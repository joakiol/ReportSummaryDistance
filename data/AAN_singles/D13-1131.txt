Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1325?1336,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsThis Text Has the Scent of Starbucks:A Laplacian Structured Sparsity Model forComputational Branding AnalyticsWilliam Yang WangSchool of Computer ScienceCarnegie Mellon Universityww@cmu.eduEdward Lin and John KominekVoci Technologies, Inc.Pittsburgh, PA 15217{ed.lin,john.kominek}@vocitec.comAbstractWe propose a Laplacian structured sparsitymodel to study computational branding ana-lytics.
To do this, we collected customer re-views from Starbucks, Dunkin?
Donuts, andother coffee shops across 38 major citiesin the Midwest and Northeastern regions ofUSA.
We study the brand related languageuse through these reviews, with focuses onthe brand satisfaction and gender factors.
Inparticular, we perform three tasks: auto-matic brand identification from raw text, jointbrand-satisfaction prediction, and joint brand-gender-satisfaction prediction.
This work ex-tends previous studies in text classification byincorporating the dependency and interactionamong local features in the form of structuredsparsity in a log-linear model.
Our quantita-tive evaluation shows that our approach whichcombines the advantages of graphical model-ing and sparsity modeling techniques signifi-cantly outperforms various standard and state-of-the-art text classification algorithms.
In ad-dition, qualitative analysis of our model re-veals important features of the language usesassociated with the specific brands.1 IntroductionIn marketing science, branding is a modern market-ing strategy of creating a unique image for a prod-uct in the customers?
mind.
Establishing the brandin the broad social context is just as important asbuilding a good product (Makens, 1965; Ledererand Hill, 2001; Kim et al 2013).
In fact, blindtaste test experiments have frequently shown howbranding directly leads to the success of productsand companies.
Most notably is a continued studysponsored by Pepsi, known as the Pepsi Challenge1,where Pepsi demonstrates how even though peoplepreferred the taste of Pepsi, Coca-Cola?s brandinghas made it more popular.
Even now, Microsoftuses similar blind taste tests2 to compare search en-gines, Bing and Google, showing that although par-ticipants prefer Bing?s results, Google?s brand mighthave strengthened over the years.
These studies allsuggest that brand and its associations play impor-tant roles in the customers?
perceptions and deci-sions.To accommodate the market change, companiesfrequently adjust branding strategies by analyzinghow their customers receive and respond to brand-ing messages.
So far, such analysis is often doneby using surveys and focus groups (Moon andQuelch, 2006), which is expensive and not time-efficient.
Recently, with the advance of machinelearning techniques, researchers from the chemistryand vision communities started to pay attention tothe problem of automatic brand identification fromsmell (Luo et al 2004) and images (Pelisson et al2003).
In contrast, even though textual data thatcontains hidden branding information is abundantlyavailable in many forms over the Web, automaticdiscovery and computational analysis on such dataare not well studied in the past.Computational branding analytics (CBA) seeks toextract information, trends, and demographics abouta brand on the basis of free-form text, e.g.
fromblogs, Twitter comments, reviews, or forum posts.As described in Section 3, in this study we use a sub-1http://en.wikipedia.org/wiki/Pepsi Challenge2http://www.bingiton.com/1325set of online Yelp reviews that discuss coffee shops.The main reason is that this source has the advan-tage of providing ground truth of multi-labeled data:each review has meta-information defining a 5-starrating, the object of the review, and the reviewer?sname (from which we infer gender).
For the pur-pose of this paper we decompose CBA into threesub-problems.?
How well can the brand being discussed beidentified by the raw text??
How well can the joint value of brand and rat-ing be predicted??
How well can the joint value of brand, rating,and gender be predicted?There are two reasons why one may want to con-struct text-based classifiers of brand, rating, and gen-der, when such information is present in the reviewheader.
The first is that trained classifiers can then beapplied to other data sources, such as blogs, wherewhat is available is only the review itself.
The sec-ond is that by ?opening the hood?
to the classifierone can examine which words exhibit high affilia-tion with the predicted variables.
This can be done,for example, to contrast the preferences of males andfemales with respect to evaluating the qualities of acoffee shop.
Examples of such insights are providedin Section 5.5.In this paper, we propose a Laplacian structuredsparsity model for computational branding analyt-ics.
Our main contributions are two-fold: first, inthe novel task of automatic brand identification fromtext, we show that by incorporating the dependencystructure and graphical interactions among localfeatures, our model significantly outperforms vari-ous text classification algorithms such as the stan-dard logistic regression, principle component anal-ysis (PCA), linear kernel support vector machine(SVM), sparse, non-sparse, and mixed-penalty log-linear models.
These improvements could also beseen from a joint brand-satisfaction prediction taskand a gender-specific joint brand-satisfaction predic-tion task.
In addition, our Laplacian augmented L1-ball projection experiment shows that the advantageof Laplacian structured sparsity is robust across dif-ferent parameter settings in a L1-constrained prob-lem.
Secondly, the qualitative analysis of our ma-chine learning model shows the interesting featuresand language use that relate to brand and its associ-ated pragmatics.In the next section, we outline related work inCBA, sparsity, and spectral graph learning.
In Sec-tion 3, we describe the corpus in this study.
TheLaplacian structured sparsity model is introduced inSection 4.
The experimental setup and results arepresented in Section 5.
A short discussion is fol-lowed in Section 6 and we conclude in Section 7.2 Related WorkEarly work on statistical brand analysis in themarketing community dates back to the work ofKuehn (1962), where he first hypothesizes thatbrand choice could be described as a learning pro-cess.
Guadagni and Little (1983) further empiri-cally tested the hypothesis by building a calibratedmultinomial logistic regression model to predict thepurchase of ground coffee, using the data from theoptical scanning of product code in supermarkets.Outside the marketing community, statistical brandanalysis is rarely seen.
More recently, a study (Luoet al 2004) applies neural networks to identifycigarette brands, with the hope of detecting illegalcigarettes from smell features.
In image process-ing, researchers have studied the problem of brandidentification from image using histogram compar-ison (Pelisson et al 2003).
However, to the bestof our knowledge, even though textual data is vastlyavailable, the problems of automatic brand identi-fication from raw text and computational brandinganalytics, are new.Although the domain of our data is on branding,our work also aligns with previous work in text andlanguage classification.
Over the years, logistic re-gression and linear kernel SVM have shown to bevery successful in various regression and classifi-cation tasks in NLP (Chahuneau et al 2012; Bi-adsy et al 2011).
Recently, sparse discriminativemethods that model the sparse nature of text be-come attractive, because unlike dense models, theyare less likely to overfit to the training data, easierto interpret, and often lead to state-of-the-art results.For example, Eisenstein et al(2011b) use the L1,?sparsity model to discover sociolinguistic patterns.Wang et al(2012a) compare lasso, ridge, and elas-tic net models to predict impoliteness behaviors inteenager conversations.
Martins et al(2011) inves-tigate the tree-structured overlapping group lasso for1326structured prediction problems.
Chen et al(2013)study the use of element-wise, group-wise, and hi-erarchical sparsity models for dialogue act classif-cation.
Sparse inducing priors are also investigatedand shown to be effective in generative models fortopic modeling (Eisenstein et al 2011a; Wang etal., 2012b; Paul and Dredze, 2012).Besides lacking sparsity, since the traditional dis-criminative methods in NLP often use interdepen-dent features such as n-grams tokens, and part-of-speech tags, they also suffer from the problem of notexplicitly modeling the complex dependency struc-ture and interaction of local features from a globalperspective.
To solve this problem, graph meth-ods seem to be a good solution, because they aresimple, generalizable, and are often used to modelsuch complex dependency structures (Cohen, 2012).However, combining the sparse modeling and spec-tral graphical modeling approaches in a principledway is challenging.
Belkin et al(2006) and Wein-berger et al(2007) are among the first to investi-gate graph Laplacians as a manifold regularizationmethod for statistical learning.
Recently, Gao etal.
(2012) propose a histogram intersection basedkNN method to construct a Laplacian matrix for aleast-square sparse coding problem in image pro-cessing.
Unfortunately, this method might be toospecific to the SIFT-based image coding tasks, thusmight not be applicable to the text classificationproblem that utilizes n-gram lexical features.3 DatasetsWe collected Yelp reviews from 1,860 Starbucks,Dunkin?
Donuts3, and other coffee shops all overthe Midwest and Northeast regions in the period of2009.
A detail statistics of our data can be foundin Table 1.
The Midwest region includes 12 states4and 19 major cities, and the Northeast region in-cludes 9 states5 and 19 major cities.
For each region,we divide the coffee shops into 60% training, 20%development, and 20% test, and there are no over-laps of coffee shops among these subsets.
There arethree values for the brand label: Starbucks, Dunkin?Donuts, and all other coffee shop brands.
The ma-3We chose these two brands because they are reported asthe leading coffee shops by WSJ (Ovide, 2011) and Forbes (Di-Carlo, 2004).4IL, WI, SD, ND, MN, MO, OH, NE, KS, IA, IN, and MI.5CT, ME, MA, NH, RI, VT, NJ, NY and PA.Coffee Shops ReviewsTrain Dev.
Test Train Dev.
Test1 451 150 150 3,513 1,087 1,4242 665 222 222 6,982 2,530 2,358T.
1,116 372 372 10,495 3,617 3,782Table 1: Dataset statistics.
1: midwest region.
2: north-east region.
T.: total.jority class is ?all other coffee shop brands?, andthe majority baseline is shown in Table 2.
In thetask of joint brand-satisfaction prediction, we utilizethe review scores to approximate user satisfaction:scores 1-2 as the unsatisfactory label, 3 as moder-ate, and 4-5 as satisfactory.
Since the Yelp reviewsdo not reveal the reviewer?s gender, we use a similarmethod that U.S. Census Bureau used (OConnelland Gooding, 2006): we first automatically matchthe first name of the reviewer with the prior name-gender distributions in the census records, then man-ually examine the no-match cases and a subsampleof the matched cases.
For those who we cannotdetermine the gender, the review will be droppedfrom the gender-specific brand-satisfaction predic-tion task.
After filtering, there are 8,528 documentsfor training, 2,928 for development, and, 3,046 fortesting.
Since the focus of this paper is not on fea-ture engineering, we use unigram features to repre-sent each review.
Below is an example of positivereview from a male Starbucks customer from Mid-west.My favorite place for my iced vanilla lattes.They have screwed up my order before: insteadof a grande, I got a venti.
Not a fan of theirpastries though.
I got a donut once, and endedup feeding it to a pigeon in city garden.
Friendlyand fast service.
Not open Sundays.The coffee shop dataset is freely available6 for re-search purposes.4 Our Approach4.1 Problem Formulation and Predictive TasksThe automatic brand identification problem couldbe considered as a traditional multiclass classifica-6http://www.cs.cmu.edu/?yww/data/emnlp2013.zip1327tion problem where the estimated label Y?
couldbe drawn from Mult(?
), where ?
is the parame-ter for the multinomial distribution.
To solve this,a simple but accurate solution is to decompose themulticlass problem into multiple binary classifica-tion problems (Rifkin and Klautau, 2004) by train-ing k one-vs-all binary classifiers, and then use theargmax criteria to select the best hypothesis from thek posteriors.
As for a binary classifier, we need toinfer the posterior from a Bernoulli distribution thatis parametrized by ??y.
Similarly, we can derive kbinary classifiers:??
(1)y , ??
(2)y , ..., ??
(k)y .
(1)So, instead of drawing Y?
from a multinomial distri-bution Mult(?
), we can draw the final label Y?
thathas the largest posterior across all k classifiers:Y?
= argmaxY,i=1,2,...,kPr(Y |??
(i)y , ~Xt) (2)where ~Xt is the testing vector, and Pr(Y |??
(i)y , ~Xt) isthe posterior probability given the learned classifiersand the testing vector.In this paper, we investigate three multiclass clas-sification tasks: first, we perform a 3-way classi-fication task for automatic brand identification.
Inthe task of brand-satisfaction prediction, we modelthe brand and the satisfaction label at the sametime (Chahuneau et al 2012): we perform the taskof jointly predicting aggregate brand-satisfactionscore for a review using 9-way classification.
Sim-ilarly, we perform 18-way classification for thegender-specific joint brand-satisfaction predictiontask.4.2 The Log-Linear Framework and ItsRegularized VariantsIf we consider the standard logistic regression modelas the binary classifier in this log-linear framework7,then each classifier can be written as:?
?y =exp(~W> ~Xj)1 + exp(~W> ~Xj) (3)here, ~Xj is the j-th observed feature vector, labely ?
{0, 1}, and ~W is a vector of the coefficients.
To7We thank Jacob Eisenstein for the initial derivation of thelogistic regression model.estimate the model parameters in equation (3), weonly need to set the weights ~W .
We can obtain thefollowing log likelihood, and its gradient functionby taking the first-order partial derivative of ~W :` =?jyj log ?
?yj + (1?
yj) log(1?
?
?yj ) (4)?`?
~W=?j(???yj?
~W)(yj??yj?1?
yj1?
??yj)(5)???yj?
~W=(?
?yj ?
(?
?yj )2)~X, (6)since the log likelihood objective function (4) is con-cave, using standard gradient ascent with maximumlikelihood estimation can solve the problem.
How-ever, this model does not penalize the noisy featuresand unreliable features that might overfit to the train-ing data.
To address this issue, we introduce the L1norm from lasso technique (Tibshirani, 1996) to reg-ularize the above likelihood function.
Thus, insteadof maximizing the likelihood, we can minimize theloss function of the negative log-likelihood with alinear penalty:min(?
`+ ?1|| ~W ||)(7)where ?1 is the regularization coefficient.
The bene-fit of L1 penalty in a discriminative model is sim-ilar to the double exponential distribution of thesparse priors in generative models (Eisenstein et al2011a): they both push the weights of many noisyfeatures into zeros, revealing only the important fea-tures.
However, since the L1 penalty can intro-duce discontinuities to the original convex function,we can also consider an alternative non-sparse ridgeestimator (Le Cessie and Van Houwelingen, 1992)with log loss and L2 norm, and has the convex prop-erty:min(?
`+ ?2|| ~W ||2)(8)Another option that balances the sparsity andsmoothness would be the elastic net model (Zou andHastie, 2005) that uses the composite penalty:min(?
`+ ?1|| ~W ||+ ?2|| ~W ||2)(9)4.3 The Laplacian Structured Sparsity ModelSo far, none of the above element-wise penalty mod-els in the previous subsection takes into account the1328dependency structure of the local features.
Inspiredby Gao et al2012), we group the local features thathave similar distributions together.
The intuition isthat, for features that have very similar empirical dis-tributions in the training set, their weights should notbe drastically different after the learning process inthe same task.
In our new objective function, it isdesirable to introduce a new component that struc-turally penalize these cases where features that arevery similar to each other, but have learned com-pletely different weights, probably due to the noiseor the data sparsity issue in the training data.The Objective Function: To do this, we first definean inter-feature affinity matrix A, where A(p,q) mea-sures the similarity between a pair of features p andq.
In the spectral graph theory, this affinity matrixcan be viewed as a weighted undirected graph G =(V,E), where each node Vp denotes a feature p, andeach edge E(p,q) indicates the closeness among thefeatures p and q.
We also introduce a weighted di-agonal degree matrix D, of which each element inthe diagonal D(p,p) is the sum of all weighted con-nections of node Vp: D(p,p) =?Qq=1A(p,q).
Wepropose the following objective function:min(?
`+ ?1|| ~W ||+ ?2|| ~W ||2 (10)+ ??
(p,q)|| ~Wp ?
~Wq||2A(p,q))(11)We then denote a graph Laplacian matrix L = D ?A (Belkin and Niyogi, 2001), and rewrite the objec-tive function as:min(?
`+ ?1|| ~W ||+ ?2|| ~W ||2 (12)+ ?
( ~W>L ~W ))(13)where ?
is the regularization parameter for theLaplacian structured sparsity term.
Intuitively, theobjective function can be interpreted as the sum ofa negative log loss function, the sparsity-inducingpenalty, the quadratic penalty, and the Laplacianstructured penalty.
Or, another view of this newmodel could be seen as a Laplacian augmented elas-tic net model where structured sparsity and featureinteraction are considered.The Laplacian Matrix: In this model, a key aspectis to derive the Laplacian matrix L. We propose thefollowing three steps to learn the Laplacian matrix:Figure 1: An example of the graph G, the correspondingaffinity matrixA, and the corresponding Laplacian matrixL.1.
Construct the distance matrix Dist.
To con-struct the distance matrix between each fea-ture, we first transpose the instance-feature ma-trix, I =?j~Xj , and assume that each feature(e.g.
unigram in our task) is a random variablethat has a multinomial distribution over the in-stances in the training set.
Then, we compareeach pair of features, and calculate the inter-feature distance matrix Dist with Euclideandistance as a measure, and use the k-nearestneighbors (kNN) method (Beyer et al 1999)to select the top neighbors of each feature.2.
Derive the affinity matrix A.
To assign theweight on the edge E(p,q) for each connectednodes (the kNN of V in Dist), we use thecosine similarity cosine(Vp, Vq) metric (Wangand Hirschberg, 2011).3.
Generate the degree matrix D and Lapla-cian matrix L. As discussed earlier, we sumup the symmetric affinity matrix by row, andobtain a diagonal degree matrix D, and we fur-ther define a Laplacian matrix L = D ?A.To calculate the above matrices in an efficient man-ner, we partition the covariate into blocks, and pro-cess each block in parallel (Chen et al 2011).
Anintuitive example of the graphG, its associated affin-ity matrix A, and Laplacian matrix L, is shown inFigure 1.Parameter Estimation: Regarding the optimiza-tion of objective function in (12-13), a notable prob-lem is that the sparsity inducing L1 term is non-differentiable, whereas this is not the case for the L2norm and the Laplacian structured sparsity term.
Ifwe first take the derivative of the latter two terms,1329and we can derive the following gradient compo-nents:?
(?2|| ~W ||2 + ?
( ~W>L ~W ))?
~W(14)= 2?2 ~W + ?
( ~W>L> + ~W>L) (15)= 2?2 ~W + ?
(L> + L) ~W (16)since our Laplacian matrix is symmetric, we canrewrite (16) as2(?2 ~W + ?L ~W ) (17)Then, we combine the gradient of the log loss func-tion in (5) with (17), and apply a bound-constrainedre-formulation (Schmidt et al 2007) and the lim-ited memory BFGS (L-BFGS) method (Liu and No-cedal, 1989) to solve the L1 regularized problem.The L-BFGS method has relatively low space com-plexity, and does not require the calculation of fullHessian matrix, thus it is often used for L1 optimiza-tion problems.Augmented Laplacian for an L1-ConstrainedProblem: Instead of formulating the L1-regularizedproblem by adding the L1 norm, an alternative so-lution is to formulate a L1-constrained problem byfixing the sum of all weights ?
in the weight vector~W .
The reason is because adding the L1 norm willmake the objective function not continuously differ-entiable, where as the L1 constraint could be just asimple linear constraint (Lee et al 2006).
Thus, thealternative L1-constrained problem could be definedas:min(?`), s.t.
?p~Wp ?
?
(18)To test the robustness of Laplacian structured spar-sity term in the setup of a L1-constrained problem,we can incorporate the Laplacian penalty term intothe above formula, and derive:min(?
`+ ?
( ~W>L ~W )), s.t.
?p~Wp ?
?
(19)Note that the Laplacian matrix is positive-semidefinite,~W>L ~W = ~W>?
(p,q)L(p,q) ~W (20)=?
(p,q)~W>L(p,q) ~W (21)=?
(p,q)|| ~Wp ?
~Wq||2A(p,q) (22)because this graph Laplacian penalty can be viewedas a quadratic term, and the objective functionin equation 19 is now convex differentiable andwill produce sparse estimates, so that we are ableto use a limited-memory projected quasi-Newtonmethod (Schmidt et al 2009) to solve the dual formof this problem.
The Lagrangian dual form of theproblem in equation 19 can be written as:L( ~W, ?)
= ?`+ ?
( ~W>L ~W ) (23)+ ?
(?p~Wp ?
?)?
?
~W (24)where ?
?
R is a Lagrange multiplier, and ?
?
Rp+is a p-dimensional vector of non-negative Lagrangemultipliers.
And then we can take first-order partialderivative with regard to ~W , and set it to zero to de-rive the optimality:?L?
~W= ??j(?
?yj ?
(?
?yj )2)~X(yj??yj?1?
yj1?
?
?yj)(25)+ 2?L ~W + ?
?
?
= 0 (26)To speed up the training, we use the linear-time L1-ball projection method from Duchi et al(2008) inour implementation.5 ExperimentsWe first compare our model to various baselines inthe 3-way automatic brand identification task.
Be-sides the logistic regression, lasso, ridge and elas-tic net model that we introduced in Section 4.2, wealso compare with a PCA-based logistic regressionmodel where the dimensions of the feature space isreduced in half before the classification.
A state-of-the-art linear kernel SVM model (Chang and Lin,2011) is also taken into the comparison.
In thesecond part, we perform 9-way joint classificationof the brand-satisfaction labels.
Similarly, we alsoperform a 18-way joint classification of the brand-gender-satisfaction labels.
To test the robustnessof our model, we vary the levels of sparsity of ourLaplacian augmented method in a L1-constrainedproblem.
Finally, we analyze the identified featuresfor CBA.
Throughout this section, we use classifi-cation accuracy to report the results.
We tune theregularization parameters of log-linear models and1330Method Dev.
TestMajority class 75.67 78.08Logistic regression 91.98 91.06Linear SVM 92.45 91.75PCA 91.67 91.20Lasso 92.81 91.96Ridge 92.56 91.67Elastic net 92.81 91.83Laplacian structured sparsity 93.17* 92.44*Table 2: The automatic brand identification (3-way) per-formances.
The best result is highlighted in bold.
* indi-cates p < .001 comparing to the second best result.the cost parameter of the SVM on the developmentset, and report results on both the development setand the held-out test set.
The parameter for kNNwas set to 5 according to previous literature (Gao etal., 2012).
A paired two-tailed t-test is used to testthe statistical differences among various models.5.1 Automatic Brand Identification from TextGiven any piece of raw text from the Web (e.g.blogs, tweets, news, or forum posts), the first taskfor CBA is to identify which brand this text is re-lated to.
Our customer review data set is useful forthis task, because the ground truth of the brand labelis attached to each review.
Table 2 shows the re-sult of our model in this automatic brand identifica-tion task.
In this 3-way classification task, the over-all results indicate that it is relatively easy to iden-tify the related brand from customer reviews.
Whenevaluating our Laplacian structured sparsity model,our proposed model obtains the best performancesof 93.17% and 92.44%, which are statistically bet-ter than the second best results (p < .001) in bothdatasets.5.2 Joint Brand-Satisfaction PredictionIn our training data set, we observe a subtle correla-tion between the brand and satisfaction labels (r =0.09, p < .001), which suggests us that it might beinteresting to perform a joint prediction task for thebrand-satisfaction labels.
This task is also attractivefrom the business perspective, because it would bevery useful for the companies to directly identifyuser?s level of satisfaction about their brands.
Ta-ble 3 shows that we achieve 69.56% accuracy on theMethod Dev.
TestMajority class 55.43 55.18Logistic regression 65.80 65.80Linear SVM 67.67 65.44PCA 63.92 62.53Lasso 68.37 66.84Ridge 67.79 65.55Elastic net 68.79 66.82Laplacian structured sparsity 69.56* 67.32*Table 3: The joint brand-satisfaction prediction (9-way)performances.
The best result is highlighted in bold.
*indicates p < .001 comparing to the second best result.Method Dev.
TestMajority class 28.24 27.68Logistic regression 36.03 35.16Linear SVM 41.05 39.49PCA 35.35 34.44Lasso 40.74 39.53Ridge 40.98 38.94Elastic net 41.15 38.96Laplacian structured sparsity 41.22* 40.22*Table 4: The joint brand-gender-satisfaction prediction(18-way) performances.
The best result is highlighted inbold.
* indicates p < .001 comparing to the second bestresult.development set, and 67.32% accuracy on the testset using our proposed Laplacian structured model(p < .001 comparing to the second best results).5.3 Joint Brand-Gender-SatisfactionPredictionAnother big interest in the marketing community isto predict subgroup preferences of specific brands.In this direction, we perform a 18-way joint brand-gender-satisfaction prediction using the gender la-bels that we described in Section 3.
Table 4shows that our proposed Laplacian structured spar-sity model obtains a test accuracy of 40.22%, signif-icantly better than the second best result (p < .001).1331Figure 2: Automatic brand identification test perfor-mance varying the level of sparsity ?
in a L1 constrainedproblem.Figure 3: Joint brand-satisfaction prediction test perfor-mance varying the level of sparsity ?
in a L1 constrainedproblem.5.4 Varying the Level of Sparsity in aL1-Constrained ProblemTo test the robustness of the Laplacian structuredsparsity component, we exponentially increase thesum of weights ?
to vary the level of sparsity in aL1-constrained setup.
When ?
increases, the non-zero weights in the model also increases.
Figures 2and 3 show that the Laplacian augmented L1-ballprojection statistically outperform the L1-ball pro-jection baseline in all levels of sparsity (p < .001).In Figure 4, Laplacian augmented L1-ball projectionis also statistically better than the L1-ball projection(p < .001), except when ?
= 32 and ?
= 64.5.5 Exploratory Data AnalysisWe outline the top 15 keywords from the Laplacianstructured sparsity model that are associated with theStarbucks and Dunkin?
Donuts brands in the auto-matic brand identification task in the Table 5.
Firstof all, it is observed that our model has discoveredsynonyms for both brands: ?sbux?, ?dd?, ?dds?.Figure 4: Joint brand-gender-satisfaction prediction testperformance varying the level of sparsity ?
in a L1 con-strained problem.Also, the results imply that Starbucks?
unique cupsize branding strategy, ?venti?, ?grande?, ?tall?, hasresonated with their customers as the words promi-nently show up as top features in reviews.
Alignedwith previous study in marketing science (Moon andQuelch, 2006), an informative set of features re-lated to Starbucks store decorations showed up inour model: ?store?, ?restroom?, ?public?, ?bath-room?, and ?spacious?.
In contrast, these featuresstopped to show up on the list of Dunkin?
Donuts.Instead, TV and game (sports), which are indeedimportant features of dining at Dunkin?
Donut, ap-peared.
Note that Baskin-Robbins, which is a sub-brand of Dunkin?
Brands Group, Inc., also appearedas informative features to predict Dunkin?
Donuts.To understand the preferences of different gen-der subgroups towards the two brands, we contrastin Table 6 and Table 7 the top features that identifythe satisfied female and male customers in the jointbrand-gender-satisfaction prediction task.Interestingly, it seems that the female customersidentify Starbucks as a place for ?studying?, with?fireplace?
as the top preference of the spots in thestore, and ?winter?
is also a high-ranked feature.Also, the adjective ?super?
was frequently men-tioned by the female Starbucks customers (but notthe males).
As for Dunkin?
Donuts, the top-rankedkeywords are still mainly associated with its names,but it seems the snack ?Munchkins?
is highly pre-ferred by the female customers.
Not surprisingly,the cue words that the male customers identify theStarbucks brand do not always agree with those ofthe females.
For example, instead of ?fireplace?,they prefer staying at the ?patio?, and drink the cof-fee from the ?clover?
brewing system.
Interestingly,1332Starbucks weight Dunkin?
weightstarbucks 1.9365 dd 2.4224sbux 1.0152 dunkin 1.7781venti 0.8216 donuts 1.6989corporate 0.7032 dunks 1.6455store 0.6580 dds 1.4936particular 0.6512 donut 1.3979tall 0.5496 dunkins 1.3729restroom 0.5447 glazed 0.9975tourists 0.5431 robbins 0.9402public 0.5260 baskin 0.8578lines 0.4956 sugar 0.6475drink 0.4787 d 0.6327bathroom 0.4721 ice 0.5835spacious 0.4629 stale 0.5404location 0.4611 game 0.5049grande 0.4563 tv 0.5010Table 5: Top features that identify the Starbucks andDunkin?
Donuts brands from the best model..on the Dunkin?s side, ?munchkins?
also disappearedand replaced by ?glazed?
(donuts).
However, bothmales and females agreed that ?fast?
or ?quick?
ser-vice was an important feature of creating satisfac-tion, which echoes with the result from self-reportedcustomer surveys (Moon and Quelch, 2006).The word ?name?
is a prominent indicator for thefemale customers of Starbucks: at first we were puz-zled, but after we digged into the database, we foundreviews such as:?
?...
and the baristas are one of the nicest theyalways ask for your name, so you never end upwith coffee meant for the guy behind you.??
?...
she asked me my name and i told her andshe excidetly proclaimed melissa and wrote myname on the cup.
This place was probably oneof the better starbucks ive been to.??
?...
all of their employees are really friendly,and embarrassingly enough most know me byname and know my typical drink order grandenonfat misto with a flavor shot of white mocha.This is actually very helpful.
?The above examples show how our system effec-tively serves as a salient keyword spotter.
And thatas a keyword spotter one can use it to extract sur-rounding context and feed that through to the nextStarbucks weight Dunkin?
weightstarbucks 0.5013 dd 0.6931chain 0.4268 dds 0.5620winter 0.3382 dunkin 0.5344fireplace 0.3089 donuts 0.4270studying 0.2972 donut 0.3732particular 0.2967 dunks 0.3687super 0.2786 morning 0.3077name 0.2543 quick 0.3012know 0.2443 how 0.2940because 0.2263 munchkins 0.2758Table 6: Top features that jointly identify the satisfiedfemale customers and the Starbucks and Dunkin?
Donutsbrands from the best model.Starbucks weight Dunkin?
weightstarbucks 0.6632 dd 0.7491throw 0.3514 dunkin 0.6075know 0.2959 dds 0.5333store 0.2885 donuts 0.5326fix 0.2498 donut 0.3215particular 0.2487 dunks 0.3158sbux 0.2462 morning 0.3095patio 0.2349 rush 0.3030prefer 0.2324 fast 0.2979clover 0.2215 moving 0.2520corporate 0.2153 glazed 0.2326Table 7: Top features that jointly identify the satisfiedmale customers and the Starbucks and Dunkin?
Donutsbrands from the best model.stage of analysis, including examination by humans.This is extremely practical and useful, because itprovides actionable items.
For example, analystscan advise managers to revise their training manualand tell store employees to remember the names ofyour frequent female customers.6 DiscussionsIn our preliminary experiments, we have also ex-perimented with the setup where the two keywords?starbucks?
and ?dunkin?
were removed from thelist of features.
This change resulted in a uniformed2% decrease in performances across all the modelsin Table 2, which did not affect the comparisons.1333However, we kept these two keywords in our finalexperiments, because the reviewers sometimes men-tion ?Dunkin?
in Starbucks reviews, and vice versa.Removing the two keywords could be problematic,since it changes the natural distribution of the data.Regarding the alternative problem setups, our pre-liminary experiments showed that instead of usingone-vs-all binary classifiers, a direct 9-way multi-class classification of joint brand-satisfaction labelsusing logistic regression only resulted an accuracyof 62%.
We also did not adopt the hierarchical clas-sification pipeline, where instead of performing jointclassification, multiple layers of classifiers could betrained to classify brand, gender, and satisfaction la-bels incrementally.
This is because the hierarchicalclassifiers suffered from the error propagation prob-lem, and the second/third layer classifier could notcorrect the errors from the previous layers (Bennettand Nguyen, 2009).Our proposed method to generate inter-featureaffinity matrix captures interesting dependency offeatures in this dataset.
For example, although thewords ?frappuccino?
and ?slurping?, ?furniture?
and?mismatched?
are semantically very different, ourmethod actually group them together due to the sub-tle interactions of these word pairs in our tasks.
Theexample in Figure 1 is also very specific to ourdataset.
This is very useful, because the word se-mantic similarity might be context-dependent, andour method learns and adapts the semantic similar-ity on the fly, hinges on the particular training set.On the other end of the spectrum, even though ourmethod is desirable in our task, one might need to becautious when working on very small data sets withonly a handful of samples.
This is because smallsamples typically have large variances in feature dis-tributions, and that the generated Laplacian matrixmight not be as reliable as in our study.
To alleviatethis potential problem, one might consider buildingthe Laplacian matrix using external resources suchas WordNet or FrameNet, even though this approachcould also introduce biases due to the mismatchedtask domains.We also observed that the accuracy of the auto-matic brand identification task was high, indicatingthe promising future of CBA for hidden brand infor-mation from other genres of text over the Web.
Al-though the performances of joint brand-satisfactionand joint brand-gender-satisfaction predictions arerelatively lower, there is still much room for im-provements: for example, using the syntactic, se-mantic, and meta-data features could potentially en-rich the proposed model.
Also, it is possible to con-sider the higher order n-gram features for better ex-ploratory data analysis.
However, since the focus ofthis paper is a proof of concept for Laplacian struc-tured sparsity models and computational brandinganalytics, we have not yet explored various multi-view representations to augment our model.Why does Laplacian structured sparsity modelwork better in these classication tasks?
Similar tothe application in image classifcation (Gao et al2010), one advantage of Laplacian regularization intext classification is that our model can explicitlymodel the dependency of local features.
Anotherreason is the expressiveness of our model: our modelallows one to express the feature interactions in astructured manner.
Thirdly, by embedding the struc-ture in the regularization term, our model is moreflexible: one can now control the structured penaltyby tuning the regularization parameter on the devel-opment set.7 ConclusionsWe introduce a Laplacian structured sparsity modelfor computational branding analytics (CBA).
In theautomatic brand identification, our model achievesthe best result, dominating many competitive base-lines.
We also introduce the tasks of joint brand-satisfaction and brand-gender-satisfaction predic-tions, and show that the Laplacian structured spar-sity do well in these tasks.
A closer evaluation thatvarying the levels of sparsity in a L1 constrainedproblem also indicates that the Laplacian augmentedL1-ball projection model can provide state-of-the-art results.
By examining the weights of the de-rived Laplacian structured sparsity model, interest-ing indicators of brands and theirs gender-specificcustomer satisfaction associations are also discov-ered.
In the future, we would like to investigate othermethods for generating robust inter-feature Lapla-cians that include deep syntactic and semantic fea-tures.AcknowledgementThe authors would like to thank the anonymous re-viewers for valuable comments.1334ReferencesM.
Belkin and P. Niyogi.
2001.
Laplacian eigenmapsand spectral techniques for embedding and cluster-ing.
Advances in neural information processing sys-tems (NIPS).M.
Belkin, P. Niyogi, and V. Sindhwani.
2006.
Mani-fold regularization: A geometric framework for learn-ing from labeled and unlabeled examples.
The Journalof Machine Learning Research (JMLR).P.
N. Bennett and N. Nguyen.
2009.
Refined experts:improving classification in large taxonomies.
In Pro-ceedings of the 32nd international ACM SIGIR con-ference on Research and development in informationretrieval.K.
Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft.1999.
When is nearest neighbor meaningful?
Pro-ceedings of the International Conference on DatabaseTheory (ICDT).F.
Biadsy, W.Y.
Wang, A. Rosenberg, and J. Hirschberg.2011.
Intoxication detection using phonetic, phono-tactic and prosodic cues.
In Proceedings of the 12thAnnual Conference of the International Speech Com-munication Association (Interspeech 2011).V.
Chahuneau, K. Gimpel, B.R.
Routledge, L. Scherlis,and N.A.
Smith.
2012.
Word salad: Relating foodprices and descriptions.C.C.
Chang and C.J.
Lin.
2011.
Libsvm: a library forsupport vector machines.
ACM Transactions on Intel-ligent Systems and Technology (TIST).W.
Y. Chen, Y.
Song, H. Bai, C. J. Lin, and E. Y. Chang.2011.
Parallel spectral clustering in distributed sys-tems.
IEEE Transactions on Pattern Analysis and Ma-chine Intelligence (TPAMI).Y.
N. Chen, W. Y. Wang, and A. I. Rudnicky.
2013.An empirical investigation of sparse log-linear modelsfor improved dialogue act classification.
In Proceed-ings of the 38th International Conference on Acous-tics, Speech, and Signal Processing (ICASSP 2013).W.
W. Cohen.
2012.
Learning similarity measures basedon random walks.
In Procceedings of the 21nd ACMInternational Conference on Information and Knowl-edge Management (CIKM).L.
DiCarlo.
2004.
Dunkin?
donuts vs. starbucks.
InForbes.com - Monday Matchup.J.
Duchi, S. Shalev-Shwartz, Y.
Singer, and T. Chandra.2008.
Efficient projections onto the l1-ball for learn-ing in high dimensions.
In Proceedings of the 25th in-ternational conference on Machine learning (ICML).J.
Eisenstein, A. Ahmed, and E. Xing.
2011a.
Sparseadditive generative models of text.
Proceedings of the28th International Conference on Machine Learning(ICML 2011).J.
Eisenstein, N. A. Smith, and E. P. Xing.
2011b.
Dis-covering sociolinguistic associations with structuredsparsity.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Hu-man Language Technologies (ACL-HLT).S.
Gao, I. W. Tsang, L. T. Chia, and P. Zhao.
2010.
Localfeatures are not lonely?laplacian sparse coding for im-age classification.
In 2010 IEEE Conference on Com-puter Vision and Pattern Recognition (CVPR).S.
Gao, I. Tsang, and L. Chia.
2012.
Laplacian sparsecoding, hypergraph laplacian sparse coding, and ap-plications.
IEEE Transactions on Pattern Analysis andMachine Intelligence (TPAMI).P.
M. Guadagni and J. D. C. Little.
1983.
A logit modelof brand choice calibrated on scanner data.
Marketingscience.M.
K. Kim, K. Lopetcharat, and M. A. Drake.
2013.
In-fluence of packaging information on consumer likingof chocolate milk.
Journal of dairy science.A.A.
Kuehn.
1962.
Consumer brand choice as a learningprocess.S.
Le Cessie and JC Van Houwelingen.
1992.
Ridgeestimators in logistic regression.
Applied statistics.Chris Lederer and Sam Hill.
2001.
See your brandsthrough your customers eyes.
Harvard Business Re-view, 79(6):125?133.S.I.
Lee, H. Lee, P. Abbeel, and A.Y.
Ng.
2006.
Effi-cient l1 regularized logistic regression.
In Proceedingsof the National Conference on Artificial Intelligence(AAAI).D.C.
Liu and J. Nocedal.
1989.
On the limited memorybfgs method for large scale optimization.
Mathemati-cal programming.D.
Luo, H.G.
Hosseini, and J.R. Stewart.
2004.
Appli-cation of ann with extracted parameters from an elec-tronic nose in cigarette brand identification.
Sensorsand Actuators B: Chemical.J.
C. Makens.
1965.
Effect of brand preference uponconsumers perceived taste of turkey meat.
Journal ofApplied Psychology.A.
F. T. Martins, N. A. Smith, P. M. Q. Aguiar, andM.
A. T. Figueiredo.
2011.
Structured sparsity instructured prediction.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP).Y.
Moon and J. Quelch.
2006.
Starbucks: deliveringcustomer service.
Harvard Business School.M.
OConnell and G. Gooding.
2006.
The use of firstnames to evaluate reports of gender and its effecton the distribution of married and unmarried couplehouseholds.
In Proceedings of the Annual Meetings ofthe Population Association of America.S.
Ovide.
2011.
Face off!
dunkin?
donuts vs. starbucks.In Deal Journal - Wall Street Journal Blogs.1335M.
Paul and M. Dredze.
2012.
Factorial lda: Sparsemulti-dimensional text models.
In Advances in NeuralInformation Processing Systems (NIPS).F.
Pelisson, D. Hall, O. Riff, and J. Crowley.
2003.
Brandidentification using gaussian derivative histograms.Computer Vision Systems.R.
Rifkin and A. Klautau.
2004.
In defense of one-vs-all classification.
The Journal of Machine LearningResearch (JMLR).M.
Schmidt, G. Fung, and R. Rosales.
2007.
Fast opti-mization methods for l1 regularization: A comparativestudy and two new approaches.
Machine Learning.M.
Schmidt, E. Van Den Berg, M. Friedlander, andK.
Murphy.
2009.
Optimizing costly functionswith simple constraints: A limited-memory projectedquasi-newton algorithm.
In Proceedings of Confer-ence on Artificial Intelligence and Statistics (AIStats).R.
Tibshirani.
1996.
Regression shrinkage and selectionvia the lasso.
Journal of the Royal Statistical Society.Series B (Methodological).W.
Y. Wang and J. Hirschberg.
2011.
Detecting levels ofinterest from spoken dialog with multistream predic-tion feedback and similarity based hierarchical fusionlearning.
In Proceedings of the 12th annual SIGdialMeeting on Discourse and Dialogue (SIGDIAL 2011).W.
Y. Wang, S. Finkelstein, A. Ogan, A. W. Black, andJ.
Cassell.
2012a.
?love ya, jerkface?
: using sparselog-linear models to build positive (and impolite) re-lationships with teens.
In Proceedings of the 13thannual SIGdial Meeting on Discourse and Dialogue(SIGDIAL 2012).W.
Y. Wang, E. Mayfield, S. Naidu, and J. Dittmar.2012b.
Historical analysis of legal opinions with asparse mixed-effects latent variable model.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics (ACL 2012).K.
Q. Weinberger, F. Sha, Q. Zhu, and L. K. Saul.
2007.Graph laplacian regularization for large-scale semidef-inite programming.
Advances in neural informationprocessing systems (NIPS).H.
Zou and T. Hastie.
2005.
Regularization and vari-able selection via the elastic net.
Journal of the RoyalStatistical Society: Series B (Statistical Methodology).1336
