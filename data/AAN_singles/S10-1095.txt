Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 427?432,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsUMCC-DLSI: Integrative resource for disambiguation taskYoan Gutie?rrez and Antonio Ferna?ndezDI, University of MatanzasAutopista a Varadero km 31/2Matanzas, Cubayoan.gutierrez,antonio.fernandez@umcc.cuAndre?s Montoyo and Sonia Va?zquezDLSI, University of AlicanteCarretera de San Vicente S/NAlicante, Spainmontoyo,svazquez@dlsi.ua.esAbstractThis paper describes the UMCC-DLSIsystem in SemEval-2010 task number 17(All-words Word Sense Disambiguationon Specific Domain).
The main purposeof this work is to evaluate and compareour computational resource of WordNet?smappings using 3 different methods:Relevant Semantic Tree, RelevantSemantic Tree 2 and an Adaptation ofk-clique?s Technique.
Our proposal isa non-supervised and knowledge-basedsystem that uses Domains Ontology andSUMO.1 IntroductionAmbiguity is the task of building up multiplealternative linguistic structures for a singleinput (Kozareva et al, 2007).
Word SenseDisambiguation (WSD) is a key enabling-technology that automatically chooses theintended sense of a word in context.
In this task,one of the most used lexical data base is WordNet(WN) (Fellbaum, 1998).
WN is an online lexicalreference system whose design is inspired bycurrent psycholinguistic theories of human lexicalmemory.
Due to the great popularity of WNin Natural Language Processing (NLP), severalauthors (Magnini and Cavaglia, 2000), (Nilesand Pease, 2001), (Niles and Pease, 2003),(Valitutti, 2004) have proposed to incorporate tothe semantic net of WN, some taxonomies thatcharacterize, in one or several concepts, the sensesof each word.
In spite of the fact that there havebeen developed a lot of WordNet?s mappings,there isn?t one unique resource to integrate allof them in a single system approach.
To solvethis need we have developed a resource that joinsWN1, the SUMO Ontology2, WordNet Domains3and WordNet Affect4.
Our purpose is to test theadvantages of having all the resources together forthe resolution of the WSD task.The rest of the paper is organized as follows.In Section 2 we describe the architecture of theintegrative resource.
Our approach is shown inSection 3.
Next section presents the obtainedresults and a discussion.
And finally theconclusions in Section 5.2 Background and techniques2.1 Architecture of the integrative resourceOur integrative model takes WN 1.6 as nucleusand links to it the SUMO resource.
Moreover,WordNet Domains 2.0 (WND) and WordNetAffect 1.1 (WNAffects) are also integrated butmapped instead to WN 2.0.
From the modelshowed in Figure 1, a computational resource hasbeen built in order to integrate the mappings abovementioned.The model integrator?s proposal providesa software that incorporates bookstores ofprogramming classes, capable to navigate insidethe semantic graph and to apply any type ofpossible algorithm to a net.
The softwarearchitecture allows to update WN?s version.In order to maintain the compatibility with otherresources mapped to WN, we have decided to useWN 1.6 version.
However, the results can beoffered in anyone of WN?s versions.1http://www.cogsci.princeton.edu/ wn/2http://suo.ieee.org3http://wndomains.fbk.eu/4http://wndomains.fbk.eu/wnaffect.html427Figure 1: WordNet integrative model2.2 The k-clique?s TechniqueFormally, a clique is the maximum number ofactors who have all possible ties presented amongthemselves.
A ?Maximal complete sub-graph?
issuch a grouping, expanded to include as manyactors as possible.
?A k-clique is a subset of vertices C such that,for every i, j ?
C, the distance d(i, j)k. The 1-clique is identical to a clique, because the distancebetween the vertices is one edge.
The 2-cliqueis the maximal complete sub-graph with a pathlength of one or two edges?.
(Cavique et al, 2009)3 The ProposalOur proposal consists in accomplishing three runswith different algorithms.
Both first utilize thedomain?s vectors; the third method utilizes k-cliques?
techniques.This work is divided in several stages:1.
Pre-processing of the corpus (lemmatizationwith Freeling) (Atserias et al, 2006).2.
Context selection (For the first (3.1), andthe third (3.3) run the context window wasconstituted by the sentence that containsthe word to disambiguate; in the secondrun the context window was constitutedby the sentence that contains the word todisambiguate, the previous sentence and thenext one).3.
Obtaining the domain vector, this vector isused in first and the second runs (whenthe lemma of the words in the analyzedsentence is obtained, the integrative resourceof WordNet?s Mappings is used to get therespective senses from each lemma).4.
Obtaining the all resource vector: SUMO,Affects, and Domain resource.
This is onlyfor the third run (3.3).5.
Relevant Semantic Tree construction(Addition of concepts parents to the vectors.For the first (3.1) and second (3.2) runs onlyDomain resource is used; for the third (3.3)run all the resources are used).6.
Selection of the correct senses (the first andthe second runs use the same way to do theselection; the third run is different.
We makean exception: For the verb ?be?
we select thesense with the higher frequency according toFreeling.3.1 Relevant Semantic TreeWith this proposal we measure how much aconcept is correlated to the sentence, similar toReuters Vector (Magnini et al, 2002), but witha different equation.
This proposal has a partialsimilarity with the Conceptual Density (Agirreand Rigau, 1996) and DRelevant (Va?zquez et al,2004) to get the concepts from a hierarchy thatthey associate with the sentence.In order to determine the Association Ratio(RA) of a domain in relation to the sentence, theEquation 1 is used.RA(D, f) =n?i=1RA(D, fi) (1)where:RA(D,w) = P (D,w) ?
log2P (D,w)P (D)(2)f : is a set of words w.fi: is a i-th word of the phrase f .P (D,w): is joint probability distribution.P (D): is marginal probability.From now, vectors are created using theSenseval-2?s corpus.
Next, we show an example:For the phrase: ?But it is unfair to dumpon teachers as distinct from the educationalestablishment?.By means of the process Pres-processinganalyzed in previous stage 1 we get the lemma andthe following vector.428Phrase [unfair; dump; teacher, distinct,educational; establishment]Each lemma is looked for in WordNet?sintegrative resource of mappings and it iscorrelated with concepts of WND.VectorRA Domains0.9 Pedagogy0.9 Administration0.36 Buildings0.36 Politics0.36 Environment0.36 Commerce0.36 Quality0.36 Psychoanalysis0.36 EconomyTable 1: Initial Domain VectorAfter obtaining the Initial Domain Vector weapply the Equation 3 in order to build the RelevantSemantic Tree related to the phrase.DN(CI,Df) = RA CI ?MP (CI,Df)TD(3)Where DN : is a normalized distanceCI: is the Initial Concept which you want toadd the ancestors.Df : is Parent Domain.RA CI: is a Association Ratio of the childConcept.TD: is Depth of the hierarchic tree of theresource to use.MP : is Minimal Path.Applying the Equation 3 the algorithm to decidewhich parent domain will be added to the vector isshown here:if (DN(CI,Df) > 0){if ( Df not exist)Df is added to the vector with DN value;elseDf value = Df value + DN ;}As a result the Table 2 is obtained.This vector represents the Domain treeassociated to the phrase.After the Relevant Semantic Tree is obtained,the Domain Factotum is eliminated from the tree.Due to the large amount of WordNet synsets,VectorRA Domains1.63 Social Science0.9 Administration0.9 Pedagogy0.8 RootDomain0.36 Psychoanalysis0.36 Economy0.36 Quality0.36 Politics0.36 Buildings0.36 Commerce0.36 Environment0.11 Factotum0.11 Psychology0.11 Architecture0.11 Pure ScienceTable 2: Final Domain VectorFigure 2: Relevant semantic treethat do not belong to a specific domain, butrather they can appear in almost all of them, theFactotum domain has been created.
It basicallyincludes two types of synsets: Generic synsets,which are hard to classify in a particular domain;and Stop Senses synsets which appear frequentlyin different contexts, such as numbers, weekdays, colors, etc.
(Magnini and Cavaglia, 2000),(Magnini et al, 2002).
Words that contain thissynsets are frequently in the phrases, therefore thesenses associated to this domain are not selected.After processing the patterns that characterizethe sentence, the following stage is to determinethe correct senses, so that the next steps ensue:1.
Senses that do not coincide with thegrammatical category of Freeling areremoved.4292.
For each word to disambiguate all candidatesenses are obtained.
Of each sensethe relevant vector are obtained using theEquation 4, and according to the previousEquation 3 parent concepts are added.RA(D, s) = P (D, s) ?
log2P (D, s)P (D)(4)where s: is a sense of word.P (D, s): is joint probability distributionbetween Domain concept D and the sense s.P (D): is marginal probability of the Domainconcept.3.
The one that accumulates the bigger value ofrelevance is assigned as correct sense.
Thefollowing process is applied:For each coincidence of the elements in thesenses?
domain vector with the domain vectorof the sentence, the RA value of the analyzedelements is accumulated.
The process isdescribed in the Equation 5.AC(s, V RA) =?kV RA[V sk]?i=1V RAi(5)where AC: The RA value accumulated forthe analyzed elements.V RA: Vector of relevant domains of thesentence with the format: V RA [domain ?value RA].V s: Vector of relevant domain of the sensewith the format: V s [domain].V sk: Is a k-th domain of the vector V s.V RA[V sk]: Represents the value of RAassigned to the domain V sk for the valueV RA.The?i=1V RAiterm normalizes the result.3.2 Relevant Semantic Tree 2This run is the same as the first one with alittle difference, the context window is constitutedby the sentence that contains the word todisambiguate, the previous sentence and the nextone.3.3 Adaptation of k-clique?s technique to theWSDThey are applied, of the section 3, the steps fromthe 1 to the 5, where the semantic trees of conceptsare obtained.Then they are already obtained for all thewords of the context, all the senses discriminatedaccording to Freeling (Atserias et al, 2006).Then a sentence?s net of knowledge is builtby means of minimal paths among each senseand each concept at trees.
Next the k-clique?stechnique is applied to the net of knowledge toobtain cohesive subsets of nodes.To obtain the correct sense of each word it islooked, as proposed sense, the sense belonging tothe subset containing more quantities of nodes andif it has more than a sense for the same word,the more frequent sense is chosen according toFreeling.4 Results and DiscussionThe conducted experiments measure theinfluence of the aforementioned resources inthe disambiguation task.
We have evaluated themindividually and as a whole.
In the Table 3 itis represented each one of the inclusions andcombinations experimented with the RelevantSemantic Tree method.Resources Precision Recall AttemptedWNAffect 0.242 0.237 97.78%SUMO 0.267 0.261 98.5%WND 0.328 0.322 98.14%WND &SUMO0.308 0.301 97.78%WND &SUMO &WNAffect0.308 0.301 97.78%Table 3: Evaluation of integrated resourcesAs it can be observed, in the evaluation forspecific domain corpus the best results are reachedwhen only domain resource is used.
But thisis not a conclusion about the resources inclusionbecause the use of this method for global domain,for example with the task English All words fromSenseval-2 (Agirre et al, 2010), the experimentadding all the resources showed good results.
Thisis due to the fact that the global domain includesinformation of different contexts, exactly whatis representing in the mentioned resources.
For430this reason, in the experiment with global domainand the inclusion of all the resource obtainedbetter results than using this method with specificdomain, 42% of recall and 45% of precision(Gutie?rrez, 2010).For example, with the k-clique?s technique,utilizing the English All word task from Senseval-2?s corpus, the results for the test with globaldominion were: with single domain inclusion 40% of precision and recall; but with the threeresources 41.7 % for both measures.Table 4 shows the obtained results for the testdata set.
The average performance of our systemis 32% and we ranked on 27-th position from27 participating systems.
Although, we haveused different sources of information and variousapproximations, in the future we have to surmounta number of obstacles.One of the limitations comes from the usageof the POS-tagger Freeling which introducessome errors in the grammatical discrimination.Representing a loss of 3.7% in the precision of oursystem.The base of knowledge utilized in the task wasWordNet 1.6; but the competition demanded theresults with WordNet 3.0.
In order to achievethis we utilized mappings among versions where119 of 1398 resulting senses emitted by Semeval-2 were did not found.
This represents an 8.5%.In our proposal, the sense belonging to theFactotum Domain was eliminated, what disabledthat the senses linked to this domain wentcandidates to be recovered.
777 senses of 1398annotated like correct for Semeval-2 belong todomain Factotum, what represents that the 66%were not recovered by our system.
Consideringthe senses that are not correlated to Factotum,that is, that correlate to another domains, we arespeaking about 621 senses to define; The systemwould emit results of a 72,4%.
Senses selectedcorrectly were 450, representing a 32%.
However,189 kept on like second candidates to be elected.This represents a 13.5%.
If a technique of moreprecise decision takes effect, the results of thesystem could be increased largely.5 Conclusion and future worksFor our participation in the Semeval-2 task17 (All-words Word Sense Disambiguation onSpecific Domain), we presented three methodsfor disambiguation approach which uses anMethods Precision Recall AttemptedRelevantDomainsTree0.328 0.322 98.14%RelevantSemanticTree 20.321 0.315 98.14%RelevantCliques0.312 0.303 97.35%Table 4: Evaluation resultsintegrative resource of WordNet mappings.
Weconducted an experimental study with the traildata set, according to which the Relevant SemanticTree reaches the best performance.
Our currentapproach can be improved with the incorporationof more granularities in the hierarchy of WordNetDomains.
Because it was demonstrated thatto define correct senses associated to specificdomains an improvement of 72.4% is obtained.At this moment, only domain information is usedin our first and second method.
Besides wasdemonstrated for specific domains, the inclusionof several resources worsened the results with thefirst and second proposal method, the third one hasbeen not experimented yet.
Despite the fact thatwe have knowledge of SUMO, WordNet-Affectand WordNet Domain in our third method we stillnot obtain a relevant result.It would be convenient to enrich our resourcewith other resources like Frame-Net, Concept-Netor others with the objective of characterizing evenmore the senses of the words.AcknowledgmentsThis paper has been supported partially byMinisterio de Ciencia e Innovacio?n - SpanishGovernment (grant no.
TIN2009-13391-C04-01), and Conselleria d?Educacio?
- GeneralitatValenciana (grant no.
PROMETEO/2009/119 andACOMP/2010/288).ReferencesEneko Agirre and German Rigau.
1996.
Wordsense disambiguation using conceptual density.
InProceedings of the 16th International Conferenceon Computational Linguistic (COLING?96),Copenhagen, Denmark.Eneko Agirre, Oier Lopez de Lacalle, ChristianeFellbaum, Shu-kai Hsieh, Maurizio Tesconi, Monica431Monachini, Piek Vossen, and Roxanne Segers.2010.
Semeval-2010 task 17: All-words wordsense disambiguation on a specific domain.
InProceedings of the 5th International Workshop onSemantic Evaluations (SemEval-2010), Associationfor Computational Linguistics.Jordi Atserias, Bernardino Casas, Elisabet Comelles,Meritxell Gonza?lez, Llu?
?s Padro?, and Muntsa Padro?.2006.
Freeling 1.3: Syntactic and semantic servicesin an open-source nlp library.
In Proceedingsof the fifth international conference on LanguageResources and Evaluation (LREC 2006), ELRA.Lu?
?s Cavique, Armando B. Mendes, and Jorge M.Santos.
2009.
An algorithm to discover the k-clique cover in networks.
In EPIA ?09: Proceedingsof the 14th Portuguese Conference on ArtificialIntelligence, pages 363?373, Berlin, Heidelberg.Springer-Verlag.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
The MIT Press.Yoan Gutie?rrez.
2010.
Resolucio?n de ambiguedadsema?ntica mediante el uso de vectores de conceptosrelevantes.Zornitsa Kozareva, Sonia Va?zquez, and Andre?sMontoyo.
2007.
Ua-zsa: Web page clustering onthe basis of name disambiguation.
In Semeval I.
4thInternational Wordshop on Semantic Evaluations.Bernardo Magnini and Gabriela Cavaglia.
2000.Integrating subject field codes into wordnet.
InProceedings of Third International Conference onLanguage Resources and Evaluation (LREC-2000).Bernardo Magnini, Carlo Strapparava, GiovanniPezzulo, and Alfio Gliozzo.
2002.
Comparingontology-based and corpus-based domainannotations in wordnet.
In Proceedings of theFirst International WordNet Conference, pages146?154.Ian Niles and Adam Pease.
2001.
Towards a standardupper ontology.
In FOIS, pages 2?9.Ian Niles and Adam Pease.
2003.
Linking lexiconsand ontologies: Mapping wordnet to the suggestedupper merged ontology.
In IKE, pages 412?416.Ro Valitutti.
2004.
Wordnet-affect: an affectiveextension of wordnet.
In Proceedings of the 4thInternational Conference on Language Resourcesand Evaluation, pages 1083?1086.Sonia Va?zquez, Andre?s Montoyo, and German Rigau.2004.
Using relevant domains resource for wordsense disambiguation.
In IC-AI, pages 784?789.432
