Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1235?1244,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsNeural Network-Based Modelfor Japanese Predicate Argument Structure AnalysisTomohide Shibata and Daisuke Kawahara and Sadao KurohashiGraduate School of Informatics, Kyoto UniversityYoshida-honmachi, Sakyo-ku, Kyoto, 606-8501, Japan{shibata, dk, kuro}@i.kyoto-u.ac.jpAbstractThis paper presents a novel model forJapanese predicate argument structure(PAS) analysis based on a neural networkframework.
Japanese PAS analysis is chal-lenging due to the tangled characteristicsof the Japanese language, such as case dis-appearance and argument omission.
Tounravel this problem, we learn selectionalpreferences from a large raw corpus, andincorporate them into a SOTA PAS anal-ysis model, which considers the consis-tency of all PASs in a given sentence.
Wedemonstrate that the proposed PAS anal-ysis model significantly outperforms thebase SOTA system.1 IntroductionResearch on predicate argument structure (PAS)analysis has been conducted actively these days.The improvement of PAS analysis would benefitmany natural language processing (NLP) applica-tions, such as information extraction, summariza-tion, and machine translation.The target of this work is Japanese PAS analy-sis.
The Japanese language has the following char-acteristics:?
head final,?
free word order (among arguments), and?
postpositions function as (surface) casemarkers.Japanese major surface cases are?
(ga),?
(wo),and ?
(ni), which correspond to Japanese post-positions (case markers).
We call them nomina-tive case, accusative case, and dative case, respec-tively.
In this paper, we limit our target cases tothese three cases.
Note that though they are sur-face cases, they roughly correspond to Arg1, Arg2,and Arg3 of English semantic role labeling basedon PropBank.Japanese PAS analysis has been considered asone of the most difficult basic NLP tasks, due tothe following two phenomena.Case disappearance When a topic marker ?
(wa) is used or a noun is modified by a relativeclause, their case markings disappear as in the fol-lowing examples.1(1) a.
????John-TOP???bread-ACC????ate????
?John-NOM(John ate bread.)b.
???bread-TOP????John-NOM????ate???
?bread-ACC(John ate bread.
)(2) a.
??????????
... ?bread-ACC ate John-ACC????
(???
)John-NOM (ate)(John, who ate bread, ...)b.
????John-NOM??????
...?ate bread-NOM???
(???
)(ate) bread-ACC(Bread, which John ate, ...)In the example sentences (1a) and (1b), since atopic marker ?
is used, the NOM and ACC casemarkers disappear.
In the example sentences (2a)and (2b), since a noun is modified by a relativeclause, the NOM case of ?????
(John) for ?????
(eat) and ACC case of ????
(bread) for?????
disappear.Argument omission Arguments are very oftenomitted in Japanese sentences.
This phenomenonis totally different from English sentences, wherethe word order is fixed and pronouns are used con-1In this paper, we use the following abbreviations:NOM (nominative), ACC (accusative), DAT (dative) andTOP (topic marker).1235!
"#$%&&'#$(&&)*+,&&&-./0!1"#$%&'()1*+,-.&/001 *#12$3&-%.1 -3,1.,4,%.,%56!4-+78%215-7,!-%-967871:(;!!
<,+#!-%-4$#+-!+,7#91=#%1>&:(;1 >&/001Figure 1: An example of PAS analysis.
Input sen-tence: ?????????????????
(Johnbought bread, and ate it.)sistently.
For example, let us compare the follow-ing parallel Japanese and English sentences:(3) a.
????John-TOP???bread-ACC????bought????ateb.
John bought bread, and ate it.The dependency parse of (3a) is shown in Figure1.
In general, the first phrase with a topic marker?
is treated as modifying the final predicate ac-cording to the guidelines of Japanese dependencyannotation.
As a result, ?????
(bought) has noNOM argument (omitted), and ?????
(ate) hasno ACC argument.
Note that ?????
has an ar-gument ?????
(John), but its case does not ap-pear.In the case of the parallel sentences (4) below,again we can witness the difficulty of JapanesePAS analysis.
(4) a.
???bread-ACC???bought????John-TOP???hurry????ateb.
John who bought bread ate it in a hurry.Although all the case arguments of the predicates?bought?
and ?ate?
are explicit in (4b), the case of?????
(John) for ?????
(bought) and that for?????
(ate) are hidden, and the ACC argumentof ?????
(ate) is omitted in (4a).Many researchers have been tackling JapanesePAS analysis (Taira et al, 2008; Imamura et al,2009; Hayashibe et al, 2011; Sasano and Kuro-hashi, 2011; Hangyo et al, 2013; Ouchi et al,2015).
However, because of the two aforemen-tioned characteristics in Japanese sentences, theaccuracy of Japanese PAS analysis for omitted(zero) arguments remains around 40%.This paper proposes a novel Japanese PAS anal-ysis model based on a neural network (NN) frame-work, which has been proved to be effective forseveral NLP tasks recently.
To unravel the tan-gled situation in Japanese, we learn selectionalpreferences from a large raw corpus, and incorpo-rate them into a SOTA PAS analysis model pro-posed by Ouchi et al (2015), which considersthe consistency of all PASs in a given sentence.This model is achieved by an NN-based two-stagemodel that acquires selectional preferences in anunsupervised manner in the first stage and predictsPASs in a supervised manner in the second stageas follows.1.
The most important clue for PAS analysis isselectional preferences, that is, argument pre-diction from a predicate phrase.
For exam-ple, how likely the phrase ????????
(bought bread) takes ?????
(John) as itsNOM argument.Such information cannot be learned froma medium-sized PAS annotated corpus withsize of the order of ten-thousand sentences; itis necessary to use a huge raw corpus by anunsupervised method.
Ouchi et al (2015) didnot utilize such knowledge extracted from araw corpus.
Some work has utilized PMI be-tween a predicate and an argument, or caseframes obtained from a raw corpus.
How-ever, this is discrete word-based knowledge,not generalized semantic knowledge.As the first stage of the method, we learn aprediction score from a predicate phrase toan argument by an NN-based method.
Theresultant vector representations of predicatesand arguments are used as initial vectors forthe second stage of the method.2.
In the second stage, we calculate a score thata predicate in a given sentence takes an el-ement in the sentence as an argument usingNN framework.
We use the prediction scorein the first stage as one feature for the secondstage NN.
The system by Ouchi et al (2015)used a manually designed feature template totake the interactions of the atomic featuresinto consideration.
In the case of an NNframework, no feature template is required,and a hidden layer in an NN can capture theinteractions of the atomic features automati-cally and flexibly.We demonstrate that the proposed PAS analysismodel outperforms the SOTA system by Ouchi etal.
(2015).12362 Related WorkSeveral methods for Japanese PAS analysis havebeen proposed.
The methods can be dividedinto three types: (i) identifying one case argu-ment independently per predicate (Taira et al,2008; Imamura et al, 2009; Hayashibe et al,2011), (ii) identifying all the three case arguments(NOM, ACC, and DAT) simultaneously per pred-icate (Sasano and Kurohashi, 2011; Hangyo et al,2013), and (iii) identifying all case arguments ofall predicates in a sentence (Ouchi et al, 2015).The third method can capture interactions betweenpredicates and their arguments, and thus performsthe best among the three types.
This method isadopted as our base model (see Section 3 for de-tails).Most methods for PAS analysis handle bothintra-sentential and inter-sentential zero anaphora.For identifying inter-sentential zero anaphora, anantecedent has to be searched in a broad searchspace, and the salience of discourse entities hasto be captured.
Therefore, the task of identify-ing inter-sentential zero anaphora is more difficultthan that of intra-sentential zero anaphora.
Thus,Ouchi et al (2015) and Iida et al (2015) focusedon only intra-sentential zero anaphora.
Followingthis trend, this paper focuses on intra-sententialzero anaphora.Recently, NN-based approaches have achievedimprovement for several NLP tasks.
For exam-ple, in transition-based parsing, Chen and Man-ning (2014) proposed an NN-based approach,where the words, POS tags, and dependency la-bels are first represented by embeddings individu-ally.
Then, an NN-based classifier is built to makeparsing decisions, where an input layer is a con-catenation of embeddings of words, POS tags, anddependency labels.
This model has been extendedby several studies (Weiss et al, 2015; Dyer et al,2015; Ballesteros et al, 2015).
In semantic role la-beling, Zhou and Xu (2015) propose an end-to-endapproach using recurrent NN, where an originaltext is the input, and semantic role labeling is per-formed without any intermediate syntactic knowl-edge.
Following these approaches, this paper pro-poses an NN-based PAS method.3 Base ModelThe model proposed by Ouchi et al (2015) isadopted as our base model (Figure 2).
We brieflyintroduce this base model before describing our!"#$%&&'#$(&&&)*+,&&&-./0!1"#$%&1!
'()#*+,-1 ./012*344 !.
(%5)&*1#21 !1&01!"#!'()#1!"##!)2!.%61-.3!01&!
'#!./0121)2!.%6!-.3!01&1 73+1a1a2a3a4a5p1p2344!18,91344!173+18,91Figure 2: Our base model (Ouchi et al, 2015).proposed model.3.1 Predicate-Argument GraphIn this model, for an input sentence, a bipar-tite graph is constructed, consisting of the setof predicate and argument nodes.
This is calledPredicate-Argument Graph (PA Graph).
A PAgraph represents a possible interpretation of theinput sentence, including case analysis result andzero anaphora resolution result.A PA graph is a bipartite graph ?A,P,E?,where A is the node set consisting of candidatearguments, P is the node set consisting of predi-cates, and E is the set of edges.
A PA graph isdefined as follows:A = {a1, .
.
.
, an, an+1= NULL}P = {p1, .
.
.
, pm}E = {?a, p, c?|deg(p, c) = 1,?a ?
A,?p ?
P, ?c ?
C}where n and m represent the number of predicatesand arguments, and C denotes the case role set(NOM, ACC, and DAT).
An edge e ?
E is rep-resented by a tuple ?a, p, c?, indicating the edgewith a case role c connecting a candidate argu-ment node a and a predicate node p. deg(p, c) isthe number of the edges with a case role c outgo-ing from a predicate node p. An admissible PAgraph satisfies the constraint deg(p, c) = 1, whichmeans each predicate node p has only one edgewith a case role c. A dummy node an+1is added,which is defined for the cases where a predicaterequires no case argument (e.g.
when the pred-icate node ????
(exist) connects a NULL nodewith a case ACC, this means this predicate takes1237no ACC argument) or the required argument doesnot appear in the sentence.In the bipartite graph shown in Figure 2, thethree kinds of edge lines have the meaning as fol-lows:solid line: the argument node and the predicatenode has a dependency relation, and the ar-gument node is followed by a case mark-ing postposition.
In this case, these nodeshave a relation through its corresponding casemarking postposition.
Therefore, this edge isfixed.dashed line: the argument node and the predicatenode has a dependency relation, and the ar-gument node is not followed by a case mark-ing postposition.
These nodes are likely tohave a relation2, but the case role is unknown.Identifying this case role corresponds to caseanalysis.dotted line: the argument node and the predi-cate node do not have a dependency relation.Identifying this edge and its case role corre-sponds to zero anaphora resolution.For an input sentence x, a scoring functionScore(x, y) is defined for a candidate graph y,and the PA graph that has the maximum score issearched.y?
= argmaxy?G(x)Score(x, y) (1)where G(x) is a set of admissible PA graphs forthe input sentence x.
Score(x, y) is defined as fol-lows3:?e?E(y)scorel(x, e)+?ei,ej?Epair(y)scoreg(x, ei, ej).
(2)scorel(x, e) = ?l?
?l(x, e)scoreg(x, ei, ej) = ?g?
?g(x, ei, ej)(3)where E(y) is the edge set on the candidate graphy, Epair(y) is a set of edge pairs in the edge setE(y), scorel(x, e) and scoreg(x, ei, ej) represent2For example, in the sentence ???????
(today-TOPhot), the predicate ????
does not take ???
?, which rep-resents time, as an argument.
Therefore, these nodes do notalways have a relation.3Ouchi et al (2015) introduce two models: Per-CaseJoint Model and All-Cases Joint Model.
Since All-CasesJoint Model performed better than Per-Case Joint Model, All-Cases Joint Model is adopted as our base model.a local score for the edge e and a global score forthe edge pair eiand ej, ?l(x, e) and ?g(x, ei, ej)represent local features and global features.
While?l(x, e) is defined for each edge e, ?g(x, ei, ej)is defined for each edge pair ei, ej(i ?= j) .
?land ?grepresent model parameters for local andglobal features.
By using global scores, the inter-action between multiple case assignments of mul-tiple predicates can be considered.3.2 Inference and TrainingSince global features make the inference of find-ing the maximum scoring PA graph more difficult,the randomized hill-climbing algorithm proposedin (Zhang et al, 2014) is adopted.Figure 3 describes the pseudo code for hill-climbing algorithm.
First, an initial PA graph y(0)is sampled from the set of admissible PA graphG(x).
Then, the union Y is constructed fromthe set of neighboring graphs NeighborG(y(t)),which is a set of admissible graphs obtained bychanging one edge in y(t), and the current graphy(t).
The current graph y(t)is updated to a higherscoring graph y(t+1).
This process continues untilno more improvement is possible, and finally anoptimal graph y?
can be obtained.Input: sentence x, parameter ?Output: a locally optimal PA graph y?1 Sample a PA graph y(0)from G(x)2 t?
03 repeat4 Y ?
NeighborG(y(t))?y(t)5 y(t+1)?
argmaxy?YScore(x, y;?
)6 t?
t + 17 until y(t)= y(t+1)8 return y?
?
y(t)Figure 3: Hill climbing algorithm for obtain-ing optimal PA graph.Given N training examples D = {(x, y?
)}Nk,the model parameter ?
are estimated.
?
is the setof ?land ?g, and is estimated by averaged per-ceptron (Collins, 2002) with a max-margin frame-work (Taskar et al, 2005).1238!"#$!"##$%&%&'!
'()*+$% ()!%,%'$+&!-./% 011%*!2$%3%+,-!
"'')$%4$5"67$!%"8')$%%...%'#$2*+&%Figure 4: Argument prediction model.
In the PAS????
(police) NOM ????
(suspect) ACC ????
(arrest), ????
with the NOM case is pre-dicted given the predicate ????
(arrest) and itsACC ????
(suspect).4 Proposed Model4.1 Argument Prediction ModelNo external knowledge is utilized in the basemodel.
One of the most important types of knowl-edge in PAS analysis is selectional preferences.Sasano and Kurohashi (2011) and Hangyo et al(2013) extract knowledge of the selectional pref-erences in the form of case frames from a raw cor-pus, and the selectional preference score is used asa feature.
In this work, argument prediction modelis trained using a neural network from a raw cor-pus, in a similar way to Titov and Khoddam (2015)and Hashimoto et al (2014).PASs are first extracted from an automatically-parsed raw corpus, and in each PAS, the argu-ment aiis generated with the following probabilityp(ai|PAS?ai):p(ai|PAS?ai) =exp(vTaiWTai(Wpredvpred+?j ?=iWajvaj))Z(4)where PAS?airepresents a PAS excluding thetarget argument ai, vpred, vaiand vajrepresentembeddings of the predicate, argument aiand ar-gument aj, and Wpred, Wai, and Wajrepresenttransformation matrices for a predicate and an ar-gument aiand aj.
Z is the partition function.Figure 4 illustrates the argument predictionmodel.
The PAS ????
(police) NOM ????
(suspect) ACC ????
(arrest)?
is extracted from araw corpus, and the probability of NOM argument????
given the predicate ????
and its ACC ar-gument ????
is calculated.All the parameters including predi-cate/argument embeddings and transformationmatrices are trained, so that the likelihood givenby Equation (4) is high.
Since the denominator ofEquation (4) is impractical to be calculated sincethe number of vocabulary is enormous, negativesampling (Mikolov et al, 2013) is adopted.
Inthe example shown in Figure 4, as for a NOMargument, negative examples, such as ???
(desk)and ?????
(apple), are drawn from the noisedistribution, which is a unigram distribution raisedto the 3/4th power.In each PAS, all the arguments are predictedin turn.
All the parameters are updated usingstochastic gradient descent.This model is first trained using the automaticparsing result on a raw corpus, and in performingPAS analysis described in Section 4.2, the scorederived from this model is used as a feature.4.2 Neural Network-Based Score CalculationIn the base model, the score for an edge (localscore) or an edge pair (global score) is calculatedusing the dot product of a sparse high-dimensionalfeature vector with a model parameter, as shown inEquation (3).
In our proposed model, these scoresare calculated in a standard neural network withone hidden layer, as shown in Figure 5.We first describe the calculation of the localscore scorel(x, e).
A predicate p and an argumenta are represented by embeddings (a d dimensionalvector) vpand va?
Rd, and vfl?
Rdf(dfrep-resents a dimensional of vfl) represents a featurevector obtained by concatenating the case role be-tween a and p, the argument prediction score ob-tained from the model described in Section 4.1,and the other atomic features.
An input layer is aconcatenation of these vectors, and then, a hiddenlayer hl?
Rdh(dhrepresents a dimension of thehidden layer) is calculated as follows:hl= f(W1l[vp;va;vfl]) (5)where f is an element-wise activation function(tanh is used in our experiments), and W1l?Rdh(2d+dh)is a weight matrix (for the local score)from the input layer to the hidden layer.
The scalarscore in an output layer is then calculated as fol-lows:scorel(x, e) = f(W2lhl) (6)where W2l?
R(2d+dh)?1is a weight matrix (forthe local score) from the hidden layer to the outputlayer.
By calculating the score in this way, all the1239!"#$%#&'#$!(")%#&'#$!*+,(*%-,+"#!
)*+'(*%-,+"#!W 1lW 2lscorel(x, e)!"#$%#&'#$!
(")%#&'#$!scoreg(x, ei, ej)W 1gW 2g,(-#!
,(-#.!,(-#/!(")0%!
"#$%%-,+"#!+12#"%3#(14"#-!+12#"%3#(14"#-!vp vavflvpi vpj vai vajvfgFigure 5: A score calculation in our proposed neural-network based model.
The left part and right partrepresent a local and global score calculation.combinations of features in the input layer can beconsidered.Next we describe the calculation of the globalscore scoreg(x, ei, ej).
In the base model, the twotypes of global features are utilized: one is for thetwo predicates having different arguments, and theother is for the two predicates sharing the sameargument.
The input layer is a concatenation ofinvolving vectors of predicates/arguments and theother features vfg.
For example, when calculat-ing the global score for the two predicates havingdifferent arguments, the input layer is a concate-nation of the vectors of two predicates and two ar-guments and vfg.A hidden layer hgis calculated as follows:hg= f(W1g[vpi;vpj;vai;vaj;vfg]) (7)whereW1gis a weight matrix (for the global score)from the input layer to the hidden layer, vpiandvaiare the embeddings of the predicate/argumentconnected by ei, and vpjand vajare defined inthe same way.The scalar score in an output layer is then cal-culated as follows:scoreg(x, ei, ej) = f(W2ghg) (8)whereW2gis a weight matrix (for the global score)from the hidden layer to the output layer.4.3 Inference and TrainingWhile inference is the same as the base model,training is slightly different.In our proposed model, the model param-eter ?
consists of the embeddings of predi-cates/arguments and weight matrices for the lo-cal/global score in the neural networks.
Our ob-jective is to minimize the following loss function:case# of deparguments# of zeroargumentstotalNOM 1,402 1,431 2,833ACC 278 113 391DAT 92 287 379ALL 1,772 1,831 3,603Table 1: Test set statistics of the number of argu-ments.J(?)
=N?klk(?
), (9)wherelk(?)
= maxyk?G(x)(Score(xk, yk;?
)?Score(xk, y?k;?
)+ ||yk?
y?k||1),(10)and ||yk?
y?k||1denotes the Hamming distance be-tween the gold PA graph y?kand a candidate PAgraph yk.Stochastic gradient descent is used for param-eter inference.
Derivatives with respect to pa-rameters are taken using backpropagation.
Adam(Kingma and Ba, 2014) is adopted as the opti-mizer.For initialization of the embeddings of a pred-icate/argument, the embeddings of the predi-cate/argument trained by the method described inSection 4.1 are utilized.
The weight matrices arerandomly initialized.5 Experiment5.1 Experimental SettingThe KWDLC (Kyoto University Web DocumentLeads Corpus) evaluation set (Hangyo et al, 2012)was used for our experiments, because it contains1240a wide variety of Web documents, such as newsarticles and blogs.
This evaluation set consists ofthe first three sentences of 5,000 Web documents.Morphology, named entities, dependencies, PASs,and coreferences were manually annotated.This evaluation set was divided into 3,694 docu-ments (11,558 sents.)
for training, 512 documents(1,585 sents.)
for development, and 700 docu-ments (2,195 sents.)
for testing.
Table 1 shows thestatistics of the number of arguments in the testset.
While ?dep argument?
means that the argu-ment and a predicate have a dependency relation,but a specified case marking postposition is hid-den (corresponds to ?dashed line?
in Section 3.1),?zero argument?
means that the argument and apredicate do not have a dependency relation (cor-responds to ?dotted line?
in Section 3.1).Since we want to focus on the accuracy ofcase analysis and zero anaphora resolution, goldmorphological analysis, dependency analysis, andnamed entities were used.The sentences having a predicate that takes mul-tiple arguments in the same case role were ex-cluded from training and test examples, since thebase model cannot handle this phenomena (it as-sumes that each predicate has only one argumentwith one case role).
For example, the followingsentence,(5) ???such????funny-material???full??
?daily life-ACC????picture-with??????
?,report(I report my daily life full of such funny ma-terials along with pictures.
)where the predicate ????????
(report) takesboth ????
(daily life) and ???
(picture) as ACCcase arguments, was excluded from training andtesting.
About 200 sentences (corresponding toabout 1.5% of the whole evaluation set) were ex-cluded.In this evaluation set, zero exophora, which isa phenomenon that a referent does not appear ina document, is annotated.
Among five types ofzero exophora, the two major types, ?author?
and?reader,?
are adopted, and the others are discarded.To consider ?author?
and ?reader?
as a referent,the two special nodes, AUTHOR and READER, areadded as well as a NULL node in a PA graph ofthe base model.
When the argument predicationscore is calculated for ?author?
or ?reader,?
be-cause its lemma does not appear in a document,for each noun in the following noun list of ?au-thor?/?reader?
(Hangyo et al, 2013), the argumentprediction score is calculated, and the maximumscore is used as a feature.?
author: ???
(I), ????
(we), ???
(I), ????
(our company), ?
?
??
reader: ?????
(you), ???
(customer), ???
(you), ????
(you all), ?
?
?In the argument prediction model training de-scribed in Section 4.1, a Japanese Web corpusconsisting of 10M sentences was used.
We pre-formed syntactic parsing with a publicly availableJapanese parser, KNP4.
The number of negativesamples was 5, and the number of epochs was 10.In the model training described in Section 4.3,the dimensions of both embeddings for predi-cates/arguments and hidden layer were set to 100.The number of epochs was set to 20, following thebase model.5.2 ResultWe compared the following three methods:?
Baseline (Ouchi et al, 2015)?
Proposed model w/o arg.
prediction score:in the PAS analysis model, the feature de-rived from the argument prediction modelwas not utilized.
The embeddings of apredicate/argument were randomly initial-ized.
This method corresponds to adoptingthe NN-based score calculation in the basemodel.?
Proposed model w/ arg.
prediction score:the feature derived from the argument pre-diction model was utilized, and the embed-dings of a predicate/argument were initial-ized with those obtained in the argument pre-diction model learning.The performances of case analysis and zeroanaphora resolution were evaluated by micro-averaged precision, recall, and F-measure.
Theprecision, recall, and F-measure were averaged4http://nlp.ist.i.kyoto-u.ac.jp/index.php?KNP1241case method case analysis zero anaphoraP R F P R FNOM Baseline 0.880 0.868 0.874 0.693 0.377 0.488Proposed model w/o arg.
prediction score 0.927 0.917 0.922 0.559 0.532 0.545Proposed model w arg.
prediction score 0.946 0.936 0.941 0.568 0.586 0.577ACC Baseline 0.433 0.374 0.402 0.000 0.000 0.000Proposed model w/o arg.
prediction score 0.805 0.553 0.656 0.151 0.060 0.085Proposed model w/ arg.
prediction score 0.890 0.658 0.756 0.297 0.124 0.173DAT Baseline 0.224 0.359 0.276 0.531 0.059 0.107Proposed model w/o arg.
prediction score 0.512 0.104 0.173 0.535 0.242 0.332Proposed model w/ arg.
prediction score 0.834 0.185 0.300 0.622 0.273 0.378ALL Baseline 0.765 0.764 0.765 0.686 0.304 0.421Proposed model w/o arg.
prediction score 0.908 0.818 0.860 0.544 0.458 0.497Proposed model w/ arg.
prediction score 0.937 0.853 0.893 0.563 0.509 0.534Table 2: Experimental results on the KWDLC corpus.over 5 runs.
Table 2 shows our experimental re-sults.
Our proposed method outperformed thebaseline method by about 11 absolute points inF-measure.
The comparison of ?Proposed modelw/o arg.
prediction score?
with the baselineshowed that the neural network-based approachwas effective, and the comparison of ?Proposedmodel w/ arg.
prediction score?
with ?Proposedmodel w/o arg.
prediction score?
showed that ourarg.
prediction model was also effective.The following is improved by adding an argu-ment prediction score.
(6) ????
?after a long time???????
?part-time job????
?begin to work???new???step-ACC???????
?step forward(It?s my first part-time job in a long time.
Ibegin to work, and make a new step.
)While in the base model, the NOM arguments ofthe predicate ???????
(begin to work) and??????
(step forward) were wrongly classifiedas NULL, by adding an argument prediction score,they were correctly identified as ?author.
?The phenomenon ?case disappearance?
occursin other languages such as Korean, and the phe-nomenon ?argument omission?
occurs in otherlanguages such as Korean, Hindi, Chinese, andSpanish.
We believe that our neural network ap-proach to the argument prediction and the calcula-tion of the local and global scores is also effectivefor such languages.5.3 Error AnalysisErrors in our proposed model are listed below:?
Recall for ACC and DAT in both case analy-sis and zero anaphora resolution is low.One reason is that since the number of theACC and DAT arguments is smaller than thatof the NOM argument, the system tends toassign the ACC and DAT arguments withNULL.
Another reason is that since this paperfocuses on intra-sentential zero anaphora, theNULL arguments include arguments that ap-pear in previous sentences as well as the casewhere a predicate takes no argument, whichmakes the training for NULL arguments dif-ficult.
We are planing to tackle with inter-sentential zero anaphora resolution.?
The distinction of ?author?
from NULL fails.
(7) ??meat-ACC?????roast-only-NOMBBQ????
?BBQ-(COPULA)(Roasting meat isn?t all in BBQ!
)Although the NOM argument of the predi-cate ????
(roast) is ?author,?
our proposedmodel wrongly classified it as NULL.
Hangyoet al (2013) identify mentions referring toan author or reader in a document, and uti-lize this result in the zero anaphora resolu-1242tion.
We plan to incorporate the author/readeridentification into our model.6 ConclusionIn this paper we presented a novel model forJapanese PAS analysis based on neural networkframework.
We learned selectional preferencesfrom a large raw corpus, and incorporated theminto a PAS analysis model, which considers theconsistency of all PASs in a given sentence.
Inour experiments, we demonstrated that the pro-posed PAS analysis model significantly outper-formed the base SOTA model.In the future, we plan to extend our modelto incorporate coreference resolution and inter-sentential zero anaphora resolution.AcknowledgmentsThis work is supported by CREST, Japan Scienceand Technology Agency.ReferencesMiguel Ballesteros, Chris Dyer, and Noah A. Smith.2015.
Improved transition-based parsing by model-ing characters instead of words with lstms.
In Pro-ceedings of the 2015 Conference on Empirical Meth-ods in Natural Language Processing, pages 349?359, Lisbon, Portugal, September.
Association forComputational Linguistics.Danqi Chen and Christopher Manning.
2014.
A fastand accurate dependency parser using neural net-works.
In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Process-ing (EMNLP), pages 740?750, Doha, Qatar, Octo-ber.
Association for Computational Linguistics.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedingsof the ACL-02 Conference on Empirical Methods inNatural Language Processing - Volume 10, EMNLP?02, pages 1?8, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Chris Dyer, Miguel Ballesteros, Wang Ling, AustinMatthews, and Noah A. Smith.
2015.
Transition-based dependency parsing with stack long short-term memory.
In Proceedings of the 53rd AnnualMeeting of the Association for Computational Lin-guistics and the 7th International Joint Conferenceon Natural Language Processing (Volume 1: LongPapers), pages 334?343, Beijing, China, July.
Asso-ciation for Computational Linguistics.Masatsugu Hangyo, Daisuke Kawahara, and SadaoKurohashi.
2012.
Building a diverse docu-ment leads corpus annotated with semantic relations.In Proceedings of the 26th Pacific Asia Confer-ence on Language, Information, and Computation,pages 535?544, Bali,Indonesia, November.
Facultyof Computer Science, Universitas Indonesia.Masatsugu Hangyo, Daisuke Kawahara, and SadaoKurohashi.
2013.
Japanese zero reference resolu-tion considering exophora and author/reader men-tions.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Process-ing, pages 924?934, Seattle, Washington, USA, Oc-tober.
Association for Computational Linguistics.Kazuma Hashimoto, Pontus Stenetorp, Makoto Miwa,and Yoshimasa Tsuruoka.
2014.
Jointly learn-ing word representations and composition functionsusing predicate-argument structures.
In Proceed-ings of the 2014 Conference on Empirical Methodsin Natural Language Processing (EMNLP), pages1544?1555, Doha, Qatar, October.
Association forComputational Linguistics.Yuta Hayashibe, Mamoru Komachi, and Yuji Mat-sumoto.
2011.
Japanese predicate argument struc-ture analysis exploiting argument position and type.In Proceedings of 5th International Joint Conferenceon Natural Language Processing, pages 201?209,Chiang Mai, Thailand, November.
Asian Federationof Natural Language Processing.Ryu Iida, Kentaro Torisawa, Chikara Hashimoto, Jong-Hoon Oh, and Julien Kloetzer.
2015.
Intra-sentential zero anaphora resolution using subjectsharing recognition.
In Proceedings of the 2015Conference on Empirical Methods in Natural Lan-guage Processing, pages 2179?2189, Lisbon, Portu-gal, September.
Association for Computational Lin-guistics.Kenji Imamura, Kuniko Saito, and Tomoko Izumi.2009.
Discriminative approach to predicate-argument structure analysis with zero-anaphora res-olution.
In Proceedings of the ACL-IJCNLP 2009Conference Short Papers, pages 85?88, Suntec, Sin-gapore, August.
Association for Computational Lin-guistics.Diederik P. Kingma and Jimmy Ba.
2014.
Adam:A method for stochastic optimization.
CoRR,abs/1412.6980.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-rado, and Jeffrey Dean.
2013.
Distributed repre-sentations of words and phrases and their composi-tionality.
In C.J.C.
Burges, L. Bottou, M. Welling,Z.
Ghahramani, and K.Q.
Weinberger, editors, Ad-vances in Neural Information Processing Systems26, pages 3111?3119.
Curran Associates, Inc.Hiroki Ouchi, Hiroyuki Shindo, Kevin Duh, and YujiMatsumoto.
2015.
Joint case argument identi-fication for Japanese predicate argument structureanalysis.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on Natu-ral Language Processing (Volume 1: Long Papers),1243pages 961?970, Beijing, China, July.
Association forComputational Linguistics.Ryohei Sasano and Sadao Kurohashi.
2011.
A dis-criminative approach to Japanese zero anaphora res-olution with large-scale lexicalized case frames.
InProceedings of 5th International Joint Conferenceon Natural Language Processing, pages 758?766,Chiang Mai, Thailand, November.
Asian Federationof Natural Language Processing.Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata.2008.
A Japanese predicate argument structureanalysis using decision lists.
In Proceedings ofthe 2008 Conference on Empirical Methods in Nat-ural Language Processing, pages 523?532, Hon-olulu, Hawaii, October.
Association for Computa-tional Linguistics.Ben Taskar, Vassil Chatalbashev, Daphne Koller, andCarlos Guestrin.
2005.
Learning structured pre-diction models: A large margin approach.
In Pro-ceedings of the 22Nd International Conference onMachine Learning, ICML ?05, pages 896?903, NewYork, NY, USA.
ACM.Ivan Titov and Ehsan Khoddam.
2015.
Unsupervisedinduction of semantic roles within a reconstruction-error minimization framework.
In Proceedings ofthe 2015 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pages 1?10,Denver, Colorado, May?June.
Association for Com-putational Linguistics.David Weiss, Chris Alberti, Michael Collins, and SlavPetrov.
2015.
Structured training for neural net-work transition-based parsing.
In Proceedings ofthe 53rd Annual Meeting of the Association forComputational Linguistics and the 7th InternationalJoint Conference on Natural Language Processing(Volume 1: Long Papers), pages 323?333, Beijing,China, July.
Association for Computational Linguis-tics.Yuan Zhang, Tao Lei, Regina Barzilay, and TommiJaakkola.
2014.
Greed is good if randomized: Newinference for dependency parsing.
In Proceedings ofthe 2014 Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 1013?1024, Doha, Qatar, October.
Association for Com-putational Linguistics.Jie Zhou and Wei Xu.
2015.
End-to-end learning ofsemantic role labeling using recurrent neural net-works.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on Natu-ral Language Processing (Volume 1: Long Papers),pages 1127?1137, Beijing, China, July.
Associationfor Computational Linguistics.1244
