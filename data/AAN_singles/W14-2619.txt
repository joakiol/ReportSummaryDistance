Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 113?118,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsDive deeper: Deep Semantics for Sentiment AnalysisNikhikumar JadhavMasters StudentComputer Science & Engineering Dept.IIT Bombaynikhilkumar@cse.iitb.ac.inPushpak BhattacharyyaProfessorComputer Science & Engineering Dept.IIT Bombaypb@cse.iitb.ac.inAbstractThis paper illustrates the use of deep se-mantic processing for sentiment analysis.Existing methods for sentiment analysisuse supervised approaches which take intoaccount all the subjective words and orphrases.
Due to this, the fact that not allof these words and phrases actually con-tribute to the overall sentiment of the textis ignored.
We propose an unsupervisedrule-based approach using deep semanticprocessing to identify only relevant sub-jective terms.
We generate a UNL (Uni-versal Networking Language) graph forthe input text.
Rules are applied on thegraph to extract relevant terms.
The sen-timent expressed in these terms is used tofigure out the overall sentiment of the text.Results on binary sentiment classificationhave shown promising results.1 IntroductionMany works in sentiment analysis try to make useof shallow processing techniques.
The commonthing in all these works is that they merely try toidentify sentiment-bearing expressions as shownby Ruppenhofer and Rehbein (2012).
No efforthas been made to identify which expression actu-ally contributes to the overall sentiment of the text.In Mukherjee and Bhattacharyya (2012) these ex-pressions are given weight-age according to theirposition w.r.t.
the discourse elements in the text.But it still takes into account each expression.Semantic analysis is essential to understand theexact meaning conveyed in the text.
Some wordstend to mislead the meaning of a given piece of textas shown in the previous example.
WSD (WordSense Disambiguation) is a technique which canbeen used to get the right sense of the word.
Bal-amurali et al., (2012) have made use of Word-Net synsets for a supervised sentiment classifica-tion task.
Tamare (2010) and Rentoumi (2009)have also shown a performance improvement byusing WSD as compared to word-based featuresfor a supervised sentiment classification task.
InHasan et al., (2012), semantic concepts have beenused as additional features in addition to word-based features to show a performance improve-ment.
Syntagmatic or structural properties oftext are used in many NLP applications like ma-chine translation, speech recognition, named en-tity recognition, etc.
A clustering based approachwhich makes use of syntactic features of text hasbeen shown to improve performance in Kashyapet al., (2013).
Another approach can be foundin Mukherjee and Bhattacharyya (2012) whichmakes use of lightweight discourse for sentimentanalysis.
In general, approaches using seman-tic analysis are expensive than syntax-based ap-proaches due to the shallow processing involvedin the latter.
As pointed out earlier, all these worksincorporate all the sentiment-bearing expressionsto evaluate the overall sentiment of the text.
Thefact that not all expressions contribute to the over-all sentiment is completely ignored due to this.Our approach tries to resolve this issue.
To do this,we create a UNL graph for each piece of text andinclude only the relevant expressions to predict thesentiment.
Relevant expressions are those whichsatisfy the rules/conditions.
After getting these ex-pressions, we use a simple dictionary lookup alongwith attributes of words in a UNL graph to calcu-late the sentiment.The rest of the paper is organized as follows.Section 2 discusses related work.
Section 3 ex-plains our approach in detail.
The experimentalsetup is explained in Section 4.
Results of the ex-periments are presented in Section 5.
Section 6discusses these results followed by conclusion inSection 7.
Section 8 hints at some future work.1132 Related WorkThere has been a lot of work on using semanticsin sentiment analysis.
Hasan et al., (2012) havemade use of semantic concepts as additional fea-tures in a word-based supervised sentiment classi-fier.
Each entity is treated as a semantic concepte.g.
iPhone, Apple, Microsoft, MacBook, iPad,etc..
Using these concepts as features, they try tomeasure their correlation with positive and nega-tive sentiments.
In Verma et al., (2009), effort hasbeen made to construct document feature vectorsthat are sentiment-sensitive and use world knowl-edge.
This has been achieved by incorporatingsentiment-bearing words as features in documentvectors.
The use of WordNet synsets is found inBalamurali et al., (2012), Rentoumi (2009) andTamara (2010).
The one thing common with theseapproaches is that they make use of shallow se-mantics.An argument has been made in Choi andCarde (2008) for determining the polarity of asentiment-bearing expression that words or con-stituents within the expression can interact witheach other to yield a particular overall polarity.Structural inference motivated by compositionalsemantics has been used in this work.
This workshows use of deep semantic information for thetask of sentiment classification.
A novel use ofsemantic frames is found in Ruppenhofer and Re-hbein (2012).
As a step towards making useof deep semantics, they propose SentiFrameNetwhich is an extension to FrameNet.
A semanticframe can be thought of as a conceptual struc-ture describing an event, relation, or object andthe participants in it.
It has been shown that po-tential and relevant sentiment bearing expressionscan be easily pulled out from the sentence usingthe SentiFrameNet.
All these works try to bridgethe gap between rule-based and machine-learningbased approaches but except the work in Ruppen-hofer and Rehbein (2012), all the other approachesconsider all the sentiment-bearing expressions inthe text.3 Use of Deep SemanticsBefore devising any solution to a problem, it is ad-visable to have a concise definition of the prob-lem.
Let us look at the formal definition of thesentiment analysis problem as given in Liu (2010).Before we do that, let us consider the followingreview for a movie, ?1) I went to watch the newJames Bond flick, Skyfall at IMAX which is thebest theater in Mumbai with my brother a monthago.
2) I really liked the seating arrangement overthere.
3) The screenplay was superb and kept meguessing till the end.
4) My brother doesnt like thehospitality in the theater even now.
5) The movieis really good and the best bond flick ever.?
This isa snippet of the review for a movie named Skyfall .There are many entities and opinions expressed init.
1) is an objective statement.
2) is subjective butis intended for the theater and not the movie.
3) isa positive statement about the screenplay which isan important aspect of the movie.
4) is a subjectivestatement but is made by the authors brother andalso it is about the hospitality in the theater andnot the movie or any of its aspects.
5) reflects apositive view of the movie for the author.
We cansee from this example that not only the opinion butthe opinion holder and the entity about which theopinion has been expressed are also very impor-tant for sentiment analysis.
Also, as can be seenfrom 1),4) and 5) there is also a notion of time as-sociated with every sentiment expressed.
Now, letus define the sentiment analysis problem formallyas given in Liu (2010).A direct opinion about the object is a quintuple< oj, fjk, ooijkl, hi, tl>, where ojis the the ob-ject, fjkis the feature of the object oj, ooijklis theorientation or polarity of the opinion on featurefjkof object oj, hiis the opinion holder and tiisthe time when the opinion is expressed by hi.As can be seen from the formal definition ofsentiment analysis and the motivating example,not all sentiment-bearing expressions contribute tothe overall sentiment of the text.
To solve thisproblem, we can make use of semantic roles in thetext.
Semantic role is the underlying relationshipthat the underlying participant has with the mainverb.
To identify the semantic roles, we make useof UNL in our approach.UNL (Universal Networking Language)UNL is declarative formal language specificallydesigned to represent semantic data extracted fromnatural language texts.
In UNL, the informationis represented by a semantic network, also calledUNL graph.
UNL graph is made up of three dis-crete semantic entities, Universal Words, Univer-sal Relations, and Universal Attributes.
UniversalWords are nodes in the semantic network, Univer-sal Relations are arcs linking UWs, and Universalattributes are properties of UWs.
To understand114UNL better, let us consider an example.
UNLgraph for ?I like that bad boy?
is as shown in Fig-ure 1Figure 1: UNL graph for ?I like that bad boy?Here, ?I?, ?like?, ?bad?, and ?boy?
are theUWs.
?agt?
(agent), ?obj?
(patient), and ?mod?
(modifier) are the Universal Relations.
Universalattributes are the properties associated with UWswhich will be explained as and when necessarywith the rules of our algorithm.UNL relationsSyntax of a UNL relation is as shown below,< rel >:< scope >< source >;< target >Where, < rel > is the name of the rela-tion, < scope > is the scope of the relation,< source > is the UW that assigns the relation,and < target > is the UW that receives therelationWe have considered the following Universal re-lations in our approach,1) agt relation : agt stands for agent.
An agent isa participant in action that provokes a change ofstate or location.
The agt relation for the sentence?John killed Mary?
is agt( killed , John ).
Thismeans that the action of killing was performed byJohn.2) obj relation : obj stands for patient.
A patient isa participant in action that undergoes a change ofstate or location.
The obj relation for the sentence?John killed Mary?
is obj( killed , Mary ).
Thismeans that the patient/object of killing is Mary.3) aoj relation : aoj stands for object of an at-tribute.
In the sentence ?John is happy?, the aojrelation is aoj( happy , John ).4) mod relation : mod stands for modifier of an ob-ject.
In the sentence ?a beautiful book?, the modrelation is mod( book , beautiful ).5) man relation : man relation stands for manner.It is used to indicate how the action, experience orprocess of an event is carried out.
In the sentence?The scenery is beautifully shot?, the man relationis man( beautifully , shot ).6) and relation : and relation is used to state aconjunction between two entities.
In the sen-tence ?Happy and cheerful?, the and relation isand(Happy,cheerful).ArchitectureAs show in Figure 1, the modifier ?bad?
is associ-ated with the object of the main verb.
It shouldn?taffect the sentiment of the main agent.
Therefore,we can ignore the modifier relation of the main ob-ject in such cases.
After doing that, the sentimentof this sentence can be inferred to be positive.
Theapproach followed in the project is to first generatea UNL graph for the given input sentence.
Then aset of rules is applied and used to infer the sen-timent of the sentence.
The process is shown inFigure 2.
The UNL generator shown in the Figure2 has been developed at CFILT.1Before, the givenpiece of text is passed on to the UNL generator,it goes through a number of pre-processing stages.Removal of redundant punctuations, special char-acters, emoticons, etc.
are part of this process.This is extremely important because the UNL gen-erator is not able to handle special characters at themoment.
We can see that, the performance of theoverall system is limited by this.
A more robustversion of the UNL generator will certainly allowthe system to infer the sentiment more accurately.Figure 2: System ArchitectureRulesThere is a separate rule for each relation.
For eachUW (Universal word) considered, if it has a @notattribute then its polarity is reversed.
Rules usedby the system are as follows,1) If a given UW is source of the agt relation, thenits polarity is added to the overall polarity of the1http://www.cfilt.iitb.ac.in/115text.
e.g., ?I like her?.
Here, the agt relation willbe agt ( like , I ).
The polarity of like being posi-tive, the overall polarity of the text is positive.
e.g,?I don?t like her?.
Here the agt relation will be agt( like@not , I ).
The polarity of like is positive butit has an attribute @not so its polarity is negative.The overall polarity of the text is negative in thiscase.2) If a given UW is source or target of the obj rela-tion and has the attribute @entry then its polarityis added to the overall polarity of the text.
Thisrule merely takes into account the main verb ofthe sentence into account, and the it?s is polarityconsidered.
e.g., ?I like her?, here the obj relationwill be obj ( like@entry , her ).
The polarity oflike being positive, the overall polarity of the textis positive3) If a given UW is the source of the aoj rela-tion and has the attribute @entry then its polarityis added to the overall polarity of the text.
e.g.,?Going downtown tonight it will be amazing onthe waterfront with the snow?.
Here, the aoj re-lation is aoj ( amazing@entry , it ).
amazing hasa positive polarity and therefore overall polarity ispositive in this case.4) If a given UW is the target of the mod relationand the source UW has the attribute @entry or hasthe attribute @indef then polarity of the target UWis added to the overall polarity of the text.
e.g., ?Ilike that bad boy?.
Here, the aoj relation is mod( boy , bad ).
bad has a negative polarity but thesource UW, boy does not have an @entry attribute.So, in this case negative polarity of bad is not con-sidered as should be the case.
e.g., ?She has agorgeous face?.
Here, the mod relation is mod (face@indef , gorgeous ).
gorgeous has a positivepolarity and face has an attribute @indef.
So, po-larity of gorgeous should be considered.5) If a given UW is the target of the man relationand the source UW has the attribute @entry thenpolarity of the target UW is added to the overallpolarity of the text.
Or if the target UW has theattribute @entry then also we can consider polar-ity of the target UW.
e.g., ?He always runs fast?.Here, the aoj relation is mod ( run@entry , fast ).fast has a positive polarity and the source UW, runhas the @entry attribute.
So, in this case positivepolarity of fast is added to the overall polarity ofthe sentence.
Polarities of both the source and tar-get UW of the and relation are considered.6) In ?Happy and Cheerful?, the and relation isand(Happy, Cheerful).
Happy and Cheerful, bothhave a positive polarity, which gives this sentencean overall positive polarity.The polarity value of each individual word islooked up in a dictionary of positive of negativewords used is Liu (2010) After all the rules areapplied, summation of all the calculated polarityvalues is done.
If this sum is greater than 0 then itis considered as positive, and negative otherwise.This system is negative biased due to the fact thatpeople often tend to express negative sentiment in-directly or by comparison with something good.
Amore detailed discussion on negative texts is pro-vided in section 6.4 Experimental SetupAnalysis was performed for monolingual binarysentiment classification task.
The language usedin this case was English.
The comparison wasdone between 5 systems viz.
System using wordsas features, WordNet sense based system as givenin Balamurali et al., (2012), Clusters based sys-tem as described in Kashyap et al., (2013), Dis-course rules based system as given in Mukherjeeand Bhattacharyya (2012), UNL rule based sys-tem.
Two polarity datasets were used to performthe experiments.1.
EN-TD: English Tourism corpus as used inYe et al., (2009).
It consists of 594 positiveand 593 negative reviews.2.
EN-PD: English Product (music albums) re-view corpus Blitzer et al., (2007).
It consistsof 702 positive and 702 negative reviews.For the WordNet sense, and Clusters based sys-tems, a manually sense tagged version of the (EN-PD) has been used.
Also, a automatically sensetagged version of (EN-TD) was used on these sys-tems.
The tagging in the later case was using anautomated WSD engine, trained on a tourism do-main Khapra et al., (2013).
The results reportedfor supervised systems are based on 10-fold crossvalidation.5 ResultsThe results for monolingual binary sentimentclassification task are shown in Table 1.
The re-sults reported are the best results obtained in caseof supervised systems.
The cluster based system116System EN-TD EN-PDBag of Words 85.53 73.24Synset-based 88.47 71.58Cluster-based 95.20 79.36Discourse-based 71.52 64.81UNL rule-based 86.08 79.55Table 1: Classification accuracy (in %) for mono-lingual sentiment analysisEN-TD EN-PDSystem Pos Neg Pos NegDiscourse rules 94.94 48.06 92.73 36.89UNL rules 95.72 76.44 90.75 68.35Table 2: Classification accuracy (in %) for positiveand negative reviewsperforms the best in both cases.
The UNL rule-based system performs better only than the bagof words and discourse rule based system.
ForEN-PD ( music album reviews ) dataset, the UNLbased system outperforms every other system .These results are very promising for a rule-basedsystem.
The difference between accuracy for pos-itive and negative reviews for the rule-based sys-tems viz.
Discourse rules based and UNL rulesbased is shown in Table 2.
It can be seen thatthe Discourse rules based system performs slightlybetter than the UNL based system for positive re-views.
On the other hand, the UNL rules basedsystem outperforms it in case of negative reviewsby a huge margin.6 DiscussionThe UNL generator used in this case is the bottle-neck in terms of performance due to it?s speed.
Itcan take a long time to generate UNL graphs forlarge sentences.
Also, it makes use of the stan-dard NLP tools viz.
parsing, co-reference resolu-tion, etc.
to assign the proper semantic roles in thegiven text.
It is well known fact that these tech-niques work properly only on structured data.
Thelanguage used in the reviews present in both thedatasets is unstructured in considerable number ofcases.
The UNL generator is still in its infancyand cannot handle text involving special charac-ters.
Due to these reasons, a proper UNL graph isnot generated in some cases.
Also, it is not able togenerator proper UNL graphs for even well struc-tured sentences.
As a result of these things, theclassification accuracy is low.
Negative reviewsare difficult to classify due to comparitive state-ments and presence of positive words.
Also thereare some sarcastic sentences which are difficult toclassify.
Sarcasm is a very difficult problem totackle.
Some related works can be found in Car-valho et al., (2009) and Muresan et al., (2011).
Insome cases, the reviewers make use of their nativelanguage and expressions.
This is a big problemfor the task of monolingual sentiment classifica-tion.7 ConclusionThis paper made use of deep semantics to tacklethe the problem of sentiment analysis.
A seman-tic role labeling method through generation of aUNL graph was used to do this.
The main mo-tivation behind this research was the fact that notall sentiment bearing expressions contribute to theoverall sentiment of the text.
The approach wasevaluated on two datasets and compared with suc-cessful previous approaches which don?t make useof deep semantics.
The system underperformedall the supervised systems but showed promise byyielding better results than the other rule-based ap-proach.
Also, in some cases the performance wasvery close to the other supervised systems.
Thesystem works well on sentences where are inher-ently complex and difficult for sentiment analysisas it makes use of semantic role labeling.
Any rulebased system can never be exhaustive in terms ofrules.
We always need to add new rules to improveon it.
In some case, adding new rules might causeside-effects.
In this case, as the rules are intuitive,adding of new rules will be easy.
Also, analysisof the results hints at some ways to tackle specificproblems effectively.8 Future WorkAdding more rules to the system will help to im-prove the system.
Language gets updated almostdaily, we plan to update our dictionary with thesenew words and expressions to increase the accu-racy.
Also, we plan to replace the UNL systemwith a dependency parsing system and apply rulessimilar to the ones described in this work.117ReferencesRuppenhofer, Josef and Rehbein, Ines.
2012.
Seman-tic frames as an anchor representation for sentimentanalysis.
Proceedings of the 3rd Workshop in Com-putational Approaches to Subjectivity and SentimentAnalysisMukherjee, Subhabrata and Bhattacharyya, Push-pak.
2012.
Sentiment Analysis in Twitter withLightweight Discourse Analysis.
COLINGBalamurali, AR and Joshi, Aditya and Bhattacharyya,Pushpak 2011.
Harnessing wordnet senses for su-pervised sentiment classification.
Proceedings ofthe Conference on Empirical Methods in NaturalLanguage ProcessingRentoumi, Vassiliki and Giannakopoulos, George andKarkaletsis, Vangelis and Vouros, George A 2009.Sentiment analysis of figurative language using aword sense disambiguation approach.
Proceedingsof the International Conference RANLPMart?n-Wanton, Tamara and Balahur-Dobrescu,Alexandra and Montoyo-Guijarro, Andres andPons-Porrata, Aurora 2010.
Word sense dis-ambiguation in opinion mining: Pros and cons.Special issue: Natural Language Processing and itsApplicationsKashyap Popat, Balamurali A.R, Pushpak Bhat-tacharyya and Gholamreza Haffari 2013.
TheHaves and the Have-Nots: Leveraging UnlabelledCorpora for Sentiment Analysis.
The Associationfor Computational LinguisticsSaif, Hassan and He, Yulan and Alani, Harith 2012.Semantic sentiment analysis of twitter.
The Seman-tic Web?ISWC 2012Verma, Shitanshu and Bhattacharyya, Pushpak 2009.Incorporating semantic knowledge for sentimentanalysis.
Proceedings of ICONChoi, Yejin and Cardie, Claire 2008.
Learning withcompositional semantics as structural inference forsubsentential sentiment analysis.
Proceedings of theConference on Empirical Methods in Natural Lan-guage ProcessingLiu, Bing 2010.
Sentiment analysis and subjectivity.Handbook of natural language processingYe, Qiang and Zhang, Ziqiong and Law, Rob 2009.Sentiment classification of online reviews to traveldestinations by supervised machine learning ap-proaches.
Expert Systems with ApplicationsBalamurali, AR and Khapra, Mitesh M and Bhat-tacharyya, Pushpak 2013.
Lost in translation: via-bility of machine translation for cross language sen-timent analysis.
Computational Linguistics and In-telligent Text ProcessingBlitzer, John and Dredze, Mark and Pereira, Fernando2007.
Biographies, bollywood, boom-boxes andblenders: Domain adaptation for sentiment classi-fication.
ACLGonz?alez-Ib?a?nez, Roberto and Muresan, Smaranda andWacholder, Nina 2011.
Identifying Sarcasm in Twit-ter: A Closer Look.
ACLCarvalho, Paula and Sarmento, Lu?
?s and Silva, M?arioJ and de Oliveira, Eug?enio 2009.
Clues for detect-ing irony in user-generated contents: oh...!!
it?s soeasy;-).
ACM118
