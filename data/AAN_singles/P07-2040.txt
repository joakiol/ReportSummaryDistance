Proceedings of the ACL 2007 Demo and Poster Sessions, pages 157?160,Prague, June 2007. c?2007 Association for Computational LinguisticsDetecting Semantic Relations between Named Entities in TextUsing Contextual FeaturesToru Hirano, Yoshihiro Matsuo, Genichiro KikuiNTT Cyber Space Laboratories, NTT Corporation1-1 Hikarinooka, Yokosuka-Shi, Kanagawa, 239-0847, Japan{hirano.tohru, matsuo.yoshihiro, kikui.genichiro}@lab.ntt.co.jpAbstractThis paper proposes a supervised learn-ing method for detecting a semantic rela-tion between a given pair of named enti-ties, which may be located in different sen-tences.
The method employs newly intro-duced contextual features based on center-ing theory as well as conventional syntac-tic and word-based features.
These featuresare organized as a tree structure and arefed into a boosting-based classification al-gorithm.
Experimental results show the pro-posed method outperformed prior methods,and increased precision and recall by 4.4%and 6.7%.1 IntroductionStatistical and machine learning NLP techniques arenow so advanced that named entity (NE) taggers arein practical use.
Researchers are now focusing onextracting semantic relations between NEs, such as?George Bush (person)?
is ?president (relation)?
of?the United States (location)?, because they provideimportant information used in information retrieval,question answering, and summarization.We represent a semantic relation between twoNEs with a tuple [NE1, NE2, Relation Label].
Ourfinal goal is to extract tuples from a text.
For exam-ple, the tuple [George Bush (person), the U.S. (loca-tion), president (Relation Label)] would be extractedfrom the sentence ?George Bush is the president ofthe U.S.?.
There are two tasks in extracting tuplesfrom text.
One is detecting whether or not a givenpair of NEs are semantically related (relation detec-tion), and the other is determining the relation label(relation characterization).In this paper, we address the task of relation de-tection.
So far, various supervised learning ap-proaches have been explored in this field (Culottaand Sorensen, 2004; Zelenko et al, 2003).
Theyuse two kinds of features: syntactic ones and word-based ones, for example, the path of the given pair ofNEs in the parse tree and the word n-gram betweenNEs (Kambhatla, 2004).These methods have two problems which we con-sider in this paper.
One is that they target only intra-sentential relation detection in which NE pairs arelocated in the same sentence, in spite of the fact thatabout 35% of NE pairs with semantic relations areinter-sentential (See Section 3.1).
The other is thatthe methods can not detect semantic relations cor-rectly when NE pairs located in a parallel sentencearise from a predication ellipsis.
In the followingJapanese example1, the syntactic feature, which isthe path of two NEs in the dependency structure,of the pair with a semantic relation (?Ken11?
and?Tokyo12?)
is the same as the feature of the pair withno semantic relation (?Ken11?
and ?New York14?).
(S-1) Ken11-wa Tokyo12-de, Tom13-waNew York14-de umareta15.
(Ken11 was born15 in Tokyo12, Tom13 inNew York14.
)To solve the above problems, we propose a super-vised learning method using contextual features.The rest of this paper is organized as follows.
Sec-tion 2 describes the proposed method.
We report theresults of our experiments in Section 3 and concludethe paper in Section 4.2 Relation DetectionThe proposed method employs contextual featuresbased on centering theory (Grosz et al, 1983) aswell as conventional syntactic and word-based fea-tures.
These features are organized as a tree struc-ture and are fed into a boosting-based classificationalgorithm.
The method consists of three parts: pre-processing (POS tagging, NE tagging, and parsing),1The numbers show correspondences of words betweenJapanese and English.157feature extraction (contextual, syntactic, and word-based features), and classification.In this section, we describe the underlying idea ofcontextual features and how contextual features areused for detecting semantic relations.2.1 Contextual FeaturesWhen a pair of NEs with a semantic relation appearsin different sentences, the antecedent NE must becontextually easily referred to in the sentence withthe following NE.
In the following Japanese exam-ple, the pair ?Ken22?
and ?amerika32 (the U.S.)?have a semantic relation ?wataru33 (go)?, because?Ken22?
is contextually referred to in the sentencewith ?amerika32?
(In fact, the zero pronoun ?irefers to ?Ken22?).
Meanwhile, the pair ?Naomi25?and ?amerika32?
has no semantic relation, becausethe sentence with ?amerika32?
does not refer to?Naomi25?.
(S-2) asu21, Ken22-wa Osaka23-o otozure24Naomi25-to au26.
(Ken22 is going to visit24 Osaka23 to see26Naomi25, tomorrow21.
)(S-3) sonogo31, (?i-ga) amerika32-ni watari33Tom34-to ryoko35 suru.
(Then31, (hei) will go33 to the U.S.32 to travel35with Tom34.
)Furthermore, when a pair of NEs with a seman-tic relation appears in a parallel sentence arise frompredication ellipsis, the antecedent NE is contextu-ally easily referred to in the phrase with the follow-ing NE.
In the example of ?
(S-1)?, the pair ?Ken11?and ?Tokyo12?
have a semantic relation ?umareta15(was born)?.
Meanwhile, the pair ?Ken11?
and?New York14?
has no semantic relation.Therefore, using whether the antecedent NE is re-ferred to in the context with the following NE as fea-tures of a given pair of NEs would improve relationdetection performance.
In this paper, we use cen-tering theory (Kameyama, 1986) to determine howeasily a noun phrase can be referred to in the follow-ing context.2.2 Centering TheoryCentering theory is an empirical sorting rule used toidentify the antecedents of (zero) pronouns.
Whenthere is a (zero) pronoun in the text, noun phrasesthat are in the previous context of the pronoun aresorted in order of likelihood of being the antecedent.The sorting algorithm has two steps.
First, from thebeginning of the text until the pronoun appears, nounOsaka23o asu21, Naomi25othersniga Ken22waPriorityFigure 1: Information Stacked According to Center-ing Theoryphrases are stacked depending on case markers suchas particles.
In the above example, noun phrases,?asu21?, ?Ken22?, ?Osaka23?
and ?Naomi25?, whichare in the previous context of the zero pronoun ?i,are stacked and then the information shown in Fig-ure 1 is acquired.
Second, the stacked information issorted by the following rules.1.
The priority of case markers is as follows: ?wa> ga > ni > o > others?2.
The priority of stack structure is as follows:last-in first-out, in the same case markerFor example, Figure 1 is sorted by the above rulesand then the order, 1: ?Ken22?, 2: ?Osaka23?, 3:?Naomi25?, 4: ?asu21?, is assigned.
In this way, us-ing centering theory would show that the antecedentof the zero pronoun ?i is ?Ken22?.2.3 Applying Centering TheoryWhen detecting a semantic relation between a givenpair of NEs, we use centering theory to determinehow easily the antecedent NE can be referred to inthe context with the following NE.
Note that we donot explicitly execute anaphora resolutions here.Applied centering theory to relation detection isas follows.
First, from the beginning of the text untilthe following NE appears, noun phrases are stackeddepending on case markers, and the stacked infor-mation is sorted by the above rules (Section 2.2).Then, if the top noun phrase in the sorted order isidentical to the antecedent NE, the antecedent NE is?positive?
when being referred to in the context withthe following NE.When the pair of NEs, ?Ken22?
and ?amerika32?,is given in the above example, the noun phrases,?asu21?, ?Ken22?, ?Osaka23?
and ?Naomi25?, whichare in the previous context of the following NE?amerika32?, are stacked (Figure 1).
Then they aresorted by the above sorting rules and the order, 1:?Ken22?, 2: ?Osaka23?, 3: ?Naomi25?, 4: ?asu21?,is acquired.
Here, because the top noun phrase inthe sorted order is identical to the antecedent NE,the antecedent NE ?Ken22?
is ?positive?
when be-158amerika32wa: Ken22o: Osaka23others: Naomi25others: asu21Figure 2: Centering Structureing referred to in the context with the following NE?amerika32?.
Whether or not the antecedent NE isreferred to in the context with the following NE isused as a feature.
We call this feature Centering Top(CT).2.4 Using Stack StructureThe sorting algorithm using centering theory tendsto rank highly thoes words that easily become sub-jects.
However, for relation detection, it is necessaryto consider both NEs that easily become subjects,such as person and organization, and NEs that do noteasily become subjects, such as location and time.We use the stack described in Section 2.3 as astructural feature for relation detection.
We call thisfeature Centering Structure (CS).
For example, thestacked information shown in Figure 1 is assumedto be structure information, as shown in Figure 2.The method of converting from a stack (Figure 1)into a structure (Figure 2) is described as follows.First, the following NE, ?amerika32?, becomes theroot node because Figure 1 is stacked informationuntil the following NE appears.
Then, the stackedinformation is converted to Figure 2 depending onthe case markers.
We use the path of the given pairof NEs in the structure as a feature.
For example,?amerika32 ?
wa:Ken22?2 is used as the feature ofthe given pair ?Ken22?
and ?amerika32?.2.5 Classification AlgorithmThere are several structure-based learning algo-rithms proposed so far (Collins and Duffy, 2001;Suzuki et al, 2003; Kudo and Matsumoto, 2004).The experiments tested Kudo and Matsumoto?sboosting-based algorithm using sub trees as features,which is implemented as the BACT system.In relation detection, given a set of training exam-ples each of which represents contextual, syntactic,and word-based features of a pair of NEs as a treelabeled as either having semantic relations or not,the BACT system learns that a set of rules are ef-fective in classifying.
Then, given a test instance,which represents contextual, syntactic, and word-2?A?
B?
means A has a dependency relation to B.Type % of pairs with semantic relations(A) Intra-sentential 31.4% (3333 / 10626)(B) Inter-sentential 0.8% (1777 / 225516)(A)+(B) Total 2.2% (5110 / 236142)Table 1: Percent of pairs with semantic relations inannotated textbased features of a pair of NEs as a tree, the BACTsystem classifies using a set of learned rules.3 ExperimentsWe experimented with texts from Japanese newspa-pers and weblogs to test the proposed method.
Thefollowing four models were compared:1.
WD : Pairs of NEs within n words are detectedas pairs with semantic relation.2.
STR : Supervised learning method using syn-tactic3 and word-based features, the path of thepairs of NEs in the parse tree and the word n-gram between pairs of NEs (Kambhatla, 2004)3.
STR-CT : STR with the centering top featureexplained in Section 2.3.4.
STR-CS : STR with the centering structure fea-ture explained in Section 2.4.3.1 SettingWe used 1451 texts from Japanese newspapers andweblogs, whose semantic relations between personand location had been annotated by humans for theexperiments4.
There were 5110 pairs with seman-tic relations out of 236,142 pairs in the annotatedtext.
We conducted ten-fold cross-validation over236,142 pairs of NEs so that sets of pairs from asingle text were not divided into the training and testsets.We also divided pairs of NEs into two types: (A)intra-sentential and (B) inter-sentential.
The reasonfor dividing them is so that syntactic structure fea-tures would be effective in type (A) and contextualfeatures would be effective in type (B).
Another rea-son is that the percentage of pairs with semantic rela-tions out of the total pairs in the annotated text differsignificantly between types, as shown in Table 1.In the experiments, all features were automati-cally acquired using a Japanese morphological anddependency structure analyzer.3There is no syntactic feature in inter-sentential.4We are planning to evaluate the other pairs of NEs.159(A)+(B) Total (A) Intra-sentential (B) Inter-sententialPrecision Recall Precision Recall Precsion RecallWD10 43.0(2501/5819) 48.9(2501/5110) 48.1(2441/5075) 73.2(2441/3333) 8.0(60/744) 3.4(60/1777)STR 69.3(2562/3696) 50.1(2562/5110) 75.6(2374/3141) 71.2(2374/3333) 33.9(188/555) 10.6(188/1777)STR-CT 71.4(2764/3870) 54.1(2764/5110) 78.4(2519/3212) 75.6(2519/3333) 37.2(245/658) 13.8(245/1777)STR-CS 73.7(2902/3935) 56.8(2902/5110) 80.1(2554/3187) 76.6(2554/3333) 46.5(348/748) 27.6(348/1777)WD10: NE pairs that appear within 10 words are detected.Table 2: Results for Relation Detection00.20.40.60.810 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1RecallPrecisionWDSTRSTR-CTSTR-CSSTR-CSSTRWDSTR-CTFigure 3: Recall-precision Curves: (A)+(B) total3.2 ResultsTo improve relation detection performance, we in-vestigated the effect of the proposed method usingcontextual features.
Table 2 shows results for Type(A), Type (B), and (A)+(B).
We also plotted recall-precision curves5, altering threshold parameters, asshown in Figure 3.The comparison between STR and STR-CT andbetween STR and STR-CS in Figure 3 indicates thatthe proposed method effectively contributed to rela-tion detection.
In addition, the results for Type (A):intra-sentential, and (B): inter-sentential, in Table2 indicate that the proposed method contributed toboth Type (A), improving precision by about 4.5%and recall by about 5.4% and Type (B), improvingprecision by about 12.6% and recall by about 17.0%.3.3 Error AnalysisOver 70% of the errors are covered by two majorproblems left in relation detection.Parallel sentence: The proposed method solvesproblems, which result from when a parallelsentence arises from predication ellipsis.
How-ever, there are several types of parallel sentencethat differ from the one we explained.
(For ex-ample, Ken and Tom was born in Osaka andNew York, respectively.
)5Precision = # of correctly detected pairs / # of detected pairsRecall = # of correctly detected pairs / # of pairs with semanticrelationsDefinite anaphora: Definite noun phrase, such as?Shusho (the Prime Minister)?
and ?Shacho(the President)?, can be anaphors.
We shouldconsider them in centering theory, but it is dif-ficult to find them in Japanese .4 ConclusionIn this paper, we propose a supervised learningmethod using words, syntactic structures, and con-textual features based on centering theory, to im-prove both inter-sentential and inter-sentential rela-tion detection.
The experiments demonstrated thatthe proposed method increased precision by 4.4%,up to 73.7%, and increased recall by 6.7%, up to56.8%, and thus contributed to relation detection.In future work, we plan to solve the problems re-lating to parallel sentence and definite anaphora, andaddress the task of relation characterization.ReferencesM.
Collins and N. Duffy.
2001.
Convolution Kernels forNatural Language.
Proceedings of the Neural InformationProcessing Systems, pages 625?632.A.
Culotta and J. Sorensen.
2004.
Dependency Tree Kernelsfor Relation Extraction.
Annual Meeting of Association ofComputational Linguistics, pages 423?429.B.
J. Grosz, A. K. Joshi, and S. Weistein.
1983.
Providing aunified account of definite nounphrases in discourse.
AnnualMeeting of Association of Computational Linguistics, pages44?50.N.
Kambhatla.
2004.
Combining Lexical, Syntactic, and Se-mantic Features with Maximum Entropy Models for Infor-mation Extraction.
Annual Meeting of Association of Com-putational Linguistics, pages 178?181.M.
Kameyama.
1986.
A property-sharing constraint in center-ing.
Annual Meeting of Association of Computational Lin-guistics, pages 200?206.T.
Kudo and Y. Matsumoto.
2004.
A boosting algorithm forclassification of semi-structured text.
In Proceedings of the2004 EMNLP, pages 301?308.J.
Suzuki, T. Hirao, Y. Sasaki, and E. Maeda.
2003.
Hier-archical directed acyclic graph kernel : Methods for struc-tured natural language data.
Annual Meeting of Associationof Computational Linguistics, pages 32?39.D.
Zelenko, C. Aone, and A. Richardella.
2003.
Kernel Meth-ods for Relation Extraction.
Journal of Machine LearningResearch, pages 3:1083?1106.160
