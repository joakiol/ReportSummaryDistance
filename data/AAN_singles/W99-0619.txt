Word Informativeness and Automatic Pitch Accent ModelingShimei Pan and Kathleen R. McKeownDept.
of Computer ScienceColumbia UniversityNew York, NY 10027, USA{pan, kathy}@cs, columbia, eduAbstractIn intonational phonology and speech syn-thesis research, it has been suggested thatthe relative informativeness of a word can beused to predict pitch prominence.
The moreinformation conveyed by a word, the morelikely it will be accented.
But there are oth-ers who express doubts about such a correla-tion.
In this paper, we provide some empiri-cal evidence to support he existence of sucha correlation by employing two widely ac-cepted measures of informativeness.
Our ex-periments how that there is a positive corre-lation between the informativeness of a wordand its pitch accent assignment.
They alsoshow that informativeness enables statisti-cally significant improvements in pitch ac-cent prediction.
The computation of wordinformativeness i  inexpensive and can beincorporated into speech synthesis ystemseasily.1 IntroductionThe production of natural, intelligiblespeech remains a major challenge for speechsynthesis research.
Recent research hasfocused on prosody modeling (Silverman,1987; Hirschberg, 1990; Santen, 1992), whichdetermines the variations in pitch, tempoand rhythm.
One of the critical issues inprosody modeling is pitch accent assign-ment.
Pitch accent is associated with thepitch prominence of a word.
For example,some words may sound more prominent thanothers within a sentence because they are as-sociated with a sharp pitch rise or fall.
Usu-ally, the prominent words bear pitch accentswhile the less prominent ones do not.
A1-though native speakers of a particular lan-guage have no difficulty in deciding whichwords in their utterances should be accented,the general pattern of accenting in a lan-guage, such as English, is still an open ques-tion.Some linguists speculate that relative in-formativeness, or semantic weight of a wordcan influence accent placement.
Ladd  (1996)claims that "the speakers assess the relativesemantic weight or informativeness of poten-tially accentable words and put the accent onthe most  informative point or points" (ibid,pg.
175).
He  also claims that "if we  un-derstand relative semantic weight, we  willautomatically understand accent placement"(ibid, pg.
186).
Bolinger (Bolinger, 1972)also uses the following examples to illustratethe phenomenon:1.
"He was arrested because he KILLED aman."2.
"He was arrested because he killed aPOLICEMAN.
"The capitalized words in the examples areaccented.
In (1), "man" is semanticallyempty relative to "kill"; therefore, the verb"kill" gets accented.
However, in (2), "po-liceman" is semantically rich and is accentedinstead.However, different heories, not based oninformativeness, were proposed to explainthe above phenomenon.
For example, Bres-nan's (1971) explanation is based on syn-tactic function.
She suggests that "man"in the above sentence does not get accentedbecause "man" and other words like "guy"or "person" or "thing" form a category of148"semi-pronouns".
Counter-examples li tedbelow raise more questions about the use-fulness of semantic informativeness.
The ac-cent pattern in the following examples can-not be explaihed solely by semantic informa-tiveness.3.
"HOOVER dam."4.
"Hoover TOWER.
"While researchers have discussed the pos-sible influence of semantic informativeness,there has been no known empirical studyof the claim nor has this type of informa-tion been incorporated into computationalmodels of prosody.
In this work, we employtwo measurements of informativeness.
First,we adopt an information-based framework(Shannon, 1948), quantifying the "Informa-tion Content', (IC)" of a word as the negativelog likelihood of a word in a corpus.
Thesecond measurement is TF*IDF (Term Fre-quency times Inverse Document Frequency)(Salton, 1989; Salton, 1991), which has beenwidely used :to quantify word importance ininformation retrieval tasks.
Both IC andTF*IDF are well established measurementsof informativeness and therefore, good can-didates to investigate.
Our empirical studyshows that word informativeness not onlyis closely related to word accentuation, butalso provides new power in pitch accent pre-diction.
Our results suggest hat informa-tion content is a valuable feature to be in-coiporated in speech synthesis ystems.In the following sections, we first define ICand TF*IDF.
Then, a description of the cor-pus used in ~this tudy is provided.
We thendescribe a Set of experiments conducted tostudy the relation between informativenessand pitch accent.
We explain how machinelearning techniques are used in the pitch ac-cent modeling process.
Our results showthat:?
Both iC and TF*IDF scores arestrongly correlated with pitch accent as-signment.?
IC is a more powerful predictor thanTF*IDF.?
IC provides better prediction power inpitch accent prediction than previoustechniques.The investigated pitch accent models can beeasily adopted by speech synthesis ystems.2 Definit ions of IC andTF* IDFFollowing the standard definition in infor-mation theory (Shannon, 1948; Fano, 1961;Cover and Thomas, 1991) the IC of a wordisIC(w) = -log(P(w))where P(w) is the probability of the wordw appearing in a corpus and P(w) is esti-matted as: _~2 where F(w) is the frequencyof w in the corpus and N is the accumula-tive occurrence of all the words in the cor-pus.
Intuitively, if the probability of a wordincreases, its informativeness decreases andtherefore it is less likely to be an informationfocus.
Similarly, it is therefore less likely tobe communicated with pitch prominence.TF*IDF is defined by two componentsmultiplied together.
TF (Term Frequency)is the word frequency within a document;IDF (Inverse Document Frequency) is thelogarithm of the ratio of the total number ofdocuments to the number of documents con-taining the word.
The product of TF*IDF ishigher if a word has a high frequency withinthe document, which signifies high impor-tance for the current document, and low dis-persion in the corpus, which signifies highspecificity.
In this research, we employeda variant of TF*IDF score used in SMART(Buckley, 1985), a popular information re-trieval package:(TF*IDF)~o,,d; =N(1.0 + log F,o,,dj) log N,o~I M N 2E ((1"0 + log F~ok,dj ) log ~)k=lwhere F,~.dj is the the frequency of word wiin document dj, N is the total number of149documents, Nw~ is the number of documentscontaining word w~ and M is the number ofdistinct stemmed words in document dj.IC and TF*IDF capture different kinds ofinformativeness.
IC is a matrix global inthe domain of a corpus and each word ina corpus has a unique IC score.
TF*IDFcaptures the balance of a matrix local to agiven document (TF) and a matrix globalin a corpus (IDF).
Therefore, the TF*IDFscore of a word changes from one documentto another (different TF).
However, someglobal features are also captured by TF*IDF.For example, a common word in the domaintends to get low TF*IDF score in all the doc-uments in the corpus.3 Corpus DescriptionIn order to empirically study the relationsbetween word informativeness and pitch ac-cent, we use a medical corpus which includesa speech portion and a text portion.
Thespeech corpus includes fourteen segmentswhich total about 30 minutes of speech.
Thespeech was collected at Columbia Presbyte-rian Medical Center (CPMC) where doctorsinformed residents or nurses about the post-operative status of a patient who has just un-dergone a bypass urgery.
The speech corpuswas transcribed orthographically b a medi-cal professional nd is also intonationally a-beled with pitch accents by a ToBI (Toneand Break Index) (Silverman et al, 1992;Beckman and Hirschberg, 1994) expert.
Thetext corpus includes 1.24 million, 2,422 dis-charge summaries, spanning a larger groupof patients.
The majority of the patientshave also undergone cardiac surgery.
The or-thographic transcripts as well as the text cor-pus are used to calculate the IC and TF*IDFscores.
First, all the words in the text cor-pus as well as the speech transcripts are pro-cessed by a stemming model so that wordslike "receive" and "receives" are treated asone word.
We employ a revised version ofLovins' stemming algorithm (Lovins, 1968)which is implemented in SMART.
Althoughthe usefulness of stemming is arguable, wechoose to use stemming because we think"receive" and "receives" are equally likelyto be accented.
Then, IC and TF*IDF arecalculated.
After this, the effectiveness ofinformativeness in accent placement is veri-fied using the speech corpus.
Each word inthe speech corpus has an IC score, a TF*IDFscore, a part-of-speech (POS) tag and a pitchaccent label.
Both IC and TF*IDF are usedto test the correlation between informative-ness and accentuation.
POS is also investi-gated by several machine learning techniquesin automatic pitch accent modeling.4 ExperimentsWe conducted a series of experiments todetermine whether there is a correlationbetween informativeness and pitch accentand whether informativeness provides an im-provement over other known indicators onpitch accent, such as part-of-speech.
We ex-perimented with different forms of machinelearning to integrate indicators within a sin-gle framework, testing whether ule induc-tion or hidden Markov modeling provides abetter model.4.1 Ranking Word Informativenessin the CorpusTable 1 and 2 shows the most and least in-formative words in the corpus.
The IC orderindicates the rank among all the words in thecorpus, while TF*IDF order in the table in-dicates the rank among the words within adocument.
The document was picked ran-domly from the corpus.
In general, mostof the least informative words are functionwords, such as "with" or "and".
However,some content words are selected, such as "pa-tient", "year", "old".
These content wordsare very common in this domain and arementioned in almost all the documents in thecorpus.
In contrast, the majority of the mostinformative words are content words.
Someof the selections are less expected.
For ex-ample "your" ranks as the most informativeword in a document using TF*IDF.
This in-dicates that listeners or readers are rarely ad-dressed in the corpus.
It appears only oncein the entire corpus.150Rank12345678910ICMost Informative IC Least InformativeWords IC Words ICzophrinnamelxyphoidwytensinpyonephritisorobuccaltzancksyntheticRxquote14.0272514.0272514.0272514.0272514.0272514.0272514.0272514.0272514.0272514.02725withonpatientinshehefornodayhad4.087774.208784.263544.358344.524094.529184.664364.690194.788324.98343Rank12345678910Table I: IC Most  and Least informative wordsTF*IDF Most InformativeWords TF*IDFyourvoltanksonometerpapillarypancuroniumname2name3incompleteyes0.157460.152380.152380.152380.152380.152380.152380.152380.143450.13883TF*IDF Least InformativeWords TF*IDFand 0.00008a 0.00009the 0.00009to 0.00016was 0.00020of 0.00024with 0.00034in 0.00041old 0.00068year 0.00088Table 2: TF* IDF  Most  and Least informative words4.2 Test ing the  Cor re la t ion  ofIn format iveness  and AccentP red ic t ionIn order to verify whether word informa-tiveness is correlated with pitch accent, weemploy Spearman's  rank correlation coeffi-cient p and associated test (Conover, 1980)to estimate the correlations between IC andpitch prominence as well as TF* IDF  andpitch prominence.
As  shown in Table 3,both IC and TF* IDF  are closely correlatedto pitch accent with a significance level p =2.67.10 -85 and p = 2.90. i0 TM respectively.Because the!
correlation coefficient p is pos-itive, this indicates that the higher the ICand TF*IDF are, the more likely a word isto be accented.4.3 Learn ing  IC and  TF* IDF  AccentMode lsThe correlation test suggests that there isa strong connection between informativenessand pitch accent.
But we also want to showhow much performance gain can be achievedby adding this information to pitch accentmodels.
To study the effect of TF*IDF andIC on pitch accent, we use machine learningtechniques to learn models that predict the151Feature Correlation Coefficient Significance LevelTF*IDF p -- 0.29 p = 2.67.10 -65IC p = 0.34 p = 2.90.10 TMTable 3: The  Correlation of Informativeness and Accentuationeffect of these indicators on pitch accent.
Weuse both RIPPER (Cohen, 1995) and Hid-den Markov Models (HMM) (Rabiner andJuang, 1986) to build pitch accent models.RIPPER is a system that learns sets of clas-sification rules from training data.
It auto-matically selects rules which maximize theinformation gain and employs heuristics todecide when to stop to prevent over-fitting.The performance of RIPPER is compara-ble with most benchmark rule induction sys-tems such as C4.5 (Quinlan, 1993).
We trainRIPPER on the speech corpus using 10-fold cross-validation, a standard procedurefor training and testing when the amountof data is limited.
In this experiment, thepredictors are IC or TF*IDF, and the re-sponse variable is the pitch accent assign-ment.
Once a set of RIPPER rules are ac-quired, they can be used to predict whichword should be accented in a new corpus.HMM is a probability model which hasbeen successfully used in many applications,such as speech recognition (Rabiner, 1989)and part-of-speech tagging (Kupiec, 1992).A HMM is defined as a triple: )~=(A, B, H)where A is a state transition probability ma-trix, B is a observation probability distribu-tion matrix, and H is an initial state distribu-tion vector.
In this experiment, he hiddenstates are the accent status of words whichcan be either "accented" or "not accented".The observations are IC or TF*IDF scoreof each word.
Because of the limitation ofthe size of the speech corpus, we use a first-order HMM where the following condition isassumed:P(  Qt+I -~i\[Qt = j, Qt-1 = k, .
.
.
Q1 =n)  =P(Qt+i  = i lQt=j )where Qt is the state at t ime t. Becausewe employ  a supervised training process,no sophisticated parameter estimation pro-cedure, such as the Baum-Welch algorithm(Rabiner, 1989) is necessary.
Here all theparameters are precisely calculated using thefollowing formula:A = {c~j : i  = 1 , .
.
,N , j  = 1 , .
.
,N}F (Qt -1 - - i ,  Qt= j )o~i3 -- F (Qt  = j )B = ( l~m:  j = 1 , .
.
,N ,m = 1,.., M}Zjm = F (Qt  = j, = m)F(Qt  = j )R = i=  1 , .
.
,N}F(Q i  =i)~'i= F(Qi)where N is the number of hidden states andM is the number of observations.Once all the parameters of a HMM are set,we employ the Viterbi algorithm (Viterbi,1967; Forney, 1973) to find an optimal accen-tuation sequence which maximizes the pos-sibility of the occurrence of the observed ICor TF*IDF sequence given the HMM.Both RIPPER and HMM are widely ac-cepted machine learning systems.
However,their theoretical bases are very different.HMM focuses on optimizing a sequence ofaccent assignments instead of isolated accentassignment.
By employing both of them, wewant to show that our conclusions hold forboth approaches.
Furthermore, we expectHMM to do better than RIPPER becausethe influence of context words is incorpo-rated.We use a baseline model where all wordsare assigned a default accent status (ac-cented).
52% of the words in the corpusare actually accented and thus, the baselinehas a performance of 52~0.
Our results in152Models HMM Performance R IPPER PerformanceBaseline 52.02% 52.02%TF* IDF  Model  67.25% 65.66%IC Model  71.96% 70.06%TaBle 4: Compar i son  of IC, TF* IDF  model  with the baseline mode lTable 4 show that when TF* IDF  is usedto predict pitch accent, performance is in-creased over the baseline of 52% to 67.25%and 65.66 ?7o for HMM and R IPPER respec-tively.
In the IC model, the performanceis further increased to 71.96% and 70.06%.These results 'are obtained by using 10-foldcross-validation.
We can draw two conclu-sions from the results.
First, both IC andTF* IDF  are very effective in pitch accentprediction.
All the improvements over thebaseline mode l  are statistically significantwith p < i.Iii.
10 -16 1, using X 2 test (Fien-berg, 1983; Fleiss, 1981).
Second, the ICmodel  is more  powerful than the TF* IDFmodel.
It out performs the TF* IDF  mode lwith p = 3.8.10 -5 for the HMM mode l  andp = 0.0002 for the R IPPER model.
The  lowp-values show the improvements  achieved bythe IC models are significant.
Since IC per-forms better than TF* IDF  in pitch accentprediction, we  choose IC to measure infor-mativeness in all the following experiments.Another  observation of the results is that theHMM models do show some improvementsover the R IPBER models.
But  the differenceis marginal.
More  data is needed to test thesignificance of the improvements.4.4 Incorporat ing IC  in ReferenceAccent  Mode lsIn order to show that IC provides additionalpower in predicting pitch accent than cur-rent models, we  need to directly comparethe influence of IC with that of other ref-erence models.
In this section, we  describeexperiments that compare  IC alone againstiS reports p=0 because of underflow.
The  real pvalue is less than I.ii ?
10 -16, wh ich  is the smallestvalue the comptlter can represent in this casea part-of-speech (POS) model for pitch ac-cent prediction and then compare a modelthat integrates IC with POS against he POSmodel.
Finally, anticipating the possibilitythat other features within a traditional TTSin combination with POS may provide equalor better performance than the addition ofIC, we carried out experiments hat directlycompare the performance of Text-to-Speech(TTS) synthesizer alone with a model thatintegrates TTS with IC.In most speech synthesis ystems, part-of-speech (POS) is the most powerful featurein pitch accent prediction.
Therefore, show-ing that IC provides additional power overPOS is important.
In addition to the im-portance of POS within TTS for predictingpitch accent, there is a clear overlap betweenPOS and IC.
We have shown that the wordswith highest IC usually are content wordsand the words with lowest IC are frequentlyfunction words.
This is an added incentivefor comparing IC with POS models.
Thus,we want to explore whether the new informa-tion added by IC can provide any improve-ment when both of them are used to predictaccent assignment.In order to create a POS model, we firstutilize MXPOST, a maximum entropy part-of-speech tagger (Ratnaparkhi, 1996) to getthe POS information for each word.
Theperformance of the MXPOST tagger is com-parable with most benchmark POS taggers,such as Brill's tagger (Brill, 1994).
Afterthis, we map all the part-of-speech tags intoseven categories: "noun", "verb", "adjec-tive", "adverb", "number", "pronoun" and"others".
The mapping procedure is con-ducted because keeping all the initial tags(about 35) will drastically increase the re-quirements for the amount of training data.Models HMM Performance RIPPER PerformanceIC Model 71.96% 70.06%POS Model 71.33% 70.52%POS+IC Model 74.06% 73.71%Table 5: Comparison of POS+IC model with POS modelModels HMM Performance RIPPER PerformanceTTS Model 71.75% 71.75%TTS+IC Model 72.30% 72.75%POS+IC Model 74.06% 73.71%Table 6: Compar i son  of TTS+IC  mode l  with TTS  mode lThe  obtained POS tag is the predictor in thePOS model.
As  shown in table 5, the perfor-mance  of these two POS models  are 71.33%and 70.52% for HMM and R IPPER respec-tively, which is comparable  with that of theIC model.
This comparison further showsthe strength of IC because it has similarpower to POS in pitch accent prediction andit is very easy to compute.
When the POSmodels are augmented  with IC, the POS+ICmode l  performance is increased to 74.06%and 73.71% respectively.
The  improvementis statistically significant with p -- 0.015 forHMM mode l  and p = 0.005 for R IPPERwhich means  the new information capturedby IC provides additional predicting powerfor the POS+IC  models.
These experimentsproduce new evidence confirming that IC isa valuable feature in pitch accent modeling.We also tried another reference model,Text-to-Speech (TTS)  synthesizer output, toevaluate the results.
The  TTS  pitch ac-cent mode l  is more  comprehensive than thePOS model.
It has taken many features intoconsideration, such as discourse and seman-tic information.
It is well established andhas been evaluated in various situations.
Inthis research, we  adopted Bell Laboratories'TTS  system (Sproat, 1997; Olive and Liber-man,  1985; Hirschberg, 1990).
We run it onour corpus first to get the TTS  pitch accentassignments.
Compar ing  the TTS  accentassignment with the expert accent assign-ment, the TTS  performance is 71.75% whichis statistically significantly lower than theHMM POS+IC  mode l  with p = 0.039.
Wealso tried to incorporate IC in TTS  model.A simple way  of doing this is to use theTTS  output and  IC as predictors and trainthem with our data.
The  obtained TTS+ICmodels achieve marginal improvement.
Theperformance of TTS+IC  mode l  increases to72.30% and 72.75% for HMM and R IPPERrespectively, which is lower than that of thePOS?IC  models.
We speculate that this ismay be due to the corpus we used.
TheBell Laboratories' TTS  pitch accent modelis trained in a totally different domain, andour medical corpus seems to negatively affectthe TTS  performance (71.75% compared  toaround 80%, its normal  performance).
Sincethe TTS+IC  models  involve two totally dif-ferent domains, the effectiveness of IC maybe compromised.
If this assumption holds,we think that the TTSwIC model will per-form better when IC is trained together withthe TTS internal features on our corpus di-rectly.
But since this requires retraining aTTS system for a new domain and it is veryhard for us to conduct such an experiment,no further comparison was conducted to ver-ify this assumption.Although TF*IDF is less powerhfl than ICin pitch accent prediction, since they mea-sure two different kinds of informativeness,it is possible that a TF*IDF+IC model can154!perform better than the IC model.
Similarly,if TF*IDF is incorporated in the POS?ICmodel, the overall performance may increasefor the POS+IC+TF*IDF model.
How-ever, our experiment shows no improvementswhen TF*IDF is incorporated in the IC andPOS+IC model.
Our experiments show thatIC is always the dominant predictor whenboth IC and TF*IDF are presented.5 Related WorkInformation based approaches were appliedin some natural anguages applications be-fore.
In (Resnik, 1993; Resnik, 1995), ICwas used to measure semantic similarity be-tween words and it is shown to be moreeffective than traditional measurements ofsemantic distance within the WordNet hi-erarchy.
A similar log-based information-like measurement was also employed in (Lea-cock and Chodorow, 1998) to measure se-mantic similarity.
TF*IDF scores are mainlyused in keyword-based information retrievaltasks.
For example, TF*IDF has been usedin (Salton, :1989; Salton, 1991) to indexthe words ini a document and is also imple-mented in SMART (Buckley, 1985) whichis a general;-purpose information retrievalpackage, providing basic tools and librariesto facilitate information retrieval tasks.Some early work on pitch accent predic-tion in speech synthesis only uses the dis-tinction between content words and functionwords.
Although this approach is simple, ittends to assign more pitch accents than nec-essary.
We also tried the content/functionword model on our corpus and as expected,we found it to be less powerful than the part-of-speech model.
More advanced pitch ac-cent models make use of other information,such as part-of-speech, given/new distinc-tions and contrast information (Hirschberg,1993).
Semantic information is also em-ployed in predicting accent patterns for com-plex nominal phrases (Sproat, 1994).
Othercomprehensive pitch accent models havebeen suggested in (Pan and McKeown, 1998)in the framework of Concept-to-Speech gen-eration where the output of a natural an-guage generation system is used to predictpitch accent.6 Discuss ionSince IC is not a perfect measurement  of in-formativeness, it can cause problems in ac-cent prediction.
Moreover, even if a perfectmeasurement  of informativeness is available,more  features may be needed in order tobuild a satisfactory pitch accent model.
Inthis section, we  discuss each of these issues.IC does not directly measure  the informa-tiveness of a word.
It measures the rarity of aword  in a corpus.
That  a word  is rare doesn'tnecessarily mean that it is informative.
Se-mantically empty  words can be ranked highusing IC as well.
For example, CABG is acommon operation in this domain.
"CABG"is almost always used whenever  the opera-tion is mentioned.
However,  in a few in-stances, it is referred to as a "CABG oper-ation".
As  a result, the semantically emptyword  (in this context) "operation" gets ahigh IC score and  it is very hard to distin-guish high IC scores resulting from this sit-uation f rom those that accurately measureinformativeness and this causes problems inprecisely measur ing the IC of a word.
Simi-larly, misspelled words also can have high ICscore due to their rarity.A l though IC is not ideal for quantifyingword  informativeness, even with a perfectmeasurement  of informativeness, there arestill many  cases where this information byitself wou ld  not be enough.
For example,each word  only gets a unique IC score re-gardless of its context; yet it is well knownthat context information, such as g iven/newand contrast, plays an important role in ac-centuation.
In the future, we  plan to build acomprehensive accent mode l  with more  pitchaccent indicators, such as syntactic, seman-tic and discourse features.7 Conc lus ionIn this paper, we have provided empirical ev-idence for the usefulness of informativenessfor accent assignment.
Overall, there is a155positive correlation between indicators of in-formativeness, such as IC and TF*IDF, andpitch accent.
The more informative a wordis, the more likely that a pitch accent is as-signed to the word.
Both of the two measure-ments of informativeness improve over thebaseline performance significantly.
We alsoshow that IC is a more powerful measure ofinformativeness than TF*IDF for pitch ac-cent prediction.
Later, when comparing IC-empowered POS models with POS models,we found that IC enables additional, statis-tically significant improvements for pitch ac-cent assignment.
This performance also out-performs the TTS pitch accent model signif-icantly.
Overall, IC is not only effective, asshown in the results, but also relatively in-expensive to compute for a new domain.
Al-most all speech synthesis ystems, text-to-speech as well as concept-to-speech systems,can employ this feature as long as there isa large corpus.
In the future, we plan toexplore other information content measure-ments and incorporate them in a more com-prehensive accent model with more discourseand semantic features included.8 AcknowledgementThanks to Julia Hirschberg, Vasileios Hatzi-vassiloglou and James Shaw for commentsand suggestions on an earlier version of thispaper.
Thanks to Desmand Jordan for help-ing us with the collection of the speech andtext corpus.
This research is supportedin part by the National Science Founda-tion under Grant No.
IRI 9528998, theNational Library of Medicine under projectR01 LM06593-01 and the Columbia Univer-sity Center for Advanced Technology in HighPerformance Computing and Communica-tions in Healthcare (funded by the New YorkState Science and Technology Foundation).ReferencesMary Beckman and Julia Hirschberg.
1994.The ToBI annotation conventions.
Tech-nical report, Ohio State University,Columbus.Dwight Bolinger.
1972.
Accent is pre-dictable (if you're a mind-reader).
Lan-guage, 48:633-644.Joan Bresnan.
1971.
Sentence stressand syntactic transformations.
Language,47:257-280.Eric Brill.
1994.
Some advances in rule-based part of speech tagging.
In Proceed-ings of the 12th National Conference onArtificial Intelligence.Chris Buckley.
1985.
Implementation ofthe SMART information retreival system.Technical Report 85-686, Cornell Univer-sity.William Cohen.
1995.
Fast effective rule in-duction.
In Proceedings of the 12th In-ternational Conference on Machine Learn-ing.W.
J. Conover.
1980.
Practical Nonparam-etic Statistics.
Wiley, New York, 2nd edi-tion.Thomas M. Cover and Joy A. Thomas.
1991.Elements of Information Theory.
Wiley,New York.Robert M. Fano.
1961.
Transmission ofInformation: A Statistical Theory ofCommunications.
MIT Press, Cambridge,Massachusetts.Stephen E. Fienberg.
1983.
The Analysisof Cross-Classified Categorical Data.
MITPress, Cambridge, Mass, 2nd edition.Joseph L. Fleiss.
1981.
Statistical Methodsfor Rates and Proportions.
Wiley, NewYork, 2nd edition.G.
David Forney.
1973.
The Viterbi algo-rithm.
Proceedings of IEEE, 61(3).Julia Hirschberg.
1990.
Assigning pitch ac-cent in synthetic speech: The given/newdistinction and deaccentability.
In Pro-ceedings of the Seventh National Confer-ence of American Association of ArtificialIntelligence, pages 952-957, Boston.Julia Hirschberg.
1993.
Pitch accent in con-text: predicting intonational prominencefrom text.
Artificial Intelligence, 63:305-340.Julian Kupiec.
1992.
Robust part-of-speechtagging using a hidden markov model.156Computer Speech and Language, 6(3):225-242, July.D.
Robert Ladd.
1996.
Intonational Phonol-ogy.
Cambridge University Press, Cam-bridge.Claudia Leacock and Martin Chodorow.1998.
Combining local context and Word-Net similai:ity for word sense identifi-cation.
In Christiane Fellbaum, editor,WordNet: An electronic lexical database,chapter 11.
MIT Press.Julie Beth Lovins.
1968.
Development ofa stemming algorithm.
In MechanicalTranslation and Computational Linguis-tics, volume 11.Joseph.
P. Olive and Mark Y. Liberman.1985.
Text to Speech--An overview.Journal of lthe Acoustic Society of Amer-ica, 78(Fall~ :s6.Shimei Pan and Kathleen R. McKeown.1998.
Learning intonation rules for con-cept to speech generation.
In Proceedingsof COLING/A CL '98, Montreal, Canada.John R. Quinlan.
1993.
C4.5: Programs forMachine Learning.
Morgan Kaufmann,San Mateo.Lawrence R. Rabiner and B. H. Juang.
1986.An introduction to hidden Markov rood-els.
IEEE ASSP Magazine, pages 4-15,January.Lawrence R. Rabiner.
1989.
A tutorial onhidden Ma~:kov models and selected appli-cations in speech recognition.
Proceedingsof the IEEE, 77(2):257-286.Adwait Ratnaparkhi.
1996.
A maximum en-tropy part iof speech tagger.
In Eric Brilland Kenneth Church, editors, Conferenceon Empirical Natural Language Process-ing.
Univ.
of Pennsylvania.Philip Resnik.
1993.
Semantic classes andsyntactic ambiguity.
In Proc.
of ARPAWorkshop on Human Language Technol-ogy, pages 278-283.
Morgan KaufmannPublishers.Philip Resnik.
1995.
Using information con-tent to evaluate semant ic  similarity ina taxonomy.
In Proceedings of the 14thInternatioi~al Joint Conference on Artifi-cial Intelligence, pages 448-453, Montreal,Canada.Gerard Salton.
1989.
Automatic Text Pro-cessing: The Transformation, Analysis,and Retrieval of Information by Com-puter.
Addison-Wesley, Reading, Mas-sachusetts.Gerard Salton.
1991.
Developments in auto-matic text retrieval.
Science, 253:974-980,August.Jan P. H. Van Santen.
1992.
Contextual el-fects on vowel duration.
Speech Commu-nicatio n, 11:513-546, January.Claude E. Shannon.
1948.
A mathemati-cal theory of communication.
Bell SystemTechnical Journal, 27:379-423 and 623-656, July and October.Kim Silverman, Mary Beckman, JohnPitrelli, Mari Ostendorf, Colin Wightman,Patti Price, Janet Pierrehumbert, and Ju-lia Hirschberg.
1992.
ToBI: a standard forlabelling English prosody.
In Proceedingsof ICSLP92, volume 2.Kim Silverman.
1987.
The structure andprocessing of fundamental frequency con-tours.
Ph.D. thesis, Cambridge Univer-sity.Richard Sproat.
1994.
English noun-phrase accent prediction for Text-to-Speech.
Computer Speech and Language,8:79-94.Richard Sproat.
1997.
Multilingual Text-to-Speech Synthesis: The Bell Labs Ap-proach.
Kluwer, Boston.Andrew J. Viterbi.
1967.
Error boundfor convolutionM codes and an asymp-totically optimum decoding algorithm.IEEE Transactions in Information The-or'y, 13(2).157
