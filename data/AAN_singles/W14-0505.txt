Proc.
of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19?28,Gothenburg, Sweden, April 26 2014.c?2014 Association for Computational LinguisticsAn explicit statistical model of learning lexical segmentation usingmultiple cuesC?a?gr?
C?
?oltekinUniversity of Groningenc.coltekin@rug.nlJohn NerbonneUniversity of Groningenj.nerbonne@rug.nlAbstractThis paper presents an unsupervised andincremental model of learning segmenta-tion that combines multiple cues whoseuse by children and adults were attested byexperimental studies.
The cues we exploitin this study are predictability statistics ,phonotactics , lexical stress and partial lex-ical information .
The performance of themodel presented in this paper is competi-tive with the state-of-the-art segmentationmodels in the literature, while followingthe child language acquisition more faith-fully.
Besides the performance improve-ments over the similar models in the liter-ature, the cues are combined in an explicitmanner, allowing easier interpretation ofwhat the model learns.1 IntroductionSegmenting the continuous speech stream into lex-ical units is one of the challenges we face while lis-tening to other speakers.
For competent languageusers, probably the biggest aid in identifying theword boundaries is the knowledge of the words.Not surprisingly, the models of adult word recog-nition depend heavily on a lexicon (see Dahan andMagnuson, 2006, for a recent review).
The samecan be observed in speech and language technol-ogy where all automatic speech recognition sys-tems make use of a comprehensive lexicon.Even with a comprehensive lexicon and anerror-free representation of the acoustic input, theproblem is not trivial, since the input is often com-patible with multiple segmentations spanning thecomplete utterance.
The problem, however, iseven more difficult for a learner who starts withno lexicon.
Fortunately, the lexicon is not theonly aid for segmentation.
Experimental researchwithin last two decades has revealed an array ofcues that are used by adults and children for lexi-cal segmentation.
These cues include, but are notlimited to, lexical stress (Cutler and Butterfield,1992; Jusczyk, Houston, et al., 1999), phonotac-tics (Jusczyk, Cutler, et al., 1993), predictabilitystatistics (Saffran et al., 1996), allophonic differ-ences (Jusczyk, Hohne, et al., 1999), coarticula-tion (E. K. Johnson and Jusczyk, 2001), and vowelharmony (Suomi et al., 1997).
The relative utilityor dominance of these cues is a matter of currentdebate.
However, it seems uncontroversial thatnone of these cues solves the segmentation prob-lem alone and, when available, they are used inconjunction.Along with experimental research on segmen-tation, a large number of computational modelshave been proposed in the literature.
The earlystudies typically made use of connectionist mod-els (e.g., Elman, 1990; Christiansen et al., 1998).Of these studies, Christiansen et al.
(1998) is par-ticularly interesting for the present study since itincorporates most of the cues used in this study.Using a simple recurrent network (SRN, Elman,1990), Christiansen et al.
(1998) demonstrated theusefulness of lexical stress, predictability statistics(included implicitly in any SRN model), and utter-ance boundaries, and showed that combining thecues improves the performance.
The connection-ist models have been instrumental in investigatinga large number of cognitive phenomena.
However,they have also been subject to the criticism thatwhat a connectionist model learns is rather dif-ficult to interpret.
Furthermore, the performanceachieved using connectionist models is far lowerthan that is expected from humans.Models that use explicit representations in com-bination with statistical procedures (e.g., Brentand Cartwright, 1996; Brent, 1999; Venkatara-man, 2001; Goldwater et al., 2009; M. Johnsonand Goldwater, 2009) avoid both problems: thesemodels perform better, and it is easier to reasonabout what they learn.
Although these modelswere also instrumental in our understanding of theproblem, they lack at least two aspects of con-19nectionist models that fit human processing better.First, even though we know that human segmen-tation is incremental and predictive, most of thesemodels process their input either in a batch fash-ion, or they require the complete utterance to bepresented before attempting to segment the input.Second, it is generally difficult to incorporate ar-bitrary cues into most of these models.Models that use explicit representations withincremental models exist (e.g., Monaghan andChristiansen, 2010; Lignos, 2011), but are ratherrare.
Furthermore, the investigation of cues andcue combination in segmentation is also relativelyscarce within the recent studies (exceptions in-clude the investigation of various suprevised mod-els by Jarosz and J.
A. Johnson, 2013).The present paper introduces a strictly incre-mental, unsupervised method for learning seg-mentation where the learning method and internalrepresentations are explicitly defined.
Crucially,we use a set of cues demonstrated to be used byhumans in solving the segmentation problem.
Thesimulations results that we present are based onthe same child-directed speech input used by manyother studies in the literature.The rest of this article is organized as follows:in the next section, we present a method for com-bining cues.
Section 3 describes the cues used inthis study.
The simulations are described and re-sults are presented in Section 4.
A general discus-sion of the modeling framework and the simula-tion results are given in Section 5.2 A cue combination methodWe know that there is no single cue that alwaysgives the correct answer in the lexical segmenta-tion task.
We also know that humans combinemultiple cues when available.
In this section wedefine a method to segment a given utterance usingmultiple boundary indicators, or cues, and learnto segment better by estimating usefulness of eachindicator.
In essence, each indicator makes a de-cision on each potential boundary location.
Themethod combines these indicators?
decisions to ar-rive at a hopefully more accurate decision.
In ma-chine learning terms, we formulate a number ofbinary classifiers, and aim to get a better classi-fier using a combination of them.
This problemsis a relatively well-studied subject in the machinelearning literature (e.g., Bishop, 2006, chapter 14).Here a simple and well-known method, major-ity voting , will be used for combining multipleboundary indicators.Majority voting is a common (and arguably ef-fective) method in everyday social and politicallife.
As a result, it has been well studied, andknown to work well especially if each voter?s de-cision is better than random on average, and votesare cast independently.
In practice, even thoughthe votes are almost never independent, majorityvoting is still an effective way of combining mul-tiple classifiers (see Narasimhamurthy, 2005, for adiscussion of the effectiveness of the method).The majority voting combines each voteequally.
Even though this may be a virtue in thesocial and political context, it is a shortcoming fora computational procedure that incorporates infor-mation from multiple sources with varying useful-ness.
We will use a simple augmentation of ma-jority voting to model, weighted majority voting(Littlestone and Warmuth, 1994), that weighs theutility of the information provided by each source.In weighted majority voting, the voters thatmake fewer errors get higher weights.
In an un-supervised setting as ours, we do not know forcertain when a voter makes an mistake.
Instead,we take a voter?s decision to be correct if it agreeswith the majority.
Initially we set all the weightsto 1, trusting all the voters equally.
We adopt anincremental version of the algorithm, where wekeep the count of ?errors?
made by each voter i,ei, which is incremented every time the voter dis-agrees with the majority.
After every boundary de-cision, first, the error counts are updated for eachvoter.
Then, the weight, wi, of each voter is up-dated using,wi?
2(0.5?eiN)where N is the number of boundary decisionsmade so far, including the current one.This update rule sets the weight of a voter thatis half the time wrong (a voter that votes at ran-dom) to zero, eliminating the incompetent voters.If the votes of a voter are in accordance with theweighted majority decision almost all the time, theweight stays close to one.3 Cues and boundary indicatorsThe combination method above allows us to com-bine an arbitrary number of boundary indicators.In our setting, each psychologically motivated cueis represented by multiple boundary indicators that20differ based on the source of information used andthe way this information is turned into a quantita-tive measure.
This section introduces all of thesecues, and the boundary indicators that stem fromquantification of these cues in different ways.3.1 Predictability statisticsAt least as early as Harris (1955), it was knownthat a simple property of natural language utter-ances can aid identifying the lexical units thatform an utterance: predictability within the unitsis high, predictability between the units is low.However, until the influential study by Saffran,Aslin, and Newport (1996), the idea was not in-vestigated in developmental psycholinguistics as apossible source of information that children mayuse for segmentation.
After Saffran et al.
(1996)showed that 8-month-old infants make use of pre-dictability statistics to extract word-like units froman artificial language stream, a large number ofstudies confirmed that predictability based strate-gies are used by adults and children for learningdifferent aspects of language (e.g., Thiessen andSaffran, 2003; Newport and Aslin, 2004; GrafEstes et al., 2007; Thompson and Newport, 2007;Perruchet and Desaulty, 2008).To use in our cue combination system, we needto quantify the notion of predictability.
In thisstudy, we use two information theoretic measuresof predictability (or surprise), to define a set ofboundary indicators.
The first one, pointwise mu-tual information (MI) is defined asMI(l, r) = log2P(l, r)P(l)P(r)where l and r are strings of phonemes to the leftand right of the possible boundary location.
Wedefine our second measure, boundary entropy (H)of a potential boundary after string l asH(l) = ?
?r?AP(r|l) log2(P (r|l))where the sum ranges over all phonemes in the al-phabet, A.1The use of both the MI and the H is moti-vated by the finding that combination multiple pre-dictability measures result in better segmentation1The input to children is better represented by ?segments?or ?phones?.
However, since the data used in our simulationsdoes not contain any phonetic variation, in this paper, we usethe term phoneme when referring to the basic input unit.
(see C?
?oltekin, 2011, p.101, for an analysis).
Fur-thermore, for asymmetric measures, like entropy,H(l) is clearly not the same asH(r).
Motivated bythe finding that children use ?reverse predictabil-ity?
(Pelucchi et al., 2009), we also incorporate areverse entropy measure in the present study.In most studies in the literature, the context land r are single basic units (phonemes in our case).The different phoneme context sizes may captureregularities that exist because of different linguis-tic units.
The relation between the phoneme con-text size and the linguistic units, of course, is notclear-cut.
However, for example, we expect con-text size of one to capture the regularities betweenthe phonemes, while context size of two or threeto capture regularities between larger units, suchas syllables.The above parameters result in an array of in-dicators.
However, none of the indicators we usehave a natural threshold to decide whether a givenposition is a boundary or not.
To get a boundarydecision out of a single measure (MI or H), weadopt a method similar to a commonly used unsu-pervised method that decides for a boundary at the?peaks?
of unpredictability.
A particular shortcom-ing of this strategy, however, is that it can neverfind both boundaries of a single-phoneme word,as there cannot be two peaks one after another.
Toremedy this, the partial-peak strategy we employhere makes use of two sets of boundary indicatorsfor each potential boundary: one posits a bound-ary after an increase in H (or a decrease in MI)and the other posits a boundary before a decreasein H.3.2 Utterance boundariesAn attractive aspect of the predictability-basedsegmentation is that it does not require any lexicalknowledge in advance?unlike other cues noted inSection 1.
However, certain aspects of phonotac-tics, such as the regularities found at the beginningand end of words, can be induced from the bound-aries already marked in the input without the needfor a lexicon.
As a result, clearly marked lexicalunit boundaries may serve as another source of in-formation that can bootstrap the acquisition of lex-ical units.22There are a number of acoustic cues (e.g., pauses) thatare highly correlated with lexical unit boundaries.
However,we do not make use of them in this study since they are con-sidered to be unreliable, and they are not marked in the cor-pora at hand.21All models of segmentation in the literatureuse utterance boundaries implicitly by assumingthat the words cannot straddle utterance bound-aries.
The explicit use of utterance boundariesto discover regularities about words is commonin connectionist models (e.g., Aslin et al., 1996;Christiansen et al., 1998; Stoianov and Nerbonne,2000).
Similar use of utterance boundaries in non-connectionist models is rather rare.
Three excep-tions to this are the models described by Brent(1996), Fleck (2008) and Monaghan and Chris-tiansen (2010).
The method described in this sec-tion is similar to Fleck?s method, where the modelestimates the probability of observing a boundarygiven its left and right context, P(b|l, r), where brepresents boundary, and as before, l and r rep-resent left and right contexts, respectively.
If thisprobability is greater than 0.5, the model insertsa boundary.
Using utterance boundaries and thepauses, Fleck (2008) presents a batch algorithmwith a few ad hoc corrections that estimates theprobabilities P(b), P(l|b), P(r|b), P(l), P(r), anduses Bayesian inversion to estimate P(b|l, r).In this work, instead of P(b|l, r), we estimateprobabilities of utterance beginnings, P(ub|r),and probabilities of utterance ends, P(ub|l),where ub stands for utterance boundary.
Theseprobabilities can directly be estimated from theutterance edges in the input corpus, and can beused as cues for discovering non-initial or non-final boundaries.
Similar to the predictability, us-ing different length l and r we obtain a set of indi-cators for P(ub|r) and P(ub|l).Unlike P(b|l, r), for P(ub|r) and P(ub|l) wedo not have a straightforward threshold to makea boundary decision.
Instead, we appeal to thefamiliar solution, and use ?partial peaks?
in thesevalues as boundary indications.3.3 Lexical stressLexical stress is one of the cues for segmentationthat is well supported by psycholinguistic research(e.g., Cutler and Butterfield, 1992; Jusczyk, Hous-ton, et al., 1999; Jusczyk, 1999).
Lexical stressis used in many languages for marking the promi-nent syllable in a word.
For languages that exhibitlexical stress, the prominent syllable will typicallybe in a particular position in the word, allowingdiscovery of the boundaries based on the positionof stressed syllable.Despite the prominence of stress as a cue forsegmentation, there are relatively few computa-tional studies that investigate use of stress.
Chris-tiansen et al.
(1998) incorporates stress as a cuein their connectionist cue combination system.Swingley (2005) provides a careful analysis ofstress patterns of the bisyllabic words found bya discovery procedure on mutual information andfrequency.
Gambell and Yang (2006) present sur-prisingly good segmentation results with a rule-based learner whose main source of informationis lexical stress.
One of the major problems withthe these studies, which has also been carried overto the present study, is the lack of corpora with re-alistic stress assignment (see Section 4.1).Our stress-based strategy is similar to the strat-egy used for learning phonotactics described inSection 3.2.
Instead of collecting statistics aboutphoneme n-grams, we collect statistics over stressassignments on phoneme n-grams.
However, theprobabilities are estimated over already knownlexical units.
Given stress patterns l and r, we es-timate P(b|l) from endings of the known lexicalunits, and P(b|r) from the beginnings of the lexi-cal units.
Again we use these quantities as indica-tors for variable length l and r. Using the partial-peak boundary decision strategy in combinationwith the weighted majority voting algorithm, asbefore, we define a set of boundary indicators andoperationalize lexical stress as another cue for seg-mentation.3.4 LexiconFor adults, a comprehensive lexicon is probablythe most useful cue for segmentation.
We donot expect infants to have a lexicon at the begin-ning.
However, as they build their lexicon, or?proto-lexicon?, they may put it in use for discov-ering novel lexical units.
This is the main strat-egy behind the majority of state-of-the-art compu-tational models of segmentation (e.g., Brent, 1999;Venkataraman, 2001; Goldwater et al., 2009).
Themodels that guess boundaries rarely build and usean explicit lexicon (exceptions include Monaghanand Christiansen, 2010).In this study we also experiment with an (admit-tedly naive) set of lexical cues to word boundaries.The idea is to indicate a boundary when there areword-like strings on both sides of the boundarycandidate.
In our usual majority voting frame-work, these form two additional sets of boundaryindicators.
First, given a possible boundary loca-22tion, we simply count the frequencies of alreadyknown words beginning or ending at the positionin question.
The second indicator is based onthe number of times the phoneme sequences sur-rounding the boundary found at the beginnings orends of the previously discovered words.
The sec-ond indicator is essentially the same as the phono-tactics component discussed in Section 3.2, ex-cept that it is calculated using already known wordtypes instead of utterance boundaries.Similar to the other asymmetric indicators dis-cussed previously, we have two flavors for each in-dicator.
One indicating the existence of words tothe right of the boundary candidate (words begin-ning at the boundary), and the other indicating theexistence of words the left of the boundary can-didate (word ending at the boundary).
As with theother cues, these result in a set of indicators whoseprimary source of information is the potential lexi-cal units in the learner?s incomplete and noisy lex-icon.4 Experiments4.1 DataWe use a child-directed speech corpus from theCHILDES database (MacWhinney and Snow,1985).
It was collected by Bernstein Ratner (1987)and the original orthographic transcription of thecorpus was converted to a phonemic transcriptionby Brent and Cartwright (1996).
The same corpushas been used by many recent studies.
Followingthe convention in the literature the corpus will becalled the BR corpus .For the results reported for segmentation strate-gies that make use of lexical stress, the BR corpuswas marked for lexical stress semi-automaticallyfollowing the procedure described by Christiansenet al.
(1998) for annotating the Korman corpus(Korman, 1984).
The stress assignment is doneaccording to stress patterns in the MRC psycholin-guistic database.
All single-syllable words arecoded as having primary stress, and the words thatwere not found or did not have stress assignmentin the MRC database were annotated manually.4.2 Evaluation metricsTwo quantitative measures, precision (P), recall(R) and their harmonic mean F1-score (F-score, orF, for short), have become the standard evaluationmeasures for computational simulations.
Follow-ing recent studies in the literature we present pre-cision recall and F-scores for boundaries (BP, BR,BF), word tokens (WP, WR, WF) and word typesor lexicon (LP, LR, LF).
Besides precision andrecall, we also present two error measures, over-segmentation (Eo) and undersegmentation (Eu) er-rors, defined as Eo= FP/(FP + TN) and Eu=FN/(FN+TP), where TP, FP, TN and FN are truepositives, false positives, true negatives, and falsenegatives respectively.In plain words, Eois the number of the falseboundaries inserted by the model divided by thetotal number of word internal positions in thecorpus.
Similarly, Euis the ratio of boundariesmissed to the total number of boundaries.
Al-though these error measures are related to preci-sion and recall, they provide different, and some-times better, insights into the model?s behavior.4.3 Reference modelsIn this paper, we compare the results obtained bythe cue combination model with two baselines.The first baseline is a random model (RM) thatassigns boundaries with the probability of bound-aries in the input corpus.
The RM is more in-formed than a completely random classifier, but ithas been customary (since Brent and Cartwright,1996) in segmentation literature to set the bar alittle bit higher.
The second reference model is alexicon-building model similar to many state-of-the-art models.
The model described here, whichwe call LM, assigns probabilities to possible seg-mentations as described in Equations 1 and 2.P(s) =n?i=1P(wi) (1)P(w) ={(1?
?
)f(w) if w is known?
?mi=1P(ai) if w is unknown(2)where s is a sequence of phonemes (e.g., an ut-terance or a corpus), wiis the ithword in the se-quence, aiis the ithsound in the word, f(w) is therelative frequency of the wordw,m is the numberof known words, and 0 ?
?
?
1 is the only pa-rameter of the model.
In all experiments reportedin this paper, we will fix ?
at 0.5.For the incremental model defined here, a wordis ?known?, if it was used in a previous segmenta-tion.
The model accepts whole utterances as singlewords if the utterance does not contain any knownwords.23boundary word lexiconmodel P R F P R F P R FBrent (1999) 80.3 84.3 82.3 67.0 69.4 68.2 53.6 51.3 52.4Venkataraman (2001) 81.7 82.5 82.1 68.1 68.6 68.3 54.5 57.0 55.7Goldwater et al.
(2009) 90.3 80.8 85.2 75.2 69.6 72.3 63.5 55.2 59.1Blanchard et al.
(2010) 81.4 82.5 81.9 65.8 66.4 66.1 57.2 55.4 56.3RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3Table 1: Performance scores of the reference mod-els LM and RM in comparison with some of theearlier scores reported in the literature.
If therewere multiple models reported in a study, the re-sult with the highest lexicon F-score is presented.All scores are obtained on the BR corpus.Table 1 compares the performances of some re-cent models in the literature using the BR corpuswith the two reference models.
The LM performssimilar to the state-of-the-art models presented inthis table.
Hence, to aid comparison of the mod-els proposed in this study with the others in theliterature, we will (re)report the result of the twobaseline models in the rest of this paper.
Notethat the scores presented in Table 1 can be mis-leading since the batch models have an advantagedue to the way scores are calculated.
The scoresof the batch models are calculated at the end oftraining, while scores of the incremental modelsinclude initial (presumably bad) choices made be-fore enough exposure to the input.
For example,the LM achieves boundary, word and lexicon F-scores of 89%, 81% and 74% respectively, towardsthe end of the BR corpus.
These scores are higherthan all of the scores presented in Table 1 (see Ta-ble 4 for details the way these scores are calcu-lated).4.4 Experiments and resultsThis section reports results of a set of simulationsusing the modeling framework described so far.All experiments are run on the BR corpus.
Forall the results reported below, each cue is repre-sented by a set indicators as described in Section 3,multiple indicators for each phoneme n-gram oflength one and three are used for left (l) and right(r) contexts, for all measures that are calculatedover phoneme n-grams surrounding the potentialboundary.
The use of lexical information and lex-ical stress as standalone strategies are similar tothe ?lexicon-building?
strategy.
The learner insertscomplete utterances to the lexicon when the strat-egy cannot segment the utterance.
As the learnerstarts to learn (from the edges of the sequences inthe lexicon) what the edges of words look like, ituses this information to segment later utterancesin the input.3We first report the performance results of indi-vidual cues, namely, predictability (P), utteranceboundaries (U), lexical information (W) and lexi-cal stress (S) in Table 2.Using the predictability cue alone leads to asegmentation performance lower than but close tothe state-of-the-art reference model LM.
Althoughthese results are not directly comparable to theearlier studies in the literature, the performancescores presented in Table 2 are the best scores pre-sented to date for models using the predictabilitycue alone.
Graphs presented by Brent (1999) in-dicates about 50%?60% WP and WR and 20%?30% LP for his baseline model utilizing mutualinformation on the BR corpus.
Cohen et al.
(2007)report 76% BP, and 75% BR on George Orwell?s1984.
Christiansen et al.
(1998) report 37% WPand 40% WR with an SRN using phonotactics andutterance boundary cues on another child-directedspeech corpus (Korman, 1984).The model that learns from the utterance bound-aries seems to perform the best.
The results arecomparable, and in some cases better than the LM.Furthermore, the overall scores are also higherthan the scores reported by Fleck (2008), wherethe boundary, word and lexical F-scores were82.9%, 70.7% and 36.6%, respectively.Although it is somewhat behind both pre-dictability and utterance boundary cues, the lexicalinformation alone certainly performs better thanrandom.
The lower performance of this model incomparison to ?U?
suggests that, at least in this set-ting, phonotactics learned from word tokens foundat the utterance edges leads to a better perfor-mance compared to the phonotactics learned fromthe word types in the learner?s lexicon.The experiment that takes only the stress cueinto account yields the worst overall results.
Itseems, when the cue indicates a boundary, it isextremely precise.
However, it is also very con-servative.
This seems to be due to the fact thatthe model learns to segment at weak?strong tran-sitions, which is expected to be precise.
However,since majority of the stress transitions are strong?strong, this covers rather a small portion of theboundaries.3The source code of the application and the data used inthis study can be found at https://bitbucket.org/coltekin/seg/.24boundary word lexicon errormodel P R F P R F P R F EoEuP 69.6 92.5 79.5 56.9 70.2 62.9 36.7 49.8 42.3 15.3 7.5U 82.9 84.8 83.8 70.5 71.7 71.1 33.8 66.9 44.9 6.6 15.2W 77.5 71.3 74.3 60.6 57.2 58.9 18.3 47.7 26.4 7.8 28.7S 78.2 8.2 14.8 26.5 9.7 14.2 8.2 38.7 13.5 0.9 92.8RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 27.1 73.0LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 5.9 17.3Table 2: Results of simulations using individualcues: predictability (P), utterance boundaries (U),lexicon (W) and lexical stress (S).
The rows la-beled LM and RM are scores of reference modelsrepeated for ease of comparison.boundary word lexicon errormodel P R F P R F P R F EoEuPU 82.6 90.7 86.5 72.4 77.4 74.8 42.8 65.3 51.7 7.2 9.3PUW 83.7 91.2 87.3 74.1 78.8 76.4 43.9 67.7 53.3 6.7 8.8PUWS 92.8 75.7 83.4 78.3 68.1 72.9 26.8 62.7 37.5 2.2 24.3RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 27.1 73.0LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 5.9 17.3Table 3: Results of combination of strategiesbased on four cues: starting with predictabilityand utterance boundaries (PU), addition of lexi-con (PUW) and lexical stress (PUWS).
The rowslabeled LM and RM are scores of reference mod-els repeated for ease of comparison.Table 3 presents combination of predictabilityand utterance boundaries, followed by lexical in-formation and stress.
Here all indicators are com-bined in a flat, non-hierarchical manner.
The com-bination of predictability and utterance bound-aries results in higher F-scores, and it results inmore balanced under- and over-segmentation er-rors.
The addition of the lexical information pro-vide a small but consistent improvement.
How-ever, adding stress information seems to have anadverse effect.
Despite the increased boundaryand word precision, all other performance scoresgo down substantially when we add the stress cue.The scores in Table 3 are obtained over the com-plete corpus.
As noted in Section 4.3, these scoresdo not reflect the ?learned?
state of the models.Furthermore, we are interested in the progress of alearner as more input is provided.
To demonstrateboth, Eoand Eufor all combined models are plot-ted in Figure 1 for each 500 utterances.An interesting observation that can be madein these graphs is that the models without thestress cue make fewer undersegmentation errors,with the cost of slightly higher oversegmentation.However, the strategy that combines all cues keepsboundary word lexicon errormodel P R F P R F P R F EoEuPU 85.6 96.7 90.8 78.7 86.0 82.2 71.8 75.9 73.8 6.6 3.3PUW 83.3 97.2 89.7 75.6 84.5 79.8 69.8 75.5 72.5 7.9 2.8PUWS 92.5 89.3 90.9 84.2 82.2 83.2 70.9 77.6 74.1 2.9 10.7Table 4: The same results presented in Table 3, butmeasured for the last 290-utterances (last block inan incremental experiment with 500-utterance in-crements).oversegmentation errors low throughout the learn-ing process, and towards the end, it makes fewerundersegmentation errors as well.
This suggeststhat the model combining all cues, including thestress, may be doing better as it collects moreevidence.
To demonstrate this further, Table 4presents the same results presented in Table 3, cal-culated on the last block of an experiment whereperformance scores were calculated after every500 input utterances.
Besides demonstrating theincrease in performance scores when calculated atlater stages of learning, the differences betweentables 3 and 4 show clearly that despite the factthat it has a detrimental affect when scores are cal-culated over the complete corpus, the stress cuehas a positive effect at the end of the learning pro-cess.
This suggests that the combined model usingstress cue learns slower and makes more mistakesat the beginning.
However as evidence accumu-lates, it starts to be useful, and increases the over-all performance of the combined model.5 General discussionThis paper introduced an unsupervised and in-cremental model of segmentation that focuses oncombining multiple cues relevant to child lan-guage acquisition as attested by earlier studies inpsycholinguistics.
Unsupervised and incremen-tal models of segmentation that combine multiplecues are not new.
There have been many modelssharing these properties to some extent.
In partic-ular, the model presented in this paper has manysimilarities with an earlier connectionist modelof segmentation presented by Christiansen et al.(1998).
However, unlike connectionist models, themodel presented here uses accessible explicit rep-resentations, and an concrete learning procedure.Most recent models with explicit representa-tions and statistical learning procedures tend to bemodels that process their input in ?batch?.
Thesemodels typically perform better when measured atthe overall best performance level, and the insights250.00.20.40.60.8(a) Oversegmentation errors1000 uttrancesErrorrate1 2 3 4 5 6 7 8 9 10PUPUWPUWSLM0.00.20.40.60.8(b) Undersegmentation errors1000 uttrances1 2 3 4 5 6 7 8 9 10PUPUWPUWSLMFigure 1: Progression of (a) over- and (b) under-segmentation errors of the combined strategies.we get from these models are undeniably useful.However, these models typically provide explana-tions at Marr?s (1982) computational level .
Themodeling practice we follow is similar to thesemodels in many ways, and can provide explana-tions for the same type of questions.
However,it may also provide explanations at lower levels(e.g., Marr?s algorithmic level ).
This is not toclaim that children learn exactly the way the modellearns.
However, the type of models presented inthis paper follow human behavior more faithfully,and, at least in principle, more detailed predictionscan be tested on these models.
Naturally, rele-vance of the findings for human cognition will beincreased as we constrain our models further in ac-cordance with what we know about the cognitiveprocesses.The first contribution of this study is the de-scription of a modeling framework that followswhat we know about human segmentation processwith high fidelity while keeping the benefits of amodel with explicit representations and statisticallearning methods.Besides the performance scores that are com-petitive with the state-of-the-art models in the lit-erature, the simulations also provide some insightsregarding the cues commonly studied in the psy-cholinguistics literature.
Some of the findings con-firm the previous results.
Indeed, it seems thatcombining multiple cues help.
However, the prop-erties of the modeling framework presented in thispaper allows us to make some other interesting ob-servations, for example, the effect of stress cuepresented in Section 4.4.When we look at the overall effect of the stresscue throughout the complete simulations, it seemsstress degrades the performance.
However, if wetake a look at the models?
performances at the endof the learning, we see that effect of the stress cueis actually positive.
In other words, once ?boot-strapped?
by the other cues, stress becomes a use-ful cue.
Furthermore, the way the stress cue is use-ful for the model is also in line with the findings inthe literature where stress is commonly found tobe a dominant cue (Jusczyk, Cutler, et al., 1993;Thiessen and Saffran, 2003).
Given the findingshere that stress is rather a precise cue (despite itslow recall), it is understandable why it dominatesthe boundary decisions when available.The segmentation model presented in this pa-per demonstrates a way to achieve good segmenta-tion performance using more cognitively relevantand transparent strategies.
It is also instrumentalat investigating some of the interesting issues re-garding cue combination in segmentation, and it isa first step towards models that are more faithfulto the human segmentation process.
Among otherthings, we consider two important improvementsto the model described here for future work.
First,although the combination method used (weightedmajority voting) has been successful, other meth-ods such as Bayesian cue combination used formodeling other cognitive processes may be a bet-ter approach for segmentation as well.
The sec-ond improvement we plan is regarding the input.Even though we used a standard corpus as usedby many other studies in the literature, it is ide-alized (e.g., contains no phonetic variation), andpoor (e.g., lacking some cues that are available tochildren) at the same time.
Hence, as well as bet-ter input representations, using input with varia-tion and noise, and the use of different languagesare steps we would like to take in future studiestowards a better modeling of segmentation.26ReferencesRichard N. Aslin, Julide Z. Woodward, Nicholas P. LaMen-dola, and Thomas G. Bever (1996).
?Models of Word Seg-mentation in Fluent Maternal Speech to Infants?.
In: Sig-nal to Syntax: Bootstrapping From Speech to Grammar inEarly Acquisition.
Ed.
by James L. Morgan and KatherineDemuth.
Lawrence Erlbaum Associates.
Chap.
8, pp.
117?134.Nan Bernstein Ratner (1987).
?The phonology of parent-child speech?.
In: Children?s language.
Ed.
by K. Nel-son and A. van Kleeck.
Vol.
6.
Hillsdale, NJ: Erlbaum,pp.
159?174.Christopher M. Bishop (2006).
Pattern Recognition and Ma-chine Learning.
Springer.Daniel Blanchard, Jeffrey Heinz, and Roberta Golinkoff(2010).
?Modeling the contribution of phonotactic cues tothe problem of word segmentation?.
In: Journal of ChildLanguage 37.Special Issue 03, pp.
487?511.Michael R. Brent (1996).
?Advances in the computationalstudy of language acquisition?.
In: Cognition 61 (1-2),pp.
1?38.Michael R. Brent (1999).
?An Efficient, ProbabilisticallySound Algorithm for Segmentation and Word Discovery?.In: Machine Learning 34.1-3, pp.
71?105.Michael R. Brent and Timothy A. Cartwright (1996).
?Distri-butional regularity and phonotactic constraints are usefulfor segmentation?.
In: Cognition 61 (1-2), pp.
93?125.Morten H. Christiansen, Joseph Allen, and Mark S. Seiden-berg (1998).
?Learning to Segment Speech Using MultipleCues: A Connectionist Model?.
In: Language and Cogni-tive Processes 13.2, pp.
221?268.Paul Cohen, Niall Adams, and Brent Heeringa (2007).
?Vot-ing experts: An unsupervised algorithm for segmenting se-quences?.
In: Intelligent Data Analysis 11.6, pp.
607?625.C?a?gr?
C?
?oltekin (2011).
?Catching Words in a Stream ofSpeech: Computational simulations of segmenting tran-scribed child-directed speech?.
PhD thesis.
University ofGroningen.Anne Cutler and Sally Butterfield (1992).
?Rhythmic cues tospeech segmentation: Evidence from juncture mispercep-tion?.
In: Journal of Memory and Language 31.2, pp.
218?236.Delphine Dahan and James S. Magnuson (2006).
?SpokenWord Recognition?.
In: Handbook of Psycholinguistics.2nd.
Elsevier.
Chap.
8, pp.
249?283.Jeffrey L. Elman (1990).
?Finding Structure in Time?.
In:Cognitive Science 14, pp.
179?211.Margaret M. Fleck (2008).
?Lexicalized phonotactic wordsegmentation?.
In: Proceedings of the Annual Meeting ofthe Association of Computational Linguistics (ACL-08),pp.
130?138.Timothy Gambell and Charles Yang (2006).
Word segmenta-tion: Quick but not dirty.
Unpublished manuscript.Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson(2009).
?A Bayesian framework for word segmentation:Exploring the effects of context?.
In: Cognition 112 (1),pp.
21?54.Katharine Graf Estes, Julia L. Evans, Martha W. Alibali, andJenny R. Saffran (2007).
?Can Infants Map Meaning toNewly Segmented Words?
Statistical Segmentation andWord Learning?.
In: Psychological Science 18.3, pp.
254?260.Zellig S. Harris (1955).
?From Phoneme to Morpheme?.
In:Language 31.2, pp.
190?222.Gaja Jarosz and J. Alex Johnson (2013).
?The Richness ofDistributional Cues to Word Boundaries in Speech toYoung Children?.
In: Language Learning and Develop-ment 9.2, pp.
175?210.Elizabeth K. Johnson and Peter W. Jusczyk (2001).
?WordSegmentation by 8-Month-Olds: When Speech CuesCount More Than Statistics?.
In: Journal of Memory andLanguage 44.4, pp.
548?567.Mark Johnson and Sharon Goldwater (2009).
?Improvingnonparameteric Bayesian inference: experiments on unsu-pervised word segmentation with adaptor grammars?.
In:Proceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter of theAssociation for Computational Linguistics, pp.
317?325.Peter W. Jusczyk (1999).
?How infants begin to extractwords from speech?.
In: Trends in Cognitive Sciences 3.9,pp.
323?328.Peter W. Jusczyk, Anne Cutler, and Nancy J. Redanz (1993).?Infants?
preference for the predominant stress patterns ofEnglish words?.
In: Child Development 64.3, pp.
675?687.Peter W. Jusczyk, Elizabeth A. Hohne, and Angela Bauman(1999).
?Infants?
sensitivity to allophonic cues for wordsegmentation?.
In: Perception and Psychophysics 61.8,pp.
1465?1476.Peter W. Jusczyk, Derek M. Houston, and Mary New-some (1999).
?The Beginnings of Word Segmentation inEnglish-Learning Infants?.
In: Cognitive Psychology 39,pp.
159?207.Myron Korman (1984).
?Adaptive aspects of maternal vocal-izations in differing contexts at ten weeks?.
In: First Lan-guage 5, pp.
44?45.Constantine Lignos (2011).
?Modeling infant word segmen-tation?.
In: Proceedings of the Fifteenth Conference onComputational Natural Language Learning, pp.
29?38.Nick Littlestone and Manfred K. Warmuth (1994).
?TheWeighted Majority Algorithm?.
In: Information and Com-putation 108.2, pp.
212?261.Brian MacWhinney and Catherine Snow (1985).
?The childlanguage data exchange system?.
In: Journal of Child Lan-guage 12.2, pp.
271?269.David Marr (1982).
Vision: A Computational Investigationinto the Human Representation and Processing of VisualInformation.
New York: Freeman.Padraic Monaghan and Morten H. Christiansen (2010).
?Words in puddles of sound: modelling psycholinguisticeffects in speech segmentation?.
In: Journal of Child Lan-guage 37.Special Issue 03, pp.
545?564.Anand Narasimhamurthy (2005).
?Theoretical Bounds ofMajority Voting Performance for a Binary ClassificationProblem?.
In: IEEE Trans.
Pattern Anal.
Mach.
Intell.
27(12), pp.
1988?1995.Elissa L. Newport and Richard N. Aslin (2004).
?Learningat a distance: I.
Statistical learning of non-adjacent depen-dencies?.
In: Cognitive Psychology 48.2, pp.
127?162.Bruna Pelucchi, Jessica F. Hay, and Jenny R. Saffran (2009).
?Learning in reverse: Eight-month-old infants track back-ward transitional probabilities?.
In: Cognition 113.2,pp.
244?247.Pierre Perruchet and St?ephane Desaulty (2008).
?A rolefor backward transitional probabilities in word segmenta-tion??
In: Memory and Cognition 36.7, pp.
1299?1305.Jenny R. Saffran, Richard N. Aslin, and Elissa L. Newport(1996).
?Statistical learning by 8-month old infants?.
In:Science 274.5294, pp.
1926?1928.Ivelin Stoianov and John Nerbonne (2000).
?ExploringPhonotactics with Simple Recurrent Networks?.
In: Pro-ceedings of Computational Linguistics in the Netherlands1999.
Ed.
by Frank van Eynde, Ineke Schuurman, andNess Schelkens, pp.
51?67.Kari Suomi, James M. McQueen, and Anne Cutler (1997).
?Vowel Harmony and Speech Segmentation in Finnish?.In: Journal of Memory and Language 36.3, pp.
422?444.27Daniel Swingley (2005).
?Statistical clustering and the con-tents of the infant vocabulary?.
In: Cognitive Psychology50.1, pp.
86?132.Erik D. Thiessen and Jenny R. Saffran (2003).
?When CuesCollide: Use of Stress and Statistical Cues to Word Bound-aries by 7- to 9-Month-Old Infants,?
in: DevelopmentalPsychology 39.4, pp.
706?716.Susan P. Thompson and Elissa L. Newport (2007).
?Statisti-cal Learning of Syntax: The Role of Transitional Probabil-ity?.
In: Language Learning and Development 3.1, pp.
1?42.Anand Venkataraman (2001).
?A Statistical Model for WordDiscovery in Transcribed Speech?.
In: Computational Lin-guistics 27.3, pp.
351?372.28
