Proceedings of the 7th Workshop on Statistical Machine Translation, pages 362?368,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsDEPFIX: A System for Automatic Correction of Czech MT Outputs?Rudolf Rosa, David Marec?ek and Ondr?ej Dus?ekCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostranske?
na?me?st??
25, Prague{rosa,marecek,odusek}@ufal.mff.cuni.czAbstractWe present an improved version of DEPFIX(Marec?ek et al, 2011), a system for auto-matic rule-based post-processing of English-to-Czech MT outputs designed to increasetheir fluency.
We enhanced the rule set usedby the original DEPFIX system and measuredthe performance of the individual rules.We also modified the dependency parser ofMcDonald et al (2005) in two ways to adjustit for the parsing of MT outputs.
We show thatour system is able to improve the quality of thestate-of-the-art MT systems.1 IntroductionThe today?s outputs of Machine Translation (MT)often contain serious grammatical errors.
Thisis particularly apparent in statistical MT systems(SMT), which do not employ structural linguisticrules.
These systems have been dominating the areain the recent years (Callison-Burch et al, 2011).Such errors make the translated text less fluent andmay even lead to unintelligibility or misleadingstatements.
The problem is more evident in lan-guages with rich morphology, such as Czech, wheremorphological agreement is of a relatively high im-portance for the interpretation of syntactic relations.The DEPFIX system (Marec?ek et al, 2011) at-tempts to correct some of the frequent SMT sys-?This research has been supported by the European UnionSeventh Framework Programme (FP7) under grant agree-ment n?
247762 (Faust), and by the grants GAUK116310,GA201/09/H057 (Res-Informatica), and LH12093.tems?
errors in English-to-Czech translations.1 It an-alyzes the target sentence (the SMT output in Czechlanguage) using a morphological tagger and a de-pendency parser and attempts to correct it by apply-ing several rules which enforce consistency with theCzech grammar.
Most of the rules use the sourcesentence (the SMT input in English language) as asource of information about the sentence structure.The source sentence is also tagged and parsed, andword-to-word alignment with the target sentence isdetermined.In this paper, we present DEPFIX 2012, an im-proved version of the original DEPFIX 2011 system.It makes use of a new parser, described briefly inSection 3, which is adapted to handle the generallyungrammatical target sentences better.
We have alsoenhanced the set of grammar correction rules, forwhich we give a detailed description in Section 4.Section 5 gives an account of the experiments per-formed to evaluate the DEPFIX 2012 system andcompare it to DEPFIX 2011.
Section 6 then con-cludes the paper.2 Related WorkOur approach can be regarded as converse to themore common way of using an SMT system to auto-matically post-edit the output of a rule-based transla-tion system, as described e.g.
in (Simard et al, 2007)or (Lagarda et al, 2009).The DEPFIX system is implemented in the1Although we apply the DEPFIX system just to SMT systemsin this paper as it mainly targets the errors induced by this typeof MT systems, it can be applied to virtually any MT system(Marec?ek et al, 2011).362TectoMT/Treex NLP framework (Popel andZ?abokrtsky?, 2010),2 using the Morc?e tagger (Spous-tova?
et al, 2007) and the MST parser (McDonaldet al, 2005) trained on the CoNLL 2007 SharedTask English data (Nivre et al, 2007) to analyze thesource sentences.
The source and target sentencesare aligned using GIZA++ (Och and Ney, 2003).3 ParsingThe DEPFIX 2011 system used the MST parser (Mc-Donald et al, 2005) with an improved feature setfor Czech (Nova?k and Z?abokrtsky?, 2007) trained onthe Prague Dependency Treebank (PDT) 2.0 (Hajic?and others, 2006) to analyze the target sentences.DEPFIX 2012 uses a reimplementation of the MSTparser capable of utilizing parallel features from thesource side in the parsing of the target sentence.The source text is usually grammatical and there-fore is likely to be analyzed more reliably.
Thesource structure obtained in this way can then pro-vide hints for the target parser.
We use local featuresprojected through the GIZA++ word alignment ?
i.e.for each target word, we add features computed overits aligned source word, if there is one.To address the differences between the gold stan-dard training data and SMT outputs, we ?worsen?the treebank used to train the parser, i.e.
introduceerrors similar to those found in target sentences:The trees retain their correct structure, only the wordforms are modified to resemble SMT output.We have computed a ?part-of-speech tag er-ror model?
on parallel sentences from the PragueCzech-English Dependency Treebank (PCEDT) 2.0(Bojar et al, 2012), comparing the gold standardCzech translations to the output of an SMT system(Koehn et al, 2007) and estimating the MaximumLikelihood probabilities of errors for each part-of-speech tag.
We then applied this error model to theCzech PCEDT 2.0 sentences and used the resulting?worsened?
treebank to train the parser.4 RulesDEPFIX 2012 uses 20 hand-written rules, address-ing various frequent errors in MT output.
Eachrule takes an analyzed target sentence as its in-put, often together with its analyzed source sen-2http://ufal.mff.cuni.cz/treextence, and attempts to correct any errors found ?usually by changing morphosyntactic categories ofa word (such as number, gender, case, person anddependency label) and regenerating the correspond-ing word form if necessary, more rarely by deletingsuperfluous particles or auxiliary words or changingthe target dependency tree structure.
However, nei-ther word order problems nor bad lexical choices arecorrected.Many rules were already present in DEPFIX 2011.However, most were modified in DEPFIX 2012 toachieve better performance (denoted as modified),and new rules were added (new).
Rules not modifiedsince DEPFIX 2011 are denoted as reused.The order of rule application is important as thereare dependencies among the rules, e.g.
FixPrepo-sitionNounAgreement (enforcing noun-prepositioncongruency) depends on FixPrepositionalCase (fix-ing incorrectly tagged prepositional case).
The rulesare applied in the order listed in Table 2.4.1 Analysis Fixing RulesAnalysis fixing rules try to detect and rectify taggerand parser errors.
They do not change word formsand are therefore invisible on the output as such;however, rules of other types benefit from their cor-rections.FixPrepositionalCase (new)This rule corrects part-of-speech-tag errors inprepositional phrases.
It looks for all words that de-pend on a preposition and do not match its part-of-speech tag case.
It tries to find and assign a com-mon morphological case fitting for both the wordform and the preposition.
Infrequent preposition-case combinations are not considered.FixReflexiveTantum (new)If the word form ?se?
or ?si?
is classified as reflex-ive tantum particle by the parser, but does not be-long to an actual reflexive tantum verb (or a dever-bative noun or an adjective), its dependency label ischanged to a different value, based on the context.FixNounNumber (reused)If a noun is tagged as singular in target but as plu-ral in source, the tag is likely to be incorrect.
Thisrule tries to find a tag that would match both the363source number and the target word form, changingthe target case if necessary.FixPrepositionWithoutChildren (reused)A target preposition with no child nodes is clearlyan analysis error.
This rule tries to find children forchildless prepositions by projecting the children ofthe aligned source preposition to the target side.FixAuxVChildren (new)Since auxiliary verbs must not have child nodes,we rehang all their children to the governing fullverb.4.2 Agreement Fixing RulesThese rules relate to morphological agreement re-quired by Czech grammar, which they try to enforcein case it is violated.
Czech grammar requires agree-ment in morphological gender, number, case andperson where applicable.These rules typically use the source sentence onlyfor confirmation.FixRelativePronoun (new)The Czech word relative pronoun ?ktery??
is as-signed gender and number identical to the closestpreceding noun or pronoun, if the source analysisconfirms that it depends on this noun/pronoun.FixSubject (modified)The subject (if the subject dependency label isconfirmed by the source analysis) will have its caseset to nominative; the number is changed if this leadsto the word form staying unchanged.FixVerbAuxBeAgreement (modified)If an auxiliary verb is a child of an infinitive, theauxiliary verb receives the gender and number of thesubject, which is a child of the infinitive (see alsoFixAuxVChildren).FixSubjectPredicateAgreement (modified)An active verb form receives the number and per-son from its subject (whose relation to the verb mustbe confirmed by the source).FixSubjectPastParticipleAgreement (modified)A past participle verb form receives the numberand gender from its subject (confirmed by the sourceanalysis).FixPassiveAuxBeAgreement (modified)An auxiliary verb ?by?t?
(?to be?)
depending on apassive verb form receives its gender and number.FixPrepositionNounAgreement (modified)A noun or adjective depending on a prepositionreceives its case.
The dependency must be con-firmed in the source.FixNounAdjectiveAgreement (modified)An adjective (or an adjective-like pronoun or nu-meral) preceding its governing noun receives itsgender, number and case.4.3 Translation Fixing RulesThe following rules detect and correct structures of-ten mistranslated by SMT systems.
They usually de-pend heavily on the source sentence.FixBy (new)English preposition ?by?
is translated to Czech us-ing the instrumental case (if modifying a verb, e.g.
?built by David?
: ?postaveno Davidem?)
or using thegenitive case (if modifying a noun, e.g.
?songs byDavid?
: ?p??sne?
Davida?
).FixPresentContinuous (modified)If the source sentence is in a continuous tense (e.g.
?Ondr?ej isn?t experimenting.?
), the auxiliary verb ?tobe?
must not appear on the output, which is oftenthe case (e.g.
*?Ondr?ej nen??
experimentovat.?).
Thisrule deletes the auxiliary verb in target and transfersits morphological categories to the main verb (e.g.
?Ondr?ej neexperimentuje.?
).FixVerbByEnSubject (new)If the subject of the source sentence is a personalpronoun, its following morphological categeries arepropagated to the target predicate:?
person?
number (except for ?you?, which does not ex-hibit number)?
gender (only in case of ?he?
or ?she?, which ex-hibit the natural gender)FixOf (new)English preposition ?of?
modifying a noun istranslated to Czech using the genitive case (e.g.
?pic-tures of Rudolf?
: ?obra?zky Rudolfa?
).364FixAuxT (reused)Reflexive tantum particles ?se?
or ?si?
not belong-ing to any verb or adjective are deleted.
This situa-tion usually occurs when the meaning of the sourceverb/adjective is lost in translation and only the par-ticle is produced.4.4 Other RulesVocalizePrepos (reused)Prepositions ?k?, ?s?, ?v?, ?z?
are vocalized (i.e.changed to ?ke?, ?se?, ?ve?, ?ze?)
where neces-sary.
The vocalization rules in Czech are similar to?a?/?an?
distinction in English.FixFirstWordCapitalization (new)If the first word of source is capitalized and thefirst word of target is not, this rule capitalizes it.5 Experiments and ResultsFor parameter tuning, we used datasets from theWMT10 translation task and translations by ON-LINEB and CU-BOJAR systems.5.1 Manual EvaluationManual evaluation of both DEPFIX 2011 and DEP-FIX 2012 was performed on the WMT113 test settranslated by ONLINEB.
500 sentences were ran-domly selected and blind-evaluated by two indepen-dent annotators, who were presented with outputs ofONLINEB, DEPFIX 2011 and DEPFIX 2012.
(For246 sentences, at least one of the DEPFIX setupsmodified the ONLINEB translation.)
They providedus with a pairwise comparison of the three setups,with the possibility to mark the sentence as ?indef-inite?
if translations were of equal quality.
The re-sults are given in Table 1.In Table 2, we use the manual evaluation to mea-sure the performance of the individual rules in DEP-FIX 2012.
For each rule, we ran DEPFIX 2012 withthis rule disabled and compared the output to theoutput of the full DEPFIX 2012.
The number ofaffected sentences on the whole WMT11 test set,given as ?changed?, represents the impact of therule.
The number of affected sentences selected formanual evaluation is listed as ?evaluated?.
Finally,the annotators?
ratings of the ?evaluated?
sentences3http://www.statmt.org/wmt11A / BSetup 1 Setup 2Indefinitebetter betterSetup 1 better 55% 1% 11%Setup 2 better 1% 8% 4%Indefinite 3% 2% 15%Table 3: Inter-annotator agreement matrix for ONLINEB+ DEPFIX 2012 as Setup 1 and ONLINEB as Setup 2.
(suggesting whether the rule improved or worsenedthe translation, or whether the result was indefinite)were counted and divided by the number of anno-tators to get the average performance of each rule.Please note that the lower the ?evaluated?
number,the lower the confidence of the results.The inter-annotator agreement matrix for com-parison of ONLINEB + DEPFIX 2012 (denoted asSetup 1) with ONLINEB (Setup 2) is given in Ta-ble 3.
The results for the other two setup pairs weresimilar, with the average inter-annotator agreementbeing 77%.5.2 Automatic EvaluationWe also performed several experiments with auto-matic evaluation using the standard BLEU metric(Papineni et al, 2002).
As the effect of DEPFIX interms of BLEU is rather small, the results are not asconfident as the results of manual evaluation.4In Table 4, we compare the DEPFIX 2011 andDEPFIX 2012 systems and measure the contributionof parser adaptation (Section 3) and rule improve-ments (Section 4).
It can be seen that the com-bined effect of applying both system modificationsis greater than when they are applied alone.
The im-provement of DEPFIX 2012 over ONLINEB withoutDEPFIX is statistically significant at 95% confidencelevel.The effect of DEPFIX 2012 on the outputs of someof the best-scoring SMT systems in the WMT12Translation Task5 is shown in Table 5.
AlthoughDEPFIX 2012 was tuned only on ONLINEB and CU-BOJAR system outputs, it improves the BLEU scoreof all the best-scoring systems, which suggests that4As already noted by Marec?ek et al (2011), BLEU seemsnot to be very suitable for evaluation of DEPFIX.
See (Kos andBojar, 2009) for a detailed study of BLEU performance whenapplied to evaluation of MT systems with Czech as the targetlanguage.5http://www.statmt.org/wmt12365Setup 1 Setup 2DifferingAnnotatorSetup 1 Setup 2Indefinitesentences better betterONLINEBONLINEB 169A 58% 13% 29%+ DEPFIX 2011 B 47% 11% 42%ONLINEBONLINEB 234A 65% 14% 21%+ DEPFIX 2012 B 59% 11% 30%ONLINEB ONLINEB148A 54% 24% 22%+ DEPFIX 2012 + DEPFIX 2011 B 56% 22% 22%Table 1: Manual pairwise comparison on 500 sentences from WMT11 test set processed by ONLINEB, ONLINEB +DEPFIX 2011 and ONLINEB + DEPFIX 2012.
Evaluated by two independent annotators.SentencesRule changed evaluated impr.
% wors.
% indef.
%FixPrepositionalCase 34 5 3 60 2 40 0 0FixReflexiveTantum 1 0 ?
?
?
?
?
?FixNounNumber 80 11 5 45 5 45 1 9FixPrepositionWithoutChildren 16 6 3 50 3 50 0 0FixBy 75 13 10.5 81 1 8 1.5 12FixAuxVChildren 26 6 4.5 75 0 0 1.5 25FixRelativePronoun 56 8 6 75 2 25 0 0FixSubject 142 18 13.5 75 3 17 1.5 8FixVerbAuxBeAgreement 8 2 1 50 1 50 0 0FixPresentContinuous 30 7 5.5 79 1 14 0.5 7FixSubjectPredicateAgreement 87 10 5.5 55 1 10 3.5 35FixSubjectPastParticipleAgreement 396 63 46.5 74 9.5 15 7 11FixVerbByEnSubject 25 6 5 83 0 0 1 17FixPassiveAuxBeAgreement 43 8 6 75 0.5 6 1.5 19FixPrepositionNounAgreement 388 62 40 65 13 21 9 15FixOf 84 13 11.5 88 0 0 1.5 12FixNounAdjectiveAgreement 575 108 69.5 64 20 19 18.5 17FixAuxT 38 7 4 57 1 14 2 29VocalizePrepos 53 12 6 50 2.5 21 3.5 29FixFirstWordCapitalization 0 0 ?
?
?
?
?
?Table 2: Impact and accuracy of individual DEPFIX 2012 rules using manual evaluation on 500 sentences fromWMT11 test set translated by ONLINEB.
The number of changed sentences is counted on the whole WMT11 testset, i.e.
3003 sentences.
The numbers of improved, worsened and indefinite translations are averaged over the annota-tors.366DEPFIX setup BLEUwithout DEPFIX 19.37DEPFIX 2011 19.41DEPFIX 2011 + new parser 19.42DEPFIX 2011 + new rules 19.48DEPFIX 2012 19.56Table 4: Performance of ONLINEB and various DEPFIXsetups on the WMT11 test set.System BLEUONLINEB 16.25ONLINEB + DEPFIX 2012 16.31UEDIN 15.54UEDIN + DEPFIX 2012 15.75CU-BOJAR 15.41CU-BOJAR + DEPFIX 2012 15.45CU-TAMCH-BOJ 15.35CU-TAMCH-BOJ + DEPFIX 2012 15.39Table 5: Comparison of BLEU of baseline system outputand corrected system output on WMT12 test set.it is able to improve the quality of various SMTsystems when applied to their outputs.
(The im-provement on UEDIN is statistically significant at95% confidence level.)
We submitted the ONLINEB+ DEPFIX 2012 system to the WMT12 TranslationTask as CU-DEPFIX.6 ConclusionWe have presented two improvements to DEPFIX,a system of rule-based post-editing of English-to-Czech Machine Translation outputs proven by man-ual and automatic evaluation to improve the qual-ity of the translations produced by state-of-the-artSMT systems.
First, improvements in the existingrules and implementation of new ones, which can beregarded as an additive, evolutionary change.
Sec-ond, a modified dependency parser, adjusted to pars-ing of SMT outputs by training it on a parallel tree-bank with worsened word forms on the Czech side.We showed that both changes led to a better perfor-mance of the new DEPFIX 2012, both individuallyand combined.In future, we are planning to incorporate deeperanalysis, devising rules that would operate on thedeep-syntactic, or tectogrammatical, layer.
TheCzech and English tectogrammatical trees are moresimilar to each other, which should enable us to ex-ploit more information from the source sentences.We also hope to be able to perform more complexcorrections, such as changing the part of speech of aword when necessary.Following the success of our modified parser, wewould also like to modify the tagger in a similar way,since incorrect analyses produced by the tagger of-ten hinder the correct function of our rules, some-times leading to a rule worsening the translation in-stead of improving it.As observed e.g.
by Groves and Schmidtke (2009)for English-to-German and English-to-French trans-lations, SMT systems for other language pairs alsotend to produce reoccurring grammatical errors.
Webelieve that these could be easily detected and cor-rected in a rule-based way, using an approach similarto ours.ReferencesOndr?ej Bojar, Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?,Petr Sgall, Silvie Cinkova?, Eva Fuc??
?kova?, MarieMikulova?, Petr Pajas, Jan Popelka, Jir???
Semecky?,Jana S?indlerova?, Jan S?te?pa?nek, Josef Toman, Zden?kaUres?ova?, and Zdene?k Z?abokrtsky?.
2012.
Announc-ing Prague Czech-English Dependency Treebank 2.0.In Proceedings of LREC 2012, Istanbul, Turkey, May.ELRA, European Language Resources Association.In print.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Omar Zaidan.
2011.
Findings of the 2011 work-shop on statistical machine translation.
In Proceedingsof the Sixth Workshop on Statistical Machine Transla-tion, pages 22?64, Edinburgh, Scotland, July.
Associ-ation for Computational Linguistics.Declan Groves and Dag Schmidtke.
2009.
Identificationand analysis of post-editing patterns for MT.
Proceed-ings of MT Summit XII, pages 429?436.Jan Hajic?
et al 2006.
Prague Dependency Treebank 2.0.CD-ROM, Linguistic Data Consortium, LDC CatalogNo.
: LDC2006T0 1, Philadelphia.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In ACL2007, Proceedings of the 45th Annual Meeting of the367Association for Computational Linguistics CompanionVolume Proceedings of the Demo and Poster Sessions,pages 177?180, Prague, Czech Republic, June.
Asso-ciation for Computational Linguistics.Kamil Kos and Ondr?ej Bojar.
2009.
Evaluation of ma-chine translation metrics for czech as the target lan-guage.
The Prague Bulletin of Mathematical Linguis-tics, 92(-1):135?148.Antonio L. Lagarda, Vicent Alabau, Francisco Casacu-berta, Roberto Silva, and Enrique Diaz-de Liano.2009.
Statistical post-editing of a rule-based ma-chine translation system.
In Proceedings of HumanLanguage Technologies: The 2009 Annual Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics, Companion Vol-ume: Short Papers, pages 217?220.
Association forComputational Linguistics.David Marec?ek, Rudolf Rosa, Petra Galus?c?a?kova?, andOndr?ej Bojar.
2011.
Two-step translation with gram-matical post-processing.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages426?432.
Association for Computational Linguistics.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-projective dependency parsingusing spanning tree algorithms.
In HLT ?05: Proceed-ings of the conference on Human Language Technol-ogy and Empirical Methods in Natural Language Pro-cessing, pages 523?530, Vancouver, British Columbia,Canada.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The CoNLL 2007 shared task on de-pendency parsing.
In Proceedings of the CoNLL 2007Shared Task.
Joint Conf.
on Empirical Methods in Nat-ural Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), June.Va?clav Nova?k and Zdene?k Z?abokrtsky?.
2007.
Featureengineering in maximum spanning tree dependencyparser.
In Va?clav Matous?ek and Pavel Mautner, edi-tors, Lecture Notes in Artificial Intelligence, Proceed-ings of the 10th I nternational Conference on Text,Speech and Dialogue, Lecture Notes in Computer Sci-ence, pages 92?98, Pilsen, Czech Republic.
SpringerScience+Business Media Deutschland GmbH.Franz Josef Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In ACL 2002, Proceed-ings of the 40th Annual Meeting of the Association forComputational Linguistics, pages 311?318, Philadel-phia, Pennsylvania.Martin Popel and Zdene?k Z?abokrtsky?.
2010.
TectoMT:modular NLP framework.
In Proceedings of the 7thinternational conference on Advances in natural lan-guage processing, IceTAL?10, pages 293?304, Berlin,Heidelberg.
Springer-Verlag.Michel Simard, Cyril Goutte, and Pierre Isabelle.
2007.Statistical phrase-based post-editing.
In Human Lan-guage Technologies 2007: The Conference of theNorth American Chapter of the Association for Com-putational Linguistics; Proceedings of the Main Con-ference, pages 508?515, Rochester, New York, April.Association for Computational Linguistics.Drahom?
?ra Spoustova?, Jan Hajic?, Jan Votrubec, Pavel Kr-bec, and Pavel Kve?ton?.
2007.
The best of two worlds:Cooperation of statistical and rule-based taggers forczech.
In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing, ACL 2007,pages 67?74, Praha.368
