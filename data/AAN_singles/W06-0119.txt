Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 130?133,Sydney, July 2006. c?2006 Association for Computational LinguisticsBMM-based Chinese Word Segmentor with Word Support Model forthe SIGHAN Bakeoff 2006Jia-Lin TsaiTung Nan Institute of Technology, Department of Information ManagementTaipei 222, Taiwan, R.O.C.tsaijl@mail.tnit.edu.twAbstractThis paper describes a Chinese wordsegmentor (CWS) for the third Inter-national Chinese Language ProcessingBakeoff (SIGHAN Bakeoff 2006).
Weparticipate in the word segmentationtask at the Microsoft Research (MSR)closed testing track.
Our CWS is basedon backward maximum matching withword support model (WSM) and con-textual-based Chinese unknown wordidentification.
From the scored resultsand our experimental results, it showsWSM can improve our previous CWS,which was reported at the SIGHANBakeoff 2005, about 1% of F-measure.1 IntroductionA high-performance Chinese word segmentor(CWS) is a critical processing stage to producean intermediate result for later processes, suchas search engines, text mining, word spellchecking, text-to-speech and speech recognition,etc.
As per (Lin et al 1993; Tsai et al 2003; Tsai,2005), the bottleneck for developing a high-performance CWS is to comprise of high per-formance Chinese unknown word identification(UWI).
It is because Chinese is written withoutany separation between words and more than50% words of the Chinese texts in web corpusare out-of-vocabulary (Tsai et al 2003).
In ourreport for the SIGHAN Bakeoff 2005 (Tsai,2005), we have shown that a highly performanceof 99.1% F-measure can be achieved while aBMM-based CWS using a perfect system dic-tionary (Tsai, 2005).
A perfect system dictionarymeans all word types of the dictionary are ex-tracted from training and testing gold standardcorpus.Conventionally, there are four approaches todevelop a CWS: (1) Dictionary-based ap-proach (Cheng et al 1999), especial forwardand backward maximum matching (Wong  andChan, 1996); (2) Linguistic approach based onsyntax-semantic knowledge (Chen et al 2002);(3) Statistical approach based on statistical lan-guage model (SLM) (Sproat and Shih, 1990;Teahan et al 2000; Gao et al 2003); and (4)Hybrid approach trying to combine the bene-fits of dictionary-based, linguistic and statisticalapproaches (Tsai et al 2003; Ma and Chen,2003).
In practice, statistical approaches aremost widely used because their effective andreasonable performance.To develop UWI, there are three approaches:(1) Statistical approach, researchers use com-mon statistical features, such as maximum en-tropy (Chieu et al 2002), association strength,mutual information, ambiguous matching, andmulti-statistical features for unknown word de-tection and extraction; (2) Linguistic approach,three major types of linguistic rules (knowledge):morphology, syntax, and semantics, are used toidentify unknown words; and (3) Hybrid ap-proach, recently, one important trend of UWIfollows a hybrid approach so as to take advan-tage of both merits of statistical and linguisticapproaches.
Statistical approaches are simpleand efficient whereas linguistic approaches areeffective in identifying low frequency unknownwords (Chen et al 2002).To develop WSD, there are two major typesof word segmentation ambiguities while thereare no unknown word problems with them: (1)Overlap Ambiguity (OA).
Take string C1C2C3130comprised of three Chinese characters C1, C2and C3 as an example.
If its segmentation can beeither C1C2/C3 or C1/C2C3 depending on con-text meaning, the C1C2C3 is called an overlapambiguity string (OAS), such as ???
(a gen-eral)/?(use)?
and ??
(to get)/??
(for militaryuse)?
(the symbol ?/?
indicates a word bound-ary).
(2) Combination Ambiguity (CA).
Takestring C1C2 comprised of two Chinese charac-ters C1 and C2 as an example.
If its segmenta-tion can be either C1/C2 or C1C2 depending oncontext meaning, the C1C2 is called a combina-tion ambiguity string (CAS), such as ??(just)/?(can)?
and ???(ability).?
Besides the OAand CA problems, the other two types of wordsegmentation errors are caused by unknownword problems.
They are: (1) Lack of unknownword (LUW), it means segmentation error oc-curred by lack of an unknown word in the sys-tem dictionary, and (2) Error identified word(EIW), it means segmentation error occurred byan error identified unknown words.The goal of this paper is to report the ap-proach and experiment results of our backwardmaximum matching-based (BMM-based) CWSwith word support model (WSM) for theSIGHAN Bakeoff 2006.
In (Tsai, 2006), WSMhas been shown effectively to improve Chineseinput system.
In the third Bakeoff, our CWS ismainly addressed on improving its performanceof OA/CA disambiguation by WSM.
We showthat WSM is able to improve our BMM-basedCWS, which reported at the SIGHAN Bakeoff2005, about 1% of F-measure.The remainder of this paper is arranged asfollows.
In Section 2, we present the details ofour BMM-based CWS comprised of WSM.
InSection 3, we present the scored results of theCWS at the Microsoft Research closed track andgive our experiment results and analysis.
Finally,in Section 4, we give our conclusions and futureresearch directions.2 BMM-based CWS with WSMFrom our work (Tsai et al 2004), the Chineseword segmentation performance of BMM tech-nique is about 1% greater than that of forwardmaximum matching (FMM) technique.
Thus, weadopt BMM technique as base to develop ourCWS.
In this Bakeoff, we use context-basedChinese unknown word identification (CCUWI)(Tsai, 2005) to resolve unknown word problem.The CCUWI uses template matching techniqueto extract unknown words from sentences.
Thecontext template includes triple context template(TCT) and word context template (WCT).
Thedetails of the CCUWI can be found in (Tsai,2005).
In (Tsai, 2006), we propose a new lan-guage model named word support model (WSM)and shown it can effectively perform homo-phone selection and word-syllable segmentationto improve Chinese input system.
For this Bake-off, we use WSM to resolve OA/CA problems.The two steps of our BMM-based CWS withWSM are as below:Step 1.
Generate the BMM segmentation for thegiven Chinese sentence by system dictionary.Step 2.
Use WSM to resolve OA/CA problemsfor the BMM segmentation of Step 1.
Now,we give a brief description of how we useWSM to resolve OA/CA problem.
Firstly, wepre-collect OA/CA pattern-pairs (such as ??/??-????)
by compare each training goldsegmentation and its corresponding BMMsegmentation.
The pattern of OA/CA pattern-pairs can be a segmentation pattern, such as??/?,?
or just a word, such as ???.?
Sec-ondly, for a BMM segmentation of Step 1, ifone pattern matching (matching pattern) withat least one pattern of those pre-collectedOA/CA pattern-pairs (matching OA/CA pat-tern-pairs), CWS will compute the word sup-port degree for each pattern of the matchingOA/CA pattern-pair.
Finally, select out thepattern with maximum word support degree asits segmentation for the matching pattern.
Ifthe patterns of the matching OA/CA pattern-pair having the same word support degree,randomly select one to be its segmentation.The details of WSM can be found in (Tsai,2006).3 Scored Results and Our ExperimentsIn the SIGHAN Bakeoff 2006, there are fourtraining corpus for word segmentation (WS)task: AS (Academia Sinica) and CU (City Uni-versity of Hong Kong) are traditional Chinesecorpus; PU (Peking University) and MicrosoftResearch (MSR) are simplified Chinese corpus.And, for each corpus, there are closed and open131track.
In the Bakeoff 2006, we attend the Micro-soft Research closed (MSR_C) track.3.1 Scored Results and our ExperimentsTables 1a and 1b show the details of MSR train-ing and testing corpus for 2nd (2005) and 3rd(2006) bakeoff.
From Table 1a and 1b, it indi-cates that MSR track of 3rd bakeoff seems to bea more difficult WS task than that of 2nd bakeoff,since (1) the training size of 2nd bakeoff is twotimes as great as that of 3rd bakeoff; (2) in train-ing data, the word type number of 3rd bakeoff isless than that of 2nd bakeoff, and (3) in testingdata, the word type number of 3rd bakeoff isgreater than that of 2nd bakeoff.Training  TestingSentences 86,924  3,985Word types 88,119  12,924Words  2,368,391 109,002Character types 5,167  2,839Characters 4,050,469 184,356Table 1a.
Details of MSR_C corpus of 2nd bake-off.Training  TestingSentences 46,364  4356Word types 63,494  13,461Words  1,266,169 100,361Character types 4,767  3,103Characters 2,169879 172,601Table 1b.
Details of MSR_C corpus of 3rd bake-off.Table 2 shows the scored results of our CWSat the MSR_C track of this bakeoff.
In Table 2,the symbols a, b and c stand for the CWS with a,b and c system dictionary.
The system diction-ary ?a?
is the dictionary comprised of all wordtypes found in the MSR training corpus.
Thesystem dictionary ?b?
is the dictionary com-prised of ?a?
system dictionary and the wordtypes found in the testing corpus by CCUWIwith TCT knowledge.
The system dictionary ?c?is the dictionary comprised of ?a?
system dic-tionary and the word types found in the testingcorpus by CCUWI with TCT and WCT knowl-edge.
Table 3 is F-measure differences betweenthe BMM-based CWS system and it with WSMand CCUWI using ?a?, ?b?
and ?c?
system dic-tionary in the MSR_C track.From Tables 2 and 3, we conclude that ourCWS of 3rd bakeoff improve the CWS of 2ndbakeoff about 1.8% of F-measure.
Among the1.8% F-measure improvement, 1% is contrib-uted by WSM for resolving OA/CA problemsand the other 0.8% is contributed by CCUWI forresolving UWI problem.System R P F ROOV RIVa 0.949 0.897 0.922 0.022 0.982b 0.954  0.921  0.937  0.163  0.981c 0.950  0.930  0.940  0.272  0.974Table 2.
The scored results of our CWS in theMSR_C track (OOV is 0.034) for 3rd bakeoff.System  R P F Improvea1.BMM 0.949 0.897 0.922a2.BMM+WSM 0.958 0.907 0.932 0.010b1.BMM 0.946 0.911 0.928b2.BMM+WSM 0.954  0.921  0.937 0.009c1.BMM 0.938 0.920 0.929c2.BMM+WSM 0.950  0.930  0.940 0.011Table 3.
The F-measure improvement betweenthe BMM-based CWS and it with WSM in theMSR_C track (OOV is 0.034) using a, b, and csystem dictionary.3.2 Error AnalysisTable 4 shows the F-measure and ROOV differ-ences between each result of our CWS with a, band c system dictionaries.
From Table 4, it indi-cates that the most contribution for increasingthe overall performance (F-measure) of ourCWS is occurred while our CWS comprised ofWSM and CCUWI with TCT knowledge.System F F(d) ROOV ROOV(d)a 0.922  - 0.022  -b 0.937 0.015 0.163 0.141c 0.940  0.003 0.272  0.109Table 4.
The differences of F-measure andROOV between near-by steps of our CWS.OA              CA               LUW              EIWa      667(389)     403(194)      3268(2545)    0(0)c      160(147)     231(150)      2310(1887)    805(605)Table 5.
The number of OAS (types), CAS(types), LUW (types) and EIW (types) for ourCWS.132Table 5 shows the distributions of four seg-mentation error types (OA, CA, LUW and EIW)for each result of our CWS with a and c systemdictionaries.
From Table 5, it shows CCUWIwith the knowledge of TCT and WCT can beused to optimize the LUW-EIW tradeoff.
More-over, it shows that WSM can effectively to re-duce the number of OA/CA segmentation errorsfrom 1,070 to 391.4 Conclusions and Future DirectionsIn this paper, we have applied a BMM-basedCWS comprised of a context-based UWI andword support model to the Chinese word seg-mentation.
While we repeat the CWS with theMSR_C track data of 2nd bakeoff, we obtained96.3% F-measure, which is 0.8% greater thanthat (95.5%) of our CWS at 2nd bakeoff.
To sumup the results of this study, we have followingconclusions and future directions:(1) UWI and OA/CA problems could be in-dependent tasks for developing a CWS.The experiment results of this study supportthis observation.
It is because we found 1%improvement is stable contributed by WSMand the other 0.8% improvement is stablecontributed by the CCUWI while the BMM-based CWS with difference a, b and c sys-tem dictionaries and different MSR_C train-ing and testing data of  2nd and 3rd bakeoff.
(2) About 89% of segmentation errors of ourCWS caused by unknown word problem.
Inthe 89%, we found 66% is LUW problemand 23% is EIW problem.
This result indi-cates that the major target to improve ourCWS is CCUWI.
The result also supportsthat a high performance CWS is relied on ahigh performance Chinese UWI (Tsai, 2005).
(3) We will continue to expand our CWS withother unknown word identification tech-niques, especially applying n-gram extractorwith the TCT and WCT template matchingtechnique to improve our CCUWI for at-tending the fourth SIGHAN Bakeoff.ReferencesChen, Keh-Jiann and Wei-Yun, Ma.
2002.
UnknownWord Extraction for Chinese Documents, Pro-ceedings of 19th COLING 2002, Taipei, 169-175.Cheng, Kowk-Shing, Gilbert H. Yong and Kam-FaiWong.. 1999.
A study on word-based and in-tegral-bit Chinese text compression algorithms.JASIS, 50(3): 218-228.Chieu, H.L.
and H.T.
Ng.
2002.
Named Entity Rec-ognition: A Maximum Entropy Approach Us-ing Global Information.
Proceedings of 19thCOLING 2002, Taipei, 190-196.Gao, Jianfeng, Mu Li and Chang-Ning uang.
2003.Improved Source-Channel Models for ChineseWord Segmentation.
Proceedings of the 41stAnnual Meeting of the Association for Compu-tational Linguistics, 272-279.Lin, Ming-Yu, Tung-Hui Chiang and Keh-Yi Su.1993.
A preliminary study on unknown wordproblem in Chinese word segmentation.ROCLING 6, 119-141.Ma, Wei-Yun and Keh-Jiann Chen, 2003, "Introduc-tion to CKIP Chinese Word SegmentationSystem for the First International ChineseWord Segmentation Bakeoff", Proceedings ofACL, Second SIGHAN Workshop on ChineseLanguage Processing, pp168-171.Sproat, R. and C., Shih.
1990.
A Statistical Methodfor Finding Word Boundaries in Chinese Text.Computer proceeding of Chinese and OrientalLanguage, 4(4):336 349.Teahan, W. J., Yingying Wen, Rodger McNad andIan Witten.
2000.
A compression-based algo-rithm for Chinese word segmentation.
Compu-tational Linguistics, 26(3): 375-393.Tsai, Jia-Lin, C.L., Sung and W.L., Hsu.
2003.
Chi-nese Word Auto-Confirmation Agent, Pro-ceedings of ROCLING XV, Taiwan, 175-192.Tsai, Jia-Lin, G., Hsieh and W.L., Hsu.
2004.
Auto-Generation of NVEF knowledge in Chinese,Computational Linguistics and Chinese Lan-guage Processing, 9(1):41-64.Tsai, Jia-Lin.
2005.
A Study of Applying BTMModel on the Chinese Chunk Bracketing.
Pro-ceedings of IJCNLP, 6th International Work-shop on Linguistically Interpreted Corpora,Jeju Island.Tsai, Jia-Lin.
2006.
Using Word Support Model toImprove Chinese Input System.
Proceedingsof ACL/COLING 2006, Sydney.Wong, Pak-Kwong and Chorkin ChanWong.
1996.Chinese Word Segmentation.
based on Maxi-mum Matching and Word Binding Force.
Pro-ceedings of the 16th International conferenceon Computational linguistic, 1:200-203.133
