An evolutionary approach for improving the quality of automatic summariesConstantin Ora?sanResearch Group in Computational LinguisticsSchool of Humanities, Languages and Social SciencesUniversity of WolverhamptonC.Orasan@wlv.ac.ukAbstractAutomatic text extraction techniqueshave proved robust, but very often theirsummaries are not coherent.
In thispaper, we propose a new extractionmethod which uses local coherence as ameans to improve the overall quality ofautomatic summaries.
Two algorithmsfor sentence selection are proposedand evaluated on scientific documents.Evaluation showed that the methodameliorates the quality of summaries,noticeable improvements being obtainedfor longer summaries produced by analgorithm which selects sentences usingan evolutionary algorithm.1 IntroductionIt is generally accepted that there are two mainapproaches for producing automatic summaries.The first one is called extract and rearrange becauseit extracts the most important sentences from a textand tries to arrange them in a coherent way.
Thesemethods were introduced in the late 50s (Luhn,1958) and similar methods are still widely used.The second approach attempts to understand thetext and, then, generates its abstract, for this reasonit is referred to as understand and generate.
Thebest-known method that uses such an approach isdescribed in (DeJong, 1982).
Given that the methodswhich ?understand?
a text are domain dependent,whenever robust methods are required, extractionmethods are preferred.Even though the extraction methods currentlyused are more advanced than the one proposed in(Luhn, 1958), many still produce summaries whichare not very coherent, making their reading difficult.This paper presents a novel summarisation approachwhich tries to improve the quality of the producedsummaries by ameliorating their local cohesion.This paper is structured as follows: In Section2 we present our hypothesis: it is possibleto produce better summaries by enforcing thecontinuity principle (see next section for a definitionof this principle) .
A corpus of scientific abstractsis analysed in Section 3 to learn whether thisprinciple holds in human produced summaries.In Section 4, we present two algorithms whichcombine traditional techniques with informationprovided by the continuity principle.
Severalcriteria are used to evaluate these algorithms onscientific articles in Section 5.
We finish withconcluding remarks, which also indicate possiblefuture research avenues.2 How to ensure local cohesionIn the previous section we already mentionedthat we are trying to improve the automaticsummaries by using the continuity principle definedin Centering Theory (CT) (Grosz et al, 1995).
Thisprinciple, requires that two consecutive utteranceshave at least one entity in common.
Even thoughit sounds very simple, this principle is important forthe rest of the principles defined in the CT becauseif it does not hold, none of the other principlescan be satisfied.
Given that only the continuityprinciple will be used in this paper and due to spacelimits, the rest of these principles are not discussedhere.
Their description can be found in (Kibble andPower, 2000).
For the same reason we will not gointo details about the CT.In this paper, we take an approach similar to(Karamanis and Manurung, 2002) and try to producesummaries which do not violate the continuityprinciple.
In this way, we hope to producesummaries which contain sequences of sentencesthat refer the same entity, and therefore will be morecoherent.
Before we can test if the principle issatisfied, it is necessary to define certain parameterson which the principle relies.
As aforementioned,the principle is tested on pairs of consecutiveutterances.
In general utterances are clauses orsentences.
Given that the automatic identification ofclauses is not very accurate, we consider sentencesas utterances.
An advantage of using sentences isthat most summarisation methods extract sentences,which makes it easier to integrate them with ourmethod.In this paper, we consider that two utteranceshave an entity in common if the same head nounphrase appears in both utterances.
In order todetermine the head of noun phrases we use the FDGtagger (Tapanainen and Ja?rvinen, 1997) which alsoprovides partial dependency relations between theconstituents of a sentence.
At this stage we do notemploy any other method to determine whether twonoun phrases are semantically related.3 Corpus investigationBefore we implemented our method, we wantedto learn if the continuity principle holds in humanproduced summaries.
In order to perform thisanalysis we investigated a corpus of 146 humanproduced abstracts from the Journal of ArtificialIntelligence Research (JAIR).
1Most of the processing was done automaticallyusing a simple script which tests if the principleis satisfied by pairs of consecutive utterances (i.e.if the pair has at least one head noun phrase incommon).
Those pairs which violate the principlewere manually analysed.In our corpus almost 75% of the pairs of1The full articles and their abstracts are freely available athttp://www.jair.orgconsecutive utterances (614 out of 835) satisfy theprinciple.
In terms of summaries, it was noticedthat 44 out of 146 do not have any such pairs whichviolate the principle.After analysing the violations, we can explainthem in one of the following ways:?
In 126 out of 221 cases (57%) the link betweenutterances is realised by devices such as rhetoricalrelations.?
In 76 cases (34%) the continuity principle wasrealised, but was not identified by the script becauseof words were replaced by semantic equivalents.
Inonly 17 of these cases pronouns were used.?
Ramifications in the discourse structure violatethe principle in 19 cases (9%).
These ramificationsare usually explicitly marked by phrases such asfirstly, secondly.After investigating our corpus we can definitelysay that the continuity principle is present inhuman produced abstracts, and therefore by tryingto enforce it in automatic summaries, we mightproduce better summaries.
However, by usingsuch approach we cannot be sure that the producedsummaries are coherent, being known that it ispossible to produce cohesive texts, but which areincoherent.
In Section 4 we present a method whichuses the continuity principle to score the sentences.This method is then evaluated in Section 5.We also have to emphasise that we do notclaim that humans consciously apply the continuityprinciple when they produce summaries or any othertexts.
The presence of the violations identified in ourcorpus is an indication for this.4 The methodKaramanis and Manurung (2002) used thecontinuity principle in text generation to choosethe most coherent text from several produced bytheir generation system.
In their case, the candidatetexts were sequences of facts, their best orderingwas determined by an evolutionary algorithm whichtried to minimise the number of violations of thecontinuity principle they contained.We take a similar approach in our attempt toproduce coherent summaries, trying to minimise thenumber of violations of the principle they contain.However, our situation is more difficult becausea summarisation program needs firstly to identifythe important information in the document andthen present it in a coherent way, whereas in textgeneration the information to be presented is alreadyknown.
?Understand and generate?
methods wouldbe appropriate, but they can only be applied torestricted domains.
Instead, we employ a methodwhich scores a sentence not only using its content,but also considering the context in which thesentence would appear in a summary.
Two differentalgorithms are proposed.
Both algorithms use thesame content-based scoring method (see Section4.1), but they use different approaches to extractsentences.
As a result, the way the context-basedscoring method defined in Section 4.2 is applieddiffers.
The first algorithm is a greedy algorithmwhich does not always produce the best summary,but it is simple and fast.
The second algorithmemploys an evolutionary technique to determine thebest set of sentences to be extracted.We should point out that another differencebetween our method and the ones used in textgeneration is that we do not intend to change theorder of the extracted sentences.
Such an additionwould be interesting, but preliminary experimentsdid not lead to any promising results.4.1 Content-based scoring methodWe rely on several existing scoring methods todetermine the importance of a sentence on the basisof its content.
In this section we briefly describe howthis score is computed.
The heuristics employed tocompute the score are:Keyword method: uses the TF-IDF scores of wordsto compute the importance of sentences.
The scoreof a sentence is the sum of words?
scores from thatsentence (Zechner, 1996)Indicator phrase method: Paice (1981) noticedthat in scientific papers it is possible to identifyphrases such as in this paper, we present,in conclusion, which are usually meta-discoursemarkers.
A list of such phrases has been built andall the sentences which contain an indicating phrasehave their scores boosted or penalised depending onthe phrase.Location method: In scientific papers importantsentences tend to appear at the beginning and end ofthe document.
For this reason sentences in the firstand the last 13 paragraphs have their scores boosted.This value was determined through experiments.Title and headers method: Words in the titleand headers are usually important, so sentencescontaining these words have their scores boosted.Special formatting rules: Quite often certainimportant or unimportant information is marked intexts in a special way.
In scientific paper it iscommon to find equations, but they rarely appear inthe abstracts.
For this reason sentences that containequations are excluded.The score of a sentence is a weighted functionof these parameters, the weights being establishedthrough experiments.
As already remarked by otherresearchers, one of the most important heuristicsproved to be the indicating phrase method.4.2 Context-based scoring methodDepending on the context in which a sentenceappears in a summary, its score can be boostedor penalised.
If the sentence which is consideredsatisfies the continuity principle with either thesentence that precedes or follows it in the summaryto be produced, its score is boosted.2 Ifthe continuity principle is violated the score ispenalised.
After experimenting with different valueswe decided to boost the sentence?s score with theTF-IDF scores of the common NPs?
heads andpenalise with the highest TF-IDF score in thedocument.While analysing our corpus we noticed that largenumber of violations of the continuity principle aredue to utterances in different segments.
Usually thisis explicitly marked by a phrase.
We extracted a listof such phrases from our corpus and decided not topenalise those sentences which violate the continuityprinciple, but contain one of these phrases.4.3 The greedy algorithmThe first of the two sentence selection algorithms is agreedy algorithm which always extracts the highestscored sentence from those not extracted yet.
Thesentences?
scores are computed in the way described2The way the sentences which precedes and follows it isdetermined depends very much on the algorithm used (seeSections 4.3 and 4.4 for details).
If the sentence is the first orthe last in a summary (i.e.
there is no preceding or followingsentence) the score is not changed.Given an extract ,,...,and S the sentence which is considered forextraction1.
Findandfffiffiflfrom the extract which are the closest sentences before and after S in thedocument, respectively.2.
Adjust the score S considering the context  ,  , fiffifl .Figure 1: The way the weights of a sentence are adjusted by the greedy algorithmin Section 4.2.
Given that the original order ofsentences is maintained in the summary, whenever asentence is considered for extraction, the algorithmpresented in Figure 1 is used.
We should emphasisethat at this stage the sentence is not extracted, butits score is computed as if it is included in theextract.
After this process is completed for all thesentences which are not present in the extract, theone with the highest score is extracted.
The processis repeated until the required length of the summaryis reached.
As it can be noticed, the algorithmcannot be applied to the first sentence.
For thisreason the first extracted sentence is always the onewith the highest content-based score.It should be noted that it is possible to extract asentence  "!
which satisfies the continuity principlewith its preceding sentence  $# , but in a later iterationto extract another sentence, which is between thesetwo, and which satisfies the continuity principlewith  %# , but not with  "!
.
Unfortunately, given thenature of the algorithm, it is impossible to go backand replace  "!
with another sentence, and thereforesometimes the algorithm does not find the best set ofsentences.
In order to alleviate this problem, in thenext section we present an algorithm which selectssentences using an evolutionary algorithm.4.4 The evolutionary algorithmThe greedy algorithm presented in the previoussection selects sentences in an interactive manner,the inclusion of a sentence in the summarydepending on the sentences which were includedbefore.
As a result it is possible that the bestsummary is not produced.
In order to alleviatethis problem an algorithm which uses evolutionarytechniques to select the set of sentences is proposed.Evolutionary algorithms are advanced searchingalgorithms which use techniques inspired by thenature to find the solution of a problem.
Aspecific type of evolutionary algorithms are genetic10 14 18 66 793 5 8Figure 2: A chromosome representing a summarywhich contains the sentences 3, 5, 8, 10, 14, 18, 66,79 from the documentalgorithms (Holland, 1975) which encode theproblem as a series of genes, called chromosome.The most common way to encode genes is the binaryencoding, where each gene can take the values 0or 1.
If we have decided to use such an encodingthe value 0 would have meant not to include thesentence in the summary, whereas 1 to include it.For our problem the length of a chromosome wouldhave been equal to the number of sentences in thetexts.
For long texts, such as the ones we use, thiswould have meant very long chromosomes, and as aresult slow convergence, without any certainty thatthe best solution is found (Holland, 1975).Instead of using binary encoding, we decidedthat our genes take integer values, each valuerepresenting the position of a sentence from theoriginal document to be included in the summary.The length of the chromosome is the desired lengthof the summary.
Caution needs to be taken whenevera new chromosome is produced so the values ofthe genes are distinct (i.e.
the summary containsdistinct sentences).
If a duplication is found in achromosome, then the gene?s value which containsthe duplication is incremented by one.
In thisway the chromosome will contain two consecutivesentences, and therefore it could be more coherent.A chromosome is presented in Figure 2.Genetic algorithms use a fitness function to assesshow good a chromosome is.
In our case the fitnessfunction is the sum of the scores of the sentencesindicated in the chromosome.
The sentences?scores are not considered ?in isolation?, they areadjusted in the way described in Section 4.2.
Forthis algorithm, determining the preceding and thefollowing sentence is trivial, all the informationbeing encoded in the chromosome.Genetic algorithms use genetic operators toevolve a population of chromosomes (Holland,1975).
In our case, we used weighed roulette wheelselection to select chromosomes.
Once severalchromosomes are selected they are evolved usingcrossover and mutation.
We used the classicalsingle point crossover operator and two mutationoperators.
The first one replaces the value of agene with a randomly generated integer value.
Thepurpose of this operator is to try to include randomsentences in the summary and in this way to help theevolutionary process.
The second mutation operatorreplaces the values of a gene with the value of thepreceding gene incremented by one.
This operatorintroduces consecutive sentences in the summary,which could improve coherence.The genetic algorithm starts with a populationof randomly generated chromosomes which is thenevolved using the operators.
Each of the operatorshas a certain probability of being applied.
Thebest chromosome (i.e.
the one with the highestfitness score) produced during all generations isthe solution to our problem.
In our case weiterated a population of 500 chromosomes for 100generations.
Given that the search space (i.e.
theset of sentences from the document) is very largewe noticed that at least 50 generations are necessaryuntil the best solution is achieved.
The algorithm isevaluated in the next section.5 Evaluation and discussionWe evaluated our methods on 10 scientific papersfrom the Journal of Artificial Intelligence Research,totalising almost 90,000 words.
The number of textsused for evaluation might seem small, but giventhat from each text we produced eight differentsummaries which had to be read and assessedby humans, the evaluation process was very timeconsuming.Throughout the paper we have mentioned theterm quality of a summary several times withoutdefining it.
In this paper the quality of asummary is measured in terms of coherence,cohesion and informativeness.
The coherence andcohesion were quantified through direct evaluationusing a methodology similar to the one proposedin (Minel et al, 1997).
The cohesion of asummary is indicated by the number of danglinganaphoric expressions,3 whereas the coherenceby the number of ruptures in the discourse.For informativeness we computed the similaritybetween the automatic summary and the documentas proposed in (Donaway et al, 2000).
Given thatthe methods discussed in this paper try to enforcelocal coherence they directly influence only thenumber of discourse ruptures, the changes of theother two measures are a secondary effect.In our evaluation, we compared the two newalgorithms with a baseline method and the content-based method.
The baseline, referred to as TF-IDF, extracts the sentences with the highest TF-IDF scores.
The comparison with the baseline doesnot tell us if by adding the context informationdescribed in Section 4.2 the quality of a summaryimproves.
In order to learn this, we compared thenew algorithms with the one presented in Section4.1.
They all use the same content-based scoringmethod, so if differences were noticed, they weredue to the context information added and the waysentences are extracted.The results of the evaluation are presented inTables 1, 2 and 3.
In these tables TF-IDF representsthe baseline, Basic method is the method describedin section 4.1, whereas Greedy and Evolutionaryare the two algorithms which use the continuityprinciple.
In Table 1, the row Maximum indicatesthe maximum number of ruptures which could befound in that summary.
This number is given by thetotal number of sentences in the summary.Given that for the direct evaluation the summarieshad to be analysed manually, in a first step, weproduced 3% summaries.
After noticing only slightimprovement when using our methods, we decidedto increase their lengths to 5%, to learn if themethods perform better when they produce longersummaries.
The values for the 5% summaries arerepresented in the tables in brackets.3A dangling anaphor is a referential expression which isdeprived of its referent as a result of extracting only the sentencewith the anaphoric expression.TextMethod 1 2 3 4 5 6 7 8 9 10 TotalTFIDF 12 (29) 5 (13) 17 (33) 10 (16) 7 (10) 12 (19) 9 (15) 14 (18) 12 (35) 8 (15) 106 (203)Basic method 8 (24) 4 (11) 11 (23) 5 (7) 4 (6) 7 (14) 9 (8) 12 (11) 10 (16) 7 (12) 77 (132)Greedy 8 (20) 4 (7) 12 (20) 4 (10) 4 (7) 8 (16) 11 (7) 8 (9) 9 (14) 8 (12) 76 (122)Evolutionary 6 (11) 3 (9) 14 (16) 4 (5) 4 (4) 7 (9) 7 (3) 8 (3) 9 (9) 5 (6) 67 (75)Maximum 15 (39) 12 (21) 20 (51) 13 (20) 7 (13) 15 (23) 14 (23) 15 (25) 17 (44) 11 (40) 139 (299)Table 1: The number of discourse ruptures in the summaries5.1 Number of ruptures in the discourseA factor which reduces the legibility is the numberof discourse ruptures (DR).
Using an approachsimilar to (Minel et al, 1997) we consider that adiscourse rupture occurs when a sentence seemscompletely isolated from the rest of the text.
Usuallythis happens due to presence of isolated discoursemarkers such as firstly, secondly, however, on theother hand, etc.
Table 1 shows the number of DRin these summaries.A result which was expected is the large numberof DR in the summaries produced by our baseline.Such a result is normal given that the method doesnot use any kind of discourse information.
Thebaseline is outperformed by the rest of the methodsin almost all the cases, the overall number of DR foreach method being significantly lower than the DRof the baseline.Table 1 shows that for 3% summaries, the contextinformation has little influence on the numberof the discourse ruptures present in a summary.This suggests that the information provided bythe indicating phrases (which are meta-discoursemarkers) has greater influence on the coherence ofthe summary than the continuity principle.The situation changes when longer summaries areconsidered.
As can be observed in Table 1, thecontinuity principle reduces the number of DR; thisnumber for the Evolutionary algorithm being almosthalf the number for Basic method.
Actually, byexamining the table, we can see that the evolutionaryalgorithm performs better than the basic method inall of the cases.
The same cannot be said about thegreedy algorithm.
It performs more or less the sameas the basic algorithm, the overall improvementbeing negligible.
This clearly indicates that in ourcase a simple greedy algorithm is not enough tochoose the set of sentences to extract, and moreadvanced techniques need to be used instead.The methods proposed in this paper performbetter when longer summaries are produced.
Sucha result is not obtained only because the summarycontains more sentences, and is therefore morelikely to contain sentences which are related to eachother.
If this was the case, we would not have such alarge number of DR in summaries generated by thebaseline.
We believe that the improvement is due tothe discourse information used by the methods.If the values of DR for each text are scrutinised,we can notice very mixed values.
For some ofthe texts the continuity principle helps a lot, butfor others it has little influence.
This suggests thatfor some of the texts the continuity principle is tooweak to influence the quality of a summary, anda combination of the continuity principle with theother principles from centering theory, as alreadyused for text generation in (Kibble and Power,2000), could lead to better summaries.The methods proposed in this paper rely onseveral parameters to boost or penalise the scores ofa sentence on the basis of context.
A way to improvethe results of these methods could be by selectingbetter values for these parameters.5.2 Dangling anaphorsEven though the problem of anaphora is not directlyaddressed by our methods, a subsidiary effect ofthe improvement of the local cohesion should be adecrease in the number of dangling references.Table 2 contains the number of danglingreferences in the summaries produced by differentTextMethod 1 2 3 4 5 6 7 8 9 10 TotalTFIDF 12 (31) 3 (25) 22 (35) 13 (15) 4 (10) 14 (22) 14 (16) 11 (22) 12 (19) 9 (15) 144 (210)Basic method 12 (26) 2 (23) 17 (29) 7 (13) 2 (7) 11 (20) 10 (9) 10 (8) 6 (12) 8 (15) 85 (162)Greedy 11 (19) 3 (14) 15 (20) 4 (19) 3 (9) 13 (23) 16 (10) 4 (11) 7 (12) 7 (14) 83 (151)Evolutionary 8 (18) 3 (16) 15 (18) 6 (6) 2 (6) 9 (12) 10 (7) 4 (5) 5 (13) 7 (12) 69 (113)Table 2: Number of dangling anaphors in the summariesmethods.
This number reduces in the summariesproduced by the evolutionary algorithm.
As in thecase of discourse ruptures, the greedy algorithmdoes not perform significantly better than the basicmethod.
All the methods outperform the baseline.We noticed that the most frequent danglingreferences were due to phrases referring to tables,figures, definitions and theorems (e.g.
As we showedin Table 3     ).
They can be referred to in anypoint in the text, and therefore, the local coherencecannot guarantee inclusion of the referred entities.Moreover, in many cases the referred entity is notnecessarily textual (e.g.
tables and figure), andtherefore should not be included in a summary.In light of these, we believe that the problem ofsuch dangling references should be addressed by thecontent-based method, which normally should filtersentences containing them.Dangling referential pronouns are virtuallynonexistent, which means that in most of the casesthe reader can understand, at least partially, themeaning of the referential expression.As observed for DR, the values for individualtexts are mixed.5.3 Text informativenessIn order to assess whether information is lostwhen the context-based method is used to enhancethe sentence selection, we used a content-basedevaluation metric (Donaway et al, 2000).
Thismetric computes the similarity between thesummary and the whole document, a good summarybeing one which has a value close to 1.4Table 3 shows that the evolutionary algorithm4In this paper we used cosine distance between thedocument?s vector and the automatic summary?s vector.
Beforebuilding the vectors the texts were lemmatised.does not lead to major loss of information, forseveral text this method obtains the highest score.In contrast, the greedy method seems to excludeuseful information, for several texts, performingworse than the basic method and the baseline.6 Related workIn text summarisation several researchers haveaddressed the problem of producing coherentsummaries.
In general, rules are applied to revisesummaries produced by a summarisation system(Mani et al, 1999; Otterbacher et al, 2002).These rules are produced by humans who readthe automatic summaries and identify coherenceproblems.
Marcu (2000) produced coherentsummaries using Rhetorical Structure Theory(RST).
A combination of RST and lexical chains isemployed in (Alonso i Alemany and Fuentes Fort,2003) for the same purpose.
Comparison to the workby Marcu and Alonso i Alemany is difficult to makebecause they worked with different types of texts.As already mentioned, information from centeringtheory was used in text generation to select the mostcoherent text from several candidates (Kibble andPower, 2000; Karamanis and Manurung, 2002).7 ConclusionIn this paper we presented two algorithmswhich combine content information with contextinformation.
The first one is a greedy algorithmwhich chooses one sentence at a time, but oncea sentence is selected it cannot be discarded.The second algorithm employs an evolutionarytechnique to determine the set of extractedsentences, overcoming the limitations of the firstalgorithm.Evaluation on scientific articles showed that theTextMethod 1 2 3 4 5 6 7 8 9 10TF-IDF 0.84(0.92)0.85(0.95)0.84(0.93)0.92(0.87)0.87(0.94)0.80(0.90)0.86(0.87)0.92(0.86)0.82(0.89)0.88(0.85)Basic method 0.81(0.91)0.85(0.87)0.87(0.90)0.93(0.87)0.89(0.93)0.88(0.87)0.89(0.83)0.90(0.89)0.68(0.88)0.92(0.86)Greedy 0.87(0.90)0.85(0.94)0.80(0.89)0.93(0.88)0.86(0.95)0.84(0.74)0.78(0.85)0.90(0.86)0.58(0.84)0.90(0.88)Evolutionary 0.82(0.86)0.88(0.95)0.84(0.91)0.94(0.89)0.86(0.88)0.87(0.88)0.90(0.88)0.86(0.87)0.81(0.82)0.88(0.91)Table 3: The similarity between the summary and the document from which it is producedevolutionary method performs consistently betterthan the rest of the methods in terms of coherenceand the cohesion, and does not degrade theinformation content in most of the cases.From each text we produced 3% and 5%summaries.
For the 3% summaries there isno significant improvement when contextualinformation is used (not even when the evolutionaryalgorithm is used).
However, for 5% summaries,the number of discourse ruptures in the summariesproduced by the evolutionary algorithm is almosthalf the number of DR in the ones produced by thebasic method.
The number of dangling referentialexpressions also reduces.
Regardless the length ofthe summary, it seems to be no significant differencebetween the basic method and the greedy algorithm.One could argue that for long documents, 5%summaries are too long, and that shorter versions arerequired.
This is true, but these summaries can beshortened by using aggregation rules like the onesproposed in (Otterbacher et al, 2002), where twosentences referring to the same entity are mergedinto one.
Given that the summaries produced withthe evolutionary algorithm contain more sequencesof sentences related to the same entity, it will beeasier to apply such aggregation rules.As noted in Section 5.1, the results vary fromone text to another.
In some cases the continuityprinciple noticeably improves the quality of asummary, but in other cases the improvement ismoderate or low.
One reason could be thatthe continuity principle alone is too weak to beable to guarantee the coherence of the producedsummary.
We intend to extend our experimentsand test whether a combination of centering theory?sprinciples, as used in (Kibble and Power, 2000), canlead to better results.Our algorithms were tested on scientific articles.We intend to extend the evaluation using other typesof texts in order to learn if the genre influences theresults.To conclude, in this paper we argue that itis possible to improve the quality of automaticsummaries by using the continuity principle andby employing an evolutionary algorithm to selectsentences.
This improvement seems to be textdependent, in some cases being small.AcknowledgementsPreparation of this paper was supported by the Artsand Humanities Research Board through the CASTproject.ReferencesLaura Alonso i Alemany and Maria Fuentes Fort.
2003.Integrating cohesion and coherence for automaticsummarisation.
In Proceedings of EACL2003, pages1 ?
8, Budapest, Hungary, April.G.
DeJong.
1982.
An overview of the FRUMP system.In W. G. Lehnert and M. H. Ringle, editors, Strategiesfor natural language processing, pages 149 ?
176.Hillsdale, NJ: Lawrence Erlbaum.Robert L. Donaway, Kevin W. Drummey, and Laura A.Mather.
2000.
A comparison of rankingsproduced by summarization evaluation measures.
InProceedings of NAACL-ANLP 2000 Workshop on TextSummarisation, pages 69 ?
78, Seattle, Washington,April 30.Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.1995.
Centering: A framework for modelling the localcoherence of discourse.
Computational Linguistics,21(2):203 ?
225.J.H.
Holland.
1975.
Adaptation in Natural and ArtificialSystems.
University of Michigan Press.Nikiforos Karamanis and Hisar Maruli Manurung.
2002.Stochastic text structuring using the principle ofcontinuity.
In Proceedings of International NaturalLanguage Generation Conference, pages 81 ?
88, NewYork, USA, 1 ?
3 July.Rodger Kibble and Richard Power.
2000.
An integratedframework for text planning and pronominalisation.In Proceedings of International Natural LanguageGeneration Conference, pages 77 ?
84, MitzpeRamon, Israel, 12 - 16 June.H.
P. Luhn.
1958.
The automatic creation of literatureabstracts.
IBM Journal of research and development,2(2):159 ?
165.Inderjeet Mani, Barbara Gates, and Eric Bloedorn.1999.
Improving summaries by revising them.
InProceedings of the 37th Annual Meeting of the ACL,pages 558 ?
565, University of Maryland, CollegePark, Maryland, USA, 20 ?
26 June.Daniel Marcu.
2000.
The theory and practice ofdiscourse parsing and summarisation.
The MIT Press.J Minel, S Nugier, and G Piat.
1997.
How to appreciatethe quality of automatic text summarization?
InProceedings of the ACL?97/EACL?97 Workshop onIntelligent Scallable Text Summarization, pages 25 ?30, Madrid, Spain, July 11.Jahna C. Otterbacher, Dragomir R. Radev, and AirongLuo.
2002.
Revisions that improve cohesionin multi-document summaries: A preliminarystudy.
In Proceedings of the Workshop on TextSummarization, pages 27 ?
36, University ofPennsylvania, Philadelphia, PA, USA, 11 ?
12 July.Chris D. Paice.
1981.
The automatic generationof literature abstracts: an approach based on theidentification of self-indicating phrases.
In R. N.Oddy, C. J. Rijsbergen, and P. W. Williams, editors,Information Retrieval Research, pages 172 ?
191.London: Butterworths.P.
Tapanainen and T. Ja?rvinen.
1997.
A non-projectivedependency parser.
In Proceedings of the 5thConference of Applied Natural Language Processing,pages 64 ?
71, Washington D.C., USA.Klaus Zechner.
1996.
Fast generation of abstracts fromgeneral domain text corpora by extracting relevantsentences.
In COLING - 96, The InternationalConference on Computational Linguistics, volume 1,pages 986?989, Center for Sprogteknologi,Copenhagen, Denmark, August.
