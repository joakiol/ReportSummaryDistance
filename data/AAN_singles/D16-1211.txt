Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2005?2010,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsTraining with Exploration Improves a Greedy Stack LSTM ParserMiguel Ballesteros?
Yoav Goldberg?
Chris Dyer?
Noah A.
Smith?
?NLP Group, Pompeu Fabra University, Barcelona, Spain?Computer Science Department, Bar-Ilan University, Ramat Gan, Israel?Google DeepMind, London, UK?Computer Science & Engineering, University of Washington, Seattle, WA, USAmiguel.ballesteros@upf.edu, yoav.goldberg@gmail.com,cdyer@google.com, nasmith@cs.washington.eduAbstractWe adapt the greedy stack LSTM dependencyparser of Dyer et al (2015) to support atraining-with-exploration procedure using dy-namic oracles (Goldberg and Nivre, 2013) in-stead of assuming an error-free action his-tory.
This form of training, which accounts formodel predictions at training time, improvesparsing accuracies.
We discuss some modifi-cations needed in order to get training with ex-ploration to work well for a probabilistic neu-ral network dependency parser.1 IntroductionNatural language parsing can be formulated as a se-ries of decisions that read words in sequence and in-crementally combine them to form syntactic struc-tures; this formalization is known as transition-based parsing, and is often coupled with a greedysearch procedure (Yamada and Matsumoto, 2003;Nivre, 2003; Nivre, 2004; Nivre, 2008).
The lit-erature on transition-based parsing is vast, but allworks share in common a classification componentthat takes into account features of the current parserstate1 and predicts the next action to take condi-tioned on the state.
The state is of unbounded size.Dyer et al (2015) presented a parser in which theparser?s unbounded state is embedded in a fixed-dimensional continuous space using recurrent neu-ral networks.
Coupled with a recursive tree com-position function, the feature representation is able1The term ?state?
refers to the collection of previous de-cisions (sometimes called the history), resulting partial struc-tures, which are typically stored in a stack data structure, andthe words remaining to be processed.to capture information from the entirety of the state,without resorting to locality assumptions that werecommon in most other transition-based parsers.
Theuse of a novel stack LSTM data structure allows theparser to maintain a constant time per-state update,and retain an overall linear parsing time.The Dyer et al parser was trained to maximizethe likelihood of gold-standard transition sequences,given words.
At test time, the parser makes greedydecisions according to the learned model.
Althoughthis setup obtains very good performance, the train-ing and testing conditions are mismatched in the fol-lowing way: at training time the historical context ofan action is always derived from the gold standard(i.e., perfectly correct past actions), but at test time,it will be a model prediction.In this work, we adapt the training criterion soas to explore parser states drawn not only from thetraining data, but also from the model as it is be-ing learned.
To do so, we use the method of Gold-berg and Nivre (2012; 2013) to dynamically chosean optimal (relative to the final attachment accuracy)action given an imperfect history.
By interpolatingbetween algorithm states sampled from the modeland those sampled from the training data, more ro-bust predictions at test time can be made.
We showthat the technique can be used to improve the strongparser of Dyer et al2 Parsing Model and Parameter LearningOur departure point is the parsing model describedby Dyer et al (2015).
We do not describe the modelin detail, and refer the reader to the original work.
Ateach stage t of the parsing process, the parser state is2005encoded into a vector pt, which is used to computethe probability of the parser action at time t as:p(zt | pt) =exp(g>ztpt + qzt)?z?
?A(S,B) exp(g>z?pt + qz?)
, (1)where gz is a column vector representing the (out-put) embedding of the parser action z, and qz is abias term for action z.
The set A(S,B) representsthe valid transition actions that may be taken in thecurrent state.
Since pt encodes information about allprevious decisions made by the parser, the chain rulegives the probability of any valid sequence of parsetransitions z conditional on the input:p(z | w) =|z|?t=1p(zt | pt).
(2)The parser is trained to maximize the conditionalprobability of taking a ?correct?
action at each pars-ing state.
The definition of what constitutes a ?cor-rect?
action is the major difference between a staticoracle as used by Dyer et al (2015) and the dynamicoracle explored here.Regardless of the oracle, our training implemen-tation constructs a computation graph (nodes thatrepresent values, linked by directed edges from eachfunction?s inputs to its outputs) for the negative logprobability for the oracle transition sequence as afunction of the current model parameters and usesforward- and backpropagation to obtain the gradi-ents respect to the model parameters (Lecun et al,1998, section 4).2.1 Training with Static OraclesWith a static oracle, the training procedure com-putes a canonical reference series of transitions foreach gold parse tree.
It then runs the parser throughthis canonical sequence of transitions, while keep-ing track of the state representation pt at each step t,as well as the distribution over transitions p(zt | pt)which is predicted by the current classifier for thestate representation.
Once the end of the sentence isreached, the parameters are updated towards maxi-mizing the likelihood of the reference transition se-quence (Equation 2), which equates to maximizingthe probability of the correct transition, p(zgt | pt),at each state along the path.2.2 Training with Dynamic OraclesIn the static oracle case, the parser is trained topredict the best transition to take at each parsingstep, assuming all previous transitions were cor-rect.
Since the parser is likely to make mistakes attest time and encounter states it has not seen dur-ing training, this training criterion is problematic(Daume?
III et al, 2009; Ross et al, 2011; Gold-berg and Nivre, 2012; Goldberg and Nivre, 2013,inter alia).
Instead, we would prefer to train theparser to behave optimally even after making a mis-take (under the constraint that it cannot backtrackor fix any previous decision).
We thus need to in-clude in the training examples states that result fromwrong parsing decisions, together with the optimaltransitions to take in these states.
To this end wereconsider which training examples to show, andwhat it means to behave optimally on these trainingexamples.
The framework of training with explo-ration using dynamic oracles suggested by Goldbergand Nivre (2012; 2013) provides answers to thesequestions.
While the application of dynamic oracletraining is relatively straightforward, some adapta-tions were needed to accommodate the probabilistictraining objective.
These adaptations mostly followGoldberg (2013).Dynamic Oracles.
A dynamic oracle is the com-ponent that, given a gold parse tree, provides theoptimal set of possible actions to take for any validparser state.
In contrast to static oracles that derivea canonical state sequence for each gold parse treeand say nothing about states that deviate from thiscanonical path, the dynamic oracle is well definedfor states that result from parsing mistakes, and theymay produce more than a single gold action for agiven state.
Under the dynamic oracle framework,an action is said to be optimal for a state if the besttree that can be reached after taking the action is noworse (in terms of accuracy with respect to the goldtree) than the best tree that could be reached prior totaking that action.Goldberg and Nivre (2013) define the arc-decomposition property of transition systems, andshow how to derive efficient dynamic oracles fortransition systems that are arc-decomposable.2 Un-fortunately, the arc-standard transition system does2Specifically: for every parser configuration p and group of2006not have this property.
While it is possible to com-pute dynamic oracles for the arc-standard system(Goldberg et al, 2014), the computation relies ona dynamic programming algorithm which is polyno-mial in the length of the stack.
As the dynamic ora-cle has to be queried for each parser state seen duringtraining, the use of this dynamic oracle will make thetraining runtime several times longer.
We chose in-stead to switch to the arc-hybrid transition system(Kuhlmann et al, 2011), which is very similar tothe arc-standard system but is arc-decomposable andhence admits an efficient O(1) dynamic oracle, re-sulting in only negligible increase to training run-time.
We implemented the dynamic oracle to thearc-hybrid system as described by Goldberg (2013).Training with Exploration.
In order to exposethe parser to configurations that are likely to resultfrom incorrect parsing decisions, we make use of theprobabilistic nature of the classifier.
During training,instead of following the gold action, we sample thenext transition according to the output distributionthe classifier assigns to the current configuration.Another option, taken by Goldberg and Nivre, is tofollow the one-best action predicted by the classifier.However, initial experiments showed that the one-best approach did not work well.
Because the neuralnetwork classifier becomes accurate early on in thetraining process, the one-best action is likely to becorrect, and the parser is then exposed to very fewerror states in its training process.
By sampling fromthe predicted distribution, we are effectively increas-ing the chance of straying from the gold path duringtraining, while still focusing on mistakes that receiverelatively high parser scores.
We believe further for-mal analysis of this method will reveal connectionsto reinforcement learning and, perhaps, other meth-ods for learning complex policies.Taking this idea further, we could increase thenumber of error-states observed in the training pro-cess by changing the sampling distribution so asto bias it toward more low-probability states.
Wedo this by raising each probability to the power of?
(0 < ?
?
1) and re-normalizing.
This trans-arcs A, if each arc in A can be derived from p, then a validtree structure containing all of the arcs in A can also be derivedfromp.
This is a sufficient condition, but whether it is necessaryis unknown; hence the question of an efficient, O(1) dynamicoracle for the augmented system is open.formation keeps the relative ordering of the events,while shifting probability mass towards less frequentevents.
As we show below, this turns out to be verybeneficial for the configurations that make use ofexternal embeddings.
Indeed, these configurationsachieve high accuracies and sharp class distributionsearly on in the training process.The parser is trained to maximize the likelihood ofa correct action zg at each parsing state pt accordingto Equation 1.
When using the dynamic oracle, astate pt may admit multiple correct actions zg ={zgi , .
.
.
, zgk}.
Our objective in such cases is themarginal likelihood of all correct actions,3p(zg | pt) =?zgi?zgp(zgi | pt).
(3)3 ExperimentsFollowing the same settings of Chen and Manning(2014) and Dyer et al(2015) we report results4 inthe English PTB and Chinese CTB-5.
Table 1 showsthe results of the parser in its different configura-tions.
The table also shows the best result obtainedwith the static oracle (obtained by rerunning Dyer etal.
parser) for the sake of comparison between staticand dynamic training strategies.English ChineseMethod UAS LAS UAS LASArc-standard (Dyer et al) 92.40 90.04 85.48 83.94Arc-hybrid (static) 92.08 89.80 85.66 84.03Arc-hybrid (dynamic) 92.66 90.43 86.07 84.46Arc-hybrid (dyn., ?
= 0.75) 92.73 90.60 86.13 84.53+ pre-training:Arc-standard (Dyer et al) 93.04 90.87 86.85 85.36Arc-hybrid (static) 92.78 90.67 86.94 85.46Arc-hybrid (dynamic) 93.15 91.05 87.05 85.63Arc-hybrid (dyn., ?
= 0.75) 93.56 91.42 87.65 86.21Table 1: Dependency parsing: English (SD) and Chinese.The score achieved by the dynamic oracle for En-glish is 93.56 UAS.
This is remarkable given thatthe parser uses a completely greedy search proce-dure.
Moreover, the Chinese score establishes thestate-of-the-art, using the same settings as Chen andManning (2014).3A similar objective was used by Riezler et al(2000), Char-niak and Johnson (2005) and Goldberg (2013) in the context oflog-linear probabilistic models.4The results on the development sets are similar and onlyused for optimization and validation.2007Catalan Chinese Czech English German Japanese SpanishMethod UAS LAS UAS LAS UAS LAS UAS LAS UAS LAS UAS LAS UAS LASArc-standard, static + PP 89.60 85.45 79.68 75.08 77.96 71.06 91.12 88.69 88.09 85.24 93.10 92.28 89.08 85.03+ pre-training ?
?
82.45 78.55 ?
?
91.59 89.15 88.56 86.15 ?
?
90.76 87.48Arc-hybrid, dyn.
+ PP 90.45 86.38 80.74 76.52 85.68 79.38 91.62 89.23 89.80 87.29 93.47 92.70 89.53 85.69+ pre-training ?
?
83.54 79.66 ?
?
92.22 89.87 90.34 88.17 ?
?
91.09 87.95Y?15 ?
?
?
?
85.2 77.5 90.75 88.14 89.6 86.0 ?
?
88.3 85.4A?16 + pre-training 91.24 88.21 81.29 77.29 85.78 80.63 91.44 89.29 89.12 86.95 93.71 92.85 91.01 88.14A?16-beam 92.67 89.83 84.72 80.85 88.94 84.56 93.22 91.23 90.91 89.15 93.65 92.84 92.62 89.95Table 2: Dependency parsing results.
The dynamic oracle uses ?
= 0.75 (selected on English; see Table 1).
PP refers to pseudo-projective parsing.
Y?15 and A?16 are beam = 1 parsers from Yazdani and Henderson (2015) and Andor et al (2016), respectively.A?16-beam is the parser with beam larger than 1 by Andor et al (2016).
Bold numbers indicate the best results among the greedyparsers.The error-exploring dynamic-oracle training al-ways improves over static oracle training control-ling for the transition system, but the arc-hybrid sys-tem slightly under-performs the arc-standard systemwhen trained with static oracle.
Flattening the sam-pling distribution (?
= 0.75) is especially beneficialwhen training with pretrained word embeddings.In order to be able to compare with similar greedyparsers (Yazdani and Henderson, 2015; Andor etal., 2016)5 we report the performance of the parseron the multilingual treebanks of the CoNLL 2009shared task (Hajic?
et al, 2009).
Since some of thetreebanks contain nonprojective sentences and arc-hybrid does not allow nonprojective trees, we usethe pseudo-projective approach (Nivre and Nilsson,2005).
We used predicted part-of-speech tags pro-vided by the CoNLL 2009 shared task organizers.We also include results with pretrained word em-beddings for English, Chinese, German, and Span-ish following the same training setup as Dyer etal.
(2015); for English and Chinese we used thesame pretrained word embeddings as in Table 1, forGerman we used the monolingual training data fromthe WMT 2015 dataset and for Spanish we used theSpanish Gigaword version 3.
See Table 2.4 Related WorkTraining greedy parsers on non-gold outcomes, fa-cilitated by dynamic oracles, has been explored byseveral researchers in different ways (Goldberg andNivre, 2012; Goldberg and Nivre, 2013; Gold-berg et al, 2014; Honnibal et al, 2013; Honnibaland Johnson, 2014; Go?mez-Rodr?
?guez et al, 2014;5We report the performance of these parsers in the mostcomparable setup, that is, with beam size 1 or greedy search.Bjo?rkelund and Nivre, 2015; Tokgo?z and Eryig?it,2015; Go?mez-Rodr?
?guez and Ferna?ndez-Gonza?lez,2015; Vaswani and Sagae, 2016).
More gener-ally, training greedy search systems by paying atten-tion to the expected classifier behavior during testtime has been explored under the imitation learningand learning-to-search frameworks (Abbeel and Ng,2004; Daume?
III and Marcu, 2005; Vlachos, 2012;He et al, 2012; Daume?
III et al, 2009; Ross et al,2011; Chang et al, 2015).
Directly modeling theprobability of making a mistake has also been ex-plored for parsing (Yazdani and Henderson, 2015).Generally, the use of RNNs to conditionally predictactions in sequence given a history is spurring in-creased interest in training regimens that make thelearned model more robust to test-time prediction er-rors.
Solutions based on curriculum learning (Ben-gio et al, 2015), expected loss training (Shen et al,2015), and reinforcement learning have been pro-posed (Ranzato et al, 2016).
Finally, abandoninggreedy search in favor of approximate global searchoffers an alternative solution to the problems withgreedy search (Andor et al, 2016), and has been an-alyzed as well (Kulesza and Pereira, 2007; Finleyand Joachims, 2008), including for parsing (Martinset al, 2009).5 ConclusionsDyer et al (2015) presented stack LSTMs and usedthem to implement a transition-based dependencyparser.
The parser uses a greedy learning strat-egy which potentially provides very high parsingspeed while still achieving state-of-the-art results.We have demonstrated that improvement by trainingthe greedy parser on non-gold outcomes; dynamic2008oracles improve the stack LSTM parser, achieving93.56 UAS for English, maintaining greedy search.AcknowledgmentsThis work was sponsored in part by the U. S. ArmyResearch Laboratory and the U. S. Army ResearchOffice under contract/grant number W911NF-10-1-0533, and in part by NSF CAREER grant IIS-1054319.
Miguel Ballesteros was supported bythe European Commission under the contract num-bers FP7-ICT-610411 (project MULTISENSOR)and H2020-RIA-645012 (project KRISTINA).
YoavGoldberg is supported by the Intel CollaborativeResearch Institute for Computational Intelligence(ICRI-CI), a Google Research Award and the IsraeliScience Foundation (grant number 1555/15).ReferencesPieter Abbeel and Andrew Y. Ng.
2004.
Apprenticeshiplearning via inverse reinforcement learning.
In Proc.of ICML.Daniel Andor, Chris Alberti, David Weiss, AliakseiSeveryn, Alessandro Presta, Kuzman Ganchev, SlavPetrov, and Michael Collins.
2016.
Globally nor-malized transition-based neural networks.
In Proc.
ofACL.Samy Bengio, Oriol Vinyals, Navdeep Jaitly, andNoam Shazeer.
2015.
Scheduled sampling forsequence prediction with recurrent neural networks.arXiv:1506.03099.Anders Bjo?rkelund and Joakim Nivre.
2015.
Non-deterministic oracles for unrestricted non-projectivetransition-based dependency parsing.
In Proc.
ofIWPT.Kai-Wei Chang, Akshay Krishnamurthy, Alekh Agarwal,Hal Daume, and John Langford.
2015.
Learning tosearch better than your teacher.
In Proc.
of ICML.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative rerank-ing.
In Proc.
of ACL.Danqi Chen and Christopher D. Manning.
2014.
Afast and accurate dependency parser using neural net-works.
In Proc.
of EMNLP.Hal Daume?
III and Daniel Marcu.
2005.
Learning assearch optimization: Approximate large margin meth-ods for structured prediction.
In Proc.
of ICML.Hal Daume?
III, John Langford, and Daniel Marcu.
2009.Search-based structured prediction.
Machine Learn-ing, 75:297?325.Chris Dyer, Miguel Ballesteros, Wang Ling, AustinMatthews, and Noah A. Smith.
2015.
Transition-based dependency parsing with stack long short-termmemory.
In Proc.
of ACL.T.
Finley and T. Joachims.
2008.
Training structuralSVMs when exact inference is intractable.
In In Proc.of ICML.Yoav Goldberg and Joakim Nivre.
2012.
A dynamicoracle for arc-eager dependency parsing.
In Proc.
ofCOLING.Yoav Goldberg and Joakim Nivre.
2013.
Trainingdeterministic parsers with non-deterministic oracles.Transactions of the Association for ComputationalLinguistics, 1:403?414.Yoav Goldberg, Francesco Sartorio, and Giorgio Satta.2014.
A tabular method for dynamic oracles intransition-based parsing.
Transactions of the associ-ation for Computational Linguistics, 2.Yoav Goldberg.
2013.
Dynamic-oracle transition-basedparsing with calibrated probabilistic output.
In Proc.of IWPT.Carlos Go?mez-Rodr?
?guez and Daniel Ferna?ndez-Gonza?lez.
2015.
An efficient dynamic oracle forunrestricted non-projective parsing.
In Proc.
of ACL.Carlos Go?mez-Rodr?
?guez, Francesco Sartorio, and Gior-gio Satta.
2014.
A polynomial-time dynamic oraclefor non-projective dependency parsing.
In Proc.
ofEMNLP.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic dependen-cies in multiple languages.
In Proc.
of CoNLL.He He, Hal Daume?
III, and Jason Eisner.
2012.
Imitationlearning by coaching.
In NIPS.Matthew Honnibal and Mark Johnson.
2014.
Joint in-cremental disfluency detection and dependency pars-ing.
Transactions of the Association for Computa-tional Linguistics, 2:131?142.Matthew Honnibal, Yoav Goldberg, and Mark Johnson.2013.
A non-monotonic arc-eager transition systemfor dependency parsing.
In Proc.
of CoNLL.Marco Kuhlmann, Carlos Go?mez-Rodr?
?guez, and Gior-gio Satta.
2011.
Dynamic programming algorithmsfor transition-based dependency parsers.
In Proc.
ofACL.A.
Kulesza and F. Pereira.
2007.
Structured learningwith approximate inference.
In NIPS.Yann Lecun, Le?on Bottou, Yoshua Bengio, and PatrickHaffner.
1998.
Gradient-based learning applied todocument recognition.
Proceedings of the IEEE,86(11):2278?2324.2009Andre?
F. T. Martins, Noah A. Smith, and Eric P. Xing.2009.
Polyhedral outer approximations with applica-tion to natural language parsing.
In Proc.
of ICML.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-projectivedependency parsing.
In Proc.
of ACL.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proc.
of IWPT.Joakim Nivre.
2004.
Incrementality in deterministic de-pendency parsing.
In Proceedings of the Workshop onIncremental Parsing: Bringing Engineering and Cog-nition Together.Joakim Nivre.
2008.
Algorithms for deterministic incre-mental dependency parsing.
Computational Linguis-tics, 34(4):513?553.Marc?Aurelio Ranzato, Sumit Chopra, Michael Auli, andWojciech Zaremba.
2016.
Sequence level trainingwith recurrent neural networks.
In Proc.
of ICLR.Stefan Riezler, Detlef Prescher, Jonas Kuhn, and MarkJohnson.
2000.
Lexicalized stochastic modeling ofconstraint-based grammars using log-linear measuresand em training.
In Proc.
of ACL.Ste?phane Ross, Geoffrey J. Gordon, and J. Andrew Bag-nell.
2011.
A reduction of imitation learning andstructured prediction to no-regret online learning.
InProc.
of AISTAT.Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, HuaWu, Maosong Sun, and Yang Liu.
2015.
Minimumrisk training for neural machine translation.
In Proc.of ACL.Alper Tokgo?z and Gu?ls?en Eryig?it.
2015.
Transition-based dependency DAG parsing using dynamic ora-cles.
In Proc.
of ACL SRW.Ashish Vaswani and Kenji Sagae.
2016.
Efficient struc-tured inference for transition-based parsing with neu-ral networks and error states.
Transactions of the As-sociation for Computational Linguistics, 4:183?196.Andreas Vlachos.
2012.
An investigation of imitationlearning algorithms for structured prediction.
In Proc.of the European Workshop on Reinforcement Learn-ing.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProc.
of IWPT.Majid Yazdani and James Henderson.
2015.
Incre-mental recurrent neural network dependency parserwith search-based discriminative training.
In Proc.
ofCoNLL.2010
