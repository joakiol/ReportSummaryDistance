Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 305?306,New York City, June 2006. c?2006 Association for Computational Linguistics4.
Automatic Spoken Document Processing for Retrieval and BrowsingCiprian Chelba, Google, and T. J. Hazen, MITEver increasing computing power and connectivity bandwidth together with falling storage costs is re-sulting in overwhelming amounts of multimedia data being produced, exchanged, and stored.
One keyapplication area in this realm is the search and retrieval of spoken audio documents.
As storage becomescheaper, the availability and usefulness of large collections of spoken documents is limited strictly by thelack of adequate technology to exploit them.
Manually transcribing speech is expensive and sometimesoutright impossible due to privacy concerns.
This leads us to exploring an automatic approach to searchingand navigating spoken document collections.
This tutorial will present an overview of speech transcription,indexing, and search technologies for spoken documents, with an emphasis on a corpus containing recordedacademic lectures.
The tutorial will point out general problems in this area and suggest possible solutions.Included in the tutorial will be a discussion of scenarios and previous projects in the area of spoken doc-ument retrieval, issues of automatic transcription of long audio files, and techniques for the indexing andretrieval of spoken audio files.4.1 Tutorial Outline1.
Introduction: Scenarios/Previous Work/Corpora?
Scenarios:* Economic considerations for viability of such technology* Scenarios where technology is not expected to be useful* Scenarios where technology is expected to be useful:?
Broadcast News* Characteristics* Meta-data annotation* Past work (HP SpeechBot, BBN, TREC, PodZinger, etc.)?
Academic & Scientific Lectures* Examples (OCW, CSJ, MICASE)* Characteristics* Challenges and opportunities2.
Automatic Speech Transcription?
Overview of speech recognition models and processing?
Vocabulary Issues* Examination of vocabulary statistics and coverage* Vocabulary expansion from supplemental materials?
Language Modeling Issues* Spontaneous conversational speech vs. read speech* Appropriateness of written materials* Language model adaptation?
Acoustic Modeling Issues* Speaker independent modeling* Speaker dependent modeling* Supervised and unsupervised adaptation?
Out-Of-Vocabulary (OOV) modeling* Methods for recognizing OOV words* Phonetic transcription of OOV words3053.
Audio Retrieval?
Overview of text retrieval algorithms:* TF-IDF/vector space methods* Probabilistic methods* Large scale web search (Google)* Inverted indexing; query processing/language.?
Speech recognition lattices:* Word/phone/OOV-models for generation* Lattice accuracy vs. 1-best accuracy?
Query processing (OOV problem)/language:* ?Soft?-indexing with pruning to control size* Combine sub-word and word-level indexing/recognition results?
Relevance scoring:* Proximity* Incorporating multiple data streams: speech, text, title, author, abstract, etc.
* Tuning precision/recall at query run-time?
Evaluation:* Basic Metrics: Precision/Recall* Ordered list metrics: Kendall-Tau, Spearman* TREC measures and package (Mean Average Precision, R-precision)* Issues with evaluating speech data?
User interface:* Issues in consuming speech (as opposed to text, images)* Pro?s/con?s for displaying transcription* Navigation in long documents with errorful transcriptions* Segmentation: topic boundaries, keywords, summaries4.2 Target AudienceThis tutorial is designed for people interested in learning about the technologies used to transcribe, process,search, and retreive spoken audio materials.
Detailed prior knowledge of speech recognition and/or searchtechnologies is not required.Ciprian Chelba is a Research Scientist with Google.
Previously he worked as a Researcher in the SpeechTechnology Group at Microsoft Research.
His core research interests are in statistical modeling of naturallanguage and speech.
Recent projects include speech content indexing for search in spoken documents,discriminative language modeling for large vocabulary speech recognition, as well as speech and text clas-sification.Timothy J. Hazen is a Research Scientist at the MIT Computer Science and Artificial Intelligence Laboratorywhere he works in the areas of automatic speech recognition, automatic person identification, multi-modalspeech processing, and conversational speech systems.
For the last two years he has been a key contributorto the MIT Spoken Lecture Processing Project.306
