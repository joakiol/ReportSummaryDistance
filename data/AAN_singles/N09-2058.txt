Proceedings of NAACL HLT 2009: Short Papers, pages 229?232,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsDetermining the Position of Adverbial Phrases in EnglishHuayan Zhong and Amanda StentComputer Science DepartmentStony Brook UniversityStony Brook, NY 11794, USAzhong@cs.sunysb.edu, amanda.stent@stonybrook.eduAbstractIn this paper we compare three approaches toadverbial positioning using lexical, syntactic,semantic and sentence-level features.
We findthat: (a), one- and two-stage classification-based approaches can achieve almost 86% ac-curacy in determining the absolute position ofadverbials; (b) a classifier trained with onlysyntactic features gives performance close tothat of a classifier trained with all features; and(c) a surface realizer incorporating a two-stageclassifier for adverbial positioning as the sec-ond stage gives improvements of at least 10%in simple string accuracy over a baseline real-izer for sentences containing adverbials.1 IntroductionThe job of a surface realizer is to transform an inputsemantic/syntactic form into a sequence of words.This task includes word choice, and word and con-stituent ordering.
In English, the positions of re-quired elements of a sentence, verb phrase or nounphrase are relatively fixed.
However, many sen-tences also include adverbials whose position is notfixed (Figure 1).
There may be several appropriatepositions for an adverbial in a particular context, butother positions give output that is non-idiomatic ordisfluent, ambiguous, or incoherent.Some computational research has included mod-els for adjunct ordering (e.g.
(Ringger et al, 2004;Marciniak and Strube, 2004; Elhadad et al, 2001)).However, this is the first computational study to lookspecifically at adverbials.
Adverbial positioning haslong been studied in linguistics (e.g.
(Keyser, 1968;Allen and Cruttenden, 1974; Ernst, 1984; Haider,2000)).
Most linguistic research focuses on whetheradverbial placement is functional or semantic in na-ture.
However, Costa (2004) takes a more flexi-ble feature-based approach that uses: lexical fea-tures (e.g.
phonological shape, ambiguity of mean-ing, categorical status); syntactic features (e.g.
pos-sible adjunction sites, directionality of adjunction,domain of modification); and information structurefeatures (e.g.
focus, contrast).
We decided to evalu-ate Costa?s approach computationally, using featuresautomatically extracted from an annotated corpus.In this paper, we compare three approaches to ad-verbial positioning: a simple baseline approach us-ing lexical and syntactic features, and one- and two-stage classification-based approaches using lexical,syntactic, semantic and sentence-level features.
Weapply these approaches in a hybrid surface realizerthat uses a probabilistic grammar to produce real-ization alternatives, and a second-stage classifier toselect among alternatives.
We find that: (a) One-and two-stage classification-based approaches canachieve almost 86% accuracy in determining the ab-solute position of adverbials; (b) A classifier trainedwith only syntactic features gives performance closeto that of a classifier trained with all features; and (c)A surface realizer using a two-stage classifier for ad-verbial positioning can get improvements of at least10% in simple string accuracy over a baseline real-izer for sentences containing adverbials.As well as being useful for surface realization, amodel of adverbial ordering can be used in machinetranslation (e.g.
(Ogura et al, 1997)), languagelearning software (e.g.
(Leacock, 2007; Burstein etal., 2004)), and automatic summarization (e.g.
(El-hadad et al, 2001; Clarke and Lapata, 2007; Mad-nani et al, 2007)).229Figure 1: Example syntax tree for Then she cashed thecheck at your bank on Tuesday with adverbials circledand possible VP and S adverbial positions in squares.2 Data and FeaturesFrom the sentences in the Wall Street Journal (WSJ)and Switchboard (SWBD) sections of the PennTreebank III (Marcus et al, 1999), we extracted allNP, PP and ADVP phrases labeled with the adver-bial tags -BNF, -DIR, -EXT, -LOC, -MNR, -PRP,-TMP or -ADV.
These phrases mostly modify S con-stituents (including RRC, S, SBAR, SBARQ, SINV,SQ), VP constituents, or NP constituents (includ-ing NP and WHNP), but also modify other adjuncts(PP, ADJP or ADVP) and other phrase types (FRAG,INTJ, LST, NAC, PRT, QP, TOP, UCP, X).Corpus Number of adverbials of type:PP-ADVP NP-ADVP ADVPWSJ 36128 10587 13700SWBD 12231 5405 17193Table 1: Adverbials in the Penn Treebank IIIFor each adverbial, we automatically extractedlexical, syntactic, semantic and discourse features.We included features similar to those in (Costa,2004) and from our own previous research on prepo-sitional phrase ordering (Zhong and Stent, 2008).Due to the size of our data set, we could only usefeatures that can be extracted automatically, so somefeatures were approximated.
We dropped adverbialsfor which we could not get features, such as emptyadverbials.
Tables 1 and 2 summarize the resultingdata.
A list of the features we used in our classifi-cation experiment appears in Table 3.
We withheld10% of this data for our realization experiment.3 Classification ExperimentOur goal is to determine the position of an adverbialwith respect to its siblings in the phrase of which itAdverbial Data SetType WSJ SWBDS 8196 5144VP 29734 22845NP 12985 2071PP/ADJP/ADVP 1739 987Other 297 686Table 2: Adverbials in the Penn Treebank IIIis a part.
An adverbial may have non-adverbial sib-lings, whose position is typically fixed.
It may alsohave other adverbial siblings.
In the sentence in Fig-ure 1, at your bank has one adverbial and two non-adverbial siblings.
If this adverbial were placed atpositions VP:0 or VP:1 the resulting sentence wouldbe disfluent but meaningful; placed at position VP:2the resulting sentence is fluent, meaningful and id-iomatic.
(In this sentence, both orderings of the twoadverbials at position VP:2 are valid.
)3.1 ApproachesWe experimented with three approaches to adverbialpositioning.Baseline Our baseline approach has two stages.
Inthe first stage the position of each adverbial withrespect to its non-adverbial siblings is determined:each adverbial is assigned the most likely positiongiven its lexical head and category (PP, NN, ADVP).In the second stage, the relative ordering of adjacentadverbials is determined in a pairwise fashion (cf.
(Marciniak and Strube, 2004)): the ordering of a pairof adverbials is assigned to be the most frequent inthe training data, given the lexical head, adverbialphrase type, and category of each adverbial.One-stage For our one-stage classification-basedapproach, we determine the position of all adver-bials in a phrase at one step.
There is one featurevector for each phrase containing at least one adver-bial.
It contains features for all non-adverbial sib-lings in realization order, and then for each adverbialsibling in alphabetical order by lexical head.
The la-bel is the order of the siblings.
For example, for theS-modifying adverbial in Figure 1, the label wouldbe 2 0 1, where 0 = ?she?, 1 = ?cashed?
and 2 =?Then?.
If there are n siblings, then there are n!possible labels for each feature vector, so the perfor-mance of this classifier by chance would be .167 ifeach adverbial has on average three siblings.230Type Featureslexical preposition in this adverbial and in adverbial siblings 0-4; stems of lexical heads of this adverbial,its parent, non-adverbial siblings 0-4, and adverbial siblings 0-4; number of phonemes in lexicalhead of this adverbial and in lexical heads of adverbial siblings 0-4; number of words in thisadverbial and in adverbial siblings 0-4syntactic syntactic categories of this adverbial, its parent, non-adverbial siblings 0-4, and adverbial sib-lings 0-4; adverbial type of this adverbial and of adverbial siblings 0-4 (one of DIR, EXT, LOC,MNR, PRP, TMP, ADV); numbers of siblings, non-adverbial siblings, and adverbial siblingssemantic hypernyms of heads of this adverbial, its parent, non-adverbial siblings 0-4, and adverbial sib-lings 0-4; number of meanings for heads of this adverbial and adverbial siblings 0-4 (usingWordNet)sentence sequence of children of S node (e.g.
NP VP, VP); form of sentence (declarative, imperative,interrogative, clause-other); presence of the following in the sentence: coordinating conjunc-tion(s), subordinating conjunction(s), correlative conjunction(s), discourse cue(s) (e.g.
?how-ever?, ?therefore?
), pronoun(s), definite article(s)Table 3: Features used for determining adverbial positions.
We did not find phrases with more than 5 adverbial siblingsor more more than 5 non-adverbial siblings.
If a phrase did not have 5 adverbial or non-adverbial siblings, NA valueswere used in the features for those siblings.Two-stage For our two-stage classification-basedapproach, we first determine the position of each ad-verbial in a phrase in relation to its non-adverbialsiblings, and then the relative positions of adjacentadverbials.
For the first stage we use a classifier.There is one feature vector for each adverbial.
Itcontains features for all non-adverbial siblings in re-alization order, then for each adverbial sibling in al-phabetical order by lexical head, and finally for thetarget adverbial itself.
The label is the position ofthe target adverbial with respect to the non-adverbialsiblings.
For our example sentence in Figure 1, thelabel for ?Then?
would be 0; for ?at the bank?
wouldbe 2, and for ?on Tuesday?
would be 2.
If there are nnon-adverbial siblings, then there are n+1 possiblelabels for each feature vector, so the performance ofthis classifier by chance would be .25 if each adver-bial has on average three non-adverbial siblings.For the second stage we use the same second stageas the baseline approach.3.2 MethodWe use 10-fold cross-validation to compute perfor-mance of each approach.
For the classifiers, we usedthe J4 decision tree classifier provided by Weka1.We compute correctness for each approach as thepercentage of adverbials for which the approach out-puts the same position as that found in the original1We experimented with logistic regression and SVM classi-fiers; the decision tree classifier gave the highest performance.human-produced phrase.
(In some cases, multiplepositions for the adverbial would be equally accept-able, but we cannot evaluate this automatically.
)3.3 ResultsOur classification results are shown in Table 4.
Theone- and two-stage approaches both significantlyoutperform baseline.
Also, the two-stage approachoutperforms the one-stage approach for WSJ.The decision trees using all features are quitelarge.
We tried dropping feature sets to see if wecould get smaller trees without large drops in per-formance.
We found that for all data sets, themodels containing only syntactic features performonly about 1% worse for one-stage classification andonly about 3% worse for two-stage classification,while in most cases giving much smaller trees (1015[WSJ] and 972 [SWBD] nodes for the one-stage ap-proach; 1008 [WSJ] and 877 [SWBD] for the two-stage approach).
This is somewhat surprising givenCosta?s arguments about the need for lexical and dis-course features; it may be due to errors introducedby approximating discourse features automatically,as well as to data sparsity in the lexical features.There are only small performance differences be-tween the classifiers for speech and those for text.4 Realization ExperimentTo investigate how a model of adverbial position-ing may improve an NLP application, we incorpo-231Approach Tree Classification SSAsize accuracyWSJbaseline n/a 45.98 75.1one-stage 6519 84.43 82.2two-stage 1053 86.27 85.1SWBDbaseline n/a 41.48 61.3one-stage 4486 85.13 74.5two-stage 3707 85.01 73.1Table 4: Performance of adverbial position determinationrated our best-performing models into a surface re-alizer.
We automatically extracted a probabilisticlexicalized tree-adjoining grammar from the wholeWSJ and SWBD corpora minus our held-out data,using the method described in (Zhong and Stent,2005).
We automatically re-realized all adverbial-containing sentences in our held-out data (10%), af-ter first automatically constructing input using themethod described in (Zhong and Stent, 2005).We compute realization performance using sim-ple string accuracy (SSA)2.
Realization performanceis reported in Table 4.
Both classification-based ap-proaches outperform baseline, with the two-stageapproach performing best for WSJ with either met-ric (for SWBD, the classification-based approachesperform similarly).5 Conclusions and Future WorkIn this paper, we tested classification-based ap-proaches to adverbial positioning.
We showed thatwe can achieve good results using syntactic featuresalone, with small improvements from adding lexi-cal, semantic and sentence-level features.
We alsoshowed that use of a model for adverbial position-ing leads to improved surface realization.
In futurework, we plan a human evaluation of our results tosee if more features could lead to performance gains.6 AcknowledgmentsThis research was partially supported by the NSFunder grant no.
0325188.2Although in general we do not find SSA to be a reliablemetric for evaluating surface realizers, in this case it is validbecause lexical selection is done already; only the positions ofadverbials will generally be different.ReferencesD.
Allen and A. Cruttenden.
1974.
English sentence ad-verbials: Their syntax and their intonation in BritishEnglish.
Lingua, 34:1?30.J.
Burstein, M. Chodorow, and C. Leacock.
2004.
Auto-mated essay evaluation: The Criterion online writingservice.
AI Magazine, 25(3):27?36.J.
Clarke and M. Lapata.
2007.
Modelling compres-sion with discourse constraints.
In Proceedings ofEMNLP/CoNLL.J.
Costa.
2004.
A multifactorial approach to adverbplacement: assumptions, facts, and problems.
Lingua,114:711?753.M.
Elhadad, Y. Netzer, R. Barzilay, and K. McKeown.2001.
Ordering circumstantials for multi-documentsummarization.
In Proceedings of BISFAI.Thomas Ernst.
1984.
Towards an integrated theory ofadverb position in English.
Ph.D. thesis, Indiana Uni-versity, Bloomington, Indiana.H.
Haider.
2000.
Adverb placement.
Theoretical lin-guistics, 26:95?134.J.
Keyser.
1968.
Adverbial positions in English.
Lan-guage, 44:357?374.C.
Leacock.
2007.
Writing English as a secondlanguage: A proofreading tool.
In Proceedings ofthe Workshop on optimizing the role of language intechnology-enhanced learning.N.
Madnani, D. Zajic, B. Dorr, N. F. Ayan, and J. Lin.2007.
Multiple alternative sentence compressions forautomatic text summarization.
In Proceedings of theDocument Understanding Conference.T.
Marciniak and M. Strube.
2004.
Classification-based generation using TAG.
In Lecture Notesin Computer Science, volume 3123/2004.
SpringerBerlin/Heidelberg.M.
Marcus, B. Santorini, M. Marcinkiewicz, and A. Tay-lor.
1999.
Treebank-3.
Available from the LinguisticData Consortium, Catalog Number LDC99T42.K.
Ogura, S. Shirai, and F. Bond.
1997.
English ad-verb processing in Japanese-to-English machine trans-lation.
In Seventh International Conference on Theo-retical and Methodological Issues in Machine Trans-lation.E.
Ringger, M. Gamon, R. Moore, D. Rojas, M. Smets,and S. Corston-Oliver.
2004.
Linguistically informedstatistical models of constituent structure for orderingin sentence realization.
In Proceedings of COLING.H.
Zhong and A. Stent.
2005.
Building surface realiz-ers automatically from corpora using general-purposetools.
Proceedings of UCNLG.H.
Zhong and A. Stent.
2008.
A corpus-based compari-son of models for predicting ordering of prepositionalphrases.
In submission.232
