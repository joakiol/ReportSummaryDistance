D-Tree Substitution GrammarsOwen Rambow*AT&T Labs-ResearchDav id  Weir~University of SussexK.
V i jay -Shanker tUniversity of DelawareThere is considerable interest among computational linguists in lexicalized grammatical frame-works; lexicalized tree adjoining rammar (LTAG) is one widely studied example.
In this paper,we investigate how derivations in LTAG can be viewed not as manipulations of trees but asmanipulations of tree descriptions.
Changing the way the lexicalized formalism is viewed raisesquestions as to the desirability of certain aspects of the formalism.
We present anew formalism,d-tree substitution grammar (DSG).
Derivations in DSG involve the composition of d-trees,special kinds of tree descriptions.
Trees are read off rom derived -trees.
We show how the DSGformalism, which is designed to inherit many of the characterestics of LTAG, can be used to expressa variety of linguistic analyses not available in LTAG.1.
IntroductionThere is considerable interest among computational linguists in lexicalized grammati-cal frameworks.
From a theoretical perspective, this interest is motivated by the widelyheld assumption that grammatical structure is projected from the lexicon.
From a prac-tical perspective, the interest stems from the growing importance of word-based cor-pora in natural anguage processing.
Schabes (1990) defines a lexicalized grammar asa grammar in which every elementary structure (rules, trees, etc.)
is associated with alexical item and every lexical item is associated with a finite set of elementary struc-tures of the grammar.
Lexicalized tree adjoining grammar (LTAG) (Joshi and Schabes1991) is a widely studied example of a lexicalized grammatical formalism.
1In LTAG, the elementary structures of the grammar are phrase structure trees.Because of the extended omain of locality of a tree (as compared to a context-freestring rewriting rule), the elementary trees of an LTAG can provide possible syntacticcontexts for the lexical item or items that anchor the tree, i.e., from which the syntacticstructure in the tree is projected.
LTAG provides two operations for combining trees:substitution and adjunction.
The substitution operation appends one tree at a frontiernode of another tree.
The adjunction operation is more powerful: it can be used toinsert one tree within another.
This property of adjoining has been widely used in theLTAG literature to provide an account for long-distance dependencies.
For example,* ATT Labs-Research, B233 180 Park Ave, PO Box 971, Florham Park, NJ 07932-0971, USA.
E-mail:rambow@research.att.comt Department ofComputer and Information Science University of Delaware Newark, Delaware 19716.E-mail: vijay@udel.eduSchool of Cognitive and Computing Sciences University of Sussex Brighton, BN1 6QH E. Sussex UK.E-mail: david.weir@cogs.susx.ac.uk1 Other examples of lexicalized grammar formalisms include different varieties of categorial grammarsand dependency grammars.
Neither HPSG nor LFG are lexicalized in the sense of Schabes (1990).Computational Linguistics Volume 27, Number 1NP SPeter NP VPJohn V NPI Isaw efl: SNP VPyou V SIthoughtNP SPeter NP VPyou V Sthought NP VPI /NJohn V NPI Isaw eFigure 1Example of adjunction.Figure I shows a typical analysis of topicalization.
2 The related nodes for the filler andthe gap in the elementary tree c~ are moved further apart when the tree 7 is obtainedby adjoining the auxiliary tree fl within ~.
This shows that adjunction changes thestructural relationship between some of the nodes in the tree into which adjunctionoccurs.In LTAG, the lexicalized elementary objects are defined in such a way that thestructural relationships between the anchor and each of its dependents change duringthe course of a derivation through the operation of adjunction, as just illustrated.
Thisapproach is not the only possibility.
An alternative would be to define the relationshipsbetween the nodes of the elementary objects in such a way that these relationshipshold throughout the derivation, regardless of how the derivation proceeds.This perspective on the LTAG formalism was explored in Vijay-Shanker (1992)where, following the principles of d-theory parsing (Marcus, Hindle, and Fleck 1983),LTAG was seen as a system manipulating descriptions of trees rather than as a tree2 The same analysis holds for wh-movement, but we use topicalization as an example in order to avoidthe superficial complication of the auxiliary needed in English questions.
Sometimes, topicalizedsentences sound somewhat less natural than the corresponding wh-questions, which are alwaysstructurally equivalent.88Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsfl':NP SIPeterIISNP VPI 'JohnItVPV NPI Isaw eS O d :NP VPI 'Iyou VPV SIthoughtFigure 2Adjunction example revisited.NP SPeter NP VPI ' !you VPV Sthought NP VPI 'IJohn VPV NPI Isaw erewriting formalism.
Elementary objects are descriptions of possible syntactic ontextsfor the anchor, formalized in a logic for describing nodes and the relationships (dom-inance, immediate dominance, linear precedence) that hold between them.From this perspective, instead of positing the elementary tree ~ in Figure 1, we candescribe the projection of syntactic structure from the transitive verb.
This description ispresented pictorially as c~  in Figure 2.
The solid lines indicate immediate domination,whereas the dashed lines indicate a domination of arbitrary length.
The descriptiona ~ not only partially describes the tree c~ (by taking the dominations to be those oflength 0) but also any tree (such as "~) that can be derived by using the operationsof adjunction and substitution starting from c~.
In fact, (~t describes exactly what iscommon among these trees.By expressing elementary objects in terms of tree descriptions, we can describesyntactic structure projected from a lexical item in a way that is independent of thederivations in which it is used.
This is achieved by employing composition operationsthat produce descriptions that are compatible with the descriptions being combined.For instance, adjoining, seen from this perspective, serves to further specify the un-derspecified ominations.
In Figure 2, the description -y~ is obtained by additionallystating that the domination between the two nodes labeled S in c~  is now given bythe domination relation between the two nodes labeled S in fl~.As we will explore in this paper, changing the way the lexicalized formalism isviewed, from tree rewriting to tree descriptions, raises questions as to the desirability89Computational Linguistics Volume 27, Number 1SNP~ S NP VP' I ' !
!many of us VP John VPto meet NPi V VPI Ie hopesFigure 3A problem for LTAG.of certain aspects of the formalism.
Specifically, we claim that the following two aspectsof LTAG appear unnecessarily restrictive from the perspective of tree description:..In LTAG, the root and foot of auxiliary trees must be labeled by the samenonterminal symbol.
This is not a minor issue since it derives from oneof the most fundamental principles of LTAG, factoring of recursion.
Thisprinciple states that auxiliary trees express factored out recursion, whichcan be reintroduced via the adjunction operation.
It has had a profoundinfluence on the way that the formalism has been applied linguistically.
3An example of how this can create problems is shown in Figure 3.
In thiscase, the "adjoined" tree has a root labeled S and a foot labeled VP,something that is not permissible in LTAG.
Note that without hisconstraint, he combination would appear to be exactly like adjoining.We consider this aspect in more detail in Section 4.1.The adjunction operation embeds all of the adjoined tree within that partof the tree at which adjunction occurs.
This is illustrated in -y' (Figure 2)where both parts (separated by domination) of fl~ appear within oneunderspecified domination relationship in c~'.The foot node of tree fl in Figure 1 corresponds to a required argumentof the lexical anchor, thought.
The adjunction operation accomplishes therole of expanding this argument node.
Unlike the substitution operation,where an entire tree is inserted below the argument node, withadjunction, only a subtree of ~ appears below the argument node; theremainder appears in its entirety above the root node of ft.
However, ifwe view the trees as descriptions, as in Figure 2, and if we take theexpansion of the foot node as the main goal served by adjunction, it isnot clear why the composition should have anything to say about thedomination relationship between the other parts of the two objects beingcombined.
In the description approach, in order to obtain 3/we (in a3 Note that in feature-based LTAG there is no restriction that the two feature structures be the same, oreven that they be compatible.90Rambow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsPP S ,IiTo some of us VPV PPI Iappears eFigure 4Another problem for LTAG.VPSNP VPI ' I iJohn VPto be happysense to be made precise later) substitute the second component of ~(rooted in S) at the foot node of fl'.
This operation does not itself entailany further domination constraints between the components of ~P and fl~that are not directly involved in the substitution, specifically, the topcomponents of o /and fl'.
In the trees described it is possible for eitherone to dominate the other.
4However, adjunction further stipulates thatthe rest of ~' will appear above all of fl'.
This additional constraintmakes certain analyses unavailable for the LTAG formalism (as is wellknown).
For instance, given the two lexical projections in Figure 4, thesubtrees must be interleaved in a fashion not available with adjoining toproduce the desired result.
This aspect of adjoining is the focus of thediscussion in Section 4.2.In this paper, we describe a formalism based on tree descriptions called d-treesubstitution grammars (DSG).
5 The elementary tree descriptions in DSG can be usedto describe lexical items and the grammatical structure they project.
Each elementarytree description can be seen as describing two aspects of the tree structure: one part ofthe description specifies phrase structure rules for lexical projections, and a second partof the description states domination relationships between pairs of nodes.
DSG inheritsfrom LTAG the extended omain of locality of its elementary structures, and, in DSG asin LTAG, this extended omain of locality allows us to develop a lexicalized grammarin which lexical items project grammatical structure, including positions for arguments.But DSG departs from LTAG in that it does not include factoring of recursion asa constraint on the makeup of the grammatical projections.
Furthermore, in DSG,arguments are added to their head by a single operation that we call generalizedsubstitution, whereas in LTAG two operations are used: adjunction and substitution.DSG is intended to be a simple framework with which it is possible to provideanalyses for those cases described with LTAG as well as for various cases in whichextensions of LTAG have been needed, such as different versions of multicomponent4 Of course, the node labels further estrict possible dominance in this case.5 This paper is based on Rarnbow, Vijay-Shanker, and Weir (1995), where DSG was called DTG (d-treegrammar).91Computational Linguistics Volume 27, Number 1Z% {Xl ~ X2, {Ul ~ U2, Xl /k X3, ~3 U3 ~1 /k U3~ X2 -~ 3:3~ U2 "~ ~3~X3 '/~ Y l ,  I Iyl /k y2, I I Zl /~ Z2,Yl /X Y3' O~ O~ z l  /X za' y2 -~ Y3} z2 -~ z3}Y3 z3Figure 5A pair of tree descriptions (which are also d-trees).LTAG.
Furthermore, because the elementary objects are expressed in terms of logicaldescriptions, it has been possible to investigate the characteristics of the underspecifi-cation that is used in these descriptions (Vijay-Shanker and Weir 1999).In Section 2, we give some formal definitions and in Section 3 discuss some ofthe formal properties of DSG.
In Section 4, we present analyses in DSG for variouslinguistic constructions in several languages, and compare them to the correspondingLTAG analyses.
In Section 5, we discuss the particular problem of modeling syntacticdependency.
We conclude with a discussion of some related work and summary.2.
Def in i t ion of DSGD-trees are the primitive elements of a DSG.
D-trees are descriptions of trees, in partic-ular, certain types of expressions in a tree description language such as that of Rogersand Vijay-Shanker (1992).
In this section we define tree descriptions and substitutionof tree descriptions (Section 2.1) and d-trees (Section 2.2) together with some associ-ated terminology and the graphical representation (Section 2.3).
We then define d-treesubstitution grammars, along with derivations of d-tree substitution grammars (Sec-tion 2.4) and languages generated by these grammars (Section 2.5), and close with aninformal discussion of path constraints (Section 2.6).2.1 Tree Descr ipt ions and Subst i tut ionIn the following, we are interested in a tree description language that provides at leastthe following binary predicate symbols: A, /~, and -~.
These three predicate sym-bols are intended to be interpreted as the immediate domination, domination, andprecedence r lations, respectively.
That is, in a tree model, the literal x/~ y would beinterpreted as node (referred to by the variable) x immediately dominates node (re-ferred to by) y, the literal x/~ y would be interpreted such that x dominates y, andx -~ y indicates that x is to the left of y.
In addition to these predicate symbols, weassume there is a finite set of unary function symbols, such as label, which are to beused to describe node labeling.
Finally, we assume the language includes the equalitysymbol.We will now introduce the notion of tree description.Def in i t ionA tree descr ipt ion is a finite set (conjunction) of positive literals in a tree descriptionlanguage.In order to make the presentation more readable, tree descriptions are usually pre-sented graphically rather than as logical expressions.
Figure 5 gives two tree descrip-tions, each presented both graphically and in terms of tree descriptions.
We introduce92Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsx x3,p/Z3Y5Figure 6A tree description (which is also a d-tree) with three components.the conventions used in the graphical representations in more detail in Section 2.3.Note that with a functor for each feature, feature structure labels can be specified asrequired.
Although feature structures will be used in the linguistic examples presentedin Section 4, for the remainder of this section we will assume that each node is labeledwith a symbol by the function label.
Furthermore, we assume that these symbols comefrom two pairwise distinct sets of symbols, the terminal and nonterminal labels.
(Notethat the examples in this section do not show labels for nodes, but rather their names,while the examples in subsequent sections how the labels.
)In the following, we consider a tree description to be satisfiable if it is satisfiedby a finite tree model.
For our current purposes, we assume that a tree model will bedefined as a finite universe (the set of nodes) and will interpret the predicate symbols:G, ,~,, and -~ as the immediate domination, domination, and precedence relations,respectively.
For more details on the notion of satisfiability and the definition of treemodels, see Backofen, Rogers, and Vijay-Shanker (1995), where the axiomatization oftheir theory is also discussed.
6We use d ~ d ~ to indicate that the description d~ logically follows from d, in otherwords, that d ~ is known in d. 7 Given a tree description d, we say x dominates y in d ifd ~ x ,~ y (similarly for the immediate domination and precedes relations).We use vars(d) to denote the set of variables involved in the description d. Forconvenience, we will also call the variables in vars(d) the nodes of description d. For atree description d, a node x E vars(d) is a frontier node of d if for all y E vars(d) suchthat x # y, it is not the case that d =~ x ~ y.
Only frontier nodes of the tree descriptioncan be labeled with terminals.
A frontier node labeled with a nonterminal is called asubst i tut ion node.A useful notion for tree description is the notion of components.
Given a treedescription d, consider the binary relation on vars(d) corresponding to the immediatedomination relations pecified in d; i.e., the relation {(x, Y/ I x, Y E vars(d), d =~ x A y}.The transitive, symmetric, reflexive closure of this relation partitions vars(d) into equiv-alence classes that we call components.
For example, the nodes in the tree descrip-tion in Figure 6 fall into the three components: { Xl, x2, x3, x4, x5 }, { yl, y2, y3, y4, Y5 },and { zl,z2, Zg, Z4,Z5 }- In particular, note that y4 and Zl (likewise x3 and z2) are notin the same components despite the fact that y4 dominates zl is known in that de-6 Note that the symbol /~ in this paper replaces the symbol/~* used in Backofen, Rogers, andVijay-Shanker (1995).7 In other words, d =~ d ~ iff d A ~d ~ is not satisfied by any tree model.93Computational Linguistics Volume 27, Number 10 3 : ~{Xl  t 2:2~x l  /k x3, OFX2 ~ X 33:2 "~ X3~ Ix3/h Yl, IYl /k y2,y2 "< Ul,Ul \]~ U2~ I?1Ul t u3,  ~U 2 0153I/,2 "~ u3'//'2 \]~' Zl ~ !
IZl \]~ Z2 ~ IZl t z3, Z~Z 1z2 "~ Z3}Z3Figure 7Result of substitution by tree description root.scription.
This is because the reflexive, symmetric, and transitive closure of the im-mediate domination relation known in the description will not include these pairsof nodes.We say that x is the root of a component  if it dominates every node in its com-ponent, and we say that x is on the frontier of a component if the only node in itscomponent that it dominates i  itself.
Note that x can be on the frontier of a componentof d without being a frontier node of a tree description.
For example, in Figure 6, x3is a frontier of a component but not a frontier of the tree description.
In contrast, z3 isboth a frontier of a component as well as a frontier of the tree description.
We say thatx is the root of a tree descr ipt ion if it dominates every node in the tree description.Note that it need not be the case that every tree description has a root.
For example,according to the definition of tree descriptions, the description in Figure 6 is a tree de-scription and does not have a root.
Although we know that either xl or Yl dominatesall nodes in a tree model of the tree description, we don't know which.We can now define the subst i tut ion operat ion on tree descr ipt ions that will beused in DSG.
We use dl \[y/x\] to denote the description obtained from dl by replacingall instances in dl of the variable x by y.Def in i t ionLet dl and d2 be two tree descriptions.
Without loss of generality, we assume thatvars(dl) N vars(d2) = ?.
Let x E vars(dl) be a root of a component of dl andy E vars(d2) be a substitution ode in the frontier of d2.
Let d be the descriptiondl kJ d2\[x/y\].
We say that d is obtained from dl and d2 by subst i tut ing x at y.Note that in addition, we may place restrictions on the values of the labelingfunctions for x and y in the above definition.
Typically, for a node labeling function suchas label we require label(x) = label(y), and for functions that return feature structureswe require unifiability (with the unification being the new value of the feature functionfor y).Figure 7 shows the result of substituting the root Ul of the tree description onthe right of Figure 5 at the substitution ode Y3 of the tree description on the left ofFigure 5.Figure 8 shows the result of substituting a node that is not the root of the tree94Rambow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsXl \]~ .T2~Xl /'x X3,x3 ~ y~, ~X2 N~ x3 c~t  ,Yl A y~, .
/ 'c 4 Yl fk Zl, I q) U 2 O '//3Y2 "~ Zl, I IUl \]k U2~ ~ Y l  iUl ~ U3~u2 -~ ua, (5 Y2 ~Y3:  zlU2 /~ Zl~Zl /k Z2, (9 Z2 (9 Z3zl /k z3,z2 ~ z3}Figure 8Result of substitution by component root.description but the root Zl of a component of the tree description on the right of Figure 5at the substitution ode y3 of the tree description on the left of Figure 5.2.2 D-TreesD-trees are certain types of tree descriptions: not all tree descriptions are d-trees.
Indescribing syntactic structure, we are interested in two kinds of primitive tree de-scriptions.
The first kind of primitive tree description, which we call parent-childdescriptions, involves n + 1 (n _> 1) variables, say x, xl,.
?., Xn, and in addition to spec-ifying categorial information associated with these variables, specifies tree structure ofthe form{X & I1 .
.
.
.
.
X A Xn, Xl "g X2 .
.
.
.
.
Xn-1 "?, Xn}A parent-child escription corresponds to a phrase structure rule in a context-freegrammar, and by extension, to a phrase structure rule in X-bar theory, to the instanti-ation of a rule schema in HPSG, or to a c-structure rule in LFG.
As in a context-freegrammar, in DSG we assume the siblings Xl , .
.
.
,  Xn are totally ordered by precedence, sThe second kind of primitive description, which we call a dominat ion description,has the form {x & y}, where x and y are variables.
In projecting from a lexical item toobtain the elementary objects of a grammar, this underspecified domination statementallows for structures projected from other lexical items to be interspersed during thederivation process.Definit ionA d-tree is a satisfiable description in the smallest class of tree descriptions obtainedby closing the primitive tree descriptions under the substitution operation.For example, Figure 9 shows how the d-tree in Figure 6 is produced by usingsix parent-child escriptions and two domination descriptions.
The ovals show casesof substitution; the circle represents a case of two successive substitutions.
Figure 10shows a tree description that is not a d-tree: it is not a parent-child escription, nor8 One could, of course, relax this constraint and assume that they are only partially ordered.
However,for now, we do not consider such an extension.
See Section 4.4 for a discussion.95Computational Linguistics Volume 27, Number 1~g4X5 IX3Y2Y5,sJJ2:4| fZ3Figure 9Derivation of an elementary d-tree.
{x & y, o.x6y "o zy -~ z}Figure 10A description that is not a d-tree.Y~can it be derived from two domination descriptions by substitution, since substitutioncan only occur at the frontier nodes.A d-tree d is complete if it does not contain any substitution odes, i.e., all thefrontier nodes of the description d are labeled by terminals.
Given a d-tree d, we saythat a pair of nodes, x and y (variables in vars(d)), are related by an i-edge if d ::~ xAy .We say that x is an i-parent and y is an i-child.
Given a d-tree d, we say that a pair ofnodes, x and y, are related by a d-edge if it is known from d that x dominates y, it isnot known from d that x immediately dominates y, and there is no other variable in dthat is known to be between them.
That is, a pair of nodes x and y, x ~ y, are relatedbyad-edge i fd  ~ x~y,d  ~ xGy,  and for a l l z  E vars(d), i fd ~ (x&zAz~y)then z = x or z = y.
If x and y are related by a d-edge, then we say that they ared-parent and d-child, respectively.
Note that a node in a d-tree (unlike a node in atree description) cannot be both an i-parent and a d-parent at the same time.2.3 Graphical Presentation of a D-TreeWe usually find it more convenient to present d-trees graphically.
When presenting ad-tree graphically, i-edges are represented with a solid line, while d-edges are repre-sented with a broken line.
All immediate dominance relations are always representedgraphically, but only the domination relations corresponding to d-edges are shownexplicitly in graphical presentations.By definition of d-trees, each component of a d-tree is fully specified with respectto immediate domination.
Thus, all immediate domination relations between nodesin a component are indicated by i-edges.
Also, by definition, components must befully specified with respect o precedence.
That is, for any two nodes u and v within96Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsa component we must know whether u precedes v or vice versa.
In fact, all prece-dence information derives from precedence among siblings (two nodes immediatelydominated by a common node).
This means that all the precedence in a descriptioncan be expressed graphically simply by using the normal left-to-right ordering amongsiblings.Another important restriction on d-trees has to do with how components are re-lated to one another.
As we said above, a frontier node of a component of a d-treecan be a d-parent but not an i-parent, and only frontier nodes of a component canserve as d-parents.
However, by definition, a frontier node of a d-tree can neither be ad-parent nor an i-parent.
Graphically, this restriction can be characterized as follows:edges specifying domination (d-edges) must connect a node on the frontier of a com-ponent with a node of another component.
Furthermore, nodes on the frontier of acomponent can have at most one d-child.Recall that not every set of positive literals involving A, /~, and -~ is a legal d-tree.In particular, we can show that a description is a d-tree if and only if it is logicallyequivalent to descriptions that, when written graphically, would have the appearancedescribed above.2.4 D-Tree Substitution GrammarsWe can now define d-tree substitution grammars.DefinitionA d-tree substitution grammar (DSG) G is a 4-tuple (VT, VN, T, ds), where VT andVN are pairwise distinct terminal and nonterminal alphabets, respectively, T is afinite set of elementary d-trees such that the functor label assigns each node ineach d-tree in T a label in VT U VN and such that only d-tree frontier nodes takelabels in VT, and ds is a characterization f the labels that can appear at the rootof a derived tree.Derivations in DSG are defined as follows.
Let G = (VT, VN, T, ds) be a DSG.Furthermore:?
Let T0(G) --- T.?
Let Ti+I = Ti U {d\[d is satisfiable and d results from combining a pair ofd-trees in Ti by substitution at a node x such that label(x) c VN}.The d-tree language T(G) generated by G is defined as follows.T (G)={dcT i l i>0 ,  d i scomplete}In a lexicalized DSG, there is at least one terminal node on the frontier of everyd-tree; this terminal is (these terminals are) designated the anchor(s) of the d-tree.The remaining frontier nodes (of the description) and all internal nodes are labeled bynonterminals.
Nonterminal nodes on the frontier of a description are called substitutionnodes because these are nodes at which a substitution must occur (see below).
Finally,we say that a d-tree d is sentential if d has a single component and the label of theroot of d is compatible with ds.2.5 Reading D-TreesA description d is a tree if and only if it has a single component (i.e., it does not haveany d-edges).
Therefore, the process of reading off trees from d-trees can be viewed as97Computational Linguistics Volume 27, Number 1a nondeterministic process that involves repeatedly removing d-edges until a d-treewith a single component results.In defining the process of removing a d-edge, we require first, that no i-edgesbe added which are not already specified in the components, and second, that thosei-edges that are distinct prior to the process of reading off remain distinct after theremoval of the d-edges.
This means that each removal of a d-edge results in equatingexactly one pair of nodes.
These requirements are motivated by the observation thatthe i-edges represent linguistically determined structures embodied in the elementaryd-trees that cannot be created or reduced uring a derivation.We now define the d-edge removal algorithm.
A d-edge represents a dominationrelation of length zero or more.
Given the above requirements, at the end of thecomposition process, we can, when possible, get a minimal reading of a d-edge tobe a domination relation of length zero.
Thus, we obtain the following procedure forremoving d-edges: Consider ad-edge with a node x as the d-parent and with a d-childy.
By definition of d-trees, x is on the frontier of a component.
The d-child y can eitherbe a root of a component or not.
Let us first consider the case in which y is a root ofa component.
To remove this d-edge, we equate x with y.9 This gives us the minimalreading that meets the above requirement ( hat no i-edges are added which are notalready specified in the components, and that those i-edges that are distinct prior tothe process of reading off remain distinct after the removal of the d-edge).
Now weconsider the alternate case in which the d-child is not the root of its component.
Let zbe the root of the component containing y.
Now both z and x are known to dominatey and hence in any model of the description, either z will dominate x or vice versa.Equating x with y (the two nodes in the d-edge under consideration) has the potentialof requiring the collapsing of i-edges (e.g., i-edges between x and its parent and y andits parent in the component including z).
As a consequence of our requirement, theonly way to remove the d-edge is by equating the nodes x and z.
If we equated xwith any other node dominated by z (such as y), we would also be collapsing i-edgesfrom two distinct components and equating more than one pair of nodes, contrary toour requirement.
The removal of the d-edge by equating x and z can also be viewedas adding a d-edge from x to z (which, as mentioned, is compatible with the givendescription and does not have the potential for collapsing i-edges).
Now since this d-edge is between a frontier of a component and the root of another, it can be removedby equating the two nodes.DefinitionA tree t can be read off from a d-tree d iff t is obtained from d by removing the d-edgesof d in any order using the d-edge removal algorithm.By selecting d-edges for removal in different orders, different rees can be pro-duced.
Thus, in general, we can read off several trees from each d-tree in T(G).
Forexample, the d-tree in Figure 6 can produce two trees: one rooted in xl (if we chooseto collapse the edge between y4 and zl first) and one rooted in yl (if we choose to col-lapse the edge between x3 and z2 first).
The fact that a d-tree can have several minimalreadings can be exploited to underspecify different word orderings (see Section 4.4).9 This additional equality to obtain the minimal  readings is similar to unification of the so-called top andbottom feature structures associated with a node in tree adjoining grammars,  which happens at the endof a derivation.
In DSG, if the labeling specifications on x and y are incompatible, then the addit ionalequality statement does not lead to any minimal  tree model, just as in TAG, a derivation cannotterminate if the top and bottom feature structures associated with a node do not unify.98Rambow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsThus, while a single d-tree may describe several trees, only some of these treeswill be read off in this way.
This is because of our assumptions about what is beingimplicitly stated in a d-tree--for example, our requirement that i-edges can be neitherdestroyed nor created in a derivation.
Assumptions uch as these about the implicitcontent of d-trees constitute a theory of how to read off from d-trees.
Variants of theDSG formalism can be defined, which differ with respect o this theory.We now define the tree and string languages of a DSG.DefinitionLet G be a DSG.
The tree language T(G) generated by G is the set of trees that can beread off from sentential d-trees in T(G).DefinitionThe string language generated by G is the set of terminal strings on the frontier oftrees in T(G).2.6 DSG with Path ConstraintsIn DSG, domination statements are used to express domination paths of arbitrarylength.
There is no requirement placed on the nodes that appear on such paths.
In thissection, we informally define an extension to DSG that allows for additional statementsconstraining the paths.Path constraints can be associated with domination statements o constrain whichnodes, in terms of their labels, can or cannot appear within a path instantiating ad-edge.
1?
Path constraints do not directly constrain the length of the domination path,which still remains underspecified.
Path constraints are specified in DSG by associat-ing with domination statements a set of labels that defines which nodes cannot appearwithin this path.
u Suppose we have a statement x A y with an associated path con-straint set, P, then logically this pair can be understood as x A y A Vz(z ~ x A z y~y AxAzAzA y) ~ label(z) ~P.Note that during the process of derivation involving substitution, the dominationstatements in the two descriptions being composed continue to exist and do not playany role in the composition operation itself.
The domination statements only affectthe reading off process.
For this reason, we can capture the effect of path constraintsby merely defining how they affect the reading off process.
Recall that the reading offprocess is essentially the elimination of d-edges to arrive at a single component d-tree.If there is a d-edge between x and y, we consider two situations: is the d-child y theroot of a component, or not?
When y is the root of a component, then x and y arecollapsed.
Clearly any path constraint on this d-edge has no effect.
However, when yis not the root of a component, and z is the root of the component containing y, thenthe tree we obtain from the reading off process is one where x dominates z and notwhere z properly dominates x.
That is, in this case, we replace the d-edge betweenx and y with a d-edge between x and z, which we then eliminate in the reading offprocess by equating x and z.
But in order to replace the d-edge between x and y witha d-edge between x and z, we need to make sure that the path between z and y doesnot violate the path constraint associated with the d-edge between x and y.10 In Rambow, Vijay-Shanker, and Weir (1995), path constraints are called "subsertion-insertionconstraints.
"11 Rambow (1996) uses regular expressions to specify path constraints.99Computational Linguistics Volume 27, Number 1A Aa A a AI II I, oB Bb B b BI I!
Ii iC Ce 6'Figure 11Counting to three: A derivation.Aa BIIiB/Nb CiIiCC3.
Properties of the Languages of DSGIt is clear that any context-free language can be generated by DSG (a context-freegrammar can simply be reinterpreted as a DSG).
It is also easy to show that the weakgenerative capacity of DSG exceeds that of context-free grammars.
Figure 11 showsthree d-trees (including two copies of the same d-tree) that generate the non-context-free language { anb'c" In > 1 }.
Figure 12 shows the result of performing the first oftwo substitutions indicated by the arrows (top) and the result of performing bothsubstitutions (bottom).
Note that although there are various ways that the dominationedges can be collapsed when reading off trees from this d-tree, the order in whichwe collapse domination edges is constrained by the need to consistently label nodesbeing equated.
This is what gives us the correct order of terminals.Figure 13 shows a grammar for the language{ w E { a, b, c }* \] w has an equal nonzero number of a's, b's and c's },which we call Mix.
This grammar is very similar to the previous one.
The only differ-ence is that node labels are no longer used to constrain word order.
Thus the domi-nation edges can be collapsed in any order.Both of the previous two examples can be extended to give a grammar for stringscontaining an equal number of any number of symbols imply by including additionalcomponents in the elementary d-trees for each symbol to be counted.
Hence, DSGgenerates not only non-context-free languages but also non-tree adjoining languages,since LTAG cannot generate the language { anbncndnen i n _~ 1 } (Vijay-Shanker 1987).However, it appears that DSG cannot generate all of the tree adjoining languages,and we conjecture that the classes are therefore incomparable (we offer no proof ofthis claim in this paper).
It does not appear to be possible for DSG to generate thecopy language { ww \[ w c { a, b }* }.
Intuitively, this claim can be motivated by theobservation that nonterminal labels can be used to control the ordering of a boundednumber of terminals (as in Figure 12), but this cannot be done in an unbounded way,as would be required for the copy language (since the label alphabet is finite).100Rainbow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsA Aa A a At II Io nB Bb B b B!
/o /c 6'c 6'A A Aa A a A a BI I !I I Ii n iB B Bb B b B b C| d / / tI / .
, .
II /C / ., / t/ 1 1 /f /s jiie CICFigure 12Counting to three: After substituting one tree (above) and the derived d-tree (below).DSG is closely related (and weakly equivalent) to two equivalent string rewritingsystems, UVG-DL and {}-LIG (Rainbow 1994a, 1994b).
In UVG-DL, several context-free rewrite rules are grouped into a set, and dominance links may hold between101Computational Linguistics Volume 27, Number 1S S S Sa S b S c S a SS <S Sb S c S:" SI?Sa SS S S S Sb S c S a S b S c SSIFigure 13A grammar for Mix.right-hand-side nonterminals and left-hand-side nonterminals of different rules fromthe same set.
In a derivation, the context-free rules are applied as usual, except hat allrules from an instance of a set must be used in the derivation, and at the end of thederivation, the dominance links must correspond to dominance relations in the deriva-tion tree.
{}-LIG is a multisebvalued variant of Linear Index Grammar (Gazdar 1988).UVG-DL and {}-LIG, when lexicalized, generate only context-sensitive languages.Finally, Vijay-Shanker, Weir, and Rainbow (1995), using techniques developed forUVG-DL (Rainbow 1994a; Becker and Rambow 1995), show that the languages gen-erated by lexicalized DSG can be recognized in polynomial time.
This can be shownwith a straightforward extension to the usual bottom-up dynamic programming algo-rithm for context-free grammars.
In the DSG case, the nonterminals in the chart arepaired with multisets.
The nonterminals are used to verify that the immediate dom-inance relations (i.e., the parent-child escriptions) hold, just as in the case of CFG.The multisets record the domination descriptions whose lower (dominated) node hasbeen found but whose upper (dominating) node still needs to be found in order forthe parse to find a valid derivation of the input string (so-called open dominationdescriptions).
The key to the complexity result is that the size of the multisets is lin-early bounded by the length of the input string if the grammar is lexicalized, and thenumber of multisets of size n is polynomial in n. Furthermore, if the number of opendomination descriptions in any chart entry is bounded by some constant independent102Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsof the length of the input string (as is plausible for many natural anguages includingEnglish), the parser performs in cubic time.4.
Some Linguistic Analyses with DSGIn Section 1, we saw that the extended omain of locality of the elementary structuresof DSG--which DSG shares with LTAG--allows us to develop lexicalized grammarsin which the elementary structures contain lexical items and the syntactic structurethey project.
There has been considerable research in the context of LTAG on the is-sue of how to use the formalism for modeling natural anguage syntax--we mentionas salient examples XTAG-Group (1999), a wide-coverage grammar for English, andFrank (1992, forthcoming), an extensive investigation from the point of view of theo-retical syntax.
Since DSG shares the same extended omain of locality as LTAG, muchof this research carries over to DSG.
In this section, we will be presenting linguis-tic analyses in DSG that follow some of the elementary principles developed in thecontext of LTAG.
We will call these conventions the standard LTAG practices andsummarize them here for convenience.?
Each elementary structure contains a lexical item (which can bemultiword) and the syntactic structure it projects.?
Each elementary structure for a syntactic head contains yntacticpositions for its arguments.
(In LTAG, this means substitution or footnodes; in DSG, this means substitution odes.)?
When combining two elementary structures, a syntactic relation betweentheir lexical heads is established.
For example, when substituting theelementary structure for lexical item ll into an argument position of theelementary structure for lexical item 12, then ll is in fact an argumentof 12.In Section 1 we also saw that the adjoining operation of LTAG has two propertiesthat appear arbitrary from a tree description perspective.
The first property is therecursion requirement, which states that the root and foot of an auxiliary tree mustbe identically labeled.
This requirement embodies the principle that auxiliary treesare seen as factoring recursion.
The second property, which we will refer to as thenesting property of adjunction, follows from the fact that the adjoining operationis not symmetrical.
All the structural components projected from one lexical item(corresponding to the auxiliary tree used in an adjoining step) are included entirelybetween two components in the other projected structure.
That is, components of onlyone of the lexically projected structures can get separated in an adjoining step.In this section, we examine some of the ramifications of these two constraintsby giving a number of linguistic examples for which they appear to preclude theformulation of an attractive analysis.
We show that the additional flexibility inherent inthe generalized substitution operation is useful in overcoming the problems that arise.4.1 Factoring of RecursionWe begin by explaining why, in LTAG, the availability of analyses for long-distancedependencies is limited by the recursion requirement.
Normally, substitution is usedin LTAG to associate a complement to its head, and adjunction is used to associatea modifier.
However, adjunction rather than substitution must be used with com-plements involving long-distance dependencies, e.g., in wh-dependencies and raising103Computational Linguistics Volume 27, Number 1SNP~ S NP VPI Imany of us S John VPNP VP V SPRO VP hopesto meet NPiIeFigure 14S-analysis for extraction from infinitival complements.constructions.
Such auxiliary trees are called predicative auxiliary trees.
12 In a pred-icative auxiliary tree, the foot node should be one of the nonterminal nodes on thefrontier that is included ue to argument requirements of the lexical anchor of the tree(as determined by its active valency).
However, the recursion requirement means thatall frontier nonterminal nodes that do not have the same label as the root node mustbe designated as substitution nodes, which may mean that no well-formed auxiliarytree can be formed.Let us consider again the topicalized sentence used as an example in Section 1,repeated here for convenience:(1) Many of us, John hopes to meetA possible analysis is shown in Figure 3 in Section 1.
We will refer to this anal-ysis as the VP-complement analysis.
Note that the individual pieces of the structuresprojected from lexical items follow standard LTAG practices.
Because of the recursionrequirement, the tree on the right is not (a description of) an auxiliary tree.
To obtainan auxiliary tree in order to give a usual TAG-style account of long-distance depen-dencies, the complement of the equi-verb (control verb) hopes must be given an S label,which in turn imposes a linguistic analysis using an empty (PRO) subject as shownin Figure 14 (or, at any rate, an analysis in which the infinitival to meet projects to S).The VP-complement analysis has been proposed within different frameworks, andhas been adopted as the standard analysis in HPSG (Pollard and Sag 1994).
However,because this would require an auxiliary tree rooted in S with a VP foot node, therecursion requirement precludes the adoption of such an analysis in LTAG.
We are12 This term is from Schabes and Shieber (1994).
Kroch (1987) calls such trees complement auxiliary trees.104Rainbow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsNPi S/ / x , ,x  ' I Ii iJohn PP VPP NPi V NP PPI Ito e gave the bookFigure 15HPSG analysis of give expressed as trees.SNP VPIPeternot suggesting that one linguistic analysis is better than another, but instead we pointout that the formal mechanism ofLTAG precludes the adoption of certain linguisticallymotivated analyses.
Furthermore, this mechanism akes it difficult to express entiregrammars originally formulated in other formalisms in LTAG; for example, whencompiling a fragment of HPSG into TAG (Kasper et al 1995).
In fact, the compilationproduces tructures just like those (described) in Figure 3.
Kasper et al (1995) considerthe tree on the right of Figure 3 to be an auxiliary tree with the VP sibling of the anchordetermined tobe the foot node.
Technically, the tree on the right of Figure 3 caimot bean auxiliary tree.
Kasper et al (1995) overcome the problem by making the node labela feature (with all nodes having a default label of no significance).
This determinationof the foot node is independent of the node labels of the frontier nodes.
Instead, thefoot node is chosen because it shares certain crucial features (other than label!)
withthe root node.
These shared features are extracted from the HPSG rule schema ndare used to define the localization of dependencies in the compiled TAG grammar.
SeeKasper et al (1995) for details.A similar example involves analyses for sentences such as (2), which involve ex-traction from argument PPs.
(2) John, Peter gave the book toFigure 15 shows the structures obtained by using the method of Kasper et al (1995)for compiling an HPSG fragment to TAG-like structures.
In contrast to traditional TAGanalyses (in which the elementary tree contains the preposition and its PP, with theNP complement of the preposition as a substitution ode), the PP argument of theditransitive verb is not expanded.
~3Instead the PP tree anchored by the prepositionis substituted.
However, because of the extraction, DSG's notion of substitution ratherthan LTAG substitution would need to be used.These examples uggest hat the method for compiling an HPSG fragment intoTAG-like structures discussed in Kasper et al (1995) can be simplified by compilingHPSG to a DSG-like framework.13 Recall that we are not, in this section, advocating one analysis over another; rather, we are discussingthe range of options available to the syntactician working in the TAG framework.105Computational Linguistics Volume 27, Number 1NPi S / , , ,  ,IiThis painting NPDET KIa N PPcopy PIolFigure 16Extraction from picture-NPs.SNP VPI ' I iJohn VPV NPIboughtNP~IeWe have shown a number of examples where some, but not all, of the possiblelinguistic analyses can be expressed in LTAG.
It could be claimed that a formal frame-work limiting the range of possible analyses constitutes a methodological dvantagerather than a disadvantage.
However, as is well known, there are several other exam-ples in English syntax where the factoring of recursion requirement in fact eliminatesall plausible LTAG analyses.
The only constraint assumed here is that extraction islocalized in elementary trees.
One such example in English is extraction out of a "pic-ture-NP" (a noun which takes a prepositional complement from which extraction i tothe main sentence is possible), as illustrated in the following example:(3) This painting, John bought a copy ofFollowing the standard LTAG practices, we would obtain the structures describedin Figure 16.
As these descriptions show, the recursion constraint means that adjoiningcannot be used to provide this analysis of extraction out of NPs.
See Kroch (1989) forvarious examples of such constructions in English and their treatment using an exten-sion of TAG called multicomponent tree adjoining rammars.
(We return to analysesusing multicomponent TAG in Section 4.2.
)However, we now show that all of these cases can be captured uniformly withgeneralized substitution (see Figure 17).
The node labeled X in fl arises due to theargument requirements of the anchor (the verb) and when X = S, fl is a predica-tive auxiliary tree in LTAG.
The required derived phrase structure in these cases isdescribed by 7.
To obtain these trees, it would suffice to simply substitute the compo-nent rooted in X of c~ at the node labeled X in ft.
While in general, such a substitutionwould not constrain the placement of the upper component of t ,  because of the labelsof the relevant nodes, this substitution will always result in % The use of substitutionat argument nodes not only captures the situations where adjoining or multicompo-106Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsg t :  S v gYPi S NP VP YPi S!
Ii iX VP NP VPV X V XJeeFigure 17General case of extraction.nent adjoining is used for these examples, it also allows the DSG treatment to beuniform, and is applicable ven in cases where there is no extraction (e.g., the uppercomponent of a is not present).We end this discussion of the nature of foot nodes by addressing the questionof how the choice of foot nodes limits illicit extractions.
In the TAG approach, thedesignation of a foot node specifically rules out extraction from any structure thatgets attached to any other frontier node (other arguments), or from structures thatare adjoined in (adjuncts).
However, as has been pointed out before (Abeill6 1991), thechoice of foot nodes is not always determined by node labels alone, for example in thepresence of sentential subjects or verbs such as ddduire, which can be argued to havetwo sentential objects.
In these cases some additional linguistic riteria are needed inorder to designate the foot node.
These same linguistic riteria can be used to designatefrontier nodes from which extraction is possible; extraction can be regulated throughthe use of features.
We also note that in moving to a multicomponent TAG analysis, anadditional regulatory mechanism becomes necessary in any case to avoid extractionsout of subjects (and, to a lesser degree, out of adjuncts).
We refer the interested readerto Rainbow, Vijay-Shanker, and Weir (1995) and Rambow and Vijay-Shanker (1998) fora fuller discussion.4.2 Interspersing of ComponentsWe now consider how the nesting constraint of LTAG limits the TAG formalism as adescriptive device for natural language syntax.
We contrast this with the case of DSG,which, through the use of domination in describing elementary structures projectedfrom a lexical item, allows for the interleaving of components projected from lexicalitems during a derivation.Consider the raising example introduced in Section 1 repeated here as (4a), alongwith its nontopicalized version (4b), which indicates a possible original position for107Computational Linguistics Volume 27, Number 1gPPi S /, , , ,  ,IiTo many of us VPSI ' I tJohn VPV PP VP to be happyI Iappears eFigure 18Topicalization out of the clause of a raising verb.the topicalized phrase) 4(4) a.
To many of us, John appears to be happyb.
John appears to many of us to be happyFollowing standard LTAG practices of localizing argument structure (even in thepresence of topicalization) and the standard LTAG analysis for the raising verb appear,the descriptions shown in Figure 18 could be proposed.
Because of the nesting propertyof adjunction, the interleaving required to obtain the relevant phrase structure for thesentence (4a) cannot be realized using LTAG with the assumed lexical projections (orany other reasonable structures where the topicalized PP and the verb appear are inthe same projected structure).
In contrast, with these projections, using generalizedsubstitution in DSG (i.e., equating the VP argument node of the verb and the root ofthe infinitival VP), the only possible derived tree is the desired one.We will now consider an example that does not involve a wh-type dependency:(5) Didn't John seem to like the gift?Following the principles laid out in Frank (1992) for constructing the elementarytrees of TAG, we would obtain the projections described in Figure 19 (except for thenode labels).
Note in particular the inclusion of the auxiliary node with the cliticizednegation marker in the projection of the raising verb seem.
Clearly the TAG opera-tions could never yield the necessary phrase structure given this localization.
Onceagain, the use of generalized substitution in DSG would result in the desired phrasestructure.An alternative to the treatment in Frank (1992) is implemented in the XTAG gram-mar for English (XTAG-Group 1999) developed at the University of Pennsylvania.
TheXTAG grammar does not presuppose the inclusion of the auxiliary in the projectionof the main verb.
Rather, the auxiliary gets included by separately adjoining a tree14 Throughout this section, we underline the embedded clause with all of its arguments, such as here, theraised subject.108Rainbow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsIDidn'tV VPIseemFigure 19Raising verb with a fronted auxiliary.S SI I I i iVP John VPto like the giftprojected from the auxiliary verb.
The adjunction of the auxiliary is forced througha linguistically motivated system of features.
A treatment such as this is needed toavoid using multicomponent adjoining.
In our example, the auxiliary, along with thenegation marker, is adjoined into the tree projected by the embedded verb l ike, whichmay be considered undesirable since semantically, it is the matrix verb seem that isnegated.
We take this example to show once more that TAG imposes restrictions onthe linguistic analyses that can be expressed in it.
Specifically, there are constructions(which do not involve long-distance phenomena) for which one of the most widelydeveloped and comprehensive theories for determining the nature of localization inelementary trees--that of Frank (1992)---calmot be used because of the nature of theTAG operation of adjunction.
In contrast, the operations of DSG allow this theory ofelementary lexical projections to be used.In English, the finite verb appears before the subject only in questions (and insome other contexts uch as neg-inversion), but in other languages, this word orderis routine, leading to similar problems for an LTAG analysis.
In V1 languages uchas Welsh, the subject appears in second position after the finite verb in the standarddeclarative sentence.
The raised subject behaves in the same manner as the matrixsubject, as observed in Harley and Kulick (1998) and illustrated in (6), from Hen-drick (1988):(6) a. MaeIsJohnb.
MaeIsJohnSi6n yn gweld MairJohn seeing Maryis seeing MarySi6n yn digwydd bod yn gweld MairJohn happening be seeing Maryhappens to be seeing MaryIn German, a V2 language, the finite verb appears in second position in matrixclauses.
The first position may be occupied by any constituent (not necessarily thesubject).
When the subject is not in initial position, it follows the finite verb, both in109Computational Linguistics Volume 27, Number 1SNP VPI 'JohnNPi SIi, Which bridge VPuI VP PPvI P NPisleep I IFigure 20Licit extraction from an adjunct in English.under esimplex sentences and in raising constructions:(7) a. Leider wird es standig regnenunfortunately will itNOM continually rainUnfortunately, it will rain continuallyb.
Oft schien e_~s uns st~indig zu regnenoften seemed itNo M USDA w continually to rainOften it seemed to us to rain continuallyIn the German example, a separate adjunction of the tensed verb (as in the XTAGanalysis of the English auxiliary) is not a viable analysis at all, since the tensed verbis not an auxiliary but the main (raising) verb of the matrix clause.We now return to examples that do not include raising, but only wh-dependencies.
(8) a. John slept under the bridgeb.
Which bridge did John sleep under?Most LTAG analyses would treat he prepositional phrase in (8a) as an adjunct anduse an intransitive frame for the verb.
However, the related sentence (8b) cannot beanalyzed with TAG operations in the same way, because the projected structures fromthe verb and the preposition would have to be as shown in Figure 20.
The interspersingof components from these projections to obtain the desired tree cannot be obtainedusing adjoining.
Clearly, with the appropriate generalized substitutions in DSG, thistree alone will be derived with these lexical projections.Related problems arise in languages in which a wh-moved element does not in-variably appear in sentence-initial position, as it does in English.
For example, in110Rambow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsKashmiri, the wh-element ends up in second position in the presence of a topic.
Thisis the case even if the wh-element comes from the embedded clause and the topic fromthe matrix clause.
(The data is from Bhatt, \[1994\].
)(9) a. rameshan kyaa dyutnay tseRameShERc whatNoM gave yOUDA TWhat did you give Ramesh?b.
rameshan kyaai chu baasaan ki me kor tiRameShERc what is belieVeNPERF that IERC doWhat does Ramesh believe that I did?Another example comes from Rumanian.
Rumanian differs from English in that itallows multiple fronted wh-elements in the same clause.
Leahu (1998) illustrates thispoint with the examples in (10) (her (8a) and (11a)); (10a) shows multiple wh-movementin the same clause, while (10b) shows multiple wh-words in one clause that originatefrom different clauses, resulting again in an interspersed order.
(10) a. Cinei cuij ti promite o masina tj?who to whom promises a carWho promises a car to whom?b.
Cinei pe cinej a zis ti ca a vazut tj?who whom has said that has seenWho has said he has seen whom?The examples discussed in this section show a range of syntactic phenomena inEnglish and in other languages that cannot be analyzed using the operations of TAG.We conclude that complex interspersing is a fairly common phenomenon i natu-ral language.
As in the case of factoring of recursion, sometimes we find that thedefinition of adjunction precludes certain linguistically plausible analyses but allowsothers; in other cases, TAG does not seem to allow any linguistically plausible anal-ysis at all.
However, in each case, we can use standard LTAG practices for projectingstructures from lexical items and combine the resulting structures using the general-ized substitution operation of DSG to obtain the desired analyses, thus bringing outthe underlying similarity of related constructions both within languages and cross-linguistically.4.3 Linguistic Use of Path ConstraintsIn the examples discussed so far, we have not had the need to use path constraints.The d-edges een so far express any domination path.
Recall that path constraints canbe associated with a d-edge to express certain constraints on what nodes, in terms oftheir labels, cannot appear within a path instantiating a d-edge.111Computational Linguistics Volume 27, Number 1SNP VPI 'IIwood IIIIIIII" ' " ' " ' .
.
.
ok? '
' ? '
.
o  ?
oI path cgnstr,aint: I ',no ~ nocle%.S!iI....." ~ ' " ' .
.
.ok .V S' l Seem8S?
,~ .
II "~"IVPV Vp' TappearsVPNPIit~tc ?
?SVPto floatFigure 21Path constraints are needed to rule out ungrammatical super-raising.As an example of the use of path constraints, let us consider the well-known caseof "super-raising":(11) a.
It seems wood appears to floatb.
*Wood seems it appears to floatc.
Wood seems to appear to floatIn (11a), the subject of float, wood, has raised to the appears clause, while the raisingverb seem does not trigger raising and has an expletive it as its subject?
In (11b),wood has raised further, and appear now has an expletive subject; (11b) is completelyungrammatical.
If we make the intermediate raising verb appear nonfinite (and hencewithout a subject), as in (11c), the sentence is again grammatical.Now consider the DSG analysis for (11a) shown in Figure 21.
The d-tree for seemhas an S substitution node, since seems takes a finite complement with a subject?
Appear,112Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarssince it is finite, projects to S, but takes a VP complement since its complement, hefloat clause, is nonfinite and has no overt subject, is We furthermore assume that theraising verbs seem and appear do not select for subjects, but that the expletive subjectit is freely available for inclusion in their d-trees, since expletive it is semanticallyvacuous and merely fulfills syntactic requirements ( uch as subject-verb agreement),not semantic ones.
We substitute the float d-tree into the appear d-tree, and the resultinto the seem d-tree, as indicated by the solid arrows in Figure 21.
Given the readingoff process, this derived d-tree can be seen to express two possibilities, dependingon where the wood component and the expletive it end up.
These two possibilitiescorrespond to (11a) and (11b).To exclude the ungrammatical result, we use the path constraints discussed inSection 2.6.
Let us make the uncontroversial ssumption that as we project from averb, we will project to a VP before projecting to an S. But we will interpret hisnotion of projection as also applying to the d-edges between nodes labeled VP: weannotate the d-edge between the VP nodes in the float tree (and in fact in all trees, ofcourse) as having a path constraint that does not allow an S node on this path.
Thisis, after all, what we would expect in claiming that the float tree represents a structurelexically projected from the verb float.
16 Given this additional grammatical expression,after the substitution at the S node of the seems tree, it is no longer possible to read offfrom the d-tree in Figure 21 a tree whose yield is the ungrammatical (11b).
The onlypossible way of reading off from the derived d-tree yields (11a).What is striking is that this particular path constraint disallowing S nodes betweenVP nodes in structures projected from a verb can be used in other cases as well.
In fact,this same path constraint on its own, when applied to the English examples consideredso far, predicts the correct arrangement of all components among the two d-treesbeing combined, regardless of whether the nesting constraint of adjoining must be met(extraction out of clausal or VP complements, extraction from NP or PP complements),or not (extraction from the clause of a raising verb, raising verb with fronted auxiliary,or extraction from an adjunct).
For example, in Figure 18, after substituting the to behappy component at the VP node of the appears d-tree, a path constraint on the d-edgebetween the two VP nodes of the to be happy tree makes it impossible for the to anyof us component to intervene, thus leaving the interspersed tree as the only possibleresult of the reading off process, even if we relaxed the requirement on label equalityfor the removal of d-edges during the reading off process.Note that while the same path constraints apply in all cases, in LTAG, as we haveseen, the nesting constraint of adjoining precludes deriving the correct order in somecases, and the use of extensions such as mult icomponent adjoining has been suggested.In fact, because there are both situations in which the arrangement of components ofthe lexically projected structures corresponds to adjoining and situations in whichthis arrangement is inappropriate, Vijay-Shanker (1992) raises the question of whetherthe definition of the formalism should limit the arrangement of components of thelexically projected structures, or whether the possible arrangements should be derivedfrom the linguistic theory and from intuitions about the nature of the elementaryobjects of a grammar.
This subsection partially addresses this question and shows15 The point we are making in this section relies on there being some distinction between the labels of theroots of the appear and float clauses, a linguistically uncontroversial assumption.
Here, we use thecategorial distinction between Sand VP for convenience only; we could also have assumed a differencein feature content.16 Bleam (2000) uses informal path constraints inmuch the same way in order to restrict Spanish cliticclimbing in an LTAG analysis.113Computational Linguistics Volume 27, Number 1how the path constraint expressing the nature of projection from a lexical item can beused to derive the arrangements of components corresponding to adjoining in somecases as well as predict when the nesting condition of adjoining is too limiting in theothers.4.4 Underspecification of Linear PrecedenceIn our proposed tree description language, we provide for underspecified dominancebut not for underspecified linear precedence.
As a consequence, in the graphical repre-sentations of d-trees, we assume that sister nodes are always ordered as shown.
Thismay seem arbitrary at first glance, especially since in many linguistic frameworksand theories it is common to specify linear precedence (LP) separately from syntacticstructure (GPSG, HPSG, LFG, ID/LP-TAG \[Joshi 1987\] and FO-TAG \[Becker, Joshi,and Rambow 1991\], various dependency-based formalisms, and so on).
This separatespecification of LP rules allows for underspecified LP rules, which is useful in casesin which word order is not fully fixed.In principle, an underspecification f LP could easily be added to DSG withoutprofoundly changing its character or formal properties.
The reason we have not doneso is that in all cases, the same effect can be achieved using underspecified dominancealone, though at the cost of forcing a linguistic analysis that uses binary branchingphrase structure trees rather than n-ary branching ones.
We will illustrate the pointusing examples from German, which allows for scrambling of the arguments.Consider the following German examples.
17(12) a. dat~ die Kinder dem Lehrer das Buch gebenthat \[the children\]NOM \[the teacher\]DAT \[the book\]Acc givethat the children give the teacher the bookb.
dat~ dem Lehrer die Kinder das Buch gebenc.
dat~ dem Lehrer das Buch die Kinder gebenAll orders of the three arguments are possible, resulting in six possible sentences(three of which are shown in (12)).
In DSG, we can express this by giving the lexicalentry for geben shown in Figure 22.
TM The arguments of the verb have no dominancespecified among them, so that when using this d-tree (which is of course not yet atree) in a derivation, we can choose whichever dominance relations we want whenwe read off a tree at the end of the derivation.
As a result, we obtain any ordering ofthe arguments.As mentioned previously, while we can derive any ordering, we cannot, in DSG,obtain a flat VP structure.
However, our analysis has an advantage when we consider"long scrambling," in which arguments from two lexical verbs intersperse.
(In German,only certain matrix verbs allow long scrambling.)
If we have the subject-control verbversuchen 'to try', the nominative argument is the overt subject of the matrix clause,while the dative and accusative arguments are arguments of the embedded clause.Nonetheless, the same six word orders are possible (we again underline the embedded17 We give embedded clauses tarting with the complementizer in order to avoid the problem of V2.
Fora discussion of V2 in a framework like DSG, see Rambow (1994a) and Rambow and Santorini (1995).18 We label all projections from the verb (except the immediate preterminal) VP.
We assume that relevantlevels of projection are distinguished by the feature content of the nodes.
This choice has mainly beenmade in order to allow us to derive verb-second matrix clause order using the same d-trees, which isalso why the verb is in a component of its own.114Rambow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsVP VP VPNPNoM VP NPAcc VP NPDAT VP VPVPIVIeFigure 22D-tree for German verb geben 'to give'.VPgebenSUBJ XCOMPVP VPNP VP VP VPVPIeFigure 23D-tree for German verb versuchen 'to try'.VPVP Vversuchenclause material):(13) a. daf~ die Kinder dem Lehrer das Buch zu gebenthat \[the children\]NOM \[the teacher\]DAT \[the book\]ncc to givethat the children try to give the teacher the bookb.
daf~ dem Lehrer die Kinder das Buch zu geben versuchenc.
daf~ dem Lehrer das Buch die Kinder zu geben versuchenversuchentryWe can represent the matrix verb as shown in Figure 23, and a derivat ion as shownin Figure 24.
It is clear that we  can still obtain all possible word  orders, and that this115Computational Linguistics Volume 27, Number 1OBJ INDOBJ XGOMPVP VP VP VPNP VP NP VP VP VP VP VSUBJVPNP VP- -  - , i x ,  ' ' I "\ I .#VP V , ~versuchen.
-IVP zu geben VPI Ie eFigure 24DSG derivation for a complex sentence.wou ld  be imposs ib le  us ing  s imple  LP rules that order  s ister nodes.
19 (It wou ld  alsobe imposs ib le  in LTAG, but  see Joshi, Becker, and  Rambow \[2000\] for an a l ternated iscuss ion of long sc rambl ing  in LTAG.)5.
Modeling Syntactic DependencyIn the prev ious  sections, we  have presented  DSG and have  shown how it can be used  toprov ide  ana lyses  for a range of l inguist ic  phenomena.
In this section, we  conc lude  ourin t roduct ion  of DSG by  d iscuss ing  the re lat ionsh ip  between der ivat ions  in DSG andsyntactic dependency.
Recently, syntact ic  dependency  has emerged as an impor tantfactor for app l icat ions  in natura l  language process ing.In lex ica l ized fo rmal i sms such as LTAG, the operat ions  of the fo rmal i sm (i.e.,in the case of LTAG, subst i tut ion and  adjunct ion)  relate structures assoc iated w i thtwo lexical i tems.
It is therefore natura l  to interpret  hese operat ions  as estab l ish inga direct syntact ic re lat ion between the two lexical i tems,  i.e., a re lat ion of syntact icdependency.
There are at least two  types  of syntact ic  dependency :  a re lat ion of com-p lementat ion  (pred icate -argument  relat ion) and  a re lat ion of modi f i cat ion  (predicate-ad junct  relat ion).
2?
Syntact ic dependency  represents  an impor tant  l inguist ic  intui t ion,p rov ides  a un i fo rm interface to semant ics ,  and  is, as Schabes and  Shieber (1994) argue,impor tant  in order  to suppor t  stat ist ical  parameters  in stochast ic f rameworks .
In fact,19 This kind of construction has been extensively analyzed in the Germanic syntax literature.
Followingthe descriptive notion of "coherent construction" proposed by Bech (1955), Evers (1975) proposes thatin German (and in Dutch, but not in English) a biclausal structure undergoes a special process toproduce a monoclausal structure, in which the argument lists of the two verbs are merged and theverbs form a morphological unit.
This analysis has been widely adopted (in one form or another) inthe formal and computational syntax literature by introducing special mechanisms into the underlyingformal system.
If the special mechanism produces a single (flat) VP for the new argument list, then LPrules for the simplex case can also apply to the complex case.
However, the DSG analysis has theadvantage that it does not involve a special mechanism, and the difference between German andEnglish complex clauses is related simply to the difference in word orders allowable in the simplexcase (i.e., German but not English allows scrambling).
Furthermore, the DSG analysis correctly predictssome "interleaved" word orders to be grammatical.
See Rambow (1995) for details.20 In addition, we may want to identify the relation between a function word and its lexical headword(e.g., between a determiner and a noun) as a third type of relation.116Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsadore claimhe seemMary / OBJ \ seems I COMPIhotdog claim adoreI SUB J SUBJ~~~ BJhe Mary hotdogFigure 25LTAG derivation tree for (14) (left); dependency tree for (14) (right).recent advances in parsing technology are due to the explicit stochastic modeling ofdependency information (Collins 1997).Purely CFG-based approaches do not represent syntactic dependency, but otherframeworks do, e.g.
the f-structure (functional structure) of LFG (Kaplan and Bresnan1982), and dependency grammars (see, for example, Mel'~uk \[1988\]), for which syn-tactic dependency is the sole basis for representation.
As observed by Rambow andJoshi (1997), for LTAG, we can see the derivation structure as a dependency structure,since in it lexemes are related directly.However, as we have pointed out in Section 4.1, the LTAG composition operationsare not used uniformly: while substitution is used only to add a (nominal) complement,adjunction is used both for modification and (clausal) complementation.
21 Furthermore,there is an inconsistency in the directionality of the substitution operation and thoseuses of adjunction for clausal complementation: i  LTAG, nominal complements aresubstituted into their governing verb's tree, while the governing verb's tree is ad-joined into its own clausal complement.
The fact that adjunction and substitution areused in a linguistically heterogeneous manner means that (standard) LTAG derivationtrees do not provide a direct representation f the dependencies between the wordsof the sentence, i.e., of the predicate-argument a d modification structure.
In DSG,this problem is overcome straightforwardly, since DSG uses generalized substitutionfor all complementation (be it nominal or clausal), while still allowing long-distanceeffects.
=There is a second, more serious problem with modeling syntactic dependency inLTAG, as can be seen from the following example:(14) Hot dogs he claims Mary seems to adoreThe problem is that in the standard LTAG derivation, we adjoin both the treesfor claim and seem into the tree for adore (Figure 25, left), while in the (commonlyassumed) dependency structure, seem depends on claim, and adore depends on seem(Figure 25, right).
The problem is in fact related to the interleaving problem discussedin Section 4.2, and can easily be solved in DSG by proposing a structure such as that21 Clausal complementation ca not be handled nniformly by substitution because ofthe existence ofsyntactic phenomena such as long-distance wh-movement i  English.22 Modification can be handled by some other operation, such as sister adjunction (Rainbow,Vijay-Shanker, and Weir 1995), and is thus distinguished from complementation.
We do not discussmodification i  this paper.117Computational Linguistics Volume 27, Number 1SIIiVPV VPIseemsFigure 26Elementary d-tree for finite seems.in Figure 26 for seems, which we have already seen in Figure 21.
(This structure canbe justified on linguistic grounds independently from the dependency considerations,by assuming that all finite verbs--whether raising or not--project to at least S \[= IP\].Raising verbs simply lack a subject of their own, but the S node is justified by thefiniteness of the verb, not by the presence or absence of a subject.)
Thus, DSG can beused to develop grammars in which the derivation faithfully and straightforwardlyreflects yntactic dependency.
236.
Related WorkIn this section, we mention some related theoretical work and some application-oriented work that is based on DSG.On the theoretical side, Kallmeyer (1996, 1999) presents an independently con-ceived formalism called tree description grammar (TDG).
TDG is similar to DSG:in both formalisms, descriptions of trees are composed uring derivations throughconjunction and equation of nodes.
Furthermore, like DSG, TDG does not allow theconflation of immediate dominance structure specified in elementary structures.
How-ever, TDG allows for more than one node to be equated in a derivation step: nodesare "marked" and all marked nodes are required to be equated with other nodes in aderivation step.
(Equating more than one pair of nodes in each derivation step shiftssome of the work done in reading off in DSG to the derivation in TDG.)
In DSG,we have designed a simple generative system based on tree descriptions involvingdominance, using an operation that directly correspond to the linguistic notion ofcomplementation.
Additional mechanisms, uch as the marking of nodes and theirsimultaneous involvement in a derivation step, are not available in DSG.Hepple (1998) relates DSG to a system he has previously proposed in which de-ductions in implicational linear logic are recast as deductions involving only first-orderformulas (Hepple 1996).
He shows how this relation can be exploited to give deriva-tions in DSG a functional semantics.There is an ongoing effort to evaluate the theoretical proposals presented in thispaper through the development of a wide-coverage DSG-based parsing system thatprovides analysis in a broadly HPSG style (Carroll et al 2000).
One aspect of this workinvolves exploiting the extended omain of locality that DSG shares with TAG in order23 Candito and Kahane (1998) propose to use derivations in DSG to model semantic (rather thansyntactic) dependency.118Rambow, Vijay-Shanker, and Weir D-Tree Substitution Grammarsto maximize localization of syntactic dependencies within elementary tree descriptions,thereby avoiding the need for unification during parsing (Carroll et al 1999).Nicolov and Mellish (2000) use DSG as the formalism in a generation application.The principal motivation for using DSG is that DSG is a lexicalized formalism whichcan provide derivations that correspond to the traditional notion of (deep) syntacticdependency (see Section 5), which is often considered to be the input to the syntacticcomponent of a generation system.7.
Conc lus ionsWe have introduced the grammar formalism of d-tree substitution grammars by show-ing how it emerges from a tree-description-theoretic analysis of tree adjoining ram-mars.
Derivations in DSG involve the composition of d-trees, special kinds of treedescriptions.
Trees are read off from derived d-trees.We have shown that the DSG formalism can be used to express a variety of lin-guistic analyses, including styles of analysis that do not appear to be available withthe LTAG approach, and analyses for constructions that appear to be beyond the de-scriptive capacity of LTAG.
Furthermore, linguistic analyses of syntactic phenomenaare uniform, both language-internally nd cross-linguistically.
Finally, DSG allows fora consistent modeling of syntactic dependency.ReferencesAbeillG Anne.
1991.
Une grammaire l xicalisded'arbres adjoints pour le fran?ais.
Ph.D.thesis, Universit~ Paris 7.Backofen, Roll James Rogers, and K.Vijay-Shanker.
1995.
A first-orderaxiomatization f the theory of finitetrees.
Journal of Language, Logic, andInformation, 4(1):5-39.Bech, Gunnar.
1955.
Studien fiber das deutscheVerbum infinitum.
Det Kongelige Danskevidenskabernes selskab.Historisk-Filosofiske M ddelelser, bd.
35,nr.
2 (1955) and bd.
36, nr.
6 (1957).Munksgaard, Kopenhagen.
Secondunrevised edition published 1983 by MaxNiemeyer Verlag, Tiibingen (LinguistischeArbeiten 139).Becker, Tilman, Aravind Joshi, and OwenRainbow.
1991.
Long distance scramblingand tree adjoining rammars.
In FifthConference ofthe European Chapter of theAssociation for Computational Linguistics(EACL'91), pages 21-26.Becker, Tilman and Owen Rainbow.
1995.Parsing non-immediate dominancerelations.
In Proceedings ofthe FourthInternational Workshop on ParsingTechnologies, pages 26-33, Prague.Bhatt, Rakesh.
1994.
Word Order and Case inKashmiri.
Ph.D. thesis, University ofIllinois, Urbana-Champaign.Bleam, Tonia.
2000.
Clitic climbing and thepower of tree adjoining rammar.
InAnne AbeilM and Owen Rambow, editors,Tree Adjoining Grammars: Formalisms,Linguistic Analyses and Processing.
CSLIPublications, pages 193-220.
Paperinitially presented in 1995.Candito, Marie-He'l~ne and Sylvain Kahane.1998.
Defining DTG derivations to getsemantic graphs.
In Proceedings oftheFourth International Workshop on TreeAdjoining Grammars and Related Frameworks(TAG+4), IRCS Report 98-12, pages 25-28.Institute for Research in CognitiveScience, University of Pennsylvania.Carroll, John, Nicolas Nicolov, OlgaShaumyan, Martine Smets, and DavidWeir.
1999.
Parsing with an extendeddomain of locality.
In Ninth Conference ofthe European Chapter of the Association forComputational Linguistics (EACL'99),pages 217-224.Carroll, John, Nicolas Nicolov, OlgaShaumyan, Martine Smets, and DavidWeir.
2000.
Engineering a wide-coveragelexicalized grammar.
In Proceedings oftheFifth International Workshop on TreeAdjoining Grammars and RelatedFrameworks, pages 55-60.Collins, Michael.
1997.
Three generative,lexicalised models for statistical parsing.In Proceedings ofthe 35th Annual Meeting,Madrid, Spain, July.
Association forComputational Linguistics.Evers, Arnold.
1975.
The TransformationalCycle in Dutch and German.
Ph.D. thesis,University of Utrecht.
Distributed by theIndiana University Linguistics Club.119Computational Linguistics Volume 27, Number 1Frank, Robert.
1992.
Syntactic Locality andTree Adjoining Grammar: Grammatical,Acquisition and Processing Perspectives.Ph.D.
thesis, Department of Computerand Information Science, University ofPennsylvania.Frank, Robert.
Forthcoming.
Phrase StructureComposition and Syntactic Dependencies.MIT Press, Cambridge.Gazdar, G. 1988.
Applicability of indexedgrammars to natural anguages.
In U.Reyle and C. Rohrer, editors, NaturalLanguage Parsing and Linguistic Theories.
D.Reidel, Dordrecht, pages 69-94.Harley, Heidi and Seth Kulick.
1998.
TAGand raising in VSO languages.
InProceedings ofthe Fourth InternationalWorkshop on Tree Adjoining Grammars andRelated Frameworks (TAG+4), IRCS Report98-12, pages 62-65.
Institute for Researchin Cognitive Science, University ofPennsylvania.Hendrick, R. 1988.
Anaphora in Celtic andUniversal Grammar.
Kluwer AcademicPublishers, Dordrecht.Hepple, Mark.
1996.
A compilation-chartmethod for linear categorical deduction.In Proceedings ofthe 16th InternationalConference on Computational Linguistics(COLING'96), pages 537-542.Hepple, Mark.
1998.
On same similaritiesbetween D-Tree Grammars andtype-logical grammars.
In Proceedings ofthe Fourth International Workshop on TreeAdjoining Grammars and Related Frameworks(TAG+4), IRCS Report 98-12, pages 66-69.Institute for Research in CognitiveScience, University of Pennsylvania.Joshi, Aravind K. 1987.
Word-ordervariation in natural anguage generation.Technical Report, Department ofComputer and Information Science,University of Pennsylvania.Joshi, Aravind K., Tilman Becker, and OwenRambow.
2000.
A new twist on thecompetence/performance distinction.
InAnne Abeill4 and Owen Rambow, editors,Tree Adjoining Grammars: Formalisms,Linguistic Analysis, and Processing.
CSLIPublications, pages 167-182.Joshi, Aravind K. and Yves Schabes.
1991.Tree-adjoining grammars and lexicalizedgrammars.
In Maurice Nivat and AndreasPodelski, editors, Definability andRecognizability of Sets of Trees.
Elsevier.Kallmeyer, Laura.
1996.
Tree descriptiongrammars.
In D. Gibbon, editor, NaturalLanguage Processing and Speech Technology.Results of the 3rd KONVENS Conference,pages 332-341, Berlin.
Mouton deGruyter.KaUmeyer, Laura.
1999.
Tree DescriptionGrammars and UnderspecifiedRepresentations.
Ph D. thesis, University ofTiibingen.
Available as Technical ReportNo.
99-08 from the Institute for Researchin Cognitive Science at the University ofPennsylvania.Kaplan, Ronald M. and Joan W. Bresnan.1982.
Lexical-functional grammar: Aformal system for grammaticalrepresentation.
I  J. W. Bresnan, editor,The Mental Representation of GrammaticalRelations.
MIT Press, Cambridge, MA.Kasper, Robert, Bernd Kiefer, Klaus Netter,and K. Vijay-Shanker.
1995.
Compilationof HPSG and TAG.
In Proceedings oftheAnnual Meeting, pages 92-99.
Associationfor Computational Linguistics.Kroch, Anthony.
1987.
Subjacency in a treeadjoining grammar.
In AlexisManaster-Ramer, ditor, Mathematics ofLanguage.
John Benjamins, Amsterdam,pages 143-172.Kroch, Anthony.
1989.
Asymmetries in longdistance xtraction i  a Tree AdjoiningGrammar.
In Mark Baltin and AnthonyKroch, editors, Alternative Conceptions ofPhrase Structure.
University of ChicagoPress, Chicago, pages 66-98.Leahu, Manuela.
1998.
Wh-dependencies nRomanian and TAG.
In Proceedings oftheFourth International Workshop on TreeAdjoining Grammars and Related Frameworks(TAG+4), pages 92-95, IRCS Report 98-12,Institute for Research in CognitiveScience, University of Pennsylvania.Marcus, Mitchell, Donald Hindle, andMargaret Fleck.
1983.
D-theory: Talkingabout talking about rees.
In Proceedings ofthe 21st Annual Meeting, Cambridge, MA.Association for ComputationalLinguistics.Mel'~uk, Igor A.
1988.
Dependency S ntax:Theory and Practice.
State University ofNew York Press, New York.Nicolov, Nicolas and Christopher Mellish.2000.
Protector: Efficient generation withlexicalized grammars.
In Ruslan Mitkovand Nicolas Nicolov, editors, RecentAdvances in Natural Language Processing(RANLP vol.
II).
John Benjamins,Amsterdam and Philadelphia,pages 221-243.Pollard, Carl and Ivan Sag.
1994.Head-Driven Phrase Structure Grammar.University of Chicago Press, Chicago.Rambow, Owen.
1994a.
Formal andComputational Aspects of Natural LanguageSyntax.
Ph.D. thesis, Department ofComputer and Information Science,University of Pennsylvania, Philadelphia.120Rambow, Vijay-Shanker, and Weir D-Tree Substitution GrammarsAvailable as Tectmical Report 94-08 fromthe Institute for Research in CognitiveScience (IRCS) and also at ftp://ftp.cis.upenn.edu/pub/rambow/thesis.ps.Z.Rambow, Owen.
1994b.
Multiset-valuedlinear index grammars.
In Proceedings ofthe 32nd Annual Meeting, pages 263-270.Association for ComputationalLinguistics.Rambow, Owen.
1995.
Coherentconstructions in German: Lexicon orsyntax?
In Glyn Morrill and RichardOehrle, editors, Formal Grammar:Proceedings ofthe Conference ofthe EuropeanSummer School in Logic, Language, andInformation, pages 213-226, Barcelona.Rambow, Owen.
1996.
Word order, clauseunion, and the formal machinery ofsyntax.
In Miriam Butt and TracyHolloway King, editors, Proceedings oftheFirst LFG Conference.
On-line version athttp://www-csli.stanford.edu/publications/LFG/lfgl.html.Rainbow, Owen and Aravind Joshi.
1997.
Aformal ook at dependency gran~nars andphrase-structure grammars, with specialconsideration of word-order phenomena.In Leo Wanner, editor, Recent Trends inMeaning-Text Theory.
John Benjamins,Amsterdam and Philadelphia.Rainbow, Owen and Beatrice Santorini.1995.
Incremental phrase structuregeneration and a universal theory of V2.In J. N. Beckman, editor, Proceedings ofNELS 25, pages 373-387, Amherst, MA.GSLA.Rambow, Owen and K. Vijay-Shanker.
1998.Wh-islands in TAG and relatedformalisms.
In Proceedings ofthe FourthInternational Workshop on Tree AdjoiningGrammars and Related Frameworks (TAG+4),pages 147-150, IRCS Report, 98-12.Institute for Research in CognitiveScience, University of Pennsylvania.Rambow, Owen, K. Vijay-Shanker, andDavid Weir.
1995.
D-Tree Grammars.
InProceedings ofthe 33rd Annual Meeting,pages 151-158.
Association forComputational Linguistics.Rogers, James and K. Vijay-Shanker.
1992.Reasoning with descriptions of trees.
InProceedings ofthe 30th Annual Meeting,pages 72-80.
Association forComputational Linguistics.Schabes, Yves.
1990.
Mathematical ndComputational Aspects of LexicalizedGrammars.
Ph.D. thesis, Department ofComputer and Information Science,University of Pennsylvania.Schabes, Yves and Stuart Shieber.
1994.
Analternative conception of tree-adjoiningderivation.
Computational Linguistics,20(1):91-124.Vijay-Shanker, K. 1987.
A Study of TreeAdjoining Grammars.
Ph.D. thesis,Department of Computer and InformationScience, University of Pennsylvania,Philadelphia, PA, December.Vijay-Shanker, K. 1992.
Using descriptionsof trees in a Tree Adjoining Grammar.Computational Linguistics, 18(4):481-518.Vijay-Shanker, K. and David Weir.
1999.Exploring the underspecified world ofLexicalized Tree Adjoining Grammars.
InProceedings ofthe Sixth Meeting onMathematics of Language.Vijay-Shanker, K., David Weir, and OwenRainbow.
1995.
Parsing D-Tree Grammars.In Proceedings ofthe Fourth InternationalWorkshop on Parsing Technologies,pages 252-259.
ACL/SIGPARSE.XTAG-Group, The.
1999.
A lexicalized TreeAdjoining Grammar for English.Technical Report.
The Institute forResearch in Cognitive Science, Universityof Pennsylvania.
Available at:http://www.cis.upenn.edu/~xtag/tech-report/tech-report.html.121
