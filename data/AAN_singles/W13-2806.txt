Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 25?33,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsUsing Unlabeled Dependency Parsing for Pre-reorderingfor Chinese-to-Japanese Statistical Machine TranslationDan Han1,2 Pascual Mart?
?nez-Go?mez2,3 Yusuke Miyao1,2Katsuhito Sudoh4 Masaaki Nagata41The Graduate University For Advanced Studies2National Institute of Informatics, 3The University of Tokyo4NTT Communication Science Laboratories, NTT Corporation{handan,pascual,yusuke}@nii.ac.jp{sudoh.katsuhito,nagata.masaaki}@lab.ntt.co.jpAbstractChinese and Japanese have a different sen-tence structure.
Reordering methods areeffective, but need reliable parsers to ex-tract the syntactic structure of the sourcesentences.
However, Chinese has a looseword order, and Chinese parsers that ex-tract the phrase structure do not performwell.
We propose a framework where onlyPOS tags and unlabeled dependency parsetrees are necessary, and linguistic knowl-edge on structural difference can be en-coded in the form of reordering rules.
Weshow significant improvements in transla-tion quality of sentences from news do-main, when compared to state-of-the-artreordering methods.1 IntroductionTranslation between Chinese and Japanese lan-guages gains interest as their economic and polit-ical relationship intensifies.
Despite their linguis-tic influences, these languages have different syn-tactic structures and phrase-based statistical ma-chine translation (SMT) systems do not performwell.
Current word alignment models (Och andNey, 2003) account for local differences in wordorder between bilingual sentences, but fail at cap-turing long distance word alignments.
One ofthe main problems in the search of the best wordalignment is the combinatorial explosion of wordorders, but linguistically-motivated heuristics canhelp to guide the search.This work explores syntax-informed pre-reordering for Chinese; that is, we obtain syntacticstructures of Chinese sentences, reorder the wordsto resemble the Japanese word order, and thentranslate the reordered sentences using a phrase-based SMT system.
However, Chinese parsershave difficulties in extracting reliable syntactic in-formation, mainly because Chinese has a looseword order and few syntactic clues such as inflec-tion and function words.On one hand, parsers implementing head-drivenphrase structure grammars infer a detailed con-stituent structure, and such a rich syntactic struc-ture can be exploited to design well informed re-ordering methods.
However, inferring abundantsyntactic information often implies introducing er-rors, and reordering methods that heavily rely ondetailed information are sensitive to those parsingerrors (Han et al 2012).On the other hand, dependency parsers are com-mitted to the simpler task of finding dependencyrelations and dependency labels, which can also beuseful to guide reordering (Xu et al 2009).
How-ever, reordering methods that rely on those depen-dency labels will also be prone to errors, speciallyin the case of Chinese since it has a richer set ofdependency labels when compared to other lan-guages.
Since improving parsers for Chinese ischallenging, we thus aim at reducing the influenceof parsing errors in the reordering procedure.We present a hybrid approach that boosts theperformance of phrase-based SMT systems bypre-reordering the source language using unla-beled parse trees augmented with constituentinformation derived from Part-of-Speech tags.Specifically, we propose a framework to pre-reorder a Subject-Verb-Object (SVO) language,in order to improve its translation to a Subject-Object-Verb (SOV) language, where the only re-quired syntactic information are POS tags and un-labeled dependency parse trees.
We test the per-formance of our pre-reordering method and com-pare it to state-of-the-art reordering methods in thenews domain for Chinese.In the next section, we describe similar work onpre-reordering methods for language pairs that in-25volve either Chinese or Japanese, and explain howour method builds upon them.
From a linguis-tic perspective, we describe in section 3 our ob-servations of reordering issues between Chineseand Japanese and detail how our framework solvesthose issues.
In section 4 we assess to what extentour pre-reordering method succeeds in reorderingwords in Chinese sentences to resemble the orderof Japanese sentences, and measure its impact ontranslation quality.
The last section is dedicated todiscuss our findings and point to future directions.2 Related WorkAlthough there are many works on pre-reorderingmethods for other languages to English translationor inverse (Xia and McCord, 2004; Xu et al 2009;Habash, 2007; Wang et al 2007; Li et al 2007;Wu et al 2011), reordering method for Chinese-to-Japanese translation, which is a representativeof long distance language pairs, has received littleattention.The most related work to ours is in (Han et al2012), in which the authors introduced a refinedreordering approach by importing an existing re-ordering method for English proposed in (Isozakiet al 2010b).
These reordering strategies arebased on Head-driven phrase structure grammars(HPSG) (Pollard and Sag, 1994), in that the re-ordering decisions are made based on the head ofphrases.
Specifically, HPSG parsers (Miyao andTsujii, 2008; Yu et al 2011) are used to extract thestructure of sentences in the form of binary trees,and head branches are swapped with their depen-dents according to certain heuristics to resemblethe word order of the target language.
However,those strategies are sensitive to parsing errors, andthe binary structure of their parse trees imposehard constraints in sentences with loose word or-der.
Moreover, as Han et al(2012) noted, reorder-ing strategies that are derived from the HPSG the-ory may not perform well when the head definitionis inconsistent in the language pair under study.
Atypical example for the language pair of Chineseand Japanese that illustrates this phenomenon isthe adverb ?bu4?, which is the dependent of itsverb in Chinese but the head in Japanese.The work in (Xu et al 2009) used an Englishdependency parser and formulated handcrafted re-ordering rules with dependency labels, POS tagsand weights as triplets and implemented them re-cursively into sentences.
This design, however,limited the extensibility of their method.
Our ap-proach follows the idea of using dependency treestructures and POS tags, but we discard the infor-mation on dependency labels since we did not findthem informative to guide our reordering strate-gies in our preliminary experiments, partly due toChinese showing less dependencies and a largerlabel variability (Chang et al 2009).3 MethodologyIn Subject-Verb-Object (SVO) languages, objectsusually follow their verbs, while in Subject-Object-Verb (SOV) languages, objects precedethem.
Our objective is to reorder words in Chinesesentences (SVO) to resemble the word order ofJapanese sentences (SOV).
For that purpose, ourmethod consists in moving verbs to the right-handside of their objects.
However, it is challengingto correctly identify the appropriate verbs and ob-jects that trigger a reordering, and this section willbe dedicated to that end.More specifically, the first step of our methodconsists in identifying the appropriate verb (andcertain words close to it) that need to be moved tothe right-hand side of its object argument.
Verbs(and those accompanying words) will move as ablock, preserving the relative order among them.We will refer to them as verbal blocks (Vbs).
Thesecond step will consist in identifying the right-most argument object of the verb under considera-tion, and moving the verbal block to the right-handside of it.
Finally, certain invariable grammaticalparticles in the original vicinity of the verb willalso be reordered, but their positions will be de-cided relative to their verb.In what follows, we describe in detail how toidentify verbal blocks, their objects and the invari-able grammatical particles that will play a role inour reordering method.
As mentioned earlier, theonly information that will be used to perform thistask will be the POS tags of the words and theirunlabeled dependency structures.3.1 Identifying verbal blocks (Vbs)Verbal blocks are composed of a head (Vb-H)and possibly accompanying dependents (Vb-D).In the Chinese sentence ?wo3 (I) chi1 le5 (ate) li2(pear).
?1, ?chi1?
refers to the English verb ?eat?1In this paper, we represent a Chinese character by usingPinyin plus a tone number (there are 5 tones in Chinese).
Inthe example, ?chi1(eat)?
is a verb and ?le5(-ed)?
is an aspectparticle that adds preterit tense to the verb.26Vb-H VV VE VC VA PVb-D AD AS SP MSP CC VV VE VC VABEI LB SBRM-D NN NR NT PN OD CD M FW CCETC LC DEV DT JJ SP IJ ONOth-DEP LB SB CSTable 1: Lists of POS tags in Chinese used to iden-tify blocks of words to reorder (Vb-H, Vb-D, BEIlists), the POS tags of their dependents (RM-Dlists) which indicate the reordering position, andinvariable grammatical particles (Oth-DEP) thatneed to be reordered.and the aspect particle ?le5?
adds a preterit tenseto the verb.
The words ?chi1 le5?
are an exampleof verbal block that should be reordered as a blockwithout altering its inner word order, i.e.
?wo3(I) li2 (pear) chi1 le5 (ate).
?, which matches theJapanese SOV order.Possible heads of verbal blocks (Vb-H) areverbs (words with POS tags VV, VE, VC and VA),or prepositions (words with POS tag P).
The Vb-Hentry of Table 1 contains the list of POS tags forheads of verbal blocks.
We use prepositions forVb-H identification since they behave similarly toverbs in Chinese and should be moved to the right-most position in a prepositional phrase to resemblethe Japanese word order.
There are three condi-tions that a word should meet to be considered asa Vb-H:i) Its POS tag is in the set of Vb-H in Table 1.ii) It is a dependency head, which indicates thatit may have an object as a dependent.iii) It has no dependent whose POS tag is in theset of BEI in Table 1.
BEI particles indicatethat the verb is in passive voice and shouldnot be reordered since it already resemblesthe Japanese order.Chinese language does not have inflection, con-jugation, or case markers (Li and Thompson,1989).
For that reason, some adverbs (AD), as-pect particles (AS) or sentence-final particles (SP)are used to signal modality, indicate grammati-cal tense or add aspectual value to verbs.
Wordsin this category preserve the order when translat-ing to Japanese, and they will be candidates to bepart of the verbal block (Vb-D) and accompanythe verb when it is reordered.
Other words in thiscategory are coordinating conjunctions (CC) thatconnect multiple verbs, and both resultative ?de5?
(DER) and manner ?de5?
(DEV).
The full list ofPOS tags used to identify Vb-Ds can be found inTable 1.
To be a Vb-D, there are three necessaryconditions as well:i) Its POS tag is in the Vb-D entry in Table 1.ii) It is a dependent of a word that is already inthe Vb.iii) It is next to its dependency head or only acoordination conjunction is in between.To summarize, to build verbal blocks (Vbs) wefirst find the words that meet the three Vb-H con-ditions.
Then, we test the Vb-D conditions on thewords adjacent to the Vb-Hs and extend the verbalblocks to them if they meet the conditions.
Thisprocess is iteratively applied to the adjacent wordsof a block until no more words can be added to theverbal block, possibly nesting other verbal blocksif necessary.Figure 1a 2 shows an example of a dependencytree of a Chinese sentence that will be used to il-lustrate Vb identification.
By observing the POStags of the words in the sentence, only the words?bian1 ji4 (edit)?
and ?chu1 ban3 (publish)?
havea POS tag (i.e.
VV) in the Vb-H entry of Table 1.Moreover, both words are dependency heads anddo not have any dependent whose POS tag is inthe BEI entry of Table 1.
Thus, ?bian1 ji4 (edit)?and ?chu1 ban3 (publish)?
will be selected as Vb-Hs and form, by themselves, two separate incipi-ent Vbs.
We arbitrarily start building the Vb fromthe word ?chu1 ban3 (publish)?, by analyzing itsadjacent words that are its dependents.We observe that only ?le5 (-ed)?
is adjacent to?chu1 ban3 (publish)?, it is its dependent, and itsPOS tag is in the Vb-D list.
Since ?le5 (-ed)?meets all three conditions stated above, ?le5 (-ed)?will be included in the Vb originated by ?chu1ban3 (publish)?.
The current Vb thus consists ofthe sequence of tokens ?chu1 ban3 (publish)?
and?le5 (-ed)?, and the three conditions for Vb-D aretested on the adjacent words of this block.
Sincethe adjacent words (or words separated by a coor-dinating conjunction) do not meet the conditions,the block is not further extended.
Figure 1b showsthe dependency tree where the Vb block that con-sists of the words ?chu1 ban3 (publish)?
and ?le5(-ed)?
is represented by a rectangular box.By checking in the same way, there are threedependents that meet the requirements of being2For all the dependency parsing trees in this paper, arrowsare pointing from heads to their dependents.27..xue2 xiao4 .yi3 jing1 .bian1 ji4 .he2 .chu1 ban3 .le5 .yi1 .ben3 .shu1 ..??
.??
.??
.?
.??
.?
.?
.?
.?
.
?.School .has already .edit (-ed) .and .publish .-ed .a .
.book.NN .AD .VV .CC .VV .AS .CD .M .NN .PU.ROOT.o .o.o.o .o .o .o .o .o(a) Original dependency tree..xue2 xiao4 .yi3 jing1 .bian1 ji4 .he2 .chu1 ban3 .le5 .yi1 .ben3 .shu1 ..??
.??
.??
.?
.??
.?
.?
.?
.?
.
?.School .has already .edit (-ed) .and .publish .-ed .a .
.book.NN .AD .VV .CC .VV .AS .CD .M .NN .PU.ROOT .o.o .o .o.o(b) Vbs in rectangular boxes..xue2 xiao4 .yi3 jing1 .bian1 ji4 .he2 .chu1 ban3 .le5 .yi1 .ben3 .shu1 ..??
.?
.?
.?
.??
.??
.?
.??
.?
.
?.School .a .
.book .has already .edit (-ed) .and .publish .-ed(c) Merged and reordered VbFigure 1: An example that shows how to de-tect and reorder a Verbal block (Vb) in a sen-tence.
In the first two figures 1a and 1b, Chi-nese Pinyin, Chinese tokens, word-to-word En-glish translations, and POS tags of each Chinesetoken are listed in four lines.
In Figure 1c, thereare Chinese Pinyin, reordered Chinese sentenceand its word-to-word English counterpart.Vb-Ds for ?bian1 ji4 (edit)?
: ?yi3 jing1 (has al-ready)?, ?he2 (and)?
and ?chu1 ban4 (publish)?and hence this Vb consists of three tokens and oneVb.
The outer rectangular box in Figure 1b showsthat the Vb ?bian1 ji4 (edit)?
as the Vb-H. Fig-ure 1c shows an image of how this Vb will bereordered while the inner orders are kept.
Notethat the order of building Vbs from which Vb-Hs,?chu1 ban3 (publish)?
or ?bian1 ji4 (edit)?
will notaffect any change of the final result.3.2 Identifying objectsIn the most general form, objects are dependentsof verbal blocks3 that act as their arguments.While the simplest objects are nouns (N) or pro-nouns (PN), they can also be comprised of nounphrases or clauses (Downing and Locke, 2006)such as nominal groups, finite clauses (e.g.
thatclauses, wh-clauses) or non-finite clauses (e.g.
-ing clauses), among others.For every Vb in a verb phrase, clause, or sen-tence, we define the right-most object dependent(RM-D) as the word that:3Dependents of verbal blocks are dependents of any wordwithin the verbal block...ta1 .chi1 .le5 .wu3 fan4 .
.qu4 .xue2 xiao4 ..?
.?
.?
.??
.?
.?
.??
.
?.he .eat .-ed .lunch .
(and) .go(to) .school ..PN .VV .AS .NN .PU .VV .NN .PU.ROOT.o .o .o.o.o.o .o?
??
?
?
?
??
?
?he lunch eat -ed school go(to)V ??????
O V ????
OSO ?????
V O ????
VSEnglish Translation: He ate lunch, and went to school.Figure 2: An example of a Chinese sentence witha coordination of verb phrases as predicate.
Sub-ject(S), verbs(V), and objects(O) are displayed forboth verb phrases.
Lines between the original Chi-nese sentence and the reordered Chinese sentenceindicate the reordering trace of Verbal blocks(Vb).i) its POS tag is in the RM-D entry of Table 1,ii) its dependency head is inside of the verbalblock, andiii) is the right-most object among all objects ofthe verbal block.All verbal blocks in the phrase, clause, or sen-tence will move to the right-hand side of their cor-respondent RM-Ds recursively.
Figure 1b and Fig-ure 1c show a basic example of object identifica-tion.
The Chinese word corresponding to ?shu1(book)?
is a dependent of a word within the verbalblock and its POS tag is within the RM-D entrylist of Table 1 (i.e.
NN).
For this reason, ?shu1(book)?
is identified as the right-most dependentof the verbal block (Vb), and the Vb will move tothe right-hand side of it to resemble the Japaneseword order.A slightly more complex example can be foundin Figure 2.
In this example, there is a coordina-tion structure of verb phrases, and the dependencytree shows that the first verb, ?chi1 (eat)?, ap-pears as the dependency head of the second verb,?qu4 (go)?.
The direct right-most object depen-dent (RM-D) of the first verb, ?chi1 (eat)?, is theword ?wu3 fan4 (lunch)?, and the verb ?chi1 (eat)?will be moved to the right-hand side of its objectdependent.There are cases, however, where there is no co-ordination structure of verb phrases but a simi-lar dependency relation occurs between two verbs.Figure 3 illustrates one of these cases, where themain verb ?gu3 li4 (encourage)?
has no direct de-28..xue2 xiao4 .gu3 li4 .xue2 sheng1 .can1 yu3 .she4 hui4 .shi2 jian4 ..??
.??
.??
.??
.??
.??
.
?.school .encourage .student .participate .social .practice.NN .VV .NN .VV .NN .NN .PU.o .ROOT.o.o.o .o .o??
??
??
??
??
??
?school student social practice participate encourageS ????
V ??????
OS ????
V ??????????
OS ??????
O ???????
VS ????????????
O ???????????
VEnglish Translation: School encourages student to participate in social practice.Figure 3: An example of a Chinese sentence inwhich an embedded clause appears as the objectof the main verb.
Subjects (S), verbs (V), and ob-jects (O) are displayed for both the sentence andthe clause.
Lines between the original Chinesesentence and the reordered Chinese sentence in-dicate the reordering trace of Verbal blocks (Vb).pendent that can be considered as an object sinceno direct dependent has a POS tag in the RM-D en-try of Table 1.
Instead, an embedded clause (SVO)appears as the object argument of the main verb,and the main verb ?gu3 li4 (encourage)?
appearsas the dependency head of the verb ?can1 yu2 (par-ticipate)?.In the news domain, reported speech is a fre-quent example that follows this pattern.
In ourmethod, if the main verb of the sentence (labeledas ROOT) has dependents but none of them is adirect object, we move the main verb to the end ofthe sentence.
As for the embedded clause ?xue2sheng1 (student) can1 yu2 (participate) she4 hui4(social) shi2 jian4 (practice)?, the verbal block ofthe clause is the word ?can1 yu2 (participate)?and its object is ?shi2 jian4 (practice)?.
Apply-ing our reordering method, the clause order resultsin ?xue2 sheng1 (student) she4 hui4 (social) shi2jian4 (practice) can1 yu2 (participate)?.
The resultis an SOV sentence with an SOV clause, whichresembles the Japanese word order.3.3 Identifying invariable grammaticalparticlesIn Chinese, certain invariable grammatical parti-cles that accompany verbal heads have a differentword order relative to their heads, when comparedto Japanese.
Those particles are typically ?bei4?particle (POS tags LB and SB) and subordinatingconjunctions (POS tag CS).
Those particles appearon the left-hand side of their dependency heads inChinese, and they should be moved to the right-hand side of their dependency heads for them toresemble the Japanese word order.
Reordering in-variable grammatical particles in our frameworkcan be summarized as:i) Find dependents of a verbal head (Vb-H)whose POS tags are in the Oth-DEP entry ofTable 1.ii) Move those particles to the right-hand side oftheir (possibly reordered) heads.iii) If there is more than one such particle, movethem keeping the relative order among them.3.4 Summary of the reordering frameworkBased on the definitions above, our dependencyparsing based pre-reordering framework can besummarized in the following steps:1.
Obtain POS tags and an unlabeled depen-dency tree of a Chinese sentence.2.
Obtain reordering candidates: Vbs.3.
Obtain the object (RM-D) of each Vb.4.
Reorder each Vb in two exclusive cases byfollowing the order:(a) If RM-D exists, reorder Vb to be theright-hand side of RM-D.(b) If Vb-H is ROOT and its RM-D does notexist, reorder Vb to the end of the sen-tence.
(c) If none of above two conditions is met,no reordering happens.5.
Reorder grammatical particles (Oth-DEPs) tothe right-hand side of their correspondingVbs.Note that, unlike other works in reordering dis-tant languages (Isozaki et al 2010b; Han et al2012; Xu et al 2009), we do not prevent chunksfrom crossing punctuations or coordination struc-tures.
Thus, our method allows to achieve anauthentic global reordering in reported speech,which is an important reordering issue in news do-mains.In order to illustrate our method, a more compli-cated Chinese sentence example is given in Fig-ure 4, which includes the unlabeled dependency29..xin1wen2 .bao2dao3 .
.sui2zhe5 .jing1ji4 .de5 .fa1zhan3 .
.sheng4dan4jie2 .zhu2jian4 .jin4ru4 .le5 .zhong1guo2 .
.cheng2wei2 .shang1jia1 .jia1qiang2 .li4cu4 .mai3qi4 .de5 .yi1 .ge4 .ji2ri4 ..??
.??
.?
.??
.??
.?
.??
.?
.???
.??
.??
.?
.??
.?
.??
.??
.??
.??
.??
.?
.?
.?
.??
.
?.news .report .
.with .economic .
?s .development .
.Christmas .gradually .enter .-ed .China .
.become .businesses .strengthen .urge .purchase .
?s .one .kind .festival ..NN .VV .PU .P .NN .DEG .NN .PU .NN .AD .VV .AS .NR .PU .VV .NN .VV .VV .NN .DEC .CD .M .NN .PU.ROOT.o.o .o .o .o.o.o.o .o .o .o.o .o.o.o.o .o.o .o .o .o.o.o??
?
??
?
??
??
?
???
??
??
??
?
?
??
??
??
??
?
?
?
????
??
?????
??
??
??
???
??????
?
???
??
?
???
?
??
?
?
??
??
?
??
?
??
?
??????
??
?Entire English translation: News reports, with the economic development, Christmas has gradually entered into China, and becomes one of the festivals that businesses use to promote commerce.Figure 4: Dependency parse tree of a complex Chinese sentence example, and word alignments forreordered sentence with its Japanese counterpart.
The first four lines are Chinese Pinyin, tokens, word-to-word English translations, and the POS tags of each Chinese token.
The fifth line shows the reorderedChinese sentence while the sixth line is the segmented Japanese translation.
The entire English transla-tion for the sentence is showed in the last line.parsing tree of the original Chinese sentence, andthe word alignment between reordered Chinesesentence and its Japanese counterpart, etc.Based on both POS tags and the unlabeled de-pendency tree, first step of our method is to obtainall Vbs.
For all heads in the tree, according to thedefinition of Vb introduced in Section 3.1, thereare six tokens which will be recognized as the can-didates of Vb-Hs, that is ?bao4 dao3 (report)?,?sui2 zhe5 (with)?, ?jin4 ru4 (enter)?, ?cheng2wei2 (become)?, ?jia1 qiang2 (strengthen)?, and?li4 cu4 (urge)?.
Then, for each of the candidate,its direct dependents will be checked if they areVb-Ds.
For instance, for the verb of ?jin4 ru4 (en-ter)?, its dependents of ?zhu2 jian4 (gradually)?and ?le5 (-ed)?
will be considered as the Vb-Ds.For the case of ?jia1 qiang2 (strengthen)?, insteadof being a Vb-H, it will be recognized as Vb-Dof the Vb ?li4 cu4 (urge)?
since it is one of thedirect dependents of ?li4 cu4 (urge)?
with a qual-ified POS tag for Vb-D.
Therefore, there are fiveVbs in total, which are ?bao4 dao3 (report)?, ?sui2zhe5 (with)?, ?zhu2 jian4 (gradually) jin4 ru4 (en-ter) le5 (-ed)?, ?cheng2 wei2 (become)?, and ?jia1qiang2 (strengthen) li4 cu4 (urge)?.The next step is to identify RM-D for eachVb, if there is one.
By checking all conditions,four Vbs have their RM-Ds: ?fa1 zhan3 (develop-ment)?
is the RM-D of the Vb ?sui2 zhe5 (with)?
;?zhong1 guo2 (China)?
is the RM-D of the Vb?zhu2 jian4 (gradually) jin4 ru4 (enter) le5 (-ed)?
;?jie2 ri4 (festival)?
is the RM-D of the Vb ?cheng2wei2 (become)?
; ?mai3 qi4 (purchase)?
is the RM-D of the Vb ?jia1 qiang2 (strengthen) li4 cu4(urge)?.After obtaining all RM-Ds, we find those Vbsthat have RM-Ds and move them to right of theirRM-Ds.
As for the case of ?bao4 dao3 (report)?,since it is the root and does not have any matchedRM-D, it will be moved to the end of the sen-tence, before any final punctuation.
Finally, sincethere is no any invariable grammatical particle inthe sentence that need to be reordered, reorderinghas been finished.
From the alignments betweenthe reordered Chinese and its Japanese translationshowed in the figure, an almost monotonic wordalignment has been achieved.For comparison purposes, particle seed wordshad been inserted into the reordered sentences inthe same way as the Refined-HFC method, whichis using the information of predicate argumentstructure output by Chinese Enju (Yu et al 2011).We therefore can not entirely disclaim the useof the HPSG parser at the present stage in ourmethod.
However, we believe that dependencyparser can provide enough information for insert-ing particles.4 ExperimentsWe conducted experiments to assess how our pro-posed dependency-based pre-reordering for Chi-nese (DPC) impacts on translation quality, andcompared it to a baseline phrase-based systemand a Refined-HFC pre-reordering for Chinese toJapanese translation.We used two Chinese-Japanese training data30News CWMT+NewsBLEU RIBES BLEU RIBESBaseline 39.26 84.83 38.96 85.01Ref-HFC 39.22 84.88 39.26 84.68DPC 39.93 85.23 39.94 85.22Table 3: Evaluation of translation quality of twotest sets when CWMT, News and the combinationof both corpora were used for training.sets of parallel sentences, namely an in-house-collected Chinese-Japanese news corpus (News),and the News corpus augmented with theCWMT (Zhao et al 2011) corpus.
We extracteddisjoint development and test sets from News cor-pus, containing 1, 000 and 2, 000 sentences re-spectively.
Table 2 shows the corpora statistics.We used MeCab 4 (Kudo and Matsumoto, 2000)and the Stanford Chinese segmenter 5 (Chang etal., 2008) to segment Japanese and Chinese sen-tences.
POS tags of Chinese sentences were ob-tained using the Berkeley parser 6 (Petrov et al2006), while dependency trees were extracted us-ing Corbit 7 (Hatori et al 2011).
Following thework in (Han et al 2012), we re-implementedthe Refined-HFC using the Chinese Enju to ob-tain HPSG parsing trees.
For comparison purposeswith the work in (Isozaki et al 2010b), particleseed words were inserted at a preprocessing stagefor Refined-HFC and our DPC method.DPC and Refined-HFC pre-reordering strate-gies were followed in the pipeline by a standardMoses-based baseline system (Koehn et al 2007),using a default distance reordering model and alexicalized reordering model ?msd-bidirectional-fe?.
A 5-gram language model was built usingSRILM (Stolcke, 2002) on the target side of thecorresponding training corpus.
Word alignmentswere extracted using MGIZA++ (Gao and Vogel,2008) and the parameters of the log-linear combi-nation were tuned using MERT (Och, 2003).Table 3 summarizes the results of the Baselinesystem (no pre-reordering nor particle word inser-tion), the Refined-HFC (Ref-HFC) and our DPCmethod, using the well-known BLEU score (Pap-ineni et al 2002) and a word order sensitive met-ric named RIBES (Isozaki et al 2010a).4http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html5http://nlp.stanford.edu/software/segmenter.shtml6http://nlp.cs.berkeley.edu/Software.shtml7http://triplet.cc/software/corbitAs it can be observed, our DPC method obtainsaround 0.7 BLEU points of improvement whencompared to the second best system in both cor-pora.
When measuring the translation quality interms of RIBES, our method obtains an improve-ment of 0.3 and 0.2 points when compared to thesecond best system in News and CWMT + Newscorpora, respectively.
We suspect that corpus di-versity might be one of the reasons for Refined-HFC not to show any advantage in this setting.We tested the significance of BLEU improve-ment for Refined-HFC and DPC when comparedto the baseline phrase-based system.
Refined-HFCtests obtained p-values 0.355 and 0.135 on Newsand CWMT + News corpora, while our proposedDPC method obtained p-values 0.002 and 0.0,which indicates significant improvements over thephrase-based system.5 ConclusionsIn the present paper, we have analyzed the dif-ferences in word order between Chinese andJapanese sentences.
We captured the regulari-ties of ordering differences between Chinese andJapanese sentences, and proposed a framework toreorder Chinese sentences to resemble the wordorder of Japanese.Our framework consists in three steps.
First,we identify verbal blocks, which consist of Chi-nese words that will move all together as a blockwithout altering their relative inner order.
Sec-ond, we identify the right-most object of the verbalblock, and move the verbal block to the right of it.Finally, we identify invariable grammatical parti-cles in the original vicinity of the verbal block andmove them relative to their dependency heads.Our framework only uses the unlabeled depen-dency structure of sentences and POS tag informa-tion of words.
We compared our system to a base-line phrase-based SMT system and a refined head-finalization system.
Our method obtained a Chi-nese word order that is more similar to Japaneseword order, and we showed its positive impact ontranslation quality.6 Discussion and future workIn the literature, there are mainly two types ofparsers that have been used to extract sentencestructure and guide reordering.
The first type cor-responds to parsers that extract phrase structures(i.e.
HPSG parsers).
These parsers infer a rich31News CWMT+NewsChinese Japanese Chinese JapaneseTrainingSentences 342, 050 621, 610Running words 7,414,749 9,361,867 9,822,535 12,499,112Vocabulary 145,133 73,909 214,085 98,333News Devel.Sentences 1, 000 ?Running words 46,042 56,748 ?
?Out of Vocab.
255 54 ?
?News TestSentences 2, 000 ?Running words 51,534 65,721 ?
?Out of Vocab.
529 286 ?
?Table 2: Basic statistics of our corpora.
News Devel.
and News Test were used to tune and test thesystems trained with both training corpora.
Data statistics were collected after tokenizing and filteringout sentences longer than 64 tokens.annotation of the sentence in terms of semanticstructure or phrase heads.
Other reordering strate-gies use a different type of parsers, namely depen-dency parsers.
These parsers extract dependencyinformation among words in the sentence, oftenconsisting in the dependency relation between twowords and the type of relation (dependency label).Reordering strategies that use syntactic infor-mation have proved successful, but they are likelyto magnify parsing errors if their reordering rulesheavily rely on abundant parse information.
Thisis aggravated when reordering Chinese sentences,due to its loose word order and large variety ofpossible dependency labels.In this work, we based our study of orderingdifferences between Chinese and Japanese solelyon dependency relations and POS tags.
This con-trasts with the work in (Han et al 2012) that re-quires phrase structures, phrase-head informationand POS tags, and the work in (Xu et al 2009)that requires dependency relations, dependency la-bels and POS tags.In spite of the fact that our method uses less syn-tactic information, it succeeds at reordering sen-tences with reported speech even in presence ofpunctuation symbols.
It is worth saying that re-ported speech is very common in the news domain,which might be one of the reasons of the supe-rior translation quality achieved by our reorderingmethod.
Our method also accounted for orderingdifferences in serial verb constructions, comple-mentizers and adverbial modifiers, which wouldhave required an increase in the complexity of thereordering logic in other methods.To the best of our knowledge, dependencyparsers are more common than HPSG parsersacross languages, and our method can potentiallybe applied to translate under-resourced languagesinto other languages with a very different sentencestructure, as long as they count with dependencyparsers and reliable POS taggers.Implementing our method for other languageswould first require a linguistic study on the re-ordering differences between the two distant lan-guage pairs.
However, some word ordering differ-ences might be consistent across SVO and SOVlanguage pairs (such as verbs going before or aftertheir objects), but other ordering differences mayneed special treatment for the language pair underconsideration (i.e.
Chinese ?bei?
particles).There are two possible directions to extend thepresent work.
The first one would be to refine thecurrent method to reduce its sensitivity to POS tag-ging or dependency parse errors, and to extend ourlinguistic study on ordering differences betweenChinese and Japanese languages.
The second di-rection would be to manually or automatically findcommon patterns of ordering differences betweenSVO and SOV languages.
The objective would bethen to create a one-for-all reordering method thatinduces monotonic word alignments between sen-tences from distant language pairs, and that couldalso be easily extended to account for the uniquecharacteristics of the source language of interest.AcknowledgmentsWe would like to thank Dr. Takuya Matsuzaki forhis precious advice on this work and Dr. Jun Ha-tori for his support on using Corbit.32ReferencesPi-Chuan Chang, Michel Galley, and Christopher D.Manning.
2008.
Optimizing Chinese word segmen-tation for machine translation performance.
In Proc.of the 3rd Workshop on SMT, pages 224?232.Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, andChristopher D Manning.
2009.
Discriminative re-ordering with Chinese grammatical relations fea-tures.
In Proc.
of the Third Workshop on Syntax andStructure in Statistical Translation, pages 51?59.Angela Downing and Philip Locke.
2006.
Englishgrammar: a university course.
Routledge.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57.Nizar Habash.
2007.
Syntactic preprocessing for sta-tistical machine translation.
In Proc.
of MachineTranslation Summit XI, pages 215?222.Dan Han, Katsuhito Sudoh, Xianchao Wu, Kevin Duh,Hajime Tsukada, and Masaaki Nagata.
2012.
Headfinalization reordering for Chinese-to-Japanese ma-chine translation.
In Proc.
of the Sixth Workshop onSyntax, Semantics and Structure in Statistical Trans-lation, pages 57?66.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Ju-nichi Tsujii.
2011.
Incremental joint POS taggingand dependency parsing in Chinese.
In Proc.
of5th International Joint Conference on Natural Lan-guage Processing, pages 1216?1224.Hideki Isozaki, Tsutomu Hirao, Kevin Duh, KatsuhitoSudoh, and Hajime Tsukada.
2010a.
Automaticevaluation of translation quality for distant languagepairs.
In Proc.
of EMNNLP.Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, andKevin Duh.
2010b.
Head finalization: A simple re-ordering rule for SOV languages.
In Proc.
of WMT-MetricsMATR, pages 244?251.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProc.
of ACL ?07, Demonstration Sessions, pages177?180.Taku Kudo and Yuji Matsumoto.
2000.
Japanese de-pendency structure analysis based on support vectormachines.
In Proc.
of the EMNLP/VLC-2000, pages18?25.Charles N Li and Sandra Annear Thompson.
1989.Mandarin Chinese: A functional reference gram-mar.
Univ of California Press.Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,Ming Zhou, and Yi Guan.
2007.
A probabilistic ap-proach to syntax-based reordering for statistical ma-chine translation.
In Proc.
of ACL, page 720.Yusuke Miyao and Jun?ichi Tsujii.
2008.
Feature for-est models for probabilistic HPSG parsing.
Compu-tational Linguistics, 34:35?80.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Comput.
Linguist., 29:19?51.Franz J. Och.
2003.
Minimum error rate trainingfor statistical machine translation.
In Proc.
of ACL,pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automaticevaluation of machine translation.
In Proc.
of ACL,pages 311?318.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proc.
of the 21st COL-ING and the 44th ACL, pages 433?440.Carl Jesse Pollard and Ivan A.
Sag.
1994.
Head-driven phrase structure grammar.
The Universityof Chicago Press and CSLI Publications.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proc.
of the 7th interna-tional conference on Spoken Language Processing,2002, pages 901?904.Chao Wang, Michael Collins, and Philipp Koehn.2007.
Chinese syntactic reordering for statisticalmachine translation.
In Proc.
of the 2007 Joint Con-ference on EMNLP-CoNLL, pages 737?745.Xianchao Wu, Katsuhito Sudoh, Kevin Duh, HajimeTsukada, and Masaaki Nagata.
2011.
Extractingpre-ordering rules from predicate-argument struc-tures.
In Proc.
of 5th International Joint Conferenceon Natural Language Processing, pages 29?37.Fei Xia and Michael McCord.
2004.
Improvinga statistical MT system with automatically learnedrewrite patterns.
In Proc.
of the 20th internationalconference on Computational Linguistics.Peng Xu, Jaeho Kang, Michael Ringgaard, and FranzOch.
2009.
Using a dependency parser to improveSMT for subject-object-verb languages.
In Proc.
ofHLT: NA-ACL 2009, pages 245?253.Kun Yu, Yusuke Miyao, Takuya Matsuzaki, XiangliWang, and Junichi Tsujii.
2011.
Analysis of thedifficulties in Chinese deep parsing.
In Proc.
of the12th International Conference on Parsing Technolo-gies, pages 48?57.Hong-Mei Zhao, Ya-Juan Lv, Guo-Sheng Ben, YunHuang, and Qun Liu.
2011.
Evaluation reportfor the 7th China workshop on machine translation(CWMT2011).
The 7th China Workshop on Ma-chine Translation (CWMT2011).33
