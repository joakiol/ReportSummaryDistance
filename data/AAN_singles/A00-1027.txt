Compound Noun Segmentat ion Based on Lexical DataExtracted from Corpus*J untae  Yoonj t yoon@l inc .c i s .upenn.eduIRCS,  Un ivers i ty  of  Pennsy lvan ia ,3401 Walnut  St. ,  Su i te  400A,Ph i lade lph ia ,  PA  19104-6228,  USAAbst ractCompound noun analysis is one of the crucial prob-lems in Korean language processing because a seriesof nouns in Korean may appear without white spacein real texts, which makes it difficult to identify themorphological constituents.
This paper presents aneffective method of Korean compound noun segmen-tation based on lexical data extracted from corpus.The segmentation is done by two steps: First, it isbased on manually constructed built-in dictionaryfor segmentation whose data were extracted from 30million word corpus.
Second, a segmentation algo-rithm using statistical data is proposed, where sim-ple nouns and their frequencies are also extractedfrom corpus.
The analysis is executed based on CYKtabular parsing and min-max operation.
By exper-iments, its accuracy is about 97.29%, which turnsout to be very effective.1 I n t roduct ionMorphological analysis is crucial for processing theagglutinative language like Korean since words insuch languages have lots of morphological variants.A sentence is represented by a sequence of eojeolswhich are the syntactic unit~ delimited by spacingcharacters in Korean.
Unlike in English, an eojeolis not one word but composed of a series of words(content words and functional words).
In particu-lar, since an eojeol can often contain more than onenoun, we cannot get proper interpretation of the sen-tence or phrase without its accurate segmentation.The problem in compound noun segmentation isthat it is not possible to register all compound nounsin the dictionary since nouns are in the open setof words as well as the number of them is verylarge.
Thus, they must be treated as unseen wordswithout a segmentation process.
Furthermore, ac-curate compound noun segmentation plays an im-portant role in the application system.
Compoundnoun segmentation is necessarily required for im-proving recall and precision in Korean information* This work was supported by a KOSEF's  postdoctoral fel-lowship grant.retrieval, and obtaining better translation in ma-chine translation.
For example, suppose that acompound noun 'seol'agsan-gugrib-gongwon(Seol'agMountain National Park)' appear in documents.A user might want to retrieve documents about'seol'agsan(Seol'ag Mountain)', and then it is likelythat the documents with seol'agsan-gugrib-gongwon'are also the ones in his interest.
Therefore, itshould be exactly segmented before indexing in or-der for the documents to be retrieved with the query'seol'agsan'.
Also, to translate 'seol'agsan-gugrib-gongwon' to Seol'ag Mountain National Park, theconstituents should be identified first through theprocess of segmentation.This paper presents two methods for segmentationof compound nouns.
First, we extract compoundnouns from a large size of corpus, manually dividethem into simple nouns and construct the hand builtsegmentation dictionary with them.
The dictionaryincludes compound nouns which are frequently usedand need exceptional process.
The number of dataare about 100,000.Second, the segmentation algorithm is applied ifthe compound noun does not exist in the built-indictionary.
Basically, the segmenter is based on fre-quency of individual nouns extracted from corpus.However, the problem is that it is difficult to dis-tinguish proper noun and common noun since thereis no clue like capital letters in Korean.
Thus, justa large amount of lexical knowledge does not makegood results if it contains incorrect data and also it isnot appropriate to use frequencies obtained by auto-matically tagging large corpus.
Moreover, sufficientlexical data cannot be acquired from small amountsof tagged corpus.In this paper, we propose a method to get sim-ple nouns and their frequencies from frequently oc-curring eojeols using repetitiveness of natural lan-guage.
The amount of eojeols investigated is man-ually tractable and frequently used nouns extractedfrom them are crucial for compound noun segmen-tation.
Furthermore, we propose rain-max compo-sition to divide a sequence of syllables, which wouldbe proven to be an effective method by experiments.l_qF~To briefly show the reason that we select the oper-ation, let us consider the following example.
Sup-pose that a compound noun be composed of foursyllables 'sl s2s3s4 '.
There are several possibilities ofsegmentation i  the sequence of syllables, where weconsider the following possibilities (Sl/S2S3S4) and(sls2/s3s4).
Assume that 'sl' is a frequently ap-pearing word in texts whereas 's2s3s4' is a rarelyoccurring sequence of syllables as a word.
On theother hand 'sis2' and 's3s4' occurs frequently butalthough they don't occur as frequently as 'sl'.
Inthis case, the more likely segmentation would be(sls2/s3s4).
It means that a sequence of syllablesshould not be divided into frequently occurring oneand rarely occurring one.
In this sense, min-max isthe appropriate operation for the selection.
In otherwords, rain value is selected between two sequencesof syllables, and then max is taken from min valuesselected.
To apply the operation repetitively, we usethe CYK tabular parsing style algorithm.2 Lexica l  Data  AcquisitionSince the compound noun consists of a series ofnouns, the probability model using transition amongparts of speech is not helpful, and rather lexical in-formation is required for the compound noun seg-mentation.
Our segmentation algorithm is based ona large collection of lexical information that consistsof two kinds of data: One is the hand built seg-mentation dictionary (HBSD)  and the other is thesimple noun dictionary for segmentation (SND).2.1 Hand-Built  Segmentation DictionaryThe first phase of compound noun segmentation usesthe built-in dictionary (HBSD).
The advantage ofusing the built-in dictionary is that the segmenta-tion could (1) be very accurate by hand-made dataand (2) become more efficient.
In Korean compoundnoun, one syllable noun is sometimes highly ambigu-ous between suffix and noun, but human can easilyidentify them using semantic knowledge.
For ex-ample, one syllable noun 'ssi' in Korean might beused either as a suffix or as a noun which means'Mr/Ms' or 'seed' respectively.
Without any seman-tic information, the best way to distinguish themis to record all the compound noun examples con-taining the meaning of seed in the dictionary sincethe number of compound nouns containing a mean-ing of 'seed' is even smaller.
Besides, we can treatgeneral spacing errors using the dictionary.
By thespacing rule for Korean, there should be one contentword except noun in an eojeol, but it turns out thatone or more content words of short length sometimesappear without space in real texts, which causes thelexical ambiguities.
It makes the system inefficientto deal with all these words on the phase of basicmorphological analysis.compound nounsgajuggudu(leather shoes)gajugggeun(leather string)gaguyong(used for furniture)sagwassi(apple seed)podossi(graph seed)chuggutim (football team)analysis informationgaj ug(leather)-bgudu(shoes)gajug(leather) +ggeun(string)gagu(furniture)-bxyong(used for)sagwa(apple) q-nssi (seed)podo(grape)-t-nssi(seed)chuggu(foot ball)+tim(team)Table 1: Examples of compound noun and analysisinformation in built-in dictionaryTo construct the dictionary, compound nouns axeextracted from corpus and manually elaborated.First, the morphological analyzer analyzes 30 mil-lion eojeol corpus using only simple noun dictionary,and the failed results are candidates for compoundnoun.
After postpositions, if any, are removed fromthe compound noun candidates of the failure eoje-ols, the candidates axe modified and analyzed byhand.
In addition, a collection of compound nounsof KAIST (Korea Advanced Institute of Science &Technology) is added to the dictionary in order tosupplement them.
The number of entries containedin the built-in dictionary is about 100,000.
Table 1shows some examples in the built-in dictionary.
_Theitalic characters such as 'n' or 'x' in analysis infor-mation (right column) of the table is used to makedistinction between oun and suffix.2.2 Extraction of Lexical Information forSegmentation from CorpusAs we said earlier, it is impossible for all compoundnouns to be registered in the dictionary, and thus thebuilt-in dictionary cannot cover all compound nounseven though it gives more accurate results.
We needsome good segmentation model for compound noun,therefore.In compound noun segmentation, the thing thatwe pay attention to was that lexical information iscrucial for segmenting noun compounds.
Since acompound noun consists only of a sequence of nounsi.e.
(noun)+, the transition probability of parts ofspeech is no use.
Namely, the frequency of each nounplays highly important role in compound noun seg-mentation.
Besides, since the parameter space ishuge, we cannot extract enough lexicai informationfrom hundreds of thousands of POS tagged corpus 1even if accurate lexical information can be extractedfrom annotated corpus.
Thus, a large size of cor-pus should be used to extract proper frequencies ofnouns.
However, it is difficult to look at a large sizeof corpus and to assign analyses to it, which makesit difficult to estimate the frequency distribution ofwords.
Therefore, we need another approach for ob-taining frequencies of nouns.~It is the size of POS tagged corpus currently publicizedby ETRI (Electronics and Telecommunications Research In-stitute) project.197l#ll l i i i l l~Figure 1: Distribution of eojeols in Korean corpusIt must be noted here that each noun in compoundnouns could be easily segmented by human in manycases because it has a prominent figure in the sensethat it is a frequently used word and so familiar withhim.
In other words, nouns prominent in documentscan be defined as frequently occurred ones, which wecall distinct nouns.
Compound nouns contains thesedistinct nouns in many cases, which makes it easierto segment them and to identify their constituents.Empirically, it is well-known that too many wordsin the dictionary have a bad influence on morpho-logical analysis in Korean.
It is because rarely usednouns result in oversegmentation f they are includedin compound noun segmentation dictionary.
There-fore, it is necessary to select distinct nouns, whichleads us to use a part of corpus instead of entirecorpus that consists of frequently used ones in thecorpus.First, we examined istribution of eojeols in cor-pus in order to make the subset of corpus to extractlexical frequencies of nouns.
The notable thing inour experiment is that the number of eojeols in cor-pus is increased in proportion to the size of corpus,but a small portion of eojeols takes most parts of thewhole corpus.
For instance, 70% of the corpus con-sists of just 60 thousand types of eojeols which take7.5 million of frequency from 10 million eojeol corpusand 20.5 million from 30 million eojeols.
The lowestfrequency of the 60,000 eojeols is 49 in 30 million eo-jeol corpus.
We decided to take 60,000 eojeols whichare manually tractable and compose most parts ofcorpus (Figure 1).Second, we made morphological analyses for the60,000 eojeols by hand.
Since Korean is an aggluti-native language, an eojeol is represented by a se-quence of content words and functional words asmentioned before.
Especially, content words andfunctional words often have different distributionof syllables.
In addition, inflectional endings forpredicate and postpositions for nominals also havequite different distribution for syllables.
Hence wecan distinguish the constituents of eojeols in manycases.
Of course, there are also many cases in whichthe result of morphological analysis has ambigui-ties.
For example, an eojeol 'na-neun' in Koreanhas ambiguity of 'na/N+neun/P', 'na/PN+neun/P'and 'nal/V+neun/E'.
In this example, the partsof speech N, PN, P, V and E mean noun, pro-noun, postposition, verb and ending, respectively.On the other hand, many eojeols which are ana-lyzed as having ambiguities by a morphological n-alyzer are actually not ambiguous.
For instance,'ga-geora' (go/imperative) has ambiguities by mostmorphological nalyzer among 'ga/V+geora/E' and'ga/N+i/C+geora/E' (C is copula), but it is actu-ally not ambiguous.
Such morphological mbiguityis caused by overgeneration f the morphological n-alyzer since the analyzer uses less detailed rules forrobustness of the system.
Therefore, if we examineand correct he results scrupulously, many ambigui-ties can be removed through the process.As the result of the manual process, only 15% of60,000 eojeols remain ambiguous at the mid-level ofpart of speech classification 2.
Then, we extractedsimple nouns and their frequencies from the data.Despite of manual correction, there must be ambigu-ities left for the reason mentioned above.
There maybe some methods to distribute frequencies in caseof ambiguous words, but we simply assign the equaldistribution to them.
For instance, gage has two pos-sibilities of analysis i.e.
'gage/N' and 'galV+ge/E',and its frequency is 2263, in which the noun 'gage' isassigned 1132 as its frequency.
Table 2 shows exam-ples of manually corrected morphological nalyses ofeojeols containing a noun 'gage' and their frequen-cies.
We call the nouns extracted in such a way aset of distinct nouns.In addition, we supplement the dictionary withother nouns not appeared in the words obtainedby the method mentioned above.
First, nouns ofmore than three syllables are rare in real texts inKorean, as shown in Lee and Ahn (1996).
Theirexperiments proved that syllable based bigram in-dexing model makes much better result than othern-gram model such as trigram and quadragram inKorean IR.
It follows that two syllable nouns takean overwhelming majority in nouns.
Thus, there arenot many such nouns in the simple nouns extractedby the manually corrected nouns (a set of distinctnouns).
In particular, since many nouns of more2At the mid-level of part of speech classification, for ex-ample, endings and postpositions are represented just by onetag e.g.
E and P. To identify the sentential or clausal type(subordinate or declarative) in Korean, the ending should besubclassified for syntactic analysis more detail which can bedone by statistical process.
It is beyond the subject of thispaper.198eojeols constituents meaninggage gage/N@ga/V+ge/E store@go 2263gage-ga gage/N+ga/P store/SUBJ 165gage-neun gage/N+neun/P@ga/V+geneun/E store/TOP@go 113gage-ro gage/N+ro/P to the store 166gage-reul gage/N+reul/P store/OBJ 535gage-e gage/N+e/P in the store 312gage-eseo gage/N+eseo/P in the store 299gage-yi gage/N+yi /P  of the store 132frequenciesextracted noun frequencygage store 2797Table 2: Example of extraction of distinct nouns.
Here N, V, P and E mean tag for noun, verb, postpositionand ending and '@' is marked for representation f ambiguous analysisthan three syllables are derived by a word and suf-fixes and have some syllable features, they are usefulfor distinguishing the boundaries of constituents incompound nouns.
We select nouns of more thanthree syllables from morphological dictionary whichis used for basic morphological nalysis and consistsof 89,000 words (noun, verb, adverb etc).
Second,simple nouns are extracted from hand-built segmen-tation dictionary.
We selected nouns which do notexist in a set of distinct nouns.The frequency is assigned equally with some valuefq.
Since the model is based on min-max composi-tion and the nouns extracted in the first phase aremost important, the value does not take an effect onthe system performance.The nouns extracted in this way are referred toas a set of supplementary nouns.
And the SND forcompound noun segmentation is composed of a setof distinct nouns and a set of supplementary nouns.The number of simple nouns for compound noun seg-mentation is about 50,000.3 Compound Word  Segmentat ionA lgor i thm3.1 Basic IdeaTo simply describe the basic idea of our compoundnoun segmentation, we first consider a compoundnoun to be segmented into only two nouns.
Given acompound noun, it is segmented by the possibilitythat a sequence of syllables inside it forms a word.The possibility that a sequence of syllables forms aword is measured by the following formula.Word(si, .
.
.
sj) - fq(si , .
.
,  sj) Iq~ (1)In the formula, fq(s~,...sj) is the frequency ofthe syllable s i .
.
.s j ,  which is obtained from SNDconstructed on the stages of lexical data extraction.And, fqN is the total sum of frequencies of simplenouns.
Colloquially, the equation (1) estimates howmuch the given sequence of syllables are likely to beword.
If a sequence of syllables in the set of distinctnouns is included in a compound noun, it is moreprobable that it is divided around the syllables.
Ifa compound noun consists of, for any combinationof syllables, sequences of syllables in the set of sup-plementary nouns, the boundary of segmentation issomewhat fuzzy.
Besides, if a given sequence of syl-lables is not found in SND, it is not probable that itis a noun.Consider a compound noun 'hag?gyo-saeng-hwal(school life)'.
In case that segmentation ofsyllables is made into two, there would be fourpossibilities of segmentation for the example asfollows:1. hag 9yo-saeng-hwal2.
hag-gyo saeng-hwal3.
hag-gyo-saeng hwal4.
hag-gyo-saeng-hwal ?As we mentioned earlier, it is desirable that the eo-jeol is segmented in the position where each sequenceof syllables to be divided occurs frequently enoughin training data.
As the length of a sequence of sylla-bles is shorter in Korean, it occurs more frequently.That is, the shorter part usually have higher fre-quency than the other (longer) part when we dividesyllables into two.
Moreover, if the other part isthe syllables that we rarely see in texts, then thepart would not be a word.
In the first of the aboveexample, hag is a sequence of syllable appearing fre-quently, but gyo-saeng-hwa!
is not.
Actually, gyo-saeng-hwal is not a word.
On the other hand, bothhag-gyo and saeng-hwal re frequently occurring syl-lables, and actually they are all words.
Put anotherway, if it is unlikely that one sequence of syllables isa word, then it is more likely that the entire syllablesare not segmented.
The min-max composition is asuitable operation for this case.
Therefore, we first199take the minimum value from the function Word foreach possibility of segmentation, and then we choosethe maximum from the selected minimums.
Also,the argument taking the maximum is selected as themost likely segmentation result.Here, Word(si .
.
.
sj) is assigned the frequency ofthe syllables i .
.
.
sj from the dictionary SND.
Be-sides, if two minimums are equal, the entire sylla-ble such as hag-gyo-saeng-hwal, if compared, is pre-ferred, the values of the other sequence of syllablesare compared or the dominant pattern has the pri-ority.3.2 Segmentat ion  A lgor i thmIn this section, we generalize the word segmentationalgorithm based on data obtained by the trainingmethod escribed in the previous ection.
The basicidea is to apply min-max operation to each sylla-ble in a compound noun by the bottom-up strat-egy.
That is, if the minimum between Words oftwo sequences of syllables is greater than Word ofthe combination of them, the syllables should besegmented.
For instance, let us suppose a com-pound noun consist of two syllable Sl and s2.
Ifmin(Word(Sl), Word(s2)) > Word(sis2), then thecompound noun is segmented into Sl and s2.
It isnot segmented, otherwise.
That is, we take the max-imum among minimums.
For example, 'hag' is a fre-quently occurring word, but 'gyo' is not in Korean.In this case, we can hardly regard the sequence ofsyllable 'hag-gyo' as the combination of two words'hag' and 'gyo'.
The algorithm can be applied recur-sively from individual syllable to the entire syllableof the compound noun.The segmentation algorithm is effectively imple-mented by borrowing the CYK parsing method.Since we use the bottom-up strategy, the execu-tion looks like composition rather than segmenta-tion.
After all possible segmentation f syllables be-ing checked, the final result is put in the top of thetable.
When a compound noun is composed of nsyllables, i.e.
sis2.
.
,  s,~, the composition is startedfrom each si (i = 1. .
.
n).
Thus, the possibility thatthe individual syllable forms a word is recorded inthe cell of the first row.Here, Ci,j is an element of CYK ta-ble where the segment result of the sylla-bles sj,...j+i-1 is stored (Figure 2).
Forinstance, the segmentation result such thatar g max(min( W ord( s l ), Word(s2)), Word(s1 s2))is stored in C1,2.
What is interesting here isthat the procedure follows the dynamic pro-gramming.
Thus, each cell C~,j has the mostprobable segmentation result for a series of syl-lables sj ..... j+i-1- Namely, C1,2 and C2,3 havethe most likely segmentation of sis2 and s2s3respectively.
When the segmentation of sls2s3 isabout to be checked, min(value(C2,1), value(C1,3)),1i11-1n1 ... j ... n -1  n\\composition resul tfor sl""sl+l-1Figure 2: Composition Tablemin(value(Cl,1),value(C2,2)) and Word(sls2s3)are compared to determine the segmentation forthe syllables, because all Ci,j have the most likelysegmentation.
Here, value(Ci,j) represents thepossibility value of Ci,j.Then, we can describe the segmentation algorithmas follows:When it is about to make the segmentation f syl-lables s~... sj, the segmentation results of less lengthof syllables like s i .
.
.
s j -1 ,  S~+l... sj and so forthwould be already stored in the table.
In order tomake analysis of s i .
.
.
s j, we combine two shorterlength of analyses and the word generation possibil-ities are computed and checked.To make it easy to explain the algorithm, let ustake an example compound noun 'hag-gyo-saeng-hwa~ (school ife) which is segmented with 'haggyo'(school) and 'saenghwar (life) (Figure 3).
When itcomes up to cell C4,1, we have to make the mostprobable segmentation for 'hag-gyo-saeng-hwal' i.e.SlS2S3S4.
There are three kinds of sequences of syl-lables, i.e.
sl in CI,1, sis2 in C2,1 and SlS2S3 in C3,1that can construct he word consisting of 8182s384which would be put in Ca,1.
For instance, the wordsls2s3s4 (hag-gyo-saeng-hwal) is made with Sl (hag)combined with sus3s4 (gyo-saeng-hwal).
Likewise,it might be made by sis2 combined with s3s4 andsls2s3 combined with s4.
Since each cell has themost probable result and its value, it is simple tofind the best segmentation for each syllables.
Inaddition, four cases, including the whole sequencesof syllables, are compared to make segmentation ofSlS2SaS4 as follows:1. rain(value(C3,1), value(C3,4))2. min(value(C2,1), value(C2,3))3. min(value( Cl,1), value(C3,2))4.
Word(SlS2SaS4) = Word(hag-gyo-saeng-hwal)Again, the most probable segmentation result isput in C4,1 with the likelihood value for its segmen-tation.
We call it MLS (Most Likely Segmentation)200hag gyo saeng hwa2( ?
.... .
.
.
.
.
.
.
_ _arg max(min(w(hag),w(gyo)),w(hag-gyo))Figure 3: State of table when analyzing 'hag-gyo-saeng-hwal'.
Here, w(si .
.
.
sj) = value(Cij)which is found in the following way:MLS(C4,z) =ar g max(rain(value(C3,1), value( C3,a ) ),rain(value(G2,1), value(C2,3)),rain(value(C1,1), value(C3,2)),Word(sls2s3sa))From the four cases, the maximum value and thesegmentation result are selected and recorded inC4,1.
To generalize it, the algorithm is describedas shown in Figure 4.The algorithm is straightforward.
Let Word andMLS be the likelihood of being a noun and the mostlikely segmentation for a sequence of syllables.
In theinitialization step, each cell of the table is assignedWord value for a sequence of syllables sj .
.
.
sj+i+lusing its frequency if it is found in SND.
In otherwords, if the value of Word for the sequence in eachcell is greater than zero, the syllables might be as anoun a part of a compound noun and so the value isrecorded as MLS.
It could be substituted by morelikely one in the segmentation process.In order to make it efficient, the segmentation re-sult is put as MLS instead of the syllables in casethe sequence of syllables exists in the HBND.
Theminimum of each Word for constituents of the resultas Word is recorded.Then, the segmenter compares possible analysesto make a larger one as shown in Figure 4.
When-ever Word of the entire syllables is less than that ofsegmented one, the syllables and value are replacedwith the segmented result and its value.
For in-stance, sl + s2 and its likelihood substitutes C2,1if min(Word(sl) ,  Word(s2)) > Word(sis2).
Whenthe entire syllables from the first to nth syllable areprocessed, C,~,x has the segmentation result.The overall complexity of the algorithm followsthat of CYK parsing, O(n3).3.3 Defau l t  Analys is  and Tun ingFor the final result, we should take into considerationseveral issues which are related with the syllablesthat left unsegmented.
There are several reasonsthat the given string remains unsegmented:i .o?1 .. .i i .oo I~equence of ~yllabl~ iu diviner geldefault ~ementatitm pointerFigure 5: Default segmentation pointer for 'geon-chug-sa-si-heom' where 'si-heom' is a very frequentlyused noun.1.
The first one is a case where the string consistsof several nouns but one of them is a unreg-istered word.
A compound noun 'geon-chug-sa-si-heom' is composed of 'geon-chug-sa' and'si-heom', which have the meanings of autho-rized architect and examination.
In this case,the unknown noun is caused by the suffix suchas 'sa' because the suffix derives many words.However, it is known that it is very difficult totreat the kinds of suffixes since the suffix like'sa' is a very frequently used character in Ko-rean and thus prone to make oversegmentationif included in basic morphological nalysis.2.
The string might consist of a proper noun alad anoun representing a position or geometric infor-mation.
For instance, a compound noun 'kim-dae-jung-dae-tong-ryeong' is composed of 'kim-dae-jung' and 'dae-tong-ryeong' where the for-mer is personal name and the latter means pres-ident respectively.3.
The string might be a proper noun itself.
Forexample, 'willi'amseu' is a transliterated wordfor foreign name 'Williams' and 'hong-gil-dong'is a personal name in Korean.
Generally, sinceit has a different sequence of syllables from ina general Korean word, it often remains unseg-mented.If the basic segmentation is failed, three proce-dures would be executed for solving three problemsabove.
For the first issue, we use the set of distinctnouns.
That is, the offset pointer is stored in the ini-tialization step as well as frequency of each noun incompound noun is recorded in the table.
Attentionshould be paid to non-frequent sequence of syllables(ones in the set of supplementary nouns) in the de-fault segmentation because it could be found in anyproper noun such as personal names, place names,etc or transliterated words.
It is known that the per-formance drops if all nouns in the compound nounsegmentation dictionary are considered for defaultsegmentation.
We save the pointer to the boundaryonly when a noun in distinct set appears.
For theabove example 'geon-chug-sa-si-heom', the defaultsegmentation would be 'geon-chug-sa' nd 'si-heom'since 'si-heom' is in the set of distinct nouns and thepointer is set before 'si-heom' (Figure 5).201/* initialization step */for i----1 to n dofor j= l  to n- i+l dovalue(Ci,j) = Word(s t .
.
.
sj+i-1);MLS(C i , j )  = s t .
.
.
sj+~-i ; if value(Ci,j) > 0?
; otherwisefor i=2 to n dofor j= 1 to i dovalue( Ci,j ) = max(min( value( Ci_l, j  ), value( C1j+i_ l  ) ),min (value( C i -  2,j ) , value( C2,j_ 2 ) ) ,min(va\[ue(Cl, j) ,value(Ci_,, j+l)),Word(st... s~+~))M LS(  Ci,j ) = arg max(min(value( C i _ l j ) ,  value( C i j+ i_ l  ) ),min( value( Ci_ 2j  ) , value( C2 j_  2 ) ) ,Word(s~ .
, .
si+j)):, , , , , ,  , , , ,% .
.
.
.
.
.
, , , ,Figure 4: The segmentation algorithmIf this procedure is failed, the sequence of syllablesis checked whether it might be proper noun or not.Since proper noun in Korean could have a kind ofnominal suffix such as 'daetongryeong(president)' or'ssi(Mr/Ms)'  as mentioned above, we can identifyit by detaching the nominal suffixes.
If there doesnot exist any nominal suffix, then the entire syllableswould be regarded just as the transliterated foreignword or a proper noun like personal or place name.4 Experimental ResultsFor the test of compound noun segmentation, wefirst extracted compound noun from ETRI POStagged corpus 3.
By the processing, 1774 types ofcompound nouns were extracted, which was used asa gold standard test set.We evaluated our system by two methods: (1)the precision and recall rate, and (2) segmentationaccuracy per compound noun which we refer to asSA.
They are defined respectively as follows:P rec is ion  =number of correct constituents in proposed segment resultstotal number o\] constituents in proposed segment resultsReca l l  =number of correct constituents in proposed segment resultstotal number of constituents in compoundnounsSA =number of correctly segmented compound nounsto ta l  number of compoundnouns3The corpus was constructed by the ETRI (Electronicsand Telecommunications Research Institute) project for stan-dardization of natural anguage processing technology and thecorpus presented consists of about 270,000 eojeols at present.What influences on the Korean IR system iswhether words are appropriately segmented or not.The precision and recall estimate how appropriatethe segmentation results are.
They are 98.04% and97.80% respectively, which shows that our algorithmis very effective (Table 3).SA reflects how accurate the segmentation is for acompound noun at all.
We compared two methods:(1) using only the segmentation algorithm with de-fault analysis which is a baseline of our system andso is needed to estimate the accuracy of the algo-rithm.
(2) using both the built-in dictionary and thesegmentation algorithm which reflects system accu-racy as a whole.
As shown in Table 4, the baselineperformance using only distinct nouns and the al-gorithm is about 94.3% and fairly good.
From theresults, we can find that the distinct nouns has greatimpact on compound noun segmentation.
Also, theoverall segmentation accuracy for the gold standardis about 97.29% which is a very good result for theapplication system.
In addition, it shows that thebuilt-in dictionary supplements he algorithm whichresults in better segmentation.Lastly, we compare our system with the previouswork by (Yun et al , 1997).
It is impossible that wedirectly compare our result with theirs, since the testset is different.
It was reported that the accuracygiven in the paper is about 95.6%.
When comparingthe performance only in terms of the accuracy, oursystem outperforms theirs.Embeded in the morphological nalyzer, the com-pound noun segmentater is currently being used forsome projects on MT and IE which are worked inseveral institutes and it turns out that the system isvery effective.202Number of correct constituentsRatePrecision3553/362898.04Recall3553/363797.80Table 3: Result 1: Precision and recall rateSANumber of correct constituentsRateWhole System Baseline1726\]1774 1673/177497.29 94.30Table 4: Result 2: Segmentation accuracy for Compound Noun5 Conc lus ionsIn this paper, we presented the new method forKorean compound noun segmentation.
First, weproposed the lexical acquisition for compound nounanalysis, which consists of the manually constructedsegmentation dictionary (HBSD) and the dictionaryfor applying the segmentation algorithm (SND).
Thehand-built segmentation dictionary was made manu-ally for compound nouns extracted from corpus.
Thesimple noun dictionary is based on very frequentlyoccurring nouns which are called distinct nouns be-cause they are clues for identifying constituents ofcompound nouns.
Second, the compound noun wassegmented based on the modification of CYK tab-ular parsing and min-max composition, which wasproven to be the very effective method by exper-iments.
The bottom up approach using min-maxoperation guarantees the most likely segmentation,being applied in the same way as dynamic program-ming.With our new method, the result for segmenta-tion is as accurate as 97.29%.
Especially, the al-gorithm made results good enough and the built-in dictionary supplemented the algorithm.
Conse-quently, the methodology is promising and the seg-mentation system would be helpful for the applica-tion system such as machine translation and infor-mation retrieval.6 AcknowledgementWe thank Prof. Mansuk Song at Yonsei Univ.
andProf.
Key-Sun Choi at KAIST to provide data forexperiments.Re ferencesCha, J., Lee, G. and Lee, J.
1998.
Generalized Un-known Morpheme Guessing for Hybrid POS Tag-ging of Korean.
In Proceedings of the 6th Work-shop on Very Large Corpora.Choi, K. S., Han, Y. S., Han, Y. G., and Kwon, O.W.
1994.
KAIST Tree Bank Project for Korean:Present and Future Development.
In Proceedingsof the International Workshop on Sharable Natu-ral Language Resources.Elmi, M. A. and Evens, M. 1998.
Spelling Cor-rection Using Context.
In Proceedings o\] COL-ING/A CL 98Hopcroft, J. E. and Ullman, J. D. 1979.
Introduc-tion to Automata Theory, Languages, and Com-putation.Jin, W. and Chen, L. 1995.
Identifying UnknownWords in Chinese Corpora In Proceedings of NL-PRS 95Lee, J. H. and Ahn, J. S. 1996.
Using n-gramsfor Korean Text Retrieval.
In Proceedings of 19thAnnual International A CM SIGIR Conference onResearch and Development in Information Re-trievalLi, J. and Wang, K. 1995.
Study and Implementa-tion of Nondictionary Chinese Segmentation.
InProceedings of NLPRS 95Nagao, M. and Mori, S. 1994.
A New Method ofN-gram Statistics for Large Number of N and Au-tomatic Extraction of Words and Phrases fromLarge Text Data of Japanese.
In Proceedings ofCOLING 94Park, B, R., Hwang, Y. S. and Rim, H. C. 1997.Recognizing Korean Unknown Words by Compar-atively Analyzing Example Words.
In Proceedingso\] ICCPOL 97Sproat, R. W., Shih, W., Gale, W. and Chang,N.
1994.
A Stochastic Finite-State Word-segmentation Algorithm for Chinese.
In Proceed-ings of the 32nd Annual Meeting o\] ACLYoon, J., Kang, B. and Choi, K. S. 1999.
Informa-tion Retrieval Based on Compound Noun Analysisfor Exact Term Extraction.
Submitted in Journalof Computer Processing of Orientla Language.Yoon, J., Lee, W. and Choi, K. S. 1999.
Word Seg-mentation Based on Estimation of Words fromExamples.
Technical Report.Yun, B. H., Cho, M. C. and Rim, H. C. 1997.
Seg-menting Korean Compound Nouns Using Statis-tical Information and a Preference Rules.
In Pro-ceedings of PACLING.203
