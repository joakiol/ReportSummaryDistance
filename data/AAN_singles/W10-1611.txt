Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,pages 76?83, Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsCombining CBIR and NLP for Multilingual Terminology Alignmentand Cross-Language Image IndexingDiego A. Burgos HerreraTranslation and New Technologies GroupUniversity of AntioquiaCalle 67 No.
53-108 ?
Bloque 11burgos.diego@gmail.comAbstractIn this paper, an overview of an approach forcross-language image indexing and multilin-gual terminology alignment is presented.
Con-tent-Based Image Retrieval (CBIR) isproposed as a means to find similar images intarget language documents in the web andnatural language processing is used to reducethe search space and find the image index.
Asthe experiments are carried out in specializeddomains, a systematic and recursive use of theapproach is used to align multilingual termi-nology by creating repositories of images withtheir respective cross-language indices.1 IntroductionImages, as representation of real world entities,constitute a sine qua non prerequisite for a numberof language tasks.
For instance, children as well asforeign language learners often resort to images inorder to concretize lexical learning through asso-ciative processes (cf.
Bloom, 2000: 57).Likewise, human translators particularly benefita lot from images when dealing with specializedtexts.
For example, a word-based image search is avery useful technique to enhance understanding ofthe source text and achieve precision in the targettext.
In the context of online resources, a site withthe image of a device provides the translator notonly with an illustration of the object, but also withhyperlinks to websites containing relevant infor-mation.However, for an integral usage of images as asupportive resource for automated languageprocesses, comprehensive indexed image databasesas well as wide-coverage lists of suitable indexterms are required.
The availability of such listsand the material to index images are language de-pendent.
For instance, for English, considerablymore resources are available than for Spanish.
Astudy carried out by Burgos (2006) with bilingualSpanish-English terminological dictionaries re-vealed that the average of retrieved Spanish docu-ments per term from the web was dramaticallylower (7,860) than the average of retrieved Englishdocuments (246,575).
One explanation to this isthe huge size of the web search space for Englishand the little search space for Spanish.
However,another reason is that Spanish terms found in tradi-tional terminological dictionaries could not be ofconventional usage among experts and do notrepresent what is actually contained in the searchspace.
Therefore, more suitable index terms mustbe looked for.In the present work, content-based image re-trieval (CBIR) is proposed as a means for multilin-gual terminology retrieval from the web with thepurpose of aligning a multilingual glossary andbuilding up an image index.
The main goal of thisresearch is to exploit the co-occurrence of imagesand terms in specialized texts which has beencalled the bimodal co-occurrence (BC).
Experi-ments have been done so far for English and Span-76ish with a few observations in other languages,e.g., Portuguese.
Figure 1 shows a forecast of thewhole system.The following section provides references onprevious work and suggests that the use of termi-nology for indexing specialized domain images ina bilingual or multilingual setting has not beendiscussed in previous literature.
Section 3 de-scribes the bimodal co-occurrence (BC) hypothesiswith more detail.
Section 4 provides an overviewof how CBIR supports image indexing and termalignment and includes an outline of the procedureto select candidate indices through concrete / ab-stract discrimination.
Section 5 presents the currentappeals and needs of this research and section 6sketches the future work.Figure 1.
Forecast of the system.
A spider is launch tothe Internet.
Websites fulfilling predefined criteria aretemporarily saved and their images analyzed by DORIS.If an image in the website presents feature values withina threshold determined by the example image features,nouns are extracted and classified from the surroundingtext to make up a list of candidate target terms whichcould designate the object in the website?s image.
Final-ly, index-image alignment is carried out.2 Related ResearchThe particular nature of this research where lin-guistic and visual representations converge tomake up a bimodal co-occurrence which is in-tended to be exploited for multilingual term re-trieval from the web requires the support of diversespecialized knowledge to be applied along theimage-based multilingual term retrieval proposedhere.
As a consequence, the required processes willbe framed within or related to the fields and sub-fields of cross-language information retrieval,cross-language retrieval from image collections,image-term alignment, image annotation and con-tent-based image retrieval.Many of the latest contributions on the abovementioned fields have been presented in widelyknown events such as the Text Retrieval Confe-rence (TREC), the Cross-Language EvaluationForum (CLEF), the Language Resource EvaluationConference (LREC), the Special Interest Group inInformation Retrieval (SIGIR) Conference or theSymposium on String Processing and InformationRetrieval (SPIRE), among others.For work related to cross-language image re-trieval which deals with the problem of retrievingimages from multilingual collections, see Cloughet al (2006), Clough et al (2005), Clough (2005),Bansal et al (2005), Daumke et al (2006), Iz-quierdo-Bevi?
et al (2005) or Peinado et al(2005).Likewise, for standard and alternatives propos-als for Content-Based Image Retrieval systems, thereader can check DORIS (Jaramillo and Branch,2009b), CIRES1 (Iqbal and Aggarwal, 2003),QBIC2 (Flickner et al, 1995), PHOTOBOOK3(Pentland et al, 1996), IMATCH4 and Visual-SEEk5 (Smith and Chang, 1996), Nakazato et al(2003) or Iqbal and Aggarwal (2003).
On the otherhand, for a detailed description of the CBIR stan-dard technology, see Urcid Pliego (2003), Geradts(2003) or Rui et al (1999) who present concreteinformation on the main features for CBIR as wellas on some related systems and research.
For web-based CBIR related work, see Carson et al (2002),Yi et al, (2000), Chang et al (1997), Tollmar et al(2004) or  Drelie et al (2007).
An updated review,compilation of CBIR techniques, real world appli-cations, evaluation techniques and interesting ref-erences can be found in Datta et al (2008).Content and Text-Based Cross-Language ImageRetrieval works can be found in Alvarez et al(2005), Besan?on et al (2005), Besan?on and Mil-1 http://amazon.ece.utexas.edu/~qasim/research.htm2http://domino.research.ibm.com/comm/pr.nsf/pages/rsc.qbic.html3 http://vismod.media.mit.edu/vismod/demos/photobook/4 http://www.photools.com/5http://www.ctr.columbia.edu/~jrsmith/html/pubs/acmmm96/acmfin.html77Index2Index1L1 L2Referentlet (2006), Chang and Chen (2006)  or Deselaers etal.
(2006).Image Annotation contributions can be reviewedin Barnard et al (2003), Cheng et al (2005), Liu etal.
(2006), Qiu et al (2006), Rahman et al (2005),Florea et al (2006), G?ld et al (2006), Petkovaand Ballesteros (2005), M?ller et al (2006) or Liand Wang (2003).Finally, some image-term alignment work hasbeen presented in Burgos and Wanner (2006), Dec-lerck and Alcantara (2006); Li and Wang (2003);Barnard and Forsyth (2001); Pastra (2006) andWang et al (2004).3 BC HypothesisThe starting point of this proposal is the BC hypo-thesis which can be defined as follows.We assume language independent bimodal co-occurrence of images and their index terms in thecorpus.
This implies that if an image occurs in adocument of the corpus, the corresponding indexterm will also occur in the same document (seeFigure 2).Figure 2.
Representation of the BC-hypothesisFigure 2 also suggests the BC in a bilingual set-ting.
That is, when there is an image of an object inthe source language corpus along with its indexterm there should also be an image of the sameobject along with its index term in the target lan-guage corpus.
This means that matching both im-ages would get the two equivalent terms closer.Table 1 shows an example of the bilingual settingof the BC.
Both bimodal pairs (image and term)were extracted from manually tracked websites.
Itis an example of two manually matched imagestaken from two different language websites whichalso serve to illustrate how cross-language equiva-lences between index terms can be established.Table 1.
BC-hypothesis for indexing in a bilingual set-ting.In order to prove this BC assumption with somemore representative data, a preliminary empiricalstudy (carried out initially for English) was carriedout.
A sub-corpus of 20 noun phrases6 designatingconcrete entities from the automotive industry wasextracted from an issue of the Automotive Engi-neering International Online7 journal?s Tech Briefssection and used to retrieve documents from theweb.
The first 10 results (i.e., web pages) for eachterm were stored.
Each of the web pages was ma-nually analyzed to check the BC.
The result wasthat the 20 terms confirmed the BC-hypothesis in145 sites (out of 200) which means a 72.5% ofpositive cases.4 CBIR-Based Image indexingIn order to make the most of the BC, it is necessaryto automate the process of image matching andimage indexing.
The fact of matching two imagescoming from different language documents gene-rates comparable corpora (i.e., topic related) andincreases the probability of aligning two equivalentterms by reducing the search space.
To do so, weuse DORIS, a Domain-ORiented Image Searcher(Jaramillo and Branch, 2009a).
DORIS is a JAVAapplication to retrieve visual information whichuses both geometric and Zernike moments basedon texture and shape information contained in im-ages.
DORIS performance reaches a 90% of preci-sion (Jaramillo and Branch, 2009b).For the image indexing, we first start from asource language indexed image.
An internet seg-ment in the target language is delimited as thesearch space whose images are compared with thesource language image using DORIS.
When a6 See (Quirk et al, 1985: 247) or (Bosque, 1999: 8-28, 45-51)with respect to the interpretation of the concept ?concretenoun?.7 Cf.
http://www.sae.org/automag/, state January, 2006.78positive image matching occurs, the target lan-guage document containing the matched image ismarked as a potential location of the target lan-guage index term.Given that more noise results from a largesearch space, the size of the image database isusually one of the major concerns in CBIR applica-tions.
In our work, we observed that the first prob-lem to tackle is the appropriate definition of theweb segment that will constitute the search space.Therefore, scalability and quality issues will beinitially addressed by systematically predefiningthe websites which could contain the image andtherefore the target term.
In this regard, and as astarting point, the Open Directory Project8 is usedto define our search space.
This way, not only cat-egories but also languages can be filtered.
For ex-ample, the urlhttp://www.dmoz.org/Business/Automotive/ leadsto the automotive category which contains subca-tegories and sites in English.
On the other hand,following the urlhttp://www.dmoz.org/World/Espa?ol/Negocios/Industrias/Automotriz/ which specifies the language,the user finds subcategories and sites of the catego-ry automotriz for Spanish.The image database size and quality will dependon this definition.
Uniformity is more likely, forexample, within the photographs of the same sitethan between the images of two or more sites.Likewise, there will be greater variance of imagecharacteristics between the images of two differentdomains than within the images of the same do-main, and so on.Current results were achieved using DORIS.The observations made so far with respect tomatching of images on the web suggest that somepositive matches in rather homogeneous searchspaces provided enough target index term locationsto pursue index candidate selection.4.1 Index Candidate SelectionAs it has been suggested, BC can be used for mo-nolingual or bilingual indexing.
Once this settinghas been decided and the target image has beenlocated as described in the previous section, theindex candidate selection can be carried out but,before, it is possible to reduce even more the8 http://dmoz.org/search space for the index term location by parsingthe text surrounding the target image and extract-ing the noun phrases (NP).We distinguish NPs from other sort of phrasesby means of a chunker.
Once all NPs have beenextracted, some normalization is done in order tooptimize the coming noun classification stage.
Thecleaning consists of removing determiners at thebeginning of the phrase; lemmatization (if appro-priate); discarding NPs whose head noun is anacronym9; splitting Saxon possessives, and delet-ing proper nouns and numbers:three development objectives --> development objectiveFSE?s single direct injector --> single direct injectorGiven the nature of the association, we are fo-cusing, that is image-term alignment, the list ofremaining NPs can be additionally pruned by clas-sifying nouns intro concrete and abstract10.Classifying nouns as denoting an abstractum ora concretum is not a trivial task and cannot bewidely covered in this paper because of the limitedspace.
It can be said, however, that for noun classi-fication, some approaches have been consideredhere.
For example, remarkable contributions weremade particularly by Bullinaria (2008), Katrenkoand Adriaans (2008), Peirsman et al (2008),Shaoul and Westbury (2008), Van de Cruys (2008)and Versley (2008).
They use word space and syn-tactic models which, in some cases, behave verywell.As for the present study experimentation con-cerning noun classification, three approaches weretested.
The number one used non-linguistic va-riables, the number two was based on syntacticpatterns and the number three used lexical seman-tics information taken from WordNet (Fellbaum,1998).
The automatic semantic annotation wasdone by the SuperSenseTagger (Ciaramita, 2006).In fact, it is the latter approach the one that yieldedthe best results with a precision of 88.6% (for de-tailed information, see Burgos, 2009).9 NPs with acronyms as HN are not included at this stage ofthe work since often do not reveal whether they designateconcrete or abstract entities ?
which could hinder furthervalidation.10 The experiments in this stage so far have been done forEnglish.79Concrete Abstract Noannota-tionNoana-lysisConcrete 81 14 1 4Abstract 8 90 0 2Table 2.
Results of noun classification for 100 concretenouns and 100 abstract nouns.
The first two col-umns/rows show the confusion matrixThese figures suggest that out of 95 concretenouns, 81 were correctly annotated, and that out of98 abstract nouns, 90 were annotated with the rightsense.4.2 Index-Image AlignmentWith a 90% of precision in image matching and an88.6% of precision in the noun classification task,we assume a high probability of having the rightimage with a reduced list of index candidates.Now, the indexing process can be simplified ifthe image file name matches any of the candidates.For cases where such matching does not occur, thefollowing procedure is proposed.For indexing the target image, each candidate isused to query the image database (e.g., Google) forimages.
For each candidate, the 20 first retrievedimages are compared with the target image usingDORIS.
When a positive image match occurs, theoriginal image is indexed with the candidate thatwas used to retrieve from the web the image thatyielded the positive image match.
Table 4 illu-strates this procedure by an example.
In the exam-ple, the images retrieved by steering wheel and airfilter did not match with the original image, butone of the images retrieved by cylinder head did.Therefore, the original image is indexed as cylind-er head.NP GoogleImagesOriginalimageMatching(+/-)Newindexsteeringwheel?
??
?
???
?cylinderhead?
??
??
???+?
?cylinderheadair filter ?
??
?
???
?Table 3.
Illustration of the monolingual image-indexalignment procedure.5 DiscussionThe approach shows that image indices can beassigned taking into account usage, specificity andgeographical variants.
The fact of indexing theimage with a term retrieved from its context as-sures that the index term is being used.
Moreover,this technique tries to retrieve the appropriate de-gree of specificity that the index of a specific do-main image is expected to present ?
which is oftendetermined by the number of modifiers of multi-word expressions.
Likewise, even for specializeddiscourse, indices should respond to geographicalvariants.
This aspect can be controlled by specify-ing country domains.6 Appeals and needsThis work could be incorporated with projectsdealing with the access to existing informationbases by providing multilingual and multimodalextensions to them.
For instance, assistive technol-ogy databases (e.g.
EASTIN) or patent retrievalengines (cf.
Codina et al, 2008) which contain agreat deal of visual content.Content-Based Image Retrieval (CBIR) is animportant contribution to multimodal informationretrieval.
In addition, pairing images with equiva-lent multilingual terminology has become a matterof interest, particularly in specialized domains.This work could integrate CBIR and natural lan-guage processing (NLP) techniques so that imagescan be used as language independent representa-tions to help in finding documents of textual orontology descriptions.Our approach can be especially useful for webusers who do not know the structure of the classifi-cation system to successfully search or when theydo not know the language and special terminologyof the information base.Thus, this work can be integrated to other sys-tems in order to provide cross-lingual retrieval andmachine translation for both queries and docu-ments and to enable visualization support for queryformulation and document content presentation.Given the nature of this research?s products,they can be included into the scope of multilingual-ity by combining CBIR and cross-language infor-mation retrieval technology.
A link toterminological databases can also be established so80they can be automatically fed with entries and vis-ual content.As for this research needs, an adaptation of theSST to Spanish would be really valuable.
The SSThas already been ported to Italian which representsan interesting experience to take into account.On the other hand, optimization and integrationof the research modules such as a web crawler andan interface for CBIR and noun classification arestill pending.7 Future workGiven that not all process stages of the proposalpresented in this paper have been completely inte-grated and automated, an overall evaluation has notbeen possible so far.
Future work aims at integrat-ing DORIS in modules for index candidate selec-tion and index-image alignment.
The goal is to beable to compile multilingual specialized glossariesafter systematic and recursive exploration of welldelimited web segments and storage of imageswith their respective cross-language indices.
Like-wise, some other methods to improve discrimina-tion between concrete and abstract nouns will beresearched.
The above cited related works in thisline have not been tested yet for our proposal, but,for future work, they will be taken into accountprovided that these models rely on local informa-tion and it certainly represents an advantage forthis specific task11.
Even if linguistic specific fea-tures are hard to find in both classes of nouns, theyare not completely discarded.
Finally, further expe-riments will be carried out with other domains thanautomotive engineering.AcknowledgmentsThis study is part of a wider research work beingcarried out by the author within the framework ofhis PhD thesis at the IULA, Universitat PompeuFabra, Barcelona, Spain.
It was partially supportedby a grant from the Government of Catalonia ac-cording to resolution UNI/772/2003 of the Depar-tament d?Universitats, Recerca i Societat de laInformaci?
dated March 10th, 2003.11 From a theoretical and experimental point of view, Altarribaet al (1999) provide concreteness, context availability, andimageability ratings and word associations for abstract, con-crete, and emotion words.
These ratings may be used to fur-ther research in areas such as retrieval of abstract and concretenouns.The author is very grateful with the anonymousreviewers of this paper as well as with Leo Wannerand Stefanos Vrochidis for their valuable com-ments.ReferencesAltarriba, J.; Bauer, L. M. & Benvenuto, C. (1999),'Concreteness, context availability, and imageabilityratings and word associations for abstract, concrete,and emotion words', Behavior Research Methods,Instruments, & Computers 31(4), 578-602.Alvarez, C.; Oumohmed, A. I.; Mignotte, M. & Nie,J.Y.
(2005), Multilingual Information Access forText, Speech and Images, Springer Berlin / Heidel-berg, Berlin, chapter Toward Cross-Language andCross-Media Image Retrieval, pp.
676-687.Bansal, V.; Zhang, C.; Chai, J. Y.
& Jin, R. (2005),Multilingual Information Access for Text, Speechand Images, Springer Berlin / Heidelberg, Berlin,chapter MSU at ImageCLEF: Cross Language andInteractive Image Retrieval, pp.
805-815.Barnard, K. & Forsyth, D. (2001), Learning the seman-tics of words and pictures, in 'Proceedings of the In-ternational Conference on Computer Vision', pp.408--415.Barnard, K.; Duygulu, P.; Forsyth, D.; de Freitas, N.;Blei, D. M. & Jordan, M. I.
(2003), 'MatchingWords and Pictures', Journal of Machine LearningResearch 3, 1107?1135.Besan?on, R. & Millet, C. (2006), Using Text and Im-age Retrieval Systems: Lic2m Experiments at Im-ageCLEF 2006, in 'Working notes of the CLEF 2006Workshop'.Besan?on, R.; Hede, P.; Moellic, P.A.
& Fluhr, C.(2005), Multilingual Information Access for Text,Speech and Images, Springer Berlin / Heidelberg,Berlin, chapter Cross-Media Feedback Strategies:Merging Text and Image Information to ImproveImage Retrieval, pp.
709-717.Bloom, P. (2000), How Children Learn the Meanings ofWords, MIT Press.Bosque, I.
(1999).
El nombre com?n.
In Bosque, I.,Demonte, V. (eds) Gram?tica descriptiva de la len-gua castellana.
Madrid: Espasa Calpe, pp.
3-75.Bullinaria, J.
A.
(2008), Semantic Categorization UsingSimple Word Co-occurrence Statistics, in BaroniMarco; Evert Stefan & Lenci Alessandro,ed.,'ESSLLIWorkshop on Distributional LexicalSemantics'.Burgos, D. & Wanner, L. (2006), Using CBIR for Mul-tilingual Terminology Glossary Compilation andCross-Language Image Indexing, in 'Proceedings ofthe Workshop on Language Resources for Content-based Image Retrieval', pp.
5-8.Burgos, D. (2006).
Concept and Usage-Based Approach81for Highly Specialized Technical Term Translation.In Gotti, M., Sarcevic, S. (eds) 2006.
Insights intoSpecialized Translation.
Bern: Peter Lang.Burgos, D. (2009) ?Clasificaci?n de nombres concretosy abstractos para extracci?n terminol?gica?.
In Laterminolog?a y los usuarios de la informaci?n: pun-tos de encuentro y relaciones necesarias para latransferencia de la informaci?n.
4, 5 and 6 of May,2009.
Medellin, Colombia.
ISBN: 978-958-714-251-8 .Carson, C., Belongie, S., Greenspan, H., Malik, J.(2002).
Blobworld: Image Segmentation Using Ex-pectation-Maximisation and its Application to ImageQuerying.
IEEE Trans.
Pattern Analysis and Ma-chine Intelligence 24(8), pp.
1026-1038.Chang, S., Smith, J. R., Beigi, M., Benitez, A.
(1997).Visual Information Retrieval from Large DistributedOnline Repositories.
Communications of the ACM40(12).
63-71.Chang, Y.C.
& Chen, H.H.
(2006), Approaches of Us-ing a Word-Image Ontology and an Annotated Im-age Corpus as Intermedia for Cross-Language ImageRetrieval, in 'Working notes of the CLEF 2006Workshop'.Chen, F., Gargi, U., Niles, L., Schutze, H. (1999).
Mul-ti-Modal Browsing of Images in Web Documents.Document Recognition and Retrieval VI, Proceed-ings of SPIE 3651, pp.
122-133.Chen, Y., Wang, J. Krovetz, R. (2003).
CLUE: Cluster-Based Retrieval of Images by Unsupervised Learn-ing.
IEEE Transactions on Image Processing, Vol.14 (8) pp.
1187-1201.Cheng, P.C.
; Chien, B.C.
; Ke, H.R.
& Yang, W.P.
(2005), NCTU_DBLAB@ImageCLEF 2005: Auto-matic annotation task, in 'Working Notes of theCLEF Workshop 2005'.Ciaramita, M. & Altun, Y.
(2006), Broad-CoverageSense Disambiguation and Information Extractionwith a Supersense Sequence Tagger, in 'Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing'.Clough, P. (2005), Multilingual Information Access forText, Speech and Images, Springer Berlin / Heidel-berg, Berlin, chapter Caption and Query Translationfor Cross-Language Image Retrieval, pp.
614-625.Clough, P.; Grubinger, M.; Deselaers, T.; Hanbury, A.& M?ller, H. (2006), Overview of the ImageCLEF2006 photographic retrieval and object annotationtasks, in 'Working notes of the CLEF 2006 Work-shop'.Clough, P.; M?ller, H. & Sanderson, M. (2005), Multi-lingual Information Access for Text, Speech and Im-ages, Springer Berlin / Heidelberg, Berlin, chapterThe CLEF 2004 Cross-Language Image RetrievalTrack, pp.
597-613.Codina, J.; Pianta, E.; Vrochidis, S.; Papadopoulos, S.(2008) ?Integration of Semantic, Metadata and Im-age search engines with a text search engine for pa-tent retrieval?, Semantic Search 2008 Workshop,Tenerife, Spain, 2 June.Datta, R.; Joshi, D.; Li, J.
& Wang, J.
Z.
(2008), 'Imageretrieval: Ideas, influences, and trends of the newage', ACM Comput.
Surv.
40(2), 1--60.Daumke, P.; Paetzold, J.
& Mark?, K. (2006), Morpho-saurus in ImageCLEF 2006: The effect of subwordson biomedical IR, in 'Working notes of the CLEF2006 Workshop'.Declerck, T. & Alcantara, M. (2006), Semantic Analysisof Text Regions Surrounding Images in Web Docu-ments, in 'Proceedings of the Workshop on Lan-guage Resources for Content-based ImageRetrieval', pp.
9-12.Deselaers, T.; Weyand, T. & Ney, H. (2006), ImageRetrieval and Annotation Using Maximum Entropy,in 'Working notes of the CLEF 2006 Workshop'.Fellbaum, C. (1998), WordNet: An Electronic LexicalDatabase, MIT Press, Cambridge.Gelasca, E. D.; Ghosh, P.; Moxley, E.; Guzman, J. D.;Xu, J.; Bi, Z.; Gauglitz, S.; Rahimi, A. M. & Manju-nath, B. S. (2007), 'CORTINA: Searching a 10 Mil-lion + Images Database'.G?ld, M. O.; Thies, C.; Fischer, B.
& Lehmann, T. M.(2006), Combining global features for content-basedretrieval of medical images, in 'Working notes of theCLEF 2006 Workshop'.Iqbal, I.
& Aggarwal, J. K. (2003), Feature Integration,Multi-image Queries and Relevance Feedback inImage Retrieval, in '6th International Conference onVisual Information Systems (VISUAL 2003)', pp.467-474.Izquierdo-Bevi?, R.; Tom?s, D.; Saiz-Noeda, M. &Vicedo, J. L. (2005), University of Alicante in Im-ageCLEF2005, in 'Working Notes of the CLEFWorkshop 2005'.Jaramillo, G. & Branch, J.
(2009), 'Recuperaci?n deIm?genes por Contenido Utilizando Momentos', Re-vista Iteckne 5(2).Jaramillo, G. E. & Branch, J. W. (2009), Recuperaci?nEficiente de Informaci?n Visual Utilizando Momen-tos, in 'XXXV Conferencia Latinoamericana de In-form?tica - CLEI 2009'.Katrenko, S. & Adriaans, P. (2008), Qualia Structuresand their Impact on the Concrete Noun Categoriza-tion Task, in Baroni Marco; Evert Stefan & LenciAlessandro, ed.,'ESSLLIWorkshop on DistributionalLexical Semantics'.Li, J.
& Wang, J.
Z.
(2003), 'Automatic Linguistic In-dexing of Pictures by a Statistical Modeling Ap-proach', IEEE TRANSACTIONS ON PATTERNANALYSIS AND MACHINE INTELLIGENCE 25(9),1075-1088.Liu, J.; Hu, Y.; Li, M. & Ying Ma, W. (2006), MedicalImage Annotation and Retrieval Using Visual Fea-82tures, in 'Working notes of the CLEF 2006 Work-shop'.M?ller, H.; Gass, T. & Geissbuhler, A.
(2006), Perform-ing image classification with a frequency?based in-formation retrieval schema for ImageCLEF 2006, in'Working notes of the CLEF 2006 Workshop'.Pastra, K. (2006), Image-Language Association: are welooking at the right features?, in 'Proceedings of theWorkshop on Language Resources for Content-based Image Retrieval', pp.
40-43.Peinado, V.; L?pez-Ostenero, F. & Gonzalo, J.
(2005),UNED at ImageCLEF 2005: Automatically Struc-tured Queries with Named Entities over Metadata, in'Working Notes of the CLEF Workshop 2005'.Peirsman, Y.; Heylen, K. & Geeraerts, D. (2008), SizeMatters: Tight and Loose Context Definitions inEnglish Word Space Models, in Baroni Marco;Evert Stefan & Lenci Alessandro,ed.,'ESSLLIWorkshop on Distributional LexicalSemantics'.Petkova, D. & Ballesteros, L. (2005), Categorizing andAnnotating Medical Images by Retrieving TermsRelevant to Visual Features, in 'Working Notes ofthe CLEF Workshop 2005'.Qiu, B.; Xu, C. & Tian, Q.
(2006), Two-stage SVM forMedical Image Annotation, in 'Working notes of theCLEF 2006 Workshop'.Quirk, R., Greenbaum, S., Leech, G. Svartvik, J.
(1985).A Comprehensive Grammar of the English Lan-guage.
London: Longman.Rahman, M. M.; Desai, B. C. & Bhattacharya, P.(2005), Supervised Machine Learning based Medi-cal Image Annotation and Retrieval, in 'WorkingNotes of the CLEF Workshop 2005'.Routledge English Technical Dictionary.
Copenhaguen:Routledge.
1998.Shaoul, C. & Westbury, C. (2008), Performance ofHAL-like word space models on semantic cluster-ing, in Baroni Marco; Evert Stefan & Lenci Ales-sandro, ed.,'ESSLLIWorkshop on DistributionalLexical Semantics'.Shen H.T., Ooi B.C., Tan K.L.
(2000).
Giving Mean-ings to WWW Images.
In: Proceedings of the 8thACM international conference on multimedia, 30October - 3 November 2000, Los Angeles, pp 39-48Tsai, C. (2003).
Stacked Generalisation: a Novel Solu-tion to Bridge the Semantic Gap for Content-BasedImage Retrieval.
Online Information Review, Vol.27 (6), pp.
442-445.Van de Cruys, T. (2008), A Comparison of Bag of-Words and Syntax-based Approaches for Word Ca-tegorization, in Baroni Marco; Evert Stefan & LenciAlessandro, ed.,'ESSLLIWorkshop on DistributionalLexical Semantics'.Versley, Y.
(2008), Decorrelation and Shallow Seman-tic Patterns for Distributional Clustering of Nounsand Verbs, in Baroni Marco; Evert Stefan & LenciAlessandro, ed.,'ESSLLIWorkshop on DistributionalLexical Semantics'.Wang, X. J.; Ma, W.Y.
& Li, X.
(2004), Data-drivenapproach for bridging the cognitive gap in image re-trieval, in 'Proceedings of the 2004 IEEE Interna-tional Conference on Multimedia and Expo (ICME2004)', pp.
2231-2234.Yeh, T., Tollmar, K., Darrell, T. (2004).
Searching theWeb with Mobile Images for Location Recognition.IEEE Computer Society Conference on ComputerVision and Pattern Recognition (CVPR'04), Vol.
2,pp.
76-81.83
