TOWARDS A DICTIONARY SUPPORT ENVIRONMENTFOR REALTIME PARSINGABSTRACTHiyan Alshawi, Bran Boguraev, Ted BriscoeComputer Laboratory, Cambridge UniversityCorn Exchange StreetCambridge CB2 3QG, U.K.In this article we describe research on thedevelopment of large dictionaries for naturallanguage processing.
We detail the development of adictionary support environment linking arestructrured version of the Longman Dictionary ofContemporary English to natural languageprocessing systems.
We describe the process ofrestructuring the information in the dictionary andour use of the Longman grammar code system toconstruct dictionary entries for the PATR-II parsingsystem and our use of the Longman word definitionsfor automated word sense classification.INTRODUCTIONRecent developments in linguistics, andespecially on grammatical theory - for example,Generalised Phrase Structure Grammar' (GPSG)(Gazdar et al, In Press), Lexical FunctionalGrammar (LFG) (Kaplan & Bresnan, 1982) - and onnatural anguage parsing frameworks - for example,Functional Unification Grammar (FUG) (Kay,1984a), PATR-II (Shieber, 1984) - make it feasible toconsider the implementation f efficient systems forthe syntactic analysis of substantial fragments ofnatural language.
These developments alsodemonstrate that if natural language processingsystems are to be able to handle the grammatical ndlogical idiosyncracies of individual lexical itemselegantly and efficiently, then the lexicon must be acentral component of the parsing system.
Real-timeparsing imposes stringent requirements on adictionary support environment; at the very least itmust allow frequent and rapid access to theinformation i  the dictionary via the dictionary headwords.The idea of using the machine-readablesource of a published dictionary has occurred to awide range of researchers - for spelling correction,lexical analysis, thesaurus construction, machine-translation, to name but a few applications - very fewhowever have used such a dictionary to support anatural anguage parsing system.
Most of the workon automated dictionaries has concentrated onextracting lexical or other information i , essentially,batch processing (eg.
Amsler, 1981; Walker &Amsler, 1983), or on developing dictionary servers foroffice automation systems (Kay, 1984b).
Few parsingsystems have substantial lexicons and even thosewhich employ very comprehensive grammars (eg.Robinson, 1982; Bobrow, 1978) consult relativelysmall lexicons, typically generated by hand.
Twoexceptions to this generalisation are the LinguisticString Project (Sager, 1981) and the Epistle Project(Heidorn et al, 1982); the former employs adictionary of less than 10,000 words, most of whichare specialist medical terms, the latter has well over100,000 entries, gathered from machine-readablesources, however, their grammar formalism and thelimited grammatical information supplied by thedictionary make this achievement, thoughimpressive, theoretically ess interesting.We chose to employ the Longman Dictionaryof Contemporary English (Procter 1978, henceforthLDOCE) as the machine-readable source for ourdictionary environment because this dictionary hasseveral properties which make it uniquelyappropriate for use as the core knowledge base of anatural anguage processing system.
Most prominentamong these are the rich grammaticalsubcategorisations of the 60,000 entries, the largeamount of information concerning phrasal verbs,noun compounds and idioms, the individual subject,collocational nd semantic odes for the entries andthe consistent use of a controlled 'core' vocabulary indefining the words throughout the dictionary.
(Michiels (1982) gives further description anddiscussion of LDOCE from the perspective ofnaturallanguage processing.
)The problem of utilising LDOCE in naturallanguage processing falls into two areas.
Firstly, wemust provide a dictionary environment which linksthe dictionary to our existing natural languageprocessing systems in the appropriate fashion andsecondly, we must restructure the information in thedictionary in such a way that these systems are ableto utilise it effectively.
These two tasks form thesubject matter of the next two sections.171THE ACCESS ENVIRONMENTTo link the machine-readable version ofLDOCE to existing natural language processingsystems we need to provide fast access from Lisp todata held in secondary storage.
Furthermore, thecomplexity of the data structures stored on discshould not be constrained in any way by the methodof access, because we have little idea what form therestructured dictionary may eventually take.Our first task in providing an environmentwas therefore the creation ofa 'l ispifed' version ofthemachine-readable LDOCE file.
A batch programwritten in a general editing facility was used toconvert the entrire LDOCE typesetting tape into asequence of Lisp s-expressions without any loss ofgenerality or information.
Figure 1 il lustrates part ofan entry as it appears in the published ictionary, onthe typesetting tape and after lispification.~vet2 ul\[Tl;X9\]tocauseto ~sten with RIVETsI:...28289801<RO154300<rlvet28289902<02< <28290005<v<28290107<0100<TI;X9<NAZV< H XS28290208<to cause to fasten with28290318<\[*CA\]RIVET\[*CB\]\[*46}s{*44}{*8A}:, , o * , o o .
o((rivet)(1 R0154300 !
< rivet)(2 2 !< !<)(5v!<)(7 100 !< T1 !
; X9 !< NAZV !< .... H---XS)(8 to cause to fasten with*CA RIVET *CB *46 s *44 *8A :.
.
.
.
.
.
.
.  )
)Figure IThis still leaves the problem of access, fromLisp, to the dictionary entry s-expressions held onsecondary storage.
Ad  hoc solutions, such assequential scanning of files on disc or extractingsubsets of such files which will fit in main memoryare not adequate as an efficient interface to a parser.
(Exactly the same problem would occur if our naturallanguage systems were implemented in Prolog, sincethe Prolog 'database facility', refers to the knowledgebase that Prolog maintains in main memory.)
Inprinciple, given that the dictionary is now in a Lisp-readable format, a powerful virtual memory  systemmight be able to manage access to the internal Lispstructures resulting from reading the entiredictionary; we have, however, adopted an alternativesolution as outlined below.We have implemented an efficient dictionaryaccess system which services requests for s-expression entries made by client Cambridge Lispprograms.
The lispified file was sorted and convertedinto a random access file together with indexinginformation from which the disc addresses ofdictionary entries for words and compounds can berecovered.
Standard database indexing techniqueswere used for this purpose.
The current access ystemis implemented in the programming language C. Itruns under UNIX  and makes use of the random fileaccess and inter-process communication facilitiesprovided by this operating system.
(UNIX  is a TradeMark  of Bell Laboratories.)
To the Lisp programmer,the creation of a dictionary process and subsequentrequests for information from the dictionary appearsimply as Lisp function calls.We have provided for access to the dictionaryvia head words and the first words of compounds andphrasal verbs, either through the spelling orpronunciation fields.
Random selection of dictionaryentries is also provided to allow the testing ofsoftware on an unbiased sample.
This access issufficient to support our current parsingrequirements but could be supplemented with theaddition of further indexing files if required.Eventually access to dictionary entries will need to beconsiderably more intelligent and flexible than asimple left-to-fight sequential pass through thelexical items to be parsed, if our processing systemsare to make full use of the information concerningcompounds and idioms stored in LDOCE.RESTRUCTURING THE DICT IONARYThe lispified LDOCE file retains the broadstructure of the typesetting tape and divides eachentry into a number of fe lds head word,pronunciation, grammar codes, definitions, examplesand so forth.
However, each of these fields requiresfurther decoding and restructuring to provide clientprograms with easy access to the information theyrequire (Calzolari (1984) discusses this need).
For thispurpose the formatting codes on the typesetting tapeare crucial since they provide clues to the correctstructure of this information.
For example, wordsenses are largely defined in terms of the 2000 wordcore vocabulary, however, in some cases other words(themselves defined elsewhere in terms of thisvocabulary) are used.
These words always appear insmall capitals and can therefore be recognisedbecause they will be preceded by a font change controlcharacter.
In Figure 1 above the definition of"r ivet"includes the noun definition of"RIVETI", as  signalledby the font change and the numerical superscriptwhich indicates that it is the noun entry homograph;additional notation exists for word senses withinhomograhps.
On the typesetting tape, font control172characters are indicated within curly brackets byhexadecimal numbers.
In addition, there is a furthercomplication because this sense is used in the pluraland the plural morpheme must be removed before"RIVET" can be associated with a dictionary entry.However, the restructuring program can achieve thisbecause such morphology is always italicised, so theprogram knows that in the context of non-corevocabulary items the italic font control charactersignals the occurrence of a morphological variant of aLDOCE head entry.A suite of programs to unscramble andrestructure all the fields in LDOCE entries has beenwritten which is capab|e of decoding all the fieldsexcept those providing cross-reference and usageinformation for complete homographs.
Figure 2illustrates a simple lexical entry before and after theapplication of these programs.The development of the restructuringprograms is a non-trivial task because theorganisation of information on the typesetting tapepresupposes it 'visual presentation, and the ability ofhuman users to apply common sense, utilise basicmorphological knowledge, ignore minor notationalinconsistencies, and so forth.
To provide a test-bed forthese programs we have implemented an interactivedictionary browser capable of displaying therestructured information in a variety of ways andrepresenting it in perspicuous and expanded form.To illustrate the problems involved in therestructuring process we will discuss therestructuring of the grammar codes in some detail,however, the reader should bear in mind that thisrepresents only one comparatively constrained fieldof an LDOCE entry and therefore, a small proportionof the overall restructuring task.
Figure 3 (Illustratesthe grammar code field for the third word sense of theverb "believe" as it appears in the publisheddictionary, on the typesetting tape and afterrestructuring.Multiple grammar codes are elided andabbreviated in the dictionary to save space andrestructuring must reconstruct the full set of codes.This can be done with knowledge of the syntax of thegrammar code system and the significance ofpunctuation and font changes.
For example, semi-colons indicate concatenated codes and commasindicate concatenated, elided codes.
However,discovering the syntax of the system is dimcult sinceno explicit description isavailable from Longman andthe code is geared more towards visual presentationthan formal precision; for example, words whichqualify codes, such as "to be" in Figure 3, appear initalics and therefore, will be preceded by the fontcontrol character "45'.
But sometimes the thin space((pair)(1 P0008800 < pair)(2 1 < <)(3 peER)(7 200 < C9 !, esp !
"46 of < CD-- < .
.
.
.
J - - -Y )(8 "45 a *44 2 things that are alike or of the samekind !, and are usu !
used together : *46 a pair ofshoes tJ a beautiful pair of legs *44 "63 compare*CA COUPLE "CB *8B *45 b *44 2 playing cards of thesame value but of different *CA SUIT *CB *46 s *8A*44 (3) : *46 a pair of kings)(7 300 < GC < ---  < --S-U---Y)(8 *45 a "44 2 people closely connected : *46 a pairof dancers *45 b *CA COUPLE *CB "88 *44 (2)(esp t. in the phr !.
*45 the happy pair *44) "45 c*46 sl "44 2 people closely connected who causeannoyance or displeasure : *46 You !
're a fine paircoming as late as this !!).
.
.
.
.
.
.
.
)(Word-sense (Number 2)((Sub-definition(Item a) (Label NIL)(Definition 2 things that are alike or of the samekind !, and are usually used together)((Example NIL (a pair of shoes))(Example NIL (a beautiful pair of legs)))(Cross-referencecompare-with(Ldoce-entry (Lexical COUPLE)(Morphology NIL )(Homograph-number 2)(Word-sense-number NIL)))(Sub-definition(item b) (Label NIL)(Definition 2 playing cards of the same valuebut of different(Ldoce-entry (SUIT)(Morphology s)(Homograph-number 1)(Word-sense-number 3))((Example NIL (a pair of kings))))))(Word-sense (Number 3)((Sub-definition(Item a) (Label NIL)(Definition 2 people closely connected)((Example NIL (a pair of dancers))))(Sub-definition(Item b) (Label NIL)(Definition(Ldoce-entry (Lexical COUPLE )(Morphology NIL)(Homograph-number 2)(Word-sense-number 2))(Gloss: especiat$y in the phrase the happy pair )))(Sub-definition(Item c) (Label slang)(Definition 2 people closely connected whocause annoyance or displeasure)((Example NIL(You!'
re a fine pair coming as/ate as this!
))))))Figure 2173believer3(7 300 !< T5ai !, (*46 toword sense 3\[TSa,b,V3;X (to be) 1, (to be) 7\]!
,  b !
;  V3 l; X (*46 to be "44)be *44) 7 !< .
.
.
.
.
.
.
.
)head: X7xhead: Xlxhead: V3head:TSahead:TSbFigure 3control character "64'  also appears; the insertion ofthis code is based solely on visual criteria, ratherthan the informational structure of the dictionary.Similarly, choice of font can be varied for reasons ofappearance and occasionally information normallyassociated with one field of an entry is shifted intoanother to create a more compact or elegant printedentry.
In addition to the 'noise' generated by the factthat we are working with a typesetting tape geared tovisual presentation, rather than a database, there areerrors in the use of the grammar code system; forexample, Figure 4 il lustrates the code for the firstsense of the noun "promise".I prOmisenl \[C (of},C3,5; under+ UIFigure 4The occurrence of the full code "C3" betweencommas is incorrect because commas are clearlyintended to delimit sequences of elided codes.
Thistype of error arises because grammatical codes areconstructed by hand and no automatic checkingprocedure is attempted (see Michiels, 1982).
Finally,there are errors or omissions in the use of the codes;for example, Figure 5 illustrates the grammar  codesfor the listed senses of the verb "upset".upset:for cat = vword sense 1 head T1word sense 2 head Iword sense 3 head T1word sense 4 head T1Figure 5These codes correspond to the simpletransitive and intransitive uses of "upset"; no codesare given for the uses of "upset" with sententialcomplements.
Clearly, the restructuring programscannot correct this last type of error, however, wehave developed a system which is sufficiently robustto handle the other problems described above.
Ratherthan apply these programs to the dictionary andcreate a new restructured file, they are applied on ademand basis, as required by the dictionary browseror the other client programs described in the nextsection; this allows us to continue to refine therestructuring programs incrementally as furtherproblems emerge.US ING THE D ICT IONARYOnce the information ia LDOCE has beenrestructured into a format suitable for accessing byclient programs, it still remains to be shown that thisinformation is of use to our natural languageprocessing systems.
In this section, we describe theuse that we have made of the grammar  codes andword sense definitions.Grammar  codesThe grammar code system used in LDOCE isbased quite closely on the descriptive grammaticalframework of Quirk et al (1972).
The codes aredoubly articulated; capital letters represent thegrammatical  relations which hold between a verb andits arguments and numbers representsubcategorisation frames which a verb can appear in.
(The small letters which appear with some codesrepresent a variety of less important information, forexample, whether a sentential complement will takean obligatory or optional complementiser.)
Most ofthe subcategorisation frames are specified bysyntactic category, but some are very ill-specified; forinstance, 9 is defined as "needs a descriptive word orphrase".
In practice anything functioning as anadverbial will satisfy this code, when attached to averb.
The criteria for assignment of capital letters toverbs is not made explicit, but is influenced by thesyntactic and semantic relations which hold betweenthe verb and its arguments; for example, 15, L5 andT5 can all be assigned to verbs which take a NPsubject and a sentential complement, but 15 will onlybe assigned if there is a fairly close semantic linkbetween the two arguments and T5 will be used inpreference to I5 if the verb is felt to be semantical lytwo place rather than one place, such as "know"versus "appear".
On the other hand, both "believe"and "promise" are assigned V3 which means theytake a NP object and infinitival complement, yetthere is a similar semantic distinction to be madebetween the two verbs; so the criteria for theassignment ofthe V code seem to be syntactic.174The parsing systems we are interested in allemploy grammars which carefully distinguishsyntactic and semantic information of this kind,therefore, if the information provided by theLongman grammar code system is to be of use weneed to be able to separate out this information andmap it into the representation scheme used for lexicalentries used by one of these parsing systems.
Todemonstrate that this is possible we haveimplemented a system which constructs dictionaryentries for the PATR-II system (Shieber, 1984 andreferences therein).
PATR-II was chosen because thesystem has been reimplemented in Cambridge andwas therefore, available; however, the task would benearly identical if we were constructing entries for asystem based on GPSG, FUG or LFG.The PATR-H parsing system operates byunifying directed graphs (DGs); the completed parsefor a sentence will be the result of successivelyunifying the DGs associated with the words andconstituents of the sentence according to the rules ofthe grammar.
The DG for a lexical item is constructedfrom its lexical entry which will consist of a set oftemplates for each syntactically distinct variant.Templates are themselves abbreviations forunifications which define the DG.
For example, thebasic entry and associated DG for the verb "storm"are illustrated in Figure 6.word storm:word sense ~ <head trans sense-no> = 1V Takes NP Dyadicworddag storm:\[cat: vhead: \[aux: falsetrans: \[pred: stormsense-no: Iarg l :  <DG15> = \[\]arg2: <DG16> = \[\]\]\]syncat: \[first : \[cat: NPhead: \[trans: <DG15>\ ] \ ]rest: \[first: \[cat: NPhead: \[trans: <DG16>\ ] \ ]rest: \[first: lambda\]\]\]\]Figure 6The template Dyadic defines the way inwhich the syntactic arguments to the verb contributeto the logical structure of the sentence; thus, theinformation that "storm" is transitive and that it islogically a two-place predicate is kept distinct.Consequently, the system can represent the fact thatsome verbs which take two syntactic arguments arenevertheless logically one-place predicates.It is not possible to automatical ly constructPATR-II dictionary entries for verbs just by mappingone full grammar code from the restructured LDOCEentry into a set of templates.
However, it turns outthat if we compare the full set of grammar  codesassociated with a particular sense of a verb, followinga suggestion of Michiels (1982), then we can constructthe correct set of templates.
That is, we can extract allthe information that PATR-II requires concerningthe subcategorisation a d semantic type of verbs.
Forexample, as we saw above, "believe" under one senseis assigned the codes T5 and V3; the presence of theT5 code tells us that "believe" is a 'raising-to-object'verb and logically two-place under the V3interpretation.
On the other hand, "persuade" is onlyassigned the V3 code, so we can conclude that it isthree-place with object control of the infinitive.
Bysystematically exploiting the collocation of differentcodes in the same field, it is possible to distinguishthe raising, equi and control properties of verbs.
Ineffect, we are utilising what was seen as thetransformational consequences of the semantic typeof the verb within classical generative grammar.word marry:word sense =~word senseword sense =>word senseword persuade:word senseword senseword senseword sense<head trans sense-no> = 1V Takes NP Dyadic<head trans sense-no> = 1V TakeslntransNP Monadic< head trans sense-no > = 2V TakesNP Dyadic<head trans sense-no> = 3V TakesNPPP Triadic<headt rans  sense-no> = IV Takes NP Dyadic<head trans sense-no> = IV TakesNPSbar Triadic<head trans sense-no> = 2V TakesNP Dyadic<head trans sense-no> = 2V TakesNPInf ObjectControl TriadicFigure 7The modified version of PATR-II that wehave implemented contains a small dictionary andconstructs entries automatically from restructuredLDOCE entries for most verbs that it encounters.
Aswell as carrying over the grammar codes, PATR-IIhas been modified to represent the word sensenumbers which particular grammar codes areassociated with.
Thus, the analysis of a sentence bythe PATR-II system now represents its syntactic andlogical structure and the particular senses of thewords (as defined in LDOCE) which are relevant inthe grammatical context.
Figure 7 il lustrates the175dictionary entries for "marry" and "persuade"constructed by the system from LDOCE.In Figure 8 we show one of the two analysesproduced by PATR-II for a sentence containing thesetwo verbs.
The other analysis is syntactically andparse: uther might persuade gwen to marry cornwallanalysis 1 :\[cat: SENTENCEhead: \[form: finiteagr: \[per: p3 hum: sg\]aux: truetrans: \[pred: possiblesense-no: 1argl:  \[pred: persuadesense-no: 2argl : \[ref: uther sense-no: 1\]arg2: \[ref: gwen sense-no: 1\]arg3: \[pred: marrysense-no: 2arg1: \[ref: gwensense-no 1 \]arg2: \[ref: cornwallsense-no: 1 \]\]\]\]\]\]Figure 8logically identical but incorporates sense two of"marry".
Thus, the system knows that furthersemantic analysis need only consider sense two of"persuade" and sense one and two of "marry"; thisrules out one further sense of each, as defined inLDOCE.Word sense def in i t ionsThe automatic analysis of the definitiontexts of LDOCE entries is aimed at making thesemantic information on word senses encoded inthese definitions available to natural languageprocessing systems.
LDOCE is particularly suitableto such an endeavour because of the 2000 wordrestricted definition vocabulary, and in fact only'central' senses of the words in this restrictedvocabulary occur in definition texts.
It is thuspossible to process the LDOCE definition of a wordsense in order to produce some representation of thesense definition in terms of senses of words in therestricted vocabulary.
This representation could thenbe combined, for the benefit of the client languageprocessing system, with the other semanticinformation encoded for word senses in LDOCE; inparticular the 'box codes' that give simple selectionalrestrictions and the 'subject codes' that classify sensesaccording to subject area usage.
(These are not in thepublished version of the dictionary, but are availableon the tape.
)There are various possibilities for the form ofthe output resulting from processing a definition.
Thecurrent experimental system produces output that isconvenient for incorporating new word senses into aknowledge base organized around classificationhierarchies, as discussed shortly.
However, thesystem allows the form of output structures to bespecified in a flexible way.
Alternative possibleoutput representations would be meaning postulatesand definitions based on semantic primitives.As mentioned above, the implementedexperimental system is intended to enable theclassification (see e.g.
Schmolze, 1983) of new wordsenses with respect to a hierarchically organizedknowledge base, for example the one described inAlshawi (1983).
The proposal being made here is thatthe analysis of dictionary definitions can provideenough information to link a new word sense todomain knowledge already encoded in the knowledgebase of a limited domain natural  languageapplication such as a database query system.
Given ahand-coded hierarchical organization of the relevant(central) senses of the definition vocabulary togetherwith a classification of the relationships betweenthese senses and domain specific concepts, theLDOCE definition of a new word sense often containsenough information to enable the inclusion of theword sense in this classification, and hence allow thenew word to be handled correctly when performingthe application task.The information ecessary for this process ispresent, in the case of nouns, as restrictions on theclasses which subsume the new type of object, itsproperties, and predications often expressed byrelative clauses.
There are also a number of morespecific predications (such as "purpose" in theexample given below) that are very common indictionary definitions, and have immediate utility forthe classification of the relationships between wordsenses.
Similarly, the information relevant to theclassification of verb and adjective senses present insense definitions includes the classes of predicatesthat subsume the new predicate corresponding to theword sense, restrictions on the arguments of thispredicate, and words indicating opposites as isfrequently the case with adjective definitions.Figure 9 below shows the output produced bythe implemented efinition analyser for lispifiedLDOCE definitions of one of the noun senses and oneof the verb senses of the word "launch".
It should beemphasized that the output produced is not regardedas a formal language, but rather as an intermediatedata structure containing information relevant o theclassification process.176(launch)(a large usu.
motor-driven boat used for carrying peopleon rivers, lakes, harbours, etc .
)((CLASS BOAT) (PROPERTIES (LARGE))(PURPOSE(PREDICATION (CLASS CARRY) (OBJECT PEOPLE))))(to send (a modern weapon or instrument) into the sky orspace by means of scientific explosive apparatus)((CLASS SEND)(OBJECT((CLASS INSTRUMENT) (OTHER-CLASSES (WEAPON))(PROPERTIES (MODERN)))) ?
(ADVERBIAL ((CASE INTO) (FILLER (CLASS SKY)))))Figure 9The analysis process is intended to extractthe most important information from definitionswithout necessarily having to produce a completeanalysis of the whole of a particular definition textsince attempting toproduce complete analyses wouldbe difficult for many LDOCE definition texts.
In factthe current definition analyser applies successivelymore specific phrasal analysis patterns; moredetailed analyses being possible when relativelyspecific phrasal patterns are applied successfully to adefinition.
A description of the details of this analysismechanism is beyond the scope of the present paper.Currently, around fifty phrasal patterns are usedaltogether for noun, verb, and adjective definitions.
Amajor difficulty encountered so far in this work stemsfrom the liberal use in LDOCE definitions ofderivational morphology and phrasal verbs whichgreatly expands the effective definition vocabulary.CONCLUSIONThe research reported in this paperdemonstrates that it is both possible and useful torestructure the information contained in LDOCE foruse in natural language processing systems.
Mostapplications for natural anguage processing systemswill require vocabularies substantially larger thanthose typically developed for theoretical ordemonstration purposes and it is often not practical,and certainly never desirable, to generate these byhand.
The use of machine-readable sources ofpublished dictionaries represents a practical andfeasible alternative tohand generation.Clearly, there is much more work to be donewith LDOCE in the extension of the use of grammarcodes and the improvement of the word senseclassification system.
Similarly, there is aconsiderable amount of information i  LDOCE whichwe have not attempted toexploit as yet; for example,the box codes, which contain selection restrictions forverbs or the subject codes, which classify word sensesaccording to the Merriam-Webster codes for subjectmatter (see Walker & Amsler (1983) for a suggesteduse for these).
The large amount of semi-formalisedinformation concerning the interpretation of nouncompounds and idioms also represents a rich andpotentially very useful source of information fornatural language processing systems.
In particular,we intend to investigate the automatic generation ofphrasal analysis rules from the information onidiomatic word usage.In the longer term, it is clear that no existingpublished ictionary can meet al the requirements ofa natural language processing system and asubstantial component ofthe research reported abovehas been devoted to restructuring LDOCE to make itmore suitable for automatic analysis.
This suggeststhat the automatic onstruction of dictionaries frompublished sources intended for other purposes willhave a limited life unless lexicography is heavilyinfluenced by the requirements of automated naturallanguage analysis.
In the longer term, therefore, theautomatic onstruction of dictionaries for naturallanguage processing systems may need to be based ontechniques for the automatic analysis of large corpora(eg.
Leech et al, 1983).
However, in the short term,the approach outlined in this paper will allow us toproduce asophisticated and useful dictionary rapidly.ACKNOWLEDGEMENTSWe would like to thank the Longman Group Limitedfor kindly allowing us access to the LDOCEtypesetting tape for research purposes.
We also thankKaren Sparck Jones and John Tait for theircomments on the first draft, which substantiallyimproved this paper.
We are very grateful to theSERC for funding this research.REFERENCESAlshawi, H.(1983) Memory and Context Mechanismsfor Automatic Text Processing, PhD Thesis, TechnicalReport 60, University Computer Laboratory,CambridgeAmsler, R.(1981) 'A Taxonomy for English Nouns andVerbs', Proceedings of the 19th Annual Meeting of theAssociation for Computational Linguistics, Stanford,California, pp.
133-138Bobrow, R.(1978) The RUS System, BBN Report3878, Bolt, Beranek and Newman Inc., Cambridge,Mass177Calzolari, N.(1984) 'Machine-Readable Dictionaries,Lexical Data Bases and the Lexical System',Proceedings of the 10th International Congress onComputational Linguistics, Stanford, CA, pp.460-461Gazdar, G., Klein, E., Pullum, G. and Sag, I.
(In press)Generalised Phrase Structure Grammar, Blackwell,OxfordHeidorn, G. et ai.
(1982) ~rhe EPISTLE text-critiquing system', IBM Systems Journal, vol.21, 305-326Kaplan, R. and Bresnan, J.
(1982) 'Lexical-FunctionalGrammar: A Formal System for GrammaticalRepresentation' in J.Bresnan (dd.
), The MentalRepresentation of Grammatical Relations, The MITPress, Cambridge, Mass, pp.173-281Kay, M.(1984a) 'Functional Unification Grammar: AFormalism for Machine Translation', Proceedings ofthe lOth International Congress on ComputationalLinguistics, Stanford, CA, pp.75-79Kay, M.(1984b) "rhe Dictionary Server', Proceedingsof the 10th International Congress on ComputationalLinguistics, Stanford, California, pp.461-462Leech, G., Garside, R. and Atwell, E.(1983), TheAutomatic Grammatical Tagging of the LOB Corpus,Bulletin of the International Computer Archive ofModern English, Norwegian Computing Centre forthe Humanities, BergenMichiels, A.
(1982) Exploiting a Large Dictionary DataBase, PhD Thesis, Universitd e Liege, LiegeProcter, P.(1978) LongmanContemporary English, LongmanHarlow and LondonDictionary ofGroup Limited,Quirk, R. et a1.
(1972) A Grammar of ContemporaryEnglish, Longman Group Limited, Harlow andLondonRobinson, J.
(1982) 'DIAGRAM: A Grammar forDialogues', Communications of the ACM, voi.25, 27-47Sager, N.(1981) Natural Language InformationProcessing, Addison-Wesley, Reading, MassShieber, S.(1984) "rhe Design of a ComputerLanguage for Linguistic Information', Proceedings ofthe lOth International Congress on ComputationalLinguistics, Stanford, CA, pp.362-366Schmolze, J.G., and Lipkis, T.A.
(1983) 'Classificationin the KL-ONE Knowledge Representation System',Proceedings, IJCAI-83, Karlsruhe, pp.330-332Walker, D. and Axnsler, A.
(1983) The Use of Machine-Readable Dictionaries in Sublanguage Analysis, SRIInternational Technical Note, Menlo Park, CA178
