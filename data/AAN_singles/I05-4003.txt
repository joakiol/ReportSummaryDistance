Corpus-oriented Acquisition of Chinese GrammarYan ZhangATR Spoken languageCommunication ResearchLaboratories2-2-2 Keihanna Science City,Kyoto, 619-0288yan.zhang@atr.jpHideki KashiokaATR Spoken languageCommunication ResearchLaboratories2-2-2 Keihanna Science City,Kyoto, 619-0288Hideki.kashioka@atr.jpAbstractThe acquisition of grammar from acorpus is a challenging task in thepreparation of a knowledge bank.
Inthis paper, we discuss the extraction ofChinese grammar oriented to a re-stricted corpus.
First, probabilistic con-text-free grammars (PCFG) areextracted automatically from the PennChinese Treebank and are regarded asthe baseline rules.
Then a corpus-oriented grammar is developed by add-ing specific information including headinformation from the restricted corpus.Then, we describe the peculiarities andambiguities, particularly between thephrases ?PP?
and ?VP?
in the extractedgrammar.
Finally, the parsing results ofthe utterances are used to evaluate theextracted grammar.1 IntroductionResearch and development work on spoken lan-guage systems for special domains has beengaining more attention in recent years.
Manyapproaches to spoken language processing re-quire a grammar system for parsing the inpututterances in order to obtain the structures, espe-cially for rule-based approaches.Manually developing grammars based on lin-guistics theories is a very difficult task.
Lan-guage phenomena are usually described as beingsymbolic systems such as lexical, syntactic, se-mantic and common sense.
Grammar develop-ment has to depend on linguistic knowledge andthe characteristics of the corpus to explicate asystem of linguistic entities.
However, it is ex-pensive and time-consuming to maintain a ro-bust grammar system by manual writing.Recently some researchers (H. Meng et al,2002; S. Dipper, 2004 and Y. Ding, 2004) havepresented a methodology to semi-automaticallycapture different grammar inductions from an-notated corpora within restricted domains.
Acorpus-oriented approach (Y. Miyao, 2004) pro-vides a way to extract grammars automaticallyfrom an annotated corpus.
The specific languageknowledge and knowledge relations need to beconstructed and oriented to different corpora andtasks (K. Chen, 2004).The Chinese treebank is a useful resource foracquiring grammar rules and the context rela-tions.
Currently there are several Chinese tree-banks on a scale of size.
In the Penn ChineseTreebank (F. Xia, 2000), each structural tree isannotated with words, parts-of-speech and syn-tactic structure brackets.
In the Sinica Treebank(CKIP), thematic roles are also labeled in theCKIP to provide deeper information.In this paper, we discuss the extraction of Chi-nese grammar oriented to a restricted corpus.First, probabilistic context-free grammars(PCFG) are extracted automatically from thePenn Chinese Treebank and are regarded as thebaseline rules.
Then a corpus-oriented grammaris developed by adding specific information in-cluding head information from the restrictedcorpus.
We then describe the peculiarities andambiguities, especially between the phrases?PP?
and ?VP?
in the extracted grammar.
Fi-17nally, the parsing results of the utterances areused to evaluate the extracted grammar.The outline of this paper is as follows: Section 2gives the process of acquiring the baseline Chi-nese grammar and the extension of the currentgrammar oriented to the corpus.
Section 3 ex-plains the grammar properties in our corpus andour approach to disambiguating some specialphrase rules, such as ?PP?
and ?VP?
and theword ??(ZAI)?
in different categories.
Section4 describes the evaluation results of the ex-tracted Chinese grammar.
Finally section 5 of-fers some concluding remarks and outlines ourfuture work.2 Grammar AcquisitionThere are two parts to acquiring grammar in oursystem.
The baseline grammar is extractedautomatically from the Penn Chinese Treebank.We define a suitable parts-of-speech and phrasecategories and extend them by introducing spe-cific information from our corpus.2.1 Grammar Extraction from Penn ChineseTreebankThe University of Pennsylvania (Upenn) hasreleased a scale of Chinese treebanks as a kindof resource since 2000 (Xia Fei et al, 2000).Each structural tree includes parts-of-speech andsyntactic structure brackets, which provides agood way to extract Chinese probabilistic con-text-free grammars (PCFG).
There are a total of325 files collected from the Xinhua newswire inthis treebank.
The majority of these documentsfocus on economic development and are organ-ized in written formats as opposed to spokenutterances, so the grammars extracted from it areseen as the baseline bank.The probabilistic context-free grammars haveproven to be very effective for parsing naturallanguage.
The produced rules are learnt bymatching the bracketed structures automaticallyfrom the trees, and the rule probabilities are cal-culated based on the maximum likelihood esti-mation (MLE), presented in the followingformula (Charniak, 1996):?
oo okkijijiNCNCNP)()()( ]]]   (1)The baseline grammar includes about 400 PCFGrules after cleaning and merging some rules withlow probabilities (Imamula et al, 2003).2.2 Extension of the Extracted GrammarDifferent corpora produce different grammarsthat have some specific information.
In baselinegrammars, many grammars are not suitable forspoken corpora.
Therefore, we need to build anappropriate grammar by using specific informa-tion in our corpus to improve the parsing resultsand machine translation systems that operates ina restricted field.
The data we used in this sys-tem is from the ATR Basic Travel ExpressionCorpus (BTEC) in which the format of utter-ances is different from the sentences in Upenn.Consequently, an appropriate phrase category isrequired to be constructed by analyzing theknowledge characteristics in BTEC.
We defineit by comparing three Chinese structure categorysystems: Sinica, University of Pennsylvania, andHIT (Harbin Institute of Technology).
A phrasecategory should be not too complicated as butcover language phenomenon in the corpus.
Ourphrase category is defined and explained in table1.Categories ExplanationNNP Noun PhraseTNP Temporal Noun PhraseLP Localizer PhraseNSP Location PhraseVP Verb PhraseAP Adjective PhraseDP Adverbial PhraseQP Quantifier PhrasePP Preposition PhraseVBAP Phrase with ??
(BA)?DENP Nominal Phrase Endingby ??
(DE)?DEP Attributive Phrase formedby ??
(DE)?Table 1 Phrase CategoriesIn BTEC, Chinese utterances are segmented andlabeled as parts-of-speech.
We not only con-struct corpus-oriented grammar rules differentlyfrom the baseline grammars but also add headinformation for each rule.In the above Table 1, the phrase category?VBAP?
is a phrase name including the preposi-tion ??(BA)?
and its following noun or verbphrase.
The phrase ?DENP?
is a special nominalphrase which has no word after the auxiliary18word ??
(DE)?, and it is usually put at the endof the utterance.
Following are some examplesof our grammars.1.
PP ?
p(sem"?")
(head)n2.
DENP ?
(head)a y(sem"?")3.
PP ?
p(sem"?")
(head)r4.
DEP ?
(head)DP deIn above rules, the mark ?sem?
means its fol-lowing word is a terminal node.3 Grammar Annotation and Disam-biguationAbove constructed Chinese grammars some-times bring out conflicts when parsing utter-ances because of the ambiguity phenomenon.Grammar annotation is done to make the gram-matical relations of an utterance more explicit.Thus, some ideas are proposed to deal with theseambiguities that are tightly related to Chineselanguage.3.1 Annotation and Analysis of GrammarPlenty of prepositions are rooted in verbs inChinese language, and most of them still keepthe function of verbs.
This phenomenon pro-duces ambiguous problems not only betweencategories preposition ?p?
and verb ?v?
but be-tween the phrases ?VP?
and ?PP?
in the struc-tures of the utterances.
PP-attachment ambiguityis a big problem related to the construction ofgrammar (S. Zhao.
2004).Firstly, we extract a lexicon of Chinese preposi-tions, which have other categories at the sametime, such as the category ?v?, adjective ?a?, andso on.
The following table shows the colloca-tions of these words and their frequencies.Word Category Frequencyp 226?v 85p 2423?vt 4857p 579?a 1058p 6422?v 4309p 1270?v 1226p 11115v 2381?d 39Table 2 Some Examples in the PrepositionLexiconWe construct some particular grammar rules forthese preposition words showed in Table 2 inorder to deal with the conflicts among thesewords.
For example, following rules are relatedto the word ???.PP?
p(sem"?")
(head)nVP?
p(sem"?")
(head)VVP?
v(sem"?")
NNP (head)VPIn order to represent the function of the ex-tracted grammar, we compare the coverage ofthe grammar in different layers between a termi-nal node and a phrase layer.
The different struc-tural trees of the same utterance in Figure 1 arelisted as follows.1.Sentence (?
?/r ?/de ?/n ?/r ?/q ?/v1??/n?
?/n?/w )|__ NNP__NNP(head)__DEP__r(head) ?
?|     |              |                       | ___ de ?|     |              | _________NNP __ n(head) ?|     ||     | ___ QP __ r(sem"?
")|               | ____q(head) ?|| __ v1(sem"?
")|| __ NNP(head) __ NNP _____n(head) ?
?|         | _________NNP(head)__n(head) ?
?| __ w ?2.
Sentence (?
?/r ?/de ?/n ?/r ?/q ?/v1??/n?
?/n?/w )|__NNP__NNP(head)*__ r ?
?|     |                       | ___ de ?|     |                       | ____  n(head) ?|     ||     | ___ QP __ r(sem"?
")|                | __ q(head) ?|| __ v1(sem"?
")|| __ NNP(head)** __ n ?
?|           | __________ n(head) ?
?| __ w ?Figure 1 Annotation of Different trees in thesame sentenceThe same utterance obtains different structuraltrees from different levels of grammar rules byparsing results, although these two trees are cor-19rect and acceptable.
The grammar plays an im-portant role in the machine translation systemwhen we build the mapping relations with thegoal languages by transform rules.
This problemis also called Granularity (K. Chen, 2004).Symbol ?**?
in Figure 1 denotes that the phrase?NNP?
is produced by the rule ?NNP ?
n(head)n?
rather than ?NNP ?
NNP (head)NNP?.3.2 Grammar DisambiguationA grammar inevitably includes ambiguitiesamong its rules.
To some extent, certain kinds ofambiguities are produced by the same ambigu-ous problems found among part-of-speech tags.As with the expression in Section 2, the ambigu-ity between the phrases ?PP?
and ?VP?
is partlyproduced by the multiple categories ?p?
and ?v?of the words.
This is a common case where thephrases ?PP?
and ?VP?
are nested against eachother.
For example, the rule ?PP ?
p (head)v?and ?VP ?
PP (head)VP?.
This situation is de-scribed in the following two utterances in Figure2.1.
Sentence (??
?/n ?/d ?/p ?
?/v ?/de??/n?/v?
)|__NNP__ n??
?||__VP__d?|      |___VP__PP*__p?|               |        |____NNP__v?
?|               |                    |____de ?|               |                    |_____n?
?|               ||               |___VP__v?|| ___ w ?2.
sentence (?/vw?/p?/r?/v?/q??/n?
)|__VP__vw?|      ||      |___VP**__PP__p?|                |          |___r?|                ||                |___VP__VP__v?|                         ||                         |___NNP__q?|                                   |____n?
?||__w?Figure 2 The Correct Trees of Utterances In-cluding phrases ?PP?
and ?VP?In sentence 1 of figure 2, the phrase ?PP?
(?/p?
?/v ?/de ?
?/n) contains the verb ???
?,and is produced by the rule ?DEP ?
v de?
and?NNP?
DEP n?
firstly.
Likewise, in sentence 2,the phrase ?VP(????)?
is produced firstlyrather than phrase ?????
is got by rule ?VP?
PP v?.
That is to say, the phrase ?VP?
hashigher priority to be produced than ?PP?.The Chinese word ???
is a special individualword in our corpus.
Its correlative disambigua-tion rules are constructed by the knowledge rela-tions listed in the following table:Categoryof ?
?
(ZAI)?The order ofrulesAmbiguity partsbracketed in  ut-teranceP(preposi-tion)1.
VP ?V(sem?
?
?)(head)r2.
VP ?
PP(head)VP?/r ?
?/d [[?/p??
/r] [?
/v ?
?/n] ]?V (verb) 1.
VP ?V(sem?
?
?)(head)r2.
VP D(head)VP?/r [?
?/d ?/v?
?/n]D (ad-verb)1.
VP ?D(sem?
?
?)(head)VP2.
DP ?
D(head)d?/r [?
?/d ?/d?/v?/u?/n]Table 3 The characteristics of word ??
?The following steps are used to identify the am-biguities between the phrases ?PP?
and ?VP?:1.
The first step is to look up the prepositionlexicon based on the category of the word andfind the relative rules from the extracted gram-mar.2.
When the ?PP?
rules conflict with the ?VP?rules, we firstly consider the verb and then selectan appropriate rule by comparing the relation-ship to neighboring preposition words.3.
Long distance rules have priority.
For in-stance, rule ?PP ?
p v nd?
is preferred to rule?PP?
p  v?.4.
It is clear that the fine-grained rules have lessrepresentational ambiguity than the coarse-20grained grammar rules in relation to the treepresentations.5.
The head information in the rules is viewed asbeing types of reference knowledge because oftheir own ambiguities.4 Evaluation for GrammarWe use the extracted grammar described in sec-tion 3 to parse Chinese utterances in BTEC andto evaluate the roles of the grammar.4.1 Parsing with GrammarThe parser adopts a bottom-up parsing algorithmin order to obtain the phrase structures of utter-ances.
There are 200 Chinese utterances selectedin our experiment.
The number of rules totals682 that are constructed manually except base-line rules from Upenn Chinese treebank.
Table 4lists the number of PCFG rules which have dif-ferent left-side phrases.Left-sidephrasefre-quencyProportion ashead informationAP 42 15DENP 20 2DEP 15 2DP 9 5LP 10 3NNP 240 114NSP 18 2PP 39 1QP 50 17TNP 28 15VBAP 7 0VP 162 106sentence 40 --Table 4 The number of rules with different left-side phrasesIn our current experiment, the evaluation is lim-ited to obtaining several special phrase struc-tures including ?NNP?, ?VP?, ?PP?, and?DENP?
by using the extracted grammar.
There-fore, the parsing results are calculated using theprecision of these phrases in the following for-mula (2) and are listed in Table 5.
We give theevaluation results of the word ???
separately inTable 6.%100)(Pr utcNNphraseec (2)where denotes the number of correctphrases in the parsing results, and is the totalnumber of the phrases in the utterances.cNtNPhrase Precisionwithout dis-ambiguationPrecisionwith disam-biguationPrec(NNP) 70.03 70.43Prec(PP) 81.51 84.17Prec(VP) 69.01 70.13Prec(DENP) 82.61 82.81Table 5 The evaluation resultsPhrasewith ??
?Precision with-out disam-biguationPrecisionwith disam-biguationPrec(PP) 79.12 83.67Prec(VP) 89.34 91.72Prec(DP) 87.71 88.02Table 6 The evaluation results of ??
?From the evaluation results, we found that theprecisions of the phrases ?NNP?
and ?VP?
werenot high due to the diversity and complexity.
Weonly processed the ambiguity between ?VP?
and?PP?
and improve the precision of phrase ?PP?.From the condition of the word ??
?, it is veryuseful for the grammar extraction to constructinformation on high-frequency words and word-to-word collocation relations.4.2 DiscussionThe Chinese language is one of the most diffi-cult languages to process.
There is still no uni-form standard for acquiring Chinese grammarthat covers all domains.
Hence, a grammarshould be constructed from the view of point ofreal research requirements in real corpora.
It isthe most important to maintain consistency andsatisfy the actual requirements of a real corpus.One of the main purposes in constructing a Chi-nese grammar is to improve its validity and ro-bustness to machine translation in a restrictedcorpus.
The development of a robust grammarbased on linguistics is difficult because of thecomplexity of deep linguistic analysis.
For ex-ample, how many annotated grammars are suit-able for the parsing system and a real machinetranslation?
What is the balance between thegranularity of grammar structures and grammar21coverage including the ambiguities?
In general,the coarse-grained grammar rules have a highercoverage rate compared with fine-grained rules,which contain more terminal nodes.
There isalso the major problem of determining whichTreebank size is required to acquire the gram-mar rules.5 Conclusion and Future WorkCorpus-oriented grammar extraction is con-ducted for the purpose of constructing more ex-plicit grammar knowledge and improving themachine translation system in a restricted corpus.Treebanks provide a useful resource for acquir-ing grammar rules.
However, it is time consum-ing to construct a much larger size Treebank,which is better for grammar extraction.
It wouldbe better if the knowledge extraction processcould be carried out iteratively.
The parser coulduse the initial grammar to produce a largeamount of structural trees.
These new treeswould provide more information on the gram-mar to improve the robustness of the grammarand the power of the parsing system.
This wholeprocess can be regarded as an automatic knowl-edge learning system.The principal idea in this paper was to acquireChinese grammar from a restricted corpus for amachine translation system.
The extractedgrammar was not only from the Penn Chinesetreebank but also from new information added toour experimental corpus.
The corpus-orientedChinese grammar was evaluated by parsing thephrase structures that includes ?NNP?, ?VP?,?PP?, ?DENP?, and the phrases relative to theword ??
?.Currently, we only focus on a few limitedphrases, and the disambiguation process hasbeen explored with specific rules manually.Therefore, to improve grammar extraction in thefuture, we will aim at increasing the robustnessand coverage of the rules and try to automati-cally reduce the ambiguity rate by constructingmore knowledge relations.
The word-to-wordcollocation relations provided useful informa-tion on grammar extraction for the detailedprocessing.AcknowledgmentThis research was supported by a contract withthe National Institute of Information and Com-munication Technology (NICT) of Japan.ReferencesHelen M. Meng and Kai-Chung Siu.
2002.
Semi-Automatic Acquisition of Domain-Specific Se-mantic Structures, IEEE Transactions on Knowl-edge and Data Engineering, vol 14, n 1,January/February, pp.
172-180Stefanie Dipper.
Grammar Modularity and its Impacton Grammar Documentation.
In Proceedings ofthe 20th International Conference on Computa-tional Linguistics (COLING), pp.
1-7, Geneva,Switzerland, 2004Claire Gardent, Marilisa Amoia and Evelyne Jacquey.Paraphrastic Grammars.
ACL Workshop on textmeaning, Barcelona, July 2004Yuan Ding and Martha Palmer.
Automatic Learningof Parallel Dependency Treelet Pairs.
In  Proceed-ings of the First International Joint Conference onNatural Language Processing (IJCNLP2004).March, Sanya, pp.
30-37, 2004Shaojun Zhao and Dekang Lin.
A nearest-neighbormethod for resolving pp-attachment ambiguity.
InProceedings of the First International Joint Con-ference on Natural Language Processing(IJCNLP2004).
March, Sanya, pp.
428-434, 2004Kenji Imamura, Eiichiro Sumita and Yuji Matsumoto.2003.
Feedback Cleaning of Machine TranslationRules Using Automatic Evaluation.
In Proceed-ings of the 41st Annual Meeting of the Associationfor Computational Linguistics (ACL 2003), pp.447-454.Keh-Jian Chen and Yu-Ming Hsieh.
Chinese Tree-bank and Grammar Extraction.
In  Proceedings ofthe First International Joint Conference on NaturalLanguage Processing (IJCNLP2004).
March,Sanya, pp.
560-565, 2004CKIP (Chinese Knowledge Information Processing).1993.
The Categorical Analysis of Chinese.
[InChinese].
CKIP Technical Report 93-05.Nankang: Academic Sinica.Fei Xia, Martha Palmer, Nianwen Xue, Mary EllenOkurowski, John Kovarik, Fudong Chiou, ShizheHuang, Tony Kroch, and Mitch Marcus.
2000.Developing Guidelines and Ensuring Consistencyfor Chinese Text Annotation.
Proceeding of thesecond International Conference on Language Re-22sources and Evaluation (LREC-2000), Athens,Greece.Rashmi Prasad, Elini Miltsahaki, Aravind Joshi andBonnie Webber.
Annotation and Data Mining ofthe Penn Discourse Treebank.
In Proceedings ofthe ACL 2004 Workshop on Discourse Annotation,Barcelona.
2004.Yusuke Miyao, Takashi Ninomiya and Jun?ichi Tsu-jii.
Corpus-oriented Grammar Development forAcquiring a Head-driven Phrase Structure Gram-mar from the Penn Treebank.
In Proceedings ofthe First International Joint Conference on NaturalLanguage Processing (IJCNLP2004).
March,Sanya, pp.
390-397, 2004E.
Charniak.
1996.
Treebank Grammars.
TechnicalReport CS-96-02, Department of Computer Sci-ence, Brown University.23
