Grapheme-to-phoneme transcription rules for Spanish,with application to automatic speech recognition and synthesisPatrizia BonaventuraCluster ReplyCorso Francia I I0Turin, Italy, 10143p.bonaventura((/replT.itJuan Maria GarridoDepartament deFilologia EspanyolaUniversitat Aut6noma de Barcelona08193 Bellaterra (Barcelona), Spainjuanlnar~ liccu.uab.esFabio GiulianiCluster ReplyCorso Francia 110Turin, Italy, 10143f.giuliani(@eply.itIsabel OrtinDepartament deFilologia EspanyolaUniversitat Aut6noma de Barcelona08193 Bellaterra (Barcelona), Spaini sabcl~/:liccu.uab.csAbstractLarge phonetic orpora including both standard and variant ranscriptions are available for manylanguages.
However, applications requiring the use of dynamic vocabularies make necessary totranscribe words not present in the dictionary.
Also, additional alternative pronunciations tostandard forms have shown to improve recognition accuracy.
Therefore, new techniques toautomatically generate variants in pronunciations have been investigated and proven to be veryeffective.
However, rule-based systems till remain useful to generate standard transcriptions otpreviously available or to build new corpora, oriented chiefly to synthesis applications.The present paper describes a letter-to-phone conversion system for Spanish designed to supplytranscriptions to the flexible vocabulary speech recogniser and to the synthesiser, both developedat CSELT (Centro Studi e Laboratori relecomunicazioni), Turin, Italy.
Different sets of rules aredesigned for the two applications.
Symbols inventories also differ, although the IPA alphabet is thereference system for both.
Rules have been written in ANSI C and implemented on DOS andWindows 95 and can be selectively applied.
Two speech corpora have been transcribed by meansof these grapheme-to-phoneme conversion rules: a) the SpeechDat Spanish corpus which includes4444 words extracted from the phonetically balanced sentences of the database b) a corpusdesigned to train an automatic aligner to segment units for synthesis, composed of 303 sentences(3240 words) and 338 isolated words; rule-based transcriptions of this corpus were manuallycorrected.The phonetic forms obtained by the rules matched satisfactorily the reference transcriptions: mostmistakes on the first corpus were caused by the presence of secondary stresses in the SpeechDattranscriptions, which were not assigned by the rules, whereas errors on the synthesis corpusappeared mostly on hiatuses and on words of foreign origin.Further developments oriented to recognition can imply addition of rules to account for LatinAmerican pronunciations (especially Mexican, Argentinian and Paraguayan); for synthesis, on theother hand, rules to represent coarticulatory phenomena atword boundaries can be implemented,in order to transcribe whole sentences.33IntroductionGrapheme-to-phoneme conversion is animportant prerequisite for many applicalionsinvolving speech synthesis and recognition \[I\].Large corpora used for these applications (e.g.WSJ, CMU, Oxford Pronunciation Dictionary,ONOMASTICA, SpeechDat) include phonetictranscriptions for both standard pronunciationsand for variants, which can represent eitherdifferences in dialectal or individual realisationof single words (intra-word variants) \[2, 3\] orvariations in the standard form produced bycoarticulation between words (inter-wordvariants) \[4\].These alternative pronuciations have been shownto improve recognition accuracy \[5\] and theyneed to be present in large phonetic database: thevariants can either be realised manually on thebasis of expert phonetic knowledge, or by a rule-based system.
However, maintenace of suchsystems is complex, because insertion of newrules often causes to change the overallperformance of the module.Therefore, new techniques to deriveautomatically rules for vapheme-to-phonemeconversion from training data have beeninvestigated.
Generally rules are obtainedthrough forced recognition, according to thefollowing procedure: 1) aligning of the canonicalpronunciation to the alternative ones by means ofa dynamic programming algorithm, in order togenerate an aligned database 2) use this databaseto train a statistical model or a binary decisiontree to generate variants of words or propernames \[1\] \[3\] \[6\] \[5\] or to model context-dependent variations at word boundary \[4\];neural networks can also be used to generatevariants in pronunciation of words \[2\] or ofsurnames \[7\], on the basis of pre-aligned or non-aligned training data \[8\].
Finally, a mixedapproach combining knowledge obtained fi'omtraining data and a priori phonetic expertise hasalso been experimented to derive possible non-native pronunciations of English and Italianwords \[9\].All these techniques have proven to be veryeffective to generate plausible alternatives tocanonical ones.
However, rule-based approachescan still represent an effective tool toautomatically obtain standard transcriptions oflarge corpora built ad hoc for special applications,in particular oriented to synthesis: a letter-to-phone rules component is very suitable torepresent allophonic and allomorphic variations\[10\] \[11\] \[12\] which are essential to allowsegmentation and diphone extraction from anacoustic database \[13\].The rule system described in the present paperwas developed on the basis of phoneticknowledge \[14\] \[15\] and has two differentapplication domains, which imply differenttranscription requirements: the recogniser forSpanish uses sub-word units \[16\] \[17\] linked tothe phonetic representation f isolated words; theunits have been trained on the corpus of wordsextracted from the phonetically balancedsentences included in the SpeechDat database.Therefore, the SpeechDat corpus has beenconsidered as the reference set of words that theconversion rules minimally had to correctlytranscribe.
Only isolated words were used, withthe same phoneme inventory employed in theoriginal SpeechDat ranscriptions, including noallophones.On the other hand, the corpus for synthesis wasselected to collect speech material to train theautomatic phonetic aligner, in order to extractdiphones for a concatenative synthesis system\[18\] and had to meet different requirements: a)units were to be pronounced both in isolatedwords and in sentences b) the phoneme inventoryhad to include the maximum number ofallophones o to allow to build a representativeacoustic dictionary containing occurences of allunits and sequences in every appropriatesegmental and prosodic context (stressed andunstressed syllables; initial and final position inthe syllable; initial, internal and final position inthe sentence; short and long sentences).Therefore, two partially different sets of ruleshave been designed for synthesis and recognition,which can be alternatively activated: the latter area subset of the former.
Both systems provide only34one variant in output, i.e.
the standard Castilian(Madrid) Spanish pronunciation.1.
Orthographic and phonetic symbolsThe orthographic string in input is preprocessedto avoid problems relative to the configuration ofthe operating system: at this stage, letters withdiacritics (corresponding to non-standard ASCIIcharacters) can either be represented by means ofextended ASCII (e.g.
'fi' = ext.
ASCII code 241)or they can be converted into a sequence ofstandard ASCII symbols ('n ~' = st. ASCII110+126).
This preprocessing is common to boththe recognition and the synthesis systems.The phonetic symbols used for recognitionrepresent the 30 basic Spanish phones, which arealso common to synthesis.
For this latter system,however, 11 extra symbols have also been addedto represent a set of allophones of the standardSpanish which show an acoustic structure clearlydifferentiated from the rest of already includedallophones.
These symbols represent stressedvowels, semivowels (i.e.
\[i\] and \[u\] allophones insecond position of falling diphthongs,distinguished from semi-consonants, or glides, i.e.
\[i\] and \[u\] allophones in first position of risingdiphthongs), the nasal labiodental allophone \[n\]\],the palatal voiced stop ~\], which accounts for thedistribution of the palatal voiced approximant \[j\],in initial position or after T or 'n'(e.g.
'conyuge'= \[k "o Gn J u x e\]) and the interdentat voicedfricative \[.6\], which accounts for the distributionof the the unvoiced interdental fricative \[9\], inend of syllable before a voiced consonant (e.g.
'llovizna' \[L o.
B'i Zh.
n a\]).
Finally, two phonestypical of most frequent foreign loan words, i.e.the unvoiced dental affricate \[ts\] (e.g.
'pizza')and the unvoiced palatal fricative \[J\] (e.g.
'flash')were added.
This gives a final set of 43 synthesissymbols.Front vowelsCentral vowelsBack vowelsSemiconsonantsSemivowelsBilabial/labiodentalconsonantsDental/alveolarconsonantsPalatal consonantsVelar consonantsi, 'i, e, 'ea, 'ao, 'o, n, 'uw.ji~ .
U ~p, b, 13, f, m, nj0, ~, t, d, 6, Ls, s,z, n, 1, r, r:tJ, X,.la,.t, j. ik,g, y,x,qTable 1.
Phonetic symbols used for transcriptions(bold: synthesis allophones; underlined: phones fromloan-words)2.
Rule componentThe rule module is composed by a) table look-upscontaining pre-stressed roots with hiatuses andwords that do not take stress within a sentence b)stress assignment rules c) transcription rules.Vowels are transcribed before consonants.
Themain complexity in vowel conversion consists indisambiguation f diphthongs and hiatuses: stressposition is crucial for correct ranscription of thesevowel sequences.
However, in the rulecomponent, they undergo a different treatment forrecognition and synthesis, which is illustrated inthe following, before a description of theconsonant rules.2.1.
Diphthongs and hiatuses rulesZ 1.1.RecognitionRules for recognition do not transcribe diphthongsand hiatuses according to the stress position.
Infact, the SpeechDat transcriptions, that theconversion rules have to reproduce, always stressthe first element of a vowel sequence andtranscribe all closed vowels as glides (es.
'rehfiye'\[rr 'e w .jj e\], 'reir' \[rr 'ej r\], 'oir' \['oj r\]).This target can be attained by deterministic rules,that account for three realisations of \[u\]: a)deletion b) full vowel \[u\] and c) semivowel \[w\].In particular, instance (a) applies when letter 'u'(henceforth letters are included between apices)appears within sequences 'gu', 'qu' before frontvowels (e.g.
'burguesia' \[b u r .
G e .
s 'i .
a\]);35transcription (b) occurs when h'  either precedes arising diphthong or it follows a consonantdifferent from 'g', 'q' and it is the stressed firstelement of a hiatus (e.g.
'cuyo' \[k u.  jj o\], 'muy'\[m 'u j\]).In all other positions, both as a first element of arising diphthong ('abuela' \[a.
B w 'e.
I a\]) or asa second element of a falling diphthong('acaudalados' \[a. k a w.  D a. l 'a .
D o s\]), 'u'istranscribed as the glide \[w\].On the other hand, \[i\] can be transcribed either asa voiced palatal approximant \[,j\] when it occursafter 'h' before a vowel (e.g.
'hiedra' \[jj 'e .
D ra\]) or like the glide \[j\] when it is the secondelement of a falling diphthong ('afeitar' \[a. f e j .t 'a r\], 'prohibido' \[p r o j .
B 'i.
D o\]), or in firstposition of a rising diphthong ('sociedad' \[s o.  Tj e .
D 'a D\]).
Otherwise, when stressed, it isrealised as \[i\] ('pingfiino' \[p i N.  g w 'i.
n o\]).Most of these transcriptions are incorrect from alinguistic point of view, but they are functional tothe recognizer they are designed for, which doesnot distinguish semi-vowels from full vowels,and unstressed vowels from stressed ones.2.1.2.
SynthesisHowever, correct rendition of hiatuses anddiphthongs is crucial for synthesis, in order toselect appropriate correspondent units.
Adifferent, more complex treatment of thesegroups is therefore required, which involves: a)initial retrieval of pre-stressed roots containinghiatuses from a table look-up b) stressassignment to other vowel sequences c)transcription according to stress position.Only primary stress is assigned by the followingprocedure, which searches in the string whether:a) the word ends either by a simple vowel (i.e.preceded by a consonant e.g.
'moc'illa','ov'illo') or by a rising diphthong (i.e.
by avowel preceded by ' i ' , 'u' or 'y', e.g.
'l ' impio', "agua', 'desm'ayo'); then stress isassigned to the vowel preceding the lastvowel or diphthong, if it is 'a,e,o' (es.'Can'aria').
Also ' i ' , 'u' and 'y' can bestressed in that position, if they are precededby 'qu', 'cu', 'gu', or by a consonant or ifthey are initial (e.g.
'Chiqu'illlo', 'engu'anta','b'urgo', 'argent'ina', "uma').b) the word ends by a vowel, preceded by avowel different from 'i,u,y'; then the second-last is stressed (es.
'Paragu'ay', 'can'oa','Bilb'ao', "cefal'ea').c) the words ends by 'n' or 's' preceded by asimple vowel; then stress falls on the second-last vowel if it is 'a,e,o' (e.g.
"orden','c'asas'); if the second-last is 'i', 'u' or 'y'and one of these vowels is either initial, orpreceded by a consonant or preceded by 'qu','cu', 'gu', then even 'i,u,y' can be stressed(es. '
'umas', 'b'urgos', 'chi qu'illos').d) the word ends by a consonant different from'n,s' preceded by a single vowel; then thatvowel is stressed (e.g.
'pap'el', 'muj'er').Stressed vowels in the sequence are thentranscribed as full vowels and unstressed oneseither as semi-vowels when in second position offalling diphthongs ('afeitar' \[a. f e i~.
t 'a r\]), oras semi-consonants if in first position of a risingdiphthong ('propia' \[p r 'o.
p j a\]).2.2.
Consonant  rulesAlso, consonants undergo a different reatment forsynthesis and recognition:'b, d, g' are transcribed as voiced stops \[b d g\] ifinitials (e.g.
'bueno') or preceded by ahomorganic nasal (e.g.
'hombre', 'conde','mingo'), or by \[1\] for the dental stop (e.g.
'told&).Otherwise, if they are internal, preceded by aconsonant different from a nasal, they are realisedas the corresponding voiced bilabial or velarfricative ~,y\]  or dental approximant \[6\] (e.g.
'amaba', 'an'uga', 'crudo').For synthesis, voiced stops are devoiced whenthey precede an unvoiced phone.
'p, t, k, c' are transcribed in the following way:'p' is deleted before 's' (e.g.
'psic61ogo'),otherwise it is realised with the correspondingbilabial stop \[p\] (e.g.
'papel').36't' is realised as the voiced dental approximant\[~5\] before 'b', 'm' and final (e.g.
'fftbol', 'cenit','istmo'), otherwise as 't' (e.g, 't6cnica').
'c' is realised as the unvoiced interdentalfricative \[0\] before a front vowel (e.g.
'exception', ceso') or as a velar voiced fricative\[y\] before 'd, n' (e.g.
'an6cdotas', 't~cnica').For synthesis, \[p t k\] are converted in thecorrespondent voiced approximant allophones,before a voiced consonant (e.g.
'atm6sfera' \[a Dhm'o  s fe r a\]).Nasals assimilate place of articulation of thefollowing consonant and are transcribed with thecorrespondent allophones (e.g.
'amplio' \ [am p l jo\], 'chanfla' ITS "a M f l  a\], 'berrinche' \[b e r: 'iGn TS e\], ~ingulo \['a N g u 1 o\]).
'r' is realised as a geminate \[r:\] when initial,before 'r', 'n', T ,  's' (e.g.
'burrito', 'redondo','honra', 'alrededores'), otherwise it is transcribedas the alveolar flap \[r\].
'z' is realised as the (inter)dental voicedapproximant \[6\] before a voiced consonant (e.g.
'juzgar', 'hallazgo', 'gozne'), otherwise as theunvoiced (inter)dental fricative \[0\] (e.g.
'azteca','raz6n', 'zapata').
'v' is transcribed as \[b\] when inital or precededby \[hi (e.g.
'verdad', 'conviene'), otherwise asthe bilabial voiced approximant (e.g.
'ovillo').
'x' is transcribed as \[ks\] when initial (in Catalanwords, present in SpeechDat, e.g.
'Xavier') or as\[ys\] when followed by a vowel or 'h' (e.g.
'examen', 'exhortaci6n'); for synthesis 'x' inthese context is realised as \[k s\].
'y' is always transcribed as the palatal voicedapproximant \[j\] in every condition forrecognition, whereas two allophones aredistinguished for synthesis: if initial, or internalafter \[1\], \[hi, 'y' is realised as a palatal voicedstop \[j\] (e.g.
'yelmo', 'inyectar'), otherwise asthe palatal approximant \[j\] (e.g.
'cayado').3.
T ranscr ip t ion  resultsThe recognition rules have been tested over theSpeechDat Spanish corpus, used to train therecogniser, and on the synthesis corpus, includingboth isolated words and sentences; however,single words composing sentences have beenseparately treated and then reassembled, becauserestructuring rules at word boundary to accountfor inter-word coarticulation were not yetimplemented.
Transcription results are reported inTable 2.SpeechDatTranscription 1.5% 0.6%errorsTotal words 4444 3578SynthesisTable 2.
Transcription errorsLack of matching between the transcriptionsproduced by the rules and those provided by theSpeechDat corpus were due to the followingreasons: a) the 23 single alphabetic letters werenot transcribed by the rules b) stress on Catalancity names was not correctly placed in theSpeechDat corpus, and the rules provided thecorrect version (e.g.
'Masnou' SD: \[m'asnow\] vs.rules: \[masn'ow\]) b) vowel sequences werealways stressed on the first element and \[i\] and \[u\]in diphthongs and hiatuses were always reportedas glides \[j\] and \[w\] respectively.
These twoSpeechDat conventions obscure the differencebetween the diphthongs and hiatuses (see abovepar.
2.1).
The rules assign stress on diphthongsand hiatuses and consequently produce correcttranscription of the closed vowels ('rehfiye' \[rr e"ujj e\], 'reir' \[rr e "i r\], 'oir' \[o "i r\]) c) city namesthat included a stressed initial capital letter in theSpeechDat corpus (e. g. Avila) could not be readin input by the transcriber, so their transcriptiondoes not match the reference one d) secondarystress is not assigned by the rules, so alltranscriptions of SpeechDat which report it, do notmatch with those provided by the rules, whichconsider only main stress (e.g.
"unicam'ente' vs."unicamente') e) some phenomena occurring atmorpheme boundary could not be transcribed (e.g.37absence of voicing of \[s\] in final position of aprefix before a voiced consonant; e.g.
'disyuntivas' \[d i s + jj u n .
t 'i .
B a s\]); in fact,no morphological parser is included.Errors over the synthesis corpus chiefly appearedon hiatuses (e.g.
'circuito' \[Th i r k w "i t o\] vs.\[Th i r k 'u i t o\]) and on words of foreign origin('boxeador' \[Bh o Gh s e a Dh 'o r\] vs. \[Bh o k se a Dh "o r\]).4.
Discussion and  fu r ther  deve lopmentsRules matched effectively the reference phonetictranscriptions in the SpeechDat corpus andshowed to constitute a useful tool to generatenew standard pronunciations, even whenextended to new corpora, like the one adopted forthe synthesis application.Further developments of the present system canconsist in adding rules for pronunciation variantsof standard Castilian Spanish, like South-American varieties (especially Mexican,Argentinian and Paraguayan), to be implementedwithin the recogniser as optional pronunciationsto the standard forms, according to a procedureused to generate dialectal variants of standardItalian \[ 19\].For synthesis, on the other hand, possibleextensions would include restructuring rules atword boundary, which enable to automaticallytranscribe words within sentences.
These rulesshould account for changes like placeassimilation of final nasals and laterals to thefollowing word-initial consonant (e.g.
'conganas' \[k o N g 'a n a s\]; 'el cho" fer' \[e G1 T$ "o fe r\]); deletion of a final unstressed vowel beforeidentical unstressed ones (e.g.
'la atmo'sfera' \[l aDh m "o s f e r a\]) and realisation of closedvowels as glides before a word-initial vowel (e.g.
'ni un' \[nj'un\]).
Also syllabification rules can beadded, in order to allow a more adequatetreatment of vowel sequences.AcknowledgementsOur thanks go to CSELT Labs synthesis andrecognition research groups and to VahidJunuzovic, for their collaboration and support.References\[1\] Andersen O., Kuhn R. et al (1996) "Comparison ofTwo Tree-Structured Approaches for Grapheme-to-Phoneme Conversion", ICSLP '96, V. 3, pp.
1700-1703, Oct. 1996.\[2\] Fukada T. and Sagisaka Y.
(1997) "AutomaticGeneration of a Pronunciation Dictionary Based on aPronunciation Network", Eurospeech '97, V. 5, pp.2471-2474, Sept. 1997.\[3\] Torre D., Villarubia L. et al (1997) "AutomaticAlternative Transcription Generation andVocabulary Selection for Flexible WordRecognizers", ICASSP-97, V. II, pp.
1463-1466,April 1997.\[4\] Ravishankar M. and Eskenazi M. (1997)"Automatic Generation of Context-IndependentPronunciations", Eurospeech '97.
V. 5, pp.
2467-2470, Sept. 1997.\[5\] Cremelie N. and Martens J.-P. (1997) "AutomaticRule-Based Generation of Word PronunciationNetworks", Eurospeech '97, V. 5. pp.
2459-2462,Sept.
1997.\[6\] Andersen O. and Dalsgaard P. (1995) "Multi-lingual testing of a self-learning approach tophonemic transcription of orthography", Eurospeech'95, pp.
1117-1120.
Sept. 1995.\[7\] Deshmukh N., Ngan J.. Hamaker J. and J. Picone(1997) "An Advanced System to GeneratePronunciations of Proper Nouns", Int.
Conf.
onAcoustics, Speech, and Signal Processing (ICASSP-97), V. II, pp.
1467-1470, April 1997.\[8\] Adamson M. and Damper R. (1996) "A RecurrentNetwork that Learns to Pronounce English Text",Int.
Conf.
on Spoken Language Processing 1996(ICSLP '96), V. 3, pp.
1704-1707, Oct. 1996.\[9\] Bonaventura P., Micca G. and Gallocchio F. (1998)"Speech recognition methods for non-nativepronunciation variations", ESCA Workshop, Rolduc,4-6 May 1998, pp.
17-23.\[10\] Bonaventura P. and Di Carlo, A.
(1985) "Regoledi trascfizione da grafema fonema per applicazionialla sintesi dell'italiano standard", Rivista Italiana diAcustica, vol.
3, pp.
85-105.\[I1\] Cavalcante Albano E. and Antonio Moreira A.
(1996) "Archisegment-based letter-to-phoneconversion for concatenative speech synthesis in38Portuguese", Int.
Conf.
on Spoken LanguageProcessing 1996 (ICSLP '96), V. 3, pp.
1708-17011,Oct.
1996.\[12\] Rios A.
(1993) "La informaci6n ling~iistica en latranscripci6n fon6tica automatica del espafiol",Boleth7 de la Sociedad Espatiola para elProcesamiento del Lenguaje Natural 13, pp.
381-387.\[13\] Salza P. (1990) "Phonetic transcription rules fortext-to-speech synthesis of Italian", Phonetica, vol.47 pp.66-83.\[14\] Canepari L. (1979) "Introduzione alia fonetica ",Einaudi, Torino.\[15\] Quilis A.
(1993) "Tratado de Fonologia yFonetica espafiolas", Madrid, Gredos.\[16\] Fissore L., Ravera F., Laface.
P. (1995)"Acoustic-phonetic modelling for flexiblevocabulary speech recognition".
EuroSpeech 95,Madrid.
pp.
799-802.\[17\] Bonaventura P., Gallocchio F. and Micca G.(1997) "Improvement of a vocabulary- and speaker-independent speech recogniser for English andSpanish", CSELT Working Papers n. DTR 97.0788.\[18\] Angelini B. et al (1997) "Automatic diphoneextraction for an Italian text-to-speech synthesissystem", Eurospeech '97, V. II, pp.
581-584, Sept.1997.\[19\] Bonaventura P. and Leprieur H. (1994)"Grapheme-to-phoneme transcription rules forsynthesis of regional Italian".
Rivista Italiana diAcustica.
vol.
3.39
