Distributed Modules for Text Annotation and IEapplied to the Biomedical DomainHarald Kirsch and Dietrich Rebholz-SchuhmannEMBL-EBIWellcome Trust Genome CampusHinxton, Cambridge CB10 1SD, UK{kirsch,rebholz}@ebi.ac.ukAbstractBiological databases contain facts from scien-tific literature, which have been curated byhand to ensure high quality.
Curation is time-consuming and can be supported by informa-tion extraction methods.
We present a serverwhich identifies biological facts in scientific textand presents the annotation to the curator.Such facts are: UniProt, UMLS and GO ter-minology, identification of gene and proteinnames, mutations and protein-protein interac-tions.
UniProt, UMLS and GO concepts areautomatically linked to the original source.
Themodule for mutations is based on syntax pat-terns and the one for protein-protein interac-tions on NLP.
All modules work independentlyof each other in single threads and are combinedin a pipeline to ensure proper meta data inte-gration.
For fast response time the modules aredistributed on a Linux cluster.
The server is atpresent available to curation teams of biomedi-cal data and will be opened to the public in thefuture.Contents1 IntroductionBiologists rely on facts from public databaseslike GenBank1, LocusLink2 and UniProt3 andincreasingly integrate facts from scientific liter-ature into OMIM4, FlyBase5, Gene Ontology(GO)6 or COSMIC7.
Curation of such facts istime-consuming and costly.
It can be supportedby text mining methods (Yeh et al, 2003), butinformation extraction is not yet able to fully1www.ncbi.nlm.nih.gov/Genbank2www.ncbi.nlm.nih.gov/LocusLink3www.ebi.ac.uk/uniprot4www.ncbi.nlm.nih.gov/omim5www.flybase.org6www.geneontology.org7www.sanger.ac.uk/perl/CGP/cosmicreplace curators, since these databases target100% precision.Tools to support curation extract facts andcontext.
Results are then presented to cura-tors for evaluation and eventually are added tothe database.
A supervisor may resolve conflicts(Albert et al, 2003).Such information extraction (IE) tools haveto meet a number of demands.
First proteinand gene names (PGNs) have to be identified inthe text.
Although protein and gene names canbe gathered from public resources like HumanGenome Nomenclature (Hugo)8 and UniProt,the sets are not complete and do not coverthe full morphological variability encounteredin the literature.
Promissing automatic extrac-tion methods have been reported (Hanisch etal., 2003), but the BioCreAtIve contest revealedlower performance9, thus leaving the problemunsolved.
Second, relevant facts associated toPGNs have to be extracted like disease, tissuetype, species, indication of function and mu-tations of sequence.
Again controlled vocabu-laries are available, e.g.
UMLS10 and GO, butare also not complete.
In the case of muta-tions, syntax patterns support proper identifica-tion (Rebholz-Schuhmann et al, 2004).
Finally,identification of relationships between PGNs,e.g.
extraction of protein-protein interactions(Temkin and Gilder, 2003), is relevant to de-termine protein function.Current IE tools like PASTA11 are geared to-wards special tasks (Gaizauskas et al, 2003).No IE tool exists that fulfills all above men-tioned demands for the following reasons.
Thecomplexity of data makes it difficult to providefully annotated data sets to train IE techniquesbased on machine learning, since annotation is8www.gene.ucl.ac.uk/hugo9www.pdg.cnb.uam.es/BioLINK/BioCreative.eval.html10www.nlm.nih.gov/research/umls11www.dcs.shef.ac.uk/nlp/pasta50time-consuming and costly.
In addition, grow-ing demands from curation teams and diversityof their needs require a flexible solution, whichcan incrementally be extended by new compo-nents.
To meet this challenge and to providean appropriate service, we developed a modularsoftware environment which tackles basic tasksfor curators.We implemented a server solution which an-notates facts identified in biological text andlinks them to biomedical databases where pos-sible.
The server is typically accessed via webbrowser.
Its modular design allows integra-tion of controlled vocabularies (GO, UniProt,UMLS), of syntax pattern sets, e.g.
for ab-breviation definitions, and of natural languageprocessing like the identification of protein-protein interactions.
The server will be avail-able through EBI?s Web server12 and acceptstext via cut&paste or via a URL.2 Available ModulesThe available modules belong to three cate-gories: (1) basic NLP modules which mainlyidentify syntactical information, (2) moduleswhich match controlled vocabularies, (3) mod-ules which match a set of syntax patterns, and(4) modules for shallow parsing based on cas-caded patterns.
The categories are not inde-pendent, since named entity (NE) recognitionrelies on controlled vocabularies as well as onpatterns for the identification of yet unknownNEs.
Most modules match regular expressions(REs).
These are matched with a finite state au-tomata (FSA) engine we implemented.
It is op-timized for pipelined execution and huge REs.Basic NLP modules comprise the sentenciserand a part-of-speech (PoS) tagger.
The senten-ciser splits text into sentences and wraps theminto a SENT XML element with a unique ID.
ThePoS tagger13 was trained on the British nationalcorpus, but contains lexicon extensions for thebiomedical concepts.
Noun phrases (NPs) areidentified with syntax patterns equivalent toDET (ADJ|ADV) N+.Controlled vocabularies Identification andtagging of terminology is a variant of NE recog-nition.
In biology and medicine a large num-ber of concepts is stored in databases likeUniProt, where roughly 190000 database entrieslink PGNs to protein function, species and tis-sue type.
PGNs from UniProt are transformed12Open to the public after assessment for heavy load13developed at CIS, www.cis.uni-muenchen.deinto REs which account for morphological vari-ability.
For example col1a1 is transformed intothe pattern (COL1A1|[cC]ol1a1) and IL-1 into(IL|[Ii]l)[- ]1.
The PGNs available fromthe database automatically generate a suitablelink from the text to one or more database en-tries.
While adding more dictionaries is techni-cally trivial, it creates the problem of conflictingdefinitions.
Already UniProt introduces the up-percase concept names CAT, NOT and FOR asPGNs.
Disambiguation of such definitions willbe added as soon as available.Syntax patterns A number of IE tasks aresolved with syntax patterns.
The followingmodules are integrated into the server: (1)identification of abbreviations, (2) definitions ofPGNs, and (3) identification of mutations.Abbreviation extraction is described for ex-ample in (Chang et al, 2002).
In our approach avariety of patterns equivalent to NP ?(?
token?)?
is used, where the token has to be the ab-breviation of NP.
If an abbreviation is found inthe text without its expanded form, however,it is necessary to decide whether it is indeed anabbreviation and which expansion applies (workin progress).A separate module identifies sentence pieceswhere the author explicitely stated the factthat the concept denotes a PGN.
Examplesare The AZ2 protein was ...14 and PMP22is the crucial gene ...15.
Such exampleswere translated into the following four patterns:(1) the X protein, (2) the protein X, (3) Tdomain of NP, and (4) NP is a protein.
TheX denotes a single token and T represents a se-lection of concepts which are known to be usedin conjunction with a protein.
The tokens the,is, a and protein again represent sets of equiv-alent tokens.Identification of mutations is integratedas described in (Rebholz-Schuhmann et al,2004).
Integrated patterns identify nomencla-ture equivalent to AA [0-9]+ AA, where AA de-notes all variants of an amino acid or nucleicacid.
Apart from the infix representation of themutation, any postfix and prefix representationis covered as well as other syntactical variation.NLP base IE One component identifies andhighlights protein-protein interactions.
It is es-sential that a phrase describing an interactioncontains a verb or a nominal form describingan interaction like bind or dimerization.
In to-14PMID 1058014815PMID 762808451tal, 21 verbs are considered including 10 verbswhich are specific to molecular biology like far-nesylate.
A protein-protein interaction is iden-tified and tagged, if such a verb phrase connectstwo noun phrases and if at least one of the NPscontains a PGN according to the terminologytagging.3 Pipeline of modules shared indistributed computingObviously the presented modules do not workindependently of each other.
For examplethe protein-protein interaction module usesNP detection (basic NLP module) whichitself relies on PoS tagging.
In addition, NPdetection integrates marked concepts from theterminology tagging module for the identi-fication of protein-protein interactions.
Themodules form a pipeline equivalent to a UNIXpipe like "cat input.txt | inputFilter |sentencise | dictfilter | mutations |tagger | ...> output.xml".
Dependenciesbetween the modules have to be kept in mindto determine their correct order.
While thetext passes through the pipeline, every filterpicks the XML element it is responsible for andcopies everything else unchanged to the output.The input filter wraps arbitrary natural lan-guage text into an XML element describing thesource of the document.
Any further moduleanalyses the text and adds meta data (XMLtags).
The following synthesis phase combinesthe facts available into larger structures, e.g.mutations of a gene or protein-protein interac-tions.Running the pipeline of modules on a sin-gle compute node leads to insufficient responsetime, since the modules tend to have large mem-ory footprints.
In particular the PoS-tagger aswell as terminology taggers load large dictionar-ies into memory and therefore have considerablestartup time, whereas steady state operation isfast.
One solution which solves this problem isto implement each module as a dedicated serverprocess, which is kept in memory for immediateresponse.REs are applied for processing of data andmeta data.
This leads to a special constraintin the handling of XML tags.
It is well knownthat REs cannot match recursive parenthesizedstructures.
As a result, XML elements usedas meta data are not allowed to contain them-selves.
If the XML elements denote parts ofa phrase structure of a natural language sen-M1 comm Mncommdatarequestclient.
.
.controllingserver.
.
.Figure 1: Processing modules Mi are pluggedinto communication components (comm).
Thecontrolling server sends a request to the lastcomponent in the pipe.
Each component con-tacts its predecessor for input and routes itthrought the module.
The first component fi-nally contacts back to the controlling server tofetch the input and send it down the pipe.tence, this may in principle be a restriction, butin practical applications it is not.We implemented a set of Java classes whichallows to set up distributed pipelined process-ing.
It solves the details of client/server com-munication to run IE modules in a pipeline andallows modification to and replacement of mod-ules through the developer (researcher).
As aresult, any class with a method that reads froman input stream and writes results to an outputstream can serve as a module.
In Java terms,the applied interface is a java.lang.Runnablecalling its methods in void run().
A generalpurpose server class is available which, given afactory method to create the Runnable, handlesall the details of setting up and shutting downthe connections.
In particular, connections toestablish a pipeline M1,?
.
.
.
?,Mn, are cre-ated as follows (fig 1):The controlling server C generates thepipeline of modules M1,?
.
.
.
?,Mn (fig.
1).Typically a component in the web server createsa reversed list of the modules and adds itself tothe end of the list: Mn, .
.
.
,M1, C. Then it re-moves Mn from the list, contacts Mn, sends itthe shortened list Mn?1, .
.
.
,M1, C and startsreading input from Mn.
Module Mn followsthe same procedure as the server and starts theRunnable which performs its function receivinginput from the upstream server and writing out-put to the downstream server.
All modules actthe same way and finally M1 contacts the con-trolling server C to obtain the input data.
Ob-viously C needs to write data to M1 and readdata from Mn in parallel.524 ConclusionThe presented server solution has been set upto support curators of biomedical facts in theirwork.
Its modules identify domain knowledgefor molecular biologists and automatically linkinto public data resources.
We are unaware ofany existing solution like ours, which can inte-grate modules for information extraction tasksinto a process pipeline based on XML.
In col-laboration with curation teams for UniProt andCOSMIC, the modules will undergo evaluationfor their usefulness in the curation process.Eventually, information will be automaticallyextracted and inserted into public databases.Every module needs proper evaluation.
Mu-tation extraction already produces reliable data(Rebholz-Schuhmann et al, 2004), but willbe extended (chromosomal aberrations).
Theprotein-protein interaction module relies onchunk parsing and demonstrates how NLP isintegrated as a separate module.
Together withcuration teams single modules will be adaptedto their needs.
In particular the integrationof controlled vocabularies for species and tissuetypes are of strong interest as well as additionalNLP modules, e.g.
for the identification of generegulation.A given combination of modules has to con-sider the dependencies between modules to al-low efficient handling of information extractiontasks.
When a user requests tagging of UniProtprotein and gene names as well as informationextraction for protein/protein interactions, theformer is actually redundant, because it has tobe run anyway for the latter to work.
As aconclusion the curation teams will propose theproper combination of modules that they need.Normalization of identified information is an-other step.
One example is simplication ofacronym definitions, e.g.
transformation of"...androgen receptor (AR) ..." into "<acid=?1?>AR</ac>" with meta data accompany-ing the sentence specifying the expansion "<exid=?1?>androgen receptor</ex>".
The re-sult is normalized text which is easier to parseand thereby leads to better IE results.The server has been tested on Medline ab-stracts and on Pdf documents (full papers fromMedline).
As (Shah et al, 2003) have shown,the sections of full text scientific publicationshave noticably different information content.The modular system described allows us to eas-ily add a module for sectioning of full text pub-lications.ReferencesS.
Albert, S. Gaudan, H. Knigge, A. Raetsch,A.
Delgado, B. Huhse, H. Kirsch, M. Albers,D.
Rebholz-Schuhmann, and M. Koegl.
2003.Computer-assisted generation of a protein-interaction database for nuclear receptors.Molecular Endocrinology, 17(8):1555?1567.J.T.
Chang, H. Schutze, and R.B.
Altman.2002.
Creating an online dictionary of abbre-viations from medline.
Journal of the Amer-ican Medial Association, 9(6):612?620.R.
Gaizauskas, G. Demetriou, P.J.
Artymiuk,and P. Willett.
2003.
Protein structuresand information extraction from biologicaltexts: The pasta system.
Bioinformatics,19(1):135?143.D.
Hanisch, J. Fluck, H.-T. Mevissen, andR.
Zimmer.
2003.
Playing biology?s namegame: identifying protein names in scientifictext.
Pacific Symposium on Biocomputing.D.
Rebholz-Schuhmann, S. Marcel, S. Albert,R.
Tolle, G. Casari, and H. Kirsch.
2004.Automatic extraction of mutations from med-line and cross-validation with omim.
NucleicAcids Research, 32(1):135?142.P.K.
Shah, C. Perez-Iratxeta, and M.A.
An-drade.
2003.
Information extraction from fulltext scientific articles: where are the key-words?
Bioinformatics, 4(20).J.M.
Temkin and M.R.
Gilder.
2003.
Extrac-tion of protein interaction information fromunstructured text using a context-free gram-mar.
Bioinformatics, 19(16):2046?2053.A.S.
Yeh, L. Hirschman, and A.A. Morgan.2003.
Evaluation of text data mining fordatabase curation: lessons learned from thekdd challenge cup.
Bioinformatics, 19:i331?i339.53
