Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 402?411,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsExtracting bilingual terminologies from comparable corporaAhmet Aker, Monica Paramita, Robert GaizauskasUniversity of Sheffieldahmet.aker, m.paramita, r.gaizauskas@sheffield.ac.ukAbstractIn this paper we present a method for extractingbilingual terminologies from comparable corpora.In our approach we treat bilingual term extrac-tion as a classification problem.
For classificationwe use an SVM binary classifier and training datataken from the EUROVOC thesaurus.
We test ourapproach on a held-out test set from EUROVOCand perform precision, recall and f-measure eval-uations for 20 European language pairs.
The per-formance of our classifier reaches the 100% pre-cision level for many language pairs.
We alsoperform manual evaluation on bilingual terms ex-tracted from English-German term-tagged compa-rable corpora.
The results of this manual evalu-ation showed 60-83% of the term pairs generatedare exact translations and over 90% exact or partialtranslations.1 IntroductionBilingual terminologies are important for variousapplications of human language technologies, in-cluding cross-language information search and re-trieval, statistical machine translation (SMT) innarrow domains and computer-aided assistanceto human translators.
Automatic construction ofbilingual terminology mappings has been investi-gated in many earlier studies and various methodshave been applied to this task.
These methods maybe distinguished by whether they work on parallelor comparable corpora, by whether they assumemonolingual term recognition in source and targetlanguages (what Moore (2003) calls symmetricalapproaches) or only in the source (asymmetric ap-proaches), and by the extent to which they rely onlinguistic knowledge as opposed to simply statis-tical techniques.We focus on techniques for bilingual term ex-traction from comparable corpora ?
collections ofsource-target language document pairs that are notdirect translations but are topically related.
Wechoose to focus on comparable corpora becausefor many less widely spoken languages and fortechnical domains where new terminology is con-stantly being introduced, parallel corpora are sim-ply not available.
Techniques that can exploit suchcorpora to deliver bilingual terminologies are ofsignificant practical interest in these cases.The rest of the paper is structured as follows.In Section 2 we outline our method.
In Section3 we review related work on bilingual term ex-traction.
Section 4 describes feature extraction forterm pair classification.
In Section 5 we presentthe data used in our evaluations and discuss ourresults.
Section 6 concludes the paper.2 MethodThe method we present below for bilingual termextraction is a symmetric approach, i.e.
it assumesa method exists for monolingual term extraction inboth source and target languages.
We do not pre-scribe what a term must be.
In particular we do notplace any particular syntactic restrictions on whatconstitutes an allowable term, beyond the require-ment that terms must be contiguous sequences ofwords in both source and target languages.Our method works by first pairing each term ex-tracted from a source language document S witheach term extracted from a target language doc-ument T aligned with S in the comparable cor-pus.
We then treat term alignment as a binaryclassification task, i.e.
we extract features for eachsource-target language potential term pair and de-cide whether to classify the pair as a term equiv-alent or not.
For classification purposes we usean SVM binary classifier.
The training data forthe classifier is derived from EUROVOC (Stein-berger et al, 2002), a term thesaurus coveringthe activities of the EU and the European Parlia-ment.
We have run our approach on the 21 officialEU languages covered by EUROVOC, construct-ing 20 language pairs with English as the source402language.
Considering all these languages allowsus to directly compare our method?s performanceon resource-rich (e.g.
German, French, Spanish)and under-resourced languages (e.g.
Latvian, Bul-garian, Estonian).
We perform two different tests.First, we evaluate the performance of the classifieron a held-out term-pair list from EUROVOC us-ing the standard measures of recall, precision andF-measure.
We run this evaluation on all 20 lan-guage pairs.
Secondly, we test the system?s per-formance on obtaining bilingual terms from com-parable corpora.
This second test simulates thesituation of using the term alignment system in areal world scenario.
For this evaluation we col-lected English-German comparable corpora fromWikipedia, performed monolingual term taggingand ran our tool over the term tagged corpora toextract bilingual terms.3 Related WorkPrevious studies have investigated the extractionof bilingual terms from parallel and comparablecorpora.
For instance, Kupiec (1993) uses statisti-cal techniques and extracts bilingual noun phrasesfrom parallel corpora tagged with terms.
Dailleet al (1994), Fan et al (2009) and Okita etal.
(2010) also apply statistical methods to extractterms/phrases from parallel corpora.
In additionto statistical methods Daille et al use word trans-lation information between two words within theextracted terms as a further indicator of the correctalignment.
More recently, Bouamor et al (2012)use vector space models to align terms.
The en-tries in the vectors are co-occurrence statistics be-tween the terms computed over the entire corpus.Bilingual term alignment methods that work oncomparable corpora use essentially three sorts ofinformation: (1) cognate information, typically es-timated using some sort of transliteration similar-ity measure (2) context congruence, a measure ofthe extent to which the words that the source termco-occurs with have the same sort of distributionand co-occur with words with the same sort dis-tribution as do those words that co-occur with thecandidate term and (3) translation of componentwords in the term and/or in context words, wheresome limited dictionary exists.
For example, inRapp (1995), Fung and McKeown (1997), Morinet.
al.
(2007), Cao and Li (2002) and Ismailand Manandhar (2010) the context of text unitsis used to identify term mappings.
Transliterationand cognate-based information is exploited in Al-Onaizan and Knight (2002), Knight and Graehl(1998), Udupa et.
al.
(2008) and Aswani andGaizauskas (2010).Very few approaches have treated term align-ment as a classification problem suitable for ma-chine learning (ML) techniques.
So far as weare aware, only Cao and Li (2002), who treatonly base noun phrase (NP) mapping, consider theproblem this way.
However, it naturally lends it-self to being viewed as a classification task, as-suming a symmetric approach, since the differ-ent information sources mentioned above can betreated as features and each source-target languagepotential term pairing can be treated as an in-stance to be fed to a binary classifier which decideswhether to align them or not.
Our work differsfrom that of Cao and Li (2002) in several ways.First they consider only terms consisting of noun-noun pairs.
Secondly for a given source languageterm ?N1, N2?, target language candidate termsare proposed by composing all translations (givenby a bilingual dictionary) ofN1 into the target lan-guage with all translations ofN2.
We remove boththese restrictions.
By considering all terms pro-posed by monolingual term extractors we considerterms that are syntactically much richer than noun-noun pairs.
In addition, the term pairs we align arenot constrained by an assumption that their com-ponent words must be translations of each other asfound in a particular dictionary resource.4 Feature extractionTo align or map source and target terms we use anSVM binary classifier (Joachims, 2002) with a lin-ear kernel and the trade-off between training errorand margin parameter c = 10.
Within the classi-fier we use language dependent and independentfeatures described in the following sections.4.1 Dictionary based featuresThe dictionary based features are language depen-dent and are computed using bilingual dictionar-ies which are created with GIZA++ (Och and Ney,2000; Och and Ney, 2003).
The DGT-TM par-allel data (Steinberger et al, 2012) was input toGIZA++ to obtain the dictionaries.
Dictionary en-tries have the form ?s, ti, pi?, where s is a sourceword, ti is the i-th translation of s in the dictio-nary and pi is the probability that s is translatedby ti, the pi?s summing to 1 for each s in the dic-tionary.
From the dictionaries we removed all en-tries with pi < 0.05.
In addition we also removed403every entry from the dictionary where the sourceword was less than four characters and the targetword more than five characters in length and viceversa.
This step is performed to try to eliminatetranslation pairs where a stop word is translatedinto a non-stop word.
After performing these fil-tering steps we use the dictionaries to extract thefollowing language dependent features:?
isFirstWordTranslated is a binary feature in-dicating whether the first word in the sourceterm is a translation of the first word in thetarget term.
To address the issue of com-pounding, e.g.
for languages like Germanwhere what is a multi-word term in En-glish may be expressed as a single com-pound word, we check whether the com-pound source term has an initial prefix thatmatches the translation of the first targetword, provided that translation is at least 5character in length.?
isLastWordTranslated is a binary feature in-dicating whether the last word in the sourceterm is a translation of the last word in thetarget term.
As with the previous feature incase of compound terms we check whetherthe source term ends with the translation ofthe target last word.?
percentageOfTranslatedWords returns thepercentage of words in the source term whichhave their translations in the target term.
Toaddress compound terms we check for eachsource word translation whether it appearsanywhere within the target term.?
percentageOfNotTranslatedWords returnsthe percentage of words of the source termwhich have no translations in the target term.?
longestTranslatedUnitInPercentage returnsthe ratio of the number of words within thelongest contiguous sequence of source wordswhich has a translation in the target term tothe length of the source term, expressed as apercentage.
For compound terms we proceedas with percentageOfTranslatedWords.?
longestNotTranslatedUnitInPercentage re-turns the percentage of the number of wordswithin the longest sequence of source wordswhich have no translations in the target term.These six features are direction-dependent andare computed in both directions, reversing whichlanguage is taken as the source and which asthe target.
We also compute another feature av-eragePercentageOfTranslatedWords which buildsthe average between the feature values of percent-ageOfTranslatedWords from source to target andtarget to source.
Thus in total we have 13 dic-tionary based features.
Note for non-compoundterms if we compare two words for equality we donot perform string match but rather use the Lev-enshtein Distance (see Section 4.2) between thetwo words and treat them as equal if the Leven-shtein Distance returns >= 0.95.
This is per-formed to capture words with morphological dif-ferences.
We set 0.95 experimentally.4.2 Cognate based featuresDictionaries mostly fail to return translation en-tries for named entities (NEs) or specialized termi-nology.
Because of this we also use cognate basedmethods to perform the mapping between sourceand target words or vice versa.
Aker et al (2012)have applied (1) Longest Common SubsequenceRatio, (2) Longest Common Substring Ratio, (3)Dice Similarity, (4) Needleman-Wunsch Distanceand (5) Levenshtein Distance in order to extractparallel phrases from comparable corpora.
Weadopt these measures within our classifier.
Eachof them returns a score between 0 and 1.?
Longest Common Subsequence Ratio(LCSR): The longest common subsequence(LCS) measure measures the longest com-mon non-consecutive sequence of charactersbetween two strings.
For instance, the words?dollars?
and ?dolari?
share a sequence of5 non-consecutive characters in the sameordering.
We make use of dynamic program-ming (Cormen et al, 2001) to implementLCS, so that its computation is efficient andcan be applied to a large number of possibleterm pairs quickly.
We normalize relative tothe length of the longest term:LCSR(X,Y ) = len[LCS(X,Y )]max[len(X), len(Y )]where LCS is the longest common subse-quence between two strings and charactersin this subsequence need not be contiguous.The shorthand len stands for length.?
Longest Common Substring Ratio (LC-STR): The longest common substring(LCST) measure is similar to the LCSmeasure, but measures the longest common404consecutive string of characters that twostrings have in common.
I.e.
given two termswe need to find the longest character n-gramthe terms share.
The formula we use for theLCSTR measure is a ratio as in the previousmeasure:LCSTR(X,Y ) = len[LCST (X,Y )]max[len(X), len(Y )]?
Dice Similarity:dice = 2 ?
LCSTlen(X) + len(Y )?
Needlemann Wunsch Distance (NWD):NWD = LCSTmin[len(X) + len(Y )]?
Levenshtein Distance (LD): This methodcomputes the minimum number of operationsnecessary to transform one string into an-other.
The allowable operations are insertion,deletion, and substitution.
Compared to theprevious methods, which all return scores be-tween 0 and 1, this method returns a score sthat lies between 0 and n. The number n rep-resents the maximum number of operationsto convert an arbitrarily dissimilar string to agiven string.
To have a uniform score acrossall cognate methods we normalize s so thatit lies between 0 and 1, subtracting from 1 toconvert it from a distance measure to a simi-larty measure:LDnormalized = 1?LDmax[len(X), len(Y )]4.3 Cognate based features with termmatchingThe cognate methods assume that the source andtarget language strings being compared are drawnfrom the same character set and fail to capturethe corresponding terms if this is not the case.For instance, the cognate methods are not directlyapplicable to the English-Bulgarian and English-Greek language pairs, as both the Bulgarian andGreek alphabets, which are Cyrillic-based, differfrom the English Latin-based alphabet.
However,the use of distinct alphabets is not the only prob-lem when comparing source and target terms.
Al-though most EU languages use the Latin alpha-bet, the occurrence of special characters and di-acritics, as well spelling and phonetic variations,are further challenges which are faced by term orentity mapping methods, especially in determin-ing the variants of the same mention of the entity(Snae, 2007; Karimi et al, 2011).1 We address thisproblem by mapping a source term to the targetlanguage writing system or vice versa.
For map-ping we use simple character mappings betweenthe writing systems, such as ?
?
a, ?
?
ph,etc., from Greek to English.
The rules allow onecharacter on the lefthand side (source language) tomap onto one or more characters on the righthandside (target language).
We created our rules man-ually based on sound similarity between sourceand target language characters.
We created map-ping rules for 20 EU language pairs using primar-ily Wikipedia as a resource for describing phoneticmappings to English.After mapping a term from source to target lan-guage we apply the cognate metrics described in4.2 to the resulting mapped term and the originalterm in the other language.
Since we perform bothtarget to source and source to target mapping, thenumber of cognate feature scores on the mappedterms is 10 ?
5 due to source to target mappingand 5 due to target to source mapping.4.4 Combined featuresWe also combined dictionary and cognate basedfeatures.
The combined features are as follows:?
isFirstWordCovered is a binary feature indi-cating whether the first word in the sourceterm has a translation (i.e.
has a translationentry in the dictionary regardless of the score)or transliteration (i.e.
if one of the cognatemetric scores is above 0.72) in the target term.The threshold 0.7 for transliteration similar-ity is set experimentally using the trainingdata.
To do this we iteratively ran featureextraction, trained the classifier and recordedprecision on the training data using a thresh-old value chosen from the interval [0, 1] insteps of 0.1.
We selected as final thresholdvalue, the lowest value for which the preci-sion score was the same as when the thresh-old value was set to 1.?
isLastWordCovered is similar to the previ-ous feature one but indicates whether the lastword in the source term has a translation or1Assuming the terms are correctly spelled, otherwise themisspelling is another problem.2Note that we use the cognate scores obtained on the char-acter mapped terms.405transliteration in the target term.
If this is thecase, 1 is returned otherwise 0.?
percentageOfCoverage returns the percent-age of source term words which have a trans-lation or transliteration in the target term.?
percentageOfNonCoverage returns the per-centage of source term words which have nei-ther a translation nor transliteration in the tar-get term.?
difBetweenCoverageAndNonCoveragereturns the difference between the last twofeatures.Like the dictionary based features, these fivefeatures are direction-dependent and are computedin both directions ?
source to target and target tosource, resulting in 10 combined features.In total we have 38 features ?
13 features basedon dictionary translation as described in Section4.1, 5 cognate related features as outlined in Sec-tion 4.2, 10 cognate related features derived fromcharacter mappings over terms as described inSection 4.3 and 10 combined features.5 Experiments5.1 Data SourcesIn our experiments we use two different data re-sources: EUROVOC terms and comparable cor-pora collected from Wikipedia.5.1.1 EUROVOC termsEUROVOC is a term thesaurus covering the ac-tivities of the EU and the European Parliament inparticular.
It contains 6797 term entries in 24 dif-ferent languages including 22 EU languages andCroatian and Serbian (Steinberger et al, 2002).5.1.2 Comparable CorporaWe also built comparable corpora in the infor-mation technology (IT) and automotive domainsby gathering documents from Wikipedia for theEnglish-German language pair.
First, we man-ually chose one seed document in English as astarting point for crawling in each domain3.
Wethen identified all articles to which the seed doc-ument is linked and added them to the crawlingqueue.
This process is performed recursively foreach document in the queue.
Since our aim is tobuild a comparable corpus, we only added English3http://en.wikipedia.org/wiki/Information technology forIT and http://en.wikipedia.org/wiki/Automotive industry forautomotive domain.documents which have an inter-language link inWikipedia to a German document.
We set a max-imum depth of 3 in the recursion to limit size ofthe crawling set, i.e.
documents are crawled onlyif they are within 3 clicks of the seed documents.A score is then calculated to represent the impor-tance of each document di in this domain:scoredi =n?j=1freqdijdepthdjwhere n is the total number of documents in thequeue, freqdij is 1 if di is linked to dj , or 0 other-wise, and depthdj is the number of clicks betweendj and the seed document.
After all documents inthe queue were assigned a score, we gathered thetop 1000 documents and used inter-language linkinformation to extract the corresponding article inthe target language.We pre-processed each Wikipedia article byperforming monolingual term tagging usingTWSC (Pinnis et al, 2012).
TWSC is a term ex-traction tool which identifies terms ranging fromone to four tokens in length.
First, it POS-tagseach document.
For German POS-tagging weuse TreeTagger (Schmid, 1995).
Next, it usesterm grammar rules, in the form of sequences ofPOS tags or non-stop words, to identify candidateterms.
Finally, it filters the candidate terms us-ing various statistical measures, such as pointwisemutual information and TF*IDF.5.2 Performance test of the classifierTo test the classifier?s performance we evaluated itagainst a list of positive and negative examples ofbilingual term pairs using the measures of preci-sion, recall and F -measure.
We used 21 EU offi-cial languages, including English, and paired eachnon-English language with English, leading to 20language pairs.4 In the evaluation we used 600positive term pairs taken randomly from the EU-ROVOC term list.
We also created around 1.3Mnegative term pairs by pairing a source term with200 randomly chosen distinct target terms.
Weselect such a large number to simulate the realapplication scenario where the classifier will beconfronted with a huge number of negative cases4Note that we do not use the Maltese-English languagepair, as for this pair we found that 5861 out of 6797 termpairs were identical, i.e.
the English and the Maltese termswere the same.
Excluding Maltese, the average number ofidentical terms between a non-English language and Englishin the EUROVOC data is 37.7 (out of a possible 6797).406Table 1: Wikipedia term pairs processed and judged as pos-itive by the classifier.Processed PositiveDE IT 11597K 3249DE Automotive 12307K 1772and a relatively small number of positive pairs.The 600 positive examples contain 200 single termpairs (i.e.
single word on both sides), 200 termpairs with a single word on only one side (eithersource or target) and 200 term pairs with morethan one word on each side.
For training we tookthe remaining 6200 positive term pairs from EU-ROVOC and constructed another 6200 term pairsas negative examples, leading to total of 12400term pairs.
To construct the 6200 negative exam-ples we used the 6200 terms on the source sideand paired each source term with an incorrect tar-get term.
Note that we ensure that in both train-ing and testing the set of negative and positiveexamples do not overlap.
Furthermore, we per-formed data selection for each language pair sep-arately.
This means that the same pairs foundin, e.g., English-German are not necessarily thesame as in English-Italian.
The reason for this isthat the translation lengths, in number of words,vary between language pairs.
For instance adulteducation is translated into Erwachsenenbildungin German and contains just a single word (al-though compound).
The same term is translatedinto istruzione degli adulti in Italian and containsthree words.
For this reason we carry out the datapreparation process separately for each languagepair in order to obtain the three term pair sets con-sisting of term pairs with only a single word oneach side, term pairs with a single word on justone side and term pairs with multiple words onboth sides.5.3 Manual evaluationFor this evaluation we used the Wikipedia com-parable corpora collected for the English-German(EN-DE) language pair.
For each pair ofWikipedia articles we used the terms tagged byTWSC and aligned each source term with everytarget term.
This means if both source and targetarticles contain 100 terms then this leads to 10Kterm pairs.
We extracted features for each pairof terms and ran the classifier to decide whetherthe pair is positive or negative.
Table 1 shows thenumber of term pairs processed and the count ofpairs classified as positive.
Table 2 shows fivepositive term pairs extracted from the English-German comparable corpora for each of the IT andautomotive domains.
We manually assessed a sub-set of the positive examples.
We asked human as-sessors to categorize each term pair into one of thefollowing categories:1.
Equivalence: The terms are exact transla-tions/transliterations of each other.2.
Inclusion: Not an exact transla-tion/transliteration, but an exact transla-tion/transliteration of one term is entirelycontained within the term in the other lan-guage, e.g: ?F1 car racing?
vs ?Autorennen(car racing)?.3.
Overlap: Not category 1 or 2, but the termsshare at least one translated/transliteratedword, e.g: ?hybrid electric vehicles?
vs ?hy-bride bauteile (hybrid components)?.4.
Unrelated: No word in either term is a trans-lation/transliteration of a word in the other.In the evaluation we randomly selected 300pairs for each domain and showed them to twoGerman native speakers who were fluent in En-glish.
We asked the assessors to place each of theterm pair into one of the categories 1 to 4.5.4 Results and Discussion5.4.1 Performance test of the classifierThe results of the classifier evaluation are shownin Table 3.
The results show that the overall per-formance of the classifier is very good.
In manycases the precision scores reach 100%.
The low-est precision score is obtained for Lithuanian (LT)with 67%.
For this language we performed an er-ror analysis.
In total there are 221 negative ex-amples classified as positive.
All these terms aremulti-term, i.e.
each term pair contains at leasttwo words on each side.
For the majority of themisclassified terms ?
209 in total ?
50% or moreof the words on one side are either translations orcognates of words on the other side.
Of these, 187contained 50% or more translation due to cognatewords ?
examples of such cases are capital in-crease ?
kapitalo eksportas or Arab organisation?
Arabu lyga with the cognates capital ?
kapitaloand Arab ?
Arabu respectively.
For the remain-der, 50% or more of the words on one side aredictionary translations of words on the other side.In order to understand the reason why the classi-fier treats such cases as positive we examined the407Table 2: Example positive pairs for English-German.IT Automotivechromatographic technique ?
chromatographie methode distribution infrastructure ?
versorgungsinfrastrukturelectrolytic capacitor ?
elektrolytkondensatoren ambient temperature ?
au?enlufttemperaturnatural user interfaces ?
natu?rliche benutzerschnittstellen higher cetane number ?
erho?hter cetanzahlanode voltage ?
anodenspannung fuel tank ?
kraftstoffpumpedigital subscriber loop ?
digitaler teilnehmeranschluss hydrogen powered vehicle ?
wasserstoff fahrzeugTable 3: Classifier performance results on EUROVOC data (P stands for precision, R for recall and F for F -measure).
Eachlanguage is paired with English.
The test set contains 600 positive and 1359400 negative examples.ET HU NL DA SV DE LV FI PT SL FR IT LT SK CS RO PL ES EL BGP 1 1 .98 1 1 .98 1 1 .7 1 1 1 .67 .81 1 1 1 1 1 1R .67 .72 .82 .69 .81 .77 .78 .65 .82 .66 .66 .7 .77 .84 .72 .78 .69 .8 .78 .79F .80 .83 .89 .81 .89 .86 .87 .78 .75 .79 .79 .82 .71 .91 .83 .87 .81 .88 .87 .88training data and found 467 positive pairs whichhad the same characteristics as the negative exam-ples in the testing set classified.
We removed these467 entries from the training set and re-trained theclassifier.
The results with the new classifier are99% precision, 68% recall and 80% F score.In addition to Lithuanian, two further lan-guages, Portuguese (PT) and Slovak (SK), alsohad substantially lower precision scores.
For theselanguages we also removed positive entries fallinginto the same problem categories as the LT onesand trained new classifiers with the filtered train-ing data.
The precision results increased substan-tially for both PT and SK ?
95% precision, 76%recall, 84% F score for PT and 94% precision,72% recall, 81% F score for SK.
The recall scoresare lower than the precision scores, ranging from65% to 84%.
We have investigated the recall prob-lem for FI, which has the lowest recall score at65%.
We observed that all the missing term pairswere not cognates.
Thus, the only way these termscould be recognized as positive is if they are foundin the GIZA++ dictionaries.
However, due to datasparsity in these dictionaries this did not happen inthese cases.
For these term pairs either the sourceor target terms were not found in the dictionar-ies.
For instance, for the term pair offshoring ?uudelleensijoittautuminen the GIZA++ dictionarycontains the entry offshoring but according to thedictionary it is not translated into uudelleensijoit-tautuminen, which is the matching term in EU-ROVOC.5.4.2 Manual evaluationThe results of the manual evaluation are shown inTable 4.
From the results we can see that both as-sessors judge above 80% of the IT domain termsas category 1 ?
the category containing equivalentTable 4: Results of the EN-DE manual evaluation by twoannotators.
Numbers reported per category are percentages.Domain Ann.
1 2 3 4IT P1 81 6 6 7P2 83 7 7 3Automotive P1 66 12 16 6P2 60 15 16 9term pairs.
Only a small proportion of the termpairs are judged as belonging to category 4 (3?7%)?
the category containing unrelated term pairs.
Forthe automotive domain the proportion of equiva-lent term pairs varies between 60 and 66%.
Forunrelated term pairs this is below 10% for both as-sessors.We investigated the inter-annotator agreement.Across the four classes the percentage agreementwas 83% for the automotive domain term pairs and86% for the IT domain term pairs.
The kappastatistic, ?, was .69 for the automotive domainpairs and .52 for the IT domain.
We also consid-ered two class agreement where we treated termpairs within categories 2 and 3 as belonging tocategory 4 (i.e.
as ?incorrect?
translations).
Inthis case, for the automotive domain the percent-age agreement was 90% and ?
= 0.72 and for theIT domain percentage agreement was 89% with?
= 0.55.
The agreement in the automotive do-main is higher than in the IT one although bothjudges were computer scientists.
We analyzedthe differences and found that they differ in caseswhere the German and the English term are both inEnglish.
One of the annotators treated such casesas correct translation, whereas the other did not.We also checked to ensure our technique wasnot simply rediscovering our dictionaries.
Sincethe GIZA++ dictionaries contain only singleword?single word mappings, we examined the408newly aligned term pairs that consisted of oneword on both source and target sides.
Taking boththe IT and automotive domains together, our al-gorithm proposed 5021 term pairs of which 2751(55%) were word-word term pairs.
462 of these(i.e.
17% of the word-word term pairs or 9% ofthe overall set of aligned term pairs) were alreadyin either the EN-DE or DE-EN GIZA++ dictionar-ies.
Thus, of our newly extracted term pairs a rela-tively small proportion are rediscovered dictionaryentries.
We also checked our evaluation data to seewhat proportion of the assessed term pairs werealready to be found in the GIZA++ dictionaries.A total of 600 term pairs were put in front of thejudges of which 198 (33%) were word-word termpairs.
Of these 15 (less than 8% of the word-wordpairs and less then 3% of the overall assessed set ofassessed term pairs) were word-word pairs alreadyin the dictionaries.
We conclude that our evalua-tion results are not unduly affected by assessingterm pairs which were given to the algorithm.Error analysis For both domains we performedan error analysis for the unrelated, i.e.
category4 term pairs.
We found that in both domains themain source of errors is due to terms with differentmeanings but similar spellings such as the follow-ing example (1).
(1) accelerator ?
deceleratorFor this example the cognate methods, e.g.
theLevenshtein similarity measure, returns a score of0.81.
This problem could be addressed in differentways.
First, it could be resolved by applying a veryhigh threshold for the cognate methods.
Any cog-nate score below that threshold could be regardedas zero ?
as we did for the combined features (cf.Section 4.4).
However, setting a similarity thresh-old higher than 0.9 ?
to filter out cases as in (1)?
will cause real cognates with greater variationin the spellings to be missed.
This will, in par-ticular, affect languages with a lot of inflection,such as Latvian.
Another approach to address thisproblem would be to take the contextual or dis-tributional properties of the terms into considera-tion.
To achieve this, training data consisting ofterm pairs along with contextual information is re-quired.
However, such training data does not cur-rently exist (i.e.
resources like EUROVOC do notcontain contextual information) and it would needto be collected as a first step towards applying thisapproach to the problem.Partial Translation The assessors assigned 6 ?7% of the term pairs in the IT domain and 12 ?16% in the automotive domain to categories 2 and3.
In both categories the term pairs share transla-tions or cognates.Clearly, if humans such as professional transla-tors are the end users of these terms, then it couldbe helpful for them to find some translation unitswithin the terms.
In category 2 this will be the en-tire translation of one term in the other such as thefollowing examples.5(2) visible graphical interface ?
grafische be-nutzerschnittstelle(3) modern turbocharger systems ?
moderneturboladerIn example (3) the a translation of the Germanterm is to be found entirely within in the Englishterm but the English term has the additional wordvisible, a translation of which is not found in theGerman term.
In example (4), again the transla-tion of the German term is entirely found in theEnglish term, but as in the previous example, oneof the English words ?
systems ?
in this case, hasno match within the German term.
In category 3there are only single word translation overlaps be-tween the terms as shown in the following exam-ples.
(4) national standard language ?niederla?ndischen standardsprache(5) thermoplastic material ?
thermoplastischeelastomereIn example (5) standard language is translatedto standardsprache and in example (6) thermo-plastic to thermoplastische.
The other wordswithin the terms are not translations of each other.Another application of the extracted term pairsis to use them to enhance existing parallel corporato train SMT systems.
In this case, including thepartially correct terms may introduce noise.
Thisis especially the case for the terms within category3.
However, the usefulness of terms in both thesescenarios requires further investigation, which weaim to do in future work.5In our data it is always the case that the target term isentirely translated within the English one and the other wayround.4096 ConclusionIn this paper we presented an approach to alignterms identified by a monolingual term extractor inbilingual comparable corpora using a binary clas-sifier.
We trained the classifier using data fromthe EUROVOC thesaurus.
Each candidate termpair was pre-processed to extract various featureswhich are cognate-based or dictionary-based.
Wemeasured the performance of our classifier usingInformation Retrieval (IR) metrics and a manualevaluation.
In the IR evaluation we tested the per-formance of the classifier on a held out test settaken from EUROVOC.
We used 20 EU languagepairs with English being always the source lan-guage.
The performance of our classifier in thisevaluation reached the 100% precision level formany language pairs.
In the manual evaluationwe had our algorithm extract pairs of terms fromWikipedia articles ?
articles forming comparablecorpora in the IT and automotive domains ?
andasked native speakers to categorize a selection ofthe term pairs into categories reflecting the levelof translation of the terms.
In the manual evalu-ation we used the English-German language pairand showed that over 80% of the extracted termpairs were exact translations in the IT domain andover 60% in the automotive domain.
For both do-mains over 90% of the extracted term pairs wereeither exact or partial translations.We also performed an error analysis and high-lighted problem cases, which we plan to addressin future work.
Exploring ways to add contextualor distributional features to our term representa-tions is also an avenue for future work, though itclearly significantly complicates the approach, oneof whose advantages is its simplicitiy.
Further-more, we aim to extend the existing dictionariesand possibly our training data with terms extractedfrom comparable corpora.
Finally, we plan to in-vestigate the usefulness of the terms in differentapplication scenarios, including computer assistedtranslation and machine translation.AcknowledgementsThe research reported was funded by the TaaSproject, European Union Seventh Framework Pro-gramme, grant agreement no.
296312.
The au-thors would like to thank the manual annotatorsfor their helpful contributions.
We would also liketo thank partners at Tilde SIA and at the Universityof Zagreb for supplying the TWSC term extractiontool, developed within the EU funded project AC-CURAT.ReferencesA.
Aker, Y. Feng, and R. Gaizauskas.
2012.
Auto-matic bilingual phrase extraction from comparablecorpora.
In 24th International Conference on Com-putational Linguistics (COLING 2012), IIT Bom-bay, Mumbai, India, 2012.
Association for Compu-tational Linguistics.Y.
Al-Onaizan and K. Knight.
2002.
Machine translit-eration of names in arabic text.
In Proceedings ofthe ACL-02 workshop on Computational approachesto semitic languages, pages 1?13.
Association forComputational Linguistics.N.
Aswani and R. Gaizauskas.
2010.
English-hinditransliteration using multiple similarity metrics.
InProceedings of the Seventh International Confer-ence on Language Resources and Evaluation (LREC2010), Valetta, Malta.D.
Bouamor, N. Semmar, and P. Zweigenbaum.
2012.Identifying bilingual multi-word expressions for sta-tistical machine translation.
In LREC 2012, EigthInternational Conference on Language Resourcesand Evaluation, pages 674-679, Istanbul, Turkey,2012.
ELRA.Y.
Cao and H. Li.
2002.
Base noun phrase translationusing web data and the em algorithm.
In Proceed-ings of the 19th international conference on Com-putational linguistics-Volume 1, pages 1?7.
Associ-ation for Computational Linguistics.T.
H. Cormen, C. E. Leiserson, R. L. Rivest, andC.
Stein.
2001.
Introduction to Algorithms.
TheMIT Press, 2nd revised edition, September.B.
Daille, E?.
Gaussier, and J.M.
Lange?.
1994.
Towardsautomatic extraction of monolingual and bilingualterminology.
In Proceedings of the 15th conferenceon Computational linguistics-Volume 1, pages 515?521.
Association for Computational Linguistics.X.
Fan, N. Shimizu, and H. Nakagawa.
2009.
Auto-matic extraction of bilingual terms from a chinese-japanese parallel corpus.
In Proceedings of the3rd International Universal Communication Sympo-sium, pages 41?45.
ACM.P.
Fung and K. McKeown.
1997.
Finding terminol-ogy translations from non-parallel corpora.
In Pro-ceedings of the 5th Annual Workshop on Very LargeCorpora, pages 192?202.A.
Ismail and S. Manandhar.
2010.
Bilingual lexi-con extraction from comparable corpora using in-domain terms.
In Proceedings of the 23rd Inter-national Conference on Computational Linguistics:Posters, pages 481?489.
Association for Computa-tional Linguistics.410T.
Joachims.
2002.
Learning to classify text using sup-port vector machines: Methods, theory and algo-rithms, volume 186.
Kluwer Academic PublishersNorwell, MA, USA:.S.
Karimi, F. Scholer, and A. Turpin.
2011.
Ma-chine transliteration survey.
ACM Computing Sur-veys (CSUR), 43(3):17.K.
Knight and J. Graehl.
1998.
Machine translitera-tion.
Computational Linguistics, 24(4):599?612.J.
Kupiec.
1993.
An algorithm for finding noun phrasecorrespondences in bilingual corpora.
In Proceed-ings of the 31st annual meeting on Association forComputational Linguistics, pages 17?22.
Associa-tion for Computational Linguistics.R.
Moore.
2003.
Learning translations of named-entity phrases from parallel corpora.
In In Proceed-ings of the tenth conference on European chapterof the Association for Computational Linguistics-Volume 1, pages 259266.
Association for Compu-tational Linguistics.E.
Morin, B. Daille, K. Takeuchi, and K. Kageura.2007.
Bilingual terminology mining - using brain,not brawn comparable corpora.
In Proceedingsof the 45th Annual Meeting of the Association ofComputational Linguistics, pages 664?671, Prague,Czech Republic, June.
Association for Computa-tional Linguistics.F.
J. Och and H. Ney.
2000.
A comparison of align-ment models for statistical machine translation.
InProceedings of the 18th conference on Computa-tional linguistics, pages 1086?1090, Morristown,NJ, USA.
Association for Computational Linguis-tics.F.
J. Och Och and H. Ney.
2003.
A systematic compar-ison of various statistical alignment models.
Com-putational Linguistics, 29(1):19?51.T.
Okita, A. Maldonado Guerra, Y. Graham, andA.
Way.
2010.
Multi-word expression-sensitiveword alignment.
Association for ComputationalLinguistics.Ma?rcis Pinnis, Nikola Ljubes?ic?, Dan S?tefa?nescu, In-guna Skadin?a, Marko Tadic?, and Tatiana Gornostay.2012.
Term extraction, tagging, and mapping toolsfor under-resourced languages.
In Proc.
of the 10thConference on Terminology and Knowledge Engi-neering (TKE 2012), June, pages 20?21.R.
Rapp.
1995.
Identifying word translations in non-parallel texts.
In Proceedings of the 33rd annualmeeting on Association for Computational Linguis-tics, pages 320?322.
Association for ComputationalLinguistics.Helmut Schmid.
1995.
Treetagger?
a lan-guage independent part-of-speech tagger.
Insti-tut fu?r Maschinelle Sprachverarbeitung, Universita?tStuttgart, page 43.C.
Snae.
2007.
A comparison and analysis ofname matching algorithms.
International Journalof Applied Science.
Engineering and Technology,4(1):252?257.R.
Steinberger, B. Pouliquen, and J. Hagman.
2002.Cross-lingual document similarity calculation usingthe multilingual thesaurus eurovoc.
ComputationalLinguistics and Intelligent Text Processing, pages101?121.R.
Steinberger, A. Eisele, S. Klocek, S. Pilos, andP.
Schlter.
2012.
Dgt-tm: A freely available trans-lation memory in 22 languages.
In Proceedings ofLREC, pages 454?459.R.
Udupa, K. Saravanan, A. Kumaran, and J. Jagarla-mudi.
2008.
Mining named entity transliterationequivalents from comparable corpora.
In Proceed-ing of the 17th ACM conference on Information andknowledge management, pages 1423?1424.
ACM.411
