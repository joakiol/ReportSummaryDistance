Proceedings of NAACL HLT 2007, Companion Volume, pages 9?12,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsConquest ?
an Open-Source Dialog System for ConferencesDan Bohus, Sergio Grau Puerto, David Huggins-Daines, Venkatesh Keri,Gopala Krishna,  Rohit Kumar, Antoine Raux, Stefanie TomkoSchool of Computer ScienceCarnegie Mellon University{ dbohus, sgrau, dhuggins, vkeri, gopalakr, rohitk, antoine, stef }@ cs.cmu.eduAbstractWe describe ConQuest, an open-source,reusable spoken dialog system that pro-vides technical program information dur-ing conferences.
The system uses atransparent, modular and open infrastruc-ture, and aims to enable applied researchin spoken language interfaces.
The con-ference domain is a good platform for ap-plied research since it permits periodicalredeployments and evaluations with a realuser-base.
In this paper, we describe thesystem?s functionality, overall architec-ture, and we discuss two initial deploy-ments.1 IntroductionConducting applied spoken language interface re-search is generally a costly endeavor.
Developing,deploying and maintaining real-world spoken lan-guage interfaces requires an existing infrastructure,a significant amount of engineering effort, and cangreatly benefit from the availability of certain re-sources such as transcribed in-domain data.In an effort to enable applied research and tolower this high cost of entry, we have developedConQuest (Conference Questions) an open-sourcespoken dialog system that provides access toschedule and technical program information duringconferences.
We believe the conference domainhas a number of good properties for applied re-search: it includes a number of tasks of differentcomplexities, it provides regular access to a real-world user population; it permits periodical rede-ployments and evaluations and therefore can pro-vide a natural common evaluation task for thespoken language interfaces community.The ConQuest system is constructed on top ofthe open, transparent and modular Olympus dialogsystem framework (2007), and can be easily reusedacross different conferences.
To date, the systemhas been deployed in two conferences: InterSpeech2006 and IJCAI 2007.
Together with corpora col-lected from these deployments, the system is freelyavailable for download (Conquest, 2007).We begin by describing the ConQuest function-ality in the next section.
Then, in section 3 we pro-vide an overview of the system architecture anddiscuss the development process.
In section 4 webriefly discuss the two deployment efforts.
Finally,in section 5 we discuss related work and draw anumber of conclusions.2 FunctionalityAs Figure 1 illustrates, ConQuest is a mixed-initiative spoken dialog system that provides ac-cess to schedule and technical program informationduring conferences.Users can browse the schedule and find detailsabout various papers or sessions of interest by pro-viding identifying information, such as topics, ses-sion names, special events, paper titles, authornames, specific dates and times, specific locations,or a combination thereof (e.g.
turns 2, 4, 14).
Addi-tionally, the system also allows uses to listen tocurrent announcements and to cast their votes for aBest Paper Award (e.g.
turns 10-17).The interaction is mixed-initiative; at any point,the user may switch the current focus of the con-versation (e.g.
turn 8).
ConQuest employs an adap-tive information presentation strategy that allows9users to easily navigate the schedule (see turns 3, 5and 15).
The system uses a rich repertoire of errorrecovery strategies to handle potential errors, in-cluding several fall-back strategies (e.g.
turn 13).3 System ArchitectureThe ConQuest system was built using RavenClaw/Olympus (2007), an open-source framework thatfacilitates research and development in task ori-ented conversational spoken language interfaces.Olympus consists of a collection of componentsfor recognition, language understanding, dialogmanagement, language generation, speech synthe-sis, etc., and the corresponding communicationinfrastructure.
To date, Olympus has been used todevelop and deploy a number of other systemsspanning different domains and interaction types(Bohus and Rudnicky, 2003).A key characteristic of the Olympus frameworkis a clear separation between the domain independ-ent programs (or components) and domain specificresources.
This decoupling promotes reusabilityand significantly lessens the system developmenteffort.
In ConQuest, the authoring effort was fo-cused on developing resources such as the lexicon,language model, grammar, dialog task specifica-tion, etc.
Some interesting, unanticipated engineer-ing challenges we faced during development weredealing with foreign names and accented charac-ters and performing text normalization on variousfields (e.g.
Alex Smith and Alexander Smith arethe same author), while at the same time ensuringconsistency between these various resources.
Be-low, we briefly comment of each component andthe corresponding resources.
Figure 2 provides atop-level architectural view.Speech Recognition.
ConQuest uses a recogni-tion server coupled to a set of parallel recognitionengines: two SPHINX-II decoders (Huang et al,1992) that use gender-specific acoustic models,and a DTMF (touch-tone decoder).
Each recogni-tion engine uses class-based (e.g.
paper titles, au-thor names, etc.
), state-specific trigram-languagemodels.
We started with an initial language modelbuilt using data collected with an early text-onlyprototype.
We then internally deployed a speechbased system, collected more data, transcribed it,and used it to retrain the language models.
TheFigure 1.
A sample interaction with ConQuest1 S: Welcome to ConQuest [?]
I can give you information about papers, sessions, special events and announcements at Inter-Speech 2006.
You can also cast a vote for the best paper award.
How can I help you?2 U: are there any papers on spoken dialog systems today3 S:  There are 23 papers on spoken dialog systems today.
These papers are being presented in 3 sessions: Dialog and Discourse,Language Modeling for Spoken Dialog Systems and Spoken Dialog Systems I.
To browse this list of papers, please tell me theauthor name, the paper title, the time or the venue you?re looking for.
If you?re not interested in any of these papers say ?quit?.4 U: which ones are in the afternoon5 S:  There will be 11 papers on spoken dialog systems this afternoon.
Would you like to hear information about all these papers?6 U: yes7 S:  The list of papers on spoken dialog systems this afternoon is: Paper 1 - ?Dynamic Extension of a Grammar-based DialogueSystem: Constructing an All-Recipes Knowing Robot?, Paper 2 ?
[?]
Would you like more information about any of these?8 U: tell me more about the third one9 S:  Paper 3 is titled ?System- versus user-initiative dialog strategy for driver information systems?, and was presented yesterday at 2pm in the poster session in Allegheny Ballroom Foyer.
This paper was written by Chantal Ackermann, and Marion Libossek.Would you like more information about any of these?8 U: no when is the banquet9 S:  The Banquet will be held Wednesday from 7pm to 9:30 pm in the Heintz History Center.
The Heinz History Center is located onSmallman street between 12th and 13th streets.
The History Center is a museum that relates and interprets 250 years of historyin the Western Pennsylvania area.
Is there anything else I can do for you?10 U: yes I?d like to cast a vote11 S:  Please tell me the title of the paper you?d like to vote for..12 U: I don?t really know the title but I think it had Diane as one of the main authors ?
[non-understanding]13 S:  Sorry, I didn?t catch that.
Please dial the first six letters from the title of the paper you would like to vote for.14 U: I don?t know it it?s a paper by Diane Litman15 S:  There are 3 papers by Diane Litman.
Paper 1 ?
?Discourse Structure and Speech Recognition Problems?, Paper 2 ?
[?
], Paper3 ?
[?]
Would you like to vote for any of these?16 U: Discourse Structure and Speech Recognition Problems17 S:  Okay, I?ve recorded your vote for the paper entitled ?Discourse Structure and Speech Recognition Problems?
What else can I dofor you?18 U: [?
]10final language models used during the InterSpeechdeployment were trained from on a corpus of 6350utterances.
The system operated with a lexicon of4795 words, which included 659 lexicalized (con-catenated) paper titles, and 1492 lexicalized authornames, and 78 lexicalized session names.
The pro-nunciations were generated using CMU Dictionaryand later manually corrected.Language understanding.
The system uses thePhoenix (Ward and Issar, 1994) robust parser toextract concepts from the recognition results.
Adomain-specific shallow semantic grammar wasdeveloped and concatenated with a domain-independent grammar for generic expressions like[Yes], [No], [Date], [Time], etc.Dialog management.
ConQuest uses a Raven-Claw-based dialog manager (Bohus and Rudnicky,2003).
We developed a dialog task specificationfor the conference schedule domain, expressed as ahierarchical plan for the interaction, which theRavenClaw engine uses to drive the dialog.
In theprocess, the RavenClaw engine automatically pro-vides additional generic conversational skills suchas error recovery strategies and support for variousuniversal dialog mechanisms (e.g.
repeat, start-over, what-can-I-say, etc.)Backend/Database.
A backend agent looks upschedule information from the database (stored asa flat text file).
The backend agent also performsdomain specific pre-lookup normalization (e.g.mapping author names to their canonical forms),and post-lookup processing of the returned records(e.g.
clustering papers by sessions).
The databasefile serves as starting point for constructing anumber of other system resources (e.g.
languagemodel classes, lexicon, etc.
)Figure 2.
The Olympus dialog system reference architecture (a typical system)Temporal reference resolution agent.
Apartfrom the database agent, the dialog manager alsocommunicates with an agent that resolves temporalexpressions (e.g.
tomorrow at four p.m.) into ca-nonical forms.Language generation.
ConQuest uses Rosetta,a template-based language generation component.The authoring effort at this level consisted of writ-ing various templates for the different system ques-tions and information presentation prompts.Speech synthesis.
ConQuest uses the Cepstral(2005) speech synthesis engine, configured with anopen-domain unit selection voice.
We manuallychecked and corrected pronunciations for authornames, various technical terms and abbreviations.4 Development and DeploymentThe first development of ConQuest system wasdone for the Interspeech 2006 conference held inPittsburgh, PA.
The iterative development processinvolved regular interaction with potential usersi.e.
researchers who regularly attend conferences.Seven developers working half time participated inthis development for about three months.
An esti-mated one man-year of effort was spent.
This esti-mate does not include the effort involved intranscribing the data collected after the conference.Two systems were deployed at the Interspeech2006 conference: a desktop system using a close-talking microphone placed by the registration desk,and a telephone-based system.
Throughout theconference we collected a corpus of 174 sessions.We have orthographically transcribed the user ut-11terances and are currently analyzing the data; weplan to soon release it to the community, togetherwith detailed statistics, the full system logs as wellas the full system source code (Conquest, 2007).Following Interspeech 2006, ConQuest was re-deployed at IJCAI 2007 conference held in Hy-derabad, India.
The second deployment took anestimated two man-months: three developers work-ing half-time for over a month.
The significantparts of the second deployment involved incorpo-rating scheduling data for the IJCAI 2007 and im-plementing two new requirements i.e.
support forworkshops and Indian English speech recognition.The IJCAI development had fewer iterations thanthe first effort.
The two desktop systems set up atthe conference venue collected 129 sessions ofdata.
This data is currently being transcribed andwill soon be released to the community through theConquest website (Conquest, 2007).Through these two deployments of ConQuestthe system specifications have been refined and weexpect the development time to asymptote to lessthan a month after a few more deployments.5 Discussion and ConclusionOur primary goal in developing ConQuest was toenable research by constructing and releasing anopen-source, full-fledged dialog system, as well asan initial corpus collected with this system.
Thesystem is built on top of an open, transparent andmodular infrastructure that facilitates research inspoken language interfaces (Olympus, 2007).There have been a number of other efforts tocollect and publish dialog corpora, for instancewithin the DARPA Communicator project.
A morerecent project, that operates in a domain similar toConQuest is DiSCoH, a Dialog System for Confer-ence Help developed by researchers at AT&T,ICSI and Edinburgh University, and deployed dur-ing the SLT-2006 workshop (Adreani et al, 2006).While their goals are similar, i.e.
to enable re-search, DiSCoH and ConQuest differ in a numberof dimensions.
Functionality-wise, DiSCoH offersgeneral conference information about the venue,accommodation options and costs, paper submis-sion, etc., while ConQuest provides access to thetechnical schedule and allows participants to votefor a best paper award.
DiSCoH is built usingAT&T technology and a call-routing approach;ConQuest relies on a plan-based dialog manage-ment framework (RavenClaw) and an open-sourceinfrastructure (Olympus).
Finally, the DiSCoH ef-fort aims to develop a richly annotated dialog cor-pus to be used for research; ConQuest?s aim is toprovide both the full system and an initial tran-scribed and annotated corpus to the community.The conference domain is interesting in that itallows for frequent redeployment and in theoryprovides regular access to a certain user-base.
Itshould therefore facilitate research and periodicalevaluations.
Unfortunately, the dialog corpora col-lected so far using DiSCoH and ConQuest havebeen somewhat smaller than our initial expecta-tions.
We believe this is largely due to the fact thatthe systems provide information that is alreadyaccessible to users by other means (paper confer-ence program, web-sites, etc.).
Perhaps combiningthe functionalities of these two systems, and ex-panding into directions where the system providesotherwise hard-to-access information (e.g.
localrestaurants, transportation, etc.)
would lead to in-creased traffic.ReferencesAdreani, G., Di Fabbrizio, G., Gilbert, M., Gillick, D.,Hakkani-Tur, D., and Lemon, O., 2006 Let?s DiS-CoH: Collecting an Annotated Open Corpus withDialogue Acts and Reward Signals for Natural Lan-guage Helpdesk, in Proceedings of IEEE SLT-2006Workshop, Aruba Beach, Aruba.Bohus, D., and Rudnicky, A., 2003.
RavenClaw: DialogManagement Using Hierarchical Task Decomposi-tion and an Expectation Agenda, in Proceedings ofEurospeech 2003, Geneva, Switzerland.Cepstral, LLC, 2005, SwiftTM: Small Footprint Text-to-Speech Synthesizer, http://www.cepstral.com.Conquest, 2007, http://www.conquest-dialog.org.Huang, X., Alleva, F., Hon, H.-W., Hwang, M.-Y., Lee,K.-F. and Rosenfeld, R., 1992.
The SPHINX-IISpeech Recognition System: an overview, in Com-puter Speech and Language, 7(2), pp 137-148, 1992.Olympus/RavenClaw web page, as of January 2007:http://www.ravenclaw-olympus.org/.Ward, W., and Issar, S., 1994.
Recent improvements inthe CMU spoken language understanding system, inProceedings of the ARPA Human Language Tech-nology Workshop, pages 213?216, Plainsboro, NJ.12
