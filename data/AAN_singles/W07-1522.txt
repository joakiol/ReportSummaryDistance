Proceedings of the Linguistic Annotation Workshop, pages 132?139,Prague, June 2007. c?2007 Association for Computational LinguisticsAnnotating a Japanese Text Corpus withPredicate-Argument and Coreference RelationsRyu Iida, Mamoru Komachi, Kentaro Inui and Yuji MatsumotoGraduate School of Information Science,Nara Institute of Science and Technology8916-5 Takayama, Ikoma, Nara, 630-0192, Japan{ryu-i,mamoru-k,inui,matsu}@is.naist.jpAbstractIn this paper, we discuss how to anno-tate coreference and predicate-argument re-lations in Japanese written text.
Therehave been research activities for buildingJapanese text corpora annotated with coref-erence and predicate-argument relations asare done in the Kyoto Text Corpus version4.0 (Kawahara et al, 2002) and the GDA-Tagged Corpus (Hasida, 2005).
However,there is still much room for refining theirspecifications.
For this reason, we discussissues in annotating these two types of re-lations, and propose a new specification foreach.
In accordance with the specification,we built a large-scaled annotated corpus, andexamined its reliability.
As a result of ourcurrent work, we have released an anno-tated corpus named the NAIST Text Corpus1,which is used as the evaluation data set inthe coreference and zero-anaphora resolu-tion tasks in Iida et al (2005) and Iida et al(2006).1 IntroductionCoreference resolution and predicate-argumentstructure analysis has recently been a growing fieldof research due to the demands from NLP appli-cation such as information extraction and machinetranslation.
With the research focus placed on thesetasks, the specification of annotating corpora and the1The NAIST Text Corpus is downloadable fromhttp://cl.naist.jp/nldata/corpus/, and it has already beendownloaded by 102 unique users.data sets used in supervised techniques (Soon et al,2001; Ng and Cardie, 2002, etc.)
have also grown insophistication.For English, several annotation schemes have al-ready been proposed for both coreference relationand argument structure, and annotated corpora havebeen developed accordingly (Hirschman, 1997; Poe-sio et al, 2004; Doddington et al, 2004).
For in-stance, in the Coreference task on Message Under-standing Conference (MUC) and the Entity Detec-tion and Tracking (EDT) task in the Automatic Con-tent Extraction (ACE) program, which is the suc-cessor of MUC, the details of specification of anno-tating coreference relation have been discussed forseveral years.
On the other hand, the specificationof predicate-argument structure analysis has mainlybeen discussed in the context of the CoNLL sharedtask2 on the basis of the PropBank (Palmer et al,2005).In parallel with these efforts, there have also beenresearch activities for building Japanese text corporaannotated with coreference and predicate-argumentrelations such as the Kyoto Text Corpus version 4.0(Kawahara et al, 2002) and the GDA3-Tagged Cor-pus (Hasida, 2005).
However, as we discuss in thispaper, there is still much room for arguing and re-fining the specification of such sorts of semantic an-notation.
In fact, for neither of the above two cor-pora, the adequacy and reliability of the annotationscheme has been deeply examined.In this paper, we discuss how to annotate coref-erence and predicate-argument relations in Japanese2http://www.lsi.upc.edu/?srlconll/3The Global Document Annotation132text.
In Section 2 to Section 4, we examine the an-notation issues of coreference, predicate-argumentrelations, and event-nouns and their argument rela-tions respectively, and define adequate specificationof each annotation task.
Then, we report the resultsof actual annotation taking the Kyoto Corpus 3.0 as astarting point.
Section 6 discusses the open issues ofeach annotation task and we conclude in Section 7.2 Annotating coreference relations2.1 Approaches to coreference annotationCoreference annotation in English has been evolvingmainly in the context of information extraction.
Forinstance, in the 6th and 7th Message Understand-ing Conferences (MUC), coreference resolution istreated as a subtask of information extraction4.
Theannotated corpora built in the MUC contain coref-erence relations between NPs, which are used as agold standard data set for machine learning-basedapproaches to coreference resolution by researcherssuch as Soon et al (2001) and Ng and Cardie (2002).However, van Deemter and Kibble (1999) claimthat the specification of the MUC coreference taskguides us to annotate expressions that are not nor-mally considered coreferential, such as appositiverelations (e.g.
Julius Caesari, a well-known em-perori, ...).In the task of Entity Detection and Tracking(EDT) in the Automatic Content Extraction (ACE)program (Doddington et al, 2004), the successorof MUC, the coreference relations are redefined interms of two concepts, mentions and entities, in or-der to avoid inappropriate co-indexing.
In the speci-fication of EDT, mentions are defined as the expres-sions appearing in the texts, and entities mean thecollective set of specific entities referred to by thementions in the texts.
Entities are limited to namedentities such as PERSON and ORGANIZATION foradequacy and reliability of annotation.
Therefore,the ACE data set has the drawback that not all coref-erence relations in the text are exhaustively anno-tated.
It is insufficient to resolve only the annotatedcoreference relations in order to properly analyze atext.4http://www-nlpir.nist.gov/related projects/muc/proceedings/co task.html2.2 Coreference annotated corpora of JapaneseIn parallel with these efforts, Japanese corpora havebeen developed that are annotated with coreferencerelations, such as the Kyoto Text Corpus version4.0 (Kawahara et al, 2002) and GDA-Tagged Cor-pus (Hasida, 2005).
Before reviewing these works,we explain the relationship between anaphora andcoreference in Japanese, referring to the followingexamples.
In example (1), the pronoun sorei (it)points back to iPodi, and these two mentions referto the same entity in the world and thus are consid-ered both anaphoric and coreferential.
(1) Tom-wa iPodi-o ka-tta .Tom-TOP iPodi-ACC buy-PAST PUNCTom bought an iPod.kare-wa sorei-de ongaku-o ki-ita .he-TOP iti-INS music-ACC listen to-PAST PUNCHe listened to music on it.On the other hand, in example (2), we still see ananaphoric relation between iPodi (iPodi) and sorej(itj) and sorej points back to iPodi.
However, thesetwo mentions are not coreferential since they referto different entities in the world.
(2) Tom-wa iPodi-o ka-tta .Tom-TOP iPodi-ACC buy-PAST PUNCTom bought an iPod.Mary-mo sorej-o ka-tta .Mary-TOP onej -ACC buy-PAST PUNCMary also bought one.As in the above examples, an anaphoric relationcan be either coreferential or not.
The former case iscalled an identity-of-reference anaphora (IRA) andthe latter an identity-of-sense anaphora (ISA) (seeMitkov (2002)).
In English the difference betweenIRA and ISA is clearly expressed by the anaphoricrelations formed with ?it?
and ?one?
respectively.This makes it possible to treat these classes sepa-rately.
However, in Japanese, no such clear lexicaldistinction can be drawn.
In both the Kyoto Cor-pus and GDA-Tagged Corpus, there is no discussionin regards to distinction between ISA and IRA, thusit is unclear what types of coreference relations theannotators annotated.
To make matters worse, theirapproaches do not consider whether or not a mentionrefers to a specific entity like in the EDT task.2.3 Annotating IRA relations in JapaneseAs described in the previous section, conventionalspecifications in Japanese are not based on a pre-133cise definition of coreference relations, resulting ininappropriate annotation.
On the other hand, in ourspecification, we consider two or more mentions ascoreferential in case they satisfy the following twoconditions:?
The mentions refer to not a generic entity butto a specific entity.?
The relation between the mentions is consid-ered as an IRA relation.3 Annotating predicate-argument relations3.1 Labels of predicate-argument relationsOne debatable issue in the annotation of predicate-argument relations is what level of abstraction weshould label those relations at.The GDA-Tagged Corpus, for example, adopts afixed set of somewhat ?traditional?
semantic rolessuch as Agent, Theme, and Goal that are definedacross verbs.
The PropBank (Palmer et al, 2005),on the other hand, defines a set of semantic roles (la-beled ARG0, ARG1, and AM-ADV, etc.)
for eachverb and annotates each sentence in the corpus withthose labels as in (3).
(3) [ARGM?TMP A year earlier], [ARG0 the refiner] [relearned] [ARG1 $66 million, or $1.19 a share].In the FrameNet (Fillmore and Baker, 2000), a spe-cific set of semantic roles is defined for each set ofsemantically-related verbs called a FrameNet frame.However, there is still only limited consensus onhow many kinds of semantic roles should be iden-tified and which linguistic theory we should adoptto define them at least for the Japanese language.An alternative way of labeling predicate-argument relations is to use syntactic cases aslabels.
In Japanese, arguments of a verb are markedby a postposition, which functions as a case marker.In sentence (4), for example, the verb tabe hastwo arguments, each of which is marked by apostposition, ga or o.
(4) Tom-ga ringo-o tabe-ruTom-NOM apple-ACC eat-PRES(Tom eats an apple.
)Labeling predicate-argument relations in terms ofsyntactic cases has a few more advantages over se-mantic roles as far as Japanese is concerned:?
Manual annotation of syntactic cases is likelyto be more cost-efficient than semantic rolesbecause they are often explicitly marked bycase markers.
This fact also allows us to avoidthe difficulties in defining a label set.?
In Japanese, the mapping from syntactic casesto semantic roles tends to be reasonablystraightforward if a semantically rich lexicon ofverbs like the VerbNet (Kipper et al, 2000) isavailable.?
Furthermore, we have not yet found many NLPapplications for which the utility of seman-tic roles is actually demonstrated.
One maythink of using semantic roles in textual infer-ence as exemplified by, for example, Tatu andMoldovan (2006).
However, similar sort ofinference may well be realized with syntacticcases as demonstrated in the information ex-traction and question answering literature.Taking these respects into account, we choose tolabel predicate-argument relations in terms of syn-tactic cases, which follows the annotation schemeadopted in the Kyoto Corpus.3.2 Syntactic case alternationOnce the level of syntactic cases is chosen for ourannotation, another issue immediately arises, alter-ation of syntactic cases by syntactic transformationssuch as passivization and causativization.
For exam-ple, sentence (5) is an example of causativization,where Mary causes Tom?s eating action.
(5) Mary-ga Tom-ni ringo-o tabe-saseruMary-NOM Tom-DAT apple-ACC eat-CAUSATIVIZED(Mary helps Tom eat an apple.
)One way of annotating these arguments is some-thing like (6), where the relations between thecausativized predicate tabe-saseru (to make some-one eat) and its arguments are indicated in terms ofsurface syntactic cases.
(6) [REL=tabe-saseru (eat-CAUSATIVE),GA=Mary, NI=Tom, O=ringo (apple)]In fact, the Kyoto Corpus adopts this way of label-ing.An alternative way of treating such case alterna-tions is to identify logical (or deep) case relations,i.e.
the relations between the base form of each pred-icate and its arguments.
(7) illustrates how the ar-guments in sentence (5) are annotated with logicalcase relations: Tom is labeled as the ga-case (Nom-inative) filler of the verb tabe (to eat) and Mary is134labeled as the Extra-Nominative (EX-GA) which wenewly invent to indicate the Causer of a syntacticallycausativized clause.
(7) [REL=tabe-(ru) (eat), GA=Tom, O=ringo (ap-ple), EX-GA=Mary]In the NAIST Text Corpus, we choose to this lat-ter way of annotation motivated by such considera-tions as follows:?
Knowing that, for example, Tom is the filler ofthe ga-case (Nominative) of the verb tabe (toeat) in (5) is more useful than knowing that Tomis the ni-case (Dative) of the causativized verbtabe-saseru (to make someone eat) for such ap-plications as information extraction.?
The mapping from syntactic cases to semanticroles should be described in terms of logicalcase relations associated with bare verbs.3.3 Zero-anaphoraIn the PropBank the search space for a given pred-icate?s arguments is limited to the sentence thatpredicate appears in, because, syntactically, Englishobligatory arguments are overtly expressed exceptpro-form (e.g.
John hopes [PRO to leave.
]).In contrast, Japanese is characterized by extensiveuse of nominal ellipses, called zero-pronouns, whichbehave like pronouns in English texts.
Thus, if anargument is omitted, and an expression correspond-ing to that argument does not appear in the samesentence, annotators should search for its antecedentoutside of the sentence.
Furthermore, if an argumentis not explicitly mentioned in the text, they need toannotate that relation as ?exophoric.?
In the secondsentence of example (8), for instance, the ga (Nomi-native) argument of the predicate kaeru (go back) isomitted and refers to Tom in the first sentence.
Thekara (Ablative) argument of that predicate is alsoomitted, however the corresponding argument doesnot explicitly appear in the text.
In such cases, omit-ted arguments should be considered as ?exophoric.?
(8) Tomi-wa kyo gakko-ni it-ta .Tomi-TOP today school-LOC go-PAST PUNCTom went to school today.
(?i-ga) (?exophoric-kara) kae-tte suguni?i-NOM ?exophoric-ABL go back immediately(?i-ga) kouen-ni dekake-ta .
?i-NOM park-LOC go out-PAST PUNCHe went to the park as soon as he came backfrom school.Table 1: Comparison of annotating predicate-argument relationscorpus label search spacePropBank semantic role intraGDA Corpus semantic role inter, exoKyoto Corpus surface case intra, inter,(voice alternation involved) exoNAIST Corpus logical (deep) case intra, inter,(our corpus) (relation with bare verb) exointra: intra-sentential relations, inter: inter-sentential relations,exo: exophoric relationsTo the best of our knowledge, the GDA-Tagged Cor-pus does not contain intra-sentential zero-anaphoricrelations as predicate-argument relations, so it has aserious drawback when used as training data in ma-chine learning approaches.Unlike coreference between two explicit nounswhere only an IRA is possible, the relation betweena zero-pronoun and its antecedent can be either IRAor ISA.
For example, in example (8), ?i is annotatedas having an IRA relation with its antecedent Tomi.In contrast, example (9) exhibits an ISA relation be-tween iPodi and ?i.
(9) Tom-wa iPodi-o kaa-tta .Tom-TOP iPodi-ACC buya-PAST PUNCTom bought an iPod.Mary-mo (?i-o) kab-tta .Mary-TOP ?i-ACC buyb-PAST PUNCMary also bought one.
[REL=ka-(u) (buy), GA=Mary, O=iPodi]The above examples indicate that predicate-argument annotation in Japanese can potentially beannotated as either an IRA or ISA relation.
Note thatin Japanese these two relations cannot be explicitlyseparated by syntactic clues.
Thus, in our corpuswe annotate them without explicit distinction.
It isarguable that separate treatment of IRA and ISA inpredicate-argument annotation could be preferable.We consider this issue as a task of future work.A comparison of the specification is summarizedin Table 1.4 Annotating event-noun-argumentrelationsMeyers et al (2004) propose to annotate seman-tic relations between nouns referring to an eventin the context, which we call event-nouns in this135paper.
They release the NomBank corpus, inwhich PropBank-style semantic relations are anno-tated for event-nouns.
In (10), for example, thenoun ?growth?
refers to an event and ?dividends?and ?next year?
are annotated as ARG1 (roughlycorresponding to the theme role) and ARGM-TMP(temporal adjunct).
(10) 12% growth in dividends next year [REL=growth,ARG1=in dividends, ARGM-TMP=next year]Following the PropBank-style annotation, the Nom-Bank also restricts the search space for the argu-ments of a given event-noun to the sentence in whichthe event-noun appears.
In Japanese, on the otherhand, since predicate-argument relations are oftenzero-anaphoric, this restriction should be relaxed.4.1 Labels of event-noun-relationsRegarding the choice between semantic roles andsyntactic cases, we take the same approach asthat for predicate-argument relations, which is alsoadopted in the Kyoto Corpus.
For example, in (11),akajii (deficit) is identified as the ga argument of theevent-noun eikyo (influence).
(11) kono boueki akajii-wa waga kuni-nothis trade deficit-TOP our country-OFkyosoryokuj-ni eikyo-o oyobosucompetitiveness-DAT influence-ACC affect[REL=eikyo (influence), GA=akajii (deficit),O=kyosoryokuj (competitiveness)]The trade deficit affects our competitiveness.Note that unlike verbal predicates, event-nouns cannever be a subject of voice alternation.
An event-noun-argument relation is, therefore, necessarily an-notated in terms of the relation between the bareverb corresponding to the event-noun and its argu-ment.
This is another reason why we consider itreasonable to annotate the logical case relations be-tween bare verbs and their arguments for predicate-argument relations.4.2 Event-hoodAnother issue to be addressed is on the determina-tion of the ?event-hood?
of noun phrases, i.e.
thetask of determining whether a given noun refers toan event or not.
In Japanese, since neither singular-plural nor definite-indefinite distinction is explic-itly marked, event-hood determination tends to behighly context-dependent.
In sentence (12), for ex-ample, the first occurrence of denwa (phone-call),subscripted with i, should be interpreted as Tom?scalling event, whereas the second occurrence of thesame noun denwa should be interpreted as a physicaltelephone (cellphone).
(12) karea-karano denwai-niyoruto watashib-wahea-ABL phone-calli according to Ib-NOMkare-no ie-ni denwaj-o wasure-tarasiihis-OF home-LOC phonej -ACC leave-PASTAccording to his phone call, I might have leftmy cell phone at his home.To control the quality of event-hood determina-tion, we constrain the range of potential event-nounsfrom two different points of view, neither of whichis explicitly discussed in designing the specificationsof the Kyoto Corpus.First, we impose a POS-based constraint.
In ourcorpus annotation, we consider only verbal nouns(sahen-verbs; e.g.
denwa (phone) ) and deverbalnouns (the nominalized forms of verbs; e.g.
furumai(behavior)) as potential event-nouns.
This meansthat event-nouns that are not associated with a verb,such as jiko (accident), are out of scope of our anno-tation.Second, the determination of the event-hood ofa noun tends to be obscure when the noun consti-tutes a compound.
In (13), for example, the ver-bal noun kensetsu (construction) constituting a com-pound douro-kensetsu (road construction) can be in-terpreted as a constructing event.
We annotate it asan event and douro (road) as the o argument.
(13) (?-ga) douro-kensetsu-o tsuzukeru?-NOM road construction-ACC continueSomeone continues road construction.In (14), on the other hand, since the compoundfuransu kakumei (French Revolution) is a named-entity and is not semantically decomposable, it isnot reasonable to consider any sort of predicate-argument-like relations between its constituents fu-ransu (France) and kakumei (revolution).
(14) furansu-kakumei-ga okoruFrench Revolution-NOM take placeThe French Revolution took place.We therefore do not consider constituents of such se-mantically non-decomposable compounds as a tar-get of annotation.5 Statistics of the new corpusTwo annotators annotated predicate-argument andcoreference relations according to the specifications,136using all the documents in Kyoto Text Corpus ver-sion 3.0 (containing 38,384 sentences in 2,929 texts)as a target corpus.
We have so far annotatedpredicate-argument relations with only three majorcases: ga (Nominative), o (Accusative) and ni (Da-tive).
We decided not to annotate other case relationslike kara-case (Ablative) because the annotation ofthose cases was considered even further unreliable atthe point where we did not have enough experiencesin this annotation task.
Annotating other cases is oneof our future directions.The numbers of the annotated predicate-argumentrelations are shown in Table 2.
These relations arecategorized into five cases: (a) a predicate and itsargument appear in the same phrase, (b) the argu-ment syntactically depends on its predicate or viceversa, (c) the predicate and its argument have anintra-sentential zero-anaphora relation, (d) the pred-icate and its argument have an inter-sentential zero-anaphora relation and (e) the argument does not ex-plicitly appear in the text (i.e.
exophoric).
Table 2shows that in annotation for predicates over 80%of both o- and ni-arguments were found in depen-dency relations, while around 60% of ga-argumentswere in zero-anaphoric relations.
In comparison, inthe case of event-nouns, o- and ni-arguments arelikely to appear in the same phrase of given event-nouns, and about 80% of ga-arguments have zero-anaphoric relations with event-nouns.
With respectto the corpus size, we created a large-scaled anno-tated corpus with predicate-argument and corefer-ence relations.
The data size of our corpus alongwith other corpora is shown in Table 3.Next, to evaluate the agreement between the twohuman annotators, 287 randomly selected articleswere annotated by both of them.
The results areevaluated by calculating recall and precision inwhich one annotation result is regarded as correctand the other?s as the output of system.
Note thatonly the predicates annotated by both annotators areused in calculating recall and precision.
For eval-uation of coreference relations, we calculated re-call and precision based on the MUC score (Vilainet al, 1995).
The results are shown in Table 4,where we can see that most annotating work wasdone with high quality except for the ni-argument ofevent-nouns.
The most common source of error wascaused by verb alternation, and we will discuss thisTable 3: Data size of each corpuscorpus sizePropBank I 7,891 sentencesNomBank 0.8 24,311 sentencesACE (2005 English) 269 articlesGDA Corpus 2,177 articlesKyoto Corpus 555 articles (5,127 sentences)NAIST Corpus (ours) 2,929 articles (38,384 sentences)Table 4: Agreement of annotating each relationrecall precisionpredicate 0.947 (6512/6880) 0.941 (6512/6920)ga (NOM) 0.861 (5638/6549) 0.856 (5638/6567)o (ACC) 0.943 (2447/2595) 0.919 (2447/2664)ni (DAT) 0.892 (1060/1189) 0.817 (1060/1298)event-noun 0.905 (1281/1415) 0.810 (1281/1582)ga (NOM) 0.798 (1038/1300) 0.804 (1038/1291)o (ACC) 0.893 (469/525) 0.765 (469/613)ni (DAT) 0.717 (66/92) 0.606 (66/109)coreference 0.893 (1802/2019) 0.831 (1802/2168)issue in detail in Section 6.
Such investigation of thereliability of annotation has not been reported for ei-ther the Kyoto Corpus or the GDA-Tagged Corpus.However, our results also show that each annotatingtask still leaves room for improvement.
We summa-rize open issues and discuss the future directions inthe next section.6 Discussion6.1 Identification of predicates andevent-nounsIdentification of predicates is sometimes unreliabledue to the ambiguity between a literal usage and acompound functional usage.
For instance, the ex-pression ?to-shi-te?, which includes the verb shi (todo), is ambiguous: either the verb shi functions as acontent word, i.e.
an event-denoting word, or it con-stitutes a multi-word expression together with to andte.
In the latter case, it does not make sense to inter-pret the verb shi to denote an event.
However, thisjudgment is highly context-dependent and we havenot been able to devise a reliable criterion for it.Tsuchiya et al (2006) have built a functionalexpression-tagged corpus for automatically classify-ing these usages.
They reported that the agreementratio of functional expressions is higher than ours.We believe their findings to also become helpful in-formation for annotating predicates in our corpus.With regards to event-nouns, a similar problem137Table 2: Statistics: annotating predicate-arguments relationsga (Nominative) o (Accusative) ni (Dative)predicates (a) in same phrase 177 (0.002) 60 (0.001) 591 (0.027)106,628 (b) dependency relations 44,402 (0.419) 35,882 (0.835) 18,912 (0.879)(c) zero-anaphoric (intra-sentential) 32,270 (0.305) 5,625 (0.131) 1,417 (0.066)(d) zero-anaphoric (inter-sentential) 13,181 (0.124) 1,307 (0.030) 542 (0.025)(e) exophoric 15,885 (0.150) 96 (0.002) 45 (0.002)total 105,915 (1.000) 42,970 (1.000) 21,507 (1.000)event-nouns (a) in same phrase 2,195 (0.077) 5,574 (0.506) 846 (0.436)28,569 (b) dependency relations 4,332 (0.152) 2,890 (0.263) 298 (0.154)(c) zero-anaphoric (intra-sentential) 9,222 (0.324) 1,645 (0.149) 586 (0.302)(d) zero-anaphoric (inter-sentential) 5,190 (0.183) 854 (0.078) 201 (0.104)(e) exophoric 7,525 (0.264) 42 (0.004) 10 (0.005)total 28,464 (1.000) 11,005 (1.000) 1,941 (1.000)also arises.
If, for example, a compound noun con-tains a verbal noun, we have to judge whether theverbal noun can be interpreted as an event-noun ornot.
Currently, we ask annotators to check if themeaning of a given compound noun can be compo-sitionally decomposed into those of its constituents.However, the judgement of compositionality tendsto be highly subjective, causing the degradation ofthe agreement ratio of event-nouns as shown inTable 4.
We are planning to investigate this problemmore closely and refine the current compositionalitycriterion.
One option is to build lexical resources ofmulti-word expressions and compounds.6.2 Identification of argumentsAs we mentioned in 3.1, we use (deep) cases insteadof semantic roles as labels of predicate-argument re-lations.
While it has several advantages as discussedin 3.1, this choice has also a drawback that shouldbe removed.
The problem arises from lexical verbalternation.
It can sometimes be hard for annota-tors to determine a case frame of a given predicatewhen verb alternation takes place.
For example, sen-tence (15) can be analyzed simply as in (16a).
How-ever, since the verb shibaru (bind) has also anotheralternative case frame as in (16b), the labeling of thecase of the argument kisoku (rule), i.e.
either GA(NOM) or DE (INST) may be undecidable if the argu-ment is omitted.
(15) kisoku-ga hitobito-o shibarurule-NOM people-ACC bindThe rule binds people.
(16) a.
[REL = shibaru (bind), GA = kisoku (rule), O = hitobito(people)]b.
[REL = shibaru (bind), GA = ?
(exophoric), O = hito-bito (people), DE (Instrumental) = kisoku (rule)]Similar problems occur for event-nouns as well.For example, the event-noun hassei (realization) hasboth transitive and intransitive readings, which mayproduce awkward ambiguities.To avoid this problem, we have two options; oneis to predefine the preference in case frames as aconvention for annotation and the other is to dealwith such alternations based on generic resources oflexical semantics such as Lexical Conceptual Struc-ture (LCS) (Jackendoff, 1990).
Creating a JapaneseLCS dictionary is another on-going project, so wecan collaborate with them in developing the valuableresources.6.3 Event-hood determinationEvent-nouns of some semantic types such as keiyaku(contract), kisei (regulation) and toushi (investment)are interpreted as either an event or an entity result-ing from an event depending on are context.
How-ever, it is sometimes difficult to judge whether suchan event-noun should be interpreted as an event or aresultant entity even by considering the whole con-text, which degrades the stability of annotation.
Thisphenomena is also discussed in the NomBank, andwe will share their insights and refine our annotationmanual in the next step.6.4 Identification of coreference relationEven though coreference relation is defined as IRArelations, the lack of agreement on the granularity ofnoun classes makes the agreement ratio worse.
Inother words, it is crucial to decide how to annotateabstract nouns in order to improve the annotation.138Annotators judge coreference relations as whetheror not abstract nouns refer to the same entity in theworld.
However, the equivalence of the referents ofabstract nouns cannot be reconciled based on real-world existence since by definition abstract nounshave no physical entities in the real world.As far as predicate-argument relation is con-cerned, there might be a need for treating genericentities in addition to specific entities as coreferen-tial in some application.
For example, one may wantto relate kids to children in sentence (17).
(17) We all want children to be fit and healthy.However, the current invasion of fast food iscreating overweight and unhealthy kids.The coreference relation between generic nouns aremissed in the current specification since we annotateonly IRA relations between specific nouns.
Eventhough there are various discussions in the area ofsemantics, the issue of how to deal with genericnouns as either coreferential or not in real texts isstill left open.7 ConclusionIn this paper, we reported on the current specifica-tion of our annotated corpus for coreference reso-lution and predicate-argument analysis.
Taking theprevious work of corpus annotation into account, wedecided to annotate predicate-argument relations byISA and IRA relations, and coreference relations ac-cording to IRA relations.
With the Kyoto Text Cor-pus version 3.0 as a starting point, we built a largeannotated corpus.
We also discussed the revelationsmade from annotating our corpus, and discussed fu-ture directions for refining our specifications of theNAIST Text Corpus.AcknowledgementThis work is partially supported by the Grant-in-Aidfor Scientific Research in Priority Areas JAPANESECORPUS (http://tokuteicorpus.jp).ReferencesG.
Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,S.
Strassel, and R. Weischedel.
2004.
Automatic contentextraction (ace) program - task definitions and performancemeasures.
In Proceedings of the 4rd International Confer-ence on Language Resources and Evaluation (LREC-2004),pages 837?840.Charles J. Fillmore and Collin F. Baker.
2000.
Framenet:Frame semantics meets the corpus.
In Proceedings of the74th Annual Meeting of the Linguistic Society of America.K.
Hasida.
2005.
Global document annotation (gda) annotationmanual.
http://i-content.org/tagman.html.L.
Hirschman.
1997.
MUC-7 coreference task definition.
ver-sion 3.0.R.
Iida, K. Inui, and Y. Matsumoto.
2005.
Anaphora reso-lution by antecedent identification followed by anaphoricitydetermination.
ACM Transactions on Asian Language Infor-mation Processing (TALIP), 4:417?434.R.
Iida, K. Inui, and Y. Matsumoto.
2006.
Exploiting syntac-tic patterns as clues in zero-anaphora resolution.
In Proced-dings of the 21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the Association forComputational Linguistics (COLING-ACL), pages 625?632.R.
Jackendoff.
1990.
Semantic Structures.
Current Studies inLinguistics 18.
The MIT Press.D.
Kawahara, T. Kurohashi, and K. Hasida.
2002.
Construc-tion of a japanese relevance-tagged corpus (in japanese).
InProceedings of the 8th Annual Meeting of the Association forNatural Language Processing, pages 495?498.K.
Kipper, H. T. Dang, and M. Palmer.
2000.
Class-based con-struction of a verb lexicon.
In Proceedings of the 17th Na-tional Conference on Artificial Intelligence and 12th Confer-ence on on Innovative Applications of Artificial Intelligence,pages 691?696.A.
Meyers, R. Reeves, C. Macleod, R. Szekely, V. Zielinska,B.
Young, and R. Grishman.
2004.
The nombank project:An interimreport.
In Proceedings of the HLT-NAACL Work-shop on Frontiers in Corpus Annotation.Ruslan Mitkov.
2002.
Anaphora Resolution.
Studies in Lan-guage and Linguistics.
Pearson Education.V.
Ng and C. Cardie.
2002.
Improving machine learning ap-proaches to coreference resolution.
In Proceedings of the40th ACL, pages 104?111.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
The proposi-tion bank: An annotated corpus of semantic roles.
Compu-tational Linguistics, 31(1):71?106.M.
Poesio, R. Mehta, A. Maroudas, and J. Hitzeman.
2004.Learning to resolve bridging references.
In Proceddings ofthe 42nd Annual Meeting of the Association for Computa-tional Linguistics (ACL), pages 144?151.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
A machinelearning approach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.M.
Tatu and D. Moldovan.
2006.
A logic-based semantic ap-proach to recognizing textual entailment.
In Proceddingsof the 21st International Conference on Computational Lin-guistics and 44th Annual Meeting of the Association forComputational Linguistics (COLING-ACL), pages 819?826.M.
Tsuchiya, T. Utsuro, S. Matsuyoshi, S. Sato, and S. Nak-agawa.
2006.
Development and analysis of an exam-ple database of japanese compound functional expressions.IPSJ Journal, 47(6):1728?1741.K.
van Deemter and R. Kibble.
1999.
What is coreference, andwhat should coreference annotation be?
In Proceedings ofthe ACL ?99 Workshop on Coreference and its applications,pages 90?96.M.
Vilain, J. Burger, J. Aberdeen, D. Connolly, andL.
Hirschman.
1995.
A model-theoretic coreference scoringscheme.
In Proceedings of the 6th Message UnderstandingConference (MUC-6), pages 45?52.139
