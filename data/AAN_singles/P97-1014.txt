Centering in-the-Large:Computing Referential Discourse SegmentsUdo Hahn & Michael StrubeComputat iona l  Linguist ics Research GroupFreiburg University, Werthmannplatz  1D-79085 Freiburg, Germanyhttp://www.coling.uni-freiburg.de/AbstractWe specify an algorithm that builds up a hi-erarchy of referential discourse segments fromlocal centering data.
The spatial extension andnesting of these discourse segments constrainthe reachability of potential antecedents of ananaphoric expression beyond the local levelof adjacent center pairs.
Thus, the centeringmodel is scaled up to the level of the globalreferential structure of discourse.
An empiri-cal evaluation of the algorithm is supplied.1 IntroductionThe centering model (Grosz et al, 1995) has evolved asa major methodology for computational discourse analy-sis.
It provides imple, yet powerful data structures, con-straints and rules for the local coherence of discourse.
Asfar as anaphora resolution is concerned, e.g., the modelrequires to consider those discourse ntities as potentialantecedents for anaphoric expressions in the current ut-terance Ui, which are available in the forward-lookingcenters of the immediately preceding utterance Ui- 1.
Noconstraints or rules are formulated, however, that ac-count for anaphoric relationships which spread out overnon-adjacent u terances.
Hence, it is unclear how dis-course elements which appear in utterances precedingutterance Ui-1 are taken into consideration as potentialantecedents for anaphoric expressions in Ui.The extension of the search space for antecedents is byno means a trivial enterprise.
A simple linear backwardsearch of all preceding centering structures, e.g., maynot only turn out to establish illegal references but alsocontradicts the cognitive principles underlying the lim-ited attention constraint (Walker, 1996b).
The solutionwe propose starts from the observation that additionalconstraints on valid antecedents are placed by the globaldiscourse structure previous utterances are embedded in.We want to emphasize from the beginning that our pro-posal considers only the referential properties underlyingthe global discourse structure.
Accordingly, we definethe extension of referential discourse segments (over sev-eral utterances) and a hierarchy of referential discoursesegments (structuring the entire discourse).
1 The algo-rithmic procedure we propose for creating and manag-ing such segments receives local centering data as inputand generates a sort of superimposed index structure bywhich the reachability of potential antecedents, in par-ticular those prior to the immediately preceding utter-ance, is made explicit.
The adequacy of this definitionis judged by the effects centered iscourse segmentationhas on the validity of anaphora resolution (cf.
Section 5for a discussion of evaluation results).2 Global Discourse StructureThere have been only few attempts at dealing with therecognition and incorporation of discourse structure be-yond the level of immediately adjacent utterances withinthe centering framework.
Two recent studies deal withthis topic in order to relate attentional and intentionalstructures on a larger scale of global discourse coher-ence.
Passonneau (1996) proposes an algorithm for thegeneration of referring expressions and Walker (1996a)integrates centering into a cache model of attentionalstate.
Both studies, among other things, deal with thesupposition whether a correlation exists between partic-ular centering transitions (which were first introducedby Brennan et al (1987); cf.
Table 1) and intention-based discourse segments.
In particular, the role ofSHIFT-type transitions i examined from the perspectiveof whether they not only indicate a shift of the topic be-tween two immediately successive utterances but alsosignal (intention-based) segment boundaries.
The datain both studies reveal that only a weak correlation be-tween the SHIFT transitions and segment boundaries canbe observed.
This finding precludes a reliable predic-tion of segment boundaries based on the occurrence of1 Our notion of referential discourse segment should not beconfounded with the intentional one originating from Grosz &Sidner (1986), for reasons discussed inSection 2.104SHIFTS and vice versa.
In order to accommodate to theseempirical results divergent solutions are proposed.
Pas-sonneau suggests that the centering data structures needto be modified appropriately, while Walker concludesthat the local centering data should be left as they areand further be complemented by a cache mechanism.She thus intends to extend the scope of centering in ac-cordance with cognitively plausible limits of the atten-tional span.
Walker, finally, claims that the content ofthe cache, rather than the intentional discourse segmentstructure, determines the accessibility of discourse nti-ties for anaphora resolution.c~(v.) = cdu.-~) c~(u.)
#OR Cb(Vn-1) undef.
Cb(Vn-1)Cb(Un) = CONTINUE (C) SMOOTH-SHIFT (SS) c~(u.)cb(u.)
# RETAIN (R) ROUGH-SHIFT (RS) c~(u.
)Table h Transition TypesAs a working hypothesis, for the purposes of anaphoraresolution we subscribe to Walker's model, in particularto that part which casts doubt on the hypothesized de-pendency of the attentional from the intentional structureof discourse (Grosz & Sidner, 1986, p. 180).
We divergefrom Walker (1996a), however, in that we propose an al-ternative to the caching mechanism, which we considerto be methodologically more parsimonious and, at least,to be equally effective (for an elaboration of this claim,cf.
Section 6).The proposed extension of the centering model buildson the methodological framework of functional center-ing (Strube & Hahn, 1996).
This is an approach to cen-tering in which issues such as thematicity or topicalityare already inherent.
Its linguistic foundations relate theranking of the forward-looking centers and the functionalinformation structure of the utterances, a notion origi-nally developed by Dane~ (1974).
Strube & Hahn (1996)use the centering data structures to redefine Dane~'s tri-chotomy between given information, theme and rhemein terms of the centering model.
The Cb(Un), the mosthighly ranked element of C!
(Un-1) realized in Un, cor-responds to the element which represents the given in-formation.
The theme of Un is represented by the pre-ferred center Cp (Un), the most highly ranked element ofC!
( Un ).
The theme/rheme hierarchy of Un correspondsto the ranking in the C!
s. As a consequence, utteranceswithout any anaphoric expression do not have any givenelements and, therefore, no Cb.
But independent of theuse of anaphoric expressions, each utterance must have atheme and a C!
as well.The identification of the preferred center with thetheme implies that it is of major relevance for determin-ing the thematic progression of a text.
This is reflected inour reformulation of the two types of thematic progres-sion (TP) which can be directly derived from centeringdata (the third one requires to refer to conceptual gener-alization hierarchies and is therefore beyond the scope ofthis paper, cf.
Dane~ (1974) for the original statement):1.
TP with a constant heme: Successive utterancescontinuously share the same Cp.2.
TP with linear thematization f rhemes: An elementof the C!
(Ui- 1 ) which is not the Cp (Ui- 1 ) appearsin Ui and becomes the Cp(Ui) after the processingof this utterance.Cf (V i -1 )  : \[ c 1 .
.
.
.
.
e j  .
.
.
.
.
cs \]C~(V i )  : \[ Cl .
.
.
.
.
ck .
.
.
.
.
et \]Cf (U i -1 ) :  \ [e l  .
.
.
.
.
c j  .
.
.
.
.
cs \ ]  l< j<sCf (Vd:  \ [e l  ..... ek ..... e~lTable 2: Thematic Progression PatternsTable 2 visualizes the abstract schemata of TP pat-terns.
In our example (cf.
Table 8 in Section 4), U1 to Uaillustrate the constant theme, while U7 to U10 illustratethe linear thematization f rhemes.
In the latter case,the theme changes in each utterance, from "Handbuch"(manual) via "Inhaltsverzeichnis" (table of contents) to"Kapitel" (chapter) etc.
Each of the new themes are in-troduced in the immediately preceding utterance so thatlocal coherence between these utterances i established.Daneg (1974) also allows for the combination and re-cursion of these basic patterns; this way the global the-matic coherence of a text can be described by recurrenceto these structural patterns.
These principles allow fora major extension of the original centering algorithm.Given a reformulation of the TP constraints in center-ing terms, it is possible to determine referential segmentboundaries and to arrange these segments in a nested,i.e., hierarchical manner on the basis of which reacha-bility constraints for antecedents can be formulated.
Ac-cording to the segmentation strategy of our approach, theCp of the end point (i.e., the last utterance) of a discoursesegment provides the major theme of the whole segment,one which is particularly salient for anaphoric referencerelations.
Whenever a relevant new theme is established,however, it should reside in its own discourse segment,either embedded or in parallel to another one.
Anaphoraresolution can then be performed (a) with the forward-looking centers of the linearly immediately preceding ut-terance, (b) with the forward-looking centers of the endpoint of the hierarchically immediately reachable dis-course segment, and (c) with the preferred center of theend point of any hierarchically reachable discourse seg-ment (for a formalization of this constraint, cf.
Table 4).1053 Computing Global Discourse StructurePrior to a discussion of the algorithmic procedure for hy-pothesizing discourse segments based on evidence fromlocal centering data, we will introduce its basic build-ing blocks.
Let x denote the anaphoric expression underconsideration, which occurs in utterance Ui associatedwith segment level s. The function Resolved(x, s, Us)(cf.
Table 3) is evaluated in order to determine the properantecedent ante for x.
It consists of the evaluation ofa teachability predicate for the antecedent on which wewill concentrate here, and of the evaluation of the predi-cate lsAnaphorFor which contains the linguistic and con-ceptual constraints imposed on a (pro)nominal anaphor(viz.
agreement, binding, and sortal constraints) or a tex-tual ellipsis (Hahn et al, 1996), not an issue in this paper.The predicate lsReachable (cf.
Table 4) requires ante tobe reachable from the utterance Us associated with thesegment level s. 2 Reachability is thus made dependenton the segment structure DS of the discourse as builtup by the segmentation algorithm which is specified inTable 6.
In Table 4, the symbol "=str" denotes tringequality, N the natural numbers.
We also introduce as anotational convention that a discourse segment is identi-fied by its index s and its opening and closing utterance,viz.
DS\[s.beg\] and DS\[s.end\], respectively.
Hence, wemay either identify an utterance Ui by its linear text in-dex, i, or, if it is accessible, with respect o its hierarchi-cal discourse segment index, s (e.g., cf.
Table 8 whereU3 = UDs\[1.end\] or U13 = UDs\[3.end\]).
The discoursesegment index is always identical to the currently validsegment level, since the algorithm in Table 6 implementsa stack behavior.
Note also that we attach the discoursesegment index s to center expressions, e.g., Cb(s, Us).Resolved(x, s Ui) :=l ante if  IsReachable(ante, s, Ui)A IsAnaphorFor(x, ante)under elseTable 3: Resolution of AnaphoraIsReachable(ante, s, Ui )i f  ante 6 C/(s, Ui-1)else i f  ante E C/(s - 1, Uosts_,.~,a\])else if  (3v E N : ante =~tr Cp(v, UDsI .... a\])^ v < (s  - 1))A (-~Sv' 6 N :  ante =,t , -  Cp(v',UDst~,.~ndl)A v < v')Table 4: Reachability of the Anaphoric AntecedentFinally, the function Lift(s, i) (cf.
Table 5) determinesthe appropriate discourse segment level, s, of an utter-2The Cf lists in the functional centering model are totallyordered (Strobe & Hahn, 1996, p.272) and we here implicitlyassume that they are accessed inthe total order given.ance Ui (selected by its linear text index, i).
Lift onlyapplies to structural configurations in the centering listsin which themes continuously shift at three different con-secutive segment levels and associated preferred centersat least (cf.
Table 2, lower box, for the basic pattern).Lift(s, i) :=L i f t ( s -  1, i -  1) i fs>2Ai>3^ c.(s,u,_~) # c~(~ - 1,u,_~)^ c~(s - I, u,_~) # c.(s - 2, u,_~)^ c~(s,u,_,) ?
c j ( s -  1,u,_~)8 elseTable 5: Lifting to the Appropriate Discourse SegmentWhenever a discourse segment is created, its startingand closing utterances are initialized to the current po-sition in the discourse.
Its end point gets continuouslyincremented as the analysis proceeds until this discoursesegment DS  is ultimately closed, i.e., whenever anothersegment DS' exists at the same or a hierarchically higherlevel of embedding such that the end point of DS' ex-ceeds that of the end point of DS.
Closed segments areinaccessible for the antecedent search.
In Table 8, e.g.,the first two discourse segments at level 3 (ranging fromU5 to U5 and Us to Ul l  ) are closed, while those at level1 (ranging from U1 to U3), level 2 (ranging from U4 toUT) and level 3 (ranging from U12 to U13) are open.The main algorithm (see Table 6) consists of three ma-jor logical blocks (s and Ui denote the current discoursesegment level and utterance, respectively).1.
Continue Current Segment.
The Cp(s, Ui-1) istaken over for Ui.
If Ui-1 and Ui indicate the endof a sequence in which a series of thematizations ofrhemes have occurred, all embedded segments arelifted by the function Lift to a higher level s'.
As aresult of lifting, the entire sequence (including thefinal two utterances) forms a single segment.
Thisis trivially true for cases of a constant theme.2.
Close Embedded Segment(s).
(a) Close the embedded segment(s) and continueanother, already existing segment: If Ui doesnot include any anaphoric expression which isan element of the Cf (s, Ui-O, then match theantecedent in the hierarchically reachable seg-ments.
Only the Cp of the utterance at the endpoint of any of these segments is considereda potential antecedent.
Note that, as a sideeffect, hierarchically lower segments are ulti-mately closed when a match at higher segmentlevels succeeds.
(b) Close the embedded segment and open a new,parallel one: If none of the anaphoric ex-pressions under consideration co-specify the106Cp(8  - 1, U\[8_l.end\]), then the entire C!
atthis segment level is checked for the given ut-terance.
If an antecedent matches, the segmentwhich contains Ui- 1 is ultimately closed, sinceUi opens a parallel segment at the same level ofembedding.
Subsequent anaphora checks ex-clude any of the preceding parallel segmentsfrom the search for a valid antecedent and justvisit the currently open one.
(c) Open new, embedded segment: If there is nomatching antecedent in hierarchically reach-able segments, then for utterance Ui a new, em-bedded segment is opened.3.
Open New, Embedded Segment.
If none of theabove cases applies, then for utterance Ui a new,embedded segment is opened.
In the course of pro-cessing the following utterances, this decision maybe retracted by the function Lift.
It serves as a kindof "garbage collector" for globally insignificant dis-course segments which, nevertheless, were reason-able from a local perspective for reference resolu-tion purposes.
Hence, the centered iscourse seg-mentation procedure works in an incremental wayand revises only locally relevant, yet globally irrel-evant segmentation decisions on the fly.s := li :=1DS\[s.be9\] :=iDS\[s.end\] := iwhile -- end of texti := i+1n := {Resolved(x,s, Ui) lx E U~}i f3 r  ?
T~ : r ~---str Cp(s, Ui-1) (1)then s' 1= si' := iDS\[Lift(s', i').end\] := ielse i f~3r E Tt : r ?
Cl(s, Ui_l ) (2a)then found := FALSEk :~swhile-,found A (k > 1)k :=k-1i_f3r ?
7?.
: r =s,r Cp(k, Utk.~,,~)then s := kDS\[s.end\] := ifound := TRUEelse if k = s - 1 (2b)then if3r ?~ : r ?Cs(k, Utk.o,,,~)then DS\[s.beg\] :=iDS\[s.end\] := ifound := TRUEif -,found (2e)then s := s + 1DS\[s.beg\] := iDS\[s.end\] := ielse s := s q- 1 (3)DS\[s.beg\] := iDS\[s.end\] := iTable 6: Algorithm for Centered Segmentation4 A Sample Text SegmentationThe text with respect to which we demonstrate he work-ing of the algorithm (see Table 7) is taken from a Germancomputer magazine (c't, 1995, No.4, p.209).
For easeof presentation the text is somewhat shortened.
Sincethe method for computing levels of discourse segmentsdepends heavily on different kinds of anaphoric expres-sions, (pro)nominal anaphors and textual ellipses aremarked by italics, and the (pro)nominal naphors are un-derlined, in addition.
In order to convey the influence ofthe German word order we provide a rough phrase-to-phrase translation of the entire text.The centered segmentation a alysis of the sample textis given in Table 8.
The first column shows the linear textindex of each utterance.
The second column containsthe centering data as computed by functional centering(Strube & Hahn, 1996).
The first element of the C I, thepreferred center, Cp, is marked by bold font.
The thirdcolumn lists the centering transitions which are derivedfrom the Cb/C!
data of immediately successive utter-ances (cf.
Table 1 for the definitions).
The fourth columndepicts the levels of discourse segments which are com-puted by the algorithm in Table 6.
Horizontal ines in-dicate the beginning of a segment (in the algorithm, thiscorresponds to a value assignment to DS\[s.beg\]).
Verti-cal lines show the extension of a segment (its end is fixedby an assignment to DS\[s.end\]).
The fifth column indi-cates which block of the algorithm applies to the currentutterance (cf.
the right margin in Table 6).The computation starts at U1, the headline.
TheC1(Ux ) is set to "1260" which is meant as an abbre-viation of "Brother HL-1260".
Upon initialization, thebeginning as well as the ending of the initial discoursesegment are both set to "1".
U2 and Ua simply con-tinue this segment (block (1) of the algorithm), so Liftdoes not apply.
The C v is set to "1260" in all utter-ances of this segment.
Since U4 does neither contain anyanaphoric expression which co-specifies the Cv(1 ,Ua)(block (1)) nor any other element of the 67/( 1, U3) (block(2a)), and as there is no hierarchically preceding seg-ment, block (2c) applies.
The segment counter s is in-cremented and a new segment at level 2 is opened, set-ting the beginning and the ending to "4".
The phrase"das diinne Handbiichlein" (the thin leaflet) in U5 doesnot co-specify the C v (2, U4) but co-specifies an elementof the C!
(2, U4) instead (viz.
"Handbuch" (manual)).Hence, block (3) of the algorithm applies, leading tothe creation of a new segment at level 3.
The anaphor"Handbuch" (manual) in U6 co-specifies the Cv(3 ,Us).Hence block (1) applies (the occurrence of "1260" inCI(U5 ) is due to the assumptions specified by Strube& Hahn (1996)).
Given this configuration, the func-tion Lift lifts the embedded segment one level, so the107(1)(2)(3)(4)(5)(6)(7)Brother HL- 1260Ein Detail fiillt schon beim ersten Umgang mit demgrogen Brother auf:One particular - is already noticed - in the first approachto - the big Brother.Im Betrieb macht e._gr durch ein kr~iftiges Arbeitsger~uschauf sich aufmerksam, das auch im Stand-by-Modus nochgut vemehmbar ist.In operation - draws - it - with a heavy noise level -attention to itself-  which - also - in the stand-by mode -is still well audible.F~r Standard-InstaUationen kommt man gut ohne Hand-buch aus.As far as standard installations are concerned- gets - one- well - by - without any manual.Zwar ed~iutert das dSnne Handbiichlein die Bedienungder Hardware anschaulich und gut illustriert.Admittedly, gives - the thin leaflet- the operation of thehardware- aclear description of - and - well illustrated.Die Software-Seite wurde im Handbuch dagegenstiefmSttedich behandelt:The software part - was - in the manual- however - likea stepmother- treated:bis auf eine karge Seite mit einem Inhaltsverzeichnis zumHP-Modus sucht man vergebens weitere Informationen.except for one meagre page- containing the table of con-tents for the HP mode - seeks- one-  in vain-  for furtherinformation.
(8) Kein Wander: unter dem lnhaltsverzeichnis steht der lap-idare Hinweis, man m6ge sich die Seiten dieses Kapitelsdoch bitte yon Diskette ausdrucken- Frechheit.No wonder: beneath the table of contents - one finds theterse instruction, one should - oneself-  the pages of thissection - please - from disk - print out - - impertinence.
(9) Ohne diesen Ausdruck sucht man vergebens nach einemHinweis darauf, warum die Auto-Continue-Funktion nder PostScript-Emulation nicht wirkt.Without his print-out, looks - one - in vain - for a hint -why - the auto-continue-function - in the PostScript em-ulation - does not work.
(10) Nach dem Einschalten zeigt das LC-Display an, dab diesepraktische Hilfsfunktion icht aktiv ist;After switching on - depicts - the LC display - that - thispractical help function - not active - is;(11) si__.ge tiberwacht den Dateientransfer vom Computer.it monitors the file transfer from the computer.
(12) Viele der kleinen Macken verzeiht man dem HL-1260wenn man erste Ausdrucke in H~inden h~ilt.Many of the minor defects - pardons - one - theHL-1260, when - one - the first print outs - holds in\[one' s\] hands.
(13) Gerasterte Grauflftchen erzeugt der Brother sehr homogenRaster-mode grey-scale areas - generates - the Brother-very homogeneously...Table 7: Sample Textsegment which ended with U4 is now continued up toU6 at level 2.
As a consequence, the centering data ofU5 are excluded from further consideration as far as theco-specification by any subsequent anaphoric expressionis concerned.
Uz simply continues the same segment,since the textual ellipsis "Seite" (page) refers to "Hand-buch" (manual).
The utterances U8 to U10 exhibit a typ-ical thematization-of-the-rhemes pattern which is quitecommon for the detailed description of objects.
(Notethe sequence of SHIFT transitions.)
Hence, block (3)of the algorithm applies to each of the utterances and,correspondingly, new segments at the levels 3 to 5 arecreated.
This behavior breaks down at the occurrenceof the anaphoric expression "sie" (it) in Uxl which co-specifies the Cp ( 5, Ul o ), viz.
"auto-continue function",denoted by another anaphoric expression, namely "Hil-fsfunktion" (help function) in U10.
Hence, block (1) ap-plies.
The evaluation of  Lift succeeds with respect totwo levels of  embedding.
As a result, the whole se-quence is lifted up to level 3 and continues this segmentwhich started at the discourse lement "lnhaltsverzeich-his" (list o f  contents).
As a result of applying Lift, thewhole sequence is captured in one segment.
U12 doesnot contain any anaphoric expression which co-specifiesan element of  the C!
(3, U11), hence block (2) of  the al-gorithm applies.
The anaphor "HL-1260" does not co-specify the Cp of the utterance which represents the endof the hierarchically preceding discourse segment (UT),but it co-specifies an element of the C!
(2, UT).
The im-mediately preceding segment is ultimately closed and aparallel segment is opened at UI~ (cf.
block (2b)).
Notealso that the algorithm does not check the C!
(3, U10) de-spite the fact that it contains the antecedent of  "1260".However, the occurrences of "1260" in the C fs  of  U9and Ux0 are mediated by textual ellipses.
I f  these ut-terances contained the expression "1260" itself, the al-gorithm would have built a different discourse structureand, therefore, "1260" in U10 were reachable for theanaphor in Ulz.
Segment 3, finally, is continued by Ulz.5 Empi r i ca l  Eva luat ionIn this section, we present some empirical data concern-ing  the centered segmentation algorithm.
Our study wasbased on the analysis of twelve texts from the informa-tion technology domain (IT), of one text from a Ger-108U~(1) Cb:Cf.
"(2) Cb:Cf:(3) Cb:Cf:(4) Cb:Cf.
"(5) Cb:Cf:(6) Cb:Cf:(7) Cb:Cf:(8) Cb:Cf:(9) Cb:Cf:(10) Cb:Cf:(11) Cb:Cf:(12) Cb:Cf:(13) Cb:Cf:Centering Data Trans.\[1260\]1260 C\[1260, Umgang, Detail\]1260 C\[1260, Betrieb, Arbeitsger~usch, Stand-by-Modus\]\[Standard-Installation, Ha dbuch\]Handbuch C\[Handbueh, 1260, Hardware, Bedienung\]Handbuch C\[Handbuch, 1260, Software\]Handbuch C\[Handbueh, Seite, 1260, HP-Modus,Inhaltsverzeichnis, Informationen\]Inhaltsverzeichnis SS\[Inhaltsverzeiehnis, H nweis, Seiten, Kapitel,Diskette, Frechheit\]Kapitel SS\[Kapitel, Ausdmck, Hinweis, 1260,Auto-Continue-Funktion, PostScript-Emulation\]1260 RS\[Auto-Continue-Funktion, 1260, LC-Display\]Auto-Continue-Funktion SS\[Auto-Continue-Funktion, Dateien-Transfer,Computer\]\[1260, Macken, Ausdmck\]1260 C\[1260, Graufl~ichen\]man news magazine (Spiegel) 3, and of two literary texts 4(Lit).
Table 9 summarizes the total numbers of anaphors,textual ellipses, utterances, and words in the test set.Levels of Discourse Segments1 2 3 4 5E4962405478319IT Spiegelanaphors 197 101 198ellipses 195 22 23utterances 336 84 127words 5241 1468 1610Block112e31, Lift1I 31, Lift2bTable 8: Sample of a Centered Text Segmentation Analysisneither specified for anaphoric antecedents in Ui, not anissue here, nor for anaphoric antecedents beyond Ui-1.In the test set, 139 anaphors (28%) and 116 textual el-lipses (48,3%) fall out of the (intersentential) scope ofLit those common algorithms.
So, the problem we consideris not a marginal one.U~Ui-2Ui-aUi-4Ui-5Table 9: Test SetTable 10 and Table 11 consider the number ofanaphoric and text-elliptical expressions, respectively,and the linear distance they have to their correspond-ing antecedents.
Note that common centering algorithms(e.g., the one by Brennan et al (1987)) are specifiedonly for the resolution of anaphors in Ui-1.
They are3japan - Der Neue der alten Garde.
In Der Spiegel, Nr.
3,1996.4The first two chapters of a short story by the Germanwriter Heiner MOiler (Liebesgeschichte.
In Heiner MOiler.Geschichten aus der Produktion 2.
Berlin: Rotbuch Verlag,1974, pp.57-63) and the first chapter of a novel by Uwe Johnson(ZweiAnsichten.
Frankfurt/Main: Suhrkamp Verlag, 1965.
)10117281866Lit E7 32 4970 121 30814 24 665 10 331 5 120 1 71 3 121 1 52 1 4Ui-~ to Ui-lO 8Ui-l, to Ui-15 3Ui-l~ to U,-2o 1Table 10: Anaphoric Antecedent in Utterance U~Table 12 and Table 13 give the success rate of thecentered segmentation algorithm for anaphors and tex-tual ellipses, respectively.
The numbers in these tablesindicate at which segment level anaphors and textual el-lipses were correctly resolved.
The category of errors109U/-1Ui-2Ui-3Ui-4Ui-5Ui-6 to Ui-loUi-u to Ui-15IT Spiegel Lit E94 15 15 12442 6 8 5616 0 0 1614 0 0 148 0 0 814 1 0 157 0 0 7Table 11: Elliptical Antecedent in Utterance Ucovers erroneous analyses the algorithm produces, whilethe one for false positives concerns those resolution re-sults where a referential expression was resolved withthe hierarchically most recent antecedent but not with thelinearly most recent (obviously, the targeted) one (both ofthem denote the same discourse ntity).
The categoriesCy(s,  Ui-1) in Tables 12 and 13 contain more elementsthan the categories Ui-1 in Tables 10 and 11, respec-tively, due to the mediating property of textual ellipses infunctional centering (Strube & Hahn, 1996).U~cI(~,U~-,)Cp(s - 1, UDS\[,--L,,d\])C/(s  - 1, UDsls--l.end\])Cp(s - 2, UDS\[8-2...~)Cp(s - 3, UDS\[~-3.,,~)Cp(s - 4, UDSl,--4.,,d\])c~( ~ - s, uo  s\[,-~.,,~l)errorsfalse positives~ m10 7 32 49161 78 125 36414 9 24 477 5 9 211 0 1 21 0 1 20 0 1 10 1 0 I3 1 5 9(I) (3) (7) (11)Table 12: Anaphoric Antecedent in Center~c l  (s, U~-i )Cp(s - 1, UDSi,-1.,,~d\])CI(s - 1, Uosls-~.
*,a\])Cp(s - 2, Uosts-~.~,,~l)Cp(s - 3, UDats-Z.ena\])errorsIT Spiegel Lit156 18 1718 0 410 1 27 1 03 0 01 2 0(2) (0) (3)E1912213833(5)Table 13: Elliptical Antecedent in CenterxThe centered segmentation algorithm reveals a prettygood performance.
This is to some extent implied bythe structural patterns we find in expository texts, viz.their single-theme property (e.g., "1260" in the sampletext).
In contrast, the literary texts in the test exhibiteda much more difficult internal structure which resem-bled the multiple thread structure of dialogues discussedby Ros6 et al (1995).
The good news is that the seg-mentation procedure we propose is capable of dealingeven with these more complicated structures.
While onlyone antecedent of a pronoun was not reachable given thesuperimposed text structure, the remaining eight errorsare characterized by full definite noun phrases or propernames.
The vast majority of these phenomena can beconsidered informationally redundant utterances in theterminology of Walker (1996b) for which we currentlyhave no solution at all.
It seems to us that these kindsof phrases may override text-grammatical structures asevidenced by referential discourse segments and, rather,trigger other kinds of search strategies.Though we fed the centered segmentation algorithmwith rather long texts (up to 84 utterances), the an-tecedents of only two anaphoric expressions had tobridge a hierarchical distance of more than 3 levels.
Thiscoincides with our supposition that the overall structurecomputed by the algorithm should be rather fiat.
Wecould not find an embedding of more than seven levels.6 Related WorkThere has always been an implicit relationship betweenthe local perspective of centering and the global viewof focusing on discourse structure (cf.
the discussion inGrosz et al (1995)).
However, work establishing an ex-plicit account of how both can be joined in a computa-tional model has not been done so far.
The efforts ofSidner (1983), e.g., have provided a variety of differentfocus data structures to be used for reference resolution.This multiplicity and the on-going rowth of the numberof different entities (cf.
Suri & McCoy (1994)) mirrorsan increase in explanatory constructs that we consider amethodological drawback to this approach because theycan hardly be kept control of.
Our model, due to its hier-archical nature implements a stack behavior that is alsoinherent o the above mentioned proposals.
We refrain,however, from establishing a new data type (even worse,different ypes of stacks) that has to be managed on itsown.
There is no need for extra computations to deter-mine the "segment focus", since that is implicitly givenin the local centering data already available in our model.A recent attempt at introducing lobal discourse no-tions into the centering framework considers the use of acache model (Walker, 1996b).
This introduces an addi-tional data type with its own management principles fordata storage, retrieval and update.
While our proposalfor centered iscourse segmentation also requires a datastructure of its own, it is better integrated into centeringthan the caching model, since the cells of segment struc-tures simply contain "pointers" that implement a directlink to the original centering data.
Hence, we avoid ex-tra operations related to feeding and updating the cache.The relation between our centered segmentation algo-rithm and Walker's (1996a) integration of centering intothe cache model can be viewed from two different angles.On the one hand, centered segmentation may be a partof the cache model, since it provides an elaborate, non-linear ordering of the elements within the cache.
Note,however, that our model does not require any prefixedsize corresponding to the limited attention constraint.
Onthe other hand, centered segmentation may replace the110cache model entirely, since both are competing modelsof the attentional state.
Centered segmentation has alsothe additional advantage of restricting the search space ofanaphoric antecedents tothose discourse ntities actuallyreferred to in the discourse, while the cache model allowsunrestricted retrieval in the main or long-term memory.Text segmentation procedures (more with an informa-tion retrieval motivation, rather than being related to ref-erence resolution tasks) have also been proposed for acoarse-grained partitioning of texts into contiguous, non-overlapping blocks and assigning content labels to theseblocks (Hearst, 1994).
The methodological basis of thesestudies are lexical cohesion indicators (Morris & Hirst,1991) combined with word-level co-occurrence statis-tics.
Since the labelling is one-dimensional, this approxi-mates our use of preferred centers of discourse segments.These studies, however, lack the fine-grained informa-tion of the contents of Cf lists also needed for properreference resolution.Finally, many studies on discourse segmentation high-light the role of cue words for signaling segment bound-aries (cf., e.g., the discussion in Passonneau & Litman(1993)).
However useful this strategy might be, we seethe danger that such a surface-level description may actu-ally hide structural regularities at deeper levels of inves-tigation illustrated by access mechanisms for centeringdata at different levels of discourse segmentation.7 ConclusionsWe have developed a proposal for extending the cen-tering model to incorporate the global referential struc-ture of discourse for reference resolution.
The hierarchyof discourse segments we compute realizes certain con-straints on the reachability of antecedents.
Moreover, theclaim is made that the hierarchy of discourse segmentsimplements an intuitive notion of the limited attentionconstraint, as we avoid a simplistic, cognitively implausi-ble linear backward search for potentional discourse ref-erents.
Since we operate within a functional framework,this study also presents one of the rare formal accounts ofthematic progression patterns for full-fledged texts whichwere informally introduced by Dane~ (1974).The model, nevertheless, still has several restrictions.First, it has been developed on the basis of a small corpusof written texts.
Though these cover diverse text sorts(viz.
technical product reviews, newspaper articles andliterary narratives), we currently do not account for spo-ken monologues as modelled, e.g., by Passonneau & Lit-man (1993) or even the intricacies of dyadic conversa-tions Ros6 et al (1995) deal with.
Second, a thoroughintegration of the referential and intentional descriptionof discourse segments still has to be worked out.Acknowledgments.
We like to thank our colleagues in theCLIF group for fruitful discussions and instant support, JoeBush who polished the text as a native speaker, the three anony-mous reviewers for their critical comments, and, in particular,Bonnie Webber for supplying invaluable comments to an ear-lier draft of this paper.
Michael Strube is supported by a post-doctoral grant from DFG (Str 545/1-1).ReferencesBrennan, S. E., M. W. Friedman & C. J. Pollard (1987).
Acentering approach to pronouns.
In Proc.
of the 25 th AnnualMeeting of the Association for Computational Linguistics;Stanford, Cal., 6-g July 1987, pp.
155-162.Dane~, E (1974).
Functional sentence perspective and the orga-nization of the text.
In E Dane~ (Ed.
), Papers on FunctionalSentence Perspective, pp.
106-128.
Prague: Academia.Grosz, B. J., A. K. Joshi & S. Weinstein (1995).
Centering:A framework for modeling the local coherence ofdiscourse.Computational Linguistics, 21 (2):203-225.Grosz, B. J.
& C. L. Sidner (1986).
Attention, intentions,and the structure of discourse.
Computational Linguistics,12(3): 175-204.Hahn, U., K. Markert & M. Strube (1996).
A conceptual rea-soning approach to textual ellipsis.
In Proc.
of the 12 th Euro-pean Conference on Artificial Intelligence (ECAI '96); Bu-dapest, Hungary, 12-16 August 1996, pp.
572-576.
Chich-ester: John Wiley.Hearst, M. A.
(1994).
Multi-paragraph segmentation f expos-nd itory text.
In Proc.
of the 32 Annual Meeting of the As-sociation for Computational Linguistics; Las Cruces, N.M.,27-30June 1994, pp.
9-16.Morris, J.
& G. Hirst (1991).
Lexical cohesion computed bythesaural relations as an indicator of the structure of text.Computational Linguistics, 17(1):21-48.Passonneau, R. J.
(1996).
Interaction of discourse structurewith explicitness of discourse anaphoric noun phrases.
InM.
Walker, A. Joshi & E. Prince (Eds.
), Centering in Dis-course.
Preprint.Passonneau, R. J.
& D. J. Litman (1993).
Intention based seg-mentation: Human reliability and correlation with linguisticcues.
In Proc.
of the 318t Annual Meeting of the Associa-tion for Computational Linguistics; Columbus, Ohio, 22-26June 1993, pp.
148-155.Ros6, C. E, B.
Di Eugenio, L. S. Levin & C. Van Ess-Dykema(1995).
Discourse processing of dialogues with multiplerd  threads.
In Proc.
of the 33 Annual Meeting of the Asso-ciation for Computational Linguistics; Cambridge, Mass.,26-30June 1995, pp.
31-38.Sidner, C. L. (1983).
Focusing in the comprehension f definiteanaphora.
InM.
Brady & R. Berwick (Eds.
), ComputationalModels of Discourse, pp.
267-330.
Cambridge, Mass.
: MITPress.Strobe, M. & U. Hahn (1996).
Functional centering.
In Proc.of the 34 th Annual Meeting of the Association for Computa-tional Linguistics; Santa Cruz, Cal., 23-28 June 1996, pp.270-277.Suri, L. Z.
& K. E McCoy (1994).
RAFT/RAPR and center-ing: A comparison and discussion of problems related toprocessing complex sentences.
Computational Linguistics,20(2):301-317.Walker, M. A.
(1996a).
Centering, anaphora resolution, anddiscourse structure.
In M. Walker, A. Joshi & E.
Prince(Eds.
), Centering in Discourse.
Preprint.Walker, M. A.
(1996b).
Limited attention and discourse struc-ture.
Computational Linguistics, 22(2):255-264.111
