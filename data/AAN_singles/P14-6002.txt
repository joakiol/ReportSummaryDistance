Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: Tutorials, pages 4?5,Baltimore, Maryland, USA, 22 June 2014.c?2014 Association for Computational LinguisticsScalable Large-Margin Structured Learning:Theory and AlgorithmsLiang Huang Kai Zhao Lemao LiuGraduate Center and Queens College, City University of New York{liang.huang.sh, kzhao.hf, lemaoliu}@gmail.com1 MotivationsMuch of NLP tries to map structured input (sen-tences) to some form of structured output (tag se-quences, parse trees, semantic graphs, or trans-lated/paraphrased/compressed sentences).
Thusstructured prediction and its learning algorithmare of central importance to us NLP researchers.However, when applying machine learning tostructured domains, we often face scalability is-sues for two reasons:1.
Even the fastest exact search algorithms formost NLP problems (such as parsing andtranslation) is too slow for repeated use on thetraining data, but approximate search (suchas beam search) unfortunately breaks downthe nice theoretical properties (such as con-vergence) of existing machine learning algo-rithms.2.
Even with inexact search, the scale of thetraining data in NLP still makes pure onlinelearning (such as perceptron and MIRA) tooslow on a single CPU.This tutorial reviews recent advances that ad-dress these two challenges.
In particular, we willcover principled machine learning methods thatare designed to work under vastly inexact search,and parallelization algorithms that speed up learn-ing on multiple CPUs.
We will also extend struc-tured learning to the latent variable setting, wherein many NLP applications such as translation andsemantic parsing the gold-standard derivation ishidden.2 Contents1.
Overview of Structured Learning(a) key challenge 1: search efficiency(b) key challenge 2: interactions betweensearch and learning2.
Structured Perceptron(a) the basic algorithm(b) the geometry of convergence proof(c) voted and averaged perceptrons, and ef-ficient implementation tricks(d) applications in tagging, parsing, etc.3.
Structured Perceptron under Inexact Search(a) convergence theory breaks under inex-act search(b) early update(c) violation-fixing perceptron(d) applications in tagging, parsing, etc.
?coffee break?4.
From Perceptron to MIRA(a) 1-best MIRA; geometric solution(b) k-best MIRA; hildreth algorithm(c) MIRA with all constraints; loss-augmented decoding(d) MIRA under inexact search5.
Large-Margin Structured Learning with La-tent Variables(a) examples: machine translation, seman-tic parsing, transliteration(b) separability condition and convergenceproof(c) latent-variable perceptron under inexactsearch(d) applications in machine translation6.
Parallelizing Large-Margin StructuredLearning(a) iterative parameter mixing (IPM)(b) minibatch perceptron and MIRA43 Instructor BiographiesLiang Huang is an Assistant Professor at the CityUniversity of New York (CUNY).
He receivedhis Ph.D. in 2008 from Penn and has workedas a Research Scientist at Google and a Re-search Assistant Professor at USC/ISI.
His workis mainly on the theoretical aspects (algorithmsand formalisms) of computational linguistics, aswell as theory and algorithms of structured learn-ing.
He has received a Best Paper Award at ACL2008, several best paper nominations (ACL 2007,EMNLP 2008, and ACL 2010), two Google Fac-ulty Research Awards (2010 and 2013), and a Uni-versity Graduate Teaching Prize at Penn (2005).He has given two tutorials at COLING 2008 andNAACL 2009, being the most popular tutorial atboth venues.Kai Zhao is a Ph.D. candidate at the City Univer-sity of New York (CUNY), working with LiangHuang.
He received his B.S.
from the Univer-sity of Science and Technology in China (USTC).He has published on structured prediction, onlinelearning, machine translation, and parsing algo-rithms.
He was a summer intern with IBM TJWat-son Research Center in 2013.Lemao Liu is a postdoctoral research associate atthe City University of New York (CUNY), work-ing with Liang Huang.
He received his Ph.D. fromthe Harbin Institute of Technology in 2013.
Muchof his Ph.D. work was done while visiting NICT,Japan, under Taro Watanabe.
His research area ismachine translation and machine learning.5
