SESSION 6: DEMONSTRATIONS AND VIDEOTAPES OFSPEECH AND NATURAL LANGUAGE TECHNOLOGIESMari OstendorfBoston UniversityECS Department44 Cummington StreetBoston, MA 02215In this session, several sites presented videos or demos toillustrate research progress and demonstrate operation of theirspoken language system.
Since papers were optional for thissession, the proceedings do not completely reflect theaccomplishments that were reviewed in this session.Richard Lyon, from Apple, showed a video imaging speechthrough a correlogram: a signal representation based on acochlear model.
Though the video is based on simulations on aCray, the algorithm is currently being implemented in analogVLSI for real-time signal processing.
The associated paper inthis proceedings describes the VLSI circuit implementation.Harvey Silverman, from Brown, showed a video illustratingsignal and noise separation using microphone arrays.
Suchalgorithms can improve speech recognition performance innoisy environments and free the user from the close-talkingmicrophone.
Not surprisingly, algorithm performance in arealistic environment with reverberation noise is not as goodas the theory predicts, and much research remains in this area.Paul Bamberg of Dragon Systems demonstrated theirconnected word recognition system in two domains: radiologyand Resource Management.
The system runs on a PC with aspecial purpose signal processing board and was trained on adatabase which includes peech from very diverse sources.Pat Peterson from BBN showed a video illustrating: 1) theirreal-time spoken language system HARC which uses Byblos,the speech recognition system, to provide the top N sentencehypotheses for natural language processing; 2) dialectnormalization through speaker adaptation which results indramatic recognition performance improvements for non-native English speakers and native speakers with strongaccents; and 3) demonstrating how integration of HARC intothe BBN DART (Dynamic Analytical Replanning Tool) projectcan allow faster user access to information than through amouse alone.
A paper in this proceedings describes the use ofspoken language in the DART system.Miteh Weintraub of SRI International demonstrated his noiserobust signal processing algorithm in a digit recognition task.He was able to switch between three different microphones - aclose-talking rnic, a hand-held mie and a table-top rnic - with noloss in recognition performance.
Patti Price and JohnButzberger demonstrated the SRI ATIS system.
The system usesa PC with a DSP board for signal processing, a Spare station forHMM speech recognition with includes a bigram Markovlanguage model, and a second Spare station for natural languageprocessing using the template matching rammar.
The systemused in this demo runs in real time using a perplexity 10grammar; the benchmark system has a higher perplexity with a1-2 minute response time.Victor Zue and Stephanie Seneff demonstrated the M1T ATISsystem as used for data collection, specifically operating thesystem in the flight booking mode.
The system involvescooperative computer/human i teraction working toward thegoal of filling out information in a ticket in data collectionmode.
They pointed out that we do not yet know how to collectspontaneous speech data and that we should experiment withdifferent procedures.
A paper describing their data collectionprocedure and analysis of different ATIS corpora appears in theproceedings.Alex Rudnieky showed a video illustrating the CMU OfficeManagement spoken language system, based on the Sphinxrecognition system and a frame-based parser.
The system usesmulti-modal input (mouse, text, and different modes of voiceinput) to control various tools including a personalinformation database, voice mall, an appointment calendar anda calculator.
The goal of working with this task domain is tostudy a large user population and a complete human/machineinterface.
CMU considers task completion time is an importantmeasure of system performance.Ralph Weischedel, from BBN, showed a video produced toillustrate the DARPA Program on Natural Language Processingwhich is aimed at developing technology for enablingmachines to process text intelligently.
Because of thetremendous growth in volume of data, the ability toautomatically extract and process relevant information inmessages is becoming an important echnology.
Naturallanguage processing offers the potential for automatic databaseupdate, query and retrieval, and message routing, prioritization,fusion and alerts.
The video showed that, although today'snatural anguage systems are limited to constrained omains,they are quite successful within those constraints.Papers were optional in this session, due to the difficulties intranslation from the different media.211
