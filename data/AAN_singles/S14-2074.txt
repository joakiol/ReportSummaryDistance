Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 428?432,Dublin, Ireland, August 23-24, 2014.NILC USP: An Improved Hybrid System for Sentiment Analysis inTwitter MessagesPedro P. Balage Filho, Lucas Avanc?o, Thiago A. S. Pardo, Maria G. V. NunesInterinstitutional Center for Computational Linguistics (NILC)Institute of Mathematical and Computer Sciences, University of S?ao PauloS?ao Carlos - SP, Brazil{balage, taspardo, gracan}@icmc.usp.br avanco@usp.brAbstractThis paper describes the NILC USP sys-tem that participated in SemEval-2014Task 9: Sentiment Analysis in Twitter, are-run of the SemEval 2013 task under thesame name.
Our system is an improvedversion of the system that participated inthe 2013 task.
This system adopts a hybridclassification process that uses three clas-sification approaches: rule-based, lexicon-based and machine learning.
We sug-gest a pipeline architecture that extractsthe best characteristics from each classi-fier.
In this work, we want to verify howthis hybrid approach would improve withbetter classifiers.
The improved systemachieved an F-score of 65.39% in the Twit-ter message-level subtask for 2013 dataset(+ 9.08% of improvement) and 63.94% for2014 dataset.1 IntroductionTwitter is an important platform of social com-munication.
The analysis of the Twitter messages(tweets) offers a new possibility to understand so-cial behavior.
Understanding the sentiment con-tained in such messages showed to be very impor-tant to understand user behavior and also to as-sist market analysis (Java et al., 2007; Kwak et al.,2010).Sentiment analysis, the area in charge of study-ing how sentiments and opinions are expressed intexts, is usually associated with text classificationThis work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/tasks.
Sentiment classifiers are commonly cate-gorized in two basic approaches: lexicon-basedand machine learning approaches (Taboada et al.,2011).
A lexicon-based classifier uses a lexiconto provide the polarity, or semantic orientation, ofeach word or phrase in the text.
A machine learn-ing classifier uses features (usually the vocabularyin the texts) obtained from labeled examples toclassify the texts according to their polarity.In this paper, we present a hybrid system forsentiment classification in Twitter messages.
Oursystem combines the lexicon-based and machinelearning approaches, as well as uses simple rulesto aid in the process.
Our system participated inSemEval-2014 Task 9: Sentiment Analysis in Twit-ter (Rosenthal et al., 2014), a re-run for the Se-mEval 2013 task under the same name (Nakov etal., 2013).
The task goal was to determine the sen-timent contained in tweets.
The task included twosub-tasks: a expression-level classification (TaskA) and a message-level classification (Task B).Our system participated only in Task B, where, fora given message, it should classify it as positive,negative, or neutral.The system presented is an improved version ofthe system submitted for Semeval 2013.
Our pre-vious system had demonstrated that a hybrid ap-proach could achieve good results (F-measure of56.31%), even if we did not use the state-of-the-art algorithms for each approach (Balage Filho andPardo, 2013).
In this way, this work aims to ver-ify how much this hybrid system could improve inrelation to the previous one by including modifica-tions on both lexicon-based and machine learningapproaches.4282 Related workThe analysis of Tweets has gained lots of interestrecently.
One evidence is the expressive numberof participants in the SemEval-2013 Task 2: Sen-timent Analysis in Twitter (Nakov et al., 2013).There were a total of 149 submissions from 44teams.
The best performing system on twitterdataset for task B was reported by Mohammad etal.
(2013) with an F-mesaure of 69.02%.
Theirsystem used a machine learning approach and avery rich feature set.
They showed that the bestresults were achieved using a built-in positive andnegative lexicon and a bag-of-words as features.Other important system in Semeval 2013 wasreported by Malandrakis et al.
(2013).
The authorspresented a hybrid system for twitter sentimentanalysis combining two approaches: a hierarchi-cal model based on an affective lexicon and a lan-guage modeling approach.
The system achievedan F-mesaure of 60.14%.Most work in sentiment analysis uses either ma-chine learning or lexicon-based techniques.
How-ever, few studies have shown promising resultswith the hybrid approach.
K?onig and Brill (2006)proposed a hybrid classifier that uses human rea-soning over automatically discovered text patternsto complement machine learning.
Prabowo andThelwall (2009) evaluated the effectiveness of dif-ferent classifiers.
Their study showed that the useof multiple classifiers in a hybrid manner couldimprove the effectiveness of sentiment analysis.3 System ArchitectureOur system is described as a pipeline solution offour main processes: normalization, rule-basedclassification, lexicon-based classification and ma-chine learning classification.
This is the same ar-chitecture presented by our system in 2013.This pipeline architecture works as a back-offmodel.
In this model, each classifier tries to clas-sify the tweets by using the underlying approach.If a certain degree of confidence is achieved, theclassifier will provide the final sentiment class forthe message.
Otherwise, the next classifier willcontinue the classification task.
The last possibil-ity is the machine learning classifier, responsibleto deliver the class when the previous two couldnot achieve the confidence level.
We decided touse this back-off model instead of a voting system,for example, due to the high precision achieved forthe rule-based and the lexicon-based classifiers.The aim of this pipeline architecture is to im-prove the classification process.
In Balage Filhoand Pardo (2013), we have shown that this hybridclassification approach may outperform the indi-vidual approaches.In the following subsections, we detail the com-ponents of our system.
In the next section, we ex-plain how the confidence level was determined.3.1 Normalization and Rule-based ClassifierThe normalization module is responsible for nor-malizing and tagging the texts.
This module per-forms the following operations:?
Hashtags, urls and mentions are transformedinto codes;?
Emoticons are grouped into representativecategories (such as ?happy?, ?sad?, ?laugh?
)and are converted to particular codes;?
Part-of-speech tagging is performed by usingthe Ark-twitter NLP (Owoputi et al., 2013)The rule-based classifier is designed to providerules that better impact the precision than the re-call.
In our 2014 system, we decided to use thesame rule-based classifier from the 2013 system.The rules in this classifier only verify the pres-ence of emoticons in the text.
Empirically, weevidenced that the use of emoticons indicates theactual polarity of the message.
In this module,we consider the number of positive and negativeemoticons found in the text to determine its clas-sification.3.2 Lexicon-based ClassifierThe lexicon-based classifier is based on the ideathat the polarity of a text can be given by the sumof the individual polarity values of each word orphrase present in the text.
For this, a sentiment lex-icon identifies polarity words and assigns polarityvalues to them (known as semantic orientations).In the 2013 system, we had used SentiStrengthlexicon (Thelwall et al., 2010).
In 2014, weimproved our lexicon-based classifier by usinga larger sentiment lexicon.
We used the senti-ment lexicon provided by Opinion-Lexicon (Huand Liu, 2004) and a list of sentiment hashtagsprovided by the NRC Hashtag Sentiment Lexicon(Mohammad et al., 2013).
For dealing with nega-tion, we used a handcrafted list of negative words.429In our algorithm, the semantic orientations ofeach individual word in the text are added up.In this approach, the algorithm searches for eachword in the lexicon and only the words that werefound are returned.
We associate the value +1 tothe positive words, and -1 to the negative words.If a polarity word is negated, its value is inverted.This lexicon-based classifier assumes the signal ofthe final score as the sentiment class (positive ornegative) and the score zero as neutral.3.3 Machine Learning ClassifierThe machine learning classifier uses labeled ex-amples to learn how to classify new instances.The features used for this 2014 system were com-pletely changed from 2013 system.
We inspiredour machine learning module in the work reportedby Mohammad et al.
(2013).
The features used bythe classifier are:1. unigrams, bigrams and trigrams2.
the presence of negation3.
the presence of three or more characters inthe words4.
the sequence of three or more punctuationmarks5.
the number of words with all letters in upper-case6.
the total number of each tag present in thetext7.
the number of positive words computed bythe lexicon-based method8.
the number of negative words computed bythe lexicon-based methodWe use a Linear Kernel SVM classifier providedby the python sckit-learn library with C=0.0051.4 Hybrid Approach and TuningThe organization from SemEval-2014 Task 9: Sen-timent Analysis in Twitter provided four datasetsfor the task: a training dataset (TrainSet) with9675 messages directly retrieved from Twitter; adevelopment dataset (DevSet), with 1654 mes-sages; the testing dataset from 2013 run, whichwas not used; and the testing dataset for 20141Available at http://scikit-learn.org/with 8987 messages.
The 2014 testing dataset wascomposed of 5 different sources:?
Twitter2013: Twitter test data from 2013 run?
SMS2013: SMS test data from 2013 run?
Twitter2014: 2000 tweets?
LiveJournal2014: 2000 sentences from Live-Journal blogs?
Twitter2014Sarcasm: 100 tweets that containsarcasmAs we said in the previous section, our system isa pipeline of classifiers where each classifier mayassign a sentiment class if it achieves a particu-lar confidence threshold score.
This confidencescore is a fixed value set for each system in or-der to have a decision boundary.
This decisionwas made by inspecting the results obtained for thedevelopment set.
Tables 1 and 2 shows how therule-based and lexicon-based classifiers performfor the development dataset in terms of score.
Thescore obtained by the rule-based classifier consistsof the difference between the number of positiveemoticons and the number of negative emoticonsfound in the messages.
The score obtained by thelexicon-based classifier represents the total seman-tic orientation obtained by the algorithm by addingup the semantic orientation for their lexicon.Inspecting Table 1, for the best threshold, weadjusted the rule-based classifier boundary to de-cide when the score is different from zero.
Forvalues greater than zero, the classifier will assignthe positive class and, for values below zero, theclassifier will assign the negative class.
For valuesequal to zero, the classifier will call the lexicon-based classifier.Table 1: Correlation between the rule-based clas-sifier scores and the gold standard classes in theDevSetRule-based Gold Standard Classclassifier score Negative Neutral Positive-1 22 3 30 311 709 4951 7 26 732 0 0 23 to 6 0 1 2Inspecting Table 2, for the best threshold, weadjusted the lexicon-based classifier to assign the430positive class when the total score is greater than1 and negative class when the total score is below-2.
For any other values, the classifier will call themachine learning classifier.Table 2: Correlation between the lexicon-basedclassifier score and the gold standard classes in thedevsetLexicon-based Gold Standard Classclassifier scores Negative Neutral Positive-7 to -4 2 0 0-3 10 4 0-2 48 18 7-1 111 99 350 108 432 1781 48 143 2102 11 39 1043 to 5 3 4 47As the machine learning classifier is responsiblefor the final stage, we did not have to decide anythreshold for this classifier.
However, we empiri-cally identified a bias toward the positive class (thenegative class was barely chosen).
In order to cor-rect this problem, we setup the machine learningclassifier to decide for the negative class wheneverthe SVM score for this class is bigger than -0.4.Next section shows the results achieved for the Se-meval test dataset.5 ResultsTable 3 shows the results obtained by each individ-ual classifier and by the hybrid classifier for theTwitter2014 messages in the testset.
In the task,the systems were evaluated with the average F-score obtained for positive and negative classes.Table 3: Average F-score (positive and negative)obtained by each classifier and the hybrid ap-proach for the Twitter2014 testsetClassifier Twitter2014 TestsetRule-based 14.03Lexicon-Based 47.55Machine Learning 63.36Hybrid Approach 63.94Table 4 shows the improvement of the systemover the 2013 run.
Unlike last year, we notice thatthe performance of this hybrid system is very closeto the performance of the machine-learning.Table 4: Comparison of the average F-score (pos-itive and negative) obtained by each classifier andthe hybrid approach for the Twitter2013 testset for2013 and 2014 versionsClassifier 2013 system 2014 systemRule-based 14.37 13.31Lexicon-Based 44.87 46.80Machine Learning 49.99 63.75Hybrid Approach 56.31 65.39Table 5 shows the scores for each source in thetestset.
Last column shows our system rank amongthe 50 systems that participated in the competition.For the entire testing dataset, our algorithm had503 (5%) examples classified by the rule-basedclassifier, 3204 (36%) by the lexicon-based classi-fier and 5280 (59%) by the machine learning clas-sifier.6 ConclusionWe described our improved hybrid classificationsystem used for Semeval-2014 Task 9: SentimentAnalysis in Twitter.
This work showed that thishybrid classifier can be improved as its modulesare too.
However, we noticed that, improving thelexicon and machine learning modules, the overallscore tends towards the machine learning score.The source code produced for the experiment isavailable at https://github.com/pedrobalage.AcknowledgmentsWe would like to thank the organizers for theirwork in constructing the dataset and in the over-seeing of the task.
We also would like tothank FAPESP and SAMSUNG for supportingthis work.ReferencesPedro Balage Filho and Thiago Pardo.
2013.NILC USP: A Hybrid System for Sentiment Analy-sis in Twitter Messages.
In Second Joint Conferenceon Lexical and Computational Semantics (*SEM),Volume 2: Proceedings of the Seventh InternationalWorkshop on Semantic Evaluation (SemEval 2013),pages 568?572, Atlanta, Georgia, USA, June.
Asso-ciation for Computational Linguistics.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the TenthACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, KDD ?04, pages168?177, New York, NY, USA.
ACM.431Table 5: Results for Twitter TestSetTestSet Source Majority Baseline Our Score Best Result Our RankTwitter2013 29.2 65.39 72.12 15thSMS2013 19.0 61.35 70.28 16thTwitter2014 34.6 63.94 70.96 19thLiveJournal2014 27.2 69.02 74.84 18thTwitter2014Sarcasm 27.7 42.06 58.16 34thAkshay Java, Xiaodan Song, Tim Finin, and BelleTseng.
2007.
Why we twitter: understanding mi-croblogging usage and communities.
In Proceed-ings of the 9th WebKDD and 1st SNA-KDD 2007workshop on Web mining and social network anal-ysis, WebKDD/SNA-KDD ?07, pages 56?65, NewYork, NY, USA.
ACM.Arnd Christian K?onig and Eric Brill.
2006.
Reducingthe human overhead in text categorization.
In Pro-ceedings of the 12th ACM SIGKDD internationalconference on Knowledge discovery and data min-ing, KDD ?06, pages 598?603, New York, NY, USA.ACM.Haewoon Kwak, Changhyun Lee, Hosung Park, andSue Moon.
2010.
What is twitter, a social networkor a news media?
In Proceedings of the 19th inter-national conference on World wide web, WWW ?10,pages 591?600, New York, NY, USA.
ACM.Nikolaos Malandrakis, Abe Kazemzadeh, Alexan-dros Potamianos, and Shrikanth Narayanan.
2013.SAIL: A hybrid approach to sentiment analysis.
InSecond Joint Conference on Lexical and Computa-tional Semantics (*SEM), Volume 2: Proceedingsof the Seventh International Workshop on Seman-tic Evaluation (SemEval 2013), pages 438?442, At-lanta, Georgia, USA, June.
Association for Compu-tational Linguistics.Saif Mohammad, Svetlana Kiritchenko, and XiaodanZhu.
2013.
NRC-Canada: Building the State-of-the-Art in Sentiment Analysis of Tweets.
In SecondJoint Conference on Lexical and Computational Se-mantics (*SEM), Volume 2: Proceedings of the Sev-enth International Workshop on Semantic Evalua-tion (SemEval 2013), pages 321?327, Atlanta, Geor-gia, USA, June.
Association for Computational Lin-guistics.Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,Veselin Stoyanov, Alan Ritter, and Theresa Wilson.2013.
Semeval-2013 task 2: Sentiment analysis intwitter.
In Second Joint Conference on Lexical andComputational Semantics (*SEM), Volume 2: Pro-ceedings of the Seventh International Workshop onSemantic Evaluation (SemEval 2013), pages 312?320, Atlanta, Georgia, USA, June.
Association forComputational Linguistics.Olutobi Owoputi, Brendan O?Connor, Chris Dyer,Kevin Gimpel, Nathan Schneider, and Noah A.Smith.
2013.
Improved part-of-speech tagging foronline conversational text with word clusters.
InProceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 380?390, Atlanta, Georgia, June.
Associationfor Computational Linguistics.Rudy Prabowo and Mike Thelwall.
2009.
Sentimentanalysis: A combined approach.
Journal of Infor-metrics, 3(2):143?157.Sara Rosenthal, Preslav Nakov, Alan Ritter, andVeselin Stoyanov.
2014.
SemEval-2014 Task 9:Sentiment Analysis in Twitter.
In Preslav Nakov andTorsten Zesch, editors, Proceedings of the 8th In-ternational Workshop on Semantic Evaluation, Se-mEval ?14, Dublin, Ireland.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-Based Methods for Sentiment Analysis.
Computa-tional Linguistics, 37(2):267?307, June.Mike Thelwall, Kevan Buckley, Georgios Paltoglou,Di Cai, and Arvid Kappas.
2010.
Sentiment inshort strength detection informal text.
Journal of theAmerican Society for Information Science and Tech-nology, 61(12):2544?2558, December.432
