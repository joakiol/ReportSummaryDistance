Directions For Multi-Party Human-Computer Interaction ResearchKatrin KirchhoffDepartment of Electrical EngineeringUniversity of Washington, Seattlekatrin@ee.washington.eduMari OstendorfDepartment of Electrical EngineeringUniversity of Washington, Seattlemo@ee.washington.eduAbstractResearch on dialog systems has so far concen-trated on interactions between a single user anda machine.
In this paper we identify novel re-search directions arising from multi-party hu-man computer interaction, i.e.
scenarios whereseveral human participants interact with a dia-log system.1 IntroductionMost current work on spoken human-computer interac-tion (HCI) involves dialog systems.
In recent years, spo-ken dialog systems with system initiative have becomemore commonplace in commercial telephony applica-tions, and there have been important advances in mixedinitiative and multi-modal research systems.
Telephone-based systems have made it possible to collect largeamounts of human-computer interaction data, which hasbenefited empirical research as well as methods based onautomatic training.
In addition, evaluation frameworkshave improved beyond the single utterance accuracy mea-sures used a decade ago to dialog-level subjective andquantitative measures (Walker et al, 1998).As dialog systems have advanced, a new area of re-search has also been developing in automatic recog-nition and analysis of multi-party human-human spo-ken interactions, such as meetings, talk shows, court-room proceedings, and industrial settings (Cohen et al,2002).
Multi-party interactions pose challenges forspeech recognition and speaker tracking because of fre-quent talker overlap (Shriberg et al, 2001), noise androom reverberation, but they also introduce new chal-lenges for discourse modeling.
Until recently, empiricalresearch was only possible using single-speaker and di-alog corpora, but now there are many hours of data be-ing collected in multi-talker environments (Morgan et al2001; Schultz et al 2001).While many challenges remain in dialog systems ?from error handling and user modeling to response gen-eration ?
technology has advanced to the point whereone can also envision tackling the combined problem ofmulti-party human-computer interaction.
A key motiva-tion for research in such a domain is supporting human-human collaboration.
We envision a scenario where acomputer plays a role as a conversational agent, much asin a dialog system, except that it interacts with multiplecollaborating humans.
The human participants may beat distributed locations, perhaps with small subgroups ateach location, possibly with different platforms for inputand output.
For example, one might imagine a group ofpeople in a facility with high-end computers interactingwith workers in the field with lightweight communicationclients, using the computer assistant to help gather vitalinformation or help plan a transportation route.
A key dif-ference from previous work in such scenarios is the ideaof computer initiative.
The computer as a participant alsosignificantly changes the focus of research relative to thatinvolved in transcription and analysis of meetings, fromwork aimed at indexing and summarization to a focus oninteraction.Besides the application-oriented motivation for re-search on multi-party human-computer interaction, thescenario provides a useful technology pull.
In currentdialog systems, there is a disincentive to explore userinitiative, simply because much better accuracy can beachieved by ?controlling?
the dialog.
However, it wouldbe impractical for a system to try to constrain the in-puts from a group of users.
Secondly, current dialog sys-tems generally assume a fixed platform, and hence the re-sponse generation can be greatly simplified.
With varyingplatforms and participants with different needs, a morecomplex output rendering strategy will be needed, whichwill also have implications for future dialog systems aswell.
In the follow section, we expand on these issuesand many more research questions that arise in the con-text of multi-party HCI research.2 RESEARCH ISSUESSome of the most intensively pursued research questionsin single-party human-computer interaction are the fol-lowing: initiative strategies (human vs. system vs. mixedinitiative); dialog planning, in particular the possibilityof learning probabilistic dialog models from data; han-dling recognition/understanding errors and other systemfailures or miscommunications; user modeling, i.e.
find-ing models of interaction patterns specific to certainusers in order to adapt the dialog system; and multi-modal input/output strategies.
A multi-party scenario ex-tends these questions in various interesting ways but alsopresents entirely new challenges, such as described be-low.Initiative.
It needs to be asked how human-humancommunication affects interaction with an automatic di-alog system on the one hand, and how the presence ofthe system influences communication among the humanparticipants on the other.
Specifically, how is the fre-quency and type of each user?s interaction with the sys-tem determined?
Does every user address the system ona ?first come, first speak?
basis, do users take turns, or dothey first communicate among themselves and then inter-act with the system via a designated ?proxy?
speaker?How do these different interaction protocols affect theoutcome?
For instance, communicative goals might beachieved more frequently and more rapidly when the pro-tocol is fixed in advance but users might be more satisfiedwith a less structured interaction.Two other questions are closely tied to the issue of in-teraction and initiative protocols: (a) should the systembe an open-mike dialog system, i.e.
able to record ev-erything at all times, though responding only to specificevents?
and (b) are users in the same physical locationor are they distributed (e.g.
in videoconferencing)?
In thecase of an open-mike system, special provisions need tobe made to distinguish between utterances addressed tothe dialog system and utterances that are exclusively partof the human-human interaction.
This additional chal-lenge is offset by the possibility of gathering useful back-ground information from the participants?
conversationthat might enable the system to better respond to queries.Dialog Modeling.
Distributed scenarios, where differ-ent subgroups of participants are separated from eachother physically, will typically lead to parallel subdialogsevolving in the course of the interaction.
In this casethe system needs to be able to track several subdialogssimultaneously and to relate them to each other.
Thepossibility of having multiple concurrent subdialogs di-rectly affects the dialog planning component.
Differentuser queries and dialog states might need to be trackedsimultaneously, and formal models of this type of in-teraction need to be established.
Recently, probabilis-tic models of human-computer dialogs have become in-creasingly popular.
The most commonly used paradigmis that of Markov decision processes and partially observ-able Markov decision processes, where the entire dialogis modelled as a sequence of states and associated actions,each of which has a certain value (or reward) (Singh etal., 1999; Roy et al, 2000).
The goal is to to choose thatsequence of actions which maximizes the overall rewardin response to the user?s query.
States can be thoughtof as representing the underlying intentions of the user.These are typically not entirely transparent but only indi-rectly (or partially) observable through the speech input.Multi-party dialogs might require extensions to this andother modeling frameworks.
For instance, it is unclearwhether multiple parallel subdialogs can be modelled bya single state sequence (i.e.
a single decision process), orwhether multiple, partially independent decision processare required.
The issue of how to acquire data to trainthese models is a further problem, since parallel subdi-alogs tend to occur spontaneously and can often not beelicited in a natural way.Error handling.
The prevention and repair of systemerrors and miscommunications may take on an entirelynew shape in the context of multi-party interactions.First, the notion of what constitutes an error may changesince some participants might interpret a particular sys-tem response as an error whereas others might not.
Sec-ond, the inherent susceptibility of the system to recogni-tion and understanding errors will be higher in a groupthan when interacting with a single user since both thespeech input and the interaction style exhibit greater vari-ation.
Third, error recovery strategies cannot necessarilybe tailored to a single user but need to take into accountthe input from multiple participants, such as the sponta-neous and possibly diverging reactions to a system recog-nition error.
Studies on different reactions to system er-rors (e.g.
building on related studies in single-party HCI(Oviatt et al, 1998)) should be included in a roadmap formulti-party HCI research.User Modeling.
User modeling has recently gained in-creased importance in the field of dialog systems re-search, as evidenced by the growing number of dialog-related publications in e.g.
the International Conferenceon User Modeling, and the User Modeling and Adap-tation journal.
When multiple users are present, severalconcurrent user models need to be established, unless in-teraction is restricted to a proxy scenario as describedabove.
Here, too, the question is not only what individualmodels should look like, but also how they can be learnedfrom data.
Group interactions are typically dominated bya small number of active speakers, whereas the remainingparticipants provide fewer contributions, such that multi-party data collections tend to be rather unbalanced withrespect to the amount of data per speaker.
Furthermore,individual users might behave differently in different sce-narios, depending e.g.
on other participants in the group.Flexible ?Multi?
Input/Output.
Research on multi-modal input/output for language-based dialog systems isa relatively new field, though many contributions havebeen made in recent years.
Many developments will im-pact both dialog and multi-party systems, but introducingthe multi-party dimension brings further challenges.
Forexample, the problem of coordinating speech and gesturefrom one person is complicated by increasing the numberof people, making the problem of speaker tracking impor-tant.
For speech input, there are questions of whether touse an open-mike system, as mentioned earlier, but theremay also be different requirements for participants withdistributed platforms/locations (e.g.
noisy environmentsmay require push-to-talk).
One could envision haptic de-vices controlled simultaneously be multiple users.
On theoutput side, there is a problem of incorporating backchan-nels and visual evidence of attentiveness (equivalent tohead nods), as well as turn-taking and interruption cuesfor coordinating with other human speech.
Coordina-tion of different output modalities faces an added chal-lenge when some platforms/environments preclude useof all modalities.
Considering language alone, the re-sponse generator must provide alternatives depending onwhether voice output is available and on display size (i.e.how much text and/or visual aids can be included).
Userand context modeling should also impact response gener-ation.3 INFRASTRUCTUREIn order to study the research questions addressed abovewe need appropriate resources.
Currently, no publiclyavailable corpus of multi-party human-machine interac-tions exists.
Several corpora of human-human communi-cation are available and may be used to study phenomenasuch as negotiation of turn-taking but are clearly not suf-ficient to support work on multi-party HCI.Data collection mechanism.
It would be desirableto collect several corpora of multi-party human-machine communication, representing different scenar-ios, e.g.
corporate meetings, remote collaboration of sci-entific teams, or, remaining closer to existing scenarios,collaborative travel planning of business partners.
Careshould be taken to collect data from groups of varioussizes, co-located as well as distributed teams, technolog-ically experienced vs. inexperienced users, different in-put modalities, and teams working on a variety of dif-ferent tasks.
Ideally, data collection should be coordi-nated across different sites with complementary exper-tise.
Data collections should be made available publicly,e.g.
through LDC.
Existing multi-party recording facili-ties (such as instrumented meeting rooms) could be lever-aged for this effort.New Evaluation Paradigms.
One of the most impor-tant research questions is how to evaluate the success ofmulti-party HCI.
Can we build on existing frameworksfor single-person dialogs?
For example, can we extendthe Paradise framework (Walker et al, 1998) by introduc-ing new quantitative measures (such as speaker trackingerror, computer interruption rate) and designing groupquestionnaires or averaging responses to individual ques-tionnaires?
As in dialog system research, component-level evaluations will continue to be a key driver of re-search progress, but a multi-party system would likelyinclude new components relative to a dialog system.
Forexample, a natural task for the computer might be infor-mation retrieval (IR), in which case there measures fromthe IR community would be relevant.
Additionally, wecan incorporate insights from more general (i.e.
not nec-essarily speech-specific) evaluation frameworks for col-laborative systems (Drury et al 1999; Damianos et al2000), which take into account factors such as group size,social interaction parameters, and collaborative tasks.Multi-party HCI represents a substantial step beyondcurrent research, but it is an important challenge that willdrive new ideas in many areas.
Since multi-party HCI isfundamentally about collaboration, it is an ideal problemfor fostering the type of multi-site and multi-disciplineinteractions that will advance human communicationReferencesP.R.
Cohen, R. Coulston, and K. Krout.
2002.
Multiparty mul-timodal interaction: A preliminary analysis.
In Proc.
of IC-SLP, pages 201?204.L.
Damianos et al 2000.
Evaluating multi-party multi-modalsystems.
Technical paper, The MITRE Corporation.J.
Drury et al 1999.
Methodology for evaluation of collabora-tive systems, v.4.0.
http://www.nist.gov/nist-icv.N.
Morgan et al 2001.
The meeting project at ICSI.
In Proc.of HLT, pages 246?252.S.
Oviatt, G.A.
Levow, E. Moreton, and M. MacEachern.
1998.Modeling global and focal hyperarticulation during human-computer error resolution.
JASA, 104(5).N.
Roy, J. Pineau, and S. Thrun.
2000.
Spoken dialogue man-agement using probabilistic reasoning.
In Proc.
of ACL.T.
Schultz et al 2001.
The ISL meeting room system.In Proc.
Workshop on Hands-Free Speech Communication(HSC-2001), Kyoto Japan.E.
Shriberg, A. Stolcke, and D. Baron.
2001.
Observations onoverlap: Findings and implications for automatic processingof multi-party conversation.
In Proc.
EUROSPEECH, pages1359?1362.S.
Singh, M. Kearns, D. Litman, and M. Walker.
1999.
Rein-forcement learning for spoken dialog systems.
In Advancesin Neural Processing Systems, volume 12.M.
Walker et al 1998.
Evaluating spoken dialogue agents withPARADISE: Two case studies.
Computer Speech and Lan-guage, 12(3):317?348.
