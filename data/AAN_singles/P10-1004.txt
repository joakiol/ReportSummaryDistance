Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 30?39,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsComputing weakest readingsAlexander KollerCluster of ExcellenceSaarland Universitykoller@mmci.uni-saarland.deStefan ThaterDept.
of Computational LinguisticsSaarland Universitystth@coli.uni-saarland.deAbstractWe present an efficient algorithm for com-puting the weakest readings of semanticallyambiguous sentences.
A corpus-based eval-uation with a large-scale grammar showsthat our algorithm reduces over 80% of sen-tences to one or two readings, in negligibleruntime, and thus makes it possible to workwith semantic representations derived bydeep large-scale grammars.1 IntroductionOver the past few years, there has been consid-erable progress in the ability of manually createdlarge-scale grammars, such as the English ResourceGrammar (ERG, Copestake and Flickinger (2000))or the ParGram grammars (Butt et al, 2002), toparse wide-coverage text and assign it deep seman-tic representations.
While applications should ben-efit from these very precise semantic representa-tions, their usefulness is limited by the presenceof semantic ambiguity: On the Rondane Treebank(Oepen et al, 2002), the ERG computes an aver-age of several million semantic representations foreach sentence, even when the syntactic analysis isfixed.
The problem of appropriately selecting oneof them to work with would ideally be solved bystatistical methods (Higgins and Sadock, 2003) orknowledge-based inferences.
However, no suchapproach has been worked out in sufficient detail tosupport the disambiguation of treebank sentences.As an alternative, Bos (2008) proposes to com-pute the weakest reading of each sentence and thenuse it instead of the ?true?
reading of the sentence.This is based on the observation that the readingsof a semantically ambiguous sentence are partiallyordered with respect to logical entailment, and theweakest readings ?
the minimal (least informative)readings with respect to this order ?
only express?safe?
information that is common to all other read-ings as well.
However, when a sentence has mil-lions of readings, finding the weakest reading is ahard problem.
It is of course completely infeasibleto compute all readings and compare all pairs forentailment; but even the best known algorithm inthe literature (Gabsdil and Striegnitz, 1999) is onlyan optimization of this basic strategy, and wouldtake months to compute the weakest readings forthe sentences in the Rondane Treebank.In this paper, we propose a new, efficient ap-proach to the problem of computing weakest read-ings.
We follow an underspecification approachto managing ambiguity: Rather than deriving allsemantic representations from the syntactic analy-sis, we work with a single, compact underspecifiedsemantic representation, from which the semanticrepresentations can then be extracted by need.
Wethen approximate entailment with a rewrite sys-tem that rewrites readings into logically weakerreadings; the weakest readings are exactly thosereadings that cannot be rewritten into some otherreading any more (the relative normal forms).
Wepresent an algorithm that computes the relative nor-mal forms, and evaluate it on the underspecified de-scriptions that the ERG derives on a 624-sentencesubcorpus of the Rondane Treebank.
While themean number of scope readings in the subcorpusis in the millions, our system computes on average4.5 weakest readings for each sentence, in less thantwenty milliseconds; over 80% of all sentences arereduced to at most two weakest readings.
In otherwords, we make it feasible for the first time to buildan application that uses the individual (weakest)semantic representations computed by the ERG,both in terms of the remaining ambiguity and interms of performance.
Our technique is not lim-ited to the ERG, but should be applicable to otherunderspecification-based grammars as well.Technically, we use underspecified descriptionsthat are regular tree grammars derived from dom-inance graphs (Althaus et al, 2003; Koller et al,302008).
We compute the weakest readings by in-tersecting these grammars with other grammarsrepresenting the rewrite rules.
This approach canbe used much more generally than just for the com-putation of weakest readings; we illustrate this byshowing how a more general version of the redun-dancy elimination algorithm by Koller et al (2008)can be seen as a special case of our construction.Thus our system can serve as a general frameworkfor removing unintended readings from an under-specified representation.The paper is structured as follows.
Section 2starts by reviewing related work.
We recall domi-nance graphs, regular tree grammars, and the basicideas of underspecification in Section 3, before weshow how to compute weakest readings (Section 4)and logical equivalences (Section 5).
In Section 6,we define a weakening rewrite system for the ERGand evaluate it on the Rondane Treebank.
Section 7concludes and points to future work.2 Related workThe idea of deriving a single approximative seman-tic representation for ambiguous sentences goesback to Hobbs (1983); however, Hobbs only workshis algorithm out for a restricted class of quantifiers,and his representations can be weaker than ourweakest readings.
Rules that weaken one readinginto another were popular in the 1990s underspeci-fication literature (Reyle, 1995; Monz and de Rijke,2001; van Deemter, 1996) because they simplifylogical reasoning with underspecified representa-tions.
From a linguistic perspective, Kempson andCormack (1981) even go so far as to claim thatthe weakest reading should be taken as the ?basic?reading of a sentence, and the other readings onlyseen as pragmatically licensed special cases.The work presented here is related to other ap-proaches that reduce the set of readings of an un-derspecified semantic representation (USR).
Kollerand Niehren (2000) showed how to strengthena dominance constraint using information aboutanaphoric accessibility; later, Koller et al (2008)presented and evaluated an algorithm for redun-dancy elimination, which removes readings froman USR based on logical equivalence.
Our systemgeneralizes the latter approach and applies it to anew inference problem (weakest readings) whichthey could not solve.This paper builds closely upon Koller and Thater(2010), which lays the formal groundwork for the?xsampleyseex,y?yrepr-ofx,z?zcompz24 35 6 78?1Figure 1: A dominance graph describing the fivereadings of the sentence ?it is not the case thatevery representative of a company saw a sample.
?work presented here.
Here we go beyond that paperby applying a concrete implementation of our RTGconstruction for weakest readings to a real-worldgrammar, evaluating the system on practical inputs,and combining weakest readings with redundancyelimination.3 UnderspecificationThis section briefly reviews two formalisms forspecifying sets of trees: dominance graphs andregular tree grammars.
Both of these formalismscan be used to model scope ambiguities compactlyby regarding the semantic representations of a sen-tence as trees.
Some example trees are shown inFig.
2.
These trees can be read as simplified for-mulas of predicate logic, or as formulas involv-ing generalized quantifiers (Barwise and Cooper,1981).
Formally, we assume a ranked signature?
of tree constructors { f ,g,a, .
.
.
}, each of whichis equipped with an arity ar( f ) ?
0.
We take a(finite constructor) tree t as a finite tree in whicheach node is labelled with a symbol of ?, and thenumber of children of the node is exactly the arityof this symbol.
For instance, the signature of thetrees in Fig.
1 is {?x|2,?y|2,compz|0, .
.
.}.
Finiteconstructor trees can be seen as ground terms over?
that respect the arities.
We write T (?)
for thefinite constructor trees over ?.3.1 Dominance graphsA (labelled) dominance graph D (Althaus et al,2003) is a directed graph that consists of a col-lection of trees called fragments, plus dominanceedges relating nodes in different fragments.
We dis-tinguish the roots WD of the fragments from theirholes, which are the unlabelled leaves.
We writeLD : WD?
?
for the labeling function of D.The basic idea behind using dominance graphsto model scope underspecification is to specify31(a) (b)?y?xrepr-ofx,zcompzsampleyseex,y?repr-ofx,zcompzseex,ysampley?z?
?y?x?z[+][-][-] [-][-] [-][-][-][+][+][-][-][-][+][+] [+](c)compzrepr-ofx,zseex,ysampley??y?x?z[+][-][-][-][-][-][-][+](e)sampleyseex,yrepr-ofx,zcompz??y?x?z[+][-][+][-][-][-][+][+](d)compzrepr-ofx,zseex,ysampley?
?y?x?z[+][-][-][-][-][-][-][+]Figure 2: The five configurations of the dominance graph in Fig.
1.the ?semantic material?
common to all readingsas fragments, plus dominance relations betweenthese fragments.
An example dominance graphD is shown in Fig.
1.
It represents the five read-ings of the sentence ?it is not the case that everyrepresentative of a company saw a sample.
?Each reading is encoded as a (labeled) configura-tion of the dominance graph, which can be obtainedby ?plugging?
the tree fragments into each other,in a way that respects the dominance edges: Thesource node of each dominance edge must dom-inate (be an ancestor of) the target node in eachconfiguration.
The trees in Fig.
2 are the five la-beled configurations of the example graph.3.2 Regular tree grammarsRegular tree grammars (RTGs) are a general gram-mar formalism for describing languages of trees(Comon et al, 2007).
An RTG is a 4-tuple G =(S,N,?,P), where N and ?
are nonterminal and ter-minal alphabets, S ?
N is the start symbol, andP is a finite set of production rules.
Unlike incontext-free string grammars (which look super-ficially the same), the terminal symbols are treeconstructors from ?.
The production rules are ofthe form A?
t, where A is a nonterminal and t is atree from T (?
?N); nonterminals count as havingarity zero, i.e.
they must label leaves.
A derivationstarts with a tree containing a single node labeledwith S. Then in each step of the derivation, someleaf u which is labelled with a nonterminal A isexpanded with a rule A?
t; this results in a newtree in which u has been replaced by t, and thederivation proceeds with this new tree.
The lan-guage L(G) generated by the grammar is the set ofall trees in T (?)
that can be derived in this way.Fig.
3 shows an RTG as an example.
This gram-mar uses sets of root names from D as nonterminalsymbols, and generates exactly the five configura-tions of the graph in Fig.
1.The languages that can be accepted by regulartree grammars are called regular tree languages{1,2,3,4,5,6,7,8}?
?({2,3,4,5,6,7,8}){2,3,4,5,6,7,8}?
?x({4,5,6},{3,7,8}){2,3,4,5,6,7,8}?
?y({7},{2,4,5,6,8}){2,3,4,5,6,7,8}?
?z({5},{2,3,6,7,8}){2,4,5,6,8}?
?x({4,5,6},{8})| ?z({5},{2,6,8}){2,3,6,7,8}?
?x({6},{3,7,8})| ?y({7},{2,6,8}){2,6,8}?
?x({6},{8}){3,7,8}?
?y({7},{8}){4,5,6}?
?z({5},{6}){5}?
compz {7}?
sampley{6}?
repr-ofx,z {8}?
seex,yFigure 3: A regular tree grammar that generatesthe five trees in Fig.
2.
(RTLs), and regular tree grammars are equivalentto finite tree automata, which are defined essen-tially like the well-known finite string automata,except that they assign states to the nodes in a treerather than the positions in a string.
Regular treelanguages enjoy many of the closure properties ofregular string languages.
In particular, we will laterexploit that RTLs are closed under intersection andcomplement.3.3 Dominance graphs as RTGsAn important class of dominance graphs are hy-pernormally connected (hnc) dominance graphs(Koller et al, 2003).
The precise definition of hncgraphs is not important here, but note that virtuallyall underspecified descriptions that are producedby current grammars are hypernormally connected(Flickinger et al, 2005), and we will restrict our-selves to hnc graphs for the rest of the paper.Every hypernormally connected dominancegraph D can be automatically translated into anequivalent RTG GD that generates exactly the sameconfigurations (Koller et al, 2008); the RTG inFig.
3 is an example.
The nonterminals of GD are32always hnc subgraphs of D. In the worst case, GDcan be exponentially bigger than D, but in practiceit turns out that the grammar size remains manage-able: even the RTG for the most ambiguous sen-tence in the Rondane Treebank, which has about4.5?
1012 scope readings, has only about 75 000rules and can be computed in a few seconds.4 Computing weakest readingsNow we are ready to talk about computing theweakest readings of a hypernormally connecteddominance graph.
We will first explain how we ap-proximate logical weakening with rewrite systems.We will then discuss how weakest readings can becomputed efficiently as the relative normal formsof these rewrite systems.4.1 Weakening rewrite systemsThe different readings of a sentence with a scopeambiguity are not a random collection of formulas;they are partially ordered with respect to logicalentailment, and are structurally related in a waythat allows us to model this entailment relationwith simpler technical means.To illustrate this, consider the five configurationsin Fig.
2.
The formula represented by (d) logicallyentails (c); we say that (c) is a weaker reading than(d) because it is satisfied by more models.
Similarentailment relations hold between (d) and (e), (e)and (b), and so on (see also Fig.
5).
We can definethe weakest readings of the dominance graph asthe minimal elements of the entailment order; inthe example, these are (b) and (c).
Weakest read-ings capture ?safe?
information in that whicheverreading of the sentence the speaker had in mind,any model of this reading also satisfies at least oneweakest reading; in the absence of convincing dis-ambiguation methods, they can therefore serve asa practical approximation of the intended meaningof the sentence.A naive algorithm for computing weakest read-ings would explicitly compute the entailment order,by running a theorem prover on each pair of config-urations, and then pick out the minimal elements.But this algorithm is quadratic in the number ofconfigurations, and therefore impractically slowfor real-life sentences.Here we develop a fast algorithm for this prob-lem.
The fundamental insight we exploit is thatentailment among the configurations of a domi-nance graph can be approximated with rewritingrules (Baader and Nipkow, 1999).
Consider the re-lation between (d) and (c).
We can explain that (d)entails (c) by observing that (c) can be built from(d) by exchanging the positions of the adjacentquantifiers ?x and ?y; more precisely, by applyingthe following rewrite rule:[?]
?x(Q,?y(P,R))?
?y(P,?x(Q,R)) (1)The body of the rule specifies that an occurrence of?x which is the direct parent of an occurrence of ?ymay change positions with it; the subformulas P,Q, and R must be copied appropriately.
The annota-tion [?]
specifies that we must only apply the ruleto subformulas in negative logical polarity: If thequantifiers in (d) were not in the scope of a nega-tion, then applying the rule would actually makethe formula stronger.
We say that the rule (1) islogically sound because applying it to a subformulawith the correct polarity of some configuration talways makes the result t ?
logically weaker than t.We formalize these rewrite systems as follows.We assume a finite annotation alphabet Ann with aspecial starting annotation a0 ?
Ann; in the exam-ple, we had Ann = {+,?}
and a0 = +.
We alsoassume an annotator function ann : Ann???N?Ann.
The function ann can be used to traverse atree top-down and compute the annotation of eachnode from the annotation of its parent: Its firstargument is the annotation and its second argu-ment the node label of the parent, and the thirdargument is the position of the child among the par-ent?s children.
In our example, the annotator annmodels logical polarity by mapping, for instance,ann(+,?z,1)= ann(+,?z,2)= ann(+,?y,2)=+,ann(?,?z,1)= ann(?,?z,2)= ann(+,?x,1)=?,etc.
We have labelled each node of the configura-tions in Fig.
1 with the annotations that are com-puted in this way.Now we can define an annotated rewrite systemR to be a finite set of pairs (a,r) where a is an anno-tation and r is an ordinary rewrite rule.
The rule (1)above is an example of an annotated rewrite rulewith a =?.
A rewrite rule (a,r) can be applied atthe node u of a tree t if ann assigns the annotation ato u and r is applicable at u as usual.
The rule thenrewrites t as described above.
In other words, an-notated rewrite systems are rewrite systems whererule applications are restricted to subtrees with spe-cific annotations.
We write t?R t ?
if some rule ofR can be applied at a node of t, and the result ofrewriting is t ?.
The rewrite system R is called linear33if every variable that occurs on the left-hand sideof a rule occurs on its right-hand side exactly once.4.2 Relative normal formsThe rewrite steps of a sound weakening rewrite sys-tem are related to the entailment order: Because ev-ery rewrite step transforms a reading into a weakerreading, an actual weakest readings must be suchthat there is no other configuration into which itcan be rewritten.
The converse is not always true,i.e.
there can be non-rewritable configurations thatare not weakest readings, but we will see in Sec-tion 6 that this approximation is good enough forpractical use.
So one way to solve the problem ofcomputing weakest readings is to find readings thatcannot be rewritten further.One class of configurations that ?cannot berewritten?
with a rewrite system R is the set of nor-mal forms of R, i.e.
those configurations to whichno rule in R can be applied.
In our example, (b)and (c) are indeed normal forms with respect toa rewrite system that consists only of the rule (1).However, this is not exactly what we need here.Consider a rewrite system that also contains the fol-lowing annotated rewrite rule, which is also soundfor logical entailment:[+] ?(?z(P,Q))??z(P,?
(Q)), (2)This rule would allow us to rewritethe configuration (c) into the tree?z(compz,?
(?y(sampley,?x(repr?ofx,z,seex,y)))).But this is no longer a configuration of the graph.If we were to equate weakest readings with normalforms, we would erroneously classify (c) as notbeing a weakest reading.
The correct conceptfor characterizing weakest readings in terms ofrewriting is that of a relative normal form.
Wedefine a configuration t of a dominance graph D tobe a R-relative normal form of (the configurationsof) D iff there is no other configuration t ?
of D suchthat t?R t ?.
These are the configurations that can?tbe weakened further without obtaining a tree thatis no longer a configuration of D. In other words,if R approximates entailment, then the R-relativenormal forms approximate the weakest readings.4.3 Computing relative normal formsWe now show how the relative normal forms of adominance graph can be computed efficiently.
Forlack of space, we only sketch the construction andomit all proofs.
Details can be found in Koller andThater (2010).The key idea of the construction is to repre-sent the relation ?R in terms of a context treetransducer M, and characterize the relative nor-mal forms of a tree language L in terms of thepre-image of L under M. Like ordinary regulartree transducers (Comon et al, 2007), context treetransducers read an input tree, assigning states tothe nodes, while emitting an output tree.
But whileordinary transducers read the input tree symbol bysymbol, a context tree transducer can read multiplesymbols at once.
In this way, they are equivalent tothe extended left-hand side transducers of Graehlet al (2008).We will now define context tree transducers.
Let?
be a ranked signature, and let Xm be a set of mvariables.
We write Con(m)(?)
for the contexts withm holes, i.e.
those trees in T (?
?Xm) in which eachelement of Xm occurs exactly once, and alwaysas a leaf.
If C ?
Con(m)(?
), then C[t1, .
.
.
, tm] =C[t1/x1, .
.
.
, tm/xm], where x1, .
.
.
,xm are the vari-ables from left to right.A (top-down) context tree transducer from ?
to ?is a 5-tuple M =(Q,?,?,q0,?
).
?
and ?
are rankedsignatures, Q is a finite set of states, and q0 ?
Q isthe start state.
?
is a finite set of transition rules ofthe form q(C[x1, .
.
.
,xn])?D[q1(xi1), .
.
.
,qm(xim)],where C ?
Con(n)(?)
and D ?
Con(m)(?
).If t ?
T (???
?Q), then we say that M derivest ?
in one step from t, t ?M t ?, if t is of the formC?
[q(C[t1, .
.
.
, tn])] for some C?
?
Con(1)(?
), t ?
isof the form C?
[D[q1(ti1), .
.
.
,qm(tim)]], and there isa rule q(C[x1, .
.
.
,xn])?
D[q1(xi1), .
.
.
,qm(xim)] in?
.
The derivation relation ?
?M is the reflexive,transitive closure of?M.
The translation relation?M of M is?M = {(t, t ?)
| t ?T (?)
and t ?
?T (?)
and q0(t)??
t ?
}.For each linear annotated rewrite system R, wecan now build a context tree transducer MR suchthat t ?R t ?
iff (t, t ?)
?
?MR .
The idea is that MRtraverses t from the root to the leaves, keepingtrack of the current annotation in its state.
MRcan nondeterministically choose to either copy thecurrent symbol to the output tree unchanged, or toapply a rewrite rule from R. The rules are built insuch a way that in each run, exactly one rewriterule must be applied.We achieve this as follows.
MR takes as itsstates the set {q?}?
{qa | a ?
Ann} and as its startstate the state qa0 .
If MR reads a node u in stateqa, this means that the annotator assigns annota-tion a to u and MR will rewrite a subtree at or34below u.
If MR reads u in state q?, this meansthat MR will copy the subtree below u unchangedbecause the rewriting has taken place elsewhere.Thus MR has three types of rewrite rules.
First,for any f ?
?, we have a rule q?
( f (x1, .
.
.
,xn))?f (q?
(x1), .
.
.
, q?(xn)).
Second, for any f and1 ?
i ?
n, we have a rule qa( f (x1, .
.
.
,xn)) ?f (q?
(x1), .
.
.
,qann(a, f ,i)(xi), .
.
.
, q?
(xn)), which non-deterministically chooses under which child therewriting should take place, and assigns it thecorrect annotation.
Finally, we have a ruleqa(C[x1, .
.
.
,xn])?
C?[q?
(xi1), .
.
.
, q?
(xin)] for everyrewrite rule C[x1, .
.
.
,xn]?C?
[xi1 , .
.
.
,xin ] with an-notation a in R.Now let?s put the different parts together.
Weknow that for each hnc dominance graph D, there isa regular tree grammar GD such that L(GD) is theset of configurations of D. Furthermore, the pre-image ?
?1M (L) = {t | exists t ?
?
L with (t, t ?)
?
?M}of a regular tree language L is also regular (Kollerand Thater, 2010) if M is linear, and regular treelanguages are closed under intersection and com-plement (Comon et al, 2007).
So we can computeanother RTG G?
such thatL(G?)
= L(GD)?
?
?1MR (L(GD)).L(G?)
consists of the members of L(GD) whichcannot be rewritten by MR into members of L(GD);that is, L(G?)
is exactly the set of R-relative normalforms of D. In general, the complement construc-tion requires exponential time in the size of MR andGD.
However, it can be shown that if the rules inR have at most depth two and GD is deterministic,then the entire above construction can be computedin time O(|GD| ?
|R|) (Koller and Thater, 2010).In other words, we have shown how to computethe weakest readings of a hypernormally connecteddominance graph D, as approximated by a weaken-ing rewrite system R, in time linear in the size ofGD and linear in the size of R. This is a dramatic im-provement over the best previous algorithm, whichwas quadratic in |conf(D)|.4.4 An exampleConsider an annotated rewrite system that containsrule (1) plus the following rewrite rule:[?]
?z(P,?x(Q,R))?
?x(?z(P,Q),R) (3)This rewrite system translates into a top-downcontext tree transducer MR with the following tran-sition rules, omitting most rules of the first two{1,2,3,4,5,6,7,8}F ??
({2,3,4,5,6,7,8}F ){2,3,4,5,6,7,8}F ??y({7}{q?
},{2,4,5,6,8}F )| ?z({5}{q?
},{2,3,6,7,8}F ){2,3,6,7,8}F ??y({7}{q?},?x({6}{q?},{8}{q?
})){2,4,5,6,8}F ??x({4,5,6}{q?},{8}{q?}){4,5,6}{q?}??z({5}{q?},{6}{q?}){5}{q?}?
compz {6}{q?}?
repr-ofx,z{7}{q?}?
sampley {8}{q?}?
seex,yFigure 4: RTG for the weakest readings of Fig.
1.types for lack of space.q?(?x(x1,?y(x2,x3)))??y(q?(x2),?x(q?
(x1), q?(x3)))q?(?y(x1,?x(x2,x3)))??x(?y(q?
(x1), q?
(x2)), q?(x3))q?(?(x1))??(q?(x1))q+(?(x1))??(q?(x1))q?(?x(x1,x2))??x(q?
(x1), q?(x2))q+(?x(x1,x2))??x(q?(x1),q+(x2))q+(?x(x1,x2))??x(q?
(x1), q?
(x2)) .
.
.The grammar G?
for the relative normal formsis shown in Fig.
4 (omitting rules that involve un-productive nonterminals).
We obtain it by startingwith the example grammar GD in Fig.
3; then com-puting a deterministic RTG GR for ?
?1MR (L(GD));and then intersecting the complement of GR withGD.
The nonterminals of G?
are subgraphs of D,marked either with a set of states of MR or the sym-bol F , indicating that GR had no production rulefor a given left-hand side.
The start symbol of G?is marked with F because G?
should only gener-ate trees that GR cannot generate.
As expected, G?generates precisely two trees, namely (b) and (c).5 Redundancy elimination, revisitedThe construction we just carried out ?
characterizethe configurations we find interesting as the rela-tive normal forms of an annotated rewrite systemR, translate it into a transducer MR, and intersectconf(D) with the complement of the pre-image un-der MR ?
is more generally useful than just for thecomputation of weakest readings.
We illustrate thison the problem of redundancy elimination (Vestre,1991; Chaves, 2003; Koller et al, 2008) by show-ing how a variant of the algorithm of Koller et al(2008) falls out of our technique as a special case.Redundancy elimination is the problem of com-puting, from a dominance graph D, another domi-nance graph D?
such that conf(D?)?
conf(D) and35every formula in conf(D) is logically equivalentto some formula in conf(D?).
We can approximatelogical equivalence using a finite system of equa-tions such as?y(P,?z(Q,R)) = ?z(Q,?y(P,R)), (4)indicating that ?y and ?z can be permuted withoutchanging the models of the formula.Following the approach of Section 4, we cansolve the redundancy elimination problem by trans-forming the equation system into a rewrite systemR such that t?R t ?
implies that t and t ?
are equiv-alent.
To this end, we assume an arbitrary linearorder < on ?, and orient all equations into rewriterules that respect this order.
If we assume ?y < ?z,the example rule (4) translates into the annotatedrewrite rules[a] ?z(P,?y(Q,R))?
?y(Q,?z(P,R)) (5)for all annotations a ?
Ann; logical equivalenceis not sensitive to the annotation.
Finally, we cancompute the relative normal forms of conf(D) un-der this rewrite system as above.
The result will bean RTG G?
describing a subset of conf(D).
Everytree t in conf(D) that is not in L(G?)
is equivalentto some tree t ?
in L(G?
), because if t could not berewritten into such a t ?, then t would be in rela-tive normal form.
That is, the algorithm solves theredundancy elimination problem.
Furthermore, ifthe oriented rewrite system is confluent (Baaderand Nipkow, 1999), no two trees in L(G?)
will beequivalent to each other, i.e.
we achieve completereduction in the sense of Koller et al (2008).This solution shares much with that of Koller etal.
(2008), in that we perform redundancy elimina-tion by intersecting tree grammars.
However, theconstruction we present here is much more general:The algorithmic foundation for redundancy elim-ination is now exactly the same as that for weak-est readings, we only have to use an equivalence-preserving rewrite system instead of a weakeningone.
This new formal clarity also simplifies thespecification of certain equations, as we will see inSection 6.In addition, we can now combine the weakeningrules (1), (3), and (5) into a single rewrite system,and then construct a tree grammar for the relativenormal forms of the combined system.
This algo-rithm performs redundancy elimination and com-putes weakest readings at the same time, and in ourexample retains only a single configuration, namely(5)(e) ?
?x(?z,?y) (a) ?
?y?z?x(3)(1)(1)(b) ?
?y?x?z(c) ?
?z?y?x(d) ?
?z?x?y(3)Figure 5: Structure of the configuration set of Fig.
1in terms of rewriting.
(b); the configuration (c) is rejected because it canbe rewritten to (a) with (5).
The graph in Fig.
5 il-lustrates how the equivalence and weakening rulesconspire to exclude all other configurations.6 EvaluationIn this section, we evaluate the effectiveness andefficiency of our weakest readings algorithm ona treebank.
We compute RTGs for all sentencesin the treebank and measure how many weakestreadings remain after the intersection, and howmuch time this computation takes.Resources.
For our experiment, we use the Ron-dane treebank (version of January 2006), a ?Red-woods style?
(Oepen et al, 2002) treebank con-taining underspecified representations (USRs) inthe MRS formalism (Copestake et al, 2005) forsentences from the tourism domain.Our implementation of the relative normal formsalgorithm is based on Utool (Koller and Thater,2005), which (among other things) can translate alarge class of MRS descriptions into hypernormallyconnected dominance graphs and further into RTGsas in Section 3.
The implementation exploits cer-tain properties of RTGs computed from dominancegraphs to maximize efficiency.
We will make thisimplementation publically available as part of thenext Utool release.We use Utool to automatically translate the 999MRS descriptions for which this is possible intoRTGs.
To simplify the specification of the rewritesystems, we restrict ourselves to the subcorpus inwhich all scope-taking operators (labels with arity> 0) occur at least ten times.
This subset contains624 dominance graphs.
We refer to this subset as?RON10.
?Signature and annotations.
For each domi-nance graph D that we obtain by converting anMRS description, we take GD as a grammar overthe signature ?= { fu | u ?WD, f = LD(u)}.
Thatis, we distinguish possible different occurrencesof the same symbol in D by marking each occur-36rence with the name of the node.
This makes GD adeterministic grammar.We then specify an annotator over ?
that assignspolarities for the weakening rewrite system.
Wedistinguish three polarities: + for positive occur-rences, ?
for negative occurrences (as in predicatelogic), and ?
for contexts in which a weakeningrule neither weakens or strengthens the entire for-mula.
The starting annotation is +.Finally, we need to decide upon each scope-taking operator?s effects on these annotations.
Tothis end, we build upon Barwise and Cooper?s(1981) classification of the monotonicity prop-erties of determiners.
A determiner is upward(downward) monotonic if making the denotation ofthe determiner?s argument bigger (smaller) makesthe sentence logically weaker.
For instance, ev-ery is downward monotonic in its first argumentand upward monotonic in its second argument,i.e.
every girl kissed a boy entails every blondgirl kissed someone.
Thus ann(everyu,a,1) =?aand ann(everyu,a,2) = a (where u is a node nameas above).
There are also determiners with non-monotonic argument positions, which assign theannotation ?
to this argument.
Negation reversespositive and negative polarity, and all other non-quantifiers simply pass on their annotation to thearguments.Weakest readings.
We use the following weak-ening rewrite system for our experiment, wherei ?
{1,2}:1.
[+] (E/i,D/1), (D/2,D/1)2.
[+] (E/i,P/1), (D/2,P/1)3.
[+] (E/i,A/2), (D/1,A/2)4.
[+] (A/2,N/1)5.
[+] (N/1,E/i), (N/1,D/2)6.
[+] (E/i,M/1), (D/1,M/1)Here the symbols E, D, etc.
stand for classesof labels in ?, and a rule schema [a] (C/i,C?/k) isto be read as shorthand for a set of rewrite ruleswhich rearrange a tree where the i-th child of asymbol from C is a symbol from C?
into a treewhere the symbol from C becomes the k-th childof the symbol from C?.
For example, because wehave allu ?
A and notv ?
N, Schema 4 licenses thefollowing annotated rewrite rule:[+] allu(P,notv(Q))?
notv(allu(P,Q)).We write E and D for existential and definitedeterminers.
P stands for proper names and pro-nouns, A stands for universal determiners like alland each, N for the negation not, and M for modaloperators like can or would.
M also includes in-tensional verbs like have to and want.
Notice thatwhile the reverse rules are applicable in negativepolarities, no rules are applicable in polarity ?.Rule schema 1 states, for instance, that the spe-cific (wide-scope) reading of the indefinite in thepresident of a company is logically stronger thanthe reading in which a company is within the re-striction of the definite determiner.
The schema isintuitively plausible, and it can also be proved to belogically sound if we make the standard assumptionthat the definite determiner the means ?exactly one?
(Montague, 1974).
A similar argument applies torule schema 2.Rule schema 3 encodes the classical entailment(1).
Schema 4 is similar to the rule (2).
Noticethat it is not, strictly speaking, logically sound;however, because strong determiners like all orevery carry a presupposition that their restrictionshave a non-empty denotation (Lasersohn, 1993),the schema becomes sound for all instances thatcan be expressed in natural language.
Similar ar-guments apply to rule schemas 5 and 6, which arepotentially unsound for subtle reasons involvingthe logical interpretation of intensional expressions.However, these cases of unsoundness did not occurin our test corpus.Redundancy elimination.
In addition, we as-sume the following equation system for redundancyelimination for i, j ?
{1,2} and k ?
N (again writ-ten in an analogous shorthand as above):7.
E/i = E/ j8.
D/1 = E/i, E/i = D/19.
D/1 = D/110.
?/k = P/2These rule schemata state that permuting exis-tential determiners with each other is an equiva-lence transformation, and so is permuting definitedeterminers with existential and definite determin-ers if one determiner is the second argument (inthe scope) of a definite.
Schema 10 states thatproper names and pronouns, which the ERG ana-lyzes as scope-bearing operators, can permute withany other label.We orient these equalities into rewrite rules byordering symbols in P before symbols that are not37All KRT08 RE RE+WR#conf = 1 8.5% 23.4% 34.9% 66.7%#conf?
2 20.5% 40.9% 57.9% 80.6%avg(#conf) 3.2M 7603.1 119.0 4.5med(#conf) 25 4 2 1runtime 8.1s 9.4s 8.7s 9.1sFigure 6: Analysis of the numbers of configurationsin RON10.in P, and otherwise ordering a symbol fu before asymbol gv if u < v by comparison of the (arbitrary)node names.Results.
We used these rewrite systems to com-pute, for each USR in RON10, the number of allconfigurations, the number of configurations thatremain after redundancy elimination, and the num-ber of weakest readings (i.e., the relative normalforms of the combined equivalence and weakeningrewrite systems).
The results are summarized inFig.
6.
By computing weakest readings (WR), wereduce the ambiguity of over 80% of all sentencesto one or two readings; this is a clear improvementeven over the results of the redundancy elimina-tion (RE).
Computing weakest readings reducesthe mean number of readings from several millionto 4.5, and improves over the RE results by a factorof 30.
Notice that the RE algorithm from Section 5is itself an improvement over Koller et al?s (2008)system (?KRT08?
in the table), which could notprocess the rule schema 10.Finally, computing the weakest readings takesonly a tiny amount of extra runtime compared tothe RE elimination or even the computation of theRTGs (reported as the runtime for ?All?
).1 This re-mains true on the entire Rondane corpus (althoughthe reduction factor is lower because we have norules for the rare scope-bearers): RE+WR compu-tation takes 32 seconds, compared to 30 secondsfor RE.
In other words, our algorithm brings thesemantic ambiguity in the Rondane Treebank downto practically useful levels at a mean runtime in-vestment of a few milliseconds per sentence.It is interesting to note how the different ruleschemas contribute to this reduction.
While theinstances of Schemata 1 and 2 are applicable in 340sentences, the other schemas 3?6 together are only1Runtimes were measured on an Intel Core 2 Duo CPUat 2.8 GHz, under MacOS X 10.5.6 and Apple Java 1.5.0_16,after allowing the JVM to just-in-time compile the bytecode.applicable in 44 sentences.
Nevertheless, wherethese rules do apply, they have a noticeable effect:Without them, the mean number of configurationsin RON10 after RE+WR increases to 12.5.7 ConclusionIn this paper, we have shown how to compute theweakest readings of a dominance graph, charac-terized by an annotated rewrite system.
Evaluat-ing our algorithm on a subcorpus of the RondaneTreebank, we reduced the mean number of config-urations of a sentence from several million to 4.5,in negligible runtime.
Our algorithm can be ap-plied to other problems in which an underspecifiedrepresentation is to be disambiguated, as long asthe remaining readings can be characterized as therelative normal forms of a linear annotated rewritesystem.
We illustrated this for the case of redun-dancy elimination.The algorithm presented here makes it possible,for the first time, to derive a single meaningful se-mantic representation from the syntactic analysisof a deep grammar on a large scale.
In the future,it will be interesting to explore how these semanticrepresentations can be used in applications.
For in-stance, it seems straightforward to adapt MacCart-ney and Manning?s (2008) ?natural logic?-basedTextual Entailment system, because our annotatoralready computes the polarities needed for theirmonotonicity inferences.
We could then performsuch inferences on (cleaner) semantic representa-tions, rather than strings (as they do).On the other hand, it may be possible to re-duce the set of readings even further.
We retainmore readings than necessary in many treebank sen-tences because the combined weakening and equiv-alence rewrite system is not confluent, and there-fore may not recognize a logical relation betweentwo configurations.
The rewrite system could bemade more powerful by running the Knuth-Bendixcompletion algorithm (Knuth and Bendix, 1970).Exploring the practical tradeoff between the furtherreduction in the number of remaining configura-tions and the increase in complexity of the rewritesystem and the RTG would be worthwhile.Acknowledgments.
We are indebted to JoachimNiehren, who pointed out a crucial simplificationin the algorithm to us.
We also thank our reviewersfor their constructive comments.38ReferencesE.
Althaus, D. Duchier, A. Koller, K. Mehlhorn,J.
Niehren, and S. Thiel.
2003.
An efficient graphalgorithm for dominance constraints.
Journal of Al-gorithms, 48:194?219.F.
Baader and T. Nipkow.
1999.
Term rewriting and allthat.
Cambridge University Press.J.
Barwise and R. Cooper.
1981.
Generalized quanti-fiers and natural language.
Linguistics and Philoso-phy, 4:159?219.J.
Bos.
2008.
Let?s not argue about semantics.
InProceedings of the 6th international conference onLanguage Resources and Evaluation (LREC 2008).M.
Butt, H. Dyvik, T. Holloway King, H. Masuichi,and C. Rohrer.
2002.
The parallel grammarproject.
In Proceedings of COLING-2002 Workshopon Grammar Engineering and Evaluation.R.
P. Chaves.
2003.
Non-redundant scope disambigua-tion in underspecified semantics.
In Proceedings ofthe 8th ESSLLI Student Session.H.
Comon, M. Dauchet, R. Gilleron, C. L?ding,F.
Jacquemard, D. Lugiez, S. Tison, and M. Tom-masi.
2007.
Tree automata techniques and appli-cations.
Available on: http://www.grappa.univ-lille3.fr/tata.A.
Copestake and D. Flickinger.
2000.
An open-source grammar development environment andbroad-coverage english grammar using HPSG.
InProceedings of the 2nd International Conference onLanguage Resources and Evaluation (LREC).A.
Copestake, D. Flickinger, C. Pollard, and I. Sag.2005.
Minimal recursion semantics: An introduc-tion.
Journal of Language and Computation.D.
Flickinger, A. Koller, and S. Thater.
2005.
A newwell-formedness criterion for semantics debugging.In Proceedings of the 12th International Conferenceon HPSG, Lisbon.M.
Gabsdil and K. Striegnitz.
1999.
Classifying scopeambiguities.
In Proceedings of the First Intl.
Work-shop on Inference in Computational Semantics.J.
Graehl, K. Knight, and J.
May.
2008.
Training treetransducers.
Computational Linguistics, 34(3):391?427.D.
Higgins and J. Sadock.
2003.
A machine learningapproach to modeling scope preferences.
Computa-tional Linguistics, 29(1).J.
Hobbs.
1983.
An improper treatment of quantifi-cation in ordinary English.
In Proceedings of the21st Annual Meeting of the Association for Compu-tational Linguistics (ACL?83).R.
Kempson and A. Cormack.
1981.
Ambiguity andquantification.
Linguistics and Philosophy, 4:259?309.D.
Knuth and P. Bendix.
1970.
Simple word problemsin universal algebras.
In J. Leech, editor, Computa-tional Problems in Abstract Algebra, pages 263?297.Pergamon Press, Oxford.A.
Koller and J. Niehren.
2000.
On underspecifiedprocessing of dynamic semantics.
In Proceedings ofthe 18th International Conference on ComputationalLinguistics (COLING-2000).A.
Koller and S. Thater.
2005.
Efficient solving and ex-ploration of scope ambiguities.
In ACL-05 Demon-stration Notes, Ann Arbor.A.
Koller and S. Thater.
2010.
Computing relative nor-mal forms in regular tree languages.
In Proceedingsof the 21st International Conference on RewritingTechniques and Applications (RTA).A.
Koller, J. Niehren, and S. Thater.
2003.
Bridg-ing the gap between underspecification formalisms:Hole semantics as dominance constraints.
In Pro-ceedings of the 10th EACL.A.
Koller, M. Regneri, and S. Thater.
2008.
Regulartree grammars as a formalism for scope underspeci-fication.
In Proceedings of ACL-08: HLT.P.
Lasersohn.
1993.
Existence presuppositions andbackground knowledge.
Journal of Semantics,10:113?122.B.
MacCartney and C. Manning.
2008.
Modelingsemantic containment and exclusion in natural lan-guage inference.
In Proceedings of the 22nd Inter-national Conference on Computational Linguistics(COLING).R.
Montague.
1974.
The proper treatment of quantifi-cation in ordinary English.
In R. Thomason, editor,Formal Philosophy.
Selected Papers of Richard Mon-tague.
Yale University Press, New Haven.C.
Monz and M. de Rijke.
2001.
Deductions withmeaning.
In Michael Moortgat, editor, Logical As-pects of Computational Linguistics, Third Interna-tional Conference (LACL?98), volume 2014 of LNAI.Springer-Verlag, Berlin/Heidelberg.S.
Oepen, K. Toutanova, S. Shieber, C. Manning,D.
Flickinger, and T. Brants.
2002.
The LinGORedwoods treebank: Motivation and preliminaryapplications.
In Proceedings of the 19th Inter-national Conference on Computational Linguistics(COLING).Uwe Reyle.
1995.
On reasoning with ambiguities.
InProceedings of the 7th Conference of the EuropeanChapter of the Association for Computational Lin-guistics (EACL?95).K.
van Deemter.
1996.
Towards a logic of ambiguousexpressions.
In Semantic Ambiguity and Underspec-ification.
CSLI Publications, Stanford.E.
Vestre.
1991.
An algorithm for generating non-redundant quantifier scopings.
In Proc.
of EACL,Berlin.39
