Proceedings of NAACL HLT 2007, Companion Volume, pages 205?208,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsComparing Wikipedia and German Wordnetby Evaluating Semantic Relatedness on Multiple DatasetsTorsten Zesch and Iryna Gurevych and Max M?hlh?userUbiquitous Knowledge Processing Group, Telecooperation DivisionDarmstadt University of Technology, D-64289 Darmstadt, Germany{zesch,gurevych,max} (at) tk.informatik.tu-darmstadt.deAbstractWe evaluate semantic relatedness mea-sures on different German datasets show-ing that their performance depends on: (i)the definition of relatedness that was un-derlying the construction of the evalua-tion dataset, and (ii) the knowledge sourceused for computing semantic relatedness.We analyze how the underlying knowl-edge source influences the performanceof a measure.
Finally, we investigate thecombination of wordnets andWikipedia toimprove the performance of semantic re-latedness measures.1 IntroductionSemantic similarity (SS) is typically defined via thelexical relations of synonymy (automobile ?
car)and hypernymy (vehicle ?
car), while semantic re-latedness (SR) is defined to cover any kind of lexi-cal or functional association that may exist betweentwo words.
Many NLP applications, like sense tag-ging or spelling correction, require knowledge aboutsemantic relatedness rather than just similarity (Bu-danitsky and Hirst, 2006).
For these tasks, it is notnecessary to know the exact type of semantic rela-tion between two words, but rather if they are closelysemantically related or not.
This is also true for thework presented herein, which is part of a projecton electronic career guidance.
In this domain, itis important to conclude that the words ?baker?
and?bagel?
are closely related, while the exact type of asemantic relation does not need to be determined.As we work on German documents, we evalu-ate a number of SR measures on different Germandatasets.
We show that the performance of mea-sures strongly depends on the underlying knowledgesource.
While WordNet (Fellbaum, 1998) mod-els SR, wordnets for other languages, such as theGerman wordnet GermaNet (Kunze, 2004), containonly few links expressing SR.
Thus, they are notwell suited for estimating SR.Therefore, we apply theWikipedia category graphas a knowledge source for SR measures.
We showthat Wikipedia based SR measures yield better cor-relation with human judgments on SR datasets thanGermaNet measures.
However, using Wikipediaalso leads to a performance drop on SS datasets,as knowledge about classical taxonomic relationsis not explicitly modeled.
Therefore, we combineGermaNet with Wikipedia, and yield substantial im-provements over measures operating on a singleknowledge source.2 DatasetsSeveral German datasets for evaluation of SS or SRhave been created so far (see Table 1).
Gurevych(2005) conducted experiments with a German trans-lation of an English dataset (Rubenstein and Goode-nough, 1965), but argued that the dataset (Gur65)is too small (it contains only 65 noun pairs), anddoes not model SR.
Thus, she created a Germandataset containing 350 word pairs (Gur350) con-taining nouns, verbs and adjectives that are con-nected by classical and non-classical relations (Mor-ris and Hirst, 2004).
However, the dataset is bi-ased towards strong classical relations, as wordpairs were manually selected.
Thus, Zesch andGurevych (2006) semi-automatically created wordpairs from domain-specific corpora.
The resultingZG222 dataset contains 222 word pairs that are con-nected by all kinds of lexical semantic relations.Hence, it is particularly suited for analyzing the ca-pability of a measure to estimate SR.205CORRELATION rDATASET YEAR LANGUAGE # PAIRS POS TYPE SCORES # SUBJECTS INTER INTRAGur65 2005 German 65 N SS discrete {0,1,2,3,4} 24 .810 -Gur350 2006 German 350 N, V, A SR discrete {0,1,2,3,4} 8 .690 -ZG222 2006 German 222 N, V, A SR discrete {0,1,2,3,4} 21 .490 .647Table 1: Comparison of datasets used for evaluating semantic relatedness.3 Semantic Relatedness MeasuresSemantic wordnet based measures Lesk (1986)introduced a measure (Les) based on the number ofword overlaps in the textual definitions (or glosses)of two terms, where higher overlap means highersimilarity.
As GermaNet does not contain glosses,this measure cannot be employed.
Gurevych (2005)proposed an alternative algorithm (PG) generatingsurrogate glosses by using a concept?s relationswithin the hierarchy.
Following the description inBudanitsky and Hirst (2006), we further define sev-eral measures using the taxonomy structure.simPL = l(c1, c2)simLC = ?
logl(c1, c2)2?
depthsimRes = IC(ci) = ?
log(p(lcs(c1, c2)))distJC = IC(c1) + IC(c2)?
2IC(lcs(c1, c2))simLin = 2?IC(lcs(c1, c2))IC(c1) + IC(c2)PL is the taxonomic path length l(c1, c2) betweentwo concepts c1 and c2.
LC normalizes the pathlength with the depth of the taxonomy.
Res com-putes SS as the information content (IC) of the low-est common subsumer (lcs) of two concepts, whileJC combines path based and IC features.1 Lin isderived from information theory.Wikipedia based measures For computing theSR of two words w1 and w2 using Wikipedia, wefirst retrieve the articles or disambiguation pageswith titles that equal w1 and w2 (see Figure 1).
Ifwe hit a redirect page, we retrieve the correspond-ing article or disambiguation page instead.
In caseof an article, we insert it into the candidate articleset (A1 for w1, A2 for w2).
In case of a disam-biguation page, the page contains links to all en-coded word senses, but it may also contain other1Note that JC returns a distance value instead of a similarityvalue resulting in negative correlation with human judgments.Word w2Word w11Candidatearticle setsCandidatearticle pairs3aSemantic RelatednessSemantic relatedness of (w1, w2)MaxaA 2A 12a1aArticleDisambig.pageRedirectsFigure 1: Steps for computing SR using Wikipedia.links.
Therefore, we only consider links conformingto the pattern ?Title_(DisambiguationText)?2 (e.g.
?Train_(roller coaster)?).
Following all such linksgives the candidate article set.
If no disambiguationlinks are found, we take the first link on the page, asmost important links tend to come first.
We add thecorresponding articles to the candidate set.
We formpairs from each candidate article ai ?
A1 and eacharticle aj ?
A2.
We then compute SR(ai, aj) foreach pair.
The output of the algorithm is the maxi-mum SR value maxai?A1,aj?A2(SR(ai, aj)).3As most SR measures have been developed fortaxonomic wordnets, porting them to Wikipedia re-quires some modifications (see Figure 2).
Text over-lap measures can be computed based on the articletext, while path based measures operate on the cate-gory graph.
We compute the overlap between article2?_(DisambiguationText)?
is optional.3Different from our approach, Strube and Ponzetto (2006)use a disambiguation strategy that returns only a single candi-date article pair.
This unnecessarily limits a measure?s potentialto consider SR between all candidate article pairs.
They alsolimit the search for a lcs to a manually specified threshold of 4.206WikipediacategorygraphA BA DB BB DC BC DCategory pairsACBBDCategoriesof article 1AHGCEFBDArticle 1 Text1ABCText1Text2Text2FirstparagraphFull textArticle 2 Text2BDText1LCS(B,D)Category graph basedTextbasedCombinationstrategyAvgBestCandidate article pairCategoriesof article 2C 2C 1a) b)Figure 2: SR measures adapted on Wikipedia.texts based on (i) the first paragraph, as it usuallycontains a short gloss, and (ii) the full article text.As Wikipedia articles do not form a taxonomy, pathbased measures have to be adapted to the Wikipediacategory graph (see the right part of Figure 2).
Wedefine C1 and C2 as the set of categories assigned toarticle ai and aj , respectively.
We compute the SRvalue for each category pair (ck, cl) with ck ?
C1and cl ?
C2.
We use two different strategies to com-bine the resulting SR values: First, we choose thebest value among all pairs (ck, cl), i.e., the minimumfor path based, and the maximum for informationcontent based measures.
As a second strategy, weaverage over all category pairs.4 Experiments & ResultsTable 2 gives an overview of our experimental re-sults on three German datasets.
Best values for eachdataset and knowledge source are in bold.
We usethePGmeasure in optimal configuration as reportedby Gurevych (2005).
For the Les measure, we givethe results for considering: (i) only the first para-graph (+First) and (ii) the full text (+Full).
For thepath length based measures, we give the values foraveraging over all category pairs (+Avg), or tak-ing the best SR value computed among the pairs(+Best).
For each dataset, we report Pearson?s cor-relation r with human judgments on pairs that arefound in both resources (BOTH).
Otherwise, the re-sults would not be comparable.
We additionally usea subset containing only noun-noun pairs (BOTHNN).
This comparison is fairer, because article titlesin Wikipedia are usually nouns.
Table 2 also givesthe inter annotator agreement for each subset.
It con-stitutes an upper bound of a measure?s performance.Our results on Gur65 using GermaNet are veryclose to those published by Gurevych (2005), rang-ing from 0.69?0.75.
For Gur350, the performancedrops to 0.38?0.50, due to the lower upper bound,and because GermaNet does not model SR well.These findings are endorsed by an even more sig-nificant performance drop on ZG222.
The measuresbased on Wikipedia behave less uniformly.
Lesyields acceptable results on Gur350, but is generallynot among the best performing measures.
LC +Avgyields the best performance on Gur65, but is outper-formed on the other datasets by PL +Best, whichperforms equally good for all datasets.If we compare GermaNet based and Wikipediabased measures, we find that the knowledge sourcehas a major influence on performance.
When evalu-ated on Gur65, that contains pairs connected by SS,GermaNet based measures perform near the upperbound and outperformWikipedia based measures bya wide margin.
On Gur350 containing a mix of SSand SR pairs, most measures perform comparably.Finally, on ZG222, that contains pairs connected bySR, the best Wikipedia based measure outperformsall GermaNet based measures.The impressive performance of PL on theSR datasets cannot be explained with the struc-tural properties of the category graph (Zesch andGurevych, 2007).
Semantically related terms, thatwould not be closely related in a taxonomic word-net structure, are very likely to be categorized underthe same Wikipedia category, resulting in short pathlengths leading to high SR.
These findings are con-trary to that of (Strube and Ponzetto, 2006), whereLC outperformed path length.
They limited thesearch depth using a manually defined threshold,and did not compute SR between all candidate ar-ticle pairs.Our results show that judgments on the perfor-mance of a measure must always be made with re-spect to the task at hand: computing SS or SR. De-pending on this decision, we can choose the best un-derlying knowledge source.
GermaNet is better for207GUR65 GUR350 ZG222BOTH NN BOTH BOTH NN BOTH BOTH NN# Word Pairs 53 116 91 55 45Inter Annotator Agreement 0.80 0.64 0.63 0.44 0.43GermaNetPG 0.69 0.38 0.42 0.23 0.21JC -0.75 -0.52 -0.48 -0.19 -0.25Lin 0.73 0.50 0.50 0.08 -0.12Res 0.71 0.42 0.42 0.10 0.13WikipediaLes +First 0.16 0.36 0.32 0.01 0.11Les +Full 0.19 0.34 0.37 0.13 0.17PL +Avg -0.32 -0.34 -0.46 -0.36 -0.43PL +Best -0.35 -0.42 -0.53 -0.43 -0.49LC +Avg 0.37 0.25 0.34 0.30 0.30LC +Best 0.21 0.12 0.21 0.15 0.12CombinationLinear 0.77 0.59 0.60 0.38 0.43POS - 0.55 - 0.48 -Table 2: Correlation r of human judgments with SR measures on different datasets.estimating SS, while Wikipedia should be used toestimate SR.
Therefore, a measure based on a singleknowledge source is unlikely to perform well in allsettings.
We computed a linear combination of thebest measure from GermaNet and from Wikipedia.Results for this experiment are labeled Linear in Ta-ble 2.
POS is an alternative combination strategy,where Wikipedia is only used for noun-noun pairs.GermaNet is used for all other part-of-speech (POS)combinations.
For most datasets, we find a combi-nation strategy that outperforms all single measures.5 ConclusionWe have shown that in deciding for a specific mea-sure and knowledge source it is important to con-sider (i) whether the task at hand requires SS orSR, and (ii) which POS are involved.
We pointedout that the underlying knowledge source has a ma-jor influence on these points.
GermaNet is betterused for SS, and contains nouns, verbs, and adjec-tives, while Wikipedia is better used for SR betweennouns.
Thus, GermaNet and Wikipedia can be re-garded as complementary.
We have shown that com-bining them significantly improves the performanceof SR measures up to the level of human perfor-mance.Future research should focus on improving thestrategies for combining complementary knowledgesources.
We also need to evaluate a wider range ofmeasures to validate our findings.
As the simple PLmeasure performs remarkably well, we should alsoconsider computing SR based on the Wikipedia arti-cle graph instead of the category graph.AcknowledgmentsThis work was supported by the German Research Foundationunder grant "Semantic Information Retrieval from Texts in theExample Domain Electronic Career Guidance", GU 798/1-2.ReferencesAlexander Budanitsky and Graeme Hirst.
2006.
EvaluatingWordNet-based Measures of Semantic Distance.
Computa-tional Linguistics, 32(1).Christiane Fellbaum.
1998.
WordNet An Electronic LexicalDatabase.
MIT Press, Cambridge, MA.Iryna Gurevych.
2005.
Using the Structure of a ConceptualNetwork in Computing Semantic Relatedness.
In Proc.
ofIJCNLP, pages 767?778.Claudia Kunze, 2004.
Lexikalisch-semantische Wortnetze,chapter Computerlinguistik und Sprachtechnologie, pages423?431.
Spektrum Akademischer Verlag.Michael Lesk.
1986.
Automatic Sense Disambiguation Us-ing Machine Readable Dictionaries: How to tell a pine conefrom an ice cream cone.
In Proc.
of the 5th Annual Interna-tional Conference on Systems Documentation, pages 24?26.Jane Morris and Graeme Hirst.
2004.
Non-Classical LexicalSemantic Relations.
In Proc.
of the Workshop on Computa-tional Lexical Semantics, NAACL-HTL.Herbert Rubenstein and John B. Goodenough.
1965.
Contex-tual Correlates of Synonymy.
Communications of the ACM,8(10):627?633.Michael Strube and Simone Paolo Ponzetto.
2006.
WikiRelate!Computing Semantic Relatedness UsingWikipedia.
In Proc.of AAAI, pages 1219?1224.Torsten Zesch and Iryna Gurevych.
2006.
Automatically Creat-ing Datasets for Measures of Semantic Relatedness.
In Proc.of the Workshop on Linguistic Distances, ACL, pages 16?24.T.
Zesch and I. Gurevych.
2007.
Analysis of the WikipediaCategory Graph for NLP Applications.
In Proc.
of theTextGraphs-2 Workshop, NAACL-HLT, (to appear).208
