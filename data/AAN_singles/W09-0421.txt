Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 120?124,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsImproving alignment for SMT by reorderingand augmenting the training corpusMaria Holmqvist, Sara Stymne, Jody Foo and Lars AhrenbergDepartment of Computer and Information ScienceLink?ping University, Sweden{marho,sarst,jodfo,lah}@ida.liu.seAbstractWe describe the LIU systems for English-German and German-English translationin the WMT09 shared task.
We focus ontwo methods to improve the word align-ment: (i) by applying Giza++ in a sec-ond phase to a reordered training cor-pus, where reordering is based on thealignments from the first phase, and (ii)by adding lexical data obtained as high-precision alignments from a different wordaligner.
These methods were studied inthe context of a system that uses com-pound processing, a morphological se-quence model for German, and a part-of-speech sequence model for English.Both methods gave some improvements totranslation quality as measured by Bleuand Meteor scores, though not consis-tently.
All systems used both out-of-domain and in-domain data as the mixedcorpus had better scores in the baselineconfiguration.1 IntroductionIt is an open question whether improved wordalignment actually improves statistical MT.
Fraserand Marcu (2007) found that improved alignmentsas measured by AER will not necessarily improvetranslation quality, whereas Ganchev et al (2008)did improve translation quality on several lan-guage pairs by extending the alignment algorithm.For this year?s shared task we therefore stud-ied the effects of improving word alignment in thecontext of our system for the WMT09 shared task.Two methods were tried: (i) applying Giza++ ina second phase to a reordered training corpus,where reordering is based on the alignments fromthe first phase, and (ii) adding lexical data ob-tained as high-precision alignments from a differ-ent word aligner.
The submitted system includesthe first method in addition to the processing ofcompounds and additional sequence models usedby Stymne et al (2008).
Heuristics were usedto generate true-cased versions of the translationsthat were submitted, as reported in section 6.In this paper we report case-insensitive Bleuscores (Papineni et al, 2002), unless otherwisestated, calculated with the NIST tool, and case-insensitive Meteor-ranking scores, without Word-Net (Agarwal and Lavie, 2008).2 Baseline systemOur baseline system uses compound split-ting, compound merging and part-of-speech/morphological sequence models (Stymneet al, 2008).
Except for these additions it issimilar to the baseline system of the workshop1.The translation system is a factored phrase-based translation system that uses the Mosestoolkit (Koehn et al, 2007) for decoding and train-ing, GIZA++ for word alignment (Och and Ney,2003), and SRILM (Stolcke, 2002) for languagemodels.
Minimum error rate training was used totune the model feature weights (Och, 2003).Tuning was performed on the news-dev2009aset with 1025 sentences.
All development test-ing was performed on the news-dev2009b set with1026 sentences.2.1 Sequence model based on part-of-speechand morphologyThe translation models were factored with one ad-ditional output factor.
For English we used part-of-speech tags obtained with TreeTagger (Schmid,1994).
For German we enriched the tags fromTreeTagger with morphological information, suchas case or tense, that we get from a commercial1http://www.statmt.org/wmt09/baseline.html120dependency parser2.We used the extra factor in an additional se-quence model which can improve agreement be-tween words, and word order.
For German thisfactor was also used for compound merging.2.2 Compound processingPrior to training and translation, compound pro-cessing was performed using an empirical methodbased on (Koehn and Knight, 2003; Stymne,2008).
Words were split if they could be splitinto parts that occur in a monolingual corpus.
Wechose the split with the highest arithmetic meanof the corpus frequencies of compound parts.
Wesplit nouns, adjectives and verbs into parts thatwere content words or particles.
A part had tobe at least 3 characters in length and a stop listwas used to avoid parts that often lead to errors,such as arische (Aryan) in konsularische (con-sular).
Compound parts sometimes have specialcompound suffixes, which could be additions ortruncations of letters, or combinations of these.We used the top 10 suffixes from a corpus studyof Langer (1998), and we also treated hyphens assuffixes of compound parts.
Compound parts weregiven a special part-of-speech tag that matched thehead word.For translation into German, compound partswere merged to form compounds, both during testand tuning.
The merging is based on the spe-cial part-of-speech tag used for compound parts(Stymne, 2009).
A token with this POS-tag ismerged with the next token, either if the POS-tagsmatch, or if it results in a known word.3 Domain adaptationThis year three training corpora were available, asmall bilingual news commentary corpus, a rea-sonably large Europarl corpus, and a very largemonolingual news corpus, see Table 1 for details.The bilingual data was filtered to remove sen-tences longer than 60 words.
Because the Germannews training corpus contained a number of En-glish sentences, this corpus was cleaned by remov-ing sentences containing a number of common En-glish words.Based on Koehn and Schroeder (2007) weadapted our system from last year, which was fo-cused on Europarl, to perform well on test data2Machinese syntax, from Connexor Oy http://www.connexor.euCorpus German Englishnews-commentary09 81,141Europarl 1,331,262news-train08 9,619,406 21,215,311Table 1: Number of sentences in the corpora (afterfiltering)Corpus En?De De?EnBleu Meteor Bleu MeteorNews com.
12.13 47.01 17.21 36.08Europarl 12.92 47.27 18.53 37.65Mixed 12.91 47.96 18.76 37.69Mixed+ 14.62 49.48 19.92 38.18Table 2: Results of domain adaptationfrom the news domain.
We used the possibilityto include several translation models in the Mosesdecoder by using multiple alternative decodingpaths.
We first trained systems on either bilingualnews data or Europarl.
Then we trained a mixedsystem, with two translation models one from eachcorpus, a language model from the bilingual newsdata, and a Europarl reordering model.
The mixedsystem was slightly better than the Europarl onlysystem.
All sequence models used 5-grams forsurface form and 7-grams for part-of-speech.
Allscores are shown in Table 2.We wanted to train sequence models on thelarge monolingual corpora, but due to limitedcomputer resources, we had to use a lower orderfor this, than on the small corpus.
Thus our se-quence models on this data has lower order thanthose trained on bilingual news or Europarl, with4-grams for surface form and 6-grams for part-of-speech.
We also used the entropy-based prun-ing included in the SRILM toolkit, with 10?8 asa threshold.
Using these sequence models in themixed model, called mixed+, improved the resultsdrastically, as shown in Table 2.The other experiments reported in this paper arebased on the mixed+ system.4 Improved alignment by reorderingWord alignment with Giza++ has been shown toimprove from making the source and target lan-guage more similar, e.g., in terms of segmentation(Ma et al, 2007) or word order.We used the following simple procedure to im-prove alignment of the training corpus by reorder-ing the words in one of the texts according to the121Corpus En?De De?EnBleu Meteor Bleu MeteorMixed+ 14.62 49.48 19.92 38.18Re-Src 14.63 49.80 20.54 38.86Re-Trg 14.51 48.62 20.48 38.73Table 3: Results of reordering experimentsword order in the other language:1.
Word align the corpus with Giza++.2.
Reorder the German words according to theorder of the English words they are alignedto.
(This is a common step in approaches thatextract reordering rules for translation.
How-ever, this is not what we use it for here.)3.
Word align the reordered German and origi-nal English corpus with Giza++.4.
Put the reordered German words back intotheir original position and adjust the align-ments so that the improved alignment is pre-served.After this step we will have a possibly improvedalignment compared to the original Giza++ align-ment.
A phrase table was extracted from the align-ment and training was performed as usual.
The re-ordering procedure was carried out on both source(Re-Src) and target data (Re-Trg) and the resultsof translating devtest data using these alignmentsare shown in Table 3.Compared with our baseline (mixed+), Bleuand Meteor increased for the translation directionGerman?English.
Both source reordering and tar-get reordering resulted in a 0.6 increase in Bleu.For translation into German, source reorderingresulted in a somewhat higher Meteor score, butoverall did not seem to improve translation.
Tar-get reordering in this direction resulted in lowerscores.It is not clear why reordering improved trans-lation for German?English and not for English?German.
In all experiments, the heuristic sym-metrization of directed Giza++ alignments wasperformed in the intended translation direction 3.3Our experiments show that symmetrization in the wrongtranslation direction will result in lower translation qualityscores.5 Augmenting the corpus with anextracted dictionaryPrevious research (Callison-Burch et al, 2004;Fraser and Marcu, 2006) has shown that includ-ing word aligned data during training can improvetranslation results.
In our case we included a dic-tionary extracted from the news-commentary cor-pus during the word alignment.Using a method originally developed for termextraction (Merkel and Foo, 2007), the news-commentary09 corpus was grammatically anno-tated and aligned using a heuristic word aligner.Candidate dictionary entries were extracted fromthe alignments.
In order to optimize the qual-ity of the dictionary, dictionary entry candidateswere ranked according to their Q-value, a metricspecifically designed for aligned data (Merkel andFoo, 2007).
The Q-value is based on the followingstatistics:?
Type Pair Frequencies (TPF), i.e.
the numberof times where the source and target types arealigned.?
Target types per Source type (TpS), i.e.
thenumber of target types a specific source typehas been aligned to.?
Source types per Target type (SpT), i.e.
thenumber of source types a specific target typehas been aligned to.The Q-value is calculated asQ?value= TPFTpS+SpT .
A high Q-value indi-cates a dictionary candidate pair with a relativelylow number of translation variations.
The candi-dates were filtered using a Q-value threshold of0.333, resulting in a dictionary containing 67287entries.For the experiments, the extracted dictionarywas inserted 200 times into the corpus used dur-ing word alignment.
The added dictionary entrieswere removed before phrase extraction.
Experi-ments using the extracted dictionary as an addi-tional phrase table were also run, but did not resultin any improvement of translation quality.The results can be seen in Table 4.
There wasno evident pattern how the inclusion of the dictio-nary during alignment (DictAl) affected the trans-lation quality.
The inclusion of the dictionary pro-duced both higher and lower Bleu scores than the122Corpus En?De De?EnBleu Meteor Bleu MeteorMixed+ 14.62 49.48 19.92 38.18DictAl 14.73 49.39 18.93 37.71Table 4: Results of domain adaptationCorpus En?De De?EnMixed+ 13.31 17.47with OOV 13.74 17.96Table 5: Case-sensitive Bleu scoresbaseline system depending on the translation di-rection.
Meteor scores were however consistentlylower than the baseline system.6 Post processing of out-of-vocabularywordsIn the standard systems all out-of-vocabularywords are transferred as is from the translation in-put to the translation output.
Many of these wordsare proper names, which do not get capitalizedproperly, or numbers, which have different for-matting in German and English.
We used post-processing to improve this.For all unknown words we capitalized either thefirst letter, or all letters, if they occur in that formin the translation input.
For unknown numberswe switched between the German decimal commaand the English decimal point for decimal num-bers.
For large numbers, English has a commato separate thousands, and German has a period.These were also switched.
This improved case-sensitive Bleu scores in both translation directions,see Table 5.7 Submitted systemFor both translation directions De-En and En-Dewe submitted a system with two translation mod-els trained on bilingual news and Europarl.
Thealignment was improved by using the reorderingtechniques described in section 4.
The systemsalso use all features described in this paper exceptfor the lexical augmentation (section 5) which didnot result in significant improvement.
The resultsof the submitted systems on devtest data are bold-faced in Table 3.Corpus En?De De?EnAll 14.63 20.54En-De orig.
19.93 26.82Other set 11.66 16.17Table 6: Bleu scores for the reordered systems ontwo sections of development set news-dev2009b.NIST scores show the same distribution.8 Results on two sections of devtest dataComparisons of translation output with referencetranslations on devtest data showed some surpris-ing differences, which could be attributed to cor-responding differences between source and refer-ence data.
The differences were not evenly dis-tributed but especially frequent in those sectionswhere the original language was something otherthan English or German.
To check the homogene-ity of the devtest data we divided it into two sec-tions, one for documents of English or Germanorigin, and the other for the remainder.
It turnedout that scores were dramatically different for thetwo sections, as shown in Table 6.The reason for the difference is likely to be thatonly the En-De set contains source texts and trans-lations, while the other section contains paralleltranslations from the same source.
This suggeststhat it would be interesting to study the effects ofsplitting the training corpus in the same way be-fore training.9 ConclusionThe results of augmenting the training corpus withan extracted lexicon were inconclusive.
How-ever, the alignment reordering improved transla-tion quality, especially in the De?En direction.The result of these reordering experiments indi-cates that better word alignment quality will im-prove SMT.
The reordering method described inthis paper also has the advantage of only requir-ing two runs of Giza++, no additional resources ortraining is necessary to get an improved alignment.ReferencesAbhaya Agarwal and Alon Lavie.
2008.
Meteor, M-BLEU and M-TER: Evaluation metrics for high-correlation with human rankings of machine trans-lation output.
In Proceedings of the Third Workshopon Statistical Machine Translation, pages 115?118,Columbus, Ohio.123Chris Callison-Burch, David Talbot, and Miles Os-borne.
2004.
Statistical machine translation withword- and sentence-aligned parallel corpora.
In Pro-ceedings of the 42nd Annual Meeting of ACL, pages175?182, Barcelona, Spain.Alexander Fraser and Daniel Marcu.
2006.
Semi-supervised training for statistical word alignment.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meetingof ACL, pages 769?776, Sydney, Australia.Alexander Fraser and Daniel Marcu.
2007.
Measuringword alignment quality for statistical machine trans-lation.
Computational Linguistics, 33(3):293?303.Kuzman Ganchev, Jo?o de Almeida Varelas Gra?a, andBen Taskar.
2008.
Better alignments = better trans-lations?
In Proceedings of the 46th Annual Meetingof ACL, pages 986?993, Columbus, Ohio.Philipp Koehn and Kevin Knight.
2003.
Empiricalmethods for compound splitting.
In Proceedings ofthe tenth conference of EACL, pages 187?193, Bu-dapest, Hungary.Philipp Koehn and Josh Schroeder.
2007.
Experi-ments in domain adaptation for statistical machinetranslation.
In Proceedings of the Second Workshopon Statistical Machine Translation, pages 224?227,Prague, Czech Republic.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbst.
2007.
Moses:Open source toolkit for statistical machine transla-tion.
In Proceedings of the 45th Annual Meeting ofACL, demonstration session, Prague, Czech Repub-lic.Stefan Langer.
1998.
Zur Morphologie und Seman-tik von Nominalkomposita.
In Tagungsband der4.
Konferenz zur Verarbeitung nat?rlicher Sprache(KONVENS), pages 83?97.Yanjun Ma, Nicolas Stroppa, and Andy Way.
2007.Boostrapping word alignment via word packing.
InProceedings of the 45th Annual Meeting of ACL,pages 304?311, Prague, Czech Republic.Magnus Merkel and Jody Foo.
2007.
Terminologyextraction and term ranking for standardizing termbanks.
In Proceedings of the 16th Nordic Con-ference of Computational Linguistics (NODALIDA-2007), pages 349?354, Tartu, Estonia.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of ACL, pages 160?167, Sap-poro, Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of ACL, pages 311?318,Philadelphia, Pennsylvania.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In International Con-ference on New Methods in Language Processing,pages 44?49, Manchester, UK.Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In Proceedings of the Sev-enth International Conference on Spoken LanguageProcessing (ICSLP), pages 901?904, Denver, Col-orado.Sara Stymne, Maria Holmqvist, and Lars Ahrenberg.2008.
Effects of morphological analysis in transla-tion between German and English.
In Proceedingsof the Third Workshop on Statistical Machine Trans-lation, pages 135?138, Columbus, Ohio.Sara Stymne.
2008.
German compounds in factoredstatistical machine translation.
In Aarne Ranta andBengt Nordstr?m, editors, Proceedings of GoTAL,6th International Conference on Natural LanguageProcessing, LNCS/LNAI Volume 5221, pages 464?475.Sara Stymne.
2009.
A comparison of merging strate-gies for translation of German compounds.
In Pro-ceedings of the EACL09 Student Research Work-shop, Athens, Greece.124
