An Empirical Study on Rule Granularity andUnification Interleaving Toward an EfficientUnification-Based Parsing SystemMasaak i  NAGNFAATR In terpret ing  Te lephony  Research Laborator ies2-2 H ikar ida i ,  Seika-cho, Soraku-gun,  Kyoto  619-{}2, JA I 'ANnagat  a@atr - la .at r .co .
jpAbst rac tThis paper describes an empirical study on the op-timal granularity of the phrase structure rules andthe optimal strategy for interleaving CFG parsingwith unification in order to implement an eltlcientunification-based parsing system.
We claim that us-ing "medium-grained" CFG phrase structure rules,which balance tile computational cost of CI?G parsingand unification, are a cost-effective solution for mak-ing unification-based grammar both efficicnt and easyto maintain.
We also claim that "late unification",which delays unification until a complete CI"G parseis found, saves unnecessary copies of DAGs for ir-relevant subparses and improves performance signifi-cantly.
The effectiveness of these methods was provedin an extensive xperiment.
The results how that, onaverage, the proposed system parses 3.5 times fasterthan our previous one.
The grammar and the parserdescribed in this paper are fully implemented andased as the .lapmmse analysis module in SL-TRANS,the speech-to-speech translation system of ATR.1 I n t roduct ionUuifieation-based framework bins been an area of ac-tive research in natural anguage processing.
Unifi-cation, wbich is the primary operation of ibis frame.-work, provides a kind of constraint-checking mecha-nism for nlerging varioas information sources, sllcbas syntax, semantics, and pragmatics.
The computa-tional inefficiency of unification, however, precludestile development of large practical NLP systems, al-though the framework has many attractiw~ theoreticalproperties.The efforts made to improve tile efficiency of auriitication-ba.sed parsing system can be classified intofour categories.?
CFG parsing algorithm?
Graph unification algorithm?
Granunar epresentation a d organizati(m?
Interaction between CFG parsing and unilicationThere bave been well-known efficient CFG parsingalgorithms such as CKY \[Aho mid UllHnm, 77\], Ear~ley \[Earley, 70\], CtIAffl' (Kay, 80\], eatd I,R \[Aho andUllmaa L 77\] \['t'omita, 86\].
There have also been sev-eral recent in-depth studies into efficient graph uni-fication algoritbms, whose main concerns have beeneither avoiding irrelevant copies of l)AGs \[Karttunenand Kay, 85\] \[Pereira, 85\] \[Karttun .... 86\] \[Wrob-lewski, 87\] \[Godden, 90\] \[Kogure, 90\] \[Tomabechi,91\] \[E1aele, 91\], or the exhaustive xpansion of dis-junctions into their disjunctive normal forms \[Kasper,87\] \[Eisele mad l)Srre, 88\] \[Maxwell and Kaplmh 89\]\[l)arre and l~i,~ele, 90\] ickier, 901 \[Nat ...... 91\].There has, however, been litth: discussion regardingthe optimal representation f a grammar, or linguis-tic knowledge, in the unification-based framework,from tile engineering point of view.
Grammar or-ganization is highly flexible, as tile unification-basedframework uses two different forms of knowledge rep-resentation; atomic phrase structure rules and featurestructure descriptions.
Method selection greatly at"facts both the computational elficieney and the maiu-tenauce cost of the system.
There luL~ also been littlediscussion regarding optimal interaction between theCFG parsing process and the unification process inunificatlon-based parsing, which also greatly af|~ct~;overall performance.Here we introduce the notion of granularity, andsuggest mcdium-gra~ued phrase structure rules, inwhich morph~.syutactic specifications in the teaturedescriptious are expallded into phrase structure rules.We claim that it reduce the computational loads ofunification without intractably increasing tim lmulberof rules, and it is optimal ill tile sense that it sat isties both ettleiency and maintainability.
We also sug-gest late unification as another ~lution to tim COl)y-lug problem, as it avoids unnecessary copies of irrelevant subparses by delaying unification mttil a COln-ph:te CI,'G parse is found.In tile following sections, the design and iml)lementatiun of tim medimn-grained phrase structure rulesin explailmd, then the implementation f the late uni:tication is illustrated, anti finally the elfectiveness ofthe proposed nlethods is proven in experiments.ACrF.S DE COLING-92, NANTES, 23-28 AO~rf 1992 1 7 7 Pat~.
OF COt.lNG-92, NAN'ri~.S, Aua.
23-28, 1992Granularity of Phrase Constraints in Phrase Constraints in Nmnber of PhraseStructure Rules Structure \]Eules Feature Descriptions Structure RulesExtremely-Coarse-Grained weak very strong .
1 ~ 10Coarse-Grained medium strong 10 ~ 100Medium-Grained strong medimn 100 ~ 1000Fine-Grained very strong weak 1000Table 1: Granularity of phrase structure rules characterized by tile number of rules and the strength of linguisticconstraints in tile phrase structure rules aJtd the feature descriptions2 The Granular i ty  of  PhraseStructure  Rules2.1  Granu lar i tyPhrase structure rule granularity has been intro-duced to refer to the amount of linguistic constraintsspecified in the atomic CFG phrase structures ruleswithout annotations.
The rule granularity spectrumhas been classified into four categories as shown inTable 1, using the number of grammar rules ms a rues-sure.Unification-based grammars, in general, are char-acterized by a few general annotated pbrase structurerules, and a lexicon with specific linguistic descrip-tions.
This is especially true for HPSG \[Pollard andSag, 87\] and JPSG \[Gunji, 87\], which are to be cat-egorized as extremely-coarse grained, as they drasti-cally reduce the nmnber of phrase structure rules intotwo for English and one for Japanese, respectively.
Inthese frameworks, the only role of the phrase struc-ture rules is to provide a device for combining a headwith its complement.
Most linguistic constraints arestored in the feature descriptions.Coarse-grained rules have been characterized asa grammar consisting of atonfic phrase structurerules with medium constraints, and feature descriptions with strong constraints.
Medium-grained ruleshave been characterized as a grammar consistingof atomic phrase structure rules witb strong con-straints, and feature descriptions with mediuln con-straints.
Medium-grained rules differ from coarse-grained rules in that they include morpho~syntax inthe phrase structure rules, while coarse-grained rulesinclude them in the feature descriptions.
This meansthat medium-grained rules are strong enough to de-rive syntactic structures from atomic phrase structurerules without feature descriptions.Grammars for conventional NLP systems usingsimple or augmented CFG fall into the category offine-grained rules, which represent most of linguisticconstraints as CFG phrase structure rules, and thenumber of rules usually amounts to an intractablenumber of several thousands for practical applica-tions.2 .2  Ma inta inab i l i ty  and  E f f i c iencyIn unification-based framework, a linguistic con-straint cart either be described as atomic context-fleephrase structure rules, or as feature descriptions inannotations and lexical entries.
As the number ofatomic phrase structure rules decreases, the numberof feature descriptions increases.It is true that the lexieo-syntactic approach makestile granunar modular and improves its maintainabil-ity by reducing the number of rules.
However, it mustbe noted that the computational cost of disjunctivefeature structure unification, in the worst ease, is ex-ponential in the nmnber of disjunctions \[Kasper, 87\],whereas tile cost of CFG parsing is o(N s) in the inputlength N. Therefore, extreme rule reduction resultsin inefficiency.
This overwhelms the benefits of themaintainability of the reduced number of rules sincegrammar development is essentially a trial-and-errorprocess and requires a short turn-around time.
How-ever, the cost for CFG parsing also increases as thenumber of rules increases.
Therefore, we must chosetile granularity so that the reduction in unificationcost outweighs tile increase in CFG parsing cost, inorder to gain overall etfieiency.3 The HPSG-Based  JapaneseGrammarsIn this section, we illustrate the difference between"coarse-grained" rules and "medium-grained" rulesusing our HPSG-based spoken-style Japanese grarn-lnal 'S as an  exa lup le ,We have developed two unification-based gram-mars with different granularity l, which are essen-tially based on tIPSG and its application to Japanese(JPSG), for the analysis module \[Nagata and Kogure,90\] of an experimental Japanese-to-English speech-to-speech translation system (SL-TRANS) \[Morimoto eta l .
,  90\].We have selected the "secretarial service of an inter-national conference registration" as our task domain,in which a conversation between a secretary and aquest ioner  is car r ied  out .
T i le  Japanese  grauunars~however, ~tre not task-specific, but rather general-purpose OlleSj which cover a wide range of pllenonl-I Historically speaking, we fil~t developed coarse-grainedrules &lid then we nlallllally tl'al|sfonned them into medium-grldned rules for e|licicncy.ACTES DE COL1NG-92, NAmes, 23-28 hotyr 1992 1 7 8 PRoc.
OF COLING-92, NANTES, AUG. 23-28, 1992ena at ruazly linguistic levels from syntax, and semantics, to pragmatics using typcd feature structure de-scriptions.
The linguistic phenomena covered in thesegrammars include:?
l, 'undamental Constructions: causative, passive,benefactive, negation, interrogative, tc.,?
Control and Gaps: subject/object ontrol,?
Unbounded Dependencies: topic, relative,?
Word Order Variation and Ellipsis.3.1 Coarse -Gra ined  Rules  vs.Medium-Gra ined  RulesThe coarse-grained HPSG-based Japanese grammarhas about 20 generalized phrase structure rules, whilethe medium-grained grarmnar has about 200 phrasestructure rules.
Both gra, lnmars use the same lexiconwith a vocabulary of about 400.
~In the coarse-grained grarmnar, phrase structurerules only refer to the relative position l)etween thefive basic syntactic ategories for Japanese: verb (V),noun (N), adverb (ADV), postposition (P), and at-tributive (ATT).
Most of the specific linguistic infor-mation is encoded as feature descriptions in eitherthe annotation of the l)hrase structure rules or thelexical entries.
In principle, there is no distinctionas to whether a constituent is lexical or phrasal, andno subcategories of the 5 basic categories.
This con-tributes greatly to the reduction in the numbcr ofphrase structure rules, which results in better gram-mar maintainability.
We present all the phrase struc-ture rules of the coarse-grained Japanese grammar inAppendix A.It has been noticed that the extensive use of dis--junctions in feature descriptions, which results fromthe reduction of the number of phrase structure rules,is the main cause of incfficieney in the coarse-grainedversion of the grammar.
The three major sources ofdisjunctions are, lnorpho-syntactic specifications fordiverse expressions in the final part of the sentence,frec word order and ellipsis of verb complements ( ub-eat slash scrambling), and semantic interpretation ofdeep case and aspect, where the first two particularlyare the problems in spoken-style Japanese.We have manually converted the coarse-grainedphrase structure rules into medium-grained rules toreduce thc computational cost of unilication.
First,we divided each of the basic categories into severalsubcategories.
Then, we divided the coarse-grainedphrase structure rules according to the subcategorics.qb kee I) the grammar eadable, however, we chooseto leave the subcat slash scrambling and the semantic2We also }lave aalother vel~iOll of tile gF~nlllal" for tile sam,:8t|bCOll)lls, whlcll is nsed for tile continuous peech l'ecogni-tion module \[Takez.awa el, ~xl.
, 911.
It only imea atoaalc CFGla31esp a31d the \]lulll}~r of rules ~llOUll{S to Inol~ thall 2,0(~,It is, thcrefore~ categolJzed ~-s a tin,grained gr~Htnar in ourdefiltition.interpretation undone, and nmde extensive fforts toexpand the morpho-syntactic speeificatioas.3.2 Example:  Med ium-Gra ined  Rulesfor P red icate  Verb PhrasesIn this section, we illustrate the process of transfofmarion using a predicate verb l)hrasc production rulcas an example.
Japanese predicate phrases consistof a main verb followed by a sequence of auxiliariesazld sentence final particles.
There is an ahnost otto-dimensional order of verbal constituents such as inFigure l, which reflects the basic hierarchy of theJ apanese sentence structure.Kernel verbs occur first in a predicate phrase se-quence.
Voice auxiliaries precede all other auxil-iaries, and within this category, the causative auxil-iary (sa)se,'u precedes the passive auxiliary (ra)re~t.Aspect auxiliaries, such a.s the progressive auxiliary(Ie)ivu precede modal auxiliaries ;rod follow voiceauxiliaries.
Modal auxiliaries are classified into twogroups with respect o the relative order of negativeand tense auxiliaries.
Mood1 iuehldes the optativearlxiliaries, such as tai (want), beki (should/must),etc.
Mood2 includes the evidential or inferentialauxiliarics uch as rashii (seem/look), kamoshirenai(may), etc.
Negative auxiliaries uai, u (not) followvoice, aspect, and mood l auxiliaries, and precedetense and mood2 auxiliaries.
Tease auxiliaries la,da (-ed) show irregular behavior.
They follow thevoice, aspect, mood1, and negative auxiliaries, andprecede the mood2 auxiliaries.
They also can tollowthe mood2 auxiliaries.in the coarse-grained grammar, we provide a singlephrase structure rule for the phcnomena.v~(v  AUXV) O)The order constraints between auxiliaries are spec-ified in the annotution of rule (1) and each lexical entry by the combination of tile syntactic fea-tures, such as the synlheadlsubcat for preceding con-stituents, tile synlheadlcoh for following constituents,and the syn\[headlroodl for the position of the constituent~ in the verb phrase hierarchy.
For example,the causative auxiliary verb sern has the following,feature bundles in its syn{headlmodl feature.\[\[CAUS +\] \[DEhC -1 \[hSPC - \]  \[DONT - \ ]  \[OPTT - \ ]\[IEGT - \ ]  \[PhST - \ ]lEWD - \ ]  \[TENT - \ ]  \[PONT - \]  \[POLT-AUX - \ ]  \[INT~ -\]\[SFP-I - \ ]  \[SFP-2 - \ ]  \[SFP-3 - \ ] \ ]In converting the rule, first we have claasitied theverbal phrasal categories according to the hierar.ehy, e.g.
V-kernel, V-aspect, V-moodl, V-negt, V-mood2~ and V-tease, then we have subcategorizedthe auxil iari~ as shown in Table 2.
Thus, the coarse-grained phrase structure rule (1) is converted to the32 medium-grained grammar rules in Appendix BACRES DE COLING-92.
NANTES, 23-28 AOt~W 1992 1 7 9 Prtoc.
OF COLING-92, NANTI~S, AUG. 23-28, 1992kernel < voice < aspect < moodl < negate < tense < mood2 < tense(sa)seru (te)iru tai nai ta rasii ta(ra)reru (te)morau tagaru  n da desu umasu darouFigure l: The predicate hierarchy of JapaneseAUXV-causAUXV-deacAUXV-aspcAUXV-dontcausative auxiliary: (sa)sei'upassive auxiliary: (ra)reruaspect auxiliary: (~e)iru, Oe)a(ubenefactive auxiliary: (le)tnorauAUXV-optt optative auxiliary: tai, bekiAUX%negt negative auxiliary: nai, nAUXV-tense tense auxiliary: la, daAUXV-evid evidential auxiliary: rashii, darouAUXV-copl copulative auxiliary: da, desuTable 2: Subcategories of auxiliaries in the medium-grained grammar4 Interleaving CFG Parsingand Unification4.1 S t ra teg ies  fo r  Eva luat ing  FeatureDescr ip t ionsUnification is an expensive operation, so the point ofevaluating feature descriptions during CFG parsinghas serious affects on the overall performance.
Wehave implemented two strategies for feature descrip-tion evaluation:Ear ly  Unif icat ion (Step-by-step St rategy)Featnre descriptions are evaluated step-by-step,at each rule invocation in the CFG parsing.Late Unif icat ion (P ipe l ine St rategy)  Featuredescriptions are evaluated when a complete CFGparse is found.
The "well-formedness" of a parsederived from atomic CFG rules is verified by eval-uating associated feature descriptions.The granularity of the phrase structnre rules isclosely related to the proper selection of the evalua-tion strategy.
Since the atomic phrase structure rulesill the coarse-grained grammar are not so strong asto constrain syntactic structures, we have to employthe early unification to avoid a nnmber of irrelevantsubparses which should have been eliminated by theevaluation of annotations.
IIowever, since the atomicrules in the medium-grained grammar have detailedmorpho-syntax specifications, they should be able toavoid irrelevant copies by using the late unification.4 .2 Imp lement ing  the  Eva luat ionS t ra teg iesWe have implemented the various evaluation strate-gies by doing additional housekeeping in the underly-ing parser.
The parser used here is called the TypedACTES DE COLING-92, NANTES, 23-28 AOfYr 1992 1 80procedure  AcpContinue(chart)begini f  SatisfySuspendingCondition?
(chart)then return chartelseAcpContinue(AcpOneStep(chart))endprocedure  AepOneStep(chart)beginpendingedge = GetPendingEdge(chart)AddEdge(pendingedge)i f  EdgeActive?
(pendingedge) thenTryToContinueActiveEdge(pendingedge, chart)elseTryToContinuelnactiveEdge(pendingedge, chart)ProposeProductlons(pendingedge)return chartendFigure 2: Iterative Rule Invocation in an ActiveChart Parsing AlgorithmFeature Structure Propagation Parser (TFSP Parser)\[Kogure, 89\], which is based on the active chart pars-ing algorithm \[Kay, 80\] and typed feature structureunification \[Ait-Kaci, 86\].Tile active chart parser and the unification algo-rithm are implemented in C on Sun4, which is a10-MIPS work station.
The unification algorithmis based oil nondestructive graph unification \[Wrob-lewski, 87\], which we extend to treat negation, loop,type symbol subsumption relationships, and disjunc-tiou.
Successive approximation \[Kasper, 87\] is usedfor disjunctive feature structure unification.The Active chart parsing algorithm basically con-sists of chart initialization and iterative rule invo-cation.
The basic part of the iterative rule invoca-tion is shown in Figure 2.
AcpContinue checks thesuspending condition and calls rule invocation recur-sivcly.
AcpOneStep carries out a cycle of rule invo-cation which consists of getting a new pending edge(GetPendingEdge), adding it to the chart (AddEdge),combining active and inactive edges (TryToContinue-ActiveEdge/TryToContinuelnactiveEdge), and propos-ing new edges (ProposeProductions).
The parser stops(SatisfySuspendingCondition?)
when it finds an inac-tive edge whose starting and ending vertex are theleft-most and right-most vertex of the chart, respec-tively, and whose label is the start symbol of thegranunar.PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992In early unification, the feature descriptions areevaluated when the edges are combined, while in lateunification, they are evaluated iu the chart suspend-ing condition check only if tile clmrt suspending con-dition bolds.
Delaying unification is implemented byadding a slot edge.parse to the edge structure, whichkeeps a list of the pair of active aud inactive edgesconstructing the edge.
If either or both of the ar-gument feature structures of the unification have notbeen evaluated, they are recursively evaluated to getthe target feature structure.It has to bc j~oted that some derivations that ter-mhmte when feature descriptions are evaluated, maynot terminate if they are ignored.
For example, it ispossible to write a rule for unbounded ependencylike (2), in which m~ element in tile subcat featureis moved to the slash feature, to introduce slashedcategories dynamically 3.--~ (~) (2)Ignoring feature descriptions in the rule may causeaal infinite loop.
Therefore, feature descriptions arcforced to be evaluated, when rules that cause a loopare encountered in late unification.5 ExperimentTile effectiveness of the strategies proposed in thispaper call be judged by observing their behavior inpractice.
We have tested the time behavior of pars-lug with respect o rule granularity and interleavingstrategy of CFG parsing and unification.
85 sam-ple sentences are used.
These are selected from thesample subcorpus of ATR's dialogue corpus whoseteu~k dornain is the "secretarial service of an interna-tional conference".
The average length of the samplesentences i 11.0 characters, and their maximum andminimum length are 2 and 28 characters, respectively.We have developed two 3 al)anese grammars of dif-ferent granularity with ahnost the same coverage.The coarse-grained rules consist of 22 generalizedphrase structure rules with detailed ti~.ature descrip-tion ill their annotations, while the medium-grainedrules consist of 164 detailed phra.se structure ruleswith less detailed feature descriptions.
Both gram-mars use the same lexicon with about 400 lexical cntries.
We haw: ,also implemented two different fcature descrilrtion evaluation modes in tile active chartparser.
'file early unificalion cwdurdion mode evah>ates tile feature descriptions at each rule application(tile step-by-step strategy).
The late uniJica*io, cval-ualio~ mode, on the other hand, delays unificationuntil a CUlnl)lete syntactic structure is tk~und lly usingthe atomic phrase structure rules only (tile pipelin,~strategy).The average parsing tilne is shown ill Table :1 Itshows that, on average, tile m(~diun>grained glumSin o/u.
imp le lnentat ion ,  for e| l ic iency l'e~ualls, w~: gellotal~"all the appro l ) f iate  combinat ions  of sul)cat and  sl:tsl~ in ~ulV&IICe, at ld kee I) thert l  ~.s a d is junct ive  fe~tttll'e st rttcLiil'OAortas DE COTING-92, NANTrS, 23-28 ^o?rr 1992 1 8 1I/.ule GrmndarityUnification ModeAverage Runt|meRelative SpeedTable 3: Aw~ragc parsing time with respect o grail-ularity and unification mode~ 0I:260?
co~e,  Eady^ Mmdlum, Early?
?
?^ ?xa xx x AxFigure 3: Comparison of Coarse-Grained ILules andMedimn-(-;rained Rulesmar rules are 1.7 times more elllcient han the coarsegrained rules ill the early unit|cation mode, and thattile late unification mode is 2.0 times more etncientthan tile early unilieation mode with the medium~grained gramniar.
Moreover, when tile mediuul-grained grauunar ules and tile late unification modem'e combined, tile new parser runs 3.5 times fmqterthan till', l/revklus olle using the coarse-grained gram-mar rules and the early unities|ion.
46 DiscussionThe relationship between inlmt length and 1)arsingtime with resl)CCt to grammar gramllarity is shownill Figure 3.
Ill general, tim medimn grained ru/e.spertormed bet, ter than the coarse grained rules.
This13: l ldency  beCOl l les  dearer, *is tile 8e l l te l lee  le l lg\ ] .h ill~crelmes.
This reslllLs from the redllction of disjunc..tiw!
feature descriptions whose computational cost in-4"1'}m rq~l)l-Oach of st~Villg illllleCc~ssilay c:ol}i(~s for ill-d~!V~tlasub}Dalai.- ~, \]it a iI,%i.~\]llg ptot:ess |)~,.
l&tc IIIlil\[c#tt\]oll is el thogonat|\[tl t ~le a\]lpl o~;hes  ,}f sav ing  illtll{:CeSS&ly c~pieS wi th in  a unif ies-l ion in'acess, such a_s \[T,mla\[mchi,  9@ The lc fmv,  the ctfects (ffspeed up  citii be mult ip l ied.
We haw~ gdte;tdy impleme|~ted his(lll~kqi d?
:stltlCtiVe g~l,~l)ll Iltli|i(:atiOll, &lid the l)l*~|illlillal y {:XpeFilIl~lll l('Slllt shows that  th,: \])~l*er wit l l  new ulli|iel" rlltls a\[lllOSlt wh:c am ta~st *Ls the one t'el)orte(| ill this l);tl)el-.Paoc.
el: COI,ING-92, NAm'ES, AUG. 23-28, 19921~01 a Madlum, ~ly a lf~l * IAtdiusa, Ls~^ a a^ ^a a^ aa  ~ * a a *0 S t0  ~S ~0 ~ 30Figure 4: Comparison of Early Unification and LateUnificationcreases exponentially in the number of disjunctions.However, we occasionally encounter sentences whichare parsed faster using coarse-grained rules ratherthan medium-grained rules.
This is because the in-crease in the atomic CFG parsing cost exceeds thereduction of tbe unification cost.The relationship between input length and parsingtime with respect to unification evaluation mode isshown in Figure 4.
This shows that the late unifica-tion mode is significantly more efficient han the earlyunification mode.
It also shows that the parsing timein the late unification mode seems to be lmlynomial(not exponential) in the input length, while that inthe early unification mode varies widely and irregn-larly.
This is because the parsing time in tile late uni-fication mode is mainly predominated by the cost ofatomic CFG parsing by dclaying unification, whereasthe parsing tiule in the early unification mode ismainly predominated by the cost of unification.We have demonstrated tbc effectiveness of com-bining medium-grained phrase structure rules withlate unification.
Experiment results suggest that newprospective techniques for speeding up ratification-based parsing exist.The first is automatic transformation of phrasestructure rules, which converts disjunctions in the fea-ture descriptions into atomic phrase structure rifles.Some disjunctions such as subcat slash scrambling areso reguhu" that it seems possible to exl)and them intoa set of CF(; rules using forlnal i)rocedures.
If thegrammar compiler can perform this kind of transfor-mation automatically, we can gain efficiency withoutlosing grammar maintainability.The second is feature-sensitive lazy unification.Unilication is used for both huihling up a structureusing infornratiou-propugat, ion and blocking rule a F-plication using constraint-checking.
If the grammarcompiler can separately output those features forconstraint-checking such ~ syntactic llcatnrcs, andthose for information-propagation such as semanticrel)resental;ions , irrelevant subparses can be prunedefficiently by evaluating the constraint-checking fea-tures first.
Unification is an associative and comnm-tative operation, so the same results from the feature-sensitive lazy unification are assured.The third is parallel implementation of aunification-based parser based on late unification(pipe-line strategy).
In early unification (step-by-stepstrategy), it is hard to perform parsing in parallelbecause the CFG parsing process and the unifica-tion process depend strongly on each other.
How-ever, both processes are completely separated in thepipe-line strategy .
Therefore, it is easy to introducethe existing parallel algorithms to both CFG pars-ing and unification.
It is estimated that most featuredescriptions can be evaluated in parallel, at least, atthe \]exical level, because unification-based grammarssuch as IIPSG derive phrase structure by iterativelypropagating the local constraints.7 Conc lus ion\]n this paper, we have proposed two techniques forimplementing an efficient unification-based parsingsystem, which, when combined, significantly improvethe overall performance.
The first is changing thegranularity of the context-free phrase structure rulesinto medium-grained rules.
This enables us to re-duce the amount of unification for feature descrip-tions without intractably increasing the number ofphrase structure rules.
The second is late unifica-tion in which the unification for feature descriptionsis delayed until a complete CFG parse is found.
Thissaves unnecessary copies of feature structures whichare wasted for irrelevant subparses.We have tested the time behavior of the parsingsystem using two granunars of different granularity(coarse/medium) and two different strategies for in-voking unification (early/late).
It is proved that, onaverage, late unification using medium-grained rulesparses 3.5 times fester than the previous early unifi-cation using coarse-grained rules.AcknowledgmentsThe author would like to thank Dr. l(urematsu, and all then,embers of A2'R huerpreting q'elephony Besearch I,al)s. fortheir constant help m)d fl'tfitflfl discussions.References\[Aho eJld Ullman, 77\] Aho, A. and Ulhnan, J., Principles ofCompiler Design Addismi-Wesley, 1977.\[Ai't-Kaci, 86\] A~'t-l(aci, lI., "An Algebraic Semantias Ap-ploach to the Effective Resolution of Type l~;quations, ''Journal o\] Theoretical Computer Science ~5, 1986.\[Crater, 90\] Carter, D., "Efficient Disjunctive Unification for\[~ottonl-Up Paining," Proc.
o\] COLIN(;-90, 1990.\[I)Sn'e and l~iselc, 90\] DSn'e and Eisele, "Featm'e Logic whhDi@mctive Unification," Proc.
o\] COLING-90, 1990.\[Earley, 70\] Era'Icy, J., "An Efficient ConLext-l,'rec Parsing AIgorithm," AG'/~i, 13, ~, 1970.\[Eisele and I)Srre, 88\] Eisele, A. m,d D~rre, J.. "Unillcat.lon ofDisjunctive Feature Descrlptions," Prom o\] ihe ~Oth A CL,1988.ACITe~q DE COLING-92.
NANTES, 23-28 ^ ofrr 1992 1 8 2 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992\[Emele, 91\] lgmele, M., "/Jnitlcation with Lazy Non-ltedun-dant Copying," Proc.
o\] the $9ih A UL, 1.~91.\[Godden, 90\] Godden, K., "l,azy lhdfication," Prec.
of the~8*h A CL, 1990.\[Gu*kii, 87\] Clu*~ii, T., Japanese Phrase Structure GrammarA Unification-Based Approach, t)o*xh,echt, lteidel, 1987.\[K~sper, 87\] Kasper, It., '% Unification Method for Disjunc-tive Feature Deacfipthms," Proc.
of the ~5th A CL, 1987.\[Km~tunen, 86\] Karttunmt, L., D-PATR- A l)evelopment En-vironment for Unification-Bmsed Ormtnnara, CSLI-8C~91,CSLI, 1986.\[Karttunen mid Kay, 85\] Karttunen, L. and Kay, M., "Strut-time Shari*tg with Bin~as?
Trees," Proc.
o/the $3rd A CL,1985.\[Kay, 801 Kay, M., Algorithm Schemata and Data Slvucturesin Synlaeilc Proce~slnO, Tedudcal tleport CSl,-80q2, Xe-rox PAItC, 1980.\[Kogm~, 89\] Kogure, K., "Pruning dapmmse Spoken Sentence.~b~ed on l IPS(l," Prec.
oJ lhe IWPT, 1989.\[l{og~i~, 99\] Kogu~, K., "Strategic Leu.y lnerementM (3opyGraph Unification," Proc.
of COLING-90, 1999.\[Maxwell emd Kaplaa*, 89\] Maxwell, J. and Kaplan, 11., "AnOverview of Disjtmctive ConstreJnt Satisfaction," Proc.oa t fhe IWPT, 1989.\[Mozqmoto et al , 90\] Morimoto,T.
et al, "Integration ofSpeedt Recognition altd Language }'roceasing in SpokenL~ngn~gc Trmislatlon Syntetzl (8I/ I 'RANH)," llrac, of theICSLP, 1.990.\[Nagata mid Kogure, 90\] Nagata, M. mM l<.ogm~e, K.,"\[\[PSO~B~.sed Lattice Parser for Spoken Japanese in aSpoken I,~ngunge Tr~amlation System," Prec.
o\] ~he 9lhECAI, 1990.\[Nakeato, 91\] Nakmm, M., "Co~L~traint Projection: An Ef-ficient 'Freatment of l)isjmlctive Feature l)cscriptions,"Proc.
of 2gth A 6'L, 1991.\[Pereira, 85\] Perelra, l,'., "A Stl~mtu~-Sharlng liepl~sent*~tlon for \[Jnitic,~tion-ltased l nnnMisnas," Prec.
o\] lhe 23rdA UL, 1985.\[Pollard mtd Sag, 87\] Pollard, (3. and Sag, I., An Information,-Based Syntax and Semantics, CSLI l,ecture Notes No.
13,CS\[,I, 1987.\[T~kegawa et M.,  91\] Tak~zawa, T. et M., "Linguistic G'on-strahtts for Continuous Speech llecognition in (h,al-Directed DiMogue," Prec.
o\] I(,'ASSP-91, 1991.\[Tomabechi, 91\] Tomabedfi, l l., "Quasi-Destmctlve GraphUnification," Proc.
of 29th A CL, 1991.\[Tomita, 86\] *fomita, M., Efficient Parsin9 Jor Natural i,an9uage: A Fast Algorithm for Practical Systema, I(hlwerAcademic Puhlishms, 1986.\[Wroblewuki, 87\] Wroblewski, D., "Nondestructive (;ra|,hUnification," Proe.
o| the 6th AAAI, 1987.Append ixA Coarse-grained Gramn,arRules for JapaneseThe ll~k\[l/e of each rule is showl l  ill ILhe cOlnlllellt~where  t.he su\[t~x -al L -ch, -coord means  adjm~ction,COnlp lenmntat ion.
a im coord inat ion ,  respect ive ly .
; ; ; Start Symbolstart -> (V) j star~xute; ;; ~0mt Phras~n -> (a t t  n) ; a t t -n -ahxt -> (p n) ; p-n-ahit -> (v :gtt) ; v-i 'n-chn -> (v n) ; w-at=ahit -> (p it) ; n-lt~coord; ; ;  Complox Ithd Coral)erred IJoult~* -> (nprefix zt)n -> (n  nBu~fix); ; ; Postpoz i t iona l  Phrauop > (n postp)p -> (v poutp)p -> (p l, oBtp); ; ; Adverbial |)ltx'~Soadv -> (adv po.
tp )adv -> (v ~adv)adv -> (~t ~adv); ; ; Vurb Phr~sov ~> (p v)v .> (~dv v); ; ; Prudicat~ Verb PhraB~v -> (v auxv)v -> (~t auxv)v -> (adv aunt); ; ; Verb InZloctioltv -> (v~t~ vin~l)auxv - )  (allxvste~ ~in f l )npre~ix-n-ahn-n -ahit-llsurfix-chIr-postp-ch*"pontp-chp"postp?chadv-postp-chv-fadv-chn-lady-oh; p" v"altyadv~v-ahv-auxv-chll-ttllXv-chadv-~uxv-chv--at e=- in* lauxv-st om~inflB Medium-grained Rules iorJat)anese Verb PhrasesThe coarse -gra ined  grammar  rule (1) is conver ted  tothe fo l lowing 32 med ium-grMned ~;rammar ules.V-voice -> (V-ko*a~el AUXg-volc~V-asp,t:t -> (ADV AUXV-a~pc)V-a~poct -> (hOt l l l lV-dont)V-moodl --> (V-k~rltol AUXV--ot,tt)V~moodl -> (V-voice AUIV~optt)V-moodl -'> (V-a8puct AUXV-optt)V'-ltegt > (V~kexltt*l AOXV-lteg?
)V-negt --> (V-voice AOXV-negt)V~negt -> (V-aspect hll\]\[V~zlegt/V-.m~gt .-> (V-moodl lUlV-negt)V-tonue -> (V-kernel AIJXV-tClltce)V~t~Itse -> (V=voico AUlV-toIt~e)V-ton.~e -> (V-aspect AUXV-t,itsu)V~toltse -> (V-moo~1 AUXV~telI.~B)V" t.nue -> (V"n~gt AllJfV--tellse)V-mood2 " > (V-kelae\]  hUXV-,!vid)V'taood2 -> (V-voice hU~V'-evid)V-mood2 -> (V-aap~ct AUXV-evid)V-mood2 -> (V-moodl AU~V-evid)V-mood2 -> (V-negt AUXV-evid)V--mood2 -> (V-toltBe AUXV-ovid)V-tense -> (V-mood2 AO~V-tense)AUAV voice "-> (AUXV-caus)AOIV' voice "> (AUiV-'duac)AUXV-voice ~> (AIH\[V-caus AUlV-deac)V -> (V-kq~rnel)V -> (V-voice)V -> (V-aspect)V -> (V-moodl)V-'> (V-negt)V > (V refuse)V ?
> (V-mood2)AcrEs DE COL1NG-92, NANTES, 23-28 AOUT 1992 1 8 3 PRo(;.
OF COLING-92, NANrES, AUU.
23-28, 1992
