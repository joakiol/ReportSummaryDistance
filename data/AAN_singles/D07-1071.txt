Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
678?687, Prague, June 2007. c?2007 Association for Computational LinguisticsOnline Learning of Relaxed CCG Grammars for Parsing to Logical FormLuke S. Zettlemoyer and Michael CollinsMIT CSAILlsz@csail.mit.edu,mcollins@csail.mit.eduAbstractWe consider the problem of learning toparse sentences to lambda-calculus repre-sentations of their underlying semantics andpresent an algorithm that learns a weightedcombinatory categorial grammar (CCG).
Akey idea is to introduce non-standard CCGcombinators that relax certain parts of thegrammar?for example allowing flexibleword order, or insertion of lexical items?with learned costs.
We also present a new,online algorithm for inducing a weightedCCG.
Results for the approach on ATISdata show 86% F-measure in recoveringfully correct semantic analyses and 95.9%F-measure by a partial-match criterion, amore than 5% improvement over the 90.3%partial-match figure reported by He andYoung (2006).1 IntroductionRecent work (Mooney, 2007; He and Young, 2006;Zettlemoyer and Collins, 2005) has developed learn-ing algorithms for the problem of mapping sentencesto underlying semantic representations.
In one suchapproach (Zettlemoyer and Collins, 2005) (ZC05),the input to the learning algorithm is a training setconsisting of sentences paired with lambda-calculusexpressions.
For instance, the training data mightcontain the following example:Sentence: list flights to bostonLogical Form: ?x.flight(x) ?
to(x, boston)In this case the lambda-calculus expression denotesthe set of all flights that land in Boston.
In ZC05it is assumed that training examples do not includeadditional information, for example parse trees ora) on may four atlanta to denver delta flight 257?x.month(x,may) ?
day number(x, fourth)?from(x, atlanta) ?
to(x, denver)?airline(x, delta air lines) ?
flight(x)?flight number(x, 257)b) show me information on american airlines from fort worthtexas to philadelphia?x.airline(x, american airlines)?from(x, fort worth) ?
to(x, philadelphia)c) okay that one?s great too now we?re going to go on apriltwenty second dallas to washington the latest nighttimedeparture one wayargmax(?x.flight(x) ?
from(x, dallas)?to(x,washington) ?
month(x, april)?day number(x, 22) ?
during(x, night)?one way(x), ?y.depart time(y))Figure 1: Three sentences from the ATIS domain.other derivations.
The output from the learning algo-rithm is a combinatory categorial grammar (CCG),together with parameters that define a log-linear dis-tribution over parses under the grammar.
Experi-ments show that the approach gives high accuracy ontwo database-query problems, introduced by Zelleand Mooney (1996) and Tang and Mooney (2000).The use of a detailed grammatical formalism suchas CCG has the advantage that it allows a system tohandle quite complex semantic effects, such as co-ordination or scoping phenomena.
In particular, itallows us to leverage the considerable body of workon semantics within these formalisms, for examplesee Carpenter (1997).
However, a grammar basedon a formalism such as CCG can be somewhat rigid,and this can cause problems when a system is facedwith spontaneous, unedited natural language input,as is commonly seen in natural language interfaceapplications.
For example, consider the sentencesshown in figure 1, which were taken from the ATIStravel-planning domain (Dahl et al, 1994).
Thesesentences exhibit characteristics which present sig-nificant challenges to the approach of ZC05.
For ex-678ample, the sentences have quite flexible word order,and include telegraphic language where some wordsare effectively omitted.In this paper we describe a learning algorithm thatretains the advantages of using a detailed grammar,but is highly effective in dealing with phenomenaseen in spontaneous natural language, as exempli-fied by the ATIS domain.
A key idea is to extendthe approach of ZC05 by allowing additional non-standard CCG combinators.
These combinators re-lax certain parts of the grammar?for example al-lowing flexible word order, or insertion of lexicalitems?with learned costs for the new operations.This approach has the advantage that it can be seam-lessly integrated into CCG learning algorithms suchas the algorithm described in ZC05.A second contribution of the work is a new, on-line algorithm for CCG learning.
The approach in-volves perceptron training of a model with hiddenvariables.
In this sense it is related to the algorithmof Liang et al (2006).
However it has the addi-tional twist of also performing grammar induction(lexical learning) in an online manner.
In our exper-iments, we show that the new algorithm is consid-erably more efficient than the ZC05 algorithm; thisis important when training on large training sets, forexample the ATIS data used in this paper.Results for the approach on ATIS data show 86%F-measure accuracy in recovering fully correct se-mantic analyses, and 95.9% F-measure by a partial-match criterion described by He and Young (2006).The latter figure contrasts with a figure of 90.3% forthe approach reported by He and Young (2006).1Results on the Geo880 domain also show an im-provement in accuracy, with 88.9% F-measure forthe new approach, compared to 87.0% F-measurefor the method in ZC05.2 Background2.1 SemanticsTraining examples in our approach consist of sen-tences paired with lambda-calculus expressions.
Weuse a version of the lambda calculus that is closelyrelated to the one presented by Carpenter (1997).There are three basic types: t, the type of truth val-1He and Young (2006) do not give results for recoveringfully correct parses.ues; e, the type for entities; and r, the type for realnumbers.
Functional types are defined by specify-ing their input and output types, for example ?e, t?is the type of a function from entities to truth val-ues.
In general, declarative sentences have a logicalform of type t. Question sentences generally havefunctional types.2 Each expression is constructedfrom constants, logical connectors, quantifiers andlambda functions.2.2 Combinatory Categorial GrammarsCombinatory categorial grammar (CCG) is a syn-tactic theory that models a wide range of linguisticphenomena (Steedman, 1996; Steedman, 2000).The core of a CCG grammar is a lexicon ?.
Forexample, consider the lexiconflights := N : ?x.flight(x)to := (N\N)/NP : ?y.?f.
?x.f(x) ?
to(x, y)boston := NP : bostonEach entry in the lexicon is a pair consisting of aword and an associated category.
The category con-tains both syntactic and semantic information.
Forexample, the first entry states that the word flightscan have the category N : ?x.flight(x).
This cat-egory consists of a syntactic type N , together withthe semantics ?x.flight(x).
In general, the seman-tic entries for words in the lexicon can consist of anylambda-calculus expression.
Syntactic types can ei-ther be simple types such as N , NP , or S, or can bemore complex types that make use of slash notation,for example (N\N)/NP .CCG makes use of a set of combinators whichare used to combine categories to form larger piecesof syntactic and semantic structure.
The simplestsuch rules are the functional application rules:A/B : f B : g ?
A : f(g) (>)B : g A\B : f ?
A : f(g) (<)The first rule states that a category with syntactictype A/B can be combined with a category to theright of syntactic type B to create a new categoryof type A.
It also states that the new semanticswill be formed by applying the function f tothe expression g. The second rule handles argu-ments to the left.
Using these rules, we can parse the2For example, many question sentences have semantics oftype ?e, t?, as in ?x.flight(x) ?
to(x, boston).679following phrase to create a new category of typeN :flights to bostonN (N\N)/NP NP?x.flight(x) ?y.?f.
?x.f(x) ?
to(x, y) boston>(N\N)?f.
?x.f(x) ?
to(x, boston)<N?x.flight(x) ?
to(x, boston)The top-most parse operations pair each word with acorresponding category from the lexicon.
The latersteps are labeled ?> (for each instance of forwardapplication) or ?< (for backward application).A second set of combinators in CCG grammarsare the rules of functional composition:A/B : f B/C : g ?
A/C : ?x.f(g(x)) (> B)B\C : g A\B : f ?
A\C : ?x.f(g(x)) (< B)These rules allow for an unrestricted notion of con-stituency that is useful for modeling coordinationand other linguistic phenomena.
As we will see, theyalso turn out to be useful when modeling construc-tions with relaxed word order, as seen frequently indomains such as ATIS.In addition to the application and compositionrules, we will also make use of type raising and co-ordination combinators.
A full description of thesecombinators goes beyond the scope of this paper.Steedman (1996; 2000) presents a detailed descrip-tion of CCG.2.3 Log-Linear CCGsWe can generalize CCGs to weighted, or probabilis-tic, models as follows.
Our models are similar toseveral other approaches (Ratnaparkhi et al, 1994;Johnson et al, 1999; Lafferty et al, 2001; Collins,2004; Taskar et al, 2004).
We will write x to de-note a sentence, and y to denote a CCG parse for asentence.
We use GEN(x; ?)
to refer to all possi-ble CCG parses for x under some CCG lexicon ?.We will define f(x, y) ?
Rd to be a d-dimensionalfeature?vector that represents a parse tree y pairedwith an input sentence x.
In principle, f could in-clude features that are sensitive to arbitrary sub-structures within the pair (x, y).
We will definew ?
Rd to be a parameter vector.
The optimal parsefor a sentence x under parameters w and lexicon ?is then defined asy?
(x) = arg maxy?GEN(x;?
)w ?
f(x, y) .Assuming sufficiently local features3 in f , search fory?
can be achieved using dynamic-programming-style algorithms, typically with some form of beamsearch.4 Training a model of this form involveslearning the parameters w and potentially also thelexicon ?.
This paper focuses on a method for learn-ing a (w,?)
pair from a training set of sentencespaired with lambda-calculus expressions.2.4 Zettlemoyer and Collins 2005We now give a description of the approach of Zettle-moyer and Collins (2005).
This method will formthe basis for our approach, and will be one of thebaseline models for the experimental comparisons.The input to the ZC05 algorithm is a set of train-ing examples (xi, zi) for i = 1 .
.
.
n. Each xi isa sentence, and each zi is a corresponding lambda-expression.
The output from the algorithm is a pair(w,?)
specifying a set of parameter values, and aCCG lexicon.
Note that for a given training example(xi, zi), there may be many possible parses y whichlead to the correct semantics zi.5 For this reasonthe training problem is a hidden-variable problem,where the training examples contain only partial in-formation, and the CCG lexicon and parse deriva-tions must be learned without direct supervision.A central part of the ZC05 approach is a functionGENLEX(x, z) which maps a sentence x togetherwith semantics z to a set of potential lexical entries.The function GENLEX is defined through a set ofrules?see figure 2?that consider the expression z,and generate a set of categories that may help inbuilding the target semantics z.
An exhaustive setof lexical entries is then generated by taking all cat-egories generated by the GENLEX rules, and pair-ing themwith all possible sub-strings of the sentencex.
Note that our lexicon can contain multi-word en-tries, where a multi-word string such as New Yorkcan be paired with a CCG category.
The final out-3For example, features which count the number of lexicalentries of a particular type, or features that count the number ofapplications of a particular CCG combinator.4In our experiments we use a parsing algorithm that is simi-lar to a CKY-style parser with dynamic programming.
Dynamicprogramming is used but each entry in the chart maintains a fullsemantic expression, preventing a polynomial-time algorithm;beam search is used to make the approach tractable.5This problem is compounded by the fact that the lexiconis unknown, so that many of the possible hidden derivationsinvolve completely spurious lexical entries.680Rules Example categories produced from the logical formInput Trigger Output Category argmax(?x.flight(x) ?
from(x, boston), ?x.cost(x))constant c NP : c NP : bostonarity one predicate p N : ?x.p(x) N : ?x.flight(x)arity one predicate p S\NP : ?x.p(x) S\NP : ?x.flight(x)arity two predicate p2 (S\NP )/NP : ?x.
?y.p2(y, x) (S\NP )/NP : ?x.
?y.from(y, x)arity two predicate p2 (S\NP )/NP : ?x.
?y.p2(x, y) (S\NP )/NP : ?x.
?y.from(x, y)arity one predicate p1 N/N : ?g.
?x.p1(x) ?
g(x) N/N : ?g.
?x.flight(x) ?
g(x)literal with arity two predicate p2and constant second argument c N/N : ?g.
?x.p2(x, c) ?
g(x) N/N : ?g.
?x.from(x, boston) ?
g(x)arity two predicate p2 (N\N)/NP : ?y.?g.
?x.p2(x, y) ?
g(x) (N\N)/NP : ?y.?g.
?x.from(x, y) ?
g(x)an argmax /min with secondargument arity one function f NP/N : ?g.
argmax /min(g, ?x.f(x)) NP/N : ?g.
argmax(g, ?x.cost(x))arity one function f S/NP : ?x.f(x) S/NP : ?x.cost(x)arity one function f (N\N)/NP : ?y.?f.
?x.g(x) ?
f(x) >/< y (N\N)/NP : ?y.?f.
?x.g(x) ?
cost(x) > yno trigger S/NP : ?x.x, S/N : ?f.
?x.f(x) S/NP : ?x.x, S/N : ?f.
?x.f(x)Figure 2: Rules used in GENLEX.
Each row represents a rule.
The first column lists the triggers that identify some sub-structurewithin a logical form.
The second column lists the category that is created.
The third column lists categories that are created whenthe rule is applied to the logical form at the top of this column.
We use the 10 rules described in ZC05 and add two new rules,listed in the last two rows above.
This first new rule is instantiated for greater than (>) and less than (<) comparisions.
The secondnew rule has no trigger; it is always applied.
It generates categories that are used to learn lexical entries for semantically vacuoussentence prefixes such as the phrase show me information on in the example in figure 1(b).put from GENLEX(x, z) is a large set of potentiallexical entries, with the vast majority of those en-tries being spurious.
The algorithm in ZC05 embedsGENLEX within an overall learning approach thatsimultaneously selects a small subset of all entriesgenerated by GENLEX and estimates parameter val-uesw.
Zettlemoyer and Collins (2005) present morecomplete details.
In section 4.2 we describe a new,online algorithm that uses GENLEX.3 Parsing Extensions: CombinatorsThis section describes a set of CCG combinatorswhich we add to the conventional CCG combinatorsdescribed in section 2.2.
These additional combi-nators are natural extensions of the forward appli-cation, forward composition, and type-raising rulesseen in CCG.
We first describe a set of combina-tors that allow the parser to significantly relax con-straints on word order.
We then describe a set oftype-raising rules which allow the parser to copewith telegraphic input (in particular, missing func-tion words).
In both cases these additional ruleslead to significantly more parses for any sentencex given a lexicon ?.
Many of these parses will besuspect from a linguistic perspective; broadening theset of CCG combinators in this way might be con-sidered a dangerous move.
However, the learningalgorithm in our approach can learn weights for thenew rules, effectively allowing the model to learn touse them only in appropriate contexts; in the exper-iments we show that the rules are highly effectiveadditions when used within a weighted CCG.3.1 Application and Composition RulesThe first new combinators we consider are therelaxed functional application rules:A\B : f B : g ?
A : f(g) (&)B : g A/B : f ?
A : f(g) (.
)These are variants of the original applicationrules, where the slash direction on the principal cat-egories (A/B or A\B) is reversed.6 These rules al-low simple reversing of regular word order, for ex-ampleflights one wayN N/N?x.flight(x) ?f.
?x.f(x) ?
one way(x).N?x.flight(x) ?
one way(x)Note that we can recover the correct analysis for thisfragment, with the same lexical entries as those usedfor the conventional word order, one-way flights.A second set of new combinators are the relaxedfunctional composition rules:A\B : f B/C : g ?
A/C : ?x.f(g(x)) (& B)B\C : g A/B : f ?
A\C : ?x.f(g(x)) (.
B)These rules are variantions of the standard func-tional composition rules, where the slashes of theprincipal categories are reversed.6Rules of this type are non-standard in the sense that theyviolate Steedman?s Principle of Consistency (2000); this princi-ple states that rules must be consistent with the slash directionof the principal category.
Steedman (2000) only considers rulesthat do not violate this principle?for example, crossed compo-sition rules, which we consider later, and which Steedman alsoconsiders, do not violate this principle.681An important point is that that these new compo-sition and application rules can deal with quite flex-ible word orders.
For example, take the fragment towashington the latest flight.
In this case the parse isto washington the latest flightN\N NP/N N?f.?x.f(x)?
?f.
argmax(f, ?x.flight(x)to(x,washington) ?y.depart time(y)).BNP\N?f.
argmax(?x.f(x)?to(x,washington), ?y.depart time(y))&NPargmax(?x.flight(x) ?
to(x,washington),?y.depart time(y))Note that in this case the substring the latest has cat-egory NP/N , and this prevents a naive parse wherethe latest first combines with flight, and to washing-ton then combines with the latest flight.
The func-tional composition rules effectively allow the latestto take scope over flight and to washington, in spiteof the fact that the latest appears between the twoother sub-strings.
Examples like this are quite fre-quent in domains such as ATIS.We add features in the model which track the oc-currences of each of these four new combinators.Specifically, we have four new features in the def-inition of f; each feature tracks the number of timesone of the combinators is used in a CCG parse.
Themodel learns parameter values for each of these fea-tures, allowing it to learn to penalise these rules tothe correct extent.3.2 Additional Rules of Type-RaisingWe now describe new CCG operations designed todeal with cases where words are in some sense miss-ing in the input.
For example, in the string flightsBoston to New York, one style of analysis wouldassume that the preposition from had been deletedfrom the position before Boston.The first set of rules is generated from the follow-ing role-hypothesising type shifting rules template:NP : c ?
N\N : ?f.
?x.f(x) ?
p(x, c) (TR)This rule can be applied to any NP with semanticsc, and any arity-two function p such that the secondargument of p has the same type as c. By ?any?
arity-two function, we mean any of the arity-two func-tions seen in training data.
We define features withinthe feature-vector f that are sensitive to the numberof times these rules are applied in a parse; a separatefeature is defined for each value of p.In practice, in our experiments most rules of thisform have p as the semantics of some preposition,for example from or to.
A typical example of a useof this rule would be the following:flights boston to new yorkN NP N\N?x.flight(x) bos ?f.
?x.f(x)?to(x, new york)TRN\N?f.
?x.f(x) ?
from(x, bos)<N?f.
?x.flight(x) ?
from(x, bos)<N?x.flight(x) ?
to(x, new york) ?
from(x, bos)The second rule we consider is the null-head typeshifting rule:N\N : f ?
N : f(?x.true) (TN)This rule allows parses of fragments such as Amer-ican Airlines from New York, where there is again aword that is in some sense missing (it is straightfor-ward to derive a parse for American Airlines flightsfrom New York).
The analysis would be as follows:American Airlines from New YorkN/N N\N?f.
?x.f(x) ?
airline(x, aa) ?f.
?x.f(x) ?
from(x, new york)TNN?x.from(x, new york)>N?x.airline(x, aa) ?
from(x, new york)The new rule effectively allows the preposi-tional phrase from New York to type-shift toan entry with syntactic type N and semantics?x.from(x, new york), representing the set of allthings from New York.7We introduce a single additional feature whichcounts the number of times this rule is used.3.3 Crossed Composition RulesFinally, we include crossed functional compositionrules:A/B : f B\C : g ?
A\C : ?x.f(g(x)) (>B?
)B/C : g A\B : f ?
A/C : ?x.f(g(x)) (<B?
)These rules are standard CCG operators but theywere not used by the parser described in ZC05.When used in unrestricted contexts, they can sig-nificantly relax word order.
Again, we address this7Note that we do not analyze this prepositional phrase ashaving the semantics ?x.flight(x) ?
from(x, new york)?although in principle this is possible?as the flight(x) predi-cate is not necessarily implied by this utterance.682dallas to washington the latest on fridayNP (N\N)/NP NP NP/N (N\N)/NP NPdallas ?y.?f.
?x.f(x) washington ?f.
argmax(f, ?y.?f.
?x.f(x) friday?to(x, y) ?y.depart time(y)) ?day(x, y)TR > >N\N N\N N\N?f.
?x.f(x) ?
from(x, dallas) ?f.
?x.f(x) ?
to(x,washington) ?f.
?x.f(x) ?
day(x, friday)<B TNN\N N?f.
?x.f(x) ?
from(x, dallas) ?
to(x,washington) ?x.day(x, friday).BNP\N?f.
argmax(?x.f(x) ?
from(x, dallas) ?
to(x,washington), ?y.depart time(y))&NPargmax(?x.day(x, friday) ?
from(x, dallas) ?
to(x,washington), ?y.depart time(y))Figure 3: A parse with the flexible parser.problem by introducing features that count the num-ber of times they are used in a parse.83.4 An ExampleAs a final point, to see how these rules can interactin practice, see figure 3.
This example demonstratesthe use of the relaxed application and compositionrules, as well as the new type-raising rules.4 LearningThis section describes an approach to learning in ourmodel.
We first define the features used and then de-scribe a new online learning algorithm for the task.4.1 Features in the ModelSection 2.3 described the use of a function f(x, y)which maps a sentence x together with a CCG parsey to a feature vector.
As described in section 3,we introduce features for the new CCG combina-tors.
In addition, we follow ZC05 in defining fea-tures which track the number of times each lexicalitem in ?
is used.
For example, we would have onefeature tracking the number of times the lexical entryflights := N : ?x.flights(x) is used in a parse,and similar features for all other members of ?.Finally, we introduce new features which directlyconsider the semantics of a parse.
For each predicatef seen in training data, we introduce a feature thatcounts the number of times f is conjoined with itselfat some level in the logical form.
For example, theexpression ?x.flight(x) ?
from(x, new york) ?from(x, boston) would trigger the new feature for8In general, applications of the crossed composition rulescan be lexically governed, as described in work on Multi-ModalCCG (Baldridge, 2002).
In the future we would like to incorpo-rate more fine-grained lexical distinctions of this type.the from predicate signaling that the logical-formdescribes flights with more than one origin city.
Weintroduce similar features which track disjunction asopposed to conjunction.4.2 An Online Learning AlgorithmFigure 4 shows a learning algorithm that takes atraining set of (xi, zi) pairs as input, and returnsa weighted CCG (i.e., a pair (w,?))
as its output.The algorithm is online, in that it visits each ex-ample in turn, and updates both w and ?
if neces-sary.
In Step 1 on each example, the input xi isparsed.
If it is parsed correctly, the algorithm im-mediately moves to the next example.
In Step 2,the algorithm temporarily introduces all lexical en-tries seen in GENLEX(xi, zi), and finds the highestscoring parse that leads to the correct semantics zi.A small subset of GENLEX(xi, zi)?namely, onlythose lexical entries that are contained in the highestscoring parse?are added to ?.
In Step 3, a simpleperceptron update (Collins, 2002) is performed.
Thehypothesis is parsed again with the new lexicon, andan update to the parameters w is made if the result-ing parse does not have the correct logical form.This algorithm differs from the approach in ZC05in a couple of important respects.
First, the ZC05 al-gorithm performed learning of the lexicon ?
at eachiteration in a batch method, requiring a pass over theentire training set.
The new algorithm is fully online,learning both ?
and w in an example-by-examplefashion.
This has important consequences for theefficiency of the algorithm.
Second, the parameterestimation method in ZC05 was based on stochasticgradient descent on a log-likelihood objective func-tion.
The new algorithm makes use of perceptron683Inputs: Training examples {(xi, zi) : i = 1 .
.
.
n} whereeach xi is a sentence, each zi is a logical form.
An initiallexicon ?0.
Number of training iterations, T .Definitions: GENLEX(x, z) takes as input a sentence x anda logical form z and returns a set of lexical items as de-scribed in section 2.4.
GEN(x; ?)
is the set of all parsesfor x with lexicon ?.
GEN(x, z; ?)
is the set of all parsesfor x with lexicon ?, which have logical form z. Thefunction f(x, y) represents the features described in sec-tion 4.1.
The function L(y) maps a parse tree y to itsassociated logical form.Initialization: Set parameters w to initial values described insection 6.2.
Set ?
= ?0.Algorithm:?
For t = 1 .
.
.
T, i = 1 .
.
.
n :Step 1: (Check correctness)?
Let y?
= argmaxy?GEN(xi;?)
w ?
f(xi, y) .?
If L(y?)
= zi, go to the next example.Step 2: (Lexical generation)?
Set ?
= ?
?
GENLEX(xi, zi) .?
Let y?
= argmaxy?GEN(xi,zi;?)
w ?
f(xi, y) .?
Define ?i to be the set of lexical entries in y?.?
Set lexicon to ?
= ?
?
?i .Step 3: (Update parameters)?
Let y?
= argmaxy?GEN(xi;?)
w ?
f(xi, y) .?
If L(y?)
6= zi :?
Set w = w + f(xi, y?)
?
f(xi, y?)
.Output: Lexicon ?
together with parameters w.Figure 4: An online learning algorithm.updates, which are simpler and cheaper to compute.As in ZC05, the algorithm assumes an initial lex-icon ?0 that contains two types of entries.
First, wecompile entries such as Boston := NP : bostonfor entities such as cities, times and month-namesthat occur in the domain or underlying database.
Inpractice it is easy to compile a list of these atomicentities.
Second, the lexicon has entries for somefunction words such as wh-words, and determiners.95 Related WorkThere has been a significant amount of previ-ous work on learning to map sentences to under-lying semantic representations.
A wide variety9Our assumption is that these entries are likely to be domainindependent, so it is simple enough to compile a list that canbe reused in new domains.
Another approach, which we mayconsider in the future, would be to annotate a small subset ofthe training examples with full CCG derivations, from whichthese frequently occurring entries could be learned.of techniques have been considered including ap-proaches based on machine translation techniques(Papineni et al, 1997; Ramaswamy and Kleindienst,2000; Wong and Mooney, 2006), parsing techniques(Miller et al, 1996; Ge and Mooney, 2006), tech-niques that use inductive logic programming (Zelleand Mooney, 1996; Thompson and Mooney, 2002;Tang and Mooney, 2000; Kate et al, 2005), andideas from string kernels and support vector ma-chines (Kate and Mooney, 2006; Nguyen et al,2006).
In our experiments we compare to He andYoung (2006) on the ATIS domain and Zettlemoyerand Collins (2005) on the Geo880 domain, be-cause these systems currently achieve the best per-formance on these problems.The approach of Zettlemoyer and Collins (2005)was presented in section 2.4.
He and Young (2005)describe an algorithm that learns a probabilisticpush-down automaton that models hierarchical de-pendencies but can still be trained on a data set thatdoes not have full treebank-style annotations.
Thisapproach has been integrated with a speech recog-nizer and shown to be robust to recognition errors(He and Young, 2006).There is also related work in the CCG litera-ture.
Clark and Curran (2003) present a method forlearning the parameters of a log-linear CCG pars-ing model from fully annotated normal?form parsetrees.
Watkinson and Manandhar (1999) present anunsupervised approach for learning CCG lexiconsthat does not represent the semantics of the train-ing sentences.
Bos et al (2004) present an al-gorithm that learns CCG lexicons with semanticsbut requires fully?specified CCG derivations in thetraining data.
Bozsahin (1998) presents work on us-ing CCG to model languages with free word order.In addition, there is related work that focuses onmodeling child language learning.
Siskind (1996)presents an algorithm that learns word-to-meaningmappings from sentences that are paired with a setof possible meaning representations.
Villavicencio(2001) describes an approach that learns a categorialgrammar with syntactic and semantic information.Both of these approaches use sentences from child-directed speech, which differ significantly from thenatural language interface queries we consider.Finally, there is work on manually developingparsing techniques to improve robustness (Carbonell684and Hayes, 1983; Seneff, 1992).
In contrast, our ap-proach is integrated into a learning framework.6 ExperimentsThe main focus of our experiments is on the ATIStravel planning domain.
For development, we used4978 sentences, split into a training set of 4500 ex-amples, and a development set of 478 examples.
Fortest, we used the ATIS NOV93 test set which con-tains 448 examples.
To create the annotations, wecreated a script that maps the original SQL annota-tions provided with the data to lambda-calculus ex-pressions.He and Young (2006) previously reported resultson the ATIS domain, using a learning approachwhich also takes sentences paired with semantic an-notations as input.
In their case, the semantic struc-tures resemble context-free parses with semantic (asopposed to syntactic) non-terminal labels.
In our ex-periments we have used the same split into train-ing and test data as He and Young (2006), ensur-ing that our results are directly comparable.
He andYoung (2006) report partial match figures for theirparser, based on precision and recall in recoveringattribute-value pairs.
(For example, the sentenceflights to Boston would have a single attribute-valueentry, namely destination = Boston.)
It is sim-ple for us to map from lambda-calculus expressionsto attribute-value entries of this form; for example,the expression to(x,Boston) would be mapped todestination = Boston.
He and Young (2006) gaveus their data and annotations, so we can directlycompare results on the partial-match criterion.
Wealso report accuracy for exact matches of lambda-calculus expressions, which is a stricter criterion.In addition, we report results for the method onthe Geo880 domain.
This allows us to comparedirectly to the previous work of Zettlemoyer andCollins (2005), using the same split of the data intotraining and test sets of sizes 600 and 280 respec-tively.
We use cross-validation of the training set, asopposed to a separate development set, for optimiza-tion of parameters.6.1 Improving RecallThe simplest approach to the task is to train theparser and directly apply it to test sentences.
In ourexperiments we will see that this produces resultswhich have high precision, but somewhat lower re-call, due to some test sentences failing to parse (usu-ally due to words in the test set which were neverobserved in training data).
A simple strategy to alle-viate this problem is as follows.
If the sentence failsto parse, we parse the sentence again, this time al-lowing parse moves which can delete words at somecost.
The cost of this deletion operation is optimizedon development data.
This approach can signifi-cantly improve F-measure on the partial-match cri-terion in particular.
We report results both with andwithout this second pass strategy.6.2 Parameters in the ApproachThe algorithm in figure 4 has a number of param-eters, the set {T, ?, ?, ?
}, which we now describe.The values of these parameters were chosen to op-timize the performance on development data.
T isthe number of passes over the training set, and wasset to be 4.
Each lexical entry in the initial lexicon?0 has an associated feature which counts the num-ber of times this entry is seen in a parse.
The initialparameter value in w for all features of this formwas chosen to be some value ?.
Each of the newCCG rules?the application, composition, crossed-composition, and type-raising rules described in sec-tion 3?has an associated parameter.
We set al ofthese parameters to the same initial value ?.
Finally,when new lexical entries are added to ?
(in step 2of the algorithm), their initial weight is set to somevalue ?.
In practice, optimization on developmentdata led to a positive value for ?, and negative val-ues for ?
and ?.6.3 ResultsTable 1 shows accuracy for the method by the exact-match criterion on the ATIS test set.
The two passstrategy actually hurts F-measure in this case, al-though it does improve recall of the method.Table 2 shows results under the partial-match cri-terion.
The results for our approach are higherthan those reported by He and Young (2006) evenwithout the second, high-recall, strategy.
With thetwo-pass strategy our method has more than halvedthe F-measure error rate, giving improvements from90.3% F-measure to 95.9% F-measure.Table 3 shows results on the Geo880 domain.
The685Precision Recall F1Single-Pass Parsing 90.61 81.92 86.05Two-Pass Parsing 85.75 84.6 85.16Table 1: Exact-match accuracy on the ATIS test set.Precision Recall F1Single-Pass Parsing 96.76 86.89 91.56Two-Pass Parsing 95.11 96.71 95.9He and Young (2006) ?
?
90.3Table 2: Partial-credit accuracy on the ATIS test set.new method gives improvements in performanceboth with and without the two pass strategy, showingthat the new CCG combinators, and the new learn-ing algorithm, give some improvement on even thisdomain.
The improved performance comes from aslight drop in precision which is offset by a large in-crease in recall.Table 4 shows ablation studies on the ATIS data,where we have selectively removed various aspectsof the approach, to measure their impact on perfor-mance.
It can be seen that accuracy is seriously de-graded if the new CCG rules are removed, or if thefeatures associated with these rules (which allow themodel to penalize these rules) are removed.Finally, we report results concerning the effi-ciency of the new online algorithm as compared tothe ZC05 algorithm.
We compared running timesfor the new algorithm, and the ZC05 algorithm, onthe geography domain, with both methods making4 passes over the training data.
The new algorithmtook less than 4 hours, compared to over 12 hoursfor the ZC05 algorithm.
The main explanation forthis improved performance is that on many trainingexamples,10 in step 1 of the new algorithm a cor-rect parse is found, and the algorithm immediatelymoves on to the next example.
Thus GENLEX isnot required, and in particular parsing the examplewith the large set of entries generated by GENLEXis not required.7 DiscussionWe presented a new, online algorithm for learn-ing a combinatory categorial grammar (CCG), to-gether with parameters that define a log-linear pars-ing model.
We showed that the use of non-standardCCG combinators is highly effective for parsing sen-10Measurements on the Geo880 domain showed that in the 4iterations, 83.3% of all parses were successful at step 1.Precision Recall F1Single-Pass Parsing 95.49 83.2 88.93Two-Pass Parsing 91.63 86.07 88.76ZC05 96.25 79.29 86.95Table 3: Exact-match accuracy on the Geo880 test set.Precision Recall F1Full Online Method 87.26 74.44 80.35Without control features 70.33 42.45 52.95Without relaxed word order 82.81 63.98 72.19Without word insertion 77.31 56.94 65.58Table 4: Exact-match accuracy on the ATIS development setfor the full algorithm and restricted versions of it.
The sec-ond row reports results of the approach without the featuresdescribed in section 3 that control the use of the new combi-nators.
The third row presents results without the combinatorsfrom section 3.1 that relax word order.
The fourth row reportsexperiments without the type-raising combinators presented insection 3.2.tences with the types of phenomena seen in sponta-neous, unedited natural language.
The resulting sys-tem achieved significant accuracy improvements inboth the ATIS and Geo880 domains.AcknowledgementsWewould like to thank Yulan He and Steve Youngfor their help with obtaining the ATIS data set.
Wealso acknowledge the support for this research.
LukeZettlemoyer was funded by a Microsoft graduateresearch fellowship and Michael Collins was sup-ported by the National Science Foundation undergrants 0347631 and DMS-0434222.ReferencesJason Baldridge.
2002.
Lexically Specified Derivational Con-trol in Combinatory Categorial Grammar.
Ph.D. thesis,University of Edinburgh.Johan Bos, Stephen Clark, Mark Steedman, James R. Curran,and Julia Hockenmaier.
2004.
Wide-coverage semantic rep-resentations from a CCG parser.
In Proceedings of the 20thInternational Conference on Computational Linguistics.Cem Bozsahin.
1998.
Deriving the predicate-argument struc-ture for a free word order language.
In Proceedings of the36th Annual Meeting of the Association for ComputationalLinguistics.Jaime G. Carbonell and Philip J. Hayes.
1983.
Recovery strate-gies for parsing extragrammatical language.
American Jour-nal of Computational Linguistics, 9.Bob Carpenter.
1997.
Type-Logical Semantics.
The MIT Press.Stephen Clark and James R. Curran.
2003.
Log-linear modelsfor wide-coverage CCG parsing.
In Proceedings of the Con-ference on Empirical Methods in Natural Language Process-ing.686Michael Collins.
2002.
Discriminative training methods forhidden markov models: Theory and experiments with per-ceptron algorithms.
In Proceedings of the 2002 Conferenceon Empirical Methods in Natural Language Processing.Michael Collins.
2004.
Parameter estimation for statisticalparsing models: Theory and practice of distribution-freemethods.
In Harry Bunt, John Carroll and Giorgio Satta,editors, New Developments in Parsing Technology.
Kluwer.Deborah A. Dahl, Madeleine Bates, Michael Brown, WilliamFisher, Kate Hunicke-Smith, David Pallett, Christine Pao,Alexander Rudnicky, and Elizabeth Shriberg.
1994.
Ex-panding the scope of the atis task: the atis-3 corpus.
In ARPAHuman Language Technology Workshop.Ruifang Ge and Raymond J. Mooney.
2006.
Discriminativereranking for semantic parsing.
In Proceedings of the COL-ING/ACL 2006 Main Conference Poster Sessions.Yulan He and Steve Young.
2005.
Semantic processing usingthe hidden vector state model.
Computer Speech and Lan-guage.Yulan He and Steve Young.
2006.
Spoken language under-standing using the hidden vector state model.
Speech Com-munication Special Issue on Spoken Language Understand-ing for Conversational Systems.Mark Johnson, Stuart Geman, Steven Canon, Zhiyi Chi, andStefan Riezler.
1999.
Estimators for stochastic ?unification-based?
grammars.
In Proceedings of the Association forComputational Linguistics.Rohit J. Kate and Raymond J. Mooney.
2006.
Using string-kernels for learning semantic parsers.
In Proceedings of the44th Annual Meeting of the Association for ComputationalLinguistics.Rohit J. Kate, Yuk Wah Wong, and Raymond J. Mooney.
2005.Learning to transform natural to formal languages.
In Pro-ceedings of the 20th National Conference on Artificial Intel-ligence.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.Conditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proceedings of the18th International Conference on Machine Learning.Percy Liang, Alexandre Bouchard-Co?te?, Dan Klein, and BenTaskar.
2006.
An end-to-end discriminative approach to ma-chine translation.
In Proceedings of the 44th Annual Meetingof the Association for Computational Linguistics.Scott Miller, David Stallard, Robert J. Bobrow, and Richard L.Schwartz.
1996.
A fully statistical approach to natural lan-guage interfaces.
In Proceedings of the Association for Com-putational Linguistics.Raymond J. Mooney.
2007.
Learning for semantic parsing.
InComputational Linguistics and Intelligent Text Processing:Proceedings of the 8th International Conference.Le-Minh Nguyen, Akira Shimazu, and Xuan-Hieu Phan.
2006.Semantic parsing with structured SVM ensemble classifica-tion models.
In Proceedings of the COLING/ACL 2006MainConference Poster Sessions.K.
A. Papineni, S. Roukos, and T. R. Ward.
1997.
Feature-based language understanding.
In Proceedings of EuropeanConference on Speech Communication and Technology.Ganesh N. Ramaswamy and Jan Kleindienst.
2000.
Hierar-chical feature-based translation for scalable natural languageunderstanding.
In Proceedings of 6th International Confer-ence on Spoken Language Processing.Adwait Ratnaparkhi, Salim Roukos, and R. Todd Ward.
1994.A maximum entropy model for parsing.
In Proceedings ofthe International Conference on Spoken Language Process-ing.Stephanie Seneff.
1992.
Robust parsing for spoken languagesystems.
In Proceedings of the IEEE Conference on Acous-tics, Speech, and Signal Processing.Jeffrey M. Siskind.
1996.
A computational study of cross-situational techniques for learning word-to-meaning map-pings.
Cognition, 61(2-3).Mark Steedman.
1996.
Surface Structure and Interpretation.The MIT Press.Mark Steedman.
2000.
The Syntactic Process.
The MIT Press.Lappoon R. Tang and Raymond J. Mooney.
2000.
Automatedconstruction of database interfaces: Integrating statisticaland relational learning for semantic parsing.
In Joint Confer-ence on Empirical Methods in Natural Language Processingand Very Large Corpora.Ben Taskar, Dan Klein, Michael Collins, Daphne Koller, andChristopher Manning.
2004.
Max-margin parsing.
In Pro-ceedings of the Conference on Empirical Methods in NaturalLanguage Processing.Cynthia A. Thompson and Raymond J. Mooney.
2002.
Acquir-ing word-meaning mappings for natural language interfaces.Journal of Artificial Intelligence Research, 18.Aline Villavicencio.
2001.
The acquisition of a unification-based generalised categorial grammar.
Ph.D. thesis, Uni-versity of Cambridge.Stephen Watkinson and Suresh Manandhar.
1999.
Unsuper-vised lexical learning with categorial grammars using theLLL corpus.
In Proceedings of the 1st Workshop on Learn-ing Language in Logic.Yuk Wah Wong and Raymond Mooney.
2006.
Learning for se-mantic parsing with statistical machine translation.
In Pro-ceedings of the Human Language Technology Conference ofthe NAACL.John M. Zelle and Raymond J. Mooney.
1996.
Learning toparse database queries using inductive logic programming.In Proceedings of the 14th National Conference on ArtificialIntelligence.Luke S. Zettlemoyer and Michael Collins.
2005.
Learningto map sentences to logical form: Structured classificationwith probabilistic categorial grammars.
In Proceedings ofthe 21st Conference on Uncertainty in Artificial Intelligence.687
