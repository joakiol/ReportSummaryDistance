Recognizing Syntactic Errors in theWriting of Second Language Learners*Dav id  Schne ider  and Kath leen  F. McCoyDepartment of Linguistics Computer and Information SciencesUniversity of Delaware University of DelawareNewark, DE 19716 Newark, DE 19716{dschneid,mccoy}@cis.udel.eduAbst ractThis paper reports on the recognition compo-nent of an intelligent utoring system that isdesigned to help foreign language speakers learnstandard English.
The system models the gram-mar of the learner, with this instantiation ofthe system tailored to signers of American SignLanguage (ASL).
We discuss the theoretical mo-tivations for the system, various difficulties thathave been encountered in the implementation,as well as the methods we have used to over-come these problems.
Our method of cap-turing ungrammaticalities nvolves using mal-rules (also called 'error productions').
However,the straightforward a dition of some mal?rulescauses significant performance problems withthe parser.
For instance, the ASL populationhas a strong tendency to drop pronouns and theauxiliary verb 'to be'.
Being able to accountfor these as sentences results in an explosionin the number of possible parses for each sen-tence.
This explosion, left unchecked, greatlyhampers the performance of the system.
Wediscuss how this is handled by taking into ac-count expectations from the specific population(some of which are captured in our unique usermodel).
The different representations of lexicalitems at various points in the acquisition pro-cess are modeled by using mal-rules, which ob-viates the need for multiple lexicons.
The gram-mar is evaluated on its ability to correctly di-agnose agreement problems in actual sentencesproduced by ASL native speakers.1 Overv iewThis paper reports on the error-recognitioncomponent of the ICICLE (Interactive Com-puter Identification and Correction of LanguageErrors) system.
The system is designed to bea tutorial system for helping second-language(L2) learners of English.
In this instantiation" This work was supported by NSF Grant#SRS9416916.of the system, we are focusing on the par-ticular problems of American Sign Language(ASL) native signers.
The system recognizeserrors by using mal-rules (also called 'error-production rules') (Sleeman, 1982), (Weischedelet al, 1978) which extend the language acceptedby the grammar to include sentences contain-ing the specified errors.
The mal-rules them-selves are derived from an error taxonomy whichwas the result of an analysis of writing samples.This paper focuses primarily on the unique chal-lenges posed by developing a grammar that al-lows the parser to efficiently parse and recog-nize errors in sentences even when multiple er-rors occur.
Additionally, it is important to notethat the users will not be at a uniform stageof acquisition - the system must be capable ofprocessing the input of users with varying lev-els of English competence.
We briefly describehow acquisition is modeled and how this modelcan help with some of the problems faced by asystem designed to recognize rrors.We will begin with an overview of the entireICICLE system.
To motivate some of the dif-ficulties encountered by our mal-rule-based r-ror recognition system, we will briefly describesome of the errors common to the populationunder study.
A major problem that must befaced is parsing efficiency caused by multipleparses.
This is a particularly difficult problemwhen expected errors include omission errors,and thus this class of errors will be discussedin some detail.
Another important problem in-volves the addition/subtraction of various syn-tactic features in the grammar and lexicon dur-ing acquisition.
We describe how our systemmodels this without he use of multiple lexicons.We follow this by a description of the currentimplementation a d grammar coverage of thesystem.
Finally, we will present an evaluationof the system for number/agreement rrors inthe target group of language learners.11982 System Overv iewThe ICICLE system is meant to help second-language learners by identifying errors and en-gaging the learners in a tutorial dialogue.
Ittakes as input a text written by the student.This is given to the error identification compo-nent, which is responsible for flagging the er-rors.
The identification is done by parsing theinput one sentence at a time using a bottom-up chart parser which is a successor to (Allen,1995).
The grammar formalism used by theparser consists of context-free rules augmentedwith features.
The grammar itself is a gram-mar of English which has been augmented witha set of mal-rules which capture rrors commonto this user population.
We will briefly discusssome classes of errors that were uncovered inour writing sample analysis which was used toidentify errors expected in this population.
Thisdiscussion will motivate some of the mal-ruleswhich were written to capture some classes oferrors, and the difficulties encountered in im-plementing these mal-rules.
The mal-rules arespecially tagged with information helpful in thecorrection phase of the system.The error identification component relies oninformation in the user model - the most inter-esting aspect of which is a model of the acquisi-tion of a second language.
This model (instan-tiated with information from the ASL/Englishlanguage model) is used to highlight thosegrammar rules which the student has most likelyalready acquired or is currently in the processof acquiring.
These rules will be the ones theparser attempts to use when parsing the user'sinput.
Thus we take an interlanguage view ofthe acquisition process (Selinker, 1972), (Ellis,1994), (Cook, 1993) and attempt o model howthe student's grammar is likely to change overtime.
The essence of the acquisition model isthat there are discrete stages that all learners ofa particular language will go through (Krashen,1981), (Ingram, 1989), (Dulay and Burt, 1974),(Bailey et al, 1974).
Each of these stages ischaracterized in our model by sets of languagefeatures (and therefore constructions) that thelearner is in the process of acquiring.
It is antici-pated that most of the errors that learners makewill be within the constructions (where "con-struction" is construed broadly) that they are inthe process of acquiring (Vygotsky, 1986) andthat they will favor sentences involving thoseconstructions in a "hypothesize and test" styleof learning, as predicted by interlanguage the-ory.
Thus, the parser favors grammar ules in-volving constructions currently being acquired(and, to a lesser extent, constructions alreadyacquired).The correction phase of the system is a focusof current research.
A description of the strate-gies for this phase can be found in (Michaudand McCoy, 1998) and (Michaud, 1998).3 Expected  Er rorsIn order to identify the errors we expect thepopulation to make, we collected writing sam-ples from a number of different schools and or-ganizations for the deaf.
To help identify anyinstances of language transfer between ASL andwritten English, we concentrated on elicitingsamples from deaf people who are native ASLsigners.
It is important o note that ASL is notsimply a translation of standard English intomanual gestures, but rather is a complete lan-guage with its own syntax, which is significantlydifferent from English.
Some of our previouswork (Suri and McCoy, 1993) explored how lan-guage transfer might influence written Englishand suggested that negative language transfermight occur when the realization of specific lan-guage features differed between the first lan-guage and written English.
For instance, onefeature is the realization of the copula "be".
InASL the copula "be" is often not lexicalized.Thus, negative language transfer might predictomission errors resulting from not lexicalizingthe copula "be" in the written English of ASLsigners.
While we concentrate here on errorsfrom the ASL population, the errors identifiedare likely to be found in learners coming fromfirst languages other than ASL as well.
Thiswould be the case if the first language has fea-tures in common with ASL.
For instance themissing copula "be" is also a common error inthe writing of native Chinese speakers since Chi-nese and ASL share the feature that the copula"be" is often not lexicalized.
Thus, the exam-ples seen here will generalize to other languages.In the following we describe some classes oferrors which we uncovered (and attempt o "ex-plain" why an ASL native might come to makethese errors).3.1 Const i tuent  Omiss ionsLearners of English as a second language (ESL)omit constituents for a variety of reasons.
Oneerror that is common for many ASL learners isthe dropping of determiners.
Perhaps becauseASL does not have a determiner system simi-lar to that of English, it is not unusual for adeterminer to be omitted as in:(1) I am _ t rans fer  s tudent  f rom .
.
.
.These errors can be flagged reasonably wellwhen they are syntactic (and not pragmatic) in1199nature and do not pose much additional burdenon the parser/grammar.However, missing main verbs (most com-monly missing copulas) are also common in ourwriting samples:(2) Once the situation changes they _ differentpeople.One explanation for this (as well as othermissing elements uch as missing prepositions)is that copulas are not overtly lexicalized inASL because the copula (preposition) is got-ten across in different ways in ASL.
Because thecopula (preposition) is realized in a radically dif-ferent fashion in ASL, there can be no positivelanguage transfer for these constructions.In addition to omitting verbs, some NPs mayalso be omitted.
It has been argued (see, forexample (Lillo-Martin, 1991)) that ASL allowstopic NP deletion (Huang, 1984) which meansthat topic noun phrases that are prominent inthe discourse context may be left out of a sen-tence.
Carrying this strategy over to Englishmight explain why some NPs are omitted fromsentences such as:(3) While living at college I spend lot of moneybecause _ go out to eat almost everyday.Mal-rules written to handle these errors mustcapture missing verbs, NPs, and prepositions.The grammar is further complicated becauseASL natives also have many errors in relativeclause formation including missing relative pro-nouns.
The possibility of all of these omissionscauses the parser to explore a great number ofparses (many of which will complete success-fully).3.2 Hand l ing  Omiss ionsAs we just saw, omissions are frequent in thewriting of ASL natives and they are difficult todetect using the mal-rule formalism.
To clearlysee the problem, consider the following two sen-tences, which would not be unusual in the writ-ing of an ASL native.
(4) The boy happy.
(5) Is happy.As the reader can see, in (4) the main verb"be" is omitted, while the subject is missing in(5).To handle these types of sentences, we in-cluded in our grammar mal-rules like the fol-lowing:(6) VP(error +) -+ AdjP(7) S(error +) -+ VPA significant problem that arises from theserules is that a simple adjective is parsed as an Seven if it is in a normal, grammatical sentence.This behavior leads to many extra parses, sincethe S will be able to participate in lots of otherparses.
The problem becomes much more seri-ous when the other possible omissions are addedinto the grammar.
However, closer examinationof our writing samples indicates that, exceptfor determiners, our users generally leave outat most one word (constituent) per sentence.Thus it is unlikely that "happy" will ever be anentire sentence.
We would like this fact to bereflected in the analyses explored by the parser.However, a traditional bottom-up context-freeparser has no way to deal with this case, as thereis no way to block rules from firing as long asthe features are capable of unification.One possibility would be to allow the (e r ror+) feature to percolate up through the parse.Any rule which introduces the (e r ror  +) fea-ture could then be prevented from having anychildren specified with (e r ror  +).
However,this solution would be far too restrictive, as itwould restrict he number of errors in a sentenceto one, and many of the sentences in our ASLcorpus involve multiple errors.Recall, however, that in our analysis we foundthat (except for determiners) our writing sam-ples did not contain multiple omission errors ina sentence.
Thus another possibility might be topercolate an error feature associated with omis-sions only-perhaps called (miss ing +).Upon closer inspection, this solution also hasdifficulties.
The first difficulty has to do withimplementing the feature percolation.
For in-stance, for a VP to be specified as (miss ing+) whenever any of its sub-constituents has thatfeature, one would need to have separate rulesraising the feature up from each of the sub-constituents, as in the following:(8) VP(missing ?a) ~ V NP NP(missing ?a)(9) VP(missing ?a) --~ V NP(missing ?a) NP(I0) VP(missing ?a) --> V(missing ?a) NP NPThis would cause an unwarranted increase inthe size of the grammar, and would also causean immense increase in the number of parses,since three VPs would be added to the chart,one for each of the rules.At first glance it appears that this problemcan be overcome with the use of "foot features,"which are included in the parser we are using.
Afoot feature moves features from any child to theparent.
For example, for a foot feature F, if onechild has a specification for F, it will be passed1200on to the parent.
If more than one child is spec-ified for F, then the values of F must unify, andthe unified value will be passed up the parent.While the use of foot features appears to makethe feature percolation easier, it will not allowthe feature to be used as desired.
In particu-lar, we need to have the feature percolated onlywhen it has a positive value and only when thatvalue is associated with exactly one constituenton the right-hand side of a rule.
The foot fea-ture as defined by the parser would allow thepercolation of the feature even if it were speci-fied in more than one constituent.A further complication with using this typeof feature propagation arises because there aresome situations where multiple omission errorsdo occur, especially when determiners are omit-ted.
1 Consider the following example takenfrom our corpus where both the main verb "be"and a determiner "the" are omitted.
(11) Student always bothering me while I amat dorm.
(Corrected) Students are always bothering mewhile I am at th___.ee dorm.Our solution to the problem involves usingprocedural attachment.
The parser we are us-ing builds constituents and stores them in achart.
Before storing them in the chart, theparser can run arbitrary procedures on new con-stituents.
These procedures, specified in thegrammar, will be run on all constituents thatmeet a certain pattern specified by the gram-mar writer.Our procedure amounts to specifying an al-ternative method for propagating the (miss ing+) feature, which will still be a foot feature.It will be run on any constituent that specifies(miss ing +).
The procedure can either deletea constituent that has more than one child with(miss ing +), or it can alter the (miss ing +)feature on the constituent in the face of deter-miner omissions (as discussed in footnote 1).
Byusing a special procedure to implement he fea-ture percolation, we will be able to be more flex-ible in where we allow the "missing" feature topercolate.3.3 Syntactic Feature AdditionFor this system to properly model language ac-quisition, it must also model the addition (andpossible subtraction) of syntactic features in thelexicon and grammar of the learner.
For in-stance, ASL natives have a great deal of dif-ficulty with many of the agreement features in1While our analysis so far has only indicated thatdeterminer omissions have this property, we do not wantto rule out the possibility that other combinations ofomission errors might be found to occur as well.English.
As a concrete xample, this populationfrequently has trouble with the difference be-tween "other" and "another".
They frequentlyuse "other" in a singular NP, where "another"would normally be called for.
We hypothesizethat this is partly a result of their not under-standing that there is agreement between NPsand their specifiers (determiners, quantifiers,etc.).
Even if this is recognized, the learnersmay not have the lexical representations ec-essary to support the agreement for these twowords.
2 Thus, the most accurate model of thelanguage of these early learners involves a lexi-con with impoverished entries - i.e.
no personor number features for determiners and quanti-tiers.
Such an impoverished lexicon would meanthat the entries for the two words might be iden-tical, which appears to be the case for theselearners.There are at least two reasons for not us-ing this sort of impoverished lexicon.
Firstly,it would require having multiple lexicons (someimpoverished, others not), with the systemneeding to determine which to use for a givenuser.
Secondly, it would not allow grammat-ical uses of the impoverished items to be dif-ferentiated from ungrammatical uses.
With animpoverished lexicon, any use (grammatical ornot) of "other" or "another" would be flaggedas an error, since it would involve using a lexicalentry that does not have all of the features thatthe standard entry has.
Since the lexical itemwould not have the agr specification, it couldnot match the rule that requires agreement be-tween determiners and nouns.3.3.1 Imp lementat ionFor these reasons, we decided not to use differ-ent lexical entries to model the different stagesof acquisition.
Instead, we use mal-rules, thesame mechanism that we are using to modelsyntactic changes.
A standard (grammatical)DP (Determiner Phrase) rule has the followingformat:(12)  DP(agr ?a) --~ Det (agr  ?a) NP(agr ?a)We initially tried simply eliminating the ref-erences to agreement between the NP and thedeterminer, as in the following mal-rule:(13)  DP(er ror  +) (agr  ?a) --+ Det NP(agr ?a)This has the advantage of flagging any de-viant DPs as having the error feature, since un-grammatical DPs will trigger the mal-rule (13),but won't trigger (12).
However, a grammatical2 "Another" and "other" are not separate l xical itemsin ASL.1201DP (e.g.
"another child") fires both the mal-rule (13) and the grammatical rule (12).
Notonly did this behavior cause the parser to slowdown very significantly, since it effectively dou-bled the number of DPs in a sentence, but it alsohas the potential to report an error when onedoes not exist.
We also briefly considered usingimpoverishment rules on specific categories.
Forexample, we could have used a rule stating thatdeterminers have all possible agreement values.This has the effect of eliminating agreement asa barrier to unification, much as would be ex-pected if the learner has no knowledge of agree-ment on determiners.
However, this solutionhas a problem very similar to that of the pre-vious possible solution: all determiners in theinput could suddenly have two entries in thechart - one with the actual agreement, one withthe impoverished agreement.
These would thenboth be used in parsing, leading to another ex-plosion in the number of parses.We finally ended up building a set of rulesthat matches just the ungrammatical possibili-ties, i.e.
they do not allow a grammatical struc-ture to fire both the mal-rule and the normalrule.
The present set of rules for determiner-NP agreement include the following:(14) DP(agr ?a) --+ Det (agr ?a) NP (agr?a)(15) DP(agr s ) (er ror  +) -+ Det(agr (?
!as)) NP(agr s)(16) DP(agr p) (error  +) ~ Det(agr (?
!ap)) NP(agr p)This solution required using the negation op-erator "!"
present in our parser to specifythat a Det not allow singular/plural agreement.However, this feature is limited in the presentimplementation to constant values, i.e.
wecan't negate a variable.
This solution achievesthe major goal of not introducing extraneousparses for grammatical constituents.
However,it achieves this goal at some cost.
Namely, weare forced to increase the number of rules in or-der to accomplish the task.3.3.2 Future  p lansWe are presently working on the implementa-tion of a variant of unification that will allow usto do the job with fewer rules.
The new opera-tion will work in the following sort of rule:(17) DP (agr ?a)--+ Det(agr ?
!a) NP(agr ?a)This rule will be interpreted as follows: theagr values between the DP and the NP will bethe same, and none of the values in Det willbe allowed to be in the agreement values forthe NP and the DP.
This will allow the rule tofire precisely when there are no possible waysto unify the values between the Det and the NP,i.e.
none of the agr values for the Det will beallowed in the variable ?a.
Thus, this rule willonly fire for ungrammatical constructions.4 Grammar  Coverage/User  In ter faceThe ICICLE grammar is a broad-coveragegrammar designed to parse a wide variety ofboth grammatical sentences and sentences con-taining errors.
It is built around the COM-LEX Syntax 2.2 lexicon (Grishman et al, 1994),which contains approximately 38,000 differentsyntactic head words.
We have a simple setof rules that allows for inflection, thereby dou-bling the number of noun forms, while giving usthree to four times as many verb forms as thereare heads.
Thus we can handle approximately40,000 noun forms, 8,000 adjectives, and wellover 15,000 verb forms.
In addition, unknownwords coming into the system are assumed tobe proper nouns, thus expanding the number ofwords handled even further.The grammar itself contains approximately25 different adjectival subcategorizations, in-cluding subcategorizations requiring an extra-posed structure (the "it" in "it is true thathe is here").
We also include half a dozennoun complementation types.
We have ap-proximately 110 different verb complementationframes, many of which are indexed for severaldifferent subcategorizations.
The grammar isalso able to account for verb-particle construc-tions when the verb is adjacent o the particle,as well as when they are separated (e.g.
"I calledhim up" ).Additionally, the grammar allows for variousdifferent ypes of subjects, including infinitivalswith and without subjects ("to fail a class isunfortunate", "for him to fail the class is irre-sponsible").
It handles yes/no questions, wh-questions, and both subject and object relativeclauses.The grammar has only limited abilities con-cerning coordination - it only allows limitedconstituent coordination, and does not allownon-constituent coordination (e.g.
"I saw andhe hit the ball") at all.
It is also fairly weakin its handling of adjunct subordinate clauses.The population we are concerned with also hassignificant rouble with this, in particular thereis a strong propensity towards over-using "be-cause".
Adverbs are also problematic, in thatthe system is not yet able to differentiate whatposition a given adverb should be able to take ina sentence, thus no errors in adverb placement1202can be flagged.
We are presently in the processof integrating a new version of the lexicon thatincludes features pecifying what each adverbcan attach to.
Once this is done, we expect tobe able to process adverbs quite effectively.The user interface presently consists of a mainwindow where the user can input the text andcontrol parsing, file access, etc.
After parsing,the sentences are highlighted with different col-ors corresponding to different ypes of errors.When the user double-clicks on a sentence, aseparate "fix-it" window is displayed with thesentence in question, along with descriptions ofthe errors.
The user can click on the errors andthe system will highlight the part of the sen-tence where the error occurred.
For example,in the sentence "I see a boys", only "a boys"will be highlighted.
The "fix-it" window alsoallows the user to change the sentence and thenre-parse it.
If the changes are acceptable to theuser, the new sentence can be substituted backinto the main text.5 Eva luat ion  o f  E r ro r  Recogn i t ionAn evaluation of the grammar was conductedon a variety of sentences pulled from the cor-pus of ASL natives.
The corpus contains essayswritten by ASL natives which is annotated withreferences to different ypes of errors in the sen-tences.
The focus for this paper was on recog-nition of agreement-type roblems, and as suchwe pulled out all of the sentences that had beenmarked with the following errors:?
NUM: Number problems, which are typi-cally errors in subject-verb agreement?
ED: extra determiner?
MD: missing determiner for an NP that re-quires a determiner?
ID: incorrect determinerIn addition to testing sentences with theseproblems, we also tested fully grammatical sen-tences from the same corpus, to see if we couldcorrectly differentiate between grammatical ndungrammatical sentences that might be pro-duced by our target user group.After gathering the sentences from thedatabase, we cut them down to mono-clausalsentences wherever possible, due to the fact thatthe handling of adjunct clauses is not yet com-plete (see ?4).
An example of the type of sen-tence that had to be divided is the following:(18) They should communicate ach other be-cause the communication is very important tounderstand each other.This sentence was divided into "They shouldcommunicate each other" and "the communi-cation is very important o understand eachother."
In addition to separating the clauses,we also fixed the spelling errors in the sentencesto be tested since spelling correction is beyondthe scope of the current implementation.5.1 Resu l ts  for Ungrammat ica lSentencesWe ended up with 79 sentences to test for thedeterminer and agreement errors.
Of these 79sentences, 44 (56%) parse with the expectedtype of error.
Another 23 (29%) have no parsesthat cover the entire sentence, and 12 (15%)parse as having no errors at all.A number of the sentences that had beenflagged with errors in the database were actuallygrammatical sentences, but were deemed inap-propriate in context.
Thus, sentences like thefollowing were tagged with errors in the corpus:(19) I started to attend the class last Saturday.It was evident from the context hat this sen-tence should have had "classes" rather than"the class."
Of the 12 sentences that wereparsed as error-free, five were actually syntacti-cally and semantically acceptable, but were in-appropriate for their contexts, as in the previousexample.
Another four had pragmatic/semanticproblems, but were syntactically well-formed, asin(20) I want to succeed in jobs anywhere.Thus, there are really only three sentencesthat do not have a parse with the appropriateerror.
Since this parser is a syntactic parser,it should not be expected to find the seman-tic/pragmatic errors, nor should it know if thesentence was inappropriate for its context in theessay.
If we eliminate the nine sentences thatare actually grammatical in isolation, we areleft with 70 sentences, of which 44 (63%) haveparses with the expected error, three (4%) arewrongly accepted as grammatical, and 23 (33%)do not parse.In terms of evaluating these results for thepurposes of the system, we must consider theimplications of the various categories.
63%would trigger tutoring, and 33% would betagged as problematic, but would have no in-formation about the type of error.
In only 4%of sentences containing errors would the systemincorrectly indicate that no errors are present.5.2 Resu l ts  for Grammat ica l  SentencesWe also tested the system on 101 grammaticalsentences that were pulled from the same cor-pus.
These sentences were modified in the same1203way as the ungrammatical ones, with multi-clausal sentences being divided up into mono-clausal sentences.
Of these 101 sentences, 89(88%) parsed as having no errors, 3 (3%) parsedwith errors, and the remaining 8 (8%) did notparse.The present implementation f the grammarsuffers from poor recognition of coordination,even within single clauses.
Five of the elevensentences that did not return an error-free parsesuffered from this limitation.
We expect o beable to improve the numbers ignificantly byincluding in the grammar some recognition ofpunctuation, which, due to technical problems,is presently filtered out of the input before theparser has a chance to use it.6 Conc lus ions  and  Future  WorkFuture work will include extending the gram-mar to better deal with coordination and ad-junct clauses.
We will also continue to work onthe negation operator and the propagation ofthe missing feature discussed above.
In orderto cut down on the number of parses, as well asto make it easier to decide which is the appropri-ate parse to correct, we have recently switchedto a best-first parsing strategy.
This should al-low us to model which rules are most likely tobe used by a given user, with the mal-rules cor-responding to the constructions currently beingacquired having a higher probability than thosethat the learner has already mastered.
How-ever, at the moment we have simply lowered theprobabilities of all mal-rules, so that any gram-matical parses are generated first, followed bythe "ungrammatical" parses.As we have shown, this system does a goodjob of flagging ungrammatical sentences pro-duced by the target population, with a highproportion of the flagged sentences containingsignificant information about the type and lo-cation of the error.
Our continuing work willhopefully improve these percentages, and couplethis recognition component with an intelligenttutoring phase.Re ferencesJames Allen.
1995.
Natural LanguageUnderstanding, Second Edition.
Ben-jamin/Cummings, CA.N.
Bailey, C. Madden, and S. D. Krashen.
1974.Is there a 'natural sequence' in adult sec-ond language learning?
Language Learning,24(2):235-243.Vivian Cook.
1993.
Linguistics and SecondLanguage Acquisition.
Macmillan Press Ltd,London.Heidi C. Dulay and Marina K. Burt.
1974.
Nat-ural sequences inchild second language acqui-sition.
Language Learning, 24:37-53.Rod Ellis.
1994.
The Study of Second Lan-guage Acquisition.
Oxford University Press,Oxford.Ralph Grishman, Catherine Macleod, andAdam Meyers.
1994.
Comlex syntax: Build-ing a computational lexicon.
In Proceedingsof the 15th International Conference on Com-putational Linguistics, Kyoto, Japan, July.Coling94.C.-T. James Huang.
1984.
On the distributionand reference of empty pronouns.
LinguisticInquiry, 15(4):531-574, Fall.David Ingram.
1989.
First Language Acqui-sition: Method, Description, and Explana-tion.
Cambridge University Press, Cam-bridge; New York.Stephen Krashen.
1981.
Second LanguageAcquisition and Second Language Learning.Pergamon Press, Oxford.Diane C. Lillo-Martin.
1991.
Universal Gram-mar and American Sign Language.
KluwerAcademic Publishers, Boston.Lisa N. Michaud and Kathleen F. McCoy.
1998.Planning tutorial text in a system for teach-ing english as a second language to deaf learn-ers.
In Proceedings of the 1998 AAAI Work-shop on Integrating Artificial Intelligence andAssistive Technology, Madison, Wisconsin,July.Lisa N. Michaud.
1998.
Tutorial response gen-eration in a writing tool for deaf learnersof english.
In Proceedings of the FifteenthNational Conference on Artificial Intelligence(poster abstract), Madison, Wisconsin, July.L.
Selinker.
1972.
Interlanguage.
InternationalReview of Applied Linguistics, 10:209-231.D.
Sleeman.
1982.
Inferring (mal) rules frompupil's protocols.
In Proceedings of ECAI-82,pages 160-164, Orsay, France.
ECAI-82.Linda Z. Suri and Kathleen F. McCoy.
1993.
Amethodology for developing an error taxon-omy for a computer assisted language learn-ing tool for second language learners.
Techni-cal report TR-93-16.
Dept.
of CIS, Universityof Delaware.Lev Semenovich Vygotsky.
1986.
Thought andLanguage.
MIT Press, Cambridge, MA.Ralph M. Weischedel, Wilfried M. Voge, andMark James.
1978.
An artificial intelligenceapproach to language instruction.
ArtificialIntelligence, 10:225-240.1204
