Should we Translate the Documents  or the Queries inCross- language Information Retrieval?J.
Scott McCarleyIBM T.J. Watson Research CenterP.O.
Box 218Yorktown Heights, NY 10598jsmc@watson.ibm.comAbstractPrevious comparisons of document andquery translation suffered difficulty due todiffering quality of machine translation inthese two opposite directions.
We avoidthis difficulty by training identical statisticaltranslation models for both translation di-rections using the same training data.
We in-vestigate information retrieval between En-glish and French, incorporating both trans-lations directions into both document trans-lation and query translation-based informa-tion retrieval, as well as into hybrid sys-tems.
We find that hybrids of documentand query translation-based systems out-perform query translation systems, evenhuman-quality query translation systems.1 Introduct ionShould we translate the documents or thequeries in cross-language information re-trieval?
The question is more subtle thanthe implied two alternatives.
The need fortranslation has itself been.
questioned : al-though non-translation based methods ofcross-language information retrieval (CLIR),such as cognate-matching (Buckley et al,1998) and cross-language Latent SemanticIndexing (Dumais et al, 1997) have beendeveloped, the most common approacheshave involved coupling information retrieval(IR) with machine translation (MT).
(Forconvenience, we refer to dictionary-lookuptechniques and interlingua (Diekema et al,1999) as "translation" even if these tech-niques make no attempt to produce coherentor sensibly-ordered language; this distinctionis important in other areas, but a streamof words is adequate for IR.)
Translatingthe documents into the query's language(s)and translating the queries into the docu-ment's language(s) represent wo extremeapproaches to coupling MT and IR.
Thesetwo approaches are neither equivalent normutually exclusive.
They are not equivalentbecause machine translation is not an invert-ible operation.
Query translation and doc-ument translation become quivalent only ifeach word in one language is translated intoa unique word in the other languages.
In factmachine translation tends to be a many-to-one mapping in the sense that finer shadesof meaner are distinguishable in the originaltext than in the translated text.
This effectis readily observed, for example, by machinetranslating the translated text back into theoriginal anguage.
These two approaches arenot mutually exclusive, either.
We find thata hybrid approach combining both directionsof translation produces uperior performancethan either direction alone.
Thus our answerto the question posed by the title is both.Several arguments suggest hat documenttranslation should be competitive or supe-rior to query translation.
First, MT iserror-prone.
Typical queries are short andmay contain key words and phrases onlyonce.
When these are translated inappro-priately, the IR engine has no chance torecover.
Translating a long document of-fers the MT engine many more opportuni-ties to translate key words and phrases.
Ifonly some of these are translated appropri-ately, the IR engine has at least a chanceof matching these to query terms.
The sec-ond argument is that the tendency of MT208engines to produce fewer distinct words thanwere contained in the original document (theoutput vocabulary is smaller than the in-put vocabulary) also indicates that machinetranslation should preferably be applied tothe documents.
Note the types of prepro-cessing in use by many monolingual IR en-gines: stemming (or morphological nalysis)of documents and queries reduces the num-ber of distinct words in the document index,while query expansion techniques increasethe number of distinct words in the query.Query translation is probably the mostcommon approach to CLIR.
Since MT is fre-quently computationally expensive and thedocument sets in IR are large, query transla-tion requires fewer computer esources thandocument ranslation.
Indeed, it has beenasserted that document ranslation is sim-ply impractical for large-scale retrieval prob-lems (Carbonell et al, 1997), or that doc-ument translation will only become practi-cal in the future as computer speeds im-prove.
In fact, we have developed fast MTalgorithms (McCarley and Roukos, 1998) ex-pressly designed for translating large col-lections of documents and queries in IR.Additionally, we have used them success-fully on the TREC CLIR task (Franz etal., 1999).
Commercially available MT sys-tems have also been used in large-scale doc-ument translation experiments (Oard andHackett, 1998).
Previously, large-scale at-tempts to compare query translation anddocument ranslation approaches to CLIR(Oard, 1998) have suggested that documenttranslation is preferable, but the results havebeen difficult to interpret.
Note that in orderto compare query translation and documenttranslation, two different ranslation systemsmust be involved.
For example, if queries arein English and document are in French, thenthe query translation IR system must incor-porate English=~French translation, whereasthe document ranslation IR system mustincorporate French=~English.
Since famil-iar commercial MT systems are "black box"systems, the quality of translation is notknown a priori.
The present work avoidsthis difficulty by using statistical machinetranslation systems for both directions thatare trained on the same training data us-ing identical procedures.
Our study of doc-ument translation is the largest comparativestudy of document and query translation ofwhich we are currently aware.
We also inves-tigate both query and document translationfor both translation directions within a lan-guage pair.We built and compared three informationretrieval systems : one based on documenttranslation, one based on query translation,and a hybrid system that used both trans-lation directions.
In fact, the "score" of adocument in the hybrid system is simply thearithmetic mean of its scores in the queryand document ranslation systems.
We findthat the hybrid system outperforms eitherone alone.
Many different hybrid systemsare possible because of a tradeoff betweencomputer esources and translation quality.Given finite computer esources and a col-lection of documents much larger than thecollection of queries, it might make senseto invest more computational resources intohigher-quality query translation.
We inves-tigate this possibility in its limiting case: thequality of human translation exceeds thatof MT; thus monolingual retrieval (queriesand documents in the same language) rep-resents the ultimate limit of query transla-tion.
Surprisingly, we find that the hybridsystem involving fast document ranslationand monolingual retrieval continues to out-perform monolingual retrieval.
We thus con-clude that the hybrid system of query anddocument translation will outperform a purequery translation system no matter how highthe quality of the query translation.2 Trans la t ion  Mode lThe algorithm for fast translation, whichhas been described previously in some de-tail (McCarley and Roukos, 1998) and usedwith considerable success in TREC (Franzet al, 1999), is a descendent of IBM Model1 (Brown et al, 1993).
Our model capturesimportant features of more complex models,such as fertility (the number of French words209output when a given English word is trans-lated) but ignores complexities such as dis- Jtortion parameters that are unimportant forIR.
Very fast decoding is achieved by imple-menting it as a direct-channel model ratherthan as a source-channel model.
The ba-sic structure of the English~French modelis the probability distributionfl...A, le,,co text(e,)).
(1)of the fertility ni of an English word ei and aset of French words fl...f,~ associated withthat English word, given its context.
Herewe regard the context of a word as the pre-ceding and following non-stop words; our ap-proach can easily be extended to other typesof contextual features.
This model is trainedon approximately 5 million sentence pairs ofHansard (Canadian parliamentary) and UNproceedings which have been aligned on asentence-by-sentence basis by the methodsof (Brown et al, 1991), and then furtheraligned on a word-by-word basis by meth-ods similar to (Brown et al, 1993).
TheFrench::~English model can be described bysimply interchanging English and French no-tation above.
It is trained separately on thesame training data, using identical proce-dures.3 Information RetrievalExperimentsThe document sets used in our experimentswere the English and French parts of the doc-ument set used in the TREC-6 and TREC-7 CLIR tracks.
The English documentset consisted of 3 years of AP newswire(1988-1990), comprising 242918 stories orig-inally occupying 759 MB.
The French doc-ument set consisted of the same 3 years ofSDA (a Swiss newswire service), compris-ing 141656 stories and originally occupy-ing 257 MB.
Identical query sets and ap-propriate relevance judgments were availablein both English and French.
The 22 top-ics from TREC-6 were originally constructedin English and translated by humans intoFrench.
The 28 topics from TREC-7 wereoriginally constructed (7 each from four dif-ferent sites) in English, French, German, andItalian, and human translated into all fourlanguages.
We have no knowledge of whichTREC-7 queries were originally constructedin which language.
The queries contain threeSGML fields (<topic>, <description>,<narrative>), which allows us to' con-trast short (<description> field only) andlong (all three fields) forms of the queries.Queries from TREC-7 appear to be some-what "easier" than queries from TREC-6,across both document sets.
This differenceis not accounted for simply by the number ofrelevant documents, ince there were consid-erably fewer relevant French documents perTREC-7 query than per TREC-6 query.With this set of resources, we performedthe two different sets of CLIR experiments,denoted EqFd (English queries retrievingFrench documents), and FqBd (Frenchqueries retrieving English documents.)
Inboth EqFd and' FqEd we employed bothtechniques (translating the queries, trans-lating the documents).
We emphasizethat the query translation in EqFd wasperformed with the same English=~Frenchtranslation system as the document transla-tion in FqEd, and that the document trans-lation EqFd was performed with the sameFrench=~English translation system as thequery translation in FqEd.
We further em-phasize that both translation systems werebuilt from the same training data, and thusare as close to identical quality as can likelybe attained.
Note also that the resultspresented are not the TREC-7 CLIR task,which involved both cross-language informa-tion retrieval and the merging of documentsretrieved from sources in different languages.Preprocessing ofdocuments includes part-of-speech tagging and morphological anal-ysis.
(The training data for the transla-tion models was preprocessed i entically, sothat the translation models translated be-tween morphological root words rather thanbetween words.)
Our information retrievalsystems consists of first pass scoring withthe Okapi formula (Robertson et al, 1995)on unigrams and symmetrized bigrams (with210en, des, de, and - allowed as connectors) fol-lowed by a second pass re-scoring using localcontext analysis (LCA) as a query expan-sion technique (Xu and Croft, 1996).
Ourprimary basis for comparison of the resultsof the experiments was TREC-style averageprecision after the second pass, although wehave checked that our principal conclusionsfollow on the basis of first pass scores, andon the precision at rank 20.
In the querytranslation experiments, our implementationof query expansion corresponds to the post-translation expansion of (Ballasteros andCroft, 1997), (Ballasteros and Croft, 1998).All adjustable parameters in the IR sys-tem were left unchanged from their valuesin our TREC ad-hoc experiments (Chan etal., 1997),(Franz and Roukos, 1998), (Franzet al, 1999) or cited papers (Xu and Croft,1996), except for the number of documentsused as the basis for the LCA, which wasestimated at 15 from scaling considerations.Average precision for both query and docu-ment translation were noted to be insensitiveto this parameter (as previously observed inother contexts) and not to favor one or theother method of CLIR.4 Resu l tsIn experiment EqFd, document ranslationoutperformed query translation, as seen incolumns qt and dt of Table 1.
In experimentFqEd, query translation outperformed oc-ument translation, as seen in the columnsqt and dt of Table 2.
The relative perfor-mances of query and document ranslation,in terms of average precision, do not differbetween long and short forms of the queries,contrary to expectations that query transla-tion might fair better on longer queries.
Amore sophisticated translation model, incor-porating more nonlocal features into its def-inition of context might reveal a differencein this aspect.
A simple explanation is thatin both experiments, French=eeEnglish trans-lation outperformed English=~French trans-lation.
It is surprising that the differencein performance is this large, given that thetraining of the translation systems was iden-tical.
Reasons for this difference could bein the structure of the languages themselves;for example, the French tendency to usephrases such as pomme de terre for potatomay hinder retrieval based on the Okapi for-mula, which tends to emphasize matchingunigrams.
However, separate monolingualretrieval experiments indicate that the ad-vantages gained by indexing bigrams in theFrench documents were not only too smallto account for the difference between the re-trieval experiments involving opposite trans-lation directions, but were in fact smallerthan the gains made by indexing bigramsin the English documents.
The fact thatFrench is a more highly inflected languagethan English is unlikely to account for thedifference since both translation systems andthe IR system used morphologically ana-lyzed text.
Differences in the quality of pre-processing steps in each language, such astagging and morphing, are more difficult toaccount for, in the absence of standard met-rics for these tasks.
However, we believethat differences in preprocessing for each lan-guage have only a small effect on retrievalperformance.
Furthermore, these differencesare likely to be compensated for by the train-ing of the translation algorithm: since itstraining data was preprocessed i entically,a translation engine trained to produce lan-guage in a particular style of morphing iswell suited for matching translated docu-ments with queries morphed in the samestyle.
A related concern is "matching" be-tween translation model training data andretrieval set - the English AP documentsmight have been more similar to the Hansardthan the Swiss SDA documents.
All of theseconcerns heighten the importance of study-ing both translation directions within thelanguage pair.On a query-by-query basis, the scores arequite correlated, as seen in Fig.
(1).
OnTREC-7 short queries, the average preci-sions of query and document translation arewithin 0.1 of each other on 23 of the 28queries, on both FqEd and EqFd.
The re-maining outlier points tend to be accountedfor by simple translation errors, (e.g.
vol211EqFd qt dt qt + dt ht ht + dttrec6.dtrec6.tdntrec7.dtrec7.tdn0.2685 0.2819 0.2976 0.3494 0.35480.2981 0.3379 0.3425 0.3823 0.36640.3296 0.3345 0.3532 0.3611 0.40210.3826 0.3814 0.4063 0.4072 0.4192Table 1: Experiment EqFd: English queries retrieving French documentsAll numbers are TREC average precisions.qt : query translation systemdt : document ranslation systemqt + dt : hybrid system combining qt and dtht : monolingual baseline (equivalent to human translation)ht + dt : hybrid system combining ht and dtFqEdtrec6.dtrec6.tdntrec7.dtrec7.tdnqt0.32710.36660.40140.4541dt0.29920.33900.39260.4384qt + dt0.33960.37430.42640.4739ht0.28730.38890.43770.4812ht + dt0.33690.40160.44750.4937Table 2: Experiment FqEd: French queries retrieving English documentsAll numbers are TREC average precisions.qt : query translation systemdt : document ranslation systemqt + dt : hybrid system combining qt and dtht : monolingual baseline (equivalent to human translation)ht + dt : hybrid system combining ht and dtd'oeuvres d'art --4 flight art on the TREC-7 query CL,036.)
With the limited numberof queries available, it is not clear whetherthe difference in retrieval results between thetwo translation directions is a result of smalleffects across many queries, or is principallydetermined by the few outlier points.We remind the reader that the querytranslation and document translation ap-proaches to CLIR are not symmetrical.
In-formation is distorted in a different mannerby the two approaches, and thus a combi-nation of the two approaches may yield newinformation.
We have investigated this as-pect by developing a hybrid system in whichthe score of each document is the mean of its(normalized) scores from both the query anddocument translation experiments.
(A moregeneral linear combination would perhaps bemore suitable if the average precision of thetwo retrievals differed substantially.)
We ob-serve that the hybrid systems which combinequery translation and document translationoutperform both query translation and doc-ument translation individually, on both setsof documents.
(See column qt + dt of Tables1 and 2.
)Given the tradeoff between computer e-sources and quality of translation, somewould propose that correspondingly morecomputational effort should be put intoquery translation.
From this point of view,a document translation system based on fastMT should be compared with a query trans-lation system based on higher quality, butslower MT.
We can meaningfully investigatethis limit by regarding the human-translatedversions of the TREC queries as the ex-treme high-quality limit of machine trans-lation.
In this task, monolingual retrieval(the usual baseline for judging the degreeto which translation degrades retrieval per-formance in CLIR) can be regarded as theextreme high-quality limit of query trans-212o8 !g 0.4 i ,.0.0 0 ,  ?0.0 0.2 0.4 0.6 0.8 1.0Query trans.Figure 1: Scatterplot of average precision of document translation vs. query translation.lation.
Nevertheless, document translationprovides another source of information, sincethe context sensitive aspects of the transla-tion account for context in a manner distinctfrom current algorithms of information re-trieval.
Thus we do a further set of experi-ments in which we mix document translationand monolingual retrieval.
Surprisingly, wefind that the hybrid system outperforms thepure monolingual system.
(See columns htand ht +dr of Tables 1 and 2.)
Thus weconclude that a mixture of document trans-lation and query translation can be expectedto outperform pure query translation, evenvery high quality query translation.5 Conclusions and FutureWorkWe have performed experiments o comparequery and document translation-based CLIRsystems using statistical translation modelsthat are trained identically for both trans-lation directions.
Our study is the largestcomparative study of document translationand query translation of which we are aware;furthermore we have contrasted query anddocument translation systems on both direc-tions within a language pair.
We find noclear advantage for either the query trans-lation system or the document translationsystem; instead French=eeEnglish translationappears advantageous over English~Frenchtranslation, in spite of identical proceduresused in constructing both.
However a hy-brid system incorporating both directionsof translation outperforms either.
Further-more, by incorporating human query trans-lations rather than machine translations,we show that the hybrid system contin-ues to outperform query translation.
Wehave based our conclusions by comparingTREC-style average precisions of retrievalwith a two-pass IR system; the same con-clusions follow if we instead compare preci-sions at rank 20 or average precisions fromfirst pass (Okapi) scores.
Thus we concludethat even in the limit of extremely high qual-ity query translation, it will remain advan-tageous to incorporate both document andquery translation into a CLIR system.
Fu-ture work will involve investigating trans-lation direction differences in retrieval per-formance for other language pairs, and forstatistical translation systems trained fromcomparable, rather than parallel corpora.6 AcknowledgmentsThis work is supported by NIST grant no.70NANB5H1174.
We thank Scott Axel-rod, Martin Franz, Salim Roukos, and ToddWard for valuable discussions.213ReferencesL.
Ballasteros and W.B.
Croft.
1997.Phrasal translation and query expansiontechniques for cross-language informationretrieval.
In 20th Annual ACM SIGIRConference on Information Retrieval.L.
Ballasteros and W.B.
Croft.
1998.
Re-solving ambiguity for cross-language r -trieval.
In 21th Annual ACM SIGIR Con-ference on Information Retrieval.P.F.
Brown, J.C. Lai, and R.L.
Mercer.1991.
Aligning sentences in parallel cor-pora.
In Proceedings of the 29th AnnualMeeting of the Association for Computa-tional Linguistics.P.
Brown, S. Della Pietra, V. Della Pietra,and R. Mercer.
1993.
The mathematics ofstatistical machine translation : Param-eter estimation.
Computational Linguis-tics, 19:263-311.C.
Buckley, M. Mitra, J. Wals, andC.
Cardie.
1998.
Using clustering andsuperconcepts within SMART : TREC-6.In E.M. Voorhees and D.K.
Harman, ed-itors, The 6th Text REtrieval Conference(TREC-6).J.G.
Carbonell, Y. Yang, R.E.
Frederk-ing, R.D.
Brown, Yibing Geng, andDanny Lee.
1997.
Translingual informa-tion retrieval : A comparative evaluation.In Proceedings of the Fifteenth Interna-tional Joint Conference on Artificial In-telligence.E.
Chan, S. Garcia, and S. Roukos.
1997.TREC-5 ad-hoc retrieval using k nearest-neighbors re-scoring.
In E.M. Voorheesand D.K.
Harman, editors, The 5th TextREtrieval Conference (TREC-5).A.
Diekema, F. Oroumchian, P. Sheridan,and E. Liddy.
1999.
TREC-7 evaluationof Conceptual Interlingua Document Re-trieval (CINDOR) in English and French.In E.M. Voorhees and D.K.
Harman, ed-itors, The 7th Text REtrieval Conference(TREC-7).S.
Dumais, T.A.
Letsche, M.L.
Littman, andT.K.
Landauer.
1997.
Automatic cross-language retrieval using latent semanticindexing.
In AAAI Symposium on Cross-Language Text and Speech Retrieval.M.
Franz and S. Roukos.
1998.
TREC-6 ad-hoc retrieval.
In E.M. Voorhees and D.K.Harman, editors, The 6th Text REtrievalConference (TREC-6).M.
Franz, J.S.
McCarley, and S. Roukos.1999.
Ad hoc and multilingual informa-tion retrieval at IBM.
In E.M. Voorheesand D.K.
Harman, editors, The 7th TextREtrieval Conference (TREC-7).J.S.
McCarley and S. Roukos.
1998.
Fastdocument ranslation for cross-languageinformation retrieval.
In D. Farwell.,E.
Hovy, and L. Gerber, editors, MachineTranslation and the Information Soup,page 150.D.W.
Oard and P. Hackett.
1998.
Docu-ment translation for cross-language t xtretrieval at the University of Maryland.In E.M. Voorhees and D.K.
Harman, ed-itors, The 6th Text REtrieval Conference(TREC-6).D.W.
Oard.
1998.
A comparative study ofquery and document translation for cross-language information retrieval.
In D.
Far-well., E. Hovy, and L. Gerber, editors,Machine Translation and the InformationSoup, page 472.S.E.
Robertson, S. Walker, S. Jones, M.M.Hancock-Beaulieu, and M. Gatford.
1995.Okapi at TREC-3.
In E.M. Voorhees andD.K.
Harman, editors, The 3d Text RE-trieval Conference (TREC-3).Jinxi Xu and W. Bruce Croft.
1996.
Queryexpansion using local and global docu-ment analysis.
In 19th Annual ACM SI-GIR Conference on Information Retrieval.214
