Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 256?263,New York, June 2006. c?2006 Association for Computational LinguisticsSynchronous Binarization for Machine TranslationHao ZhangComputer Science DepartmentUniversity of RochesterRochester, NY 14627zhanghao@cs.rochester.eduLiang HuangDept.
of Computer & Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104lhuang3@cis.upenn.eduDaniel GildeaComputer Science DepartmentUniversity of RochesterRochester, NY 14627gildea@cs.rochester.eduKevin KnightInformation Sciences InstituteUniversity of Southern CaliforniaMarina del Rey, CA 90292knight@isi.eduAbstractSystems based on synchronous grammarsand tree transducers promise to improvethe quality of statistical machine transla-tion output, but are often very computa-tionally intensive.
The complexity is ex-ponential in the size of individual gram-mar rules due to arbitrary re-orderings be-tween the two languages, and rules ex-tracted from parallel corpora can be quitelarge.
We devise a linear-time algorithmfor factoring syntactic re-orderings by bi-narizing synchronous rules when possibleand show that the resulting rule set signif-icantly improves the speed and accuracyof a state-of-the-art syntax-based machinetranslation system.1 IntroductionSeveral recent syntax-based models for machinetranslation (Chiang, 2005; Galley et al, 2004) canbe seen as instances of the general framework ofsynchronous grammars and tree transducers.
In thisframework, both alignment (synchronous parsing)and decoding can be thought of as parsing problems,whose complexity is in general exponential in thenumber of nonterminals on the right hand side of agrammar rule.
To alleviate this problem, we investi-gate bilingual binarization to factor the synchronousgrammar to a smaller branching factor, although it isnot guaranteed to be successful for any synchronousrule with arbitrary permutation.
In particular:?
We develop a technique called synchronous bi-narization and devise a fast binarization algo-rithm such that the resulting rule set alows ef-ficient algorithms for both synchronous parsingand decoding with integrated n-gram languagemodels.?
We examine the effect of this binarizationmethod on end-to-end machine translationquality, compared to a more typical baselinemethod.?
We examine cases of non-binarizable rules in alarge, empirically-derived rule set, and we in-vestigate the effect on translation quality whenexcluding such rules.Melamed (2003) discusses binarization of multi-text grammars on a theoretical level, showing theimportance and difficulty of binarization for efficientsynchronous parsing.
One way around this diffi-culty is to stipulate that all rules must be binaryfrom the outset, as in inversion-transduction gram-mar (ITG) (Wu, 1997) and the binary synchronouscontext-free grammar (SCFG) employed by the Hi-ero system (Chiang, 2005) to model the hierarchicalphrases.
In contrast, the rule extraction method ofGalley et al (2004) aims to incorporate more syn-tactic information by providing parse trees for thetarget language and extracting tree transducer rulesthat apply to the parses.
This approach results inrules with many nonterminals, making good bina-rization techniques critical.Suppose we have the following SCFG, where su-perscripts indicate reorderings (formal definitions of256SNPBaoweierPPyuShalongVPjuxing lehuitanSNPPowellVPhelda meetingPPwithSharonFigure 1: A pair of synchronous parse trees in theSCFG (1).
The dashed curves indicate pairs of syn-chronous nonterminals (and sub trees).SCFGs can be found in Section 2):(1)S?
NP(1) VP(2) PP(3), NP(1) PP(3) VP(2)NP?
Powell, BaoweierVP?
held a meeting, juxing le huitanPP?
with Sharon, yu ShalongDecoding can be cast as a (monolingual) parsingproblem since we only need to parse the source-language side of the SCFG, as if we were construct-ing a CFG projected on Chinese out of the SCFG.The only extra work we need to do for decodingis to build corresponding target-language (English)subtrees in parallel.
In other words, we build syn-chronous trees when parsing the source-language in-put, as shown in Figure 1.To efficiently decode with CKY, we need to bi-narize the projected CFG grammar.1 Rules can bebinarized in different ways.
For example, we couldbinarize the first rule left to right or right to left:S?
VNP-PP VPVNP-PP?
NP PP orS?
NP VPP-VPVPP-VP ?
PP VPWe call those intermediate symbols (e.g.
VPP-VP) vir-tual nonterminals and corresponding rules virtualrules, whose probabilities are all set to 1.These two binarizations are no different in thetranslation-model-only decoding described above,just as in monolingual parsing.
However, in thesource-channel approach to machine translation, weneed to combine probabilities from the translationmodel (an SCFG) with the language model (an n-gram), which has been shown to be very impor-tant for translation quality (Chiang, 2005).
To dobigram-integrated decoding, we need to augmenteach chart item (X, i, j) with two target-language1Other parsing strategies like the Earley algorithm use aninternal binary representation (e.g.
dotted-rules) of the originalgrammar to ensure cubic time complexity.boundary words u and v to produce a bigram-itemlike( u ???
vXi j), following the dynamic program-ming algorithm of Wu (1996).Now the two binarizations have very different ef-fects.
In the first case, we first combine NP with PP:( Powell ???
PowellNP1 2): p( with ???
SharonPP2 4): q( Powell ???
Powell ???
with ???
SharonVNP-PP1 4): pqwhere p and q are the scores of antecedent items.This situation is unpleasant because in the target-language NP and PP are not contiguous so we can-not apply language model scoring when we build theVNP-PP item.
Instead, we have to maintain all fourboundary words (rather than two) and postpone thelanguage model scoring till the next step where VNP-PPis combined with ( held ???
meetingVP2 4) to form an S item.We call this binarization method monolingual bina-rization since it works only on the source-languageprojection of the rule without respecting the con-straints from the other side.This scheme generalizes to the case where wehave n nonterminals in a SCFG rule, and the decoderconservatively assumes nothing can be done on lan-guage model scoring (because target-language spansare non-contiguous in general) until the real nonter-minal has been recognized.
In other words, target-language boundary words from each child nonter-minal of the rule will be cached in all virtual non-terminals derived from this rule.
In the case ofm-gram integrated decoding, we have to maintain2(m ?
1) boundary words for each child nontermi-nal, which leads to a prohibitive overall complex-ity of O(|w|3+2n(m?1)), which is exponential in rulesize (Huang et al, 2005).
Aggressive pruning mustbe used to make it tractable in practice, which ingeneral introduces many search errors and adverselyaffects translation quality.In the second case, however:( with ???
SharonPP2 4): r( held ???
meetingVP4 7): s( held ???
SharonVPP-VP2 7): rs ?
Pr(with | meeting)Here since PP and VP are contiguous (butswapped) in the target-language, we can include the257NPNPPPVPVPPPtarget (English)source (Chinese)VPP-VPNPPPVPChinese indicesEnglishboundarywords 1 2 4 7PowellPowellheldmeetingwithSharonVPP-VPFigure 2: The alignment pattern (left) and alignmentmatrix (right) of the synchronous production.language model score by adding Pr(with | meeting),and the resulting item again has two boundarywords.
Later we add Pr(held | Powell) when theresulting item is combined with ( Powell ???
PowellNP1 2) toform an S item.
As illustrated in Figure 2, VPP-VP hascontiguous spans on both source and target sides, sothat we can generate a binary-branching SCFG:(2) S?
NP(1) VPP-VP(2), NP(1) VPP-VP(2)VPP-VP ?
VP(1) PP(2), PP(2) VP(1)In this case m-gram integrated decoding can bedone in O(|w|3+4(m?1)) time which is much lower-order polynomial and no longer depends on rule size(Wu, 1996), allowing the search to be much fasterand more accurate facing pruning, as is evidenced inthe Hiero system of Chiang (2005) where he restrictsthe hierarchical phrases to be a binary SCFG.
Thebenefit of binary grammars also lies in synchronousparsing (alignment).
Wu (1997) shows that parsinga binary SCFG is in O(|w|6) while parsing SCFG isNP-hard in general (Satta and Peserico, 2005).The same reasoning applies to tree transducerrules.
Suppose we have the following tree-to-stringrules, following Galley et al (2004):(3)S(x0:NP, VP(x2:VP, x1:PP))?
x0 x1 x2NP(NNP(Powell))?
BaoweierVP(VBD(held), NP(DT(a) NPS(meeting)))?
juxing le huitanPP(TO(with), NP(NNP(Sharon)))?
yu Shalongwhere the reorderings of nonterminals are denotedby variables xi.Notice that the first rule has a multi-level left-hand side subtree.
This system can model non-isomorphic transformations on English parse treesto ?fit?
another language, for example, learning thatthe (S (V O)) structure in English should be trans-formed into a (V S O) structure in Arabic, by look-ing at two-level tree fragments (Knight and Graehl,2005).
From a synchronous rewriting point of view,this is more akin to synchronous tree substitutiongrammar (STSG) (Eisner, 2003).
This larger localityis linguistically motivated and leads to a better pa-rameter estimation.
By imagining the left-hand-sidetrees as special nonterminals, we can virtually cre-ate an SCFG with the same generative capacity.
Thetechnical details will be explained in Section 3.2.In general, if we are given an arbitrary syn-chronous rule with many nonterminals, what are thegood decompositions that lead to a binary grammar?Figure 2 suggests that a binarization is good if ev-ery virtual nonterminal has contiguous spans on bothsides.
We formalize this idea in the next section.2 Synchronous BinarizationA synchronous CFG (SCFG) is a context-freerewriting system for generating string pairs.
Eachrule (synchronous production) rewrites a nontermi-nal in two dimensions subject to the constraint thatthe sequence of nonterminal children on one side isa permutation of the nonterminal sequence on theother side.
Each co-indexed child nonterminal pairwill be further rewritten as a unit.2 We define thelanguage L(G) produced by an SCFG G as the pairsof terminal strings produced by rewriting exhaus-tively from the start symbol.As shown in Section 3.2, terminals do not playan important role in binarization.
So we now writerules in the following notation:X ?
X(1)1 ...X(n)n , X(pi(1))pi(1) ...X(pi(n))pi(n)where each Xi is a variable which ranges over non-terminals in the grammar and pi is the permutationof the rule.
We also define an SCFG rule as n-aryif its permutation is of n and call an SCFG n-ary ifits longest rule is n-ary.
Our goal is to produce anequivalent binary SCFG for an input n-ary SCFG.2In making one nonterminal play dual roles, we follow thedefinitions in (Aho and Ullman, 1972; Chiang, 2005), origi-nally known as Syntax Directed Translation Schema (SDTS).An alternative definition by Satta and Peserico (2005) allowsco-indexed nonterminals taking different symbols in two di-mensions.
Formally speaking, we can construct an equivalentSDTS by creating a cross-product of nonterminals from twosides.
See (Satta and Peserico, 2005, Sec.
4) for other details.258(2,3,5,4)(2,3)2 3(5,4)5 4(2,3,5,4)2 (3,5,4)3 (5,4)5 4(a) (b) (c)Figure 3: (a) and (b): two binarization patternsfor (2, 3, 5, 4).
(c): alignment matrix for the non-binarizable permuted sequence (2, 4, 1, 3)However, not every SCFG can be binarized.
Infact, the binarizability of an n-ary rule is determinedby the structure of its permutation, which can some-times be resistant to factorization (Aho and Ullman,1972).
So we now start to rigorously define the bi-narizability of permutations.2.1 Binarizable PermutationsA permuted sequence is a permutation of consec-utive integers.
For example, (3, 5, 4) is a permutedsequence while (2, 5) is not.
As special cases, singlenumbers are permuted sequences as well.A sequence a is said to be binarizable if it is apermuted sequence and either1.
a is a singleton, i.e.
a = (a), or2.
a can be split into two sub sequences, i.e.a = (b; c), where b and c are both binarizablepermuted sequences.
We call such a division(b; c) a binarizable split of a.This is a recursive definition.
Each binarizablepermuted sequence has at least one hierarchical bi-narization pattern.
For instance, the permuted se-quence (2, 3, 5, 4) is binarizable (with two possiblebinarization patterns) while (2, 4, 1, 3) is not (seeFigure 3).2.2 Binarizable SCFGAn SCFG is said to be binarizable if the permu-tation of each synchronous production is binariz-able.
We denote the class of binarizable SCFGs asbSCFG.
This set represents an important subclassof SCFG that is easy to handle (parsable in O(|w|6))and covers many interesting longer-than-two rules.33Although we factor the SCFG rules individually and de-fine bSCFG accordingly, there are some grammars (the dashedSCFG bSCFG SCFG-2O(|w|6) parsableFigure 4: Subclasses of SCFG.
The thick arrow de-notes the direction of synchronous binarization.
Forclarity reasons, binary SCFG is coded as SCFG-2.Theorem 1.
For each grammar G in bSCFG, thereexists a binary SCFG G?, such that L(G?)
= L(G).Proof.
Once we decompose the permutation of nin the original rule into binary permutations, allthat remains is to decorate the skeleton binary parsewith nonterminal symbols and attach terminals tothe skeleton appropriately.
We explain the technicaldetails in the next section.3 Binarization AlgorithmsWe have reduced the problem of binarizing an SCFGrule into the problem of binarizing its permutation.This problem can be cast as an instance of syn-chronous ITG parsing (Wu, 1997).
Here the parallelstring pair that we are parsing is the integer sequence(1...n) and its permutation (pi(1)...pi(n)).
The goalof the ITG parsing is to find a synchronous tree thatagrees with the alignment indicated by the permu-tation.
In fact, as demonstrated previously, somepermutations may have more than one binarizationpatterns among which we only need one.
Wu (1997,Sec.
7) introduces a non-ambiguous ITG that prefersleft-heavy binary trees so that for each permutationthere is a unique synchronous derivation (binariza-tion pattern).However, this problem has more efficient solu-tions.
Shapiro and Stephens (1991, p. 277) infor-mally present an iterative procedure where in eachpass it scans the permuted sequence from left to rightand combines two adjacent sub sequences wheneverpossible.
This procedure produces a left-heavy bi-narization tree consistent with the unambiguous ITGand runs in O(n2) time since we need n passes in theworst case.
We modify this procedure and improvecircle in Figure 4), which can be binarized only by analyzinginteractions between rules.
Below is a simple example:S?
X(1) X(2) X(3) X(4), X(2) X(4) X(1) X(3)X?
a , a259iteration stack input action1 5 3 4 21 5 3 4 2 shift1 1 5 3 4 2 shift2 1 5 3 4 2 shift3 1 5 3 4 2 shift1 5 3-4 2 reduce [3, 4]1 3-5 2 reduce ?5, [3, 4]?4 1 3-5 2 shift1 2-5 reduce ?2, ?5, [3, 4]?
?1-5 reduce [1, ?2, ?5, [3, 4]??
]Figure 5: Example of Algorithm 1 on the input(1, 5, 3, 4, 2).
The rightmost column shows thebinarization-trees generated at each reduction step.it into a linear-time shift-reduce algorithm that onlyneeds one pass through the sequence.3.1 The linear-time skeleton algorithmThe (unique) binarization tree bi(a) for a binariz-able permuted sequence a is recursively defined asfollows:?
if a = (a), then bi(a) = a;?
otherwise let a = (b; c) to be the rightmostbinarizable split of a. thenbi(a) ={[bi(b), bi(c)] b1 < c1?bi(b), bi(c)?
b1 > c1.For example, the binarization tree for (2, 3, 5, 4)is [[2, 3], ?5, 4?
], which corresponds to the binariza-tion pattern in Figure 3(a).
We use [] and ??
forstraight and inverted combinations respectively, fol-lowing the ITG notation (Wu, 1997).
The rightmostsplit ensures left-heavy binary trees.The skeleton binarization algorithm is an instanceof the widely used left-to-right shift-reduce algo-rithm.
It maintains a stack for contiguous subse-quences discovered so far, like 2-5, 1.
In each it-eration, it shifts the next number from the input andrepeatedly tries to reduce the top two elements onthe stack if they are consecutive.
See Algorithm 1for details and Figure 5 for an example.Theorem 2.
Algorithm 1 succeeds if and only if theinput permuted sequence a is binarizable, and incase of success, the binarization pattern recoveredis the binarization tree of a.Proof.
?
: it is obvious that if the algorithm suc-ceeds then a is binarizable using the binarizationpattern recovered.?
: by a complete induction on n, the length of a.Base case: n = 1, trivial.Assume it holds for all n?
< n.If a is binarizable, then let a = (b; c) be its right-most binarizable split.
By the induction hypothesis,the algorithm succeeds on the partial input b, reduc-ing it to the single element s[0] on the stack and re-covering its binarization tree bi(b).Let c = (c1; c2).
If c1 is binarizable and trig-gers our binarizer to make a straight combinationof (b; c1), based on the property of permutations, itmust be true that (c1; c2) is a valid straight concate-nation.
We claim that c2 must be binarizable in thissituation.
So, (b, c1; c2) is a binarizable split to theright of the rightmost binarizable split (b; c), whichis a contradiction.
A similar contradiction will ariseif b and c1 can make an inverted concatenation.Therefore, the algorithm will scan through thewhole c as if from the empty stack.
By the in-duction hypothesis again, it will reduce c into s[1]on the stack and recover its binarization tree bi(c).Since b and c are combinable, the algorithm re-duces s[0] and s[1] in the last step, forming the bi-narization tree for a, which is either [bi(b), bi(c)] or?bi(b), bi(c)?.The running time of Algorithm 1 is linear in n, thelength of the input sequence.
This is because thereare exactly n shifts and at most n?1 reductions, andeach shift or reduction takes O(1) time.3.2 Binarizing tree-to-string transducersWithout loss of generality, we have discussed howto binarize synchronous productions involving onlynonterminals through binarizing the correspondingskeleton permutations.
We still need to tackle a fewtechnical problems in the actual system.First, we are dealing with tree-to-string trans-ducer rules.
We view each left-hand side subtreeas a monolithic nonterminal symbol and factor eachtransducer rule into two SCFG rules: one fromthe root nonterminal to the subtree, and the otherfrom the subtree to the leaves.
In this way we canuniquely reconstruct the tree-to-string derivation us-ing the two-step SCFG derivation.
For example,260Algorithm 1 The Linear-time Binarization Algorithm1: function BINARIZABLE(a)2: top?
0 .
stack top pointer3: PUSH(a1, a1) .
initial shift4: for i?
2 to |a| do .
for each remaining element5: PUSH(ai, ai) .
shift6: while top > 1 and CONSECUTIVE(s[top], s[top?
1]) do .
keep reducing if possible7: (p, q)?
COMBINE(s[top], s[top?
1])8: top?
top?
29: PUSH(p, q)10: return (top = 1) .
if reduced to a single element then the input is binarizable, otherwise not11: function CONSECUTIVE((a, b), (c, d))12: return (b = c?
1) or (d = a?
1) .
either straight or inverted13: function COMBINE((a, b), (c, d))14: return (min(a, c), max(b, d))consider the following tree-to-string rule:ADJPx0:RB JJresponsiblePPINforNP-CNPBDTthex2:NNx1:PP?
x0 fuze x1 de x2We create a specific nonterminal, say, T859, whichis a unique identifier for the left-hand side subtreeand generate the following two SCFG rules:ADJP ?
T859 (1), T859 (1)T859 ?
RB(1) resp.
for the NN(2) PP(3),RB(1) fuze PP(3) de NN(2)Second, besides synchronous nonterminals, ter-minals in the two languages can also be present, asin the above example.
It turns out we can attach theterminals to the skeleton parse for the synchronousnonterminal strings quite freely as long as we canuniquely reconstruct the original rule from its binaryparse tree.
In order to do so we need to keep track ofsub-alignments including both aligned nonterminalsand neighboring terminals.When binarizing the second rule above, we firstrun the skeleton algorithm to binarize the under-lying permutation (1, 3, 2) to its binarization tree[1, ?3, 2?].
Then we do a post-order traversal to theskeleton tree, combining Chinese terminals (one ata time) at the leaf nodes and merging English termi-nals greedily at internal nodes:[1, ?3, 2?
]1 ?3, 2?3 2?T859 [1,?3,2?
]V[RB, fuze]1RB fuzeV?V[PP, de], resp.
for the NN?
?3,2?V[PP, de]3PP deNN2A pre-order traversal of the decorated binarizationtree gives us the following binary SCFG rules:T859 ?
V1(1) V2(2), V1(1) V2(2)V1 ?
RB(1), RB(1) fuzeV2 ?
resp.
for the NN(1) V(2)3 , V(2)3 NN(1)V3 ?
PP(1), PP(1) dewhere the virtual nonterminals are:V1: V[RB, fuze]V2: V?V[PP, de], resp.
for the NN?V3: V[PP, de]Analogous to the ?dotted rules?
in Earley pars-ing for monolingual CFGs, the names we createfor the virtual nonterminals reflect the underlyingsub-alignments, ensuring intermediate states can beshared across different tree-to-string rules withoutcausing ambiguity.The whole binarization algorithm still runs in timelinear in the number of symbols in the rule (includ-ing both terminals and nonterminals).4 ExperimentsIn this section, we answer two empirical questions.26102e+064e+066e+068e+061e+070  5  10  15  20  25  30  35  40020406080100#ofrulespercentage(%)lengthFigure 6: The solid-line curve represents the distribution of all rules against permutation lengths.
Thedashed-line stairs indicate the percentage of non-binarizable rules in our initial rule set while the dotted-linedenotes that percentage among all permutations.4.1 How many rules are binarizable?It has been shown by Shapiro and Stephens (1991)and Wu (1997, Sec.
4) that the percentage of binariz-able cases over all permutations of length n quicklyapproaches 0 as n grows (see Figure 6).
However,for machine translation, it is more meaningful tocompute the ratio of binarizable rules extracted fromreal text.
Our rule set is obtained by first doing wordalignment using GIZA++ on a Chinese-English par-allel corpus containing 50 million words in English,then parsing the English sentences using a variantof Collins parser, and finally extracting rules usingthe graph-theoretic algorithm of Galley et al (2004).We did a ?spectrum analysis?
on the resulting ruleset with 50,879,242 rules.
Figure 6 shows how therules are distributed against their lengths (numberof nonterminals).
We can see that the percentageof non-binarizable rules in each bucket of the samelength does not exceed 25%.
Overall, 99.7% ofthe rules are binarizable.
Even for the 0.3% non-binarizable rules, human evaluations show that themajority of them are due to alignment errors.
It isalso interesting to know that 86.8% of the rules havemonotonic permutations, i.e.
either taking identicalor totally inverted order.4.2 Does synchronous binarizer help decoding?We did experiments on our CKY-based decoder withtwo binarization methods.
It is the responsibility ofthe binarizer to instruct the decoder how to computethe language model scores from children nontermi-nals in each rule.
The baseline method is mono-lingual left-to-right binarization.
As shown in Sec-tion 1, decoding complexity with this method is ex-ponential in the size of the longest rule and since wepostpone all the language model scorings, pruningin this case is also biased.system bleumonolingual binarization 36.25synchronous binarization 38.44alignment-template system 37.00Table 1: Syntax-based systems vs. ATSTo move on to synchronous binarization, we firstdid an experiment using the above baseline systemwithout the 0.3% non-binarizable rules and did notobserve any difference in BLEU scores.
So wesafely move a step further, focusing on the binariz-able rules only.The decoder now works on the binary translationrules supplied by an external synchronous binarizer.As shown in Section 1, this results in a simplified de-coder with a polynomial time complexity, allowingless aggressive and more effective pruning based onboth translation model and language model scores.We compare the two binarization schemes interms of translation quality with various pruningthresholds.
The rule set is that of the previous sec-tion.
The test set has 116 Chinese sentences of nolonger than 15 words.
Both systems use trigram asthe integrated language model.
Figure 7 demon-strates that decoding accuracy is significantly im-proved after synchronous binarization.
The numberof edges proposed during decoding is used as a mea-sure of the size of search space, or time efficiency.Our system is consistently faster and more accuratethan the baseline system.We also compare the top result of our syn-chronous binarization system with the state-of-the-art alignment-template approach (ATS) (Och andNey, 2004).
The results are shown in Table 1.
Oursystem has a promising improvement over the ATS26233.534.535.536.537.538.53e+09  4e+09  5e+09  6e+09  7e+09bleuscores# of edges proposed during decodingsynchronous binarizationmonolingual binarizationFigure 7: Comparing the two binarization methodsin terms of translation quality against search effort.system which is trained on a larger data-set but tunedindependently.5 ConclusionModeling reorderings between languages has been amajor challenge for machine translation.
This workshows that the majority of syntactic reorderings, atleast between languages like English and Chinese,can be efficiently decomposed into hierarchical bi-nary reorderings.
From a modeling perspective, onthe other hand, it is beneficial to start with a richerrepresentation that has more transformational powerthan ITG or binary SCFG.
Our work shows how toconvert it back to a computationally friendly formwithout harming much of its expressiveness.
As aresult, decoding with n-gram models can be fast andaccurate, making it possible for our syntax-basedsystem to overtake a comparable phrase-based sys-tem in BLEU score.
We believe that extensions ofour technique to more powerful models such as syn-chronous tree-adjoining grammar (Shieber and Sch-abes, 1990) is an interesting area for further work.Acknowledgments Much of this work was donewhen H. Zhang and L. Huang were visitingUSC/ISI.
The authors wish to thank Wei Wang,Jonathan Graehl and Steven DeNeefe for help withthe experiments.
We are also grateful to DanielMarcu, Giorgio Satta, and Aravind Joshi for discus-sions.
This work was partially supported by NSFITR IIS-09325646 and NSF ITR IIS-0428020.ReferencesAlbert V. Aho and Jeffery D. Ullman.
1972.
The The-ory of Parsing, Translation, and Compiling, volume 1.Prentice-Hall, Englewood Cliffs, NJ.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofACL-05, pages 263?270, Ann Arbor, Michigan.Jason Eisner.
2003.
Learning non-isomorphic tree map-pings for machine translation.
In Proceedings of ACL-03, companion volume, Sapporo, Japan.Michel Galley, Mark Hopkins, Kevin Knight, and DanielMarcu.
2004.
What?s in a translation rule?
In Pro-ceedings of HLT/NAACL-04.Liang Huang, Hao Zhang, and Daniel Gildea.
2005.
Ma-chine translation as lexicalized parsing with hooks.
InProceedings of IWPT-05, Vancouver, BC.Kevin Knight and Jonathan Graehl.
2005.
An overviewof probabilistic tree transducers for natural languageprocessing.
In Conference on Intelligent Text Process-ing and Computational Linguistics (CICLing).
LNCS.I.
Dan Melamed.
2003.
Multitext grammars and syn-chronous parsers.
In Proceedings of NAACL-03, Ed-monton.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Computational Linguistics, 30(4).Giorgio Satta and Enoch Peserico.
2005.
Some computa-tional complexity results for synchronous context-freegrammars.
In Proceedings of HLT/EMNLP-05, pages803?810, Vancouver, Canada, October.L.
Shapiro and A.
B. Stephens.
1991.
Bootstrap percola-tion, the Schro?der numbers, and the n-kings problem.SIAM Journal on Discrete Mathematics, 4(2):275?280.Stuart Shieber and Yves Schabes.
1990.
Synchronoustree-adjoining grammars.
In COLING-90, volume III,pages 253?258.Dekai Wu.
1996.
A polynomial-time algorithm for sta-tistical machine translation.
In 34th Annual Meetingof the Association for Computational Linguistics.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?403.263
