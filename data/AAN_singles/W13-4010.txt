Proceedings of the SIGDIAL 2013 Conference, pages 78?86,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsModeling Collaborative Referring for Situated Referential GroundingChangsong Liu, Rui Fang, Lanbo She, Joyce Y. ChaiDepartment of Computer Science and EngineeringMichigan State UniversityEast Lansing, MI 48824{cliu, fangrui, shelanbo, jchai}@cse.msu.eduAbstractIn situated dialogue, because humans andagents have mismatched capabilities ofperceiving the shared physical world, ref-erential grounding becomes difficult.
Hu-mans and agents will need to make ex-tra efforts by collaborating with each otherto mediate a shared perceptual basis andto come to a mutual understanding of in-tended referents in the environment.
Inthis paper, we have extended our previousgraph-matching based approach to explic-itly incorporate collaborative referring be-haviors into the referential grounding al-gorithm.
In addition, hypergraph-basedrepresentations have been used to accountfor group descriptions that are likely to oc-cur in spatial communications.
Our empir-ical results have shown that incorporatingthe most prevalent pattern of collaborationwith our hypergraph-based approach sig-nificantly improves reference resolution insituated dialogue by an absolute gain ofover 18%.1 IntroductionAs more and more applications require humansto interact with robots, techniques to support sit-uated dialogue have become increasingly impor-tant.
In situated dialogue, humans and artificialagents (e.g., robots) are co-present in a sharedenvironment to achieve joint tasks.
Their dia-logues often involve making references to the en-vironment.
To ensure the conversation proceedssmoothly, it is important to establish a mutual un-derstanding of these references, a process calledreferential grounding (Clark and Brennan, 1991):the agent needs to identify what the human refersto in the environment and the human needs toknow whether the agent?s understanding is correct;and vice versa.Although reference resolution (Heeman andHirst, 1995; Gorniak and Roy, 2004; Siebertand Schlangen, 2008) and referential ground-ing (Traum, 1994; DeVault et al 2005) have beenstudied in previous work, the unique characteris-tics of situated dialogue post bigger challenges tothis problem.
In situated dialogue, although hu-mans and agents are co-present in a shared world,they have different capabilities in perceiving theenvironment (a human can perceive and reasonabout the environment much better than an agent).The shared perceptual basis, which plays an im-portant role in facilitating referential groundingbetween the human and the agent, thus is miss-ing.
Communication between the human and theagent then becomes difficult, and they will needto make extra efforts to jointly mediate a sharedbasis and reach a mutual understanding (Clark,1996).
The goal of this paper is to investigate whatkinds of collaborative efforts may happen undermismatched perceptual capabilities and how suchcollaborations can be incorporated into our refer-ential grounding algorithm.Previous psycholinguistic studies have indi-cated that grounding references is a collaborativeprocess (i.e., collaborative referring) (Clark andWilkes-Gibbs, 1986; Clark and Brennan, 1991):The process begins with one participant present-ing an initial referring expression.
The other par-ticipant would then either accept it, reject it, orpostpone the decision.
If a presentation is notaccepted, then either one participant or the otherneeds to refashion it.
This new presentation (i.e.,the refashioned expression) is then judged again,and the process continues until the current pre-sentation is accepted.
To understand the implica-tion of collaborative referring under the situationof mismatched perceptual capabilities, we haveconducted experiments on human-human conver-sation using a novel experimental setup.
Our col-lected data demonstrate an overwhelming use of78collaborative referring to mediate a shared percep-tual basis.Motivated by these observations, we have de-veloped an approach that explicitly incorporatescollaborative referring into a graph-matching al-gorithm for referential grounding.
As the conver-sation unfolds, our approach incrementally buildsa dialogue graph by keeping track of the contri-butions (i.e., presentation and acceptance) fromboth the human and the robot.
This dialoguegraph is then matched against the perceived en-vironment (i.e., a vision graph representing whatare perceived by the robot from the environment)in order to resolve referring expressions from thehuman.
In addition, in contrast to our previousgraph-based approach (Liu et al 2012), the newapproach applies hypergraphs: a more generaland flexible representation that can capture group-based (n-ary) relations (whereas a regular graphcan only model binary relations between two enti-ties).
Our empirical results have shown that, incor-porating the most prevalent pattern of collabora-tion (i.e., agent-present-human-accept, discussedlater) with the hypergraph-based approach signif-icantly improves reference resolution in situateddialogue by an absolute gain of over 18%.In the following sections, we first give a briefdiscussion about the related work.
We then de-scribe our experiment setting and the patterns ofcollaboration observed in the collected data.
Wethen illustrate how to build a dialogue graph asthe conversation unfolds, followed by the formaldefinition of the hypergraph representation andthe referential grounding procedure.
Finally wedemonstrate the advantage of using hypergraphsand incorporating a prevalent collaborative behav-ior into the graph-matching approach for referenceresolution.2 Related WorkIn an early work, Mellish (Mellish, 1985) used aconstraint satisfaction approach to identify refer-ents that could be only partially specified.
Thiswork illustrated the theoretical idea of how to re-solve referring expressions based on an internalmodel of a world.
Heeman and Hirst (Heemanand Hirst, 1995) presented a planning-based ap-proach to cast Clark?s collaborative referring ideainto a computational model.
They used plan con-struction and plan inference to capture the pro-cesses of building referring expressions and identi-fying their referents.
Previous work in situated set-tings (Dhande, 2003; Gorniak and Roy, 2004; Fu-nakoshi et al 2005; Siebert and Schlangen, 2008)mainly focused on developing/learning computa-tional models that map words to visual features ofobjects in the environment.
These ?visual seman-tics?
of words were then integrated into seman-tic composition procedures to resolve referring ex-pressions.These previous work has provided valuable in-sights in computational approaches for referenceresolution.
However, they mostly dealt with a sin-gle expression or a single referent.
In this pa-per, our goal is to resolve complex referring di-alogues that involve multiple objects in a sharedenvironment.
In our previous work (Liu et al2012), we developed a graph-matching based ap-proach to address this problem.
However, the pre-vious approach can not handle group-based rela-tions among multiple objects.
Furthermore, it didnot look into incorporating collaborative behav-iors, which is a particularly important characteris-tic in situated dialogue.
This paper aims to addressthese limitations.3 Experiments and ObservationsTo investigate collaborative referring under mis-matched perceptual capabilities, we conducted ex-periments on human-human interaction (details ofthe experimental setup can be found in (Liu et al2012)).
In these experiments, we have two humansubjects play a set of naming games.
One sub-ject (referred to as the human-player) is providedwith an original image containing over ten objects(Figure 1(a)).
Several of these objects have se-cret names.
The other subject (referred to as therobot-player) only has access to an impoverishedimage of the same scene (Figure 1(b)) to mimicthe lower perceptual capability of a robot.
Thehuman-player?s goal is to communicate the namesof target objects to the robot-player so that therobot-player knows which object in his view haswhat name.
The impoverished image was auto-matically created by applying standard computervision algorithms and thus may contain differenttypes of processing errors (e.g., mis-segmentationand/or mis-recognition).Using this setup, we have collected a set of dia-logues.
The following shows an example dialoguesegment (collected using the images shown in Fig-ure 1):79Figure 1: An example of different images used inour experiments.H1: there is basically a cluster of four objects in the upperleft, do you see thatR2 : yesH: ok, so the one in the corner is a blue cupR : I see there is a square, but fine, it is blueH: alright, I will just go with that, so and then right underthat is a yellow pepperR : ok, I see apple but orangish yellowH: ok, so that yellow pepper is named BrittanyR : uh, the bottom left of those four?
Because I do see ayellow pepper in the upper rightH: the upper right of the four of them?R : yesH: ok, so that is basically the one to the right of the blue cupR : yeahH: that is actually an apple, it is green, I guess it has someamount of yellow on it, but that is a green apple and itis named Ashley.
.
.
.
.
.This example demonstrates two important char-acteristics regarding referential communicationunder mismatched perceptual capabilities.
First,conversation partners rely on both object-specificproperties (e.g., object class, color) and spatialrelations to describe objects in the environment.Spatial expressions include not only the binary re-lations (e.g., ?the one to the left of the blue cup?
),but also the group-based references (Tenbrink andMoratz, 2003; Funakoshi et al 2005) (e.g., ?theupper right of the four of them?
).Second, because the shared perceptual basisis missing here, the partners make extra effortsto refer and ground references.
For example,the human-player go through step-by-step install-ments (Clark and Wilkes-Gibbs, 1986) to cometo the targeted object.
The robot-player oftenproactively provides what he perceives from theenvironment.
The human-player and the robot-player collaborate with each other through itera-tive presentation-acceptance phases as describedin the Contribution Model proposed in (Clark andSchaefer, 1989; Clark and Brennan, 1991).1H stands for the human-player.2R stands for the robot-player.These observations indicate that, the approachto referential grounding in situated dialogueshould capture not only binary relations but alsogroup-based relations.
Furthermore, it should gobeyond traditional approaches that purely rely onsemantic constraints from single utterances.
Itshould incorporate the step-by-step collaborativedynamics from the discourse as the conversationproceeds.4 Modeling CollaborationIn this section, we first give a brief description ofcollaboration patterns observed in our data, andthen discuss one prevalent pattern and illustratehow it may be taken into consideration by ourcomputational approach for referential grounding.4.1 Patterns of CollaborationConsistent with Clark?s Contribution Model, theinteractions between the human-player and therobot-player in general fall into two phases: a pre-sentation phase and an acceptance phase.
In ourdata, a presentation phase mainly consists of thefollowing three forms:?
A complete description: the speaker issues acomplete description in a single turn.
For ex-ample, ?there is a red apple on the top right?.?
An installment: a description is dividedinto several parts/installments, each of whichneeds to be confirmed before continuing tothe rest.
For example,A: under the big green cup we just talked about,B: yesA: there are two apples,B: OKA: one is red and one is yellow.?
A trial: a description (either completed or in-complete) with a try marker.
For example, ?Isthere a red apple on the top right?
?In an acceptance phase, the addressee can eitheraccept or reject the current presentation.
Two ma-jor forms of accepting a presentation are observedin our data:?
Acknowledgement: the addressee explicitlyshows his/her understanding, using assertions(e.g., ?Yes?,?Right?, ?I see?)
or continuers(e.g., ?uh huh?, ?ok?).?
Relevant next turn: the addressee proceedsto the next contribution that is relevant to thecurrent presentation.
For example: A says ?Isee a red apple?
and directly following that Bsays ?there is also a green apple to the rightof that red one?.80In addition, there are also two forms of rejectinga presentation:?
Rejection: the addressee explicitly rejects thecurrent presentation, for example, ?I don?tsee any apple?.?
Alternative description: the addresseepresents an alternative description.
Forexample, A says ?there is a red apple on thetop left,?
and immediately following that Bsays ?I only see a red apple on the right?.In general, referential grounding dialogues inour data emerge as hierarchical structures of re-cursive presentation-acceptance phases.
The ac-ceptance to a previous presentation often repre-sents a new presentation itself, which triggers fur-ther acceptance.
In particular, our data showsthat when mediating their shared perceptual ba-sis, the human-player often takes into considera-tion what the robot-player sees and uses that togradually lead to his intended referents.
This isdemonstrated in the following example3, wherethe human-player accepts (Turn 3) the robot-player?s presentation (Turn 2) through a relevantnext turn.
(Turn 1) H: There is a kiwi fruit.
(Turn 2) R: I don?t see any kiwi fruit.
I see an apple.
(Turn 3) H: Do you see a mug to the right of that apple?
(Turn 4) R: Yes.
(Turn 5) H: OK, then the kiwi fruit is to the left of that apple.As shown later in Section 5, this is one promi-nent collaborative strategy observed in our data.We give this pattern a special name: agent-present-human-accept collaboration.
Next wecontinue to use this example to show how theagent-present-human-accept pattern can be incor-porated to potentially improve reference resolu-tion.4.2 An Illustrating ExampleIn this example, the human and the robot facea shared physical environment.
The robot per-ceives the environment through computer vision(CV) algorithms and generates a graph represen-tation (i.e., a vision graph), which captures theperceived objects and their spatial relations4.
Asshown in Figure 2(a), the kiwi is represented asan unknown object in the vision graph due to in-sufficient object recognition.
Besides the vision3This is a clean-up version of the original example todemonstrate the key ideas.4The spatial relations between objects are represented astheir relative coordinates in the vision graph.graph, the robot also maintains a dialogue graphthat captures the linguistic discourse between thehuman and the robot.At Turn 1 in Figure 2(b), the human says ?thereis a kiwi fruit?.
Upon receiving this utterance,through semantic processing, a node representing?a kiwi?
is generated (i.e., x1).
The dialogue graphat this point only contains this single node.
Iden-tifying the referent of the expression ?a kiwi fruit?is essentially a process that matches the dialoguegraph to the vision graph.
Because the visiongraph does not have a node representing a kiwi ob-ject, no high confidence match is returned at thispoint.
Therefore, the robot responds with a rejec-tion as in Turn 2 (Figure 2(c)) ?I don?t see anykiwi fruit?
5.
In addition, the robot takes an extraeffort to proactively describe what is being con-fidently perceived (i.e., ?I see an apple?).
Nowan additional node y1 is added to the dialoguegraph to represent the term ?an apple?
6.
Note thatwhen the robot generates the term ?an apple?, itknows precisely which object in the vision graphthis term refers to.
Therefore, as shown in Fig-ure 2(c), y1 is mapped to v2 in the vision graph.In Turn 3 (Figure 2(d)), through semantic pro-cessing on the human?s utterance ?a mug to theright of that apple?, two new nodes (x2 and x3)and their relation (RightOf ) are added to the di-alogue graph.
In addition, since ?that apple?
(i.e.,x2) corefers with ?an apple?
(i.e., y1) presented bythe robot in the previous turn, a coreference linkis created from x2 to y1.
Importantly, in this turnhuman displays his acceptance of the robot?s pre-vious presentation (?an apple?)
by coreferring to itand building further reference based on it.
This isexactly the agent-present-human-accept strategydescribed earlier.
Since y1 maps to object v2 andx2 now links to y1, it becomes equivalent to con-sider x2 also maps to v2.
We name a node suchas x2 a grounded node, since from the robot?spoint of view this node has been ?grounded?
to aperceived object (i.e., a vision graph node) via theagent-present-human-accept pattern.At this point, the robot matches the updated di-alogue graph with the vision graph again and can5Note that, since in this paper we are working with adataset of human-human (i.e., the human-player and therobot-player) dialogues, decisions from the robot-player areassumed known.
We leave robot?s decision making (i.e., re-sponse generation) into our future work.6We use xi to denote nodes that represent expressionsfrom the human?s utterances and yi to represent nodes fromthe robot?s utterances.81Figure 2: An example of incorporating collaborative efforts in an unfolding dialogue into graph representations.successfully match x3 to v3.
Note that, the match-ing occurs here is considered constrained graph-matching in the sense that some nodes in the dia-logue graph (i.e., x2) are already grounded, andthe only node needs to be matched against thevision graph is x3.
Different from previous ap-proaches that do not take dialogue dynamics intoconsideration, the constrained matching utilizesadditional constraints from the collaboration pat-terns in a dialogue and thus can improve both theefficiency and accuracy of the matching algorithm.This is one innovation of our approach here.Based on such matching result, the robot re-sponds with a confirmation as in Turn 4 Fig-ure 2(e)).
The human further elaborates in Turn5 ?the kiwi is to the left of the apple?.
Again se-mantic processing and linguistic coreference reso-lution will allow the robot to update the dialoguegraph as shown in Figure 2(f).
Given this dialoguegraph, based on the context of the larger dialoguegraph and through constrained matching, it willbe possible to match x1 to v1 although the objectclass of v1 is unknown.This example demonstrates how the dialoguegraph can be created to incorporate the collabo-rative referring behaviors as the conversation un-folds and how such accumulated dialogue graphcan help referential resolution through constrainedmatching.
Next, we give a detailed account onhow to create a dialogue graph and briefly discussgraph-matching for reference resolution.4.3 Dialogue GraphTo account for different types of referring expres-sions (i.e., object-properties, binary relations andgroup-based relations), we use hypergraphs to rep-resent dialogue graphs.4.3.1 Hypergraph RepresentationA directed hypergraph (Gallo et al 1993) is a 2-tuple in the form of G = (X, A), in whichX = {xm}A = {ai = (ti, hi) | ti ?
X, hi ?
X}82(a) Dialogue Graph (b) Vision GraphFigure 3: Example hypergraph representationsX is a set of nodes, and A is a set of ?hyperarcs?.Similar to an arc in a regular directed graph, eachhyperarc ai in a hypergraph also has two ?ends?,i.e., a tail (ti) and a head (hi).
The tail and headof a hyperarc are both subsets of X , thus they cancontain any number of nodes in X .
Hypergraph isa more general representation than regular graph.It can represent not only binary relations betweentwo nodes, but also group-based relations amongmultiple nodes.For example, suppose the language input issuedby the human includes the following utterances:1.
There is a cluster of four objects in the upper left.2.
The one in the corner is a blue cup.3.
Under the blue cup is a yellow pepper.4.
To the right of the blue cup, which is also in the upperright of the four objects, is a green apple.The corresponding dialogue graph Gd =(Xd, Ad) is shown in Figure 3(a), where Xd ={x1, x2, x3, x4} and Ad = {a1, a2, a3}.
In Ad,for example, a1 = ({x1}, {x3}) represents therelation ?right of?
between the tail {x3} and thehead {x1}, and a3 = ({x3}, {x1, x2, x3, x4}) rep-resents the group-based relation ?upper right?
be-tween one node and a group of nodes.As also illustrated in Figure 3(a), we can at-tach a set of labels (or attributes) {attrk} to anode/hyperarc, and use them to store specific in-formation about this node/hyperarc.
The per-ceived visual world can be represented by ahypergraph in a similar way (i.e., a vision graph),as shown in Figure 3(b) 7.4.3.2 Building Dialogue GraphsGiven the hypergraph representation, a set of op-erations can be applied to build a dialogue graphas the conversation unfolds.
It mainly consists ofthree components:7Hyperarcs of the vision graph are not shown in the figure.A hyperarc may exist between any two subsets of objects.Semantic Constraints.
Apply a semantic parser toextract information from human utterances.
Forexample, the utterance ?The kiwi is to the left ofthe apple?
can be parsed into a formal meaningrepresentation as[x1, x2] , [Kiwi(x1), Apple(x2), LeftOf(x1, x2)]This representation contains a list of discourseentities introduced by the utterance, and a list ofFOL predicates specifying the properties and rela-tions of these entities.
For each discourse entity, anode is added to the graph.
Unary predicates be-come the labels for nodes, and binary predicatesbecome arcs in the graph.
Group-based relationsare incorporated into the graphs as hyperarcs.Discourse Coreference.
For each discourse entityin a referring expression, identify whether it is anew discourse entity or it corefers to a discourseentity mentioned earlier.
In our previous examplein Figure 2(d), x2 corefers with y1, thus a coref-erence link is added to link the coreferring nodes.Coreferring nodes are merged before matching.Dialogue Dynamics.
Different types of dialoguedynamics can be modeled.
In this paper, we onlyfocus on a particularly prevalent type of dynamicsas observed from our data, i.e.
the agent-present-human-accept pattern as we described in Section4.1.
When such a pattern is identified, the associ-ated nodes (e.g., x2 in the previous example) willbe marked as grounded nodes and the mappingsto their grounded visual entities (i.e., vision graphnodes) will be added into the dialogue graph.Based on the above three types of operations,the dialogue graph is updated at each turn of theconversation.4.3.3 Constrained MatchingGiven a dialogue graph G = (X, A) and a vi-sion graph G?
= (X ?, A?
), reference resolutionbecomes a graph matching problem which is to83find a one-to-one mapping between the nodes inX and in X ?.
Due to the insufficiencies of theNLP and the CV components, both the dialoguegraph and the vision graph are likely to contain er-rors.
Therefore, we do not require every node inthe dialog graph to be mapped to a node in the vi-sion graph, but follow the inexact graph matchingcriterion (Conte et al 2004) to find the best matcheven if they are only partial.The matching algorithm is similar to the oneused in our previous work for regular graphs (Liuet al 2012), which uses a state-space search ap-proach (Zhang, 1999).
The key difference hereis to incorporate the agent-present-human-acceptcollaboration pattern.
The search procedure cannow start from the state that already representsthe known matching of grounded nodes (as il-lustrated in Section 4.2), instead of starting fromthe root.
Thus it is constrained in a smaller andmore promising subspace to improve both effi-ciency and accuracy.5 EvaluationA total of 32 dialogues collected from our ex-periments (as described in Section 3) are used inthe evaluation.
For each of these dialogues, wehave manually annotated (turn-by-turn) the formalsemantics, discourse coreferences and groundednodes as described in Section 4.3.2.
Since the fo-cus of this paper is on incorporating collaborationinto graph matching for referential grounding, weuse these annotations to build the dialogue graphsin our evaluation.
Vision graphs are automaticallygenerated by CV algorithms from the original im-ages used in the experiments.
The CV algorithms?object recognition performance is rather low: only5% of the objects in those images are correctly rec-ognized.
Thus reference resolution will need torely on relations and collaborative strategies.The 32 dialogue graphs have a total of 384nodes8 that are generated from human-players?
ut-terances (12 per dialogue on average), and a to-tal of 307 nodes generated from robot-players?
ut-terances (10 per dialogue on average).
Amongthe 307 robot-player generated nodes, 187 (61%)are initially presented by the robot-player andthen coreferred by human-players?
following ut-terances (i.e., relevant next turns).
This indicates8As mentioned in Section 4.3.2, multiple expressions thatare coreferential with each other and describing the same en-tity are merged into a single node.that the agent-present-human-accept strategy is aprevalent way to collaborate in our experiment.
Asmentioned earlier, those human-player generatednodes which corefer to nodes initiated by robot-players are marked as grounded nodes.
In total,187 out of the 384 human-player generated nodesare in fact grounded nodes.To evaluate our approach, we apply the graph-matching algorithm on each pair of dialogue graphand vision graph.
The matching results are com-pared with the annotated ground-truth to calcu-late the accuracy of our approach in ground-ing human-players?
referring descriptions to vi-sual objects.
For each dialogue, we have pro-duced matching results under four different set-tings: with/without modeling collaborative re-ferring (i.e., the agent-present-human-accept col-laboration) and with/without using hypergraphs.When collaborative referring is modeled, thegraph-matching algorithm uses the groundednodes to constrain its search space to match theremaining ungrounded nodes.
When collabora-tive referring is not modeled, all the human-playergenerated nodes need to be matched.The results of four different settings (averagedaccuracies on the 32 dialogues) are shown in Ta-ble 1.
Modeling collaborative referring improvesthe matching accuracies for both regular graphsand hypergraphs.
When regular graphs are used,it improves overall matching accuracy by 11.6%(p = 0.05, paired Wilcoxon T-test).
The improve-ment is even higher as 18.3% when hypergraphsare used (p = 0.012, paired Wilcoxon T-test).
Theresults indicate that proactively describing whatthe robot sees to the human to facilitate com-munication is an important collaborative strategyin referential grounding dialogues.
Humans canoften ground the robot presented object via theagent-present-human-accept strategy and use thegrounded object as a reference point to furtherdescribe other intended object(s), and our graph-matching approach is able to capture and utilizesuch collaboration pattern to improve the referen-tial grounding accuracy.The improvement is more significant whenhypergraphs are used.
A potential explanationis that those group-based relations captured byhypergraphs always involve multiple (more than2) objects (nodes).
If one node in a group-basedrelation is grounded, all other involved nodes canhave a better chance to be correctly matched.84Regular graph HypergraphNot modeling 44.1% 47.9%collaborative referringModeling 55.7% 66.2%collaborative referringImprovement 11.6% 18.3%Table 1: Averaged matching accuracies under fourdifferent settings.Group 1 Group 2 Group 3Number of dialogues 9 11 12% of grounded nodes <30% 30%?60% >60%Average number of 20 21 12object properties aAverage number of 11 13 8relations bNot modeling 49.7% 49.4% 45.3%collaborative referringModeling 57.0% 76.6% 63.6%collaborative referringImprovement 7.3% 27.2% 18.3%aSpecified by human-players.bSpecified by human-players.
The number includes bothbinary and group-based relations.Table 2: Matching accuracies of three groups ofdialogues (all the matching results here are pro-duced using hypergraphs).Whereas in regular graphs one grounded node canonly improve the chance of one other node, sinceonly one-to-one (binary) relations are captured byregular graphs.To further investigate the effect of modelingcollaborative referring, we divide the 32 dia-logues into three groups according to how oftenthe agent-present-human-accept collaboration pat-tern happens (measured by the percentage of thegrounded nodes among all the human-player gen-erated nodes in a dialogue).
As shown at the toppart of Table 2, the agent-present-human-acceptpattern happened less often in the dialogues ingroup 1 (i.e., less than 30% of human-player gen-erated nodes are grounded nodes).
In the dia-logues in group 2, robot-players more frequentlyprovided proactive descriptions which led to moregrounded nodes.
Robot-players were the mostproactive in the dialogues in group 3, thus thisgroup contains the highest percentage of groundednodes.
Note that, although the dialogues in group3 contain more proactive contributions from robot-players, human-players tend to specify less num-ber of properties and relations describing intendedobjects (as shown in the middle part of Table 2).The matching accuracies for each of the threegroups are shown at the bottom part of Table 2.Since the agent-present-human-accept pattern ap-pears less often in group 1, modeling collabora-tive referring only improves matching accuracyby 7.3%.
The improvements for group 2 andgroup 3 are more significant compared to group1.
However, group 3?s improvement is less thangroup 2, although the dialogues in group 3 containmore proactive contributions from robot-players.This indicates that in some cases even with mod-eling collaborative referring, underspecified in-formation from human speakers (human-playersin our case) may still be insufficient to identifythe intended referents.
Therefore, incorporating abroader range of dialogue strategies to elicit ade-quate information from humans is also importantfor successful human-robot communication.6 ConclusionIn situated dialogue, conversation partners makeextra collaborative efforts to mediate a shared per-ceptual basis for referential grounding.
It is impor-tant to model such collaborations in order to buildsituated conversational agents.
As a first step, wedeveloped an approach for referential groundingthat takes a particular type of collaborative refer-ring behavior, i.e.
agent-present-human-accept,into account.
By incorporating this pattern into thegraph-matching process, our approach has shownan absolute gain of over 18% in subsequent refer-ence resolution.
Extending the results in this pa-per, our future work will address explicitly model-ing the collaborative dynamics with a richer repre-sentation.
The dialogue graph presented in this pa-per represents all the mentioned entities and theirrelations that are currently available at any givendialogue status.
But we have not modeled the col-laborative dynamics at the illocutionary level.
Ournext step is to explicitly represent those dynam-ics, not only for grounding human references tothe physical world, but also generating the collab-orative behaviors for the agent.AcknowledgmentsThis work was supported by N00014-11-1-0410from the Office of Naval Research and IIS-1208390 from the National Science Foundation.ReferencesHerbert H Clark and Susan E Brennan.
1991.
Ground-ing in communication.
Perspectives on sociallyshared cognition, 13(1991):127?149.85Herbert H Clark and Edward F Schaefer.
1989.Contributing to discourse.
Cognitive science,13(2):259?294.Herbert H Clark and Deanna Wilkes-Gibbs.
1986.Referring as a collaborative process.
Cognition,22(1):1?39.Herbert H Clark.
1996.
Using language, volume 4.Cambridge University Press Cambridge.Donatello Conte, Pasquale Foggia, Carlo Sansone, andMario Vento.
2004.
Thirty years of graph match-ing in pattern recognition.
International journalof pattern recognition and artificial intelligence,18(03):265?298.David DeVault, Natalia Kariaeva, Anubha Kothari, IrisOved, and Matthew Stone.
2005.
An information-state approach to collaborative reference.
In Pro-ceedings of the ACL 2005 on Interactive poster anddemonstration sessions, pages 1?4.
Association forComputational Linguistics.Sheel Sanjay Dhande.
2003.
A computational modelto connect gestalt perception and natural language.Master?s thesis, Massachusetts Institute of Technol-ogy.Kotaro Funakoshi, Satoru Watanabe, Takenobu Toku-naga, and Naoko Kuriyama.
2005.
Understandingreferring expressions involving perceptual grouping.In 4th International Conference on Cyberworlds,pages 413?420.Giorgio Gallo, Giustino Longo, Stefano Pallottino,and Sang Nguyen.
1993.
Directed hypergraphsand applications.
Discrete applied mathematics,42(2):177?201.Peter Gorniak and Deb Roy.
2004.
Grounded seman-tic composition for visual scenes.
J. Artif.
Intell.Res.
(JAIR), 21:429?470.Peter A Heeman and Graeme Hirst.
1995.
Collabo-rating on referring expressions.
Computational Lin-guistics, 21(3):351?382.Changsong Liu, Rui Fang, and Joyce Y Chai.
2012.Towards mediating shared perceptual basis in situ-ated dialogue.
In Proceedings of the 13th AnnualMeeting of the Special Interest Group on Discourseand Dialogue, pages 140?149.
Association for Com-putational Linguistics.Christopher S Mellish.
1985.
Computer interpretationof natural language descriptions.
John Wiley andSons, New York, NY.Alexander Siebert and David Schlangen.
2008.
Asimple method for resolution of definite referencein a shared visual context.
In Proceedings of the9th SIGdial Workshop on Discourse and Dialogue,pages 84?87.
Association for Computational Lin-guistics.Thora Tenbrink and Reinhard Moratz.
2003.
Group-based spatial reference in linguistic human-robot in-teraction.
In Proceedings of EuroCogSci, volume 3,pages 325?330.David R Traum.
1994.
A Computational Theoryof Grounding in Natural Language Conversation.Ph.D.
thesis, University of Rochester.Weixiong Zhang.
1999.
State Space Search: Algo-rithms, Complexity, Extensions, and Applications.Springer.86
