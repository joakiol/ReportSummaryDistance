CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 97?104Manchester, August 2008Fully Unsupervised Graph-Based Discovery of General-Specific NounRelationships from Web Corpora Frequency CountsGa?l DiasHULTIGUniversity ofBeira Interiorddg@di.ubi.ptRaycho MukelovHULTIGUniversity ofBeira Interiorraicho@hultig.di.ubi.ptGuillaume CleuziouLIFOUniversity ofOrl?anscleuziou@univ-orleans.ptAbstract.In this paper, we propose a new metho-dology based on directed graphs and theTextRank algorithm to automatically in-duce general-specific noun relations fromweb corpora frequency counts.
Differentasymmetric association measures are im-plemented to build the graphs uponwhich the TextRank algorithm is appliedand produces an ordered list of nounsfrom the most general to the most specif-ic.
Experiments are conducted based onthe WordNet noun hierarchy and assess65.69% of correct word ordering.1 IntroductionTaxonomies are crucial for any knowledge-based system.
They are in fact important becausethey allow to structure information, thus foster-ing their search and reuse.
However, it is wellknown that any knowledge-based system suffersfrom the so-called knowledge acquisition bottle-neck, i.e.
the difficulty to actually model the do-main in question.
As stated in (Caraballo, 1999),WordNet has been an important lexical know-ledge base, but it is insufficient for domain spe-cific texts.
So, many attempts have been made toautomatically produce taxonomies (Grefenstette,1994), but (Caraballo, 1999) is certainly the firstwork which proposes a complete overview of theproblem by (1) automatically building a hierar-chical structure of nouns based on bottom-upclustering methods and (2) labeling the internalnodes of the resulting tree with hypernyms fromthe nouns clustered underneath by using patternssuch as ?B is a kind of A?.?
2008.
Licensed under the Creative Commons At-tribution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.In this paper, we are interested in dealing withthe second problem of the construction of an or-ganized lexical resource i.e.
discovering general-specific noun relationships, so that correct nounsare chosen to label internal nodes of any hierar-chical knowledge base, such as the one proposedin (Dias et al, 2006).
Most of the works pro-posed so far have (1) used predefined patterns or(2) automatically learned these patterns to identi-fy hypernym/hyponym relationships.
From thefirst paradigm, (Hearst, 1992) first identifies a setof lexico-syntactic patterns that are easily recog-nizable i.e.
occur frequently and across text genreboundaries.
These can be called seed patterns.Based on these seeds, she proposes a bootstrap-ping algorithm to semi-automatically acquirenew more specific patterns.
Similarly, (Carabal-lo, 1999) uses predefined patterns such as ?X is akind of Y?
or ?X, Y, and other Zs?
to identifyhypernym/hyponym relationships.
This approachto information extraction is based on a techniquecalled selective concept extraction as defined by(Riloff, 1993).
Selective concept extraction is aform of text skimming that selectively processesrelevant text while effectively ignoring surround-ing text that is thought to be irrelevant to the do-main.A more challenging task is to automatically learnthe relevant patterns for the hypernym/hyponymrelationships.
In the context of pattern extraction,there exist many approaches as summarized in(Stevenson and Greenwood, 2006).
The mostwell-known work in this area is certainly the oneproposed by (Snow et al, 2005) who use ma-chine learning techniques to automatically re-place hand-built knowledge.
By using depend-ency path features extracted from parse trees,they introduce a general-purpose formalizationand generalization of these patterns.
Given atraining set of text containing known hypernympairs, their algorithm automatically extracts use-ful dependency paths and applies them to newcorpora to identify novel pairs.
(Sang and Hof-97mann, 2007) use a similar way as (Snow et al,2006) to derive extraction patterns for hy-pernym/hyponym relationships by using websearch engine counts from pairs of words en-countered in WordNet.
However, the most inter-esting work is certainly proposed by (Bollegalaet al, 2007) who extract patterns in two steps.First, they find lexical relationships betweensynonym pairs based on snippets counts and ap-ply wildcards to generalize the acquired knowl-edge.
Then, they apply a SVM classifier to de-termine whether a new pair shows a relation ofsynonymy or not, based on a feature vector oflexical relationships.
This technique could beapplied to hypernym/hyponym relationships al-though the authors do not mention it.On the one hand, links between words that resultfrom manual or semi-automatic acquisition ofrelevant predicative or discursive patterns(Hearst, 1992; Carballo, 1999) are fine and accu-rate, but the acquisition of these patterns is a te-dious task that requires substantial manual work.On the other hand, works done by (Snow et al,2005; Snow et al, 2006; Sang and Hofmann,2007; Bollegala et al, 2007) have proposed me-thodologies to automatically acquire these pat-terns mostly based on supervised learning to le-verage manual work.
However, training sets stillneed to be built.Unlike other approaches, we propose an unsu-pervised methodology which aims at discoveringgeneral-specific noun relationships which can beassimilated to hypernym/hyponym relationshipsdetection2.
The advantages of this approach areclear as it can be applied to any language or anydomain without any previous knowledge, basedon a simple assumption: specific words tend toattract general words with more strength than theopposite.
As (Michelbacher et al, 2007) state:?there is a tendency for a strong forward associa-tion from a specific term like adenocarcinoma tothe more general term cancer, whereas the asso-ciation from cancer to adenocarcinoma is weak?.Based on this assumption, we propose a metho-dology based on directed graphs and the Tex-tRank algorithm (Mihalcea and Tarau, 2004) toautomatically induce general-specific noun rela-tionships from web corpora frequency counts.Indeed, asymmetry in Natural LanguageProcessing can be seen as a possible reason for2We must admit that other kinds of relationships may becovered.
For that reason, we will speak about general-specific relationships instead of hypernym/hyponym rela-tionships.the degree of generality of terms (Michelbacheret al, 2007).
So, different asymmetric associa-tion measures are implemented to build thegraphs upon which the TextRank algorithm isapplied and produces an ordered list of nouns,from the most general to the most specific.
Expe-riments have been conducted based on theWordNet noun hierarchy and assessed that 65%of the words are ordered correctly.2 Asymmetric Association MeasuresIn (Michelbacher et al, 2007), the authorsclearly point at the importance of asymmetry inNatural Language Processing.
In particular, wedeeply believe that asymmetry is a key factor fordiscovering the degree of generality of terms.
Itis cognitively sensible to state that when some-one hears about mango, he may induce the prop-erties of a fruit.
But, when hearing fruit, morecommon fruits will be likely to come into mindsuch as apple or banana.
In this case, there existsan oriented association between fruit and mango(mango ?
fruit) which indicates that mango at-tracts more fruit than fruit attracts mango.
As aconsequence, fruit is more likely to be a moregeneral term than mango.Based on this assumption, asymmetric associa-tion measures are necessary to induce these asso-ciations.
(Pecina and Schlesinger, 2006) and(Tan et al, 2004) propose exhaustive lists of as-sociation measures from which we present theasymmetric ones that will be used to measure thedegree of attractiveness between two nouns, xand y, where f(.,.
), P(.
), P(.,.)
and N are respec-tively the frequency function, the marginal prob-ability function, the joint probability function andthe total of digrams.
( ))),(),(),,(),(max(,Blanquet-Braunyxfyxfyxfyxfyxf++=(1)?????????????
?++=)()|(log),()()|(log),(,)()|(log),()()|(log),(maxmeasure JxPyxPyxPxPyxPyxPyPxyPyxPyPxyPyxP(2)[ ])|(),|(maxConfidence xyPyxP=(3)??????++++=2)(.1),(.,2)(.1),(.maxLaplaceyPNyxPNxPNyxPN(4)??????=),()().(,),()().(maxConvictionyxPyPxPyxPyPxP(5)98?????????
?=)(1)()|(,)(1)()|(maxFactorCertaintyxPxPyxPyPyPxyP(6)[ ])()|(),()|(maxValue Added xPyxPyPxyP ?
?=(7)All seven definitions show their asymmetry byevaluating the maximum value between two hy-potheses i.e.
by evaluating the attraction of xupon y but also the attraction of y upon x.
As aconsequence, the maximum value will decide thedirection of the general-specific association i.e.
(x ?
y) or (y ?
x).3 TextRank AlgorithmGraph-based ranking algorithms are essential-ly a way of deciding the importance of a vertexwithin a graph, based on global information re-cursively drawn from the entire graph.
The basicidea implemented by a graph-based rankingmodel is that of voting or recommendation.When one vertex links to another one, it is basi-cally casting a vote for that other vertex.
Thehigher the number of votes that are cast for a ver-tex, the higher the importance of the vertex.Moreover, the importance of the vertex castingthe vote determines how important the vote itselfis, and this information is also taken into accountby the ranking model.
Hence, the score asso-ciated with a vertex is determined based on thevotes that are cast for it, and the score of the ver-tices casting these votes.Our intuition of using graph-based ranking algo-rithms is that more general words will be morelikely to have incoming associations as they willbe associated to many specific words.
On theopposite, specific words will have few incomingassociations as they will not attract general words(see Figure 1).
As a consequence, the voting pa-radigm of graph-based ranking algorithms shouldgive more strength to general words than specificones, i.e.
a higher voting score.For that purpose, we first need to build a directedgraph.
Informally, if x attracts more y than y at-tracts x, we will draw an edge between x and y asfollows (x ?
y) as we want to give more creditsto general words.
Formally, we can define a di-rected graph G = (V, E) with the set of vertices V(in our case, a set of words) and a set of edges Ewhere E is a subset of V?V (in our case, definedby the asymmetric association measure valuebetween two words).
In Figure 1, we show thedirected graph obtained by using the set of wordsV = {isometry, rate of growth, growth rate, rate}randomly extracted from WordNet where rate ofgrowth and growth rate are synonyms, isometryan hyponym of the previous set and rate anhypernym of the same set.
The weights asso-ciated to the edges have been evaluated by theconfidence association measure (Equation 3)based on web search engine counts3.Fig.
1.
Directed Graph based on synset #13153496 (rate ofgrowth, growth rate) and its direct hypernym (rate) andhyponym (isometry).Figure 1 clearly shows our assumption of gene-rality of terms as the hypernym rate only hasincoming edges whereas the hyponym isometryonly has outgoing edges.
As a consequence, byapplying a graph-based ranking algorithm, weaim at producing an ordered list of words fromthe most general (with the highest value) to themost specific (with the lowest value).
For thatpurpose, we present the TextRank algorithm pro-posed by (Mihalcea and Tarau, 2004) both forunweighted and weighted directed graphs.3.1 Unweighted Directed GraphFor a given vertex Vi let In(Vi) be the set ofvertices that point to it, and let Out(Vi) be the setof vertices that vertex Vi points to.
The score of avertex Vi is defined in Equation 8 where d is adamping factor that can be set between 0 and 1,which has the role of integrating into the modelthe probability of jumping from a given vertex toanother random vertex in the graph4.
(8)3.2 Weighted Directed GraphIn order to take into account the edge weights,a new formula is introduced in Equation 9.3We used counts returned by http://www.yahoo.com.4d is usually set to 0.85.
)()|(|1)1()( jiVInVj ji VSVOutdd)S(V ?
?+?= ?
?99(9)After running the algorithm in both cases, a scoreis associated to each vertex, which represents the?importance?
of the vertex within the graph.
No-tice that the final values obtained after TextRankruns to completion are not affected by the choiceof the initial values randomly assigned to the ver-tices.
Only the number of iterations needed forconvergence may be different.
As a consequence,after running the TextRank algorithm, in both itsconfigurations, the output is an ordered list ofwords from the most general one to the mostspecific one.
In table 1, we show both the listswith the weighted and unweighted versions ofthe TextRank based on the directed graph shownin Figure 1.Unweighted Weighted WordNetS(Vi) Word WS(Vi) Word Categ.
Word0.50 rate 0.81 rate Hyper.
rate0.27 growthrate0.44 growthrateSynset growthrate0.19 rate of growth 0.26rate ofgrowth Synsetrate ofgrowth0.15 isometry 0.15 isometry Hypo.
isometryTable 1.
TextRank ordered lists.The results show that asymmetric measurescombined with directed graphs and graph-basedranking algorithms such as the TextRank arelikely to give a positive answer to our hypothesisabout the degree of generality of terms.
More-over, we propose an unsupervised methodologyfor acquiring general-specific noun relationships.However, it is clear that deep evaluation isneeded.4 Experiments and ResultsEvaluation is classically a difficult task inNatural Language Processing.
In fact, as humanevaluation is time-consuming and generally sub-jective even when strict guidelines are provided,measures to automatically evaluate experimentsmust be proposed.
In this section, we proposethree evaluation measures and discuss the respec-tive results.4.1 ConstraintsWordNet can be defined as applying a set ofconstraints to words.
Indeed, if word w is thehypernym of word x, we may represent this rela-tion by the following constraint y ?
x, where ?
isthe order operator stating that y is more generalthan x.
As a consequence, for each set of threesynsets (the hypernym synset, the seed synsetand the hyponym synset), a list of constraints canbe established i.e.
all words of the hypernymsynset must be more general than all the words ofthe seed synset and the hyponym synset, and allthe words of the seed synset must be more gener-al than all the words in the hyponym synset.
So,if we take the synsets presented in Table 1, wecan define the following set of constraints: {rate?
growth rate, rate ?
rate of growth, growth rate ?isometry, rate of growth ?
isometry}.In order to evaluate our list of words ranked bythe level of generality against the WordNet cate-gorization, we just need to measure the propor-tion of constraints which are respected as shownin Equation (10).
We call, correctness this meas-ure.
(10)For example, in Table 1, all the constraints arerespected for both weighted and unweightedgraphs, giving 100% correctness for the orderedlists compared to WordNet categorization.4.2 ClusteringAnother way to evaluate the quality of the or-dering of words is to apply hard clustering to thewords weighted by their level of generality.
Byevidencing the quality of the mapping betweenthree hard clusters generated automatically andthe hypernym synset, the seed synset and the hy-ponym synset, we are able to measure the qualityof our ranking.
As a consequence, we propose to(1) perform 3-means clustering over the list ofranked words, (2) classify the clusters by level ofgenerality and (3) measure the precision, recalland f-measure of each cluster sorted by level ofgenerality with the hypernym synset, the seedsynset and the hyponym synset.For the first task, we use the implementation ofthe k-means algorithm of the NLTK toolkit5.
Inparticular, we bootstrap the k-means by choosingthe initial means as follows.
For the first mean,we choose the weight (the score) of the first wordin the TextRank generated list of words.
For thesecond mean, we take the weight of the middleword in the list and for the third mean, the weightof the last word in the list.For the second task the level of generality ofeach cluster is evaluated by the average level of5http://nltk.sourceforge.net/)()1()()(jiVInVjjVOutVkjkjii VWSwwdd)WS(V ?
?+?= ?
??
?constraint of #constraintcommon  of #=scorrectnes100generality of words inside the cluster (or saidwith other words by its mean).For the third task, the most general cluster andthe hypernym synset are compared in terms of-precision, recall and f-measure as shown in Equ-ation (11), (12) and (13)6.
The same process isapplied to the second most general cluster andthe seed synset, and the third cluster and the hy-ponym synset.
(11)(12)(13)4.3 Rank Coefficient TestThe evaluation can be seen as a rank test be-tween two ordered lists.
Indeed, one way to eva-luate the results is to compare the list of general-specific relationships encountered by the Tex-tRank algorithm and the original list given byWordNet.
However, we face one problem.WordNet does not give an order of generalityinside synsets.
In order to avoid this problem, wecan order words in each synset by their estimatedfrequency given by WordNet7  as well as theirfrequency calculated by web search hits.
An ex-ample of both ordered lists is given in Table 2 forthe synset #6655336 and its immediate hyper-nyms and hyponyms.WordNet Estimated Frequency  Web Estimated FrequencyCategory Word Category WordHypernym statement Hypernym statementSynset answer Synset replySynset reply Synset responseSynset response Synset answerHyponym rescript Hyponym feedbackHyponym feedback Hyponym rescriptTable 2.
Estimated Frequency ordered lists for synset#6655336.For that purpose, we propose to use the Spear-man?s rank correlation coefficient (Rho).
TheSpearman?s Rho is a statistical coefficient thatshows how much two random variables are cor-6Where Cluster ?
Synset means the number of wordscommon to both Synset and Cluster, and |Synset| and|Cluster| respectively measure the number of words in theSynset and the Cluster.7We use WordNet 2.1.related.
It is defined in Equation (14) where d isthe distance between every pair of words in thelist ordered with TextRank and the reference listwhich is ordered according to WordNet or theWeb and n is the number of pairs of rankedwords.
(14)In particular, the Spearman?s rank correlationcoefficient is a number between -1 (no correla-tion at all) and 1 (very strong correlation).4.4 ExperimentsIn order to evaluate our methodology, we ran-domly8 extracted 800 seed synsets for which weretrieved their hypernym and hyponym synsets.For each seed synset, we then built the associateddirected weighted and unweighted graphs basedon the asymmetric association measures referredto in section 29 and ran the TextRank algorithmto produce a general-specific ordered lists ofterms.4.4.1 Results by ConstraintsIn Table 3, we present the results of the cor-rectness for all seven asymmetric measures, bothfor the unweighted and weighted graphs.Equation Type of Graph CorrectnessBraun-BlanquetUnweighted 65.68%Weighted 65.52%J measureUnweighted 60.00%Weighted 60.34%ConfidenceUnweighted 65.69%Weighted 65.40%LaplaceUnweighted 65.69%Weighted 65.69%ConvictionUnweighted 61.81%Weighted 63.39%Certainty FactorUnweighted 65.59%Weighted 63.76%Added ValueUnweighted 65.61%Weighted 64.90%Baseline10 None 55.68%Table 3.
Results for the Evaluation by Constraints.The best results are obtained by the Confidenceand the Laplace measures reaching 65.69% cor-8We guarantee 98% significance level for an error of 0.05following the normal distribution.9The probability functions are estimated by the MaximumLikelihood Estimation (MLE).10The baseline is the list of words ordered by web hits fre-quency (without TextRank).)1(6122???=?nndi?recallprecisionprecisionrecallmeasuref+?
?=?2|Cluster|Synset Cluster ?=precision|Synset|Synset Cluster ?=recall101rectness.
However, the Braun-Blanquet, the Cer-tainty Factor and the Added Value give resultsnear the best ones.
Only the J measure and theConviction metric seem to perform worst.It is also important to note that the differencebetween unweighted and weighted graphs ismarginal which clearly points at the fact that thetopology of the graph is more important than itsweighting.
This is also confirmed by the fact thatmost of the asymmetric measures perform alike.4.4.2 Results by ClusteringIn Table 4, we present the results of precision,recall and f-measure for both weighted and un-weighted graphs for all the seven asymmetricmeasures.
The best precision is obtained for theweighted graph with the Confidence measureevidencing 47.62% and the best recall is alsoobtained by the Confidence measure also for theweighted graph reaching 47.68%.
Once again,the J measure and the Conviction metric performworst showing worst f-measures.
Contrarily, theConfidence measure shows the best performancein terms of f-measure for the weighted graph, i.e.47.65% while the best result for the unweightedgraphs is obtained by the Certainty factor with46.50%.These results also show that the weighting of thegraph plays an important issue in our methodolo-gy.
Indeed, most metrics perform better withweighted graphs in terms of f-measure.Equation Graph Precision Recall F-measureBraun-BlanquetUnweighted 46.61 46.06 46.33Weighted 47.60 47.67 47.64J measureUnweighted 40.92 40.86 40.89Weighted 42.61 43.71 43.15ConfidenceUnweighted 46.54 46.02 46.28Weighted 47.62 47.68 47.65LaplaceUnweighted 46.67 46.11 46.39Weighted 46.67 46.11 46.39ConvictionUnweighted 42.13 41.67 41.90Weighted 43.62 43.99 43.80CertaintyFactorUnweighted 46.49 46.52 46.50Weighted 44.84 45.85 45.34AddedValueUnweighted 46.61 46.59 46.60Weighted 47.13 47.27 47.19Table 4.
Results for the Evaluation by Clustering.In Table 5, 6 and 7, we present the same resultsas in Table 4 but at different levels of analysisi.e.
precision, recall and f-measure at hypernym,seed and hyponym levels.
Indeed, it is importantto understand how the methodology performs atdifferent levels of generality as we verified thatour approach performs better at higher levels ofgenerality.Equation Graph Precision Recall F-measureBraun-BlanquetUnweighted 59.38 37.38 45.88Weighted 58.75 39.35 47.14J measureUnweighted 46.49 37.00 41.20Weighted 47.19 41.90 44.38ConfidenceUnweighted 59.20 37.30 45.77Weighted 58.71 39.22 47.03LaplaceUnweighted 59.50 37.78 45.96Weighted 59.50 37.78 45.96ConvictionUnweighted 50.07 35.88 41.80Weighted 52.72 40.74 45.96CertaintyFactorUnweighted 55.90 38.29 45.45Weighted 51.64 42.93 46.88AddedValueUnweighted 56.26 37.90 45.29Weighted 58.21 40.09 47.48Table 5.
Results at the hypernym level.Equation Graph Precision Recall F-measureBraun-BlanquetUnweighted 43.05 37.86 40.29Weighted 46.38 33.14 38.66J measureUnweighted 40.82 43.72 42.22Weighted 43.98 33.89 38.28ConfidenceUnweighted 43.03 37.67 40.17Weighted 46.36 33.02 38.57LaplaceUnweighted 43.10 37.78 40.27Weighted 43.10 37.78 40.27ConvictionUnweighted 40.36 38.02 39.16Weighted 42.60 26.39 32.59CertaintyFactorUnweighted 44.28 40.87 42.51Weighted 44.14 40.70 42.35AddedValueUnweighted 44.21 40.74 42.40Weighted 45.78 32.90 38.29Table 6.
Results at the seed level.Equation Graph Precision Recall F-measureBraun-BlanquetUnweighted 37.39 62.96 46.92Weighted 37.68 70.50 49.12J measureUnweighted 35.43 41.87 38.38Weighted 36.69 55.33 44.12ConfidenceUnweighted 37.38 63.09 46.95Weighted 37.79 70.80 49.27LaplaceUnweighted 37.40 63.11 46.97Weighted 37.40 63.11 46.97ConvictionUnweighted 35.97 50.94 42.16Weighted 35.54 64.85 45.92CertaintyFactorUnweighted 39.28 60.40 47.60Weighted 38.74 53.92 45.09AddedValueUnweighted 39.36 61.15 47.89Weighted 37.39 68.81 48.45Table 7.
Results at the hyponym level.Indeed, the precision scores go down from59.50% at the hypernym level to 39.36% at thehyponym level with 46.38% at the seed level.The same phenomenon is inversely true for therecall with 42.93% at the hypernym level,10243.72% at the seed level and 70.80% at the hy-ponym level.This situation can easily be understood as mostof the clusters created by the k-means present thesame characteristics i.e.
the upper level clusterusually has fewer words than the middle levelcluster which in turn has fewer words than thelast level cluster.
As a consequence, the recall isartificially high for the hyponym level.
But onthe opposite, the precision is high for higher le-vels of generality which is promising for the au-tomatic construction of hierarchical thesauri.
In-deed, our approach can be computed recursivelyso that each level of analysis is evaluated as if itwas at the hypernym level, thus taking advantageof the good performance of our approach at up-per levels of generality11.4.4.3 Results by Rank TestFor each produced list, we calculated theSpearman?s Rho both with WordNet and WebEstimated Lists for weighted and unweightedgraphs.
Table 8 presents the average results forthe 800 randomly selected synsets.EquationType ofGraphRho withWNet Est.listRho withWeb Est.listBraun-BlanquetUnweighted 0.38 0.30Weighted 0.39 0.39J measureUnweighted 0.23 0.19Weighted 0.27 0.27ConfidenceUnweighted 0.38 0.30Weighted 0.39 0.39LaplaceUnweighted 0.38 0.30Weighted 0.38 0.38ConvictionUnweighted 0.30 0.22Weighted 0.33 0.33CertaintyFactorUnweighted 0.38 0.29Weighted 0.35 0.35Added ValueUnweighted 0.37 0.29Weighted 0.38 0.38Baseline12 None 0.14 0.14Table 8.
Results for the Spearman?s rank correlationcoefficient.Similarly to what we evidenced in section 4.4.1.,the J measure and the Conviction metric are themeasures which less seem to map the correct or-der by evidencing low correlation scores.
On theother hand, the Confidence metric still gives thebest results equally with the Laplace and Braun-Blanquet metrics.11This will be studied as future work.12The baseline is the list of words ordered by web hits fre-quency.It is interesting to note that in the case of the webestimated list, the weighted graphs evidencemuch better results than the unweighted ones,although they do not show improved resultscompared to the WordNet list.
On the one hand,these results show that our methodology is capa-ble to map to WordNet lists as easily as to Weblists even that it is based on web frequencycounts.
On the other hand, the fact that weightedgraphs perform best, shows that the topology ofthe graph lacks in accuracy and needs the appli-cation of weights to counterpoint this lack.4.5 DiscussionAn important remark needs to be made at thispoint of our explanation.
There is a large ambi-guity introduced in the methodology by justlooking at web counts.
Indeed, when countingthe occurrences of a word like answer, we countall its occurrences for all its meanings and forms.For example, based on WordNet, the word an-swer can be a verb with ten meanings and a nounwith five meanings.
Moreover, words are morefrequent than others although they are not sogeneral, unconfirming our original hypothesis.Looking at Table 2, feedback is a clear exampleof this statement.
As we are not dealing with asingle domain within which one can expect tosee the ?one sense per discourse?
paradigm, it isclear that the Rho coefficient would not be asgood as expected as it is clearly biased by ?incor-rect?
counts.
One direct implication of this com-ment is the use of web estimated lists to evaluatethe methodology.Also, there has been a great discussion over thelast few months in the corpora list13 whether oneshould use web counts instead of corpus countsto estimate word frequencies.
In our study, weclearly see that web counts show evident prob-lems, like the ones mentioned by (Kilgarriff,2007).
However, they cannot be discarded soeasily.
In particular, we aim at looking at webcounts in web directories that would act as spe-cific domains and would reduce the space forambiguity.
Of course, experiments with well-known corpora will also have to be made to un-derstand better this phenomenon.5 Conclusions and Future WorkIn this paper, we proposed a new methodologybased on directed weighted/unweighted graphsand the TextRank algorithm to automatically in-13Finalized by (Kilgarriff, 2007).103duce general-specific noun relationships fromweb corpora frequency counts.
To our know-ledge, such an unsupervised experiment has nev-er been attempted so far.
In order to evaluate ourresults, we proposed three different evaluationmetrics.
The results obtained by using sevenasymmetric association measures based on webfrequency counts showed promising resultsreaching levels of (1) constraint coherence of65.69%, (2) clustering mapping of 59.50% interms of precision for the hypernym level and42.72% on average in terms of f-measure and (3)ranking similarity of 0.39 for the Spearman?srank correlation coefficient.As future work, we intend to take advantage ofthe good performance of our approach at thehypernym level to propose a recursive process toimprove precision results over all levels of gene-rality.Finally, it is important to notice that the evalua-tion by clustering evidences more than a simpleevaluation of the word order, but shows how thisapproach is capable to automatically map clus-ters to WordNet classification.ReferencesBollegala, D., Matsuo, Y. and Ishizuka, M. 2007.Measuring Semantic Similarity between Words Us-ing WebSearch Engines.
In Proceedings of Interna-tional World Wide Web Conference (WWW2007).Caraballo, S.A. 1999.
Automatic Construction of aHypernym-labeled Noun Hierarchy from Text.
InProceedings of the Conference of the Associationfor Computational Linguistics (ACL 1999).Dias, G., Santos, C., and Cleuziou, G. 2006.
Automat-ic Knowledge Representation using a Graph-basedAlgorithm for Language-Independent LexicalChaining.
In Proceedings of the Workshop on In-formation Extraction Beyond the Document asso-ciated to the Joint Conference of the InternationalCommittee of Computational Linguistics and theAssociation for Computational Linguistics (COL-ING/ACL), pages.
36-47.Grefenstette, G. 1994.
Explorations in AutomaticThesaurus Discovery.
Kluwer Academic Publish-ers, USA.Hearst, M.H.
1992.
Automatic Acquisition of Hypo-nyms from Large Text Corpora.
In Proceedings ofthe Fourteenth International Conference on Com-putational Linguistics (COLING 1992), pages 539-545.Kilgarriff, A.
2007.
Googleology is Bad Science.Computational Linguistics 33 (1), pages: 147-151.Michelbacher, L., Evert, S. and Sch?tze, H. 2007.Asymmetric Association Measures.
In Proceedingsof the Recent Advances in Natural LanguageProcessing (RANLP 2007).Mihalcea, R. and Tarau, P. 2004.
TextRank: BringingOrder into Texts.
In Proceedings of the Conferenceon Empirical Methods in Natural LanguageProcessing (EMNLP 2004), pages 404-411.Pecina, P. and Schlesinger, P. 2006.
Combining Asso-ciation Measures for Collocation Extraction.
InProceedings of the International Committee ofComputational Linguistics and the Association forComputational Linguistics (COLING/ACL 2006).Riloff, E. 1993.
Automatically Constructing a Dictio-nary for Information Extraction Tasks.
In Proceed-ings of the Eleventh National Conference on Ar-tificial Intelligence (AAAI 1993), pages 811-816.Sang, E.J.K.
and Hofmann, K. 2007.
Automatic Ex-traction of Dutch Hypernym-Hyponym Pairs.
InProceedings of Computational Linguistics in theNetherlands Conference (CLIN 2007).Snow, R., Jurafsky, D. and Ng, A. Y.
2005.
LearningSyntactic Patterns for Automatic Hypernym Dis-covery.
In Proceedings of the International Com-mittee of Computational Linguistics and the Asso-ciation for Computational Linguistics (COL-ING/ACL 2006).Snow, R., Jurafsky, D. and Ng, A. Y.
2005.
SemanticTaxonomy Induction from Heterogenous Evidence.In Proceedings of the Neural InformationProcessing Systems Conference (NIPS 2005).Stevenson, M., and Greenwood, M. 2006.
ComparingInformation Extraction Pattern Models.
In Proceed-ings of the Workshop on Information ExtractionBeyond the Document associated to the Joint Con-ference of the International Committee of Compu-tational Linguistics and the Association for Com-putational Linguistics (COLING/ACL 2006), pag-es.
29-35.Tan, P.-N., Kumar, V. and Srivastava, J.
2004.
Select-ing the Right Objective Measure for AssociationAnalysis.
Information Systems, 29(4).
pages 293-313.104
