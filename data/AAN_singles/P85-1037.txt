EXTRACTING SEMANTIC HIERARCHIES FROM A LARGE ON-LINE DICTIONARYMartin S. ChodorowDepartment of Psychology, Hunter College of CUNYandI.B.M.
Thomas J. Watson Research CenterYorktown Heights, New York 10598Roy J. ByrdGeorge E. HeidornI.B.M.
Thomas J. Watson Research CenterYorktown Heights, New York 10598ABSTRACTDictionaries are rich sources of detailed semantic infor-mation, but in order to use the information for naturallanguage processing, it must be organized systematically.This paper describes automatic and semi-automaticprocedures for extracting and organizing semantic fea=ture information implicit in dictionary definitions.
Twohead-finding heuristics are described for locating thegenus terms in noun and verb definitions.
The assump-tion is that the genus term represents inherent featuresof the word it defines.
The two heuristics have beenused to process definitions of 40,000 nouns and 8,000verbs, producing indexes in which each genus term isassociated with the words it defined.
The Sprout pro-gram interactively grows a taxonomic "tree" from anyspecified root feature by consulting the genus index.
Itsoutput is a tree in which all of the nodes have the rootfeature for at least one of their senses.
The Filter pro-gram uses an inverted form of the genus index.
Filteringbegins with an initial filter file consisting of words thathave a given feature (e.g.
\[+human\]) in all of theirsenses.
The program then locates, in the index, wordswhose genus terms all appear in the filter file.
The out-put is a list of new words that have the given feature inall of their senses.1.
Introduction.The goal of this research is to extract semantic informa-tion from standard dictionary definitions, for use inconstructing lexicons for natural language processingsystems.
Although dictionaries contain finely detailedsemantic knowledge, the systematic organization of thatknowledge has not heretofore been exploited in such away as to make the information available for computerapplications.Amsler(1980) demonstrates that additional structurecan be imposed upon a dictionary by making certain as-sumptions about the ways in which definitions are con-structed.
Foremost among these assumptions is thatdefinitions consist of a "genus" term, which identifiesthe superordinate concept of the defined word, and"differentia" which distinguish this instance of thesuperordinate category from other instances.
By manu-ally extracting and disambiguating genus terms for apocket dictionary, Amsler demonstrated the feasibilityof generating semantic hierarchies.It was our goal to automate the genus extraction anddisambiguation processes o that semantic hierarchiescould be generated from full-sized dictionaries.
Thefully automatic genus extraction process is described inSection 2.
Sections 3 and 4 describe two differentdisambiguation and hierarchy-extraction techniques thatrely on the genus information.
Both of these techniques299are semi-automatic, since they crucially require decisions?
to be made by a human user during processing.
Never-theless, significant savings occur when the system or-ganizes the presentation of material to the user.
Furthereconomy results from the automatic access to word de-finitions contained in the on-line dictionary from whichthe genus terms were extracted.The information extracted using the techniques we havedeveloped will initially be used to add semantic infor-mation to entries in the lexicons accessed by variousnatural anguage processing programs developed as partof the EPISTLE project at IBM.
Descriptions of someof these programs may be found in Heidorn, et al(1982), and Byrd and McCord(1985).2.
Head finding.In the definition of car given in Figure 1, and repeatedhere:car : a vehicle moving on wheels.the word vehicle serves as the genus term, while movingon wheels differentiates cars from some other types ofvehicles.
Taken as an ensemble, all of the word/genuspairs contained in a normal dictionary for words of agiven part-of-speech form what Amsler(1980) calls a"tangled hierarchy".
In this hierarchy, each word wouldconstitute a node whose subordinate nodes are wordsfor which it serves as a genus term.
The words at thosesubordinate nodes are called the word's "hyponyms".Similarly, the words at the superordinate nodes for agiven word are the genus terms for the various sensedefinitions of that word.
These are called the givenword's "hypernyms".
Because words are ambiguous(i.e.. have multiple senses), any word may have multiplehypernyms; hence the hierarchy is "tangled".Figure I shows selected efinitions from Webster's Sev-enth New Collegiate Dictionary for vehicle and a few re-lated words.
In each definition, the genus term has beenitalicized.
Figure 2 shows the small segment of the tan-fled hierarchy based on those definitions, with thehyponyms and hypernyms of vehicle labelled.vehicle: (n) (often attrib) an inert medium inwhich a medicinally active agent is ad-ministeredvehicle: (n) any of various other media acting usu.as solvents, carriers, or binders for ac-five ingredients or pigmentsvehicle: (n) an agent of transmission : CARRIERvehicle: (n) a medium through which somethingis expressed, achieved, or displayedvehicle: (n) a means of carrying or transportingsomething : CONVEYANCEvehicle: (n) a piece of mechanized equipmentambulance: (n) a vehicle equipped for transport-ing wounded, injured, or sick personsor animalsbicycle: (n) a vehicle with two wheels tandem, asteering handle, a saddle seat, andpedals by which it is propelledcar: (n) a vehicle moving on wheelstanker: (n) a cargo boat fitted with tanks for car-rying liquid in bulktanker: (n) a vehicle on which a tank is mountedto carry liquids: also : a cargo airplanefor transporting fuelFigure 1.
Selected ictionary definitions.Our automated mechanism for finding the genus termsis based on the observation that the genus term for verband noun definitions is typically the head of the definingphrase.
This reduces the task to that of finding theheads of verb phrases and noun phrases.300medium means agent equipmentvehicle',~ boat airplaneIambulance bicycle car tankerFigure 2.
The tangled hierarchy around "vehicle".The syntax of the verb phrase used in verb definitionsmakes it possible to locate its head with a simpleheuristic: the head is the single verb following the wordto.
If there is a conjunction of verbs following to, thenthey are all heads.
Thus, given the following two defi-nitions for winter.winter: (v) to pass the winterwinter: (v} to keep.
feed.
or manage during the winterthe heuristic would find four heads: pass.
keep, feed, andmanage.Applying this heuristic to the definitions for the 8,000verbs that have definitions in Webster's Seventh showedthat 2225 distinct verbs were used as heads of defi-nitions and that they were used 24,000 times.
In otherwords, each genus term served as the hypernym for tenother verbs, on average.
The accuracy of head findingfor verbs was virtually 100 percent.Head finding is much more complex for noun definitionsbecause of their ffeater variety.
At the same time, themagnitude of the task (over 80,000 defining nounphrases) demanded that we use a heuristic procedure,rather than a full parser, which would have been pro-hibitively expensive.
We were able to take advantageof the fact that dictionary definitions are written in aspecial and predictable style, and that their analysis doesnot require the full power of an analyzer for generalEnglish.The procedure used may be briefly described as follows.First the substring of the definition which must containthe head is found.
This substring is bounded on the leftby a word which obligatorily appears in prenominal po-sition: a, an, the, its, two, three ..... twelve, first, second,...
It is bounded on the right by a word or sequence thatcan only appear in postnominal position:?
a relative pronoun (introducing a relative clause)?
a preposition ot followed by a conjunction (thus.introducing a complement to the head noun)?
a preposition-conjunction-preposition configuration(also introducing a complement)?
a present participle following a noun (thus, intro-ducing a reduced relative clause)The heuristic for finding the boundary on the rightworks because of certain restrictions on constituentsappearing within a noun phrase.
Emends (1976, pp.167-172} notes that an adjective phrase or a verb phrasemust end with its phrasal head if it appears to the left ofthe head noun in a noun phrase.
For example, in the veryold man, the adjective phrase very old has its head ad-jective in final position; in the quietly sleeping children,the verb phrase quietly sleeping ends in its head verb.Another constraint, the Surface Recursion Restriction(Emends, 1976, p. 19), prohibits free recursion of anode appearing within a phrase, to the left of the phrasehead.
This prevents prenominal modifying phrases fromcontaining S and PP nodes.
Taken together, the tworestrictions specify that S, PP, and any other constituentwhich does not end in its head-of-phrase element cannotappear as a prenominal modifier and must, therefore, bepostnominal.
Lexical items or sequences that mark thebeginnings of these constituents are used by the heuristicto establish the right boundary of the substring whichmust contain the head of the noun definition.Once the substring is isolated, the search for the headbegins.
Typically, but not always, it is the rightmostnoun in the substring.
If however, the substring containsa conjunction, each conjunct is processed separately,and multiple heads may result.
\[f the word found be-longs to a small class of "empty heads" (words like one,any, kind.
class, manner, family, race.
group, complex,etc.)
and is followed by of, then the string following ofis reprocessed in an effort to locate additional heads.301Applying this procedure to the definitions for the 40,000defined nouns in Webster's Seventh showed that 10,000distinct nouns were used as heads of definitions and thatthey were used 85,000 times.
In other words, eachgenus term served as the hypernym for 8.5 other verbs,on average.
The accuracy of head-finding for nouns wasapproximately 98 percent, based on a random sampleof the output.3.
Sprout ingSprouting, which derives its name from the action ofgrowing a semantic tree from a specified root, uses theresults of head-finding as its raw material.
This infor-mation is organized into a "hyponym index", in whicheach word that was used as a genus term is associatedwith all of its hyponyms.
Thus, "vehicle" woula havean entry which reads (in part):vehicle: ambulance ... bicycle ... car ... tanker ...For a given part-of-speech, the hyponym index needs tobe built only once.When invoking the sprouting process, the user selects aroot from which a semantic tree is to be grown.
Thesystem then computes the transitive closure over thehyponym index, beginning at the chosen root.
In effect,for each new word (including the root), all of itshyponyms are added to the tree.
This operation is ap-plied recursively, until no further new words are found.The interactiveness of the sprouting process results fromthe fact that the user is consulted for each new word.If he decides that that word does not belong to the treebeing grown, he may prune it (and the branches thatwould emerge from it).
These pruning decisions resultin the disambiguation of the tree.
The user is assisted inmaking such decisions by having available an on-lineversion of Webster's Seventh, in which he may reviewthe definitions, usage notes, etc.
for any words of whichhe is unsure.The output of a sprouting session, then, is adisambiguated tree extracted from the tangled hierarchyrepresented by the hyponym index.
Actually, the outputmore nearly resembles a bush since it is usually shallow(typically only 3 to 4 levels deep) and very wide.
Forexample, a tree grown from vehicle had 75 direct de-scendants from the root, and contained over 250 nodesin its first two levels, alone.
The important aspect of theoutput, therefore, is not its structure, but rather the factthat the words it contains all have at least one sensewhich bears the property for which the root was ori-ginally selected.
It is important to note that any serioususe of sprouting to locate all words bearing a particularsemantic feature must involve the careful selection anduse of several roots, because of the variety of genusterms employed by the Webster's lexicographers.
Forexample, if it were desired to find all nouns which bearthe \[+female\] inherent feature, sprouts should at leastbe begun from female, woman, girl and even wife.4.
F i l te r ingFiltering, like sprouting, results in lists of words bearinga certain property (e.g., \[+human\]).
Unlike sprouting.however, filtering only picks up words all of whosesenses have the property.It is based on a "hypernym index" (the inversion of thehyponym index), in which each word is listed with itshypernyms, as in the example given here:vehicle: agent equipment means mediumThe filtering process begins with a "seed filter" consist-ing of an initial set of words all of whose senses bearsome required property.
The seed filter may be obtainedin any manner that is convenient.
\[n our work, this maybe either from the semantic codes assigned to words bythe Longman Dictionary of Contemporary English, orfrom morphological processing of word lists, as de-scribed in Byrd and McCord (1985).
For example.morphological analysis of words ending in -man,  -sman,-ee, -er, and -ist constitute a rich source of \[+human\]nouns.
Given the filter, the system uses it to evaluateall of the words in the hypernym index.
Any words, allof whose hypernyms are already in the filter, becomecandidates for inclusion in the filter during the next pass.The user is consulted for each candidate, and may accept302pass# FilterSize New Words1 2539* 10912 4113"* 2343 4347 434 4390 05 4661"** 49Total 4710* Obtained from Longman Dictionary of Contempory English** Includes 483 new words from morphological nalysis*** Includes 271 new words from morphological nalysisFigure 3.
A Filtering of \[+human\] ouns.or reject it.
Finally, all accepted words are added to thefilter, and the process is repeated until it converges.An example of the filtering procedure applied to nounsbearing the \[+human\] inherent feature is given in Figure3.
It can be seen that the process converges fairlyquickly, and that it is fairly productive, yielding, in thiscase, an almost wo-for-one return on the size of the in-itial filter.
For nouns with the \[-human\] inherent fea-ture, an initial filter of 22,000 words yielded I 1,600 newwords on the first pass, with a false alarm rate of lessthan 1% based on a random sample of the output.
Froman initial filter of 15 \[+time\] nouns, 300 additional oneswere obtained after three passes through the filter.These examples demonstrate another important factabout filtering: that it can be used to project he seman-tic information available from a smaller, more manage-able source such as a learner's dictionary onto the largerset of words obtained from a collegiate sized dictionary.?
As does sprouting, filtering also produces a list of wordshaving some desired property.
In this case, however, theresulting words have the property in all of their senses.This type of result is useful in a parsing system, such asthe one described in Heidorn, et al (1982), in which itmay be necessary to know whether a noun must refer toa human being, not merely that it may refer to one.5.
ConclusionThis work receives its primary motivation from the de-sire to build natural language processing systems capableof processing unrestricted English input.
As we emergefrom the days when hand-built lexicons of several hun-dred to a few thousand entries were sufficient, we needto explore ways of easing the lexicon construction task.Fortunately, the tools required to do the job are becom-ing available at the same time.
Primary among them aremachine readable dictionaries, such as Webster's andLongman, which contain the raw material for analysis.Software tools for dictionary analysis, such as those de-scribed here and in Calzolari (1982), are also graduallyemerging.
With experience, and enhanced understand-ing of the information structure in published diction-3O3aries, we expect to achieve some success in theautomated construction of lexicons for natural languageprocessing systems.ReferencesAmsler, R. A.
(1980), The Structure of the Merriam.Webster Pocket Dictionary, Doctoral Dissertation,TR-164, University of Texas, Austin.Byrd, R. J. and M. C. McCord (1985), "The lexical basefor semantic interpretation in a Prolog parser" presentedat the CUNY Workshop on the Lexicon, Parsing, andSemantic Interpretation, 18January 1985.Caizolari, N. (1984), "Detecting Patterns in a LexicalData Base," Proceedings of COI.JNG/ACL-1984Emonds, J.E.
(1976), A Transformational Approach toEnglish Syntax.
New York: Academic Press.Heidorn, G. E., K. Jensen, L. A. Miller, R. J. Byrd, andM.
S. Chodorow (1982), "The EPISTLE Text-Critiquing System," IBM Systems Journal, 21,305-326.Longman Dictionary of Contemporary English (1978),Longman Group Limited, London.Webster'$ Seventh New Collegiate Dictionary (1963), G.& C. Merriam, Springfield, Massachusetts.3O4
