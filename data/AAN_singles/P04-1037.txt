Unsupervised Sense Disambiguation Using Bilingual Probabilistic ModelsIndrajit BhattacharyaDept.
of Computer ScienceUniversity of MarylandCollege Park, MD,USAindrajit@cs.umd.eduLise GetoorDept.
of Computer ScienceUniversity of MarylandCollege Park, MD,USAgetoor@cs.umd.eduYoshua BengioDept.
IROUniversit?e de Montr?ealMontr?eal, Qu?ebec,Canadabengioy@IRO.UMontreal.CAAbstractWe describe two probabilistic models for unsuper-vised word-sense disambiguation using parallel cor-pora.
The first model, which we call the Sensemodel, builds on the work of Diab and Resnik(2002) that uses both parallel text and a sense in-ventory for the target language, and recasts their ap-proach in a probabilistic framework.
The secondmodel, which we call the Concept model, is a hier-archical model that uses a concept latent variable torelate different language specific sense labels.
Weshow that both models improve performance on theword sense disambiguation task over previous unsu-pervised approaches, with the Concept model show-ing the largest improvement.
Furthermore, in learn-ing the Concept model, as a by-product, we learn asense inventory for the parallel language.1 IntroductionWord sense disambiguation (WSD) has been a cen-tral question in the computational linguistics com-munity since its inception.
WSD is fundamental tonatural language understanding and is a useful in-termediate step for many other language process-ing tasks (Ide and Veronis, 1998).
Many recentapproaches make use of ideas from statistical ma-chine learning; the availability of shared sense defi-nitions (e.g.
WordNet (Fellbaum, 1998)) and recentinternational competitions (Kilgarrif and Rosen-zweig, 2000) have enabled researchers to comparetheir results.
Supervised approaches which makeuse of a small hand-labeled training set (Bruceand Wiebe, 1994; Yarowsky, 1993) typically out-perform unsupervised approaches (Agirre et al,2000; Litkowski, 2000; Lin, 2000; Resnik, 1997;Yarowsky, 1992; Yarowsky, 1995), but tend to betuned to a specific corpus and are constrained byscarcity of labeled data.In an effort to overcome the difficulty of find-ing sense-labeled training data, researchers have be-gun investigating unsupervised approaches to word-sense disambiguation.
For example, the use of par-allel corpora for sense tagging can help with wordsense disambiguation (Brown et al, 1991; Dagan,1991; Dagan and Itai, 1994; Ide, 2000; Resnik andYarowsky, 1999).
As an illustration of sense disam-biguation from translation data, when the Englishword bank is translated to Spanish as orilla, it isclear that we are referring to the shore sense of bank,rather than the nancial institution sense.The main inspiration for our work is Diab andResnik (2002), who use translations and linguisticknowledge for disambiguation and automatic sensetagging.
Bengio and Kermorvant (2003) presenta graphical model that is an attempt to formalizeprobabilistically the main ideas in Diab and Resnik(2002).
They assume the same semantic hierarchy(in particular, WordNet) for both the languages andassign English words as well as their translationsto WordNet synsets.
Here we present two variantsof the graphical model in Bengio and Kermorvant(2003), along with a method to discover a clusterstructure for the Spanish senses.
We also presentempirical word sense disambiguation results whichdemonstrate the gain brought by this probabilisticapproach, even while only using the translated wordto provide disambiguation information.Our first generative model, the Sense Model,groups semantically related words from the twolanguages into senses, and translations are gener-ated by probabilistically choosing a sense and thenwords from the sense.
We show that this improveson the results of Diab and Resnik (2002).Our next model, which we call the ConceptModel, aims to improve on the above sense struc-ture by modeling the senses of the two languagesseparately and relating senses from both languagesthrough a higher-level, semantically less preciseconcept.
The intuition here is that not all of thesenses that are possible for a word will be relevantfor a concept.
In other words, the distribution overthe senses of a word given a concept can be expectedto have a lower entropy than the distribution overthe senses of the word in the language as a whole.In this paper, we look at translation data as a re-source for identification of semantic concepts.
Notethat actual translated word pairs are not always goodmatches semantically, because the translation pro-cess is not on a word by word basis.
This intro-duces a kind of noise in the translation, and an addi-tional hidden variable to represent the shared mean-ing helps to take it into account.
Improved perfor-mance over the Sense Model validates the use ofconcepts in modeling translations.An interesting by-product of the Concept Modelis a semantic structure for the secondary language.This is automatically constructed using backgroundknowledge of the structure for the primary languageand the observed translation pairs.
In the model,words sharing the same sense are synonyms whilesenses under the same concept are semantically re-lated in the corpus.
An investigation of the modeltrained over real data reveals that it can indeedgroup related words together.It may be noted that predicting senses from trans-lations need not necessarily be an end result in it-self.
As we have already mentioned, lack of labeleddata is a severe hindrance for supervised approachesto word sense disambiguation.
At the same time,there is an abundance of bilingual documents andmany more can potentially be mined from the web.It should be possible using our approach to (noisily)assign sense tags to words in such documents, thusproviding huge resources of labeled data for super-vised approaches to make use of.For the rest of this paper, for simplicity we willrefer to the primary language of the parallel docu-ment as English and to the secondary as Spanish.The paper is organized as follows.
We begin by for-mally describing the models in Section 2.
We de-scribe our approach for constructing the senses andconcepts in Section 3.
Our algorithm for learningthe model parameters is described in Section 4.
Wepresent experimental results in Section 5 and ouranalysis in Section 6.
We conclude in Section 7.2 Probabilistic Models for ParallelCorporaWe motivate the use of a probabilistic model by il-lustrating that disambiguation using translations ispossible even when a word has a unique transla-tion.
For example, according to WordNet, the wordprevention has two senses in English, which maybe abbreviated as hindrance (the act of hinderingor obstruction) and control (by prevention, e.g.
thecontrol of a disease).
It has a single translation inour corpus, that being prevenci ?on.
The first En-glish sense, hindrance, also has other words likebar that occur in the corpus and all of these otherwords are observed to be translated in Spanish asthe word obstrucci?on.
In addition, none of theseother words translate to prevenci ?on.
So it is notunreasonable to suppose that the intended sense forprevention when translated as prevenci ?on is differ-ent from that of bar.
Therefore, the intended senseis most likely to be control.
At the very heart ofthe reasoning is probabilistic analysis and indepen-dence assumptions.
We are assuming that sensesand words have certain occurrence probabilities andthat the choice of the word can be made indepen-dently once the sense has been decided.
This is theflavor that we look to add to modeling parallel doc-uments for sense disambiguation.
We formally de-scribe the two generative models that use these ideasin Subsections 2.2 and 2.3.TWe WsTe TsCWsWewordconceptsenseb) Concept Modela) Sense ModelFigure 1: Graphical Representations of the a) SenseModel and the b) Concept Model2.1 NotationThroughout, we use uppercase letters to denote ran-dom variables and lowercase letters to denote spe-cific instances of the random variables.
A transla-tion pair is (   ,   ) where the subscript  and indicate the primary language (English) and the sec-ondary language (Spanish).
  	and     .
We use the shorthandffflfiffi for ffflfi  !#"$ffi .2.2 The Sense ModelThe Sense Model makes the assumption, inspiredby ideas in Diab and Resnik (2002) and Ben-gio and Kermorvant (2003), that the English word ! and the Spanish word  % in a translation pairshare the same precise sense.
In other words, theset of sense labels for the words in the two lan-guages is the same and may be collapsed into oneset of senses that is responsible for both Englishand Spanish words and the single latent variablein the model is the sense label & '()*(+,for both words   and  - .
We also make the as-sumption that the words in both languages are con-ditionally independent given the sense label.
Thegenerative parameters .0/ for the model are the priorprobability ffflfi ( ffi of each sense ( and the conditionalprobabilities ffflfi21 ( ffi and ff3fi*1 ( ffi of each wordand in the two languages given the sense.
Thegeneration of a translation pair by this model maybe viewed as a two-step process that first selectsa sense according to the priors on the senses andthen selects a word from each language using theconditional probabilities for that sense.
This maybe imagined as a factoring of the joint distribution:ffflfi      &ffi4"5ffflfi&ffiffflfi    1&ffiffflfi    1&ffi .
Notethat in the absence of labeled training data, twoof the random variables  - and   are observed,while the sense variable & is not.
However, we canderive the possible values for our sense labels fromWordNet, which gives us the possible senses foreach English word  - .
The Sense model is shownin Figure 1(a).2.3 The Concept ModelThe assumption of a one-to-one association be-tween sense labels made in the Sense Model may betoo simplistic to hold for arbitrary languages.
In par-ticular, it does not take into account that translationis from sentence to sentence (with a shared mean-ing), while the data we are modeling are alignedsingle-word translations fi  %   -6ffi , in which the in-tended meaning of  - does not always match per-fectly with the intended meaning of  7 .
Generally,a set of 8 related senses in one language may betranslated by one of 9 related senses in the other.This many-to-many mapping is captured in our al-ternative model using a second level hidden vari-able called a concept.
Thus we have three hid-den variables in the Concept Model ?
the Englishsense &  , the Spanish sense &  and the concept : ,where & ;" ( <*( >=  , & ?"
( <*( A@  and:"B)*<BCD .We make the assumption that the senses &  and& are independent of each other given the sharedconcept : .
The generative parameters ./in themodel are the prior probabilities ffflfi B ffi over theconcepts, the conditional probabilities ffflfi ( E1 B ffi andffflfi(*1Bffi for the English and Spanish senses given theconcept, and the conditional probabilities ffflfiF1 ( $ffiand ffflfi21 ( $ffi for the words and in eachlanguage given their senses.
We can now imag-ine the generative process of a translation pair bythe Concept Model as first selecting a concept ac-cording to the priors, then a sense for each lan-guage given the concept, and finally a word foreach sense using the conditional probabilities of thewords.
As in Bengio and Kermorvant (2003), thisgenerative procedure may be captured by factor-ing the joint distribution using the conditional inde-pendence assumptions as ff3fi  -   -  &   &   : ffi"ffflfi:ffiffflfi&F1:ffiff3fi  !21&$ffiffflfi&E1:ffiffflfi  21&$ffi .
TheConcept model is shown in Figure 1(b).3 Constructing the Senses and ConceptsBuilding the structure of the model is crucial forour task.
Choosing the dimensionality of the hiddenvariables by selecting the number of senses and con-cepts, as well as taking advantage of prior knowl-edge to impose constraints, are very important as-pects of building the structure.If certain words are not possible for a given sense,or certain senses are not possible for a given con-cept, their corresponding parameters should be 0.For instance, for all words that do not belong to asense (  , the corresponding parameter .EGIH$J KLH wouldbe permanently set to 0.
Only the remaining param-eters need to be modeled explicitly.While model selection is an extremely difficultproblem in general, an important and interesting op-tion is the use of world knowledge.
Semantic hi-erarchies for some languages have been built.
Weshould be able to make use of these known tax-onomies in constructing our model.
We make heavyuse of the WordNet ontology to assign structure toboth our models, as we discuss in the following sub-sections.
There are two major tasks in building thestructure ?
determining the possible sense labelsfor each word, both English and Spanish, and con-structing the concepts, which involves choosing thenumber of concepts and the probable senses for eachconcept.3.1 Building the Sense ModelEach word in WordNet can belong to multiplesynsets in the hierarchy, which are its possiblesenses.
In both of our models, we directly use theWordNet senses as the English sense labels.
AllWordNet senses for which a word has been ob-served in the corpus form our set of English senselabels.
The Sense Model holds that the sense labelsfor the two domains are the same.
So we must usethe same WordNet labels for the Spanish words aswell.
We include a Spanish word for a sense ( if is the translation of any English word in ( .3.2 Building the Concept ModelUnlike the Sense Model, the Concept Model doesnot constrain the Spanish senses to be the same asthe English ones.
So the two major tasks in build-ing the Concept Model are constructing the Spanishsenses and then clustering the English and Spanishsenses to build the concepts.Concept Modelte2 ts1te1barpreventionc6118ts2c20prevencio?n obstruccio?nSense Modelbar preventionte1 te2prevencio?nobstruccio?nFigure 2: The Sense and Concept models for prevention, bar, prevenci ?on and obstrucci?onFor each Spanish wordM , we have its set of En-glish translations N=O .
One possibility isto group Spanish words looking at their translations.However, a more robust approach is to consider therelevant English senses for .
Each English trans-lation for has its set of English sense labels P GIHDQdrawn from WordNet.
So the relevant English senselabels for may be defined as P GSR "UTNV P GIH Q .We call this the English sense map or 2WXY for .
We use the 2WXY s to define the Spanish senses.We may imagine each Spanish word to come fromone or more Spanish senses.
If each word has asingle sense, then we add a Spanish sense (  foreach *WZXY and all Spanish words that share that2WXY belong to that sense.
Otherwise, the *WZXY shave to be split into frequently occurring subgroups.Frequently co-occurring subsets of 2WXY s can de-fine more refined Spanish senses.
We identify thesesubsets by looking at pairs of 2WZXY s and comput-ing their intersections.
An intersection is consid-ered to be a Spanish sense if it occurs for a signifi-cant number of pairs of 2WXY s. We consider bothways of building Spanish senses.
In either case, aconstructed Spanish sense (  comes with its rele-vant set (  Q  of English senses, which we denoteas 2WZXY fi ( ffi .Once we have the Spanish senses, we clusterthem to form concepts.
We use the *WZXY corre-sponding to each Spanish sense to define a measureof similarity for a pair of Spanish senses.
Thereare many options to choose from here.
We use asimple measure that counts the number of commonitems in the two *WZXY s.1 The similarity measure isnow used to cluster the Spanish senses (  .
Sincethis measure is not transitive, it does not directlydefine equivalence classes over (6 .
Instead, we geta similarity graph where the vertices are the Span-ish senses and we add an edge between two sensesif their similarity is above a threshold.
We nowpick each connected component from this graph asa cluster of similar Spanish senses.1Another option would be to use a measure of similarity forEnglish senses, proposed in Resnik (1995) for two synsets ina concept hierarchy like WordNet.
Our initial results with thismeasure were not favorable.Now we build the concepts from the Spanishsense clusters.
We recall that a concept is defined bya set of English senses and a set of Spanish sensesthat are related.
Each cluster represents a concept.A particular concept is formed by the set of Spanishsenses in the cluster and the English senses relevantfor them.
The relevant English senses for any Span-ish sense is given by its 2WZXY .
Therefore, the unionof the *WZXY s of all the Spanish senses in the clusterforms the set of English senses for each concept.4 Learning the Model ParametersOnce the model is built, we use the popular EM al-gorithm (Dempster et al, 1977) for hidden vari-ables to learn the parameters for both models.
Thealgorithm repeatedly iterates over two steps.
Thefirst step maximizes the expected log-likelihood ofthe joint probability of the observed data with thecurrent parameter settings .
/ .
The next step then re-estimates the values of the parameters of the model.Below we summarize the re-estimation steps foreach model.4.1 EM for the Sense Modelff3fi&V"(ffi[" \]^_VL`)ffflfi&"(1QQ./ffiffflfi  Q"1&V"(ffia"b^GIHDQ`cVL`)ff3fi&"(1QdQ.F/ffibb^eHQ`<cVL`)ffflfi&"(1QQ./ffiffflfi  Q"1&V"(ffi follows similarly.4.2 EM for the Concept Modelffflfi:V"gfhffia"\]^_Vi`)ffflfi:V"gfj1QQ./ffiffflfi&Q"lk<1:V"gfhffia"b^VL`)ffflfi:V"mf&Q"lk<1QdQ.F/ffib^VL`)ffflfi:V"gfj1QQ./ffiffflfi  !Q"1&Q"lk ffi["b^eHDQ`<cVL`)ffflfi&Q"lk<1Q"Q.
/ffibb^eHDQ`<cVL`)ffflfi&Q"gk1n Q"Q./ffiffflfi&Q"81:V"ofhffi and ffflfi    Q "  1 &  Q " 8 ffifollow similarly.4.3 Initialization of Model ProbabilitiesSince the EM algorithm performs gradient ascentas it iteratively improves the log-likelihood, it isprone to getting caught in local maxima, and se-lection of the initial conditions is crucial for thelearning procedure.
Instead of opting for a uni-form or random initialization of the probabilities,we make use of prior knowledge about the Englishwords and senses available from WordNet.
Word-Net provides occurrence frequencies for each synsetin the SemCor Corpus that may be normalized toderive probabilities ff Gqp fi ( $ffi for each English sense(> .
For the Sense Model, these probabilities formthe initial priors over the senses, while all English(and Spanish) words belonging to a sense are ini-tially assumed to be equally likely.
However, ini-tialization of the Concept Model using the sameknowledge is trickier.
We would like each En-glish sense (  to have ff V p V K fi ( ffi"rff Gqp fi ( $ffi .
Butthe fact that each sense belongs to multiple con-cepts and the constraint bKH6sEtffflfi(E1Bffiu"\ makesthe solution non-trivial.
Instead, we settle for acompromise.
We set ff V p V K fi ( E1 B ffiv"wff Gqp fi ( $ffi andffflfiBffix"bKLHs2tffGqpfi($ffi .
Subsequent normalizationtakes care of the sum constraints.
For a Spanishsense, we set ffflfi (< ffia" bKLHsy{z}|E~KLRffGqpfi(>ffi .
Oncewe have the Spanish sense probabilities, we followthe same procedure for setting ffflfi ( 21 B ffi for each con-cept.
All the Spanish and English words for a senseare set to be equally likely, as in the Sense Model.It turned out in our experiments on real data thatthis initialization makes a significant difference inmodel performance.5 Experimental EvaluationBoth the models are generative probabilistic modelslearned from parallel corpora and are expected tofit the training and subsequent test data.
A good fitshould be reflected in good prediction accuracy overa test set.
The prediction task of interest is the senseof an English word when its translation is provided.We estimate the prediction accuracy and recall ofour models on Senseval data.2 In addition, the Con-cept Model learns a sense structure for the Spanish2Accuracy is the ratio of the number of correct predictionsand the number of attempted predictions.
Recall is the ratio ofthe number of correct predictions and the size of the test set.language.
While it is hard to objectively evaluatethe quality of such a structure, we present some in-teresting concepts that are learned as an indicationof the potential of our approach.5.1 Evaluation with Senseval DataIn our experiments with real data, we make use ofthe parallel corpora constructed by Diab and Resnik(2002) for evaluation purposes.
We chose to workon these corpora in order to permit a direct compar-ison with their results.
The sense-tagged portion ofthe English corpus is comprised of the English ?all-words?
section of the SENSEVAL-2 test data.
Theremainder of this corpus is constructed by addingthe Brown Corpus, the SENSEVAL-1 corpus, theSENSEVAL-2 English Lexical Sample test, trialand training corpora and the Wall Street Journal sec-tions 18-24 from the Penn Treebank.
This Englishcorpus is translated into Spanish using two com-mercially available MT systems: Globalink Pro 6.4and Systran Professional Premium.
The GIZA++implementation of the IBM statistical MT modelswas used to derive the most-likely word-level align-ments, and these define the English/Spanish wordco-occurrences.
To take into account variability oftranslation, we combine the translations from thetwo systems for each English word, following in thefootsteps of Diab and Resnik (2002).
For our ex-periments, we focus only on nouns, of which thereare 875 occurrences in our tagged data.
The sensetags for the English domain are derived from theWordNet 1.7 inventory.
After pruning stopwords,we end up with 16,186 English words, 31,862 Span-ish words and 2,385,574 instances of 41,850 distincttranslation pairs.
The English words come from20,361 WordNet senses.Table 1: Comparison with Diab?s ModelModel Accuracy Recall ParametersDiab 0.618 0.572 -Sense M. 0.624 0.616 154,947Concept M. 0.672 0.651 120,268As can be seen from the following table, both ourmodels clearly outperform Diab (2003), which isan improvement over Diab and Resnik (2002), inboth accuracy and recall, while the Concept Modeldoes significantly better than the Sense Model withfewer parameters.
The comparison is restricted tothe same subset of the test data.
For our best re-sults, the Sense Model has 20,361 senses, while theConcept Model has 20,361 English senses, 11,961Spanish senses and 7,366 concepts.
The ConceptModel results are for the version that allows mul-tiple senses for a Spanish word.
Results for the00.10.20.30.40.50.60.70.80.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9RecallAccuracyunsup.sup.diabconcept modelsense modelFigure 3: Comparison with Senseval2 Systemssingle-sense model are similar.In Figure 3, we compare the prediction accuracyand recall against those of the 21 Senseval-2 EnglishAll Words participants and that of Diab (2003),when restricted to the same set of noun instancesfrom the gold standard.
It can be seen that our mod-els outperform all the unsupervised approaches inrecall and many supervised ones as well.
No un-supervised approach is better in both accuracy andrecall.
It needs to be kept in mind that we take intoaccount only bilingual data for our predictions, andnot monolingual features like context of the word asmost other WSD approaches do.5.2 Semantic Grouping of Spanish SensesTable 2 shows some interesting examples of differ-ent Spanish senses for discovered concepts.3 Thecontext of most concepts, like the ones shown, canbe easily understood.
For example, the first conceptis about government actions and the second dealswith murder and accidental deaths.
The penulti-mate concept is interesting because it deals with dif-ferent kinds of association and involves three dif-ferent senses containing the word conexi ?on.
Theother words in two of these senses suggest thatthey are about union and relation respectively.
Thethird probably involves the link sense of connection.Conciseness of the concepts depends on the simi-larity threshold that is selected.
Some may bringtogether loosely-related topics, which can be sepa-rated by a higher threshold.6 Model AnalysisIn this section, we back up our experimental resultswith an in-depth analysis of the performance of ourtwo models.Our Sense Model was motivated by Diab andResnik (2002) but the flavors of the two are quite3Some English words are found to occur in the SpanishSenses.
This is because the machine translation system usedto create the Spanish document left certain words untranslated.different.
The most important distinction is that theSense Model is a probabilistic generative model forparallel corpora, where interaction between differ-ent words stemming from the same sense comesinto play, even if the words are not related throughtranslations, and this interdependence of the sensesthrough common words plays a role in sense disam-biguation.We started off with our discussions on semanticambiguity with the intuition that identification ofsemantic concepts in the corpus that relate multi-ple senses should help disambiguate senses.
TheSense Model falls short of this target since it onlybrings together a single sense from each language.We will now revisit the motivating example fromSection 2 and see how concepts help in disambigua-tion by grouping multiple related senses together.For the Sense Model, ffflfi??S?<?
?F?
?I?D???E?
?1 ( >?
ffi??ffflfi??S?<?
?F?
?I?D???E?
?1 ( <ffi since it is the only word that( ?
can generate.
However, this difference is com-pensated for by the higher prior probability ffflfi ( ffi ,which is strengthened by both the translation pairs.Since the probability of joint occurrence is given bythe product ff3fi ( ffiffflfiF1 ( ffiffflfi21 ( ffi for any sense ( ,the model does not develop a clear preference forany of the two senses.The critical difference in the Concept Model canbe appreciated directly from the corresponding jointprobability ffflfi B ffiffflfi ( F1 B ffiffflfiO1 ( ffiffflfi ( 21 B ffiffflfi21 ( 6ffi ,where B is the relevant concept in the model.The preference for a particular instantiation in themodel is dependent not on the prior ffflfi ( ffi overa sense, but on the sense conditional ff3fi ( 21 B ffi .
Inour example, since ?
bar, obstrucci ?on ?
can begenerated only through concept B?E?
, ffflfi ( *1 B?E?
ffi isthe only English sense conditional boosted by it.?
prevention, prevenci?on?
is generated through adifferent concept B?
\F\?
, where the higher condi-tional ffflfi??q???E?
?S?D?D?E?
?1 ( ?
ffi gradually strengthens oneof the possible instantiations for it, and the otherone becomes increasingly unlikely as the iterationsprogress.
The inference is that only one sense ofprevention is possible in the context of the parallelcorpus.
The key factor in this disambiguation wasthat two senses of prevention separated out in twodifferent concepts.The other significant difference between the mod-els is in the constraints on the parameters and theeffect that they have on sense disambiguation.
Inthe Sense Model, bKffflfi(ffiu"\ , while in the Con-cept Model, bKH6sEtffflfi(E1Bffi?
"\ separately for eachconceptB.
Now for two relevant senses for an En-glish word, a slight difference in their priors willtend to get ironed out when normalized over the en-Table 2: Example Spanish Senses in a Concept.
For each concept, each row is a separate sense.
Dictionarysenses of Spanish words are provided in English within parenthesis where necessary.actos accidente accidentessupremas muertes(deaths)decisio?n decisiones casualtygobernando gobernante matar(to kill) matanzas(slaughter) muertes-legubernamentales slayinggobernacio?n gobierno-proporciona derramamiento-de-sangre (spilling-of-blood)prohibir prohibiendo prohibitivo prohibitiva cachiporra(bludgeon) obligar(force) obligando(forcing)gubernamental gobiernos asesinato(murder) asesinatoslinterna-ele?ctrica linterna(lantern) mani?a crazefaros-automo?vil(headlight) culto(cult) cultos proto-senilitylinternas-portuarias(harbor-light) delirio deliriumantorcha(torch) antorchas antorchas-pino-nudo rabias(fury) rabia farfulla(do hastily)oportunidad oportunidades diferenciacio?nocasio?n ocasiones distincio?n distincionesriesgo(risk) riesgos peligro(danger) especializacio?ndestino sino(fate) maestri?a (mastery)fortuna suerte(fate) peculiaridades particularidades peculiaridades-inglesasprobabilidad probabilidades especialidad especialidadesdiablo(devil) diablos modelo parango?ndickens ideal idealesheller santo(saint) santos sanlucifer satan satana?s idol idols i?dolodeslumbra(dazzle) dios god diosescromo(chromium) divinidad divinitymeteoro meteoros meteor meteoros-blue inmortal(immortal) inmortalesmeteorito meteoritos teologi?a teologpedregosos(rocky) deidad deity deidadesvariacio?n variaciones minutos minutodiscordancia desacuerdo(discord) discordancias momento momentos un-momentodesviacio?n(deviation) desviaciones desviaciones-normales minutos momentos momento segundosdiscrepancia discrepancias fugaces(fleeting) variacio?n diferencia instante momentodisensio?n pestan?eo(blink) guin?a(wink) pestan?eanadhesio?n adherencia ataduras(tying) pasillo(corridor)enlace(connection) ataduras aisleatadura ataduras pasarela(footbridge)conexio?n conexiones hall vesti?bulosconexio?n une(to unite) pasaje(passage)relacio?n conexio?n callejo?n(alley) callejas-ciegas (blind alley) callejones-ocultosimplicacio?n (complicity) envolvimientotire set of senses for the corpus.
In contrast, if thesetwo senses belong to the same concept in the Con-cept Model, the difference in the sense conditionalswill be highlighted since the normalization occursover a very small set of senses ?
the senses foronly that concept, which in the best possible sce-nario will contain only the two contending senses,as in concept B \F\?
of our example.As can be seen from Table 1, the Concept Modelnot only outperforms the Sense Model, it does sowith significantly fewer parameters.
This may becounter-intuitive since Concept Model involves anextra concept variable.
However, the dissociation ofSpanish and English senses can significantly reducethe parameter space.
Imagine two Spanish wordsthat are associated with ten English senses and ac-cordingly each of them has a probability for belong-ing to each of these ten senses.
Aided with a con-cept variable, it is possible to model the same re-lationship by creating a separate Spanish sense thatcontains these two words and relating this Spanishsense with the ten English senses through a conceptvariable.
Thus these words now need to belong toonly one sense as opposed to ten.
Of course, nowthere are new transition probabilities for each of theeleven senses from the new concept node.
The exactreduction in the parameter space will depend on thefrequent subsets discovered for the 2WXY s of theSpanish words.
Longer and more frequent subsetswill lead to larger reductions.
It must also be bornein mind that this reduction comes with the indepen-dence assumptions made in the Concept Model.7 Conclusions and Future WorkWe have presented two novel probabilistic modelsfor unsupervised word sense disambiguation usingparallel corpora and have shown that both modelsoutperform existing unsupervised approaches.
Inaddition, we have shown that our second model,the Concept model, can be used to learn a senseinventory for the secondary language.
An advan-tage of the probabilistic models is that they can eas-ily incorporate additional information, such as con-text information.
In future work, we plan to investi-gate the use of additional monolingual context.
Wewould also like to perform additional validation ofthe learned secondary language sense inventory.8 AcknowledgmentsThe authors would like to thank Mona Diab andPhilip Resnik for many helpful discussions and in-sightful comments for improving the paper and alsofor making their data available for our experiments.This study was supported by NSF Grant 0308030.ReferencesE.
Agirre, J. Atserias, L. Padr, and G. Rigau.
2000.Combining supervised and unsupervised lexicalknowledge methods for word sense disambigua-tion.
In Computers and the Humanities, SpecialDouble Issue on SensEval.
Eds.
Martha Palmerand Adam Kilgarriff.
34:1,2.Yoshua Bengio and Christopher Kermorvant.
2003.Extracting hidden sense probabilities from bi-texts.
Technical report, TR 1231, Departementd?informatique et recherche operationnelle, Uni-versite de Montreal.Peter F. Brown, Stephen Della Pietra, Vin-cent J. Della Pietra, and Robert L. Mercer.1991.
Word-sense disambiguation using statisti-cal methods.
In Meeting of the Association forComputational Linguistics, pages 264?270.Rebecca Bruce and Janyce Wiebe.
1994.
A newapproach to sense identification.
In ARPA Work-shop on Human Language Technology.Ido Dagan and Alon Itai.
1994.
Word sense disam-biguation using a second language monolingualcorpus.
Computational Linguistics, 20(4):563?596.Ido Dagan.
1991.
Lexical disambiguation: Sourcesof information and their statistical realization.
InMeeting of the Association for ComputationalLinguistics, pages 341?342.A.P.
Dempster, N.M. Laird, and D.B.
Rubin.
1977.Maximum likelihood from incomplete data viathe EM algorithm.
Journal of the Royal Statis-tical Society, B 39:1?38.Mona Diab and Philip Resnik.
2002.
An unsuper-vised method for word sense tagging using paral-lel corpora.
In Proceedings of the 40th Anniver-sary Meeting of the Association for Computa-tional Linguistics (ACL-02).Mona Diab.
2003.
Word Sense DisambiguationWithin a Multilingual Framework.
Ph.D. thesis,University of Maryland, College Park.Christiane Fellbaum.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Nancy Ide and Jean Veronis.
1998.
Word sense dis-ambiguation: The state of the art.
ComputationalLinguistics, 28(1):1?40.Nancy Ide.
2000.
Cross-lingual sense determina-tion: Can it work?
In Computers and the Hu-manities: Special Issue on Senseval, 34:147-152.Adam Kilgarrif and Joseph Rosenzweig.
2000.Framework and results for english senseval.Computers and the Humanities, 34(1):15?48.Dekang Lin.
2000.
Word sense disambiguationwith a similarity based smoothed library.
InComputers and the Humanities: Special Issue onSenseval, 34:147-152.K.
C. Litkowski.
2000.
Senseval: The cl researchexperience.
In Computers and the Humanities,34(1-2), pp.
153-8.Philip Resnik and David Yarowsky.
1999.
Distin-guishing systems and distinguishing senses: newevaluation methods for word sense disambigua-tion.
Natural Language Engineering, 5(2).Philip Resnik.
1995.
Using information content toevaluate semantic similarity in a taxonomy.
InProceedings of the International Joint Confer-ence on Articial Intelligence, pages 448?453.Philip Resnik.
1997.
Selectional preference andsense disambiguation.
In Proceedings of ACLSiglex Workshop on Tagging Text with LexicalSemantics, Why, What and How?, Washington,April 4-5.David Yarowsky.
1992.
Word-sense disambigua-tion using statistical models of Roget?s cate-gories trained on large corpora.
In Proceedingsof COLING-92, pages 454?460, Nantes, France,July.David Yarowsky.
1993.
One sense per collocation.In Proceedings, ARPA Human Language Tech-nology Workshop, Princeton.David Yarowsky.
1995.
Unsupervised word sensedisambiguation rivaling supervised methods.
InMeeting of the Association for ComputationalLinguistics, pages 189?196.
