AN EMPIRICAL STUDY ON THEMATIC KNOWLEDGE ACQUISITIONBASED ON SYNTACTIC CLUES AND HEURISTICSRey-Long L iu*  and  Von-Wun Soo**Department of Computer ScienceNational Tsing-Hua UniversityHsinChu, Taiwan, R.O.C.Email: dr798303@cs.nthu.edu.tw* and soo@cs.nthu.edu.tw**AbstractThematic knowledge is a basis of semamic interpreta-tion.
In this paper, we propose an acquisition methodto acquire thematic knowledge by exploiting syntacticclues from training sentences.
The syntactic lues,which may be easily collected by most existing syn-tactic processors, reduce the hypothesis space of thethematic roles.
The ambiguities may be furtherresolved by the evidences either from a trainer orfrom a large corpus.
A set of heurist-cs based onlinguistic constraints i employed to guide the ambi-guity resolution process.
When a train,-.r is available,the system generates new sentences wtose thematicvalidities can be justified by the trainer.
When a largecorpus is available, the thematic validity may be justi-fied by observing the sentences in the corpus.
Usingthis way, a syntactic processor may become athematic recognizer by simply derivir.g its thematicknowledge from its own syntactic knowledge.Keywords: Thematic Knowledge Acquisition, Syntac-tic Clues, Heuristics-guided Ambigu-ty Resolution,Corpus-based Acquisition, Interactive Acquisition1.
INTRODUCTIONNatural language processing (NLP) systems needvarious knowledge including syntactic, semantic,discourse, and pragmatic knowledge in differentapplications.
Perhaps due to the relatively well-established syntactic theories and forrc.alisms, therewere many syntactic processing systew, s either manu-ally constructed or automatically extenJ~d by variousacquisition methods (Asker92, Berwick85, Brentgl,Liu92b, Lytinen90, Samuelsson91, Simmons91 Sanfi-lippo92, Smadja91 and Sekine92).
However, the satis-factory representation and acquisition methods ofdomain-independent semantic, disco~lrse, and prag-matic knowledge are not yet develo~d or computa-tionally implemented.
NLP systems 6f'.en suffer thedilemma of semantic representation.
Sophisticatedrepresentation of semantics has better expressivepower but imposes difficulties on acquF;ition in prac-tice.
On the other hand, the poor adequacy of naivesemantic representation may deteriorate the perfor-mance of NLP systems.
Therefore, for plausibleacquisition and processing, domain-dependent seman-tic bias was 9ften employed in many previous acquisi-tion systez, s (Grishman92b, Lang88, Lu89, andVelardi91).In thi~ paper, we present an implemented sys-tem that acquires domain-independent thematicknowledge using available syntactic resources (e.g.syntactic p~acessing systems and syntactically pro-cessed cort;ara).
Thematic knowledge can representsemantic or conceptual entities.
For correct and effi-cient parsing, thematic expectation serves as a basisfor conflict resolution (Taraban88).
For naturallanguage understanding and other applications (e.g.machine translation), thematic role recognition is amajor step.
~ematic relations may serve as the voca-bulary shared by the parser, the discourse model, andthe world knowledge (Tanenhaus89).
More impor-tantly, since thematic structures are perhaps mostclosely link~d to syntactic structures ($ackendoff72),thematic knowledge acquisition may be more feasiblewhen only .
:'yntactic resources are available.
The con-sideration of the availability of the resources fromwhich thematic knowledge may be derived promotesthe practica2 feasibility of the acquisition method.In geaeral, lexical knowledge of a lexical headshould (at ~east) include 1) the number of argumentsof the lexic~-~l head, 2) syntactic properties of the argu-ments, and 3) thematic roles of the arguments (theargument ,:~ructure).
The former two componentsmay be eitt~er already constructed in available syntac-tic processors or acquired by many syntactic acquisi-tion system s .
However, the acquisition of the thematicroles of th~ arguments deserves more exploration.
Aconstituent~ay have different hematic roles for dif-ferent verbs in different uses.
For example, "John" hasdifferent th,~matic roles in (1.1) - (1.4).
(1.1) \[Agenz John\] turned on the light.
(1.2) \[Goal rohn\] inherited amillion dollars.
(1.3) The magic wand turned \[Theme John\] into afrog.243Table 1.
Syntactic lues for hypothesizing thematic rolesTheta roleAgent(Ag)Goal(Go)Source(So)Instrument(In)Theme(Th)Beneficiary(Be)Location(Lo)Time(Ti)Quantity(Qu)Proposition(Po)Manner(Ma)Cause(Ca)Result(Re)ConstituentNPNPNPNPNPNPNP,ADJPNP(Ti)NP(Qu)PropositionADVP,PPNPNPAnimate SubjectYy(animate)y(animate)y(no Ag)YnYYObjectnnnYPreposition in PPbytill,untill,to,into,downfromwith,byof, aboutforat,in,on,underat,in,before,after,about,by,on,duringfornonein,withby,for,because ofin ,into(1.4) The letter eached \[Goal John\] yesterday.To acquire thematic lexical knowledge, precisethematic roles of arguments in the sentences needs tobe determined.In the next section, the thematic roles con-sidered in this paper are listed.
The syntactic proper-ties of the thematic roles are also summarized.
Thesyntactic properties erve as a preliminary filter toreduce the hypothesis space of possible thematic rolesof arguments in training sentences.
To further esolvethe ambiguities, heuristics based on various linguisticphenomena and constraints are introduced in section3.
The heuristics erve as a general guidance for thesystem to collect valuable information to discriminatethematic roles.
Current status of the experiment isreported in section 4.
In section 5, the method isevaluated and related to previous methodologies.
Weconclude, in section 6, that by properly collectingdiscrimination information from available sources,thematic knowledge acquisition may be, more feasiblein practice.2.
THEMATIC  ROLES AND SYNTAC-T IC  CLUESThe thematic roles considered in this paper and thesyntactic lues for identifying them are presented inTable 1.
The syntactic lues include i) the possiblesyntactic onstituents of the arguments, 2) whetheranimate or inanimate arguments, 3) grammaticalfunctions (subject or object) of the a;guments whenthey are Noun Phrases (NPs), and 4) p:epositions ofthe prepositional phrase in which the aaguments mayoccur, The syntactic onstituents inc!t:de NP, Propo-sition (Po), Adverbial Phrase (ADVP), AdjectivePhrase (ADJP), and Prepositional phrase (PP).
Inaddition to common animate nouns (e.g.
he, she, andI), proper nguns are treated as animate NPs as well.In Table 1, "y", "n", "?
", and "-" denote "yes", "no","don't care", and "seldom" respectively.
For example,an Agent should be an animate NP which may be atthe subject (but not object) position, and if it is in aPP, the preposition of the PP should be "by" (e.g.
"John" in "the light is turned on by John").We consider the thematic roles to be well-known and referred, although slight differences mightbe found in various works.
The intrinsic properties ofthe thematic roles had been discussed from variousperspectivez in previous literatures (Jackendoff72 andGruber76).
Grimshaw88 and Levin86 discussed theproblems o_ ~ thematic role marking in so-called lightverbs and aJjectival passives.
More detailed escrip-tion of the thematic roles may be found in the litera-tures.
To illustrate the thematic roles, consider (2.1)-(2.9).
(2.1) lag The robber\] robbed \[So the bank\] of \[Th themoney\].
(2.2) \[Th The rock\] rolled down \[Go the hill\].
(2.3) \[In Tt,e key\] can open \[Th the door\].
(2.4) \[Go Will\] inherited \[Qua million dollars\].
(2.5) \[Th ~!e letter\] finally reached \[Go John\].
(2.6) \[Lo "121e restaurant\] can dine \[Th fifty people\].
(2.7) \[Ca A fire\] burned own \[Th the house\].
(2.8) lAg John\] bought \[Be Mary\] \[Th a coat\] \[Mareluctantly\].
(2.9) lag John\] promised \[Go Mary\] \[Po to marryher\].
-When a tr, lining sentence is entered, arguments oflexical verbs in the sentence need to be extractedbefore leart ing.
This can be achieved by invoking asyntactic processor.244Table 2.
Heuristics for discriminating ther atic roles?
Volition Heuristic (VH): Purposive constructions (e.g.
in order to) an0 purposive adverbials (e.g.
deliberately andintentionally) may occur in sentences with Agent arguments (Gruber76).?
Imperative Heuristic OH): Imperatives are permissible only for Agent subjects (Gruber76).?
Thematic Hierarchy Heuristic (THH): Given a thematic hierarchy (from higher to lower) "Agent > Location,Source, Goal > Theme", the passive by-phrases must reside at a higher level than the derived subjects in the hierar-chy (i.e.
the Thematic Hierarchy Condition in Jackendoff72).
In this papzr, we set up the hierarchy: Agent > Loca-tion, Source, Goal, Instrument, Cause > Theme, Beneficiary, Time, Quantity, Proposition, Manner, Result.
Subjectsand objects cannot reside at the same level.?
Preposition Heuristic (PH): The prepositions of the PPs in which the arguments occur often convey gooddiscrimination i formation for resolving thematic roles ambiguities ( ee the "Preposition in PP" column in Table 1).?
One-Theme Heuristic (OTH): An ~xgument is preferred to be Theme if itis the only possible Theme in the argu-ment structure.?
Uniqueness Heuristic (UH): No twc, arguments may receive the sanle thematic role (exclusive of conjunctionsand anaphora which co-relate two constituents a signed with the same thematic role).If the sentence is selected from a syntactically pro-cessed corpus (such as the PENN treebank) the argu-ments may be directly extracted from the corpus.
Toidentify the thematic roles of the arguments, Table 1is consulted.For example, consider (2.1) as the training sen-tence.
Since "the robber" is an animate NP with thesubject grammatical function, it can only qualify forAg, Go, So, and Th.
Similarly, since "the bank" is aninanimate NP with the object grammatical function, itcan only satisfy the requirements of Go, So, Th, andRe.
Because of the preposition "of", "th~ money" canonly be Th.
As a result, after con,;ulting the con-straints in Table 1, "the robber", "the bank", and "themoney" can only be {Ag, Go, So, Tb}, {Go, So, Th,Re}, and {Th} respectively.
Therefore, although theclues in Table 1 may serve as a filter, lots of thematicrole ambiguities till call for other discriminationinformation and resolution mechanisms.3.
F INDING EXTRA INFORMATIONFOR RESOLVING THETA ROLEAMBIGUIT IESThe remaining thematic role ambiguities hould beresolved by the evidences from other sources.Trainers and corpora are the two most commonlyavailable sources of the extra information.
Interactiveacquisition had been applied in various systems inwhich the oracle from the trainer may reduce mostambiguities (e.g.
Lang88, Liu93, Lu89, andVelardi91).
Corpus-based acquisition systems mayalso converge to a satisfactory performance by col-lecting evidences from a large corpus (e.g.
Brent91,Sekine92, Smadja91, and Zernik89).
We are con-cerned with the kinds of information the availablesources may contribute to thematic knowledgeacquisition.The heuristics to discriminate hematic roles areproposed in Table 2.
The heuristics uggest the sys-tem the ways of collecting useful information forresolving ambiguities.
Volition Heuristic and Impera-tive Heuriz'jc are for confirming the Agent role,One-Theme Heuristic is for Theme, while ThematicHierarchy Heuristic, Preposition Heuristic andUniqueness Heuristic may be used in a general way.It sh~ald be noted that, for the purposes of effi-cient acquisition, not all of the heuristics were identi-cal to the corresponding original linguistic postula-tions.
For example, Thematic Hierarchy Heuristic wasmotivated by the Thematic Hierarchy Condition(Jackendoff72) but embedded with more constraintsto filter ou~ more hypotheses.
One-Theme Heuristicwas a relaxed version of the statement "every sen-tence has a theme" which might be too strong in manycases (Jack.
mdoff87).Becaase of the space limit, we only use anexample tc illustrate the idea.
Consider (2.1) "Therobber rob'~ed the bank of the money" again.
As245mentioned above, after applying the preliminary syn-tactic clues, "the robber", "the bank", and "themoney" may be {Ag, Go, So, Th}, {Ge, So, Th, Re},and {Th} respectively.
By applying UniquenessHeuristic to the Theme role, the argument structure of"rob" in the sentence can only be(AS1) "{Ag, Go, So}, {Go, So, Re}, {Th}",which means that, the external argument is {Ag, Go,So} and the internal arguments are {Go, So, Re} and{Th}.
Based on the intermediate result, VolitionHeuristic, Imperative Heuristic, Thematic HierarchyHeuristic, and Preposition Heuristic ould be invokedto further esolve ambiguities.Volition Heuristic and Imperative Heuristic askthe learner to verify the validities of:the sentencessuch as "John intentionally robbed the bank" ("John"and "the robber" matches because they have the sameproperties considered in Table 1 and Table 2).
If thesentence is "accepted", an Agent is needed for "rob".Therefore, the argument structure becomes(AS2) "{Ag}, {Go, So, Re}, {Th}"Thematic Hierarchy Heuristic guides thelearner to test the validity of the passive Form of (2.1).Similarly, since sentences like "The barb: is robbed byMary" could be valid, "The robber" is higher than"the bank" in the Thematic Hierarchy.
Therefore, thelearner may conclude that either AS3 or AS4 may bethe argument structure of "rob":(AS3) "{Ag}, {Go, So, Re}, {Th}"(AS4) "{Go, So}, {Re}, {Th}".Preposition Heuristic suggests the learner to toresolve ambiguities based on the prel:ositions of PPs.For example, it may suggest he sys~.em to confirm:The money is from the bank?
If sc, "the bank" isrecognized as Source.
The argument structurebecomes(AS5) "{Ag, Go}, {So}, {Th}".Combining (AS5) with (AS3) or (ASS) with (AS2),the learner may conclude that the arg~rnent structureof"rob" is "{Ag}, {So}, {Th}".In summary, as the arguments of lexical headsare entered to the acquisition system, the clues inTable 1 are consulted first to reduce tiae hypothesisspace.
The heuristics in Table 2 are then invoked tofurther resolve the ambiguities by coliecting usefulinformation from other sources.
The information thatthe heuristics suggest he system to collect is thethematic validities of the sentences that may help toconfirm the target hematic roles.The confirmation i formation required by Voli-tion Heuristic, Imperative Heuristic.
and ThematicHierarchy Heuristic may come from corpora (and ofcourse trainers as well), while Preposition Heuristicsometimes r, eeds the information only available fromtrainers.
This is because the derivation of new PPsmight generate ungrammatical sentences not availablein general .:orpora.
For example, (3.1) from (2.3)"The key can open the door" is grammatical, while(3.2) from (2.5) "The letter finally reached John" isungrammatical.
(3.1) The door is opened by the key.
(3.2) *The letter finally reached to John.Therefore, simple queries as above are preferred inthe method.It should also be noted that since these heuris-tics only serve as the guidelines for finding discrimi-nation information, the sequence of their applicationsdoes not have significant effects on the result oflearning.
However, the number of queries may beminimized by applying the heuristics in the order:Volition Heuristic and Imperative Heuristic ->Thematic Hierarchy Heuristic -> Preposition Heuris-tic.
One-Th',~me Heuristic and Uniqueness Heuristicare invoked each time current hypotheses of thematicroles are changed by the application of the clues, Vol-ition Heuristic, Imperative Heuristic, ThematicHierarchy Heuristic, or Preposition Heuristic.
This isbecause One-Theme Heuristic and UniquenessHeuristic az'e constraint-based.
Given a hypothesis ofthematic r~.es, they may be employed to filter outimpossible combinations of thematic roles withoutusing any qaeries.
Therefore, as a query is issued byother heuristics and answered by the trainer or thecorpus, the two heuristics may be used to "extend" theresult by ft~lher educing the hypothesis space.4.
EXPERIMENTAs described above, the proposed acquisition methodrequires yntactic information of arguments as input(recall Table 1).
We believe that the syntactic infor-mation is one of the most commonly availableresources, it may be collected from a syntactic pro-cessor or a ;yntactically processed corpus.
To test themethod wita a public corpus as in Grishman92a, thePENN Tre~Bank was used as a syntactically pro-cessed co~pus for learning.
Argument packets(including VP packets and NP packets) wereextracted .tom ATIS corpus (including JUN90,SRI_TB, and TI_TB tree files), MARI corpus (includ-ing AMBIC~ and WBUR tree files), MUC1 corpus,and MUC2 corpus of the treebank.
VP packets andNP packets recorded syntactic properties of the argu-ments of verbs and nouns respectively.246Corpus SentencesATIS 1373MARI 543MUC1 1026MUC2 3341Table 3.
Argument extraction from TreeBank{Nords1528698972266273548VP packe~ Verbs NPpacke~ Nouns1716 138 959 1881067 509 425 2881916 732 907 4906410 1556 3313 1177Since not all constructions involving movementwere tagged with trace information in the corpus, toderive the arguments, the procedure needs to considerthe constructions of passivization, interjection, andunbounded ependency (e.g.
in relative clauses andwh-questions).
That is, it needs to determine whethera constituent is an argument of a verb (or noun),whether an argument is moved, and if so, which con-stituent is the moved argument.
Basically, CaseTheory, Theta Theory (Chomsky81), and FootFeature Principle (Gazdar85) were employed to locatethe arguments (Liu92a, Liu92b).Table 3 summarizes the results of the argumentextraction.
About 96% of the trees were extracted.Parse trees with too many words (60) or nodes (i.e.
50subgoals of parsing) were discarded.
~2~1 VP packetsin the parse trees were derived, but only the NP pack-ets having PPs as modifiers were extracted.
These PPscould help the system to hypothesize axgument s ruc-tures of nouns.
The extracted packets were assimi-lated into an acquisition system (called EBNLA,Liu92a) as syntactic subcategorization frames.
Dif-ferent morphologies of lexicons were not counted asdifferent verbs and nouns.As an example of the extracted argument pack-ets, consider the following sentence from MUCI:"..., at la linea ..... where a FARC front ambushed an1 lth brigade army patrol".The extraction procedure derived the following VPpacket for "ambushed":ambushed (NP: a FARC fxont) (WHADVP: where)(NP: an 1 lth brigade army patrol)The first NP was the external argument of the verb.Other constituents were internal arga:nents of theverb.
The procedure could not determ,r.e whether anargument was optional or not.In the corpora, most packets were for a smallnumber of verbs (e.g.
296 packets tot "show" werefound in ATIS).
Only 1 to 2 packets could be foundfor most verbs.
Therefore, although tt.e parse treescould provide good quality of argument packets, theinformation was too sparse to resoNe, thematic roleambiguities.
This is a weakness embedded in mostcorpus-based acquisition methods, since the learnermight finally fail to collect sufficient information afterspending much.
effort to process the corpus.
In thatcase, the ~ambiguities need to be temporarilysuspended.
~To seed-up learning and focus on theusage of the proposed method, a trainer was asked tocheck the thematic validities (yes/no) of the sentencesgenerated b,, the learner.Excluding packets of some special verbs to bediscussed later and erroneous packets (due to a smallamount of inconsistencies and incompleteness of thecorpus and the extraction procedure), the packetswere fed into the acquisition system (one packet for averb).
The average accuracy rate of the acquired argu-ment struct~ares was 0.86.
An argument structure wascounted as correct if it was unambiguous and con-firmed by the trainer.
On average, for resolving ambi-guities, 113 queries were generated for every 100 suc-cessfully acquired argument structures.
The packetsfrom ATIS caused less ambiguities, since in thiscorpus there were many imperative sentences towhich Impe:ative Heuristic may be applied.
VolitionHeuristic, Thematic Hierarchy Heuristic, and Preposi-tion Heuristic had almost equal frequencies of appli-cation in the experiment.As an.
example of how the clues and heuristicscould successfully derive argument structures ofverbs, consider the sentence from ATIS:"The flight going to San Francisco ...".Without issuing any queries, the learner concludedthat an argument structure of "go" is "{Th}, {Go}"This was because, according to the clues, "San Fran-cisco" couM only be Goal, while according to One-Theme Heuristic, "the flight" was recognized asTheme.
Most argument structures were acquiredusing 1 to ~ queries.The result showed that, after (manually orautomatically) acquiring an argument packet (i.e.
asyntactic st, bcategorization frame plus the syntacticconstituent l 3f the external argument) of a verb, theacquisition~'rnethod c uld be invoked to upgrade thesyntactic knowledge to thematic knowledge by issu-ing only 113 queries for every 100 argument packets.Since checking the validity of the generated sentencesis not a heavy burden for the trainer (answering 'yes'247or 'no' only), the method may be attached to varioussystems for promoting incremental extensibility ofthematic knowledge.The way of counting the accuracy rate of theacquired argument structures deserves notice.
Failedcases were mainly due to the clues and heuristics thatwere too strong or overly committed.
For example,the thematic role of "the man" in (4.1) from MARIcould not be acquired using the clues and heuristics.
(4.1) Laura ran away with the man.In the terminology of Gruber76, this is an expressionof accompaniment which is not considered in theclues and heuristics.
As another example, consider(4.2) also from MARI.
(4.2) The greater Boston area ranked eight amongmajor cities for incidence of AIDS.The clues and heuristics could not draw any conclu-sions on the possible thematic roles of "eight".On the other hand, the cases cour.ted as "failed"did not always lead to "erroneous" argument struc-tures.
For example, "Mary" in (2.9) "John promisedMary to marry her" was treated as Theme rather thanGoal, because "Mary" is the only possible Theme.Although "Mary" may be Theme in this case as well,treating "Mary" as Goal is more f'me-grained.The clues and heuristics may often lead toacceptable argument structures, even if the argumentstructures are inherently ambiguous.
For example, anNP might function as more than one thematic rolewithin a sentence (Jackendoff87).
Ia (4.3), "John"may be Agent or Source.
(4.3) John sold Mary a coat.Since Thematic Hierarchy Heuristic assumes that sub-jects and objects cannot reside at the same level,"John" must not be assigned as Sotuce.
Therefore,"John" and "Mary" are assigned as Agent and Goalrespectively, and the ambiguity is resolved.In addition, some thematic roles may causeambiguities if only syntactic evidences are available.Experiencer, such as "John" in (4.4), arid Maleficiary,such as "Mary" in (4.5), are the two examples.
(4.4) Mary surprised John.
(4.5) Mary suffers a headache.There are difficulties in distinguishing Experiencer,Agent, Maleficiary and Theme.
Fortunately, the verbswith Experiencer and Maleficiary may be enumeratedbefore learning.
Therefore, the argumen,: structures ofthese verbs are manually constructed rather thanlearned by the proposed method.5.
RELATED WORKTo explore the acquisition of domain-independentsemantic knowledge, the universal linguistic con-straints postulated by many linguistic studies mayprovide gefieral (and perhaps coarse-grained) hints.The hints may be integrated with domain-specificsemantic bias for various applications as well.
In thebranch of Lhe study, GB theory (Chomsky81) anduniversal feature instantiation principles (Gazdar85)had been shown to be applicable in syntacticknowledge ,.cquisition (Berwick85, Liu92a, Liu92b).The proposed method is closely related to thosemethodolog,.es.
The major difference is that, variousthematic theories are selected and computationalizedfor thematic knowledge acquisition.
The idea ofstructural patterns in Montemagni92 is similar toPreposition Heuristic in that the patterns uggest gen-eral guidance to information extraction.Extra information resources are needed forthematic knawledge acquisition.
From the cognitivepoint of view, morphological, syntactic, semantic,contextual (Jacobs88), pragmatic, world knowledge,and observations of the environment (Webster89,Siskind90) .~e all important resources.
However, theavailability~of the resources often deteriorated thefeasibility o f  learning from a practical standpoint.The acquisition often becomes "circular" when rely-ing on semantic information to acquire target seman-tic informatmn.Prede~:ined omain linguistic knowledge isanother important information for constraining thehypothesis ,space in learning (or for semanticbootstrapping).
From this point of view, lexicalcategories (Zernik89, Zemik90) and theory of lexicalsemantics (Pustejovsky87a, Pustejovsky87b) playedsimilar role~ as the clues and heuristics employed inthis paper.
The previous approaches had demon-strated the?
::etical interest, but their performance onlarge-scale acquisition was not elaborated.
We feelthat, requ~,ng the system to use available resourcesonly (i.e, .,;yntactic processors and/or syntacticallyprocessed c'orpora) may make large-scale implemen-tations more feasible.
The research investigates theissue as to l what extent an acquisition system mayacquire thematic knowledge when only the syntacticresources a:e available.McClelland86 showed a connectionist modelfor thematic role assignment.
By manually encodingtraining ass!gnments and semantic microfeatures for alimited number of verbs and nouns, the connectionistnetwork learned how to assign roles.
Stochasticapproaches (Smadja91, Sekine92) also employedavailable corpora to acquire collocational data forresolving ambiguities in parsing.
However, theyacquired numerical values by observing the whole248,training corpus (non-incremental learning).
Explana-tion for those numerical values is difficult to derive inthose models.
As far as the large-scale thematicknowledge acquisition is concerned, the incrementalextensibility of the models needs to be furtherimproved.6.
CONCLUSIONPreliminary syntactic analysis could be achieved bymany natural anguage processing systems.
Towardsemantic interpretation on input sentences, thematiclexical knowledge is needed.
Although each lexiconmay have its own idiosyncratic thematic requirementson arguments, there exist syntactic clues forhypothesizing the thematic roles of the arguments.Therefore, exploiting the information derived fromsyntactic analysis to acquire thematic knowledgebecomes a plausible way to build an extensiblethematic dictionary.
In this paper, various syntacticclues are integrated to hypothesize thematic roles ofarguments in training sentences.
Heuristics-guidedambiguity resolution is invoked to collect extradiscrimination information from the nainer or thecorpus.
As more syntactic resources become avail-able, the method could upgrade the acquiredknowledge from syntactic level to thematic level.AcknowledgementThis research is supported in part by NSC (NationalScience Council of R.O.C.)
under the grant NSC82-0408-E-007-029 and NSC81-0408-E007-19 fromwhich we obtained the PENN TreeBank by Dr.Hsien-Chin Liou.
We would like to thank theanonymous reviewers for their helpful comments.References\[Asker92\] Asker L., Gamback B., Samuelsson C.,EBL2 : An Application to Automatic Lezical Acquisi-tion, Proc.
of COLING, pp.
1172-1176, 1992.\[Berwick85\] Berwick R. C., The Acquisition of Syn-tactic Knowledge, The MIT Press, Cambridge, Mas-sachusetts, London, England, 1985.\[Brent91\] Brent M. R., Automatic Acquisition of Sub-categorization Frames from Untagged Text, Proc.
ofthe 29th annual meeting of the ACL, pp.
209-214,1991.\[Chomsky81\] Chomsky N., Lectures or Governmentand Binding, Foris Publications - Dordrecht, 1981.\[Gazdar85\] Gazdar G., Klein E., Pullum G. K., andSag I.
A., Generalized Phrase Struc;ure Grammar,Harvard University Press, Cambridge Massachusetts,1985.\[Grimshaw88\] Grimshaw J. and Mester A., LightVerbs and Theta-Marking, Linguistic Inquiry, Vol.19, No.
2, pp.
205-232, 1988.\[Grishman92a\] Grishman R., Macleod C., and Ster-ling J., Evaluating Parsing Strategies Using Stand-ardized Parse Files, Proc.
of the Third Applied NLP,pp.
156-161, 1992.\[Grishman92b\] Grishman R. and Sterling J., Acquisi-tion of Selec tional Patterns, Proc.
of COLING-92, pp.658-664, 1992.\[Gruber76\] .Gruber J. S., Lexical Structures in Syntaxand Semantics, North-Holland Publishing Company,1976.\[Jackendoff72\] Jackendoff R. S., Semantic Interpreta-tion in Generative Grammar, The MIT Press, Cam-bridge, Massachusetts, 1972.\[Jackendoff87\] Jackendoff R. S., The Status ofThematic Relations in Linguistic Theory, LinguisticInquiry, VoL 18, No.
3, pp.369-411, 987.\[Jacobs88\] Jacobs P. and Zernik U., Acquiring Lexi-cal Knowledge from Text: A Case Study, Proc.
ofAAAI, pp.
739-744, 1988.\[Lang88\] Lang F.-M. and Hirschman L., ImprovedPortability ~nd Parsing through Interactive Acquisi-tion of Semantic Information, Proc.
of the secondconference on Applied Natural Language Processing,pp.
49-57, ~988.\[-Levin86\] Lzvin B. and Rappaport M., The Formationof Adjectival Passives, Linguistic Inquiry, Vol.
17,No.
4, pp.
623-661, 1986.\[Liu92a\] L.ia R.-L. and Soo V.-W., Augmenting andEfficiently Utilizing Domain Theory in Explanation-Based Nat~.ral Language Acquisition, Proc.
of theNinth International Machine Learning Conference,ML92, pp.
282-289, 1992.\[Liu92b\] Liu R.-L and Soo V.-W., Acquisition ofUnbounded Dependency Using Explanation-BasedLearning, Froc.
of ROCLING V, 1992.\[Liu93\] Li~a R.-L. and Soo V.-W., Parsing-DrivenGeneralization for Natural Language Acquisition,International Journal of Pattern Recognition andArtificial Intelligence, Vol.
7, No.
3, 1993.\[Lu89\] Lu R., Liu Y., and Li X., Computer-AidedGrammar Acquisition in the Chinese UnderstandingSystem CC!~AGA, Proc.
of UCAI, pp.
I550-I555,1989.\[Lytinen90\] Lytinen S. L. and Moon C. E., A Com-parison of Learning Techniques in Second LanguageLearning, \]r oc.
of the 7th Machine Learning confer-ence, pp.
317-383, 1990.249\[McClelland86\] McClelland J. L. and Kawamoto A.H., Mechanisms of Sentence Processing: AssigningRoles to Constituents of Sentences, in Parallel Distri-buted Processing, Vol.
2, pp.
272-325, 1986.\[Montemagni92\] Montemagni S. and VanderwendeL., Structural Patterns vs.
String Patterns for Extract-ing Semantic Information from Dictionary, Proc.
ofCOLING-92, pp.
546-552, 1992.\[Pustejovsky87a\] Pustejovsky J. and Berger S., TheAcquisition of Conceptual Structure for the Lexicon,Proc.
of AAM, pp.
566-570, 1987.\[Pustejovsky87b\] Pustejovsky J, On the Acquisition ofLexical Entries: The Perceptual Origin of ThematicRelation, Proc.
of the 25th annual meeting of theACL, pp.
172-178, 1987.\[Samuelsson91\] Samuelsson C. and Rayner M.,Quantitative Evaluation of Explanation-Based Learn-ing as an Optimization Tool for a Large-ScaleNatural Language System, Proc.
of IJCAI, pp.
609-615, 1991.\[Sanfilippo92\] Sanfilippo A. and Pozanski V., TheAcquisition of Lexical Knowledge from CombinedMachine-Readable Dictionary Sources, Proc.
of theThird Conference on Applied NLP, pp.
80-87, 1992.\[Sekine92\] Sekine S., Carroll J. J., Ananiadou S., andTsujii J., Automatic Learning for Semantic Colloca-tion, Proc.
of the Third Conference on Applied NLP,pp.
104-110, 1992.\[Simmons91\] Simmons R. F. and Yu Y.-H., TheAcquisition and Application of Context SensitiveGrammar for English, Proc.
of the 29th annual meet-ing of the ACL, pp.
122-129, 1991.\[Siskind90\] Siskind J. M., Acquiring Core Meaningsof Words, Represented as Jackendoff-style Concep-tual structures, from Correlated Streams of Linguisticand Non-linguistic Input, Proc.
of the 28th annualmeeting of the ACL, pp.
143-156, 1990.\[Smadja91\] Smadja F. A., From N-Grams to Colloca-tions: An Evaluation of EXTRACT, Proc.
of the 29thannual meeting of the ACL, pp.
279-284, 1991.\[Tanenhaus89\] Tanenhaus M. K. and Carlson G. N.,Lexical Structure and Language Comprehension, inLexical Representation and Process, WilliamMarson-Wilson (ed.
), The MIT Press, 1989.\[Taraban88\] Taraban R. and McClelland J. L., Consti-tuent Attachment and Thematic Role Assignment inSentence Processing: Influences of Content-BasedExpectations, Journal of memory and language, 27,pp.
597-632, 1988.\[Velardi91\] Velardi P., Pazienza M. T., and FasoloM., How to Encode Semantic Knowledge: A Methodfor Meaning Representation and Computer-AidedAcquisition,~Computational Li guistic, Vol.
17, No.
2,pp.
153-17G~ 1991.\[Webster89\] I Webster M. and Marcus M., AutomaticAcquisition o f  the Lexical Semantics of Verbs fromSentence Frames, Proc.
of the 27th annual meeting ofthe ACL, pp.
177-184, 1989.\[Zernik89\] Zernik U., Lexicon Acquisition: Learningfrom Corpus by Capitalizing on Lexical Categories,Proc.
of IJC&I, pp.
1556-1562, 1989.\[Zernik90\] Zernik U. and Jacobs P., Tagging forLearning: Collecting Thematic Relation from Corpus,Proc.
of COLING, pp.
34-39, 1990.250
