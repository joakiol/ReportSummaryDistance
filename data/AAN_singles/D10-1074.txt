Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 756?766,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsTowards Conversation Entailment: An Empirical InvestigationChen Zhang Joyce Y. ChaiDepartment of Computer Science and EngineeringMichigan State UniversityEast Lansing, MI 48824, USA{zhangch6, jchai}@cse.msu.eduAbstractWhile a significant amount of research hasbeen devoted to textual entailment, automatedentailment from conversational scripts has re-ceived less attention.
To address this limi-tation, this paper investigates the problem ofconversation entailment: automated inferenceof hypotheses from conversation scripts.
Weexamine two levels of semantic representa-tions: a basic representation based on syntac-tic parsing from conversation utterances andan augmented representation taking into con-sideration of conversation structures.
For eachof these levels, we further explore two ways ofcapturing long distance relations between lan-guage constituents: implicit modeling basedon the length of distance and explicit mod-eling based on actual patterns of relations.Our empirical findings have shown that theaugmented representation with conversationstructures is important, which achieves thebest performance when combined with ex-plicit modeling of long distance relations.1 IntroductionTextual entailment has received increasing attentionin recent years (Dagan et al, 2005; Bar-Haim et al,2006; Giampiccolo et al, 2007; Giampiccolo et al,2008; Bentivogli et al, 2009).
Given a segment froma textual document, the task of textual entailment isto automatically determine whether a given hypoth-esis can be entailed from the segment.
The capa-bility of such kind of inference can benefit manytext-based applications such as information extrac-tion and question answering.Textual entailment has mainly focused on infer-ence from written text in monologue.
Recent yearsalso observed an increasing amount of conversa-tional data such as conversation scripts of meetings,call center records, court proceedings, as well as on-line chatting.
Although conversation is a form oflanguage, it is different from monologue text withseveral unique characteristics.
The key distinctivefeatures include turn-taking between participants,grounding between participants, different linguisticphenomena of utterances, and conversation impli-catures.
Traditional approaches dealing with tex-tual entailment were not designed to handle theseunique conversation behaviors and thus to supportautomated entailment from conversation scripts.Example 1:Conversation Segment:B: My mother also was very very independent.She had her own, still had her own little houseand still driving her own car,A: Yeah.B: at age eighty-three.Hypothesis:(1) B?s mother is eighty-three.
(2) B is eighty-three.To address this limitation, our previouswork (Zhang and Chai, 2009) has initiated aninvestigation on the problem of conversation en-tailment.
The problem was formulated as follows:given a conversation discourse D and a hypothesisH concerning its participant, the goal was to identifywhether D entails H. For instance, as in Example1, the first hypothesis can be entailed from the756conversation segment while the second hypothesiscannot.
While our previous work has providedsome interesting preliminary observations, it mostlyfocused on data collection and initial experimentsand analysis using a small set of development data.It is not clear whether the previous results aregenerally applicable, how different components inthe entailment framework interact with each other,and how different representations may influence theentailment outcome.To reach a better understanding of conversationentailment, we conducted a further investigationbased on the larger set of test data collected in ourprevious work (Zhang and Chai, 2009).
We specifi-cally examined two levels of representations: a basicrepresentation based on syntactic parsing from con-versation utterances and an augmented representa-tion taking into consideration of conversation struc-tures.
For each of these levels, we further exploredtwo ways of capturing long distance relations: (1)implicit modeling based on the length of distanceand (2) explicit modeling based on actual patternsof relations.
Our empirical findings have shown thataugmented representation with conversation struc-tures is important in conversation entailment.
Com-bining conversation structures with explicit model-ing of long distance relations results in the best per-formance.2 Related WorkOur work here is related to recent advances in tex-tual entailment, automated processing of conversa-tion scripts, and our initial investigation on conver-sation entailment.There is a large body of work on textual en-tailment initiated by the Pascal Recognizing Tex-tual Entailment (RTE) Challenges (Dagan et al,2005; Bar-Haim et al, 2006; Giampiccolo et al,2007; Giampiccolo et al, 2008; Bentivogli et al,2009).
Different approaches have been developed,for example, based on logic proving (Tatu andMoldovan, 2005; Bos and Markert, 2005; Raina etal., 2005) and graph match (Haghighi et al, 2005;de Salvo Braz et al, 2005; MacCartney et al, 2006).Supervised learning approaches have also been ap-plied to measure the similarities between trainingand testing pairs (Zanzotto and Moschitti, 2006).
Inthe most recent RTE Challenge (Bentivogli et al,2009), the best system achieves 73.5% of accuracy,while the median performance among all partici-pants is 60.4%.
These results indicate that, whileprogress has been made, textual entailment remainsa challenging problem.As more and more conversation data becomesavailable, researchers have investigated automatedprocessing of conversation data to acquire usefulinformation, for example, related to opinions (So-masundaran et al, 2007; Somasundaran et al,2008; Somasundaran et al, 2009), biographic at-tributes (Garera and Yarowsky, 2009), social net-works (Jing et al, 2007), and agreements anddisagreements between participants (Galley et al,2004).
Recent studies have also developed ap-proaches to summarize conversations (Murray andCarenini, 2008) and to model conversation struc-tures (dialogue acts) from online Twitter conversa-tions (Ritter et al, 2010).
Here we address a dif-ferent angle regarding conversation scripts, namelyconversation entailment.In our previous work (Zhang and Chai, 2009),we started an initial investigation on conversationentailment.
We have collected a dataset of 875instances.
Each instance consists of a conversa-tion segment and a hypothesis (as described in Sec-tion 1).
The hypotheses are statements about conver-sation participants and are further categorized intofour types: about their profile information, their be-liefs and opinions, their desires, and their commu-nicative intentions.
We developed an approach thatis motivated by previous work on textual entailment.We use clauses in the logic-based approaches as theunderlying representation of our system.
Based onthis representation, we apply a two stage entailmentprocess similar to MacCartney et al (2006) devel-oped for textual entailment: an alignment stage fol-lowed by an entailment stage.Building upon our previous work, in this paper,we systematically examine different representationsof the conversation segment and different modelingof long distance relations between language con-stituents.
We compare the roles of these differentrepresentations on the performance of entailmentprediction using a larger testing dataset that was notpreviously evaluated.
This analysis allows better un-derstanding of the problem and provides insight on757potential solutions.3 Overall FrameworkIn our previous work (Zhang and Chai, 2009), con-versation entailment is formulated as the follow-ing: given a conversation segment D which is rep-resented by a set of clauses D = d1 ?
.
.
.
?
dm,and a hypothesis H represented by another set ofclauses H = h1 ?
.
.
.
?
hn, the prediction onwhether D entails H is determined by the productof probabilities that each hypothesis clause hj isentailed from all the conversation segment clausesd1 .
.
.
dm as follows.
This is based on a simple as-sumption that whether a clause is entailed from aconversation segment is conditionally independentfrom other clauses.P (D  H|D,H)= P (D  h1, .
.
.
, D  hn|D,h1, .
.
.
, hn)=n?j=1P (D  hj |D = d1 .
.
.
dm, hj)=n?j=1P (d1 .
.
.
dm  hj |d1, .
.
.
, dm, hj) (1)A clause here is similar to a sentence in first-order predicate calculus.
It is made up by termsand predicates.
A term is either: 1) an entitydescribed by a noun phrase, e.g., John Lennon,mother, or she; or 2) an action or event de-scribed by a verb phrase, e.g., marry in ?Johnmarried Eva in 1940?.
A predicate representseither: 1) a property (i.e., unary) for a term,e.g., Russian(company), or recently(visit);or 2) a relation (i.e., binary) between twoterms, e.g., subj(visit, Prime Minister) andobj(visit, Brazil) in ?Prime Minister recently vis-ited Brazil?.Given the clause representation, we follow theidea similar to MacCartney et al (2006), and predictthe entailment decision in two stages of processing:(1) an alignment model aligns terms in the hypothe-sis to terms in the conversation segment; and (2) aninference model predicts the entailment based on thealignment between the hypothesis and the conversa-tion segment.3.1 Alignment ModelAn alignment is defined as a mapping function gbetween a term x in the conversation segment and aterm y in the hypothesis.
g(x, y) = 1 if x and y arealigned; otherwise g(x, y) = 0.
It is possible thatmultiple terms from the segment are mapped to oneterm in the hypothesis (g(x1, y) = g(x2, y) = 1),or vice versa (g(x, y1) = g(x, y2) = 1).
To predictthese alignments, the problem is formulated as bi-nary classification: given any two terms x from theconversation and y from the hypothesis, decide thevalue of their alignment function g(x, y).3.2 Inference ModelOnce an alignment between a hypothesis and a con-versation segment is established, an inference modelis applied to predict whether the conversation seg-ment entails the hypothesis given such alignment.More specifically, as shown in Equation 1, given aclause from the hypothesis hj , a set of clauses fromthe conversation segment d1, .
.
.
, dm, and an align-ment g between them, the goal is to predict whetherd1, .
.
.
, dm entails hj under the alignment g.The prediction is treated differently according todifferent types of clauses.
If hj is a property clause(i.e., takes one argument hj(?
)), a property inferencemodel is applied; otherwise (i.e., relational clauseswith two arguments hj(?, ?
)), a relational inferencemodel is applied.In this paper we follow the same framework.However our focus here is on the new question thathow different levels of semantic representation anddifferent approaches of modeling long distance rela-tionship affect the alignment and inference modelsas well as the overall entailment performance.4 Semantic RepresentationGiven the clause representation described earlier,an important question is what information from theconversation segment should be captured and repre-sented.
To address this question, we examined twolevels of shallow semantic representation.
The firstlevel is basic representation which only captures theinformation from all the utterances in the conversa-tion segment.
The second representation includesconversation structures (e.g., speakers and dialogue758acts).
Next we use Example 2 to illustrate these rep-resentations.Example 2:Conversation Segment:B: Have you seen Sleeping with the Enemy?A: No.
I?ve heard that?s really great, though.B: You have to go see that one.Hypothesis:B suggests A to watch Sleeping with the Enemy.4.1 Basic RepresentationThe first representation is based on the syntacticparsing from conversation utterances and we call ita basic representation.
Figure 1(a) shows an exam-ple of dependency structures for several utterancesthat are derived from the Stanford parser (Klein andManning, 2003), and Figure 1(b) shows the corre-sponding clause representation.
In the dependencystructure, the vertices represent entities (e.g., x1) andactions (e.g., x3) within an utterance.
They corre-spond to terms in the clause representation.
An edgebetween vertices captures a dependency relation andis represented as predicates in the clause representa-tion.
For example, the edge between x1 and x3 indi-cates x1 is the subject of x3, which is represented bythe clause representation subj(x3, x1).
Similar rep-resentation also applies to the hypothesis as shownin Figure 1(c), 1(d).4.2 Augmented RepresentationThe second representation is built upon the basicrepresentation and incorporates conversation struc-ture across turns and utterances.
We call it an aug-mented representation.
Figure 2(a) shows the aug-mented structures of the conversation segment andFigure 2(b) shows the corresponding clause repre-sentation.
Compared to the basic representation,there are two additional types of vertices (i.e., terms)highlighted in the figures:?
Vertices representing utterances (e.g.,u1 .
.
.
u4).
Their corresponding terms capturethe dialogue acts for the utterances (e.g.u1 = yes no question).
To focus our effort,currently we only apply annotated dialogueacts provided in the Switchboard corpus (God-frey and Holliman, 1997).
Two edges areadded to connect different utterances.
Thefirst edge connects each utterance vertex tothe head of the corresponding utterance toindicate the specific content of the utterance(e.g., content(u1, x3)).
The second edge con-nects an utterance to its succeeding utteranceto indicate the temporal progression of theconversation (e.g., follow(u2, u1)).?
Vertices representing speakers or participants(e.g., sA, sB).
One edge is added toconnect each utterance to its speaker (e.g.,speaker(u1, sB)).Note that since our clause representations aremainly based on the dependency relations, they aremostly syntactic-driven.
However, it does capturesome shallow semantics such as who is the agent(i.e., subject) or the patient (i.e., object) of an event.The incorporation of speakers and dialogue acts inour augmented representations provides additionalsemantics of conversation discourse.5 Modeling LDRA critical part in predicting entailment is to recog-nize the semantic relationship between two languageconstituents, especially when these two constituentsare not directly related.
In Figure 2(a), for exam-ple, we want to recognize that x9 (You) is the (log-ical) subject of x11 (see).
Here we experimentedtwo ways of modeling such long distance relations(LDR).5.1 Implicit Modeling of LDRThe first method characterizes the relationship sim-ply by the distance between two constituents in thedependency structure (or augmented structure).
Forexample, in Figure 2(a) the distance between x11and x9 is 3.
We call this method an implicit mod-eling of long distance relationship.The advantage of implicit modeling is that it iseasy to implement based on the dependency struc-ture.
However, its limitation is that the distance mea-sure does not capture sufficient information of se-mantic relations between language constituents.5.2 Explicit Modeling of LDRThe second way of modeling long distance relation-ship is called explicit modeling.
It uses a string to759B:HaveyouseenSleeping withthe Enemy?A:No.
I'veheardthat'sreallygreat, though.B:You havetogoseethat one.x 9x 13x 12x 11x 10x 4x 1x 3x 2x 5x 8x 6x 7obj(x 3,x 2)subj(x3,x1)aux(x 3,x 4)x 1=Ax 2=Sleepingwith theEnemyx 3=seen, x4=haveobj(x 11,x10)obj(x 12,x11)obj(x 13,x12)subj(x13,x9)x 9=A,x 10=one,x 11=see, x12=go,x 13=havesubj(x7,x6)obj(x 8,x 7)subj(x8,x5)x 5=A,x 6=thatx 7=is really greatx 8=have heardClausesTerms(a) dependency structure of the conversationutterancesB:HaveyouseenSleeping withthe Enemy?A:No.I've heardthat'sreallygreat, though.B:Youhavetogoseethat one.x 9x 13x 12x 11x 10x 4x 1x 3x 2x 5x 8x 6x 7obj(x3,x2)subj(x3,x1)aux(x3,x4)x 1=Ax 2=SleepingwiththeEnemyx 3=seen,x 4=haveobj(x11,x 10)obj(x12,x 11)obj(x13,x 12)subj(x13,x 9)x 9=A,x 10=one,x 11=see,x 12=go,x 13=havesubj(x7,x6)obj(x8,x7)subj(x8,x5)x 5=A,x 6=thatx 7=is reallygreatx 8=haveheardClausesTerms(b) basic representation of the conver-sation segmentx 1x 2x 5x 4x 3BsuggestsAtowatchSleepingwith theEnemy.subjsubjobjobjB:HaveyouseenSleeping withthe Enemy?A:No.
I've heardthat's reallygreat,though.B:You havetogoseethat one.x 9x 13x 12x 11x 10x 4x 1x 3x 2x 5x 8x 6x 7u 1 u 2 u 3 u 4s B s A(c) dependency structure of the hypothesisobj(x3,x2),subj(x 3,x 1)aux(x3,x4)x 1=A,x 3=seen,x 4=havex 2=SleepingwiththeEnemyobj(x11,x 10),obj(x12,x 11)obj(x13,x 12),subj(x 13,x 9)x 9=A,x 10=one, x11=seex 12=go,x 13=havespeaker(u 4,s B)content(u 4,x 13)follow(u 4,u 3)u 4=viewpointsubj(x7,x6),obj(x8,x7)subj(x8,x5)x 5=A,x 7=is reallygreatx 6=that, x8=have heardspeaker(u 3,s A)content(u 3.x 8)follow(u 3,u 2)u 3=statementspeaker(u 2,s A)follow(u 2,u 1)u 2=no_answerspeaker(u 1,s B)content(u 1, x3)s A,s Bu 1=yes_no_questionClausesTermssubj(x4,x2)obj(x4,x3)subj(x5,x1)obj(x5,x4)x 1=B,x 2=Ax 3=SleepingwiththeEnemyx 4=watchx 5=suggestsClausesTerms(d) representation of the hy-pothesisFigure 1: The dependency structures and corresponding basic representation of Example 2x 1x 2x 5x 4x 3BsuggestsAtowatchSleepingwiththe Enemy.subjsubjobjobjB:HaveyouseenSleeping withthe Enemy?A:No.I've heardthat'sreallygreat, though.B:Youhavetogoseethat one.x 9x 13x 12x 11x 10x 4x 1x 3x 2x 5x 8x 6x 7u 1 u 2 u 3 u 4s B s A(a) dependency and conversation structures of the conversationsegmentobj(x 3,x 2), subj(x 3,x 1)aux(x 3,x 4)x 1=A,x 3=seen, x4=havex 2=Sleepingwith theEnemyobj(x 11,x10), obj(x12,x11)obj(x 13,x12), subj(x 13,x 9)x 9=A,x 10=one,x 11=seex 12=go, x13=havespeaker(u 4,s B)content(u 4,x 13)follow(u 4,u 3)u 4=viewpointsubj(x7,x6),obj(x 8,x 7)subj(x8,x5)x 5=A,x 7=is really greatx 6=that, x8=haveheardspeaker(u 3,s A)content(u 3.x 8)follow(u 3,u 2)u 3=statementspeaker(u 2,s A)follow(u 2,u 1)u 2=no_answerspeaker(u 1,s B)content(u 1, x 3)s A,s Bu 1=yes_no_questionClausesTermssubj(x4,x2)obj(x 4,x 3)subj(x5,x1)obj(x 5,x 4)x 1=B,x 2=Ax 3=Sleepingwith theEnemyx 4=watchx 5=suggestsClausesTerms(b) augmented representation of the conversation seg-mentFigure 2: The dependency and conversation structures and corresponding augmented representation of Example 2760describe the path from one constituent to the other:v1e1 .
.
.
vl?1el?1vl, where v1, .
.
.
, vl are the verticeson the path and e1, .
.
.
, el?1 are the edges.
Each videscribes the type of the vertex in the dependencystructure, which is either a noun (N ), a verb (V ),or an utterance (U ).
Each ei describes whether theedge is forward (?)
or backward (?).
For ex-ample, in Figure 2(a), the path from x11 to x9 isV ?
V ?
V ?
N .This kind of string representation of paths in syn-tactic parse is known as a way of modeling ?shal-low semantics?
between any two constituents in alanguage structure.
It is largely used in other NLPtasks such as semantic role labeling (Pradhan et al,2008).
The difference here is our paths are extractedfrom dependency parses as opposed to traditionalconstituent parses, and our paths also incorporate therepresentation of conversation structures (e.g., utter-ances and speakers).6 Applications in Entailment ModelsIn this section we describe how different representa-tions and modeling of LDR are used in the alignmentand inference models.6.1 Applications in Alignment ModelAlthough a noun and a verb can potentially bealigned, to simplify the problem, we restrict theproblem to the alignment between two nouns or twoverbs.
We trained an alignment model for nouns andone for verbs separately.Table 1 summarizes a set of features used in thealignment models.
Most of these features are sharedby the model for noun alignment and the model forverb alignment.
These features include whether thetwo strings are the same, two terms have the samestem, the similarity between the two terms eitherbased on WordNet or distributional statistics (Lin,1998).To learn the alignment model for nouns, we anno-tated the noun alignments for the development dataused in PASCAL RTE-3 Challenge (Giampiccolo etal., 2007) and trained a logistic regression modelbased on the features in Table 1.
Cross-validationon the same dataset shows relatively satisfying per-formance (96.4% precision and 94.9% recall).
Inthis paper, we focus on the alignment between verbsNoun VerbAlign.
Align.Verb be identification XString equality X XStemmed equality X XAcronym equality XNamed entity equality XWordNet similarity X XDistributional similarity X XSubject consistency XObject consistency XTable 1: Features for alignment modelssince it appears more difficult.A major difference between noun alignment andverb alignment is that, for verb alignment the con-sistency of their arguments is also important.
Fortwo events (described by two verbs) to be aligned, atleast their subjects (usually denoting the executers ofactions) and objects (usually denoting the receiversof actions) should match to each other respectively.Note that, although actions/events also depend onother arguments or adjuncts, here we only considerthe subjects and objects and leave the consistencycheck of other arguments/adjuncts to downstreamprocesses.
Based on two different ways of model-ing long distance relationship (as described in Sec-tion 5), we explored two methods for modeling ar-gument consistency (AC) in verb alignment models.6.1.1 Implicit Modeling of ACThe first approach models argument consistencybased on implicit modeling of the relationship be-tween a verb and its aligned subject/object.
Specif-ically, given a pair of verb terms (x, y) where x isfrom the conversation segment and y is from the hy-pothesis, let sy be the subject of y and sx be thealigned entity of sy in the conversation (in case ofmultiple alignments, sx is the one closest to x).
Thesubject consistency of the verbs (x, y) is then mea-sured by the distance between sx and x in the de-pendency structure.
Similarly, the distance betweena verb and its aligned object is used as a measure ofthe object consistency.In Example 2, to decide whether the conversa-tion term see (x11 in Figure 1(a), 1(b), and 2) andthe hypothesis term watch (x4 in Figure 1(c), 1(d))should be aligned, we first identify the subject of x4in the hypothesis, which is x2 (A).
We then look for761x2?s alignments in the conversation segment, amongwhich x9 (You) is the closest to x11 (see).
In Fig-ure 2(a), we find the distance between x11 and x9 is3.Using the implicit modeling of argument consis-tency, we follow the same approach as in our pre-vious work (Zhang and Chai, 2009) and trained alogistic regression model to predict verb alignmentbased on the features in Table 1.6.1.2 Explicit Modeling of ACThe second approach captures argument consis-tency based on explicit modeling of the relationshipbetween a verb and its aligned subject (or object).Given a pair of verb terms (x, y), let sy be the sub-ject of y and sx be the aligned entity of sy in theconversation closest to x, we use the string describ-ing the path from x to sx as the feature to capturesubject consistency.
For example, in Figure 2(a), thepath from x11 to x9 is V ?
V ?
V ?
N .This string representation of paths is used to cap-ture both the subject consistency and the object con-sistency.
Since they are non-numerical features, andthe variability of their values can be extremely large,so we applied an instance-based classification model(e.g., k-nearest neighbor) to determine alignmentsbetween verb terms.
We measure the distance be-tween two path features by their minimal string editdistance, and then simply use the Euclidean distanceto measure the closeness between any two verbs.Again this model is trained from our developmentdata described in Zhang and Chai (2009).Figure 3 shows an example of alignment betweenthe conversation terms and hypothesis terms in Ex-ample 2.
Note that in this figure the alignmentbetween x5 = suggests from the hypothesis andu4 = opinion from the conversation segment is apseudo alignment, which directly maps a verb termin the hypothesis to an utterance term representedby its dialogue act.
This alignment is obtained byfollowing the same set of rules learned from the de-velopment dataset as in (Zhang and Chai, 2009).6.2 Applications in Inference ModelAs mentioned earlier, once an alignment is estab-lished, the inference model is to predict whethereach clause in the hypothesis is entailed from theconversation segment.
Two separate models werex 4=havex 5=Ax 2=SleepingwiththeEnemyx 1=A x 7=is reallygreatx 10=oneu 4=opinionConversation Segmentx 3=SleepingwiththeEnemyx 5=suggestsx 2=Ax 1=Bx 4=watchHypothesisx 6=thatx 11=seex 12=gox 13=havex 8=haveheardu 3=statementu 2=no_answeru 1=yes_no_questionx 3=seenx 9=As B s AFigure 3: The alignment result for Example 2used to handle the inference of property clauses(hj(x)) and and the inference of relational clauses(hj(x, y)).
Property clauses involve less variablesand are relatively simple, so we used the same prop-erty inference model as in (Zhang and Chai, 2009).Here we focus on relational inference model and ex-amine how different modeling of long distance rela-tionship may affect relation inference.For a relation h between x and y to be entailedfrom a conversation segment, we need to find a sameor similar relation in the conversation segment be-tween x?s and y?s counterparts (i.e., aligned entitiesof x and y in the conversation segment).More specifically, given a relational clause fromthe hypothesis, hj(x, y), we find the sets ofterms X ?
= {x?|x?
?
D, g(x?, x) = 1} and Y ?
={y?|y?
?
D, g(y?, y) = 1}, which are aligned with xand y, respectively.
We then find the closest re-lation between these two sets of terms, (x?, y?
),such that the distance between x?
and y?
is thesmallest for any x?
?
X ?
and y?
?
Y ?.
For in-stance, in the hypothesis of Example 2 there areterms x5=suggests and x4=watch, and a relationalclause obj(x5, x4) describing an action-object rela-tion between them.
Their counterparts in the con-762versation segment are X ?
= {u4=viewpoint} andY ?
= {x3=seen, x11=see}.
So the closest pair ofterms between these two sets is u4 and x11.
Conse-quently, whether the target relational clause hj(x, y)is entailed is determined by the relationship betweenx?
and y?.
Such relationship can be modeled eitherimplicitly or explicitly.6.3 Implicit modeling of relation inferenceIn this model we follow the simple idea that theshorter a path is between two terms, the more likelythese two terms have a direct relationship.
So wepredefine a threshold, ?L.
We predict that hj(x, y) isentailed if the distance between x?
and y?
is smallerthan ?L.
However, as can be seen, this distance doesnot reflect whether the type of relationship betweenx?
and y?
is similar to the relationship that holds be-tween x and y.6.4 Explicit modeling of relation inferenceIn order to capture more semantics from the rela-tion between two terms, we use explicit modelingof the relationship between terms x?
and y?.
Inthe previous example, the relationship between u4and x11 is modeled by the path from u4 to x11,U ?
V ?
V ?
V .Given this characterization, the prediction ofwhether hj(x, y) is entailed from the conversationsegment is formulated as a binary classificationproblem, using a k-nearest neighbor classificationmodel with following features:1.
Explicit modeling of long distance relationship,i.e., the path from x?
to y?
in the dependencystructure of the conversation segment;2.
The types (N, V, or U) of x, y, x?, and y?;3.
The type of relation between x and y, for ex-ample, obj in obj(x, y);4.
The order (i.e., before or after) between x andy, and between x?
and y?;5.
The specific type of the hypothesis.7 Evaluation and AnalysisWe evaluated different model configurations usingour data1.
This dataset consists of 291 developmentinstances and 584 testing instances.
The hypotheses1The data is available for download at http://links.cse.msu.edu:8000/lair/projects/conversationentailment_data.html.
(a) Based on basic representation(b) Based on augmented representationFigure 4: Evaluation of verb alignmentwere categorized into four types: (1) fact: profileand social relations of conversation participants (ac-counted for 47% of the development data and 49%of the testing data); (2) belief: participants?
beliefsand opinions (34% and 35%); (3) desire: partici-pants?
desire of certain actions or outcomes (11%and 4%); (4) intent: communicative intent that cap-tures some perlocutionary force from one participantto the other (e.g.
A stops B from doing something;A disagreees with B on something, 8% and 12%)Note that in our original work (Zhang and Chai,2009), only development data were used to showsome initial observations.
Here we trained our mod-els on the development data and results shown arefrom the testing data.7.1 Evaluation of Alignment ModelsThe evaluation of alignment models is based on pair-wise decision.
For each pair of terms (x, y), wherex is from a conversation segment and y is froma hypothesis, we measure whether the model cor-rectly predicts that the two terms should or shouldnot be aligned.
Because the alignment classificationhas extremely unbalanced classes, we use precision-recall of true alignments as evaluation metrics.Figure 4(a) and 4(b) shows the comparison (F-measure) of two alignment models for verb align-763Figure 5: Evaluation of inference models based on different representationsment, based on the basic representation and the aug-mented representation, respectively.
Note that wecannot directly compare the results between thesetwo figures since they involve different number ofalignment instances2.
Nevertheless, we can see theoverall trend within each figure: the explicit modeloutperforms the implicit model.
This suggests thatthe explicit modeling of semantic relationship be-tween verbs and arguments works better than the im-plicit modeling used in previous work.
Furthermore,the improvement is most noticeable when hypothe-ses are facts (24.8% with the basic representationand 24.1% with the augmented representation), andleast when hypotheses are intents (12.2% with thebasic representation and 6.2% with the augmentedrepresentation).7.2 Evaluation of Inference ModelsIn order to compare different inference models, inthis section (and this section only) we use gold-standard alignment results.
They are obtained frommanual annotation in our evaluation.
We evaluatedtwo inference models, one with implicit modelingof long distance relationship and one with explicitmodeling.
Evaluations were conducted based onboth the basic representation and the augmented rep-resentation.
Figure 5 shows the four groups of eval-uation results.Overall speaking, the augmented representationoutperforms the basic representation for both im-plicit modeling and explicit modeling of long dis-tance relationship (McNemar?s tests, p < 0.05).
Theexplicit model performs better than implicit modelonly based on augmented representation (McNe-mar?s test, p < 0.05).2The alignment based on the augmented representation inFigure 4(b) also includes pseudo alignments.Clause Rep- Relation modeling Improve-resentation Implicit Explicit mentBasic 53.9% 53.9% 0Augmented 54.8% 58.7% 3.9%Table 2: Entailment performance with different represen-tations and LDR modelingThe results were further broken down by differenthypothesis types.
For the fact type of hypotheses,there is no difference between different represen-tations and modeling of long distance relationship.This is not surprising since most hypotheses aboutpartipants?
profiling information can be inferred di-rectly from the utterances.
The augmented repre-sentation affects the intent type of hypothesis mostsignificantly, so does the explicit modeling of longdistance relationship.7.3 Interaction between ClauseRepresentations and LDR ModelingIt was shown in previous sections that the aug-mented representation helps entailment predictioncompared to the basic representation.
Here we wantto study how they interact with other entailmentcomponents and what is their effect in the enhancedmodeling of long distance relations.
Specifically, wetest the performance of implicit and explicit mod-eling of long distance relations under two differentrepresentation settings: the basic representation andthe augmented representation.Table 2 compares the performance (accuracy) ofentailment models with different relationship mod-eling.
We can see that the explicit model makes im-provement over the implicit model for augmentedrepresentation (McNemar?s test, p < 0.05), whileno improvement is made for basic representation.These evaluation results appear to suggest that there764is an interaction between clause representations andsemantic modeling of long distance relations: themodeling of long distance relations between lan-guage constituents appears only effective when con-versation structure is incorporated in the representa-tion.It is interesting to see the difference in the predic-tion performances on fact hypotheses and intent hy-potheses.
For fact, the most benefit of incorporatingexplicit modeling of long distance relationship ap-pears at the alignment stage, but not much at the in-ference stage.
However, this situation is different forintent, where the benefit of explicitly modeling longdistance relationship mostly happened at the infer-ence stage.
This observation suggests that the effectsof different types of modeling may vary for differenttypes of hypotheses, which indicates that hypothesistype dependent models may be beneficial.8 Discussion and ConclusionThis paper presents an empirical investigation onconversation entailment.
We specifically examinetwo levels of representation of conversation seg-ments and two different ways of modeling long dis-tance relations between language constituents.
Ourfindings indicate that, although traditional architec-ture and approaches for textual entailment remainimportant, additional representation and processingthat address conversation structures is critical.
Theaugmented representation with conversation struc-tures, together with explicit modeling of semanticrelations between language constituents, results inthe best performance (58.7% accuracy).The work here only represents an initial step to-wards conversation entailment.
Conversation phe-nomena are rich and complex.
Conversation entail-ment is extremely difficult.
Besides the same chal-lenges faced by textual entailment, it is further com-plicated by conversation implicature.
Although ourcurrent data enables us to start an initial investiga-tion, its small size poses significant limitations ontechnology development and evaluation.
For ex-ample, our studies have indicated hypothesis type-dependent approaches may be beneficial, howeverwe do not have sufficient data to yield reasonablemodels.
A more systematical approach to collectand create a larger set of data is crucial.
Inno-vative community-based approaches (e.g., throughweb) for data collection and annotation can be pur-sued in the future.
As more techniques in semanticprocessing (e.g., semantic role) become available,future work should also capture deeper semantics,address pragmatics, and incorporate richer worldknowledge.Finally, as the technology in conversation entail-ment is developed, its applications in NLP problemsshould be explored.
Example applications includeinformation extraction, question answering, summa-rization from conversation scripts, and modeling ofconversation participants.
These applications mayprovide new insights on the nature of the conversa-tion entailment problem and its potential solutions.AcknowledgmentsThis work was supported by grant IIS-0347548 fromthe National Science Foundation.
We thank theanonymous reviewers for their valuable commentsand suggestions.ReferencesRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, DaniloGiampiccolo, Bernardo Magnini, and Idan Szpektor.2006.
The second pascal recognising textual entail-ment challenge.
In Proceedings of the Second PAS-CAL Challenges Workshop on Recognising TextualEntailment, Venice, Italy.Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, DaniloGiampiccolo, and Bernardo Magnini.
2009.
The fifthpascal recognizing textual entailment challenge.
InProceedings of the Second Text Analysis Conference(TAC 2009).Johan Bos and Katja Markert.
2005.
Recognising textualentailment with logical inference.
In Proceedings ofHLT-EMNLP, pages 628?635.Ido Dagan, Oren Glickman, and Bernardo Magnini.2005.
The pascal recognising textual entailment chal-lenge.
In PASCAL Challenges Workshop on Recognis-ing Textual Entailment.Rodrigo de Salvo Braz, Roxana Girju, Vasin Pun-yakanok, Dan Roth, and Mark Sammons.
2005.
Aninference model for semantic entailment in natural lan-guage.
In Proceedings of AAAI.Michel Galley, Kathleen McKeown, Julia Hirschberg,and Elizabeth Shriberg.
2004.
Identifying agreementand disagreement in conversational speech: Use ofbayesian networks to model pragmatic dependencies.In Proceedings of ACL, pages 669?676.765Nikesh Garera and David Yarowsky.
2009.
Modeling la-tent biographic attributes in conversational genres.
InProceedings of the Joint Conference of the 47th An-nual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processing ofthe AFNLP, pages 710?718, Suntec, Singapore, Au-gust.Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, andBill Dolan.
2007.
The third pascal recognizing tex-tual entailment challenge.
In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Para-phrasing, pages 1?9.Danilo Giampiccolo, Hoa Trang Dang, BernardogMagnini, Ido Dagan, Elena Cabrio, and Bill Dolan.2008.
The fourth pascal recognizing textual entail-ment challenge.
In Proceedings of the First Text Anal-ysis Conference (TAC 2008).John J. Godfrey and Edward Holliman.
1997.Switchboard-1 Release 2.
Linguistic Data Consor-tium, Philadelphia.Aria Haghighi, Andrew Ng, and Christopher Manning.2005.
Robust textual inference via graph matching.
InProceedings of HLT-EMNLP, pages 387?394.Hongyan Jing, Nanda Kambhatla, and Salim Roukos.2007.
Extracting social networks and biographicalfacts from conversational speech transcripts.
In Pro-ceedings of ACL, pages 1040?1047.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In ACL ?03: Proceedingsof the 41st Annual Meeting on Association for Compu-tational Linguistics, pages 423?430, Morristown, NJ,USA.Dekang Lin.
1998.
An information-theoretic definitionof similarity.
In Proceedings of International Confer-ence on Machine Learning, pages 296?304.Bill MacCartney, Trond Grenager, Marie-Catherinede Marneffe, Daniel Cer, and Christopher D. Man-ning.
2006.
Learning to recognize features of validtextual entailments.
In Proceedings of HLT-NAACL,pages 41?48.Gabriel Murray and Giuseppe Carenini.
2008.
Summa-rizing spoken and written conversations.
In Proceed-ings of the 2008 Conference on Empirical Methods inNatural Language Processing, pages 773?782, Hon-olulu, Hawaii, October.Sameer S. Pradhan, Wayne Ward, and James H. Martin.2008.
Towards robust semantic role labeling.
Compu-tational Linguistics, 34(2):289?310.Rajat Raina, Andrew Y. Ng, and Christopher D. Man-ning.
2005.
Robust textual inference via learning andabductive reasoning.
In Proceedings of AAAI, pages1099?1105.Alan Ritter, Colin Cherry, and Bill Dolan.
2010.
Unsu-pervised modeling of twitter conversations.
In HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics, pages 172?180, Los An-geles, California, June.Swapna Somasundaran, Josef Ruppenhofer, and JanyceWiebe.
2007.
Detecting arguing and sentiment inmeetings.
In Proceedings of the 8th SIGdial Workshopon Discourse and Dialogue, Antwerp, September.Swapna Somasundaran, Janyce Wiebe, and Josef Rup-penhofer.
2008.
Discourse level opinion interpreta-tion.
In Proceedings of the 22nd International Con-ference on Computational Linguistics (Coling 2008),pages 801?808, Manchester, UK, August.Swapna Somasundaran, Galileo Namata, Janyce Wiebe,and Lise Getoor.
2009.
Supervised and unsupervisedmethods in employing discourse relations for improv-ing opinion polarity classification.
In Proceedings ofthe 2009 Conference on Empirical Methods in Natu-ral Language Processing, pages 170?179, Singapore,August.Marta Tatu and Dan Moldovan.
2005.
A semantic ap-proach to recognizing textual entailment.
In Proceed-ings of HLT-EMNLP, pages 371?378.Fabio Massimo Zanzotto and Alessandro Moschitti.2006.
Automatic learning of textual entailments withcross-pair similarities.
In ACL-44: Proceedings of the21st International Conference on Computational Lin-guistics and the 44th annual meeting of the Associ-ation for Computational Linguistics, pages 401?408,Morristown, NJ, USA.Chen Zhang and Joyce Chai.
2009.
What do we knowabout conversation participants: Experiments on con-versation entailment.
In Proceedings of the SIGDIAL2009 Conference, pages 206?215.766
