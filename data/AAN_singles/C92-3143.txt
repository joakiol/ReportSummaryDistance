COUPLING AN AUTOMATIC DICTATION SYSTEM WITH A GRAMMAR CHECKERJean-Pierre CHANOD, Marc EL-BEZE, Sylvle GUILLEMIN-LANNEIBM France, Paris Scientific CenterAutomatic dictation systems (ADS) arenowadays powerful and reliable.
However,some Inadequacies of the underlyingmodels still cause errors.
In this paper, weare essentially interested in the languagemodel implemented In the linguisticcomponent, and we leave aside the acousticmodule.
More precisely, we aim atImproving this linguistic model by couplingthe ADS with a syntactic parser, able todiagnose and correct grammatical errors.We describe the characteristics of such acoupling, and show how the performance ofthe ADS improves with the actual couplingrealized for French between the TangoraADS and the grammar checker developed atthe IBM France Scientific Center.Description of the TangorasystemThe Tangora system is implemented on apersonal computer IBM PSI2 or IBMRS/6000.
A vocal I/O card is added, as wellas a specialized card equipped with twomicro-processors, which provide the neededpower for the decoding algorithms.
Theprograms are written In assembly or C.The multi-lingual aspect of the Tangorasystem (DeGennaro 91) constitutes a majorasset.
Indeed, It was Initially conceived forEnglish (Averbuch, 87) by the F. Jellnekteam (IBM T. J. Watson Research Center),but It was adapted since to process Italian,German and French Inputs.
As a whole, theaverage error rate is close to 5%.
Butproblems specific to each language requireadapted solutions.The user is required to train the system byuttering 100 sentences during an enrollmentphase, and to manage slight pausesbetween two words.
For the French system,liaisons at this time are prohibited.Architecture of the systemThe voice signal is submitted to a chain ofsignal processing, in order to extractacoustic parameters from the sound wave.Thus, the data flow is reduced from 30,000to 100 bytes per second.
Two passes ofacoustic evaluation are performed: arelatively gross pass (so-called Fast Match)selects a first list of candidate words(around 500 words); this list is furtherreduced thanks to the language model (seebelow)~ so that only a small number ofremaining candidates are submitted to asecond, more precise, acoustic pass (so-called Detailed Match).
Storage constraintsas we!l as the methods used to provide thelanguage model explain that the size of thedictionary is limited to about 20,000 entries.The decoding algorithmThis algorithm determines the more likelyuttered sequence of words.
It works fromleft to right by combining the various scoresestimated by the acoustic and linguisticmodels, according to a so-called stackdecoding strategy.
At this stage, theelementary operation consists tn expandingthe best existing hypothesis which Is not yetexpanded, i. e. It consists In keeping thesentence segment, which, followed by thecontemplated current word, Is rated with thehighest likelihood.MethodsIf one formulates the problem of speechrecognition according to an Informationtheory approach, one naturally choosesprobabillstic models among all availablelanguage models (Jeltnek, 76).
The trlgram(Cerf, 90), trlPOS 1 (Derouault, 84), ortri lemma (Derouault, 90) models offer waysof estimating the probability of anysequence of words.
For instance, formula ofthe trlgram model:f lP(W~) = P(wl) ?
P(w2/wO ?
HP(wj/wI_ =, wl_ 1)1~3The analysis of decoding errors show thathalf of them are due to the acoustic model,the other half being associated with theI Model ba led on triplets of parts of AOooeh (POS),ACTES DE COLING-92, NANTI'S, 23 28 AoOr 1992 9 4 0 PRO\[:.
OF COLING-92, NArcr~s.
AUG. 23-28, 1992language model.
Actually, the number ofhomophones being quite high (2.6) In aninflected language such as French, it Isclear that no acoustic model, as perfect as Itmay be, can produce a satisfactorydecoding without the support of a languagemodel.Power and limitations of  probabilisticlanguage modelsProbablllstlc language models are powerfulenough to considerably reduce ambiguitiesthat the acoustic model alone cannot solve.However, they suffer from punctual Imper-fections that are bound to their formulation.This Is clearly shown by testing aprobablllstlc model on the lattice formed bythe set of the homophones of the words ofevery sentence.
The decoding obtained bysearching for the maxlreum likelihood path(Cerf, 91) gives an error rate close to 3%,thus showing some of the Inadequacies ofthe probablllstlc language models.Besides, and agatn for reliability reasons,statistics need to be gathered from largelearning corpora (tens or even hundreds ofmillions words).
In spite of all thepreliminary cleaning that may be done(automatic correction of typos, tripledconsonants for Instance), such a hugecorpus contains a certain number ofgrammatical errors, that Introduce noise Inthe model.Probablllstlc estlmatlons are produced bycounting triplets of words or grammaticalclasses, tn any of the trtgram, triPeS ortrllemma models, a word Is generallypredicted according to the two precedingwords, classes or lemmas only.
However,grammatical rules may apply to largerframes.
Not only the rules often apply towords located out of the window used bythe probabtllstlc model, but alsogrammatically significant words are to befound either In previous or In posteriorposition.
Let us mention, as Illustrations,some phenomena for which the probablllstlcmodel does not fit:?
Adverbs and complements constitute anobstacle to tile transfer of information ongender, number and person, while thisInformation Is needed to choosebetween different homophones, as In:I~ COMMISSION charg(ie d' 6tabllr unplan de aoutlen global aux populotlonedes terrltolres occup~m s" est RdUNIEdlmanche,Appositions and interpolated clausesIncrease the distance between elemeutswhich must agree:Plusloun= PARTI5 d'oppo=lUo, degaucho, notammant Io paHl commu=nlate, PARTAGENT co point de rue.Predicting a word thanks to timpreceding words does not allow thesystem to appropriately control personagreement when the subject follows theverb.
Example:Quo aont DEVENUS los prlnelpauxPROTAGONtSTES de la vlctolre duonze novombre?Moreover, some confusions due tohomophony induce changes ofgrammatical category, that require acomplete Interpretation of the sentenceto be properly diagnosed, as in "et"/'est ~(conjunction/verb) or "&"l"a ~(preposition/verb).Coupling the ADS with thegrammar checkerTo bring a solution to the problemsdescribed above, we propose to perform agrammatical analysis after the decodingoperation.
The grammatical analysis appliesto the best of the hypotheses selected bythe ADS.
It serves as a basis to diagnosegrammatical errors and te suggest correc-tions 2 .The syntactic parser must prove powerfuland reliable enough to effectively Improvethe performance of the ADS.
It must providea broad coverage, In order to cope with alarge variety of texts, the source and thedomain of which are not known In advance.It must also compute a global analysis ofthe sentence In order to fill the deficienciesof the probablllstlc model.Description of the syntactic parserThe syntactic parser we use meets therequirements described above (Chased el).It is actually conceived to provide the globalsyntactic analysis of extremely diversifiedtexts.It is based on an original linguistic ~rategydeveloped by Karen Jonson for US English(Heldorn 132, Jonson, 8G).
The parser Initiallye A similar approach was tested in English, but only to detect grammatically incorre~ct ~nionceB (Bellegarda 92)AcrEs DE COLING-92, NANTES, 23-28 AO~r 1992 9 4 1 PROC.
o=: (;OI.ING-92, NANTES, AUG. 23-28, 1992compute8 a syntactic sketch, whichrepresents the likeliest syntactic surfacestructure of the sentence; at this stage, suchphenomena s coordinations, ellipses,interpolated clauses, If not totally resolved,do not block the parsing.
The analysis Isbased on the so-called relaxed approach,which consists in rejecting linguisticconstraints which, as pertinent as they maybe In descriptive linguistics, are rarelysatisfied strlcto sansu In the surface struc-tures of free texts.
This strategy proves tobroaden the coverage of the grammar aswell as it allows the parser to deal witherroneous texts.Architecture of the parser:.The system is written in PLNLP(Programming Language for NaturalLanguage Processing, G. Heldorn, 72).
ItIncludes:?
A morphologic dictionary (50,000lemmas plus their Inflection tables), =* A morpho-syntactlo dictionary, whichdescribes the sub-categorizationsattached to each temma,?
A set of more than 300 PLNLP produc-tion rules, which produce the syntacticsketches,?
A set of procedures built to re-interpretthe syntactic sketches and to diagnoseerrors,?
A form generator, which providescorrected forms.Indeed, some other techniques are alsoused.
Strong syntactic constraints arerelaxed during a second pass; It allows thesystem to detect errors which induce majorsyntactic changes (for Instance confusion"et/est"), whim forbidding undesired or toonumerous parses.
Fitted parses arecomputed In case the global analysis falls(Jansen, 83) and multiple parses are rankedthanks to specific procedures (Heldorn, 76).This last point allows the system toautomatically select the strongesthypothesis, according to the linguisticfeatures (Including the grammar errors) ofthe syntactic trees.Adaptation of  the parser to the ADSAs mentioned above, many grammaticalerrors In written French are actually causedby homophones (gender, numberagreement, confusion between Infinitive andpast participle, "chantez/chanter', %t/esf",etc.).
The parser, Initially built for writtenFrench, Is thus well prepared to detecterrors produced by an ADS.It can however be adapted to the specificneeds of the ADS, by adding specificprocedures (detection of ill-recognizedfrozen phrases, etc.
), and by filtering outnon-homophonic orrections, or correctionswhich do not belong to the list of candidatesinitially proposed by the ADS.Indeed, post-processing procedures arelargely used to diagnose errors after thesyntactic tree has been computed.
Thisoffers the Immense advantage of making thesystem evolutionary: It can be easilymodified, In order to Improve the scope ofthe detections.
This made the adaptation ofthe grammar checker to the ADS quitestraightforward.Description of the processing chainIn case of the ADS, the coupling Is done bya simple call to the parser for each sen-tence.
In case of the homophone scheme,the diagram of the processing chain Isshown In the following figure:= The=e 50,000 lemmae produce about 350,000 inflected forms, which largely exceeds the 20,000 forms uemd bythe Tangora system.ACTES DE COLING-92, NANTES, 23-28 AOI)T 1992 9 4 2 Pr~oc.
OF COLIN'G-92, NANTES, AUG. 23-28, 1992Figure 1.
Coupling DiagramExpeHencosOur tests were carried on the followingtexts:corpl AFP dispatches (1000 words)corp2 AFP dispatches (3221 words)corp3 e-mail notes (1909 words)corp4 grammar books (1337 words)Only the CORP1 file was obtained through areal decoding; the other corpora wereprocessed by automatically generating theirhomophones.ResultsThe experiments were made at an earlystage of the coupling.
They could certainlybe improved with more extensive tests, asthe adaptation of the grammar checker tothe ADS would gain In accuracy.Percentage of erroneous words leftuncorrectedLM without parser with parsercorpl 4.5% 3.6%corp2 4.6% 3.6%corp3 6.3% 6.1%4corp4 7% 5.8%Given the high performance of the ADS andthe difficulty to Improve It In the frame of theprobablllstlc model, the improvement ofaround 1% observed on three of the testcorpora is very promising.Samples of corrected sentences:Example 1: Subject-predicate, attributiveadjective-noun, subject-verb agreementLee conditions ont t r~ durs ro l l  ie pays,devenus Ind6fendable, les accepteeLAfter parsing, the suggested correction Is:LUS condWons sont ~ DURES mall; lepays, DEVENU Ind6fendeble, les ACCEPTE.Example 2: subject.verb agreement; contusionbetween the conjunction "st" end the verbal form"est" :Le felt que le I~ros de chscun des bolsromans solent dlffdrents el: rGv~lateers.After parsing, the suggested correction Is:Le felt qua le h6ros de chscun des b~lsromans SOIT DIFF6RENT ESTR6V6LATEUR.Example 3: Confusion between the verbal form"e ~ and the preposition "A"; Confusion betweenthe past participle and the Infinitive form of thecorresponding verb.Ce document est a falro sign6 recto etverso par le propdGtalro st par le gesUon-nalro.After parsing, the suggested correction Is:Ce document est & falro SIGNER recto etverso par le proprl6talro et par le gestlon-nalro.ConclusionCoupling the ADS and the syntactic parsermeets the Initially assigned objectives quitesatisfactorily: broad coverage of the textsparsed by the grammar, meaningfulpercentage of justified corrections,adequacy of the syntactic parser to thetypes of errors specifically generated by thedecoder.The tests that we performed on variouscorpora are all the more encouraging, sincea great deal of the remaining errors resultfrom semantic ambiguities that no grammarchecker based upon a syntactic analysis ofthe sentence can detect.4 The bad results of the CORP3 file are due In greet part to the difficulties of e-mall, that make parsing lessaccurate.ACTES DE COLING-92, NANTES, 23-28 AOt~T 1992 9 4 3 PROC.
OF COLING-92, NANH'ES, AUG. 23-28, 1992L'~ge do la MER lu plus fr~luent ~ I'accou-chement est de vlngt-slx ans.A subsidiary advantage of the couplingwould be to detect errors that would not beproduced by the ADS but by the speakerhim/herself (punctuation, stylistic infelicities,mood of subordinate clauses, etc.).
Not onlywe may contemplate transcribing asaccurately as possible the words of aspeaker, but also offering him/her a stylisticaid.ReferencesAverbuch A. et al, 1987: Experiments withthe TANGORA 20,000 word SpeechRecognizer, Proceedings of ICASSP, Dallas,pp.
701-704.Bellegarda J., Braden-Harder L., Jensen K.,Kanevsky D., Zadrozny W., 1992: "Post-recognizer language processing: applica-tions to speech, handwriting", submitted toEUSIPCO'92.Cerf-Danon H., de La Noue P., Dlrlnger L.,EI-B~ze M., Marcadet J.C., 1990: "A 20,000words, automatic speech recognizer.
Adap-tation to French of the US TANGORAsystem", Nato 1990.Cerf-Danon H., EI-B~ze M., 1991: "Threedifferent Probablllstlc Language Models:Comparison and Combination", ICASSP1991.Chanod J-P., 1991: Analyse automatlqued'erreurs: strat(~gie Ilngulstlque tcomputatlonnelle, Colloque Informatlque tLangue naturelle, 23-24 janvler 91, LianaUniv.
de Nantes.DeGennaro S., Cerf-Danon H., Ferrettl M.,Gonzales J., Keppel E., 1991: "Tangora - alarge vocabulary speech recognition systemfor five languages ", EuroSpeech 1991,Genoa.Derouault A-M., M~rialdo B., 1984:"Language modeling at the syntactic level"7th International Conference on PatternRecognition, August 1984, Montreal.Derouault A-M., EI-B~ze M., 1990: "AMorphological Model for Large VocabularySpeech Recognition", ICASSP 1990.Heldorn, G.E., 1972: Natural Language Inputsto a Simulation Programming System, Ph.D.dissertation, Yale University.Heidorn G.E., Jensen K., Miller L.A., ByrdR.J., Chodorow M.S., 1962: "3"he EPISTLEText-Critiquing System", IBM system Journal,vol.21, n?3.Heidorn, G.E., 1976: "An Easily ComputedMetric for Ranking Alternative Parses",Presented at the Fourteenth Annual Meetingof the ACL, San Francisco, October 1976.Jellnek F., 1976: "Continuous SpeechRecognition by Statistical Methods",Proceedings of the IEEE, Vo/ 64, April 1976.Jensen, K., Heldorn, G.E., 1983: "The FittedParse: 100% Parsing Capability In aSyntactic Grammar of English", Prec.
Conf.on Applied Natural Language Processing,Santa Monlca, California, pp.93-98.Jensen, K. 1966: "A Broad-CoverageComputational Syntax of English",Unpublished documents, IBM T.J. WatsonResearch Center, Yorktown Heights, N.Y.ACt'ES DE COLING-92, NANTES, 23-28 AO~V 1992 9 4 4 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992
