Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 552?561,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsA Decision-Theoretic Approach to Natural Language GenerationNathan McKinleyDepartment of EECSCase Western Reserve UniversityCleveland, OH, USAnath@nmckinley.comSoumya RayDepartment of EECSCase Western Reserve UniversityCleveland, OH, USAsray@case.eduAbstractWe study the problem of generating an En-glish sentence given an underlying prob-abilistic grammar, a world and a com-municative goal.
We model the genera-tion problem as a Markov decision processwith a suitably defined reward functionthat reflects the communicative goal.
Wethen use probabilistic planning to solve theMDP and generate a sentence that, withhigh probability, accomplishes the com-municative goal.
We show empirically thatour approach can generate complex sen-tences with a speed that generally matchesor surpasses the state of the art.
Further,we show that our approach is anytime andcan handle complex communicative goals,including negated goals.1 IntroductionSuppose someone wants to tell their friend thatthey saw a dog chasing a cat.
Given such a com-municative goal, most people can formulate a sen-tence that satisfies the goal very quickly.
Fur-ther, they can easily provide multiple similar sen-tences, differing in details but all satisfying thegeneral communicative goal, with no or very lit-tle error.
Natural language generation (NLG) de-velops techniques to extend similar capabilities toautomated systems.
In this paper, we study the re-stricted NLG problem: given a grammar, lexicon,world and a communicative goal, output a validEnglish sentence that satisfies this goal.
The prob-lem is restricted because in our work, we do notconsider the issue of how to fragment a complexgoal into multiple sentences (discourse planning).Though restricted, this NLG problem is still dif-ficult.
A key source of difficulty is the nature ofthe grammar, which is generally large, probabilis-tic and ambiguous.
Some NLG techniques usesampling strategies (Knight and Hatzivassiloglou,1995) where a set of sentences is sampled froma data structure created from an underlying gram-mar and ranked according to how well they meetthe communicative goal.
Such approaches natu-rally handle statistical grammars, but do not solvethe generation problem in a goal-directed manner.Other approaches view NLG as a planning prob-lem (Koller and Stone, 2007).
Here, the commu-nicative goal is treated as a predicate to be sat-isfied, and the grammar and vocabulary are suit-ably encoded as logical operators.
Then auto-mated classical planning techniques are used toderive a plan which is converted into a sentence.This is an elegant formalization of NLG, however,restrictions on what current planning techniquescan do limit its applicability.
A key limitation isthe logical nature of automated planning systems,which do not handle probabilistic grammars, orforce ad-hoc approaches for doing so (Bauer andKoller, 2010).
A second limitation comes from re-strictions on the goal: it may be difficult to en-sure that some specific piece of information shouldnot be communicated, or to specify preferencesover communicative goals, or specify general con-ditions, like that the sentence should be readableby a sixth grader.
A third limitation comes fromthe search process: without strong heuristics, mostplanners get bogged down when given commu-nicative goals that require chaining together longsequences of operators (Koller and Petrick, 2011).In our work, we also view NLG as a plan-ning problem.
However, we differ in that ourunderlying formalism for NLG is a suitably de-fined Markov decision process (MDP).
This set-ting allows us to address the limitations outlined552above: it is naturally probabilistic, and handlesprobabilistic grammars; we are able to specifycomplex communicative goals and general criteriathrough a suitably-defined reward function; and,as we show in our experiments, recent develop-ments in fast planning in large MDPs result in ageneration system that can rapidly deal with veryspecific communicative goals.
Further, our sys-tem has several other desirable properties: it is ananytime approach; with a probabilistic grammar, itcan naturally be used to sample and generate mul-tiple sentences satisfying the communicative goal;and it is robust to large grammar sizes.
Finally,the decision-theoretic setting allows for a precisetradeoff between exploration of the grammar andvocabulary to find a better solution and exploita-tion of the current most promising (partial) solu-tion, instead of a heuristic search through the solu-tion space as performed by standard planning ap-proaches.Below, we first describe related work, followedby a detailed description of our approach.
We thenempirically evaluate our approach and a state-of-the-art baseline in several different experimentalsettings and demonstrate its effectiveness at solv-ing a variety of NLG tasks.
Finally, we discussfuture extensions and conclude.2 Related WorkTwo broad lines of approaches have been used toattack the general NLG problem.
One directioncan be thought of as ?overgeneration and rank-ing.?
Here some (possibly probabilistic) struc-ture is used to generate multiple candidate sen-tences, which are then ranked according to howwell they satisfy the generation criteria.
This in-cludes work based on chart generation and pars-ing (Shieber, 1988; Kay, 1996).
These generatorsassign semantic meaning to each individual token,then use a set of rules to decide if two words canbe combined.
Any combination which containsa semantic representation equivalent to the inputat the conclusion of the algorithm is a valid out-put from a chart generation system.
Other exam-ples of this idea are the HALogen/Nitrogen sys-tems (Langkilde-Geary, 2002).
HALogen uses atwo-phase architecture where first, a ?forest?
datastructure that compactly summarizes possible ex-pressions is constructed.
The structure allows fora more efficient and compact representation com-pared to lattice structures that were previouslyused in statistical sentence generation approaches.Using dynamic programming, the highest rankedsentence from this structure is then output.
Manyother systems using similar ideas exist, e.g.
(Whiteand Baldridge, 2003; Lu et al, 2009).A second line of attack formalizes NLG as anAI planning problem.
SPUD (Stone et al, 2003),a system for NLG through microplanning, con-siders NLG as a problem which requires realiz-ing a deliberative process of goal-directed activ-ity.
Many such NLG-as-planning systems usea pipeline architecture, working from their com-municative goal through discourse planning andsentence generation.
In discourse planning, in-formation to be conveyed is selected and splitinto sentence-sized chunks.
These sentence-sizedchunks are then sent to a sentence generator,which itself is usually split into two tasks, sen-tence planning and surface realization (Koller andPetrick, 2011).
The sentence planner takes in asentence-sized chunk of information to be con-veyed and enriches it in some way.
This is thenused by a surface realization module which en-codes the enriched semantic representation intonatural language.
This chain is sometimes referredto as the ?NLG Pipeline?
(Reiter and Dale, 2000).Another approach, called integrated generation,considers both sentence generation portions of thepipeline together (Koller and Stone, 2007).
Thisis the approach taken in some modern generatorslike CRISP (Koller and Stone, 2007) and PCRISP(Bauer and Koller, 2010).
In these generators, theinput semantic requirements and grammar are en-coded in PDDL (Fox and Long, 2003), which anoff-the-shelf planner such as Graphplan (Blum andFurst, 1997) uses to produce a list of applicationsof rules in the grammar.
These generators generateparses for the sentence at the same time as the sen-tence, which keeps them from generating realiza-tions that are grammatically incorrect, and keepsthem from generating grammatical structures thatcannot be realized properly.In the NLG-as-planning framework, the choiceof grammar representation is crucial in treatingNLG as a planning problem; the grammar pro-vides the actions that the planner will use to gener-ate a sentence.
Tree Adjoining Grammars (TAGs)are a common choice (Koller and Stone, 2007;Bauer and Koller, 2010).
TAGs are tree-basedgrammars consisting of two sets of trees, calledinitial trees and auxiliary or adjoining trees.
An553entire initial tree can replace a leaf node in the sen-tence tree whose label matches the label of the rootof the initial tree in a process called ?substitution.
?Auxiliary trees, on the other hand, encode recur-sive structures of language.
Auxiliary trees have,at a minimum, a root node and a foot node whoselabels match.
The foot node must be a leaf of theauxiliary tree.
These trees are used in a three-stepprocess called ?adjoining?.
The first step finds anadjoining location by searching through our sen-tence to find any subtree with a root whose labelmatches the root node of the auxiliary tree.
In thesecond step, the target subtree is removed from thesentence tree, and placed in the auxiliary tree as adirect replacement for the foot node.
Finally, themodified auxiliary tree is placed back in the sen-tence tree in the original target location.
We use avariation of TAGs in our work, called a lexicalizedTAG (LTAG), where each tree is associated with alexical item called an anchor.Though the NLG-as-planning approaches areelegant and appealing, a key drawback is the diffi-culty of handling probabilistic grammars, whichare readily handled by the overgeneration andranking strategies.
Recent approaches such asPCRISP (Bauer and Koller, 2010) attempt to rem-edy this, but do so in a somewhat ad-hoc way, bytransforming the probabilities into costs, becausethey rely on deterministic planning to actually re-alize the output.
In this work, we directly addressthis by using a more expressive underlying formal-ism, a Markov decision process (MDP).
We showempirically that this modification has other bene-fits as well, such as being anytime and an abilityto handle complex communicative goals beyondthose that deterministic planners can handle.We note that prior work exists that uses MDPsfor NLG (Lemon, 2011).
That work differs fromours in several key respects: (i) it considers NLGat a coarse level, for example choosing the type ofutterance (in a dialog context) and how to fill inspecific slots in a template, (ii) the source of un-certainty is not language-related but comes fromthings like uncertainty in speech recognition, and(iii) the MDPs are solved using reinforcementlearning and not planning, which is impracticalin our setting.
However, that work does considerNLG in the context of the broader task of dialogmanagement, which we leave for future work.3 Sentence Tree Realization with UCTIn this section, we describe our approach, calledSentence Tree Realization with UCT (STRUCT).We describe the inputs to STRUCT, followed bythe underlying MDP formalism and the probabilis-tic planning algorithm we use to generate sen-tences in this MDP.3.1 Inputs to STRUCTSTRUCT takes three inputs in order to generate asingle sentence.
These inputs are a grammar (in-cluding a lexicon), a communicative goal, and aworld specification.STRUCT uses a first-order logic-based seman-tic model in its communicative goal and worldspecification.
This model describes named ?en-tities,?
representing general things in the world.Entities with the same name are considered to bethe same entity.
These entities are described us-ing first-order logic predicates, where the name ofthe predicate represents a statement of truth aboutthe given entities.
In this semantic model, thecommunicative goal is a list of these predicateswith variables used for the entity names.
For in-stance, a communicative goal of ?red(d), dog(d)?
(in English, ?say anything about a dog which isred.?)
would match a sentence with the seman-tic representation ?red(subj), dog(subj), cat(obj),chased(subj, obj)?, like ?The red dog chased thecat?, for instance.A grammar contains a set of PTAG trees, di-vided into two sets (initial and adjoining).
Thesetrees are annotated with the entities in them.
En-tities are defined as any element anchored by pre-cisely one node in the tree which can appear in astatement representing the semantic content of thetree.
In addition to this set of trees, the grammarcontains a list of words which can be inserted intothose trees, turning the PTAG into an PLTAG.
Werefer to this list as a lexicon.
Each word in thelexicon is annotated with its first-order logic se-mantics with any number of entities present in itssubtree as the arguments.A world specification is simply a list of all state-ments which are true in the world surrounding ourgeneration.
Matching entity names refer to thesame entity.
We use the closed world assumption,that is, any statement not present in our world isfalse.
Before execution begins, our grammar ispruned to remove entries which cannot possibly beused in generation for the given problem, by tran-554chased(subj,obj), dog(subj)chased(subj,obj)S VP NP?subjdet N?self"dog" "chased"V?self NP?obj"dog"N?selfdetNPdog(self) V?self NP?objNP?subj"chased"VPSFigure 1: An example tree substitution operationin STRUCT.sitively discovering all predicates that hold aboutthe entities mentioned in the goal in the world,and eliminating all trees not about any of these.This often allows STRUCT to be resilient to largegrammar sizes, as our experiments will show.3.2 Specification of the MDPWe formulate NLG as a planning problem ona Markov decision process (MDP) (Puterman,1994).
An MDP is a tuple (S,A, T,R, ?)
whereS is a set of states, A is a set of actions avail-able to an agent, T : S ?
A ?
S ?
[0, 1] is apossibly stochastic function defining the probabil-ity T (s, a, s?)
with which the environment tran-sitions to s?when the agent does a in state s.R : S ?
A ?
S ?
R is a real-valued rewardfunction that specifies the utility of performing ac-tion a in state s to reach another state.
Finally, ?is a discount factor that allows planning over in-finite horizons to converge.
In such an MDP, theagent selects actions at each state to optimize theexpected infinite-horizon discounted reward.In the MDP we use for NLG, we must defineeach element of the tuple in such a way that a planin the MDP becomes a sentence in a natural lan-guage.
Our set of states, therefore, will be par-tial sentences which are in the language definedby our PLTAG input.
There are an infinite numberof these states, since TAG adjoins can be repeatedindefinitely.
Nonetheless, given a specific worldand communicative goal, only a fraction of thisMDP needs to be explored, and, as we show be-low, a good solution can often be found quickly us-ing a variation of the UCT algorithm (Kocsis andSzepesvari, 2006).Our set of actions consist of all single substitu-tions or adjoins at a particular valid location in thetree (example shown in Figure 1).
Since we are us-ing PLTAGs in this work, this means every actionadds a word to the partial sentence.
In situationswhere the sentence is complete (no nonterminalswithout children exist), we add a dummy actionthat the algorithm may choose to stop generationand emit the sentence.
Based on these state andaction definitions, the transition function takes amapping between a partial sentence / action pairand the partial sentences which can result fromone particular PLTAG adjoin / substitution, and re-turns the probability of that rule in the grammar.In order to control the search space, we restrictthe structure of the MDP so that while substitu-tions are available, only those operations are con-sidered when determining the distribution over thenext state, without any adjoins.
We do this is inorder to generate a complete and valid sentencequickly.
This allows STRUCT to operate as ananytime algorithm, described further below.The immediate value of a state, intuitively, de-scribes closeness of an arbitrary partial sentence toour communicative goal.
Each partial sentence isannotated with its semantic information, built upusing the semantic annotations associated with thePLTAG trees.
Thus we use as a reward a measureof the match between the semantic annotation ofthe partial tree and the communicative goal.
Thatis, the larger the overlap between the predicates,the higher the reward.
For an exact reward signal,when checking this overlap, we need to substituteeach combination of entities in the goal into predi-cates in the sentence so we can return a high valueif there are any mappings which are both possible(contain no statements which are not present in thegrounded world) and mostly fulfill the goal (con-tain most of the goal predicates).
However, thisis combinatorial; also, most entities within sen-tences do not interact (e.g.
if we say ?the whiterabbit jumped on the orange carrot,?
the whitenessof the rabbit has nothing to do with the carrot),and finally, an approximate reward signal gener-ally works well enough unless we need to emitnested subclauses.
Thus as an approximation, weuse a reward signal where we simply count howmany individual predicates overlap with the goalwith some entity substitution.
In the experiments,we illustrate the difference between the exact andapproximate reward signals.The final component of the MDP is the discountfactor.
We generally use a discount factor of 1;this is because we are willing to generate lengthysentences in order to ensure we match our goal.A discount factor of 1 can be problematic in gen-eral since it can cause rewards to diverge, but since555there are a finite number of terms in our rewardfunction (determined by the communicative goaland the fact that because of lexicalization we donot loop), this is not a problem for us.3.3 The Probabilistic PlannerWe now describe our approach to solving the MDPabove to generate a sentence.
Determining the op-timal policy at every state in an MDP is polyno-mial in the size of the state-action space (Brafmanand Tennenholtz, 2003), which is intractable in ourcase.
But for our application, we do not need tofind the optimal policy.
Rather we just need toplan in an MDP to achieve a given communica-tive goal.
Is it possible to do this without explor-ing the entire state-action space?
Recent work an-swers this question affirmatively.
New techniquessuch as sparse sampling (Kearns et al, 1999) andUCT (Kocsis and Szepesvari, 2006) show how togenerate near-optimal plans in large MDPs witha time complexity that is independent of the statespace size.
Using the UCT approach with a suit-ably defined MDP (explained above) allows us tonaturally handle probabilistic grammars as wellas formulate NLG as a planning problem, unify-ing the distinct lines of attack described in Sec-tion 2.
Further, the theoretical guarantees of UCTtranslate into fast generation in many cases, as wedemonstrate in our experiments.Online planning in MDPs as done by UCT fol-lows two steps.
From each state encountered, weconstruct a lookahead tree and use it to estimatethe utility of each action in this state.
Then, wetake the best action, the system transitions to thenext state and the procedure is repeated.
In orderto build a lookahead tree, we use a ?rollout policy.
?This policy has two components: if it encountersa state already in the tree, it follows a ?tree pol-icy,?
discussed further below.
If it encounters anew state, the policy reverts to a ?default?
pol-icy that randomly samples an action.
In all cases,any rewards received during the rollout search arebacked up.
Because this is a Monte Carlo esti-mate, typically, we run several simultaneous trials,and we keep track of the rewards received by eachchoice and use this to select the best action at theroot.The tree policy needed by UCT for a state s isthe action a in that state which maximizes:P (s, a) = Q(s, a) + c?lnN(s)N(s, a)(1)Algorithm 1 STRUCT algorithm.Require: Number of simulations numTrials,Depth of lookahead maxDepth, time limit TEnsure: Generated sentence tree1: bestSentence?
nil2: while time limit not reached do3: state?
empty sentence tree4: while state not terminal do5: for numTrials do6: testState?
state7: currentDepth?
08: if testState has unexplored actionsthen9: Apply one unexplored PLTAG pro-duction sampled from the PLTAGdistribution to testState10: currentDepth++11: end if12: while currentDepth < maxDepthdo13: Apply PLTAG production selectedby tree policy (Equation 1) or de-fault policy as required14: currentDepth++15: end while16: calculate reward for testState17: associate reward with first action taken18: end for19: state?
maximum reward testState20: if state score > bestSentence scoreand state has no nonterminal leaf nodesthen21: bestSentence?
state22: end if23: end while24: end while25: return bestSentenceHere Q(s, a) is the estimated value of a as ob-served in the tree search, computed as a sum overfuture rewards observed after (s, a).
N(s) andN(s, a) are visit counts for the state and state-action pair.
Thus the second term is an explorationterm that biases the algorithm towards visiting ac-tions that have not been explored enough.
c is aconstant that trades off exploration and exploita-tion.
This essentially treats each action decisionas a bandit problem; previous work shows thatthis approach can efficiently select near-optimalactions at each state.We use a modified version of UCT in order to556increase its usability in the MDP we have defined.First, because we receive frequent, reasonably ac-curate feedback, we favor breadth over depth inthe tree search.
That is, it is more important in ourcase to try a variety of actions than to pursue a sin-gle action very deep.
Second, UCT was originallyused in an adversarial environment, and so is bi-ased to select actions leading to the best averagereward rather than the action leading to the bestoverall reward.
This is not true for us, however, sowe choose the latter action instead.With the MDP definition above, we use ourmodified UCT to find a solution sentence (Algo-rithm 1).
After every action is selected and ap-plied, we check to see if we are in a state in whichthe algorithm could terminate (i.e.
the sentencehas no nonterminals yet to be expanded).
If so,we determine if this is the best possibly-terminalstate we have seen so far.
If so, we store it,and continue the generation process.
Wheneverwe reach a terminal state, we begin again fromthe start state of the MDP.
Because of the struc-ture restriction above (substitution before adjoin),STRUCT generates a valid sentence quickly.
Thisenables STRUCT to perform as an anytime algo-rithm, which if interrupted will return the highest-value complete and valid sentence it has found.This also allows partial completion of communica-tive goals if not all goals can be achieved simulta-neously in the time given.4 Empirical EvaluationIn this section, we compare STRUCT to a state-of-the-art NLG system, CRISP,1and evaluatethree hypotheses: (i) STRUCT is comparable inspeed and generation quality to CRISP as it gen-erates increasingly large referring expressions, (ii)STRUCT is comparable in speed and generationquality to CRISP as the size of the grammar whichthey use increases, and (iii) STRUCT is capableof communicating complex propositions, includ-ing multiple concurrent goals, negated goals, andnested subclauses.For these experiments, STRUCT was imple-mented in Python 2.7.
We used a 2010 version ofCRISP which uses a Java-based GraphPlan imple-mentation.
All of our experiments were run on a4-core AMD Phenom II X4 995 processor clockedat 3.2 GHz.
Both systems were given access to 81We were unfortunately unable to get the PCRISP systemto compile, and so we could not evaluate it.0.010.11101001000100000  2  4  6  8  10  12  14  16Timeto Generate (seconds)Referring Expression LengthCRISPSTRUCT, finalSTRUCT, initialFigure 2: Experimental comparison betweenSTRUCT and CRISP: Generation time vs. lengthof referring expressionGB of RAM.
The times reported are from the startof the generation process, eliminating variationsdue to interpreter startup, input parsing, etc.4.1 Comparison to CRISPWe begin by describing experiments comparingSTRUCT to CRISP.
For these experiments, we usethe approximate reward function for STRUCT.Referring Expressions We first evaluateCRISP and STRUCT on their ability to gen-erate referring expressions.
Following priorwork (Koller and Petrick, 2011), we consider aseries of sentence generation problems which re-quire the planner to generate a sentence like ?TheAdj1Adj2... Adjkdog chased the cat.
?, wherethe string of adjectives is a string that distin-guishes one dog (whose identity is specified in theproblem description) from all other entities in theworld.
In this experiment, maxDepth was setequal to 1, since each action taken improved thesentence in a way measurable by our reward func-tion.
numTrials was set equal to k(k + 1), sincethis is the number of adjoining sites available inthe final step of generation, times the number ofpotential words to adjoin.
This allows us to en-sure successful generation in a single loop of theSTRUCT algorithm.The experiment has two parameters: j, thenumber of adjectives in the grammar, and k, thenumber of adjectives necessary to distinguish theentity in question from all other entities.
We setj = k and show the results in Figure 2.
We ob-serve that CRISP was able to achieve sub-secondor similar times for all expressions of less thanlength 5, but its generation times increase ex-ponentially past that point, exceeding 100 sec-onds for some plans at length 10.
At length 15,CRISP failed to generate a referring expression;557after 90 minutes the Java garbage collector termi-nated the process.
STRUCT (the ?STRUCT final?line) performs much better and is able to generatemuch longer referring expressions without failing.Later experiments had successful referring expres-sion generation of lengths as high as 25.
The?STRUCT initial?
curve shows the time taken bySTRUCT to come up with the first complete sen-tence, which partially solves the goal and which(at least) could be output if generation was inter-rupted and no better alternative was found.
As canbe seen, this always happens very quickly.Grammar Size.
We next evaluate STRUCTand CRISP?s ability to handle larger grammars.This experiment is set up in the same way as theone above, with the exception of l ?distracting?words, words which are not useful in the sentenceto be generated.
l is defined as j ?
k. In these ex-periments, we vary l between 0 and 50.
Figure 3ashows the results of these experiments.
We ob-serve that CRISP using GraphPlan, as previouslyreported in (Koller and Petrick, 2011), handles anincrease in number of unused actions very well.Prior work reported a difference on the order ofsingle milliseconds moving from j = 1 to j = 10.We report similar variations in CRISP runtime asj increases from 10 to 60: runtime increases byapproximately 10% over that range.No Pruning.
If we do not prune the gram-mar (as described in Section 3.1), STRUCT?s per-formance is similar to CRISP using the FF plan-ner (Hoffmann and Nebel, 2001), also profiled in(Koller and Petrick, 2011), which increased from27 ms to 4.4 seconds over the interval from j = 1to j = 10.
STRUCT?s performance is less sensi-tive to larger grammars than this, but over the sameinterval where CRISP increases from 22 secondsof runtime to 27 seconds of runtime, STRUCT in-creases from 4 seconds to 32 seconds.
This is duealmost entirely to the required increase in the valueof numTrials as the grammar size increases.
Atthe low end, we can use numTrials = 20, but atl = 50, we must use numTrials = 160 in orderto ensure perfect generation as soon as possible.Note that, as STRUCT is an anytime algorithm,valid sentences are available very early in the gen-eration process, despite the size of the set of ad-joining trees.
This time does not change substan-tially with increases in grammar size.
However,the time to perfect this solution does.With Pruning.
STRUCT?s performance im-proves significantly if we allow for pruning.
Thisexperiment involving distracting words is an ex-ample of a case where pruning will perform well.When we apply pruning, we find that STRUCTis able to ignore the effect of additional distract-ing words.
Experiments showed roughly constanttimes for generation for j = 1 through j = 5000.Our experiments do not show any significant im-pact on runtime due to the pruning procedure it-self, even on large grammars.4.2 Complex Communicative GoalsIn the next set of experiments, we illustrate thatSTRUCT can solve a variety of complex commu-nicative goals such as negated goals, conjuctionsand goals requiring nested subclauses to be out-put.Multiple Goals.
We first evaluate STRUCT?sability to accomplish multiple communicativegoals when generating a single sentence.
In thisexperiment, we modify the problem from the pre-vious section.
In that section, the referred-to dogwas unique, and it was therefore possible to pro-duce a referring expression which identified it un-ambiguously.
In this experiment, we remove thiscondition by creating a situation in which the gen-erator will be forced to ambiguously refer to sev-eral dogs.
We then add to the world a numberof adjectives which are common to each of thesepossible referents.
Since these adjectives do notfurther disambiguate their subject, our generatorshould not use them in its output.
We then encodethese adjectives into communicative goals, so thatthey will be included in the output of the genera-tor despite not assisting in the accomplishment ofdisambiguation.
For example, assume we had twoblack cats, and we wanted to say that one of themwas sleeping, but we wanted to emphasize that itwas a black cat.
We would have as our goal both?sleeps(c)?
and ?black(c)?.
We want the genera-tor to say ?the black cat sleeps?, instead of simply?the cat sleeps.
?We find that, in all cases, these otherwise use-less adjectives are included in the output of ourgenerator, indicating that STRUCT is successfullybalancing multiple communicative goals.
As weshow in figure 3b (the ?Positive Goals?
curve) , thepresence of additional satisfiable semantic goalsdoes not substantially affect the time required forgeneration.
We are able to accomplish this taskwith the same very high frequency as the CRISP5580 510 1520 2530 3510  20  30  40  50  60Time to Generate (seconds)Adjoining Grammar SizeCRISPSTRUCTSTRUCT (pruning)(a) Effect of grammar size3.5 44.5 55.5 66.5 77.5 81  2  3  4  5  6  7  8  9Time to Generate (seconds)Number of GoalsPositive GoalsNegative Goals(b) Effect of multiple/ negated goals0200400600800100012002  4  6  8  10  12  14  16  18ScoreTime (seconds)Generated ScoreBest Available Score(c) Effect of nested subclausesFigure 3: STRUCT experiments (see text for details).01234561  2  3  4  5Time to Generate (seconds)Number of SentencesSTRUCT (1 entity)CRISP (1 entity)(a) One entity (?The man sat and the girlsat and ...?
).0 2040 6080 100120 1401601  2  3  4  5Time to Generate (seconds)Number of SentencesSTRUCT (2 entities)CRISP (2 entities)(b) Two entities (?The dog chased the catand ...?
).0 1020 3040 5060 701  2  3  4  5Time to Generate (seconds)Number of SentencesSTRUCT, 3 entities(c) Three entities (?The man gave the girlthe book and ...?
).Figure 4: Time taken by STRUCT to generate sentences with conjunctions with varying numbers ofentities.comparisons, as we use the same parameters.Negated Goals.
We now evaluate STRUCT?sability to generate sentences given negated com-municative goals.
We again modify the prob-lem used earlier by adding to our lexicon severalnew adjectives, each applicable only to the tar-get of our referring expression.
Since our targetcan now be referred to unambiguously using onlyone adjective, our generator should just select oneof these new adjectives (we experimentally con-firmed this).
We then encode these adjectives intonegated communicative goals, so that they will notbe included in the output of the generator, despiteallowing a much shorter referring expression.
Forexample, assume we have a tall spotted black cat,a tall solid-colored white cat, and a short spottedbrown cat, but we wanted to refer to the first onewithout using the word ?black?.We find that these adjectives which should havebeen selected immediately are omitted from theoutput, and that the sentence generated is the bestpossible under the constraints.
This demonstratesthat STRUCT is balancing these negated commu-nicative goals with its positive goals.
Figure 3b(the ?Negative Goals?
curve) shows the impact ofnegated goals on the time to generation.
Sincethis experiment alters the grammar size, we seethe time to final generation growing linearly withgrammar size.
The increased time to generate canbe traced directly to this increase in grammar size.This is a case where pruning does not help us in re-ducing the grammar size; we cannot optimisticallyprune out words that we do not plan to use.
Doingso might reduce the ability of STRUCT to producea sentence which partially fulfills its goals.Nested subclauses.
Next, we evaluateSTRUCT?s ability to generate sentences withnested subclauses.
An example of such a sentenceis ?The dog which ate the treat chased the cat.
?This is a difficult sentence to generate for severalreasons.
The first, and clearest, is that there arewords in the sentence which do not help to in-crease the score assigned to the partial sentence.Notably, we must adjoin the word ?which?
to ?thedog?
during the portion of generation where thesentence reads ?the dog chased the cat?.
This de-cision requires us to do planning deeper than onelevel in the MDP, which increases the number ofsimulations STRUCT requires in order to get thecorrect result.
In this case, we require lookaheadfurther into the tree than depth 1.
We need toknow that using ?which?
will allow us to furtherspecify which dog is chasing the cat; in order todo this we must use at least d = 3.
Our rewardfunction must determine this with, at a minimum,the actions corresponding to ?which?, ?ate?, and?treat?.
For these experiments, we use the exactreward function for STRUCT.559Despite this issue, STRUCT is capable of gen-erating these sentences.
Figure 3c shows the scoreof STRUCT?s generated output over time for twonested clauses.
Notice that, because the exact re-ward function is being used, the time to generateis longer in this experiment.
To the best of ourknowledge, CRISP is not able to generate sen-tences of this form due to an insufficiency in theway it handles TAGs, and consequently we presentour results without this baseline.Conjunctions.
Finally, we evaluate STRUCT?sability to generate sentences including conjunc-tions.
We introduce the conjunction ?and?, whichallows for the root nonterminal of a new sentence(?S?)
to be adjoined to any other sentence.
Wethen provide STRUCT with multiple goals.
Givensufficient depth for the search (d = 3 was suf-ficient for our experiments, as our reward signalis fine-grained), STRUCT will produce two sen-tences joined by the conjunction ?and?.
Again, wefollow prior work in our experiment design (Kollerand Petrick, 2011).As we can see in Figures 4a, 4b, and 4c,STRUCT successfully generates results for con-junctions of up to five sentences.
This is not a hardupper bound, but generation times begin to be im-practically large at that point.
Fortunately, humanlanguage tends toward shorter sentences than theseunwieldy (but technically grammatical) sentences.STRUCT increases in generation time both asthe number of sentences increases and as the num-ber of objects per sentences increases.
We com-pare our results to those presented in (Koller andPetrick, 2011) for CRISP with the FF Planner.They attempted to generate sentences with threeentities and failed to find a result within their 4GB memory limit.
As we can see, CRISP gener-ates a result slightly faster than STRUCT when weare working with a single entity, but works muchmuch slower for two entities and cannot generateresults for a third entity.
According to Koller?sfindings, this is because the search space grows bya factor of the universe size with the addition ofanother entity (Koller and Petrick, 2011).5 ConclusionWe have proposed STRUCT, a general-purposenatural language generation system which iscomparable to current state-of-the-art generators.STRUCT formalizes the generation problem as anMDP and applies a version of the UCT algorithm,a fast online MDP planner, to solve it.
Thus,STRUCT naturally handles probabilistic gram-mars.
We demonstrate empirically that STRUCTis anytime, comparable to existing generation-as-planning systems in certain NLG tasks, and is alsocapable of handling other, more complex taskssuch as negated communicative goals.Though STRUCT has many interesting prop-erties, many directions for exploration remain.Among other things, it would be desirable to in-tegrate STRUCT with discourse planning and di-alog systems.
Fortunately, reinforcement learn-ing has already been investigated in such con-texts (Lemon, 2011), indicating that an MDP-based generation procedure could be a natural fitin more complex generation systems.
This is a pri-mary direction for future work.
A second directionis that, due to the nature of the approach, STRUCTis highly amenable to parallelization.
None ofthe experiments reported here use parallelization,however, to be fair to CRISP.
We plan to paral-lelize STRUCT in future work, to take advantageof current multicore architectures.
This should ob-viously further reduce generation time.STRUCT is open source and available fromgithub.com upon request.AcknowledgmentsThis work was supported in part by NSF CNS-1035602.
SR was supported in part by CWRUaward OSA110264.
The authors are grateful toUmang Banugaria for help with the STRUCT im-plementation.ReferencesD.
Bauer and A. Koller.
2010.
Sentence generation asplanning with probabilistic LTAG.
Proceedings ofthe 10th International Workshop on Tree AdjoiningGrammar and Related Formalisms, New Haven, CT.A.L.
Blum and M.L.
Furst.
1997.
Fast planningthrough planning graph analysis.
Artificial intelli-gence, 90(1):281?300.R.
I. Brafman and M. Tennenholtz.
2003.
R-MAX-ageneral polynomial time algorithm for near-optimalreinforcement learning.
Journal of Machine Learn-ing Research, 3:213?231.M.
Fox and D. Long.
2003.
PDDL2.1: An extensionto PDDL for expressing temporal planning domains.Journal of Artificial Intelligence Research, 20:61?124.560Jorg Hoffmann and Bernhard Nebel.
2001.
TheFF planning system: fast plan generation throughheuristic search.
Journal of Artificial IntelligenceResearch, 14(1):253?302, May.Martin Kay.
1996.
Chart generation.
In Proceed-ings of the 34th annual meeting on Association forComputational Linguistics, ACL ?96, pages 200?204, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.M.
Kearns, Y. Mansour, and A.Y.
Ng.
1999.
Asparse sampling algorithm for near-optimal plan-ning in large Markov decision processes.
In Inter-national Joint Conference on Artificial Intelligence,volume 16, pages 1324?1331.
Lawrence ErlbaumAssociates Ltd.K.
Knight and V. Hatzivassiloglou.
1995.
Two-level,many-paths generation.
In Proceedings of the 33rdannual meeting on Association for ComputationalLinguistics, pages 252?260.
Association for Com-putational Linguistics.Levente Kocsis and Csaba Szepesvari.
2006.
Ban-dit based Monte-Carlo planning.
In Proceedings ofthe Seventeenth European Conference on MachineLearning, pages 282?293.
Springer.Alexander Koller and Ronald P. A. Petrick.
2011.
Ex-periences with planning for natural language gener-ation.
Computational Intelligence, 27(1):23?40.A.
Koller and M. Stone.
2007.
Sentence generation asa planning problem.
In Proceedings of the 45th An-nual Meeting of the Association for ComputationalLinguistics, volume 45, page 336.I.
Langkilde-Geary.
2002.
An empirical verification ofcoverage and correctness for a general-purpose sen-tence generator.
In Proceedings of the 12th Inter-national Natural Language Generation Workshop,pages 17?24.Oliver Lemon.
2011.
Learning what to say and how tosay it: joint optimization of spoken dialogue man-agement and natural language generation.
Com-puter Speech and Language, 25(2):210?221.W.
Lu, H.T.
Ng, and W.S.
Lee.
2009.
Natural languagegeneration with tree conditional random fields.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume1-Volume 1, pages 400?409.
Association for Com-putational Linguistics.M.L.
Puterman.
1994.
Markov decision processes:Discrete stochastic dynamic programming.
JohnWiley & Sons, Inc.Ehud Reiter and Robert Dale.
2000.
Building NaturalLanguage Generation Systems.
Cambridge Univer-sity Press, January.Stuart M. Shieber.
1988.
A uniform architecture forparsing and generation.
In Proceedings of the 12thconference on Computational linguistics - Volume2, COLING ?88, pages 614?619, Stroudsburg, PA,USA.
Association for Computational Linguistics.Matthew Stone, Christine Doran, Bonnie Webber, To-nia Bleam, and Martha Palmer.
2003.
Microplan-ning with communicative intentions: The SPUDsystem.
Computational Intelligence, 19(4):311?381.M.
White and J. Baldridge.
2003.
Adapting chart real-ization to CCG.
In Proceedings of the 9th EuropeanWorkshop on Natural Language Generation, pages119?126.561
