DISCOURSE-NEW DETECTORS FOR DEFINITE DESCRIPTIONRESOLUTION: A SURVEY AND A PRELIMINARY PROPOSALMassimo Poesio,?
Olga Uryupina,?
Renata Vieira,?Mijail Alexandrov-Kabadjov?
and Rodrigo Goulart?
?University of Essex, Computer Science and Cognitive Science (UK)?Universita?t des Saarlandes, Computerlinguistik (Germany)?Unisinos, Computac?a?o Aplicada (Brazil)AbstractVieira and Poesio (2000) proposed an algorithm fordefinite description (DD) resolution that incorpo-rates a number of heuristics for detecting discourse-new descriptions.
The inclusion of such detec-tors was motivated by the observation that morethan 50% of definite descriptions (DDs) in an av-erage corpus are discourse new (Poesio and Vieira,1998), but whereas the inclusion of detectors fornon-anaphoric pronouns in algorithms such as Lap-pin and Leass?
(1994) leads to clear improvementsin precision, the improvements in anaphoric DD res-olution (as opposed to classification) brought aboutby the detectors were rather small.
In fact, Ng andCardie (2002a) challenged the motivation for theinclusion of such detectors, reporting no improve-ments, or even worse performance.
We re-examinethe literature on the topic in detail, and propose a re-vised algorithm, taking advantage of the improveddiscourse-new detection techniques developed byUryupina (2003).1 IntroductionAlthough many theories of definiteness and manyanaphora resolution algorithms are based on the as-sumption that definite descriptions are anaphoric,in fact in most corpora at least half of definite de-scriptions are DISCOURSE-NEW (Prince, 1992), asshown by the following examples, both of which arethe first sentences of texts from the Penn Treebank.
(1) a. Toni Johnson pulls a tape measure acrossthe front of what was once a stately Victorianhome.b.
The Federal Communications Commissionallowed American Telephone & TelegraphCo.
to continue offering discount phoneservices for large-business customersand said it would soon re-examine itsregulation of the long-distance market.Vieira and Poesio (2000) proposed an algorithm fordefinite description resolution that incorporates anumber of heuristics for detecting discourse-new(henceforth: DN) descriptions.
But whereas theinclusion of detectors for non-anaphoric pronouns(e.g., It in It?s raining) in algorithms such as Lappinand Leass?
(1994) leads to clear improvements inprecision, the improvements in anaphoric DD reso-lution (as opposed to classification) brought aboutby the detectors were rather small.
In fact, Ngand Cardie (2002a) challenged the motivation forthe inclusion of such detectors, reporting no im-provements or even worse performance.
We re-examine the literature on the topic in detail, andpropose a revised algorithm, taking advantage ofthe improved DN detection techniques developed byUryupina (2003).2 Detecting Discourse-New DefiniteDescriptions2.1 Vieira and PoesioPoesio and Vieira (1998) carried out corpus stud-ies indicating that in corpora like the Wall StreetJournal portion of the Penn Treebank (Marcus etal., 1993), around 52% of DDs are discourse-new(Prince, 1992), and another 15% or so are bridg-ing references, for a total of about 66-67% first-mention.
These results led Vieira and Poesio topropose a definite description resolution algorithmincorporating independent heuristic strategies forrecognizing DN definite descriptions (Vieira, 1998;Vieira and Poesio, 2000).The heuristics proposed by Vieira and Poesioassumed a parsed input (the Penn Treebank) andaimed at identifying five categories of DDs licensedto occur as first mention on semantic or pragmaticgrounds on the basis of work on definiteness includ-ing Loebner?s account (1987):1.
So-called SEMANTICALLY FUNCTIONAL de-scriptions (Loebner, 1987).
This class includeddescriptions with modifiers like first or bestthat turned a possibly sortal predicate into afunction (as in the first person to cross the Pa-cific on a row boat); as well as descriptionswith predicates like fact or belief followed by athat-clause with the function of specifying thefact or belief under question.
Both types ofdefinites descriptions were recognized by con-sulting a hand-coded list of SPECIAL PREDI-CATES.2.
Descriptions serving as disguised PROPERNAMES, such as The Federal CommunicationsCommission or the Iran-Iraq war.
The heuris-tics for recognizing these definite descriptionswere primarily based on capitalization (of thehead or the modifiers).3.
PREDICATIVE descriptions, i.e., descriptionssemantically functioning as predicates ratherthan as referring.
These include descriptionsoccurring in appositive position (as in GlennCox, the president of Phillips Petroleum) andin certain copular constructions (as in the manmost likely to gain custody of all this is a careerpolitician named Dinkins).
The heuristics usedto recognize these cases examined the syntac-tic structure of the NP and the clause in whichit appeared.4.
Descriptions ESTABLISHED (i.e., turnedinto functions in context) by restric-tive modification, particularly by es-tablishing relative clauses (Loebner,1987) and prepositional phrases, as inThe hotel where we stayed last night waspretty good.
These heuristics, as well,examined the syntactic structure of the NP.5.
LARGER SITUATION definite descriptions(Hawkins, 1978), i.e., definite descriptions likethe sun, the pope or the long distance mar-ket which denote uniquely on the grounds ofshared knowledge about the situation (these areLoebner?s ?situational functions?).
Vieira andPoesio?s system had a small list of such defi-nites.These heuristics were included as tests both of a de-cision tree concerned only with the task of DN de-tection, and of decision trees determining the classi-fication of DDs as anaphoric, bridging or discoursenew.
In both cases, the DN detection tests were in-tertwined with attempts to identify an antecedent forsuch DDs.
Both hand-coded decision trees and auto-matically acquired ones (trained using ID3, (Quin-lan, 1986)) were used for the task of two-way clas-sification into discourse-new and anaphoric.
Vieiraand Poesio found only small differences in the orderof tests in the two decision trees, and small differ-ences in performance.
The hand-coded decision treeexecutes in the following order:1.
Try the DN heuristics with the highest accu-racy (recognition of some types of semanti-cally functional DDs using special predicates,and of potentially predicative DDs occurring inappositions);2.
Otherwise, attempt to resolve the DD as directanaphora;3.
Otherwise, attempt the remaining DN heuris-tics in the order: proper names, descrip-tions established by relatives and PPs, propername modification, predicative DDs occurringin copular constructions.If none of these tests succeeds, the algorithm can ei-ther leave the DD unclassified, or classify it as DN.The automatically learned decision tree attempts di-rect anaphora resolution first.
The overall results onthe 195 DDs on which the automatically trained de-cision tree was tested are shown in Table 1.
Thebaseline is the result achieved by classifying everyDD as discourse-new?with 99 discourse-new DDsout of 195, this means a precision of 50.8%.
Tworesults are shown for the hand-coded decision tree:in one version, the system doesn?t attempt to clas-sify all DDs; in the other, all unclassified DDs areclassified as discourse-new.Version of the System P R FBaseline 50.8 100 67.4Discourse-new detection only 69 72 70Hand-coded DT: partial 62 85 71.7Hand-coded DT: total 77 77 77ID3 75 75 75Table 1: Overall results by Vieira and Poesio2.2 Bean and RiloffBean and Riloff (1999) developed a system for iden-tifying discourse-new DDs1 that incorporates, in ad-dition to syntax-based heuristics aimed at recogniz-ing predicative and established DDs using postmod-ification heuristics similar to those used by Vieiraand Poesio, additional techniques for mining fromcorpora unfamiliar DDs including proper names,larger situation, and semantically functional.
Two1Bean and Riloff use the term EXISTENTIAL for these DDs.of the techniques proposed by Bean and Riloff areparticularly worth noticing.
The SENTENCE-ONE(S1) EXTRACTION heuristic identifies as discourse-new every DD found in the first sentence of a text.More general patterns can then be extracted fromthe DDs initially found by S1-extraction, using theEXISTENTIAL HEAD PATTERN method which, e.g.,would extract the N+ Government from theSalvadoran Government and the Guatemalan Gov-ernment.
The DEFINITE ONLY (DO) list containedNPs like the National Guard or the FBI with a highDEFINITE PROBABILITY, i.e., whose nominal com-plex has been encountered at least 5 times with thedefinite article, but never with the indefinite.
VAC-CINES were also developed that prevented the useof patterns identified by S1-extraction or DO-list el-ements when the definite probability of the definitewas too low.
Overall, the algorithm proposed byBean and Riloff is as follows:1.
If the head noun of the DD appeared earlier inthe text, classify as anaphoric.2.
Otherwise, if the DD occurs in the S1 list, clas-sify as discourse-new unless stopped by vac-cine.3.
Otherwise, classify the DD as DN if one of thefollowing tests applies:(a) it occurs in the DO list;(b) it matches one of the EHP patterns, and isnot stopped by vaccine;(c) it matches one of the syntactic heuristics4.
Otherwise, classify the DD as anaphoric.
(Note that as in the machine-learned version of theVieira and Poesio decision tree, a (simplified) directanaphora test is tried first, followed by DN detectorsin decreasing order of accuracy.
)Bean and Riloff trained their system on 1600 ar-ticles from MUC-4, and tested it on 50 texts.
TheS1 extraction methods produced 849 DDs; the DOlist contained 65 head nouns and 321 full NPs.
Theoverall results are shown in Table 2; the baselineare the results obtained when classifying all DDs asdiscourse-new.Although the overall precision is not better thanwhat obtained with the partial hand-coded decisiontree used by Vieira and Poesio, recall is substantiallyimproved.2.3 Ng and CardieNg and Cardie (2002a) directly investigate the ques-tion of whether employing a discourse-new pre-diction component improves the performance of aMethod R PBaseline 100 72.2Syntactic Heuristics 43 93.1Synt.
Heuristics + S1 66.3 84.3Synt.
Heuristics + EHP 60.7 87.3Synt.
Heuristics + DO 69.2 83.9Synt.
Heuristics + S1 + EHP + DO 81.7 82.2Synt.
Heuristics + S1 + EHP + DO + V 79.1 84.5Table 2: Discourse-new prediction results by Beanand Riloffcoreference resolution system (specifically, the sys-tem discussed in (Ng and Cardie, 2002b)).
Ng andCardie?s work differs from the work discussed so farin that their system attempts to deal with all types ofNPs, not just definite descriptions.The discourse-new detectors proposed by Ng andCardie are statistical classifiers taking as input 37features and trained using either C4.5 (Quinlan,1993) or RIPPER (Cohen, 1995).
The 37 featuresof a candidate anaphoric expression specify, in ad-dition to much of the information proposed in pre-vious work, a few new types of information aboutNPs.?
The four boolean so-called LEXICAL featuresare actually string-level features: for exam-ple, str_match is Y if a preceding NPstring-matches the anaphoric expression (ex-cept for the determiner), and head_match =Y if a preceding NP?s head string-matches theanaphoric expression?s.
embedded=Y if theanaphoric expression is a prenominal modifier.?
The second group of 11 (mostly boolean) fea-tures specifies the type of NP: e.g., pronounis Y if the anaphoric expression is a pronoun,else N.?
The third group of 7 features specifies syn-tactic properties of the anaphoric expression,including number, whether NPj is the first oftwo NPs in an appositive or predicative con-struction, whether NPj is pre- or post-modified,whether it contains a proper noun, and whetherit is modified by a superlative.?
The next group of 8 features are mostly novel,and capture information not used by previ-ous DN detectors about the exact compositionof definite descriptions: e.g., the_2n=Y ifthe anaphoric expression starts with deter-miner the followed by exactly two commonnouns, the_num_n=Y if the anaphoric ex-pression starts with determiner the followedby a cardinal and a common noun, andthe_sing_n=Y if the anaphoric expressionstarts with determiner the followed by a singu-lar NP not containing a proper noun.?
The next group of features consists of 4 fea-tures capturing a variety of ?semantic?
infor-mation, including whether a previous NP is an?alias?
of NPj , or whether NPj is the title of aperson (the president).?
Finally, the last three features capture informa-tion about the position in the text in which NPjoccurs: the header, the first sentence, or thefirst paragraph.Ng and Cardie?s discourse-new predictor wastrained and tested over the MUC-6 and MUC-7 coref-erence data sets, achieving accuracies of 86.1% and84%, respectively, against a baseline of 63.8% and73.2%, respectively.
Inspection of the top partsof the decision tree produced with the MUC-6 sug-gests that head_match is the most important fea-ture, followed by the features specifying NP type,the alias feature, and the features specifying thestructure of definite descriptions.Ng and Cardie discuss two architectures for theintegration of a DN detector in a coreference sys-tem.
In the first architecture, the DN detector isrun first, and the coreference resolution algorithmis run only if the DN detector classifies that NP asanaphoric.
In the second architecture, the systemfirst computes str_match and alias, and runsthe anaphoric resolver if any of them is Y; other-wise, it proceeds as in the first architecture.
Theresults obtained on the MUC-6 data with the base-line anaphoric resolver, the anaphoric resolver aug-mented by a DN detector as in the first architecture,and as in the second architecture (using C4.5), areshown in Table 3.
The results for all NPs, pronounsonly, proper names only, and common nouns onlyare shown.2As indicated in the Table, running the DN detectorfirst leads to worse results?this is because the detec-tor misclassifies a number of anaphoric NPs as non-anaphoric.
However, looking first for a same-headantecedent leads to a statistically significant im-provement over the results of the baseline anaphoricresolver.
This confirms the finding both of Vieiraand Poesio and of Bean and Riloff that the directanaphora should be called very early.2It?s not clear to us why the overall performance of the algo-rithm is much better than the performance on the three individ-ual types of anaphoric expressions considered?i.e., which otheranaphoric expressions are handled by the coreference resolver.MUC-6 MUC-7R P F R P FBaseline (no DN detector) 70.3 58.3 63.8 65.5 58.2 61.6Pronouns 17.9 66.3 28.2 10.2 62.1 17.6Proper names 29.9 84.2 44.1 27.0 77.7 40.0Common nouns 25.2 40.1 31.0 26.6 45.2 33.5DN detector runs first 57.4 71.6 63.7 47.0 77.1 58.4Pronouns 17.9 67.0 28.2 10.2 62.1 17.6Proper names 26.6 89.2 41.0 21.5 84.8 34.3Common nouns 15.4 56.2 24.2 13.8 77.5 23.4Same head runs first 63.4 68.3 65.8 59.7 69.3 64.2Pronouns 17.9 67.0 28.2 10.2 62.1 17.6Proper names 27.4 88.5 41.9 26.1 84.7 40.0Common nouns 20.5 53.1 29.6 21.7 59.0 31.7Table 3: Evaluation of the three anaphoric resolversdiscussed by Ng and Cardie.2.4 UryupinaUryupina (2003) trained two separate classifiers (us-ing RIPPER, (Cohen, 1995)): a DN detector and aUNIQUENESS DETECTOR, i.e., a classifier that de-termines whether an NP refers to a unique object.This is useful to identify proper names (like 1998,or the United States of America), semantic definites(like the chairman of Microsoft) and larger situationdefinite descriptions (like the pope).
Both classi-fiers use the same set of 32 features.
The features ofan NP encode, first, of all, string-level information:e.g., whether the NP contains capitalized words, dig-its, or special symbols.
A second group of featuresspecifies syntactic information: whether the NP ispostmodified, and whether it contains an apposition.Two types of appositions are distinguished, with andwithout commas.
CONTEXT features specify thedistance between the NP and the previous NP withthe same head, if any.
Finally, Uryupina?s systemcomputes four features specifying the NP?s definiteprobability.
Unlike the definite probability used byBean and Riloff, these features are computed fromthe Web, using Altavista.
From each NP, its head Hand entire NP without determiner Y are determined,and four ratios are then computed:#?the Y?#Y ,#?the Y?#?
?aY ??
,#?the H?#H ,#?the H?#??aH??
.The classifiers were tested on 20 texts from MUC-7 (a subset of the second data set used by Ng andCardie), parsed by Charniak?s parser.
19 texts wereused for training and for tuning RIPPER?s parame-ters, one for testing.
The results for the discoursenew detection task are shown in Table 4, separat-ing the results for all NPs and definite NPs only,and the results without definite probabilities and in-cluding them.
The results for uniqueness detectionare shown in Table 4, in which the results obtainedby prioritizing precision and recall are shown sepa-rately.Features P R FAll NPs String+Syn+Context 87.9 86.0 86.9All 88.5 84.3 86.3Def NPs String+Syn+Context 82.5 79.3 80.8All 84.8 82.3 83.5Table 4: Results of Uryupina?s discourse new clas-sifierFeatures P R FBest Prec String+Syn+Context 94.0 84.0 88.7All 95.0 83.5 88.9Best Rec String+Syn+Context 86.7 96.0 91.1All 87.2 97.0 91.8Table 5: Results of Uryupina?s uniqueness classifierThe first result to note is that both of Uryupina?sclassifiers work very well, particularly the unique-ness classifier.
These tables also show that the def-inite probability helps somewhat the discourse newdetector, but is especially useful for the uniquenessdetector, as one would expect on the basis of Loeb-ner?s discussion.2.5 SummaryQuite a lot of consensus on many of the factors play-ing a role in DN detection for DDs.
Most of the al-gorithms discussed above incorporate methods for:?
recognizing predicative DDs;?
recognizing discourse-new proper names;?
identifying functional DDs;?
recognizing DDs modified by establishing rel-atives (which may or may not be discourse-new).There is also consensus on the fact that DN detectioncannot be isolated from anaphoric resolution (wit-ness the Ng and Cardie results).One problem with some of the machine learningapproaches to coreference is that these systems donot achieve very good results on pronoun and defi-nite description resolution in comparison with spe-cialized algorithms: e.g., although Ng and Cardie?sbest version achieves F=65.8 on all anaphoric ex-pressions, it only achieves F=29.6 for definite de-scriptions (cfr.
Vieira and Poesio?s best result ofF=77), and F=28.2 for pronouns (as opposed to re-sults as high as F=80 obtained by the pronoun res-olution algorithms evaluated in (Tetreault, 2001)).Clearly these systems can only be properly com-pared by evaluating them all on the same corporaand the same data, and discussion such as (Mitkov,2000) suggest caution in interpreting some of theresults discussed in the literature as pre- and post-processing often plays a crucial role, but we feel thatevaluating DN detectors in conjunction with high-performing systems would give a better idea of theimprovements that one may hope to achieve.3 Do Discourse-New Detectors Help?Preliminary EvaluationsVieira and Poesio did not test their system with-out DN-detection, but Ng and Cardie?s results indi-cate that DN detection does improve results, if notdramatically, provided that the same_head test isrun first?although their DN detector does not appearto improve results for pronouns, the one categoryfor which detection of non-anaphoricity has beenshown to be essential (Lappin and Leass, 1994).
Inorder to evaluate how much improvement can weexpect by just improving the DN detector, we dida few preliminary evaluations both with a reimple-mentation of Vieira and Poesio?s algorithm whichdoes not include a discourse-new detector, runningover treebank text as the original algorithm, andwith a simple statistical coreference resolver at-tempting to resolve all anaphoric expressions andrunning over unparsed text, using Uryupina?s fea-tures for discourse-new detection, and over the samecorpus used by Ng and Cardie (MUC-7).3.1 How much does DN-detection help theVieira / Poesio algorithm?GUITAR (Poesio and Alexandrov-Kabadjov, 2004)is a general-purpose anaphoric resolver that in-cludes an implementation of the Vieira / Poesio al-gorithm for definite descriptions and of Mitkov?s al-gorithm for pronoun resolution (Mitkov, 1998).
It isimplemented in Java, takes its input in XML formatand returns as output its input augmented with theanaphoric relations it has discovered.
GUITAR hasbeen implemented in such a way as to be fully mod-ular, making it possible, for example, to replace theDD resolution method with alternative implementa-tions.
It includes a pre-processor incorporating achunker so that it can run over both hand-parsed andraw text.A version of GUITAR without the DN detectionaspects of the Vieira / Poesio algorithm was evalu-ated on the GNOME corpus (Poesio, 2000; Poesio etal., 2004), which contains 554 definite descriptions,of which 180 anaphoric, and 305 third-person pro-nouns, of which 217 anaphoric.
The results for defi-nite descriptions over hand-parsed text are shown inTable 6.Total Res Corr NM WM SM R P F180 182 121 43 16 45 67.2 66.5 66.8Table 6: Evaluation of the GUITAR system withoutDN detection over a hand-annotated treebankGUITAR without a DN recognizer takes 182 DDs(Res) as anaphoric, resolving 121 of them cor-rectly (Corr); of the 182 DDs it attempts to resolve,only 16 are incorrectly resolved (WM); almost threetimes that number (45) are Spurious Matches (SM),i.e., discourse-new DDs incorrectly interpreted asanaphoric.
(Res=Corr+WM+SM.)
The system can?tfind an antecedent for 43 of the 180 anaphoric DDs.When endowed with a perfect DN detector, GUI-TAR could achieve a precision P=88.3 which, as-suming recall stays the same (R=67.2) would meana F=76.3.Of course, these results are obtained assumingperfect parsing.
For a fairer comparison with theresults of Ng and Cardie, we report in Table 7 theresults for both pronouns and definite descriptionsobtained by running GUITAR off raw text.R P FPronouns 65.5 63.0 64.2DDs 56.7 56.1 56.4Table 7: Evaluation of the GUITAR system withoutDN detection off raw textNotice that although these results are not partic-ularly good, they are still better than the results re-ported by Ng and Cardie for pronouns and definiteNPs.3.2 How much might DN detection help asimple statistical coreference resolver?In order to have an even closer comparison withthe results of Ng and Cardie, we implemented asimple statistical coreference system, that, like Ngand Cardie?s system, would resolve all types ofanaphoric expressions, and would run over unparsedtext, but without DN detection.
We ran the systemover the MUC-7 data used by Ng and Cardie, andcompared the results with those obtained by usingperfect knowledge about discourse novelty.
The re-sults are shown in Table 8.R P FWithout DN detection 44.7 54.9 49.3With DN detection 41.4 80.0 54.6Table 8: Using an oracleThese results suggest that a DN detector couldlead to substantial improvements for coreferenceresolution in general: DN detection might improveprecision by more than 30%, which more thanmakes up for the slight deterioration in recall.
Ofcourse, this test alone doesn?t tell us how much im-provement DN detection would bring to a higher-performance anaphoric resolver.4 A New Set of Features forDiscourse-New DetectionNext, we developed a new set of features for dis-course new detection that takes into account thefindings of the work on DN detection discussed inthe previous sections.
This set of features will beinput to an anaphoric resolver for DDs working intwo steps.
For each DD,1.
The direct anaphora resolution algorithm from(Vieira and Poesio, 2000) is run, which at-tempts to find an head-matching antecedentwithin a given window and taking premodifica-tion into account.
The results of the algorithm(i.e., whether an antecedent was found) is usedas one of the input features of the classifier inthe next step.
In addition, a number of featuresof the DD that may help recognizing the classesof DDs discussed above are extracted from theinput.
Some of these features are computed ac-cessing the Web via the Google API.2.
A decision tree classifier is used to classify theDD as anaphoric (in which case the antecedentsidentified at the first step are also returned) ordiscourse-new.The features input to the classifier can be catego-rized as follows:Anaphora A single feature,direct-anaphora, specifying the distanceof the (same-head) antecedent from the DD, ifany (values: none, zero, one, more)Predicative NPs Two boolean features:?
apposition, if the DD occurs in appos-itive position;?
copular, if the DD occurs in post-verbalposition in a copular construction.Proper Names Three boolean features:?
c-head: whether the head is capitalized;?
c-premod: whether one of the premod-ifiers is capitalized;?
S1: whether the DD occurs in the first sen-tence of a Web page.Functionality The four definite probabilities usedby Uryupina (computed accessing the Web),plus a superlative feature specifying ifone of the premodifiers is a superlative, ex-tracted from the part of speech tags.Establishing relative A single feature, specifyingwhether NP is postmodified, and by a relativeclause or a prepositional phrase;Text Position Whether the DD occurs in the title,the first sentence, or the first paragraph.We are testing several classifiers in-cluded in the Weka 3.4 library(http://www.cs.waikato.ac.nz/?ml/)including an implementation of C4.5 and amulti-layer perceptron.5 EvaluationData We are using three corpora for the evalua-tion, including texts from different genres, in whichall anaphoric relations between (all types of) NPs aremarked.
The GNOME corpus includes pharmaceuti-cal leaflets and museum ?labels?
(i.e., descriptionsof museum objects and of the artists that realizedthem).
As said above, the corpus contains 554 def-inite descriptions.
In addition, we are using the 14texts from the Penn Treebank included in the cor-pus used by Vieira and Poesio.
We transferred thesetexts to XML format, and added anaphoric informa-tion for all types of NPs according to the GNOMEscheme.
Finally, we are testing the system on theMUC-7 data used by Ng and CardieMethods We will compare three versions of theDD resolution component:1.
The baseline algorithm without DN detectionincorporated in GUITAR described above (i.e.,only the direct anaphora resolution part of(Vieira and Poesio, 2000));2.
A complete implementation of the Vieira andPoesio algorithm, including also the DN detect-ing heuristics;3.
An algorithm using the statistical classifier dis-cussed above.Results Regrettably, the system is still beingtested.
We will report the results at the workshop.6 Discussion and ConclusionsDiscussions and conclusions will be based on thefinal results.AcknowledgmentsMijail Alexandrov-Kabadjov is supported by Cona-cyt.
Renata Vieira and Rodrigo Goulart are partiallysupported by CNPq.ReferencesD.
L. Bean and E. Riloff.
1999.
Corpus-basedidentification of non-anaphoric noun phrases.
InProc.
of the 37th ACL, pages 373?380, Universityof Maryland.
ACL.W.
Cohen.
1995.
Fast effective rule induction.
InProc.
of ICML.J.
A. Hawkins.
1978.
Definiteness and Indefinite-ness.
Croom Helm, London.S.
Lappin and H. J. Leass.
1994.
An algorithm forpronominal anaphora resolution.
ComputationalLinguistics, 20(4):535?562.S.
Loebner.
1987.
Definites.
Journal of Semantics,4:279?326.M.
P. Marcus, B. Santorini, and M. A.Marcinkiewicz.
1993.
Building a large an-notated corpus of english: the Penn Treebank.Computational Linguistics, 19(2):313?330.R.
Mitkov.
1998.
Robust pronoun resolution withlimited knowledge.
In Proc.
of the 18th COL-ING, pages 869?875, Montreal.R.
Mitkov.
2000.
Towards more comprehensiveevaluation in anaphora resolution.
In Proc.
ofthe 2nd International Conference on LanguageResources and Evaluation, pages 1309?1314,Athens, May.V.
Ng and C. Cardie.
2002a.
Identifying anaphoricand non-anaphoric noun phrases to improvecoreference resolution.
In Proc.
of 19th COL-ING.V.
Ng and C. Cardie.
2002b.
Improving machinelearning approaches to coreference resolution.
InProceedings of the 40th Meeting of the ACL.M.
Poesio and M. Alexandrov-Kabadjov.
2004.
Ageneral-purpose, off the shelf anaphoric resolver.In Proc.
of LREC, Lisbon, May.M.
Poesio and R. Vieira.
1998.
A corpus-based in-vestigation of definite description use.
Compu-tational Linguistics, 24(2):183?216, June.
Alsoavailable as Research Paper CCS-RP-71, Centrefor Cognitive Science, University of Edinburgh.M.
Poesio, R. Stevenson, B.
Di Eugenio, and J. M.Hitzeman.
2004.
Centering: A parametric theoryand its instantiations.
Computational Linguistics.To appear.M.
Poesio.
2000.
Annotating a corpus to developand evaluate discourse entity realization algo-rithms: issues and preliminary results.
In Proc.of the 2nd LREC, pages 211?218, Athens, May.E.
F. Prince.
1992.
The ZPG letter: subjects, defi-niteness, and information status.
In S. Thompsonand W. Mann, editors, Discourse description: di-verse analyses of a fund-raising text, pages 295?325.
John Benjamins.J.
R. Quinlan.
1986.
Induction of decision trees.Machine Learning, 1(1):81?106.J.
R. Quinlan.
1993.
C4.5: programs for machinelearning.
Morgan Kaufmann, San Mateo, CA.J.
R. Tetreault.
2001.
A corpus-based evaluationof centering and pronoun resolution.
Computa-tional Linguistics, 27(4):507?520.O.
Uryupina.
2003.
High-precision identificationof discourse-new and unique noun phrases.
InProc.
of the ACL 2003 Student Workshop, pages80?86.R.
Vieira and M. Poesio.
2000.
An empirically-based system for processing definite descriptions.Computational Linguistics, 26(4), December.R.
Vieira.
1998.
Definite Description Resolutionin Unrestricted Texts.
Ph.D. thesis, University ofEdinburgh, Centre for Cognitive Science, Febru-ary.
