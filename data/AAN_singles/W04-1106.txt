Character-Sense Association and Compounding Template Similarity:Automatic Semantic Classification of Chinese CompoundsChao-Jan ChenLATTICE, University Paris VII, Paris, Francechen_chaojan@yahoo.com.twAbstractThis paper presents a character-based model ofautomatic sense determination for Chinesecompounds.
The model adopts a senseapproximation approach using synonymouscompounds retrieved by measuring similarityof semantic template in compounding.
Thesimilarity measure is derived from anassociation network among characters andsenses, which is built from a formatted MRD.Adopting the taxonomy of CILIN, a system ofdeep semantic classification (at least to thesmall classes) for V-V compounds isimplemented and evaluated to test the model.The experiment reports a high precision rate(about 38% in outside test and 61% in insidetest) against the baseline one (about 18%).1.
IntroductionSense tagging is an important task in NLP.
It issupposed to provide semantic information useful tothe application tasks like IR and MT.
As generallyacknowledged, sense tagging is to assign a certainsense to a word in a certain context by using asemantic lexicon (Yarowsky, 1992, Wilks andStevenson, 1997).
In addition to word sensedisambiguation (WSD) for known words, sensedetermination for words unknown to the lexiconposes another challenge in sense tagging.
This isespecially the case in NLP of Chinese, a languagerich in compound words.
According to the data in(Chen and Lin, 2000), about 5.51% of unknownwords is encountered in their sense-tagging task ofChinese corpus.
Instead of proper names, thecross-linguistically most common type of unknownwords, compound words constitute the majority ofunknown words in Chinese text.
According to Chenand Chen (2000), the three most dominant types ofChinese unknown words are: compound nouns(about 51%), compound verbs (about 34%), andproper names (about 15%).
While the identificationand classification of proper names is an issue alreadywell discussed in Chinese NLP researches, the sensedetermination of unknown compounds remains asubject relatively less tackled.1.1 Shallow vs.
Deep ClassificationWhile word sense might be conceptually vague andcontroversial in linguistics and difficult to define(Manning and Sch?tze, 1999), sense tag is moreconcrete and can be defined according to the specificneed of the NLP tasks in question.
For example, in atask of semantic tagging or classification, sense tagcan be the semantic class from a thesaurus.
Orotherwise, in a task of machine translation, theequivalent foreign word from a bilingual dictionarycan be chosen as sense tag.
In this paper, it is thesense tag so defined that is meant by the term sense.The notion sense determination then refers to theassignment of sense tag to a word without usingcontextual information.
It is so called to bedistinguished from sense tagging, which requirescontextual information.
Under such a definition,semantic classification can be regarded as a case ofsense determination using the taxonomy of a certainthesaurus, in which a semantic class is a sense tag.According to Wilks and Stevenson (1997), atask assigning broad sense tags like HUMAN,ANIMATE in WordNet is referred to as semantictagging, different from sense tagging, which assignsmore particular sense tags.
In fact, a similardistinction can also be made for semanticclassification according to the target level of thesemantic classes in the taxonomy tree: a task aimingat the top-level classes can be called shallowsemantic classification (like Lua, 1997), while a taskaiming at the bottom-level classes can be called adeep semantic classification1 (like Chen and Chen,2000).
Since many top-level semantic classes, likeTIME, SPACE, QUALITY, ACTION, etc., are oftenalready reflected in the syntactic information, ashallow semantic classification does not actuallyprovide much semantic information independent ofsyntactic tagging.
It is therefore the deep semanticclassification that the paper is concerned about.1Take the word ?(?attack?)
for example.
According toCILIN (a thesaurus widely used in Chinese semanticclassification, see 3.1), it can be classified to shallow-levels asmajor class H (ACTIVITY) or as medium class Hb (MILITARYACTIVITY).
It can also be classified to deep-levels as smallclass Hb03 (specific military operations: ATTACK, RESIST,and COUNTERATTACK) or as subclass Hb031 (ATTACK).1.2 Previous ResearchesIn the previous researches of automatic semanticclassification of Chinese compounds, compoundsare generally presupposed to be endocentric,composed of a head and a modifier.
Determining theclass of the head is therefore determining the class ofthe target compound (Lua, 1997, Chen and Chen,2000).
This head-determination approach has twoadvantages: (1) it is simple and easy to implement (2)it works effectively for compound nouns, thedominant type of compounds, since most of them arehead-final endocentric words.2 However, there existconsiderable exocentric compounds, for which sucha simple algorithm does not work successfully.
It isespecially the case for compound verbs like V-Vs3.For example, q is a V-V compound meaning ?tokill by beating?.
Obviously, neither the sense of q(?beat?)
nor that of (?die?)
is appropriate to beassigned to the compound q as the sense of B(?car?)
can be assigned to ?B (?tram?, literally?electricity-car?)
as a general meaning.A second problem encountered in compoundsemantic classification is that there are considerableout-of-coverage morphemes, which are not listed inthe lexicon, as remarked in (Chen and Chen, 2000).Moreover, even a morpheme is listed, the givensenses are not necessarily appropriate to the task.For example, in the search of compoundmorphological rules in (Chen and Chen, 1998), someappropriate senses of morphemes have to be addedmanually to facilitate the task.
Obviously this causesa great difficulty to an automatic task, especially tothe example-based models which rely on thesimilarity measurement of the modifier morphemesto disambiguate the head senses (Chen and Chen,1998, 2000).
An alternative approach is thus neededto solve the problems of exocentric compounds andlexicon incompleteness.Therefore in this paper I will present a nonhead-oriented model of Chinese compound sensedetermination, in which lexicon incompleteness willbe overcome by exploring the association between2Though a compound noun and its head are strictly speaking ina hyponym relation, they are usually categorized as members ofthe same class.
For example, in CILIN,B(?car?, ?vehicle?)
andmost of the compounds X-B are put under the same class Bo21(VEHICLES), where X can be a morpheme designating theenergy source (like horse, cow, electricity) or the load content(like passenger, merchandise).3An introspection on the two-character verbs in CILIN showsthat about 48% of them are semantically exocentric, whichmeans the semantic class of a compound X-Y in CILIN is equalneither to that of X nor to that of Y.
As to the endocentric V1-V2,V1 and V2 are about equally likely to be the head of a compoundverb according to the introspection.characters and senses in a MRD.
The sense of anunknown compound can be approximated byretrieved synonyms.
Its sense tag can be assignedaccording to a certain MRD.
This model facilitatesan automatic system of deep semantic classificationfor unknown compounds.
In this paper, a system forV-V compounds is implemented and evaluated.
Themodel can however be extended to handle generalChinese compounds, like V-N and N-N, as well.2.
Compound Sense Determination2.1 Compounding Semantic TemplatesMost of the Chinese compounds are composed oftwo constituents, which can be bound morphemes ofone character or free words of one or morecharacters.
The two-character compound is a mostrepresentative type because its components can bebound morphemes as well as free words.
Thehandling of two-character compounds becomestherefore the focus in this paper.As in general Chinese compounding, atwo-character compound is usually semanticallycompositional, with each character conveying acertain sense.
The principle of semantic compositionimplies that under each compound lies a semanticpattern, which can be represented as the combinationof the sense tags of the two component characters.The combination pattern is referred to ascompounding semantic template (denoted byS-template) in this paper; compounds of the sameS-template are then referred to as template-similar(denoted by T-similar).
Since T-similar compoundsare alike in their semantic compositions, they aresupposed to possess roughly the same meaning andto be put under a considerably fine-grained semanticclass.
Take the compound verbq~ for example.This compound suggests the existence of aS-template of HIT-BROKEN, as the senses of thetwo component characters q and ~  arerespectively ?hit?
and ?broken?.
The S-templateHIT-BROKEN refers to a complex event schema [tomake something BROKEN by HITting].
ThisS-template can also be found in many othercompounds with a similar meaning:q?,?,~,??etc.
Obviously such T-similar words canmake a good set of examples for the example-basedapproach to the sense determination, if an effectivemeasure of word similarity is available for theirretrieval.2.2 Compound SimilarityAs a critical technique, word similarity is generallyused in the example-based models of semanticclassification.
The measure of word similarity can bedivided into two major approaches: taxonomy-basedlexical approach (Resnik 1995, Lin 1998a, Chen andChen 1998) and context-based syntactic approach(Lin 1998b,Chen and You 2002), which is not theconcern in this context-free model.
However, twoproblems arise here for the taxonomy-based lexicalapproach.
First, such similarity measures risk thefailure to capture the similarity among somesemantically highly related words, if they happen tobe put under classes distant from each otheraccording to a specific ontology 4 .
Second, asmentioned, the appropriate senses of somecharacters just cannot be found in the thesaurus.
Onemajor reason why dictionaries do not include certaincharacter senses is that many of such characters areused in contemporary Chinese only as boundmorphemes not as free words, when the senses inquestion are involved.
However, such senses couldbe kept in the compounds in the lexicon, so theymight be covert but not inextricable.To remedy the effects of such lexiconincompleteness, I propose an approach to retrievethe latent senses 5  of characters and the latentsynonymy among characters by exploringassociation among characters and senses.
The idea isthat if a character C appears in a compound W, thenaccording to semantic composition, the sense of Cmust somehow contributes to S, the sense of W.Therefore the association strength between characterC and sense S in a MRD is supposed to reflect thepotentiality of S to be a sense of C. By transitivity,such association between characters and sensesallows to capture association among characters.
Anew way to measure word similarity of twocompounds can be thus derived based on theassociation strength of the corresponding componentcharacters.
This measure actually reflects theS-template similarity between two compounds andcan be used to retrieve for a compound its T-similarwords, which are potentially synonymous.4Take an example in CILIN (a Chinese thesaurus, see 3.1).KILL(), BUTCHER(??
), and EXCUTE(?) are threeconcepts all meaning ?cause to die?.
However, the wordsexpressing these three ideas are respectively put under smallclasses Hn05, Hd28, and Hm10, respectively under mediumclass Hn: Criminal Activities(u@ ), class Hd: EconomicalProduction Activities(?Y), and class Hm: Security and JusticeActivities(??-P[).
We wonder if any measurement based onthat hierarchy can capture the similarity among the wordssituated in these three small classes in CILIN, for those wordsshare only a common major class H, denoting vaguely Activities,which includes 296 small classes and 836 subclasses.5Here the term latent is used only to mean ?hidden, potential,and waiting to be discovered?.
It has nothing to do with the LSItechniques, though they both evoke the same meaning of latent.2.3 Synonyms and Sense ApproximationThe acquisition of synonyms plays an important rolein the sense determination of a word.
When anative-speaker is capable of giving synonyms to aword, he is considered to understand the meaning ofthat word.
In fact, such a way of sense capturing isalso reflected in how the senses of words can beexplained in many dictionaries6.
Moreover, as someresearches propose, synonyms can be used toconstruct the semantic space for a given word (Plouxand Victorri, 1998, Ploux and Ji, 2003).
In such asemantic space, each synonym with different nuanceoccupies a certain area.
As visually reflected in thisapproach, retrieving a proper set of its synonymsmeans the ability to well capture the senses of aword.
In fact, my model of automatic sensedetermination for a compound is exactly built uponthe retrieval of its near synonyms, the T-similarcompounds as previously described.2.4 Model RepresentationWith a S-template similarity measure, one canretrieve, for a given compound, its potentialsynonymous T-similar compounds.
Then the sensetags of the retrieved compounds can be used todetermine the sense tag of the target compound.
Themodel of compound sense determination can be thuscomposed of two modules, as illustrated in Fig.1.W(X-Y){dico1,dico2,?
}Module-A       < T-similar Word Retriever >{ SW-set(X-Y) }Filter-CdicoxModule-B       < S-tag Determiner >Fig.1 Model of CompoundSense Determination{S-tag(X-Y)}Module-A (<T-similar Word Retriever>) is to findthe potential synonyms ({SW-set(X-Y)}) of a givencompound (X-Y) by using association informationprovided from dicos {dico1, dico2,?}.
Module-B(<S-tag Determiner>) is to obtain the most likely6Especially in Chinese dictionaries, it is often the case thatseveral synonymous words are given as explanation to themeaning of a word, especially when it is a compound verb.sense tags ({S-tag(X-Y)}) according to dicox for thetarget word by using the output of Module-A.
Thecomponent filter-C is optional, which passes onlythe T-similar words with the same syntactic categoryas the target compound, if it is already known.
Infact, a system of semantic classification can be socreated by choosing dico2 as dicox and the S-tag isthen the semantic class in CILIN (as in section 4).3 Character-Sense Association NetworkBefore exploring the critical measurement ofassociation among characters and senses needed inthe model, I have to briefly present the lexicalsources in use and to define the idealized dictionaryformat adopted in this task.3.1 Lexical SourcesThe lexical sources used to implement my systeminclude:(1) Sinica Corpus: a balanced Chinese corpuswith 5 million words segmented and tagged withsyntactic categories.
(Huang et al, 1995)(2) HowNet: an on-line Chinese-English bilinguallexical resource created by Dong.
It is used inthis paper as a Chinese-English dictionaryregistering about 51,600 Chinese words, eachassigned with its equivalent English words andits POS.
(http://www.keenage.com/)(3) CILIN: a Chinese thesaurus collecting about53,200 words.
CILIN classifies its lexicon in afour-level hierarchy according to differentsemantic granularities: 12 major classes (level-1),95 medium classes (level-2), 1428 small classes(level-3), and 3924 subclasses (level-4).
Thewords in the same small class can be regarded assemantically similar, but only the words in thesame subclasses can be surely regarded assynonyms7.
(Mei et al, 1984)3.2 Idealized Dictionary Format (dico)The idealized dictionary, denoted as dico, is actuallya formatted MRD defined as follows:A dico is a set of <W-S> correspondence pairs,where W is a word, and S is a sense tag.
(1)7Take two verbs?
(?to buy?)
and [(?to sell?)
as examples todemonstrate the taxonomy of CILIN.
Both of the two verbs aregrouped in the small class He03 (commercial trade), which isunder the major class H (activities) and the medium class He(economic activities).
However, the two antonyms are put undertwo different subclasses, respectively He031 (buying) andHe032 (selling).In the system implementation in this paper, twodicos are converted respectively from HowNet andCILIN for the calculation of the associationmeasures among characters and sense tags withdifferent types of sense tags adopted.
For HowNet,the English equivalent words are used as sense tagsto form dico1.
For CILIN, the subclasses are used assense tags to form dico2.3.3 Character-Sense AssociationAll the semantic information provided by a dico, asdefined in (1), can be in fact represented as anetwork with links between two domains: W domain(words) and S domain (sense tags).
In such aviewpoint, polysemy is then a one-to-many mappingfrom W to S, while synonymy a one-to-manymapping from S to W. If we further link acomponent character C of a word W to one of the Slinked to W, such a C-S link might intuitively reflecta potential sense S for the character C, probably alatent sense of C, as previously described in section2.2.
We can use a statistical association measure,like MI or ?2, to extract such C-S links.
Thestatistically extracted C-S association can then leadto the finding of latent senses for a character.
Therevelation of a latent character-sense association willfurther lead to the retrieval of new synonymyrelation between characters.
Symmetrically, therevelation of a latent character-sense association willalso lead to the retrieval of the potential polysemy ofa character.
As illustrated in the Z-diagram below,supposed that C1 is already associated to S1 and C2to S2, the retrieval of latent sense S1 to C2 will,meanwhile, lead to the finding of an associationbetween C1 and C2 (latent synonymy), and anassociation between S1 and S2 (latent polysemy).C1          S1latent synonymy      latent sense       latent polysemyC2           S2Fig.
2  Z-diagram of C-S linksThe directed association measure from a character toa sense, denoted as CS-asso(Ci,Sj), can be defined asfollows:?
(Ci, Sj) = [ freq(Ci,Sj)E/ ( freq(Ci)+freq(Sj) ) ] ^ 0.5CS-asso (Ci, Sj) =  ?
(Ci,Sj) / Max k { ?
(Ci,Sk) }      (2)where freq(Ci,Sj) is the number of the words in theMRD that contain character Ci and is tagged withsense Sj, while freq(Ci) is the number of wordscontaining character Ci, and freq(Sj) the number ofwords tagged with sense Sj.8Likewise, the directedassociation measure from a sense to a character,denoted as SC-asso(Si,Cj), can be defined asfollows9:?
(Si,Cj)= [ freq(Si,Cj)E/( freq(Si)+freq(Cj) ) ] ^0.5SC-asso (Si,Cj) =  ?
(Si,Cj) / Max k { ?
(Si , Ck) },     (3)Consequently, by link of a Ci-Sj-Ck chain (a latentsynonymy), the directed association measure for acharacter Ci to another character Ck is defined as acombination of two types of directed associationmeasures, the maximal association measureCC-asso1(Ci ,Ck) and the over-all associationmeasure CC-asso2(Ci ,Ck), with respective weightsof 1-?
and ?
(the value ?
is by default set at 0.5).asso-chain(Ci,Sj,Ck) = ?asso (Ci,Sj) * asso (Sj,Ck) ) ^ 0.5f1 (Ci,Ck) = Max j {asso-chain (Ci,Sj,Ck) }CC-asso1(Ci,Ck) = f1 (Ci,Ck) / Max m { f1 (Ci,Cm) }f2 (Ci,Ck) = ?j asso-chain(Ci,Sj,Ck)CC-asso2(Ci,Ck) = f2 (Ci,Ck) / Max m { f2 (Ci,Cm) }CC-asso = (1-?)
* CC-asso1 + ?
* CC-asso2           (4)3.4 S-Template Similarity MeasureSupposed that Wi(Ci1-Ci2) and Wj(Cj1-Cj2) are bothtwo-character compounds, a measure of word-worddirected association (denoted as WW-asso) from Wito Wj can be defined based on the CC-asso betweentheir corresponding component characters:?
(Wi,Wj) = { CC-asso(Ci1,Cj1) * CC-asso(Ci2,Cj2) } ^ 0.5WW-asso(Wi,Wj) = ?
(Wi,Wj) / Max k { ?
(Wi,Wk) }       (5)Since the corresponding characters of two T-similarcompounds must share the same sense tags and thushave strong CC-asso, the measure WW-asso(Wi,Wj)indicates, in fact, how T-similar for a compound Wjto a target Wi, compared with other compounds.WW-asso(Wi,Wj) is therefore taken as the measureof S-template similarity (denoted as T-similarity).Applying the S-template similarity measure in(5), now the T-similar Word Retriever (<TWR>) can8The formula ?
in (2) is actually a simplified approximation tothe ?2 -test measure by supposing that freq(C,S) is much smallerthan freq(C) and freq(S).
In fact, MI (mutual information) isanother association measure frequently used in Chinese NLP.For example, it is successfully used for the character-POSassociation measure in the task of syntactical classification forChinese unknown words (Chen et al, 1997).
However, aheuristic evaluation on some randomly picked examples showsthat it seems to be outperformed by the ?2 measure in this task.9It must be noted that the measures of directed association (2)and (3) are asymmetric in that they give different values for theassociation from Ci to Sj and for the one from Sj to Ci becausetheir normalization factors are not the same.
That is why thenotion directed is added here to point out the asymmetry.give for a compound X-Y the list of its mostT-similar compounds from the corpus and theirT-similarity scores.
As to the <S-tag Determiner>, itreceives as input the output T-similar words from<TWR>.
Among the input T-similar words, the onesknown to dicox, are picked out and their sense tags(S-tag) with the T-similarity scores (WW-asso) areused, as in the formula (6), to calculate thelikelihood score ?
for a compound V-Vi to possess acertain S-tagj.
Therefore a set of ranked possiblesemantic classes for the compound X-Y can be given({S-tag(X-Y)}).?
(V-Vi, S-tagj) = ?
j WW-asso (V-Vi, SWk)            (6),where SWk is a known word in dicoxand S-tagj is one of the S-tages to SWk?(V-Vi,S-tagj)=?
(V-Vi,S-tagj)/Max n { ?
(V-Vi, S-tagn) }4.
System Implementation4.1 Classification for V-V CompoundsBased on the model proposed, a system of semanticclassification can be implemented for two-characterV-V compound verbs by using dico2 as the dicox inthe Module-B (the S-tag now is the semantic class inCILIN).
The V-V compounds are chosen as subjectsin this system because the choice can bestdistinguish the present model from the previoushead-orientated approaches.
As the involvement ofonly V characters make training data homogeneous,it simplifies the association network and reduceslargely the computational complexity.
However, thepartial system for V-V compounds can be easilyextended to handle V-N compounds and N-Ncompounds as well when the character-senseassociation network for N characters is established.Since only the V characters are involved, asubset of <W-S> pairs of dico1 (HowNet) and dico2(CILIN) is extracted to calculate the associationmeasures and then the T-similarity measure.
Thesubset contains only the <W-S> pairs whose W areone-character or two-character verbs.
In CILIN theverbs are put under the major classes from E to J,designating the concepts of attributes (E), actions (F),mental activities (G), activities (H), physical states(I), and relations (J).
By choosing only the words inthe above 6 major classes, the nominal senses ofcharacters (A: human, B: concrete object, C: timeand space, D: abstract object) are supposed to beexcluded.
Besides, the occurrence frequency of acharacter in a mono-character word will be doubleweighted, since in this case the word sense is surelycontributed by that character alone.Let us take the V-V compound ?> (?to catchby hunting?, literally ?hunt-catch?)
for example tosee how the model operates.
Based on theassociation network created from HowNet, thecharacters associated to ?
and > are listed inList 1 and List 2 (only the 10 top ranked are listedhere), the 20 top ranked T-similar compounds of ?> are listed in List 3 with their similarity scores,syntactic categories and semantic classes, if they areknown in CILIN.
Among the 20 T-similarcompounds retrieved, 10 of them (the grayed ones)can be found in CILIN; 9 of them (the framed ones)can be considered as good synonyms of ?>, whileother 7 (the starred ones) considered semanticallyreally close.
In this particular example, 80% (16/20)of the T-similar compounds can be considered as atleast near synonymous, while 50%(8/16) of themcan be actually found in CILIN to serve theautomatic semantic classification.????????
?
????????
?
??
?????????
?
Z???????????????
?
????????
?
??
S???????
????????
?????????
?
????????
?
??
????????
?
????????
?Z???????
?
????????
?
??
??
???????
????????
?????????
?
????????
?
??
????????
????????
?????????
List 1                  List 2???????????????
 ???
??????????????? ??????????????????
 ????
?S??????????
??S??????????
?
?
?S??????????????????Z???????????
?
?
????????????
?????????
?????? ????
????????????????????????????? ????
??????????????????????????????
?
?
??????????????????????????
?
Z?????????????? ?????)??????????
?
?
?S????????????????
???????????????? ????
?S 0.7790 VCList 3Applying the formula for the likelihood score ofsemantic class determination in (6), we have the 4top ranked semantic classes for ?> predicted bythe system as follows:(1) Hm051 (Z?
?arrest?
)(2) Je121 (7S ?acquire?
)(3) Hb121  (??
?attack and occupy?
)(4) Hb141 (??
?capture as war prisoner?
)In this case, the standard answer of class Hm051 forthe compound ?> is ranked as the first candidate,while the second ranked candidate class Je121(?acquire?)
is also reasonable, which can beconsidered rather correct in a certain way by humanjudgment.
In fact, according to the native speaker?sinstinct, the 4th ranked candidate class Hb141(?capture?)
is also quite suitable to the meaning ofthe verb ?>, though that is not what it is classifiedin CILIN.
However, to avoid the subjectiveinterference of human judgment and particularly tomake the evaluation task automatic, the evaluation inthe following sections will be made by machine onlyaccording to the standard classification in CILIN.4.2 Experiment ResultsFor evaluating the performance of the system, 500V-V compounds are randomly picked out fromCILIN to form the test set.
Two modes of evaluationexperiments are carried out: both modes adopt dico2(CILIN) in Module-B (dicox=dioc2) to determinesemantic classes, while the inside-test mode usesdico2 (CILIN) in Module-A and the outside-testmode uses dico1 (HowNet) in Module-A, to obtainassociation network and retrieve the T-similar words.To make the test compounds unknown to the model,the semantic classes of the test compounds have tobe invisible to CILIN, while the invisibility shouldnot undermine the training of the associationnetwork in Module-A.
The effect is done bydynamically withdrawing a word from dico2 inModule-B each time when it is in test.
Two ways ofevaluation can be made: by verifying the answer tothe level of small class (level-3) and to the level ofsubclasses (level-4).
The accuracy is calculated byverifying if the correct answer or one of the correctanswers (if V-V is polysemous) according to CILINcan be found in the first n ranked semantic classespredicted by the system.
The performance of arandom head-picking model is offered as thebaseline.
In this baseline model, one of the semanticclasses of X and Y is randomly chosen as thesemantic class of the compound X-Y.Level-3(Small Class)     Level-4(Subclass )n outside inside Baseline outside inside Baseline1 39.80% 61.60% 18.83% 36.60% 60.40% 17.34%2 56.80% 76.00% 31.40% 52.80% 74.40% 29.12%3 64.40% 83.80% 40.21% 59.80% 80.80% 37.54%Table 1.
Performance for 500 V-V compoundsThe results in Table 1 show that the system achievesa precision rate of 60.40% for inside test and 36.60%for outside test in level-4 classification against thebaseline one of 17.34%.
Not to our surprise, theperformance of classification to level-3, a slightlyshallower level, is slightly better: 61.60% for insidetest and 39.80% for outside test.
Table 1 also showsthat the system can achieve a correction rate of59.8% (outside) and 80.80% (inside) for includingthe correct answer in the first 3 ranked candidateclasses in level-4, 64.40% (outside) and 83.80%(inside) in level-3, all much better than the baselineones, 37.54% and 40.21%.4.3 A Pseudo-WSD ProblemIf the correct semantic class can be found in alimited number of candidates, context informationcan be used to help determine which candidate ismore likely to be the proper one, just as a WSD taskdoes.
Take again the example of the compound ?> in section 4.1, which the system classifies mostlikely as: ?arrest?, ?acquire?
and ?attack-occupy?.Obviously the verbs in the three classes should takedifferent stereotypes of objects: respectively person,thing, and place.
Therefore it is not difficult todetermine the correct semantic class of the verb inquestion by using context information, in this casethe type of the object.
Through this example, we cansee that the high inclusion rate of the correct answerin the top ranked classes has in fact a greatsignificance: the ranking of the top candidates can befurther adjusted and eventually ameliorated bycontext information, and thus the task of classdetermination can become a pseudo-WSD problem,in which domain various techniques are wellavailable (Manning and Schutze, 1999).
Theperformance of the present non-contextual system ofautomatic semantic classification is then expected tobe improvable with the eventual help of a goodcontext-sensitive WSD system, though it is out ofthe scope in this paper.
Therefore the correctinclusion rate of top n ranked classes is also theconcern of this paper.4.4 Endocentric vs. Exocentric CompoundsTable 2 shows the performance of the system on theendocentric compounds (with heads) and on theexocentric ones (without heads) in level-3.
Amongthe 500 V-V compounds, the endocentric V-Vcompounds have much higher precision rates thanthe exocentric ones.
But even for the exocentriccompounds, the precision rate of the system is49.28% in inside test and 27.05% in outside test,while the correct inclusion rate of top 3 rankedclasses achieves 74.64% in inside test and 51.69% inoutside test.
Such a performance is in fact ratherencouraging since it shows that this model hasovercome the inherent difficulty met by ahead-oriented approach.Outside insiden +Head -Head +Head -Head1 48.81% 27.05% 70.69% 49.28%2 68.26% 40.58% 84.83% 64.11%3 73.38% 51.69% 90.69% 74.64%Table 2.
Level-3 performance for [+/- Head] V-V4.5 Syntactic Category FilterTo test the function of the Filter-C in the model, twosets of 500 V-V compounds are randomly picked outfrom verbs of category VC corpus, and from verbsof category VA in Sinica Corpus.10.
Table 3 and 4show the performance of the system on the twokinds of verbs when evaluated to level-3.
The resultsshow that the system using the syntactic categoryfilter (+SCF) performs slightly better than thatwithout using the filter (-SCF) only in the precisionof first ranked class in the outside test.
Beside that,the use of the syntactic category filter generallyundermines the performance of the system.
Such aresult might be explained by the fact thatsynonymous words in CILIN are not necessarily ofthe same syntactic category; it also suggests that forthe entire model recall is perhaps more importantthan precision in Module-A.outside Insiden +SCF -SCF +SCF -SCFBaseline1 49.60% 47.60% 64.40% 67.20% 22.90%2 63.20% 64.00% 76.40% 78.40% 39.74%3 70.00% 73.60% 84.40% 84.80% 50.27%Table 3.
Level-3 performance for V-V of category VCoutside insiden +SCF -SCF +SCF -SCFBaseline1 41.00% 38.60% 52.00% 58.60% 15.90%2 52.20% 49.60% 67.40% 73.80% 26.84%3 55.80% 55.00% 73.00% 80.20% 34.61%Table 4.
Level-3 performance for V-V of category VA4.6 Classification ErrorsAn examination of the bad performing casessuggests that there are three major sources oferroneous classification in the experiments.
(1)Some test compounds are just idiomatic or nonsemantic compositional.
Naturally, it is highlydifficult, if not impossible, to correctly predict theirsemantic classes.
(2) Some compounds are fromunproductive S-templates, which causes the examplesparseness of the T-similar compounds.
The scarcityof examples will easily lead to a poor determinationresult caused by a low noise tolerance of occasionalbad examples.
(3) Some classifications predicted bythe system are reasonable to native speakers, buthappen not to be the case in CILIN as the standardanswers.5.
Conclusions and Further RemarksIn this paper I have proposed a character-basedmodel of sense determination for Chinese10VC (transitive action/activity) and VA (intransitiveaction/activity) are the two most dominant types oftwo-character verbs in the corpus, occupying respectively 44%and 27% around.
Here the statistics does not include the VH(intransitive state) verbs, because they generally correspond tothe adjectives in English, and in deed they are categorized asadjective in HowNet.compounds using compounding template similarity.Based on this model, a system of deep semanticclassification for V-V compounds is implemented,which classifies compounds according to thetaxonomy of CILIN to its deep-level (level-3 andlevel-4) classes.
The evaluation experiment reports afairly satisfactory precision rate of the first rankedpredicted semantic class (about 38% in outside testand 61% in inside test) against the baseline one(about 18%).
The results also show a high inclusionrate of correct answer in the top3 ranked classes,which suggests that in the future the presentnon-contextual system can cooperate with a WSDmodule using context information.
Though themodel is only tested on a partial system for V-Vcompounds, it can be extended to work for generalcompounds, like V-N and N-N, with the associationnetwork further established for N characters.The model proposed in this paper has thefollowing advantages: (1) It proposes a similaritymeasure of compounding template to retrievepotential synonyms for sense approximation, whichavoids the inherent difficulty of head determinationin a head-oriented approach and is thus capable ofhandling exocentric compounds.
(2) It establishes anetwork of character-sense association, which allowsthe discovery of latent senses of characters, latentsynonymy, and latent polysemy, thus remedying theincompleteness effect of the MRD in use.
(3) It cancarry out deep semantic classification, not justshallow classification assigning general and vaguecategories.
(4) It requires only a simple format ofidealized dictionary, which facilitates the conversionfrom a general MRD and allows an easyenhancement of the system by adding a new MRD.However, as can be remarked in the discussionof classification errors, the performance of the modelrelies much on the productivity of compoundingsemantic templates of the target compounds.
Tocorrectly predict the semantic class of a compoundwith an unproductive semantic template is no doubtvery difficult due to a sparse existence of theT-similar compounds.
How to remedy such an effectis thus a challenging task in the future.
In addition,how to generalize the present character-based modelto make it applicable to compounds withmulti-character component morphemes will beanother essential task to undertake.
Besides, a task ofautomatic lexical translation for Chinese unknowncompounds will also be carried out in the future.
Thetask can be executed under the very same structureof the present model, since the only difference willbe the change of working dicox (from dico2 to dico1)in the Module-B.
A pilot experiment has alreadyshown encouraging results.ReferencesChao-Jan Chen, Ming-hong Bai, and Keh-Jiann Chen.1997.
Category Guessing for Chinese Unknown Words.In Proceedings of the Natural Language ProcessingPacific Rim Symposium 1997, pages 35-40.Hsin-Hsi Chen and Chi-Ching Lin.
2000.
Sense-taggingChinese corpus.
In Proceedings of ACL-2000 workshopon Chinese Language Processing, pages 7-14.Keh-Jiann Chen and Chao-Jan Chen.
1998.
A CorpusBased Study on Computational Morphology forMandarin Chinese.
In Quantitative and ComputationalStudies on the Chinese Language, pages 283-306.Keh-Jiann Chen and Chao-Jan Chen.
2000.
AutomaticSemantic Classification for Chinese UnknownCompound Nouns, In Proceedings of Coling-2000,pages 173-179.Keh-Jiann Chen and Jia-Ming You.
2002.
A Study onWord Similarity Using Context Vector Models,Computational Linguistics & Chinese LanguageProcessing, 8(2):37-58.Chu-Ren Huang et al 1995.
The Introduction of SinicaCorpus.
In Proceedings of ROCLING VIII, pages81-99.Dekang Lin.
1998a.
An Information-Theoretic Definitionof Similarity, In Proceedings of InternationalConference on Machine Learning, pages 296-304Dekang Lin.
1998b.
Automatic retrieval and clustering ofsimilar words.
In Proceedings of COLING/ACL-98,pages 768?774.Kim-Teng Lua.
1997.
Prediction of Meaning ofBi-syllabic Chinese Compound Words Using BackPropagation Neural Network.
In Computer Processingof Oriental Languages, 11(2):133-144.Christopher Manning and Hinrich Sch?tze.
1999.Fondations of Statistical Natural Language Processing,MIT Press.Jia-Ju Mei et al 1984.
TonYiCi CiLin ?
thesaurus ofChinese words (???
?<), Shangwu Yinshuguan(OD??`???
), Hong Kong.Sabine Ploux and Bernard Victorri.
1998.
Constructiond?espace s?mantique ?
l?aide de dictionnaires desynonymes.
Traitement Automatique des Langues,39(1):161-182.Sabine Ploux and Hyungsuk Ji.
2003.
A Model forMatching Semantic Maps Between Languages(French/English, English/French).
ComputationalLinguistics, 29(2):155-178.Philip Resnik.
1995.
Using Information Content toEvaluate Semantic Similarity in a Taxonomy.
InProceedings of the 14th International Joint Conferenceon Artificial Intelligence (IJCAI), pages 448-453.Yorick Wilks and Mark Stevenson.
1997.
Sense Tagging:Semantic Tagging with a Lexicon.
In Proceedings ofthe SIGLEX Workshop on Tagging Text with LexicalSemantics, pages 47-51.David Yarowsky.
1992.
Word-Sense DisambiguationUsing Statistical Models of Rogets Categories Trainedon Large Corpora?, In Proceedings of COLING-92,pages 454-460.
