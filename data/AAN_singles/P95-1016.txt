Utilizing Statistical Dialogue Act Processing in VerbmobilNorbert Reithinger and Elisabeth Maier*DFKI GmbHStuhlsatzenhausweg 3D-66123 SaarbriickenGermany{re?thinger, maier}@dfki, uni- sb.
deAbstractIn this paper, we present a statistical ap-proach for dialogue act processing in the di-alogue component of the speech-to-speechtranslation system VERBMOBIL.
Statisticsin dialogue processing is used to predictfollow-up dialogue acts.
As an applicationexample we show how it supports repairwhen unexpected dialogue states occur.1 IntroductionExtracting and processing communicative intentionsbehind natural language utterances plays an im-portant role in natural anguage systems (see e.g.
(Cohen et al, 1990; Hinkelman and Spackman,1994)).
Within the speech-to-speech translation sys-tem VERBMOBIL (Wahlster, 1993; Kay et al, 1994),dialogue acts are used as the basis for the treatmentof intentions in dialogues.
The representation f in-tentions in the VERBMOBIL system serves two mainpurposes:?
Utilizing the dialogue act of an utterance asan important knowledge source for transla-tion yields a faster and often qualitative bettertranslation than a method that depends on sur-face expressions only.
This is the case especiallyin the first application of VV.RBMOBIL, the on-demand translation of appointment schedulingdialogues.?
Another use of dialogue act processing in VERB-MOBIL is the prediction of follow-up dialogueacts to narrow down the search space on theanalysis ide.
For example, dialogue act pre-dictions are employed to allow for dynamicallyadaptable language models in word recognition.
*This work was funded by the German Federal Min-istry for Education, Research and Technology (BMBF)in the framework of the Verbmohil Project under Grant01IV101K/1.
The responsibility for the contents of thisstudy lies with the authors.
Thanks to Jan Alexanders-son for valuable comments and suggestions on earlierdrafts of this paper.Recent results (e.g.
(Niedermair, 1992)) show areduction of perplexity in the word recognizerbetween 19% and 60% when context dependentlanguage models are used.DiMogue act determination in VERBMOBIL is donein two ways, depending on the system mode: usingdeep or shallow processing.
These two modes dependon the fact that VERBMOBIL is only translating ondemand, i.e.
when the user's knowledge of Englishis not sufficient to participate in a dialogue.
If theuser of VERBMOBIL needs translation, she presses abutton thereby activating deep processing.
In depthprocessing of an utterance takes place in maximally50% of the dialogue contributions, namely when theowner speaks German only.
DiMogue act extractionfrom a DRS-based semantic representation (Bos etal., 1994) is only possible in this mode and is thetask of the semantic evaluation component ofVERB-MOBIL.In the other processing mode the diMogue com-ponent ries to process the English passages of thediMogue by using a keyword spotter that tracks theongoing dialogue superficiMly.
Since the keywordspotter only works reliably for a vocabulary of someten words, it has to be provided with keywords whichtypically occur in utterances of the same diMogueact type; for every utterance the dialogue componentsupplies the keyword spotter with a prediction of themost likely follow-up dialogue act and the situation-dependent keywords.The dialogue component uses a combination ofstatistical and knowledge based approaches to pro-cess dialogue acts and to maintain and to providecontextual information for the other modules ofVERBMOBIL (Maier and McGlashan, 1994).
It in-cludes a robust dialogue plan recognizing module,which uses repair techniques to treat unexpected di-alogue steps.
The information acquired uring di-alogue processing is stored in a dialogue memory.This contextual information is decomposed into theintentional structure, the referential structure, andthe temporal structure which refers to the datesmentioned in the dialogue.116An overview of the dialogue component is givenin (Alexandersson et al, 1995).
In this paper mainemphasis is on statistical dialogue act prediction inVEFtBMOBIL, with an evaluation of the method, andan example of the interaction between plan recogni-tion and statistical dialogue act prediction.Main WadoguoGro~ SuggeaIntroduce Init I=lequoet_CornmQmtRequut Commont?
Commont /Thank Su99eet Requeet_CommentCon(mrnPotonUol additionsIn any cllelogueClarily_Amvo?
?--.-= <, /I:)igam= V COa~y_Ou=ryI 1-1 Initial Stw 0 Final State ?
Nc~4iaal SUm \[Figure 1: A dialogue model for the description ofappointment scheduling dialogs2 The  D ia logue  Mode l  andPred ic t ions  o f  D ia logue  ActsLike previous approaches for modeling task-orienteddialogues we assume that a dialogue can be de-scribed by means of a limited but open set of di-alogue acts (see e.g.
(Bilange, 1991), (Mast et al,1992)).
We selected the dialogue acts by examiningthe VERBMOBIL corpus, which consists of transliter-ated spoken dialogues (German and English) for ap-pointment scheduling.
We examined this corpus forthe occurrence of dialogue acts as proposed by e.g.
(Austin, 1962; Searle, 1969) and for the necessity tointroduce new, sometimes problem-oriented dialogueacts.
We first defined 17 dialogue acts together withsemi-formal rules for their assignment to utterances(Maier, 1994).
After one year of experience withthese acts, the users of dialogue acts in VERBMOBILselected them as the domain independent "upper"concepts within a more elaborate hierarchy that be-comes more and more propositional nd domain de-pendent owards its leaves (Jekat et al, 1995).
Sucha hierarchy is useful e.g.
for translation purposes.Following the assignment rules, which also servedas starting point for the automatic determination ofdialogue acts within the semantic evaluation com-ponent, we hand-annotated over 200 dialogues withdialogue act information to make this informationavailable for training and test purposes.Figure 1 shows the domain independent dialogueacts and the transition etworks which define admis-sible sequences of dialogue acts.
In addition to thedialogue acts in the main dialogue network, there arefive dialogue acts, which we call deviations, that canoccur at any point of the dialogue.
They are repre-sented in an additional subnetwork which is shownat the bottom of figure 1.
The networks serve asthe basis for the implementation of a parser whichdetermines whether an incoming dialogue act is com-patible with the dialogue model.As mentioned in the introduction, it is not onlyimportant o extract the dialogue act of the cur-rent utterance, but also to predict possible followup dialogue acts.
Predictions about what comesnext are needed internally in the dialogue compo-nent and externally by other components in VERB-MOBIL.
An example of the internal use, namely thetreatment of unexpected input by the plan recog-nizer, is described in section 4.
Outside the dialoguecomponent dialogue act predictions are used e.g.
bythe abovementioned semantic evaluation componentand the keyword spotter.
The semantic evaluationcomponent needs predictions when it determines thedialogue act of a new utterance to narrow down theset of possibilities.
The keyword spotter can onlydetect a small number of keywords that are selectedfor each dialogue act from the VERBMOBIL corpus ofannotated ialogues using the Keyword Classifica-tion Tree algorithm (Kuhn, 1993; Mast, 1995).For the task of dialogue act prediction aknowledgesource like the network model cannot be used sincethe average number of predictions in any state of themain network is five.
This number increases whenthe five dialogue acts from the subnetwork which canoccur everywhere are considered as well.
In that casethe average number of predictions goes up to 10.
Be-cause the prediction of 10 dialogue acts from a totalnumber of 17 is not sufficiently restrictive and be-cause the dialogue network does not represent pref-erence information for the various dialogue acts weneed a different model which is able to make reliabledialogue act predictions.
Therefore we developed astatistical method which is described in detail in thenext section.3 The  Stat i s t i ca l  P red ic t ion  Methodand  i t s  Eva luat ionIn order to compute weighted dialogue act predic-tions we evaluated two methods: The first methodis to attribute probabilities to the arcs of our net-work by training it with annotated ialogues fromour corpus.
The second method adopted informa-tion theoretic methods from speech recognition.
We117implemented and tested both methods and currentlyfavor the second one because it is insensitive to de-viations from the dialogue structure as described bythe dialogue model and generally ields better pre-diction rates.
This second method and its evaluationwill be described in detail in this section.Currently, we use n-gram dialogue act probabil-ities to compute the most likely follow-up dialogueact.
The method is adapted from speech recogni-tion, where language models are commonly used toreduce the search space when determining a wordthat can match a part of the input signal (Jellinek,1990).
It was used for the task of dialogue act pre-diction by e.g.
(Niedermair, 1992) and (Nagata ndMorimoto, 1993).
For our purpose, we consider adi-alogue S as a sequence of utterances Si where eachutterance has a corresponding dialogue act si.
IfP(S) is the statistical model of S, the probabilitycan be approximated by the n-gram probabilitiesP(S) = H P(siIsi-N+I'"" S,-l)i=1Therefore, to predict the nth dialogue act sn wecan use the previously uttered ialogue acts and de-termine the most probable dialogue act by comput-ings .
:=  max P(sls._;,  s,,-u, s.,-z, ...)$To approximate he conditional probability P(.I.
)the standard smoothing technique known as deletedinterpolation is used (Jellinek, 1990) withP(s. ls .
- , ,s .
-2)  =qlf(sn) q- qzf(sn Is.-x) + q3f(Sn I'.-1, s.-u)where f are the relative frequencies computedfrom a training corpus and qi weighting factors with~"~qi = 1.To evaluate the statistical model, we made vari-ous experiments.
Figure 2 shows the results for threerepresentative experiments (TS1-TS3, see also (Rei-thinger, 1995)).I Pred.
I TS1 TS2 TS31 44,24% 37.47 % 40.28%2 66,47 % 56.50% 59.62%3 81,46% 69.52% 71.93%Figure 2: Predictions and hit ratesIn all experiments 41 German dialogues (with2472 dialogue acts) from our corpus are used astraining data, including deviations.
TS1 and TS2use the same 81 German dialogues as test data.
Thedifference between the two experiments i that inTS1 only dialogue acts of the main dialogue networkare processed uring the test, i.e.
the deviation actsof the test dialogues are not processed.
As can beseen - -  and as could be expected - -  the predictionrate drops heavily when unforseeable d viations oc-cur.
TS3 shows the prediction rates, when all cur-rently available annotated dialogues (with 7197 dia-logue acts) from the corpus are processed, includingdeviations.16wmwMm | | |$ Io I $| !
!
| i !Figure 3: Hit rates for 47 dialogues using 3 predic-tionsCompared to the data from (Nagata and Mori-moto, 1993) who report prediction rates of 61.7 %,77.5% and 85.1% for one, two or three predictionsrespectively, the predictions are less reliable.
How-ever, their set of dialogue acts (or the equivalents,called illocutionary force types) does not include di-alogue acts to handle deviations.
Also, since thedialogues in our corpus are rather unrestricted, theyhave a big variation in their structure.
Figure 3shows the variation in prediction rates of three dia-logue acts for 47 dialogues which were taken at ran-dom from our corpus.
The x-axis represents he dif-ferent diMogues, while the y-axis gives the hit ratefor three predictions.
Good examples for the differ-ences in the dialogue structure are the diMogue pairs#15/#16 and #41/#42.
The hit rate for dialogue#15 is about 54% while for #16 it is about 86%.Even more extreme is the second pair with hit ratesof approximately 93% vs. 53%.
While diMogue #41fits very well in the statisticM model acquired fromthe training-corpus, dialogue #42 does not.
Thisfigure gives a rather good impression of the wide va-riety of material the dialogue component has to copewith.4 App l i ca t ion  o f  the  S ta t i s t i ca lMode l :  T reatment  o f  UnexpectedInputThe dialogue model specified in the networks mod-els all diMogue act sequences that can be usuallyexpected in an appointment scheduling dialogue.
Incase unexpected input occurs repair techniques have118to be provided to recover from such a state and tocontinue processing the dialogue in the best possibleway.
The treatment of these cases is the task of thedialogue plan recognizer of the dialogue component.The plan recognizer uses a hierarchical depth-firstleft-to-right echnique for dialogue act processing(Vilain, 1990).
Plan operators have been used toencode both the dialogue model and methods for re-covery from erroneous dialogue states.
Each planoperator epresents a specific goal  which it is ableto fulfill in case specific const ra in ts  hold.
Theseconstraints mostly address the context, but theycan also be used to check pragmatic features, likee.g.
whether the dialogue participants know eachother.
Also, every plan operator can trigger follow-up actions, h typical action is, for example, theupdate of the dialogue memory.
To be able to fulfilla goal a plan operator can define subgoals whichhave to be achieved in a pre-specified order (see e.g.
(Maybury, 1991; Moore, 1994) for comparable ap-proaches).fmwl_2_01: der Termin den wir neul ichabgesprochen haben am zehnten an demSamstag (MOTIVATE)(the date we recently agreed upon, the lOth thatSaturday)da kann ich doch nich' (REJECT)(then I can not)wit  so l l ten  e inen  anderen  ausmachen (INIT)(we should make another one)mpsl_2_02: wean i ch  da  so meinen Termin-Kalender anschaue, (DELIBERATE)(if I look at my diary)dan s ieht  sch lecht  aus  (REJECT).
(that looks bad)Figure 4: Part of an example dialogueSince the VERBMOBIL system is not actively par-ticipating in the appointment scheduling task butonly mediating between two dialogue participants ithas to be assumed that every utterance, even if itis not consistent with the dialogue model, is a legaldialogue step.
The first strategy for error recoverytherefore is based on the hypothesis that the attri-bution of a dialogue act to a given utterance hasbeen incorrect or rather that an utterance has vari-ous facets, i.e.
multiple dialogue act interpretations.Currently, only the most plausible dialogue act isprovided by the semantic evaluation component.
Tofind out whether there might be an additional inter-pretation the plan recognizer elies on informationprovided by the statistics module.
If an incompat-ible dialogue act is encountered, an alternative dia-logue act is looked up in the statistical module whichis most likely to come after the preceding dialogueact and which can be consistently followed by thecurrent dialogue act, thereby gaining an admissibledialogue act sequence.To illustrate this principle we show a part of theprocessing of two turns (fmwl..2_01 and mpsl_2_02,see figure 4) from an example dialogue with the di-alogue act assignments as provided by the seman-tic evaluation component.
The translations tick tothe German words as close as possible and are notprovided by VERBMOBIL.
The trace of the dialoguecomponent is given in figure 5, starting with pro-cessing of INIT.Planner: - -  Process ing  INITP lanner :  - -  P rocess ing  DELIBERATEWarning -- Repairing...P lanner :  -- Process ing  REJECTTrying to f ind a dialogue act  to  br idgeDELIBERATE and REJECT .
.
.Poss ib le  inser t ions  and the i r  scores :((SUGGEST 81326)(REQUEST_COMMENT 37576)(DELIBERATE20572))Test ing  SUGGEST for  compatibi l i ty withsur round ing  d ia logue  acts .
.
.The prev iomsd ia logue  act  INIThas  an add i t iona l  read ing  o f  SUGGEST:INIT -> INIT SUGGEST !Warning - -  Repa i r ing .
.
.P lanner :  - -  P rocess ing  I i I TPlanner: -- Processing SUGGEST, .
.Figure 5: Example of statistical repairIn this example the case for statistical repair oc-curs when a REJECT does not - as expected - followa SUGGEST.
Instead, it comes after the INIT of thetopic to be negotiated and after a DELIBERATE.
Thelatter dialogue act can occur at any point of thedialogue; it refers to utterances which do not con-tribute to the negotiation as such and which can bebest seen as "thinking aloud".
As first option, theplan recognizer tries to repair this state using sta-tistical information, finding a dialogue act which isable to connect INIT and REJECT 1.
As can be seen infigure 5 the dialogue acts REQUEST_COMMENT, DE-LIBERATE, and SUGGEST can be inserted to achievea consistent dialogue.
The annotated scores are theproduct of the transition probabilities times 1000 be-tween the previous dialogue act, the potential inser-tion and the current dialogue act which are provided1 Because DELIBERATE has only the function of "so-cial noise" it can be omitted from the followingconsiderations.119by the statistic module.
Ordered according to theirscores, these candidates for insertion are tested forcompatibility with either the previous or the currentdialogue act.
The notion of compatibility refers todialogue acts which have closely related meanings orwhich can be easily realized in one utterance.To find out which dialogue acts can be combinedwe examined the corpus for cases where the repairmechanism proposes an additional reading.
Lookingat the sample dialogues we then checked which of theproposed ialogue acts could actually occur togetherin one utterance, thereby gaining a list of admissi-ble dialogue act combinations.
In the VERBMOBILcorpus we found that dialogue act combinations likeSUGGEST and REJECT can never be attributed to oneutterance, while INIT can often also be interpretedas a SUQGEST therefore getting a typical follow-upreaction of either an acceptance or a rejection.
Thelatter case can be found in our example: INIT getsan additional reading of SUGeEST.In cases where no statistical solution is possibleplan-based repair is used.
When an unexpected di-alogue act occurs a plan operator is activated whichdistinguishes various types of repair.
Depending onthe type of the incoming dialogue act specializedrepair operators are used.
The simplest case cov-ers dialogue acts which can appear at any point ofthe dialogue, as e.g.
DELIBERATE and clarificationdialogues (CLARIFY_QUERY and CLARIFY-ANSWER).We handle these dialogue acts by means of repair inorder to make the planning process more efficient:since these dialogue acts can occur at any point inthe dialogue the plan recognizer in the worst casehas to test for every new utterance whether it is oneof the dialogue acts which indicates a deviation.
Toprevent this, the occurrence of one of these dialogueacts is treated as an unforeseen event which triggersthe repair operator.
In figure 5, the plan recognizerissues a warning after processing the DELIBERATE di-alogue act, because this act was inserted by meansof a repair operator into the dialogue structure.5 Conc lus ionThis paper presents the method for statistical dia-logue act prediction currently used in the dialoguecomponent of VERBMOBIL.
It presents plan repairas one example of its use.The analysis of the statistical method shows thatthe prediction algorithm shows satisfactory resultswhen deviations from the main dialogue model areexcluded.
If dialogue acts for deviations are in-cluded, the prediction rate drops around 10%.
Theanalysis of the hit rate shows also a large variationin the structure of the dialogues from the corpus.We currently integrate the speaker direction into theprediction process which results in a gain of up to5 % in the prediction hit rate.
Additionally, we in-vestigate methods to cluster training dialogues inclasses with a similar structure.An important application of the statistical predic-tion is the repair mechanism ofthe dialogue plan rec-ognizer.
The mechanism proposed here contributesto the robustness of the whole VERBMOBIL systeminsofar as it is able to recognize cases where dialogueact attribution has delivered incorrect or insufficientresults.
This is especially important because the in-put given to the dialogue component is unreliablewhen dialogue act information is computed via thekeyword spotter.
Additional dialogue act readingscan be proposed and the dialogue history can bechanged accordingly.Currently, the dialogue component processes morethan 200 annotated ialogues from the VERBMOBILcorpus.
For each of these dialogues, the plan rec-ognizer builds a dialogue tree structure, using themethod presented in section 4, even if the dialoguestructure is inconsistent with the dialogue model.Therefore, our model provides robust echniques forthe processing of even highly unexpected ialoguecontributions.In a next version of the system it is envisaged thatthe semantic evaluation component and the keywordspotter are able to attribute a set of dialogue actswith their respective probabilities to an utterance.Also, the plan operators will be augmented with sta-tistical information so that the selection of the bestpossible follow-up dialogue acts can be retrieved byusing additional information from the plan recog-nizer itself.ReferencesJan Alexandersson, Elisabeth Maier, and NorbertReithinger.
1995.
A Robust and EfficientThree-Layered Dialog Component  for a Speech-to-Speech Translation System.
In Proceedings ofthe 7th Conference of the European Chapter of theA CL (EA CL-95), Dublin, Ireland.John Austin.
1962.
How to do things with words.Oxford: Clarendon Press.Eric Bilange.
1991.
A task independent oral dia-logue model.
In Proceedings of the Fifth Confer-ence of the European Chapter of the Associationfor Computational Linguistics (EACL-91), pages83-88, Berlin, Germany.Johan Bos, Elsbeth Mastenbroek, Scott McGlashan,Sebastian Millies, and Manfred Pinkal.
1994.
TheVerbmobil Semantic Formalismus.
Technical re-port, Computerlinguistik, Universit~it des Saar-landes, Saarbriicken.Philip R. Cohen, Jerry Morgan, and Martha E. Pol-lack, editors.
1990.
Intentions in Communication.MIT Press, Cambridge, MA.Elizabeth A. Hinkelman and Stephen P. Spackman.1994.
Communicating with Multiple Agents.
In120Proceedings of the 15th International Conferenceon Computational Linguistics (COLING 94), Au-gust 5-9, 1994, Kyoto, Japan, volume 2, pages1191-1197.Susanne Jekat, Alexandra Klein, Elisabeth Maier,Ilona Maleck, Marion Mast, and J. JoachimQuantz.
1995.
Dialogue Acts in Verbmobil.
Verb-mobil Report Nr.
65, Universit~it Hamburg, DFKISaarbriicken, Universit~it Erlangen, TU Berlin.Fred Jellinek.
1990.
Self-Organized Language Mod-eling for Speech Recognition.
In A. Waibel andK.-F. Lee, editors, Readings in Speech Recogni-tion, pages 450-506.
Morgan Kaufmann.Martin Kay, Jean Mark Gawron, and Peter Norvig.1994.
Verbmobil.
A Translation System for Face-to-Face Dialog.
Chicago University Press.
CSLILecture Notes, Vol.
33.Roland Kuhn.
1993.
Keyword Classification Treesfor Speech Understanding Systems.
Ph.D. thesis,School of Computer Science, McGill University,Montreal.Elisabeth Maier and Scott McGlashan.
1994.
Se-mantic and Dialogue Processing in the VERB-MOBIL Spoken Dialogue Translation System.
InHeinrich Niemann, Renato de Mori, and Ger-hard Hanrieder, editors, Progress and Prospects ofSpeech Research and Technology, volume 1, pages270-273, Miinchen.Elisabeth Maier.
1994.
Dialogmodellierung inVERBMOBIL - Pestlegung der Sprechhandlun-gen fiir den Demonstrator.
Technical ReportVerbmobil Memo Nr.
31, DFKI Saarbriicken.Marion Mast, Ralf Kompe, Franz Kummert, Hein-rich Niemann, and Elmar NSth.
1992.
The Di-alogue Modul of the Speech Recognition and Di-alog System EVAR.
In Proceedings of Interna-tional Conference on Spoken Language Processing(ICSLP'92), volume 2, pages 1573-1576.Marion Mast.
1995.
SchliisselwSrter zur Detek-tion yon Diskontinuit~iten und Sprechhandlun-gen. Technical Report Verbmobil Memo Nr.57, Friedrich-Alexander-Universit~it, Erlangen-Niirnberg.Mark T. Maybury.
1991.
Planning Multisen-tential English Text Using Communicative Acts.Ph.D.
thesis, University of Cambridge, Camb-dridge, GB.Johanna Moore.
1994.
Participating in ExplanatoryDialogues.
The MIT Press.Masaaki Nagata and Tsuyoshi Morimoto.
1993.
Anexperimental statistical dialogue model to predictthe Speech Act Type of the next utterance.
InProceedings of the International Symposium onSpoken Dialogue (ISSD-93), pages 83-86, WasedaUniversity, Tokyo, Japan.Gerhard Th.
Niedermair.
1992.
Linguistic Mod-elling in the Context of Oral Dialogue.
In Pro-ceedings of International Conference on SpokenLanguage Processing (ICSLP'92}, volume 1, pages635-638, Banff, Canada.Norbert Reithinger.
1995.
Some Experiments inSpeech Act Prediction.
In AAAI 95 Spring Sym-posium on Empirical Methods in Discourse Inter-pretation and Generation, Stanford University.John R. Searle.
1969.
Speech Acts.
Cambridge:University Press.Marc Vilain.
1990.
Getting Serious about ParsingPlans: a Grammatical Analysis of Plan Recogni-tion.
In Proceedings of AAAI-90, pages 190-197.Wolfgang Wahlster.
1993.
Verbmobil-Translation ofPa~e-to-Pace Dialogs.
Technical report, GermanResearch Centre for Artificial Intelligence (DFKI).In Proceedings of MT Summit IV, Kobe, Japan.121
