Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1765?1773,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsTracking unbounded Topic StreamsDominik WurzerSchool of InformaticsUniversity of Edinburghd.s.wurzer@sms.ed.ac.ukVictor LavrenkoSchool of InformaticsUniversity of Edinburghvlavrenk@inf.ed.ac.ukMiles OsborneBloombergLondonmosborne29@bloomberg.netAbstractTracking topics on social media streams isnon-trivial as the number of topics men-tioned grows without bound.
This com-plexity is compounded when we want totrack such topics against other fast mov-ing streams.
We go beyond traditionalsmall scale topic tracking and consider astream of topics against another documentstream.
We introduce two tracking ap-proaches which are fully applicable to truestreaming environments.
When tracking4.4 million topics against 52 million doc-uments in constant time and space, wedemonstrate that counter to expectations,simple single-pass clustering can outper-form locality sensitive hashing for nearestneighbour search on streams.1 IntroductionThe emergence of massive social media streamshas sparked a growing need for systems able toprocess them.
While previous research (Hassanet al, 2009; Becker et al, 2009; Petrovic etal., 2010; Cataldi et al, (2010); Weng et al,(2011); Petrovic 2013) has focused on detectingnew topics in unbounded textual streams, lessattention was paid to following (tracking) thesteadily growing set of topics.
Standard topictracking (Allan, 2002) deals with helping humananalysts follow and monitor ongoing events onmassive data streams.
By pairing topics withrelevant documents, topic tracking splits a noisystream of documents into sub-streams groupedby their target topics.
This is a crucial task forfinancial and security analysts who are interestedin pulling together relevant information fromunstructured and noisy data streams.
Other fieldslike summarization or topic modeling benefitfrom topic tracking as a mean to generate theirdata sources.In todays data streams however, new topicsemerge on a continual basis and we are interestedin following all instead of just a small fractionof newly detected topics.
Since its introduction(Allan, 2002), standard topic tracking typicallyoperates on a small scale and against a staticset of predefined target topics.
We go beyondsuch approaches and deal for the first time withmassive, unbounded topic streams.
Examplesof unbounded topic streams include all eventsreported by news agencies each day across theworld; popular examples of unbounded documentstreams include social media services such asTwitter.
Tracking streams of topics allows re-search tasks like topic-modeling or summarizationto be applied to millions of topics, a scale thatis several orders of magnitude larger than thoseof current publications.
We present two massivescale topic tracking systems capable of trackingunbounded topic streams.
One is based on localitysensitive hashing (LSH) and the other on clus-tering.
Since we operate on two unbounded datasources we are subject to the streaming model ofcomputation (Muthukrishnan, 2005), which re-quires instant and single-pass decision making inconstant time and space.
Contrary to expectations,we find that nearest neighbour search on a streambased on clustering performs faster than LSH forthe same level of accuracy.
This is surprising asLSH is widely believed to be the fastest way ofnearest neighbour search.
Our experiments revealhow simple single-pass clustering outperformsLSH in terms of effectiveness and efficiency.
Ourresults are general and apply to any setting wherewe have massive or infinite numbers of topics,matched against unboundedly large documentstreams.1765Contributions?
For the first time we show how it is possi-ble to track an unbounded stream of topicsin constant time and space, while maintain-ing a level of effectiveness that is statisticallyindistinguishable from an exact tracking sys-tem?
We show how single-pass clustering can out-perform locality sensitive hashing in termsof effectiveness and efficiency for identifyingnearest neighbours in a stream?
We demonstrate that standard measures ofsimilarity are sub-optimal when matchingshort documents against long documents2 Related WorkTopic or event tracking was first introduced in theTopic Detection and Tracking (TDT) program (Al-lan, 2002).
In TDT, topic tracking involves mon-itoring a stream of news documents with the in-tent to identify those documents relevant to a smallpredefined set of target topics.
During the courseof TDT, research focused extensively on the effec-tiveness of tracking systems, neglecting scale andefficiency.
The three official data sets only rangefrom 25k to 74k documents with a few hundredtopics (Allan, 2002).More recently, the rise of publicly availablereal-time social media streams triggered newresearch on topic detection and tracking, in-tended to apply the technology to those highvolume document streams.
The novel datastreams differ from the TDT data sets in theirvolume and level of noise.
To provide real-time applications, traditional methods need tobe overhauled to keep computation feasible.It became common practice to limit data sets tocope with the computational effort.
Popular strate-gies involve reducing the number of tracked top-ics (Lin et al, 2011; Nichols et al, 2012;) aswell as sampling the document stream (Ghosh etal., 2013).
These approaches have proven to beefficient in cutting down workload but they alsolimit an application?s performance.
Furthermore,Sayyadi et al (2009) discovered and tracked top-ics in social streams based on keyword graphs.They applied the sliding window principle to keepthe computation feasible, although their data setonly contained 18k documents.
Yang et al 2012tracked topics in tweet streams using languagemodels.
To cope with the computational effortthey assume a small set of topics of only a fewdozen, which are defined in advance.
Tang et al(2011) tracked a single topic on a few thousandblogs based on semantic graph topic models.
Ponet al (2007) recommend news by tracking multi-ple topics for a user but their data sets only spanseveral thousand documents and a few topics.Further related work includes the real-time filter-ing task, introduced as part of TREC?s MicroblogTrack in 2012 (Soboroff et al, 2012).
Hong et al(2013) explore topic tracking in tweet streams inrelation to the TREC real-time filtering task by re-lying on a sliding window principle, while focus-ing on the cold start problem.3 Topic Tracking3.1 Traditional ApproachNumerous approaches to topic tracking haveemerged, spanning from probabilistic retrieval tostatistical classification frameworks.
While thereis no single general approach, we define the tradi-tional approach to tracking from a high-level per-spective covering the basic principle of all previ-ous approaches.
We do not make any assump-tions about the kind of topics, documents or dis-tance functions used.
As defined by TDT (Allan,2002), we assume, we operate on an unboundeddocument stream with the goal of tracking a fixedset of target topics.
Although topics are allowed todrift conceptually and evolve over time, new top-ics would always trigger the start of a new trackingsystem.Algorithm 1 Traditional TrackingINPUT:TOPIC-SET {t  T}DOCUMENT-STREAM {d  D}OUTPUT:relevant topic-document pairs {t, d}while documents d in stream D dofor all topics t in set T dosimilarity = computeSimilarity(d,t)if similarity > threshold thenemit relevant {t, d}As seen in Algorithm 1, documents arrive one ata time, requiring instant decision making throughsingle pass processing.
Each document is com-pared to all topics representations to identify theclosest topic.
The tracking decision is based on thesimilarity to the closest topic and usually definedby a thresholding strategy.
Because incoming doc-uments can be relevant to more than one topic, we1766need to match it against all of them.
Due to its sim-plicity, the traditional tracking approach is highlyefficient when applied to a fairly low number oftopics.3.2 Shortcomings of the traditional approachThe traditional approach - though low in compu-tational effort - becomes challenging when scal-ing up the number of target topics.
The compu-tational effort arises from the number of compar-isons made (the number of documents times top-ics).
That explains, why researches following thetraditional approach have either lowered the num-ber of documents or topics.
Heuristics and index-ing methods increase the performance but offer nosolution scalable to true streaming environmentsbecause they only allow for one-side scaling (ei-ther a large number of documents or topics).
In-creasing either of the two components by a singledocument, increases the computational effort bythe magnitude of the other one.
For the extremecase of pushing to an infinite number of topics,tracking in constant space is a necessity.4 Tracking at scaleBefore directly turning to a full streaming set upin constant space, we approach tracking a topicstream on a document stream in unbounded space.The key to scale up documents and topics, liesin reducing the number of necessary comparisons.Throughout the remainder of this paper we repre-sent documents and topics arriving from a steadyhigh volume stream by term-weighted vectors inthe vector space.In order to cut down the search space, we encap-sulate every topic vector by a hypothetical regionmarking its area of proximity.
Those regions areintend to capture documents that are more likelyto be relevant.
Ideally, these regions form a hy-persphere centred around every topic vector witha radius equal to the maximum distance to rele-vant documents.
The tracking procedure is thenreduced to determining whether an incoming doc-ument is also enclosed by any of the hyperspheres.4.1 Approximated TrackingOur first attempt to reach sub-linear executiontime uses random segmentation of the vector spaceusing hashing techniques.
We frame the track-ing process as a nearest neighbour search prob-lem, as defined by Gionis et al (1999).
Docu-ments arriving from a stream are seen as queriesand the closest topics are the nearest neighbours tobe identified.
We explore locality sensitive hash-ing (LSH), as described by Indyk et al (1998),to approach high dimensional nearest neighboursearch for topic tracking in sub-linear time.
LSH,which has been used to speed up NLP applica-tions (Ravichandran et al, 2005), provides hashfunctions that guarantee that similar documentsare more likely to be hashed to the same binaryhash key than distant ones.
Hash functions capturesimilarities between vectors in high dimensionsand represent them on a low dimensional binarylevel.
We apply the scheme by Charikar (2002),which describes the probabilistic bounds for thecosine similarity between two vectors.
Each bit ina hash key represents a documents position withrespect to a randomly placed hyperplane.
Thoseplanes segment the vector space, forming high di-mensional polygon shaped buckets.
Documentsand topics are placed into a bucket by determin-ing on which side of each the hyperplanes they arepositioned.
We interpret these buckets as regionsof proximity as the collision probability is directlyproportional to the cosine similarity between twovectors.Algorithm 2 LSH-based TrackingINPUT:TOPIC-STREAM {T}DOCUMENT-STREAM {D}OUTPUT:relevant topic-document pairs {t, d}while document d in T, D doif d  T thenhashKeys = hashLSH(d)store hashKeys in hashTableselse if d  D thencandidateSet = lookupHashtables(hashLSH(d))for all topics t in candidateSet doif similarity(d,t) > threshold thenemit relevant {t, d}Algorithm 2 outlines the pseudo code to LSH-based tracking.
Whenever a topic arrives, it ishashed, placing it into a bucket.
To increase col-lision probability with similar documents, we re-peat the hashing process with different hash func-tions, storing a topic and hash-key tuple in a hashtable.
On each arrival of a new document the samehash functions are applied and the key is matchedagainst the hash tables, yielding a set of candidatetopics.
The probabilistic bounds of the hashingscheme guarantee that topics in the candidate set1767are on average more likely to be similar to the doc-ument than others.We then match each topic in the candidate setagainst the document to lower the false positiverate of LSH (Gionis, et al, 1999).
The numberof exact comparisons necessary is reduced to thenumber of topics in the candidate set.4.2 Cluster based TrackingLSH based tracking segments the vector-spacerandomly without consideration of the data?s dis-tribution.
In contrast, we now propose a data de-pendent approach through document clustering.The main motivation for data dependent spacesegmentation is increased effectiveness resultingfrom taking the topic distribution within the vec-tor space into account when forming the regions ofproximity.
We construct these regions by group-ing similar topics to form clusters represented by acentroid.
When tracking a document, it is matchedagainst the centroids instead of all topics, yield-ing a set of candidate topics.
This allows reducingthe number of comparisons necessary to only thenumber of centroids plus the number of topics cap-tured by the closest cluster.Algorithm 3 Cluster based TrackingINPUT:INITIAL-CLUSTER-SET {c  C}TOPIC-STREAM {T}DOCUMENT-STREAM {D}threshold for spawning a new cluster {thrspawn}threshold for adapting an existing cluster {thradapt}OUTPUT:relevant topic-document pairs {t, d}while document d in T, D doif d  T thencmin= argminc{distances(d, c  C)}if distance(d,cmin) > thrspawnthenspawnNewCluster(d?
C)else if distance(d,cmin) < thradaptthencontribute,assign(cmin,d)elseassign(cmin,d)else if d  D thencmin= argminc{distances(d,c  C)}candidateSet = {t  cmin}for all topics t in candidateSet doif similarity(d,t) > threshold thenemit relevant {t, d}While the literature provides a vast diversity ofclustering methods for textual documents, ourrequirements regarding tracking streams of top-ics naturally reduce the selection to lightweightsingle-pass algorithms.
Yang et al (2012) pro-vided evidence that in extreme settings simple ap-proaches work well in terms of balancing effec-tiveness, efficiency and scalability.
We identifiedArteCM by Carullo et al (2008), originally in-tended to cluster documents for the web, as suit-able.
Algorithm 3 outlines our approach for clus-ter based tracking.
Given an initial set of 4 ran-dom centroids, we compare each arriving topic toall centroids.
We associate the new topic with thecluster whenever it is close enough.
Particularlyclose documents contribute to a cluster, allowingit to drift towards topic dense regions.
If the docu-ment is distant to all existing clusters, we spawn anew cluster based on the document.Documents arriving from the document stream areexactly matched against all centroids to determinethe k-closest clusters.
Topics associated with thoseclusters are subsequently exhaustively comparedwith the document, yielding topic-document pairsconsidered to be relevant.
Probing more than onecluster increases the probability of finding similartopics.
This does not correlate with soft-clusteringmethods as multiple probing happens at queryingtime while topics are assigned under a hard clus-tering paradigm.4.3 Algorithm ComparisonBoth the LSH- and the cluster-based tracking al-gorithm provide two parameters that are conceptu-ally directly comparable to each other.
The num-ber of bits per hash key and the threshold forspawning new clusters directly determine the sizeof the candidate set by either varying the bucketsize or the cluster radius.
The size of the candi-date set trades a gain in efficiency against a lossin effectiveness.
Fewer topics in the candidate setheavily reduce the search space for the trackingprocess but increase the chance of missing a rele-vant topic.
Bigger sets are more likely to cover rel-evant topics but require more computational effortduring the exact comparison step.
The proposedalgorithms allow continuously adjusting the can-didate set size between two extremes of having alltopics in a single set and having a separate set foreach topic.The second parameter both algorithms have incommon, is the number of probes to increase theprobability of identifying similar topics.
WhileLSH-based tracking offers the number of hash ta-bles, cluster-based tracking provides the numberof clusters probed.
We again encounter a trade-offbetween gains in efficiency at the cost of effective-1768ness.
Each additionally probed cluster or lookedup table increases the chance of finding relevanttopics as well as the computational effort.5 Tracking Streams in Constant SpaceOperation in constant space is crucial when track-ing topic streams.
We ensure this by placing anupper limit on the number of concurrently trackedtopics.
Whenever the limit is reached, an activetopic is deleted and subsequently not consideredany longer.
The strategy for selecting deletioncandidates is heavily application dependant.
Tohandle topic streams, LSH-based tracking replacesthe entries of an active topic in its hash-tables bythe values of the new topic, whenever the maxi-mum number of topics is reached.
Cluster-basedtracking requires more adaptation because we al-low clusters to drift conceptually.
Whenever themaximum number of topics is reached, the con-tribution of the deletion candidate to its cluster isreverted and it is removed, freeing space for a newtopic.6 ExperimentsWe evaluate the three algorithms in termsof effectiveness and efficiency.
Starting outwith tracking a small set of topics using thetraditional approach, we evaluate various sim-ilarity metrics to ensure high effectiveness.We then conduct scaling experiments on mas-sive streams in bounded and unbounded space.CorporaTraditional tracking datasets are unsuitable toapproach tracking at scale as they consist of onlya few thousand documents and several hundredtopics (Allan, 2002).
We created a new dataset consisting of two streams (document andtopic stream).
The document stream consistsof 52 million tweets gathered through Twitter?sstreaming API1.
The tweets are order by theirtime-stamps.
Since we are advocating a highvolume topic stream, we require millions oftopics.
To ensure a high number of topics, wetreat the entire English part (4.4 mio articles) ofWikipedia2as a proxy for a collection of topicsand turn it into a stream.
Each article is consideredto be an unstructured textual representation of atopic time-stamped by its latest verified update.1http://stream.twitter.com2http://en.wikipedia.org/wiki/Wikipedia databaseRelevance JudgementsThe topics we picked range from natural disasters,political and financial events to news aboutcelebrities, as seen in table 3.
We adopted thesearch-guided-annotation process used by NIST(Fiscus et al, 2002) and followed NIST?s TDTannotation guidelines.
According to the definitionof TDT, a document is relevant to a topic ifit speaks about it (Allan, 2002).
In total weidentified 14,436 tweets as relevant to one of 30topics.total number of topics 4.4 mioannotated topics 30total number of documents 52 miodocuments relevant toone of the 30 annotated topics 14.5kTable 1: Data set statisticsBaselineWe use an exact tracking system as a baseline.To speed up runtime, we implement an invertedindex in conjunction with term-at-a-time queryexecution.
Additionally, we provide a trade offbetween effectiveness and efficiency by ran-domly down sampling the Twitter stream.
Notethat this closely resembles previous approachesto scale topic tracking (Ghosh et al, 2013).Evaluation MetricsWe evaluate effectiveness by recall and precisionand combine them using F1 scores.
Efficiencyis evaluated using two different metrics.
Weprovide a theoretical upper bound by computingthe number of dot products required for tracking(Equations 1-4).DPtraditional= nD?
nT(1)DPLSH?based= (nD+nT)?
(k?L)+DPcs(2)DPcluster?based= (nD+ nT) ?
c + DPcs(3)DPcs= nD?
nC(4)Variables DefinitionnDtotal number of documentsnTtotal number of topicsk number of bits per hashL total number of hash tablesc total number of clustersnCtotal number of topicsin all candidate setsTable 2: Definition of variables for equation 1-41769Topic-Title Topic description Number of relevant tweetsAmy Winehouse Amy Winehouse dies 3265Prince William William and Kate arrive in Canada 1021Floods in Seoul Floods and landslides in North and South Korea 432Flight 4896 Flight 4896 crashed 11Bangladesh-India border Bangladesh and India sign a border pact 4Goran Hadzic War criminal Goran Hadzic got arrested 2Table 3: Showing 6 example topics plus a short summary of relevant tweets, as well as the number of relevant tweets per topicThey therefore indicate performance withoutsystem- or implementation-dependent distortions.Equations 2 and 3 represent the cost to identify thecandidate set for the LSH- and cluster-based al-gorithm plus the cost resulting from exhaustivelycomparing the candidate sets with the documents(Equation 4).Because we compute the dot products for a worstcase scenario, we also provide the runtime in sec-onds.
All run-times are averaged over 5 runs, mea-sured on the same idle machine.
To ensure faircomparison, all algorithms are implemented in Cusing the same libraries, compiler, compiler opti-mizations and run as a single process using 4 GBof memory.
Because the runtime of the traditionalapproach (?171 days) exceeds our limits, we esti-mate it based on extrapolating 50 runs using up to25,000 topics.
Note that this extrapolation favoursthe efficiency of the baseline system as it ignoreshardware dependent slowdowns when scaling upthe number of topics.6.1 Exact trackingIn our first experiment we track 30 annotatedtopics on 52 million tweets using the traditionalapproach.
We compare various similarity mea-sures (Table 4) and use the best-performing onein all following experiments.
Our data set dif-fers from the TREC and TDT corpora, which usednews-wire articles.
Allan et al (2000) reportthat the cosine similarity constantly performed asthe best distance function for TDT.
The use ofWikipedia and Twitter causes a different set ofsimilarity measures to perform best.
This resultsfrom the imbalance in average document lengthbetween Wikipedia articles (590 terms) and tweets(11 terms).
The term weights in short tweets(many only containing a single term) are inflatedby the cosine?s length normalization.
Those shorttweets are however not uniquely linkable to targettopics and consequently regarded as non-relevantby annotators, which explains the drop in per-formance.
The similarity function chosen for allsubsequent experiments is a BM25 weighted dotproduct, which we found to perform best.F1 scoretf-idf weighted cosine 0.147tf-idf weighted dot product 0.149BM25 weighted cosine 0.208BM25 weighted dot product 0.217Table 4: Comparing the effectiveness of similarity mea-sures when matching 30 Wikipedia articles against 52 milliontweets6.2 Tracking at scale, using Wikipedia andTwitterPreviously, we conducted small scale experi-ments, now we are looking to scale them up,by tracking 4.4 million Wikipedia articles on 52million tweets without limiting the number oftopics tracked.
The resulting trade-off betweeneffectiveness and efficiency is shown in Figure1 and 2.
The right-most point corresponds toexhaustive comparison of every document againstevery topic ?
this results in highest possible ef-fectiveness (F1 score) and highest computationalcost.
All runs use optimal tracking thresholds de-termined by sweeping them while optimizing onF1 score as an objective function.
We also showthe performance resulting from the traditionalapproach when randomly down-sampling the doc-ument (Twitter) stream, which resembles previousattempts to scale tracking (Ghosh et al, 2013).Every point on the LSH-based tracking curvein Figure 1 and 2 represents a different numberof bits per hash key (varying between 4 and 20)and tables (ranging from 6 to 200).
The pointson the cluster-based tracking curves result fromvarying the number of clusters (ranging from 1 to100,000) and probes.
The resulting bucket sizesspan from a few dozen to over a million topics.As expected, the graphs in Figure 1 closelyresembles those in Figure 2.
The two figures alsoshow that the performance of all three algorithmsis continuously adjustable.
Unsurprisingly, LSH-and cluster-based tracking clearly outperform1770Figure 1: Trade-off between efficiency and dot-products forLSH- and cluster-based tracking as well as a random down-sampling approach for traditional trackingFigure 2: Trade-off between efficiency and runtime forLSH- and cluster-based tracking as well as a random down-sampling approach for traditional tracking;random document sampling for the traditional ap-proach, based on their more effective search spacereduction strategies.
More surprisingly, we alsoobserve that cluster-based tracking outperformstracking based on LSH in terms of efficiency forF1 scores between 10% and 20%.
To understandwhy tracking based on clustering is faster thanrandomized tracking, we further investigatetheir abilities in cutting down the search space.Figure 3 presents the candidate set size nec-essary to find a certain ratio of relevant topics.The graph also illustrates the impact of probingmultiple clusters.
When focusing on a recall upto 60%, LSH-based tracking requires a signif-icantly larger candidate set size in comparisonwith tracking through clustering.
For example,LSH-based tracking needs to examine 30% of alltopics to reach a recall of 50%, while the clusterbased approach only needs to look at 9%.
Thiseffect diminishes for higher recall values.
Fur-thermore, we observe an impressive performancegain in recall from 20% to 60%, resulting fromadditionally probing the k-closest clusters insteadFigure 3: Comparing the candidate set size with the Recallof LSH- with cluster-based tracking without the exact evalua-tion phase; The magnitude of the candidate set size representsthe ratio between the number of candidate topics and the totalnumber of topics;of just the closest one.
While data dependentsegmentation is expected to outperform LSH interms of effectiveness, we were surprised by themagnitude of its impact on efficiency.The lack in effectiveness of LSH has a directnegative implication on its efficiency for tracking.In order to make up for its suboptimal space seg-mentation, it requires substantially bigger candi-date sets to reach the same level of recall as thecluster-based approach.
The size of the candi-date set is critical because we assume a subsequentexact comparison phase to lower the false posi-tive rate.
The overhead of both algorithms is out-weighed by the cost of exact comparison for thecandidate set.Table 5, which compares the performance of thethree algorithms, reveals a drastic reduction in run-time of up to 80%, at the cost of only a minordecrease in F1 score.
The differences of 6% and10% percent in F1 score are statistically not sig-nificant according to a sign test (p<=0.362 andp<=0.2).
Consequently, both algorithms achievesubstantial runtime reduction, while maintaining alevel of effectiveness that is statistically indistin-guishable from the traditional (exact) approach.6.3 Tracking Wikipedia on Twitter inconstant spaceTracking a stream of topics in bounded space ishighly application specific due to the deletion pro-cedure.
We know from previous studies (Nicholset al, 2012) that a topic?s popularity within Twit-ter fades away over time.
We are interested inkeeping currently active topics and delete thosethat attract the least number of recent documents.This set-up has the interesting aspect that the doc-1771Algorithm F1 score Dot Products Runtime (sec)traditional approach 0.217 2.3 ?
10141.5 ?
107LSH-based tracking 0.196 (-10%) 1.4 ?
1014(-39%) 8.0 ?
106(-46%)cluster-based tracking 0.204 (-6%) 3.1 ?
1013(-86%) 2.5 ?
106(-83%)Table 5: Effectiveness and efficiency of LSH- and cluster-based tracking to the traditional approachAlgorithm Space F1 score dot products runtime (sec)LSH-based trackingunbounded 0.196 1.4 ?
10148.0 ?
106bounded 0.173 (-12%) 5.1 ?
1011(-99%) 4.1 ?
104(-99%)cluster-based trackingunbounded 0.204 3.1 ?
10132.5 ?
106bounded 0.189 (-7%) 1.8 ?
1011(-99%) 3.3 ?
104(-98%)Table 6: Effectiveness and efficiency for tracking in bounded and unbounded spaceument stream dictates the lifespan of each topicin the topic stream.
Table 6 contains the resultsof cluster- and LSH-based tracking and comparesthem to their bounded versions using the same setup.
Note that the hit in performance is solelydefined by the amount of memory provided andtherefore continuously adjustable.For this particular experiment, we chose an upperbound of 25k concurrent topics.
The table repre-sents a substantial drop in runtime, following thereduced search space, at a fairly low expense ineffectiveness.
Based on our observations, we hy-pothesise that significant topics are more likely tobe discussed during random Twitter chatter thanthe average Wikipedia topic.
It is interesting tonotice that the runtime also indicates a lower over-head for LSH-based tracking in comparison withthe cluster-based approach.
This difference washidden in the unbounded tracking experiments butcarries now more weight.7 ConclusionWe extended traditional topic tracking by demon-strating that it is possible to track an unboundedstream of topics in constant space and time.
Wealso presented two approaches to tracking, basedon LSH and clustering that efficiently scale to ahigh number of topics and documents while main-taining a level of effectiveness that is statisticallyindistinguishable from an exact tracking system.While they trade gains in efficiency against a lossin effectiveness, we showed that cluster basedtracking does so more efficiently due to more ef-fective space segmentation, which allows a higherreduction of the search space.
Contrary to com-mon believes this showed how nearest neighboursearch in data streams based on clustering per-forms faster than LSH, for the same level of accu-racy.
Furthermore, we showed that standard mea-sures of similarity (cosine) are sub-optimal whentracking Wikipedia against Twitter.ReferencesJames Allan, Victor Lavrenko, Daniella Malin, andRussell Swan.
2000.
Detections, bounds, and time-lines: Umass and tdt-3.
In Proceedings of Topic De-tection and Tracking Workshop, pages 167-174.James Allan, Ron Papka, and Victor Lavrenko.
1998.On-line new event detection and tracking.
In Pro-ceedings of the 21st annual international ACM SI-GIR conference on Research and development in in-formation retrieval (SIGIR ?98).
ACM, New York,NY, USA.James Allan.
2002.
Topic Detection and Track-ing: Event-Based Information Organization.
KluwerAcademic Publishers, Norwell, MA, USA.Mario Cataldi, Luigi Di Caro, and Claudio Schifanella.2010.
Emerging topic detection on Twitter based ontemporal and social terms evaluation.
In Proceedingsof the Tenth International Workshop on MultimediaData Mining, pages 1-10.
ACM.H.
Becker, M. Naaman, and L. Gravano.
2009.
EventIdentification in Social Media.
In 12th InternationalWorkshop on the Web and Databases (WebDB?09),Providence, USA.Moreno Carullo, Elisabetta Binaghi, Ignazio Gallo andNicola Lamberti.
2008.
?Clustering of short com-mercial documents for the web.?
Paper presented atthe meeting of the ICPR.Moses S. Charikar.
2002.
Similarity estimation tech-niques from rounding algorithms.
In Proceedings ofthe thirty-fourth annual ACM symposium on Theoryof computing (STOC ?02).
ACM, New York, NY,USA.Eichmann, D. and P. Sirivasan.
1999.
?Filters, Websand Answers: The University of Iowa TREC-8 Re-sults?
Eighth Conference on Text Retrieval, NIST,USA.1772Fiscus, J. G. and Doddington, G. R. 2002.
Topic detec-tion and tracking evaluation overview.
Topic detec-tion and tracking: event-based information organi-zation, pages 17-31.Saptarshi Ghosh, Muhammad Bilal Zafar, ParantapaBhattacharya, Naveen Sharma, Niloy Ganguly, andKrishna Gummadi.
2013.
On sampling the wisdomof crowds: random vs. expert sampling of the twit-ter stream.
In Proceedings of the 22nd ACM inter-national conference on Conference on information& knowledge management (CIKM-13).
New York,NY, USA.Aristides Gionis, Piotr Indyk, and Rajeev Motwani.1999.
Similarity Search in High Dimensions viaHashing.
InProceedings of the 25th InternationalConference on Very Large Data Bases (VLDB ?99),San Francisco, CA, USA.Sayyadi Hassan, Hurst Matthew and Maykov Alexey.2009.
?Event Detection and Tracking in SocialStreams.?
In Proceedings of the ICWSM, CA, USA.Yihong Hong, Yue Fei, and Jianwu Yang.
2013.
Ex-ploiting topic tracking in real-time tweet streams.
InProceedings of the 2013 international workshop onMining unstructured big data using natural languageprocessing.
ACM, New York, NY, USA.Piotr Indyk and Rajeev Motwani.
1998.
Approximatenearest neighbours: towards removing the curse ofdimensionality.
In Proceedings of the thirtieth an-nual ACM symposium on Theory of computing(STOC ?98).
ACM, New York, NY, USA.Jimmy Lin, Rion Snow, and William Morgan.
2011.Smoothing techniques for adaptive online languagemodels: topic tracking in tweet streams.
In Proceed-ings of the 17th ACM SIGKDD international con-ference on Knowledge discovery and data mining(KDD ?11).
ACM, New York, NY, USA, 422-429.S.
Muthukrishnan.
2005.
Data streams: Algorithms andapplications.
Now Publishers Inc.Jeffrey Nichols, Jalal Mahmud, and Clemens Drews.2012.
Summarizing sporting events using twitter.
In-Proceedings of the 2012 ACM international confer-ence on Intelligent User Interfaces (IUI ?12).
ACM,New York, NY, USA.Sasa Petrovic, Miles Osborne, and Victor Lavrenko.2010.
Streaming first story detection with applica-tion to Twitter.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics (HLT ?10).
Association for ComputationalLinguistics, Stroudsburg, PA, USA.Sasa Petrovic.
2013.
Real-time event detection in mas-sive streams.
Ph.D. thesis, School of Informatics,University of Edinburgh.Deepak Ravichandran, Patrick Pantel, and EduardHovy.
2005.
Randomized Algorithms and NLP: Us-ing Locality Sensitive Hash Functions for HighSpeed Noun Clustering.
In Proceedings of ACL.Raymond K. Pon, Alfonso F. Cardenas, David Buttler,and Terence Critchlow.
2007.
Tracking multiple top-ics for finding interesting articles.
In Proceedings ofthe 13th ACM SIGKDD international conference onKnowledge discovery and data mining (KDD ?07).ACM, New York, NY, USA.I.
Soboroff, I. Ounis, and J. Lin.
2012.
Overview of thetrec-2012 microblog track.
In Proceedings of TREC.Jintao Tang, Ting Wang, Qin Lu, Ji Wang, and WenjieLi.
2011.
A Wikipedia based semantic graph modelfor topic tracking in blogosphere.
In Proceedings ofthe Twenty-Second international joint conference onArtificial Intelligence - Volume Three (IJCAI?11).TDT by NIST - 1998-2004.http://www.itl.nist.gov/iad/mig/tests/tdt/resources.html (Last Update: 2008)Jianshu Weng, Erwin Leonardi, Francis Lee.
Event De-tection in Twitter.
2011.
In Proceeding of ICWSM.AAAI Press.Xintian Yang, Amol Ghoting, Yiye Ruan, and Srini-vasan Parthasarathy.
2012.
A framework for summa-rizing and analysing twitter feeds.
In Proceedings ofthe 18th ACM SIGKDD international conference onKnowledge discovery and data mining (KDD ?12).ACM, New York, NY, USA.1773
