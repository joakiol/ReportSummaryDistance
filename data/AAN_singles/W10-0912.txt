Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 96?104,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsAnalogical Dialogue Acts: Supporting Learning by Reading AnalogiesDavid BarbellaQualitative Reasoning GroupNorthwestern University2133 Sheridan Road, Evanston, IL, USAbarbella@u.northwestern.eduKenneth D. ForbusQualitative Reasoning GroupNorthwestern University2133 Sheridan Road, Evanston, IL, 60201, USAforbus@northwestern.eduAbstractAnalogy is heavily used in written explana-tions, particularly in instructional texts.
Weintroduce the concept of analogical dialogueacts (ADAs) which represent the roles utter-ances play in instructional analogies.
We de-scribe a catalog of such acts, based on ideasfrom structure-mapping theory.
We focus onthe operations that these acts lead to while un-derstanding instructional texts, using theStructure-Mapping Engine (SME) and dynam-ic case construction in a computational model.We test this model on a small corpus of in-structional analogies, expressed in simplifiedEnglish, which were understood via a semi-automatic natural language system using ana-logical dialogue acts.
The model enabled asystem to answer questions after understand-ing the analogies that it was not able to answerwithout them.1 IntroductionPeople use analogy heavily in written explanations.Instructional texts, for example, use analogy toconvey new concepts and systems of related ideasto learners.
Any learning by reading system mustultimately include the capability of understandingsuch analogies.
Here we combine Gentner?s(1983) structure-mapping theory with ideas fromdialogue act theory (Traum, 2000) to describe acatalog of analogical dialogue acts (ADAs) whichcapture the functional roles that discourse elementsplay in instructional analogies.
We outline criteriafor identifying ADAs in text and describe whatoperations they suggest for discourse processing.We provide evidence that this model captures im-portant aspects of understanding instructionalanalogies via a simulation that uses knowledgegleaned from reading instructional analogies toanswer questions.We start by reviewing the relevant aspects ofstructure-mapping theory and dialogue act theory.Then we describe our catalog of analogical dialo-gue acts, based on a theoretical analysis of theroles structure-mapping operations can play in lan-guage understanding.
A prototype implementationof these ideas is described next, followed by anexperiment illustrating that these ideas can be usedto understand analogies in text, based on answeringquestions.
We close with a discussion of relatedand future work.2 BackgroundDialogue act theories (also called speech acts(Allen & Perrault, 1980)) are concerned with theroles utterances play in discourse and the effectsthey have on the world or on understanding.
Anutterance identified as a Requesting Information,for example, might take the syntactic form of aquestion that makes the information requested ex-plicit, e.g.
?What time is it??
The surface manife-station might instead be a statement, or an indirectquestion, e.g.
?Do you have the time??
In otherwords, its classification is based on its function inthe dialogue and the set of operations it suggestsfor the recipient to undertake.
We claim that thereexists a set of analogical dialogue acts that are usedin communicating analogies.
Like other dialogueacts, they have criteria by which they can be rec-96ognized, and a set of implied commitments andobligations for the dialogue participants.
This pa-per focuses on instructional analogies in texts, bothbecause they are an important phenomenon andbecause it allows us to factor out follow-up ques-tions, making it a useful starting point.There are a wide variety of dialogue act models,but all of them include some variation of acts likeInform (Traum, 2000), which indicate the intent todescribe the state of the world.
The analogical di-alogue acts we discuss here can be viewed as spe-cializations of Inform.The organization of analogical dialogue acts fol-lows directly from the concepts of structure-mapping theory.
In structure-mapping, analogicalmatching takes as input two structured, relationalrepresentations, the base and target, and producesas output one or more mappings.
Each mappingconsists of a set of correspondences, identifyinghow entities and statements in the base align withentities and statements in the target.
Mappingsinclude a structural evaluation score providing anestimate of their overall quality.
This estimate isbased on systematicity, i.e., the amount of nestedrelational structure in the mapping, especiallyhigher-order relations that serve as inferential con-nections between other statements.
Causal, logi-cal, and mathematical statements are all examplesof higher-order relations.
Systematicity thusserves as a local heuristic measure of the explana-tory promise of a mapping.Mappings can also contain candidate inferences,statements in the base that are projected onto thetarget, using the correspondences of the mapping.The candidate inferences represent conjecturesabout the target, and constitute a source of analo-gy?s generative power.
Whether or not the candi-date inferences are in fact correct is evaluatedoutside of the matching process.
In discourse,candidate inferences are often used to convey newinformation about the target to the learner.
Candi-date inferences can be forward, from base to target,or reverse, from target to base.
Candidate infe-rences also represent differences between two re-presentations, when they cannot be consistentlyprojected from one description to the other.The Structure-Mapping Engine (SME, Falken-hainer et al1989) provides a simulation of analogi-cal matching.
SME typically produces only onemapping, but can produce a second or third map-ping if they are sufficiently close to the best map-ping.
SME can accept input about the base andtarget incrementally, updating its mappings as newinformation becomes available (Forbus et al1994),which can be important for modeling the incre-mental nature of discourse.
One cost of SME?sgreedy match algorithm and incremental operationis that matches can go awry.
Consequently, SMEalso supports a small set of constraints, optionallyspecified as part of the matcher?s input, whichguide it based on task constraints.
Here the rele-vant constraints are those concerning correspon-dences.
That is, given a base item bi and targetitem tj, either entities or statements, the followingconstraints are defined: required(bi tj) means that bimust correspond to tj in every mapping, and ex-cluded(bi tj) means that bi cannot correspond to tj inany mapping.
The following open constraints arealso defined: requiredBase(bi), means that some-thing in every mapping must correspond to bi, withrequiredTarget(tj) defined similarly.
excluded-Base(bi) means that bi cannot participate in anycorrespondence, with excludedTarget(tj) definedsimilarly.An important problem in understanding analogyin discourse concerns how the representations pro-vided to SME are constructed.
As described be-low, the representations that constitute anunderstanding of the text are produced in our mod-el via a semi-automatic natural language under-standing system, which reduces tailorability.
Inunderstanding instructional analogies, a learner isexpected to draw upon their existing world know-ledge.
In some situations, whole casesrepresenting a prior experience are retrieved frommemory.
In other situations, cases seem to be con-structed dynamically from one?s general know-ledge of the world.
We use dynamic caseconstruction methods (Mostek et al2000) to modelthis process.
In dynamic case construction, a seedentity or concept is provided as a starting point,and facts which mention it are gathered, perhapsfiltering by some criterion.
For example, ?Theeconomy of India?
might have India as its seed,and facts filtered based on their judged relevanceto economic matters.
When a reader is processingan instructional analogy, we believe that somethinglike this process is used to create representations tobe used in their understanding of the analogy.973 Analogical Dialogue ActsOur model of analogical dialog acts is based on ananalysis of how the functional constraints on per-forming analogical mapping and case constructioninteract with the properties of discourse.
To carryout an analogy, a reader must be able to infer thatan analogy is required.
They must understandwhat goes into the base and what goes into the tar-get, which can be complex because what is statedin the text typically needs to be combined with thereader?s own knowledge.
Since readers oftenknow quite a lot to begin with, figuring out whichsubset of what they know is relevant to the analogycan be complicated.
Finally, they have to under-stand how the author intends the mapping to go,since there can be multiple mappings between thesame domains.
Analogical dialogue acts, we ar-gue, provide readers with information that theyneed to perform these tasks.Let us examine this process in more detail.
To car-ry out an analogy, the contents of the base and tar-get representations must be identified.
Afundamental problem is that the reader must figureout an appropriate construal of the base and target,i.e., what subset of their knowledge should bebrought to bear in the current comparison?
Areader?s starting knowledge may or may not besufficient to guide the mapping process correctly,in order to reconstruct the mapping that the authorintended.
This is especially true in instructionalanalogies, of course.
We believe that this is whyone commonly finds explicit information aboutintended correspondences provided as part of in-structional analogies.
Such information provides asource of constraints that can be used to guide caseconstruction and mapping.
Similarly, and we be-lieve for similar reasons, the desired inferences tobe drawn from the analogy are often highlighted.Since there can be multiple construals (i.e., specificsets of facts retrieved) for the given base and tar-get, mentioning candidate inferences explicitlyprovides clues to the reader about how to construethe base and target (i.e., the given candidate infe-rence should be derivable) as well as informationabout its validity.Next we describe our proposed analogy dialogueacts.
For each act, we give an example, some cri-teria for identifying them, and describe what opera-tions a reader might do when they detect such anact has occurred.
At this point our focus has beenon developing the basic set and the operations theyentail, rather than on developing a comprehensiveset of identification criteria.
The first three acts areconcerned with introducing the representations tobe compared, and the rest are concerned with cor-respondences and candidate inferences.
We use agreenhouse/atmosphere analogy as a source of ex-amples.Introduce Comparison: Introduces a compari-son by providing both base and target.
For exam-ple, in ?We can understand the greenhouse effectby comparing it to what goes on in an actualgreenhouse.?
the base is a greenhouse, and the tar-get is the Earth?s atmosphere.
Recognizing an In-troduce Comparison can require combininginformation across multiple sentences.
In Figure 1,for example, the target is described in the para-graph above the point where the comparison is in-troduced.
Sometimes this intent must be inferredfrom parallel sentence structure in subsequent sen-Heat flows from one place to another because thetemperature of the two places is different.
A hotbrick loses heat to a cool room.
The temperaturedifference - the brick's temperature minus theroom's temperature ?
drives the heat from thebrick.
Heat leaks from the brick until the tempera-ture difference is gone.
No more heat flows fromthe brick when it becomes as cool as the room it isin.Similarly, a full can of water will leak volumefrom a hole in the side of the can.
The depth of thewater is higher than the depth of the hole, so thedepth difference drives volume out through thehole.Eventually, all the volume that can leak out doesso.
When this happens, the water depth has fallenso that it is the same as that of the hole.
There isno more depth difference, so no more volumeflows out through the hole.
Just as a difference intemperature causes heat to flow, so a difference indepth causes volume to flow.
When there is notemperature difference, heat flow ceases; whenthere is no depth difference, volume flow ceases.Extend TargetExtend BaseIntroduce ComparisonCandidate InferenceFigure 1: An analogy from our test corpus,hand-annotated with analogical dialogue acts.98tences and other sophisticated rhetorical devices,while in other cases, like this example, the compar-ison is introduced explicitly.What is the base and what is the target requires anon-local assessment about what the containingtext is about.
(This particular example is drawnfrom a book on solar energy, and the rest of thechapter makes clear that heat is the domain beingtaught.)
Since we assume that candidate inferencescan be constructed bidirectionally, an incorrectassessment is not catastrophic.Processing an Introduce Comparison act re-quires finding appropriate construals of the baseand target.
The target, as in this case, is con-strained by what has already been introduced in thetext.
The base, unless it has been used before inthe same text and is being used in a consistentmanner, must be constructed from the reader?sknowledge.
Whether this is done aggressively orlazily is, we suspect, a strategy that is subject toindividual variation.
Ambiguity in linguistic cuescan lead to the need to explore multiple construals,to find combinations with significant overlap.Extend Base, Extend Target: These acts addinformation to the base or target of a comparison,respectively.
Such acts are identified by relation-ships and/or entities being mentioned in the samestatement as an entity in the base or target, butwhich is not a statement about correspondences orcandidate inferences.
For example, ?The glass of agreenhouse lets the short solar rays through.?
isextending the base, and ?The earth?s atmosphereadmits most of the solar radiation.?
is an exampleof extending the target.
Entities that are mentionedin these acts are added to the construal of the case,if not there already, by retrieving additional know-ledge about them, focusing on statements involv-ing other entities in the current construal.
If thespecific facts mentioned are not already known tothe reader, they are provisionally accepted as beingtrue about the base or target, as appropriate.Introduce Correspondence: These acts provideclues as to the author?s intended mapping.
Forexample, ?The Earth?s atmosphere is like the glassin the greenhouse.?
indicates that ?Earth?s atmos-phere?
corresponds to ?glass in greenhouse?.
Dis-tinguishing these acts from introducing acomparison can be tricky, since ?is like?
is a syn-tactic pattern common to both.
The first occur-rence of ?is like?
in such cases is typically theintroduction of the base and target, with subse-quent statements introducing correspondences.Sometimes Introduce Correspondence acts are ex-pressed as identity statements, e.g.
?The glass isthe atmosphere.?
Sometimes these acts are sig-naled by pairs of sentences, one expressing a factabout the base followed immediately by one aboutthe target, with identical syntax.When an Introduce Correspondence act is de-tected, the base and target are checked to see ifthey already contain the entities or relationshipsmentioned.
If they do not, then the descriptionsare extended to include them.
The final step is in-troducing a required constraint between them aspart of the input to SME.
If mappings have al-ready been generated that are not consistent withthis constraint, they are discarded and new map-pings are generated.Block Correspondence:  These acts are pro-vided by the author to block a correspondence thata reader might otherwise find tempting.
An exam-ple is ?The greenhouse door is not like the hole inthe ozone layer.?
We believe that these acts arerelatively rare, and especially in written text com-pared with spoken dialogue, where there are oppor-tunities for feedback, a matter discussed later.When both a base and target item are men-tioned, an exclude constraint is introduced betweenthem.
When only one of them is mentioned, theminimal operation is to add an open exclusion con-straint (e.g.
excludedBase or excludedTarget).
Thereader may decide to simply remove the excludeditem from the construal, along with all of the factsthat mention it.
This would prevent it from beingmapped, but it would also prevent it from appear-ing in any candidate inferences, and hence is moreextreme.Introduce Candidate Inference: These actsalert the reader to information that the author in-tended to convey via the analogy.
An example is?Just as heat is trapped by the greenhouse roof,heat is trapped by the Earth?s atmosphere.?
Phras-es such as ?just as?
and ?just like?, or even ?Like<base statement to be projected>, <resulting can-didate inference>.?
are clues for identifying suchacts.
If the candidate inference can be found in themapping that the reader has built up so far, thenthat surmise should be given additional weight asbeing true.
(If it is already known by the reader, itmay already be part of a mapping.
This does notindicate failure, only that it is uninformative forthat reader.)
If the candidate inference cannot be99found, then there are several possibilities that areader should explore: Their construal of the baseand/or target might be too different from what theauthor expects, or they should generate a differentmapping.It is important to note that whether a statementcombining information from the base and target isconsidered an intended correspondence versus anintended candidate inference depends to some de-gree on the reader?s state of knowledge.
If the tar-get information is unknown, then for that reader, acandidate inference is being introduced.
A veryactive reader may ponder whether it would be acorrespondence for a more informed reader, andconversely, whether something an active and well-informed reader views as a correspondence mighthave been intended as a candidate inference.
Inboth cases, considering the alternate classificationwould affect the reader?s judgment of informative-ness, so the distinction between these two types ofacts is useful to make.
Candidate inferencesrepresent the point of the analogy, what it was setup to convey, and hence distinguishing them seemsimportant.Block Candidate Inference: These acts alertthe reader that an inference that they are likely tomake is not in fact correct.
For example, ?Unlikesolar radiation, radiation heat flow reacts in thesame way to different colors.?
If the candidateinference is part of the reader?s mapping, thenthese acts indicate that the reader should markthem as incorrect.
A reader with an aggressiveprocessing style who did not generate this infe-rence might explore modifications of their baseand/or target to see if they can generate that infe-rence, thereby ensuring they are more in sync withthe author?s intentions and thus better able toprocess subsequent statements.
These acts aresometimes identifiable by terms such as ?unlike,??however,?
or ?you might expect?
but?
whichinclude one clause expressing information aboutthe base and one clause expressing informationabout the target.
We believe that, like Block Cor-respondence, these occur relatively infrequently.4 A prototype implementationTo explore the utility of our analogical dialogueacts theory, we implemented a simple computa-tional model which uses ADAs to learn from in-structional texts and answer questions based onwhat it has learned, synthesized with what it al-ready knows (Figure 1).
Our model uses the FIREreasoning engine, which incorporates SME.
Theknowledge base contents are extracted from Re-searchCyc1 and extended with other knowledge,including an analogy ontology that lets analogyoperations and other forms of reasoning be freelymixed (Forbus et al2002).
In addition to the natu-ral language lexical information built into Re-searchCyc, we also use the COMLEX lexicon(Macleod et al1998) for part of speech and subcatinformation.
For natural language understanding,we use EA NLU (Tomai & Forbus, 2009), whichalso uses FIRE and the same knowledge base.
EANLU uses Allen?s (1994) parser for syntacticprocessing and construction of initial semantic re-presentations.
It uses Discourse RepresentationTheory (Kamp & Reyle, 1993) for dealing withtense, quotation, logical and numerical quantifica-tion, and counterfactuals.EA NLU is useful for this type of learning byreading experiment because it focuses on generat-ing rich semantic representations.
It does so at theexpense of syntactic coverage: We restrict inputssyntactically, using QRG-CE (Kuehne & Forbus,2004), a form of simplified English much like CPL(Clark et al2005).
For example, complex sen-1 http://research.cyc.comSource Text Translation* QRG-CE TextEA NLUSemantic RepresentationDiscourseInterpretationADAHypothesesRecognitionRulesBuild Base andTargetBuild RequiredCorrespondencesRequiredCorrespondencesCasesFacts fromMemoryDynamic CaseConstructionSME CandidateInferencesQuestionAnsweringComprehensionQuestions Translation* QueriesAnswersFigure 2: Architecture of the experimental prototype.
Processes performed by hand are marked with an asterisk.100tences are broken up into a number of shorter,simpler sentences.
Explicit object references (e.g.
?the greenhouse greenhouse12?
every time thesame greenhouse is mentioned) are used to factorout the difficulty of anaphora resolution.
EA NLUprovides facilities for semi-automatic processing;In this mode, the ambiguities it cannot resolve onits own are presented as choices to the experimen-ter.
This keeps tailorability low, while allowingthe system to process more complex texts.As noted above, we do not yet have a robustmodel of identification criteria for analogical di-alogue acts, so we extended EA NLU?s grammarto have at least one naturally occurring pattern forevery ADA.
As part of the translation to QRG-CE,texts are rewritten to use those patterns when weview an analogical dialogue act as being present.This allows the system to automatically classifyADAs during processing.
Here our goal is to mod-el the processing that must take place once suchacts are recognized, since identifying such acts isirrelevant if they are not useful for reasoning.
EANLU?s parsing system produces semantic repre-sentations used in its discourse interpretationprocessing.
The ADA recognition rules are usedalong with EA NLU?s standard discourse interpre-tation rules to generate ADA hypotheses as part ofits discourse representations (Figure 1).We believe that there are significant individualdifferences in processing strategies for these acts.For example, some people seem to be quite aggres-sive about building up mappings, whereas othersappear to do minimal work.
Consequently, wehave started with the simplest possible approach.Here is what our simulation currently does for eachof the types of acts:Introduce Comparison: Builds initial con-struals of the base and the target by retrieving rele-vant facts from the knowledge base2.Extend Base/Extend Target: The understand-ing of the sentence is added to the base or target, asappropriate.
This decision is made by keepingtrack of the concepts that are mentioned by state-ments in each domain, starting with the IntroduceComparison act.Introduce Correspondence: A required corres-pondence constraint is introduced for the entities2 We use a case constructor similar to CaseFn from Mosteket al2000, but including automatic expansion of rule macropredicates and using microtheory information for filtering.involved, to be used when SME is run for thisanalogy.Introduce Candidate Inference: The informa-tion in these statements is simply treated as a factabout the target domain.
We do not currentlychange the mapping if a candidate inference in textis not part of the mapping computed.Block Correspondence/Candidate Inference:Not implemented currently, because examples ofthese did not show up in our initial corpus.Analogical dialogue acts are identified via infe-rence rules that are run over the discourse-levelinterpretation that EA NLU produces.
Analogicalmapping occurs only at the end of processing atext, rather than incrementally.
Statements aboutthe base and target are accepted uncritically, ratherthan being tested for inconsistencies against back-ground knowledge.
These simplificationsrepresent one point in the possible space of strate-gies that people seem likely to use; plans to ex-plore other strategies are discussed below.Once the ADA hypotheses are used to constructthe base and target domain and the required cor-respondences between them, this information isused by SME to generate candidate inferences -statements that might be true on the basis of theanalogy constructed.
The base and target case areexpanded using dynamic case construction, whichadds knowledge from the KB to fill in informationthat the text leaves out.
For example, a text maynot explicitly mention that rain falls from the skyto the earth, taking it as a given that the reader isaware of this.5 ExperimentAn essential test for a theory of analogy dialogueacts is whether or not it can be used to constructnew knowledge from instructional analogies intext.
To test this, we extracted a small corpus of 6instructional analogies from a book on solar energy(Buckley, 1979) and a book on weather (Lehr et alExample #O #AGold mining/Collecting solar energy 8 11Water flow/heat flow 11 12depth of water in bucket/temperature of house 8 16Bucket with hole/house leaking heat 4 10Bucket/Solar collector 5 8Earth?s atmosphere/greenhouse 7 14Mean 7.2 11.8Table 1: Corpus Information.
#O/#A = # sen-tences before/after translation to QRG-CE101Condition # correct %-A, -K 0 0+A, -K 7 58-A, +K 0 0+A, +K 12 100Table 2: Results for Q/A.
+/- meanswith/without, A means analogy, Kmeans facts retrieved from KB1987).
We simplified the syntax of the originaltexts into QRG-CE, using the appropriate surfaceforms for the analogy dialogue acts that we per-ceived in the text.
One of the analogies is illu-strated in Figure 1, with part of its translation isshown in Figure 3.
Table 1 summarizes propertiesof the original texts and the simplification process.To test the effectiveness of knowledge capture,12 comprehension questions similar to those foundin middle-school science texts were generated byindependent readers of the texts (see Figure 4 foran example).
All questions were designed to re-quire understanding the analogy in order to answerthem.
Moreover, some of the questions requirecombining information from the knowledge basewith knowledge gleaned from the text.Four experimental conditions were run, basedon a 2x2 design here the factors were whether ornot analogy was used (+A) or not used (-A), andwhether what was learned from the text was aug-mented with information from the knowledge base(+K) or not (-K).Table 2 shows the results.
The system was ableto answer all twelve questions when it understoodthe analogy and combined what it learned by read-ing with information from the knowledge base.That this was due to understanding the analogy canbe seen from the other conditions.
The informa-tion from the text alone is insufficient to answerany of the questions (-A, -K), as is the informationfrom the KB alone (-A, +K).
Analogy by itselfover what was learned by reading the passages canhandle over half the questions (+A, -K), but therest require combining facts learned by readingwith facts from the KB (+A, +K).6 Related WorkThere has been very little work on modeling anal-ogies in dialogue.
One of the few efforts has beenLulis & Evans (2003), who examined the use ofanalogies by human tutors for potential extensionsto their intelligent tutoring system for cardiac func-tion.
Recently they have begun incorporatinganalogies into their tutor (Lulis, Evans, & Michael,2004), but they have not focused on understandingnovel analogies presented via language.Because EA NLU is designed to explore issuesof understanding, it is focused more on semanticcoverage than on syntactic coverage.
The mostsimilar system is Boeing?s BLUE (Clark & Harri-son, 2008), which also uses simplified syntax andfocuses on integrating language with a knowledgebase and reasoning.Aside from SME, we suspect that the only othercurrent widely tested model of analogy that mightbe able to handle this task is IAM (Keane & Bray-shaw 1988).
CAB (Larkey & Love 2003) does notmodel inference, and hence could not model thistask.
Although LISA (Hummel & Holyoak, 2003)can model some analogical inferences, the numberof relations (see Table 3) in these analogies isbeyond the number of relationships it can currentlyhandle (2 or 3).The first simulation of analogy to use naturallanguage input was Winston?s (1982, 1986), whichused a simple domain-specific parser in modelingthe learning of if-then rules and censors.
EA NLUOriginal: Similarly, a full can of water will leakvolume from a hole in the side of the can.QRG-CE: A hot brick brick005 is like a cancan001 of water water001.
There is a hole hole001in can can001.
The water water001 exits cancan001 through hole hole001.Figure 3: Example of translation to QRG-CE.The specific individuals are added to factor outanaphora processing.
Cues to analogical dialo-gue acts spread across multiple sentences in theoriginal text are combined into single sentencesduring the translation process.Question: What disappears as the heat leaks from thebrick?Predicate calculus version:(and(inputsDestroyed ?d ?ourAnswer)(after-Underspecified ?d ?leaving)(objectMoving ?leaving heat005)(isa ?heat ThermalEnergy)(isa ?leaving LeavingAPlace)(fromLocation ?leaving brick005))Figure 4: A question for the analogy of Figure1, in English and the hand-generated predicatecalculus generated from it.102benefits from subsequent progress in natural lan-guage research, enabling it to handle a wider rangeof phenomena.7 Discussion and Future WorkModeling the roles that analogy plays in under-standing language is an important problem inlearning by reading.
This paper is an initial explo-ration of how analogy can be integrated into dialo-gue act theories, focusing on instructionalanalogies in text.
We presented a catalog of ana-logical dialogue acts, based on an analysis of howthe functional constraints of analogical mappingand case construction interact with the propertiesof discourse.
We showed that a simulation usingthese ideas, combined with a natural language un-derstanding system to semi-automatically produceinput representations, can indeed learn informationfrom simplified English analogies, which is en-couraging evidence for these ideas.The next step is to expand the corpus substan-tially, including more examples of all the ADAs, tobetter test our model.
We also need to implementthe rest of the ADAs, and experiment with a widerrange of processing strategies.To better model how ADAs can be identified innatural texts, we plan to use a large-scale web-based corpus analysis.
We have focused on texthere, but we believe that these ideas apply to spo-ken dialogue as well.
We predict more opportuni-ties for blocking in spoken dialogue, due toopportunities for feedback.Our goal is to incorporate these ideas into a 2ndgeneration learning by reading system (e.g., Forbuset al2007; Forbus et al2009a), along with otherdialogue processing, to better interpret larger-scaletexts (e.g., Lockwood & Forbus, 2009).
This willbe built using the Companions cognitive architec-ture (Forbus et al2009b), to more easily model awider range of processing strategies, and so thatthe system can learn to improve its interpretationprocesses.AcknowledgmentsThis research was supported by the Intelligent andAutonomous Systems Program of the Office ofNaval Research.ReferencesAllen, J.F.
(1994).
Natural Language Understanding.
(2nd Ed.)
Redwood City, CA: Benjamin/Cummings.Allen, J. F. & C. R. Perrault (1980).
Analyzing Intentionin Utterances.
Artificial Intelligence 15(3).Buckley, S. (1979).
From Sun Up to Sun Down.
NewYork: McGraw-Hill.Clark, P. & Harrison, P. (2008).
Boeing?s NLP systemand the challenges of semantic representationClark, P., Harrison, P., Jenkins, T., Thompson, J.
&Wojcik, R. (2005).
Acquiring and using world know-ledge using a restricted subset of English.
18th In-ternational FLAIRS Conference.Falkenhainer, B., Forbus, K. & Gentner, D. (1989).
TheStructure-Mapping Engine: Algorithms and Exam-ples.
Artificial Intelligence, 41, 1-63.Forbus, K., Ferguson, R. & Gentner, D. (1994) Incre-mental structure-mapping.
Proceedings of CogSci94.Forbus, K., Lockwood, K. & Sharma, A.
(2009).
Stepstowards a 2nd generation learning by reading system.AAAI Spring Symposium on Learning by Reading,Spring 2009.Forbus, K., Klenk, M., & Hinrichs, T. , (2009).
Compa-nion Cognitive Systems: Design Goals and LessonsLearned So Far.
IEEE Intelligent Systems, vol.
24,no.
4, pp.
36-46, July/August.Forbus, K., Mostek, T. & Ferguson, R. (2002).
An anal-ogy ontology for integrating analogical processingand first-principles reasoning.
Proceedings of IAAI-02, July.Forbus, K. Riesbeck, C., Birnbaum, L., Livingston, K.,Sharma, A., & Ureel, L. (2007).
Integrating naturallanguage, knowledge representation and reasoning,and analogical processing to learn by reading.
Pro-ceedings of AAAI-07 Vancouver, BC.Example #S #BA #BR #TA #TRGold mining/Collectingsolar energy8 26 32 4 4Water flow/heat flow 11 14 21 13 16depth of water in buck-et/temperature of house8 12 19 9 12Bucket with hole/houseleaking heat4 14 20 8 6Bucket/Solar collector 5 13 15 4 4Earth?s atmos-phere/greenhouse7 12 19 11 14Mean 7.2 15.2 21 8.2 9.3Table 3: Statistics of base and target domainsproduced by EA NLU.
#S = number of sen-tences, B/T = Base, Target; A/T =Attributes/Relations103Gentner, D. (1983).
Structure-Mapping: A TheoreticalFramework for Analogy.
Cognitive Science, 7: 155-170.Gentner, D., Bowdle, B., Wolff, P., & Boronat, C.(2001).
Metaphor is like analogy.
In Gentner, D.,Holyoak, K., and Kokinov, B.
(Eds.)
The analogicalmind: Perspective from cognitive science.
pp.
199-253, Cambridge, MA: MIT Press.Hummel, J. E., & Holyoak, K. J.
(2003).
A symbolic-connectionist theory of relational inference and gene-ralization.
Psychological Review, 110, 220-264.Kamp, H. & Reyle, U.
(1993).
From Discourse to Log-ic: Introduction to Model-theoretic Semantics ofNatural Language.
Kluwer Academic Dordrecht:Boston.Keane, M., and Brayshaw, M. (1988).
The IncrementalAnalogy machine: A computational model of analo-gy.
European Working Session on Learning.Larkey, L. & Love, B.
(2003).
CAB: ConnectionistAnalogy Builder.
Cognitive Science 27,781-794.Lehr, P. E., Burnett, R. W., & Zim, H. S. (1987).Weather.
New York, NY: Golden Books PublishingCompany, Inc.Lockwood, K. & Forbus, K. 2009.
Multimodal know-ledge capture from text and diagrams.
Proceedingsof KCAP-2009.Lulis, E. & Evans, M. (2003).
The use of analogies inhuman tutoring dialogues.
AAAI Technical ReportSS-03-06.Lulis, E., Evans, M. & Michael, J.
(2004).
Implement-ing analogies in an electronic tutoring system.
InLecture Notes in Computer Science, Vol 3220, pp.228-231, Springer Berlin/Heidelberg.Macleod, C., Grisham, R., & Meyers, A.
(1998).COMLEX Syntax Reference Manual, Version 3.0.Linguistic Data Consortium, University of Pennsyl-vania: Philadelphia, PA.Mostek, T., Forbus, K, & Meverden, C. (2000).
Dynam-ic case creation and expansion for analogical reason-ing.
Proceedings of AAAI-2000.
Austin, TX.Tomai, E. & Forbus, K. (2009).
EA NLU: PracticalLanguage Understanding for Cognitive Modeling.Proceedings of the 22nd International Florida Artifi-cial Intelligence Research Society Conference.
Sani-bel Island, Florida.Traum, David R. (2000).
20 Questions on Dialogue ActTaxonomies.
Journal of Semantics, 17, 7-30.Winston, P.H.
1982.
Learning new principles from pre-cedents and exercises.
Artificial Intelligence 23(12).Winston, P. 1986.
Learning by augmenting rules andaccumulating censors.
In Michalski, R., Carbonell, J.and Mitchell, T.
(Eds.)
Machine Learning: An Artifi-cial Intelligence Approach, Volume 2.
Pp.
45-62.Morgan-Kaufman.104
