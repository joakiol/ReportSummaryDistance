Unificational Combinatory Categorial Grammar:Combining Information Structure and Discourse RepresentationsMaarika TraatThe University of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW,United Kingdom,M.Traat@ed.ac.ukJohan BosThe University of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW,United Kingdom,jbos@inf.ed.ac.ukAbstractIn this paper we present a grammar formalism thatcombines the insights from Combinatory CategorialGrammar with feature structure unification.
Weshow how information structure can be incorporatedwith syntactic and semantic representations in aprincipled way.
We focus on the way theme, rheme,and focus are integrated in the compositional se-mantics, using Discourse Representation Theory asfirst-order semantic theory.
UCCG can be used forparsing and generating prosodically annotated text,and therefore has the potential to advance spokendialogue systems.1 IntroductionThe integration of information structure (theway information is ?packaged?
in a sentence)in practical formalisms in computational lin-guistics has long been ignored.
There are twomain reasons for this: (1) formalisations of in-formation structure often use variants of higher-order logic to characterise its semantic impact(Krifka, 1993; Kruijff-Korbayova, 1998; Steed-man, 2000), which limits the use of inferencein practice (Blackburn and Bos, 2003); and (2)the effect of information structure on the com-positional semantics of an utterance is rarelyworked out in enough detail useful for compu-tational implementation.
On the other hand,exploring information structure in spoken dia-logue systems is becoming realistic now becauseof the recent advances made in text-to-speechsynthesisers and automated speech recognisers?
hence there is a growing need for computa-tional implementations of information structurein grammar formalisms.In this paper we present Unificational Com-binatory Categorial Grammar (UCCG), whichintegrates aspects of Combinatory CategorialGrammar (Steedman, 2000), Unification Cat-egorial Grammar (Zeevat, 1988; Calder et al,1988), and Discourse Representation Theory(Kamp and Reyle, 1993).
It offers a compo-sitional analysis of information structure, a se-mantics compatible with first-order logic, anda computational implementation for a fragmentof English, using unification in combining gram-matical categories.
As we will show, this makesUCCG easy to implement, and allows us to in-tegrate prosodic information in the semanticsin a transparent and systematic way.
Althoughbased on first-order logic, we claim that UCCGhas enough expressive power to model informa-tion structure such that it has the potential toimprove speech generation with context appro-priate intonation in spoken dialogue systems.2 BackgroundCategorial Grammars (CG) (Wood, 2000) arelexicalised theories of grammar.
The notion of?category?
refers to the functional type that isassociated with each entry in the lexicon whichdetermines the ability of a lexical item to com-bine with other lexical items.
CGs also havea set of rules defining the syntactico-semanticoperations that can be performed on the cate-gories.Combinatory Categorial Grammar (CCG) isa generalisation of CG (Steedman, 2000).
Whilethe pure CG only involved functional applica-tion rules for combining categories, CCG intro-duces several additional combinatory rules forboth syntactic and semantic composition ?
for-ward and backward composition, and crossedcomposition, as well as substitution rules.
Asa result, CCG covers a wide range of linguis-tic phenomena, including various kinds of coor-dination.
For building semantic representationCCG uses the lambda calculus, although uni-fication has been proposed as well (Steedman,1990).
Moreover, CCG has a built-in theoryof intonation and information structure (Steed-man, 2000), that we will use as the basis for ourcomputational treatment of theme, rheme andfocus.Unification Categorial Grammar (UCG) usesHead-Driven Phrase Structure Grammar typeof feature structures, called signs, to representthe categories of lexical items (Zeevat, 1988;Calder et al, 1988).
The directionality of theattributes of a functor category is marked bythe features pre and post on its attributes ratherthan by the directionality of the slashes as itis done in CCG.
In contrast to CCG, UCGonly uses forward and backward applicationas means for combining categories.
The useof signs makes it straightforward to define thesyntax-semantic interface.The formalism that we introduce in this pa-per, UCCG, aims to marry the best parts ofCCG and UCG.
Following UCG, we use signsto represent the linguistic data, and both se-mantics and syntax are built up simultaneouslyvia unification.
From CCG we inherit the di-rectional slash notation, the additional com-binatory rules, and the analysis of intonation.UCCG employs DRT (Kamp and Reyle, 1993)with neo-davidsonian style event semantics assemantic formalism, but extends the basic DRSlanguage to allow integration of prosodic infor-mation in syntactic and semantic analysis.3 Unificational CCG3.1 SignsUCCG makes use of feature structures calledsigns in its linguistic description.
There are twotypes of signs: basic and complex signs.
A basicsign is a list of attributes or features describingthe syntactic and semantic characteristics ofa lexical expression, in the spirit of UCG.We deviate from UCG in the way we definecomplex signs, which is done recursively:?
If X and Y are signs then X/Y is a com-plex sign.?
If X and Y are signs X\Y is a complexsign.?
All basic and complex signs are signs.A basic sign can have a varied number offeatures, depending on the syntactic categoryof the lexical expression the sign is character-ising.
There are three obligatory features anysign must have, namely pho, cat and drs.
phostands for the phonological form, cat for thesyntactic category of the lexical expression, anddrs for its semantical representation.
Besidesthe above three a sign can also have the follow-ing features:1?
agr to mark the inflectional characteristicsof categories;?
var for discourse referents ranging over in-dividuals;?
sit for discourse referents ranging overeventualities (events or states).In our notation inside the feature structureswe use the following convention: constants startwith a lower case letter, and variables start withan upper case letter.
The feature names arewritten using small capitals.
To make the fea-ture structures more easily readable we narrowthe choice of possible variable names for eachtype of variables:?
(pho) variables: W, W1, W2, etc.?
(agr) variables: A, A1, A2, etc.?
(drs) variables: D, D1, D2, etc.?
(sit) variables: E, E1, E2, etc.?
Discourse referents (var) use any othercapital letter with the preference for thecharacters towards the end of the alphabet.There are three kinds of basic signs in UCCG,corresponding to the basic categories ?
thosewith cat feature sentence (s), those with catfeature noun (n), and those with cat featureverb phrase (vp).
A basic sign for verb phrasesis shown in (1), and a complex sign for nounphrases is shown in (2).(1)?????????????
?pho: walkscat: vpagr: finvar: Xsit: Edrs:Ewalk(E)agent(E,X)??????????????(2)????????
?pho: every+man+Wcat: sdrs: Xman(X)?D?????????/???????
?pho: Wcat: vpagr: finvar: Xsit:drs: D???????
?1Depending of the needs of a specific application andlanguage for which a UCCG grammar is constructedmany more features could be introduced in basic signs.The above examples illustrate the role of uni-fication by creating a link between syntax andsemantics.
UCCG explores the fact that thesame variables can be used at several differentlevels.
For example, the variables standing fordiscourse referents serve as a link between syn-tax and semantics ?
the variable in the varfeature in the feature structure fits into its cor-responding slot in the DRS in the drs feature.We use this technique to integrate informationstructure as well.3.2 CategoriesEach sign corresponds to a related CCG cate-gory.
The category of a basic sign is the value ofits cat feature.
The category of a complex signit is made up of the cat feature values of all thecomponent parts of the complex sign, separatedby the slashes and brackets used in the complexsign, resulting in a complex category.
For in-stance, the the syntactic category of the sign in(1) is vp, and in (2) the category is s/vp.
Thethree basic categories used in UCCG are thus s,n and vp, while all other categories are formedby combining the above three, using backwardand forward slashes.Note that noun phrase is not among the basiccategories.
In UCCG We use its ?type-raised?variant s/vp (corresponding to the CCG cate-gory s/(s\np)).
This choice is motivated by theneed to determine quantifier scope in the se-mantics of quantified noun phrases.
The some-what unconventional basic category vp is a by-product of the above.3.3 Feature ValuesIn order to make it easier to refer to parts ofcomplex signs later, we introduce the followingterminology:?
X is the result of a sign X/Y or X\Y.?
Y is the argument of a sign X/Y or X\Y.The value of the var and the sit featuresis always a variable, while other features canhave a number of constant values.
The pho fea-ture holds the string value of the linguistic ex-pression represented by the given feature struc-ture.
Presently, we use the orthographic formof words.
In basic signs the pho feature is filledby lexical items, in complex signs it also con-tains variables, which get constant values whenthe complex sign is combined with its argumentsigns.
The pho feature in result parts of com-plex signs is of the form:.
.
.
+ W1 + word + W2 + .
.
.where word is a lexical item, and W1 and W2are variables that get values through unificationin the categorial combination process.
The itemunifying with W1 precedes and the one unifyingwith W2 follows the lexical item word.
The ex-act number and order of the variables the phofeature contains depends on the category of thegiven sign.In the present implementation the agr fea-ture is only used in connection with verb phrasesand can take constant values fin (finite) or non-fin (non finite).The drs feature, if it is not a variable itself,holds a DRS corresponding to the semantics ofthe lexical item(s) characterised by the givensign.
DRSs are constructed in a compositionalway using the var and sit features of the signto take care of predicate argument structure,and the merge operator (;) to construct largerDRSs from smaller ones.
Merge-reduction isused to eliminate merge operators introducedin the composition process.
This is also thestage where discourse referents are renamed toavoid accidental clashes of variables introducedby unification (Blackburn and Bos, 2003).3.4 The Combinatory RulesPresently we have introduced the following fourCCG combinatory rules in UCCG: forwardapplication, backward application, forwardcomposition, and backward composition.Other CCG combinatory rules could be intro-duced equally easily should the need arise.X/Y Y =?
XForward application ????
?>Y X\Y =?
XBackward application <????
?X/Y Y/Z =?
X/ZForward composition ??
?Comp>Y\Z X\Y =?
X\ZBackward composition <Comp???
?The rule boxes above are to be interpreted inthe following way: in the first row there is therule, on the left in the second row there is thename of the rule and on the right the markingfor it as used in the derivations.
The variablesX, Y and Z in the rules above stand for (basicor complex) signs.Some of the combinatory rules can be seen inaction on UCCG signs in Figures 1 to 3 below.4 Adding Information StructureBy information structure we mean the way in-formation is packaged in a sentence.
We use theterms theme and rheme as introduced by thePrague circle of linguists.
Theme is the centralquestion or topic the sentence is about, whilerheme is the novel contribution of the sentence.In many languages, including English,prosody is the main means of indicating the in-formation structure of the sentence.
In otherlanguages additional or alternative means maybe available, such as word order, and the useof specific lexical items.
Example (3) illustratesthe connection between information structureand prosody in English.
(3) Who taught Alexander the Great?
[ARISTOTLE]rh [taught Alexander the Great.]th?
[Aristotle taught]th[ALEXANDER the GREAT.
]rhThe lexical items in capital letters in (3) carrythe main rhematic accent of the sentence.
Asillustrated by this example, the placement ofthis accent determines whether the answer givento the question is appropriate or not.4.1 Information Structure in CCGSteedman introduces information structure asan integral part of the CCG formalism (Steed-man, 2000).
He argues that there is a specificset of pitch accents in English that can accom-pany theme, and another set that accompanyrheme, the most common theme pitch accentbeing L+H* and the most common rheme pitchaccent being H*.2 The main pitch accent of theintonational phrase combined with a boundarytone gives us a complete intonational phrase.There are various boundary tones, the mostfrequently occurring ones being a low boundaryLL% and a rising boundary LH%.
There is atendency for LH% to occur at the end of anintonational phrase containing the theme pitchaccent L+H*, and for LL% to occur after therheme pitch accent H*.According to the prosodical phrasing, CCGprovides different parses for the same stringof words, giving rise to different interpretationwith respect to information structure:2The intonational notation used is due to Pierrehum-bert (Pierrehumbert, 1980).
According to her intona-tional phrases are made up of the following components:pitch accent(s), phrasal tone and boundary tone.
InSteedman?s (Steedman, 2000) representation the last twohave been joined together under the name ?boundarytone?.
L stands for low pitch, and H for high pitch.
(4) AnnaH* LL%married Manny.L+H* LH%Annamarried Manny(5) AnnaL+H*marriedLH%Manny.H* LL%Anna marriedMannyParsing according to intonational phrasingin CCG is achieved in the following way: thecategories of lexical items can be either thememarked by a theme accent, rheme marked by arheme accent, or unmarked (i.e., unaccented).Theme and rheme marked categories can freelycombine with adjacent categories with the samemarking or adjacent categories with no intona-tional marking.
If a theme or rheme markedcategory combines with an intonationally un-marked category, the result category inheritsthe themeness or rhemeness from the markedcategory that participated in the combinationprocess.While pitch accents are seen as propertiesof words that carry them, boundary tones areseen as individual lexical entries, and have theirown category of the form S$?\S$?/?, whereS$ is a variable that stands for any cate-gory that is a function whose result is S (i.e.,sentence), ?
stands for phrase, ?
for themeand ?
for rheme (Steedman, 2000).
The ef-fect this category achieves is copying the cat-egory to its left it combines with, and replac-ing its intonational marking by phrase.
Phrasemarked categories can only combine with otherphrase marked categories, and hence avoid com-bination over intonational phrase boundaries.In other words, boundary tones function like?stoppers?
of theme and rheme categories, pre-venting theme and rheme to be further spreadalong sub-phrases of the sentence.4.2 Information Structure in UCCGWhen introducing prosodical and information-structural features to UCCG we follow the the-ory of CCG, with a few exeptions.
As wealso aim to derive a computational implemen-tation of UCCG in the form of a parser we needto be concrete about how sign unification inUCCG interacts with CCG?s theory of informa-tion structure.Adding intonation to UCCG raises severalproblems, as combination of signs only viastraighforward unification is not possible anymore.
We have to give prosodical signs the abil-ity to alter prosodical feature values in the re-sult signs they produce when combining witha lexical sign.
We will do this using recursiveunification?the details of this process will bediscussed in Sections 4.3 and 4.4.Integrating information structure with theUCCG sign representation brought along someadditions.
Firstly, we introduce two new fea-tures in the sign.
The first of them is called infand expresses information structure.
It can ei-ther be a variable ?
in the case of unmarkedexpressions, or it can take the following values ?
(theme), ?
(rheme), or ?
(phrase).
The secondnewly introduced feature is foc.
This featureindicates focus, i.e.
whether the particular wordcarries a pitch accent or not.
This feature is onlypresent on lexical signs.The second change involves introducing in-formation structural labels on DRS conditions(except on those expressing the semantic roles ofverbs).
The labels are of the form Cond:Inf Foc,where Cond is a DRS condition, Inf stands forthe information-structure value (?, ?, or ?
), andFoc for the value of the focus (+ or ?).
Theinformation-structure label in the DRS is tiedto the inf feature through the use of the samevariable, and gets its constant value from thefeature by unification.4.3 Pitch AccentsCCG views pitch accents as properties of wordsand introduces multiple entries for each lexicalitem in the lexicon, whether it is theme marked,rheme marked, or unmarked.
We do not opposeCCG?s view of pitch accents, but we chose aslightly different approach in UCCG: pitch ac-cents get similar treatment as boundary tones?
they are independent entries in the lexicon.This way we avoid having to expand the lexi-con.
For instance, the lexical sign for the propername Manny is shown in (6).(6)????????
?pho: Manny+Wcat: sinf: Ifoc: Fdrs:Xmanny(X):I F;D?????????/?????????
?pho: Wcat: vpvar: Xsit: Einf: Ifoc: Fdrs: D?????????
?Like all lexical signs, the sign in (6) showsthat the values for foc and inf are still unin-stantiated.
Once it combines with the sign fora pitch accent, both of these features will getinstantiated.
For example, (7) shows the resultof combining the above lexical sign with a thesign for L+H*:(7)?????
?pho: Manny+Wcat: sinf: ?drs:Xmanny(X):?+;D??????/???????
?pho: Wcat: vpvar: Xsit: Einf: Idrs: D???????
?Note that signs for pitch accents need to becombined first with the signs of the lexical itemsthe accents appear on.
Otherwise it would beimpossible to tell which item actually carriesthe accent for larger phrases such as marriedManny H* LL% , where without the above men-tioned constraint we could combine married andManny first to form the unit married Manny ,and only then combine this two word unit withthe pitch accent.
However, this is not what wewant, because this way we cannot determineany more which of the two words was accented.Note also, that the foc feature only appears inlexical signs.So what does a sign for pitch accents looklike?
Borrowing from Steedman?s notation, thesign for L+H* has the following format:(8)???????
?pho: Wcat: Cvar: Xsit: Einf: ?drs: D???????
?$ \?????????
?pho: Wcat: Cvar: Xsit: Einf: ?foc: +drs: D?????????
?$The idea behind the sign in (8) is the fol-lowing: the sign X$ stands for unification of Xwith a (basic or complex) sign.
In the case ofbasic signs, ordinary unification on the level ofsigns applies, in the case of complex signs, uni-fication of S also applies to sub-signs.
Throughunification of variables the information struc-tural marking also finds its way to the DRS inthe form of labels on the appropriate DRS con-ditions.Combining the sign for ?Manny?
(6) with thesign for the theme accent ?L+H*?
(8) results inthe unit ?Manny L+H*?, shown in (7).
Noticehow through unification also the information??????
?pho: married+W1cat: vpvar: Zsit: Einf: Idrs: D1???????/(??
?pho: W1+W2cat: sinf: Idrs: D1???/????????????
?pho: W2cat: vpvar: Ysit: Einf: Idrs:Emarry(E):I?agent(E,Z)patient(E,Y)?????????????)?????
?pho: Manny+W3cat: sinf: ?drs: (Xmanny(X):?+;D)??????/??????
?pho: W3cat: vpvar: Xsit: E1inf: ?drs: D????????????????????????????????????????????????>?????????????
?pho: married+Mannycat: vpvar: Zsit: Einf: ?drs: (Xmanny(X):?+;Emarry(E):??agent(E,Z)patient(E,X))?????????????
?Figure 1: Derivation for married Manny H* using Forward Applicationstructural label of the DRS condition manny(X)gets the value ?+ (theme and focus).4.4 Boundary TonesIn essence the signs for boundary tones are sim-ilar to the pitch accent signs, except that theydo not contain a foc feature in the argumentpart.
They take the following form:(9)???????
?pho: Wcat: Cvar: Xsit: Einf: ?drs: D???????
?$ \???????
?pho: Wcat: Cvar: Xsit: Einf: ?drs: D???????
?$As with pitch accents, when combining signsof boundary tones the argument sign will unifyrecursively with all sub-signs of the lexical sign,effectively replacing the value of the inf featureby ?
(phrase).Hence, the constant value ?
for the inf fea-ture only serves the purpose of keeping thefull intonational phrase from combining withany other signs than similarly phrase markedsigns, and it has no impact on the semantics.There are two signs for each boundary tone: onethat deals with boundary tones occurring at theend of a rheme marked intonational phrase (asshown above), and another one that deals withboundary tones after themes.We have restricted the variable in the argu-ment part of the boundary signs to only be ableto combine with themes and rhemes, assum-ing that in the case of unmarked themes (ashere is no pitch accent, there is no theme mark-ing on the sign) we do not encounter boundarytones after the theme part, and therefore we aredealing with genuinely ambiguous informationstructure.
An unmarked theme will in our ap-proach be automatically marked as part of therheme.
For illustration of combining a lexicalsign with a boundary tone sign see Figure 2.??????????????
?pho: married+Mannycat: vpvar: Zsit: Einf: ?drs:X Emanny(X):?+marry(E):??agent(E,Z)patient(E,X)?????????????????????
?pho: Wcat: Cvar: Xsit: Einf: ?drs: D??????
?$ \??????
?pho: Wcat: Cvar: Xsit: Einf: ?drs: D???????$?????????????????????<??????????????
?pho: married+Mannycat: vpvar: Zsit: Einf: ?drs:X Emanny(X):?+marry(E):??agent(E,Z)patient(E,X)??????????????
?Figure 2: Derivation of married Manny H* LL%using Backward ApplicationFinally, Figures 1 to 3 show a complete parseof the prosodically marked sentence ?AnnaL+H* LH% married Manny H* LL%?.
Dueto space considerations we omitted the twoinitial steps that involve combining the signof ?Anna?
with the sign of the theme accent?L+H*?
to form a new theme unit ?AnnaL+H*?, and then combining this unit with thesign of the boundary tone ?LH%?
to form thefull intonational phrase ?Anna L+H* LH%?.
(These steps are similar to the ones illustratedin Figure 2.)
Due to variable unification inthe features var and sit, while performingthe syntactic combination of the lexical signs,we simultaneously construct the semanticrepresentation in the DRS.?????
?pho: Anna+Wcat: sinf: ?drs:Yanna(Y):?+;D??????/???????
?pho:Wcat:vpvar:Ysit: Einf: ?drs:D??????????????????????
?pho: married+Mannycat: vpvar: Zsit: Einf: ?drs:X Emanny(X):?+marry(E):??agent(E,Z)patient(E,X)???????????????????????????????????>????????????
?pho: Anna+married+Mannycat: sinf: ?drs:Y X Eanna(Y):?+manny(X):?+marry(E):??agent(E,Y)patient(E,X)????????????
?Figure 3: Derivation for ?Anna L+H* LH%married Manny H* LL%?, using Forward Ap-plication and Merge-Reduction5 Conclusions and Future workThe present paper described the UnificationalCombinatory Categorial Grammar (UCCG)formalism, which was developed bearing inmind its future application in parsing and gen-erating prosodically annotated text.
One of thekey features of UCCG is the novel use of Dis-course Representation Theory combined witha theory of information structure.
We believethat UCCG has the potential to advance spokenlanguage dialogue systems, both in natural lan-guage analysis and generation.
Although cur-rent automatic speech recognisers do not out-put prosodic information, some of the state-of-the-art speech synthesisers handle prosodicallyannotated input strings.We have implemented a UCCG parser for afragment of English that takes prosodically an-notated strings as input and generates DRSs en-riched with information structure.
Future workinvolves implementing a generation componentbased on UCCG, evalating the expressive powerof UCCG with respect to information structureon a selected corpus, and using the formalismin existing spoken dialogue systems.AcknowledgementsWe would like to thank Frank Keller and MarkSteedman for their comments on earlier versionsof this paper.ReferencesPatrick Blackburn and Johan Bos.
2003.
Computa-tional semantics.
Theoria, 18(46):27?45.Jonathan Calder, Ewan Klein, and Henk Zeevat.1988.
Unification categorial grammar: A con-cise, extendable grammar for natural languageprocessing.
In Proceedings of the 12th Interna-tional Conerence on Computational Linguistics,Budapest, August.Hans Kamp and Uwe Reyle.
1993.
From Discourseto Logic.
Kluwer Academic Publishers, London.Manfred Krifka.
1993.
Focus and Presuppositionin Dynamic Interpretation.
Journal of Semantics,10(4):269?300.Ivana Kruijff-Korbayova.
1998.
The Dynamic Po-tential of Topic and Focus: A Praguian Approachto Discourse Representation Theory.
Ph.D. the-sis, Faculty of Mathematics and Physics, CharlesUniversity, Prague.Janet Pierrehumbert.
1980.
The Phonology andPhonetics of English Intonation.
Ph.D. thesis,Massachusetts Institute of Technology, Blooming-ton, IN.
Published 1988 by Indiana UniversityLinguistics Club.Mark Steedman.
1990.
Gapping as constituent co-ordination.
Linguistics and Philosophy, 13.Mark Steedman.
2000.
The Syntactic Process.
TheMIT Press, Cambridge, Massachusetts.Mary McGee Wood.
2000.
Syntax in categorialgrammar: An introduction for linguists.
ESS-LLI 2000, Birmingham, England.
ESSLLI course-book.Henk Zeevat.
1988.
Combining categorial grammarand unification.
In U.Reyle and C.Rohrer, ed-itors, Natural Language Parsing and LinguisticTheories.
D.Reidel Publishing Company.
