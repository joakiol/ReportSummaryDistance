Proceedings of ACL-08: HLT, pages 763?770,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsEnriching Morphologically Poor Languagesfor Statistical Machine TranslationEleftherios Avramidise.avramidis@sms.ed.ac.ukPhilipp Koehnpkoehn@inf.ed.ac.ukSchool of InformaticsUniversity of Edinburgh2 Baccleuch PlaceEdinburgh, EH8 9LW, UKAbstractWe address the problem of translating frommorphologically poor to morphologically richlanguages by adding per-word linguistic in-formation to the source language.
We usethe syntax of the source sentence to extractinformation for noun cases and verb personsand annotate the corresponding words accord-ingly.
In experiments, we show improvedperformance for translating from English intoGreek and Czech.
For English?Greek, we re-duce the error on the verb conjugation from19% to 5.4% and noun case agreement from9% to 6%.1 IntroductionTraditional statistical machine translation methodsare based on mapping on the lexical level, whichtakes place in a local window of a few words.
Hence,they fail to produce adequate output in many caseswhere more complex linguistic phenomena play arole.
Take the example of morphology.
Predictingthe correct morphological variant for a target wordmay not depend solely on the source words, but re-quire additional information about its role in the sen-tence.Recent research on handling rich morphology haslargely focused on translating from rich morphologylanguages, such as Arabic, into English (Habash andSadat, 2006).
There has been less work on the op-posite case, translating from English into morpho-logically richer languages.
In a study of translationquality for languages in the Europarl corpus, Koehn(2005) reports that translating into morphologicallyricher languages is more difficult than translatingfrom them.There are intuitive reasons why generating richermorphology from morphologically poor languagesis harder.
Take the example of translating nounphrases from English to Greek (or German, Czech,etc.).
In English, a noun phrase is rendered the sameif it is the subject or the object.
However, Greekwords in noun phrases are inflected based on theirrole in the sentence.
A purely lexical mapping ofEnglish noun phrases to Greek noun phrases suffersfrom the lack of information about its role in the sen-tence, making it hard to choose the right inflectedforms.Our method is based on factored phrase-basedstatistical machine translation models.
We focusedon preprocessing the source data to acquire theneeded information and then use it within the mod-els.
We mainly carried out experiments on Englishto Greek translation, a language pair that exemplifiesthe problems of translating from a morphologicallypoor to a morphologically rich language.1.1 Morphology in Phrase-based SMTWhen examining parallel sentences of such lan-guage pairs, it is apparent that for many Englishwords and phrases which appear usually in the sameform, the corresponding terms of the richer targetlanguage appear inflected in many different ways.On a single word-based probabilistic level, it is thenobvious that for one specific English word e theprobability p(f |e) of it being translated into a wordf decreases as the number of translation candidatesincrease, making the decisions more uncertain.763?
English: The president, after reading thepress review and the announcements, lefthis office?
Greek-1: The president[nominative], afterreading[3rdsing] the pressreview[accusative,sing] and theannouncements[accusative,plur],left[3rdsing] his office[accusative,sing]?
Greek-2: The president[nominative], afterreading[3rdsing] the pressreview[accusative,sing] and theannouncements[nominative,plur],left[3rdplur] his office[accusative,sing]Figure 1: Example of missing agreement information, af-fecting the meaning of the second sentenceOne of the main aspects required for the flu-ency of a sentence is agreement.
Certain wordshave to match in gender, case, number, person etc.within a sentence.
The exact rules of agreementare language-dependent and are closely linked to themorphological structure of the language.Traditional statistical machine translation modelsdeal with this problems in two ways:?
The basic SMT approach uses the target lan-guage model as a feature in the argumentmaximisation function.
This language modelis trained on grammatically correct text, andwould therefore give a good probability forword sequences that are likely to occur in a sen-tence, while it would penalise ungrammaticalor badly ordered formations.?
Meanwhile, in phrase-based SMT models,words are mapped in chunks.
This can resolvephenomena where the English side uses morethan one words to describe what is denoted onthe target side by one morphologically inflectedterm.Thus, with respect to these methods, there is a prob-lem when agreement needs to be applied on part ofa sentence whose length exceeds the order of the ofthe target n-gram language model and the size of thechunks that are translated (see Figure 1 for an exam-ple).1.2 Related WorkIn one of the first efforts to enrich the source inword-based SMT, Ueffing and Ney (2003) used part-of-speech (POS) tags, in order to deal with the verbconjugation of Spanish and Catalan; so, POS tagswere used to identify the pronoun+verb sequenceand splice these two words into one term.
The ap-proach was clearly motivated by the problems oc-curring by a single-word-based SMT and have beensolved by adopting a phrase-based model.
Mean-while, there is no handling of the case when the pro-noun stays in distance with the related verb.Minkov et al (2007) suggested a post-processingsystem which uses morphological and syntactic fea-tures, in order to ensure grammatical agreement onthe output.
The method, using various grammaticalsource-side features, achieved higher accuracy whenapplied directly to the reference translations but itwas not tested as a part of an MT system.
Similarly,translating English into Turkish (Durgar El-Kahloutand Oflazer, 2006) uses POS and morph stems inthe input along with rich Turkish morph tags on thetarget side, but improvement was gained only afteraugmenting the generation process with morphotac-tical knowledge.
Habash et al (2007) also inves-tigated case determination in Arabic.
Carpuat andWu (2007) approached the issue as a Word SenseDisambiguation problem.In their presentation of the factored SMT mod-els, Koehn and Hoang (2007) describe experimentsfor translating from English to German, Spanish andCzech, using morphology tags added on the mor-phologically rich side, along with POS tags.
Themorphological factors are added on the morpholog-ically rich side and scored with a 7-gram sequencemodel.
Probabilistic models for using only sourcetags were investigated by Birch et al (2007), whoattached syntax hints in factored SMT models byhaving Combinatorial Categorial Grammar (CCG)supertags as factors on the input words, but in thiscase English was the target language.This paper reports work that strictly focuses ontranslation from English to a morphologically richerlanguage.
We go one step further than just using eas-ily acquired information (e.g.
English POS or lem-mata) and extract target-specific information fromthe source sentence context.
We use syntax, not in764Figure 2: Classification of the errors on our English-Greek baseline system (ch.
4.1), as suggested by Vilaret al (2006)order to aid reordering (Yamada and Knight, 2001;Collins et al, 2005; Huang et al, 2006), but as ameans for getting the ?missing?
morphology infor-mation, depending on the syntactic position of thewords of interest.
Then, contrary to the methodsthat added only output features or altered the gen-eration procedure, we used this information in orderto augment only the source side of a factored transla-tion model, assuming that we do not have resourcesallowing factors or specialized generation in the tar-get language (a common problem, when translatingfrom English into under-resourced languages).2 Methods for enriching inputWe selected to focus on noun cases agreementand verb person conjugation, since they were themost frequent grammatical errors of our baselineSMT system (see full error analysis in Figure 2).Moreover, these types of inflection signify the con-stituents of every phrase, tightly linked to the mean-ing of the sentence.2.1 Case agreementThe case agreement for nouns, adjectives and arti-cles is mainly defined by the syntactic role that eachnoun phrase has.
Nominative case is used to definethe nouns which are the subject of the sentence, ac-cusative shows usually the direct object of the verbsand dative case refers to the indirect object of bi-transitive verbs.Therefore, the followed approach takes advantageof syntax, following a method similar to SemanticRole Labelling (Carreras and Marquez, 2005; Sur-deanu and Turmo, 2005).
English, as morpholog-ically poor language, usually follows a fixed wordorder (subject-verb-object), so that a syntax parsercan be easily used for identifying the subject and theobject of most sentences.
Considering such annota-tion, a factored translation model is trained to mapthe word-case pair to the correct inflection of the tar-get noun.
Given the agreement restriction, all wordsthat accompany the noun (adjectives, articles, deter-miners) must follow the case of the noun, so theirlikely case needs to be identified as well.For this purpose we use a syntax parser to acquirethe syntax tree for each English sentence.
The treesare parsed depth-first and the cases are identifiedwithin particular ?sub-tree patterns?
which are man-ually specified.
We use the sequence of the nodesin the tree to identify the syntactic role of each nounphrase.Figure 3: Case tags are assigned on depth-first parse ofthe English syntax tree, based on sub-tree patternsTo make things more clear, an example can beseen in figure 3.
At first, the algorithm identifiesthe subtree ?S-(NPB-VP)?
and the nominative tag isapplied on the NPB node, so that it is assigned to theword ?we?
(since a pronoun can have a case).
Theexample of accusative shows how cases get trans-ferred to nested subtrees.
In practice, they are recur-sively transferred to every underlying noun phrase(NP) but not to clauses that do not need this infor-mation (e.g.
prepositional phrases).
Similar rulesare applied for covering a wide range of node se-quence patterns.Also note that this method had to be target-765oriented in some sense: we considered the targetlanguage rules for choosing the noun case in ev-ery prepositional phrase, depending on the leadingpreposition.
This way, almost all nouns were taggedand therefore the number of the factored words wasincreased, in an effort to decrease sparsity.
Simi-larly, cases which do not actively affect morphology(e.g.
dative in Greek) were not tagged during factor-ization.2.2 Verb person conjugationFor resolving the verb conjugation, we needed toidentify the person of a verb and add this piece oflinguistic information as a tag.
As we parse thetree top-down, on every level, we look for two dis-crete nodes which, somewhere in their children, in-clude the verb and the corresponding subject.
Con-sequently, the node which contains the subject issearched recursively until a subject is found.
Then,the person is identified and the tag is assigned to thenode which contains the verb, which recursively be-queaths this tag to the nested subtree.For the subject selection, the following rules wereapplied:?
The verb person is directly connected to thesubject of the sentence and in most cases it isdirectly inferred by a personal pronoun (I, youetc).
Therefore, since this is usually the case,when a pronoun existed, it was directly used asa tag.?
All pronouns in a different case (e.g.
them, my-self ) were were converted into nominative casebefore being used as a tag.?
When the subject of the sentence is not a pro-noun, but a single noun, then it is in third per-son.
The POS tag of this noun is then used toidentify if it is plural or singular.
This was se-lectively modified for nouns which despite be-ing in singular, take a verb in plural.?
The gender of the subject does not affect theinflection of the verb in Greek.
Therefore, allthree genders that are given by the third personpronouns were reduced to one.In Figure 4 we can see an example of how theperson tag is extracted from the subject of the sen-Figure 4: Applying person tags on an English syntax treetence and gets passed to the relative clause.
In par-ticular, as the algorithm parses the syntax tree, itidentifies the sub-tree which has NP-A as a headand includes the WHNP node.
Consequently, it re-cursively browses the preceding NPB so as to getthe subject of the sentence.
The word ?aspects?
isfound, which has a POS tag that shows it is a pluralnoun.
Therefore, we consider the subject to be ofthe third person in plural (tagged by they) which isrecursively passed to the children of the head node.3 Factored ModelThe factored statistical machine translation modeluses a log-linear approach, in order to combine theseveral components, including the language model,the reordering model, the translation models and thegeneration models.
The model is defined mathemat-ically (Koehn and Hoang, 2007) as following:p(f |e) = 1Z expn?i=1?ihi(f , e) (1)where ?i is a vector of weights determined during atuning process, and hi is the feature function.
Thefeature function for a translation probability distri-bution ishT (f |e) =?j?
(ej , f j) (2)While factored models may use a generation step tocombine the several translation components basedon the output factors, we use only source factors;766therefore we don?t need a generation step to combinethe probabilities of the several components.Instead, factors are added so that both words andits factor(s) are assigned the same probability.
Ofcourse, when there is not 1-1 mapping between theword+factor splice on the source and the inflectedword on the target, the well-known issue of sparsedata arises.
In order to reduce these problems, de-coding needed to consider alternative paths to trans-lation tables trained with less or no factors (as Birchet al (2007) suggested), so as to cover instanceswhere a word appears with a factor which it has notbeen trained with.
This is similar to back-off.
Thealternative paths are combined as following (fig.
5):hT (f |e) =?jhTt(j)(ej , f j) (3)where each phrase j is translated by one translationtable t(j) and each table i has a feature function hTi .as shown in eq.
(2).Figure 5: Decoding using an alternative path with differ-ent factorization4 ExperimentsThis preprocessing led to annotated source data,which were given as an input to a factored SMT sys-tem.4.1 Experiment setupFor testing the factored translation systems, we usedMoses (Koehn et al, 2007), along with a 5-gramSRILM language model (Stolcke, 2002).
A Greekmodel was trained on 440,082 aligned sentences ofEuroparl v.3, tuned with Minimum Error Training(Och, 2003).
It was tuned over a development setof 2,000 Europarl sentences and tested on two setsof 2,000 sentences each, from the Europarl and aNews Commentary respectively, following the spec-ifications made by the ACL 2007 2nd Workshopon SMT1.
A Czech model was trained on 57,464aligned sentences, tuned over 1057 sentences of theNews Commentary corpus and and tested on twosets of 964 sentences and 2000 sentences respec-tively.The training sentences were trimmed to a lengthof 60 words for reducing perplexity and a standardlexicalised reordering, with distortion limit set to6.
For getting the syntax trees, the latest versionof Collins?
parser (Collins, 1997) was used.
Whenneeded, part-of-speech (POS) tags were acquired byusing Brill?s tagger (Brill, 1992) on v1.14.
Resultswere evaluated with both BLEU (Papineni et al,2001) and NIST metrics (NIST, 2002).4.2 ResultsBLEU NISTset devtest test07 devtest test07baseline 18.13 18.05 5.218 5.279person 18.16 18.17 5.224 5.316pos+person 18.14 18.16 5.259 5.316person+case 18.08 18.24 5.258 5.340altpath:POS 18.21 18.20 5.285 5.340Table 1: Translating English to Greek: Using a singletranslation table may cause sparse data problems, whichare addressed using an alternative path to a second trans-lation tableWe tested several various combinations of tags,while using a single translation component.
Somecombinations seem to be affected by sparse dataproblems and the best score is achieved by usingboth person and case tags.
Our full method, usingboth factors, was more effective on the second test-set, but the best score in average was succeeded byusing an alternative path to a POS-factored transla-tion table (table 1).
The NIST metric clearly showsa significant improvement, because it mostly mea-sures difficult n-gram matches (e.g.
due to the long-distance rules we have been dealing with).1see http://www.statmt.org/wmt07 referring to sets dev2006(tuning) and devtest2006, test2007 (testing)7674.3 Error analysisIn n-gram based metrics, the scores for all words areequally weighted, so mistakes on crucial sentenceconstituents may be penalized the same as errorson redundant or meaningless words (Callison-Burchet al, 2006).
We consider agreement on verbs andnouns an important factor for the adequacy of the re-sult, since they adhere more to the semantics of thesentence.
Since we targeted these problems, we con-ducted a manual error analysis focused on the suc-cess of the improved system regarding those specificphenomena.system verbs errors missingbaseline 311 19.0% 7.4%single 295 4.7% 5.4%alt.path 294 5.4% 2.7%Table 2: Error analysis of 100 test sentences, focused onverb person conjugation, for using both person and casetagssystem NPs errors missingbaseline 469 9.0% 4.9%single 465 6.2% 4.5%alt.
path 452 6.0% 4.0%Table 3: Error analysis of 100 test sentences, focused onnoun cases, for using both person and case tagsThe analysis shows that using a system with onlyone phrase translation table caused a high percent-age of missing or untranslated words.
When a wordappears with a tag with which it has not been trained,that would be considered an unseen event and re-main untranslated.
The use of the alternative pathseems to be a good solution.step parsing tagging decodingVPs 16.7% 25% 58.3%NPs 39.2% 21.7% 39.1%avg 31.4% 22.9% 45.7 %Table 4: Analysis on which step of the translation pro-cess the agreement errors derive from, based on manualresolution on the errors of table 3The impact of the preprocessing stage to the er-rors may be seen in table 4, where errors are trackedback to the stage they derived from.
Apart from thedecoding errors, which may be attributed to sparsedata or other statistical factors, a large part of theerrors derive from the preprocessing step; either thesyntax tree of the sentence was incorrectly or par-tially resolved, or our labelling process did not cor-rectly match all possible sub-trees.4.4 Investigating applicability to other inflectedlanguagesThe grammatical phenomena of noun cases and verbpersons are quite common among many human lan-guages.
While the method was tested in Greek, therewas an effort to investigate whether it is useful forother languages with similar characteristics.
For thisreason, the method was adapted for Czech, whichneeds agreement on both verb conjugation and 9noun cases.
Dative case was included for the indi-rect object and the rules of the prepositional phraseswere adapted to tag all three cases that can be verbphrase constituents.
The Czech noun cases whichappear only in prepositional phrases were ignored,since they are covered by the phrase-based model.BLUE NISTset devtest test devtest testbaseline 12.08 12.34 4.634 4.865person+casealtpath:POS 11.98 11.99 4.584 4.801personaltpath:word 12.23 12.11 4.647 4.846casealtpath:word 12.54 12.51 4.758 4.957Table 5: Enriching source data can be useful when trans-lating from English to Czech, since it is a morpholog-ically rich language.
Experiments shown improvementwhen using factors on noun-cases with an alternative pathIn Czech, due to the small size of the corpus, itwas possible to improve metric scores only by usingan alternative path to a bare word-to-word transla-tion table.
Combining case and verb tags worsenedthe results, which suggests that, while applying themethod to more languages, a different use of the at-tributes may be beneficial for each of them.7685 ConclusionIn this paper we have shown how SMT performancecan be improved, when translating from Englishinto morphologically richer languages, by addinglinguistic information on the source.
Although thesource language misses morphology attributes re-quired by the target language, the needed infor-mation is inherent in the syntactic structure of thesource sentence.
Therefore, we have shown thatthis information can be easily be included in a SMTmodel by preprocessing the source text.Our method focuses on two linguistic phenomenawhich produce common errors on the output and areimportant constituents of the sentence.
In partic-ular, noun cases and verb persons are required bythe target language, but not directly inferred by thesource.
For each of the sub-problems, our algorithmused heuristic syntax-based rules on the statisticallygenerated syntax tree of each sentence, in order toaddress the missing information, which was conse-quently tagged in by means of word factors.
Thisinformation was proven to improve the outcome ofa factored SMT model, by reducing the grammaticalagreement errors on the generated sentences.An initial system using one translation table withadditional source side factors caused sparse dataproblems, due to the increased number of unseenword-factor combinations.
Therefore, the decodingprocess is given an alternative path towards a trans-lation table with less or no factors.The method was tested on translating from En-glish into two morphologically rich languages.
Notethat this may be easily expanded for translating fromEnglish into many morphologically richer languageswith similar attributes.
Opposed to other factoredtranslation model approaches that require target lan-guage factors, that are not easily obtainable for manylanguages, our approach only requires English syn-tax trees, which are acquired with widely avail-able automatic parsers.
The preprocessing scriptswere adapted so that they provide the morphologyattributes required by the target language and thebest combination of factors and alternative paths waschosen.AcknowledgmentsThis work was supported in part under the Euro-Matrix project funded by the European Commission(6th Framework Programme).
Many thanks to JoshSchroeder for preparing the training, developmentand test data for Greek, in accordance to the stan-dards of ACL 2007 2nd Workshop on SMT; to HieuHoang, Alexandra Birch and all the members ofthe Edinburgh University SMT group for answeringquestions, making suggestions and providing sup-port.ReferencesBirch, A., Osborne, M., and Koehn, P. 2007.
CCGSupertags in factored Statistical Machine Translation.In Proceedings of the Second Workshop on StatisticalMachine Translation, pages 9?16, Prague, Czech Re-public.
Association for Computational Linguistics.Brill, E. 1992.
A simple rule-based part of speech tag-ger.
Proceedings of the Third Conference on AppliedNatural Language Processing, pages 152?155.Callison-Burch, C., Osborne, M., and Koehn, P. 2006.Re-evaluation the role of bleu in machine translationresearch.
In Proceedings of the 11th Conference ofthe European Chapter of the Association for Computa-tional Linguistics.
The Association for Computer Lin-guistics.Carpuat, M. and Wu, D. 2007.
Improving Statistical Ma-chine Translation using Word Sense Disambiguation.In Proceedings of the Joint Conference on EmpiricalMethods in Natural Language Processing and Compu-tational Natural Language Learning (EMNLP-CoNLL2007), pages 61?72, Prague, Czech Republic.Carreras, X. and Marquez, L. 2005.
Introduction to theCoNLL-2005 Shared Task: Semantic Role Labeling.In Proceedings of 9th Conference on ComputationalNatural Language Learning (CoNLL), pages 169?172,Ann Arbor, Michigan, USA.Collins, M. 1997.
Three generative, lexicalised modelsfor statistical parsing.
Proceedings of the 35th con-ference on Association for Computational Linguistics,pages 16?23.Collins, M., Koehn, P., and Kuc?erov?, I.
2005.
Clause re-structuring for statistical machine translation.
In ACL?05: Proceedings of the 43rd Annual Meeting on Asso-ciation for Computational Linguistics, pages 531?540,Morristown, NJ, USA.
Association for ComputationalLinguistics.769Durgar El-Kahlout, i. and Oflazer, K. 2006.
Initial explo-rations in english to turkish statistical machine trans-lation.
In Proceedings on the Workshop on StatisticalMachine Translation, pages 7?14, New York City.
As-sociation for Computational Linguistics.Habash, N., Gabbard, R., Rambow, O., Kulick, S., andMarcus, M. 2007.
Determining case in Arabic: Learn-ing complex linguistic behavior requires complex lin-guistic features.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 1084?1092.Habash, N. and Sadat, F. 2006.
Arabic preprocessingschemes for statistical machine translation.
In Pro-ceedings of the Human Language Technology Confer-ence of the NAAC L, Companion Volume: Short Pa-pers, pages 49?52, New York City, USA.
Associationfor Computational Linguistics.Huang, L., Knight, K., and Joshi, A.
2006.
Statisticalsyntax-directed translation with extended domain oflocality.
Proc.
AMTA, pages 66?73.Koehn, P. 2005.
Europarl: A parallel corpus for statisticalmachine translation.
MT Summit, 5.Koehn, P. and Hoang, H. 2007.
Factored translationmodels.
In Proceedings of the 2007 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 868?876.Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran,C., Zens, R., Dyer, C., Bojar, O., Constantin, A.,and Herbst, E. 2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics Companion Volume Proceed-ings of the Demo and Poster Sessions, pages 177?180, Prague, Czech Republic.
Association for Com-putational Linguistics.Minkov, E., Toutanova, K., and Suzuki, H. 2007.
Gen-erating complex morphology for machine translation.In ACL 07: Proceedings of the 45th Annual Meet-ing of the Association of Computational linguistics,pages 128?135, Prague, Czech Republic.
Associationfor Computational Linguistics.NIST 2002.
Automatic evaluation of machine translationquality using n-gram co-occurrence statistics.Och, F. J.
2003.
Minimum error rate training in statisti-cal machine translation.
In ACL ?03: Proceedings ofthe 41st Annual Meeting on Association for Compu-tational Linguistics, pages 160?167, Morristown, NJ,USA.
Association for Computational Linguistics.Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
2001.BLEU: a method for automatic evaluation of machinetranslation.
In ACL ?02: Proceedings of the 40th An-nual Meeting on Association for Computational Lin-guistics, pages 311?318, Morristown, NJ, USA.
Asso-ciation for Computational Linguistics.Stolcke, A.
2002.
SRILM-an extensible language model-ing toolkit.
Proc.
ICSLP, 2:901?904.Surdeanu, M. and Turmo, J.
2005.
Semantic Role Label-ing Using Complete Syntactic Analysis.
In Proceed-ings of 9th Conference on Computational Natural Lan-guage Learning (CoNLL), pages 221?224, Ann Arbor,Michigan, USA.Ueffing, N. and Ney, H. 2003.
Using pos informationfor statistical machine translation into morphologicallyrich languages.
In EACL ?03: Proceedings of thetenth conference on European chapter of the Associ-ation for Computational Linguistics, pages 347?354,Morristown, NJ, USA.
Association for ComputationalLinguistics.Vilar, D., Xu, J., D?Haro, L. F., and Ney, H. 2006.
ErrorAnalysis of Machine Translation Output.
In Proceed-ings of the 5th Internation Conference on LanguageResources and Evaluation (LREC?06), pages 697?702,Genoa, Italy.Yamada, K. and Knight, K. 2001.
A syntax-based statis-tical translation model.
In ACL ?01: Proceedings ofthe 39th Annual Meeting on Association for Compu-tational Linguistics, pages 523?530, Morristown, NJ,USA.
Association for Computational Linguistics.770
