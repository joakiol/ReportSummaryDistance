Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 63?67,Baltimore, Maryland, USA, 26 June 2014. c?2014 Association for Computational LinguisticsEstimating Native Vocabulary Size in an Endangered LanguageTimofey ArkhangelskiyNational Research UniversityHigher School of Economics,Moscow, Russiatimarkh@gmail.comAbstractThe  vocabularies  of  endangeredlanguages  surrounded  by  moreprestigious  languages  are  graduallyshrinking  in  size  due  to  the  influx  ofborrowed items.
It is easy to observe thatin  such  languages,  starting  from  somefrequency rank, the lower the frequencyof  a  vocabulary  item,  the  higher  theprobability of that item being a borrowedone.
On the basis  of  the  data  from theBeserman dialect  of  Udmurt,  the articleprovides a model according to which theportion  of  borrowed  items  among  theitems  with  frequency  ranks  less  than  rincreases  logarithmically  in  r,  startingfrom  some  rank  r0,  while  for  morefrequent items, it can behave differently.Apart from theoretical interest, the modelcan be used to roughly predict the totalnumber of native items in the vocabularybased on a limited corpus of texts.1 IntroductionIt is well known that in the situation of languagecontact  the  most  easily  borrowed  part  of  thelanguage  is  the  lexicon  (although  there  arecounterexamples, see e.g.
(Thomason, 2001:82)).Typically, for an endangered language or dialectL1  whose  speakers  are  bilingual  in  anotherlanguage  L2  which  is  more  prestigious  and/orofficial  in  the  area,   the  borrowing  process  isoverwhelmingly unidirectional.
Due to the influxof  borrowed  stems,  words,  and  constructionsfrom L2, as well as frequent code switching inspeech, the size of the native vocabulary of L1(defined  as  the  set  of  vocabulary  items  in  L1which were not borrowed from L2 and are stillremembered  by  the  language  community)  isgradually decreasing.
The stronger the influenceof  L2,  the  less  native  items  remain  in  thevocabulary of L1, native lexemes being replacedwith  loanwords  or  just  being  lost  without  anyreplacement.
Eventually the process may lead toa  situation  whereby L1  is  confined  to  a  smallrange  of  communicative  situations,  retainingonly  that  part  of  native  vocabulary  which  isrelevant  in  these  situations,  and  ultimately  tolanguage death (Wolfram, 2002).It  is interesting to study the vocabulary of alanguage  currently  undergoing  the  process  oflexical erosion and search for rules that governthe  process.
Indeed,  the  process  of  nativevocabulary shrinkage is not chaotic and turns outto  conform  to  certain  rules.
In  this  article,  Iprovide  a  model  which  shows  how the  nativelexicon  of  an  endangered  language  is  beinggradually  lost.
The  model  may  be  used  toroughly estimate  the  native  vocabulary  size  ofthe  language.
Apart  from  theoretical  interest,such an estimate could have practical value for afield linguist, since it helps evaluate the coverageof the dictionary she compiled for the language:if  the  number  of  items  in  the  dictionary  issignificantly less than the estimate, chances arethere are vocabulary items still not covered by it.2 The model and the dataThe model is based on two observations relatedto  frequency  of  vocabulary  items.
The  mainobservation is that in the situation of extensivebilingualism, the probability of an item being aloanword instead of a native one increases withdecreasing frequency of that item in L1: the lessfrequent the item, the more likely it is to turn outto be a borrowing.
This synchronic property ofthe vocabulary is  probably a consequence of  adiachronic  property  of  the  borrowing  process63whereby  the  less  frequent  an  item  in  L1,  thehigher the probability it will be replaced with anon-native  item from L2  in  a  given  period  oftime.
The other observation is that such behavioris characteristic of vocabulary items starting withsome  frequency  f0,  while  items  of  higherfrequency may be governed by different laws.The  relation  between  frequency,  rank  andother properties of lexical (and other linguistic)items has a long history of study, starting at leastfrom Zipf?s work (Zipf, 1949).
The idea that themost frequent items can have special propertiesis also well known (see e. g. (Dixon, 1977:20)for syntactic properties or (Bybee,  2010:37?48)for  phonetic  and  morphosyntactic  effects  offrequency),  and  it  has  been  widely  used  inlexicostatistics  and  glottochronology  sinceSwadesh  (Swadesh,  1955)  for  estimating  thedegree to which several languages are related toeach other and determining the point in time atwhich they diverged.Based on these two observations  and on thedata  from  an  endangered  dialect,  I  propose  amodel  of  synchronic  distribution  of  loanworditems  in  the  vocabulary  of  an  endangeredlanguage.
The  model  highlights  the  connectionbetween the rank of an item (i. e. its number inthe  frequency list)  and  the  probability  that  theitem is a borrowed one.
By a borrowed item Iunderstand an item that was borrowed from thelanguage  L2  whose  influence  L1  is  currentlyexperiencing.
This definition might seem a littlearbitrary: what if L1 has a number of items leftfrom its  previous  extensive  contact?
But  sincemost  vocabulary items  in most  languages wereprobably  borrowed  from  another  language  atsome  point  and  since  it  is  often  impossible  todistinguish  between  native  items  and  oldborrowings, one has to draw a line somewhere,and this seems to be the most reasonable way todo so.
According to this model, the fact ?item ofthe rank r is a borrowed one?
can be viewed asan  outcome  of  a  Bernoulli  trial  in  which  theprobability of success can be approximated quiteprecisely by a logarithm of the rank of the itemin  the  frequency  list,  starting  from  some  (notvery  high)  rank  r0,  while  for  any  item  withsmaller rank it can behave differently:(1) Pr[the item is a borrowed one] = a log(r)+ b, if r > r0,where r is the rank of that item.The actual  language data,  however,  makes itdifficult  to  prove  the  hypothesis  in  the  formpresented above.
The data the model should betested  against  is  a  list  of  stems  with  theirfrequencies  in  the  corpus  and  labels  sayingwhether a stem was borrowed from L2.
Thus, wehave a  situation of  binary choice,  as  for  everyfrequency rank the  stem corresponding to  it  iseither  native,  or  borrowed.
Besides,  for  greatmany stems  it  is  impossible  to  determine  theirrank precisely, since, however large the corpus,there are always many low-frequency stems thathave  same  frequencies  in  it  (there  are,  forexample, more than 1200 hapax legomena in mycase).
When  several  stems  have  the  samefrequency, we can determine the segment (r1, r2)their frequency ranks occupy, but we cannot saywhich stem has which frequency rank.To overcome these difficulties, I first will seekan approximation for the function P(r) defined asthe portion of borrowed stems among all stemswhose rank does not exceed r:(2) P(r) =  (number  of  borrowed  stemsamong those with rank < r) / rAs I will show, P(r) grows logarithmically inr,  for  r  >  r0,  and  this  approximation  is  veryprecise for our data.
In Section 4 I discuss whythis fact implies the original claim (1).The  data  I  used  comes  from  the  Besermandialect  of  the  Udmurt  language  (Finno-Ugric).All  speakers  of  this  dialect  are  bilingual  inRussian  (and  some  in  literary  Udmurt),  thenumber  of  speakers  is  at  most  2000  and  isdecreasing  steadily.
The  dialect,  unlike  literaryUdmurt,  is  endangered,  since  most  fluentspeakers are now in their forties or older, and thechildren  usually  communicate  in  Russian  bothwith each other and in the family.
Beserman hasa  number  of  older  loanwords  borrowed  fromneighboring  Turkic  languages  (which  arerecognized as native by the speakers and will notbe  dealt  with  in  this  article  by definition  of  aborrowed item)  and a  vast  number  of  Russianborrowings, either incorporated into the lexicon,or spontaneous.
My primary source was a corpusof  spoken  Beserman  totalling  about  64,000tokens  that  was  collected  in  the  village  ofShamardan, Yukamensk region, Udmurtia, withmy participation.3 The analysis of the dataThe items whose distribution was studied werestems,  although  similar  calculations  could  becarried out for lexemes.
I built a frequency list of64all stems, both Beserman and borrowed/Russian,for our corpus of spoken Beserman.
Productivederivational  affixes  were  not  incorporated  intostems, and in Russian stems, aspectual pairs werecounted  as  one  stem.
The  list  was  manuallyannotated: each stem was marked as either nativeor borrowed.The distribution of native and borrowed stemsis  plotted  at  the  figures  1  and  2.
The  onlydifference between the graphs is that the x axis ofthe plot  on Fig.
1 is  logarithmically scaled; allthe  data  points  and  lines  are  identical  at  bothplots.
For each point,  x stands for the rank of astem  in  the  frequency  list,  and  y denotes  theportion  of  borrowed  stems  among  those  withrank less than x.Fig.
1.
Portion of borrowed stems with respectto  the  frequency  rank  with  logarithmicapproximation (semi-log plot)Fig.
2.
Portion of borrowed stems with respectto  the  frequency  rank  with  logarithmicapproximation (linear axes)The data points plotted at the graphs were splitin two parts.
Starting from r0 of roughly 350, thedata can be approximated nicely by a logarithmicfunction (a  line  in  the  semi-log plot):  the  bluecurves  are  the  approximations  of  the  formy = a log(r) + b obtained  with  the  least  squaresmethod.
The peaks and declines in the beginningot the frequency ranks range, e. g. for r < 50, donot provide any real insight into the behavior ofthe  corresponding  stems  because  thedenominator in the formula for P(r) is small andevery single borrowed stem causes a visible riseof the line.
For 50 < r < 350, it can be seen thatthe portion of borrowed stems grows with r, butits  growth  does  not  conform to  the  same  lawwhich  governs  the  behavior  of  less  frequentitems.
For r0 > 350, the best fit has the followingparameters (p < 0.001):a = 0.1550712 ?
0.000254, (3)b = ?0.71760178The approximation is quite precise, as can beseen  from  the  picture  and  the  statistics  (root-mean-square  error  0.0088,  coefficient  ofdetermination  0.99).
One  possible  point  ofconcern is the fact that the density of data pointsis much higher on the left part of the plot, so thatthe result is heavily influenced by the points withlow frequency and only slightly influenced  bythe  points  with  rank  greater  than  1000.
If  theitems  with  higher  ranks  behave  slightlydifferently  than  those  with  lower  ranks,  thedifference  could  go  unnoticed  and  theapproximation  will  be  not  so precise  for  itemswith greater  ranks.
The only way to overcomethis  obstacle  is  testing  the  model  on  largercorpora.
Another  negative  effect  of  suchdisparity  stems  from  higher  variance  of  thepoints  on  the  left.
However,  it  seems  that  forpoints with r > 350, the variance is already smallenough for this effect to be significant (note thatthe y coordinate in such points is an average overat least 350 original observations).Borrowed  stems  make  up  about  0.21  of  thefirst 350 stems, and the behavior of  P(r) differsin this segment.
The portion of borrowed stemsincreases slowly until it reaches the level of 0.2for r = 150.
For the next 200 frequency ranks orso, P(r) stays at that level until it starts growingagain around r = 350.4 Calculating  the  probability  of  beingborrowedAccording  to  the  model  I  propose,  the  labels?native?
or ?borrowed?
in the data table can be65seen  as  generated  by  independent  Bernoullitrials:  the  stem with frequency rank  r gets  thelabel ?borrowed?
with the probability a log(r) +b,  for  all  r >  r0.
However,  the  logarithmicapproximation  that  was  derived  in  Section  3,estimates  P(r) rather than the probability of  rthstem being  a  borrowed one.
Here  I  will  showhow a logarithmic approximation for probabilitycan be deduced from the approximation for P(r).Suppose  the  label  for  the  rth  stem  is  anoutcome of a Bernoulli trial with probability ofsuccess (i. e. getting the label ?borrowed?)
equalto  f(r),  an increasing function whose values donot exceed 0 and 1.
We define z(r) as 0 if the rthitem  is  native  or  1  otherwise.
Then  theexpectation of P(r) can be estimated as follows:(4) E[P(r)] = E[(1/r) ?z(i)] = (1/r) ?E[z(i)]= (1/r) ?f(i)The  resulting  sum may  be  estimated  by thefollowing inequalities:(5) (1/r )?1r f ( x?1)dx ?
(1/r )?1r f (i) ?
(1/r )?1r f ( x)dxProvided  the  interval  is  sufficiently  narrow,we  can  assume  that  E[P(r)]  is  approximatelyequal to the right part of (5).
Now, we know thatE[P(r)]  is  well  approximated  by  a  logarithmicfunction  y =  c log(r) +  d (for points where thislogarithmic function is less than 0 or greater than1, let y equal 0 or 1, respectively).
Therefore, thefollowing holds:(6) (1/r )?1r f ( x)dx=c log r+d ?
(1/r )(F (r )?F (1))=c log r+d ?F (r )=c r log r+d r+F (1) ?f (r )=F ' (r )=c log r+ (c+ d ) ,where F(r) stands for the indefinite integral off(r).
Using the constants obtained in the Section3, we can estimate the probability as follows:(7) Pr[the  item  is  a  borrowed  one]  =(0.1550712  ?
0.000254)  log(r)  ?
(0.534576  ?0.000254), if r > 350.5 Using  the  data  for  assessingdictionary coverageThe logarithmic model  predicts that every itemwhich has sufficiently large frequency rank willnecessarily be a borrowed one, as the logarithmcrosses the line  y = 1 at some point.
Based onthis observation, one can estimate  the expectedtotal  number  of  native  vocabulary  items  thelanguage retains.
To do that, one should sum upthe expected values of y for every r from 1 to therightmost  r for which the probability is still lessthan 1.
In doing so, we assume that the events?the item of the rank  r is a borrowed one?
areindependent  and  random  (they  happen  withprobability  (0.1550712 ?
0.000298) log(r) ?
(0.56253058 ?
0.000298) for  r > 350 and withprobability  0.21  for  more  frequent  stems).Calculations  reveal  that  the  point  at  which theprobability curve crosses the line y = 1 lies in theinterval  (23770,  24206),  and the expected totalnumber  of  native  stems  is  between  3603  and3725 (for  a = 0.1550712, it equals 3664).
Thesebounds  should  be  further  widened  as  theobserved value of a random variable is likely todeviate  from the  expected  value  within certainlimits.
Using Hoeffding?s inequality for the sumof  independently  distributed  random  variables(Hoeffding,  1963)  (8),  we  get  that  with  0.99probability,  the  number  of  native  Besermanstems should lie somewhere between and 3369and 3962.
(8) Pr[|?Xi ?
E[?Xi]| ?
t] ?exp(?2t2 / ?
(bi?ai)2),  where Pr[ai ?
Xi ?
bi] = 1This  estimate  is  rather  imprecise,  butnevertheless it provides information on the orderof magnitude of the native vocabulary size.
Atthe  moment,  there  are  about  2000  nativeBeserman stems known to us (which yields about4000  dictionary  entries  in  the  dictionary(Kuznetsova et  al.,  2013)),  therefore the modelindicates  that  the  list  of  stems  can  besignificantly expanded and the efforts should becontinued.6 Assumptions and limitationsApart  from  the  two  observations  connectingfrequency  of  vocabulary  items  and  theprobability of borrowing, there are more subtleassumptions the proposed estimate is based on,which  can  introduce  additional  pitfalls  to  themethod.One  of  such  pitfalls  is  the  assumption  ofrepresentativeness of the corpus.
When speakingof frequencies and frequency ranks of stems orwords in the framework of this method, I meanthe frequencies of those items in the corpus of66texts.
In reality, however, an item is less likely tobe replaced by a loanword if it is either frequentin  speech  in  general,  or  frequent  in  particularcommunicative situations.
As corpus data is theonly means to estimate frequencies, we have tosubstitute the real frequencies with those foundin the corpus.
Although in the case of corpora oflarger  languages  for  which  multiple  means  ofcommunication  are  available  (books,  press,broadcasts etc.
), the notion of representativenessis  quite  vague  (Leech,  2006),  for  languageswhich  exist  only  in  spoken  form,representativeness is much easier to define: thecorpus  can  be  said  to  be  representative  if  thefrequencies  of  items  in  the  corpus  faithfullyreproduce the frequencies of the same items inspeech.
Thus,  for  the  model  to  yield  reliableresults,  we  need  a  representative  corpus.
Inpractice  that  means  that  the  corpus  shouldcontain  texts  of  various  genres  (interviews,dialogues,  folklore  etc.
),  texts  should  cover  awide range of topics (including topics connectedto the traditional culture and way of life as thevocabulary of these areas is especially likely toretain native items), they should be produced byspeakers of different age, sex, background, etc.Failure to represent certain genres or topics in thecorpus leads to certain items or classes of itemsbeing overseen by the researcher.
For example,although  our  corpus  covers  a  wide  range  oftopics and genres, there were no occurrences ofthe words  t?
?lungs?
and  l?
?spine?, the only twowords in the dialect that retain the phoneme  /?/.The  reason  for  that  was,  of  course,  not  theiroverall low frequency in speech, but lack of textsrecorded in situations where use of those wordswould be appropriate.7 Further workIn order  to  verify the  model  presented here,  itwill be necessary to look at the data from otherlanguages with similar  status.
As there exists ahandful  of  manually  annotated  corpora  forvarious  indigenous  languages  of  Russia  whichhave undergone the same influence for roughlythe  same  period  as  Beserman,  the  task  ofanalyzing  two  or  three  more  languages  withcomparable  data  seems  realistic.
Of  course,  itwould  be  more  productive  to  analyze  largercorpora,  but  this  is  more  of  an  obstacle  herebecause  such  languages  usually  don?t  havecorpora  whose  size  would  significantly  exceedone or, at best, several hundred thousand tokens.Apart  from  other  languages  in  similarcircumstances  it  would be helpful  to see if  themodel  works for languages that are engaged inlanguage  contact  but  not  endangered(specifically,  languages  whose  own  word-formation  mechanisms  are  still  active),  e.  g.literary Udmurt.If  the  data  from other  comparable  languagecorpora  indeed  verifies  the  model,  a  possiblefurther  step  would  be  to  come  up  with  adiachronic model that would describe the processwhereby the native vocabulary is being graduallyreplaced  with  loanwords  in  a  language  whoseown  word-formation  system  has  ceased  tofunction.ReferencesJoan  Bybee.
2010.
Language,  usage  and cognition.Cambridge University Press, New York.Robert  M.  W.  Dixon.
1977.
Where  have  all  theadjectives gone?
Studies in Language 1.1:19?80.Ariadna  I.  Kuznetsova  et  al.
2013.
Slovar?besermjanskogo  dialekta  udmurtskogo  jazyka[Dictionary  of  the  Beserman  dialect  of  Udmurt].Tezaurus, Moscow, Russia.Wassily Hoeffding.
1963.
Probability inequalities forsums of bounded random variables.
Journal of theAmerican Statistical Association, 58 (301):13?30.Geoffrey Leech.
2006.
New resources,  or just betterold  ones?
The  Holy  Grail  of  representativeness.Language and Computers, 59.1:133?149.Morris Swadesh.
1955.
Towards greater accuracy inlexicostatistic  dating.
International  Journal  ofAmerican Linguistics, 21:121?137.Sarah  G.  Thomason.
2001.
Language  contact.Edinburgh University Press, Edinburgh, UK.Walt Wolfram.
2002.
Language death and dying.
Thehandbook of language variation and change, 764?787.
Blackwell Publishing, Oxford, UK.George  K.  Zipf.
1949.
Human  Behavior  and  thePrinciple  of  Least  Effort.
Addison-Wesley,Cambridge, MA.67
