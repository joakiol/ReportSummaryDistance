Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
810?818, Prague, June 2007. c?2007 Association for Computational LinguisticsA Statistical Language Modeling Approach toLattice-Based Spoken Document RetrievalTee Kiah Chia?
Haizhou Li?
Hwee Tou Ng?
?Department of Computer ScienceNational University of Singapore3 Science Drive 2, Singapore 117543{chiateek,nght}@comp.nus.edu.sg?Institute for Infocomm Research21 Heng Mui Keng TerraceSingapore 119613hli@i2r.a-star.edu.sgAbstractSpeech recognition transcripts are far fromperfect; they are not of sufficient quality tobe useful on their own for spoken documentretrieval.
This is especially the case for con-versational speech.
Recent efforts have triedto overcome this issue by using statisticsfrom speech lattices instead of only the 1-best transcripts; however, these efforts haveinvariably used the classical vector space re-trieval model.
This paper presents a novelapproach to lattice-based spoken documentretrieval using statistical language models: astatistical model is estimated for each doc-ument, and probabilities derived from thedocument models are directly used to mea-sure relevance.
Experimental results showthat the lattice-based language modelingmethod outperforms both the language mod-eling retrieval method using only the 1-besttranscripts, as well as a recently proposedlattice-based vector space retrieval method.1 IntroductionInformation retrieval (IR) is the task of ranking acollection of documents according to an estimate oftheir relevance to a query.
With the recent growthin the amount of speech recordings in the form ofvoice mails, news broadcasts, and so forth, the taskof spoken document retrieval (SDR) ?
informationretrieval in which the document collection is in theform of speech recordings ?
is becoming increas-ingly important.SDR on broadcast news corpora has been?deemed to be a solved problem?, due to the fact thatthe performance of retrieval engines working on 1-best automatic speech recognition (ASR) transcriptswas found to be ?virtually the same as their perfor-mance on the human reference transcripts?
(NIST,2000).
However, this is still not the case for SDRon data which are more challenging, such as conver-sational speech in noisy environments, as the 1-besttranscripts of these data contain too many recogni-tion errors to be useful for retrieval.
One way toameliorate this problem is to work with not just oneASR hypothesis for each utterance, but multiple hy-potheses presented in a lattice data structure.
A lat-tice is a connected directed acyclic graph in whicheach edge is labeled with a term hypothesis and alikelihood value (James, 1995); each path through alattice gives a hypothesis of the sequence of termsspoken in the utterance.Each lattice can be viewed as a statistical modelof the possible transcripts of an utterance (given thespeech recognizer?s state of knowledge); thus, anIR model based on statistical inference will seemto be a more natural and more principled approachto lattice-based SDR.
This paper thus proposes alattice-based SDR method based on the statisticallanguage modeling approach of Song and Croft(1999).
In this method, the expected word count ?the mean number of occurrences of a word givena lattice?s statistical model ?
is computed for eachword in each lattice.
Using these expected counts,a statistical language model is estimated for eachspoken document, and a document?s relevance to aquery is computed as a probability under this model.810The rest of this paper is organized as follows.
InSection 2 we review related work in the areas ofspeech processing and IR.
Section 3 describes ourproposed method as well as the baseline methods.Details of the experimental setup are given in Sec-tion 4, and experimental results are in Section 5.
Fi-nally, Section 6 concludes our discussions and out-lines our future work.2 Related Work2.1 Lattices for Spoken Document RetrievalJames and Young (1994) first introduced the latticeas a representation for indexing spoken documents,as part of a method for vocabulary-independent key-word spotting.
The lattice representation was laterapplied to the task of spoken document retrievalby James (1995): James counted how many timeseach query word occurred in each phone lattice witha sufficiently high normalized log likelihood, andthese counts were then used in retrieval under a vec-tor space model with tf ?
idf weighting.
Jones et al(1996) combined retrieval from phone lattices usingvariations of James?
method with retrieval from 1-best word transcripts to achieve better results.Since then, a number of different methods forSDR using lattices have been proposed.
For in-stance, Siegler (1999) used word lattices instead ofphone lattices as the basis of retrieval, and gener-alized the tf ?
idf formalism to allow uncertaintyin word counts.
Chelba and Acero (2005) prepro-cessed lattices into more compact Position SpecificPosterior Lattices (PSPL), and computed an aggre-gate score for each document based on the poste-rior probability of edges and the proximity of searchterms in the document.
Mamou et al (2006) con-verted each lattice into a word confusion network(Mangu et al, 2000), and estimated the inverse doc-ument frequency (idf ) of each word t as the ratio ofthe total number of words in the document collectionto the total number of occurrences of t.Despite the differences in the details, the abovelattice-based SDR methods have all been based onthe classical vector space retrieval model with tf ?idfweighting.2.2 Expected Counts from LatticesA speech recognizer generates a 1-best transcriptof a spoken document by considering possible tran-scripts of the document, and then selecting the tran-script with the highest probability.
However, unlikea text document, such a 1-best transcript is likely tobe inexact due to speech recognition errors.
To rep-resent the uncertainty in speech recognition, and toincorporate information from multiple transcriptionhypotheses rather than only the 1-best, it is desirableto use expected word counts from lattices output bya speech recognizer.In the context of spoken document search, Siegler(1999) described expected word counts and for-mulated a way to estimate expected word countsfrom lattices based on the relative ranks of wordhypothesis probabilities; Chelba and Acero (2005)used a more explicit formula for computing wordcounts based on summing edge posterior probabili-ties in lattices; Saraclar and Sproat (2004) performedword-spotting in speech lattices by looking for wordoccurrences whose expected counts were above acertain threshold; and Yu et al (2005) searched forphrases in spoken documents using a similar mea-sure, the expected word relevance.Expected counts have also been used to sum-marize the phonotactics of a speech recording rep-resented in a lattice: Hatch et al (2005) per-formed speaker recognition by computing the ex-pected counts of phone bigrams in a phone lattice,and estimating an unsmoothed probability distribu-tion of phone bigrams.Although many uses of expected counts have beenstudied, the use of statistical language models builtfrom expected word counts has not been well ex-plored.2.3 Retrieval via Statistical LanguageModelingFinally, the statistical language modeling approachto retrieval was used by Ponte and Croft (1998) forIR with text documents, and it was shown to outper-form the tf ?
idf approach for this task; this methodwas further improved on in Song and Croft (1999).Chen et al (2004) applied Song and Croft?s methodto Mandarin spoken document retrieval using 1-bestASR transcripts.
In this task, it was also shown to811outperform tf ?
idf .
Thus, the statistical languagemodeling approach to retrieval has been shown to besuperior to the vector space approach for both theseIR tasks.2.4 Contributions of Our WorkThe main contributions of our work include?
extending the language modeling IR approachfrom text-based retrieval to lattice-based spo-ken document retrieval; and?
formulating a method for building a statisticallanguage model based on expected word countsderived from lattices.Our method is motivated by the success of the sta-tistical retrieval framework over the vector space ap-proach with tf ?
idf for text-based IR, as well asfor spoken document retrieval via 1-best transcripts.Our use of expected counts differs from Saraclar andSproat (2004) in that we estimate probability mod-els from the expected counts.
Conceptually, ourmethod is close to that of Hatch et al (2005), asboth methods build a language model to summa-rize the content of a spoken document representedin a lattice.
In practice, our method differs fromHatch et al (2005)?s in many ways: first, we deriveword statistics for representing semantics, instead ofphone bigram statistics for representing phonotac-tics; second, we introduce a smoothing mechanism(Zhai and Lafferty, 2004) to the language model thatis specific for information retrieval.3 MethodsWe now describe the formulation of three differentSDR methods: a baseline statistical retrieval methodwhich works on 1-best transcripts, our proposed sta-tistical lattice-based SDR method, as well as a pre-viously published vector space lattice-based SDRmethod.3.1 Baseline Statistical Retrieval MethodOur baseline retrieval method is motivated by Songand Croft (1999), and uses the language modelsmoothing methods of Zhai and Lafferty (2004).This method is used to perform retrieval on the docu-ments?
1-best ASR transcripts and reference humantranscripts.Let C be the collection of documents to retrievefrom.
For each document d contained in C, and eachquery q, the relevance of d to q can be defined asPr(d | q).
This probability cannot be computed di-rectly, but under the assumption that the prior Pr(d)is uniform over all documents in C, we see thatPr(d | q) = Pr(q | d) Pr(d)Pr(q) ?
Pr(q | d);This means that ranking documents by Pr(d | q) isequivalent to ranking them by Pr(q | d), and thusPr(q | d) can be used to measure relevance (Bergerand Lafferty, 1999).Now express q as a series of words drawn froma vocabulary V = {w1, w2, ?
?
?wV }; that is, q =q1q2 ?
?
?
qK , where K is the number of words in thequery, and qi ?
V for 1 ?
i ?
K. Then givena unigram model derived from d which assigns aprobability Pr(w | d) to each word w in V , we cancompute Pr(q | d) as follows:Pr(q | d) = Pr(q1q2 ?
?
?
qK | d)=K?i=1Pr(qi | d)=?w?V ,C(w|q)>0Pr(w|d)C(w|q) (1)where C(w | q) is the word count of w in q.Before using Equation 1, we must estimate a uni-gram model from d: that is, an assignment of proba-bilities Pr(w | d) for all w ?
V .
One way to do thisis to use a maximum likelihood estimate (MLE) ?
anassignment of Pr(w | d) for all w which maximizesthe probability of generating d. The MLE is givenby the equationPr mle(w | d) =C(w | d)|d|where C(w | d) is the number of occurrences ofw in d, and |d| is the total number of words in d.However, using this formula means we will get avalue of zero for Pr(q | d) if even a single queryword qi is not found in d. To overcome this problem,we smooth the model by assigning some probabilitymass to such unseen words.
Specifically, we adopt812a two-stage smoothing method (Zhai and Lafferty,2004):Pr(w | d) = (1 ?
?
)C(w | d) + ?Pr(w | C)|d| + ?+?Pr(w | U) (2)Here, U denotes a background language model, and?
> 0 and ?
?
(0, 1) are parameters to the smooth-ing procedure.
This is a combination of Bayesiansmoothing using Dirichlet priors (MacKay and Peto,1984) and Jelinek-Mercer smoothing (Jelinek andMercer, 1980).The parameter ?
can be set empirically accordingto the nature of the queries.
For the parameter ?, weadopt the estimation procedure of Zhai and Lafferty(2004): we maximize the leave-one-out log likeli-hood of the document collection, namely??1(?
| C) =?d?C?w?VC(w | d)log(C(w | d) ?
1 + ?Pr(w | C)|d| ?
1 + ?
)(3)by using Newton?s method to solve the equation???1(?
| C) = 03.2 Our Proposed Statistical Lattice-BasedRetrieval MethodWe now propose our lattice-based retrieval method.In contrast to the above baseline method, our pro-posed method works on the lattice representation ofspoken documents, as generated by a speech recog-nizer.First, each spoken document is divided into Mshort speech segments.
A speech recognizer thengenerates a lattice for each speech segment.
Aspreviously stated, a lattice is a connected directedacyclic graph with edges labeled with word hypothe-ses and likelihoods.
Thus, each path through the lat-tice contains a hypothesis of the series of words spo-ken in this speech segment, t = t1t2 ?
?
?
tN , alongwith acoustic probabilities Pr(o1 | t1), Pr(o2 | t2),?
?
?
Pr(oN | tN ), where oi denotes the acousticobservations for the time interval of the word tihypothesized by the speech recognizer.
Let o =o1o2 ?
?
?
oN denote the acoustic observations for theentire speech segment; thenPr(o | t) =N?i=1Pr(oi | ti)We then rescore each lattice with an n-gram lan-guage model.
Effectively, this means multiplyingthe acoustic probabilities with n-gram probabilities:Pr(t,o) = Pr(o | t) Pr(t)=N?i=1Pr(oi | ti) Pr(ti | ti?n+1 ?
?
?
ti?1)This produces an expanded lattice in which paths(hypotheses) are weighted by their posterior proba-bilities rather than their acoustic likelihoods: specif-ically, by Pr(t,o) ?
Pr(t | o) rather than Pr(o | t)(Odell, 1995).
The lattice is then pruned, by remov-ing those paths in the lattice whose log posteriorprobabilities ?
to be precise, whose ?
ln Pr(t | o)?
are not within a threshold ?
of the best path?s logposterior probability (in our implementation, ?
=10000.5).Next, we compute the expected count of eachword in each document.
For each word w and eachdocument d comprised of M speech segments rep-resented by M acoustic observations o(1), o(2), ?
?
?o(M), the expected count of w in d isE[C(w | d)] =M?j=1?tC(w | t) Pr(t | o(j))where C(w | t) is the word count of w in the hy-pothesized transcript t. We can also analogouslycompute the expected document length:E[|d|] =M?j=1?t|t|Pr(t | o(j))where |t| denotes the number of words in t.We now replace C(w | d) and |d| in Equation 2with E[C(w | d)] and E[|d|]; thusPr(w | d) = (1 ?
?
)E[C(w | d)] + ?Pr(w | C)E[|d|] + ?+?Pr(w | U) (4)In addition, we also modify the procedure forestimating ?, by replacing C(w | d) and813?
0.528?
0.472?0.5803 0.404?
0.016? 0.764?
0.236? 0.764?q 0.099?- 0.071??
0.066??
0.673?
0.327Figure 1: Example of a word confusion network|d| in Equation 3 with?E[C(w | d)] + 12?and?w?V?E[C(w | d)] + 12?respectively.
The prob-ability estimates from Equation 4 can then be sub-stituted into Equation 1 to yield relevance scores.3.3 Baseline tf ?
idf Lattice-Based RetrievalMethodAs a further comparison, we also implementedMamou et al (2006)?s vector space retrieval method(without query refinement via lexical affinities).
Inthis method, each document d is represented asa word confusion network (WCN) (Mangu et al,2000) ?
a simplified lattice which can be viewed asa sequence of confusion sets c1, c2, c3, ?
?
?
.
Each cicorresponds approximately to a time interval in thespoken document and contains a group of word hy-potheses, and each word w in this group of hypothe-ses is labeled with the probability Pr(w | ci,d) ?
theprobability that w was spoken in the time interval ofci.
A confusion set may also give a probability forPr(?
| ci,d), the probability that no word was spo-ken in the time of ci.
Figure 1 gives an example of aWCN.Mamou et al?s retrieval method proceeds as fol-lows.
First, the documents are divided into speechsegments, lattices are generated from the speech seg-ments, and the lattices are pruned according to thepath probability threshold ?, as described in Sec-tion 3.2.
The lattice for each speech segment is thenconverted into a WCN according to the algorithmof Mangu et al (2000).
The WCNs for the speechsegments in each document are then concatenated toform a single WCN per document.Now, to retrieve documents in response to a queryq, the method computes, for each document d ?
Cand each word w ?
V ,?
the ?document length?
|d|, computed as thenumber of confusion sets in the WCN of d;?
the ?average document length?
avdl, computedasavdl = 1|C|?d??C??d???
;?
the ?document term frequency?
C?
(w | d),computed asC?
(w|d) =?c?occ(w,d)(brank(w|c,d)?Pr(w|c,d))where occ(w,d) is the set of confusion setsin d?s WCN which contain w as a hypothe-sis, rank(w | c,d) is the rank of w in termsof probability within the confusion set c, and(b1, b2, b3, ?
?
? )
= (10, 9, 8, 7, 6, 5, 4, 3, 2, 1,0, 0, 0, ?
?
? )
is a boosting vector which servesto discard all but the top 10 hypotheses, andgives more weight to higher-ranked word hy-potheses;?
the query term frequency C(w | q), which issimply the word count of w in q; and?
the ?inverse document frequency?
idf(w),computed asidf(w) = log OOwwhereOw =?d?C?c?occ(w,d)Pr(w | c,d)O =?w?
?VOw?With these, the relevance of d to q is computed as(Carmel et al, 2001)rel(d,q) =Pw?V C?
(w | d) ?
C(w | q) ?
idf(w)p0.8 ?
avdl + 0.2 ?
|d|4 Experiments4.1 Document CollectionTo evaluate our proposed retrieval method, we per-formed experiments using the Hub5 Mandarin train-ing corpus released by the Linguistic Data Consor-tium (LDC98T26).
This is a conversational tele-phone speech corpus which is 17 hours long, and814contains recordings of 42 telephone calls corre-sponding to approximately 600Kb of transcribedMandarin text.
Each conversation has been brokenup into speech segments of less than 8 seconds each.As the telephone calls in LDC98T26 have notbeen divided neatly into ?documents?, we had tochoose a suitable unit of retrieval which could serveas a ?document?.
An entire conversation would betoo long for such a purpose, while a speech segmentor speaker turn would be too short.
We decided touse 12 -minute time windows with 50% overlap as re-trieval units, following Abberley et al (1999) andTuerk et al (2001).
The 42 telephone conversationswere thus divided into 4,312 retrieval units (?doc-uments?).
Each document comprises multiple con-secutive speech segments.4.2 Queries and Ground Truth RelevanceJudgementsWe then formulated 18 queries (14 test queries, 4development queries) to issue on the document col-lection.
Each query was comprised of one or morewritten Chinese keywords.
We then obtained groundtruth relevance judgements by manually examiningeach of the 4,312 documents to see if it is relevantto the topic of each query.
The number of retrievalunits relevant to each query was found to range from4 to 990.
The complete list of queries and the num-ber of documents relevant to each query are given inTable 1.4.3 Preprocessing of Documents and QueriesNext, we processed the document collection with aspeech recognizer.
For this task we used the Abacussystem (Hon et al, 1994), a large vocabulary contin-uous speech recognizer which contains a triphone-based acoustic system and a frame-synchronizedsearch algorithm for effective word decoding.
EachMandarin syllable was modeled by one to four tri-phone models.
Acoustic models were trained froma corpus of 200 hours of telephony speech from500 speakers sampled at 8kHz.
For each speechframe, we extracted a 39-dimensional feature vec-tor consisting of 12 MFCCs and normalized en-ergy, and their first and second order derivatives.Sentence-based cepstral mean subtraction was ap-plied for acoustic normalization both in the trainingand testing.
Each triphone was modeled by a left-Test queriesTopic Keywords # relevantdocumentsContact information ??,Rh,??,?
?,v 103Chicago z?
15The weather ?,?,y,FZ,Z,?O,?,8?, 117?,?,?,?
?Housing matters 2,,?,2,?,?,?2, 354?
?,y?,2?,?Studies, academia ?,?,A,,?,Wt,'V, 9901,I,?,D,3Litigation F,F,K?,??
31Raising children B/,/,	?,?,??
?,m, 334m?,E?Christian churches s?, ,?,??,s?,?
?,?, 78L?Floods vy,?,?,y 4Clothing q,?
,?,F,?
:g,g, 28:F,?q,Eating out ?,j,iq,?j,>0,,?
57Playing sports KE,?
?,?|E,\E 24Dealings with banks Uq,|,,?,TQ 54Computers and ?,?
?,?G 175softwareDevelopment queriesTopic Keywords # relevantdocumentsPassport and visa ?L,?y,?
?,C?,I,#?
143mattersWashington D. C. ??
15Working life ??,,K?,{,?*,??,?
?, 509??,l,??,?
?,3/,?,?1996 Olympics ??
?,?}L 8Table 1: List of test and development queriesto-right 3-state hidden Markov model (HMM), eachstate having 16 Gaussian mixture components.
Intotal, we built 1,923 untied within-syllable triphonemodels for 43 Mandarin phonemes, as well as 3 si-lence models.
The search algorithm was supportedby a loop grammar of over 80,000 words.We processed the speech segments in our collec-tion corpus, to generate lattices incorporating acous-tic likelihoods but not n-gram model probabilities.We then rescored the lattices using a backoff tri-815gram language model interpolated in equal propor-tions from two trigram models:?
a model built from the TDT-2, TDT-3, andTDT-4 Mandarin news broadcast transcripts(about 58Mb of text)?
a model built from corpora of transcripts ofconversations, comprised of a 320Kb subset ofthe Callhome Mandarin corpus (LDC96T16)and the CSTSC-Flight corpus from the ChineseCorpus Consortium (950Kb)The unigram counts from this model were also usedas the background language model U in Equations 2and 4.The reference transcripts, queries, and trigrammodel training data were all segmented into wordsusing Low et al (2005)?s Chinese word segmenter,trained on the Microsoft Research (MSR) corpus,with the speech recognizer?s vocabulary used as anexternal dictionary.
The 1-best ASR transcripts weredecoded from the rescored lattices.Lattice rescoring, trigram model building, WCNgeneration, and computation of expected wordcounts were done using the SRILM toolkit (Stolcke,2002), while lattice pruning was done with the helpof the AT&T FSM Library (Mohri et al, 1998).We also computed the character error rate (CER)and syllable error rate (SER) of the 1-best tran-scripts, and the lattice oracle CER, for one ofthe telephone conversations in the speech corpus(ma_4160).
The CER was found to be 69%, theSER 63%, and the oracle CER 29%.4.4 Retrieval and EvaluationWe then performed retrieval on the document col-lection using the algorithms in Section 3, using thereference transcripts, the 1-best ASR transcripts, lat-tices, and WCNs.
We set ?
= 0.1, which was sug-gested by Zhai and Lafferty (2004) to give good re-trieval performance for keyword queries.The results of retrieval were checked against theground truth relevance judgements, and evaluated interms of the non-interpolated mean average preci-sion (MAP):MAP = 1LL?i=1??1RiRi?j=1jri,j?
?Retrieval Retrieval MAP for MAP formethod source development testqueries queriesStatistical Reference 0.5052 0.4798transcriptsStatistical 1-best 0.1251 0.1364transcriptsVector space Lattices, 0.1685 0.1599tf ?
idf ?
= 27, 500Statistical Lattices, 0.2180 0.2154?
= 65, 000Table 2: Summary of experimental resultswhere L denotes the total number of queries, Ri thetotal number of documents relevant to the ith query,and ri,j the position of the jth relevant documentin the ranked list output by the retrieval method forquery i.For the lattice-based retrieval methods, we per-formed retrieval with the development queries usingseveral values of ?
between 0 and 100,000, and thenused the value of ?
with the best MAP to do retrievalwith the test queries.5 Experimental ResultsThe results of our experiments are summarizedin Table 2; the MAP of the two lattice-basedretrieval methods, Mamou et al (2006)?s vectorspace method and our proposed statistical retrievalmethod, are shown in Figure 2 and Figure 3 respec-tively.The results show that, for the vector space re-trieval method, the MAP of the development queriesis highest at ?
= 27, 500, at which point the MAPfor the test queries is 0.1599; and for our proposedmethod, the MAP for the development queries ishighest at ?
= 65, 000, and at this point the MAPfor the test queries reaches 0.2154.As can be seen, the performance of our statisticallattice-based method shows a marked improvementover the MAP of 0.1364 achieved using only the 1-best ASR transcripts, and indeed a one-tailed Stu-dent?s t-test shows that this improvement is statisti-cally significant at the 99.5% confidence level.
Thestatistical method also yields better performancethan Mamou et al?s vector space method ?
a t-test816For 4 development queries0.120.130.140.150.160.170.180.190.20.210.220.230.240  20000  40000  60000  80000  100000MAP?
(max.
log probability difference of paths)Retrieval using word probabilities from word confusion networks?
= 27,500For 14 test queries0.130.140.150.160.170.180.190.20.210.220.230.240  20000  40000  60000  80000  100000MAP?
(max.
log probability difference of paths)Retrieval using word probabilities from word confusion networks?
= 27,500Figure 2: MAP of Mamou et al (2006)?s vectorspace method for lattice-based retrieval, at variouspruning thresholds ?shows the performance difference to be statisticallysignificant at the 97.5% confidence level.6 Conclusions and Future WorkWe have presented a method for performing spo-ken document retrieval using lattices which is basedon a statistical language modeling retrieval frame-work.
Results show that our new method can sig-nificantly improve the retrieval MAP compared tousing only the 1-best ASR transcripts.
Also, ourproposed retrieval method has been shown to out-perform Mamou et al (2006)?s vector space lattice-based retrieval method.Besides the better empirical performance, ourmethod also has other advantages over Mamou etal.
?s vector space method.
For one, our method com-putes expected word counts directly from rescoredlattices, and does not require an additional step toFor 4 development queries0.120.130.140.150.160.170.180.190.20.210.220.230.240  20000  40000  60000  80000  100000MAP?
(max.
log probability difference of paths)Retrieval using expected counts from latticesRetrieval using 1?best transcripts?
= 65,000For 14 test queries0.130.140.150.160.170.180.190.20.210.220.230.240  20000  40000  60000  80000  100000MAP?
(max.
log probability difference of paths)Retrieval using expected counts from latticesRetrieval using 1?best transcripts?
= 65,000Figure 3: MAP of our proposed statistical methodfor lattice-based retrieval, at various pruning thresh-olds ?convert lattices lossily to WCNs.
Furthermore, ourmethod uses all the hypotheses in each lattice, ratherthan just the top 10 word hypotheses at each timeinterval.
Most importantly, our method providesa more natural and more principled approach tolattice-based spoken document retrieval based on asound statistical foundation, by harnessing the factthat lattices are themselves statistical models; thestatistical approach also means that our method canbe more easily augmented with additional statisticalknowledge sources in a principled way.For future work, we plan to test our proposedmethod on English speech corpora, and with larger-scale retrieval tasks involving more queries andmore documents.
We would like to extend ourmethod to other speech processing tasks, such asspoken document classification and example-basedspoken document retrieval as well.817ReferencesDave Abberley, David Kirby, Steve Renals, and TonyRobinson.
1999.
The THISL broadcast news retrievalsystem.
In Proceedings of ESCA ETRW Workshop onAccessing Information in Spoken Audio, pages 14?19.Adam Berger and John Lafferty.
1999.
Information re-trieval as statistical translation.
In Proceedings of SI-GIR 1999, pages 222?229.David Carmel, Einat Amitay, Miki Herscovici, YoelleMaarek, Yael Petruschka, and Aya Soffer.
2001.
Juruat TREC 10 ?
Experiments with index pruning.
InProceedings of the Tenth Text Retrieval Conference(TREC-10), pages 228?236.Ciprian Chelba and Alex Acero.
2005.
Position specificposterior lattices for indexing speech.
In Proceedingsof ACL 2005, pages 443?450.Berlin Chen, Hsin-min Wang, and Lin-shan Lee.
2004.
Adiscriminative HMM/n-gram-based retrieval approachfor Mandarin spoken documents.
ACM Transactionson Asian Language Information Processing, 3(2):128?145.Andrew O. Hatch, Barbara Peskin, and Andreas Stol-cke.
2005.
Improved phonetic speaker recognition us-ing lattice decoding.
In Proceedings of IEEE ICASSP2005, 1:169?172.Hsiao-Wuen Hon, Baosheng Yuan, Yen-Lu Chow, S.Narayan, and Kai-Fu Lee.
1994.
Towards large vocab-ulary Mandarin Chinese speech recognition.
In Pro-ceedings of IEEE ICASSP 1994, 1:545?548.David Anthony James and Steve J.
Young.
1994.
Afast lattice-based approach to vocabulary independentwordspotting.
In Proceedings of ICASSP 1994, 1:377?380.David Anthony James.
1995.
The Application of Classi-cal Information Retrieval Techniques to Spoken Docu-ments.
Ph.
D. thesis, University of Cambridge.Frederick Jelinek and Robert L. Mercer.
1980.
Interpo-lated estimation of Markov source parameters fromsparse data.
In Proceedings of the Workshop on Pat-tern Recognition in Practice, pages 381?397.Gareth J. F. Jones, Jonathan T. Foote, Karen Sp?rckJones, and Steve J.
Young.
1996.
Retrieving spokendocuments by combining multiple index sources.
InProceedings of SIGIR 1996, pages 30?38.Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo.
2005.
Amaximum entropy approach to Chinese word segmen-tation.
In Proceedings of the Fourth SIGHAN Work-shop on Chinese Language Processing, pages 161?164.David J. C. MacKay and Linda C. Bauman Peto.
1994,A hierarchical Dirichlet language model.
Natural Lan-guage Engineering, 1(3):1?19.Jonathan Mamou, David Carmel, and Ron Hoory.
2006.Spoken document retrieval from call-center conversa-tions.
In Proceedings of SIGIR 2006, pages 51?58.Lidia Mangu, Eric Brill, and Andreas Stolcke.
2000.Finding consensus in speech recognition: word errorminimization and other applications of confusion net-works.
Computer Speech and Language, 14(4):373?400.Mehryar Mohri, Fernando C. N. Pereira, and Michael Ri-ley.
1998.
A rational design for a weighted finite-statetransducer library.
Lecture Notes in Computer Science,1436:144?158.National Institute of Standards and Technol-ogy.
2000.
TREC-9 SDR Track web site.www.nist.gov/speech/tests/sdr/sdr2000/sdr2000.htm.Julian James Odell.
1995.
The Use of Context in LargeVocabulary Speech Recognition.
Ph.
D. thesis, Cam-bridge University Engineering Department.Jay M. Ponte and W. Bruce Croft.
1998.
A language mod-eling approach to information retrieval.
In Proceedingsof SIGIR 1998, pages 275?281.Murat Saraclar and Richard Sproat.
2004.
Lattice-basedsearch for spoken utterance retrieval.
In Proceedingsof HLT-NAACL 2004, pages 129?136.Matthew A. Siegler.
1999.
Integration of ContinuousSpeech Recognition and Information Retrieval for Mu-tually Optimal Performance.
Ph.
D. thesis, CarnegieMellon University.Fei Song and W. Bruce Croft.
1999.
A general lan-guage model for information retrieval.
In Proceedingsof CIKM 1999, pages 316?321.Andreas Stolcke.
2002.
SRILM ?
An extensible languagemodeling toolkit.
In Proceedings of ICSLP, 2:901?904.Andy Tuerk, Sue E. Johnson, Pierre Jourlin, KarenSp?rck Jones, and Philip C. Woodland.
2001.
TheCambridge University multimedia document retrievaldemo system.
International Journal of Speech Tech-nology, 4(3?4):241?250.Peng Yu, Kaijiang Chen, Lie Lu, and Frank Seide.2005.
Searching the audio notebook: keywordsearch in recorded conversations.
In Proceedings ofHLT/EMNLP 2005, pages 947?954.Chengxiang Zhai and John Lafferty.
2004.
A study ofsmoothing methods for language models applied to in-formation retrieval.
ACM Transactions on InformationSystems, 22(2):179?214.818
