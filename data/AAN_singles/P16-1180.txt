Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1913?1923,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsMining Paraphrasal Typed Templates from a Plain Text CorpusOr BiranColumbia Universityorb@cs.columbia.eduTerra BlevinsColumbia Universitytlb2145@columbia.eduKathleen McKeownColumbia Universitykathy@cs.columbia.eduAbstractFinding paraphrases in text is an impor-tant task with implications for genera-tion, summarization and question answer-ing, among other applications.
Of par-ticular interest to those applications is thespecific formulation of the task where theparaphrases are templated, which providesan easy way to lexicalize one message inmultiple ways by simply plugging in therelevant entities.
Previous work has fo-cused on mining paraphrases from paralleland comparable corpora, or mining veryshort sub-sentence synonyms and para-phrases.
In this paper we present an ap-proach which combines distributional andKB-driven methods to allow robust miningof sentence-level paraphrasal templates,utilizing a rich type system for the slots,from a plain text corpus.1 IntroductionOne of the main difficulties in Natural LanguageGeneration (NLG) is the surface realization ofmessages: transforming a message from its inter-nal representation to a natural language phrase,sentence or larger structure expressing it.
Oftenthe simplest way to realize messages is though theuse of templates.
For example, any message aboutthe birth year and place of any person can be ex-pressed with the template ?
[Person] was born in[Place] in [Year]?.Templates have the advantage that the genera-tion system does not have to deal with the inter-nal syntax and coherence of each template, andcan instead focus on document-level discourse co-herence and on local coreference issues.
On theother hand, templates have two major disadvan-tages.
First, having a human manually compose atemplate for each possible message is costly, espe-cially when a generation system is relatively open-ended or is expected to deal with many domains.In addition, a text generated using templates oftenlacks variation, which means the system?s outputwill be repetitive, unlike natural text produced bya human.In this paper, we are concerned with a taskaimed at solving both problems: automaticallymining paraphrasal templates, i.e.
groups of tem-plates which share the same slot types and which,if their slots are filled with the same entities, re-sult in paraphrases.
We introduce an unsupervisedapproach to paraphrasal template mining from thetext of Wikipedia articles.Most previous work on paraphrase detection fo-cuses either on a corpus of aligned paraphrasecandidates or on such candidates extracted froma parallel or comparable corpus.
In contrast, weare concerned with a very large dataset of tem-plates extracted from a single corpus, where anytwo templates are potential paraphrases.
Specifi-cally, paraphrasal templates can be extracted fromsentences which are not in fact paraphrases; forexample, the sentences ?The population of Mis-souri includes more than 1 million African Ameri-cans?
and ?Roughly 185,000 Japanese Americansreside in Hawaii?
can produce the templated para-phrases ?The population of [american state] in-cludes more than [number] [ethnic group]?
and?Roughly [number] [ethnic group] reside in [amer-ican state]?.
Looking for paraphrases among tem-plates, instead of among sentences, allows us toavoid using an aligned corpus.Our approach consists of three stages.
First, weprocess the entire corpus and determine slot lo-cations, transforming the sentences to templates(Section 4).
Next, we find most approriate type foreach slot using a large taxonomy, and group to-gether templates which share the same set of types1913as potential paraphrases (Section 5).
Finally, wecluster the templates in each group into sets ofparaphrasal templates (Section 6).We apply our approach to six corpora represent-ing diverse subject domains, and show through acrowd-sourced evaluation that we can achieve ahigh precision of over 80% with a reasonable sim-ilarity threshold setting.
We also show that ourthreshold parameter directly controls the trade-offbetween the number of paraphrases found and theprecision, which makes it easy to adjust our ap-proach to the needs of various applications.2 Related WorkTo our knowledge, although several works existwhich utilize paraphrasal templates in some way,the task of extracting them has not been definedas such in the literature.
The reason seems to be adifference in priorities.
In the context of NLG, An-geli et al (2010) as well as Kondadadi et al (2013)used paraphrasal templates extracted from alignedcorpora of text and data representations in specificdomains, which were grouped by the data typesthey relate to.
Duma and Klein (2013) extracttemplates from Wikipedia pages aligned with RDFinformation from DBPedia, and although they donot explicitly mention aligning multiple templatesto the same set of RDF templates, the possibilityseems to exist in their framework.
In contrast, weare interested in extracting paraphrasal templatesfrom non-aligned text for general NLG, as alignedcorpora are difficult to obtain for most domains.While template extraction has been a relativelysmall part of NLG research, it is very prominentin the field of Information Extraction (IE), begin-ning with Hearst (1992).
There, however, the goalis to extract good data and not to extract templatesthat are good for generation.
Many pattern extrac-tion (as it is more commonly referred to in IE) ap-proaches focus on semantic patterns that are notcoherent lexically or syntactically, and the idea ofparaphrasal templates is not important (Chambersand Jurafsky, 2011).
One exception which expic-itly contains a paraphrase detection component is(Sekine, 2006).Meanwhile, independently of templates, detect-ing paraphrases is an important, difficult and well-researched problem of Natural Language Process-ing.
It has implications for the general study of se-mantics as well as many specific applications suchas Question Answering and Summarization.
Re-search that focuses on mining paraphrases fromlarge text corpora is especially relevant for ourwork.
Typically, these approaches utilize a paral-lel (Barzilay and McKeown, 2001; Ibrahim et al,2003; Pang et al, 2003; Quirk et al, 2004; Fujitaet al, 2012; Regneri and Wang, 2012) or compa-rable corpus (Shinyama et al, 2002; Barzilay andLee, 2003; Sekine, 2005; Shen et al, 2006; Zhaoet al, 2009; Wang and Callison-Burch, 2011), andthere have been approaches that leverage bilingualaligned corpora as well (Bannard and Callison-Burch, 2005; Madnani et al, 2008).Of the above, two are particularly relevant.Barzilay and Lee (2003) produce slotted latticesthat are in some ways similar to templates, andtheir work can be seen as the most closely relatedto ours.
However, as they rely on a comparablecorpus and produce untyped slots, it is not directlycomparable.
In our approach, it is precisely thefact that we use a rich type system that allows us toextract paraphrasal templates from sentences thatare not, by themselves, paraphrases and avoid us-ing a comparable corpus.
Sekine (2005) producestyped phrase templates, but the approach doesnot allow learning non-trivial paraphrases (that is,paraphrases that do not share the exact same key-words) from sentences that do not share the sameentities (thus remaining dependent on a compara-ble corpus), and the type system is not very rich.
Inaddition, that approach is limited to learning shortparaphrases of relations between two entities.Another line of research is based on contex-tual similarity (Lin and Pantel, 2001; Pas?ca andDienes, 2005; Bhagat and Ravichandran, 2008).Here, shorter (phrase-level) paraphrases are ex-tracted from a single corpus when they appearin a similar lexical (and in later approaches, alsosyntactic) context.
The main drawbacks of thesemethods are their inability to handle longer para-phrases and their tendency to find phrase pairs thatare semantically related but not real paraphrases(e.g.
antonyms or taxonomic siblings).More recent work on paraphrase detection has,for the most part, focused on classifying providedsentence pairs as paraphrases or not, using the Mi-crosoft Paraphrase Corpus (Dolan et al, 2004).Mihalcea et al (2006) evaluated a wide range oflexical and semantic measures of similarity and in-troduced a combined metric that outperformed allprevious measures.
Madnani et al (2012) showedthat metrics from Machine Translation can be used1914to find paraphrases with high accuracy.
Anotherline of research uses the similarity of texts in alatent space created through matrix factorization(Guo and Diab, 2012; Ji and Eisenstein, 2013).Other approaches that have been explored are ex-plicit alignment models (Das and Smith, 2009),distributional memory tensors (Baroni and Lenci,2010) and syntax-aware representations of multi-word phrases using word embeddings (Socher etal., 2011).
Word embeddings were also used byMilajevs et al (2014).
These approaches are notcomparable to ours because they focus on classifi-cation, as opposed to mining, of paraphrases.Detecting paraphrases is closely related to re-search on the mathematical representation of sen-tences and other short texts, which draws on a vastliterature on semantics, including but not limitedto lexical, distributional and knowledge-based se-mantics.
Of particular interest to us is the work ofBlacoe and Lapata (2012), which show that simplecombination methods (e.g., vector multiplication)in classic vector space representations outperformmore sophisticated alternatives which take into ac-count syntax and which use deep representations(e.g.
word embeddings, or the distributional mem-ory approach).
This finding is appealing sinceclassic vector space representation (distributionalvectors) are easy to obtain and are interpretable,making it possible to drill into errors.3 TaxonomyOur method relies on a type system which linksentities to one another in a taxonomy.
We usea combination of WordNet (Fellbaum, 1998) andDBPedia (Auer et al, 2007), which provides botha rich top-level type system with lexicalizationsof multiple senses and a large database of enti-ties linked through the type system (the top-levelDBPedia categories all have cognates in WordNet,which make the two easy to combine).
Leveragingthe fact that DBPedia entities have correspondingWikipedia pages, we also use the redirect termsfor those pages as alternative lexicalizations of theentity (e.g., the Wikipedia article ?United States?has ?USA?
as a redirect term, among others).4 Creating TemplatesThe first step to creating the templates is to findentities, which are candidates to becoming slotsin the templates.
Since we are trying to findsentence-level paraphrasal templates, each sen-tence in the corpus is a potential template.Entities are found in multiple ways.
First, weuse regular expressions to find dates, percentages,currencies, counters (e.g., ?9th?)
and general num-bers.
Those special cases are immediately giventheir known type (e.g., ?date?
or ?percentage?
).Next, after POS-tagging the entire corpus, we lookfor candidate entities of the following kinds: termsthat contain only NNP (including NNPS) tags;terms that begin and end with an NNP and con-tain only NNP, TO, IN and DT tags; and termsthat contain only capitalized words, regardless ofthe POS tags.
Of these candidates, we only keepones that appear in the taxonomy.
Unlike the spe-cial cases above, the type of the slots created fromthese general entities is not yet known and will bedecided in the next step.At the end of this step, we have a set of partially-typed templates: one made from each sentence inthe corpus, with its slots (but not their types inmost cases) defined by the location of entities.
Weremove from this set al templates which have lessthan two slots as these are not likely to be interest-ing, and all templates which have more than fiveslots to avoid excessively complicated templates.We originally experimented with simply accept-ing any term that appears in the taxonomy as anentity.
That method, however, resulted in a largenumber of both errors and entities that were toogeneral to be useful (e.g, ?table?, ?world?
and sim-ilar terms are in the taxonomy).
Note that NER ap-proaches, even relatively fine-grained ones, wouldnot give us the same richness of types that directlycomparing to the taxonomy allows (and the nextstep requires that each entity we handle exist inthe taxonomy, anyway).5 Template Typing and GroupingDetermining the type of a slot in the templatepresents two difficulties.
First, there is a sense dis-ambiuation problem, as many lexical terms havemore than one sense (that is, they can correspondto more than one entry in the taxonomy).
Sec-ond, even if the sense is known, it is not clearwhich level of the taxonomy the type should bechosen from.
For example, consider the sentence?
[JFK] is [New York]?s largest airport?
(the termsin square brackets will become slots once theirtypes are determined).
?JFK?
is ambiguous: it canbe an airport, a president, a school, etc.
The first1915step in this process is, then, to determine which ofthe possible senses of the term best fits the sen-tence.
But once we determine that the sense of?JFK?
here is of an airport, there are differenttypes we can choose.
JFK is a New York Air-port, which is a type of Airport, which is a typeof Air Field, which is a type of Facility and soon.
The specificity of the type we choose will de-termine the correctness of the template, and alsowhich other templates we can consider as poten-tial paraphrases.Our solution is a two-stage distributional ap-proach: choosing the sense, and then choosing thetype level that best fit the context of the slot.
Ineach stage, we construct a pseudo ?
sentence (acollection of words in arbitrary, non-grammaticalorder) from words used in the taxonomy to de-scribe each option (a sense in the first stage, and atype level in the second stage), and then use theirvector representations to find the option that bestmatches the context.Following the observation of Blacoe and Lapata(2012) that simple similarity metrics in traditionalvector representations match and even outperformmore sophisticated representations in finding rela-tions among short texts as long as multiplicationis used in forming vector representations for thetexts, we use traditional context vectors as the ba-sis of our comparisons in both stages.
We collectcontext vectors from the entire English Wikipediacorpus, with a token window of 5.
To avoid noisefrom rarely occuring words and reduce the size ofthe vectors, we remove any feature with a countbelow a threshold of log10(?)
where ?
is thesum of all feature counts in the vector.
Finally,the vector features are weighted with (normalized)TF*IDF.1For a multi-word collection (e.g.
a pseudo-sentence) ?, we define the features of the com-bined vector V?using the vectors of memberwords Vwas:Vj?= (?w?
?Vjw)1|S|(1)Where Vjwis the value of the jth feature of Vw.To choose the sense of the slot (the first stage),we start with S, the set of all possible senses (inthe taxonomy) for the entity in the slot.
We cre-ate a pseudo-sentence ?sfrom the primary lexi-1A ?term?
being a single feature count, and a ?document?being a vectorcalizations of all types in the hierarchy above eachsense s - e.g., for the airport sense of JFK we cre-ate a single pseudo-sentence ?JFK?airport?senseconsisting of the terms ?New York airport?, ?air-port?, ?air field?, ?facility?
and so on.2We create avector representation V?sfor each ?susing Equa-tion 1.
Then, we create a pseudo-sentence ?contextfor the context of the slot, composed of the wordsin a 5-word window to the left and right of theslot in the original sentence, and create the vectorV?context.
We choose the sense s?
with the highestcosine similarity to the contex:s?
= arg maxs?Scos(V?s, V?context)Note that this is a deep similarity - the similarityof the (corpus) context of the sense and the (cor-pus) context of the slot context; the words in thesentence themselves are not used directly.We use the lexicalizations of all types in the hi-erarchy to achieve a more robust vector represen-tation that has higher values for features that co-occur with many levels in the sense?s hierarchy.For example, we can imagine that ?airplane?
willco-occur with many of the types for the JFK air-port sense, but ?La Guardia?
will not (helping tolower the score of the first, too-specific sense of?New York airport?)
and neither will features thatco-occur with other senses of a particular type -e.g., ?Apple?
for the ?airport?
type.3Once the sense is chosen, we choose the propertype level to use (the second stage).
Here we cre-ate a pseudo-sentence for each type level sepa-rately, composed of all possible lexicalizations forthe type.
For example, the ?air field?
type containsthe lexicalizations ?air field?, ?landing field?, and?flying field?.
These pseudo-sentences are thencompared to the context in the same way as above,and the one with highest similarity is chosen.
Thereason for using all lexicalizations is similar tothe one for using all types when determining thesense: to create a more robust representation thatdown-scores arbitrary co-occurences.At the end of this step, the templates are fullytyped.
Before continuing to the next step offinding paraphrases, we group all potential para-phrases together.
Potential paraphrases are simply2But we exclude a fixed, small set of the most abstracttypes from the first few levels of the WordNet hierarchy, asthese turn out to never be useful3AirPort is the name of an Apple product1916groups of templates which share exactly the sameset of slot types (regardless of ordering).6 Finding Paraphrases within GroupsEach group of potential paraphrases may containmultiple sub-groups such that each of the membersof the subgroup is a paraphrase of all the others.
Inthis last stage, we use a clustering algorithm to findthese sub-groups.We define the distance between any two tem-plates in a group as the Euclidean distance be-tween the vectors (created using Equation 1) of thetwo templates with the entity slots removed (thatis, the pseudo-sentences created with all words inthe template outside of the slots).
We tried otherdistance metrics as well (for example, averagingthe distances between the contexts surroundingeach pair of corresponding slots in both templates)but the Euclidean distance seemed to work best.Using this metric, we apply single-linkage ag-glomerative clustering, with the stopping criteriadefined as a threshold ?
for the maximum sum ofsquared errors (SSE) within any cluster.
Specifi-cally, the algorithm stops linking if the cluster Cthat would be created by the next link satisfies:log(C?vd(v, ?C)2) ?
?Where ?Cis the centroid of C and d is the Eu-clidean distance.
The logarithm is added for con-venience, since the SSE can get quite large and wewant to keep ?
on a smaller scale.The intuition behind this algorithm is that someparaphrases will be very similar (lexically or on adeeper level) and easy to find, while some will bemore difficult to distinguish from template pairsthat are related but not paraphrasal.
The single-linkage approach is essentially transductive, al-lowing the most obvious clusters to emerge firstand avoiding the creation of a central model thatwill become less precise over time.
The thresholdis a direct mechanism for controlling the trade-offbetween precision and recall.At the end of this step, any pair of templateswithin the same cluster is considered a para-phrase.
Clusters that contain only a single tem-plate are discarded (in groups that have high dis-tances among their member templates, often theentire group is discarded since even a single linkviolates the threshold).7 EvaluationTo evaluate our method, we applied it to the six do-mains described in Table 1.
We tried to choose aset of domains that are diverse in topic, size anddegree of repeated structure across documents.For each domain, we collected a corpus com-posed of relevant Wikipedia articles (as describedin the table) and used the method described inSections 4-6 to extract paraphrasal templates.
Weused Wikipedia for convenience, since it allows usto easily select domain corpora, but there is noth-ing in our approach that is specific to Wikipedia;it can be applied to any text corpus.We sampled 400 pairs of paraphrases extractedfrom each domain and used this set of 2400 pairsto conduct a crowd-sourced human evaluation onCrowdFlower.
For each template pair, we ran-domly selected one and used its original entitiesin both templates to create two sentences aboutthe same set of entities.
The annotators were pre-sented with this pair and asked to score the extentto which they are paraphrases on a scale from 1 to5.
Table 2 shows the labels and a brief version ofthe explanations provided for each.
To ensure thequality of annotations, we used a set of hidden testquestions throughout the evaluation and rejectedthe contributions of annotators which did not get atleast 70% of the test questions correctly.
Of thosethat did perform well on the test questions, we hadthree annotators score each pair and used the aver-age as the final score for the pair.
In 39.4% of thecases, all three annotators agreed; two annotatorsagreed in another 47% of the cases, and in the re-maining 13.6% there was complete disagreement.The inter-annotator agreement for the two anno-tators that had the highest overlap (27 annotatedpairs), using Cohen?s Kappa, was ?
= 0.35.The overall results are shown in Figure 1.
Notethat because of our clustering approach, we havea choice of similarity threshold.
The results areshown across a range of thresholds from 8 to 11- it is clear from the figure that the threshold pro-vides a way to control the trade-off between thenumber of paraphrases generated and their preci-sion.
Table 3 shows the results with our preferredthreshold of 9.5.The number of paraphrase clusters foundchanges with the threshold.
For the 9.5 thresholdwe find 512 clusters over all domains, a little over60% of the number of paraphrases.
The distribu-tion of their sizes is Zipfian: a few very large clus-1917Domain Description Size Source article linkNBA NBA teams 30 National_Basketball_AssociationStates US states 50 N/AAuMa Automobile manufacturers 241 List_of_automobile_manufacturersMetal Heavy Metal bands (originalmovement, 1967-1981)291 List_of_heavy_metal_bandsCWB Battles of the AmericanCivil War446 List_of_American_Civil_War_battlesMarvel Superheroes from the Mar-vel Comics universe932 Category:Marvel_Comics_superheroesTable 1: Evaluation domains.
Source article links are preceded by https://en.wikipedia.org/wiki/Score Label Explanation5 Perfect Paraphrase The two sentences are equivalent in meaning (but allow differencesin e.g.
tense, wordiness or sentiment)4 Almost Paraphrase The two sentences are equivalent in meaning with one minor differ-ence (e.g., change or remove one word)3 Somewhat Paraphrase The two sentences are equivalent in meaning with a few minor dif-ferences, or are complex sentences with a part that is a paraphraseand a part that is not2 Related The sentences are related in meaning, but are not paraphrases1 Unrelated The meanings of the sentences are unrelatedTable 2: Annotation score labels and explanationsFigure 1: The average scores for each domain,for a range of threshold choices.
The number inparentheses for each threshold is the number ofparaphrases generatedDomain # paraphrases Avg.
%3+ %4+NBA 30 4.1 88% 70%States 171 4.1 86% 76%AuMa 58 3.5 80% 50%Metal 98 3.7 82% 63%CWB 81 3.6 75% 56%Marvel 428 3.7 83% 63%Table 3: Size, average score, % of pairs with ascore above 3 (paraphrases), and % of pairs witha score above 4 (high quality paraphrases) for thedifferent domains with a 9.5 thresholdters, dozens of increasingly smaller medium-sizedones and a long tail of clusters that contain onlytwo templates.The vast majority of paraphrase pairs comefrom sentences that were not originally para-phrases (i.e, sentences that originally had differ-ent entities).
With a 9.5 threshold, 86% of para-phrases answer that criteria.
While that numbervaries somewhat across thresholds, it is alwaysabove 80% and does not consistently increase ordecrease as the threshold increases.1918Corpus type Prec.
PPSThis paper, ?
= 8 Unaligned 94% 0.005This paper, ?
= 9.5 Unaligned 82% 0.013This paper, ?
= 11 Unaligned 65% 0.1Barzilay and McKeown (2001) Parallel 86.5% 0.1 *Ibrahim et al (2003) Parallel 41.2% 0.11 *Pang et al (2003) Parallel 81.5% 0.33Barzilay and Lee (2003) Comparable 78.5% 0.07Bannard and Callison-Burch (2005) Parallel bilingual 61.9% n/a **Zhao et al (2009) Parallel or Comparable 70.6% n/a **Wang and Callison-Burch (2011) Comparable 67% 0.01Fujita et al (2012) Parallel bilingual + unaligned 58% 0.34Regneri and Wang (2012) Parallel 79% 0.17*These papers do not report the number of sentences in the corpus, but do report enough for us to estimate it(e.g.
the number of documents or the size in MB)**These papers do not report the number of paraphrases extracted, or such a number does not exist in their approachTable 4: Comparison with the precision and paraphrases generated per input sentence (PPS) of relevantprior workWhile we wanted to show a meaningful com-parison with another method from previous work,none of them do what we are doing here - extrac-tion of sentence-size paraphrasal templates froma non-aligned corpus - and so a comparison us-ing the same data would not be fair (and in mostcases, not possible).
While it seems that provid-ing the results of human evaluation without com-parison to prior methods is the norm in most rel-evant prior work (Ibrahim et al, 2003; Pas?ca andDienes, 2005; Bannard and Callison-Burch, 2005;Fujita et al, 2012), we wanted to at least get somesense of where we stand in comparison to othermethods, and so we provide a list of (not directlycomparable) results reported by other authors inTable 4.4While it is impossible to meaningfullycompare and rate such different methods, thesenumbers support the conclusion that our single-corpus, domain-agnostic approach achieves a pre-cision that is similar to or better than other meth-ods.
We also include the paraphrase per sentence(PPS) value - the ratio of paraphrases extracted tothe number of input sentences of the corpus - foreach method in the table.
We intend this figureas the closest thing to recall that we can conceive4We always show the results of the best system described.Where needed, if results were reported in a different way thansimple percentages, we use averages and other appropriatemeasures.
Some previous work defines related sentences (asopposed to paraphrases) as positives and some does not; wedo not change their numbers to fit a single definition, but weuse the harsher measure for our own resultsfor mining paraphrases.
However, keep in mindthat it is not a comparable figure across the meth-ods, since different corpora are used.
In partic-ular, it is expected to be significantly higher forparallel corpora, where the entire corpus consistsof potential paraphrases (and that fact is reflectedin Table 4, where some methods that use parallelcorpora have a PPS that is an order of magnitudehigher than other methods).8 Discussion and ExamplesThe first thing to note about the results shownin Figure 1 is that even for the highest thresholdconsidered, which gives us a ?21 improvementin size over the smallest threshold considered, alldomains except CWB achieve an average scorehigher than 3, meaning most of the pairs extractedare paraphrases (CWB is close - a little over 2.9on average).
For the lowest threshold considered,all domains are at a precision above 88%, and forthree of them it is 100%.
In general, across all do-mains, there seems to be a significant drop in pre-cision (and a significant boost in size) for thresh-olds between 9 and 10, while the precisions andsizes are fairly stable for thresholds between 8 and9 and between 10 and 11.
This result is encourag-ing: since the method seems to behave fairly simi-larly for different domains with regard to changesin the threshold, we should be able to expect sim-ilar behavior for new domains as the threshold is1919adjusted.The magnitude of precision across domains isanother matter.
It is clear from the results thatsome domains are more difficult than others.
TheMetal domain seems to be the hardest: it neverachieves an average score higher than 3.8.
Forthe highest threshold, however, Metal is not dif-ferent from most of the others, while CWB is sig-nificantly lower in precision.
The reason seems tobe the styles of the domain articles: some domainstend to have a more structured form.
For exam-ple, each article in the States domain will discussthe economy, demographics, formation etc.
of thestate, and we are more likely to find paraphrasesthere (simply by virtue of there being 50?49 can-didates).
Articles in the Metal domain are muchless structured, and there are fewer obvious para-phrase candidates.
In CWB articles, there are afew repetitive themes: the outcome of the battle,the casualties, the generals involved etc., but be-yond that it is fairly unstructured.
This ?struc-turality?
of the domain also affects the number ofparaphrases that can be found, as evident from thenumber of paraphrases found in the states domainin Table 3 as compared with the (much larger)Metal and CWB domains.Table 5 shows a number of examples from eachdomain, along with the score given to each by theannotators.
In an informal error analysis, we sawa few scenarios recurring in low-scored pairs.
TheMetal example at the bottom of Table 5 is a dou-ble case of bad sense disambiguation: the albumin the second sentence (?Pyromania?
in the origi-nal) happened to have a name that is also a patho-logical state.
In addition, the number in the sec-ond sentence really was a date (?1980?).
If wehad correctly assigned the senses, these two tem-plates would not be paraphrase candidates.
Theprocess of grouping by type is an important partof improving precision: two sentences can be mis-leadingly similar in the vector space, but it is lesslikely to have two sentences with the exact sameentity types and a high vector similarity that arenot close in meaning.Another scenario is the one seen in the NBAexample that was scored as 1.
Here the senseswere chosen correctly, but the level of the hierar-chy chosen for the person slot was too high.
Ifinstead we had chosen basketball coach and bas-ketball player for the two sentences respectively,they would not be considered as paraphrase can-didates (and note that both meanings are impliedby the templates).
This sort of error does not cre-ate a problem (in our evaluation, at least) if themore accurate sense is the same in both sentences- for example, in the other NBA example (whichscored 4), the place slot could be more accuratelyreplaced with sports arena in both templates.Cases where the types are chosen correctly donot always result in perfect paraphrases, but aretypically at least related (e.g.
in the examples thatscored 2, and to a lesser extent those that scored3).
That scenario can be controlled using a lowerthreshold, with the downside that the number ofparaphrases found decreases.9 Conclusion and Future WorkWe presented a method for extracting paraphrasaltemplates from a plain text corpus in three steps:templatizing the sentences of the corpus; findingthe most appropriate type for each slot; and clus-tering groups of templates that share the sameset of types into paraphrasal sub-groups.
Weconducted a crowd-sourced human evaluation andshowed that our method performs similarly to orbetter than prior work on mining paraphrases, withthree major improvements.
First, we do not relyon a parallel or comparable corpus, which are notas easily obtained; second, we produce typed tem-plates that utilize a rich, fine-grained type system,which can make them more suitable for genera-tion; and third, by using such a type system we areable to find paraphrases from sentence pairs thatare not, before templatization, really paraphrases.Many, if not most, of the worst misidentifica-tions seem to be the result of errors in the sec-ond stage of the approach - disambiguating thesense and specificity of the slot types.
In this paperwe focused on a traditional distributional approachthat has the advantage of being explainable, but itwould be interesting and useful to explore otheroptions such as word embeddings, matrix factor-ization and semantic similarity metrics.
We leavethese to future work.Another task for future work is semantic align-ment.
Our approach discovers paraphrasal tem-plates without aligning them to a semantic mean-ing representation; while these are perfectly usableby summarization, question answering, and othertext-to-text generation applications, it would beuseful for concept-to-text generation and other ap-plications to have each cluster of templates aligned1920Score Domain Templates5 States Per dollar of federal tax collected in [date 1], [american state 1] citizens received approximately [money1] in the way of federal spending.In [date) 1] the federal government spent [money 1] on [american state 1] for every dollar of tax revenuecollected from the state.AuMa Designed as a competitor to the [car 1], [car 2] and [car 3].It is expected to rival the [car 1], [car 2], and [car 3].4 CWB Federal casualties were heavy with at least [number 1] killed or mortally wounded, [number 2] wounded, and [number 3] made prisoner.Federal losses were [number 1] killed, [number 2] wounded, and [number 3] unaccounted for ?
primar-ily prisoners.NBA For the [date 1] season, the [basketball team 1] moved into their new arena , the [place 1], with a seatingcapacity of [number 1].As a result of their success on the court, the [basketball team 1] moved into the [place 1] in [date 1],which seats over [number 1] fans.3 Marvel [imaginary being 1] approached [imaginary being 2], hunting for leads about the whereabouts of theX-Men.
[imaginary being 1] and [imaginary being 2] eventually found the X-Men and became full time mem-bers.Metal In [date 1], [band) 1] recorded their third studio album, ?
[album 1]?, which was produced by KornelijeKova?c.
[band 1] released their next full-length studio album, ?
[album 1]?
in [date 1].2 Auma [company 1] and its subsidiaries created a variety of initiatives in the social sphere, initially in [country1] and then internationally as the company expanded.
[company 1] participated in [country 1]?s unprecedented economic growth of the 1950s and 1960s.Marvel Using her powers of psychological deduction, she picked up on [first name 1]?s attraction towards her,and then [first name 2] admits she is attracted to him as well.While [first name 1] became shy, reserved and bookish, [first name 2] became athletically inclined,aggressive, and arrogant.1 NBA Though the [date 1] 76ers exceeded many on-court expectations, there was a great deal of behind-the-scenes tension between [person 1], his players, and the front office.After an [date 1] start, with [person 1] already hurt, these critics seemed to have been proven right.Metal Within [number 1] hours of the statement, he died of bronchial pneumonia, which was brought on as acomplication of [pathological state 1].With the album?s massive success, ?
[pathological state 1]?
was the catalyst for the [number 1] pop-metalmovement.Table 5: Examples of template pairs and their scoresto a semantic representation of the meaning ex-pressed.
Since we already discover all the entitytypes involved, all that is missing is the proposi-tion (or frame, or set of propositions); this seemsto be a straightforward, though not necessarilyeasy, task to tackle in the near future.ReferencesGabor Angeli, Percy Liang, and Dan Klein.
2010.
Asimple domain-independent probabilistic approachto generation.
In Proceedings of the 2010 Confer-ence on Empirical Methods in Natural LanguageProcessing, EMNLP ?10, pages 502?512, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.S?oren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, and Zachary Ives.2007.
Dbpedia: a nucleus for a web of open data.In Proceedings of the 6th international The seman-tic web and 2nd Asian conference on Asian semanticweb conference, ISWC?07/ASWC?07, pages 722?735, Berlin, Heidelberg.
Springer-Verlag.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Pro-ceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics, ACL ?05, pages 597?604, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Marco Baroni and Alessandro Lenci.
2010.
Distri-butional memory: A general framework for corpus-based semantics.
Comput.
Linguist., 36(4):673?721,December.Regina Barzilay and Lillian Lee.
2003.
Learn-ing to paraphrase: An unsupervised approach us-ing multiple-sequence alignment.
In Proceedings ofthe 2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology - Volume 1, NAACL?03, pages 16?23, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Regina Barzilay and Kathleen R. McKeown.
2001.Extracting paraphrases from a parallel corpus.
InProceedings of the 39th Annual Meeting on As-sociation for Computational Linguistics, ACL ?01,pages 50?57, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.1921Rahul Bhagat and Deepak Ravichandran.
2008.
LargeScale Acquisition of Paraphrases for Learning Sur-face Patterns.
In Proceedings of ACL-08: HLT,pages 674?682, Columbus, Ohio, June.
Associationfor Computational Linguistics.William Blacoe and Mirella Lapata.
2012.
A com-parison of vector-based representations for seman-tic composition.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, EMNLP-CoNLL ?12, pages 546?556, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Nathanael Chambers and Dan Jurafsky.
2011.Template-based information extraction without thetemplates.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies - Volume 1,HLT ?11, pages 976?986, Stroudsburg, PA, USA.Association for Computational Linguistics.Dipanjan Das and Noah A. Smith.
2009.
Paraphraseidentification as probabilistic quasi-synchronousrecognition.
In Proc.
of ACL-IJCNLP.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: Exploiting massively parallel news sources.In Proceedings of Coling 2004, pages 350?356,Geneva, Switzerland, Aug 23?Aug 27.
COLING.Daniel Duma and Ewan Klein.
2013.
Generating nat-ural language from linked data: Unsupervised tem-plate extraction.
In Proceedings of the 10th Inter-national Conference on Computational Semantics(IWCS 2013) ?
Long Papers, pages 83?94.
ASSOCCOMPUTATIONAL LINGUISTICS-ACL.Christiane Fellbaum, editor.
1998.
WordNet An Elec-tronic Lexical Database.
The MIT Press.Atsushi Fujita, Pierre Isabelle, and Roland Kuhn.2012.
Enlarging paraphrase collections throughgeneralization and instantiation.
In Proceedings ofthe 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, EMNLP-CoNLL ?12,pages 631?642, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Weiwei Guo and Mona Diab.
2012.
Modeling sen-tences in the latent space.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics: Long Papers - Volume 1, ACL?12, pages 864?872, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Marti A Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 14th conference on Computational linguistics-Volume 2, pages 539?545.
Association for Compu-tational Linguistics.Ali Ibrahim, Boris Katz, and Jimmy Lin.
2003.
Ex-tracting structural paraphrases from aligned mono-lingual corpora.
In Proceedings of the Second In-ternational Workshop on Paraphrasing - Volume 16,PARAPHRASE ?03, pages 57?64, Stroudsburg, PA,USA.
Association for Computational Linguistics.Yangfeng Ji and Jacob Eisenstein.
2013.
Discrimi-native improvements to distributional sentence sim-ilarity.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Process-ing, EMNLP 2013, 18-21 October 2013, Grand Hy-att Seattle, Seattle, Washington, USA, A meeting ofSIGDAT, a Special Interest Group of the ACL, pages891?896.
ACL.Ravi Kondadadi, Blake Howald, and Frank Schilder.2013.
A statistical nlg framework for aggregatedplanning and realization.
In ACL (1), pages 1406?1415.
The Association for Computer Linguistics.Dekang Lin and Patrick Pantel.
2001.
Dirt@sbt@discovery of inference rules from text.
InProceedings of the Seventh ACM SIGKDD Inter-national Conference on Knowledge Discovery andData Mining, KDD ?01, pages 323?328, New York,NY, USA.
ACM.N.
Madnani, Philip Resnik, Bonnie J Dorr, andR.
Schwartz.
2008.
Applying automatically gener-ated semantic knowledge: A case study in machinetranslation.
NSF Symposium on Semantic Knowl-edge Discovery, Organization and Use.Nitin Madnani, Joel Tetreault, and Martin Chodorow.2012.
Re-examining machine translation metricsfor paraphrase identification.
In Proceedings of the2012 Conference of the North American Chapterof the Association for Computational Linguistics:Human Language Technologies, NAACL HLT ?12,pages 182?190, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Rada Mihalcea, Courtney Corley, and Carlo Strappa-rava.
2006.
Corpus-based and knowledge-basedmeasures of text semantic similarity.
In Proceedingsof the 21st National Conference on Artificial Intelli-gence - Volume 1, AAAI?06, pages 775?780.
AAAIPress.D.
Milajevs, D. Kartsaklis, M. Sadrzadeh, andM.
Purver.
2014.
Evaluating neural word repre-sentations in tensor-based compositional settings.
InEmpirical Methods in Natural Language Process-ing (EMNLP), Doha, Qatar.
Association for Compu-tational Linguistics, Association for ComputationalLinguistics.Marius Pas?ca and P?eter Dienes.
2005.
Aligning nee-dles in a haystack: Paraphrase acquisition acrossthe web.
In Proceedings of the Second Interna-tional Joint Conference on Natural Language Pro-cessing, IJCNLP?05, pages 119?130, Berlin, Hei-delberg.
Springer-Verlag.1922Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations:Extracting paraphrases and generating new sen-tences.
In Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology - Volume 1, NAACL ?03, pages 102?109, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Chris Quirk, Chris Brockett, and William Dolan.2004.
Monolingual machine translation for para-phrase generation.
In In Proceedings of the 2004Conference on Empirical Methods in Natural Lan-guage Processing, pages 142?149.Michaela Regneri and Rui Wang.
2012.
Using dis-course information for paraphrase extraction.
InProceedings of the 2012 Joint Conference on Em-pirical Methods in Natural Language Processingand Computational Natural Language Learning,EMNLP-CoNLL ?12, pages 916?927, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Satoshi Sekine.
2005.
Automatic paraphrase discoverybased on context and keywords between ne pairs.
InProceedings of the Third International Workshop onParaphrasing (IWP2005), pages 80?87.Satoshi Sekine.
2006.
On-demand information ex-traction.
In Proceedings of the COLING/ACL onMain Conference Poster Sessions, COLING-ACL?06, pages 731?738, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Siwei Shen, Dragomir R. Radev, Agam Patel, andG?unes?
Erkan.
2006.
Adding syntax to dynamicprogramming for aligning comparable texts for thegeneration of paraphrases.
In Proceedings of theCOLING/ACL on Main Conference Poster Sessions,COLING-ACL ?06, pages 747?754, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.2002.
Automatic paraphrase acquisition from newsarticles.
In Proceedings of the Second InternationalConference on Human Language Technology Re-search, HLT ?02, pages 313?318, San Francisco,CA, USA.
Morgan Kaufmann Publishers Inc.Richard Socher, Jeffrey Pennington, Eric H. Huang,Andrew Y. Ng, and Christopher D. Manning.
2011.Semi-supervised recursive autoencoders for predict-ing sentiment distributions.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, EMNLP ?11, pages 151?161,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Rui Wang and Chris Callison-Burch.
2011.
Paraphrasefragment extraction from monolingual comparablecorpora.
In Proceedings of the 4th Workshop onBuilding and Using Comparable Corpora: Compa-rable Corpora and the Web, BUCC ?11, pages 52?60, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li.
2009.Application-driven statistical paraphrase generation.In Proceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Pro-cessing of the AFNLP: Volume 2 - Volume 2, ACL?09, pages 834?842, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.1923
