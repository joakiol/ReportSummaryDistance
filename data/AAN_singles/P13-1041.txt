Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 412?422,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsThe Haves and the Have-Nots: Leveraging Unlabelled Corpora forSentiment AnalysisKashyap Popat2 Balamurali A R1,2,3 Pushpak Bhattacharyya2 Gholamreza Haffari31IITB-Monash Research Academy, IIT Bombay 3Monash University2Dept.
of Computer Science and Engineering, IIT Bombay Australia{kashyap,balamurali,pb}@cse.iitb.ac.in reza@monash.eduAbstractExpensive feature engineering based onWordNet senses has been shown tobe useful for document level sentimentclassification.
A plausible reason forsuch a performance improvement is thereduction in data sparsity.
However,such a reduction could be achieved witha lesser effort through the means ofsyntagma based word clustering.
Inthis paper, the problem of data sparsityin sentiment analysis, both monolingualand cross-lingual, is addressed throughthe means of clustering.
Experimentsshow that cluster based data sparsityreduction leads to performance better thansense based classification for sentimentanalysis at document level.
Similar ideais applied to Cross Lingual SentimentAnalysis (CLSA), and it is shown thatreduction in data sparsity (after translationor bilingual-mapping) produces accuracyhigher than Machine Translation basedCLSA and sense based CLSA.1 IntroductionData sparsity is the bane of Natural LanguageProcessing (NLP) (Xue et al, 2005; Minkov et al,2007).
Language units encountered in the test databut absent in the training data severely degrade theperformance of an NLP task.
NLP applicationsinnovatively handle data sparsity through variousmeans.
A special, but very common kind ofdata sparsity viz., word sparsity, can be addressedin one of the two obvious ways: 1) sparsityreduction through paradigmatically related wordsor 2) sparsity reduction through syntagmaticallyrelated words.Paradigmatic analysis of text is the analysisof concepts embedded in the text (Cruse, 1986;Chandler, 2012).
WordNet is a byproduct of suchan analysis.
In WordNet, paradigms are manuallygenerated based on the principles of lexical andsemantic relationship among words (Fellbaum,1998).
WordNets are primarily used to address theproblem of word sense disambiguation.
However,at present there are many NLP applicationswhich use WordNet.
One such application isSentiment Analysis (SA) (Pang and Lee, 2002).Recent research has shown that word sense basedsemantic features can improve the performance ofSA systems (Rentoumi et al, 2009; Tamara et al,2010; Balamurali et al, 2011) compared to wordbased features.Syntagmatic analysis of text concentrates onthe surface properties of the text.
Comparedto paradigmatic property extraction, syntagmaticprocessing is relatively light weight.
One ofthe obvious syntagmas is words, and words aregrouped into equivalence classes or clusters, thusreducing the model parameters of a statistical NLPsystem (Brown et al, 1992).
When used asan additional feature with word based languagemodels, it has been shown to improve the systemperformance viz., machine translation (Uszkoreitand Brants, 2008; Stymne, 2012), speechrecognition (Martin et al, 1995; Samuelsson andReichl, 1999), dependency parsing (Koo et al,2008; Haffari et al, 2011; Zhang and Nivre, 2011;Tratz and Hovy, 2011) and NER (Miller et al,2004; Faruqui and Pado?, 2010; Turian et al, 2010;Ta?ckstro?m et al, 2012).In this paper, the focus is on alleviating thedata sparsity faced by supervised approachesfor SA through the means of cluster basedfeatures.
As WordNets are essentially word412clusters wherein words with the same meaningare clubbed together, they address the problem ofdata sparsity at word level.
The abstraction anddimensionality reduction thus achieved attributesto the superior performance for SA systems thatemploys WordNet senses as features.
However,WordNets are manually created.
Automaticcreation of the same is challenging and not muchsuccessful because of the linguistic complexityinvolved.
In case of SA, manually creating thefeatures based on WordNet senses is a tedious andan expensive process.
Moreover, WordNets arenot present for many languages.
All these factorsmake the paradigmatic property based clusterfeatures like WordNet senses a less promisingpursuit for SA.The syntagmatic analysis essentially makes useof distributional similarity and may in manycircumstances subsume the paradigmatic analysis.In the current work, this particular insight isused to solve the data sparsity problem inthe sentiment analysis by leveraging unlabelledmonolingual corpora.
Specifically, experimentsare performed to investigate whether featuresdeveloped from manually crafted clusterings(coming from WordNet) can be replaced by thosegenerated from clustering based on syntagmaticproperties.Further, cluster based features are used toaddress the problem of scarcity of sentimentannotated data in a language.
Popularapproaches for Cross-Lingual Sentiment Analysis(CLSA) (Wan, 2009; Duh et al, 2011) dependon Machine Translation (MT) for convertingthe labeled data from one language to theother (Hiroshi et al, 2004; Banea et al, 2008;Wan, 2009).
However, many languages whichare truly resource scarce, do not have an MTsystem or existing MT systems are not ripe tobe used for CLSA (Balamurali et al, 2013).
Toperform CLSA, this study leverages unlabelledparallel corpus to generate the word alignments.These word alignments are then used to linkcluster based features to obliterate the languagegap for performing SA.
No MT systems orbilingual dictionaries are used for this study.Instead, language gap for performing CLSA isbridged using linked cluster or cross-lingualclusters (explained in section 4) with thehelp of unlabelled monolingual corpora.
Thecontributions of this paper are two fold:1.
Features created from manually built andfiner clusters can be replaced by inexpensivecluster based features generated solely fromunlabelled corpora.
Experiments performedon four publicly available datasets in threelanguages viz., English, Hindi and Marathi1suggest that cluster based features canconsiderably boost the performance of an SAsystem.
Moreover, state of the art resultis obtained for one of the publicly availabledataset.2.
An alternative and effective approach forCLSA is demonstrated using clusters asfeatures.
Word clustering is a powerfulmechanism to ?transfer?
a sentimentclassifier from one language to another.
Thuscan be used in truly resource scarce scenarioslike that of English-Marathi CLSA.The rest of the paper is organized as follows:section 2 presents related work.
Section 3 explainsdifferent word cluster based features employedto reduce data sparsity for monolingual SA.
Insection 4, alternative CLSA approaches basedon word clustering are elucidated.
Experimentaldetails are explained in section 5.
Results anddiscussions are presented in section 6 and section7 respectively.
Finally, section 8 concludesthe paper pointing to some future researchpossibilities.2 Related WorkThe problem of SA at document level is definedas the classification of document into differentpolarity classes (positive and negative) (Turney,2002).
Both supervised (Benamara et al, 2007;Martineau and Finin, 2009) and unsupervisedapproaches (Mei et al, 2007; Lin and He, 2009)exist for this task.Supervised approaches are popular becauseof their superior classification accuracy (Mullenand Collier, 2004; Pang and Lee, 2008).Feature engineering plays an important rolein these systems.
Apart from the commonlyused bag-of-words features based onunigrams/bigrams/ngrams (Dave et al, 2003;Ng et al, 2006; Martineau and Finin, 2009),1Hindi and Marathi belong to the Indo-Aryan subgroupof the Indo-European language family and are two widelyspoken Indian languages with a speaker population of 450million and 72 million respectively.413syntax (Matsumoto et al, 2005; Nakagawa etal., 2010), semantic (Balamurali et al, 2011)and negation (Ikeda et al, 2008) have also beenexplored for this task.
There has been researchrelated to clustering and sentiment analysis.
InRooney et al (2011), documents are clusteredbased on the context of each document andsentiment labels are attached at the cluster level.Zhai et al (2011) attempts to cluster features of aproduct to perform sentiment analysis on productreviews.
In this work, word clusters (syntagmaticand paradigmatic) encoding a mixture of syntacticand semantic information are used for featureengineering.In situations where labeled data is not presentin a language, approaches based on cross-lingualsentiment analysis are used.
Most often thesemethods depend on an intermediary machinetranslation system (Wan, 2009; Brooke et al,2009) or a bilingual dictionary (Ghorbel andJacot, 2011; Lu et al, 2011) to bridge thelanguage gap.
Given the subtle and differentways the sentiment can be expressed which itselfmanifested as a result of cultural diversity amongstdifferent languages, an MT system has to be of asuperior quality to capture them.3 Clustering for Sentiment AnalysisThe goal of this paper, to remind the reader, is toinvestigate whether superior word cluster featuresbased on manually crafted and fine grained lexicalresource like WordNet can be replaced with thesyntagmatic property based word clusters createdfrom unlabelled monolingual corpora.In this section, different clustering approachesare presented for feature engineering in amonolingual setting.3.1 Approach 1: Clustering based onWordNet SenseA synonymous set of words in a WordNet is calleda synset.
Each synset can be considered as a wordcluster comprising of semantically similar words.Balamurali et al (2011) showed that WordNetsynsets can act as good features for document levelsentiment classification.Motivation for their study stems from the factthat different senses of a word can have differentpolarities.
To empirically prove the superiorityof sense based features, different variants ofa travel review domain corpus were generatedby using automatic/manual sense disambiguationtechniques.
Thereafter, accuracies of classifiersbased on different sense-based and word-basedfeatures were compared.
The results suggestedthat WordNet synset based features performedbetter than word-based features.In this study, synset identifiers are extractedfrom manually/automatically sense annotatedcorpora and used as features for creating sentimentclassifiers.
The classifier thus build is used asa baseline.
Apart from this, another baselineemploying word based features are used for acomprehensive comparison.3.2 Approach 2: Syntagmatic Property basedClusteringFor this particular study, a co-occurrence basedalgorithm is used to create word clusters.
Asthe algorithm is based on co-occurrence, onecan extract the classes that have the flavour ofsyntagmatic grouping, depending on the natureof underlying statistics.
Agglomerative clusteringalgorithm by Brown et al (1992) is used for thispurpose.
It is a hard clustering algorithm i.e., eachword belongs to one cluster only.Formally, as mentioned in Brown et al (1992),let C be a hard clustering function which mapsvocabulary V to one of the K clusters.
Then,the likelihood (L()) of a sequence of word tokens,w = [wj ]mj=1, with wj ?
V , can be factored as,L(w;C) =m?j=1p(wj|C(wj))p(C(wj)|C(wj?1)))(1)Words are assigned to clusters such that theabove quantity is maximized.
For the purposeof sentiment classification, cluster identifiersrepresenting words in the document are used asfeatures for training.4 Clustering for Cross LingualSentiment AnalysisExisting approaches for CLSA depend on anintermediary machine translation system to bridgethe language gap (Hiroshi et al, 2004; Banea etal., 2008).
Machine translation is very resourceintensive.
If a language is truly resource scarce, itis mostly unlikely to have an MT system.
Giventhat sentiment analysis is a less resource intensivetask compared to machine translation, the use ofan MT system is hard to justify for performing414CLSA.
As a viable alternative, cluster linkagescould be learned from a bilingual parallel corpusand these linkages can be used to bridge thelanguage gap for CLSA.In this section, three approaches using clustersas features for CLSA are compared.
The languagewhose annotated data is used for training iscalled the source language (S), while the languagewhose documents are to be sentiment classified isreferred to as the target language (T ).4.1 Approach 1: Projection based on Sense(PS)In this approach, a Multidict is used to bridge thelanguage gap for SA.
A Multidict is an instanceof WordNet where the same sense from differentlanguages are linked (Mohanty et al, 2008).An entry in the multidict will have a WordNetsense identifier from S and the correspondingWordNet sense identifier from T .
The approachof projection based on sense is explained inAlgorithm 1.
Note that after the Sense Markoperation, each document will be represented asa vector of WordNet sense identifiers.Algorithm 1 Projection based on senseInput: Polarity labeled data in source language(S) and data in target language (T ) to belabeledOutput: Classified documents1: Sense mark the polarity labeled data from S2: Project the sense marked corpora from S to Tusing a Multidict3: Model the sentiment classifier using the dataobtained in step-24: Sense mark the unlabelled data from T5: Test the sentiment classifier on data obtainedin step-4 using model obtained in step-3Sense identifiers are the features for theclassifier.
For those sense identifiers which do nothave a corresponding entry in the Multidict, noprojection is performed.4.2 Approach 2: Direct Cluster Linking(DCL)Given a parallel bilingual corpus, word clusters inS can be aligned to clusters in T .
Word alignmentsare created using parallel corpora.
Given twoaligned word sequences wS = [wSj ]mj=1 andwT = [wTk ]nk=1, let ?T |S be a set of scoredalignments from the source language to the targetlanguage.
Here, an alignment from the akth sourceword to the kth target word, with score sk,ak > ?is represented as (wTk , wSak , sk,ak ) ?
?T |S .
Tosimplify, k ?
?T |S is used to denote those targetwords wTk that are aligned to some source wordwSak .The source and the target side clusters are linkedusing the Equation (2).LC(l) = argmaxt?k?
?T |S ?
?S|Ts.t.CT (wTk )=tCS (wSak )=lsk,ak (2)Here, a target side cluster t ?
CT is linked toa source side cluster l ?
CS such that the totalalignment score between words in l and words int is maximum.
CS and CT stands for source andtarget side cluster list respectively.
LC(l) givesthe target side cluster t to which l is linked.4.3 Approach 3: Cross-Lingual Clustering(XC)Direct cluster linking approach suffers from thesize of alignment dataset in the form of parallelcorpora.
The size of the alignment dataset istypically smaller than the monolingual dataset.To circumvent this problem, Ta?ckstro?m et al(2012) introduced cross-lingual clustering.
Incross-lingual clustering, the objective functionmaximizes the joint likelihood of monolingualand cross-lingual factors.
Given a list ofwords and clusters it belongs to, a clusteringalgorithm tries to obtain word-cluster associationwhich maximizes the joint likelihood of wordsand clusters.
Whereas in case of cross-lingual clustering, the same clustering can beexplained in terms of maximizing the likelihoodof monolingual word-cluster pairs of the source,the target and alignments between them.Formally, as stated in Ta?ckstro?m et al (2012),Using the model of Uszkoreit and Brants (2008),the likelihood of a sequence of word tokens,w = [wj ]mj=1, with wj ?
V , can be factored as,L(w;C) =m?j=1p(wj|C(wj))p(C(wj)|wj?1))(3)Note this is different from the likelihoodestimation of Brown et al (1992) (Equation (1)),where C(wj) was conditioned on C(wj?1).
This415makes the computation easier as suggested in theoriginal paper.
The Equation (3) in a cross lingualsetting will be transformed as given below:LS,T (wS , wT ;?T |S , ?S|T , CS , CT ) =LS(...).LT (...).LT |S(...).LS|T (...) (4)Here, LT |S(...) and LS|T (...) are factors based onword alignments, which can be represented as:LT |S(wT ;?T |S , CT , CS) =?k?
?T |Sp(wTk |CT (wTk ))p(CT (wTk )|CS(wSak)))(5)Based on the optimization objective inEquation (4), a pseudo algorithm is defined inAlgorithm 2.
For more information, readers arerequested to refer Ta?ckstro?m et al (2012).Algorithm 2 Cross-lingual Clustering (XC)Input: Source and target language corpusOutput: Cross-lingual clusters1: ## CS , CT randomly initialized2: for i?
1 to N do3: Find CS?
?
argmaxCS LS(wS ;CS)4: Project CS?
to CT5: Find CT?
?
argmaxCT LT (wT ;CT )6: Project CT?
to CS7: end forAn MT based CLSA approach is used as thebaseline.
Training data from S is translated to Tand classification model is learned using unigrambased features.
Thereafter, the classifier is directlytested on data from T .5 Experimental SetupAnalysis was performed on three languages, viz.,English (En), Hindi (Hi) and Marathi (Mar).CLSA was performed on two languagepairs, English-Hindi and English-Marathi.For clustering the words, monolingual data ofIndian Languages Corpora Initiative (ILCI)2 wasused.
It should also be noted that sentimentannotated data was also included in the data usedfor the word clusterings process.
For Brownclustering, an implementation by Liang (2005)was used.
Cross-lingual clustering for CLSA2http://sanskrit.jnu.ac.in/ilci/index.jspwas implemented as directed in Ta?ckstro?m et al(2012).Monolingual SA: For experiments in English,two polarity datasets were used.
The firstone (En-TD) by Ye et al (2009) contains user-written reviews on travel destinations.
Thedataset consists of approximately 600 positiveand 591 negative reviews.
Reviews were alsomanually sense annotated using WordNet 2.1.The sense annotation was performed by twoannotators with an inter-annotation agreement of93%.
The second dataset (En-PD)3 on productreviews (music instruments) from Amazon byBlitzer et al (2007) contains 1000 positive and1000 negative reviews.
This dataset was senseannotated using an automatic WSD engine whichwas trained on tourism domain (Khapra et al,2010).
Experiments using this dataset weredone to study the effect of domain on CLSA.For experiments in Hindi and Marathi, polaritydatasets by Balamurali et al (2012) were used.4These are reviews collected from various Hindiand Marathi blogs and Sunday editorials.
Hindidataset consist of 98 positive and 100 negativereviews.
Whereas Marathi dataset contains 75positive and 75 negative reviews.
Apart frombeing marked with polarity labels at documentlevel, they are also manually sense annotated usingHindi and Marathi WordNet respectively.CLSA: The same datasets used in SA are alsoused for CLSA.
Three approaches (as describedin section 4) were tested for English-Hindiand English-Marathi language pairs.
To createalignments, English-Hindi and English-Marathiparallel corpora from ILCI were used.
English-Hindi parallel corpus contains 45992 sentencesand English-Marathi parallel corpus contains47881 sentences.
To create alignments, GIZA++5was used (Och and Ney, 2003).As a preprocessing step, all stop wordswere removed.
Stemming was performed onEnglish and Hindi whereas for Marathi data,Morphological Analyzer was used to reduce thewords to their respective lemmas.All experiments were performed using C-SVM3http://www.cs.jhu.edu/?mdredze/datasets/sentiment/4http://www.cfilt.iitb.ac.in/resources/senti/MPLC_tour_downloaderInfo.php5http://www-i6.informatik.rwth-aachen.de/Colleagues/och/software/GIZA++.html416Features En-TD En-PD Hi MarWords 87.02 77.60 77.36 92.28WordNet Sense (Paradigmatic) 89.13 74.50 85.80 96.88Clusters (Syntagmatic) 97.45 87.80 83.50 z 98.66Table 1: Classification accuracy for monolingual sentiment analysis.
For English, results are reported ontwo publicly available datasets based on Travel Domain (TD) and Product Domain (PD).Features Words Clust-200 Clust-500 Clust-1000 Clust-1500 Clust-2000 Clust-2500 Clust-3000En-TD 87.02 97.37 97.45 96.94 96.94 96.52 96.52 96.52En-PD 77.60 73.20 82.30 84.30 86.35 86.45 87.80 87.40Table 2: Classification accuracy (in %) versus cluster size (number of clusters to be used).
(linear kernel with parameter optimized overtraining set using 5 fold cross validation) availableas a part of LibSVM package6.
SVM was usedsince it is known to perform well for sentimentclassification (Pang et al, 2002).
Results reportedare based on the average of ten-fold cross-validation accuracies.
Standard text metrics areused for reporting the experimental results.6 ResultsMonolingual classification results are shown inTable71.
Table shows accuracies of SA systemsdeveloped on feature set based on words, sensesand clusters.
It must be noted that accuraciesreported for cluster based features are withrespect to the best accuracy based on differentcluster sizes.
The improvements in results ofcluster features based approach is found to bestatistically significant over the word featuresbased approach and sense features based approachat 95% confidence level when tested using a pairedt-test (except for Hindi cluster features basedapproach).
But in general, their accuracies do notsignificantly vary after cluster size crosses 1500.Table 2 shows the classification accuracyvariation when cluster size is altered.
For,En-TD and En-PD experiments, the cluster sizewas varied between 200-3000 with an intervalof 500 (after a size of 500).
In the En-TDexperiment, the best accuracy is achieved forcluster size 500, which is lesser than the number ofunique-words/unique-senses (6435/6004) presentin the data.
Similarly, for the En-PD experiment,6http://www.csie.ntu.edu.tw/?cjlin/libsvm7All results reported here are based on 10-fold except forMarathi (2-fold-5-repeats), as it had comparatively lesser datasamples.the optimal cluster size of 2500 is also lesserthan the number of unique-words/unique-senses(30468/4735) present in the data.To see the effect of training data size variationfor different SA approaches in the En-TDexperiment, the training data size is variedbetween 50 to 500.
For this, a test set consistingof 100 positive and 100 negative documents isfixed.
The training data size is varied by selectingdifferent number of documents from rest of thedataset (?500 negative and ?500 positive) as atraining set.
For each training data set 10 repeatsare performed, e.g., for training data size of 50, 50negative and 50 positive documents are randomlyselected from the training data pool of ?500negative and ?500 positive.
This was repeated10 times (with replacement).
The results of thisexperiment are presented in Figure 1.7075808590951000  100  200  300  400  500Accuracy(%)Training data sizeWordsSenses (Paradigmatic)Clusters (Syntagmatic)Figure 1: Training data variation on En-TDdataset.Cross-lingual SA accuracies are presented inTable 3.
As in monolingual case, the reportedaccuracies are for features based on the bestcluster size.417Target Language MT PS DCL XCT=Hi 63.13 53.80 51.51 66.16T=Mar NA 54.00 56.00 60.30Table 3: Cross-Lingual SA accuracy (%) on T=Hi and T=Mar with S=En for different approaches(MT=Machine Translation, PS=Projection based on Sense, DCL=Direct Cluster Linking , XC=Cross-Lingual Clustering.
There is no MT system available for (S=En, T=Mar).7 DiscussionsIn this section, some important observations fromthe results are discussed.1.
Syntagmatic analysis may be used in lieuof paradigmatic analysis for SA: The resultssuggest that word cluster based features usingsyntagmatic analysis is comparatively better thancluster (sense) based features using paradigmaticanalysis.
For two datasets in English and forthe one in Marathi this holds true.
For English,the gap between classification accuracy based onsense features and cluster features is around 10%.A state-of-art accuracy is obtained for the publicdataset on travel domain (En-TD).The difference in accuracy reduces as thelanguage gets morphologically rich.
In amorphologically rich language, morphologyencompasses syntactical information, limiting thecontext it can provide for clustering.
This can beseen from the classification results on Marathi.However for Hindi, classifier built on featuresbased on syntagmatic analysis trails the one basedon paradigmatic analysis.Compared to Marathi, Hindi is a lessmorphologically rich language, hence, a betterresult was expected.
However, a contrary resultwas obtained.z In Hindi, the subject and theobject of the sentence are linked using a casemarker.
Upon error analysis, it was found thatthere was a lot of irregular compounding basedon case markers.
Case markers were compoundedwith the succeeding word.
This is a deviationfrom the real scenario which would have resultedin incorrect clustering leading to an unexpectedresult.
However, the same would not haveoccurred for a classifier developed on sense basedfeatures as it was manually sense tagged.Clustering induces a reduction in the datasparsity.
For example, on En-PD, percentage offeatures present in the test set and not present inthe training set to those present in the test setare 34.17%, 11.24%, 0.31% for words, synsetsand cluster based features respectively.
Theimprovement in the performance of classifiersmay be attributed to this feature size reduction.However, it must be noted that clustering basedon unlabelled corpora is less taxing than manuallycreating paradigmatic property based clusters likeWordNet synsets.Barring one instance, both cluster basedfeatures outperform word based features.
Thereason for the drop in the accuracy of approachbased on sense features for En-PD datasetis the domain specific nature of sentimentanalysis (Blitzer et al, 2007), which is explainedin the next point.2.
Domain issues are resolved while usingcluster based features: For En-PD, the classifierdeveloped using sense features based onparadigmatic analysis performs inferior toword based features.
Compared to other datasetsused for analysis, this dataset was sense annotatedusing an automatic WSD engine.
This engine wastrained on a travel domain corpus and as WSDis also domain specific, the final classificationperformance suffered.
Additionally, as the targetdomain was on products, the automatic WSDengine employed had an in-domain accuracyof 78%.
The sense disambiguation accuracy ofthe same would have lowered in a cross-domainsetting.
This might have had a degrading effect onthe SA accuracy.However, it was seen that classifier developedon cluster features based on syntagmatic analysisdo not suffer from this.
Such clustersobliterate domain relates issues.
In addition, asmore unlabelled data is included for clustering,the classification accuracy improves.8 Thus,clustering may be employed to tackle otherspecific domain related issues in SA.8It was observed that adding 0.1 million unlabelleddocuments, SA accuracy improved by 1%.
This was observedin the case of English for which there is abundant unlabelledcorpus.4183.
Cluster based features using syntagmaticanalysis requires lesser training data: Clusterbased features drastically reduces the dimensionof the feature vector.
For instance, the sizeof sense based features for En-TD dataset was1/6th of the size of word based features.
Thisreduces the perplexity of the classification model.The reduction in the perplexity leads to thereduction of training documents to attain the sameclassification accuracy without any dimensionalityreduction.
This is evident from Figure 1where accuracy of the cluster features based onunlabelled corpora are higher even with lessertraining data.4.
Effect of cluster size: The cluster size(number of clusters employed) has an implicationon the purity of each cluster with respect to theapplication.
The system performance improvedupon increasing the cluster size and convergedafter attaining a certain level of accuracy.
Ingeneral, it was found that the best classificationaccuracy was obtained for a cluster size between1000 and 2500.
As evident from Table 2, oncethe optimal accuracy is obtained, no significantchanges were observed by increasing the clustersize.5.
Clustering based CLSA is effective:For target language as Hindi, CLSA accuracybased on cross-lingual clustering (syntagmatic)outperforms the one based on MT (refer toTable 3).
This was true for the constraintclustering approach based on cross-lingualclustering.
Whereas, sentiment classifier usingsense (PS) or direct cluster linking (DCL) isnot very effective.
In case of PS approach, thecoverage of the multidict was a problem.
Thenumber of a linkages between sense from Englishto Hindi is only around 1/3rd the size of PrincetonWordNet (Fellbaum, 1998).
Similarly in caseof DCL approach, monolingual likelihood isdifferent from the cross-lingual likelihood interms of the linkages.6.
A note on CLSA for truly resource scarcelanguages: Note that there is no publicly availableMT system for English to Marathi.
Moreover,the digital content in Marathi language does nothave a standard encoding format.
This impedesthe automatic crawling of the web for corporacreation for SA.
Much manual effort has to be putto collect enough corpora for analysis.
However,even in these languages, unlabelled corpora iseasy to obtain.
Marathi was chosen to depicta truly resource scarce SA scenario.
Clusterfeatures based classifier comparatively performedwell with 60% classification accuracy.
An MTbased system would have suffered in this case asMarathi, as stated earlier, is a morphologicallyrich language and as compared to English, has adifferent word ordering.
This could degrade theaccuracy of the machine translation itself, limitingthe performance of an MT based CLSA system.All this is obliterated by the use of a cluster basedCLSA approach.
Moreover, as more monolingualcopora is added for clustering, the cross lingualcluster linkages could be refined.
This can furtherboost the CLSA accuracy.8 Conclusion and Future WorkThis paper explored feasibility of using wordcluster based features in lieu of features based onWordNet senses for sentiment analysis to alleviatethe problem of data sparsity.
Abstractly, themotivation was to see if highly effective featuresbased on paradigmatic property based clusteringcould be replaced with the inexpensive ones basedon syntagmatic property for SA.The study was performed for both monolingualSA and cross-lingual SA.
It was found thatcluster features based on syntagmatic analysisare better than the WordNet sense features basedon paradigmatic analysis for SA.
Invesitgationrevealed that a considerable decrease in thetraining data could be achieved while using suchclass based features.
Moreover, as syntagma basedword clusters are homogenous, it was able toaddress domain specific nature of SA as well.For CLSA, clusters linked together usingunlabelled parallel corpora do away with the needof translating labelled corpora from one languageto another using an intermediary MT system orbilingual dictionary.
Such a method outperformsan MT based CLSA approach.
Further, thisapproach was found to be useful in cases wherethere are no MT systems to perform CLSA andthe language of analysis is truly resource scarce.Thus, wider implication of this study is that manywidely spoken yet resource scare languages likePashto, Sundanese, Hausa, Gujarati and Punjabiwhich do not have an MT system could now beanalysed for sentiment.
The approach presentedhere for CLSA will still require a parallel corpora.However, the size of the parallel corpora required419for CLSA can considerably be much lesser thanthe size of the parallel corpora required to train anMT system.A naive cluster linkage algorithm based on wordalignments was used to perform CLSA.
As aresult, there were many erroneous linkages whichlowered the final SA accuracy.
Better cluster-linking approaches could be explored to alleviatethis problem.
There are many applications whichuse WordNet like IR, IE etc.
It would beinteresting to see if these could be replaced byclusters based on the syntagmatic property.ReferencesA.
R. Balamurali, Aditya Joshi, and Pushpak Bhat-tacharyya.
2011.
Harnessing wordnet senses for su-pervised sentiment classification.
In Proceedings ofEMNLP 2011, pages 1081?1091, Stroudsburg, PA,USA.A.
R. Balamurali, Aditya Joshi, and Pushpak Bhat-tacharyya.
2012.
Cross-lingual sentiment analysisfor Indian languages using linked wordnets.
In Pro-ceedings of COLING 2012, pages 73?82, Mumbai,India.A.
R. Balamurali, Mitesh M. Khapra, and PushpakBhattacharyya.
2013.
Lost in translation: viabilityof machine translation for cross language sentimentanalysis.
In Proceedings of CICLing 2013, pages38?49, Berlin, Heidelberg.Carmen Banea, Rada Mihalcea, Janyce Wiebe, andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
In Proceedingsof EMNLP 2008, pages 127?135, Honolulu, Hawaii.Farah Benamara, Sabatier Irit, Carmine Cesarano,Napoli Federico, and Diego Reforgiato.
2007.
Sen-timent analysis: Adjectives and adverbs are betterthan adjectives alone.
In Proceedings of the Inter-national Conference on Weblogs and Social Media.John Blitzer, Mark Dredze, and Fernando Pereira.2007.
Biographies, bollywood, boom-boxes andblenders: Domain adaptation for sentiment classi-fication.
In Proceedings of ACL 2007, pages 440?447, Prague, Czech Republic.Julian Brooke, Milan Tofiloski, and Maite Taboada.2009.
Cross-linguistic sentiment analysis: From en-glish to spanish.
In Proceedings of the InternationalConference RANLP-2009, pages 50?54, Borovets,Bulgaria.Peter F. Brown, Peter V. deSouza, Robert L. Mer-cer, Vincent J. Della Pietra, and Jenifer C. Lai.1992.
Class-based n-gram models of natural lan-guage.
Computational Linguistics, pages 467?479,December.D.
Chandler.
2012.
Semiotics for begin-ners.
http://users.aber.ac.uk/dgc/Documents/S4B/sem01.html.
Online, ac-cessed 20-February-2013.D.
A. Cruse.
1986.
Lexical Semantics.
CambridgeUniversity Press.Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: opinion extractionand semantic classification of product reviews.
InProceedings of WWW 2003, pages 519?528, NewYork, NY, USA.Kevin Duh, Akinori Fujino, and Masaaki Nagata.2011.
Is machine translation ripe for cross-lingualsentiment classification?
In Proceedings of ACL-HLT 2011, pages 429?433, Stroudsburg, PA, USA.Manaal Faruqui and Sebastian Pado?.
2010.
Trainingand Evaluating a German Named Entity Recognizerwith Semantic Generalization.
In Proceedings ofKONVENS 2010, Saarbru?cken, Germany.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Bradford Books.Hatem Ghorbel and David Jacot.
2011.
Further ex-periments in sentiment analysis of french movie re-views.
In Proceedings of AWIC 2011, pages 19?28,Fribourg, Switzerland.Gholamreza Haffari, Marzieh Razavi, and AnoopSarkar.
2011.
An ensemble model that combinessyntactic and semantic clustering for discriminativedependency parsing.
In Proceedings of ACL-HLT2011, pages 710?714, Stroudsburg, PA, USA.Kanayama Hiroshi, Nasukawa Tetsuya, and WatanabeHideo.
2004.
Deeper sentiment analysis usingmachine translation technology.
In Proceedings ofCOLING 2004, Stroudsburg, PA, USA.Daisuke Ikeda, Hiroya Takamura, Lev arie Ratinov, andManabu Okumura.
2008.
Learning to shift the po-larity of words for sentiment classification.
In Pro-ceedings of the Third International Joint Conferenceon Natural Language Processing.Mitesh Khapra, Sapan Shah, Piyush Kedia, and Push-pak Bhattacharyya.
2010.
Domain-specific wordsense disambiguation combining corpus based andwordnet based parameters.
In Proceedings ofGlobal Wordnet Conference.Terry Koo, Xavier Carreras, and Michael Collins.2008.
Simple semi-supervised dependency parsing.In Proceedings of ACL-HLT 2008, pages 595?603,Columbus, Ohio.Percy Liang.
2005.
Semi-supervised learning for natu-ral language.
M. eng.
thesis, Massachusetts Instituteof Technology.420Chenghua Lin and Yulan He.
2009.
Joint senti-ment/topic model for sentiment analysis.
In Pro-ceedings of CIKM 2009, pages 375?384, New York,NY, USA.Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin K.Tsou.
2011.
Joint bilingual sentiment classificationwith unlabeled parallel corpora.
In Proceedings ofACL-HLT 2011, pages 320?330, Stroudsburg, PA,USA.Sven Martin, Jrg Liermann, and Hermann Ney.
1995.Algorithms for bigram and trigram word clustering.In Speech Communication, pages 1253?1256.Justin Martineau and Tim Finin.
2009.
Delta TFIDF:An improved feature space for sentiment analysis.In Proceedings of ICWSM.Shotaro Matsumoto, Hiroya Takamura, and ManabuOkumura.
2005.
Sentiment classification usingword sub-sequences and dependency sub-trees.
InAdvances in Knowledge Discovery and Data Min-ing, Lecture Notes in Computer Science, pages 301?311.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and ChengXiang Zhai.
2007.
Topic sentiment mix-ture: modeling facets and opinions in weblogs.
InProceedings of WWW 2007, pages 171?180, NewYork, NY, USA.Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name tagging with word clusters and dis-criminative training.
In Proceedings of HLT-NAACL2004: Main Proceedings, pages 337?342, Boston,Massachusetts, USA.Einat Minkov, Kristina Toutanova, and Hisami Suzuki.2007.
Generating complex morphology for machinetranslation.
In Proceedings of ACL 2007, pages128?135, Prague, Czech Republic.Rajat Mohanty, Pushpak Bhattacharyya, PrabhakarPande, Shraddha Kalele, Mitesh Khapra, and AdityaSharma.
2008.
Synset based multilingual dictio-nary: Insights, applications and challenges.
In Pro-ceedings of Global Wordnet Conference.Tony Mullen and Nigel Collier.
2004.
Sentiment anal-ysis using support vector machines with diverse in-formation sources.
In Proceedings of EMNLP 2004,pages 412?418, Barcelona, Spain.Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.2010.
Dependency tree-based sentiment classifica-tion using crfs with hidden variables.
In Proceed-ings of HLT-NAACL 2010, pages 786?794, Strouds-burg, PA, USA.Vincent Ng, Sajib Dasgupta, and S. M. Niaz Arifin.2006.
Examining the role of linguistic knowledgesources in the automatic identification and classifi-cation of reviews.
In Proceedings of the COLING2006, pages 611?618, Stroudsburg, PA, USA.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51,March.Bo Pang and Lillian Lee.
2002.
Thumbs up?
sen-timent classification using machine learning tech-niques.
In Proceedings of EMNLP 2002, pages 79?86, Stroudsburg, PA, USA.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in In-formation Retrieval, 2(1-2):1?135, January.Vassiliki Rentoumi, George Giannakopoulos, VangelisKarkaletsis, and George A. Vouros.
2009.
Senti-ment analysis of figurative language using a wordsense disambiguation approach.
In Proceedings ofRANLP 2009, pages 370?375, Borovets, Bulgaria,September.Niall Rooney, Hui Wang, Fiona Browne, Fergal Mon-aghan, Jann Mller, Alan Sergeant, Zhiwei Lin,Philip Taylor, and Vladimir Dobrynin.
2011.
An ex-ploration into the use of contextual document clus-tering for cluster sentiment analysis.
In Proceedingsof RANLP 2011, pages 140?145, Hissar, Bulgaria.C.
Samuelsson and W. Reichl.
1999.
A class-basedlanguage model for large-vocabulary speech recog-nition extracted from part-of-speech statistics.
InProceedings of ICASSP 1999, pages 537?540.Sara Stymne.
2012.
Clustered word classes for pre-ordering in statistical machine translation.
In Pro-ceedings of the Joint Workshop on Unsupervised andSemi-Supervised Learning in NLP, pages 28?34.Oscar Ta?ckstro?m, Ryan McDonald, and Jakob Uszkor-eit.
2012.
Cross-lingual Word Clusters for DirectTransfer of Linguistic Structure.
In Proceedingsof NAACL-HLT 2012, pages 477?487, Montre?al,Canada.Martin Tamara, Balahur Alexandra, and Montoyo An-dres.
2010.
Word sense disambiguation in opinionmining: Pros and cons.
Journal Research in Com-puting Science, 46:119?130.Stephen Tratz and Eduard Hovy.
2011.
A fast, ac-curate, non-projective, semantically-enriched parser.In Proceedings of EMNLP 2011, pages 1257?1268,Stroudsburg, PA, USA.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In Proceedings ofACL 2010, pages 384?394, Stroudsburg, PA, USA.Peter D. Turney.
2002.
Thumbs up or thumbs down?
:semantic orientation applied to unsupervised classi-fication of reviews.
In Proceedings of ACL 2002,pages 417?424, Stroudsburg, PA, USA.421Jakob Uszkoreit and Thorsten Brants.
2008.
Dis-tributed word clustering for large scale class-basedlanguage modeling in machine translation.
In Pro-ceedings of ACL-HLT 2008, pages 755?762, Colum-bus, Ohio.Xiaojun Wan.
2009.
Co-training for cross-lingual sen-timent classification.
In Proceedings of ACL 2009,pages 235?243, Stroudsburg, PA, USA.Gui-Rong Xue, Chenxi Lin, Qiang Yang, WenSi Xi,Hua-Jun Zeng, Yong Yu, and Zheng Chen.
2005.Scalable collaborative filtering using cluster-basedsmoothing.
In Proceedings of SIGIR 2005, pages114?121, New York, NY, USA.Qiang Ye, Ziqiong Zhang, and Rob Law.
2009.Sentiment classification of online reviews to traveldestinations by supervised machine learning ap-proaches.
Expert Systems with Applications, 36(3,Part 2):6527?6535.Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia.
2011.Clustering product features for opinion mining.
InProceedings of WSDM 2011, pages 347?354, NewYork, NY, USA.Yue Zhang and Joakim Nivre.
2011.
Transition-based dependency parsing with rich non-local fea-tures.
In Proceedings of ACL-HLT 2011, pages 188?193, Stroudsburg, PA, USA.422
