Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 462?472,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsEvent-Driven Headline GenerationRui Sun?, Yue Zhang?, Meishan Zhang?and Donghong Ji?
?Computer School, Wuhan University, China?Singapore University of Technology and Design{ruisun, dhji}@whu.edu.cn{yue zhang, meishan zhang}@sutd.edu.sgAbstractWe propose an event-driven model forheadline generation.
Given an inputdocument, the system identifies a keyevent chain by extracting a set of structuralevents that describe them.
Then a novelmulti-sentence compression algorithmis used to fuse the extracted events,generating a headline for the document.Our model can be viewed as a novelcombination of extractive and abstractiveheadline generation, combining theadvantages of both methods using eventstructures.
Standard evaluation shows thatour model achieves the best performancecompared with previous state-of-the-artsystems.1 IntroductionHeadline generation (HG) is a text summarizationtask, which aims to describe an article (or a set ofrelated paragraphs) using a single short sentence.The task is useful in a number of practicalscenarios, such as compressing text for mobiledevice users (Corston-Oliver, 2001), generatingtable of contents (Erbs et al, 2013), and emailsummarization (Wan and McKeown, 2004).
Thistask is challenging in not only informativenessand readability, which are challenges to commonsummarization tasks, but also the length reduction,which is unique for headline generation.Previous headline generation models fall intotwo main categories, namely extractive HGand abstractive HG (Woodsend et al, 2010;Alfonseca et al, 2013).
Both consist oftwo steps: candidate extraction and headlinegeneration.
Extractive models choose a set ofsalient sentences in candidate extraction, andthen exploit sentence compression techniques toachieve headline generation (Dorr et al, 2003;TextsPhrases Events SentencesCandidate RankingCandidate #1...Candidate #i...Candidate #KMulti-Sentence CompressionHeadlineCandidate ExtractionHeadline GenerationFigure 1: System framework.Zajic et al, 2005).
Abstractive models choose aset of informative phrases for candidate extraction,and then exploit sentence synthesis techniques forheadline generation (Soricut and Marcu, 2007;Woodsend et al, 2010; Xu et al, 2010).Extractive HG and abstractive HG havetheir respective advantages and disadvantages.Extractive models can generate more readableheadlines, because the final title is derived bytailoring human-written sentences.
However,extractive models give less informative titles(Alfonseca et al, 2013), because sentencesare very sparse, making high-recall candidateextraction difficult.
In contrast, abstractive modelsuse phrases as the basic processing units, whichare much less sparse.
However, it is more difficultfor abstractive HG to ensure the grammaticalityof the generated titles, given that sentencesynthesis is still very inaccurate based on a setof phrases with little grammatical information(Zhang, 2013).In this paper, we propose an event-driven modelfor headline generation, which alleviates the462disadvantages of both extractive and abstractiveHG.
The framework of the proposed model isshown in Figure 1.
In particular, we useevents as the basic processing units for candidateextraction.
We use structured tuples to representthe subject, predicate and object of an event.
Thisform of event representation is widely used inopen information extraction (Fader et al, 2011;Qiu and Zhang, 2014).
Intuitively, events canbe regarded as a trade-off between sentencesand phrases.
Events are meaningful structures,containing necessary grammatical information,and yet are much less sparse than sentences.We use salience measures of both sentences andphrases for event extraction, and thus our modelcan be regarded as a combination of extractive andabstractive HG.During the headline generation step, A graph-based multi-sentence compression (MSC) modelis proposed to generate a final title, given multipleevents.
First a directed acyclic word graph isconstructed based on the extracted events, andthen a beam-search algorithm is used to find thebest title based on path scoring.We conduct experiments on standard datasetsfor headline generation.
The results showthat headline generation can benefit not onlyfrom exploiting events as the basic processingunits, but also from the proposed graph-basedMSC model.
Both our candidate extractionand headline generation methods outperformcompetitive baseline methods, and our modelachieves the best results compared with previousstate-of-the-art systems.2 BackgroundPrevious extractive and abstractive models taketwo main steps, namely candidate extraction andheadline generation.
Here, we introduce these twotypes of models according to the two steps.2.1 Extractive Headline GenerationCandidate Extraction.
Extractive models exploitsentences as the basic processing units in this step.Sentences are ranked by their salience accordingto specific strategies (Dorr et al, 2003; Erkan andRadev, 2004; Zajic et al, 2005).
One of the state-of-the-art approaches is the work of Erkan andRadev (2004), which exploits centroid, positionand length features to compute sentence salience.We re-implemented this method as our baselinesentence ranking method.
In this paper, we useSentRank to denote this method.Headline Generation.
Given a set of sentences,extractive models exploit sentence compressiontechniques to generate a final title.
Most previouswork exploits single-sentence compression (SSC)techniques.
Dorr et al (2003) proposed the HedgeTrimmer algorithm to compress a sentence bymaking use of handcrafted linguistically-basedrules.
Alfonseca et al (2013) introduce amulti-sentence compression (MSC) model intoheadline generation, using it as a baseline in theirwork.
They indicated that the most importantinformation is distributed across several sentencesin the text.2.2 Abstractive Headline GenerationCandidate Extraction.
Different from extractivemodels, abstractive models exploit phrases as thebasic processing units.
A set of salient phrasesare selected according to specific principles duringcandidate extraction (Schwartz, 01; Soricut andMarcu, 2007; Xu et al, 2010; Woodsend etal., 2010).
Xu et al (2010) propose to rankphrases using background knowledge extractedfrom Wikipedia.
Woodsend et al (2010) usesupervised models to learn the salience score ofeach phrase.
Here, we use the work of Soricutand Marcu (2007) , namely PhraseRank, asour baseline phrase ranking method, which is anunsupervised model without external resources.The method exploits unsupervised topic discoveryto find a set of salient phrases.Headline Generation.
In the headline generationstep, abstractive models exploit sentence synthesistechnologies to accomplish headline generation.Zajic et al (2005) exploit unsupervised topicdiscovery to find key phrases, and use theHedge Trimmer algorithm to compress candidatesentences.
One or more key phrases are addedinto the compressed fragment according to thelength of the headline.
Soricut and Marcu(2007) employ WIDL-expressions to generateheadlines.
Xu et al (2010) employ keywordclustering based on several bag-of-words modelsto construct a headline.
Woodsend et al(2010) use quasi-synchronous grammar (QG) tooptimize phrase selection and surface realizationpreferences jointly.4633 Our ModelSimilar to extractive and abstractive models, theproposed event-driven model consists of twosteps, namely candidate extraction and headlinegeneration.3.1 Candidate ExtractionWe exploit events as the basic units for candidateextraction.
Here an event is a tuple (S, P,O),where S is the subject, P is the predicate and O isthe object.
For example, for the sentence ?UkraineDelays Announcement of New Government?, theevent is (Ukraine, Delays, Announcement).
Thistype of event structures has been used in openinformation extraction (Fader et al, 2011), and hasa range of NLP applications (Ding et al, 2014; Nget al, 2014).A sentence is a well-formed structure withcomplete syntactic information, but can containredundant information for text summarization,which makes sentences very sparse.
Phrases canbe used to avoid the sparsity problem, but withlittle syntactic information between phrases, fluentheadline generation is difficult.
Events can beregarded as a trade-off between sentences andphrases.
They are meaningful structures withoutredundant components, less sparse than sentencesand containing more syntactic information thanphrases.In our system, candidate event extraction isperformed on a bipartite graph, where the twotypes of nodes are lexical chains (Section 3.1.2)and events (Section 3.1.1), respectively.
MutualReinforcement Principle (Zha, 2002) is appliedto jointly learn chain and event salience on thebipartite graph for a given input.
We obtain thetop-k candidate events by their salience measures.3.1.1 Extracting EventsWe apply an open-domain event extractionapproach.
Different from traditional eventextraction, for which types and arguments are pre-defined, open event extraction does not have aclosed set of entities and relations (Fader et al,2011).
We follow Hu?s work (Hu et al, 2013) toextract events.Given a text, we first use the Stanforddependency parser1to obtain the Stanford typeddependency structures of the sentences (Marneffeand Manning, 2008).
Then we focus on1http://nlp.stanford.edu/software/lex-parser.shtmlDT NNPS MD VB DT NNP NNP POS NNSthe Keenans could demand the Aryan Nations ?
assetsnsubjauxdobjdet nnpossFigure 2: Dependency tree for the sentence?the Keenans could demand the Aryan Nations?assets?.two relations, nsubj and dobj, for extractingevent arguments.
Event arguments that havethe same predicate are merged into one event,represented by tuple (Subject, Predicate, Object).For example, given the sentence, ?the Keenanscould demand the Aryan Nations?
assets?, Figure2 present its partial parsing tree.
Basedon the parsing results, two event argumentsare obtained: nsubj(demand, Keenans) anddobj(demand, assets).
The two event argumentsare merged into one event: (Keenans, demand,assets).3.1.2 Extracting Lexical ChainsLexical chains are used to link semantically-related words and phrases (Morris and Hirst, 1991;Barzilay and Elhadad, 1997).
A lexical chain isanalogous to a semantic synset.
Compared withwords, lexical chains are less sparse for eventranking.Given a text, we follow Boudin and Morin(2013) to construct lexical chains based on thefollowing principles:1.
All words that are identical after stemmingare treated as one word;2.
All NPs with the same head word fall into onelexical chain;23.
A pronoun is added to the correspondinglexical chain if it refers to a word in the chain(The coreference resolution is performedusing the Stanford Coreference Resolutionsystem);34.
Lexical chains are merged if their main wordsare in the same synset of WordNet.42NPs are extracted according to the dependency relationsnn and amod.
As shown in Figure 2, we can extract the nounphrase Aryan Nations according to the dependency relationnn(Nations, Aryan).3http://nlp.stanford.edu/software/dcoref.shtml4http://wordnet.princeton.edu/464At initialization, each word in the document is alexical chain.
We repeatedly merge existing chainsby the four principles above until convergence.In particular, we focus on content words only,including verbs, nouns and adjective words.
Afterthe merging, each lexical chain represents a wordcluster, and the first occuring word in it can beused as the main word of chain.3.1.3 Learning Salient EventsIntuitively, one word should be more important ifit occurs in more important events.
Similarly, oneevent should be more important if it includes moreimportant words.
Inspired by this, we construct abipartite graph between lexical chains and events,shown in Figure 3, and then exploit MRP to jointlylearn the salience of lexical chains and events.MRP has been demonstrated effective for jointlylearning the vertex weights of a bipartite graph(Zhang et al, 2008; Ventura et al, 2013).Given a text, we construct bipartite graphbetween the lexical chains and events, with anedge being constructed between a lexical chainand an event if the event contains a word in thelexical chain.
Suppose that there are n events{e1, ?
?
?
, en} and m lexical chains: {l1, ?
?
?
, lm}in the bipartite graph Gbi.
Their scores arerepresented by sal(e) = {sal(e1), ?
?
?
, sal(en)}and sal(l) = {sal(l1), ?
?
?
, sal(lm)}, respectively.We compute the final sal(e) and sal(l) iterativelyby MRP.
At each step, sal(ei) and sal(lj) arecomputed as follows:sal(ei) ?m?j=1rij?
sal(lj)sal(lj) ?n?i=1rij?
sal(ei)rij=?
(lj,ei)?Gbiw(lj) ?
w(ei)A(1)where rij?
R denotes the cohesion betweenlexicon chain liand event ej, A is a normalizationfactor, sal(?)
denotes the salience, and the initialvalues of sal(e) and sal(t) can be assignedrandomly.The remaining problem is how to define thesalience score of a given lexicon chain liand agiven event ej.
In this work, we use the guidanceof abstractive and extractive models to computeLexical ChainsEventsFigure 3: Bipartite graph where two vertex setsdenote lexical chains and events, respectively.sal(lj) and sal(ei), respectively, as shown below:w(lj) =?w?ljsalabs(w)w(ei) =?s?Sen(ei)salext(s)(2)where salabs(?)
denotes the word salience scoreof an abstractive model, salext(?)
denotes thesentence salience score of an extractive model,and Sen(ei) denotes the sentence set where eiis extracted from.
We exploit our baselinesentence ranking method, SentRank, to obtainthe sentence salience score, and use our baselinephrase ranking method, PhraseRank, to obtainthe phrase salience score.3.2 Headline GenerationWe use a graph-based multi-sentence compression(MSC) model to generate the final title for theproposed event-driven model.
The model isinspired by Filippova (2010).
First, a weighteddirected acyclic word graph is built, with a startnode and an end node in the graph.
A headlinecan be obtained by any path from the start nodeto the end node.
We measure each candidate pathby a scoring function.
Based on the measurement,we exploit a beam-search algorithm to find theoptimum path.3.2.1 Word-Graph ConstructionGiven a set of candidate events CE, we extractall the sentences that contain the events.
Inparticular, we add two artificial words, ?S?
and?E?, to the start position and end position ofall sentences, respectively.
Following Filippova(2010), we extract all words in the sentences asgraph vertexes, and then construct edges basedon these words.
Filippova (2010) adds edges465?S?
?E?KingNorodom...oppositiongroups...HunSunon...rejectedparty......fortalks.........Figure 4: Word graph generated from candidatesand a possible compression path.for all the word pairs that are adjacent in onesentence.
The title generated using this strategycan mistakenly contain common word bigrams(i.e.
adjacent words) in different sentences.
Toaddress this, we change the strategy slightly, byadding edges for all word pairs of one sentence inthe original order.
In another words, if word wjoccurs after wiin one sentence, then we add anedge wi?
wjfor the graph.
Figure 4 gives anexample of the word graph.
The search space ofthe graph is larger compared with that of Filippova(2010) because of more added edges.Different from Filippova (2010), salienceinformation is introduced into the calculation ofthe weights of vertexes.
One word that occursin more salient candidate should have higherweight.
Given a graph G = (V, E), where V ={V1, ?
?
?
, Vn} denotes the word nodes and E ={Eij?
{0, 1}, i, j ?
[1, n]} denotes the edges.The vertex weight is computed as follows:w(Vi) =?e?CEsal(e) exp{?dist(Vi.w, e)} (3)where sal(e) is the salience score of an eventfrom the candidate extraction step, Vi.w denotesthe word of vertex Vi, and dist(w, e) denotes thedistance from the word w to the event e, whichare defined by the minimum distance from wto all the related words of e in a sentence bythe dependency path5between them.
Intuitively,equation 3 demonstrates that a vertex is salientwhen its corresponding word is close to salient5The distance is +?
when e and w are not in onesentence.events.
It is worth noting that the formulacan adapt to extractive and abstractive modelsas well, by replacing events with sentences andphrases.
We use them for the SentRank andPhraseRank baseline systems in Section 4.3,respectively.The equation to compute the edge weight isadopted from Filippova (2010):w?
(Eij) =?srdist(Vi.w, Vj.w)w(Eij) =w(Vi)w(Vj) ?
w?
(Eij)w(Vi) + w(Vj)(4)where w?
(Eij) refers to the sum ofrdist(Vi.w, Vj.w) over all sentences, and rdist(?
)denotes the reciprocal distance of two words in asentence by the dependency path.
By the formula,an edge is salient when the corresponding vertexweights are large or the corresponding words areclose.3.2.2 Scoring MethodThe key to our MSC model is the path scoringfunction.
We measure a candidate path basedon two aspects.
Besides the sum edge score ofthe path, we exploit a trigram language model tocompute a fluency score of the path.
Languagemodels have been commonly used to generatemore readable titles.The overall score of a path is compute by:score(p) = edge(p) + ??
flu(p)edge(p) =?Eij?pln{w(Eij)}nflu(p) =?iln{p(wi|wi?2wi?1)}n(5)where p is a candidate path and the correspondingword sequence of p is w1?
?
?wn.
A trigramlanguage model is trained using SRILM6onEnglish Gigaword (LDC2011T07).3.2.3 Beam SearchBeam search has been widely used aiming tofind the sub optimum result (Collins and Roark,2004; Zhang and Clark, 2011), when exactinference is extremely difficult.
Assuming ourword graph has a vertex size of n, the worstcomputation complexity is O(n4) when using atrigram language model, which is time consuming.6http://www.speech.sri.com/projects/srilm/466Input: G?
(V, E), LM, BOutput: bestcandidates?
{ {?S?}
}loop dobeam?
{ }for each candidate in candidatesif candidate endwith ?E?ADDTOBEAM(beam, candidate)continuefor each Viin Vcandidate?
ADDVERTEX(candidate, Vi)COMPUTESCORE(candidate, LM)ADDTOBEAM(beam, candidate)end forend forcandidates?
TOP-K(beam, B)if candidates all endwith ?E?
: breakend loopbest?
BEST(candidates)Figure 5: The beam-search algorithm.Using beam search, assuming the beam size is B,the time complexity decreases to O(Bn2).Pseudo-code of our beam search algorithm isshown in Figure 5.
During search, we usecandidates to save a fixed size (B) of partialresults.
For each iteration, we generate a set ofnew candidates by adding one vertex from thegraph, computing their scores, and maintainingthe top B candidates for the next iteration.
Ifone candidate reaches the end of the graph, wedo not expand it, directly adding it into the newcandidate set according to its current score.
Ifall the candidates reach the end, the searchingalgorithm terminates and the result path is thecandidate from candidates with the highest score.4 Experiment4.1 SettingsWe use the standard HG test dataset to evaluateour model, which consists of 500 articles fromDUC?04 task 17, where each article is providedwith four reference headlines.
In particular, weuse the first 100 articles from DUC?07 as ourdevelopment set.
There are averaged 40 events perarticle in the two datasets.
All the pre-processingsteps, including POS tagging, lemma analysis,dependency parsing and anaphora resolution, are7http://duc.nist.gov/duc2004/tasks.htmlconducted using the Stanford NLP tools (Marneffeand Manning, 2008).
The MRP iteration numberis set to 10.We use ROUGE (Lin, 2004) to automaticallymeasure the model performance, which has beenwidely used in summarization tasks (Wang et al,2013; Ng et al, 2014).
We focus on Rouge1and Rouge2 scores, following Xu et al (2010).In addition, we conduct human evaluations, usingthe same method as Woodsend et al (2010).Four participants are asked to rate the generatedheadlines by three criteria: informativeness (howmuch important information in the article doesthe headline describe?
), fluency (is it fluent toread?)
and coherence (does it capture the topic ofarticle?).
Each headline is given a subjective scorefrom 0 to 5, with 0 being the worst and 5 beingthe best.
The first 50 documents from the test setand their corresponding headlines are selected forhuman rating.
We conduct significant tests usingt-test.4.2 Development ResultsThere are three important parameters in theproposed event-driven model, including the beamsize B, the fluency weight ?
and the numberof candidate events N .
We find the optimumparameters on development dataset in this section.For efficiency, the three parameters are optimizedseparately.
The best performance is achieved withB = 8, ?
= 0.4 andN = 10.
We report the modelresults on the development dataset to study theinfluences of the three parameters, respectively,with the other two parameters being set with theirbest value.4.2.1 Influence of Beam SizeWe perform experiments with different beamwidths.
Figure 6 shows the results of the proposedmodel with beam sizes of 1, 2, 4, 8, 16, 32,64.
As can be seen, our model can achieve thebest performances when the beam size is set to 8.Larger beam sizes do not bring better results.4.2.2 Influence of Fluency WeightThe fluency score is used for generating readabletitles, while the edge score is used for generatinginformative titles.
The balance between them isimportant.
By default, we set one to the weightof edge score, and find the best weight ?
for thefluency score.
We set ?
ranging from 0 to 1 withand interval of 0.1, to investigate the influence of4670.30.320.340.360.380.40.4210  20  30  40  50  60  0.10.110.120.130.140.150.16Rouge1Rouge2Beam SizeRouge1Rouge2Figure 6: Results with different beam sizes.0.350.360.370.380.390.40.410.420  0.2  0.4  0.6  0.8  1  0.130.1350.140.1450.150.1550.160.165Rouge1Rouge2Fluency WeightRouge1Rouge2Figure 7: Results using different fluency weights.this parameter8.
Figure 7 shows the results.
Thebest result is obtained when ?
= 0.4.4.2.3 Influence of Candidate Event CountIdeally, all the sentences of an original text shouldbe considered in multi-sentence compression.
Butan excess of sentences would bring more noise.We suppose that the number of candidate eventsN is important as well.
To study its influence, wereport the model results with different N , from 1to 15 with an interval of 1.
As shown in Figure8, the performance increases significantly from 1to 10, and no more gains when N > 10.
Theperformance decreases drastically whenM rangesfrom 12 to 15.4.3 Final ResultsTable 1 shows the final results on the testdataset.
The performances of the proposed event-driven model are shown by EventRank.
Inaddition, we use our graph-based MSC model to8Preliminary results show that ?
is better below one.9The mark ?
denotes the results are inaccurate, which areguessed from the figures in the published paper.0.320.340.360.380.40.422  4  6  8  10  12  140.120.130.140.150.16Rouge1Rouge2Number of Candidate EventsRouge1Rouge2Figure 8: Results using different numbers ofcandidate events.Method Model Type Rouge1 Rouge2Our SalMSCSentRank Extractive 0.3511 0.1375PhraseRank Abstractive 0.3706 0.1415EventRank Event-driven 0.4247?0.1484?Using MSCSentRank Extractive 0.2773 0.0980PhraseRank Abstractive 0.3652 0.1299EventRank Event-driven 0.3822?0.1380?Other workSentRank+SSC Extractive 0.2752 0.0855Topiary Abstractive 0.2835 0.0872Woodsend Abstractive 0.26?0.06?9Table 1: Performance comparison for automaticevaluation.
The mark ?
denotes that the result issignificantly better with a p-value below 0.01.generate titles for SentRank and PhraseRank,respectively, as mentioned in Section 3.2.1.
Bycomparison with the two models, we can examinethe effectiveness of the event-driven model.
Asshown in Table 1, the event-driven model achievesthe best scores on both Rouge1 and Rouge2,demonstrating events are more effective thansentences and phrases.Further, we compare our proposed MSCmethod with the MSC proposed by Filippova(2010), to study the effectiveness of ournovel MSC.
We use MSC10and SalMSC11to10The MSC source code, published by Boudin and Morin(2013), is available at https://github.com/boudinfl/takahe.11Our source code is available at https://github.com/dram218/WordGraphCompression.468Method Info.
Infu.
Cohe.SentRank 4.13 2.85 2.54PhraseRank 4.21 3.25 2.62EventRank 4.35?3.41?3.22?Table 2: Results from the manual evaluation.
Themark ?
denotes the result is significantly betterwith a p-value below 0.01.SentRank, PhraseRank and EventRank todenote their MSC method and our proposed MSC,respectively, applying them, respectively.
Asshown in Table 1, better performance is achievedby our MSC, demonstrating the effectiveness ofour proposed MSC.
Similarly, the event-drivenmodel can achieve the best results.We report results of previous state-of-the-artsystems as well.
SentRank+SSC denotes theresult of Erkan and Radev (2004), which usesour SentRank and SSC to obtain the final title.Topiary denotes the result of Zajic et al (2005),which is an early abstractive model.
Woodsenddenotes the result of Woodsend et al (2010),which is an abstractive model using a quasi-synchronous grammar to generate a title.
Asshown in Table 1, MSC is significantly better thanSSC, and our event-driven model achieves thebest performance, compared with state-of-the-artsystems.Following Alfonseca et al (2013), we conducthuman evaluation also.
The results are shown inTable 2, by three aspects: informativeness, fluencyand coherence.
The overall tendency is similar tothe results, and the event-driven model achievesthe best results.4.4 Example OutputsWe show several representative examples of theproposed event-driven model, in comparison withthe extractive and abstractive models.
Theexamples are shown in Table 3.In the first example, the results of bothSentRank and PhraseRank contain theredundant phrase ?catastrophe Tuesday?.
Theoutput of PhraseRank is less fluent comparedwith that of SentRank.
The preposition ?for?is not recovered by the headline generationsystem PhraseRank.
In contrast, the output ofEventRank is better, capturing the major eventin the reference title.Method Generated HeadlinesReference Honduras, other Caribbean countries bracefor the wrath of Hurricane MitchSentRank Honduras braced for potential catastropheTuesday as Hurricane Mitch roared throughnorthwest CaribbeanPhraseRank Honduras braced catastrophe TuesdayHurricane Mitch roared northwestCaribbeanEventRank Honduras braced for Hurricane Mitchroared through northwest CaribbeanReference At Ibero-American summit Castro protestsarrest of Pinochet in LondonSentRank Castro disagreed with the arrest AugustoPinochet calling international meddlingPhraseRank Cuban President Fidel Castro disagreedarrest London Chilean dictator AugustoPinochetEventRank Fidel Castro disagreed with arrest inLondon of Chilean dictator AugustoPinochetReference Cambodian leader Hun Sen rejectsopposition demands for talks in BeijingSentRank Hun Sen accusing opposition parties ofinternationalize the political crisisPhraseRank opposition parties demands talksinternationalize political crisisEventRank Cambodian leader Hun Sen rejectedopposition parties demands for talksTable 3: Comparison of headlines generated by thedifferent methods.In the second example, the outputs of threesystems all lose the phrase ?Ibero-Americansummit?.
SentRank gives different additionalinformation compared with PhraseRank andEventRank.
Overall, the three outputs can beregarded as comparable.
PhraseRank also has afluency problem by ignoring some function words.In the third example, SentRank does notcapture the information on ?demands for talks?.PhraseRank discards the preposition word?for?.
The output of EventRank is better, beingboth more fluent and more informative.From the three examples, we can see thatSentRank tends to generate more readabletitles, but may lose some important information.PhraseRank tends to generate a title withmore important words, but the fluency isrelatively weak even with MSC.
EventRankcombines the advantages of both SentRankand PhraseRank, generating titles that containmore important events with complete structures.The observation verifies our hypothesis in theintroduction ?
that extractive models havethe problem of low information coverage, and469abstractive models have the problem of poorgrammaticality.
The event-driven mothod canalleviate both issues since event offer a trade-offbetween sentence and phrase.5 Related WorkOur event-driven model is different fromtraditional extractive (Dorr et al, 2003; Erkanand Radev, 2004; Alfonseca et al, 2013) andabstractive models (Zajic et al, 2005; Soricutand Marcu, 2007; Woodsend et al, 2010; Xuet al, 2010) in that events are used as the basicprocessing units instead of sentences and phrases.As mentioned above, events are a trade-offbetween sentences and phrases, avoiding sparsityand structureless problems.
In particular, ourevent-driven model can interact with sentencesand phrases, thus is a light combination for twotraditional models.The event-driven model is mainly inspiredby Alfonseca et al (2013), who exploit eventsfor multi-document headline generation.
Theyleverage titles of sub-documents for supervisedtraining.
In contrast, we generate a title for asingle document using an unsupervised model.We use novel approaches for event ranking andtitle generation.In recent years, sentence compression (Galanisand Androutsopoulos, 2010; Yoshikawa and Iida,2012; Wang et al, 2013; Li et al, 2014;Thadani, 2014) has received much attention.Some methods can be directly applied for multi-document summarization (Wang et al, 2013; Liet al, 2014).
To our knowledge, few studieshave been explored on applying them in headlinegeneration.Multi-sentence compression based on wordgraph was first proposed by Filippova (2010).Some subsequent work was presented recently.Boudin and Morin (2013) propose that the keyphrase is helpful to sentence generation.
Thekey phrases are extracted according to syntacticpattern and introduced to identify shortest pathin their work.
Mehdad et al (2013; Mehdadet al (2014) introduce the MSC based on wordgraph into meeting summarization.
Tzouridis etal.
(2014) cast multi-sentence compression as astructured predication problem.
They use a large-margin approach to adapt parameterised edgeweights to the data in order to acquire the shortestpath.
In their work, the sentences introduced toa word graph are treated equally, and the edges inthe graph are constructed according to the adjacentorder in original sentence.Our MSC model is also inspired by Filippova(2010).
Our approach is more aggressivethan their approach, generating compressionswith arbitrary length by using a different edgeconstruction strategy.
In addition, our searchalgorithm is also different from theirs.
Ourgraph-based MSC model is also similar inspirit to sentence fusion, which has been usedfor multi-document summarization (Barzilay andMcKeown, 2005; Elsner and Santhanam, 2011).6 Conclusion and Future WorkWe proposed an event-driven model headlinegeneration, introducing a graph-based MSC modelto generate the final title, based on a set ofevents.
Our event-driven model can incorporatesentence and phrase salience, which has been usedin extractive and abstractive HG models.
Theproposed graph-based MSC model is not limitedto our event-driven model.
It can be appliedon extractive and abstractive models as well.Experimental results on DUC?04 demonstratethat event-driven model can achieve better resultsthan extractive and abstractive models, and theproposed graph-based MSC model can bringimproved performances compared with previousMSC techniques.
Our final event-driven modelobtains the best result on this dataset.For future work, we plan to explore twodirections.
Firstly, we plan to introduce eventrelations to learning event salience.
In addition,we plan to investigate other methods about multi-sentence compression and sentence fusion, such assupervised methods.AcknowledgmentsWe thank all reviewers for their detailedcomments.
This work is supported by theState Key Program of National Natural ScienceFoundation of China (Grant No.61133012), theNational Natural Science Foundation of China(Grant No.61373108, 61373056), the NationalPhilosophy Social Science Major Bidding Projectof China (Grant No.11&ZD189), and the KeyProgram of Natural Science Foundation ofHubei, China (Grant No.2012FFA088).
Thecorresponding authors of this paper are MeishanZhang and Donghong Ji.470ReferencesEnrique Alfonseca, Daniele Pighin and GuillermoGarrido.
2013.
HEADY: News headline abstractionthrough event pattern clustering.
In Proceedings ofACL 2013,pages 1243?1253.Regina Barzilay and Michael Elhadad.
1997.Using Lexical Chains for Text Summarization.In Proceedings of the Intelligent Scalable TextSummarization Workshop(ISTS?97), Madrid.Regina Barzilay and Kathleen R. McKeown.2005.
Sentence fusion for multidocument newssummarization.
Computational Linguistics, 31(3),pages 297?328.Florian Boudin and Emmanuel Morin.
2013.Keyphrase Extraction for N-best Reranking inMulti-Sentence Compression.
In Proccedings of theNAACL HLT 2013 conference, page 298?305.James Clarke and Mirella Lapata.
2010.
DiscourseConstraints for Document Compression.Computational Linguistics, 36(3), pages 411?441.Michael Collins and Brian Roark.
2004.
IncrementalParsing with the Perceptron Algorithm.
InProceedings of ACL 2004, pages 111-118.Corston-Oliver, Simon.
2001.
Text compaction fordisplay on very small screens.
In Proceedings ofthe NAACL Workshop on Automatic Summarization,Pittsburg, PA, 3 June 2001, pages 89?98.Xiao Ding, Yue Zhang, Ting Liu, Junwen Duan.2014.
Using Structured Events to Predict StockPrice Movement : An Empirical Investigation.
InProceedings of EMNLP 2014, pages 1415?1425.Bonnie Dorr, David Zajic, and Richard Schwartz.2003.
Hedge trimmer: A parse-and-trim approachto headline generation.
In proceedings of theHLT?NAACL 03 on Text summarization workshop,volume 5, pages 1?8.Micha Elsner and Deepak Santhanam.
2011.
Learningto fuse disparate sentences.
In Proceedings of ACL2011, pages 54?63.Nicolai Erbs, Iryna Gurevych and Torsten Zesch.2013.
Hierarchy Identification for AutomaticallyGenerating Table-of-Contents.
In Proceedings ofRecent Advances in Natural Language Processing,Hissar, Bulgaria, pages 252?260.Gunes Erkan and Dragomir R Radev.
2004.
LexRank :Graph-based Lexical Centrality as Salience in TextSummarization.
Journal of Artificial IntelligenceResearch 22, 2004, pages 457?479.Fader A, Soderland S, Etzioni O.
2011.
Identifyingrelations for open information extraction.
InProceedings of EMNLP 2011, pages 1535?1545.Katja Filippova.
2010.
Multi-sentence compression:Finding shortest paths in word graphs.
InProceedings of Coling 2010, pages 322?330.Dimitrios Galanis and Ion Androutsopoulos.
2010.
Anextractive supervised two-stage method for sentencecompression.
In Proceedings of NAACL 2010, pages885?893.Barbara J. Grosz and Scott Weinstein and Aravind K.Joshi.
1995.
Centering: A framework for modelingthe local coherence of discourse.
ComputationalLinguistics, volume 21, pages 203?225.Zhichao Hu, Elahe Rahimtoroghi, Larissa Munishkina,Reid Swanson and Marilyn A.Walker.
2013.Unsupervised Induction of Contingent Event Pairsfrom Film Scenes.
In Proceedings of EMNLP 2013,pages 369?379.Chen Li,Yang Liu, Fei Liu, Lin Zhao, Fuliang Weng.2014.
Improving Multi-documents Summarizationby Sentence Compression based on ExpandedConstituent Parse Trees.
In Proceedings of EMNLP2014, pages 691?701.Chin-Yew Lin.
2004.
Rouge: A package forautomatic evaluation of summaries.
In TextSummarization Branckes Out: Proceedings of theACL?04 Workshop, pages 74?81.Andre F.T.
Martins and Noah A. Smith.
2009.Summarization with a joint model for sentenceextraction and compression.
In Proceedings ofthe Workshop on Integer Linear Programming forNatural Language Processing, pages 1?9.Yashar Mehdad, Giuseppe Carenini, Frank W.Tompaand Raymond T.Ng.
2013.
Abstractive MeetingSummarization with Entailment and Fusion.
InProceedings of the 14th European Workshop onNatural Language Generation, pages 136?146.Yashar Mehdad, Giuseppe Carenini and RaymondT.Ng.
2014.
Abstractive Summarization ofSpoken and Written Conversations Based on PhrasalQueries.
In Proceedings of ACL 2014, pages 1220?1230.Jane Morris and Graeme Hirst.
1991.
Lexical cohesioncomputed by thesaural relations as an indicator ofthe structure of text.
Computational Linguistics,17(1), pages 21?48.Marie-Catherine de Marneffe and Christopher D.Manning.
2008.
The stanford typed dependenciesrepresentation.
In COLING 2008 Workshopon Cross-framework and Cross-domain ParserEvaluation.Jun-Ping Ng, Yan Chen, Min-Yen Kan, Zhoujun Li.2014.
Exploiting Timelines to Enhance Multi-document Summarization.
Proceedings of ACL2014, pages 923?933.471Likun Qiu and Yue Zhang.
2014.
ZORE: A Syntax-based System for Chinese Open Relation Extraction.Proceedings of EMNLP 2014, pages 1870?1880.Robert G. Sargent.
1988.
Polynomial Time JointStructural Inference for Sentence Compression.Management Science, 34(10), pages 1231?1251.Schwartz R. 1988.
Unsupervised topic discovery.
InProceedings of workshop on language modeling andinformation retrieval, pages 72?77.R.
Soricut, and D. Marcu.
2007.
Abstractive headlinegeneration using WIDL-expressions.
InformationProcessing and Management, 43(6), pages 1536?1548.Kapil Thadani.
2014.
Approximation Strategiesfor Multi-Structure Sentence Compression.Proceedings of ACL 2014, pages 1241?1251.Emmanouil Tzouridis, Jamal Abdul Nasir and UlfBrefeld.
2014.
Learning to Summarise RelatedSentences.
Proceedings of COLING 2014,Dublin,Ireland, August 23-29 2014. pages 1636?1647.Carles Ventura, Xavier Giro-i-Nieto, VeronicaVilaplana, Daniel Giribet, and Eusebio Carasusan.2013.
Automatic keyframe selection based onMutual Reinforcement Algorithm.
In Proceedingsof 11th international workshop on content-basedmultimedia indexing(CBMI), pages 29?34.Stephen Wan and Kathleen McKeown.
2004.Generating overview summaries of ongoing emailthread discussions.
In Proceedings of COLING2004, Geneva, Switzerland, 2004, pages 1384?1394.Lu Wang, Hema Raghavan, Vittorio Castelli, RaduFlorian, Claire Cardie.
2013.
A sentencecompression based framework to query-focusedmutli-document summarization.
In Proceedings ofACL 2013, Sofia, Bulgaria, August 4-9 2013, pages1384?1394.Kristian Woodsend, Yansong Feng and Mirella Lapata.2010.
Title generation with quasi-synchronousgrammar.
In Proceedings of EMNLP 2010, pages513?523.Songhua Xu, Shaohui Yang and Francis C.M.
Lau.2010.
Keyword extraction and headline generationusing novel work features.
In Proceedings of AAAI2010, pages 1461?1466.Katsumasa Yoshikawa and Ryu Iida.
2012.
SentenceCompression with Semantic Role Constraints.
InProceedings of ACL 2012, pages 349?353.David Zajic, Bonnie Dorr and Richard Schwartz.
2005.Headline generation for written and broadcast news.lamp-tr-120, cs-tr-4698.Hongyuan Zha.
2002.
Generic summarizationand keyphrase extraction using mutual reinforementprinciple and sentence clustering.
In Proceedings ofSIGIR 2002, pages 113?120.Qi Zhang, Xipeng Qiu, Xuanjing Huang, Wu Lide.2008.
Learning semantic lexicons using graphmutual reinforcement based bootstrapping.
ActaAutomatica Sinica, 34(10), pages 1257?1261.Yue Zhang, Stephen Clark.
2011.
Syntactic ProcessingUsing the Generalized Perceptron and Beam Search.Computational Linguistics, 37(1), pages 105?150.Yue Zhang.
2013.
Partial-Tree Linearization:Generalized Word Ordering for Text Synthesis.
InProceedings of IJCAI 2013, pages 2232?2238.472
