UNISYS :MUC-3 TEST RESULTS AND ANALYSI SCarl Weir, Robin McEntire, Barry Silk, and Tim FininUnisys Center for Advanced Information Technolog yPaoli, Pennsylvani aweir@prc .unisys .com(215) 648-2369INTRODUCTIO NThe Unisys MUC-3 system is based on a three-tiered approach to text processing in which a novel an dquite powerful knowledge-based form of information retrieval plays a central role .
The main componentsof this approach are as follows :A Keyword-Based Information Retrieval Component .This component predicts the occurrence of types of events in texts based on the presenc eof key words and phrases .A Knowledge-Based Information Retrieval Component .This component, called KBIRD in the Unisys MUC-3 system, performs the followin gtasks :?
Based on the co-occurrence of the predictions made by the keyword-based analysi scomponent and expressions and concepts discovered in a given text, it predicts th elikely occurrence of additional event types .?
It locates instances of predicted event types in texts .?
It identifies possible slot values for located instances of events .
[A Linguistic Analysis Component .
]Although a natural language processing component was included in the design of theUnisys MUC-3 system as a third level of text analysis, not enough time was availabl eduring the MUC-3 development cycle both to develop a knowledge-based informationretrieval component and to port the Unisys Pundit text-processing system to the MUC -3 terrorist domain .
A decision was made to focus on developing the knowledge-base dinformation retrieval component and postpone the integration of Pundit until MUC-4 .A Template Generation Component .An application-specific Prolog program was written to merge templates describing thesame event, and to select the most likely slot values for templates in cases where multipleslot values were proposed .The Unisys MUC-3 development effort was comprised of two full-time Unisys staff members and on egovernment employee on industrial rotation .
A total of 2650 person-hours were put into the project, 80 0of which were contributed by the government employee .
The effort was partially supported by a DARP Agrant, which covered approximately 30% of the development cost .'
The bulk of the effort involved thedevelopment of the KBIRD system and its MUC-3 rule base .
These two tasks took approximately thesame amount of time, and in total comprised roughly 85% of the effort .
'Work on this project was partially supported by Darpa under contract MDA-903-89-C-0041 .112SLOT POS ACT COR PAR INC ICR IPA SPU MIS NON ABC FRB OVO PA Ltemplate-id 104 47 38 0 0 0 0 9 66 36 36 81 1 9incident-date 100 35 26 7 3 0 7 0 65 4 28 81 0incident-type 104 38 34 4 0 0 4 0 66 0 35 95 0 0category 71 28 15 0 7 0 0 6 49 27 21 54 21 1 0indiv-perps 93 14 6 1 3 0 1 4 83 41 7 46 2 8org-perps 60 41 11 1 6 2 1 23 42 37 19 28 58perp-confidence 60 37 7 2 9 1 2 19 42 37 13 22 51 5phys-target-ids 53 17 10 2 0 0 2 5 41 66 21 65 29phys-target-num 37 11 7 0 4 0 0 0 26 67 19 64 0phys-target-types 53 17 9 1 2 0 1 5 41 66 18 56 29 0human-target-ids 127 37 12 7 6 3 7 12 102 19 12 42 3 2human-target-num 83 25 10 1 12 0 1 2 60 19 13 42 8human-target-types 127 37 15 7 3 3 7 12 102 19 14 50 32 1target-nationality 16 3 0 0 0 0 0 3 16 89 0 0 100 0instrument-types 23 13 3 1 0 0 0 9 19 77 15 27 69 0incident-location 104 33 8 22 3 0 2 0 71 0 18 58 0phys-effects 36 17 6 2 1 1 2 8 27 77 19 41 47 1human-effects 53 1 0 0 1 0 0 0 52 71 0 0 0 0MATCHED ONLY 519 451 216 68 60 10 37 117 185 274 47 54 2 6MATCHED/MISSING 1304 451 216 58 60 10 37 117 970 752 19 54 2 6ALL TEMPLATES 1304 558 216 58 60 10 37 224 970 818 19 44 4 0SET FILLS ONLY 543 191 89 17 23 5 16 62 414 463 18 51 32 0Figure 1: Unisys MUC-3 System ScoresTEST RESULT SThe scores reported for the Unisys MUC-3 system are shown in Figure 1 .
The low ACT and high MI Sscores reported for the template id slot indicate that event detection was a problem .
2 Poor event detectio nperformance explains the relatively low recall scores reported for all but the MATCHED ONLY summarymeasurement .
The MATCHED ONLY recall score is a measure of performance in which spurious (fals epositive) and missing (false negative) templates are not factored in .
The extremely low SPU score reportedfor the template id slot suggests that further training of the rule base to improve event detection will no tcome at the expense of lower precision scores .
In Figure 2, the performance of the Unisys system wit hrespect to other MUC-3 systems is indicated in two scatter plots .Since template slot-filling algorithms are triggered by the detection of an event, poor event detectio nperformance has a direct negative impact on slot-filling performance .
The recall scores for the UnisysMUC-3 system reflect this fact .
However, for five slots precision scores are also low .
These low precisio nscores are not a consequence of poor event detection, but result instead from a combination of poorl ytrained inference rules used to extract the sort of information expressed in the pertinent slots, and bug sin the template generation routines that gather and merge correctly detected information into templat estructures .ANALYSISContrary to what the low recall scores that have been reported suggest, the Unisys MUC-3 system ca nperform well at predicting events .
The keyword-based prediction of event types is very robust ; the databas eused during this stage of processing was derived from the full 1300 message DEV corpus .
Moreover, whenthe rules used by KBIRD are properly trained, they do a very good job of locating instances of th eevents predicted by keyword analysis .
Unfortunately, the KBIRD locator rules used to detect instance sof events were trained on a relatively small set of messages?the 200 NOSC DEV and TST1 messages .Consequently, even though the keyword-based analysis phase may have correctly predicted the likel yoccurrence of a given event type, KBIRD may not have been able to locate an instance of the predicte devent type .
Thus, KBIRD 's locator rules had a negating influence on the performance of the keyword -based analysis phase .
Prior to the final MUC-3 test, versions of the Unisys system with fewer, mor e2 The template id slot is scored differently from other slots?the values reported for this slot are a measure of even tdetection performance (it doesn ' t make sense to report system performance in generating template ids, since the order i nwhich templates are generated is not relevant in this task) [2].11 3Unisy snUnisy s5 0mmnm40 -enmnmmmmn20 -mm0 nm1 01020304050600 020 504030 607 06 03 040ReczlIReczl iFigure 2: The scatter plot on the left indicates the relative performance of the Unisys MUC-3 system withou ttaking into consideration false negative and false positive hits (the MATCHED-ONLY score) .
The scatter plo ton the right indicates the relative performance of the Unisys MUC-3 system when taking into consideratio nboth false negative and false positive hits (the ALL-TEMPLATES score) .general event detection rules in place had recall scores ranging in the high 30's and low 40's for all th esummary measures .
A tactical mistake was made in attempting to replace this general rule base with alarger, more context-sensitive one, since there was not enough time to allow the larger rule base to beproperly trained .
In the evaluation, generating spurious templates tended to have much less of an impac ton scores than failing to generate templates at all .
In future evaluations, we will investigate the use o fdifferent locator rule sets as a settable system parameter .Rule training was hindered during the MUC-3 development cycle by the need to concurrently build thecomponent that would be using the rules .
In addition to this development problem, technical difficultiesin KBIRD's design began to appear once the number of rules had grown to a realistic size .
These technicalproblems resulted in slow message processing speeds, which further complicated the rule training process .The following three key problems were identified :Heavy use of forward-chaining .There is currently too much reliance on forward-chaining in the KBIRD system .
ManyKBIRD reasoning tasks could be more efficiently achieved in a backward-chaining fashion .Expensive TMS system .KBIRD was built on top of a very general inferencing mechanism with an expensiv eTMS system.
KBIRD's needs for truth maintenance could be accomodated using a muchsimpler TMS component .Inability to focus search .In KBIRD, it is currently not possible to focus search on a specific region of text .
Themechanism used to satisfy a rule looks for all chart elements (concepts, words, phrases ,and so forth) that match constituent expressions in the antecedent of a rule .
If the KBIRDrule specifies that an element of a certain type must be in the same sentence as some otherelement, it would be more efficient to limit the search space to just those chart element sthat fall within the span of the sentence.
However, KBIRD's algorithm currently searche sthrough chart elements indexed to locations anywhere in the text for suitable candidates .114CONCLUDING REMARK SThe time constraints imposed in MUC-3 made it impossible to fully develop the Unisys MUC-3 system' sknowledge-based information retrieval component, KBIRD, before the evaluation deadline .
Consequently ,it is not possible at this time to establish the capabilities of the three-tiered approach realized in th esystem.
The system's scores indicate, however, that although the rules for locating instances of event swere inadequately trained, its performance at identifying slot values once an instance has been found i squite good .Future work on the system will solve the technical problems that have been observed .
This will b eachieved by performing the following tasks :?
The overall system flow will be restructured to allow backward-chaining to handle more of theprocessing load .?
The current forward-chaining mechanism will be reimplemented so that it is specifically geared t othe processing tasks envisoned for KBIRD .?
Subject to an appropriate funding source, the KBIRD locator rules used to detect instances o fpredicted event types will be properly trained .In addition to solving the technical problems that have arisen in the system's KBIRD component, amajor effort will be made to incorporate the Unisys Pundit NLP system into the MUC-3 system .REFERENCES[1] Tim Finin, Robin McEntire, Carl Weir, and Barry Silk .
A three-tiered approach to natural languag etext retrieval .
In Proceedings of the AAAI workshop on Natural Language Text Retrieval, Los Angeles ,July 1991 .
[2] NOSC.
Muc Scoring Manual, 1991 .
Manual prepared for use in the Darpa-sponsored Third MessageUnderstanding Conference (MUC-3) .
[3] Carl Weir, Tim Finin, Barry Silk, Marcia Linebarger, and Robin McEntire .
Knowledge-based strategie sfor robust text-understanding .
The Eighth Annual Intelligence Community AI/Advance ComputingSymposium, March 1991 .115
