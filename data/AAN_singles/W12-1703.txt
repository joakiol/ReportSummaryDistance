In: R. Levy & D. Reitter (Eds.
), Proceedings of the 3rd Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2012), pages 21?30,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsWhy long words take longer to read:the role of uncertainty about word lengthKlinton BicknellDepartment of PsychologyUniversity of California, San Diego9500 Gilman Drive #109La Jolla, CA 92093-0109kbicknell@ucsd.eduRoger LevyDepartment of LinguisticsUniversity of California, San Diego9500 Gilman Drive #108La Jolla, CA 92093-0108rlevy@ucsd.eduAbstractSome of the most robust effects of linguis-tic variables on eye movements in reading arethose of word length.
Their leading explana-tion states that they are caused by visual acu-ity limitations on word recognition.
However,Bicknell (2011) presented data showing that amodel of eye movement control in reading thatincludes visual acuity limitations and modelsthe process of word identification from visualinput (Bicknell & Levy, 2010) does not pro-duce humanlike word length effects, provid-ing evidence against the visual acuity account.Here, we argue that uncertainty about wordlength in early word identification can driveword length effects.
We present an extensionof Bicknell and Levy?s model that incorpo-rates word length uncertainty, and show that itproduces more humanlike word length effects.1 IntroductionControlling the eyes while reading is a complextask, and doing so efficiently requires rapid deci-sions about when and where to move the eyes 3?4 times per second.
Research in psycholinguisticshas demonstrated that these decisions are sensitiveto a range of linguistic properties of the text be-ing read, suggesting that the eye movement recordmay be viewed as a detailed trace of the timecourseof incremental comprehension.
A number of cog-nitive models of eye movement control in read-ing have been proposed, the most well-known ofwhich are E-Z Reader (Reichle, Pollatsek, Fisher, &Rayner, 1998; Reichle, Rayner, & Pollatsek, 2003)and SWIFT (Engbert, Longtin, & Kliegl, 2002; En-gbert, Nuthmann, Richter, & Kliegl, 2005).
Thesemodels capture a large range of the known proper-ties of eye movements in reading, including effectsof the best-documented linguistic variables on eyemovements: the frequency, predictability, and lengthof words.Both models assume that word frequency, pre-dictability, and length affect eye movements in read-ing by affecting word recognition, yet neither onemodels the process of identifying words from visualinformation.
Rather, each of these models directlyspecifies the effects of these variables on exoge-nous word processing functions, and the eye move-ments the models produce are sensitive to thesefunctions?
output.
Thus, this approach cannot an-swer the question of why these linguistic variableshave the effects they do on eye movement behav-ior.
Recently, Bicknell and Levy (2010) presented amodel of eye movement control in reading that di-rectly models the process of identifying the text fromvisual input, and makes eye movements to max-imize the efficiency of the identification process.Bicknell and Levy (2012) demonstrated that thisrational model produces effects of word frequencyand predictability that qualitatively match those ofhumans: words that are less frequent and less pre-dictable receive more and longer fixations.
Becausethis model makes eye movements to maximize theefficiency of the identification process, this resultgives an answer for the reason why these variablesshould have the effects that they do on eye move-ment behavior: a model that works to efficientlyidentify the text makes more and longer fixations on21words of lower frequency and predictability becauseit needs more visual information to identify them.Bicknell (2011) showed, however, that the ef-fects of word length produced by the rational modellook quite different from those of human readers.Because Bicknell and Levy?s (2010) model imple-ments the main proposal for why word length effectsshould arise, i.e., visual acuity limitations, the factthat the model does not reproduce humanlike wordlength effects suggests that our understanding of thecauses of word length effects may be incomplete.In this paper, we argue that this result arose be-cause of a simplifying assumption made in the ra-tional model, namely, the assumption that the readerhas veridical knowledge about the number of char-acters in a word being identified.
We present an ex-tension of Bicknell and Levy?s (2010) model whichdoes not make this simplifying assumption, andshow in two sets of simulations that effects of wordlength produced by the extended model look morelike those of humans.
We argue from these resultsthat uncertainty about word length is a necessarycomponent of a full understanding of word lengtheffects in reading.2 Reasons for word length effectsThe empirical effects of word length displayed byhuman readers are simple to describe: longer wordsreceive more and longer fixations.
The major rea-son proposed in the literature on eye movements inreading for this effect is that when fixating longerwords, the average visual acuity of all the letters inthe word will be lower than for shorter words, andthis poorer average acuity is taken to lead to longerand more fixations.
This intuition is built into the ex-ogenous word processing functions in E-Z Readerand SWIFT.
Specifically, in both models, the wordprocessing rate slows as the average distance to thefovea of all letters in the word increases, and thisspecification of the effect of length on word process-ing rates is enough to produce reasonable effects ofword length on eye movements: both models makemore and longer fixations on longer words ?
similarto the pattern of humans ?
across a range of mea-sures (Pollatsek, Reichle, & Rayner, 2006; Engbertet al, 2005) including the duration of the first fixa-tion on a word (first fixation duration), the durationof all fixations on a word prior to leaving the word(gaze duration), the rate at which a word is not fix-ated prior to a fixation on a word beyond it (skiprate), and the rate with which a word is fixated morethan once prior to a word beyond it (refixation rate).There are, however, reasons to believe that this ac-count may be incomplete.
First, while it is the casethat the average visual acuity of all letters in a fixatedword must be lower for longer words, this is just be-cause there are additional letters in the longer word.While these additional letters pull down the aver-age visual acuity of letters within the word, each ad-ditional letter should still provide additional visualinformation about the word?s identity, an argumentsuggesting that longer words might require less ?
notmore ?
time to be identified.
In fact, in SWIFT, theexogenous word processing rate function slows asboth the average and the sum of the visual acuities ofthe letters within the word decrease, but E-Z Readerdoes not implement this idea in any way.
Addi-tionally, a factor absent from both E-Z Reader andSWIFT, is that the visual neighborhoods of longerwords (at least in English) appear to be sparser,when considering the number of words formed bya single letter substitution (Balota, Cortese, Sergent-Marshall, Spieler, & Yap, 2004), or the average or-thographic Levenshtein distance of the most simi-lar 20 words (Yarkoni, Balota, & Yap, 2008).
Be-cause reading words with more visual neighbors isgenerally slower (Pollatsek, Perea, & Binder, 1999),this argument gives another reason to expect longerwords to require less ?
not more ?
time to be read.So while E-Z Reader and SWIFT produce rea-sonable effects of word length on eye movementmeasures (in which longer words receive more andlonger fixations) by assuming a particular effect ofvisual acuity, it is less clear whether a visual acu-ity account can yield reasonable word length effectsin a model that also includes the two opposing ef-fects mentioned above.
Determining how these dif-ferent factors should interact to produce word lengtheffects requires a model of eye movements in read-ing that models the process of word identificationfrom disambiguating visual input (Bicknell & Levy,in press).
The model presented by Bicknell and Levy(2010) fits this description, and includes visual acu-ity limitations (in fact, identical to the visual acuityfunction in SWIFT).
As already mentioned, how-22ever, Bicknell (2011) showed that the model didnot yield a humanlike length effect.
Instead, whilelonger words were skipped less often and refixatedmore (as for humans), fixation durations generallyfell with word length ?
the opposite of the patternshown by humans.
This result suggests that visualacuity limitations alone cannot explain the positiveeffect of word length on fixation durations in thepresence of an opposing force such as the fact thatlonger words have smaller visual neighborhoods.We hypothesize that the reason for this patternof results relates to a simplifying assumption madeby Bicknell and Levy?s model.
Specifically, whilevisual input in the model yields noisy informationabout the identities of letters, it gives veridical in-formation about the number of letters in each word,for reasons of computational convenience.
There aretheoretical and empirical reasons to believe that thissimplifying assumption is incorrect, that early in theword identification process human readers do havesubstantial uncertainty about the number of lettersin a word, and further, that this may be especiallyso for long words.
For example, results with maskedpriming have shown that recognition of a target wordis facilitated by a prime that is a proper subset ofthe target?s letters (e.g., blcn?balcon; Peressotti &Grainger, 1999; Grainger, Granier, Farioli, Van Ass-che, & van Heuven, 2006), providing evidence thatwords of different length have substantial similarityin early processing.
For these reasons, some recentmodels of isolated word recognition (Gomez, Rat-cliff, & Perea, 2008; Norris, Kinoshita, & van Cast-eren, 2010) have suggested that readers have someuncertainty about the number of letters in a wordearly in processing.If readers have uncertainty about the length ofwords, we may expect that the amount of uncertaintywould grow proportionally to length, as uncertaintyis proportional to set size in other tasks of num-ber estimation (Dehaene, 1997).
This would agreewith the intuition that an 8-character word shouldbe more easily confused with a 9-character wordthan a 3-character word with a 4-character word.
In-cluding uncertainty about word length that is largerfor longer words would have the effect of increas-ing the number of visual neighbors for longer wordsmore than for shorter words, providing another rea-son (in addition to visual acuity limitations) thatlonger words may require more and longer fixations.In the remainder of this paper, we describe anextension of Bicknell and Levy?s (2010) model inwhich visual input provides stochastic ?
rather thanveridical ?
information about the length of words,yielding uncertainty about word length, and in whichthe amount of uncertainty grows with length.
Wethen present two sets of simulations with this ex-tended model demonstrating that it produces morehumanlike effects of word length, suggesting thatuncertainty about word length may be an importantcomponent of a full understanding of the effects ofword length in reading.3 A rational model of readingIn this section, we describe our extension of Bicknelland Levy?s (2010) rational model of eye movementcontrol in reading.
Except for the visual input sys-tem, and a small change to the behavior policy toallow for uncertainty about word length, the modelis identical to that described by Bicknell and Levy.The reader is referred to that paper for further com-putational details beyond what is described here.In this model, the goal of reading is taken to beefficient text identification.
While it is clear that thisis not all that readers do ?
inferring the underly-ing structural relationships among words in a sen-tence and discourse relationships between sentencesthat determine text meaning is a fundamental part ofmost reading ?
all reader goals necessarily involveidentification of at least part of the text, so text iden-tification is taken to be a reasonable first approxima-tion.
There are two sources of information relevantto this goal: visual input and language knowledge,which the model combines via Bayesian inference.Specifically, it begins with a prior distribution overpossible identities of the text given by its languagemodel, and combines this with noisy visual inputabout the text at the eyes?
position, giving the likeli-hood term, to form a posterior distribution over theidentity of the text taking into account both the lan-guage model and the visual input obtained thus far.On the basis of the posterior distribution, the modeldecides whether or not to move its eyes (and if sowhere to move them to) and the cycle repeats.233.1 Formal problem of reading: ActionsThe model assumes that on each of a series ofdiscrete timesteps, the model obtains visual inputaround the current location of the eyes, and thenchooses between three actions: (a) continuing to fix-ate the currently fixated position, (b) initiating a sac-cade to a new position, or (c) stopping reading.
Ifthe model chooses option (a), time simply advances,and if it chooses option (c), then reading immedi-ately ends.
If a saccade is initiated (b), there is a lagof two timesteps, representing the time required toplan and execute a saccade, during which the modelagain obtains visual input around the current posi-tion, and then the eyes move toward the intendedtarget.
Because of motor error, the actual landing po-sition of the eyes is normally distributed around theintended target with the standard deviation in char-acters given by a linear function of the intended dis-tance d (.87+ .084d; Engbert et al, 2005).13.2 Language knowledgeFollowing Bicknell and Levy (2010), we use verysimple probabilistic models of language knowledge:word n-gram models (Jurafsky & Martin, 2009),which encode the probability of each word condi-tional on the n?1 previous words.3.3 Formal model of visual inputVisual input in the model consists of noisy informa-tion about the positions and identities of the charac-ters in the text.
Crucially, in this extended versionof the model, this includes noisy information aboutthe length of words.
We begin with a visual acuityfunction taken from Engbert et al (2005).
This func-tion decreases exponentially with retinal eccentric-ity ?
, and decreases asymmetrically, falling off moreslowly to the right than the left.2 The model obtainsvisual input from the 19 character positions with thehighest acuity ?
?
[?7,12], which we refer to asthe perceptual span.
In order to provide the modelwith information about the current fixation positionwithin the text, the model also obtains veridical in-1In the terminology of the literature, the model has only ran-dom motor error (variance), not systematic error (bias).
Follow-ing Engbert and Kr?gel (2010), systematic error may arise fromBayesian estimation of the best saccade distance.2While we refer to this function as visual acuity, it is clearfrom its asymmetric nature that it has an attentional component.formation about the number of word boundaries tothe left of the perceptual span.Visual information from the perceptual span con-sists of stochastic information about the number ofcharacters in the region and their identities.
We makethe simplifying assumption that the only charactersare letters and spaces.
Formally, visual input on agiven timestep is represented as a string of symbols,each element of which has two features.
One fea-ture denotes whether the symbol represents a space([+SPACE]) or a letter ([?SPACE]), an important dis-tinction because spaces indicate word boundaries.Symbols that are [+SPACE] veridically indicate theoccurrence of a space, while [?SPACE] symbols pro-vide noisy information about the letter?s identity.The other feature attached to each symbol speci-fies whether the character in the text that the symbolwas emitted from was being fixated ([+FIX]) or not([?FIX]).
The centrally fixated character has specialstatus so that the model can recover the eyes?
posi-tion within the visual span.This visual input string is generated by a pro-cess of moving a marker from the beginning to theend of the perceptual span, generally inserting asymbol into the visual input string for each char-acter it moves across (EMISSION).
To provide onlynoisy information about word length, however, thisprocess is not always one of EMISSION, but some-times it inserts a symbol into the visual input stringthat does not correspond to a character in the text(INSERTION), and at other times it fails to inserta symbol for a character in the text (SKIPPING).Specifically, at each step of the process, a deci-sion is first made about INSERTION, which occurswith probability ?
.
If INSERTION occurs, then a[?SPACE] identity for the character is chosen ac-cording to a uniform distribution, and then noisy vi-sual information about that character is generated inthe same way as for EMISSION (described below).If a character is not inserted, and the marker has al-ready moved past the last character in the perceptualspan, the process terminates.
Otherwise, a decisionis made about whether to emit a symbol into the vi-sual input string from the character at the marker?scurrent position (EMISSION) or whether to skip out-putting a symbol for that character (SKIPPING).
Ineither case, the marker is advanced to the next char-acter position.
If the character at the marker?s cur-241 2 32468102468100.050.12 4 6 8 10 2 4 6 8 10 2 4 6 8 10Inferred word length (chars)Actualword length (chars)probability0.20.40.60.8Figure 1: The expectation for the posterior distributionover the length of a word for actual lengths 1?10 after themodel has received 1, 2, or 3 timesteps of visual inputabout the word, for two levels of length uncertainty: ?
?
{.05, .1}.
These calculations use as a prior distributionthe empirical distribution of word length in the BNC andassume no information about letter identity.rent position is [+SPACE] or [+FIX], then EMISSIONis always chosen, but if it is any other character, thenSKIPPING occurs with probability ?
.A [?SPACE] symbol (produced through EMIS-SION or INSERTION) contains noisy informationabout the identity of the letter that generated it, ob-tained via sampling.
Specifically, we represent eachletter as a 26-dimensional vector, where a single el-ement is 1 and the others are zeros.
Given this rep-resentation, a [?SPACE] symbol contains a samplefrom a 26-dimensional Gaussian with a mean equalto the letter?s true identity and a diagonal covariancematrix ?(?)
= ?
(?
)?1I, where ?
(?)
is the visualacuity at eccentricity ?
.
We scale the overall process-ing rate by multiplying each rate by ?, set to 8 forthe simulations reported here.Allowing for INSERTION and SKIPPING meansthat visual input yields noisy information about thelength of words, and this noise is such that uncer-tainty is higher for longer words.
Figure 1 gives avisualization of this uncertainty.
It shows the expec-tation for the posterior distribution over the lengthof a word for a range of actual word lengths, afterthe model has received 1, 2, or 3 timesteps of visualinput about the word, at two levels of uncertainty.This figure demonstrates two things: first, that thereis substantial uncertainty about word length even af-ter three timesteps of visual input, and second, thatthis uncertainty is larger for longer words.
(a) m = [.6, .7, .6, .4, .3, .6]: Keep fixating (3)(b) m = [.6, .4, .9, .4, .3, .6]: Move back (to 2)(c) m = [.6, .7, .9, .4, .3, .6]: Move forward (to 6)(d) m = [.6, .7, .9, .8, .7, .7]: Stop readingFigure 2: Values of m for a 6 character text under whicha model fixating position 3 would take each of its fouractions, if ?
= .7 and ?
= .5.3.4 Inference about text identityThe model?s initial beliefs about the identity ofthe text are given by the probability of each pos-sible identity under the language model.
On eachtimestep, the model obtains a visual input string asdescribed above and calculates the likelihood of gen-erating that string from each possible identity of thetext.
The model then updates its beliefs about thetext via standard Bayesian inference: multiplying theprobability of each text identity under its prior be-liefs by the likelihood of generating the visual inputstring from that text identity and normalizing.
Wecompactly represent all of these distributions usingweighted finite-state transducers (Mohri, 1997) us-ing the OpenFST library (Allauzen, Riley, Schalk-wyk, Skut, & Mohri, 2007), and implement be-lief update with transducer composition and weightpushing.3.5 Behavior policyThe model uses a simple policy with two parame-ters, ?
and ?
, to decide between actions based onthe marginal probability m of the most likely char-acter c in each position j,m( j) = maxcp(w j = c)where w j indicates the character in the jth posi-tion.
A high value of m indicates relative confidenceabout the character?s identity, and a low value rel-ative uncertainty.
Because our extension has uncer-tainty about the absolute position of its eyes withinthe text, each position j is now defined relative to thecentrally fixated character.Figure 2 illustrates how the model decides amongfour possible actions.
If the value of m( j) for the cur-rent position of the eyes is less than the parameter?
, the model continues fixating the current position(2a).
Otherwise, if the value of m( j) is less than the25parameter ?
for some leftward position, the modelinitiates a saccade to the closest such position (2b).If no such positions exist to the left, the model initi-ates a saccade to n characters past the closest posi-tion to the right for which m( j) < ?
(2c).3 Finally,if no such positions exist, the model stops reading(2d).
Intuitively, then, the model reads by making arightward sweep to bring its confidence in each char-acter up to ?
, but pauses to move left to reread anycharacter whose confidence falls below ?
.4 Simulation 1: full modelWe now assess the effects of word length producedby the extended version of the model.
FollowingBicknell (2011), we use the model to simulate read-ing of a modified version of the Schilling, Rayner,and Chumbley (1998) corpus of typical sentencesused in reading experiments.
We compare three lev-els of length uncertainty: ?
?
{0, .05, .1}.
The firstof these (?
= 0) corresponds to Bicknell and Levy?s(2010) model, which has no uncertainty about wordlength.
We predict that increasing the amount oflength uncertainty will make effects of word lengthmore like those of humans, and we compare themodel?s length effects to those of human readers ofthe Schilling corpus.4.1 Methods4.1.1 Model parameters and language modelFollowing Bicknell (2011), the model?s languageknowledge was an unsmoothed bigram model usinga vocabulary set consisting of the 500 most frequentwords in the British National Corpus (BNC) as wellas all the words in the test corpus.
Every bigram inthe BNC was counted for which both words were invocabulary, and ?
due to the intense computation re-quired for exact inference ?
this set was trimmed byremoving rare bigrams that occur less than 200 times(except for bigrams that occur in the test corpus), re-sulting in a set of about 19,000 bigrams, from whichthe bigram model was constructed.4.1.2 Optimization of policy parametersWe set the parameters of the behavior policy(?,? )
to values that maximize reading efficiency.3The role of n is to ensure that the model does not centerits visual field on the first uncertain character.
For the presentsimulations, we did not optimize this parameter, but fixed n = 3.We define reading efficiency E to be an interpolationof speed and accuracy, E =(1??)L?
?T , where L isthe log probability of the true identity of the text un-der the model?s beliefs at the end of reading, T is thenumber of timesteps before the model stopped read-ing, and ?
gives the relative value of speed.
For thepresent simulations, we use ?
= .1, which producesreasonably accurate reading.
To find optimal valuesof the policy parameters ?
and ?
for each model, weuse the PEGASUS method (Ng & Jordan, 2000) totransform this stochastic optimization problem intoa deterministic one amenable to standard optimiza-tion algorithms, and then use coordinate ascent.4.1.3 Test corpusWe test the model on a corpus of 33 sentencesfrom the Schilling corpus slightly modified byBicknell and Levy (2010) so that every bigram oc-curred in the BNC, ensuring that the results do notdepend on smoothing.4.1.4 AnalysisWith each model, we performed 50 stochasticsimulations of the reading of the corpus.
For eachrun, we calculated the four standard eye movementmeasures mentioned above for each word in the cor-pus: first fixation duration, gaze duration, skippingprobability, and refixation probability.
We then av-eraged each of these four measures across runs foreach word token in the corpus, yielding a singlemean value for each measure for each word.Comparing the fixation duration measures to hu-mans required converting the model?s timesteps intomilliseconds.
We performed this scaling by multi-plying the duration of each fixation by a conversionfactor set to be equal to the mean human gaze du-ration divided by the mean model gaze duration forwords with frequencies higher than 1 in 100, mean-ing that the model predictions exactly match the hu-man mean for gaze durations on these words.4.2 ResultsFigure 3 presents the results for all four measuresof interest.
Looking first at the model with no un-certainty, we see that the results replicate those ofBicknell (2011): while there is a monotonic effectof word length on skip rates and refixation rates inthe same direction as humans, longer words receive261802002202402602803002 4 6 8 10Word length (chars)First fixation duration(ms)2002503003502 4 6 8 10Word length (chars)Gaze duration(ms)0.00.20.40.60.82 4 6 8 10Word length (chars)Skip rate0.00.10.20.30.42 4 6 8 10Word length (chars)RefixationrateFigure 3: Effects of word length in three version of thefull model with ?
= 0 (red), ?
= 0.05 (green), and ?
=0.1 (blue) on first fixation durations, gaze durations, skiprates, and refixation rates compared with the empiricalhuman data for this corpus (purple).
Estimates obtainedvia loess smoothing and plotted with standard errors.shorter fixations in the model, opposite to the patternfound in human data.
As predicted, adding lengthuncertainty begins to reverse this effect: as uncer-tainty is increased, the effect of word length on fixa-tion durations becomes less negative.However, while these results look more like thoseof humans, there are still substantial differences.
Forone, even for the model with the most uncertainty,the effect of word length ?
while not negative ?
isalso not really positive.
Second, the effect appearsrather non-monotonic.
We hypothesize that thesetwo problems are related to the aggressive trimmingwe performed of the model?s language model.
By re-moving low frequency words and bigrams, we artifi-cially trimmed especially the visual neighborhoodsof long words, since frequency and length are nega-tively correlated.
This could have led to another in-verse word length effect, which even adding morelength uncertainty was unable to fully overcome.
Ineffect, extending the visual neighborhoods of longwords (by adding length uncertainty) may not havemuch effect if we have removed all the words thatwould be in those extended neighborhoods.
In ad-dition, the aggressive trimming could have been re-sponsible for the non-monotonicities apparent in themodel?s predictions.
We performed another set ofsimulations using a language model with substan-tially less trimming to test these hypotheses.5 Simulation 2: model without contextIn this simulation, we used a unigram languagemodel instead of the bigram language model usedin Simulation 1.
Since this model cannot make useof linguistic context, it will not show as robust ef-fects of linguistic variables such as word predictabil-ity (Bicknell & Levy, 2012), but since here our fo-cus is on effects of word length, this limitation isunlikely to concern us.
Crucially, because of themodel?s simpler structure, it allows for the use ofa substantially larger vocabulary than the bigrammodel used in Simulation 1.
In addition, using thismodel avoids the problems mentioned above associ-ated with trimming bigrams.
We predicted that thislanguage model would allow us to obtain effects ofword length on fixation durations that were actu-ally positive (rather than merely non-negative), andthat there would be fewer non-monotonicities in thefunction.5.1 MethodsExcept the following, the methods were identicalto those of Simulation 1.
We replaced the bigramlanguage model with a unigram language model.Training was performed in the same manner, exceptthat instead of including only the most common 500words in the BNC, we included all words that occurat least 200 times (corresponding to a frequency of2 per million; about 19,000 words).
Because of thegreater computational complexity for the two mod-els with non-zero ?
, we performed only 20 simula-tions of the reading of the corpus instead of 50.5.2 ResultsFigure 4 presents the results for all four measuresof interest.
Looking at the model with no uncer-tainty, we see already that the predictions are a sub-stantially better fit to human data than was the fullmodel.
The skipping and refixation rates look sub-stantially more like the human curves.
And whilethe word length effect on first fixation duration isstill negative, it is already non-negative for gaze du-ration.
This supports our hypotheses that aggres-sive trimming were partly responsible for the fullmodel?s negative word length effect.271802002202402602803002 4 6 8 10Word length (chars)First fixation duration(ms)2002503003502 4 6 8 10Word length (chars)Gaze duration(ms)0.00.20.40.60.82 4 6 8 10Word length (chars)Skip rate0.00.10.20.30.42 4 6 8 10Word length (chars)RefixationrateFigure 4: Effects of word length in three version of themodel without context (unigram model) with ?
= 0 (red),?
= 0.05 (green), and ?
= 0.1 (blue) on first fixation dura-tions, gaze durations, skip rates, and refixation rates com-pared with the empirical human data for this corpus (pur-ple).
Estimates obtained via loess smoothing and plottedwith standard errors.Moving on to the models with uncertainty, we seethat predictions are still in good agreement with hu-mans for skip rates and refixation rates.
More in-terestingly, we see that adding length uncertaintymakes both durations measures relatively positivefunctions of word length.
While the overall size ofthe effect is incorrect for first fixation durations, wesee striking similarities between the models predic-tions and human data on both duration measures.For first fixations, the human pattern is that dura-tions go up from word lengths 1 to 2, down from 2to 3 (presumably because of ?the?
), and then up to 5,after which the function is relatively flat.
That pat-tern also holds for both models with uncertainty.
Forgaze duration, both models more or less reproducethe human pattern of a steadily-increasing functionthroughout the range, and again match the humanfunction in dipping for word length 3.
For gaze du-rations, even the overall size of the effect producedby the model is similar to that of humans.
Theseresults confirm our original hypothesis that addinglength uncertainty would lead to more humanlikeword length effects.
In addition, comparing the re-sults of Simulation 2 with Simulation 1 reveals theimportance to this account of words having realis-tic visual neighborhoods.
When the visual neighbor-hoods of (especially longer) words were trimmed tobe artificially sparse, adding length uncertainty didnot allow the model to recover the human pattern.6 ConclusionIn this paper, we argued that the success of majormodels of eye movements in reading to reproducethe (positive) human effect of word length via acuitylimitations may be a result of not including oppos-ing factors such as the negative correlation betweenvisual neighborhood size and word length.
We de-scribed the failure of the rational model presentedin Bicknell and Levy (2010) to obtain humanlike ef-fects of word length, despite including all of thesefactors, suggesting that our understanding of wordlength effects in reading is incomplete.
We proposeda new reason for word length effects ?
uncertaintyabout word length that is larger for longer words ?and noted that this reason was not implemented inBicknell and Levy?s model because of a simplifyingassumption.
We presented an extension of the modelrelaxing this assumption, in which readers obtainnoisy information about word length, and showedthrough two sets of simulations that the new modelproduces effects of word length that look more likethose of human readers.
Interestingly, while addinglength uncertainty made both models more human-like, it was only in Simulation 2 ?
in which wordshad more realistic visual neighborhoods ?
that allmeasures of the effect of word length on eye move-ments showed the human pattern, underscoring theimportance of the structure of the language for thisaccount of word length effects.We take these results as evidence that word lengtheffects cannot be completely explained through lim-itations on visual acuity.
Rather, they suggest that afull understanding of the reasons underlying wordlength effects on eye movements in reading shouldinclude a notion of uncertainty about the number ofletters in a word, which grows with word length.AcknowledgmentsThis research was supported by NIH grant T32-DC000041 from the Center for Research in Lan-guage at UC San Diego to K. B. and by NSF grant0953870 and NIH grant R01-HD065829 to R. L.28ReferencesAllauzen, C., Riley, M., Schalkwyk, J., Skut, W.,& Mohri, M. (2007).
OpenFst: A generaland efficient weighted finite-state transducerlibrary.
In Proceedings of the Ninth Inter-national Conference on Implementation andApplication of Automata, (CIAA 2007) (Vol.4783, p. 11-23).
Springer.Balota, D. A., Cortese, M. J., Sergent-Marshall,S.
D., Spieler, D. H., & Yap, M. J.
(2004).Visual word recognition of single-syllablewords.
Journal of Experimental Psychology:General, 133, 283?316.Bicknell, K. (2011).
Eye movements in read-ing as rational behavior.
Unpublished doc-toral dissertation, University of California,San Diego.Bicknell, K., & Levy, R. (2010).
A rational model ofeye movement control in reading.
In Proceed-ings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL)(pp.
1168?1178).
Uppsala, Sweden: Associa-tion for Computational Linguistics.Bicknell, K., & Levy, R. (2012).
Word predictabil-ity and frequency effects in a rational modelof reading.
In N. Miyake, D. Peebles, &R. P. Cooper (Eds.
), Proceedings of the 34thAnnual Conference of the Cognitive ScienceSociety.
Austin, TX: Cognitive Science Soci-ety.Bicknell, K., & Levy, R. (in press).
The utility ofmodelling word identification from visual in-put within models of eye movements in read-ing.
Visual Cognition.Dehaene, S. (1997).
The number sense: How themind creates mathematics.
New York: OxfordUniversity Press.Engbert, R., & Kr?gel, A.
(2010).
Readers useBayesian estimation for eye movement con-trol.
Psychological Science, 21, 366?371.Engbert, R., Longtin, A., & Kliegl, R. (2002).
A dy-namical model of saccade generation in read-ing based on spatially distributed lexical pro-cessing.
Vision Research, 42, 621?636.Engbert, R., Nuthmann, A., Richter, E. M., & Kliegl,R.
(2005).
SWIFT: A dynamical model ofsaccade generation during reading.
Psycho-logical Review, 112, 777?813.Gomez, P., Ratcliff, R., & Perea, M. (2008).
TheOverlap model: A model of letter positioncoding.
Psychological Review, 115, 577?601.Grainger, J., Granier, J.-P., Farioli, F., Van Assche,E., & van Heuven, W. J.
B.
(2006).
Letterposition information and printed word percep-tion: The relative-position priming constraint.Journal of Experimental Psychology: HumanPerception and Performance, 32, 865?884.Jurafsky, D., & Martin, J. H. (2009).
Speech and lan-guage processing: An introduction to naturallanguage processing, computational linguis-tics, and speech recognition (2nd ed.).
UpperSaddle River, NJ: Prentice Hall.Mohri, M. (1997).
Finite-state transducers in lan-guage and speech processing.
ComputationalLinguistics, 23, 269?311.Ng, A. Y., & Jordan, M. (2000).
PEGASUS:A policy search method for large MDPs andPOMDPs.
In Uncertainty in Artificial Intel-ligence, Proceedings of the Sixteenth Confer-ence (pp.
406?415).Norris, D., Kinoshita, S., & van Casteren, M. (2010).A stimulus sampling theory of letter identityand order.
Journal of Memory and Language,62, 254?271.Peressotti, F., & Grainger, J.
(1999).
The role of let-ter identity and letter position in orthographicpriming.
Perception & Psychophysics, 61,691?706.Pollatsek, A., Perea, M., & Binder, K. S. (1999).The effects of ?neighborhood size?
in readingand lexical decision.
Journal of Experimen-tal Psychology: Human Perception and Per-formance, 25, 1142?1158.Pollatsek, A., Reichle, E. D., & Rayner, K. (2006).Tests of the E-Z Reader model: Explor-ing the interface between cognition and eye-movement control.
Cognitive Psychology, 52,1?56.Reichle, E. D., Pollatsek, A., Fisher, D. L., &Rayner, K. (1998).
Toward a model of eyemovement control in reading.
PsychologicalReview, 105, 125?157.Reichle, E. D., Rayner, K., & Pollatsek, A.
(2003).The E-Z Reader model of eye-movement con-trol in reading: Comparisons to other models.29Behavioral and Brain Sciences, 26, 445?526.Schilling, H. E. H., Rayner, K., & Chumbley, J.
I.(1998).
Comparing naming, lexical decision,and eye fixation times: Word frequency effectsand individual differences.
Memory & Cogni-tion, 26, 1270?1281.Yarkoni, T., Balota, D. A., & Yap, M. J.
(2008).Moving beyond Coltheart?s N: A new mea-sure of orthographic similarity.
PsychonomicBulletin & Review, 15, 971?979.30
