Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 235?243,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPCo-Training for Cross-Lingual Sentiment ClassificationXiaojun WanInstitute of Compute Science and Technology & Key Laboratory of Computational Lin-guistics, MOEPeking University, Beijing 100871, Chinawanxiaojun@icst.pku.edu.cnAbstractThe lack of Chinese sentiment corpora limitsthe research progress on Chinese sentimentclassification.
However, there are many freelyavailable English sentiment corpora on theWeb.
This paper focuses on the problem ofcross-lingual sentiment classification, whichleverages an available English corpus for Chi-nese sentiment classification by using the Eng-lish corpus as training data.
Machine transla-tion services are used for eliminating the lan-guage gap between the training set and test set,and English features and Chinese features areconsidered as two independent views of theclassification problem.
We propose a co-training approach to making use of unlabeledChinese data.
Experimental results show theeffectiveness of the proposed approach, whichcan outperform the standard inductive classifi-ers and the transductive classifiers.1 IntroductionSentiment classification is the task of identifyingthe sentiment polarity of a given text.
The senti-ment polarity is usually positive or negative andthe text genre is usually product review.
In recentyears, sentiment classification has drawn muchattention in the NLP field and it has many usefulapplications, such as opinion mining and summa-rization (Liu et al, 2005; Ku et al, 2006; Titovand McDonald, 2008).To date, a variety of corpus-based methodshave been developed for sentiment classification.The methods usually rely heavily on an anno-tated corpus for training the sentiment classifier.The sentiment corpora are considered as the mostvaluable resources for the sentiment classifica-tion task.
However, such resources in differentlanguages are very imbalanced.
Because mostprevious work focuses on English sentimentclassification, many annotated corpora for Eng-lish sentiment classification are freely availableon the Web.
However, the annotated corpora forChinese sentiment classification are scarce and itis not a trivial task to manually label reliableChinese sentiment corpora.
The challenge beforeus is how to leverage rich English corpora forChinese sentiment classification.
In this study,we focus on the problem of cross-lingual senti-ment classification, which leverages only Englishtraining data for supervised sentiment classifica-tion of Chinese product reviews, without usingany Chinese resources.
Note that the above prob-lem is not only defined for Chinese sentimentclassification, but also for various sentimentanalysis tasks in other different languages.Though pilot studies have been performed tomake use of English corpora for subjectivityclassification in other languages (Mihalcea et al,2007; Banea et al, 2008), the methods are verystraightforward by directly employing an induc-tive classifier (e.g.
SVM, NB), and the classifica-tion performance is far from satisfactory becauseof the language gap between the original lan-guage and the translated language.In this study, we propose a co-training ap-proach to improving the classification accuracyof polarity identification of Chinese product re-views.
Unlabeled Chinese reviews can be fullyleveraged in the proposed approach.
First, ma-chine translation services are used to translateEnglish training reviews into Chinese reviewsand also translate Chinese test reviews and addi-tional unlabeled reviews into English reviews.Then, we can view the classification problem intwo independent views: Chinese view with onlyChinese features and English view with onlyEnglish features.
We then use the co-trainingapproach to making full use of the two redundantviews of features.
The SVM classifier is adoptedas the basic classifier in the proposed approach.Experimental results show that the proposed ap-proach can outperform the baseline inductiveclassifiers and the more advanced transductiveclassifiers.The rest of this paper is organized as follows:Section 2 introduces related work.
The proposed235co-training approach is described in detail inSection 3.
Section 4 shows the experimental re-sults.
Lastly we conclude this paper in Section 5.2 Related Work2.1 Sentiment ClassificationSentiment classification can be performed onwords, sentences or documents.
In this paper wefocus on document sentiment classification.
Themethods for document sentiment classificationcan be generally categorized into lexicon-basedand corpus-based.Lexicon-based methods usually involve deriv-ing a sentiment measure for text based on senti-ment lexicons.
Turney (2002) predicates the sen-timent orientation of a review by the average se-mantic orientation of the phrases in the reviewthat contain adjectives or adverbs, which is de-noted as the semantic oriented method.
Kim andHovy (2004) build three models to assign a sen-timent category to a given sentence by combin-ing the individual sentiments of sentiment-bearing words.
Hiroshi et al (2004) use the tech-nique of deep language analysis for machinetranslation to extract sentiment units in textdocuments.
Kennedy and Inkpen (2006) deter-mine the sentiment of a customer review bycounting positive and negative terms and takinginto account contextual valence shifters, such asnegations and intensifiers.
Devitt and Ahmad(2007) explore a computable metric of positiveor negative polarity in financial news text.Corpus-based methods usually consider thesentiment analysis task as a classification taskand they use a labeled corpus to train a sentimentclassifier.
Since the work of Pang et al (2002),various classification models and linguistic fea-tures have been proposed to improve the classifi-cation performance (Pang and Lee, 2004; Mullenand Collier, 2004; Wilson et al, 2005; Read,2005).
Most recently, McDonald et al (2007)investigate a structured model for jointly classi-fying the sentiment of text at varying levels ofgranularity.
Blitzer et al (2007) investigate do-main adaptation for sentiment classifiers, focus-ing on online reviews for different types of prod-ucts.
Andreevskaia and Bergler (2008) present anew system consisting of the ensemble of a cor-pus-based classifier and a lexicon-based classi-fier with precision-based vote weighting.Chinese sentiment analysis has also been stud-ied (Tsou et al, 2005; Ye et al, 2006; Li and Sun,2007) and most such work uses similar lexicon-based or corpus-based methods for Chinese sen-timent classification.To date, several pilot studies have been per-formed to leverage rich English resources forsentiment analysis in other languages.
StandardNa?ve Bayes and SVM classifiers have been ap-plied for subjectivity classification in Romanian(Mihalcea et al, 2007; Banea et al, 2008), andthe results show that automatic translation is aviable alternative for the construction of re-sources and tools for subjectivity analysis in anew target language.
Wan (2008) focuses on lev-eraging both Chinese and English lexicons toimprove Chinese sentiment analysis by usinglexicon-based methods.
In this study, we focuson improving the corpus-based method for cross-lingual sentiment classification of Chinese prod-uct reviews by developing novel approaches.2.2 Cross-Domain Text ClassificationCross-domain text classification can be consid-ered as a more general task than cross-lingualsentiment classification.
In the problem of cross-domain text classification, the labeled and unla-beled data come from different domains, andtheir underlying distributions are often differentfrom each other, which violates the basic as-sumption of traditional classification learning.To date, many semi-supervised learning algo-rithms have been developed for addressing thecross-domain text classification problem bytransferring knowledge across domains, includ-ing Transductive SVM (Joachims, 1999),EM(Nigam et al, 2000), EM-based Na?ve Bayesclassifier (Dai et al, 2007a), Topic-bridgedPLSA (Xue et al, 2008), Co-Clustering basedclassification (Dai et al, 2007b), two-stage ap-proach (Jiang and Zhai, 2007).
Daum?III andMarcu (2006) introduce a statistical formulationof this problem in terms of a simple mixturemodel.In particular, several previous studies focus onthe problem of cross-lingual text classification,which can be considered as a special case ofgeneral cross-domain text classification.
Bel et al(2003) present practical and cost-effective solu-tions.
A few novel models have been proposed toaddress the problem, e.g.
the EM-based algo-rithm (Rigutini et al, 2005), the information bot-tleneck approach (Ling et al, 2008), the multi-lingual domain models (Gliozzo and Strapparava,2005), etc.
To the best of our knowledge, co-training has not yet been investigated for cross-domain or cross-lingual text classification.2363 The Co-Training Approach3.1 OverviewThe purpose of our approach is to make use ofthe annotated English corpus for sentiment polar-ity identification of Chinese reviews in a super-vised framework, without using any Chinese re-sources.
Given the labeled English reviews andunlabeled Chinese reviews, two straightforwardmethods for addressing the problem are as fol-lows:1) We first learn a classifier based on the la-beled English reviews, and then translate Chi-nese reviews into English reviews.
Lastly, weuse the classifier to classify the translated Eng-lish reviews.2) We first translate the labeled English re-views into Chinese reviews, and then learn aclassifier based on the translated Chinese reviewswith labels.
Lastly, we use the classifier to clas-sify the unlabeled Chinese reviews.The above two methods have been used in(Banea et al, 2008) for Romanian subjectivityanalysis, but the experimental results are not verypromising.
As shown in our experiments, theabove two methods do not perform well for Chi-nese sentiment classification, either, because theunderlying distribution between the original lan-guage and the translated language are different.In order to address the above problem, wepropose to use the co-training approach to makeuse of some amounts of unlabeled Chinese re-views to improve the classification accuracy.
Theco-training approach can make full use of boththe English features and the Chinese features in aunified framework.
The framework of the pro-posed approach is illustrated in Figure 1.The framework consists of a training phaseand a classification phase.
In the training phase,the input is the labeled English reviews and someamounts of unlabeled Chinese reviews1.
The la-beled English reviews are translated into labeledChinese reviews, and the unlabeled Chinese re-views are translated into unlabeled English re-views, by using machine translation services.Therefore, each review is associated with anEnglish version and a Chinese version.
The Eng-lish features and the Chinese features for eachreview are considered two independent and re-dundant views of the review.
The co-trainingalgorithm is then applied to learn two classifiers1 The unlabeled Chinese reviews used for co-training do notinclude the unlabeled Chinese reviews for testing, i.e., theChinese reviews for testing are blind to the training phase.and finally the two classifiers are combined intoa single sentiment classifier.
In the classificationphase, each unlabeled Chinese review for testingis first translated into English review, and thenthe learned classifier is applied to classify thereview into either positive or negative.The steps of review translation and the co-training algorithm are described in details in thenext sections, respectively.Figure 1.
Framework of the proposed approach3.2 Review TranslationIn order to overcome the language gap, we musttranslate one language into another language.Fortunately, machine translation techniques havebeen well developed in the NLP field, though thetranslation performance is far from satisfactory.A few commercial machine translation servicescan be publicly accessed, e.g.
Google Translate2,Yahoo Babel Fish3 and Windows Live Translate4.2 http://translate.google.com/translate_t3 http://babelfish.yahoo.com/translate_txt4 http://www.windowslivetranslator.com/UnlabeledChineseReviewsLabeledEnglishReviewsMachineTranslation(CN-EN)Co-TrainingMachineTranslation(EN-CN)LabeledChineseReviewsUnlabeledEnglishReviewsPos\NegChinese View English ViewTestChineseReviewSentimentClassifierMachineTranslation(CN-EN)TestEnglishReviewTraining PhaseClassification Phase237In this study, we adopt Google Translate for bothEnglish-to-Chinese Translation and Chinese-to-English Translation, because it is one of thestate-of-the-art commercial machine translationsystems used today.
Google Translate appliesstatistical learning techniques to build a transla-tion model based on both monolingual text in thetarget language and aligned text consisting ofexamples of human translations between the lan-guages.3.3 The Co-Training AlgorithmThe co-training algorithm (Blum and Mitchell,1998) is a typical bootstrapping method, whichstarts with a set of labeled data, and increase theamount of annotated data using some amounts ofunlabeled data in an incremental way.
One im-portant aspect of co-training is that two condi-tional independent views are required for co-training to work, but the independence assump-tion can be relaxed.
Till now, co-training hasbeen successfully applied to statistical parsing(Sarkar, 2001), reference resolution (Ng andCardie, 2003), part of speech tagging (Clark etal., 2003), word sense disambiguation (Mihalcea,2004) and email classification (Kiritchenko andMatwin, 2001).In the context of cross-lingual sentiment clas-sification, each labeled English review or unla-beled Chinese review has two views of features:English features and Chinese features.
Here, areview is used to indicate both its Chinese ver-sion and its English version, until stated other-wise.
The co-training algorithm is illustrated inFigure 2.
In the algorithm, the class distributionin the labeled data is maintained by balancing theparameter values of p and n at each iteration.The intuition of the co-training algorithm isthat if one classifier can confidently predict theclass of an example, which is very similar tosome of labeled ones, it can provide one moretraining example for the other classifier.
But, ofcourse, if this example happens to be easy to beclassified by the first classifier, it does not meanthat this example will be easy to be classified bythe second classifier, so the second classifier willget useful information to improve itself and viceversa (Kiritchenko and Matwin, 2001).In the co-training algorithm, a basic classifica-tion algorithm is required to construct Cen andCcn.
Typical text classifiers include Support Vec-tor Machine (SVM), Na?ve Bayes (NB), Maxi-mum Entropy (ME), K-Nearest Neighbor (KNN),etc.
In this study, we adopt the widely-used SVMclassifier (Joachims, 2002).
Viewing input dataas two sets of vectors in a feature space, SVMconstructs a separating hyperplane in the spaceby maximizing the margin between the two datasets.
The English or Chinese features used in thisstudy include both unigrams and bigrams5 andthe feature weight is simply set to term fre-quency6.
Feature selection methods (e.g.
Docu-ment Frequency (DF), Information Gain (IG),and Mutual Information (MI)) can be used fordimension reduction.
But we use all the featuresin the experiments for comparative analysis, be-cause there is no significant performance im-provement after applying the feature selectiontechniques in our empirical study.
The outputvalue of the SVM classifier for a review indi-cates the confidence level of the review?s classi-fication.
Usually, the sentiment polarity of a re-view is indicated by the sign of the predictionvalue.Given:- Fen and Fcn are redundantly sufficientsets of features, where Fen representsthe English features, Fcn represents theChinese features;- L is a set of labeled training reviews;- U is a set of unlabeled reviews;Loop for I iterations:1.
Learn the first classifier Cen from Lbased on Fen;2.
Use Cen to label reviews from Ubased on Fen;3.
Choose p positive and n negative themost confidently predicted reviewsEen from U;4.
Learn the second classifier Ccn from Lbased on Fcn;5.
Use Ccn to label reviews from Ubased on Fcn;6.
Choose p positive and n negative themost confidently predicted reviewsEcn from U;7.
Removes reviews Een?Ecn from U7;8.
Add reviews Een?Ecn with the corre-sponding labels to L;Figure 2.
The co-training algorithmIn the training phase, the co-training algorithmlearns two separate classifiers: Cen and Ccn.5 For Chinese text, a unigram refers to a Chinese word and abigram refers to two adjacent Chinese words.6 Term frequency performs better than TFIDF by our em-pirical analysis.7 Note that the examples with conflicting labels are not in-cluded in Een?Ecn In other words, if an example is in bothEen and Ecn, but the labels for the example is conflicting, theexample will be excluded from Een?Ecn.238Therefore, in the classification phase, we canobtain two prediction values for a test review.We normalize the prediction values into [-1, 1]by dividing the maximum absolute value.
Finally,the average of the normalized values is used asthe overall prediction value of the review.4 Empirical Evaluation4.1 Evaluation Setup4.1.1 Data setThe following three datasets were collected andused in the experiments:Test Set (Labeled Chinese Reviews): In or-der to assess the performance of the proposedapproach, we collected and labeled 886 productreviews (451 positive reviews + 435 negativereviews) from a popular Chinese IT product website-IT1688.
The reviews focused on such prod-ucts as mp3 players, mobile phones, digital cam-era and laptop computers.Training Set (Labeled English Reviews):There are many labeled English corpora avail-able on the Web and we used the corpus con-structed for multi-domain sentiment classifica-tion (Blitzer et al, 2007)9, because the corpuswas large-scale and it was within similar do-mains as the test set.
The dataset consisted of8000 Amazon product reviews (4000 positivereviews + 4000 negative reviews) for four differ-ent product types: books, DVDs, electronics andkitchen appliances.Unlabeled Set (Unlabeled Chinese Reviews):We downloaded additional 1000 Chinese productreviews from IT168 and used the reviews as theunlabeled set.
Therefore, the unlabeled set andthe test set were in the same domain and hadsimilar underlying feature distributions.Each Chinese review was translated into Eng-lish review, and each English review was trans-lated into Chinese review.
Therefore, each re-view has two independent views: English viewand Chinese view.
A review is represented byboth its English view and its Chinese view.Note that the training set and the unlabeled setare used in the training phase, while the test set isblind to the training phase.4.1.2 Evaluation MetricWe used the standard precision, recall and F-measure to measure the performance of positiveand negative class, respectively, and used the8 http://www.it168.com9 http://www.cis.upenn.edu/~mdredze/datasets/sentiment/accuracy metric to measure the overall perform-ance of the system.
The metrics are defined thesame as in general text categorization.4.1.3 Baseline MethodsIn the experiments, the proposed co-training ap-proach (CoTrain) is compared with the followingbaseline methods:SVM(CN): This method applies the inductiveSVM with only Chinese features for sentimentclassification in the Chinese view.
Only English-to-Chinese translation is needed.
And the unla-beled set is not used.SVM(EN): This method applies the inductiveSVM with only English features for sentimentclassification in the English view.
Only Chinese-to-English translation is needed.
And the unla-beled set is not used.SVM(ENCN1): This method applies the in-ductive SVM with both English and Chinese fea-tures for sentiment classification in the twoviews.
Both English-to-Chinese and Chinese-to-English translations are required.
And the unla-beled set is not used.SVM(ENCN2): This method combines the re-sults of SVM(EN) and SVM(CN) by averagingthe prediction values in the same way with theco-training approach.TSVM(CN): This method applies the trans-ductive SVM with only Chinese features for sen-timent classification in the Chinese view.
OnlyEnglish-to-Chinese translation is needed.
Andthe unlabeled set is used.TSVM(EN): This method applies the trans-ductive SVM with only English features for sen-timent classification in the English view.
OnlyChinese-to-English translation is needed.
Andthe unlabeled set is used.TSVM(ENCN1): This method applies thetransductive SVM with both English and Chinesefeatures for sentiment classification in the twoviews.
Both English-to-Chinese and Chinese-to-English translations are required.
And the unla-beled set is used.TSVM(ENCN2): This method combines theresults of TSVM(EN) and TSVM(CN) by aver-aging the prediction values.Note that the first four methods are straight-forward methods used in previous work, whilethe latter four methods are strong baselines be-cause the transductive SVM has been widelyused for improving the classification accuracy byleveraging additional unlabeled examples.2394.2 Evaluation Results4.2.1 Method ComparisonIn the experiments, we first compare the pro-posed co-training approach (I=40 and p=n=5)with the eight baseline methods.
The three pa-rameters in the co-training approach are empiri-cally set by considering the total number (i.e.1000) of the unlabeled Chinese reviews.
In ourempirical study, the proposed approach can per-form well with a wide range of parameter values,which will be shown later.
Table 1 shows thecomparison results.Seen from the table, the proposed co-trainingapproach outperforms all eight baseline methodsover all metrics.
Among the eight baselines, thebest one is TSVM(ENCN2), which combines theresults of two transductive SVM classifiers.
Ac-tually, TSVM(ENCN2) is similar to CoTrainbecause CoTrain also combines the results oftwo classifiers in the same way.
However, theco-training approach can train two more effectiveclassifiers, and the accuracy values of the com-ponent English and Chinese classifiers are 0.775and 0.790, respectively, which are higher thanthe corresponding TSVM classifiers.
Overall, theuse of transductive learning and the combinationof English and Chinese views are beneficial tothe final classification accuracy, and the co-training approach is more suitable for makinguse of the unlabeled Chinese reviews than thetransductive SVM.4.2.2 Influences of Iteration Number (I)Figure 3 shows the accuracy curve of the co-training approach (Combined Classifier) withdifferent numbers of iterations.
The iterationnumber I is varied from 1 to 80.
When I is set to1, the co-training approach is degenerated intoSVM(ENCN2).
The accuracy curves of the com-ponent English and Chinese classifiers learned inthe co-training approach are also shown in thefigure.
We can see that the proposed co-trainingapproach can outperform the best baseline-TSVM(ENCN2) after 20 iterations.
After a largenumber of iterations, the performance of the co-training approach decreases because noisy train-ing examples may be selected from the remain-ing unlabeled set.
Finally, the performance of theapproach does not change any more, because thealgorithm runs out of all possible examples in theunlabeled set.
Fortunately, the proposed ap-proach performs well with a wide range of itera-tion numbers.
We can also see that the two com-ponent classifier has similar trends with the co-training approach.
It is encouraging that the com-ponent Chinese classifier alone can perform bet-ter than the best baseline when the iterationnumber is set between 40 and 70.4.2.3 Influences of Growth Size (p, n)Figure 4 shows how the growth size at each it-eration (p positive and n negative confident ex-amples) influences the accuracy of the proposedco-training approach.
In the above experiments,we set p=n, which is considered as a balancedgrowth.
When p differs very much from n, thegrowth is considered as an imbalanced growth.Balanced growth of (2, 2), (5, 5), (10, 10) and(15, 15) examples and imbalanced growth of (1,5), (5, 1) examples are compared in the figure.We can see that the performance of the co-training approach with the balanced growth canbe improved after a few iterations.
And the per-formance of the co-training approach with largep and n will more quickly become unchanged,because the approach runs out of the limited ex-amples in the unlabeled set more quickly.
How-ever, the performance of the co-training ap-proaches with the two imbalanced growths isalways going down quite rapidly, because thelabeled unbalanced examples hurt the perform-ance badly at each iteration.Positive Negative Total Method Precision Recall F-measure Precision Recall F-measure AccuracySVM(CN) 0.733 0.865 0.793 0.828 0.674 0.743 0.771SVM(EN) 0.717 0.803 0.757 0.766 0.671 0.716 0.738SVM(ENCN1) 0.744 0.820 0.781 0.792 0.708 0.748 0.765SVM(ENCN2) 0.746 0.847 0.793 0.816 0.701 0.754 0.775TSVM(CN) 0.724 0.878 0.794 0.838 0.653 0.734 0.767TSVM(EN) 0.732 0.860 0.791 0.823 0.674 0.741 0.769TSVM(ENCN1) 0.743 0.878 0.805 0.844 0.685 0.756 0.783TSVM(ENCN2) 0.744 0.896 0.813 0.863 0.680 0.761 0.790CoTrain(I=40; p=n=5) 0.768 0.905 0.831 0.879 0.717 0.790 0.813Table 1.
Comparison results2400.720.730.740.750.760.770.780.790.80.810.821 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80Iteration Number (I )AccuracyEnglish Classifier(CoTrain) Chinese Classifier(CoTrain)Combined Classifier(CoTrain) TSVM(ENCN2)Figure 3.
Accuracy vs. number of iterations for co-training (p=n=5)0.50.550.60.650.70.750.81 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80Iteration Number (I )Accuracy(p=2,n=2) (p=5,n=5) (p=10,n=10)(p=15,n=15) (p=1,n=5) (p=5,n=1)Figure 4.
Accuracy vs. different (p, n) for co-training0.760.770.780.790.80.810.8225% 50% 75% 100%Feature sizeAccuracyTSVM(ENCN1) TSVM(ENCN2) CoTrain (I=40; p=n=5)Figure 5.
Influences of feature size2414.2.4 Influences of Feature SelectionIn the above experiments, all features (unigram +bigram) are used.
As mentioned earlier, featureselection techniques are widely used for dimen-sion reduction.
In this section, we further con-duct experiments to investigate the influences offeature selection techniques on the classificationresults.
We use the simple but effective docu-ment frequency (DF) for feature selection.
Fig-ures 6 show the comparison results of differentfeature sizes for the co-training approach andtwo strong baselines.
The feature size is meas-ured as the proportion of the selected featuresagainst the total features (i.e.
100%).We can see from the figure that the feature se-lection technique has very slight influences onthe classification accuracy of the methods.
It canbe seen that the co-training approach can alwaysoutperform the two baselines with different fea-ture sizes.
The results further demonstrate theeffectiveness and robustness of the proposed co-training approach.5 Conclusion and Future WorkIn this paper, we propose to use the co-trainingapproach to address the problem of cross-lingualsentiment classification.
The experimental resultsshow the effectiveness of the proposed approach.In future work, we will improve the sentimentclassification accuracy in the following two ways:1) The smoothed co-training approach used in(Mihalcea, 2004) will be adopted for sentimentclassification.
The approach has the effect of?smoothing?
the learning curves.
During thebootstrapping process of smoothed co-training,the classifier at each iteration is replaced with amajority voting scheme applied to all classifiersconstructed at previous iterations.2) The feature distributions of the translatedtext and the natural text in the same language arestill different due to the inaccuracy of the ma-chine translation service.
We will employ thestructural correspondence learning (SCL) domainadaption algorithm used in (Blitzer et al, 2007)for linking the translated text and the natural text.AcknowledgmentsThis work was supported by NSFC (60873155),RFDP (20070001059), Beijing Nova Program(2008B03), National High-tech R&D Program(2008AA01Z421) and NCET (NCET-08-0006).We also thank the anonymous reviewers for theiruseful comments.ReferencesA.
Andreevskaia and S. Bergler.
2008.
When special-ists and generalists work together: overcomingdomain dependence in sentiment tagging.
In Pro-ceedings of ACL-08: HLT.C.
Banea, R. Mihalcea, J. Wiebe and S. Hassan.
2008.Multilingual subjectivity analysis using machinetranslation.
In Proceedings of EMNLP-2008.N.
Bel, C. H. A. Koster, and M. Villegas.
2003.Cross-lingual text categorization.
In Proceedings ofECDL-03.J.
Blitzer, M. Dredze and F. Pereira.
2007.
Biogra-phies, bollywood, boom-boxes and blenders: do-main adaptation for sentiment classification.
InProceedings of ACL-07.A.
Blum and T. Mitchell.
1998.
Combining labeledand unlabeled data with cotraining.
In Proceedingsof COLT-98.S.
Brody, R. Navigli and M. Lapata.
2006.
Ensemblemethods for unsupervised WSD.
In Proceedings ofCOLING-ACL-2006.S.
Clark, J. R. Curran, and M. Osborne.
2003.
Boot-strapping POS taggers using unlabelled data.
InProceedings of CoNLL-2003.W.
Dai, G.-R. Xue, Q. Yang, Y. Yu.
2007a.
Transfer-ring Na?ve Bayes Classifiers for text classification.In Proceedings of AAAI-07.W.
Dai, G.-R. Xue, Q. Yang, Y. Yu.
2007b.
Co-clustering based classification for out-of-domaindocuments.
In Proceedings of KDD-07.H.
Daum?III and D. Marcu.
2006.
Domain adaptationfor statistical classifiers.
Journal of Artificial Intel-ligence Research, 26:101?126.A.
Devitt and K. Ahmad.
2007.
Sentiment polarityidentification in financial news: a cohesion-basedapproach.
In Proceedings of ACL2007.T.
G. Dietterich.
1997.
Machine learning research:four current directions.
AI Magazine, 18(4), 1997.A.
Gliozzo and C. Strapparava.
2005.
Cross languagetext categorization by acquiring multilingual do-main models from comparable corpora.
In Pro-ceedings of the ACL Workshop on Building andUsing Parallel Texts.K.
Hiroshi, N. Tetsuya and W. Hideo.
2004.
Deepersentiment analysis using machine translation tech-nology.
In Proceedings of COLING-04.J.
Jiang and C. Zhai.
2007.
A two-stage approach todomain adaptation for statistical classifiers.
In Pro-ceedings of CIKM-07.T.
Joachims.
1999.
Transductive inference for textclassification using support vector machines.
InProceedings of ICML-99.242T.
Joachims.
2002.
Learning to classify text usingsupport vector machines.
Dissertation, Kluwer,2002.A.
Kennedy and D. Inkpen.
2006.
Sentiment classifi-cation of movie reviews using contextual valenceshifters.
Computational Intelligence, 22(2):110-125.S.-M. Kim and E. Hovy.
2004.
Determining the sen-timent of opinions.
In Proceedings of COLING-04.S.
Kiritchenko and S. Matwin.
2001.
Email classifica-tion with co-training.
In Proceedings of the 2001Conference of the Centre for Advanced Studies onCollaborative Research.L.-W. Ku, Y.-T. Liang and H.-H. Chen.
2006.
Opin-ion extraction, summarization and tracking in newsand blog corpora.
In Proceedings of AAAI-2006.J.
Li and M. Sun.
2007.
Experimental study on senti-ment classification of Chinese review using ma-chine learning techniques.
In Proceeding of IEEE-NLPKE-07.X.
Ling, W. Dai, Y. Jiang, G.-R. Xue, Q. Yang, and Y.Yu.
2008.
Can Chinese Web pages be classifiedwith English data source?
In Proceedings ofWWW-08.B.
Liu, M. Hu and J. Cheng.
2005.
Opinion observer:Analyzing and comparing opinions on the web.
InProceedings of WWW-2005.R.
McDonald, K. Hannan, T. Neylon, M. Wells and J.Reynar.
2007.
Structured models for fine-to-coarsesentiment analysis.
In Proceedings of ACL-07.R.
Mihalcea.
2004.
Co-training and self-training forword sense disambiguation.
In Proceedings ofCONLL-04.R.
Mihalcea, C. Banea and J. Wiebe.
2007.
Learningmultilingual subjective language via cross-lingualprojections.
In Proceedings of ACL-2007.T.
Mullen and N. Collier.
2004.
Sentiment analysisusing support vector machines with diverse infor-mation sources.
In Proceedings of EMNLP-04.V.
Ng and C. Cardie.
2003.
Weakly supervised natu-ral language learning without redundant views.
InProceedings of HLT-NAACL-03.K.
Nigam, A. K. McCallum, S. Thrun, and T.Mitchell.
2000.
Text Classification from Labeledand Unlabeled Documents using EM.
MachineLearning, 39(2-3):103?134.B.
Pang, L. Lee and S. Vaithyanathan.
2002.
Thumbsup?
sentiment classification using machine learn-ing techniques.
In Proceedings of EMNLP-02.B.
Pang and L. Lee.
2004.
A sentimental education:sentiment analysis using subjectivity summariza-tion based on minimum cuts.
In Proceedings ofACL-04.J.
Read.
2005.
Using emoticons to reduce dependencyin machine learning techniques for sentiment clas-sification.
In Proceedings of ACL-05.L.
Rigutini, M. Maggini and B. Liu.
2005.
An EMbased training algorithm for cross-language textcategorization.
In Proceedings of WI-05.A.
Sarkar.
2001.
Applying cotraining methods to sta-tistical parsing.
In Proceedings of NAACL-2001.I.
Titov and R. McDonald.
2008.
A joint model of textand aspect ratings for sentiment summarization.
InProceedings of ACL-08:HLT.B.
K. Y. Tsou, R. W. M. Yuen, O. Y. Kwong, T. B. Y.La and W. L. Wong.
2005.
Polarity classificationof celebrity coverage in the Chinese press.
In Pro-ceedings of International Conference on Intelli-gence Analysis.P.
Turney.
2002.
Thumbs up or thumbs down?
seman-tic orientation applied to unsupervised classifica-tion of reviews.
In Proceedings of ACL-2002.X.
Wan.
2008.
Using bilingual knowledge and en-semble techniques for unsupervised Chinese sen-timent analysis.
In Proceedings of EMNLP-2008.T.
Wilson, J. Wiebe and P. Hoffmann.
2005.
Recog-nizing Contextual Polarity in Phrase-Level Senti-ment Analysis.
In Proceedings of HLT/EMNLP-05.G.-R. Xue, W. Dai, Q. Yang, Y. Yu.
2008.
Topic-bridged PLSA for cross-domain text classification.In Proceedings of SIGIR-08.Q.
Ye, W. Shi and Y. Li.
2006.
Sentiment classifica-tion for movie reviews in Chinese by improvedsemantic oriented approach.
In Proceedings of 39thHawaii International Conference on System Sci-ences, 2006.243
