Dialog Navigator : A Spoken Dialog Q-A Systembased on Large Text Knowledge BaseYoji Kiyota, Sadao Kurohashi (The University of Tokyo)kiyota,kuro@kc.t.u-tokyo.ac.jpTeruhisa Misu, Kazunori Komatani, Tatsuya Kawahara (Kyoto University)misu,komatani,kawahara@kuis.kyoto-u.ac.jpFuyuko Kido (Microsoft Co., Ltd.)fkido@microsoft.comAbstractThis paper describes a spoken dialog Q-A system as a substitution for call centers.The system is capable of making dialogsfor both fixing speech recognition errorsand for clarifying vague questions, basedon only large text knowledge base.
We in-troduce two measures to make dialogs forfixing recognition errors.
An experimentalevaluation shows the advantages of thesemeasures.1 IntroductionWhen we use personal computers, we often en-counter troubles.
We usually consult large manu-als, experts, or call centers to solve such troubles.However, these solutions have problems: it is diffi-cult for beginners to retrieve a proper item in largemanuals; experts are not always near us; and callcenters are not always available.
Furthermore, op-eration cost of call centers is a big problem for en-terprises.
Therefore, we proposed a spoken dialogQ-A system which substitute for call centers, basedon only large text knowledge base.If we consult a call center, an operator will helpus through a dialog.
The substitutable system alsoneeds to make a dialog.
First, asking backs for fixingspeech recognition errors are needed.
Note that toomany asking backs make the dialog inefficient.
Sec-ondly, asking backs for clarifying users?
problemsare also needed, because they often do not knowtheir own problems so clearly.To realize such asking backs, we developed a sys-tem as shown in Figure 1.
The features of our systemare as follows: Precise text retrieval.The system precisely retrieves texts from largeconfirmation usingconfidence in recognitionconfirmation usingsignificance for retrievalautomatic speech recognizer(Julius)speech inputconfirmation forsignificant partsuser?s selectionN-best candidates(or reject all)user?s selectionN-best candidates of speech recognitionasking back(s)with dialog cardsdescription extractionchoices indialog cardsuser?s selectionfinal resultretrieval result textretrievalsystemusertextknowledgebasedialog for clarifyingvague questionsdialogcardsdialog for fixingspeech recognitionerrorsFigure 1: Architecture.text knowledge base provided by MicrosoftCorporation (Table 1), using question types,products, synonymous expressions, and syntac-tic information.
Dialog cards which can copewith very vague questions are also retrieved. Dialog for fixing speech recognition errors.When accepting speech input, recognition er-rors are inevitable.
However, it is not obvi-ous which portions of the utterance the sys-tem should confirm by asking back to the user.A great number of spoken dialog systems forparticular task domains, such as (Levin et al,2000), solved this problem by defining slots,but it is not applicable to large text knowledgebase.
Therefore, we introduce two measuresof confidence in recognition and significancefor retrieval to make dialogs for fixing speechrecognition errors. Dialog for clarifying vague questions.When a user asks a vague question such as?An error has occurred?, the system navigateshim/her to the desired answer, asking him/herback using both dialog cards and extraction ofTable 1: Text collections.# of # of matchingtext collection texts characters targetGlossary 4,707 700,000 entriesHelp texts 11,306 6,000,000 titlesSupport KB 23,323 22,000,000 entire textssummaries that makes differences between re-trieved texts more clear.Our system makes asking backs by showing themon a display, and users respond them by selectingthe displayed buttons by mouses.Initially, we developed the system as a keyboardbased Q-A system, and started its service in April2002 at the web site of Microsoft Corporation.
Theextension for speech input was done based on theone-year operation.
Our system uses Julius (Lee etal., 2001) as a Japanese speech recognizer, and ituses language model acquired from the text knowl-edge base of Microsoft Corporation.In this paper, we describe the above three featuresin Section 2, 3, and 4.
After that, we show experi-mental evaluation, and then conclude this paper.2 Precise Text RetrievalIt is critical for a Q-A system to retrieve relevanttexts for a question precisely.
In this section, wedescribe the score calculation method, giving largepoints to modifier-head relations between bunsetsu1based on the parse results of KNP (Kurohashi andNagao, 1994), to improve precision of text retrieval.Our system also uses question types, product names,and synonymous expression dictionary as describedin (Kiyota et al, 2002).First, scores of all sentences in each text are calcu-lated as shown in Figure 2.
Sentence score is the to-tal points of matching keywords and modifier-headrelations.
We give 1 point to a matching of a key-word, and 2 points to a matching of a modifier-headrelation (these parameters were set experimentally).Then sentence score is normalized by the maximummatching score (MMS) of both sentences as follows(the MMS is the sentence score with itself):sentence scorethe MMS of auser questionthe MMS of atext sentence1Bunsetsu is a commonly used linguistic unit in Japanese,consisting of one or more adjoining content words and zero ormore following functional words.Outlook?Outlook?tsukau?use?meru?mail?jushin?receive?Outlook wo tsukattemeru wo jushin dekinai.
?I cannot receive mails using Outlook.?Outlook?Outlook?
?mail?jushin?receive?error?error?Outlook de meru wo jushinsuru sai no error.
?An error while receiving mailsusing Outlook.
?+1+1+1MMS8 10user question text sentencemeru+2sentence score= 5  Figure 2: Score calculation.vagueconcreteError ga hassei shita.
?An error has occurred.
?Komatte imasu.
?I have a problem.
?Windows 98 de kidouji nierror ga hassei shita.
?An error has occurredwhile booting Windows 98.?text knowledge baseclarifying questionsusing dialog cardstext retrieval &description extractionuserquestionsFigure 3: User navigation.Finally, the sentence that has the largest score ineach text is selected as the representative sentence ofthe text.
Then, the score of the sentence is regardedas the score of the text.3 Dialog Strategy for Clarifying QuestionsIn most cases, users?
questions are vague.
To copewith such vagueness, our system uses the followingtwo methods: asking backs using dialog cards andextraction of summaries that makes difference be-tween retrieved texts more clear (Figure 3).3.1 Dialog cardsIf a question is very vague, it matches many texts,so users have to pay their labor on finding a rele-vant one.
Our system navigates users to the desiredanswer using dialog cards as shown in Figure 3.We made about three hundred of dialog cardsto throw questions back to users.
Figure 4 showstwo dialog cards.
UQ (User Question) is fol-lowed by a typical vague user question.
If a userquestion matches it, the dialog manager asks theback question after SYS, showing choices be-[Error]UQ Error ga hassei suru?An error occurs?SYSError wa itsu hassei shimasuka?
?When does the error occurs?
?SELECTWindows kidou ji goto [Error/Booting Windows]?while booting Windows?in?satsu ji goto [Error/Printing Out]?while printing out?application kidou ji goto [Error/Launching Applications]?while launching applications?/SELECT[Error/Booting Windows]UQ Windows wo kidou ji ni error ga hassei suru?An error occurs while booting Windows?SYSAnata ga otsukai no Windows wo erande kudasai.
?Choose your Windows.
?SELECTWindows 95 retrieve Windows 95 wo kidou ji ni error ga hassei suru?An error occurs while booting Windows 95?Windows 98 retrieve Windows 98 wo kidou ji ni error ga hassei suru?An error occurs while booting Windows 98?Windows ME retrieve Windows ME wo kidou ji ni error ga hassei suru?An error occurs while booting Windows ME?/SELECTFigure 4: Dialog cards.tween SELECT and /SELECT.
Every choice isfollowed by goto or retrieve.
goto means that thesystem follow the another dialog cards if this choiceis selected.
retrieve means that the system retrievetexts using the query specified there.3.2 Description extraction from retrieved textsIn most cases, the neighborhood of the part thatmatches the user question describes specific symp-toms and conditions of the problem users encounter.Our system extracts such descriptions from the re-trieved texts as the summaries of them.
The algo-rithm is described in (Kiyota et al, 2002).4 Dialog Strategy for Speech InputIt is necessary for a spoken dialog system to deter-mine which portions of the speech input should beconfirmed.
Moreover, criteria for judging whetherit should make confirmation or not are needed, be-cause too many confirmations make the dialog inef-ficient.
Therefore, we introduce two criteria of con-fidence in recognition and significance for retrieval.Our system makes two types of asking backs forfixing recognition errors (Figure 1).
First, Julius out-puts  -best candidates of speech recognition.
Then,the system makes confirmation for significant partsbased on confidence in recognition.
After that, thesystem retrieves relevant texts in the text knowledgebase using each candidate, and makes confirmationbased on significance for retrieval.4.1 Confidence in recognitionWe define the confidence in recognition for eachphrase in order to reject partial recognition errors.
Itis calculated based on word perplexity, which is of-ten used in order to evaluate suitability of languagemodels for test-set sentences.
We adopt word per-plexity because of the following reasons: incorrectlyrecognized parts are often unnatural in context, andwords that are unnatural in context have high per-plexity values.As Julius uses trigram as its language model, theword perplexity  is calculated as follows:     s are summed up in each bunsetsu (phrases).As a result, the system assigned the sum of  sto each bunsetsu as the criterion for confidence inrecognition.We preliminarily defined the set of product namesas significant phrases2.
If the sums of  s for anysignificant phrases are beyond the threshold (now,we set it 50), the system makes confirmation forthese phrases.4.2 Significance for retrievalThe system calculates significance for retrieval us-ing  -best candidates of speech recognition.
Be-cause slight speech recognition errors are not harm-ful for retrieval results, we regard a difference thataffects its retrieval result as significant.
Namely,when the difference between retrieval results foreach recognition candidate is large, we regard thatthe difference is significant.Significance for retrieval is defined as a rateof disagreement of five high-scored retrieved textsamong  recognition candidates.
For example, ifthere is a substituted part in two recognition candi-dates, and only one text is commonly retrieved outof five high-scored texts by both candidates, the sig-nificance for retrieval for the substituted part is 0.8(   ).The system makes confirmation which candidateshould be used, if significance for retrieval is beyondthe threshold (now, we set it 0.5).2We are now developing a method to define the set of sig-nificant phrases semi-automatically.Table 2: Number of successful retrieval for each speaker.speaker # of ASR transcription speech recognition with confidence with significance with bothID utterances corr.
(1) results (2) in recognition (3) for retrieval (4) measures (5)A 13 87.8% 10/13 8/13 8/13 10/13 10/13B 14 55.0% 6/14 3/14 5/14 3/14 5/14C 13 61.7% 5/13 5/13 5/13 5/13 5/13D 13 83.1% 11/13 9/13 9/13 9/13 9/13total 53 68.5% 32/53 25/53 27/53 27/53 29/53U: OS ?
ME ????????????????????????????????????????????????????????????????????????
?I am using (Windows) ME as OS(operating system), then ...?ASR: OS ?
IME ??????????????????????????????????????????????????????(?ME?
was incorrectly recognized as ?IME?.
)S: The underlined product name seems to be uncorrectly recognized.
May Iremove it, or leave it?U: (selected ?remove?
)S: The following texts are retrieved.1.
[AC97]?????????????
[???]
??????????2.
[??????]?
[???]??????????3.
[WinMe] TrueType???????????????
(a correct answer)U: Word 2002 ?
??
???????????????
?Please tell me the way to input formulas in Word 2002.?ASR: 1.
Word 2002 ?
??
(numbers) ???????????????2.
Word 2002 ?
??
(formulas) ???????????????3.
Word 2002 ?
??
(values) ??????????????
?S: Please select the most correct recognition result from the above candidates.U: (selected No.
2)S: The following texts are retrieved.1.
Word ????????
(a correct answer)2.
Word ??????????????3.
???????????????
?Figure 5: Dialogs for fixing speech recognition er-rors.
(U: user, S: system, ASR: automatic speech recognition)5 Experimental EvaluationWe evaluated the system performance experimen-tally.
For the experiments, we had 4 subjects, whowere accustomed to using computers.
They madeutterances by following given 10 scenarios and alsomade several utterances freely.
In total, 53 utter-ances were recorded.
Figure 5 shows two successfuldialogs by confirmation using confidence in recog-nition and by that using significance for retrieval.We experimented on the system using the 53recorded utterances by the following methods:(1) Using correct transcription of recorded utter-ance, including fillers.
(2) Using speech recognition results from whichonly fillers were removed.
(3) Using speech recognition results and makingconfirmation by confidence in recognition.
(4) Using  -best candidates of speech recognitionand making confirmation by significance for re-trieval.
Here,   .
(5) Using  -best candidates of speech recognitionand both measures in (3) and (4).In these experiments, we assumed that users al-ways correctly answer system?s asking backs.
Weregarded a retrieval as a successful one if a relevanttext was contained in ten high-scored retrieval texts.Table 2 shows the result.
It indicates that ourconfirmation methods for fixing speech recognitionerrors improve the success rate.
Furthermore, thesuccess rate with both measures gets close to thatwith the transcriptions.
Considering that the speechrecognition correctness is about 70%, the proposeddialog strategy is effective.6 ConclusionWe proposed a spoken dialog Q-A system in whichasking backs for fixing speech recognition errors andthose for clarifying vague questions are integrated.To realize dialog for fixing recognition errors basedon large text knowledge base, we introduced twomeasures of confidence in recognition and signif-icance for retrieval.
The experimental evaluationshows the advantages of these measures.ReferencesYoji Kiyota, Sadao Kurohashi, and Fuyuko Kido.
2002.?Dialog Navigator?
: A Question Answering Systembased on Large Text Knowledge Base.
In Proceedingsof COLING 2002, pages 460?466.Sadao Kurohashi and Makoto Nagao.
1994.
A syntacticanalysis method of long Japanese sentences based onthe detection of conjunctive structures.
ComputationalLinguistics, 20(4).A.
Lee, T. Kawahara, and K. Shikano.
2001.
Julius ?
anopen source real-time large vocabulary recognition en-gine.
In Proceedings of European Conf.
Speech Com-mun.
& Tech.
(EUROSPEECH), pages 1691?1694.E.
Levin, S. Narayanan, R. Pieraccini, K. Biatov,E.
Bocchieri, G. Di Fabbrizio, W. Eckert, S. Lee,A.
Pokrovsky, M. Rahim, P. Ruscitti, and M. Walker.2000.
The AT&T-DARPA communicator mixed-initiative spoken dialogue system.
In Proceedings ofInt?l Conf.
Spoken Language Processing (ICSLP).
