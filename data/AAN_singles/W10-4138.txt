Term Contributed Boundary Tagging by Conditional RandomFields for SIGHAN 2010 Chinese Word Segmentation BakeoffTian-Jian Jiang??
Shih-Hung Liu*?
Cheng-Lung Sung*?
Wen-Lian Hsu??
?Department ofComputer ScienceNational Tsing-Hua University*Department ofElectrical EngineeringNational Taiwan University?Institute ofInformation ScienceAcademia Sinica{tmjiang,journey,clsung,hsu}@iis.sinica.edu.twAbstractThis paper presents a Chinese wordsegmentation system submitted to theclosed training evaluations of CIPS-SIGHAN-2010 bakeoff.
The system usesa conditional random field model withone simple feature called term contri-buted boundaries (TCB) in addition tothe ?BI?
character-based tagging ap-proach.
TCB can be extracted from unla-beled corpora automatically, and seg-mentation variations of different do-mains are expected to be reflected impli-citly.
The experiment result shows thatTCB does improve ?BI?
tagging domain-independently about 1% of the F1 meas-ure score.1 IntroductionThe CIPS-SIGHAN-2010 bakeoff task of Chi-nese word segmentation is focused on cross-domain texts.
The design of data set is challeng-ing particularly.
The domain-specific trainingcorpora remain unlabeled, and two of the testcorpora keep domains unknown before releasing,therefore it is not easy to apply ordinary machinelearning approaches, especially for the closedtraining evaluations.2 Methodology2.1 The ?BI?
Character-Based Tagging ofConditional Random Field as BaselineThe character-based ?OBI?
tagging ofConditional Random Field (Lafferty et al, 2001)has been widely used in Chinese wordsegmentation recently (Xue and Shen, 2003;Peng and McCallum, 2004; Tseng et al, 2005).Under the scheme, each character of a word islabeled as ?B?
if it is the first character of amultiple-character word, or ?I?
otherwise.
If thecharacter is a single-character word itself, ?O?will be its label.
As Table 1 shows, the lost ofperformance is about 1% by replacing ?O?
with?B?
for character-based CRF tagging on thedataset of CIPS-SIGHAN-2010 bakeoff task ofChinese word segmentation, thus we choose?BI?
as our baseline for simplicity, with this 1%lost bearing in mind.
In tables of this paper, SCstands for Simplified Chinese and TC representsfor Traditional Chinese.
Test corpora of SC andTC are divided into four domains, where suffixA, B, C and D attached, for texts of literature,computer, medicine and finance, respectively.R P F OOVSC-A OBI 0.906 0.916 0.911 0.539BI 0.896 0.907 0.901 0.508SC-B OBI 0.868 0.797 0.831 0.410BI 0.850 0.763 0.805 0.327SC-C OBI 0.897 0.897 0.897 0.590BI 0.888 0.886 0.887 0.551SC-D OBI 0.900 0.903 0.901 0.472BI 0.888 0.891 0.890 0.419TC-A OBI 0.873 0.898 0.886 0.727BI 0.856 0.884 0.870 0.674TC-B OBI 0.906 0.932 0.919 0.578BI 0.894 0.920 0.907 0.551TC-C OBI 0.902 0.923 0.913 0.722BI 0.891 0.914 0.902 0.674TC-D OBI 0.924 0.934 0.929 0.765BI 0.908 0.922 0.915 0.722Table 1.
OBI vs. BI; where the lost of F > 1%,such as SC-B, is caused by incorrect Englishsegments that will be discussed in the section 4.2.2 Term Contributed BoundaryThe word boundary and the word frequency arethe standard notions of frequency in corpus-based natural language processing, but they lackthe correct information about the actual boun-dary and frequency of a phrase?s occurrence.The distortion of phrase boundaries and frequen-cies was first observed in the Vodis Corpuswhen the bigram ?RAIL ENQUIRIES?
and tri-gram ?BRITISH RAIL ENQUIRIES?
were ex-amined and reported by O'Boyle (1993).
Both ofthem occur 73 times, which is a large number forsuch a small corpus.
?ENQUIRIES?
follows?RAIL?
with a very high probability when it ispreceded by ?BRITISH.?
However, when?RAIL?
is preceded by words other than ?BRIT-ISH,?
?ENQUIRIES?
does not occur, but wordslike ?TICKET?
or ?JOURNEY?
may.
Thus, thebigram ?RAIL ENQUIRIES?
gives a misleadingprobability that ?RAIL?
is followed by ?EN-QUIRIES?
irrespective of what precedes it.
Thisproblem happens not only with word-token cor-pora but also with corpora in which all the com-pounds are tagged as units since overlapping N-grams still appear, therefore corresponding solu-tions such as those of Zhang et al (2006) wereproposed.We uses suffix array algorithm to calculate ex-act boundaries of phrase and their frequencies(Sung et al, 2008), called term contributedboundaries (TCB) and term contributed fre-quencies (TCF), respectively, to analogize simi-larities and differences with the term frequencies(TF).
For example, in Vodis Corpus, the originalTF of the term ?RAIL ENQUIRIES?
is 73.However, the actual TCF of ?RAIL ENQUI-RIES?
is 0, since all of the frequency values arecontributed by the term ?BRITISH RAIL ENQUIRIES?.
In this case, we can see that ?BRIT-ISH RAIL ENQUIRIES?
is really a more fre-quent term in the corpus, where ?RAIL EN-QUIRIES?
is not.
Hence the TCB of ?BRITISHRAIL ENQUIRIES?
is ready for CRF tagging as?BRITISH/TB RAIL/TB ENQUIRIES/TI,?
forexample.3 ExperimentsBesides submitted results, there are severaldifferent experiments that we have done.
Theconfiguration is about the trade-off between datasparseness and domain fitness.
For the sake ofOOV issue, TCBs from all the training and testcorpora are included in the configuration ofsubmitted results.
For potentially better consis-tency to different types of text, TCBs from thetraining corpora and/or test corpora are groupedby corresponding domains of test corpora.
Table2 and Table 3 provide the details, where thebaseline is the character-based ?BI?
tagging, andothers are ?BI?
with additional different TCBconfigurations: TCBall stands for the submittedresults; TCBa, TCBb, TCBta, TCBtb, TCBtc,TCBtd represents TCB extracted from the train-ing corpus A, B, and the test corpus A, B, C, D,respectively.
Table 2 indicates that F1 measurescores can be improved by TCB about 1%, do-main-independently.
Table 3 gives a hint of themajor contribution of performance is from TCBof each test corpus.Table 2.
Baseline vs.
Submitted ResultsR P F OOVSC-A BI 0.896 0.907 0.901 0.508TCBall 0.917 0.921 0.919 0.699SC-B BI 0.850 0.763 0.805 0.327TCBall 0.876 0.799 0.836 0.456SC-C BI 0.888 0.886 0.887 0.551TCBall 0.900 0.896 0.898 0.699SC-D BI 0.888 0.891 0.890 0.419TCBall 0.910 0.906 0.908 0.562TC-A BI 0.856 0.884 0.870 0.674TCBall 0.871 0.891 0.881 0.670TC-B BI 0.894 0.920 0.907 0.551TCBall 0.913 0.917 0.915 0.663TC-C BI 0.891 0.914 0.902 0.674TCBall 0.900 0.915 0.908 0.668TC-D BI 0.908 0.922 0.915 0.722TCBall 0.929 0.922 0.925 0.732F OOVSC-A TCBta 0.918 0.690TCBa 0.917 0.679TCBta + TCBa 0.917 0.690TCBall 0.919 0.699SC-B TCBtb 0.832 0.465TCBb 0.828 0.453TCBtb + TCBb 0.830 0.459TCBall 0.836 0.456SC-C TCBtc 0.897 0.618TCBall 0.898 0.699SC-D  TCBtd 0.905 0.557TCBall 0.910 0.562Table 3a.
Simplified Chinese Domain-specificTCB vs. TCBallF OOVTC-A TCBta 0.889 0.706TCBa 0.888 0.690TCBta + TCBa 0.889 0.710TCBall 0.881 0.670TC-B TCBtb 0.911 0.636TCBb 0.921 0.696TCBtb + TCBb 0.912 0.641TCBall 0.915 0.663TC-C TCBtc 0.918 0.705TCBall 0.908 0.668TC-D TCBtd 0.927 0.717TCBall 0.925 0.732Table 3b.
Traditional Chinese Domain-specificTCB vs. TCBall4 Error AnalysisThe most significant type of error in our resultsis unintentionally segmented English words.
Ra-ther than developing another set of tag for Eng-lish alphabets, we applies post-processing to fixthis problem under the restriction of closed train-ing by using only alphanumeric character infor-mation.
Table 4 compares F1 measure score ofthe Simplified Chinese experiment results beforeand after the post-processing.F1 measure scorebefore afterSC-A OBI 0.911 0.918BI 0.901 0.908TCBta 0.918 0.920TCBta + TCBa 0.917 0.920TCBall 0.919 0.921SC-B OBI 0.831 0.920BI 0.805 0.910TCBtb 0.832 0.917TCBtb + TCBb 0.830 0.916TCBall 0.836 0.916SC-C OBI 0.897 0.904BI 0.887 0.896TCBtc 0.897 0.901TCBall 0.898 0.902SC-D OBI 0.901 0.919BI 0.890 0.908TCBtd 0.905 0.915TCBall 0.908 0.918Table 4.
F1 measure scores before and afterEnglish Problem FixedThe major difference between gold standardsof the Simplified Chinese corpora and the Tradi-tional Chinese corpora is about non-Chinesecharacters.
All of the alphanumeric and thepunctuation sequences are separated from Chi-nese sequences in the Simplified Chinese corpo-ra, but can be part of the Chinese word segmentsin the Traditional Chinese corpora.
For example,a phrase ???
/ simvastatin / ?
/ statins?
/ ?
/ ?
/?
/ ??
(?/?
represents the word boundary) fromthe domain C of the test data cannot be eitherrecognized by ?BI?
and/or TCB tagging ap-proaches, or post-processed.
This is the reasonwhy Table 4 does not come along with Tradi-tional Chinese experiment results.Some errors are due to inconsistencies in thegold standard of non-Chinese character, For ex-ample, in the Traditional Chinese corpora, somepercentage digits are separated from their per-centage signs, meanwhile those percentage signsare connected to parentheses right next to them.5 ConclusionThis paper introduces a simple CRF featurecalled term contributed boundaries (TCB) forChinese word segmentation.
The experimentresult shows that it can improve the basic ?BI?tagging scheme about 1% of the F1 measurescore, domain-independently.Further tagging scheme for non-Chinese cha-racters are desired for recognizing some sophis-ticated gold standard of Chinese word segmenta-tion that concatenates alphanumeric charactersto Chinese characters.AcknowledgementThe CRF model used in this paper is developed basedon CRF++, http://crfpp.sourceforge.net/Term Contributed Boundaries used in this paper areextracted by YASA, http://yasa.newzilla.org/ReferencesJohn Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: proba-bilistic models for segmenting and labeling se-quence data.
In Proceedings of International Con-ference of Machine Learning, 591?598.Peter O'Boyle.
1993.
A Study of an N-Gram Lan-guage Model for Speech Recognition.
PhD thesis.Queen's University Belfast.Fuchun Peng and Andrew McCallum.
2004.
Chinesesegmentation and new word detection using condi-tional random fields.
In Proceedings of Interna-tional Conference of Computational linguistics,562?568, Geneva, Switzerland.Cheng-Lung Sung, Hsu-Chun Yen, and Wen-LianHsu.
2008.
Compute the Term Contributed Fre-quency.
In Proceedings of the 2008 Eighth Inter-national Conference on Intelligent Systems Designand Applications, 325-328, Washington, D.C.,USA.Huihsin Tseng, Pichuan Chang, Galen Andrew, Da-niel Jurafsky, and Christopher Manning.
2005.
Aconditional random field word segmenter for Sig-han bakeoff 2005.
In Proceedings of the FourthSIGHAN Workshop on Chinese LanguageProcessing, Jeju, Korea.Nianwen Xue and Libin Shen.
2003.
Chinese word-segmentation as LMR tagging.
In Proceedings ofthe Second SIGHAN Workshop on Chinese Lan-guage Processing.Ruiqiang Zhang, Genichiro Kikui, and Eiichiro Sumi-ta.
2006.
Subword-based tagging by conditionalrandom fields for Chinese word segmentation.
InProceedings of the Human Language TechnologyConference of the North American Chapter of theAssociation for Computational Linguistics, 193-196, New York, USA.
