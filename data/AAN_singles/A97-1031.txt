An Information Extraction Core System forReal World German Text ProcessingGf in ter  Neumann*  Ro l f  Backofen  t Jud i th  Baur  t Markus  Becker~ Chr i s t ian  Braun  ~Abst rac tThis paper describes SMES, an informa-tion extraction core system for real worldGerman text processing.
The basic designcriterion of the system is of providing a setof basic powerful, robust, and efficient nat-ural language components and generic lin-guistic knowledge sources which can easilybe customized for processing different asksin a flexible manner.1 I n t roduct ionThere is no doubt that the amount of textual infor-mation electronically available today has passed itscritical mass leading to the emerging problem thatthe more electronic text data is available the moredifficult it is to find or extract relevant information.In order to overcome this problem new technologiesfor future information management systems are ex-plored by various researchers.
One new line of suchresearch is the investigation and development of in-formation extraction (IE) systems.
The goal of IEis to build systems that find and link relevant infor-mation from text data while ignoring extraneous andirrelevant information (Cowie and Lehnert, 1996).Current IE systems are to be quite successfully inautomatically processing large text collections withhigh speed and robustness (see (Sundheim, 1995),(Chinchor et al, 1993), and (Grishman and Sund-heim, 1996)).
This is due to the fact that they canprovide a partial understanding of specific types oftext with a certain degree of partial accuracy usingfast and robust shallow processing strategies (basi-cally finite state technology).
They have been "madesensitive" to certain key pieces of information and*DFKI GmbH, Stuhlsatzenhausweg 3, 66123Saarbriicken, Germany, neumannOdfki, uni-sb, de~LMU, Oettingenstrasse 67, 80538 Miinchen, Ger-many, backofen@informatik, uni-muenchen, de*DFKI GmbH, baur@dfki, uni-sb, de~DFKI GmbH, mbecker0dfki, uni-sb, de~DFKI GmbH, cbraun@dfki, uni-sb, dethereby provide an easy means to skip text withoutdeep analysis.The majority of existing information systems areapplied to English text.
A major drawback of previ-ous systems was their restrictive degree of portabil-ity towards new domains and tasks which was alsocaused by a restricted degree of re-usability of theknowledge sources.
Consequently, the major goalswhich were identified during the sixth message un-derstanding conference (MUC-6) were.
on the onehand, to demonstrate task-independent componenttechnologies of information extraction, and, on theother hand, to encourage work on increasing porta-bility and "deeper understanding" (of.
(Grishmanand Sundheim, 1996)).In this paper we report on SMES an informationextraction core system for real world German textprocessing.
The main research topics we are con-cerned with include easy portability and adaptabil-ity of the core system to extraction tasks of differ-ent complexity and domains.
In this paper we willconcentrate on the technical and implementationalaspects of the IE core technology used for achievingthe desired portability.
We will only briefly describesome of the current applications built on top of thiscore machinery (see section 7).2 The  overa l l  a rch i tec ture  of  SMESThe basic design criterion of the SMES system is topr(r,-:de a set of basic powerful, robust, and efficientnatural language components and generic linguisticknowledge sources which can easily be customizedfor processing different tasks in a flexible manner.Hence, we view SMES as a core information extrac-tion system.
Customization is achieved in tile fol-lowing directions:?
defining the flow of control between modules(e.g., cascaded and/or interleaved)?
selection of the linguistic knowledge sources?
specifying domain specific knowledge?
defining task-specific additional functionality209ASCII  TextTokenizerMorph./Lex.ProcessingFragmentProcessingFragment comb.Template gen.Netscape_~ BrowserHTMLInterfac~Marked-up TextTemplatesFigure 1: A blueprint of the core systemFigure 1 shows a blueprint of the core system(which roughly follows the design criteria of thegeneric information extraction system described in(Hobbs, 1992)) .
The main components are:A tokenizer based on regular expressions: it scansan ASCII text file for recognizing text structure, spe-cial tokens like date and time expressions, abbrevi-ations and words.A very efficient and robust German morphologicalcomponent which performs morphological infectionand compound processing.
For each analyzed wordit returns a (set of) triple containing the stem (ora list of stems in case of a compound), the part ofspeech, and inflectional information.
Disambigua-tion of the morphological output is performed by aset of word-case sensitive rules, and a Brill-basedunsupervised tagger.A declarative specification tool for expressing fi-nite state grammars for handling word groups andphrasal entities (e.g., general NPs, PPs, or verbgroups, complex time and date expressions, propername expressions).
A finite state grammar con-sists of a set of fragment extraction patterns definedas finite state transducers (FST), where modular-ity is achieved through a generic input/output de-vice.
FST are compiled to Lisp functions using anextended version of the compiler defined in (Krieger,1987).A bidirectional lexical-driven shallow parser forthe combination of extracted fragments.
Shal-low parsing is basically directed through frag-ment combination patterns FCP of the form(FSTtelt, anchor, FSTright), where anchor is a lex-ical entry (e.g., a verb like "to meet") or a nameof a class of lexical entries (e.g., "transitive-verb").FCPs are attached to lexical entries (e.g., verbs), andare selected right after a corresponding lexical entryhas been identified.
They are applied to their leftand right stream of tokens of recognized fragments.The fragment combiner is used for recognizing andextracting clause level expressions, as well as for theinstantiation of templates.An interface to TDL, a type description languagefor constraint-based grammars (Krieger and Sch~fer,1994).
TDL is used in SMES for performing type-driven lexical retrieval, e.g., for concept-driven fil-tering, and for the evaluation of syntactic agreementtests during fragment processing and combination.The knowledge base is the collection of differ-ent knowledge sources, viz.
lexicon, subgram-mars, clause-level expressions, and template pat-terns.
Currently it includes 120.000 lexical root en-tries, subgra.mmars for simple and complex date andtime expressions, person names, company names,currency expressions, as well as shallow grammarsfor general nominal phrases, prepositional phrases,and general verb-modifier expressions.Additionally to the above mentioned componentsthere also exists a generic graphical editor for textitems and an HTML interface to the Netscapebrowser which performs marking of the relevant extparts by providing typed parentheses which alsoserve as links to the internal representation of theextracted information.There are two important properties of the systemfor supporting portability:?
Each component outputs the resulting struc-tures uniformly as feature value structures, to-gether with its type and the corresponding startand end positions of the spanned input expres-sions.
We call these output structures textitems.?
All (un-filtered) resulting structures of eachcomponent are cached so that a component cantake into account results of all previous compo-nents.
This allows for the definition of cascadedas well as interleaved flow of control.
The for-mer case means that it is possible to apply acascade of finite state expressions (comparableto that proposed in (Appelt et al, 1993))~ andthe latter supports the definition of finite stateexpressions which incrementally perform a mixof keyword spotting, fragment processing: andtemplate instantiation.
I1Of course, it is also possible---and usually the casein our current applications--to combine both sorts of210The system has already successfully been ap-plied to classifying event announcements made viaemail, scheduling of meetings also sent via email,and extraction of company information from on-linenewswires (see 7 for more details).
In the next sec-tion, we are describing some of the components'properties in more detail.3 Word  leve l  p rocess ingText  scanning Each file is firstly preprocessed bythe text scanner.
Applying regular expressions (thetext scanner is implemented in lex, the well-knownUnix tool), the text scanner identifies some textstructure (e.g., paragraphs, indentations), word,number, date and time tokens (e.g, "1.3.96", "12:00h"), and expands abbreviations.
The output of thetext scanner is a stream of tokens, where each wordis simply represented as a string of alphabetic har-acters (including delimiters, e.g.
"Daimler-Benz").Number, date and time expressions are normalizedand represented as attribute values structures.
Forexample the character stream "1.3.96" is representedas (:date ((:day l)(:mon 3)(:year 96)), and "13:15 h"as (:time ((:hour 13)(:min 15))).Morpho log ica l  process ing follows text scanningand performs inflection, and processing of com-pounds.
The capability of efficiently processing com-pounds is crucial since compounding is a very pro-ductive process of the German language.The morphological component called MONA is adescendant of MORPHIX, a fast classification-basedmorphology component for German (Finkler andNeumann, 1988).
MONA improves MORPHIX in thatthe classification-based approach as been combinedwith the well-known two-level approach, originallydeveloped by (Koskenniemi, 1983).
Actually, theextensions concern?
the use of tries (see (Aho et al, 1983)) as thesole storage device for all sorts of lexical infor-mation in MONA (e.g., for lexical entries, prefix,inflectional endings) , and?
the analysis of compound expressions which isrealized by means of a recursive trie traversal.During traversal two-level rules are applied forrecognizing linguistically well-formed ecompo-sitions of the word form in question.The output of MONA is the word form togetherwith all its readings.
A reading is a triple of the form(stem, inf lection,pos),  where stem is a string or alist of strings (in the case of compounds), inf lect ionis the inflectional information, and pos is the part ofspeech.Currently, MONA is used for the German and Ital-ian language.
The German version has a very broadcontrol flow.coverage (a lexicon of more then 120.000 stem en-tries), and an excellent speed (5000 words/sec with-out compound handling, 2800 words/sec with com-pound processing (where for each compound all lex-ically possible decompositions are computed).
2Par t -o f - speech  d isambiguat ion  Morphologicalambiguous readings are disambiguated wrt.
part-of-speech using case-sensitive rules 3 and filteringrules which have been determined using Brill's un-supervised tagger (Brill, 1995).
The filtering rulesare also used for tagging unknown words.The filtering rules are determined on the basisof unannotated corpora.
Starting from untaggedcorpora ,  MONA is used for initial tagging, whereunknown words are ambiguously tagged as noun,verb, and adjective.
Then, using contextual informa-tion from unambiguously analysed word forms, filterrules are determined which are of the form changetag of word form from noun or verb to noun if theprevious word is a determiner.First experiments using a training set of 100.000words and a set of about 280 learned filter rulesyields a tagging accuracy (including tagging of un-known words) of 91.4%.
4Note that the un-supervised tagger requiredno hand-tagged corpora and considered unknownwords.
We expect to increase the accuracy by im-proving the un-supervised tagger through the useof more linguistic information determined by MONAespecially for the case of unknowns words.4 F ragment  process ingWord group recognition and extraction is performedthrough fragment extraction patterns which are ex-pressed as finite state transducers (FST) and whichare compiled to Lisp functions using a compilerbased on (Krieger, 1987).
An FST consists of aunique name, the recognition part, the output de-scription, and a set of compiler parameters.The  recogn i t ion  par t  An FST operates on astream of tokens.
The recognition part of an FST isused for describing regular patterns over such token2Measurement has been performed on a Sun 20 usingan on-line lexicon of 120.000 entries.3Generally, only nouns (and proper names) axe writ-ten in standard German with an capitalized initial letter(e.g., "der Wagen" the car vs. "wit wagen" we venture).Since typing errors are relatively rare in press releases(or similar documents) the application of case-sensitiverules are a reliable and straightforward tagging meansfor the German language.4Brill reports a 96% accuracy using a training set of350.000 words and 1729 rules.
However, he does nothandle unknown words.
In (Aone and Hausman, 1996),an extended version of Brill's tagger is used for taggingSpanish texts, which includes unknown words.
They re-port an accuracy of 92.1%.211streams.
For supporting modularity the differentpossible kind of tokens are handled via basic edges,where a basic edge can be viewed as a predicate for aspecific class of tokens.
More precisely a basic edgeis a tuple of the form (name, test, variable), wherename is the name of the edge, test is a predicate, andvariable holds the current oken Tc , if test appliedon Tc holds.
For example the following basic edge(:mona-cat "partikel" pre) tests whether Tc producedby MONA is a particle, and if so binds the token tothe variable pre (more precisely, each variable of abasic edge denotes a stack, so that the current okenis actually pushed onto the stack).We assume that for each component of the sys-tem for which fragment extraction patterns are tobe defined, a set of basic edges exists.
Furthermore,we assume that such a set of basic edges remains fixat some point in the development of the system andthus can be re-used as pre-specified basic buildingblocks to a grammar writer.Using basic edges the recognition part of an FSTis then defined as a regular expression using a func-tional notation.
For example the recognition part forsimple nominal phrases might be defined as follows::conc(:star<_n (:mona-cat "det" det) 1)(:star (:mona-cat "adj" adj))(:mona-cat "n" noun))Thus defined, a nominal phrase is the concatena-tion of one optional determiner (expressed by theloop operator :star<n, where n starts from 0 andends by 1), followed by zero or more adjectives fol-lowed by a noun.Output  description part The output structureof an FST is constructed by collecting together thevariables of the recognition part's basic edges fol-lowed by some specific construction handlers.
In or-der to support re-usability of FST to other applica-tions, it is important o separate the constructionhandlers from the FST definition.
Therefore, theoutput description part is realized through a func-tion called BUILD-ITEM which receives as input theedge variables and a symbol denoting the class ofthe FST.
For example, if :np is used as a type namefor nominal phrases then the output description ofthe above NP-recognition part is(build-item :type :np :out (list det adj noun)).The function BUILD-ITEM then discriminates ac-cording to the specified type and constructs the de-sired output to some pre-defined requests (note, thatin the above case the variables DET and ADJ mighthave received no token.
In that case their defaultvalue NIL is used as an indication of this fact).
Usingthis mechanism it is possible to define or re-definethe output structure without changing the wholeFST.Special edges There exist some special ba-sic edges namely (:var var), (:current-pos pos) and(:seek name var).
The edge (:var var) is used forsimply skipping or consuming a token without anychecks.
The edge :current-pos i used for storing theposition of the current oken in the variable pos, andthe edge :seek is used for calling the FST namedname, where var is used as a storage for the outputof name.
This is similar to the :seek edge knownfrom Augmented Transition Networks with the no-tably distinction that in our system recursive callsare disallowed.
Thus :seek can also be seen as amacro expanding operator.
The :seek mechanismis very useful in defining modular grammars, sinceit allows for a hierarchical definition of finite stategrammars, from general to specific constructions (orvice versa).
The following example demonstrates theuse of these special edges:(compile-regexp:conc(:current-pos start)(:alt(:seek time-phase time)(:conc(:star_<n (:seek time-expr-vorfield vorfield) 1)(:seek mona-time time)))(:current-pos end)):name time-expr:output-desc(build-item :type time-expr :start start:end end :out (list vorfield time))))This FST recognizes expressions like "sp~testensum 14:00 h" (by two o'clock at the latest) with theoutput description ((:out (:time-rel .
"spaet") (:time-prep.
"urn") (:minute.
0) (:hour.
14)) (:end .
4)(:start.
0) (:type.
time-expr))Interface to TDL The interface to TDL, a typedfeature-based language and inference system is alsorealized through basic edges.
TDL allows the userto define hierarchically-ordered types consisting oftype constraints and feature constraints, and hasbeen originally developed for supporting high-levelcompetence grammar development.In SMES we are using TDL for two purposes:1. defining domain-specific type lattices2.
expressing syntactic agreement constraintsThe first knowledge is used for performingconcept-based lexical retrieval (e.g., for extractingword forms which are compatible to a given super-type, or for filtering out lexical readings which areincompatible wrt.
a given type), and the secondknowledge is used for directing fragment process-ing and combination, e.g., for filtering out certainun-grammatical phrases or for extracting phrases ofcertain syntactic type.212The integration of TDL and finite state expres-sions is easily achieved through the definition of ba-sic edges.
For example the edge(:mona-cat-type (:and "n .... device") var)will accept a word form which has been analyzedas a noun and whose lexical entry type identifier issubsumed by "device".
As an example of definingagreement test consider the basic edge(:mona-cat-unify "det""\[(num %l)(case %2 = gen-val) (gender %3)\]"agr det)which checks whether the current token is a deter-miner and whether its inflection information (com-puted by MONA) unifies with the specified con-straints (here, it is checked whether the determinerhas a genitive reading, where structure sharing isexpressed through variables like %1).
If so, agr isbound to the result of the unifier and token is boundto det.
If in the same FST a similar edge for nountokens follows which also makes reference to the vari-able agr, the new value for agr is checked with its oldvalue.
In this way, agreement information is propa-gated through the whole FST.An important advantage of using TDL in this wayis that it supports the specification of very compactand modular finite expressions.
However, one mightargue that using TDL in this way could have dra-matic effects on the efficiency of the whole system,if the whole power of TDL would be used.
In somesense this is true.
However, in our current systemwe only allow the use of type subsumption which isperformed by TDL very efficiently, and constraintsused very carefully and restrictively.
Furthermore,the TDL interface opens up the possibility of inte-grating deeper processing components very straight-forwardly.Control parameters In order to obtain flexiblecontrol mechanisms for the matching phase it is pos-sible to specify whether an exact match is requestedor whether an FST should already succeed when therecognition part matches a prefix of the input string(or suffix, respectively).
The prefix matching mech-anism is used in conjunction with the Kleene :starand the identity edge :var, to allow for searchingthe whole input stream for extracting all matchingexpressions of an FST (e.g., extracting all NP's, ortime expressions).
For example the following FSTextracts all genitive NPs found in the input streamand collects them in a list :(compile-regexp(:star(:alt(:seek gen-phrase x)(:var dummy))):output-desc (build-item :type list :out x ):prefix T:suffix NIL5 Fragment  combinat ion  andtemplate  generat ionBidirectional shallow parsing The combina-tion of extracted fragments i performed by a lexical-driven bidirectional shallow parser which operateson fragment combination patterns FCP which areattached to lexical entries (mainly verbs).
We callthese lexical entries anchors.The input stream for the shallow parser consists ofa double-linked list of all extracted fragments foundin some input text, all punctuation tokens and texttokens (like newline or paragraph) and all found an-chors (i.e., all other tokens of the input text are ig-nored).
The shallow parser then applies for eachanchor its associated FCP.
An anchor can be viewedas splitting the input stream into a left and right in-put part.
Application of an FCP then starts directlyfrom the input position of the anchor and searchesthe left and right input parts for candidate frag-ments.
Searching stops either if the beginning orthe end of a text has been reached or if some punc-tuation, text tokens or other anchors defined as stopmarkers have been recognized.General fo rm of  f ragment  combinat ion  pat-terns A FCP consists of a unique name, an recog-nition part applied on the left input part and one forthe right input part, an output description part anda set of constraints on the type and number of col-lected fragments.
As an prototypical case, considerthe following FCP defined for intransitive verbs liketo come or to begin:(com pile-a nchored-regexp((:set (cdr (assoc :start ?
*)) anchor-pos)(:set ((:np (1 1) (nom-val (1 1)))) nec)(:set ((:tmp (0 2))) opt))((:dl-list-left(:star(:alt(:ignore-token (", .... ;"))(:ignore-fragment :type (:time-phase :pp))(:add-nec (:np :name-np):np nec Icompl)(:add-opt (:time-expr :date-expr):tmp opt Icompl))))(:dl-list-right(:star(:alt(:ignore-token (", .... ;" ))(:add-nec (:np) :np nec rcompl)(:add-opt (:time-expr :date-expr):name gen-star)Additionally, a boolean parameter can be used tospecify whether longest or shortest matches houldbe prefered (the default is longest match, see also(Appelt et al, 1993) where also longest subsumingphrases are prefered).213:tmp opt rcompl))))):name intrans:output-desc (build-item :type :intrans:out (list anchor-pos Icompl rcompl)))The first list remembers the position of the activeanchor and introduces two sets of constraints, whichare used to define restrictions on the type and num-ber of necessary and optional fragments, e.g., thefirst constraint says that exactly one :np fragment(expressed by the lower and upper bound in (1 1))in nominative case must be collected, where the sec-ond constraint says that at most two optional frag-ments of type :tmp can be collected.
The two con-straints are maintained by the basic edges :add-necand :add-opt.
:add-nec performs as follows.
If thecurrent oken is a fragment of type :np or :name-npthen inspect the set named nec and select the con-straint set typed :np .
If the current token agreesin case (which is tested by type subsumption) thenpush it to lcompl and reduce the upper bound by1.
Since next time the upper bound is 0 no morefragments will be considered for the set nec.
5 In asimilar manner :add-opt is processed.The edges :ignore-token and :ignore-fragment areused to explicitly specify what sort of tokens willnot be considered by :add-nec or :add-opt.
In otherwords this means, that each token which is not men-tioned in the FCP will stop the application of theFCP on the current input part (left or right).Complex  verb  const ruct ions  In our currentsystem, FCPs are attached to main verb entries.Expressions which contain modal, auxiliary verbsor separated verb prefixes are handled by lexicalrules which are applied after fragment processingand before shallow processing.
Although this mech-anism turned out to be practical enough for ourcurrent applications, we have defined also complexverb group fragments VGF.
A VGF is applied afterfragment processing took place.
It collects all verbforms used in a sentence, and returns the underlyingdependency-based structure.
Such an VGF is thenused as a complex anchor for the selection of appro-priate fragment combination patterns as describedabove.
The advantage of verb group fragments isthat they help to handle more complex construc-tions (e.g., time or speech act) in a more systematic(but still shallow) way.Template generation An FCP expresses restric-tions on the set of candidate fragments to be col-lected by the anchor.
If successful the set of foundfragments together with the anchor builds up an in-stantiated template or frame.
In general a templateis a record-like structure consisting of features andtheir values, where each collected fragment and the5In some sense this mechanism behaves like the sub-categorization principle employed in constraint-basedlexical grammars.anchor builds up a feature/value pair.
An FCP alsodefines which sort of fragments are necessary or op-tional for building up the whole template.
FCPs areused for defining linguistically oriented general head-modifier construction (linguistically based on depen-dency theory) and application-specific database n-tries.
The "shallowness" of the template construc-tion/instantiation process depends on the weaknessof the defined FST of an FCP.A major drawback of our current approach is thatnecessary and optional constraints are defined to-gether in one FCP.
For example, if an FCP is usedfor defining generic clause expressions, where com-plements are defined through necessary constraintsand adjuncts through optional constraints then ithas been shown that the constraints on the adjunctscan change for different applications.
Thus we ac-tually lack some modularity concerning this issue.A better solution would be to attach optional con-straints directly with lexical entries and to "splice"them into an FCP after its selection.6 Coverage  o f  knowledge sourcesThe lexicon in use contains more than 120.000 stementries (concerning morpho-syntactic information).The time and date subgrammar covers a widerange of expressions including nominal, preposi-tional, and coordinated expressions, as well as com-bined date-time xpressions (e.g., "vom 19.
(8.00h) his einschl.
21.
Oktober (18.00 h)" yields: (:pp(from :np (day.
19) (hour.
8) (minute.
0)) (to :np(day.
21) (month.
10) (hour.
18) (minute.
0))))The NP/PP  subgrammars cover e.g., coordinateNPs, different forms of adjective constructions, gen-itive expressions, pronouns.
The output struc-tures reflects the underlying head-modifier relations(e.g., " Die neuartige und vielf~ltige Gesellschaft "yields: (((:sere (:head "gesellschaft") (:mods "neuar-tig .... vielfaeltig") (:quantifier "d-det")) (:agr nom-acc-val) (:end.
6) (:start.
1) (:type.
:np)))30 generic syntactic verb subcategorization framesare defined by fragment combination patterns (e.g,for transitive verb frame).
Currently, these verbframes are handled by the shallow parser with no or-dering restriction, which is reasonably because Ger-man is a language with relative free word order.However, in future work we will investigate the in-tegration of shallow linear precedence constraints.The specification of the current data has beenperformed on a tagged corpora of about 250 texts(ranging in size from a third to one page) which areabout event announcement, appointment schedulingand business news following a bottom-up grammardevelopment approach.7 Current applicationsOn top of SMES three application systems have beenimplemented:2141. appointment scheduling via email: extraction ofco-operate act, duration, range, appointment,sender, receiver, topic2.
classification of event announcements sent viaemail: extraction of speaker, title, time, andlocation3.
extraction of company information from news-paper articles: company name, date, turnover,revenue, quality, differenceFor these applications the main architecture (asdescribed above), the scanner, morphology, the setof basic edges, the subgrammars for t ime/date andphrasal expressions could be used basically un-changed.In (1) SMES is embedded in the COSMA system,a German language server for existing appointmentscheduling agent systems (see (Busemann et al,1997), this volume, for more information).
In case(2) additional FST for the text structure have beenadded, since the text structure is an importantsource for the location of relevant information.
How-ever, since the form of event announcements is usu-ally not standardized, shallow NLP mechanisms arenecessary.
Hence, the main strategy realized is a mixof text structure recognition and restricted shallowanalysis.
For application (3), new subgrammars forcompany names and currency expressions have to bedefined, as well as a task-specific reference resolutionmethod.Processing is very robust and fast (between 1 and10 CPU seconds (Sun UltraSparc) depending on thesize of the text which ranges from very short texts(a few sentences) upto short texts (one page)).
In allof the three applications we obtained high coverageand good results.
Because of the lack of compara-ble existing IE systems defined for handling Germantexts in similar domains and the lack of evaluationstandards for the German language (comparable tothat of MUC), we cannot claim that these resultsare comparable.However, we have now started the implementa-tion of a new application together with a commer-cial partner, where a more systematic evaluation ofthe system is carried out.
Here, SMES is applied on aquite different domain, namely news items concern-ing the German IFOR mission in former Yugoslavia.Our task is to identify those messages which areabout violations of the peace treaty and to extractthe information about location, aggressor, defenderand victims.The corpus consists of a set of monthly reports(Jan. 1996 to Aug. 1996) each consisting of about25 messages from which 2 to 8 messages are aboutfighting actions.
These messages have been hand-tagged with respect o the relevant information.
Al-though we are still in the development phase wewill briefly describe our experience of adapting SMESto this new domain.
Starting from the assumptionthat the core machinery can be used un-changed wefirst measured the coverage of the existing linguisticknowledge sources.
Concerning the above mentionedcorpus the lexicon covers about 90%.
However, fromthe 10% of unrecognized words about 70% are propernames (which we will handle without a lexicon) and1.5% are spelling errors, so that the lexicon actuallycovers more then 95% of this unseen text corpus.The same "blind" test was also carried out for thedate, time, and location subgrammar, i.e., they havebeen run on the new corpus without any adaption tothe specific domain knowledge.
For the date-/timeexpressions we obtained a recall of 77% and a pre-cision of 88%, and for the location expressions weobtained 66% and 87%, respectively.
In the lattercase, most of the unrecognized expressions concernexpressions like "nach Taszar/Ungarn", "im serbis-chen bzw.
kroatischen Teil Bosniens", or "in derMoslemisch-kroatischen FSderation".
For the gen-eral NP and PP subgrammars we obtained a recallof 55% and a precision of 60% (concerning correcthead-modifier structure).
The small recall is due tosome lexical gap (including proper names) and un-foreseen complex expressions like "die Mehrzahl derauf 140.000 gesch~itzten moslemischen Fltichtlinge".But note that these grammars have been written onthe basis of different corpora.In order to measure the coverage of the fragmentcombination patterns FCP, the relevant main verbsof the tagged corpora have been associated withthe corresponding FCP (e.g., the FCP for transi-tive verbs), without changing the original definitionof the FCPs.
The only major change to be doneconcerned the extension of the output descriptionfunction BUILD-ITEM for building up the new tem-plate structure.
After a first trial run we obtained anunsatisfactory ecognition rate of about 25%.
Onemajor problem we identified was the frequent use ofpassive constructions which the shallow parser wasnot able to process.
Consequently, as a first actualextension of SMES to the new domain we extendedthe shallow parser to cope with passive construc-tions.
Using this extension we obtained an recogni-tion of about 40% after a new trial run.After the analysis of the (partially) unrecognizedmessages (including the misclassified ones), we iden-tified the following major bottlenecks of our currentsystem.
First, many of the partially recognized tem-plates are part of coordinations (including enumera-tions), in which case several (local) templates harethe same slot, however this slot is only mentionedone time.
Resolving this kind of "slot sharing" re-quires processing of elliptic expressions of differentkinds as well as the need of domain-specific inferencerules which we have not yet foreseen as part of thecore system.
Second, the wrong recognition of mes-sages is often due to the lack of semantic onstraintswhich would be applied during shallow parsing in asimilar way as the subcategorization constraints.215Although these current results should and can beimproved we are convinced that the idea of develop-ing a core IE-engine is a worthwhile venture.8 Re la ted  workIn Germany, IE based on innovative language tech-nology is still a novelty.
The only groups which weare aware of which also consider NLP-based IE are(Hahn, 1992; Bayer et al, 1994).
None of them makeuse of such sophisticated components, as we do inSMES.
Our work is mostly influence by the work of(Hobbs, 1992; Appelt et al, 1993; Grishman, 1995)as well as by the work described in (Anderson et al,1992; Dowding et al, 1993).9 Conc lus ionWe have described an information extraction coresystem for real world German text processing.
Thebasic design criterion of the system is of providinga set of basic powerful, robust, and efficient naturallanguage components and generic linguistic knowl-edge sources which can easily be customized for pro-cessing different tasks in a flexible manner.
Themain features are: a very efficient and robust mor-phological component, a powerful tool for expressingfinite state expressions, a flexible bidirectional shal-low parser, as well as a flexible interface to an ad-vanced formalism for typed feature formalisms.
Thesystem has been fully implemented in Common Lispand C.Future research will focus towards automaticadaption and acquisition methods, e.g., automaticextraction of subgrammars from a competence baseand learning methods for domain-specific extractionpatterns.10 AcknowledgementThe research underlying this paper was supportedby research grants from the German Bundesmin-isterium fiir Bildung, Wissenschaft, Forschungund Technologie (BMBF) to the DFKI  projectsPARADICE, FKZ ITW 9403 and PARADIME,FKZ ITW 9704.
We would like to thank the follow-ing people for fruitful discussions: Hans Uszkoreit,Gregor Erbach, and Luca Dini.ReferencesA.
Aho, J. Hopcraft, and J. Ullmann.
1983.
Data struc-tures and algorithms.
Addison Wesley, Reading, Mass.P.
Anderson, P. Hays, A. Huettner, L. Schmandt,I.
Nirenburg, and S. Weinstein.
1992.
Automatic ex-traction of facts from press releases to generate newsstories.
In 3rd ANLP, pages 170-177, Trento, Italy.C.
Aone and K. Hausman.
1996.
Unsupervised learningof a rule-based Spanish part of speech tagger.
In Pro-ceedings of COLING-96, pages 53-58, Kopenhagen,Denmark, Europe.D.
Appelt, J. Hobbs, J.
Bear, D. Israel, and M. Tyson.1993.
Fastus: A finite state processor for informationextraction from real world text.
In Proceedings of the13th IJCAI, Chambery, France, August.T.
Bayer, U. Bohnacker, and H. Mogg-Schneider.
1994.Infoportlab - an experimental document understand-ing system.
In Proceedings of the 1st DAS.E.
Brill.
1995.
Unsupervised learning of disambiguationrules for part of speech tagging.
In Very Large CorporaWorkshop.S.
Busemann, T. Declereck, A. Diagne, L. Dini, J. Klein,and S. Schmeier.
1997.
Natural anguage dialogue ser-vice for appointment scheduling agents.
This volume.N.
Chinchor, L. Hirschman, and D. Lewis.
1993.
Evalu-ating message understanding systems: An analysis ofthe third message understanding conference (muc-3).Computational linguistics, 19(3).J.
Cowie and W. Lehnert.
1996.
Information extraction.Communications of the ACM, 39(1):51-87.J.
Dowding, J. Gawron, D. Appelt, J.
Bear, L. Cherny,R.
Moore, and D. Moran.
1993.
Gemini: A naturallanguage system for spoken-language understanding.In 31th ACL, Ohio.W.
Finkler and G. Neumann.
1988.
Morphix: A fastrealization of a classification-based approach to mor-phology.
In H. Trost, editor, Proceedings of 4th OFAI,Berlin, August.
Springer.R.
Grishman and B. Sundheim.
1996.
Message Under-standing Conference - 6: A Brief History.
In Pro-ceedings of COLING-96, pages 466-471, Kopenhagen,Denmark, Europe.R.
Grishman.
1995.
The NYU MUC-6 System orWhere's the Syntax?
In Sixth Message UnderstandingConference (MUC-6).
Morgan Kaufmann, November.U.
Hahn.
1992.
On text coherence parsing.
In Pro-ceedings of COLING-92, pages 25-31, Nantes, France,Europe.J.
Hobbs.
1992.
The generic information extraction sys-tem.
In B. Sundheim, editor, Fourth Message Un-derstanding Conference (MUC-4), McLean, Virginia,June.
Distributed by Morgan Kaufmann Publishers,Inc.,San Mateo, California.K.
Koskenniemi.
1983.
Two-level model for morphologi-cal analysis.
In 8th IJCAI, pages 683-685, Karlsruhe.Hans-Ulrich Krieger and Ulrich Sch~ifer.
1994.
7"D/:--atype description language for constraint-based gram-mars.
In Proceedings of COLING-94, pages 893-899.Hans-Ulrich Krieger.
1987.
Nil--eine Lisp-basiertenat/irlichsprachliche Schnittstelle zu Ramses.
Un-terst/itzung der NMR-Diagnostik von Him- und Mam-matumoren.
Master's thesis, RWTH Aachen.B.
Sundheim, editor.
1995.
Sixth Message Understand-ing Conference (MUC-6), Washington.
Distributed bYMorgan Kaufmann Publishers, Inc.,San Mateo, Cali-fornia.216
