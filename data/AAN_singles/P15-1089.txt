Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 920?928,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsTweet Normalization with SyllablesKe XuSchool of Software Eng.Beijing U. of Posts & Telecom.Beijing 100876, Chinaxxukez2@gmail.comYunqing XiaSTCAMicrosoftBeijing 100084, Chinayxia@microsoft.comChin-Hui LeeSchool of Electr.
& Comp.
Eng.Georgia Institute of TechnologyAtlanta, GA 30332-0250, USAchl@ece.gatech.eduAbstractIn this paper, we propose a syllable-basedmethod for tweet normalization to studythe cognitive process of non-standardword creation in social media.
Assumingthat syllable plays a fundamental role informing the non-standard tweet words,we choose syllable as the basic unit andextend the conventional noisy channelmodel by incorporating the syllables torepresent the word-to-word transitionsat both word and syllable levels.
Thesyllables are used in our method notonly to suggest more candidates, but alsoto measure similarity between words.Novelty of this work is three-fold: First,to the best of our knowledge, this is anearly attempt to explore syllables in tweetnormalization.
Second, our proposednormalization method relies on unlabeledsamples, making it much easier to adaptour method to handle non-standard wordsin any period of history.
And third, weconduct a series of experiments and provethat the proposed method is advantageousover the state-of-art solutions for tweetnormalization.1 IntroductionDue to the casual nature of social media, thereexists a large number of non-standard words intext expressions which make it substantially dif-ferent from formal written text.
It is reported in(Liu et al, 2011) that more than 4 million dis-tinct out-of-vocabulary (OOV) tokens are foundin the Edinburgh Twitter corpus (Petrovic et al,2010).
This variation poses challenges whenperforming natural language processing (NLP)tasks (Sproat et al, 2001) based on such texts.Tweet normalization, aiming at converting theseOOV non-standard words into their in-vocabulary(IV) formal forms, is therefore viewed as a veryimportant pre-processing task.Researchers focus their studies in tweet normal-ization at different levels.
A character-level tag-ging system is used in (Pennell and Liu, 2010) tosolve deletion-based abbreviation.
It was furtherextended in (Liu et al, 2012) using more charac-ters instead of Y or N as labels.
The character-levelmachine translation (MT) approach (Pennell andLiu, 2011) was modified in (Li and Liu, 2012a)into character-block.
While a string edit distancemethod was introduced in (Contractor et al, 2010)to represent word-level similarity, and this ortho-graphical feature has been adopted in (Han andBaldwin, 2011), and (Yang and Eisenstein, 2013).Challenges are encountered in these differentlevels of tweet normalization.
In the character-level sequential labeling systems, features are re-quired for every character and their combinations,leading to much more noise into the later reversetable look-up process (Liu et al, 2012).
In thecharacter-block level MT systems equal number ofblocks and their corresponding phonetic symbolsare required for alignment (Li and Liu, 2012b).This strict restriction can result in a great difficultyin training set construction and a loss of usefulinformation.
Finally, word-level normalizationmethods cannot properly model how non-standardwords are formed, and some patterns or consisten-cies within words can be omitted and altered.We observe the cognitive process that, givennon-standard words like tmr, people tend to firstsegment them into syllables like t-m-r. Thenthey will find the corresponding standard wordwith syllables like to-mor-row.
Inspired bythis cognitive observation, we propose a syllablebased tweet normalization method, in which non-standard words are first segmented into syllables.Since we cannot predict the writers deterministicintention in using tmr as a segmentation of tm-r920(representing tim-er) or t-m-r (representingto-mor-row), every possible segmentation for-m is considered.
Then we represent similarityof standard syllables and non-standard syllablesusing an exponential potential function.
Afterevery transition probabilities of standard syllableand non-standard syllable are assigned, we thenuse noisy channel model and Viterbi decoder tosearch for the most possible standard candidate ineach tweet sentence.Our empirical study reveals that syllable is aproper level for tweet normalization.
The syllableis similar to character-block but it represents pho-netic features naturally because every word is pro-nounced with syllables.
Our syllable-based tweetnormalization method utilizes effective features ofboth character- and word-level: (1) Like character-level, it can capture more detailed informationabout how non-standard words are generated; (2)Similar to word-level, it reduces a large amount ofnoisy candidates.
Instead of using domain-specificresources, our method makes good use of standardwords to extract linguistic features.
This makesour method extendable to new normalization tasksor domains.The rest of this paper is organized as follows:previous work in tweet normalization are reviewedand discussed in Section 2.
Our approach ispresented in Section 3.
In Section 4 and Section 5,we provide implementation details and results.Then we make some analysis of the results inSection 6.
This work is finally concluded inSection 7.2 Related WorkNon-standard words exhibit different forms andchange rapidly, but people can still figure outtheir original standard words.
To properly modelthis human ability, researchers are studying whatremain unchanged under this dynamic character-istic.
Human normalization of an non-standardword can be as follows: After realizing the word isnon-standard, people usually first figure out stan-dard candidate words in various manners.
Thenthey replace the non-standard words with the stan-dard candidates in the sentence to check whetherthe sentence can carry a meaning.
If not, theyswitch to a different candidate until a good one isfound.
Most normalization methods in existencefollow the same procedure: candidates are firstgenerated, and then put into the sentence to checkwhether a reasonable sentence can be formed.Differences lie in how the candidates are generatedand weighted.
Related work can be classified intothree groups.2.1 Orthographical similarityOrthographical similarity is built upon the as-sumption that the non-standard words look like itsstandard counterparts, leading to a high LongestCommon Sequence (LCS) and low Edit Distance(ED).
This method is widely used in spell checker,in which the LCS and ED scores are calculat-ed for weighting possible candidates.
However,problems are that the correct word cannot alwaysbe the most looked like one.
Taking the non-standard word nite for example, note looksmore likely than the correct form night.
Toovercome this problem, an exception dictionaryof strongly-associated word pairs are constructedin (Gouws et al, 2011).
Further, these pairs areadded into a unified log-linear model in (Yangand Eisenstein, 2013) and Monte Carlo samplingtechniques are used to estimate parameters.2.2 Phonetic similarityThe assumption underlying the phonetic similarityis that during transition, non-standard words soundlike the standard counterparts, thus the pronunci-ation of non-standard words can be traced backto a standard dictionary.
The challenge is thealgorithm to annotate pronunciation of the non-standard words.
Double Metaphone algorithm(Philips, 2000) is used to decode pronunciationand then to represent phonetic similarity by editdistance of these transcripts (Han and Baldwin,2011).
IPA symbols are utilized in (Li and Liu,2012b) to represent sound of words and then wordalignment-based machine translation is applied togenerate possible pronunciation of non-standardwords.
And also, phoneme is used in (Liu et al,2012) as one kind of features to train their CRFmodel.2.3 Contextual similarityIt is accepted that after standard words are trans-formed into non-standard words, the meaning of asentence remains unchanged.
So the normalizedstandard word must carry a meaning.
Most re-searchers use n-gram language model to normal-ize a sentence, and several researches use morecontextual information.
For example, trainingpairs are generated in (Liu et al, 2012) by a921cosine contextual similarity formula whose itemsare defined by TF-IDF scheme.
A bipartite graphis constructed in (Hassan and Menezes, 2013) torepresent tokens (both non-standard and standardwords) and their context.
Thus, random walkson the graph can represent contextual-similaritybetween non-standard and standard words.
Veryrecently, word-embedding (Mikolov et al, 2010;Mikolov et al, 2013) is utilized in (Li and Liu,2014) to represent more complex contextual rela-tionship.In word-to-word candidate selection, most re-searches use orthographical similarity and phonet-ic similarity separately.
In the log-linear model(Yang and Eisenstein, 2013), edit distance is mod-eled as major feature.
In the character- and phone-based approaches (Li and Liu, 2012b), ortho-graphical information and phonetic informationwere treated separately to generate candidates.In (Han and Baldwin, 2011), candidates fromlexical edit distance and phonemic edit distanceare merged together.
Then an up to 16% increas-ing recall was reported when adding candidatesfrom phonetic measure.
But improper processinglevel makes it difficult to model the two types ofinformation simultaneously: (1) Single charactercan hardly reflect orthographical features of oneword.
(2) As fine-grained reasonable restrictionsare lacked, as showed in (Han and Baldwin, 2011),several times of candidates are included whenadding phonetic candidates and this will bringmuch more noise.
To combine orthographicaland phonetic measure in a fine-grained level, weproposed the syllable-level approach.3 Approach3.1 FrameworkThe framework of the proposed tweet normal-ization method is presented in Figure 1.
Theproposed method extends the basic HMM channelmodel (Choudhury et al, 2007; Cook and Steven-son, 2009) into syllable level.
And the followingfour characteristics are very intersting.
(1) Combination: When reading a sentence,fast subvocalization will occur in our mind.In the process, some non-standard wordsgenerated by phonetic substitution are cor-rectly pronounced and then normalized.
Andalso, because subvocalization is fast, peopletend to ignore some minor flaws in spellingintentionally or unintentionally.
As this oftenoccurs in people?s real-life interacting withthese social media language, we believe thecombination of phonetic and orthographicalinformation is of great significance.
(2) Syllable level: Inspired by Chinese normal-ization (Xia et al, 2006) using pinyin (pho-netic transcripts of Chinese), syllable can beseen as basic unit when processing pronunci-ation.
Different from mono-syllable Chinesewords, English words can be multi-syllable;this will bring changes in our method thatextra layers of syllables must be put intoconsideration.
Thus, apart from word-basednoisy-channel model, we extend it into asyllable-level framework.
(3) Priori knowledge: Priori knowledge is ac-quired from standard words, meaning thatboth standard syllabification and pronunci-ation can shed some lights to non-standardwords.
This assumption makes it possibleto obtain non-standard syllables by standardsyllabification and gain pronunciation of syl-lables by standard words and rules generatedwith them.
(4) General patterns: Social media languagechanges rapidly while labeled data is ex-pensive thus limited.
To effectively solvethe problem, linguistic features instead ofstatistical features should be emphasized.
Weexploit standard words of their syllables, pro-nunciation and possible transition pattern-s and proposed the four-layer HMM-basedmodel (see Figure 1).In our method, non-standard words ciare firstsegmented into syllables sc(1)i. .
.
sc(k)i, and forstandard syllable sw(j)imapping to non-standardsyllable sw(j)i, we calculate their similarity bycombining the orthographical and phonetic mea-sures.
Standard syllables sw(1)i. .
.
sw(k)imakeup one standard candidates.
Since candidatesare generated and weighted, we can use Viterbidecoder to perform sentence normalization.
Ta-ble 1 shows some possible candidates for the non-standard word tmr.3.2 MethodWe extend the noisy channel model to syllable-level as follows:922FormalwordsFormal wordsyllablesInformal wordsyllablesInformalwordsFigure 1: Framework of the propose tweet normalization method.w?
= argmax p(w|c)= argmax p(c|w)?
p(w)= argmax p(~sc| ~sw)?
p( ~sw),(1)where w indicates the standard word and c thenon-standard word, and sw and sc represent theirsyllabic form, respectively.
To simplify the prob-lem, we restrict the number of standard syllablesequals to the number of non-standard syllables inour method.Assuming that syllables are independent of eachother in transforming, we obtain:p(~sc| ~sw) =k?j=1p(scj|swj).
(2)For syllable similarity, we use an exponentialpotential function to combine orthographical dis-tance and phonetic distance.
Because pronun-ciation can be represented using letter-to-phonetranscripts, we can treat string similarity of thesetmr t-mr tm-r t-m-rtamer ta-mer tim-er to-mor-rowti-mor tim-ber tri-mes-terti-more ton-er tor-men-tortu-mor tem-per ta-ma-ra.
.
.
.
.
.
.
.
.Table 1: Standard candidates of tmr in syllable lev-el.
The first row gives the different segmentationsand the second row presents the candidates.transcripts as phonetic similarity.
Thus the sylla-ble similarity can be calculated as follows.p(scj|swj, ?)
=?
(scj, swj)Z(swj)(3)Z(swj) =?scj?
(scj, swj)(4)?
(sc, sw) = exp(?
(LCS(sc, sw)?
ED(sc, sw))+(1?
?
)(PLCS(sc, sw)?
PED(sc, sw)))(5)Exponential function grows tremendously as itsargument increases, so much more weight can beassigned if syllables are more similar.
The param-eter ?
here is used to empirically adjust relativecontribution of letters and sounds.
Longest com-mon sequence (LCS) and edit distance (ED) areused to measure orthographical similarity, whilephonetic longest common sequence (PLCS) andphonetic edit distant (PED) are used to measurephonetic similarity but based on letter-to-soundtranscripts.
The PLCS are defined as basic LCSbut PED here is slightly different.When performing phonetic similarity calcula-tion based on syllables, we follow (Xia et al,2006) in treating consonant and vowels separate-ly because transition of consonants can make atotally different pronunciation.
So if consonantsof scjand swjare exactly the same or fit ruleslisted in Table 2, PED(scj, swj) equals to edit923Description Rules Examples1.
-ng as suffix: g-dropping -n/-ng do-in/do-ing, go-in/go-ing, talk-in/talk-ing, mak-in/mak-ing2.
-ng as suffix: n-dropping -g/-ng tak-ig/tak-ing, likig/lik-ing3.
suffix: z/s equaling -z/-s, -s/-z jamz/james, plz/please4.
suffix: n/m equaling -m/-n, -n/-m in-portant/im-portant, get-tim/get-ting5.
suffix: t/d equaling -t/-d, -d/-t shid/shit, shult/should6.
suffix: t-dropping -/-t jus/just, wha/what, mus/must, ain/ain?t7.
suffix: r-dropping -/-r holla/holler, t-m-r/tomorrow8.
prefix: th-/d- equaling d-/th-, th-/d- de/the, dat/that, dats/that?s, dey/theyTable 2: The consonant rules.distance of letter-to-phone transcripts, or it willbe assigned infinity to indicate that their pronun-ciation are so different that this transition canseldom happen.
For example, as consonantaltransition between suffix z and s can alwayshappen, PED(plz,please) equals string editdistance of their transcripts.
But as consonataltransition of f and d is rare, phonetic distanceof fly and sky is assigned infinity.
Note theconsonant rules in Table 2 are manually definedin our empirical study, which represent the mostcommonly used ones.3.3 ParameterParameter in the proposed method is only the?
in Equation (5), which represents the rela-tive contribution of orthographical similarity andphonetic similarity.
Because the limited numberof annotated corpus, we have to enumerate theparameter in {0, 0.1, 0.2, ..., 1} in the experimentto find the optimal setting.4 ImplementationThe method described in the previous section areimplemented with the following details.4.1 PreprocessingBefore performing normalization, we need to pro-cess several types of non-standard words:?
Words containing numbers: People usuallysubstitute some kind of sounds with number-s like 4/four, 2/two and 8/eight ornumbers can be replacement of some letterslike 1/i, 4/a.
So we replace numbers withits words or characters and then use them togenerate possible candidates.?
Words with repeating letters: As ourmethod is syllable-based, repeating lettersfor sentiment expressing (like cooool,(Brody and Diakopoulos, 2011)) can causesyllabifying failure.
For repeating letters, wereduce it to both two and one to generatecandidate separately.
Then the two lists aremerged together to form the whole candidatelist.4.2 Letter-to-sound conversionSyllable in this work refers to orthographic sylla-bles.
For example, we convert word tomorrowinto to-mor-row.
However, when comparingthe syllable of a standard word and that of a non-standard word, sound (i.e., phones) of the syllablesare considered.
Thus letter-to-sound conversiontools are required.Several TTS system can perform the task ac-cording to some linguistic rules, even for non-standard words.
The Double Metaphone algorith-m used in (Han and Baldwin, 2011) is one ofthem.
But it uses consonants to encode a word,which gives less information than we need.
In ourmethod, we use freeTTS (Walker et al, 2002) withCMU lexicon1to transform words into APRA-bet2symbols.
For example, word tomorrow istranscribed to {T-UW M-AA R-OW} and tmr to{T M R}.4.3 Dictionary preparation?
Dictionary #1: In-vocabulary (IV) wordsFollowing (Yang and Eisenstein, 2013), ourset of IV words is also based on the GNU as-pell dictionary (v0.60.6).
Differently, we usea collection of 100 million tweets (roughlythe same size of Edinburgh Twitter corpus)because the Edinburgh Twitter corpus is nolonger available due to Twitter policies.
The1http://www.speech.cs.cmu.edu/cgi-bin/cmudict2http://en.wikipedia.org/wiki/Arpabet924final IV dictionary contains 51,948 standardwords.?
Dictionary #2: Syllables for the standardwordsFollowing (Pennell and Liu, 2010), we usethe online dictionary3to extract syllablesfor each standard words.
We encounteredsame problem when accessing words withprefixes or suffixes, which are not syllabifiedin the same format as the base words on thewebsite.
To address the issue, we simplyregard these prefixes and suffixes as syllables.?
Dictionary #3: Pronunciation of the sylla-blesUsing the CMU pronouncing dictionary(Weide, 1998) and dictionary 2, and knowingall possible APRAbet symbol for allconsonant characters, we can program tocapture every possible pronunciation of allsyllables in the standard dictionary.4.4 Automatic syllabification of non-standardwordsAutomatic syllabification of non-standard wordsis a supervised problem.
A straightforward ideais to train a CRF model on manually labeledsyllables of non-standard words.
Unfortunately,such a corpus is not available and very expensiveto produce.We assume that both standard and non-standardforms follow the same syllable rules (i.e., thecognitive process).
Thus we propose to train theCRF model on the corpus of syllables of standardwords (which is easy to obtain) to construct anautomatic annotation system based on CRF++(Kudo, 2005).
In this work, we extract syllablesof standard words from Dictionary #2 as trainingset.
Annotations follow (Pennell and Liu, 2010) toidentify boundaries of syllables and in our work,CRF++ can suggest several candidate solutions,rather than an optimal segmentation solution forsyllable segmentation of the non-standard words.In the HMM channel model, the candidate solu-tions are included as part of the search space.4.5 Language modelUsing Tweets from our corpus that contain noOOV words besides hashtags and username men-tions (following (Han and Baldwin, 2011)), the3http://www.dictionary.comKneser-Ney smoothed tri-gram language model isestimated using SRILM toolkit (Stolcke, 2002).Note that punctuations, hashtags, and usernamementions have some syntactic value (Kaufmannand Kalita, 2010) to some extent, we replace themwith ?<PUNCT>?, ?<TOPIC>?
and ?<USER>?.5 Evaluation5.1 DatasetsWe use two labeled twitter datasets in existence toevaluate our tweet normalization method.?
LexNorm1.1 contains 549 complete tweetswith 1184 non-standard tokens (558 uniqueword type) (Han and Baldwin, 2011).?
LexNorm1.2 is a revised version of LexNor-m1.1 (Yang and Eisenstein, 2013).
Someinconsistencies and errors in LexNorm1.1 arecorrected and some more non-standard wordsare properly recovered.In both datasets, to-be-normalized non-standardwords are detected manually as well as the corre-sponding standard words.5.2 Evaluation criteriaHere we use precision, recall and F-score to e-valuate our method.
As normalization methodson these datasets focused on the labeled non-standard words (Yang and Eisenstein, 2013), re-call is the proportion of words requiring normal-ization which are normalized correctly; precisionis the proportion of normalizations which are cor-rect.
When we perform the tweet normalizationmethods, every error is both a false positive andfalse negative, so in the task, precision equals torecall.5.3 Sentence level normalizationWe choose the following prior normalizationmethods:?
(Liu et al, 2012): the extended character-level CRF tagging system;?
(Yang and Eisenstein, 2013): log-linear mod-el using string edit distance and longest com-mon sequence measures as major features;?
(Hassan and Menezes, 2013): bipartite graphmajor exploit contextual similarity;925Method Dataset Precision Recall F-measure(Han and Baldwin, 2011)LexNorm 1.175.30 75.30 75.30(Liu et al, 2012) 84.13 78.38 81.15(Hassan and Menezes, 2013) 85.37 56.4 69.93(Yang and Eisenstein, 2013) 82.09 82.09 82.09Syllable-based method 85.30 85.30 85.30(Yang and Eisenstein, 2013)LexNorm 1.282.06 82.06 82.06Syllable-based method 86.08 86.08 86.08Table 3: Experiment results of the tweet normalization methods.?
(Han and Baldwin, 2011): the orthography-phone combined system using lexical editdistance and phonemic edit distance.In our method, we set ?=0.7 because it isfound best in our experiments (see Figure 2).The experimental results are presented in Table 3,which indicate that our method outperforms thestate-of-the-art methods.
Details on how to adjustparameter is given in Section 5.4.Recall we argue that combination of three simi-larity is necessary when performing sentence-levelnormalization.
Apart from contextual similaritylike language model or graphic model, methodsin (Yang and Eisenstein, 2013) or (Hassan andMenezes, 2013) do not include phonetic measure,causing loss of important phonetic information.Though using phoneme, morpheme boundary andsyllable boundary as features (Liu et al, 2012), thecharacter-level reversed approach will bring muchmore noise into the later reversed look-up table,and also, features of whole word are omitted.Like (Han and Baldwin, 2011), we also uselexical measure and phonetic measure.
Greatdifference between the two approaches is the pro-cessing level: word level and syllable level.
Intheir work, average candidates number sufferstimes of increase when adding phonetic measure.This is because when introducing phonemic editdistance, important pronunciations can be altered(phonemic edit distance of night-need andnight-kite is equal).
Syllable level allows usto reflect consistencies during transition in a finer-grained level.
Thus the phonetic similarity can bemore precisely modeled.5.4 Contributions of phone and orthographyIn our method, the parameter ?
in Equation 5 isused to represent the relatively contributions ofboth phonetic and orthographical information.
Butas the lack of prior knowledge, we cannot judgean optimal ?.
We choose to conduct experimentsvarying ?
= {0, 0.1, ..., 1} to find out how thisadjustment can affect performance.
The experi-mental results are presented in Figure 2.0.
80.810.820.830.840.850.860.870 0.
2 0.
4 0.
6 0.
8 1F-measure?LexNorm1.1LexNorm1.2Figure 2: Contribution of phone and orthography.As shown in Figure 2, when ?
is set 0 or 1 (indi-cating no contribution of either orthographical orphonetic in assigning weight to candidates), ourmethod performs much worse.
In our experiment,when ?
= 0.7, the models performs best, showingthat orthographical measure makes relatively morecontribution over phonetic measure, but the latteris indispensable.
This justifies the effectiveness ofcombining orthographical and phonetic measure,indicating that human normalization process isproperly modeled.6 Analysis6.1 Our exceptionsDeeper observation of our normalization resultsshows that there are several types of exceptionsbeyond our consonant-based rules.
For example,thanks fails to be selected as a candidate for thenon-standard word thx because the pronunciationof thanks contains an N but thx does not.The same situation happens when we processstong/strong because of the lacking R. We926believe some more consonant should be exploitedand more precisely described.6.2 Non-standard words involving multiplesyllablesThere are one type of transition that wecannot solve like acc/accelerate andbio/biology because the mapping is betweensingle-syllable word and multi-syllable word.We add possible standard syllable sw(i)0andsw(i)k+1to the head and tail of origin syllables,but this extended form failed to be assigned highprobability because the string edit distances aretoo large.
We leave this problem for furtherresearch.6.3 Annotation issueThough similar, our results of LexNorm1.2 isbetter than LexNorm1.1.
After scrutinizing, wenotice that several issues in LexNorm1.1 are fixedin LexNorm1.2.
So our results like meh/me(meaning the non-standard word meh are correct-ed to me) in LexNorm1.1 is wrong but in LexNor-m1.2 is right.
Even in LexNorm1.2, there existsome inconsistencies and errors.
For example,our result buyed/bought is wrong for bothdatasets, which is actually correct.
For anotherexample, til is normalized to until in somecases but to till in other cases.
We show that theLexNorm test corpus is still imperfect.
We appealfor systematic efforts to produce a standard datasetunder a widely-accepted guideline.6.4 ConventionsSocial media language often contains words thatare culture-specific and widely used in daily life.Some word like congrats, tv and pic areincluded into several dictionaries.
We also ob-served several transitions like atl/atlanta orwx/weather in the datasets.
These kinds ofconventional abbreviations pose great difficultyto us.
Normalization of those conventional non-standard words still needs further study.7 ConclusionIn this paper, a syllable-based tweet normalizationmethod is proposed for social media text normal-ization.
Results on publicly available standarddatasets justify our assumption that syllable playsa fundamental role in social media non-standardwords.
Advantage of our proposed method liesin that syllable is viewed as the basic processingunit and syllable-level similarity.
This accords tothe human cognition in creating and understandingthe social non-standard words.
Our method isdomain independent.
It is robust on non-standardwords in any period of history.
Furthermore, givethe syllable transcription tool, our method can beeasily adapted to a new language.AcknowledgementThis research work was carried out when theauthors worked at Tsinghua University.
Weacknowledge the financial support from NaturalScience Foundation of China (NSFC: 61272233,61373056, 61433018).
We thank the anonymousreviewers for the insightful comments.ReferencesSamuel Brody and Nicholas Diakopoulos.
2011.Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!
usingword lengthening to detect sentiment in microblogs.In EMNLP, pages 562?570.
ACL.Monojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, and Anupam Basu.2007.
Investigation and modeling of the structureof texting language.
International Journal ofDocument Analysis and Recognition (IJDAR), 10(3-4):157?174.Danish Contractor, Tanveer A. Faruquie, and L. Venka-ta Subramaniam.
2010.
Unsupervised cleansing ofnoisy text.
In Chu-Ren Huang and Dan Jurafsky,editors, COLING (Posters), pages 189?196.
ChineseInformation Processing Society of China.Paul Cook and Suzanne Stevenson.
2009.
Anunsupervised model for text message normalization.In CALC ?09: Proceedings of the Workshop onComputational Approaches to Linguistic Creativity,pages 71?78, Morristown, NJ, USA.
Association forComputational Linguistics.Stephan Gouws, Dirk Hovy, and Donald Metzler.2011.
Unsupervised mining of lexical variants fromnoisy text.
In Proceedings of the First workshopon Unsupervised Learning in NLP, pages 82?90.Association for Computational Linguistics.Bo Han and Timothy Baldwin.
2011.
Lexicalnormalisation of short text messages: Makn sensa #twitter.
In Dekang Lin, Yuji Matsumoto, andRada Mihalcea, editors, ACL, pages 368?378.
TheAssociation for Computer Linguistics.Hany Hassan and Arul Menezes.
2013.
Social textnormalization using contextual graph random walks.In ACL (1), pages 1577?1586.
The Association forComputer Linguistics.927Max Kaufmann and Jugal Kalita.
2010.
Syntacticnormalization of Twitter messages.
In Interna-tional conference on natural language processing,Kharagpur, India.Taku Kudo.
2005.
Crf++: Yet another crf toolkit.Software available at http://crfpp.
sourceforge.
net.Chen Li and Yang Liu.
2012a.
Improving textnormalization using character-blocks based modelsand system combination.
In COLING 2012, 24thInternational Conference on Computational Lin-guistics, Proceedings of the Conference: TechnicalPapers, 8-15 December 2012, Mumbai, India, pages1587?1602.Chen Li and Yang Liu.
2012b.
Normalization of textmessages using character- and phone-based machinetranslation approaches.
In INTERSPEECH.
ISCA.Chen Li and Yang Liu.
2014.
Improving text normal-ization via unsupervised model and discriminativereranking.
In Proceedings of the 52nd AnnualMeeting of the Association for ComputationalLinguistics, ACL 2014, June 22-27, 2014, Baltimore,MD, USA, Student Research Workshop, pages 86?93.Fei Liu, Fuliang Weng, Bingqing Wang, and YangLiu.
2011.
Insertion, deletion, or substitu-tion?
: normalizing text messages without pre-categorization nor supervision.
In Proceedingsof the 49th Annual Meeting of the Associationfor Computational Linguistics: Human LanguageTechnologies: short papers-Volume 2, pages 71?76.Association for Computational Linguistics.Fei Liu, Fuliang Weng, and Xiao Jiang.
2012.A broad-coverage normalization system for socialmedia language.
In In Proceedings of ACL: LongPapers-Volume 1, pages 1035?1044.
Association forComputational Linguistics.Tom?a?s Mikolov, Martin Karafi?at, Luk Burget, Janernock, and Sanjeev Khudanpur.
2010.
Recurrentneural network based language model.
In Inter-speech, pages 1045?1048.Tom?a?s Mikolov, Kai Chen, Greg Corrado, andJeffrey Dean.
2013.
Efficient estimation ofword representations in vector space.
CoRR,abs/1301.3781.Deana Pennell and Yang Liu.
2010.
Normalization oftext messages for text-to-speech.
In ICASSP, pages4842?4845.
IEEE.Deana Pennell and Yang Liu.
2011.
A character-levelmachine translation approach for normalization ofsms abbreviations.
In IJCNLP, pages 974?982.S.
Petrovic, M. Osborne, and V. Lavrenko.
2010.The edinburgh twitter corpus.
In Proceedingsof the NAACL HLT Workshop on ComputationalLinguistics in a World of Social Media, pages 25?26.Lawrence Philips.
2000.
The double metaphonesearch algorithm.
C/C++ Users Journal, 18(5),June.Richard Sproat, Alan W. Black, Stanley F. Chen,Shankar Kumar, Mari Ostendorf, and ChristopherRichards.
2001.
Normalization of non-standardwords.
Computer Speech & Language, 15(3):287?333.Andreas Stolcke.
2002.
Srilm-an extensible languagemodeling toolkit.
In Proceedings InternationalConference on Spoken Language Processing, pages257?286, November.Willie Walker, Paul Lamere, and Philip Kwok.
2002.Freetts: a performance case study.Robert L Weide.
1998.
The cmu pronouncingdictionary.
URL: http://www.
speech.
cs.
cmu.edu/cgibin/cmudict.Yunqing Xia, Kam-Fai Wong, and Wenjie Li.
2006.A phonetic-based approach to chinese chat textnormalization.
In Nicoletta Calzolari, Claire Cardie,and Pierre Isabelle, editors, ACL.
The Associationfor Computer Linguistics.Yi Yang and Jacob Eisenstein.
2013.
A log-linearmodel for unsupervised text normalization.
InEMNLP, pages 61?72.
ACL.928
