Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 48?54,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsCombining Rule-Based and Statistical Syntactic AnalyzersMar?a Jes?s Aranzabe*, Arantza D?az de Ilarraza, Nerea Ezeiza, Kepa Bengoetxea,Iakes Goenaga, Koldo Gojenola,Department of Computer Languages and Systems / * Department of Basque PhilologyUniversity of the Basque Country UPV/EHU{maxux.aranzabe@ehu.es, kepa.bengoetxea, jipdisaa@si.ehu.es,n.ezeiza@ehu.es, koldo.gojenola@ehu.es, iakes@gmail.com}AbstractThis paper presents the results of a set ofpreliminary experiments combining twoknowledge-based partial dependencyanalyzers with two statistical parsers,applied to the Basque DependencyTreebank.
The general idea will be to applya stacked scheme where the output of therule-based partial parsers will be given asinput to MaltParser and MST, two state ofthe art statistical parsers.
The results showa modest improvement over the baseline,although they also present interesting linesfor further research.1.
IntroductionIn this paper we present a set of preliminaryexperiments on the combination of twoknowledge-based partial syntactic analyzers withtwo state of the art data-driven statistical parsers.The experiments have been performed on theBasque Dependency Treebank (Aduriz et al,2003).In the last years, many attempts have beenperformed trying to combine different parsers(Surdeanu and Manning, 2010), with significantimprovements over the best individual parser?sbaseline.
The two most successful approaches havebeen stacking (Martins et al, 2008) and voting(Sagae and Lavie, 2006, Nivre and McDonald,2008, McDonald and Nivre, 2011).
In this paperwe will experiment the use of the stackingtechnique, giving the tags obtained by the rule-based syntactic partial parsers as input to thestatistical parsers.Morphologically rich languages present newchallenges, as the use of state of the art parsers formore configurational and non-inflected languageslike English does not reach similar performancelevels in languages like Basque, Greek or Turkish(Nivre et al, 2007a).
As it was successfully doneon part of speech (POS) tagging, where the use ofrule-based POS taggers (Tapanainen andVoutilainen, 1994) or a combination of a rule-based POS tagger with a statistical one (Aduriz etal., 1997, Ezeiza et al, 1998) outperformed purelystatistical taggers, we think that exploring thecombination of knowledge-based and data-drivensystems in syntactic processing can be aninteresting line of research.Most of the experiments on combined parsershave relied on different types of statistical parsers(Sagae and Lavie, 2006, Martins et al, 2008,McDonald and Nivre, 2011), trained on anautomatically annotated treebank.
Yeh (2000) usedthe output of several baseline diverse parsers toincrease the performance of a secondtransformation-based parser.
In our work we willstudy the use of two partial rule-based syntacticanalyzers together with two data-driven parsers:?
A rule-based chunker (Aduriz et al, 2004)that marks the beginning and end of nounphrases, postpositional phrases and verbchains, in the IOB (Inside/Outside/Beginning of a chunk) style.?
A shallow dependency relation annotator(Aranzabe et al, 2004), which tries todetect dependency relations by assigning a48set of predefined tags to each word, whereeach tag gives both the name of adependency relation (e.g.
subject) togetherwith the direction of its head (left or right).?
We will use two statistical dependencyparsers, MaltParser (Nivre et al, 2007b)and MST (McDonald et al 2005).In the rest of this paper, section 2 will firstpresent the corpus and the different parsers we willcombine, followed by the experimental results insection 3, and the main conclusions of the work.2.
ResourcesThis section will describe the main resources thathave been used in the experiments.
First,subsection 2.1 will describe the BasqueDependency Treebank, and then subsection 2.2will explain the main details of the analyzers thathave been employed.
The analyzers are a rule-based chunker, a rule-based shallow dependencyparser and two state of the art data-drivendependency parsers, MaltParser and MST.2.1 CorporaOur work will make use the second version of theBasque dependency Treebank (BDT II, Aduriz etal., 2003), containing 150,000 tokens (11,225sentences).
Figure 1 presents an example of asyntactically annotated sentence.
Each wordcontains its form, lemma, category or coarse partof speech (CPOS), POS, morphosyntactic featuressuch as case, number of subordinate relations, andthe dependency relation (headword + dependency).The information in figure 1 has been simplifieddue to space reasons, as typically each wordcontains many morphosyntactic features (case,number, type of subordinated sentence, ...), whichare relevant for parsing.
The last two lines of thesentence in figure 1 do not properly correspond tothe treebank, but are the result of the rule-basedpartial syntactic analyzers (see subsection 2.2).
Forevaluation, we divided the treebank in three sets,corresponding to training, development, and test(80%, 10%, and 10%, respectively).
Theexperiments were performed on the developmentset, leaving the best system for the final test.2.2 AnalyzersThis subsection will present the four types ofanalyzers that have been used.
The rule-basedanalyzers are based on the Contraint Grammar(CG) formalism (Karlsson et al, 1995), based onthe assignment of morphosyntactic tags to wordsusing a formalism that has the capabilities of finitestate automata or regular expressions, by means ofa set of rules that examine mainly local contexts ofwords to determine the correct tag assignment.The rule-based chunker (RBC henceforth,Aranzabe et al, 2009) uses 560 rules, where 479 ofthe rules deal with noun phrases and the rest withverb phrases.
The chunker delimits the chunks withthree tags, using a standard IOB marking style (seefigure 1).
The first one is to mark the beginning ofthe phrase (B-VP if it is a verb phrase and B-NPwhether it's a noun phrase) and the other one tomark the continuation of the phrase (I-NP or I-VP,meaning that the word is inside an NP or VP).
Thelast tag marks words that are outside a chunk.
Theevaluation of the chunker on the BDT gave a resultof 87% precision and 85% recall over all chunks.We must take into account that this evaluation wasauxmodccomp_objauxmodGizonak    mutil    handia   etorri     dela        esan      du .The-man       boy        tall-the    come         has+he+that     tell      he+did+itN-ERG-S       N          ADJ-ABS-S   V            AUXV+S+COMPL    V         AUXVB-NP          B-NP       I-NP        B-VP         I-NP            B-VP      I-VP&NCSUBJ>      &NCSUBJ>   $<NCMOD     $CCOMP_OBJ>  &<AUXMOD        &MAINV    &<AUXMODncsubjncmodncsubjFigure 1.
Dependency tree for the sentence Gizonak mutil handia etorri dela esan du (the man told that the tallboy has come).
The two last lines show the tags assigned by the rule-based chunker and the rule-baseddependency analyzer, respectively.
(V = main verb, N = noun, AUXV = auxiliary verb, COMPL = completive, ccomp_obj = clausal complement object, ERG =ergative, S: singular, auxmod = auxiliary, ncsubj = non-clausal subject, B-NP = beginning of NP, I-NP = inside an NP,&MAINV = main verb, &<AUXMOD = verbal auxiliary modifier).49performed on the gold POS tags, rather than onautomatically assigned POS tasks, as in the presentexperiment.
For that reason, the results can serveas an upper bound on the real results.The rule-based dependency analyzer (RBDA,Aranzabe et al, 2004) uses a set of 505 CG rulesthat try to assign dependency relations towordforms.
As the CG formalism only allows theassignment of tags, the rules only aim at markingthe name of the dependency relation together withthe direction of the head (left or right).
Forexample, this analyzer assigns tags of the form&NCSUBJ> (see figure 1), meaning that thecorresponding wordform is a non-clausal syntacticsubject and that its head is situated to its right (the?>?
or ?<?
symbols mark the direction of thehead).
This means that the result of this analysis ison the one hand a partial analysis and, on the otherhand, it does not define a dependency tree, and canalso be seen as a set of constraints on the shape ofthe tree.
The system was evaluated on the BDT,obtaining f-scores between 90% for the auxmoddependency relation between the auxiliary and themain verb and 52% for the subject dependencyrelation, giving a (macro) average of 65%.Regarding the data-driven parsers, we havemade use of MaltParser (Nivre et al, 2007b) andMST Parser (McDonald et al, 2006), two state ofthe art dependency parsers representing twodominant approaches in data-driven dependencyparsing, and that have been successfully applied totypologically different languages and treebanks(McDonald and Nivre, 2007).MaltParser (Nivre, 2006) is a representative oflocal, greedy, transition-based dependency parsingmodels, where the parser obtains deterministicallya dependency tree in a single pass over the inputusing two data structures: a stack of partiallyanalyzed items and the remaining input sequence.To determine the best action at each step, theparser uses history-based feature models anddiscriminative machine learning.
The learningconfiguration can include any kind of information(such as word-form, lemma, category, subcategoryor morphological features).
Several variants of theparser have been implemented, and we will useone of its standard versions (MaltParser version1.4).
In our experiments, we will use the Stack-Lazy algorithm with the liblinear classifier.The MST Parser can be considered arepresentative of global, exhaustive graph-basedparsing (McDonald et al, 2005, 2006).
Thisalgorithm finds the highest scoring directedspanning tree in a dependency graph forming avalid dependency tree.
To learn arc scores, it useslarge-margin structured learning algorithms, whichoptimize the parameters of the model to maximizethe score margin between the correct dependencygraph and all incorrect dependency graphs forevery sentence in a training set.
The learningprocedure is global since model parameters are setrelative to classifying the entire dependency graph,and not just over single arc attachments.
This is incontrast to the local but richer contexts used bytransition-based parsers.
We use the freelyavailable version of MSTParser1.
In the followingexperiments we will make use of the second ordernon-projective algorithm.3.
ExperimentsWe will experiment the effect of using the outputof the knowledge-based analyzers as input to thedata-driven parsers in a stacked learning scheme.Figure 1 shows how the two last lines of theexample sentence contain the tags assigned by therule-based chunker (B-NP, I-NP, B-VP and I-VP)and the rule-based partial dependency analyzer(&NCSUBJ, &<NCMOD, &<AUXMOD,&CCOMP_OBJ and &MAINV) .The first step consisted in applying the completeset of text processing tools for Basque, including:?
Morphological analysis.
In Basque, eachword can receive multiple affixes, as eachlemma can generate thousands of word-forms by means of morphologicalproperties, such as case, number, tense, ordifferent types of subordination for verbs.Consequently, the  morphological analyzerfor Basque (Aduriz et al 2000) gives ahigh ambiguity.
If only categorial (POS)ambiguity is taken into account, there is anaverage of 1.55 interpretations per word-form, which rises to 2.65 when the fullmorphosyntactic information is taken intoaccount, giving an overall 64% ofambiguous word-forms.?
Morphological disambiguation.Disambiguating the output ofmorphological analysis, in order to obtaina single interpretation for each word-form,1 http://mstparser.sourceforge.net50can pose an important problem, asdetermining the correct interpretation foreach word-form requires in many cases theinspection of local contexts, and in someothers, as the agreement of verbs withsubject, object or indirect object, it couldalso suppose the examination of elementswhich can be far from each other, added tothe free constituent order of the mainsentence elements in Basque.
Theerroneous assignment of incorrect part ofspeech or morphological features candifficult the work of the parser.?
Chunker?
Partial dependency analyzerWhen performing this task, we found theproblem of matching the treebank tokens withthose obtained from the analyzers, as there weredivergences on the treatment of multiword units,mostly coming from Named Entities, verbcompounds and complex postpositions (formedwith morphemes appearing at two different words).For that reason, we performed a matching processtrying to link the multiword units given by themorphological analysis module and the treebank,obtaining a correct match for 99% of the sentences.Regarding the data-driven parsers, they aretrained using two kinds of tags as input:?
POS and morphosyntactic tags comingfrom the automatic morphologicalprocessing of the dependency treebank.Disambiguation errors, such as anincorrect POS category or morphologicalanalyses (e.g.
the assignment of anincorrect case) can harm the parser, astested in Bengoetxea et al (2011).?
The output of the rule-based partialsyntactic analyzers (two last lines of theexample in figure 1).
These tags containerrors of the CG-based syntactic taggers.As the analyzers are applied aftermorphological processing, the errors canbe propagated and augmented.Table 1 shows the results of using the output ofthe knowledge-based analyzers as input to thestatistical parsers.
We have performed threeexperiments for each statistical parser, trying withthe chunks provided by the chunker, the partialdependency parser, and both.
The table showsmodest gains, suggesting that the rule-basedanalyzers help the statistical ones, giving slightincreases over the baseline, which are statisticallysignificant when applying MaltParser to the outputof the rule-based dependency parser and acombination of the chunker and rule-based parsers.As table 1 shows, the parser type is relevant, asMaltParser seems to be sensitive when using thestacked features, while the partial parsers do notseem to give any significant improvement to MST.3.1 Error analysisLooking with more detail at the errors made by thedifferent versions of the parsers, we observesignificant differences in the results for differentdependency relations, seeing that the statisticalparsers behave in a different manner regarding toeach relation, as shown in table 2.
The table showsthe differences in f-score2  corresponding to fivelocal dependency relations, (determination ofverbal modifiers, such as subject, object andindirect object).McDonald and Nivre (2007) examined the typesof errors made by the two data-driven parsers usedin this work, showing how the greedy algorithm ofMaltParser performed better with local dependencyrelations, while the graph-based algorithm of MSTwas more accurate for global relations.
As both thechunker and the partial dependency analyzer arebased on a set of local rules in the CG formalism,we could expect that the stacked parsers couldbenefit mostly on the local dependency relations.2 f-score = 2 * precision * recall / (precision + recall)MaltParser MST ParserLAS UAS LAS UASBaseline 76.77% 82.09%  77.96% 84.04%+ RBC 77.10% (+0.33) 82.29% (+0.20)  77.99% (+0.03) 83.99% (-0.05)+ RBDA *77.15% (+0.38) 82.27% (+0.18)  78.03% (+0.07) 83.76% (-0.28)+ RBC + RBDA  *77.25% (+0.48) 82.18% (+0.09)  78.00% (+0.04) 83.34% (-0.70)Table 1.
Evaluation results(RBC = rule-based chunker, RBDA = rule-based dependency analyzer, LAS: Labeled Attachment Score,UAS: Unlabeled Attachment Score, *: statistically significant in McNemar's test, p < 0.05)51Table 2 shows how the addition of the rule-basedparsers?
tags performs in accord with this behavior,as MaltParser gets f-score improvements for thelocal relations.
Although not shown in Table 2, wealso inspected the results on the long distancerelations, where we did not observe noticeableimprovements with respect to the baseline on anyparser.
For that reason, MaltParser, seems tomostly benefit of the local nature of the stackedfeatures, while MST does not get a significantimprovement, except for some local dependencyrelations, such as ncobj and ncsubj.We performed an additional test using the partialdependency analyzer?s gold dependency relationsas input to MaltParser.
As could be expected, thegold tags gave a noticeable improvement to theparser?s results, reaching 95% LAS.
However,when examining the scores for the outputdependency relations, we noticed that the goldpartial dependency tags are beneficial for somerelations, although negative for some others.
Forexample the non-clausal modifier (ncmod)relation?s f-score increases 3.25 points, while thedependency relation for clausal subordinatesentences functioning as indirect object decreases0.46 points, which is surprising in principle.For all those reasons, the relation between theinput dependency tags and the obtained resultsseems to be intricate, and we think that it deservesnew experiments in order to determine their nature.As each type of syntactic information can have animportant influence on the results on specificrelations, their study can shed light on novelschemes of parser combination.4.
ConclusionsWe have presented a preliminary effort to integratedifferent syntactic analyzers, with the objective ofgetting the best from each system.
Although thepotential gain is in theory high, the experimentshave shown very modest improvements, whichseem to happen in the set of local dependencyrelations.
We can point out some avenues forfurther research:?
Development of the rule-baseddependency parser using the dependenciesthat give better improvements on the golddependency tags, as this can measure theimpact of each kind of shallowdependency tag on the data-driven parsers.?
Development of rules that deal with thephenomena where the statistical parsersperform worse.
This requires a carefulerror analysis followed by a redesign ofthe manually developed CG tagging rules.?
Application of other types of combiningschemes, such as voting, trying to get thebest from each type of parser.Finally, we must also take into account that therule-based analyzers were developed mainlyhaving linguistic principles in mind, such ascoverage of diverse linguistic phenomena or thetreatment of specific syntactic constructions(Aranzabe et al, 2004), instead of performance-oriented measures, such as precision and recall.This means that there is room for improvement inthe first-stage knowledge-based parsers, which willhave, at least in theory, a positive effect on thesecond-phase statistical parsers, allowing us to testwhether knowledge-based and machine learning-based systems can be successfully combined.AcknowledgementsThis research was supported by the Department ofIndustry of the Basque Government (IT344-10, S-PE11UN114), the University of the BasqueCountry (GIU09/19) and the Spanish Ministry ofMaltParser MST ParserDependencyrelationBaseline + RBC + RBDA + RBC+ RBDABaseline + RBC + RBDA + RBC+ RBDAncmod 75,29 75,90 76,08 76,40 77,15 77,44 76,39 76,92ncobj 67,34 68,49 69,67 69,54 64,85 64,86 65,56 66,18ncpred 61,37 61,92 61,26 63,50 60,37 57,55 58,44 59,27ncsubj 61,92 61,90 63,96 63,91 59,19 59,26 62,23 61,61nciobj 75,76 76,53 77,16 76,29 74,23 74,47 72,16 69,08Table 2.
Comparison of the different parsers?
f-score with regard to specific dependency relations(ncmod = non-clausal modifier, ncobj = non-clausal object, ncpred = non-clausal predicate, ncsubj = non-clausal subject,nciobj = non-clausal indirect object)52Science and Innovation (MICINN, TIN2010-20218).ReferencesItziar Aduriz, Jos?
Mar?a Arriola, Xabier Artola,Arantza D?az de Ilarraza, Koldo Gojenola andMontse Maritxalar.
1997.
Morphosyntacticdisambiguation for Basque based on the ConstraintGrammar Formalism.
Conference on RecentAdvances in Natural Language Processing(RANLP), Bulgaria.Itziar Aduriz, Eneko Agirre, Izaskun Aldezabal, I?akiAlegria, Xabier Arregi, Jose Mari Arriola, XabierArtola, Koldo Gojenola, Montserrat Maritxalar, KepaSarasola, and Miriam Urkia.
2000.
A word-grammarbased morphological analyzer for agglutinativelanguages.
Coling 2000, Saarbrucken.Itziar Aduriz, Jos?
Mar?a Arriola, Arantza D?az deIlarraza, Koldo Gojenola, Maite Oronoz and LarraitzUria.
2004.
A cascaded syntactic analyser forBasque.
In Computational Linguistics and IntelligentText Processing, pages 124-135.
LNCS Series.Springer Verlag.
Berlin.
2004Itziar Aduriz, Maria Jesus Aranzabe, Jose MariaArriola, Aitziber Atutxa, Arantza Diaz de Ilarraza,Aitzpea Garmendia and Maite Oronoz.
2003.Construction of a Basque dependency treebank.Treebanks and Linguistic Theories.Mar?a Jes?s Aranzabe, Jos?
Mar?a Arriola and ArantzaD?az de Ilarraza.
2004.
Towards a DependencyParser for Basque.
In Proceedings of the Workshopon Recent Advances in Dependency Grammar,Geneva, Switzerland.Maria Jesus Aranzabe, Jose Maria Arriola and ArantzaD?az de Ilarraza.
2009.
Theoretical andMethodological issues of tagging Noun PhraseStructures following Dependency GrammarFormalism.
In Artiagoitia, X. and Lakarra J.A.
(eds)Gramatika Jaietan.
Patxi Goenagaren omenez.Donostia: Gipuzkoako Foru Aldundia-UPV/EHU.Kepa Bengoetxea and Koldo Gojenola.
2010.Application of Different Techniques to DependencyParsing of Basque.
Proceedings of the 1st Workshopon Statistical Parsing of Morphologically RichLanguages (SPMRL), NAACL-HLT Workshop.Kepa Bengoetxea, Arantza Casillas and KoldoGojenola.
2011.
Testing the Effect of MorphologicalDisambiguation in Dependency Parsing of Basque.Proceedings of the International Conference onParsing Technologies (IWPT).
2nd Workshop onStatistical Parsing Morphologically Rich Languages(SPMRL), Dublin, Ireland.G?lsen Eryi?it, Joakim Nivre and Kemal Oflazer.
2008.Dependency Parsing of Turkish.
ComputationalLinguistics, Vol.
34 (3).Nerea Ezeiza, I?aki Alegria, Jos?
Mar?a Arriola, Rub?nUrizar and Itziar Aduriz.
1998.
CombiningStochastic and Rule-Based Methods forDisambiguation in Agglutinative Languages.COLING-ACL?98, Montreal.Fred Karlsson, Atro Voutilainen, Juka Heikkila andArto Anttila.
1995.
Constraint Grammar: ALanguage-independent System for ParsingUnrestricted Text.
Mouton de Gruyter.Andr?
F. T. Martins, Dipanjan Das, Noah A. Smith andEric P. Xing.
2008.
Stacking Dependency Parsing.Proceedings of EMNLP-2008.Ryan McDonald, Kevin Lerman and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of ACL.Ryan McDonald, Kevin Lerman and Fernando Pereira.2006.
Multilingual dependency analysis with a two-stage discriminative parser.
In Proc.
CoNLL.Ryan McDonald and Joakim Nivre.
2007.Characterizing the Errors of Data-DrivenDependency Parsing Models.
Proceedings of the2007 Joint Conference on Empirical Methods inNatural Language Processing and ComputationalNatural Language Learning, EMNLP/CoNLL.Ryan McDonald and Joakim Nivre.
2011.
Analyzingand Integrating Dependency Parsers.
ComputationalLinguistics, Vol.
37(1), 197-230.Joakim Nivre.
2006.
Inductive Dependency Parsing.Springer.Joakim Nivre, Johan Hall, Sandra K?bler, RyanMcDonald, Jens Nilsson, Sebastian Riedel and DenizYuret.
2007a.
The CoNLL 2007 Shared Task onDependency Parsing.
Proceedings of EMNLP-CoNLL.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,G?lsen Eryi?it, Sandra K?bler, S. Marinov andEdwin Marsi.
2007b.
MaltParser: A language-independent system for data-driven dependencyparsing.
Natural Language Engineering.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependencyparsers.
Proceedings of ACL-2008.Kenji Sagae and Alon Lavie.
2006.
Parser Combinationby Reparsing.
Proceedings of the Human Language53Technology Conference of the North AmericanChapter of the ACL, pages 129?132, New York.Mihai Surdeanu and Christopher D. Manning.
2010.Ensemble Models for Dependency Parsing: Cheapand Good?
Proceedings of the Human LanguageTechnology Conference of the North AmericanChapter of the ACL.Pasi Tapanainen and Atro Voutilainen.
1994.
TaggingAccurately-Don?t guess if you know.
Proceedingsof the Conference on Applied Natural LanguageProcessing, ANLP?94.Alexander Yeh.
2000.
Using existing systems tosupplement small amounts of annotatedgrammatical relations training data.
Proceedings ofACL 2000.54
