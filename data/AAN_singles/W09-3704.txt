Proceedings of the 8th International Conference on Computational Semantics, pages 4?17,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsA computational account of comparativeimplicatures for a spoken dialogue agent?Luciana BenottiLORIA/INRIA, Francebenottil@loria.frDavid TraumICT/USC, USAtraum@ict.usc.eduAbstractComparative constructions are common in dialogue, especially innegotiative dialogue where a choice must be made between differentoptions, and options must be evaluated using multiple metrics.
Com-paratives explicitly assert a relationship between two elements along ascale, but they may also implicate positions on the scale especially ifconstraints on the possible values are present.
Dialogue systems mustoften understand more from a comparative than the explicit assertionin order to understand why the comparative was uttered.
In this paperwe examine the pragmatic meaning of comparative constructions froma computational perspective.1 IntroductionIt is a big challenge for computational semantics of dialogue that much ofthe meaning of an utterance is conveyed not just through the compositionalmeanings of the words themselves, but in relation to the situation in whichthe utterance is performed, including the background knowledge, commonground, goals, and ontologies of the participants.
A number of pragmaticprinciples have been proposed to bridge this gap, including Grice?s maxims(and the associated concepts of Implicature and Relevance)[6], Accommo-dation[12]and Bridging[2].
?This work was sponsored by the U.S. Army Research, Development, and EngineeringCommand (RDECOM).
Statements and opinions expressed do not necessarily reflect theposition or the policy of the United States Government, and no official endorsement shouldbe inferred.4While these principles can provide elegant explanations of how meaningcan be conveyed between people, they often require fairly strong assump-tions about the common knowledge between participants and the ontologiesthat this knowledge must be organized in.
There are two general prob-lems in developing computational accounts of these phenomena.
First, it issometimes difficult to specify the required knowledge and relationships in acomputational way, such that a reasoner given the input and context cancompute a particular, specific meaning as opposed to other possibilities thatare not as appropriate.
Second, even if the principles are sufficiently clear sothat a computational account can be formulated, there may still be a prob-lem providing a given computational dialogue system with the appropriateknowledge to carry out the inferences in a way that is congruent with humaninterpretations.
For a hand-constructed limited domain, the system designerwill often take shortcuts and represent only the knowledge that is necessaryto carry out and understand tasks in that domain.
These limitations oftenrender the dialogue system unable to reason about the domain in as muchdetail as a knowledgeable human would, but often this characterization issufficient for the purposes of the conversation.In this paper we examine one aspect of computational non-compositionalmeaning: the pragmatic meaning of comparative constructions.
Compara-tive constructions are common in dialogue, especially in negotiative dialoguewhere a choice must be made between different options, and options mustbe evaluated using multiple metrics.
Comparatives explicitly assert a rela-tionship between two elements along a scale, but they may also implicatepositions on the scale especially if either information about the position ofone of the compared items or constraints on the possible values are present.Dialogue systems must often understand more from a comparative than theexplicit assertion in order to understand why the comparative was uttered;why it is relevant to the dialogue.In the next section, we present linguistic background on comparativesand conversational implicature.
In section 3, we review some issues of howimplicatures play out in dialogue in which multiple participants are involved,and a listener can clarify a lack of understanding.
In section 4, we introducethe computational framework in which the present work is implemented.In section 5, we present extensions to this framework which provide thecomputational agents with the ability to understand implicatures arisingfrom comparatives.
In section 6 we evaluate this with respect to the scenarioof SASO-EN[15], in which an army captain, a doctor, and a town elderdiscuss the best location for a medical clinic.
Finally, we discuss relatedissues, remaining problems, and future work in Section 7.52 Linguistic backgroundIn this section we review some of the previous work on comparatives con-structions and conversational implicatures in order to establish the necessarytheoretical basis for the discussion on comparative implicatures in the restof the paper.2.1 Comparative constructionsIn the classical literature on semantics of natural language comparatives (seee.g.,[4]), comparative constructions such as (1) are analyzed as a relationbetween two degrees as in (2).
(1) Downtown is safer than the market.
(2) Degree to which downtown is safe > Degree to which the market issafe.The problem now, of course, is what a degree is and what are the prop-erties of the relation >.
Abstractly, a degree can be considered just as acollection of objects ?
the collection of those objects that share the samedegree with respect to a given property P .
These collections are defined asthe equivalence classes of the equivalence relation =P, which in turn is de-fined in terms of an order >Pamong objects.
The relation > among degreesis defined as a lifting of >Pto the set of equivalent classes of =P.
Finally,scales are defined in terms of degrees, a scale SPis a sequence of degrees ofP ordered by the relation >.Summing up then, once we know what >Pis for a property P we knowwhat degrees of P are and how to compare them on scale SP.
All is goodand well, but this approach assumes the relation >Pas given.
Such a strongassumption was already criticized by[9]and certainly cannot be made in adialogue system where information about the domain of discourse (in partic-ular, any order >Pfor a given property P ) is incomplete and is constructed(and negotiated) during the dialogue.
As dialogue system builders, the is-sue that interests us is, not so much how to determine the truth value of aparticular comparative utterance, but mainly how comparatives contributeto the construction of the information about the domain.
So, for our taskit is crucial to figure out ?where do scales come from?
?62.2 Conversational implicaturesModelling how listeners draw inferences from what they hear is a basicproblem for the theories of understanding natural language.
An importantpart of the information conveyed is inferred, as in the following classicalexample by Grice[6]:(3) A: I am out of petrol.B: There is a garage around the corner.
; B thinks that the garage is open and has petrol to sell.B?s answer conversationally implicates (;) information that is relevantto A.
In Grice?s terms, B made a relevance implicature, he would be floutingGrice?s maxim of relevance unless he believes that the garage is open.
Aconversational implicature (CI) is different from an entailment in that it iscancelable without contradiction (B can append material that is inconsistentwith the CI ?
?but I don?t know whether it?s open?).
Since the CI can becancelled, B knows that it does not necessarily hold and then both B orA are able to reinforce it (or negotiate it) without repetition.
CIs are non-conventional, they are not part of the conventional meaning of the words butcalculable from their utterance in context given the nature of conversationas a goal-oriented enterprise.Scalar implicatures are a type of CI that are particularly relevant tothis paper since they involve the use of scales, as comparatives do.
Theseimplicatures are inferred on the basis of the assumption that the speaker istrying to make his utterance sufficiently informative for the current purposesof the exchange.
A typical example is:(4) A is hungry (and B knows it).A: Did somebody eat the brownies that I bought this morning?B: Fred ate some of them.
; B thinks that Fred didn?t eat all of them, there are some left.Theories of scalar implicature have been deeply influenced by Horn?sdissertation work[8].
A Horn scale is an ordered sequence of expressionssuch as ?some,many,most, all?
and ?warm, hot, scalding?.
The recipe tocalculate the scalar implicature is the following.
The use of a weaker wordin the scale (such as some) implicates that (the speaker believes that) thestronger form (such as all) is not the case, as exemplified in (4).
However,there are cases in which such a recipe does not apply, such as in (5).7(5) A realizes that the brownies were injected with strychnine and suspectsthat somebody may have eaten from them (and B knows it).A: Did somebody eat the brownies that I bought this morning?B: Fred ate some of them.In this example the scalar implicature is (at the very least) less likely toarise, it?s not relevant for the current purposes of the exchange; it doesn?tmatter how many brownies Fred ate, he needs medical attention.
Comparing(4) and (5) we can see that conversational implicatures are affected by theconversational goals.
We believe this to be an starting point for answeringthe question left open in Section 2.1: ?Where do scales come from??
andwe will investigate it in next section.3 Comparative implicatures in dialogueIn this Section we are going to introduce comparative implicatures and todevelop two lines of thought introduced in the previous section, but now inthe context of dialogue.
First, we relate the cancellability and negotiabilityof CIs and clarification requests in dialogue.
It?s often controversial whethersomething is actually a CI or not (people sometimes have different intu-itions).
Dialogue provide us with an extra tools for identifying the partici-pants?
beliefs about implicatures: feedback and negotiation of CIs.
Listenerscan give both positive (e.g.
acknowledgements) and negative (e.g.
clarifi-cation requests) feedback about their understanding and the acceptabilityof utterances, which can shed light on how they interpret CIs.
Moreover,speakers can negotiate whether something is really implicated, or whetheran implicature is meant by the speaker.
We also investigate the fact thatconversational implicatures change when the conversational goals change.Conversational goals establish structure on the information that is beingdiscussed, determining which distinctions are relevant and which are not forthe a given interaction.3.1 ClarificationsIn dialogue, a useful way to spot content that was meant but not actuallysaid is to look at the kinds of dialogue feedback that is given.
Clarificationrequests are one important part of this - focusing on cases where the initiallistener is not sure of what the speaker means.
Here we use the phraseclarification requests in its broad sense, including all those questions thatwould not make sense without the previous utterance in the dialogue.8Many times the clarification requests make the implicatures explicit, thisis illustrated by the fact that the clarification request in (6) can follow Grice?sexample in (3).
(6) A: and you think it?s open?Here we present clarifications as a test that helps us identify not onlythe potential conversational implicatures but also the presuppositions in adialogue.
(7) is an example of a well studied case of inferrable content: thepresupposition triggered by definite descriptions.
In this exchange, A mightbelieve that the intended referent is salient for different reasons: because itwas mentioned before, because it?s bigger, etc.
If such a piece of informationis available to B then he will be able to infer the presupposition and addit to the conversational record.
Otherwise, B might well signal A that thepresupposition did not get through, like in (7).
(7) There are 100 cups on a table.A: Pick up THE cup.B: Which cup?
(I don?t know which one you are referring to.
)The presence of a conversational implicature must be capable of beingworked out, so the hearer might well inquire about them.
The speaker willhave to answer and support the implicature if he wants to get it added tothe common ground.
In[13], the authors present a study of the differentkinds of clarification requests (CRs) found in a dialogue corpus.
Their re-sults show that the most frequent CRs in their corpus (51.74%) are due toproblems with referring expressions (such as example (7)) and the secondmost common (22.17%) are examples like the following.
(8) A: Turn it on.B: By pushing the red button?Here, the CR made explicit a potential requirement for the performanceof the requested action.
By saying ?Turn it on?
A meant that B had topush the red button but this was not explicitly mentioned in the commanduttered by A.
Such an implicature can be inferred from knowledge about thetask (or in Clark terms, from knowledge about the interaction level of jointaction[3]).
From this examples it should be clear that implicated contentis a rich source of CRs.93.2 Goals and Contextual ScalesAs described in Section 2, comparative sentences explicitly claim an orderingof two items on a relevant scale.
However, with more context, a comparativecan implicate degrees on a scale as well.
If we know the degree of one ofthe items then we have a fixed range for the other item.
If this rangecontains only one possible degree, then the comparative also sets the degreefor this item.
In the simplest possible scale in which a comparative could beapplied, there are only two degrees, and a comparative indicates the degreesof each item even without more knowledge of the degrees of either item.
Forexample, consider (9) inspired by[5]:(9) B is drawing and A is giving instructions to B:A: Draw two squares, one bigger than the other.B: Done.A: Now, paint the small square blue and the big one red.
; A thinks that one of the squares can be described as small and theother as big.The question remains, however, of how the scales are selected?
Theseare not generalized implicatures that always arise.
Every time we say ?Fredis taller than Tom?
we don?t mean that ?Fred is tall?
and ?Tom is short?.As discussed in Section 2, conversational implicatures are affected by con-versational goals.
We believe that this is the path that we have to follow inorder to explain comparative implicatures as particularized implicatures.Predicates such as tall and small are vague in that they can refer todifferent ranges of a scale and in fact different scales.
Small refers to size,which as a default we might think of as a continuous scale measure, however,as in the example above, we might prefer to use a simpler scale.
Thisphenomena was already noticed by[7]who says:There is a range of structures we can impose on scales.
Thesemap complex scales into simpler scales.
For example, in muchwork in qualitative physics the actual measurement of some pa-rameter may be anything on the real line, but this is mappedinto one of three values ?
positive, zero, and negative.How are such structures over scales defined?
The intuitive idea is thatthe structure only distinguishes those values that are relevant for the goalsof the agent; that is when the attribute takes a particular value, it plays acausal role in deciding whether some agent?s goal can be achieved or not.10In the example above, we have only small and big as relevant values forsize, and a comparative in this context will implicate that we are using thisbinary scale as well as the degrees that each of the items of comparison have.4 Computational frameworkThe computational framework we have used for the implementation is theICT Virtual Human dialogue manager[14; 16].
This dialogue manager al-lows virtual humans to participate in bilateral or multiparty task-orientedconversations in a variety of domains, including teamand non-teamnegotiation.This dialogue manager follows the information state approach[11], with arich set of dialogue acts at different levels.
The dialogue manager is em-bedded within the Soar cognitive architecture[10], and decisions about in-terpreting and producing speech compete with other cognitive and physicaloperations.
When an utterance has been perceived (either from processing ofAutomatic Speech Recognizer and Natural Language Understanding (NLU)components which present hypotheses of context-independent semantic rep-resentations, or messages from self or other agents), the dialogue managerprocesses these utterances, making decisions about pragmatic informationsuch as the set of speech acts that this utterance performs as well as themeanings of referring expressions.
Updates are then performed to the in-formation state on the basis of the recognized acts.
The representations ofsemantic and pragmatic elements for questions and assertions are presentedin[14].
The semantic structure derives from the task model used for plan-ning, emotion and other reasoning.
(10a) shows an example proposition inthis domain, where propositions have an object id, an attribute, and a value(whose type is defined by the attribute).
(10b) shows an assertion speechact, with this proposition as content.
(10) a.
(<prop1> ?attribute safety ?object market ?type state ?value no)b.
(<da1> ?action assert ?actor doctor ?addressee captain ?content<prop1>)In the next section, we extend this framework to allow comparativepropositions and speech acts arising from implicatures of comparatives.5 Implementing comparative implicaturesWe have added an ability for the ICT dialogue manager to handle compara-tive constructions and comparative implicatures.
Some of the attributes in11the task model for a given domain will be scalar, where there is some impliedordering of the possible values.
This will not be the case for all attributes,for example, the location allows for different possible places that an entitycan be, but there is no scale among them.
For each scalar attribute, P , inthe task model of our domain, we can create a comparative attribute >Pthat will compare objects and values according to the designated scale forP .
(11a) means that X is higher on the P scale than Y.
In our system, whena comparative of the form ?X is P -er than Y ?
is uttered, the NLU gener-ates a semantic frame that has the structure shown in (11a).
The dialoguemanager will then create an assertion speech act as represented in (11b) andthen infer the conversational implicatures that arise.
(11) a.
(<prop1> ?attribute >P?object X ?type state ?value Y )b.
(<da1> ?action assert ?actor A ?addressee B ?content <prop1>)The comparative implicatures depend on both the nature of the scaleand the available information about the positions of the compared items.For the special case of a binary scale (e.g.
yes > no), the comparativeconstruction itself can generate multiple implicatures, as in (12).
(12) a.
By the definition of the scale S = ?no, yes?
and its association withthe attribute P then we know that, if <prop> ?attribute P ?valueV , then V ?
Sb.
As the utterance asserts (<prop1> ?attribute >P?object X ?valueY ), it is interpreted as asserting (<prop2> ?attribute P ?objectX ?value V 1) and (<prop3> ?attribute P ?object Y ?value V 2),where values V 1 and V 2 are not known but it is known that V 1 >V 2From (12a) we have that V 1 ?
S and V 2 ?
S, from (12b) we have thatV 1 > V 2.
Since S has 2 elements and yes > no, there is a unique valuationfor V 1 and V 2, namely V 1 = yes and V 2 = no.
Once the values of V 1and V 2 are determined the following two dialogue acts are generated aspart of the interpretation and reinserted in the dialogue manager cycle.
Theinformation state will not only be updated with the comparative assertion?X is P -er than Y ?
but also with the two following dialogue acts.
The firstone asserts that ?X is P?.
And the second one asserts that ?Y is not P?.
(13) (<prop2> ?attribute P ?object X ?type state ?value yes)(<da2> ?action assert ?actor A ?addressee B ?content <prop2>)12(14) (<prop3> ?attribute P ?object Y ?type state ?value no)(<da3> ?action assert ?actor A ?addressee B ?content <prop3>)This is the first part of the problem.
The question now is when andhow to update the information state with (13) and (14): before, at the sametime or after the explicit assertion (11b)); we will discuss these issues innext subsection.
Moreover, in some contexts the conversational implicaturecarried by the comparative will not get through, how are such informationstates recognized and what is done instead will be addressed in Section 7.5.1 When and how is the information state updated?When interpreting an utterance U that has a conversational implicature I,the dialogue manager needs to have accessible the content of the implicaturebefore generating a response.
The three approaches presented below makeexplicit the implicature in the dialogue, just as if its verbalization has beenuttered during the dialogue.
Since the inferred content is made explicit,these approaches can be seen as implementations of the Principle of ExplicitAddition[1]which applies both to accommodation of content that has beenlexically triggered (such as presuppositions) as well as content that has not(such as conversational implicatures).The after approach: A first approach is to add the inferred assertion Ias further input received by the dialogue manager once it finishedprocessing the utterance U .
The idea for the implementation is simple:just re-insert the frame of the inferred assertion(s) as an input to thedialogue manager, as if it had been uttered in the dialogue.At the same time: A second approach is to consider that a single asser-tion performs multiple speech acts.
The implementation of this optionin the current computational framework is also quite straightforwardbecause the framework already allows for multiple speech acts asso-ciated with an utterance and then the information state is correctlyupdated.The before approach: The third approach is to interrupt the processingof the explicit assertion U to update the information state first with theimplicature I.
Such an implementation requires significant changes tothe dialogue manager to interrupt processing on the current assertionand first interpret the inferred speech acts before re-interpreting.13The crucial difference among the three implementations is what contentwill be available in the information state when the rest of the content has tobe interpreted.
In the same time approach all the updates are independent,the information state does not contain the implicatures, nor the explicitassertion when interpreting any of them.
In the after approach, U is avail-able in the information state when interpreting I; by contrast, in the beforeapproach I is available when interpreting U .These differences are relevant when they interact with other parts of theinterpretation process, such as reference resolution.
Consider for instancethe following utterance:(15) A: I went to the hospital Saint-Joseph, the British clinic was too far.A: The doctor gave me some medicineThe utterance ?The doctor gave me some medicine?
would normallybe interpreted as implicating that A saw a doctor in the hospital Saint-Joseph.
In order to properly interpret this utterance, it?s important thatthe implicature is in the context before resolving the referring expression?the doctor?.
We leave for future work the interaction with other aspectsof interpretation, such as word sense disambiguation.6 A case-studyWe have evaluated the implementation in the context of the SASO-EN sce-nario[15], where both comparatives and binary scales are present in the taskmodel.
This domain contains over 60 distinct states that the agents con-sider as relevant for plan and negotiation purposes.
There are currently 11attributes used for this domain, 7 of which are binary scales and 4 of whichare non-scalar.
Adding the comparative implicature rules from the previoussection allows understanding of additional arguments that were not previ-ously dealt with adequately by the system.
Consider the following fragmentof a dialogue among the Captain (a human agent), the Elder and the Doctor(two virtual agents) about the location of a clinic.
(16) Captain: Doctor would you be willing to move the clinic downtown?Doctor: It is better to keep the clinic here in the marketplace.Captain: Well, downtown is safer than the marketElder: Why do you think that the market is not safe?During the interpretation of the comparative uttered by the Captain,the dialogue manager receives the following semantic frame:14(17) (<prop> ?attribute safer ?object downtown ?type state ?value mar-ket)Then the inferred rules developed in Section 5 are applied and the in-formation state is updated not only with an assertion of (17) but also withthe following two assertions:(18) (<prop1> ?attribute safety ?object downtown ?type state ?value yes)(<prop1> ?attribute safety ?object market ?type state ?value no)Since these propositions assert the fact that the market is not safe beforethe Elder generates a response, he can directly address and query the reasonfor one of these implicatures with ?why do you think that the market is notsafe?
?In the general case, we might have to reason about the appropriate scaleto use for this attribute, but in our domain, only one scale is relevant, sothis additional inference is not needed.Without the comparative implicature rules, neither the elder nor thedoctor would recognize that the captain is asserting something about thesafety of each of the locations and will not be able to properly assess theargument about desirability of moving the clinic.7 DiscussionAs mentioned in Section 3, the relevant information sources of a dialogue,such as the task model, shed light on how the scales that are relevant forcalculating implicatures should be constructed.
However, once comparativeimplicatures are inferred they interact with the structure of the dialoguein relevant ways.
When implicated assertions are already in the context,because they have been uttered before, the information state does not needto be updated again with them.If A says ?
and implicates ?
but A said ?
before in the dialogue thenthe context of the dialogue does not have to be updated again with ?.
Inthis case, we say that the implicature has been bound (to use standardterminology in the area) and the information state is not modified by it.The result is a coherent dialogue, a dialogue that gives the intuition of?continuing on the same topic or stressing the same point?
such as in thefollowing example:(19) Captain: the market is not safeCaptain: downtown is safer than the market15The point can be better illustrated when the two contributions are notmade by the same speaker.
In this case, A says ?
and B says ?
whichimplicates ?, then ?
has the effect of accepting ?
and adding it to thecommon ground.
This implements the intuition that, in (20), the elderseems to be supporting the captain in his claim that the market is not safe.
(20) Captain: the market is not safeElder: downtown is safer than the marketFinally, implicature cancellation is implemented in a simplistic way inthe current framework.
When A says ?
and implicates ?
but ??
is alreadyin the common ground, the implicature is simply ignored.Our implementation captures the intuition that the relevant values ofthe properties in a domain are those that are causally related to the agent?sgoals.
This is used in order to construct or locate appropriate scales andinfer useful implicatures that interact with the dialogue structure in differentways.
However, not all the predictions achieved by such an implementationare explainable and further refinement is needed.
Consider the followingdialogue:(21) C: Downtown is safer than the marketC: The US base is safer than downtownIf we apply the inference rules developed in Section 5 to this exchange,which implicature gets through will depend on the order in which the utter-ances in (21) are said.
If they are said in the order shown in (21) then theimplicature that downtown is safe will get through; if they are uttered inthe opposite order, then the implicature that downtown is not safe will getthrough.
We leave the study of these kinds of interactions to further work.It is clear that treating conversational implicatures in dialogue is a com-plex problem, and that it interacts in relevant ways with other key featuresof dialogue, namely positive and negative evidence of understanding.
It isimportant that the theory of implicatures acknowledges the fact that con-versational implicatures are a phenomena that arises in conversation andthat then needs to be studied in its environment to be fully understood.This paper starts by motivating this big picture, and then relates it to thesemantic theory of comparatives and the pragmatic theory of implicaturesin order to address the practical problem of comparative implicatures thatarises in an implemented dialogue agent.16References[1]D. Beaver and H. Zeevat.
Accommodation.
In The Oxford Handbook of Lin-guistic Interfaces, pages 503?539.
OUP, 2007.[2]H.
Clark.
Bridging.
In The 1975 Workshop on Theoretical issues in naturallanguage processing, pages 169?174.
ACL, 1975.[3]H.
Clark.
Using Language.
CUP, 1996.[4]M.
Cresswell.
The semantics of degree.
In Montague Grammar, 1976.[5]D.
DeVault and M. Stone.
Interpreting vague utterances in context.
In Proc.of COLING04, pages 1247?1253, 2004.[6]H.
Grice.
Logic and conversation.
In P. Cole and J. L. Morgan, editors, Syntaxand Semantics: Vol.
3: Speech Acts, pages 41?58.
AP, 1975.[7]J.
Hobbs.
Discourse and inference.
To appear.[8]L.
Horn.
On the semantic properties of logical operators in english.
PhD thesis,University of California Los Angeles (UCLA), 1972.[9]E.
Klein.
A semantics for positive and comparative adjectives.
Linguistics andPhilosophy, 4:1?45, 1980.[10]J.
Laird, A. Newell, and P. Rosenbloom.
SOAR: an architecture for generalintelligence.
AI, 33(1):1?64, September 1987.[11]S.
Larsson and D. Traum.
Information state and dialogue management in theTRINDI dialogue move engine toolkit.
Natural Language Engineering, 6:323?340, September 2000.[12]D.
Lewis.
Scorekeeping in a language game.
Journal of Philosophical Logic,8:339?359, 1979.[13]K.
Rodr?
?guez and D. Schlangen.
Form, intonation and function of clarificationrequests in german task oriented spoken dialogues.
In CATALOG04, pages101?108, 2004.[14]D.
Traum.
Semantics and pragmatics of questions and answers for dialogueagents.
In Proc.
of IWCS-5, pages 380?394, 2003.[15]D.
Traum, S. Marsella, J. Gratch, J. Lee, and A. Hartholt.
Multi-party,multi-issue, multi-strategy negotiation for multi-modal virtual agents.
InH.
Prendinger, J. Lester, and M. Ishizuka, editors, IVA, volume 5208 of LNCS,pages 117?130.
Springer, 2008.[16]D.
Traum, W. Swartout, J. Gratch, and S. Marsella.
A virtual human dialoguemodel for non-team interaction.
In L. Dybkjaer and W. Minker, editors, RecentTrends in Discourse and Dialogue.
Springer, 2008.17
