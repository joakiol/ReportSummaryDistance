Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 301?304,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsImproving Phrase-Based Translation with Prototypes of Short PhrasesFrank Liberato?, Behrang Mohit?, Rebecca Hwa??
?Department of Computer Science ?Intelligent Systems ProgramUniversity of Pittsburgh{frank,behrang,hwa@cs.pitt.edu}AbstractWe investigate methods of generating addi-tional bilingual phrase pairs for a phrase-based decoder by translating short sequencesof source text.
Because our translation taskis more constrained, we can use a model thatemploys more linguistically rich features thana traditional decoder.
We have implementedan example of this approach.
Experimental re-sults suggest that the phrase pairs produced byour method are useful to the decoder, and leadto improved sentence translations.1 IntroductionRecently, there have been a number of successfulattempts at improving phrase-based statistical ma-chine translation by exploiting linguistic knowledgesuch as morphology, part-of-speech tags, and syn-tax.
Many translation models use such knowledgebefore decoding (Xia and McCord, 2004) and dur-ing decoding (Birch et al, 2007; Gimpel and Smith,2009; Koehn and Hoang, 2007; Chiang et al, 2009),but they are limited to simpler features for practi-cal reasons, often restricted to conditioning left-to-right on the target sentence.
Traditionally, n-bestrerankers (Shen et al, 2004) have applied expen-sive analysis after the translation process, on boththe source and target side, though they suffer frombeing limited to whatever is on the n-best list (Hasanet al, 2007).We argue that it can be desirable to pre-translateparts of the source text before sentence-level decod-ing begins, using a richer model that would typicallybe out of reach during sentence-level decoding.
Inthis paper, we describe a particular method of gen-erating additional bilingual phrase pairs for a newsource text, using what we call phrase prototypes,which are are learned from bilingual training data.Our goal is to generate improved translations of rel-atively short phrase pairs to provide the SMT de-coder with better phrasal choices.
We validate theidea through experiments on Arabic-English trans-lation.
Our method produces a 1.3 BLEU score in-crease (3.3% relative) on a test set.2 ApproachRe-ranking tends to use expensive features of the en-tire source and target sentences, s and t, and align-ments, a, to produce a score for the translation.
Wewill call this scoring function ?
(s, t, a).
While ?(?
)might capture quite a bit of linguistic information, itcan be problematic to use this function for decodingdirectly.
This is due to both the expense of com-puting it, and the difficulty in using it to guide thedecoder?s search.
For example, a choice of ?(?)
thatrelies on a top-down parser is difficult to integrateinto a left-to-right decoder (Charniak et al, 2003).Our idea is to use an expensive scoring functionto guide the search for potential translations for partof a source sentence, S, even if translating all of itisn?t feasible.
We can then provide these transla-tions to the decoder, along with their scores, to in-corporate them as it builds the complete translationof S. This differs from approaches such as (Och andNey, 2004) because we generate new phrase pairs inisolation, rather than incorporating everything intothe sentence-level decoder.
The baseline system isthe Moses phrase-based translation system (Koehn301et al, 2007).2.1 Description of Our Scoring FunctionFor this work, we consider a scoring function basedon part-of-speech (POS) tags, ?POS(?).
It oper-ates in two steps: it converts the source and targetphrases, plus alignments, into what we call a phraseprototype, then assigns a score to it based on howcommon that prototype was during training.Each phrase pair prototype is a tuple containingthe source prototype, target prototype, and align-ment prototype, respectively.
The source and tar-get prototypes are a mix of surface word forms andPOS tags, such as the Arabic string ?NN Al JJ?,or the English string ?NN NN?.
For example, thesource and target prototypes above might be used inthe phrase prototype ?NN0 Al JJ1 , NN1 NN0?,with the alignment prototype specified implicitly viasubscripts for brevity.
For simplicity, the alignmentprototype is restricted to allow a source or targetword/tag to be unaligned, plus 1:1 alignments be-tween them.
We do not consider 1:many, many:1, ormany:many alignments in this work.For any input ?s, t, a?, it is possible to con-struct potentially many phrase prototypes from it bychoosing different subsets of the source and targetwords to represent as POS tags.
In the above ex-ample, the Arabic determiner Al could be convertedinto an unaligned POS tag, making the source pro-totype ?NN DT JJ?.
For this work, we convert allaligned words into POS tags.
As a practical con-cern, we insist that unaligned words are always keptas their surface form.
?POS(s, t, a) assign a score based on the proba-bility of the resulting prototypes; more likely proto-types should yield higher scores.
We choose:?POS(s, t, a) = p(SP,AP |TP ) ?
p(TP,AP |SP )where SP is the source prototype constructed froms, t, a.
Similarly, TP and AP are the target andalignment prototypes, respectively.To compute ?POS(?
), we must build a model foreach of p(SP,AP |TP ) and p(TP,AP |SP ).
To dothis, we start with a corpus of aligned, POS-taggedbilingual text.
We then find phrases that are consis-tent with (Koehn et al, 2003).
As we extract thesephrase pairs, we convert each into a phrase proto-type by replacing surface forms with POS tags forall aligned words in the prototype.After we have processed the bilingual trainingtext, we have collected a set of phrase prototypesand a count of how often each was observed.2.2 Generating New PhrasesTo generate phrases, we scan through the source textto be translated, finding any span of source wordsthat matches the source prototype of at least onephrase prototype.
For each such phrase, and for eachphrase prototype which it matches, we generate alltarget phrases which also match the target and align-ment prototypes.To do this, we use a word-to-word dictionary togenerate all target phrases which honor the align-ments required by the alignment prototype.
For eachsource word which is aligned to a POS tag in the tar-get prototype, we substitute all single-word transla-tions in our dictionary1.For each target phrase that we generate, we mustensure that it matches the target prototype.
We giveeach phrase to a POS tagger, and check the resultingtags against any tags in the target prototype.
If thereare no mismatches, then the phrase pair is retainedfor the phrase table, else it is discarded.
In the lattercase, ?POS(?)
would assign this pair a score of zero.2.3 Computing Phrase WeightsIn the Moses phrase table, each entry has four pa-rameters: two lexical weights, and the two condi-tional phrase probabilities p(s|t) and p(t|s).
Whilethe lexical weights can be computed using the stan-dard method (Koehn et al, 2003), estimating theconditional phrase probabilities is not straightfor-ward for our approach because they are not ob-served in bilingual training data.
Instead, we esti-mate the maximum conditional phrase probabilitiesthat would be assigned by the sentence-level decoderfor this phrase pair, as if it had generated the tar-get string from the source string using the baselinephrase table2.
To do this efficiently, we use some1Since we required that all unaligned target words are keptas surface forms in the target prototype, this is sufficient.
If wedid not insist this, then we might be faced with the unenviabletask of choosing a target languange noun, without further guid-ance from the source text.2If we use these probabilities for our generated phrase pair?sprobability estimates, then the sentence-level decoder would see302simplifying assumptions: we do not restrict how of-ten a source word is used during the translation, andwe ignore distortion / reordering costs.
These admita simple dynamic programming solution.We must also include the score from ?POS(?
), togive the decoder some idea of our confidence in thegenerated phrase pair.
We include the phrase pair?sscore as an additional weight in the phrase table.3 Experimental SetupThe Linguistic Data Consortium Arabic-Englishcorpus23 is used to train the baseline MT system(34K sentences, about one million words), and tolearn phrase prototypes.
The LDC multi-translationArabic-English corpus (NIST2003)4 is used for tun-ing and testing; the tuning set consists of the first500 sentences, and the test set consists of the next500 sentences.
The language model is a 4-grammodel built from the English side of the parallel cor-pus, plus the English side of the wmt07 German-English and French-English news commentary data.The baseline translation system is Moses (Koehnet al, 2007), with the msd-bidirectional-fereordering model.
Evaluation is done using theBLEU (Papineni et al, 2001) metric with four ref-erences.
All text is lowercased before evaluation;recasing is not used.
We use the Stanford ArabicPOS Tagging system, based on (Toutanova et al,2003)5.
The word-to-word dictionary that is used inthe phrase generation step of our method is extractedfrom the highest-scoring translations for each sourceword in the baseline phrase table.
For some closed-class words, we use a small, manually constructeddictionary to reduce the noise in the phrase table thatexists for very common words.
We use this in placeof a stand-alone dictionary to reduce the need foradditional resources.4 ExperimentsTo see the effect on the BLEU score of the result-ing sentence-level translation, we vary the amountof bilingual data used to build the phrase prototypes.
(approximately) no difference between building the generatedphrase using the baseline phrase table, or using our generatedphrase pair directly.3Catalogue numbers LDC2004T17 and LDC2004T184Catalogue number: LDC2003T185It is available at http://nlp.stanford.edu/software/tagger.shtml0.36 0.37 0.38 0.39 0.4 0.41 0.420 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1BLEUPercentage of Generated Phrases in Phrase Table# Bilingual TrainingSentencesEffectof Biligual Data onArabic Development SetBaseline BLEUOur Approach BLEU% GeneratedPhrasesFigure 1: Bilingual training size vs. BLEU score (mid-dle line, left axis) and phrase table composition (top line,right axis) on Arabic Development Set.
The baselineBLEU score (bottom line) is included for comparison.As we increase the amount of training data, we ex-pect that the phrase prototype extraction algorithmwill observe more phrase prototypes.
This will causeit to generate more phrase pairs, introducing bothmore noise and more good phrases into the phrasetable.
Because quite a few phrase prototypes arebuilt in any case, we require that each is seen atleast three times before we use it to generate phrases.Phrase prototypes seen fewer times than this are dis-carded before phrase generation begins.
Varying thisminimum support parameter does not affect the re-sults noticeably.The results on the tuning set are seen in Figure 1.The BLEU score on the tuning set generally im-proves as the amount of bilingual training data is in-creased, even as the percentage of generated phrasesapproaches 100%.
Manual inspection of the phrasepairs reveals that many are badly formed; this sug-gests that the language model is doing its job in fil-tering out disfluent phrases.Using the first 5,000 bilingual training sentencesto train our model, we compare our method to thebaseline moses system.
Each system was tuned viaMERT (Och, 2003) before running it on the test set.The tuned baseline system scores 38.45.
Includingour generated phrases improves this by 1.3 points to39.75.
This is a slightly smaller gain than exists inthe tuning set experiment, due in part that we did not303run MERT for experiment shown in Figure 1.5 DiscussionAs one might expect, generated phrases bothhelp and hurt individual translations.
A sentencethat can be translated starting with the phrase?korea added that the syrian primeminister?
is translated by the baseline system as?korean | foreign minister | added |that | the syrian?.
While ?the syrianforeign minister?
is an unambiguous sourcephrase, the baseline phrase table does not include it;the language and reordering models must stitch thetranslation together.
Ours method generates ?thesyrian foreign minister?
directly.Generated phrases are not always correct.
Forexample, a generated phrase causes our system tochoose ?europe role?, while the baseline sys-tem picks ?the role of | europe?.
Whilethe same prototype is used (correctly) for reorderingArabic ?NN0 JJ1?
constructs into English as ?NN1NN0?
in many instances, it fails in this case.
The lan-guage model shares the blame, since it does not pre-fer the correct phrase over the shorter one.
In con-trast, a 5-gram language model based on the LDCWeb IT 5-gram counts6 prefers the correct phrase.6 ConclusionWe have shown that translating short spans of sourcetext, and providing the results to a phrase-basedSMT decoder can improve sentence-level machinetranslation.
Further, it permits us to use linguisti-cally informed features to guide the generation ofnew phrase pairs.AcknowledgementsThis work is supported by U.S. National Science Foun-dation Grant IIS-0745914.
We thank the anonymous re-viewers for their suggestions.ReferencesA.
Birch, M. Osborne, and P. Koehn.
2007.
CCG su-pertags in factored statistical machine translation.
InProc.
of the Second Workshop on SMT.6Catalogue number LDC2006T13.E.
Charniak, K. Knight, and K. Yamada.
2003.
Syntax-based language models for statistical machine transla-tion.
In Proceedings of MT Summit IX.D.
Chiang, K. Knight, and W. Wang.
2009.
11,001 newfeatures for statistical machine translation.
In NAACL?09: Proceedings of Human Language Technologies:The 2009 Annual Conference of the North AmericanChapter of the Assoc.
for Computational Linguistics.K.
Gimpel and N.A.
Smith.
2009.
Feature-rich transla-tion by quasi-synchronous lattice parsing.
In Proc.
ofEMNLP.S.
Hasan, R. Zens, and H. Ney.
2007.
Are very large n-best lists useful for SMT?
Proc.
NAACL, Short paper,pages 57?60.P.
Koehn and H. Hoang.
2007.
Factored translationmodels.
In Proceedings of the 2007 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 868?876.P.
Koehn, F.J. Och, and D. Marcu.
2003.
Statisti-cal phrase-based translation.
In Proceedings of the2003 Conference of the North American Chapter of theAssociation for Computational Linguistics on HumanLanguage Technology-Volume 1, page 54.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, et al 2007.
Moses: Opensource toolkit for statistical machine translation.
InAnnual meeting-Association for Computational Lin-guistics, volume 45, page 2.F.
J. Och and H. Ney.
2004.
The alignment templateapproach to statistical machine translation.
Computa-tional Linguistics, 30(4):417?449.F.J.
Och.
2003.
Minimum error rate training in statisti-cal machine translation.
In Proc.
of the 41st AnnualMeeting on Assoc.
for Computational Linguistics.K.
Papineni, S. Roukos, T. Ward, and W.J.
Zhu.
2001.Bleu: a method for automatic evaluation of machinetranslation.
In Proc.
of the 40th Annual Meeting ofAssociation for Computational Linguistics.L.
Shen, A. Sarkar, and F.J. Och.
2004.
Discrimina-tive reranking for machine translation.
In Proceedingsof the Joint HLT and NAACL Conference (HLT 04),pages 177?184.K.
Toutanova, D. Klein, C. D. Manning, and Y. Singer.2003.
Feature-rich part-of-speech tagging with acyclic dependency network.
In NAACL ?03: Proceed-ings of the 2003 Conference of the North AmericanChapter of the Association for Computational Linguis-tics on Human Language Technology.F.
Xia and M. McCord.
2004.
Improving a statistical mtsystem with automatically learned rewrite patterns.
InCOLING ?04: Proceedings of the 20th internationalconference on Computational Linguistics.304
