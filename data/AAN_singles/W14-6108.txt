First Joint Workshop on Statistical Parsing of Morphologically Rich Languagesand Syntactic Analysis of Non-Canonical Languages, pages 82?89 Dublin, Ireland, August 23-29 2014.Initial Explorations in Two-phase Turkish Dependency Parsing byIncorporating Constituents?Ilknur Durgar El-Kahlout Ahmet Afs?
?n Ak?nT ?UB?ITAK-B?ILGEMGebze, KOCAEL?I{ilknur.durgar,akin.ahmet,yilmaz.ertugrul}@tubitak.gov.trErtug?rul Y?lmazAbstractThis paper describes a two-phase Turkish dependency parsing which separates dependency andlabeling into two similar to (McDonald et al., 2006b).
First, in order to solve the long distance de-pendency attachment problem, the sentences are split into constituents and the dependencies areestimated on shorter sentences.
Later, for better estimation of labels, Conditional Random Fields(CRFs) are used with previously learned chunk and several dependency and morphosyntacticfeatures.
Finally, a post-processing step is applied to ?correct?
some of labels, if necessary.1 IntroductionDependency parsing, a well-studied problem in natural language processing, is the task of forming adependency tree by attaching each word of a sentence (dependent) to another word in the same sentence(head) with a label that describes the dependency relation between these words.
In the last decade, thedata-driven dependency parsing approaches (Nivre et al., 2007; McDonald et al., 2006a) have received aconsiderable attention as it learns solely from labeled data and can be rapidly adapted to new languagesand domains.The accuracy of a dependency parser is negatively affected by two factors, among possibly others.First, a parser?s accuracy is sensitive to sentence length (McDonald and Nivre, 2007).
As the parserstend to assign dependencies in relatively short distances (Nivre et al., 2006), long sentences are noteasy to parse correctly.
Second, wrong labels that are assigned to correct dependencies result in labeledaccuracy drop.In data-driven dependency parsing approaches (Nivre et al., 2007; McDonald et al., 2006a), the de-pendencies and labels are often learned at the same time.
To our best knowledge, the work by McDonaldet al.
(2006b) is unique in that it learns the dependencies and labels in two separate stages.
In this paper,we present a two-phase data-driven dependency parsing of Turkish that addresses the above-mentionedproblems in consecutive steps.In order to solve the long distance dependency attachment problem, we first split sentences into theirconstituents.
For each constituent, we construct a sub-sentence by appending the verb group of theoriginal sentence to the end of the constituent.
We then parse all these short sentences by the MaltParser(Nivre et al., 2007) which is trained with Turkish specific parameters (Eryig?it et al., 2008).
Finally, wecombine the generated sentences to form the original sentence with full dependencies.For the labeling problem, we use a CRF-based (Lafferty et al., 2001) approach with the use of chunkinformation and parser output for identifying dependencies.
On top of our CRF-based labeling approach,we also apply a post-processing step to correct dependency labels if necessary.
Our methodology im-proves the state-of-the-art Turkish dependency parsing (Eryig?it et al., 2008) with a 1.7% increase in thelabeled attachment score (ASL) and 0.4% increase in the unlabeled attachment score (ASU ).There are several related research on incorporating different features during the parsing such as chunk(Attardi and Dell?Orletta, 2008) and causal (Gadde et al., 2010) and morphosyntactic features (Ambatiet al., 2010).
Our works differs from several aspects; first, instead of using the chunk information as aThis work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedingsfooter are added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/82Short Mid LongGold 3188 506 815MaltParser 3268/2881 498/298 743/537Table 1: The Dependency Distance Statistics of the Validation Set.feature in the parsing, we used the chunk information as a preprocessing step to split the sentences into?shorter?
ones and in the second step of parsing while estimating the labels.
Second, as an addition to theword?s morphosyntactic features, we employed the morphosyntactic features of the head word for eachtoken again in label estimation step.2 Turkish Dependency ParsingTurkish, a member of the Turkic languages, is an agglutinative language with very productive inflectionaland derivational morphology.
From the dependency point of view, Turkish is generally a head-finallanguage.
The dependency relation arcs are formed from left to right and do not cross each other exceptin some rare cases (Oflazer et al., 2003).
The first investigations on a Turkish dependency parser wasdone by Oflazer (Oflazer, 2003).
Following this grammar-based work, Turkish dependency parsing wasinvestigated by Eryig?it et al.
(Eryig?it et al., 2008) where the impact of morphological units on differenttypes of parsers was explored.
This study showed that the correct dependency representation of a Turkishsentence should use root words and inflectional groups (IGs)1 instead of the whole words themselves.The best performing Turkish dependency parsing is obtained via the data-driven MaltParser (Nivre et al.,2007) by using Turkish-specific features.For training the parser, we used the Turkish dependency treebank (Oflazer et al., 2003) that is alsoused in CoNLL-X (Buchholz and Marsi, 2006)2.
The treebank corpus contains several features includingword, lemma, POS, coarse POS3, and IGs that reflect the morphological structure of Turkish.Recently, Turkish dependency parsing was improved with the use of multiword expressions (Eryig?itet al., 2011) and the effects of automatic morphological analyzer and disambiguation were explored(Eryig?it, 2012).To show that the transition-based dependency parsers are in favor of identifying dependencies in shortdistances, we examined the dependency attachments of the MaltParser with respect to distance on theITU validation set (Eryig?it, 2007)4.
We classified the dependency attachments into three categories withrespect to the number of words that occur between the attached words: i) Short, dependency attachmentsat a distance of 1 or 2 words, ii) Mid, dependency attachments at a distance between 3 and 6 words, andiii) Long, dependency attachments at a distance of 6 or more words.
Table 2 shows the comparison of thedistances in the gold data and in the attachments identified by the dependency parser for the validationset (all/correct attachments).
As can be seen from the results, the Turkish dependency parser assigns66% of the ?correct?
long distance attachments and 58% of the mid distance attachments that appear inthe gold data.3 Incorporating Constituents as a Preprocessing StepA constituent is a group of words that behave as a single unit from the structural and meaning views.
Con-stituents can be ommitted in the sentence without influencing the sentence gramaticality.
Constituentsare the word groups that we can be found by asking the questions ?who/what?, ?when?, ?where?, etc.to the verb constituent.
Most frequent Turkish constituents can be listed as Subject, Sentence (Verb),Object, and Adjunct.
The main constituent of a sentence is its verb and other constituents can form a1To represent the morphology, words are separated at the derivational boundaries.
The inflectional morphemes with deriva-tion (or the root word for the first IG) are called as inflectional groups.2Shared Task on Multilingual Dependency Parsing3The Turkish morphological analyzer gives a two-layered POS information such as Noun+Proper and Num+Ordinal.
Thecoarse POS is the first part of this POS information.
In the absence of the second layer, the POS is the coarse POS.4This set was used as the test set in this work.83?teleme i?leminde   kuyrukta bekleyen eleman      y??
?na        itilir     .
(during the shifting process) (the element in the queue) (onto the stack) (is pushed) (.)WHEN?
WHERE?WHAT?1.
?teleme i?leminde itilir .2. kuyrukta bekleyen eleman itilir .3.
y??
?na itilir .VERB(pushed during the shifting process .
)(the element in the queue is pushed .
)(pushed onto the stack .
)(a) Constituent Chunking(b) Generating Short SentencesFigure 1: Constituent Chunking and Generation of Shorter Sentences.sentence with the presence of the verb.
Every word in a constituent is dependent to a word within theconstituent except the head word of the constituent.
Head word of the constituent is dependent to theverb.
Any constituent becomes an ungrammatical and meaningless structure if its head word is removed.Figure 1 illustrates the chunking process for the sentence ?Oteleme1 is?leminde2 kuyrukta3 bekleyen4eleman5 y?g?
?na6 itilir7 (The element5 in3 the3 queue3 is7 pushed7 onto6 the6 stack6 during2 the1shifting1 process2).
This sentence contains four constituents sequentially, Locative.Adjunct, Subject,Dative.Adjunct and finally (Sentence/Verb).
One can observe by dropping the head word is?leminde inthe Locative.Adjunct constituent, contituent looses its meaning completely.
Each of these constituents(except the verb) are ?phrases?
alone and can form a sentence only with the verb chunk.
After drop-ping any constituent (again except the verb), for example the Subject, the sentence is still a grammaticalTurkish sentence as ?Oteleme is?leminde y?g?
?na itilir.
(is pushed onto the stack during the shifting process.
)In our work, we used the Turkish dependency treebank and ITU validation test set which is enrichedwith the chunk information (Durgar El-Kahlout and Ak?n, 2013).
The chunker is reported to work withan F-measure 91.95 for verb chunks and 87.50 for the other chunks.
In that work, only verb chunksare labeled separately and the other chunks are labeled with the same type such as [CHUNK ?Otelemeis?leminde] [CHUNK kuyrukta bekleyen eleman] [CHUNK y?g?
?na] [VERB itilir] .3.1 ProcedureBefore the parsing process, we split each sentence of the test set into their constituents.
The idea be-hind splitting sentences was to create synthetically shorter sentences in order to make the dependencyparsing task easier by ?shortening?
long distance dependencies.
For each constituent, we generated asub-sentence by appending the verb to the end of the constituent.
As a result, we generated n ?
1 newsentences from a sentence with n constituents.
Part (b) of Figure 1 illustrates the generation of shortersentences from the chunked sentence shown in part (a) of the same figure.
Each of these shorter sen-tences are grammatical for Turkish.
The shorter sentences contains only the dependencies within theconstituent and the dependencies of the constituent to the verb constituent.After splitting the original sentence into a number of shorter sentences, each of these sentences areparsed by the MaltParser in order to obtain the dependencies.
Finally, these parsed sentences werecombined into a whole in such a way that the original sentence was generated back with identifieddependency relations.Splitting complex sentences with more than one verb group was not trivial.
We classified these sen-tences into two groups; complex sentences with two verb groups and complex sentences with more thantwo verb groups.
For the first case, the last verb group was considered as the dominating one and thesentence was splitted according to this verb group.
In this work, we didn?t split sentences that belong tothe second group and kept them as whole sentences in our experiments.Figure 2 illustrates a sample Turkish sentence, its dependency parse generated by the MaltParser (part(a)), and the gold parse (part (b)) of the sentence.
As can be seen from this example, the parser mistakenlyattaches the word ?is?leminde?
to the word ?bekleyen?
(shown with a dotted link in part (a)).
The figurealso shows the parses of the shorter sentences generated from this sentence (part (c)).
The generationof the original sentence from the parses of shorter sentences (part (d)) are also given in the figure.
Itis noteworthy to mention that splitting the original sentence and parsing shorter sentences individuallyenables the parser to find the correct attachment of the word ?is?leminde?
to the verb ?itilir?
(as is in the84?tele +me bekle +yeni?leminde kuyrukta eleman y??
?na it +ilir .DERIV CLASSIFIERLOC.ADJLOC.ADJDAT.ADJSUBJECTDERIVSENTDERIV MODIFIER?tele +me bekle +yeni?leminde kuyrukta eleman y??
?na it +ilir .DERIV CLASSIFIER LOC.ADJDAT.ADJSUBJECTDERIVSENTDERIV MODIFIERLOC.ADJit +ilir .DERIVSENT?tele +me i?lemindeDERIV CLASSIFIERbekle +yenkuyrukta eleman it +ilir .LOC.ADJSUBJECTDERIVSENTDERIV MODIFIERLOC.ADJy??
?na it +ilir .DAT.ADJDERIVSENT(a) MaltParser output(b) Gold Parse(c) Parses of "Short" SentencesSUBJECT?tele +me bekle +yeni?leminde kuyrukta eleman y??
?na it +ilir .DERIV CLASSIFIER LOC.ADJDAT.ADJDERIVSENTDERIV MODIFIERLOC.ADJ(d) Generation of the Original SentenceFigure 2: An Example of the Dependency Parsing by Chunks.Distance Original Sents.
Gold Chunks Our Approachprec.
recall prec.
recall prec.
recall1 90.47 94.06 89.58 95.45 89.91 95.362 75.29 76.48 75.10 79.10 74.32 80.083 ?
6 70.72 70.43 73.61 73.16 71.75 70.30> 6 79.48 60.86 92.91 60.88 88.43 58.32Table 2: Precision and Recall Scores Relative to the Head Distance.gold output part (b)).3.2 ResultsFor our evaluations, we used the evaluation tool distributed with the MaltParser.
The performance ofa dependency parser is mainly evaluated with three scores; the labeled attachment score (ASL); theunlabeled attachment score (ASU ) and the label accuracy score (LA).
We conducted experiments bothon the chunked sentences using Turkish constituent chunker (Durgar El-Kahlout and Ak?n, 2013) andgold chunks as described in Section 3.1.Table 2 compares the precision and recall scores of the MaltParser output with original sentencesand our approach relative to the dependency attachment distance.
The results showed that dependencyparsing with the use of constituent chunks increased the recall for all distance lengths (i.e., up to 6 points)and improved the precision approximately 3 points for dependency distances between 3 and 6 words andmore than 13 points for dependency distances more than 6 words.To see the effects of sentence lengths on parsing performance, we split sentences relative to theirlengths (i.e., 1-8, 9-15, 16-30, and >30) and reported the scores with respect to different length groups.Table 3 shows the parser performance depending on sentence lengths.
The results showed that ASUwas improved up to 1.5 points for all sentence lengths.
For shorter sentences, the ASL was relativelyworse than the parses of original sentences but for longer sentences the performance was better with thegold chunks.
For the chunker output, performance slightly better for sentences with 16 to 30 words forthe chunker chunks.
It is particularly noteworthy to mention that the labeling (the label accuracy result)was worse than the parses of original sentences for all sentence lengths.
Our approach in a second step85# of # of Original Sents.
Gold Chunks Our ApproachTokens Sentences ASL ASU LA ASL ASU LA ASL ASU LA1 ?
8 57 79.85 88.81 83.96 79.10 90.30 82.46 79.48 90.30 82.099 ?
15 130 76.48 83.18 86.31 75.76 84.62 84.62 74.96 83.29 84.3516 ?
30 99 67.48 76.55 80.76 68.20 77.17 80.55 67.84 76.63 81.26> 30 14 68.73 76.98 82.82 69.07 78.69 82.13 66.67 76.98 80.76all 300 71.95 79.90 83.28 72.05 81.23 82.37 71.40 80.23 82.44Table 3: Evaluation Relative to the Sentence Lengths.improved the label accuracy as described in Section 4.4 Relabeling the parser outputIn the parses of original sentences5, we observed that the intersection of the correct dependencies (2461)and the correct labels (2565) is only 2216 out of 30806 attachments.
This shows us that approximately10% of the correct dependencies are missed because of the wrong labels; this causes an accuracy drop inthe ASL score.Assigning dependency labels can be approximated as a sequential labeling task for Turkish with theprojectivity assumption, where the dependency tags are associated with every token in a sequence oftokens (Ramshaw and Marcus, 1995).
Adding features of the head word?s (that is learnt in the previousstep) can be included to each token to create syntetically sequential data.To assign the labels, we used CRFs (Lafferty et al., 2001) which became the state-of-the-art frameworkfor several labeling tasks such as text segmentation, named entity recognition, part of speech tagging, andshallow parsing.
They are shown to outperform the probabilistic models such as HMMs (Church, 1988;Freitag and McCallum, 2000) and MEMMs (McCallum et al., 2000) in several sequential assignmenttasks.4.1 FeaturesTo model the label attachment problem with CRFs, we used four types of features; i) baseline features:the set of features that exists in the Turkish dependency treebank, ii) morphological features: the featuresthat are split from the IG information, iii) dependency features: features that are extracted from the firstphase of the dependency parsing, and iv) chunk features: the features from the chunk annotation.
Thefull set of features that are used in the dependency labeling task are as follows:?
Baseline Features: Word, Lemma, The main POS of the word (CPOS), The second layer ofthe POS information of the word (POS), The combined inflectional morpheme information of theword?s last inflectional group (IG)7.?
Morphological Features: The case of the word when its POS is Noun or Pronoun (CASE).
Thefeature can take the values Acc, Dat, Nom, Loc, or Abl8.?
Dependency Features: The word?s distance to its head (DIST); If the word is attached to a headwithin a distance of one or two words then the distance is short, otherwise it is long, Head wordCPOS (HCPOS), lemma of the word?s head (HLEM).?
Chunk Features: Chunk type (ChnkTYPE), Chunk type is Verb for the sentence/verb chunks andRegular for the rest of the chunks.
The chunk type is Undefined if the token is not assigned to anychunk.5The situation is more or less same in the output of our approach.6This excludes the derivation and punctuation tokens.7To represent the morphology, words are separated at the derivational boundaries.
The inflectional morphemes with deriva-tion (or the root word for the first IG) are called as inflectional groups.8The Case information also exists in the IG feature but combined with the Person and Number information86WORD LEM POS CPOS IG DIST CASE HCPOS HLEM ChnkTYPEBurada bura Noun Noun A3sg|Pnon|Loc long Loc Verb var REGULARc?ic?eklerin c?ic?ek Noun Noun A3pl|Pnon|Gen short Gen Verb sat REGULARsat Verb Verb short Verb sat REGULARVerb Verb Pass|Pos short APastPart sat REGULARsat?ld?g??
Adj APastPart P3sg long Noun alan REGULARgenis?
genis?
Adj Adj short Noun alan REGULARbir bir Det Det short Noun alan REGULARalan alan Noun Noun A3sg|Pnon|Nom short Nom Verb var REGULARvard?
var Verb Verb Pos|Past|A3sg short Punc .
VERB GROUP.
.
Punc Punc long EMPTY EMPTY UNDEFINEDTable 4: An Example of a Sentence with Labeling Features.To the train the CRF relabeling, the gold labels (morphology, dependencies, etc.)
are used for eachtype of features.
Table 4 shows the complete set of features used for the Turkish sentence ?Buradac?ic?eklerin sat?ld?g??
genis?
bir alan vard??
(There used to be a huge area here where the flowers were sold).4.2 Post-processingTo better estimate the labels, we should figure out the type of labeling errors that the dependency parserproduces.
In order to designate such kind of errors, we parsed 50 sentences from a Turkish corpus(different from the test set).
After a manual inspection, we observed that from several others, some of the?DATIVE.ADJUNCT?s are labeled as ?OBJECT?.
This error can be easily corrected by just controllingthe Case feature of the token.
In Turkish, specific adjuncts ends with specific case suffixes.
For example,all dative adjuncts have the Case ?Dat?.
Both MaltParser and our labeling procedure fails to assignthe correct label for this case.
So, after the relabeling procedure, we replaced every token with the label?OBJECT?
and the Case feature ?Dat?
to ?DATIVE.ADJUNCT?.
This manual post-processing corrected41 (out of 56) of the problematic cases on the test set.4.3 ResultsWe used the CRF++9 tool, to train and test the Turkish dependency labeling.
The window size of thesentence was 5 taking the preceding two words and following two words.
For training, we used allTurkish dependency treebank data.
As the test data, we used the output produced in the first phase ofparsing.
Table 5 compares the performance of the labeling according to the ASL and LA scores fororiginal sentences, attachments obtained by the gold chunks and chunker chunks in the previous step.
Asa result, we obtained same ASL without the post-processing step score and 0.26 points in ASL after thepost-processing step with better LA scores over the MaltParser output of the original sentences with thechunker output.
The performance is much better with the gold chunked assignments.
Our experimentsshowed that using a CRF-based labeling enhanced with extra features increased the label accuracy andoutperformed the Turkish dependency parser with respect to ASL.5 Results and Main FindingsDependency parsers have problems in assigning long distance dependencies.
They tend to assign depen-dencies relatively in short distances.
In order to solve this problem, we offered a new chunking-basedparsing methodology.
Our methodology first chunks sentences into constituents.
For each constituent,one grammatically correct sentence is generated with some meaning loss by attaching the verb chunkand parsed with MaltParser.
First chunking a sentence and then using the dependency parser outper-forms the state-of-the-art results.
However, the results with respect to the ASL is not satisfying due towrong labeling.
Thus, in a second phase, our approach treats labeling as a sequential attachment prob-lem.
CRF-based models are used with enhanced features extracted from morphological structure, chunksand dependency attachments.In our experiments, 52 sentences out of 300 sentences were not split as either they have only onechunk or more than two verb chunks.
We generated approximately 2.69 short sentences from each of9CRF++: Yet Another CRF toolkit.87Method ASL LAOriginal Sents.
71.95 83.28+POST 72.95 84.51Chunks - GoldShortened Sents.
72.05 82.37+POST 73.28 83.67CRF Feat.s 72.63 83.21+POST 73.86 84.51Chunks - ChunkerShortened Sents.
71.40 82.44+POST 72.56 83.73CRF Feat.s 71.95 83.51+POST 73.21 84.81Table 5: CRF-based Labeling and Post-processing Results.the remaining sentence.
The performance with respect to ASL was improved from 71.95 to 73.21 (animprovement of 1.7%) and with respect to ASU from 79.90 to 80.23 (an improvement of 0.4%) overparses of original sentences.6 Conclusions and Future WorkIn this paper, we presented a two-phase Turkish dependency parsing approach where the dependenciesare identified in the first phase and the labels are identified in the second phase.
We improved dependencyattachments by chunking sentences into their constituents, generating shorter sentences from these con-stituents, finding dependencies in these shorter sentence, and finally generating the original sentence backfrom these dependency parses.
For the labeling task, we used a CRF-based approach enriched with extrafeatures from the morphological information, dependencies and chunking.
Moreover, we performed arule-based post-processing to correct some dependency labels, if necessary.Future work includes splitting the dependency treebank into constituents also and train the parser withshorter sentences similar to the test data.
Because the lack of different test sets for Turkish, we willalso make 10-fold cross validation with the training data.
Moreover, we are planning to replicate theexperiments with different state-of-the-art parsers such as Bohnet parser (Bohnet and Nivre, 2012).ReferencesBharat Ram Ambati, Samar Husain, Sambhav Jain, Dipti Misra Sharma, and Rajeev Sangal.
2010.
Two methodsto incorporate local morphosyntactic features in hindi dependency parsing.
In Proceedings of the First Workshopon Statistical Parsing of Morphologically Rich Languages in NAACL-HLT?10, pages 22?30.Gluseppe Attardi and Felice Dell?Orletta.
2008.
Chunking and dependency parsing.
In Proceedings of LRECWorkshop on Partial Parsing: Between Chunking and Deep Parsing.Bernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech and labeled non-projective dependency parsing.
In Prooceedings of the EMNLP-CoNLL, pages 1455?1465.Sabine Buchholz and Erwin Marsi.
2006.
Conll-x shared task on multilingual dependency parsing.
In Proceedingsof the 10th Conference on Computational Natural Language Learning (CoNLL), pages 149?164, New York, NY.Kenneth Church.
1988.
A stochastic parts program and noun phrase parser for unrestricted texts.
In Proceedingsof the Second Conference on Applied Natural Language Processing, pages 136?143, Austin, Texas.
?Ilknur Durgar El-Kahlout and Ahmet Afs?
?n Ak?n.
2013.
Turkish constituent chunking with morphological andcontextual features.
In Prooceedings of the Computatioanl Linguistics and Intelligent Text Processing (CI-CLING), pages 270?281.88Gu?ls?en Eryig?it, Joakim Nivre, and Kemal Oflazer.
2008.
Dependency parsing of turkish.
Computational Linguis-tics, 34:357?389.Gu?ls?en Eryig?it, Tugay ?Ilbay, and Ozan Arkan Can.
2011.
Multiword expressions in statistical dependency parsing.In Proceedings of the 2nd Workshop on Statistical Parsing of Morphologically-Rich Langauges (SPMRL), pages45?55, Dublin, Ireland.Gu?ls?en Eryig?it.
2007.
Itu validation set for metu-sabanc?
turkish treebank.Gu?ls?en Eryig?it.
2012.
The impact of automatic morphological analysis and disambiguation on dependency parsingof turkish.
In Proceedings of the LREC, pages 1960?1965, ?Istanbul, Turkey.Dayne Freitag and Andrew McCallum.
2000.
Information extraction with hmm structures learned by stochasticoptimization.
In Proceedings of 17th National Conference on Artificial Intelligence (AAAI), pages 584?589,Austin,Texas.Phani Gadde, Karan Jindal, Samar Husain, Sambhav Jain, Dipti Misra Sharma, and Rajeev Sangal.
2010.
Im-proving data driven dependency parsing using clausal information.
In Proceedings of the Human LanguageTechnology Conference of the NAACL, pages 657?660.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In Proceedings of the 18th International Conference on MachineLearning (ICML), pages 282?289, Williamstown, MA.Andrew McCallum, Dayne Freitag, and Fernanda Pereira.
2000.
Maximum entropy markov models for informa-tion extraction and segmentation.
In Proceedings of International Conference on Machine Learning (ICML),pages 591?598, California, CA.Ryan McDonald and Joakim Nivre.
2007.
Characterizing errors of data-driven dependency parsing models.
InProceedings of the Conference Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), pages 122?131, Prague.Ryan McDonald, Koby Crammer, and Fernando Pereira.
2006a.
Online large-margin training of dependencyparsers.
In Proceedings of the 43th Annual Meeting of the Association for Computational Linguistics (ACL).Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006b.
Multilingual dependency analysis with a two-stagediscriminative parser.
In Proceedings of the 10th Conference on Computational Natural Language Learning(CONLL), New York, NY.Joakim Nivre, Johan Hall, Jens Nilsson, Gu?ls?en Eryig?it, and Svetoslav Marinov.
2006.
Labeled pseudo-projectivedependency parsing with support vector machines.
In Proceedings of the 10th Conference on ComputationalNatural Language Learning (CoNLL), pages 221?225, New York, NY.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, Gu?ls?en Eryig?it, Sandra Ku?bler, Stetoslav Marinov, andErwin Marsi.
2007.
Maltparser: A language-independent system for data-driven dependency parsing.
NaturalLangauge Engineering Journal, 2:99?135.Kemal Oflazer, Bilge Say, Deniz Z. Hakkani-Tr, and Go?khan Tu?r, 2003.
Building a Turkish Treebank, pages261?277.
Kluwer.Kemal Oflazer.
2003.
Dependency parsing with an extended finite-state approach.
Computational Linguistics,29:515?544.Lance A. Ramshaw and Mitchell P. Marcus.
1995.
Text chunking using transformation-based learning.
In Pro-ceedings of the Third ACL Workshop on Very Large Corpora, pages 88?94, Cambridge, Massachusetts.89
