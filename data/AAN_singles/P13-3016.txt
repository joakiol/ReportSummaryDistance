Proceedings of the ACL Student Research Workshop, pages 110?116,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDetecting Chronic Critics Based onSentiment Polarity and User?s Behavior in Social MediaSho Takase?
Akiko Murakami?
Miki Enoki?
Naoaki Okazaki?
Kentaro Inui?Tohoku University?
IBM Research - Tokyo?
{takase, okazaki, inui}@ecei.tohoku.ac.jp{akikom, enomiki}@jp.ibm.comAbstractThere are some chronic critics who al-ways complain about the entity in socialmedia.
We are working to automaticallydetect these chronic critics to prevent thespread of bad rumors about the reputationof the entity.
In social media, most com-ments are informal, and, there are sarcas-tic and incomplete contexts.
This meansthat it is difficult for current NLP technol-ogy such as opinion mining to recognizethe complaints.
As an alternative approachfor social media, we can assume that userswho share the same opinions will link toeach other.
Thus, we propose a methodthat combines opinion mining with graphanalysis for the connections between usersto identify the chronic critics.
Our ex-perimental results show that the proposedmethod outperforms analysis based onlyon opinion mining techniques.1 IntroductionOn a social media website, there may be millionsof users and large numbers of comments.
Thecomments in social media are related to the realworld in such fields as marketing and politics.
An-alyzing comments in social media has been shownto be effective in predicting the behaviors of stockmarkets and of voters in elections (Bollen et al2011; Tumasjan et al 2010; O?Connor et al2010).
Because of their effects on the real world,some complaints may harm the reputation of a cor-poration or an individual and cause serious dam-age.
Consider a comment such as ?Working forCompany A is really awful?
as an example.
Thecomplaint gives viewers a negative impression ofCompany A and can increase the number of peoplewho think the company is bad.Some complaints are expressed by a specificuser who is always criticizing a specific target en-tity (in this example, Company A).
We call thisuser a chronic critic of that entity, a person whois deliberately trying to harm the reputation of theentity.
That is, a chronic critic is trying to run anegative campaign against the entity.
If the entityis aware of its own chronic critics, then it is ableto take prompt action to stop the malicious com-plaints.
When the complaints are false, the entitycan use that defense.
In contrast, if the chroniccritics are justified, then the entity should addressthe concerns to limit the damage.
Hence, to han-dle malicious rumors, it is important to detect thechronic critics.However, it is generally quite difficult for acomputer to detect a chronic critic?s comments,since especially the comments in social media areoften quite informal.
In addition, there are com-plexities such as sarcasm and incomplete contexts.For example, if Company A has been involved in awidely recognized fiasco, then some chronic crit-ics might sarcastically write ?good job?
or ?won-derful?
about Company A.
They are using posi-tive words, but in the context they are effectivelycriticizing Company A.
Some chronic critics basha target entity solely with sarcasm, so they dam-age the target with positive words.
It is exceed-ingly difficult to directly detect these chronic crit-ics based on their comments.
In an example ofan incomplete context, if one author starts an ex-change with a comment such as ?The new prod-uct from Company A is difficult to use?
and an-other user responds with something like ?Fool?,we cannot easily recognize the meaning of thiscomment as related to ?Company A being foolishbecause the product really is difficult to use?
orwhether ?the user is the fool because the productis easy for other people to use?.
To find chroniccritics for a given entity, we need to identify theactual target of the complaints.
Take the comment?Company B is much worse than Company A?
for110example.
This comment is probably complainingabout Company B but not Company A.
In contrast,most of the previous work on sentiment analysisin social media does not consider these kinds ofproblems (Barbosa and Feng, 2010; Davidov etal., 2010; Speriosu et al 2011).Switching to the behavior of each user, in so-cial media we often see that users who have sim-ilar ideas will tend to cooperate with each other.In fact, previous work suggests that users whohave the same opinions tend to create links to eachother (Conover et al 2011b; Yang et al 2012).Because chronic critics share the purpose of at-tacking some target?s reputation, they may alsodecide to cooperate.
For this reason, to detectchronic critics, we believe that information aboutthe connections among users will be effective.In this paper, we present a method that com-bines opinion mining based on NLP and graphanalysis of the connections among users to rec-ognize the chronic critics.
In the experiments, wedemonstrate the difficulty in detecting chronic crit-ics by analyzing only the individual comments.
Inaddition, we investigate the effectiveness of usingthe connections between users, i.e., using the pro-posed method.
For our experiments, we used Twit-ter, a popular social media service.
In particular,we focus on Japanese comments on Twitter.This paper is organized as follows.
Section 2reviews related work.
Section 3 presents the pro-posed method which applies the opinion miningand graph analysis.
Section 4 demonstrates the ef-fectiveness of the proposed method and discussesthe experimental results.
Section 5 concludes thispaper.2 Related WorkIn recent years, an interest in opinion mining inonline communities has emerged (Conover et al2011a; O?Connor et al 2010; Speriosu et al2011; Murakami and Raymond, 2010; Barbosaand Feng, 2010; Davidov et al 2010).
O?Connoret al(2010), Barbosa and Feng (2010), Davidovet al(2010), and Speriosu et al(2011) proposedmethods to predict a sentiment polarity (i.e., pos-itive or negative) of a comment in social media.O?Connor et al(2010) studied a subjectivity lexi-con.
Barbosa and Feng (2010) and Davidov et al(2010) used machine learning approaches.
Spe-riosu et al(2011) introduced connections betweenwords, emoticons, tags, n-grams, comments andusers.
These studies did not identify the target ofthe polarized sentiment of each comment.Conover et al(2011a) proposed a method thatpredicts the political polarity of a social mediauser based on the connections between users andtags.
They demonstrated that label propagationon the graph representing the connections betweenusers is effective.
However, this method is notguaranteed to obtain the optimal solution.
In con-trast, our research uses graph analysis that con-verges on the optimal solution.Murakami and Raymond (2010) proposed amethod that uses the connections between usersto predict each user?s opinion, i.e., support or op-pose a topic in online debates.
They analyzedthe content of the discussions to infer the connec-tions.
However, in social media, it is difficult to in-fer connections based on content because of suchcomplexities as incomplete contexts.
To addressthese problem, we analyzed the behavior of theusers to predict the connections between users.Our task is similar to spammer detection (Wang,2010; Yang et al 2012).
Wang (2010) pro-posed a method using a classifier to detect spam-mers.
They used the content in the commentsand the number of linked users as features.
Yanget al(2012) analyzed spammer communities anddemonstrated that spammers closely link to eachother in social media.
They also proposed amethod that extracts spammers using the connec-tions between users.
WhileWang (2010) and Yanget al(2012) required manually annotated data fortraining or as seeds, we extract the seeds for thegraph analysis automatically through opinion min-ing.3 Proposed MethodFigure 1 presents an overview of the proposedmethod.
The proposed method has two phases,opinion mining and graph analysis.
First, we ex-tract a few chronic critics by analyzing the opin-ions of many users referencing the target entity.For the opinion mining, we are initially lookingfor users who strongly criticize the target entity.
InFigure 1, given Company A as a target entity, wefind users ?b?
and ?e?
since they said ?Workingfor Company A is really awful?
and ?This productfrom Company A is useless?.
However, we maymiss the other chronic critics since they used sar-casm and incomplete contexts.Next, we find the users who are linked to the111???
?Opinion miningMaking graph Company A is very very nice.I use only products of Company A.I like products of Company A.The attitude of Company A is perfect.Company A always makes shitty produces.Working for Company A is really awful.Comments in social mediaCompany B is much worse than Company A.A product of Company A is wonderful.Fiasco of Company A occurs almost every day.Company A, good job!The product from Company A is difficult to use.This product from Company A is useless.Company A is a bad company.Why do people praise Company A?adcbgfeAn account of a target entity xWorking for Company A is really awful.Company A always makes shitty produces.A product of Company A is useless.A new product of Company A is difficult to use.Chronic critics extracted by the opinion miningbeThe graph based on a relationship of agreements  Results of the graph analysisGraph analysisChronic criticsadcbgfeadcbgfex x?Figure 1: Overview of proposed methodchronic critics that were detected through opinionmining.
We built a graph in which the users arerepresented by nodes and the links between theusers are represented by edges.We recognize ad-ditional chronic critics based on the graph anal-ysis.
In the example of Figure 1, we find morechronic critics not recognized by the opinion min-ing, such as ?a?
and ?c?, because they are linkedto the chronic critics ?b?
and ?e?.
In this section,we explain the opinion mining and graph analysis.Since a comment in Twitter is called a tweet, weuse the term tweet below.3.1 Opinion MiningAs defined in Section 1, we defined a user whofrequently criticizes a target entity as a chroniccritic.
Therefore, we classify the tweets of eachuser into critical or non-critical and label any userswho complain about the target entity many timesas chronic critics.
Because we want to investi-gate the opinions of each user in public, we an-alyze public tweets, excluding the private conver-sations between users.
In Twitter, this means weignore a reply that is a response to a specific usernamed username (written in the format ?
@user-name response?)
and QT that is a mention in aquoted tweet from username (written in the format?mention RT @username: quoted tweet?
).We assume a phrase representing negative po-larity or profanity to be critical phrases.
The pro-posed method determines whether a tweet com-plains about the target entity by investigating acritical phrase and the target of the phrase.Note that a negative polarity is represented bydeclinable words or substantives.
We used thesentiment analyzer created by Kanayama and Na-sukawa (2012) to detect a phrase representing neg-A?????????????
?Working for   Company A is    really    awful.Figure 2: Example of critic tweetative polarity by using declinable words.
We usedthe lexicon collected by Higashiyama et al(2008)to find negative polarity in substantives.
For de-tecting profanity, we use a profane lexicon col-lected by Ogino et al(2012).The sentiment analyzer can find not only senti-ment phrases but the targets of the phrases basedon syntactic parsing and the case frames1.
How-ever, because there are many informal tweets andbecause most users omit the grammatical case intweets, the sentiment analyzer often fails to cap-ture any target.
To address this problem, in ad-dition to a target extracted by the sentiment ana-lyzer, we obtain a target based on the dependencytree.
We extract nouns in parent and child phraseswithin distance 2 from a critical phrase in the de-pendency tree.Figure 2 shows an example of a Japanese tweetcriticizing Company A and its English translation.The Japanese tweet is split into phrase-like units(bunsetsu).
Each English phrase is linked to thecorresponding bunsetsu by a dotted line.
The de-pendency relationships among the bunsetsu are ex-pressed by the arrows.
In the tweet, the black-edged phrase ?awful?
is a critical phrase.
We ex-tract the nouns in ?Working for?
and ?CompanyA is?
as targets of the critical phrase since these1A case frame is a list which represents grammatical casesof a predicate.112phrases are parents within distance 2 of the criti-cal phrase.
Therefore, we decide that the tweet iscriticizing Company A.Since a chronic critic frequently complainsabout the target entity, we can predict that mostof the tweets written by a chronic critic of the tar-get entity will be critical tweets.
Therefore, wecan calculate a ratio of critical tweets for all of thetweets about the target entity.
We score the user uiwith equation (1).scorei =niNi(1)Ni is the number of all tweets about the target en-tity and ni is the number of critical tweets aboutthe entity by that user 2.
We extract the top Musers based on scorei as chronic critics.3.2 Graph AnalysisIn social media, it is often very difficult to deter-mine whether a tweet is critical since many tweetsinclude sarcasm or incomplete contexts.
The opin-ion mining may miss numerous complaints withsarcasm or incomplete contexts.
To resolve thisproblem, we apply user behaviors.
In social me-dia, we assume that users having the same opinioninteract with each other in order to demonstrate thecorrectness of their opinion.
In particular, sincethe purpose of chronic critics is to spread the badreputation, we assume that they want to assist eachother.
We supplement the opinion mining by agraph analysis using this assumption.
Thus, wemake a graph representing connections among theusers and use label propagation on the graph basedon the results of the opinion mining as the seeds.In addition, we believe that a user will try tospread user matching opinions.
This implies that auser who spreads the opinion of another of agreeswith the author of that opinion.
In Twitter, a usercan spread an opinion as an RT, which is a repost-ing of a tweet by a username (written in the format?RT @username: tweet?).
Conover et al(2011b)demonstrated that they can make a graph repre-senting the connections among users who supporteach others opinions by using RTs.
Hence, an RTexpresses a relationship of endorsement.
We alsocreated a graph based on this feature.Our graph has m users (U = {u1, ..., um}) asnodes, where ui connects with uj via an edge that2The formula (1) assigns a high score to a user if the useronly produces one or two tweets about the target entity andthose tweets are negative.
To prevent this, we disregard theusers whose the number of tweets are fewer than 5.has weightwij (0 ?
wij ?
1) andwij correspondsto the degree to which ui supports uj .
We calcu-late wij by using Equation (2).wij =12(rijRi+ rjiRj)(2)rij is the total RT tweets of uj by ui and Ri is thenumber of RTs by ui.
Therefore, the more ui anduj RT each other, the more weight wij is close to1.
In contrast, if ui and uj rarely RT each other, thevalue of wij will approach 0.
In addition, this wijdefinition is symmetric means (i.e., wij = wji).We find more new chronic critics by label prop-agation on the graph.
We use the chronic criticsobtained by the opinion mining as seeds.
It is as-sumed that a user who supports the target entity isnot a chronic critic.
Using this knowledge, we usethe account of the target entity as a seed.The label propagation assigns a confidencescore c = (c1, ..., cm) to each node U =u1, ..., um, where the score is a real number be-tween ?1 and 1.
A score close to 1 indicatesthat we are very confident that the node (user) isa chronic critic.
A score close to ?1 indicates thatwe are sure that the node is not a chronic critic.
Inaddition, the scores of seeds are fixed and cannotbe changed.
The scores of chronic critics obtainedby the opinion mining are 1 and the score of thetarget entity is set to ?1.
To formulate the labelpropagation as an optimization problem, we usedthe loss function proposed by Zhu et al(2003),because wij ?
0 for all i, j.E(c) = 12?i,jwij(ci ?
cj)2 (3)To minimize E(c), ci is close to cj when wijis greater than 0.
That is, if the users supporteach other, the scores of the users are close toeach other.
Thus, by minimizing E(c), we as-sign the confidence scores considering the resultsof the opinion mining and agreement relationshipsamong the users.
We find the users that havescores greater than the threshold.We believe that if the distance between users onthe graph is large, then users slightly support eachother.
However, we can assign a score of 1 to eachnode in any subgraph that has chronic critics ex-tracted by the opinion mining to minimize E(c)if the subgraph does not include the account ofthe target entity, no matter how far away a node113Table 1: Properties of the experimental datasetsTarget entity Tweets Critics KappaCompany A 35,807 112 0.81Politician A 45,378 254 1.0is from the seeds.
To avoid this problem, Yin andTan (2011) introduced a neutral fact, which de-creases each confidence score by considering thedistance from the seeds.
The neutral fact has afixed confidence score 0 and connects with all ofthe nodes except the seeds.
Suppose u1 is the neu-tral fact, Ul = {u2, ..., ul} is the set of seeds andUt = {ul+1, ..., um} is the set of all nodes exceptseeds.
To assign the weight of the edge betweenu1 and other nodes considering the degrees of thenodes, we calculate the weight by as:w1i ={0 i = 1, ..., l?
?j>1 |wij | i = l + 1, ...,m(4)where ?
is a small constant.
Thus, the weight isproportional to the total weight of the edges fromeach node.4 Experiments4.1 Experimental SettingFor our experiment, we gathered tweets by usingthe Twitter search API.
The twitter search API re-turns the tweets that contain an input query.
Weused the name of a target entity, words related tothe entity3, and the account name of the entity asqueries.
In this research, there were two targetentities, Company A and Politician A.
We foundmany critical tweets about these target entities.The entities have their own accounts in Twitter.We collected the Japanese tweets for one month.We want to extract the users who frequently ex-press a public opinion related to a target entity.For this reason, we eliminated users whose thenumber of tweets except conversation (i.e., reply,QT, RT) are fewer than 5.
In addition, to elimi-nate bots that automatically post specific tweets,we eliminated users whose conversational tweetswere fewer than 2.
We selected some of the re-maining users for the experiment.
To satisfy ourdefinition, a chronic critic must tweet about thetarget entity many times.
Therefore, we focused3We manually prepared the words that have a correlationwith the entity.
In this paper, we only used the name of thepolitical party of Politician A as the related word.on the top 300 users based on the number of tweetsas our experimental users.
Table 1 shows the totalnumbers of tweets by the top 300 users, excludingthe account of the target entity.We created an evaluation set by manually di-viding the experimental users into chronic criticsand regular users.
A chronic critic actively com-plained and tried to harm the reputation of thetarget entity.
We also regarded a user who fre-quently reposted a critic?s tweets and unfavorablenews about the target entity as a chronic critic.
Forthe experimental users tweeting aboutCompany A,we asked two human annotators to judge whethera user was a chronic critic based on one month oftweets.
The Cohen?s kappa value was 0.81 whichinter-annotator agreement was good.
We selectedthe arbitrarily annotating by one of the annotatorsas our evaluation set.
Table 1 expresses the num-ber of chronic critics for each target entity in theevaluation set.
For the experimental users tweet-ing about Politician A, we randomly extracted 50users randomly to calculate Cohen?s kappa, whichis displayed in Table 1.We evaluated the effects of combining the opin-ion mining with the graph analysis.
We comparedopinion mining (OM), graph analysis (GA), andthe combination of opinion mining and graph anal-ysis (our proposed method).
GA randomly se-lected M users from experimental users as seedsand takes the average of the results obtained byperforming label propagation three times.
Thenumber of chronic critics extracted by the opinionmining (i.e., the valuable M ) was set to 30.
Theparameter ?, that we use to calculate the weight ofthe edges connected to neutral fact, was set to 0.1.4.2 ResultsFigure 3 represents the precision and recall of eachmethod for each target entity.
In OM, we variedthe threshold from 0 to 0.2 in increments of 0.02and accepted a user with a score over the thresholdas a chronic critic.
In GA, we varied the thresholdfrom 0.35 to 0.8 in increments of 0.05.In Figure 3, the results for Company A andPolitician A are quite different, though there aresome similar characteristics.
Figure 3 shows thatOM achieved high precision but it was difficult toimprove the recall.
In contrast, GA easily achievedhigh recall.
The proposed method achieved highprecision similar to OM and high recall.
Inother words, the proposed method found many114!"#$%!"&%!"&$%!"$%!"$$%!"'%!"'$%!"(%!"($%!")%!
")$%!% !
"*% !
"+% !
"#% !
"&% !
"$% !
"'% !
"(% !
")% !
",% *%PrecisionRecallOM GA The proposed method(a) Company A!"#$!"#%$!"&$!
"&%$'$!$ !
"'$ !
"($ !
")$ !
"*$ !
"%$ !
"+$ !
",$ !
"#$ !
"&$ '$PrecisionRecallOM GA The proposed method(b) Politician AFigure 3: Precision and recall of each method for each target entityTable 2: Users connected with the target entityTarget entity Users Non-criticsCompany A 45 39Politician A 74 35chronic critics while retaining high precision ofOM.
Therefore, the combination of the opinionmining and the graph analysis improved the per-formance of recognizing the chronic critics.Figure 3 shows that the recall of OM was low,which means that OM missed some of the criticaltweets.
In this paper, we used domain-independentlexicons to detect the critical phrases.
Therefore,OM failed to find domain-dependent critic phrasessuch as slang words.
In addition, some chroniccritics do not express criticism clearly in their owntweets.
To spread the bad reputation, they refer-ence only a title and link to a webpage that criti-cizes the target entity such as:This shows the reality of Company A.Why do you buy products from thiscompany?
http://xxxWe believe that is often done because each tweet islimited to 140 characters.
It is difficult to classifythe tweet as a complaint based only on its content.However, the proposed method recognized mostchronic critics that complain with these methodsbased on the GA.It cannot reasonably be assumed that a userwho supports the account of the target entity is achronic critic.
For this reason, in the graph analy-sis, we used the entity?s account to recognize non-critics.
We believe that using the account correctsfor mistakes in selecting the seed chronic critics.Table 2 shows the number of users connected withthe account.
Table 2 also shows the number ofnon-critics among the users.
As seen in Table 2,many non-critics were connected with the account.Especially for Politician A, most of the non-criticsin the evaluation set were connected with the ac-count.
Therefore, incorporating the account intothe graph analysis can correct for errors in theseeding of chronic critics.
However, some chroniccritics were connected with the target?s accountand reposted tweets from the account.
We noticedthat they mentioned their negative opinions aboutthe content of such a tweet immediately after re-posting that tweet.
Hence, we need to analyze thecontexts before and after each RT.For Politician A, Table 1 shows that most of theusers in the evaluation set criticized the politician.We were able to find most of the chronic criticsby extracting the users linked to each other.
How-ever, for Company A, the precision of GA was low.This means we need high accuracy in selecting theseeds to correctly capture chronic critics.
Becausewe used the users extracted by the opinion miningas the seeds, the proposed method outperformedOM and GA.5 ConclusionIn this paper, we proposed a method that uses notonly opinion mining but graph analysis of the con-nections between users to detect chronic critics.In our experiments, we found that the proposedmethod outperformed each technique.In our study, we used two entities.
To im-prove reliability, we should study more entities.We used a relationship between users that supporteach other.
However, we suspect that the rela-tionship includes adversaries.
We hope to addressthese topics in the future.115AcknowledgmentsThis research was partly supported by JSPS KAK-ENHI Grant Numbers 23240018.
The authorswould like to acknowledge Hiroshi Kanayama andShiho Ogino in IBM Research-Tokyo for provid-ing their tools for our experiments.ReferencesLuciano Barbosa and Junlan Feng.
2010.
Robust Sen-timent Detection on Twitter from Biased and NoisyData.
In Proceedings of the 23rd International Con-ference on Computational Linguistics, pages 36?44.Johan Bollen, Huina Mao, and Xiao-Jun Zeng.
2011.Twitter mood predicts the stock market.
Journal ofComputational Science, 2(1):1?8.Michael D. Conover, Bruno Gonc?alves, JacobRatkiewicz, Alessandro Flammini, and FilippoMenczer.
2011a.
Predicting the Political Alignmentof Twitter Users.
In Proceedings of the 3rd IEEEConference on Social Computing, pages 192?199.Michael D. Conover, Jacob Ratkiewicz, Matthew Fran-cisco, Bruno Gonc?alves, Alessandro Flammini, andFilippo Menczer.
2011b.
Political Polarization onTwitter.
In Proceeding of the 5th International AAAIConference on Weblogs and Social Media, pages89?96.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Enhanced Sentiment Learning Using Twitter Hash-tags and Smileys.
In Proceedings of the 23rd Inter-national Conference on Computational Linguistics,pages 241?249.Masahiko Higashiyama, Kentaro Inui, and Yuji Mat-sumoto.
2008.
Learning Polarity of Nouns by Se-lectional Preferences of Predicates (in Japanese).
InProceedings of the 14th Annual Meeting of The As-sociation for Natural Language Processing, pages584?587.Hiroshi Kanayama and Tetsuya Nasukawa.
2012.
Un-supervised Lexicon Induction for Clause-Level De-tection of Evaluations.
Natural Language Engineer-ing, 18(1):83?107.Akiko Murakami and Rudy Raymond.
2010.
Supportor Oppose?
Classifying Positions in Online Debatesfrom Reply Activities and Opinion Expressions.
InProceedings of the 23rd International Conference onComputational Linguistics, pages 869?875, Beijing,China.Brendan O?Connor, Ramnath Balasubramanyan,Bryan R. Routledge, and Noah A. Smith.
2010.From Tweets to Polls: Linking Text Sentiment toPublic Opinion Time Series.
In Proceedings of the4h International AAAI Conference on Weblogs andSocial Media, pages 122?129.Shiho Ogino, Tetsuya Nasukawa, Hiroshi Kanayama,and Miki Enoki.
2012.
Knowledge Discovery Us-ing Swearwords (in Japanese).
In Proceedings of the8th Annual Meeting of The Association for NaturalLanguage Processing, pages 58?61.Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Ja-son Baldridge.
2011.
Twitter Polarity Classificationwith Label Propagation over Lexical Links and theFollower Graph.
In Proceedings of the 1st workshopon Unsupervised Learning in NLP, pages 53?63.Andranik Tumasjan, Timm O. Sprenger, Philipp G.Sandner, and Isabell M. Welpe.
2010.
PredictingElections with Twitter: What 140 Characters Revealabout Political Sentiment.
In Proceedings of the 4thInternational AAAI Conference on Weblogs and So-cial Media, pages 178?185.Alex Hai Wang.
2010.
Don?t Follow Me - Spam De-tection in Twitter.
In Proceedings of the 5th Inter-national Conference on Security and Cryptography,pages 142?151.Chao Yang, Robert Harkreader, Jialong Zhang, Seung-won Shin, and Guofei Gu.
2012.
Analyzing Spam-mers?
Social Networks for Fun and Profit: A CaseStudy of Cyber Criminal Ecosystem on Twitter.
InProceedings of the 21st international conference onWorld Wide Web, pages 71?80.Xiaoxin Yin and Wenzhao Tan.
2011.
Semi-Supervised Truth Discovery.
In Proceedings of the20th international conference on World Wide Web,pages 217?226.Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.2003.
Semi-Supervised Learning Using GaussianFields and Harmonic Functions.
In Proceedingsof the 20th International Conference on MachineLearning, pages 912?919.116
