Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 1?7,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsMedEval ?
A Swedish Medical Test Collectionwith Doctors and Patients User GroupsKarin Friberg HeppinDepartment of SwedishUniversity of GothenburgGothenburg, Swedenkarin.friberg@svenska.gu.seAbstractMedEval is a Swedish medical test collectionwhere assessments have been made, not onlyfor topical relevance, but also for target readergroup: Doctors or Patients.
The user of thetest collection can choose if s/he wishes tosearch in the Doctors or the Patients scenar-ios where the topical relevance assessmentshave been adjusted with consideration to usergroup, or to search in a scenario which regardsonly topical relevance.
MedEval makes it pos-sible to compare the effectiveness of searchterms when it comes to retrieving documentsaimed at the different user groups.
MedEval isalso the first medical Swedish test collection.1 A New Test CollectionWhen the decision was made to build a new test col-lection, the Department of Swedish at the Univer-sity of Gothenburg was involved in projects of re-search in medical language processing.
There wasalso a growing interest of research in information re-trieval.
There existed no Swedish medical test col-lection.
Creating one seemed to be a good invest-ment in knowledge and resources, even though thisinvolved a team of people during many months.
Asbuilding a test collection is a major undertaking notmany exist.
OHSUMED is a medical test collection,albeit in English.
It is built on nearly 350 000 refer-ences from MEDLINE.
The OHSUMED documentsare assessed on a three graded scale: definitely, pos-sibly and not relevant.
OHSUMED contains 106topics generated by physicians from authentic situa-tions.
The topics consist of both information aboutthe patient and the request.
(OHSUMED, 2007)With a new collection such as MedEval, theSwedish department could take control over the ar-chitecture and make decisions such as using a fourgraded scale of relevance, making it possible to em-ploy a variety of evaluation tools.
However, themost important decision was to assess documents,not only for relevance to topics, but also for intendedgroups of readers, ?Doctors: medical professionals?or ?Patients: lay persons?, and to allow the user tochoose user scenario: None, Doctors or Patients.2 DocumentsThe MedEval test collection is built on docu-ments from the MedLex medical corpus (Kokki-nakis, 2004).
MedLex consists of scientific arti-cles from medical journals, teaching material, guide-lines, patient FAQs, health care information, etc.The set of documents used in MedEval is a snapshotof MedLex in October 2007, approximately 42 200documents or 15 million tokens (see table 1).
Thedocuments are stored in the trectext format.3 IndexesThe MedEval test collection has two indexes.
Onewhere the documents are converted to lower case,tokenized and lemmatized, and one where the com-pounds also are decomposed.
In the second index,the compound terms are indexed as a whole togetherwith the compound constituents.
For instance: thecompound saltkoncentration ?salt concentration?
isindexed as saltkoncentration, salt, and koncentra-tion.1Type of source Number of Percent of Number Percentdocuments documents of tokens of tokensJournals and periodicals 8 453 20.0 5.3 million 34.6Specialized sites 14 631 34.6 2.9 million 19.1Pharmaceutical companies 9 200 21.8 2.3 million 14.8Government, faculties, institutes, and hospitals 2 955 7.0 2.0 million 13.3Health-care communication companies 4 036 9.6 1.7 million 11.3Media (TV, daily newspapers) 2 980 7.1 1.0 million 6.9Total 42 255 100.1 15.2 million 100Table 1: The genres of the MedEval document sources.
The document collection is a snapshot of the MedLex corpusin October 2007.
(D. Kokkinakis, p.c.
)4 TopicsTwo medical students in their fourth year of studieswere hired to create the topics.
Their instructionswere to create information needs that could be re-quested in real medical situations.
100 topics werecreated in the first stage.
62 of these were used inthe collection.A topic consists of a title, a description and a nar-rative.
The title is a short phrase summarizing the in-formation need.
The description is concise informa-tion about the topic, usually in the form of a questionor a request.
The narrative is a few sentences longand it stipulates what makes a document relevant tothe topic.
The narrative contains the guidelines forthe assessors when judging the relevance of the doc-uments in the next stage.
An example of a topic isgiven below.
The English equivalent of the descrip-tion of topic 51 is: Why can a patient with cancercontract anemia?<TOP><TOPNO>51</TOPNO><TITLE> Anemi och cancer </TITLE><DESC> Varfo?r kan en patient med cancerdrabbas av anemi?
</DESC><NARR> Relevanta dokument ska inneha?llainformation om vad anemi /blodbrist a?r, sym-tom, behandling och orsaker.
Information omcancerrelaterad anemi dels utlo?st av cancernoch dels utlo?st av cancerbehandlingen a?rrelevant.
</NARR></TOP>5 Selecting Documents to AssessIn the ideal test collection every document would beassessed for relevance with respect to every topic.But with over 42 000 documents and 62 topics, tak-ing 8 minutes to assess each document, it would takefour persons more than 40 years working 40 hoursper week to finish the assessments.Instead, only the documents that were consideredmost likely to be relevant to each topic were as-sessed.
The documents were filtered out by use offour queries, one specific and one exhaustive foreach index.
The documents selected for each topicwere sorted by document ID and duplicates were re-moved.
This was done so that the assessors wouldnot know how high a document had been ranked,or in how many searches it had been retrieved.
Foreach topic and each of the four queries the 100 high-est ranked documents were selected, if, in fact, therewere that many.6 Relevance JudgmentsFor the relevance judgments four new medical stu-dents were consulted.
For each of 62 topics, an as-sessor read through the documents to be assessedand decided, for each document, the intended groupof readers and the degree of relevance to the topic.The documents for each individual need were as-sessed by one and the same assessor for reasons ofconsistency.The MedEval relevance assessments were madeon a four graded scale, 0-3, where 0 is ?Not at allrelevant?
and 3 is ?Highly relevant?.
The scale iseasily turned into a binary scale by stating that thedocuments with the lower grades are to be consid-2ered non-relevant and the ones with higher gradesrelevant.
Where the division is made between rel-evant and non-relevant depends on the needs of theuser in each case.The relevance considered by the assessors wastopical relevance, how well a document correspondsto a topic.
The assessors were instructed not to in-volve user relevance in this score.
Each documentwas judged on its own merits.
The novelty of thecontents of a document should not be considered.7 Target GroupsIn addition to topical relevance the assessors judgedeach document for reader target group, that is whichgroup of readers was the intended: Patients, if a doc-ument was written for lay persons, or Doctors, if itwas written for medical professionals.For a classification of documents according tointended reader group to be useful, there must bea measureable difference between the documentclasses.
Table 2 shows a number of type/token fre-quencies in different subsets of the collection.
Ineach set duplicates were removed in the case thata document had been assessed for more than onetopic.
The subsets considered are described below.Full form types are the original terms of the doc-uments before lemmatization and lemma types arethe same terms after lemmatization.Entire collection All documents of the MedEvalcollection.Assessed documents All documents that have beenassessed for any topic.Doctors assessed All documents that for at leastone topic have been assessed to have targetgroup Doctors.Patients assessed All documents that for at leastone topic have been assessed to have targetgroup Patients.Common files All documents that for at least onetopic have been assessed to have target groupDoctors and for another to have target groupPatients.Doctors relevant All documents that for at leastone topic have been assessed to have at leastrelevance grade 1 and to have target group Doc-tors.Patients relevant All documents that for at leastone topic have been assessed to have at leastrelevance grade 1 and to have target group Pa-tients.Before counting frequencies, the files werecleaned from tags, IDs, dates (in the date tag, notin the actual text), web information and punctua-tion marks.
Some observations are readily made bystudying table 2.The number of tokens per document is signifi-cantly smaller for the entire collection, than for anysubset.
This means that there is a large numberof short documents that were not retrieved by anyquery when the documents to be assessed were se-lected.
Maybe not surprising, since short documentscontain few terms which can match the queries.The documents in the set ?Patients assessed?
hadonly 57% the number of tokens per document, com-pared to the documents in ?Doctors assessed?.
Eventhough there were over 1 000 more documents in?Patients assessed?
than in ?Doctors assessed?, therewere over 50 000 more lemma types in the doctordocuments and almost 30 000 more lemma com-pound types.
The average word length in ?Doctorsassessed?
was 6.29 compared to 5.73 for ?Patientsassessed?.
The ratio of compound tokens was alsohigher in the doctor documents, 0.128 compared to0.098.Table 3 illustrates the fact that the doctor docu-ments contain more and longer terms and more com-pounds than patient documents.
This table showsfrequencies of all full form types of strings be-ginning with fo?rmak ?atria?
in ?Patients assessed?and ?Doctors assessed?
respectively.
The patientdocuments have 18 full form types beginning withfo?rmak while doctor documents have 75.
That ismore than four times more types for the doctor doc-uments.A closer look at the frequencies of fo?rmak?
in theprofessional and lay person texts reveals that not allfrequencies are higher for professionals.
The fre-quencies of nouns in the definite form in the lay per-son texts are close to, equal or higher than the sameforms in the professional texts.3Entire Assessed Doctors Patients Common Doctors Patientscollection documents assessed assessed files relevant relevantNumber of documents 42 250 7 044 3 272 4 334 562 1 233 1 654Tokens 12 991 157 5 034 323 3 232 772 2 431 160 629 609 1 361 700 988 236Tokens/document 307 715 988 561 1 120 1 104 596Average word length 5.75 6.04 6.29 5.73 6.16 6.33 5.63Full form types 334 559 181 354 154 901 92 803 50 961 87 814 43 825Lemma types 267 892 146 631 126 217 73 121 40 857 71 974 34 263Compound tokens 1 273 874 573 625 412 475 237 267 76 117 179 580 92 420Full form compound types 187 904 99 614 83 846 47 387 24 083 45 257 20 157Lemma compound types 144 159 78 508 66 907 37 151 19 685 36 867 16 006Ratio of compounds 0.098 0.114 0.128 0.098 0.120 0.132 0.094Table 2: Type and token frequencies of the terms in different subsets of the MedEval test collection.Looking at all instances of strings beginning withfo?rmak?
in the two sets of documents there is a sig-nificant difference.
In the patient documents 66 to-kens of 372, or 17.7%, are nouns in the definiteform, while the corresponding numbers for the doc-tor documents is 89 of 932 tokens, or 9.6%.
At thisstage one can only speculate why this is so.
A hy-pothesis is that doctors/medical professionals oftendiscuss matters in a generic point of view, while pa-tients/lay persons discuss specific cases.Term Doctors Patientsfo?rmaken 21 21fo?rmakens 1 2fo?rmaket 11 14fo?rmaksflimret 16 28fo?rmaksmyocyterna 2 1Table 4: Frequencies of terms beginning with fo?rmak?atria?, which are in the definite form in the set ?Patientsassessed?.
The frequencies of these word forms in thedocuments written for the two target groups are com-pared.8 User GroupsThe MedEval test collection allows the user to stateuser group: None (no specified group), Doctors orPatients.
This choice directs the user to one of threescenarios.
The None scenario contains the topicalrelevance grades as made by the assessors.
The Doc-tors scenario contains the same grades with the ex-ception that the grades of the documents marked forPatients target group are downgraded by one.
Inthe same way the Patients scenario has the docu-ments marked for Doctors target group downgradedby one.
This means that for a doctor user patientdocuments originally given relevance 3, are gradedwith 2, documents given relevance 2 are graded 1and documents given relevance 1 are graded 0.
Thesame is done in the Patients scenario with the doc-tor documents.
The idea is that a document that iswritten for a reader from one target group but re-trieved for a user from the other group will not benon-relevant, but less useful than a document fromthe correct target group.
Put differently, a docu-ment intended for patients would contain informa-tion that doctors (hopefully) already know.
On theother hand, documents intended for doctors, eventhough they might be topically relevant for a pa-tient?s need, run a great risk of being written in sucha way that a patient will have problems grasping thewhole content.Adjusting relevance in the manner described af-fects the scenario recall bases.
Since relevancegrades are downgraded for documents of the oppos-ing target group there will be fewer relevant docu-ments in the Doctors and Patients scenarios than inthe None scenario.
This is demonstrated in figure 1where the ideal cumulated gain for the three scenar-ios of topics 28, 36 and 92 are shown.
The ideal cu-mulated gain is the maximum score of retrieved in-formation possible at each position in a ranked list ofdocuments (Ja?rvelin, Keka?la?inen, 2002).
The scorefor each position is the sum of all relevance scoresso far in the ranked list.The three topics of figure 1 show different char-acteristics with reference to the number of relevant4Lay fo?rmak 73 fo?rmaksflimmer 219person fo?rmaken 21 fo?rmaksflimmerattacker 1audience fo?rmakens 2 fo?rmaksflimmerpatienter 1fo?rmaket 14 fo?rmaksflimret 28fo?rmaks 1 fo?rmakslimmer 1fo?rmaksarytmier 2 fo?rmaksmyocyterna 1fo?rmakseffekt 1 fo?rmakstakykardi 1fo?rmaksfladder 2 fo?rmaksutlo?sta 2fo?rmaksflimer 1 fo?rmakso?ra 1Professional fo?rmak 93 fo?rmaksmuskelns 1audience fo?rmaken 21 fo?rmaksmuskulaturen 2fo?rmakens 1 fo?rmaksmyocyterna 2fo?rmaket 11 fo?rmaksmyokard 3fo?rmakets 1 fo?rmaksmyokardiet 1fo?rmaks 21 fo?rmaksmyxom 2fo?rmaksaktivering 1 fo?rmaksniva?
2fo?rmaksaktivitet 1 fo?rmaksna?ra 1fo?rmaksaktiviteten 2 fo?rmaksoch 1fo?rmaksanatomi 1 fo?rmakspacing 7fo?rmaksarytmi 2 fo?rmakspeptider 1fo?rmaksarytmier 9 fo?rmaksrytmer 1fo?rmaksbidraget 1 fo?rmaksseptostomi 1fo?rmaksbradyarytmi 1 fo?rmaksseptum 2fo?rmaksdefibrillator 2 fo?rmaksseptumaneurysm 10fo?rmakseffekt 2 fo?rmaksseptumdefekt 5fo?rmaksfladder 57 fo?rmaksseptumdefekten 1fo?rmaksfladdret 2 fo?rmaksseptumdefekter 1fo?rmaksflimmer 544 fo?rmaksseptums 1fo?rmaksflimmerablationer 2 fo?rmaksstimulerat 1fo?rmaksflimmerattacker 1 fo?rmaksstimulerin 5fo?rmaksflimmerduration 2 fo?rmaksstorlek 2fo?rmaksflimmerepisoder 4 fo?rmaksstorleken 1fo?rmaksflimmerfladder 2 fo?rmakssynkron 1fo?rmaksflimmerpatienter 4 fo?rmakssystole 1fo?rmaksflimmerrecidiv 1 fo?rmakstaket 1fo?rmaksflimmertendensen 1 fo?rmakstakykardi 11fo?rmaksflimmerunderha?llande 1 fo?rmakstakykardie 8fo?rmaksflimret 16 fo?rmakstromb 2fo?rmaksflimrets 4 fo?rmakstryck 1fo?rmaksfrekvenser 1 fo?rmakstrycket 1fo?rmaksfunktion 1 fo?rmaksvolym 2fo?rmaksfo?rstoring 1 fo?rmaksva?gg 1fo?rmaksimpuls 1 fo?rmaksva?ggarna 2fo?rmaksinhiberad 1 fo?rmaksva?ggen 6fo?rmakskontraktion 4 fo?rmaksva?vnaden 2fo?rmakskontraktionen 6 fo?rmakso?ra 9fo?rmakskontraktionens 1 fo?rmakso?ronen 2fo?rmaksmuskeln 1Table 3: This is a randomly chosen example of the difference in the number of types and of tokens in the documentswritten for a lay person audience, in the set ?Patients assessed?
and the ones written for a professional audience, in theset ?Doctors assessed?.
The table shows all types of strings beginning with fo?rmak ?atria?
in documents written for thetwo target groups.
The number of tokens for each type is also shown.50204060801001201401600  20  40  60  80  100  120Ideal cumulatedgainNumber of documentsTopic 28.
Vilka indikationer f?religger vid behandlingmed benzodiazepiner?
N?r ska preparatet anv?ndas?What indications exist for treatment withbenzodiazepines?
When should the drug be used?NoneDoctorsPatients0204060801001201401601802002200  20  40  60  80  100  120  140  160Ideal cumulatedgainNumber of documentsTopic 36.
Vilka effekter och interaktioner med andra l?kemedelkan man f?rv?nta sig vid anv?ndning av waran?What effects and interactions with other medicinescan be expected with the use of waran?NoneDoctorsPatients0204060801001200  10  20  30  40  50  60  70  80Ideal cumulatedgainNumber of documentsTopic 92.
Hud: Hur g?r man tillv?ga vid behandlingav eksem med steroider?Skin: How does one perform treatment of eczema with steroids?NoneDoctorsPatientsFigure 1: The recall bases of topic 28, 36 and 92 rep-resented in ideal cumulated gain for the three scenarios:None, Doctors and Patients.
For topic 28 most of thehighly relevant and fairly relevant documents were as-sessed to have target group Doctors.
Topic 36 had the rel-evant documents spread fairly evenly between the Doc-tors and Patients target groups.
Topic 92 showed no doc-uments of any relevance grade for documents marked fortarget group Doctors.
Thus the None and the Patientsideal gain vector coincide fully, while the cumulated gainfor the Doctors scenario is very low.doctor and patient documents.
Topic 36 has fairlysimilar cumulated gain curves for the Doctors andPatients scenarios.
Topic 28 has a majority of doc-tor documents, while topic 92 had no documents ofany relevance grade for documents marked for tar-get group Doctors.
Thus the None and the Patientsideal gain vector coincide fully, while the cumulatedgain for the Doctors scenario is very low, originatingfrom downgraded patient documents.9 Example RunsTo demonstrate the effectiveness of search termsfrom the different styles of language of the two tar-get groups, the synonyms anemi ?anemia?
and blod-brist ?blood lack?
were run as search keys for topic51 in the Doctors and Patients scenarios.
anemi is aneoclassical term, belonging to the professional lan-guage and blodbrist is the corresponding lay personterm.In the Doctors scenario the difference betweenthe results of the two search keys was striking: fullrecall for the neoclassical term quite early in theranked list of documents and no recall at all for thelay person term.
The Patients scenario did not showas big difference between the search keys.
Note thatthe resulting ranked lists of documents is the samefor both scenarios for the same search key.
It is therelevance grades of the retrieved documents that dif-fer.Scenario Recall anemi blodbristDoctors @10 50% (4/8) 0% (0/8)@20 100% (8/8) 0% (0/8)@100 100% (8/8) 0% (0/8)Patients @10 22% (4/18) 33% (6/18)@20 39% (7/18) 39% (7/18)@100 66% (12/18) 56% (10/18)Table 5: Running the synonyms anemi ?anemia?
andblodbrist ?blood lack?
as search keys for topic 51 in theDoctors scenario gave full recall early in the ranking listfor the neoclassical term anemi, but no recall at all forthe lay person term blodbrist.
In the Patients scenario thedifference in effectiveness for these search keys was notas striking.610 Final WordsThis paper shows a few aspects of medical informa-tion retrieval which can be studied with the use ofthe MedEval test collection.
The main novelty of thecollection is the marking of document target groups,Doctors and Patients, together with with the possi-bility to choose user group.
This opens up new areasof research in Swedish information retrieval such ashow one can retrieve documents suited for differentgroups of users.The Department of Swedish at the University ofGothenburg is in the process of making the MedEvaltest collection available to academic researchers.AcknowledgmentsThe author would like to thank the FIRE (FinnishInformation Retrieval Experts) research group at theUniversity of Tampere, Finland, for their invaluablehelp in building the MedEval test collection.ReferencesOSHUMED.
2007.
The OHSUMED test collection.
[www] <http://ir.ohsu.edu/ohsumed/ohsumed.html>.Kalervo Ja?rvelin and Jaana Keka?la?inen.
2002.
Cumu-lated gain-based evaluation of IR techniques.
ACMTransactions on Information Systems, Vol.
20, No.4,pages 422-446.Dimitrios Kokkinakis.
2004.
Medlex: Tech-nical report.
Department of Swedish, Uni-versity of Gothenburg, Sweden.
[www]<http://demo.spraakdata.gu.se/svedk/pbl/MEDLEXwork2004.pdf>.7
