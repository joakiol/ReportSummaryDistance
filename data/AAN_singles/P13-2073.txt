Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 412?418,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsLanguage Independent Connectivity Strength Featuresfor Phrase Pivot Statistical Machine TranslationAhmed El Kholy, Nizar HabashCenter for Computational Learning Systems, Columbia University{akholy,habash}@ccls.columbia.eduGregor Leusch, Evgeny MatusovScience Applications International Corporation{gregor.leusch,evgeny.matusov}@saic.comHassan SawafeBay Inc.hsawaf@ebay.comAbstractAn important challenge to statistical ma-chine translation (SMT) is the lack of par-allel data for many language pairs.
Onecommon solution is to pivot through athird language for which there exist par-allel corpora with the source and targetlanguages.
Although pivoting is a robusttechnique, it introduces some low qualitytranslations.
In this paper, we present twolanguage-independent features to improvethe quality of phrase-pivot based SMT.The features, source connectivity strengthand target connectivity strength reflect thequality of projected alignments betweenthe source and target phrases in the pivotphrase table.
We show positive results (0.6BLEU points) on Persian-Arabic SMT asa case study.1 IntroductionOne of the main issues in statistical machine trans-lation (SMT) is the scarcity of parallel data formany language pairs especially when the sourceand target languages are morphologically rich.
Acommon SMT solution to the lack of parallel datais to pivot the translation through a third language(called pivot or bridge language) for which thereexist abundant parallel corpora with the sourceand target languages.
The literature covers manypivoting techniques.
One of the best performingtechniques, phrase pivoting (Utiyama and Isahara,2007), builds an induced new phrase table betweenthe source and target.
One of the main issues ofthis technique is that the size of the newly cre-ated pivot phrase table is very large (Utiyama andIsahara, 2007).
Moreover, many of the producedphrase pairs are of low quality which affects thetranslation choices during decoding and the over-all translation quality.
In this paper, we introducelanguage independent features to determine thequality of the pivot phrase pairs between sourceand target.
We show positive results (0.6 BLEUpoints) on Persian-Arabic SMT.Next, we briefly discuss some related work.
Wethen review two common pivoting strategies andhow we use them in Section 3.
This is followed byour approach to using connectivity strength fea-tures in Section 4.
We present our experimentalresults in Section 5.2 Related WorkMany researchers have investigated the use of piv-oting (or bridging) approaches to solve the datascarcity issue (Utiyama and Isahara, 2007; Wu andWang, 2009; Khalilov et al, 2008; Bertoldi et al,2008; Habash and Hu, 2009).
The main idea is tointroduce a pivot language, for which there existlarge source-pivot and pivot-target bilingual cor-pora.
Pivoting has been explored for closely re-lated languages (Hajic?
et al, 2000) as well as un-related languages (Koehn et al, 2009; Habash andHu, 2009).
Many different pivot strategies havebeen presented in the literature.
The followingthree are perhaps the most common.The first strategy is the sentence translationtechnique in which we first translate the sourcesentence to the pivot language, and then translatethe pivot language sentence to the target language412(Khalilov et al, 2008).The second strategy is based on phrase pivot-ing (Utiyama and Isahara, 2007; Cohn and Lap-ata, 2007; Wu and Wang, 2009).
In phrase pivot-ing, a new source-target phrase table (translationmodel) is induced from source-pivot and pivot-target phrase tables.
Lexical weights and transla-tion probabilities are computed from the two trans-lation models.The third strategy is to create a synthetic source-target corpus by translating the pivot side ofsource-pivot corpus to the target language using anexisting pivot-target model (Bertoldi et al, 2008).In this paper, we build on the phrase pivotingapproach, which has been shown to be the bestwith comparable settings (Utiyama and Isahara,2007).
We extend phrase table scores with twoother features that are language independent.Since both Persian and Arabic are morphologi-cally rich, we should mention that there has beena lot of work on translation to and from morpho-logically rich languages (Yeniterzi and Oflazer,2010; Elming and Habash, 2009; El Kholy andHabash, 2010a; Habash and Sadat, 2006; Katholand Zheng, 2008).
Most of these efforts are fo-cused on syntactic and morphological processingto improve the quality of translation.To our knowledge, there hasn?t been a lot ofwork on Persian and Arabic as a language pair.The only effort that we are aware of is basedon improving the reordering models for Persian-Arabic SMT (Matusov and Ko?pru?, 2010).3 Pivoting StrategiesIn this section, we review the two pivoting strate-gies that are our baselines.
We also discuss howwe overcome the large expansion of source-to-target phrase pairs in the process of creating apivot phrase table.3.1 Sentence PivotingIn sentence pivoting, English is used as an inter-face between two separate phrase-based MT sys-tems; Persian-English direct system and English-Arabic direct system.
Given a Persian sentence,we first translate the Persian sentence from Per-sian to English, and then from English to Arabic.3.2 Phrase PivotingIn phrase pivoting (sometimes called triangulationor phrase table multiplication), we train a Persian-to-Arabic and an English-Arabic translation mod-els, such as those used in the sentence pivotingtechnique.
Based on these two models, we inducea new Persian-Arabic translation model.Since we build our models on top of Mosesphrase-based SMT (Koehn et al, 2007), we needto provide the same set of phrase translation prob-ability distributions.1 We follow Utiyama and Isa-hara (2007) in computing the probability distribu-tions.
The following are the set of equations usedto compute the lexical probabilities (?)
and thephrase probabilities (pw)?
(f |a) =?e?
(f |e)?(e|a)?
(a|f) =?e?(a|e)?
(e|f)pw(f |a) =?epw(f |e)pw(e|a)pw(a|f) =?epw(a|e)pw(e|f)where f is the Persian source phrase.
e isthe English pivot phrase that is common in bothPersian-English translation model and English-Arabic translation model.
a is the Arabic targetphrase.We also build a Persian-Arabic reordering tableusing the same technique but we compute the re-ordering weights in a similar manner to Henriquezet al (2010).As discussed earlier, the induced Persian-Arabic phrase and reordering tables are very large.Table 1 shows the amount of parallel corporaused to train the Persian-English and the English-Arabic and the equivalent phrase table sizes com-pared to the induced Persian-Arabic phrase table.2We introduce a basic filtering technique dis-cussed next to address this issue and present somebaseline experiments to test its performance inSection 5.3.3.3 Filtering for Phrase PivotingThe main idea of the filtering process is to selectthe top [n] English candidate phrases for each Per-sian phrase from the Persian-English phrase ta-ble and similarly select the top [n] Arabic targetphrases for each English phrase from the English-Arabic phrase table and then perform the pivot-ing process described earlier to create a pivoted1Four different phrase translation scores are computed inMoses?
phrase tables: two lexical weighting scores and twophrase translation probabilities.2The size of the induced phrase table size is computed butnot created.413Training Corpora Phrase TableTranslation Model Size # Phrase Pairs SizePersian-English ?4M words 96,04,103 1.1GBEnglish-Arabic ?60M words 111,702,225 14GBPivot Persian-Arabic N/A 39,199,269,195 ?2.5TBTable 1: Translation Models Phrase Table comparison in terms of number of line and sizes.Persian-Arabic phrase table.
To select the top can-didates, we first rank all the candidates based onthe log linear scores computed from the phrasetranslation probabilities and lexical weights mul-tiplied by the optimized decoding weights then wepick the top [n] pairs.We compare the different pivoting strategiesand various filtering thresholds in Section 5.3.4 ApproachOne of the main challenges in phrase pivoting isthe very large size of the induced phrase table.It becomes even more challenging if either thesource or target language is morphologically rich.The number of translation candidates (fanout) in-creases due to ambiguity and richness (discussedin more details in Section 5.2) which in returnincreases the number of combinations betweensource and target phrases.
Since the only criteriaof matching between the source and target phraseis through a pivot phrase, many of the inducedphrase pairs are of low quality.
These phrase pairsunnecessarily increase the search space and hurtthe overall quality of translation.To solve this problem, we introduce twolanguage-independent features which are added tothe log linear space of features in order to deter-mine the quality of the pivot phrase pairs.
We callthese features connectivity strength features.Connectivity Strength Features provide twoscores, Source Connectivity Strength (SCS) andTarget Connectivity Strength (TCS).
These twoscores are similar to precision and recall metrics.They depend on the number of alignment links be-tween words in the source phrase to words of thetarget phrase.
SCS and TSC are defined in equa-tions 1 and 2 where S = {i : 1 ?
i ?
S} is theset of source words in a given phrase pair in thepivot phrase table and T = {j : 1 ?
j ?
T}is the set of the equivalent target words.
Theword alignment between S and T is defined asA = {(i, j) : i ?
S and j ?
T }.SCS = |A||S| (1)TCS = |A||T | (2)We get the alignment links by projecting thealignments of source-pivot to the pivot-targetphrase pairs used in pivoting.
If the source-targetphrase pair are connected through more than onepivot phrase, we take the union of the alignments.In contrast to the aggregated values representedin the lexical weights and the phrase probabilities,connectivity strength features provide additionalinformation by counting the actual links betweenthe source and target phrases.
They provide anindependent and direct approach to measure howgood or bad a given phrase pair are connected.Figure 1 and 2 are two examples (one good, onebad) Persian-Arabic phrase pairs in a pivot phrasetable induced by pivoting through English.3 In thefirst example, each Persian word is aligned to anArabic word.
The meaning is preserved in bothphrases which is reflected in the SCS and TCSscores.
In the second example, only one Persianword in aligned to one Arabic word in the equiv-alent phrase and the two phrases conveys two dif-ferent meanings.
The English phrase is not a goodtranslation for either, which leads to this bad pair-ing.
This is reflected in the SCS and TCS scores.5 ExperimentsIn this section, we present a set of baseline ex-periments including a simple filtering technique toovercome the huge expansion of the pivot phrasetable.
Then we present our results in using connec-tivity strength features to improve Persian-Arabicpivot translation quality.3We use the Habash-Soudi-Buckwalter Arabic transliter-ation (Habash et al, 2007) in the figures with extensions forPersian as suggested by Habash (2010).414Persian: "A?tmAd"myAn"dw"k?wr " " "?
?"??"()"?"?%$#"?,-.
?""
" " " " " " " " " " " "?trust"between"the"two"countries?
"English: "trust"between"the"two"countries"Arabic:" "Al?q?
"byn"Aldwltyn " " " "?
/012?52?2$3"34"?
?""
" " " " " " " " " " " "?the"trust"between"the"two"countries?
"Figure 1: An example of strongly connected Persian-Arabic phrase pair through English.
All Persianwords are connected to one or more Arabic words.
SCS=1.0 and TCS=1.0.Persian: "AyjAd"cnd"?rkt"m?trk " " " "?
0/.+?",+*(")'&"?$#"?
?""
" " " " " " " " " " " "?Establish"few"joint"companies?
"English: "joint"ventures"Arabic:" "b?D"?rkAt"AlmqAwlAt"fy"Albld" "?
123"?<=>&";:"?89"?6?",+5"?
?""
" " " " " " " " " " " "?Some"construcBon"companies"in"the"country?
"Figure 2: An example of weakly connected Persian-Arabic phrase pairs through English.
Only onePersian word is connected to an Arabic word.
SCS=0.25 and TCS=0.2.5.1 Experimental SetupIn our pivoting experiments, we build two SMTmodels.
One model to translate from Persian toEnglish and another model to translate from En-glish to Arabic.
The English-Arabic parallel cor-pus is about 2.8M sentences (?60M words) avail-able from LDC4 and GALE5 constrained data.
Weuse an in-house Persian-English parallel corpus ofabout 170K sentences and 4M words.Word alignment is done using GIZA++ (Ochand Ney, 2003).
For Arabic language model-ing, we use 200M words from the Arabic Giga-word Corpus (Graff, 2007) together with the Ara-bic side of our training data.
We use 5-gramsfor all language models (LMs) implemented us-ing the SRILM toolkit (Stolcke, 2002).
For En-glish language modeling, we use English Giga-word Corpus with 5-gram LM using the KenLMtoolkit (Heafield, 2011).All experiments are conducted using the Mosesphrase-based SMT system (Koehn et al, 2007).We use MERT (Och, 2003) for decoding weight4LDC Catalog IDs: LDC2005E83, LDC2006E24,LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05,LDC2007E06, LDC2007E101, LDC2007E103,LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56,LDC2008G05, LDC2009E16, LDC2009G01.5Global Autonomous Language Exploitation, or GALE,is a DARPA-funded research project.optimization.
For Persian-English translationmodel, weights are optimized using a set 1000 sen-tences randomly sampled from the parallel cor-pus while the English-Arabic translation modelweights are optimized using a set of 500 sen-tences from the 2004 NIST MT evaluation testset (MT04).
The optimized weights are used forranking and filtering (discussed in Section 3.3).We use a maximum phrase length of size 8across all models.
We report results on an in-house Persian-Arabic evaluation set of 536 sen-tences with three references.
We evaluate usingBLEU-4 (Papineni et al, 2002) and METEOR(Lavie and Agarwal, 2007).5.2 Linguistic PreprocessingIn this section we present our motivation andchoice for preprocessing Arabic, Persian, Englishdata.
Both Arabic and Persian are morphologi-cally complex languages but they belong to twodifferent language families.
They both expressrichness and linguistic complexities in differentways.One aspect of Arabic?s complexity is its vari-ous attachable clitics and numerous morphologi-cal features (Habash, 2010).
We follow ElKholy and Habash (2010a) and use the PATB to-kenization scheme (Maamouri et al, 2004) in our415experiments.
We use MADA v3.1 (Habash andRambow, 2005; Habash et al, 2009) to tokenizethe Arabic text.
We only evaluate on detokenizedand orthographically correct (enriched) output fol-lowing the work of El Kholy and Habash (2010b).Persian on the other hand has a relatively sim-ple nominal system.
There is no case system andwords do not inflect with gender except for a fewanimate Arabic loanwords.
Unlike Arabic, Persianshows only two values for number, just singularand plural (no dual), which are usually marked byeither the suffix A?+ +hA and sometimes 	?
@+ +An,or one of the Arabic plural markers.
Verbal mor-phology is very complex in Persian.
Each verbhas a past and present root and many verbs haveattached prefix that is regarded part of the root.A verb in Persian inflects for 14 different tense,mood, aspect, person, number and voice combina-tion values (Rasooli et al, 2013).
We use Perstem(Jadidinejad et al, 2010) for segmenting Persiantext.English, our pivot language, is quite differentfrom both Arabic and Persian.
English is poorin morphology and barely inflects for number andtense, and for person in a limited context.
Englishpreprocessing simply includes down-casing, sepa-rating punctuation and splitting off ?
?s?.5.3 Baseline EvaluationWe compare the performance of sentence pivot-ing against phrase pivoting with different filteringthresholds.
The results are presented in Table 2.
Ingeneral, the phrase pivoting outperforms the sen-tence pivoting even when we use a small filteringthreshold of size 100.
Moreover, the higher thethreshold the better the performance but with a di-minishing gain.Pivot Scheme BLEU METEORSentence Pivoting 19.2 36.4Phrase Pivot F100 19.4 37.4Phrase Pivot F500 20.1 38.1Phrase Pivot F1K 20.5 38.6Table 2: Sentence pivoting versus phrase pivotingwith different filtering thresholds (100/500/1000).We use the best performing setup across the restof the experiments.5.4 Connectivity Strength FeaturesEvaluationIn this experiment, we test the performance ofadding the connectivity strength features (+Conn)to the best performing phrase pivoting model(Phrase Pivot F1K).Model BLEU METEORSentence Pivoting 19.2 36.4Phrase Pivot F1K 20.5 38.6Phrase Pivot F1K+Conn 21.1 38.9Table 3: Connectivity strength features experi-ment result.The results in Table 3 show that we get anice improvement of ?0.6/0.5 (BLEU/METEOR)points by adding the connectivity strength fea-tures.
The differences in BLEU scores betweenthis setup and all other systems are statisticallysignificant above the 95% level.
Statistical signif-icance is computed using paired bootstrap resam-pling (Koehn, 2004).6 Conclusion and Future WorkWe presented an experiment showing the effect ofusing two language independent features, sourceconnectivity score and target connectivity score,to improve the quality of pivot-based SMT.
Weshowed that these features help improving theoverall translation quality.
In the future, we planto explore other features, e.g., the number of thepivot phases used in connecting the source and tar-get phrase pair and the similarity between thesepivot phrases.
We also plan to explore languagespecific features which could be extracted fromsome seed parallel data, e.g., syntactic and mor-phological compatibility of the source and targetphrase pairs.AcknowledgmentsThe work presented in this paper was possiblethanks to a generous research grant from ScienceApplications International Corporation (SAIC).The last author (Sawaf) contributed to the effortwhile he was at SAIC.
We would like to thank M.Sadegh Rasooli and Jon Dehdari for helpful dis-cussions and insights into Persian.
We also thankthe anonymous reviewers for their insightful com-ments.416ReferencesNicola Bertoldi, Madalina Barbaiani, Marcello Fed-erico, and Roldano Cattoni.
2008.
Phrase-basedstatistical machine translation with pivot languages.Proceeding of IWSLT, pages 143?149.Trevor Cohn and Mirella Lapata.
2007.
Ma-chine translation by triangulation: Making ef-fective use of multi-parallel corpora.
In AN-NUAL MEETING-ASSOCIATION FOR COMPU-TATIONAL LINGUISTICS, volume 45, page 728.Ahmed El Kholy and Nizar Habash.
2010a.
Ortho-graphic and Morphological Processing for English-Arabic Statistical Machine Translation.
In Proceed-ings of Traitement Automatique du Langage Naturel(TALN-10).
Montre?al, Canada.Ahmed El Kholy and Nizar Habash.
2010b.
Tech-niques for Arabic Morphological Detokenizationand Orthographic Denormalization.
In Proceed-ings of the seventh International Conference on Lan-guage Resources and Evaluation (LREC), Valletta,Malta.Jakob Elming and Nizar Habash.
2009.
SyntacticReordering for English-Arabic Phrase-Based Ma-chine Translation.
In Proceedings of the EACL 2009Workshop on Computational Approaches to SemiticLanguages, pages 69?77, Athens, Greece, March.David Graff.
2007.
Arabic Gigaword 3, LDC Cat-alog No.
: LDC2003T40.
Linguistic Data Consor-tium, University of Pennsylvania.Nizar Habash and Jun Hu.
2009.
Improving Arabic-Chinese Statistical Machine Translation using En-glish as Pivot Language.
In Proceedings of theFourth Workshop on Statistical Machine Transla-tion, pages 173?181, Athens, Greece, March.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and Morphologi-cal Disambiguation in One Fell Swoop.
In Proceed-ings of the 43rd Annual Meeting of the Associationfor Computational Linguistics (ACL?05), pages 573?580, Ann Arbor, Michigan.Nizar Habash and Fatiha Sadat.
2006.
Arabic Pre-processing Schemes for Statistical Machine Transla-tion.
In Proceedings of the Human Language Tech-nology Conference of the NAACL, Companion Vol-ume: Short Papers, pages 49?52, New York City,USA.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van denBosch and A. Soudi, editors, Arabic Computa-tional Morphology: Knowledge-based and Empiri-cal Methods.
Springer.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.MADA+TOKAN: A toolkit for Arabic tokenization,diacritization, morphological disambiguation, POStagging, stemming and lemmatization.
In KhalidChoukri and Bente Maegaard, editors, Proceedingsof the Second International Conference on ArabicLanguage Resources and Tools.
The MEDAR Con-sortium, April.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing.
Morgan & Claypool Publish-ers.Jan Hajic?, Jan Hric, and Vladislav Kubon.
2000.
Ma-chine Translation of Very Close Languages.
In Pro-ceedings of the 6th Applied Natural Language Pro-cessing Conference (ANLP?2000), pages 7?12, Seat-tle.Kenneth Heafield.
2011.
KenLM: Faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages187?197, Edinburgh, UK.Carlos Henriquez, Rafael E. Banchs, and Jose?
B.Marin?o.
2010.
Learning reordering models for sta-tistical machine translation with a pivot language.Amir Hossein Jadidinejad, Fariborz Mahmoudi, andJon Dehdari.
2010.
Evaluation of PerStem: a sim-ple and efficient stemming algorithm for Persian.
InMultilingual Information Access Evaluation I. TextRetrieval Experiments, pages 98?101.Andreas Kathol and Jing Zheng.
2008.
Strategies forbuilding a Farsi-English smt system from limited re-sources.
In Proceedings of the 9th Annual Confer-ence of the International Speech Communication As-sociation (INTERSPEECH2008), pages 2731?2734,Brisbane, Australia.M.
Khalilov, Marta R. Costa-juss, Jos A. R. Fonollosa,Rafael E. Banchs, B. Chen, M. Zhang, A. Aw, H. Li,Jos B. Mario, Adolfo Hernndez, and Carlos A. Hen-rquez Q.
2008.
The talp & i2r smt systems for iwslt2008.
In International Workshop on Spoken Lan-guage Translation.
IWSLT 2008, pg.
116?123.Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-pher Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Christopher Dyer, Ondrej Bo-jar, Alexandra Constantin, and Evan Herbst.
2007.Moses: open source toolkit for statistical machinetranslation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational LinguisticsCompanion Volume Proceedings of the Demo andPoster Sessions, pages 177?180, Prague, Czech Re-public.Philipp Koehn, Alexandra Birch, and Ralf Steinberger.2009.
462 machine translation systems for europe.Proceedings of MT Summit XII, pages 65?72.Philipp Koehn.
2004.
Statistical significance tests for-machine translation evaluation.
In Proceedings ofthe Empirical Methods in Natural Language Pro-cessing Conference (EMNLP?04), Barcelona, Spain.Alon Lavie and Abhaya Agarwal.
2007.
Meteor: Anautomatic metric for mt evaluation with high levelsof correlation with human judgments.
In Proceed-ings of the Second Workshop on Statistical MachineTranslation, pages 228?231, Prague, Czech Repub-lic.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.417In NEMLAR Conference on Arabic Language Re-sources and Tools, pages 102?109, Cairo, Egypt.Evgeny Matusov and Selc?uk Ko?pru?.
2010.
Improv-ing reordering in statistical machine translation fromfarsi.
In AMTA The Ninth Conference of the Associ-ation for Machine Translation in the Americas, Den-ver, Colorado, USA.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29(1):19?52.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofthe 41st Annual Meeting on Association for Compu-tational Linguistics-Volume 1, pages 160?167.
As-sociation for Computational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proceed-ings of the 40th Annual Meeting of the Associa-tion for Computational Linguistics, pages 311?318,Philadelphia, PA.Mohammad Sadegh Rasooli, Manouchehr Kouhestani,and Amirsaeid Moloodi.
2013.
Development ofa Persian syntactic dependency treebank.
In The2013 Conference of the North American Chapterof the Association for Computational Linguistics:Human Language Technologies (NAACL HLT), At-lanta, USA.Andreas Stolcke.
2002.
SRILM - an Extensible Lan-guage Modeling Toolkit.
In Proceedings of the In-ternational Conference on Spoken Language Pro-cessing (ICSLP), volume 2, pages 901?904, Denver,CO.Masao Utiyama and Hitoshi Isahara.
2007.
A com-parison of pivot methods for phrase-based statisticalmachine translation.
In Human Language Technolo-gies 2007: The Conference of the North AmericanChapter of the Association for Computational Lin-guistics; Proceedings of the Main Conference, pages484?491, Rochester, New York, April.
Associationfor Computational Linguistics.Hua Wu and Haifeng Wang.
2009.
Revisiting pivotlanguage approach for machine translation.
In Pro-ceedings of the Joint Conference of the 47th AnnualMeeting of the ACL and the 4th International JointConference on Natural Language Processing of theAFNLP, pages 154?162, Suntec, Singapore, August.Association for Computational Linguistics.Reyyan Yeniterzi and Kemal Oflazer.
2010.
Syntax-to-morphology mapping in factored phrase-based sta-tistical machine translation from english to turkish.In Proceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, pages 454?464, Uppsala, Sweden, July.
Association for Com-putational Linguistics.418
