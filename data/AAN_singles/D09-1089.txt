Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 852?861,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPEnhancement of Lexical Concepts Using Cross-lingual Web MiningDmitry DavidovICNCThe Hebrew University of Jerusalemdmitry@alice.nc.huji.ac.ilAri RappoportInstitute of Computer ScienceThe Hebrew University of Jerusalemarir@cs.huji.ac.ilAbstractSets of lexical items sharing a significantaspect of their meaning (concepts) are fun-damental in linguistics and NLP.
Manualconcept compilation is labor intensive, er-ror prone and subjective.
We present aweb-based concept extension algorithm.Given a set of terms specifying a conceptin some language, we translate them toa wide range of intermediate languages,disambiguate the translations using webcounts, and discover additional conceptterms using symmetric patterns.
We thentranslate the discovered terms back intothe original language, score them, and ex-tend the original concept by adding back-translations having high scores.
We eval-uate our method in 3 source languages and45 intermediate languages, using both hu-man judgments and WordNet.
In all cases,our cross-lingual algorithm significantlyimproves high quality concept extension.1 IntroductionA concept (or lexical category) is a set of lex-ical items sharing a significant aspect of theirmeanings (e.g., types of food, tool names, etc).Concepts are fundamental in linguistics and NLP,in thesauri, dictionaries, and various applicationssuch as textual entailment and question answering.Great efforts have been invested in manualpreparation of concept resources such as WordNet(WN).
However, manual preparation is labor in-tensive, which means it is both costly and slowto update.
Applications needing data on somevery specific domain or on a recent news-relatedevent may find such resources lacking.
In addition,manual preparation is error-prone and susceptibleto subjective concept membership decisions, fre-quently resulting in concepts whose terms do notbelong to the same level of granularity1.
As a re-sult, there is a need to find methods for automaticimprovement of concept coverage and quality.The web is a huge up-to-date corpus coveringmany domains, so using it for concept extensionhas the potential to address the above problems.The majority of web pages are written in a fewsalient languages, hence most of the web-based in-formation retrieval studies are done on these lan-guages.
However, due to the substantial growth ofthe multilingual web2, languages in which conceptterms are expressed in the most precise mannerfrequently do not match the language where in-formation is needed.
Moreover, representations ofthe same concept in different languages may com-plement each other.In order to benefit from such cross-lingual in-formation, concept acquisition systems should beable to gather concept terms from many availablelanguages and convert them to the desired lan-guage.
In this paper we present such an algorithm.Given a set of words specifying a concept in somesource language, we translate them to a rangeof intermediate languages and disambiguate thetranslations using web counts.
Then we discoveradditional concept terms using symmetric patternsand translate the discovered terms back into theoriginal language.
Finally we score the back-translations using their intermediate languages?properties, and extend the original concept byadding back-translations having high scores.
Theonly language-specific resource required by the al-gorithm are multilingual dictionaries, and its pro-cessing times are very modest.We performed thorough evaluation for 24 con-cepts in 3 source languages (Hebrew, English andRussian) and 45 intermediate languages.
Conceptdefinitions were taken from existing WordNet sub-trees, and the obtained new terms were manually1See Section 5.1.1.2http://www.internetworldstats.com/stats7.htm852scored by human judges.
In all cases we have sig-nificantly extended the original concept set withhigh precision.
We have also performed a fullyautomatic evaluation with 150 concepts, showingthat the algorithm can re-discover WN conceptswith high precision and recall when given onlypartial lists as input.Section 2 discusses related work, Section 3 de-tails the algorithm, Section 4 describes the evalua-tion protocol and Section 5 presents our results.2 Related workOne of the main goals of this paper is the extensionor automated creation of lexical databases suchas WN.
Due to the importance of WN for NLPtasks, substantial research was done on direct orindirect automated extension of the English WN(e.g., (Snow et al, 2006)) or WN in other lan-guages (e.g., (Vintar and Fi?ser, 2008)).
The major-ity of this research was done on extending the treestructure (finding new synsets (Snow et al, 2006)or enriching WN with new relationships (Cuadrosand Rigau, 2008)) rather than improving the qual-ity of existing concept/synset nodes.
Other re-lated studies develop concept acquisition frame-works for on-demand tasks where concepts are de-fined by user-provided seeds or patterns (Etzioni etal., 2005; Davidov et al, 2007), or for fully unsu-pervised database creation where concepts are dis-covered from scratch (Banko et al, 2007; Davi-dov and Rappoport, 2006).Some papers directly target specific applica-tions, and build lexical resources as a side effect.Named Entity Recognition can be viewed as an in-stance of the concept acquisition problem wherethe desired concepts contain words that are namesof entities of a particular kind, as done in (Fre-itag, 2004) using co-clustering and in (Etzioni etal., 2005) using predefined pattern types.The two main algorithmic approaches to theproblem are pattern-based concept discovery andclustering of context feature vectors.
The latterapproach represents word contexts as vectors insome space and uses similarity measures and au-tomatic clustering in that space (Deerwester et al,1990).
Pereira et al(1993), Curran and Moens(2002) and Lin (1998) use syntactic features in thevector definition.
Pantel and Lin (2002) improveson the latter by clustering by committee.
Cara-ballo (1999) uses conjunction and appositive an-notations in the vector representation.
While greateffort has been made for improving the computa-tional complexity of these methods (Gorman andCurran, 2006), they still remain data and compu-tation intensive.The second major algorithmic approach is touse lexico-syntactic patterns.
Patterns have beenshown to produce more accurate results than fea-ture vectors, at a lower computational cost on largecorpora (Pantel et al, 2004).
In concept acquisi-tion, pattern-based methods were shown to out-perform LSA by a large margin (Widdows andDorow, 2002).
Since (Hearst, 1992), who used amanually prepared set of initial lexical patterns inorder to acquire relationships, numerous pattern-based methods have been proposed for the discov-ery of concepts from seeds (Pantel et al, 2004;Davidov et al, 2007; Pasca et al, 2006).
Most ofthese studies were done for English, while someshow the applicability of their methods to otherlanguages, including Greek, Czech, Slovene andFrench.Most of these papers attempt to discover con-cepts from data available in some specific lan-guage.
Recently several studies have proposed toutilize a second language or several specified lan-guages in order to extract or extend concepts (Vin-tar and Fi?ser, 2008; van der Plas and Tiedemann,2006) or paraphrases (Bosma and Callison-Burch,2007).
However, these methods usually requirethe availability of parallel corpora, which limitstheir usefulness.
Most of these methods utilizedistributional measures, hence they do not possessthe advantages of the pattern-based framework.Unlike in the majority of recent studies, wherethe framework is designed with specific languagesin mind, in our task, in order to take advantageof information from diverse languages, the algo-rithm should be able to deal well with a wide va-riety of possible intermediate languages withoutany manual adaptations.
Relying solely on mul-tilingual dictionaries and the web, our algorithmshould be able to discover language-specific pat-terns and concept terms.
While some of the pro-posed frameworks could potentially be language-independent, little research has been done to con-firm this.
There are a few obstacles that mayhinder applying common pattern-based methodsto other languages.
Many studies utilize parsingor POS tagging, which frequently depend on theavailability and quality of language-specific tools.Some studies specify seed patterns in advance, and853it is not clear whether translated patterns can workwell on different languages.
Also, the absence ofclear word segmentation in some languages (e.g.,Chinese) can make many methods inapplicable.A few recently proposed concept acquisitionmethods require only a handful of seed words andno pattern pre-specification (Davidov et al, 2007;Pasca and Van Durme, 2008).
While these studiesavoid some of the obstacles above, it still remainsopen whether such methods are indeed language-independent.
In the translation to intermediate lan-guages part of our framework, we adapt the algo-rithms in (Davidov and Rappoport, 2006; Davi-dov et al, 2007) to suit diverse languages (includ-ing ones without explicit word segmentation).
Wealso develop a method for efficient automated dis-ambiguation and translation of terms to and fromany available intermediate language.Our study is related to cross-language infor-mation retrieval (CLIR/CLEF) frameworks.
Bothdeal with information extracted from a set of lan-guages.
However, the majority of CLIR stud-ies pursue different targets.
One of the mainCLIR goals is the retrieval of documents basedon explicit queries, when the document lan-guage is not the query language (Volk and Buite-laar, 2002).
These frameworks usually developlanguage-specific tools and algorithms includingparsers and taggers in order to integrate multilin-gual queries and documents (Jagarlamudi and Ku-maran, 2007).
Our goal is to develop a language-independent method using cross-lingual informa-tion, for the extension and improvement of con-cepts rather than the retrieval of documents.
Be-sides, unlike in many CLIR frameworks, interme-diate languages are not specified in advance andthe language of requested data is the same as thelanguage of request, while available informationmay be found in many different intermediate lan-guages.3 The AlgorithmOur algorithm is comprised of the followingstages: (1) given a set of words in a source lan-guage as a specification for some concept, we au-tomatically translate them to a diverse set of inter-mediate languages, using multilingual dictionar-ies; (2) the translations are disambiguated usingweb counts; (3) for each language, we retrieve aset of web snippets where these translations co-appear and apply a pattern-based concept exten-sion algorithm for discovering additional terms;(4) we translate the discovered terms back to thesource language, and disambiguate them; (5) wescore the back-translated terms using data on theirbehavior in the intermediate languages, and mergethe sets obtained from different languages into asingle one, retaining terms whose score passes acertain threshold.
Stages 1-3 of the algorithm havebeen described in (Davidov and Rappoport, 2009),where the goal was to translate a concept given inone language to other languages.
The frameworkpresented here includes the new stages 4-5, and itsgoal and evaluation methods are completely dif-ferent.3.1 Concept specification and translationWe start from a set of words denoting a concept ina given source language.
Thus we may use wordslike (apple, banana, ...) as the definition of theconcept of fruit or (bear, wolf, fox, ...) as the def-inition of wild animals.
In order to reduce noise,we limit the length (in words) of multiword ex-pressions considered as terms.
To calculate thislimit for a language, we randomly take 100 termsfrom the appropriate dictionary and set a limitas Limmwe= round(avg(length(w))) wherelength(w) is the number of words in term w. Forlanguages like Chinese without inherent word seg-mentation, length(w) is the number of charactersin w. While for many languages Limmwe= 1,some languages like Vietnamese usually requiretwo or more words to express terms.3.2 Disambiguation of translated termsOne of the problems in utilization of multilingualinformation is ambiguity of translation.
First, inorder to apply the concept acquisition algorithm,at least some of the given concept terms must beautomatically translated to each intermediate lan-guage.
In order to avoid reliance on parallel cor-pora, which do not exist or are extremely small formost of our language pairs, we use bilingual dic-tionaries.
Such dictionaries usually provide manytranslations, one or more for each sense, so thistranslation is inherently fuzzy.
Second, once weacquire translated term lists for each intermedi-ate language, we need to translate them back tothe source language and such back-translations arealso fuzzy.
In both cases, we need to select the ap-propriate translation for each term.While our desire would be to work with as manylanguages as possible, in practice, some or even854most of the concept terms may be absent from theappropriate dictionary.
Such concept terms are ig-nored.One way to deal with ambiguity is by applyingdistributional methods, usually requiring a largesingle-language corpus or, more frequently, paral-lel corpora.
However, such corpora are not readilyavailable for many languages and domains.
Ex-tracting such statistical information on-demand isalso computationally demanding, limiting its us-ability.
Hence, we take a simple but effectivequery-based approach.
This approach, while be-ing powerful as we show in the evaluation, onlyrelies on a few web queries and does not rely onany language-specific resources or data.We use the conjecture that terms of the sameconcept tend to co-appear more frequently thanones belonging to different concepts3.
Thus, weselect a translation of a term co-appearing mostfrequently with some translation of a differentterm of the same concept.
We estimate how welltranslations of different terms are connected toeach other.
Let C = {Ci} be the given seedwords for some concept.
Let Tr(Ci, n) be then-th available translation of word Ciand Cnt(s)denote the web count of string s obtained by asearch engine.
We select a translation Tr(Ci)according to:F (w1, w2) =Cnt(?w1?
w2?)?
Cnt(?w2?
w1?)Cnt(w1)?
Cnt(w2)Tr(Ci) =argmaxsi(maxsjj 6=i(F (Tr(Ci, si), T r(Cj, sj))))We utilize the Y ahoo!
?x * y?,?x * * y?
wild-cards that allow to count only co-appearanceswhere x and y are separated by a single word orword pair.
As a result, we obtain a set of disam-biguated term translations.
This method is usedboth in order to translate from the source lan-guage to each intermediate language and to back-translate the newly discovered concept terms fromthe intermediate to the source language.The number of queries in this stage depends onthe ambiguity of the concept terms?
translations.In order to decrease the amount of queries, if thereare more than three possible senses we sort themby frequency4and take three senses with mediumfrequency.
This allows us to skip the most ambigu-ous and rare senses without any significant effecton performance.
Also, if the number of combina-3Our results here support this conjecture.4Frequency is estimated by web count for a given word.tions is still too high (>30), we randomly sampleat most 30 of the possible combinations.3.3 Pattern-based extension of concept termsin intermediate languagesWe first mine the web for contexts containingthe translations.
Then we extract from the re-trieved snippets contexts where translated termsco-appear, and detect patterns where they co-appear symmetrically.
Then we use the detectedpatterns to discover additional concept terms.
Inorder to define word boundaries, for each languagewe manually specify boundary characters such aspunctuation/space symbols.
This data, along withdictionaries, is the only language-specific data inour framework.Web mining for translation contexts.
In orderto get language-specific data, we need to restrictweb mining each time to the processed interme-diate language.
This restriction is straightforwardif the alphabet or term translations are language-specific or if the search API supports restriction tothis language5.
In case where there are no suchnatural restrictions, we attempt to detect and addto our queries a few language-specific frequentwords.
Using our dictionaries, we find 1?3 of the15 most frequent words in a desired language thatare unique to that language, and we ?and?
themwith the queries to ensure proper language selec-tion.
This works well for almost all languages (Es-peranto being a notable exception).For each pair A,B of disambiguated term trans-lations, we construct and execute the followingtwo queries: {?A * B?, ?B * A?}6.
When wehave 3 or more terms we also add {A B C D}-likeconjunction queries which include 3-5 words.
Forlanguages with Limmwe> 1, we also constructqueries with several ?*?
wildcards between terms.For each query we collect snippets containing textfragments of web pages.
Such snippets frequentlyinclude the search terms.
Since Y ahoo!
Boss al-lows retrieval of up to the 1000 first results (50 ineach query), we collect several thousands snippets.For most of the intermediate languages, only a fewdozen queries (40 on the average) are required toobtain sufficient data, and queries can be paral-lelized.
Thus the relevant data can be downloaded5Yahoo!
allows restriction for 42 languages.6These are Yahoo!
queries where enclosing words in ?
?means searching for an exact phrase and ?*?
means a wild-card for exactly one arbitrary word.855in seconds.
This makes our approach practical foron-demand retrieval or concept verification tasks.Meta-patterns.
Following (Davidov et al,2007), we seek symmetric patterns to retrieveconcept terms.
We use two meta-pattern types.First, a Two-Slot pattern type constructed asfollows:[Prefix] C1[Infix] C2[Postfix]Ciare slots for concept terms.
We allow up toLimmwespace-separated7words to be in a sin-gle slot.
Infix may contain punctuation, spaces,and up to Limmwe?
4 words.
Prefix and Post-fix are limited to contain punctuation charactersand/or Limmwewords.Terms of the same concept frequently co-appearin lists.
To utilize this, we introduce two additionalList pattern types8:[Prefix] C1[Infix] (Ci[Infix])+ (1)[Infix] (Ci[Infix])+ Cn[Postfix] (2)Following (Widdows and Dorow, 2002), we definea pattern graph.
Nodes correspond to terms andpatterns to edges.
If term pair (w1, w2) appearsin pattern P , we add nodes Nw1, Nw2to the graphand a directed edge EP(Nw1, Nw2) between them.Symmetric patterns.
We consider only sym-metric patterns.
We define a symmetric pat-tern as a pattern where some concept termsCi, Cjappear both in left-to-right and right-to-left order.
For example, if we consider theterms {apple, pineapple} we select a List pattern?
(one Ci, )+ and Cn.?
if we find both ?one apple,one pineapple, one guava and orange.?
and ?onewatermelon, one pineapple and apple.?.
If no suchpatterns are found, we turn to a weaker definition,considering as symmetric those patterns where thesame terms appear in the corpus in at least two dif-ferent slots.
Thus, we select a pattern ?for C1andC2?
if we see both ?for apple and guava,?
and ?fororange and apple,?.Retrieving concept terms.
We collect terms intwo stages.
First, we obtain ?high-quality?
coreterms and then we retrieve potentially more noisyones.
At the first stage we collect all terms9that7As before, for languages without space-based word sep-aration Limmwelimits the number of characters instead.8(E)+ means one or more instances of E.9We do not consider as terms the 50 most frequent words.are bidirectionally connected to at least two differ-ent original translations, and call them core con-cept terms Ccore.
We also add the original ones ascore terms.
Then we detect the rest of the termsCrestthat are connected to the core stronger thanto the remaining words, as follows:Gin(c)={w?Ccore|E(Nw, Nc) ?
E(Nc, Nw)}Gout(c)={w/?Ccore|E(Nw, Nc) ?
E(Nc, Nw)}Crest={c||Gin(c)|>|Gout(c)|}For the sake of simplicity, we do not attempt todiscover more patterns/instances iteratively by re-querying the web.
If we have enough data, we usewindowing to improve result quality.
If we obtainmore than 400 snippets for some concept, we di-vide the data into equal parts, each containing upto 400 snippets.
We apply our algorithm indepen-dently to each part and select only the words thatappear in more than one part.3.4 Back-translation and disambiguationAt the concept acquisition phase of our frameworkwe obtained sets of terms for each intermediatelanguage, each set representing a concept.
In or-der to be useful for the enhancement of the origi-nal concept, these terms are now back-translated tothe source language.
We disambiguate each back-translated term using the process described in Sec-tion 3.2.
Having sets of back-translated terms foreach intermediate language, our goal is to combinethese into a single set.3.5 Scoring and merging the backtranslationsWe do this merging using the following scoringstrategy, assigning for each proposed term t?inconcept C the score S(t?, C), and selecting termswith S(t?, C) > H where H is a predefinedthreshold.Our scoring is based on the two following con-siderations.
First, we assume that terms extractedfrom more languages tend to be less noisy andlanguage-dependent.
Second, we would like to fa-vor languages with less resources for a given con-cept, since noise empirically appears to be lessprominent in such languages10.For language L and concept C = {t1.
.
.
tk}we get a disambiguated set of translations{Tr(t1, L) .
.
.
T r(tk, L)}.
We define relative lan-10Preliminary experimentation, as well as the evaluationresults presented in this paper, support both of these consid-erations.856guage frequency byLFreq(L,C) =?ti?C(Freq(Tr(ti, L)))?L?,ti?C(Freq(Tr(ti, L?
))where Freq(Tr(ti, L)) is a frequency of term?s titranslation to language L estimated by the num-ber of web hits.
Thus languages in which trans-lated concept terms appear more times will gethigher relative frequency, potentially indicating agreater concept translation ambiguity.
Now, foreach new term t?discovered through LNum(t?
)different languages L1.
.
.
LLNum(t?
)we calculatea term score11S(t?, C):S(t?, C) = LNum(t?)?(1?
?iLFreq(Li, C))For each discovered term t?, S(t?, C) ?
[0, LNum(t?
)], while discovery of t?in less fre-quent languages will cause the score to be closer toLNum(t?).
So terms appearing in a greater num-ber of infrequent languages will get higher scores.After the calculation of score for each proposedterm, we retain terms whose scores are above thepredefined threshold H .
In our experiments wehave used H = 3, usually meaning that acquisi-tion of a term through 3-4 uncommon intermedi-ate languages should be enough to accept it.
Thesame score measure can also be used to filter out?bad?
terms in an already existing concept.4 Experimental SetupWe describe here the languages, concepts and dic-tionaries we used in our experiments.4.1 Languages and conceptsOne of the main goals in this research is to takeadvantage of concept data in every possible lan-guage.
As intermediate languages, we used 45 lan-guages including major west European languageslike French or German, Slavic languages like Rus-sian, Semitic languages as Hebrew and Arabic,and diverse Asian languages such as Chinese andPersian.
To configure parameters we have used aset of 10 concepts in Russian as a development set.These concepts were not used in evaluation.We examined a wide variety of concepts and foreach of them we used all languages with availabletranslations.
Table 1 shows the resulting top 10most utilized languages in our experiments.11In this expression i runs only on languages with term t?hence the summation is not 1.English Russian HebrewGerman(68%) English(70%) English(66%)French(60%) German(62%) German(65%)Italian(60%) French(62%) Italian(61%)Portuguese(57%) Spanish(58%) French(59%)Spanish(55%) Italian(56%) Spanish(57%)Turkish(51%) Portuguese(54%) Portuguese(57%)Russian(50%) Korean(50%) Korean(48%)Korean(46%) Turkish(49%) Russian(43%)Chinese(45%) Chinese(47%) Turkish(43%)Czech(42%) Polish (44%) Czech(40%)Table 1: The ten most utilized intermediate languages inour experiments.
In parentheses we show the percentage ofnew terms that these languages helped discover.We have used the English, Hebrew (Ordan andWinter, 2008) and Russian (Gelfenbeynand et al,2003) WordNets as sources for concepts and forthe automatic evaluation.
Our concept set selec-tion was based on English WN subtrees.
To per-form comparable experiments with Russian andHebrew, we have selected the same subtrees inthe Hebrew and Russian WN.
Concept definitionsgiven to human judges for evaluation were basedon the corresponding WN glosses.
For automatedevaluation we selected 150 synsets/subtrees con-taining at least 10 single word terms (existing inall three tested languages).For manual evaluation we used a subset of 24of these concepts.
In this subset we tried to selectgeneric concepts manually, such that no domainexpert knowledge was required to check their cor-rectness.
Ten of these concepts were identical toones used in (Widdows and Dorow, 2002; Davi-dov and Rappoport, 2006), which allowed us tocompare our results to recent work in case of En-glish.
Table 2 shows these 10 concepts along withthe sample terms.
While the number of tested con-cepts is not very large, it provides a good indica-tion for the quality of our approach.Concept Sample termsMusical instruments guitar, flute, pianoVehicles/transport train, bus, carAcademic subjects physics, chemistry, psychologyBody parts hand, leg, shoulderFood egg, butter, breadClothes pants, skirt, jacketTools hammer, screwdriver, wrenchPlaces park, castle, gardenCrimes murder, theft, fraudDiseases rubella, measles, jaundiceTable 2: Ten of the selected concepts with sample terms.8574.2 Multilingual dictionariesWe developed tools for automatic access to a num-ber of dictionaries.
We used Wikipedia cross-language links as our main source (> 60%) foroffline translation.
These links include translationof Wikipedia terms into dozens of languages.
Themain advantage of using Wikipedia is its wide cov-erage of concepts and languages.
However, oneproblem it has is that it frequently encodes toospecific senses and misses common ones (bear istranslated as family Ursidae, missing its common?wild animal?
sense).
To overcome these difficul-ties, we also used Wiktionary and complementedthese offline resources with automated queries toseveral (25) online dictionaries.
We start withWikipedia definitions, then Wiktionary, and then,if not found, we turn to online dictionaries.5 Evaluation and ResultsPotential applications of our framework includeboth the extension of existing lexical databasesand the construction of new databases from a smallset of seeds for each concept.
Consequently, inour evaluation we aim to check both the abilityto extend nearly complete concepts and the abil-ity to discover most of the concept given a fewseeds.
Since in our current framework we extenda small subset of concepts rather than the wholedatabase, we could not utilize application-basedevaluation strategies such as performance in WSDtasks (Cuadros and Rigau, 2008).5.1 Human judgment evaluationIn order to check how well we can extend existingconcepts, we count and verify the quality of newconcept terms discovered by the algorithm givencomplete concepts from WN.
Performing an auto-matic evaluation of such new terms is a challeng-ing task, since there are no exhaustive term listsavailable.
Thus, in order to check how well newlyadded terms fit the concept definition, we have touse human judges.We provided four human subjects with 24 listsof newly discovered terms, together with originalconcept definitions (written as descriptive naturallanguage sentences) and asked them to rank (1-10,10 being best) how well each of these terms fitsthe given definition.
We have instructed judges toaccept common misspellings and reject words thatare too general/narrow for the provided definition.We mixed the discovered terms with equalamounts of terms from three control sets: (1) termsfrom the original WN concept; (2) randomly se-lected WN terms; (3) terms obtained by apply-ing the single-language concept acquisition algo-rithm described in Section 3.3 in the source lan-guage.
Kappa inter-annotator agreement scoreswere above 0.6 for all tests below.5.1.1 WordNet concept extensionThe middle column of Table 3 shows the judgescores and average amount of added terms foreach source language.
In this case the algorithmwas provided with complete term lists as con-cept definitions, and was requested to extend theselists.
We can see that while the scores for originalWN terms are not perfect (7/10), single-languageand cross-lingual concept extension achieve nearlythe same scores.
However, the latter discoversmany more new concept terms without reducingquality.
The difference becomes more substan-tial for Hebrew, which is a resource-poor sourcelanguage, heavily affecting the performance ofsingle-language concept extension methods.The low ranks for WN reflect the ambiguity ofdefinition of some of its classification subtrees.Thus, for the ?body part?
concept defined in Word-Net as ?any part of an organism such as an or-gan or extremity?
(which is not supposed to re-quire domain-specific knowledge to identify) lowscores were given (correctly) by judges to genericterms such as tissue, system, apparatus and pro-cess (process defined in WN as ?a natural pro-longation or projection from a part of an organ-ism?
), positioned in WN as direct hyponyms ofbody parts.
Low scores were also given to veryspecific terms like ?saddle?
(posterior part of theback of a domestic fowl) or very ambiguous termslike ?small?
(the slender part of the back).5.1.2 Seed-based concept extensionThe rightmost column of Table 3 shows similar in-formation to the middle column, but when onlythe three most frequent terms from the originalWN concept were given as concept definitions.We can see that even given three words as seeds,the cross-lingual framework allows to discovermany new terms.
Surprisingly, terms extracted bythe cross-lingual framework achieve significantlyhigher scores not only in comparison to the single-language algorithm but also in comparison to ex-isting WN terms.
Thus while the ?native?
WNconcept and single-language concept extension re-858sults get a score of 7/10, terms obtained by thecross-lingual framework obtain an average scoreof nearly 9/10.This suggests that our cross-lingual frameworkcan lead to better (from a human judgment pointof view) assignment of terms to concepts, even incomparison to manual annotation.Inputall terms 3 termsEnglishWordNet 7.2 7.2Random 1.8 1.8SingleLanguage 7.0(10) 7.8(18)Crosslingual 6.9(19) 8.8(26)RussianWordNet 7.8 7.8Random 1.9 1.9SingleLanguage 7.4(10) 8.1(16)Crosslingual 7.6(21) 9.0(29)HebrewWordNet 7.0 7.0Random 1.3 1.3SingleLanguage 6.5(4) 7.5(6)Crosslingual 6.8(18) 8.9(24)Table 3: Human judgment scores for concept extension inthree languages (1 .
.
.
10, 10 is best).
The WordNet, Randomand SingleLanguage rows provide corresponding baselines.Average count of newly added terms are shown in parenthe-ses.
Average original WN concept size in this set was 36 forEnglish, 32 for Russian and 27 for Hebrew.5.2 WordNet-based evaluationWhile human judgment evaluation provides agood indication for the quality of our framework,it has severe limitations.
Thus terms in many con-cepts require domain expertise to be properly la-beled.
We have complemented human judgmentevaluation with automated WN-based evaluationwith a greater (150) number of concepts.
For eachof the 150 concepts, we have applied our frame-work on a subset of the available terms, and esti-mated precision and recall of the resulting term listin comparison to the original WN term list.
Theevaluation protocol and metrics were very simi-lar to (Davidov and Rappoport, 2006; Widdowsand Dorow, 2002) which allowed us to do indirectcomparison to previous work.Table 4 shows precision and recall for this taskcomparing single-language concept extension andthe cross-lingual framework.
We can see thatin all cases, utilization of the latter greatly im-proves recall.
It also significantly outperformsthe single-language pattern-based method intro-duced by (Davidov and Rappoport, 2006), whichachieves average precision of 79.3 on a similar setin English (in comparison to 86.7 in this study).We can also see a decrease in precision when thealgorithm is provided with 50% of the conceptterms as input and had to discover the remaining50%.
However, careful examination of the resultsshows that this decrease is due to discovery of ad-ditional correct terms not present in WordNet.Input50% terms 3 termsP R F P R FEnglishSingleLanguage 89.2 75.9 82.0 80.6 15.2 25.6CrossLingual 86.5 91.1 88.7 86.7 60.2 71.1RussianSingleLanguage 91.3 69.0 78.6 82.1 18.3 29.9CrossLingual 84.9 86.2 85.5 85.3 62.1 71.9HebrewSingleLanguage 93.8 38.6 54.7 90.2 5.7 10.7CrossLingual 86.5 82.4 84.4 93.9 55.6 69.8Table 4: WordNet-based precision (P) and recall (R) forconcept extension.5.3 Contribution of each languageEach of the 45 languages we used influences thescore of at least 5% of the discovered terms.
How-ever, it is not apparent if all languages are indeedbeneficial or if only a handful of languages canbe used.
In order to check this point we have per-formed partial automated tests as described in Sec-tion 5.2, removing one language at a time.
We alsotried to remove random subsets of 2-3 languages,comparing them to removal of one of them.
Wesaw that in each case removal of more languagescaused a consistent (while sometimes minor) de-crease both in precision and recall metrics.
Thus,each language contributes to the system.6 DiscussionWe proposed a framework which given a set ofterms defining a concept in some language, uti-lizes multilingual information available on theweb in order to extend this list.
This methodallows to take advantage of web data in manylanguages, requiring only multilingual dictionar-ies.
Our method was able to discover a substan-tially greater number of terms than state-of-the-artsingle language pattern-based concept extensionmethods, while retaining high precision.We also showed that concepts obtained by thismethod tend to be more coherent in compari-son to corresponding concepts in WN, a man-ually prepared resource.
Due to its relativelanguage-independence and modest data require-ments, this framework allows gathering required859concept information from the web even if it is scat-tered among different and relatively uncommon orresource-poor languages.ReferencesMishele Banko, Michael J Cafarella , Stephen Soder-land, Matt Broadhead, Oren Etzioni, 2007.
Openinformation extraction from the Web.
IJCAI ?07.Wauter Bosma, Chris Callison-Burch, 2007.
Para-phrase substitution for recognizing textual entail-ment..
Evaluation of Multilingual and MultimodalInformation Retrieval, Lecture Notes in ComputerScience ?07.Sharon Caraballo, 1999.
Automatic construction ofa hypernym-labeled noun hierarchy from text.
ACL?99.Montse Cuadros, German Rigau, 2008.
KnowNet:Building a large net of knowledge from the Web.COLING ?08.James R. Curran, Marc Moens, 2002.
Improvementsin automatic thesaurus extraction SIGLEX 02?, 59?66.Dmitry Davidov, Ari Rappoport, 2006.
Effi-cient unsupervised discovery of word categories us-ing symmetric patterns and high frequency words.COLING-ACL ?06.Dmitry Davidov, Ari Rappoport, Moshe Koppel,2007.
Fully unsupervised discovery of concept-specific relationships by web mining.
ACL ?07.Dmitry Davidov, Ari Rappoport, 2009.
Translationand extension of concepts across languages.
EACL?09.Scott Deerwester, Susan Dumais, George Furnas,Thomas Landauer, Richard Harshman, 1990.
In-dexing by latent semantic analysis.
J. of the Ameri-can Society for Info.
Science, 41(6):391?407.Beate Dorow, Dominic Widdows, Katarina Ling, Jean-Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.Using curvature and Markov clustering in graphs forlexical acquisition and word sense discrimination.MEANING ?05.Oren Etzioni, Michael Cafarella, Doug Downey,S.
Kok, Ana-Maria Popescu, Tal Shaked, StephenSoderland, Daniel Weld, Alexander Yates, 2005.Unsupervised named-entity extraction from theweb: An experimental study.
Artificial Intelligence,165(1):91134.Dayne Freitag, 2004.
Trained named entity recogni-tion using distributional clusters.
EMNLP ?04.Ilya Gelfenbeyn, Artem Goncharuk, Vladislav Lehelt,Anton Lipatov, Victor Shilo, 2003.
Automatictranslation of WordNet semantic network to Russianlanguage (in Russian) International Dialog 2003Workshop.J.
Gorman, J.R. Curran, 2006.
Scaling distributionalsimilarity to large corpora.
COLING-ACL ?06.Marti Hearst, 1992.
Automatic acquisition of hy-ponyms from large text corpora.
COLING ?92.Jagadeesh Jagarlamudi, A Kumaran, 2007.
Cross-lingual information retrieval system for Indian lan-guages.
Working Notes for the CLEF 2007 Work-shop.Dekang Lin, 1998.
Automatic retrieval and clusteringof similar words.
COLING ?98.Noam Ordan, Shuly Wintner, 2007.
Hebrew Word-Net: a test case of aligning lexical databases acrosslanguages.
International Journal of Translation19(1):39-58, 2007.Marius Pasca, Dekang Lin, Jeffrey Bigham, AndreiLifchits, Alpa Jain, 2006.
Names and similarities onthe web: fact extraction in the fast lane.
COLING-ACL ?06.Marius Pasca, Benjamin Van Durme, 2008.
Weakly-supervised acquisition of open-domain classes andclass attributes from web documents and query logs.ACL ?08.Patrick Pantel, Dekang Lin, 2002.
Discovering wordsenses from text.
SIGKDD ?02.Patrick Pantel, Deepak Ravichandran, Eduard Hovy,2004.
Towards terascale knowledge acquisition.COLING ?04.John Paolillo, Daniel Pimienta, Daniel Prado, et al,2005.
Measuring linguistic diversity on the Internet.UNESCO Institute for Statistics Montreal, Canada.Adam Pease, Christiane Fellbaum, Piek Vossen, 2008.Building the global WordNet grid.
CIL18.Fernando Pereira, Naftali Tishby, Lillian Lee, 1993.Distributional clustering of English words.
ACL ?93.Ellen Riloff, Rosie Jones, 1999.
Learning dictionariesfor information extraction by multi-level bootstrap-ping.
AAAI ?99.Rion Snow, Daniel Jurafsky, Andrew Ng, 2006.
Se-mantic taxonomy induction from heterogeneous ev-idence.
COLING-ACL ?06.Lonneke van der Plas, Jorg Tiedemann, 2006.
Find-ing synonyms using automatic word alignment andmeasures of distributional similarity.
COLING-ACL?06.860Martin Volk, Paul Buitelaar, 2002.
A systematic eval-uation of concept-based cross-language informationretrieval in the medical domain.
In: Proc.
of 3rdDutch-Belgian Information Retrieval Workshop.
?Spela Vintar, Darja Fi?ser, 2008.
Harvesting multi-word expressions from parallel corpora.
LREC ?08.Dominic Widdows, Beate Dorow, 2002.
A graphmodel for unsupervised lexical acquisition.
COL-ING ?02.861
