Proceedings of the 6th Workshop on Building and Using Comparable Corpora, pages 11?15,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsBilingual Lexicon Extractionvia Pivot Language and Word Alignment ToolHong-Seok Kwon     Hyeong-Won Seo     Jae-Hoon KimKorea Maritime University,Dongsam-Dong, Yeongdo-Gu, Busan, South Koreahong8c@naver.com, wonn24@gmail.com, jhoon@hhu.ac.krAbstractThis paper presents a simple and effectivemethod for automatic bilingual lexicon extrac-tion from less-known language pairs.
To dothis, we bring in a bridge language named thepivot language and adopt information retrievaltechniques combined with natural languageprocessing techniques.
Moreover, we use afreely available word aligner: Anymalign(Lardilleux et al 2011) for constructing con-text vectors.
Unlike the previous works, weobtain context vectors via a pivot language.Therefore, we do not require to translate con-text vectors by using a seed dictionary and im-prove the accuracy of low frequency wordalignments that is weakness of statistical mod-el by using Anymalign.
In this paper, experi-ments have been conducted on two differentlanguage pairs that are bi-directional Korean-Spanish and Korean-French, respectively.
Theexperimental results have demonstrated thatour method for high-frequency words shows atleast 76.3 and up to 87.2% and for the low-frequency words at least 43.3% and up to 48.9%within the top 20 ranking candidates, respec-tively.1 IntroductionBilingual lexicons are an important resource inmany domains, for example, machine translation,cross-language information retrieval, and so on.The direct way of bilingual lexicon extraction isto align words from a parallel corpus (Wu andXia, 1994), which contains source texts and theirtranslations.
For some language pairs, however,collecting the parallel corpus is not easy and arerestricted to specific domains.
For these reasons,many researchers in bilingual lexicon extractionhave focused on comparable corpora (Fung,1995; Yu and Tsujii, 2009; Ismail andManandhar, 2010).
These corpora are also hardto build on less-known language pairs, for in-stances, Korean and Spanish, Korean and French,and so on.
Therefore, some researchers havestudied the use of pivot languages as an interme-diary language to extract bilingual lexicons(Tanaka and Ummemura, 1994; Wu and Wang,2007; Tsunakawa et al 2008).On the other hand, some researchers adopt in-formation retrieval (IR) techniques to extract bi-lingual lexicons (Fung, 1998; Gaussier et al2004;  Hazem et al 2012).
The techniques arecollecting all the lexical units from each of twolanguages,    and   , respectively, and then aregenerating context vectors   and   for the col-lected lexical units in   and   , respectively.
Thecontext vector,   and   are translated using seeddictionaries, which are manually constructed byhand and of which the size is huge for accuratetranslation.
Finally, the context vectors,    andare compared with each other in order to get theirtranslation candidates.In this paper, we propose a simple and effectivemethod for bilingual lexicons between two less-known language pairs using a pivot language andIR techniques.
The pivot language is used forrepresenting both of context vectors of a sourcelanguage and a target language and IR tech-niques for calculating the similarity between thesource context vector and the target context vec-tor represented by the pivot language.
Unlike theprevious studies, therefore, we use two parallelcorpora, Korean (KR)-English (EN) and English(EN) and English (EN)-Spanish (ES).
Here Eng-lish is the pivot language.
We also use a freeavailable word aligner, called Anymalign to gen-erate the context vectors easily.The proposed method has many advantagessuch as easy adaptation to less-known languagepairs through a pivot language like English, easyextension to multi-word expression, and dramaticreduction in labor-intensive words to get a largescale seed dictionary.The remainder of this paper is organized asfollows: we describe the proposed approach inSection 2.
The experimental results are presentedin Section 3.
Finally Section 4 draws conclusionsand discusses the future works.112 Proposed ApproachIn this paper, a simple and effective method forbilingual lexicons between two less-known lan-guage pairs using a pivot language and IR tech-niques.
We use parallel corpora with more accu-rate alignment information instead of comparablecorpora.
It, however, is difficult to obtain parallelcorpora for less-known language pairs.
For suchreasons, we use a pivot language which is well-known like English.The pivot language is used for representingboth of context vectors of a source language anda target language.
Unlike the previous studiesusing comparable corpora, therefore, we use twoparallel corpora through the pivot language likeKorean (KR)-English (EN) and English (EN)-Spanish (ES) and IR techniques for calculatingthe similarity between the source context vectorand the target context vector represented by thepivot language.In the previous works, translating context-vectors is required using a seed dictionary, but inthis paper, translating them is not needed any-more.
Therefore, any bilingual dictionaries arenot expected.
Besides, we use a free availableword aligner, called Anymalign, to constructcontext-vectors.
Anymalign shows high accuracyfor low-frequency words to extract translationcandidates (Lardilleux et al 2011).
Overallstructure of the proposed method is depicted inFigure 1.
The proposed method can be summa-rized in the following three steps:i.
To build source context vectors and tar-get source context vectors for eachword in the source language (eg.
KR)and the target language (eg.
ES) usingtwo sets of independent parallel corporathat are KR-EN and EN-ES, respective-ly.
All words in context vectors areweighted by Anymalign.ii.
To calculate the similarity between eachword in source context vector and allwords in the target context vectors onthe basis of the cosine measureiii.
To sort the top k word pairs based ontheir similarity scoresTwo parallel corpora share a pivot language,English, in our case, and are used to build con-text vectors because Korean-Spanish bilingualcorpora are publicly unavailable.
Anymalign isused to weight all words in the context vectors.As mentioned before, in the previous work, aseed dictionary is required to translate contextvectors at this time, but we do not carry out them.After context vectors are built once, all sourceand target context vectors are compared eachother to get its similarity between them by usingthe cosine measure.
Finally, top k word pairs areextracted as a result.3 Experiments and ResultsIn this paper, we extract translation candidatesfrom two different language pairs that are bi-directional KR-ES and KR-FR.Figure 1.
Overall structure of the proposed method.123.1 Experimental setting3.1.1 Parallel corporaWe used the KR-EN parallel corpora compiledby Seo et al(2006) (433,151 sentence pairs),and two sets of sub-corpora (500,000 sentencepairs each) that are randomly selected from ES-EN and FR-EN in the Europarl parallel corpus(Koehn, 2005).
The average number of wordsper sentence is described in Table 1 below.
Thenumber of words in ES-EN and FR-EN parallelcorpora is nearly similar, but the number of KRwords (called eojeol in Korean) in KR-EN paral-lel corpus is lower than that of EN words.
In fact,KR words are a little bit different from EN wordsand others.
Korean words consist of one mor-pheme or more.
Therefore, the number of KRwords can be similar to that of EN words if mor-phemes instead of words are counted.KR-EN ES-EN FR-ENKR EN ES EN FR EN19.2 31 26.4 25.4 29.7 27.1Table 1.
The average number of words per sen-tence.3.1.2 Data preprocessingAll words are tokenized by the following tools:Hannanum1 (Lee et al 1999) for Korean, Tree-Tagger2 (Schmid, 1994) for English, Spanish andFrench.
All words in English, Spanish, andFrench are converted to lower case, and those inKorean are morphologically analyzed into mor-phemes and pos-tagged by Hannanum.1 http://kldp.net/projects/hannanum2 http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/3.1.3 Building evaluation dictionaryTo evaluate the performance of the proposedmethod, we build two sets of bilingual lexicons(KR-ES and KR-FR) manually using the Webdictionary3.
Each lexicon is unidirectional, mean-ing that they list the meanings of words of onelanguage in another, and contains 100 high fre-quent words (denoted by HIGH hereafter) and100 low rare words (denoted by LOW hereafter),respectively.
The frequent words are randomlyselected from 50% in high rank and the rarewords from 20% in low rank.
Table 2 shows theaverage number of the translations per sourceword in each lexicon.
The number means thedegree of ambiguity and is same as the numberof polysemous words.EvaluationdictionaryHIGH LOWKR-FR 5.79 2.26KR-ES 7.36 3.12ES-KR 10.31 5.49FR-KR 10.42 6.32Table 2.
The average number of the translationsper source word in the evaluation dictionaries.3.1.4 Evaluation metricsWe evaluate the quality of translation candidatesextracted by the proposed systems.
Similar to theevaluation in information retrieval, the accuracy,the recall, and the mean reciprocal rank (MRR)(Voorhees, 1999) are used as evaluation metrics.The accuracy is the fraction of its translationcandidates that are correct.
The recall is the ratioof the suggested translation candidates that agreewith the marked answer to the total number oftranslations in the evaluation words.
The MRR is3 http://dic.naver.com/Figure 2.
Accuracies of the proposed method for HIGH and LOW words.13the average of the reciprocal ranks of translationcandidates that are correct translations for a sam-ple of evaluation words.3.2 ResultsThe accuracies of the HIGH and LOW words areshown in Figure 2.
As seen in the figure, at thetop 4 below, the accuracies of ES-KR and FR-KR are lower than the others.
The difference canbe attributed to stopwords such cardinal, ordinal,etc.
The stopwords is normalized by Tree-Taggerfor ES and FR, but not normalized by KoreanPOS-tagger (Hannanum).
KR stopwords canbadly affect the accuracies of ES-KR and FR-KR.In Table 3 below, ?300?
and ?4?
are stopwordsand examples of the mistranslation of atenci?n(attention)?
in Spanish.
Accordingly, ???
(at-tention)?
can be extracted as the first translationcandidate if ?300?
and ?4?
are removed as stop-words.RankSourcelanguageTargetlanguageSimilarityscore1 atenci?n 300 0.9992 atenci?n ??
(attention) 0.9933 atenci?n 4 0.8944 atenci?n ?
(eye) 0.8385 atenci?n ??
(gather) 0.802Table 3.
Top 5 translation candidates of?atenci?n (attention)?.The MRR results of the proposed method areshown in Figure 3.
As shown in Figure 3, theMRR of the HIGH words is rapidly increaseduntil the top 5, after then the MRR is steadilyincreased.
This means that correct translationcandidates tend to appear within the top 5.
In thesame experiments, the correct translation candi-dates for the LOW words tend to appear withintop 10.Lastly, the recalls of HIGH and LOW wordsare calculated in Table 4 below.
As seen in thefigure, the best recall is 32.7% on the KR-FR forHIGH words.
One of reasons can be why wordsusually have one sense per corpus in parallelcorpus (Fung, 1998).
Another reason can be whywords do not belong to various domains and ourdata sets only come from European Parliamentproceedings and news article.Top20 RecallLanguage pairs High 100 Low 100KR-FR 32.73% 24.20%KR-ES 27.49% 26.20%ES-KR 29.55% 20.64%FR-KR 27.30% 20.52%Table 4.
Recalls for HIGH and LOW words.Our experimental results show that the pro-posed method is encouraging results because wedo not use any linguistic resources such as a seeddictionary, and that the proposed method is suffi-ciently valuable where parallel corpus is unavail-able between source and target languages.4 ConclusionWe have presented an IR based approach for ex-tracting bilingual lexicons from parallel corpusvia pivot languages.
We showed that the pro-posed method overcomes some of the problemsof previous works that need a seed dictionary anduse comparable corpora instead of parallel corpo-ra in terms of lack of linguistic resources.In future work, we will remove stopwords, andsome words that have similar meaning could beclustered to improve the performance.
Further-more, we will handle multi word expression.Lastly, we plan to resolve a domain-constraint.Figure 3.
MRR of the proposed method for HIGH and LOW words.14AcknowledgmentsThis work was supported by the Korea Ministryof Knowledge Economy (MKE) under GrantNo.10041807ReferencesP.
Fung.
1995.
Compiling bilingual lexicon entriesfrom a non-parallel English-Chinese corpus.
InProceedings of the Third Workshop on VeryLarge Corpora (VLC?95), pages 173-183.P.
Fung.
1998.
A statistical view on bilingual lexiconextraction: from parallel corpora to non-parallelcorpora.
In Proceedings of the Parallel TextProcessing, pages 1-16.E.
Gaussier, J.-M. Renders, I. Matveeva, C. Goutteand H. Dejean.
2004.
A geometric view on bilin-gual lexcion extraction from comparable corpora.In Proceedings of the 42th Annual Meeting ofthe Association for Computational Linguistics,Barcelona, Spain, pages 527-534.A.
Hazem and E. Morin.
2012.
Adaptive dictionaryfor bilingual lexicon extraction from comparablecorpora.
In Proceedings of the 8th InternationalConference on Language Resources and Eval-uation (LREC'12), pages 288-292.A.
Ismail and S. Manandhar.
2010.
Bilingual lexiconextraction from comparable corpora using in-domain terms.
In Proceedings of the Interna-tional Conference on Computational Linguis-tics, pages 481-489.P.
Koehn.
2005.
EuroParl: A parallel corpus for statis-tical machine translation.
In proceedings of theConference on the      Machine TranslationSummit, page 79-86.W.
Lee, S. Kim, G. Kim and K. Choi.
1999.
Imple-mentation of modularized morphological analyzer.In Proceedings of The 11th Annual Conferenceon Human and Cognitive Language Technolo-gy, pages 123-136.A.
Lardilleux, Y. Lepage, and F. Yvon.
2011.
Thecontribution of low frequencies to multilingualsub-sentential alignment: a differential associativeapproach.
International Journal of AdvancedIntelligence, 3(2):189-217.H Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proceedings of Interna-tional Conference on New Methods in Lan-guage Processing, Manchester, UK, pages 44-49.H.
Seo, H. Kim, H. Cho, J. Kim and S. Yang, 2006.Automatically constructing English-Korean paral-lel corpus from web documents.
Korea Infor-mation Proceedings Society, 13(2):161-164.K.
Tanaka and K. Umemura.
1994.
Construction of aBilingual Dictionary Intermediated by a ThirdLanguage.
In Proceedings of the 15th Interna-tional Conference on Computational Linguis-tics (Coling' 94), Kyoto, Japan, August, pages297-303.T.
Tsunakawa, N. Okazaki, and J. Tsujii.
2008.
Build-ing Bilingual Lexicons Using Lexical TranslationProbabilities via Pivot Languages.
In Proceedingsof the      International Conference onComputational Linguistics, Posters Proceedings,pages 18-22.E.
Voorhees.
1999.
The TREC-8 Question AnsweringTrack Report.
In 8th Text Retrieval Conference(TREC-8), pages 77-82.D.
Wu and X. Xia.
1994.
Learning an English-Chinese lexicon from a parallel corpus.
In Pro-ceedings of the First Conference of the Asso-ciation for Machine Translation in the Ameri-cas (AMTA 1994, Columbia, Maryland, USA,October), pages 206-213.H.
Wu and H. Wang.
2007.
Pivot Language Approachfor Phrase-Based Statistical Machine Translation.In Proceedings of 45th Annual Meeting of theAssociation for Computational Linguistics,pages 856-863.K.
Yu and J. Tsujii.
2009.
Bilingual dictionary extrac-tion from Wikipedia.
In Proceedings of the 12thMachine Translation Summit (MTS 2009), Ot-tawa, Ontario, Canada.15
