Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 85?93,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsLemmatization and Lexicalized Statistical Parsing of Morphologically RichLanguages: the Case of FrenchDjam?
SeddahAlpage Inria & Univ.
Paris-SorbonneParis, FranceGrzegorz Chrupa?aSpoken Language System, Saarland Univ.Saarbr?cken, Germany?zlem ?etinog?lu and Josef van GenabithNCLT & CNGL, Dublin City Univ.Dublin, IrelandMarie CanditoAlpage Inria & Univ.
Paris 7Paris, FranceAbstractThis paper shows that training a lexicalizedparser on a lemmatized morphologically-richtreebank such as the French Treebank slightlyimproves parsing results.
We also show thatlemmatizing a similar in size subset of the En-glish Penn Treebank has almost no effect onparsing performance with gold lemmas andleads to a small drop of performance when au-tomatically assigned lemmas and POS tags areused.
This highlights two facts: (i) lemmati-zation helps to reduce lexicon data-sparsenessissues for French, (ii) it also makes the pars-ing process sensitive to correct assignment ofPOS tags to unknown words.1 IntroductionLarge parse-annotated corpora have led to an explo-sion of interest in statistical parsing methods, includ-ing the development of highly successful models forparsing English using the Wall Street Journal PennTreebank (PTB, (Marcus et al, 1994)).
Over thelast 10 years, parsing performance on the PTB hashit a performance plateau of 90-92% f-score usingthe PARSEVAL evaluation metric.
When adapted toother language/treebank pairs (such as German, He-brew, Arabic, Italian or French), to date these mod-els have performed much worse.A number of arguments have been advancedto explain this performance gap, including limitedamounts of training data, differences in treebank an-notation schemes, inadequacies of evaluation met-rics, linguistic factors such as the degree of word or-der variation, the amount of morphological informa-tion available to the parser as well as the effects ofsyncretism prevalent in many morphologically richlanguages.Even though none of these arguments in isola-tion can account for the systematic performance gap,a pattern is beginning to emerge: morphologicallyrich languages tend to be susceptible to parsing per-formance degradation.Except for a residual clitic case system, Frenchdoes not have explicit case marking, yet its mor-phology is considerably richer than that of English,and French is therefore a candidate to serve as aninstance of a morphologically rich language (MRL)that requires specific treatment to achieve reasonableparsing performance.Interestingly, French also exhibits a limitedamount of word order variation occurring at dif-ferent syntactic levels including (i) the word level(e.g.
pre or post nominal adjective, pre or post ver-bal adverbs); (ii) phrase level (e.g.
possible alterna-tions between post verbal NPs and PPs).
In orderto avoid discontinuous constituents as well as tracesand coindexations, treebanks for this language, suchas the French Treebank (FTB, (Abeill?
et al, 2003))or the Modified French Treebank (MFT, (Schluterand van Genabith, 2007)), propose a flat annota-tion scheme with a non-configurational distinctionbetween adjunct and arguments.Finally, the extraction of treebank grammars fromthe French treebanks, which contain less than a thirdof the annotated data as compared to PTB, is subjectto many data sparseness issues that contribute to aperformance ceiling, preventing the statistical pars-ing of French to reach the same level of performanceas for PTB-trained parsers (Candito et al, 2009).This data sparseness bottleneck can be summa-rized as a problem of optimizing a parsing modelalong two axes: the grammar and the lexicon.
Inboth cases, the goal is either to get a more compactgrammar at the rule level or to obtain a consider-85ably less sparse lexicon.
So far, both approacheshave been tested for French using different meansand with different degrees of success.To obtain better grammars, Schluter and van Gen-abith (2007) extracted a subset of an early releaseof the FTB and carried out extensive restructuring,extensions and corrections (referred to as the Modi-fied French Treebank MFT) to support grammar ac-quisition for PCFG-based LFG Parsing (Cahill etal., 2004) while Crabb?
and Candito (2008) slightlymodified the original FTB POS tagset to optimizethe grammar with latent annotations extracted by theBerkeley parser (BKY, (Petrov et al, 2006)).Moreover, research oriented towards adaptingmore complex parsing models to French showedthat lexicalized models such as Collins?
model 2(Collins, 1999) can be tuned to cope effectively withthe flatness of the annotation scheme in the FTB,with the Charniak model (Charniak, 2000) perform-ing particularly well, but outperformed by the BKYparser on French data (Seddah et al, 2009).Focusing on the lexicon, experiments have beencarried out to study the impact of different forms ofword clustering on the BKY parser trained on theFTB.
Candito et al (2009) showed that using goldlemmatization provides a significant increase in per-formance.
Obviously, less sparse lexical data whichretains critical pieces of information can only help amodel to perform better.
This was shown in (Canditoand Crabb?, 2009) where distributional word clus-ters were acquired from a 125 million words corpusand combined with inflectional suffixes extractedfrom the training data.
Training the BKY parserwith 1000 clusters boosts its performance to the cur-rent state-of-the-art with a PARSEVAL F1 score of88.28% (baseline was 86.29 %).We performed the same experiment using theCHARNIAK parser and recorded only a small im-provement (from 84.96% to 85.51%).
Given thefact that lexical information is crucial for lexicalizedparsers in the form of bilexical dependencies, thisresult raises the question whether this kind of clus-tering is in fact too drastic for lexicalized parsers asit may give rise to head-to-head dependencies whichare too coarse.
To answer this question, in this paperwe explore the impact of lemmatization, as a (ratherlimited) constrained form of clustering, on a state-of-the-art lexicalized parser (CHARNIAK).
In orderto evaluate the influence of lemmatization on thisparser (which is known to be highly tuned for En-glish) we carry out experiments on both the FTB andon a lemmatized version of the PTB.
We used goldlemmatization when available and an automatic sta-tistical morphological analyzer (Chrupa?a, 2010) toprovide more realistic parsing results.The idea is to verify whether lemmatization will helpto reduce data sparseness issues due to the Frenchrich morphology and to see if this process, whenapplied to English will harm the performance of aparser optimized for the limited morphology of En-glish.Our results show that the key issue is the way un-seen tokens (lemmas or words) are handled by theCHARNIAK parser.
Indeed, using pure lemma isequally suboptimal for both languages.
On the otherhand, feeding the parser with both lemma and part-of-speech slightly enhances parsing performance forFrench.We first describe our data sets in Section 2, intro-duce our data driven morphology process in Section3, then present experiments in Section 4.
We dis-cuss our results in Section 5 and compare them withrelated research in Section 6 before concluding andoutlining further research.2 CorpusTHE FRENCH TREEBANK is the first annotated andmanually corrected treebank for French.
The data isannotated with labeled constituent trees augmentedwith morphological annotations and functional an-notations of verbal dependents.
Its key properties,compared with the PTB, are the following :Size: The FTB consists of 350,931 tokens and12,351 sentences, that is less than a third of the sizeof PTB.
The average length of a sentence is 28.41tokens.
By contrast, the average sentence length inthe Wall Street Journal section of the PTB is 25.4tokens.A Flat Annotation Scheme: Both the FTB and thePTB are annotated with constituent trees.
However,the annotation scheme is flatter in the FTB.
For in-stance, there are no VPs for finite verbs and only onesentential level for clauses or sentences whether ornot they are introduced by a complementizer.
Onlythe verbal nucleus (VN) is annotated and comprises86the verb, its clitics, auxiliaries, adverbs and nega-tion.Inflection: French morphology is richer than En-glish and leads to increased data sparseness for sta-tistical parsing.
There are 24,098 lexical types inthe FTB, with an average of 16 tokens occurring foreach type.Compounds: Compounds are explicitly annotatedand very frequent in the treebank: 14.52% of to-kens are part of a compound.
Following Canditoand Crabb?
(2009), we use a variation of the tree-bank where compounds with regular syntactic pat-terns have been expanded.
We refer to this instanceas FTB-UC.Lemmatization: Lemmas are included in the tree-bank?s morphological annotations and denote an ab-straction over a group of inflected forms.
As thereis no distinction between semantically ambiguouslexemes at the word form level, polysemic homo-graphs with common inflections are associated withthe same lemma (Abeill?
et al, 2003).
Thus, exceptfor some very rare cases, a pair consisting of a wordform and its part-of-speech unambiguously maps tothe same lemma.2.1 Lemmatizing the Penn TreebankUnlike the FTB, the PTB does not have gold lem-mas provided within the treebank.
We use the finitestate morphological analyzer which comes withinthe English ParGram Grammar (Butt et al, 1999) forlemmatization.
For open class words (nouns, verbs,adjectives, adverbs) the word form is sent to the mor-phological analyzer.
The English ParGram morpho-logical analyzer outputs all possible analyses of theword form.
The associated gold POS from the PTBis used to disambiguate the result.
The same processis applied to closed class words where the word formis different from the lemma (e.g.
?ll for will).
For theremaining parts of speech the word form is assignedto the lemma.Since gold lemmas are not available for the PTB,a large-scale automatic evaluation of the lemmatizeris not possible.
Instead, we conducted two manualevaluations.
First, we randomly extracted 5 sam-ples of 200 <POS,word> pairs from Section 23 ofthe PTB.
Each data set is fed into the lemmatiza-tion script, and the output is manually checked.
Forthe 5x200 <POS,word> sets the number of incorrectlemmas is 1, 3, 2, 0, and 2.
The variance is smallindicating that the results are fairly stable.
For thesecond evaluation, we extracted each unseen wordfrom Section 23 and manually checked the accuracyof the lemmatization.
Of the total of 1802 unseenwords, 394 words are associated with an incorrectlemma (331 unique) and only 8 with an incorrect<POS,lemma> pair (5 unique).
For an overall un-seen word percentage of 3.22%, the lemma accu-racy is 77.70%.
If we assume that all seen wordsare correctly lemmatized, overall accuracy would be99.28%.2.2 Treebank propertiesIn order to evaluate the influence of lemmatizationon comparable corpora, we extracted a random sub-set of the PTB with properties comparable to theFTB-UC (mainly with respect to CFG size and num-ber of tokens).
We call this PTB subset S.PTB.
Ta-ble 1 presents a summary of some relevant featuresof those treebanks.FTBUC S.PTB PTB# of tokens 350,931 350,992 1,152,305# of sentences 12,351 13,811 45,293average length 28,41 25.41 25.44CFG size 607,162 638,955 2,097,757# unique CFG rules 43,413 46,783 91,027# unique word forms 27,130 26,536 47,678# unique lemmas 17,570 20,226 36,316ratio words/lemma 1.544 1.311 1.312Table 1: French and Penn Treebanks propertiesTable 1 shows that the average number of wordforms associated with a lemma (i.e.
the lemma ratio)is higher in the FTB-UC (1.54 words/lemma) than inthe PTB (1.31).
Even though the PTB ratio is lower,it is still large enough to suggest that even the limitedEnglish morphology should be taken into accountwhen aiming at reducing lexicon sparseness.Trying to learn French and English morphologyin a data driven fashion in order to predict lemmafrom word forms is the subject of the next section.3 Morphology learningIn order to assign morphological tags and lemmasto words we use the MORFETTE model (Chrupa?a,2010), which is a variation of the approach describedin (Chrupa?a et al, 2008).87MORFETTE is a sequence labeling model whichcombines the predictions of two classification mod-els (one for morphological tagging and one forlemmatization) at decoding time, using beam search.3.1 Overview of the Morfette modelThe morphological classes correspond simply to the(fine-grained) POS tags.
Lemma classes are editscripts computed from training data: they specifywhich string manipulations (such as character dele-tions and insertions) need to be performed in orderto transform the input string (word form) into thecorresponding output string (lemma).The best sequence of lemmas and morphologicaltags for input sentence x is defined as:(?l, m?)
= arg max(l,m)P (l,m|x)The joint probability is decomposed as follows:P (l0...li,m0...mi|x) =PL(li|mi,x)PM (mi|x)?
P (m0...mi?1, l0...li?1|x)where PL(li|mi,x) is the probability of lemma classl at position i according to the lemma classifier,PM (mi|x) is the probability of the tag m at posi-tion i according to the morphological tag classifier,and x is the sequence of words to label.While Chrupa?a et al (2008) use Maximum En-tropy training to learn PM and PL, here we learnthem using Averaged Perceptron algorithm due toFreund and Schapire (1999).
It is a much simpleralgorithm which in many scenarios (including ours)performs as well as or better than MaxEnt.We also use the general Edit Tree instantiation ofthe edit script as developed in (Chrupa?a, 2008).
Wefind the longest common substring (LCS) betweenthe form w and the lemma w?.
The portions of thestring in the word form before (prefix) and after (suf-fix) the LCS need to be modified in some way, whilethe LCS (stem) stays the same.
If there is no LCS,then we simply record that we need to replace wwith w?
.
As for the modifications to the prefix andthe suffix, we apply the same procedure recursively:we try to find the LCS between the prefix of w andthe prefix of w?.
If we find one, we recurse; if we donot, we record the replacement; we do the same forthe suffix.3.2 Data SetWe trained MORFETTE on the standard splits of theFTB with the first 10% as test set, the next 10% forthe development set and the remaining for training(i.e.
1235/1235/9881 sentences).
Lemmas and part-of-speech tags are given by the treebank annotationscheme.As pointed out in section 2.1, PTB?s lemmas havebeen automatically generated by a deterministic pro-cess, and only a random subset of them have beenmanually checked.
For the remainder of this paper,we treat them as gold, regardless of the errors in-duced by our PTB lemmatizer.The S.PTB follows the same split as the FTB-UC,first 10% for test, next 10% for dev and the last 80%for training (i.e.
1380/1381/11050 sentences).MORFETTE can optionally use a morphologicallexicon to extract features.
For French, we used theextended version of Lefff (Sagot et al, 2006) and forEnglish, the lexicon used in the Penn XTAG project(Doran et al, 1994).
We reduced the granularity ofthe XTAG tag set, keeping only the bare categories.Both lexicons contain around 225 thousands wordform entries.3.3 Performance on French and EnglishTable 2 presents results of MORFETTE applied to thedevelopment and test sets of our treebanks.
Part-of-speech tagging performance for French is state-of-the-art on the FTB-UC, with an accuracy of 97.68%,on the FTB-UC test set, only 0.02 points (absolute)below the MaxEnt POS tagger of Denis and Sagot(2009).
Comparing MORFETTE?s tagging perfor-mance for English is a bit more challenging as weonly trained on one third of the full PTB and evalu-ated on approximately one section, whereas resultsreported in the literature are usually based on train-ing on sections 02-18 and evaluating on either sec-tions 19-21 or 22-24.
For this setting, state-of-the-art POS accuracy for PTB tagging is around 97.33%.On our PTB sample, MORFETTE achieves 96.36%for all words and 89.64 for unseen words.Comparing the lemmatization performance for bothlanguages on the same kind of data is even more dif-ficult as we are not aware of any data driven lem-matizer on the same data.
However, with an overallaccuracy above 98% for the FTB-UC (91.5% for un-88seen words) and above 99% for the S.PTB (95% forunseen words), lemmatization performs well enoughto properly evaluate parsing on lemmatized data.FTBUC S.PTBDEV All Unk.
(4.8) All Unk.
(4.67)POS acc 97.38 91.95 96.36 88.90Lemma acc 98.20 92.52 99.11 95.51Joint acc 96.35 87.16 96.26 87.05TEST All Unk.
(4.62) All Unk.
(5.04)POS acc 97.68 90.52 96.53 89.64Lemma acc 98.36 91.54 99.13 95.72Joint acc 96.74 85.28 96.45 88.49Table 2: POS tagging and lemmatization performance onthe FTB and on the S.PTB4 Parsing ExperimentsIn this section, we present the results of two setsof experiments to evaluate the impact of lemmatiza-tion on the lexicalized statistical parsing of two lan-guages, one morphologically rich (French), but withnone of its morphological features exploited by theCHARNIAK parser, the other (English) being quitethe opposite, with the parser developed mainly forthis language and PTB annotated data.
We show thatlemmatization results in increased performance forFrench, while doing the same for English penalizesparser performance.4.1 Experimental ProtocolData The data sets described in section 3.2 are usedthroughout.
The version of the CHARNIAK parser(Charniak, 2000) was released in August 2005 andrecently adapted to French (Seddah et al, 2009).Metrics We report results on sentences of lengthless than 40 words, with three evaluation met-rics: the classical PARSEVAL Labeled brackets F1score, POS tagging accuracy (excluding punctua-tion tags) and the Leaf Ancestor metric (Sampsonand Babarczy, 2003) which is believed to be some-what more neutral with respect to the treebank an-notation scheme than PARSEVAL (Rehbein and vanGenabith, 2007).Treebank tag sets Our experiments involve the in-clusion of POS tags directly in tokens.
We brieflydescribe our treebank tag sets below.?
FTB-UC TAG SET: ?CC?
This is the tag set de-veloped by (Crabb?
and Candito, 2008) (Table4), known to provide the best parsing perfor-mance for French (Seddah et al, 2009).
Like inthe FTB, preterminals are the main categories,but they are also augmented with a WH flagfor A, ADV, PRO and with the mood for verbs(there are 6 moods).
No information is propa-gated to non-terminal symbols.ADJ ADJWH ADV ADVWH CC CLO CLR CLS CS DETDETWH ET I NC NPP P P+D P+PRO PONCT PREF PROPROREL PROWH V VIMP VINF VPP VPR VSTable 4: CC tag set?
THE PTB TAG SET This tag set is describedat length in (Marcus et al, 1994) and containssupplementary morphological information (e.g.number) over and above what is represented inthe CC tag set for French.
Note that some infor-mation is marked at the morphological level inEnglish (superlative, ?the greatest (JJS)?)
andnot in French (?
le plus (ADV) grand (ADJ)?
).CC CD DT EX FW IN JJ JJR JJS LS MD NN NNP NNPSNNS PDT POS PRP PRP$ RB RBR RBS RP SYM TO UHVB VBD VBG VBN VBP VBZ WDT WP WP$ WRBTable 5: PTB tag set4.2 Cross token variation and parsing impactFrom the source treebanks, we produce 5 versionsof tokens: tokens are generated as either simplePOS tag, gold lemma, gold lemma+gold POS, wordform, and word form+gold POS.
The token versionssuccessively add more morphological information.Parsing results are presented in Table 3.Varying the token form The results show thathaving no lexical information at all (POS-only) re-sults in a small drop of PARSEVAL performance forFrench compared to parsing lemmas, while the cor-responding Leaf Ancestor score is actually higher.For English having no lexical information at allleads to a drop of 2 points in PARSEVAL.
The so-called impoverished morphology of English appearsto bring enough morphological information to raisetagging performance to 95.92% (from POS-only toword-only).For French the corresponding gain is only 2 pointsof POS tagging accuracy.
Moreover, between these89TokensPOS-onlylemma-onlyword-only(1)lemma-POS(1)word-POSFrench Treebank UCF1 score Pos acc.
leaf-Anc.84.48 100 93.9784.77 94.23 93.7684.96 96.26 94.0886.83(1) 98.79 94.6586.13(2) 98.4 94.46Sampled Penn TreebankF1 score Pos acc.
leaf-Anc.85.62 100 94.0287.69 89.22 94.9288.64 95.92 95.1089.59(3) 99.97 95.4189.53(4) 99.96 95.38Table 3: Parsing performance on the FTB-UC and the S.PTB with tokens variations using gold lemmas and gold POS.
( p-value (1) & (2) = 0.007; p-value (3) & (4) = 0.146.
All other configurations are statistically significant.
)two tokens variations, POS-only and word-only,parsing results gain only half a point in PARSEVALand almost nothing in leaf Ancestor.Thus, it seems that encoding more morphology(i.e.
including word forms) in the tokens does notlead to much improvement for parsing French as op-posed to English.
The reduction in data sparsenessdue to the use of lemmas alone is thus not sufficientto counterbalance the lack of morphological infor-mation.However, the large gap between POS taggingaccuracy seen between lemma-only and word-onlyfor English indicates that the parser makes use ofthis information to provide at least reasonable POSguesses.For French, only 0.2 points are gained for PAR-SEVAL results between lemma-only to word-only,while POS accuracy benefits a bit more from includ-ing richer morphological information.This raises the question whether the FTB-UC pro-vides enough data to make its richer morphology in-formative enough for a parsing model.Suffixing tokens with POS tags It is only whengold POS are added to the lemmas that one can seethe advantage of a reduced lexicon for French.
In-deed, performance peaks for this setting (lemma-POS).
The situation is not as clear for English, whereperformance is almost identical when gold POS areadded to lemmas or words.
POS Tagging is nearlyperfect, thus a performance ceiling is reached.
Thevery small differences between those two configura-tions (most noticeable with the Leaf Ancestor scoreof 95.41 vs. 95.38) indicates that the reduced lemmalexicon is actually of some limited use but its impactis negligible compared to perfect tagging.While the lemma+POS setting clearly boosts per-formance for parsing the FTB, the situation is lessclear for English.
Indeed, the lemma+POS and theword+POS gold variations give almost the same re-sults.
The fact that the POS tagging accuracy is closeto 100% in this mode shows that the key parameterfor optimum parsing performance in this experimentis the ability to guess POS for unknown words well.In fact, the CHARNIAK parser uses a two lettersuffix context for its tagging model, and when goldPOS are suffixed to any type of token (being lemmaor word form), the PTB POS tagset is used as a sub-stitute for lack of morphology.It should also be noted that the FTB-UC tag setdoes include some discriminative features (such asPART, INF and so on) but those are expressed bymore than two letters, and therefore a two lettersuffix tag cannot really be useful to discriminatea richer morphology.
For example, in the PTB,the suffix BZ, as in VBZ, always refers to a verb,whereas the FTB pos tag suffix PP, as in NPP(Proper Noun) is also found in POS labels such asVPP (past participle verb).4.3 Realistic Setup: Using Morfette to helpparsingHaving shown that parsing French benefits from areduced lexicon is not enough as results imply that akey factor is POS tag guessing.
We therefore test ourhypothesis in a more realistic set up.
We use MOR-FETTE to lemmatize and tag raw words (instead ofthe ?gold?
lemma-based approach described above),and the resulting corpus is then parsed using the cor-responding training set.In order to be consistent with PARSEVAL POS eval-uation, which does not take punctuation POS intoaccount, we provide a summary of MORFETTE?sperformance for such a configuration in (Table 6).Results shown in Table 7 confirm our initial hy-90POS acc Lemma acc Joint accFTB-UC 97.34 98.12 96.26S.PTB 96.15 99.04 96.07Table 6: PARSEVAL Pos tagging accuracy of treebankstest setpothesis for French.
Indeed, parsing performancepeaks with a setup involving automatically gener-ated lemma and POS pairs, even though the differ-ence with raw words+auto POS is not statisticallysignificant for the PARSEVAL F1 metric1.
Note thatparser POS accuracy does not follow this pattern.
Itis unclear exactly why this is the case.
We specu-late that the parser is helped by the reduced lexiconbut that performance suffers when a <lemma,POS>pair has been incorrectly assigned by MORFETTE,leading to an increase in unseen tokens.
This is con-firmed by parsing the same lemma but with goldPOS.
In that case, parsing performance does not suf-fer too much from CHARNIAK?s POS guessing onunseen data.For the S.PTB, results clearly show that both theautomatic <lemma,POS> and <word,POS> config-urations lead to very similar results (yet statisticallysignificant with a F1 p-value = 0.027); having thesame POS accuracy indicates that most of the workis done at the level of POS guessing for unseentokens, and in this respect the CHARNIAK parserclearly takes advantage of the information includedin the PTB tag set.F1 score Pos acc.
leaf-Anc.S.PTBauto lemma only 87.11 89.82 94.71auto lemma+auto pos (a) 88.15 96.21 94.85word +auto pos (b) 88.28 96.21 94.88F1 p-value: (a) and (b) 0.027auto lemma+gold pos 89.51 99.96 95,36FTB-UCauto lemma only 83.92 92.98 93.53auto lemma+auto pos (c) 85.06 96.04 94.14word +auto pos (d) 84.99 96.47 94.09F1 p-value: (c) and (d) 0.247auto lemma+gold pos 86.39 97.35 94.68Table 7: Realistic evaluation of parsing performance1Statistical significance is computed using Dan Bikel?sstratified shuffling implementation: www.cis.upenn.edu/~dbikel/software.html.5 DiscussionWhen we started this work, we wanted to explorethe benefit of lemmatization as a means to reducedata sparseness issues underlying statistical lexical-ized parsing of small treebanks for morphologicallyrich languages, such as the FTB.
We showed thatthe expected benefit of lemmatization, a less sparselexicon, was in fact hidden by the absence of inflec-tional information, as required by e.g.
the CHAR-NIAK parser to provide good POS guesses for un-seen words.
Even the inclusion of POS tags gen-erated by a state-of-the-art tagger (MORFETTE) didnot lead to much improvement compared to a parserrun in a regular bare word set up.An unexpected effect is that the POS accuracyof the parser trained on the French data does notreach the same level of performance as our tag-ger (96.47% for <word, auto POS> vs. 97.34% forMORFETTE).
Of course, extending the CHARNIAKtagging model to cope with lemmatized input shouldbe enough, because its POS guessing model buildson features such as capitalization, hyphenation anda two-letter suffix (Charniak, 2000).
Those featuresare not present in our current lemmatized input andthus cannot be properly estimated.CHARNIAK also uses the probability that a givenPOS is realized by a previously unobserved word.If any part of a <lemma,POS> pair is incorrect, thenumber of unseen words in the test set would behigher than the one estimated from the training set,which only contained correct lemmas and POS tagsin our setting.
This would lead to unsatisfying POSaccuracy.
This inadequate behavior of the unknownword tagging model may be responsible for the POSaccuracy result for <auto lemma> (cf.
Table 7, lines<auto lemma only> for both treebanks).We believe that this performance degradation (orin this case the somewhat less than expected im-provement in parsing results) calls for the inclusionof all available lexical information in the parsingmodel.
For example, nothing prevents a parsingmodel to condition the generation of a head upona lemma, while the probability to generate a POSwould depend on both morphological features and(potentially) the supplied POS.916 Related WorkA fair amount of recent research in parsing morpho-logically rich languages has focused on coping withunknowns words and more generally with the smalland limited lexicons acquired from treebanks.
Forinstance, Goldberg et al (2009) augment the lex-icon for a generative parsing model by includinglexical probabilities coming from an external lexi-con.
These are estimated using an HMM tagger withBaum-Welch training.
This method leads to a sig-nificant increase of parsing performance over pre-viously reported results for Modern Hebrew.
Ourmethod is more stratified: external lexical resourcesare included as features for MORFETTE and there-fore are not directly seen by the parser besides gen-erated lemma and POS.For parsing German, Versley and Rehbein (2009)cluster words according to linear context features.The clusters are then integrated as features to boost adiscriminative parsing model to cope with unknownwords.
Interestingly, they also include all possibleinformation: valence information, extracted from alexicon, is added to verbs and preterminal nodes areannotated with case/number.
This leads their dis-criminative model to state-of-the-art results for pars-ing German.Concerning French, Candito and Crabb?
(2009)present the results of different clustering methodsapplied to the parsing of FTB with the BKY parser.They applied an unsupervised clustering algorithmon the 125 millions words ?Est Republicain?
corpusto get a reduced lexicon of 1000 clusters which theythen augmented with various features such as capi-talization and suffixes.
Their method is the best cur-rent approach for the probabilistic parsing of Frenchwith a F1 score (<=40) of 88.29% on the standardtest set.
We run the CHARNIAK parser on their clus-terized corpus.
Table 8 summarizes the current state-of-the-art for lexicalized parsing on the FTB-UC.2Clearly, the approach consisting in extending clus-ters with features and suffixes seems to improveCHARNIAK?s performance more than our method.2For this comparison, we also trained the CHARNIAK parseron a disinflected variation of the FTB-UC.
Disinflection is a de-terministic, lexicon based process, standing between stemmingand lemmatization, which preserves POS assignment ambigui-ties (Candito and Crabb?, 2009).In that case, the lexicon is drastically reduced, aswell as the amount of out of vocabulary words(OOVs).
Nevertheless, the relatively low POS ac-curacy, with only 36 OOVs, for this configurationconfirms that POS guessing is the current bottleneckif a process of reducing the lexicon increases POSassignment ambiguities.tokens F1 Pos acc % of OOVsraw word (a) 84.96 96.26 4.89auto <lemma,pos> (b) 85.06 96.04 6.47disinflected (c) 85.45 96.51 3.59cluster+caps+suffixes (d) 85.51 96.89 0.10Table 8: CHARNIAK parser performance summary on theFTB-UC test set (36340 tokens).
Compared to (a), all F1 re-sults, but (b), are statistically significant (p-values < 0.05), dif-ferences between (c) & (d), (b) & (c) and (b) & (d) are not(p-values are resp.
0.12, 0.41 and 0.11).
Note that the (b) &(d) p-value for all sentences is of 0.034, correlating thus theobserved gap in parsing performance between these two con-figuration.7 ConclusionWe showed that while lemmatization can be ofsome benefit to reduce lexicon size and remedy datasparseness for a MRL such as French, the key factorthat drives parsing performance for the CHARNIAKparser is the amount of unseen words resulting fromthe generation of <lemma,POS> pairs for the FTB-UC.
For a sample of the English PTB, morphologi-cal analysis did not produce any significant improve-ment.Finally, even if this architecture has the potential tohelp out-of-domain parsing, adding morphologicalanalysis on top of an existing highly tuned statisti-cal parsing system can result in suboptimal perfor-mance.
Thus, in future we will investigate tighterintegration of the morphological features with theparsing model.AcknowledgmentsD.
Seddah and M. Candito were supported by the ANRSequoia (ANR-08-EMER-013); ?.
?etinog?lu and J.van Genabith by the Science Foundation Ireland (Grant07/CE/I1142) as part of the Centre for Next GenerationLocalisation at Dublin City University; G. Chrupa?a byBMBF project NL-Search (contract 01IS08020B).92ReferencesAnne Abeill?, Lionel Cl?ment, and Fran?ois Toussenel,2003.
Building a Treebank for French.
Kluwer, Dor-drecht.Miriam Butt, Mar?a-Eugenia Ni?o, and Fr?d?riqueSegond.
1999.
A Grammar Writer?s Cookbook.
CSLIPublications, Stanford, CA.Aoife Cahill, Michael Burke, Ruth O?Donovan, Josefvan Genabith, and Andy Way.
2004.
Long-DistanceDependency Resolution in Automatically AcquiredWide-Coverage PCFG-Based LFG Approximations.In Proceedings of the 42nd Annual Meeting of the As-sociation for Computational Linguistics, pages 320?327, Barcelona, Spain.Marie Candito and Beno?t Crabb?.
2009.
Im-proving generative statistical parsing with semi-supervised word clustering.
In Proceedings of the11th International Conference on Parsing Technolo-gies (IWPT?09), pages 138?141, Paris, France, Octo-ber.
Association for Computational Linguistics.Marie Candito, Benoit Crabb?, and Djam?
Seddah.
2009.On statistical parsing of french with supervised andsemi-supervised strategies.
In EACL 2009 WorkshopGrammatical inference for Computational Linguistics,Athens, Greece.Eugene Charniak.
2000.
A maximum entropy inspiredparser.
In Proceedings of the First Annual Meetingof the North American Chapter of the Association forComputational Linguistics (NAACL 2000), pages 132?139, Seattle, WA.Grzegorz Chrupa?a, Georgiana Dinu, and Josef van Gen-abith.
2008.
Learning morphology with morfette.
InIn Proceedings of LREC 2008, Marrakech, Morocco.ELDA/ELRA.Grzegorz Chrupa?a.
2008.
Towards a machine-learningarchitecture for lexical functional grammar parsing.Ph.D.
thesis, Dublin City University.Grzegorz Chrupa?a.
2010.
Morfette: A tool for su-pervised learning of morphology.
http://sites.google.com/site/morfetteweb/.
Version0.3.1.Michael Collins.
1999.
Head Driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania, Philadelphia.Benoit Crabb?
and Marie Candito.
2008.
Exp?riencesd?analyse syntaxique statistique du fran?ais.
In Actesde la 15?me Conf?rence sur le Traitement Automatiquedes Langues Naturelles (TALN?08), pages 45?54, Avi-gnon, France.Pascal Denis and Beno?t Sagot.
2009.
Coupling an anno-tated corpus and a morphosyntactic lexicon for state-of-the-art pos tagging with less human effort.
In Proc.of PACLIC, Hong Kong, China.Christy Doran, Dania Egedi, Beth Ann Hockey, B. Srini-vas, and Martin Zaidel.
1994.
Xtag system: A widecoverage grammar for english.
In Proceedings of the15th conference on Computational linguistics, pages922?928, Morristown, NJ, USA.
Association for Com-putational Linguistics.Yoav Freund and Robert E. Schapire.
1999.
Large mar-gin classification using the perceptron algorithm.
Ma-chine learning, 37(3):277?296.Yoav Goldberg, Reut Tsarfaty, Meni Adler, and MichaelElhadad.
2009.
Enhancing unlexicalized parsing per-formance using a wide coverage lexicon, fuzzy tag-setmapping, and EM-HMM-based lexical probabilities.In Proc.
of EACL-09, pages 327?335, Athens, Greece.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1994.
Building a large annotated cor-pus of English: The Penn TreeBank.
ComputationalLinguistics, 19(2):313?330.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the Association for Com-putational Linguistics, Sydney, Australia, July.
Asso-ciation for Computational Linguistics.Ines Rehbein and Josef van Genabith.
2007.
Treebankannotation schemes and parser evaluation for german.In Proceedings of the 2007 Joint Conference on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), Prague.Benoit Sagot, Lionel Cl?ment, Eric V. de La Clergerie,and Pierre Boullier.
2006.
The lefff 2 syntactic lexi-con for french: Architecture, acquisition, use.
Proc.
ofLREC 06, Genoa, Italy.Geoffrey Sampson and Anna Babarczy.
2003.
A test ofthe leaf-ancestor metric for parse accuracy.
NaturalLanguage Engineering, 9(04):365?380.Natalie Schluter and Josef van Genabith.
2007.
Prepar-ing, restructuring, and augmenting a French Treebank:Lexicalised parsers or coherent treebanks?
In Proc.
ofPACLING 07, Melbourne, Australia.Djam?
Seddah, Marie Candito, and Benoit Crabb?.
2009.Cross parser evaluation and tagset variation: A FrenchTreebank study.
In Proceedings of the 11th Interna-tion Conference on Parsing Technologies (IWPT?09),pages 150?161, Paris, France, October.
Associationfor Computational Linguistics.Yannick Versley and Ines Rehbein.
2009.
Scalable dis-criminative parsing for german.
In Proceedings of the11th International Conference on Parsing Technolo-gies (IWPT?09), pages 134?137, Paris, France, Octo-ber.
Association for Computational Linguistics.93
