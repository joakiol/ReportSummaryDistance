Selecting Text Features for Gene Name Classification:from Documents to TermsGoran Nenadi?1,2, Simon Rice2, Irena Spasi?3, Sophia Ananiadou3, Benjamin Stapley21Dept.
of ComputationUMISTManchester, M60 1QD2Dept.
of BioMolecular SciencesUMISTManchester, M60 1QD3Computer ScienceUniversity of SalfordSalford, M5 4WTAbstractIn this paper we discuss the performanceof a text-based classification approach bycomparing different types of features.
Weconsider the automatic classification ofgene names from the molecular biologyliterature, by using a support-vector ma-chine method.
Classification featuresrange from words, lemmas and stems, toautomatically extracted terms.
Also, sim-ple co-occurrences of genes within docu-ments are considered.
The preliminaryexperiments performed on a set of 3,000S.
cerevisiae gene names and 53,000Medline abstracts have shown that usingdomain-specific terms can improve theperformance compared to the standardbag-of-words approach, in particular forgenes classified with higher confidence,and for under-represented classes.1 IntroductionDynamic development and new discoveries in thedomain of biomedicine have resulted in the hugevolume of the domain literature, which is con-stantly expanding both in the size and thematiccoverage (Blaschke et al, 2002).
The literature,which is still the most relevant and the most usefulknowledge source, is swamped by newly coinedterms and relationships representing and linkingnewly identified or created compounds, genes,drugs, reactions, etc., which makes the existingterminological resources rarely up-to-date.
There-fore, domain knowledge sources need to frequentlyadapt to the advent of such terms by assorting theminto appropriate classes, in order to allow biolo-gists to rapidly acquire, analyse and visualise enti-ties or group of entities (Stapley et al, 2002).Naming conventions solely cannot be used asreliable classification criteria, since they typicallydo not systematically reflect any particular func-tional property or relatedness between biologicalentities.
On the other hand, it has proved surpris-ingly difficult to automatically predict classes forsome types of biological entities based solely onexperimental data (e.g.
the prediction of proteincellular locations from sequences (Eisenhaber andBork, 1998) or the amino acid composition of pro-teins (Nishikawa and Ooi, 1982)).In order to overcome this problem, several lit-erature-based classification methods have beendeveloped (Collier et al 2001; Hatzivassiloglou etal., 2001).
Classification methods typically rely onsupervised machine learning techniques that ex-amine the wider context in which terms are used.For example, Raychaudhuri et al (2002) useddocument-based word counts and naive Bayesianclassification, maximum entropy modelling andnearest-neighbour classification to assign the GOontology codes to a set of genes.
Recently, sup-port-vector machines (SVMs, (Vapnik, 1995))have been widely used as fast, effective and reli-able means for text-based classification, both fordocument classification (Joachims, 1998) and clas-sification of specific named entities (Stapley et al,2002; Kazama et al, 2002).Regardless of the learning approach and targetentities (documents or terms), different types oftext features have been employed for the classifica-tion task.
For example, a bag-of-words approachwas used by Stapley et al (2002) to classify pro-teins, while Collier et al (2001) used orthographicfeatures to classify different biological entities.
Onthe other hand, Hatzivassiloglou et al (2001) ex-perimented with morphological, distributional andshallow-syntactic information to discriminate be-tween proteins, genes and RNAs.In this paper we analyse the impact of differenttypes of features on the performance of an SVM-based classifier.
More precisely, we discuss themulti-class SVM performance with respect to thetype of features used, ranging from document iden-tifiers, through words, lemmas and stems, to auto-matically extracted terms.The paper is organised as follows.
After pre-senting the related work on feature selection inSection 2, the methods used for engineering fea-tures in our approach are explained in Section 3.Section 4 discusses the experiments and results.2 Related workAn SVM is a binary classification method thatcombines statistical learning and optimisation tech-niques with kernel mapping (Vapnik, 1995).
Themain idea of the method is to automatically learn aseparation hyperplane from a set of trainingexamples, which splits classified entities into twosubsets according to a certain classification prop-erty.
The optimisation part is used to maximise thedistance (called the margin) of each of the twosubsets from the hyperplane.The SVM approach has been used for differentclassification tasks quite successfully, in particularfor document classification, where the method out-performed many alternative approaches (Joachims,1998).
Similarly, SVMs have been used for termclassification.
For example, a bag-of-simple-wordsapproach with idf-like weights was used to learn amulti-class SVM classifier for protein cellular lo-cation classification (Stapley et al, 2002).
Proteinswere represented by feature vectors consisting ofsimple words co-occurring with them in a set ofrelevant Medline abstracts.
The precision of themethod was better than that of a classificationmethod based on experimental data, and similar toa rule-based classifier.Unlike many other classification methods thathave difficulties coping with huge dimensions, oneof the main advantages of the SVM approach isthat its performance does not depend on the dimen-sionality of the space where the hyperplane separa-tion takes place.
This fact has been exploited in theway that many authors have suggested that ?thereare few irrelevant features?
and that ?SVMs elimi-nate the need for feature selection?
(Joachims,1998).
It has been shown that even the removal ofstop-words is not necessary (Leopold and Kinder-mann, 2002).Few approaches have been undertaken only re-cently to tune the original SVM approach by se-lecting different features, or by using differentfeature weights and kernels, mostly for the docu-ment classification task.
For example, Leopold andKindermann (2002) have discussed the impact ofdifferent feature weights on the performance ofSVMs in the case of document classification inEnglish and German.
They have reported that anentropy-like weight was generally performing bet-ter than idf, in particular for larger documents.Also, they suggested that, if using single words asfeatures, the lemmatisation was not necessary, as ithad no significant impact on the performance.Lodhi et al (2002) have experimented with dif-ferent kernels for document classification.
Theyhave shown that a string kernel (which generatesall sub-sequences of a certain number of charac-ters) could be an effective alternative to linear ker-nel SVMs, in particular in the sense of efficiency.In the case of term classification, Kazama et al(2002) used a more exhaustive feature set contain-ing lexical information, POS tags, affixes and theircombinations in order to recognise and classifyterms into a set of general biological classes usedwithin the GENIA project (GENIA, 2003).
Theyinvestigated the influence of these features on theperformance.
For example, they claimed that suffixinformation was helpful, while POS and prefixfeatures did not have clear or stable influence.While each of these studies used some kind oforthographical and/or lexical indicators to generaterelevant features, we wanted to investigate the us-age of semantic indicators (such as domain-specific terms) as classification features, and tocompare their performance with the classic lexi-cally-based features.3 Feature selection and engineeringThe main aim while selecting classification fea-tures is to find (and use) textual attributes that canimprove the classification accuracy and acceleratethe learning phase.
In our experiments we exam-ined the impact of different types of features on theperformance of an SVM-based gene name classifi-cation task.
The main objective was to investigatewhether additional linguistic pre-processing ofdocuments could improve the SVM results, and, inparticular, whether semantic processing (such asterminological analysis) was beneficial for theclassification task.
In other words, we wanted tosee which textual units should be generated as in-put feature vectors, and what level of pre-processing was appropriate in order to producemore accurate predictions.We have experimented with two types of tex-tual features: in the first case, we have used a clas-sic bag-of-single-words approach, with differentlevels of lexical pre-processing (i.e.
single words,lemmas, and stems).
In the second case, featuresrelated to semantic pre-processing of documentshave been generated: a set of automatically ex-tracted multi-word terms (other than gene names tobe classified) has been used as a feature set.
Addi-tionally, we have experimented with featuresreflecting simple gene-gene co-occurrences withinthe same documents.3.1 Single words as featuresThe first set of experiments included a classic bag-of-single-words approach.
All abstracts (from alarger collection, see Section 4) that contained atleast one occurrence of a given gene or its aliaseshave been selected as documents relevant for thatgene.
These documents have been treated as a sin-gle virtual document pertinent to the given gene.All words co-occurring with a given gene in any ofthe abstracts were used as its features.A word has been defined as an alphanumericsequence between two standard separators, with allnumeric expressions that were not part of otherwords filtered out.
In addition, a standard list ofaround 300 stop-words has been used to excludesome frequent non-content words.An idf-like measure has been used for featureweights: the weight of a word w for gene g is givenby(1)                        |)|1()(1loggwRjjRNwfg++ ?
?where Rg  is a set of relevant documents for thegene g,  fj(w) is the frequency of w in document j,and Nw is the global frequency of w. Gene vectors,containing weights for all co-occurring words,have been used as input for the SVM.It is widely accepted that rare words do nothave any significant influence on accuracy (cf.
(Leopold and Kindermann, 2002)), neither dowords appearing only in few documents.
In ourexperiments (demonstrated in Section 4), we com-pared the performance between the ?all-words ap-proach?
and an approach featuring words appearingin at least two documents.
In the latter case, thedimension of the problem (expressed as the num-ber of features) was significantly reduced (withfactor 3), and consequently the training time wasshortened (see Section 4).Since many authors claimed that the biomedicalliterature contained considerably more linguisticvariations than text in general (cf.
Yakushiji et al,2001), we applied two standard transformations inorder to reduce the level of lexical variability.
Inthe first case, we used the EngCG POS tagger(Voutilainen and Heikkila, 1993) to generate lem-mas, so that lemmatised words were used as fea-tures, while, in the second case, we generatedstems by the Porter?s algorithm (Porter, 1980).Analogously to words, the same idf-based measurewas used for weights, and experiments were alsoperformed with all features and with the featuresappearing in no less than two documents.3.2 Terms as featuresMany literature-mining techniques rely heavily onthe identification of main concepts, linguisticallyrepresented by domain specific terms (Nenadic etal., 2002b).
Terms represent the most importantconcepts in a domain and have been used to char-acterise documents semantically (Maynard andAnaniadou, 2002).
Since terms are semantic indi-cators used in scientific discourse, we hypothesisedthat they might be useful classification features.The high neology rate for terms makes existingglossaries incomplete for active and time-limitedresearch, and thus automatic term extraction toolsare needed for efficient terminological processing.In order to automatically generate term as features,we have used an enhanced version of the C-valuemethod (Frantzi et al, 2000), which assigns term-hoods to automatically extracted multi-word termcandidates.
The method combines linguistic forma-tion patterns and statistical analysis.
The linguisticpart includes part-of-speech tagging, syntactic pat-tern matching and the use of a stop list to eliminatefrequent non-terms, while statistical termhoodsamalgamate four numerical characteristic of a can-didate term, namely: the frequency of occurrence,the frequency of occurrence as a nested element,the number of candidate terms containing it as anested element, and term?s length.Due to the extensive term variability in the do-main, the same concept may be designated bymore than one term.
Therefore, term variants con-flation rules have been added to the linguistic partof the C-value method, in order to enhance the re-sults of the statistical part.
When term variants areprocessed separately by the statistical module, theirtermhoods are distributed across different variantsproviding separate frequencies for individual vari-ants instead of a single frequency calculated for aterm candidate unifying all of its variants.
Hence,in order to make the most of the statistical part ofthe C-value method, all variants of the candidateterms are matched to their normalised forms byapplying rule-based transformations and treatedjointly as a term candidate  (Nenadic et al, 2002a).In addition, acronyms are acquired prior to the se-lection of the term candidates and also mapped totheir expanded forms, which are normalised in thesame manner as other term candidates.Once a corpus has been terminologically proc-essed, each target gene is assigned a set of termsappearing in the corresponding set of documentsrelevant to the given gene.
Thus, in this case, genevectors used in the SVM classifier contain co-occurring terms, rather than single words.
As termweights, we have used a formula analogous to (1).Also, similarly to single-word features, we haveexperimented with terms appearing in at least twodocuments.3.3 Combining word and term featuresThe C-value method extracts only multi-wordterms, which may be enriched during the normali-sation process with some single-word terms, sourc-ing from e.g.
acronyms or orthographic variations.In order to assess impact of both single and multi-word terms as features, we experimented withcombining single-word based features with multi-word terms by using a simple kernel modificationthat concatenates the corresponding feature vec-tors.
Thus, gene vectors used in this case containboth words and terms that genes co-occur with.3.4 Document identifiers as featuresTerm co-occurrences have been traditionally usedas an indication of their similarity (Ushioda, 1986),with documents considered as bags of words in themajority of approaches.
For example, Stapley et al(2000) used document co-occurrence statistics ofgene names in Medline abstracts to predict theirconnections.
The co-occurrence statistics were rep-resented by the reciprocal Dice coefficient.
Similarapproach has been undertaken by Jenssen et al(2001): they identified co-occurrences of genenames within abstracts, and assigned weights totheir ?relationship?
based on frequency of co-occurrence.In our experiments, abstract identifiers (Pub-Med identifiers, PMIDs) have been used as fea-tures for classification, where the dimensionality ofthe feature space was equal to the number ofdocuments in the document set.
As featureweights, binary values (i.e.
a gene is present/absentin a document) were used.We would like to point out that ?
contrary toother features ?
this approach is not a generallearning approach, as document identifiers are notclassification attributes that can be learnt and usedagainst other corpora.
Instead, this approach can beonly used to classify new terms that appear in aclosed corpus used for training.4 Experiments and discussionsAn experimental environment was set up by usingthe following resources:a) corpus: a set of documents has been ob-tained by collecting Medline abstracts (NLM,2003) related to the baker?s yeast (S. cerevisiae),resulting in 52,845 abstracts; this set, containingalmost 5 million word occurrences, was used asboth training and testing corpus.b) classification entities: a set of 5007 S. cere-visiae gene names has been retrieved from theSGD (Saccharomyces Genome Database) generegistry1, which also provided synonyms and ali-ases of genes; 2975 gene names appearing in thecorpus have been used for the classification task.c) classification scheme: each gene name hasbeen classified according to a classification schemebased on eleven categories (see Table 1) of the up-1 http://genome-www.stanford.edu/Saccharomyces/registry.htmlper part of the GO ontology (Ashburner et al,2000)2.d) training and testing sets: positive examplesfor each class were split evenly between the train-ing and testing sets, and, also, the number of nega-tive examples in the training set was set equal tothe number of positive examples within each class.The only exception was the metabolism class,which had far more positive than negatives exam-ples.
Therefore, in this case, we have evenly splitnegative examples between the training and testingsets.
Table 1 presents the distribution of positiveand negative examples for each class.d) SVM engine: for training the multi-classSVM, we used SVM Light package v3.50(Joachims, 1998) with a linear kernel function withthe regulation parameter calculated as avg(<x,x>)-1.examples Category(GO code) training testing 1 testing 2autophagy(GO:0006914) 12/12 11/2940 11/11cell organisation(GO:0016043) 379/379 378/1839 378/378cell cycle(GO:0007049) 226/226 225/2298 225/225intracellularprotein transport(GO:0006886)135/135 134/2571 134/134ion homeostasis(GO:0006873) 37/37 37/2864 37/37meiosis(GO:0007126) 45/45 44/2841 44/44metabolism(GO:0008152) 1118/370 1117/370 370/370signaltransduction(GO:0007165)68/68 68/2771 68/68sporulation (sc)(GO:0007151) 27/27 27/2894 27/27response tostress(GO:0006950)91/91 91/2702 91/91transport(GO:0006810) 284/284 284/2123 284/284Table 1.
Classification categories and the numberof examples in the training and the testing sets2 The January 2003 release of the GO ontology was used.
Asimilar classification scheme was used in (Raychaudhuri et al,2002).Features have been generated according to themethods explained in Section 3 (Table 2 shows thenumber of features generated).
As indicated earlier,the experiments have been performed by using ei-ther all features or by selecting only those that ap-peared in at least two documents.
As a rule, therewere no significant differences in the classificationperformance between the two.feature no.
of all featuresno.
of featuresappearing in >1 docswords 160k 60klemmas 150k 54kstems 140k 50kterms 127k 62kTable 2.
The number of features generatedTo evaluate the classification performance wehave firstly generated precision/recall plots foreach class.
In the majority of classes, terms havedemonstrated the best performance (cf.
Figures 1and 2).
However, the results have shown a widedisparity in performance across the classes, de-pending on the size of the training set.
The classeswith fairly large number of training entities (e.g.metabolism) have been predicted quite accurately(regardless of the features used), while, on theother hand, under-represented classes (e.g.
sporu-lation) performed quite modestly (cf.
Figure 1).Figure 1.
Precision/recall plots for some classesusing words and termsComparison between performances on differentclasses is difficult if the classes contain fairly dif-ferent ratios of positive/negative examples in thetesting sets, as it was the case in our experiments(see Table 1, column testing 1).
Therefore, we re-evaluated the results by selecting ?
for each class ?the same number of positive and negative exam-ples (see Table 1, column testing 2), so that wecould compare relative performance across classes.The results shown in Figure 2 actually indicatewhich classes are ?easier?
to learn (only the per-formance of single-words and terms are presented).To assess the global performance of classifica-tion methods, we employed micro-averaging of theprecision/recall data presented in Figure 2.
In mi-cro-averaging (Yang, 1997), the precision and re-call are averaged over the number of entities thatare classified (giving, thus, an equal weight to theperformance on each gene).
In other words, micro-average shows the performance of the classifica-tion system on a gene selected randomly from thetesting set.The comparison of micro-averaging results forwords, lemmas and stems has shown that there wasno significant difference among them.
This out-come matches the results previously reported forthe document classification task (Leopold andKindermann, 2002), which means that there is noneed to pre-process documents.Figure 3 shows the comparison of micro-averaging plots for terms and lemmas.
Terms per-form generally much better at lower recall points,while there is just marginal difference between thetwo at the higher recall points.
Very high precisionpoints at lower recall mean that terms may be use-ful classification features for precise predictionsfor genes classified with the highest confidence.Figure 2.
Precision/recall plots for the 11 classes using words and terms(horizontal lines indicate the performance of a random classifier)Figure 3.
Micro-averaging plot for 11 classes usinglemmas and termsThe results obtained by combining terms andwords have not shown any improvements over us-ing only terms as classification features.
We be-lieve that adding more features has introducedadditional noise that derogated the overall per-formance of terms.Finally, Figure 4 presents the comparison ofclassification results using terms and abstract iden-tifiers.
Although PMIDs outperformed terms, wereiterate that ?
while other features allow learningmore general properties that can be applied onother corpora ?
PMIDs can be only used to classifynew terms that appear in a closed training/testingcorpus.Figure 4.
Micro-averaging plot for 11 classes usingPMIDs and terms5 ConclusionDue to an enormous number of terms and thecomplex and inconsistent structure of the biomedi-cal terminology, manual update of knowledge re-positories are prone to be both inefficient andinconsistent (Nenadic et al, 2002b; Stapley et al,2002).
Therefore, automatic text-based classifica-tion of biological entities (such as gene and proteinnames) is essential for efficient knowledge man-agement and systematic approach that can copewith huge volume of the biomedical literature.
Fur-thermore, classified terms irrefutably have a posi-tive impact on improving the results of IE/IR,knowledge acquisition, document classificationand terminology management (Blaschke et al,2002).In this paper we have examined the proceduresfor engineering text-based features at various lev-els of linguistic pre-processing, and consideredtheir impacts on the performance of an SVM-basedgene name classifier.
The experiments have shownthat simple linguistic pre-processing (such as lem-matisation and stemming) does not have significantinfluence on the performance, i.e.
there is no needto pre-process documents.
Also, reducing the fea-ture space by selecting only features that appear inmore documents does not result in decrease of theperformance, but can significantly reduce the timeneeded for training.
PMID-based classification hasshown very good performance, but a PMID-basedclassifier can be applied only on the training set ofdocuments.The experiments have also shown that usingsemantic indicators (represented by dynamicallyextracted domain-specific terms) can improve theperformance compared to the standard bag-of-words approach, in particular at lower recallpoints, and for rare classes.
This means that termscan be used as reliable features for classifyinggenes with higher confidence, and for under-represented classes.
However, terminologicalanalysis requires considerable pre-processing time.Our further research will focus on generatingthe biological interpretation and justification of theclassification results by using terms (that havebeen used as key distinguishing features for classi-fication) as semantic indicators of the correspond-ing classes.ReferencesM.
Ashburner, et al.
2000.
Gene Ontology: Tool for theUnification of Biology.
Nature, 25:25-29.C.
Blaschke, L. Hirschman and A. Valencia.
2002.
In-formation Extraction in Molecular Biology.
Briefingsin Bioinformatics, 3(2):154-165.N.
Collier, C. Nobata and J. Tsujii.
2001.
AutomaticAcquisition and Classification of Terminology Usinga Tagged Corpus in the Molecular Biology Domain.Journal of Terminology, John Benjamins.F.
Eisenhaber and P. Bork.
1998.
Wanted: SubcellularLocalization of Proteins Based on Sequences.
TrendsCell Biology, 8(4):169-170.K.
Frantzi, S. Ananiadou and H. Mima.
2000.
AutomaticRecognition of Multi-Word Terms: the C-value/NC-value Method.
International Journal on Digital Li-braries 3(2):115-130.GENIA project.
2003.
GENIA resources.
Available at:http://www-tsujii.is.s.u-tokyo.ac.jp/~genia/V.
Hatzivassiloglou, P. Duboue and A. Rzhetsky.
2001.Disambiguating Proteins, Genes, and RNA in Text: AMachine Learning Approach.
Bioinformatics, 1(1):1-10.T.
Jenssen, A. Laegreid, J. Komorowski and E. Hovig.2001.
A literature Network of Human Genes forHigh-throughput Analysis of Gene Expressions.
Na-ture Genetics, 28: 21-28.T.
Joachims.
1998.
Text Categorization with SupportVector Machines: Learning Many Relevant Features.Proceedings of 10th European Conference on Ma-chine Learning, Springer-Verlag, Heidelberg, 137-142.J.
Kazama, T. Makino, Y. Ohta and J. Tsujii.
2002.
Tun-ing Support Vector Machines for Biomedical NamedEntity Recognition.
Proceedings of the WorkshopNLP in Biomedicine, ACL 2002.E.
Leopold and J. Kindermann.
2002.
Text Categoriza-tion with Support Vector Machines.
How to Repre-sent Texts in Input Space?
Machine Learning,46:423-444.H.
Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianiniand C. Watkins.
2002.
Text Classification usingString Kernels.
Journal of Machine Learning Re-search, 2:419-444.D.
Maynard and S. Ananiadou.
2000.
Identifying Termsby their Family and Friends.
Proceedings ofCOLING 2000, Saarbrucken, Germany, 530-536.K.
Nishikawa and T. Ooi.
1982.
Correlation of theAmino Acid Composition of a Protein to its Struc-tural and Biological Characters.
Journal of Bio-chemistry (Tokyo), 91(5):1281-1824.G.
Nenadic, I. Spasic and S. Ananiadou.
2002a.
Auto-matic Acronym Acquisition and Term VariationManagement within Domain-Specific Texts.
Proceed-ings of LREC-3, Las Palmas, Spain, 2155-2162.G.
Nenadic, H. Mima, I. Spasic, S. Ananiadou and J.Tsujii.
2002b.
Terminology-based Literature Miningand Knowledge Acquisition in Biomedicine.
Interna-tional Journal of Medical Informatics, 67(1-3):33-48.NLM, National Library of Medicine.
2003.
Medline.Available at http://www.ncbi.nlm.nih.gov/PubMed/M.
Porter.
1980: An Algorithm for Suffix Stripping.
Pro-gram, 14(1):130-137.S.
Raychaudhuri, J. Chang, P. Sutphin and R. Altman.2002.
Associating Genes with Gene Ontology CodesUsing a Maximum Entropy Analysis of BiomedicalLiterature.
Genome Research, 12:203-214.B.
Stapley and G. Benoit.
2000.
Bibliometrics: Informa-tion Retrieval and Visualization from Co-occurrenceof Gene Names in Medline Abstracts.
Proceedings ofthe Pacific Symposium on Bio-computing, PSB 2000B.
Stapley, L. Kelley and M. Sternberg.
2002.
Predict-ing the Sub-Cellular Location of Proteins from TextUsing Support Vector Machines.
Proceedings of thePacific Symposium on Bio-computing, PSB 2002.A.
Ushioda.
1996.
Hierarchical Clustering of Words.Proceedings of COLING 96.V.
Vapnik.
1995.
The Nature of Statistical LearningTheory.
Springer Verlag, Heidelberg.A.
Voutilainen and J. Heikkila.
1993.
An English Con-straint Grammar (ENGCG) a Surface-SyntacticParser of English.
In Fries, U et al (Eds.
): Creatingand Using English Language Corpora, Rodopi, Am-sterdam/Atlanta, 189-199.A.
Yakushiji, Y. Tateisi, Y. Miyao and J. Tsujii.
2001.Event Extraction From Biomedical Papers Using aFull Parser.
Proceedings PSB 2001, Hawaii, USA,408-419.Y.
Yang.
1997.
An Evaluation of Statistical Approachesto Text Categorization.
Information Retrieval,1(1/2):69-90.
