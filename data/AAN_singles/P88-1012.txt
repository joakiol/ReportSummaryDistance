I n terpretat ion  as Abduct ionJerry R. Hobbs, Mark Stickel,Paul Martin, and Douglas EdwardsArtificial Intelligence CenterSRI InternationalAbstractAn approach to abductive inference developed in the TAC-ITUS project has resulted in a dramatic simplification ofhow the problem of interpreting texts is conceptualized.
Itsuse in solving the local pragmatics problems of reference,compound nominals, syntactic ambiguity, and metonymyis described and illustrated.
It also suggests an elegant andthorough integration ofsyntax, semantics, and pragmatics.1 IntroductionAbductive inference is inference to the best explanation.The process of interpreting sentences in discourse can beviewed as the process of providing the best explanation ofwhy the sentences would be true.
In the TACITUS Projectat SRI, we have developed a scheme for abductive inferencethat yields a signi~caut simplification i the description ofsuch interpretation processes and a significant extensionof the range of phenomena that can be captured.
It hasbeen implemented in the TACITUS System (Stickel, 1982;Hobbs, 1986; Hobbs and Martin, 1987) and has been andis being used to solve a variety of interpretation problemsin casualty reports, which are messages about breakdownsin machinery, as well as in other texts3It~ is well-known that people understand discourse so well ~because they know so much.
Accordingly, the aim of theTACITUS Project has been to investigate how knowledgeis used in the interpretation f discourse.
This has involvedbuilding a large knowledge base of commonsense and do-main knowledge (see Hobbs et al, 1986), and developingprocedures for using this knowledge for the interpretationof discourse.
In the latter effort, we have concentrated onproblems in local pragmatics, pecifically, the problems ofreference resolution, the interpretation f compound nom-inals, the resolution of some kinds of syntactic ambiguity,and metonymy resolution.
Our approach to these problemsis the focus of this paper.In the framework we have developed, what the interpre-tation of a sentence is can be described very concisely:ZCharniak (1986) and Norvig (1987) have also applied abductiveinference t chniques todiscoume interpretation.
(1)To interpret a sentence:Derive the logical form of the sentence,together with the constraints that predicatesimpose on their arguments,allowing for coercions,Merging redundancies where possible,Making assumptions where necessary.By the first line we mean "derive in the logical sense, orprove from the predicate calculus axioms in the "knowledgebase, the logical form that has been produced by syntacticanalysis and semantic translation of the sentence.
"In a discourse situation, the speaker and hearer bothhave their sets of private beliefs, and there is a large over-lapping set of mutual beliefs.
An utterance stands with onefoot in mutual belief and one foot in the speaker's privatebeliefs.
It is a bid to extend the area of mutual belief toinclude some private beliefs of the speaker's.
It is anchoredreferentially in mutual belief, and when we derive the logi-cal form and the constraints, we are recognizing this refer-ential anchor.
This is the given information, the definite,the presupposed.
Where it is necessary to make assump-tions, the information comes from the speaker's privatebeliefs, and hence is the new information, the indefinite,the asserted.
Merging redundancies is a way of getting aminimal, and hence a best, interpretation.
2In Section 2 of this paper, we justify the first clause ofthe above characterization by showing that solving localpragmatics problems is equivalent to proving the logicalform plus the constraints.
In Section 3, we justify the lasttwo clauses by describing our scheme of abductive infer-ence.
In Section 4 we provide several examples.
In Section5 we describe briefly the type hierarchy that is essentialfor making abduction work.
In Section 6 we discuss futuredirections.2Interpreting i direct speech acts, such u "It's cold in here," mean-ing "C1?w?
the window," is not a counterexample to the principle thatthe minimal interpretation is the best interpretation, but rather canbe seen as a matter of achieving the minimal interpretation coherentwith the interests of the speaker.952 Local PragmaticsThe fbur local pragmatics problems we have addressed canbe illustrated by the following "sentence" from the casualtyreports:(2) Disengaged compressor after lube-oil alarm.Identifying the compressor and the alarm are referenceresolut ion problems.
Determinlug the implicit relationbetween "lube-oil" and "alarm" is the problem of com-pound nominal  in terpretat ion.
Deciding whether "af-ter lube-oil alarm" modifies the compressor or the disen-gaging is a problem in syntact ic  ambigu i ty  resolut ion.The preposition "after" requires an event or condition asits object and this forces us to coerce "lube-oil alarm" into"the sounding of the lube-oil alarm"; this is an exampleof metonymy resolut ion.
We wish to show that solvingthe farst three of these problems amounts to deriving thelogical form of the sentence.
Solving the fourth amounts toderiving the constraints predicates impose on their argu-ments, allowing for coercions.
For each of these problems,our approach is to frame a logical expression whose deriva-tion, or proof, constitutes an interpretation.Reference: To resolve the reference of "compressor" insentence (1), we need to prove (constructively) the follow-ing logical expression:(3) (B c)comFeessor(c)If, for example, we prove this expression by using axiomsthat say (71 is a starting air compressor, and that a startingair compressor is a compressor, then we have resolved thereference of "compressor" to 6'i.In general, we would expect definite noun phrases torefer to entities the hearer already knows about and canidentify, and indefinite noun phrases to refer to new enti-ties the speaker is introducing.
However, in the casuallyreports most noun phrases have no determiner.
There aresentences, uch asRetained oil sample and filter for future analysis.where "sample" is indefinite, or new information, and "fil-ter" is definite, or already known to the hearer.
In thiscase, we try to prove the existence of both the sample andthe filter.
When we fail to prove the existence of the sam-ple, we know that it is new, and we simply assume itsexistence.Elements in a sentence other than nominals can alsofunction referentially.
InAlarm sounded.Alarm activated during routine start ofcompressor.one can argue that the activation is the same as, or at leastimplicit in, the sounding.
Hence, in addition to tryingto derive expressions such as (3) for nominal reference,for possible non-nomlnal reference we try to prove similarexpressions.
(3 ...  e, a , .
.
. )
.
.
.
^  activate'(e, a) ^ ...sThat is, we wish to derive the existence, from backgroundknowledge or the previous text, of some known or impliedactivation.
Most, but certainly not all, information con-veyed non-nominally is new, and hence will be assumed.Compound Nominals :  To resolve the reference of thenoun phrase "lube-oi\] alarm", we need to Find two entitieso and a with the appropriate properties.
The entity o mustbe lube oil, a must be an alarm, and there must be someimplicit relation betwee~ them.
Let us call that implicitrelation nn.
Then the expression that must be proved is(3 o, a, nn)tu~-oit(o) ^ atarm(a) ^  nn(o, a)In the proof, instantiating nn amounts to interpreting theimplicit relation between the two nouns in the compoundnominal.
Compound nominal interpretation is thus just aspecial case of reference resolution.Treating nn as a predicate variable in this way seems toindicate that the relation between the two nouns can beanything, and there are good reasons for believing this tobe the case (e.g., Downing, 1977).
In "lube-oil alarm", forexample, the relation is~x, y \[y sounds if pressure of z drops too low\]However, in our implementation we use a first-order sim-ulation of this approach.
The symbol nn is treated as apredicate constant, and the most common possible rela-tions (see Levi, 1978) are encoded in axioms.
The axiom(v=, v)r~,~(y, =) ~ --(=,y)allows interpretation of compound nominals of the form"<whole> <part>",  such as "filter element".
Axioms ofthe form(Vz, y)sample(y, z) D nn(z, y)handle the very common ease in which the head noun isa relational noun and the prenominal noun fills one of itsroles, as in "oil sample".
Complex relations uch as theone in "luhe-oil alarm" can sometimes be glossed as "for".
(v=, v)fo~Cy, =) ~ --(=, y)Syntact ic  Ambigu i ty :  Some of the most com-mon types of syntactic ambiguity, including prepositionalphrase and other attachment ambiguities and very com-pound nominal ambiguities, can be converted into con-strained coreference problems (see Bear and Hobbs, 1988).SSee Hobbs (1985a) for explanation fthis notation for events.96For example, in (2) the first argument of after is taken tobe an existentially quantified variable which is equal to ei-ther the compressor the alarm.
The logical form wouldthus include(3. .
.e,c,y,a .
.
.
.  )
.
.
.
A aftcr(y,a) A ye  {c,~}A .
.
.That is, however after(y, a) is proved or assumed, y mustbe equal to either the compressor c or the disengaging c.This kind of ambiguity isoften solved as a byproduct of theresolution of metonymy orof the merging of redundancies.Metonymy: Predicates impose constraints on theirarguments that are often violated.
When they are vio-lated, the arguments must be coerced into something re-lated which satisfies the constraints.
This is the process ofmetonymy resolution.
Let us suppose, for example, thatin sentence (2), the predicate after requires its argumentsto be events:after(ca,e2) : event(ca) A event(e2)To allow for coercions, the logical form of the sentence isaltered by replacing the explicit arguments by "coercionvariables" which satisfy the constraints and which are re-lated somehow to the explicit arguments.
Thus the alteredlogical form for (2) would include(3 ... kt, k2, y, a, rela, eel2,...).., h after(k1, k2)A event(ka) A rcll(kl, y)A event(k~) A ret2(k2,a) A ...As in the most general approach to compound nominalinterpretation, this treatment is second-order, and suggeststhat any relation at all can hold between the implicit andexplicit arg~unents.
Nunberg (1978), among others, has infact argued just this point.
However, in our implementa-tion, we are using a first-order simulation.
The symbol eelis treated as a predicate constant, and there are a num-ber of axioms that specify what the possible coercions are.Identity is one possible relation, since the explicit argu-ments could in fact satisfy the constraints.
(Vx)rel(=, x)In general, where this works, it will lead to the best inter-pretation.
We can also coerce from a whole to a part andfrom an object to its function.
Hence,(vx, y)part(z, y) ~ eel(x, y)(Vx, e)function(c, x) D rel(e,z)Putting it all together, we find that to solve all the localpragnaatics problems posed by sentence (2), we must derivethe following expression:(3 e, x, c, ka, k2, y, a, o)Past(e)h disengage'(e, z, c)A compressor(c) A after(k1, k~)Aevent(kl) A rel(ka,y) A y E {c,e}A event(k2) A ret(k2,a) A alarm(a)A nn(o, a) A tube-oil(o)But this is just the logical form of the sentence 4 togetherwith the constraints that predicates impose on their ar-guments, allowing for coercions.
That is, it is the firsthalf of our characterization (1)of what it is to interpret asentence.When parts of this expression cannot be derived, as-sumptions must be made, and these assumptions are takento be the new information.
The likelihood of differentatoms in this expression being new information varies ac-cording to how the information is presented, linguistically.The main verb is more likely to convey new informationthan a definite noun phrase.
Thus, we assign a cost toeach of the atoms--the cost of assuming that atom.
Tluscost is expressed in the same currency in which other fac-tors involved in the "goodness" of an interpretation areexpressed; among these factors are likely to be the lengthof the proofs used and the salience of the axioms they relyon.
Since a definite noun phrase is generally used referen-tially, an interpretation that simply assumes the existenceof the referent and thus falls to identify it should be an ex-pensive one.
It is therefore given a high assumability cost.For purposes of concreteness, let's call this $10.
Indefinitenoun phrases arc not usually used referentially, sothey aregiven a low cost, say, $1.
Bare noun phrases are givenan inte~ediate cost, say, $5.
Propositions presented non-nominally are usually new information, so they are givena low cost, say, $3.
One does not usually use selectionalconstraints o convey new information, so they are giventhe same cost as definite noun phrases.
Coercion relationsand the compound nominal relations are given a very highcost, say, $20, since to assume them is to fail to solve theinterpretation problem.
If we superscript the atoms in theabove logical form by their assumability costs, we get thefollowing expression:(3 e, z, c, kl, k2, y, a, o)Past( z)"^ disengagc'(e, z, c)"^ cornpreJsor(c) ss ^ aftcr(kt, k2)"^event(k~) .2?
^  rel(kt,y) *~ ^  y ~ {c,e}A event(k2) sa?
A rel(k2,a) s2?
A alarm(a) gs^ nn(o, a) s~?
^  tube-oil(o)"While this example gives a rough idea of the relative as-sumability costs, the real costs must mesh well with the in-ference processes and thus must be determined experimen-tally.
The use of numbers here and throughout the nextsection constitutes one possible regime with the neededproperties.
Vv'e are at present working, and with someoptimism, on a semantics for the numbers and the proce-dures that operate on them.
In the course of this work, wemay modify the procedures to an extent, but we expect oretain their essential properties.4For justification for this kind of logical form for sentences withquantifiers and inteusional operators, ee Hobbs(1983) and Hobbs(1985a).973 AbductionWe now argue for the last half of the characterization (I)of interpretation.Abduction is the process by which, from (Vz)p(z I Dq(r) and q(A), one concludes p(A I.
One can think of q(A)as the observable evidence, of (Vz)p(z) D q(z) as a gen-eral principle that could explain q(A)'s occurrence, and ofp(A) as the inferred, underlying cause of q(A).
Of course,this mode of inference is not valid; there may be manypossible such p(A)'s.
Therefore, other criteria are neededto choose among the possibilities.
One obvious criterionis consistency of p(A I with the rest of what one knows.Two other criteria are what Thasard (1978) has calledconsilience and simplicity.
Roughly, simplicity is that p(A)should be as small as possible, and consilience is that q(A)should be as big as possible.
We want to get more bangfor the buck, where q(A) is bang, and p(A) is buck.There is a property of natural anguage discourse, no-ticed by a number of linguists (e.g., Joos (19721, Wilks(1972)), that su~ests a role for simplicity and consiliencein its interpretation--its high degree of redundancy.
Con-siderInspection of oll filter revealed metal particle~.An inspection is a looking at that causes one ~o learn aproperty relevant to the j~nc~io~ of the inspected object.The ~nc~io?
of a falter is to capture p,~eticle~ from a fluid.To reveal is to os~e one ~o/earn.
If we assume the twocausings to learn are identical, the two sets of particlesare identical, and the two functions are identical, then wehave explained the sentence in a minimal fashion.
A smallnumber of inferences and assumptions have explained alarge number of syntactically independent propositions inthe sentence.
As a byproduct, we have moreover shownthat the inspector is the one to whom the particles arerevealed and that the particles are in the filter.Another issue that arises in abduction is what mightbe called the "informativeness-correctness radeotP'.
Mostprevious uses of abduction in AI from a theorem-provingperspective have been in diagnostic reasoning (e.g., Pople,1973; Cox and Pietrzykowski, 1986), and they have as-maned "most specific abduction".
If we wish to explainchest palna~ it is not su~cient to assume the cause is sim-ply chest pains.
We want something more specific, such as"pneumonia".
We want the most specific possible xpla-nation.
In natural language processing, however, we oftenwant the least specific assumption.
If there is a mention ofa fluid, we do not necessarily want to assume it is lube oil.Assuming simply the existence of a fluid may be the bestwe can do.
s However, if there is corroborating evidence,we may want to make a more specific assumption.
InAlarm sounded.
Flow obstructed.SSometimes a cigar is just a cigar.we know the alarm is for the lube oil pressure, and thisprovides evidence that the flow is not merely of a fluid butof lube oil.
The more specific our assumptions are, themore informative our interpretation is.
The less specificthey are, the more likely they are to be correct.We therefore need a scheme of abductive inference withthree features.
First, it should be possible for goal ex-pressions to be assumable~ at varying costs.
Second, thereshould be the possibility of making assumptions at vari-ous levels of specificity.
Third, there should be a way ofexploiting the natural redundancy of texts.We have devised just such an abduction scheme, s First:every conjunct in the logical form of the sentence is givenan assumability cost, as described at the end of Section 2.Second, this cost is passed back to the antecedents in Hornclauses by assigming weights to them.
Axion~s are statedin the form(4) Pp ^Pp ~ QThis says that Pl and P2 imply Q, but also that if thecost of assuming Q is c, then the cost of assuming PI iswlc, and the cost of assuming P2 is w2c.
Third, factoringor synthesis i  allowed.
That is, goal wi~s may be unified,in which case the resulting wi~ is given the smaller of thecosts of the input wi~s.
This feature leads to minimalitythrough the exploitation of redundancy.Note that in (41, if wl + w2 <= 1, most specific abductionis favored--why assume Q when it is cheaper to assume PIand P~.
Hwlq-w2  I, least specific abduction isfavored--why assume PI and P2 when it is cheaper to assume Q. Butinpis ^  P~s ~ Qif PI has already been derived, it is cheaper to assume P2than ~.
P1 has provided evidence for Q, and assumlug the"remainder" P2 of the necessary evidence for Q should becheaper.Factoring can also override least specific abduction.Suppose we have the axiomsPiS A P~ s D QIp~s ^  p~s ~ Q~and we wish to derive ~i  ^  ~2, where each conjunct has anassumability cost of $10.
Then assuming QI ^ ~2 will cost$20, whereas assuming Pl ^ P2 ^  Ps will cost only $18, sincethe two instances of P2 can be unified.
Thus, the abductionscheme allows us to adopt the careful policy of favoringleast specific abduction while also allowing us to exploitthe redundancy of texts for more specific interpretations.In the above examples we have used equal weights onthe conjuncts in the antecedents.
I~ is more reasonable,SThe ~bduction scheme isdue to Mark Stickel, and it, or a variantof it, is described at~-eater length in Stickel (1988).98however, to assign the weights according to the "seman-tic contribution" each conjunct makes to the consequent.Consider, for example, the axiom(Vz)ear(z) "s A no-top(z) "4 D convertible(x)We have an intuitive sense that ear contributes more toconvertible than no-top does.
r In principle, the weights in(4) should be a function of the probabilities that instancesof the concept Pi are instances ofthe concept Q in the cor-pus of interest.
In practice, all we can do is assign weightsby a rough, intuitive sense of semantic ontribution, andrefine them by successive approximation  a representa-tive sample of the corpus.One would think that since we are deriving the logicalform of the sentence, rather than determining what can beinferred from the logical form of the sentence, we could notuse super~et information i  processing the sentence.
Thatis, since we are back-chaining from the propositions in thelogical form, the fact that, say, lube oil is a fluid, whichwould be expressed as(5) (Vz)lube-oil(z) D f luid(z)could not play a role in the analysis.
Thus, in the textFlow obstructed.
Metal particles in lube oil filter.we know from the first sentence that there is a fluid.
Wewould like to identify it with the lube oil mentioned inthesecond sentence.
In interpreting the second sentence, wemust prove the expression( 5 z )lube-oil( z)If we had as an axiom(Vz)/tuid(z) ~ tub,-al(:)then we could establish the identity.
But of course wedon't have such an axiom, for it isn't true.
There are lotsof other kinds of fluids.
There would seem to be no wayto use superset information i  our scheme.Fortunately, however, there is a way.
We can make useof this information by converting the axiom into a bicon-ditional.
In general, axioms of the formspecies D genuscan be converted into a bieonditional xiom of the formgenus A differentiae _= speciesrTo prime this intuition, imagine two doom.
Behind one is n ear.Behind the other is something with no top.
You pick a door.
If there'sa convertible b hind it, you get to keep it.
Which door would youpick?Often, of course, as in the above example, we will notbe able to prove the differentiae, and in many cases thedifferentiae can not even be spelled out.
But in our ab-ductive scheme, this does not matter.
They can simply beassumed.
In fact, we need not state them explicitly.
Wecan simply introduce a predicate which stands for all theremaining properties.
It will never be provable, but it willbe assumable.
Thus, we can rewrite (5) as(Vz)f lu id(z)  h etcl(z) _ lube-oil(z)Then the fact that something is fluid can be used as evi-dence for its being lube oil.
With the weights distributedaccording to semantic contribution, we can go to extremesand use an axiom like(Vz)rnammal(z) "2 A atc2(z) "s D elephant(z)to allow us to use the fact that something is a mammal as(weak) evidence that it is an elephant.In principle, one should try to prove the entire logicalform of the sentence and the constraints at once.
In thisglobal strategy, any heuristic ordering of the individualproblems is done by the theorem prover.
From a practi-cal point of view, however, the global strategy generallytakes longer, sometimes significantly so, since it presentsthe theorem-prover with a longer expression to be proved.We have experimented both with this strategy and witha bottom-up strategy in which, for example, we try toidentify the lube oil before trying to identify the lube oilalarm.
The latter is quicker since it presents the theorem-prover with problems in a piecemeal fashion, but the for-mer frequently results in better interpretations since it isbetter able to exploit redundancies; The analysis of thesentence in Section 4.2 below, for example, requires eitherthe global strategy or very careful axiomatization.
Thebottom-up strategy, with only a view of a small local re-gion of the sentence, cannot recognize and capitalize onredundancies among distant elements in the sentence.
Ide-ally, we would like to have detailed control over the proofprocess to allow a number of different factors to interact indeterr-ln~ng the allocation of deductive resources.
Amongsuch factors would be word order, lexlcal form, syntacticstructure, topic-comment structure, and, in speech, pitchaccent .s4 Examples4.1 D is t ingu ish ing  the  G iven  and  NewWe will examine two difllcult definite reference problems inwhich the given and the new information are intertwinedand must be separated.
In the first, new and old informa-tion about the same entity are encoded in a single nounphrase.SPereira nd Pollnck's CANDIDE system (1988) is specifically de-signed to aid investigation of the question ofthe most effective orderof interpretation.99There was adequate lube oil.We know about the lube oil already, and there is a corre-sponding axiom in the knowledge base.lube-oil( O)Its adequacy is new information, however.
It is what thesentence is telling us.The logical form of the sentence is, roughly,(3 o)lube-oil( o) A adequate(o)This is the expression that must be derived.
The proof ofthe existence of the lube oil is immediate.
It is thus oldinformation.
The adequacy can't be proved, and is henceassumed as new information.The second example is from Clark (1975), and illustrateswhat happens when the given and new information arecombined into a single lexical item.John walked into the room.The chandelier shone brightly.What chandelier is being referred to?Let us suppose we have in our knowledge base the factthat rooms have lights.
(6) (Vr)roorn(r) D (31)light(1) A in(l,r)Suppose we also have the fact that lights with numerousfixtures are chandeliers.
(7) (Vl)light(l) A has-fiztures(l) D chandelier(l)The first sentence has given us the existence of a room mroom(R).
To solve the definite reference problem in thesecond sentence, we must prove the existence of a chande-lier.
Back-chaining on axiom (7), we see we need to provethe existence of a light with fixtures.
Back-chaining fromlight(1) in axiom (6), we see we need to prove the exis-tence of a room.
We have this in room(R).
To completethe derivation, we assume the light I has fixtures.
Thelight is thus given by the room mentioned in the previoussentence, while the fact that it has fl.xtures is new infor-mation.4.2 Exploiting RedundancyWe next show the use of the abduction scheme in solvinginternal coreference problems.
Two problems raised by thesentenceThe plain was reduced by erosion to its presen tlevel.are determining what was eroding and determining what"it" refers to.
Suppose our knowledge base consists of thefollowing axioms:(Vp, l, s)decrease(p, l, s) A vertical(s)A etc3(p, I, s) = (3 el)reduce'(el, p l)or el is a reduction of p to l if and only if p decreases to lon some vertical scale s (plus some other conditions).
(Vp)landform(p) A flat(p) ^  etc4(p) - plain(p)or p is a plain if and only if p is a fiat landform (plus someother conditions).
(V e, lt, l, s)at'(e, It, l) ^ on(l, s) ^ vertical(s)A/tat(y) A etcs(e, it, l ,s)  -- levee(e,l,y)or e is the condition of l's being the level of y if and onlyif e is the condition of y's being at I on some vertical scales and It is fiat (plus some other conditions).
(Vz, I, s )decrease( z, I, s) A landform(z)A altitude(a) A etce(y, l s) -- (3 e)erode'(e, z)or ?
is an eroding of z if and only if z is a landform thatdecreases to some point I on the altitude scale s (plus someother conditions)?
(Vs)vertical(s) A etcr(p) - altitude(s)or s is the altitude scale if and only if s is vertical (plussome other conditions).Now the analysis.
The logical form of the sentence isroughly(3 ca, p, l, z, e2, It)reduce'(el, p l) A plain(p)A erode'(el, z) A present(e2) A level'(e2, l, y)Our characterization f interpretation says that we mustderive this expression from the axioms or from assump-tions.
Back-chainlng on reducer(el, p, l) yieldsdecrease(p, l, sl) A vertical(s1 ) A etcs(p, l, sl )Back-cb~r~ing on erode'(e:, z) yieldsdecrease(z, 12,s2) A landform(z) ^  altitude(s2)A etc4( z,12, s2 )and back-chaining on altitude(s2) in turn yieldsvertical(s2) A etcr( s2 )We unify the goals decrease(p, I, st) and decrease(z, 12, s2),and thereby identify the object of the erosion with theplain.
The goals vertical(sl ) and vertical(s2) also unify,telling us the reduction was on the altitude scale.
Back-chaining on plain(p) yieldslandform(p) A flat(p) A ete,(p)and landform(z) unifies with landform(p), reinforcing ouridentification of the object of the erosion with the plain.Back-chainlng on level'(e2, I, y ) yields100at'(e2,y,l) A on(l, ss) A vertical(ss) A flat(y)^ etcs(p)and vertical(s3) and vertical(s2) unify, as do flat(y) andflat(p), thereby identifying "it", or y, as the plain p. Wehave not written out the axioms for this, but note also that"present" implies the existence of a change of level, or achange in the location of "it" on a vertical scale, and adecrease of a plain is a change of the plain's location on avertical scale.
Unifying these would provide reinforcementfor our identification of "it" with the plain.
Now assum-ing the most specific atoms we have derived including allthe "et cetera" conditions, we arrive at an interpretationthat is minimal and that solves the internal coreferenceproblems as a byproduct.4.3 A Thorough In tegrat ion  o f  Syntax ,Semantics, and PragmaticsBy combining the idea of interpretation asabduction withthe older idea of parsing as deduction (Kowalski, 1980, pp.52-53; Pereira and Warren, 1983), it becomes possible tointegrate syntax, semantics, and pragmatics in a very thor-ough and elegant way.
9 Below is a simple grammar writtenin Prolog style, but incorporating calls to local pragmatics.The syntax portion is represented in standard Prolog man-ner, with nonterminals treated as predicates and having astwo of its arguments the beginning and end points of thephrase spanned by the nonterminal.
The one modificationwe would have to make to the abduction scheme is to allowconjuncts in the antecedents to take costs directly as wellas weights.
Constraints on the application of phrase struc-ture rules have been omitted, but could be incorporated inthe usual way.
(Vi, j ,  k, x,p, args, req, e, c, rel)np(i, j, x)A vp(j, k,p, args, req) A 'pt(e, c) $3 A rel(c, z) $2?A subst(req, cons(c, args)) $1?
D s(i, k, e)(V i, j, k, e, p, ar gs, req, et, c, ~el)s( i, j, e)A pp(j, k,p, args, req) A p'(el, c) s3 A tel(c, e) 12?A subst(req, cons(c, args)) *x?
D s(i, k, e&el)(V i , j ,k ,w,z ,c ,  rel)v(i, j,w) A np(j ,k,z)A rel(c, z) *2?3 vp(i, k, ~z\[w(z, c)\], <c>, Req(w))(V i, j, k, z)det(i, j,"the") A cn(j, k, z, p)Ap(z) 'm D n1~i,k,z)(Vi, j ,k,z)det(i , j ,"a") A cn(j ,k,z,p) A p(z) nD rip(i, k, z)(V i , j ,k ,w,z ,y ,p ,  nn)n(i , j ,w) A cn(j ,k,z,p)^w(y)" ^  .n(y,=) '=?
~ ~(i,k,z,p)(V i, j, k, z, ~ , ~ ,  args, req, c, rel)cn( i, j, z, Pl )A pp(j, k,p2, args, req)9This idea is due to Stuart Shieber.A subst(req, cons(c, argo)) st?
^  rel(c, z) s2?~(i,k,=,;~z\[p~(:) ^ ~(~)\])(Vi , j ,w)n( i , j ,w) D (3z)cn( i , j ,z ,w)(Vi, j ,  k, w, z, c, rel)prep(i, j, w) ^ np(j, k, x)A rel(c, z) In?3 ptXi, k, ,~z\[w(c, z)\], <c>, Req(w))For example, the first axiom says that there is a sentencefrom point i to point k asserting eventuality e if thereis a noun phrase from i to j referring to z and a verbphrase from j to k denoting predicate p with argumentsarg8 and having an associated requirement req, and thereis (or, for $3, can be assumed to be) an eventuality e ofp's being true of ?, where c is related to or coercible fromx (with an assumability cost of $20), and the requirementreq associated with p can be proved or, for $10, assumed tohold of the arguments of p. The symbol c&el denotes theconjunction of eventualities e and el (See Hobbs (1985b),p.
35.)
The third argument of predicates corresponding toterminal nodes such as n and det is the word itself, whichthen becomes the name of the predicate.
The functionReq returns the requirements a sociated with a predicate,and subst takes care of substituting the right argumentsinto the requirements.
<c> is the list consisting of thesingle element c, and cons is the LISP function cons.
Therelations re/and nn are treated here as predicate variables,but they could be treated as predicate constants, in whichcase we would not have quantified over them.In this approach, s(0, n, e) can be read as saying there isan interpretable sentence from point 0 to point n (assertinge).
Syntax is captured in predicates like np, vp, and s.Compositional semantics is encoded in, for example, theway the predicat e p' is applied to its arguments in the firstaxiom, and in the lambda expression i the third argumentof vp in the third axiom.
Local pragmatics i captured byvirtue of the fact that in order to prove s(O, n, e), one mustderive the logical form of the sentence together with theconstraints predicates impose on their arguments, allowingfor metonymy.Implementations of different orders of interpretation,or different sorts of interaction among syntax, composi-tional semantics, and local pragmatics, can then be seenas different orders of search for a proof of s(O, n, e).
Ina syntax-first order of interpretation, one would try firstto prove all the "syntactic" atoms, such as np(i, j ,x),before any of the "local pragmatic" atoms, such asp'(e, c).
Verb-driven interpretation would first try to provevp(j, k, p, args, req) by proving v(i, j ,  w) and then using theinformation in the requirements associated with the verbto drive the search for the arguments of the verb, by de-riving subst(req, cons(c, args)) before trying to prove thevarious np atoms.
But more fluid orders of interpreta-tion are obviously possible.
This formulation allows oneto prove those things first which are easiest o prove.
It isalso easy to see how processing could occur in parallel.101It is moreover possible to deal with ill-formed or unclea~input in this framework, by having axioms such as thisrevision of our first axiom above.
(V i, j, k, z, p, args, req, e, c, tel)rip(i, j, z) '4^ vp(j, k,p, args, req) "s ^  p'(e, c) IsA re/(c, :)12o A subst(req, cons(c, args)) st?D s(i, k, e)This says that a verb phrase provides more evidence fora sentence than a noun phrase does, but either one canconstitute a sentence if the string of words is otherwiseinterpretable.It is likely that this approach could be extended tospeech recognition by using Prolog-style rules to decom-pose morphemes into their phonemes and weighting themaccording to their acoustic prominence.5 Controlling Abduction: TypeHierarchyThe first example on which we tested the new abductivescheme was the sentenceThere was adequate lube oil.The system got the correct interpretation, that the lube oilwas the lube oil in the lube oil system of the air compressor,and it assumed that that lube oil was adequate.
But italso got another interpretation.
There is a mention in theknowledge base of the adequacy of the lube oil pressure, soit identified that adequacy with the adequacy mentionedin the sentence.
It then assumed that the pressure waslube oil.It is clear what went wrong here.
Pressure is a ma~i -rude whereas lube oil is a material, and magnitudes can'tbe materials.
In principle, abduction requires a check forthe consistency of what is e.mumed, and our knowledgebase should have contained axioms from which it could beinferred that a magnitude is not a material.
In practice,unconstrained consistency hecking is undecidable and, atbest, may take a long time.
Nevertheless, one can, throughthe use of a type hierarchy, eI~minate a very large numberof possible assumptions that are likely to result in an in-consistency.
We have consequently hnplemented a modulewhich specifies the types that various predicate-argumentpositions can take on, and the likely disjointness relationsamong types.
This is a way of exploiting the specificityof the English lexicon for computational purposes.
Thisaddition led to a speed-up of two orders of magn/tude.There is a problem, however.
In an ontologically promis-cuous notation, there is no commitment in a primed propo-sition to truth or existence in the real world.
Thus, \]ube-oil'(e, o) does not say that o is lube oil or even that itexists; rather it says that ?
is the eventuality of o's beinglube oil.
This eventuality may or may not exist in the realworld.
If it does, then we would express this as Re,fists(e),and from that we could derive from axioms the existenceof o and the fact that it is lube oil.
But e's existentialstatus could be something different.
For example, e couldbe nonexistent, expressed as not(e) in the notation, andin English as "The eventuality e of o's being lube oil doesnot exist," or as "o is not lube oil."
Or e may exist onlyin someone's beliefs.
While the axiom(V z)Fressure(z) D-qube-oil(x)is certainly true, the axiom(Vel,z)~essure'(e,,=) ~ -,(3 eDtu~e-oir(e2, =)would not be true.
The fact that a variable occupies thesecond argument position of the predicate lube-o/l' doesnot mean it is lube oil.
We cannot properly restrict hatar~Btment position to be lube oil, or fluid, or even a ma-terial, for that would rule out perfectly true sentences like"~uth  is not lube oil.
"Generally, when one uses a type hierarchy, one assumesthe types to be disjoint sets with cleanly dei~ed bound-aries, and one assumes that predicates take arguments ofonly certain types.
There are a lot of problems with thisidea- In any case, in our work, we are not buying into thisnotion that the universe is typed.
P~ther we are using thetype hierarchy strictly as a heuristic, as a set of guessesnot about what could or could not be but about what itwould or would not occur to someone to 5~zI/.
~'hen twotypes are declared to be disjoint, we are saying that theyare certainly disjoint in the real world, and that they arevery probably disjoint everywhere except in certain bizarremodal contexts.
This means, however, that we risk fmlingon certain rare examples.
We could not, for example, dealwith the sentence, ~It then assumed that the pressure waslube oily6 Future  D i rec t ionsDeduction is explosive, and since the abduction schemeaugments deduction with the assumptions, it is even moreexplosive.
We are currently engaged in an empirical in-vestigation of the behavior of this abductive scheme on avery large knowledge base performing sophisticated pro-ceasing.
In addition to type checking, we have introducedtwo other tevhnlques that are necessary for controlling theexploslon~unwinding recursive axioms and making use ofsyntactic noncoreference information.
We expect our in-vestigation to continue to yield techniques for controllingthe abduction process.We are also looking toward extending the interpretationprocesses to cover lexical ambiguity, quantifier scope am-biguity and metaphor interpretation problems as well.
Wewill also be investigating the integration proposed in Sec-tion 4.3 and an approach that integrates all of this withthe recognition of discourse structure and the recognitionof relations between utterances and the hearer's interests.102AcknowledgementsThe authors have profited from discussions with ToddDavies, John Lowrance, Stuart Shieber, and Mabry Tysonabout this work.
The research was funded by the DefenseAdvanced Research Projects Agency under Office of NavalResearch contract N00014-85-C-0013.References\[1\] Bear, John, and Jerry R. Hobbs, 1988.
"Localizing theExpression of Ambiguity", Proceeding-., Second Confer-ence on Applied Natural Language Proce-.-.ing, Austin,Texas, February, 1988.\[2\] Charniak, Eugene, 1986.
"A Neat Theory of MarkerPassing", Proceedings, AAAI-86, Fifth National Con-ference on Artificial Intelligence, Philadelphia, Pennsyl-vania, pp.
584-588.\[3\] Clark,Herbert, 1975.
"Bridging".
In R. Schank andB.
Nash-Webber (Eds.
), Theoretical I~sue-.
in Natu-ral Language Processing, pp.
169-174.
Cambridge, Mas-sachusetts.\[41 Cox, P. T., and T. Pietrzykowski, 1986.
"Causes forEvents: Their Computation and Applications", Proceed.ing~, CADE-&\[5\] Downing, Pamela, 1977.
"On the Creation and Use ofEnglish Compound Nouns", Language, vol.
53, no.
4,pp.
810-842.\[6\] Hobbs, Jerry 1~, 1983.
"An Improper Treatment ofQuantification i Ordinary English", Proceeding, of the51Jr Annual Meeting, Association for ComputationalI, inguiatic$, pp.
5%63.
Cambridge, Massachusetts, June1983.\[7\] Hobbs, Jerry R. 1985a.
"Ontological promiscuity."
Pro.ceedings, 23rd Annual Meeting of the A85ociation forComputational Linguistics, pp.
61-69.\[8\] Hobbs, Jerry R., 1985b, "The Logical Notation: Onto-logical Promiscuity", manuscript.\[9\] Hobbs, Jerry (1986) "Overview of the TACITUSProject", CL, Vol.
12, No.
3.\[10\] Hobbs, Jerry R., William Croft, Todd Davies, Dou-glas Edwards, and Kenneth Laws, 1986.
"CommonsenseMetaphysics and Lexical Semautics', Proceeding-., ~thAnnual Meeting of the A~aociation for ComputationalLinguiaticJ, New York, June 1986, pp.
231-240.\[11\] Hobbs, Jerry R., and Paul Martin 1987.
"Local Prag-matics".
Proceedings, International Joint Conference onArtificial Intelligence, pp.
520-523.
Mila~o, Italy, Au-gust 1987.\[12\] Joos, Martin, 1972.
"Semantic Axiom Number One",Language, pp.
257-265.\[13\] Kowalski, Robert, 1980.
The Logic of Problem Soh.lug, North Holland, New York.\[14\] Levi, Judith, 1978.
The Synta= and Semantics ofComplez Nominals, Academic Press, New York.\[15\] Norvig, Peter, 1987.
"Inference in Text Understand-ing", Proceedings, AAAI-87, Sizth National Confer-ence on Artificial Intelligence, Seattle, Washington, July1987.\[16\] Nuaberg, Geoffery, 1978.
"The Pragmatics of Refer-enee", Ph.D. thesis, City University of New York, NewYork.\[17\] Pereira, Feraando C. N., and Martha E. Pollack, 1988.
"An Integrated Framework for Semantic and PragmaticInterpretation", to appear in Proceedings, 56th AnnualMeeting of the Association for Computational Linguis-tics, Buffalo, New York, June 1988.\[18\] Pereira, Fernando C. N., and David H. D. Warren,1983.
"Parsing as Deduction", Proceeding8 of the 51~Annual Meeting, AJsociation for Computational Lin-guistics, pp.
137-144.
Cambridge, Massachusetts, June1983.\[19\] Pople, Harry E., Jr., 1973, "On the Mechanizationof Abductive Logic", ProceedingJ, Third InternationalJoint Conference on Artificial Intelligence, pp.
147-152,Stanford, California, August 1973.\[20\] Stickel, Mark E., 1982.
"A Nonclausal Connection-Graph Theorem-Proving Program", ProcecdingJ, AAAI.85 National Conference on Artificial Intelligence, Pitts-burgh, Pennsylvania, pp.
229-233.\[21\] Stickel, Mark E., 1988.
"A Prolog-like Inference Sys-tem for Computing Minimum-Cost Abductive Explana-tions in Natural-Language Interpretation", forthcoming.\[22\] Thagard, Paul R., 1978.
"The Best Explanation: Cri-teria for Theory Choice", The Journal of Philosophy,pp.
76-92.\[23\] Wilks, Yorick, 1972.
Grammar, Meaning, and the Ma-chine Analy-.iJ of Language, Routledge and Kegan Paul,London.103
