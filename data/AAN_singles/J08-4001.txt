ACL Lifetime Achievement AwardOn Whose Shoulders?Yorick Wilks?University of SheffieldIntroductionThe title of this piece refers to Newton?s only known modest remark: ?If I have seenfarther than other men, it was because I was standing on the shoulders of giants.?
Sincehe himself was so much greater than his predecessors, he was in fact standing on theshoulders of dwarfs, a much less attractive metaphor.
I intend no comparisons withNewton inwhat follows: NLP/CL has noNewtons and noNobel Prizes so far, and quiterightly.
I intend only to draw attention to a tendency in our field to ignore its intellectualinheritance and debt; I intend to discharge a little of this debt in this article, partly asan encouragement to others to improve our lack of scholarship and knowledge of ourown roots, often driven by the desire for novelty and to name our own systems.
RogerSchank used to argue that it was crucial to name your own NLP system and then havelots of students to colonize all major CS departments, although time has not been kind tohis many achievements and originalities, even though he did build just such an Empire.But to me one of the most striking losses from our corporate memory is the man whois to me the greatest of the first generation and still with us: Vic Yngve.
This is the manwho gave us COMIT, the first NLP programming language; the first random generationof sentences; and the first direct link from syntactic structure to parsing processes andstorage (the depth hypothesis).
I find students now rarely recognize his name, and findthat incredible.This phenomenon is more than corporate bad memory, or being too busy with en-gineering to do the scholarship.
It is something endemic in the wider field of ComputerScience and Artificial Intelligence, although bottom-up wiki techniques are now fillingmany historical gaps for those who know where to look, as the generation of pioneershas time to reminisce in retirement.1 There are costs to us from this general lack ofawareness, though: a difficulty of ?standing on the shoulders?
of others and acknowl-edging debts, let alne passing on software packages.
Alan Bundy used to highlight thisin theAISB Quarterlywith a regular columnwhere he located and pilloried reinventionsin the field of AI; he also recommended giving obituaries for one?s own work, and thispaper could be seen in that way, too.?
Department of Computer Science, The University of Sheffield, Regent Court, 211 Portobello Street,Sheffield, S1 4DP, UK.
E-mail: Y.Wilks@dcs.shef.ac.uk.
This article is the text of the talk given on receipt ofthe ACL?s Lifetime Achievement Award in 2008.1 See the video interview with Victor Yngve on my Web site athttp://www.dcs.shef.ac.uk/?yorick/YngveInterview.html.?
2008 Association for Computational LinguisticsComputational Linguistics Volume 34, Number 4Early Academic LifeMy overwhelming emotion on getting this honor was, after surprise, a feeling of in-adequacy in measuring up to previous honorees, but nonetheless, I want to grasp atthis moment of autobiography, or at what in his own acceptance paper Martin Kaycalled: ?but one chance for such gross indulgence.?
I was born in 1939 in London atjust about the moment the Second World War started in Europe; this was, briefly, asevere career slowdown.
However, the British Government had a policy of exportingmost children out of the range of bombs and I was sent to Torquay, a seaside town insouthwest England that happened to have palm trees on all the main streets, a fact itis often difficult to convince outsiders of.
The town had, and has, a Grammar Schoolfor Boys, which had a very good Cambridge-trained mathematician as its headmaster,and eventually I made my way back across England to Pembroke College, Cambridge,to study mathematics, a college now for ever associated with my comedian contem-poraries: Peter Cook, Clive James, Eric Idle, Tim Brooke-Taylor, and similar wastrels.
Ibegan a series of changes of subject of study, downhill towards easier and easier ones:frommathematics to philosophy to (what in the end after graduation became) NLP/AI.It was not that I could not do the mathematics, but rather that I experienced the shockthat many do of finding how wide the range of talent in mathematics is, and that beingvery good in a provincial grammar school does not make one very good at Cambridge.This is a feeling peculiar to mathematics, I think, because the talent range is so muchwider than in most subjects, even at the top level.Margaret Masterman, who was to become the main intellectual influence in my life,was the philosophy tutor for my college, although her main vocation was running theInstitute she had founded, outside the University in a Cambridge suburb: CLRU, theCambridge Language Research Unit.
It was an eccentric and informal outfit, housed inwhat had been a museum of Buddhist art, some of whose sculptures were built into thewalls.
MMB (as she was known) ran the CLRU from the mid 1950s to the early 1980son a mix of US, UK, and EU grants and did pioneering work in MT, AI, and IR.
Ofthose honored by the ACL with this award over the last five years, three have beengraduates of that little Buddhist shed, and include Martin Kay and Karen Spa?rck Jones,a remarkable tribute to MMB.
The lives and work of we three have been quite differentbut all in different ways stem from MMB?s interests and vision: She had been a pupilof Wittgenstein and, had she known it, would have approved of Longuet-Higgins?sremark that ?AI is the pursuit of metaphysics by other means.?
She believed thatpractical research into the structure of language could give insight into metaphysics,but was in no way other-worldly: She was the daughter of a Cabinet Minister and knewwhat it was to command.In a final twist, I found after her death in 1986 that she had made me her literaryexecutor: She had never written a book andwantedme to construct one from her papersposthumously.
It took me twenty years to get the required permissions but the volumefinally appeared in 2005 (Masterman et al 2005).Thesis Building and CLRUWhen I started work at CLRU in 1962 to do a doctorate, it had no computer in thenormal sense, only a Hollerith card sorter of the sort built for the US census half acentury before.
Basically, you put a stack of punched cards into one of these things?which looked like a metal horse on four legs?and the cards fell into (I think) 10 slots472Wilks On Whose Shoulders?depending on how you had plugged in a set of wires at the back to identify destinationslots for sorted cards with hole patterns on the cards.
With some effort, these couldbe turned into quite interesting Boolean machines; my first task was to take a notionof Fred Parker-Rhodes that a Hallidayan grammar could be expressed as a lattice oftyped classes, and then program the card sorter so that repeated sorts of punched cardscould be used to parse a sentence.
It was triumph of ingenuity over practicality.
Laterthe CLRU owned an ICL 1202 computer with 1,200 registers on a drum, but it wasa so-called bini-ten machine designed for UK cash transactions when there were still12 pennies to a shilling, and so the 1202 has print wheel characters for 10, 11, and 12(as well as 0?9), a fact on which Parker-Rhodes built a whole world of novel printconventions for his research.
This was the period at CLRU when Karen Spa?rck Joneswas completing her highly original thesis (published twenty years later as Jones [1986])on unsupervised clustering of thesaurus terms?whose goal was to produce primitivesfor MT, it is often forgotten?until she had to move her computations to a real computerat the University Computing Laboratory, where she eventually created a new career inIR, essentially using the same clump algorithms?created by Parker-Rhodes and herhusband Roger Needham?to do IR.My own interests shifted to notions in an early Masterman paper titled ?Semanticmessage detection using an interlingua?
(Masterman 1961), an area in which MartinKay had also originally worked on an interlingua for MT.
My thesis computation wasdone in LISP 1.6 on an IBM360 (under a one-man US Air Force contract, administeredby E. Mark Gold, who later became famous as the founder of learnability theory), atSDC in Santa Monica, where I was attached loosely in 1966 to the NLP group thererun by Bob Simmons.
My thesis was to be entitled ?Argument and proof in Meta-physics from an empirical point of view?
andmy advisor wasMMB?s husband, RichardBraithwaite, Knightbridge Professor of Moral Philosophy at the University.
He was aphilosopher of science and a logician, and was given the chair of moral philosophy?a subject about which he knew nothing?because it was the only one available atCambridge at the time.
This produced an extraordinary inaugural lecture in whichhe effectively founded a new subject: ?The theory of games as a tool for the moralphilosopher.
?Unfortunately for me he was not interested in my thesis, and took me on only asa favor to MMB.
My interest was the demarcation of metaphysical text: what it was, ifanything, that distinguished it from ordinary language text.
Wittgenstein had once saidthat words were ?on holiday?
in metaphysical text, but also that he wanted to ?bringwords back from their metaphysical to their everyday usage?
(Wittgenstein 1973).
Thisis exactly what I wanted to capture with computation, and the thesis was eventuallysubmitted to the Cambridge Philosophy faculty in 1967?then called Moral Sciences?with a large appendix of LISP program code at the back, something they had neverseen before, or since.
The thesis was bound in yellow, though the regulations stipulatedblack or brown bindings; I must have had some extraordinary idea that someone mightcruise the long corridors of Cambridge theses looking for one that stood out by color?the arrogance of youth!The thesis?s starting point was Carnap?s monumental Logische Syntax der Sprache(1937) and his claim that meaningfulness in text could be determined by ?logicalsyntax?
?rules of formation and transformation (a notion which may well sound famil-iar; Chomsky was a student of Carnap).
My claim was that this was a bad demarcationand a better criterion of meaningfulness would be to have one interpretation rather thanmany, namely, that word-sense discrimination (WSD) was possible for a given text.
Onthat view, the ?meaningless?
text had too many interpretations rather than none (or473Computational Linguistics Volume 34, Number 4one).
A word in isolation is thus often meaningless.
Preference Semantics was a WSDprogram to do just that, and to provide a new sense where WSD failed.The other starting point of the thesis was a slim paper by Bosanquet on the nature ofmetaphysical discourse, entitled ?Some Remarks on Spinoza?s Ethics.?
He argued thatSpinoza?s logical arguments are all false, but that what Spinoza was actually doing isrhetorical, not logical: imposing a new sense on the reader.
The system as implementedwas, of course, a toy system, in the sense that all symbolic NLP systems were in thatera.
It consisted of an analysis of five metaphysical texts (by Wittgenstein, Spinoza,Descartes, Kant, and Leibniz) along with five randomly chosen passages from editorialsin the London Times, as some sort of control texts.The vocabulary was only about 500 words, but this was many years beforeBoguraev declared the average size of vocabularies in working NLP systems to be36 words.
The semantic structures derived?via what we would now call chunkparsing?consisted of tree structures of primitives (from a set of about 80), one treefor each participating word sense in the text chunk, that fitted into preformed triplescalled templates.
These templates were subject?predicate?object triples that definedwell-formed sequences of the triples of trees (i.e., the first tree for the sense of thesubject, the second for the action and so on), whose tree-heads had to fit those of thetemplate?s three primitive items in order.
The overall system selected the word sensesthat fitted into these structures by means of a notion of ?semantic preference?
(seesubsequent discussion), and then declared those to be the appropriate senses for thewords, thus doing a primitive kind of WSD.There was in the thesis an additional ?sense constructor?
mode, called if the WSDdid not work, which tried to identify some sense of a word in the text whose representa-tion would fit in the overall structure derived, and so could be declared a suitable ?new?sense for thewordwhich had previously failed to fit in.
Unsurprisingly, it identified, say,a sense of ?God?
in the Spinoza text with an existing sense of ?Nature?
so that, afterthis substitution, the whole thing fitted together and WSD could proceed, and thus thepassage be declared meaningful, given the criterion of having a single, ambiguity-free,interpretation.
This was the toy procedure that allowed me to argue that Spinoza?s realaim, whether he knew it or not, was to persuade us that the word ?God?
could havethe sense of ?Nature?
and that this was the real point of his philosophy?exactly in linewith what Bosanquet had predicted.The philosophy work was never really published, outside an obscure McGill Uni-versity philosophy journal, although the meaningfulness criterion appeared inMind in1971 under the title ?Decidability andNatural Language?
(Wilks 1971).
Since publishinginMind was, at the time, the ambition of every young philosopher, I was now satisfiedand could move to the simpler world of NLP.
The thesis, shorn of the metaphysics,appeared asmy first book,Grammar, Meaning and theMachine Analysis of Language (Wilks1972); the title was intended as a variation on the title of some strange German play,popular at the time, and whose actual name I can no longer remember.Preference SemanticsI returned from California to CLRU but left again for the Stanford AI Lab in 1969.I had fantasized at CLRU about all the things one could do with a methodology oftrying to base a fairly complex compositional semantics on a foundation of superficialpattern matching.
This had earlier produced speculations like my 1964 CLRU paper?Text searching with templates,?
procedures that we could not possibly have carried474Wilks On Whose Shoulders?I.1 ((*ANI 1)((SELF IN)(MOVE CAUSE))(*REAL 2))?
(1(*JUDG) 2)Or, in semi-English:[animate-1 cause-to-move-in-self real-object-2]?
[1 *judges 2]I.2 (1 BE (GOOD KIND))?
((*ANI 2) WANT 1)Or, again:[1 is good]?
[animate-2 wants 1]Figure 1Inference rules in Preference Semantics.out with the machines then available, but which I now choose to see as wanting todo Information Extraction: though, of course, it was Naomi Sager who did IE first onmedical texts at NYU (see Sager and Grishman 1975).At Stanford as a post-doc, I was on the same corridor asWinograd, just arrived fromMIT; Schank, then starting to build his Conceptual Dependency empire; and Colby andhis large team building the PARRY dialogue system, which included Larry Tesler, laterthe Apple software architect.
Schank and I agreed on far more than we disagreed on andsaw that wewould be stronger together than separately, but neither of us wanted to giveup our notation: He realized, rightly, that there was more persuasive power in diagramsthan in talk of processes like ?preference.?
It was an extraordinary period, when AI andNLP were probably closer than ever before or since: Around 1972 Colmerauer passedthrough the Stanford AI Lab, describing Prolog for the first time but, as you may ormay not remember, as a tool for machine translation!
I spent my time there defining andexpanding the coherence-based semantics underlying my thesis, calling it ?PreferenceSemantics?
(PS), adding larger scale structures such as inference rules (see Figure 1)and thesauri, and building it into the core of a small semantics-based English-to-Frenchmachine translation system programmed in LISP.
At one point the code of this MTsystem ended up in the Boston Computer Museum, but I have no idea where it is now.The principles behind PS were as follows: an emphasis on processes, not diagrams; the notion of affinity and repulsion between sense representations(cf.
Waltz and Pollack?s WSD connectionism [1985]); seeking the ?best fit?
interpretation?the one with most satisfiedpreferences (normally of verbs, prepositions, and adjectives); yielding the least informative/effort interpretation; using no explicit syntax, only segmentation and order of items; meaningfulness as being connected to a unique interpretation/sensechoice; meaning seen as represented in other words, since no other equivalent forthe notion works (e.g., objects or concepts); gists or templates of utterances as core underlying entities; and there is no correct interpretation or set of primitive concepts, only the bestavailable.475Computational Linguistics Volume 34, Number 4One could put some of these, admittedly programmatic and imprecise, points asfollows: Semantics is not necessarily deep but also superficial (see more recentresults on the interrelations between WSD, POS, and IE, e.g.
Stevensonand Wilks [2001]). Quantitative phenomena are unavoidable in language: John McCarthythought they had no place anywhere in AI, except perhaps in low-levelcomputer vision. Reference structures (like lexicons) are only temporary snapshots of alanguage in a particular state (of expansion or contraction). What is important is to locate the update mechanism of language,including crucially the creation of new word senses, which is notChomsky?s sense of the creativity of language.Constructible Belief SystemsI returned to Europe in the mid 1970s, first to the ISSCO institute in Lugano, whereCharniak was and Schank had just left, and then to Edinburgh as a visitor before takinga job at Essex.
I began a long period of interest in belief systems, in particular seekingsome representation of the beliefs of others, down to any required degree of nesting?for example, A?s belief about B?s belief about C?that could be constructed recursivelyat need, rather than being set out in advance, as in the pioneering systems emergingfrom the Toronto group under Ray Perrault (Allen and Perrault 1980).
I began thinkingabout this with Janusz Bien of the University of Warsaw, who had also published apaper arguing that CL/NLP should consider ?least effort?
methods: in the sense thatthe brain might well, due to evolution, be a lazy processor and seek methods forunderstanding that minimized some value that could be identified with processingeffort.
I had argued in PS for choosing shortest chains of inferences between templates,and that the most connected/preferred template structure for a piece of text should bethe one found first.
I am not sure we ever proved any of this: It was just speculation,as was the preference for the most semantically connected representation, and therepresentation with the least information.
All this is really only elementary informationtheory: a random string of words contains the maximum information, but that is notvery helpful.
Clearly, the preferred interpretation of ?He was named after his father?
(i.e., named the same rather than later in time) is not the least informative, since the lattercontains no information at all?being necessarily true?so one would have to adaptany such slogan to: ?prefer the interpretation with the least information, unless it iszero!
?The belief work, first with Bien, later with Afzal Ballim (Wilks and Ballim 1987)and John Barnden, has not been a successful paradigm in terms of take-up, in thatit has not got into the general discourse, even in the way that Fauconnier?s ?MentalSpaces?
(Fauconnier 1985) has.
That approach uses the same spatial metaphor, but forstrictly linguistic rather than belief and knowledge purposes.
But I think the VIEWGENbelief paradigm, as it became, had virtues, and I want to exploit this opportunity toremind people of it.
It was meant to capture the intuition that if we want, for language476Wilks On Whose Shoulders?understanding purposes, to construct X?s beliefs about Y?s beliefs?what I called theenvironment of Y-for-X?then:1.
It must be a construction that can be done in real time to any level ofnesting required, because we cannot imagine it pre-stored for all futurenestings, as Perrault el al.
in effect assumed.2.
It must capture the intuition that much of our belief is accepted by defaultfrom others: As VIEWGEN expresses it, I will accept as a belief what yousay, because I have normally no way of checking, or experimenting on, letalone refuting, the things you tell me, e.g., that you had eggs for breakfastyesterday.
As someone in politics once put it, ?There is no alternative.
?Unless, that is, what you say contradicts something I believe or can easilyprove from what I believe.3.
We must be able to maintain apparently contradictory beliefs, providedthey are held in separate spaces and will never meet as contradictions.
Ican thus maintain within my-space-for-you beliefs of yours (according tome) that I do not in fact hold.In VIEWGEN, belief construction is done in terms of a ?push down?
metaphor: Apermeable ?container?
of your beliefs is pushed into a ?container?
of my beliefs andwhat percolates through the membrane, from me to you, will be believed and ascribedto you, unless it is explicitly contradicted, namely, by some contrary belief I alreadyascribe to you, and which, as it were, keeps mine from percolating through.
The ideais to construct the appropriate ?inner belief space?
at the relevant level of nesting, sothat inference can be done, and to derive consequences (within that constrained contentspace) that also serve to model, in this case, you the belief holder in terms of goalsand desires, in addition to beliefs.
This approach is quite different not only from thePerrault/Toronto system of belief-relevant plans but also to AI theories that make use ofsets-of-support premises, since this is about belief-inheritance-by-default.
It is also quitedistinct from linguistic theories like Wilson and Sperber?s Relevance Theory, whichtake no account at all of belief as relative to individuals, but perform all operationsin some space that is the same for everyone, which is an essentially Chomskyan idealcompetence-style notion of belief that is not relative to individuals?which is of courseabsurd.Mark Lee and a number of my students have created implementations of thisapproach and linked it to dialogue and other applications, but there has been no majorapplication showing its essential role in a functioning conversational theory wherecomplex belief states are created in real time.
However, the field is, I believe, nowmoving in that direction (e.g., with POMDP theories [Williams and Young 2007]) sincethe possibility of populating belief theories with a realistic base from text by means ofInformation Extraction or Semantic Web parsing to RDF format is now real (a matter weshall return to subsequently).There were, for me at least, two connections between the VIEWGEN belief workand Preference Semantics, in terms of meaning and its relation to processes.
First,there was the role of choice and alternatives, crucial to PS, in that an assigned mean-ing interpretation for a text was no more than a choice of the best available amongalternatives, because preference implies choice, in a way that generative linguistics?though not of course traditions like Halliday?s?always displayed alternatives butconsidered choice between them a matter for mere performance.
What was dispensable477Computational Linguistics Volume 34, Number 4to generative linguistics was the heart of the matter, I argued, to NLP/CL.
Secondly,VIEWGEN suggested a view of meaning, consistent locally with PS, dependent onwhich individuals or classes one chose to see in terms of each other?the key notionhere was seeing one thing as another and its consequences for meaning.
So, if one choseto identify (as being the same person under two names) Joe (and what one believedabout him) with Fred?s father (and what one knew about him), the hypothesis was thata belief environment should be constructed for Joe-as-Fred?s-father by percolating oneset of beliefs into the other, just as was done by the basic algorithm for creating A?s-beliefs-about-B?s-beliefs from the component beliefs of A and B.
This process createda hybrid entity, with intensional meaning captured by the set of propositions in thatinner environment of belief space, but which was now neither Joe nor Fred?s father butrather the system?s point of view of their directional amalgamation: Joe-as-Fred?s-father(which might contain different propositions from the result of Fred?s-father-as-Joe).More natural, and fundable, scenarios were constructed for this technique in thosedays, such as knowledge representations for Navy ships?
captains genuinely uncertainas to whether ship-in-my-viewfinder-now was or was not to be identified with thestored representation for enemy-ship-number-X.
The important underlying notion wasone going back to Frege, and which first had an outing in Winograd?s thesis (Winograd1972), where he showed you could have representations for blocks that did not in factexist on the Blocks World table.
A semantics must be able to represent things withoutknowing whether they exist or not; that is a basic requirement.Later, and working with John Barnden and Afzal Ballim, this same underly-ing process of conflating two belief objects was extended to the representation of?metaphorical objects,?
which could be described, quite traditionally in the literature,as A-viewed-as-B (e.g., an atom viewed as a billiard ball).
The metaphorical objectatom-as-billiard-ball was again created by the same push-down or fusion of belief setsas in the basic belief point-of-view procedure.
All this may well have been fanciful,and was never fully exploited in published work with programs, but it did have acertain intellectual appeal in wanting to treat belief, points of view, metaphor andidentification of intensional individuals?normally quite separate issues in semantics?as being modellable by the same simple underlying process (see Ballim, Wilks, andBarnden 1991).
One novel element that did emerge from this analysis was that, inthe construction of these complex intensional identifications, such as between ?today?sWimbledon winner?
and ?the top male tennis seed,?
one could choose directions of?viewing as?
with the belief sets that led to objects which were neither the classic de renor de dicto outcomes: Those became just two among a range of choices, and the othersof course had no handy Latin names.Adapting to the ?Empirical Wave?
in NLPFor me, as with many others, especially in Europe, the beginning of the empirical wavein NLP was the work of Leech and his colleagues at Lancaster: CLAWS4 (a name whichhides a UK political joke), their part-of-speech tagger based on large-scale annotation ofcorpora.
Such tagging is now the standard first stage of almost every NLP process and itmay be hard for some to realize the skepticsm its arrival provoked: ?What could anyonewant that for??
was a common reaction from those still preoccupied by computationalsyntax or semantics.
That system was sold to IBM, whose speech group, under Jelinek,Mercer, and Brown, subsequently astonished the CL/NLP world with their statisticalmachine translation system CANDIDE.
I wrote critical papers about it at the time, nottotally unconnected to the fact that I was funded by DARPA on the PANGLOSS project478Wilks On Whose Shoulders?at NMSU (along with CMU and ISI/USC) to do MT by competing, but non-statistical,methods.In one paper, I used the metaphor of ?stone soup?
(Wilks 1996): A reference to theold peasant folk-tale of the traveler who arrives at a house seeking food and claimingto have a stone that makes soup from water.
He begs a ham bone to stir the waterand stone and eventually cons out of his hosts all the ingredients for real soup.
Theaspect of the story I was focusing on was that, in the CANDIDE system, I was not surethat the ?stone,?
namely IBM?s ?fundamental equation of MT,?
was in fact producingthe results, and suggested that something else they were doing was giving them theirremarkable success rate of about 50% of sentences correctly translated.
As their generalmethodology has penetrated the whole of NLP/CL, I no longer stand by my earlycriticisms; IBM was of course right, and had everything to teach the rest of us.Early critics of data-driven, alias empirical, CL found it hard to accept, whateverits successes in, say, POS tagging, that its methods could extend to the heartland ofsemantics and pragmatics.
Like others, I came to see this assumption was quite untrue,and myself moved towards Machine Learning (ML) approaches to word-sense disam-biguation (e.g., Stevenson and Wilks 2001) and I now work in ML methods applied todialogue corpora (as I shall mention subsequently).
But the overall shift in approachesto semantics since 1990 has not only been in the introduction of statistical methods, andML in particular, but also in the unexpected advantages that have been gained fromwhat one might call non-statistical empirical linguistics, and in particular InformationExtraction (IE; see Wilks 1997).I referred earlier to the fact that my early work could be called, in a general sense,semantic parsing, and that it was in fact some form of superficial pattern matchingonto language chunks that was then transformed to different layers of compositionalsemantic representation.
There were obvious relations between that general approachand what emerged from the DARPA competitions in the early 1990s as IE, a technologythat, when honed by many teams, and especially when ML techniques were added toit later, had remarkable success and a range of applications; it also expanded out intoother, traditionally separate, NLP areas such as question answering and summarization.This approach is not in essence statistical at all, however, although it is in a clearsense ?superficial,?
with the assumption that semantics is not necessarily a ?deep?phenomenon but present on the language surface.
I believe the IE movement is alsoone of the drivers behind the Semantic Web movement, to which I now turn, and whichI think has brought NLP back to a position nearer the core of AI, from which it driftedaway in the 1980s.Meaning and the Semantic WebThe Semantic Web (SW; Berners-Lee, Hendler, and Lassila 2001) is what one could callBerners-Lee?s second big idea, after the World Wide Web; it can be described briefly asturning the Web into something that can also be understood by computers in the waythat it is understood by people now, as a web of texts and pictures.
Depending on one?sattitude to this enterprise, already well-funded by the European Commission at least, itcan be described as any of the following:1.
As a revival of the traditional AI goal (at least since McCarthy and Hayes[1969]) of replacing language, with all its vagueness, by some form oflogical representation upon which inference can be done.479Computational Linguistics Volume 34, Number 42.
As a hierarchy of forms of annotation?or what I shall call augmentationof content?reaching up from simple POS tagging to semantic classannotation (e.g.
CITY, PERSON-NAME) to ontology membership andlogical forms.
DARPA/MUC/NIST competitions have worked their wayup precisely this hierarchy over the years and many now consider thatcontent can be ?annotated onto language?
reliably up to any requiredlevel.
This can be thought of as extending IE techniques to any linguisticlevel by varieties of ML and annotation.3.
As a system of access to trusted databases that ground the meanings ofterms in language; your telephone or social security number might groundyou uniquely (in what is called a URI), or better still?and this is now thestandard view?a unique identifying object number for you over andabove phones and social systems.
This is very much Tim Berners-Lee?sown view of the SW.There is also a fourth view, much harder to express, that says roughly that, if we keepour heads, the SW can come into being with any system of coding that will tolerate theexpansion of scale of the system, in the way that, miraculously, the hardware under-pinnings of the World Wide Web have tolerated its extraordinary expansion withoutmajor breakdown.
This is an engineering view that believes there are no fundamentalproblems about the meanings and reference of SW terms in, for example, the ontologieswithin the SW, and everything will be all right if we just hold tight.This view may turn out to be true but it is impossible to discuss it.
Similarly, view(3) has no special privilege because it is the WorldWideWeb founder?s own view: Marxwas notoriously not a very consistent Marxist, and one can find multiple examplesof this phenomenon.
View (3) is highly interesting and close to philosophical viewsof meaning expressed over many years by Putnam, which can be summarized as theidea that scientists (and Berners-Lee was by origin a database expert and physicist) are?guardians of meaning?
in some sense because they know what terms really mean, ina way that ordinary speakers do not.
Putnam?s standard example is that of metals likemolybdenum and aluminum, which look alike and, to the man in the street, have thesame conceptual, intensional meaning, namely light, white, shiny metal.
But only thescientist (says Putnam) knows the real meanings of those words because he knowsthe atomic weights of the two metals and methods for distinguishing them.No one who takes Wittgenstein?and his view that we, the users of the language,are in charge of what termsmean, and not any expert?at all seriously can even considersuch a view.
On the view we are attributing to Wittgenstein, the terms are synonymousin a public language, just as water and heavy water are, and any evidence to the contraryis a private matter for science, not for meaning.View (1) of the Semantic Web is a well-supported one, particularly by recycled AIresearchers: They have, of course, changed tack considerably and produced formalismsfor the SW, some of which are far closer to the surface of language than logic (whatis known as RDF triples), as well as inference mechanisms like DAML-OIL that gainadvantages over traditional AI methods on the large and practical scale the SW isintended to work over.
On the other hand there are those in AI who say they haveignored much of the last 40 years of AI research that would have helped them.
Thisdispute has a conventional flavor and it must be admitted that, in more than 40 years,AI itself did not come up with such formalisms that stood any chance at all of workingon a large scale on unstructured material (i.e., text).480Wilks On Whose Shoulders?This leaves us with View (2), which is my own: namely, that we should see the SWpartially in NLP terms, however much Berners-Lee rejects such a view and says NLPis irrelevant to the SW.
The whole trend of SW research, in Europe at least, has beento build up to higher and higher levels of semantic annotation?a technology that hasgrown directly out of IE?s success in NLP?as a way of adding content to surface text.It seems to me obvious that any new SW will evolve from the existing WWW of textby some such method, and that method is basically a form of large-scale NLP, whichnow takes the form of transducers from text to RDF (such as the recently advertisedReuters API).
The idea that the SW can start from scratch in some other place, ignoringthe existing World Wide Web, seems to me unthinkable; successful natural evolutionalways adapts the function of what is available and almost never starts again afresh.I have set out my views on this recently in more detail (Wilks 2008), but it isimportant to see that the SW movement?at least as I interpret it herein, and that doesseem pretty close to the way research in it is currently being funded, under calls andtitles like ?semantic content?
?is one that links to the themes already developed in thispaper in several ways, and which correspond closely to issues in my own early work,but which have not gone away:1.
The SW takes semantic annotation of content as being a method?whetherdone by humans or after machine learning?of recoding content withspecial terms, terms close to what have traditionally been called semanticprimitives.
It is exactly this that was denied by the early forms of, say,statistical MT, where there was nothing available to the mechanism exceptthe words themselves.
This is also quite explicit in traditional IR, where,for example, Karen Spa?rck Jones consistently argued against any form ofcontent recoding, including the SW. As she put it: ?One of these [simple,revolutionary IR] ideas is taking words as they stand?
(Spa?rck Jones 2003).2.
The SW accords a key role to ontologies as knowledge structures: partiallyhierarchical structures containing key terms?primitives again underanother guise?whose meanings must be made clear, particularly at themore abstract levels.
The old AI tradition in logic-based knowledgestructuring?descending from McCarthy and Hayes (1969)?was simplyto declare what these primitive predicates meant.
The problem was thatpredicates, normally English words written in capital letters (as alllinguistic primitives in the end seem to be), became affected by theirinferential roles over time and the process of coding itself.
This becamevery clear in the long-term Cyc project (Lenat 1995) where the keypredicates changed their meanings over 30 years of coding, but there wasno way of describing that fact within the system, so as to guaranteeconsistency.
In Nirenburg and Wilks (2000), Nirenburg and I debate thisissue in depth, and I defend the position that one cannot simply maintainthe meanings of such terms by fiat and independent of their usage?theylook like words and they function like words because, in the end, they arewords.
The SW offers a way out of this classic AI dilemma by building upthe hierarchy of annotations with empirical processes like ontologyinduction from corpora (e.g., ABRAXAS; see Iria et al 2006); in this waythe meanings of higher level terms are connected back directly to textusage.
Braithwaite, my thesis advisor, described in his classic ?Scientificexplanation?
(Braithwaite 1953) a process in the philosophy of science he481Computational Linguistics Volume 34, Number 4called ?semantic ascent?
by which the abstract high-level terms in ascientific theory, seen as a logical hierarchy of deductive processes?termssuch as ?neutron,?
possibly corresponding to unobservables?acquiredmeaning by an ascent of semantic interpretation up the theory hierarchyfrom meanings grounded in experimental terms at the bottom.
It is somesuch grounding process I envisage the SW as providing for the meaningsof primitive ontological terms in a knowledge structure.3.
The RDF forms, based on triples of surface items, as a knowledgebase?usually with subject?action?object as basic form?can provide a lessformal but more tractable base for knowledge than traditional First OrderPredicate Logic (FOPL).
They have a clear relationship back to the crudetemplates of my early work and the later templates of IE.
I claim noprecedence here, but only note the return of a functioning but plausiblenotion of ?superficial semantics.?
It seems to me not untrue historically toclaim that RDF, the representational base of the SW, is a return of the levelof representation that Schank (under the name Conceptual Dependency, inSchank [1975]) and I (under the name Preference Semantics) developed inthe late 1960s and early 1970s (Wilks 1975).
I remember that at the StanfordAI Lab at that time, John McCarthy, a strong advocate of FOPL as the rightlevel of representation of language content, would comment thatformalisms like these two might have a role as a halfway house on a routefrom language to a full logic representation.
On one view of the SW thatintermediate stage may prove to be the right stage, because full AIrepresentations have never been able to deliver in terms of scale andtractability.
Time will tell, and fairly soon.The most important interest of the SW, from the point of view of this paper, is thatit provides at last a real possibility of a large-scale test of semantic and knowledgecoding: One thing the empirical movement has taught us is the vital importance of scaleand the need to move away from toy systems and illustrative examples.
I mentionedearlier the freely available Reuters API for RDF translation which Slashdot advertisedunder the title ?Is the Semantic Web a Reality at Last??
This is exactly the kind of moveto the large scale that we can hope will settle definitively some of these ancient issuesabout meaning and knowledge.A Late Interest in Dialogue: The Companions ProjectMy only early exposure to dialogue systems was Colby?s PARRY: As I noted earlier, histeam was on the same corridor as me at Stanford AI Lab in the early 1970s.
I was agreat admirer of the PARRY system: It seemed to me then, and still does, probably themost robust dialogue system ever written.
It was available over the early ARPANETand tried out by thousands, usually at night: It was written in LISP and never brokedown; making allowances for the fact it was supposed to be paranoid, it was plausibleand sometimes almost intelligent.
In any case it was infinitely more interesting thanELIZA, and it is one of the great ironies of our subject that ELIZA is so much betterknown.
PARRY remembered what you had said, had elementary emotion parametersand, above all, had something to say, which chatbots never do.
John McCarthy, whoran the AI Lab, would never admit that PARRY was AI, even though he tolerated itunder his roof, as it were, for many years; he would say ?It doesn?t even know who482Wilks On Whose Shoulders?the President is,?
as if most of the world?s population did!
PARRY was in fact a semi-refutation of the claim that you need knowledge to understand and converse, becauseit plainly knew nothing; what it had was primitive ?intentionality,?
in the sense that ithad things ?it wanted to say.
?My own introduction to practical work on dialogue was when I was contacted inthe late 1990s by David Levy, who had written 40 books on chess and ran a companythat made chess machines.
He already had a footnote in AI as the man who had betMcCarthy, Michie, and other AI leaders that a chess machine would not beat himwithinten years, and he won the bet more than once.
In the 1990s he conceived a desire to winthe Loebner Prize2 for the best dialogue program of the year, and came to us at Sheffieldto fund a team to win it for him, which we did in 1997.
I designed the system and drewupon my memories of PARRY, along with obvious advances in the role of knowledgebases and inference, and the importance of corpora and machine learning.
For example,we took the whole set of winning Loebner dialogues off the Web so as to learn the kindsof things that the journalist-testers actually said to the trial systems to see if they werereally humans or machines.Our system, called CONVERSE (see Levy et al 1997), claimed to be Catherine, a34-year old female British journalist living in New York, and it owed something toPARRY, certainly in Catherine?s desire to tell people things.
It was driven by framescorresponding to each of about 80 topics that such a person might want to discuss;death, God, clothes, make-up, sex, abortion, and so on.
It was far too top-down andunwilling to shift from topic to topic but it could seem quite smart on a good day, andprobably won because we had built in news from the night before the competition ofa meeting Bill Clinton had had that day at the White House with Ellen de Generes, alesbian actress.
This gave a certain immediacy to the responses intended to sway thejudges, as in ?Did you see that meeting Ellen had with Clinton last night?
?This was all great fun and gave me an interest in modeling dialogue that haspersisted for a decade and is now exercised through COMPANIONS (Wilks 2004), alarge EU 15-site four-year project that I run.
COMPANIONS aims to change the way wethink about the relationships of people to computers and the Internet by developing avirtual conversational ?Companion.?
This will be an agent or ?presence?
that stays withthe user for long periods of time, developing a relationship and ?knowing?
its owner?spreferences and wishes.
It will communicate with the user primarily by using and un-derstanding speech, but also using other technologies such as touch screens and sensors.Another general motivation for the project is the belief that the current Internetcannot serve all social groups well, and it is one of our objectives to empower citizens(including the non-technical, the disabled, and the elderly) with a new kind of interfacebased on language technologies.
The vision of the Senior Companion?currently ourmain prototype?is that of an artificial agent that communicates with its user on along-term basis, adapting to their voice, needs, and interests: A companion that wouldentertain, inform, and react to emergencies.
It aims to provide access to informationand services as well as company for the elderly by chatting, remembering past con-versations, and organizing (and making sense of) the owner?s photographic and imagememories.
This Companion would assume a user with a low level of technical knowl-edge, and who might have lost the ability to read or produce documents themselvesunaided, but who might need help dealing with letters, messages, bills, and getting in-formation from the Internet.
During its conversations with its user or owner, the system2 See http://www.loebner.net/Prizef/loebner-prize.html.483Computational Linguistics Volume 34, Number 4builds up a knowledge inventory of family relations, family events in photos, placesvisited, and so on.
This knowledge base is currently stored in RDF, the Semantic Webformat, which has two advantages: first, a very simple inference scheme with whichto drive further conversational inferences, and second, the possibility, not yet fulfilled,of accessing arbitrary amounts of world information from Wikipedia, already availablein RDF, which could not possibly have been pre-coded in the dialogue manager, norelicited in a conversation of reasonable length.
So, if the user says a photo was taken inParis, the Companion should be able to ask a question about Paris without needing thatknowledge pre-coded, but only using rapidly accessedWikipedia RDFs about Paris.
Anultimate aim of this aspect of the Senior Companion is the provision of a life narrative,an assisted autobiography for everyone, one that could be given to relatives later if theowner chose to leave it to them.
There is a lot of technical stuff in the Senior Companion:script-like structures?called DAFs or Dialogue Action Forms?designed to capture thecourse of dialogues on specific topics or individuals or images, and these DAFs we aretrying to learn from tiled corpora.
The DAFs are pushed and popped on a single stack,and that simple virtual machine is the Dialogue Manager, where DAFs being pushed,popped, or reentered at a lower stack point are intended to capture the exits from, andreturns to, abandoned topics and the movement of conversational initiative betweenthe system and the user.
We are halfway through the project and currently have twoprototype Companions: The other, based not at Sheffield but at Tampere, is a Healthand Fitness Companion (HFC).3 It is more task-oriented than the Senior Companionand aims to advise on exercise and diet.
The HFC is on a mobile phone architecture aswell as a PC, andwemay seek to combine the two prototypes later.
The central notion ofa Companion is that of the same ?personality,?
with its memory and voice being presentno matter what the platform.
It is not a robot, and could be embodied later in somethinglike a chatty furry handbag, being held on a sofa and perhaps reminding you about theprevious episodes of your favorite TV program.FinaleThis article has had something of the form of a life story, and everyone wants to believetheir life is some kind of narrative rather than a random chase from funding agency tofunding agency, with occasional pauses to carry out a successful proposal.
But let usreturn to Newton for a moment in closing; for us in CL he is the great counter-example,of why we do not do science or engineering in that classic solitary manner:.
.
.where the statue stoodOf Newton, with his prism and silent face,The marble index of a mind for everVoyaging through strange seas of Thought, alone.
?William Wordsworth (1770?1850)The Prelude, book iii, line 61The emphasis there for me is on alone, which is pretty much unthinkable in our researchworld of teams and research groups.
Our form of research is essentially corporate andcooperative; we may not be sure whose shoulders we are standing on, but we knowwhose hands we are holding.
I have worked in such a way since my thirties and, at3 An early demo of a Companion can be seen on YouTube athttp://www.youtube.com/watch?v=SqIP6sTt1Dw.484Wilks On Whose Shoulders?Sheffield, my work would not have been possible without a wide range of colleaguesand former students in the NLP group there over many years and including LouiseGuthrie, Rob Gaizauskas, Hamish Cunningham, Fabio Ciravegna, Mark Stevenson,Mark Hepple, Kalina Bontcheva, Roberta Catizone, Nick Webb, and many others.
Inrecent years, what one could call ?DARPA culture?
?of competitions and cooperationsubtlymixed?aswell as the great repositories of software and data like LDC and ELRA,have gone a long way to mitigate the personal and group isolation in the field.But we do have to face the fact that, in many ways, we do not do classic science:We have no Newtons and will never have any.
That is not to deny that we need realideas and innovations, and now may be a time for fresh ones.
We have stood on theshoulders of Fred Jelinek, Ken Church, and others for nearly two decades now, and thestrain is beginning to tell as papers still strive to gain that extra 1% in their scores onsome small task.
We know that some change is in the air and I have tried to hint inthis article as to some of the places where that might be, even if that will mean a partialreturn to older, unfashionable ideas; for there is nothing new under the sun.
But locatingthem and exploiting themwill not be in my hands but in yours, readers of ComputationalLinguistics!AcknowledgmentsFirst of course to all those who have workedwith me over many years and to whom Iowe so much, particularly in connectionwith this award.
Then to my current sponsor:This work was funded by the Companionsproject (www.companions-project.org)sponsored by the European Commission aspart of the Information Society Technologies(IST) programme under EC grant numberIST-FP6-034434.ReferencesAllen, James F. and C. Raymond Perrault.1980.
Analyzing intention in utterances.Artificial Intelligence, 15:143?178.Ballim, Afzal, Yorick Wilks, and John A.Barnden.
1991.
Belief ascription, metaphor,and intensional identification.
CognitiveScience, 15(1):133?171.Berners-Lee, T., J. Hendler, and O. Lassila.2001, September.
The semantic web.Scientific American, 28?37.Braithwaite, Richard Bevan.
1953.Scientific Explanation.
A Study of theFunction of Theory, Probability and Law inScience.
Cambridge University Press,Cambridge, UK.Carnap, Rudolf.
1937.
The Logical Syntax ofLanguage.
Kegan Paul, London.Fauconnier, Gilles.
1985.Mental Spaces.Cambridge University Press,Cambridge, UK.Iria, Jose?, Christopher Brewster, FabioCiravegna, and Yorick Wilks.
2006.
Anincremental tri-partite approach toontology learning.
In Proceedings of theLanguage Resources and EvaluationConference (LREC-06), 22?28 May.Lenat, Douglas B.
1995.
CYC: A large-scaleinvestment in knowledge infrastructure.Communications of the ACM, 38(11):33?38.Levy, D., R. Catizone, B. Battacharia,A.
Krotov, and Y. Wilks.
1997.
Converse:A conversational companion.
InProceedings of the First InternationalWorkshop of Human-ComputerConversation.
Bellagio, Italy.Masterman, Margaret.
1961.
Semanticmessage detection for machinetranslation, using an interlingua.
InProceedings of the First InternationalConference on Machine Translation ofLanguages and Applied Language Analysis,pages 438?475.
HMSO, Teddington,Middlesex, UK.Masterman, Margaret.
2005.
In Yorick Wilks,editor, Language, Cohesion and Form (Studiesin Natural Language Processing).
CambridgeUniversity Press, New York.McCarthy, J. and P. J. Hayes.
1969.
Somephilosophical problems from thestandpoint of artificial intelligence.
InB.
Meltzer and D. Michie, editors,MachineIntelligence, volume 4.
EdinburghUniversity Press, Edinburgh,pages 463?502.Nirenburg, Sergei and Yorick Wilks.
2000.Machine translation.
Advances inComputers, 52:160?189.Sager, Naomi and Ralph Grishman.1975.
The restriction language forcomputer grammars of natural language.Communications of the ACM,18(7):390?400.485Computational Linguistics Volume 34, Number 4Schank, Roger C. 1975.
Conceptual InformationProcessing.
Elsevier Science Inc., New York.Spa?rck Jones, Karen.
1986.
Synonymy andsemantic classification.
EdinburghUniversity Press, Edinburgh, Scotland.Spa?rck Jones, Karen.
2003.
Documentretrieval: Shallow data, deep theories;historical reflections, potential directions.In Advances in Information Retrieval, LectureNotes in Computer Science, 1?11.
Springer,Berlin/Heidelberg.Stevenson, Mark and Yorick Wilks.
2001.
Theinteraction of knowledge sources in wordsense disambiguation.
ComputationalLinguistics, 27(3):321?349.Waltz, David L. and Jordan B. Pollack.1985.
Massively parallel parsing: Astrongly interactive model of naturallanguage interpretation.
Cognitive Science,9(1):51?74.Wilks, Y.
1975.
Preference semantics.In E. L. Keenan, editor, Formal Semantics ofNatural Language.
Cambridge UniversityPress, Cambridge, pages 329?348.Wilks, Yorick.
1971.
Decidability and naturallanguage.Mind, 80:497?520.Wilks, Yorick.
1972.
Grammar, Meaning andMachine Analysis of Language.
Routledgeand Kegan Paul, London.Wilks, Yorick.
1996.
Statistical versusknowledge-based machine translation.IEEE Expert: Intelligent Systems and TheirApplications, 11(2):12?18.Wilks, Yorick.
1997.
Information extraction asa core language technology.
In InternationalSummer School on Information Extraction: AMultidisciplinary Approach to an EmergingInformation Technology, volume 1299 ofLecture Notes In Computer Science,pages 1?9, Springer, Berlin.Wilks, Yorick.
2004.
Artificial companions.
InMachine Learning for Multimodal Interaction:First International Workshop, pages 36?45.Wilks, Yorick.
2008.
The semantic web:Apotheosis of annotation, but what are itssemantics?
IEEE Intelligent Systems,23(3):41?49.Wilks, Yorick andAfzal Ballim.
1987.Multipleagents and the heuristic ascription ofbelief.
In Proceedings of the InternationalJoint Conference Artificial Intelligence(IJCAI-87), pages 118?124, Milan, Italy.Williams, Jason D. and Steve Young.
2007.Partially observable Markov decisionprocesses for spoken dialog systems.Computer Speech and Language,21(2):393?422.Winograd, Terry.
1972.
Understanding NaturalLanguage.
Academic Press, Orlando, FL.Wittgenstein, Ludwig.
1973.
PhilosophicalInvestigations.
Blackwell Publishers,Oxford, UK.486
