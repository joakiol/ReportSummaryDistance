Learning a Perceptron-Based Named Entity Chunkervia Online Recognition FeedbackXavier Carreras and Llu?
?s Ma`rquez and Llu?
?s Padro?TALP Research CenterDepartament de Llenguatges i Sistemes Informa`ticsUniversitat Polite`cnica de Catalunya{carreras,lluism,padro}@lsi.upc.es1 IntroductionWe present a novel approach for the problem of NamedEntity Recognition and Classification (NERC), in thecontext of the CoNLL-2003 Shared Task.Our work is framed into the learning and inferenceparadigm for recognizing structures in Natural Language(Punyakanok and Roth, 2001; Carreras et al, 2002).
Wemake use of several learned functions which, appliedat local contexts, discriminatively select optimal partialstructures.
On the top of this local recognition, an infer-ence layer explores the partial structures and builds theoptimal global structure for the problem.For the NERC problem, the structures to be recognizedare the named entity phrases (NE) of a sentence.
First, weapply learning at word level to identify NE candidates bymeans of a Begin-Inside classification.
Then, we makeuse of functions learned at phrase level ?one for eachNE category?
to discriminate among competing NEs.We propose a simple online learning algorithm fortraining all the involved functions together.
Each functionis modeled as a voted perceptron (Freund and Schapire,1999).
The learning strategy works online at sentencelevel.
When visiting a sentence, the functions beinglearned are first used to recognize the NE phrases, andthen updated according to the correctness of their solu-tion.
We analyze the dependencies among the involvedperceptrons and a global solution in order to design aglobal update rule based on the recognition of named-entities, which reflects to each individual perceptron itscommitted errors from a global perspective.The learning approach presented here is closely re-lated to ?and inspired by?
some recent works in the areaof NLP and Machine Learning.
Collins (2002) adaptedthe perceptron learning algorithm to tagging tasks, viasentence-based global feedback.
Crammer and Singer(2003) presented an online topic-ranking algorithm in-volving several perceptrons and ranking-based updaterules for training them.2 Named-Entity Phrase ChunkingIn this section we describe our NERC approach as aphrase chunking problem.
First we formalize the prob-lem of NERC, then we propose a NE-Chunker.2.1 Problem FormalizationLet x be a sentence belonging to the sentence space X ,formed by n words xi with i ranging from 0 to n?1.
LetK be the set of NE categories, which in the CoNLL-2003setting is K = {LOC, PER, ORG, MISC}.A NE phrase, denoted as (s, e)k, is a phrase spanningfrom word xs to word xe, having s ?
e, with categoryk ?
K. Let NE be the set of all potential NE phrases,expressed as NE = {(s, e)k | 0 ?
s ?
e, k ?
K} .We say that two different NE phrases ne1 = (s1, e1)k1and ne2 = (s2, e2)k2 overlap, denoted as ne1?ne2 iffe1 ?
s2 ?
e2 ?
s1.
A solution for the NERC problemis a set y formed by NE phrases that do not overlap, alsoknown as a chunking.
We define the set Y as the set of allpossible chunkings.
Formally, it can be expressed as:Y = {y ?
NE | ?ne1, ne2 ?
y ne16?ne2}The goal of the NE extraction problem is to identifythe correct solution y ?
Y for a given sentence x.2.2 NE-ChunkerThe NE-Chunker is a function which given a sentencex ?
X identifies the set of NE phrases y ?
Y:NEch : X ?
YThe NE-Chunker recognizes NE phrases in two lay-ers of processing.
In the first layer, a set of NE can-didates for a sentence is identified, out of all the po-tential phrases in NE .
To do so, we apply learning atword level in order to perform a Begin-Inside classifica-tion.
That is, we assume a function hB(w) which de-cides whether a word w begins a NE phrase or not, and afunction hI(w) which decides whether a word is inside aNE phrase or not.
Furthermore, we define the predicateBI?, which tests whether a certain phrase is formed bya starting begin word and subsequent inside words.
For-mally, BI?
((s, e)k) = (hB(s) ?
?i : s < i ?
e : hI(i)).The recognition will only consider solutions formed byphases in NE which satisfy the BI?
predicate.
Thus, thislayer is used to filter out candidates from NE and conse-quently reduce the size of the solution space Y .
Formally,the solution space that is explored can be expressed asYBI?
= {y ?
Y | ?ne?y BI?
(ne)}.The second layer selects the best coherent set of NEphrases by applying learning at phrase level.
We assumea number of scoring functions, which given a NE phraseproduce a real-valued score indicating the plausibility ofthe phrase.
In particular, for each category k ?
K we as-sume a function scorek which produces a positive score ifthe phrase is likely to belong to category k, and a negativescore otherwise.Given this, the NE-Chunker is a function whichsearches a NE chunking for a sentence x according tothe following optimality criterion:NEch(x) = arg maxy?YBI??
(s,e)k?yscorek(s, e)That is, among the considered chunkings of the sen-tence, the optimal one is defined to be the one whoseNE phrases maximize the summation of phrase scores.Practically, there is no need to explicitly enumerate eachpossible chunking in YBI?
.
Instead, by using dynamicprogramming the optimal chunking can be found inquadratic time over the sentence length, performing aViterby-style exploration from left to right (Punyakanokand Roth, 2001).Summarizing, the NE-Chunker recognizes the set ofNE phrases of a sentence as follows: First, NE candidatesare identified in linear time, applying a linear number ofdecisions.
Then, the optimal coherent set of NE phrasesis selected in quadratic time, applying a quadratic numberof decisions.3 Learning via Recognition FeedbackWe now present an online learning strategy for trainingthe learning components of the NE-Chunker, namely thefunctions hB and hI and the functions scorek, for k ?
K.Each function is implemented using a perceptron1 anda representation function.A perceptron is a linear discriminant function hw?
:Rn ?
R parametrized by a weight vector w?
in Rn.Given an instance x?
?
Rn, a perceptron outputs asprediction the inner product between vectors x?
and w?,hw?
(x) = w?
?
x?.1Actually, we use a variant of the model called the votedperceptron, explained below.The representation function ?
: X ?
Rn codifies aninstance x belonging to some space X into a vector inRnwith which the perceptron can operate.The functions hB and hI predict whether a word beginsor is inside a NE phrase, respectively.
Each one consistsof a perceptron weight vector, w?B and w?I, and a sharedrepresentation function ?w, explained in section 4.
Eachfunction is computed as hl = w?l ?
?w(x), for l ?
{B, I},and the sign is taken as the binary classification.The functions scorek, for k ?
K, compute a score fora phrase (s, e) being a NE phrase of category k. For eachfunction there is a vector w?k, and a shared representationfunction ?p, also explained in section 4.
The score isgiven by the expression scorek(s, e) = w?k ?
?p(s, e).3.1 Learning AlgorithmWe propose a mistake-driven online learning algorithmfor training the parameter vectors w?
of each perceptron allin one go.
The algorithm starts with all vectors initializedto 0?, and then runs repeatedly in a number of epochs Tthrough all the sentences in the training set.
Given a sen-tence, it predicts its optimal chunking as specified aboveusing the current vectors.
If the predicted chunking is notperfect the vectors which are responsible of the incorrectpredictions are updated additively.The sentence-based learning algorithm is as follows:?
Input: {(x1, y1), .
.
.
, (xm, ym)}.?
Define: W = {w?B, w?I} ?
{w?k|k ?
K}.?
Initialize: ?w?
?
W w?
= 0?;?
for t = 1 .
.
.
T , for i = 1 .
.
.m :1. y?
= NEchW (xi)2. learning feedback(W,xi, yi, y?)?
Output: the vectors in W .We now describe the learning feedback.
Let y?
be thegold set of NE phrases for a sentence x, and y?
the set pre-dicted by the NE-Chunker.
Let goldB(i) and goldI(i) berespectively the perfect indicator functions for the beginand inside classifications, that is, they return 1 if wordxi begins or is inside some phrase in y?
and 0 otherwise.We differentiate three kinds of phrases in order to givefeedback to the functions being learned:?
Phrases correctly identified: ?
(s, e)k ?
y?
?
y?:?
Do nothing, since they are correct.?
Missed phrases: ?
(s, e)k ?
y?
\ y?:1.
Update begin word, if misclassified:if (w?B ?
?w(xs) ?
0) thenw?B = w?B + ?w(xs)2.
Update misclassified inside words:?i : s < i ?
e : such that (w?I ?
?w(xi) ?
0)w?I = w?I + ?w(xi)3.
Update score function, if it has been applied:if (w?B ?
?w(xs) > 0 ?
?i : s < i ?
e : w?I ?
?w(xi) > 0) thenw?k = w?k + ?p(s, e)?
Over-predicted phrases: ?
(s, e)k ?
y?
\ y?:1.
Update score function:w?k = w?k ?
?p(s, e)2.
Update begin word, if misclassified :if (goldB(s) = 0) thenw?B = w?B ?
?w(xs)3.
Update misclassified inside words :?i : s < i ?
e : such that (goldI(i) = 0)w?I = w?I ?
?w(xi)This feedback models the interaction between the twolayers of the recognition process.
The Begin-Inside iden-tification filters out phrase candidates for the scoringlayer.
Thus, misclassifying words of a correct phraseblocks the generation of the candidate and produces amissed phrase.
Therefore, we move the begin or endprediction vectors toward the misclassified words of amissed phrase.
When an incorrect phrase is predicted,we move away the prediction vectors of the begin and in-side words, provided that they are not in the beginning orinside a phrase in the gold chunking.
Note that we delib-erately do not care about false positives begin or insidewords which do not finally over-produce a phrase.Regarding the scoring layer, each category predictionvector is moved toward missed phrases and moved awayfrom over-predicted phrases.3.2 Voted Perceptron and KernelizationAlthough the analysis above concerns the perceptron al-gorithm, we use a modified version, the voted perceptronalgorithm, introduced in (Freund and Schapire, 1999).The key point of the voted version is that, while train-ing, it stores information in order to make better predic-tions on test data.
Specifically, all the prediction vec-tors w?j generated after every mistake are stored, togetherwith a weight cj , which corresponds to the number ofdecisions the vector w?j survives until the next mistake.Let J be the number of vector that a perceptron accumu-lates.
The final hypothesis is an averaged vote over thepredictions of each vector, computed with the expressionhw?(x?)
=?Jj=1 cj(w?j ?
x?)
.Moreover, we work with the dual formulation of thevectors, which allows the use of kernel functions.
It isshown in (Freund and Schapire, 1999) that a vector w canbe expressed as the sum of instances xj that were added(sxj = +1) or subtracted (sxj = ?1) in order to create it,as w =?Jj=1 sxjxj.
Given a kernel function K(x, x?
),the final expression of a dual voted perceptron becomes:hw?(x?)
=J?j=1cjj?l=1sxlK(x?l, x?
)In this paper we work with polynomial kernelsK(x, x?)
= (x ?
x?
+ 1)d, where d is the degree of thekernel.4 Feature-Vector RepresentationIn this section we describe the representation functions?w and ?p, which respectively map a word or a phraseand their local context into a feature vector in Rn, partic-ularly, {0, 1}n. First, we define a set of predicates whichare computed on words and return one or more values:?
Form(w), PoS(w): The form and PoS of word w.?
Orthographic(w): Binary flags of word w with re-gard to how is it capitalized (initial-caps, all-caps),the kind of characters that form the word (contains-digits, all-digits, alphanumeric, Roman-number),the presence of punctuation marks (contains-dots, contains-hyphen, acronym), single characterpatterns (lonely-initial, punctuation-mark, single-char), or the membership of the word to a predefinedclass (functional-word2), or pattern (URL).?
Affixes(w): The prefixes and suffixes of the word w(up to 4 characters).?
Word Type Patterns(ws .
.
.
we): Type pattern ofconsecutive words ws .
.
.
we.
The type of a wordis either functional (f), capitalized (C), lowercased(l), punctuation mark (.
), quote (?)
or other (x).For instance, the word type pattern for the phrase?John Smith payed 3 euros?
would be CClxl.For the function ?w(xi) we compute the predicates ina window of words around xi, that is, words xi+l withl ?
[?Lw,+Lw].
Each predicate label, together witheach relative position l and each returned value forms afinal binary indicator feature.
The word type patterns areevaluated in all sequences within the window which in-clude the central word i.For the function ?p(s, e) we represent the context ofthe phrase by evaluating a [?Lp, 0] window of predicatesat the s word and a separate [0,+Lp] window at the eword.
At the s window, we also codify the named enti-ties already recognized at the left context, capturing theircategory and relative position.
Furthermore, we representthe (s, e) phrase by evaluating the predicates without cap-turing the relative position in the features.
In particular,2Functional words are determiners and prepositions whichtypically appear inside NEs.for the words within (s, e) we evaluate the form, affixesand type patterns of sizes 2, 3 and 4.
We also evaluate thecomplete concatenated form of the phrase and the wordtype pattern spanning the whole phrase.
Finally, we makeuse of a gazetteer to capture possible NE categories of thewhole NE form and each single word within it.5 Experiments and ResultsA list of functional words was automatically extractedfrom each language training set, selecting those lower-cased words within NEs appearing 3 times or more.
Foreach language, we also constructed a gazetteer with theNEs in the training set.
When training, only a random40% of the entries was considered.We performed parameter tuning on the English lan-guage.
Concerning the features, we set the window sizes(Lw and Lp) to 3 (we tested 2 and 3) , and we did not con-sidered features occurring less than 5 times in the data.When moving to German, we found better to work withlemmas instead of word forms.Concerning the learning algorithm, we evaluated ker-nel degrees from 1 to 5.
Degrees 2 and 3 performed some-what better than others, and we chose degree 2.
We thenran the algorithm through the English training set for upto five epochs, and through the German training set for upto 3 epochs.
3 On both languages, the performance wasstill slightly increasing while visiting more training sen-tences.
Unfortunately, we were not able to run the algo-rithm until performance was stable.
Table 1 summarizesthe obtained results on all sets.
Clearly, the NERC taskon English is much easier than on German.
Figures indi-cate that the moderate performance on German is mainlycaused by the low recall, specially for ORG and MISC en-tities.
It is interesting to note that while in English theperformance is much better on the development set, inGerman we achieve better results on the test set.
Thisseems to indicate that the difference in performance be-tween development and test sets is due to irregularitiesin the NEs that appear in each set, rather than overfittingproblems of our learning strategy.The general performance of phrase recognition systemwe present is fairly good, and we think it is competitivewith state-of-the-art named entity extraction systems.AcknowledgmentsThis research has been partially funded by the EuropeanCommission (Meaning, IST-2001-34460) and the Span-ish Research Dept.
(Hermes, TIC2000-0335-C03-02; Pe-tra - TIC2000-1735-C02-02).
Xavier Carreras holds agrant by the Catalan Government Research Department.3Implemented in PERL and run on a Pentium IV (Linux,2.5GHz, 512Mb) it took about 120 hours for English and 70hours for German.English devel.
Precision Recall F?=1LOC 90.77% 93.63% 92.18MISC 91.98% 80.80% 86.03ORG 86.02% 83.52% 84.75PER 91.37% 90.77% 91.07Overall 90.06% 88.47% 89.26English test Precision Recall F?=1LOC 86.66% 89.15% 87.88MISC 84.90% 72.08% 77.97ORG 82.73% 77.60% 80.09PER 88.25% 86.39% 87.31Overall 85.81% 82.84% 84.30German devel.
Precision Recall F?=1LOC 75.21% 67.32% 71.05MISC 76.90% 42.18% 54.48ORG 76.80% 47.22% 58.48PER 76.87% 60.96% 67.99Overall 76.36% 55.06% 63.98German test Precision Recall F?=1LOC 72.89% 65.22% 68.84MISC 67.14% 42.09% 51.74ORG 77.67% 42.30% 54.77PER 87.23% 70.88% 78.21Overall 77.83% 58.02% 66.48Table 1: Results obtained for the development and thetest data sets for the English and German languages.ReferencesX.
Carreras, L. Ma`rquez, V. Punyakanok, and D. Roth.2002.
Learning and Inference for Clause Identifica-tion.
In Proceedings of the 14th European Conferenceon Machine Learning, ECML, Helsinki, Finland.M.
Collins.
2002.
Discriminative Training Meth-ods for Hidden Markov Models: Theory and Experi-ments Perceptron Algorithms.
In Proceedings of theEMNLP?02.K.
Crammer and Y.
Singer.
2003.
A Family of AdditiveOnline Algorithms for Category Ranking.
Journal ofMachine Learning Research, 3:1025?1058.Y.
Freund and R. E. Schapire.
1999.
Large Margin Clas-sification Using the Perceptron Algorithm.
MachineLearning, 37(3):277?296.V.
Punyakanok and D. Roth.
2001.
The Use of Clas-sifiers in Sequential Inference.
In Proceedings of theNIPS-13.
