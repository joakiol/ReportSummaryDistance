Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 356?365,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsUnsupervised discovery of negative categories in lexicon bootstrappingTara McIntoshNICTA Victoria Research LabDept of Computer Science and Software EngineeringUniversity of Melbournenlp@taramcintosh.orgAbstractMulti-category bootstrapping algorithms weredeveloped to reduce semantic drift.
By ex-tracting multiple semantic lexicons simultane-ously, a category?s search space may be re-stricted.
The best results have been achievedthrough reliance on manually crafted negativecategories.
Unfortunately, identifying thesecategories is non-trivial, and their use shiftsthe unsupervised bootstrapping paradigm to-wards a supervised framework.We present NEG-FINDER, the first approachfor discovering negative categories automat-ically.
NEG-FINDER exploits unsupervisedterm clustering to generate multiple nega-tive categories during bootstrapping.
Our al-gorithm effectively removes the necessity ofmanual intervention and formulation of nega-tive categories, with performance closely ap-proaching that obtained using negative cate-gories defined by a domain expert.1 IntroductionAutomatically acquiring semantic lexicons from textis essential for overcoming the knowledge bottle-neck in many NLP tasks, e.g.
question answer-ing (Ravichandran and Hovy, 2002).
Many of thesuccessful methods follow the unsupervised itera-tive bootstrapping framework (Riloff and Shepherd,1997).
Bootstrapping has since been effectively ap-plied to extracting general semantic lexicons (Riloffand Jones, 1999), biomedical entities (Yu andAgichtein, 2003) and facts (Carlson et al, 2010).Bootstrapping is often considered to be minimallysupervised, as it is initialised with a small set of seedterms of the target category to extract.
These seedsare used to identify patterns that can match the tar-get category, which in turn can extract new lexiconterms (Riloff and Jones, 1999).
Unfortunately, se-mantic drift often occurs when ambiguous or erro-neous terms and/or patterns are introduced into theiterative process (Curran et al, 2007).In multi-category bootstrapping, semantic drift isoften reduced when the target categories competewith each other for terms and/or patterns (Yangarberet al, 2002).
This process is most effective whenthe categories bound each other?s search space.
Toensure this, manually crafted negative categories areintroduced (Lin et al, 2003; Curran et al, 2007).Unfortunately, this makes these algorithms substan-tially more supervised.The design of negative categories is a very timeconsuming task.
It typically requires a domain ex-pert to identify the semantic drift and its cause, fol-lowed by a significant amount of trial and error in or-der to select the most suitable combination of nega-tive categories.
This introduces a substantial amountof supervised information into what was an unsuper-vised framework, and in turn negates one of the mainadvantages of bootstrapping ?
the quick construc-tion of accurate semantic lexicons.We show that although excellent performance isachieved using negative categories, it varies greatlydepending on the negative categories selected.
Thishighlights the difficulty of crafting negative cate-gories and thus the necessity for tools that can au-tomatically identify them.Our second contribution is the first fully unsu-pervised approach, NEG-FINDER, for discovering356negative categories automatically.
During boot-strapping, efficient clustering techniques are appliedto sets of drifted candidate terms to generate newnegative categories.
Once a negative category isidentified it is incorporated into the subsequent it-erations whereby it provides the necessary semanticboundaries for the target categories.We demonstrate the effectiveness of our ap-proach for extracting biomedical semantic lexiconsby incorporating NEG-FINDER within the WMEB-DRIFT bootstrapping algorithm (McIntosh and Cur-ran, 2009).
NEG-FINDER significantly outperformsbootstrapping prior to the domain expert?s negativecategories.
We show that by using our discoveredcategories we can reach near expert-guided perfor-mance.
Our methods effectively remove the neces-sity of manual intervention and formulation of neg-ative categories in semantic lexicon bootstrapping.2 BackgroundVarious automated pattern-based bootstrapping al-gorithms have been proposed to iteratively build se-mantic lexicons.
In multi-level bootstrapping, a lex-icon is iteratively expanded from a small sample ofseed terms (Riloff and Jones, 1999).
The seed termsare used to identify contextual patterns they appearin, which in turn may be used to extract new lexi-con entries.
This process is repeated with the newexpanded lexicon identifying new patterns.When bootstrapping semantic lexicons, polyse-mous or erroneous terms and/or patterns that weaklyconstrain the semantic class are eventually extracted.This often causes semantic drift ?
when a lexicon?sintended meaning shifts into another category dur-ing bootstrapping (Curran et al, 2007).
For exam-ple, female names may drift into gemstones whenthe terms Ruby and Pearl are extracted.Multi-category bootstrapping algorithms, such asBASILISK (Thelen and Riloff, 2002), NOMEN (Yan-garber et al, 2002), and WMEB (McIntosh andCurran, 2008), aim to reduce semantic drift byextracting multiple semantic categories simultane-ously.
These algorithms utilise information aboutother semantic categories in order to reduce the cate-gories from drifting towards each other.
This frame-work has recently been extended to extract differentrelations from text (Carlson et al, 2010).2.1 Weighted MEBIn Weighted Mutual Exclusion Bootstrapping(WMEB, McIntosh and Curran, 2008), multiple se-mantic categories iterate simultaneously betweenthe term and pattern extraction phases, competingwith each other for terms and patterns.
Semanticdrift is reduced by forcing the categories to be mu-tually exclusive.
That is, candidate terms can onlybe extracted by a single category and patterns canonly extract terms for a single category.In WMEB, multiple bootstrapping instances areinitiated for each competing target category.
Eachcategory?s seed set forms its initial lexicon.
Foreach term in the category lexicon, WMEB identifiesall candidate contextual patterns that can match theterm in the text.
To ensure mutual exclusion betweenthe categories, candidate patterns that are identifiedby multiple categories in an iteration are excluded.The remaining patterns are then ranked according tothe reliability measure and relevance weight.The reliability of a pattern for a given categoryis the number of extracted terms in the category?slexicon that match the pattern.
A pattern?s relevanceweight is defined as the sum of the ?-squared valuesbetween the pattern (p) and each of the lexicon terms(t): weight(p) =?t?T ?2(p, t).
These metrics aresymmetrical for both candidate terms and patterns.The top-m patterns are then added to the pool ofextracting patterns.
If each of the top-m patterns al-ready exists in the pool, the next unseen pattern isadded to the pool.
This ensures at least one new pat-tern is added to the pool in each iteration.In the term selection phase, all patterns within thepattern pool are used to identify candidate terms.Like the candidate patterns, terms that are extractedby multiple categories in the same iteration are alsoexcluded.
The remaining candidate terms are rankedwith respect to their reliability and relevance weight,and the top-n terms are added to the lexicon.2.2 Detecting semantic drift in WMEBIn McIntosh and Curran (2009), we showed thatmulti-category bootstrappers are still prone to se-mantic drift in the later iterations.
We proposed adrift detection metric based on our hypothesis thatsemantic drift occurs when a candidate term is moresimilar to the recently added terms than to the seed357and high precision terms extracted in the earlieriterations.
Our metric is based on distributional sim-ilarity measurements and can be directly incorpo-rated into WMEB?s term selection phase to preventdrifting terms from being extracted (WMEB-DRIFT).The drift metric is defined as the ratio of the aver-age distributional similarity of the candidate term tothe first n terms extracted into the lexicon L, and tothe last m terms extracted in the previous iterations:drift(term, n,m) =avgsim(L1...n, term)avgsim(L(N?m+1)...N , term)(1)2.3 Negative categoriesIn multi-category bootstrapping, improvements inprecision arise when semantic boundaries betweenmultiple target categories are established.
Thus, it isbeneficial to bootstrap categories that share similarsemantic spaces, such as female names and flowers.Unfortunately, it is difficult to predict if a tar-get category will suffer from semantic drift and/orwhether it will naturally compete with the other tar-get categories.
Once a domain expert establishessemantic drift and its possible cause, a set of neg-ative/stop categories that may be of no direct inter-est are manually crafted to prevent semantic drift.These additional categories are then exploited dur-ing another round of bootstrapping to provide fur-ther competition for the target categories (Lin et al,2003; Curran et al, 2007).Lin et al (2003) improved NOMEN?s perfor-mance for extracting diseases and locations fromthe ProMED corpus by incorporating negative cat-egories into the bootstrapping process.
They firstused one general negative category, seeded with the10 most frequent nouns in the corpus that were un-related to the target categories.
This single nega-tive category resulted in substantial improvements inprecision.
In their final experiment, six negative cat-egories that were notable sources of semantic driftwere identified, and the inclusion of these lead tofurther performance improvements (?20%).In similar experiments, both Curran et al (2007)and McIntosh (2010) manually crafted negativecategories that were necessary to prevent semanticdrift.
In particular, in McIntosh (2010), a biomedicalexpert spent considerable time (?15 days) and effortInitial LexiconDrift CacheClustered Terms Negative LexiconFigure 1: NEG-FINDER: Local negative discoveryidentifying potential negative categories and subse-quently optimising their associated seeds in trial anderror bootstrapping runs.By introducing manually crafted negative cate-gories, a significant amount of expert domain knowl-edge is introduced.
The use of this expert knowl-edge undermines the principle advantages of un-supervised bootstrapping, by making it difficult tobootstrap lexicons for a large number of categoriesacross diverse domains or languages.
In this pa-per, we aim to push multi-category bootstrappingback into its original minimally-supervised frame-work, with as little performance loss as possible.3 NEG-FINDEROur approach, Negative Category Finder for Boot-strapping (NEG-FINDER), can be easily incorporatedinto bootstrapping algorithms that exclude candidateterms or facts based on a selection criteria, includ-ing WMEB-DRIFT and Pas?ca et al?s (2006) large-scale fact extraction system.
For simplicity, we de-scribe our approach within the WMEB-DRIFT boot-strapping algorithm.
Figure 1 shows the frameworkof our approach.To discover negative categories during bootstrap-ping, NEG-FINDER must identify a representativecluster of the drifted terms.
In this section, wepresent the two types of clustering used (maximumand outlier), and our three different levels of nega-tive discovery (local, global and mixture).3.1 Discovering negative categoriesWe have observed that semantic drift begins to dom-inate when clusters of incorrect terms with similar358meanings are extracted.
In the term selection phaseof WMEB-DRIFT, the top-n candidate terms that sat-isfy the drift detection threshold are added to the ex-panding lexicon.
Those terms which are consideredbut do not meet the threshold are excluded.In NEG-FINDER, these drifted terms are cached asthey may provide adequate seed terms for new neg-ative categories.
However, the drifted terms can alsoinclude scattered polysemous or correct terms thatshare little similarity with the other drifted terms.Therefore, simply using the first set of drifted termsto establish a negative category is likely to introducenoise rather than a cohesive competing category.To discover negative categories, we exploit hi-erarchical clustering to group similar terms withinthe cache of drifted terms.
In agglomerative hi-erarchical clustering, a single term is assigned toan individual cluster, and these clusters are itera-tively merged until a final cluster is formed contain-ing all terms (Kaufmann and Rousseeuw, 1990).
Inour approach, the similarity between two clusters iscomputed as the average distributional similarity be-tween all pairs of terms across the clusters (average-link clustering).For calculating the similarity between two termswe use the distributional similarity approach de-scribed in Curran (2004).
We extracted window-based features from the set of candidate patterns toform context vectors for each term.
We use thestandard t-test weight and weighted Jaccard measurefunctions (Curran, 2004).To ensure adequate coverage of the possible drift-ing topics, negative discovery and hence clusteringis only performed when the drift cache consists of atleast 20 terms.3.2 Maximum and outlier clusteringAlthough hierarchical clustering is quadratic, we canefficiently exploit the agglomerative process as themost similar terms will merge into clusters first.Therefore, to identify the k most similar terms, wecan exit the clustering process as soon as a clusterof size k is established.
We refer to this approach asmaximum clustering.In our next clustering method, we aim to form anegative category with as little similarity to the tar-get seeds.
We use an outlier clustering strategy, inwhich the drifted term t with the least average distri-butional similarity to the first n terms in the lexiconmust be contained in the cluster of seeds.
We useaverage similarity to the first n terms, as it is alreadypre-computed for the drift detection metric.
As withmaximum clustering, once a cluster of size k con-taining the term t is formed, the clustering processcan be terminated.3.3 Incorporating the negative categoryAfter a cluster of negative seed terms is established,the drift cache is cleared, and a new negative cate-gory is created and introduced into the iterative boot-strapping process in the next iteration.
This meansthat the negative category can only influence thesubsequent iterations of bootstrapping.
The nega-tive categories can compete with all other categories,including any previously introduced negative cate-gories, however the negative categories do not con-tribute to the drift caches.Before the new category is introduced, its firstset of extracting patterns must be identified.
Forthis, the complete set of extracting patterns match-ing any of the negative seeds are considered andranked with respect to the seeds.
The top scoringpatterns are considered sequentially until m patternsare assigned to the new negative category.
To ensuremutual exclusion between the new category and thetarget categories, a candidate pattern that has previ-ously been selected by a target category cannot beused to extract terms for either category in the sub-sequent iterations.3.4 Levels of negative discoveryNegative category discovery can be performed at alocal or global level, or as a mixture of both.
In localdiscovery, each target category has its own driftedterm cache and can generate negative categories ir-respective of the other target categories.
This isshown in Figure 1.
The drifted terms (shaded) areextracted away from the lexicon into the local driftcache, which is then clustered.
A cluster is then usedto initiate a negative category?s lexicon.
Target cate-gories can also generate multiple negative categoriesacross different iterations.In global discovery, all drifted terms are pooledinto a global cache, from which a single negativecategory can be identified in an iteration.
This isbased on our intuition that multiple target categories359TYPE MEDLINENo.
Terms 1 347 002No.
Patterns 4 090 412No.
5-grams 72 796 760No.
Unfiltered tokens 6 642 802 776Table 1: Filtered 5-gram dataset statistics.may be drifting into similar semantic categories, andenables these otherwise missed negative categoriesto be established.In the mixture discovery method, both global andlocal negative categories can be formed.
A cate-gory?s drifted terms are collected into its local cacheas well as the global cache.
Negative discovery isthen performed on each cache when they contain atleast 20 terms.
Once a local negative category isformed, the terms within the local cache are clearedand also removed from the global cache.
This pre-vents multiple negative categories being instantiatedwith overlapping seed terms.4 Experimental setupTo compare the effectiveness of our negative discov-ery approaches we consider the task of extractingbiomedical semantic lexicons from raw text.4.1 DataThe algorithms take as input a set of candidate termsto be extracted into semantic lexicons.
The sourcetext collection consists of 5-grams (t1, t2, t3, t4, t5)from approximately 16 million MEDLINE abstracts.1The set of possible candidate terms correspond tothe middle tokens (t3), and the possible patterns areformed from the surrounding tokens (t1, t2, t4, t5).We do not use syntactic knowledge, as we did notwish to rely on any tools that require supervisedtraining, to ensure our technique is as domain andlanguage independent as possible.Limited preprocessing was required to extract the5-grams from MEDLINE.
The XML markup wasremoved, and the collection was tokenised and splitinto sentences using bio-specific NLP tools (Groveret al, 2006).
Filtering was applied to remove infre-quent patterns and terms ?
patterns appearing withless than 7 different terms, and terms only appearing1The set contains all MEDLINE titles and abstracts availableup to Oct 2007.CAT DESCRIPTIONANTI Antibodies: MAb IgG IgM rituximab infliximab(?1:0.89, ?2:1.0)CELL Cells: RBC HUVEC BAEC VSMC SMC (?1:0.91,?2:1.0)CLNE Cell lines: PC12 CHO HeLa Jurkat COS (?1:0.93,?2: 1.0)DISE Diseases: asthma hepatitis tuberculosis HIV malaria(?1:0.98, ?2:1.0)DRUG Drugs: acetylcholine carbachol heparin penicillintetracyclin (?1:0.86, ?2:0.99)FUNC Molecular functions and processes: kinase ligaseacetyltransferase helicase binding (?1:0.87, ?2:0.99)MUTN Protein and gene mutations: Leiden C677T C282Y35delG null (?1:0.89, ?2:1.0)PROT Proteins and genes: p53 actin collagen albumin IL-6(?1:0.99, ?2:1.0)SIGN Signs and symptoms: anemia fever hypertensionhyperglycemia cough (?1:0.96, ?2:0.99)TUMR Tumors: lymphoma sarcoma melanoma osteosarcomaneuroblastoma (?1:0.89, ?2:0.95)Table 2: The MEDLINE semantic categorieswith those patterns were removed.
The statistics ofthe resulting dataset are shown in Table 1.4.2 Semantic categoriesThe semantic categories we extract from MEDLINEwere inspired by the TREC Genomics entities (Hershet al, 2007) and are described in detail in McIntosh(2010).
The hand-picked seeds selected by a domainexpert for each category are shown in italics in Table2.
These were carefully chosen to be as unambigu-ous as possible with respect to the other categories.4.3 Negative categoriesIn our experiments, we use two different sets of neg-ative categories.
These are shown in Table 3.
Thefirst set corresponds to those used in McIntosh andCurran (2008), and were identified by a domain ex-pert as common sources of semantic drift in prelimi-nary experiments with MEB and WMEB.
The AMINOACID category was created in order to filter commonMUTN errors.
The ANIMAL and BODY PART cate-gories were formed with the intention of preventingdrift in the CELL, DISE and SIGN categories.
TheORGANISM category was then created to reduce thenew drift forming in the DISE category after the firstset of negative categories were introduced.The second set of negative categories was identi-fied by an independent domain expert with limited360CATEGORY SEED TERMS1 AMINO ACID arginine cysteine glycine glutamate histamineANIMAL insect mammal mice mouse ratsBODY PART breast eye liver muscle spleenORGANISM Bartonella Borrelia CryptosporidiumSalmonella toxoplasma2 AMINO ACID Asn Gly His Leu ValineANIMAL animals dogs larvae rabbits rodentsORGANISM Canidia Shigella Scedosporium SalmonellaYersiniaGENERIC decrease effects events increase responseMODIFIERS acute deep intrauterine postoperativesecondaryPEOPLE children females men subjects womenSAMPLE biopsies CFU sample specimens tissuesTable 3: Manually crafted negative categoriesknowledge of NLP and bootstrapping.
This expertidentified three similar categories to the first expert,however their seeds are very different.
They alsoidentified three more categories than the first.4.4 Lexicon evaluationOur evaluation process follows that of McIntoshand Curran (2009) and involved manually inspect-ing each extracted term and judging whether it wasa member of the semantic class.
This manual eval-uation was performed by two domain experts and isnecessary due to the limited coverage of biomedicalresources.
Inter-annotator agreement scores are pro-vided in Table 2.2 To make later evaluations moreefficient, all evaluators?
decisions for each categoryare cached.Unfamiliar terms were checked using online re-sources including MEDLINE, MeSH, and Wikipedia.Each ambiguous term was counted as correct if itwas classified into one of its correct categories, suchas lymphoma, which is a TUMR and DISE.
If a termwas unambiguously part of a multi-word term weconsidered it correct.
Abbreviations, acronyms, andobvious misspelled words were included.For comparing the performance of the algorithms,the average precision for the top-1000 terms over the10 target categories is measured.
To identify whensemantic drift has a significant impact, we report theprecision of specific sections of the lexicon, e.g.
the801-1000 sample corresponds to the last 200 terms.2All disagreements were discussed, and the kappa scores ?1and ?2 are those before and after the discussions, respectively.1-500 1-1000WMEB-DRIFT 74.3 68.6+negative 1 87.7 82.8+negative 2 83.8 77.8Table 4: Influence of negative categories4.5 System settingsAll experiments were performed using the 10 tar-get categories as input.
Unless otherwise stated, nohand-picked negative categories are used.Each target category is initialised with the 5 hand-picked seed terms (Table 2).
In each iteration a max-imum of 5 lexicon terms and 5 new patterns canbe extracted by a category.
The bootstrapping al-gorithms are run for 200 iterations.The drift detection metric is calculated over thefirst 100 terms and previous 5 terms extracted intothe lexicon, and the filter threshold is set to 0.2, asin McIntosh and Curran (2009).
To ensure infre-quent terms are not used to seed negative categories,drifted terms must occur at least 50 times to be re-tained in the drift cache.
Negative category discov-ery is only initiated when the drifted cache containsat least 20 terms, and a minimum of 5 terms are usedto seed a negative category.4.6 Random seed experimentsBoth McIntosh and Curran (2009) and Pantel etal.
(2009) have shown that a bootstrapper?s per-formance can vary greatly depending on the inputseeds.
To ensure our methods are compared reliably,we also report the average precision of randomisedseed experiments.
Each algorithm is instantiated 10times with different random gold seeds for each tar-get category.
These gold seeds are randomly sam-pled from the evaluation cache formed in McIntoshand Curran (2009).5 Results5.1 Influence of negative categoriesIn our first experiments, we investigate the per-formance variations and improvements gained us-ing negative categories selected by two indepen-dent domain experts.
Table 4 shows WMEB-DRIFT?saverage precision over the 10 target categories withand without the two negative category sets.
Both3611-200 201-400 401-600 601-800 801-1000 1-1000WMEB-DRIFT 79.5 74.8 64.7 61.9 62.1 68.6NEG-FINDERFirst discovered 79.5 74.3 64.8 67.8 66.6 70.7Local discovery+maximum 79.5 74.8 67.3 69.3 70.5 72.2+outlier 79.5 73.9 64.8 67.8 71.0 71.5Global discovery+maximum 79.5 73.9 65.7 73.2 72.7 73.4+outlier 79.5 74.7 65.6 71.4 68.2 72.1Mixture discovery+maximum 79.5 74.7 69.3 73.3 72.8 74.0+outlier 79.5 75.2 69.7 72.0 69.4 73.2Table 5: Performance comparison of WMEB-DRIFT and NEG-FINDERsets significantly improve WMEB-DRIFT, howeverthere is a significant performance difference be-tween them.
This demonstrates the difficulty of se-lecting appropriate negative categories and seeds forthe task, and in turn the necessity for tools to dis-cover them automatically.5.2 Negative category discoveryTable 5 compares the performance of NEG-FINDERincorporated with WMEB-DRIFT.
Each method hasequal average precision over the first 200 terms, assemantic drift does not typically occur in the earlyiterations.
Each discovery method significantly out-performs WMEB-DRIFT in the later stages, and overthe top 1000 terms.3The first discovery approach corresponds to thena?
?ve NEG-FINDER system that generates local neg-ative categories from the first five drifted terms.
Al-though it outperforms WMEB-DRIFT, its advantageis smaller than the clustering methods.The outlier clustering approach, which we pre-dicted to be the most effective, was surprisingly lessaccurate than the maximum approach for selectingnegative seeds.
This is because the seed clusterformed around the outlier term is not guaranteed tohave high pair-wise similarity and thus it may repre-sent multiple semantic categories.Local discovery was the least effective discov-ery approach.
Compared to local discovery, globaldiscovery is capable of detecting new negative cate-gories earlier, and the categories it detects are more3Statistical significance was tested using computationally-intensive randomisation tests (Cohen, 1995).CATEGORY NEGATIVE SEEDSCELL-NEG animals After Lambs Pigs RabbitsTUMR-NEG inoperable multinodular nonresectableoperated unrupturedGLOBAL days Hz mM post TorrGLOBAL aortas eyes legs mucosa retinasGLOBAL men offspring parents persons relativesGLOBAL Australian Belgian Dutch European ItalianGLOBAL Amblyospora Branhamella PhormodiumPseudanabaena RhodotorulaTable 6: Negative categories from mixture discoverylikely to compete with multiple target categories.The NEG-FINDER mixture approach, which ben-efits from both local and global discovery, identi-fies the most useful negative categories.
Table 6shows the seven discovered categories ?
two lo-cal negative categories from CELL and TUMOUR,and five global categories were formed.
Many ofthese categories are similar to those identified bythe domain experts.
For example, clear categoriesfor ANIMAL, BODY PART, PEOPLE and ORGANISMare created.
By identifying and then including thesenegative categories, NEG-FINDER significantly out-performs WMEB-DRIFT by 5.4% over the top-1000terms and by 10.7% over the last 200 terms, wheresemantic drift is prominent.
These results demon-strate that suitable negative categories can be identi-fied and exploited during bootstrapping.5.3 Boosting hand-picked negative categoriesIn our next set of experiments, we investigatewhether NEG-FINDER can improve state-of-the-art performance by identifying new negative cate-gories in addition to the manually selected negative3621-200 201-400 401-600 601-800 801-1000 1-1000WMEB-DRIFT+negative 1 90.5 87.3 82.0 74.6 79.8 82.8+negative 2 87.8 82.2 78.7 76.1 63.3 77.8WMEB-DRIFT+restart +local 85.5 82.6 76.5 75.7 68.5 78.4+restart +global 84.0 83.8 79.1 74.8 69.5 79.7+restart +mixture 85.2 85.0 82.3 72.5 72.7 81.4Table 7: Performance of WMEB-DRIFT using negative categories discovered by NEG-FINDER601-800 801-1000 1-1000WMEB-DRIFT+negative 1 74.6 79.8 82.8NEG-FINDER+negative 1 +local 76.4 80.1 83.2+negative 1 +global 77.5 76.0 82.7+negative 1 +mixture 76.7 79.9 83.2Table 8: Performance of NEG-FINDER with manuallycrafted negative categoriescategories.
Both NEG-FINDER and WMEB-DRIFTare initialised with the 10 target categories and thefirst set of negative categories.Table 8 compares our best performing systems(NEG-FINDER maximum clustering) with standardWMEB-DRIFT, over the last 400 terms where seman-tic drift dominates.
NEG-FINDER effectively dis-covers additional categories and significantly out-performs WMEB-DRIFT.
This further demonstratesthe utility of our approach.5.4 Restarting with new negative categoriesThe performance improvements so far using NEG-FINDER have been limited by the time at which newnegative categories are discovered and incorporatedinto the bootstrapping process.
That is, system im-provements can only be gained from the negativecategories after they are generated.
For example,in Local NEG-FINDER, five negative categories arediscovered in iterations 83, 85, 126, 130 and 150.On the other hand, in the WMEB-DRIFT +negativeexperiments (Table 8 row 2), the hand-picked neg-ative categories can start competing with the targetcategories in the very first iteration of bootstrapping.To test the full utility of NEG-FINDER, we use theset of discovered categories as competing input forWMEB-DRIFT.
Table 7 shows the average precisionof WMEB-DRIFT over the 10 target categories whenit is restarted with the new negative categories dis-covered from our three approaches (using maximumclustering).
Over the first 200 terms, significant im-provements are gained using the new negative cate-gories (+6%).
However, the manually selected cat-egories are far superior in preventing drift (+11%).This may be attributed by the target categories notstrongly drifting into the new negative categories un-til the later stages, whereas the hand-picked cate-gories were selected on the basis of observed driftin the early stages (over the first 500 terms).Each NEG-FINDER approach significantly outper-forms WMEB-DRIFT with no negative categories.For example, using the NEG-FINDER mixture cat-egories increases precision by 12.8%.
These ap-proaches also outperform their corresponding inlinediscovery methods (e.g.
+7.4% with mixture discov-ery ?
Table 5).Table 7 shows that each of the discovered neg-ative sets can significantly outperform the negativecategories selected by a domain expert (negative set2) (+0.6 ?
3.9%).
Our best system?s performance(mixture: 81.4%) closely approaches that of the su-perior negative set, trailing by only 1.4%.5.5 Individual categoriesIn this section, we analyse the effect of NEG-FINDERon the individual target categories.
Table 9 showsthe average precision of the lexicons for some tar-get categories.
All categories, except TUMOUR, im-prove significantly with the inclusion of the discov-ered negative categories.
In particular, the CELLand SIGN categories, which are affected severely bysemantic drift, increase by up to 33.3% and 45.2%,respectively.
The discovered negative categoriesare more effective than the manually crafted sets inreducing semantic drift in the ANTIBODY, CELL andDISEASE lexicons.363ANTI CELL DISE SIGN TUMRWMEB-DRIFT 92.9 47.8 49.3 27.9 39.5+negative 1 91.6 73.1 87.8 76.5 48.7+negative 2 85.8 68.0 84.2 71.3 16.3NEG-FINDER+mixture 94.9 73.9 56.0 41.0 42.2+mixture +negative 1 90.8 77.2 87.8 78.2 48.2WMEB-DRIFT+restart +local 89.9 78.8 71.6 73.1 32.2+restart +global 94.6 79.0 81.9 62.6 35.2+restart +mixture 92.6 81.1 91.1 63.6 47.5Table 9: Individual category results (1-1000 terms)5.6 Random seed experimentsIn Table 10, we report the results of our randomisedexperiments.
Over the last 200 terms, WMEB-DRIFTwith the first set of negative categories (row 2) is out-performed by NEG-FINDER (row 4).
NEG-FINDERalso significantly boosts the performance of the orig-inal negative categories by identifying additionalnegative categories (row 5).
Our final experiment,where WMEB-DRIFT is re-initialised with the nega-tive categories discovered by NEG-FINDER, furtherdemonstrates the utility of our method.
On average,the discovered negative categories significantly out-perform the manually crafted negative categories.6 ConclusionIn this paper, we have proposed the first completelyunsupervised approach to identifying the negativecategories that are necessary for bootstrapping largeyet precise semantic lexicons.
Prior to this work,negative categories were manually crafted by a do-main expert, undermining the advantages of an un-supervised bootstrapping paradigm.There are numerous avenues for further examina-tion.
We intend to use sophisticated clustering meth-ods, such as CBC (Pantel, 2003), to identify multiplenegative categories across the target categories in asingle iteration.
We would also like to explore thesuitability of NEG-FINDER for relation extraction.Our initial analysis demonstrated that althoughexcellent performance is achieved using negativecategories, large performance variations occur whenusing categories crafted by different domain experts.In NEG-FINDER, unsupervised clustering ap-proaches are exploited to automatically discover401-600 801-1000WMEB-DRIFT 66.9 58.5+negative 1 73.1 61.7NEG-FINDER+mixture 71.9 64.2+mixture +negative 1 76.1 66.7WMEB-DRIFT+restart +mixture 78.0 70.8Table 10: Random seed resultsnegative categories during bootstrapping.
NEG-FINDER identifies cohesive negative categories andmany of these are semantically similar to those iden-tified by domain experts.NEG-FINDER significantly outperforms the state-of-the-art algorithm WMEB-DRIFT, before negativecategories are crafted, by up to 5.4% over the top-1000 terms; and by 10.7% over the last 200 terms ex-tracted, where semantic drift is extensive.
The newdiscovered categories can also be fully exploited inbootstrapping, where they successfully outperforma domain expert?s negative categories and approachthat of another expert.The result is an effective approach that can be in-corporated within any bootstrapper.
NEG-FINDERsuccessfully removes the necessity of includingmanually crafted supervised knowledge to boost abootstrapper?s performance.
In doing so, we revertthe multi-category bootstrapping framework back toits originally intended minimally supervised frame-work, with little performance trade-off.AcknowledgementsWe would like to thank Dr Cassie Thornley, oursecond evaluator; and the anonymous reviewers fortheir helpful feedback.
NICTA is funded by the Aus-tralian Government as represented by the Depart-ment of Broadband, Communications and the Dig-ital Economy and the Australian Research Councilthrough the ICT Centre of Excellence program.ReferencesAndrew Carlson, Justin Betteridge, Richard C. Wang, Jr.Estevam R. Hruschka, and Tom M. Mitchell.
2010.Coupled semi-supervised learning for information ex-traction.
In Proceedings of the third ACM interna-tional conference on Web search and data mining,pages 101?110, New York, NY, USA.364Paul R. Cohen.
1995.
Empirical Methods for ArtificialIntelligence.
MIT Press, Cambridge, MA, USA.James R. Curran, Tara Murphy, and Bernhard Scholz.2007.
Minimising semantic drift with mutual exclu-sion bootstrapping.
In Proceedings of the 10th Con-ference of the Pacific Association for ComputationalLinguistics, pages 172?180, Melbourne, Australia.James R. Curran.
2004.
From Distributional to Seman-tic Similarity.
Ph.D. thesis, University of Edinburgh,Edinburgh, UK.Claire Grover, Michael Matthews, and Richard Tobin.2006.
Tools to address the interdependence betweentokenisation and standoff annotation.
In Proceed-ings of the 5th Workshop on NLP and XML: Multi-Dimensional Markup in Natural Language Process-ing, pages 19?26, Trento, Italy.William Hersh, Aaron M. Cohen, Lynn Ruslen, andPhoebe M. Roberts.
2007.
TREC 2007 Genomicstrack overview.
In Proceedings of the 16th Text RE-trieval Conference, Gaithersburg, MD, USA.Leonard Kaufmann and Peter J. Rousseeuw.
1990.
Find-ing Groups in Data: an Introdution to Cluster Analy-sis.
John Wiley and Sons.Winston Lin, Roman Yangarber, and Ralph Grishman.2003.
Bootstrapped learning of semantic classes frompositive and negative examples.
In Proceedings ofthe ICML-2003 Workshop on The Continuum from La-beled to Unlabeled Data, pages 103?111, Washington,DC, USA.Tara McIntosh and James R. Curran.
2008.
Weightedmutual exclusion bootstrapping for domain indepen-dent lexicon and template acquisition.
In Proceedingsof the Australasian Language Technology AssociationWorkshop, pages 97?105, Hobart, Australia.Tara McIntosh and James R. Curran.
2009.
Reducingsemantic drift with bagging and distributional similar-ity.
In Proceedings of the 47th Annual Meeting of theAssociation for Computational Linguistics and the 4thInternational Conference on Natural Language Pro-cessing of the Asian Federation of Natural LanguageProcessing, pages 396?404, Suntec, Singapore.Tara McIntosh.
2010.
Reducing Semantic Drift inBiomedical Lexicon Bootstrapping.
Ph.D. thesis, Uni-versity of Sydney.Marius Pas?ca, Dekang Lin, Jeffrey Bigham, Andrei Lif-chits, and Alpa Jain.
2006.
Names and similarities onthe web: Fact extraction in the fast lane.
In Proceed-ings of the 21st International Conference on Compu-tational Linguistics and the 44th Annual Meeting ofthe Association for Computational Linguistics, pages809?816, Sydney, Australia.Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-Maria Popescu, and Vishnu Vyas.
2009.
Web-scaledistributional similarity and entity set expansion.
InProceedings of the Conference on Empirical Methodsin Natural Language Processing, pages 238?247, Sin-gapore, Singapore.Patrick Pantel.
2003.
Clustering by Committee.
Ph.D.thesis, University of Alberta.Deepak Ravichandran and Eduard Hovy.
2002.
Learningsurface text patterns for a question answering system.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 41?47,Philadelphia, PA, USA.Ellen Riloff and Rosie Jones.
1999.
Learning dictionar-ies for information extraction by multi-level bootstrap-ping.
In Proceedings of the 16th National Conferenceon Artificial Intelligence and the 11th Innovative Ap-plications of Artificial Intelligence Conference, pages474?479, Orlando, FL, USA.Ellen Riloff and Jessica Shepherd.
1997.
A corpus-basedapproach for building semantic lexicons.
In Proceed-ings of the Second Conference on Empirical Meth-ods in Natural Language Processing, pages 117?124,Providence, RI, USA.Michael Thelen and Ellen Riloff.
2002.
A bootstrappingmethod for learning semantic lexicons using extractionpattern contexts.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,pages 214?221, Philadelphia, PA, USA.Roman Yangarber, Winston Lin, and Ralph Grishman.2002.
Unsupervised learning of generalized names.
InProceedings of the 19th International Conference onComputational Linguistics (COLING), pages 1135?1141, San Francisco, CA, USA.Hong Yu and Eugene Agichtein.
2003.
Extracting syn-onymous gene and protein terms from biological liter-ature.
Bioinformatics, 19(1):i340?i349.365
