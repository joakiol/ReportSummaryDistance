Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 968?976,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsTree Kernel-based Negation and Speculation Scope Detection withStructured Syntactic Parse FeaturesBowei Zou       Guodong Zhou       Qiaoming Zhu*Natural Language Processing Lab, School of Computer Science and TechnologySoochow University, Suzhou, 215006, Chinazoubowei@gmail.com, {gdzhou,qmzhu}@suda.edu.cnAbstractScope detection is a key task in information ex-traction.
This paper proposes a new approach fortree kernel-based scope detection by using thestructured syntactic parse information.
In addi-tion, we have explored the way of selectingcompatible features for different part-of-speechcues.
Experiments on the BioScope corpus showthat both constituent and dependency structuredsyntactic parse features have the advantage incapturing the potential relationships betweencues and their scopes.
Compared with the stateof the art scope detection systems, our systemachieves substantial improvement.
*1 IntroductionThe task of scope detection is to detect the linguis-tic scope dominated by a specific cue.
Current re-searches in this field focus on two semantic as-pects: negation and speculation.
The negativescope detection is to detect the linguistic scopewhich is repudiated by a negative word (viz., nega-tive cue, e.g., ?not?).
In other side, the speculativescope detection is to detect the uncertain part in asentence corresponding to the speculative word(viz., speculative cue, e.g., ?seems?).
See the sen-tence 1) below, the negative cue ?not?
dominatesthe scope of ?not expensive?.
Similarly, the specu-lative cue ?possible?
in sentence 2) dominates theuncertain scope ?the possible future scenarios?.1) The chair is [not expensive] but comfortable.2) Considering all that we have seen, what are now[the possible future scenarios]?
*	Corresponding	authorThe negative and speculative scope detectiontask consists of two basic stages.
The first one is toidentify the sentences involving negative or specu-lative meaning.
The second stage is to detect thelinguistic scope of the cue in sentences (Velldal etal, 2012).
In this paper, we focus on the secondstage.
That is, by given golden cues, we detecttheir linguistic scopes.We propose a tree kernel-based negation andspeculation scope detection with structured syntac-tic parse features.
In detail, we regard the scopedetection task as a binary classification issue,which is to classify the tokens in a sentence as be-ing inside or outside the scope.
In the basicframework, we focus on the analysis and applica-tion of structured syntactic parse features as fol-lows:Both constituent and dependency syntactic fea-tures have been proved to be effective in scopedetection (?zg?r et al2009; ?vrelid et al2010).However, these flat features are hardly to reflectthe information implicit in syntactic parse treestructures.
Our intuition is that the segments of thesyntactic parse tree around a negative or specula-tive cue is effective for scope detection.
The relat-ed structures normally underlay the indirect cluesto identify the relations between cues and theirscopes, e.g., in sentence 1), ?but something?, as afrequently co-occurred syntactic structure with?not something?, is an effective clue to determinethe linguistic scope of ?not?.The tree kernel classifier (Moschitti, 2006)based on support vector machines uses a kernelfunction between two trees, affording a compari-son between their substructures.
Therefore, a treekernel-based scope detection approach with struc-tured syntactic parse tree is employed.
The tree968kernel has been already proved to be effective insemantic role labeling (Che et al2006) and rela-tion extraction (Zhou et al2007).In addition, the empirical observation showsthat features have imbalanced efficiency for scopeclassification, which is normally affected by thepart-of-speech (abbr., POS) of cues.
Hence, webuild the discriminative classifiers for each kind ofPOS of cues, then explore and select the mostcompatible features for them.We construct a scope detection system by usingthe structured syntactic parse features based treekernel classification.
Compared with the state ofthe art scope detection systems, our systemachieves the performance of accuracy 76.90% onnegation and 84.21% on speculation (on Abstractssub-corpus).
Additionally, we test our system ondifferent sub-corpus (Clinical Reports and FullPapers).
The results show that our approach hasbetter cross-domain performance.The rest of this paper is organized as follows:Section 2 reviews related work.
Section 3 intro-duces the corpus and corresponding usage in ourexperiments.
Section 4 describes our approach andthe experiments are presented in Section 5.
Finally,there is a conclusion in Section 6.2 Related WorkMost of the previous studies on negation and spec-ulation scope detection task can be divided intotwo main aspects: the heuristic rule based methodsand the machine learning based methods.
We re-spectively introduce the aspects in below.2.1 Heuristic Rule based MethodsThe initial studies for scope detection are to com-pile effective heuristic rules (Chapman et al2001;Goldin et al2003).
Recently, the heuristic rulebased methods have further involved the syntacticfeatures.Huang et al2007) implemented a hybrid ap-proach to automated negation scope detection.They combined the regular expression matchingwith grammatical parsing: negations are classifiedon the basis of syntactic categories and located inparse trees.
Their hybrid approach is able to identi-fy negated concepts in radiology reports evenwhen they are located at some distance from thenegative term.
?zg?r et al2009) hypothesized that the scopeof a speculation cue can be characterized by itspart-of-speech and the syntactic structure of thesentence and developed rules to map the scope of acue to the nodes in the syntactic parse tree.
Bygiven golden speculation cues, their rule-basedmethod achieves the accuracies of 79.89% and61.13% on the Abstracts and the Full-Papers sub-corpus, respectively.
?vrelid et al2010) constructed a small set ofheuristic rules which define the scope for each cue.In developing these rules, they made use of theinformation provided by the guidelines for scopeannotation in the BioScope corpus, combined withmanual inspection of the training data in order tofurther generalize over the phenomena discussedby Vincze et al2008) and work out interactions ofconstructions for various types of cues.Apostolova et al2011) presented a linguistical-ly motivated rule-based system for the detection ofnegation and speculation scopes that performs onpar with state-of-the-art machine learning systems.The rules are automatically extracted from the Bi-oScope corpus and encode lexico-syntactic pat-terns in a user-friendly format.
While their systemwas developed and tested using a biomedical cor-pus, the rule extraction mechanism is not domain-specific.The heuristic rule based methods have bad ro-bustness in detecting scopes crossing differentmeaning aspects (e.g., negative vs. speculative)and crossing different linguistic resources (e.g.,Technical Papers vs. Clinical Reports).2.2 Machine Learning based MethodsThe machine learning based methods have beenignored until the release of the BioScope corpus(Szarvas et al2008), where the large-scale data ofmanually annotated cues and corresponding scopescan support machine learning well.Morante et al2008) formulated scope detectionas a chunk classification problem.
It is worth not-ing that they also proposed an effective properpost-processing approach to ensure the consecu-tiveness of scope.
Then, for further improving thescope detection, Morante et al2009a) applied ameta-learner that uses the predictions of the threeclassifiers (TiMBL/SVM/CRF) to predict thescope.For the competitive task in CoNLL?2010 (Far-kas et al2010), Morante et al2010) used a969memory-based classifier based on the k-nearestneighbor rule to determine if a token is the firsttoken in a scope sequence, the last, or neither.Therefore, in order to guarantee that all scopes arecontinuous sequences of tokens they apply a firstpost-processing step that builds the sequence ofscope.The existing machine learning based approachessubstantially improve the robustness of scope de-tection, and have nearly 80% accuracy.
However,the approaches ignore the availability of the struc-tured syntactic parse information.
This informationinvolves more clues which can well reflect the re-lations between cues and scopes.
S?nchez et al(2010) employed a tree kernel based classifier withCCG structures to identify speculative sentenceson Wikipedia dataset.
However, in S?nchez?s ap-proach, not all sentences are covered by the classi-fier.3 CorpusWe have employed the BioScope corpus (Szarvaset al2008; Vincze et al2008)1, an open resourcefrom the biomedical domain, as the benchmarkcorpus.
The corpus contains annotations at the to-ken level for negative and speculative cues and atthe sentence level for their linguistic scope (asshown in Figure 1).
(Note: <Sentence> denotes one sentence and the tag ?id?
denotes itsserial number; <xcope> denotes the scope of a cue; <cue> denotes thecue, the tag ?type?
denotes the specific kind of cues and the tag ?ref?is the cue?s serial number.
)Figure 1.
An annotated sentence in BioScope.The BioScope corpus consists of three sub-corpora: biological Full Papers from FlyBase andBMC Bioinformatics, biological paper Abstractsfrom the GENIA corpus (Collier et al1999), andClinical Reports.
Among them, the Full Paperssub-corpus and the Abstracts sub-corpus comefrom the same genre.
In comparison, the ClinicalReports sub-corpus consists of clinical radiologyreports with short sentences.1 http://www.inf.u-szeged.hu/rgai/bioscopeIn our experiments, if there is more than one cuein a sentence, we treat them as different cue andscope (two independent instances).
The statisticaldata for our corpus is presented in Table 1 in be-low.The average length of sentences in the negationportion is almost as long as that in speculation,while the average length of scope in negation isshorter than that in speculation.
In addition, thelength of sentence and scope in both Abstracts andFull Papers sub-corpora is comparative.
But inClinical Reports sub-corpus, it is shorter than thatin Abstracts and Full Papers.
Thus, looking for theeffective features in short sentences is especiallyimportant for improving the robustness for scopedetection.
(Note: ?Av.
Len?
stands for average length.
)Table 1.
Statistics for our corpus in BioScope.4 MethodologyWe regard the scope detection task as a binaryclassification problem, which is to classify eachtoken in sentence as being the element of the scopeor not.
Under this framework, we describe the flatsyntactic features and employ them in our bench-mark system.
Then, we propose a tree kernel-based scope detection approach using the struc-tured syntactic parse features.
Finally, we con-struct the discriminative classifier for each kind ofPOS of cues, and select the most compatible fea-tures for each classifier.4.1 Flat Syntactic FeaturesIn our benchmark classification system, the fea-tures relevant to the cues or tokens are selected.Then, we have explored the constituent and de-pendency syntactic features for scope detection.These features are all flat ones which reflect thecharacteristic of tokens, cues, scopes, and the rela-tion between them.Abstract Paper ClinicalNega-tionSentences 1594 336 441Words 46849 10246 3613Scopes 1667 359 442Av.
Len Sentence 29.39 30.49 8.19Av.
Len Scope 9.62 9.36 5.28Specu-lationSentences 2084 519 854Words 62449 16248 10241Scopes 2693 682 1137Av.
Len Sentence 29.97 31.31 11.99Av.
Len Scope 17.24 15.58 6.99<sentence id=?S26.8?> These findings <xcope id=?X26.8.2?><cue type=?speculation?
ref=?X26.8.2?> indicate that </cue><xcope id=?X26.8.1?> corticosteroid resistance in bronchialasthma <cue type=?negation?
ref=?X26.8.1?> can not </cue>be explained by abnormalities in corticosteroid receptor char-acteristics </xcope></xcope> .
</sentence>970Basic Features: Table 2 shows the basic fea-tures which directly relate to the characteristic ofcues or tokens in our basic classification.Feature RemarkB1 Cue.B2 Candidate token.B3 Part-of-speech of candidate token.B4 Left token of candidate token.B5 Right token of candidate token.B6 Positional relation between cue and token.Table 2.
Basic features.Constituent Syntactic Features: For improv-ing the basic classification, we employ 10 constit-uent features belonging to two aspects.
On the onehand, we regard the linguistic information of theneighbor locating around the candidate tokens asthe coherent features (CS1~CS6 in Table 3).
Thesefeatures are used for detecting the close coopera-tion of a candidate token co-occurring with itsneighbors in a scope.
On the other hand, we regardthe linguistic characteristics of the candidate to-kens themselves in a syntactic tree as the inherentfeatures (CS7~CS10 in Table 3).
These featuresare used for determining whether the token has thedirect relationship with the cue or not.Features RemarksCS1 POS of left token.CS2 POS of right token.CS3 Syntactic category of left token.CS4 Syntactic category of right token.CS5 Syntactic path from left token to the cue.CS6 Syntactic path from right token to the cue.CS7 Syntactic category of the token.CS8 Syntactic path from the token to the cue.CS9 Whether the syntactic category of the token isthe ancestor of the cue.CS10 Whether the syntactic category of the cue is theancestor of the token.Table 3.
Constituent syntactic features.Features RemarksDS1 Dependency direction (?head?or ?dependent?
).DS2 Dependency syntactic path from the token to cue.DS3 The kind of dependency relation between the tokenand cue.DS4 Whether the token is the ancestor of the cue.DS5 Whether the cue is the ancestor of the token.Table 4.
Dependency syntactic features.Dependency Syntactic Features: For the effec-tiveness to obtain the syntactic information farapart from cues, we use 5 dependency syntacticfeatures which emphasize the dominant relation-ship between cues and tokens by dependency arcsas shown in Table 4.The features in Table 2, 3, and 4 have imbal-anced classification for the scope classification.Therefore, we adopt the greedy feature selectionalgorithm as described in Jiang et al2006) to pickup positive features incrementally according totheir contributions.
The algorithm repeatedly se-lects one feature each time, which contributes most,and stops when adding any of the remaining fea-tures fails to improve the performance.4.2 Structured Syntactic FeaturesSyntactic trees involve not only the direct bridge(e.g., syntactic path) between cue and its scope butalso the related structures to support the bridge(e.g., sub-tree).
The related structures normallyinvolve implicit clues which underlay the relationbetween cue and its scope.
Therefore, we use theconstituent and dependency syntactic structures asthe supplementary features to further improve thebenchmark system.Furthermore, we employ the tree kernel-basedclassifier to capture the structured informationboth in constituent and dependency parsing trees.The results of the constituent syntactic parser aretypical trees which always consist of the syntacticcategory nodes and the terminal nodes.
Thus, theconstituent syntactic tree structures could be usedin tree kernel-based classifier directly, but not forthe dependency syntactic tree structures.
As Figure2 shows, in sentence ?The chair is not expensivebut comfortable.?
the tree kernels cannot representthe relations on the arcs (e.g., ?CONJ?
between?expensive?
and ?comfortable?).
It is hard to usethe relations between tokens and cues in tree ker-nels.Figure 2: The dependency tree of sentence ?Thechair is not expensive but comfortable.
?971Figure 3.
Two transformational rules.To solve the problem, we transform the depend-ency tree into other two forms capable of beingused directly as the compatible features in tree-kernel based classification.
The transformationalrules are described as below:(1) Extracting the dependency relations to gen-erate a tree of pure relations (named dependencyrelational frame), where the tokens on the nodes oforiginal dependency tree are ignored and only therelation labels are used.
E.g., the tokens ?chair?,?is?, etc in Figure 2 are all deleted and replaced bythe corresponding relation labels.
E.g., ?NSUBJ?,?COP?, etc are used as nodes in the dependencyrelational frame, see (1a) & (1b) in Figure 3.
(2) Inserting the tokens which have been deletedin step (1) into the dependency relational frameand making them follow and link with their origi-nal dependency relations.
E.g., the tokens ?chair?,?is?, etc are added below the nodes ?NSUBJ?,?COP?, etc, see (2a) & (2b) in Figure 3.Figure 4.
Two transformations for tree-kernel.Within the constituent and dependency syntactictrees, we have employed both the Completed Sub-Tree and the Critical Path as the syntactic structurefeatures for our classification.
The former is a min-imum sub-tree that involves the cues and the to-kens, while the latter is the path from the cues tothe tokens in the completed tree containing theprimary structural information.
Figure 4 showsthem.4.3 Part-of-Speech Based Classification Op-timizationMotivating in part by the rule-based approach of?zg?r et al2009), we infer that features have im-balanced efficiency for scope classification, nor-mally affected by the part-of-speech (POS) of cues.POS of Cues Number POS of Cues NumberCC 157 VB 31IN 115 VBD 131JJ 238 VBG 225MD 733 VBN 112NN 43 VBP 561RB 137 VBZ 207Table 5.
Distribution of different POSs of specula-tive cues in Abstracts sub-corpus.Table 5 shows the distribution for differentPOSs of cues in the Abstracts sub-corpus of Bio-Scope for speculation detection task.
The cues ofdifferent POS usually undertake different syntacticroles.
Thus, there are different characteristics intriggering linguistic scopes.
See the two examplesbelow:3) TCF-1 contained a single DNA box in the [putativemammalian sex-determining gene SRY].4) The circadian rhythm of plasma cortisol [eitherdisappeared or was inverted].The speculative cue ?putative?
in sentence 3) isan adjective.
The corresponding scope is its modi-ficatory structure (?putative mammalian sex-determining gene SRY?).
In sentence 4), ?ei-ther?or??
is a conjunction speculation cue.
Itsscope is the two connected components (?eitherdisappeared or was inverted?).
Thus, the effectivefeatures for the adjectival cue are normally the de-pendency features, e.g., the features of DS1 andDS5 in Table 4, while the features for the conjunc-tion cue are normally the constituent information,e.g., the features of CS9 in Table 3.In Table 5, considering the different function ofverb voice, we cannot combine the ?VB(*)?
POS.For instance, the POS of ?suggest?
in sentence 5)is ?VBP?
(the verb present tense).
The correspond-ing scope does not involve the sentence subject.972The POS of ?suggested?
in sentence 6) is ?VBN?
(the past participle).
The scope involves the sub-ject ?An age-related decrease?.5) These results [suggest that the genes might be in-volved in terminal granulocyte differentiation].6) [An age-related decrease was suggested betweensubjects younger than 20 years].As a result, we have built a discriminative clas-sifier for each kind of POS of cues, and then ex-plored and selected the most compatible featuresfor each classifier.5 Experiments and Results5.1 Experimental SettingConsidering the effectiveness of different features,we have split the Abstracts sub-corpus into 5 equalparts, within which 2 parts are used for featureselection (Feature Selection Data) and the rest forthe scope detection experiments (Scope DetectionData).
The Feature Selection Data are divided into5 equal parts, within which 4 parts for training andthe rest for developing.
In our scope detection ex-periments, we divide the Scope Detection Datainto 10 folds randomly, so as to perform 10-foldcross validation.
As the experiment data is easilyconfusable, Figure 5 illustrates the allocation.Checking the validity of our method, we use theAbstracts sub-corpus in Section 5.2, 5.3 and 5.4,while in Section 5.5 we use all of the three sub-corpora (Abstracts, Full Papers, and Clinical Re-ports) to test the robustness of our system whenapplied to different text types within the same do-main.Figure 5.
The allocation for experiment data.The evaluation is made using the precision, re-call and their harmonic mean, F1-score.
Addition-ally, we report the accuracy in PCS (Percentage ofCorrect Scopes) applied in CoNLL?2010, withinwhich a scope is fully correct if all tokens in a sen-tence have been assigned to the correct scope classfor a given cue.
The evaluation in terms of preci-sion and recall measures takes a token as a unit,whereas the evaluation in terms of PCS takes ascope as a unit.
The key toolkits for scope classifi-cation include:Constituent and Dependency Parser: All thesentences in BioScope corpus are tokenized andparsed using the Berkeley Parser (Petrov et al2007) 2  which have been trained on the GENIATreeBank 1.0 (Tateisi et al2005)3, a bracketedcorpus in PTB style.
10-fold cross-validation onGTB1.0 shows that the parser achieves 87.12% inF1-score.
On the other hand, we obtain the de-pendency relations by the Stanford DependenciesParser4.Support Vector Machine Classifier: SVMLight5is selected as our classifier, which provides a wayto combine the tree kernels with the default andcustom SVMLight kernels.
We use the default pa-rameter computed by SVMLight.Besides, according to the guideline of the Bio-Scope corpus, scope must be a continuous chunk.The scope classifier may result in discontinuousblocks, as each token may be classified inside oroutside the scope.
Therefore, we perform the rulebased post-processing algorithm proposed by Mo-rante et al2008) to obtain continuous scopes.5.2 Results on Flat Syntactic FeaturesRelying on the results of the greedy feature selec-tion algorithm (described in Section 4.1), we ob-tain 9 effective features {B1, B3, B6, CS3, CS4,CS9, DS1, DS3, DS5} (see Table 2, 3 and 4) fornegation scope detection and 13 effective features{B3, B4, B5, B6, CS1, CS5, CS6, CS8, CS9, CS10,DS1, DS4, DS5} for speculation.
Table 6 lists theperformances on the Scope Detection Data by per-forming 10-fold cross validation.
It shows that flatconstituent and dependency syntactic features sig-nificantly improve the basic scope detection by13.48% PCS for negation and 30.46% for specula-tion (?2; p < 0.01).
It demonstrates that the selectedsyntactic features are effective for scope detection.2 http://code.google.com/p/berkeleyparser3 http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA4 http://nlp.stanford.edu/software/lex-parser.shtml5 http://svmlight.joachims.org973NegationFeatures P R F PCSBasic 89.89 68.72 77.86 39.50Con.
85.72 67.80 75.66 41.81Dep.
90.31 69.01 78.19 40.08Bas.&Con.
88.86 79.07 83.61 51.64Bas.&Dep.
90.44 73.62 81.17 49.36All 91.21 76.57 83.25 52.98SpeculationFeatures P R F PCSBasic 89.67 86.86 88.24 40.09Con.
96.43 87.46 91.72 66.57Dep.
90.84 87.04 88.89 44.45Bas.&Con.
95.66 92.08 93.83 69.59Bas.&Dep.
92.39 88.27 90.28 67.49All 95.71 92.09 93.86 70.55(Note: ?Bas.?
denotes basic features; ?Con.?
denotes Constituentfeatures; ?Dep.?
denotes Dependency features; ?All?
contains Basic,Constituent, and Dependency features being selected.
)Table 6.
Performance of flat syntactic features.The results also show that the speculative scopedetection achieves higher performance (16.98%higher in PCS) (?2; p < 0.01) than the negationscope detection.
The main reason is that althoughthe average sentence length of negation and specu-lation are comparable (29.97 vs. 29.39 words, inTable 1), the average length of speculation scopesis much longer than the negation (17.24 vs. 9.62words, in Table 1) in Abstracts sub-corpus.
Withthe shorter scopes in training data, the classifierinevitably have more negative samples.
Thus, byusing a token as the basic unit in our classification,the imbalanced samples will seriously mislead theclassifier and result in bias on the negative samples.In addition, both constituent and dependencyflat features can improve the scope classification,for the reason that the constituent features usuallyprovide the nearer syntactic information of thecues, and that the further syntactic informationbetween cues and scopes have been obtained bythe dependency features.5.3 Results on Structured Syntactic ParseFeaturesTable 7 and Table 8 give the scope detection per-formance using the different structured syntacticparse features on negation and speculation respec-tively.
Compared to the optimal system (using allof the selected flat features in Table 6) in Section5.2, the structured syntactic parse features at bestimprove the scope classification nearly 17.29% onnegation (PCS=70.27%) and 12.32% on specula-tion (PCS=82.87%) (?2; p < 0.01).
It indicates thatthe structured syntactic parse features can providemore implicit linguistic information, as supple-mentary clues, to support scope classification.The improvements also show that both the com-pleted syntactic sub-trees and critical paths in con-stituent and dependency parsing trees are effective.The reason is that the completed syntactic sub-trees contain the surrounding information relatedto cues and tokens, while there are more directsyntactic information in the critical paths betweencue and its scope.Features P R F PCSCon.
CT 91.12 83.25 86.89 54.57Con.
CT&CP 93.31 89.32 91.20 66.58Dep.
T1 CT 87.29 84.37 85.81 53.07Dep.
T1 CT&CP 90.03 86.77 88.37 59.53Dep.
T2 CT 88.17 84.58 86.34 53.76Dep.
T2 CT&CP 91.09 87.31 89.16 60.11All 93.84 91.94 92.88 70.27(Note: ?Con.?
denotes Constituent features; ?Dep.?
denotes Depend-ency features; ?T1?
use the transformational rule (1) in Section 4.2 toget the dependency tree; ?T2?
use the transformational rule (2) inSection 4.2 to get the dependency tree; CT-?Completed syntactic sub-Tree?
; CP-?Critical Path?
; ?All?
contains Con CT&CP, Dep T1CT&CP and Dep T2 CT&CP)Table 7.
Performance of structured syntactic parsefeatures on negation.Features P R F PCSCon.
CT 95.89 93.37 94.61 75.17Con.
CT&CP 96.05 94.36 95.20 76.73Dep.
T1 CT 93.24 90.77 91.99 72.31Dep.
T1 CT&CP 94.28 92.30 93.28 73.75Dep.
T2 CT 93.76 89.68 91.67 73.06Dep.
T2 CT&CP 95.29 94.55 94.92 75.69All 96.93 96.86 96.89 82.87Table 8.
Performance of structured syntactic parsefeatures on speculation.5.4 Results on Part-of-Speech Based Classifi-cationTo confirm the assumption in Section 4.3, we havebuilt a discriminative classifier for each kind ofPOS of cues.
Considering that the features involv-ing the global structured syntactic parse infor-mation in Section 4.2 are almost effective to allinstances, we only use the flat syntactic features inSection 4.1.NegationSystem P R F PCSAll Features 91.21 76.57 83.25 52.98POS Classifier 91.79 78.29 84.50 56.77Specula-tionSystem P R F PCSAll Features  95.71 92.09 93.86 70.55POS Classifier 95.79 93.13 94.44 71.68(Note: ?All Features?
System is the optimal system in Section 5.2)Table 9.
Performances of POS based classification.Table 9 shows the performance of POS basedclassification.
Compared with the system whichonly uses one classifier for all cues in Section 5.2,974the POS based classification improves 1.13% onPCS (?2; p < 0.01), as different POS kinds of cuesinvolve respectively effective features with morerelated clues between cue and its scope.Table 10 lists the performance of each POS kindof cues in speculation scope classification.
Thereare still some low performances in some kinds ofPOS of cues.
We consider it caused by two reasons.Firstly, some kinds of POS of cues  (e.g.
NN etc.
)have fewer samples (just 43 samples shown in Ta-ble 5).
For this reason, the training for classifier islimited.
Then, for these low performance kinds ofPOS of cues, we may have not found the effectivefeatures for them.
Although there are some kindsof cues with low performance, the whole perfor-mance of part-of-speech based classification isimproved.Cue?sPOSB1~B61   2   3   4   5   6CS1~CS101   2   3   4    5   6   7   8   9 10DS1~DS51   2   3   4   5 PCSCC ?
?
?
?
?
?
?
?
?
?
38.45IN ?
?
?
?
?
?
?
?
?
?
?
87.99JJ ?
?
?
?
?
?
31.83MD    ?
?
?
?
?
?
?
?
?
?
?
?
79.84NN ?
?
?
?
?
?
?
?
65.83RB      ?
?
?
?
?
?
?
37.03VB      ?
?
?
?
44.29VBD    ?
?
?
?
?
?
?
?
?
?
?
63.57VBG    ?
?
?
?
?
?
?
?
?
?
?
82.89VBN    ?
?
?
?
?
?
?
?
?
66.38VBP    ?
?
?
?
?
?
?
?
?
?
?
?
81.91VBZ    ?
?
?
?
?
?
?
?
?
?
?
?
77.16Table 10.
Performance of each POS kind of cuesin speculation scope classification.5.5 Results of Comparison ExperimentsTo get the final performance of our approach, wetrain the classifiers respectively by different effec-tive features in Section 4.1 for POS kinds of cues,and use the structured syntactic parse features inSection 4.2 on Abstracts sub-corpus by performing10-fold cross validation.NegationSystem Abstract Paper ClinicalMorante (2008) 57.33 N/A N/AMorante (2009a) 73.36 50.26 87.27Ours 76.90 61.19 85.31Specula-tionSystem Abstract Paper ClinicalMorante (2009b) 77.13 47.94 60.59?zg?r (2009) 79.89 61.13 N/AOurs 84.21 67.24 72.92Table 11.
Performance comparison of our systemwith the state-of-the-art ones in PCS.The results in Table 11 show that our systemoutperforms the state of the art ones both on nega-tion and speculation scope detection.
Results alsoshow that the system is portable to different typesof documents, although performance varies de-pending on the characteristics of the corpus.In addition, on both negation and speculation,the results on Clinical Reports sub-corpus are bet-ter than those on Full Papers sub-corpus.
It ismainly due to that the clinical reports are easier toprocess than full papers and abstracts.
The averagelength of sentence for negative clinical reports is8.19 tokens, whereas for abstracts it is 29.39 andfor full papers 30.49.
Shorter sentences implyshorter scopes.
The more unambiguous sentencestructure of short sentence can make the structuredconstituent and dependency syntactic features eas-ier to be processed.6 ConclusionThis paper proposes a new approach for tree ker-nel-based scope detection by using the structuredsyntactic parse information.
In particular, we haveexplored the way of selecting compatible featuresfor different part-of-speech cues.
Experimentsshow substantial improvements of our scope clas-sification and better robustness.However, the results on the Full Papers and theClinical Reports sub-corpora are lower than thoseon the Abstracts sub-corpus for both negation andspeculation.
That is because the structured syntac-tic parse features contain some complicated andlengthy components, and the flat features crosscorpus are sparse.
Our future work will focus onthe pruning algorithm for the syntactic structuresand analyzing errors in depth in order to get moreeffective features for the scope detection on differ-ent corpora.AcknowledgmentsThis research is supported by the National NaturalScience Foundation of China, No.61272260,No.61373097, No.61003152, the Natural ScienceFoundation of Jiangsu Province, No.BK2011282,the Major Project of College Natural ScienceFoundation of Jiangsu Province, No.11KJA520003and the Graduates Project of Science and Innova-tion, No.CXZZ12_0818.
Besides, thanks to YuHong and the three anonymous reviewers for theirvaluable comments on an earlier draft.975ReferencesEmilia Apostolova, Noriko Tomuro and Dina Demner-Fushman.
2011.
Automatic Extraction of Lexico-Syntactic Patterns for Detection of Negation andSpeculation Scopes.
In Proceedings of ACL-HLTshort papers, pages 283-287.Wendy W. Chapman, Will Bridewell, Paul Hanbury,Gregory F. Cooper, and Bruce G. Buchanan.
2001.
ASimple Algorithm for Identifying Negated Findingsand Diseases in Discharge Summaries.
Journal ofBiomedical Informatics, 34 (5): 301-310.Wanxiang Che, Min Zhang, Ting Liu and Sheng Li.2006.
A Hybrid Convolution Tree Kernel for Seman-tic Role Labeling.
In Proceedings of ACL, pages 73-80.Nigel Collier, Hyun S. Park, Norihiro Ogata, et al1999.The GENIA Project: Corpus-Based Knowledge Ac-quisition and Information Extraction from GenomeResearch Papers.
In Proceedings of EACL.Rich?rd Farkas, Veronika Vincze, Gy?rgy M?ra, J?nosCsirik, and Gy?rgy Szarvas.
2010.
The CoNLL-2010Shared Task: Learning to Detect Hedges and theirScope in Natural Language Text.
In Proceedings ofCoNLL: Shared Task, pages 1-12.Ilya M. Goldin and Wendy W. Chapman.
2003.
Learn-ing to Detect Negation with ?Not?
in Medical Texts.In SIGIR Workshop: Text Analysis and Search forBioinformatics.Yang Huang and Henry Lowe.
2007.
A Novel HybridApproach to Automated Negation Detection in Clin-ical Radiology Reports.
Journal of the AmericanMedical Informatics Association, 14(3):304-311.Zhengping Jiang and Hwee T. Ng.
2006.
Semantic RoleLabeling of NomBank: A Maximum Entropy Ap-proach.
In Proceedings of EMNLP, pages 138-145.Roser Morante, Anthony Liekens, and Walter Daele-mans.
2008.
Learning the Scope of Negation in Bio-medical Texts.
In Proceedings of EMNLP, pages715-724.Roser Morante and Walter Daelemans.
2009a.
A Met-alearning Approach to Processing the Scope of Ne-gation.
In Proceedings of CoNLL, pages 21-29.Roser Morante and Walter Daelemans.
2009b.
Learningthe Scope of Hedge Cues in Biomedical Texts.
InProceedings of the BioNLP Workshop, pages 28-36.Roser Morante, Vincent Van Asch and Walter Daele-mans.
2010.
Memory-Based Resolution of In-Sentence Scopes of Hedge Cues.
In Proceedings ofCoNLL Shared Task, pages 40-47.Alessandro Moschitti.
2006.
Making tree kernels practi-cal for natural language learning.
In Proceedings ofthe 11th Conference of the European Chapter of theAssociation for Computational Linguistics, pages113-120.Lilja ?vrelid, Erik Velldal, and Stephan Oepen.
2010.Syntactic Scope Resolution in Uncertainty Analysis.In Proceedings of COLING, pages 1379-1387.Arzucan ?zg?r and Dragomir R. Radev.
2009.
Detect-ing Speculations and their Scopes in Scientific Text.In Proceedings of EMNLP, pages 1398-1407.Slav Petrov and Dan Klein.
2007.
Improved Inferencefor Unlexicalized Parsing.
In Proceedings of NAACL,pages 404-411.Liliana M. S?nchez, Baoli Li, Carl Vogel.
2007.
Ex-ploiting CCG Structures with Tree Kernels for Spec-ulation Detection.
In Proceedings of the FourteenthConference on Computational Natural LanguageLearning: Shared Task, pages 126-131.Gy?rgy Szarvas, Veronika Vincze, Rich?rd Farkas, andJ?nos Csirik.
2008.
The BioScope corpus: Annota-tion for Negation, Uncertainty and their Scope in Bi-omedical Texts.
In Proceedings of BioNLP, pages38-45.Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, andJun?ichi Tsujii.
2005.
Syntax Annotation for theGENIA Corpus.
In Proceedings of IJCNLP, Com-panion volume, pages 222-227.Erik Velldal, Lilja ?vrelid, Jonathon Read and StephanOepen.
2012.
Speculation and Negation: Rules,Rankers, and the Role of Syntax.
ComputationalLinguistics, 38(2):369-410.Veronika Vincze, Gy?rgy Szarvas, Rich?rd Farkas,Gy?rgy M?ra and J?nos Csirik.
2008.
The BioScopecorpus: biomedical texts annotated for uncertainty,negation and their scopes.
BMC Bioinformatics,9(Suppl 11):S9.Guodong Zhou, Min Zhang, Donghong Ji, and Qi-aoming Zhu.
2007.
Tree Kernel-based Relation Ex-traction with Context-Sensitive Structured ParseTree Information.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages, 728-736.976
