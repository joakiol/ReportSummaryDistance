Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 860?865,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDetecting Turnarounds in Sentiment Analysis: ThwartingAbstractThwarting and sarcasm are two unchartedterritories in sentiment analysis, the for-mer because of the lack of training corpo-ra and the latter because of the enormousamount of world knowledge it demands.In this paper, we propose a working defi-nition of thwarting amenable to machinelearning and create a system that detects ifthe document is thwarted or not.
We focuson identifying thwarting in product re-views, especially in the camera domain.An ontology of the camera domain is cre-ated.
Thwarting is looked upon as thephenomenon of polarity reversal at ahigher level of ontology compared to thepolarity expressed at the lower level.This notion of thwarting defined with re-spect to an ontology is novel, to the bestof our knowledge.
A rule based imple-mentation building upon this idea formsour baseline.
We show that machine learn-ing with annotated corpora (thwarted/non-thwarted) is more effective than the rulebased system.
Because of the skewed dis-tribution of thwarting, we adopt the Area-under-the-Curve measure of performance.To the best of our knowledge, this is thefirst attempt at the difficult problem ofthwarting detection, which we hope will atleast provide a baseline system to compareagainst.1 CreditsThe authors thank the lexicographers at Centerfor Indian Language Technology (CFILT) at IITBombay for their support for this work.2 IntroductionAlthough much research has been done in thefield of sentiment analysis (Liu et al 2012),thwarting and sarcasm are not addressed, to thebest of our knowledge.
Thwarting has been iden-tified as a common phenomenon in sentimentanalysis (Pang et al 2002, Ohana et al 2009,Brooke, 2009) in various forms of texts but noprevious work has proposed a solution to theproblem of identifying thwarting.
We focus onidentifying thwarting in product reviews.The definition of an opinion as specified inLiu (2012) is?An opinion is a quintuple, (   ,     ,      ,,   ), where    is the name of an entity,     isan aspect of   ,       is the sentiment on aspectof entity   ,    is the opinion holder, andis the time when the opinion is expressed by   .
?If the sentiment towards the entity or one of itsimportant attribute contradicts the sentiment to-wards all other attributes, we can say that thedocument is thwarted.Ankit RamtekeDept.
of Computer Science & Engg.,Indian Institute of TechnologyBombay, Mumbai, India.ankitr@cse.iitb.ac.inPushpak BhattacharyyaDept.
of Computer Science & Engg.,Indian Institute of TechnologyBombay, Mumbai, India.pb@cse.iitb.ac.inAkshat MaluDept.
of Computer Science & Engg.,Indian Institute of TechnologyBombay, Mumbai, India.akshatmalu@cse.iitb.ac.inJ.
Saketha NathDept.
of Computer Science & Engg.,Indian Institute of TechnologyBombay, Mumbai, India.saketh@cse.iitb.ac.in860A domain ontology is an ontology of variousfeatures pertaining to a domain, arranged in ahierarchy.
Subsumption in this hierarchy impliesthat the child is a part or feature of the parent.Domain ontology has been used by variousworks in NLP (Saggion et al 2007 and Polpinijet al 2008).
In our work, we use domain ontol-ogy of camera.
We look upon thwarting as thephenomenon of reversal of polarity from thelower level of the ontology to the higher level.
Atthe higher level of ontology the entities men-tioned are the whole product or a large criticalpart of the product.
So while statements aboutentities at the lower level of the ontology are on?details?, statements about entities at higher lev-els are on the ?big picture?.
Polarity reversalfrom details to the big picture is at the heartof thwarting.The motivation for our study on thwartingcomes from the fact that: a) Thwarting is a chal-lenging NLP problem and b) Special ML ma-chinery is needed in view of the fact that thetraining data is so skewed.
Additionally largeamount of world and domain knowledge maybecalled for to solve the problem.
In spite of therelatively fewer occurrence of the thwarting phe-nomenon the problem poses an intellectuallystimulating exercise.
We may also say that in thelimit, thwarting approaches the very difficultproblem of sarcasm detection (Tsur et al2010).We start by defining and understanding theproblem of thwarting in section 2.
In section 3,we describe a method to create the domain on-tology.
In section 4, we propose a na?ve rulebased approach to detect thwarting.
In section 5we discuss a machine learning based approachwhich could be used to identify whether a docu-ment is thwarted or not.
This is followed by ex-perimental results in section 6.
Section 7 drawsconclusions and points to future work.3 DefinitionThwarting is defined by Pang et al (2008) asfollows:?Thwarted expectations basically refer to thephenomenon wherein the author of the text firstbuilds up certain expectations for the topic, onlyto produce a deliberate contrast to the earlierdiscussion.
"For our computational purposes, we definethwarting as:?The phenomenon wherein the overall polarity ofthe document is in contrast with the polarity ofmajority of the document.
?This definition emphasizes thwarting as piggy-backing on sentiment analysis to improve thelatter?s performance.
The current work howeveronly addresses the problem of whether a docu-ment is thwarted or not and does not output thesentiment of the document.
The basic block dia-gram for our system is shown in figure 1.Figure 1: Basic Block DiagramAn example of a thwarted document is:?I love the sleek design.
The lens is impressive.The pictures look good but, somehow this cam-era disappoints me.
I do not recommend it.
?While thwarting occurs in various forms of sen-timent bearing texts, it is not a very frequent one.It accounts for hardly 1-2% of any given corpus.Thus, it becomes hard to find sufficient numberof examples of thwarting to train a classifier.Since thwarting is a complex natural languagephenomenon we require basic NLP tools andresources, whose accuracy in turn can affect theoverall performance of a thwarting detection sys-tem.4 Building domain ontologyDomain ontology comprises of features and enti-ties from the domain and the relationships be-tween them.
The process thus has two steps, viz.
(a) identify the features and entities, and (b) con-nect them in the form of a hierarchy.
We decidedto use a combination of review corpora miningand manual means for identifying key features.Our approach to building the domain ontology isas follows:Step 1: We use Latent Dirichlet Allocation(LDA) (Blei et al 2003) on a corpus containingreviews of a particular product (camera, in ourcase) to identify key features from the domain.The output is then analyzed manually to finallyselect the key features.
Some additional featuresget added by human annotator to increase thecoverage of the ontology.
For Example, in thecamera domain, the corpus may include wordsThwartingDetectionSystemInputDocumentThwarted orNot -Thwarted861like memory, card, gb, etc.
but, may not containthe word storage.
The abstract concept of stor-age is contributed by the human annotatorthrough his/her world knowledge.Step 2: The features thus obtained are ar-ranged in the form of a hierarchy by a humanannotator.Figure 2: Ontology for the camera domain5 A rule based approach to thwartingrecognitionAs per the definition of thwarting, most of thethwarted document carries a single sentiment;however, a small but critical portion of the text,carrying the contrary sentiment, actually decidesthe overall polarity.
The critical statement, thus,should be strongly polar (either positive or nega-tive), and it should be on some critical feature ofthe product.From the perspective of the domain ontology, thesentiment towards the overall product or towardssome critical feature mentioned near the root ofthe ontology should be opposite to the sentimenttowards features near the leaves.Based on these observations we propose the fol-lowing na?ve approach to thwarting detection:For each sentence in a review to be tested1.
Get the dependency parse of the sentence.This step is essential.
It makes explicit the adjec-tive noun dependencies, which in turn uncoversthe sentiment on a specific part or feature of theproduct.2.
Identify the polarities towards all nouns, us-ing the dependency parse and sentiment lexicons.3.
If a domain feature, identified using the do-main ontology, exists in the sentence, anno-tate/update the ontology node, containing thefeature, using the polarity obtained.Once the entire review is processed, we obtainthe domain ontology, with polarity marking onnodes, for the corresponding review.The given review is thwarted if there is a con-tradiction of sentiment among different levels ofthe domain ontology with polarity marking onnodes.The sentiment lexicons used are SentiWord-Net (Esuli et al 2006), Taboada (Taboada et al2004), BL lexicon (Hu et al 2004) and Inquirer(Stone et al 1966).The procedure is illustrated by an example.
?I love the sleek design.
The lens is impressive.The pictures look good but, somehow this cam-era disappoints me.
I do not recommend it.
?A part of the ontology, with polarity marking onnodes, for this example is shown in figure 3.Figure 3: ontology with polarity marking on nodes:exampleBased on this ontology we see that there is anopposition of sentiment between the root (?cam-era?)
and the lower nodes.
We thus determinethat this document is thwarted.However, since the nodes, within the samelevel, might have different weighting based uponthe product under consideration, this methodfails to perform well.
For example, the body andvideo capability might be subjective whereas anyfault in the lens or the battery will render thecamera useless, hence they are more critical.
Wethus see a need for relative weighting among allfeatures in the ontology.Camera -negativeLens  -positiveBodyDesign -positiveDisplayPicture -positive8626 A Machine Learning based approachManual fixing of relative weightages for the fea-tures of the product is possible, but that would bead hoc.
We now propose a machine learningbased approach to detect thwarting in documents.It uses the domain ontology to identify key fea-tures related to the domain.
The approach in-volves two major steps namely learning theweights and building a model that classifies thereviews using the learnt weights.6.1  Learning WeightsThe weights are learnt using the loss-regularization framework.
The key idea is thatthe overall polarity of the document is deter-mined by the polarities of individual words in thedocument.
Since, we need to find the weights forthe nodes in the domain ontology; we consideronly the words belonging to the ontology for fur-ther processing.
Thus, if P is the polarity of thereview and    is the polarity associated withword i then   ?
gives the linear model.The word i should belong to the ontology as wellas the review.
Similarly, the hinge loss is givenby               where w is the weightvector and x is the feature vector consisting of.Based on the intuition, that every word con-tributes some polarity to its parent node in thedomain ontology, we also learnt weights on theontology by percolating polarities towards theroot.
We experimented with complete percola-tion, wherein the polarity at a node is its polarityin the document summed with the polarities ofall its descendants.
We also define controlledpercolation, wherein the value added for a par-ticular descendant is a function of its distancefrom the node.
We halved the polarity value per-colated, for each edge between the two nodes.Thus, for the example in figure 2, the polarityvalue of camera would beWhere         is the final polarity for cameraand       is the polarity of the word ?
{camera,body, display, design, picture}.6.2 ClassifierWe use the SVM classifier with features generat-ed using the following steps.
We first create avector of weighted polarity values for each re-view.
This is constructed by generating a valuefor each word in the domain ontology encoun-tered while reading the review sequentially.
Thevalue is calculated by multiplying the weight,found in the previous step (5.1), with the polarityof the word as determined from the sentence.Since, these vectors will be of different dimen-sionality for each review, we extract featuresfrom these reviews.
These features are selectedbased on our understanding of the problem andthe fact that thwarting is a function of the changeof polarity values and also the position ofchange.The Features extracted are:Document polarity, number of flips of sign (i.e.change of polarity from positive to negative andvice versa), the maximum and minimum valuesin a sequence, the length of the longest contigu-ous subsequence of positive values (LCSP), thelength of the longest contiguous subsequence ofnegative values (LCSN), the mean of all values,total number of positive values in the sequence,total number of negative values in the sequence,the first and the last value in the sequence, thevariance of the moving averages, the differencein the means of LCSP and LCSN.7 ResultsExperiments were performed on a dataset ob-tained by crawling product reviews from Ama-zon1 .
We focused on the camera domain.
Weobtained 1196 reviews from this domain.
Thereviews were annotated for thwarting, i.e.,thwarted or non-thwarted as well as polarity.
Thereviews crawled were given to three differentannotators.
The instructions given for annotationwere as follows:1.
Read the entire review and try to form amental picture of how sentiment in thedocument is distributed.
Ignore anythingthat is not the opinion of the writer.2.
Try to determine the overall polarity ofthe document.
The star rating of the doc-ument can be used for this purpose.3.
If the overall polarity of the document isnegative but, most of the words in thedocument indicate positive sentiment, orvice versa, then consider the documentas thwarted.Since, identifying thwarting is a difficult taskeven for humans, we calculated the Cohen?skappa score (Cohen 1960) in order to determinethe inter annotator agreement.
It was found out to1Reviews crawled from http://www.amazon.com/863be 0.7317.
The annotators showed high agree-ment (98%) in the non-thwarted class whereasthey agreed on 70% of the thwarted documents.Out of the 1196 reviews, exactly 21 werethwarted documents, agreed upon by all annota-tors.
We used the Stanford Core NLP tools 2(Klein et al 2003, Toutanova et al 2003) forbasic NL processing.
The system was tested onthe entire dataset.Since, the data is highly skewed; we used Areaunder the Curve (AUC) for the ROC curve as themeasure of evaluation (Ling et al 2003).
TheAUC for a random baseline is expected to be50%, and the rule based approach is close to thebaseline (56.3%).Table 1 shows the results for the experimentswith the machine learning model.
We used theCVX3 library in Matlab to solve the optimizationproblem for learning weights and the LIBSVM4library to implement the svm classifier.
In orderto account for the data skew, we assign a classweight of 50 (determined empirically) to thethwarted instances and 1 for non-thwarted in-stances in the classifier.
All results were obtainedusing a 10 fold cross validation.
The same da-taset was used for this set of experiments.Loss typeforweightsPercolationtype forweightsAUC value forclassificationLinear Complete 73%Controlled 81%Hinge Complete 70%Controlled 76%Table 1: Results of the machine learning basedapproach to thwarting detectionWe see that the overall system for identificationof thwarting performs well for the weights ob-tained using the linear model with a controlledpercolation of polarity values in the ontology.The system outperforms both the random base-line as well as the rule based system.
These re-sults though great are to be taken with a pinch ofsalt.
The basic objective for creating a thwartingdetection system was to include such a module inthe general sentiment analysis framework.
Thus,using document polarity as a feature contradictsthe objective of sentiment analysis, which is tofind the document polarity.
Without the docu-2http://nlp.stanford.edu/software/corenlp.shtml3http://cvxr.com/cvx4http://www.csie.ntu.edu.tw/~cjlin/libsvm/ment polarity feature, the values drop by 10%which is not acceptable.8 Conclusions and Future WorkWe have described a system for detecting thwart-ing, based on polarity reversal between opinionon most parts of the product and opinion on theoverall product or a critical part of the product.The parts of the product are related to one anoth-er through an ontology.
This ontology guides arule based approach to thwarting detection, andalso provides features for an SVM based learningsystem.
The ML based system scores over therule based system.
Future work consists in tryingout the approach across products and across do-mains, doing better ontology harnessing from thereviews and investing and searching for distribu-tions and learning algorithms more suitable forthe problem.ReferencesBlei, D. M., Ng, A. Y., and Jordan, M. I.
2003.
LatentDirichlet alcation.
In the Journal of machineLearning research, 3, pages 993-1022.Brooke, J.
2009.
A Semantic Approach to AutomatedText Sentiment Analysis.
Ph.D. thesis, Simon Fra-ser University.Chang, C. C., and Lin, C. J.
2011.
LIBSVM: a libraryfor support vector machines.
ACM Transactions onIntelligent Systems and Technology (TIST),2(3),27.Cohen, J.
1960.
A coefficient of agreement for nomi-nal scales.
Educational and psychological meas-urement 20, no.
1, pages 37-46.Esuli, A. and Sebastiani, F. 2006.
Sentiwordnet: Apublicly available lexical resource for opinion min-ing.
In Proceedings of LREC, Volume 6, pages417-422.Hu, M. and Liu, B.
2004.
Mining and summarizingcustomer reviews.
In Proceedings of the tenthACM SIGKDD international conference onKnowledge discovery and data mining, pages 168-177.
ACM.Klein, D. and Manning, C. D. 2003.
Accurate Unlexi-calized Parsing.
In Proceedings of the 41st Meetingof the Association for Computational Linguistics,pages 423-430.Ling, C. X., Huang, J. and Zhang, H.2003.
AUC: Abetter measure than accuracy in comparing learn-ing algorithms.
In Advances in Artificial Intelli-gence, pages 329-341, Springer Berlin Heidelberg.864Liu, B., and Zhang, L. 2012.
A survey of opinionmining and sentiment analysis.
In Mining Text Da-ta (pp.
415-463).Springer US.Liu B., 2012.
Sentiment analysis and opinion min-ing.
Synthesis Lectures on Human Language Tech-nologies, 5(1), 1-167.Ohana, B. and Tierney, B.
2009.Sentiment classifica-tion of reviews using SentiWordNet.
In 9th.
IT & TConference, page 13.Pang, B., and Lee, L. 2008.
Opinion mining and sen-timent analysis.
Foundations and trends in infor-mation retrieval, 2(1-2), 1-135.Pang, B., Lee, L. and Vaithyanathan S. 2002.
Thumbsup?
Sentiment Classification using Machine Learn-ing Techniques.
In Proceedings of EMNLP pages79-86).Polpinij, J. and Ghose, A. K. 2008.An ontology-basedsentiment classification methodology for onlineconsumer reviews.
In Web Intelligence and Intelli-gent Agent Technology.Taboada, M. and Grieve, J.
2004.
Analyzing appraisalautomatically.
In Proceedings of AAAI SpringSymposium on Exploring Attitude and Affect inText (AAAI Technical Report SS# 04# 07), StanfordUniversity, CA, pages.
158-161.
AAAI Press.Toutanova, K., Klein, D., Manning, C. D. and SingerY.
2003.
Feature-Rich Part-of-Speech Taggingwith a Cyclic Dependency Network.In Proceedings of HLT-NAACL, pages 252-259.Tsur, O., Davidov, D., & Rappoport, A.
2010.
IC-WSM?A great catchy name: Semi-supervisedrecognition of sarcastic sentences in online productreviews.
In Proceedings of the fourth internationalAAAI conference on weblogs and social me-dia, pages.
162-169.Saggion, H., Funk, A., Maynard, D. and Bontcheva,K.
2007.
Ontology-based information extractionfor business intelligence.
In The SemanticWeb pages 843-856, Springer Berlin Heidelberg.Stone, P. J., Dunphy, D. C., Smith, M. S., Ogilvie, D.M.
and Associates.
1966.
The General Inquirer: AComputer Approach to Content Analysis.
The MITPress.865
