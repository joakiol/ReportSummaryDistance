Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 863?872, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsTransforming Trees to Improve Syntactic ConvergenceDavid Burkett and Dan KleinComputer Science DivisionUniversity of California, Berkeley{dburkett,klein}@cs.berkeley.eduAbstractWe describe a transformation-based learningmethod for learning a sequence of mono-lingual tree transformations that improve theagreement between constituent trees and wordalignments in bilingual corpora.
Using themanually annotated English Chinese Transla-tion Treebank, we show how our method au-tomatically discovers transformations that ac-commodate differences in English and Chi-nese syntax.
Furthermore, when transforma-tions are learned on automatically generatedtrees and alignments from the same domain asthe training data for a syntactic MT system,the transformed trees achieve a 0.9 BLEU im-provement over baseline trees.1 IntroductionMonolingually, many Treebank conventions aremore or less equally good.
For example, the En-glish WSJ treebank (Marcus et al1993) attachesverbs to objects rather than to subjects, and it at-taches prepositional modifiers outside of all quan-tifiers and determiners.
The former matches mostlinguistic theories while the latter does not, but toa monolingual parser, these conventions are equallylearnable.
However, once bilingual data is involved,such treebank conventions entail constraints on ruleextraction that may not be borne out by semanticalignments.
To the extent that there are simply di-vergences in the syntactic structure of the two lan-guages, it will often be impossible to construct syn-tax trees that are simultaneously in full agreementwith monolingual linguistic theories and with thealignments between sentences in both languages.To see this, consider the English tree in Figure 1a,taken from the English side of the English Chi-nese Translation Treebank (Bies et al2007).
Thelowest VP in this tree is headed by ?select,?
whichaligns to the Chinese verb ???.?
However, ????
also aligns to the other half of the English in-finitive, ?to,?
which, following common English lin-guistic theory, is outside the VP.
Because of thisviolating alignment, many syntactic machine trans-lation systems (Galley et al2004; Huang et al2006) won?t extract any translation rules for thisconstituent.
However, by applying a simple trans-formation to the English tree to set up the infinitiveas its own constituent, we get the tree in Figure 1b,which may be less well-motivated linguistically, butwhich corresponds better to the Chinese-mediatedsemantics and permits the extraction of many moresyntactic MT rules.In this work, we develop a method based ontransformation-based learning (Brill, 1995) for au-tomatically acquiring a sequence of tree transforma-tions of the sort in Figure 1.
Once the transformationsequence has been learned, it can be deterministi-cally applied to any parsed sentences, yielding newparse trees with constituency structures that agreebetter with the bilingual alignments yet remain con-sistent across the corpus.
In particular, we use thismethod to learn a transformation sequence for theEnglish trees in a set of English to Chinese MT train-ing data.
In experiments with a string-to-tree trans-lation system, we show resulting improvements ofup to 0.9 BLEU.A great deal of research in syntactic machinetranslation has been devoted to handling the inher-ent syntactic divergence between source and targetlanguages.
Some systems attempt to model the dif-ferences directly (Yamada and Knight, 2001; Eis-ner, 2003), but most recent work focuses on reduc-ing the sensitivity of the rule-extraction procedureto the constituency decisions made by 1-best syn-tactic parsers, either by using forest-based methods863Thefirst step is to select team membersSNPSVPVPVPTOVBZADVPVB??
?
?
?(a) BeforeThefirst step is to select team membersSNPSVPVPVPVBZ??
?
?
?TO+VBVBTO ADVP(b) AfterFigure 1: An example tree transformation merging a VB node with the TO sibling of its parent VP.
Before the trans-formation (a), the bolded VP cannot be extracted as a translation rule, but afterwards (b), both this VP and the newlycreated TO+VB node are extractable.for learning translation rules (Mi and Huang, 2008;Zhang et al2009), or by learning rules that en-code syntactic information but do not strictly ad-here to constituency boundaries (Zollmann et al2006; Marton and Resnik, 2008; Chiang, 2010).
Themost closely related MT system is that of Zhao et al(2011), who train a rule extraction system to trans-form the subtrees that make up individual translationrules using a manually constructed set of transfor-mations similar to those learned by our system.Instead of modifying the MT system to workaround the input annotations, our system modifiesthe input itself in order to improve downstreamtranslation.
Most systems of this sort learn how tomodify word alignments to agree better with the syn-tactic parse trees (DeNero and Klein, 2007; Fossumet al2008), but there has also been other work di-rectly related to improving agreement by modifyingthe trees.
Burkett et al2010) train a bilingual pars-ing model that uses bilingual agreement features toimprove parsing accuracy.
More closely related tothe present work, Katz-Brown et al2011) retrain aparser to directly optimize a word reordering metricin order to improve a downstream machine transla-tion system that uses dependency parses in a prepro-cessing reordering step.
Our system is in the samebasic spirit, using a proxy evaluation metric (agree-ment with alignments; see Section 2 for details) toimprove performance on a downstream translationtask.
However, we are concerned more generallywith the goal of creating trees that are more com-patible with a wide range of syntactically-informedtranslation systems, particularly those that extracttranslation rules based on syntactic constituents.2 AgreementOur primary goal in adapting parse trees is to im-prove their agreement with a set of external wordalignments.
Thus, our first step is to define an agree-ment score metric to operationalize this concept.Central to the definition of our agreement scoreis the notion of an extractable node.
Intuitively, anextractable English1 tree node (also often called a?frontier node?
in the literature), is one whose spanaligns to a contiguous span in the foreign sentence.Formally, we assume a fixed word alignment a ={(i, j)}, where (i, j) ?
a means that English wordi is aligned to foreign word j.
For an English span[k, `] (inclusive), the set of aligned foreign words is:fset([k, `]) = {j | ?
i : k ?
i ?
`; (i, j) ?
a}We then define the aligned foreign span as:fspan([k, `]) = [min(fset([k, `])),max(fset([k, `]))]1For expositional clarity, we will refer to ?English?
and ?for-eign?
sentences/trees, but our definitions are in no way languagedependent and apply equally well to any language pair.864The aligned English span for a given foreign span[s, t] is defined analogously:eset([s, t]) = {i | ?
j : s ?
j ?
t; (i, j) ?
a}espan([s, t]) = [min(eset([s, t])),max(eset([s, t]))]Finally, we define [k, `] to be extractable if andonly if it has at least one word alignment and itsaligned foreign span aligns back to a subspan of[k, `]:fset([k, `]) 6= ?
?
espan(fspan([k, `])) ?
[k, `]With this definition of an extractable span, we cannow define the agreement score ga(t) for an Englishtree t, conditioned on an alignment a:2ga(t) =?
[k,`]?t:|[k,`]|>1sign([k, `]) (1)Wheresign([k, `]) ={1 [k, `] is extractable?1 otherwiseImportantly, the sum in Equation 1 ranges over allunique spans in t. This is simply to make the met-ric less gameable, preventing degenerate solutionssuch as an arbitrarily long chain of unary produc-tions over an extractable span.
Also, since all indi-vidual words are generated by preterminal part-of-speech nodes, the sum skips over all length 1 spans.As a concrete example of agreement score, we canreturn to Figure 1.
The tree in Figure 1a has 6 uniquespans, but only 5 are extractable, so the total agree-ment score is 5 - 1 = 4.
After the transformation,though, the tree in Figure 1b has 6 extractable spans,so the agreement score is 6.3 Transformation-Based LearningTransformation-based learning (TBL) was origi-nally introduced via the Brill part-of-speech tag-ger (Brill, 1992) and has since been applied to a widevariety of NLP tasks, including binary phrase struc-ture bracketing (Brill, 1993), PP-attachment disam-biguation (Brill and Resnik, 1994), base NP chunk-ing (Ramshaw and Marcus, 1995), dialogue act tag-ging (Samuel et al1998), and named entity recog-nition (Black and Vasilakopoulos, 2002).2Unextractable spans are penalized in order to ensure thatspace is saved for the formation of extractable ones.The generic procedure is simple, and requiresonly four basic inputs: a set of training sentences, aninitial state annotator, an inventory of atomic trans-formations, and an evaluation metric.
First, you ap-ply the initial state annotator (here, the source oforiginal trees) to your training sentences to ensurethat they all begin with a legal annotation.
Then,you test each transformation in your inventory to seewhich one will yield the greatest improvement in theevaluation metric if applied to the training data.
Yougreedily apply this transformation to the full trainingset and then repeat the procedure, applying transfor-mations until some stopping criterion is met (usu-ally either a maximum number of transformations,or a threshold on the marginal improvement in theevaluation metric).The output of the training procedure is an orderedset of transformations.
To annotate new data, yousimply label it with the same initial state annotatorand then apply each of the learned transformationsin order.
This process has the advantage of beingquite fast (usually linear in the number of transfor-mations and the length of the sentence; for parsing,the cost will typically be dominated by the cost ofthe initial state annotator), and, unlike the learnedparameters of a statistical model, the set of learnedtransformations itself can often be of intrinsic lin-guistic interest.For our task, we have already defined the evalua-tion metric (Section 2) and the initial state annotatorwill either be the gold Treebank trees or a Treebank-trained PCFG parser.
Thus, to fully describe our sys-tem, it only remains to define the set of possible treetransformations.4 Tree TransformationsThe definition of an atomic transformation consistsof two parts: a rewrite rule and the triggering envi-ronment (Brill, 1995).
Tree transformations are bestillustrated visually, and so for each of our transfor-mation types, both parts of the definition are repre-sented schematically in Figures 2-7.
We have alsoincluded a real-world example of each type of trans-formation, taken from the English Chinese Transla-tion Treebank.Altogether, we define six types of tree transfor-mations.
Each class of transformation takes be-865A... ...B CA... ...B CB+CType: ARTICULATEArgs:A: PARENT, B: LEFT, C: RIGHT(a) Schematic?
??SOther members will arrive in two groups .?
??
?
? ?VPNP.?
??SOther members will arrive in two groups .?
??
?
? ?VPNP.NP+VP(b) Example: ARTICULATE?S, NP, VP?Figure 2: ARTICULATE transformations.A...B...C DA... ...C DType: FLATTENArgs:A: PARENT, B: TARGETA...B...D EA... ...E CType: FLATTENINCONTEXTArgs:A: PARENT, B: TARGET,C: SIBLING, left: DIRECTIONC D(a) Schematic??
?
?NPthe China Trade Promotion CouncilNML NNPNNPNNPNNPDT??
?
?NPthe China Trade Promotion CouncilNNPNNPNNPNNPDT(b) Example: FLATTENINCONTEXT?NP, NML, NNP, left?Figure 3: FLATTEN transformations.A...BC...A...B...CType: PROMOTEArgs:A: GRANDPARENT, B: PARENT,C: CHILD, left: DIRECTION(a) SchematicNP??
?
??
?INby the French player N. TaugiaNP NPPPNP??
?
??
?INby the French player N. TaugiaNPNPPP(b) Example: PROMOTE?PP, NP, NP, left?Figure 4: PROMOTE transformations.A...B C...A...B...CType: DEMOTEArgs:A: PARENT, B: DEMOTER,C: DEMOTED, left: DIRECTION......(a) Schematic?
??
?flyto Beijing on the 2ndVP?
?IN NP NPINPPVB PP?
??
?flyto Beijing on the 2ndVP?
?IN NP NPINVBPP PP(b) Example: DEMOTE?VP, PP, VB, right?Figure 5: DEMOTE transformations.866ABCD...ABC......Type: TRANSFERArgs:A: GRANDPARENT, B: AUNT,C: PARENT, D: TARGET,left: DIRECTION...D(a) Schematicserious consequences that cause lossesNPNPSBARSWHNP????
?
?JJ NNSserious consequences that cause lossesNPNP SBARS????
?
?WHNPJJ NNS(b) Example: TRANSFER?NP, NP, SBAR, WHNP, left?Figure 6: TRANSFER transformations.AB CD...AB+DC...B DType: ADOPTArgs:A: GRANDPARENT, B: AUNT,C: PARENT, D: TARGET,left: DIRECTION(a) SchematicSabor also tied with SetangonSVPPP??
?
?
?RB VBDNP ADVP???
?VPSabor also tied with SetangonSPP??
?
??RBVBDNP???
?RB+VP(b) Example: ADOPT?S, VP, ADVP, RB, right?Figure 7: ADOPT transformations.tween two and four syntactic category arguments,and most also take a DIRECTION argument thatcan have the value left or right.3 We refer to thenodes in the schematics whose categories are argu-ments of the transformation definition as participat-ing nodes.
Basically, a particular transformation istriggered anywhere in a parse tree where all partici-pating nodes appear in the configuration shown.
Theexact rules for the triggering environment are:1.
Each participating node must appear in theschematically illustrated relationship to theothers.
The non-participating nodes in theschematic do not have to appear.
Similarly, anynumber of additional nodes can appear as sib-lings, parents, or children of the explicitly illus-trated nodes.2.
Any node that will gain a new child as a re-sult of the transformation must already have atleast one nonterminal child.
We have drawn theschematics to reflect this, so this condition is3To save space, the schematic for each of these transforma-tions is only shown for the left direction, but the right version issimply the mirror image.equivalent to saying that any participating nodethat is drawn with children must have a phrasalsyntactic category (i.e.
it cannot be a POS).3.
Repeated mergings are not allowed.
That is, thenewly created nodes that result from an ARTIC-ULATE or ADOPT transformation cannot thenparticipate as the LEFT or RIGHT argument of asubsequent ARTICULATE transformation or asthe AUNT or TARGET argument of a subsequentADOPT transformation.
This is simply to pre-vent the unrestrained proliferation of new syn-tactic categories.The rewrite rule for a transformation is essentiallycaptured in the corresponding schematic.
Additionalnodes that do not appear in the schematic are gener-ally handled in the obvious way: unillustrated chil-dren or parents of illustrated nodes remain in place,while unillustrated siblings of illustrated nodes arehandled identically to their illustrated siblings.
Theonly additional part of the rewrite that is not shownexplicitly in the schematics is that if the node in thePARENT position of a TRANSFER or ADOPT trans-formation is left childless by the transformation (be-867cause the TARGET node was its only child), then it isdeleted from the parse tree.
In the case of a transfor-mation whose triggering environment appears multi-ple times in a single tree, transformations are alwaysapplied leftmost/bottom-up and exhaustively.4In principle, our transformation inventory consistsof all possible assignments of syntactic categories tothe arguments of each of the transformation types(subject to the triggering environment constraints).In practice, though, we only ever consider trans-formations whose triggering environments appear inthe training corpus (including new triggering envi-ronments that appear as the result of earlier trans-formations).
While the theoretical space of possi-ble transformations is exponentially large, the setof transformations we actually have to consider isquite manageable, and empirically grows substan-tially sublinearly in the size of the training set.5 Results and AnalysisThere are two ways to use this procedure.
One is toapply it to the entire data set, with no separate train-ing phase.
Given that the optimization has no notionof gold transformations, this procedure is roughlylike an unsupervised learner that clusters its entiredata.
Another way is to learn annotations on a sub-set of data and apply it to new data.
We choose thelatter primarily for reasons of efficiency and simplic-ity: many common use cases are easiest to managewhen annotation systems can be trained once offlineand then applied to new data as it comes in.Since we intend for our system to be used asa pre-trained annotator, it is important to ensurethat the learned transformation sequence achievesagreement score gains that generalize well to un-seen data.
To minimize errors that might be intro-duced by the noise in automatically generated parsesand word alignments, and to maximize reproducibil-ity, we conducted our initial experiments on the En-glish Chinese Translation Treebank.
For this dataset,the initial state annotations (parse trees) were man-ually created by trained human annotators, as werethe word alignments used to compute the agreement4The transformation is repeatedly applied at the lowest, left-most location of the parse tree where the triggering environmentappears, until the triggering environment no longer appears any-where in the tree.0 12 34 56 78 90 500 1000 1500 2000 2500Average Agreement ScoreImprovementNumber of TransformationsTraining DevFigure 8: Transformation results on the English ChineseTranslation Treebank.
The value plotted is the average(per-sentence) improvement in agreement score over thebaseline trees.Transfor- Total Extractable Agreementmations Spans Spans Score0 13.15 9.78 6.4010 12.57 10.36 8.1550 13.41 11.38 9.35200 14.03 11.96 9.891584 14.58 12.36 10.152471 14.65 12.35 10.06Table 1: Average span counts and agreement scores onthe English Chinese Translation Treebank developmentset.
The highest agreement score was attained at 1584transformations, but most of the improvement happenedmuch earlier.score.5 The data was divided into training/dev/testusing the standard Chinese parsing split; we trainedthe system on the training set (2261 sentences af-ter filtering out sentences with missing annotations),and evaluated on the development set (223 sentencesafter filtering).The improvements in agreement score are shownin Figure 8, with a slightly more detailed breakdownat a few fixed points in Table 1.
While the systemwas able to find up to 2471 transformations that im-proved the training set agreement score, the major-ity of the improvement, and especially the majorityof the improvement that generalized to the test set,5The annotation guidelines for the English side of this Tree-bank are similar, though not identical, to those for the WSJTreebank.8681 ARTICULATE?S,NP,VP?2 FLATTENINCONTEXT?PP,NP,IN,right?3 PROMOTE?VP,VP,VBN,left?4 ADOPT?VP,TO,VP,VB,left?5 ADOPT?PP,VBG,PP,IN,left?6 FLATTEN?VP,VP?7 ARTICULATE?VP,VBD,NP?8 FLATTENINCONTEXT?PP,NML,NNP,left?9 ARTICULATE?NP,NNP,NNS?10 ARTICULATE?S,NP,ADVP?11 TRANSFER?NP,NP,SBAR,WHNP,left?12 FLATTENINCONTEXT?NP,NML,NNP,left?13 ARTICULATE?NP,NN,NNS?14 TRANSFER?NP,NP+,,SBAR,WHNP,left?15 ADOPT?PP,IN,PP,IN,left?16 PROMOTE?S,VP,CC+VP,right?17 ARTICULATE?VP,VBZ,VBN?18 ARTICULATE?VP,VBD,PP?19 ARTICULATE?VP,MD,ADVP?20 ADOPT?PP,SYM,QP,CD,right?Table 2: The first 20 learned transformations, excludingthose that only merged punctuation or conjunctions withadjacent phrases.
The first 5 are illustrated in Figure 9.was achieved within the first 200 or so transforma-tions.
We also see from Table 1 that, though the firstfew transformations deleted many non-extractablespans, the overall trend was to produce more finelyarticulated trees, with the full transformation se-quence increasing the number of spans by more than10%.As discussed in Section 3, one advantage of TBLis that the learned transformations can themselvesoften be interesting.
For this task, some of the high-est scoring transformations did uninteresting thingslike conjoining conjunctions or punctuation, whichare often either unaligned or aligned monotonicallywith adjacent phrases.
However, by filtering outall ARTICULATE transformations where either theLEFT or RIGHT argument is ?CC?, ?-RRB-?, ?,?, or?.?
and taking the top 20 remaining transformations,we get the list in Table 2, the first 5 of which arealso illustrated in Figure 9.
Some of these (e.g.
#1,#7, #10) are additional ways of creating new spanswhen English and Chinese phrase structures roughlyagree, but many others do recover known differencesin English and Chinese syntax.
For example, manyof these transformations directly address compoundverb forms in English, which tend to align to singlewords in Chinese: #3 (past participle constructions),#4 (infinitive), #6 (all), and #17 (present perfect).We also see differences between English and Chi-nese internal NP structure (e.g.
#9, #12, #13).6 Machine TranslationThe ultimate goal of our system is to improvethe agreement between the automatically generatedparse trees and word alignments that are used astraining data for syntactic machine translation sys-tems.
Given the amount of variability between theoutputs of different parsers and word aligners (oreven the same systems with different settings), thebest way to improve agreement is to learn a trans-formation sequence that is specifically tuned for thesame annotators (parsers and word aligners) we areevaluating with.
In particular, we found that thoughtraining on the English Chinese Translation Tree-bank produces clean, interpretable rules, prelimi-nary experiments showed little to no improvementfrom using these rules for MT, primarily becauseactual alignments are not only noisier but also sys-tematically different from gold ones.
Thus, all rulesused for MT experiments were learned from auto-matically annotated text.For our Chinese to English translation experi-ments, we generated word alignments using theBerkeley Aligner (Liang et al2006) with defaultsettings.
We used an MT pipeline that conditionson target-side syntax, so our initial state annotatorwas the Berkeley Parser (Petrov and Klein, 2007),trained on a modified English treebank that has beenadapted to match standard MT tokenization and cap-italization schemes.As mentioned in Section 5, we could, in principletrain on all 500k sentences of our MT training data.However, this would be quite slow: each iteration ofthe training procedure requires iterating through alln training sentences6 once for each of the m can-didate transformations, for a total cost of O(nm)where m grows (albeit sublinearly) with n. Since the6By using a simple hashing scheme to keep track of trigger-ing environments, this cost can be reduced greatly but is stilllinear in the number of training sentences.869S... ...NP VPS... ...NP VPNP+VP(a) ARTICULATE?S,NP,VP?PP...IN...A BPP... ...A BNP IN(b) FLATTENINCONTEXT?PP,NP,IN,right?VP...VPVBN...VP...VP...VBN(c) PROMOTE?VP,VP,VBN,left?VPTO VPVB...VPTO+VB VP...TO VB(d) ADOPT?VP,TO,VP,VB,left?PPVBG PPIN...VPVBG+IN PP...VBG IN(e) ADOPT?PP,VBG,PP,IN,left?Figure 9: Illustrations of the top 5 transformations fromTable 2.most useful transformations almost by definition areones that are triggered the most frequently, any rea-sonably sized training set is likely to contain them,and so it is not actually likely that dramatically in-creasing the size of the training set will yield partic-ularly large gains.Thus, to train our TBL system, we extracted a ran-dom subset of 3000 sentences to serve as a train-ing set.7 We also extracted an additional 1000 sen-tence test set to use for rapidly evaluating agreementscore generalization.
Figure 10 illustrates the im-provements in agreement score for the automaticallyannotated data, analogous to Figure 8.
The samegeneral patterns hold, although we do see that theautomatically annotated data is more idiosyncraticand so more than twice as many transformations arelearned before training set agreement stops improv-ing, even though the training set sizes are roughlythe same.8 Furthermore, test set generalization inthe automatic annotation setting is a little bit worse,with later transformations tending to actually hurttest set agreement.For our machine translation experiments, we usedthe string-to-tree syntactic pipeline included in thecurrent version of Moses (Koehn et al2007).Our training bitext was approximately 21.8 mil-lion words, and the sentences and word alignmentswere the same for all experiments; the only differ-ence between each experiment was the English trees,for which we tested a range of transformation se-quence prefixes (including a 0-length prefix, whichjust yields the original trees, as a baseline).
Sincethe transformed trees tended to be more finely artic-ulated, and increasing the number of unique spansoften helps with rule extraction (Wang et al2007),we equalized the span count by also testing bina-rized versions of each set of trees, using the left-branching and right-branching binarization scriptsincluded with Moses.9We tuned on 1000 sentence pairs and tested on7The sentences were shorter on average than those in the En-glish Chinese Translation Treebank, so this training set containsroughly the same number of words as that used in the experi-ments from Section 5.8Note that the training set improvement curves don?t actu-ally flatten out because training halts once no improving trans-formation exists.9Binarized trees are guaranteed to have k ?
1 unique spansfor sentences of length k.870012345670 1000 2000 3000 4000 5000Average Agreement ScoreImprovementNumber of TransformationsTraining TestFigure 10: Transformation results on a subset of the MTtraining data.
The training and test sets are disjoint inorder to measure how well the learned transformation se-quence generalizes.
Once again, we plot the average im-provement over the baseline trees.
Though 5151 transfor-mations were learned from the training set, the maximumtest set agreement was achieved at 630 transformations,with an average improvement of 2.60.642 sentence pairs from the NIST MT04 and MT05data sets, using the BLEU metric (Papineni et al2001).
As discussed by Clark et al2011), the op-timizer included with Moses (MERT, Och, 2003) isnot always particularly stable, and results (even onthe tuning set) can vary dramatically across tuningruns.
To mitigate this effect, we first used the Mosestraining scripts to extract a table of translation rulesfor each set of English trees.
Then, for each ruletable, we ran MERT 11 times and selected the pa-rameters that achieved the maximum tuning BLEUto use for decoding the test set.Table 3 shows the results of our translation exper-iments.
The best translation results are achieved byusing the first 139 transformations, giving a BLEUimprovement of more than 0.9 over the strongestbaseline.7 ConclusionWe have demonstrated a simple but effective pro-cedure for learning a tree transformation sequencethat improves agreement between parse trees andword alignments.
This method yields clear improve-ments in the quality of Chinese to English trans-lation, showing that by manipulating English syn-tax to converge with Chinese phrasal structure, weimprove our ability to explicitly model the types ofTransfor- Agrmnt BLEUmations Score None Left Right0 5.36 31.66 31.81 31.8432 7.17 32.41 32.17 32.0658 7.42 32.18 32.68* 32.37139 7.81 32.20 32.60* 32.77*630 7.96 32.48 32.06 32.225151 7.89 32.13 31.84 32.12Table 3: Machine translation results.
Agreement scoresare taken from the test data used to generate Figure 10.Note that using 0 transformations just yields the originalbaseline trees.
The transformation sequence cutoffs at 32,58, and 139 were chosen to correspond to marginal train-ing (total) agreement gain thresholds of 50, 25, and 10,respectively.
The cutoff at 630 was chosen to maximizetest agreement score and the cutoff at 5151 maximizedtraining agreement score.
Column headings for BLEUscores (?None,?
?Left,?
?Right?)
refer to the type of bina-rization used after transformations.
Entries marked witha ?*?
show a statistically significant difference (p < 0.05)from the strongest (right-binarized) baseline, accordingto the paired bootstrap (Efron and Tibshirani, 1994).structural relationships between languages that syn-tactic MT systems are designed to exploit, even if welose some fidelity to the original monolingual anno-tation standards in the process.AcknowledgementsThis project is funded by an NSF graduate researchfellowship to the first author and by BBN underDARPA contract HR0011-12-C-0014.ReferencesAnn Bies, Martha Palmer, Justin Mott, and Colin Warner.2007.
English Chinese translation treebank v 1.0.Web download.
LDC2007T02.William J.
Black and Argyrios Vasilakopoulos.
2002.Language independent named entity classification bymodified transformation-based learning and by deci-sion tree induction.
In COLING.Eric Brill and Philip Resnik.
1994.
A transformation-based approach to prepositional phrase attachment dis-ambiguation.
In COLING.Eric Brill.
1992.
A simple rule-based part of speech tag-ger.
In Proceedings of the workshop on Speech andNatural Language.871Eric Brill.
1993.
Automatic grammar induction and pars-ing free text: A transformation-based approach.
InACL.Eric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: a case studyin part-of-speech tagging.
Computational Linguistics,21(4):543?565.David Burkett, John Blitzer, and Dan Klein.
2010.Joint parsing and alignment with weakly synchronizedgrammars.
In NAACL:HLT.David Chiang.
2010.
Learning to translate with sourceand target syntax.
In ACL.Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A.Smith.
2011.
Better hypothesis testing for statisticalmachine translation: controlling for optimizer instabil-ity.
In ACL:HLT.John DeNero and Dan Klein.
2007.
Tailoring wordalignments to syntactic machine translation.
In ACL.Bradley Efron and R. J. Tibshirani.
1994.
An Introduc-tion to the Bootstrap (Chapman & Hall/CRC Mono-graphs on Statistics & Applied Probability).
Chapmanand Hall/CRC.Jason Eisner.
2003.
Learning non-isomorphic tree map-pings for machine translation.
In ACL.Victoria Fossum, Kevin Knight, and Steven Abney.
2008.Using syntax to improve word alignment for syntax-based statistical machine translation.
In ACL MTWorkshop.Michel Galley, Mark Hopkins, Kevin Knight, and DanielMarcu.
2004.
What?s in a translation rule?
In HLT-NAACL.Liang Huang, Kevin Knight, and Aravind Joshi.
2006.Statistical syntax-directed translation with extendeddomain of locality.
In HLT-NAACL.Jason Katz-Brown, Slav Petrov, Ryan McDonald, FranzOch, David Talbot, Hiroshi Ichikawa, Masakazu Seno,and Hideto Kazawa.
2011.
Training a parser for ma-chine translation reordering.
In EMNLP.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In ACL.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In HLT-NAACL.Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-rice Santorini.
1993.
Building a large annotated cor-pus of English: The Penn Treebank.
ComputationalLinguistics, 19(2):313?330.Yuval Marton and Philip Resnik.
2008.
Soft syntacticconstraints for hierarchical phrase-based translation.In ACL:HLT.Haitao Mi and Liang Huang.
2008.
Forest-based transla-tion rule extraction.
In EMNLP.Franz Josef Och.
2003.
Miminal error rate training instatistical machine translation.
In ACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a method for automatic eval-uation of machine translation.
Research report, IBM.RC22176.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In HLT-NAACL.Lance A. Ramshaw and Mitchell P. Marcus.
1995.Text chunking using transformation-based learning.
InACL Workshop on Very Large Corpora.Ken Samuel, Sandra Carberry, and K. Vijay-Shanker.1998.
Dialogue act tagging with transformation-basedlearning.
In COLING.Wei Wang, Kevin Knight, and Daniel Marcu.
2007.
Bi-narizing syntax trees to improve syntax-based machinetranslation accuracy.
In EMNLP.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In ACL.Hui Zhang, Min Zhang, Haizhou Li, Aiti Aw, andChew Lim Tan.
2009.
Forest-based tree sequence tostring translation model.
In ACL-IJCNLP.Bing Zhao, Young-Suk Lee, Xiaoqiang Luo, and Liu Li.2011.
Learning to transform and select elementarytrees for improved syntax-based machine translations.In ACL:HLT.Andreas Zollmann, Ashish Venugopal, Stephan Vogel,and Alex Waibel.
2006.
The CMU-AKA syntax aug-mented machine translation system for IWSLT-06.
InIWSLT.872
