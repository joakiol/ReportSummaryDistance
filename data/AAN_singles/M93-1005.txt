DOMAIN AND LANGUAGE EVALUATION RESULTSMary Ellen Okurowsk iDepartment of Defens e9800 Savage Road, Fort Meade, Md.20755meokuro@afterlife.ncsc.
milINTRODUCTIONThe Fifth Message Understanding Conference (MUC-5) focused on the task of data extraction for tw odistinctly different applications, one within the domain of joint ventures (JV) and the other within the domain o fmicroelectronics (ME) .
For each application, the task could be performed in either English and/or Japanese, givingfour combinations : English Joint Ventures, Japanese Joint Ventures, FngJish Microelectronics, and JapaneseMicroelectronics .Interpreting the evaluation results across domains and within a single domain between languages is affecte dby a number of factors.
Differences in task focus, complexity, and domain technicality make it impossible to appl yinferential statistics between domains .
In addition, even though the task and the template design were the same acrosslanguages within a single domain, differences in the types of text sources for each language and accompanyin gvariations in template fills and fill rules by language also make it impossible to apply inferential statistics between thelanguage pairs .
Moreover, there is considerable variation in the participants' level of effort and funding, and not all o fthe participants worked in multiple languages and/or multiple domains .In light of these factors, I will present descriptive statistics comparing error per response fill to address th efollowing questions : (1) For both languages, what is the performance difference between domains?
(2) Betwee ndomains, what are performance differences for the single shared object and for unattempted slots?
(3) For bothdomains, what is the performance difference between languages?
(4) For a single domain, what are representativ edifferences at object and slot levels between English and Japanese?
The discussion of domain and language difference swill center upon general factors that influence performance in information extraction : the information defined forextraction, the information available in a corpus for extraction, and the way in which information is presented withi na text .DOMAIN PERFORMANC ESummary scores by domain for error per response fill (official All-objects scoring) averaged for MUC-5 site sin Table 1 indicate a slightly better performance in microelectronics than in joint ventures for both languages .
tThi sperformance characteristic is also reflected in the individual languages within domains in the summary of languag eperformance in Table 4 .LANGUAGE JOINT VENTURE MICROELECTRONICSAVERAGE RANGE AVERAGE RANGEENGLISH/JAPANESE 74 54-84 70 58-86TABLE 1 : ERROR AVERAGE/RANGE BY DOMAINS FOR MUC-5 SITES1 .
Averaged scores reported in this paper for MUC-5 sites are based upon 12 English JV, 5 Japanese JV, 7English ME, and 4 Japanese ME sites .
Scorns for the GE/CMU TEXTRACT system and the TRW DEFT sys-tem are not included.45This performance difference by domain can be interpreted by examining differences between the domains i nthe information defined for extraction .
Domain differences for the only object type, ENTITY, that was defined forboth domains will be presented first, followed by differences for unattempted slots, i .e.
those slots that some or alsystems left unfilled .Shared Slots in ENTITY ObjectDefining information extraction tasks entails identifying (1) the pieces of information to be extracted, (2) ho wthe pieces are related, and (3) how those pieces are to be represented in a database.
The two domains in MUC-5 definedifferent tasks and so vary along those three parameters, which are collectively called the "reporting conditions ."
Thisvariation in reporting conditions must be taken into account when examining results for a shared object extracted i ntwo different domains.
For example, in scoring performance for theENTITY object in the JV and ME domains, whatis being evaluated is not just how systems extract entities, but how systems extract entities given the reportin gconditions of the domain.
Whereas in the JV domain, systems mainly extract principals in tie-ups or newly forme dcompanies, in the ME domain, they extract entities in terms of their relation to processes as developers, manufacturers,distributors, purchasers, or users of microelectronics technology .Table 2 presents the error per response fill for the shared slots for the ENTITYobject for the three TIPSTERsites that participated in both languages for both domains .
These scores have been averaged across the two languages .In general, sites have a slightly better performance for the four slots in the JV domain than in the ME domain .
Theeffect of reporting conditions for the two domains may be evident here .
In the JV domain, the identification of the tie -up event is the central task .There are only two role distinctions to be made for the entities involved as either a principa lin the tie-up or a newly formed joint venture company.
In contrast, in the ME domain, the identification of the processand its attributes is the central task.
Entity recognition, though pre-requisite to instantiate an ME capability, is actuall yin many ways auxiliary to the ME process itself .
In addition, the entity must be assigned one of four different roles(developer, manufacturer, distributor, or purchaser/user), where no one slot dominates in terms of the number o fexpected fills .
Thus, the entity recognition task in the ME domain is in some ways harder than in the JV domain .BBN GE/CMU/MM NMSUBRANDEISJV ME JV ME JV MENAME 52 55 41 52 58 5 8LOCATION 93 94 61 72 80 79NATIONALITY 83 89 68 78 79 95TYPE 44 52 35 47 51 54TABLE 2: ERROR ENTITY OBJECT SLOTS AVERAGED ACROSS LANGUAGE SFOR THREE TIPSTER SITES ,Unattempted SlotsThe effect of differences in the information defined for extraction on performance differences between thetwo domains can also be examined by reviewing unattempted slots .
2Here, unattempted slots are defined as slots whereactual is 0 and possible is greater than 0.
Although a wide range of factors affect whether a site attempts a particula rslot (e .g ., its difficulty, fill frequency, clarity of definition in fill rules, or stability of definition in fill rules versions) ,2 .
This approach views a task independent of evaluation and its affect upon system development strategies.It ignores the fact that some objects appear more often and therefore contribute more to evaluation scores ,which may shape the development efforts of sites seeking to maximize their scores by concentrating on hig hpay-off slots while ignoring slots with little pay-off in scoring .46for this discussion I will take the position that for each application a task is defined in terms of a certain number o fobjects with slots .
A task requires a certain amount of work and each slot receives development effort .
In the Ndomain, there are ten objects with a total of 44 scored slots ; in the ME domain there are nine objects with a total of 4 4scored slots.Review of unattempted slots in each domain allows us to determine how sites redefine the task in each domai nby eliminating some subset of objects or slots from the task .
Table 3 below indicates the task reduction averaged forMUC-5 sites for the two domains, calculated for each site by dividing the number of unattempted slots by the tota lnumber of slots .
Even though performance differences for the ENTITY object indicate a somewhat better entit yrecognition for the JV domain (given reporting conditions) than for the ME domain, clearly, sites in the N domain ar emore likely to reduce the task definition regardless of language.
In both languages for N. sites mainly redefine thetask either by not filling slots in the Activity, Facility .
Revenue, and Time Objects, or by not instantiating the objec tat all .
In both languages for the ME domain, sites redefine the task mainly by not filling a subset of slots in the Etching .Packaging, and Equipment objects .
There are no cases in ME where an entire object is not attempted .This discrepancy in the extent of task redefinition between domains offers evidence of differences in tas kcomplexity that help us interpret the performance differences between domains .
The greater likelihood for sites in theJV domain to eliminate slots and/or objects offers support to the view that the task is more complex for the N domai nthan for the ME domain .
The JV template design is a more complex structure, with a deeper set of embedded objects .Most of the unattempted N slots are in the more deeply nested objects .
The exception to this, the Activity object, i snot part of the core template task for N.Discrepancies in development effort between domains for the TIPSTER sites further support the apparen tgreater complexity of the JV task .
Notwithstanding the later start date for the ME domain and the more drastic revisionprocess for the N domain, all of the TIPSTER sites reduced the N task more than the ME task.
Moreover, the factthat three of the four sites working in both domains estimate that they expended considerably more development efforton N than ME may further support that view .DOMAINENG/JPN ENG JPNAVG AVG RANGE AVG RANGEJOINT VENTURE 29 35 2-70 17 9-20MICROF.I .FCTRONICS 13 17 0-30 6 0-12TABLE 3 : TASK REDUCTION (PERCENT) BY DOMAIN/LANGUAGE FOR MUC-5 SITE SLANGUAGE PERFORMANCESummary scores by language for error per response fill (official All-Objects scoring) averaged for MUC- 5sites in Table 4 indicate a better performance in Japanese than in English for both domains .
This performancecharacteristic is also reflected in the individual domains .LANGUAGE JV/ME JOINT VENTURE MICROFI .FCTRONICSENGLISH 75 77 73JAPANESE 65 66 65TABLE 4: ERROR SUMMARY AVERAGE BY LANGUAGE FOR MUC-5 SITE SThis performance difference by language can be interpreted by analyzing how information availability (i .e .
,the amount of data of a given kind in the text that can be extracted) and information presentation (i .e ., the manner inwhich different kinds of information are expressed) reflect the similarities and differences in evaluation results47between the two languages .
Language differences by object and slot will be presented first for the ME domain and thenfor the JV domain .Microelectronics Domain: Impact of Information AvailabilityEvaluation results from the ME domain illustrate how the amount of information available in the corpu saffects performance .
In the ME domain, the application is directed at tracking microelectronics capabilities asevidenced in advances in four specific chip fabrication processes (lithography, layering, etching, and packaging) .Identifying one of these processes associated with some entity triggers the tracking .
Each of the four process object sis composed of a set of process-specific slots as well as a set of process-general slots shared by all four objects--Type ,Device, Equipment slots.
Error per response fill averaged by language for MUC-5 sites for the four process object sand their slots is presented in Tables 5-8 .LITHOGRAPHY SLOT I ENG JPNTYPE 66 1 58DEVICE 78 1 8 3EQUIPMENT 69 5 8GRANULARITY 94 89TABLE 5: ERROR FOR LITHOGRAPHY OBJECT BY LANGUAGE AVERAGED FOR MUC-5 SITESLAYERING SLOT ENG JPNTYPE 58 52DEVICE 87 82EQUIPMENT 76 69FILM 80 97TEMPERATURE 88 75TABLE 6: ERRORFOR LAYERING OBJECT BY LANGUAGE AVERAGED FOR MUC-5 SITE SETCHING SLOTiTYPEDEVICE8474EQUIP755 7TABLE 7: ERROR FOR ETCHING OBJECT BY LANGUAGE AVERAGED FOR MUC-5 SITE SENG JPN71 7548ETCHING SLOTENGJPNETCHANT83 FILM8678GRAN9186TEMP100 TABLE 7: ERROR FOR ETCHING OBJECT BY LANGUAGE AVERAGED FOR MUC-5 SITESPACKAGING ENG JPNTYPE 68 5 3DEVICE 83 6 7EQUIPMENT 88PITCH 94MATERIAL 74 7 3PI /COUNT 62 34UNITS 70BONDING 87 ---TABLE 8: ERROR FOR PACKAGING OBJECT BY LANGUAGE AVERAGED FOR MUC-5 SITE SFor both languages error per response fill is considerably lower for most of the process-general slots than forthe process-specific slots .
This discrepancy can be traced to the fact that similar types of information for the proces sobjects are available in both languages and similar development strategies are employed : Emphasize high-frequenc yslots and de-emphasize low-frequency slots.
Process-specific slots contribute significantly less to the total objec tscores than do process-general slots .
In EME, process-specific slots in lithography, layering, and etching onl ycomprise around 25% of the total object, and in JME for the same objects less than 20% .
The same frequency patternoccurs in the development data; process-specific slots have a lower frequency of occurrence than the process-genera lslots.
Note also that DEVICE and EQUIPMENT slots are pointers to other objects (with more slots) and the TYPE slotis a required slot that is indicative of the actual existence of a particular process within a text .
Since information is morelikely to be available for the process-general slots in both languages, more effort is directed at these higher pay-offslots than for the process-specific slots.This accounts for the better performance on process-specific slots in bot hlanguages .But what accounts for the better Japanese than English performance in the EME domain?
The Packagingobject provides the fast clue--differences in the amount of information between Japanese and English.
Table 8indicates that no test data are available for three of the process-specific slots for Japanese .
In comparison to Japanese,the number of possible fills in the test set for English is considerably higher on all slots, not just these three ; evenfactoring in the ratio of Japanese to English articles cannot account for this discrepancy .
The development data alsoreflect this difference.
Even though the task remained constant for these two languages in this domain, the type of dat aavailable for extraction for the Packaging object obviously differed for the two language pairs .
There were simplyfewer extractable items and thus fewer opportunities for error.The amount of extractable items within a text affects the degree of difficulty of managing extractable items .In a single text, managing all the data elements associated with different multiple processes (i .e .
multiple MEcapabilities) is more difficult than managing only data elements associated with a single process .
The English test se tcontained a higher proportion of texts with multiple processes (44%) than the Japanese test set (31%) .The test sets alsodiffered in the distribution of the types of multiple processes occurring with a text, e .g .
whether a single text contains49multiple processes of the same type or a combination of different process types.
For the subset of texts containingmultiple processes, Table 9 compares the percent distribution for the types of multiple processes .
While the Japanesetest set is more likely to contain a text with multiple layering or multiple lithography processes, the English test set ismore likely to contain multiple packaging processes and combinations of process types .The average number ofprocesses within a single text for layering, lithography, and etching types differs little across languages, but texts withmultiple packaging processes contain twice as many processes in English as in Japanese .LANGUAGEPROCESS TYPE MULTIPLEPROCES STYPE SMULTIPLELAYERINGMULTIPLELITHOGRAPHYMUTLIPLEETCHINGMULTIPLEPACKAGINGENGLISH 13 30 3 26 28JAPANESE 23 42 3 13 19TABLE 9 : PERCENT OF MULTIPLE PROCESSES IN TEST SUBSETTable 10 compares the average error per response fill for texts containing multiple processes with text scontaining a single process for TIPSTER sites .With the exception of the GE/CMU/MIVI performance in Japanese ,performance for all sites on texts with multiple processes was lower than on the texts with a single process .That ahigher percentage of English test set texts contained multiple processes negatively affected the performance.
Eventhough the Japanese test set contained more texts with multiple processes of the same type (and, in fact, an averagelower performance on those text than on texts with multiple process types), the effect was ameliorated by the lowe rdistribution of texts containing multiple processes in the Japanese test set .
In other words, the greater likelihood o fmultiple processes within a single text in English (i.e.
greater amount of extractable items) and the accompanying datamanagement problems contributed to the weaker performance in Fnglish.ENGLISH JAPANESESITE MULTIPLEPROCESSESSINGLEPROCESSMULTIPLEPROCESSESSINGLEPROCESSBBN 63 57 71 60GE/CMU/MM 59 53 47 46NMSU/Brandeis 74 67 63 54TABLE 10: AVERAGE ERROR FOR MULTIPLE PROCESES VS .
SINGLE PROCES SIN A SINGLE TEXT FOR TIPSTER SITE SJoint Ventures Domain : Impact of Information PresentationEvaluation results from the JV domain illustrate the impact of information presentation .
The way in whichinformation is expressed in a single domain for two languages may differ.
If texts in one language are more or les sformulaic in structure and represent domain concepts in more or less standardized ways, then the texts in that languageare more homogeneous in terms of discourse structure and terminology.
As a result, texts in that language may be mor eeasily exploited for information extraction than a more heterogeneous text corpus in a different language, even thoug hthe domain and application are the same.
This appears to be the case for the JV domain for Japanese and English .In the JV domain, the application is directed at tracking tie-ups among entities.
Identifying entities engage din some business activity in a tie-up relationship triggers the tracking .
Error per response fill data by language averaged50for MUC-5 sites for slots indicative of this identification are presented in Table 1 1JOINT VENTURE OBJECT SLOT ENG JPNTemplate Content 51 40Tie-up Relationship Entity 67 5 3Entity Name 71 49Entity Relationship Entity1 70 5 3Entity2 88 86Relationship2-1 76 46Industry Type 77 69TABLE 11 : ERROR JV SLOTS BY LANGUAGE AVERAGED FOR MUC-5 SITESIn general, the performs	 cE characteristic of lower Japanese error per response fill is consistent across theslots in Table 11 .
Systems perform better in Japanese in identifying the tie-up itself, participants in the tie-up, thei rrelationship, and industry of the tie-up activity.
This performance characteristic appears to be the result of the way i nwhich information is presented in the Japanese text .Preliminary analysis of the Japanese test set indicates that 60 percent or more of the articles have aprototypical text structure and that structure lends itself to a proficient extraction methodology .
Typically, an articlecontains one tie-up, and the relevant tie-up occurs in the first few sentences .
Moreover, the tie-up signal ischaracterized by a stereotypical pattern as defined below :X wa Y to.
.
.
.teikei shita to .
.
.
.happyo shitaIn this pattern, X and Y are tie-up principals with the verb phrase "teikei shita" indicating a tie-up relationship .The keyelement is the topic marker "wa."
That marker sets the stage for the entity to be the protagonist throughout the tex tand, in fact, for any other tie-ups mentioned in the article where only one of the entities is named .
This prototypicalstructure gives the Japanese systems a headstart by providing a pattern into which missing or seemingly irrelevan tinformation may later be inserted.
In short, the presentation of the information in Japanese may facilitate extractio nfills throughout the template and therefore may lead to better overall performance .CONCLUSIONIn general, evaluation results indicate a slightly better performance in the ME domain than in the JV domai nand a better performance in Japanese than in English in both domains .
This paper interprets these differences in term sof three formative factors in information extraction : information definition, information availability, and informatio npresentation .
Understanding performance differences from this perspective helps focus the examination on th einformation extraction problem rather than on dangerous, application-independent generalizations about domains andlanguages .ACKNOWLEDGEMENT SI would like to acknowledge invaluable database support from Terry Hand at the Department of Defense, i nproviding the data that formed the backbone of the arguments in this paper .
I would also like to acknowledge insights3 .
Steve Maiorano, ORD, is preparing a paper to analyze system performance in the Japanese joint ventureapplication to appear in the Proceedings from the TIPSTER Text Program, Phase One .
His initial research ha sled to the definition of the prototypical structure and interpretation of its impact on evaluation results .5 1and critique from Beth Sundheim, NRaD, in editing this paper, and in particular in shaping my argument on theimpact on performance of the amount of information .52
