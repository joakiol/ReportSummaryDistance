Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 85?89,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsUsing Rejuvenation to Improve Particle Filtering for Bayesian WordSegmentationBenjamin Bo?rschinger*?benjamin.borschinger@mq.edu.auMark Johnson*mark.johnson@mq.edu.au*Department of ComputingMacquarie UniversitySydney, Australia?Department of Computational LinguisticsHeidelberg UniversityHeidelberg, GermanyAbstractWe present a novel extension to a recently pro-posed incremental learning algorithm for theword segmentation problem originally intro-duced in Goldwater (2006).
By adding rejuve-nation to a particle filter, we are able to consid-erably improve its performance, both in termsof finding higher probability and higher accu-racy solutions.1 IntroductionThe goal of word segmentation is to segment astream of segments, e.g.
characters or phonemes,into words.
For example, given the sequence?youwanttoseethebook?, the goal is to recover thesegmented string ?you want to see the book?.
Themodels introduced in Goldwater (2006) solve thisproblem in a fully unsupervised way by defining agenerative process for word sequences, making useof the Dirichlet Process (DP) prior.Until recently, the only inference algorithmapplied to these models were batch MarkovChain Monte Carlo (MCMC) sampling algorithms.Bo?rschinger and Johnson (2011) proposed a strictlyincremental particle filter algorithm that, however,performed considerably worse than the standardbatch algorithms, in particular for the Bigram model.We extend that algorithm by adding rejuvenationsteps and show that this leads to considerable im-provements, thus strengthening the case for particlefilters as another tool for Bayesian inference in com-putational linguistics.The rest of the paper is structured as follows.
Sec-tions 2 and 3 provide the relevant background aboutword segmentation and previous work.
Section 4 de-scribes our algorithm.
Section 5 reports on an ex-perimental evaluation of our algorithm, and section6 concludes and suggests possible directions for fu-ture research.2 Model descriptionThe Unigram model assumes that words in a se-quence are generated independently whereas the Bi-gram model models dependencies between adjacentwords.
This has been shown by Goldwater (2006) tomarkedly improve segmentation performance.
Weperform experiments on both models but, for rea-sons of space, only give an overview of the Unigrammodel, referring the reader to the original papers formore detailed descriptions.
(Goldwater, 2006; Gold-water et al, 2009)A sequence of words or utterance is generated bymaking independent draws from a discrete distribu-tion over words, G. As neither the actual ?true?words nor their number is known in advance, G ismodelled as a draw from a DP.
A DP is parametrizedby a base distribution P0 and a concentration param-eter ?.
Here, P0 assigns a probability to every possi-ble word, i.e.
sequence of segments, and ?
controlsthe sparsity of G; the smaller ?, the sparser G tendsto be.To computationally cope with the unboundednature of draws from a DP, they can be ?inte-grated out?, yielding the Chinese Restaurant Process(CRP), an infinitely exchangeable conditional pre-dictive distribution.
The CRP also provides an in-tuitive generative story for the observed data.
Eachgenerated word token corresponds to a customer sit-85ting at one of the unboundedly many tables in animaginary Chinese restaurant.
Customers choosetheir seats sequentially, and they sit either at an al-ready occupied or a new table.
The former hap-pens with probability proportional to the number ofcustomers already sitting at a table and correspondsto generating one more token of the word type allcustomers at a table instantiate.
The latter happenswith probability proportional to ?
and correspondsto generating a token by sampling from the base dis-tribution, thus also determining the type for all po-tential future customers at the new table.Given this generative process, word segmentationcan be cast as a probabilistic inference problem.
Fora fixed input, in our case a sequence of phonemes,our goal is to determine the posterior distributionover segmentations.
This is usually infeasible to doexactly, leading to the use of approximate inferencemethods.3 Previous WorkThe ?standard?
inference algorithms for the Uni-gram and Bigram model are MCMC samplers thatare batch algorithms making multiple iterations overthe data to non-deterministically explore the statespace of possible segmentations.
If an MCMC algo-rithm runs long enough, the probability of it visitingany specific segmentation is the probability of thatsegmentation under the target posterior distribution,here, the distribution over segmentations given theobserved data.The MCMC algorithm of Goldwater et al (2009)is a Gibbs sampler that makes very small movesthrough the state space by changing individual wordboundaries one at a time.
An alternative MCMC al-gorithm that samples segmentations for entire utter-ances was proposed by Mochihashi et al (2009).Below, we correct a minor error in the algorithm, re-casting it as a Metropolis-within-Gibbs sampler.Moving beyond MCMC algorithms, Pearl et al(2010) describe an algorithm that can be seen asa degenerate limiting case of a particle filter withonly one particle.
Their Dynamic ProgrammingSampling algorithm makes a single pass through thedata, processing one utterance at a time by samplinga segmentation given the choices made for all pre-vious utterances.
While their algorithm comes withno guarantee that it converges on the intended pos-terior distribution, Bo?rschinger and Johnson (2011)showed how to construct a particle filter that isasymptotically correct, although experiments sug-gested that the number of particles required for goodperformance is impractically large.This paper shows how their algorithm can be im-proved by adding rejuvenation steps, which we willdescribe in the next section.4 A Particle Filter with RejuvenationThe core idea of a particle filter is to sequentiallyapproximate a target posterior distribution P by Nweighted point samples or ?particles?.
Each parti-cle is updated one observation at a time, exploitingthe insight that Bayes?
Theorem can be applied re-cursively, as illustratively shown for the case of cal-culating the posterior probability of a hypothesis Hgiven two observations O1 and O2:P (H|O1) ?
P (O1|H)P (H) (1)P (H|O1, O2) ?
P (O2|H)P (H|O1) (2)If the observations are conditionally independentgiven the hypothesis, one can simply take the poste-rior at time step t as the prior for the posterior updateat time step t+ 1.Here, each particle corresponds to a specific seg-mentation of the data observed so far, or more pre-cisely, the specific CRP seating of word tokens inthis segmentation; we refer to this as its history.
Itsweight indicates how well a particle is supported bythe data, and each observation corresponds to an un-segmented utterance.
With this, the basic particlefilter algorithm can be described as follows: Beginwith N ?empty?
particles.
To get the particles at timet+1 from the particles at time t, update each particleusing the observation at time t+1 as follows: samplea segmentation for this observation, given the parti-cle?s history, then add the words in this segmentationto that history.
After each particle has been updated,their weights are adjusted to reflect how well theyare now supported by the observations.
The set ofupdated and reweighted particles constitutes the ap-proximation of the posterior at time t+ 1.To overcome the problem of degeneracy (the sit-uation where only very few particles have non-negligible weights), Bo?rschinger and Johnson use86resampling; basically, high-probability particles arepermitted to have multiple descendants that canreplace low-probability particles.
For reasons ofspace, we refer the reader to Bo?rschinger and John-son (2011) for the details of these steps.While necessary to address the degeneracy prob-lem, resampling leads to a loss of sample diversity;very quickly, almost all particles have an identicalhistory, descending from only a small number of(previously) high probability particles.
With a strictonline learning constraint, this can only be counter-acted by using an extremely large number of parti-cles.
An alternative strategy which we explore hereis to use rejuvenation; the core idea is to restoresample diversity after each resampling step by per-forming MCMC resampling steps on each particle?shistory, thus leading to particles with different his-tories in each generation, even if they all have thesame parent.
(e.g., Canini et al (2009)) This makesit necessary to store previously processed observa-tions and thus no longer qualifies as online learn-ing in a strict sense, but it still yields an incrementalalgorithm that learns as the observations arrive se-quentially, instead of delaying learning until all ob-servations are available.In our setting, rejuvenation works as follows.
Af-ter each resampling step, for each particle the algo-rithm performs a fixed number of the following re-juvenation steps:1. randomly choose a previously observed utter-ance2.
resample the segmentation for this utteranceand update the particle accordinglyFor the resampling step, we use Mochihashi et al(2009)?s algorithm to efficiently sample segmenta-tions for an unsegmented utterance o, given a se-quence of n previously observed words W1:n. Asthe CRP is exchangeable, during resampling we cantreat every utterance as if it were the last, makingit possible to use this algorithm for any utterance,irrespective of its actual position in the data.
Cru-cially, however, the distribution over segmentationsthat this algorithm samples from is not the true pos-terior distribution P (?|o, ?,W1:n) as defined by theCRP, but a slightly different proposal distributionQ(?|o, ?,W1:n) that does not take into account theintra-sentential word dependencies for a segmenta-tion of o.
It is precisely because we ignore these de-pendencies that an efficient dynamic programmingalgorithm is possible, but because Q is differentfrom the target conditional distribution P , our algo-rithm that uses Q instead of P needs to correct forthis.
In a particle filter, this is done when the par-ticle weights are calculated (Bo?rschinger and John-son, 2011).
For an MCMC algorithm or our rejuve-nation step, a Metropolis-Hastings accept/reject stepis required, as described in detail by Johnson et al(2007) in the context of grammatical inference.1In our case, during rejuvenation an utterance uwith current segmentation s is reanalyzed as fol-lows:?
remove all the words contained in s from theparticle?s current state L, yielding state L??
sample a proposal segmentation s?
for u fromQ(?|u, L?, ?
), using Mochihashi et al (2009)?sdynamic programming algorithm?
calculate m = min{1, P (s?|L?,?)Q(s|L?,?
)P (s|L?,?)Q(s?|L?,?)}?
with probability m, accept the new sample andupdate L?
accordingly, else keep the originalsegmentation and set the particle?s state backto LThis completes the description of our extension tothe algorithm.
The remainder of the paper empiri-cally evaluates the particle filter with rejuvenation.5 ExperimentsWe compare the performance of a batch Metropolis-Hastings sampler for the Unigram and Bigrammodel with that of particle filter learners both withand without rejuvenation, as described in the previ-ous section.
For the batch samplers, we use simu-lated annealing to facilitate the finding of high prob-ability solutions, and for the particle filters, we com-pare the performance of a ?degenerate?
1-particlelearner with a 16-particle learner in the rejuvenationsetting.To get an impression of the contribution of par-ticle number and rejuvenation steps, we compare1Because Mochihashi et al (2009)?s algorithm samples di-rectly from the proposal distribution without the accept-rejectstep, it is not actually sampling from the intended posterior dis-tribution.
Because Q approaches the true conditional distribu-tion as the size of the training data increases, however, theremay be almost no noticeable difference between using and notusing the accept/reject step, though strictly speaking, it is re-quired to guarantee convergence to the the target posterior.87Unigram BigramTF logProb TF logProbMHS 50.39 -196.74 70.93 -237.24PF1 55.82 -248.21 49.43 -265.40PF16 62.34 -239.22 50.14 -262.34PF1000 64.11 -234.87 57.88 -254.17PF1,100 63.17 -245.32 66.88 -257.65PF16,100 68.05 -235.71 70.05 -251.66PF1,1600 77.06 -228.79 74.47 -249.78Table 1: Results for both the Unigram and the Bigrammodel.
MHS is a Metropolis-Hastings batch sampler.PFx is a particle filter with x particles and no rejuve-nation.
PFx,s is a particle filter with x particles and srejuvenation steps.
TF is token f-score, logProb is thelog-probability (?103) of the training-data at the end oflearning.
Less negative logProb indicates a better solu-tion according to the model, higher TF indicates a betterquality segmentation.
All results are averaged across 4runs.
Results for the 1000 particle setting are taken fromBo?rschinger and Johnson (2011).the 16-particle learner with rejuvenation with a 1-particle learner that performs 16 times as many re-juvenation samples.
For comparison, we also citeprevious results for the 1000-particle learners with-out rejuvenation reported in Bo?rschinger and John-son (2011), using their choice of parameters to allowfor a direct comparison: ?
= 20 for the Unigrammodel, ?0 = 3000, ?1 = 100 for the Bigram model,and we use their base-distribution which differs fromthe one described in Goldwater et al (2009) in that itdoesn?t assume a uniform distribution over segmentsin the base-distribution but puts a Dirichlet Prior onit.We apply each learner to the Bernstein-Ratnercorpus (Brent, 1999) that is standardly used inthe word segmentation literature, which consistsof 9790 unsegmented and phonemically transcribedchild-directed speech utterances.
We evaluate eachalgorithm in two ways: inference performance, forwhich the final log-probability of the training datais the criterion, and segmentation performance, forwhich we consider token f-score to be the best mea-sure, since it indicates how well the actual word to-kens in the data are recovered.Note that these twomeasures can diverge, as previously documented forthe Unigram model (Goldwater, 2006) and, less so,for the Bigram model (Pearl et al, 2010).
Table 1gives the results for our experiments.For both models, adding rejuvenation alwaysimproves performance markedly as compared tothe corresponding run without rejuvenation both interms of log-probability and segmentation f-score.Note in particular that for the Bigram model, us-ing 16 particles with 100 rejuvenation steps leads toan improvement in token f-score of more than 10%points over 1000 particles without rejuvenation.Comparing the 1-particle learner with 1600 reju-venation steps to the 16-particle learner with 100 re-juvenation steps, for both models the former outper-forms the latter in both log-probability and token f-score.
This suggests that if one has to trade-off par-ticle number against rejuvenation steps, one may bebetter off favouring the latter.Despite the dramatic improvement over not us-ing rejuvenation, there is still a considerable gapbetween all the incremental learners and the batchsampling algorithm in terms of log-probability.
Asimilar observation was made by Johnson and Gold-water (2009) for incremental initialisation in wordsegmentation using adaptor grammars.
Their batchsampler converged on higher token f-score but lowerprobability solutions in some settings when initial-ized in an incremental fashion as opposed to ran-domly.
We agree with their suggestion that this maybe due to the ?greedy?
character of an incrementallearner.6 Conclusion and outlookWe have shown that adding rejuvenation to a par-ticle filter improves segmentation scores and log-probabilities.
Yet, our incremental algorithm stillfinds lower probability but high quality token f-scores compared to its batch counterpart.
Whilein principle, increasing the number of rejuvenationsteps and particles will make this gap smaller andsmaller, we believe the existence of the gap to beinteresting in its own right, suggesting a general dif-ference in learning behaviour between batch and in-cremental learners, especially given the similar re-sults in Johnson and Goldwater (2009).
Furtherresearch into incremental learning algorithms mayhelp us better understand how processing limitationscan affect learning and why this may be beneficialfor language acquisition, as suggested, for example,in Newport (1988).88ReferencesBenjamin Bo?rschinger and Mark Johnson.
2011.
A parti-cle filter algorithm for bayesian wordsegmentation.
InProceedings of the Australasian Language TechnologyAssociation Workshop 2011, pages 10?18, Canberra,Australia, December.Michael R. Brent.
1999.
An efficient, probabilisticallysound algorithm for segmentation and word discovery.Machine Learning, 34(1-3):71?105.Kevin R. Canini, Lei Shi, and Thomas L. Griffiths.
2009.Online inference of topics with latent Dirichlet aloca-tion.
In David van Dyk and Max Welling, editors, Pro-ceeings of the 12th International Conference on Arti-ficial Intelligence and Statistics (AISTATS), pages 65?72.Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2009.
A bayesian framework for word segmen-tation: Exploring the effects of context.
Cognition,112(1):21?54.Sharon Goldwater.
2006.
Nonparametric Bayesian Mod-els of Lexical Acquisition.
Ph.D. thesis, Brown Uni-versity.Mark Johnson and Sharon Goldwater.
2009.
Improv-ing nonparametric bayesian inference: Experiments onunsupervised word segmentation with adaptor gram-mars.
In Proceedings of Human Language Technolo-gies: The 2009 Annual Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics, Boulder, Colorado.Mark Johnson, Thomas L. Griffiths, and Sharon Goldwa-ter.
2007.
Bayesian inference for pcfgs via markovchain monte carlo.
In Proceedings of Human Lan-guage Technologies 2007: The Conference of theNorth American Chapter of the Association for Com-putational Linguistics.Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda.2009.
Bayesian unsupervised word segmentation withnested pitman-yor language modeling.
In Proceedingsof the Joint Conference of the 47th Annual Meetingof the ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP, pages100?108, Suntec, Singapore, August.
Association forComputational Linguistics.Elissa L Newport.
1988.
Constraints on learning andtheir role in language acquisition: Studies of the acqui-sition of american sign language.
Language Sciences,10:147?172.Lisa Pearl, Sharon Goldwater, and Mark Steyvers.
2010.Online learning mechanisms for bayesian models ofword segmentation.
Research on Language and Com-putation, 8(2):107?132.89
