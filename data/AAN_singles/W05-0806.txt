Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 41?48,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Augmenting a Small Parallel Text with Morpho-syntactic LanguageResources for Serbian-English Statistical Machine TranslationMaja Popovic?, David Vilar, Hermann NeyLehrstuhl fu?r Informatik VIComputer Science DepartmentRWTH Aachen UniversityD-52056 Aachen, Germany{popovic,vilar,ney}@informatik.rwth-aachen.deSlobodan Jovic?ic?, Zoran ?Saric?Faculty of Electrical EngineeringUniversity of BelgradeSerbia and Montenegrojovicic@etf.bg.ac.yuAbstractIn this work, we examine the quality ofseveral statistical machine translation sys-tems constructed on a small amount ofparallel Serbian-English text.
The mainbilingual parallel corpus consists of about3k sentences and 20k running words froman unrestricted domain.
The translationsystems are built on the full corpus as wellas on a reduced corpus containing only200 parallel sentences.
A small set ofabout 350 short phrases from the web isused as additional bilingual knowledge.
Inaddition, we investigate the use of mono-lingual morpho-syntactic knowledge i.e.base forms and POS tags.1 Introduction and Related WorkThe goal of statistical machine translation (SMT) isto translate a source language sequence f1, .
.
.
, fJinto a target language sequence e1, .
.
.
, eI by max-imising the conditional probability Pr(eI1|fJ1 ).
Thisprobability can be factorised into the translationmodel probability P (fJ1 |eI1) which describes thecorrespondence between the words in the source andthe target sequence, and the language model proba-bility P (eJ1 ) which describes well-formedness of theproduced target sequence.
These two probabilitiescan be modelled independently of each other.
Fordetailed descriptions of SMT models see for exam-ple (Brown et al, 1993; Och and Ney, 2003).Translation probabilities are learnt from a bilin-gual parallel text corpus and language model proba-bilities are learnt from a monolingual text in the tar-get language.
Usually, the performance of a trans-lation system strongly depends on the size of theavailable training corpus.
However, acquisition ofa large high-quality bilingual parallel text for the de-sired domain and language pair requires lot of timeand effort, and, for many language pairs, is even notpossible.
Besides, small corpora have certain advan-tages - the acquisition does not require too mucheffort and also manual creation and correction arepossible.
Therefore there is an increasing number ofpublications dealing with limited amounts of bilin-gual data (Al-Onaizan et al, 2000; Nie?en and Ney,2004).For the Serbian language, as a rather minor andnot widely studied language, there are not manylanguage resources available, especially not paralleltexts.
On the other side, investigations on this lan-guage may be quite useful since the majority of prin-ciples can be extended to the wider group of Slaviclanguages (e.g.
Czech, Polish, Russian, etc.
).In this work, we exploit small Serbian-Englishparallel texts as a bilingual knowledge source forstatistical machine translation.
In addition, we in-vestigate the possibilities for improving the trans-lation quality using morpho-syntactic informationin the source language.
Some preliminary transla-tion results on this language pair have been reportedin (Popovic?
et al, 2004; Popovic?
and Ney, 2004),but no systematic investigation has been done so far.This work presents several translation systems cre-ated with different amounts and types of trainingdata and gives a detailed description of the languageresources used.412 Language Resources2.1 Language CharacteristicsSerbian, as a Slavic language, has a very rich inflec-tional morphology for all open word classes.
Thereare six distinct cases affecting not only commonnouns but also proper nouns as well as pronouns,adjectives and some numbers.
Some nouns and ad-jectives have two distinct plural forms depending onthe number (if it is larger than four or not).
Thereare also three genders for the nouns, pronouns, ad-jectives and some numbers leading to differences be-tween the cases and also between the verb participlesfor past tense and passive voice.As for verbs, person and many tenses are ex-pressed by the suffix, and the subject pronoun (e.g.I, we, it) is often omitted (similarly as in Spanish andItalian).
In addition, negation of three quite impor-tant verbs, ?biti?
(to be, auxiliary verb for past tense,conditional and passive voice), ?imati?
(to have) and?hteti?
(to want, auxiliary verb for the future tense),is done by adding the negative particle to the verb asa prefix.As for syntax, Serbian has a quite free word or-der, and there are no articles, neither indefinite nordefinite.All these characteristics indicate that morpho-syntactic knowledge might be very useful for sta-tistical machine translation involving Serbian lan-guage, especially when only scarce amounts of par-allel text are available.2.2 Parallel CorporaFinding high-quality bilingual or multilingual paral-lel corpora involving Serbian language is a difficulttask.
For example, there are several web-sites withthe news in both Serbian and English (some of themin other languages as well), but these texts are onlycomparable and not parallel at all.
To our knowl-edge, the only currently available Serbian-Englishparallel text suitable for statistical machine trans-lation is a manually created electronic version ofthe Assimil language course which has been usedfor some preliminary experiments in (Popovic?
et al,2004; Popovic?
and Ney, 2004).
We have used thiscorpus for systematical investigations described inthis work.2.2.1 Assimil Language CourseThe electronic form of Assimil language coursecontains about 3k sentences and 25k running wordsof various types of conversations and descriptions aswell as a few short newspaper articles.
Detailed cor-pus statistics can be seen in Table 1.
Since the do-main of the corpus is basically not restricted, the vo-cabulary size is relatively large.
Due to the rich mor-phology, the vocabulary for Serbian is almost twotimes larger than for English.
The average sentencelength for Serbian is about 8.5 words per sentence,and for English about 9.5.
This difference is mainlycaused by the lack of articles and omission of somesubject pronouns in Serbian .The development and test set (500 sentences) arerandomly extracted from the original corpus and therest is used for training (referred to as 2.6k).In order to investigate the scenario with extremelyscarce training material, a reduced training corpus(referred to as 200) has been created by random ex-traction of 200 sentences from the original trainingcorpus.The morpho-syntactic annotation of the En-glish part of the corpus has been done by the con-straint grammar parser ENGCG for morphologicaland syntactic analysis of English language.
For eachword, this tool provides its base form and sequenceof morpho-syntactic tags.For the Serbian corpus, to our knowlegde thereis no available tool for automatic annotation of thislanguage.
Therefore, the base forms have been in-troduced manually and the POS tags have been pro-vided partly manually and partly automatically us-ing a statistical maximum-entropy based POS taggersimilar to the one described in (Ratnaparkhi, 1996).First, the 200 sentences of the reduced training cor-pus have been annotated completely manually.
Thenthe first 500 sentences of the rest of the training cor-pus have been tagged automatically and the errorshave been manually corrected.
Afterwards, the POStagger has been trained on the extended corpus (700sentences), the next 500 sentences of the rest are an-notated, and the procedure has been repeated untilthe annotation has been finished for the completecorpus.42Table 1: Statistics of the Serbian-English Assimil corpusSerbian EnglishTraining: original base forms original no articlefull corpus Sentences 2632 2632(2.6k) Running Words + Punct.
22227 24808 23308Average Sentence Length 8.4 9.5 8.8Vocabulary Size 4546 2605 2645 2642Singletons 2728 1253 1211reduced corpus Sentences 200 200(200) Running Words + Punct.
1666 1878 1761Average Sentence Length 8.3 10.4 8.8Vocabulary Size 778 596 603 600Singletons 618 417 395Dev+Test Sentences 500 500Running Words + Punct.
4161 4657 4362Average Sentence Length 8.3 9.3 8.7Vocabulary Size 1457 1030 1055 1052Running OOVs - 2.6k 12.1% 5.2% 4.8%Running OOVs - 200 34.5% 27.6% 21.4%OOVs - 2.6k 32.7% 19.5% 19.7%OOVs - 200 76.2% 66.0% 66.8%External Test Sentences 22 22Running Words + Punct.
395 446 412Average Sentence Length 18.0 20.3 18.7Vocabulary Size 213 176 202 199Running OOVs - 2.6k 44.3% 35.4% 32.1% 34.7%Running OOVs - 200 53.7% 44.6% 43.7% 47.3 %OOVs - 2.6k 61.5% 45.4% 44.0% 44.7%OOVs - 200 74.6% 63.1% 63.9% 64.8%Table 2: Statistics of the Serbian-English short phrasesSerbian EnglishPhrases original base forms original no articleEntries 351 351 351 351Running Words + Punct.
617 617 730 700Average Entry Length 1.8 1.8 2.1 2.0Vocabulary Size 335 303 315 312Singletons 239 209 209 208New Running 2.6k 20.6% 14.4% 11.8% 11.8%Words 200 50.6% 41.3% 36.7% 37.8%New Vocabulary 2.6k 30.1% 22.1% 21.6% 21.2%Words 200 70.7% 63.0% 63.2% 63.1%432.2.2 Short PhrasesThe short phrases used as an additional bilingualknowledge source in our experiments have been col-lected from the web and contain about 350 standardwords and short expressions with an average entrylength of 1.8 words for Serbian and 2 words for En-glish.
Table 2 shows that about 30% of words fromthe phrase vocabulary are not present in the origi-nal Serbian corpus and about 70% of those wordsare not contained in the reduced corpus.
For theEnglish language those numbers are smaller, about20% for the original corpus and 60% for the reducedone.
These percentages are indicating that this par-allel text, although very scarce, might be an usefuladditional training material.The phrases have also been morpho-syntacticallyannotated in the same way as the main corpus.2.2.3 External TestIn addition to the standard development and testset described in Section 2.2.1, we also tested ourtranslation systems on a short external parallel textcollected from the BBC News web-site contain-ing 22 sentences about relations between USA andUkraine after the revolution.
As can be seen in Ta-ble 1, this text contains very large portion of out-of-vocabulary words (almost two thirds of Serbianwords and almost half of English words are not seenin the training corpus), and has an average sentencelength about two times larger than the training cor-pus.3 Transformations in the Source LanguageStandard SMT systems usually regard only fullforms of the words, so that translation of full formswhich have not been seen in the training corpus isnot possible even if the base form has been seen.Since the inflectional morphology of the Serbianlanguage is very rich, as described in Section 2.1, weinvestigate the use of the base forms instead of thefull forms to overcome this problem for the transla-tion into English.
We propose two types of trans-formations of the Serbian corpus: conversion of thefull forms into the base forms and additional treat-ment of the verbs.For the other translation direction, we propose re-moving the articles in the English part of the corpusas the Serbian language does not have any.3.1 Transformations of the Serbian Text3.1.1 Base FormsSerbian full forms of the words usually containinformation which is not relevant for translation intoEnglish.
Therefore, we propose conversion of allSerbian words in their base forms.
Although forsome other inflected languages like German andSpanish this method did not yield any translationimprovement, we still considered it as promising be-cause the number of Serbian inflections is consider-ably higher than in the other two languages.
Table 1shows that this transformation significantly reducesthe Serbian vocabulary size so that it becomes com-parable to the English one.3.1.2 Treatment of VerbsInflections of Serbian verbs might contain rel-evant information about the person, which is es-pecially important when the pronoun is omitted.Therefore, we apply an additional treatment of theverbs.
Whereas all other word classes are still re-placed only by their base forms, for each verb a partof the POS tag referring to the person is taken andthe verb is converted into a sequence of this tag andits base form.
For the three verbs described in Sec-tion 2.1, the separation of the negative particle is alsoapplied: each negative full form is transformed intothe sequence of the POS tag, negative particle andbase form.
The detailed statistics of this corpus isnot reported since there are no significant changes,only the number of running words and average sen-tence length increase thus becoming closer to thevalues of the English corpus.3.2 Transformations of the English Text3.2.1 Removing ArticlesSince the articles are one of the most frequentword classes in English, but on the other side thereare no arcticles at all in Serbian, we propose remov-ing the articles from the English corpus for trans-lation into Serbian.
Each English word which hasbeen detected as an article by means of its POS taghas been removed from the corpus.
In Table 1, itcan be seen that this method significantly reducesthe number of running words and the average sen-tence length of the English corpus thus becomingcomparable to the values of the Serbian corpus.444 Translation Experiments and Results4.1 Experimental SettingsIn order to systematically investigate the impact ofthe bilingual training corpus size and the effectsof the morpho-syntactic information on the trans-lation quality, the translation systems were trainedon the full training corpus (2.6k) and on the re-duced training corpus (200), both with and with-out short phrases.
The translation is performed inboth directions, i.e.
from Serbian to English andother way round.
For the Serbian to English trans-lation systems, three versions of the Serbian corpushave been used: original (baseline), base forms only(sr base) and base forms with additional treatmentof the verbs (sr base+v-pos).
For the translation intoSerbian, the systems were trained on two versions ofthe English corpus: original (baseline) and withoutarticles (en no-article).The baseline translation system is the AlignmentTemplates system with scaling factors (Och andNey, 2002).
Word alignments are produced usingGIZA++ toolkit without symmetrisation (Och andNey, 2003).
Preprocessing of the source data hasbeen done before the training of the system, there-fore modifications of the training and search pro-cedure were not necessary for the translation of thetransformed source language corpora.Although the development set has been used tooptimise the scaling factors, results obtained for thisset do not differ from those for the test set.
There-fore only the joint error rates (Development+Test)are reported.As for the external test set, results for this text arereported only for the full corpus systems, since forthe reduced corpus the error rates are higher but theeffects of using phrases and morpho-syntactic infor-mation are basically the same.4.2 Translation ResultsThe evaluation metrics used in our experimentsare WER (Word Error Rate), PER (Position-independent word Error Rate) and BLEU (BiLin-gual Evaluation Understudy) (Papineni et al, 2002).Since BLEU is an accuracy measure, we use 1-BLEU as an error measure.4.2.1 Translation from Serbian into EnglishError rates for the translation from Serbian intoEnglish are shown in Table 3 and some examplesare shown in Table 6.
It can be seen that there is asignificant decrease in all error rates when the fullforms are replaced with their base forms.
Since theredundant information contained in the inflection isremoved, the system can better capture the relevantinformation and is capable of producing correct orapproximatively correct translations even for unseenfull forms of the words (marked by ?UNKNOWN ?in the baseline result example).
The treatment of theverbs yields some additional improvements.From the first translation example in Table 6 it canbe seen how the problem of some out-of-vocabularywords can be overcomed with the use of the baseforms.
The second and third example are showingthe advantages of the verb treatment, the third oneillustrates the effect of separating the negative parti-cle.Reduction of the training corpus to only 200 sen-tences (about 8% of the original corpus) leads to aloss of error rates of about 45% relative.
However,the degradation is not higher than 35% if phrases andmorpho-syntactic information are available in addi-tion to the reduced corpus.The use of the phrases can improve the transla-tion quality to some extent, especially for the sys-tems with the reduced training corpus, but these im-provements are less remarkable than those obtainedby replacing words with the base forms.The best system with the complete corpus as wellas the best one with the reduced corpus use thephrases and the transformed Serbian corpus wherethe verb treatment has been applied.4.2.2 Translation from English into SerbianTable 4 shows results for the translation from En-glish into Serbian.
As expected, all error rates arehigher than for the other translation direction.
Trans-lation into the morphologically richer language al-ways has poorer quality because it is difficult to findthe correct inflection.The performance of the reduced corpus is de-graded for about 40% relative for the baseline sys-tem and for about 30% when the phrases are usedand the transformation of the English corpus hasbeen applied.45Table 3: Translation error rates [%] for Serbian?EnglishSerbian ?
English Development+TestTraining Corpus Method WER PER 1-BLEU2.6k baseline 45.6 39.6 70.02.6k sr base 43.5 38.2 68.92.6k sr base+v-pos 42.5 35.3 66.22.6k+phrases baseline 46.0 39.6 69.52.6k+phrases sr base 44.6 39.1 70.22.6k+phrases sr base+v-pos 42.1 35.3 66.0200 baseline 66.5 61.1 91.6200 sr base 63.2 58.2 90.3200 sr base+v-pos 63.3 56.2 88.5200+phrases baseline 65.2 59.5 90.2200+phrases sr base 62.3 56.9 87.7200+phrases sr base+v-pos 61.3 53.2 86.2Table 4: Translation error rates [%] for English?SerbianEnglish ?
Serbian Development+TestTraining Corpus Method WER PER 1-BLEU2.6k baseline 53.1 46.9 78.62.6k en no-article 52.6 47.2 79.42.6k+phrases baseline 52.5 46.5 76.62.6k+phrases en no-article 52.3 47.0 79.6200 baseline 73.6 68.0 93.0200 en no-article 71.5 66.5 93.4200+phrases baseline 71.7 66.7 92.3200+phrases en no-article 67.9 62.9 92.1Table 5: Translation error rates [%] for the external testSerbian ?
English External TestTraining Corpus Method WER PER 1-BLEU2.6k baseline 72.2 64.8 92.22.6k sr base 66.8 61.4 86.92.6k sr base+v-pos 67.5 61.4 88.32.6k+phrases baseline 71.3 63.9 91.92.6k+phrases sr base 67.0 61.2 88.42.6k+phrases sr base+v-pos 69.7 61.2 89.8English ?
Serbian2.6k baseline 85.3 77.0 96.42.6k en no-article 77.5 69.9 95.82.6k+phrases baseline 84.1 74.9 95.22.6k+phrases en no-article 77.7 70.1 94.846The importance of the phrases seems to be largerfor this translation direction.
Removing the Englisharticles does not have the significant role for thetranslation systems with full corpus, but for the re-duced corpus it has basically the same effect as theuse of phrases.
The best system with the reducedcorpus has been built with the use of phrases andremoval of the articles.Table 7 shows some examples of the translationinto Serbian with and without English articles.
Al-though these effects are not directly obvious, it canbe seen that removing of the redundant informationenables better learning of the relevant informationso that system is better capable of producing seman-tically correct output.
The first example illustratesan syntactically incorrect output with the wrong in-flection of the verb (?c?itam?
means ?I read?).
Theoutput of the system without articles is still not com-pletely correct, but the semantic is completely pre-served.
The second example illustrates an outputproduced by the baseline system which is neithersyntactically nor semantically correct (?you have Idrink?).
The output of the new system still has anerror in the verb, informal form of ?you?
instead ofthe formal one, but nevertheless both the syntax andsemantics are correct.4.2.3 Translation of the External TextTranslation results for the external test can beseen in Table 5.
As expected, the high number ofout-of-vocabulary words results in very high errorrates.
Certain improvement is achieved with thephrases, but the most significant improvements areyielded by the use of Serbian base forms and re-moval of English articles.
Verb treatment in this casedoes not outperform the base forms system, prob-ably because there are not so many different verbforms as in the other corpus, and only a small num-ber of pronouns is missing.5 ConclusionsIn this work, we have examined the possibilitiesfor building a statistical machine translation systemwith a small bilingual Serbian-English parallel text.Our experiments showed that the translation resultsfor this language pair are comparable with results forother language pairs, especially if the small size ofthe corpus, unrestricted domain and rich inflectionalmorphology of Serbian language are taken into ac-count.
With the baseline system, we obtained about45% WER for translation into English and about53% for translation into Serbian.We have systematically investigated the impact ofthe corpus size on translation quality, as well as theimportance of additional bilingual knowledge in theform of short phrases.
In addition, we have shownthat morpho-syntactic information is a valuable lan-guage resource for translation of this language pair.Depending on the availability of resources andtools, we plan to examine parallel texts with otherlanguages, and also to do further investigations onthis language pair.
We believe that more refined useof the morpho-syntactic information can yield betterresults (for example the hierarchical lexicon modelproposed in (Nie?en and Ney, 2001)).
We also be-lieve that the use of the conventional dictionariescould improve the Serbian-English translation.AcknowledgementThis work was partly funded by the DeutscheForschungsgemeinschaft (DFG) under the project?Statistical Methods for Written Language Transla-tion?
(Ne572/5).ReferencesY.
Al-Onaizan, U. Germann, U. Hermjakob, K. Knight,P.
Koehn, D. Marcu, and K. Yamada.
2000.
Translat-ing with scarce resources.
In National Conference onArtificial Intelligence (AAAI).Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
The mathe-matics of statistical machine translation: Parameter es-timation.
Computational Linguistics, 19(2):263?311.Sonja Nie?en and Hermann Ney.
2001.
Toward hi-erarchical models for statistical machine translationof inflected languages.
In 39th Annual Meeting ofthe Assoc.
for Computational Linguistics - joint withEACL 2001: Proc.
Workshop on Data-Driven Ma-chine Translation, pages 47?54, Toulouse, France,July.Sonja Nie?en and Hermann Ney.
2004.
Statistical ma-chine translation with scarce resources using morpho-syntactic information.
Computational Linguistics,30(2):181?204, June.Franz J. Och and Hermann Ney.
2002.
Discriminativetraining and maximum entropy models for statistical47Table 6: Examples of Serbian?English translations with and without transformationsto je suvishe skupo .
?
to biti suvishe skup .
?
to SG3 biti suvishe skup .base forms verb treatment?
Sr ?
En (baseline) ?
Sr?
?
En ?
Sr?
?
Enit is it is it istoo UNKNOWN skupo .
too expensive .
too expensive .on ne igra .
?
on ne igrati .
?
on ne SG3 igrati .base forms verb treatment?
Sr ?
En (baseline) ?
Sr?
?
En ?
Sr?
?
Enhe he does not .
he do not play .
he does not play .da , ali nemam ?
da , ali nemati ?
da , ali SG1 ne imatimnogo vremena .
base forms mnogo vreme .
verb treatment mnogo vreme .?
Sr ?
En (baseline) ?
Sr?
?
En ?
Sr?
?
Enyes , but I have yes , but not yes , but I have not gotmuch time .
much time .
much time .Table 7: Examples of English?Serbian translations with and without transformationsyou should not ?
you should notread in bed .
remove articles read in bed .?
En ?
Sr (baseline) ?
En?
?
Sr reference translation:treba ne ne bi trebalo ne bi trebaloc?itam u krevet .
c?itate u krevet .
da c?itate u krevetu .have a drink .
?
have drink .remove articles?
En ?
Sr (baseline) ?
En?
?
Sr reference translation:imate pijem .
uzmi nes?to za pic?e .
uzmite nes?to za pic?e .machine translation.
In Proc.
40th Annual Meeting ofthe Assoc.
for Computational Linguistics (ACL), pages295?302, Philadelphia, PA, July.Franz J. Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51, March.Kishore Papineni, Salim Roukos, Todd Ward, and Wie-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proc.
40th AnnualMeeting of the Assoc.
for Computational Linguistics(ACL), pages 311?318, Philadelphia, PA, July.M.
Popovic?
and H. Ney.
2004.
Towards the use of wordstems and suffixes for statistical machine translation.In Proc.
4th Int.
Conf.
on Language Resources andEvaluation (LREC), pages 1585?1588, Lisbon, Portu-gal, May.M.
Popovic?, S.
Jovic?ic?, and Z.
?Saric?.
2004.
Statisticalmachine translation of Serbian-English.
In Proc.
ofInt.
Workshop on Speech and Computer (SPECOM),pages 410?414, St. Petersburg, Russia, September.A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In Proc.
Conf.
on EmpiricalMethods for Natural Language Processing (EMNLP),pages 133?142, Sommerset, NJ.48
