Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 55?65,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsDependency Parsing of Hungarian: Baseline Results and ChallengesRicha?rd Farkas1, Veronika Vincze2, Helmut Schmid11Institute for Natural Language Processing, University of Stuttgart{farkas,schmid}@ims.uni-stuttgart.de2Research Group on Artificial Intelligence, Hungarian Academy of Sciencesvinczev@inf.u-szeged.huAbstractHungarian is a stereotype of morpholog-ically rich and non-configurational lan-guages.
Here, we introduce results on de-pendency parsing of Hungarian that em-ploy a 80K, multi-domain, fully manu-ally annotated corpus, the Szeged Depen-dency Treebank.
We show that the resultsachieved by state-of-the-art data-drivenparsers on Hungarian and English (which isat the other end of the configurational-non-configurational spectrum) are quite simi-lar to each other in terms of attachmentscores.
We reveal the reasons for this andpresent a systematic and comparative lin-guistically motivated error analysis on bothlanguages.
This analysis highlights that ad-dressing the language-specific phenomenais required for a further remarkable error re-duction.1 IntroductionFrom the viewpoint of syntactic parsing, the lan-guages of the world are usually categorized ac-cording to their level of configurationality.
At oneend, there is English, a strongly configurationallanguage while Hungarian is at the other end ofthe spectrum.
It has very few fixed structuresat the sentence level.
Leaving aside the issue ofthe internal structure of NPs, most sentence-levelsyntactic information in Hungarian is conveyedby morphology, not by configuration (E?.
Kiss,2002).A large part of the methodology for syntacticparsing has been developed for English.
How-ever, parsing non-configurational and less config-urational languages requires different techniques.In this study, we present results on Hungarian de-pendency parsing and we investigate this generalissue in the case of English and Hungarian.We employed three state-of-the-art data-drivenparsers (Nivre et al 2004; McDonald et al 2005;Bohnet, 2010), which achieved (un)labeled at-tachment scores on Hungarian not so differentfrom the corresponding English scores (and evenhigher on certain domains/subcorpora).
Our in-vestigations show that the feature representationused by the data-driven parsers is so rich that theycan ?
without any modification ?
effectively learna reasonable model for non-configurational lan-guages as well.We also conducted a systematic and compar-ative error analysis of the system?s outputs forHungarian and English.
This analysis highlightsthe challenges of parsing Hungarian and sug-gests that the further improvement of parsers re-quires special handling of language-specific phe-nomena.
We believe that some of our findingscan be relevant for intermediate languages on theconfigurational-non-configurational spectrum.2 Chief Characteristics of theHungarian MorphosyntaxHungarian is an agglutinative language, whichmeans that a word can have hundreds of wordforms due to inflectional or derivational affixa-tion.
A lot of grammatical information is encodedin morphology and Hungarian is a stereotype ofmorphologically rich languages.
The Hungarianword order is free in the sense that the positionsof the subject, the object and the verb are not fixedwithin the sentence, but word order is related toinformation structure, e.g.
new (or emphatic) in-formation (the focus) always precedes the verb55and old information (the topic) precedes the focusposition.
Thus, the position relative to the verbhas no predictive force as regards the syntacticfunction of the given argument: while in English,the noun phrase before the verb is most typicallythe subject, in Hungarian, it is the focus of thesentence, which itself can be the subject, objector any other argument (E?.
Kiss, 2002).The grammatical function of words is deter-mined by case suffixes as in gyerek ?child?
?
gye-reknek (child-DAT) ?for (a/the) child?.
Hungariannouns can have about 20 cases1 which mark therelationship between the head and its argumentsand adjuncts.
Although there are postpositionsin Hungarian, case suffixes can also express re-lations that are expressed by prepositions in En-glish.Verbs are inflected for person and number andthe definiteness of the object.
Since conjugationalinformation is sufficient to deduce the pronominalsubject or object, they are typically omitted fromthe sentence: Va?rlak (wait-1SG2OBJ) ?I am wait-ing for you?.
This pro-drop feature of Hungar-ian leads to the fact that there are several clauseswithout an overt subject or object.Another peculiarity of Hungarian is that thethird person singular present tense indicative formof the copula is phonologically empty, i.e.
thereare apparently verbless sentences in Hungarian:A ha?z nagy (the house big) ?The house is big?.However, in other tenses or moods, the copulais present as in A ha?z nagy lesz (the house bigwill.be) ?The house will be big?.There are two possessive constructions inHungarian.
First, the possessive relation is onlymarked on the possessed noun (in contrast, it ismarked only on the possessor in English): a fiu?kutya?ja (the boy dog-POSS) ?the boy?s dog?.
Sec-ond, both the possessor and the possessed bear apossessive marker: a fiu?nak a kutya?ja (the boy-DAT the dog-POSS) ?the boy?s dog?.
In the lattercase, the possessor and the possessed may not beadjacent within the sentence as in A fiu?nak la?tta akutya?ja?t (the boy-DAT see-PAST3SGOBJ the dog-POSS-ACC) ?He saw the boy?s dog?, which resultsin a non-projective syntactic tree.
Note that inthe first case, the form of the possessor coincides1Hungarian grammars and morphological coding sys-tems do not agree on the exact number of cases, some raresuffixes are treated as derivational suffixes in one grammarand as case suffixes in others; see e.g.
Farkas et al(2010).with that of a nominative noun while in the secondcase, it coincides with a dative noun.According to these facts, a Hungarian parsermust rely much more on morphological analysisthan e.g.
an English one since in Hungarian itis morphemes that mostly encode morphosyntac-tic information.
One of the consequences of thisis that Hungarian sentences are shorter in termsof word numbers than English ones.
Based onthe word counts of the Hungarian?English paral-lel corpus Hunglish (Varga et al 2005), an En-glish sentence contains 20.5% more words than itsHungarian equivalent.
These extra words in En-glish are most frequently prepositions, pronomi-nal subjects or objects, whose parent and depen-dency label are relatively easy to identify (com-pared to other word classes).
This train of thoughtindicates that the cross-lingual comparison of fi-nal parser scores should be conducted very care-fully.3 Related workWe decided to focus on dependency parsing inthis study as it is a superior framework for non-configurational languages.
It has gained inter-est in natural language processing recently be-cause the representation itself does not requirethe words inside of constituents to be consecu-tive and it naturally represent discontinuous con-structions, which are frequent in languages wheregrammatical relations are often signaled by mor-phology instead of word order (McDonald andNivre, 2011).
The two main efficient approachesfor dependency parsing are the graph-based andthe transition-based parsers.
The graph-basedmodels look for the highest scoring directed span-ning tree in the complete graph whose nodes arethe words of the sentence in question.
They solvethe machine learning problem of finding the opti-mal scoring function of subgraphs (Eisner, 1996;McDonald et al 2005).
The transition-based ap-proaches parse a sentence in a single left-to-rightpass over the words.
The next transition in thesesystems is predicted by a classifier that is basedon history-related features (Kudo and Matsumoto,2002; Nivre et al 2004).Although the available treebanks for Hungar-ian are relatively big (82K sentences) and fullymanually annotated, the studies on parsing Hun-garian are rather limited.
The Szeged (Con-stituency) Treebank (Csendes et al 2005) con-56sists of six domains ?
namely, short businessnews, newspaper, law, literature, compositionsand informatics ?
and it is manually annotatedfor the possible alternatives of words?
morpho-logical analyses, the disambiguated analysis andconstituency trees.
We are aware of only twoarticles on phrase-structure parsers which weretrained and evaluated on this corpus (Barta et al2005; Iva?n et al 2007) and there are a few studieson hand-crafted parsers reporting results on smallown corpora (Babarczy et al 2005; Pro?sze?ky etal., 2004).The Szeged Dependency Treebank (Vincze etal., 2010) was constructed by first automaticallyconverting the phrase-structure trees into depen-dency trees, then each of them was manuallyinvestigated and corrected.
We note that thedependency treebank contains more informationthan the constituency one as linguistic phenom-ena (like discontinuous structures) were not anno-tated in the former corpus, but were added to thedependency treebank.
To the best of our knowl-edge no parser results have been published on thiscorpus.
Both corpora are available at www.inf.u-szeged.hu/rgai/SzegedTreebank.The multilingual track of the CoNLL-2007Shared Task (Nivre et al 2007) addressed alsothe task of dependency parsing of Hungarian.
TheHungarian corpus used for the shared task con-sists of automatically converted dependency treesfrom the Szeged Constituency Treebank.
Severalissues of the automatic conversion tool were re-considered before the manual annotation of theSzeged Dependency Treebank was launched andthe annotation guidelines contained instructionsrelated to linguistic phenomena which could notbe converted from the constituency representa-tion ?
for a detailed discussion, see Vincze et al(2010).
Hence the annotation schemata of theCoNLL-2007 Hungarian corpus and the SzegedDependency Treebank are rather different and thefinal scores reported for the former are not di-rectly comparable with our reported scores here(see Section 5).4 The Szeged Dependency TreebankWe utilize the Szeged Dependency Treebank(Vincze et al 2010) as the basis of our experi-ments for Hungarian dependency parsing.
It con-tains 82,000 sentences, 1.2 million words and250,000 punctuation marks from six domains.The annotation employs 16 coarse grained POStags, 95 morphological feature values and 29 de-pendency labels.
19.6% of the sentences in thecorpus contain non-projective edges and 1.8% ofthe edges are non-projective2, which is almost 5times more frequent than in English and is thesame as the Czech non-projectivity level (Buch-holz and Marsi, 2006).
Here we discuss two an-notation principles along with our modificationsin the dataset for this study which strongly influ-ence the parsers?
accuracies.Named Entities (NEs) were treated as one to-ken in the Szeged Dependency Treebank.
Assum-ing a perfect phrase recogniser on the whitespacetokenised input for them is quite unrealistic.
Thuswe decided to split them into tokens for this study.The new tokens automatically got a proper nounwith default morphological features morphologi-cal analysis except for the last token ?
the head ofthe phrase ?, which inherited the morphologicalanalysis of the original multiword unit (which cancontain various grammatical information).
Thisresulted in an N N N N POS sequence for Kova?cse?s ta?rsa kft.
?Smith and Co. Ltd.?
which wouldbe annotated as N C N N in the Penn Treebank.Moreover, we did not annotate any internal struc-ture of Named Entities.
We consider the last wordof multiword named entities as the head becauseof morphological reasons (the last word of multi-word units gets inflected in Hungarian) and all theprevious elements are attached to the succeedingword, i.e.
the penultimate word is attached to thelast word, the antepenultimate word to the penulti-mate one etc.
The reasons for these considerationsare that we believe that there are no downstreamapplications which can exploit the information ofthe internal structures of Named Entities and weimagine a pipeline where a Named Entity Recog-niser precedes the parsing step.Empty copula: In the verbless clauses (pred-icative nouns or adjectives) the Szeged Depen-dency Treebank introduces virtual nodes (16,000items in the corpus).
This solution means thata similar tree structure is ascribed to the samesentence in the present third person singular andall the other tenses / persons.
A further argu-ment for the use of a virtual node is that the vir-tual node is always present at the syntactic level2Using the transitive closure definition of Nivre and Nils-son (2005).57corpus Malt MST MateULA LAS ULA LAS ULA LASHungariandev 88.3 (89.9) 85.7 (87.9) 86.9 (88.5) 80.9 (82.9) 89.7 (91.1) 86.8 (89.0)test 88.7 (90.2) 86.1 (88.2) 87.5 (89.0) 81.6 (83.5) 90.1 (91.5) 87.2 (89.4)Englishdev 87.8 (89.1) 84.5 (86.1) 89.4 (91.2) 86.1 (87.7) 91.6 (92.7) 88.5 (90.0)test 88.8 (89.9) 86.2 (87.6) 90.7 (91.8) 87.7 (89.2) 92.6 (93.4) 90.3 (91.5)Table 1: Results achieved by the three parsers on the (full) Hungarian (Szeged Dependency Treebank) andEnglish (CoNLL-2009) datasets.
The scores in brackets are achieved with gold-standard POS tagging.since it is overt in all the other forms, tenses andmoods of the verb.
Still, the state-of-the-art de-pendency parsers cannot handle virtual nodes.
Forthis study, we followed the solution of the PragueDependency Treebank (Hajic?
et al 2000) and vir-tual nodes were removed from the gold standardannotation and all of their dependents were at-tached to the head of the original virtual node andthey were given a dedicated edge label (Exd).Dataset splits: We formed training, develop-ment and test sets from the corpus where eachset consists of texts from each of the domains.We paid attention to the issue that a documentshould not be separated into different datasets be-cause it could result in a situation where a part ofthe test document was seen in the training dataset(which is unrealistic because of unknown words,style and frequently used grammatical structures).As the fiction subcorpus consists of three booksand the law subcorpus consists of two rules, wetook half of one of the documents for the testand development sets and used the other part(s)for training there.
This principle was followed atour cross-fold-validation experiments as well ex-cept for the law subcorpus.
We applied 3 folds forcross-validation for the fiction subcorpus, other-wise we used 10 folds (splitting at documentaryboundaries would yield a training fold consistingof just 3000 sentences).35 ExperimentsWe carried out experiments using three state-of-the-art parsers on the Szeged Dependency Tree-bank (Vincze et al 2010) and on the Englishdatasets of the CoNLL-2009 Shared Task (Hajic?et al 2009).3Both the training/development/test and the cross-validation splits are available at www.inf.u-szeged.hu/rgai/SzegedTreebank.Tools: We employed a finite state automata-based morphological analyser constructed fromthe morphdb.hu lexical resource (Tro?n et al2006) and we used the MSD-style morphologicalcode system of the Szeged TreeBank (Alexin etal., 2003).
The output of the morphological anal-yser is a set of possible lemma?morphologicalanalysis pairs.
This set of possible morphologi-cal analyses for a word form is then used as pos-sible alternatives ?
instead of open and closed tagsets ?
in a standard sequential POS tagger.
Here,we applied the Conditional Random Fields-basedStanford POS tagger (Toutanova et al 2003) andcarried out 5-fold-cross POS training/tagging in-side the subcorpora.4 For the English experimentswe used the predicted POS tags provided for theCoNLL-2009 shared task (Hajic?
et al 2009).As the dependency parser we employed threestate-of-the-art data-driven parsers, a transition-based parser (Malt) and two graph-based parsers(MST and Mate parsers).
The Malt parser (Nivreet al 2004) is a transition-based system, whichuses an arc-eager system along with support vec-tor machines to learn the scoring function for tran-sitions and which uses greedy, deterministic one-best search at parsing time.
As one of the graph-based parsers, we employed the MST parser (Mc-Donald et al 2005) with a second-order featuredecoder.
It uses an approximate exhaustive searchfor unlabeled parsing, then a separate arc labelclassifier is applied to label each arc.
The Mateparser (Bohnet, 2010) is an efficient second or-der dependency parser that models the interactionbetween siblings as well as grandchildren (Car-reras, 2007).
Its decoder works on labeled edges,i.e.
it uses a single-step approach for obtaininglabeled dependency trees.
Mate uses a rich and4The JAVA implementation of the morphological anal-yser and the slightly modified POS tagger along with trainedmodels are available at http://www.inf.u-szeged.hu/rgai/magyarlanc.58corpus #sent.
length CPOS DPOS ULA all ULA LAS all LASnewspaper 9189 21.6 97.2 96.5 88.0 (90.0) +0.8 84.7 (87.5) +1.0short business 8616 23.6 98.0 97.7 93.8 (94.8) +0.3 91.9 (93.4) +0.4fiction 9279 12.6 96.9 95.8 87.7 (89.4) -0.5 83.7 (86.2) -0.3law 8347 27.3 98.3 98.1 90.6 (90.7) +0.2 88.9 (89.0) +0.2computer 8653 21.9 96.4 95.8 91.3 (92.8) -1.2 88.9 (91.2) -1.6composition 22248 13.7 96.7 95.6 92.7 (93.9) +0.3 88.9 (91.0) +0.3Table 2: Domain results achieved by the Mate parser in cross-validation settings.
The scores in brackets areachieved with gold-standard POS tagging.
The ?all?
columns contain the added value of extending the trainingsets with each of the five out-domain subcorpora.well-engineered feature set and it is enhanced bya Hash Kernel, which leads to higher accuracy.Evaluation metrics: We apply the Labeled At-tachment Score (LAS) and Unlabeled AttachmentScore (ULA), taking into account punctuation aswell for evaluating dependency parsers and theaccuracy on the main POS tags (CPOS) and afine-grained morphological accuracy (DPOS) forevaluating the POS tagger.
In the latter, the analy-sis is regarded as correct if the main POS tag andeach of the morphological features of the token inquestion are correct.Results: Table 1 shows the results got by theparsers on the whole Hungarian corpora and onthe English datasets.
The most important pointis that scores are not different from the Englishscores (although they are not directly compara-ble).
To understand the reasons for this, we man-ually investigated the set of firing features withthe highest weights in the Mate parser.
Althoughthe assessment of individual feature contributionsto a particular decoder decision is not straightfor-ward, we observed that features encoding config-urational information (i.e.
the direction or lengthof an edge, the words or POS tag sequences/setsbetween the governor and the dependent) werefrequently among the highest weighted featuresin English but were extremely rare in Hungarian.For instance, one of the top weighted features fora subject dependency in English was the ?there isno word between the head and the dependent?
fea-ture while this never occurred among the top fea-tures in Hungarian.As a control experiment, we trained the Mateparser only having access to the gold-standardPOS tag sequences of the sentences, i.e.
weswitched off the lexicalization and detailed mor-phological information.
The goal of this experi-ment was to gain an insight into the performanceof the parsers which can only access configura-tional information.
These parsers achieved worseresults than the full parsers by 6.8 ULA, 20.3 LASand 2.9 ULA, 6.4 LAS on the development setsof Hungarian and English, respectively.
As ex-pected, Hungarian suffers much more when theparser has to learn from configurational informa-tion only, especially when grammatical functionshave to be predicted (LAS).
Despite this, the re-sults of Table 1 show that the parsers can practi-cally eliminate this gap by learning from morpho-logical features (and lexicalization).
This meansthat the data-driven parsers employing a very richfeature set can learn a model which effectivelycaptures the dependency structures using featureweights which are radically different from theones used for English.Another cause of the relatively high scores isthat the CPOS accuracy scores on Hungarianand English are almost equal: 97.2 and 97.3, re-spectively.
This also explains the small differ-ence between the results got by gold-standard andpredicted POS tags.
Moreover, the parser canalso exploit the morphological features as inputin Hungarian.The Mate parser outperformed the other twoparsers on each of the four datasets.
Comparingthe two graph-based parsers Mate and MST, thegap between them was twice as big in LAS than inULA in Hungarian, which demonstrates that theone-step approach looking for the maximumlabeled spanning tree is more suitable for Hun-garian than the two-step arc labeling approach ofMST.
This probably holds for other morpholog-ically rich languages too as the decoder can ex-ploit information from the labels of decoded arcs.Based on these results, we decided to use onlyMate for our further experiments.59Table 2 provides an insight into the effect ofdomain differences on POS tagging and pars-ing scores.
There is a noticeable difference be-tween the ?newspaper?
and the ?short businessnews?
corpora.
Although these domains seem tobe close to each other at the first glance (both arenews), they have different characteristics.
On theone hand, short business news is a very narrowdomain consisting of 2-3 sentence long financialshort reports.
It frequently uses the same gram-matical structures (like ?Stock indexes rose X per-cent at the Y Stock on Wednesday?)
and the lexi-con is also limited.
On the other hand, the news-paper subcorpus consists of full journal articlescovering various domains and it has a fancy jour-nalist style.The effect of extending the training dataset without-of-domain parses is not convincing.
In spiteof the ten times bigger training datasets, thereare two subcorpora where they just harmed theparser, and the improvement on other subcorporais less than 1 percent.
This demonstrates well thedomain-dependence of parsing.The parser and the POS tagger react to do-main difficulties in a similar way, according tothe first four rows of Table 2.
This observationholds for the scores of the parsers working withgold-standard POS tags, which suggests that do-main difficulties harm POS tagging and parsing aswell.
Regarding the two last subcorpora, the com-positions consist of very short and usually simplesentences and the training corpora are twice as bigcompared with other subcorpora.
Both factors areprobably the reasons for the good parsing perfor-mance.
In the computer corpus, there are manyEnglish terms which are manually tagged with an?unknown?
tag.
They could not be accurately pre-dicted by the POS tagger but the parser could pre-dict their syntactic role.Table 2 also tells us that the difference betweenCPOS and DPOS is usually less than 1 percent.This experimentally supports that the ambigu-ity among alternative morphological analysesis mostly present at the POS-level and the mor-phological features are efficiently identified byour morphological analyser.
The most frequentmorphological features which cannot be disam-biguated at the word level are related to suffixeswith multiple functions or the word itself cannotbe unambiguously segmented into morphemes.Although the number of such ambiguous cases islow, they form important features for the parser,thus we will focus on the more accurate handlingof these cases in future work.Comparison to CoNLL-2007 results: Thebest performing participant of the CoNLL-2007Shared Task (Nivre et al 2007) achieved an ULAof 83.6 and LAS of 80.3 (Hall et al 2007) onthe Hungarian corpus.
The difference between thetop performing English and Hungarian systemswere 8.14 ULA and 9.3 LAS.
The results reportedin 2007 were significantly lower and the gap be-tween English and Hungarian is higher than ourcurrent values.
To locate the sources of differencewe carried out other experiments with Mate onthe CoNLL-2007 dataset using the gold-standardPOS tags (the shared task used gold-standard POStags for evaluation).First we trained and evaluated Mate on theoriginal CoNLL-2007 datasets, where it achievedULA 84.3 and LAS 80.0.
Then we used the sen-tences of the CoNLL-2007 datasets but with thenew, manual annotation.
Here, Mate achievedULA 88.6 and LAS 85.5, which means that themodified annotation schema and the less erro-neous/noisy annotation caused an improvement ofULA 4.3 and LAS 5.5.
The annotation schemachanged a lot: coordination had to be correctedmanually since it is treated differently after con-version, moreover, the internal structure of ad-jectival/participial phrases was not marked in theoriginal constituency treebank, so it was alsoadded manually (Vincze et al 2010).
The im-provement in the labeled attachment score is prob-ably due to the reduction of the label set (from 49to 29 labels), which step was justified by the factthat some morphosyntactic information was dou-bly coded in the case of nouns (e.g.
ha?zzal (house-INS) ?with the/a house?)
in the original CoNLL-2007 dataset ?
first, by their morphological case(Cas=ins) and second, by their dependency label(INS).Lastly, as the CoNLL-2007 sentences camefrom the newspaper subcorpus, we can comparethese scores with the ULA 90.0 and LAS 87.5of Table 2.
The ULA 1.5 and LAS 2.0 differ-ences are the result of the bigger training corpus(9189 sentences on average compared to 6390 inthe CoNLL-2007 dataset).60Hungarian Englishlabel attachment label attachmentvirtual nodes 31.5% 39.5% multiword NEs 15.2% 17.6%conjunctions and negation ?
11.2% PP-attachment ?
15.9%noun attachment ?
9.6% non-canonical word order 6.4% 6.5%more than 1 premodifier ?
5.1% misplaced clause ?
9.7%coordination 13.5% 16.5% coordination 8.5% 12.5%mislabeled adverb 16.3% ?
mislabeled adverb 40.1% ?annotation errors 10.7% 6.8% annotation errors 9.7% 8.5%other 28.0% 11.3% other 20.1% 29.3%TOTAL 100% 100% TOTAL 100% 100%Table 3: The most frequent corpus-specific and general attachment and labeling error categories (based on amanual investigation of 200?200 erroneous sentences).6 A Systematic Error AnalysisIn order to discover specialties and challenges ofHungarian dependency parsing, we conducted anerror analysis of parsed texts from the newspaperdomain both in English and Hungarian.
200 ran-domly selected erroneous sentences from the out-put of Mate were investigated in both languagesand we categorized the errors on the basis of thelinguistic phenomenon responsible for the errors?
for instance, when an error occurred because ofthe incorrect identification of a multiword NamedEntity containing a conjunction, we treated it asa Named Entity error instead of a conjunction er-ror ?, i.e.
our goal was to reveal the real linguisticsources of errors rather than deducing from auto-matically countable attachment/labeling statistics.We used the parses based on gold-standardPOS tagging for this analysis as our goal was toidentify the challenges of parsing independentlyof the challenges of POS tagging.
The error cate-gories are summarized in Table 3 along with theirrelative contribution to attachment and labelingerrors.
This table contains the categories withover 5% relative frequency.5The 200 sentences contained 429/319 and353/330 attachment/labeling errors in Hungarianand English, respectively.
In Hungarian, attach-ment errors outnumber label errors to a great ex-tent whereas in English, their distribution is basi-cally the same.
This might be attributed to thehigher level of non-projectivity (see Section 4)and to the more fine-grained label set of the En-glish dataset (36 against 29 labels in English and5The full tables are available at www.inf.u-szeged.hu/rgai/SzegedTreebank.Hungarian, respectively).Virtual nodes: In Hungarian, the most commonsource of parsing errors was virtual nodes.
Asthere are quite a lot of verbless clauses in Hungar-ian (see Section 2 on sentences without copula), itmight be difficult to figure out the proper depen-dency relations within the sentence, since the verbplays the central role in the sentence, cf.
Tesnie`re(1959).
Our parser was not efficient in identify-ing the structure of such sentences, probably dueto the lack of information for data-driven parsers(each edge is labeled as Exd while they have sim-ilar features to ordinary edges).
We also note thatthe output of the current system with Exd labelsdoes not contain too much information for down-stream applications of parsing.
The appropriatehandling of virtual nodes is an important directionfor future work.Noun attachment: In Hungarian, the nomi-nal arguments of infinitives and participles werefrequently erroneously attached to the mainverb.
Take the following sentence: A Horn-kabinet ideje?n jo?l beva?lt mo?dszerhez pro?ba?lnakmeg visszate?rni (the Horn-government time-3SGPOSS-SUP well tried method-ALL try-3PLPREVERB return-INF) ?They are trying to returnto the well-tried method of the Horn government?.In this sentence, a Horn-kabinet ideje?n ?duringthe Horn government?
is a modifier of the pastparticiple beva?lt ?well-tried?, however, it is at-tached to the main verb pro?ba?lnak ?they are try-ing?
by the parser.
Moreover, mo?dszerhez ?to themethod?
is an argument of the infinitive visszate?r-ni ?to return?, but the parser links it to the main61verb.
In free word order languages, the order ofthe arguments of the infinitive and the main verbmay get mixed, which is called scrambling (Ross,1986).
This is not a common source of error inEnglish as arguments cannot scramble.Article attachment: In Hungarian, if there isan article before a prenominal modifier, it can be-long to the head noun and to the modifier as well.In a szoba ajtaja (the room door-3SGPOSS) ?thedoor of the room?
the article belongs to the modi-fier but when the prenominal modifier cannot havean article (e.g.
a februa?rban indulo?
projekt (theFebruary-INE starting project) ?the project start-ing in February?
), it is attached to the head noun(i.e.
to projekt ?project?).
It was not always clearfor the parser which parent to select for the arti-cle.
In contrast, these cases are not problematicin English since the modifier typically follows thehead and thus each article precedes its head noun.Conjunctions or negation words ?
most typ-ically the words is ?too?, csak ?only/just?
andnem/sem ?not?
?
were much more frequently at-tached to the wrong node in Hungarian than inEnglish.
In Hungarian, they are ambiguous be-tween being adverbs and conjunctions and it ismostly their conjunctive uses which are problem-atic from the viewpoint of parsing.
On the otherhand, these words have an important role in mark-ing the information structure of the sentence: theyare usually attached to the element in focus posi-tion, and if there is no focus, they are attachedto the verb.
However, sentences with or with-out focus can have similar word order but theirstress pattern is different.
Dependency parsersobviously cannot recognize stress patterns, henceconjunctions and negation words are sometimeserroneously attached to the verb in Hungarian.English sentences with non-canonical wordorder (e.g.
questions) were often incorrectlyparsed, e.g.
the noun following the main verb isthe object in sentences like Replied a salesman:?Exactly.
?, where it is the subject that follows theverb for stylistic reasons.
However, in Hungarian,morphological information is of help in such sen-tences, as it is not the position relative to the verbbut the case suffix that determines the grammati-cal role of the noun.In English, high or low PP-attachment wasresponsible for many parsing ambiguities: mosttypically, the prepositional complement whichfollows the head was attached to the verb insteadof the noun or vice versa.
In contrast, Hungarianis a head-after-dependent language, which meansthat dependents most often occur before the head.Furthermore, there are no prepositions in Hungar-ian, and grammatical relations encoded by prepo-sitions in English are conveyed by suffixes orpostpositions.
Thus, if there is a modifier beforethe nominal head, it requires the presence of aparticiple as in: Felvette a kirakatban levo?
ruha?t(take.on-PAST3SGOBJ the shop.window-INE be-ing dress-ACC) ?She put on the dress in the shopwindow?.
The English sentence is ambiguous (ei-ther the event happens in the shop window or thedress was originally in the shop window) whilethe Hungarian has only the latter meaning.6General dependency parsing difficulties:There were certain structures that led to typicallabel and/or attachment errors in both languages.The most frequent one among them is coordi-nation.
However, it should be mentioned thatsyntactic ambiguities are often problematic evenfor humans to disambiguate without contextualor background semantic knowledge.In the case of label errors, the relation betweenthe given node and its parent was labeled incor-rectly.
In both English and Hungarian, one of themost common errors of this type was mislabeledadverbs and adverbial phrases, e.g.
locative ad-verbs were labeled as ADV/MODE.
However, thefrequency rate of this error type is much higherin English than in Hungarian, which may be re-lated to the fact that in the English corpus, thereis a much more balanced distribution of adverbiallabels than in the Hungarian one (where the cat-egories MODE and TLOCY are responsible for90% of the occurrences).
Assigning the most fre-quent label of the training dataset to each adverbyields an accuracy of 82% in English and 93% inHungarian, which suggests that there is a higherlevel of ambiguity for English adverbial phrases.For instance, the preposition by may introduce anadverbial modifier of manner (MNR) in by cre-ating a bill and the agent in a passive sentence(LGS).
Thus, labeling adverbs seems to be a more6However, there exists a head-before-dependent versionof the sentence (Felvette a ruha?t a kirakatban), whose pre-ferred reading is ?She was in the shop window while dressingup?, that is, the modifier belongs to the verb.62difficult task in English.7Clauses were also often mislabeled in both lan-guages, most typically when there was no overtconjunction between clauses.
Another source oferror was when more than one modifier occurredbefore a noun (5.1% and 4.2% of attachment er-rors in Hungarian and in English): in these cases,the first modifier could belong to the noun (abrown Japanese car) or to the second modifier (abrown haired girl).Multiword Named Entities: As we mentionedin Section 4, members of multiword Named Enti-ties had a proper noun POS-tag and an NE labelin our dataset.
Hence when parsing is based ongold standard POS-tags, their recognition is al-most perfect while it is a frequent source or er-rors in the CoNLL-2009 corpus.
We investigatedthe parse of our 200 sentences with predicted POStags at NEs and found that this introduces severalerrors (about 5% of both attachment and labelingerrors) in Hungarian.
On the other hand, the re-sults are only slightly worse in English, i.e.
iden-tifying the inner structure of NEs does not dependon whether the parser builds on gold standard orpredicted POS-tags since function words like con-junctions or prepositions ?
which mark grammat-ical relations ?
are tagged in the same way in bothcases.
The relative frequency of this error type ismuch higher in English even when the Hungar-ian parser does not have access to the gold propernoun POS tags.
The reason for this is simple: inthe Penn Treebank the correct internal structure ofthe NEs has to be identified beyond the ?phraseboundaries?
while in Hungarian their membersjust form a chain.Annotation errors: We note that our analysistook into account only sentences which containedat least one parsing error and we crawled onlythe dependencies where the gold standard anno-tation and the output of the parser did not match.Hence, the frequency of annotation errors is prob-ably higher than we found (about 1% of the en-tire set of dependencies) during our investigationas there could be annotation errors in the ?error-free?
sentences and also in the investigated sen-tences where the parser agrees with that error.7We would nevertheless like to point out that adverbiallabels have a highly semantic nature, i.e.
it could be arguedthat it is not the syntactic parser that should identify them buta semantic processor.7 ConclusionsWe showed that state-of-the-art dependencyparsers achieve similar results ?
in terms of at-tachment scores ?
on Hungarian and English.
Al-though the results with this comparison should betaken with a pinch of salt ?
as sentence lengths(and information encoded in single words) differ,domain differences and annotation schema diver-gences are uncatchable ?
we conclude that parsingHungarian is just as hard a task as parsing English.We argued that this is due to the relatively goodPOS tagging accuracy (which is a consequenceof the low ambiguity of alternative morphologicalanalyses of a sentence and the good coverage ofthe morphological analyser) and the fact that data-driven dependency parsers employ a rich featurerepresentation which enables them to learn differ-ent kinds of feature weight profiles.We also discussed the domain differencesamong the subcorpora of the Szeged DependencyTreebank and their effect on parsing results.
Ourresults support that there can be higher differencesin parsing scores among domains in one languagethan among corpora from a similar domain butdifferent languages (which again marks pitfalls ofinter-language comparison of parsing scores).Our systematic error analysis showed that han-dling the virtual nodes (mostly empty copula) isa frequent source of errors.
We identified severalphenomena which are not typically listed as Hun-garian syntax-specific features but are challeng-ing for the current data-driven parsers, however,they are not problematic in English (like the at-tachment of conjunctions and negation words andthe attachment problem of nouns and articles).We concluded ?
based on our quantitative analy-sis ?
that a further notable error reduction is onlyachievable if distinctive attention is paid to theselanguage-specific phenomena.We intend to investigate the problem of vir-tual nodes in dependency parsing in more depthand to implement new feature templates for theHungarian-specific challenges as future work.AcknowledgmentsThis work was supported in part by the DeutscheForschungsgemeinschaft grant SFB 732 and theNIH grant (project codename MASZEKER) ofthe Hungarian government.63ReferencesZolta?n Alexin, Ja?nos Csirik, Tibor Gyimo?thy, Ka?rolyBibok, Csaba Hatvani, Ga?bor Pro?sze?ky, and La?szlo?Tihanyi.
2003.
Annotated Hungarian National Cor-pus.
In Proceedings of the EACL, pages 53?56.Anna Babarczy, Ba?lint Ga?bor, Ga?bor Hamp, andAndra?s Rung.
2005.
Hunpars: a rule-based sen-tence parser for Hungarian.
In Proceedings of the6th International Symposium on Computational In-telligence.Csongor Barta, Do?ra Csendes, Ja?nos Csirik, Andra?sHo?cza, Andra?s Kocsor, and Korne?l Kova?cs.
2005.Learning syntactic tree patterns from a balancedHungarian natural language database, the SzegedTreebank.
In Proceedings of 2005 IEEE Interna-tional Conference on Natural Language Processingand Knowledge Engineering, pages 225 ?
231.Bernd Bohnet.
2010.
Top accuracy and fast depen-dency parsing is not a contradiction.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics (Coling 2010), pages 89?97.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-XShared Task on Multilingual Dependency Parsing.In Proceedings of the Tenth Conference on Com-putational Natural Language Learning (CoNLL-X),pages 149?164.Xavier Carreras.
2007.
Experiments with a higher-order projective dependency parser.
In Proceed-ings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 957?961.Do?ra Csendes, Ja?nos Csirik, Tibor Gyimo?thy, andAndra?s Kocsor.
2005.
The Szeged Treebank.
InTSD, pages 123?131.Katalin E?.
Kiss.
2002.
The Syntax of Hungarian.Cambridge University Press, Cambridge.Jason M. Eisner.
1996.
Three new probabilistic mod-els for dependency parsing: an exploration.
In Pro-ceedings of the 16th conference on Computationallinguistics - Volume 1, COLING ?96, pages 340?345.Richa?rd Farkas, Da?niel Szeredi, Da?niel Varga, andVeronika Vincze.
2010.
MSD-KR harmoniza?cio?
aSzeged Treebank 2.5-ben [Harmonizing MSD andKR codes in the Szeged Treebank 2.5].
In VII.
Ma-gyar Sza?m?
?to?ge?pes Nyelve?szeti Konferencia, pages349?353.Jan Hajic?, Alena Bo?hmova?, Eva Hajic?ova?, and BarboraVidova?-Hladka?.
2000.
The Prague DependencyTreebank: A Three-Level Annotation Scenario.
InAnne Abeille?, editor, Treebanks: Building andUsing Parsed Corpora, pages 103?127.
Amster-dam:Kluwer.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 Shared Task: Syntactic and Semantic Depen-dencies in Multiple Languages.
In Proceedings ofthe Thirteenth Conference on Computational Nat-ural Language Learning (CoNLL 2009): SharedTask, pages 1?18.Johan Hall, Jens Nilsson, Joakim Nivre, Gu?lsenEryigit, Bea?ta Megyesi, Mattias Nilsson, andMarkus Saers.
2007.
Single Malt or Blended?A Study in Multilingual Parser Optimization.
InProceedings of the CoNLL Shared Task Session ofEMNLP-CoNLL 2007, pages 933?939.Szila?rd Iva?n, Ro?bert Orma?ndi, and Andra?s Kocsor.2007.
Magyar mondatok SVM alapu?
szintaxiselemze?se [SVM-based syntactic parsing of Hun-garian sentences].
In V. Magyar Sza?m?
?to?ge?pesNyelve?szeti Konferencia, pages 281?283.Taku Kudo and Yuji Matsumoto.
2002.
Japanesedependency analysis using cascaded chunking.
InProceedings of the 6th Conference on Natural Lan-guage Learning - Volume 20, COLING-02, pages1?7.Ryan McDonald and Joakim Nivre.
2011.
Analyzingand integrating dependency parsers.
ComputationalLinguistics, 37:197?230.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005.
Non-Projective Dependency Pars-ing using Spanning Tree Algorithms.
In Proceed-ings of Human Language Technology Conferenceand Conference on Empirical Methods in NaturalLanguage Processing, pages 523?530.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-Projective Dependency Parsing.
In Proceedingsof the 43rd Annual Meeting of the Associationfor Computational Linguistics (ACL?05), pages 99?106.Joakim Nivre, Johan Hall, and Jens Nilsson.
2004.Memory-Based Dependency Parsing.
In HLT-NAACL 2004 Workshop: Eighth Conferenceon Computational Natural Language Learning(CoNLL-2004), pages 49?56.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The CoNLL 2007 Shared Taskon Dependency Parsing.
In Proceedings of theCoNLL Shared Task Session of EMNLP-CoNLL2007, pages 915?932.Ga?bor Pro?sze?ky, La?szlo?
Tihanyi, and Ga?bor L. Ugray.2004.
Moose: A Robust High-Performance Parserand Generator.
In Proceedings of the 9th Workshopof the European Association for Machine Transla-tion.John R. Ross.
1986.
Infinite syntax!
ABLEX, Nor-wood, NJ.Lucien Tesnie`re.
1959.
E?le?ments de syntaxe struc-turale.
Klincksieck, Paris.64Kristina Toutanova, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency net-work.
In Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology - Volume 1, pages 173?180.Viktor Tro?n, Pe?ter Hala?csy, Pe?ter Rebrus, Andra?sRung, Eszter Simon, and Pe?ter Vajda.
2006.
Mor-phdb.hu: Hungarian lexical database and morpho-logical grammar.
In Proceedings of 5th Inter-national Conference on Language Resources andEvaluation (LREC ?06).Da?niel Varga, Pe?ter Hala?csy, Andra?s Kornai, ViktorNagy, La?szlo?
Ne?meth, and Viktor Tro?n.
2005.
Par-allel corpora for medium density languages.
In Pro-ceedings of the RANLP, pages 590?596.Veronika Vincze, Do?ra Szauter, Attila Alma?si, Gyo?rgyMo?ra, Zolta?n Alexin, and Ja?nos Csirik.
2010.
Hun-garian Dependency Treebank.
In Proceedings of theSeventh Conference on International Language Re-sources and Evaluation (LREC?10).65
