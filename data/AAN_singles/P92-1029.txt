Association-based Natural Language Processingwith Neural NetworksKIMURA Kazuhiro SUZUOKA TakashiAMANO Sin-yaInformation Systems LaboratoryResearch and Development CenterTOSHIBA Corp.1 Komukai-T6siba-ty6, Saiwai-ku, Kawasaki 210 Japankim~isl.rdc.toshiba.co.jpAbst ractThis paper describes a natural anguage pro-cessing system reinforced by the use of associ-ation of words and concepts, implemented asaneural network.
Combining an associative net-work with a conventional system contributesto semantic disambiguation i  the process ofinterpretation.
The model is employed withina kana-kanji conversion system and the advan-tages over conventional ones are shown.1 In t roduct ionCurrently, most practical applications in nat-ural language processing (NLP) have beenrealized via symbolic manipulation engines,such as grammar parsers.
However, the cur-rent trend (and focus of research) is shift-ing to consider aspects of semantics and dis-course as part of NLP.
This can be seen inthe emergence of new theories of language,such as Situation Theory \[Barwise 83\] andDiscourse Representation Theory \[Kamp 84\].While these theories provide an excellent the-oretical framework for natural language un-derstanding, the practical treatment of con-text dependency within the language can alsobe improved by enhancing underlying compo-nent technologies, uch as knowledge basedsystems.
In particular, alternate approachesto symbolic manipulation provided by connec-tionist models \[Rumelhart 86\] have emerged.Connectionist approaches enable the extrac-tion of processing knowledge from examples,instead of building knowledge bases manually.The model described here represents theunification of the connectionist approach andconventional symbolic manipulation; its mostvaluable feature is the use of word as-sociations using neural network technology.Word and concept associations appear tobe central in human cognition \[Minsky 88\].Therefore, simulating word associations con-tributes to semantic disambiguation i thecomputational process of interpreting sen-tences by putting a strong preference to ex-pected words(meanings).The paper describes NLP reinforced by as-sociation of concepts and words via a con-nectionist network.
The model is employedwithin a NLP application system for kana-224kanji conversion x.
Finally, an evaluation ofthe system and advantages over conventionalsystems are presented.2 A brief overview ofkana-kanji  conversionJapanese has a several interesting feature inits variety of letters.
Especially the ex-istence of several thousand of kanji (basedon Chinese characters; ~,  111,..) made typingtask hard before the invention of kana-kanjiconversion\[Amano 79\] .
Now it has becomea standard method in inputting Japanese tocomputers.
It is also used in word processorsand is familiar to those who are not computerexperts.
It comes from the simpleness of op-erations.
By only typing sentences by pho-netic expressions of Japanese (kan a), the kana-kanji converter automatically converts kanainto meaningful expressions(kanji).
The sim-plified mechanism of kana-kanji conversion canbe described as two stages of processing: mor-phological analysis and homonym selection.?
Morphological AnalysisKana-inputted (fragment of) sentencesare morphologically analized through dic-tionary look up, both lexicons and gram-mars.
There are many ambiguities inword division due to the agglutinative na-ture of Japanese (Japanese has no spacesin text), Each partitioning of the kanais then further open to being a possibleinterpretation of several alternate kanji.The spoken word douki, for example, canmean motivation, pulsation, synchroniza-tion, or copperware.
All of them are speltidentically in kana( k?5 -~), but have dif-ferent kanji eharacters (~,  ~'t-~, ~\ ] ,  ~11 Many commercial products use kana-kanji conver-sion technology in Japan, including the TOSHIBATosword-series of Japanese word processors.~-~,respectively).
Some kana words have10 or more possible meanings.
Thereforethe stage of Homonym Selection is indis-pensable to kana-kanji conversion for thereduction of homonyms.Homonym SelectionPreferable semantic homonyms are se-lected according to the co-occurrencerestrictions and selectional restrictions.The frequency of use of each word is alsotaken into account.
Usually, the selectionis also reinforced by a simple context hold-ing mechanism; when homonyms appearin previous discourse and one of them ischosen by a user, the word is automat-ically memorized in the system as in acache technology.
Then, when the samehomonyms appear the memorized word isselected as the most preferred candidateand is shown to the user.3 Assoc iat ion-based kana-kanji convers ionThe above mechanisms are simple and effec-tive in regarding kana-kanji converter as a typ-ing aid.
However, the abundance of homonymsin Japanese contributes to many of the am-biguities and a user is forced to choose thedesired kanji from many candidates.
To re-duce homonym ambiguities a variety of tech-niques are available; however, these tend tobe limited from a semantic disambiguationperspective.
In using word co-occurrence re-strictions, it is necessary to collect a largeamount of co-occurrence phenomena, a prac-tically impossible task.
In the case of theuse of selectional restrictions, an appropri-ate thesaurus is necessary but it is knownthat defining the conceptual hierarchy is dif-ficult work \[Lenat 89\]\[EDR 90\].
Techniquesfor storing previous kanji selections (cache)225Text ;ua .
l  Znpu ~".
......... ...... j',,'-.. / ~ \~ ~ \  ',, "t.. ~ 2"~J~ ',, " - ~Figure 1: Kana-Kanji Conversion with a Neural Networkare too simple to disambiguate between possi-ble previous elections for the same homonymwith respect o the context or between contextswitches.To avoid these problems without increasingcomputational costs, we propose the use of theassociative functionality of neural networks.The use of association is a natural extension tothe conventional context holding mechanism.The idea is summarized as follows.
There aretwo stages of processing: network generationand kana-kanji conversion.A network representing the strength of wordassociation is automatically generated fromreal documents.
Real documents can be con-sideredas training data because they are madeof correctly converted kanji.
Each node inthe network uniquely correspond to a wordentry in the dictionary of kana-kanji conver-sion.
Each node has an activation level.The link between nodes is a weighted linkand represents the strength of association be-tween words.
The network is a Hopfield-typenetwork\[Hopfield 84\]; links are bidirectionaland a network is one layered.When the user chooses a word fromhomonym candidates, a certain value is in-putted to the node corresponding to the cho-sen word and the node will be activated.
Theactivation level of nodes connected to the ac-tivated node will be then activated.
In thismanner, the activation spreads over the net-226work through the links and the active part ofthe network can be considered as the associa-tive words in that context.
In kana-kanji con-version, the converter decides the preferenceof word order for homonyms in the given con-text by comparing the node activation level ofeach node of homonyms.
An example of themethod is shown in Figure 1.Assume the network is already built fromcertain documents.
A user is inputting a textwhose topic is related to computer hardware.In the example, words like clock ( ~ t~ .~ ~ )and signal (4~'-~-) already appear in the previ-ous context, so their activation levels are rela-tively high.
When the word DOUKI (~") ~)is inputted in kana and the conversion starts,the activation level of synchronization (~J~)is higher than that of other candidates due toits relationship to clock or signal.
The inputdouki s then correctly converted into synchro-nization (\[~jtj\]).The advantages of our method are:* The method enables kanji to be givenbased on a preference related to the cur-rent context.
Alternative kanji selectionsare not discarded but are just given alower context weighing.
Should the con-text switch, the other possible selectionswill obtain a stronger context preference;this strategy allows the system to capablyhandle context change.
* Word preferences of a user are reflected inthe network.?
The correctness of the conversion is im-proved without high-cost computationsuch as semantic/discourse analyses.4 Implementat ionThe system was built on Toshiba AS-4000workstation (Sun4 compatible machine) usingC.
The system configuration is shown in Fig-ure 2.The left-hand side of the dashed line repre-sents an off-line network building process.
Theright-hand side represents a kana-kanji con-version process reinforced with a neural net-work handler.
The network is used by theneural network handler and word associationsare done in parallel with kana-kanji conver-sion.
The kana-kanji converter receives kana-sequences from a user.
It searches the dictio-nary for lexical and grammatical informationand finally creates a list of possible homonymcandidates.
Then the neural network handleris requested for activation levels of homonyms.After the selection of preferred homonyms, itshows the candidates in kanji to a user.
Whenthe user chooses the desired one, the chosenword information is sent to the neural networkhandler through a homonym choice interfaceand the corresponding node is activated.The roles and the functions of main compo-nents are described as follows.
* Neural Network GeneratorSeveral real documents are analyzed andthe network nodes and the weights of linksare automatically decided.
The docu-ments consist of the mixture of kana andkanji; homonyms for the kanji within thegiven context are also provided.
The doc-uments, therefore, can be seen as trainingdata for the neural network.
The analysisproceeds through the following steps.1.
Analyze the documents morpholog-ically and convert into a sequenceof words.
Note that particles anddemonstratives are ignored becausethey have no characteristics in wordassociation.2.
Count up the frequency of the allcombination of co-appeared word-pair in a paragraph and memorize227ass~laC lve  net~rXI1F~D~tlom.~7H~dlerLex.lcons ?
1 ~ammars h i raganasequeltce4I Kana.Kaq/i-!activation l eve lso1" neurons homonymcandlda tesfin kanJ$)actlvet~ngchoeen neuronsFigure 2: System Configuration!~ .
.
jI,u.#'~ithem as the strength of connection.A paragraph is recognized only by aformat information of documents.3.
Sum up the strength of connectionfor each word-pair.4.
Regularize the training data; thisinvolves removing low occurrences(noise) and partitioning the fre-quency range in order to obtaina monotonically decreasing (in fre-quency) training set.Although the network data haveonly positive links and not all nodesare connected, non-connected nodesare assumed to be connected by neg-ative weights so that the Hopfieldconditions \[Hopfield 84\] are satisfied.As described above, the technique usedhere is a morphological and statisticalanalysis.
Actually this module is a pat-tern learning of co-appearing words in aparagraph.The idea behind of this approach is thatwords that appear together in a para-graph have some sort of associative con-nection.
By accumulating them, pairswithout such relationships will be statis-tically rejected.From a practical point of view, automatednetwork generation is inevitable.
Sincehuman word association differ by individ-228ual, creation of a general purpose asso-ciative network is not realistic.
Becausethe training data for the network is sup-posed to be supplied by users' documentsin our system, automatic network genera-tion mechanism is necessary even if thegenerated network is somewhat inaccu-rate.?
Neural Network HandlerThe role of the module is to recall thetotal patterns of co-appearing words in aparagraph from the partial patterns of thecurrent paragraph given by a user.The output value Oj for each node j iscalculated by following equations.Oj = f (n j )nj = (1 - 5)nj + 6(Z  wjiO i -11- I j)iwheref : a sigmoidal function: a real number epresenting the inertiaof the network(0 < ~ < 1).nj : input value to node j .Ij : external input value to node j.wjl : weight of a link from node i to nodej ;  W j i  ---- Wi j  , Wii .~ O.The external input value Ij takes a cer-tain positive value when the word corre-sponding to node j is chosen by a user.Otherwise zero.Although the module is software imple-mented, it is fast enough to follow tiletyping speed of a user.
2?
Kana-Kanji Converter2A certain optinfization technique is used respect-ing for the spm-seness of the network.Tile basic algorithm is almost same asthe conventional one.
The difference isthat holnonym candidates are sorted bythe activation levels of the correspond-ing nodes in the network, except when lo-cal constraints such as word co-occurrencerestrictions are applicable to the candi-dates.
The associative information alsoaffects the preference decision of gram-matical ambiguities.5 Eva luat ionTo evaluate tile method, we tested the im-plemented sytem by doing kana-kanji conver-sion for real documents.
The training dataand tested data were taken from four typesof documents: business letters, personal et-ters, news articles, and technical articles.
Theamount of training data and tested data wasover 100,000 phrases and 10,000 phrases re-spectively, for each type of document.
Themeasure for accuracy of conversion was a re-duction ratio(RR) of the homonym choiceoperations of a user.
For comparison, wealso evaluated the reduction rat io(RR ~) of thekana-kanji conversion with a conventional con-text holding mechanism.RR = (A - B ) /ARR'  = (A - C ) /Awhe1:eA : number of clmice operations required whenan untrained kana-kanji converter was used.B : number of choice operations required whena NN-trained kana-kanji converter was used.C : nunlber of choice operations requiredwhen a kana-kanji converter with a conven-tional context holding mechanism was used.Tile result is shown in Table 1.
The ad-vantages of our method is clear for each type229Table 1: Result of the Evaluationdocument-type RR(%) RR'(%)business letters 41.8 32.6personal letters 20.7 12.7news articles 23.4 12.2technical articles 45.6 40.7of documents.
Especially, it is notable thatthe advantages in business letter field is promi-nent, because more than 80% of word proces-sor users write business letters.6 D iscuss ionAlthough the result of conversion test is sat-isfactory, word associations by neural networkare not human-like ones yet.
Following is a listof improvements that many further enhancethe system:?
Improvements for generating a networkThe quality of the network depends onhow to reduce noisy word occurrence inthe network from the point of view of as-sociation.
The existence of noisy wordsis inevitable in automatic generation butplays a role to make unwanted associa-tions.
One approach to reducing noisywords is to identify those words whichare context independent and remove themfrom the network generation stage.
Theidentification can be based on word cat-egories and meanings.
In most cases,words representing very abstract conceptsare noisy because they force unwanted ac-tivations in unrelated contexts.
There-fore they should be detected through ex-periments.
Another problem arises be-cause of the ambiguity of morphologicalanalysis.
Word extraction from real doc-uments is not always correct because ofthe agglutinative nature of the Japaneselanguage.
Other possibility for networkimprovement is to consider a syntacticrelationship or co-occurrence r lationshipwhile deciding link weights.
In addition,there are keywords in a document in gen-eral which play a central role in associa-tion.
They will be reflected in a networkmore in consideration of technical terms.Preference decision in kana-kanji conver-sionThe reinforcement of associative informa-tion complicates the decision of homonympreference in kana-kanji conversion.
Wealready have several means of seman-tic disambiguation of homonyms: co-occurrence restrictions and selectional re-strictions.
As building a complete the-saurus is very difficult, our thesaurusis still not enough to select the cor-rect meaning(kanfi-conversion) of kana-written word.
So selectional restrictionsshould be weak constraints in homonymselection.
In the same vein, associativeinformation should be considered a weakconstraint because associations by neuralnetworks are not always reliable.
Pos-sible conflict between selectional restric-tions and associative information, addedto tile grammatical mbiguities remainingin the stage of homonym selection, makekanji selection very complex.
The prob-lem of multiply and weakly constrained230homonyms i one to which we have notyet found the best solution.7 Conclus ionThis paper described an association based nat-ural language processing and its applicationto kana.kanji conversion.
We showed advan-tages of the method over the conventional onethrough the experiments.
After the improve-ments discussed above, we are planning to de-velop a neuro-word processor available in com-mercial use.
We are also planning the applica-tion of the method to other fields includingmachine translations and discourse analysesfor natural anguage interface to computers.References\[Amano 79\]\[Barwise 83\]\[EDR 90\]\[Hopfield 84\]\[Kamp 84\]Kawada, T. and Amano, S.,"Japanese Word Processor,"Proc.
IJCAI-79, pp.
466-468,1979.Barwise, J. and Perry, J., "Sit-uations and Attitudes," MITPress, 1983.Japan Electronic DictionaryResearch Institute,"Concept Dictionary," Tech.Rep.
No.027, 1990.Hopfield, J., "Neurons withGraded Response Have Col-lective Computational Proper-ties Like Those of Two-StateNeurons," Proc.
Natl.
Acad.Sci.
USA 81, pp.
3088-3092,1984.Kamp, H., "A Theory ofTruth and Semantic Repre-sentation," in Groenendijk et\[Lenat 89\]\[Minsky 88\]\[Rumelhart 86\]\[Waltz 85\]al(eds.)
"Truth, Interpreta-tion and Information", 1984.Lenat, D. and Guha, R.,"Building Large Knowledge-Based Systems: Represen-tation and Inference inthe Cyc Project," Addison-Wesley, 1989.Minsky, M., "The Society OfMind,", Simon gz SchusterInc., 1988.Rumelhart, D., McClelland,J., and the PDP ResearchGroup, "Parallel DistributedProcessing: Explorations inthe Microstructure of Cogni-tion," MIT Press, 1986.Waltz, D. and Pollack, J.,"Massively Parallel Parsing:A Strongly Interactive Modelof Natural Language Interpre-tation," Cognitive Science, pp.51-74, 1985.231
