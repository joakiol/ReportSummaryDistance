Sense Disambiguation Using SemanticRelations and Adjacency InformationAnil S. ChakravarthyMIT Media Laboratory20 Ames Street E15-468aCambridge MA 02139anil @ media.mit.eduAbstractThis paper describes aheuristic-based approach toword-sense disambiguation.
The heuristics that areapplied to disambiguate a word depend on its part ofspeech, and on its relationship to neighboring salientwords in the text.
Parts of speech are found through atagger, and related neighboring words are identified by aphrase xtractor operating on the tagged text.
To suggestpossible senses, each heuristic draws on semantic rela-tions extracted from a Webster's dictionary and thesemantic thesaurus WordNet.
For a given word, allapplicable heuristics are tried, and those senses that arerejected by all heuristics are discarded.
In all, the disam-biguator uses 39 heuristics based on 12 relationships.1 IntroductionWord-sense disambiguation has long been recognized asa difficult problem in computational linguistics.
As earlyas 1960, Bar-Hillel \[1\] noted that a computer programwould find it challenging to recognize the two differentsenses of the word "pen" in "The pen is in the box," and"The box is in the pen."
In recent years, there has been aresurgence of interest in word-sense disambiguation dueto the availability of linguistic resources like dictionar-ies and thesauri, and due to the importance of disambig-uation in applications like information retrieval andmachine translation.The task of disambiguation is to assign a word to one ormore senses in a reference by taking into account thecontext in which the word occurs.
The reference can bea standard ictionary or thesaurus, or a lexicon con-structed specially for some application.
The context isprovided by the text unit (paragraph, sentence, tc.)
inwhich the word occurs.The disambiguator described in this paper is based ontwo reference sources, the Webster's Seventh Dictionaryand the semantic thesaurus WordNet \[12\].
Before thedisambiguator is applied, the text input is processed firstby a part-of-speech tagger and then by a phrase xtrac-tor which detects phrase boundaries.
Therefore, for eachambiguous word, the disambiguator knows the part ofspeech, and other phrase headwords and modifiers thatare adjacent to it.
Based on this context information, thedisambiguator uses a set of heuristics to assign one ormore senses from the Webster's dictionary or WordNetto the word.
Here is an example of a heuristic that relieson the fact that conjoined head nouns are likely to referto objects of the same category.
Consider the ambiguousword "snow" in the sentence "Slush and snow filled theroads."
In this sentence, the tagger identifies "snow" asa noun.
The phrase xtractor indicates that "snow" and"slush" are conjoined head words of a noun phrase.Then, the heuristic uses WordNet o identify the sensesof "slush" and "snow" that belong to a common cate-gory.
Therefore, the sense of "snow" as "cocaine" is dis-carded by this heuristic.The disambiguator has been incorporated into two infor-mation retrieval applications which use semantic rela-tions (like A-KIND-OF) from the dictionary andWordNet o match queries to text.
Since semantic rela-tions are attached to particular word senses in the dictio-nary and WordNet, disambiguated representations of thetext and the queries lead to targeted use of semantic rela-tions in matching.The rest of the paper is organized as follows.
The nextsection reviews existing approaches todisambiguationwith emphasis on directly related methods.
Section 3describes in more detail the heuristics and adjacencyrelationships used by the disambiguator.2932 Previous Work on DisambiguationIn computational linguistics, considerable effort hasbeen devoted to word-sense disambiguation \[8\].
Theseapproaches can be broadly classified based on the refer-ence from which senses are assigned, and on the methodused to take the context of occurrence into account.
Thereferences have ranged from detailed custom-built lexi-cons (e.g., \[l 1\]) to standard resources like dictionariesand thesauri l ke Roget's (e.g., \[2, 10, 14\]).
To take thecontext into account, researchers have used a variety ofstatistical weighting and spreading activation models(e.g., \[9, 14, 15\]).
This section gives brief descriptionsof some approaches that use on-line dictionaries andWordNet as references.WordNet is a large, manually-constructed s mantic net-work built at Princeton University by George Miller andhis colleagues \[12\].
The basic unit of WordNet is a set ofsynonyms, called a synset, e.g., \[go, travel, move\].
Aword (or a word collocation like "operating room") canoccur in any number of synsets, with each synset reflect-ing a different sense of the word.
WordNet is organizedaround a taxonomy of hypernyms (A-KIND-OF rela-tions) and hyponyms (inverses of A-KIND-OF), and 10other elations.
The disambiguation algorithm describedby Voorhees \[16\] partitions WordNet into hoods, whichare then used as sense categories (like dictionary subjectcodes and Roget's thesaurus classes).
A single synset isselected for nouns based on the hood overlap with thesurrounding text.The research on extraction of semantic relations fromdictionary definitions (e.g., \[5, 7\]) has resulted in newmethods for disambiguation, e.g., \[2, 15\].
For example,Vanderwende \[15\] uses semantic relations extractedfrom LDOCE to interpret nominal compounds (nounsequences).
Her algorithm disambiguates nounsequences by using the dictionary to search for pre-defined relations between the two nouns; e.g., in thesequence "bird sanctuary," the correct sense of"sanctu-ary" is chosen because the dictionary definition indi-cates that a sanctuary is an area for birds or animals.Our algorithm, which is described in the next section, isin the same spirit as Vanderwende's but with two maindifferences.
In addition to noun sequences, the algo-rithm has heuristics for handling 11 other adjacencyrelationships.
Second, the algorithm brings to bear bothWordNet and semantic relations extracted from an on-line Webster's dictionary during disambiguation.3 Sense Disambiguation withAdjacency InformationThe input to the disambiguator is a pair of words, alongwith the adjacency relationship that links them in theinput text.
The adjacency relationship is obtained auto-matically by processing the text through the XeroxPARC part-of-speech tagger \[6\] and a phrase xtractor.The 12 adjacency relationships used by the disambigua-tor are listed below.
These adjacency relationships werederived from an analysis of captions of news photo-graphs provided by the Associated Press.
The examplesfrom the captions also helped us identify the heuristicrules necessary for automatic disambiguation usingWordNet and the Webster's dictionary.
In the tablebelow, each adjacency category is accompanied by anexample.
39 heuristic rules are used currently.Adjacency Relationship ExampleAdjective modifying a noun Express trainPossessive modifying anoun Pharmacist's coatNoun followed by a proper Tenor Lucianoname PavarottiPresent participle gerund Training drillmodifying anounNoun nounConjoined nounsNoun modified by a noun atthe head of a following "of 'PPNoun modified by a noun atthe head of a following "non-of" PPNoun that is the subject of anaction verbNoun that is the object of anaction verbBasketball fanA church and a homeBarrel of the rifleA mortar with a shellA monitor displaysinformationWrite a mysteryNoun that is at the head of a Sentenced to lifeprepositional phrase follow-ing a verbNouns that are subject and The hawk found aobject of the same action perchGiven a pair of words and the adjacency relationship,the disambiguator applies all heuristics corresponding tothat category, and those word senses that are rejected byall heuristics are discarded.
Due to space considerations,we will not describe the heuristic rules individually but294instead identify some common salient features.
The heu-ristics are described in detail in \[3\].?
Several heuristics look for a particular semantic rela-tion like hypernymy or purpose linking the two inputwords, e.g., "return" is a hypernym of "forehand."?
Many heuristics look for particular semantic rela-tions linking the two input words to a common wordor synset; e.g., a "church" and a "home" are bothbuildings.?
Many heuristics look for analogous adjacency pat-terns either in dictionary definitions or in examplesentences, e.g., "write a mystery" is disambiguatedby analogy to the example sentence "writes poemsand essays."?
Some heuristics look for specific hypernyms such asperson or place in the input words; e.g., if a noun isfollowed by a proper name (as in "tenor LucianoPavarotti" or "pitcher Curt Schilling"), those sensesof the noun that have "person" as a hypernym arechosen.The disambiguator has been used in two retrieval pro-grams, ImEngine, a program for semantic retrieval ofimage captions, and NetSerf, a program for findingInternet information archives \[3, 4\].
The initial resultshave not been promising, with both programs reportingdeterioration i  performance when the disambiguator isincluded.
This agrees with the current wisdom in the IRcommunity that unless disambiguation is highly accu-rate, it might not improve the retrieval system's perfor-mance \[ 13\].References1.
Bar-Hillel, Yehoshua.
1960.
"The Present Status ofAutomatic Translation of Languages," inAdvancesin Computers, F. L. Alt, editor, Academic Press, NewYork.2.
Braden-Harder, Lisa.
1992.
"Sense DisambiguationUsing On-line Dictionaries," inNatural LanguageProcessing: The PLNLP Approach, Jensen, K.,Heidorn, G. E., and Richardson, S. D., editors, Klu-wer Academic Publishers.3.
Chakravarthy, Anil S. 1995.
"Information Accessand Retrieval with Semantic Background Knowl-edge" Ph.D thesis, MIT Media Laboratory.4.
Chakravarthy, Anil S. and Haase, Kenneth B.
1995.
"NetSerf: Using Semantic Knowledge to Find Inter-net Information Archives," to appear in Proceedingsof SIGIR'95.5.
Chodorow, Martin.
S., Byrd, Roy.
J., and Heidorn,George.
E. 1985.
"Extracting Semantic Hierarchiesfrom a Large On-Line Dictionary," in Proceedings ofthe 23rd ACL.6.
Cutting, Doug, Julian Kupiec, Jan Pedersen, andPenelope Sibun.
1992.
"A Practical Part-of-SpeechTagger," in Proceedings ofthe Third Conference onApplied NLP.7.
Dolan, William B., Lucy Vanderwende, and Richard-son, Steven.
D. 1993.
"Automatically DerivingStructured Knowledge Bases from On-line Dictio-naries," in Proceedings ofthe First Conference ofthe Pacific Association for Computational Linguis-tics, Vancouver.8.
Gale, William, Church, Kenneth.
W., and DavidYarowsky.
1992.
"Estimating Upper and LowerBounds on the Performance ofWord-sense Disam-biguation Programs," in Proceedings ofACL-92.9.
Hearst, Marti.
1991.
"Noun Homograph Disambigu-ation Using Local Context in Large Text Corpora,"Proceedings ofthe 7th Annual Conference ofthe UWCentre for the New OED and Text Research, Oxford,England.10.
Lesk, Michael.
1986.
"Automatic Sense Disambigu-ation: How to Tell a Pine Cone from an Ice CreamCone," in Proceedings ofthe SIGDOC Conference11.
McRoy, Susan.
1992.
"Using Multiple KnowledgeSources for Word Sense Discrimination," in Compu-tational Linguistics, 18(1).12.
Miller, George A.
1990.
"WordNet: An On-line Lex-ical Database," in International Journal of Lexicog-raphy, 3(4).13.
Sanderson, Mark.
1994.
"Word Sense Disambigua-tion and Information Retrieval," in Proceedings ofSIGIR '94.14.
Yarowsky, David.
1992.
"Word Sense Disambigua-tion Using Statistical Models of Roget's CategoriesTrained on Large Corpora," in Proceedings ofCOL-ING-92, Nantes, France.15.
Vanderwende, Lucy.
1994.
"Algorithm for Auto-matic Interpretation fNoun Sequences," in Pro-ceedings of COLING-94, Kyoto, Japan.16.
Voorhees, Ellen.
M. 1993.
"Using WordNet o Dis-ambiguate Word Senses for Text Retrieval," in Pro-ceedings of SIGIR'93.295
