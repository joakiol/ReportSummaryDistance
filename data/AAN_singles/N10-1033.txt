Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 263?266,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsTwo monolingual parses are better than one (synchronous parse)?Chris DyerUMIACS Laboratory for Computational Linguistics and Information ProcessingDepartment of LinguisticsUniversity of Maryland, College Park, MD 20742, USAredpony AT umd.eduAbstractWe describe a synchronous parsing algorithmthat is based on two successive monolingualparses of an input sentence pair.
Althoughthe worst-case complexity of this algorithmis and must be O(n6) for binary SCFGs,its average-case run-time is far better.
Wedemonstrate that for a number of commonsynchronous parsing problems, the two-parsealgorithm substantially outperforms alterna-tive synchronous parsing strategies, making itefficient enough to be utilized without resort-ing to a pruned search.1 IntroductionSynchronous context free grammars (SCFGs) gener-alize monolingual context-free grammars to gener-ate strings concurrently in pairs of languages (Lewisand Stearns, 1968) in much the same way that fi-nite state transducers (FSTs) generalize finite stateautomata (FSAs).1Synchronous parsing is the prob-lem of finding the best derivation, or forest of deriva-tions, of a source and target sentence pair ?f, e?
underan SCFG, G.2Solving this problem is necessary forseveral applications, for example, optimizing howwell an SCFG translation model fits parallel train-ing data.
Wu (1997) describes a bottom-up O(n6)synchronous parsing algorithm for ITGs, a binarySCFG with a restricted form.
For general grammars,the situation is even worse: the problem has beenshown to be NP-hard (Satta and Peserico, 2005).Even if we restrict ourselves to binary ITGs, the?This work was supported in part by the GALE program ofDARPA, Contract No.
HR0011-06-2-001.
The author wishesto thank Philip Rensik, Adam Lopez, Phil Blunsom, and JasonEisner for helpful discussions.1SCFGs have enjoyed a resurgence in popularity as the for-mal basis for a number of statistical translation systems, e.g.Chiang (2007).
However, translation requires only the manipu-lation of SCFGs using monolingual parsing algorithms.2It is assumed that n = |f| ?
|e|.O(n6) run-time makes large-scale learning applica-tions infeasible.
The usual solution is to use a heuris-tic search that avoids exploring edges that are likely(but not guaranteed) to be low probability (Zhang etal., 2008; Haghighi et al, 2009).
In this paper, wederive an alternative synchronous parsing algorithmstarting from a conception of parsing with SCFGs asa composition of binary relations.
This enables usto factor the synchronous parsing problem into twosuccessive monolingual parses.
Our algorithm runsmore efficiently than O(n6) with many grammars(including those that required using heuristic searchwith other parsers), making it possible to take ad-vantage of synchronous parsing without developingsearch heuristics; and the SCFGs are not requiredto be in a normal form, making it possible to easilyparse with more complex SCFG types.2 Synchronous parsingBefore presenting our algorithm, we review theO(n6) synchronous parser for binary ITGs.32.1 ITG synchronous parsing algorithmWu (1997) describes a bottom-up synchronous pars-ing algorithm that can be understood as a generaliza-tion of the CKY algorithm.
CKY defines a table con-sisting of n2cells, with each cell corresponding to aspan [i, j] in the input sentence; and the synchronousvariant defines a table in 4 dimensions, with cellscorresponding to a source span [s, t] and a targetspan [u, v].
The bottom of the chart is initializedfirst, and pairs of items are combined from bottomto top.
Since combining items from the n4cells in-volves considering two split points (one source, onetarget), it is not hard to see that this algorithm runsin time O(n6).3Generalizing the algorithm to higher rank grammars is pos-sible (Wu, 1997), as is converting a grammar to a weakly equiv-alent binary form in some cases (Huang et al, 2009).2632.2 Parsing, intersection, and compositionWe motivate an alternative conception of the syn-chronous parsing problem as follows.
It has longbeen appreciated that monolingual parsing computesthe intersection of an FSA and a CFG (Bar-Hillel etal., 1961; van Noord, 1995).
That is, if S is an FSAencoding some sentence s, intersection of S with aCFG, G, results in a parse forest which contains alland only derivations of s, that is L(S) ?
L(G) ?
{{s}, ?
}.4Crucially for our purposes, the resultingparse forest is also itself a CFG.5Figure 1 illus-trates, giving two equivalent representations of theforest S?G, once as a directed hypergraph and onceas a CFG.
While S ?
G appears similar to G, thenon-terminals (NTs) of the resulting CFG are a crossproduct of pairs of states from S and NTs from G.6Two parses are better than one (for synchronous parsing)Chris DyerUMIACS Laboratory for Computational Linguistics and Information ProcessingDepartment of LinguisticsUniversity of Maryland, College Park, MD 20742, USAredpony AT umd.eduAbstractWe describe an alternative to the well-knownO(n6) synchronous parsing algorithm givenin Wu (1997).
Although this algorithm, whichis based on two successive monolingual parsesof the input sentence pair, does not (and prov-ably can not) improve the worst-case run-time, its best-case performance is O(n3).
Weshow that for a number of common syn-chronous parsing problems, the two-parse al-gorithm performs efficiently enough to be uti-lized, without pruning, in iterative learning al-gorithms that rely on inside-outside inference.The algorithm has further advantages: prun-ing strategies that would be difficult to realizein the original algorithm become feasible, andcertain kinds of discriminative training requirethe results of both parses, making this algo-rithm a natural fit when those training regimesare required.1 IntroductionSynchronous context free grammars (SCFGs) gener-alize traditional context-free grammars to generatestrings concurrently in a pair of languages (Lewisand Stearns, 1968), in much the same way that fi-nite state transducers (FSTs) generalize finite stateautomata.
In recent years, SCFGs have enjoyeda resurgence in popularity as the formal basis forseveral of the best-performing statistical machinetranslation systems (Chiang, 2007; Zollmann et al,2008).
The translation task is a straightforward ma-nipulation of SCFGs using standard monolingual al-gorithms.
To translate some f (a string of words inthe source language) into the target language, f isparsed (with a monolingual parser), which, becauseof the parallel structure of the rules, induces a forestof translations in the target language.Synchronous parsing, which is our focus for theremainder of this paper, is the problem of findingthe best derivation, or the forest of derivations, ofa source and target sentence pair ?f, e?.
This forestis particularly useful in learning problems since itcan be used to compute and optimize statistics aboutderivations of parallel training data.
In the MT lit-erature, this task is also known as ?const ained d -coding?.
Wu (1997) d cribes a bottom-up algo-rithm for constructing this forest given a sentencepair ?f, e?
and grammar G that runs in O(|f|3|e|3)since we will assume that n = |f| ?
|e|, the run-time is O(n6).1.1 Parsing as compositionWe motivate an alternative conception of the syn-chronous parsing problem as follows.
It has longbeen appreciated that parsing computes the intersec-tion of an FSA and a CFG (Bar-Hillel et al, 1961;van Noord, 1995; Grune and Jacobs, 2008).
Thatis, parsing an FSA, S, with a CFG, G, results in aparse forest which contains derivations of strings inI = L(S) ?
L(G),1and which may be ?.
But, it ishelpful to keep in mind that the resulting parse for-est is also itself a CFG (that exactly derives stringsin I).
See Figure ??
for an example.In the parallel parsing case, it?s helpful to thinkin terms of an SCFG representing a context-free re-lations and parallel parsing as being a composition1In the familiar case, S is a deterministic linear chain FSArepresenting a sentence.0 1 2 43i saw the forestTwo parses are better than one (for synchronous parsing)Chris DyerUMIACS Laboratory for Computational Linguistics and Information ProcessingDepartment of LinguisticsUniversity of Maryland, College Park, MD 20742, USAredpony AT umd.eduAbstractWe describe an alternative to the well-knownO(n6) synchronous parsing algorithm givenin Wu (1997).
Although this algorithm, whichis based on two successive monolingual parsesof the input sentence pair, does not (and prov-ably can not) improve the worst-case run-time, its best-case performance is O(n3).
Weshow that for a number of common sy -chronous parsing problems, the two-parse al-gorithm performs efficiently en ugh to be uti-lized, without pruning, iterative learning al-gorithms that rely on inside-outside infer nce.The algorithm has further advantages: prun-ing strategies that would be difficult to realizein the original algorithm become feasible, andcertain kinds of discriminative training requirethe results of both parses, making this algo-rithm a natural fit when those training regimesare required.1 IntroductionSynchronous contex free grammars (SCFGs) gener-alize traditional context-free grammars to generatestrings concurrently in a pair of languages (Lewisand Stearns, 1968), in much the same way that fi-nite state transducers (FSTs) generalize finite stateautomata.
In recent years, SCFGs have enjoyeda resurgence in popularity as the formal basis forseveral of the best-performing statistical machinetranslation systems (Chia g, 2007; Zollmann et al,2008).
The translation task is a straightforward ma-nipulation of SCFGs using standard monolingual al-gorithms.
To translate some f (a string of words inthe source language) into the target nguage, f isparsed (with a monolingual parser), which, becauseof the parallel structure of the rules, induces a forestof translations in the target language.Synchronous parsing, which is our focus for theremainder of this paper, is the problem of findingthe best derivation, or the forest of derivations, ofa source and target sentence pair ?f, e?.
This forestis particularly useful in learning problems since itcan be used to compute and optimize sta stics boutderivations of parallel training data.
In the MT lit-erature, this task is also known as ?constrained de-coding?.
Wu (1997) describes a bottom-up algo-rithm for constructing this forest given a sentencepair ?f, e?
and grammar G that runs in O(|f|3|e|3)since we will assume that n = |f| ?
|e|, the run-tim is O(n6).1.1 Parsing as compositionWe motivate an alternative conception of the syn-chronous parsing problem as follows.
It has longbeen appreciated that parsing computes the intersec-tion of an FSA and a CFG (Bar-Hillel et al, 1961;van Noord, 1995; Grune and Jacobs, 2008).
Thatis, parsing an FSA, S, with a CFG, G, results in aparse forest which contains derivations of strings inI = L(S) ?
L(G),1and which may be ?.
But, it ishelpful to keep in mind that the resulting parse for-est is also itself a CFG (that exactly derives stringsin I).
See Figure ??
for an example.In the parallel parsing case, it?s helpful to thinkin terms of an SCFG repr senting a text-fre re-lations and parallel parsing as being a composition1In the familiar case, S is a deterministic linear chain FSArepresent ng a sentence.NP VPSPRNNPDT NNNPV NPVPtheDTaDTforestNNtreeNNiPRNsawVoperation.2S ?
G (1)2 ExperimentsFigure 1 plots the average runtime of the algorithmas a function of the Arabic sentence length on anArabic-English phrasal ITG alignment task.3 R lated workSynchronous parsing has been widely used to com-pute sufficient statistics for a variety of machinelearning models of synchronous trees; however,since the naive algorithm is too slow to deal withsentence sizes, most authors have proposed pruningtechniques.
Zhang et al (2008) suggest tic-tac-toepruning, which uses Model 1 posteriors to excluderanges of cells from being computed.
Blunsom et al(2008) do a monolingual parse with of one languagebut split the parser states by the string yielded bythe target derivations, pruning any nodes that yieldstrings that do not exist in the target.
Haghighi et al(2009) also describe a pruning heuristic that resultsin average case runtime of O(n3).ReferencesY.
Bar-Hillel, M. Perles, and E. Shamir.
1961.
On for-mal properties of simple phrase structure grammars.Zeitschrift f?ur Phonetik, Sprachwissenschaft und Kom-munikationsforschung, 14:143?172.Phil Blunsom, Trevor Cohn, and Miles Osborne.
2008.A discriminative latent variable model for statisticalmachine translation.
In Proceedings of ACL-HTL.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.D.
Grune and C.J.
H. Jacobs.
2008.
Parsing as intersec-tion.
Parsing Techniques, pages 425?442.Aria Haghighi, John Blitzer, John DeNero, and DanKlein.
2009.
Better word alignments with supervisedITG models.
In Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 923?931, August.P.
M. Lewis, II and R. E. Stearns.
1968.
Syntax-directedtransduction.
J. ACM, 15(3):465?488.2For a discussion of the equivalence of composition andintersection in finite-state objects, refer to Mohri (2009).
Al-though necessity forces us to use different algorithms to realizecomposition, the relationship still holds at the context-free level.Figure 1: Synchronous parser runtime as a function of(Arabic) sentence length on an Arabic-English corpus us-ing a phrasal ITG.Mehryar Mohri.
2009.
Weighted automata algorithms.In Manfred Droste, Werner Kuich, and Heiko Vogler,editors, Handbook of Weighted Automata, Mono-graphs in Theoretical Computer Science, pages 213?254.
Springer.Gertjan van Noord.
1995.
The intersection of finite stateautomata and definite clause grammars.
In Proceed-ings of the 33rd Annual Meeting of the Assocationfor Computational Linguistics, pages 159?165, Cam-bridge, MA.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?404, Sep.Hao Zhang, Chris Quirk, Robert C. Moore, andDaniel Gildea.
2008.
Bayesian learning of non-compositional phrases with synchronous parsing.
InProceedings of ACL.Andreas Zollmann, Ashish Venugopal, Franz Och, andJay Ponte.
2008.
A systematic comparison of phrase-based, hierarchical and syntax-augmented statisticalmt.
In Proc.
of 22nd International Conference onComputational Linguistics (Coling), Manchester, U.K.2DT3 3NN42NP41V21VP40S40NP10PRN1i saw the forest0NP11VP40S40PRN10NP12DT33NN42NP41V22NP41VP4the2DT3forest3NN4i0PRN1saw1V2(a) (b)Figure 1: A CFG, G, an FSA, S, encoding a sentence, andtwo equivalent representations of the parse forest S ?
G,(a) as a directed hypergraph and (b) as a CFG.When dealing with SCFGs, rather than intersec-4L(x) denotes the set of strings generated by the gram-mar/automaton x.
In future mentions of intersection and com-position operations, this will be implicit.5Th forest grammar derives only s, but using possibly manyderivations.6Each pair of states from the FSA corresponds to a span [i, j]in a CKY table.tion, parsing computes a related operation, composi-tion.7The standard MT decoding-by-parsing taskcan be understood as computing the compositionof an FST,8F , which encodes the source sentencef with the SCFG, G, representing the translationmodel.
The result is the translation forest, F ?
G,which encodes all translations of f licensed by thetranslation model.
While G can generate a poten-tially infinite set of strings in the source and targetlanguages, F ?
G generates only f in the source lan-guage (albeit with possibly infinitely many deriva-tions), but any number of different strings in the tar-get language.
It is not hard to see that a second com-position operation of an FST, E, encoding the targetstring e with the e-side of F ?G (again using a mono-lingual parsing algorithm), will result in a parse for-est that exactly derives ?f, e?, which is the goal ofsynchronous composition.
Figure 2 shows an exam-ple.
In F ?
G ?
E the NTs (nodes) are the crossproduct of pairs of states from E, the NTs from G,and pairs of states in F .Thus, synchronous parsing is the task of comput-ing F ?
G ?E.
Since composition is associative, wecan compute this quantity either as (F ?
G) ?
E orF ?
(G ?E).
Alternatively, we can use an algorithmthat performs 3-way composition directly.2.3 The two-parse algorithm9The two-parse algorithm refers to performing a syn-chronous parse by computing either (F ?
G) ?
E orF ?
(G ?
E).
Each composition operation is carriedout using a standard monolingual parsing algorithm,such as Earley?s or CKY.
In the experiments below,since we use -free grammars, we use a variant ofCKY for unrestricted CFGs (Chiang, 2007).Once the first composition is done, the resultingparse forest must be converted into a CFG repre-sentation that the second parser can utilize.
This isstraightforward to do: each node becomes a uniquenon-terminal symbol, with its incoming edges cor-responding to different ways of rewriting it.
Tailsof edges are non-terminal variables in the RHS ofthese rewrites.
A single bottom-up traversal of theforest is sufficient to perform the conversion.
Since7Intersection is a special case of composition where the in-put and output labels on the transducers are identical (Mohri,2009).8FSTs used to represent the source and target sentences haveidentical input and output labels on every transition.9Satta (submitted) has independently derived this algorithm.264Two parses are better than one (for synchronous parsing)Chris DyerUMIACS Laboratory for Computational Linguistics and Information ProcessingDepartment of LinguisticsUniversity of Maryland, College Park, MD 20742, USAredpony AT umd.eduAbstractWe describe an alternative to the well-knownO(n6) synchronous parsing algorithm givenin Wu (1997).
Although this algorithm, whichis based on two successive monolingual parsesof the input sentence pair, does not (and prov-ably can not) improve the worst-case run-time, its best-case performance is O(n3).
Weshow that for a number of common syn-chronous parsing problems, the two-parse al-gorithm performs efficiently enough to be uti-lized, without pruning, in iterative learning al-gorithms that rely on inside-outside inference.The algorithm has further advantages: prun-ing strategies that would be difficult to realizein the original algorithm become feasible, andcertain kinds of discriminative training requirethe results of both parses, making this algo-rithm a natural fit when those training regimesare required.1 IntroductionSynchronous context free grammars (SCFGs) gener-alize traditional context-free grammars to generatestrings concurrently in a pair of languages (Lewisand Stearns, 1968), in much the same way that fi-nite state transducers (FSTs) generalize finite stateautomata.
In recent years, SCFGs have enjoyeda resurgence in popularity as the formal basis forseveral of the best-performing statistical machinetranslation systems (Chiang, 2007; Zollmann et al,2008).
The translation task is a straightforward ma-nipulation of SCFGs using standard monolingual al-gorithms.
To translate some f (a string of words inthe source language) into the target language, f isparsed (with a monolingual parser), which, becauseof the parallel structure of the rules, induces a forestof translations in the target language.Synchronous parsing, which is our focus for theremainder of this paper, is the problem of findingthe best derivation, or the forest of derivations, ofa source and target sentence pair ?f, e?.
This forestis particularly useful in learning problems since itcan be used to compute and optimize statistics aboutderivations of parallel training data.
In the MT lit-erature, this task is also known as ?constrained de-coding?.
Wu (1997) describes a bottom-up algo-rithm for constructing this forest given a sentencepair ?f, e?
and grammar G that runs in O(|f|3|e|3)since we will assume that n = |f| ?
|e|, the run-time is O(n6).1.1 Parsing as compositionWe motivate an alternative conception of the syn-chronous parsing problem as follows.
It has longbeen appreciated that parsing computes the intersec-tion of an FSA and a CFG (Bar-Hillel et al, 1961;van Noord, 1995; Grune and Jacobs, 2008).
Thatis, parsing an FSA, S, with a CFG, G, results in aparse forest which contains derivations of strings inI = L(S) ?
L(G),1and which may be ?.
But, it ishelpful to keep in mind that the resulting parse for-est is also itself a CFG (that exactly derives stringsin I).
See Figure ??
for an example.In the parallel parsing case, it?s helpful to thinkin terms of an SCFG representing a context-free re-lations and parallel parsing as being a composition1In the familiar case, S is a deterministic linear chain FSArepresenting a sentence.< X , X >S< X b , c X >X< X b , X d >X< a , c >X< a , d >XE0 1 2a bF0 1 2c dFigure 1: A CFG, G, an FSA, S, encoding a sentence,and two reprsentations of the parse forest S ?
G, (a) asa directed hypergraph and (b) as a context-free rewritesystem.
(NTs) of the resulting CFG are a cross product ofpairs of states in the FSA and the NTs in the originalgrammar.When dealing with SCFGs, rather than intersec-tion, parsing computes a related operation, compo-sition.2The standard MT decoding-by-parsing taskcan be understood as computing the composition ofan FST, F , encoding a source sentence f with theSCFG, G, representing the translation model.
Theresult is the so-called translation forest, F ?G, whichencodes all translations of f licensed by the transla-tion model.
Now observe that while G can generatea potentially infinite set of strings in both source lan-guage and target language, F ?G (as an SCFG) gen-erates only f, albeit possibly via several derivations,but different translations e. It is not hard to see thata second composition operation with an E encoding2Intersection is a special case of composition where the in-put and output labels on the transducers are identical (Mohri,2009).a string e in the target will result in the will result ina parse forest that exactly derives ?f, e?, which is thegoal of synchronous composition.Thus, in synchronous parsing, we seek to com-pute F ?G ?E.
Since composition is associative, wecan compute this quantity either as (F ?
G) ?
E orF ?
(G ?E).
Alternatively, we can use an algorithmthat performs 3-way composition directly, such asWu?s algorithm.3F ?
G (1)1.2 AnalysisMonolingual parsing is commonly thought of as aworst-case O(n3) algorithm, even the known algo-rithms do have a grammar term that can contributesignificantly.
However, since the grammar that aparser will employ is generally assumed to be fixed,2 ExperimentsFigure 2 plots the average runtime of the algorithmas a function of the Arabic sentence length on anArabic-English phrasal ITG alignment task.3 Related workSynchronous parsing has been widely used to com-pute sufficient statistics for a variety of machinelearning models of synchronous trees; however,since the naive algorithm is too slow to deal withsentence sizes, most authors have proposed pruningtechniques.
Zhang et al (2008) suggest tic-tac-toepruning, which uses Model 1 posteriors to excluderanges of cells from being computed.
Blunsom et al(2008) do a monolingual parse with of one languagebut split the parser states by the string yielded bythe target derivations, pruning any nodes that yieldstrings that do not exist in the target.
Haghighi et al(2009) also describe a pruning heuristic that resultsin average case runtime of O(n3).ReferencesCyril Allauzen and Mehryar Mohri.
2008.
3-waycomposition of weighted finite-state transducers.
In3Three-way composition algorithms that operate only onFSTs have also been developed (Allauzen and Mohri, 2008).a : c a : d0X10S20X1b :0X1d0X1b : c0X1<0X1b , c0X1>0S2<0X1b ,0X1d >0S2< a , c >0X1< a , d >0X1Figure 1: A CFG, G, an FSA, S, encoding a sentence,and two reprsentations of the parse forest S ?
G, (a) asa directed hypergraph and (b) as a context-free rewritesystem.
(NTs) of the resulting CFG are a cross product ofpairs of states in the FSA and the NTs in the originalgrammar.When dealing with SCFGs, rather than intersec-tion, parsing computes a related operation, compo-sition.2The standard MT decoding-by-parsing taskcan be understood as computing the composition ofan FST, F , encoding a source sentence f with theSCFG, G, representing the translation model.
Theresult is the so-called translation forest, F ?G, whichencod s all tr nslation of f licensed by th transla-tion model.
Now observe that while G can generatea potentially infinite set of strings in both source lan-guage and target language, F ?G (as an SCFG) gen-erates only f, albeit possibly via several derivations,but different translations e. It is not hard to see thata second composition operation with an E encoding2Intersection is a special case of composition where the in-put and output labels on the transducers are identical (Mohri,2009).a stri g e in t target will result in the will result inparse forest that exactly derives ?f, e?, which is thegoal f synchronous composition.Thus, in synchronous parsing, we seek to com-pute F ?G ?E.
Since composition is associative, wecan compute this quantity either as (F ?
G) ?
E orF ?
(G ?E).
Alternatively, we can use an algorithmthat performs 3-way composition directly, such asWu?s algorithm.3F ?
G ?
E (1)1.2 AnalysisMonolingual parsing is com only thought of as aworst-case O(n3) algor thm, even the know lgo-rithms do have a grammar ter that can contributesignificantly.
However, since the grammar that aparser will employ is generally assumed to be fixed,2 ExperimentsFigure 2 plot the average runtime of the algorithmas a fu ction of the Arabic sentence length on anArabic-English phrasal ITG alignment task.3 Related workSynchronous parsing has been widely used to com-pute sufficient statistics for a variety of machinelearning models of synchronous trees; however,since the naive algorithm is too slow to deal withsentence sizes, most authors have proposed pruningtechniques.
Zhang et al (2008) suggest tic-tac-toepruning, which uses Model 1 posteriors to excluderanges of cells from being computed.
Blunsom et al(2008) do a monolingual parse with of one languagebut split the parser states by the string yielded bythe target derivations, pruning any nodes that yieldstrings that do not exist in the target.
Haghighi et al(2009) also describe a pruning heuristic that resultsin average case runtime of O(n3).ReferencesCyril Allauzen and Mehryar Mohri.
2008.
3-waycomposition of weighted finite-state transducers.
In3Three-way composition algorithms that operate only onFSTs have also been developed (Allauzen and Mohri, 2008).0S20 20X1 0X11 20 10X1b : c0X1 0X1b :0X1da : d a : c0 1 0 11 212Figure 2: An SCFG, G, two FSAs, E and F , and twoequivalent representations of F ?
G. The synchronousparse forest of the pair ?ab, cd?
with G is given under F ?G ?
E.our parser operates m re fficie tly with a deter-minized grammar, w left-factor the grammar dur-ing this traversal as well.Analysis.
Monolingual parsing runs in worst caseO(|G| ?
n3) time, where n is the length of the in-put being pa sed and |G| is a measure of the sizeof the grammar (Graham et al, 1980).
Since thegrammar term is constant for most typical parsingapplications, it is generally not considered carefully;however, in the two-parse algorithm, the size of thegra mar term for the second parse is not |G| but|F ?
G|, which clearly depends on the size of the in-put F ; and so understanding the impact of this termis key to understanding the algorithm?s run-time.If G is an -free SCFG with non-terminals N andmaximally two NTs in a rule?s right hand side, andis the number of states in F (corresponding to thenumber of words in the f in a s ntence pair ?f, e?
),the the number of nodes in the parse forest F ?
Gwill be O(|N | ?
n2).
This can be shown easily sinceby stipulation, we are able to use CKY+ to per-form the parse, and there will be maximally as manynodes in the forest as there are cells in the CKY charttimes the number of NTs.
The number of edges willbe O(|N | ?
n3), which occurs when every node canbe derived from all possible splits.
This bound onthe number of edges implies that |F ?G| ?
O(n3).10Therefore, the worst case run-time of the two-parsealgorithm isO(|N | ?n3?n3+ |G|?n3) = O(|N | ?n6),the same as the bound on the ITG algorithm.
Wenote that while the ITG algorithm requires that theSCFGs be rank-2 and in a normal form, the two-parse algorithm analysis holds as long as the gram-mars are rank-2 and -free.113 ExperimentsWe now describe two different synchronous parsingapplications, with different classes of SCFGs, andcompare the performance of the two-parse algorithmwith that of previously used algorithms.Phrasal ITGs.
Here we compare performance ofthe two-parse algorithm and the O(n6) ITG parsingalgorithm on an Arabic-English phrasal ITG align-ment task.
We used a variant of the phrasal ITG de-scribed by Zhang et al (2008).12Figure 3 plots theaverage run-time of the two algorithms as a functionof the Arabic sentence length.
The two-parse ap-proach is far more efficient.
In total, aligning the 80ksentence pairs in the corpus completed in less than4 hours with the two-parse algorithm but requiredmore than 1 week with the baseline algorithm.13?Hiero?
grammars.
An alternative approach tocomputing a synchronous parse forest is based oncube pruning (Huang and Chiang, 2007).
Whilemore commonly used to integrate a target m-gramLM during decoding, Blunsom et al (2008), who re-quired synchronous parses to discriminatively train10How tight these bounds are depends on the ambiguity inthe grammar w.r.t.
the input: to generate n3edges, every itemin every cell must be derivable by every combination of its sub-spans.
Most grammars are substantially less ambiguous.11Since many widely used SCFGs meet these criteria, in-cluding hierarchical phrase-based translation grammars (Chi-ang, 2007), SAMT grammars (Zollmann and Venugopal, 2006),and phrasal ITGs (Zhang et al, 2008), a detailed analysis of -containing and higher rank grammars is left to future work.12The restriction that phrases contain exactly a single align-ment point was relaxed, resulting in much larger and more am-biguous grammars than those used in the original work.13A note on implementation: our ITG aligner was minimal; itonly computed the probability of the sentence pair using the in-side algorithm.
With the two-parse aligner, we stored the com-plete forest during both the first and second parses.26510 20 30 40 50 600204060Wu (1997)this workFigure 3: Average synchronous parser run-time (in sec-onds) as a function of Arabic sentence length (in words).an SCFG translation model, repurposed this algo-rithm to discard partial derivations during transla-tion of f if the derivation yielded a target m-gramnot found in e (p.c.).
We replicated their BTECChinese-English baseline system and compared thespeed of their ?cube-parsing?
technique and our two-parse algorithm.14The SCFG used here was ex-tracted from a word-aligned corpus, as described inChiang (2007).15The following table compares theaverage per sentence synchronous parse time.Algorithm avg.
run-time (sec)Blunsom et al (2008) 7.31this work 0.204 DiscussionThinking of synchronous parsing as two composi-tion operations has both conceptual and practicalbenefits.
The two-parse strategy can outperformboth the ITG parsing algorithm (Wu, 1997), as wellas the ?cube-parsing?
technique (Blunsom et al,2008).
The latter result points to a connection withrecent work showing that determinization of edgesbefore LM integration leads to fewer search errorsduring decoding (Iglesias et al, 2009).Our results are somewhat surprising in light ofwork showing that 3-way composition algorithmsfor FSTs operate far more efficiently than perform-ing successive pairwise compositions (Allauzen andMohri, 2009).
This is certainly because the 3-wayalgorithm used here (the ITG algorithm) does an ex-14To the extent possible, the two experiments were carriedout using the exact same code base, which was a C++ imple-mentation of an SCFG-based decoder.15Because of the mix of terminal and non-terminal symbols,such grammars cannot be used by the ITG synchronous parsingalgorithm.haustive search over all n4span pairs without aware-ness of any top-down constraints.
This suggests thatfaster composition algorithms that incorporate top-down filtering may still be discovered.ReferencesC.
Allauzen and M. Mohri.
2009.
N-way composition ofweighted finite-state transducers.
International Jour-nal of Foundations of Comp.
Sci., 20(4):613?627.Y.
Bar-Hillel, M. Perles, and E. Shamir.
1961.
On for-mal properties of simple phrase structure grammars.Zeitschrift f?ur Phonetik, Sprachwissenschaft und Kom-munikationsforschung, 14:143?172.P.
Blunsom, T. Cohn, and M. Osborne.
2008.
Probalisticinference for machine translation.
In EMNLP.D.
Chiang.
2007.
Hierarchical phrase-based translation.Computational Linguistics, 33(2):201?228.S.
L. Graham, W. L. Ruzzo, and M. Harrison.
1980.
Animproved context-free recognizer.
ACM Trans.
Pro-gram.
Lang.
Syst., 2(3):415?462.A.
Haghighi, J. Blitzer, J. DeNero, and D. Klein.
2009.Better word alignments with supervised ITG models.In Proc.
of ACL/IJCNLP, pages 923?931.L.
Huang and D. Chiang.
2007.
Forest rescoring: Fasterdecoding with integrated language models.
In ACL.L.
Huang, H. Zhang, D. Gildea, and K. Knight.
2009.Binarization of synchronous context-free grammars.Computational Linguistics, 35(4).G.
Iglesias, A. de Gispert, E. R. Banga, and W. Byrne.2009.
Hierarchical phrase-based translation withweighted finite state transducers.
In Proc.
NAACL.P.
M. Lewis, II and R. E. Stearns.
1968.
Syntax-directedtransduction.
J. ACM, 15(3):465?488.M.
Mohri.
2009.
Weighted automata algorithms.
InM.
Droste, W. Kuich, and H. Vogler, editors, Hand-book of Weighted Automata, Monographs in Theoreti-cal Computer Science, pages 213?254.
Springer.G.
Satta and E. Peserico.
2005.
Some computationalcomplexity results for synchronous context-free gram-mars.
In Proceedings of NAACL.G.
Satta.
submitted.
Translation algorithms by means oflanguage intersection.G.
van Noord.
1995.
The intersection of finite state au-tomata and definite clause grammars.
In Proc.
of ACL.D.
Wu.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Com-putational Linguistics, 23(3):377?404.H.
Zhang, C. Quirk, R. C. Moore, and D. Gildea.
2008.Bayesian learning of non-compositional phrases withsynchronous parsing.
In Proceedings of ACL.A.
Zollmann and A. Venugopal.
2006.
Syntax aug-mented machine translation via chart parsing.
In Proc.of the Workshop on SMT.266
