Quality-Sensitive Test Set Selection for a Speech Translation SystemFumiaki Sugaya1, Keiji Yasuda2, Toshiyuki Takezawa and Seiichi YamamotoATR Spoken Language Translation Research Laboratories2-2-2 Hikari-dai Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan{fumiaki.sugaya, keiji.yasuda, toshiyuki.takezawa,seiichi.yamamoto}@atr.co.jp121Current affiliation: KDDI R&D Laboratories.
Also at Graduate School of Science and Technology, Kobe University.2Also at Graduate School of Engineering, Doshisha University.AbstractWe propose a test set selection method tosensitively evaluate the performance of aspeech translation system.
The proposedmethod chooses the most sensitive testsentences by removing insensitivesentences iteratively.
Experiments areconducted on the ATR-MATRIX speechtranslation system, developed at ATRInterpreting TelecommunicationsResearch Laboratories.
The results showthe effectiveness of the proposed method.According to the results, the proposedmethod can reduce the test set size to lessthan 40% of the original size whileimproving evaluation reliability.IntroductionThe translation paired comparison methodprecisely measures the capability of a speechtranslation system.
In this method, native speakerscompare a system?s translation and the translations,made by examinees who have various TOEICscores.
The method requires two human costs: thedata collection of examinees?
translations and thecomparison by native speakers.
In this paper, wepropose a test set size reduction method thatreduces the number of test set utterances.
Themethod chooses the most sensitive test utterancesby removing the most insensitive utterancesiteratively.In section 2, the translation paired comparisonmethod is described.
Section 3 explains theproposed method.
In section 4, evaluation resultsfor ATR-MATRIX are shown.
Section 5 discussesthe experimental results.
In section 6, we state ourconclusions.Translation paired comparison methodThe translation paired comparison method(Sugaya, 2000) is an effective evaluation methodfor precisely measuring the capability of a speechtranslation system.
In this section, a description ofthe method is given.2.1 Methodology of the translation pairedcomparison methodFigure 1 shows a diagram of the translation pairedcomparison method in the case of Japanese toEnglish translation.
The Japanese native-speakingexaminees are asked to listen to Japanese text andprovide an English translation on paper.
TheJapanese text is spoken twice within one minute,with a pause in-between.
To measure the Englishcapability of the Japanese native speakers, theTOEIC score is used.
The examinees are requestedto present an official TOEIC score certificateshowing that they have taken the test within thepast six months.
A questionnaire is given to themand the results show that the answer time ismoderately difficult for the examinees.The test text is the SLTA1 test set, whichconsists of 330 utterances in 23 conversations froma bilingual travel conversation database (Morimoto,1994; Takezawa, 1999).
The SLTA1 test set isAssociation for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
109-116.Proceedings of the Workshop on Speech-to-Speech Translation:open for both speech recognition and languagetranslation.
The answers written on paper are typed.In the proposed method, the typed translationsmade by the examinees and the outputs of thesystem are merged into evaluation sheets and arethen compared by an evaluator who is a nativeEnglish speaker.
Each utterance information isshown on the evaluation sheets as the Japanese testtext and the two translation results, i.e., translationsby an examinee and by the system.
The twotranslations are presented in random order toeliminate bias by the evaluator.
The evaluator isasked to follow the procedure illustrated in Figure2.
The four ranks in Figure 2 are the same as thoseused in Sumita (1999).
The ranks A, B, C, and Dindicate: (A) Perfect: no problems in bothinformation and grammar; (B) Fair: easy-to-understand with some unimportant informationmissing or flawed grammar; (C) Acceptable:broken but understandable with effort; (D)Nonsense: important information has beentranslated incorrectly.2.2 Evaluation result using the translationpaired comparison methodFigure 3 shows the result of a comparison betweena language translation subsystem (TDMT) and theexaminees.
The input for TDMT included accuratetranscriptions.
The total number of examinees wasthirty, with five people having scores in everyhundred-point TOEIC range between the 300s and800s.
In Figure 3, the horizontal axis represents theTOEIC score and the vertical axis the systemwinning rate (SWR) given by following equation:TranslationResult byHumanEvaluationSheetJapanese TestText Typing Paired ComparisonAccurate Textwhere NTOTAL denotes the total number ofutterances in the test set, NTDMT represents thenumber of  "TDMT won" utterances,  and NEVEN,indicates the number of  even (non-winner)utterances, i.e., no difference between the results ofthe TDMT and humans.
The SWR ranges from 0to 1.0, signifying the degree of capability of theMT system relative to that of the examinee.
AnSWR of 0.5 means that the TDMT has the samecapability as the human examinee.Figure 3 shows that the SWR of TDMT isgreater than 0.5 at TOEIC scores of around 300and 400, i.e., the TDMT system wins over humanswith TOEIC scores of 300 and 400.
Examinees, incontrast, win at scores of around 800.
Thecapability balanced area is around a score of 600 to(1)0.5TOTALEVENTDMTNNNSWR?+=Figure 1: Diagram of translation pair comparison methodJapanese-to-EnglishLanguage Translation(J-E TDMT)Japanese Recognition(Japanese SPREC)Choose A, B, C, or D rankNoSame rank?YesConsider naturalnessYesNoSame?Select better resultEVENFigure 2: Procedure of comparisonby native speaker300 400 500 600 700 800 9000.20.30.40.50.60.70.80.9TO EIC scoreSWRFigure 3: Evaluation results using translationpaired comparison methodUnder the above condition, the standard deviationof the system's TOEIC score is calculated by(4))()(12202 ?
?
?+=XXXCn it ??
?where n is the number of examinees, C0 is thesystem's TOEIC score, and X  is the average ofthe examinees' TOEIC scores.
Equation (4)indicates that the minimum error is given when thesystem's TOEIC score equals the average of theexaminees' TOEIC scores.By using a t-distribution, the confidenceinterval (CI) of the system's TOEIC score withconfidence coefficient 1-?
is given by700.
To precisely determine the balanced point, weused regression analysis.
The straight line in Figure3 is the regression line.
The capability balancedpoint between the TDMT subsystem and theexaminees is 0.5 of SWR.
In Figure 3, the exactpoint is a TOEIC score of 708.
We call this pointthe system's TOEIC score.
Consequently, thetranslation capability of the language translationsystem equals that of the examinees at around ascore of 700 points on the TOEIC.
[ ](5)                                   )2;2(, 00??=+?=ntIICICCIt?
?In the current study, we employ 0.01 for thevalue of ?
.2.4 Costs for the translation paired comparisonmethodThe experimental result for ATR-MATRIX,which consists of a speech recognition subsystemand TDMT, has been also reported (Sugaya, 2000).This system?s TOEIC score is 548, where thenumber of speech recognition errors is a factor inthe degradation of the score.The translation paired comparison method is aneffective evaluation method because it can clearlyexpress a system?s performance as a TOEIC (Testof English for International Communication)score.
However, this method has excessiveevaluation costs.Roughly speaking, one of these costs is the needto collect translations made by examinees ofvarious TOEIC scores.
As shown in Equations (4)and (5), n, the number of examinees, affects theconfidence interval of the system?s TOEIC score.Therefore, a reduction in this number makes itdifficult to obtain a reliable evaluation result.2.3 Error in the system?s TOEIC scoreThe SWR (Yi) and TOEIC scores for the examinees(Xi) are assumed to satisfy the populationregression equation:(2)          ),...,2,1(    21 niXY iii =++= ??
?The other cost is for the evaluation.
Comparedto a conventional evaluation method, such as asimple rank evaluation method, the translationpaired comparison method uses a larger amount oflabor because the evaluator must work on nevaluation sheets.
Each sheet consists of 330 pairsof translation results to be evaluated.
Even for anaccomplished evaluator, it takes more than twoweeks to finish the work, following the methodexplained in section 2.2.where 1?
and 2?
are population regressioncoefficients.
The error term ( i? )
is assumed tosatisfy the following condition:0    (d)if     0),(),(    (c)(3)                     ,...,2,1     ,)(    (b)0)(    (a)22??=====ijijiiijiECovniVE???????
?3 Proposed methodYesNo?
?NoYesAll candidatesare calculated?Set the number of iterationsRemove worst utterances fromcandidatesIs iterationachieved?Calculate iterationUpdate worst sentence,which causes maximumiterationGet next candidateAs explained in the previous section, thetranslation paired comparison method has anexcessive evaluation cost.
Nevertheless, it is aneffective evaluation method for measuring thecapability of a speech translation system.Therefore, cost reduction for this evaluationmethod is an important subject for study.The proposed method reduces the evaluationcost by removing insensitive test utterances fromthe test set.
In this section, we explain theoptimization procedure of the proposed method.3.1 Optimization basisIn the proposed method, the basis of test setoptimization is the minimization of ?
.
As shownin Equations (4) and (5), this value has aninfluence on the confidence interval of the system'sTOEIC score.
Therefore, minimizing ?
bringsabout a reliable evaluation result.We introduce ?
iteration, which is calculated ineach iteration step.
?
iteration is also calculated byusing Equations (2) and (3).
The differencebetween ?
iteration and?
is the test set to be usedfor calculation.
?
iteration is calculated usingresidual test utterances in each iteration step.However, the values of 1?
and 2?
are fixed, i.e.,for the calculation of ?
iteration, these 1?
and 2?are calculated using the original test set consistingof 330 test utterances.Optimization is conducted iteratively bypicking up the test utterance that causes maximum?
iteration in each iteration step.
The details of thisprocedure is explained in the next subsection.3.2 Methodology of the proposed methodFigure 4 shows a diagram of the proposed method.In the first step, the number of iterations is set.This number is an actual number of removed testutterances.
During the iterations, test utterances areremoved one-by-one.
To decide which testutterance to remove in each iteration, ?
iteration iscalculated for the condition of removing each testutterance.
This calculation is done for allcandidates, i.e., all constituents of residual testutterances.Figure 4: Procedure of proposed methodAt the end of each iteration step, the testutterance to be removed is decided.
The removedtest utterance is the one that maximizes ?
iteration.We regard the utterance as maximizing?
iteration ifremoving it from the test set gives minimum?
iteration.70720740760TOEICscore0 50 100 150 200 250 300660680Iteration(upper)  C0 opt  +  IoptC0 opt(lower)  C0 opt   -  Iopt203040?toptRandom selection (Averaging of 10 trials)Optimzed  (Open)Optimzed  (Closed)0 50 100 150 200 250 300010IterationFigure 6: Relationship between iterationand ?
t optFigure 5: Relationship between iterationand system?s TOEIC scoreAs shown in the figure, from iteration 1 toiteration 250, the value of C0 opt is stable and doesnot deviate from C0, which is 708.
Furthermore,until around iteration 200, the value of Ioptdecreases concurrently with the iteration.4 Experimental resultsIn this section, we show experimental results of theproposed method.
Here, we introduce the suffix?opt?
to distinguish a variable calculated with theoptimized test set from a variable calculated withthe original test set.
All of the above variables arecalculated with the original test set.
By joining thesuffix ?opt?
to these variables, we refer to variablescalculated with the optimized test set, e.g., ?
opt 3,?
t opt, Iopt, C0 opt, CI opt, and so on.This result suggests that the proposed mayprovide low-cost evaluation with high reliability.4.2 Experiment opened for examineesIn the result shown in the previous subsection, theoptimization and evaluation were conducted on thesame examinees, i.e., the evaluation is closed forexaminees.
In this subsection, we look into therobustness of the proposed method againstdifferent examinees.
We divided the group,consisting of 30 examinees, into two groups: agroup of odd-numbered examinees and a group ofeven-numbered examinees.
Individuals were sortedby TOEIC score from lowest to highest.4.1 Closed experimentThis  subsection discusses an experimental resultobtained for the same test set and examineesdescribed in Section 2.
Namely, the target test setfor optimization consists of 330 utterances and thenumber of examinees is 30.Figure 5 shows the relationship betweeniteration and the system?s TOEIC score (C0 opt).
Inthis figure, the horizontal axis represents theiteration number and the vertical axis the TOEICscore.
The solid line represents C0 opt, which is thesystem?s TOEIC score using the optimized test ineach iteration.
The dotted line above the solid linerepresents the value of C0 opt + Iopt, and the dottedline below the solid line C0 opt - Iopt.One of the groups is used to optimize the test set.The other group is used for the translation pairedcomparison method.
We use the term?optimization group?
to refer to the first group and?evaluation group?
to refer to the second group.Figure 6 shows the relationship betweeniteration and ?
t opt.
In this figure, the horizontalaxis represents the iteration and the vertical axisshows?
t opt.
Three kinds of experimental resultsare shown in this figure.
In each of threeexperiments, the translation paired comparison isconducted by the evaluation group.
The differences3 ?
opt is different from?
iteration.
?
opt is calculated based on1?
opt and 2?
opt (not 1?
and 2? )
for the optimized test set.Figure 8: Relationship between iteration andt opt ?0 50 100 150 200 250 300051015202530Iteration?toptRandom selection (Averaging of 10 trials)Optimzed for TDM TOptimzed for ATR-M ATRIX0 50 100 150 200 250 3005506065070750800850IterationC 0optRandom selection (Averaging of 10 trials)Optimized (Open)Optimized (Closed)Figure 7: Relationship between iteration andC0 optamong the three experiments are in the group to beused for optimization of the test set or the methodused to reduce it.
The double line represents theclosed result using the test set, optimized on theevaluation group.
The solid line represents theopen result using the test set, optimized on theoptimization group.
The broken line represents theresult using the test set, which is reduced byrandomly removing test utterances one-by-one.The actual plotted broken line is averaged over 10random trials.0 50 100 150 200 250 300460480500520540560580IterationC 0optOptimized for TDM TOptimzed for ATR-M ATRIXAs shown in Figure 6, in the random selectionresult, t opt is on the rise.
On the other hand, theopen result is on the decline.
?Figure 7 shows the relationship betweeniteration and the system?s TOEIC score.
In thisfigure, the horizontal axis represents the iterationand the vertical axis the TOEIC score.
Thedenotation of each line is the same as that in Figure6.
The error bar from the broken line represents?
random, which is the standard deviation of thesystem?s TOEIC score over 10 random trials.Figure 9: Relationship between iteration andC0 optIn Figure 7, considering ?
random, C0 opt of theopen evaluation is more approximate to C0 thanthat of random selection, whereas C0 opt of theclosed evaluation is much more approximate to C0.4.3 Experiment on ATR-MATRIXTo be of actual use, the test set optimized for somesystem must be applicable for evaluation of othersystems.
In this subsection, we show the results ofan experiment aimed at verifying this requirementis met.
In this experiment, we apply the test set,which is optimized for TDMT, to evaluate ATR-MATRIX.
The experimental conditions are thesame as in Section 4.1, except for the evaluationtarget.
The results are shown in Figure 8 andFigure 9.Figure 8 shows the relationship betweeniteration and ?
t opt.
In this figure, the horizontalaxis represents the iteration and the vertical axisshows ?
t opt.
The double line represents the resultusing the test set, optimized for ATR-MATRIX.The solid line represents the result using the testset, optimized for TDMT.
The broken linerepresents the result using the test set, which isreduced by randomly removing test utterances one-6 Conclusions by-one.
The actual plotted broken line is averagedover 10 random trials.We proposed a test set selection method forevaluating a speech translation system.
Thismethod optimizes and drastically reduces the testset required by the translation paired comparisonmethod.Figure 9 shows the relationship betweeniteration and the system?s TOEIC score.
In thisfigure, the horizontal axis represents the iteration,and the vertical axis TOEIC score.
The broken lineand the solid line are plotted using the samedenotation as that in Figure 8.
Translation paired comparison is an effectivemethod for measuring a system?s performance as aTOEIC score.
However, this method has excessiveevaluation costs.
Therefore, cost reduction for thisevaluation method is an important subject for study.In Figure 8, the solid line always lies on a lowerposition than the broken line.
In Figure 9, fromiteration 1 to around iteration 200, the broken linedoes not deviate from the actual system?s TOEICscore, which is 548.
We applied the proposed method in an evaluationof ATR-MATRIX.
Experimental results showedthe effectiveness of the proposed method.
Thismethod reduced evaluation costs by more than60% and also improved the reliability of theevaluation result.Considering these results, the test set optimizedfor TDMT is shown to be applicable for evaluatingATR-MATRIX.5 DiscussionAcknowledgement In this section, we discuss the experimental resultsshown in Section 4.The research reported here was supported in partby a contract with the TelecommunicationsAdvancement Organization of Japan entitled, "Astudy of speech dialogue translation technologybased on a large corpus.
"Looking at the broken lines in Figure 6 andFigure 8, test set reduction using random selectionalways causes an increase of ?
t opt i.e., an increasein the scale of confidence interval.
Therefore, thismethod causes the reliability of the evaluationresult to deteriorate.
Meanwhile, in the case ofusing the proposed method, looking at the solidlines on these figures, ?
t opt is on the decline untilaround iteration 200.
This means that we canachieve a more reliable evaluation result with alower evaluation cost than when using the originaltest set.
Here, looking at the solid lines in Figure 7and Figure 9, the Co opt system?s TOEIC score isnearly stable until iteration 200, and it does notdeviate from Co. As mentioned before, Co forFigure 7 is 708 and Co for Figure 9 is 548.ReferencesMorimoto, T., Uratani, N., Takezawa, T., Furuse,O., Sobashima, Y., Iida, H., Nakamura, A.,Sagisaka, Y., Higuchi, N. and Yamazaki, Y.1994.
A speech and language database forspeech translation research.
In Proceedings ofICSLP `94, pages 1791-1794.Sugaya, F., Takezawa, T., Yokoo, A., Sagisaka, Y.and Yamamoto, S. 2000.
Evaluation of theATR-MATRIX Speech Translation System witha Pair Comparison Method between the Systemand Humans.
In Proceedings of ICSLP 2000,pages 1105-1108.Considering these results, the proposed methodcan reduce the 330-utterance test set to a 130-utterance test set while reducing the scale ofconfidence interval.
In other words, the proposedmethod both reduces evaluation costs by 60% andimproves  reliability of the evaluation result.Sumita, E., Yamada, S., Yamamoto K., Paul, M.,Kashioka, H., Ishikawa, K. and Shirai, S. 1999.Solutions to Problems Inherent in Spoken-language Translation: The ATR-MATRIXApproach.
In Proceedings of MT Summit `99,pages 229-235.Looking at Equations (4) and (5), the scale ofconfidence interval is also influenced by n.  Whenwe allow the scale of confidence interval obtainedfrom the original test set, we can use the proposedmethod?s reduction effect of ?
t to compensate the?
t 's increase by reducing n.  In this case, theactual achievable cost reduction will be more than60%.Takezawa, T. 1999.
Building a bilingual travelconversation database for speech recognitionresearch.
In Proceedings of Oriental COCOSDAWorkshop, pages 17-20.Takezawa, T., Morimoto, T., Sagisaka, Y.,Campbell, N., Iida., H., Sugaya, F., Yokoo, A.and Yamamoto, S. 1998.
A Japanese-to-Englishspeech translation system: ATR-MATRIX.
InProceedings of ICSLP 1998, pages 2779-2782.
