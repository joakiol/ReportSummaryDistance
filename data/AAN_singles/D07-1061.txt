Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
581?589, Prague, June 2007. c?2007 Association for Computational LinguisticsLexical Semantic Relatedness with Random Graph WalksThad Hughes and Daniel RamageComputer Science DepartmentStanford UniversityStanford, CA 94305{thughes, dramage}@cs.stanford.eduAbstractMany systems for tasks such as question answer-ing, multi-document summarization, and infor-mation retrieval need robust numerical measuresof lexical relatedness.
Standard thesaurus-basedmeasures of word pair similarity are based ononly a single path between those words in thethesaurus graph.
By contrast, we propose a newmodel of lexical semantic relatedness that incor-porates information from every explicit or im-plicit path connecting the two words in the en-tire graph.
Our model uses a random walk overnodes and edges derived from WordNet linksand corpus statistics.
We treat the graph as aMarkov chain and compute a word-specific sta-tionary distribution via a generalized PageRankalgorithm.
Semantic relatedness of a word pair isscored by a novel divergence measure, ZKL, thatoutperforms existing measures on certain classesof distributions.
In our experiments, the resultingrelatedness measure is the WordNet-based mea-sure most highly correlated with human similar-ity judgments by rank ordering at ?
= .90.1 IntroductionSeveral kinds of Natural Language Processing systemsneed measures of semantic relatedness for arbitrary wordpairs.
For example, document summarization and ques-tion answering systems often use similarity scores toevaluate candidate sentence alignments, and informationretrieval systems use relatedness scores for query expan-sion.
Several popular algorithms calculate scores frominformation contained in WordNet (Fellbaum, 1998), anelectronic dictionary where word senses are explicitlyconnected by zero or more semantic relationships.
Thecentral challenge of these algorithms is to compute rea-sonable relatedness scores for arbitrary word pairs giventhat few pairs are directly connected.Most pairs in WordNet share no direct semanticlink, and for some the shortest connecting path can besurprising?even pairs that seem intuitively related, such?furnace?
and ?stove?
share a lowest common ancestorin the hypernymy taxonomy (is-a links) all the way upat ?artifact?
(a man-made object).
Several existing algo-rithms compute relatedness only by traversing the hyper-nymy taxonomy and find that ?furnace?
and ?stove?
arerelatively unrelated.
However, WordNet provides othertypes of semantic links in addition to hypernymy, suchas meronymy (part/whole relationships), antonymy, andverb entailment, as well as implicit links defined by over-lap in the text of definitional glosses.
These links canprovide valuable relatedness information.
If we assumethat relatedness is transitive across a wide variety of suchlinks, then it is natural to follow paths such as furnace?crematory?gas oven?oven?kitchen appliance?stove andfind a higher degree of relatedness between ?furnace?and ?stove.
?This paper presents the application of random walkMarkov chain theory to measuring lexical semantic re-latedness.
A graph of words and concepts is constructedfrom WordNet.
The random walk model posits the exis-tence of a particle that roams this graph by stochasticallyfollowing local semantic relational links.
The particle isbiased toward exploring the neighborhood around a targetword, and is allowed to roam until the proportion of timeit visits each node in the limit converges to a stationarydistribution.
In this way we can compute distinct, word-specific probability distributions over how often a particlevisits all other nodes in the graph when ?starting?
from aspecific word.
We compute the relatedness of two wordsas the similarity of their stationary distributions.The random walk brings with it two distinct advan-tages.
First, it enables the similarity measure to havea principled means of combination of multiple types ofedges from WordNet.
Second, by traversing all links, thewalk aggregates local similarity statistics across the en-tire graph.
The similarity scores produced by our methodare, to our knowledge, the WordNet-based scores mosthighly correlated with human judgments.5812 Related workBudanitsky and Hirst (2006) provide a survey of manyWordNet-based measures of lexical similarity based onpaths in the hypernym taxonomy.
As an example, oneof the best performing is the measure proposed by Jiangand Conrath (1997) (similar to the one proposed by (Lin,1991)), which finds the shortest path in the taxonomic hi-erarchy between two candidate words before computingsimilarity as a function of the information content of thetwo words and their lowest common subsumer in the hi-erarchy.
We note the distinction between word similarityand word relatedness.
Similarity is a special case of relat-edness in that related words such as ?cat?
and ?fur?
sharesome semantic relationships (such as meronymy), but donot express the same likeness of form as would similarwords such as ?cat?
and ?lion.?
The Jiang-Conrath mea-sure and most other measures that primarily make use ofof hypernymy (is-a links) in the WordNet graph are bettercategorized as measures of similarity than of relatedness.Other measures have been proposed that utilize the textin WordNet?s definitional glosses, such as Extended Lesk(Banerjee and Pedersen, 2003) and later the Gloss Vec-tors (Patwardhan and Pedersen, 2006) method.
These ap-proaches are primarily based on comparing the ?bag ofwords?
of two synsets?
gloss text concatenated with thetext of neighboring words?
glosses in the taxonomy.
Asa result, these gloss-based methods measure relatedness.Our model captures some of this relatedness informationby including weighted links based on gloss text.A variety of other measures of semantic relatednesshave been proposed, including distributional similaritymeasures based on co-occurrence in a body of text?see (Weeds and Weir, 2005) for a survey.
Other mea-sures make use of alternative structured information re-sources than WordNet, such as Roget?s thesaurus (Jar-masz and Szpakowicz, 2003).
More recently, measuresincorporating information from Wikipedia (Gabrilovichand Markovitch, 2007; Strube and Ponzetto, 2006) havereported stronger results on some tasks than have beenachieved by existing measures based on shallower lexicalresources.
The results of our algorithm are competitivewith some Wikipedia algorithms while using only Word-Net 2.1 as the underlying lexical resource.
The approachpresented here is generalizable to construction from anyunderlying semantic resource.PageRank is the most well-known example of a ran-dom walk Markov chain?see (Berkhin, 2005) for a sur-vey.
It uses the local hyperlink structure of the web todefine a graph which it walks to aggregate popularityinformation for different pages.
Recent work has ap-plied random walks to NLP tasks such as PP attachment(Toutanova et al, 2004), word sense disambiguation (Mi-halcea, 2005; Tarau et al, 2005), and query expansion(Collins-Thompson and Callan, 2005).
However, to ourknowledge, the literature in NLP has only considered us-ing one stationary distribution per specially-constructedgraph as a probability estimator.
In this paper, we in-troduce a measure of semantic relatedness based on thedivergence of the distinct stationary distributions result-ing from random walks centered at different positions inthe word graph.
We believe we are the first to define sucha measure.3 Random walks on WordNetOur model is based on a random walk of a particlethrough a simple directed graphG = (V,E)whose nodesV and edges E are extracted from WordNet version 2.1.Formally, we define the probability n(t)i of finding theparticle at node ni ?
V at time t as the sum of all ways inwhich the particle could have reached ni from any othernode at the previous time-step:n(t)i =?nj?Vn(t?1)j P (ni | nj)where P (ni | nj) is the conditional probability of mov-ing to ni given that the particle is at nj .
In partic-ular, we construct the transition distribution such thatP (ni | nj) > 0 whenever WordNet specifies a local linkrelationship of the form j ?
i.
Note that this randomwalk is a Markov chain because the transition probabili-ties at time t are independent of the particle?s past trajec-tory.The subsections that follow present the construction ofthe graph for our random walk from WordNet and themathematics of computing the stationary distribution fora given word.3.1 Graph ConstructionWordNet is itself a graph over synsets.
A synset is bestthought of as a concept evoked by one sense of one ormore words.
For instance, different senses of the word?bank?
take part in different synsets (e.g.
a river bankversus a financial institution), and a single synset canbe represented by multiple synonymous words, such as?middle?
and ?center.?
WordNet explicitly marks seman-tic relationships between synsets, but we are additionallyinterested in representing relatedness between words.
Wetherefore extract the following types of nodes fromWord-Net:Synset Each WordNet synset has a corresponding node.For example, one node corresponds to the synset re-ferred to by ?dog#n#3,?
the third sense of dog asnoun, whose meaning is ?an informal term for aman.?
There are 117,597 Synset nodes.582TokenPOS One node is allocated to every word cou-pled with a part of speech, such as ?dog#n?
mean-ing dog as a noun.
These nodes link to all thesynsets they participate in, so that ?dog#n?
linksthe Synset nodes for canine, hound, hot dog, etc.Collocations?multi-word expressions such as ?hotdog?
?that take part in a synsets are also representedby these nodes.
There are 156,588 TokenPOS nodes.Token Every TokenPOS is connected to a Token nodecorresponding to the word when no part of speechinformation is present.
For example, ?dog?
links to?dog#n?
and ?dog#v?
(meaning ?to chase?).
Thereare 148,646 Token nodes.Synset nodes are connected with edges correspond-ing to many of the relationship types in Word-Net.
We use these WordNet relationships to formedges: hypernym/hyponym, instance/instance of, allholonym/meronym links, antonym, entails/entailed by,adjective satellite, causes/caused by, participle, pertainsto, derives/derived from, attribute/has attribute, and top-ical (but not regional or usage) domain links.
By con-struction, each edge created from a WordNet relationshipis guaranteed to have a corresponding edge in the oppo-site direction.Edges that connect a TokenPOS to the Synsets using itare weighted based on a Bayesian estimate drawn fromthe SemCor frequency counts included in WordNet butwith a non-uniform Dirichlet prior.
Our edge weights arethe SemCor frequency counts for each target Synset, withpseudo-counts of .1 for all Synsets, 1 for first sense ofeach word, and .1 for the first word in each Synset.
Intu-itively, this causes the particle to have a higher probabil-ity of moving to more common senses of a TokenPOS; forexample, the edges from ?dog#n?
to ?dog#n#1?
(canine)and ?dog#n#5?
(hotdog) have un-normalized weights of43.2 and 0.1, respectively.
The edges connecting a To-ken to the TokenPOS nodes in which it can occur are alsoweighted by the sum of the weights of the outgoing To-kenPOS?Synset links.
Hence a walk starting at a com-mon word like ?cat?
is far more likely to follow a link to?cat#n?
than to rarities like ?cat#v?
(to vomit).
Theseedges are uni-directional; no edges are created from aSynset to a TokenPOS that can represent the Synset.In order for our graph construction to incorporatetextual gloss-based information, we also create uni-directional edges from Synset nodes to the TokenPOSnodes for the words and collocations used in that synset?sgloss definition.
This requires part-of-speech tagging theglosses, for which we use the Stanford maximum entropytagger (Toutanova et al, 2003).
It is important to cor-rectly weight these edges, because high-frequency stop-words such as ?by?
and ?he?
do not convey much in-formation and might serve only to smear the probabilitymass across the whole graph.
Gloss-based links to thesenodes should therefore be down-weighted or removed.On the other hand, up-weighting extremely rare wordssuch as by tf-idf scoring might also be inappropriatebecause such rare words would get extremely high scores,which is an undesirable trait in similarity search.
(Haveli-wala et al, 2002) and others have shown that a ?non-monotonic document frequency?
(NMDF) weighting canbe more effective in such a setting.
Because the frequencyof words in the glosses is distributed by a power-law, weweight each word by its distance from the mean wordcount in log space.
Formally, the weight wi for a wordappearing ri times iswi = exp(?(log(ri)?
?
)22?2)where ?
and ?
are the mean and standard deviation ofthe logs of all word counts.
This is a smooth approxima-tion to the high and low frequency stop lists used effec-tively by other measures such as (Patwardhan and Ped-ersen, 2006).
We believe that because non-monotonicfrequency scaling has no parameters and is data-driven,it could stand to be more widely adopted among gloss-based lexical similarity measures.We also add bi-directional edges between Synsetswhose word senses overlap with a common TokenPOS.These edges have raw weights given by the number ofTokenPOS nodes shared by the Synsets.
The intuition be-hind adding these edges is that WordNet often divides themeanings of words into fine-grained senses with similarmeanings, so there is likely to be some semantic relation-ship between Synsets sharing a common TokenPOS.The final graph has 422,831 nodes and 5,133,281edges.
This graph is very sparse; fewer than 1 in 10,000node pairs are directly connected.
When only the un-weighted WordNet relationship edges are considered,the largest degree of any node is ?city#n#1?
with 667edges (mostly connecting to particular cities), followedby ?law#n#2?
with 602 edges (mostly connecting to alarge number of domain terms such as ?dissenting opin-ion?
and ?freedom of speech?
), and each node is on aver-age connected to 1.7 other nodes.
When the gloss-basededges are considered separately, the highest degree nodesare those with the longest definitions; the maximum out-degree is 56 and the average out-degree is 6.2.
For theedges linking TokenPOS nodes to the Synsets in whichthey participate, TokenPOS nodes with many senses arethe most connected; ?break#v?
with 59 outgoing edgesand ?make#v?
with 49 outgoing edges have the highestout-degrees, with the average out-degree being 1.3.3.2 Computing the stationary distributionEach of the K edge types presented above can be repre-sented as separate transition matrix Ek ?
RN?N where583N is the total number of nodes.
For each matrix, col-umn j contains contains a normalized outgoing proba-bility distribution,1 so the weight in cell (i, j) containsPK(ni | nj), the conditional probability of moving fromnode nj to node ni in edge type K. For many of the edgetypes, this is either 0 or 1, but for the weighted edges,these are real valued.
The full transition matrixM is thenthe column normalized sum of all of the edge types:M?
=?kEkM =(???M?????)?1?
M?M is a distillation of relevant relatedness informationabout all nodes extracted from WordNet and is not tai-lored for computing a stationary distribution for any spe-cific word.
In order to compute the stationary distribu-tion vdog#n for a walk centered around the TokenPOS?dog#n,?
we first define an initial distribution v(0)dog#n thatplaces all the probability mass in the single vector entrycorresponding to ?dog#n.?
Then at every step of the walk,we will return to v(0) with probability ?.
Intuitively, thisreturn probability captures the notion that nodes close to?dog#n?
should be given higher weight, and also guaran-tees that the stationary distribution exists and is unique(Bremaud, 1999).
The stationary distribution v is com-puted via an iterative update algorithm:v(t) = ?v(0) + (1?
?
)Mv(t?1)Because the walk may return to the initial distributionv(0) at any step with probability ?, we found that v(t)converges to its unique stationary distribution v(?)
in anumber of steps roughly proportional to ??1.
We experi-mented with a range of return probabilities and found thatour results were relatively insensitive to this parameter.Our convergence criteria was?
?v(t?1) ?
v(t)?
?1< 10?10,which, for our graph with a return probability of ?
= .1,was met after about two dozen iterations.
This computa-tion takes under two seconds on a modern desktop ma-chine.Note that because M is sparse, each iteration of theabove computation is linear in the total number of non-zero entries in P , i.e.
linear in the total number of edges.Introducing an edge type that is dense would dramaticallyincrease running time.3.3 Model variantsFor this paper, we consider three model variants that dif-fer based on which subset of the edge types are included1The frequency-count derived edges are normalized by thelargest column sum.
This effectively preserves relative term fre-quency information across the graph and causes some columnsto sum to less than one.
We interpret this lost mass as a link to?nowhere.
?in the transition matrix M .MarkovLink This variant includes the explicit WordNetrelations such as hypernymy and the edges repre-senting overlap between the TokenPOS nodes con-tained in Synsets.
A particle walking through thisgraph reaches only Synset nodes and can step fromone Synset to another whenever WordNet specifies arelationship between the Synsets or when the Synsetsshare a common word.
There is a single connectedcomponent in this model variant.
This model isloosely analogous to a smoothed version of the path-based WordNet measures surveyed in (Budanitskyand Hirst, 2006) but differs in that it integrates mul-tiple link types and aggregates relatedness informa-tion across all paths in the graph.MarkovGloss This variant includes only the weighteduni-directional edges linking Synsets to the Token-POS nodes contained in their gloss definitions, andthe edges from a TokenPOS node to the Synsets con-taining it.
The intuition behind this model variant isthat the particle can move as if it were recursivelylooking up words in a dictionary, stepping fromSynsets to the Synsets used to define them.
BecauseWordNet?s gloss definitions are not sense-tagged,the particle must make an intermediate step to a To-kenPOS contained in the gloss definition and thento a Synset representing a particular sense of thatTokenPOS.
The availability of sense-tagged glosseswould eliminate the noise introduced by this inter-mediate step.
The particle can reach both Synsetsand TokenPOS nodes in this variant, but some partsof the graph are not reachable from other parts.
Thismodel incorporates much of the same informationas the gloss-based WordNet measures (Banerjee andPedersen, 2003; Patwardhan and Pedersen, 2006)but differs in that it considers many more glossesthan just those in the immediate neighborhoods ofthe candidate words.MarkovJoined This variant is the natural combinationof the above two; we construct the graph containingWordNet relation edges, Synset overlap edges, andgloss-based Synset to TokenPOS edges.Many of the characteristics of the model variants canbe understood in terms of how much probability massthey assign to each node for a particular word-specificstationary distribution.
Table 1 shows the highest scoringnodes in the word-specific stationary distributions cen-tered around the Token node for ?wizard,?
as computed bythe MarkovLink and MarkovGloss variants.
In both vari-ants, the ?wizard?
Token?s only neighbors are the ?wiz-ard#n?
and ?wizard#a?
TokenPOS nodes, and ?wizard#n?584MarkovLink MarkovGlossNode Probability Node Probabilitywizard 1.0E-1 wizard 1.3E-01wizard#n 2.5E-3 wizard#n 2.9E-02wizard#a 7.8E-5 wizard#a 9.1E-04ace#n#3 4.2E-5 ace#n#3 1.1E-06sorcerer#n#1 2.2E-6 sorcerer#n#1 5.8E-07charming#a#2 2.2E-6 dazzlingly#r 2.4E-08expert#n#1 1.1E-6 charming#a#2 1.6E-09track star#n#1 1.1E-6 sorcery#n 2.6E-10occultist#n#1 5.7E-7 magic#n 6.8E-12Cagliostro#n#1 5.7E-7 magic#a 6.8E-12star#v#2 5.5E-7 dazzlingly#r#1 4.3E-14breeze_through#v#1 5.4E-7 dazzle#n 9.4E-16magic#n#1 2.1E-8 beholder#n 9.4E-16sorcery#n#1 2.1E-7 dazzle#v 9.4E-16magician#n#1 1.9E-7 magic#n#1 5.1E-16Table 1: Highest scoring nodes in the stationary distri-butions for ?wizard#n?
as generated by the MarkovLinkmodel and the MarkovGloss model with return probabil-ity 0.1.has a higher probability mass because of its higher Sem-Cor usage counts.
Likewise, the only possible steps per-mitted in either variant from ?wizard#n?
and ?wizard#a?are to the Synsets that can be expressed with those nodes:?ace#n#3,?
?sorcerer#n#1,?
and ?charming#a#1.?
Again,the amount of mass given to these nodes depends on thestrength of these edge weights, which is determined bythe SemCor usage counts.The highest probability nodes in the table are commonbecause both model variants share the same initial links.However, the orders of the remaining nodes in the station-ary distributions are different.
In the MarkovLink variant,the random walk can only proceed to other Synsets usingWordNet relationship edges; ?track star#n#1?
and ?ex-pert#n#1?
are first reached by following hyponym andhypernym edges from ?ace#n#1,?
and ?occultist#n#1?and ?Cagliostro#n#1?
are first reached with hypernymand instance edges from ?sorcerer#n#1.?
The node?breeze through#v#1?
is reached through a path follow-ing derivational links with ?ace#n?
and ?ace#v.
?The MarkovGloss variant in table 1 shows how infor-mation can be extracted solely from the textual glosses.Once the random walk reaches the first Synset nodes, itcan step to the TokenPOS nodes in their glosses; for ex-ample, ?ace#n#1?
has the gloss ?someone who is daz-zlingly skilled in any field.?
Links to TokenPOS nodesthat are very common in glosses are down-weighted withNMDF weighting, so ?someone#n?
receives little masswhile ?dazzlingly#r?
receives more.
From there, therandom walk can step to another Synset such as ?daz-MarkovLink model MarkovGloss modelFigure 1: Example stationary distributions plotted againsteach other for similar (top) and dissimilar (bottom) wordpairs, using the MarkovLink (left) and MarkovGloss(right) model variants.zlingly#r#1,?
and then on to other TokenPOS nodes usedin its definition: ?in a manner or to a degree that dazzlesthe beholder.
?Figure 1 demonstrates how two word-specific station-ary distributions are more highly correlated if the wordsare related.
In both model variants, random walks forrelated words are more likely to visit the same parts ofthe graph, and so assign higher probability to the samenodes.
Figure 1 also shows that the MarkovGloss variantproduces distributions with a much wider range of proba-bilities than the MarkovLink, which might be a source ofdifficulty in integrating the two model variants.Figure 2 shows the correlation between the stationarydistributions produced by the two model variants for thesame word.
The log-log scale makes it possible to see theentire range of probabilities on the same axes, and showsthat distributions produced by these two model variantsshare many of the same highest-probability words.A noteworthy property of the constructed graphs is thatword relatedness can be computed directly by compar-ing walks that start at Token nodes.
By contrast, existingWordNet-based measures require independent similarityjudgments for all word senses relevant to a target wordpair (of which the maximum relatedness value is usu-ally taken).
Our algorithm lends itself to comparisonsbetween walks centered at a Synset node, or a Token-POS node, or a Token node, or any mixed distributionthereof.
And because the Synset nodes are strongly con-nected, the model also admits direct comparison acrossparts of speech.585Figure 2: Correlation of the stationary distributions for?wizard#n,?
produced by the MarkovLink variant (x-axis)and the MarkovGloss variant (y-axis).4 Similarity judgmentsWe have shown how to compute the word-specific sta-tionary distribution from any starting distribution in thegraph.
Now consider the task of deciding similarity be-tween two words.
Intuitively, if the random walk startingat the first word?s node and the random walk starting atthe second word?s node tend to visit the same nodes, wewould like to consider them semantically related.
For-mally, we measure the divergence of their respective sta-tionary distributions, p and q.A wide literature exists on similarity measures betweenprobability distributions.
One standard choice is to con-sider p and q to be vectors and measure the cosine ofthe angle between them, which is rank equivalent to Eu-clidean distance.simcos(p, q) =?i piqi?p?
?q?Because p and q are probability distributions, we wouldalso expect a strong contender from the information-theoretic measures based on Kullback-Leibler diver-gence, defined as:DKL(p ?
q) =?ipi logpiqiUnfortunately, KL divergence is undefined if any qi iszero because those terms in the sum will have infiniteweight.
Several modifications to avoid this issue havebeen proposed in the literature.
One is Jensen-Shannondivergence (Lin, 1991), a symmetric measure based onKL-divergence defined as the average of the KL diver-gences of each distribution to their average distribution.Jensen-Shannon is well defined for all distributions be-cause the average of pi and qi is non-zero whenever eithernumber is.These measures and others are surveyed in (Lee,2001), who finds that Jensen-Shannon is outperformedby the Skew divergence measure introduced by Lee in(1999).
The skew divergence2 accounts for zeros in q bymixing in a small amount of p.s?
(p, q) = D(p ?
?q + (1?
?
)p)=?i pi logpi?qi+(1??
)piLee found that as ?
?
1, the performance of skew di-vergence on natural language tasks improves.
In partic-ular, it outperforms most other models and even beatspure KL divergence modified to avoid zeros with sophis-ticated smoothing models.
In exploring the performanceof divergence measures on our model?s stationary distri-butions, we observed the same phenomenon.
Note thatin the limit as ?
?
1, alpha skew is identically KL-divergence.4.1 Zero-KL DivergenceIn this section we introduce a novel measure of distribu-tional divergence based on a reinterpretation of the skewdivergence.
Skew divergence avoids zeros in q by mixingin some of p, but its performance on many natural lan-guage tasks improves as it better approximates KL diver-gence.
We propose an alternative approximation to KLdivergence called Zero-KL divergence, or ZKL.
Whenqi is non-zero, we use exactly the term from KL diver-gence.
When qi = 0, we have a problem?in the limit as?
?
1, the corresponding term approaches infinity.
Welet ZKL use the Skew divergence value for these terms:pi logpi?qi+(1??)pi.
Because qi = 0 this simplifies topi logpi(1??
)pi= pi log 11??
.Lee showed skew divergence?s best performance wasfor ?
near to 1, so we formalize this intuition by choosing?
exponentially near to 1, i.e.
we can choose our ?
as1?2??
for some ?
?
R+.
Zero terms in the sum can nowbe written as pi log 12??
= pi log 2?
= pi ?.
Note here ananalogy to the case with qj > 0 and where pj is exactlyone order of magnitude greater than qj , i.e.
pj = 2 ?
qj .For such a term in the standard KL divergence, we wouldget pj logpjqj= pj log(2) = pj .
Therefore, the ?
termin skew divergence implicitly defines a parameter statinghow many orders of magnitude smaller than pj to countqj if qj = 0.We define the Zero-KL divergence with respect to2In Lee?s (1999) original presentation, skew divergence isdefined not as s?
(p, q) but rather as s?
(q, p).
We reverse the ar-gument order for consistency with the other measures discussedhere.586gamma:ZKL?
(p, q) =?ipi{log piqi qi 6= 0?
qi = 0Note that this is exactly KL-divergence when KL-divergence is defined and, like skew divergence, approx-imates KL divergence in the limit as ?
?
?.A similar analysis of the skew divergence terms forwhen 0 < qi  pi (and in particular with qi less than piby more than a factor of 2??)
shows that such a term inthe skew divergence sum is again approximated by ?
pi.ZKL does not have this property.
Because ZKL is a betterapproximation to KL divergence and because they havethe same behavior in the limit, we expect ZKL?s perfor-mance to dominate that of skew divergence in many dis-tributions.
However, if there is a wide range in the ex-ponent of noisy terms, the maximum possible penalty tosuch terms ascribed by skew divergence may be benefi-cial.Figure 3 shows the relative performance of ZKL versusJensen-Shannon, skew divergence, cosine similarity, andthe Jaccard score (a measure from information retrieval)for correlations with human judgment on the MarkovLinkmodel.
ZKL consistently outperforms the other measureson distributions resulting from this model, but ZKL is notoptimal on distributions generated by our other models.The next section explores this topic in more detail.5 EvaluationTraditionally, there have been two primary types of eval-uation for measures of semantic relatedness: one is cor-relation to human judgment, the other is the relative per-formance gains of a task-driven system when it uses themeasure.
The evaluation here focuses on correlation withhuman judgments of relatedness.
For consistency withprevious literature, we use rank correlation (Spearman?s?
coefficient) rather than linear correlation when compar-ing sets of relatedness judgments because the rank corre-lation captures information about the relative ordering ofthe scores.
However, it is worth noting that many applica-tions that make use of lexical relatedness scores (e.g.
asfeatures to a machine learning algorithm) would better beserved by scores on a linear scale with human judgments.Rubenstein and Goodenough (1965) solicited humanjudgments of semantic similarity for 65 pairs of com-mon nouns on a scale of zero to four.
Miller and Charles(1991) repeated their experiment on a subset of 29 nounpairs (out of 30 total) and found that although indi-viduals varied among their judgments, in aggregate thescores were highly correlated with those found by Ruben-stein and Goodenough (at ?
= .944 by our calculation).Resnik (1999) replicated the Miller and Charles experi-ment and reported that the average per-subject linear cor-relation on the dataset was around r = 0.90, providinga rough upper bound on any system?s linear correlationperformance with respect to the Miller and Charles data.Figure 3 shows that the ZKL measure on the MarkovLinkmodel has linear correlation coefficient r = .903?at thelimit of human inter-annotator agreement.Recently, a larger set of word relatedness judg-ments was obtained by (Finkelstein et al, 2002) in theWordSimilarity-353 (WS-353) collection.
Despite thecollection?s name, the study instructed participants toscore word pairs for relatedness (on a scale of 0 to10), which is in contrast to the similarity judgments re-quested of the Miller and Charles (MC) and Rubensteinand Goodenough (RG) participants.
For this reason, theWordSimilarity-353 data contains many pairs that are notsemantically similar but still receive high scores, such as?computer-software?
at 8.81.
WS-353 contains pairs thatinclude non-nouns, such as ?eat-drink,?
one proper nounnot appearing in WordNet (?Maradona-football?
), andsome pairs potentially subject to political bias.
Again,the aggregate human judgments correlate well with ear-lier data sets where they overlap?the 30 judgments thatWordSimilarity-353 shares with the Miller and Charlesdata have ?
= .939 and the 29 shared with Rubensteinand Goodenough have ?
= .904 (by our calculations).We generated similarity scores for word pairs in allthree data sets using the three variants of our walkmodel (MarkovLink, MarkovGloss, MarkovJoined) andwith multiple distributional distance measures.
We usedthe WordNet::Similarity package (Pedersen et al, 2004)to compute baseline scores for several existing measures,noting that one word pair was not processed in WS-353because one of the words was missing from WordNet.The results are summarized in Table 2.
These num-bers differ slightly from previously reported scores due tovariations in the exact experimental setup, WordNet ver-sion, and the method of breaking ties when computing?
(here we break ties using the product-moment formu-lation of Spearman?s rank correlation coefficient).
It isworth noting that in their experiments, (Patwardhan andPedersen, 2006) report that the Vector method has rankcorrelation coefficients of .91 and .90 for MC and RG,respectively, which are also top performing values.In our experiments, the MarkovLink model with ZKLdistance measure was the best performing model over-all.
MarkovGloss and MarkovJoined were also strongcontenders but with the cosine measure instead of ZKL.One reason for this distinction is that the stationary dis-tributions resulting from the MarkovLink model are non-zero for all but the initial word nodes (i.e.
non-zerofor all Synset nodes).
Consequently, ZKL?s re-estimatefor the zero terms adds little information.
By contrast,theMarkovGloss andMarkovJoined models include linksthat traverse from Synset nodes to TokenPOS nodes, re-587Figure 3: Correlation with the Miller & Charles data sets by linear correlation (left) and rank correlation (right) for theMarkovLink model.
All data points were based on one set of stationary distributions over the graph; only the divergencemeasure between those distributions is varied.
Note that ZKL?
dominates both graphs but skew divergence does wellfor increasing ?
(computed as 1?
2?).
Gamma is swept over the range 0 to 1, then 1 through 20, then 20 through 40at equal resolutions.Model MC Rank RG Rank WS-353 RankMarkovLink (ZKL) .904 .817 .552MarkovGloss (cosine) .841 .762 .467MarkovJoined (cosine) .841 .838 .547Gloss Vectors .888 .789 .445Extended Lesk .869 .829 .511Jiang-Conrath .653 .584 .195Lin .625 .599 .216Table 2: Spearman?s ?
rank correlation coefficients withhuman judgments using ?
= 2.0 for ZKL.
Note that fig-ure 3 demonstrates ZKL?s insensitivity with regard to theparameter setting for the MarkovLink model.sulting in a final stationary distribution with more (andmore meaningful) zero/non-zero pairs.
Hence the propersetting of gamma (or alpha for skew divergence) is ofgreater importance.
ZKL?s performance improves withtuning of gamma, but cosine similarity remained the morerobust measure for these distributions.6 ConclusionIn this paper, we have introduced a new measure oflexical relatedness based on the divergence of the sta-tionary distributions computed from random walks overgraphs extracted WordNet.
We have explored the struc-tural properties of extracted semantic graphs and charac-terized the distinctly different types of stationary distribu-tions that result.
We explored several distance measureson these distributions, including ZKL, a novel variant ofKL-divergence.
Our best relatedness measure is at thelimit of human inter-annotator agreement and is one ofthe strongest measures of semantic relatedness that usesonly WordNet as its underlying lexical resource.In future work, we hope to integrate other lexical re-sources such as Wikipedia into the walk.
Incorporat-ing more types of links from more resources will un-derline the importance of determining appropriate rela-tive weights for all of the types of edges in the walk?smatrix.
Even for WordNet, we believe that certain linktypes, such as antonyms, may be more or less appropriatefor certain tasks and should weighted accordingly.
Andwhile our measure of lexical relatedness correlates wellwith human judgments, we hope to show performancegains in a real-word task from the use of our measure.AcknowledgmentsThanks to Christopher D. Manning and Dan Jurafsky fortheir helpful comments and suggestions.
We are alsograteful to Siddharth Patwardhan and Ted Pedersen forassistance in comparing against their system.
Thanks toSushant Prakash, Rion Snow, and Varun Ganapathi fortheir advice on pursuing some of the ideas in this pa-per, and to our anonymous reviewers for their helpful cri-tiques.
Daniel Ramage was funded in part by an NDSEGfellowship.
This work was also supported in part by theDTO AQUAINT Program, the DARPA GALE Program,and the ONR (MURI award N000140510388).588ReferencesS.
Banerjee and T. Pedersen.
2003.
Extended gloss over-laps as a measure of semantic relatedness.
In Proceed-ings of the Eighteenth International Joint Conferenceon Artificial Intelligence, Acapulco, pages 805?810.P.
Berkhin.
2005.
A survey on pagerank computing.
In-ternet Mathematics, 2(1):73?120.P.
Bremaud.
1999.
Markov chains: Gibbs fields, montecarlo simulation, and queues.
Springer-Verlag.A.
Budanitsky and G. Hirst.
2006.
Evaluating wordnet-based measures of lexical semantic relatedness.
Com-putational Linguistics, 32(1):13?47.K.
Collins-Thompson and J. Callan.
2005.
Query expan-sion using random walk models.
In CIKM ?05: Pro-ceedings of the 14th ACM international conference onInformation and knowledge management, pages 704?711, New York, NY, USA.
ACM Press.C.
Fellbaum.
1998.
WordNet: An electronic lexicaldatabase.
MIT Press.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and EytanRuppin.
2002.
Placing search in context: The conceptrevisited.
ACM Transactions on Information Systems,20(1):116?131.Evgeniy Gabrilovich and Shaul Markovitch.
2007.
Com-puting semantic relatedness using wikipedia-based ex-plicit semantic analysis.
In IJCAI.T.
Haveliwala, A. Gionis, D. Klein, and P. Indyk.
2002.Evaluating strategies for similarity search on the web.In WWW2002.Mario Jarmasz and Stan Szpakowicz.
2003.
Roget?sthesaurus and semantic similarity.
In Proceedings ofRANLP-03, pages 212?219.J.
J. Jiang and D. W. Conrath.
1997.
Semantic simi-larity based on corpus statistics and lexical taxonomy.In Proceedings of the International Conference on Re-search in Computational Linguistics (ROCLING X),pages 19?33.Lillian Lee.
1999.
Measures of distributional similarity.In 37th Annual Meeting of the Association for Compu-tational Linguistics, pages 25?32.Lillian Lee.
2001.
On the effectiveness of the skew di-vergence for statistical language analysis.
In ArtificialIntelligence and Statistics 2001, pages 65?72.Jianhua Lin.
1991.
Divergence measures based on theshannon entropy.
In IEEE Transactions on Informa-tion Theory, volume 37(1), pages 145?151.Rada Mihalcea.
2005.
Unsupervised large-vocabularyword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In HLT ?05: Pro-ceedings of the conference on Human Language Tech-nology and Empirical Methods in Natural LanguageProcessing, pages 411?418, Morristown, NJ, USA.Association for Computational Linguistics.G.A.
Miller and W.G.
Charles.
1991.
Contextual corre-lates of semantic similarity.
Language and CognitiveProcesses, 6:1?28.S.
Patwardhan and T. Pedersen.
2006.
Using wordnet-based context vectors to estimate the semantic related-ness of concepts.
In Proceedings of the EACL 2006Workshop Making Sense of Sense - Bringing Com-putational Linguistics and Pyscholinguistics Together,pages 1?8.Ted Pedersen, Siddharth Patwardhan, and Jason Miche-lizzi.
2004.
Wordnet::similarity - measuring the relat-edness of concepts.
In Proceedings of the NineteenthNational Conference on Artificial Intelligence.Philip Resnik.
1999.
Semantic similarity in a taxonomy:An information-based measure and its application toproblems of ambiguity in natural language.
Journal ofArtificial Intelligence Research, (11):95?130.H.
Rubenstein and J.B. Goodenough.
1965.
Contextualcorrelates of synonymy.
Computational Linguistics,8:627?633.Michael Strube and Simone Paolo Ponzetto.
2006.Wikirelate!
computing semantic relatedness usingwikipedia.
In Proceedings of the 21st National Con-ference on Artificial Intelligence, pages 1419?1424.Paul Tarau, Rada Mihalcea, and Elizabeth Figa.
2005.Semantic document engineering with wordnet andpagerank.
In SAC ?05: Proceedings of the 2005ACM symposium on Applied computing, pages 782?786, New York, NY, USA.
ACM Press.Kristina Toutanova, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of HLT-NAACL 2003, pages 252?259.Kristina Toutanova, Christopher D. Manning, and An-drew Y. Ng.
2004.
Learning random walk modelsfor inducing word dependency distributions.
In ICML?04: Proceedings of the twenty-first international con-ference on Machine learning, New York, NY, USA.ACM Press.Julie Weeds and David Weir.
2005.
Co-occurrence re-trieval: A flexible framework for lexical distributionalsimilarity.
Comput.
Linguist., 31(4):439?475.589
