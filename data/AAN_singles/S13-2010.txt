Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 58?63, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsFSS-TimEx for TempEval-3: Extracting Temporal Information from TextVanni ZavarellaJoint Research CentreEuropean Commission21027 Ispra, Italyvanni.zavarella@jrc.ec.europa.euHristo TanevJoint Research CentreEuropean Commission21027 Ispra, Italyhristo.tanev@jrc.ec.europa.euAbstractWe describe FSS-TimEx, a module for therecognition and normalization of temporal ex-pressions we submitted to Task A and B ofthe TempEval-3 challenge.
FSS-TimEx wasdeveloped as part of a multilingual event ex-traction system, Nexus, which runs on top ofthe EMM news processing engine.
It consistsof finite-state rule cascades, using minimalis-tic text processing stages and simple heuris-tics to model the relations between events andtemporal expressions.
Although FSS-TimExis already deployed within an IE applicationin the medical domain, we found it useful tocustomize its output to the TimeML standardin order to have an independent performancemeasure and guide further developments.1 IntroductionThe FSS-TimEx (Finite State-based Shallow TimeExtractor) system participating in TempEval-3 is in-tegrated in the event extraction engine Nexus (Tanevet al 2008), developed at the EC?s Joint ResearchCenter for extracting event information from on-linenews articles gathered by the Europe Media Mon-itor (EMM) news aggregation and analysis familyof applications(Steinberger et al 2009).
Nexus ishighly multilingual1 and easily portable across do-mains through semi-automatic learning of lexical re-sources.
In the domain of epidemiological surveil-lance, the event extraction task required a particu-larly deep temporal information analysis, in order to1Currently, it covers English, French, Italian, Spanish, Por-tuguese, Turkish, Russian, Arabic.detect temporal relations among event reports andmitigate the classical event duplication problem.
Asan example, from a report like:The overall death toll has risen to 160since the beginning of the year, after 2patients in Gulu and 2 in Masindi died onTue 5 Dec 2000.a system might be prevented to wrongly sum up thetwo victim counts (160+4) only if it is made aware ofthe inclusion relation between the first time intervaland the date, which in turn implies normalizing thetwo temporal expressions.Currently, FSS-TimEx is deployed for French,English and Italian and extensions are foreseen forfurther languages.
Given such requirements for mul-tilinguality, we developed FSS-TimEx using a lin-guistically light-weight approach, applying shallowprocessing modules only.
On the other hand, as weneed to extract highly structured information out ofthe detected temporal expressions, to be used in thesubsequent normalization phase, we mostly optedfor a rule-based approach, using finite-state gram-mar cascades, rather than machine learning meth-ods.
Nonetheless, some of the required lexiconswere semi-automatically learned.In our participation in Tasks A and B of theTempEval-3, we experimented with adapting an ex-isting timex recognition module for the English lan-guage, to Spanish.We first describe our system in 2,3 and 4, then in5 we show and shortly discuss the results for TaskA and Task B, and conclude with some thoughts onprospective developments.582 System ModulesThe system makes use of cascades of finite-stategrammar rules applied to the output of a set of shal-low text processing modules.Text Processing Modules.
These include tok-enization, sentence splitting, domain-specific dictio-nary look-up and morphological analysis, which areall part of the CORLEONE (Core Linguistic EntityOnline Extraction) engine (Piskorski, 2008).
Mor-phological analysis purely consists of matching texttokens over full-form entries of a dictionary from theMULTEXT project (Erjavec, 2004), which encodesrich morphological features in a cross-lingual stan-dard.
Consequently, no PoS-tagging or parsing isperformed upstream of the extraction grammars.Finite-State Grammar Engine.
We use the Ex-PRESS finite-state grammar engine (Piskorski,2007).
Grammars in the ExPRESS formalism con-sist of cascades of pattern-action rules, whose left-hand side (LHS) are regular expressions over flatfeature structures (FFS) and the right-hand side(RHS) consists of a list of FFS (see Figure 1 be-low for an example).
Variable binding from LHS toRHS, as well as string processing and Boolean op-erators on the RHS, allow to impose relatively com-plex constraints in the form of Boolean-valued pred-icates.Weakly-supervised Learning of Lexical Re-sources.
In order to determine the Class featurefor the event extraction task, we experimented withusing a language-independent method for weakly-supervised lexical acquisition.
The algorithm takesas input a small set of seed terms, an unannotatedtext corpus and a parameter for the number of boot-strapping iterations: it then learns a ranked list offurther terms, which are likely to belong to the sameclass, based on distributional n-gram features andterm clustering (Tanev et al in press).
Althoughmanual post-filtering is required, output term accu-racy is reasonably high, and very high for top rankedterms.3 Event and Event Feature Detection(Task B)Although Nexus is a high precision event extractionsystem, we have not deployed it to model the eventdetection task.
The reason is that Nexus is cus-tomized to recognize a number of highly domain-specific event types (e.g.
Armed Conflict,Earthquake,Terrorist Attack) and willnecessarily perform low in recall given the general,domain-independent definition of events in TaskB.
Instead, we tentatively used a small set oflanguage-dependent finite-state rules to model verbphrase structure.
Rules take as input MULTEXTmorphological tokens and detect verb phrases alongwith a number of VP features, including Tense,which is used by the temporal normalizer to groundevent modifying temporal expressions (see 4.2).Class attribute was encoded in the morphologi-cal dictionary by using the output of the machinelearning method sketched above: for each TimeMLEvent Class (Pustejovsky et al 2003), we providedseed verb forms for all of its sub-classes, performedmulti-class learning, and used the main Class labelto annotate the union of output forms in the lexicon,after some manual cleaning.The OCCURRENCE class was used as the defaultClass value for event verb forms, and it was overrid-den whenever a more specific event Class value waspresent2.We do not cover event nominal forms, as aftersome tests event referring and non-event referringnoun classes appeared too difficult to tell apart bymachine learning methods.
Consequently, we ex-pect system recall in Task B to be heavily limited.4 Temporal Expressions (Task A)FSS-TimEx?s temporal expression processing con-sists of two stages.In the Recognition phase, temporal expressionsare detected and segmented in text and a more ab-stract representation of them is filled for furtherprocessing.
Local parsing of timexes is performedby a cascade of hand-coded, partially language-dependent finite-state grammar rules using the Ex-PRESS engine, resulting in an intermediate fea-2Otherwise, we chose randomly among alternative values ofClass-ambiguous event expressions.59rule :> ( (lex & [TYPE:"temp_signal", SURFACE:#signal, NORMALIZED:"INCLUDED"]| lex & [TYPE:"temp_signal", NORMALIZED:"DURING"])lex & [TYPE:"quantifier", NORMALIZED:#mod]?
determiner?lex & [TYPE:"temp_mod", OP:#op, REF_TYPE:#ref_type]( (lex & [TYPE: "numeral", NORMALIZED:#amount1]lex & [TYPE: "numeral", NORMALIZED:#amount2]?
)| token & [TYPE: "any_natural_number", SURFACE:#amount1]lex & [TYPE:"time_unit", NUM:"p", GRAN:#gran]):x-> x: period & [DIR:#op,REF_TYPE:#ref_type,MOD:#mod,GRAN:#gran,QUANT:#amount,SIGNAL:#signal]& #amount := ConcForSum(#amount1,#amount2).Figure 1: Sample recognition ruleture structure-like representation, which is subse-quently used by a language-independent Normaliza-tion stage to compute exact values of the time ex-pressions, according to the TimeML standard.We judge that such a strict coupling of recognitionand normalization is better achieved through featureextraction rules than by deploying two separate pro-cesses3.4.1 Recognizing Temporal ExpressionsA cascade of around 90 rules is deployed for the En-glish language.
These comprise lower-level rules, incharge of modelling language constructions in thetarget language, and typization rules that check theattribute configuration of lower-level rule output andreturn a corresponding structure, typed according toan intermediate annotation type set, exporting all at-tribute values relevant for normalization.As an example, the rule shown in Figure1 detectssingle-boundary period expressions (e.g.
in the pre-vious four weeks or during the next five days).Notice that the rule output type is the nonTimeML-compliant period (i.e.
an anchored timeduration).
This is an intermediate annotation typewhich is subsequently converted into a TimeMLtype (Duration) during the Normalization phase.The temporal lexicon referenced by the gram-mar contains around 300 entries for the English lan-guage, classified into as many as 24 types, each de-scribed by a small attribute list.
Sample entries fromthe English lexicon are listed in Figure 2.This lexicon structure (types and attributes) wasapplied as such to the Spanish language; lexiconpopulation was manually done in one day of work,by first translating lexical triggers (e.g.
day, month3This architecture is very close to the one proposed by theITA-Chronos system (Negri, 2007).monday | TYPE:day_name | NORMALIZED:Mondayweeks | TYPE:time_unit | GRAN:week | NUM:pnight | TYPE:day_period_name | NORMALIZED:NIago | TYPE:temp_adv | OP:- | REF_TYPE:speakerlast | TYPE:temp_mod | OP:- | REF_TYPE:speakersince | TYPE:temp_signal | NORMALIZED:BEGINearly | TYPE:mod | NORMALIZED:STARTFigure 2: Sample lexicon entriesnames, numerals) and then gathering more func-tional entries (temporal adverbs, modifiers, etc.)
byrunning test rules on large corpora.
It turned out that,by using a parallel lexicon structure, we could re-duce the cross-lingual re-arrangement of extractionrules for the Spanish grammar, minimizing the workcost to only 2 days, excluding fine tuning.4.2 NormalizationNormalization is a fully language-independent pro-cess, working with calendar representations of tem-poral expressions4 built out of the output featurestructures from the Recognition phase.
It comprisestwo sub-processes:Anchor selection.
First, anchor selection deter-mines and maintains a reference time for relativetimex resolution, starting by using the Article Cre-ation Date and updating it along the resolution pro-cess according to a simple search heuristic: selectthe closest preceding resolved timex with a compat-ible level of granularity.
We experimented with twoalternative settings for this, one restricting the searchto timexes within the same sentence, the other span-ning over the whole article text: we noticed a sys-tematic gain in normalization accuracy with the for-mer setting and we used it for Task A.4The normalization is entirely implemented in Java code.60Timex-Event mapping.
For certain timexclasses5 we need to resort to Tense informationfrom event-referring verb phrases in order to dis-ambiguate between future and past interpretation.For this purpose, a simple, syntax-free heuristic isimplemented to compute a mapping from each timeexpression onto the event it modifies, which justuses a weighted token distance metric, promotingevents preceding the timex over those following it.Finally, calendar arithmetic is used to resolve andnormalize the value of relative timexes.5 Results65.1 Temporal Expression ExtractionFor English, our system scored in the middle rangeover all participant systems on relaxed match F1measure.
Strict match figures are not indicative: in-deed, temporal signals (like on in on Friday) weresystematically included in the extracted extent, con-trary to the TIMEX3 tag specification, because thisis required by finite-state parsing of the IE systemwith which FSS-TimEx was integrated.Compared to the best performing system (BestENin Table1), our approach mainly suffered from rela-tively low recall.
Although such a rate of false neg-atives can be expected from a rule-based approach,in our case it was mostly due to two main ?bugs?
inthe normalization code: first, in the process of tun-ing system output types to TimeML, we erroneouslydiscarded date expressions introduced by temporalsignals, like in from now; secondly, we do not nor-malize single adverbial expressions (currently), al-though they are detected by grammar rules.We outperformed in Precision the best F1 system.Many false positives were all coming from a singlearticle, where the word season in flu season was sys-tematically annotated as an event in the gold stan-dard.
This kind of context-based inference seems tobe out of reach for our rule-based, local parsing ap-proach.The major flaw in porting the system to Span-ish language was a 28% Recall drop.
Main types5E.g.
what we refer to as relativeTime orrelativeOffset, like on Thursday and this weekend, re-spectively.6Results were obtained in 1.89 and 1.97 seconds of com-putation time respectively for English and Spanish data, on anIntel Core i3 M380 2.53GHz processor.of false negatives included fuzzy expressions (e.g.hace tiempo), and compositional expressions.Performance in timex classification and normal-ization still falls behind top scoring systems.
Finite-state techniques can only parse local constructions,greedily consuming as long text spans as possible:therefore we systematically miss clausal relationslike in: The day before Raymond Roth was pulledwhere we wrongly parsed a fully specified, relativetimex The day before.
Similar cases resulted at thesame time in incorrect Type assignment, like inTwo years after his brain-cancer diagnosis wherewe wrongly detect a Date type expression (Twoyears after).Inaccurate event Tense attribute extractionsometimes caused wrong timex Value normaliza-tion.
One noticeable source of such an error is re-ported speech, which temporarily changes the dis-course utterance time and that we do not attemptto model in our anchor selection procedure.
Inter-estingly, we noticed that even in cases when bothtimex-event mapping, and event Tense were cor-rect,Value normalization was not.
For example, in:Northern Ireland?s World Cup qualifier with Russiahas been postponed until 15:00 GMT Saturday, onecan see that a shallow approach like ours, with no ac-cess to lexico-semantic knowledge, cannot pick upthe implicit future tense interpretation of the eventverb.5.2 Event and Event Attribute ExtractionResults for Spanish (Table 2) show that a small setof rules were sufficient to detect event verbal expres-sions with high precision.
The task was much harderfor English, where morphological derivation is lessoften marked and given that we were not performingany PoS disambiguation.Our main aim for Task B exercise was evaluatingthe performance of semi-automatic methods for verbclassification, and to see how much verb tense in-formation could help normalizing time expressions.Class attribute performance is rather poor, evenconsidering that 7% of false hits in English were dueto a bug in the MULTEXT lexicon causing the fre-quent form said not to be annotated as REPORTINGevent.
A high rate of overlapping occurs amongverb classes, causing our attempt to ?lexicalize?
theClass attribute, rather than trying to compute it61Recognition NormalizationRelaxed Strict Value TypeSystem F1 P R F1 P R F1 A F1 AEN 0.85 0.90 0.80 0.49 0.52 0.46 0.58 0.68 0.69 0.81BestEN 0.90 0.89 0.91 0.79 0.78 0.80 0.78 0.86 0.80 0.88ES 0.65 0.86 0.52 0.49 0.65 0.39 0.50 0.77 0.62 0.95BestES 0.90 0.96 0.84 0.85 0.90 0.80 0.85 0.94 0.87 0.97Table 1: Performance of Temporal Expression Extraction and Normalization.Recognition Class TenseSystem F1 P R F1 A F1 AEN 0.65 0.63 0.67 0.43 0.66 0.39 0.60BestEN 0.81 0.81 0.81 0.72 0.89 0.60 0.73ES 0.58 0.90 0.42 0.26 0.45 0.49 0.84BestES 0.89 0.92 0.86 0.85 0.96 0.87 0.98Table 2: Performance of Event and Event Attribute Extraction.from context features of verb instances, to be unfea-sible.
Tense attribute performance7 was too low todraw any conclusion on its impact on the Normal-ization task.
However, for Spanish its accuracy (Ain Figure 2) was higher and yet this did not result inincreased timex Value scores8.6 ConclusionThe main positive outcome of our participation inTempEval-3 was that we were able to build a systemwith acceptable performance on Task A for Span-ish, after a relatively quick adaptation from an ex-isting English system.
Recall was the bottleneckof such an experiment, while precision figures didnot drop significantly, and Normalization accuracyeven increased for Spanish9, suggesting that a devel-oper may be able to iteratively add language-specificrules so as to reduce false negatives, without endan-gering overall system precision.A major flaw of our finite-state, local parsing ap-proach is in recognizing event-anchored time ex-pressions.
In order to address this, our timex recog-nition rules must be further tuned to the TimeML7Tense figures are unofficial, as we did not manage to ex-port this attribute value because of a bug in the submitted sys-tem.
However, we were able to reproduce the evaluation on afixed system.8We do not have independent performance figures of thetimex-event mapping, although this mechanism was invariableacross the two languages.9Due to low F1 for timex entity extraction.standard in order to fully isolate temporal signals,and event detection recall must be significantly in-creased so as to cover event nominalizations.
Thedetection of event referring expressions accordingto the general, context-independent definition inTimeML is not our main research target, howeverwe plan to use statistical classification methods toincrease the performance on this task as this is aprerequisite to achieve a reliable evaluation of ourevent-timex mapping heuristic.
Event Tense extrac-tion should be increased with the same purpose.AcknowledgmentsMany thanks to Maud Ehrmann for several usefuldiscussions on the ontology of temporal entities andthe TimeML standard.ReferencesTomaz Erjavec.
2004.
MULTEXT -East Morphosyntactic Specifications.URL:http://nl.ijs.si/ME/V3/msd/html/.Silja Huttunen, Roman Yangarber, and Ralph Grishman.2002.
Diversity of Scenarios in Information Extrac-tion.
Proceedings of the Third International Confer-ence On Language Resources And Evaluation, LasPalmas.Matteo Negri.
2007.
Dealing with Italian Temporal Ex-pressions: The ITA-Chronos System.
Proceedings ofEVALITA 2007, Workshop held in conjunction withAI*IA 2007.62Piskorski, Jakub.
2007.
ExPRESS Extraction Pat-tern Recognition Engine and Specification Suite.
InIn Proceedings of the International Workshop Finite-State Methods and Natural language Processing 2007(FSMNLP2007), Postdam, Germany.Piskorski, Jakub.
2008.
CORLEONE Core Linguis-tic Entity Online Extraction.
Technical Report, EN23393, Joint Research Center of the European Com-mission, Ispra, Italy.James Pustejovsky, Jos M. Castao, Robert Ingria, RoserSauri, Robert J. Gaizauskas, Andrea Setzer, GrahamKatz, and Dragomir R. Radev.
2003.
TimeML: Ro-bust Specification of Event and Temporal Expressionsin Text.
In Mark T. Maybury, editor New Directions inQuestion Answering, pages 2834.
AAAI Press, 2003.Pustejovsky, J., P. Hanks, R. Sauri, A.
See, R.Gaizauskas, A. Setzer, D. Radev, B. Sundheim, D.Day, L. Ferro, et al2003.
The TimeBank corpus.In Corpus Linguisticsvolume 2003, 40.Steinberger Ralf, Bruno Pouliquen & Erik van der Goot.2009.
An introduction to the Europe Media MonitorFamily of Applications.
In Fredric Gey, Noriko Kando& Jussi Karlgren (eds.
): Information Access in a Mul-tilingual World - Proceedings of the SIGIR 2009 Work-shop (SIGIR-CLIR?2009), pp.1-8.Tanev Hristo, Piskorski Jakub, Atkinson Martin.2008.
Real-Time News Event Extraction forGlobal Crisis Monitoring.
In Proceedings of NLDB2008,2008:207218.Hristo Tanev and Vanni Zavarella.
in press.
Multilin-gual Learning and Population of Event Ontologies.
ACase Study for Social Media.
In Paul Buitelaar andPhilipp Cimiano editors Towards the Multilingual Se-mantic Web, Springer.Naushad UzZaman, Hector Llorens, James F. Allen,Leon Derczynski, Marc Verhagen, James Pustejovsky.2012.
TempEval-3: Evaluating Events, Time Expres-sions, and Temporal Relations.
arXiv:1206.5333v1.Verhagen, M., R. Sauri, T. Caselli, and J. Pustejovsky2010.
SemEval-2010 task 13: TempEval-2.
In Pro-ceedings of the 5th International Workshop on Seman-tic Evaluation, 5762, Association for ComputationalLinguistics.63
