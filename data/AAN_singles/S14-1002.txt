Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 12?21,Dublin, Ireland, August 23-24 2014.Generating a Word-Emotion Lexicon from #Emotional TweetsAnil Bandhakavi1Nirmalie Wiratunga1Deepak P2Stewart Massie11IDEAS Research Institute, Robert Gordon University, Scotland, UK2IBM Research - India, Bangalore, India{a.s.bandhakavi,n.wiratunga}@rgu.ac.ukdeepaksp@acm.org, s.massie@rgu.ac.ukAbstractResearch in emotion analysis of text sug-gest that emotion lexicon based featuresare superior to corpus based n-gram fea-tures.
However the static nature of thegeneral purpose emotion lexicons makethem less suited to social media analysis,where the need to adopt to changes in vo-cabulary usage and context is crucial.
Inthis paper we propose a set of methods toextract a word-emotion lexicon automati-cally from an emotion labelled corpus oftweets.
Our results confirm that the fea-tures derived from these lexicons outper-form the standard Bag-of-words featureswhen applied to an emotion classificationtask.
Furthermore, a comparative analysiswith both manually crafted lexicons anda state-of-the-art lexicon generated usingPoint-Wise Mutual Information, show thatthe lexicons generated from the proposedmethods lead to significantly better classi-fication performance.1 IntroductionEmotion mining or affect sensing is the compu-tational study of natural language expressions inorder to quantify their associations with differentemotions (e.g.
anger, fear, joy, sadness and sur-prise).
It has a number of applications for the in-dustry, commerce and government organisations,but uptake has arguably been slow.
This in part isdue to the challenges involved with modelling sub-jectivity and complexity of the emotive content.However, use of qualitative metrics to captureemotive strength and extraction of features fromthese metrics has in recent years shown promise(Shaikh, 2009).
A general-purpose emotion lexi-con (GPEL) is a commonly used resource that al-lows qualitative assessment of a piece of emotivetext.
Given a word and an emotion, the lexiconprovides a score to quantify the strength of emo-tion expressed by that word.
Such lexicons arecarefully crafted and are utilised by both super-vised and unsupervised algorithms to directly ag-gregate an overall emotion score or indirectly de-rive features for emotion classification tasks (Mo-hammad, 2012a), (Mohammad, 2012b).Socio-linguistics suggest that social media is apopular means for people to converse with individ-uals, groups and the world in general (Boyd et al.,2010).
These conversations often involve usage ofnon-standard natural language expressions whichconsistently evolve.
Twitter and Facebook werecredited for providing momentum for the 2011Arab Spring and Occupy Wall street movements(Ray, 2011),(Skinner, 2011).
Therefore efforts tomodel social conversations would provide valu-able insights into how people influence each otherthrough emotional expressions.
Emotion analysisin such domains calls for automated discovery oflexicons.
This is so since learnt lexicons can in-tuitively capture the evolving nature of vocabularyin such domains better than GPELs.In this work we show how an emotion la-belled corpus can be leveraged to generate a word-emotion lexicon automatically.
Key to this is theavailability of a labelled corpus which may be ob-tained using a distance-supervised approach to la-belling (Wang et al., 2012).
In this paper we pro-pose three lexicon generation methods and evalu-ate the quality of these by deploying them in anemotion classification task.
We show through ourexperiments that the word-emotion lexicon gener-ated using the proposed methods in this paper sig-nificantly outperforms GPELs such as WordnetAf-fect, NRC word-emotion association lexicon and aleaxicon learnt using Point-wise Mutual Informa-tion (PMI).
Additionally, our lexicons also outper-form the traditional Bag-of-Words representation.The rest of the paper is organised as follows: In12Section 2 we present the related work.
In Section3 we outline the problem.
In Section 4 we for-mulate the different methods proposed to generatethe word-emotion lexicons.
In Section 5 we dis-cuss experimental results followed by conclusionsand future work in Section 6.2 Related WorkComputational emotion analysis, draws from cog-nitive and physiology studies to establish the keyemotion categories; and NLP and text mining re-search to establish features designed to representemotive content.
Emotion analysis has been ap-plied in a variety of domains: fairy tales (Fran-cisco and Gervas, 2006; Alm et al., 2005);blogs (Mihalcea and Liu, 2006; Neviarouskaya etal., 2010), novels (John et al., 2006), chat mes-sages (E.Holzman and William M, 2003; Ma etal., 2005; Mohammad and Yang, 2011) and emo-tional events on social media content(Kim et al.,2009).
Comparative studies on emotive word dis-tributions on micro-blogs and personal content(e.g.
love letters, suicide notes) have shown thatemotions such as disgust are expressed well intweets.
Further, expression of emotion in tweetsand love letters have been shown to have similari-ties(K. Roberts and Harabagiu, 2012).Emotion classification frameworks provide in-sights into human emotion expressions (Ekman,1992; Plutchik, 1980; Parrott, 2001).
The emo-tions proposed by (Ekman, 1992) are popular inemotion classification tasks (Mohammad, 2012b;Aman and Szpakowicz, 2008).
Recently there hasalso been interest in extending this basic emo-tion framework to model more complex emotions(such as politeness, rudeness, deception, depres-sion, vigour and confusion) (Pearl and Steyvers,2010; Bollen et al., 2009).
A common themeacross these approaches involves the selectionof emotion-rich features and learning of relevantweights to capture emotion strength (Mohammad,2012a; Qadir and Riloff, 2013).Usefulness of a lexicon: Lexicons such asWordnet Affect (Strapparava and Valitutti, 2004)and NRC (Saif M. Mohammad, 2013)) arevery valuable resources from which emotionfeatures can be derived for text representation.These are manually crafted and typically con-tain emotion-rich formal vocabulary.
Hybrid ap-proaches that combine features derived from thesestatic lexicons with n-grams have resulted in bet-ter performance than either alone (Mohammad,2012b),(Aman and Szpakowicz, 2008).
Howeverthe informal and dynamic nature of social me-dia content makes it harder to adopt these lexi-cons for emotion analysis.
An alternative strategyis to derive features from a dynamic (i.e., learnt)lexicon.
Here association metrics such as Point-wise Mutual Information (PMI) can be used tomodel emotion polarity between a word and emo-tion labelled content (Mohammad, 2012a).
Suchapproaches will be used as baselines to compareagainst our proposed lexicon generation strategies.There are other lexicon generation methods pro-posed by Rao .et.
al (Yanghui Rao and Chen,2013) and Yang .et.
al (Yang et al., 2007).
We donot consider these in our comparative evaluationsince these methods require rated emotion labelsand emoticon classes respectively.Lexicon generation, relies on the availability ofa labelled corpus from which the word-emotiondistributions can be discovered.
For this pur-pose we exploit a distance-supervised approachwhere indirect cues are used to unearth implicit(or distant) labels that are contained in the cor-pus (Alec Go and Huang, 2009).
We adoptthe approach as in (Wang et al., 2012) to cor-pus labelling where social media content, and inparticular Twitter content is sampled for a pre-defined set of hashtag cues (P. Shaver, 1987) .Here each set of cues represent a given emotionclass.
Distant-supervision is particularly suited toTwitter-like platforms because people use hash-tags to extensively convey or emphasis the emo-tion behind their tweets (e.g., That was my bestweekend ever.#happy!!
#satisfied!).
Also giventhat tweets are length restricted (140 characters),modelling the emotional orientation of words ina Tweet is easier compared to longer documentsthat are likely to capture complex and mixed emo-tions.
This simplicity and access to sample datahas made Twitter one of the most popular domainsfor emotion analysis research (Wang et al., 2012;Qadir and Riloff, 2013).3 Problem DefinitionWe now outline the problem formally.
We startwith a set of documents D = {d1, d2, .
.
.
, dn}where each document dihas an associated labelCdiindicating the emotion class to which dibe-longs.
We consider the case where the documentsare tweets.
For example, a tweet dinice sunday13#awesome may have a label joy indicating that thetweet belongs to the joy emotion class.
We also as-sume that the labels Cdicome from a pre-definedset of six emotion classes anger, fear, joy, sad, sur-prise, love.
Since our techniques are generic anddo not depend on the number of emotion classes,we will denote the emotion classes as {Cj}Nj=1.Let there be K words extracted from the trainingdocuments, denoted as {wi}Ki=1.
Our task is to de-rive a lexiconLex that quantifies the emotional va-lence of words (from the tweets in D) to emotionclasses.
In particular, the lexicon may be thoughtof as a 2d-associative array where Lex[w][c] indi-cates the emotional valence of the word w to theemotion class c. When there is no ambiguity, wewill use Lex(i, j) to refer to the emotional valenceof word wito the emotion class Cj.
We will quan-tify the goodness of the lexicons that are generatedusing various methods by measuring their perfor-mance in an emotion classification task.4 Lexicon Generation MethodsWe now outline the various methods for lexicongeneration.
We first start off with a simple tech-nique for learning lexicons based on just term fre-quencies (which we will later use as a baselinetechnique), followed by more sophisticated meth-ods that are based on conceptual models on howtweets are generated.4.1 Term Frequency based LexiconA simple way to measure the emotional valence ofthe word wito the emotion class Cjis to computethe probability of occurrence of wiin a tweet la-belled as Cj, normalized by its probability acrossall classes.
This leads to:Lex(i, j) =p(wi|Cj)?Nk=1p(wi|Ck)(1)where the conditional probability is simplycomputed using term frequencies.p(wi|Cj) =freq(wi, Cj)freq(Cj)(2)where freq(wi, Cj) is the number of timeswioccurs in documents labeled with class Cj.freq(Cj) is the total number of documents in Cj.4.2 Iterative methods for Lexicon GenerationThe formulation in the previous section generatesa word-emotion matrix L by observing the termfrequencies within a class.
However term frequen-cies alone do not capture the term-class associa-tions, because not all frequently occurring termsexhibit the characteristics of a class.
For exam-ple, a term sunday that occurs in a tweet nice sun-day #awesome labelled joy is evidently not indica-tive of the class joy; however, the frequency basedcomputation increments the weight of sunday wrtthe class joy by virtue of this occurrence.
In thefollowing sections, we propose generative modelsthat seek to remedy such problems of the simpleterm frequency based lexicon.4.2.1 Generative models for DocumentsAs discussed above, though a document is labelledwith an emotion class, not all terms relate stronglyto the labelled emotion.
Some documents mayhave terms conveying a different emotion thanwhat the document is labelled with, since the la-bel is chosen based on the most prominent emo-tion in the tweet.
Additionally, some words couldbe emotion-neutral (e.g., sunday in our exampletweet) and could be conveying non-emotional in-formation.
We now describe two generative mod-els that account for such considerations, and thenoutline methods to learn lexicons based on them.Mixture of Classes Model: Let LCkbe theunigram language model (Liu and Croft, 2005)that expresses the lexical character for the emotionclass Ck; though microblogs are short text frag-ments, language modeling approaches have beenshown to be effective in similarity assesment be-tween them (Deepak and Chakraborti, 2012).
Wemodel a document dito be generated from acrossthe emotion class language models:1.
For each word wjin document di,(a) Lookup the unit vector [?
(1)dij, .
.
.
, ?
(N)dij];This unit vector defines a probabilitydistribution over the language models.
(b) Choose a language model L fromamong the K LMs, in accordance withthe vector(c) Samplewjin accordance with the multi-nomial distribution LIf diis labelled with the emotion class Cdi, it islikely that the value of ?
(n)dijis high for words in disince it is likely that majority of the words are sam-pled from the LCdilanguage model.
The posteriorprobability in accordance with this model can thenbe intuitively formulated as:14P (di, Cdi|?)
=?wj?diN?x=1?(x)dij?
LCx(wj) (3)where ?
is the parameters {LCj}Nj=1, ?
and Cdiis the class label for document di.Class and Neutral Model: We now introduceanother model where the words in a document areassumed to be sampled from either the languagemodel of the corresponding (i.e., labelled) emo-tion class or from the neutral language model, LC.Thus, the generative model for a document dila-belled with emotion classCdiwould be as follows:1.
For each word wjin document di,(a) Lookup the weight ?dij; this parameterdetermines the mix of the labelled emo-tion class and the neutral class, for wjindi(b) Choose LCkwith a probability of ?dij,and LCwith a probability of 1.0?
?dij(c) Samplewjin accordance with the multi-nomial distribution of the chosen lan-guage modelThe posterior probability in accordance withthis model can be intuitively formulated as :P (di, Cdi|?)
=?wj?di?dij?
LCdi(wj)+ (1?
?dij)?
LC(wj)(4)where ?
is the parameters {LCj}Nj=1, LC, ?
.Equation 3 models a document to exhibit char-acteristics of many classes with different levelsof magnitude.
Equation 4 models a document tobe a composition of terms that characterise oneclass and other general terms; a similar formula-tion where a document is modeled using a mix oftwo models has been shown to be useful in charac-terizing problem-solution documents (Deepak etal., 2012; Deepak and Visweswariah, 2014).
Thecentral idea of the expectation maximization (EM)algorithm is to maximize the probability of thedata, given the language models {LCj}Nj=1andLC.
The term weights are estimated from the lan-guage models (E-step) and the language modelsare re-estimated (M-step) using the term weightsfrom the E-step.
Thus the maximum likelihoodestimation process in EM alternates between theE-step and the M-step.
In the following sectionswe detail the EM process for the two generativemodels separately.
We compare and contrast thetwo variants of the EM algorithm in Table 1.4.2.2 EM with Mixture of Classes ModelWe will use a matrix based representation for thelanguage model and the lexicon, to simplify the il-lustration of the EM steps.
Under the matrix nota-tion, L(p)denotes theK?N matrix at the pthiter-ation where the ithcolumn is the language modelcorresponding to the ithclass, i.e., LCi.
The pthE-step estimates the various ?dijvectors for all doc-uments based on the language models in L(p?1),whereas the M-step re-learns the language modelsbased on the ?
values from the E-step.
The stepsare detailed as follows:E-Step: The ?
(n)dijis simply estimated to thefractional support for the jthword in the ithdocu-ment (denoted as wij) from the nthclass languagemodel:?
(n)dij=L(p?1)Cn(wij)?xL(p?1)Cx(wij)(5)M-Step: As mentioned before in Table 1 thisstep learns the language models from the ?
esti-mates of the previous step.
As an example, if awordw is estimated to have come from the joy lan-guage model with a weight (i.e., ?)
0.5, it wouldcontribute 0.5 as its count to the joy languagemodel.
Thus, every occurrence of a word is splitacross language models using their corresponding?
estimates:L(p)Cn[w] =?i?jI(wij= w)?
?(n)dij?i?j?
(n)dij(6)where the indicator function I(wij= w) evalu-ates to 1 if wij= w is satisfied and 0 otherwise.After any M-Step, the lexicon can be obtainedby normalizing the L(p)language models so thatthe weights for each word adds up to 1.0. i.e.,Lex(p)(i, j) =L(p)Cj[wi]?Kx=1L(p)Cx[wi](7)In the above equation, the suffix (i, j) refers tothe ithword in the jthclass, confirming to our 2d-array representation of the language models.15Table 1: EM Algorithm variantsStates EM with mixture of classes model EM with class and neutral modelINPUT Training data T Training data TOUTPUT Word-Emotion Lexicon Word-Emotion LexiconInitialisation Learn the initial language models{LCj}Nj=1Learn the initial language models{LCj}Nj=1and LCConvergence While not converged or #Iterations< ?, a thresholdWhile not converged or #Iterations< ?, a thresholdE-step Estimate the ?dijs based on thecurrent estimate of {LCj}Nj=1(Sec4.2.2)Estimate ?dijbased on the currentestimate of {LCj}Nj=1and LC(Sec4.2.3)M-step Estimate the language models{LCj}Nj=1using ?dijs (Sec 4.2.2)Estimate the language models{LCj}Nj=1and LCusing ?dij(Sec4.2.3)Lexicon Induction Induce a word-emotion lexiconfrom {LCj}Nj=1(Sec 4.2.2)Induce a word-emotion lexiconfrom {LCj}Nj=1and LC(Sec 4.2.3)4.2.3 EM with Class and Neutral ModelThe main difference in this case, when comparedto the previous is that we need to estimate a neutrallanguage model LCin addition to the class spe-cific models.
We also have fewer parameters tolearn since the ?dijis a single value rather than avector of N values as in the previous case.E-Step: ?dijis estimated to the relative weightof the wordwijfrom across the language model ofthe corresponding class, and the neutral model:?dij=L(p?1)Cdi(wij)L(p?1)Cdi(wij) + L(p?1)C(wij)(8)Where Cdidenotes the class corresponding tothe label of the document di.M-Step: In a slight contrast from the M-Stepfor the earlier case as shown in Table 1, a wordestimated to have a weight (i.e., ?
value) of 0.2would contribute 20% of its count to the cor-responding class?
language model, while the re-maining would go to the neutral language modelLC.
Since the class-specific and neutral languagemodels are estimated differently, we have two sep-arate equations:L(p)Cn[w] =?i,label(di)=Cn?jI(wij= w)?
?dij?i,label(di)=Cn?j?dij(9)L(p)C[w] =?i?jI(wij= w)?
(1.0?
?dij)?i?j(1.0?
?dij)(10)where label(di) = CnAs is obvious, the class-specific language models are contributed to bythe documents labelled with the class whereas theneutral language model has contributions from alldocuments.
The normalization to achieve the lexi-con is exactly the same as in the mixture of classescase, and hence, is omitted here.4.2.4 EM InitializationIn the case of iterative approaches like EM, the ini-tialization is often considered crucial.
In our case,we initialize the unigram class language modelsby simply aggregating the scores of the words intweets labelled with the respective class.
Thus, thejoy language model would be the initialized to bethe maximum likelihood model to explain the doc-uments labelled joy.
In the case of the class andneutral generative model, we additionally buildthe neutral language model by aggregating countsacross all the documents in the corpus (regardlessof what their emotion label is).5 ExperimentsIn this section we detail our experimental evalu-ation.
We begin with the details about the Twit-ter data used in our experiments.
We then dis-cuss how we created the folds for a cross valida-tion experiment.
Thereafter we detail the classifi-16cation task used to evaluate the word-emotion lex-icon.
Finally we discuss the performance of ourproposed methods for lexicon generation in com-parison with other manually crafted lexicons, PMIbased method for lexicon generation and the stan-dard BoW in an emotion classification task.5.1 Twitter DatasetThe data set used in our experiments was a corpusof emotion labelled tweets harnessed by (Wang etal., 2012).
The data set was available in the formof tweet ID?s and the corresponding emotion la-bel.
The emotion labels comprised namely : anger,fear, joy, sadness, surprise, love and thankfulness.We used the Twitter search API1to obtain thetweets by searching with the corresponding tweetID.
After that we decided to consider only tweetsthat belong to the primary set of emotions definedby Parrott (Parrott, 2001).
The emotion classes inour case included anger, fear, joy, sadness, sur-prise and love.
We had a collection of 0.28 mil-lion tweets which we used to carry out a 10 foldcross-validation experiment.We decided to generate the folds manually,inorder to compare the performance of the differ-ent algorithms used in our experiments.
We splitthe collection of 0.28 million tweets into 10 equalsize sets to generate 10 folds with different train-ing and test sets in each fold.
Also all the folds inour experiments were obtained by stratified sam-pling, ensuring that we had documents represent-ing all the classes in both the training and test sets.We used the training data in each fold to generatethe word-emotion lexicon and measured the per-formance of it on the test data in an emotion clas-sification task.
Table 2 shows the average distri-bution of the different classes namely: anger, fear,joy, sadness, surprise and love over the 10 folds.Observe that emotions such as joy and sadness hada very high number of representative documents.
Emotions such as anger,love and fear were thenext most represented emotions.
The emotion sur-prise had very few representative documents com-pared to that of the other emotions.5.2 Evaluating the word-emotion lexiconWe adopted an emotion classification task in orderto evaluate the quality of the word-emotion lexi-con generated using the proposed methods.
Alsoresearch in emotion analysis of text suggest that1https://dev.twitter.com/docs/using-searchTable 2: Average distribution of emotions acrossthe foldsEmotion Training TestAnger 58410 6496Fear 13692 1548Joy 74108 8235Sadness 63711 7069Surprise 2533 282Love 31127 3464Total 243855 27095lexicon based features were effective compared tothat of n-gram features in an emotion classifica-tion of text (Aman and Szpakowicz, 2008; Mo-hammad, 2012a).
Therefore we decided to use thelexicon to derive features for text representation.We followed a similar procedure as in (Moham-mad, 2012a) to define integer valued features fortext representation.
We define one feature for eachemotion to capture the number of words in a train-ing/test document that are associated with the cor-responding emotion.
The feature vector for a train-ing/test document was constructed using the word-emotion lexicon.
Given a training/test documentd we construct the corresponding feature vectord?=< count(e1), count(e2), .
.
.
, count(em)) >of length m (in our case m is 6), whereincount(ei) represents the number of words in d thatexhibit emotion ei.
count(ei) is computed as:count(ei) =?w?dI( maxj=1,...,mLex(w, j) = Ci)(11)where I(.
.
.)
is the indicator function as usedpreviously.
For example if a document has 1 joyword, 2 love words and 1 surprise word the featurevector for the document would be (0, 0, 1, 0, 1, 2).We used the different lexicon generation methodsdiscussed in sections 4.1, 4.2.2 and 4.2.3 to con-struct the feature vectors for the documents.
In thecase of the lexicon generated as in section 4.2.3the max in equation 11 is computed over m + 1columns.
We also used the lexicon generationmethod proposed in (Mohammad, 2012a) to con-struct the feature vectors.
PMI was used in (Mo-hammad, 2012a) to generate a word-emotion lexi-con which is as follows :Lex(i, j) = logfreq(wi, Cj) ?
freq(?Cj)freq(Cj) ?
freq(wi,?Cj)(12)17where freq(wi, Cj) is the number of times n-gram wioccurs in a document labelled with emo-tion Cj, freq(wi,?Cj) is the number of times n-gram wioccurs in a document not labelled withemotion Cj.
freq(Cj) and freq(?Cj) are thenumber of documents labelled with emotion Cjand ?Cjrespectively.Apart from the aforementioned automaticallygenerated lexicons we also used manually craftedlexicons such as WordNet Affect (Strapparava andValitutti, 2004) and the NRC word-emotion as-sociation lexicon (Saif M. Mohammad, 2013) toconstruct the feature vectors for the documents.Unlike the automatic lexicons, the general purposelexicons do not offer numerical scores.
There-fore we looked for presence/absence of words inthe lexicons to obtain the feature vectors.
Fur-thermore we also represented documents in thestandard BoW representation.
We performed fea-ture selection using the metric Chisquare2, to se-lect the top 500 features to represent documents.Since tweets are very short we incorporated a bi-nary representation for BoW instead of term fre-quency.
For classification we used a multiclassSVM classifier3and all the experiments were con-ducted using the data mining software Weka2.
Weused standard metrics such as Precision, Recalland F-measure to compare the performance of thedifferent algorithms.
In the following section weanalyse the experimental results for TF-lex (Sec4.1), EMallclass-lex (Sec 4.2.2), EMclass-corpus-lex (Sec 4.2.3), PMI-lex (Mohammad, 2012a),WNA-lex (Strapparava and Valitutti, 2004), NRC-lex (Saif M. Mohammad, 2013) and BoW in anemotion classification task.
Also in the case ofEM based methods we experimented with differ-ent threshold limits ?
shown in Table 1.
We reportthe results only w.r.t ?
= 1 due to space limitations.5.3 Results and AnalysisTable 3 shows the F-scores obtained for differ-ent methods for each emotion.
Observe that theF-score for each emotion shown in Table 3 for amethod is the average F-score obtained over the10 test sets (one per fold).
We carried a two tailpaired t-test4between the baselines and our pro-posed methods to measure statistical significancefor performance on the test set in each fold.
From2http://www.cs.waikato.ac.nz/ml/weka/3http://www.csie.ntu.edu.tw/ cjlin/liblinear/4http://office.microsoft.com/en-gb/excel-help/ttest-HP005209325.aspxthe t-test we observed that our proposed methodsare statistically significant over the baselines witha confidence of 95% (i.e with p value 0.05).
Alsonote that the best results obtained for an emotionare highlighted in bold.
It is evident from the re-sults that the manually crafted lexicons Wornd-net Affect and the NRC word-emotion associationlexicon are significantly outperformed by all theautomatically generated lexicons for all emotions.Also the BoW model significantly outperforms themanually crafted lexicons suggesting that theselexicons are not sufficiently effective for emotionmining in a domain like Twitter.When compared with BoW the PMI-lex pro-posed by (Mohammad, 2012a) achieves a 2% gainw.r.t emotion love, a 0.6% gain w.r.t emotion joyand 1.28% gain w.r.t emotion sadness.
Howeverin the case of emotions such as fear and sur-prise BoW achieves significant gains of 11.17%and 20.96% respectively.
The results suggest thatthe PMI-lex was able to leverage the availabilityof adequate training examples to learn the pat-terns about emotions such as anger, joy, sadnessand love.
However given that not all emotions arewidely expressed a lexicon generation method thatrelies heavily on abundant training data could beineffective to mine less represented emotions.Now we analyse the results obtained for the lex-icons generated from our proposed methods andcompare them with BoW and PMI-lex.
Fromthe results obtained for our methods in Table 3it suggests that our methods achieve the best F-scores for 4 emotions namely anger, fear, sad-ness and love out of the 6 emotions.
In par-ticular the EM-class-corpus-lex method obtainsthe best F-score for 3 emotions namely anger,sadness and love.
When compared with BoWand PMI-lex, EM-class-corpus-lex obtains a gainof 0.85% and 0.93% respectively w.r.t emotionanger, 1.85% and 0.57% respectively w.r.t emo-tion sadness, 18.67% and 16.88% respectivelyw.r.t emotion love.
Our method TF-lex achieves again of 5.47% and 16.64% respectively over BoWand PMI-lex w.r.t emotion fear.
Furthermore w.r.temotion surprise all our proposed methods outper-form PMI-lex.
However BoW still obtains the bestF-score for emotion surprise.When we compared the results between ourown methods EM-class-corpus-lex obtains thebest F-scores for emotions anger, joy, sadness andlove.
We expected that modelling a document18Table 3: Emotion classification resultsMethod Average F-ScoreAnger Fear Joy Sadness Surprise LoveBaselinesWNA-lex 25.82% 6.61% 12.94% 8.76% 0.76% 2.67%NRC-lex 21.37% 3.97% 16.04% 8.87% 1.54% 7.22%Bow 56.5% 13.56% 63.34% 50.57% 21.65% 20.52%PMI-lex 56.42% 2.39% 63.4% 50.57% 0.69% 22.31%Our Learnt LexiconsTF-lex 55.85% 19.03% 62.01% 50.54% 11.29% 37.69%EMallclass-lex 56.64% 14.53% 61.89% 50.48% 12.33% 38.13%EMclass-corpus-lex 57.35% 16.1% 62.74% 51.14% 12.05% 39.19%to exhibit more than one emotion (EM-allclass-lex) would better distinguish the class boundaries.However given that tweets are very short it wasobserved that modelling a document as a mixtureof emotion terms and general terms (EM-class-corpus-lex) yielded better results.
However we ex-pect EM-allclass-lex to be more effective in otherdomains such as blogs, discussion forums whereinthe text size is larger compared to tweets.Table 4 summarizes the overall F-scores ob-tained for the different methods.
Note that theF-scores shown in Table 4 are the average over-all F-scores over the 10 test sets.
Again we con-ducted a two tail paired t-test4between the base-lines and our proposed methods to measure theperformance gains.
It was observed that all ourproposed methods are statistically significant overthe baselines with a confidence of 95% (i.e withp value 0.05).
In Table 4 we italicize all our bestperforming methods and highlight in bold the bestamong them.
From the results it is evident that ourproposed methods obtain significantly better F-scores over all the baselines with EM-class-corpusachieving the best F-score with a gain of 3.21%,2.9%, 39.03% and 38.7% over PMI-lex, BoW,WNA-lex and NRC-lex respectively.
Our findingsreconfirm previous findings in the literature thatemotion lexicon based features improve over cor-pus based n-gram features in a emotion classifica-tion task.
Also our findings suggest that domainspecific automatic lexicons are significantly betterover manually crafted lexicons.6 Conclusions and Future WorkWe proposed a set of methods to automatically ex-tract a word-emotion lexicon from an emotion la-belled corpus.
Thereafter we used the lexicons toTable 4: Overall F-scoresMethod Avg Overall F-scoreBaselinesWNA-lex 13.17%NRC-lex 13.50%Bow 49.30%PMI-lex 48.99%Our automatic lexiconsTF-lex 51.45%EMallclass-lex 51.38%EMclass-corpus-lex 52.20%derive features for text representation and showedthat lexicon based features significantly outper-form the standard BoW features in the emotionclassification of tweets.
Furthermore our lexiconsachieve significant improvements over the generalpurpose lexicons and the PMI based automaticlexicon in the classification experiments.
In fu-ture we intend to leverage the lexicons to designdifferent text representations and also test themon emotional content from other domains.
Auto-matically generating human-interpretable models(e.g., (Balachandran et al., 2012)) to accompanyemotion classifier decisions is another interestingdirection for future work.ReferencesRicha Bhayani Alec Go and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.Processing.Cecilia Ovesdotter Alm, Dan Roth, and RichardSproat.
2005.
Emotions from text: machine learn-ing for text-based emotion prediction.
In Proceed-19ings of the conference on Human Language Tech-nology and Empirical Methods in Natural LanguageProcessing, HLT ?05, pages 579?586, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.S.
Aman and S. Szpakowicz.
2008.
Using roget?s the-saurus for fine-grained emotion recognition.
In In-ternational Joint Conference on Natural LanguageProcessing.Vipin Balachandran, Deepak P, and Deepak Khemani.2012.
Interpretable and reconfigurable clusteringof document datasets by deriving word-based rules.Knowl.
Inf.
Syst., 32(3):475?503.Johan Bollen, Alberto Pepe, and Huina Mao.
2009.Modelling public mood and emotion : Twitter senti-ment and socio-economic phenomena.
In CoRR.Danah Boyd, Scott Golder, and Gilad Lotan.
2010.Tweet, tweet, retweet: Conversational aspects ofretweeting on twitter.
In Proceedings of the 201043rd Hawaii International Conference on SystemSciences, Washington, DC, USA.P.
Deepak and Sutanu Chakraborti.
2012.
Finding rel-evant tweets.
In WAIM, pages 228?240.P.
Deepak and Karthik Visweswariah.
2014.
Unsu-pervised solution post identification from discussionforums.
In ACL.P.
Deepak, Karthik Visweswariah, Nirmalie Wiratunga,and Sadiq Sani.
2012.
Two-part segmentation oftext documents.
In CIKM, pages 793?802.Lars E.Holzman and Pottenger William M. 2003.Classification of emotions in internet chat : Anapplication of machine learning using speechphonemes.
Technical report, Technical report,Leigh University.Paul Ekman.
1992.
An argument for basic emotions.Cognition and Emotion, 6(3):169?200.Virginia Francisco and Pablo Gervas.
2006.
Auto-mated mark up of affective information in englishtext.
Text, Speech and Dialouge, volume 4188 ofLecture Notes in Computer Science:375?382.David John, Anthony C. Boucouvalas, and Zhe Xu.2006.
Representing emotinal momentum within ex-pressive internet communication.
In In Proceed-ings of the 24th IASTED international conference onInternet and multimedia systems and applications,pages 183-188, Anaheim, CA, ACTA Press.J.
Johnson J. Guthrie K. Roberts, M.A.
Roach and S.M.Harabagiu.
2012.
?empatweet: Annotating and de-tecting emotions on twitter?,.
In in Proc.
LREC,2012, pp.3806-3813.Elsa Kim, Sam Gilbert, J.Edwards, and Erhardt Graeff.2009.
Detecting sadness in 140 characters: Senti-ment analysis of mourning of michael jackson ontwitter.Xiaoyong Liu and W Bruce Croft.
2005.
Statisticallanguage modeling for information retrieval.
Tech-nical report, DTIC Document.Chunling Ma, Helmut Prendinger, and MitsuruIshizuka.
2005.
Emotion estimation and reasoningbased on affective textual interaction.
In First In-ternational Conference on Affective Computing andIntelligent Interaction (ACII-2005), pages 622-628,Beijing, China.Rada Mihalcea and Hugo Liu.
2006.
A corpus-basedapproach for finding happiness.
In In AAAI-2006Spring Symposium on Computational Approaches toAnalysing Weblogs, pages 139-144.
AAAI press.Saif M. Mohammad and Tony Yang.
2011.
Trackingseniment in mail : How genders differ on emotionalaxes.
In In Proceedings of the 2nd Workshop onComputational Approaches to Subjectivity and Sen-timent Analysis(WASSA 2011), pages 70- 79, Port-land, Oregon.
Association for Computational Lin-guistics.Saif Mohammad.
2012a.
#emotional tweets.
InThe First Joint Conference on Lexical and Compu-tational Semantics ?
Volume 1: Proceedings of themain conference and the shared task, and Volume 2:Proceedings of the Sixth International Workshop onSemantic Evaluation (SemEval 2012).Saif M. Mohammad.
2012b.
Portable features for clas-sifying emotional text.
In Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 587-591, Montreal , Canada.Alena Neviarouskaya, Helmut Prendinger, and Mit-suru Ishizuka.
2010.
Recognition of affect, judg-ment, and appreciation in text.
In Proceedings of the23rd International Conference on ComputationalLinguistics, COLING ?10, pages 806?814, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.D.
Kirson P. Shaver, J. Schwartz.
1987.
Emotionknowledge: Further exploration of a prototype ap-proach.
Journal of Personality and Social Psychol-ogy, Vol 52 no 6:1061 ?
1086.W Parrott.
2001.
Emotions in social psychology.
Psy-chology Press, Philadelphia.Lisa Pearl and Mark Steyvers.
2010.
Identifying emo-tions, intentions and attitudes in text using a gamewith a purpose.
In In Proceedings of the NAACL-HLT 2010 Workshop on Computational Approachesto Analysis and Generation of Emotion in Text, LosAbgeles, California.R.
Plutchik.
1980.
A general psychoevolutionary the-ory of emotion.
In R. Plutchik & H.
Kellerman(Eds.
), Emotion: Theory, research, and experience:,Vol.
1.
Theories of emotion (pp.
3-33).
New York:Academic:(pp.
3?33).20Ashequl Qadir and Ellen Riloff.
2013.
Bootstrappedlearning of emotion hashtahs #hashtags4you.
InIn the 4th Workshop on Computational Approachesto Subjectivity, Sentiment & Social Media Analysis(WASSA 2013).Tapas Ray.
2011.
The ?story?
of digital excess in rev-olutions of the arab spring.
Journal of Media Prac-tice, 12(2):189?196.Peter D. Turney Saif M. Mohammad.
2013.
Crowd-sourcing a word-emotion association lexicon.
Com-putational Intelligence, 29 (3), 436-465, WileyBlackwell Publishing Ltd, 2013, 29(3):436?465.Prendinger H. Ishizuka M. Shaikh, M.A.M., 2009.
ALinguistic Interpretation of the OCC Emotion Modelfor Affect Sensing from Text, chapter 4, pages 45?73.Julia Skinner.
2011.
Social media and revolu-tion: The arab spring and the occupy movementas seen though three information studies paradigms.Sprouts: Working papers on Information Systems,11(169).Carlo Strapparava and Alessandro Valitutti.
2004.Wordnet-affect: an affective extension of wordnet.Technical report, ITC-irst, Istituto per la RicercaScienti?ca e Tecnologica I-38050 Povo Trento Italy.Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,and Amit P. Sheth.
2012.
Harnessing twitter ?bigdata?
for automatic emotion identification.
In Pro-ceedings of the 2012 ASE/IEEE International Con-ference on Social Computing and 2012 ASE/IEEE.C.
Yang, K. H. Y. Lin, and H. H. Chen.
2007.
Emo-tion classification using web blog corpora.
In Pro-ceedings of the IEEE/WIC/ACM International Con-ference on Web Intelligence, WI ?07, pages 275?278,Washington, DC, USA.
IEEE Computer Society.Liu Wenyin Qing Li Yanghui Rao, Xiaojun Quan andMingliang Chen.
2013.
Building word-emotionmapping dictionary for online news.
In In Pro-ceedings of the 4th Workshop on Computational Ap-proaches to Subjectivity, Sentiment and Social Me-dia Analysis, WASSA 2013.21
