CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 33?40Manchester, August 2008Transforming Meaning Representation Grammars to Improve SemanticParsingRohit J. KateDepartment of Computer Sciences?The University of Texas at Austin1 University Station C0500Austin, TX 78712-0233, USArjkate@cs.utexas.eduAbstractA semantic parser learning system learnsto map natural language sentences intotheir domain-specific formal meaning rep-resentations, but if the constructs of themeaning representation language do notcorrespond well with the natural languagethen the system may not learn a good se-mantic parser.
This paper presents ap-proaches for automatically transforming ameaning representation grammar (MRG)to conform it better with the natural lan-guage semantics.
It introduces grammartransformation operators and meaning rep-resentation macros which are applied in anerror-driven manner to transform an MRGwhile training a semantic parser learningsystem.
Experimental results show that theautomatically transformed MRGs lead tobetter learned semantic parsers which per-form comparable to the semantic parserslearned using manually engineered MRGs.1 IntroductionSemantic parsing is the task of converting naturallanguage (NL) sentences into their meaning repre-sentations (MRs) which a computer program canexecute to perform some domain-specific task, likecontrolling a robot, answering database queriesetc.
These MRs are expressed in a formal mean-ing representation language (MRL) unique to thedomain to suit the application, like some specificcommand language to control a robot or some?Alumnus at the time of submission.?c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.query language to execute database queries.
A ma-chine learning system for semantic parsing takesNL sentences paired with their respective MRs astraining data and induces a semantic parser whichcan then map novel NL sentences into their MRs.The grammar of an MRL, which we will callmeaning representation grammar (MRG), is as-sumed to be deterministic and context-free whichis true for grammars of almost all the computerexecutable languages.
A semantic parsing learn-ing system typically exploits the given MRG of theMRL to learn a semantic parser (Kate andMooney,2006; Wong and Mooney, 2006).
Although in dif-ferent ways, but the systems presented in these pa-pers learn how the NL phrases relate to the pro-ductions of the MRG, and using this informationthey parse a test sentence to compositionally gen-erate its best MR.
In order to learn a good seman-tic parser, it is necessary that the productions ofthe MRG accurately represent the semantics be-ing expressed by the natural language.
However,an MRL and its MRG are typically designed tobest suit the application with little considerationfor how well they correspond to the semantics ofa natural language.Some other semantic parser learning systemswhich need MRL in the form of Prolog (TangandMooney, 2001) or ?-calculus (Zettlemoyer andCollins, 2007; Wong and Mooney, 2007) do notuse productions of the MRG but instead use pred-icates of the MRL.
However, in order to learn agood semantic parser, they still require that thesepredicates correspond well with the semantics ofthe natural language.
There are also systems whichlearn semantic parsers from more detailed train-ing data in the form of semantically augmentedparse trees of NL sentences in which each inter-nal node has a syntactic and a semantic label (Ge33(a) NL: If the ball is in our midfield then player 5 should go to (-5,0).MR: (bpos (rec (pt -32 -35)(pt 0 35))(do (player our {5})(pos (pt -5 0))))(b) NL: Which is the longest river in Texas?MR: answer(longest(river(loc_2(stateid(?Texas?
)))))(c) NL: Which is the longest river in Texas?MR: select river.name from river whereriver.traverse=?Texas?
and river.length=(select max(river.length) from riverwhere river.traverse=?Texas?
);Figure 1: Examples of NL sentences and their MRs from(a) the CLANG domain (b) GEOQUERY domain with func-tional MRL (c) GEOQUERY domain with SQL.and Mooney, 2005; Nguyen et al, 2006).
For thesesystems to work well, it is also necessary that thesemantic labels of the MRL correspond well withnatural language semantics.If the MRG of a domain-specific MRL does notcorrespond well with natural language semanticsthen manually re-engineering the MRG to workwell for semantic parsing is a tedious task and re-quires considerable domain expertise.
In this pa-per, we present methods to automatically trans-form a given MRG to make it more suitable forlearning semantic parsers.
No previous work ad-dresses this issue to our best knowledge.
We intro-duce grammar transformation operators and mean-ing representation macros to transform an MRG.We describe how these are applied in an error-driven manner using the base semantic parsinglearning algorithm presented in (Kate andMooney,2006) resulting in a better learned semantic parser.Our approach, however, is general enough to im-prove any semantic parser learning system whichuses productions of the MRG.
We present exper-imental results with three very different MRLs toshow how these grammar transformations improvethe semantic parsing performance.2 BackgroundThe following subsection gives some examples ofsemantic parsing domains and their correspondingMRLs and illustrates why incompatibility betweenMRGs and natural language could hurt semanticparsing.
The next subsection then briefly describesa base semantic parser learning system which weuse in our experiments.2.1 MRLs and MRGs for Semantic ParsingFigure 1 (a) gives an example of a natural lan-guage sentence and its corresponding MR in anMRL called CLANG which is a formal declar-REGION?
( rec POINT POINT )POINT?
( pt NUM NUM )NUM?
-32 NUM?
-35POINT?
( pt NUM NUM )NUM?
0 NUM?
35Figure 2: The parse for the CLANG expression ?
(rec (pt-32 -35) (pt 0 35))?
corresponding to the natural language ut-terance ?our midfield?
using its original MRG.ative language with LISP-like prefix notationdesigned to instruct simulated soccer players inthe RoboCup1 Coach Competition.
The MRLand its MRG was designed by the Coach Com-petition community (Chen et al, 2003) to suitthe requirements of their application independentof how well the MRG conforms with the naturallanguage semantics.
They were, in fact, notaware that later (Kate et al, 2005) this will beintroduced as a test domain for learning semanticparsers.
In this original MRG for CLANG, thereare several constructs which do not correspondwell with their meanings in the natural language.For example, the MR expression of the rectangle(rec (pt -32 -35) (pt 0 35)) fromthe example MR in Figure 1 (a), whose parse ac-cording to the original MRG is shown in Figure 2,corresponds to the NL utterance ?our midfield?.
Inthe parse tree, the nodes are the MRG productionsand the tokens in upper-case are non-terminalsof the MRG while the tokens in lower-case areterminals of the MRG, this convention will beused throughout the paper.
As can be seen,the numbers as well as the productions in theparse of the MR expression do not correspond toanything in its natural language utterance.
It isalso impossible to derive a semantic parse treeof this MR expression over its natural languageutterance because there are not enough words init to cover all the productions present in the MRparse at the lowest level.
To alleviate this problem,the provided MRG was manually modified (Kateet al, 2005) to make it correspond better withthe natural language by replacing such long MRexpressions for soccer regions by shorter expres-sions like (midfield our)2.
This new MRGwas used in all the previous work which uses theCLANG corpus.
In the next sections of the paper,we will present methods to automatically obtain a1http://www.robocup.org2The names for the new tokens introduced were chosen forreadability and their similarity to the natural language wordsis inconsequential for learning semantic parsers.34(a) ANSWER?
answer ( RIVER )RIVER?
longest ( RIVER )RIVER?
river ( LOCATIONS )LOCATIONS?
loc 2 ( STATE )STATE?
STATEIDSTATEID?
stateid ( ?Texas?
)(b) ANSWER?
answer ( RIVER )RIVER?
QUALIFIER ( RIVER )QUALIFIER?
longest RIVER?
river ( LOCATIONS )LOCATIONS?
LOC 2 ( STATE)LOC 2?
loc 2 STATE?
STATEIDSTATEID?
stateid ( ?Texas?
)Figure 3: Different parse trees obtained for the MR?answer(longest(river(loc 2(stateid(?Texas?)))))?
correspond-ing to the NL sentence ?Which is the longest river in Texas?
?using (a) a simple MRG (b) a manually designed MRG.better MRG which corresponds well with the NLsemantics.Figure 1 (b) shows an NL sentence and its MRfrom the GEOQUERY domain (Zelle and Mooney,1996) which consists of a database of U.S. geo-graphical facts about which a user can query.
TheMRL used for GEOQUERY in some of the previ-ous work is a variable-free functional query lan-guage, that was constructed from the original MRsin Prolog (Kate et al, 2005).
From this MRL, theMRG was then manually written so that its pro-ductions were compatible with the semantics ex-pressible in natural language.
This MRG was dif-ferent from some simple MRG one would other-wise design for the MRL.
Figure 3 (a) shows theparse tree obtained using a simple MRG for theMR shown in Figure 1 (b).
The MR parse ob-tained using the simple MRG is more like a linearchain which means that in a semantic parse of theNL sentence each production will have to corre-spond to the entire sentence.
But ideally, differentproductions should correspond to the meanings ofdifferent substrings of the sentence.
Figure 3 (b)shows a parse tree obtained using the manually de-signed MRG in which the productions QUALIFIER?
longest and LOC 2 ?
loc 2 would correspond tothe semantic concepts of ?longest?
and ?locatedin?
that are expressible in natural language.Finally, Figure 1 (c) shows the same NL sen-tence from the GEOQUERY domain but the MRin SQL which is the standard database query lan-guage.
The inner expression finds the length of thelongest river in Texas and then the outer expres-sion finds the river in Texas which has that length.Due to space restriction, we are not showing theparse tree for this SQL MR, but its incompatibil-ity with the NL sentence can be seen from the MRitself because part of the query repeats itself with?Texas?
appearing twice while in the NL sen-tence everything is said only once.2.2 KRISP: A Semantic Parser LearningSystemWe very briefly describe the semantic parser learn-ing system, KRISP (Kate and Mooney, 2006),which we will use as a base system for transform-ing MRGs, we however note that the MRG trans-formation methods presented in this paper are gen-eral enough to work with any system which learnssemantic parser using MRGs.
KRISP (Kernel-based Robust Interpretation for Semantic Parsing)is a supervised learning system for semantic pars-ing which takes NL sentences paired with theirMRs as training data.
The productions of the MRGare treated like semantic concepts.
For each ofthese productions, a Support-Vector Machine clas-sifier is trained using string similarity as the ker-nel (Lodhi et al, 2002).
Each classifier can thenestimate the probability of any NL substring rep-resenting the semantic concept for its production.During semantic parsing, the classifiers are calledto estimate probabilities on different substrings ofthe sentence to compositionally build the mostprobable MR parse over the entire sentence withits productions covering different substrings of thesentence.
KRISP was shown to perform competi-tively with other existing semantic parser learningsystems and was shown to be particularly robust tonoisy NL input.3 Transforming MRGs Using OperatorsThis section describes an approach to transforman MRG using grammar transformation operatorsto conform it better with the NL semantics.
Thefollowing section will present another approachfor transforming an MRG using macros which issometimes more directly applicable.The MRLs used for semantic parsing are alwaysassumed to be context-free which is true for al-most all executable computer languages.
Therehas been some work in learning context-free gram-mars (CFGs) for a language given several exam-35ples of its expressions (Lee, 1996).
Most of theapproaches directly learn a grammar from the ex-pressions but there also have been approaches thatfirst start with a simple grammar and then trans-form it using suitable operators to a better gram-mar (Langley and Stromsten, 2000).
The goodnessfor a grammar is typically measured in terms of itssimplicity and coverage.
Langley and Stromsten(2000) transform syntactic grammars for NL sen-tences.
To our best knowledge, there is no previouswork on transforming MRGs for semantic parsing.For this task, since an initial MRG is always givenwith the MRL, there is no need to first learn it fromits MRs.
The next subsection describes the opera-tors our method uses to transform an initial MRG.The subsection following that then describes howand when the operators are applied to transform theMRG during training.
Our criteria for goodness ofan MRG is the performance of the semantic parserlearned using that MRG.3.1 Transformation OperatorsWe describe five transformation operators whichare used to transform an MRG.
Each of these op-erators preserves the coverage of the grammar,i.e.
after application of the operator, the trans-formed grammar generates the same language thatthe previous grammar generated3.
The MRs donot change but only the way they are parsed maychange because of grammar transformations.
Thisis important because the MRs are to be used in anapplication and hence should not be changed.1.
Create Non-terminal from a Terminal(CreateNT): Given a terminal symbol t in thegrammar, this operator adds a new productionT ?
t to it and replaces all the occurrences ofthe terminal t in all the other productions by thenew non-terminal T .
In the context of seman-tic parsing learning algorithm, this operator intro-duces a new semantic concept the previous gram-mar was not explicit about.
For example, this oper-ator may introduce a production (a semantic con-cept) LONGEST ?
longest to the simple grammarwhose parse was shown in Figure 3 (a).
This isclose to the production QUALIFIER?
longest of themanual grammar used in the parse shown in Fig-ure 3 (b).2.
Merge Non-terminals (MergeNT): This op-erator merges n non-terminals T1, T2, ..., Tn, byintroducing n productions T ?
T1, T ?
T2, ...,3This is also known as weak equivalence of grammars.T ?
Tnwhere T is a new non-terminal.
All theoccurrences of the merged non-terminals on theright-hand-side (RHS) of all the remaining produc-tions are then replaced by the non-terminal T .
Inorder to ensure that this operator preserves the cov-erage of the grammar, before applying it, it is madesure that if one of these non-terminals, say T1, oc-curs on the RHS of a production pi1then there alsoexist productions pi2, ..., pinwhich are same as pi1except that T2, ..., Tnrespectively occur in themin place of T1.
If this condition is violated for anyproduction of any of the n non-terminals then thisoperator is not applicable.
This operator enablesgeneralization of some non-terminals which occurin similar contexts leading to generalization of pro-ductions in which they occur on the RHS.
For ex-ample, this operator may generalize non-terminalsLONGEST and SHORTEST in GEOQUERY MRG toform QUALIFIER4 ?
LONGEST and QUALIFIER ?SHORTEST productions.3.
Combine Two Non-terminals (Combi-neNT): This operator combines two non-terminalsT1and T2into one new non-terminal T by intro-ducing a new production T ?
T1T2.
All theinstances of T1and T2occurring adjacent in thisorder on the RHS (with at least one more non-terminal5) of all the other productions are replacedby the new non-terminal T .
For example, the pro-duction A?
a B T1T2will be changed to A?
aB T .
This operator will not eliminate other occur-rences of T1and T2on the RHS of other produc-tions in which they do not occur adjacent to eachother.
In the context of semantic parsing, this op-erator adds an extra level in the MR parses whichdoes not seem to be useful in itself, but later ifthe non-terminals T1and T2get eliminated (by theapplication of the DeleteProd operator describedshortly), this operator will be combining the con-cepts represented by the two non-terminals.4.
Remove Duplicate Non-terminals (Re-moveDuplNT): If a production has the same non-terminal appearing twice on its RHS then this op-erator adds an additional production which differsfrom the first production in that it has only one oc-currence of that non-terminal.
For example, if aproduction is A ?
b C D C, then this operatorwill introduce a new production A ?
b C D re-4A system generated name will be given to the new non-terminal.5Without the presence of an extra non-terminal on theRHS, this change will merely add redundancy to the parsetrees using this production.36moving the second occurrence of the non-terminalC.
This operator is applied only when the subtreesunder the duplicate non-terminals of the produc-tion are often found to be the same in the parsetrees of the MRs in the training data.
As such thisoperator will change the MRL the new MRG willgenerate, but this can be easily reverted by appro-priately duplicating the subtrees in its generatedMR parses in accordance to the original produc-tion.
This operator is useful during learning a se-mantic parser because it eliminates the type of in-compatibility between MRs and NL sentences il-lustrated with Figure 1 (c) in Subsection 2.1.5.
Delete Production (DeleteProd): This lastoperator deletes a production and replaces the oc-currences of its left-hand-side (LHS) non-terminalwith its RHS in the RHS of all the other produc-tions.
In terms of semantic parsing, this operatoreliminates the need to learn a semantic concept.
Itcan undo the transformations obtained by the otheroperators by deleting the new productions they in-troduce.We note that the CombineNT and MergeNT op-erators are same as the two operators used by Lan-gley and Stromsten (2000) to search a good syntac-tic grammar for natural language sentences fromthe space of its possible grammars.
We also notethat the applications of CreateNT and CombineNToperators can reduce a CFG to its Chomsky nor-mal form6, and conversely, because of the reversetransformations achieved by the DeleteProd opera-tor, a Chomsky normal form of a CFG can be con-verted into any other CFG which accepts the samelanguage.3.2 Applying Transformation OperatorsIn order to transform an MRG to improve semanticparsing, since a simple hill-climbing type approachto search the space of all possible MRGs will becomputationally very intensive, we use the follow-ing error-driven heuristic search which is faster al-though less thorough.First, using the provided MRG and the trainingdata, a semantic parser is trained using KRISP.
Thetrained semantic parser is applied to each of thetraining NL sentences.
Next, for each production piin the MRG, two values totalpiand incorrectpiarecomputed.
The value totalpicounts how many MRparses from the training examples use the produc-6In which all the productions are of the form A ?
a orA?
B C.tion pi.
The value incorrectpicounts the numberof training examples for which the semantic parserincorrectly uses the production pi, i.e.
it either didnot include the production pi in the parse of the MRit produces when the correct MR?s parse includedit, or it included the production pi when it was notpresent in the correct MR?s parse.
These two statis-tics for a production indicate how well the seman-tic parser was able to use the production in seman-tic parsing.
If it was not able to use a production piwell, then the ratio incorrectpi/totalpi, which wecall mistakeRatiopi, will be high indicating thatsome change needs to be made to that production.After computing these values for all the produc-tions, the procedure described below for applyingthe first type of operator is followed.
After this,the MRs in the training data are re-parsed usingthe newMRG, the semantic parser is re-trained andthe totalpiand incorrectpivalues are re-computed.Next, the procedure for applying the next operatoris followed and so on.
The whole process is re-peated for a specified number of iterations.
In theexperiments, we found that the performance doesnot improve much after two iterations.1.
Apply CreateNT: For each terminal t in thegrammar, totaltand incorrecttvalues are com-puted by summing up the corresponding values forall the productions in which t occurs on the RHSwith at least one non-terminal7.
If totaltis greaterthan ?
(a parameter) and mistakeRatiot=incorrectt/totaltis greater than ?
(another pa-rameter), then the CreateNT operator is applied,provided the production T ?
t is not alreadypresent.2.
Apply MergeNT: All the non-terminals oc-curring on the RHS of all those productions pi arecollected whose mistakeRatiopivalue is greaterthan ?
and whose totalpivalue is greater than ?.The set of these non-terminals is then partitionedsuch that the criteria for applying the MergeNTis satisfied by the non-terminals in each partitionwith size at least two.
The MergeNT operator isthen applied to the non-terminals in each partitionwith size at least two.3.
Apply CombineNT: For every non-terminalpair T1and T2, totalT1T2and incorrectT1T2val-ues are computed by summing their correspond-ing values for the productions in which the twonon-terminals are adjacent in the RHS in the7Without a non-terminal on the RHS, the operator willonly add a redundant level to the parses which use this pro-duction.37presence of at least one more non-terminal.
IfmistakeRatioT1T2= incorectT1T2/totalT1T2isgreater than ?
and totalT1T2is greater than ?, thenthe CombineNT operator is applied to these twonon-terminals.4.
Apply RemoveDuplNT: If a productionpi has duplicate non-terminals on the RHS underwhich the same subtrees are found in the MR parsetrees of the training data more than once then thisoperator is applied provided its mistakeRatiopiisgreater than ?
and totalpiis greater than ?.5.
Apply DeleteProd: The DeleteProd opera-tor is applied to all the productions pi and whosemistakeRatiopiis greater than ?
and totalpiisgreater than ?.
This step simply deletes the pro-ductions which are mostly incorrectly used.For the experiments, we set the ?
parameter to0.75 and ?
parameter to 5, these values were de-termined through pilot experiments.4 Transforming MRGs Using MacrosAs was illustrated with Figure 2 in Subsection 2.1,sometimes there can be large parses for MR ex-pressions which do not correspond well with theirsemantics in the natural language.
While it is pos-sible to transform the MRG using the operatorsdescribed in the previous section to reduce a sub-tree of the parse to just one production which willthen correspond directly to its meaning in the nat-ural language, it will require a particular sequenceof transformation operators to achieve this whichmay rarely happen during the heuristic search usedin the MRG transformation algorithm.
In this sec-tion, we describe a more direct way of obtainingsuch transformations using macros.4.1 Meaning Representation MacrosA meaning representation macro for an MRG is aproduction formed by combining two or more ex-isting productions of the MRG.
For example, forthe CLANG example shown in Figure 2, the pro-duction REGION?
(rec(pt -32 -35)(pt 0 35)) is a mean-ing representation macro.
There could also be non-terminals on its RHS.
From an MR parse drawnwith non-terminals at the internal nodes (instead ofproductions), a macro can be derived from a sub-tree8 rooted at any of the internal nodes by makingits root as the LHS non-terminal and the left-to-right sequence formed by its leaves (which could8Each node of a subtree must either include all the chil-dren nodes of the corresponding node from the original treeor none of them.be non-terminals) as the RHS.
We use the follow-ing error-driven procedure to introduce macros inthe MRG in order to improve the performance ofsemantic parsing.4.2 Learning Meaning RepresentationMacrosA semantic parser is first learned from the train-ing data using KRISP and the given MRG.
Thelearned semantic parser is then applied to the train-ing sentences and if the system can not produceany parse for a sentence then the parse tree of itscorresponding MR is included in a set called failedparse trees.
Common subtrees in these failed parsetrees are likely to be good candidates for introduc-ing macros.
Then a set of candidate trees is cre-ated as follows.
This set is first initialized to theset of failed parse trees.
The largest common sub-tree of every pair of trees in the candidate trees isthen also included in this set if it is not an emptytree.
The process continues with the newly addedtrees until no new tree can be included.
This pro-cess is similar to the repeated bottom-up general-ization of clauses used in the inductive logic pro-gramming system GOLEM (Muggleton and Feng,1992).
Next, the trees in this set are sorted basedon the number of failed parse trees of which theyare a subtree.
The trees which are part of fewerthan ?
subtrees are removed.
Then in highest tolowest order, the trees are selected one-by-one toform macros, provided their height is greater thantwo (otherwise it will be an already existing MRGproduction) and an already selected tree is not itssubtree.
A macro is formed from a tree by mak-ing the non-terminal root of the tree as its LHSnon-terminal and the left-to-right sequence of theleaves as its RHS.These newly formed macros (productions) arethen included in the MRG.
The MRs in the train-ing data are re-parsed and the semantic parser isre-trained using the new MRG.
In order to deletethe macros which were not found useful, a pro-cedure similar to the application of DeleteProd isused.
The totalpiand incorrectpivalues for all themacros are computed in a manner similar to de-scribed in the previous section.
The macros forwhich mistakeRatiopi= totalpi/incorrectpiisgreater than ?
and totalpiis greater than ?
are re-moved.
This whole procedure of adding and delet-ing macros is repeated a specified number of it-erations.
In the experiments, we found that two38304050607080901000  10  20  30  40  50  60  70  80  90  100PrecisionRecallManual grammarTransformed grammarInitial grammarFigure 4: The results comparing the performances of thelearned semantic parsers on the GEOUQERY domain with thefunctional query language using different MRGs.304050607080901000  10  20  30  40  50  60  70  80  90  100PrecisionRecallTransformed grammarInitial grammarFigure 5: The results comparing the performances ofthe learned semantic parsers on the GEOUQERY domain withSQL as the MRL using different MRGs.iterations are usually sufficient.5 ExperimentsWe tested our MRG transformation methods withMRGs of three different MRLs which were de-scribed in the Background section.
In each case,we first transformed the given MRG using macrosand then using grammar transformation operators.The training and testing was done using standard10-fold cross-validation and the performance wasmeasured in terms of precision (the percentage ofgenerated MRs that were correct) and recall (thepercentage of all sentences for which correct MRswere obtained).
Since we wanted to evaluate howthe grammar transformation changes the perfor-mance on the semantic parsing task, in each ofthe experiments, we used the same system, KRISP,and compared how it performs when trained usingdifferent MRGs for the same MRL.
Since KRISPassigns confidences to the MRs it generates, an en-tire range of precision-recall trade-off was plottedby measuring precision and recall values at variousconfidence levels.Figure 4 shows the results on the GEOQUERYdomain using the functional query language whose304050607080901000  10  20  30  40  50  60  70  80  90  100PrecisionRecallManual grammarTransformed grammarInitial grammarFigure 6: The results comparing the performances of thelearned semantic parsers on the CLANG corpus using differentMRGs.corpus contained total 880 NL-MR pairs.
As canbe seen, the performance of the semantic parserthat KRISP learns when trained using the initialsimple MRG for the MRL is not good.
Butwhen that MRG is transformed, the performanceof the semantic parser dramatically improves andis very close to the performance obtained with themanually-engineered grammar.
The macro trans-formations did not help improve the performancewith this MRG, and most of the the performancegain was obtained because of the CreateNT andDeleteProd operators.We next tested our MRG transformation algo-rithm on SQL as the MRL for the GEOQUERY do-main.
This corpus contains 700 NL-MR pairs inwhich the NL sentences were taken from the orig-inal 880 examples.
This corpus was previouslyused to evaluate the PRECISION system (Popescuet al, 2003), but since that system is not a machinelearning system, its results cannot be directly com-pared with ours.
The initial MRG we used con-tained the basic SQL productions.
Figure 5 showsthat results improve by a large amount after MRGtransformations.
We did not have any manually-engineered MRG for SQL for this domain avail-able to us.
With this MRG, most of the improve-ment was obtained using the macros and the Re-moveDuplNT transformation operator.Finally, we tested our MRG transformation al-gorithm on the CLANG domain using its origi-nal MRG in which all the chief regions of thesoccer field were in the form of numeric MR ex-pressions which do not correspond to their mean-ings in the natural language.
Its corpus contains300 examples of NL-MR pairs.
Figure 6 showsthe results.
After applying the MRG transforma-tions the performance improved by a large margin.The gain was due to transformations obtained us-39ing macros while the grammar transformation op-erators did not help with this MRG.
Although theprecision was lower for low recall values, the re-call increased by a large quantity and the best F-measure improved from 50% to 63%.
But the per-formance still lagged behind that obtained usingthe manually-engineered MRG.
The main reasonfor this is that the manual MRG introduced somedomain specific expressions, like left, right,left-quarter etc., which correspond directlyto their meanings in the natural language.
Onthe other hand, the only way to specify ?left?
ofa region using the original CLANG MRG is byspecifying the coordinates of the left region, like(rec(pt -32 -35)(pt 0 0)) is the left of(rec (pt -32 -35) (pt 0 35)) etc.
Itis not possible to learn the concept of ?left?
fromsuch expressions even with MRG transformations.6 ConclusionsAmeaning representation grammar which does notcorrespond well with the natural language seman-tics can lead to a poor performance by a learnedsemantic parser.
This paper presented grammartransformation operators and meaning representa-tion macros using which the meaning representa-tion grammar can be transformed to make it betterconform with the semantics of natural language.Experimental results on three different grammarsdemonstrated that the performance on semanticparsing task can be improved by large amounts bytransforming the grammars.AcknowledgmentsI would like to thank Raymond Mooney for manyuseful discussions regarding the work described inthis paper.ReferencesChen et al 2003.
Users manual: RoboCup soccer server manual for soc-cer server version 7.07 and later.
Available at http://sourceforge.net/projects/sserver/.Ge, R. and R. J. Mooney.
2005.
A statistical semantic parser that integratessyntax and semantics.
In Proc.
of CoNLL-2005, pages 9?16, Ann Arbor,MI.Kate, R. J. and R. J. Mooney.
2006.
Using string-kernels for learning se-mantic parsers.
In Proc.
of COLING/ACL-2006, pages 913?920, Sydney,Australia.Kate, R. J., Y. W.Wong, and R. J. Mooney.
2005.
Learning to transform naturalto formal languages.
In Proc.
of AAAI-2005, pages 1062?1068, Pittsburgh,PA.Langley, Pat and Sean Stromsten.
2000.
Learning context-free gramamr with asimplicity bias.
In Proc.
of ECML-2000, pages 220?228, Barcelona, Spain.Lee, Lillian.
1996.
Learning of context-free languages: A survey of the lit-erature.
Technical Report TR-12-96, Center for Research in ComputingTechnology, Harvard University.Lodhi, Huma, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and ChrisWatkins.
2002.
Text classification using string kernels.
Journal of MachineLearning Research, 2:419?444.Muggleton, Stephen and C. Feng.
1992.
Efficient induction of logic programs.In Muggleton, Stephen, editor, Inductive Logic Programming, pages 281?297.
Academic Press, New York.Nguyen, Le-Minh, Akira Shimazu, and Xuan-Hieu Phan.
2006.
Semanticparsing with structured SVM ensemble classification models.
In Proc.
ofCOLING/ACL 2006 Main Conf.
Poster Sessions, pages 619?626, Sydney,Australia.Popescu, Ana-Maria, Oren Etzioni, and Henry Kautz.
2003.
Towards a theoryof natural language interfaces to databases.
In Proc.
of IUI-2003, pages149?157, Miami, FL.Tang, L. R. and R. J. Mooney.
2001.
Using multiple clause constructors in in-ductive logic programming for semantic parsing.
In Proc.
of ECML-2001,pages 466?477, Freiburg, Germany.Wong, Y. W. and R. Mooney.
2006.
Learning for semantic parsing with statis-tical machine translation.
In Proc.
of HLT/NAACL-2006, pages 439?446,New York City, NY.Wong, Y. W. and R. J. Mooney.
2007.
Learning synchronous grammars forsemantic parsing with lambda calculus.
In Proc.
of ACL-2007, pages 960?967, Prague, Czech Republic.Zelle, J. M. and R. J. Mooney.
1996.
Learning to parse database queries usinginductive logic programming.
In Proc.
of AAAI-1996, pages 1050?1055,Portland, OR.Zettlemoyer, Luke S. and Michael Collins.
2007.
Online learning of relaxedCCG grammars for parsing to logical form.
In Proc.
of EMNLP-CoNLL-2007, pages 678?687, Prague, Czech Republic.40
