Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1293?1298,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsRecognizing Social Constructs from Textual ConversationSomak Aditya and Chitta Baral and Nguyen H. Vo and Joohyung Lee and Jieping Ye,Zaw Naung and Barry Lumpkin and Jenny HastingsDept.
of Computer Science, Arizona State UniversityRichard ScherlDept.
of Computer Science,Monmouth UniversityDawn M. SweetDept.
of Psychology,Iowa State UniversityDaniela InclezanDept.
of Computer Science,Miami UniversityAbstractIn this paper we present our work on rec-ognizing high level social constructs such asLeadership and Status from textual conversa-tion using an approach that makes use of thebackground knowledge about social hierarchyand integrates statistical methods and sym-bolic logic based methods.
We use a stratifiedapproach in which we first detect lower levellanguage constructs such as politeness, com-mand and agreement that help us to infer inter-mediate constructs such as deference, close-ness and authority that are observed betweenthe parties engaged in conversation.
These in-termediate constructs in turn are used to de-termine the social constructs Leadership andStatus.
We have implemented this systemsuccessfully in both English and Korean lan-guages and achieved considerable accuracy.1 Introduction and Related WorksThe traditional information extraction paradigm hasseen success in extracting simplistic behaviors oremotions from text.
However, to detect high-levelsocial constructs such as leadership or status, we re-quire robustly defined notions about language con-structs that cannot always be directly inferred fromtext.
Hence, in this paper we focus on extractinginformation from text that requires additional back-ground knowledge and inference.
There are a fewworks in this direction, such as (Tari et al, 2010),however our focus in this paper is to extract infor-mation pertaining to different social constructs fromtextual conversation.
The earlier research in ana-lyzing conversations includes developing annotatedchat corpuses (Shaikh et al, 2010), and developinga socio-cultural phenomena model from discoursewith a small-scale implementation (Strzalkowski etal., 2010).
Other researchers have focused on auto-matically annotating social behavior in conversationusing statistical approaches (Mayfield et al, 2013).The discourse structure of a conversation is modeledas a Hidden Markov Model in (Stolcke, 2000) to de-termine dialogue acts such as Statement, Questionand Agreement.
In (Prabhakaran et al, 2012) an-notated email threads are presented for facilitatingdetection of social relations.Among recent works, (Gilbert, 2012) uses lin-guistic cues to discover workplace hierarchy fromemails.
The use of phrases to detect language usesuch as ?commands?
is motivating.
However, dueto the lack of logical explanation and robust defi-nition, the effectiveness of this method decreases inthe semi-formally moderated Wikipedia community,which has interplay of several different LUs suchas command, politeness and informal language.
In(Danescu-Niculescu-Mizil et al, 2012), the authorsexplain how reflection of linguistic styles can shedlight on power differentials; though, a social com-munity like Wikipedia might not always conform tothe lingustic style coordination assumption.
For ex-ample, two friends who are coordinating on writingan article may have the same status socially, but dif-ference in their expertise will drive the conversation.Other works such as (Gupte et al, 2011) have con-centrated more on other features of the persons in-volved in social network, than linguistic cues.
Also,we feel that, the hierarchy depends on the task orthe context.
In other words, one person could as-1293sume different roles in different context.
The aboveworks do not seem to address this.
(Prabhakaran etal., 2012) achieves a commendable accuracy in de-tecting overt display of ?power?.
However, by ourdefinitions, this is a lower level attribute and is sim-ilar to authoritative behavior which is a lower levelconcept than Leadership or Status.
Hence, their re-sults are not directly comparable to ours.In this paper, we use a mixture of logic-based andstatistical approaches which better encodes the do-main knowledge and infers higher-level constructsfrom indirect textual cues.
The aim of this paper isto formalize the theory behind our work, highlightthe advantages of integration of statistical and logic-based approaches and present results from an empir-ical study.2 Motivation by a use-caseWe start our discussion by presenting a use-case andexplain how results of other traditional methods in-spired us to come up with an integrated approach.Consider the following conversation fromWikipedia where the participants discuss about amisleading animation that is used under the topicConvolution.
{D: Put a message on the talk page of the guy whomade it.
You?re right; g(t) should be g(tau - t), and(f*g)(t) should be (f*g)(tau).T: I don?t think he has a talk page.
He?s provided thecode so I can reproduce it.
I think he?s right with (f*g)(t),though?D: Actually, I think we?re both wrong.
You need a vari-able of integration running opposite directions ....T: I?ve updated ...
I guess it?s not important, but wouldbe kind of cool.
Feel free to suggest improvements to theanimations.
}As we understand, these conversations suggest thatparticipant D is supposed to hold a higher rank/statusthan T .
If we analyze manually, we understand thatphrases like Put a message, You?re right, I think we?reboth wrong together supports our conclusion.
Consid-ered separately, the above phrases might be misleading.To conclude the example, our system outputs :D has a higher status than T because D demonstratesmore language uses associated with status than T. Confi-dence: high.The above example illustrates the degree of context-sensitivity of our problem.
The current statistical liter-ature suggests methods such as Decision Trees, Boost-ing methods comprising of a collection of Weak classi-fiers (basically rules) and probabilistic generative models(Medhat et al, 2014), (Hutto and Gilbert, 2014), (Vanzoet al, 2014) and (Saif et al, 2012).
While their accuracyon some datasets is quite satisfactory, it is not clear howwell they do on completely unseen data.From our experience on such classifiers, we believethat a higher level of accuracy with explainability canbe achieved by imposing a structure that encodes back-ground knowledge about the social hierarchy that is ob-served in nature.
With this motivation, we built a systemwhose hierarchical architecture robustly defines the so-cial constructs, the ?hidden?
concepts that induce themand their inter-connections.
We define notions of inter-mediate Language Use (LU) and lower level LanguageIndicator (LI) categories1.
With the help of these ro-bust definitions, our system properly explains how dif-ferent emotions and behaviors interact to express statusand leadership among individuals.3 Social ConstructsOur framework supports determination of various impor-tant Social Constructs such as Leadership, Status, GroupCohesion and Sub-Group Formation.
However, due tothe length constraints of the paper, we will only discussLeadership and Status.3.1 Definitions and ArchitectureWe begin by first formally defining the two Social Con-structs and the different Language Use categories.Leadership: A leader is someone who guides a grouptoward outcomes, controls the group actions, manages in-teractions between members and members usually recog-nize the leader.Status: Status is defined as the social position of oneperson with respect to another in a group.The principal Language Use categories that we detectare: Deference, Closeness, Authoritative Behavior andMotivational Behavior.
The following intuitions are usedto infer such LUs from text:Deference is understood when one uses language thatshows respect to another conversational participant or de-fers to another?s expertise or knowledge or authority.Closeness is understood when one uses language thatshows familiarity with another conversationalist.
It is alsoindicated by dialogues where conversationalists refer tosimilar events, experiences etc.Authoritative Behavior is understood when one useslanguage that shows power, dominance and control overa situation.Motivational Behavior is understood when one useslanguage that moves conversational participants toward1These definitions were proposed as part of the IARPASocio-Cultural Content In Language(SCIL) program.1294Social  ConstructsLanguage  UsesLanguage  IndicatorsLeader StatusDeference Closeness Authority Behavior Motivational BehaviorPoliteness Respectful AppellationApologetic Behavior Indexical StatementsInformal Language Command ExpertiseNegative ExpertiseAgenda SettingAgreementDisagreementExplanation: Means that either the presence or absence of A contributes  to B ABAB Means that only the presence of A indicates BSeeking SupportImpolitenessEncouragementPraiseCriticismResource AllocationInformal AddressFigure 1: Social Construct-Language Use-Language In-dicator hierarchy for English Languagesharing a common goal, collaboration, problem solvingand solidarity.In Figure 1, we present the entire hierarchy and how thecategories are connected among each other.
The arrowsin the figure show which of the LI categories are used toinfer a particular type of LU.
It also demonstrates howeach of the LU contributes to the Social Constructs.4 Behind the Curtain: Our IntuitionsOne of the fundamental contributions in this paper is for-mally describing the hierarchy to determine the SocialConstructs, as shown in Figure 1.
To come up with theseinterconnections and each of the different pieces of thepuzzle, we went through an iterative process of discus-sions with many social scientists and linguists to analyzea large number of example conversations.
In this process,we came up with the aforementioned hierarchy, defini-tions of SC, LU and LIs and most importantly, the fol-lowing understanding:?
The Language Indicators as shown in the Figure 1,suffice for the detection of Leadership and Status.?
Each detected LI is associated with an IntensityLevel that helps us to encode the dissimilar effectsof different words in inferring LIs.?
Each LI is associated with a Signed Language Use.For example, the LI politeness is associated with thesigned LU positive deference.?
Indicators of an LU with a certain sign are counter-indicators of the same LU with the opposite sign.?
A signed LU may contribute either favorably orunfavorably towards its associated SC.
For exam-ple, positive authoritative behavior contributes fa-vorably towards higher status.?
The signed LUs that contribute towards the SC Sta-tus are ordered based on their importance.
We as-sume the following ordering exists: authoritativebehavior > motivational behavior > negative defer-ence > positive deference in the opposite direction> closeness.
However, we do not assume such anordering for the SC Leadership.Our extensive research and successful implementation ofour system for different natural languages leads us to be-lieve that these notions are universal in application.5 Fundamentals of the implementationAfter we parse each sentence using Stanford Dependencyparser to get the POS tags and mutual dependencies, thedetection of individual LIs and the mapping of LIs, LUsto SCs are achieved using a combination of statistical andlogic based approach.
Many of the ideas and insightsabout the detection of LIs and their relations with the LUsare motivated from (Simon, 1946), (Pennebaker et al,2003) , (Bernstein, 2010) , (Brown and Levinson, 1988)and a few others.
Some of our ideas for textual inferencehave been inspired by (Scherl et al, 2010).5.1 Determining the Language IndicatorsThe process of detection of language indicators from sen-tences uses a huge ensemble of complex rules.
To createthese rules, we borrowed ideas from the researchers of so-cial science and psychology (Simon, 1946; Pennebaker etal., 2003).With the help of POS tags, mutual dependencies andregular expressions, we create a framework where we de-tect individual events, verbs, other sentence constituentsand their positive and negative sense.
On top of thisframework, we use two different methods to detect lan-guage indicators.
The ideas are similar for all the LIs.
Wewill only present a few examples for the LI ?Command?.5.1.1 Using Regular Expressions AloneWe use regular expressions of theform ?.
*\b[wW]hy don?
?t (you|YOU)(start|read|submit|make|write|get)\s*\b.*?
to detectLIs such as ?Command?.
We employ a collection of suchexpressions to cover several different linguistic styleswhich indicates ?Command?
by an individual.We achieved a very high recall (close to 1.0) for mostindicators with these rules on test data.
However, in fewcases, the frequency of such indicators (such as polite-ness) were very low deeming the set of regular expres-sions as incomplete.
This observation led us to refine theregular expressions with Logical rules so that we can in-corporate our domain knowledge and remove such biasto the training set.12955.1.2 Using Logical rules on RegularExpression output and SentenceconstituentsOne example of the rules we use to detect ?Command?is: if the subject of the verb is second person and the verbis associated with a modal verb which indicates a ques-tion that suggests command, then the LI ?Command?
isdetected.Examples of such verbs are ?Would you?
and ?Couldyou?
etc.
It is to be noted that such a verb will denoteboth politeness and command depending on the rest ofthe sentence.
This fascinating inter-dependency is onereason why we have to collect all such Language Indica-tors before we infer the higher level Language Uses.5.2 Mapping of LIs to LUs and LUs to SocialConstructsInput: To encode one conversation we use a collectionof facts of the form participant(X) and addresses(X, Y,LI, Level).These facts essentially encode the identity of the par-ticipants and the Language Indicators observed in theoverall conversation among a pair of participants.Output: The module outputs a collection of claim, ev-idence and confidence mappings.For example one such mapping is: claim_mapping(X,"is the leader", "because", X, "demonstrates <languageuse>","(Confidence: <confidence level>)").
Here <lan-guage use> is one of the language uses, <confidencelevel> is either low, medium, or high.Algorithm: We employ statistical and logic-basedprocedure in parallel to get the above output.
On thestatistical side, we adopt a regression technique to learna function that can map the scores associated with LIsto individual LUs based on annotated training data andthis function is then applied to test data to get confidencescore on LUs.
The same procedure is adopted for map-ping LUs to SCs.In parallel to this procedure, we also employ a rule-based technique that uses quantized confidence scoresand outputs confidence levels along with explanations.As we are able to get the explanation from logical rea-soning, we use the output confidence scores as votes fromstatistical learning to output the final confidence level.The rules for logical reasoning are explained as defini-tions and intuitions in the following paragraphs.Mapping LIs into LUs: A signed LU is said to beexhibited by participant X towards participant Y with acertain degree of confidence based on the number of in-dicators(LI) and counter-indicators(LI) of the signed LUused by X when addressing Y.
The confidence in LU isdirectly proportional to the difference between the num-ber of indicators and counter-indicators.We categorize LUs according to the number of indi-cators and apply slight variation to the above rules foreach such category.
Also, there are a few LIs that, whenused, automatically override the computed confidencelevel for an LU and increase it to high.
For example,?criticism?
increases confidence level of positive ?moti-vational behavior?
to high.Mapping LUs to SCs: The relative status of two par-ticipants is determined based on i) the number of rele-vant signed LUs exhibited by each participant towardsthe other, ii) the ordering of relevant signed LUs and iii)the confidence level in each exhibited signed LU.The leader is determined based on the number of ex-hibited relevant LUs (both favorable and unfavorable).Mapping LIs to SCs: As shown in Figure 1, we di-rectly associate some of the LIs to Social Constructs.
Forsuch an association, we again adopt the regression tech-nique mentioned previously.
In this case, the confidencescores from LIs are directly mapped to the confidencescores of SCs.
We combine this confidence with theabove confidence levels using simplistic rules to outputfinal social constructs.It should be noted that the constants used in the rulesare obtained from statistics on annotated conversations.The annotation process involves labels about SCs, LUsand LIs for each conversation data.5.3 Brief Details and Results of the RegressionTechniqueIn this sub-section, we provide few details of the SparseLogistic Regression technique we have used alongsidethe logical formulation and present few results from ourexperiments with relevant statistical methods.
We haveused a similar formulations for mapping LIs to LUs andLUs to SCs.
Here, we provide the example of formulat-ing the entire problem of detection of Social Constructsdirectly in the Classification paradigm.Status and Leadership can be formulated as a three-class and two-class problem respectively.
For Status,we had 102 samples with the 38(higher), 26(equal) and38(lower) samples each for three classes.
For Lead-ership, we had 149 samples with 108(not-leader) and41(leader) samples for the two classes.
For both the tasks,we extracted 28 textual features.
We used the one-vs-restscheme for multi-class problem.
For each task, we eval-uated the framework as follows: i.
First, we randomlyseparate the dataset into training set(p) and test set(1-p).ii.
In the training set, we use 10-fold cross validation toselect proper parameters.
iii.
We iterate the above proce-dure for 100 times, and accuracy is evaluated on the pre-dictions in all iterations.
iv.
We select different p (from0.25 to 0.9) and observe the change of accuracy.We compared the accuracy achieved using Sparse Lo-gistic Regression with SVM(with RBF Kernel) among1296(a) (b)Figure 2: (a) Training set percentage vs Accuracy graphfor Leadership problem, (b) Training set percentage vsAccuracy graph for Status classification problem.others.
The accuracy comparison of the SVM(with RBFkernel) and sparse Logistic Regression is provided in Fig-ure 2.
As we can observe, though the two methods arecomparable, in most cases Sparse Logistic regression per-forms better.5.4 Advantages from the integrated approachThe primary advantages are the following:In general, statistical approaches need a ?lot of data?to attain a certain level of accuracy.
As the rules we useare quite universal and compact, we can achieve a com-parable(or higher) accuracy with much less training data.Using the evidence and claim mappings, we give an?explanation?
as to why we detected such a particular SCin the dialogue.
Knowldege of such depth is very hard toachieve with only statistical approaches.Explicit representation of ?context?
specific informa-tion via rules results in improved accuracy in detection ofLIs such as criticism, praise, command etc.Statistical modules complement the rule-based ap-proach where our domain knowledge is ?incomplete?.We use ASP as the Logic Programming language ofour choice as its ability to represent defaults and excep-tions eases the implementation procedure.6 ResultsWe have implemented this system using ASP(Gelfondand Lifschitz, 1988) and Java.
The Wikipedia con-versations are obtained by parsing the wiki dump fromhttp://dumps.wikimedia.org/.
We also evalu-ated on the NWTRB (US Nuclear Waste Technical Re-view Board) dataset.
The accuracy and F1 measure aresummarized in Table 1 for approximately two thousandEnglish and one thousand Korean Wikipedia conversa-tions.
We evaluated two types of questions - i. Yes-Noindicates questions like Is John the leader?
and ii.
Listindicates questions such as List all the leaders.. Our workis perhaps unique in determining such social constructsand evaluating on familiar and unfamiliar datasets.
TableTable 1: ResultsSC Q-Type Language Accuracy F1Task Leader Y-N EN 0.8900 0.6700Task Leader List EN 0.6700 0.9900Status Y-N EN 0.4700 0.3457Status List EN 0.6923 0.5200Task Leader Y-N KO 0.5667 0.4338Status Y-N KO 0.4074 0.39001 reports evaluations on wikipedia dump.
These valuesare computed by comparing the results of our systemswith annotated data.
Note, in our experiments, we haveperformed strict evaluations.
For example, the resultsare only marked positive if the complete list of leadersmatches with a human-annotated list.
Also, we considerthe ?explanation?
too while performing the evaluation.The results are true positive only when the detected con-struct is correct alongwith the explanation provided bythe reasoning module.
In general, the previous researchachieves an accuracy of 0.45 in comparable tasks such asdialog act tagging (Stolcke, 2000).7 ConclusionIn this paper, we have proposed a novel approach for log-ically recognizing social constructs from textual conver-sations.
We have used both statistical classification andlogical reasoning to robustly detect status and leadershipas observed in virtual social networks.
From our exper-iments, we show empirically how our approach achievesa significant accuracy and provides logical explanation ofconstruct detection.This research shows the merits of using logical rulesalong with statistical techniques to determine Social Con-structs.
As per our understanding, this level of accuracyand explainability needs integration of both statistical andlogic based methods.
Our observations suggest that thereis an increasing need for such integration in various do-mains.
We believe that this work is one of the early stepsin that direction.8 AcknowledgementWe thank the IARPA SCIL program for supporting thisresearch.
We also thank NSF for the DataNet FederationConsortium grant OCI-0940841 and ONR for their grantN00014-13-1-0334 for partially supporting this research.1297References[Bernstein2010] Basil Bernstein.
2010.
A public lan-guage: some sociological implications of a linguisticform.
British Journal of Sociology, pages 53?69.
[Brown and Levinson1988] Penelope Brown andSTEPHEN C. Levinson.
1988.
Politeness: Some Uni-versals in Language Usage (Studies in InteractionalSociolinguistics 4).
Cambridge University Press.
[Danescu-Niculescu-Mizil et al2012] Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang, and Jon Klein-berg.
2012.
Echoes of power: Language effects andpower differences in social interaction.
In Proceed-ings of the 21st International Conference on WorldWide Web, WWW ?12, pages 699?708, New York, NY,USA.
ACM.
[Gelfond and Lifschitz1988] Michael Gelfond andVladimir Lifschitz.
1988.
The stable model semanticsfor logic programming.
pages 1070?1080.
MIT Press.
[Gilbert2012] Eric Gilbert.
2012.
Phrases that signalworkplace hierarchy.
In Proceedings of the ACM2012 Conference on Computer Supported CooperativeWork, CSCW ?12, pages 1037?1046, New York, NY,USA.
ACM.
[Gupte et al2011] Mangesh Gupte, Pravin Shankar, JingLi, S. Muthukrishnan, and Liviu Iftode.
2011.
Find-ing hierarchy in directed online social networks.
InProceedings of the 20th International Conference onWorld Wide Web, WWW ?11, pages 557?566, NewYork, NY, USA.
ACM.
[Hutto and Gilbert2014] C. J. Hutto and Eric Gilbert.2014.
Vader: A parsimonious rule-based model forsentiment analysis of social media text.
In ICWSM.
[Mayfield et al2013] Elijah Mayfield, David Adamson,and Carolyn Penstein Ros?.
2013.
Recognizing raresocial phenomena in conversation: Empowerment de-tection in support group chatrooms.
pages 104?113.
[Medhat et al2014] W. Medhat, A. Hassan, and H. Ko-rashy.
2014.
Sentiment analysis algorithms and ap-plications: A survey.
Ain Shams Engineering Journal,5(4):1093 ?
1113.
[Pennebaker et al2003] James W. Pennebaker,Matthias R. Mehl, and Kate G. Niederhoffer.2003.
Psychological aspects of natural language use:Our words, our selves.
Annual Review of Psychology,54(1):547.
[Prabhakaran et al2012] Vinodkumar Prabhakaran,Huzaifa Neralwala, Owen Rambow, and Mona Diab.2012.
Annotations for power relations on emailthreads.
In Proceedings of the Eight InternationalConference on Language Resources and Evalua-tion (LREC?12), Istanbul, Turkey, may.
EuropeanLanguage Resources Association (ELRA).
[Saif et al2012] Hassan Saif, Yulan He, and Harith Alani.2012.
Semantic sentiment analysis of twitter.
In Pro-ceedings of the 11th International Conference on TheSemantic Web - Volume Part I, ISWC?12, pages 508?524, Berlin, Heidelberg.
Springer-Verlag.
[Scherl et al2010] R. Scherl, D. Inclezan, and M. Gel-fond.
2010.
Automated inference of socio-culturalinformation from natural language conversations.
InIEEE International Conference on Social Computing,pages 480?487, Aug.[Shaikh et al2010] Samira Shaikh, Tomek Strzalkowski,Aaron Broadwell, Jennifer Stromer-Galley, Sarah Tay-lor, and Nick Webb.
2010.
Mpc: A multi-party chatcorpus for modeling social phenomena in discourse.In Proceedings of the Seventh International Confer-ence on LREC, may.
[Simon1946] Herbert A. Simon.
1946.
The proverbsof administration.
Public Administration Review,6(1):53?67.
[Stolcke2000] Andreas Stolcke.
2000.
Dialogue act mod-eling for automatic tagging and recognition of conver-sational speech.
[Strzalkowski et al2010] Tomek Strzalkowski,George Aaron Broadwell, Jennifer Stromer-Galley,Samira Shaikh, Sarah M. Taylor, and Nick Webb.2010.
Modeling socio-cultural phenomena indiscourse.
In COLING 2010, 23rd InternationalConference on Computational Linguistics, pages1038?1046.
[Tari et al2010] Luis Tari, Saadat Anwar, ShanshanLiang, James Cai, and Chitta Baral.
2010.
Discover-ing drug-drug interactions: a text-mining and reason-ing approach based on properties of drug metabolism.Bioinformatics, 26(18).
[Vanzo et al2014] Andrea Vanzo, Danilo Croce, andRoberto Basili.
2014.
A context based model for sen-timent analysis in twitter.
In Proceedings of COLING2014, pages 2345?2354, Dublin, Ireland.
Dublin CityUniversity and Association for Computational Lin-guistics.1298
