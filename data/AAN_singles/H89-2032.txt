OVERVIEW: CONTINUOUS SPEECH RECOGNITION Icha i rperson  - Janet  M. BakerThe Continuous Speech Recognition I session consisted of 8 tightly woven presentations, rich intechnical content and experimental results.
BBN led off with three talks, followed by two eachfrom CMU and AT&T, and a final presentation from LL.The first paper, BBN1, presented by R.Schwartz, refreshingly started by recounting a series ofexperiments the first of which had not or only minimally, improved system performance.Algorithmic methods discussed included Linear Discriminant Analysis, Supervised VectorQuantization, Shared Mixture VQ, Deleted Estimation of Context Weights, MMI EstimationUsing "N-Best" Alternatives, and Cross-Word Triphone Models.
The last of these proved mosteffective in reducing word errors.
Although not all of these methods have yet been combinedinto one system, the error rate on the May 1988 Resource Management test set (using word-pairgrammar) has been halved.In the BBN2 paper, F. Kubala presented a method for speaker adaptation using multiplereference speakers.
A more traditional approach typically pools multiple speakers into a singleset of broad patterns.
This approach differs in that it first normalizes peech from multiplespeakers, separately performing spectral transformations to a common reference space, and thenpooling these, as if they were from a single speaker.
Preliminary results pooling normalizedspeech from 12 speakers appears quite promising in contrast o single reference normalizationresults.
Additional control experiments and the use of many more reference speakers areanticipated.R.
Schwartz in BBN3, recounted initial experiments aimed at detecting that a speaker has used aword not in the known vocabulary.
By comparing each of the words spoken with a generalacoustics model for all words, in addition to "in-vocabulary" word models, one can applythresholding on word match scores to help discriminate new words from in-vocabulary lexicalitems.
Depending on the level of thresholding applied, the proportion of new words detectedrelative to a false alarm rate may be altered.
Encouraging test results were obtained usingResource Management speech data where "new" words were created simply by removing asubset of in-vocabulary words from the standard system lexicon.KF.
Lee and F. Alleva jointly presented CMU1.
Lee discussed CMU's present progress,including the use of semi-continuous hidden Markov models (SCHMMs) applied to the 1000-word speaker-independent Resource Management continuous peech recognition task.
TheSCHMM used here is derived from multiple VQ codebooks, whereby the probability densityfunction for each codebook is determined by combining the corresponding discrete outputprobabilities of the HMM and the continuous Gaussian density functions for that codebook.Test results indicate superior performance with this SCHMM methodology in contrast o both adiscrete HMM approach and the continuous mixture HMM.Alleva's CMU1 presentation centered on automating new word acquisition by mapping acousticobservations in continuous peech, to appropriate standard English orthography.
A 5-gramspelling/language model using 27 tokens (A through Z plus "blank"), was constructed fromextensive (15,000 sentences) training data.
Despite a low spelling perplexity in a test set,difficulties in accurately detecting word boundaries were believed a significant factor inobserved high error rates.
Future experiments will concentrate on using intermediate mappingsfrom acoustics to phonetic units, and possibly syllables, prior to generating the correspondingorthography.The CMU2 paper presented by HW.
Hon, addressed research in constructing "vocabulary-independent" acoustic word models in an effort to avoid task-specific vocabulary training,247thereby enabling the rapid configuration of new speaker-independent recognition tasks,incorporating new lexical items.
This approach requires the extraction of flexible sub-wordunits from a large training database.
The recognition results using generalized triphones arehighly dependent on the size of the training set, from which they are derived.
Errors decreasesubstantially (though showing no asymptote...), as the training set size increases from 5000 to15,000 sentences.Delivered by CH.
Lee, the AT&TI paper reviews acoustic modeling methodologies mployed inconjunction with a large vocabulary speech recognition system being developed at AT&T BellLaboratories.
Based on the actual words in a given training set, acoustic descriptions are definedin terms of phone-like units, "PLUs".
Many tests on the Resource Management task wereperformed with both context-independent (CI) PLUs (set size = 47) and context-dependent (CD)PLUs (set sizes range from 638 to 2340).
The highest performance r sults were obtained usingCD PLUs.
Detailed error analyses were presented as well as recommendations for further workto include more detailed function word/phrase modeling, interword CD PLUs, correctivetraining, and multiple lexical entry acoustic descriptions where required.In AT&T2, S. Levinson discussed a separate speech recognition system at AT&T Bell Labs.
Thisapproach is based on matching a phonetic transcription derived from continuous peech input,against he closest string of phonetic spellings for the constituent lexical items of grammaticallyallowable sequences.
Although test results on the Resource Management ask have beendisappointing thus far, the author is encouraged by the quality of his speech synthesis of thephonetic transcriptions, effectively a 120 BPS coder.
Audio tapes were played for the audienceand are available from the author upon request.The concluding paper of this session, LLI by D. Paul, addresses the issue of employing "tiedmixtures" for compactness in implementing a continuous observation HMM system running onvery large vocabulary tasks.
Resource Management test results indicated a modest improvementfor speaker-dependent recognition without cross-word triphones models.
Performance gainswere not realized however for speaker-dependent recognition with cross-word triphones, or forthe speaker-independent system.
It was proposed that further work on smoothing of theweights for the tied mixtures may prove productive.
Using these tied mixtures results indecreased CPU usage during recognition (1/2 x), but at a cost of increased training (2x).
Incommenting on the general issue of the Resource Management comparative valuations, theauthor observed that inter-site test results show both high across-speaker standard eviations aswell as poor correlation of best-speaker lists.
Analysis indicates the need for much larger testspeaker sets, as well as tests properly accounting for speaker variability.The chair of this session strongly applauds the openness of the authors, and commends theircandor in communicating their results, both negative and positive.
Readers and audience, alike,are cautioned however to remember that negative results should not be construed as failures ofthe intended approach.
Potentially positive results from constructive ideas and methodologiescan easily be curtailed or negated due to limitations in the data provided (as realized withtraining and/or test set inadequacies), as well as the myriad of opportunities for Murphy's Lawto intervene; e.g.
program "bugs", etc.248
