Proceedings of the TextGraphs-7 Workshop at ACL, pages 30?38,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsIdentifying Untyped Relation Mentions in a Corpus given an OntologyGabor MelliVigLink Inc.539 Bryant St. #400San Francisco, CA, USAg a b o r @ v i g l i n k.c o mAbstractIn this paper we present the SDOIrmi textgraph-based semi-supervised algorithm forthe task for relation mention identificationwhen the underlying concept mentionshave already been identified and linked toan ontology.
To overcome the lack ofannotated data, we propose a labellingheuristic based on information extractedfrom the ontology.
We evaluated thealgorithm on the kdd09cma1 dataset usinga leave-one-document-out framework anddemonstrated an increase in F1 inperformance over a co-occurrence basedAllTrue baseline algorithm.
An extrinsicevaluation of the predictions suggests aworthwhile precision on the moreconfidently predicted additions to theontology.1 IntroductionThe growing availability of text documents and ofontologies will significantly increase in value oncethese two resources become deeply interlinkedsuch that all of the concepts and relationshipsmentioned in each document link to their formaldefinitions.
This type of semantic information canbe used, for example, to aid information retrieval,textual entailment, text summarization, andontology engineering (Staab & Studer, 2009;Buitelaar et al 2009).
An obstacle to this vision ofsemantically grounded documents however is thesignificant amount of effort required of domainexperts to semantically annotate the text (Erdmannet al 2000; Uren et al 2006).
Some automation ofthe annotation task is a precondition to theenvisioned future of deeply interlinkedinformation.
Fortunately, the task of linkingconcept mentions to their referent in an ontologyhas matured (Milne & Witten, 2008; Melli & Ester,2010).
Far less progress has been made on the taskof linking of relation mentions to the referentrelation in a knowledge base.
In part, we believe,this is because current approaches attempt to bothidentify mentions of relations between two or moreconcepts and to classify the type of the relation,such as one of: IsA(); HeadquarteredIn();SubcecullarLocalization(), and ComposerOf()In this paper, we present a weakly-supervisedalgorithm for the task of relation mentionidentification, SDOI 1 RMI.
Given a corpus ofdocuments whose concept mentions have beenidentified and linked to an ontology, the algorithmtrains a binary classification model that predictsthe relations mentioned within a document thatshould be (and possibly already are) in anontology.
To overcome the lack of explicitannotation of relation mentions, we propose theuse of a data labelling heuristic that assigns aTRUE or FALSE label if the candidate mentionrefers to a link that exists or does not exist in theontology.
SDOIRMI.is related to proposals by(Riedel et al 2010) and (Mintz et al 2009) exceptthat their proposal attempt to both identify and toclassify relation mentions.
By only tackling thefirst (identification) portion of the task our1 SDOI is for Supervised Document to Ontology Interlinking30algorithm can identify relation mentions of typesthat are not yet present (or are poorly represented)in the ontology.
An extrinsic evaluation of theusability of identified relation mentions to updatean ontology provides evidence that SDOIRMI?sperformance levels can contribute to a real-worldsetting.Our envisioned real-world application is to assist aknowledge engineer to process a new set ofdocuments by receiving a ranked list of candidaterelation mentions not yet in the ontology.
Withsuch a list, the knowledge engineer could dedicatemore attention to comprehending the meaning ofthe passages that (very likely) contain high-qualityrelation mention candidates.The paper is structured as follows: we first defineour proposed algorithm: SDOIrmi,, and concludewith an empirical analysis of its performance.2 Algorithm OverviewFor the task of relation mention identification, wepropose a semi-supervised algorithm inspired bythe TeGRR text graph-based relation recognitionalgorithm proposed in (Melli & al, 2007).
Thealgorithm first applies a labelling heuristic tounlabeled candidate relation mentions, and thentrains a binary classification model.
We weremotivated to follow this approach used by TeGRRfor the following reasons:1) It is based on relation recognition approaches,such as (Jiang & Zhai, 2007), that achievestate-of-the-art performance (e.g.
onbenchmark tasks such as ACE2).2) It is designed to recognize relation mentionsthat span beyond a single sentence (by the useof a text graph representation)3) It exposes an extensible feature space (thatcan be extended with information drawn fromour task?s ontology).4) It provides a natural path for the futuresupport of tasks with labelled training data ?possibly even labelled with the actual relationtype.One of the distinctive aspects of TeGRR is itsrepresentation of a document into a graph-based2 ACE Relation Detection Recognition (RDR) taskhttp://projects.ldc.upenn.edu/ace/annotation/representation, where each concept mention ortoken in the text is mapped to an ?external?
node ina graph, and which represents other syntactic andstructural features of the text as internal nodes andedges between nodes.
In Section 3 we define thetext graph representation and its effect on thealgorithm definition.Given a document?s text-graph, we can proceed todefine a feature space for each relation mentioncandidate.
Table 1 illustrates the structure of thetraining data and its feature space that we proposefor SDOIrmi.
We divide the feature space into threeinformation sources.
An initial feature source isbased on the shortest path between the conceptsmentions, all of which have been proposed forTeGRR in (Melli & al, 2007).
We also propose toinherit the concept mention linking featuresdefined in (Melli & al, 2010) for each of the twoconcept mentions associated to a relation mentioncandidate.
Finally, we also propose features thatdraw on information from the ontology.doc d m i m jTF  e  a  t  u  r  e     S  p  a  c  e F?TeGRRText-Graph basedOntology basedlabelRelationMentionConcept Mention(CM) Linking basedCMa CMbTable 1 ?
A high-level representation of trainingexamples of a document?s unique conceptmention pairs (relation mention candidates).The label assignment procedure and the featuredefinitions are presented in the two comingsubsections.2.1 Label AssignmentAnnotating relations in text is a time consumingprocess ?
more so than annotating entities.
Toovercome the lack of annotated relation mentiondata, we propose to use the ontology for thelabeling decision.
For each combination of conceptmention pairs the heuristic automatically assignlabels according to the following rule.
If theconcepts in the ontology associated with therelation mention share a direct internal link in theontology in either direction then the trainingexample is marked as true; otherwise it is labeledas False.31VPNPWeVPNPSVBPreportSNPWeVBPidentifyPPINof..NNconjoint analysisNNcase studyDTaPP..NPclick-through eventsINfromNPusers?
preferencesVPSNPWeVBPproposePP..NNconjoint analysisINforNPlogistic regressionThis approach to labeling is similar to the one usedby relation mention recognition task such as (Melli& al, 2007).
Our proposal in this paper howeverextends this automatic labeling approach for Falseexample labeling to also automatically label truerelation mentions.
This approach is more likely tolead to erroneously mislabeled candidates.
In manycases, the passages associated with a candidaterelation mention that happens to refer to directlylinked concepts in the ontology do not substantiatea direct semantic relation.
In these cases, afterreading the passage, an expert would insteadconclude that a direct relation is not implied by thepassage and would label the candidate relationmention as False.
Alternatively, the heuristicwould label some relation mention candidates asFalse simply because the relation did not yet existin the ontology; while, upon manual inspection ofthe passage, the annotator would label the relationas a True candidate.Despite this appreciation of noise in the generatedlabels, we hypothesize that this heuristic labelingapproach provides a sufficient signal for thesupervised classification algorithm to detect manydirect relation mentions with sufficient accuracy tobe useful in some real-world tasks, such asontological engineering.3 Text Graph RepresentationThe TeGRR feature space is based on a graphrepresentation of the document underconsideration.
The text graph representation iscomposed of the three types of edges: 1) Intra-sentential edges; 2) Sentence-to-sentence edges;and 3) Co-reference edges.Figure 1  - An illustration of SDOIRMI?s textgraph to create feature vectors.
The highlightednodes and path represent the information usedfor a specific candidate pair assessment.32Intra-sentential edges in a text-graph representedges between nodes associated with tokens fromthe same sentence.
These edges can vary frombeing: word-to-word edges, shallow parsing edges,dependency parse tree edges, and phrase-structureparse tree edges.
We propose the use the phrase-structure parse tree as the source of intrasententialedges for two reasons.
The choice of this datasource over the others is the analysis by (Jiang &Zhai, 2007) that suggests that the phrase-structureparse tree is the best single source of informationfor relation detection.
Secondly, all other proposedintra-sentential edge types can be derived, orapproximated, from phrase-structure parse trees bymeans of transformations.A phrase-structure parse tree is composed of twotypes of nodes: leaf nodes and internal nodes.
Leafnodes (which map to our external nodes) arelabelled with the text token (or concept mention),and with the part-of-speech role.
Internal nodescontain the syntactic phrase-structure label.The text graph in Figure 1 contains 26intrasentential edges connecting 12 internal nodesand 19 leaf nodes.Edges in a text graph can also cross sentenceboundaries.
The first type of inter-sentential edgeto be considered is the ?sentence-to-sentence?
edgethat simply joins an end-of-sentence punctuationnode with the first word of the sentence thatfollows.
The intuition for this edge type is that aconcept that is mentioned in one sentence can be ina semantic relation with a concept mention in theadjacent sentence, and that the likelihood of itbeing a relation increases as you reduce thenumber of sentences between the two entities.
Thetext graph in Figure 1 contains two sentence-to-sentence edges.Co-reference EdgesThe other source of inter-sentential edges to beconsidered, also taken from (Melli & al, 2007), arebased on concept mentions in the same documentthat are linked to (co-refer to) the same concept inthe ontology.
For example if ?hidden-Markovmodels?
is mentioned in one sentence, ?HMMs?
ismentioned in a subsequent one, and the pronoun?they?
is used to refer to the concept further on inthe document, then coreference edges would existbetween ?hidden-Markov models?
and ?HMMs?,and between ?HMM?
and ?they?
(via the HiddenMarkov Models concept).
The intuition for thisedge type is that concept mentions in separatesentences but that are near some coreferent conceptmention are more likely to be in a semanticrelation than if that co-referent mention did notexist.
The text graph in Figure 1  contains acoreference edge between the mentions of to theConjoint Analysis Algorithm that were identifiedby the concept mention identifier anddisambiguator described in (Melli & Ester, 2010).Text-Graph PropertiesWe describe properties of a text graph used todefine SDOIrmi?s text-graph related features:1) A text-graph is a connected graph: for everypair of nodes n and v there is a walk from nto v2) A text-graph can be a cyclic graph, and suchcycles must involve co-reference edges.3) A text-graph has at least one shortest pathbetween any two nodes, n and v, and thenumber of edges between them is theirdistance.4) A concept mention mi is in a p-shortest pathwith concept mention mj if there are only p-1other concept mentions in a shorter shortest-path relation with mi.
The value of p can beinterpreted as the rank of the proximitybetween the two concept mentions, e.g.
1stnearest, 2nd nearest, etc.
If two alternatemention pairs are in equal p-shortest pathrelation then both are True for the relation.5) A path-enclosed subtree is the portion of thesyntactic tree enclosed by the shortest-pathbetween two leaf-nodes.
This inner portionof a syntactic tree is predictive in relationextraction tasks (Jiang & Zhai, 2007).4 Relation Mention Identification FeaturesWe begin the definition of the feature space withthe text-graph based features that we retain from(Melli & al, 2007).
We then proceed to describethe ontology-based features, and conclude with theconcept linking features inherited from theprevious (concept linking) task.334.1 Text-Graph based FeaturesThis section describes the features that we directlyinherit from TeGRR.
We first describe theunderlying text graph representation that is thenused to define the associated features.Path-Enclosed Shortest Path FeaturesFrom the path-enclosed shortest-path subgraph weidentify all distinct subtrees with up to e edges asproposed in (Jiang & Zhai, 2007) to replicate theconvolution-kernel approach of (Haussler, 1999).A feature is created for each possibleneighborhood in the subgraph, where aneighborhood is defined by a subtrees with eedges, where e ranges from zero through to someupper limit on edges: e  [0, emax].
We retain the eproposed in (Jiang & Zhai, 2007) of emax=2.Subtree-based features associated to the subtrees ofsize zero (e=0) simply summarize the number ofnodes of a certain content type in either the entirerelation mention graph, or one of its pairings.
Forexample, one feature would count the number ofNP (Noun Phrase) nodes in the relation mentiongraph, while another feature would count thenumber of times that the word ?required?
ispresent.
Subtree-based features associated to thesubtrees of size e>0 represent the number of timesthat a subgraph with e edges appears within thesubgraph.
For example, one feature would countthe number of times that the triple IN ?
PP ?
NPappears in the graph.Sentence Count:This feature informs the classifier about thenumber of sentences that intervene betweenconcept mentions.
For example, the number ofintervening sentences between the ?case study?and ?logistic regression?
mention in the relationmention in Figure 1 is two (2) sentences.
Thisinformation will help the classifier adjust itspredictions based on the separation.
Nearermentions are more likely to be in a relation.Intervening Concept Mentions:This set of features informs the classifier about thenumber of concept mentions that intervenebetween two concept mention pairs.
For example,in Figure 1 ?conjoint analysis?
is counted as oneintervening concept mention between ?case study?and ?logistic regression?.
This information willhelp the classifier adjust its predictions based onhow many other concept mention candidates exist;the greater then number of intervening conceptmentions the less likely that a semantic relationbetween the two concept mentions is being stated.4.1.1 Concept Mention Linking-based FeaturesA second source of features that we propose is toinclude the pair of feature sets for each conceptmention defined for concept mention linking(Melli & Ester, 2010).
We concatenate the twofeature vectors in the following order: the conceptmention that appears first in the text, followed bythe other concept mention.
These features providesignals of the context of each mention, such aseven simply what sentence it is locate on.
In Figure1 for example, the ?case study?
concept mention islocated on the first sentence and the closer amention is to the first sentence may affect theimportance of the mention.4.2 Ontology-based FeaturesWe further propose four features based oninformation from the ontology ?
that differ fromthe ones inherited from the concept-mentionlinking task.
These four features captureinformation signals from their pairing in theontology: Shared_Outlinks, Shared_Inlinks,Shortest_gt1-Edge_Distance, and TF-IDF_Concepts_Similarity.Shared_Outlinks FeatureThe Shared_Outlinks feature counts the number ofshared concept outlinks.
The intuition for thisfeature is that two concepts that reference many ofthe same other concepts in the ontology are morelikely to be themselves in a direct relation.Shared_Inlinks FeatureThe Shared_Inlinks feature counts the number ofshared concept inlinks.
The intuition for thisfeature is that two concepts that are referenced bymany of the same other concepts in the ontologyare more likely to be themselves in a directrelation.Shortest1-Edge_Distance FeatureThe Shortest1-Edge_Distance feature reports theshortest distance (in the ontology) that is greaterthan one counts the number of edges that separate34the two concepts.
This feature is the one thatintroduces the risk of giving away the presence ofa direct link between the two concepts in thecandidate.
An edge distance of one (1) versus anyother edge distance would be a perfect predictor ofthe label.
However, information about the distanceof alternate paths can provide a signal that the twoconcepts should be (or are) linked.TF-IDF_Concepts_Similarity FeatureThe TF-IDF_Concepts_Similarity feature reportsthe tf-idf bag-of-words similarity between the twoconcept descriptions in the ontology.
The intuitionis similar to that of the ?Shared Outlinks?
feature:two concepts that reference many of the samewords are more likely to be themselves in arelation.
Unlike the ?Shared Outlinks?
featurehowever, this feature normalizes for very commonand uncommon words.Corpus-based FeaturesA final source of information for features that wepropose is the training corpus itself.
As with thecorpus-based features for concept linking (Melli &Ester, 2010), the use of cross-validation forperformance estimation requires that the documentassociated with the training record does not informthese features.
For this feature, the count is on?other?
documents.4.3 Relation_Mention_Other_Doc_CountFeatureThe Relation_Mention_Other_Doc_Count featurecounts the number of other documents in thecorpus that contain the pair of linked conceptmentions.
For example, if one other documentcontains the two linked concept mentions (and thuscontains the same candidate relation mention) thisfeature is set to one (1).5 Empirical Evaluation of RelationMention IdentificationIn this section, we empirically evaluate theperformance of the proposed relation-mentionidentification algorithm: SDOIrmi.
For thisevaluation, we again used the SVMlight3 packagewith its default parameter settings, as theunderlying supervised classification algorithm.
For3 http://svmlight.joachims.org/the syntactic parse trees, we use Charniak?sparser4.Evaluation SetupSimilar to evaluation of SDOI?s two othercomponent algorithms for concept mentionidentification and linking, we use a leave-one-document-out method on the kdd09cma1 corpus(Melli, 2010).
For each unseen document, wepredict which of its binary relation mentioncandidates (with linked concept mentions) alreadyexist in the ontology.
Those relations that do notexist in the ontology are proposed candidates foraddition to the ontology.A challenge associated with this task, as found inthe concept-mention linking task, is the highlyskewed distribution of the labels.
In this case, wedo not propose a filtering heuristic to change thetraining data.
Instead, we propose an algorithmicchange by tuning SVMlight?s cost-factorparameter that multiplies the training error penaltyfor misclassification of positive examples.
We setaside three documents to tune the parameter, andbased on an analysis to optimize F1 we set thecost-factor to 8.Table 2 presents some of the key statistics for thekdd09cma1 from the perspective of relationmention candidates.
The corpus contains 44,896relation mention candidates.
Of these, whichquantifies the task?s data skew, only 3.55% of themention candidates are found in the ontology.Table 2 ?
Key statistics of the number of binaryrelation mentions in the kdd09cma1 corpus, perabstract and for entire corpus.
The final rowreports the total number of concept pairingswhere, at the document-level, pairs to the sametwo concepts are consolidated.4 ftp://ftp.cs.brown.edu/pub/nlparser/Binary RelationMention Candidates Positive Candidates ProportionMinimum (per abstract)                                   42.0                                    1.0 0.88%Average (per abstract)                                322.1                                 11.5 3.86%Maximum (per abstract)                             1,582.0                                    4.3 12.50%Entire corpus                          44,896.0                           1,593.0 3.55%Entire corpus (only distinct relations)                          34,181.0                           1,080.0 3.16%35Baseline Algorithm(s)The baseline algorithm that we compare SDOIrml?sperformance against on the relation-mentionidentification task is an unsupervised co-occurrence-based algorithm that predicts allpermutations of linked concept mention pairsregardless of distance between them.
This is thebaseline algorithm compared against in (Melli &al, 2007, and Shi & al, 2007).
We refer to thisalgorithm as AllTrue.We also include as a baseline a version of SDOIrmlwith a restricted feature space that contains thefeatures originally proposed for TeGRR.Intrinsic Performance AnalysisTable 3 presents the results of the leave-one outperformance analysis.
SDOIrml outperforms thebaseline algorithm in terms of precision and F1.The proposed feature space for SDOI alsooutperforms the original feature space proposed forTeGRR.Algorithm Feature Space Precision Recall F1All 18.2% 24.3% 20.8%TeGRR 7.7% 41.8% 13.0%3.7% 100.0% 7.1%SDOIAllTrueTable 3 ?
Leave-one-out performance results onthe relation mention identification task on thekdd09cma1 corpus (excluding the three tuningabstracts) by SDOI, SDOI with its feature spacerestricted to those originally proposed forTeGRR, and the AllTrue baseline.Extrinsic Performance AnalysisWe analyze the performance on a real-world usagescenario where an ontology engineer receives thegenerated list of relation mention candidatespredicted as True for being a direct link, whichupon inspection of the ontology does not exist.
Wemanually analyzed the top 40 predicted relationmention candidates proposed for insertion into thekddo1 ontology ranked on their likelihood score5.Table 4 reports a snapshot of these relationcandidates.
Of the 40 candidates 31 (77.5%) were5 We used SVMlight?s real-number predictions, and did notboost the selection based on whether more than twodocuments resulted in predictions for the concept pair.deemed candidates for insertion into the ontology6.Given the high proportion of relation candidatesworthy of insertion, this result illustrates somebenefit to the ontology engineer.Boostrapping ExperimentIn practice, a common method of applying self-labelled learning is to treat the labelling heuristicas a means to seed a bootstrapped process wheresubsequent rounds of labelling are based on themost confident predictions by the newly trainedmodel (Chapelle & al, 2006).
Generally,evaluations of this approach have assumed high-accuracy seed labels - either from a small manuallycurated training set, such as in (Agichtein &Gravano, 2000), or with high-accuracy labellingpatterns, such as in (Yarowsky, 1995).
Eachiteration sacrifices some precision for additionalrecall performance.
In our case a bootstrappedprocess does not begin with high precision tosacrifice, because of our labelling heuristic doesnot start with high-precision predictions.Concept A Concept B20.873 Computing System Algorithm doi:10.1145/1557019.1557112?
?
?
?15.975 Computing System Algorithm doi:10.1145/1557019.155714423.584 Conditional Probability Marginal Probabilty doi:10.1145/1557019.155713022.345 Conj int Analysis User Preference doi:10.1145/1557019.155713822.075 Optimization Task Gradient Descent Algorithm doi:10.1145/1557019.155712920.349 Optimization Task Gradient Descent Algorithm doi:10.1145/1557019.155710021.788 Set Pattern doi:10.1145/1557019.155707119.849 Set Pattern doi:10.1145/1557019.155707721.047 Training Dataset Performance Measure doi:10.1145/1557019.1557144Sc reBinary RelationDocumentTable 4 ?
A sample of candidate relations (andtheir source document) with high likelihoodscore predicted by SDOI as candidates foraddition to the kddo1 ontology.
The tablegroups candidates that refer to the sameconcept pairs.However, we performed a bootstrap experiment byiteratively selecting the 10% of relation mentionsthat were predicted to be True with the highestlikelihood score, and then labelled these candidatesas True in the subsequent iteration (even if no6 This task-based result is likely dependent on the maturity ofthe ontology.36direct link existed in the ontology for thecorresponding concept pair).F1 performance dropped with each iteration.
Someanalysis can show that this deterioration inperformance is unavoidably built into the process:with each iteration the supervised classifier trainedmodels that were based on the increasingly falseassumption that True labelled training data wererepresentative of direct links in the ontology.Ensuing models would begin to predict links thatwere by definition not in the ontology and wouldthus be evaluated as false positives.Thus, we again manually inspected the top 40predicted relations for the first two iterations.
Theprecision dropped after each iteration.
After thefirst iteration, 29 (72.5%) candidates were correct,and after the second iteration, 21 (52.5%)candidates were correct.
During the manualreview, we observed that predictions in subsequentiterations began to include some of the morecommon False pairings listed in Error!
Referencesource not found.. Bootstrapping of SDOIrml doesnot improve the precision of the reportedpredictions, on the kdd09cma1 benchmark task.Observations and ConclusionWe conclude with some observations based on thepredictions reported in Table 4 of the leave-one-out evaluation on the kdd09cma1 corpus The tableincludes some promising candidates for addition tothe ontology.
For example, because of thisexperiment we noted that the obvious missingdirect relation between a Computing System andan Algorithm 7 .
The table also includes a morenuanced missing direct relation missing in theontology between Conditional Probability andMarginal Probability8.Next, we observe that suggested relation mentioncandidates whose concept pairs are predictedwithin more than one document, such asComputing System + Algorithm, may be more7 The direct relation can naturally added in both directions ?anALGORITHM can be implemented into a COMPUTING SYSTEM?and ?a COMPUTING SYSTEM can implement an ALGORITHM.
?8 Based on passage ?
?assumption made by existingapproaches, that the marginal and conditional probabilitiesare directly related....?
From 10.1145/1557019.1557130and due to the fact that the two concept descriptions arebriefly described in kddo1.indicative that the direct relation is indeed missingfrom the ontology than when only supported by asingle document.
However, as counter-evidence,some of the repeated pairs in Table 4 appear to belisted simply due to their frequent occurrence inthe corpus.
For example, the candidate relationbetween the concepts of Set and of Pattern maysimply be due to documents (abstracts) that oftenmention ?sets of patterns?.
We would not expectthe Set concept to be directly linked to everyconcept in the ontology that can be grouped into aset.
This example however does suggest thatPattern + Set may be a common and importantconcept in the data mining domain to deserve theaddition of a Pattern Set concept into the ontology.We note further that very frequent candidates, suchas Research Paper + Algorithm, were notpredicted; likely because the algorithm recognizedthat if such a commonplace relation is always falsethen it likely will be false in a new/unseendocument.
Thus, there is some evidence that thenumber of repetitions can indeed signify a morelikely candidate.
As future work, it would beworthwhile to attempt to train a second classifierthat can use the number of referring documents asa feature.A separate challenge that we observe from thepredictions in Table 4 is illustrated by theOptimization Task + Gradient Descent Algorithmentry.
While this seems like a reasonable candidatefor addition at first glance, these two concepts aremore likely indirectly related via the OptimizationAlgorithm concept (an optimization task can besolved by an optimization algorithm; a grandientdescent algorithm is an optimization algorithm.
).The resolution of these situations could requireadditional background knowledge from theontology, such as relation types, to inform theclassifier that in some situations when the parent islinked to the concept then the child is not directlylinked to it.ReferencesEugene Agichtein, and Luis Gravano.
(2000).
Snowball:Extracting Relations from Large Plain-TextCollections.
In: Proceedings of the 5th ACMInternational Conference on Digital Libraries (DL2000).37Paul Buitelaar, Philipp Cimiano, Peter Haase, andMichael Sintek.
(2009).
Towards LinguisticallyGrounded Ontologies.
In: Proceedings of the 6thEuropean Semantic Web Conference (ESWC 2009).Michael Erdmann, Alexander Maedche, Hans-PeterSchnurr, and Steffen Staab.
(2000).
From Manual toSemi-automatic Semantic Annotation: AboutOntology-Based Text Annotation Tools.
In:Proceedings of the COLING 2000 Workshop onSemantic Annotation and Intelligent Content.David Haussler.
(1999).
Convolution Kernels onDiscrete Structures.
Technical Report UCSC-CLR-99-10, University of California at Santa Cruz.Jing Jiang, and ChengXiang Zhai.
(2007).
A SystematicExploration of the Feature Space for RelationExtraction.
In: Proceedings of NAACL/HLTConference (NAACL/HLT 2007).Gabor Melli.
(2010).
Concept Mentions within KDD-2009 Abstracts (kdd09cma1) Linked to a KDDOntology (kddo1).
In: Proceedings of the 7thInternational Conference on Language Resources andEvaluation (LREC 2010).Gabor Melli, and Martin Ester.
(2010).
SupervisedIdentification of Concept Mentions and their Linkingto an Ontology.
In: Proceedings of  CIKM 2010.Gabor Melli, Martin Ester, and Anoop Sarkar.
(2007).Recognition of Multi-sentence n-ary SubcellularLocalization Mentions in Biomedical Abstracts.
In:Proceedings of the 2nd International Symposium onLanguages in Biology and Medicine (LBM 2007).Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky.(2009).
Distant Supervision for Relation Extractionwithout Labeled Data.
In: Proceedings of ACL 2009.Sebastian Riedel, Limin Yao, and Andrew McCallum.(2010).
Modeling Relations and their Mentionswithout Labeled Text.
In: Proceedings of ECML2010.Steffen Staab (editor), and Rudi Studer (editor).
(2009).Handbook on Ontologies - 2nd Ed.
Springer Verlag.Victoria Uren, Philipp Cimiano, Jos?
Iria, SiegfriedHandschuh, Maria Vargas-Vera, Enrico Motta, andFabio Ciravegna.
(2006).
Semantic Annotation forKnowledge Management: Requirements and a surveyof the state of the art.
In: Web Semantics: Science,Services and Agents on the World Wide Web, 4(1).David Yarowsky.
(1995).
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.In: Proceedings of the 33rd annual meeting onAssociation for Computational Linguistics (ACL1995)38
