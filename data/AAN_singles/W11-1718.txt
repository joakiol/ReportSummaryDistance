Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 139?145,24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational LinguisticsSentiment Classification Using Semantic Features Extracted fromWordNet-based ResourcesYoan Guti?rrezDepartment of InformaticsUniversity of Matanzas, Cuba.
{yoan.gutierrez}@umcc.cuSonia V?zquez and Andr?s MontoyoDepartment of Software and ComputingSystemsUniversity of Alicante, Spain.
{svazquez, montoyo}@dlsi.ua.esAbstractIn this paper, we concentrate on the 3 ofthe tracks proposed in the NTCIR 8MOAT, concerning the classification ofsentences according to theiropinionatedness, relevance and polarity.We propose a method for the detection ofopinions, relevance, and polarityclassification, based on ISR-WN (aresource for the multidimensional analysiswith Relevant Semantic Trees of sentencesusing different WordNet-based informationsources).
Based on the results obtained, wecan conclude that the resource and methodswe propose are appropriate for the task,reaching the level of state-of-the-artapproaches.1 IntroductionIn recent years, textual information has becomeone of the most important sources of knowledge toextract useful and heterogeneous data.
Texts canprovide from factual information such asdescriptions, lists of characteristics or instructionsto opinionated information such as reviews,emotions or feelings.
This heterogeneity hasmotivated that dealing with the identification andextraction of opinions and sentiments in textsrequire special attention.
In fact, the developmentof different tools to help government informationanalysts, companies, political parties, economists,etc to automatically get feelings from news andforums is a challenging task (Wiebe et al, 2005).Many researchers such as Balahur et al, (2010),Hatzivassiloglou et al(2000), Kim and Hovy(2006), Wiebe et al (2005) and many others havebeen working in this way and  related areas.Moreover, in the course of years we find a longtradition on developing Question Answering (QA)systems.
However, in recent years, researchershave concentrated on the development of OpinionQuestions Answering (OQA) systems (Balahur etal., 2010).
This new task has to deal with differentproblems such as Sentiment Analysis wheredocuments must be classified according tosentiments and subjectivity features.
Therefore, anew kind of evaluation that takes into account thisnew issue is needed.One of the competitions that establishes thebenchmark for opinion question answeringsystems, in a monolingual and cross-lingualsetting, is the NTCIR Multilingual OpinionAnalysis Task (MOAT) 1 .
In this competition,researchers work hard to achieve better results onOpinion Analysis, introducing differenttechniques.In this paper, we only concentrate on threetracks proposed in the NTCIR 8 MOAT,concerning to the classification of sentencesaccording to their opinionatedness, relevance andpolarity.
We propose a method for the detection ofopinions, relevance and polarity classification,based on ISR-WN which is a resource for themultidimensional analysis with Relevant SemanticTrees of sentences using different WordNet-basedinformation sources.2 Related worksRelated to Opinion Analysis task we can findmany points of view.
Some researchers say thatadjectives combined with semantic characteristicsprovide vital information to the performance ofOpinion Analysis (Hatzivassiloglou et al, 2000).Others like Zubaryeva and Savoy (2010) assume1http://research.nii.ac.jp/ntcir/ntcir-ws8/meeting/139that the extraction of relevant terms on thedocuments could define their polarity, designing amethod capable of selecting terms that clearlybelong to one type of polarity.
Another researchbased on features extraction was conducted by Laiet al (2010), they developed a trained system onJapanese Opinionated Sentence Identification.
AndBalahur and Montoyo (2009) proposed a method toextract, classify and summarize opinions onproducts from web reviews.
It was based on theprior building of product characteristics taxonomyand on the semantic relatedness given by theNormalized Google Distance (Cilibrasi andVit?nyi, 2007) and SVM learning.
As we can see,the usage of features extraction is a suitable modeto work on Opinion Analysis task.
Apart from thatother authors have used semantic resources, forexample, Kim and Hovy (2006, 2005) usedsemantic resources to get an approach on HolderDetection and Opinion Extraction tasks.In general, using semantic resources is one ofthe most applied procedures over different taskssuch as Document Indexing, DocumentClassification, Word Sense Disambiguation, etc.
InNatural Language Processing (NLP), one of themost used resources for WSD and other tasks isWordNet (WN) (Fellbaum, 1998).
WN is a lexicaldictionary with word senses and descriptions.
Inorder to enrich the WN resource, it has been linkedwith different lexical resources such as WordNetDomains (WND) (Magnini and Cavaglia, 2000) alexical resource containing the  domains of thesynsets in WordNet, SUMO (Niles, 2001) anontology relating the concepts in WordNet,WordNet Affect (WNA) an extension of WNwhere different synsets are annotated with one ofthe six basic emotions proposed by Ekman (1999),SentiWordNet (Esuli and Sebastiani, 2006) alexical resource  where each synset is annotatedwith polarity, Semantic Classes (SC) (Izquierdo etal., 2007) a set of Base Level Concepts (BLC)based on WN, etc.
The usage of these resourcesallows the tackling of NLP tasks from differentpoints of view, depending on the resource used.Our approach proposes using different semanticdimensions according to different resources.
Inorder to achieve this, we use the Integration ofSemantic Resources based on WordNet, which weexplain in the next section and the SemanticClasses (SC).2.1 Integration of Semantic Resources based onWordNet (ISR-WN)ISR-WN (Guti?rrez et al, 2010b) is a newresource that allows the integration of severalsemantic resources mapped to WN.
In ISR-WN,WordNet 1.6 or 2.0 is used as a core to link severalresources: SUMO, WND and WNA.
As Guti?rrezet al (2010a) describe, the integrated resourceallows navigate inside the semantic network.2.2 Semantic Classes (SC)The Semantic Classes resource (Izquierdo et al,2007) consists of a set of Base Level Concepts(BLC) from WN obtained before applying abottom-up process using the chain of hypernymrelations.
For each synset in WN, the processselects as its Base Level Concept the first localmaximum, according to the relative number ofrelations.
As a result, a resource with a set of BLCslinked semantically to several synsets is obtained.In order to apply the multidimensionality thatISR-WN and SC provide, we have analyzedrelated approaches like (Magnini et al, 2002;2008) ,(V?zquez et al, 2004), (Villarejo et al,2005), (Zouaq et al, 2009) and others that takeinto account semantic dimensionality.
Then, wehave decided to use Relevant Semantic Trees(Guti?rrez et al, 2010a) because it is an approachcapable of being applied over several dimensions(resources) at once.2.3 Relevant Semantic Trees (RST)RST (Guti?rrez et al, 2010a) is a method able todisambiguate the senses of the words contained ina sentence by obtaining the Relevant SemanticTrees from different resources.
In order to measurethe association between concepts in each sentenceaccording to a multidimensional perspective, RSTuses the Association Ratio (AR) measure (V?zquezet al, 2004).
Our purpose is to include theMultidimensional Semantic Analysis into theOpinion Analysis using RSTs.In order to evaluate our approach the rules andcorpus that concern the English monolingualsubtasks from MOAT were used.2.4 English monolingual subtasksIn these tasks the participants were provided withtwenty topics.
For each one of the topics, aquestion was given with a short and concise query,140the expected polarity of the answer and the periodof time.
For each of the topics, a set of documentswere assigned and they had to be splitted intosentences for the opinionated and relevancejudgements and into opinion units for the polarity,opinion target and source tasks.
In this work, wedescribe twelve runs for the opinionated, relevanceand polarity judgement tasks.3 WSD methodWe propose an unsupervised knowledge-basedmethod that uses the RST technique combinedwith SentiWordNet 3.0 (Esuli and Sebastiani,2006) to tackle 3 of the monolingual English tasksproposed in the NTCIR 8 MOAT.
In this approachWN 2.0 version is used.The aim of this method is to obtain a RST ofeach sentence and then associate the RST withpolarity values.
The process involves the followingresources: WND, WNA, the WN taxonomy,SUMO and Semantic Classes (SC).
Because of SCdoes not have a tree structure we simply obtain theRelevant Semantic Classes.
Subsequently, wedetermine the polarities collected for each label ofeach RST obtained according to the analyzedsentence.
Our proposal involves four stepspresented on sections 3.1, 3.2, 3.3 and 3.4.3.1 Obtaining the Relevant Semantic TreesIn this section, we use a fragment of the originalRST method with the aim of obtaining RelevantSemantic Trees of the sentences.
Notice that thisstep must be applied for each resource.Once each sentence is analyzed, the AR value isobtained and related to each concept in the trees.Equation 1 is used to measure and to obtain thevalues of Relevant Concepts:(1)Where:(2)In both equations C is a concept; f is a sentenceor set of words (w); fi is the i-th word of thesentence f; P (C, w) is the joint probabilitydistribution; P (C) is the marginal probability.In order to illustrate the processing steps, wewill consider the following example: ?But it isunfair to dump on teachers as distinct from theeducational establishment?.
Using the WNDresource, we show the manner in which we obtainthe RST.The first stage involves the lemmatization of thewords in the sentence.
For the example considered,the obtained lemmas are:Lemmas [unfair; dump; teacher, distinct,educational; establishment]Next, each lemma is looked up in ISR-WN andit is correlated with the WND concepts.
Table 1shows the results after applying Equation 1 overthe example.VectorAR Domain AR Domain0.90 Pedagogy 0.36 Commerce0.90 Administration 0.36 Quality0.36 Buildings 0.36 Psychoanalysis0.36 Politics 0.36 Economy0.36 EnvironmentTable 1.
Initial Concept Vector of DomainsAfter obtaining the Initial Concept Vector ofDomains we apply Equation 3 in order to obtainthe Relevant Semantic Tree related to the sentence.
;(3)Where:;(4)Here AR(PC, f) represents the AR value of PCrelated to the sentence f;           is the ARvalue calculated with equation 1 in case of ChCwas included in the Initial Vector, otherwise iscalculated with the equation 3; ChC is the ChildConcept of PC; ND is a Normalized Distance; ICis the Initial Concept from we have to add theancestors; PC is Parent Concept; TD is Depth ofthe hierarchic tree of the resource to use; and MPis Minimal Path.Applying the Equation 3, the algorithm todecide which parent concept will be added to thevector is shown here:if (         value > 0 ){if ( PC had not been added to vector)PC is added to the vector with AR(PC, f) value;else PC value = PC value + AR(PC, f) value; }The result after processing is shown in Table 2.This vector represents the Domain tree associatedto the sentence.
After the Relevant Semantic Treeis obtained, the Factotum Domain is eliminated141from the tree.
Due to the fact that Factotum is ageneric Domain associated to words that appear ingeneral contexts it does not provide usefulinformation and experimentally we confirmed thatit introduced errors; so we eliminate it (Magniniand Cavaglia, 2000).VectorAR Domain AR Domain1.63 Social_Science  0.36 Buildings0.90 Administration  0.36 Commerce0.90 Pedagogy  0.36 Environment0.80 Root_Domain  0.11 Factotum0.36 Psychoanalysis 0.11 Psychology0.36 Economy  0.11 Architecture0.36 Quality 0.11 Pure_Science0.36 PoliticsTable 2.
Final Domain Vector3.2 Obtaining the Positive Semantic TreesIn order to obtain the Positive Semantic Trees(PST) of the sentence, we will follow the sameprocess described in section 3.1.
In this case, theAR values will be replaced by the polarity valuepertaining to the analyzed sense.
The polarity isobtained from the SentiWordNet 3.0 resource,where each given sense from ISR-WN forWordNet version 2.0 is mapped to WordNetversion 3.0.
Hence, we can find each given sensefrom ISR-WN in SentiWordNet 3.0 and obtain therespective polarities.
This new value will be calledPositive Association (PosA).
The PosA value iscalculated using Equation 4 .
(4)Where:(5)Where C is a concept; f is a sentence or set ofwords (w); fi is a i-th word of the sentence f; PosA(C, wi) is the positive value of the sense (wi)related to C.The PosA is used to measure the positive valueassociated to the leaves of the Semantic Treeswhere Concepts are placed.
Subsequently, usingthe same structure of RST we create new SemanticTrees without AR values.
Instead, the leaves withConcepts of this new Semantic Trees will beannotated with the PosA value.Later, to assign some Positive value to theparent Concepts, each parent Concept willaccumulate the positive values from childConcepts.
Equation 6 shows the bottom-upprocess.
(6)Where PC is the Parent Concept; ChC is theChild Concept of PC; and PosA(ChC) representsthe positive value of the ChC.3.3 Obtaining the Negative Semantic Trees(NST)In this phase, we repeat the step described inSection 3.2, but for negative values.
Table 3 showsthe PST and NST obtained from the example.Vectors Pos-NegPosA NegA Domain PosA NegA Domain0.00 1.00 Social_Science  0.00 0.00 Buildings0.
00 0.00 Administration  0.00 0.50 Commerce0.00 0.00 Pedagogy  0.00 0.00 Environment0.00 0.00 Root_Domain  0.375 0.375 Factotum0.00 0.00 Psychoanalysis 0.00 0.00 Psychology0.00 0.50 Economy  0.00 0.00 Architecture0.375 0.375 Quality 0.00 0.00 Pure_Science0.00 0.00 PoliticsTable 3.
Final Domain Vectors Pos-NegAs we can see, the analyzed sentence is morelinked to the Social_Science domain and itaccumulates a negative value of 1 and a positivevalue of 0.
This indicates that the sentence is morenegative than positive.3.4 Obtaining polarities of the sentencesIn this step, we concentrate on detecting whichpolarity is more representative according to theSemantic Trees obtained for each resource(dimension).
For that, we combine the RST withPST and RST with NST.
Depending on the obtainedresults we classify the sentence as Positive,Negative or Neutral.
Before performing this step,we have to normalize the three types of SemanticTrees (RST, PST and NST) for each dimension towork with values between 0 and1.Our main goal is to assign more weight to thepolarities related to the most relevant Concepts ineach Relevant Semantic Tree.
Equation 7 showsthe steps followed in order to obtain the positivesemantic value.142(7)Where ACPosA is the Positive Semantic Valueof the analyzed sentence obtained for oneDimension, RST is the Relevant Semantic Treesorted with the format: RST [Concept| AR]; PST isthe Positive Semantic Tree sorted according RSTstructure with format: PST [Concept|PosA]; RSTiis the i-th AR value of Concept i;      PSTiis the i-th PosA value of the concept i.In order to measure the negative semantic value(ACNegA), we employ a similar equation replacingPST with NST.
After obtaining the semanticopinion requirements, we evaluate our approachover three of the tasks proposed in the NTCIR 8MOAT, for the monolingual English setting.3.5 Judging sentence opinionatednessThe ?opinionated?
subtask requires systems toassign the values YES or NO to each of thesentences in the document collection provided.This value is given depending on whether thesentence contains an opinion (Y) or it does not (N).In order to tackle this task, we analyze the PST andNST of all dimensions (WN, WSD, WNA, SUMOand SC).
After reviewing the PSTs and NSTs if atleast one Concept has assigned a value distinctfrom zero the result will be ?YES?
in other caseswill be ?NO?.3.6 Determining sentence relevanceIn the sentence relevance judgement task, thesystems have to decide whether a sentence isrelevant to the given question or not (Y|N).
Weassume that the given question is related to eachsentence per topic if it has a RST 50% similar (thesimilarity is obtained by quantity of Concept labelsthat match).
The analyzed sentence is relevant onlyif the PST and the NST values of all dimensionsthat are taken into account contain at least apositive or a negative value.3.7 Polarity and topic-polarity classificationThe polarity judgment task requires the systems toassign a value of ?POS?, ?NEG?
or ?NEU?
(positive, negative or neutral) to each of thesentences in the documents provided.Our proposal consists of accumulating theACPos values and ACNeg values of all Dimensionsand comparing them.
These accumulated valueswill be named ACPosD and ACNegD respectively.In case ACPosD > ACNegD the assigned value isPOS, if ACPosD < ACNegD the assigned value isNEG, otherwise, the assigned value is NEU.4 Evaluation and analysisIn this section we concentrated on measuring theinfluence of each Dimension (resource) takenseparately and jointly in our proposal.
Also, wehave compared our results with the best resultsobtained by the participant systems in the NTCIR8 MOAT competition.4.1 Influence of each dimensionIn this section, we present the results of the threetasks described above using the combination of alldimensions and using each of the resourcesseparately.
Moreover, we describe the experimentswe have performed.
Exp1: Combining allDimensions (WND, WNA, WN taxonomy, SUMOand SC).
Exp2: Using WNA.
Exp3: Using WND.Exp4: Using SC.
Exp5: Using SUMO.
Exp6:Using WN taxonomy.
The results are presented inTable 4.ExpOpinion Relevance PolarityP R F P R F P R F1 20.6 87.8 33.3 78.8 86.8 82.6 39.4 34.5 36.82 23.8 57.2 33.6 77.9 55.8 65.1 39.7 22.2 28.53 22.6 69.5 34.1 79.4 69.2 74.0 40.3 27.5 32.74 20.1 88.5 33.3 78.8 87.3 82.3 39.7 34.9 37.25 21.3 86.5 34.2 79.0 85.8 82.3 40.6 33.7 36.86 21.1 87.6 34.1 78.8 86.6 82.5 40.5 34.2 37.1Table 4.
Results on each task.
Precision (P), Recall (R)and F-Measure (F).As we can see, the best results are obtained inExperiment 4 and 6, which use the WN taxonomyand SC to obtain the RST, PST and NST.
However,the other experiments results are similar inperformance level.
This indicates that our proposalcan be successfully applied to opinion miningtasks.4.2 Influence of the semantic dimensionswithout normalizing the vectorIn order to prove that the value normalizationintroduces noise, we performed the sameexperiments without normalizing vectors.
In Table5, we show in bold font the F-Measure obtained143that constitutes an improvement to previousresults.
It is important to remark that notnormalizing the vectors helps the PolarityClassification task.
All the experiments presentedin Table 5 improved the previous results and theSC obtained one of the best results for the Polarityand the Relevance task.Exp Opinion Relevance PolarityP R F P R F P R F7 20.1 88.5 33.3 78.8 87.3 82.8 39.7 34.9 37.28 23.3 61.1 33.7 78.4 60.0 68.0 42.3 25.5 31.89 21.9 77.9 34.2 79.2 77.3 78.2 39.4 30.5 34.410 20.6 87.7 33.4 78.9 86.7 82.6 44.6 38.9 41.611 20.6 85.0 33.2 78.5 83.6 81.0 44.6 37.7 40.912 20.5 85.5 33.1 78.7 84.4 81.5 43.7 37.0 40.1Table 5.
Results without normalized vectors.
Precision(P), Recall (R) and F-Measure (F).4.3 Comparison with other proposalsIn this section, we present a comparison betweenour proposal and the best participating systems inNTCIR 8 MOAT.
In the sentence opinionatednessjudgement task , the only systems that obtainedbetter results compared to our proposal are UNINE(Zubaryeva and Savoy, 2010) and NECLCsystems.
These systems obtained F-measure valuesof 40.1% and 36.52% respectively.
These resultsare not so far from our results, with the simpledifference of 5.9% and 2.32% respectively.In comparison to our proposal, UNINE is basedon selecting terms that clearly belong to one typeof polarity compared to the others and the valuetypes of polarities are defined summing the countnumber of terms that tend to be overused inpositive, negative and neutral opinionatedsentences possibilities (Zubaryeva and Savoy,2010).
The opinionated score is the sum of PositiveScores and Negative Scores for each selected term.The score of non-opinionated sentences iscomputed as a sum of Objectivity Score for eachselected term, divided by the number of words inthe sentence.
Our proposal neither takes intoaccount the detection of relevant terms, nor theobjective scores.
UNINE also obtained betterresults than us in the Polarity task; we think thatthe combination of this proposal with ours couldobtain better results.
Taking into account that bothproposals use Features Extraction we couldcombine not only Lexical Features but alsoSemantic Features.In the Polarity task we could obtain similarresults to the first run of UNINE system around37% of F-measure but with results some distanceof the best system that obtained a 51.03% of F-measure.
For the relevance task, our proposalobtained a difference of 3.22% as far as F-measureis concerned from the best result of all runssubmitted by the National Taiwan University(NTU).
So, our proposal could be located aroundthe first places among the three tasks mentioned.5 Conclusion and further worksIn this paper our research was focused on solving arecent problem stemmed from the availability oflarge volumes of heterogeneous data whichprovides different kind of information.
We haveconducted an analysis of how the scientificcommunity confronts the tasks related to OpinionAnalysis.
One of the most used approaches is toapply Features Extraction and based on this idea,our proposal is to apply Semantic FeaturesExtraction based on Relevant Semantic Trees.With our proposal we are able to associate thepolarities presented on the sentences with ConceptSemantic Trees.
Thus, the Semantic Trees allowthe classification of sentences according to theiropinionatedness, relevance and polarity, accordingto MOAT competition.
The obtained results werecompared with the best results obtained on thiscompetition achieving values very close to the bestsystems.
Several experiments were conductedapplying vector normalization and withoutnormalization to know which semantic dimensionperformed better.After a comparative analysis with the systemswhich results were not improved, we propose asfurther work to include the lexical featuresextraction in our proposal.
We have planned to useLatent Semantic Analysis and other techniques todo this work.AcknowledgementsThis paper has been supported partially byMinisterio de Ciencia e Innovaci?n - SpanishGovernment (grant no.
TIN2009-13391-C04-01),and Conselleria d'Educaci?n - GeneralitatValenciana (grant no.
PROMETEO/2009/119,ACOMP/2010/288 and ACOMP/2011/001).144ReferencesAlexandra Balahur, Ester Boldrini, Andr?s Montoyoand Patricio Mart?nez-Barco.
2010.
The OpALSystem at NTCIR 8 MOAT.
In Proceedings ofNTCIR-8 Workshop Meeting: 241-245.
Tokyo,Japan.Alexandra Balahur and Andr?s Montoyo.
2009.
ASemantic Relatedness Approach to ClassifyingOpinion from Web Reviews.
Procesamiento delLenguaje Natural, 42:47-54.Andrea Esuli and Fabrizio Sebastiani.
2006.SentiWordNet: A Publicly Available LexicalResource for Opinion Mining.
In Fifth internationalconference on Languaje Resources and Evaluation417-422.Amal Zouaq, Michel Gagnon and Benoit Ozell.
2009.
ASUMO-based Semantic Analysis for KnowledgeExtraction.
In Proceedings of the 4th Language &Technology Conference.
Pozna?, Poland.Bernardo Magnini and Gabriela Cavaglia.
2000.Integrating Subject Field Codes into WordNet.
InProceedings of Third International Conference onLanguage Resources and Evaluation (LREC-2000):1413--1418.Bernardo Magnini, Carlo Strapparava, GiovanniPezzulo and Alfio Gliozzo.
2002.
ComparingOntology-Based and Corpus-Based DomainAnnotations in WordNet.
In Proceedings of the FirstInternational WordNet Conference: 21-25 Mysore,India.Bernardo Magnini, Carlo Strapparava, GiovanniPezzulo and Alfio Gliozzo.
2008.
Using DomainInformation for Word Sense Disambiguation.
InProceedings of the First International Conferenceon Emerging Trends in Engineering and Technology(icetet 2008): 1187-1191.
Nagpur, India.Christiane Fellbaum.
1998.
WordNet.
An ElectronicLexical Database.
The MIT Press.Guo-Hau Lai, Jyun-Wei Huang, Chia-Pei Gao andRichard Tzong-Han Tsai.
2010.
Enhance JapaneseOpinionated Sentence Identification using LinguisticFeatures: Experiences of the IISR Group at NTCIR-8 MOAT Task.
In Proceedings of NTCIR-8Workshop Meeting: 272-275.
Tokyo, Japan.Hatzivassiloglou, Vasileios and Janyce Wiebe.
2000.Effects of Adjective Orientation and Gradability onSentence Subjectivity.
In International Conferenceon Computational Linguistics (COLING-2000).Ian Niles.
2001.
Mapping WordNet to the SUMOOntology.
Teknowledge Corporation.Janyce Wiebe, Theresa Wilson and Claire Cardie.
2005.Annotating Expressions of Opinions and Emotionsin Language.
In Kluwer Academic Publishers:Netherlands.Luis Villarejo, Llu?s M?rquez and German Rigau.
2005.Exploring the construction of semantic classclassiers for WSD.
In Sociedad Espa?ola para elProcesamiento del Lenguaje Natural, 35: 195-202.Olena Zubaryeva and Jacques Savoy.
2010.
OpinionDetection by Combining Machine Learning &Linguistic Tools In Proceedings of NTCIR-8Workshop Meeting: 221-227.
Tokyo, Japan.Paul Ekman.
1999.
Handbook of Cognition andEmotion.
Handbook of Cognition and Emotion: JohnWiley & Sons, Ltd.Rub?n Izquierdo, Armando Su?rez and German Rigau.2007.
A Proposal of Automatic Selection of Coarse-grained Semantic Classes for WSD.
Procesamientodel Lenguaje Natural, 39:189-196.Rudi L. Cilibrasi and Paul M.B.
Vit?nyi.
2007.
TheGoogle Similarity Distance.
IEEE Transactions OnKnowledge And Data Engineering, 19(3).Soo-Min Kim and Eduard Hovy.
2006.
ExtractingOpinions, Opinion Holders, and Topics Expressed inOnline News Media Text.
In In Proceedings ofworkshop on sentiment and subjectivity in text atproceedings of the 21st international conference oncomputational linguistics/the 44th annual meeting ofthe association for computational linguistics(COLING/ACL 2006): 1-8.
Sydney, Australia.Soo-Min Kim and Eduard Hovy.
2005.
IdentifyingOpinion Holders for Question Answering in OpinionTexts.
In Proceedings of AAAI-05 Workshop onQuestion Answering in Restricted Domains.Sonia V?zquez, Andr?s Montoyo and German Rigau.2004.
Using Relevant Domains Resource for WordSense Disambiguation.
In IC-AI?04.
Proceedings ofthe International Conference on ArtificialIntelligence: Ed: CSREA Press.
Las Vegas,E.E.U.U.Yoan Guti?rrez, Antonio Fern?ndez, Andr?s Montoyoand Sonia V?zquez.
2010a.
UMCC-DLSI:Integrative resource for disambiguation task.
InProceedings of the 5th International Workshop onSemantic Evaluation: 427-432.
Uppsala, Sweden.Yoan Guti?rrez, Antonio Fern?ndez, Andr?s Montoyoand Sonia V?zquez.
2010b.
Integration of semanticresources based on WordNet.
In XXVI Congreso dela Sociedad Espa?ola para el Procesamiento delLenguaje Natural, 45: 161-168.
UniversidadPolit?cnica de Valencia, Valencia, Spain.145
