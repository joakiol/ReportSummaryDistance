Efficient probabilistic top-down and left-corner parsingtBr ian  Roark  and  Mark  JohnsonCognitive and Linguistic SciencesBox 1978, Brown UniversityProvidence, RI 02912, USAbrian-roark@brown, edu mj @cs.
brown, eduAbst rac tThis paper examines efficient predictive broad-coverage parsing without dynamic program-ming.
In contrast to bottom-up methods,depth-first op-down parsing produces partialparses that are fully connected trees spanningthe entire left context, from which any kind ofnon-local dependency or partial semantic inter-pretation can in principle be read.
We con-trast two predictive parsing approaches, top-down and left-corner parsing, and find both tobe viable.
In addition, we find that enhance-ment with non-local information ot only im-proves parser accuracy, but also substantiallyimproves the search efficiency.1 In t roduct ionStrong empirical evidence has been presentedover the past 15 years indicating that the hu-man sentence processing mechanism akes on-line use of contextual information i  the preced-ing discourse (Crain and Steedman, 1985; Alt-mann and Steedman, 1988; Britt, 1994) and inthe visual environment (Tanenhaus et al, 1995).These results lend support o Mark Steedman's(1989) "intuition" that sentence interpretationtakes place incrementally, and that partial in-terpretations are being built while the sentenceis being perceived.
This is a very commonlyheld view among psycholinguists today.Many possible models of human sentence pro-cessing can be made consistent with the aboveview, but the general assumption that must un-derlie them all is that explicit relationships be-tween lexical items in the sentence must be spec-ified incrementally.
Such a processing mecha-tThis material is based on work supported by theNational Science Foundation under Grant No.
SBR-9720368.nism stands in marked contrast o dynamic pro-gramming parsers, which delay construction ofaconstituent until all of its sub-constituents havebeen completed, and whose partial parses thusconsist of disconnected tree fragments.
For ex-ample, such parsers do not integrate a main verbinto the same tree structure as its subject NPuntil the VP has been completely parsed, andin many cases this is the final step of the entireparsing process.
Without explicit on-line inte-gration, it would be difficult (though not impos-sible) to produce partial interpretations on-line.Similarly, it may be difficult to use non-localstatistical dependencies (e.g.
between subjectand main verb) to actively guide such parsers.Our predictive parser does not use dynamicprogramming, but rather maintains fully con-nected trees spanning the entire left context,which make explicit the relationships betweenconstituents required for partial interpretation.The parser uses probabilistic best-first pars-ing methods to pursue the most likely analy-ses first, and a beam-search to avoid the non-termination problems typical of non-statisticaltop-down predictive parsers.There are two main results.
First, this ap-proach works and, with appropriate attentionto specific algorithmic details, is surprisinglyefficient.
Second, not just accuracy but alsoefficiency improves as the language model ismade more accurate.
This bodes well for fu-ture research into the use of other non-local (e.g.lexical and semantic) information to guide theparser.In addition, we show that the improvementin accuracy associated with left-corner parsingover top-down is attributable to the non-localinformation supplied by the strategy, and canthus be obtained through other methods thatutilize that same information.4212 Parser  a rch i tec tureThe parser proceeds incrementally from left toright, with one item of look-ahead.
Nodes areexpanded in a standard top-down, left-to-rightfashion.
The parser utilizes: (i) a probabilis-tic context-free grammar (PCFG), induced viastandard relative frequency estimation from acorpus of parse trees; and (ii) look-ahead prob-abilities as described below.
Multiple compet-ing partial parses (or analyses) are held on apriority queue, which we will call the pendingheap.
They are ranked by a figure of merit(FOM), which will be discussed below.
Eachanalysis has its own stack of nodes to be ex-panded, as well as a history, probability, andFOM.
The highest ranked analysis is poppedfrom the pending heap, and the category at thetop of its stack is expanded.
A category is ex-panded using every rule which could eventuallyreach the look-ahead terminal.
For every suchrule expansion, a new analysis is created 1 andpushed back onto the pending heap.The FOM for an analysis is the product of theprobabilities of all PCFG rules used in its deriva-tion and what we call its look-ahead probabil-ity (LAP).
The LAP approximates the productof the probabilities of the rules that will be re-quired to link the analysis in its current statewith the look-ahead terminal 2.
That is, for agrammar G, a stack state \[C1 ... C,\] and a look-ahead terminal item w:(1) LAP  --- PG(\[C1.
.
Cn\] -~ wa)We recursively estimate this with two empir-ically observed conditional probabilities for ev-ery non-terminal Ci on the stack: /~(Ci 2+ w)and/~(Ci  -~ e).
The LAP approximation for agiven stack state and look-ahead terminal is:(2) PG(\[Ci .
.. Ca\] wot) P(Ci w) +When the topmost stack category of an analy-sis matches the look-ahead terminal, the termi-nal is popped from the stack and the analysis1We count each of these as a parser state (or ruleexpansion) considered, which can be used as a measureof efficiency.2Since this is a non-lexicalized grammar, we are tak-ing pre-terminal POS markers as our terminal items.is pushed onto a second priority queue, whichwe will call the success heap.
Once there are"enough" analyses on the success heap, all thoseremaining on the pending heap are discarded.The success heap then becomes the pendingheap, and the look-ahead is moved forward tothe next item in the input string.
When the endof the input string is reached, the analysis withthe highest probability and an empty stack isreturned as the parse.
If no such parse is found,an error is returned.The specifics of the beam-search dictate howmany analyses on the success heap constitute"enough".
One approach is to set a constantbeam width, e.g.
10,000 analyses on the suc-cess heap, at which point the parser moves tothe next item in the input.
A problem withthis approach is that parses towards the bottomof the success heap may be so unlikely relativeto those at the top that they have little or nochance of becoming the most likely parse at theend of the day, causing wasted effort.
An al-ternative approach is to dynamically vary thebeam width by stipulating a factor, say 10 -5,and proceed until the best analysis on the pend-ing heap has an FOM less than 10 -5 times theprobability of the best analysis on the successheap.
Sometimes, however, the number of anal-yses that fall within such a range can be enor-mous, creating nearly as large of a processingburden as the first approach.
As a compromisebetween these two approaches, we stipulated abase beam factor a (usually 10-4), and the ac-tual beam factor used was a ?/~, where/3 is thenumber of analyses on the success heap.
Thus,when f~ is small, the beam stays relatively wide,to include as many analyses as possible; but as/3 grows, the beam narrows.
We found this tobe a simple and successful compromise.Of course, with a left recursive grammar, sucha top-down parser may never terminate.
Ifno analysis ever makes it to the success heap,then, however one defines the beam-search, atop-down depth-first search with a left-recursivegrammar will never terminate.
To avoid this,one must place an upper bound on the numberof analyses allowed to be pushed onto the pend-ing heap.
If that bound is exceeded, the parsefails.
With a left-corner strategy, which is notprey to left recursion, no such upper bound isnecessary.422(a) (b) (c) (d)NP NPDT+JJ+JJ NN DT NP-DTDT+JJ JJ cat the JJ NP-DT-JJDT JJ happy fat JJ NNI I I Ithe fat happy catNP NPDT NP-DT DT NP-DTlthe JJ NP-DT-JJ tLe JJ NP-DT-JJ_Jfat JJ NP-DT-JJ-JJ fiat JJ NP-DT-JJ-JJhappy NN happy NN NP-DT-JJ-JJ-NNI I Icat cat  eFigure 1: Binaxized trees: (a) left binaxized (LB); (b) right binaxized to binary (RB2); (c) rightbinaxized to unary (RB1); (d) right binarized to nullaxy (RB0)3 Grammar  t rans formsNijholt (1980) characterized parsing strategiesin terms of announce points: the point at whicha parent category is announced (identified) rel-ative to its children, and the point at which therule expanding the parent is identified.
In puretop-down parsing, a parent category and therule expanding it are announced before any ofits children.
In pure bottom-up parsing, theyare identified after all of the children.
Gram-mar transforms are one method for changingthe announce points.
In top-down parsing withan appropriately binaxized grammar, the pax-ent is identified before, but the rule expandingthe parent after, all of the children.
Left-cornerparsers announce a parent category and its ex-panding rule after its leftmost child has beencompleted, but before any of the other children.3.1 De lay ing  ru le  ident i f i cat ion  throughb inar i za t ionSuppose that the category on the top of thestack is an NP and there is a determiner (DT)in the look-ahead.
In such a situation, there isno information to distinguish between the rulesNP ~ DT J J  NN andNP- -+DT J J  NNS.If the decision can be delayed, however, untilsuch a time as the relevant pre-terminal is inthe look-ahead, the parser can make a more in-formed decision.
Grammar binaxization is oneway to do this, by allowing the parser to usea rule like NP --+ DT NP-DT,  where the newnon-terminal NP-DT can expand into anythingthat follows a DT in an NP.
The expansion ofNP-DT occurs only after the next pre-terminalis in the look-ahead.
Such a delay is essentialfor an efficient implementation of the kind ofincremental parser that we are proposing.There axe actually several ways to make agrammar binary, some of which are better thanothers for our parser.
The first distinction thatcan be drawn is between what we will call leftbinaxization (LB) versus right binaxization (RB,see figure 1).
In the former, the leftmost itemson the righthand-side of each rule are groupedtogether; in the latter, the rightmost items onthe righthand-side of the rule are grouped to-gether.
Notice that, for a top-down, left-to-rightparser, RB is the appropriate transform, be-cause it underspecifies the right siblings.
WithLB, a top-down parser must identify all of thesiblings before reaching the leftmost item, whichdoes not aid our purposes.Within RB transforms, however, there is somevariation, with respect o how long rule under-specification is maintained.
One method is tohave the final underspecified category rewrite asa binary rule (hereafter RB2, see figure lb).
An-other is to have the final underspecified categoryrewrite as a unary rule (RB1, figure lc).
Thelast is to have the final underspecified categoryrewrite as a nullaxy rule (RB0, figure ld).
No-tice that the original motivation for RB, to delayspecification until the relevant items are presentin the look-ahead, is not served by RB2, becausethe second child must be specified without beingpresent in the look-ahead.
RB0 pushes the look-ahead out to the first item in the string after theconstituent being expanded, which can be use-ful in deciding between rules of unequal length,e.g.
NP---+ DT NN and NP  ~ DT NN NN.Table 1 summarizes some trials demonstrat-423Binarization Rules in Percent of Avg.
States Avg.
Labelled Avg.
MLP Ratio of Avg.Grammar Sentences Considered Precision and Labelled Prob to Avg.Parsed* Recall t Prec/Rec t MLP Prob tNone 14962 34.16 19270 .65521 .76427 .001721LB 37955 33.99 96813 .65539 .76095 .001440I~B1 29851 91.27 10140 .71616 .72712 .340858RB0 41084 97.37 13868 .73207 .72327 .443705Beam Factor = 10 -4 *Length ~ 40 (2245 sentences in F23 Avg.
length -- 21.68) to f  those sentences parsedTable 1: The effect of different approaches to binarizationing the effect of different binarization ap-proaches on parser performance.
The gram-mars were induced from sections 2-21 of thePenn Wall St. Journal Treebank (Marcus etal., 1993), and tested on section 23.
For eachtransform tested, every tree in the training cor-pus was transformed before grammar induc-tion, resulting in a transformed PCFG and look-ahead probabilities estimated in the standardway.
Each parse returned by the parser was de-transformed for evaluation 3.
The parser usedin each trial was identical, with a base beamfactor c~ = 10 -4.
The performance is evaluatedusing these measures: (i) the percentage of can-didate sentences for which a parse was found(coverage); (ii) the average number of states(i.e.
rule expansions) considered per candidatesentence (efficiency); and (iii) the average la-belled precision and recall of those sentences forwhich a parse was found (accuracy).
We alsoused the same grammars with an exhaustive,bottom-up CKY parser, to ascertain both theaccuracy and probabil ity of the maximum like-lihood parse (MLP).
We can then additionallycompare the parser's performance to the MLP'son those same sentences.As expected, left binarization conferred nobenefit o our parser.
Right binarization, in con-trast, improved performance across the board.RB0 provided a substantial improvement in cov-erage and accuracy over RB1, with somethingof a decrease in efficiency.
This efficiency hitis partly attr ibutable to the fact that the sametree has more nodes with RB0.
Indeed, the effi-ciency improvement with right binarization overthe standard grammar is even more interestingin light of the great increase in the size of thegrammars.3See Johnson (1998) for details of the transform/de-transform paradigm.It is worth noting at this point that, with theRB0 grammar, this parser is now a viable broad-coverage statistical parser, with good coverage,accuracy, and efficiency 4.
Next we consideredthe left-corner parsing strategy.3.2 Lef t -corner  pars ingLeft-corner (LC) parsing (Rosenkrantz andLewis II, 1970) is a well-known strategy thatuses both bottom-up evidence (from the leftcorner of a rule) and top-down prediction (ofthe rest of the rule).
Rosenkrantz and Lewisshowed how to transform a context-free gram-mar into a grammar that, when used by a top-down parser, follows the same search path as anLC parser.
These LC grammars allow us to useexactly the same predictive parser to evaluatetop-down versus LC parsing.
Naturally, an LCgrammar performs best with our parser whenright binarized, for the same reasons outlinedabove.
We use transform composition to applyfirst one transform, then another to the outputof the first.
We denote this A o B where (A oB) (t) = B (A (t)).
After applying the left-cornertransform, we then binarize the resulting gram-mar 5, i.e.
LC o RB.Another probabilistic LC parser investigated(Manning and Carpenter, 1997), which uti-lized an LC parsing architecture (not a trans-formed grammar), also got a performance boost4The very efficient bottom-up statistical parser de-tailed in Charniak et al (1998) measured efficiency interms of total edges popped.
An edge (or, in our case, aparser state) is considered when a probability is calcu-lated for it, and we felt that this was a better efficiencymeasure than simply those popped.
As a baseline, theirparser considered an average of 2216 edges per sentencein section 22 of the WSJ corpus (p.c.
).5Given that the LC transform involves nullary pro-ductions, the use of RB0 is not needed, i.e.
nullary pro-ductions need only be introduced from one source.
Thusbinarization with left corner is always to unary (RB1).424Transform Rules in Pct.
of Avg.
States Avg Labelled Avg.
MLP Ratio of Avg.Grammar Sentences Considered Precision and Labelled Prob to Avg.Parsed* Recall t Prec/Rec t MLP Prob tLeft Corner (LC) 21797 91.75 9000 .76399 .78156 .175928LB o LC 53026 96.75 7865 .77815 .78056 .359828LC o RB 53494 96.7 8125 .77830 .78066 .359439LC o RB o ANN 55094 96.21 7945 .77854 .78094 .346778RB o LC 86007 93.38 4675 .76120 .80529*Length _ 40 (2245 sentences in F23 - Avg.
length ---- 21.68 Beam Factor ---- 10  -4.267330tOf those sentences parsedTable 2: Left Corner Resultsthrough right binarization.
This, however, isequivalent o RB o LC, which is a very differ-ent grammar from LC o RB.
Given our two bi-narization orientations (LB and RB), there arefour possible compositions of binarization andLC transforms:(a) LB o LC (b) RB o LC (c) LC o LB (d) LC o RBTable 2 shows left-corner results over variousconditions 6.
Interestingly, options (a) and (d)encode the same information, leading to nearlyidentical performance 7.
As stated before, rightbinarization moves the rule announce pointfrom before to after all of the children.
TheLC transform is such that LC o RB also delaysparent identification until after all of the chil-dren.
The transform LC o RB o ANN moves theparent announce point back to the left corner byintroducing unary rules at the left corner thatsimply identify the parent of the binarized rule.This allows us to test the effect of the position ofthe parent announce point on the performanceof the parser.
As we can see, however, the ef-fect is slight, with similar performance on allmeasures.RB o LC performs with higher accuracy thanthe others when used with an exhaustive parser,but seems to require a massive beam in order toeven approach performance at the MLP level.Manning and Carpenter (1997) used a beamwidth of 40,000 parses on the success heap ateach input item, which must have resulted in anorder of magnitude more rule expansions thanwhat we have been considering up to now, and6Option (c) is not the appropr iate  k ind of b inar izat ionfor our parser, as argued in the previous section, and sois omitted.7The difference is due to the int roduct ion of vacuousunary  rules with RB.yet their average labelled precision and recall(.7875) still fell well below what we found to bethe MLP accuracy (.7987) for the grammar.
Weare still investigating why this grammar func-tions so poorly when used by an incrementalparser.3.3 Non- loca l  annotat ionJohnson (1998) discusses the improvement ofPCFG models via the annotation of non-local in-formation onto non-terminal nodes in the treesof the training corpus.
One simple exampleis to copy the parent node onto every non-terminal, e.g.
the rule S ~ NP  VP  becomesS ~ NP~S VP~S.
The idea here is that thedistribution of rules of expansion of a particularnon-terminal may differ depending on the non-terminal's parent.
Indeed, it was shown thatthis additional information improves the MLPaccuracy dramatically.We looked at two kinds of non-local infor-mation annotation: parent (PA) and left-corner(LCA).
Left-corner parsing gives improved accu-racy over top-down or bottom-up parsing withthe same grammar.
Why?
One reason may bethat the ancestor category exerts the same kindof non-local influence upon the parser that theparent category does in parent annotation.
Totest this, we annotated the left-corner ancestorcategory onto every leftmost non-terminal cat-egory.
The results of our annotation trials areshown in table 3.There are two important points to notice fromthese results.
First, with PA we get not only thepreviously reported improvement in accuracy,but additionally a fairly dramatic decrease inthe number of parser states that must be vis-ited to find a parse.
That is, the non-local in-formation not only improves the final product ofthe parse, but it guides the parser more quickly425Transform Rules in Pct.
of Avg.
States Avg Labelled Avg.
MLP Ratio of Avg.Grammar Sentences Considered Precision and Labelled Prob to Avg.Parsed* Recall t Prec/Rec t MLP Prob tRB0 41084 97.37 13868 .73207 .72327 .443705PA o RB0 63467 95.19 8596 .79188 .79759 .486995LC o RB 53494 96.7 8125 .77830 .78066 .359439LCA o RB0 58669 96.48 11158 .77476 .78058 .495912PA o LC o RB 80245 93.52 4455 .81144 .81833 .484428Beam Factor -- 10 -4 *Length ~ 40 (2245 sentences in F23 - Avg.
length -= 21.68) tOf those sentences parsedTable 3: Non-local annotation resultsto the final product.
The annotated grammarhas 1.5 times as many rules, and would slowa bottom-up CKY parser proportionally.
Yetour parser actually considers far fewer states enroute to the more accurate parse.Second, LC-annotation gives nearly all of theaccuracy gain of left-corner parsing s, in supportof the hypothesis that the ancestor informationwas responsible for the observed accuracy im-provement.
This result suggests that if we candetermine the information that is being anno-tated by the troublesome RB o LC transform,we may be able to get the accuracy improve-ment with a relatively narrow beam.
Parent-annotation before the LC transform gave us thebest performance of all, with very few statesconsidered on average, and excellent accuracyfor a non-lexicalized grammar.4 Accuracy /E f f i c iency  t radeof fOne point that deserves to be made is that thereis something of an accuracy/efficiency tradeoffwith regards to the base beam factor.
The re-sults given so far were at 10 -4 , which func-tions pretty well for the transforms we haveinvestigated.
Figures 2 and 3 show four per-formance measures for four of our transformsat base beam factors of 10 -3 , 10 -4 , 10 -5 , and10 -6.
There is a dramatically increasing effi-ciency burden as the beam widens, with vary-ing degrees of payoff.
With the top-down trans-forms (RB0 and PA o RB0), the ratio of the av-erage probabil ity to the MLP probability doesimprove substantially as the beam grows, yetwith only marginal improvements in coverageand accuracy.
Increasing the beam seems to doless with the left-corner transforms.SThe rest could very well be within noise.5 Conc lus ions  and  Future  ResearchWe have examined several probabilistic predic-tive parser variations, and have shown the ap-proach in general to be a viable one, both interms of the quality of the parses, and the ef-ficiency with which they are found.
We haveshown that the improvement of the grammarswith non-local information not only results inbetter parses, but guides the parser to themmuch more efficiently, in contrast to dynamicprogramming methods.
Finally, we have shownthat the accuracy improvement that has beendemonstrated with left-corner approaches canbe attr ibuted to the non-local information uti-lized by the method.This is relevant to the study of the humansentence processing mechanism insofar as itdemonstrates that it is possible to have a modelwhich makes explicit the syntactic relationshipsbetween items in the input incrementally, whilestill scaling up to broad-coverage.Future research will include:?
lexicalization of the parser?
utilization of fully connected trees for ad-ditional syntactic and semantic processing?
the use of syntactic predictions in the beamfor language modeling?
an examination of predictive parsing witha left-branching language (e.g.
German)In addition, it may be of interest to the psy-cholinguistic ommunity if we introduce a timevariable into our model, and use it to comparesuch competing sentence processing models asrace-based and competition-based parsing.Re ferencesG.
Altmann and M. Steedman.
1988.
Interac-tion with context during human sentence pro-cessing.
Cognition, 30:198-238.426x lO  4 Average States Considered per Sentence98969414 i iRB0.
.
.
.
.
.
LC  0 RB12 - - - PA  0 RB0.
.
.
.
.
PA 0 LC  0 RB10864 q " -0r -10 -3 10 .-4 Base Beam Factor 10 -s  10-6Percentage of Sentences Parsed100RB0.
.
.
.
.
.
LC  o RB- - - PAo  RB0 ~ .,,, ,  =............... PAoLCoRB ~,~"~,.....,.,"'~, .
.
.
.
.
.
.
.
~ ~ .92 ~ ,4"~90880_ 3 I =10 ..4 Base Beam Factor 10 -5 10 -6Figure 2: Changes in performance with beam factor variationM.
Britt.
1994.
The interaction of referentialambiguity and argument structure.
Journalo/ Memory and Language, 33:251-283.E.
Charniak, S. Goldwater, and M. Johnson.1998.
Edge-based best-first chart parsing.
InProceedings of the Sixth Workshop on VeryLarge Corpora, pages 127-133.S.
Crain and M. Steedman.
1985.
On not be-ing led up the garden path: The use of con-text by the psychological parser.
In D. Dowty,L.
Karttunen, and A. Zwicky, editors, Natu-ral Language Parsing.
Cambridge UniversityPress, Cambridge, UK.M.
Johnson.
1998.
PCFG models of linguistictree representations.
Computational Linguis-tics, 24:617-636.C.
Manning and B. Carpenter.
1997.
Prob-abilistic parsing using left corner languagemodels.
In Proceedings of the Fifth Interna-tional Workshop on Parsing Technologies.427Average  Labelled Precision and Recal l82 , ,81807978o~ 7~(1.767574737210"-30.650.60.550.5.o0,45 rr0 .40.350.30.2510 -3RB0.
.
.
.
.
.
LC o RB- - - PAo RB0PA O LC  o RBi10 -4iBase Beam Factor 10-6  10 -sAverage Ratio of Parse Probabil ity to Maximum Likelihood Probability, RB0 -' '.
.
.
.
.
.
LC o RB- - - PAo  RB0 / ~ ~.
- "I I10 -4 Base Beam Factor 10 -s 10 -6Figure 3: Changes in performance with beam factor variationM.P.
Marcus, B. Santorini, and M.A.Marcinkiewicz.
1993.
Building a largeannotated corpus of English: The PennTreebank.
Computational Linguistics,19(2):313-330.A.
Nijholt.
1980.
Context-/tee Grammars: Cov-ers, Normal Forms, and Parsing.
SpringerVerlag, Berlin.S.J.
Rosenkrantz and P.M. Lewis II.
1970.
De-terministic left corner parsing.
In IEEE Con-ference Record of the 11th Annual Symposiumon Switching and Automata, pages 139-152.M.
Steedman.
1989.
Grammar, interpreta-tion, and processing from the lexicon.
InW.
Marslen-Wilson, editor, Lexical represen-tation and process.
MIT Press, Cambridge,MA.M.
Tanenhaus, M. Spivey-Knowlton, K. Eber-hard, and J. Sedivy.
1995.
Integration of vi-sual and linguistic information during spokenlanguage comprehension.
Science, 268:1632-1634.428
