Interleaved semantic interpretation in environment-based parsingWilliam SchulerComputer and Information Science Dept.University of PennsylvaniaPhiladelphia, PA 19103schuler@linc.cis.upenn.eduAbstractThis paper extends a polynomial-time parsing al-gorithm that resolves structural ambiguity in inputsentences by calculating and comparing the deno-tations of rival constituents, given some model ofthe application environment (Schuler, 2001).
Thealgorithm is extended to incorporate a full set oflogical operators, including quantiers and conjunc-tions, into this calculation without increasing thecomplexity of the overall algorithm beyond polyno-mial time, both in terms of the length of the in-put and the number of entities in the environmentmodel.1 IntroductionThe development of speaker-independent mixed-initiative speech interfaces, in which users not onlyanswer questions but also ask questions and give in-structions, is currently limited by the inadequacyof existing corpus-based disambiguation techniques.This paper explores the use of semantic and prag-matic information, in the form of the entities andrelations in the interfaced application's run-time en-vironment, as an additional source of information toguide disambiguation.In particular, this paper extends an existing pars-ing algorithm that calculates and compares the de-notations of rival parse tree constituents in orderto resolve structural ambiguity in input sentences(Schuler, 2001).
The algorithm is extended to incor-porate a full set of logical operators into this calcu-lation so as to improve the accuracy of the resultingdenotations { and thereby improve the accuracy ofparsing { without increasing the complexity of theoverall algorithm beyond polynomial time (both interms of the length of the input and the number ofentities in the environment model).
This parsimonyis achieved by localizing certain kinds of semanticrelations during parsing, particularly those betweenquantiers and their restrictor and body argumentsThe author would like to thank David Chiang, Karin Kip-per, and Alexander Koller, as well as the anonymous reviewersfor comments on this material.
This work was partially sup-ported by NSF IIS-9900297 and DARPA N66001-00-1-8915.
(similar to the way dependencies between predicateand argument head words are localized in lexicalizedformalisms such as tree adjoining grammars), in or-der to avoid calculating exponential higher-order de-notations for expressions like generalized quantiers.2 Basic algorithmThis section describes the basic environment-basedparser (Schuler, 2001) which will be extended in Sec-tion 3.
Because it will crucially rely on the denota-tions (or interpretations) of proposed constituentsin order to guide disambiguation, the parser will bedened on categorial grammars (Ajdukiewicz, 1935;Bar-Hillel, 1953), whose categories all have well de-ned types and worst-case denotations.
These cat-egories are drawn from a minimal set of symbols Csuch that:NP 2 C and S 2 C;if; ?
2 C then=?
2 C andn?
2 C:Intuitively, the category NP describes a noun phraseand the category S describes a sentence, and thecomplex categories=?
andn?
describe `alackinga ?
to the right' and `alacking a ?
to the left'respectively; so for example SnNP would describe adeclarative verb phrase lacking an NP subject to itsleft in the input.The type T and worst-case (most general) denota-tion W of each possible category are dened below,given a set of entities E as an environment:T (S) = t : truth value W (S) = fTRUE;FALSEgT (NP) = e : entity W (NP) = ET (=?)
= hT (?
); T ()i W (=?)
= W (?)
W ()T (n?)
= hT (?
); T ()i W (n?)
= W (?)
W ()The denotation D of any proposed constituent isconstrained to be a subset of the worst-case deno-tation W of the constituent's category; so a con-stituent of category NP would denote a set of en-tities, fe1; e2; : : : g, and a constituent of categorySnNP would denote a set of entity  truth valuepairs, fhe1;TRUEi; he2;FALSEi; : : : g. Note that nodenotation of a constituent can contain more thanO(jEjv) dierent elements, where v is a valency mea-sure of the number of NP symbols occurring withinthe constituent's category.This paper will use the following denition of acategorial grammar (CG):Denition A categorial grammar G is a formalgrammar (N;; P ) such that:  is a nite set of words w; P is a nite set of productions containing:!
w for all w2, with2 C,!=?
?
for every rule=?
!
: : : in P ,!
?n?
for every rulen?
!
: : : in P ,and nothing else; N is the nonterminal set fj!
: : : 2 Pg.and the following deductive parser,1which will beextended later to handle a richer set of semantic op-erations.
The parser is dened with: constituent chart items [i; j;] drawn from In0In0N , indicating that positions i through j inthe input can be characterized by category; a lexical item [i; j;] for every rule!
w 2 P ifw occurs between positions i and j in the input; a set of rules of the form:[i;k;=?]
[k;j;?
][i;j;]for all!=?
?
2 P; i; j; k 2 In0,[k;j;n?]
[i;k;?
][i;j;]for all!
?n?
2 P; i; j; k 2 In0.and can recognize an n-length input as a constituentof category(for example, as an S) if it can deducethe chart item [0; n;].This parser can be implemented in a dynamic pro-gramming algorithm, using the recursive function:F (x) =_a1::: aks:t:a1::: akxk^i=1F (ai)(where x; a1: : : akare proposed constituents drawnfrom In0In0N ,W;= FALSE, andV;= TRUE),by recording the result of every recursive sub-call toF (x) in a chart, then consulting this chart on sub-sequent calls to F (x) for the same x constituent.2Since the indices in every rule's antecedent con-stituents a1: : : akeach cover smaller spans thanthose in the consequent x, the algorithm will notenter into an innite recursion; and since there areonly n2jN j dierent values of x, and only 2n dier-ent rules that could prove any consequent x (two ruleforms for = and n, each with n dierent values of k),the algorithm runs in polynomial time: O(n3jN j).The resulting chart can then be annotated with backpointers to produce a polynomial-sized shared forest1Following Shieber et al (1995).2Following Goodman (1999).representation of all possible grammatical trees (Bil-lot and Lang, 1989).Traditional corpus-based parsers select preferredtrees from such forests by calculating Viterbi scoresfor each proposed constituent, according to the re-cursive function:SV(x) = maxa1::: aks:t:a1::: akxkYi=1SV(ai)! P(a1::: akj x)These scores can be calculated in polynomial time,using the same dynamic programming algorithm asthat described for parsing.
A tree can then be se-lected, from the top down, by expanding the highest-scoring rule application for each constituent.The environment-based parser described here usesa similar mechanism to select preferred trees, but thescores are based on the presence or absence of enti-ties in the denotation (interpretation) of each pro-posed constituent:3SD(x) = maxa1::: aks:t:a1::: akxkXi=1SD(ai)!+(1 if D(x) 6=;0 otherwisewhere the denotation D(x) of a proposed constituentx is calculated using another recursive function:D(x) =[a1::: aks:t:a1::: akxkoni=1D(ai)!on(R(x) if k = 0fhig otherwisein which R(x) is a lexical relation dened for eachaxiom x of categoryequal to some subset of'sworst-case denotation W (), as dened above.4Theoperator on is natural (relational) join on the eldsof its operands:AonB = fhe1:::emax(a;b)i j he1:::eai2A; he1:::ebi2Bgwhere a; b  0; and  is a projection that removesthe rst element of the result (corresponding themost recently discharged argument of the head orfunctor category):A = fhe2:::eai j he1:::eai2AgThis interleaving of semantic evaluation and pars-ing for the purpose of disambiguation has much incommon with that of Dowding et al (1994), except3Here, the score is simply equal to the number of non-empty constituents in an analysis, but other metrics are pos-sible.4So a lexical relation for the constituent `lemon' ofcategory NP would contain all and only the lemons inthe environment, and a lexical relation for the con-stituent `falling' of category SnNP would contain a map-ping from every entity in the environment to some truthvalue (TRUE if that entity is falling, FALSE otherwise):e.g.
fhlemon1; TRUEi; hlemon2; FALSEi; : : : g.NP[lemon]fl1; l2; l3; l4gP:NPnNP/NP[in]fhb1; hl1; l1ii; hm1; hl2; l2iigNP[bin]fb1; b2gP:NPnNP/NP[by]fhm1; hb1; b1ii; hm2; hb2; b2iigNP[machine]fm1;m2;m3gPP:NPnNP[in]fhl1; l1igPP:NPnNP[by]fhb1; b1i; hb2; b2igNP[lemon]fl1gNP[bin]fb1; b2gPP:NPnNP[in]fhl1; l1igNP[lemon]fl1g [ ;Figure 1: Denotation-annotated forest for `lemon in bin by machine.
'that in this case, constituents are not only seman-tically type-checked, but are also fully interpretedeach time they are proposed.Figure 1 shows a sample denotation-annotatedforest for the phrase `the lemon in the bin by themachine', using the lexicalized grammar:lemon, bin, machine : NPthe : NP=NPin, by : NPnNP=NPin which the denotation of each constituent (the setin each rectangle) is calculated using a join on thedenotations of each pair of constituents that combineto produce it.
In this example, the right-branchingtree would be preferred because the denotation re-sulting from the composition at the root of the othertree would be empty.Since this use of the join operation is linear on thesum of the cardinalities of its operands, and sincethe denotations of the categories in a grammar Gare bounded in cardinality by O(jEjv) where v is themaximum valency of the categories in G, the totalcomplexity of the above algorithm can be shown tobe O(n3jEjv): polynomial not only on the length ofthe input n, but also on the size of the environment E(Schuler, 2001).3 Extended algorithmThe above algorithm works well for attaching ordi-nary complements and modiers, but as a semantictheory it is not su?ciently expressive to produce cor-rect denotations in all cases.
For example, the lexicalrelations dened above are insu?cient to representquantiers like `no' (using category NP=NP) in thephrase `the boy with no backpack.
'5A similar prob-lem occurs with conjunctions; for example, the word`and' (using category NPnNP=NP) in the phrase `thechild wearing glasses and blue pants', also cannotbe properly represented as a lexical relation.6Thisraises the question: how much expressivity can beallowed in a shared semantic interpretation withoutexceeding the tractable parsing complexity neces-sary for practical environment-based parsing?In traditional categorial semantics (Montague,1973; Barwise and Cooper, 1981; Keenan and Stavi,1986) quantiers and noun phrase conjunctions de-note higher-order relations: that is, relations be-tween whole sets of entities instead of just be-tween individuals.
Under this interpretation, aquantier like `no' would denote a set of pairsfhA1; B1i; hA2; B2i; : : : g where each Aiand Biaredisjoint subsets of E , corresponding to an accept-able pair of restrictor and body sets satisfying thequantier `no'.
Unfortunately, since the cardinalitiesof these higher-order denotations can be exponentialon the size of the environment E (there are 2jEjpos-sible subsets of E and 22jEjpossible combinations oftwo such subsets), such an approach would destroythe polynomial complexity of the environment-basedparsing algorithm.5Assigning the identity relation fhe1; e1i; he2; e2i; : : : g tothe quantier would incorrectly yield the set of boys with abackpack as a denotation for the full noun phrase; and assign-ing the converse relation (from each entity in the environmentto every other entity fhe1; e2i; he1; e3i; : : : g) would incorrectlyyield the set of boys with anything that is not a backpack.6The identity relation fhe1; e1; e1i; he2; e2; e2i; : : : g, whichyields a correct interpretation in verb phrase conjunction,would yield an incorrect denotation for the noun phrase`glasses and blue pants,' containing only entities which areat once both glasses and pants.However, if the number of possible higher-orderfunctions is restricted to a nite set (say, to somesubset of words in a lexicon), it becomes tractableto store them by name rather than by denotation(i.e.
as sets).
Such function can then discharge alltheir rst-order arguments in a single derivationalstep to produce a rst-order result, in order to avoidgenerating or evaluating any higher-order partial re-sults.
Syntactically, this would be analogous to com-posing a quantier with both a noun phrase restric-tor and a body predicate (e.g.
a verb or verb phrase)at the same time, to produce another rst-orderpredicate (e.g.
a verb phrase or sentence).
Sincea generalized quantier function merely counts andcompares the cardinalities of its arguments in a lin-ear time operation, this analysis provides a tractableshortcut to the exponential calculations required inthe conventional analysis.Note that this analysis by itself does not admitproductive modication of quantiers (because theirfunctions are drawn from some nite set) or of quan-tied noun phrases (because they are no longer de-rived as a partial result).
This causes no disruptionto the attachment of non-conjunctive modiers, be-cause ordinary syntactic modiers of quantier con-stituents are seldom productive (in the sense thattheir composition does not yield functions outsidesome nite set), and syntactic modiers of NP con-stituents usually only modify the restrictor set of thequantier rather than the entire quantied function,and can therefore safely be taken to attach belowthe quantier, to the unquantied NP.But this is not true in cases involving conjunc-tion.
Conjoined quantiers, like `some but not all,'cannot always be dened using a single standard lex-ical function; and conjunctions of quantied nounphrases, like `one orange and one lemon', cannotbe applied to unquantied subconstituents (syntac-tically, because this would fail to subsume the sec-ond quantier, and semantically, because it is notthe restrictor sets which are conjoined).
Keenanand Stavi (1986) model conjunctions of quantiersand quantied noun phrases using lattice operationson higher-order sets, but as previously stated, thesehigher-order sets preclude tractable interleaving ofsemantic interpretation with parsing.The solution proposed here is to treat each quan-tier or quantied noun phrase conjunction as an el-liptical conjunction of two complete rst-order pred-icates (e.g.
verb phrases or sentences), each subsum-ing a dierent quantier and noun phrase restrictor(in the case of NP conjunction), but sharing or du-plicating a common body predicate.
This analysisrequires multiple components to keep track of theduplicated material above the conjunction, but aslong as the number of components is bounded, thepolynomial complexity of the parsing algorithm iscontaining(duplicated)one orange(unduplicated)and one lemon(unduplicated)Figure 2: Duplicated verb in NP conjunction.retained.7Figure 2 shows a duplicated verb predicate in thederivation of an NP conjunction.
The conjoinedconstituents (the shaded regions in the gure) areeach composed of two components: one for the NPitself, containing the quantier and the restrictorpredicate, and one for the verb which supplies thebody predicate of the quantier.
Since the conjoinedconstituents both correspond to complete quanti-er expressions with no unsatised rst-order argu-ments, their categories are that of simple rst-orderpredicates (they are each complete verb phrases inessence: `containing one orange' and `containing onelemon').
The conjunction then forms a larger con-stituent of the same form (the unshaded outlinein the gure), with a lower component containingthe conjoined constituents' NP components concate-nated in the usual way, and an upper component inwhich the conjoined constituents' non-NP compo-nents are identied or overlapped.
If the duplicatedcomponents do not cover the same string yield, theconjunction does not apply.Note that, since they are only applied to ordinaryrst-order predicates (e.g.
sentences or verb phrases)in this analysis, conjunctions can now safely be as-signed the familiar truth-functional denotations inevery case.8Also, since the resulting constituenthas the same number of components as the conjoinedconstituents, there is nothing to prevent its use asan argument in subsequent conjunction operations.A sample multi-component analysis for quantiersis shown below, allowing material to be duplicatedboth to the left and to the right of a conjoined NP:some,all,no,etc.
: XnNPq NPqnNPqNPq=NPX=NPq NPqnNPqNPq=NPThe lexical entry for a quantier can be split in this7Dahl and McCord (1983) propose a similar duplicationmechanism to produce appropriate semantic representationsfor NP and other conjunctions, but for dierent reasons.8e.g.
for the word `and': fh:::TRUE; :::TRUE; :::TRUEi;h::TRUE; ::FALSE; ::FALSEi; h::FALSE; ::TRUE; ::FALSEi;h::FALSE; ::FALSE; ::FALSEigway into a number of components, the last (or low-est) of which is not duplicated in conjunction whileothers may or may not be.
These include a com-ponent for the quantier NPq=NP(which will ulti-mately also contain a noun phrase restrictor of cate-gory NP), a component for restrictor PPs and rela-tive clauses of category NPqnNPqthat are attachedabove the quantier and duplicated in the conjunc-tion, and a component for the body (a verb or verbphrase or other predicate) of category XnNPqorX=NPq.
The subscript q species one of a niteset of quantiers, and the subscript  indicates anunquantied NP.The deductive parser presented in Section 2 cannow be extended by incorporating sequences of rec-ognized and unrecognized components into the con-stituent chart items.
As constituents are com-posed, components are shifted from the unrecog-nized sequence1  cto the recognized sequencehi1; j1;1i    hic; jc;ci, until the unrecognized se-quence is empty.The extended parser is dened with: chart items of the form [i; j;;], where  isa sequence of unrecognized components,  isa sequence of recognized components ha; b;i,and i; j; k; a; b; c are indices in the input.
Eachitem [i; j;; hi1; j1;1i    hic; jc;ci] indicatesthat the span from i to j in the input can becharacterized by the categories1throughcatpositions i1to j1through icto jcrespectively, sothat if these spans are concatenated in whateverorder they occur in the input string, they forma grammatical constituent of categorywithunrecognized components . a lexical item [i; j;; hi; j;i] for every rule!w 2 P if w occurs between positions i and j inthe input; a set of rules for all i; j; k; a; b; c 2 In0as below.Two rules to invoke left and right function ap-plication to an existing component:[i;k;=?
;hi;k;=?i] [k;j;?;hk;b;?="i][i;j;;hi;b;="i]!=?
?2P ,[k;j;n?
;hk;j;n?i] [i;k;?;ha;k;?n"i][i;j;;ha;j;n"i]!
?n?2P ,Two rules to invoke left and right function ap-plication to a fresh component:[i;k;=?
;hi;k;=?i] [k;j;=??;][i;j;;hi;k;=?i]!=?
?2P ,[k;j;n?
;hk;j;n?i] [i;k;n??;][i;j;;hk;j;n?i]!
?n?2P ,Two rules to discharge empty components:[i;j;=??;][i;j;;][i;j;n??
;][i;j;;]Three rules to skip conjunctions, by adding agap between the components in a constituent(the rst rule consumes the conjunction to cre-ate a partial result of category Conj0?, and thelatter two use this to skip the opposing NP):[k;j;?;][i;j;Conj0?;][i;k;Conj;hi;k;Conji][k;j;Conj0?;][i;j;?;][i;k;?
; ][i;k;?;][i;j;?;][k;j;Conj0?
; ]Two rules to reassemble discontinuous con-stituents (again, using a partial result Conj0?toreduce the number of ranging variables):[a;c;Conj;ha;c;Conji] [i;j;;hc;b;?i][i;j;;ha;b;Conj0?i][i;j;;hc;b;Conj0?i] [i;j;;ha;c;?i][i;j;;ha;b;?i]Two rules to combine adjacent components:[i;j;;ha;c;?="ihc;b;"i][i;j;;ha;b;?i][i;j;;hc;b;?n"iha;c;"i][i;j;;ha;b;?i]And one rule to apply quantier functions:[i;j;;ha;b;?qi][i;j;;ha;b;?i]The parsing and scoring functions remain identi-cal to those in Section 2, but an additional k = 1case containing a modied projection function  isnow added to the interpretation function, in orderto make the denotations of quantied constituentsdepend on their associated quantiers:D(x) =[a1::: aks:t:a1::: akx8>>>>>><>>>>>>>:R(x) if k = 0qD(a1) if k = 1 anda1x=[:::h:::?qi][:::h:::?i]koni=1D(ai) otherwiseThe modied projection function evaluates a quan-tier function q on some argument denotation A,comparing the cardinality of the image of the re-strictor set in A with the the cardinality of image ofthe intersected restrictor and body sets in A:9qA = fhe2:::ea; ti j h ; e2:::ea; i2A; t = q(jRj; jSj)R = Aonfh ; e2:::ea; ig;S = Aonfh ; e2:::ea;TRUEig gThis algorithm parses a categorial grammar in theusual way { constituents are initially added to thechart as single components covering a certain yieldin the input string (the indices of the componentare the same as the indices of the constituent itself),and they are combined by concatenating the yieldsof smaller constituents to make larger ones { until aconjunction is encountered.
When a conjunction is9Following Keenan and Stavi (1986).0 1 2 3 4containing one orange and one lemon[0; 1; SnNPq=NPq0; [1; 2; XnNP9 NP9nNP9 NP9; [2; 3;Conj; [3; 4; XnNP9 NP9nNP9 NP9;h0; 1; SnNPq=NPq0i] h1; 2;NP9i] fo1; o2; o3; o4g h2; 3;Conji] h3; 4;NP9i] fl1; l2; l3gfho1; x1i; hl2; x1i; hl3; x3ig.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(1)[1; 4; XnNP9 NP9nNP9 NP9; h1; 2; NP9i] fo1; o2; o3; o4g.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(2)[1; 4; XnNP9 NP9nNP9 NP9; h3; 4; NP9i] fl1; l2; l3g.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(3)[1; 4; XnNP9 NP9; h1; 2; NP9i] fo1; o2; o3; o4g.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(4)[1; 4; XnNP9 NP9; h3; 4; NP9i] fl1; l2; l3g.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(5)[0; 4; SnNPq; h0; 1; SnNPq=NP9i  h1; 2;NP9i] fho1; x1ig.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(6)[0; 4; SnNPq; h0; 1; SnNPq=NP9i  h3; 4;NP9i] fhl2; x1i; hl3; x3ig.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(7)[0; 4; SnNPq; h0; 1; SnNPq=NPi  h1; 2;NPi] fx1g.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(8)[0; 4; SnNPq; h0; 1; SnNPq=NPi  h3; 4;NPi] fx1; x3g(9)[0; 4; SnNPq; h0; 1; SnNPq=NPi  h1; 4;NPi] fx1g(10)[0; 4; SnNPq; h0; 4; SnNPqi] fx1gFigure 3: Sample derivation of conjoined NP.encountered immediately to the left or right of a rec-ognized constituent constituent x, and another con-stituent of the same category is found immediatelybeyond that conjunction, the parser creates a newconstituent that has the combined yield of both con-stituents, but copies x's component yield (the stringindices of x's original components) with no change.This has the eect of creating two new constituentsevery time two existing constituents are conjoined:each with a dierent component yield, but both withthe same (combined) constituent yield.
These newdiscontinuous constituents (with component yieldsthat do not exhaust their constituent yields) are stilltreated as ordinary constituents by the parser, whichcombines them with arguments and modiers untilall of their argument positions have been success-fully discharged, at which point pairs of discontinu-ous constituents with the same constituent yield canbe reassembled into whole { or at least less discon-tinuous { constituents again.A sample derivation for the verb phrase `con-taining one orange and one lemon,' involving con-junction of existentially quantied noun phrases, isshown in Figure 3, using the above parse rules andthe lexicalized grammar:containing : SnNPq=NPq0one : XnNPq NPqnNPq NPq=NPX=NPq NPqnNPqNPq=NPorange, lemon : NPand : ConjFirst the parser applies the skip conjunction rulesto obtain the discontinuous constituents shown af-ter steps (1) and (2), and a component is dischargedfrom each of the resulting constituents using theempty component rule in steps (3) and (4).
Theconstituents resulting from (3) and (4) are then com-posed with the verb constituent for `containing' insteps (5) and (6), using the left attachment rule forfresh components.
The quantiers are then appliedin steps (7) and (8), and the resulting constituentsare reassembled using the conjunction rules in step(9).
The adjacent components in the constituentresulting from step (9) are then merged using thecombination rule in step (10), producing a completegapless constituent for the entire input.Since the parser rules are xed, and the number ofcomponents in any chart constituent is bounded bythe maximum number of components in a category(inasmuch as the rules can only add a componentto the recognized list by subtracting one from theunrecognized list), the algorithm must run in poly-nomial space and time on the length of the inputsentence.
Since the cardinality of each constituent'sdenotation is bounded by jEjv(where E is the setof entities in the environment and v is the maxi-mum valency of any category), the algorithm runs inworst-case polynomial space on jEj; and since thereis no more than one set composition operation per-formed when a rule is applied, and each compositionoperation runs in worst-case quadratic time on thesize of its composed sets (due to the quantier oper-ation), the algorithm runs in worst-case polynomialtime on jEj as well.4 EvaluationThe extended parser described above has been im-plemented and evaluated on a corpus of 340 spo-ken instructions to simulated human-like agents ina controlled 3-D environment (that of children run-ning a lemonade stand, which was deemed suitablyfamiliar to undergraduate student subjects).
Theparser was run on the word lattice output of ano-the-shelf speech recognizer (CMU Sphinx II) andthe parser chart was seeded with every hypothesizedword.
The parser was also compared with the rec-ognizer by itself, in order to determine the degree towhich an environment-based approach could com-plement corpus-based disambiguation.
The systemswere evaluated as word recognizers (i.e.
ignoring thebrackets in the parser output) on the rst 100 sen-tences of the corpus (corresponding to the rst sevenof 33 subjects); the latter 240 sentences were re-served for training the recognizer and for developingthe grammar and semantic lexicon.The average utterance length was approximatelythree seconds (subsuming about 300 frames or posi-tions in the parser chart), containing an average ofnine words.
Parsing time averaged under 40 secondsper sentence on a P4-1500MHz, most of which wasspent in forest construction rather than denotationcalculation.Accuracy results show that the parser was able tocorrectly identify a signicant number of words thatthe recognizer missed (and vice versa), such that aperfect synthesis of the two (choosing the correctword if it is recognized by either system) would pro-duce an average of 8 percentage points more recallthan the recognizer by itself on successful parses,and as much as 19 percentage points more for somesubjects:10recognizer parser jointsubject prec recall fail prec recall recall0 76 79 18 72 74 921 77 75 28 63 55 832 70 71 33 49 54 693 71 67 43 49 45 694 66 54 37 44 39 675 53 52 54 36 31 726 84 84 50 56 63 83all 68 67 37 53 50 75which indicates that the environment may oer auseful additional source of information for disam-biguation.
Though it may not be possible to imple-ment a perfect synthesis of the environment-based10Successful parses are those that result in one or morecomplete analyses of the input, even if the correct tree is notamong them.and corpus-based approaches, if even half of theabove gains can be realized, it would mark a sig-nicant advance.5 ConclusionThis paper has described an extension to anenvironment-based parsing algorithm, increasing itssemantic coverage to include quantier and conjunc-tion operations without destroying its polynomialworst-case complexity.
Experiments using an imple-mentation of this algorithm on a corpus of spokeninstructions indicate that 1) the observed complex-ity of the algorithm is suitable for practical user in-terface applications, and 2) the ability to draw onthis kind of environment information in an inter-faced application has the potential to greatly im-prove recognition accuracy in speaker-independentmixed-initiative interfaces.ReferencesKazimierz Ajdukiewicz.
1935.
Die syntaktische konnex-itat.
In S. McCall, editor, Polish Logic 1920-1939,pages 207{231.
Oxford University Press.
Translatedfrom Studia Philosophica 1: 1{27.Yehoshua Bar-Hillel.
1953.
A quasi-arithmetical nota-tion for syntactic description.
Language, 29:47{58.Jon Barwise and Robin Cooper.
1981.
Generalizedquantiers and natural language.
Linguistics and Phi-losophy, 4.Sylvie Billot and Bernard Lang.
1989.
The structure ofshared forests in ambiguous parsing.
In Proceedings ofthe 27thAnnual Meeting of the Association for Com-putational Linguistics (ACL '89), pages 143{151.Veronica Dahl and Michael C. McCord.
1983.
Treatingcoordination in logic grammars.
American Journal ofComputational Linguistics, 9(2):69{91.John Dowding, Robert Moore, Francois Andery, andDouglas Moran.
1994.
Interleaving syntax and seman-tics in an e?cient bottom-up parser.
In Proceedings ofthe 32nd Annual Meeting of the Association for Com-putational Linguistics (ACL'94).Joshua Goodman.
1999.
Semiring parsing.
Computa-tional Linguistics, 25(4):573{605.E.
Keenan and J. Stavi.
1986.
A semantic characteriza-tion of natural language determiners.
Linguistics andPhilosophy, 9:253{326.Richard Montague.
1973.
The proper treatment of quan-tication in ordinary English.
In J. Hintikka, J.M.E.Moravcsik, and P. Suppes, editors, Approaches to Nat-ural Langauge, pages 221{242.
D. Riedel, Dordrecht.Reprinted in R. H. Thomason ed., Formal Philosophy,Yale University Press, 1994.William Schuler.
2001.
Computational properties ofenvironment-based disambiguation.
In Proceedings ofthe 39th Annual Meeting of the Association for Com-putational Linguistics (ACL '01), Toulouse, France.Stuart M. Shieber, Yves Schabes, and Fernando C.N.Pereira.
1995.
Principles and implementation of de-ductive parsing.
Journal of Logic Programming, 24:3{36.
