Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 645?653,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsSmart Paradigms and the Predictability and Complexity of InflectionalMorphologyGre?goire De?trez and Aarne RantaDepartment of Computer Science and EngineeringChalmers University of Technology and University of GothenburgAbstractMorphological lexica are often imple-mented on top of morphological paradigms,corresponding to different ways of buildingthe full inflection table of a word.
Compu-tationally precise lexica may use hundredsof paradigms, and it can be hard for a lex-icographer to choose among them.
To au-tomate this task, this paper introduces thenotion of a smart paradigm.
It is a meta-paradigm, which inspects the base form andtries to infer which low-level paradigm ap-plies.
If the result is uncertain, more formsare given for discrimination.
The numberof forms needed in average is a measureof predictability of an inflection system.The overall complexity of the system alsohas to take into account the code size ofthe paradigms definition itself.
This pa-per evaluates the smart paradigms imple-mented in the open-source GF ResourceGrammar Library.
Predictability and com-plexity are estimated for four different lan-guages: English, French, Swedish, andFinnish.
The main result is that predictabil-ity does not decrease when the complex-ity of morphology grows, which means thatsmart paradigms provide an efficient toolfor the manual construction and/or auto-matically bootstrapping of lexica.1 IntroductionParadigms are a cornerstone of grammars in theEuropean tradition.
A classical Latin grammarhas five paradigms for nouns (?declensions?)
andfour for verbs (?conjugations?).
The modern ref-erence on French verbs, Bescherelle (Bescherelle,1997), has 88 paradigms for verbs.
Swedishgrammars traditionally have, like Latin, fiveparadigms for nouns and four for verbs, but amodern computational account (Hellberg, 1978),aiming for more precision, has 235 paradigms forSwedish.Mathematically, a paradigm is a function thatproduces inflection tables.
Its argument is a wordstring (either a dictionary form or a stem), andits value is an n-tuple of strings (the word forms):P : String?
StringnWe assume that the exponent n is determined bythe language and the part of speech.
For instance,English verbs might have n = 5 (for sing, sings,sang, sung, singing), whereas for French verbs inBescherelle, n = 51.
We assume the tuples tobe ordered, so that for instance the French sec-ond person singular present subjunctive is alwaysfound at position 17.
In this way, word-paradigmpairs can be easily converted to morphogical lex-ica and to transducers that map form descriptionsto surface forms and back.
A properly designedset of paradigms permits a compact representationof a lexicon and a user-friendly way to extend it.Different paradigm systems may have differentnumbers of paradigms.
There are two reasons forthis.
One is that traditional paradigms often in factrequire more arguments than one:P : Stringm ?
StringnHere m ?
n and the set of arguments is a subsetof the set of values.
Thus the so-called fourth verbconjugation in Swedish actually needs three formsto work properly, for instance sitta, satt, suttit forthe equivalent of sit, sat, sat in English.
In Hell-berg (1978), as in the French Bescherelle, eachparadigm is defined to take exactly one argument,and hence each vowel alternation pattern must bea different paradigm.The other factor that affects the number ofparadigms is the nature of the string operations645allowed in the function P .
In Hellberg (1978),noun paradigms only permit the concatenation ofsuffixes to a stem.
Thus the paradigms are iden-tified with suffix sets.
For instance, the inflectionpatterns bil?bilar (?car?cars?)
and nyckel?nycklar(?key?keys?)
are traditionally both treated as in-stances of the second declension, with the pluralending ar and the contraction of the unstressede in the case of nyckel.
But in Hellberg, theword nyckel has nyck as its ?technical stem?, towhich the paradigm numbered 231 adds the sin-gular ending el and the plural ending lar.The notion of paradigm used in this paper al-lows multiple arguments and powerful string op-erations.
In this way, we will be able to reducethe number of paradigms drastically: in fact, eachlexical category (noun, adjective, verb), will havejust one paradigm but with a variable number ofarguments.
Paradigms that follow this design willbe called smart paradigms and are introducedin Section 2.
Section 3 defines the notions ofpredictability and complexity of smart paradigmsystems.
Section 4 estimates these figures for fourdifferent languages of increasing richness in mor-phology: English, Swedish, French, and Finnish.We also evaluate the smart paradigms as a datacompression method.
Section 5 explores someuses of smart paradigms in lexicon building.
Sec-tion 6 compares smart paradigms with relatedtechniques such as morphology guessers and ex-traction tools.
Section 7 concludes.2 Smart paradigmsIn this paper, we will assume a notion of paradigmthat allows multiple arguments and arbitrary com-putable string operations.
As argued in (Ka-plan and Kay, 1994) and amply demonstrated in(Beesley and Karttunen, 2003), no generality islost if the string operators are restricted to onescomputable by finite-state transducers.
Thus theexamples of paradigms that we will show (onlyinformally), can be converted to matching and re-placements with regular expressions.For example, a majority of French verbs canbe defined by the following paradigm, whichanalyzes a variable-size suffix of the infinitiveform and dispatches to the Bescherelle paradigms(identified by a number and an example verb):mkV : String?
String51mkV(s) =?
conj19finir(s), if s ends ir?
conj53rendre(s), if s ends re?
conj14assie?ger(s), if s ends e?ger?
conj11jeter(s), if s ends eler oreter?
conj10ce?der(s), if s ends e?der?
conj07placer(s), if s ends cer?
conj08manger(s), if s ends ger?
conj16payer(s), if s ends yer?
conj06parler(s), if s ends erNotice that the cases must be applied in the givenorder; for instance, the last case applies only tothose verbs ending with er that are not matchedby the earlier cases.Also notice that the above paradigm is justlike the more traditional ones, in the sense thatwe cannot be sure if it really applies to a givenverb.
For instance, the verb partir ends with irand would hence receive the same inflection asfinir; however, its real conjugation is number 26in Bescherelle.
That mkV uses 19 rather thannumber 26 has a good reason: a vast majority ofir verbs is inflected in this conjugation, and it isalso the productive one, to which new ir verbs areadded.Even though there is no mathematical differ-ence between the mkV paradigm and the tradi-tional paradigms like those in Bescherelle, thereis a reason to call mkV a smart paradigm.
Thisname implies two things.
First, a smart paradigmimplements some ?artificial intelligence?
to pickthe underlying ?stupid?
paradigm.
Second, asmart paradigm uses heuristics (informed guess-ing) if string matching doesn?t decide the matter;the guess is informed by statistics of the distribu-tions of different inflection classes.One could thus say that smart paradigms are?second-order?
or ?meta-paradigms?, comparedto more traditional ones.
They implement alot of linguistic knowledge and intelligence, andthereby enable tasks such as lexicon building tobe performed with less expertise than before.
Forinstance, instead of ?07?
for foncer and ?06?for marcher, the lexicographer can simply write?mkV?
for all verbs instead of choosing from 88numbers.In fact, just ?V?, indicating that the word isa verb, will be enough, since the name of theparadigm depends only on the part of speech.This follows the model of many dictionaries and646methods of language teaching, where character-istic forms are used instead of paradigm identi-fiers.
For instance, another variant of mkV coulduse as its second argument the first person pluralpresent indicative to decide whether an ir verb isin conjugation 19 or in 26:mkV : String2 ?
String51mkV(s, t) =?
conj26partir(s), if for some x, s =x+ir and t = x+ons?
conj19finir(s), if s ends with ir?
(all the other cases that can be rec-ognized by this extra form)?
mkV(s) otherwise (fall-back to theone-argument paradigm)In this way, a series of smart paradigms is builtfor each part of speech, with more and more ar-guments.
The trick is to investigate which newforms have the best discriminating power.
Forease of use, the paradigms should be displayed tothe user in an easy to understand format, e.g.
as atable specifying the possible argument lists:verb parlerverb parler, parlonsverb parler, parlons, parlera, parla, parle?noun chiennoun chien, masculinenoun chien, chiens, masculineNotice that, for French nouns, the gender is listedas one of the pieces of information needed forlexicon building.
In many cases, it can be in-ferred from the dictionary form just like the in-flection; for instance, that most nouns ending eare feminine.
A gender argument in the smartnoun paradigm makes it possible to override thisdefault behaviour.2.1 Paradigms in GFSmart paradigms as used in this paper have beenimplemented in the GF programming language(Grammatical Framework, (Ranta, 2011)).
GF isa functional programming lnguage enriched withregular expressions.
For instance, the followingfunction implements a part of the one-argumentFrench verb paradigm shown above.
It uses a caseexpression to pattern match with the argument s;the pattern _ matches anything, while + divides astring to two pieces, and | expresses alternation.The functions conj19finir etc.
are definedelsewhere in the library.
Function application isexpressed without parentheses, by the juxtaposi-tion of the function and the argument.mkV : Str -> VmkV s = case s of {_ + "ir" -> conj19finir s ;_ + ("eler"|"eter")-> conj11jeter s ;_ + "er" -> conj06parler s ;}The GF Resource Grammar Library1 hascomprehensive smart paradigms for 18 lan-guages: Amharic, Catalan, Danish, Dutch, En-glish, Finnish, French, German, Hindi, Italian,Nepalese, Norwegian, Romanian, Russian, Span-ish, Swedish, Turkish, and Urdu.
A few other lan-guages have complete sets of ?traditional?
inflec-tion paradigms but no smart paradigms.Six languages in the library have comprehen-sive morphological dictionaries: Bulgarian (53klemmas), English (42k), Finnish (42k), French(92k), Swedish (43k), and Turkish (23k).
Theyhave been extracted from other high-quality re-sources via conversions to GF using the paradigmsystems.
In Section 4, four of them will be usedfor estimating the strength of the smart paradigms,that is, the predictability of each language.3 Cost, predictability, and complexityGiven a languageL, a lexical category C, and a setP of smart paradigms for C, the predictability ofthe morphology of C in L by P depends inverselyon the average number of arguments needed togenerate the correct inflection table for a word.The lower the number, the more predictable thesystem.Predictability can be estimated from a lexiconthat contains such a set of tables.
Formally, asmart paradigm is a family Pm of functionsPm : Stringm ?
Stringnwhere m ranges over some set of integers from 1to n, but need not contain all those integers.
Alexicon L is a finite set of inflection tables,L = {wi : Stringn | i = 1, .
.
.
,ML}1 Source code and documentation in http://www.grammaticalframework.org/lib.647As the n is fixed, this is a lexicon specialized toone part of speech.
A word is an element of thelexicon, that is, an inflection table of size n.An application of a smart paradigm Pm to aword w ?
L is an inflection table resulting fromapplying Pm to the appropriate subset ?m(w) ofthe inflection table w,Pm[w] = Pm(?m(w)) : StringnThus we assume that all arguments are existingword forms (rather than e.g.
stems), or featuressuch as the gender.An application is correct ifPm[w] = wThe cost of a word w is the minimum number ofarguments needed to make the application correct:cost(w) = argminm(Pm[w] = w)For practical applications, it is useful to requirePm to be monotonic, in the sense that increasingm preserves correctness.The cost of a lexicon L is the average cost forits words,cost(L) =ML?i=1cost(wi)MLwhere ML is the number of words in the lexicon,as defined above.The predictability of a lexicon could be de-fined as a quantity inversely dependent on its cost.For instance, an information-theoretic measurecould be definedpredict(L) =11 + log cost(L)with the intuition that each added argument cor-responds to a choice in a decision tree.
However,we will not use this measure in this paper, but justthe concrete cost.The complexity of a paradigm system is de-fined as the size of its code in a given codingsystem, following the idea of Kolmogorov com-plexity (Solomonoff, 1964).
The notion assumesa coding system, which we fix to be GF sourcecode.
As the results are relative to the codingsystem, they are only usable for comparing def-initions in the same system.
However, using GFsource code size rather than e.g.
a finite automa-ton size gives in our view a better approximationof the ?cognitive load?
of the paradigm system,its ?learnability?.
As a functional programminglanguage, GF permits abstractions comparable tothose available for human language learners, whodon?t need to learn the repetitive details of a finiteautomaton.We define the code complexity as the size ofthe abstract syntax tree of the source code.
Thissize is given as the number of nodes in the syntaxtree; for instance,?
size(f(x1, .
.
.
, xn)) = 1 +n?i=1size(xi)?
size(s) = 1, for a string literal sUsing the abstract syntax size makes it possibleto ignore programmer-specific variation such asidentifier size.
Measurements of the GF ResourceGrammar Library show that code size measuredin this way is in average 20% of the size of sourcefiles in bytes.
Thus a source file of 1 kB has thecode complexity around 200 on the average.Notice that code complexity is defined in a waythat makes it into a straightforward generaliza-tion of the cost of a word as expressed in termsof paradigm applications in GF source code.
Thesource code complexity of a paradigm applicationissize(Pm[w]) = 1 +mThus the complexity for a word w is its cost plusone; the addition of one comes from the applica-tion node for the function Pm and corresponds toknowing the part of speech of the word.4 Experimental resultsWe conducted experiments in four languages (En-glish, Swedish, French and Finnish2), presentedhere in order of morphological richness.
We usedtrusted full form lexica (i.e.
lexica giving the com-plete inflection table of every word) to computethe predictability, as defined above, in terms ofthe smart paradigms in GF Resource Grammar Li-brary.We used a simple algorithm for computing thecost c of a lexicon L with a set Pm of smartparadigms:2This choice correspond to the set of language for whichboth comprehensive smart paradigms and morphologicaldictionaries were present in GF with the exception of Turk-ish, which was left out because of time constraints.648?
set c := 0?
for each word wi in L,?
for each m in growing order for whichPm is defined:if Pm[w] = w, then c := c+m, else trywith next m?
return cThe average cost is c divided by the size of L.The procedure presupposes that it is alwayspossible to get the correct inflection table.
Forthis to be true, the smart paradigms must have a?worst case scenario?
version that is able to gen-erate all forms.
In practice, this was not alwaysthe case but we checked that the number of prob-lematic words is so small that it wouldn?t be sta-tistically significant.
A typical problem word wasthe equivalent of the verb be in each language.Another source of deviation is that a lexiconmay have inflection tables with size deviatingfrom the number n that normally defines a lex-ical category.
Some words may be ?defective?,i.e.
lack some forms (e.g.
the singular formin ?plurale tantum?
words), whereas some wordsmay have several variants for a given form (e.g.learned and learnt in English).
We made no ef-fort to predict defective words, but just ignoredthem.
With variant forms, we treated a predictionas correct if it matched any of the variants.The above algorithm can also be used for help-ing to select the optimal sets of characteristicforms; we used it in this way to select the firstform of Swedish verbs and the second form ofFinnish nouns.The results are collected in Table 1.
The sec-tions below give more details of the experiment ineach language.4.1 EnglishAs gold standard, we used the electronic versionof the Oxford Advanced Learner?s Dictionary ofCurrent English3 which contains about 40,000root forms (about 70,000 word forms).Nouns.
We considered English nouns as hav-ing only two forms (singular and plural), exclud-ing the genitive forms which can be considered tobe clitics and are completely predictable.
About3available in electronic form at http://www.eecs.qmul.ac.uk/?mpurver/software.htmlone third of the nouns of the lexicon were not in-cluded in the experiment because one of the formwas missing.
The vast majority of the remaining15,000 nouns are very regular, with predictabledeviations such as kiss - kisses and fly - flies whichcan be easily predicted by the smart paradigm.With the average cost of 1.05, this was the mostpredictable lexicon in our experiment.Verbs.
Verbs are the most interesting categoryin English because they present the richest mor-phology.
Indeed, as shown by Table 1, the costfor English verbs, 1.21, is similar to what we gotfor morphologically richer languages.4.2 SwedishAs gold standard, we used the SALDO lexicon(Borin et al 2008).Nouns.
The noun inflection tables had 8forms (singular/plural indefinite/definite nomina-tive/genitive) plus a gender (uter/neuter).
Swedishnouns are intrinsically very unpredictable, andthere are many examples of homonyms falling un-der different paradigms (e.g.
val - val ?choice?
vs.val -valar ?whale?).
The cost 1.70 is the highestof all the lexica considered.
Of course, there maybe room for improving the smart paradigm.Verbs.
The verbs had 20 forms, which in-cluded past participles.
We ran two experiments,by choosing either the infinitive or the present in-dicative as the base form.
In traditional Swedishgrammar, the base form of the verb is consideredto be the infinitive, e.g.
spela, leka (?play?
intwo different senses).
But this form doesn?t dis-tinguish between the ?first?
and the ?second con-jugation?.
However, the present indicative, herespelar, leker, does.
Using it gives a predictivepower 1.13 as opposed to 1.22 with the infinitive.Some modern dictionaries such as Lexin4 there-fore use the present indicative as the base form.4.3 FrenchFor French, we used the Morphalou morpholog-ical lexicon (Romary et al 2004).
As stated inthe documentation5 the current version of the lex-icon (version 2.0) is not complete, and in par-ticular, many entries are missing some or all in-flected forms.
So for those experiments we only4http://lexin.nada.kth.se/lexin/5http://www.cnrtl.fr/lexiques/morphalou/LMF-Morphalou.php#body_3.4.11,accessed 2011-11-04649Table 1: Lexicon size and average cost for the nouns (N) and verbs (V) in four languages, with the percentage ofwords correctly inferred from one and two forma (i.e.
m = 1 and m ?
2, respectively).Lexicon Forms Entries Cost m = 1 m ?
2Eng N 2 15,029 1.05 95% 100%Eng V 5 5,692 1.21 84% 95%Swe N 9 59,225 1.70 46% 92%Swe V 20 4,789 1.13 97% 97%Fre N 3 42,390 1.25 76% 99%Fre V 51 6,851 1.27 92% 94%Fin N 34 25,365 1.26 87% 97%Fin V 102 10,355 1.09 96% 99%included entries where all the necessary formswere presents.Nouns: Nouns in French have two forms (sin-gular and plural) and an intrinsic gender (mascu-line or feminine), which we also considered to bea part of the inflection table.
Most of the unpre-dictability comes from the impossibility to guessthe gender.Verbs: The paradigms generate all of the sim-ple (as opposed to compound) tenses given in tra-ditional grammars such as the Bescherelle.
Alsothe participles are generated.
The auxiliary verbof compound tenses would be impossible to guessfrom morphological clues, and was left out ofconsideration.4.4 FinnishThe Finnish gold standard was the KOTUS lexi-con (Kotimaisten Kielten Tutkimuskeskus, 2006).It has around 90,000 entries tagged with partof speech, 50 noun paradigms, and 30 verbparadigms.
Some of these paradigms are ratherabstract and powerful; for instance, grade alterna-tion would multiply many of the paradigms by afactor of 10 to 20, if it was treated in a concate-native way.
For instance, singular nominative-genitive pairs show alternations such as talo?talon(?house?
), katto?katon (?roof?
), kanto?kannon(?stub?
), rako?raon (?crack?
), and sato?sadon(?harvest?).
All of these are treated with one andthe same paradigm, which makes the KOTUS sys-tem relatively abstract.The total number of forms of Finnish nouns andverbs is a question of definition.
Koskenniemi(Koskenniemi, 1983) reports 2000 for nouns and12,000 for verbs, but most of these forms result byadding particles and possessive suffixes in an ag-glutinative way.
The traditional number and casecount for nouns gives 26, whereas for verbs thecount is between 100 and 200, depending on howparticiples are counted.
Notice that the definitionof predictability used in this paper doesn?t dependon the number of forms produced (i.e.
not on nbut only on m); therefore we can simply ignorethis question.
However, the question is interestingif we think about paradigms as a data compressionmethod (Section 4.5).Nouns.
Compound nouns are a problem formorphology prediction in Finnish, because inflec-tion is sensitive to the vowel harmony and num-ber of syllables, which depend on where the com-pound boundary goes.
While many compoundsare marked in KOTUS, we had to remove somecompounds with unmarked boundaries.
Anotherpeculiarity was that adjectives were included innouns; this is no problem since the inflection pat-terns are the same, if comparison forms are ig-nored.
The figure 1.26 is better than the one re-ported in (Ranta, 2008), which is 1.42; the reasonis mainly that the current set of paradigms has abetter coverage of three-syllable nouns.Verbs.
Even though more numerous in formsthan nouns, Finnish verbs are highly predictable(1.09).4.5 Complexity and data compressionThe cost of a lexicon has an effect on learnabil-ity.
For instance, even though Finnish words haveten or a hundred times more forms than Englishforms, these forms can be derived from roughlythe same number of characteristic forms as in En-glish.
But this is of course just a part of the truth:it might still be that the paradigm system itself ismuch more complex in some languages than oth-650Table 2: Paradigm complexities for nouns and verbsin the four languages, computed as the syntax tree sizeof GF code.language noun verb totalEnglish 403 837 991Swedish 918 1039 1884French 351 2193 2541Finnish 4772 3343 6885ers.Following the definitions of Section 3, we havecounted the the complexity of the smart paradigmdefinitions for nouns and verbs in the differentlanguages in the GF Resource Grammar Library.Notice that the total complexity of the system islower than the sum of the parts, because manydefinitions (such as morphophonological transfor-mations) are reused in different parts of speech.The results are in Table 2.These figures suggest that Finnish indeed has amore complex morphology than French, and En-glish is the simplest.
Of course, the paradigmswere not implemented with such comparisons inmind, and it may happen that some of the differ-ences come from different coding styles involvedin the collaboratively built library.
Measuringcode syntax trees rather than source code text neu-tralizes some of this variation (Section 3).Finally, we can estimate the power of smartparadigms as a data compression function.
In asense, a paradigm is a function designed for thevery purpose of compressing a lexicon, and onecan expect better compression than with generictools such as bzip2.
Table 3 shows the compres-sion rates for the same full-form lexica as usedin the predictability experiment (Table 1).
Thesizes are in kilobytes, where the code size forparadigms is calculated as the number of con-structors multiplied by 5 (Section 3).
The sourcelexicon size is a simple character count, similar tothe full-form lexicon.Unexpectedly, the compression rate of theparadigms improves as the number of forms inthe full-form lexicon increases (see Table 1 forthese numbers).
For English and French nouns,bzip2 is actually better.
But of course, unlikethe paradigms, it also gives a global compressionover all entries in the lexicon.
Combining thetwo methods by applying bzip2 to the source codegives, for the Finnish verb lexicon, a file of 60 kB,which implies a joint compression rate of 227.That the compression rates for the code can behigher than the numbers of forms in the full-formlexicon is explained by the fact that the gener-ated forms are longer than the base forms.
Forinstance, the full-form entry of the Finnish verbuida (?swim?)
is 850 bytes, which means that theaverage form size is twice the size of the basicform.5 Smart paradigms in lexicon buildingBuilding a high-quality lexicon needs a lot ofmanual work.
Traditionally, when one is not writ-ing all the forms by hand (which would be almostimpossible in languages with rich morphology),sets of paradigms are used that require the lexi-cographer to specify the base form of the wordand an identifier for the paradigm to use.
This hasseveral usability problems: one has to rememberall the paradigm identifiers and choose correctlyfrom them.Smart paradigm can make this task easier, evenaccessible to non-specialist, because of their abil-ity to guess the most probable paradigm from asingle base form.
As shown by Table 1, this ismore often correct than not, except for Swedishnouns.
If this information is not enough, only afew more forms are needed, requiring only prac-tical knowledge of the language.
Usually (92% to100% in Table 1), adding a second form (m = 2)is enough to cover all words.
Then the best prac-tice for lexicon writing might be always to givethese two forms instead of just one.Smart paradigms can also be used for an auto-matic bootstrapping of a list of base forms into afull form lexicon.
As again shown by the last col-umn of Table 1, one form alone can provide anexcellent first approximation in most cases.
Whatis more, it is often the case that uncaught wordsbelong to a limited set of ?irregular?
words, suchas the irregular verbs in many languages.
All newwords can then be safely inferred from the baseform by using smart paradigms.6 Related workSmart paradigms were used for a study of Finnishmorphology in (Ranta, 2008).
The present papercan be seen as a generalization of that experimentto more languages and with the notion of code651Table 3: Comparison between using bzip2 and paradigms+lexicon source as a compression method.
Sizes inkB.Lexicon Fullform bzip2 fullform/bzip2 Source fullform/sourceEng N 264 99 2.7 135 2.0Eng V 245 78 3.2 57 4.4Swe N 6,243 1,380 4.5 1,207 5.3Swe V 840 174 4.8 58 15Fre N 952 277 3.4 450 2.2Fre V 3,888 811 4.8 98 40Fin N 11,295 2,165 5.2 343 34Fin V 13,609 2,297 5.9 123 114complexity.
Also the paradigms for Finnish areimproved here (cf.
Section 4.4 above).Even though smart paradigm-like descriptionsare common in language text books, there is toour knowledge no computational equivalent to thesmart paradigms of GF.
Finite state morphologysystems often have a function called a guesser,which, given a word form, tries to guess eitherthe paradigm this form belongs to or the dictio-nary form (or both).
A typical guesser differsfrom a smart paradigms in that it does not makeit possible to correct the result by giving moreforms.
Examples of guessers include (Chanodand Tapanainen, 1995) for French, (Hlava?c?ova?,2001) for Czech, and (Nakov et al 2003) for Ger-man.Another related domain is the unsupervisedlearning of morphology where machine learningis used to automatically build a language mor-phology from corpora (Goldsmith, 2006).
Themain difference is that with the smart paradigms,the paradigms and the guess heuristics are imple-mented manually and with a high certainty; in un-supervised learning of morphology the paradigmsare induced from the input forms with much lowercertainty.
Of particular interest are (Chan, 2006)and (Dreyer and Eisner, 2011), dealing with theautomatic extraction of paradigms from text andinvestigate how good these can become.
The maincontrast is, again, that our work deals with hand-written paradigms that are correct by design, andwe try to see how much information we can dropbefore losing correctness.Once given, a set of paradigms can be used inautomated lexicon extraction from raw data, as in(Forsberg et al 2006) and (Cle?ment et al 2004),by a method that tries to collect a sufficient num-ber of forms to determine that a word belongs to acertain paradigm.
Smart paradigms can then givethe method to actually construct the full inflectiontables from the characteristic forms.7 ConclusionWe have introduced the notion of smartparadigms, which implement the linguisticknowledge involved in inferring the inflection ofwords.
We have used the paradigms to estimatethe predictability of nouns and verbs in English,Swedish, French, and Finnish.
The main resultis that, with the paradigms used, less than twoforms in average is always enough.
In half of thelanguages and categories, one form is enough topredict more than 90% of forms correctly.
Thisgives a promise for both manual lexicon buildingand automatic bootstrapping of lexicon fromword lists.To estimate the overall complexity of inflectionsystems, we have also measured the size of thesource code for the paradigm systems.
Unsurpris-ingly, Finnish is around seven times as complexas English, and around three times as complex asSwedish and French.
But this cost is amortizedwhen big lexica are built.Finally, we looked at smart paradigms as a datacompression method.
With simple morphologies,such as English nouns, bzip2 gave a better com-pression of the lexicon than the source code us-ing paradigms.
But with Finnish verbs, the com-pression rate was almost 20 times higher withparadigms than with bzip2.The general conclusion is that smart paradigmsare a good investment when building morpho-logical lexica, as they ease the task of both hu-man lexicographers and automatic bootstrapping652methods.
They also suggest a method to assessthe complexity and learnability of languages, re-lated to Kolmogorov complexity.
The results inthe current paper are just preliminary in this re-spect, since they might still tell more about par-ticular implementations of paradigms than aboutthe languages themselves.AcknowledgementsWe are grateful to the anonymous referees forvaluable remarks and questions.
The researchleading to these results has received funding fromthe European Union?s Seventh Framework Pro-gramme (FP7/2007-2013) under grant agreementno FP7-ICT-247914 (the MOLTO project).References[Beesley and Karttunen2003] Kenneth R. Beesley andLauri Karttunen.
2003.
Finite State Morphology.CSLI Publications.
[Bescherelle1997] Bescherelle.
1997.
La conjugaisonpour tous.
Hatier.
[Borin et al008] Lars Borin, Markus Forsberg, andLennart Lo?nngren.
2008.
Saldo 1.0 (svenskt as-sociationslexikon version 2).
Spra?kbanken, 05.
[Chan2006] Erwin Chan.
2006.
Learning probabilisticparadigms for morphology in a latent class model.In Proceedings of the Eighth Meeting of the ACLSpecial Interest Group on Computational Phonol-ogy and Morphology, SIGPHON ?06, pages 69?78,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.
[Chanod and Tapanainen1995] Jean-Pierre Chanodand Pasi Tapanainen.
1995.
Creating a tagset,lexicon and guesser for a french tagger.
CoRR,cmp-lg/9503004.
[Cle?ment et al004] Lionel Cle?ment, Beno?
?t Sagot,and Bernard Lang.
2004.
Morphology based au-tomatic acquisition of large-coverage lexica.
InProceedings of LREC-04, Lisboa, Portugal, pages1841?1844.
[Dreyer and Eisner2011] Markus Dreyer and JasonEisner.
2011.
Discovering morphologicalparadigms from plain text using a dirichlet processmixture model.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Pro-cessing, EMNLP ?11, pages 616?627, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.
[Forsberg et al006] Markus Forsberg, Harald Ham-marstro?m, and Aarne Ranta.
2006.
Morpholog-ical Lexicon Extraction from Raw Text Data.
InT.
Salakoski, editor, FinTAL 2006, volume 4139 ofLNCS/LNAI.
[Goldsmith2006] John Goldsmith.
2006.
An Algo-rithm for the Unsupervised Learning of Morphol-ogy.
Nat.
Lang.
Eng., 12(4):353?371.
[Hellberg1978] Staffan Hellberg.
1978.
The Morphol-ogy of Present-Day Swedish.
Almqvist & Wiksell.
[Hlava?c?ova?2001] Jaroslava Hlava?c?ova?.
2001.
Mor-phological guesser of czech words.
In Va?clav Ma-tous?ek, Pavel Mautner, Roman Moucek, and KarelTaus?er, editors, Text, Speech and Dialogue, volume2166 of Lecture Notes in Computer Science, pages70?75.
Springer Berlin / Heidelberg.
[Kaplan and Kay1994] R. Kaplan and M. Kay.
1994.Regular Models of Phonological Rule Systems.Computational Linguistics, 20:331?380.
[Koskenniemi1983] Kimmo Koskenniemi.
1983.Two-Level Morphology: A General ComputationalModel for Word-Form Recognition and Production.Ph.D.
thesis, University of Helsinki.
[Kotimaisten Kielten Tutkimuskeskus2006]Kotimaisten Kielten Tutkimuskeskus.
2006.KOTUS Wordlist.
http://kaino.kotus.fi/sanat/nykysuomi.
[Nakov et al003] Preslav Nakov, Yury Bonev, andet al2003.
Guessing morphological classes of un-known german nouns.
[Ranta2008] Aarne Ranta.
2008.
How pre-dictable is Finnish morphology?
an experi-ment on lexicon construction.
In J. Nivre andM.
Dahllo?f and B. Megyesi, editor, Resource-ful Language Technology: Festschrift in Honorof Anna Sa?gvall Hein, pages 130?148.
Universityof Uppsala.
http://publications.uu.se/abstract.xsql?dbid=8933.
[Ranta2011] Aarne Ranta.
2011.
Grammatical Frame-work: Programming with Multilingual Grammars.CSLI Publications, Stanford.
ISBN-10: 1-57586-626-9 (Paper), 1-57586-627-7 (Cloth).
[Romary et al004] Laurent Romary, SusanneSalmon-Alt, and Gil Francopoulo.
2004.
Standardsgoing concrete: from LMF to Morphalou.
In The20th International Conference on ComputationalLinguistics - COLING 2004, Gene`ve/Switzerland.coling.
[Solomonoff1964] Ray J. Solomonoff.
1964.
A formaltheory of inductive inference: Parts 1 and 2.
Infor-mation and Control, 7:1?22 and 224?254.653
