Proceedings of the BioNLP Shared Task 2013 Workshop, pages 94?98,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsNaCTeM EventMine for BioNLP 2013 CG and PC tasksMakoto Miwa and Sophia AnaniadouNational Centre for Text Mining, University of Manchester, United KingdomSchool of Computer Science, University of Manchester, United Kingdom{makoto.miwa,sophia.ananiadou}@manchester.ac.ukAbstractThis paper describes NaCTeM entries forthe Cancer Genetics (CG) and PathwayCuration (PC) tasks in the BioNLP SharedTask 2013.
We have applied a state-of-the-art event extraction system EventMineto the tasks in two different settings: asingle-corpus setting for the CG task anda stacking setting for the PC task.
Event-Mine was applicable to the two tasks withsimple task specific configuration, and itproduced a reasonably high performance,positioning second in the CG task and firstin the PC task.1 IntroductionWith recent progress in biomedical natural lan-guage processing (BioNLP), automatic extractionof biomedical events from texts becomes practi-cal and the extracted events have been success-fully employed in several applications, such asEVEX (Bjo?rne et al 2012; Van Landeghem etal., 2013) and PathText (Miwa et al 2013a).The practical applications reveal a problem in thatboth event types and structures need to be cov-ered more widely.
The BioNLP Shared Task 2013(BioNLP-ST 2013) offers several tasks addressingthe problem, and especially in the Cancer Genetics(CG) (Pyysalo et al 2013) and Pathway Curation(PC) (Ohta et al 2013) tasks, new entity/eventtypes and biomedical problems are focused.Among dozens of extraction systems proposedduring and after the two previous BioNLP sharedtasks (Kim et al 2011; Kim et al 2012; Pyysaloet al 2012b), EventMine (Miwa et al 2012)1has been applied to several biomedical event ex-traction corpora, and it achieved the state-of-the-art performance in several corpora (Miwa et al2013b).
In these tasks, an event associates with1http://www.nactem.ac.uk/EventMine/a trigger expression that denotes its occurrencein text, has zero or more arguments (entities orother events) that are identified with their roles(e.g., Theme, Cause) and may be assigned hedgeattributes (e.g., Negation).This paper describes how EventMine was ap-plied to the CG and PC tasks in the BioNLP-ST2013.
We configured EventMine minimally forthe CG task and submit the results using the mod-els trained on the training and development datasets with no external resources.
We employed astacking method for the PC task; the method ba-sically trained the models on the training and de-velopment data sets, but it also employed featuresrepresenting prediction scores of models on sevenexternal corpora.We will first briefly describe EventMine and itstask specific configuration in the next section, thenshow and discuss the results, and finally concludethe paper with future work.2 EventMine for CG and PC TasksThis section briefly introduces EventMine and thePC and CG tasks, and then explains its task spe-cific configuration.2.1 EventMineEventMine (Miwa et al 2012) is an SVM-basedpipeline event extraction system.
For the de-tails, we refer the readers to Miwa et al(2012;2013b).
EventMine consists of four modules: atrigger/entity detector, an argument detector, amulti-argument detector and a hedge detector.The trigger/entity detector finds words that matchthe head words (in their surfaces, base formsby parsers, or stems by a stemmer) of trig-gers/entities in the training data, and the detectorclassifies each word into specific entity types (e.g.,DNA domain or region), event types (Regulation)or a negative type that represents the word doesnot participate in any events.
The argument94detector enumerates all possible pairs amongtriggers and arguments that match the semantictype combinations of the pairs in the training data,and classifies each pair into specific role types(e.g., Binding:Theme-Gene or gene product) ora negative type.
Similarly, the multi-argumentdetector enumerates all possible combina-tions of pairs that match the semantic typestructures of the events in the training data,and classifies each combination into an eventstructure type (e.g., Positive regulation:Cause-Gene or gene product:Theme-Phosphorylation)or a negative type.
The hedge detector attacheshedges to the detected events by classifying theevents into specific hedge types (Speculation andNegation) or a negative type.All the classifications are performed by one-vs-rest support vector machines (SVMs).
The detec-tors use the types mentioned above as their clas-sification labels.
Labels with scores larger thanthe separating hyper-plane of SVM and the labelwith the largest value are selected as the predictedlabels; the classification problems are treated asmulti-class multi-label classification problems andat least one label (including a negative type) needsto be selected in the prediction.Features for the classifications include charac-ter n-grams, word n-grams, shortest paths amongevent participants on parse trees, and word n-grams and shortest paths between event partici-pants and triggers/entities outside of the events onparse trees.
The last features are employed to cap-ture the dependencies between the instances.
Allgold entity names are replaced with their types,the feature space is compressed to 220 by hash-ing to reduce space cost, the positive instances areweighted to reduce class imbalance problems, thefeature vectors are normalised, and the C parame-ter for SVM is set to 1.In the pipeline approach, there is no way to de-tect instances if the participants are missed by thepreceding modules.
EventMine thus aims highrecall in the modules by the multi-label settingand weighting positive instances.
EventMine alsoavoids training on instances that cannot be de-tected by generating the training instances basedon predictions by the preceding modules since thetraining and test instances should be similar.EventMine is flexible and applicable to severalevent extraction tasks with task specific configura-tion on entity, role and event types.
This configu-ration is described in a separate file2.2.2 CG and PC TasksThe CG task (Pyysalo et al 2013) aims to extractinformation on the biological processes relating tothe development and progression of cancer.
Theannotation is built on the Multi-Level Event Ex-traction (MLEE) corpus (Pyysalo et al 2012a),which EventMine was once applied to.
The PCtask (Ohta et al 2013), on the other hand, aimsto support the curation of bio-molecular pathwaymodels, and the corpus texts are selected to coverboth signalling and metabolic pathways.Both CG and PC tasks offer more entity, roleand event types than most previous tasks like GE-NIA (Kim et al 2012) does, which may make theclassification problems more difficult.2.3 Configuration for CG and PC TasksWe train models for the CG and PC tasks in simi-lar configuration, except for the incorporation of astacking method for the PC task.
We first explainthe configuration applied to both tasks and then in-troduce the stacking method for the PC task.We employ two kinds of type generalisationsfor both tasks: one for the classification labelsand features and the other for the generation of in-stances.
After the disambiguation of trigger/entitytypes by the trigger/entity detector, we reduce thenumber of event role labels and event structurelabels by the former type generalisations.
Thegeneralisations are required to reduce the com-putational costs that depend on the number ofthe classification labels.
Unfortunately, we can-not evaluate the effect of the generalisations onthe performance since there are too many pos-sible labels in the tasks.
The generalisationsmay alleviate the data sparseness problem butthey may also induce over-generalised featuresfor the problems with enough training instances.For event roles, we generalise regulation types(e.g., Positive regulation, Regulation) into a singleREGULATION type and post-transcriptional mod-ification (PTM) types (e.g., Acetylation, Phos-phorylation) into a single PTM type for triggertypes, numbered role types into a non-numberedrole type (e.g., Participant2?Participant) for role2This file is not necessary since the BioNLP ST data for-mat defines where these semantic types are described, but thisfile is separated for the type generalisations explained laterand the specification of gold triggers/entities without repro-ducing a1/a2 files.95types, and event types into a single EVENT typeand entity types into a single ENTITY type forargument types.
For event structures, we applythe same generalisations except for the general-isations of numbered role types since the num-bered role types are important in differentiatingevents.
Unlike other types, the numbered roletypes in events are not disambiguated by any othermodules.
The generalisations are also applied tothe features in all the detectors when applicable.These generalisations are the combination of thegeneralisations for the GENIA, Epigenetics andPost-translational Modifications (EPI), and Infec-tious Diseases (ID) (Pyysalo et al 2012b) of theBioNLP-ST 2011 (Miwa et al 2012).The type generalisations on labels and fea-tures are not directly applicable to generate pos-sible instances in the detectors since the gen-eralisations may introduce illegal or unrealis-tic event structures.
Instead, we employ sep-arate type generalisations to expand the possi-ble event role pair and event structure types andcover types, which do not appear in the trainingdata.
For example, if there are Regulation:Theme-Gene expression instances but there are no Posi-tive regulation:Theme-Gene expression instancesin the training data, we allow the creation of thelatter instances by generalising the triggers, i.e.,REGULATION:Theme-Gene expression, and weused all the created instances for classification.The type generalisations may incorporate noisy in-stances but they pose the possibility to find unan-notated event structures.
To avoid introducing un-expected event structures, we apply the generali-sations only to the regulation trigger types.We basically follow the setting for EPI inMiwa et al(2012).
We employ a deep syntacticparser Enju (Miyao and Tsujii, 2008) and a de-pendency parser GDep (Sagae and Tsujii, 2007).We utilise liblinear-java (Fan et al 2008)3 withthe L2-regularised L2-loss linear SVM setting forthe SVM implementation, and Snowball4 for thestemmer.
We, however, use no external resources(e.g., dictionaries) or tools (e.g., a coreferenceresolver) except for the external corpora in thestacked models for the PC task.We train models for the CG task using the con-figuration described above.
For PC, in additionto the configuration, we incorporated a stacking3http://liblinear.bwaldvogel.de/4http://snowball.tartarus.org/Setting Recall Precision F-score?
42.87 47.72 45.16+Exp.
43.37 46.42 44.84+Exp.+Stack.
43.59 48.77 46.04Table 1: Effect of the type generalisations for ex-panding possible instances (+Exp.)
and stackingmethod (+Stack.)
on the PC development data set.method (Wolpert, 1992) using the models with thesame configuration for seven other available cor-pora: GENIA, EPI, ID, DNA methylation (Ohtaet al 2011a), Exhaustive PTM (Pyysalo et al2011), mTOR (Ohta et al 2011b) and CG.
Theprediction scores of all the models are used as ad-ditional features in the detectors.
Although somecorpora may not directly relate to the PC task andmodels trained on such corpora can produce noisyfeatures, we use all the corpora without selectionsince the stacking often improve the performance,e.g., (Pyysalo et al 2012a; Miwa et al 2013b).3 EvaluationWe first evaluate the type generalisations for ex-panding possible event structures and the stack-ing method in Table 1.
The scores were calcu-lated using the evaluation script provided by theorganisers with the official evaluation metrics (softboundary and partial recursive matching).
Thegeneralisations improved recall with the loss ofprecision, and they slightly degraded the F-scorein total.
The generalisations were applied to thetest set in the submission since this result was ex-pected as explained in Section 2.3 and the slightlyhigh recall is favourable for the practical applica-tions like semantic search engines (Miwa et al2013a).
Although the improvement by the stack-ing method (+Exp.+Stack.
compared to +Exp.)
isnot statistically significant (p=0.14) using the ap-proximate randomisation method (Noreen, 1989;Kim et al 2011), this slight improvement indi-cates that the corpus in the PC task shares someinformation with the other corpora.Tables 2 and 3 show the official scores of ourentries on the test data sets for the CG and PCtasks5.
EventMine ranked second in the CG taskand first in the PC task.
The scores of the best sys-tem among the other systems (TEES-2.1 (Bjo?rneand Salakoski, 2013)) are shown for reference.5We refer to the websites of the tasks for the details of theevent categories.96Task System Rec.
Prec.
F-ScoreCG EventMine 48.83 55.82 52.09TEES-2.1 48.76 64.17 55.41PC EventMine 52.23 53.48 52.84TEES-2.1 47.15 55.78 51.10Table 2: Official best and second best scores onthe CG and PC tasks.
Higher scores are shown inbold.Task Category EventMine TEES-2.1CG ANATOMY 71.31 77.20PATHOL 59.78 67.51MOLECUL 72.77 72.60GENERAL 53.08 52.20REGULAT 39.79 43.08PLANNED 40.51 39.43MOD 29.95 34.66PC SIMPLE 65.60 63.92NON-REG 65.72 63.37REGULAT 40.10 39.39MOD 28.05 28.73Table 3: F-scores on the CG and PC tasks for eventcategories.
Higher scores are shown in bold.EventMine achieved the highest recall for bothtasks, and this is favourable as mentioned above.This high recall is reasonable since EventMinesolved the problems as multi-label classificationtasks, corrected the class imbalance problem asexplained in Section 2.1 and incorporated the typegeneralisations for expanding possible event struc-tures.
The performance (in F-score) on both CGand PC tasks is slightly lower than the perfor-mance on the GENIA and ID tasks in the BioNLP-ST 2011 (Miwa et al 2012), and close to the per-formance on the EPI task.
This may be partly be-cause the GENIA and ID tasks deal with a fewernumber of event types than the other tasks.EventMine performed worse than the best sys-tem in the CG task, but this result is promis-ing considering that we did not incorporate anyother resources and tune the parameters (e.g., Cin SVM).
The detailed comparison with TEES-2.1 shows that EventMine performed much worsethan TEES-2.1 in anatomical and pathologicalevent categories, which contained relatively newevent types.
This indicates EventMine missedsome of the new structures in the new event types.The range of the scores is similar to thescores on the MLEE corpus (52.34?53.43% in F-Score (Pyysalo et al 2012a)) although we can-not directly compare the results.
The ranges ofthe scores are around 60% to 70% for non-nestedevents (e.g., SIMPLE), 40% for nested events(e.g., REGULAT) and 30% for modifications (e.g.,MOD).
This large spread of the scores may becaused by a multiplication of errors in predictingtheir participants, since similar spread was seenin the previous tasks (e.g., (Miwa et al 2012)).These results indicate that we may not be ableto improve the performance just by increasing thetraining instances.These results show that EventMine performedwell on the PC task that is a completely novel taskfor EventMine, and the stacking would also workeffectively on the test set.4 ConclusionsThis paper explained how EventMine was ap-plied to the CG and PC tasks in the BioNLP-ST 2013.
EventMine performed well on thesetasks and achieved the second best performancein the CG task and the best performance in thePC task.
We show the usefulness of incorporat-ing other existing corpora in the PC task.
Thesuccess of this application shows that the Event-Mine implementation is flexible enough to treatthe new tasks.
The performance ranges, however,shows that we may need to incorporate other noveltechniques/linguistic information to produce thehigher performance.As future work, we will investigate the causeof the missed events.
We also would like to ex-tend and apply other functions in EventMine, suchas co-reference resolution, and seek a general ap-proach that can improve the event extraction per-formance on all the existing corpora, using thetraining data along with external resources.AcknowledgementThis work is supported by the Biotechnology andBiological Sciences Research Council (BBSRC)[BB/G53025X/1] and the Grant-in-Aid for YoungScientists B [25730129] of the Japan Science andTechnology Agency (JST).ReferencesJari Bjo?rne and Tapio Salakoski.
2013.
TEES 2.1: Au-tomated annotation scheme learning in the bioNLP972013 shared task.
In Proceedings of BioNLP SharedTask 2013 Workshop, Sofia, Bulgaria, August.
Asso-ciation for Computational Linguistics.Jari Bjo?rne, Sofie Van Landeghem, Sampo Pyysalo,Tomoko Ohta, Filip Ginter, Yves Van de Peer,Sophia Ananiadou, and Tapio Salakoski.
2012.Pubmed-scale event extraction for post-translationalmodifications, epigenetics and protein structural re-lations.
In BioNLP: Proceedings of the 2012 Work-shop on Biomedical Natural Language Processing,pages 82?90, Montre?al, Canada, June.
Associationfor Computational Linguistics.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2011.
Extract-ing Bio-Molecular Events from Literature ?
theBioNLP?09 Shared Task.
Computational Intelli-gence, 27(4):513?540.Jin-Dong Kim, Ngan Nguyen, Yue Wang, Jun?ichi Tsu-jii, Toshihisa Takagi, and Akinori Yonezawa.
2012.The Genia Event and Protein Coreference tasks ofthe BioNLP Shared Task 2011.
BMC Bioinformat-ics, 13(Suppl 11):S1.Makoto Miwa, Paul Thompson, and Sophia Ana-niadou.
2012.
Boosting automatic event ex-traction from the literature using domain adapta-tion and coreference resolution.
Bioinformatics,28(13):1759?1765.Makoto Miwa, Tomoko Ohta, Rafal Rak, AndrewRowley, Douglas B. Kell, Sampo Pyysalo, andSophia Ananiadou.
2013a.
A method for integrat-ing and ranking the evidence for biochemical path-ways by mining reactions from text.
Bioinformatics.
(In Press).Makoto Miwa, Sampo Pyysalo, Tomoko Ohta, andSophia Ananiadou.
2013b.
Wide coverage biomedi-cal event extraction using multiple partially overlap-ping corpora.
BMC Bioinformatics, 14(1):175.Yusuke Miyao and Jun?ichi Tsujii.
2008.
Feature for-est models for probabilistic HPSG parsing.
Compu-tational Linguistics, 34(1):35?80, March.Eric W. Noreen.
1989.
Computer-Intensive Methodsfor Testing Hypotheses : An Introduction.
Wiley-Interscience, April.Tomoko Ohta, Sampo Pyysalo, Makoto Miwa, andJun?ichi Tsujii.
2011a.
Event extraction for dnamethylation.
Journal of Biomedical Semantics,2(Suppl 5):S2.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsu-jii.
2011b.
From pathways to biomolecularevents: Opportunities and challenges.
In Proceed-ings of BioNLP?11, pages 105?113, Portland, Ore-gon, USA.
ACL.Tomoko Ohta, Sampo Pyysalo, Rafal Rak, AndrewRowley, Hong-Woo Chun, Sung-Jae Jung, Sung-PilChoi, and Sophia Ananiadou.
2013.
Overview ofthe pathway curation (PC) task of bioNLP sharedtask 2013.
In Proceedings of BioNLP Shared Task2013 Workshop, Sofia, Bulgaria, August.
Associa-tion for Computational Linguistics.Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, andJun?ichi Tsujii.
2011.
Towards exhaustive event ex-traction for protein modifications.
In Proceedingsof BioNLP?11, pages 114?123, Portland, Oregon,USA, June.
ACL.Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, Han-Cheol Cho, Jun?ichi Tsujii, and Sophia Ananiadou.2012a.
Event extraction across multiple levels of bi-ological organization.
Bioinformatics, 28(18):i575?i581.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2012b.Overview of the ID, EPI and REL tasks of BioNLPShared Task 2011.
BMC Bioinformatics, 13(Suppl11):S2.Sampo Pyysalo, Tomoko Ohta, and Sophia Ananiadou.2013.
Overview of the cancer genetics (CG) taskof bioNLP shared task 2013.
In Proceedings ofBioNLP Shared Task 2013 Workshop, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.Kenji Sagae and Jun?ichi Tsujii.
2007.
Dependencyparsing and domain adaptation with LR models andparser ensembles.
In Proceedings of the CoNLLShared Task Session of EMNLP-CoNLL 2007, pages1044?1050, Prague, Czech Republic, June.
ACL.S.
Van Landeghem, J. Bjorne, C. H. Wei, K. Hakala,S.
Pyysalo, S. Ananiadou, H. Y. Kao, Z. Lu,T.
Salakoski, Y.
Van de Peer, and F. Ginter.2013.
Large-scale event extraction from literaturewith multi-level gene normalization.
PLoS One,8(4):e55814.David H Wolpert.
1992.
Stacked generalization.
Neu-ral networks, 5(2):241?259.98
