Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 78?87,Baltimore, Maryland USA, June 27, 2014.c?2014 Association for Computational LinguisticsLearning Predictive Linguistic Features for Alzheimer?s Disease andrelated Dementias using Verbal UtterancesSylvester Olubolu OrimayeIntelligent Health Research GroupSchool of Information TechnologyMonash University Malaysiasylvester.orimaye@monash.eduJojo Sze-Meng WongIntelligent Health Research GroupSchool of Information TechnologyMonash University Malaysiajojo.wong@monash.eduKaren Jennifer GoldenJeffrey Cheah School ofMedicine and Health SciencesMonash University Malaysiakaren.golden@monash.eduAbstractEarly diagnosis of neurodegenerative dis-orders (ND) such as Alzheimer?s disease(AD) and related Dementias is currently achallenge.
Currently, AD can only be di-agnosed by examining the patient?s brainafter death and Dementia is diagnosedtypically through consensus using spe-cific diagnostic criteria and extensive neu-ropsychological examinations with toolssuch as the Mini-Mental State Examina-tion (MMSE) or the Montreal CognitiveAssessment (MoCA).
In this paper, weuse several Machine Learning (ML) al-gorithms to build diagnostic models us-ing syntactic and lexical features resultingfrom verbal utterances of AD and relatedDementia patients.
We emphasize thatthe best diagnostic model distinguishedthe AD and related Dementias group fromthe healthy elderly group with 74% F-Measure using Support Vector Machines(SVM).
Additionally, we perform severalstatistical tests to indicate the significanceof the selected linguistic features.
Our re-sults show that syntactic and lexical fea-tures could be good indicative features forhelping to diagnose AD and related De-mentias.1 IntroductionAgeing and neurodegeneration can be a huge chal-lenge for developing countries.
As ageing popula-tion continues to increase, government and healthcare providers will need to deal with the associatedeconomic and social effects such as an increaseddependency ratio, higher need for social protec-tion, and smaller workforce.
The significance ofthis increase and demographic transition is a highprevalence of neurodegenerative diseases such asAD and related Dementias.
According to Kalariaet al.
(2008), 71% of 81.1 million dementia relatedcases have been projected to be in the developingcountries with annual costs of US$73 billion.Alzheimer?s disease is the most common formof dementia (Ballard et al., 2011).
However, earlydiagnosis of dementia is currently challenging, es-pecially in the earlier stages.
Dementias have beentypically diagnosed through extensive neuropsy-chological examinations using a series of cog-nitive tests containing set questions and images(Williams et al., 2013).
For example, the MMSEscreening tool is composed of a series of questionsand cognitive tests that assess different cognitiveabilities, with a maximum score of 30 points.
AMMSE score of 27 and above is suggestive ofnot having a Dementia related disease.
The chal-lenge with these cognitive tests is that the accu-racy depends on the clinician?s level of experi-ence and their ability to diagnose different sub-types of the disease as Dementia disease can beclassified further into Alzheimer?s disease, Vascu-lar Dementia, Dementia with Lewy bodies (DLB),Mixed dementia, Parkinson?s disease, as well asother forms1.As such, this paper investigates effective com-putational diagnostic models for predicting ADand related Dementias using several linguistic fea-tures extracted from the transcribed verbal utter-ances produced by potential patients.
The premiseis that, neurodegenrative disorders (ND) are char-acterized by the deterioration of nerve cells thatcontrol cognitive, speech and language processes,which consequentially translates to how patientscompose verbal utterances.
Thus, we proposed thediagnostic models using Machine Learning (ML)algorithms that learn such linguistic features andclassify the AD and related Dementias group fromthe healthy elderly group.1http://www.alz.org/dementia/types-of-dementia.asp782 Related WorkFew ML algorithms have been proposed to au-tomate the diagnosis of Dementias using lin-guistic features.
In a recent study, Williams etal.
(2013) experimented with different ML algo-rithms for learning neuropsychological and demo-graphic data which are then used for the predic-tion of Clinical Dementia Rating (CDR) scoresfor different sub-types of Dementia and other cog-nitive impairments.
In that study, four ML al-gorithms were used comprising of Na?
?ve Bayes(NB), C4.5 Decision Trees (DT), Neural Networkswith back-propagation (NN), and Support VectorMachines (SVM).
The study reports NB with thehighest classification accuracy; however, its accu-racy could be biased as the same NB was used forthe initial feature selection for all the four ML al-gorithms.
As such, the feature sets would havebeen optimized for NB.In another study, Chen and Herskovits (2010)proposed different diagnostic models that distin-guished the very mild dementia (VMD) groupfrom the healthy elderly group by using featuresfrom structural magnetic-resonance images (MRI)to train seven ML algorithms.
Their study reportedthat both SVM and Bayesian Networks (BayesNets) gave the best diagnostic models with thesame accuracy of 80%.
Similarly, a study byKl?oppel et al.
(2008) reported a better accuracywith SVM on the scans provided by radiologists.In contrast, we study several linguistic featuresfrom the transcribed verbal utterances of AD andrelated Dementia patients.
We emphasize that theproposed diagnostic models do not depend on thecomplex MRI scan processes but a simple verbaldescription of familiar activities in order to diag-nose the disease.A closely related work to ours is Garrardet al.
(2013) research.
The study used Na?
?veBayes Gaussian (NBG) and Na?
?ve Bayes multino-mial (NBM) to classify textual descriptions intoa Dementia group and a healthy elderly group.The Information Gain (IG) feature selection algo-rithm was used in both cases and both algorithmsachieved a better accuracy of up to 90% with fea-tures such as low frequency content words and cer-tain generic word components.
In this paper, westudy more exclusive syntactic and lexical featuresthat could distinguish the AD and related Demen-tia patients from the healthy group.
In addition, webuild several models by experimenting with differ-ent ML algorithms rather than NB alone.Similarly, Roark et al.
(2011) demonstrated theefficacy of using complex syntactic features toclassify mild cognitive impairment (MCI) but notAD and Dementia.
Also, de Lira et al.
(2011) in-vestigated the significance of lexical and syntacticfeatures from the verbal narratives of AD patientsby performing several statistical tests based on 121elderly participants comprising of 60 AD subjectsand 61 healthy subjects.
Their lexical featurescomprised of word-finding difficulties, immediateword repetition of isolated words, word revisions,semantic substitutions, and phonemic paraphasias.For syntactic features, coordinated sentences, sub-ordinated sentences, and reduced sentences wereexamined.
Upon performing and making com-parison between the parametric Student?s t-test (t)and the non-parametric Mann-Whitney test (U),only word-finding difficulties, immediate repeti-tions, word revisions, coordinated sentences, andreduced sentences were found to be statisticallysignificant with p = 0.001 at a 95% confidenceinterval (CI).
Further post-hoc analysis with theWald test (Wald X2) showed that immediate wordrepetitions, word revisions, and coordinated sen-tences could be used to distinguish AD patientsfrom the healthy elderly group.While de Lira et al.
(2011) did not perform anyevaluation using ML algorithms, we focus on thefeasibility of effectively diagnosing AD and re-lated Dementias by learning additional syntacticand lexical features with different ML algorithms.According to Ball et al.
(2009), syntactic process-ing in acquired language disorders such as Apha-sia in adults, has shown promising findings, en-couraging further study on identifying effectivesyntactic techniques.
Similarly, Locke (1997) em-phasized the significance of lexical-semantic com-ponents of a language, part of which is observ-able during utterance acquisition at a younger age.Locke highlighted further that as the lexical ca-pacity increases, syntactic processing becomes au-tomated, hence leading to changes in language.As such, it is almost certain that the effects of aspecific language disorder could be observed aschanges to the lexical and syntactic processes gov-erning language and verbal utterances.In this paper, we identify several syntactic andlexical features in addition to the significant fea-tures studied by de Lira et al.
(2011) and thentrain five different ML models to predict the like-79lihood of a patient having Dementia.
First, we ex-tract predictive syntactic and lexical features fromthe existing DementiaBank2corpus containing aset of transcribed texts from verbal utterances pro-duced by AD and related Dementia patients liv-ing in the United States.
The transcribed texts arestored in the CHAT system format in the Demen-tiaBank corpus made available by the School ofMedicine of the University of Pittsburgh as part ofthe TalkBank project3.
We further extract severallexical and syntactic features from the CHAT for-mat and conduct different statistical tests and thenlearn and evaluate with different ML algorithms.We emphasize that the best model accuracy re-ported in our study is comparable to the accuracyreported in Garrard et al.
(2013) and outperformsa model using only the three significant featuresreported in de Lira et al.
(2011).The rest of this paper is organized as follows.We present the methodology used in this study inSection 3.
The DementiaBank dataset and the par-ticipants are described in Section 3.1 and Section3.2 respectively.
Section 4 discusses the featureextraction process that extracts both the lexical andsyntactic features used in this study.
In Section 5,we perform statistical tests to understand the sig-nificant features.
Section 6 performs additionalfeature selection and make comparison with thestatistical test results.
We discuss the ML mod-els used in this study in Section 7.
Finally, results,discussion and conclusion are presented in Section8, 9, and 10.3 MethodsIt is common in clinical research to conduct inves-tigation on the actual patients (or subjects).
Thisprocess can be achieved over a period of time;however, previous research studies have madeavailable series of clinical datasets that reduce theinvestigation time considerably.
Although, thisstudy does not involve direct interaction with ac-tual patients, we focus on understanding the lin-guistic patterns from the verbal utterances of exist-ing patients.
In Section 2, we have discussed thoseverbal utterances to be present in the transcriptionfiles contained in the DementiaBank dataset andwe will describe the dataset further in Section 3.1.In this study, our focus is to use the extended syn-2http://talkbank.org/DementiaBank/3http://www.talkbank.org/browser/index.phptactic and lexical features from the transcripts andcompare to the features established in de Lira et al.
(2011) as our baseline.
We identified 21 featuresincluding the 3 significant features investigated inde Lira et al.
(2011).
9 of those features are syn-tactic, 11 are lexical features, and 1 is a confound-ing feature (age).
We will describe the features indetail in Section 4.
Our feature extraction is fol-lowed by statistical tests as performed in de Liraet al.
(2011).
Both the Student?s t-test (t) andthe Mann-Whitney test (U) are performed and fol-lowed by multiple logistic regression (MLR) thatshows the most significant features.
In addition,we also perform feature selection using the Infor-mation Gain algorithm and compare our results tothose achieved by MLR.
The final ML models arebuilt using SVM, NB, Bayes Net, DT, and NN.3.1 DatasetsIn this study, an existing DementiaBank clinicaldataset was used.
The dataset was created during alongitudinal study conducted by the University ofPittsburgh School of Medicine on Alzheimer?s andrelated Dementia and funded by the National In-stitute of Aging4.
The dataset contains transcriptsof verbal interviews with AD and related Demen-tia patients, including those with MCI.
Interviewswere conducted in the English language and werebased on the description of the Cookie-Theft pic-ture component which is part of the Boston Diag-nostic Aphasia Examination (Kaplan et al., 2001).During the interview, patients were given the pic-ture and were told to discuss everything they couldsee happening in the picture.
The patients?
ver-bal utterances were recorded and then transcribedinto the CHAT transcription format (MacWhinney,2000).
Thus, in this study, we extract the tran-scribed patient sentences from the CHAT files andthen pre-process the sentences for feature extrac-tion.3.2 ParticipantsThe participants in the DementiaBank dataset havebeen categorized into Dementia, Control, and Un-known patient groups.
Our study uses only theDementia and Control groups as we are interestedin the binary diagnosis of the AD and related De-mentias.
Thus, the Dementia group consists of 314elderly patients with an approximate age range of49 to 90 years.
The group consists of 239 peo-4http://www.nia.nih.gov/80ple diagnosed with probable AD; 21 with possibleAD; 5 with Vascula Dementia (VD); 43 with MCI;3 with Memory problem and 4 other people withan unidentified form of dementia.
On the otherhand, the Control group consists of 242 healthy el-derly without any reported diagnosis and with ap-proximate age range of 46 to 81 years.
In orderto have a balanced number of participants acrossgroups, we reduced the AD and related Dementiasgroup to the first 242 patients consisting of 189probable AD, 8 possible AD, 37 MCI, 3 memoryproblems, 4 Vascular dementia, and 1 other partic-ipant with an unidentified form of dementia.
In ad-dition, some demographic information was madeavailable in the DementiaBank dataset, however,we have only selected age in order to measure thesignificance of the disease with respect to age.4 Features ExtractionSeveral features were extracted from the transcriptfiles.
First, we extracted every CHAT symbol inthe transcript files and stored them according totheir frequencies and positions in each sentence.We emphasize that some CHAT symbols representboth explicit and implicit features that describe thelexical capability of the patient.
For example, hav-ing the CHAT symbol [//] at a specific positionwithin a sentence implies that the patient was re-tracing a verbal error that precedes that positionand at the same time attempting to make correc-tion, while the CHAT symbol [/] shows the patientmaking immediate word repetition (MacWhinney,2000).
On the other hand, it is non-trivial to extractthe syntactic features without performing syntacticparsing on the sentences.
As such, using the Stan-ford Parser Klein and Manning (2003), we gener-ated the syntactic tree structure of each sentenceand extract features as appropriate.4.1 Syntactic featuresAs described below, we investigated a numberof features that are seen to demand complexsyntactic processing, including the three syntac-tic features (coordinated, subordinated, and re-duced sentences) evaluated by de Lira et al.
(2011)and the Dependency distance feature evaluated byRoark et al.
(2011) and Pakhomov et al.
(2011).All syntactic features are extracted from the syn-tactic tree structures produced by the StanfordParser.?
Coordinated sentences: Coordinated sen-tences are those whose clauses are combinedusing coordinating conjunctions.
The num-ber of occurrence for this feature per patientnarrative is obtained based on the frequencyof the coordinating conjunction PoS tag (CC)detected in the parse tree structure.?
Subordinated sentences: Subordinated sen-tences are those that are subordinate to theindependent primary sentence to which theyare linked.
Similarly, the number of occur-rence for this feature per patient narrative isobtained based on the frequency of the sub-sentences indicated by the PoS tag (S) de-tected in the parse tree structure.?
Reduced sentences: Following the defini-tion set out by de Lira et al.
(2011), thisfeature represents those subordinated sen-tences without a conjunction but with nom-inal verb forms (which are either participlesor gerund).
To obtain the count for this fea-ture, the frequencies of PoS tags (VBG andVBN) are used.?
Number of predicates: The number of pred-icates found in every patient?s narrative canbe seen as another estimation of the sentencecomplexity.
The predicates are extracted us-ing a rule-based algorithm that locates transi-tive verbs which are followed by one or morearguments.
We emphasize that the impor-tance of predicate-argument structures hasbeen explored in the literature for text clas-sification tasks (Surdeanu et al., 2003; Ori-maye, 2013).?
Average number of predicates: The averagenumber of predicates per patient narrative isinvestigated as well to study its effect.?
Dependency distance: This feature was usedin the study of Pakhomov et al.
(2011) as away to measure grammatical complexity inpatients with Alzheimer?s disease.
The dis-tance value is calculated based on the sum ofall the dependency distances, in which eachdependency distance is the absolute differ-ence between the serial position of two wordsthat participate in a dependency relation.?
Number of dependencies: For a purpose sim-ilar as to the syntactic dependency distance,the number of unique syntactic dependency81relations found in every patient?s narrative isexamined.?
Average dependencies per sentence: We alsoconsider the average number of the uniquedependency relations per sentence.?
Production rules: Production rules derivedfrom parse trees has been explored in a num-ber of NLP related classification tasks (Wongand Dras, 2010; Post and Bergsma, 2013).We investigate this feature by counting thenumber of unique production rules in thecontext-free grammar form extracted fromeach patient?s narrative.4.2 Lexical featuresThe lexical features used in this study includethe revision and repetition features proposed inCroisile et al.
(1996) and evaluated in de Lira etal.
(2011).
The remaining features are addition-ally investigated lexical features that show betterimprovement with our models.?
Utterances: The total number of utterancesper patient was computed.
Each utterance isidentified to start from the beginning of a ver-bal communication to the next verbal pauselength, such as punctuation or a CHAT sym-bol that represents a specific break in com-munication (Marini et al., 2008).
A sentencecould have one or more utterances, and anutterance could be one word, a phrase or aclause.
It has been identified that utteranceacquisitions form a grammatical lexicon fora language (Locke, 1997).
Thus, we hypoth-esize that the absolute number of utterancesin a conversation could show the languagestrength of a potential patient.?
Mean Length of Utterances (MLU): We mea-sure the structural organization of sentencesusing the MLU.
This was computed as the ra-tio of the total number of words to the numberof utterances (Marini et al., 2008).
MLU hasbeen specifically used to measure grammargrowth in children with Specific LanguageImpairment (SLI) (Yoder et al., 2011).
In thisstudy, we investigate the significance of MLUin determining language disorder in AD andrelated Dementias.?
Function words: We compute the total num-ber of function words in the patient?s nar-rative.
Function words enable sentences tohave meaning and they have been studied asan essential attribute to brain and languageprocessing (Friederici, 2011).?
Unique words: We measure the total num-ber of unique words as the absolute wordcount minus the number of immediate re-peated words.?
Word count: This is measured as the absoluteword count including repeated words.?
Character length: We measure the absolutecharacter length of the patient?s narrative.?
Total sentences: This is the absolute count ofsentences in the patient?s narrative.?
Repetitions: This is measured as the numberof immediate word repetitions in the patient?snarrative (de Lira et al., 2011; Croisile et al.,1996).?
Revisions: This feature is measured as thecount of pause positions where the patient re-traced a preceding error and then made a cor-rection (MacWhinney, 2000; de Lira et al.,2011; Croisile et al., 1996).?
Lexical bigrams: We take into account thenumber of unique bigrams in a patient?s nar-rative in order to capture repeated bigram pat-terns.?
Morphemes: To capture the morphologystructure of the patient?s narrative, we mea-sured the number of morphemes.
Each mor-pheme represents a word or a part of it thatcannot be further divided (Creutz and Lagus,2002).5 Statistical EvaluationOne of the challenges that we encountered in eval-uating the features above is that some features arenot normally distributed.
An exception to that isthe confounding feature ?age?.
For age, it is ourassumption that the DementiaBank study was de-signed to cover normally distributed participantsin terms of age range.
For the other generatedfeatures, it is understandable, since each patientwould give specific attributes that show the sever-ity of the disease overtime.
As such, we performedone parametric test (Student?s t-test (t)) and one82non-parametric test (Mann-Whitney test (U)) andthen compared the results of the two tests similarto the baseline paper (de Lira et al., 2011).
Bothresults achieved the same results as shown in Table1; thus, we chose the parametric results for furtherstatistical evaluation.Further, we conducted a post-hoc test usingmultiple logistic regression analysis in order toidentify specific features that distinguish the ADand related Dementias group from the healthy el-derly group.
We present the results of the analy-sis using the Wald test (Wald X2) and the OddsRatio or Exp(B) as shown in Table 2.
A 95%confidence interval (CI) was computed for bothlower and upper bound of Exp(B) and p < 0.05shows statistical significance.
All tests performedare two-tailed using the IBM Statistical Packagefor the Social Sciences (SPSS) version 20.0.05.The result of our analysis is in agreement withthe study conducted by de Lira et al.
(2011); how-ever, we examined more features in our study.Our analysis shows that the statistically significantsyntactic features of the ADAG have lower meancompared to the HAG.
This indicates that the dis-ease group have difficulties in constructing com-plex sentences unlike the healthy group.
We sug-gest that effective use of predicates and reducedstructures could be of vital importance to appro-priately measure healthy language in Alzheimer?sdisease and related Dementia patients.
On theother hand, statistically significant lexical featuresof the ADAG have higher mean compared to theHAG, except for MLU with just 0.91 difference.This makes sense, for example, the disease groupperformed more immediate word repetitions andmade more revisions on grammatical errors intheir narrative.
More utterances were also noticedwith the disease group as they tend to make severalpauses resulting from syntactic errors and attemptsto correct or avoid those errors in the first place.The multiple logistic regression analysis in-dicates that number of utterances, reduced sen-tences, MLU, revisions, and number of predicatessignificantly distinguish the disease group fromthe healthy elderly group leaving out repetitionsand average predicates per sentence.
Interestingly,repetitions was found to be significant in de Liraet al.
(2011), albeit with just 121 patients.
Inour case, we suspect that repeated words could5http://www-01.ibm.com/software/analytics/spss/be less common with both groups given the com-bined 484 patients, while the absolute count ofpredicates in a discourse (not at the sentence level)could be more representative of the groups.
Theconfounding feature age was used because of theage difference between ADAG and HAG.
The re-sulting odd ratios OR emphasize the likelihoodof having Alzheimer?s and the related Demen-tia diseases when the distinguishing features areused.
Lower ?
values for MLU, predicates, andreduced sentences decreases the likelihood of hav-ing Alzheimer?s disease and related Dementias.6 Feature SelectionTo further support that the features selectedthrough statistical testing from the previous sec-tion (Section 5) are indeed significant, one of thewidely adopted metrics for feature selection in theML-based text classification paradigm ?
Infor-mation Gain (IG) ?
is explored.
We could adoptthe feature selection approach taken by Williamset al.
(2013), in which the subset of indicative fea-tures were selected based on a specific classifier,NB in their case; we chose to use IG instead giventhat the IG value for each feature is calculated in-dependent of the classifiers and thus reduces thechance of bias in terms of the model performance.By ranking the IG values for each of the extractedfeatures (both lexical and syntactic), the top eightfeatures with the highest IG values are the same asthe subset of the eight significant features identi-fied through the statistical tests.7 Machine Learning ModelsIn order to conduct an informed comparison withthe findings from the previous related work, weevaluate the same four ML models investigatedby Williams et al.
(2013) which include SupportVector Machines (SVM) with radial basis kernel,Na?
?ve Bayes (NB), J48 Decision Trees (DT), andNeural Networks (NN) with back propagation.
Inaddition, Bayesian Networks (Bayes Nets), whichhas also been found useful in the work of Chenand Herskovits (2010), is also evaluated.
Usingthe ML models, we performed three sets of exper-iments6to confirm the hypothesis that the identi-fied significant syntactic and lexical features couldgive effective diagnostic models.
First, we experi-mented with the three significant features reportedin de Lira et al.
(2011).
Second, we performed6https://github.com/soori1/ADresearch83ADAGMEAN(SD)HAGMEAN(SD)t df p 95%CI(Difference)Syntactic featuresCoordinated sentences 5.21(3.51) 4.73(3.11) 1.59 482 0.11 -0.11 to 1.07Subordinated sentences 5.37(3.41) 5.12(2.84) 0.85 482 0.40 -0.32 to 0.81Reduced Sentences 3.24(2.47) 4.12(2.67) -3.77 482 <0.000* -1.34 to -0.42Number of Predicates 5.77 (3.33) 7.03(3.63) -3.99 482 <0.000* -1.89 to -0.64Avr.Predicates per sentence 0.46(0.19) 0.57(0.23) -5.48 482 <0.000* -0.15 to -0.07Number of Dependencies 104.67(53.76) 104.12(50.20) 0.11 482 0.91 -8.75 to 9.83Avr.dependency per sen-tence8.84(2.71) 8.82(2.47) 0.09 482 0.932 -0.44 to 0.48Dependency distance 18.57(8.71) 18.12(8.04) 0.59 482 0.56 -1.05 to 1.95Production rules 128.36(50.68) 126.83(44.68) 0.35 482 0.73 -7.01 to 10.05Lexical featuresUtterances 43.56(28.22) 32.31(15.42) 5.44 482 <0.000* 7.19 to 15.31MLU 2.66(1.22) 3.57(1.31) -7.87 482 <0.000* -1.13 to -0.68Function words 59.18(34.82) 58.98(32.46) 0.07 482 0.948 -5.81 to 6.21Unique words 115.54(60.93) 116.17(55.61) -0.12 482 0.905 -11.05 to 9.79Word count 127.28(68.42) 127.25(63.24) 0.005 482 0.996 -11.74 to 11.79Character length 567.01(303.59) 580.87(292.07) -0.512 482 0.61 -67.07 to 39.35Total sentences 13.24(7.03) 12.86(5.29) 0.67 482 0.502 -0.73 to 1.49Repetitions 1.64(2.44) 0.64(0.99) 5.92 482 <0.000* 0.67 to 1.34Revision 3.77(4.36) 1.93(2.22) 5.87 482 <0.000* 1.23 to 2.47Lexical bigrams 104.84 (52.55) 106.79 (50.61) -0.42 482 0.677 -11.17 to 7.26Number of Morphemes 104.23(60.73) 107.90(55.74) -0.694 482 0.488 -14.09 to 6.74ADAG = Alzheimer?s disease and related Dementia group (n=242); HAG = Healthy elderly group (n=242); SD = standarddeviation; df = degree of freedom; CI = confidence Interval.Table 1: Statistical analysis of linguistic features based on Student?s t-test.Features ?
S.E WaldX2p OR 95% CI of ORAge -0.11 0.02 39.53 <0.000* 0.90 0.87 to 0.93Utterances -0.03 0.01 5.55 0.018* 0.97 0.95 to 0.99MLU 0.374 0.137 7.39 0.007* 1.45 1.11 to 1.90No of Predicates 0.25 0.059 17.64 <0.000* 1.28 1.14 to 1.44Revisions -0.143 0.069 4.33 0.037* 0.87 0.76 to 0.99Reduced Sentences 0.121 0.055 4.89 0.027* 1.129 1.01 to 1.26Constant 5.23 1.18 19.67 <0.000* 187.25 -ADAG, n=242; HAG, n = 242; S.E = standard error; OR = Odds ratio or Exp(?
); CI = confidence Interval.Table 2: Multiple logistic regression analysis on significant and confounding features.an experiment with the eight significant featuresidentified by the parametric test reported in Table1.
Finally, we used the six distinguishing featuresidentified by MLR in Table 2.Given the relatively small size of the datasetused in this study, we conduct a 10-fold crossvalidation on each of the ML models by usinga balanced data set with 242 instances for eachgroup: the AD and related Dementias group andthe healthy (Control) group.
Performance of theML models were measured in terms of precision,recall, and F-measure.
All the ML experimentsincluding the IG ranking are conducted using theWeka toolkit7with the default settings.7http://www.cs.waikato.ac.nz/ml/weka/8 ResultsThe results of the three experiments are shown inTable 3, 4, and 5 respectively.
In addition, Table 6shows a summary of the performance of the bestML model (SVM) for predicting Alzheimer?s dis-ease and the related Dementia diseases.Our results show that SVM gave better F-Measure and recall in most cases compared toother ML algorithms.
Interestingly, DT, BayesNets, and NB showed better precision on the dis-ease group using the 6 and 8 significant features.Specifically, using the 6 significant features, DTshowed 78% precision but 69% recall on the dis-ease group.
Similarly, Bayes Nets showed 77%precision but 66% recall on the disease group.Overall, SVM takes the lead as it showed the high-est F-Measure of 74% on the disease group with75% precision and 73% recall.84Model Precision(ADAG/HAG)Recall(ADAG/HAG)F?Measure(ADAG/HAG)SVM 0.70/0.65 0.59/0.75 0.64/0.70NB 0.72/0.57 0.34/0.87 0.47/0.69DT 0.67/0.65 0.62/0.69 0.65/0.67NN 0.70/065 0.60/0.74 0.64/0.69Bayes Nets 0.66/0.68 0.71/0.64 0.68/0.66Table 3: Results of different ML models using the three significant features reported in (de Lira et al.,2011) on both disease and healthy elderly groups.Model Precision(ADAG/HAG)Recall(ADAG/HAG)F?Measure(ADAG/HAG)SVM 0.74/0.73 0.73/0.74 0.73/0.74NB 0.77/0.62 0.46/0.86 0.58/0.72DT 0.74/0.69 0.66/0.77 0.70/0.73NN 0.75/0.72 0.69/0.77 0.72/0.74Bayes Nets 0.75/0.69 0.65/0.78 0.70/0.73Table 4: Results of different ML models using the eight statistically significant features in Table 1 onboth disease and healthy elderly groups.9 DiscussionThe results of our ML experiments and statisti-cal evaluations suggest that using ML algorithmsby learning syntactic and lexical features from theverbal utterances of elderly people can help the di-agnosis of Alzheimers and the related Dementiadiseases.
The outcome of our evaluations is simi-lar to the study conducted in de Lira et al.
(2011).However, our study identifies more indicative andrepresentative linguistic features compared to deLira et al.
(2011).
Furthermore, the results of ourstatistical evaluation agree with the feature selec-tion results (using IG).
That is, all the statisticallysignificant features discussed in Section 5 are alsothe top ranked features using the IG feature selec-tion algorithm in Section 6.
Following the identifi-cation of additional linguistic features, we empha-size that the best ML model with six significantlinguistic features (age, utterances, MLU, reducedsentences, revisions, and predicates) outperformsa three-feature model (repetitions, revisions, andcoordinated sentence).
More importantly, unlikede Lira et al.
(2011), repetitions and coordinatedsentences did not contribute to the accuracy ofour diagnostic models.
Finally, in comparison toWilliams et al.
(2013), SVM obtained the highestprediction accuracy, albeit on linguistic features.Moreover, unlike Williams et al.
(2013), our fea-ture selection process is independent of the bestML algorithm (SVM) in our case.
Again, thisavoids unnecessary bias especially in clinical di-agnosis.
A limitation of this study could be the useof a binary classification between a combined De-mentia related diseases group with different sub-types (such as AD, MCI and memory problems)and a control group of healthy participants.
Al-though MCI could sometimes (but not always) bea precursor to AD and Dementia, we suggest thatit could be important to exclude patients with MCIand other minor memory problems from the ADand related Dementia patients in future study.10 Conclusion and Future WorkWe have investigated promising diagnostic modelsfor Alzheimer?s and the related Dementia diseasesusing syntactic and lexical features from verbal ut-terances.
We performed statistical and ML evalu-ations and show that the disease group used lesscomplex sentences than the healthy elderly group.Additionally, following our regression analysis,we show that the disease group makes more gram-matical errors and at the same time makes rea-sonable attempts to correct or avoid those errorsin the first place.
We also emphasized that ut-terances, reduced sentences, MLU, revisions, andnumber of predicates, significantly distinguish thedisease group from the healthy elderly group.
Inthe future, we plan to investigate indexical cues,prosodic cues, and semantic cues in order to cap-ture the perspectives in a patient?s narrative.
Fur-thermore, we intend to evaluate our models againstthe MMSE and MoCA diagnostic thresholds onactual AD and Dementia patients in a developingcountry.
More importantly, there is a need to trainthe diagnostic models on a larger dataset, which85Model Precision(ADAG/HAG)Recall(ADAG/HAG)F?Measure(ADAG/HAG)SVM 0.75/0.74 0.73/0.76 0.74/0.75NB 0.79/0.65 0.53/0.86 0.63/0.74DT 0.78/0.71 0.69/0.76 0.71/0.73NN 0.74/0.70 0.67/0.76 0.71/0.73Bayes Nets 0.77/0.70 0.66/0.80 0.71/0.75Table 5: Results of different ML models using the six statistically significant features in Table 2 on bothdisease and healthy elderly groups.Model Precision Recall F?Measure6-feature 0.75* 0.73* 0.74*8-feature 0.74 0.73 0.733-feature(Baseline) 0.70 0.59 0.64Table 6: Summary of SVM performance with the best predictive features for diagnosing AD and relatedDementias.could lead to better accuracy.
Furthermore, longi-tudinal studies are recommended in order to im-prove sample sizes and follow the course of thedisease overtime.ReferencesMartin J Ball, Michael R Perkins, Nicole M?uller, andSara Howard.
2009.
The handbook of clinical lin-guistics, volume 56.
John Wiley & Sons.Clive Ballard, Serge Gauthier, Anne Corbett, CarolBrayne, Dag Aarsland, and Emma Jones.
2011.Alzheimer?s disease.
The Lancet, 377(9770):1019?
1031.Rong Chen and Edward H Herskovits.
2010.
Machine-learning techniques for building a diagnostic modelfor very mild dementia.
Neuroimage, 52(1):234?244.Mathias Creutz and Krista Lagus.
2002.
Unsuper-vised discovery of morphemes.
In Proceedings ofthe ACL-02 workshop on Morphological and phono-logical learning-Volume 6, pages 21?30.
Associa-tion for Computational Linguistics.Bernard Croisile, Bernadette Ska, Marie-Josee Bra-bant, Annick Duchene, Yves Lepage, GilbertAimard, and Marc Trillet.
1996.
Comparativestudy of oral and written picture description in pa-tients with alzheimer?s disease.
Brain and language,53(1):1?19.Juliana Onofre de Lira, Karin Zazo Ortiz, Aline Car-valho Campanha, Paulo Henrique FerreiraBertolucci, and Tha?
?s Soares Cianciarullo Minett.2011.
Microlinguistic aspects of the oral narrativein patients with alzheimer?s disease.
InternationalPsychogeriatrics, 23(03):404?412.Angela D Friederici.
2011.
The brain basis of lan-guage processing: from structure to function.
Phys-iological reviews, 91(4):1357?1392.Peter Garrard, Vassiliki Rentoumi, Benno Gesierich,Bruce Miller, and Maria Luisa Gorno-Tempini.2013.
Machine learning approaches to diagnosisand laterality effects in semantic dementia discourse.Cortex.Raj N Kalaria, Gladys E Maestre, Raul Arizaga,Robert P Friedland, Doug Galasko, Kathleen Hall,Jos?e A Luchsinger, Adesola Ogunniyi, Elaine KPerry, Felix Potocnik, et al.
2008.
Alzheimer?sdisease and vascular dementia in developing coun-tries: prevalence, management, and risk factors.
TheLancet Neurology, 7(9):812?826.Edith Kaplan, Harold Goodglass, Sandra Weintraub,Osa Segal, and Anita van Loon-Vervoorn.
2001.Boston naming test.
Pro-ed.Dan Klein and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, ACL ?03, pages 423?430.
Association for Computational Linguistics.Stefan Kl?oppel, Cynthia M Stonnington, JosephineBarnes, Frederick Chen, Carlton Chu, Catriona DGood, Irina Mader, L Anne Mitchell, Ameet C Pa-tel, Catherine C Roberts, et al.
2008.
Accuracyof dementia diagnosisa direct comparison betweenradiologists and a computerized method.
Brain,131(11):2969?2974.John L Locke.
1997.
A theory of neurolinguistic de-velopment.
Brain and language, 58(2):265?326.Brian MacWhinney.
2000.
The CHILDES Project:The database, volume 2.
Psychology Press.Andrea Marini, Ilaria Spoletini, Ivo Alex Rubino,Manuela Ciuffa, Pietro Bria, Giovanni Martinotti,Giulia Banfi, Rocco Boccascino, Perla Strom, Al-berto Siracusano, et al.
2008.
The language ofschizophrenia: An analysis of micro and macrolin-guistic abilities and their neuropsychological corre-lates.
Schizophrenia Research, 105(1):144?155.86Sylvester Olubolu Orimaye.
2013.
Learning to clas-sify subjective sentences from multiple domainsusing extended subjectivity lexicon and subjectivepredicates.
In Information Retrieval Technology,pages 191?202.
Springer.Serguei Pakhomov, Dustin Chacon, Mark Wicklund,and Jeanette Gundel.
2011.
Computerized assess-ment of syntactic complexity in alzheimer?s disease:A case study of iris murdoch?s writting.
BehaviorResearch Methods, 43(1):136?144.Matt Post and Shane Bergsma.
2013.
Explicit andimplicit syntactic features for text classification.
InProceedings of the 51st Annual Meeting on Associa-tion for Computational Linguistics - Volume 2, ACL?13, pages 866?872, August.Brian Roark, Margaret Mitchell, John-Paul Hosom,Kristy Hollingshead, and Jeffrey Kaye.
2011.Spoken language derived measures for detect-ing mild cognitive impairment.
Audio, Speech,and Language Processing, IEEE Transactions on,19(7):2081?2090.Mihai Surdeanu, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using predicate-argumentstructures for information extraction.
In Proceed-ings of the 41st Annual Meeting on Association forComputational Linguistics-Volume 1, pages 8?15.Association for Computational Linguistics.Jennifer A Williams, Alyssa Weakley, Diane J Cook,and Maureen Schmitter-Edgecombe.
2013.
Ma-chine learning techniques for diagnostic differentia-tion of mild cognitive impairment and dementia.
InWorkshops at the Twenty-Seventh AAAI Conferenceon Artificial Intelligence.Sze-Meng Jojo Wong and Mark Dras.
2010.
Parserfeatures for sentence grammaticality classification.In Proceedings of the Australasian Language Tech-nology Association Workshop 2010, pages 67?75,December.Paul J Yoder, Dennis Molfese, and Elizabeth Gard-ner.
2011.
Initial mean length of utterance pre-dicts the relative efficacy of two grammatical treat-ments in preschoolers with specific language impair-ment.
Journal of Speech, Language, and HearingResearch, 54(4):1170?1181.87
