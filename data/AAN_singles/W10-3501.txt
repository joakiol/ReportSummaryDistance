Proceedings of the 2nd Workshop on ?Collaboratively Constructed Semantic Resources?, Coling 2010, pages 1?9,Beijing, August 2010Constructing Large-Scale Person Ontology from WikipediaYumi ShibakiNagaoka University ofTechnologyshibaki@jnlp.orgMasaaki NagataNTT CommunicationScience Laboratoriesnagata.masaaki@labs.ntt.co.jpKazuhide YamamotoNagaoka University ofTechnologyyamamoto@jnlp.orgAbstractThis paper presents a method for con-structing a large-scale Person Ontologywith category hierarchy from Wikipe-dia.
We first extract Wikipedia categorylabels which represent person (hereafter,Wikipedia Person Category, WPC) byusing a machine learning classifier.
Wethen construct a WPC hierarchy by de-tecting is-a relations in the Wikipediacategory network.
We then extract thetitles of Wikipedia articles whichrepresent person (hereafter, Wikipediaperson instance, WPI).
Experimentsshow that the accuracy of WPC extrac-tion is 99.3% precision and 98.4% re-call, while that of WPI extraction is98.2% and 98.6%, respectively.
The ac-curacies are significantly higher thanthe previous methods.1  IntroductionIn recent years, we have become increasinglyaware of the need for, up-to-date knowledgebases offering broad coverage in order to im-plement practical semantic inference enginesfor advanced applications such as questionanswering, summarization and textual entail-ment recognition.
General ontologies, such asWordNet (Fellbaum et al, 1998), and NihongoGoi-Taikei (Ikehara et al, 1997), contain gen-eral knowledge of wide range of fields.
How-ever, it is difficult to instantly add new know-ledge, particularly proper nouns, to these gen-eral ontologies.
Therefore, Wikipedia hascome to be used as a useful corpus for know-ledge extraction because it is a free and large-scale online encyclopedia that continues to beactively developed.
For example, in DBpedia(Bizer et al 2009), RDF triples are extractedfrom the Infobox templates within Wikipediaarticles.
In YAGO (Suchanek et al 2007), anappropriate WordNet synset (most likely cate-gory) is assigned to a Wikipedia category as asuper-category, and Wikipedia articles are ex-tracted as instances of the category.As a first step to make use of proper nounand related up-to-date information in Wikipedia,we focus on person names and the articles andcategories related to them because it contains alarge number of articles and categories that in-dicate person, and because large-scale personontology is useful for applications such as per-son search and named entity recognition.
Ex-amples of a person article are personal nameand occupational title such as ?Ichiro?
and ?Fi-nancial planner,?
while an example of a personcategory is occupational title such as?Sportspeople.
?The goal of this study is to construct a large-scale and comprehensive person ontology byextracting person categories and is-a relations1among them.
We first apply a classifier basedon machine learning to all Wikipedia categoriesto extract categories that represent person.
Ifboth of the linked Wikipedia categories are per-son categories, the category link is labeled asan is-a relation.
We then use a heuristic-basedrule to extract the title of articles that representperson as person instance from the person cate-gories.In the following sections, we first describethe language resources and the previous works.We then introduce our method for constructingthe person ontology and report our experimen-tal results.1 ?is-a relation?
is defined as a relation between A and Bwhen ?B is a (kind of) A.?12 Language Resources2.1  Japanese WikipediaWikipedia is a free, multilingual, on-line en-cyclopedia that is being actively developed by alarge number of volunteers.
Wikipedia has ar-ticles and categories.
The data is open to thepublic as XML files2.
Figure 1 shows an exam-ple of an article.
An article page has a title,body, and categories.
In most articles, the firstsentence of the body is the definition sentenceof the title.
Although the Wikipedia categorysystem is organized in a hierarchal manner, it isa thematic classification, not a taxonomy.
Therelation between category and subcategory andthat between a category and articles listed on itare not necessarily an is-a relation.
A categorycould have two or more super categories andthe category network could have loops.????????
?Michelle Wie, 1989?10?11?- ???????????
?Michelle Wie (Michelle Wie, born October 11,1989 ) is a golf player.Category : American golfers | 1989 birthsMi lle Wiecategorytitle of articledefinitio  sentenceFigure 1: Example of title, body (definitionsentence), and categories for article page inJapanese Wikipedia (top) and its translation(bottom)2.2 Nihongo Goi-TaikeiTo construct the ontology, we first apply a ma-chine learning based classifier to determine if acategory label indicates a person or not.
A Wi-kipedia category label is often a common com-pound noun or a noun phrase, and the headword of a Japanese compound noun and nounphrase is usually the last word.
We assume thesemantic category of the last word is an impor-tant feature for classification.Nihongo Goi-Taikei (hereafter, Goi-Taikei)is one of the largest and best known Japanesethesauri.
Goi-Taikei contains different semanticcategory hierarchies for common nouns, propernouns, and verbs.
In this work, we use only the2http://download.wikimedia.org/jawikicommon noun category (Figure 2).
It consistsof approximately 100,000 Japanese words (he-reafter, instance) and the meanings of eachword are described by using about 2,700 hie-rarchical semantic categories.
Words (In-stances) with multiple meanings (ambiguouswords) are assigned multiple categories in Goi-Taikei.
For example, the transliterated Japaneseword (instance) raita (???? )
has twomeanings of ?writer?
and ?lighter,?
and so be-longs to two categories, ?353:author 3 ?
and?915:household.
?Japanese WordNet (approximately 90,000entries as of May 2010), which has recentlybeen released to the public (Bonds et al, 2008),could be an alternative to Goi-Taikei as a large-scale Japanese thesaurus.
We used Goi-Taikeiin this work because Japanese WordNet wastranslated from English WordNet and it is notknown whether it covers the concepts unique toJapanese.3 Previous Works3.1 Ponzetto?s method and Sakurai?s me-thodPonzetto et al (2007) presented a set oflightweight heuristics such as head matchingand modifier matching for distinguishing is-alinks from not-is-a links in the Wikipedia cate-gory network.
The main heuristic, ?Syntax-based methods?
is based on head matching, inwhich a category link is labeled as is-a relationif the two categories share the same head lem-ma, such as CAPITALS IN ASIA and CAPI-TALS.
Sakurai et al (2008) presented a methodequivalent to head matching for Japanese Wi-kipedia.
As Japanese is a head final language,they introduced the heuristic called suffixmatching; it labels a category link as a is-a rela-tion if one category is the suffix of the othercategory, such as ?????
(airports in Ja-pan) and ??(airports).
In the proposed me-thod herein, if a Wikipedia category and itsparent category are both person categories, thecategory link is labeled as is-a relation.
There-fore, is-a relations, which cannot be extractedby Ponzetto?s or Sakurai?s method, can be ex-tracted.3 The Goi-Taikei category is prefixed with ID number.2246:personalitiesand competitors5:humans 223:officials 219:semi-man249:actor 251:competitor453:shrine 221:spirit4:people151:ethnic group152:ethnic group 153:race 55:boy 56:girl1:common noun2:concrete1000:abstract3:agents 388:places 533:objects362:organizations 389:facilities 468:nature 534:animate1235:events1936:job1937:business1939:occupation1065:title1069:number1066:name2483:nature 2507:state385:nation383:assemblyWriter????
?353:author 915:household appliancelighter????
?706:inanimateSemantic category hierarchy for common nouns1236:humanactivities1001:abstractthings2422:abstractrelationshipAbout 2,700 categoriesAbout 100,000 instancesFigure 2: Part of a category hierarchy for common nouns in Nihongo Goi-Taikei3.2 Kobayashi?s methodKobayashi et al (2008) presented a tech-nique to make a Japanese ontology equivalentto YAGO; it assigns Goi-Taikei categories toJapanese Wikipedia categories.
These two me-thods and our method are similar in that a Wi-kipedia category and the title of an article areregarded as a category and an instance, respec-tively.
Kobayashi et al automatically extracthypernyms from the definition sentence of eacharticle in advance (referred to hereafter as ?D-hypernym.?)
They apply language-dependentlexico-syntactic patterns to the definition sen-tence to extract the D-hypernym.
Here are someexamples.??[hypernym]??????
<EOS>one of [hypernym]??[hypernym]??
?<EOS>is a [hypernym][hypernym] <EOS>is a [hypernym] ?where <EOS> refer to the beginning of asentenceFor example, from the article in Figure 1, thewords ??????
(golf player)?
is extractedas the D-hypernym of the article ?????????
(Michelle Wie).
?Figure 3 outlines the Kobayashi?s method.First, for a Wikipedia category, if its last wordmatches an instance of Goi-Taikei category, allsuch Goi-Taikei categories are extracted as acandidate of the Wikipedia category?s super-class.
If the last word of the D-hypernym of theWikipedia article listed on the Wikipedia cate-gory matches an instance of the Goi-Taikei cat-egory, the Goi-Taikei category is extracted asthe super-class of the Wikipedia category andits instances (Wikipedia articles) (Figure 3).Although the Kobayashi?s method is a generalone, it can be used to construct person ontologyif the super-class candidates are restricted tothose Goi-Taikei categories which representperson.
Titl             ???????
?Michelle WieHypernym   ????
?Golf player????????????
?American golfersWikipedia categoryMatchlast wordPerson category?_person?????_golfer??_player???_artist??
?Goi-TaikeiWikipedia articleTitle            ALPG??
?ALPG TourHypernym   ?????
?Golf tourDoesn?tmatchWikipedia article ?Figure 3: The outline of Kobayashi?s method3.3 Yamashita?s methodYamashita made an open source softwarewhich extracts personal names from JapaneseWikipedia4.
He extracted the titles of articleslisted on the categories ???(?
births) (e.g.,2000 births).
As these categories are used tosort the names of people, horses, and dogs byborn year, he used a simple pattern matching4http://coderepos.org/share/browser/lang/perl/misc/wikipejago3rules to exclude horses and dogs.
In the expe-riment in Section 5, we implemented his me-thod by using not only ???
(births)?
but also???
(deaths)?
and ????
(th-centurydeaths),?
????
(s deaths),?
????
(sbirths),?
and ????
(th births)?
to extractpersonal names.
As far as we know, it is theonly publicly available software to extract alarge number of person names from the Japa-nese Wikipedia.
For the comparison with ourmethod, it should be noted that his methodcannot extract person categories.4 Ontology Building Method4.1 Construction of Wikipedia person cat-egory hierarchy (WPC)We extract the WPC by using a machine learn-ing classifier.
If a Wikipedia category and itsparent category are both person categories, thecategory link is labeled as an is-a relation.
Thismeans that all is-a relations in our person on-tology are extracted from the original Wikipe-dia category hierarchy using only a categoryclassifier.
This is because we investigated1,000 randomly sampled links between personcategories and found 98.7% of them were is-arelations.
Figure 4 shows an example of theWikipedia category hierarchy and the con-structed WPC hierarchy.Music TechnologyComposersBroadcastingWikipedia personcategory (WPC)Announcer productionsAnnouncersis-ais-ais-ais-aCategory withoutparent and childR ot categoryMusiciansConductorsEngineersAnnouncersMusiciansConductorsComposersJapanese conductorsEngineersJapanese conductorsFigure 4: Example of Wikipedia category hie-rarchy (top) and constructed Wikipedia personcategory hierarchy (bottom)We detect whether the Wikipedia categorylabel represents a person by using Support Vec-tor Machine (SVM).
The semantic category ofthe words in the Wikipedia category label andthose in the neighboring categories are used forthe features.
We use the following three aspectsof the texts that exist around the target categoryfor creating the features:1.
Structural relation between the target cat-egory and the text in Wikipedia.
(6 kinds)2.
Span of the text.
(2 kinds)3.
Semantic category of the text derivedfrom Goi-Taikei.
(4 kinds)We examined 48 features by combining theabove three aspects (6*2*4).The following are the six structural relationsin Wikipedia between the target category andthe text information:Structural relationA.
The target Wikipedia category label.B.
All parent category labels of the target cat-egory.C.
All child category labels of the target   cat-egory.D.
All sibling category labels of the targetcategory.E.
All D-hypernym5 from each article listed onthe target category.F.
All D-hypernyms extracted from the ar-ticles with the same name as the target cate-gory.As for F, for example, when the article ?????
(bassist) is listed on the category: ??
?
?
?
(bassist), we regard the D-hypernym of the article as the hypernym ofthe category.As most category labels and D-hypernyms arecommon nouns, they are likely to match in-stances in Goi-Taikei which lists possible se-mantic categories of words.5As for D-hypernym extraction patterns, we used almostthe same patterns described in previous works on Japa-nese sources such as (Kobayashi et al 2008; Sumida et al,2008), which are basically equivalent to the works onEnglish sources such as (Hearst, 1992).4After the texts located at various structuralrelations A-F are collected, they are matched tothe instances of Goi-Taikei in two differentspans:Span of the text?.
All character strings of the text?.
The last word of the textFor the span ?, the text is segmented intowords using a Japanese morphological analyzer.The last word is used because the last wordusually represents the meaning of the entirenoun phrase (semantic head word) in Japanese.In the proposed method, hierarchical seman-tic categories of Goi-Taikei are divided intotwo categories; ?Goi-Taikei person categories?and other categories.
Goi-Taikei person catego-ry is defined as those categories that representperson, that is, all categories under ?5:humans?and ?223:officials,?
and ?1939: occupation?and ?1066:name?
in Goi-Taikei hierarchy asshown in Figure 1.For each structural relation A-F  and span ?and ?, we calculate four relative frequenciesa-d, which represents the manner in which thespan of texts match the instance of Goi-Taikeiperson category.
It basically indicates the de-gree to which the span of text is likely to meana person.Semantic typea.
The span of text matches only instances ofGoi-Taikei person categories.b.
The span of text matches only instances ofcategories other than Goi-Taikei person cat-egories.c.
The span of text matches both instances ofGoi-Taikei person categories and those ofother categories.d.
The span of text does not match any in-stances of Goi-Taikei.For example, when the target category is ?????
(musicians) in Figure 5 and the feature inquestion is B-?
(the last word of its parentcategories), the word ???
(whose senses arefamily and house) falls into semantic type c,and the word ????
(music) falls into seman-tic type b.
Therefore, the frequency of semantictypes a, b, c, d are 0, 1, 1, 0, respectively, in thefeatures related to B-?, and the relative fre-quencies used for the feature value related B-?are 0, 0.5, 0.5, 0, respectively.
In this way, weuse 48 relative frequencies calculated from thecombinations of structural relation A-F, span?
and ?, and semantic type a-d, as the featurevector for the SVM.
?Target category?Similar category?Last word??
?_Artists ??_Music???_Musicians?????
?_Jazz composers???_Composers??
?_Musicians by instrument??
Art ?????
?_People by occupationFigure 5: Example of Wikipedia category hie-rarchy when the target category is ????
?4.2  Similar categoryIn Wikipedia, there are categories that do nothave articles and those with few neighboringcategories.
Here, we define the neighboringcategories for a category as those categoriesthat can be reached through a few links fromthe category.
In these cases, there is a possibili-ty that there is not enough text informationfrom which features (mainly semantic categoryof words) can be extracted, which could de-grade the accuracy.The proposed method overcomes this prob-lem by detecting categories similar to the targetcategory (the category in question) from itsneighboring categories for extracting sufficientfeatures to perform classification.
Here, "simi-lar category" is defined as parent, child, andsibling categories whose last word matches thelast word of the target category.
This is becausethere is a high possibility that the similar cate-gories and the target category have similarmeaning if they share the same last word in thecategory labels.
If the parent (child) category isdetermined as a similar category, its parent(child) category is also determined as a similarcategory if the last word is the same.
The pro-cedure is repeated as long as they share thesame last word.Figure 5 shows an example of similar cate-gories when the target category is ?Musicians.
?In this case, features extracted from A-F of5similar categories are added to features ex-tracted using A-F of the target category, ?Mu-sicians.?
For example, similar category ?Art-ists?
has ?Art?
and ?People by occupation?
asB (parent categories of the target category) inFigure 5, therefore ?Art?
and ?People by occu-pation?
are added to B of ?Musicians.
?4.3 Extracting Wikipedia person instance(WPI)The proposed method extracts, as WPIs thetitles of articles listed as WPCs that meet thefollowing four requirements.1.
The last word of the D-hypernym of thetitle of the Wikipedia article matches an in-stance of Goi-Taikei person category.2.
The last word of the title of Wikipedia ar-ticle matches an instance of Goi-Taike per-son category.3.
At least one of the Wikipedia categories as-signed to the Wikipedia article matches thefollowing patterns:(??|???|???|??|???|???
)<EOS>( deaths | th-century deaths | ?s deaths | births | th-births | ?sbirths ) <EOS>These categories are used to sort a largenumber of person names by year.4.
Wikipedia categories assigned to the Wiki-pedia article satisfy the following condition:5.0categories  Wikipediaofnumber  All4.1Section in   WPCsextracted ofNumber ??
?This condition is based on the observationthat the more WPCs a Wikipedia article isassigned to, the more it is likely to be a WPI.We set the threshold 0.5 from the results of apreliminary experiment.5 Experiments5.1 Experimental setupWe used the XML file of the Japanese Wiki-pedia as of July 24, 2008.
We removed irrele-vant pages by using keywords (e.g., ?image:,??Help:?)
in advance.
This cleaning yielded477,094 Wikipedia articles and 39,782 Wiki-pedia categories.
We manually annotated eachcategory to indicate whether it represents per-son (positive) or not (negative).
For ambiguouscases, we used the following criteria:?Personal name by itself (e.g., Michael Jack-son) is not regarded as WPC because usuallyit does not have instances.
(Note: personalname as article title is regarded as WPI.
)?Occupational title (e.g., Lawyers) is regardedas WPC because it represents a person.
?Family (e.g., Brandenburg family) and Eth-nic group (e.g., Sioux) are regarded as WPC.
?Group name (e.g., The Beatles) is not re-garded as WPC.In order to develop a person category classifier,we randomly selected 2,000 Wikipedia catego-ries (positive:435, negative:1,565) from all cat-egories for training6.
We used the remaining37,767 categories for evaluation.
To evaluateWPI extraction accuracy, we used Wikipediaarticles not listed on the Wikipedia categoriesused for training.
417,476 Wikipedia articleswere used in the evaluation.To evaluate our method, we used TinySVM-0.09 7  with a linear kernel for classification,and the Japanese morphological analyzer JU-MAN-6.0 8  for word segmentation.
The com-parison methods are Kobayashi?s method andYamashita?s method under the same conditionsas our method.5.2 Experimental resultsTable 1 shows the WPCs extraction accuracy.Precision and recall of proposed method are 6.5points and 14.8 points better than those of Ko-bayashi's method, respectively.Precision Recall F-measureKobayashi?smethod92.8%(6727/7247)83.6%(6727/8050)88.0%Proposedmethod99.3%(7922/7979)98.4%(7922/8050)98.8%Table 1: The Wikipedia person categories(WPCs) extraction accuracy6We confirmed that the accuracy will level off about2,000 training data by experiment.
Details will be de-scribed in Section 6.7http://chasen.org/~taku/software/TinySVM/8http://www-lab25.kuee.kyoto-u.ac.jp/nl-resource/juman.html6To confirm our assumption on the links be-tween WPCs, we randomly selected 1,000 pairsof linked categories from extracted WPCs, andmanually investigated whether bothrepresented person and were linked by is-a re-lation.
We found that precision of these pairswas 98.3%.Errors occurred when the category link be-tween  person categories in the Wikipedia cate-gory network was not an is-a relation, such as???
(Chiba clan) ?
????
(Ohsuga clan).However, this case is infrequent, because98.7% of the links between person categoriesdid exhibit an is-a relation (as described in Sec-tion 4.1).Table 2 shows the WPIs extraction accuracy.We randomly selected 1,000 Wikipedia articlesfrom all categories in Wikipedia, and manuallycreated evaluation data (positive:281, nega-tive:719).
The recall of the proposed methodwas 98.6%, 21.0 points higher than that of Ya-mashita?s method.
Our method topped the F-measure of Kobayashi?s method by 3.4 points.Among 118,552 extracted as WPIs by our me-thod, 116,418 articles were expected be correct.In our method, errors occurred when WPI wasnot listed on any WPCs.
However, this case isvery rare.
Person instances are almost alwaysassigned to at least one WPC.
Thus, we canachieve high coverage for WPIs even if we fo-cus only on WPCs.
We randomly selected1,000 articles from all articles and obtained 277person instances by a manual evaluation.
Fur-thermore, we investigated the 277 person in-stances, and found that only two instances werenot classified into any WPCs (0.7%).Precision Recall F-measureYamashita'smethod100.0%(218/218)77.6%(218/281)87.4%Kobayashi'smethod96%(264/275)94.0%(264/281)95.0%Proposedmethod98.2%(277/282)98.6%(277/281)98.4%Table 2: The Wikipedia person instance(WPIs) extraction accuracyTable 3 shows the extracted WPC-WPI pairs(e.g., American golfers-Michelle Wie, Artists-Meritorious Artist) extraction accuracy.
Werandomly selected 1,000 pairs of Wikipediacategory and Wikipedia article from all suchpairs in Wikipedia, and manually investigatedwhether both category and article represented aperson and whether they were linked by an is-arelation (positive:296, negative:704).
Precisionand recall of proposed method are 2.1 pointsand 11.8 points higher than those of Kobaya-shi's method, respectively.
Among all 274,728extracted as WPC-WPI pairs by our method,269,233 was expected be correct.Precision Recall F-measureKobayashi?smethod95.9%(259/270)87.5%(259/296)91.5%Proposedmethod98.0%(294/300)99.3%(294/296)98.7%Table 3: The extraction accuracy of the pairsof Wikipedia person category and person in-stance (WPC-WPI)6 DiscussionsWe constructed a WPC hierarchy using the8,357 categories created by combining ex-tracted categories and training categories.
Theresulting WPC hierarchy has 224 root catego-ries (Figure 4).
Although the majority of theconstructed ontology is interconnected, 194person categories had no parent or child (2.3 %of all person categories).
In rare cases, the cat-egory network has loops (e.g., ?Historians?
and?Scholars of history?
are mutually interlinked).Shibaki et al (2009) presented a method forbuilding a Japanese ontology from Wikipediausing Goi-Taikei, as its upper ontology.
Thismethod can create a single connected taxono-my with a single root category.
We also hopeto create a large-scale, single-root, and inter-connected person ontology by using some up-per ontology.Our method is able to extract WPCs that donot match any Goi-Taikei instance (e.g., Vi-olinists and Animators).
Furthermore, our me-thod is able to detect many ambiguous Wikipe-dia category labels correctly as person category.For example, ??????????
(fashionmodel)?
is ambiguous because the last word????
(model)?
is ambiguous among threesenses: person, artificial object, and abstractrelation.
Kobayashi?s method cannot extract aWPC if the last word of the category label doesnot match any instance in Goi-Taikei.
Theirmethod is error-prone if the last word has mul-7tiple senses in Goi-Taikei because it is based onsimple pattern matching.
Our method can han-dle unknown and ambiguous category labelssince it uses machine learning-based classifierswhose features are extracted from neighboringcategories.Our method can extract is-a person categorypairs that could not be extracted by Ponzetto etal.
(2007) and Sakurai et al (2008).
Their me-thods use head matching in which a categorylink is labeled as an is-a relation only if thehead words of category labels are matched.However, our method can extract is-a relationswithout reference to surface character strings,such as ????????(Journalists)?
and?????????
(Sports writers).?
Amongall 14,408 Wikipedia category pairs extractedas is-a relations in our method, 5,558 (38.6%)did not match their head words.We investigated the learning curve of themachine learning-based classifier for extractingWPCs, in order to decide the appropriateamount of training data for future updates.As we have already manually tagged all39,767 Wikipedia categories, we randomly se-lected 30,000 categories and investigated theperformance of our method when the numberof the training data was changed from 1,000 to30,000.
The evaluation data was the remaining9,767 categories.precisionrecallf-value100.099.098.097.0PrecisionRecallF-measureThe number of training dataPrecision/Recall/F-measure[%]0 10k 20k 30kFigure 6: The effect of training data size toWPC extraction accuracyFigure 6 shows the precision, recall, and F-measure for different training data sizes.
F-measure differed only 0.4 points from 1,000samples (98.5%) to 30,000 samples (98.9%).Figure 6 shows that the proposed method of-fers high accuracy in detecting WPCs with onlya few thousand training examples.Our method uses similar categories forcreating features as well as the target Wikipe-dia category (Section 4.1).
We compared theproposed method to a variant that does not usesimilar categories to confirm the effectivenessof this technique.
Furthermore, our methoduses the Japanese thesaurus, Goi-Taikei, tolook up the semantic category of the words forcreating the features for machine learning.
Wealso compared the proposed method with theone that does not use semantic category (de-rived from Goi-Taikei) but instead uses wordsurface form for creating features (This oneuses similar categories).Figure 7 shows the performance of the clas-sifiers for each type of features.
We can clearlyobserve that using similar categories results inhigher F-measure, regardless of the trainingdata size.
We also observe that when there islittle training data, the method using word sur-face form as features results in drastically low-er F-measures.
In addition, its accuracy wasconsistently lower than the others even if thetraining data size was increased.
Therefore, wecan conclude that using similar category andGoi-Taikei are very important for creating goodfeatures for classification.???????????
?Proposed methodWithout using similar categoryWithout using Goi-TaikeiF-measure[%]The number of training data100.096.098.094.0092.090.010k 20k 30kFigure 7: The effects of using similar catego-ries and Goi-TaikeiIn future, we will attempt to apply our methodto other Wikipedia domains, such as organiza-tions and products.
We will also attempt to useother Japanese thesauri, such as JapaneseWordNet.
Furthermore, we hope to create alarge-scale and single connected ontology.
As afinal note, we plan to open the person ontologyconstructed in this paper to the public on Webin the near future.8ReferencesBizer, C., J. Lehmann, G. Kobilarov, S. Auer, C.Becker, R. Cyganiak, and S. Hellmann.
2009.?DBpedia - A crystallization point for the web ofdata,?
Web Semantics: Science, Services andAgents on the World Wide Web, vol.
7, No.3,pages 154-165.Bond, Francis, Hitoshi Isahara, Kyoko Kanzaki, andKiyotaka Uchimoto.
2008.
Boot-strapping awordnet using multiple existing wordnets.
InProceedings of the 6th International Conferenceon Language Resources and Evaluation (LREC),pages 28-30.Fellbaum, Christiane.
1998.
WordNet: An Electron-ic Lexical Database, Language, Speech, andCommunication Series.
MIT Press.Hearst, Marti A.
1992.
Automatic acquisition ofhyponyms from large text corpora.
In Proceed-ings of the 14th Conference on ComputationalLinguistics (COLING), pages 539-545.Ikehara, Satoru, Masahiro Miyazaki, Satoshi Shi-rai,Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogu-ra, Yoshifumi Ooyama, and Yoshihiko Hayashi,editors.
1997.
Nihongo Goi-Taikei ?
a JapaneseLexicon.
Iwanami Shoten.
(in Japanese).Kobayashi, Akio, Shigeru Masuyama, and SatoshiSekine.
2008.
A method for automatic construc-tion of general ontology merging goitaikei andJapanese Wikipedia.
In Information ProcessingSociety of Japan (IPSJ) SIG Technical Re-port2008-NL-187 (in Japanese), pages 7-14.Ponzetto, S. P. and Michael Strube.
2007.
Derivinga large scale taxonomy from Wikipedia.
In Pro-ceedings of the 22nd Conference on the Ad-vancement of Artificial Intelligence (AAAI), pag-es 1440?1445.Sakurai, Shinya, Takuya Tejima, Masayuki Ishika-wa, Takeshi Morita, Noriaki Izumi, and TakahiraYamaguchi.
2008.
Applying Japanese Wikipediafor building up a general ontology.
In JapaneseSociety of Artificial Intelligence (JSAI) TechnicalReport SIG-SWO-A801-06 (in Japanese), pages1-8.Shibaki, Yumi, Masaaki Nagata and Kazuhide Ya-mamoto.
2009.
Construction of General Ontolo-gy from Wikipedia using a Large-Scale JapaneseThesaurus.
In Information Processing Society ofJapan (IPSJ) SIG Technical Report2009-NL-194-4.
(in Japanese).Suchanek, Fabian M., Gjergji Kasneci, and Ger-hardWeikum.
2007.
Yago: A core of semanticknowledge unifying wordnet and Wikipedia.
InProceedings of the 16th International Conferenceon World Wide Web (WWW), pages 697-706.Sumida, Asuka, Naoki Yoshinaga, and Kentaro To-risawa.
2008.
Boosting precision and recall ofhyponymy relation acquisition from hierarchicallayouts in Wikipedia.
In Proceedings of the SixthLanguage Resources and Evaluation Confe-rence(LREC), pages 28?30.9
