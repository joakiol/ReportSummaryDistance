Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1145?1152,Sydney, July 2006. c?2006 Association for Computational LinguisticsMultilingual Document Clustering: an Heuristic Approach Based onCognate Named EntitiesSoto MontalvoGAVAB GroupURJCsoto.montalvo@urjc.esRaquel Mart?
?nezNLP&IR GroupUNEDraquel@lsi.uned.esArantza CasillasDpt.
EEUPV-EHUarantza.casillas@ehu.esV?
?ctor FresnoGAVAB GroupURJCvictor.fresno@urjc.esAbstractThis paper presents an approach for Mul-tilingual Document Clustering in compa-rable corpora.
The algorithm is of heuris-tic nature and it uses as unique evidencefor clustering the identification of cognatenamed entities between both sides of thecomparable corpora.
One of the main ad-vantages of this approach is that it doesnot depend on bilingual or multilingual re-sources.
However, it depends on the pos-sibility of identifying cognate named enti-ties between the languages used in the cor-pus.
An additional advantage of the ap-proach is that it does not need any infor-mation about the right number of clusters;the algorithm calculates it.
We have testedthis approach with a comparable corpusof news written in English and Spanish.In addition, we have compared the resultswith a system which translates selecteddocument features.
The obtained resultsare encouraging.1 IntroductionMultilingual Document Clustering (MDC) in-volves dividing a set of n documents, written indifferent languages, into a specified number k ofclusters, so the documents that are similar to otherdocuments are in the same cluster.
Meanwhilea multilingual cluster is composed of documentswritten in different languages, a monolingual clus-ter is composed of documents written in one lan-guage.MDC has many applications.
The increasingamount of documents written in different lan-guages that are available electronically, leads todevelop applications to manage that amount ofinformation for filtering, retrieving and groupingmultilingual documents.
MDC tools can makeeasier tasks such as Cross-Lingual InformationRetrieval, the training of parameters in statisticsbased machine translation, or the alignment of par-allel and non parallel corpora, among others.MDC systems have developed different solu-tions to group related documents.
The strate-gies employed can be classified in two maingroups: the ones which use translation technolo-gies, and the ones that transform the document intoa language-independent representation.One of the crucial issues regarding the methodsbased on document or features translation is thecorrectness of the proper translation.
Bilingual re-sources usually suggest more than one sense fora source word and it is not a trivial task to selectthe appropriate one.
Although word-sense disam-biguation methods can be applied, these are notfree of errors.
On the other hand, methods basedon language-independent representation also havelimitations.
For instance, those based on thesaurusdepend on the thesaurus scope.
Numbers or datesidentification can be appropriate for some typesof clustering and documents; however, for othertypes of documents or clustering it could not be sorelevant and even it could be a source of noise.In this work we dealt with MDC and we pro-posed an approach based only on cognate NamedEntities (NE) identification.
We have tested thisapproach with a comparable corpus of news writ-ten in English and Spanish, obtaining encouragingresults.
One of the main advantages of this ap-proach is that it does not depend on multilingualresources such as dictionaries, machine translationsystems, thesaurus or gazetteers.
In addition, noinformation about the right number of clusters has1145to be provided to the algorithm.
It only depends onthe possibility of identifying cognate named enti-ties between the languages involved in the corpus.It could be particularly appropriate for news cor-pus, where named entities play an important role.In order to compare the results of our approachwith other based on features translation, we alsodealt with this one, as baseline approach.
The sys-tem uses EuroWordNet (Vossen, 1998) to trans-late the features.
We tried different features cate-gories and combinations of them in order to deter-mine which ones lead to improve MDC results inthis approach.In the following section we relate previous workin the field.
In Section 3 we present our approachfor MDC.
Section 4 describes the system we com-pare our approach with, as well as the experimentsand the results.
Finally, Section 5 summarizes theconclusions and the future work.2 Related WorkMDC is normally applied with parallel (Silva et.al., 2004) or comparable corpus (Chen and Lin,2000), (Rauber et.
al., 2001), (Lawrence, 2003),(Steinberger et.
al., 2002), (Mathieu et.
al, 2004),(Pouliquen et.
al., 2004).
In the case of the com-parable corpora, the documents usually are newsarticles.Considering the approaches based on transla-tion technology, two different strategies are em-ployed: (1) translate the whole document to an an-chor language, and (2) translate some features ofthe document to an anchor language.With regard to the first approach, some authorsuse machine translation systems, whereas otherstranslate the document word by word consultinga bilingual dictionary.
In (Lawrence, 2003), theauthor presents several experiments for clusteringa Russian-English multilingual corpus; several ofthese experiments are based on using a machinetranslation system.
Columbia?s Newsblaster sys-tem (Kirk et al, 2004) clusters news into events,it categorizes events into broad topic and summa-rizes multiple articles on each event.
In the clus-tering process non-English documents are trans-lated using simple dictionary lookup techniquesfor translating Japanese and Russian documents,and the Systran translation system for the otherlanguages used in the system.When the solution involves translating onlysome features, first it is necessary to select thesefeatures (usually entities, verbs, nouns) and thentranslate them with a bilingual dictionary or/andconsulting a parallel corpus.In (Mathieu et.
al, 2004) before the cluster-ing process, the authors perform a linguistic anal-ysis which extracts lemmas and recognizes namedentities (location, organization, person, time ex-pression, numeric expression, product or event);then, the documents are represented by a set ofterms (keywords or named entity types).
In addi-tion, they use document frequency to select rele-vant features among the extracted terms.
Finally,the solution uses bilingual dictionaries to translatethe selected features.
In (Rauber et.
al., 2001)the authors present a methodology in which docu-ments are parsed to extract features: all the wordswhich appear in n documents except the stop-words.
Then, standard machine translation tech-niques are used to create a monolingual corpus.After the translation process the documents are au-tomatically organized into separate clusters usingan un-supervised neural network.Some approaches first carry out an independentclustering in each language, that is a monolingualclustering, and then they find relations among theobtained clusters generating the multilingual clus-ters.
Others solutions start with a multilingualclustering to look for relations between the doc-uments of all the involved languages.
This is thecase of (Chen and Lin, 2000), where the authorspropose an architecture of multilingual news sum-marizer which includes monolingual and multilin-gual clustering; the multilingual clustering takesinput from the monolingual clusters.
The authorsselect different type of features depending on theclustering: for the monolingual clustering they useonly named entities, for the multilingual clusteringthey extract verbs besides named entities.The strategies that use language-independentrepresentation try to normalize or standardize thedocument contents in a language-neutral way; forexample: (1) by mapping text contents to an inde-pendent knowledge representation, or (2) by rec-ognizing language independent text features insidethe documents.
Both approaches can be employedisolated or combined.The first approach involves the use of exist-ing multilingual linguistic resources, such as the-saurus, to create a text representation consisting ofa set of thesaurus items.
Normally, in a multilin-gual thesaurus, elements in different languages are1146related via language-independent items.
So, twodocuments written in different languages can beconsidered similar if they have similar representa-tion according to the thesaurus.
In some cases, itis necessary to use the thesaurus in combinationwith a machine learning method for mapping cor-rectly documents onto thesaurus.
In (Steinbergeret.
al., 2002) the authors present an approach tocalculate the semantic similarity by representingthe document contents in a language independentway, using the descriptor terms of the multilingualthesaurus Eurovoc.The second approach, recognition of languageindependent text features, involves the recognitionof elements such as: dates, numbers, and namedentities.
In others works, for instance (Silvaet.
al., 2004), the authors present a methodbased on Relevant Expressions (RE).
The RE aremultilingual lexical units of any length automat-ically extracted from the documents using theLiPXtractor extractor, a language independentstatistics-based tool.
The RE are used as basefeatures to obtain a reduced set of new featuresfor the multilingual clustering, but the clustersobtained are monolingual.Others works combine recognition of indepen-dent text features (numbers, dates, names, cog-nates) with mapping text contents to a thesaurus.In (Pouliquen et.
al., 2004) the cross-lingualnews cluster similarity is based on a linear com-bination of three types of input: (a) cognates, (b)automatically detected references of geographicalplace names, and (c) the results of a mappingprocess onto a multilingual classification systemwhich maps documents onto the multilingual the-saurus Eurovoc.
In (Steinberger et.
al., 2004) itis proposed to extract language-independent textfeatures using gazetteers and regular expressionsbesides thesaurus and classification systems.None of the revised works use as unique evi-dence for multilingual clustering the identificationof cognate named entities between both sides ofthe comparable corpora.3 MDC by Cognate NE IdentificationWe propose an approach for MDC based onlyon cognate NE identification.
The NEs cate-gories that we take into account are: PERSON,ORGANIZATION, LOCATION, and MISCEL-LANY.
Other numerical categories such as DATE,TIME or NUMBER are not considered becausewe think they are less relevant regarding the con-tent of the document.
In addition, they can lead togroup documents with few content in common.The process has two main phases: (1) cognateNE identification and (2) clustering.
Both phasesare described in detail in the following sections.3.1 Cognate NE identificationThis phase consists of three steps:1.
Detection and classification of the NEs ineach side of the corpus.2.
Identification of cognates between the NEs ofboth sides of the comparable corpus.3.
To work out a statistic of the number of docu-ments that share cognates of the different NEcategories.Regarding the first step, it is carried out in eachside of the corpus separately.
In our case we useda corpus with morphosyntactical annotations andthe NEs identified and classified with the FreeLingtool (Carreras et al, 2004).In order to identify the cognates between NEs 4steps are carried out:?
Obtaining two list of NEs, one for each lan-guage.?
Identification of entity mentions in each lan-guage.
For instance, ?Ernesto Zedillo?,?Zedillo?, ?Sr.
Zedillo?
will be consideredas the same entity after this step since theyrefer to the same person.
This step is onlyapplied to entities of PERSON category.
Theidentification of NE mentions, as well as cog-nate NE, is based on the use of the Leven-shtein edit-distance function (LD).
This mea-sure is obtained by finding the cheapest wayto transform one string into another.
Trans-formations are the one-step operations of in-sertion, deletion and substitution.
The resultis an integer value that is normalized by thelength of the longest string.
In addition, con-straints regarding the number of words thatthe NEs are made up, as well as the order ofthe words are applied.?
Identification of cognates between the NEsof both sides of the comparable corpus.
Itis also based on the LD.
In addition, also1147constraints regarding the number and the or-der of the words are applied.
First, we triedcognate identification only between NEs ofthe same category (PERSON with PERSON,.
.
. )
or between any category and MISCEL-LANY (PERSON with MISCELLANY, .
.
.
).Next, with the rest of NEs that have not beenconsidered as cognate, a next step is appliedwithout the constraint of being to the samecategory or MISCELLANY.
As result of thisstep a list of corresponding bilingual cog-nates is obtained.?
The same procedure carried out for obtainingbilingual cognates is used to obtain two morelists of cognates, one per language, betweenthe NEs of the same language.Finally, a statistic of the number of documentsthat share cognates of the different NE categoriesis worked out.
This information can be used by thealgorithm (or the user) to select the NE categoryused as constraint in the clustering steps 1(a) and2(b).3.2 ClusteringThe algorithm for clustering multilingual docu-ments based on cognate NEs is of heuristic nature.It consists of 3 main phases: (1) first clusters cre-ation, (2) addition of remaining documents to ex-isting clusters, and (3) final cluster adjustment.1.
First clusters creation.
This phase consists of2 steps.
(a) First, documents in different languagesthat have more cognates in commonthan a threshold are grouped into thesame cluster.
In addition, at least one ofthe cognates has to be of a specific cate-gory (PERSON, LOCATION or ORGA-NIZATION), and the number of men-tions has to be similar; a threshold de-termines the similarity degree.
Afterthis step some documents are assignedto clusters while the others are free (withno cluster assigned).
(b) Next, it is tried to assign each free docu-ment to an existing cluster.
This is pos-sible if there is a document in the clusterthat has more cognates in common withthe free document than a threshold, withno constraints regarding the NE cate-gory.
If it is not possible, a new clus-ter is created.
This step can also have asresult free documents.At this point the number of clusters created isfixed for the next phase.2.
Addition of the rest of the documents to ex-isting clusters.
This phase is carried out in 2steps.
(a) A document is added to a cluster thatcontains a document which has morecognates in common than a threshold.
(b) Until now, the cognate NEs have beencompared between both sides of the cor-pus, that is a bilingual comparison.
Inthis step, the NEs of a language are com-pared with those of the same language.This can be described like a monolin-gual comparison step.
The aim is togroup similar documents of the samelanguage if the bilingual comparisonsteps have not been successful.
As inthe other cases, a document is added toa cluster with at least a document of thesame language which has more cognatesin common than a threshold.
In addi-tion, at least one of the cognates have tobe of a specific category (PERSON, LO-CATION or ORGANIZATION).3.
Final cluster adjustment.
Finally, if there arestill free documents, each one is assigned tothe cluster with more cognates in common,without constraints or threshold.
Nonethe-less, if free documents are left because theydo not have any cognates in common withthose assigned to the existing clusters, newclusters can be created.Most of the thresholds can be customized in or-der to permit and make the experiments easier.
Inaddition, the parameters customization allows theadaptation to different type of corpus or content.For example, in steps 1(a) and 2(b) we enforce atleast on match in a specific NE category.
This pa-rameter can be customized in order to guide thegrouping towards some type of NE.
In Section 4.5the exact values we used are described.Our approach is an heuristic method that fol-lowing an agglomerative approach and in an it-erative way, decides the number of clusters and1148locates each document in a cluster; everything isbased in cognate NEs identification.
The finalnumber of clusters depends on the threshold val-ues.4 EvaluationWe wanted not only determine whether our ap-proach was successful for MDC or not, but we alsowanted to compare its results with other approachbased on feature translation.
That is why we tryMDC by selecting and translating the features ofthe documents.In this Section, first the MCD by feature transla-tion is described; next, the corpus, the experimentsand the results are presented.4.1 MDC by Feature TranslationIn this approach we emphasize the feature selec-tion based on NEs identification and the grammat-ical category of the words.
The selection of fea-tures we applied is based on previous work (Casil-las et.
al, 2004), in which several document rep-resentations are tested in order to study which ofthem lead to better monolingual clustering results.We used this MDC approach as baseline method.The approach we implemented consists of thefollowing steps:1.
Selection of features (NE, noun, verb, adjec-tive, ...) and its context (the whole documentor the first paragraph).
Normally, the journal-ist style includes the heart of the news in thefirst paragraph; taking this into account wehave experimented with the whole documentand only with the first paragraph.2.
Translation of the features by using Eu-roWordNet 1.0.
We translate English intoSpanish.
When more than one sense for asingle word is provided, we disambiguate byselecting one sense if it appears in the Span-ish corpus.
Since we work with a comparablecorpus, we expect that the correct translationof a word appears in it.3.
In order to generate the document represen-tation we use the TF-IDF function to weightthe features.4.
Use of an clustering algorithm.
Particu-larly, we used a partitioning algorithm of theCLUTO (Karypis, 2002) library for cluster-ing.4.2 CorpusA Comparable Corpus is a collection of simi-lar texts in different languages or in different va-rieties of a language.
In this work we com-piled a collection of news written in Spanish andEnglish belonging to the same period of time.The news are categorized and come from thenews agency EFE compiled by HERMES project(http://nlp.uned.es/hermes/index.html).
That col-lection can be considered like a comparable cor-pus.
We have used three subset of that collection.The first subset, call S1, consists on 65 news, 32in Spanish and 33 in English; we used it in orderto train the threshold values.
The second one, S2,is composed of 79 Spanish news and 70 Englishnews, that is 149 news.
The third subset, S3, con-tains 179 news: 93 in Spanish and 86 in English.In order to test the MDC results we carried out amanual clustering with each subset.
Three personsread every document and grouped them consider-ing the content of each one.
They judged inde-pendently and only the identical resultant clusterswere selected.
The human clustering solution iscomposed of 12 clusters for subset S1, 26 clus-ters for subset S2, and 33 clusters for S3.
All theclusters are multilingual in the three subsets.In the experimentation process of our approachthe first subset, S1, was used to train the parame-ters and threshold values; with the second one andthe third one the best parameters values were ap-plied.4.3 Evaluation metricThe quality of the experimentation results are de-termined by means of an external evaluation mea-sure, the F-measure (van Rijsbergen, 1974).
Thismeasure compares the human solution with thesystem one.
The F-measure combines the preci-sion and recall measures:F (i, j) = 2?Recall(i, j)?
Precision(i, j)(Precision(i, j) +Recall(i, j)) ,(1)where Recall(i, j) = nijni , Precision(i, j) =nijnj ,nij is the number of members of cluster human so-lution i in cluster j, nj is the number of membersof cluster j and ni is the number of members ofcluster human solution i.
For all the clusters:F =?inin max{F (i)} (2)The closer to 1 the F-measure value the better.11494.4 Experiments and Results with MDC byFeature TranslationAfter trying with features of different grammaticalcategories and combinations of them, Table 1 andTable 2 only show the best results of the experi-ments.The first column of both tables indicates thefeatures used in clustering: NOM (nouns), VER(verbs), ADJ (adjectives), ALL (all the lemmas),NE (named entities), and 1rst PAR (those of thefirst paragraph of the previous categories).
Thesecond column is the F-measure, and the third oneindicates the number of multilingual clusters ob-tained.
Note that the number of total clusters ofeach subset is provided to the clustering algorithm.As can be seen in the tables, the results depend onthe features selected.4.5 Experiments and Results with MDC byCognate NEThe threshold for the LD in order to determinewhether two NEs are cognate or not is 0.2, exceptfor entities of ORGANIZATION and LOCATIONcategories which is 0.3 when they have more thanone word.Regarding the thresholds of the clustering phase(Section 3.2), after training the thresholds with thecollection S1 of 65 news articles we have con-cluded:?
The first step in the clustering phase, 1(a),performs a good first grouping with thresh-old relatively high; in this case 6 or 7.
Thatis, documents in different languages that havemore cognates in common than 6 or 7 aregrouped into the same cluster.
In addition,at least one of the cognates have to be of anspecific category, and the difference betweenthe number of mentions have to be equal orless than 2.
Of course, these threshold are ap-plied after checking that there are documentsthat meet the requirements.
If they do not,thresholds are reduced.
This first step createsmultilingual clusters with high cohesiveness.?
Steps 1(b) and 2(a) lead to good results withsmall threshold values: 1 or 2.
They are de-signed to give priority to the addition of doc-uments to existing clusters.
In fact, only step1(b) can create new clusters.?
Step 2(b) tries to group similar documents ofthe same language when the bilingual com-parison steps could not be able to deal withthem.
This step leads to good results with athreshold value similar to 1(a) step, and withthe same NE category.On the other hand, regarding the NE categoryenforce on match in steps 1(a) and 2(b), we triedwith the two NE categories of cognates shared bythe most number of documents.
Particularly, withS2 and S3 corpus the NE categories of the cog-nates shared by the most number of documentswas LOCATION followed by PERSON.
We ex-perimented with both categories.Table 3 and Table 4 show the results of the ap-plication of the cognate NE approach to subsetsS2 and S3 respectively.
The first column of bothtables indicates the thresholds for each step of thealgorithm.
Second and third columns show the re-sults by selecting PERSON category as NE cat-egory to be shared by at least a cognate in steps1(a) and 2(b); whereas fourth and fifth columns arecalculated with LOCATION NE category.
The re-sults are quite similar but slightly better with LO-CATION category, that is the cognate NE categoryshared by the most number of documents.
Al-though none of the results got the exact number ofclusters, it is remarkable that the resulting valuesare close to the right ones.
In fact, no informationabout the right number of cluster is provided to thealgorithm.If we compare the performance of the two ap-proaches (Table 3 with Table 1 and Table 4 withTable 2) our approach obtains better results.
Withthe subset S3 the results of the F-measure of bothapproaches are more similar than with the subsetS2, but the F-measure values of our approach arestill slightly better.To sum up, our approach obtains slightly bet-ter results that the one based on feature translationwith the same corpora.
In addition, the number ofmultilingual clusters is closer to the reference so-lution.
We think that it is remarkable that our ap-proach reaches results that can be comparable withthose obtained by means of features translation.We will have to test the algorithm with differentcorpora (with some monolingual clusters, differ-ent languages) in order to confirm its performance.5 Conclusions and Future WorkWe have presented a novel approach for Multilin-gual Document Clustering based only on cognate1150Selected Features F-measure Multilin.
Clus./TotalNOM, VER 0.8533 21/26NOM, ADJ 0.8405 21/26ALL 0.8209 21/26NE 0.8117 19/26NOM, VER, ADJ 0.7984 20/26NOM, VER, ADJ, 1rst PAR 0.7570 21/26NOM, ADJ, 1rst PAR 0.7515 22/26ALL, 1rst PAR 0.7473 19/26NOM, VER, 1rst PAR 0.7371 20/26Table 1: MDC results with the feature translation approach and subset S2Selected Features F-measure Multilin.
Clus.
/TotalNOM, ADJ 0.8291 26/33ALL 0.8126 27/33NOM, VER 0.8028 26/33NE 0.8015 23/33NOM, VER, ADJ 0.7917 25/33NOM, ADJ, 1rst PAR 0.7520 28/33NOM, VER, ADJ, 1rst PAR 0.7484 26/33ALL, 1rst PAR 0.7288 26/33NOM, VER, 1rst PAR 0.7200 24/33Table 2: MDC results with the feature translation approach and subset S3Thresholds 1(a), 2(b) match on PERSON 1(a), 2(b) match on LOCATIONSteps Results Clusters Results Clusters1(a) 1(b) 2(a) 2(b) F-measure Multil./Calc./Total F-measure Multil./Calc./Total6 2 1 5 0.9097 24/24/26 0.9097 24/24/266 2 1 6 0.8961 24/24/26 0.8961 24/24/266 2 1 7 0.8955 24/24/26 0.8955 24/24/266 2 2 5 0.8861 24/24/26 0.8913 24/24/267 2 1 5 0.8859 24/24/26 0.8913 24/24/266 2 2 4 0.8785 24/24/26 0.8899 24/24/266 2 2 6 0.8773 24/24/26 0.8833 24/24/266 2 2 7 0.8773 24/24/26 0.8708 24/24/26Table 3: MDC results with the cognate NE approach and S2 subsetThresholds 1(a), 2(b) match on PERSON 1(a), 2(b) match on LOCATIONSteps Results Clusters Results Clusters1(a) 1(b) 2(a) 2(b) F-measure Multil./Calc./Total F-measure Multil./Calc./Total7 2 1 5 0.8587 30/30/33 0.8621 30/30/336 2 1 5 0.8552 30/30/33 0.8552 30/30/336 2 1 6 0.8482 30/30/33 0.8483 30/30/336 2 1 7 0.8471 30/30/33 0.8470 30/30/336 2 2 5 0.8354 30/30/33 0.8393 30/30/336 2 2 6 0.8353 30/30/33 0.8474 30/30/336 2 2 4 0.8323 30/30/33 0.8474 30/30/336 2 2 7 0.8213 30/30/33 0.8134 30/30/33Table 4: MDC results with the cognate NE approach and S3 subset1151named entities identification.
One of the main ad-vantages of this approach is that it does not dependon multilingual resources such as dictionaries, ma-chine translation systems, thesaurus or gazetteers.The only requirement to fulfill is that the lan-guages involved in the corpus have to permit thepossibility of identifying cognate named entities.Another advantage of the approach is that it doesnot need any information about the right numberof clusters.
In fact, the algorithm calculates it byusing the threshold values of the algorithm.We have tested this approach with a comparablecorpus of news written in English and Spanish, ob-taining encouraging results.
We think that this ap-proach could be particularly appropriate for newsarticles corpus, where named entities play an im-portant role.
Even more, when there is no previousevidence of the right number of clusters.
In addi-tion, we have compared our approach with otherbased on feature translation, resulting that our ap-proach presents a slightly better performance.Future work will include the compilation ofmore corpora, the incorporation of machine learn-ing techniques in order to obtain the thresholdsmore appropriate for different type of corpus.
Inaddition, we will study if changing the order ofthe bilingual and monolingual comparison stepsthe performance varies significantly for differenttype of corpus.AcknowledgementsWe wish to thank the anonymous reviewers fortheir helpful and instructive comments.
This workhas been partially supported by MCyT TIN2005-08943-C02-02.ReferencesBenoit Mathieu, Romanic Besancon and ChristianFluhr.
2004.
?Multilingual document clusters dis-covery?.
RIAO?2004, p. 1-10.Arantza Casillas, M. Teresa Gonza?lez de Lena andRaquel Mart??nez.
2004.
?Sampling and FeatureSelection in a Genetic Algorithm for DocumentClustering?.
Computational Linguistics and Intel-ligent Text Processing, CICLing?04.
Lecture Notesin Computer Science, Springer-Verlag, p. 601-612.Hsin-Hsi Chen and Chuan-Jie Lin.
2000.
?A Multilin-gual News Summarizer?.
Proceedings of 18th Inter-national Conference on Computational Linguistics,p.
159-165.Xavier Carreras, I. Chao, Lluis Padro?
and M.Padro?
2004 ?An Open-Source Suite of Lan-guage Analyzers?.
Proceedings of the 4th In-ternational Conference on Language Resourcesand Evaluation (LREC?04).
Lisbon, Portugal.http://garraf.epsevg.upc.es/freeling/.Karypis G. 2002. ?
CLUTO: A Clustering Toolkit?.Technical Report: 02-017.
University of Minnesota,Department of Computer Science, Minneapolis, MN55455.David Kirk Evans, Judith L. Klavans and KathleenMcKeown.
2004.
?Columbian Newsblaster: Multi-lingual News Summarization on the Web?.
Proceed-ings of the Human Language Technology Confer-ence and the North American Chapter of the Asso-ciation for Computational Linguistics Annual Meet-ing, HLT-NAACL?2004.Lawrence J. Leftin.
2003.
?Newsblaster Russian-English Clustering Performance Analysis?.Columbia computer science Technical Reports.Bruno Pouliquen, Ralf Steinberger, Camelia Ignat,Emilia Ksper and Irina Temikova.
2004.
?Multi-lingual and cross-lingual news topic tracking?.
Pro-ceedings of the 20th International Conference oncomputational Linguistics, p. 23-27.Andreas Rauber, Michael Dittenbach and Dieter Merkl.2001.
?Towards Automatic Content-Based Organi-zation of Multilingual Digital Libraries: An English,French, and German View of the Russian Infor-mation Agency Novosti News?.
Third All-RussianConference Digital Libraries: Advanced Methodsand Technologies, Digital Collections Petrozavodsk,RCDI?2001.van Rijsbergen, C.J.
1974.
?Foundations of evalua-tion?.
Journal of Documentation, 30 (1974), p. 365-373.Joaquin Silva, J. Mexia, Carlos Coelho and GabrielLopes.
2004.
?A Statistical Approach for Multi-lingual Document Clustering and Topic Extractionform Clusters?.
Pliska Studia Mathematica Bulgar-ica, v.16,p.
207-228.Ralf Steinberger, Bruno Pouliquen, and Johan Scheer.2002.
?Cross-Lingual Document Similarity Cal-culation Using the Multilingual Thesaurus EU-ROVOC?.
Computational Linguistics and Intelli-gent Text Processing, CICling?02.
Lecture Notes inComputer Science, Springer-Verlag, p. 415-424.Ralf Steinberger, Bruno Pouliquen, and Camelia Ignat.2004.
?Exploiting multilingual nomenclatures andlanguage-independent text features as an interlinguafor cross-lingual text analysis applications?.
Slove-nian Language Technology Conference.
InformationSociety, SLTC 2004.Vossen, P. 1998.
?Introduction to EuroWordNet?.Computers and the Humanities Special Issue on Eu-roWordNet.1152
