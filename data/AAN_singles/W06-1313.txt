Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 88?95,Sydney, July 2006. c?2006 Association for Computational LinguisticsAn Information State-Based Dialogue Manager for Call for Fire DialoguesAntonio Roque and David TraumUSC Institute for Creative Technologies13274 Fiji Way, Marina Del Rey, CA 90292roque@ict.usc.edu, traum@ict.usc.eduAbstractWe present a dialogue manager for ?Callfor Fire?
training dialogues.
We describethe training environment, the domain, thefeatures of its novel information state-based dialogue manager, the system it is apart of, and preliminary evaluation results.1 OverviewDialogue systems are built for many different pur-poses, including information gathering (e.g., (Austet al, 1995)), performing simple transactions (e.g,(Walker and Hirschman, 2000)), collaborative in-teraction (e.g., (Allen et al, 1996)), tutoring (e.g.,(Rose et al, 2003)), and training (e.g.
(Traumand Rickel, 2002)).
Aspects of the purpose, aswell as features of the domain itself (e.g., traintimetables, air flight bookings, schedule mainte-nance, physics, and platoon-level military opera-tions) will have a profound effect on the nature ofthe dialogue which a system will need to engagein.
Issues such as initiative, error correction, flex-ibility in phrasing and dialogue structure may de-pend crucially on these factors.The information state approach to dialoguemanagers (Larsson and Traum, 2000) has been anattempt to cast some of these differences withinthe same framework.
In this approach, a theoryof dialogue is constructed by providing informa-tion structure elements, a set of dialogue movesthat can be recognized and produced and are usedto modify the nature of these elements, a set ofupdate rules that govern the dynamics of how theinformation is changed as dialogue moves are per-formed, and an update strategy.
Many differ-ent dialogue systems have been built according tothis general approach (e.g., (Cooper and Larsson,1999; Matheson et al, 2000; Lemon et al, 2001;Johnston et al, 2002; Traum and Rickel, 2002;Purver, 2002)).In this paper, we present an information-statebased dialogue manager for a new domain: train-ing call for fire dialogues.
Like other dialogue sys-tems used as role-players in training applications,the structure of the dialogue is not completely freefor a dialogue designer to specify based on issuesof dialogue efficiency.
The dialogue system mustconform as much as possible to the type of dia-logue that a trainee would actually encounter in thetypes of interaction he or she is being trained for.In particular, for military radio dialogues, muchof the protocol for interaction is specified by con-vention (e.g., (Army, 2001)).
Still, there is a fairamount of flexibility in how other aspects of thedialogue progress.This dialogue manager is part of a system wecall Radiobot-CFF.
Radiobots are a general classof dialogue systems meant to speak over the ra-dio in military simulations.
Our most extendedeffort to date is the Radiobot-CFF system, whichengages in ?call for fire?
dialogues to train ar-tillery observers within a virtual reality trainingsimulation.
Our dialogue system can operate ac-cording to three different use cases, depending onhow much control a human operator/trainer wouldlike to exercise over the dialogue.
There is a fullyautomatic mode in which the Radiobot-CFF sys-tem engages unassisted in dialogue with the user, asemi-automatic mode in which the Radiobot-CFFsystem fills in forms (which can be edited) and theoperator can approve or change communicationwith a simulator or trainee, and a passive modein which the operator is engaging in the dialogueand the Radiobot-CFF system is just observing.In section 2, we describe the training applica-88tion that our dialogue system has been embeddedin as well as the system itself.
In section 3, we de-scribe some aspects of ?call for fire dialogues?, es-pecially the differences in initiative and purposesof different phases in the dialogue.
In section 4,we describe the information-state based dialoguemodel we have developed for this domain.
This in-cludes dialogue moves, information components,and update rules.
We describe some error handlingcapabilities in section 5, and evaluation results insection 6.2 TestbedOur current testbed, Radiobot-CFF, has beendeveloped in a military training environment,JFETS-UTM, at the U.S. Army base in in Ft. Sill,Oklahoma.
JFETS-UTM trains soldiers to makeCalls for Fire (CFFs), in which a Forward Ob-server (FO) team locates an enemy target and re-quests an artillery fire mission by radio from a FireDirection Center (FDC).
The training room resem-bles a battle-scarred apartment in a Middle East-ern country.
A window shows a virtual city dis-played by a rear-projected computer screen, andthe soldiers use binoculars with computer displaysat their ends to search for targets.Ordinarily, two trainers control a UTM session.One communicates with the FO via a simulatedradio, and the other decides what the artillery fireshould be and inputs it to a GUI for the simu-lator.
It is our goal to replace those two train-ers with one trainer focusing on assessment whileRadiobot-CFF handles the radio communicationsand interfaces with the virtual world.Radiobot-CFF is composed of several pipelinedcomponents.
A Speech Recognition componentis implemented using the SONIC speech recogni-tion system (Pellom, 2001) with custom languageand acoustic models.
An Interpreter componenttags the ASR output with its its dialogue moveand parameter labels using two separate Condi-tional Random Field (Sha and Pereira, 2003; Mc-Callum, 2002) taggers trained on hand-annotatedutterances.
A Dialogue Manager processes thetagged output, sending a reply to the FO (via atemplate-based Generator) and, when necessary, amessage to the artillery simulator FireSim XXI1 tomake decisions on what type of fire to send.
Thereply to FO and messages to simulator are medi-ated by GUIs where the trainer can intervene if1http://sill-www.army.mil/blab/sims/FireSimXXI.htmneed be.3 Call for Fire DialoguesCall for Fire procedures are specified in an Armyfield manual (Army, 2001) with variations basedon a unit?s standard operating procedure.
Mes-sages are brief and followed by confirmations,where any misunderstandings are immediatelycorrected.
A typical CFF is shown in Figure 1.1 FO steel one niner this is gator niner one adjustfire polar over2 FDC gator nine one this is steel one nine adjust firepolar out3 FO direction five niner four zero distance foureight zero over4 FDC direction five nine four zero distance four eightzero out5 FO one b m p in the open i c m in effect over6 FDC one b m p in the open i c m in effect out7 FDC message to observer kilo alpha high explo-sive four rounds adjust fire target number al-pha bravo one zero zero zero over8 FO m t o kilo alpha four rounds target number al-pha bravo one out9 FDC shot over10 FO shot out11 FDC splash over12 FO splash out13 FO right five zero fire for effect out over14 FDC right five zero fire for effect out15 FDC shot over16 FO shot out17 FDC rounds complete over18 FO rounds complete out19 FO end of mission one b m p suppressed zero ca-sualties over20 FDC end of mission one b m p suppressed zero ca-sualties outFigure 1: Example Dialogue with Radiobot-CFFCFFs can generally be divided into threephases.
In the first phase (utterances 1-6 in Fig-ure 1) the FOs identify themselves and importantinformation about the CFF, including their coor-dinates, the kind of fire they are requesting, thelocation of the target, and the kind of target.
Inutterance 1 in Figure 1 the FO performs an identi-fication, giving his own call sign and that of theFDC he is calling, and also specifies a methodof fire (?adjust fire?)
and a method of targeting(?polar?.)
Note that when speakers expect a reply,they end their utterance with ?over?
as in utter-ance 1, otherwise with ?out?
as in the confirmationin utterance 2.
In utterance 3 the FO gives targetcoordinates, and in utterance 5 the FO identifiesthe target as a BMP (a type of light tank) and re-quests ICM rounds (?improved conventional mu-nitions?.)
These turns typically follow one another89in quick sequence.In the second phase of a CFF, (utterances 7-12in Figure 1), after the FDC decides what kind offire they will send, they inform the FO in a mes-sage to observer (MTO) as in utterance 7.
Thisincludes the units that will fire (?kilo alpha?
), thekind of ammunition (?high explosive?
), the num-ber of rounds and method of fire (?4 rounds ad-just fire?
), and the target number (?alpha bravo onezero zero zero?).
CFFs are requests rather than or-ders, and they may be denied in full or in part.
Inthis example, the FO?s request for ICM rounds wasdenied in favor of High Explosive rounds.
Nextthe FDC informs the FO when the fire mission hasbeen shot, as in utterance 9, and when the fire isabout to land, as in utterance 11.
Each of these areconfirmed by the FO.In the third phase, (utterances 13-20 in Fig-ure 1) the FO regains dialogue initiative.
Depend-ing on the observed results, the FO may requestthat the fire be repeated with an adjust in locationor method of fire.
In utterance 13 the FO requeststhat the shot be re-sent to a location 50 meters tothe right of the previous shot as a ?fire for effect?all-out bombardment rather than an ?adjust fire?targeting fire.
This is followed by the abbreviatedFDC-initiated phase of utterances 15-18.
In utter-ance 19 the FO ends the mission, describing theresults and number of casualties.Besides the behavior shown, at any turn eitherparticipant may request or initiate an intelligencereport or request the status of a mission.
Further-more, after receiving an MTO the FO may imme-diately begin another fire mission and thus havemultiple missions active; subsequent adjusts aredisambiguated with the target numbers assignedduring the MTOs.4 Dialogue ManagerWe have constructed an Information State-baseddialogue manager (Larsson and Traum, 2000) onthis domain consisting of a set of dialogue moves,a set of informational components with appropri-ate formal representations, and a set of updaterules with an update strategy.
We describe eachof these in turn.4.1 Dialogue MovesWe defined a set of dialogue moves to representthe incoming FO utterances based on a study oftranscripts of human-controlled JFETS-UTM ses-sions, Army manuals, and the needs of the simu-lator.
As shown in Figure 2 these are divided intothree groups: those that provide information aboutthe FO or the fire mission, those that confirm in-formation that the FDC has transmitted, and thosethat make requests.Mission Information:Observer CoordinatesSituation ReportIdentificationWarning OrderMethod of ControlMethod of EngagementTarget LocationTarget DescriptionEnd of MissionConfirming Information:Message to ObserverShotSplashRounds CompleteIntel ReportOther Requests:Radio CheckSay AgainStatusStandbyCommandFigure 2: FO Dialogue MovesThe dialogue moves that provide informationinclude those in which the FOs transmit their Ob-server Coordinates (grid location on a map), ageneric Situation Report, or one of the variouscomponents of a fire mission request ranging fromcall sign Identification to final End of Mission.The dialogue moves that confirm information in-clude those that confirm the MTO and other FDC-initiated utterances, or a general report on scenarioIntel.
The final group includes requests to checkradio functionality, to repeat the previous utter-ance, for status of a shot, to stand by for transmis-sion of information, and finally a set of commandssuch as ?check fire?
requesting cancellation of asubmitted fire mission.Each of these dialogue moves contains informa-tion important to the dialogue manager.
This in-formation is captured by the parameters of the di-alogue move, which are enumerated in Figure 3.Each parameter is listed with the dialogue moveit usually occurs with, but this assignment is notstrict.
For example, ?number of enemies?
param-eters occur in Target Description as well as End ofMission dialogue moves.90Identification-related:fdc_idfo_idWarning Order-related:method_of_firemethod_of_controlmethod_of_engagementmethod_of_locationTarget Location-related:grid_locationdirectiondistanceattitudeleft_rightleft_right_adjustadd_dropadd_drop_adjustknown_pointEnd Of Mission-related:target_typetarget_descriptionnumber_of_enemiesdispositionOther:commanddetail_of_requesttarget_numberFigure 3: Dialogue Move ParametersFigure 4 shows how the dialogue moves and pa-rameters act to identify the components of an FOutterance.
The example is based on utterance 1 inFigure 1; the Identification move has two param-eters representing the call signs of the FDC andthe FO, and the Warning Order has two parame-ters representing the method of fire and method oflocation.
Parameters need to be identified to con-firm back to the FO, and in some cases to be sentto the simulator and for use in updating the infor-mation state.
In the example in Figure 4, the factthat the requested method of fire is an ?adjust fire?will be sent to the simulator, and the fact that amethod of fire has been given will be updated inthe information state.Identification: steel one nine this is gator niner onefdc id: steel one ninefo id: gator niner oneWarning Order: adjust fire polarmethod of fire: adjust firemethod of location: polarFigure 4: Example Dialogue Moves and Parame-ters4.2 Informational ComponentsThe Radiobot-CFF dialogue manager?s informa-tion state consists of five classes of informationalcomponents, defined by their role in the dia-logue and their level of accessibility to the user.These are the Fire Mission Decision components,the Fire Mission Value components, the Post-FireValue components, the Disambiguation compo-nents, and the Update Rule Processing compo-nents.By dividing the components into multipleclasses we separate those that are simulator-specific from more general aspects of the domain.Decisions to fire are based on general con-straints of the domain, whereas the exact com-ponents to include in a message to simulator willbe simulator-specific.
Also, the components havebeen designed such that there is almost no over-lap in the update rules that modify them (see sec-tion 4.3).
This reduces the complexity involvedin editing or adding rules; although there are over100 rules in the information state, there are fewunanticipated side-effects when rules are altered.The first class of components are the Fire Mis-sion Decision components, which are used to de-termine whether enough information has been col-lected to send fire.
These components are booleanflags, updated by rules based on incoming dia-logue moves and parameters.
Figure 5 shows thevalues of these components after utterance 3 inFigure 1 has been processed.
The FO has given awarning order, and a target location (which can ei-ther be given through a grid location, or through acombination of direction and distance values, andobserver coordinates), so the appropriate compo-nents are ?true?.
After the FO gives a target de-scription, that component will be true as well, andan update rule will recognize that enough informa-tion has been gathered to send a fire mission.has warning order?
truehas target location?
truehas grid location?
falsehas polar direction?
truehas polar distance?
truehas polar obco?
truehas target descr?
falseFigure 5: Fire Mission Decision ComponentsThe second class of information state compo-nents is the set of Fire Mission Value components,which track the value of various information el-91ements necessary for requesting a fire mission.These are specific to the FireSim XXI simulator.Figure 6 shows the values after utterance 3 in Fig-ure 1.
Components such as ?direction value?
takenumber values, and components such as ?methodof fire?
take values from a finite set of possibilities.Several of these components, such as ?attitude?have defaults that are rarely changed.
Once thedialogue manager or human trainer decides that ithas enough information to request fire, these com-ponents are translated into a simulator commandand sent to the simulator.method of control: adjust firemethod of fire: adjust firemethod of engagement: none giventarget type: -grid value: -direction value: 5940distance value: 480length: 0width: 100attitude: 0observer coordinate value: 45603595Figure 6: Fire Mission Value ComponentsFire Mission Value components are also directlymodifiable by the trainer.
Figure 7 shows the GUIwhich the trainer can use to take control of thesession, edit any of the Fire Mission Value com-ponents, and relinquish control of the session backto Radiobot-CFF.
This allows the trainer to correctany mistakes that the Radiobot may have made ortest the trainee?s adaptability by sending the fireto an unexpected location.
The example shown inFigure 7 is after utterance 5 of Figure 1; the sys-tem is running in semi-automated mode and thedialogue manager has decided that it has enoughinformation to send a fire.
The trainer may sendthe message or edit it and then send it.
A secondGUI, not shown, allows the trainer to take con-trol of the outgoing speech of the Radiobot, and,in semi-automated mode, either confirm the send-ing of a suggested output utterance, alter it beforesending, or author new text for the radiobot to say.The third class of components is the Post-FireValue components, which are also exposed to thetrainer for modification.
The example shown inFigure 8 is from after utterance 13 in Figure 1; theFO has requested an ?adjust fire?
with an indica-tor of ?fire for effect?
and a right adjustment of 50.At this point in the dialogue the FO could have in-stead chosen to end the mission.
If the initial firehad been a ?fire for effect?
it could have been re-Figure 7: GUIpeated, rather than following up an initial ?adjustfire.?
The adjust fire stage does not have any de-cision components because typically the adjust in-formation is given in one move.adjust fire: trueshift indicator: fire for effectrepeat FFE: falseleft-right adjustment: 50add-drop adjustment: 0vertical adjustment: 0end of mission: falsedisposition: -number of casualties: -Figure 8: Post-Fire Value ComponentsThe fourth class, Disambiguation components,are used by many rules to disambiguate local in-formation based on global dialogue features.
Theexample shown in Figure 9 is from the dialoguein Figure 1, after utterance 1.
The ?mission ispolar?
component helps determine the method oftarget location if speech recognition erroneouslydetects both polar and grid coordinates.
Targetnumbers allow the FOs to handle multiple mis-sions at the same time (e.g., starting a new call forfire, before the previous mission has been com-pleted).
The ?missions active?
component trackshow many missions are currently being discussed.The ?phase?
refers to the state of a three-state FSA92that tracks which of the three subdialogue phases(described in section 3) the dialogue is in for themost recently-discussed mission.An example of the use of the Disambiguationcomponents is to determine whether the phrase?fire for effect?
refers to an adjustment of a pre-vious mission or the initiation of a new mission.In utterance 13 in Figure 1, ?fire for effect?
refersto an adjustment of a CFF that began with an ?ad-just fire?
in utterance 1.
However, the FO couldhave started that CFF by calling for a ?fire for ef-fect?.
Furthermore the FO could have started asecond CFF in utterance 13 rather than doing anadjust, and might have specified ?fire for effect?.By using a rule to check the phase of the missionthe move can be disambiguated to understand thatit is referring to an adjustment, rather than the ini-tiation of a new fire mission.mission is polar?
: truetarget number: 0missions active: 0last method of fire: adjustphase: Info-GatheringFigure 9: Disambiguation ComponentsThe last class of components, shown in Fig-ure 10, is closely tied to the update rule processing,and is therefore described in the following section.current reply: gator nine one this issteel one nineprevious reply: -understood?
truesend EOM?
falsesend repeat?
falsesend repeat adjust?
falsesend repeat ffe?
falseFigure 10: Update Rule Processing Components4.3 Update RulesUpdate rules update the informational compo-nents, build a message to send to the FO, builda message to send to the simulator, and decidewhether a message should actually be sent to theFO or simulator.As an example of rule application, consider theprocessing of utterance 1 in Figure 1.
Figure 4shows the moves and parameters for this utterance.When the dialogue manager processes this utter-ance, a set of rules associated with the Identifi-cation move are applied, which starts building aresponse to the FO.
This response is built in the?current reply?
Update Rule Processing compo-nent.
Figure 10 shows a reply in the process ofbeing built: a rule has recognized that an Identifi-cation move is being given, and has filled in slotsin a template with the necessary information andadded it to the ?current reply?
component.Next, the update rules will recognize that aWarning Order is being given, and will identifythat it is an ?adjust fire?
method of fire, and up-date the ?has warning order?
decision component,the ?method of control?
and ?method of fire?
valuecomponents, and the ?last method of fire?
disam-biguation component.
As part of this, the appro-priate fields of the GUIs will be filled in to allowthe trainer to override the FO?s request if need be.Another rule will then fill in the slots of a templateto add ?adjust fire polar?
to the current reply, andlater another rule will add ?out?, thus finishing thereply to the FO.
After the reply is finished, it willplace it in the ?previous reply?
component, for ref-erence if the FO requests a repeat of the previousutterance.Certain rules are specified as achieving compre-hension ?
that is, if they are applied, the ?under-stood?
variable for that turn is set.
If no reply hasbeen built but the move has been understood, thenno reply needs to be sent.
This happens, for ex-ample, for each of utterances 8, 10, and 12 in Fig-ure 1: because they are confirmations of utterancesthat the FDC has initiated, they do not need to bereplied to.
Similarly, no reply needs to be sent ifno reply has been built and the incoming messageis empty or only contains one or two words in-dicative of an open mic and background noise.
Fi-nally, if no reply has been built and the move hasnot been understood, then the FO is prompted torepeat the message.As described above, the Fire Mission Decisioncomponents are used to determine whether to senda fire mission.
For other communications with thesimulator, a simpler approach is possible.
The de-cisions to send an end of mission, a repeat fire, or arepeat fire with the ?adjust?
or ?fire for effect?
spec-ification can be made with update rules acting ona single boolean, and so these are also part of theUpdate Rule Processing Components as shown inFigure 10.Finally, the application of rules follows a spe-cific strategy.
A given utterance may contain oneor more dialogue moves, each with a set of rulesspecific to it.
The dialogue manager applies the93appropriate rules to each dialogue move in theutterance before applying the rules that send theFO messages or simulator commands, as shown inFigure 11.
Rules for producing replies and simula-tor commands are delayed until the end of process-ing an utterance to allow for utterances that maycontain self-corrections or relevant details later inthe turn.for each dialogue move in utteranceapply rules for that dialogue moveend forapply rules to send reply to FOapply rules to send simulator commandsFigure 11: Update Strategy for Rules5 Error HandlingRadiobot-CFF is able to handle various kind ofproblematic input in a number of ways.
It can han-dle partially correct information, as in Figure 12.Speech recognition errors caused the ?three casu-alties?
information to be lost, but the update ruleswere able to handle the essential part of the FOcontribution: that the mission was ended, and thatthe target was neutralized.
The domain is forgiv-ing in this particular example, although a stricttrainer might want to intervene by the GUI andinsist that the FO re-submit the end of mission re-port.FO Said: end of mission targetneutralized estimate threecasualties overASR Output: in end of mission targetneutralized as the make threecatch a these overRadiobot: end of mission targetneutralized outFigure 12: Error CorrectionIn other cases, such as when giving number co-ordinates, all information must be fully grounded.An example of this is in Figure 13, where the num-ber ?five?
is lost by the speech recognition.
Inthis case, the domain-appropriate response is toprompt for a repetition.FO Said: right five zero overASR Output: right by zero overRadiobot: say again overFigure 13: Error Correction - Prompt6 EvaluationWe conducted an evaluation of the Radiobot-CFFsystem in fully-automated, semi-automated, andhuman-controlled conditions.
The system per-formed well in a number of measures; for exam-ple, Table 1 shows the scores for median time-to-fire and task-completion rates.
Additional mea-sures and further details are available in (Robinsonet al, 2006).Table 1: Example Evaluation MeasuresMeasure Human Semi FullyTime To Fire 106.2 s 139.4 s 104.3 sTask Compl.
100% 97.5% 85.9%Of particular relevance here, we performed anevaluation of the dialogue manager, using the eval-uation corpus of 17 missions run on 8 sessions, atotal of 408 FO utterances.
We took transcribedrecordings of the FO utterances, ran them throughthe Interpreter, and corrected them.
For each ses-sion, we ran corrected Interpreter output throughthe Dialogue Manager to print out the values of theinformational components at the end of every turn.We then corrected those, and compared the cor-rections to the uncorrected values to receive preci-sion, accuracy, and f-scores of 0.99 each.27 SummaryWe presented a dialogue manager which can en-gage in Call for Fire training dialogues, and de-scribed the environment and system in which itworks.
It has an information state-based designwith several components accessible to a humanoperator, and may be controlled either fully, inpart, or not at all by that human operator.8 AcknowledgementsThis work has been sponsored by the U.S. ArmyResearch, Development, and Engineering Com-mand (RDECOM).
Statements and opinions ex-pressed do not necessarily reflect the position orthe policy of the United States Government, andno official endorsement should be inferred.2In this preliminary evaluation, the Interpreter and infor-mational component corrections were all done by a singlecoder; also, the coder was correcting the informational com-ponent output rather than entering informational componentinformation from blank, thus any errors of omission on thepart of the coder would work in favor of the system perfor-mance.94We would like to thank Charles Hernandez andJanet Sutton of the Army Research Laboratory,and Bill Millspaugh and the Depth & Simultane-ous Attack Battle Lab in Fort Sill, Oklahoma, fortheir efforts on this project.
We would also like tothank the other members of the Radiobots project.ReferencesJames F. Allen, Bradford W. Miller, Eric K. Ringger,and Teresa Sikorski.
1996.
A robust system for nat-ural spoken dialogue.
In Proceedings of the 1996Annual Meeting of the Association for Computa-tional Linguistics (ACL-96), pages 62?70.Department of the Army.
2001.
Tactics, techniquesand procedures for observed fire and fire support atbattalion task force and below.
Technical Report FM3-09.30 (6-30), Department of the Army.H.
Aust, M. Oerder, F. Siede, and V. Steinbiss.
1995.
Aspoken language enquiry system for automatic traintimetable information.
Philips Journal of Research,49(4):399?418.Robin Cooper and Staffan Larsson.
1999.
Dialoguemoves and information states.
In H.C. Bunt andE.
C. G. Thijsse, editors, Proceedings of the ThirdInternational Workshop on Computational Seman-tics.Michael Johnston, Srinivas Bangalore, GunaranjanVasireddy, Amanda Stent, Patrick Ehlen, Mari-lyn Walker, Steve Whittaker, and Preetam Maloor.2002.
Match: An architecture for multimodal dia-logue systems.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 376?383.Staffan Larsson and David Traum.
2000.
Informationstate and dialogue management in the TRINDI dia-logue move engine toolkit.
Natural Language En-gineering, 6:323?340, September.
Special Issue onSpoken Language Dialogue System Engineering.Oliver Lemon, Anne Bracy, Alexander Gruenstein, andStanley Peters.
2001.
The witas mult-modal dia-logue system i.
In Proc.
European Conf.
on SpeechCommunication and Tech- nology, pages 559?1562.Colin Matheson, Massimo Poesio, and David Traum.2000.
Modelling grounding and discourse obliga-tions using update rules.
In Proceedings of the FirstConference of the North American Chapter of theAssociation for Computational Linguistics.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://mallet.cs.umass.edu.Bryan Pellom.
2001.
Sonic: The university of col-orado continuous speech recognizer.
Technical Re-port TR-CSLR-2001-01, University of Colorado.Matthew Purver.
2002.
Processing unknown wordsin a dialogue system.
In Proceedings of the 3rdACL SIGdial Workshop on Discourse and Dialogue,pages 174?183.
Association for Computational Lin-guistics, July.Susan Robinson, Antonio Roque, Ashish Vaswani, andDavid Traum.
2006.
Evaluation of a spoken dia-logue system for military call for fire training.
ToAppear.C.
Rose, D. Litman, D. Bhembe, K. Forbes, S. Silli-man, R. Srivastava, and K. van Lehn.
2003.
A com-parison of tutor and student behavior in speech ver-sus text based tutoring.F.
Sha and F. Pereira.
2003.
Shallow parsing with con-ditional random fields.David R. Traum and Jeff Rickel.
2002.
Embodiedagents for multi-party dialogue in immersive virtualworlds.
In Proceedings of the first InternationalJoint conference on Autonomous Agents and Mul-tiagent systems, pages 766?773.M.
Walker and L. Hirschman.
2000.
Evaluation fordarpa communicator spoken dialogue systems.95
