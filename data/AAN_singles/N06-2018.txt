Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 69?72,New York, June 2006. c?2006 Association for Computational LinguisticsMMR-based Active Machine Learningfor Bio Named Entity RecognitionSeokhwan Kim1 Yu Song2 Kyungduk Kim1 Jeong-Won Cha3 Gary Geunbae Lee11 Dept.
of Computer Science and Engineering, POSTECH, Pohang, Korea2 AIA Information Technology Co., Ltd. Beijing, China3 Dept.
of Computer Science, Changwon National University, Changwon, Koreamegaup@postech.ac.kr, Song-Y.Song@AIG.com, getta@postech.ac.krjcha@changwon.ac.kr, gblee@postech.ac.krAbstractThis paper presents a new active learningparadigm which considers not only theuncertainty of the classifier but also thediversity of the corpus.
The two measuresfor uncertainty and diversity were com-bined using the MMR (Maximal MarginalRelevance) method to give the samplingscores in our active learning strategy.
Weincorporated MMR-based active machine-learning idea into the biomedical named-entity recognition system.
Our experimen-tal results indicated that our strategies foractive-learning based sample selectioncould significantly reduce the human ef-fort.1 IntroductionNamed-entity recognition is one of the most ele-mentary and core problems in biomedical text min-ing.
To achieve good recognition performance, weuse a supervised machine-learning based approachwhich is a standard in the named-entity recognitiontask.
The obstacle of supervised machine-learningmethods is the lack of the annotated training datawhich is essential for achieving good performance.Building a training corpus manually is time con-suming, labor intensive, and expensive.
Creatingtraining corpora for the biomedical domain is par-ticularly expensive as it requires domain specificexpert knowledge.One way to solve this problem is through activelearning method to select the most informativesamples for training.
Active selection of the train-ing examples can significantly reduce the neces-sary number of labeled training examples withoutdegrading the performance.Existing work for active learning explores twoapproaches: certainty or uncertainty-based methods(Lewis and Gale 1994; Scheffer and Wrobel 2001;Thompson et al 1999) and committee-basedmethods (Cohn et al 1994; Dagan and Engelson1995; Freund et al 1997; Liere and Tadepalli1997).
Uncertainty-based systems begin with aninitial classifier and the systems assign some un-certainty scores to the un-annotated examples.
Thek examples with the highest scores will be anno-tated by human experts and the classifier will beretrained.
In the committee-based systems, diversecommittees of classifiers were generated.
Eachcommittee member will examine the un-annotatedexamples.
The degree of disagreement among thecommittee members will be evaluated and the ex-amples with the highest disagreement will be se-lected for manual annotation.Our efforts are different from the previous ac-tive learning approaches and are devoted to twoaspects: we propose an entropy-based measure toquantify the uncertainty that the current classifierholds.
The most uncertain samples are selected forhuman annotation.
However, we also assume thatthe selected training samples should give the dif-ferent aspects of learning features to the classifica-tion system.
So, we try to catch the mostrepresentative sentences in each sampling.
Thedivergence measures of the two sentences are forthe novelty of the features and their representativelevels, and are described by the minimum similar-ity among the examples.
The two measures for un-certainty and diversity will be combined using theMMR (Maximal Marginal Relevance) method(Carbonell and Goldstein 1998) to give the sam-pling scores in our active learning strategy.69We incorporate MMR-based active machine-learning idea into the POSBIOTM/NER (Song etal.
2005) system which is a trainable biomedicalnamed-entity recognition system using the Condi-tional Random Fields (Lafferty et al 2001) ma-chine learning technique to automatically identifydifferent sets of biological entities in the text.2 MMR-based Active Learning for Bio-medical Named-entity Recognition2.1 Active LearningWe integrate active learning methods into thePOSBIOTM/NER (Song et al 2005) system by thefollowing procedure: Given an active learningscoring strategy S and a threshold value th, at eachiteration t, the learner uses training corpus TMt   totrain the NER module Mt.
Each time a user wantsto annotate a set of un-labeled sentences U, thesystem first tags the sentences using the currentNER module Mt.
At the same time, each taggedsentence is assigned with a score according to ourscoring strategy S. Sentences will be marked if itsscore is larger than the threshold value th.
The tagresult is presented to the user, and those markedones are rectified by the user and added to thetraining corpus.
Once the training data accumulatesto a certain amount, the NER module Mt will beretrained.2.2 Uncertainty-based Sample SelectionWe evaluate the uncertainty degree that the currentNER module holds for a given sentence in terms ofthe entropy of the sentence.
Given an input se-quence o, the state sequence set S is a finite set.And  is the probability distribu-tion over S. By using the equation for CRF(Lafferty et al 2001) module, we can calculate theprobability of any possible state sequence s givenan input sequence o.
Then the entropy ofis defined to be:Sso|s ??
),(p)( o|s?p?
??
?=so|so|s )]([log)( 2 PPHThe number of possible state sequences growsexponentially as the sentence length increases.
Inorder to measure the uncertainty by entropy, it isinconvenient and unnecessary to compute theprobability of all the possible state sequences.
In-stead we implement N-best Viterbi search to findthe N state sequences with the highest probabilities.The entropy H(N) is defined as the entropy of thedistribution of the N-best state sequences:?
?
?= = ?
?= ??????????
?=NiNi iiNi iiPPPPNH1121)()(log)()()(o|so|so|so|s .
(1)The range of the entropy H(N) is [0,N1log 2? ]
which varies according to different N.We could use the equation (2) to normalize theH(N) to [0, 1].NNHNH1log)()(2?=?
.
(2)2.3 Diversity-based Sample SelectionWe measure the sentence structure similarity torepresent the diversity and catch the most represen-tative ones in order to give more diverse features tothe machine learning-based classification systems.We propose a three-level hierarchy to representthe structure of a sentence.
The first level is NPchunk, the second level is Part-Of-Speech tag, andthe third level is the word itself.
Each word is rep-resented using this hierarchy structure.
For exam-ple in the sentence "I am a boy", the word "boy" isrepresented as wr=[NP, NN, boy].
The similarityscore of two words is defined as:)()(),(2)(212121 wDepthwDepthwwDepthwwsim rrrrrr+?=?Where ),( 21 wwDepthrris defined from the toplevel as the number of levels that the two words arein common.
Under our three-level hierarchyscheme above, each word representation has depthof 3.The structure of a sentence S is represented asthe word representation vectors ],  ,,[ 21 NwwwrKrr .We measure the similarity of two sentences by thestandard cosine-similarity measure.
The similarityscore of two sentences is defined as:22112121 ),(SSSSSSSSsimilarity rrrrrrrr??
?= ,??
?=?i jji wwsimSS )( 2121rrrr.702.4 MMR Combination for Sample SelectionWe would like to score the sample sentences withrespect to both the uncertainty and the diversity.The following MMR (Maximal Marginal Rele-vance) (Carbonell and Goldstein 1998) formula isused to calculate the active learning score:),(Similaritymax)1(),(yUncertaint)(jiTsidefissMssscoreMj????
?= ??
(3)where si is the sentence to be selected, Uncertaintyis the entropy of si given current NER module M,and Similarity indicates the divergence degree be-tween the si and the sentence sj in the training cor-pus TM of M. The combination rule could beinterpreted as assigning a higher score to a sen-tence of which the NER module is uncertain andwhose configuration differs from the sentences inthe existing training corpus.
The value of parame-ter ?
coordinates those two different aspects ofthe desirable sample sentences.After initializing a NER module M and an ap-propriate value of the parameter?
, we can assigneach candidate sentence a score under the controlof the uncertainty and the diversity.3 Experiment and Discussion3.1 Experiment SetupWe conducted our active learning experiments us-ing pool-based sample selection (Lewis and Gale1994).
The pool-based sample selection, in whichthe learner chooses the best instances for labelingfrom a given pool of unlabelled examples, is themost practical approach for problems in whichunlabelled data is relatively easily available.For our empirical evaluation of the active learn-ing methods, we used the training and test datareleased by JNLPBA (Kim et al 2004).
The train-ing corpus contains 2000 MEDLINE abstracts, andthe test data contains 404 abstracts from theGENIA corpus.
100 abstracts were used to trainour initial NER module.
The remaining trainingdata were taken as the pool.
Each time, we chose kexamples from the given pool to train the newNER module and the number k varied from 1000to 17000 with a step size 1000.We test 4 different active learning methods: Ran-dom selection, Entropy-based uncertainty selection,Entropy combined with Diversity, and NormalizedEntropy (equation (2)) combined with Diversity.When we compute the active learning score usingthe entropy based method and the combiningmethods we set the values of parameter N (fromequation (1)) to 3 and ?
(from equation (3)) to 0.8empirically.Fig1.
Comparison of active learning strategies with the ran-l in the y-axis shows theperbinies consistently outperformthedom selection3.2 Results and AnalysesThe initial NER module gets an F-score of 52.54,while the F-score performance of the NER moduleusing the whole training data set is 67.19.
We plot-ted the learning curves for the different sampleselection strategies.
The interval in the x-axis be-tween the curves shows the number of examplesselected and the intervaformance improved.We compared the entropy, entropy combinedwith sentence diversity, normalized entropy com-ed with sentence diversity and random selection.The curves in Figure 1 show the relative per-formance.
The F-score increases along with thenumber of selected examples and receives the bestperformance when all the examples in the pool areselected.
The results suggest that all three kinds ofactive learning strategrandom selection.The entropy-based example selection has im-proved performance compared with the randomselection.
The entropy (N=3) curve approaches tothe random selection around 13000 sentences se-lected, which is reasonable since all the methodschoose the examples from the same given pool.
As71the number of selected sentences approaches thepool size, the performance difference among thedifferent methods gets small.
The best performanceof the entropy strategy is 67.31 when 17000 exam-plethenormalized combined strategybehaves the worst.4 Conclusionction could significantly reducethe human effort.by Minis-try of Commerce, Industry and Energy.s are selected.Comparing with the entropy curve, the com-bined strategy curve shows an interesting charac-teristic.
Up to 4000 sentences, the entropy strategyand the combined strategy perform similarly.
Afterthe 11000 sentence point, the combined strategysurpasses the entropy strategy.
It accords with ourbelief that the diversity increases the classifier'sperformance when the large amount of samples isselected.
The normalized combined strategy dif-fers from the combined strategy.
It exceeds theother strategies from the beginning and maintainsbest performance up until 12000 sentence point.The entropy strategy reaches 67.00 in F-scorewhen 11000 sentences are selected.
The combinedstrategy receives 67.17 in F-score while 13000 sen-tences are selected, while the end performance is67.19 using the whole training data.
The combinedstrategy reduces 24.64 % of training examplescompared with the random selection.
The normal-ized combined strategy achieves 67.17 in F-scorewhen 11000 sentences are selected, so 35.43% ofthe training examples do not need to be labeled toachieve almost the same performance as the endperformance.
The normalized combined strategy'sperformance becomes similar to the random selec-tion strategy at around 13000 sentences, and after14000 sentences theWe incorporate active learning into the biomedicalnamed-entity recognition system to enhance thesystem's performance with only small amount oftraining data.
We presented the entropy-based un-certainty sample selection and combined selectionstrategies using the corpus diversity.
Experimentsindicate that our strategies for active-learningbased sample seleAcknowledgementThis research was supported as a Brain Neuroin-formatics Research Program sponsoredReferencesCarbonell J., & Goldstein J.
(1998).
The Use of MMR,Diversity-Based Reranking for Reordering Docu-ments and Producing Summaries.
In Proceedings ofthe 21st Annual International ACM-SIGIR Confer-ence on Research and Development in InformationRetrieval, pages 335-336.Cohn, D. A., Atlas, L., & Ladner, R. E. (1994).
Improv-ing generalization with active learning, MachineLearning, 15(2), 201-221.Dagan, I., & Engelson S. (1995).
Committee-basedsampling for training probabilistic classifiers.
In Pro-ceedings of the Twelfth International Conference onMachine Learning, pages 150-157, San Francisco,CA, Morgan Kaufman.Freund Y., Seung H.S., Shamir E., & Tishby N. (1997).Selective sampling using the query by committee al-gorithm, Machine Learning, 28, 133-168.Kim JD., Ohta T., Tsuruoka Y., & Tateisi Y.
(2004).Introduction to the Bio-Entity Recognition Task atJNLPBA, Proceedings of the International Workshopon Natural Language Processing in Biomedicine andits Application (JNLPBA).Lafferty, J., McCallum, A., & Pereira, F. (2001).
Condi-tional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of the18th International Conf.
on Machine Learning, pages282-289, Williamstown, MA, Morgan Kaufmann.Lewis D., & Gale W. (1994).
A Sequential Algorithmfor Training Text Classifiers, In: Proceedings of theSeventeenth Annual International ACM-SIGIR Con-ference on Research and Development in InformationRetrieval.
pp.
3-12, Springer-Verlag.Liere, R., & Tadepalli, P. (1997).
Active learning withcommittees for text categorization, In proceedings ofthe Fourteenth National Conference on Artificial In-telligence, pp.
591-596 Providence, RI.Scheffer T., & Wrobel S. (2001).
Active learning ofpartially hidden markov models.
In Proceedings ofthe ECML/PKDD Workshop on Instance Selection.Song Y., Kim E., Lee G.G., & Yi B-k. (2005).POSBIOTM-NER: a trainable biomedical named-entity recognition system.
Bioinformatics, 21 (11):2794-2796.Thompson C.A., Califf M.E., & Mooney R.J. (1999).Active Learning for Natural Language Parsing andInformation Extraction, In Proceedings of the Six-teenth International Machine Learning Conference,pp.406-414, Bled, Slovenia.72
