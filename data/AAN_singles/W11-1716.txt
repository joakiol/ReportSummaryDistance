Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 125?131,24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational LinguisticsAutomatic Expansion of Feature-Level Opinion LexiconsFerm?
?n L. Cruz, Jose?
A. Troyano, F. Javier Ortega, Fernando Enr?
?quezUniversity of SevilleAvda.
Reina Mercedes s/n.41012 Seville, Spain{fcruz,troyano,javierortega,fenros}@us.esAbstractIn most tasks related to opinion mining andsentiment analysis, it is necessary to computethe semantic orientation (i.e., positive or neg-ative evaluative implications) of certain opin-ion expressions.
Recent works suggest that se-mantic orientation depends on application do-mains.
Moreover, we think that semantic ori-entation depends on the specific targets (fea-tures) that an opinion is applied to.
In this pa-per, we introduce a technique to build domain-specific, feature-level opinion lexicons in asemi-supervised manner: we first induce a lex-icon starting from a small set of annotateddocuments; then, we expand it automaticallyfrom a larger set of unannotated documents,using a new graph-based ranking algorithm.Our method was evaluated in three differentdomains (headphones, hotels and cars), usinga corpus of product reviews which opinionswere annotated at the feature level.
We con-clude that our method produces feature-levelopinion lexicons with better accuracy and re-call that domain-independent opinion lexiconsusing only a few annotated documents.1 IntroductionSentiment analysis is a modern subdiscipline of nat-ural language processing which deals with subjec-tivity, affects and opinions in texts (a good survey onthis subject can be found in (Pang and Lee, 2008)).This discipline is also known as opinion mining,mainly in the context of text mining and informationextraction.
Many classification and extraction prob-lems have been defined, with different levels of gran-ularity depending on applications requirements: e.g.classification of text documents or smaller piecesof text into objective and subjective, classificationof opinionated documents or individual sentencesregarding the overall opinion (into ?positive?
and?negative?
classes, or into a multi-point scale) or ex-traction of individual opinions from a piece of text(may include opinion target, holder, polarity or in-tensity of the opinions, among others).
As a key insolving most of these problems, the semantic orien-tation of some opinion expressions should be com-puted: a numeric value, usually between ?1 and 1,referring to the negative or positive affective impli-cations of a given word or prhase.
These values canbe collected in an opinion lexicon, so this resourcecan be accessed when needed.Many recent works (Popescu and Etzioni, 2005;Kanayama and Nasukawa, 2006; Cruz et al, 2010;Qiu et al, 2011) suggest the need for domain-specific opinion lexicons, containing semantic ori-entations of opinion expressions when used in a par-ticular domain (e.g., the word ?predictable?
has op-posite semantic orientations when used to define thedriving experience of a car or the plot of a movie).Moreover, within a given domain, the specific targetof the opinion is also important to induce the po-larity and the intensity of the affective implicationsof some opinion expressions ( consider for examplethe word ?cheap?
when referring to the price or tothe appearance of an electronic device).
This is es-pecially important to extract opinions from productreviews, where users write their opinions about indi-vidual features of a product.
These domain-specific,feature-level opinion lexicons can be manually col-lected, but it implies a considerable amount of time125and effort, especially if a large number of differentdomains are considered.In this work, we propose a method to automati-cally induce feature-level, domain-specific opinionlexicons from an annotated corpus.
As we are com-mitted to reduce the time and effort, we researchabout the automatic expansion of this kind of lexi-cons, so we keep the number of required annotateddocuments as low as possible.
In order to do so, wepropose a graph-based algorithm which can be ap-plied to other knowledge propagation problems.In the next section, we review some related previ-ous works to contextualize our approach.
In section3, we define the feature-level opinion lexicons anddescribe our method to induce and expand them in asemi-supervised manner.
In section 4, we carry outsome experiments over a dataset of reviews of threediferent domains.
Finally, we discuss the results anddraw some conclusions in section 5.2 Related workIn this section, we briefly discuss some relatedworks about semantic orientation induction andopinion lexicon expansion, pointing out the maindifferences with our contribution.
We also intro-duce the feature-based opinion extraction task, sinceit is the natural application context for feature-levelopinion lexicons.2.1 Semantic orientation inductionMany methods for computing semantic orientationsof words or phrases have been proposed over thelast years.
Some of them rely on a large set oftext documents to compute semantic orientations ofwords in an unsupervised manner (Hatzivassiloglouand McKeown, 1997; Turney and Littman, 2003; Yuand Hatzivassiloglou, 2003).
They all start from afew positive and negative seeds, and calculate the se-mantic orientation of target words based on conjunc-tive constructions (Hatzivassiloglou and McKeown,1997) or co-occurrences (Turney and Littman, 2003;Yu and Hatzivassiloglou, 2003) of target words andseeds.
These methods allow computing domain-specific semantic orientations, just using a set ofdocuments of the selected domain, but they obtainmodest values of recall and precision.
We are us-ing the observations about conjunctive constructionsfrom (Hatzivassiloglou and McKeown, 1997) in ourapproach.Other works use the lexical resource Word-Net(Fellbaum, 1998) to compute the semantic ori-entation of a given word or phrase.
For example, in(Kamps et al, 2004), a distance function betweenwords is defined using WordNet synonymy rela-tions, so the semantic orientation of a word is cal-culated from the distance to a positive seed (?good?
)and a negative seed (?bad?).
Other works use a big-ger set of seeds and the synonyms/antonyms setsfrom WordNet to build an opinion lexicon incremen-tally (Hu and Liu, 2004a; Kim and Hovy, 2004).In other works (Esuli and Sebastiani, 2006; Bac-cianella et al, 2010; Esuli and Sebastiani, 2005), thebasic assumption is that if a word is semanticallyoriented in one direction, then the words in its gloss(i.e.
textual definitions) tend to be oriented in thesame direction.
Two big sets of positive and nega-tive words are built, starting from two initial sets ofseed words and growing them using the synonymyand antonymy relations in WordNet.
For every wordin those sets, a textual representation is obtained bycollecting all the glosses of that word.
These textualrepresentations are transformed into vectors by stan-dard text indexing techniques, and a binary classifieris trained using these vectors.
The same assumptionabout words and their glosses is made by Esuli andSebastiani (2007), but the relation between wordsand glosses are used to build a graph representationof WordNet.
Given a few seeds as input, two scoresof positivity and negativity are computed, using arandom-walk ranking algorithm similar to PageR-ank (Page et al, 1998).
As a result of these works, anopinion lexicon named SentiWordNet (Baccianellaet al, 2010) is publicly available.
We are also us-ing a ranking algorithm in our expansion method,but applying it to a differently built, domain-specificgraph of terms.The main weakness of the dictionary-based ap-proaches is that they compute domain-independentsemantic orientations.
There are some manually-collected lexicons (Stone, 1966; Cerini et al, 2007),with semantic orientations of terms set by humans.However, they are also domain-independent re-sources.1262.2 Opinion lexicon expansionThere are a couple of works that deal with the morespecific problem of opinion lexicon expansion.
In(Kanayama and Nasukawa, 2006), the authors pro-pose an algorithm to automatically expand an initialopinion lexicon based on context coherency, the ten-dency for same polarities to appear successively incontexts.
In (Qiu et al, 2011), a method to automat-ically expand an initial opinion lexicon is presented.It consists of identifing the syntactic relations be-tween opinion words and opinion targets, and usingthese relations to automatically identify new opinionwords and targets in a bootstrapping process.
Then,a polarity (positive or negative) is assigned to eachof these new opinion words by applying some con-textual rules.
In both works, the opinion lexiconsbeing expanded are domain-specific, but they are nottaking into account the dependency between the spe-cific targets of the opinions and the semantic orienta-tions of terms used to express those opinions.
To ourknowledge, there are no previous works on inducingand expanding feature-level opinion lexicons.2.3 Feature-based opinion extractionFeature-based opinion extraction is a task related toopinion mining and information extraction.
It con-sists of extracting individual opinions from texts, in-dicating the polarity and the specific target of eachopinion; then, these opinions can be aggregated,summarized and visualized.
It was first defined byHu and Liu (2004b), and attemped by many oth-ers (Popescu and Etzioni (2005), Ding et al (2008)and Cruz et al (2010), among others), because ofits practical applications.
Being a key element inthis task, most of these works propose algorithms tocompute semantic orientations of terms, generallydomain-specific orientations.
We aim to build notonly domain-specific but also feature-level opinionlexicons, in an attempt to improve the performanceof a feature-based opinion extraction system (a de-scription of our system can be found in (Cruz et al,2010)).3 Proposed methodIn this section we define feature-level opinion lex-icons and propose a semi-supervised method to ob-tain it.
The method consists of two main steps.
First,a small lexicon is induced from a set of annotateddocuments.
Then, the lexicon is automatically ex-panded using a set of unannotated documents.3.1 DefinitionsA domain D is a class of entities with a fixed set ofopinable features FD.
A feature is any component,part, attribute or property of an entity.
A feature-based opinion is any piece of text with positive ornegative implications on any feature of an entity.
Wename opinion words to the minimun set of wordsfrom an opinion from which you can decide the po-larity (i.e., if it is a positive or a negative opinion).
Afeature-level opinion lexicon LD for a given domainD is a function T ?FD ?
[?1.0, 1.0], where T is aset of terms (i.e., individual words or phrases), andFD is the set of opinable features for the domain D.LD assign a semantic orientation to each term fromT when used as opinion words in an opinion on aparticular feature from FD.3.2 InductionIn order to generate a feature-based opinion lexiconto be used as seed in our expansion experiments,we collect a set of text reviews RD on a partic-ular domain D, and annotate all the feature-basedopinions we encounter.
Each opinion is a tuple(polarity, f, opW ), where polarity is + (positive)or - (negative), f is a feature from FD, and opWis a set of opinion words from the text.
Each anno-tated opinion gives information about the semanticorientation of the opinion words.
Most of the times,the polarity of the opinion implies the polarity of theopinion words.
But sometimes, the opinion wordsinclude some special expressions that have to beconsidered to induce the polarity of the rest of opin-ion words, as negation expressions1, which invertthe polarity of the rest of opinion words; and domi-nant polarity expressions2, which completely deter-mine the polarity of an opinion, no matter whichother opinion words take part.
For each opinion termobserved (individual words or phrases included asopinion words, once negation and dominant polarity1Negation expressions: barely, hardly, lack, never, no, not,not too, scarcely.2Dominant polarity expressions: enough, sufficient, suffi-ciently, reasonably, unnecessarily, insufficient, insufficiently,excessive, excessively, overly, too, at best, too much.127expressions been removed), the final semantic orien-tation for a given feature is the mean of the semanticorientations suggested by each annotated opinion onthat feature containing the opinion expression (wetake 1.0/-1.0 for each positive/negative annotation).3.3 ExpansionStarting from a big set of unannotated text reviewsR?D, we use the information provided by conjunctiveconstructions to expand the lexicon previously in-duced.
As explained by Hatzivassiloglou and McK-eown (1997), two opinion terms appearing in a con-junctive constructions tend to have semantic orienta-tions with the same or opposite directions, depend-ing on the conjunction employed.
Based on thisprinciple, we build a graph linking those terms ap-pearing in a conjunctive expression.
We computethe semantic orientation of each term spreading theinformation provided by those terms in the initiallexicon through the graph.
In order to do that, wepropose a new random-walk ranking algorithm withthe ability to deal with graphs containing positivelyand negatively weighted edges.3.3.1 Building the graphThe graph is built from R?D, searching for con-junctive constructions between terms.
Two termsparticipate in a conjunctive construction if they ap-pear consecutively in the text separated by a con-junction and or but, or the puntuation mark comma(,).
There are two types of conjunctive construc-tions, direct and inverse, depending on the conjunc-tion and the negation expressions participating.
Ina direct conjunctive construction, both terms seemsto share the same semantic orientation; in a reverseone, they might have opposite semantic orientations.Some examples are shown next:?
Direct conjunctive constructionsThe camera has a bright and accurate len.It is a marvellous, really entertaining movie.. .
.
clear and easy to use interface.. .
.
easy to understand, user-friendly interface.?
Inverse conjunctive constructionsThe camera has a bright but inaccurate len.It is a entertaining but typical film.The driving is soft and not aggresive.The terms observed in conjunctive constructions(in bold type in the previous examples) are the nodesof the graph.
If two terms participate in a con-junctive cosntruction, the corresponding nodes arelinked by an edge.
Each edge is assigned a weightequal to the number of direct conjunctive construc-tions minus the number of inverse conjunctive con-structions observed between the linked terms.3.3.2 PolarityRankWe propose a new random-walk ranking algo-rithm, named PolarityRank.
It is based on PageRank(Page et al, 1998).
In summary, PageRank com-putes the relevance of each node in a graph based onthe incoming edges and the relevance of the nodesparticipating in those edges; an edge is seen as a rec-ommendation of one node to another.
PolarityRankgeneralizes the concept of vote or recommendation,allowing edges with positive and negative weights.A positive edge still means a recommendation, morestrongly the greater the weight of the edge.
By con-trast, a negative edge represents a negative feedback,more strongly the greater the absolute value of theweight.
PolarityRank calculates two scores for eachnode, a positive and a negative one (PR+ and PR?,respectively).
Both scores are mutually dependent:the positive score of a node n is increased in pro-portion to the positive score of the nodes linked to nwith positively weighted edges; in addition, the pos-itive score of n is also increased in proportion to thenegative score of the nodes linked to n with nega-tively weighted edges.
The same principles apply tothe calculus of the negative scores of the nodes.The algorithm definition is as follows.
Let G =(V,E) be a directed graph where V is a set ofnodes and E a set of directed edges between pair ofnodes.
Each edge of E has an associated real valueor weight, distinct from zero, being pji the weightassociated with the edge going from node vj to vi.Let us define Out(vi) as the set of indices j of thenodes for which there exists an outgoing edge fromvi.
Let us define In+(vi) and In?
(vi) as the sets ofindices j of the nodes for which there exists an in-coming edge to vi whose weight is positive or neg-ative, respectively.
We define the positive and neg-ative PolarityRank of a node vi (equation 1), wherethe values e+ and e?
are greater than zero for cer-tain nodes acting as positive or negative seeds, re-128spectively.
The parameter d is a damping factor thatguarantees convergence; in our experiments we usea value of 0.85 (as recommended in the original def-inition of PageRank).
The computation of PR+ andPR?
is done iteratively as described by Page et al(1998).PR+(vi) = (1?
d)e+i ++ d( ?j?In+(vi)pji?k?Out(vj)|pjk|PR+(vj)++?j?In?(vi)?pji?k?Out(vj)|pjk|PR?(vj))PR?
(vi) = (1?
d)e?i ++ d( ?j?In+(vi)pji?k?Out(vj)|pjk|PR?(vj)++?j?In?
(vi)?pji?k?Out(vj)|pjk|PR+(vj))(1)The sum of the values of e+ and e?
must be equalto the number of nodes in the graph.3.3.3 Extending the lexiconBased on a seed lexicon LD, and a set of unanno-tated reviews R?D, the expanded lexicon L?D is ob-tained following these steps:1.
Build a graph G = (V,E) representing theconjunctive relations observed in R?D.2.
For each feature f from FD:(a) For each vi from V with associated termti, such that LD(ti, f) is defined, assignthat value to e+i if it is greater than 0, elseassign it to e?i .
(b) Linearly normalize the values of e+i ande?i , so that the sum of the values is equalto |V |.
(c) Compute PR+ and PR?.
(d) For each vi from V with associated termti, assign SO(vi) to L?D(ti, f), where:SO(vi) =PR+(vi)?
PR?
(vi)PR+(vi) + PR?
(vi)Note that these values are contained in theinterval [?1.0, 1.0].4 ExperimentsIn this section we report the results of some exper-iments aimed to evaluate the quality of the feature-level opinion lexicons obtained by our method.4.1 DataWe used a set of reviews of three different domains(headphones, hotels and cars).
We retrieved themfrom Epinions.com, a website specialized in prod-uct reviews written by customers.
Some reviewsfrom the dataset were labeled, including the polarity,the feature and the opinion words of each individualopinion found.
Some information of the dataset isshown in table 1.
The dataset is available for publicuse3.Domain Reviews Opinions FeaturesHeadphones 587 (2591) 3897 31Hotels 988 (6171) 11054 60Cars 972 (23179) 8519 91Table 1: Information of the dataset.
The number of un-nanotated reviews available for each domain is shown inparenthesis.4.2 Experimental setupAll the experiments were done using 10-fold cross-validation.
Each annotated dataset was randomlypartitioned into ten subsets.
The results reported foreach experiment are the average results obtained inten different runs, taking a different subset as testingset and the remaining nine subsets as training set (toinduce seed lexicons).
To evaluate the lexicons, wecompute recall and precision over the terms partic-ipating as opinion words in the opinions annotatedin the testing set.
Recall is the proportion of termswhich are contained in the lexicon; precision is theproportion of terms with a correct sentiment orien-tation in the lexicon.4.3 ResultsTable 2 shows the results of the evaluation of the in-duced and expanded lexicons.
In order to figure outthe gain in precision and recall obtained by our ex-pansion method, we induced lexicons for each do-main using different numbers of annotated reviews3http://www.lsi.us.es/?fermin/index.php/Datasets129Induced Lexicon Expanded LexiconDomain |RD| p r F1 p r F1 ?
(p) ?
(r) ?
(F1)Headphones9 0.9941 0.4479 0.6176 0.9193 0.7332 0.8158 -0.0748 +0.2853 +0.198245 0.9821 0.7011 0.8181 0.9440 0.8179 0.8764 -0.0381 +0.1168 +0.0583108 0.9665 0.8038 0.8777 0.9525 0.8562 0.9018 -0.0140 +0.0524 +0.0241531 0.9554 0.9062 0.9302 0.9526 0.9185 0.9352 -0.0028 +0.0123 +0.0051Hotels9 0.9875 0.3333 0.4984 0.9416 0.8131 0.8726 -0.0459 +0.4798 +0.3743117 0.9823 0.7964 0.8796 0.9716 0.8802 0.9236 -0.0107 +0.0838 +0.0440324 0.9822 0.8732 0.9245 0.9775 0.9128 0.9440 -0.0047 +0.0396 +0.0195891 0.9801 0.9449 0.9622 0.9792 0.9507 0.9647 -0.0009 +0.0058 +0.0026Cars9 0.9894 0.4687 0.6361 0.9536 0.8262 0.8853 -0.0358 +0.3575 +0.2493117 0.9868 0.8008 0.8841 0.9712 0.8915 0.9296 -0.0156 +0.0907 +0.0455279 0.9849 0.8799 0.9294 0.9786 0.9116 0.9439 -0.0063 +0.0317 +0.0145882 0.9847 0.9300 0.9566 0.9831 0.9408 0.9615 -0.0016 +0.0108 +0.0049Table 2: Results of expansion of lexicons induced from different numbers of annotated reviews.
The second and thirdexperiments for each domain are done selecting the number of annotated reviews needed to achieve F1 scores for theinduced lexicon similar to the F1 scores for the expanded lexicon from the previous experiment.and expanding them using the whole set of unanno-tated reviews.
For each domain, we show the re-sults of experiments using only nine annotated re-views (one from each subset of reviews of the cross-validation process), and using all the available anno-tated reviews.
The second and third experiments foreach domain are those where F1 scores for the in-duced lexicon is similar to the F1 scores for the ex-panded lexicon from the previous experiment.
Thus,we can measure the number of additional anno-tated reviews needed to obtain similar results with-out expansion.
Using only nine annotated reviews,the expanded feature-level opinion lexicon achieves0.8158 of F1 for the headphones domain, 0.8764 forthe hotels domain and 0.8853 for the cars domain,a far better result that using a domain-independentopinion lexicon4.
To obtain similar F1 scores with-out using the expansion method, you should anno-tate between six and thirteen times more reviews.5 ConclusionsThere is evidence that the semantic orientation ofan opinion term not only depends on the domain,but also on the specific feature which that term isapplied to.
In this paper, we propose a method toautomatically induce domain-specific, feature-level4We perform some experiment using the domain-independent opinion lexicon SentiWordNet (Baccianellaet al, 2010), obtaining F1 values equal to 0.7907, 0.8199 and0.8243 for the headphones, hotels and cars domains.opinion lexicons from annotated datasets.
We re-search about the automatic expansion of this kind oflexicons, so we keep the number of required anno-tated documents as low as possible.
The results ofthe experiments confirm the utility of feature-levelopinion lexicons in opinion mining tasks such asfeature-based opinion extraction, reaching 0.9538 asaverage of F1 in three tested domains.
Even thoughif only a few annotated reviews are available, the lex-icons produced by our automatic expansion methodreach an average F1 of 0.8592, which is far bet-ter that using domain-independent opinion lexicon.Our expansion method is based on the representa-tion of terms and their similarities and differencesin a graph, and the application of a graph-basedalgorithm (PolarityRank) with the ability to dealwith positively and negatively weighted graphs.
Thesame algorithm can be applied to other knowledgepropagation problems, whenever a small amount ofinformation on some of the entities involved (andabout the similarities and differences between theentities) is available.
For example, we applied thesame algorithm to compute trust and reputation insocial networks(Ortega et al, 2011).ReferencesStefano Baccianella, Andrea Esuli, and Fabrizio Se-bastiani.
2010.
Sentiwordnet 3.0: An enhancedlexical resource for sentiment analysis and opinionmining.
In Nicoletta Calzolari (Conference Chair),130Khalid Choukri, Bente Maegaard, Joseph Mariani,Jan Odijk, Stelios Piperidis, Mike Rosner, and DanielTapias, editors, Proceedings of the Seventh conferenceon International Language Resources and Evaluation(LREC?10), Valletta, Malta, may.
European LanguageResources Association (ELRA).S.
Cerini, V. Compagnoni, A. Demontis, M. Formentelli,and G. Gandini, 2007.
Language resources and lin-guistic theory: Typology, second language acquisition,English linguistics., chapter Micro-WNOp: A goldstandard for the evaluation of automatically compiledlexical resources for opinion mining.
Franco AngeliEditore, Milano, IT.Ferm?
?n L. Cruz, Jose?
A. Troyano, Fernando Enr?
?quez,Javier Ortega, and Carlos G.Vallejo.
2010.
Aknowledge-rich approach to feature-based opinion ex-traction from product reviews.
In Proceedings of the2nd International Workshop on Search and MiningUser-Generated Contents, pages 13?20.
ACM.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
Aholistic lexicon-based approach to opinion mining.
InWSDM ?08: Proceedings of the international confer-ence on Web search and web data mining, pages 231?240, New York, NY, USA.
ACM.Andrea Esuli and Fabrizio Sebastiani.
2005.
Determin-ing the semantic orientation of terms through glossanalysis.
In Proceedings of the ACM SIGIR Con-ference on Information and Knowledge Management(CIKM).Andrea Esuli and Fabrizio Sebastiani.
2006.
Determin-ing term subjectivity and term orientation for opin-ion mining.
In Proceedings of the European Chap-ter of the Association for Computational Linguistics(EACL).Andrea Esuli and Fabrizio Sebastiani.
2007.
Pagerank-ing wordnet synsets: An application to opinion min-ing.
In Proceedings of ACL-07, the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 424?431.
Association for Computational Lin-guistics.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In Proceedings of the eighth conference on Eu-ropean chapter of the Association for ComputationalLinguistics, pages 174?181, Morristown, NJ, USA.Association for Computational Linguistics.Minqing Hu and Bing Liu.
2004a.
Mining and sum-marizing customer reviews.
In Proceedings of theACM SIGKDD Conference on Knowledge Discoveryand Data Mining (KDD), pages 168?177.Minqing Hu and Bing Liu.
2004b.
Mining and summa-rizing customer reviews.
In KDD ?04: Proceedingsof the tenth ACM SIGKDD international conferenceon Knowledge discovery and data mining, pages 168?177, New York, NY, USA.
ACM.Jaap Kamps, Maarten Marx, Robert J. Mokken, andMaarten De Rijke.
2004.
Using wordnet to measuresemantic orientation of adjectives.
In National Insti-tute for, volume 26, pages 1115?1118.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.
Fullyautomatic lexicon expansion for domain-oriented sen-timent analysis.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP), pages 355?363, Sydney, Australia, July.Association for Computational Linguistics.Soo-Min Kim and Eduard Hovy.
2004.
Determiningthe sentiment of opinions.
In Proceedings of the In-ternational Conference on Computational Linguistics(COLING).Javier Ortega, Jose?
Troyano, Ferm?
?n Cruz, and Fer-nando Enr?
?quez de Salamanca.
2011.
PolarityTrust:measuring trust and reputation in social networks.In Fourth International Conference on Internet Tech-nologies and Applications (ITA 11), Wrexham, NorthWales, United Kingdom, 9.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1998.
The pagerank citation ranking:Bringing order to the web.
Technical report, StanfordDigital Library Technologies Project.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in Infor-mation Retrieval, 2(1-2):1?135.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
InProceedings of the Human Language Technology Con-ference and the Conference on Empirical Methods inNatural Language Processing (HLT/EMNLP).Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.2011.
Opinion word expansion and target extractionthrough double propagation.
Computational Linguis-tics, 37(1).Philip J.
Stone.
1966.
The General Inquirer: A Com-puter Approach to Content Analysis.
The MIT Press.Peter D. Turney and Michael L. Littman.
2003.
Measur-ing praise and criticism: Inference of semantic orien-tation from association.
ACM Transactions on Infor-mation Systems, 21:315?346.Hong Yu and Vasileios Hatzivassiloglou.
2003.
Towardsanswering opinion questions: Separating facts fromopinions and identifying the polarity of opinion sen-tences.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP).131
