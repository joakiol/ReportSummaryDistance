Automat ic  construct ion of a hypernym-labeled noun hierarchyfrom textSharon A. CaraballoDept.
of Computer ScienceBrown UniversityProvidence, RI 02912sc@cs, brown, eduAbstractPrevious work has shown that automaticmethods can be used in building semanticlexicons.
This work goes a step further byautomatically creating not just clusters ofrelated words, but a hierarchy of nouns andtheir hypernyms, akin to the hand-built hi-erarchy in WordNet.1 Introduct ionThe purpose of this work is to build some-thing like the hypernym-labeled noun hierar-chy of WordNet (Fellbaum, 1998) automat-ically from text  using no other lexical re-sources.
WordNet has been an important re-search tool, but it is insufficient for domain-specific text, such as that encountered inthe MUCs (Message Understanding Confer-ences).
Our work develops a labeled hierar-chy based on a text corpus.In this project, nouns are clustered into ahierarchy using data on conjunctions and ap-positives appearing in the Wall Street Jour-nal.
The internal nodes of the resultingtree are then labeled with hypernyms for thenouns clustered underneath them, also basedon data extracted from the Wall Street Jour-nal.
The resulting hierarchy is evaluated byhuman judges, and future research directionsare discussed.2 Bui lding the noun hierarchyThe first stage in constructing our hierar-chy is to build an unlabeled hierarchy ofnouns using bottom-up clustering methods(see, e.g., Brown et al (1992)).
Nouns areclustered based on conjunction and apposi-tive data collected from the Wall Street Jour-nal corpus.
Some of the data comes from theparsed files 2-21 of the Wall Street JournalPenn Treebank corpus (Marcus et al, 1993),and additional parsed text was obtained byparsing the 1987 Wall Street Journal text us-ing the parser described in Charniak et al(1998).From this parsed text, we identified allconjunctions of noun phrases (e.g., "execu-tive vice-president and treasurer" or "scien-tific equipment, apparatus and disposables")and all appositives (e.g., "James H. Rosen-field, a former CBS Inc. executive" or "Boe-ing, a defense contractor").
The idea hereis that nouns in conjunctions or appositivestend to be semantically related, as discussedin Riloff and Shepherd (1997) and Roark andCharniak (1998).
Taking the head words ofeach NP and stemming them results in datafor about 50,000 distinct nouns.A vector is created for each noun contain-ing counts for how many times each othernoun appears in a conjunction or appositivewith it.
We can then measure the similarityof the vectors for two nouns by computingthe cosine of the angle between these vec-tors, asV*Wcos (v, w) - Ivi Iw iTo compare the similarity of two groups ofnouns, we define similarity as the average ofthe cosines between each pair of nouns madeup of one noun from each of the two groups.sim(A,B) = Ev,wCOS (v,w)size(A)size(B)where v ranges over all vectors for nouns120in group A, w ranges over the vectors forgroup B, and size(x) represents he numberof nouns which are descendants of node x.We want to create a tree of all of the nounsin this data using standard bottom-up clus-tering techniques as follows: Put each nouninto its own node.
Compute the similaritybetween each pair of nodes using the cosinemethod.
Find the two most similar nounsand combine them by giving them a commonparent (and removing the child nodes fromfuture consideration).
We can then computethe new node's imilarity to each other nodeby computing a weighted average of the sim-ilarities between each of its children and theother node.In other words, assuming nodes A and Bhave been combined under a new parent C,the similarity between C and any other nodei can be computed assim(C, i) =sire(A, i)size(A) + sire(B, i)size(B)size(A) + size(B)Once again, we combine the two most sim-ilar nodes under a common parent.
Repeatuntil all nouns have been placed under acommon ancestor.Nouns which have a cosine of 0 with everyother noun are not included in the final tree.In practice, we cannot follow exactly thatalgorithm, because maintaining a list of thecosines between every pair of nodes requiresa tremendous amount of memory.
With50,000 nouns, we would initially require a50,000 x 50,000 array of values (or a trian-gular array of about half this size).
Withour current hardware, the largest array wecan comfortably handle is about 100 timessmaller; that is, we can build a tree startingfrom approximately 5,000 nouns.The way we handled this limitation is toprocess the nouns in batches.
Initially 5,000nouns are read in.
We cluster these until wehave 2,500 nodes.
Then 2,500 more nounsare read in, to bring the total to 5,000 again,and once again we cluster until 2,500 nodesremain.
This process is repeated until allnouns have been processed.Since the lowest-frequency nouns are clus-tered based on very little information andhave a greater tendency to be clusteredbadly, we chose to filter some of these out.By reducing the number of nouns to be read,a much nicer structure is obtained.
We nowonly consider nouns with a vector of lengthat least 2.There are approximately 20,000 nouns asthe leaves in our final binary tree structure.Our next step is to try to label each of theinternal nodes with a hypernym describingits descendant ouns.3 Assigning hypernymsFollowing WordNet, a word A is said to bea hyperuym of a word B if native speakers ofEnglish accept he sentence "B is a (kind of)A.,,To determine possible hypernyms for aparticular noun, we use the same parsed textdescribed in the previous section.
As sug-gested in Hearst (1992), we can find somehypernym data in the text by looking forconjunctions involving the word "other", asin "X, Y, and other Zs" (patterns 3 and 4in Hearst).
From this phrase we can extractthat Z is likely a hypernym for both X andY.This data is extracted from the parsedtext, and for each noun we construct avectorof hypernyms, with a value of i if a word hasbeen seen as a hypernym for this noun and 0otherwise.
These vectors are associated withthe leaves of the binary tree constructed inthe previous ection.For each internal node of the tree, we con-struct a vector of hypernyms by adding to-gether the vectors of its children.
We thenassign a hypernym to this node by sim-ply choosing the hypernym with the largestvalue in this vector; that is, the hypernymwhich appeared with the largest number ofthe node's descendant nouns.
(In case ofties, the hypernyms are ordered arbitrarily.
)We also list the second- and third-best hy-pernyms, to account for cases where a sin-121Hypernyms # nouns gle word does not describe the cluster ad-equately, or cases where there are a fewgood hypernyms which tend to alternate,such as "country" and "nation".
(Theremay or may not be any kind of seman-tic relationship among the hypernyms listed.Because of the method of selecting hyper-nyms, the hypernyms may be synonyms ofeach other, have hypernym-hyponym rela-tionships of their own, or be completely un-related.)
If a hypernym has occurred withonly one of the descendant nouns, it is notlisted as one of the best hypernyms, sincewe have insufficient evidence that the wordcould describe this class of nouns.
Not ev-ery node has sufficient data to be assigned ahypernym.4 Compressing the treeThe labeled tree constructed in the previ-ous section tends to be extremely redundant.Recall that the tree is binary.
In many cases,a group of nouns really do not have an in-herent tree structure, for example, a clusterof countries.
Although it is possible that areasonable tree structure could be createdwith subtrees of, say, European countries,Asian countries, etc., recall that we are us-ing single-word hypernyms.
A large binarytree of countries would ideally have "coun-try" (or "nation") as the best hypernym atevery level.
We would like to combine thesesubtrees into a single parent labeled "coun-try" or "nation", with each country appear-ing as a leaf directly beneath this parent.
(Obviously, the tree will no longer be bi-nary).Another type of redundancy can occurwhen an internal node is unlabeled, meaninga hypernym could not be found to describe?
its descendant nouns.
Since the tree's root islabeled, somewhere above this node there isnecessarily a node labeled with a hypernymwhich applies to its descendant nouns, in-cluding those which are a descendant of thisnode.
We want to move this node's childrendirectly under the nearest labeled ancestor.We compress the tree using the followingvery simple algorithm: in depth-first order,visionbank/group/bondconductorproblemapparel/clothing/knitwearitem/paraphernalia/carfelony/charge/activitysystemofficial/product/rightofficial/company/productproduct/factor/service229551151113226109478810,2666,056agency/areaevent/itemanimal/group/peoplecountry/nation/producerproduct/item/cropdiversionproblem/drug/disorderwildlife6013518834830013030635Table 1: The children of the root node.examine the children of each internal node.If the child is itself an internal node, andit either has no best hypernym or the samethree best hypernyms as its parent, deletethis child and make its children into childrenof the parent instead.5 Results  and evaluationThere are 20,014 leaves (nouns) and 654 in-ternal nodes in the final tree (reduced from20,013 internal nodes in the uncompressedtree).
The top-level node in our learned treeis labeled "product/analyst/official".
(Re-call from the previous discussion that we donot assume any kind of semantic relation-ship among the hypernyms listed for a par-ticular cluster.)
Since these hypernyms arelearned from the Wall Street Journal, theyare domain-specific labels rather than themore general "thing/person".
However, ifthe hierarchy were to be used for text fromthe financial domain, these labels may bepreferred.The next level of the hierarchy, the chil-dren of the root, is as shown in Table 1.
("Conductor" seems out-of-place on this list;see the next section for discussion.)
These122numbers do not add up to 20,014 because1,288 nouns are attached irectly to the root,meaning that they couldn't be clustered toany greater level of detail.
These tend tobe nouns for which little data was avail-able, generally proper nouns (e.g., Reindel,Yaghoubi, Igoe).To evaluate the hierarchy, 10 internalnodes dominating at least 20 nouns were se-lected at random.
For each of these nodes,we randomly selected 20 of the nouns fromthe cluster under that node.
Three humanjudges were asked to evaluate for each nounand each of the (up to) three hypernymslisted as "best" for that cluster, whetherthey were actually in a hyponym-hypernymrelation.
The judges were students workingin natural language processing or computa-tional linguistics at our institution who werenot directly involved in the research for thisproject.
5 "noise" nouns randomly selectedfrom elsewhere in the tree were also addedto each cluster without the judges' knowl-edge to verify that the judges were not overlygenerous.Some nouns, especially proper nouns, werenot recognized by the judges.
For anynoun that was not evaluated by at least twojudges, we evaluated the noun/hypernympair by examining the appearances of thatnoun in the source text and verifying thatthe hypernym was correct for the predomi-nant sense of the noun.Table 2 presents the results of this eval-uation.
The table lists only results for theactual candidate hyponym nouns, not thenoise words.
The "Hypernym 1" column in-dicates whether the "best" hypernym wasconsidered correct, while the "Any hyper-nym" column indicates whether any of thelisted hypernyms were accepted.
Within?
those columns, "majority" lists the opinionof the majority of judges, and "any" indi-cates the hypernyms that were accepted byeven one of the judges.The "Hypernym 1/any" column can beused to compare results to Riloff and Shep-herd (1997).
For five hand-selected cate-gories, each with a single hypernym, and the20 nouns their algorithm scored as the bestmembers of each category, at least one judgemarked on average about 31% of the nounsas correct.
Using randomly-selected cate-gories and randomly-selected category mem-bers we achieved 39%.By the strictest criteria, our algorithmproduces correct hyponyms for a randomly-selected hypernym 33% of the time.
Roarkand Charniak (1998) report that for a hand-selected category, their algorithm generallyproduces 20% to 40% correct entries.Furthermore, if we loosen our criteria toconsider also the second- and third-best hy-pernyms, 60% of the nouns evaluated wereassigned to at least one correct hypernymaccording to at least one judge.The "bank/firm/station" cluster consistslargely of investment firms, which weremarked as incorrect for "bank", resulting inthe poor performance on the Hypernym 1measures for this cluster.
The last clusterin the list, labeled "company", is actually avery good cluster of cities that because ofsparse data was assigned a poor hypernym.Some of the suggestions in the .following sec-tion might correct this problem.Of the 50 noise words, a few of them wereactually rated as correct as well, as shown inTable 3.This is largely because the noise wordswere selected truly at random, so that anoise word for the "company" cluster maynot have been in that particular cluster butmay still have appeared under a "company"hypernym elsewhere in the hierarchy.6 Discussion and futuredirectionsFuture work should benefit greatly by usingdata on the hypernyms of hypernyms.
In ourcurrent tree, the best hypernym for the en-tire tree is "product"; however, many timesnodes deeper in the tree are given this la-bel also.
For example, we have a clusterincluding many forms of currency, but be-cause there is little data for these partic-ular words, the only hypernym found was"product".
However, the parent of this nodehas the best hypernym of "currency".
If123Three best hypernymsworker/craftsmen/personnelcost/expense/areacost/operation/problemlegislation/measure/proposalbenefit/business/factorfactorlawyerfirm/investor/analystbank/firm/stationcompanyAVERAGEHypernym 1majority13763221413066.6 / 33.0%any131085271413067.8 / 39.0%Any hypernymmajority1391192214141569.5 / 47.5%any1310171857141417612.1 / 60.5%Table 2: The results of the judges' evaluation.Three best hypernymsnoise wordsHypernym 1 Any hypernymmajority any majority any1 /2 .0% 4 /8 .0% 2 /4 .0% 4 /8 .0%Table 3: The results of the judges' evaluation of noise words.we knew that "product" was a hypernym of"currency", we could detect hat the parentnode's label is more specific and simply ab-sorb the child node into the parent.
Fur-thermore, we may be able to use data onthe hypernyms of hypernyms to give bet-ter labels to some nodes that are currentlylabeled simply with the best hypernyms oftheir subtrees, such as a node labeled "prod-uct/analyst" which has two subtrees, one la-beled "product" and containing words forthings, the other labeled "analyst" and con-taining names of people.
We would like toinstead label this node something like "en-tity".
It is not yet clear whether corpus datawill provide sufficient data for hypernyms atsuch a high level of the tree, but dependingon the intended application for the hierarchy,this level of generality might not be required.As noted in the previous ection, one ma-jor spurious result is a cluster of 51 nouns,mainly people, which is given the hypernym"conductor".
The reason for this is that fewof the nouns appear with hypernyms, andtwo of them (Giulini and Ozawa) appear inthe same phrase listing conductors, thus giv-ing "conductor" a count of two, sufficient obe listed as the only hypernym for the clus-ter.
It might be useful to have some strictercriterion for hypernyms, say, that they oc-cur with a certain percentage of the nounsbelow them in the tree.
Additional hyper-nym data would also be helpful in this case,and should be easily obtainable by lookingfor other patterns in the text as suggestedby Hearst (1992).Because the tree is built in a binaryfashion, when, e.g., three clusters shouldall be distinct children of a common par-ent, two of them must merge first, givingan artificial intermediate l vel in the tree.For example, in the current tree a clusterwith best hypernym "agency" and one withbest hypernym "exchange" (as in "stock ex-change") have a parent with two best hyper-nyms "agency/exchange", rather than bothof these nodes simply being attached to thenext level up with best hypernym "group".It might be possible to correct for this situa-tion by comparing the hypernyms for the twoclusters and if there is little overlap, delet-ing their parent node and attaching them totheir grandparent instead.It would be useful to try to identify termsmade up of multiple words, rather than justusing the head nouns of the noun phrases.124Not only would this provide a more "use-ful hierarchy, or at least perhaps one thatis more useful for certain applications, butit would also help to prevent some er-rors.
Hearst (1992) gives an example ofa potential hyponym-hypernym pair "bro-ken bone/injury".
Using our algorithm, wewould learn that "injury" is a hypernym of"bone".
Ideally, this would not appear in ourhierarchy since a more common hypernymwould be chosen instead, but it is possiblethat in some cases a bad hypernym wouldbe found based on multiple word phrases.
Adiscussion of the difficulties in deciding howmuch of a noun phrase to use can be foundin Hearst.Ideally, a useful hierarchy should allow formultiple senses of a word, and this is an areawhich can be explored in future work.
How-ever, domain-specific text tends to greatlyconstrain which senses of a word will appear,and if the learned hierarchy is intended foruse with the same type of text from which itwas learned, it is possible that'this would beof limited benefit.We used parsed text for these experimentsbecause we believed we would get better re-sults and the parsed data was readily avail-able.
However, it would be interesting tosee if parsing is necessary or if we can getequivalent or nearly-equivalent results doingsome simpler text processing, as suggestedin Ahlswede and Evens (1988).
Both Hearst(1992) and Riloff and Shepherd (1997) useunparsed text.7 Related workPereira et al (1993) used clustering to buildan unlabeled hierarchy of nouns.
Their hier-archy is constructed top-down, rather thanbottom-up, with nouns being allowed mem-bership in multiple clusters.
Their cluster-ing is based on verb-object relations ratherthan on the noun-noun relations that we use.Future work on our project will include anattempt o incorporate verb-object data aswell in the clustering process.
The tree theyconstruct is also binary with some internalnodes which seem to be "artificial", but forevaluation purposes they disregard the treestructure and consider only the leaf nodes.Unfortunately it is difficult to compare theirresults to ours since their evaluation is basedon the verb-object relations.Riloff and Shepherd (1997) suggested us-ing conjunction and appositive data to clus-ter nouns; however, they approximated thisdata by just looking at the nearest NP oneach side of a particular NP.
Roark andCharniak (1998) built on that work by actu-ally using conjunction and appositive datafor noun clustering, as we do here.
(Theyalso use noun compound ata, but in a sep-arate stage of processing.)
Both of theseprojects have the goal of building a singlecluster of, e.g., vehicles, and both use seedwords to initialize a cluster with nouns be-longing to it.Hearst (1992) introduced the idea of learn-ing hypernym-hyponym relationships fromtext and gives several examples of patternsthat can be used to detect hese relation-ships including those used here, along withan algorithm for identifying new patterns.This work shares with ours the feature thatit does not need large amounts of data tolearn a hypernym; unlike in much statisticalwork, a single occurrence is sufficient.The hyponym-hypernym pairs found byHearst's algorithm include some that Hearstdescribes as "context and point-of-view de-pendent," such as "Washington/nationalist"and "aircraft/target".
Our work is some-what less sensitive to this kind of problemsince only the most common hypernym of anentire cluster of nouns is reported, so muchof the noise is filtered.8 Conc lus ionWe have shown that hypernym hierarchiesof nouns can be constructed automati-cally from text with similar performanceto semantic lexicons built automatically forhand-selected hypernyms.
With the addi-tion of some improvements we have identi-fied, we believe that these automatic meth-ods can be used to construct ruly useful hi-erarchies.
Since the hierarchy is learned from125sample text, it could be trained on domain-specific text to create a hierarchy that ismore applicable to a particular domain thana general-purpose resource such as WordNet.9 AcknowledgmentsThanks to Eugene Charniak for helpful dis-cussions and for the data used in this project.Thanks also to Brian Roark, Heidi J. Fox,and Keith Hall for acting as judges in theproject evaluation.
This research is sup-ported in part by NSF grant IRI-9319516and by ONR grant N0014-96-1-0549.ReferencesThomas Ahlswede and Martha Evens.
1988.Parsing vs. text processing in the analysisof dictionary definitions.
In Proceedings ofthe 29th Annual Meeting of the Associa-tion for Computational Linguistics, pages217-224.Peter F. Brown, Vincent J. Della Pietra,Peter V. DeSouza, Jennifer C. Lai, andRobert L. Mercer.
1992.
Class-based n-gram models of natural anguage.
Com-putational Linguistics, 18:467-479.Eugene Charniak, Sharon Goldwater, andMark Johnson.
1998.
Edge-based best-first chart parsing.
In Proceedings of theSixth Workshop on Very Large Corpora,pages 127-133.
Association for Computa-tional Linguistics.Christiane Fellbaum, editor.
1998.
Word-Net: An Electronic Lexical Database.
MITPress.Marti A. Hearst.
1992.
Automatic acquisi-tion of hyponyms from large text corpora.In Proceedings of the Fourteenth Interna-tional Conference on Computational Lin-guistics.Mitchell P. Marcus, Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Buildinga large annotated corpus of English: thePenn Treebank.
Computational Linguis-tics, 19:313-330.Fernando Pereira, Naftali Tishby, and Lil-lian Lee.
1993.
Distributional clusteringof English words.
In Proceedings of the31st Annual Meeting of the Associationfor Computational Linguistics, pages 183-190.Ellen Riloff and Jessica Shepherd.
1997.A corpus-based approach for building se-mantic lexicons.
In Proceedings of the Sec-ond Conference on Empirical Methods inNatural Language Processing, pages 117-124.Brian Roark and Eugene Charniak.
1998.Noun-phrase co-occurrence statistics forsemi-automatic semantic lexicon construc-tion.
In COLING-ACL '98: 36th An-nual Meeting of the Association for Com-putational Linguistics and 17th Interna-tional Conference on Computational Lin-guistics: Proceedings of the Conference,pages 1110-1116.126
