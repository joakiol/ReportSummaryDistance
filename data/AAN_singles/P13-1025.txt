Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 250?259,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsA computational approach to politeness with application to social factorsCristian Danescu-Niculescu-Mizil?
?, Moritz Sudhof?, Dan Jurafsky?,Jure Leskovec?, and Christopher Potts?
?Computer Science Department, ?Linguistics Department?
?Stanford University, ?Max Planck Institute SWScristiand|jure@cs.stanford.edu, sudhof|jurafsky|cgpotts@stanford.eduAbstractWe propose a computational frameworkfor identifying linguistic aspects of polite-ness.
Our starting point is a new corpusof requests annotated for politeness, whichwe use to evaluate aspects of politenesstheory and to uncover new interactionsbetween politeness markers and context.These findings guide our construction ofa classifier with domain-independent lexi-cal and syntactic features operationalizingkey components of politeness theory, suchas indirection, deference, impersonaliza-tion and modality.
Our classifier achievesclose to human performance and is effec-tive across domains.
We use our frame-work to study the relationship between po-liteness and social power, showing that po-lite Wikipedia editors are more likely toachieve high status through elections, but,once elevated, they become less polite.
Wesee a similar negative correlation betweenpoliteness and power on Stack Exchange,where users at the top of the reputationscale are less polite than those at the bot-tom.
Finally, we apply our classifier toa preliminary analysis of politeness vari-ation by gender and community.1 IntroductionPoliteness is a central force in communication, ar-guably as basic as the pressure to be truthful, in-formative, relevant, and clear (Grice, 1975; Leech,1983; Brown and Levinson, 1978).
Natural lan-guages provide numerous and diverse means forencoding politeness and, in conversation, we con-stantly make choices about where and how to usethese devices.
Kaplan (1999) observes that ?peo-ple desire to be paid respect?
and identifies hon-orifics and other politeness markers, like please,as ?the coin of that payment?.
In turn, polite-ness markers are intimately related to the powerdynamics of social interactions and are often adecisive factor in whether those interactions gowell or poorly (Gyasi Obeng, 1997; Chilton, 1990;Andersson and Pearson, 1999; Rogers and Lee-Wong, 2003; Holmes and Stubbe, 2005).The present paper develops a computationalframework for identifying and characterizing po-liteness marking in requests.
We focus on re-quests because they involve the speaker imposingon the addressee, making them ideal for exploringthe social value of politeness strategies (Clark andSchunk, 1980; Francik and Clark, 1985).
Requestsalso stimulate extensive use of what Brown andLevinson (1987) call negative politeness: speakerstrategies for minimizing (or appearing to mini-mize) the imposition on the addressee, for exam-ple, by being indirect (Would you mind) or apolo-gizing for the imposition (I?m terribly sorry, but)(Lakoff, 1973; Lakoff, 1977; Brown and Levin-son, 1978).Our investigation is guided by a new corpusof requests annotated for politeness.
The datacome from two large online communities in whichmembers frequently make requests of other mem-bers: Wikipedia, where the requests involve edit-ing and other administrative functions, and StackExchange, where the requests center around a di-verse range of topics (e.g., programming, garden-ing, cycling).
The corpus confirms the broad out-lines of linguistic theories of politeness pioneeredby Brown and Levinson (1987), but it also revealsnew interactions between politeness markings andthe morphosyntactic context.
For example, the po-liteness of please depends on its syntactic positionand the politeness markers it co-occurs with.Using this corpus, we construct a polite-ness classifier with a wide range of domain-independent lexical, sentiment, and dependencyfeatures operationalizing key components of po-250liteness theory, including not only the negativepoliteness markers mentioned above but also el-ements of positive politeness (gratitude, positiveand optimistic sentiment, solidarity, and inclusive-ness).
The classifier achieves near human-level ac-curacy across domains, which highlights the con-sistent nature of politeness strategies and paves theway to using the classifier to study new data.Politeness theory predicts a negative correlationbetween politeness and the power of the requester,where power is broadly construed to include so-cial status, authority, and autonomy (Brown andLevinson, 1987).
The greater the speaker?s powerrelative to her addressee, the less polite her re-quests are expected to be: there is no need for herto incur the expense of paying respect, and failingto make such payments can invoke, and hence re-inforce, her power.
We support this prediction byapplying our politeness framework to Wikipediaand Stack Exchange, both of which provide in-dependent measures of social status.
We showthat polite Wikipedia editors are more likely toachieve high status through elections; however,once elected, they become less polite.
Similarly,on Stack Exchange, we find that users at the top ofthe reputation scale are less polite than those at thebottom.Finally, we briefly address the question of howpoliteness norms vary across communities and so-cial groups.
Our findings confirm established re-sults about the relationship between politeness andgender, and they identify substantial variation inpoliteness across different programming languagesubcommunities on Stack Exchange.2 Politeness dataRequests involve an imposition on the addressee,making them a natural domain for studying theinter-connections between linguistic aspects of po-liteness and social variables.Requests in online communities We base ouranalysis on two online communities where re-quests have an important role: the Wikipediacommunity of editors and the Stack Exchangequestion-answer community.1 On Wikipedia, tocoordinate on the creation and maintenance ofthe collaborative encyclopedia, editors can in-teract with each other on user talk-pages;2 re-1http://stackexchange.com/about2http://en.wikipedia.org/wiki/Wikipedia:User_pagesquests posted on a user talk-page, although pub-lic, are generally directed to the owner of the talk-page.
On Stack Exchange, users often commenton existing posts requesting further information orproposing edits; these requests are generally di-rected to the authors of the original posts.Both communities are not only rich in user-to-user requests, but these requests are also partof consequential conversations, not empty socialbanter; they solicit specific information or con-crete actions, and they expect a response.Politeness annotation Computational studies ofpoliteness, or indeed any aspect of linguistic prag-matics, demand richly labeled data.
We there-fore label a large portion of our request data(over 10,000 utterances) using Amazon Mechan-ical Turk (AMT), creating the largest corpus withpoliteness annotations (see Table 1 for details).3We choose to annotate requests containing ex-actly two sentences, where the second sentenceis the actual request (and ends with a questionmark).
This provides enough context to the an-notators while also controlling for length effects.Each annotator was instructed to read a batch of13 requests and consider them as originating froma co-worker by email.
For each request, the anno-tator had to indicate how polite she perceived therequest to be by using a slider with values rang-ing from ?very impolite?
to ?very polite?.4 Eachrequest was labeled by five different annotators.We vetted annotators by restricting their resi-dence to be in the U.S. and by conducting a lin-guistic background questionnaire.
We also gavethem a paraphrasing task shown to be effectivefor verifying and eliciting linguistic attentiveness(Munro et al, 2010), and we monitored the an-notation job and manually filtered out annotatorswho submitted uniform or seemingly random an-notations.Because politeness is highly subjective and an-notators may have inconsistent scales, we ap-plied the standard z-score normalization to eachworker?s scores.
Finally, we define the politenessscore (henceforth politeness) of a request as theaverage of the five scores assigned by the annota-tors.
The distribution of resulting request scores(shown in Figure 1) has an average of 0 and stan-3Publicly available at http://www.mpi-sws.org/?cristian/Politeness.html4We used non-categorical ratings for finer granularity andto help account for annotators?
different perception scales.251domain #requests #annotated #annotatorsWiki 35,661 4,353 219SE 373,519 6,604 212Table 1: Summary of the request data and its po-liteness annotations.Figure 1: Distribution of politeness scores.
Posi-tive scores indicate requests perceived as polite.dard deviation of 0.7 for both domains; positivevalues correspond to polite requests (i.e., requestswith normalized annotations towards the ?very po-lite?
extreme) and negative values to impolite re-quests.
A summary of all our request data is shownin Table 1.Inter-annotator agreement To evaluate the re-liability of the annotations we measure the inter-annotator agreement by computing, for each batchof 13 documents that were annotated by the sameset of 5 users, the mean pairwise correlation of therespective scores.
For reference, we compute thesame quantities after randomizing the scores bysampling from the observed distribution of polite-ness scores.
As shown in Figure 2, the labels arecoherent and significantly different from the ran-domized procedure (p < 0.0001 according to aWilcoxon signed rank test).5Binary perception Although we did not im-pose a discrete categorization of politeness, weacknowledge an implicit binary perception of thephenomenon: whenever an annotator moved aslider in one direction or the other, she made abinary politeness judgment.
However, the bound-5The commonly used Cohen/Fleiss Kappa agreementmeasures are not suitable for this type of annotation, in whichlabels are continuous rather than categorical.Figure 2: Inter-annotator pairwise correlation,compared to the same measure after randomizingthe scores.Quartile: 1st 2nd 3rd 4thWiki 62% 8% 3% 51%SE 37% 4% 6% 46%Table 2: The percentage of requests for which allfive annotators agree on binary politeness.
The4th quartile contains the requests with the top 25%politeness scores in the data.
(For reference, ran-domized scoring yields agreement percentages of<20% for all quartiles.
)ary between somewhat polite and somewhat im-polite requests can be blurry.
To test this intuition,we break the set of annotated requests into fourgroups, each corresponding to a politeness scorequartile.
For each quartile, we compute the per-centage of requests for which all five annotatorsmade the same binary politeness judgment.
Asshown in Table 2, full agreement is much morecommon in the 1st (bottom) and 4th (top) quar-tiles than in the middle quartiles.
This suggeststhat the politeness scores assigned to requests thatare only somewhat polite or somewhat impoliteare less reliable and less tied to an intuitive notionof binary politeness.
This discrepancy motivatesour choice of classes in the prediction experiments(Section 4) and our use of the top politeness quar-tile (the 25% most polite requests) as a referencein our subsequent discussion.3 Politeness strategiesAs we mentioned earlier, requests impose on theaddressee, potentially placing her in social peril ifshe is unwilling or unable to comply.
Requeststherefore naturally give rise to the negative po-252liteness strategies of Brown and Levinson (1987),which are attempts to mitigate these social threats.These strategies are prominent in Table 3, whichdescribes the core politeness markers we analyzedin our corpus of Wikipedia requests.
We do notinclude the Stack Exchange data in this analysis,reserving it as a ?test community?
for our predic-tion task (Section 4).Requests exhibiting politeness markers are au-tomatically extracted using regular expressionmatching on the dependency parse obtained by theStanford Dependency Parser (de Marneffe et al,2006), together with specialized lexicons.
For ex-ample, for the hedges marker (Table 3, line 19),we match all requests containing a nominal subjectdependency edge pointing out from a hedge verbfrom the hedge list created by Hyland (2005).
Foreach politeness strategy, Table 3 shows the aver-age politeness score of the respective requests (asdescribed in Section 2; positive numbers indicatepolite requests), and their top politeness quartilemembership (i.e., what percentage fall within thetop quartile of politeness scores).
As discussed atthe end of Section 2, the top politeness quartilegives a more robust and more intuitive measure ofpoliteness.
For reference, a random sample of re-quests will have a 0 politeness score and a 25% topquartile membership; in both cases, larger num-bers indicate higher politeness.Gratitude and deference (lines 1?2) are waysfor the speaker to incur a social cost, helping tobalance out the burden the request places on theaddressee.
Adopting Kaplan (1999)?s metaphor,these are the coin of the realm when it comes topaying the addressee respect.
Thus, they are indi-cators of positive politeness.Terms from the sentiment lexicon (Liu et al,2005) are also tools for positive politeness, eitherby emphasizing a positive relationship with the ad-dressee (line 4), or being impolite by using nega-tive sentiment that damages this positive relation-ship (line 5).
Greetings (line 3) are another way tobuild a positive relationship with the addressee.The remainder of the cues in Table 3 are neg-ative politeness strategies, serving the purpose ofminimizing, at least in appearance, the impositionon the addressee.
Apologizing (line 6) deflects thesocial threat of the request by attuning to the impo-sition itself.
Being indirect (line 9) is another wayto minimize social threat.
This strategy allows thespeaker to avoid words and phrases convention-ally associated with requests.
First-person pluralforms like we and our (line 15) are also ways ofbeing indirect, as they create the sense that theburden of the request is shared between speakerand addressee (We really should .
.
.
).
Though in-directness is not invariably interpreted as polite-ness marking (Blum-Kulka, 2003), it is nonethe-less a reliable marker of it, as our scores indicate.What?s more, direct variants (imperatives, state-ments about the addressee?s obligations) are lesspolite (lines 10?11).Indirect strategies also combine with hedges(line 19) conveying that the addressee is unlikelyto accept the burden (Would you by any chance.
.
.
?, Would it be at all possible .
.
.
?).
These tooserve to provide the addressee with a face-savingway to deny the request.
We even see subtle effectsof modality at work here: the irrealis, counterfac-tual forms would and could are more polite thantheir ability (dispositional) or future-oriented vari-ants can and will; compare lines 12 and 13.
Thisparallels the contrast between factuality markers(impolite; line 20) and hedging (polite; line 19).Many of these features are correlated with eachother, in keeping with the insight of Brown andLevinson (1987) that politeness markers are of-ten combined to create a cumulative effect of in-creased politeness.
Our corpora also highlight in-teractions that are unexpected (or at least unac-counted for) on existing theories of politeness.
Forexample, sentence-medial please is polite (line 7),presumably because of its freedom to combinewith other negative politeness strategies (Couldyou please .
.
.
).
In contrast, sentence-initial pleaseis impolite (line 8), because it typically signals amore direct strategy (Please do this), which canmake the politeness marker itself seem insincere.We see similar interactions between pronominalforms and syntactic structure: sentence-initial youis impolite (You need to .
.
.
), whereas sentence-medial you is often part of the indirect strategieswe discussed above (Would/Could you .
.
.
).4 Predicting politenessWe now show how our linguistic analysis can beused in a machine learning model for automati-cally classifying requests according to politeness.A classifier can help verify the predictive power,robustness, and domain-independent generality ofthe linguistic strategies of Section 3.
Also, by pro-viding automatic politeness judgments for large253Strategy Politeness In top quartile Example1.
Gratitude 0.87*** 78%*** I really appreciate that you?ve done them.2.
Deference 0.78*** 70%*** Nice work so far on your rewrite.3.
Greeting 0.43*** 45%*** Hey, I just tried to .
.
.4.
Positive lexicon 0.12*** 32%*** Wow!
/ This is a great way to deal.
.
.5.
Negative lexicon -0.13*** 22%** If you?re going to accuse me .
.
.6.
Apologizing 0.36*** 53%*** Sorry to bother you .
.
.7.
Please 0.49*** 57%*** Could you please say more.
.
.8.
Please start ?0.30* 22% Please do not remove warnings .
.
.9.
Indirect (btw) 0.63*** 58%** By the way, where did you find .
.
.10.
Direct question ?0.27*** 15%*** What is your native language?11.
Direct start ?0.43*** 9%*** So can you retrieve it or not?12.
Counterfactual modal 0.47*** 52%*** Could/Would you .
.
.13.
Indicative modal 0.09 27% Can/Will you .
.
.14.
1st person start 0.12*** 29%** I have just put the article .
.
.15.
1st person pl.
0.08* 27% Could we find a less complex name .
.
.16.
1st person 0.08*** 28%*** It is my view that ...17.
2nd person 0.05*** 30%*** But what?s the good source you have in mind?18.
2nd person start ?0.30*** 17%** You?ve reverted yourself .
.
.19.
Hedges 0.14*** 28% I suggest we start with .
.
.20.
Factuality ?0.38*** 13%*** In fact you did link, .
.
.Table 3: Positive (1-5) and negative (6?20) politeness strategies and their relation to human perception ofpoliteness.
For each strategy we show the average (human annotated) politeness scores for the requestsexhibiting that strategy (compare with 0 for a random sample of requests; a positive number indicatesthe strategy is perceived as being polite), as well as the percentage of requests exhibiting the respectivestrategy that fall in the top quartile of politeness scores (compare with 25% for a random sample ofrequests).
Throughout the paper: for politeness scores, statistical significance is calculated by comparingthe set of requests exhibiting the strategy with the rest using a Mann-Whitney-Wilcoxon U test; for topquartile membership a binomial test is used.amounts of new data on a scale unfeasible for hu-man annotation, it can also enable a detailed anal-ysis of the relation between politeness and socialfactors (Section 5).Task setup To evaluate the robustness anddomain-independence of the analysis from Sec-tion 3, we run our prediction experiments on twovery different domains.
We treat Wikipedia as a?development domain?
since we used it for de-veloping and identifying features and for trainingour models.
Stack Exchange is our ?test domain?since it was not used for identifying features.
Wetake the model (features and weights) trained onWikipedia and use them to classify requests fromStack Exchange.We consider two classes of requests: politeand impolite, defined as the top and, respectively,bottom quartile of requests when sorted by theirpoliteness score (based on the binary notion ofpoliteness discussed in Section 2).
The classesare therefore balanced, with each class consistingof 1,089 requests for the Wikipedia domain and1,651 requests for the Stack Exchange domain.We compare two classifiers ?
a bag of wordsclassifier (BOW) and a linguistically informedclassifier (Ling.)
?
and use human labelers as areference point.
The BOW classifier is an SVMusing a unigram feature representation.6 We con-sider this to be a strong baseline for this new6Unigrams appearing less than 10 times are excluded.254classification task, especially considering the largeamount of training data available.
The linguisti-cally informed classifier (Ling.)
is an SVM usingthe linguistic features listed in Table 3 in additionto the unigram features.
Finally, to obtain a ref-erence point for the prediction task we also collectthree new politeness annotations for each of the re-quests in our dataset using the same methodologydescribed in Section 2.
We then calculate humanperformance on the task (Human) as the percent-age of requests for which the average score fromthe additional annotations matches the binary po-liteness class of the original annotations (e.g., apositive score corresponds to the polite class).Classification results We evaluate the classi-fiers both in an in-domain setting, with a standardleave-one-out cross validation procedure, and in across-domain setting, where we train on one do-main and test on the other (Table 4).
For both ourdevelopment and our test domains, and in both thein-domain and cross-domain settings, the linguis-tically informed features give 3-4% absolute im-provement over the bag of words model.
Whilethe in-domain results are within 3% of human per-formance, the greater room for improvement in thecross-domain setting motivates further research onlinguistic cues of politeness.The experiments in this section confirm thatour theory-inspired features are indeed effective inpractice, and generalize well to new domains.
Inthe next section we exploit this insight to automat-ically annotate a much larger set of requests (about400,000) with politeness labels, enabling us to re-late politeness to several social variables and out-comes.
For new requests, we use class probabil-ity estimates obtained by fitting a logistic regres-sion model to the output of the SVM (Witten andFrank, 2005) as predicted politeness scores (withvalues between 0 and 1; henceforth politeness, byabuse of language).5 Relation to social factorsWe now apply our framework to studying the rela-tionship between politeness and social variables,focussing on social power dynamics.
Encour-aged by the close-to-human performance of ourin-domain classifiers, we use them to assign po-liteness labels to our full dataset and then comparethese labels to independent measures of power andstatus in our data.
The results closely match thoseobtained with human-labeled data alone, therebyIn-domain Cross-domainTrain Wiki SE Wiki SETest Wiki SE SE WikiBOW 79.84% 74.47% 64.23% 72.17%Ling.
83.79% 78.19% 67.53% 75.43%Human 86.72% 80.89% 80.89% 86.72%Table 4: Accuracies of our two classifiers forWikipedia (Wiki) and Stack Exchange (SE), forin-domain and cross-domain settings.
Human per-formance is included as a reference point.
The ran-dom baseline performance is 50%.supporting the use of computational methods topursue questions about social variables.5.1 Relation to social outcomeEarlier, we characterized politeness markings ascurrency used to pay respect.
Such language istherefore costly in a social sense, and, relatedly,tends to incur costs in terms of communicative ef-ficiency (Van Rooy, 2003).
Are these costs worthpaying?
We now address this question by studyingpoliteness in the context of the electoral system ofthe Wikipedia community of editors.Among Wikipedia editors, status is a salient so-cial variable (Anderson et al, 2012).
Administra-tors (admins) are editors who have been grantedcertain rights, including the ability to block othereditors and to protect or delete articles.7 Ad-mins have a higher status than common editors(non-admins), and this distinction seems to bewidely acknowledged by the community (Burkeand Kraut, 2008b; Leskovec et al, 2010; Danescu-Niculescu-Mizil et al, 2012).
Aspiring editorsbecome admins through public elections,8 so weknow when the status change from non-admin toadmins occurred and can study users?
languageuse in relation to that time.To see whether politeness correlates with even-tual high status, we compare, in Table 5, the po-liteness levels of requests made by users who willeventually succeed in becoming administrators(Eventual status: Admins) with requests made byusers who are not admins (Non-admins).9 We ob-serve that admins-to-be are significantly more po-7http://en.wikipedia.org/wiki/Wikipedia:Administrators8http://en.wikipedia.org/wiki/Wikipedia:Requests_for_adminship9We consider only requests made up to one month beforethe election, to avoid confusion with pre-election behavior.255Eventual status Politeness Top quart.Admins 0.46** 30%***Non-admins 0.39*** 25%Failed 0.37** 22%Table 5: Politeness and status.
Editors whowill eventually become admins are more politethan non-admins (p<0.001 according to a Mann-Whitney-Wilcoxon U test) and than editors whowill eventually fail to become admins (p<0.001).Out of their requests, 30% are rated in the top po-liteness quartile (significantly more than the 25%of a random sample; p<0.001 according to a bi-nomial test).
This analysis was conducted on 31krequests (1.4k for Admins, 28.9k for Non-admins,652 for Failed).lite than non-admins.
One might wonder whetherthis merely reflects the fact that not all users aspireto become admins, and those that do are more po-lite.
To address this, we also consider users whoran for adminship but did not earn community ap-proval (Eventual status: Failed).
These users arealso significantly less polite than their successfulcounterparts, indicating that politeness indeed cor-relates with a positive social outcome here.5.2 Politeness and powerWe expect a rise in status to correlate with a de-cline in politeness (as predicted by politeness the-ory, and discussed in Section 1).
The previous sec-tion does not test this hypothesis, since all editorscompared in Table 5 had the same (non-admin)status when writing the requests.
However, ourdata does provide three ways of testing this hy-pothesis.First, after the adminship elections, successfuleditors get a boost in power by receiving adminprivileges.
Figure 3 shows that this boost is mir-rored by a significant decrease in politeness (blue,diamond markers).
Losing an election has the op-posite effect on politeness (red, circle markers),perhaps as a consequence of reinforced low status.Second, Stack Exchange allows us to test moresituational power effects.10 On the site, users re-quest, from the community, information they arelacking.
This informational asymmetry betweenthe question-asker and his audience puts him at10We restrict all experiments in this section to the largestsubcommunity of Stack Exchange, namely Stack Overflow.Before election Election After election0.410.370.390.46Predicted politenessscoresSuccessful candidatesFailed candidatesFigure 3: Successful and failed candidates be-fore and after elections.
Editors that will even-tually succeed (diamond marker) are significantlymore polite than those that will fail (circle mark-ers).
Following the elections, successful editorsbecome less polite while unsuccessful editors be-come more polite.a social disadvantage.
We therefore expect thequestion-asker to be more polite than the peoplewho respond.
Table 6 shows that this expectationis born out: comments posted to a thread by theoriginal question-asker are more polite than thoseposted by other users.Role Politeness Top quart.Question-asker 0.65*** 32%***Answer-givers 0.52*** 20%***Table 6: Politeness and dependence.
Requestsmade in comments posted by the question-askerare significantly more polite than the other re-quests.
Analysis conducted on 181k requests(106k for question-askers, 75k for answer-givers).Third, Stack Exchange allows us to examinepower in the form of authority, through the com-munity?s reputation system.
Again, we see a neg-ative correlation between politeness and power,even after controlling for the role of the user mak-ing the requests (i.e., Question-asker or Answer-giver).
Table 7 summarizes the results.11Human validation The above analyses arebased on predicted politeness from our classifier.This allows us to use the entire request data cor-11Since our data does not contain time stamps for reputa-tion scores, we only consider requests that were issued in thesix months prior to the available snapshot.256Reputation level Politeness Top quart.Low reputation 0.68*** 27%***Middle reputation 0.66*** 25%High reputation 0.64*** 23%***Table 7: Politeness and Stack Exchange reputation(texts by question-askers only).
High-reputationusers are less polite.
Analysis conducted on 25krequests (4.5k low, 12.5k middle, 8.4k high).pus to test our hypotheses and to apply precisecontrols to our experiments (such as restrictingour analysis to question-askers in the reputationexperiment).
In order to validate this methodol-ogy, we turned again to human annotation: wecollected additional politeness annotation for thetypes of requests involved in the newly designedexperiments.
When we re-ran our experiments onhuman-labeled data alone we obtained the samequalitative results, with statistical significance al-ways lower than 0.01.12Prediction-based interactions The human val-idation of classifier-based results suggests thatour prediction framework can be used to exploredifferences in politeness levels across factors ofinterest, such as communities, geographical re-gions and gender, even where gathering suffi-cient human-annotated data is infeasible.
Wemention just a few such preliminary results here:(i) Wikipedians from the U.S. Midwest are mostpolite (when compared to other census-definedregions), (ii) female Wikipedians are generallymore polite (consistent with prior studies in whichwomen are more polite in a variety of domains;(Herring, 1994)), and (iii) programming languagecommunities on Stack Exchange vary significantlyby politeness (Table 8; full disclosure: our analy-ses were conducted in Python).6 Related workPoliteness has been a central concern of modernpragmatic theory since its inception (Grice, 1975;Lakoff, 1973; Lakoff, 1977; Leech, 1983; Brownand Levinson, 1978), because it is a source ofpragmatic enrichment, social meaning, and cul-tural variation (Harada, 1976; Matsumoto, 1988;12However, due to the limited size of the human-labeleddata, we could not control for the role of the user in the StackExchange reputation experiment.PL name Politeness Top quartilePython 0.47*** 23%Perl 0.49 24%PHP 0.51 24%Javascript 0.53** 26%**Ruby 0.59*** 28%*Table 8: Politeness of requests from different lan-guage communities on Stack Exchange.Ide, 1989; Blum-Kulka and Kasper, 1990; Blum-Kulka, 2003; Watts, 2003; Byon, 2006).
The start-ing point for most research is the theory of Brownand Levinson (1987).
Aspects of this theoryhave been explored from game-theoretic perspec-tives (Van Rooy, 2003) and implemented in lan-guage generation systems for interactive narratives(Walker et al, 1997), cooking instructions, (Guptaet al, 2007), translation (Faruqui and Pado, 2012),spoken dialog (Wang et al, 2012), and subjectivityanalysis (Abdul-Mageed and Diab, 2012), amongothers.In recent years, politeness has been studied inonline settings.
Researchers have identified vari-ation in politeness marking across different con-texts and media types (Herring, 1994; Brennanand Ohaeri, 1999; Duthler, 2006) and betweendifferent social groups (Burke and Kraut, 2008a).The present paper pursues similar goals using or-ders of magnitude more data, which facilitates afuller survey of different politeness strategies.Politeness marking is one aspect of the broaderissue of how language relates to power and status,which has been studied in the context of workplacediscourse (Bramsen et al, ; Diehl et al, 2007;Peterson et al, 2011; Prabhakaran et al, 2012;Gilbert, 2012; McCallum et al, 2007) and so-cial networking (Scholand et al, 2010).
However,this research focusses on domain-specific textualcues, whereas the present work seeks to lever-age domain-independent politeness cues, build-ing on the literature on how politeness affectsworksplace social dynamics and power structures(Gyasi Obeng, 1997; Chilton, 1990; Anderssonand Pearson, 1999; Rogers and Lee-Wong, 2003;Holmes and Stubbe, 2005).
Burke and Kraut(2008b) study the question of how and why spe-cific individuals rise to administrative positionson Wikipedia, and Danescu-Niculescu-Mizil et al(2012) show that power differences on Wikipedia257are revealed through aspects of linguistic accom-modation.
The present paper complements thiswork by revealing the role of politeness in socialoutcomes and power relations.7 ConclusionWe construct and release a large collection ofpoliteness-annotated requests and use it to evalu-ate key aspects of politeness theory.
We build apoliteness classifier that achieves near-human per-formance and use it to explore the relation betweenpoliteness and social factors such as power, status,gender, and community membership.
We hope thepublicly available collection of annotated requestsenables further study of politeness and its relationto social factors, as this paper has only begun toexplore this area.AcknowledgmentsWe thank Jean Wu for running the AMT an-notation task, and all the participating turkers.We thank Diana Minculescu and the anonymousreviewers for their helpful comments.
Thiswork was supported in part by NSF IIS-1016909,CNS-1010921, IIS-1149837, IIS-1159679, AROMURI, DARPA SMISC, Okawa Foundation, Do-como, Boeing, Allyes, Volkswagen, Intel, AlfredP.
Sloan Fellowship, the Microsoft Faculty Fel-lowship, the Gordon and Dailey Pattee FacultyFellowship, and the Center for Advanced Study inthe Behavioral Sciences at Stanford.ReferencesMuhammad Abdul-Mageed and Mona Diab.
2012.AWATIF: A multi-genre corpus for Modern Stan-dard Arabic subjectivity and sentiment analysis.
InProceedings of LREC, pages 3907?3914.Ashton Anderson, Daniel Huttenlocher, Jon Kleinberg,and Jure Leskovec.
2012.
Effects of user similarityin social media.
In Proceedings of WSDM, pages703?712.Lynne M. Andersson and Christine M. Pearson.
1999.Tit for tat?
the spiraling effect of incivility in theworkplace.
The Academy of Management Review,24(3):452?471.Shoshana Blum-Kulka and Gabriele Kasper.
1990.Special issue on politeness.
Journal of Pragmatics,144(2).Shoshana Blum-Kulka.
2003.
Indirectness and po-liteness in requests: Same or different?
Journal ofPragmatics, 11(2):131?146.Philip Bramsen, Martha Escobar-Molana, Ami Patel,and Rafael Alonso.
Extracting social power rela-tionships from natural language.
In Proceedings ofACL, pages 773?782.Susan E Brennan and Justina O Ohaeri.
1999.
Whydo electronic conversations seem less polite?
thecosts and benefits of hedging.
SIGSOFT Softw.
Eng.Notes, 24(2):227?235.Penelope Brown and Stephen C. Levinson.
1978.Universals in language use: Politeness phenomena.In Esther N. Goody, editor, Questions and Polite-ness: Strategies in Social Interaction, pages 56?311,Cambridge.
Cambridge University Press.Penelope Brown and Stephen C Levinson.
1987.
Po-liteness: some universals in language usage.
Cam-bridge University Press.Moira Burke and Robert Kraut.
2008a.
Mind yourPs and Qs: the impact of politeness and rudenessin online communities.
In Proceedings of CSCW,pages 281?284.Moira Burke and Robert Kraut.
2008b.
Taking up themop: identifying future wikipedia administrators.
InCHI ?08 extended abstracts on Human factors incomputing systems, pages 3441?3446.Andrew Sangpil Byon.
2006.
The role of linguistic in-directness and honorifics in achieving linguistic po-liteness in Korean requests.
Journal of PolitenessResearch, 2(2):247?276.Paul Chilton.
1990.
Politeness, politics, and diplo-macy.
Discourse and Society, 1(2):201?224.Herbert H. Clark and Dale H. Schunk.
1980.
Politeresponses to polite requests.
Cognition, 8(1):111?143.Cristian Danescu-Niculescu-Mizil, Lillian Lee,Bo Pang, and Jon Kleinberg.
2012.
Echoes ofpower: Language effects and power differences insocial interaction.
In Proceedings of WWW, pages699?708.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of LREC, pages 449?454.Christopher P. Diehl, Galileo Namata, and Lise Getoor.2007.
Relationship identification for social networkdiscovery.
In Proceedings of the AAAI Workshop onEnhanced Messaging, pages 546?552.Kirk W Duthler.
2006.
The Politeness of RequestsMade Via Email and Voicemail: Support for the Hy-perpersonal Model.
Journal of Computer-MediatedCommunication, 11(2):500?521.Manaal Faruqui and Sebastian Pado.
2012.
Towards amodel of formal and informal address in english.
InProceedings of EACL, pages 623?633.258Elen P. Francik and Herbert H. Clark.
1985.
How tomake requests that overcome obstacles to compli-ance.
Journal of Memory and Language, 24:560?568.Eric Gilbert.
2012.
Phrases that signal workplace hier-archy.
In Proceedings of CSCW, pages 1037?1046.H.
Paul Grice.
1975.
Logic and conversation.
In Pe-ter Cole and Jerry Morgan, editors, Syntax and Se-mantics, volume 3: Speech Acts, pages 43?58.
Aca-demic Press, New York.S Gupta, M Walker, and D Romano.
2007.
How rudeare you?
: Evaluating politeness and affect in inter-action.
Affective Computing and Intelligent Interac-tion, pages 203?217.Samuel Gyasi Obeng.
1997.
Language and politics:Indirectness in political discourse.
Discourse andSociety, 8(1):49?83.S.
I. Harada.
1976.
Honorifics.
In MasayoshiShibatani, editor, Syntax and Semantics, volume5: Japanese Generative Grammar, pages 499?561.Academic Press, New York.Susan Herring.
1994.
Politeness in computer cul-ture: Why women thank and men flame.
In Cul-tural performances: Proceedings of the third Berke-ley women and language conference, volume 278,page 94.Janet Holmes and Maria Stubbe.
2005.
Power and Po-liteness in the Workplace: A Sociolinguistic Analysisof Talk at Work.
Longman, London.Ken Hyland.
2005.
Metadiscourse: Exploring Interac-tion in Writing.
Continuum, London and New York.Sachiko Ide.
1989.
Formal forms and discernment:Two neglected aspects of universals of linguistic po-liteness.
Multilingua, 8(2?3):223?248.David Kaplan.
1999.
What is meaning?
Explorationsin the theory of Meaning as Use.
Brief version ?draft 1.
Ms., UCLA.Robin Lakoff.
1973.
The logic of politeness; or, mid-ing your P?s and Q?s.
In Proceedings of the 9thMeeting of the Chicago Linguistic Society, pages292?305.Robin Lakoff.
1977.
What you can do with words:Politeness, pragmatics and performatives.
In Pro-ceedings of the Texas Conference on Performatives,Presuppositions and Implicatures, pages 79?106.Geoffrey N. Leech.
1983.
Principles of Pragmatics.Longman, London and New York.Jure Leskovec, Daniel Huttenlocher, and Jon Klein-berg.
2010.
Governance in Social Media: A casestudy of the Wikipedia promotion process.
In Pro-ceedings of ICWSM, pages 98?105.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion Observer: analyzing and comparing opin-ions on the Web.
In Proceedings of WWW, pages342?351.Yoshiko Matsumoto.
1988.
Reexamination of the uni-versality of face: Politeness phenomena in Japanese.Journal of Pragmatics, 12(4):403?426.Andrew McCallum, Xuerui Wang, and Andr?esCorrada-Emmanuel.
2007.
Topic and role discoveryin social networks with experiments on Enron andacademic email.
Journal of Artificial IntelligenceResearch, 30(1):249?272.Robert Munro, Steven Bethard, Victor Kuperman,Vicky Tzuyin Lai, Robin Melnick, ChristopherPotts, Tyler Schnoebelen, and Harry Tily.
2010.Crowdsourcing and language studies: the new gen-eration of linguistic data.
In Proceedings of theNAACL HLT 2010 Workshop on Creating Speechand Language Data with Amazon?s MechanicalTurk, pages 122?130.Kelly Peterson, Matt Hohensee, and Fei Xia.
2011.Email formality in the workplace: A case study onthe enron corpus.
In Proceedings of the ACL Work-shop on Language in Social Media, pages 86?95.Vinodkumar Prabhakaran, Owen Rambow, and MonaDiab.
2012.
Predicting Overt Display of Power inWritten Dialogs.
In Proceedings of NAACL-HLT,pages 518?522.Priscilla S. Rogers and Song Mei Lee-Wong.
2003.Reconceptualizing politeness to accommodate dy-namic tensions in subordinate-to-superior reporting.Journal of Business and Technical Communication,17(4):379?412.Andrew J. Scholand, Yla R. Tausczik, and James W.Pennebaker.
2010.
Social language network analy-sis.
In Proceedings of CSCW, pages 23?26.Robert Van Rooy.
2003.
Being polite is a handicap:Towards a game theoretical analysis of polite lin-guistic behavior.
In Proceedings of TARK, pages45?58.Marilyn A Walker, Janet E Cahn, and Stephen J Whit-taker.
1997.
Improvising linguistic style: social andaffective bases for agent personality.
In Proceedingsof AGENTS, pages 96?105.William Yang Wang, Samantha Finkelstein, AmyOgan, Alan W. Black, and Justine Cassell.
2012.?love ya, jerkface?
: Using sparse log-linear mod-els to build positive and impolite relationships withteens.
In Proceedings of SIGDIAL, pages 20?29.Richard J. Watts.
2003.
Politeness.
Cambridge Uni-versity Press, Cambridge.Ian H Witten and Eibe Frank.
2005.
Data Mining:Practical machine learning tools and techniques.Morgan Kaufmann.259
