Proceedings of the Workshop on Distributional Semantics and Compositionality (DiSCo?2011), pages 33?37,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsIdentifying Collocations to Measure Compositionality :Shared Task System DescriptionTed PedersenDepartment of Computer ScienceUniversity of MinnesotaDuluth, MN 55812 USAtpederse@d.umn.eduAbstractThis paper describes three systems from theUniversity of Minnesota, Duluth that partici-pated in the DiSCo 2011 shared task that eval-uated distributional methods of measuring se-mantic compositionality.
All three systemsapproached this as a problem of collocationidentification, where strong collocates are as-sumed to be minimally compositional.
duluth-1 relies on the t-score, whereas duluth-2 andduluth-3 rely on Pointwise Mutual Informa-tion (pmi).
duluth-1 was the top ranked sys-tem overall in coarse?grained scoring, whichwas a 3-way category assignment where pairswere assigned values of high, medium, or lowcompositionality.1 IntroductionAn ngram or phrase that means more than the sumof its parts is said to be non-compositional.
Wellknown examples include kick the bucket (i.e., to die)and red tape (i.e., bureaucratic steps).
The abilityto measure the degree of semantic compositionalityin a unit of text is a key capability of NLP systems,since non-compositional phrases can be treated asa single unit, rather than as a series of individualwords.
This has a tremendous impact on word sensedisambiguation systems, for example, since a non-compositional phrase will often have just one pos-sible sense and thereby be reduced to a trivial case,whereas the combination of possible sense assign-ments for the words that make up a phrase can growexponentially.Identifying collocations is another key capabilityof NLP systems.
Collocations are generally consid-ered to be units of text that occur with some regular-ity and may have some non-compositional meaning.The Duluth systems that participated in the DiSCo2011 shared task (Biemann and Giesbrecht, 2011)seek to determine the degree to which collocationidentification techniques can be used to measure se-mantic compositionality.
In particular, these systemsare based on the following hypothesis:An ngram that has a high score accord-ing to a measure of association (for iden-tifying collocations) will be less composi-tional (and less literal) than those that havelower scores.The intuition underlying this hypothesis is a highscore from a measure of association shows that thewords in the ngram are occurring together more of-ten than would be expected by chance, and thata non-compositional phrase is unlikely to occur insuch a way that it looks like a chance event.2 System DevelopmentThe Duluth systems were developed by identify-ing collocations based on frequency counts obtainedfrom the WaCky English corpus (Baroni et al,2009), hereafter referred to as the corpus.
The partof speech tags were removed from the corpus, andthe text was converted to lower case.
A set of 139training pairs was provided by the task organizersthat had been manually rated for compositionality.This gold standard data was used to select whichmeasures of association would form the basis of theDuluth systems.
Thereafter a separate set of 174 testpairs were provided by the organizers for evaluation.332.1 Collocation DiscoveryThe Ngram Statistics Package (Text::NSP) (Baner-jee and Pedersen, 2003) was used to measure theassociation between the training pairs based on fre-quency count data collected from the corpus.
Allthirteen measures in the Ngram Statistics Packagewere employed, including the Log-likelihood Ra-tio (ll) (Dunning, 1993), Pointwise Mutual Informa-tion (pmi) (Church and Hanks, 1990), Mutual Infor-mation (tmi) (Church and Hanks, 1990), Poisson-Stirling (ps) (Church, 2000), Fisher?s Exact Test(leftFisher, rightFisher, and twotailed) (Pedersen etal., 1996), Jaccard Coefficient (jaccard), Dice Coef-ficient (dice), Phi Coefficient (phi), t-score (tscore)(Church and Hanks, 1990), Pearson?s Chi-SquaredTest (x2), and the Odds Ratio (odds).These measure the co-occurrence of word pairs(bigrams) relative to their individual frequencies andassess how likely it is that the word pair is occurringtogether by chance (and is therefore likely composi-tional) or has some significant pattern of occurrenceas a pair (in which case it is non-compositional).More formally, many of these methods comparethe observed empirical data with a model that caststhe words in the bigram as independent statisticalevents.
The measures determine the degree to whichthe observed data deviates from what would be ex-pected under the model of independence.
If the ob-served data differs significantly from that, then thereis no evidence to support the hypothesis that the bi-gram is a chance event, and we assume that there issome interesting or significant pattern that impliesnon-compositionality.
In some cases the trainingand test pairs are not adjacent (e.g., reinvent wheelfor reinvent the wheel), and so window sizes of 2, 4,and 10 words were used when measuring the asso-ciation between pairs of words.
This means that 0, 2and 8 intervening words were allowed, respectively.Frequency count data for the word pairs are tabu-lated as shown in the example in Figure 1.
The vari-able W1 represents the presence or absence of redin the first position of each word pair, and W2 rep-resents the presence or absence of tape in the sec-ond position.
This table tells us, for example, thatred tape occurs 5,363 times (n11), that red occurs18,493 times (n1+), and that bigrams that containneither red nor tape occur 68,824,813 times (n22).The total number of bigrams found in the corpus is68,845,263 (n++).
Note that these counts are basedon a window size of 2.
Counts increase with a largerwindow size.
If the window size were 10, then n11would tell us how many times red and tape occurredwithin 8 words of each other (in order).W1W2tape ?tape totalsn11= n12= n1+=red 5,363 13,130 18,493n21= n22= n2+=?red 1,957 68,824,813 68,826,770n+1= n+2= n++=totals 7,320 68,837,943 68,845,263Figure 1: Contingency Table Counts2.2 Scoring Word PairsThe training pairs were ranked according to each ofthe measures in Text::NSP, where high scores in-dicate that two words (w1 and w2) are not occur-ring together by chance, and that there is a non-compositional meaning.
However, high scores in theshared task meant exactly the opposite; that a wordpair was highly compositional (and literal).
In addi-tion, the fine grained scoring in the shared task wason a scale of 0 to 100, and it was required that partic-ipating systems use that same scale.
Thus, the scoresfrom the measures were converted to this scale asfollows:Let the maximum value of the Text::NSP mea-sure for all the pairs in the set under consideration bemax(m(W1, W2)), where m represents the specificmeasure being used.
Then the score for each wordpair is normalized by dividing it by this maximumvalue, and subtracted from 1 and then multiplied by100.
More generally, the fine grained score for anyword pair (w1, w2) as computed by a specific duluth-x system is dx(w1, w2) and is calculated as follows:dx(w1, w2) = 100 ?
(1?m(w1, w2)max(m(W1, W2))) (1)Coarse grained scoring is automatically per-formed by binning all of the resulting scores in therange 0-33 to low, 34 - 66 to medium and 67 - 100to high.34Table 1: Text::NSP Rank Correlation with Gold Standard- duluth-1 corresponds to t-score window 10, duluth-2with pmi window 10 and duluth-3 with pmi window 2Window SizeMeasure 2 4 10tscore 0.1484 0.2114 0.2674tmi 0.1335 0.1908 0.2361ll 0.1336 0.1913 0.2358frequency 0.1865 0.2100 0.2126ps 0.0992 0.1554 0.1874x2 0.1157 0.1172 0.1654phi 0.1157 0.1167 0.1646jaccard 0.1253 0.1255 0.1602dice 0.1253 0.1255 0.1602odds 0.0216 0.0060 0.0257pmi -0.0241 -0.0145 0.0143rightFisher -0.1768 -0.0817 0.0740leftFisher 0.1316 0.0686 -0.0870twotailed -0.1445 -0.0651 -0.10642.3 Correlation of Word PairsBefore the evaluation period, it was decided thatduluth-1 (our flagship system) would be based on themeasure of association that had the highest Spear-man?s rank correlation with the fine grained goldstandard annotations of the training pairs.
As canbe seen from Table 1, that measure was the t-scorebased on a window size of 10.As an additional experiment, the ranking ofthe training pairs according to each measure inText::NSP was compared to the frequency rankingin the corpus.
As can be seen in Table 2, once againit was the t-score that had the highest correlation.While the correlation with the training pairs bythe t-score was encouraging, the correlation withfrequency was something of a surprise, and in factcaused some concern.
Could a measure that corre-lated so highly with frequency really be successfulin measuring semantic compositionality?
However,upon reflection it seemed that correlation with fre-quency might be quite desirable, and led to the for-mulation of a second hypothesis:Very frequent word pairs are more likelyto be compositional (i.e., highly literal)than are less frequent word pairs.Table 2: Text::NSP Rank Correlation with Frequency -duluth-1 corresponds to t-score window 10, duluth-2 withpmi window 10 and duluth-3 with pmi window 2Window SizeMeasure 2 4 10tscore 0.9857 0.9578 0.8477ps 0.8856 0.8423 0.8299ll 0.9082 0.8459 0.6953tmi 0.9080 0.8459 0.6951jaccard 0.7170 0.6128 0.5527dice 0.7170 0.6128 0.5527phi 0.7038 0.5743 0.4308x2 0.7039 0.5744 0.4303rightFisher -0.5998 -0.3279 0.2004odds 0.3714 0.1483 -0.0353pmi 0.2487 0.0789 -0.1390leftFisher 0.5675 0.3500 -0.1726twotailed -0.5965 -0.4434 -0.2712The assumption that underlies this hypothesis is thatthe most frequent word pairs tend to be very literaland non-compositional (e.g., for the, in that) and itwould (in general) be a surprise to expect a compo-sitional pair (e.g., above board, rip saw) to attain ashigh a frequency.3 duluth-1 (t-score in a 10 word window)The duluth-1 system is based on the t-score in a 10word window, and was selected because of its highcorrelation to the gold standard annotations of thetraining pairs and to the frequency ranking of thetraining pairs.
The t-score optimizes both of ourprevious hypotheses, which suggests it should be agood choice for measuring compositionality.By way of background, the t-score (t) is formu-lated as follows (Church et al, 1991), using the no-tation introduced in Figure 1 :t = n11 ?m11?n11(2)where n11 is the observed count of the word pair,and m11 is the expected value based on the hypothe-sized model of independence between variables W1and W2.
As such,m11 =n1+ ?
n+1n++(3)35If there is little difference between the observedand expected values, then the t-score is closer to zero(or even less than zero) and the pair of words can bejudged to occur together simply by chance (i.e., thehypothesis of independence is true).The t-scores for the test pairs were converted fol-lowing equation (1), and then submitted for evalu-ation.
duluth-1 placed in the middle ranks in thefine grain evaluation according to mean distance,and was the top ranked system according to the labelprecision evaluation of coarse grained scoring.4 duluth-2 (pmi with window size of 10)In studying Tables 1 and 2, it?s clear that Point-wise Mutual Information (pmi) deviates rather sig-nificantly from frequency and the t-score.
At thetime of the evaluation, we did not know if our hy-potheses that motivated the use of the t-score wouldprove to be true.
If they did not, it seemed sensible toinclude the most opposite measure to the t-score, asa kind of fail safe mechanism for our systems over-all.
In addition, pmi has a fairly significant history ofuse in identifying collocations and features for otherNLP tasks (e.g., (Pantel and Lin, 2002)), and so itseemed like a credible candidate.pmi has a well known bias towards identifyingwords that only occur together, and tends to preferless frequent word pairs, and this is why it divergesso significantly from the t-score and frequency.
In-terestingly, pmi is also based on the same observedand expected values n11 and m11 as used in the t-score (and many of the other measures), and is cal-culated as follows:pmi = log n11m11(4)If there is little difference between the observedand expected values, then pmi tends towards 0 andwe treat the word pairs as independent and compo-sitional.duluth-2 relies on a window size of 10, since it di-verges dramatically from the t-score and frequency.5 duluth-3 (pmi with window size of 2)duluth-3 is a very close relative of duluth-2, and dif-fers only in that it requires word pairs to be adjacent.Given the wider window sizes in duluth-2, it is clearthat if a pair has a high pmi score, they must only oc-cur (mostly) together.
duluth-3 only considers adja-cent words, and so the words that make up the pairsmay also appear elsewhere in the corpus.
As suchduluth-3 may tend to assign higher pmi scores thanthe more exacting duluth-2 (where high scores meanlow compositionality).
And in fact this is what oc-curred.
In the coarse scoring scheme, duluth-1 onlyidentified 2 low compositional word pairs, whereasduluth-2 identified 46 and duluth-3 identified 70.Despite the difference in the window size the rankcorrelation between duluth-2 and duluth-3 is rela-tively high (.9330).
Both performed comparably inthe evaluation, being near the bottom of both thefine and coarse grained evaluations.
By comparison,duluth-1 and duluth-2 have a relatively low rank cor-relation of .1756, and duluth-1 and duluth-3 have amodest correlation of .3438.6 ConclusionsThe Duluth systems seek to evaluate the degree towhich measures of collocation are able to measuresemantic compositionality as well.
The results ofthis shared task suggest that the t-score is well suitedto make coarse grained distinctions between high,medium, and low levels of compositionality, sinceduluth-1 was the top ranked system in the coarsegrained evaluation.
While this success might beconsidered surprising due to the simplicity of theapproach, it should not be underestimated.
Thereare two separate hypotheses that underly the t-scoreand its use in measuring semantic compositionality.These hold that word pairs with high measures of as-sociation are more likely to be non?compositional,and that more frequent word pairs are more likely tobe compositional.
Of the measures evaluated in thisstudy, the t-score was best able to optimize both ofthese conditions.7 AcknowledgementsThe experiments in this paper were conductedwith version 1.23 of the Ngram Statistics Pack-age (Text::NSP), which is implemented in Perl andfreely available from http://ngram.sourceforge.net.36ReferencesS.
Banerjee and T. Pedersen.
2003.
The design, imple-mentation, and use of the Ngram Statistics Package.In Proceedings of the Fourth International Conferenceon Intelligent Text Processing and Computational Lin-guistics, pages 370?381, Mexico City, February.M.
Baroni, S. Bernardini, A. Ferraresi, and E. Zanchetta.2009.
The WaCky wide web: A collection of verylarge linguistically processed web-crawled corpora.Language Resources and Evaluation, 43(3):209?226.C.
Biemann and E. Giesbrecht.
2011.
Distributionalsemantics and compositionality 2011: Shared taskdescription and results.
In Proceedings of DiSCo?2011 in conjunction ACL HLT 2011, Portland, Oregon,June.
Association for Computational Linguistics.K.
Church and P. Hanks.
1990.
Word association norms,mutual information and lexicography.
In Proceed-ings of the 28th Annual Meeting of the Association forComputational Linguistics, pages 76?83.K.
Church, W. Gale, P. Hanks, and D. Hindle.
1991.
Us-ing statistics in lexical analysis.
In U. Zernik, editor,Lexical Acquisition: Exploiting On-Line Resources toBuild a Lexicon.
Lawrence Erlbaum Associates, Hills-dale, NJ.K.
Church.
2000.
Empirical estimates of adaptation:The chance of two noriegas is closer to p/2 than p2.In Proceedings of the 18th International Conferenceon Computational Linguistics (COLING-2000), pages180?186, Saarbru?cken, Germany.T.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Computational Linguistics,19(1):61?74.P.
Pantel and D. Lin.
2002.
Discovering word sensesfrom text.
In Proceedings of ACM SIGKDD Confer-ence on Knowledge Discovery and Data Mining-2002.T.
Pedersen, M. Kayaalp, and R. Bruce.
1996.
Signifi-cant lexical relationships.
In Proceedings of the Thir-teenth National Conference on Artificial Intelligence,pages 455?460, Portland, OR, August.37
