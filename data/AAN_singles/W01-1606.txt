An Empirical Study of Speech Recognition Errorsin a Task-oriented Dialogue SystemMarc CAVAZZASchool of Computing and Mathematics,University of Teeside,TS1 3BA, Middlesbrough, United Kingdom,m.o.cavazza@tees.ac.ukAbstractThe development of spoken dialoguesystems is often limited by the performanceof their speech recognition component.
Theimpact of speech recognition errors ondialogue systems is often studied at theglobal level of task completion.
In thispaper, we carry an empirical study on theconsequences of speech recognition errorson a fully-implemented dialogue prototype,based on a speech acts formalisms.
Wereport the impact of speech recognitionerrors on speech act identification anddiscuss how standard control mechanismscan participate to robustness by assisting theuser in repairing the consequences of speechrecognition errors.IntroductionThe development of spoken dialogue systems isfaced with limitations in speech recognitiontechnologies that make recognition errors arecurring problem for any dialogue system.Several studies have shown little correlationbetween speech recognition scores and usersatisfaction, or the ability to complete the tasksunderlying spoken dialogue [Yankelovich et al,1995] [Dybkjaer et al, 1997], suggesting that acertain level of errors should not prevent spokendialogue systems from being successful.However, most of the studies on speechrecognition errors have concentrated either onparsing incomplete utterances or on globaldialogue robustness, i.e.
at task completion level[Allen et al, 1996] [Stromback and Jonsson,1998] [Brandt-Pook et al, 1996].In this paper, we investigate the impact ofspeech recognition errors on a fully-implemented prototype for a task-orienteddialogue system.
This system supports aconversational character for InteractiveTelevision and is based on a speech actsformalism.
We report a first empirical study onthe consequences of speech recognition errorson the identification of speech acts, and theconditions under which the system can be robustto those errors.1 System OverviewThe VIP (?Virtual Interactive Presenter?)
systemis a dialogue-based interface to an ElectronicProgramme Guide (EPG).
One main advantageof human-computer dialogue is that it breaksdown the information exchange into elementaryunits that correspond to the actual criteria on thebasis of which TV programmes are selected, i.e.individual features such as the cast, the moviegenre, its rating, etc.
It assists the user inprogressively refining the programmedescription without requiring explicit knowledgeof the editorial categories used to index the EPG.Figure 1.
The System Interface.Related applications, i.e.
dialogue systemsinvolving the choice of a film or TV programmehave been also described in [Hagen, 2000][Ludwig et al, 2000].
Our system is a mixed-initiative conversational interface organisedaround a human-like character with which theuser communicates through speech recognition[Nagao and Takeuchi, 1994] [Beskow andMcGlashan, 1997].
The interface is based on theMicrosoft Agent?
system with a set ofanimated bitmaps acquired from a real humansubject (Figure 1).An example dialogue illustrating the systemcapabilities is presented below (this example hasbeen obtained with keyboard input only).
Aftergreetings by the system, the user opens thedialogue with a first request (U1).
Even thoughthe system?s goal is to refine the selection, itoffers potential choices even at early stages ofthe dialogue, e.g.
after only the programmegenre has been specified (S2).
As the dialogueprogresses, it gives a count of programmesmatching the current criteria and proposes thebest one.
The system acknowledges the mostspecific selections only (S10, S14).
Also, thesystem takes initiative whenever necessary(S12).
It repairs non-productive dialogue, i.e.when several utterances have not altered theprogramme description (?is this programme allright, then??).
Whenever high-level categoriesare rejected by the user, leaaving the systemwithout sufficient criteria to filter the EPGcontents, it re-starts the dialogue (?what wouldyou like then?
?, S12).U1: Do you have any sports programmesS2: I have found 5 programmes for this choice.Would you like to watch ?Keegan?s greatestgames?
?U3: Can I have some cricket instead?S4: I can suggest this programme with cricket:?Sportstalk?U5: Who?s conducting?S6: ?Sportstalk?
features DonaldU7: Anything else?S8: I have no other programmes for thatselectionU9: Is there anything funny, then?S10: I can recommend the following comedy:?Starting Out?U11: I do not want a sitcomS12: What would you like to see, then?U13: A funny movieS14: I would suggest this programme withcomedy: ?Analyze This?U15: Can I have another one?S16 There are 1 other programmes for thischoice.
What about the following programme:?Casablanca?
?U17: I want a western insteadS18: I would suggest the following western:?Unforgiven?The software architecture is a pipelinecomprising speech recognition, parsing anddialogue.
In the next sections, we describe eachof these components from the perspective ofspeech recognition errors.
Finally, we discussthe impact of speech recognition errors onexample dialogues and the mechanisms thatcontribute to dialogue robustness.Figure 2.
The ABBOT Interface.2 The Speech Recognition ComponentSpeech recognition is based on the ABBOTsystem [Robinson et al, 1996].
A specificABBOT version has been developed for the VIPprototype, VIP-ABBOT, with a test vocabularyof 300+ words (Figure 2).
This version is basedon a trigram model, trained on a small corpus of200 user questions and replies, using data fromsix speakers (average recording time is twelveminutes).
Though the size of the corpus is inprinciple too small to obtain an accuratelanguage model, the VIP-ABBOT systemachieves a satisfactory performance.
Globalspeech recognition accuracy has been tested aspart of the development of the VIP-ABBOTversion.
The recognition accuracy varied acrosstests from 65 to a maximum 80 % (at this stageonly laboratory conditions with non-noisyenvironments and good quality microphoneshave been considered).
The system outputs the1-best recognised utterance, which is passed tothe dialogue system via a datagram socket.We have assembled an evaluation corpus of 500utterances, collected from five speakersincluding one non-native speaker.
Including anon-native speaker was an empirical way ofincreasing the error rate.
Other researchers havesuggested varying parameters of the speechrecognition system, such as the beam width[Boros et al, 1996], as a method to increaseword error rate, in order to collect error corpora.However, they have not documented whether thekind of errors induced in this way actuallyreproduce (in terms of distribution) thoseobtained during the actual use of the system.
Onthe other hand, recognition errors obtained withnative and non-native speakers appear similar inour experience, the overall error rate just beinghigher in the latter.For the whole corpus, approximately 50% ofrecognised utterances contain at least one speechrecognition error.3 Integrated Parsing of User UtterancesStrictly speaking, a significant proportion(around 50%) of the recognition hypothesesproduced by VIP-ABBOT are ungrammatical.For obvious reasons, and since the early stagesof system development, we have abandoned theidea of producing a complete parse for thespeech input, not so much because userexpressions themselves could be ungrammaticalbut rather because recognised utterances weremost certain to be, considering the error rate.One of the key questions for parsing, especiallyin the case of dialogue, where the averageutterance length is 5-7 words, is whethercomplete parsing is at all necessary [Lewin etal., 1999].
We have implemented a simplifiedparser based on a variant of Tree-AdjoiningGrammars [Cavazza, 1998], This syntacticformalism being lexicalised has interestingproperties in terms of syntax-semanticsintegration.
This lexicalised formalism,combined with a simple bottom-up parser, iswell adapted to the partial parsing ofungrammatical utterances (Figure 3).The main goal of parsing is to produce asemantic structure from which speech acts canbe identified.
Semantic features are aggregatedas the parsing progresses following the syntacticoperations.
As a result, the parser produces afeature structure whose semantic elements canbe mapped to the descriptors indexing theprogrammes in the EPG, such as genre (e.g.
?movie?, ?news?, ?documentary?
), sub-genre(e.g., ?comedy?, ?lifestyle?
), cast (e.g., ?JeremyClarkson?
), channel (?BBC one?
), rating  (e.g.,?caution?, ?family?
), etc.Whenever the parser fails to produce a singleparse, the semantic structures obtained frompartial parses are merged on a content basis.
Forinstance, descriptors such as ?cast?
or ?channel?are attached to programme descriptions, etc.This process confers a good level of robustnessand tolerance to ungrammaticality.
This kind ofapproach, where dialogue strategy is privilegedover parsing was inspired from early versions ofthe AGS system [Sadek, 1999].
These semanticstructures are used to generate search filters onthe EPG database, which correspond to semanticdescriptions of the user choice.
They are alsoused for content-based speech act identification,by comparing the semantic contents ofsuccessive utterances [Cavazza, 2000].Figure 3.
Parsing of an Utterance4 The Dialogue ProcessT e dialogue strategy has been determinedmpuaHc?
(twiWiTps[rsccSVis thereN0 ?
*N Nanything funnyNIproSVcan-?N0 ?
V0 ?VwatchS1 F2S3S4hainly from the task model.
As the task is torogressively refine a programme description bysing elementary dialogue acts, we have adoptedspeech acts based approach [Traum andinkelmann, 1992].
Each speech actorresponds to a specific construction operationit is possible to map communicative operationsrejection, implicit rejection, specification, etc.
)o the updating of the programme description,hich is a filter through which the EPG databases searched.e are using a content-based approach to thedentification of speech acts [Cavazza, 2000].his method has similarities with the onereviously described by Maier [1996].
Anotherource of inspiration was the work of Walker1996], though it was restricted to theecognition of acceptance rather than a completeet of speech acts.
Figure 4 shows theonstruction of search filters from the semanticontents of user utterances.
Once a newutterance is analysed, its semantic contents arecompared with the active search filter, which hasbeen constructed from previous user utterances,and this comparison determines speech actrecognition.
For instance, when the lastutterance contains semantic information for aprogramme sub-genre, the speech act is aspecification.
Explicit rejections are signalled bymarkers of negation, while implicit rejectionspeech acts are recognised when the semanticcontents of the latest utterance overwrite thedescriptors of the current filter (this is the casewhen, for instance, when the current filtercontains the comedy sub-genre and the user asks?can I have a western??
).In this context, speech acts provide a unified andconsistent way to determine the mostappropriate answer to the user as well as the wayin which the search filter should be updated ateach dialogue turn.
In the next section, wepropose a first empirical categorisation ofspeech recognition errors according to theirimpact on the dialogue process.5 From Speech Recognition Errors to SpeechActs Recognition ErrorsTraditional error metrics used in speechrecognition such as ?word accuracy?
are notreliable to measure the global consequences ofspeech recognition errors on the dialogueprocess.
This is why it has been proposed that a?concept accuracy?
be used in place of a wordaccuracy.
These two metrics appear however tobe linearly correlated [Boros et al, 1996].Word errors result in semantic errors, which inturn result in speech act recognition errors.
It isthe latter phenomenon that we are investigating,though through a largely empirical approach.We have developed the following experimentalapproach to assess the consequences of speechrecognition errors.
Within a set of possible ?test?dialogues, we have been running each user replyon several users to collect an error corpus.
Thenthe impact of errors at critical points of dialoguecan be tested on the system using textual input,entering the utterances comprising speechrecognition errors.
This also makes possible toexplore the consequences of a set of errors atvarious stages of the dialogue process (seebelow).In doing so, we are essentially exploring systembehaviour in a glass box approach: this does notconstitute an evaluation method for dialogueperformance [Walker et al, 1997].
The onlyglobal metric that can be used in our case isdialogue length, as a measure of the extradialogue turns required to repair theconsequences of a speech recognition error.5.1 ?Fatal?
Speech Recognition ErrorsObviously, the worst errors are those whichterminate the dialogue by selecting a programmethat the user intended to reject.
This happenswhen the semantic structure produced from themis-recognised utterance can be interpreted asan acceptance speech act.
In the following shortdialogues, the user implicitly rejects theselection offered by the system.
He does so byspecifying either the parental rating (U21) or thesub-genre (U25).
However, due to speechrecognition errors, specific semantic informationdisappears in both cases, while the insertion ofthe word ?good?
results in the system producinga semantic structure that is recognised as anacceptance speech act.U19: Can I have a movie?S20: I have found 22 programmes for thatselection.
I would recommend: ?Midnight Fear?U21: I want a movie my good can watch(REF: I want a movie my kids can watch)S22: Here is ?Midnight Fear?, then.
Goodbye!U23: Do you have any movies?S24: I found 22 programmes for your request.
Iwould suggest: ?Twelve Monkeys?U25: Good if I mean anything for long (REF:could you find me anything funny)S26: Here is ?Twelve Monkeys?, then.Goodbye!5.2 User Correction of Mis-recognitionSome speech recognition errors result in anincorrect speech act being recognised, but can beeasily corrected by the user at the expense of afew additional dialogue turns, as shown by thefollowing example (especially U31).U27: I would like to watch a movieS28: I found 22 programmes for this choice.
Ican recommend: ?The Day of the Jackal?U29: Can I have worse him?
(REF: can I havea western?
)S30: What about the following programme:?Midnight Fear?
?U31: No, I want a westernS32: I can recommend this programme which isa western: ?Unforgiven?The next dialogue illustrates an important aspectof speech recognition errors.
Their impactactually varies according to the dialogue stage atwhich they take place.
The same kind of errorthat resulted in premature acceptance has lessdramatic consequences when it occurs in theopening request.
It results in a partialunderstanding, where the EPG is searched forthe right genre (?movie?)
but without the rightparental rating.
This additional criterion can thusbe subsequently added by the user, resulting in asuccessful search at the price of a longerdialogue.U33: Is there a movie my good can watch?
(REF: is there a movie my kids can watch?
)S34: I have 22 programmes for your request.Would you like to watch: ?Midnight Fear?U35: What is its rating?S36: Its rating is cautionU37: No, I want a movie my kids can watchS38: I would recommend this programmecorresponding to that ?family?
rating: ?RioBravo?5.3 System Detection of Mis-recognitionSome dialogue control mechanisms originallydeveloped to monitor dialogue progression canalso assist in recovering from speech recognitionerrors.
The system can detect dead ends indialogue, for instance when not enoughinformation is available for programmeselection.
The speech recognition error in U39results in a semantic structure rejecting sportsprogrammes as ?boring?.
In the absence of anycategory selected, the system returns to the user(S40), who can then correct the selection: anexplicit request for the sports category over-writes its previous rejection.U39:  What kind of sports boring you have?
(REF: what kind of sports programmes do youhave)S40: What would you like to see, then?U41: A sports programmeS42: I could find 5 programmes for this choice.
Ican recommend: ?Row Z?Also, the system reacts to non-productivedialogue, i.e.
utterances that simply repeatcategories already represented in the programmedescriptors.
This has an interesting side effect, inthat it can detect deletion of negation markers, asin the example below.S43: What about the following programme:?Countryfile?U44: Again want a documentary (REF: I don?twant a documentary)S45: Is this programme all right, then?5.4 ?Semantic?
RobustnessThe basis for robustness can be seen as acombination of shallow processing and naturalredundancy of information in some of the userreplies.
For instance, in U52, even though theentry ?role?
as been deleted from the recognisedutterance, there are sufficient semantic cues toactivate a ?cast?
descriptor.U46: I would like to watch a movieS47: I found 22 programmes for this choice.
Iwould recommend: ?Midnight Fear?U48: Good if I mean anything funny (REF:could you find me anything funny)S49: I can recommend this programme which isa comedy: ?Casablanca?U50: what kind of movies do you haveS51: I have found 22 programmes for thischoice.
I would suggest: ?Twelve Monkeys?U52: Who is playing the title all?
(REF: who isplaying the title role?
)S53: ?Twelve Monkeys?
features Bruce WillisU54: Do you have any documentariesS55: I have 2 programmes for your request.
Myfirst selection is: ?Ground Force?U56: An old gardening is not a little A   (REF:no, gardening is not OK)S57: I can recommend this programme, which isnot a gardening: ?Fangs?Another element of robustness lies in the surfaceform of some linguistic expressions foracknowledgement, acceptance and rejection,which often contains redundant information:?yes, this is fine?, ?no, I don?t like that one?,?no, gardening is not OK?, etc.User:            IS THERE ANYTHING FUNNY I CAN WATCHRecognised: THE IS THERE ANYTHING FUNNY I CAN WATCHSemantics: (((QUESTION) (EXIST) (PROGRAMME ((CHOICE+))) (DET))((GOOD) (SUB_GENRE COMEDY)) ((AUDIENCE USER)) ((QUESTION))((VIEW)))Filter: ((SUB_GENRE COMEDY))Speech Act: (INITIAL (SUB_GENRE COMEDY) SEARCH)System: I found 4 programmes corresponding to that selection.
What about: ?Starting Out?
?User:              NO I DON?T WANT A SITCOMRecognised:   AN OLD I DON'T WANT A SITCOMSemantics: ((CHOICE+) (NEGATIVE) (AUDIENCE ((AUDIENCE USER)))(PROGRAMME((SUB_GENRE COMEDY) (GENRE ENTERTAINMENT) (INDET))))Filter: ((GENRE ENTERTAINMENT) (SUB_GENRE COMEDY) (NEGATIVE))Speech Act: (REJECT GENRE NIL NO_SEARCH)System: What would you like to see, then?User:            A COMEDY MOVIERecognised: A COMEDY MOVIESemantics: (((SUB_GENRE COMEDY) (INDET)) ((GENRE MOVIES)))Filter: ((GENRE MOVIES) (SUB_GENRE COMEDY))Speech Act: (SPECIFY SUB_GENRE COMEDY SEARCH)System: My first selection is this programme with comedy: ?Casablanca?User:            YES THIS IS FINERecognised: YES THE IS FIND THATSemantics: (((GOOD) (POSITIVE)) ((DET)) ((ATTRIBUTE)))Speech Act: (SIMPLE-ACCEPT)System: Here is ?Casablanca?, then.
Goodbye!Figure 4.
A Sample Dialogue with Internal Representations5.5  ?Accidental?
RobustnessAnother form of robustness appears to be ratheraccidental.
It happens when a incorrect speechact is recognised, but its effects in terms ofsystem response are a subset of those of thecorrect speech act.
In the following example, theuser intends to reject the proposal (?Salvador?
)by specifying a parental rating.
This is actuallyinterpreted as a simple rejection of theprogramme instance (Other speech act),preserving the current ?movie?
categoryselected.
The new proposal happens to match thecriteria by chance (i.e., the parental rating is notgrounded in the system reply, see e.g.
S38).U58: What movies do you have?S59: I found 22 programmes for this choice.
Ican suggest: ?Salvador?U60: Other one like is this to there it is (REF:I don?t want my kids to see this)S61: I have 21 other programmes for thatselection.
What about the following programme:?Casablanca?ConclusionWe have explored the consequences of speechrecognition errors in terms of content-basedspeech acts recognition.
There appears to be anumber of factors that support the robustness ofthe system to speech recognition errors, amongwhich the fact that dialogue control mechanismstriggered by speech act recognition cancontribute to repairing the consequences ofspeech recognition errors.
Some improvement ispossible in the treatment of errors involvingmismatches between categories andconnotations (such as ?funny motoring?
), byincluding semantic consistency checks.
On theother hand, errors involving wrongfulacceptance and dialogue termination appeardifficult to deal with.Finally, Fischer and Batliner [2000] haveinvestigated which system replies are mostlikely to upset the user.
These replies cannotalways be always avoided, though, preciselybecause they are used to repair incorrectunderstanding or inconsistent one.
It is thusimportant to investigate whether speechrecognition errors increase the occurrence ofthese upsetting replies (apart from theunavoidable and necessary repairs).
Obviously,in our context the most upsetting cases are theselection of a programme explicitly rejected bythe user.
However, It would also be necessary toexplore whether the repair mechanismsdescribed above are well accepted by the users.AcknowledgementsJames Christie at Cambridge UniversityEngineering Department developed the VIP-ABBOT version and produced some of theglobal speech recognition results.
TonyRobinson (now at Softsound Ltd) is thanked forhis assistance in using the ABBOT system.Steve Francis developed the user interface andthe character.
EPG data has been provided bythe BBC: David Kirby, Matthew Marks andAdam Hume are thanked for their support.
Thiswork has been funded in part by the DTI, underthe DTI/EPSRC ?LINK Broadcast?
Programme.ReferencesJames F. Allen, Brad Miller, Eric Ringger, andTeresa Sikorski (1996).
Robust Understanding in aDialogue System.
Proceedings of the 34th AnnualMeeting of the Association for ComputationalLinguistics, San Francisco, pp.
62-70.Jonas Beskow, and Scott McGlashan (1997).
Olga: AConversational Agent with Gestures.
In:Proceedings of the IJCAI'97 workshop onAnimated Interface Agents - Making themIntelligent, Nagoya, Japan, August 1997.Manuela Boros, W. Eckert, F. Gallwitz, G. Gorz, G.Hanrieder, and H. Niemann (1996).
TowardsUnderstanding Spontaneous Speech: WordAccuracy Vs. Concept Accuracy.
Proceedings ofthe Int.
Conf.
on Spoken Language Processing(ICSLP?96), Philadelphia, pp.
1009-1012.Hans Brandt-Pook, Gernot A. Fink, BerndHildebrandt, Franz Kummert, and Gerhard Sagerer.(1996).
A Robust Dialogue System for Making anAppointment.
Proceedings of the Int.
Conf.
onSpoken Language Processing (ICSLP?96),Philadelphia, pp.
693-696.Marc Cavazza, (1998).
An Integrated TFG Parserwith Explicit Tree Typing.
In: Proceedings of thefourth TAG+ workshop, IRCS, University ofPennsylvania, pp.
34-37.Marc Cavazza (2000).
From Speech Acts to SearchActs: a Semantic Approach to Speech ActRecognition.
Proceedings of GOTALOG 2000,Gothenburg, Sweden, pp.
187-190, June 2000.Kerstin Fischer and Anton Batliner (2000).
WhatMakes Speakers Angry in Human-ComputerConversation.
Proceedings of the Third Human-Computer Conversation Workshop (HCCW),Bellagio, Italy, pp.
62-67.Eli Hagen (2000).
A Flexible Spoken DialogueManager.
Proceedings of the Third Human-Computer Conversation Workshop (HCCW),Bellagio, Italy, pp.68-73.Ian Lewin, Ralph Becket, Johan Boye, David Carter,Manny Rayner, and Mats Wiren (1999).
Languageprocessing for spoken dialogue systems: is shallowparsing enough?
Accessing Information in SpokenAudio: Proceedings of ESCA ETRW Workshop,Cambridge, pp.
37--42.Bernard Ludwig, Martin Klarner, Heinrich Niemannand Gunther Goerz (2000).
Context and Content inDialogue Systems.
Proceedings of the ThirdHuman-Computer Conversation Workshop(HCCW), Bellagio, Italy, pp.
105-111.Elisabeth Maier (1996).
Context Construction asSubtask of Dialogue Processing: the VERBMOBILCase.
Proceedings of the Eleventh TwenteWorkshop on Language Technologies (TWLT-11),Dialogue Management in Natural LanguageSystems, University of Twente, The Netherlands,pp.
113-122.Katashi Nagao and Akikazu Takeuchi,(1994).
SpeechDialogue with Facial Displays: MultimodalHuman-Computer Conversation.
In: Proceedingsof the 32nd Annual Meeting of the Association forComputational Linguistics (ACL'94), pp.
102-109.Tony Robinson, Mike Hochberg and Steve Renals(1996).
The use of recurrent neural networks incontinuous speech recognition.
In: C. H. Lee, K. K.Paliwal and F. K. Soong (Eds.
), Automatic Speechand Speaker Recognition ?
Advanced Topics,Kluwer.Lena Stromback and Arne Jonsson.
Robustinterpretation for spoken dialogue systems.
(1998).Proceedings of ICSLP'98, Sydney, Australia.David Traum and Elisabeth A. Hinkelman (1992).Conversation Acts in Task-Oriented SpokenDialogue.
Computational Intelligence, vol.
8, n. 3.Marilyn A. Walker (1996).
Inferring Acceptance andRejection in Dialogue by Default Rules ofInference.
Language and Speech, 39-2.Marilyn A. Walker, Diane J. Litman, Candace A.Kamm and Alicia Abella (1997).
PARADISE: AFramework for Evaluating Spoken DialogueAgents.
Proceedings of the 35th Annual Meeting ofthe Association for Computational Linguistics, pp.271-280.Nicole Yankelovich, Gina-Anne Levow and MattMarx (1995).
Designing Speech Acts: Issues inSpeech User Interfaces.
Procedings of CHI'95,Denver.
