Exploiting the Student Model to Emphasize Language TeachingPedagogy in Natural Language ProcessingTrude HeiftLinguistics DepartmentSimon Fraser UniversityBurnaby, BC, Canada V5A1S6heift@sfu.caPaul McFetridgeLinguistics DepartmentSimon Fraser UniversityBurnaby, BC, Canada V5AIS6mcfet@sfu.caAbstractOne of the typical problems of NaturalLanguage Processing (NLP) is the explosiveproperty of the parser and this is aggravated inan Intelligent Language Tutoring System (ILTS)because the grammar is unconstrained andadmits even more analyses.
NLP applicationsfrequently incorporate chniques for selecting apreferred parse.
Computational criteria,however, are insufficient for a pedagogic systembecause the parse chosen will possibly result inmisleading feedback for the learner.
Preferably,the analysis emphasizes language teachingpedagogy by selecting the sentenceinterpretation a student most likely intended.
Inthe system described in this paper, severalmodules are responsible for selecting theappropriate analysis and these are informed bythe Student Model.
Aspects in the StudentModel play an important pedagogic role indetermining the desired sentence interpretation,handling multiple errors, and deciding on thelevel of interaction with the student.IntroductionOne of the fundamental problems of any NaturalLanguage Processing (NLP) system is the oftenoverwhelming number of interpretations aphrase or sentence can be assigned.
Forexample, van Noord (1997) states that the AlveyTools Grammar with 780 rules averages about100 readings per sentence on sentences rangingin length between 13 and 30 words.
The problemis not always improved with deeper analysis, forthough a semantic analysis may rule some of thepossible syntactic structures, it will introducelexical and scope ambiguity.The problem of resolving multipleinterpretations is compounded in an IntelligentLanguage Tutoring System (ILTS) because thegrammar must not only admit grammaticalstructures, but must also be able to navigate overungrammatical structures and record the errorsthat the student has made.
As a consequence, agrammar for an ILTS will not only assignstructures to a grammatical sentence, but mayalso find analyses which interpret the sentenceas ungrammatical, a set of analyses that atraditionally constrained grammar would notfind.The usual method of limiting the number ofparses that an ILTS grammar assigns is toexamine the effects of relaxing those constraintsthat represent likely sources of error by studentsand introduce new constraints into the grammarrules to block unlikely parses (Schneider &McCoy 1998).
Such techniques, however,overlook individual learner differences as a keyfactor in language teaching pedagogy.The system introduced in this paper differs fromthe traditional approach by permitting thegrammar to freely generate as many parses as itcan and using separate pedagogic principles toselect the appropriate interpretation andresponse.
The system tightly integrates theStudent Model into the process of selecting theappropriate interpretation and generating aresponse tailored to the student's level ofexpertise.
The Student Model keeps a record ofstudents' performance history which providesinformation essential to the analysis of multipleparses, multiple errors, and the level ofinteraction with the student.In the German Tutor, the ILTS described, theprocess leading to the creation of aninstructional message in the event of an error has55three stages:(1) Given a forest of parse treescreated by the grammar and parser,the parse most likely representativeof the intentions of the student mustbe selected;(2) In the cases when the parserepresenting a student's intentionscontains several errors, one of theerror must be selected as the onethat will be addressed.
This step isnecessary because mpirical studieshave found that reporting all theerrors in a sentence is pedagogicallyinappropriate.
For example, inevaluating her own system Schwind(1990) reports that "\[s\]ometimes,however, the explanations were toolong, especially when studentsaccumulated rrors.
"~;(3) Given an error, an instructionalmessage must be constructed that isappropriate to the student's level ofexpertise and background.In Section 1, the theory behind the grammar andits formalism is briefly discussed.
Section 2describes the process leading to the selection ofa particular parse and how the Student Modelparticipates in this process.
We further discussthe pedagogic role of the Student Model inhandling multiple errors and deciding on thelevel of interaction with the student.
Section 3presents conclusions and Section 4 looks atfurther esearch.1 Design of the Grammar1.1.
Grammatical  Formal ism andImplementationThe grammar for the German Tutor is written inALE (The Attributed Logic  Engine), anintegrated phrase structure parsing and definiteclause programming system in whichgrammatical information is expressed as typedfeature structures (Carpenter & Penn 1994).The grammar formalism used is derived froml Schwind \[1990a\], p. 577.Head-driven Phrase Structure Grammar (Pollard& Sag 1994).
This theory is one of a familywhich share several properties.
Linguisticinformation is presented as feature/valuematrices.
Theories in this family are to varyingdegrees lexicalist, that is, a considerable amountof grammatical information is located in thelexicon rather than in the grammar ules.
Forexample, Figure 1 illustrates a minimal lexicalentry for geht.
The subcategorization list of theverb, notated with the feature subj, specifies thatgeht takes a subject which is minimallyspecified as a singular noun.
Rules of grammarspecify how words and phrases are combinedinto larger units according to thesubcategorization list.
In addition, otherprinciples govern how information such as thehead features, which inter alia determine thegrammatical category of a constituent, isinherited.
2phon < geht >head vcat subj\[cat\[ ea n\]\[content \[~ \[index \[num sgRein geht lc?ntent \[Geher \[~ \]Figure 1 : Partial Lexical Entry for gehtUnification-based grammars place an importantrestriction on unification, namely that twocategories A and B fail to unify if they containmutually inconsistent information (Gazdar &Pullum 1985).
However, this inconsistentinformation constitutes exactly the errors madeby second language learners.
For example, if thetwo categories A and B do not agree in numbera parse will fail.
To overcome this restriction,we relax the constraint on number agreement bychanging its structure so that, rather thanchecking that the noun is singular, the systemrecords whether or not the subject of geht is inthe singular.
To achieve this, the noun is no2 Inheritance in feature-value matrices is indicated bymultiple occurrences of a coindexing box labeling thesingle value.56longer marked as \[num .sg\], but instead the pathnumlsg terminates with the values error orcorrect.
For example, for a singular noun phrase,the value of the path numlsg is correct, while itis error for a plural noun phrase.
The two pa~iallexical entries are given in Figure 2(a) andFigure 2(b), respectively.content \[index \[num \[sg c?rrect\]\]\]\]Figure 2a : Marking Number Features for SingularNouns:ontent index num pl correctFigure 2b : Marking Number Features for PluralNounsThe verb geht records the value of s g from itssubject (Figure 3).
If the value of the pathnumlsg is correct, the subject is in the singular.In case of a plural noun, geht records the valueerror for number agreement)phon < geht >head v\[cat \[head n\] \]Jlcat subj \[ ' \[\[content lindex \[num \[sg \[~\]\]descriptor \[main_clause \[vp_num \[sg ~\]\]Figure 3 : Recording Number Features for geht1.2 Phrase DescriptorsThe goal of the parser and the grammar is thegeneration of phrase descriptors, each of which3 For an analysis of errors in linear precedence, s e \[Heift98\].describes a particular grammatical constraint, itspresence or absence in the input sentence andthe student's performance on this constraint.Phrase descriptors correspond to structures inthe Student Model and are the interface mediumbetween the Student Model and other modulesin the system.A phrase descriptor is implemented asa framestructure that models a grammaticalphenomenon.
Each member of the frameconsists of a name followed by a value.
Forexample, subject-verb agreement in number ismodeled by the frame \[number, value\] wherevalue represents an as yet uninstantiated valuefor number.
If the grammatical phenomenon ispresent in the student's input, the value is eithercorrect or error depending on whether thegrammatical constraint has been met or not,respectively.
If the grammatical constraint is notpresent in the student's input, the feature valueis absent.
Consider examples (4a) and (b):(4a) *Er gehen.
(4b) Ergeht.He is leaving.The phrase descriptor for subject-verbagreement in number in example (4a) is\[number,error\], while that for the sentence in (b)is \[number,correct\].
For either sentence, (4a) or(b) ,  the information will be recorded in theStudent Model.
A system presented with (4a),however, will also instruct he learner on thenature of subject-verb agreement i  number.In addition to the grammatical features definedin HPSG the grammar uses a type descriptorrepresenting the description of the phrase thatthe parser builds up.
This type is set-valued andis initially underspecified in each lexical entry.During parsing, the values of the features ofdescriptor are specified.
For example, one of themembers of descriptor, vp num in Figure 3,records the number agreement of subject-verb ina main-clause.
Its value is inherited from the .~gfeature specified in the verb geht.
Ultimately,descriptor ecords whether the sentence isgrammatical nd what errors were made.572 The Role of the Student Model inAnalysis and FeedbackThe initial goals of the analysis of the results ofparsing a student's entence are selecting theappropriate parse and, from it, selecting the error(if there is one) that the system will focus on forinstruction.A parse of a sentence is a collection of phrasedescriptors.
For example, the phrase descriptorgiven in (5) indicates that the learner hasviolated subject-verb agreement in number in amain clause.
(5) \[main_clause \[vp_num \[sg error\]\]\]The constraint that generated this descriptor hasa correlate in the Student Model, in this case arecord labelled vp_nummaincl.
For eachgrammar constraint, the Student Model keeps acounter which, at any given instance in theevaluation process, falls in the range of one ofthe three learner levels, given in (6a) - (c).
(6a) novice: 20 _< X <_ 30(b) intermediate: 10 _< X < 20(c) expert: 0 _< X < 10Initially, the learner is assessed with the value 15for each grammar constraint, representing themean score of the intermediate l arner: Once astudent uses the system, the Student Modeladjusts the counter of each grammar constraintaccordingly.
If a grammatical constraint hasbeen met, the counter is decremented.
If theconstraint has not been met, the counter isincremented and, ultimately, a feedback messageis displayed to the learner.The result of the parsing process is a set ofcollections of phrase descriptors, each collectionrepresenting a separate parse.
The step ofwinnowing this set down to a single collection isperformed by a set of licensing conditions.2.1 Selecting the Desired ParseA sentence which is unambiguous in many otherNLP applications can nonetheless result inmultiple sentence readings in a system designed4 The intermediate learner has been chosen as a reasonabledefault.
While the messages might be initially toooverspecified for the expert and too underspecified forthenovice, they will quickly adjust to the actual learner level.tO parse ill-formed input.
For example, considera system which relaxes the constraint ongrammatical case.
Without case marking, theparser has no way of knowing if a constituent isa subject or a verb complement.
As a result,more than one sentence analysis will beproduced and the errors flagged in each sentencereading can vary.
For instance, for the sentenceSie liebt er the parser can assign at least twolegitimate syntactic structures.
The two sentencereadings are given in (7a) and (7b).
(7a) *Sie liebt er.
(7b) Sic liebt er.Sie liebt ihn.
It is her he loves.She loves him.For the sentence Sie liebt er, er could be taken tobe either the direct object or the subject of thesentence.
Assuming that the choice between thetwo parses were arbitrary, sentence structure(7a) where er is the object of the sentencecontains an error and would yield the feedbackThis is not the correct case for  the direct object.In contrast, the alternative sentence readinggiven in (7b) where er is the subject of thesentence and the direct object sie is topicalizedcontains no errors.The example illustrates two important points.First, an algorithm that selects the appropriateparse by counting the numbers of errors flaggedin each parse and selecting that which has theleast number oferrors \[as in Weischedel (1978),Covington & Weinrich (1991)\] is inadequate.
Ifthe student is at an introductory level, theappropriate analysis is the sentence readinggiven in (7a), the parse that has more errors.
5The algorithm promoted here uses instead a setof licensing conditions to mark sentences for therules that were used to parse them and select heappropriate sentence reading on the basis of thelikelihood of a grammatical construction.
Thetask of the licensing conditions in this exampleis to distinguish multiple sentence readingsconditioned by word order.
During parsing,three of the syntactic rules, the Subject-Head,the Head-Subject-Complement, and the Head-Subject rule each assign a distinct licensingdescriptor.
Any of the three licensing conditions5 Object topicalization is a rare construction and notexplicitly taught at the introductory level where the focusis on the grammar of more commonly used rules ofGerman.58can license a sentence.
After parsing, theLicensing Module prioritizes multiple sentencereadings so that, in the event of a choice, theparses are selected in a particular order.
Thechosen parse is passed on to the next module ofthe system for further processing.The second point important to the currentdiscussion is that it is not sufficient o excludeall other alternatives whenever they appear.
Anadvanced student may be practicing objecttopicalization and in that case the system shouldpreferably choose the alternative parse given in(7b).This consideration illustrates the importance ofthe Student Model to the problem of sorting outa set of parses to find the intended interpretation.To provide input to the licensing conditions, wegenerate a figure representing the student'soverall mastery of the grammar by averagingexpertise levels on each grammar constraint inthe Student Model.
A threshold of expertise isset, below which the analysis in (7a) is preferredand above which that in (7b) is chosen.After licensing, a single parsehas been selectedand a learner model update on each of thegrammatical constraints present in students'input has been extracted.
A single parse,however, can contain a number of errors and thesystem has to decide on how to communicatethese errors to the learner.
The following sectionwill discuss the task of filtering multiple errorsto select he appropriate one.2.2 Filtering Multiple ErrorsA further challenge in analyzing student input ispresented by multiple errors.
The sentence givenin (8a) illustrates an example.
(8a) *Heute die Kindern haben gespeilt mit dasAuto.
(8b) Heute haben die Kinder mit dem Autogespielt.Today the children were playing with thecar.In example (8a) the student made the followingfive errors:1. word order: the finite verb haben needsto be in second position2.
word order: the nonfinite verb gespieltneeds to be in final position3.
spelling error with the past participlegespielt?
4. wrong plural inflection for the subjectKinder5.
wrong case for the dative determinerdemFrom a pedagogical and also motivational pointof view, a system should not overwhelm astudent with instructional feedback referring tomore than one error at a time.
Little research asbeen done in Computer-Assisted LanguageLearning regarding the volume of feedback fordifferent kinds of learners at different stages intheir language development.
However, van derLinden (1993) found that "feedback, in order tobe consulted, has to be concise and precise.Long feedback (exceeding three lines) is notread and for that reason not useful.
''6 She furtherstates that displaying more than one feedbackresponse at a time makes the correction processtoo complex for the student.
The task for anIntelligent Language Tutor is to develop an errorfiltering mechanism that incorporates languageteaching pedagogy.
The sheer amount offeedback should not overwhelm the student.
Inaddition, if feedback messages are displayed oneat a time they need to be ordered in apedagogically sound way.To filter the possible errors, an Error PriorityQueue is implemented.
This queue takes studenterrors and selects the most important error.Criteria for selection can be set by the languageinstructor based on her knowledge of thedifficulty of a grammatical construction, thelikelihood of an error and/or the focus of theexercise.However, the Student Model can also beinvoked to rank errors.
One criterion for rankingis the students' performance history as indicatedby the Student Model: the grammar constraintmost  often violated will be reported first.
Therationale for this criterion is that thisgrammatical property has been mastered theleast and therefore needs the most attention.After student errors have been ranked and themost important one has been selected, thesystem needs to generate instructional feedbackmessages to be displayed to the learner.
This is6 Van der Linden \[1993\], p. 65.59achieved by an Analysis Module which will bediscussed in the following section.2.3 Generating Instructional FeedbackA further difficulty in ILTSs lies in framinginstructional feedback to student input.
In atypical student-teacher interaction, feedbackdepends on the students' previous performancehistory.
Inexperienced students require detailedinstruction while experienced students benefitbest from higher level reminders andexplanations (LaReau & Vockell 1989).For instance, in example (9a) the student madean error with the determiner einen of theprepositional phrase.
Von is a dative prepositionand Urlaub is a masculine noun.
The correctarticle is einem.
(9a) *Sie tr~iumt von einen Urlaub.
(9b) Sie tr~iumt von einem Urlaub.She is dreaming of a vacation.In the German Tutor, the Analysis Modulegenerates instructional feedback of differentlevels of specificity.
The pedagogical principleunderlying this design is guided discoverylearning.
According to Elsom-Cook \[1988\],guided discovery takes the student along acontinuum from heavily structured, ~ tutor-directed learning to where the tutor plays lessand less of a role.
Applied to feedback, thepedagogy scales messages on a continuum fromleast-to-most specific guiding the studenttowards the correct answer.For the error in example (9a), the sy, stemgenerates feedback of increasing abstraction thatthe instruction system can use when interactingwith the student.
The level of  the learner, eitherexpert, intermediate, or novice according to thecurrent state of the Student Model, determinesthe particular feedback displayed.
Theresponses, given in (10a) - (c) correspond to thethree learner levels for the error in example (9a),respectively:(10a) There is a mistake with the articleeinen of the prepositional phrase.
(10b) There is a mistake in case with thearticle einen of the prepositional phrase.
(10c) This is not the correct case for thearticle einen of the prepositional phrase.
Vonassigns the dative case,For the expert, the feedback is most general,providing a hint to where in the sentence theerror occurred (prepositional phrase).
For theintermediate learner, the feedback is moredetailed, providing additional information on thetype of error (case).
For the beginner, thefeedback is the most precise.
It not onlypinpoints the location and type of the error butalso refers to the exact source of the error(dative preposition).The Analysis Module is implemented in DATR\[Evans and Gazdar 1990\], a language designedfor pattern-matching and representing multipleinheritance.
For each grammar constraint, theAnalysis Module creates three categories ofinstructional feedback corresponding to the threelearning levels.
Provided with three categoriesof feedback, the system selects an error responsesuited to students' expertise.
The student level isdetermined by the numerical value for eachgrammatical constraint maintained in theStudent Model.
Each value is adjusted each timethe learner interacts with the system.For example, the grammar constraint pp-datrecords the student's performance on dativeassigning prepositions.
A learner who violatesthe constraint on dative prepositions will, atfirst, obtain the feedback message for theintermediate.
If the student commits the sameerror in subsequent exercises, s/he will soon beassessed a novice.
At this point, the system willdisplay the more detailed feedback messagesuited to the beginner.
However, each time thestudent applies the grammatical constraintcorrectly, the Student Model records thesuccess.
After demonstrating proficiency, thestudent will again be assessed as intermediate,or, even expert.
Maintaining a large number ofgrammatical constraints allows for a verydetailed portrait of an individual student'slanguage competence over a wide-range ofgrammatical phenomena.After instructional feedback for student inputhas been generated; the feedback message ispassed to the Teaching Module.
The TeachingModule interacts with the learner.
It displaysinstructional feedback and, at the end of anexercise set, shows the student's performancehistory on each grammatical constraint.
Studentsperformance history informs learners andinstructors of the grammatical construction the60student has mastered as well as the ones thatrequire remedial work.ConclusionIn this paper, we have described a StudentModel that implements language teachingpedagogy in guiding the analysis of studentinput in an ILTS for German.
The StudentModel keeps a record of students' previousperformance history which provides informationessential to the analysis of multiple parses,multiple errors, and the level of interaction withthe student.For multiple parses, the system implementslicensing conditions which select one of thepossible parses by taking into account thelikelihood of the error.
The likelihood of an erroris determined by the performance level of thestudent as indicated by the Student Model.
Formultiple errors, the system implements an ErrorPriority Queue which takes student errors andselects the most important error.
Criteria forselection can be set by the instructor or evokedby the Student Model.
The Student Model rankserrors with respect to students' performancehistory.
Finally, by consult ing the StudentModel, the Analysis Module selects instructionalfeedback of different levels of specificity.From a language teaching perspective, thesystem reflects a pedagogically informed,student-centered approach.
System decisions arebased on a dynamic Student Model rather thanstatic computational factors.
As a consequence,the learning process is individualized throughoutthe analysis of student input.Further ResearchThe ILTS described in this paper has beenimplemented on the World Wide Web.
Whilethe system encompasses all the necessarygrammar ules, we are currently expanding thelexicon for an introductory course of German.Our immediate goal is to test the system withlearners of German to assess accuracy.
Long-term goals include expanding the StudentModel.
Student performance is only onecriterion to individualize the language learningprocess.
The native language of the student aswell as different learning styles might also bekey factors in the analysis of student input.ReferencesCarpenter, B., and Penn, Gerald.
(1994) The AttributeLogic Engine: User's Guide, Version 2.0.Computational Linguistics Program, CarnegieMellon University, Pittsburgh.Covington, M.A., and Weinrich, K.B.
(1991)"Unification-Based Diagnosis of LanguageLearners' Syntax Errors."
Literary and LinguisticComputing, 6(3): 149-154.Elsom-Cook, M. (1988) "Guided Discovery Tutoringand Bounded User Modelling."
ArtificialIntelligence and Human Learning.
Self, J., ed.Bristol: J. W. Arrowsmith Ltd.: 165-178.Evans, R., and Gazdar, G. (1990).
The DATR Papers,Volume L Brighton, School of Cognitive andComputing Sciences.
The University of Sussex.Gazdar, G., and Pullum, G. (1985) "ComputationallyRelevant Properties of Natural Languages and theirGrammars."
New Generation Computing.
3: 273-306.Heift, T. (1998) Designed Intelligence: A LanguageTeacher Model.
Doctoral Dissertation, SimonFraser University.LaReau, P., and Vockell, E. (1989) The Computer inthe Foreign Language Curriculum.
Santa Cruz,CA: Mitchell Publishing.Pollard, C., and Sag, I.
(1994) Head-Driven PhraseStructure Grammar.
Chicago University Press.Schneider, D., and McCoy K. (1998) "RecognizingSyntactic Errors in the Writing of SecondLanguage Learners."
Proceedings of the 17thInternational Conference on ComputationalLinguistics.Schwind, C. B.
(1990) "An Intelligent LanguageTutoring System."
International Journal of Man-Machine Studies, 33: 557-579.Van der Linden, E. (1993) "Does Feedback EnhanceComputer-Assisted Language Learning.
"Computers & Education, 21 (1-2): 61-65.Van Noord, G. (1997) "An Efficient Implementationof the Head-Corner Parser."
ComputationalLinguistics, 23 (3): 425-456.Weischedel, R.M., Voge, W.M., and James, M.(1978) "An Artificial Intelligence Approach toLanguage Instruction."
Artificial Intelligence, 10:225-240.61
