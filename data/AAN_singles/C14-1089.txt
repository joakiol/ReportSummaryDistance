Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 940?949, Dublin, Ireland, August 23-29 2014.The Impact of Deep Hierarchical Discourse Structuresin the Evaluation of Text CoherenceVanessa Wei Feng1, Ziheng Lin2, and Graeme Hirst11Department of Computer ScienceUniversity of Toronto{weifeng, gh}@cs.toronto.edu2Singapore Press Holdingslinziheng@gmail.comAbstractPrevious work by Lin et al.
(2011) demonstrated the effectiveness of using discourse relationsfor evaluating text coherence.
However, their work was based on discourse relations annotatedin accordance with the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), which encodesonly very shallow discourse structures; therefore, they cannot capture long-distance discoursedependencies.
In this paper, we study the impact of deep discourse structures for the task of co-herence evaluation, using two approaches: (1) We compare a model with features derived fromdiscourse relations in the style of Rhetorical Structure Theory (RST) (Mann and Thompson,1988), which annotate the full hierarchical discourse structure, against our re-implementation ofLin et al.
?s model; (2) We compare a model encoded using only shallow RST-style discourserelations, against the one encoded using the complete set of RST-style discourse relations.
Withan evaluation on two tasks, we show that deep discourse structures are truly useful for better dif-ferentiation of text coherence, and in general, RST-style encoding is more powerful than PDTB-style encoding in these settings.1 IntroductionIn a well-written text, utterances are not simply presented in an arbitrary order; rather, they are presentedin a logical and coherent form, so that the readers can easily interpret the meaning that the writer wishesto present.
Therefore, coherence is one of the most essential aspects of text quality.
Given its importance,the automatic evaluation of text coherence is one of the crucial components of many NLP applications.A particularly popular model for the evaluation of text coherence is the entity-based local coherencemodel of Barzilay and Lapata (B&L) (2005; 2008), which extracts mentions of entities in the text, andmodels local coherence by the transitions, from one sentence to the next, in the grammatical role of eachmention.
Since the initial publication of this model, a number of extensions have been proposed, themajority of which are focused on enriching the original feature set.
However, these enriched featuresets are usually application-specific, i.e., it requires a certain expertise and intuition to conceive goodfeatures.In contrast, we seek insights of better feature encoding from a more general problem: discourse parsing(to be introduced in Section 2).
Discourse parsing aims to identify the discourse relations held amongvarious discourse units in the text.
Therefore, one can expect that discourse parsing provides usefulinformation to the evaluation of text coherence, because, essentially, the existence and the distribution ofdiscourse relations are the basis of the coherence in a text.In fact, there is already evidence showing that discourse relations can help better capture text coher-ence.
Lin et al.
(2011) use a PDTB-style discourse parser (to be introduced in Section 2.1) to identifydiscourse relations in the text, and they represent a text by entities and their associated discourse rolesin each sentence.
In their experiments, using discourse roles alone, their model performs very simi-lar or even better than B&L?s model.
Combining their discourse role features with B&L?s entity-basedtransition features further improves the performance.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/940S1: The dollar finished lower yesterday, after tracking another rollercoaster session on Wall Street.S2: [Concern about the volatile U.S. stock market had faded in recent sessions]C2.1, [and tradersappeared content to let the dollar languish in a narrow range until tomorrow, when the preliminaryreport on third-quarter U.S. gross national product is released.
]C2.2S3: But seesaw gyrations in the Dow Jones Industrial Average yesterday put Wall Street back in thespotlight and inspired market participants to bid the U.S. unit lower.Three discourse relations are presented in the text above:1.
Implicit EntRel between S1as Arg1, and S2as Arg2.2.
Explicit Conjunction within S2: C2.1as Arg1, C2.2as Arg2, with and as the connective.3.
Explicit Contrast between S2as Arg1 and S3as Arg2, with but as the connective.Figure 1: An example text fragment composed of three sentences, and its PDTB-style discourse relations.However, PDTB-style discourse relations encode only very shallow discourse structures, i.e., the re-lations are mostly local, e.g., within a single sentence or between two adjacent sentences.
Therefore,in general, features derived from PDTB-style discourse relations cannot capture long discourse depen-dency, and thus the resulting model is still limited to being a local model.
Nonetheless, long-distancediscourse dependency could be quite useful for capturing text coherence from a global point of view.Therefore, in this paper, we study the effect of deep hierarchical discourse structure in the evalua-tion of text coherence, by adopting two approaches to perform a direct comparison between models thatincorporate deep hierarchical discourse structures and models with shallow structures.
To evaluate ourmodels, we conduct experiments on two datasets, each of which resembles a real sub-task in the evalu-ation of text coherence: sentence ordering and essay scoring.
On both tasks, the model derived fromdeep discourse structures is shown to be more powerful than the model derived from shallow discoursestructures.
Moreover, for sentence ordering, combining our model with entity-based transition featuresachieves the best performance.
However, for essay scoring, the combination is detrimental.2 Discourse parsingDiscourse parsing is the problem of identifying the discourse structure within a text, by recognizing thespecific type of its discourse relations, such as Contrast, Explanation, and Causal relations.
Althoughdiscourse parsing is still relatively less well-studied, a number of theories have been proposed to capturedifferent rhetorical characteristics or to serve different applications.Currently, the two main directions in the study of discourse parsing are PDTB-style and RST-styleparsing.
These two directions are based on distinct theoretical frameworks, and each can be potentiallyuseful for particular kinds of downstream applications.
As will be discussed shortly, the major differencebetween PDTB- and RST-style discourse parsing is the notion of deep hierarchical discourse structure,which, according to our hypothesis, can be very useful for recognizing text coherence.2.1 PDTB-style Discourse ParsingThe Penn Discourse Treebank (PDTB), developed by Prasad et al.
(2008), is currently the largestdiscourse-annotated corpus, consisting of 2159 Wall Street Journal articles.
The annotation in PDTBadopts the predicate-argument view of discourse relations, where a discourse connective (e.g., because)is treated as a predicate that takes two text spans as its arguments.
The argument that the discourse con-nective structurally attaches to is called Arg2, and the other argument is called Arg1.
In PDTB, relationsare further categorized into explicit and implicit relations: a relation is explicit if there is an explicit dis-course connective presented in the text; otherwise, it is implicit.
PDTB relations focus more on localityand adjacency: explicit relations seldom connect text units beyond local context; for implicit relations,941S1: [The dollar finished lower yesterday,]e1[after tracking another rollercoaster session on WallStreet.
]e2S2: [Concern about the volatile U.S. stock market had faded in recent sessions,]e3[and tradersappeared content to let the dollar languish in a narrow range until tomorrow,]e4[when the preliminaryreport on third-quarter U.S. gross national product is released.
]e5S3: [But seesaw gyrations in the Dow Jones Industrial Average yesterday put Wall Street back in thespotlight]e6[and inspired market participants to bid the U.S. unit lower.
]e7Condition(e1-e7)(e1) (e2)(e1-e2) (e3-e7)(e4-e5)(e4) (e5)BackgroundTemporalList Cause(e6) (e7)(e6-e7)(e3-e5)(e3)ContrastFigure 2: An example text fragment composed of seven EDUs, and its RST discourse tree representation.only adjacent sentences within paragraphs are examined for the existence of implicit relations.The PDTB-style discourse parsing is thus the type of framework in accordance with the PDTB, whichextracts the discourse relations in a text, by identifying the presence of discourse connectives, the asso-ciated discourse arguments, and the specific types of the relations.
An example text fragment is shownin Figure 1, consisting of three sentences, S1, S2, and S3.
A sentence may further contain clauses, e.g.,C2.1and C2.2in S2.
The three PDTB-style discourse relations in this text are explained below the text.2.2 RST-style Discourse ParsingRST-style discourse parsing follows the theoretical framework of Rhetorical Structure Theory (RST)(Mann and Thompson, 1988).
In the framework of RST, a coherent text can be represented as a discoursetree whose leaves are non-overlapping text spans called elementary discourse units (EDUs); these are theminimal text units of discourse trees.
Adjacent nodes can be related through particular discourse relationsto form a discourse subtree, which can then be related to other adjacent nodes in the tree structure.RST-style discourse relations can be categorized into two types: mononuclear and multi-nuclear.
Inmononuclear relations, one of the text spans, the nucleus, is more salient than the other, the satellite,while in multi-nuclear relations, all text spans are equally important for interpretation.Consider Figure 2, in which the same example as in Figure 1 is chunked into seven EDUs (e1-e7),segmented by square brackets.
Its discourse tree representation is shown below in the figure, followingthe notational convention of RST.
The two EDUs e1and e2are related by a mononuclear relation Tem-poral, where e1is the more salient span; e4and e5are related by Condition, with e4as the nucleus; ande6and e7are related by Cause, with e7as the nucleus.
Then, the spans (e3-e5) and (e6-e7) are related byContrast to form a higher-level discourse structure, and so on.
Finally, a Background relation merges thespan (e1-e2) and (e3-e7) on the top level of the tree.As can be seen, thanks to the tree-structured representation of RST, compared to PDTB-style repre-sentation, we have a full hierarchy of discourse relations in the text: discourse relations exist not only ina local context, but also on higher text levels, such as between S1and the concatenation of S2and S3.3 Entity-based Local Coherence ModelThe entity-based local coherence model was initially developed by Barzilay and Lapata (B&L) (2005;2008).
The fundamental assumption of this model is that a document makes repeated reference to ele-ments of a set of entities that are central to its topic.For a document d, an entity grid is constructed, in which the columns represent the entities referred942S1: [The dollar]Sfinished lower [yesterday]X, after tracking [another rollercoaster session]Oon[Wall Street]X.S2: [Concern]Sabout [the volatile U.S. stock market]Xhad faded in [recent sessions]X, and[traders]Sappeared content to let [the dollar]Slanguish in [a narrow range]Xuntil [tomorrow]X,when [the preliminary report]Son [third-quarter U.S. gross national product]Xis released.S3: But [seesaw gyrations]Sin [the Dow Jones Industrial Average]X[yesterday]Xput [WallStreet]Oback in [the spotlight]Xand inspired [market participants]Oto bid [the U.S. unit]Slower.dollaryesterdaysessionWallStreetconcernmarketsessionstradersrangetomorrowreportGNPgyrationsDJIAspotlightparticipantsS1S X O X - - - - - - - - - - - -S2S - - - S X S X X X S X - - - -S3S X - O - - - - - - - - S X X OTable 1: The entity grid for the example text with three sentences and eighteen entities.
Grid cellscorrespond to grammatical roles: subjects (S), objects (O), or neither (X).to in d, and rows represent the sentences.
Each cell corresponds to the grammatical role of an entity inthe corresponding sentence: subject (S), object (O), neither (X), or nothing (?
), and an entity is definedas a class of coreferent noun phrases.
If the entity serves in multiple roles in a single sentence, thenwe resolve its grammatical role following the priority order: S  O  X  ?.
Consider the text in ourprevious examples; its entity grid is shown in Table 1, and the entities are highlighted in boldface in thetext above1.
A local transition is defined as a sequence {S,O,X,?
}n, representing the occurrence andgrammatical roles of an entity in n adjacent sentences.
Such transition sequences can be extracted fromthe entity grid as continuous subsequences in each column.
For example, the entity dollar in Table 1has a bigram transition {S,S} from sentence 1 to 2.
The entity grid is then encoded as a feature vector?
(d) = (p1(d), p2(d), .
.
.
, pm(d)), where pt(d) is the normalized frequency of the transition t in theentity grid, and m is the number of transitions with length no more than a predefined length k. pt(d) iscomputed as the number of occurrences of t in the entity grid of document d, divided by the total numberof transitions of the same length.
Moreover, entities are differentiated by their salience ?
an entity isdeemed to be salient if it occurs at least l times in the text, and non-salient otherwise ?
and transitionsare computed separately for salient and non-salient entities.3.1 Extension: Lin et al.
?s Discourse Role MatrixAs mentioned previously, most extensions to B&L?s entity-based local coherence model focus on enrich-ing the feature set, including the work of Filippova and Strube (2007), Cheung and Penn (2010), Elsnerand Charniak (2011), and Lin et al.
(2011).
To the best of our knowledge, the only exception is Feng andHirst (2012a)?s extension from the perspective of improving the learning procedure.Among various extensions to B&L?s entity-based local coherence model, the one most related to oursis Lin et al.
(2011)?s work on encoding a text as a set of entities with their associated discourse roles.
Linet al.
observed that coherent texts preferentially follow certain relation patterns.
However, simply usingsuch patterns to measure the coherence of a text can result in feature sparseness.
To solve this problem,they expand the relation sequence into a discourse role matrix, as shown in Table 2.
Columns correspondto the entities in the text and rows represent the contiguous sentences.
Each cell?Ei,Sj?corresponds tothe set of discourse roles that the entity Eiserves as in sentence Sj.
For example, the entity yesterdayfrom S3takes part in Arg2 of the last relation, so the cell ?yesterday,S3?
contains the role Contrast.Arg2.1Text elements are considered to be a single entity with multiple mentions if they refer to the same object or concept in theworld, even if they have different textual realizations; e.g., dollar in S1and U.S. unit in S3refer to the same entity.943dollar yesterday session Wall Street concern marketS1EntRel.Arg1 EntRel.Arg1 EntRel.Arg1 EntRel.Arg1 nil nilS2EntRel.Arg2nil nil nilEntRel.Arg2 EntRel.Arg2Conj.Arg2 Conj.Arg1 Conj.Arg1Contrast.Arg1 Contrast.Arg1 Contrast.Arg1S3Contrast.Arg2 Contrast.Arg2 nil Contrast.Arg2 nil nilTable 2: A fragment of Lin et al.
?s PDTB-style discourse role matrix for the example text with the firstsix entities across three sentences.An entry may be empty (with a symbol nil, as in ?yesterday,S2?)
or contain multiple discourse roles (as in?dollar,S2?).
Next, the frequencies of the discourse role transitions of lengths 2 and 3, e.g., EntRel.Arg1?
Conjunction.Arg2 and EntRel.Arg1?
nil?
Contrast.Arg2, are calculated with respect to the matrix.For example, the frequency of EntRel.Arg1?
Conjunction.Arg2 is 1/24 = 0.042 in Table 2.4 MethodologyAs discussed in Section 1, the main objective of our work is to study the impact of deep hierarchical dis-course structures in the evaluation of text coherence.
In order to conduct a direct comparison between amodel with features derived from deep hierarchical discourse relations and a model with features derivedfrom shallow discourse relations only, we adopt two separate approaches: (1) We implement a modelwith features derived from RST-style discourse relations, and compare it against a model with featuresderived from PDTB-style relations.
(2) In the framework of RST-style discourse parsing, we deprive themodel of any information from higher-level discourse relations and compare its performance against themodel that uses the complete set of discourse relations.
Moreover, as a baseline, we also re-implementedB&L?s entity-based local coherence model, and we will study the effect of incorporating one of our dis-course feature sets into this baseline model.
Therefore, we have four ways to encode discourse relationfeatures, namely, entity-based, PDTB-style, full RST-style, and shallow RST-style.4.1 Entity-based Feature EncodingIn entity-based feature encoding, our goal is to formulate a text into an entity grid, such as the one shownin Table 1, from which we extract entity-based local transitions.
In our re-implementation of B&L, weuse the same parameter settings as B&L?s original model, i.e., the optimal transition length k = 3 and thesalience threshold l = 2.
However, when extracting entities in each sentence, e.g., dollar, yesterday, etc.,we do not perform coreference resolution; rather, for better coverage, we follow the suggestion of Elsnerand Charniak (2011) and extract all nouns (including non-head nouns) as entities.
We use the Stanforddependency parser (de Marneffe et al., 2006) to extract nouns and their grammatical roles.
This strategyof entity extraction also applies to the other three feature encoding methods to be described below.4.2 PDTB-style Feature EncodingTo encode PDTB-style discourse relations into the model, we parse the texts using an end-to-end PDTB-style discourse parser2developed by Lin et al.
(2014).
The F1score of this parser is around 85% for rec-ognizing explicit relations and around 40% for recognizing implicit relations.
A text is thus representedby a discourse role matrix in the same way as shown in Table 2.
Most parameters in our PDTB-style fea-ture encoding follow those of Lin et al.
(2011): each entity is associated with the fully-fledged discourseroles, i.e., with type and argument information included; the maximum length of discourse role transi-tions is 3; and transitions are generated separately for salient and non-salient entities with a threshold setat 2.
However, compared to Lin et al.
?s model, there are two differences in our re-implementation, andevaluated on a held-out development set, these modifications are shown to be effective in improving theperformance.2http://wing.comp.nus.edu.sg/?linzihen/parser/944dollar yesterday session Wall Street concern marketS1Background.N Background.N Temporal.S Temporal.S nil nilTemporal.N Temporal.NList.N List.N List.NS2Condition.N nil nil nil Contrast.S Contrast.SContrast.SContrast.NS3Background.N Cause.S nil Cause.S nil nilCause.NTable 3: A fragment of the full RST-style discourse role matrix for the example text with the first sixentities across three sentences.First, we differentiate between intra- and multi-sentential discourse relations, which is motivated by afinding in the field of RST-style discourse parsing ?
distributions of various discourse relation types arequite distinct between intra-sentential and multi-sentential instances (Feng and Hirst, 2012b; Joty et al.,2012) ?
and we assume that a similar phenomenon exists for PDTB-style discourse relations.
Therefore,we assign two sets of discourse roles to each entity: intra-sentential and multi-sentential roles, which arethe roles that the entity plays in the corresponding intra- and multi-sentential relations.Second, instead of Level-1 PDTB discourse relations (6 in total), we use Level-2 relations (18 in total)in feature encoding, so that richer information can be captured in the model, resulting in 18?
2 = 36different discourse roles with argument attached.
We then generate four separate set of features for thecombination of intra-/multi-sentential discourse relation roles, and salient/non-salient entities, amongwhich transitions consisting of only nil symbols are excluded.
Therefore, the total number of features inPDTB-style encoding is 4?
(362+363?2)?
192K.4.3 Full RST-style Feature EncodingFor RST-style feature encoding, we parse the texts using an end-to-end RST-style discourse parser de-veloped by Feng and Hirst (2014), which produces a discourse tree representation for each text, such asthe one shown in Figure 2.
For relation labeling, the overall accuracy of this discourse parser is 58%,evaluated on the RST-DT.We encode the RST-style discourse relations in a similar fashion to PDTB-style encoding.
However,since the definition of discourse roles depends on the particular discourse framework, here, we adapt Linet al.
?s PDTB-style encoding by replacing the PDTB-style discourse relations with RST-style discourserelations, and the argument information (Arg1 or Arg2) by the nuclearity information (nucleus or thesatellite) in an RST-style discourse relation.
More importantly, in order to reflect the hierarchical struc-ture in an RST-style discourse parse tree, when extracting the set of discourse relations that an entityparticipates in, we find all those discourse relations that the entity appears in the main EDUs of eachrelation3and represent the role of the entity in each of these discourse relations.
In this way, we canencode long-distance discourse relations for the most relevant entities.
For example, considering theRST-style discourse tree representation in Figure 2, we encode the Background relation for the entitiesdollar and yesterday in S1, as well as the entity dollar in S3, but not for the remaining entities in the text,even though the Background relation covers the whole text.
The corresponding full RST-style discourserole matrix for the example text is shown in Table 3.As in PDTB-style feature encoding, we differentiate between intra- and multi-sentential discourserelations; we use 17 coarse-grained classes of RST-style relations in feature encoding; the optimal transi-3The main EDUs of a discourse relation are the EDUs obtained by traversing the discourse subtree in which the relation ofinterest constitutes the root node, following the nucleus branches down to the leaves.
For instance, for the RST discourse treein Figure 2, the main EDUs of the Background relation on the top level are {e1,e7}, and the main EDUs of the List relationamong (e3-e5) are {e3,e4}.945tion length k is 3; and the salience threshold l is 2.
The total number of features in RST-style encoding istherefore 4?(342+343?2)?
162K, which is roughly the same as that in PDTB-style feature encoding.4.4 Shallow RST-style Feature EncodingShallow RST-style encoding is almost identical to full RST-style encoding, as introduced in Section4.3, except that, when we derive discourse roles, we consider shallow discourse relations only.
To beconsistent with the majority of PDTB-style discourse relations, we define shallow discourse relations asthose relations which hold between text spans of the same sentence, or between two adjacent sentences.For example, in Figure 2, the Background relation between (e1-e2) and (e3-e7) is not a shallow discourserelation (it holds between a single sentence and the concatenation of two sentences), and thus will beexcluded from shallow RST-style feature encoding.5 ExperimentsTo evaluate our proposed model with deep discourse structures encoded, we conduct two series of exper-iments on two different datasets, each of which simulates a sub-task in the evaluation of text coherence,i.e., sentence ordering and essay scoring.
Since text coherence is a matter of degree rather than a bi-nary classification, in both evaluation tasks we formulate the problem as a pairwise preference rankingproblem.
Specifically, given a set of texts with different degrees of coherence, we train a ranker whichlearns to prefer a more coherent text over a less coherent counterpart.
Accuracy is therefore measuredas the fraction of correct pairwise rankings as recognized by the ranker.
In our experiments, we use theSVMlightpackage4(Joachims, 1999) with the ranking configuration, and all parameters are set to theirdefault values.5.1 Sentence OrderingThe task of sentence ordering, which has been extensively studied in previous work, attempts to simulatethe situation where, given a predefined set of information-bearing items, we need to determine the bestorder in which the items should be presented.
As argued by Barzilay and Lapata (2005), sentence order-ing is an essential step in many content-generation components, such as multi-document summarization.In this task, we use a dataset consisting of a subset of the Wall Street Journal (WSJ) corpus, in whichthe minimum length of a text is 20 sentences, and the average length is 41 sentences.
For each text, wecreate 20 random permutations by shuffling the original order of the sentences.
In total, we have 735source documents and 735?20 = 14,700 permutations.
Because the RST-style discourse parser we useis trained on a fraction of the WSJ corpus, we remove the training texts from our dataset, to guaranteethat the discourse parser will not perform exceptionally well on some particular texts.
However, sincethe PDTB-style discourse parser we use is trained on almost the entire WSJ corpus, we cannot do thesame for the PDTB-style parser.In this experiment, our learning instances are pairwise ranking preferences between a source text andone of its permutations, where the source text is always considered more coherent than its permutations.Therefore, we have 735?20 = 14,700 total pairwise rankings, and we conduct 5-fold cross-validation onfive disjoint subsets.
In each fold, one-fifth of the rankings are used for testing, and the rest for training.5.2 Essay ScoringThe second task is essay scoring, and we use a subset of International Corpus of Learner English (ICLE)(Granger et al., 2009).
The dataset consists of 1,003 essays about 34 distinct topics, written by universityundergraduates speaking 14 native languages who are learners of English as a Foreign Language.
Eachessay has been annotated with an organization score from 1 to 4 at half-point increments by Persing etal.
(2010).
We use these organization scores to approximate the degrees of coherence in the essays.
Theaverage length of the essays is 32 sentences, and the average organization score is 3.05, with a standarddeviation of 0.59.4http://svmlight.joachis.org/946Model sentence ordering essay scoringNo discourse structure Entity 95.1 66.4Shallow discourse structuresPDTB 97.2 82.2PDTB&Entity 97.3 83.3Shallow RST 98.5 87.2Shallow RST&Entity 98.8 87.2Deep discourse structuresFull RST 99.1 88.3Full RST&Entity 99.3 87.7Table 4: Accuracy (%) of various models on the two evaluation tasks: sentence ordering and essayscoring.
For sentence ordering, accuracy difference is significant with p < .01 for all pairs of modelsexcept between PDTB and PDTB&Entity.
For essay scoring, accuracy difference is significant withp < .01 for all pairs of models except between shallow RST and shallow RST&Entity.
Significance isdetermined with the Wilcoxon signed-rank test.In this experiment, our learning instances are pairwise ranking preferences between a pair of essayson the same topic written by students speaking the same native language, excluding pairs with the sameorganization score.
In total, we have 22,362 pairwise rankings.
Similarly, we conduct 5-fold cross-validations on these rankings.In fact, the two datasets used in the two evaluation tasks reflect different characteristics by themselves.The WSJ dataset, although somewhat artificial due to the permuting procedure, is representative of textswith well-formed syntax.
By contrast, the ICLE dataset, although not artificial, contains occasionalsyntactic errors, because the texts are written by non-native English speakers.
Therefore, using these twodistinct datasets allows us to evaluate our models in tasks where different challenges may be expected.6 ResultsIn this section, we demonstrate the performance of our models with discourse roles encoded in one ofthe three ways: PDTB-style, full RST-style or shallow RST-style, and compare against their combinationwith our re-implemented B&L?s entity-based local transition features.
The evaluation is conducted onthe two tasks, sentence ordering and essay scoring, and the accuracy is reported as the fraction of correctpairwise rankings averaged over 5-fold cross-validation.The performance of various models is shown in Table 4.
The first section of the table shows theresults of our re-implementation of B&L?s entity-based local coherence model, representing the effectwith no discourse structure encoded.
The second section shows the results of four models with shallowdiscourse structures encoded, including the two basic models, PDTB-style and shallow RST-style featureencoding, and their combination with the entity-based feature encoding.
The last section shows theresults of our models with deep discourse structures encoded, including the RST-style feature encodingand its combination with the entity-base feature encoding.
With respect to the performance, we observea number of consistent patterns across both evaluation tasks.First, with no discourse structure encoded, the entity-based model (the first row) performs the worstamong all models, suggesting that discourse structures are truly important and can capture coherence ina more sophisticated way than pure grammatical roles.
Moreover, the performance gap is particularlylarge for essay scoring, which is probably due to the fact that, as argued by Persing et al.
(2010), theorganization score, which we use to approximate the degrees of coherence, is not equivalent to textcoherence.
Organization relates more to the logical development in the texts, while coherence is aboutlexical and semantic continuity; but discourse relations can capture the logical relations at least to someextent.Secondly, with deep discourse structures encoded, the RST-style model in the third section signif-icantly outperforms (p < .01) the models with shallow discourse structures, i.e., the PDTB-style and947shallow RST-style models in the middle section, confirming our intuition that deep discourse structuresare more powerful than shallow structures.
This is also the case when entity-based features are included.Finally, considering the models in the middle section of the table, we can gain more insight into thedifference between PDTB-style and RST-style encoding.
As can be seen, even without information fromthe more powerful deep hierarchical discourse structures, shallow RST-style encoding still significantlyoutperforms PDTB-style encoding on both tasks (p < .01).
This is primarily due to the fact that thediscourse relations discovered by RST-style parsing have wider coverage of the text5, and thus inducericher information about the text.
Therefore, because of its ability to annotate deep discourse structuresand its better coverage of discourse relations, RST-style discourse parsing is generally more powerfulthan PDTB-style parsing, as far as coherence evaluation is concerned.However, with respect to combining full RST-style features with entity features, we have contradictoryresults on the two tasks: for sentence ordering, the combination is significantly better than each singlemodel, while for essay scoring, the combination is worse than using RST-style features alone.
This isprobably related to the previously discussed issue of using entity-based features for essay scoring, due tothe subtle difference between coherence and organization.7 Conclusion and Future WorkIn this paper, we have studied the impact of deep discourse structures in the evaluation of text coher-ence by two approaches.
In the first approach, we implemented a model with discourse role featuresderived from RST-style discourse parsing, which represents deep discourse structures, and compared itagainst our re-implemented Lin et al.
(2011)?s model derived from PDTB-style parsing, with no deepdiscourse structures annotated.
In the second approach, we compared our complete RST-style modelagainst a model with shallow RST-style encoding.
Evaluated on the two tasks, sentence ordering andessay scoring, deep discourse structures are shown to be effective for better differentiation of text coher-ence.
Moreover, we showed that, even without deep discourse structures, shallow RST-style encoding ismore powerful than PDTB-style encoding, because it has better coverage of discourse relations in texts.Finally, combining discourse relations with entity-based features is shown to have an inconsistent effecton the two evaluation tasks, which is probably due to the different nature of the two tasks.In our future work, we wish to explore the effect of automatic discourse parsers in our methodology.As discussed previously, the PDTB- and RST-style discourse parsers used in our experiments are far fromperfect.
Therefore, it is possible that using automatically extracted discourse relations creates some biasto the training procedure; it is also possible that what our model actually learns is the distribution overthose discourse relations which automatic discourse parsers are mostly confident with, and thus errors (ifany) made on other relations do not matter.
One potential way to verify these two possibilities is to studythe effect of each particular type of discourse relation to the resulting model, and we leave it for futureexploration.AcknowledgementsWe thank the reviewers for their valuable advice and comments.
This work was financially supported bythe Natural Sciences and Engineering Research Council of Canada and by the University of Toronto.ReferencesRegina Barzilay and Mirella Lapata.
2005.
Modeling local coherence: An entity-based approach.
In Proceedingsof the 42rd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pages 141?148.Jackie Chi Kit Cheung and Gerald Penn.
2010.
Entity-based local coherence modelling using topological fields.In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL 2010), pages186?195.5The entire text is covered by the annotation produced by RST-style discourse parsing, while this is generally not true forPDTB-style discourse parsing.948Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning.
2006.
Generating typed dependencyparses from phrase structure parses.
In Proceedings of the 5th International Conference on Language Resourcesand Evaluation (LREC 2006).Micha Elsner and Eugene Charniak.
2011.
Extending the entity grid with entity-specific features.
In Proceedingsof the 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011), pages 125?129.Vanessa Wei Feng and Graeme Hirst.
2012a.
Extending the entity-based coherence model with multiple ranks.
InProceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics(EACL 2012), pages 315?324, Avignon, France.Vanessa Wei Feng and Graeme Hirst.
2012b.
Text-level discourse parsing with rich linguistic features.
In Proceed-ings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012), pages 60?68,Jeju, Korea.Vanessa Wei Feng and Graeme Hirst.
2014.
A linear-time bottom-up discourse parser with constraints and post-editing.
In Proceedings of The 52nd Annual Meeting of the Association for Computational Linguistics (ACL2014), Baltimore, USA, June.Katja Filippova and Michael Strube.
2007.
Extending the entity-grid coherence model to semantically relatedentities.
In Proceedings of the Eleventh European Workshop on Natural Language Generation (ENLG 2007),pages 139?142.Sylviane Granger, Estelle Dagneaux, Fanny Meunier, and Magali Paquot.
2009. International Corpus of LearnerEnglish (Version 2).
Presses universitaires de Louvain.Thorsten Joachims.
1999.
Making large-scale SVM learning practical.
In B. Sch?olkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods ?
Support Vector Learning, chapter 11, pages 169?184.
MIT Press, Cam-bridge, MA.Shafiq Joty, Giuseppe Carenini, and Raymond T. Ng.
2012.
A novel discriminative framework for sentence-leveldiscourse analysis.
In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural LanguageProcessing and Computational Natural Language Learning, EMNLP-CoNLL 2012, pages 904?915.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2011.
Automatically evaluating text coherence using discourserelations.
In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: HumanLanguage Technologies (ACL 2011), Portland, Oregon, USA, June.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014.
A PDTB-styled end-to-end discourse parser.
NaturalLanguage Engineering, 2:151?184.William Mann and Sandra Thompson.
1988.
Rhetorical structure theory: Toward a functional theory of textorganization.
Text, 8(3):243?281.Isaac Persing, Alan Davis, and Vincent Ng.
2010.
Modeling organization in student essays.
In Proceedings ofthe 2010 Conference on Empirical Methods in Natural Language Processing, pages 229?239, Cambridge, MA,October.
Association for Computational Linguistics.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber.2008.
The Penn Discourse Treebank 2.0.
In Proceedings of the 6th International Conference on LanguageResources and Evaluation (LREC 2008).949
