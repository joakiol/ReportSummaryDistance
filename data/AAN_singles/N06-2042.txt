Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 165?168,New York, June 2006. c?2006 Association for Computational LinguisticsWord Pronunciation Disambiguation using the WebEiichiro Sumita1, 21 NiCT2 ATR SLCKyoto 619-0288, JAPANeiichiro.sumita@atr.jpFumiaki Sugaya33 KDDI R&D LabsSaitama 356-8502, JAPANfsugaya@kddilabs.jpAbstractThis paper proposes an automatic methodof reading proper names with multiplepronunciations.
First, the method obtainsWeb pages that include both the propername and its pronunciation.
Second, themethod feeds them to the learner for clas-sification.
The current accuracy is around90% for open data.1 IntroductionWithin text-to-speech programs, it is very impor-tant to deal with heteronyms, that is, words that arespelt the same but that have different readings, e.g.
"bow" (a ribbon) and "bow" (of a ship).
Reportedly,Japanese text-to-speech programs read sentencesincorrectly more than 10 percent of the time.
Thisproblem is mainly caused by heteronyms and threestudies have attempted to solve it (Yarowsky,1996; Li and Takeuchi, 1997; and Umemura andShimizu, 2000).They assumed that the pronunciation of a wordcorresponded directly to the sense tag or part-of-speech of that word.
In other words, sense taggingand part-of-speech tagging can determine the read-ing of a word.
However, proper names have thesame sense tag, for example, ?location?
for land-marks and the same part-of-speech, the ?noun.
?Clearly then, reading proper names is outside thescope of previous studies.
Also, the proper namesof locations, people, organizations, and others aredominant sources of heteronyms.
Here, we focuson proper names.
Our proposal is similar to previ-ous studies in that both use machine learning.However, previous methods used expensive re-sources, e.g., a corpus in which words aremanually tagged according to their pronunciation.Instead, we propose a method that automaticallybuilds a pronunciation-tagged corpus using theWeb as a source of training data for word pronun-ciation disambiguation.This paper is arranged as follows.
Section 2proposes solutions, and Sections 3 and 4 reportexperimental results.
We offer our discussion inSection 5 and conclusions in Section 6.2 The Proposed MethodsIt is crucial to correctly read proper names in open-domain text-to-speech programs, for example, ap-plications that read Web pages or newspaperarticles.
To the best of our knowledge, no otherstudies have approached this problem.
In this paper,we focus on the Japanese language.
In this section,we first explain the Japanese writing system (Sec-tions 2.1), followed by our proposal, the basicmethod (Section 2.2), and the improved method(Section 2.3).2.1 The Japanese writing systemFirst, we should briefly explain the modern Japa-nese writing system.
The Japanese language is rep-resented by three scripts:[i] Kanji, which are characters of Chinese ori-gin;[ii] Hiragana, a syllabary (reading); and[iii] Katakana, also a syllabary (reading).Script SampleKANJI ?
?HIRAGANA (reading) ????
?KATAKANA (reading) ????
?Table 1 Three writings of a single word165As exemplified in Table 1, there are three writ-ings for the word ???.?
The lower two sam-ples are representations of the same pronunciationof ?oo daira.
?Listing possible readings can be done by con-sulting a dictionary (see Section 3.1 for the ex-periment).
Therefore, in this paper, we assume thatlisting is performed prior to disambiguation.2.2 The basic method based on page hitsThe idea is based on the observation that propernames in Kanji often co-occur with their pro-nunciation in Hiragana (or Katakana) within a sin-gle Web page, as shown Figure 1.
In the figure,the name ????
in Kanji is indicated with anoval, and its pronunciation in Katakana, ??????,?
is high-lighted with the dotted oval.According to Google, there are 464 pages inwhich ????
and ???????
co-occur.In this sense, the co-occurrence frequencysuggests to us the most common pronunciation.Figure 1 On the Web, words written in Kanjioften co-occur with the pronunciation written inKatakana 1Our simple proposal to pick up the most fre-quent pronunciation achieves surprisingly highaccuracy for open data, as Section 4 will later show.2.3 The improved method using a classifierThe basic method mentioned above merely selectsthe most frequent pronunciation and neglects allothers.
This is not disambiguation at all.The improved method is similar to standardword-sense disambiguation.
The hit pages can pro-1http://oyudokoro.mimo.com/area/C/cd/tng/000370/index.htmlvide us with training data for reading a particularword.
We feed the downloaded data into thelearner of a classifier.
We do not stick to a certainmethod of machine learning; any state-of-the-artmethod will work.
The features used in classifica-tion will be explained in the latter half of this sub-section.Collecting training data from the WebOur input is a particular word, W, and the set of itsreadings, {Rk | k=1~K}.In the experiments for this report, L is set to1,000.
Thus, for each reading Rk of W, we have, atmost 1,000 training data Tl(W).Training the classifierFrom the training data Tl(W), we make featurevectors that are fed into the learner of the decisiontree with the correct reading Rk for the word inquestion, W.Here, we write Tl(W) as W-m W-(m-1) ... W-2 W-1W W1 W2 ... Wm-1 Wm, where m is from 2 to M,which hereafter is called the window size.We use two kinds of features:z The part-of-speech of W-2 W-1 and W1 W2z Keywords within the snippet.
In this ex-periment, keywords are defined as the topN frequent words, but for W in the bagconsisting of all words in {Tl(W)}.In this paper, N is set to 100.
These featuresground the pronunciation disambiguation task tothe real world through the Web.
In other words,they give us knowledge about the problem at hand,i.e., how to read proper names in a real-world con-text.3 Experimental DataWe conducted the experiments using proper loca-tion names.For all k =1~K:i) search the Web using the query ?W ANDRk.
?ii) obtain the set of snippets, {Sl (W, Rk)|l=1~L}.iii) separate Rk from Sl and obtain the set oftraining data,{(Tl(W), Rk)| l=1~L}.end1663.1 Ambiguous name listsJapan Post openly provides postal address listsassociated with pronunciations .From that list, we extracted 79,861 pairs ofproper location names and their pronunciations.
Asthe breakdown of Table 2 shows, 5.7% of properlocation names have multiple pronunciations,while 94.3% have a single pronunciation.
The av-erage ambiguity is 2.26 for ambiguous types.
Next,we took into consideration the frequency of eachproper name on the Web.
Frequency is surrogatedby the page count when the query of a word itselfis searched for using a search engine.
About onequarter of the occurrences were found to be am-biguous.Number ofreadingstype %1 70,232 94.32 3,4433 5994 1505 456 117 48 211 15.7total 74,487 100.0Table 2 Pronunciation ambiguities in Japaneselocation namesOur proposal depends on co-occurrences on aWeb page.
If the pairing of a word W and its read-ing R do not occur on the Web, the proposal willnot work.
We checked this, and found that therewas only one pair missing out of the 79,861 on ourlist.
In this sense, the coverage is almost 100%.3.2 Open DataWe tested the performance of our proposed meth-ods on openly available data.Open data were obtained from the EDR corpus,which consists of sentences from Japanese news-papers.
Every word is tagged with part-of-speechand pronunciation.We extracted sentences that include locationheteronyms, that is, those that contain Kanji thatcan be found in the above-mentioned list of loca-tion heteronyms within the postal address data.There were 268 occurrences in total.
There were72 types of heteronyms.4 Experiment ResultsWe conducted two experiments: (1) an open test;and (2) a study on the degree of ambiguity.4.1 Open testWe evaluated our proposals, i.e., the basic methodand the improved method with the open data ex-plained in Section 3.1.
Both methods achieved ahigh rate of accuracy.Basic method performanceIn the basic method, the most common pronuncia-tion on the Web is selected.
The frequency is esti-mated by the page count of the query for thepairing of the word W and its pronunciation, Ri.There are two variations based on the Hiraganaand Katakana pronunciation scripts.
The averageaccuracy for the open data was 89.2% for Hiraganaand 86.6% for Katakana (Table 3).
These resultsare very high, suggesting a strong bias of pronun-ciation distribution in the open data.Scripts AccuracyHIRAGANA 89.2KATAKANA 86.6Table 3 Open test accuracy for the basic methodPerformance of the improved methodTable 4 shows the average results for all 268occurrences.
The accuracy of the basic method(Table 3) was lower than that of our improvedproposal in all window sizes, and it was outper-formed at a window size of ten by about 3.5% forboth Hiragana and Katakana.Script M=2 M=5 M=10HIRAGANA 89.9 90.3 92.9KATAKANA 89.2 88.4 89.9Table 4 Open test accuracy for the improvedmethod1674.2 Degree of ambiguityHere, we examine the relationship between thedegree of pronunciation ambiguity and pronuncia-tion accuracy using a cross-validation test for train-ing data2 for the improved method with Hiragana.Average caseWe conducted the first experiment with twentywords 3 that were selected randomly from the Am-biguous Name List (Section 3.1).
The average am-biguity was 2.1, indicating the averageperformance of the improved proposal.Class M=2 M=5 M=10 basic2.1 89.2 %  90.9 %  92.3 % 67.5%Table 5 Average casesTable 5 summarizes the ten-fold cross valida-tion, where M in the table is the training data size(window size).
The accuracy changes word byword, though the average was high about 90% ofthe time.The ?basic?
column shows the average accu-racy of the basic method, i.e., the percentage forthe most frequent pronunciation.
The improvedmethod achieves much better accuracy than the?basic?
one.The most ambiguous caseNext, we obtained the results (Table 6) for themost ambiguous cases, where the degree of ambi-guity ranged from six to eleven4.
The average am-biguity was 7.1.Class M=2 M=5 M=10 basic7.1 73.9 %  77.3 %  79.9 % 57.5%Table 6 Most ambiguous cases2 There is some question as to whether the training data cor-rectly catch all the pronunciations.
The experiments in thissubsection are independent of this problem, because our inten-tion is to compare the performance of the average case and themost ambiguous case.3??
?, ??
?, ??
?, ??
,??
?, ?
?, ??
?, ??
?, ??
?, ?
?, ??
?, ?
?, ??
?, ??
?, ????,??
?, ?
?, ??
?, ??
?, ???.4?
?, ??
?, ?
?, ?
?, ?
?, ?
?, ?
?, ?
?, ?
?, ??
?, ?
?, ??
?, ??
?, ??
?, ??
?, ??
?, ??
?, ?
?.As we expected, the performances were poorerthan the average cases outlined above, althoughthey were still high, i.e., the average ranged fromabout 70% to about 80 %.
Again, the improvedmethod achieved much better accuracy than the?basic?
method.
55 Discussion on TransliterationTransliteration (Knight and Graehl, 1998) is amapping from one system of writing into another,automation of which has been actively studied be-tween English and other languages such as Arabic,Chinese, Korean, Thai, and Japanese.
If there aremultiple translation candidates, by incorporatingcontext in a way similar to our proposal, one willbe able to disambiguate them.6 ConclusionThis paper proposed a new method for readingproper names.
In our proposed method, using Webpages containing Kanji and Hiragana (or Katakana)representations of the same proper names, we canlearn how to read proper names with multiple read-ings via a state-of-the-art machine learner.
Thus,the proposed process requires no human interven-tion.
The current accuracy was around 90% foropen data.ReferencesK.
Knight and J. Graehl.
1998 Machine transliteration.Computational Linguistics, 24(4):599-612.H.
Li and J. Takeuchi.
1997.
Using Evidence that isboth string and Reliable in Japanese Homograph Dis-ambiguation, SIGNL119-9, IPSJ.Y.
Umemura and T. Shimizu.
2000.
Japanese homo-graph disambiguation for speech synthesizers, Toy-ota Chuo Kenkyujo R&D Review, 35(1):67-74.D.
Yarowsky.
1996.
Homograph Disambiguation inSpeech Synthesis.
In J. van Santen, R. Sproat, J.Olive and J. Hirschberg (eds.
), Progress in SpeechSynthesis.
Springer-Verlag, pp.
159-175.5 For some words, the basic accuracy is higher than the crossvalidation accuracy because the basic method reaches all oc-currences on the Web thanks to the search engine, while ourimproved method limits the number of training data by L inSection 2.3.
For example, the most frequent pronunciation of????
has 93.7% on the Web, whereas the distribution in thetraining data is different from such a sharp distribution due tothe limitation of L.168
