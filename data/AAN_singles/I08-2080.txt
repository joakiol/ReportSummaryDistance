Japanese Named Entity RecognitionUsing Structural Natural Language ProcessingRyohei Sasano?Graduate School of Information Scienceand Technology, University of Tokyoryohei@nlp.kuee.kyoto-u.ac.jpSadao KurohashiGraduate School of Infomatics,Kyoto Universitykuro@i.kyoto-u.ac.jpAbstractThis paper presents an approach that usesstructural information for Japanese namedentity recognition (NER).
Our NER systemis based on Support Vector Machine (SVM),and utilizes four types of structural informa-tion: cache features, coreference relations,syntactic features and caseframe features,which are obtained from structural analyses.We evaluated our approach on CRL NE dataand obtained a higher F-measure than exist-ing approaches that do not use structural in-formation.
We also conducted experimentson IREX NE data and an NE-annotated webcorpus and confirmed that structural infor-mation improves the performance of NER.1 IntroductionNamed entity recognition (NER) is the task of iden-tifying and classifying phrases into certain classesof named entities (NEs), such as names of persons,organizations and locations.Japanese texts, which we focus on, are writtenwithout using blank spaces.
Therefore, JapaneseNER has tight relation with morphological analy-sis, and thus it is often performed immediately aftermorphological analysis (Masayuki and Matsumoto,2003; Yamada, 2007).
However, such approachesrely only on local context.
The Japanese NER sys-tem proposed in (Nakano and Hirai, 2004), whichachieved the highest F-measure among conventionalsystems, introduced the bunsetsu1 feature in order toconsider wider context, but considers only adjacentbunsetsus.
*Research Fellow of the Japan Society for the Promotion of Science (JSPS)1Bunsetsu is a commonly used linguistic unit in Japanese,consisting of one or more adjacent content words and zero ormore following functional words.On the other hand, as for English or Chinese, var-ious NER systems have explored global informationand reported their effectiveness.
In (Malouf, 2002;Chieu and Ng, 2002), information about features as-signed to other instances of the same token is uti-lized.
(Ji and Grishman, 2005) uses the informationobtained from coreference analysis for NER.
(Mohitand Hwa, 2005) uses syntactic features in building asemi-supervised NE tagger.In this paper, we present a Japanese NER systemthat uses global information obtained from severalstructural analyses.
To be more specific, our systemis based on SVM, recognizes NEs after syntactic,case and coreference analyses and uses informationobtained from these analyses and the NER resultsfor the previous context, integrally.
At this point,it is true that NER results are useful for syntactic,case and coreference analyses, and thus these analy-ses and NER should be performed in a complemen-tary way.
However, since we focus on NER, we rec-ognize NE after these structural analyses.2 Japanese NER TaskA common standard definition for Japanese NERtask is provided by IREXworkshop (IREX Commit-tee, 1999).
IREX defined eight NE classes as shownin Table 1.
Compared with the MUC-6 NE task def-inition (MUC, 1995), the NE class ?ARTIFACT,?which contains book titles, laws, brand names andso on, is added.NER task can be defined as a chunking problemto identify token sequences that compose NEs.
Thechunking problem is solved by annotating chunktags to tokens.
Five chunk tag sets, IOB1, IOB2,IOE1, IOE2 and IOBES are commonly used.
In thispaper, we use the IOBES model, in which ?S?
de-notes a chunk itself, and ?B,?
?I?
and ?E?
denote the607Table 1: Definition of NE in IREX.NE class ExamplesORGANIZATION NHK Symphony OrchestraPERSON Kawasaki KenjiroLOCATION Rome, SinuijuARTIFACT Nobel PrizeDATE July 17, April this yearTIME twelve o?clock noonMONEY sixty thousand dollarsPERCENT 20%, thirty percentsbeginning, intermediate and end parts of a chunk.If a token does not belong to any named entity, it istagged as ?O.?
Since IREX defined eight NE classes,tokens are classified into 33 (= 8 ?
4 + 1) NE tags.For example, NE tags are assigned as following:(1) Kotoshi 4 gatsu Roma ni itta.this year April Rome to wentB-DATE I-DATE E-DATE S-LOCATION O O(?
went to Rome on April this year.
)3 Motivation for Our ApproachOur NER system utilizes structural information.
Inthis section, we describe the motivation for our ap-proach.High-performance Japanese NER systems are of-ten based on supervised learning, and most of themuse only local features, such as features obtainedfrom the target token, two preceding tokens and twosucceeding tokens.
However, in some cases, NEscannot be recognized by using only local features.For example, while ?Kawasaki?
in the secondsentence of (2) is the name of a person, ?Kawasaki?in the second sentence of (3) is the name of a soc-cer team.
However, the second sentences of (2) and(3) are exactly the same, and thus it is impossible tocorrectly distinguish these NE classes by only usinginformation obtained from the second sentences.
(2) Kachi-ha senpatsu-no Kawasaki Kenjiro.winner starterKawasaki-ha genzai 4 shou 3 pai.now won lost(The winning pitcher is the starter Kenjiro Kawasaki.Kawasaki has won 4 and lost 3.
)(3) Dai 10 setsu-wa Kawasaki Frontale-to taisen.the round againstKawasaki-ha genzai 4 shou 3 pai.now won lost(The 10th round is against Kawasaki Frontale.Kawasaki has won 4 and lost 3.
)In order to recognize these NE classes, it is essentialto use the information obtained from the previouscontext.
Therefore, we utilize information obtainedfrom the NER for the previous context: cache fea-ture and coreference relation.For another example, ?Shingishu?
in (4) is thename of city in North Korea.
The most importantclue for recognizing ?Shingishu?
as ?LOCATION?may be the information obtained from the head verb,?wataru (get across).?
(4) Shingishu-kara Ouryokko-wo wataru.Sinuiju from Amnokkang get across(?
gets across the Amnokkang River from Sinuiju.
)However, when using only local features, the word?wataru?
is not taken into consideration becausethere are more than two morphemes between ?shu2?and ?wataru.?
In order to deal with such problem,we use the information obtained from the head verb:syntactic feature and caseframe feature.4 NER Using Structural Information4.1 Outline of Our NER SystemOur NER system performs the chunking processbased on morpheme units because character-basedmethods do not outperform morpheme-based meth-ods (Masayuki and Matsumoto, 2003) and are notsuitable for considering wider context.A wide variety of trainable models have been ap-plied to Japanese NER task, including maximum en-tropy models (Utsuro et al, 2002), support vectormachines (Nakano and Hirai, 2004; Yamada, 2007)and conditional random fields (Fukuoka, 2006).
Oursystem applies SVMs because, for Japanese NER,SVM-based systems achieved higher F-measurethan the other systems.
(Isozaki and Kazawa, 2003)proposed an SVM-based NER system with Viterbisearch, which outperforms an SVM-based NER sys-tem with sequential determination, and our systembasically follows this system.
Our NER system con-sists of the following four steps:1.
Morphological analysis2.
Syntactic, case and coreference analyses3.
Feature extraction for chunking4.
SVM and Viterbi search based chunkingThe following sections describe each of these stepsin detail.2Since the dictionary for morphological analysis has no en-try ?Shingishu,?
?Shingishu?
is analyzed as consisting of threemorphemes: ?shin,?
?gi?
and ?shu.
?608Input sentence:Gai mu sho no shin Bei ha .foreign affairs ministry in pro America group(Pro-America group in the Ministry of Foreign Affairs.
)Output of JUMAN:Gaimu sho no shin Bei ha .noun noun particle noun noun nounOutput of ChaSen:Gaimusho no shin-Bei ha .noun particle noun nounFigure 1: Example of morphological analyses.4.2 Morphological AnalysisWhile most existing Japanese NER systems useChaSen (Matsumoto et al, 2003) as a morphologicalanalyzer, our NER system uses a Japanese morpho-logical analyzer JUMAN (Kurohashi and Kawahara,2005) because of the following two reasons.First, JUMAN tends to segment a sentence intosmaller morphemes than ChaSen, and this is a goodtendency for morpheme-based NER systems be-cause the boundary contradictions between morpho-logical analysis and NEs are considered to be re-duced.
Figure 1 shows an example of the outputsof JUMAN and ChaSen.
Although both analysesare reasonable, JUMAN divided ?Gaimusho?
and?shin-Bei?
into two morphemes, while ChaSen leftthem as a single morpheme.
Second, JUMAN addscategories to some morphemes, which can be uti-lized for NER.
In JUMAN, about thirty categoriesare defined and tagged to about one fifth of mor-phemes.
For example, ?ringo (apple),?
?inu (dog)?and ?byoin (hospital)?
are tagged as ?FOOD,?
?AN-IMAL?
and ?FACILITY,?
respectively.4.3 Syntactic, Case and Coreference Analysessyntactic analysis Syntactic analysis is performedby using the Japanese parser KNP (Kurohashi andNagao, 1994).
KNP employs some heuristic rules todetermine the head of a modifier.case analysis Case analysis is performed by usingthe system proposed in (Kawahara and Kurohashi,2002).
This system uses Japanese case frames thatare automatically constructed from a large corpus.To utilize case analysis for NER, we constructedcase frames that include NE labels in advance.
Weexplain details in Section 4.4.2.
The case analysis isapplied to each predicate in an input sentence.
Fordetails see (Kawahara and Kurohashi, 2002).coreference analysis Coreference analysis is per-formed by using the coreference analyzer proposedby (Sasano et al, 2007).
As will be mentioned inSection 4.4.2, our NER system uses coreference re-lations only when coreferential expressions do notshare same morphemes.
Basically, such coreferencerelations are recognized by using automatically ac-quired synonym knowledge.4.4 Feature Extraction4.4.1 Basic FeaturesAs basic features for chunking, our NER systemuses the morpheme itself, character type, POS tagand category if it exists.As character types, we defined seven types:?kanji,?
?hiragana,?
?katakana,?
?kanji with hira-gana,?
?punctuation mark,?
?alphabet?
and ?digit.
?As for POS tag, more than one POS feature areextracted if the target morpheme has POS ambigu-ity.
In addition, besides POS tag obtained by JU-MAN, our system also uses POS tag obtained fromJapanese morphological analyzer MeCab3 that usesIPADIC as a word dictionary (Asahara and Mat-sumoto, 2002).
The JUMAN dictionary has fewnamed entity entries; thus our system supplementsthe lack of lexical knowledge by using MeCab.4.4.2 Structural FeaturesOur NER system uses three types of global fea-tures: cache features, syntactic features and case-frame features, and a rule that reflects coreferencerelations.
Although the coreference relations are notused as features, we describe how to use them in thissection.cache feature If the same morpheme appears mul-tiple times in a single document, in most cases theNE tags of these morphemes have some relation toeach other, and the NER results for previous partsof the document can be a clue for the analysis forfollowing parts.We consider the examples (2) and (3) again.
Al-though the second sentences of (2) and (3) are ex-actly the same, we can recognize ?Kawasaki?
inthe second sentence of (2) is ?S-PERSON?
and?Kawasaki?
in the second sentence of (3) is ?S-ORGANIZATION?
by reading the first sentences.To utilize the information obtained from previousparts of the document, our system uses the NERresults for previous parts of the document as fea-tures, called cache features.
When analyzing (2),our system uses the outputs of NE recognizer for3http://mecab.sourceforge.jp/609?Kawasaki?
in the first sentence as a feature for?Kawasaki?
in the second sentence.
For simplicity,our system uses correct NE tags when training.
Thatis, as a feature for ?Kawasaki?
in the second sen-tence of (2), the correct feature ?B-PERSON?
is al-ways added when training, not always added whenanalyzing.coreference rule Coreference relation can be aclue for NER.
This clue is considered by using cachefeatures to a certain extent.
However, if the samemorpheme is not used, cache features cannot work.For example, ?NHK kokyo gakudan?
and ?N-kyo?in (5) have coreference relation, but they do notshare the same morpheme.
(5) NHK kokyo gakudan-no ongaku kantoku-nisymphony orchestra musical directorshuunin.
N-kyo-to kyoen-shite irai ... .became perform together since(He became musical director of the NHK SymphonyOrchestra.
Since performing together with N-kyo ...
.
)In this case, ?NHK kokyo gakudan?
can easily berecognized as ?ORGANIZATION,?
because it endswith ?kokyo gakudan (symphony orchestra).?
Mean-while, ?N-kyo,?
the abbreviation of ?NHK kokyogakudan,?
cannot easily be recognized as ?ORGA-NIZATION.
?Therefore, our system uses a heuristic rule that ifa morpheme sequence is analyzed to be coreferentialto a previous morpheme sequence that is recognizedas an NE class, the latter morpheme sequence is rec-ognized as the same NE class.
Since this heuristicrule is introduced in order to utilize the coreferencerelation that is not reflected by cache features, oursystem applies this rule only when coreferential ex-pressions do not have any morphemes in common.syntactic feature As mentioned in Section 3, oursystem utilizes the information obtained from thehead verb.
As syntactic features, our system uses thehead verb itself and the surface case of the bunsetsuthat includes the target morpheme.For the morpheme ?shin?
in example (4), thehead verb ?wataru (get across)?
and the surface case?kara (from)?
are added as syntactic features.caseframe feature Syntactic features cannot workif the head verb does not appear in the training data.To overcome this data sparseness problem, case-frame features are introduced.Table 2: Case frame of ?haken (dispatch).
?case examplesga Japan:23,party:13,country:12,government:7,(nominative) company6,ward:6,corps:5,UN:4,US:4,Korea:4,team:4,. .
.
(ORGANIZATION,LOCATION)wo party:1249,him:1017,soldier:932,official:906,(objective) company6:214,instructor:823,expert:799,helper:694,staff:398,army:347,. .
.ni Iraq:700,on-the-scene:576,abroad:335,(locative) home:172,Japan:171,Indirect Ocean:142,scene:141,China:125,. .
.
(LOCATION)For example, although the head verb ?haken (dis-patch)?
can be a clue for recognizing ?ICAO?
in(6) as ?ORGANIZATION,?
syntactic features can-not work if ?haken (dispatch)?
did not appear in thetraining data.
(6) ICAO-ha genchi-ni senmonka-wo haken-shita.scene to expert dispatched(ICAO dispatched experts to the scene)However, this clue can be utilized if there is knowl-edge that the ?ga (nominative)?
case of ?haken (dis-patch)?
is often assigned by ?ORGANIZATION.
?Therefore, we construct case frames that includeNE labels in advance.
Case frames describe whatkinds of cases each verb has and what kinds of nounscan fill a case slot.
We construct them from aboutfive hundred million sentences.
We first recognizeNEs appearing in the sentences by using a primitiveNER system that uses only local features, and thenconstruct the case frames from the NE-recognizedsentences.
To be more specific, if one tenth of theexamples of a case are classified as a certain NEclass, the corresponding label is attached to the case.Table 2 shows the constructed case frame of ?haken(dispatch).?
In the ?ga (nominative)?
case, the NElabels, ?ORGANIZATION?
and ?LOCATION?
areattached.We then explain how to utilize these case frames.Our system first performs case analysis, and uses ascaseframe features the NE labels attached in the caseto which the target morpheme is assigned.
For in-stance, by the case analyzer, the postpositional par-ticle ?-ha?
in (6) is recognized as meaning nom-inative and ?ICAO?
is assigned to the ?ga (nom-inative)?
case of the case frame of ?haken (dis-patch).
?Therefore, the caseframe features, ?ORGA-NIZATION?
and ?LOCATION?
are added to thefeatures for the morpheme ?ICAO.
?4.5 SVM and Viterbi Search Based ChunkingTo utilize cache features obtained from the previousparts of the same sentence, our system determines610Table 3: Experimental results (F-measure).CRL IREX WEBbaseline 88.63 85.47 68.98+ cache 88.81 +0.18* 85.94 +0.47 69.67 +0.69*+ coreference 88.68 +0.05 86.52 +1.05*** 69.17 +0.19+ syntactic 88.80 +0.17* 85.77 +0.30 70.25 +1.27**+ caseframe 88.57?0.06 85.51 +0.04 70.12 +1.14*+ thesaurus 88.77 +0.14 86.36 +0.89* 68.63?0.35use all 89.40 +0.77*** 87.72 +2.25*** 71.03 +2.05***significant at the .1 level:*, .01 level:**, .001 level:***NE tags clause by clause.
The features extractedfrom two preceding morphemes and two succeed-ing morphemes are also used for chunking a targetmorpheme.
Since SVM can solve only a two-classproblem, we have to extend a binary classifier SVMto n-class classifier.
Here, we employ the one versusrest method, in which we prepared n binary classi-fiers and each classifier is trained to distinguish aclass from the rest of the classes.To consider consistency of NE tags in a clause,our system uses Viterbi search with some constraintssuch as a ?B-DATE?
must be followed by ?I-DATE?or ?E-DATE.?
Since SVMs do not output proba-bilities, our system uses the SVM+sigmoid method(Platt et al, 2000).
That is, a sigmoid functions(x) = 1/(1+exp(?
?x)) is applied to map the out-put of SVM to a probability-like value.
Our systemdetermines NE tags by using these probability-likevalues.
Our system is trained by TinySVM-0.094with C = 0.1 and uses a fixed value ?
= 10.
Thisprocess is almost the same as the process proposedby Isozaki and Kazawa and for details see (Isozakiand Kazawa, 2003).5 Experiments5.1 DataFor training, we use CRL NE data, which was pre-pared for IREX.
CRL NE data has 18,677 NEs on1,174 articles in Mainichi Newspaper.For evaluation, we use three data: CRL NE data,IREX?s formal test data called GENERAL andWEBNE data.
When using CRL NE data for evalua-tion, we perform five-fold cross-validation.
IREXtest data has 1,510 NEs in 71 articles from MainichiNewspaper.
Although both CRL NE data and IREXtest data use Mainichi Newspaper, these formats arenot the same.
For example, CRL NE data removesparenthesis expressions, but IREX test data does not.WEB NE data, which we annotated NEs on corpuscollected from the Web, has 1,686 NEs in 354 arti-4http://chasen.org/ taku/software/TinySVM/cles.
Although the domain of the web corpus differsfrom that of CRL NE data, the format of the webcorpus is the same as CRL NE data format.5.2 Experiments and DiscussionTo confirm the effect of each feature, we conductedexperiments on seven conditions as follows:1.
Use only basic features (baseline)2.
Add cache features to baseline3.
Add the coreference rule to baseline4.
Add parent features to baseline5.
Add caseframe features to baseline6.
Add thesaurus features to baseline7.
Use all structural information and thesaurusSince (Masayuki andMatsumoto, 2003; Nakano andHirai, 2004) reported the performance of NER sys-tem was improved by using a thesaurus, we alsoconducted experiment in which semantic classes ob-tained from a Japanese thesaurus ?Bunrui Goi Hyo?
(NLRI, 1993) were added to the SVM features.
Ta-ble 3 shows the experimental results.To judge the statistical significance of the dif-ferences between the performance of the baselinesystem and that of the others, we conducted aMcNemar-like test.
First, we extract the outputs thatdiffer between the baseline method and the targetmethod.
Then, we count the number of the outputsthat only baseline method is correct and that onlytarget method is correct.
Here, we assume that theseoutputs have the binomial distribution and apply bi-nomial test.
As significance level, we use .1 level,.01 level and .001 level.
The results of the signifi-cance tests are also shown in Table 3.When comparing the performance between datasets, we can say that the performance for WEB NEdata is much worse than the others.
This may bebecause the domain of the WEB corpus differs fromthat of CRL NE data.As for the differences in the same data set, cachefeatures and syntactic features improve the perfor-mance not dramatically but consistently and inde-pendently from the data set.
The coreference rulealso improves the performance for all data sets, butespecially for IREX test data.
This may be becauseIREX test data does not remove parenthesis expres-sions, and thus there are a many coreferential ex-pressions in the data.
Caseframe features improvethe performance for WEB NE data, but do not con-tribute to the performance for CRL NE data and611Table 4: Comparison with previous work.CRL cross IREX Learning Analysis Featuresvalidation test data Method Units(Isozaki and Kazawa, 2003) 86.77 85.10 SVM + Viterbi morpheme basic features(Masayuki and Matsumoto, 2003) 87.21 SVM character +thesaurus(Fukuoka, 2006) 87.71 Semi-Markov CRF character basic features(Yamada, 2007) 88.33 SVM + Shift-Reduce morpheme +bunsetsu features(Nakano and Hirai, 2004) 89.03 SVM character +bunsetsu features & thesaurusOur system 89.40 87.72 SVM + Viterbi morpheme +structural information & thesaurusIREX test data.
This result shows that caseframefeatures are very generalized features and effectivefor data of different domain.
On the other hand, the-saurus features improve the performance for CRLNE data and IREX test data, but worsen the perfor-mance for WEB NE data.
The main cause for thismay be overfitting to the domain of the training data.By using all structural information, the perfor-mance is significantly improved for all data sets, andthus we can say that the structural information im-proves the performance of NER.5.3 Comparison with Previous WorkTable 4 shows the comparison with previous workfor CRL NE data and IREX test data.
Our systemoutperforms all other systems, and thus we can con-firm the effectiveness of our approach.6 ConclusionIn this paper, we presented an approach that usesstructural information for Japanese NER.
We in-troduced four types of structural information to anSVM-based NER system: cache features, coref-erence relations, syntactic features and caseframefeatures, and conducted NER experiments on threedata.
As a consequence, the performance of NERwas improved by using structural information andour approach achieved a higher F-measure than ex-isting approaches.ReferencesMasayuki Asahara and Yuji Matsumoto, 2002.
IPADIC UserManual.
Nara Institute of Science and Technology, Japan.Hai Leong Chieu and Hwee Tou Ng.
2002.
Named entityrecognition: A maximum entropy approach using global in-formation.
In Proc.
of COLING 2002, pages 1?7.Kenta Fukuoka.
2006.
Named entity extraction with semi-markov conditional random fields (in Japanese).
Master?sthesis, Nara Institute of Science and Technology.IREX Committee, editor.
1999.
Proc.
of the IREX Workshop.Hideki Isozaki and Hideto Kazawa.
2003.
Speeding upsupport vector machines for named entity recognition (injapanese).
Trans.
of Information Processing Society ofJapan, 44(3):970?979.Heng Ji and Ralph Grishman.
2005.
Improving name taggingby reference resolution and relation detection.
In Proc.
ofACL-2005, pages 411?418.Daisuke Kawahara and Sadao Kurohashi.
2002.
Fertilization ofCase Frame Dictionary for Robust Japanese Case Analysis.In Proc.
of COLING-2002, pages 425?431.Sadao Kurohashi and Daisuke Kawahara.
2005.
Japanese mor-phological analysis system JUMAN version 5.1 manual.Sadao Kurohashi and Makoto Nagao.
1994.
A syntactic anal-ysis method of long Japanese sentences based on the detec-tion of conjunctive structures.
Computational Linguistics,20(4):507?534.R.
Malouf.
2002.
Markov models for language-independentnamed entity recognition.
In Proc.
of CoNLL-2002, pages187?190.Asahara Masayuki and Yuji Matsumoto.
2003.
Japanesenamed entity extraction with redundant morphological anal-ysis.
In Proc.
of HLT-NAACL 2003, pages 8?15.Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita, YoshitakaHirano, Hiroshi Matsuda, Kazuma Takaoka, and MasayukiAsahara.
2003.
Morphological analysis System chasen2.3.3 users manual.Behrang Mohit and Rebecca Hwa.
2005.
Syntax-based semi-supervised named entity tagging.
In Proc.
of ACL InteractivePoster and Demonstration Sessoins, pages 57?60.MUC-6.
1995.
Proc.
of the Sixth Message Understanding Con-ference.
Morgan Kaufmann Publishers, INC.Keigo Nakano and Yuzo Hirai.
2004.
Japanese named entityextraction with bunsetsu features (in Japanese).
Trans.
ofInformation Processing Society of Japan, 45(3):934?941.The National Language Institute for Japanese Language, NLRI,editor.
1993.
Bunrui Goi Hyo (in Japanese).
Shuuei Pub-lishing.John C. Platt, Nello Cristiani, and John ShaweTaylor.
2000.Lage margin DAGs for multiclas classification.
In Advancesin Neural Information Processing System 12.Ryohei Sasano, Daisuke Kawahara, and Sadao Kurohashi.2007.
Improving coreference resolution using bridging ref-erence resolution and automatically acquired synonyms.
InProc.
of DAARC-2007.Takehito Utsuro, Manabu Sassano, and Kiyotaka Uchimoto.2002.
Combing outputs of multiple named entity chunkersby stacking.
In Proc.
of EMNLP-2002.Hiroyasu Yamada.
2007.
Shift reduce chunking for Japanesenamed entity extraction (in Japanese).
In IPSJ SIG NotesNL-179-3, pages 13?18.612
