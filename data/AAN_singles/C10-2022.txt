Coling 2010: Poster Volume, pages 189?196,Beijing, August 2010Unsupervised cleansing of noisy textDanish ContractorIBM India Software Labsdcontrac@in.ibm.comTanveer A. FaruquieIBM Research Indiaftanveer@in.ibm.comL.
Venkata SubramaniamIBM Research Indialvsubram@in.ibm.comAbstractIn this paper we look at the problem ofcleansing noisy text using a statistical ma-chine translation model.
Noisy text is pro-duced in informal communications suchas Short Message Service (SMS), Twit-ter and chat.
A typical Statistical Ma-chine Translation system is trained on par-allel text comprising noisy and clean sen-tences.
In this paper we propose an un-supervised method for the translation ofnoisy text to clean text.
Our method hastwo steps.
For a given noisy sentence, aweighted list of possible clean tokens foreach noisy token are obtained.
The cleansentence is then obtained by maximizingthe product of the weighted lists and thelanguage model scores.1 IntroductionNoisy unstructured text data is found in informalsettings such as Short Message Service (SMS),online chat, email, social message boards, news-group postings, blogs, wikis and web pages.
Suchtext may contain spelling errors, abbreviations,non-standard terminology, missing punctuation,misleading case information, as well as falsestarts, repetitions, and special characters.We define noise in text as any kind of differencebetween the surface form of a coded representa-tion of the text and the correct text.
The SMS ?ukno whn is d last train of delhi metro?
is noisybecause several of the words are not spelled cor-rectly and there are grammar mistakes.
Obviouslythe person who wrote this message intended towrite exactly what is there in the SMS.
But still itis considered noisy because the message is codedusing non-standard spellings and grammar.Current statistical machine translation (SMT)systems rely on large parallel and monolingualtraining corpora to produce high quality transla-tions (Brown et al, 1993).
Most of the large paral-lel corpora available comprise newswire data thatinclude well formed sentences.
Even when websources are used to train a SMT system, noisy por-tions of the corpora are eliminated (Imamura etal., 2003) (Imamura and Sumita, 2002) (Khadiviand Ney, 2005).
This is because it is known thatnoise in parallel corpora results in incorrect train-ing of models thus degrading the performance.We are not aware of sufficiently large paral-lel datasets comprising noisy and clean sentences.In fact, even dictionaries comprising of noisy toclean mappings in one language are very limitedin size.With the increase in noisy text data generatedin various social communication media, cleans-ing of such text has become necessary.
The lackof noisy parallel datasets means that this prob-lem cannot be tackled in the traditional SMT way,where translation models are learned based on theparallel dataset.
Consider the problem of translat-ing a noisy English sentence e to a clean Englishsentence h. SMT imagines that e was originallyconceived in clean English which when transmit-ted over the noisy channel got corrupted and be-came a noisy English sentence.
The objective ofSMT is to recover the original clean sentence.189The goal of this paper is to analyze how noisecan be tackled.
We present techniques to trans-late noisy text sentences e to clean text sentencesh.
We show that it is possible to clean noisy textin an unsupervised fashion by incorporating stepsto construct ranked lists of possible clean Englishtokens and then searching for the best clean sen-tence.
Of course as we will show for a given noisysentence, several clean sentences are possible.
Weexploit the statistical machine learning paradigmto let the decoder pick the best alternative fromthese possible clean options to give the final trans-lation for a given noisy sentence.The rest of the paper is organized as follows.In section 2 we state our contributions and givean overview of our approach.
In Section 3 wedescribe the theory behind clean noisy text usingMT.
In Section 4 we explain how we use a weigh-ing function and a plain text dictionary of cleantokens to guess possible clean English languagetokens.
Section 5 describes our system along withour results.
We have given an analysis of the kindof noise present in our data set in section 5.22 Our ApproachIn this paper we describe an unsupervised methodto clean noisy text.
We formulate the text cleans-ing problem in the machine translation frameworkusing translation model 1 (Brown et al, 1993).We clean the text using a pseudo-translationmodel of clean and noisy words along with a lan-guage model trained using a large monolingualcorpus.
We use a decoder to search for the bestclean sentence for a noisy sentence using thesemodels.We generate scores for the pseudo translationmodel using a weighing function for each token inan SMS and use these scores along with languagemodel probabilities to hypothesize the best cleansentence for a given noisy SMS.
Our approach canbe summarized in the following steps:?
Tokenize noisy SMS S into n tokens s1, s2 ...sn.
For each SMS token si create a weightedlist based on a weighing function.
These listsalong with their scores corresponds to thetranslation probabilities of the SMT transla-tion model.?
Use the lists generated in the step abovealong with clean text language model scores,in a decoder to hypothesize the best cleansentence?
At the end of the search choose the highestscoring sentence as the clean translation ofthe noisy sentenceIn the above approach we do not learn the trans-lation model but emulate the translation modelduring decoding by analyzing the noise of the to-kens in the input sentence.3 Noisy sentence translationStatistical Translation models were invented byBrown, et al(Brown et al, 1993) and are basedon the source-channel paradigm of communica-tion theory.
Consider the problem of translating anoisy sentence e to a clean sentence h. We imag-ine that e was originally conceived cleanly whichwhen transmitted over the noisy communicationchannel got corrupted and became a noisy sen-tence.
The goal is to get back the original cleansentence from the noisy sentence.
This can be ex-pressed mathematically ash?
= argmaxhPr(h|e)By Bayes?
Theoremh?
= argmaxhPr(e|h)Pr(h)Conceptually, the probability distributionP (e|h) is a table which associates a probabilityscore with every possible pair of clean and noisysentences (e, h).
Every noisy sentence e is acandidate translation of a given clean sentence h.The goodness of the translation h?
e is given bythe probability score of the pair (e, h).
Similarly,Pr(h) is a table which associates a probabilityscore with every possible clean sentence h andmeasures how well formed the sentence h is.It is impractical to construct these tables exactlyby examining individual sentences (and sentencepairs) since the number of conceivable sentencesin any language is countably infinite.
Therefore,the challenge in Statistical Machine Translationis to construct approximations to the probability190distributions P (e|h) and Pr(h) that give an ac-ceptable quality of translation.
In the next sectionwe describe a model which is used to approximateP (e|h).3.1 IBM Translation Model 2IBM translation model 2 is a generative model,i.e., it describes how a noisy sentence e could bestochastically generated given a clean sentence h.It works as follows:?
Given a clean sentence h of length l, choosethe length (m) for the noisy sentence from adistribution (m|l).?
For each position j = 1, 2, .
.
.m in the noisystring, choose a position aj in the clean stringfrom a distribution a(aj |j, l,m).
The map-ping a = (a1, a2, .
.
.
, am) is known as align-ment between the noisy sentence e and theclean sentence h. An alignment between eand h tells which word of e is the corruptedversion of the corresponding word of h.?
For each j = 1, 2, .
.
.m in the noisy string,choose an noisy word ej according to the dis-tribution t(ej |haj ).It follows from the generative model that prob-ability of generating e = e1e2 .
.
.
em given h =h1h2 .
.
.
hl with alignment a = (a1, a2, .
.
.
, am)isPr(e, a|h) = (m|l)m?j=1t(ej |haj )a(aj |j,m, l).It can be easily seen that a sentence e could beproduced from h employing many alignments andtherefore, the probability of generating e givenh is the sum of the probabilities of generatinge given h under all possible alignments a, i.e.,Pr(e|h) =?a Pr(e, a|h).
Therefore,Pr(e|h) =(m|l)l?a1=0..l?am=0m?j=1t(ej |haj )a(aj |j,m, l).The above expression can be rewritten as follows:Pr(e|h) = (m|l)m?j=1l?i=0t(ej |hi)a(i|j,m, l).Typical statistical machine translation systemsuse large parallel corpora to learn the transla-tion probabilities (Brown et al, 1993).
Tradi-tionally such corpora have consisted of news ar-ticles and other well written articles.
Thereforein theory P (e|h) should be constructed by ex-amining sentence pairs of clean and noisy sen-tences.
There exists some work to remove noisefrom SMS (Choudhury et al, 2007) (Byun et al,2008) (Aw et al, 2006) (Neef et al, 2007) (Kobuset al, 2008).
However, all of these techniques re-quire an aligned corpus of SMS and conventionallanguage for training.Aligned parallel corpora for noisy sentence isdifficult to obtain.
This lack of data for a lan-guage and the domain dependence of noise makesit impractical to construct corpus from whichP (e|h) can be learnt automatically.
This leadsto difficulty in learning P (e|h).
Fortunately thealignment between clean and noisy sentences aremonotonic in nature hence we assume a uniformdistribution for a(i|j,m, l) held fixed at (l+1)?1.This is equivalent to model 1 of IBM translationmodel.
The translation models t(ej |haj ) can bethought of as a ranked list of noisy words givena clean word.
In section 4.2 we show how thisranked list can be constructed in an unsupervisedfashion.3.2 Language ModelThe problem of estimating the sentence forma-tion distribution Pr(h) is known as the lan-guage modeling problem.
The language mod-eling problem is well studied in literature par-ticularly in the context of speech recognition.Typically, the probability of a n-word sentenceh = h1h2 .
.
.
hn is modeled as Pr(h) =Pr(h1|H1)Pr(h2|H2) .
.
.
P r(hn|Hn), where Hiis the history of the ith word hi.
One of the mostpopular language models is the n-gram model(Brown et al, 1993) where the history of a wordconsists o f the word and the previous n?1 wordsin the sentence, i.e., Hi = hihi?1 .
.
.
hi?n+1.
Inour application we use a smoothed trigram model.3.3 DecodingThe problem of searching for a sentence h whichminimizes the product of translation model prob-191ability and the language model probability isknown as the decoding problem.
The decodingproblem has been proved to be NP-complete evenwhen the translation model is IBM model 1 andthe language model is bi-gram (K Knight., 1999).Effective suboptimal search schemes have beenproposed (F. Jelinek, 1969), (C. Tillman et al,1997).4 Pseudo Translation ModelIn order to be able to exploit the SMT paradigmwe first construct a pseudo translation model.
Thefirst step in this direction is to create noisy tokento clean token mapping.
In order to process thenoisy input we first have to map noisy tokens innoisy sentence, Se, to the possible correct lexicalrepresentations.
We use a similarity measure tomap the noisy tokens to their clean lexical repre-sentations .4.1 Similarity MeasureFor a term te ?
De, where De is a dictionary ofpossible clean tokens, and token si of the noisyinput Se, the similarity measure ?
(te, si) betweenthem is?
(te, si) =??????????????
?LCSRatio(te,si)EditDistanceSMS(te,si) if te and si sharesame startingcharacter0 otherwise(1)where LCSRatio(te, si) = length(LCS(te,si))length(te) andLCS(te, si) is the Longest common subsequencebetween te and si.
The intuition behind this mea-sure is that people typically type the first few char-acters of a word in an SMS correctly.
This way welimit the possible variants for a particular noisy to-ken.The Longest Common Subsequence Ratio (LC-SRatio) (Melamed et al, 1999) of two strings isthe ratio of the length of their LCS and the lengthof the longer string.
Since in the SMS scenario,the dictionary term will always be longer than theSMS token, the denominator of LCSR is taken asthe length of the dictionary term.The EditDistanceSMS (Figure 1) comparesthe Consonant Skeletons (Prochasson et al, 2007)of the dictionary term and the SMS token.
If theLevenshtein distance between consonant skele-tons is small then ?
(te, si) will be high.
The intu-ition behind using EditDistanceSMS can be ex-plained through an example.
Consider an SMStoken ?gud?
whose most likely correct form is?good?.
The two dictionary terms ?good?
and?guided?
have the same LCSRatio of 0.5 w.r.t?gud?, but the EditDistanceSMS of ?good?
is1 which is less than that of ?guided?, which hasEditDistanceSMS of 2 w.r.t ?gud?.
As a re-sult the similarity measure between ?gud?
and?good?
will be higher than that of ?gud?
and?guided?.
Higher the LCSRatio and lower theEditDistanceSMS , higher will be the similaritymeasure.
Hence, for a given SMS token ?byk?,the similarity measure of word ?bike?
is higherthan that of ?break?.In the next section we show how we usethis similarity measure to construct ranked lists.Ranked lists of clean tokens have also been usedin FAQ retrieval based on noisy queries (Kothariet al, 2009).Procedure EditDistanceSMS(te, si)Beginreturn LevenshteinDistance(CS(si), CS(te)) + 1EndProcedure CS (t): // Consonant Skeleton GenerationBeginStep 1. remove consecutive repeated characters in t// (fall?
fal)Step 2. remove all vowels in t//(painting ?
pntng, threat?
thrt)return tEndFigure 1: EditDistanceSMS4.2 List CreationFor a given noisy input string Se, we tokenize iton white space and replace any occurrence of dig-its to their string based form (e.g.
4get, 2day) toget a series of n tokens s1, s2, .
.
.
, sn.
A list Leiis created for each token si using terms in a dic-192hv u cmplted ure prj rprtd ddline fr sbmission of d rprt hs bn xtndedi wil be lte by 20 mnsd docs shd rech u in 2 daysthnk u for cmg 2 d prtyFigure 2: Sample SMS queriestionary De consisting of clean english words.
Aterm te from De is included in Lei if it satisfies thethreshold condition?
(te, si) > ?
(2)Heuristics are applied to boost scores of somewords based on positional properties of charactersin noisy and clean tokens.
The scores of the fol-lowing types of tokens are boosted:1.
Tokens that are a substring of a dictionarywords from the first character.2.
Tokens having the same first and last charac-ter as a dictionary word.3.
Token that are dictionary words themselves(clean text).The threshold value ?
is determined experimen-tally.
Thus we select only the top scoring possibleclean language tokens to construct the sentence.Once the list are constructed the similarity mea-sure along with the language model scores is usedby the decoding algorithm to find the best possi-ble English sentence.
It is to be noted that theselists are constructed at decoding time since theydepend on the noisy surface forms of words in theinput sentence.5 ExperimentsTo evaluate our system we used a set of 800 noisyEnglish SMSes sourced from the publicly avail-able National University of Singapore SMS cor-pus1 and a collection of SMSes available from theIndian Institute of Technology, Kharagpur.
TheSMSes are a collection of day-to-day SMS ex-changes between different users.
We manually1http://wing.comp.nus.edu.sg/downloads/smsCorpusFigure 3: System implementationBLEU scores 1-gram 2-gram 3-gram 4-gramNoisy text 40.96 63.7 45.1 34.5 28.3Cleaned text 53.90 77.5 58.7 47.4 39.5Table 1: BLEU scoresgenerated a cleaned english version of our test setto use as a reference.The noisy SMS tokens were used to generateclean text candidates as described in section 4.2.The dictionary De used for our experiments was aplain text list of 25,000 English words.
We cre-ated a tri-gram language model using a collec-tion of 100,000 clean text documents.
The docu-ments were a collection of articles on news, sport-ing events, literature, history etc.
For decodingwe used Moses2, which is an open source decoderfor SMT (Hoang et al, 2008), (Koehn et al,2007).
The noisy SMS along with clean candi-date token lists, for each SMS token and languagemodel probabilities were used by Moses to hy-pothesize the best clean english output for a givennoisy SMS.
The language model and translationmodels weights used by Moses during the decod-ing phase, were adjusted manually after some ex-perimentation.We used BLEU (Bilingual evaluation under-study) and Word error rate (WER) to evaluate theperformance of our system.
BLEU is used to2http://www.statmt.org/moses/193Figure 4: Comparison of BLEU scoresestablish similarity between a system translatedand human generated reference text.
A noisySMS ideally has only one possible clean transla-tion and all human evaluators are likely to providethe same translation.
Thus, BLEU which makesuse of n-gram comparisons between reference andsystem generated text, is very useful to measurethe accuracy of our system.
As shown in Fig 4, our system reported significantly higher BLEUscores than unprocessed noisy text.The word error rate is defined asWER = S +D + IN (3)where S is the number of substitutions, D is thenumber of the deletions, I is the number of the in-sertions and N is the number of words in the refer-ence The WER can be thought of as an executionof the Levenstein Edit distance algorithm at thetoken level instead of character level.Fig 5 shows a comparison of the WER.
Sen-tences generated from our system had 10 % lowerWER as compared to the unprocessed noisy sen-tences.
In addition, the sentences generated by oursystem match a higher number of tokens (words)with the reference sentences, as compared to thenoisy sentences.5.1 System performanceUnlike standard MT system when P (e|h) is pre-computed during the training time, list generationin our system is dynamic because it depends onthe noisy words present in the input sentence.
Inthis section we evaluate the computation time forlist generation along with the decoding time forfinding the best list.
We used an Intel Core 2Duo 2.2 GHz processor with 3 GB DDR2 RAMFigure 5: Word error ratesFigure 6: Execution time slicesto implement our system.
As shown in Fig 6 theadditional computation involving list creation etctakes up 56% (90 milliseconds) of total translationtime.
43% of the total execution time is taken bythe decoder, while I/O operations take only 1% ofthe total execution time.
The decoder executiontime slices reported above exclude the time takento load the language model.
Moses took approxi-mately 10 seconds to load our language model.5.2 Measuring noise level in SMS queriesThe noise in the collected SMS corpus can be cat-egorized as follows1.
Removal of characters : The commonly ob-served patterns include deletion of vowels(as in ?msg?
for ?message?
), deletion of re-peated character (as in ?happy?
for ?hapy?
)and truncation (as in ?tue?
for ?tuesday?
)Type of Noise % of Total Noisy TokensDeletion of Characters 48%Phonetic Substitution 33%Abbreviations 5%Dialectical Usage 4%Deletion of Words 1.2%Table 2: Measure of Types of SMS Noise194Clean (Reference) text Noisy text Output textPerplexity 19.61 34.56 21.77Table 3: Perplexity for Reference, Noisy CleanedSMS2.
Phonetic substitution: For example, ?2?
for?to?
or ?too?, ?lyf??
for ?life?, ?lite?
for?light?
etc.3.
Abbreviation: Some frequently used abbre-viations are ?tb?
for ?text back?, ?lol?
for?laughs out loud?, ?AFAICT?
for ?as far asi can tell?
etc.4.
Dialectal and informal usage: Often multiplewords are combined into a single token fol-lowing certain dialectal conventions.
For ex-ample, ?gonna?
is used for ?going to?, ?aint?is used for ?are not?, etc.5.
Deletion of words: Function words (e.g.
ar-ticles) and pronouns are commonly deleted.
?I am reading the book?
for example may betyped as ?readin bk?.Table 2 lists statistics on these noise types from101 SMSes selected at random from our data set.The average length of these SMSes was 13 words.Out of the total number of words in the SMSes,52% were non standard words.
Table 2 lists thestatistics for the types of noise present in these nonstandard words.Measuring character level perplexity can be an-other way of estimating noise in the SMS lan-guage.The perplexity of a LM on a corpus givesan indication of the average number of bits neededper n-gram to encode the corpus.
Noise resultsin the introduction of many previously unseenn-grams in the corpus.
Higher number of bitsare needed to encode these improbable n-gramswhich results in increased perplexity.We built a character-level language model (LM)using a document collection (vocabulary size is20K) and computed the perplexity of the languagemodel on the noisy and the cleaned SMS test-setand the SMS reference data.From Table 3 we can see the difference in per-plexity for noisy and clean SMS data.
Large per-plexity values for the SMS dataset indicates a highlevel of noise.
The perplexity evaluation indicatesthat our method is able to remove noise from theinput queries as given by the perplexity and isclose to the human correct reference corpus whoseperplexity is 19.61.6 ConclusionWe have presented an inexpensive, unsupervisedmethod to clean noisy text.
It does not requirethe use of a noisy to clean language parallel cor-pus for training.
We show how a simple weigh-ing function based on observed heuristics and avocabulary file can be used to shortlist clean to-kens.
These tokens and their weights are usedalong with language model scores, by a decoderto select the best clean language sentence.ReferencesMonojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, Anupam Basu.
2007.Investigation and modeling of the structure of tex-ting language.
International Journal on DocumentAnalysis and Recognition.Jeunghyun Byun, Seung-Wook Lee, Young-In Song,Hae-Chang Rim.
2008.
Two Phase Model for SMSText Messages Refinement.
In Proceedings of AAAIWorkshop on Enhanced Messaging.Aiti Aw, Min Zhang, Juan Xiao, and Jian Su.
2006.
Aphrase-based statistical model for SMS text normal-ization.
In Proceedings of COLING-ACL.Guimier de Neef, Emilie, Arnaud Debeurme, andJungyeul Park.
2007.
TILT correcteur de SMS :Evaluation et bilan quantitatif.
In Actes de TALN,Toulouse, France.Catherine Kobus, Francois Yvon and GeraldineDamnati.
2008.
Normalizing SMS: Are twometaphors better than one?
In Proceedings of COL-ING, Manchester.Sreangsu Acharya, Sumit Negi, L Venkata Subrama-niam, Shourya Roy.
2009.
Language independentunsupervised learning of short message service di-alect.
International Journal on Document Analysisand Recognition.Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,Christopher Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-tine Moran, Richard Zens, Chris Dyer, Ondrej Bo-jar, Alexandra Constantin, Evan Herbst 2007.Moses: Open source toolkit for statistical machine195translation.
In Proceedings of ACL, DemonstrationSession .Peter F. Brown, Vincent J.Della Pietra, Stephen A.Della Pietra, Robert.
L. Mercer 1993.
The Math-ematics of Statistical Machine Translation: Parame-ter Estimation Computational Linguistics.I.
D. Melamed.
1999.
Bitext maps and alignment viapattern recognition.
Computational Linguistics.E.
Prochasson, C. Viard-Gaudin, and E. Morin.
2007.Language models for handwritten short messageservices.
In Proceedings of ICDAR.S.
Khadivi and H. Ney.
2005.
Automatic filtering ofbilingual corpora for statistical machine translation.In Proceedings of NLDB, pages 263?274, 2005.K.
Imamura and E. Sumita.
2002.
Bilingual corpuscleaning focusing on translation literality.
In In Pro-ceedings of ICSLP.K.
Imamura, E. Sumita, and Y. Matsumoto.
2003.
Au-tomatic construction of machine translation knowl-edge using translation literalness.
In In Proceedingsof EACL.K.
Knight, 1999.
Decoding complexity in word re-placement translation models.
Computational Lin-guistics.F.
Jelinek, 1969.
A fast sequential decoding algorithmusing a stack.
IBM Journal of Research and Devel-opment.C.
Tillman, S. Vogel, H. Ney, and A. Zubiaga.
1997.A DP-based search using monotone alignments instatistical translation.
In Proceedings of ACL.Hieu Hoang, Philipp Koehn.
2008.
Design of theMoses decoder for statistical machine translation.In Proceedings of ACL Workshop on Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing.Govind Kothari, Sumit Negi, Tanveer A. Faruquie,Venkatesan T. Chakraverthy, L. Venkata Subrama-niam.
2009.
SMS based interface for FAQ retrieval,In In Proceedings of ACL-IJCNLP196
