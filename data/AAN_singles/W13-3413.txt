Proceedings of the Fourth Workshop on Teaching Natural Language Processing, pages 85?92,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsSemantic Technologies in IBM WatsonTMAlfio GliozzoIBM Watson Research CenterYorktown Heights, NY 10598gliozzo@us.ibm.comOr BiranColumbia UniversityNew York, NY 10027orb@cs.columbia.eduSiddharth PatwardhanIBM Watson Research CenterYorktown Heights, NY 10598siddharth@us.ibm.comKathleen McKeownColumbia UniversityNew York, NY 10027kathy@cs.columbia.eduAbstractThis paper describes a seminar course de-signed by IBM and Columbia Universityon the topic of Semantic Technologies,in particular as used in IBM WatsonTM?
a large scale Question Answering sys-tem which famously won at Jeopardy!
R?against two human grand champions.
Itwas first offered at Columbia Universityduring the 2013 spring semester, and willbe offered at other institutions starting inthe fall semester.
We describe the course?sfirst successful run and its unique features:a class centered around a specific indus-trial technology; a large-scale class projectwhich student teams can choose to par-ticipate in and which serves as the ba-sis for an open source project that willcontinue to grow each time the course isoffered; publishable papers, demos andstart-up ideas; evidence that the course canbe self-evaluating, which makes it poten-tially appropriate for an online setting; anda unique model where a large companytrains instructors and contributes to creat-ing educational material at no charge toqualifying institutions.1 IntroductionIn 2007, IBM Research took on the grand chal-lenge of building a computer system that can per-form well enough on open-domain question an-swering to compete with champions at the game ofJeopardy!
In 2011, the open-domain question an-swering system dubbed Watson beat the two high-est ranked players in a two-game Jeopardy!
match.To be successful at Jeopardy!, players must re-tain enormous amounts of information, must havestrong language skills, must be able to understandprecisely what is being asked, and must accuratelydetermine the likelihood they know the right an-swer.
Over a four year period, the team at IBMdeveloped the Watson system that competed onJeopardy!
and the underlying DeepQA questionanswering technology (Ferrucci et al 2010).
Wat-son played many games of Jeopardy!
against cel-ebrated Jeopardy!
champions and, in games tele-vised in February 2011, won against the greatestplayers of all time, Ken Jennings and Brad Rutter.DeepQA has applications well beyond Jeop-ardy!, however.
DeepQA is a software architec-ture for analyzing natural language content in bothquestions and knowledge sources.
DeepQA dis-covers and evaluates potential answers and gathersand scores evidence for those answers in both un-structured sources, such as natural language doc-uments, and structured sources such as relationaldatabases and knowledge bases.
Figure 1 presentsa high-level view of the DeepQA architecture.DeepQA utilizes a massively parallel, component-based pipeline architecture (Ferrucci, 2012) whichuses an extensible set of structured and unstruc-tured content sources as well as a broad range ofpluggable search and scoring components that al-low integration of many different analytic tech-niques.
Machine Learning techniques are used tolearn the weights for each scoring component inorder to combine them into a single final score.Watson components include a large variety of stateof the art solutions originating in the fields of Nat-ural Language Processing (NLP), Machine Learn-ing (ML), Information Retrieval (IR), SemanticWeb and Cloud Computing.
IBM is now aggres-sively investing in turning IBM Watson from a re-search prototype to an industry level highly adapt-able system to be applied in dozens of business ap-85Figure 1: Overview of the DeepQA architectureplications ranging from healthcare to finance (Fer-rucci et al 2012).Finding that particular combination of skills inthe entry-level job market is hard: in many casesstudents have some notion of Machine Learningbut are not strong in Natural Language Processing;in other cases they have background in KnowledgeManagement and some of the basics of SemanticWeb, but lack an understanding of statistical mod-els and Machine Learning.
In most cases semanticintegration is not a topic of interest, and so un-derstanding sophisticated platforms like ApacheUIMATM (Ferrucci and Lally, 2004) is a chal-lenge.
Learning how to develop the large scale in-frastructure and technology needed for IBM Wat-son prepares students for the real-world challengesof large-scale natural language projects that arecommon in industry settings and which studentshave little experience with before graduation.Of course, IBM is interested in hiring entry-level students as a powerful way of scaling Wat-son.
Therefore, it has resolved to start an ed-ucational program focused on these topics.
Ini-tially, tutorials were given at scientific conferences(NAACL, ISWC and WWW, among others), uni-versities and summer schools.
The great numberof attendees (usually in the range of 50 to 150)and strongly positive feedback received from thestudents was a motivation to transform the didac-tic material collected so far into a full graduate-level course, which has been offered for the firsttime at Columbia University.
The course (whichis described in the rest of this paper) received verypositive evaluations from the students and will beused as a template to be replicated by other part-ner universities in the following year.
Our ultimategoal is to develop high quality didactic materialfor an educational curriculum that can be used byinterested universities and professors all over theworld.2 Syllabus and Didactic MaterialThe syllabus1 is divided equally between classesspecifically on the Watson system, its architec-ture and technologies used within it, and classeson more general topics that are relevant to thesetechnologies.
In particular, background classes onNatural Language Processing; Distributional Se-mantics; the Semantic Web; Domain Adaptationand the UIMA framework are essential for under-standing the Watson system and producing suc-cessful projects.The course at Columbia included four lecturesby distinguished guest speakers from IBM, whichwere advertised to the general Columbia commu-nity as open talks.
Instead of exams, the courseincluded two workshop-style presentation days:one at the mid term and another at the end of the1The syllabus is accessible on line http://www.columbia.edu/?ag336686course.
During these workshops, all student teamsgave presentations on their various projects.
At themid-term workshop, teams presented their projectidea and timeline, as well as related work and thestate-of-the-art of the field.
At the final workshop,they presented their completed projects, final re-sults and demos.
This workshop was also madeopen to the Columbia community and in particu-lar to faculty and affiliates interested in start-ups.The workshops will be discussed in further detailin the following sections.
The syllabus is brieflydetailed here.?
Introduction: The Jeopardy!
ChallengeThe motivation behind Watson, the task andits challenges (Prager et al 2012; Tesauro etal., 2012; Lewis, 2012).?
The DeepQA Architecture Chu-Carroll etal.
(2012b), Ferrucci (2012), Chu-Carroll etal.
(2012a), Lally et al(2012).?
Natural Language Processing BackgroundPre-processing, tokenization, POS tagging,named entity recognition, syntactic parsing,semantic role labeling, word sense disam-biguation, evaluation best practices and met-rics.?
Natural Language Processing in WatsonMurdock et al(2012a), McCord et al(2012).?
Structured Knowledge in Watson Murdocket al(2012b), Kalyanpur et al(2012), Fan etal.
(2012).?
Semantic Web OWL, RDF, Semantic Webresources.?
Domain Adaptation Ferrucci et al(2012).?
UIMA The UIMA framework, Annotators,Types, Descriptors, tools.
Hands-on exercisewith the class project architecture (Epstein etal., 2012).?
Midterm Workshop Presentations of eachteam?s project idea and their research into re-lated work and the state of the art.?
Distributional Semantics Miller et al(2012), Gliozzo and Isabella (2005).?
Machine Learning and Strategy in Watson?
What Watson Tells Us About CognitiveComputing?
Final Workshop Presentations of eachteam?s final project implementation, evalua-tion, demo and future plans.3 Watson-like Architecture for ProjectsThe goal of the class projects was for the stu-dents to learn to design and develop language tech-nology components in an environment very sim-ilar to IBM?s Watson architecture.
We providedthe students with a plug-in framework for seman-tic search, into which they could integrate theirproject code.
Student projects will be describedin the following section.
This section details theframework that was made available to the studentsin order to develop their projects.Like the Watson system, the project frameworkfor this class was built on top of Apache UIMA(Ferrucci and Lally, 2004)2 ?
an open-sourcesoftware architecture for building applications thathandle unstructured information.The Watson system makes extensive use ofUIMA to enable interoperability and scale-out of alarge question answering system.
The architecture(viz., DeepQA) of Watson (Ferrucci, 2012) definesseveral high-level ?stages?
of analysis in the pro-cessing pipeline, such as Question and Topic Anal-ysis, Primary Search, Candidate Answer Genera-tion, etc.
Segmentation of the system into high-level stages enabled a group of 25 researchers atIBM to independently work on different aspectsof the system with little overhead for interoper-ability and system integration.
Each stage of thepipeline clearly defined the inputs and outputs ex-pected of components developed for that particu-lar stage.
The researchers needed only to adhereto these input/output requirements for their indi-vidual components to easily integrate them intothe system.
Furthermore, the high-level stages inWatson, enabled massive scale-out of the systemthrough the use of the asynchronous scaleout ca-pability of UIMA-AS.Using the Watson architecture for inspitration,we developed a semantic search framework for theclass projects.
As shown in Figure 2, the frame-work consists of a UIMA pipeline that has severalhigh-level stages (similar to those of the Watsonsystem):2http://uima.apache.org87Figure 2: Overview of the class project framework1.
Query Analysis2.
Primary Document Search3.
Structured Data Search4.
Query Expansion5.
Expanded Query Analysis6.
Secondary Document SearchThe input to this system is provided by a QueryCollection Reader, which reads a list of searchqueries from a text file.
The Query Collec-tion Reader is a UIMA ?collection reader?
thatreads the text queries into memory data struc-tures (UIMA CAS structures) ?
one for eachtext query.
These UIMA CASes flow through thepipeline and are processed by the various process-ing stages.
The processing stages are set up sothat new components designed to perform the taskof each processing stage can easily be added to thepipeline (or existing components easily modified).The expected inputs and outputs of components ineach processing stage are clearly defined, whichmakes the task of the team building the componentsimpler: they no longer have to deal with man-aging data structures and are spared the overheadof converting from and into formats of data ex-changed between various components.
All of theoverhead is handled by UIMA.
Furthermore, someof the processing stages generate new CAS struc-tures and the flow of all the UIMA CAS structuresthrough this pipeline is controlled by a ?Flow Con-troller?
designed by us for this framework.The framework was made available to each ofthe student teams, and their task was to buildtheir project by extending this framework.
Eventhough we built the framework to perform seman-tic search over a text corpus, many of the teamsin this course had projects that went far beyondjust semantic search.
Our hope was that each teamwould be able to able independently develop inter-esting new components for the processing stagesof the pipeline, and at the end of the course wewould be able to merge the most interesting com-ponents to create a single useful application.
In thefollowing section, we describe the various projectsundertaken by the student teams in the class, whileSection 5 discusses the integration of componentsfrom student projects and the demo applicationthat resulted from the integrated system.4 Class ProjectsProjects completed for this course fall into threetypes: scientific projects, where the aim is toproduce a publishable paper; integrated projects,where the aim is to create a component that will beintegrated into the class open-source project; andindependent demo projects, where the aim is toproduce an independent working demo/prototype.The following section describes the integratedprojects briefly.4.1 Selected Project DescriptionsAs described in section 3, the integrated classproject is a system with an architecture which, al-though greatly simplified, is reminiscent of Wat-son?s.
While originally intended to be simply asemantic search tool, some of the student teamscreated additional components which resulted ina full question answering system.
Those projects88as well as a few other related ones are describedbelow.Question Categorization: Using the DBPediaontology (Bizer et al 2009) as a semantictype system, this project classifies questionsby their answer type.
It can be seen as a sim-plified version of the question categorizationsystem in Watson.
The classification is basedon a simple bag-of-words approach with afew additional features.Answer Candidate Ranking: Given the answertype as well as additional features derived bythe semantic search component, this projectuses regression to rank the candidate an-swers which themselves come from semanticsearch.Twitter Semantic Search: Search in Twitter isdifficult due to the huge variations amongtweets in lexical terms, spelling and style, andthe limited length of the tweets.
This projectemploys LSA (Landauer and Dumais, 1997)to cluster similar tweets and increase searchaccuracy.Fine-Grained NER in the Open Domain: Thisproject uses DBPedia?s ontology as a typesystem for named entities of type Person.Given results from a standard NER system,it attempts to find the fine-grained classifica-tion of each Person entity by finding the mostsimilar type.
Similarity is computed usingtraditional distributional methods, using thecontext of the entity and the contexts of eachtype, collected from Wikipedia.News Frame Induction: Working with a largecorpus of news data collected by ColumbiaNewsblaster, this team used the MachineLinking API to tag entities with semantictypes.
From there, they distributionally col-lected ?frames?
prevalent in the news do-main such as ?
[U.S President] meeting with[British Prime Minister]?.Other projects took on problems such as SenseInduction, NER in the Biomedical domain, Se-mantic Role Labeling, Semantic Video Search,and a mobile app for Event Search.5 System Integration and DemonstrationThe UIMA-based architecture described in section3 allows us to achieve a relatively easy integra-tion of different class projects, independently de-veloped by different teams, in a common archi-tecture and expose their functionality with a com-bined class project demo.
The demo is a collab-oratively developed semantic search engine whichis able to retrieve knowledge from structured dataand visualize it for the user in a very concise way.The input is a query; it can be a natural languagequestion or simply a set of keywords.
The outputis a set of entities and their relations, visualizedas an entity graph.
Figure 3 shows the results ofthe current status of our class project demo on thefollowing Jeopardy!
question.This nation of 200 million has foughtsmall independence movements likethose in Aceh and East Timor.The output is a set of DBPedia entities related tothe question, grouped by Type (provided by theDBPedia ontology).
The correct answer, ?Indone-sia?, is among the candidate entities of type Place.Note that only answers of type Place and Agenthave been selected: this is due to the question cate-gorization component, implemented by one of thestudent teams, that allows us to restrict the gener-ated answer set to those answers having the righttypes.The demo will be hosted for one year fol-lowing the end of the course at http://watsonclass.no-ip.biz.
Our goal is toincrementally improve this demo, leveraging anynew projects developed in future versions of thecourse, and to build an open source software com-munity involving students taking the course.6 EvaluationThe course at Columbia drew a relatively large au-dience.
A typical size for a seminar course on aspecial topic is estimated at 15-20 students, whileours drew 35.
The vast majority were Master?s stu-dents; there were also three PhD students and fiveundergraduates.During the student workshops, students wereasked to provide grades for each team?s presen-tation and project.
After the instructor indepen-dently gave his own grades, we looked at the cor-relation between the average grades given by thestudents and those give by the instructor.
While89Figure 3: Screenshot of the project demo90Team 1 2 3 4 5 6 7 8 9 10 11Instructor?s grade B+ B C+ A- B- A+ B B- B+ A B-TA?s grade B+ B B A B- A B- B+ B+ A C+Class?
average grade B/B+ B+/A- B/B+ A- B/B+ A- B+ A-/A B+/A- A-/A B/B+Table 1: Grades assigned to class projectsthe students tended to be more ?generous?
(theiraverage grade for each team was usually half agrade above the instructor?s), the agreement wasquite high.
Table 1 shows the grades given by theinstructor, the teaching assistant and the class av-erage for the midterm workshop.Feedback about the course from the studentswas very good.
Columbia provides electoniccourse evaluations to the students which are com-pletely optional.
Participation in the evaluation forthis course was just under 50% in the midtermevaluation and just over 50% in the final eval-uation.
The scores (all in the 0-5 range) givenby the students in relevant categories were quitehigh: ?Overall Quality?
got an average score of4.23, ?Amount Learned?
got 4, ?Appropriatenessof Workload?
4.33 and ?Fairness of Grading Pro-cess?
got 4.42.The course resulted in multiple papers that areor will soon be under submission, as well as a fewprojects that may be developed into start-ups.
Al-most all student teams agreed to share their codein an open source project that is currently beingset up, and which will include the current questionanswering and semantic search system as well asadditional side projects.7 ConclusionWe described a course on the topic of SemanticTechnologies and the IBM Watson system, whichfeatures a diverse curriculum tied together by itsrelevance to an exciting, demonstrably successfulreal-world system.
Through a combined architec-ture inspired by Watson itself, the students get theexperience of developing an NLP-heavy compo-nent with specifications mandated by the largerarchitecture, which requires a combination of re-search and software engineering skills that is com-mon in the industry.An exciting result of this course is that theclass project architecture and many of the studentprojects are to be maintained as an open sourceproject which the students can, if they choose,continue to be involved with.
The repository andcommunity of this project can be expected to groweach time the class is offered.
Even after one class,it already contains an impressive semantic searchsystem.Feedback for this course from the studentswas excellent, and many teams have achievedtheir personal goals as stated at the beginning ofthe semester, including paper submissions, opera-tional web demos and mobile apps.Our long term goal is to replicate this course inmultiple top universities around the world.
WhileIBM does not have enough resources to alwaysdo this with its own researchers, it is instead go-ing to provide the content material and the opensource code generated so far to other universities,encouraging professors to teach the course them-selves.
Initially we will work on a pilot phaseinvolving only a restricted number of professorsand researchers that are already in collaborationwith IBM Research, and eventually (if the posi-tive feedback we have seen so far is repeated inthe pilot phase) give access to the same content toa larger group.ReferencesC.
Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker,R.
Cyganiak, and S. Hellmann.
2009.
DBpedia?Crystallization Point for the Web of Data.
Journalof Web Semantics: Science, Services and Agents onthe World Wide Web, 7(3):154?165, September.J.
Chu-Carroll, J.
Fan, B. Boguraev, D. Carmel,D.
Sheinwald, and C. Welty.
2012a.
Finding Nee-dles in the Haystack: Search and Candidate Gener-ation.
IBM Journal of Research and Development,56(3.4):6:1?6:12.J.
Chu-Carroll, J.
Fan, N. Schlaefer, and W. Zadrozny.2012b.
Textual Resource Acquisition and Engineer-ing.
IBM Journal of Research and Development,56(3.4):4:1?4:11.E.
Epstein, M. Schor, B. Iyer, A. Lally, E. Brown, andJ.
Cwiklik.
2012.
Making Watson Fast.
IBM Jour-nal of Research and Development, 56(3.4):15:1?15:12.J.
Fan, A. Kalyanpur, D. Gondek, and D. Ferrucci.2012.
Automatic Knowledge Extraction from Doc-uments.
IBM Journal of Research and Development,56(3.4):5:1?5:10.91D.
Ferrucci and A. Lally.
2004.
UIMA: an Ar-chitectural Approach to Unstructured InformationProcessing in the Corporate Research Environment.Natural Language Engineering, 10(3-4):327?348.D.
Ferrucci, E. Brown, J. Chu-Carroll, J. Fan,D.
Gondek, A. Kalyanpur, A. Lally, J. W. Murdock,E.
Nyberg, J. Prager, N. Schlaefer, and C. Welty.2010.
Building Watson: An Overview of theDeepQA project.
AI magazine, 31(3):59?79.D.
Ferrucci, A. Levas, S. Bagchi, D. Gondek, andE.
Mueller.
2012.
Watson: Beyond Jeopardy.
Arti-ficial Intelligence (in press).D.
Ferrucci.
2012.
Introduction to ?This is Wat-son?.
IBM Journal of Research and Development,56(3.4):1:1?1:15.A.
Gliozzo and T. Isabella.
2005.
Semantic Domainsin Computational Linguistics.
Technical report.A.
Kalyanpur, B. Boguraev, S. Patwardhan, J. W.Murdock, A. Lally, C. Welty, J. Prager, B. Cop-pola, A. Fokoue-Nkoutche, L. Zhang, Y. Pan, andZ.
Qiu.
2012.
Structured Data and Inference inDeepQA.
IBM Journal of Research and Develop-ment, 56(3.4):10:1?10:14.A.
Lally, J. Prager, M. McCord, B. Boguraev, S. Pat-wardhan, J.
Fan, P. Fodor, and J. Chu-Carroll.
2012.Question Analysis: How Watson Reads a Clue.
IBMJournal of Research and Development, 56(3.4):2:1?2:14.T.
Landauer and S. Dumais.
1997.
A Solution toPlato?s Problem: the Latent Semantic Analysis The-ory of Acquisition, Induction and Representationof Knowledge.
Psychological Review, 104(2):211?240.B.
Lewis.
2012.
In the Game: The Interface betweenWatson and Jeopardy!
IBM Journal of Research andDevelopment, 56(3.4):17:1?17:6.M.
McCord, J. W. Murdock, and B. Boguraev.
2012.Deep Parsing in Watson.
IBM Journal of Researchand Development, 56(3.4):3:1?3:15.T.
Miller, C. Biemann, T. Zesch, and I. Gurevych.2012.
Using Distributional Similarity for LexicalExpansion in Knowledge-based Word Sense Disam-biguation.
In Proceedings of the International Con-ference on Computational Linguistics, pages 1781?1796, Mumbai, India, December.J.
W. Murdock, J.
Fan, A. Lally, H. Shima, andB.
Boguraev.
2012a.
Textual Evidence Gatheringand Analysis.
IBM Journal of Research and Devel-opment, 56(3.4):8:1?8:14.J.
W. Murdock, A. Kalyanpur, C. Welty, J.
Fan, D. Fer-rucci, D. Gondek, L. Zhang, and H. Kanayama.2012b.
Typing Candidate Answers Using Type Co-ercion.
IBM Journal of Research and Development,56(3.4):7:1?7:13.J.
Prager, E. Brown, and J. Chu-Carroll.
2012.
Spe-cial Questions and Techniques.
IBM Journal of Re-search and Development, 56(3.4):11:1?11:13.G.
Tesauro, D. Gondek, J. Lenchner, J.
Fan, andJ.
Prager.
2012.
Simulation, Learning, and Op-timization Techniques in Watson?s Game Strate-gies.
IBM Journal of Research and Development,56(3.4):16:1?16:11.92
