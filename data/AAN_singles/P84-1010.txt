DENORMALIZATION AND CROSS REFERENCING IN THEORETICAL LEXICOGRAPHYJoseph E. GrimesDMLL, Morrill Hall, Cornell UniversityIthaca NY lh853 USASummer Institute of Linguistics7500 West Camp Wisdom RoadDallas TX 75236 USAABSTRACTA computational vehicle for lexicography wasdesigned to keep to the constraints of meaning-text theory: sets of lexical correlates, limits onthe form of definitions, and argument relationssimilar to lexical-functional grA--~-r.Relational data bases look like a natural frame-work for this.
But linguists operate with a non-normalized view.
Mappings between semantic actantsand grammatical relations do not fit actant fieldsuniquely.
Lexical correlates and examples are poly-valent, hence denormalized.Cross referencing routines help the lexicogra-pher work toward a closure state in which everyterm of a definition traces back to zero levelterms defined extralinguistically or circularly.Dummy entries produced from defining terms ensureno trace is overlooked.
Values of lexical corre-lates lead to other word senses.
Cross referencesfor glosses produce an indexed unilingual diction-ary, the start of a fully bilingual one.To assist field work a small structured editorfor a systematically denormalized data base wasimplemented in PTP under RT-11; Mumps would now beeasier to implement on small machines.
It allowedfields to be repeated and nonatomic strings includ-ed, and produced cross reference entries.
Itserved for a monograph on a language of Mexico?and for student projects from Africa and Asia.-I LEXICOGRAPHYNatural language dictionaries seem like obviouscandidates for information management in data baseform, at least until you try to do one.
Then it ap-pears as if the better the dictionary in terms oflexicographic theory, the more awkward it is tofit relational constraints.
Vest pocket touristdictionaries are a snap; Webster's Collegiate andparser dictionaries require careful thought; theMel'chuk style of explanatory-combinatory diction-ary forces us out of the strategies that work onordinary data bases.In designing a tool to manage lexicographicfield work under the constraints of Mel'chuk'smeaning-text model, the most fully specified oneavailable for detailed lexicography, I laid downspecifications in four areas.
First, it must han-dle all lexical correlates of the head word.
Lex-ical correlates relate to the head in ways thathave numerous parallels within the language.
InEnglish, for example, we have nouns that denotethe doer of an action.
Some, such as driver, writ-er, builder, are morphologically transparent.Others like pilot (from fly) and cook (from cook)are not; yet they relate to the corresponding verbsin the same way as the transparent ones do.
Mel'-chuk and associates have identified about fiftysuch types, or lexical functions, of which S_, thehabitual first substantive Just illustrated, isone.These types appear to have analogous meanings indifferent languages, though not all types are nec-essarily used in every language, and the relativepopularity of each differs from one language to an-other, as does the extent to which each is grammat-icalized.
For example, English has a rich vocabu-lary of values for a relation called Ma~n (fromLatin magnus) that denotes the superlative degreeof its argument: Magn (sit) = ti6ht, Magn (black)= Je t ,  pitch, coal, Magn (left) = hard, Magn---~ay)= for all you're worth, and on and on.
On the otherhand Huichol, a Uto-Aztecan language of Mexico Ihave been working on since 1952, has no such vo-cabulary; it uses the simple intensives yeme andva~c~a for all this, and2picks up its lexicalrichness in other areas.Second, a theoretically sound definition useswords that are themselves defined through as longa chain as possible back to zero level words thatcan be defined only in one of two ways: by accept-ing that some definitions -- as few as possible --may be circular, or by defining the zero level viaextralinguistic experiences.
Some dictionaries de-fine sweet circularly in terms of sugar and viceversa; but one could also begin by passing the sug-ar bowl and thus break the circularity.
The toolmust help trace the use of defining words.Third, the arguments in the semantic represen-tation of a word have to relate explicitly togrammatical elements like subjects and objects andpossessors: his projection of the budget and1 NSF grant BNS-79060hl funded some of this work.2 Huichol transcription follows Spanish excepthigh back unrounded, ' glottal stop, ?
high tone,W long syllable, ~ rhythm break, ~ voiced retro-flex alveopalatal fricative, ~ retroflex flap, cuVlabiovelar stop.38please turn out the li6ht each involve two argu-ments to the main operative word (him and budget,you and li6ht), but the relationship is handled indifferent grammatical frames.Finally, the tool must run on the smallest,most portable machine available, if necessary trad-ing processing time for memory and external space.II RELATIONSRelations were proposed by Codd and elaboratedon by Fagin, Ullman, and many others.
They are un-ordered sets of tuples, each of which contains anordered set of fields.
Each field has a value tak-en from a domain -- semantically, from a particu-lar kind of information.
In lexicography the tuplescorrespond, not to entries in a dictionary, but tosubentries, each with a particular sense.
Eachtuple contains fields for various aspects of theform, meaning, meaning-to-form mapping, and use ofthat sense.For the update and retrieval operations definedon relations to work right, the information storedin a relation is normalized.
Each field is restric-ted to an atomic value~ it says only one thing, nota series of different things.
No field appears morethan once in a tuple.
Beyond these formal con-straints are conceptual constraints based on thefact that the information in some fields determineswhat can be in other fields; Ullman spells out themain kinds of such dependency.It is possible, as Shu and associates show, tonormalize nearly any information structure by par-titioning it into a set of normal form relations.It can be presented to the user, however, in a viewthat draws on all these relations but is not itselfin normal form.Reconstituting a subentry from normal formtuples was beyond the capacity of the equipmentthat could be used in the field; it would have beencripplingly slow.
Before sealed Winchester diskscame out, floppies were unreliable in tropical hu-midity where the work was to be done, and onlysmall digital tape cartridges were thoroughly reli-able.
So the organization had to be managed by se-quential merges across a series of small (.25M)tapes without random access.The requirements of normal form came to be anissue in three areas.
First, the prosaic matter ofexamples violates normal form.
Nearly any field ina dictionary can take any number of illustrativeexamples.Second, the actants or arguments at the level ofsemantic representation that corresponds to thedefinition are in a theoretical status that is notyet clear.
Mel'chnk (1981) simply numbers the act-ants in a way that allows them to map to gram-matical relations in as general a way as possible.Others, ~'self included, find recurring componentsof definitions on the order of Fillmore's cases(1968) that are at least as consistently motivatedas are the lexical functions, and that map as setsof actants to sets of grammatical relations.
Ratherthan load the dice at this uncertain stage by des-ignating either numbered or labeled actants as dis-tinct field types, it furthers discussion to beable to have Actant as a single field type that isrepeatable, and whose value in each instance is alink between an actant number, a prcposed case, andeven possibly a conceptual dependency category forcomparison (Schank and Abelson, 1977.11-17).Third, lexical correlates are inherently many-to-one.
For example, Huichol ~u~i 'house' in itssense labeled 1.1 'where a person lives' has sever-= taa.
cuaa al antonyms: Ant (~u~i 1.1) + 'space in.
.
~ o front of a house', ~ull.ru'aa 'space behlnd a thehouse', tel.cuarle 'space outside the fence', andJ an adverbial use of taa.cuaa 'outdoors' (Grimes,1981.88).One could normalize the cases of all threetypes.
But both lexicographers and users expect theinformation to be in nonnormal form.
Furthermore,we can make a realistic assumption that relationaloperations on a field are satisfied when there isone instance of that field that satisfies them.This is probably fatal for Joins like "get me theHuichol word for 'travel', then merge its defini-tion with the definitions of all other words whoseagent and patient are inherently coreferential andinvolve motion'.
But that kind of capability is be-yond a small implementation anyway; the lexicogra-pher who makes that kind of pass needs a largescale, fully normalized system.
The kinds of selec-tions one usually does can be aimed at any instanceof a field, and projections can produce all in-stances of a field, quite happily for most work,and at an order of magnitude lower cost.The important thing is to denormalize systemat-ically so that normal form can be recovered whenit is needed.
Actants denormalize to fields repeat-ed in a specified order.
Examples denormalize tostrings of examples appended to whatever fieldthey illustrate.
Lexical correlates denormalize tostrings of values of particular functions, as inthe antonym example Just given.
The functions them-selves are ordered by a conventional list thatgroups similar functions together (Grimes 1981.288-291).III CROSS REFERENCINGTo build a dictionary consistently along thelines chosen, a computational tool needs to incor-porate cross referencing.
This means that for eachfield that is built, dummy entries are created forall or most of the words in the field.For example, the definition for 'opossum', y~u-xu, includes clauses like ca +u.~u+urime Ucu~'aaw'eats things that are not green' and pUcu~i .m~e-s_~e 'its tail is bare'.
From these notes are gener-ated that guarantee that each word used in the def-inition will ultimately either get defined itselfor will be tagged yuun~itG mep~im~ate 'everybodyknows it' to identify it as a zero level form thatis undefinable.
Each note tells what subentry itsown head word is taken out of, and what field;this information is merged into a repeatable Notesfield in the new entry.
Under the stem~ruuri B 'be39alive, grow' appears the note d (y~uxu) ?
i cayuu.yuu-?
J o rMne pUcua'aa 'eats thlngs that are not green'.This is a reminder to the lexicographer, first thatthere needs to be an entry for yuuri in sense B,and second that it needs to account at the veryleast for the way that stem is used in the defini-tion (d) field of the entry for yeuxu.Cross referencing to guarantee full coverage ofall words that are used in definitions backs up atheoretical claim about definitional closure: thestate where no matter how many words are added tothe dictionary, all the words used to define themare themselves already defined, back to a finiteset of zero level defining vocabulary.
There is noclai, r that such a set is the only one possible; on-ly that at least one such set is l~Ossible.
To reachclosure even on a single set is such an ~--,ensetask -- I spent eight months full time on Huichollexicography and didn't get even a twentieth of theeveryday vocabulary defined -- that it can be ap-proached only by some such systematic means.There are sets of conformable definitions thatshare most parts of their definitions, yet are notsynonyms.
Related species and groups of als~mals andplants have conformable definitions that are large-ly identical, but have differentiating parts aswell (Grimes 1980).
The same is true of sets ofverbs llke ca/tel 'be sitting somewhere', ve/'u 'hestanding somewhere', ma/mane 'be spread out some-where', and caa/hee 'be laid out straight some-where' (the slash separategunitary and multiplereference stems), which all share as part of their?
.
?
, J ?
.
deflnltlons ee.p~reu.teevl X-s~e cayupatatU?
xa~.-s~e 'spend an extended time at X without changingto another location', but differ regarding thespatial orientation of what is at X.
Cross refer-encing of words in definitions helps identifythese cases.Values of lexical functions are not always com-pletely specified by the lexical function and thehead word, so they are always cross referenced tocreate the opportunity for saying more about them.Qu~i 1.1 'house' in the sense of 'habitation of hu-mans'--~ersus 'stable' or 'lair' or 'hangar' 1.2and 'ranch' 1.3) is pretty well defined by thefunction S_, substantive of the second actant, plusthe head v~rb ca/tel 1.2 'live in a house' (versus'be sitting somewhere', 1,1 and 'live in a locality'1.3).
Nevertheless it ha~ fifteen lexical functionsof its own, includin@ the antonym set given ear-lier, and only one of those functions matches oneof the nine that are associated with ca/tel 1.2:S. (ca/tei 1.2) = S 2 (~u~i 1.1) = ~ u ~  'inhab-itant, householder'.Stepping outside the theoretical constraints oflexicography proper, the same cross referencingmechanism helps set up bilingual dictionaries.
Def-initions are always in the language of the entries,but it is useful in many situations to gloss thedefinitions in some language of scientific dis-course or trade, then cross reference on the glos-ses by adding a tag that puts the notes from theminto a separate section.
I have done this both forSpanish, the national language of the country whereHuichol is spoken, and for Latin, the language ofthe Linnean names of life forms.
What results isnot really a bilingual dictionary, because it ex-plains nothing at all about the second or thirdlanguage -- no definitions, no mapping betweengrammatical relations and actants, no lexical func-tions for that language.
It simply gives examplesof counterparts of glosses.
As such, however, it isno less useful than some bilingual dictionaries.
Tobe consistent, the entries on the second languageside would have to be as full as the first languageentries, and some mechanism would have to be intro-duced for distinguishing translation equivalentsrather than Just senses in each language.
As it is,cross referencing the glosses gives what is prop-erly called an indexed unilingual dictionary as ahandy intermediate stage.IV IMPLEMENTATIONBecause of the field situation far which thecomputational tool was required, it was implement-ed first in 1979 on an 8080 microcomputer with 32/(of memor~and two 130K sequentially accessible tapecartridges as an experimental package, later movedto an LSI-11/2 under RT-11 with .25M tapes.
Thelanguage used was Simons's PTP (198h), designedfor perspicuous handling of linguistic data.
Datamanagement was done record by record to maintainintegrity, but the normal form constraints on at-omicity and singularity of fields were dropped.Functions were implemented as subtypes of a singlefield type, ordered with reference to a speciallist.Because dictionary users expect ordered records,that constraint was added, with provision for map-ping non-ASCII sort sequences to an ASCII sort keythat controlled merging.Data entry and merging both put new instancesof fields after existing instances of the samefield, but this order of inclusion could be modi-fied by the editor.
Furthermore, multiple instancesof a field could be collapsed into a single non-atomic value with separator symbols in it, or sucha string value could be returned to multiple in-stances, both by the editor.
Transformations be-tween repeated fields, strings of atomic values,and various normal forms were worked out with GarySimons but not implemented.Cross referencing was done in two ways: automat-ically for values of lexical functions, and bymeans of tags written in while editing for anyfield.
Tags directed the processor to build a crossreference note for a full word, prefix, stem, orsuffix, and to file it in the first, second, orthird language part.
In every case the lexicogra-pher had opportunity to edit in order to remove ir-relevant material and to associate the correct nameform.Besides the major project in Huichol, the systemwas used by students for original lexicographicwork in Dinka of the Sudan, Korean, and Isnag ofthe Philippines.
If I were to rebuild the systemnow, I would probably use the University of Cali-fornia at Davis's CP/M version of Mumps on a port-able Winchester machine in order to have total40random access in portable form.
The strategy of da-ta management, however, would remain the same, asit fits the application area well.
I suspect, buthave not proved, that full normalization capabilityprovided by random access would still turn out un-acceptably slow on a small machine.V DISCUSSIONInvestigation of a language centers around fourcollections of information that computationallyare like data bases: field notes, text collectionwith glosses and translations, grammar, and dic-tionary.
The first two fit the relational para-digm easily, and are especially useful when sup-plemented with functions that display glosses in-terlinearly.The grammar and dictionary, however, require de-normalization in order to handle multiple examples,and dictionaries require the other kinds of denorm-alization that are presented here.
Ideally thoseexamples come out of the field notes and texts,where they are discovered by an automatic parsingcomponent of the grammar that is used by the selec-tion algorithm, and they are attached to the ap-propriate spots in the grammar and dictionary byrelational join operations.
~-VI REFERENCESCodd, E. F. 1970.
A relational model for largeshared data banks.
Communications of the ACM13:6.377-387.Fagin~ R. 1979.
A normal form for relational data-bases that is based on domains and keys.
IBMResearch Report RJ 2520.Fillmore, Charles J.
1968.
The case for case.
In~m~on Bach and Robert T. Harms, eds., Univers-als in linguistic theory, New York: Holt, Rine-hart and Winston, 1-88.Grimes, Joseph E. 1980.
Huichol life form clas-sification I: Animals.
Anthropological Linguist-ics 22:5.187-200.
II: Plants.
AnthropologicalLinguistics 22:6.264-27h.W .
..... .
1981.
E1 huiehol: apuntes sobre el lexlco\[Huichol: notes on the lexicon\], with P. de laCruz, J. Carrillo, F. Dzaz, R. Dlaz, and A. dela Rosa.
ERIC document ED 210 901, microfiche.Kaplan, Ronald M. and Joan Bresnan.
1982.
Lexical-functional grammar: a formal system for gram-matical representation.
In Joan Bresnan, ed.The mental representation of grammatical rela-tions, Cambridge: The MIT Press, 173-281.Mel'chuk, Igor A.
1981.
Meaning-text models: arecent trend in Soviet linguistics.
Annual Re-view of Anthropology 10:27-62...... , A. K. Zholkovsky, and Ju.
D. Apresyan.
inpress.
Tolkovo-kombinatornyJ slovar' russkogojazyka (with English introduction).
Vienna:Wiener SlawistischerAlmanach.Schank, Roger C. and Robert P. Abelson.
1977.Scripts, plans, goals and understanding: an in-quiry into hnma~ knowledge structures.
HillsdaleNJ: Lawrence Erlbaum Associates.Simons, Gary F. 198h.
Powerful ideas for text pro-cessing.
Dallas: Summer Institute of Linguist-ics.Ullman, Jeffrey D. 1980.
Principles of databasesystems.
Rockville MD: Computer Science Press.Wong, H. K. T. and N. C. Shu.
1980.
An approach torelational data base scheme design.
IBM ComputerScience Research Report RJ 2688.41
