Nanjing  Normal  University  Segmenterfor  the  Fourth  SIGHAN  BakeoffXiaohe CHEN, Bin LI, Junzhi LU, Hongdong NIAN, Xuri TANGNanjing Normal University,122, Ninghai Road, Nanjing, P. R. China, 210097chenxiaohe5209@msn.com,gothere@126.com,lujunzhi@gmail.com,nianhong-dong@hotmail.com,tangxuriyz@hotmail.comAbstractThis paper expounds a Chinese word seg-mentation system built for the FourthSIGHAN Bakeoff.
The system participatesin six tracks, namely the CityU Closed,CKIP Closed, CTB Closed, CTB Open,SXU Closed and SXU Open tracks.
Themodel of Conditional Random Field is usedas a basic approach in the system, with at-tention focused on the construction of fea-ture templates and Chinese character cate-gorization.
The system is also augmentedwith some post-processing approaches suchas the Extended Word String, model inte-gration and others.
The system performsfairly well on the 5 tracks of the Bakeoff.1 IntroductionThe Nanjing Normal University (NJNU) team par-ticipated in CityU Closed, CKIP Closed, CTBClosed, CTB Open, SXU Closed, SXU Opentracks in the WS bakeoff.
The system employed inthe Bakeoff is based mainly on the model of CRF,optimized with some pre-processing and post-processing methods.
The team has focused its at-tention on the construction of feature templates,Chinese character categorization, the use of Ex-tended Word String and the integration of differentsegmentation models in the hope of achieving bet-ter performance in both IVs?In Vocabularywords?
and OOVs (Out Of Vocabulary words).Due to time limitations, some of these methods arestill not fully explored.
However, the Bakeoff re-sults show that the performance of the overall sys-tem is fairly satisfactory.The paper is organized as follows: section 2gives a brief description of the system; section 3and 4 are devoted to the discussion of the results ofclosed test and open test; a conclusion is given tocomment on the overall performance of the system.2 System DescriptionConditonal Ramdom Field (CRF) has been widelyused by participants in the basic tasks of NLP sincePeng(2004).
In both SIGHAN 2005 and 2006Bakeoffs CRF-based segmenters prove to have abetter performance over other models.
We havealso chosen CRF as the basic model for the task ofsegmentation and uses the package CRF++ devel-oped by Taku Kudo1.
Some post-processing op-timizations are also employed to improve the over-all segmentation performance.
The general descrip-tion of the system is illustrated in Figure 1.
Thebasic segmenter and post-processing are explainedin the next two sections.2.1 Basic SegmenterAs in many other segmentation models, our systemalso treats word segmentation as a task of classifi-cation problem.
During the experiment of themodel, two aspects are taken into consideration,namely tag set and feature template.
The 6-tag(Table 1) set proposed in Zhao(2006) is employedto mark various character position status in a Chi-nese word.
The feature template (Table 2) consid-1 Package CRF++, version 0.49, available athttp://crfpp.sourceforge.net.115Sixth SIGHAN Workshop on Chinese Language Processingers three templates of character features and threetemplates of character type features.
The introduc-tion of character type (Table 3) is based on the ob-servation that many segmentation errors are causedby different segmentation standards among differ-ent corpora, especially between Traditional Chi-nese corpora and Simplified Chinese Corpora.Figure 1: Flow ChatStatus Tagbegin B2nd B23rd B3middle Mend Esingle STable 1:6-tag SetTable 2: Feature Templates in Close TestCharacter Type ExampleChinese Character ?
?Serial Number ??
?
?Roman Number ??
?Aribic Number 12?
?Chinese Number ???
?Ganzhi ???
?Foreign Character ??
?National Pronunciation Letters ??
?Sentence Punctuation ???
?Hard Punctuation \t\r\nPunctuation ??-?
''Dun ?
?Dot1 ?
?Dot2 .
?Di ?At @Other Character ?
?Table 3:Character Type2.2 Post-ProcessingTwo methods are used in post-processing to opti-mize the results obtained from basic segmenter.The first is the binding of digits and English Char-acters.
The second is the use of extended wordstring to solve segmentation ambiguity.2.2.1 Binding Digits and Roman LettersDigits (ranging from ?0?
to ?9?)
are always boundas a word in Chinese corpora, while roman lettersare treated differently in different corpora, someadding a full-length blank between the letters,some not.
The system employs rule-based ap-proach to bind both digits and roman letters.
Wealso submitted two segmentation results for theBakeoff, please refer to section 3.2 for discussionof these results.2.2.2 Extended Word String (EWS) ApproachThe CRF model performs well in segmenting IVword strings in general, but not in all contexts.
Oursystem thus uses a memory based method, whichis named as Extended Word String approach, toprevent CRF from making such error.
All the Chi-nese word strings, which are of character lengthfrom 2 to 10 and appear more than two times, arestored in a hash table, together with information oftheir segmentation forms.
An example of EWS isgiven in Table 5.
If the same character string ap-pears in the test data, the system can easily re-segment them by querying the hash table.
If thequery finds that the character string has only onesegmentation form and checking shows that thestring has no overlapping ambiguity with its left orright word, the segmentation of the string is thenmodified according to the stored segmentation type.Our experiment shows that the approach can pro-Type Feature FunctionCharUnigramCn, n=-2,-1, 0, 1, 2Character in position n tothe current characterCharBigramCnCn+1,n=-1,0Previous(next) characterand current characterChar Jump C-1 C1Previous character andnext characterCharTypeUnigramTn,n=-1, 0, 1Type of previous (current,next) characterCharTypeBigramTnTn+1,n=-1,0Type of previous characterand next characterCharTypeJump T-1 T1Type of previous characterand next characterInput Character StringsBasic Segmenter (CRF Tagging)Post-processingOutput Word Strings116Sixth SIGHAN Workshop on Chinese Language Processingmote the F-measure by 0.2% to 1% on differenttracks.Table 5: Example of EWS3 Evaluation Results on Closed Test3.1 CKIP Closed TestIn CKIP Closed Test, another kind of post process-ing is used for OOVs.
Examination on the outputfrom basic segmenter shows that some OOVs iden-tified by CRFs are not OOV errors, but IV errors.Sometimes it can not always segment the sameOOV correctly in different context.
For example,the person name ?????
appears three times inthe test, but it is only correctly detected twice, andfor once it is wrongly detected.
Our approach is tore-segment the OOVs string (with its left and rightword) twice.
Firstly the string is segmented usingthe training data wordlist, followed by a secondsegmentation using the OOV wordlist recognizedby the Basic Segmenter.
The result with the mini-mum number of words is accepted.Example:Basic Seg Output?/?/??/?
?/OOV Adjusting?
/?/??
?/?/Basic Seg Output?/??/?
?/?/OOV Adjusting?
/?/??/?
?/With the OOV Adjusting Approach mentionedabove, we got the third place in the track (Table 6).But when we use it on other corpora, the methoddoes not promote the performance.
Rather, it low-ers the performance score.
The reason is still notclear.System?rank?
F Foov FivBest(1/21) 0.9510 0.7698 0.9667Njnu(3/21) 0.9454 0.7475 0.9637Table 6: CityU Closed Test3.2 CKIP and CTB Closed TestIn CKIP Closed Test, only the basic segmenterintroduced in section 2 is used.
Two segmentationresults, namely a and b (Table 7 and 8) are submit-ted for the Bakeoff.
Result a binds the roman let-ters as a word, while result b does not.
The scoresof the two results show that the approach is notstable in terms of score.
We suggest that corporasubmitted for evaluation purposes should pay moreattention to non-Chinese word tagging and complywith the request of Bakeoff organizers.System?rank?
F Foov FivBest(1/19) 0.9470 0.7524 0.9623Njnu a(6/19) 0.9378 0.6948 0.9580Njnu b(9/19) 0.9204 0.6341 0.9452Table 7: CKIP Closed TestSystem?rank?
F Foov FivBest(1/26) 0.9589 0.7745 0.9697Njnu a(9/26) 0.9498 0.7152 0.9645Njnu b(7/26) 0.9499 0.7142 0.9647Table 8: CTB Closed Test3.3 SXU Closed TestFour results (a, b, c and d) are submitted for thistrack (Table 9).
Results a and b are dealt in thesame way as described in section 3.2.
Result c isobtained by incorporating results from a memory-based segmenter.
The memory-based segmenter ismainly based on memory-based learning proposedby Daelemans(2005).
We tested it on the trainingdata with 90% as training data and 10% as testingdata.
The result shows that performance is im-proved.
However, when the method is applied onthe Bakeoff test data, the performance is lowered.The reason is not identified yet.Result d was based on result c. It incorporatesOOV words recognized by the system introducedin (Li & Chen, 2007) in the post-processing stage.Based on suffix arrays, Chinese character stringswith mutual information value above 8.0 are auto-matically extracted as words without any manualoperation.
We can see from table 9 that the F-measure of result d improved and Foov of d got 2rdplace in the test.
And it is likely to get higher scoreif we combine it with result a.System?rank?
F Foov FivBest(1/29) 0.9623 0.7292 0.9752Njnu a(9/29) 0.9539 0.6789 0.9702Njnu b(10/29) 0.9538 0.6778 0.9701Njnu c(15/29) 0.9526 0.6793 0.9688Njnu d(14/29) 0.9532 0.6817 0.9694Table 9: Sxu Closed TestEWS Seg Form Freq???
/?/?
?/ 4117Sixth SIGHAN Workshop on Chinese Language Processing4 Evaluation Results on Open Test4.1 MethodsMore features and resources are used in open test,mainly applied in the modification of feature tem-plates.
Besides the features used in the close test,we add to feature templates more informationabout Chinese characters, such as the Chinese radi-cals (????
), tones (5 tones), and another 6 Boo-lean values for each Chinese character.
The 6 Boo-lean values indicate respectively whether the char-acter is of Chinese surnames (????
), or of Chi-nese names (????
), or of characters used forwestern person name translation (????
), or ofcharacter used for English location name transla-tion(????
), or of affixes (??-?,?-??
), or of sin-gle character words (????).
The feature tem-plates constructed in this way is given in Table 10.Type Feature FunctionCharUnigramCn,n=-1,0,1The prevoius (current,next) characterCharBigramCn Cn+1,n=-1,0The previous(next) charac-ter and current characterChar Jump C-1 C1The previous characterand next characterCharTypeUnigram T0The type of the current,next characterCharTypeTrigram T-1 T0T1The type of the previous,current and next characterCharInformationUnigramnT0 ,n=1,?,6The 6 information of thecurrent, next characterCharInformationTrigramnnn TTT 101?
,n=1,?,6The 6 information of theprevious, current and nextcharacterTable10: Feature Templates for Open TestIn the post-processing stage, we also add a Chi-nese idiom dictionary (about 27000 items) to helpincrease the OOV word recall.4.2 ResultsIn SXU open test, we submitted 3 results (a, b andc), but only a achieves the 4th rank in F-measure(Table 11).
Features and resources added to thesystem turns out not to be of much use in the task,compared with our score on the closed test.Result b, c and all the results in CTB open testsubmitted have errors due to our pre-processingstage with CRF.
Thus, the scores of them are verylow, and some are even lower than our scores inclosed test (see table 12).System?rank?
F Foov FivBest(1/9) 0.9735 0.8109 0.9820Njnu a(4/12) 0.9559 0.6925 0.9714Table 11: SXU Open TestSystem?rank?
F Foov FivBest(1/12) 0.9920 0.9654 0.9936Njnu a(9/12) 0.9346 0.6341 0.9528Table 12: CTB Open Test5 Conclusions and Future WorkThis is the first time that the NJNU team takes partin SIGHAN WS Bakeoff.
In the construction of thesystem, we conducted experiments on the CRF-based segmenter with different feature templates.We also employs different post-processing ap-proaches, including Extended Word String ap-proach, digit and western roman letter combination,and OOV detection.
An initial attempt is also madeon the integration of different segmentation models.Time constraint has prevented the team from fullerexploration of the methods used in the system.Future efforts will be directed towards more com-plicated segmentation models, the examination ofthe function of different features in the task, theintegration of different models, and more efficientutility of other relevant resources.ReferencesBin Li, Xiaohe Chen.
2007.
A Human-Computer Inter-action Word Segmentation Method Adapting to Chi-nese Unknown Texts, Journal of Chinese Informa-tion Processing, 21(3):92-98.Daelemans, W. and Van den Bosch.
2005.
Memory-Based Language Processing.
Cambridge UniversityPress, Cambridge, UK.Fuchun Peng, et al 2004.
Chinese Segmentation andNew Word Detection Using Conditional RandomFields, COLING2004, 562-568, 23-27 August, Ge-neva, Switzerland.Gina-Anne Levow.
2006.
The Third International Chi-nese Language Processing Bakeoff: Word Segmenta-tion and Named Entity Recognition, Proceedings ofthe Fifth SIGHAN Workshop on Chinese LanguageProcessing, 108-117, 22-23 July, Sydney, Australia.118Sixth SIGHAN Workshop on Chinese Language ProcessingHai Zhao, et al 2006.
An Improved Chinese WordSegmentation System with Conditional RandomField, Proceedings of the Fifth SIGHAN Workshopon Chinese Language Processing, 162-165, 22-23July, Sydney, Australia.Richard Sproat and Thomas Emerson.
2003.
The FirstInternational Chinese Word Segmentation Bakeoff,The Second SIGHAN Workshop on Chinese Lan-guage Procesing, 133-143, Aspporo, Japan.Thomas Emerson.
2005.
The Second  International Chi-nese Word Segmentation Bakeoff, Proceedings of theFourth SIGHAN Workshop on Chinese LanguageProcessing, 123-133, Jeju Island, Korea.119Sixth SIGHAN Workshop on Chinese Language Processing
