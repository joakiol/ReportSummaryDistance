Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 164?168,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsFast and Accurate Unlexicalized Parsing via Structural AnnotationsMaximilian Schlund, Michael Luttenberger, and Javier EsparzaInstitut f?ur InformatikTechnische Universit?at M?unchenBoltzmannstra?e 3D-85748 Garching{schlund,luttenbe,esparza}@model.in.tum.deAbstractWe suggest a new annotation scheme forunlexicalized PCFGs that is inspired byformal language theory and only dependson the structure of the parse trees.
Weevaluate this scheme on the T?uBa-D/Ztreebank w.r.t.
several metrics and showthat it improves both parsing accuracy andparsing speed considerably.
We also showthat our strategy can be fruitfully com-bined with known ones like parent annota-tion to achieve accuracies of over 90% la-beled F1and leaf-ancestor score.
Despiteincreasing the size of the grammar, ourannotation allows for parsing more thantwice as fast as the PCFG baseline.1 IntroductionAs shown by (Klein and Manning, 2003), un-lexicalized PCFGs can achieve high parsing ac-curacies when training trees are annotated withadditional information.
An annotation basicallyamounts to splitting each nonterminal into sev-eral subcategories, which can even be derivedautomatically (Petrov et al., 2006; Petrov andKlein, 2007).
Currently used annotation strate-gies, e.g.
parent annotation (Johnson, 1998) or se-lectively splitting special nonterminals (e.g.
mark-ing relative clauses) as in (Schiehlen, 2004), aremostly linguistically motivated (with the excep-tion of the above mentioned automatic approach).In this paper we study new heuristics motivatedby formal language theory for improving the pars-ing accuracy of unlexicalized PCFGs by means ofrefining the nonterminals of the grammar: Oneheuristic splits a nonterminal X into a family ofnonterminals (Xd)d?Dbased on the notion of thedimension (also Horton-Strahler number) of a tree(Strahler, 1952; Esparza et al., 2007; Esparza etal., 2014).The dimension of a rooted tree t is defined as theheight of the highest perfect binary tree1we canobtain from t by pruning subtrees and contractingedges.2A result of (Flajolet et al., 1979) shows thatthe dimension characterizes the minimal amountof memory that is required to traverse a tree.
So,intuitively, parse trees of high dimension shouldindicate an unnaturally complex sentence structurerequiring the reader to remember too many incom-plete dependent clauses in the course of readingthe sentence.
Section 2 corroborates experimen-tally that, indeed, parse trees of natural languagehave small dimension.Since dimension is a meaningful measure ofcomplexity and parse trees have low dimension,we conjectured that annotating nonterminals withthe dimension of the subtree rooted at them couldimprove parsing accuracy (see Fig.
1 for an il-lustration).
Section 5 shows that this is indeedthe case: The combination of the dimension an-notation and the well known parent annotationtechnique leads to absolute improvements of morethan 5% F1, 7?8% leaf-ancestor score, and a rela-tive reduction of the number of crossing bracketsof over 25% compared to a plain PCFG baseline.At the same time, quite surprisingly, parsing speedmore than doubles.It could be argued that any other graph theo-retical measure for the complexity of a tree couldlead to similar results.
For this reason we havealso considered annotating nonterminals with theheight of the subtree rooted at them (the height isthe most basic measure related to trees).
Our ex-periments show that height annotation is also ben-eficial but further refinement via parent annotationyields less improvements than for the dimensionannotation.1A binary tree of height h is perfect if it has 2hleaves.2In other words, the dimension of t is the height of thehighest perfect binary tree which is a minor of t.164SIMPX-3MF-2NX-2NX-1NN-0MalerspainterART-0desof theNX-1NN-0FreundfriendART-0einaLK-0VXFIN-0VAFIN-0warwasVF-2NX-2NX-1NE-0NogaretNogaretNE-0dedeNX-1NN-0RechtsanwaltattorneyART-0DerTheFigure 1: Dimension annotation of a tree from T?uBa-D/Z: the label of every nonterminal is decoratedwith the dimension of the subtree rooted at it.
The dimension of a parent node is the maximum of thedimensions of its children (plus one if this maximum is attained at least twice).In the following two sections, we present moredetails on the use of tree dimension in NLP, con-tinue with describing our experiments (Section 4)together with their results (Section 5), and finallyconclude with some ideas for further improve-ments.2 Tree Dimension of Natural LanguagesWe were able to validate our conjecture that parsetrees of natural language should typically havesmall dimension on several treebanks for a varietyof languages (cf.
Table 1).
The average dimensionof parse trees varies only from 1.7 to 2.4 over alllanguages and the maximum dimension we everencountered is 4.3 Annotation MethodsIn this paper we compare three different annota-tion methods: dimension, height, and parent an-notation.
The dimension (resp.
height) annotationrefine a given nonterminal X by annotating it withthe dimension (resp.
height) of the subtree rootedat it.
A standard technique in unlexicalized pars-ing we compare against is vertical markovization,i.e.
to refine nonterminals by annotating them withtheir parent (or grandparent) nonterminal (Kleinand Manning, 2003).Let us remark that we focus here only on meth-ods to split nonterminals and leave merging strate-gies for further investigations.
Amongst them hor-izontal markovization (Klein and Manning, 2003)is especially valuable for battling sparsity and canLanguage Average MaximumBasque 2.12 3English 2.38 4French 2.29 4German(1) 1.94 4German(2) 2.13 4Hebrew 2.44 4Hungarian 2.11 4Korean 2.18 4Polish 1.68 3Swedish 1.83 4Table 1: Average and maximum dimension forseveral treebanks of natural languages.
Sources:English ?
10% sample from the Penn treebankshipped with python nltk (Loper and Bird, 2002),German(2) ?
release 8 of the T?uBa-D/Z treebank(Telljohann et al., 2003), the remaining treebanksare taken from the SPMRL shared task dataset(Seddah et al., 2013).lead to more compact and often more accuratePCFGs.4 Methodology4.1 Experimental SetupWe use release 8 of the T?uBa-D/Z treebank(Telljohann et al., 2003) as dataset.
To com-bine easy prototyping and data exploration withefficient parsing and standard evaluation methodswe used python nltk (Loper and Bird, 2002) to-gether with the Stanford parser (Klein and Man-165ning, 2003).
For evaluation we used the built inevalb, leaf-ancestor, and crossing brackets metricsprovided by the Stanford parser.
Is is important tonote that all our experiments use gold tags fromthe treebank3which had the pleasant side effectthat no parse failures were encountered.
All exper-iments were carried out on a machine with an Inteli7 2.7 GHz CPU and 8 GB RAM and took aboutone week to run4.
Our scripts and raw data can beobtained freely from https://github.com/mschlund/nlp-newton.4.2 RandomizationWe decided to sample our training- and test-datarandomly from the treebank several times inde-pendently for each annotation strategy under test.This enables us to give more precise estimationsof parsing accuracy (Section 5) and to assess theirvariability (cf.
Figure 2).
For each sample size Nfrom {5k, 10k, 20k, .
.
.
, 70k} we selected a ran-dom sample of size N from the set of all 75408trees in the treebank.
The first 90% of this samplewas used as training set and the remaining 10% astest set.
We then evaluated each of our six anno-tation methods on this same training/test set.
Thewhole process was repeated ten times each, yield-ing 480 experiments altogether.
For each experi-ment we evaluated parsing accuracy according tothree evaluation measures as well as the parsingspeed and the size of the derived grammar.
Eachof these numbers was then averaged over the tenrandom trials.
To ensure perfect reproducibilitywe saved the seeds we used to seed the randomgenerator.4.3 Evaluation MeasuresTo thoroughly assess the performance of our anno-tation schemes we not only report the usual con-stituency measures (labeled precision/recall/F1and crossing brackets) proposed originally by(Abney et al., 1991) but also calculate leaf-ancestor scores (LA) proposed by (Sampson,2000) since it has been argued that LA-scores de-scribe the informal notion of a ?good?
parse betterthan the usual constituency measures.
This is es-pecially relevant for comparing parsing accuracyover different treebanks (Rehbein and Van Gen-abith, 2007a; Rehbein and van Genabith, 2007b).3This is unrealistic of course, but is used for comparabilitywith other work like (Rafferty and Manning, 2008).4We only used a single core, since memory turned out tobe the main bottleneck.5 ResultsOur results are collected in Table 5.
We measureda baseline accuracy of 84.8% labeled F1-scorefor a plain PCFG without any annotations, lowerthan the 88% reported by (Rafferty and Manning,2008) on a previous release of the T?uBa-D/Z tree-bank (comprising only 20k sentences of length atmost 40).
However, the absolute improvementswe found using annotations are consistent withtheir work, e.g.
our experiments show an abso-lute increase of 3.4% when using parent annota-tion while (Rafferty and Manning, 2008) report a3.1% increase.
We suspect that the differences arelargely suspect to the different data: consideringsentences up to length 40, our experiments yieldscores that are 1% higher.
To explain all remain-ing differences we plan to replicate their setup.5.1 Impact of AnnotationsAll three annotation methods (w.r.t.
parent, dimen-sion, height which we will abbreviate by PA, DA,HA for convenience) lead to comparable improve-ments w.r.t.
constituency measures with small ad-vantages for the two structural annotations.
LA-evaluation on the other hand shows that HA andDA have a clear advantage of 3% over PA.Quite surprisingly, both DA and HA can befruitfully combined with parent annotation im-proving F1further by almost 2% and LA-metricsby 1?2% as well.
However, the height+parentcombination cannot compete with the dimen-sion+parent method.
One reason for this might bethe significant increase in grammar size and result-ing data-sparseness problems, although our learn-ing curves (cf.
Figure 2) suggest that lack of train-ing data is not an issue.Altogether, the DA+PA combination is the mostprecise one w.r.t.
all metrics.
It provides abso-lute increases of 5.6% labeled F1and 7.4?8.4%LA-score and offers a relative reduction of cross-ing brackets by 27%.
This is especially relevantsince according to (Manning and Sch?utze, 1999) ahigh number of crossing brackets is often consid-ered ?particularly dire?.
Finally, this combinationleads to a 60% increase in the number of exactlyparsed sentences, significantly more than for theother methods.5.2 Parsing SpeedWe further study to what extent the three heuris-tics increase the size of the grammar and the time166evalb Leaf-Ancestor Crossing bracketsAnnotation |G| Speed ?
stderr F1exact LA (s) LA (c) # CB zero CBPlain 21009 1.74?
0.04 84.8 24.4 84.0 79.7 1.17 58.5Parent 34192 1.07?
0.01 88.2 31.8 86.6 82.9 1.07 61.8Height 76096 3.06?
0.03 88.7 33.7 89.8 86.2 0.93 65.2Height+parent 130827 2.20?
0.04 89.2 36.8 90.8 87.0 0.95 65.4Dim 49798 6.02?
0.10 88.5 31.8 89.7 86.1 0.90 64.9Dim+parent 84947 4.04?
0.07 90.4 39.1 91.4 88.1 0.85 67.2Table 2: Average grammar sizes, parsing speed, and parsing accuracies according to various metrics (forthe 70k samples only, i.e.
on 7000 test trees).
All numbers are averaged over 10 independent randomsamples.
|G| denotes the number of rules in the grammar, parsing speed is measured in sentences persecond.
LA scores are reported as sentence-level (s) and corpus-level (c) averages, respectively.
Allaccuracies reported in % (except # CB ?
the average number of crossing brackets per sentence).0 1 2 3 4 5 6 7?1048284868890Sample sizeLabeledF1scorein%plain PCFG ParentDim Dim+ParentHeight Height+ParentFigure 2: Learning curves for different annotationstrategies.
Average F1with standard deviation forrandom samples of various sizes (10 independentsamples each).needed to parse a sentence.
As expected all threeannotations increase the size of the grammar con-siderably (PA by 60%, DA by almost 140%, andHA by 260%).
Surprisingly, our experiments didnot show a direct influence of the grammar sizeon the average time needed to parse a tree: Whileparsing speed for PA drops by about 40%, DA andHA actually lead to significant speedups over thebaseline (factor 3.4 for DA and 1.7 for HA).
Forthe combination of dimension and parent annota-tion the gain in speed is less pronounced but stilla factor of 2.3.
One possible explanation is thefact that (for a grammar in CNF) a nonterminal ofdimension d can only be produced either by com-bining one of dimension d with one of dimensionstrictly less than d or by two of dimension exactlyd?
1.
Since the dimensions involved are typicallyvery small (cf.
Table 1) this may restrict the searchspace significantly.6 DiscussionWe have described a new and simple yet effec-tive annotation strategy to split nonterminals basedon the purely graph-theoretic concept of tree di-mension.
We show that annotating nonterminalswith either their dimension or their height givesaccuracies that lie beyond parent annotation.
Fur-thermore dimension and parent annotation in com-bination yield even higher accuracies (90.4% la-beled F1and 91.4% LA-score on a sentence-level).
Lastly, one of the most surprising findingsis that, despite considerable growth of grammarsize, parsing is significantly faster.6.1 Future WorkWe are currently experimenting with other tree-banks like the SPMRL dataset (Seddah et al.,2013) which contains various ?morphologicallyrich?
languages (cf.
Table 1).
Although we cannotpossibly expect to match the accuracies achievedby highly optimized lexicalized parsers with oursimple annotation strategy alone, we are confidentthat our results transfer to other languages.
A logi-cal next step is to integrate our annotation methodsinto current parsing frameworks.Since our annotations increase the size ofthe grammar significantly, horizontal markoviza-tion and more careful, selective dimension/height-splits (i.e.
only carry out ?profitable?
splits) seempromising to avoid problems of data-sparsity ?
inparticular if one wants to use further state-splittingtechniques that are more linguistically motivated.Finally, we are interested in understanding theparsing speedup incurred by dimension/height-annotations and to provide a theoretical analysis.167ReferencesS.
Abney, S. Flickenger, C. Gdaniec, C. Grishman,P.
Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Kla-vans, M. Liberman, M. Marcus, S. Roukos, B. San-torini, and T. Strzalkowski.
1991.
Procedure forQuantitatively Comparing the Syntactic Coverage ofEnglish Grammars.
In E. Black, editor, Proceedingsof the Workshop on Speech and Natural Language,HLT ?91, pages 306?311, Stroudsburg, PA, USA.Association for Computational Linguistics.Javier Esparza, Stefan Kiefer, and Michael Lutten-berger.
2007.
An Extension of Newton?s Method to?-Continuous Semirings.
In Developments in Lan-guage Theory, volume 4588 of LNCS, pages 157?168.
Springer.Javier Esparza, Michael Luttenberger, and MaximilianSchlund.
2014.
A Brief History of Strahler Num-bers.
In Language and Automata Theory and Appli-cations, volume 8370 of Lecture Notes in ComputerScience, pages 1?13.
Springer International Publish-ing.Philippe Flajolet, Jean-Claude Raoult, and JeanVuillemin.
1979.
The Number of Registers Re-quired for Evaluating Arithmetic Expressions.
The-oretical Computer Science, 9:99?125.Mark Johnson.
1998.
PCFG Models of LinguisticTree Representations.
Computational Linguistics,24(4):613?632.Dan Klein and Christopher D. Manning.
2003.
Ac-curate Unlexicalized Parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, ACL ?03, pages 423?430, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Edward Loper and Steven Bird.
2002.
NLTK: TheNatural Language Toolkit.
In Proceedings of theACL-02 Workshop on Effective tools and methodolo-gies for teaching natural language processing andcomputational linguistics-Volume 1, pages 63?70.Association for Computational Linguistics.Christopher D. Manning and Hinrich Sch?utze.
1999.Foundations of statistical natural language process-ing, volume 999.
MIT Press.Slav Petrov and Dan Klein.
2007.
Improved Inferencefor Unlexicalized Parsing.
In HLT-NAACL, pages404?411.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning Accurate, Compact, andInterpretable Tree Annotation.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Asso-ciation for Computational Linguistics, pages 433?440.
Association for Computational Linguistics.Anna N. Rafferty and Christopher D. Manning.
2008.Parsing Three German Treebanks: Lexicalized andUnlexicalized Baselines.
In Proceedings of theWorkshop on Parsing German, PaGe ?08, pages 40?46, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Ines Rehbein and Josef Van Genabith.
2007a.
Eval-uating Evaluation Measures.
In NODALIDA, pages372?379.Ines Rehbein and Josef van Genabith.
2007b.
Tree-bank Annotation Schemes and Parser Evaluation forGerman.
In EMNLP-CoNLL, pages 630?639.Geoffrey Sampson.
2000.
A Proposal for Improvingthe Measurement of Parse Accuracy.
InternationalJournal of Corpus Linguistics, 5(1):53?68.Michael Schiehlen.
2004.
Annotation strategies forprobabilistic parsing in german.
In Proceedings ofthe 20th international conference on ComputationalLinguistics, COLING ?04, Stroudsburg, PA, USA.Association for Computational Linguistics.Djam?e Seddah, Reut Tsarfaty, Sandra K?ubler, MarieCandito, Jinho D. Choi, Rich?ard Farkas, Jen-nifer Foster, Iakes Goenaga, Koldo Gojenola, YoavGoldberg, Spence Green, Nizar Habash, MarcoKuhlmann, Wolfgang Maier, Joakim Nivre, AdamPrzepiorkowski, Ryan Roth, Wolfgang Seeker, Yan-nick Versley, Veronika Vincze, Marcin Woli?nski,Alina Wr?oblewska, and Eric Villemonte de laCl?ergerie.
2013.
Overview of the SPMRL 2013Shared Task: A Cross-Framework Evaluation ofParsing Morphologically Rich Languages.
In Pro-ceedings of the 4th Workshop on Statistical Parsingof Morphologically Rich Languages: Shared Task,Seattle, WA.Arthur N. Strahler.
1952.
Hypsometric (Area-Altitude) Analysis of Erosional Topology.
Bulletinof the Geological Society of America, 63(11):1117?1142.Heike Telljohann, Erhard W. Hinrichs, Sandra K?ubler,Heike Zinsmeister, and Kathrin Beck.
2003.
Style-book for the T?ubingen Treebank of Written German(T?uBa-D/Z).
Seminar f?ur Sprachwissenschaft, Uni-versit?at T?ubingen, Germany.168
