85Modelling Atypical Syntax ProcessingMichael S. C. THOMASSchool of PsychologyBirkbeck College, Malet St.,London WC1E 7HXm.thomas@bbk.ac.ukMartin REDINGTONSchool of PsychologyBirkbeck College, Malet St.,London WC1E 7HXm.redington@ucl.ac.ukAbstractWe evaluate the inferences that can be drawnfrom dissociations in syntax processingidentified in developmental disorders andacquired language deficits.
We use an SRN tosimulate empirical data from Dick et al (2001)on the relative difficulty of comprehendingdifferent syntactic constructions under normalconditions and conditions of damage.
Weconclude that task constraints and internalcomputational constraints interact to predictpatterns of difficulty.
Difficulty is predicted byfrequency of constructions, by the requirementof the task to focus on local vs. globalsequence information, and by the ability of thesystem to maintain sequence information.
Wegenerate a testable prediction on the empiricalpattern that should be observed underconditions of developmental damage.1 Dissociations in language functionBehavioural dissociations in language, identifiedboth in cases of acquired brain damage in adultsand in developmental disorders, have often beenused to infer the functional components of theunderlying language system.
Generally theseattempted fractionations appeal to broaddistinctions within language.
However, fine-scaleddissociations have also been proposed, such as theloss of individual semantic categories or ofparticular linguistic features in inflecting verbs.Here, we consider the implications ofdevelopmental and acquired deficits for the natureof syntax processing.1.1 Developmental deficitsA comparison of developmental disorders suchas autism, Downs syndrome, Williams syndrome,Fragile-X syndrome, and Specific LanguageImpairment reveals that dissociations can occurbetween phonology, lexical semantics, morpho-syntax, and pragmatics.
The implications of suchfractionations remain controversial but will becontingent on understanding the developmentalorigins of language structures (Karmiloff-Smith,1998).
These processes remain to be clarified evenfor the normal course of development.In the area of syntax, Fowler (1998) concludedthat a consistent picture emerges.
Individuals withlearning disabilities are systematic in theirgrammatical knowledge, follow the normal courseof development, and show similar orders ofdifficulty in acquiring constructions.
However,such individuals can often handle only limitedlevels of syntactic complexity and thereforedevelopment seems to terminate at a lower level.While there is great variability in linguisticfunction both across different disorders and withinsingle disorders, this cannot be attributed solely todifferences in ?general cognitive functioning?
(e.g.,as assessed by problem solving ability).
Syntaxacquisition is therefore to some extent independentof IQ.
However, adults with developmentaldisorders who have successfully acquired syntaxtypically have mental ages of at least 6 or 7, an ageat which typically developing children also havewell-structured language.
The variability inoutcome has been attributed to various factorsspecific to language, including verbal workingmemory and the quality of phonologicalrepresentations (Fowler, 1998; McDonald, 1997).Most notably, disorders with different cognitiveabilities show similarity in syntactic acquisition.The apparent lack of deviance acrossheterogeneous disorders has been used to argue fora model of language acquisition that is heavilyconstrained by the brain that is acquiring thelanguage (Newport, 1990).1.2 Acquired deficits in adulthoodOne of the broadest distinctions in acquiredlanguage deficits is between Broca?s andWernicke?s aphasia.
Broca?s aphasics aresometimes described as having greater deficits ingrammar processing, and Wernicke?s aphasics ashaving greater deficits in lexical processing.
Thedissociation is taken to support the idea that thedivision between grammar and the lexicon is oneof the constraints that the brain brings to languageacquisition.Dick et al (2001) recently argued that four typesof evidence undermine this claim: (1) all aphasics86have naming deficits to some extent; (2) apparentlyagrammatic patients retain knowledge of grammarthat can be exhibited in grammaticalityjudgements; (3) grammar deficits are found inmany populations both with and without damage toBroca?s area, the reputed seat of syntax in thebrain; and (4) aphasic symptoms of languagecomprehension can be simulated in normal adultsby placing them in stressed conditions (e.g., viamanipulating the speech input or giving the subjecta distracter task).
Dick et al pointed out that insyntax comprehension, the constructions mostresilient in both aphasic patients and normal adultswith simulated aphasia are those that are mostregular or most frequent, and conversely thoseliable to errors are non-canonical and/or lowfrequency.
Dick et al (2001) illustrated thesearguments in an experiment that comparedcomprehension of four complex syntacticstructures:x Actives (e.g., The dog [subject] is biting thecow [object])x Subject Clefts (e.g., It is the dog [subject] thatis biting the cow [object])x Passives (e.g., The cow [object] is bitten bythe dog [subject])x Object Clefts (e.g., It is the cow [object] thatthe dog [subject] is biting)The latter two constructions are lower frequency,and have non-canonical word orders in which theobject precedes the subject.
Dick et al tested 56adults with different types of aphasia on a task thatinvolved identifying the agent of spoken sentences.Patients with all types of aphasia demonstratedlower performance on Passives and Object Cleftsthan Actives and Subject Clefts.
Moreover, normaladults given the same task but with a degradedspeech signal (either speeded up, low-pass filtered,or with noise added) or in combination with adistracter task (such as remembering a set of digits)produced a similar profile of performance to theaphasics (see Figure 1).Dick et al (2001) argued that the commonpattern of deficits could be explained by theCompetition Model (MacWhinney & Bates, 1989),which proposes that the difficulty of acquiringcertain aspects of language and their retention afterbrain damage could be explained by consideringcue validity (the reliability of a source ofinformation in predicting the structure of a targetlanguage) and cue cost (the difficulty of processingeach cue).
Cues high in validity and low in cost,such as Subject-Verb-Object word order inEnglish, should be acquired more easily and berelatively spared in adult breakdown.
The proposalis that for a given language, any domain-generalprocessing system placed under sub-optimalFigure 1.
Aphasic and simulated (human) aphasicdata from Dick et al (2001)conditions should exhibit a similar pattern ofdevelopmental or acquired deficits.
Thus Dick etal.
predicted that a connectionist model trained onan appropriate frequency-weighted corpus wouldshow equivalent vulnerability of non-canonicalword orders and low frequency constructions underconditions of damage.
In contrast to the inferencesdrawn from developmental deficits, the focus hereis on attributing similarities in patterns of acquireddeficits to features of the problem domain ratherthan constraints of the language system.2 Computational modellingProposals that site the explanation of behaviouraldata in the frequency structure of the problemdomain (here, the relative frequency of theconstruction types) are insufficient for threereasons: (1) language comprehension is not aboutpassive reception.
The language learner must dosomething with the words in order to derive themeanings of sentences.
It is the nature of thetransformations required that crucially determinestask difficulty, which statistics of language inputalone cannot reveal.
(2) Whatever the statistics ofthe environment, such information must beaccessed by an implemented learning system.
Thissystem may be differentially sensitive to certainfeatures of the input, and it may find certaintransformations more computationally expensivethan others, further modulating task difficulty.
(3)In the context of atypical syntax processing indevelopmental and acquired disorders, behaviouralDick et al Agent / Patient taskElderly vs. aphasic data20406080100Active SubjectCleftObject Cleft PassivePerformance%ElderlyAnomicConductionBrocaWernickeDick et al Agent / Patient taskNormal adults under stressed conditions20406080100Active SubjectCleftObject Cleft PassivePerformance%NormalCompressed +Visual DigitsNoise + VisualDigitsLow Pass +Compression87deficits are caused by changes in internalcomputational constraints.
Without animplemented, parameterised learning system, wecan have no understanding of how sub-optimalprocessing conditions generate behavioural deficitsin syntax processing.
To date, this issue has beenrelatively under-explored.The choice of learning system is evidently ofimportance here.
In this paper, we explore thebehaviour of a connectionist network, since thesesystems have been widely applied to phenomenawithin cognitive and language development(Elman et al, 1996) and more recently to capturingboth atypical development and acquired deficits inadults (Thomas & Karmiloff-Smith, 2002, 2003).3 Simulation DesignOur starting point is a set of models of syntaxacquisition proposed by Christiansen and Dale(2001).
These authors employed a simple recurrentnetwork (SRN; Elman, 1990), an architecture thatis the dominant connectionist model of sequenceprocessing in language studies and in sequencelearning more generally.
As is typical of currentconnectionist models of syntax processing, theChristiansen and Dale (henceforth C&D) modelfocuses on small fragments of grammar and asmall vocabulary.
Nevertheless, it provides auseful platform to begin considering the effects ofprocessing constraints on syntax processing.The following models performed a predictiontask at the word level.
At each time step, thenetwork was presented with the current word andhad to predict the next word in the sentence.
Thiscomponent of the task induces sensitivity tosyntactic structures.
A localist representation wasused, with each input unit corresponding to asingle word.
The artificial corpus consisted of 54words and included 6 nouns, 10 verbs, 5adjectives, and 10 functions words.
Nouns andverbs had inflected forms represented by separateword units (N: stem, pluralised; V: stem, pasttense, progressive, 3rd person singular).C&D investigated the effect of several cues onsyntax acquisition, such as prosody, stress, andword length.
Prosody was represented as utteranceboundary information that occurred at the end ofan utterance with 92% probability.
The utteranceboundary cue was represented by an additionalinput and output unit.Distributional cues of where words appeared invarious sentences, along with utterance boundaryinformation, were available to all networks.
Werefer to the networks that received only these cuesas the ?basic?
model.
We also tested a second setof ?multiple cue?
networks that also received cuesabout word length and stress.
Word length wasencoded with thermometer encoding, with one tothree units being activated according to the numberof syllables in the input word.
In English, longerwords tend to be content words.
This was reflectedin the vocabulary items that were selected for thegrammar.
Stress was encoded as a single unit thatwas activated for content words, which are stressedmore heavily.
The word length and stress unitswere present both as inputs and outputs, so thatmultiple cue networks had 59 input and outputunits to represent the words and cues.3.1 The materialsThe input corpus was a stochastic phrasestructure grammar, derived from the materials usedby C&D (2001).
The grammar featured a range ofconstructions (imperatives, interrogatives anddeclarative statements).
Frequencies were based onthose observed in child-directed language.
Weadded passives, subject and object cleftconstructions to the grammar, which is illustratedin Figure 2.Figure 2.
Stochastic phrase structure grammar,including the probabilities of each constructionThe four sentence types appeared with thefollowing frequency: (Declarative) Active: 16.8%,Subject Cleft: 0.84%, Object Cleft: 0.84%,Passives: 2.52%.
This gave a Passive-to-Activeratio of roughly 1:7, and ratio of OVS to SVOsentences of 1:21.
Dick and Elman (2001) foundthat for English, the Passive-to-Active ratio rangedfrom 1:2 to 1:9 across corpora and that subject andobject clefts appear in less than 0.05% of Englishsentences.
They found that the relative frequencyof word orders depended on whether one comparesthe passive OVS against transitive (SVO) orintransitive (SV) sentences and reported ratios thatvaried from 1:5 to 1:63 depending on corpus(spoken or written).
The simulation frequencieswere therefore an approximate fit, with the SubjectS -> Imperative [0.1] | Interrogative [0.3] | Declarative [0.6]Declarative -> NP V-int [0.35] | NP V-tran NP active [.28] |NP V-tran NP passive [0.042] |subject cleft [0.014] |object cleft [0.014] | NP-Adj [0.1] |That-NP [0.075] | You-P [0.125]NP-ADJ -> NP is/are adjectiveThat-NP -> that/those is/are NPYou-P -> you are NPImperative -> VPInterrogative -> Wh-Question [0.65] | Aux-Question [0.35]Wh-Question -> where / who / what is/are NP[0.5] | where / who / what do /does NP VP [0.5]Aux-Question -> do / does NP VP [0.33] |do / does NP wanna VP [0.33] |is / are NP adjective [0.34]NP -> a / the N-sing / N-plurVP -> V-int | V-trans NP88and Object Clefts slightly higher than in Englishdue to the requirement to have at least a handfulappear in our training corpus.We generated a corpus of 10,000 sentences fromthis grammar as our training materials for thenetwork, and a set of 100 test sentences for each ofthe active, passive, subject cleft and object cleftconstructions.3.2 Simulation OneThe Dick et al (2001) task consisted ofpresenting participants with a spoken sentence, andtwo pictures corresponding to the agent and patientof the sentence.
The participant?s task was toindicate with a binary choice which of the pictureswas the agent of the sentence.
For example, forsentences such as ?the dog is biting the cow?,participants were asked to ?press the button for theside of the animal that is doing the bad action?.Our next step was to implement this task in themodel.
One approach would be to train thenetwork to output at each processing step not onlythe next predicted word in the sentence but also thethematic role of the current input.
If the currentinput is a noun, this would be agent or patient.Joanisse (2000) proposed just such a solution toparsing in a connectionist model of anaphorresolution.
We will refer to the implementation ofactivating units for agent or patient (solely) on thesame cycle as the relevant noun as the ?Discrete?mapping problem of relating nouns to roles.The mapping problem adds to the difficulty ofthe prediction task.
We can assess the extent of thisdifficulty by measuring performance on theprediction component alone, against the metrics oftwo statistical models.
The bigram and trigrammodels are statistical descriptions of the sentenceset that predict the next word given the previoustwo or three words of context, respectively, andthese were derived from the observed frequenciesin the training set.Lastly, for the purposes of this simulation, we donot distinguish between the syntactic roles ofsubject and object, and semantic roles of agent andpatient, even though a more complex model mayseparate these levels and include a process thatmaps between them.
Although these simulationsconflate the syntactic and semantic categories, weuse the terms agent / patient for clarity in linking tothe Dick et al empirical data.3.2.1 MethodFor Simulation 1, we added two output units tothe C&D network.
The network was trained toactivate the first extra unit when the current inputelement was the subject / agent of the sentence,and to activate the second extra unit when theobject / patient of the sentence was presented.
Forall other inputs, the target activation of both unitswas zero.
Thus, the number of input and outputunits was 55 and 57 respectively for the basicmodel, and 59 units and 61 units for the multiple-cue model.The network?s ability to correctly predict thenext word was measured over the 55 word outputunits using the cosine between the target and actualoutput vectors.
On novel sentences, a perfectnetwork will only be able to predict the next itemprobabilistically.
However, over many test items,this measure gives a fair view of the network?sperformance and we followed C&D (2001) inusing this measure.We initially chose our parameters based on thoseused by C&D (2001).
Our learning rate was 0.1,and we trained the network for ten epochs.
Weperformed a simple search of the parameter spacefor the number of hidden units to establish a?normal?
condition (see Thomas & Karmiloff-Smith, 2003, for discussion of parameters definingnormality).
Eighty hidden units, the number usedby C&D, gave adequate results for both models.This value was used to define the normal model.We first evaluate normal performance at the endof training, then under the developmental deficit ofa reduction in hidden units in the start state, andfinally under the acquired deficit of a randomlesion to a proportion of connection weights fromthe trained network.3.2.2 ResultsOn the prediction component of the task, bothmodels demonstrated better prediction ability thanthe bigram model, and marginally less predictionability than the trigram model.
This is in contrast toC&D?s original prediction-only SRN model, whichexceeded trigram model performance.
It shows thatthe requirement to derive agent and patient rolesincreased the complexity of the learning problem,interfering with prediction ability.The role-assignment component of the task wasindexed by the activation of the agent and patientunits when presented with the second noun of thesentence.
At presentation of the first noun, therewas no information available in the test sentencesthat would allow the network to distinguishbetween the possible interpretations of thesentence.
At the second noun, the most active ofthe two units was assumed to drive theinterpretation of the sentence and subsequentpicture identification in the Dick et al task.Therefore, the network?s response was ?correct?for Active and Subject Cleft sentences if the?patient?
unit had the highest activation, and forPassive and Object Cleft sentences if the ?agent?89unit had the highest activation.
The scores,measured in terms of the proportion of correctinterpretations for the test sentences for eachconstruction are shown in Figure 3.Somewhat surprisingly, both the basic andmultiple-cue models exhibited better performanceon the Passive and Object Cleft sentences than onActive and Subject Cleft sentences.
(Thesedifferences were statistically reliable.)
The maindifference between the two models was lowerperformance on Subject Cleft in the basic model,implying that cues to content-word status help todisambiguate the two cleft constructions.Examining the profiles of performance for eachsentence type gives some insight into the dynamicsof the networks.
Figures 4 to 7 show the activationof the agent and patient units for the multiple-cuemodel during the processing of examples of eachconstruction, selected at random.
The Subject Cleftsentence shown in Figure 5 is typical of the patternfor both Active and Subject Cleft sentences.
Thatis, agent unit activation is close to 1.0 at the firstnoun, while patient unit activation is close to zero.At the second noun, the network is usually able tocorrectly distinguish the patient, but some agentunit activation also occurs.
Therefore, using ourdecision criteria, the network is not always able tocorrectly identify the patient, and scores on Activeand Subject Cleft sentences are not perfect.In contrast, in the example Passive and ObjectCleft sentences, the network incorrectly activatesthe agent unit at presentation of the first noun.
Atthis point, the network has no information thatcould possibly allow it to distinguish between thetwo different kinds of sentence, and so its responseis driven by the relative frequency of theconstructions.
However, for the second noun (theagent), although the patient unit does show someactivation, the agent unit is clearly favoured.Generally, the advantage of the agent unit for thePassive and Object Cleft sentences is greater thanthe advantage of the patient unit for the Active andSubject Cleft sentences.
This can be explained by ageneral bias in the network in favour of the agentunit.
In the training set, agents (subjects) occurmuch more frequently than patients (objects).
Allof the interrogatives and imperatives only haveagents, and these comprise 30% of the trainingsentences.
Thus, paradoxically, the network sufferswhen attempting to produce activation on thepatient unit, and this impacts on the Active andSubject Cleft performance, despite the muchgreater frequency of these constructions.Figures 8 and 9 illustrate the affects of initiallyreducing the numbers of hidden units in thenetwork and of lesioning connections in thePassive0.00.20.40.60.81.0the croco-dilesare eaten by the catUnitActivationagentpatientActive0.00.20.40.60.81.0a boy eats the catUnitActivationagentpatientSubject Cleft0.00.20.40.60.81.0it is a boy that is kissing the bunnyUnitActivationagentpatientObject Cleft0.00.20.40.60.81.0it is a boy that a dog is eatingUnitActivationagentpatientSimulated Agent / Patient taskDiscrete Mapping Model0%20%40%60%80%100%Active SubjectCleftObjectCleftPassivePerformance%Basic modelMultiple cue modelSimulated Agent / Patient taskDiscrete Mapping model: Acquired Deficit0%20%40%60%80%100%Active SubjectcleftsObjectcleftsPassivePerformance% Normal5% lesion10% lesion20% lesionSimulated Agent / Patient taskDiscrete Mapping model - Developmental Deficit0%20%40%60%80%100%Active SubjectCleftObject Cleft PassivePerformance%20 hid.
units40 hid.
units80 hid.
unitsFigure 3Figure 4Figure 5Figure 6Figure 7Figure 8 Figure 990endstate.
In both cases, non-optimal processingconditions exaggerated the pattern of taskdifficulty, with Actives and Subject Clefts failingto be learned or showing greater impairment afterlesioning.
Object Clefts are the most easily learntand most robust to damage, despite their non-canonical word order and low frequency.
With thetask definition of responding ?agent?
to the secondnoun, this construction gains most from theprevalence of the agent status of nouns in thecorpus.This interpretation of the Dick et al agent-identification task does not provide an adequate fitto the human data, either for normal or atypicalperformance.
Why not?
This implementation of thetask requires that the network keep track of tworoles at the same time and assign those roles at thecorrect moment.
It is therefore driven by theindependent probability of a noun being an agentor a patient at multiple time points through thesentence.
The result is a de-emphasis of globalsequence information and an emphasis on locallexical information, leading to a relative advantageof responding ?agent?
to any noun.In the Dick et al task, the participant is asked tomake a single decision based on the entiresentence, rather than continously monitor word-by-word probabilities.
Responses occurred between 2and 4 seconds after sentence onset, with wordspresented at around 3 words-per-second.
In thenext section, we therefore provide an alternateimplementation of the task based on a singlecategorisation decision for the whole sentence.
ButSimulation 1 serves as a demonstration that thestatistics of the input set alne do not generate thetask difficulty.
It is the mappings required of thenetwork.
Moreover, we might predict that amodification of the Dick et al study to encourageon-line monitoring of roles would alter the patternof task difficulty.
Thus, the four options might bepresented as pictures (each noun twice, once asagent, once as patient), and the participants?
eye-gaze direction recorded as the sentence unfolds.3.3 Simulation TwoAn alternate implementation of the Dick et altask is that the network should be required to makea single categorisation on the whole sentence as towhether the agent precedes the patient, or thepatient precedes the agent.
This implementationfollows the assumption that task performance isdriven by higher-level sentence-based informationrather than lexically-based information.
A singleunit can serve to categorise the input sentence asagent-then-patient or patient-then-agent.
Duringtraining, the target activation for the unit is appliedcontinuously throughout the entire utterance.
Wetherefore call this the Continuous Mappingproblem for sentence comprehension.
Like theDiscrete Mapping problem, the Continuous versionhas also been employed in previous connectionistmodels of parsing (Miikkulainen & Mayberry,1999).
(Note that Morris, Cottrell & Elman, 2000,used an implementation that combines Discreteand Continuous methods, providing a trainingsignal that is activated when a word appears and isthen maintained until the end of the sentence).
TheContinous method generates a training signal forcomprehension.
It does not constrain on-linecomprehension, which may be subject to garden-pathing and dynamic revision.3.3.1 MethodA single output unit was trained to produce anactivation of 1 for sentences with Subject-Objectword order (active and subject cleft constructions),and 0 for Object-Subject word order (passives andobject cleft constructions).
Apart from thisdifference, the basic and multiple-cue models wereidentical in all other respects, with 55 input andoutput units in the basic model, and 59 units in themultiple cue model.
As before, we trained thenetwork on 10,000 sentences generated by thestochastic phrase structure grammar, and tested thetrained network on sets of 100 Active, Passive,Subject Cleft and Object Cleft sentences.
Onehundred and twenty hidden units were required todefine the ?normal condition?
for these simulations.3.3.2 ResultsAs with Simulation 1, the prediction ability ofboth basic and multiple-cue models suffered due tothe burden imposed by the mapping task.
Althoughthe networks?
performance reliably exceeded abigram prediction model, the trigram statisticalmodel was slightly superior.The network?s ability to correctly ?interpret?
thetest sentences was measured as follows.
If thesemantic output unit?s activation at the time ofsecond noun presentation was greater than 0.5,then the response was assumed to indicate that thesentence had Subject-Object word order and theagent was the first noun.
If the activation was lessthan or equal to 0.5, then the response wasassumed to indicate that the sentence had Object-Subject word order and the agent was the secondnoun.
Although the target output for the networkwas consistent throughout each sentence, weselected the presentation of the second noun as ourpoint of measurement, as this was where thenetwork?s discrimination ability was greatest.Figure 10 depicts performance on the fourconstructions.On Active, Subject Cleft, and Passive sentencesthe basic model showed appropriate performance,91but it failed to correctly distinguish the ObjectCleft sentences.
Doubling the hidden units did notmarkedly alter this pattern.
The multiple-cuemodel showed a much better fit to the human data,performing at close to ceiling for the Active,Passive and Subject Cleft constructions, andscoring in excess of 85% correct on Object Cleftconstructions.
The content-word cues provided inthe multiple-cue model again appeared importantin disambiguating the cleft constructions.Focusing on the multiple-cue model, Figures 11-14 show the activation of the network?s semanticoutput unit over a random sentence from each ofthe four test constructions.
For the Active sentence,the network maintains a fairly constant high levelof activation throughout the sentence.
That is, itstarts with the ?assumption?
that sentences willhave a Subject-Object word order, and becomesmore certain of this result (as shown by risingoutput activation) as the sentence proceeds.For the Passive sentence, again, the networkstarts out assuming that the sentence will have themore frequent Subject-Object word order.
But onseeing ?eaten by?, the network reverses its originaldiagnosis.
However, the influence of this cuenoticeably fades as the sentence proceeds.
Itpersists enough that by the second noun, thenetwork (just) manages to indicate correctly thatthe sentence has Object-Subject word order.The Cleft constructions show a very differentpattern.
For the Subject Clefts, the network beginswith a low output value from the semantic unit.This increases slightly as the first determiner andnoun are presented, but the most valuable cuearrives with the words ?that is kissing?.
Theseprovide a perfect indicator (in this context) that thesentence has Subject-Object word order, and theactivation of the semantic unit jumps dramatically,staying near ceiling for the rest of the sentence.Finally, examining the Object Cleft sentence,output activation again starts low and rises onlymodestly during presentation of the first noun.However, the presence of a second noun followingimmediately after the first pulls the activation backdown, to correctly indicate that the sentence hasObject-Subject word order.
Notice that, as with thePassive sentence, as the distance increases from thecue that marks the (less common) status of theObject Cleft sentence, so the activation level of thesemantic unit tends to drift back to the default ofthe more frequent constructions.Figures 15 and 16 illustrate, respectively, theeffects of reducing the initial numbers of hiddenunits in the network and of lesioning connectionsin the endstate.
In the case of acquired damage,non-optimal processing conditions exaggerate theSimulated Agent / patient taskContinuous Mapping Model0%20%40%60%80%100%Active SubjectCleftObjectCleftPassivePerformance%Basic modelMultiple cue modelSimulated Agent / Patient taskContinuous Mapping model - Acquired Deficit0%20%40%60%80%100%Active SubjectCleftObjectCleftPassivePerformance% Normal5% lesion10% lesion20% lesionSimulated Agent / Patient taskContinuous Mapping model - Developmental Deficit0%20%40%60%80%100%Active SubjectCleftObjectCleftPassivePerformance%80 hid.
units100 hid.
units120 hid.
UnitsActive0.00.20.40.60.81.0a boy eats the catSentencetype(1=SVO)Subject Cleft0.00.20.40.60.81.0it is a boy that is kissing the bunnySentencetype(1=SVO)Passive0.00.20.40.60.81.0the croco-dilesare eaten by the catSentencetype(1=SVO)Object Cleft0.00.20.40.60.81.0it is a boy that a dog is eatingSentencetype(1=SVO)Figure 10Figure 11Figure 12Figure 13Figure 14Figure 15 Figure 1692pattern of task difficulty, with Passives and ObjectCleft?s showing greater impairment after lesioningin line with the empirical data in Figure 1.Interestingly, in the case of the developmentaldeficit, the pattern is subtly different.
While ObjectClefts show increased vulnerability, Passives arefar more resilient to developmental damage.We carried out further analysis of this difference.Using the examples in Figs.
13 and 14, the cuespredicting Object-Subject order for Passives turnedout to be the inflected verb ?eaten?
followed by?by?, i.e., two lexical cues (the second redundant).For Object Clefts, the cue for Object-Subject orderwas sequence-based information: in thisconstruction, two nouns are not separated by averb.
This is marked by the arrival of a secondnoun prior to a verb, that is, the words ?a?
and?dog?.
While both lexical and sequence cues arelow frequency by virtue of their constructions, theydiffer in that the Passive cue comprises lexicalitems unique to this construction, while the ObjectCleft cue involves a particular sequence of lexicalitems that also appear in other other constructions.Examination of activation dynamics reveals thatboth low frequency cues are lost after acquireddamage.
However, the network with thedevelopmental deficit retains the ability to learnthe lexically-based cue that marks the Passive, buthas insufficient resources to learn the sequence-based cue that marks the Object Cleft construction.Three points are evident here.
First, the modelmakes a strong empirical prediction that whendevelopmental deficits are compared to acquireddeficits, passive constructions will be relativelyless vulnerable.
This renders the model testableand therefore falsifiable.
Second, the modeldemonstrates the differential computationalrequirements of tasks driven by local (lexically-based) and global (sequence-based) information ina parsing task.
Third, the model reveals thedistinction between acquired and developmentaldeficits, with compensation possible in the lattercase for cues with low processing cost (seeThomas & Karmiloff-Smith, 2002, for discussion).4 DiscussionImplemented learning models are an essentialrequirement to begin an exploration of the internalconstraints that influence successful and atypicalsyntax processing.
Our model necessarily makessimplifications to begin this exploration (e.g., thedistribution and frequency of lexical items acrossconstructions is not in reality uniform; cleftconstructions may have different stress / prosodiccues).
A precise quantitative fit to the empiricaldata must await models that include those factors.However, the current model is sufficient todemonstrate the importance of the mapping task inspecifying difficulty (over and above the statisticsof the input); how internal processing constraintsinfluence performance; and how local and globalinformation show a differential contribution to andvulnerability in sequence processing in a recurrentconnectionist network.5 AcknowledgementsThis research was supported by grants from theBritish Academy and the Medical ResearchCouncil (G0300188) to Michael Thomas.ReferencesChristiansen, M. & Dale, R. 2001.
Integrating distributional,prosodic and phonological information in a connectionistmodel of language acquisition.
In Proceedings of the 23rdAnnual Conference of the Cognitive Science Society (p.220-225).
Mahwah, NJ: LEA.Dick, F. & Elman, J.
2001.
The frequency of major sentencetypes over discourse levels: A corpus analysis.
CRL:Newsletter, 13.Dick, F., Bates, E., Wulfeck, B., Aydelott, J., Dronkers, N., &Gernsbacher, M. 2001.
Language deficits, localization, andgrammar: Evidence for a distributive model of languagebreakdown in aphasic patients and neurologically intactindividuals.
Psychological Review, 108(3): 759-788.Elman, J.
1990.
Finding structure in time.
Cognitive Science,14, 179-211.Elman, J., et al, (1996).
Rethinking innateness.
Cambridge,Mass.
: MIT Press.Fowler, A.
(1998).
Language in mental retardation:Associations with and dissociations from general cognition.In J. Burack et al, Handbook of Mental Retardation andDevelopment (p.290-333).
Cambridge, UK: CUP.Joanisse, M. 2000.
Connectionist phonology.
UnpublishedPh.D.
Dissertation, University of Southern California.Karmiloff-Smith, A.
(1998).
Development itself is the key tounderstanding developmental disorders.
Trends in CognitiveSciences, 2(10): 389-398.MacWhinney, B.
& Bates, E. 1989.
The cross-linguistic studyof sentence processing.
New York: CUP.McDonald, J.
1997.
Language acquisition: The acquisition oflinguistic structure in normal and special populations.
Annu.Rev.
Psychol., 48, 215-241Miikkulainen, R. & Mayberry, M. 1999.
Disambiguation andgrammar as emergent soft constraints.
In B.
MacWhinney(ed.)
Emergence of Language.
Hillsdale, NJ: LEA.Morris, W., Cottrell, G., and Elman, J.
2000.
A connectionistsimulation of the empirical acquisition of grammaticalrelations.
In S. Wermter & R. Sun (eds.
), Hybrid NeuralSystems.
Heidelberg: Springer Verlag.Newport, E. 1990.
Maturational constraints on languagelearning.
Cognitive Science, 14, 11-28.Thomas, M.S.C.
& Karmiloff-Smith, A.
(2002).
Aredevelopmental disorders like cases of adult brain damage?Implications from connectionist modelling.
Behaviouraland Brain Sciences, 25(6), 727-788.Thomas, M.S.C.
& Karmiloff-Smith, A.
2003.
Modellinglanguage acquisition in atypical phenotypes.
PsychologicalReview, 110(4), 647-682.
