AUTOMATIC  AL IGNMENT IN PARALLEL  CORPORAHarris Papageorgiou, Lambros Cranias, Stelios Piperidis IInstitute for Language and Speech Processing22, Margari Street, 115 25 Athens, GreeceStelios.Piperidis@eurokom.ieABSTRACTThis paper addresses the alignment issue inthe framework of exploitation of large bi-multilingual corpora for translation purposes.
Ageneric alignment scheme is proposed that canmeet varying requirements of differentapplications.
Depending on the level at whichalignment is sought, appropriate surfacelinguistic information is invoked coupled withinformation about possible unit delimiters.
Eachtext unit (sentence, clause or phrase) isrepresented by the sum of its content ags.
Theresults are then fed into a dynamic programmingframework that computes the optimum alignmentof units.
The proposed scheme has been tested atsentence l vel on parallel corpora of the CELEXdatabase.
The success rate exceeded 99%.
Thenext steps of the work concern the testing of thescheme's efficiency at lower levels endowed withnecessary bilingual information about potentialdelimiters.INTRODUCTIONParallel linguistically meaningful text unitsare indispensable in a number of NLP andlexicographic applications and recently in the socalled Example-Based Machine Translation(EBMT).As regards EBMT, a large amount of bi-multilingual translation examples is stored in adatabase and input expressions are rendered inthe target language by retrieving from thedatabase that example which is most similar tothe input.
A task of crucial importance in thisframework, is the establishment ofcorrespondences between units of multilingualtexts at sentence, phrase or even word level.The adopted criteria for ascertaining theadequacy of alignment methods are stated asfollows :1This research was supported by the LRE ITRANSLEARN project of the European Union?
an alignment scheme must cope with theembedded extra-linguistic data (tables, anchorpoints, SGML markers, etc) and their possibleinconsistencies.?
it should be able to process a large amountof texts in linear time and in a computationallyeffective way.?
in terms of performance a considerablesuccess rate (above 99% at sentence level) mustbe encountered in order to construct a databasewith truthfully correspondent units.
It is desirablethat the alignment method is language-independent.s the proposed method must be extensible toaccommodate future improvements.
In addition,any training or error correction mechanismshould be reliable, fast and should not requirevast amounts of data when switching from a pairof languages to another or dealing with differenttext type corpora.Several approaches have been proposedtackling the problem at various levels.
\[Catizone89\] proposed linking regions of text according tothe regularity of word co-occurrences acrosstexts.\[Brown 91\] described a method based on thenumber of words that sentences contain.Moreover, certain anchor points and paragraphmarkers are also considered.
The method hasbeen applied to the Hansard Corpus achieving anaccuracy between 96%-97%.\[Gale 91\] \[Church 93\] proposed a methodthat relies on a simple statistical model ofcharacter lengths.
The model is based on theobservation that longer sentences in one languagetend to be translated into longer sequences in theother language while shorter ones tend to betranslated into shorter ones.
A probabilistic scoreis assigned to each pair of proposed sentencepairs, based on the ratio of lengths of the twosentences and the variance of this ratio.334Although the apparent efficacy of the Gale-Church algorithm is undeniable and validated ondifferent pairs of languages, it faces problemswhen handling complex alignments.
The 2-1alignments had five times the error rate of 1-1.The 2-2 category disclosed a 33% error rate,while the 1-0 or 0-1 alignments were totallymissed.To overcome the inherited weaknesses of theGale-Church method, \[Simard 92\] proposedusing cognates, which are pairs of tokens ofdifferent languages which share "obvious"phonological or orthographic and semanticproperties, since these are likely to be used asmutual translations.In this paper, an alignment scheme isproposed in order to deal with the complexity ofvarying requirements envisaged by differentapplications in a systematic way.
For example, inEBMT, the requirements are strict in terms ofinformation integrity but relaxed in terms ofdelay and response time.
Our approach is basedon several observations.
First of all, we assumethat establishment of correspondences betweenunits can be applied at sentence, clause, andphrase level.
Alignment at any of these levels hasto invoke a different set of textual and linguisticinformation (acting as unit delimiters).
In thispaper, alignment is tackled at sentence l vel.THE AL IGNMENT ALGORITHM_Content words, unlike functional ones, mightbe interpreted as the bearers that conveyinformation by denoting the entities and theirrelationships in the world.
The notion ofspreading the semantic load supports the ideathat every content word should be represented asthe union of all the parts of speech we can assignto it \[Basili 92\].
The postulated assumption isthat a connection between two units of text isestablished if, and only if, the semantic load inone unit approximates the semantic load of theother.Based on the fact that the principalrequirement in any translation exercise ismeaning preservation across the languages of thetranslation pair, we define the semantic load of asentence as the patterns of tags of its contentwords.
Content words are taken to be verbs,nouns, adjectives and adverbs.
The complexity oftransfer in translation imposes the considerationof the number of content ags which appear in atag pattern.
By considering the total number ofcontent tags the morphological derivationprocedures observed across languages, e.g.
thetransfer of a verb into a verb+deverbal nounpattern, are taken into account.
Morphologicalambiguity problems pertaining to content wordsare treated by constructing ambiguity classes(acs) leading to a generalised set of content ags.It is essential here to clarify that in thisapproach no disambiguation module isprerequisite.
The time breakdown formorphological tagging, without a disambiguatordevice, is according to \[Cutting 92\] in the orderof 1000 ~tseconds per token.
Thus, tens ofmegabytes of text may then be tagged per hourand high coverage can be obtained withoutprohibitive ffort.Having identified the semantic load of asentence, Multiple Linear Regression is used tobuild a quantitative model relating the contenttags of the source language (SL) sentence to theresponse, which is assumed to be the sum of thecounts of the corresponding content ags in thetarget language (TL) sentence.
The regressionmodel is fit to a set of sample data which hasbeen manually aligned at sentence level.
Sincewe intuitively believe that a simple summationover the SL content ag counts would be a rathergood estimator of the response, we decide thatthe use of a linear model would be a cost-effective solution.The linear dependency of y (the sum of thecounts of the content ags in the TL sentence)upon x i (the counts of each content ag categoryand of each ambiguity class over the SLsentence) can be stated as :Y=bo+b 1 x 1 ?b2x2+b3x3 +--.+bnxn~ (I)where the unknown parameters {bi} are theregression coefficients, and s is the error ofestimation assumed to be normally distributedwith zero mean and variance 02 .In order to deal with different taggers andalternative tagsets, other configurations of (1),merging acs appropriately, are alsorecommended.
For example, if an acs accountsfor unknown words, we can use the fact thatmost unknown words are nouns or proper nounsand merge this category with nouns.
We can alsomerge acs that are represented with only a fewdistinct words in the training corpus.
Moreover,the use of relatively few acs (associated withcontent words) reduces the number of parameters335to be estimated, affecting the size of the sampleand the time required for training.The method of least squares is used toestimate the regression coefficients in (1).Having estimated the b i and 0 2, theprobabilistic score assigned to the comparison oftwo sentences across languages i  just the areaunder the N(0,o 2) p.d.f., specified by theestimation error.
This probabilistic score isutilised in a Dynamic Programming (DP)framework similar to the one described in \[Gale91\].
The DP algorithm is applied to alignedparagraphs and produces the optimum alignmentof sentences within the paragraphs.EVALUATIONThe application on which we are developingand testing the method is implemented on theGreek-English language pair of sentences of theCELEX corpus (the computerised documentationsystem on European Community Law).Training was performed on 40 Articles ofthe CELEX corpus accounting for 30000 words.We have tested this algorithm on a randomlyselected corpus of the same text type of about3200 sentences.
Due to the sparseness of acs(associated only with content words) in ourtraining data, we reconstruct (1) by using fourvariables.
For inflective languages like Greek,morphological information associated to wordforms plays a crucial role in assigning a singlecategory.
Moreover, by counting instances of acsin the training corpus, we observed that wordsthat, for example, can be a noun or a verb, are(due to the lack of the second singular person inthe corpus) exclusively nouns.
Hence :Y=bo+b 1x 1 +b2x2+b3x3+b4x4+s (2)where x 1 represents verbs, x 2 stands for nouns,unknown words, vernou (verb or noun) andnouadj (noun or adjective), x3 adjectives andveradj (verb or adjective), x 4 adverbs andadvadj (adverb or adjective )02 was estimated at 3.25 on our trainingsample, while the regression coefficients were:b 0 = 0.2848,b 1 = 1.1075, b 2 = 0.9474,b 3 = 0.8584,b 4 = 0.7579An accuracy that approximated a 100%success rate was recorded.
Results are shown inTable 1.
It is remarkable that there is no need forany lexical constraints or certain anchor points toimprove the performance.
Additionally, the samemodel and parameters can be used in order tocope with the infra-sentence alignment.In order to align all the CELEX texts, weintend to prepare the material (text handling, postagging in different languages pairs and differenttag sets, etc.)
so that we will be able to evaluatethe method on a more reliable basis.
We alsohope to test the method's efficiency at phraselevel endowed with necessary bilingualinformation about phrase delimiters.
It will beshown there, that reusability of previousinformation facilitates tuning and resolving ofinconsistencies between various delimiters.category1-0 or 0-1N correct matches4 51-1 3178 31782-1 or 1-2 36 352-2 0 0iTable 1 : Matches in sentence pairs of theCELEX corpusREFERENCES.\[Basili 92\] Basili R. Pazienza M. Velardi P."Computational lexicons: The neat examples andthe odd exemplars".
Prec.
of the ThirdConference on Applied NLP 1992\[Brown 91\] Brown P. Lai J. and Mercer R."Aligning sentences in parallel corpora".
Prec.
ofACL 1991\[Catizone 89\] Catizone R. Russell G. WarwickS.
"Deriving translation data from bilingualtexts".
Prec.
of the First Lexical AcquisitionWorkshop, Detroit 1989\[Church 93\] Church K. "Char_align: A programfor aligning parallel texts at character level"Prec.
of ACL 93\[Cutting 92\] Cutting D. Kupiec J. Pedersen J.Sibun P. "A practical part-of-speech tagger "Proc.of ACL 1992\[Gale 91\] Gale W. Church K. "A program foraligning sentences in bilingual corpora", Prec.
ofACL 1991\[Simard 92\] Simard M. Foster G. Isabelle P."Using cognates to align sentences in bilingualcorpora" Prec.
of TMI 1992336
