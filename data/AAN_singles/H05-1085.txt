Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 676?683, Vancouver, October 2005. c?2005 Association for Computational LinguisticsImproving Statistical MT through Morphological AnalysisSharon GoldwaterDept.
of Cognitive and Linguistic SciencesBrown Universitysharon goldwater@brown.eduDavid McCloskyDept.
of Computer ScienceBrown Universitydmcc@cs.brown.eduAbstractIn statistical machine translation, estimat-ing word-to-word alignment probabilitiesfor the translation model can be difficultdue to the problem of sparse data: mostwords in a given corpus occur at most ahandful of times.
With a highly inflectedlanguage such as Czech, this problem canbe particularly severe.
In addition, muchof the morphological variation seen in Czechwords is not reflected in either the morphol-ogy or syntax of a language like English.
Inthis work, we show that using morphologi-cal analysis to modify the Czech input canimprove a Czech-English machine transla-tion system.
We investigate several differ-ent methods of incorporating morphologicalinformation, and show that a system thatcombines these methods yields the best re-sults.
Our final system achieves a BLEUscore of .333, as compared to .270 for thebaseline word-to-word system.1 IntroductionIn a statistical machine translation task, the goal isto find the most probable translation of some foreignlanguage text f into the desired language e. That is,the system seeks to maximize P (e|f).
Rather thanmaximizing P (e|f) directly, the standard noisy chan-nel approach to translation uses Bayes inversion tosplit the problem into two separate parts:argmaxeP(e|f) = argmaxeP(e)P(f |e) (1)where P (e) is known as the language model andP (f |e) is known as the translation model.
The limit-ing factor in machine translation is usually the qual-ity of the translation model, since the monolingualresources needed for training the language model aregenerally more available than the parallel corporaneeded for training the translation model.Due to the difficulty in obtaining large parallel cor-pora, sparse data is a serious issue when estimatingthe parameters of the translation model.
This prob-lem is compounded when one or both of the lan-guages involved is a highly inflected language.
In thispaper, we present a series of experiments suggestingthat morphological analysis can be used to reducedata sparseness and increase similarity between lan-guages, thus improving the quality of machine trans-lation for highly inflected languages.
Our work is ona language pair in which the input language (Czech)is highly inflected, and the output language (English)is not.
We discuss in Section 5 how our methodsmight be generalized to pairs where both languagesare highly inflected.The plan of this paper is as follows: In Section2, we review previous work on using morphologi-cal analysis for statistical machine translation.
InSection 3, we describe several methods for utilizingmorphological information in a statistical translationmodel.
Section 4 presents the results of our experi-ments using these methods.
Sections 5 and 6 discussthe results of our experiments and conclude the pa-per.2 Previous WorkUntil recently, most machine translation projects in-volved translating between languages with relativelylittle morphological structure.
Nevertheless, a fewresearch projects have investigated the use of mor-phology to improve translation quality.
Niessen andNey (2000; 2004) report work on German-Englishtranslation, where they investigate various typesof morphosyntactic restructuring, including mergingGerman verbs with their detached prefixes, annotat-ing a handful of frequent ambiguous German wordswith POS tags, combining idiomatic multi-word ex-pressions into single words, and undoing question in-676version and do-insertion in both German and En-glish.
In addition, Niessen and Ney (2004) decom-pose German words into a hierarchical representa-tion using lemmas and morphological tags, and usea MaxEnt model to combine the different levels ofrepresentation in the translation model.
The resultsfrom these papers indicate that on corpus sizes upto 60,000 parallel sentences, the restructuring op-erations yielded a large improvement in translationquality, but the morphological decomposition pro-vided only a slight additional benefit.
However, sinceGerman is not as morphologically complex as Czech,we might expect a larger benefit from morphologicalanalysis in Czech.Another project utilizing morphological analysisfor statistical machine translation is described by Lee(2004).
Lee?s system for Arabic-English translationtakes as input POS-tagged English and Arabic text,where the Arabic words have been pre-segmentedinto stems and affixes.
The system performs an ini-tial alignment of the Arabic morphemes to the En-glish words.
Based on the consistency of the EnglishPOS tag that each Arabic morpheme aligns to, thesystem determines whether to keep that morphemeas a separate item, merge it back onto the stem,or delete it altogether.
In addition, multiple occur-rences of the determiner Al within a single Arabicnoun phrase are deleted (i.e.
only one occurrenceis allowed).
Using a phrase-based translation model,Lee found that Al-deletion was more helpful than therest of the morphological analysis.
Also, Al-deletionhelped for training corpora up to 3.3 million sen-tences, but the other morphological analysis helpedonly on the smaller corpus sizes (up to 350,000 paral-lel sentences).
This result is consistent with anecdo-tal evidence suggesting that morphological analysisbecomes less helpful as corpus sizes increase.
How-ever, since parallel corpora of hundreds of thousandsof sentences or more are often difficult to obtain, itwould still be worthwhile to develop a method forimproving systems trained on smaller corpora.Previous results on Czech-English machine trans-lation suggest that morphological analysis may bequite productive for this highly inflected languagewhere there is only a small amount of closely trans-lated material.
C?mejrek et al (2003), while not fo-cusing on the use of morphology, give results indicat-ing that lemmatization of the Czech input improvesBLEU score relative to baseline.
These results sup-port the earlier findings of Al-Onaizan et al (1999),who used subjective scoring measures.
Al-Onaizanet al measured translation accuracy not only forlemmatized input, but for an input form they re-fer to as Czech?.
Czech?
is intended to capture manyof the morphological distinctions of English, whilediscarding those distinctions that are Czech-specific.The Czech?
input was created by distinguishing theCzech lemmas for singular and plural nouns, differ-ent verb tenses, and various inflections on pronouns.Artificial words were also added automatically incases where syntactic information in the Czech parsetrees indicated that articles, pronouns, or preposi-tions might be expected in English.
The transforma-tion to Czech?
provided a small additional increasein translation quality over basic lemmatization.The experiments described here are similar tothose performed by Al-Onaizan et al (1999), butthere are several important differences.
First, we useno syntactic analysis of the Czech input.
Our intentis to determine how much can be gained by a purelymorphological approach to translation.
Second, wepresent some experiments in which we modify thetranslation model itself to take advantage of morpho-logical information, rather than simply transformingthe input.
Finally, our use of BLEU scores ratherthan subjective measurements allows us to performmore detailed evaluation.
We examine the effects ofeach type of morphological information separately.3 Morphology for MTMorphological variations in Czech are reflected inseveral different ways in English.
In some cases, suchas verb past tenses or noun plurals, morphologicaldistinctions found in Czech are also found in English.In other instances, English may use function wordsto express a meaning that occurs as a morphologicalvariant in Czech.
For example, genitive case markingcan often be translated as of and instrumental caseas by or with.
In still other instances, morphologi-cal distinctions made in Czech are either completelyabsent in English (e.g.
gender on common nouns)or are reflected in English syntax (e.g.
many casemarkings).
Handling these correspondences betweenmorphology and syntax requires analysis above thelexical level and is therefore beyond the scope of thispaper.
However, morphological analysis of the Czechinput can potentially be used to improve the trans-lation model by exploiting the other types of corre-spondences we have mentioned.Before we describe how this can be done, it is im-portant to clarify the kind of morphological anal-ysis we assume in our input.
Our data comesfrom the Prague Czech-English Dependency Tree-bank (PCEDT) (Hajic?, 1998; C?mejrek et al, 2004),the Czech portion of which has been fully annotatedwith morphological information.
Each Czech word inthe corpus is associated with an analysis containingthe word?s lemma and a sequence of morphological677Pro/pro/RR--4----------ne?koho/ne?kdo/PZM-4----------by/by?t/Vc-X---3-------jej??/jeho/PSZS1FS3-------proveden??/proveden??/NNNS4-----A----me?lo/m?
?t/VpNS---XR-AA---smysl/smysl/NNIS4-----A----././Z:-------------Figure 1: A sentence from the PCEDT corpus.
Eachtoken is followed by its lemma and a string givingthe values of up to 15 morphological tags.
Dashesindicates tags that are not applicable for a particu-lar token.
This sentence corresponds to the Englishsentence It would make sense for somebody to do it.tags.
These tags provide values along several mor-phological dimensions, such as part of speech, gen-der, number, tense, and negation.
There are a totalof 15 dimensions along which words may be charac-terized, although most words have a number of di-mensions unspecified.
An example sentence from theCzech corpus is shown in Figure 1.In what follows, we describe four different waysthat the Czech lemma and tag information can beused to modify the parameters of the translationmodel.
The first three of these are similar to the workof Al-Onaizan et al (1999) and involve transforma-tions to the input data only.
The assumptions un-derlying the word alignment model P (fj|ei) (wherefj and ei are individual words in an aligned sen-tence pair) are maintained.
The fourth method ofincorporating morphological information is novel andchanges the alignment model itself.3.1 LemmasA very simple way to modify the input data us-ing morphological information is by replacing eachwordform with its associated lemma (see Figure 2).Based on previous results (Al-Onaizan et al, 1999;C?mejrek et al, 2003), we expected that this trans-formation would lead to an improvement in trans-lation quality due to reduction of data sparseness.However, since lemmatization does remove some use-ful information from the Czech wordforms, we alsotried two alternative lemmatization schemes.
First,we tried lemmatizing only certain parts of speech,leaving other parts of speech alone.
We reasonedthat nouns, verbs, and pronouns all carry inflectionalmorphology in English, so by lemmatizing only theother parts of speech, we might retain some of thebenefits of full lemmatization without losing as muchinformation.
We also tried lemmatizing all parts ofspeech except pronouns, which are very common andtherefore should be less affected by sparse data prob-lems.As a second alternative to full lemmatization, weexperimented with lemmatizing only the less fre-quent wordforms in the corpus.
This allows thetranslation system to use the full wordform infor-mation from more frequent forms, where sparse datais less of a problem.To determine whether knowledge of lemmas wasactually necessary, we compared lemmatization withword truncation.
We truncated each wordform in thedata after a fixed number of characters, as suggestedby Och (1995).3.2 PseudowordsAs discussed earlier, much of the information en-coded in Czech morphology is encoded as functionwords in English.
One way to reintroduce some ofthe information lost during Czech lemmatization isby using some of the morphological tags to add ex-tra ?words?
to the Czech input.
In many cases,these pseudowords will also increase the correspon-dence of English function words to items in the Czechinput.
In our system, each pseudoword encodes asingle morphological tag (feature/value pair), suchas PER 1 (?first person?)
or TEN F (?future tense?
).Figure 2 shows a Czech input sentence after gener-ating pseudowords for the person feature on verbs.We expected that the class of tags most likely tobe useful as pseudowords would be the person tags,because Czech is a pro-drop language.
Using theperson tags as pseudowords should simulate the ex-istence of pronouns for the English pronouns to alignto.
We also expected that negation (which is ex-pressed on verbs in Czech) would be a useful pseu-doword, and that case markings might also be helpfulsince they sometimes correspond to prepositions inEnglish, such as of, with, or to.3.3 Modified LemmasIn some cases, such as the past tense, Czech mor-phology is likely to correspond not to a functionword in English, but rather to English inflectionalmorphology.
In order to capture this kind of phe-nomenon, we experimented with concatenating theCzech morphological tags onto their lemmas insteadof inserting them as separate input tokens.
See Fig-ure 2 for an example.
This concatenation createsdistinctions between some lemmas, which will ide-ally correspond to morphological distinctions madein English.
Although this transformation splits theCzech data (relative to pure lemmatization), it stillsuppresses many of the distinctions made in the fullCzech wordforms.
We expected that number mark-678Words: Pro ne?koho by jej??
proveden??
me?lo smysl .Lemmas: pro ne?kdo by?t jeho proveden??
m?
?t smysl .Lemmas+Pseudowords: pro ne?kdo by?t PER 3 jeho proveden??
m?
?t PER X smysl .Modified Lemmas: pro ne?kdo by?t+PER 3 jeho proveden??
m?
?t+PER X smysl .Figure 2: Various transformations of the Czech sentence from Figure 1.
The pseudowords and modifiedlemmas encode the verb person feature, with the values 3 (third person) and X (?any?
person).ing on nouns and tense marking on verbs would bethe tags best treated in this way.3.4 MorphemesOur final set of experiments used the same input for-mat as the Modified Lemma experiments.
However,in this set of experiments, we changed the model usedto calculate the word-to-word alignment probabili-ties.
In the standard system, the alignment modelparameters P (fj |ei) are found using maximum like-lihood estimation based on the expected number oftimes fj aligns to ei in the parallel corpus.
Our newmodel assumes a compositional structure for fj , sothat fj = fj0 .
.
.
fjK , where fj0 is the lemma offj , and fj1 .
.
.
fjK are morphemes generated fromthe tags associated with fj .
We assume that everyword contains exactly K morphemes, and that thekth morpheme in each word is used to encode thevalue for the kth class of morphological tag, wherethe classes (e.g.
person or tense) are assigned an or-dering beforehand.
fjk is assigned a null value if thevalue of the kth tag class is unspecified for fj .Given this decomposition of words into mor-phemes, and a generative model in which each mor-pheme in fj is generated independently conditionedon ei, we haveP(fj|ei) =K?k=0P(fjk|ei) (2)We can now estimate P(fj |ei) using a slightlymodified version of the standard EM algorithm forlearning alignment probabilities.
During the E step,we calculate the expected alignment counts betweenCzech morphemes and English words based on thecurrent word alignments, and revise our estimate ofP(fj|ei) using Equation 2.
The M step of the algo-rithm remains the same.The morpheme-based model in Equation 2 is sim-ilar to the modified lemma model in that it removesmuch of the differentiation between Czech word-forms, but leaves the differences that are most likelyto appear as inflection on English words.
However,it also performs an additional smoothing function.The model assumes that, in the absence of other in-formation, an English word that has aligned mostlyto Czech words with a particular morphological tagis more likely to align to another word with this tagthan to a Czech word with a different tag.
For ex-ample, an English word aligned to mostly past tenseforms is more likely to align to another past tenseform than to a present or future tense form.4 ExperimentsIn order to evaluate the effectiveness of the tech-niques described in the previous section, we ran anumber of experiments using data from the PCEDTcorpus.
The English portion of this corpus (used totrain the language model) contains the same materialas the Penn WSJ corpus, but with a different divi-sion into training, development, and test sets.
About250 sentences each for development and test weretranslated once into Czech and then back into En-glish by five different translators.
These translationsare used to calculate BLEU scores.
The remainderof the corpus (about 50,000 sentences) is used fortraining.
About 21,000 of the training sentences havebeen translated into Czech and morphologically an-notated for use as a parallel corpus.Some statistics on the parallel corpus are shownin the graph in Figure 3.
This graph illustrates thesparse data problem in Czech that our morpholog-ical analysis is intended to address.
Although thenumber of infrequently occurring lemmas is aboutthe same in both English and Czech, the number ofinfrequently occurring inflected wordforms is approx-imately twice as high in Czech.1For all of our experiments, we used the same lan-guage model, trained with the CMU Statistical Lan-guage Modelling Toolkit (Clarkson and Rosenfeld,1997).
Our translation models were trained usingGIZA++ (Och and Ney, 2003), which we modi-1Although we did not use it for the experiments inthis paper, the PCEDT corpus does contain lemma in-formation for the English data.
There is a slight discrep-ancy between the English and Czech data in the lemmainformation for pronouns, in that English pronouns (in-cluding accusitive, possessive, and other forms) are as-signed themselves as lemmas, whereas Czech pronounsare reduced to uninflected forms.
Given that pronounsgenerally have many tokens, this discrepancy should notaffect the data in Figure 3.6791 2 3 4 5 6 7 8 9 1000.511.522.533.5x 104Token countItemcountEnglish WordformsCzech WordformsEnglish LemmasCzech LemmasFigure 3: The number of items (full wordforms orlemmas) y appearing in the parallel corpus with atoken count of x.fied as necessary for the morpheme-based experi-ments.
We used the ISI ReWrite Decoder (Marcuand Germann, 2005) for producing translations.
Be-fore beginning our experiments, we obtained a base-line BLEU score by training a standard word-to-wordtranslation model.
Our baseline results indicate thatthe test set for this corpus is considerably more diffi-cult than the development set: word-to-word scoreswere .311 (development) and .270 (test).4.1 LemmasAs Figure 3 shows, lemmatization of the Czech cor-pus cuts the number of unique items by more thanhalf, and the number of items with no more thanten occurrences by nearly half.
The lemmatizationBLEU scores in Table 1 indicate that this has a largeimpact on the quality of translation.
As expected,full lemmatization performed better than word-to-word translation, with an an improvement of about.04 in the development set BLEU score and .03 inthe test set.
(In this and the following experiments,BLEU score differences of .009 or more are signifi-cant at the .05 level.)
Experiments on the develop-ment set showed that leaving certain parts of speechunlemmatized did not improve results, but lemma-tizing only low-frequency words did.
A frequencycutoff of 50 worked best on the development set (i.e.only words with frequency less than 50 were lemma-tized).
Despite the improvement on the developmentset, using this cutoff with the test set yielded only anon-significant improvement over full lemmatization.The results of these lemmatization experimentssupport the argument that lemmatization improvestranslation quality by reducing data sparseness, butalso removes potentially useful information.
Our re-Dev Testword-to-word .311 .270lemmatize all .355 .299except Pro .350except Pro, V, N .346lemmatize n < 50 .370 .306truncate all .353 .283Table 1: BLEU scores for the word-to-word baseline,lemmatization, and word truncation experiments.sults suggest that lemmatizing only infrequent wordsmay, in some cases, work better than lemmatizing allwords.As Table 1 indicates, it is possible to get someof the benefits of lemmatization without using anymorphological knowledge at all.
For both dev andtest sets, truncating words to 6 characters (the bestlength on the dev set) provided a significant im-provement over word-to-word translation, but wasalso significantly worse than the best lemmatizationscores.
Changing the frequency cutoff for trunca-tion did not produce any significant differences inthe BLEU score.4.2 PseudowordsResults for the pseudoword experiments on the devel-opment set are shown in the first column of Table 2.Note that in these (and the following) experiments,we treated all words the same way regardless of theirfrequency, so the effects of adding morphological in-formation are in comparison to the full lemmatiza-tion scheme.
In most of our experiments, we addedmorphological information for only a single class oftags at a time in order to determine the effects ofeach class individually.
The classes we used wereverb person (PER), verb tense (TEN), noun number(NUM), noun case (CASE), and negation (NEG).Most of the results of the pseudoword experimentsconfirm our expectations.
Adding the verb persontags was helpful, and examination of the alignmentsrevealed that they did indeed align to English pro-nouns with high probability.
The noun number tagsdid not help, since plurality is expressed as an affixin English.
Negation tags helped slightly, though theimprovement was not significant.
This is probablybecause negation tags are relatively infrequent, ascan be seen in Table 3.
The addition of pseudowordsfor case did not yield an improvement, probably be-cause these pseudowords were so frequent.
The ad-ditional ambiguity caused by so many extra wordslikely overwhelmed any positive effect.A somewhat puzzling result is the behavior of the680Tag type Pseudo Mod-Lem MorphPER .365 .356 .356TEN .365 .361 .364PER,TEN .355 .362 .355NUM .354 .367 .361CASE .353 .340 .337NEG .357 .356 .353Table 2: BLEU scores indicating the results of in-corporating the information from different classesof morphological tags in the the experiments us-ing pseudowords (Pseudo), modified lemmas (Mod-Lem), and morphemes (Morph).
Scores are from thedevelopment set.
Differences of .009 are significant(p < .05).Tag class Count Avg/sentencePER 49700 2.35TEN 47744 2.26past 22544 1.07pres 20291 0.96fut 1707 0.08?any?
3202 0.15NUM 151646 7.17CASE 151646 7.17NEG 3326 0.16Table 3: Number of occurrences of each class of tagsin the Czech training data.verb tense tags.
With the exception of future tense,English generally does not mark tense with an aux-iliary.
Yet Table 3 shows that only a very small per-centage of sentences have a future tense marker, soit seems unlikely that this explains the positive ef-fects of the tense pseudowords.
In fact, we triedadding only future tense pseudowords to the lem-matized Czech data, and found that the results wereno better than basic lemmatization.The other unusual behavior we see with pseu-dowords is that when verb person and tense tags arecombined, they seem to cancel each other out, result-ing in a score that is no better than lemmatizationalone.
Examination of the alignments did not revealany obvious reason for this effect.4.3 Modified LemmasAs shown in the second column of Table 2, the num-ber and tense tags yield an improvement under themodified lemma transformation, while the persontags do not.
Again, this confirms our predictionsbased on the morphology of English.Our results using the case tags under this modelactually decreased performance, but this is notsurprising given that differentiating Czech lemmasbased on case marking creates as much as a 7-waysplit of the data (there are seven cases in Czech),without adding much information that would be use-ful in English.4.4 MorphemesBLEU scores for the morpheme-based model aregiven in the third column of Table 2.
None of thedifferences in scores between this model and the mod-ified lemma model are significant, although the trendfor most of the tag classes is for this model to per-form slightly worse.
This suggests that the type ofsmoothing induced by the morpheme-based modelmay not be as helpful as simply attempting to cre-ate Czech words that reflect the same morphologicaldistinctions as the English words.
In Section 5, wepropose a generalized version of the morpheme modelthat might be an improvement.4.5 Combined ModelIn the experiments described so far, we used onlya single method at a time of incorporating mor-phological information into the translation process.However, it is straightforward to combine the pseu-doword method with either the modified-lemma ormorpheme-based methods by using pseudowords forcertain tags and attaching others to the Czech lem-mas.
The experiments described above allowed us toconfirm our intuitions about how each class of tagsshould be treated under such a combined model.
Wethen created a model using the pseudoword treat-ment of the person and negation tags, and the mod-ified lemma treatment of number and tense.
We didnot use the case tags in this model, since they didnot seem to yield an improvement in any of the threebasic morphological models.Our combined model achieved a BLEU score of.390 (development) and .333 (test), outperformingthe models in all of our previous experiments.5 DiscussionThe results of our experiments provide additionalsupport for the findings of previous researchers thatusing morphological analysis can improve the qualityof statistical machine translation for highly-inflectedlanguages.
While human judgment is probably thebest metric for evaluating translation quality, our useof the automatically-derived BLEU score allowed usto easily compare many different translation modelsand evaluate the effects of each one individually.
Wefound that simple lemmatization, by significantly re-ducing the sparse data problem, was quite effective681despite the loss of information involved.
Lemmatiz-ing the less frequent words in the corpus seemed toincrease performance slightly, but these results wereinconclusive.
Word truncation, which requires nomorphological information at all, was effective at in-creasing scores over the word-to-word baseline, butdid not perform quite as well as lemmatization.
Thisresult conflicts with Och?s (Och, 1995), and is likelydue to the much smaller size of our corpus.
In anycase, our results suggest that lemmatization or wordtruncation could yield a significant improvement inthe quality of translation from a highly-inflected toa less-inflected language, even when limited morpho-logical information is available.Our primary results concern the use of full mor-phological information.
We found that certain tagswere more useful when we treated them as discreteinput words, while others provided a greater benefitwhen attached directly to their lemmas.
The bestchoice of which method to use for each class of tagsseems to correspond closely with how that class of in-formation is expressed in English (either using func-tion words or inflection).
In a sense, the goal of themorphological analysis is to make the Czech inputdata more English-like by suppressing unnecessarymorphological distinctions and expressing necessarydistinctions in ways that are similar to English.
Thissort of procedure could be taken further by incorpo-rating syntactic information as well, but as we statedearlier, our goal was to determine exactly how muchbenefit we could derive from a strictly morphologicalapproach.In the work we have presented, the output lan-guage (English) is low in inflection.
We thereforeconsidered it less important to perform morphologi-cal analysis on the English data.
However, we expectthat the work described here could be generalized tohighly inflected output languages by doing morpho-logical analysis on both the input and output lan-guages.
The most promising way to do this seemsto be by extending the morpheme-based translationmodel in Equation 2 to incorporate morphemes inboth languages, so thatP(fj|ei) =K?k=0P(fjk|eik) (3)where fjk are the morphemes in the input language,and eik are the corresponding morphemes in the out-put language.
This extended model may also provea benefit to Czech-English translation; we are cur-rently investigating this possibility.In this work, we used a word-based translation sys-tem due to the availability of source code that couldbe modified for our morph experiments.
An obviousextension to the current work would be to move to aphrase-based translation system.
One advantage ofphrase-based models is their ability to align phrasesin one language to morphologically complex words inthe other language.
However, this feature still suffersfrom the same sparse data problems as a word-basedsystem: if a morphologically complex word only ap-pears a handful of times in the training corpus, thesystem will have difficulty determining its (phrasalor word) alignment.
We expect that morphologicalanalysis would still be helpful in this situation, at thevery least because it can be used to remove distinc-tions that appear in only one language.6 ConclusionIn this paper we used morphological analysis ofCzech to improve a Czech-English statistical machinetranslation system.
We have argued that this im-provement was primarily due to a reduction of thesparse data problem caused by the highly inflectednature of Czech.
An alternative method for reducingsparse data is to use a larger parallel corpus; however,it is often easier to obtain additional monolingual re-sources, such as a morphological analyzer or taggedcorpus, than additional parallel data for a specificlanguage pair.
For that reason, we believe that theapproach taken here is a promising one.We have described several different ways of usingmorphological information for machine translation,and have shown how these can be combined to yieldan improved translation model.
In general, we wouldnot expect the exact combination of techniques thatyielded our best results for Czech-English to be op-timal for other language pairs.
Rather, we have sug-gested that these techniques should be combined ina way that makes the input language more similarto the output language.
Although this combinationwill need to be determined for each language pair, thegeneral approach outlined here should provide ben-efits for any MT system involving a highly inflectedlanguage.AcknowledgementsWe would like to thank Eugene Charniak and themembers of BLLIP for their encouragement andhelpful suggestions.
This research was partially sup-ported by NSF awards IGERT 9870676 and ITR0085940.682ReferencesY.
Al-Onaizan, J. Cur?in, M. Jahr, K. Knight, J. Laf-ferty, D. Melamed, F. Och, D. Purdy, N. Smith,and D. Yarowsky.
1999.
Statistical machine trans-lation.
Final Report, JHU Summer Workshop1999.P.
Clarkson and R. Rosenfeld.
1997.
Sta-tistical language modeling using the CMU-Cambridge Toolkit.
In Proceedings of ESCAEurospeech.
Current version available athttp://mi.eng.cam.ac.uk/?prc14/toolkit.html.J.
Hajic?.
1998.
Building a Syntactically Anno-tated Corpus: The Prague Dependency Treebank.In Eva Hajic?ova?, editor, Issues of Valency andMeaning.
Studies in Honor of Jarmila Panevova?,pages 12?19.
Prague Karolinum, Charles Univer-sity Press.Y.
Lee.
2004.
Morphological analysis for statisticalmachine translation.
In Proceedings NAACL.D.
Marcu and U. Germann.
2005.
TheISI ReWrite Decoder 1.0.0a.
Available athttp://www.isi.edu/licensed-sw/rewrite-decoder/.S.
Niessen and H. Ney.
2000.
Improving SMT qualitywith morpho-syntactic analysis.
In Proceedings ofCOLING.S.
Niessen and H. Ney.
2004.
Statistical machinetranslation with scarce resources using morpho-syntactic analysis.
Computational Linguistics,30(2):181?204.F.
J. Och and H. Ney.
2003.
A systematic compari-son of various statistical alignment models.
Com-putational Linguistics, 29(1):19?51.F.
Och.
1995.
Statistical machine translation: Thefabulous present and future.
Invited talk at theWorkshop on Building and Using Parallel Textsat ACL?05.M.
C?mejrek, J.
Cur??
?n, and J. Havelka.
2003.
Czech-english dependency-based machine translation.
InProceedings of EACL.M.
C?mejrek, J.
Cur??
?n, J. Havelka, J.
Hajic?, andV.
Kubon?.
2004.
Prague czech-english dependecytreebank: Syntactically annotated resources formachine translation.
In 4th International Confer-ence on Language Resources and Evaluation, Lis-bon, Portugal.683
