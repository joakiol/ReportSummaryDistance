Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 11?20,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsUnsupervised Relation Extraction of In-Domain Datafrom Focused CrawlsSteffen RemusFG Language TechnologyComputer Science Department, Technische Universit?at DarmstadtInformation Center for EducationGerman Institute for Educational Research (DIPF)remus@cs.tu-darmstadt.deAbstractThis thesis proposal approaches unsuper-vised relation extraction from web data,which is collected by crawling only thoseparts of the web that are from the same do-main as a relatively small reference cor-pus.
The first part of this proposal is con-cerned with the efficient discovery of webdocuments for a particular domain and ina particular language.
We create a com-bined, focused web crawling system thatautomatically collects relevant documentsand minimizes the amount of irrelevantweb content.
The collected web data issemantically processed in order to acquirerich in-domain knowledge.
Here, we focuson fully unsupervised relation extractionby employing the extended distributionalhypothesis.
We use distributional similar-ities between two pairs of nominals basedon dependency paths as context and viceversa for identifying relational structure.We apply our system for the domain ofeducational sciences by focusing primarilyon crawling scientific educational publica-tions in the web.
We are able to producepromising initial results on relation identi-fication and we will discuss future direc-tions.1 IntroductionKnowledge acquisition from written or spokentext is a field of interest not only for theoreticalreasons but also for practical applications, such assemantic search, question answering and knowl-edge management, just to name a few.In this work, we propose an approach for un-supervised relation extraction (URE) where wemake use of the Distributional Hypothesis by Har-ris (1954).
The underlying data set is collectedfrom the world wide web by focusing on web doc-uments that are from the same domain as a smallinitialization data set that is provided beforehand.We hereby enrich this existing, domain-defining,corpus with more data of the same kind.
This isneeded for practical reasons when working withthe Distributional Hypothesis (Harris, 1954): A lotof data is required for plausible outcomes and anappropriate coverage.
However, we want as littleirrelevant data as possible.
The proposal?s contri-bution is thus twofold: a) focused crawling, andb) unsupervised relation extraction.
As a partic-ular use case, we are especially interested in sci-entific publications from the German educationaldomain.
However, we would like to point out thatthe methodology itself is independent of languageand domain and is generally applicable to any do-main.This work is structured as follows: First we willmotivate our combined approach and introduceeach part individually.
We then present relatedwork in Section 2.
Section 3 explains the method-ology of both parts, and in Section 4 we outline theevaluation procedure of each of the componentsindividually.
This is followed by some prelimi-nary results in Section 5, and Section 6 concludesthis proposal with some prospects for future work.1.1 MotivationThe identification of relations between entitiessolely from text is one of many challenges inthe development of language understanding sys-tem (Carlson et al., 2010; Etzioni et al., 2008);and yet it is the one step with the highest informa-tion gain.
It is used e.g.
for taxonomy induction(Hearst, 1992) or ontology accumulation (Mintz etal., 2009) or even for identifying facts that expressgeneral knowledge and that often recur (Cham-bers and Jurafsky, 2011).
Davidov et al.
(2007)performed unsupervised relation extraction by ac-tively mining the web and showed major improve-11ments in the detection of new facts from only littleinitial seed.
They used a major web search engineas a vital component of their system.
According toKilgarriff (2007), however, this strategy is unreli-able and should be avoided.
Nevertheless, the webis undeniably the largest source for any kind ofdata, and we feel the need for developing easy-to-use components that make it possible to create cor-pora from the web with only little effort (cf.
e.g.Biemann et al.
(2013)).
When it comes to specificin-domain information, the complete world wideweb is first of all too vast to be processed conve-niently, and second the gain is little because of toomuch irrelevant information.
Thus we need meth-ods for reducing the size of data to process withoutlosing the focus on the important information andwithout using web search engines.
The combina-tion of a focused crawling system with a subse-quent unsupervised relation extraction system en-ables the acquisition of richer in-domain knowl-edge than just relying on little local data, but with-out having to process petabytes of data and still notrelying of web search.
And yet, by using the webas a resource, our system is generally applicableand independent of language and target domain.1.2 Focused CrawlingThe first part of this proposal is concerned withthe efficient discovery of publications in the webfor a particular domain.
The domain definition isgiven as a limited number of reference documents.An extra challenge is, that non-negligible amountsof scientific publications are only available as pdfdocuments, which makes the necessity of new fo-cused crawling techniques even more important.This holds especially for our target use case, theGerman educational domain.
In Section 2.1 wewill discuss this issue in more detail.
We developa focused web crawling system which collects pri-marily relevant documents and ignores irrelevantdocuments and which is particularly suited for har-vesting documents from a predefined specific do-main.1.3 Unsupervised Relation ExtractionThe second part of this proposal is the semanticstructuring of texts ?
in our particular use casescientific publications from the educational do-main ?
by using data-driven techniques of com-putational semantics.
The resulting structure en-ables forms of post-processing like inference orreasoning.
In the semantic structuring part, theoverall goal is to discover knowledge which canthen be used in further steps.
Specifically, we willfocus on unsupervised relation extraction.2 Related Work2.1 Focused CrawlingThe development of high-quality data-driven se-mantic models relies on corpora of large sizes(Banko and Brill, 2001; Halevy et al., 2009), andthe world wide web is by far the biggest avail-able source of textual data.
Nowadays, a largenumber of research projects rely on corpora thatcomes from data in the world wide web.
The Web-as-Corpus Kool Yinitiative1(WaCKy) (Baroni etal., 2009) for example produced one of the largestcorpora used in linguistic research which comesfrom web documents.
Another research initia-tive which produces a variety of corpora by crawl-ing the web is the COW2(corpora from the web)project (Sch?afer and Bildhauer, 2012).
Currentlyone of the largest N-gram corpora coming fromweb data is the Google V1 and Google V2 (Lin etal., 2010), which are used e.g.
for improving nounphrase parsing (Pitler et al., 2010).
Also the pre-decessor Google Web1T (Brants and Franz, 2006),which is computed from 1 Trillion words from theweb, is heavily used in the community.All these corpora are generated from generaltexts which either come from crawling specifictop-level-domains (tlds) or preprocessing and fil-tering very large amounts of texts for a specifiedlanguage.
Additionally, we are not aware of anycorpus that is created by collecting pdf documents.This is especially an issue when aiming at a cor-pus of scientific publications, such as e.g.
the ACLanthology3(Bird et al., 2008).
As of today, elec-tronic publications are primarily distributed as pdfdocuments.
Usually these are omitted by the par-ticular crawler because of a number of practicalissues, e.g.
difficulties in extracting clean plain-text.Further, we are not interested in sheer collec-tion size, but also in domain specificity.
Crawlingis a time-consuming process and it comes with lo-gistic challenges for processing the resulting data.While standard breadth-first or depth-first crawl-ing strategies can be adjusted to include pdf files,we want to avoid to harvest the huge bulk of data1http://wacky.sslmit.unibo.it/2http://hpsg.fu-berlin.de/cow/3http://acl-arc.comp.nus.edu.sg/12that we are not interested in, namely those docu-ments that are of a different topical domain as ourinitial domain definition.In focused crawling, which is sometimes alsoreferred to as topical crawling, web crawlers aredesigned to harvest those parts of the web firstthat are more interesting for a particular topic(Chakrabarti et al., 1999).
By doing so, task-specific corpora can be generated fast and ef-ficient.
Typical focused crawlers use machinelearning techniques or heuristics to prioritizenewly discovered URIs (unified resource iden-tifier) for further crawling (Blum and Mitchell,1998; Chakrabarti et al., 1999; Menczer et al.,2004).
In our scenario however, we do not rely onpositively and negatively labeled data.
The sourcedocuments that serve as the domain definition areassumed to be given in plain text.
The develop-ment of tools that are able to generate in-domainweb-corpora from focused crawls is the premisefor further generating rich semantic models tai-lored to a target domain.2.2 Unsupervised Relation ExtractionThe unsupervised relation extraction (URE) partof this proposal is specifically focused on ex-tracting relations between nominals.
Typically thechoice of the entity type depends merely on thefinal task at hand.
Kinds of entities which are usu-ally considered in relation extraction are namedentities like persons or organizations.
However,we will focus on nominals which are much moregeneral and also include named entities since theyare basically nouns or noun phrases (Nastase etal., 2013).
Nominals are discussed in more de-tail in Section 3.2.
Unsupervised methods for re-lation extraction is a particularly interesting areaof research because of its applicability across lan-guages without relying on labeled data.
In con-trast to open information extraction, in unsuper-vised relation extraction the collected relations areaggregated in order to identify the most promisingrelations for expressing interesting facts.
Here, thegrouping is made explicit for further processing.One possible application of relation extractionis the establishment of so-called knowledge graphs(Sowa, 2000), which encode facts that manifestsolely from text.
The knowledge graph can thenbe used e.g.
for reasoning, that is finding new factsfrom existing facts.Many approaches exist for acquiring knowledgefrom text.
Hearst (1992) first discovered that rela-tions between entities occur in a handful of welldeveloped text patterns.
For example ?X is a Y?or ?X and other Ys?
manifest themselves as hy-ponymic relations.
However, not every kind of re-lation is as easy to identify as those ?is-a?
relations.Often semantic relations cannot be expressed byany pattern.
A variety of methods were devel-oped that automatically find new patterns and en-tities with or without supervision.
These methodsreach from bootstrapping methods (Hearst, 1992)over distant supervision (Mintz et al., 2009) andlatent relational analysis (LRA) (Turney, 2005)to extreme unsupervised relation extraction (Davi-dov and Rappoport, 2008a), just to name a few.The importance of unsupervised methods for re-lation extraction is obvious: The manual creationof knowledge resources is time consuming and ex-pensive in terms of manpower.
Though manual re-sources are typically very precise they are almostalways lacking of lexical and relational coverage.The extraction of relations between entities is acrucial process which is performed by every mod-ern language understanding system like NELL4(Carlson et al., 2010) or machine reading5, whichevolved among others from TextRunner6(Etzioniet al., 2008).
The identification of relations in nat-ural language texts is at the heart of such systems.3 Methodology3.1 Focused CrawlingLanguage models (LMs) are a rather old butwell understood and generally accepted conceptin Computational Linguistics and Information Re-trieval.
Our focused crawling strategy builds uponthe idea of utilizing a language model to discrim-inate between relevant and irrelevant web docu-ments.
The key idea of this methodology is thatweb pages which come from a certain domain ?which implies the use of a particular vocabulary(Biber, 1995) ?
link to other documents of thesame domain.
The assumption is that the crawlerwill most likely stay in the same topical domainas the initial language model was generated from.Thus the crawling process can be terminated whenenough data has been collected.4Never Ending Language Learner:http://rtw.ml.cmu.edu/5http://ai.cs.washington.edu/projects/open-information-extraction6http://openie.cs.washington.edu/13A language model is a statistical model overshort sequences of consecutive tokens called N-grams.
The order of a language model is definedby the length of such sequences, i.e.
the ?N?
in N-gram.
The probability of a sequence of m words,that could be for example a sentence, is computedas:p(w1, ..., wm) ?m?i=1p(wi|wi?N+1:i?1) ,(1)where N is the order of the language model andp(wi|wi?n+1:i?1) is the probability of the particu-lar N-gram.
In the simplest case the probability ofan N-gram is computed as:p(wi|wi?n+1:i?1) =count(wi?N+1:i)count(wi?N+1:i?1), (2)where count(N-gram) is a function that takes asargument an N-gram of length N or an N-gramof length N ?
1 and returns the frequency of ob-servations in the source corpus.
This model hassome obvious limitations when it comes to out-of-vocabulary (OOV) terms because of probabil-ities being zero.
Due to this limitation, a numberof LMs were proposed which handle OOV termswell.One of the most advanced language models isthe Kneser-Ney language model (Kneser and Ney,1995), which applies an advanced interpolationtechnique for OOV issues.
According to Halevyet al.
(2009), simpler models that are trained onlarge amounts of data often outperform complexmodels with training procedures that are feasibleonly for small data.
Anyway, we have only littledata in the initial phase, thus we use Kneser andNey?s model.Perplexity is used to measure the amount ofcompatibility with another model X:Perplexity(X) = 2H(X), (3)where H(X) = ?1|X|?x?Xlog2p(x) is thecross entropy of a model X .
Using perplexity weare able to tell how well the language model fitsthe data and vice versa.The key idea is that documents which comefrom a certain register or domain ?
which im-plies the use of a particular vocabulary (Biber,1995) ?
link to other documents of the same reg-ister.
Using perplexity, we are able to rank out-going links by their deviation from our initial lan-guage model.
Hence weblinks that are extractedfrom a highly deviating webpage are less priori-tized for harvesting.
The open source crawler soft-ware Heritrix7(Mohr et al., 2004) forms the basisof our focused crawling strategy, since it providesa well-established framework which is easily ex-tensible through its modularity.3.2 Identification of NominalsNominals are defined to be expressions which syn-tactically act like nouns or noun phrases (Quirket al., 1985, p.335).
Another definition accordingto Nastase et al.
(2013) is that nominals are de-fined to be in one of the following classes: a) com-mon nouns, b) proper nouns, c) multi-word propernouns, d) deverbal nouns, e) deadjectival nouns,or f) non-compositional (adjective) noun phrases.In this work we will follow the definition givenby Nastase et al.
(2013).
We will further addressonly relations that are at least realized by verbal orprepositional phrases and ignore relations that areimplicitly present in compounds, which is a taskof its own, cf.
(Holz and Biemann, 2008).
Notehowever we do not ignore relations between com-pounds, but within compounds.The identification of nominals can be seenas the task of identifying reliable multi-word-expressions (MWEs), which is a research questionof its own right.
As a first simplified approachwe only consider nouns and heads of noun com-pounds to be representatives for nominals.
E.g.
acompound is used as an entity, but only the headis taken into further consideration as a represen-tative since it encapsulates the main meaning forthat phrase.3.3 Unsupervised Relation ExtractionOur system is founded in the idea of distributionalsemantics on the level of dependency parses.
TheDistributional Hypothesis by Harris (1954) (cf.also (Miller and Charles, 1991)) states that wordswhich tend to occur in similar contexts tend tohave similar meanings.
This implies that one canestimate the meaning of an unknown word by con-sidering the context in that it occurs.
Lin and Pan-tel (2001) extended this hypothesis to cover short-est paths in the dependency graph ?
so-called de-pendency paths ?
and introduced the ExtendedDistributional Hypothesis.
This extended hypoth-esis states that dependency paths which tend to oc-cur in similar contexts, i.e.
they connect the simi-7http://crawler.archive.org14lar sets of words, also tend to have similar mean-ings.Sun and Grishman (2010) used an agglomera-tive hierarchical clustering based approach in or-der to group the patterns found by Lin and Pan-tel?s method.
The clusters are used in a semi-supervised way to extract relation instances thatare used in a bootstrapping fashion to find newrelations.
While Sun and Grishman (2010) per-formed a hard clustering, meaning every relation isassigned exactly to one cluster, we argue that rela-tions are accompanied by a certain degree of am-biguity.
Think for example about the expression?X comes from Y?
which could be both, a causalrelation or a locational relation depending on themeaning of X and Y.That being said, we use the Extended Distri-butional Hypothesis in order to extract meaning-ful relations from text.
We follow Lin and Pantel(2001) and use the dependency path between twoentities to identify both, similar entity pairs andsimilar dependency paths.
Specifically we use theStanford Parser8(Klein and Manning, 2003) to geta collapsed dependency graph representation of asentence, and apply the JoBimText9(Biemann andRiedl, 2013) software for computing the distribu-tional similarities.By using the JoBimText framework, we ac-cept their theory, which states that dimensionality-reduced vector space models are not expressiveenough to capture the full semantics of words,phrases, sentences, documents or relations.
Tur-ney and Pantel (2010) surveyed that vector spacemodels are commonly used in computational se-mantics and that they are able to capture the mean-ing of words.
However, by doing various kinds ofvector space transformations, e.g.
dimensionalityreduction with SVD10important information fromthe long tail, i.e.
items that do not occur often,is lost.
Instead, Biemann and Riedl (2013) intro-duced the scalable JoBimText framework, whichmakes use of the Distributional Hypothesis.
Wetake this as a starting point to steer away from theuse of vector space models.For each entity pair ?X::Y?, where ?X?
and ?Y?are nominals, we collect all dependency paths that8http://nlp.stanford.edu/downloads/lex-parser.shtml9http://sf.net/p/jobimtext10Singular Value Decomposition, used for example in la-tent semantic analysis, latent relational analysis, principalcomponent analysis and many more.rain :: seawater @1nsubj?????
comesprep from????????
@2rain :: seawater @1dobj????
causesnsubj?????
@2seawater :: rain @1prep from????????
comesnsubj?????
@2seawater :: rain @1nsubj?????
causesdobj????
@2Figure 1: Upper12: collapsed dependency parsesof the example sentences ?Rain comes from evapo-rated seawater.?
and ?Evaporated seawater causesrain?.
Lower: extracted entity pairs plus shortestdependency paths per entity pair from both sen-tences.co-occur with it in the complete dataset.
A par-ticular path for a particular relation instance hasform ?
@1-PATH-@2?, where ?-PATH-?
is the in-stantiation of the directed shortest path in the col-lapsed dependency path starting from a particu-lar ?X?
and ending in a particular ?Y?.
The @1,resp.
@2, symbolizes the place where ?X?
and ?Y?were found in the path.
Here we restrict the pathto be shorter than five edges and additionally weignore paths that have only nn relations, i.e.
com-pound dependency relations.
See Figure 1 for anillustration of this strategy on two small examplesentences.
Note that this procedure strongly co-heres with the methodologies proposed by Lewisand Steedman (2013) or Akbik et al.
(2013).We then compute the distributional similaritiesfor both directions: a) similarities of entity pairsby paths, and b) similarities of paths by entitypairs.
This gives us two different views on thedata.4 EvaluationThe two major directions of this paper, i.e.
the fo-cused crawling part and the unsupervised relationextraction part are evaluated individually and in-dependent of each other.
First we will present an12Images generated with GrammarScope:http://grammarscope.sf.net .15evaluation methodology to assess the quality of thecrawler and second we will outline the evaluationof relations.
While we can only show anecdoticalevidence of the viability of this approach, since thework is in progress, we are able to present encour-aging preliminary results in Section 5.4.1 Focused CrawlingThe quality of a focused crawl is measured interms of perplexity (cf.
Section 3.1) by creatinga language model from the harvested data duringa particular crawl.
Perplexity is then calculatedwith respect to a held out test set.
The follow-ing three phases describe the evaluation proceduremore precisely:1.
The source corpus is split i.i.d.13into a train-ing and test set.2.
We create a language model U of the trainingdata, which is applied according to Section3.1 for automatically focusing the crawl.
Inorder to compare the data of different crawls,the repeated crawls are initialized with thesame global parameter settings, e.g.
polite-ness settings, seed, etc.
are the same, and areterminated after reaching a certain number ofdocuments.3.
From the harvested data, another languagemodel V is produced which is used for theevaluation of the test data.
Here we arguethat a crawl which collects data that is usedfor evaluating V and V results in a lower per-plexity score, is preferred as it better modelsthe target domain.Figure 2 shows a schematic overview of the threephases of evaluation.4.2 Unsupervised Relation ExtractionThe evaluation of relation extraction is a non-trivial task, as unsupervised categories do usuallynot exactly match the distinctions taken in annota-tion studies.
For the evaluation of our method weconsider the following three approaches:1.
We test our relations directly on datasets thatwere provided as relation classification chal-lenge datasets (Girju et al., 2007; Hendrickx13independent and identically distributedUVw w wPhase 1Phase 3Phase 2Figure 2: Schematic overview of the evaluationprocedure for a particular crawl.et al., 2010).
Whereas the first dataset is pro-vided as a binary classification task, the sec-ond is a multi-way classification task.
How-ever, both datasets can be transformed to ad-dress the one or the other task.
This is possi-ble because the challenge is already finished.2.
We apply our extracted relations for assistingclassification algorithms for the task of tex-tual entailment (Dagan et al., 2006).3.
Following Davidov and Rappoport (2008b)we would further like to apply our system tothe task of question answering.While the first approach is an intrinsic evaluation,the other three approaches are extrinsic, i.e.
theextracted relations are used in a particular taskwhich is then evaluated against some gold stan-dard.5 Preliminary Results5.1 Focused crawlingTable 1 shows some quantitative characteristics ofa non-focused crawl.
Here the crawl was per-formed as a scoped crawl, which means that it wasbounded to the German top-level-domain ?.de?
andadditionally by a maximum number of 20 hopsfrom the start seed14.
The crawl was terminatedafter about two weeks.
Although these numbers14The start seed for the first crawl consists of five web pageurls which are strongly connected to German educational re-search.16pdf htmlsize in GBytes 17 400number of documents 43K 9Mruntime ?
2 weeksTable 1: Numbers are given as approximate num-bers.do not seem surprising, they do support the mainargument of this proposal.
Focused crawling isnecessary in order to reduce the massive load ofirrelevant data.Initial encouraging results on the comparison ofa focused vs. a non-focused crawl are shown inFigure 3.
The crawls were performed under thesame conditions and we recorded the perplexityvalue during the process.
We plot the history forthe first 300,000 documents.
Although these re-sults are preliminary, a trend is clearly observable.The focused crawl harvests more relevant doc-uments as it proceeds, whereas the non-focusedcrawl deviates more as longer the crawl proceeds,as indicated by higher perplexity values for laterdocuments ?
an effect that is likely to increase asthe crawl proceeds.
The focused crawl, on theother hand, stays within low perplexity limits.
Weplan to evaluate settings and the interplay betweencrawling parameters and language modeling morethoroughly in future evaluations.5.2 Unsupervised Relation ExtractionThe unsupervised extraction of relations was per-formed on a small subset of one Million sentencesof the news corpus from the Leipzig Corpora Col-lection (Richter et al., 2006).Preliminary example results are shown in Ta-ble 2 and in Table 3.
Table 2 shows selected resultsfor similar entity pairs, and Table 3 shows selectedresults for similar dependency paths.In Table 2, three example entity pairs are showntogether with their most similar counterparts.
It isinteresting to see that the relation of gold to ounceis the same as stock to share or oil to barrel andwe can easily agree here, since the one is the mea-suring unit for the other.Table 3 shows for three example prepositionalpaths the similar paths.
We have chosen prepo-sitional phrases here because of their intuitive in-terpretability.
The example output shows that thesimilar phrases which were identified by the sys-tem are also interpretable for humans.Figure 3: Two crawl runs under same conditionsand with same settings.
Upper: a focused crawlrun.
Lower: a non-focused crawl run.6 Conclusion and Future WorkThis research thesis proposal addressed the twomajor objectives:1. crawling with a focus on in-domain data byusing a language model of an initial corpus,which is small compared to the expected re-sult of the crawls, in order to discriminaterelevant web documents from irrelevant webdocuments, and2.
unsupervised relation extraction by follow-ing the principles of the Distributional Hy-pothesis by Harris (1954) resp.
the ExtendedDistributional Hypothesis by Lin and Pantel(2001).The promising preliminary results encourageus to examine this approach for further direc-tions.
Specifically the yet unaddressed parts of theevaluation will be investigated.
Further, the un-supervised relation extraction techniques will beapplied on the complete set of in-domain data,thus finalizing the workflow of enriching a smallamount of domain defining data with web data17gold/NN :: ounce/NNcrude/NN :: barrel/NNoil/NN :: barrel/NNfutures/NNS :: barrel/NNstock/NN :: share/NNgraduate/NN :: University/NNPgraduate/NN :: School/NNPgraduate/NN :: College/NNPgoals/NNS :: season/NNpoints/NNS :: season/NNpoints/NNS :: game/NNtouchdowns/NNS :: season/NNTable 2: Example results for selected entity pairs.Similar entity pairs with respect to the boldfacepair are shown.from focused crawls in order to extract rich in-domain knowledge, particularly from the germaneducational domain as our application domain.While we made clear that crawling the web is acrucial process in order to get the amounts of in-domain data needed by the unsupervised relationextraction methods, we did not yet point out thatwe will also examine the reverse direction, i.e.
thepossibility to use the extracted relations for fur-ther improving the focused crawler.
A focusedcrawler that is powered by semantic relations be-tween entities would raise a new level of semanti-cally focused crawls.
Additionally, we will inves-tigate possibilities for further narrowing the rela-tions found by our system.
Here it is possible tofurther categorize or cluster the relations by usingeither the similarity graph or the features itself, asdone by Pantel and Lin (2002).AcknowledgmentsThis work has been supported by the German In-stitute for Educational Research (DIPF) under theKDSL program.ReferencesAlan Akbik, Larysa Visengeriyeva, JohannesKirschnick, and Alexander L?oser.
2013.
Ef-fective selectional restrictions for unsupervisedrelation extraction.
In Proceedings of the Sixth In-ternational Joint Conference on Natural LanguageProcessing (IJCNLP), pages 1312?1320, Nagoya,Japan.Michele Banko and Eric Brill.
2001.
Scaling to very@1 <= prep above = @2@1 <= prep below = @2@1 <= nsubj = rose/V BD = dobj => @2@1 <= nsubj = dropped/V BD = dobj => @2@1 <= nsubj = fell/V BD = dobj => @2@1 <= prep regarding = @2@1 <= prep about = @2@1 <= prep on = @2@1 <= prep like = @2@1 <= prep such as = @2@1 <= prep including = @2@1 <= nsubj = are/V BP = prep among => @2Table 3: Example results for selected dependencypaths.
Similar paths with respect to the boldfacepath are shown.very large corpora for natural language disambigua-tion.
In Proceedings of the 39th Annual Meeting onAssociation for Computational Linguistics (ACL),pages 26?33, Toulouse, France.Marco Baroni, Silvia Bernardini, Adriano Ferraresi,and Eros Zanchetta.
2009.
The wacky wide web:a collection of very large linguistically processedweb-crawled corpora.
Language Resources andEvaluation, 43(3):209?226.Douglas Biber.
1995.
Dimensions of Register Varia-tion: A Cross-Linguistic Comparison.
CambridgeUniversity Press, Cambridge.Chris Biemann and Martin Riedl.
2013.
Text: Nowin 2d!
a framework for lexical expansion with con-textual similarity.
Journal of Language Modelling(JLM), 1(1):55?95.Chris Biemann, Felix Bildhauer, Stefan Evert, DirkGoldhahn, Uwe Quasthoff, Roland Sch?afer, Jo-hannes Simon, Swiezinski Swiezinski, and TorstenZesch.
2013.
Scalable construction of high-qualityweb corpora.
Journal for Language Technology andComputational Linguistics (JLCL), 27(2).Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson,Mark Joseph, Min-Yen Kan, Dongwon Lee, BrettPowley, Dragomir Radev, and Yee Fan Tan.
2008.The acl anthology reference corpus: A referencedataset for bibliographic research in computationallinguistics.
In Proceedings of the 8th InternationalConference on Language Resources and Evaluation(LREC), Marrakech, Morocco.Avrim Blum and Tom Mitchell.
1998.
Combininglabeled and unlabeled data with co-training.
InProceedings of the Eleventh Annual Conference onComputational Learning Theory (COLT), pages 92?100, Madison, Wisconsin, USA.18Thorsten Brants and Alex Franz.
2006.
Web 1T 5-gramVersion 1.
Linguistic Data Consortium, Philadel-phia.Andrew Carlson, Justin Betteridge, Bryan Kisiel, BurrSettles, Estevam R. Hruschka Jr., and Tom M.Mitchell.
2010.
Toward an architecture for never-ending language learning.
In Proceedings of the24th Conference on Artificial Intelligence (AAAI),Atlanta, GA, USA.Soumen Chakrabarti, Martin van den Berg, and ByronDom.
1999.
Focused crawling: a new approachto topic-specific web resource discovery.
ComputerNetworks, 31(11?16):1623?1640.Nathanael Chambers and Dan Jurafsky.
2011.Template-based information extraction without thetemplates.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies, pages 976?986, Portland, Oregon, USA.Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.
The pascal recognising textual entailmentchallenge.
In Machine Learning Challenges.
Evalu-ating Predictive Uncertainty, Visual Object Classifi-cation, and Recognising Tectual Entailment, volume3944 of Lecture Notes in Computer Science, pages177?190.
Springer Berlin Heidelberg.Dmitry Davidov and Ari Rappoport.
2008a.
Clas-sification of semantic relationships between nomi-nals using pattern clusters.
In Proceedings of the46th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies (ACL-HLT), pages 227?235, Columbus, Ohio.Dmitry Davidov and Ari Rappoport.
2008b.
Unsuper-vised discovery of generic relationships using pat-tern clusters and its evaluation by automatically gen-erated SAT analogy questions.
In Proceedings of the46th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies (ACL-HLT), pages 692?700, Columbus, Ohio.Dmitry Davidov, Ari Rappoport, and Moshe Koppel.2007.
Fully unsupervised discovery of concept-specific relationships by web mining.
In Proceed-ings of the 45th Annual Meeting of the Association ofComputational Linguistics (ACL), pages 232?239,Prague, Czech Republic.Oren Etzioni, Michele Banko, Stephen Soderland, andDaniel S. Weld.
2008.
Open information extrac-tion from the web.
Communications of the ACM,51(12):68?74.Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-pakowicz, Peter Turney, and Deniz Yuret.
2007.Semeval-2007 task 04: Classification of semanticrelations between nominals.
In Proceedings of theFourth International Workshop on Semantic Evalu-ation (SemEval), pages 13?18, Prague, Czech Re-public.Alon Halevy, Peter Norvig, and Fernando Pereira.2009.
The unreasonable effectiveness of data.
IEEEIntelligent Systems, 24(2):8?12.Zellig S. Harris.
1954.
Distributional structure.
Word,10(23):146?162.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 15th Conference on Computational Linguistics(Coling), pages 539?545, Nantes, France.Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,Preslav Nakov, Diarmuid?O S?eaghdha, SebastianPad?o, Marco Pennacchiotti, Lorenza Romano, andStan Szpakowicz.
2010.
Semeval-2010 task 8:Multi-way classification of semantic relations be-tween pairs of nominals.
In Proceedings of theFifth International Workshop on Semantic Evalua-tion (SemEval), pages 33?38, Los Angeles, Califor-nia.Florian Holz and Chris Biemann.
2008.
Unsupervisedand knowledge-free learning of compound splits andperiphrases.
In CICLing 2008: Proceedings of theConference on Intelligent Text Processing and Com-putational Linguistics, pages 117?127, Haifa, Israel.Adam Kilgarriff.
2007.
Googleology is bad science.Computational Linguististics (CL), 33(1):147?151.Dan Klein and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics (ACL), pages 423?430, Sapporo,Japan.Reinhard Kneser and Hermann Ney.
1995.
Improvedbacking-off for m-gram language modeling.
In InProceedings of the IEEE International Conferenceon Acoustics, Speech and Signal Processing, pages181?184, Detroit, Michigan.Mike Lewis and Mark Steedman.
2013.
Unsuper-vised induction of cross-lingual semantic relations.In Proceedings of the 2013 Conference on Em-pirical Methods in Natural Language Processing(EMNLP), pages 681?692, Seattle, WA, USA.Dekang Lin and Patrick Pantel.
2001.
Dirt - discov-ery of inference rules from text.
In Proceedings ofthe Seventh International Conference on KnowledgeDiscovery and Data Mining (KDD), pages 323?328,San Francisco, California.Dekang Lin, Kenneth Church, Heng Ji, Satoshi Sekine,David Yarowsky, Shane Bergsma, Kailash Patil,Emily Pitler, Rachel Lathbury, Vikram Rao, KapilDalwani, and Sushant Narsale.
2010.
New toolsfor web-scale n-grams.
In Proceedings of the 7thInternational Conference on Language Resourcesand Evaluation (LREC), pages 2221?2227, Valletta,Malta.19Filippo Menczer, Gautam Pant, and Padmini Srini-vasan.
2004.
Topical web crawlers: Evaluatingadaptive algorithms.
ACM Transactions InternetTechnology (TOIT), 4(4):378?419.George A Miller and Walter G Charles.
1991.
Contex-tual correlates of semantic similarity.
Language andCognitive Processes (LCP), 6(1):1?28.Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-rafsky.
2009.
Distant supervision for relation ex-traction without labeled data.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP, pages1003?1011, Suntec, Singapore.Gordon Mohr, Michele Kimpton, Micheal Stack, andIgor Ranitovic.
2004.
Introduction to heritrix,an archival quality web crawler.
In Proceedingsof the 4th International Web Archiving WorkshopIWAW?04, Bath, UK.Vivi Nastase, Preslav Nakov, Diarmuid?O S?eaghdha,and Stan Szpakowicz.
2013.
Semantic relations be-tween nominals.
In Synthesis Lectures on HumanLanguage Technologies, volume 6.
Morgan & Cay-pool Publishers.Patrick Pantel and Dekang Lin.
2002.
Documentclustering with committees.
In Proceedings of the25th Annual International ACM SIGIR Conferenceon Research and Development in Information Re-trieval, pages 199?206.Emily Pitler, Shane Bergsma, Dekang Lin, and Ken-neth Church.
2010.
Using web-scale n-grams to im-prove base np parsing performance.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics (Coling), pages 886?894, Beijing,China.Randolph Quirk, Sidney Greenbaum, Geoffrey Leech,and Jan Svartvik.
1985.
A Comprehensive Gram-mar of the English Language.
Longman, London.Matthias Richter, Uwe Quasthoff, Erla Hallsteinsd?ottir,and Chris Biemann.
2006.
Exploiting the leipzigcorpora collection.
In Proceesings of the IS-LTC,Ljubljana, Slovenia.Roland Sch?afer and Felix Bildhauer.
2012.
Buildinglarge corpora from the web using a new efficienttool chain.
In Proceedings of the 8th InternationalConference on Language Resources and Evaluation(LREC), pages 486?493, Istanbul, Turkey.John Sowa.
2000.
Knowledge Representation: Logi-cal, Philosophical and Computational Foundations.Brooks Cole Publishing Co., Pacific Grove, CA.Ang Sun and Ralph Grishman.
2010.
Semi-supervisedsemantic pattern discovery with guidance from un-supervised pattern clusters.
In Proceedings of the23rd International Conference on ComputationalLinguistics (Coling), pages 1194?1202, Beijing,China.Peter D. Turney and Patrick Pantel.
2010.
From fre-quency to meaning: Vector space models of seman-tics.
Journal for Artificial Intelligence Research(JAIR), 37:141?188.Peter D. Turney.
2005.
Measuring semantic similar-ity by latent relational analysis.
In Proceedings ofthe 19th International Joint Conference on ArtificialIntelligence (IJCAI), pages 1136?1141, Edinburgh,Scotland, UK.20
