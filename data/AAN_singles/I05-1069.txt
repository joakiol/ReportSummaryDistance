R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
792 ?
803, 2005.?
Springer-Verlag Berlin Heidelberg 2005Global Path-Based Refinement of Noisy GraphsApplied to Verb SemanticsTimothy Chklovski and Patrick PantelInformation Sciences Institute,University of Southern California,4676 Admiralty Way,Marina del Rey, CA  90292{timc, pantel}@isi.eduAbstract.
Recently, researchers have applied text- and web-mining algorithmsto mine semantic resources.
The result is often a noisy graph of relations be-tween words.
We propose a mathematically rigorous refinement framework,which uses path-based analysis, updating the likelihood of a relation between apair of nodes using evidence provided by multiple indirect paths between thenodes.
Evaluation on refining temporal verb relations in a semantic resourcecalled VERBOCEAN showed a 16.1% error reduction after refinement.1   IntroductionIncreasingly, researchers are creating broad-coverage semantic resources by miningtext corpora [1][5] and the Web [2][6].
These resources typically consist of a noisycollection of relations between words.
The data is typically extracted on a per linkbasis (i.e., the relation between two nodes is determined without regard to othernodes).
Yet, little work has taken a global view of the graph of relations, which mayprovide additional information to refine local decisions by identifying inconsistencies,updating confidences in specific edges (relations), and suggesting relations betweenadditional pairs of nodes.For example, observing the temporal verb relations ?discover happens-before re-fine?
and ?refine happens-before exploit?
provides evidence for the relation ?discoverhappens-before exploit,?
because the happens-before relation is transitive.We conceptualize a semantic resource encoding relations between words as a graphwhere words are nodes and binary relations between words are edges.
In this paper, weinvestigate the refinement of such graphs by updating the confidence in edges using aglobal analysis relying on link semantics.
Our approach is based on the observation thatsome paths (chains of relations) between a pair of nodes xi and xj imply the presence orabsence of a particular direct relation between xi and xj.
Despite each individual pathbeing noisy, multiple indirect paths can provide sufficient evidence for adding, remov-ing, or altering a relation between two nodes.
As illustrated by the earlier example,inferring a relation based on the presence of an indirect path relies on the semantics ofthe links that make up the path, like transitivity or equivalence classes.As an evaluation and a sample practical application, we apply our refinementframework to the task of refining the temporal precedence relations in VERBOCEAN,a broad-coverage noisy network of semantic relations between verbs extracted bymining the Web [2].
Examples of new edges discovered (added) by applying theGlobal Path-Based Refinement of Noisy Graphs Applied to Verb Semantics 793framework include: ?ascertain happens-before evaluate?, ?approve happens-beforeback?, ?coat happens-before bake?, ?plan happens-before complete?, and ?interrogatehappens-before extradite?.Examples of edges that are removed by applying our framework include: ?inducehappens-before treat?, ?warm happens-before heat?, ?halve happens-before slice?,and ?fly happens-before operate?.Experiments show that our framework is particularly good at filtering out the in-correct temporal relations in VERBOCEAN.
Removing incorrect relations is particu-larly important for inference systems.2   VerbOceanWe apply our path-based refinement framework to VERBOCEAN [2], a web-extractedlexical semantics resource with potential applications to a variety of natural languagetasks such as question answering, information retrieval, document summarization, andmachine translation.
VERBOCEAN is a graph of semantic relations between verbs, with3,477 verbs (nodes) and 22,306 relations (edges).
Although the framework applieswhenever some paths through the graph imply presence or absence of a relation, forthe evaluation we focus on the temporal precedence relation in VERBOCEAN, and, inan ancillary role, on the similarity relation.
Senses are not discriminated and an edgeindicates that the relation is believed to hold between some senses of the verbs in thisrelation.The five semantic relations present in VERBOCEAN are presented in Table 1.
Tem-poral precedence (happens-before) is a transitive asymmetric temporal relation be-tween verbs.
Similarity is a relation that suggests two nodes are likely to be in thesame equivalence class, although polysemy makes it only weakly transitive.Table 1.
Types, examples and frequencies of 22,306 semantic relations in VERBOCEANSemantic Relation Example Transitive Symmetric # in VERBOCEANtemporal precedence marry :: divorce Y N 4,205similarity produce :: create Y Y 11,515strength wound :: kill Y N 4,220antonymy open :: close N Y 1,973enablement fight :: win Y N 393In VERBOCEAN, asymmetric relations between two nodes are enforced to be unidi-rectional (i.e., presence of an edge xi happens-before xj guarantees absence of an edgexj happens-before xi).
Larger, inconsistent loops are possible, however, as extractionis strictly local.
Taking advantage of the global picture to refine the edges of the graphcan improve quality of the resource, helping performance of any algorithms or appli-cations that rely on the resource.794 T. Chklovski and P. Pantel3   Global RefinementOur approach relies on a global view of the graph to refine a relation between a givenpair of nodes xi and xj, based on multiple indirect paths between the two nodes.
Theanalysis processes triples <xi, r, xj> for the relation r to output r, its opposite (whichwe will denote q), or neither.
The opposite of happens-before is the same relation inthe reverse direction (happens-after).
The refinement is based on evidence providedby indirect paths, over a probabilistic representation of the graph.Section 3.1 introduces the steps of the refinement, Section 3.2 details which pathsare used as evidence, and Section 3.3 derives the statistical model used for combiningevidence from multiple unreliable paths.3.1   Overview of the Refinement AlgorithmWe first introduce some notation.
Let Ri,j denote the event that the relation r is presentbetween nodes xi and xj in the original graph ?
i.e., the graph indicates (perhaps spuri-ously) the presence of the relation r between xi and xj.
Let ri,j denote the relation ractually holding between xi and xj.
Let ?i,j denote an acyclic path from xi to xj of (pos-sibly distinct) relations {Ri,i+1 .. Rj-1,j}.
For example, the path ?x1 similar x2 happens-before x3?
can be denoted ?1,3.
If the edges of ?i,j indicate the relation r between thenodes xi and xj, we say that ?i,j indicates ri,j.Given a triple <xi, r, xj>, we identify the set ?r full of all paths ?i,j such that ?i,j indi-cates ri,j and ?i,j?s sequence of relations {Ri,i+1 .. Rj-1,j} matches one of the allowedsequences.
That is, we only consider certain path types.
The restriction on types ofpaths considered is introduced because identifying and processing all possible pathsindicating ri,j is too demanding computationally in a large non-sparse graph.
The pathtypes considered are detailed in Section 3.2.
Note that the intermediate nodes of pathscan range over the entire graph.For each ?i,j in the above set ?r full, we compute the estimated probability that ri,jholds given the observation of (relations that make up) ?i,j.
Each edge in the inputgraph is treated as a probabilistic one, with probabilities P(ri,j) and P(ri,j|Ri,j) estimatedfrom human judgments on a representative sample.
Generally, longer paths and pathsmade up of less reliable edges will have lower probabilities.
Section 3.3 presents thefull model for estimating these probabilities.Next, we form the set ?r by selecting from ?r full only the paths which have nocommon intermediate nodes.
This is done greedily, processing all paths in ?r full inorder of decreasing score, placing each in ?r iff it does not share any intermediatenodes with any path already in ?r.
This is done to avoid double-counting the availableevidence in our framework, which operates assuming conditional independence ofpaths.Next, we compute P(ri,j | ?r), the probability of ri,j given the evidence provided bythe paths in ?r.
The model for computing this is described in Section 3.3.
Similarly,?q and P(qi,j | ?q) are computed for qi,j, the opposite of ri,j.
Next, the evidence for rand q are reconciled by computing P(ri,j | ?r, ?q) and, similarly, P(qi,j | ?r, ?q).Finally, the more probable of the two relations ri,j and qi,j is output if its probabilityexceeds a threshold value Pmin (i.e., ri,j is output if P(ri,j | ?r, ?q) > P(qi,j | ?r, ?q) andP(ri,j | ?r, ?q) > Pmin.
In Section 4.2, we experiment with varying values of Pmin.Global Path-Based Refinement of Noisy Graphs Applied to Verb Semantics 7953.2   Paths ConsideredThe enabling observation behind our approach is that in a graph in which edges havecertain properties such as transitivity, some paths ?i,j indicate the presence of a rela-tion between the first node xi and the last node xj.
In the paths we consider, we rely ontwo kinds of inferences: transitivity and equivalence.
Also, we do not consider verylong paths, as they tend to become unreliable due to accumulation of chance of falsedetection of each edge and sense drift in each intermediate node.
The set of paths toconsider was not rigorously motivated.
Rather, we aimed to cover some commoncases.
Refining the sets of paths is a possible fruitful direction for future work.For the presence of happens-before, a transitive asymmetric relation, we consid-ered all 11 path types of length 3 or less which imply happens-before between the endnodes based on transitivity and equivalence:?happens-before?
?similar, similar, happens-before?
?happens-before, similar?
?happens-before, happens-before, similar?
?similar, happens-before?
?similar, happens-before, happens-before?
?happens-before, happens-before?
?happens-before, similar, happens-before?
?happens-before, similar, similar?
?happens-before, happens-before, happens-before?
?similar, happens-before, similar?3.3   Statistical Model for Combining EvidenceThis section presents a rigorous derivation of the probabilistic model for computingand combining probabilities with which indirect paths indicate a given edge.3.3.1   Estimating from a Single PathWe first derive probability of r1,n given single path ?
1,n:( )nnrP ,1,1 |?If n is 2, i.e.
?1,n has only one edge R1,2, we have simply the probability that theedge actually holds given its presence in the graph:( ) ( )2,12,12,12,1 || RrPrP =?
(1)Otherwise, ?1,n has intermediate nodes, in which case P(r1,n | ?1,n) can be estimatedas follows:( ) ( ) ( ) ( )( )( ) ( )( )nnnnnnnnnnnnnnnnnnnnnnnRRrrPrrRRrPRRrrPrrRRrPRRrPrP,12,1,12,1,12,1,12,1,1,12,1,12,1,12,1,12,1,1,12,1,1,1,1...,,|...,,...,,,...,,|...,,|...,,...,,,...,,|...,,||??????????
?+==?Because r1,n is conditionally independent from Ri,i+1 given ri,i+1 or ?ri,i+1, we cansimplify:( ) ( ) ( )( )( ) ( )( )nnnnnnnnnnnnnnnnRRrrPrrrPRRrrPrrrPrP,12,1,12,1,12,1,1,12,1,12,1,12,1,1,1,1...,,|...,,...,,|...,,|...,,...,,||???????
?+=?Assuming independence of a given relation ri,i+1 from all edges in ?1,n except forthe edge Ri,i+1 yields:796 T. Chklovski and P. Pantel( ) ( ) ( )( )( ) ( )( )???=++??=++??
?+=1..1 1,1,,12,1,11..1 1,1,,12,1,1,1,1|1...,,||...,,||ni iiiinnnni iiiinnnnnRrPrrrPRrPrrrPrP ?Let Pmatch denote the probability that there is no significant shift in meaning at agiven intermediate node.
Then, assume that path r1,2,?, rn-1,n indicates r1,n iff themeanings at n ?
2 intermediate nodes match:( ) 2,12,1,1 ...,,| ??
= nmatchnnn PrrrPAlso, when one or more of the relations ri,i+1 do not hold, nothing is generally im-plied1 about r1,n, thus( )( ) ( )nnnn rPrrrP ,1,12,1,1 ...,,| =?
?Plugging these in, we have:( ) ( ) ( ) ( )( )???=++??=++?
?+=1..1 1,1,2,11..1 1,1,2,1,1 |1|| ni iiiinmatchnni iiiinmatchnn RrPPrPRrPPrP ?which can be rewritten as:( ) ( ) ( )( ) ( )??=++?
?+=1..1 1,1,2,1,1,1,1 |1| ni iiiinmatchnnnn RrPPrPrPrP ?
(2)where the prior P(r1,n) and the conditional P(ri,i+1 | Ri,i+1) can be estimated empiricallyby manually tagging the relations Ri,j in a graph as correct or incorrect: P(r1,n) is theprobability that an edge will be labeled with relation r by a human judge, andP(ri,i+1 | Ri,i+1) is the precision with which the system could identify R. While Pmatchcan be estimated empirically we have not done so.
We experimentally set Pmatch = 0.9.3.3.2   Combining Estimates from Multiple PathsIn this subsection we derive an estimate of the validity of inferring r1,n given the set?r of m paths ?1,n1, ?1,n2, ?, ?1,nm:( )mnnnnrP ,12,11,1,1 ,...,,| ???
(3)In the case of zero paths, we use simply P(r1,n)=P(r), the probability of observing rbetween a pair of nodes from a sample set with no additional evidence.
The case ofone path has been treated in the previous section.
In the case of multiple paths, wederive the expression as follows (omitting for convenience subscripts on paths, anddistinguishing them by their superscripts).
We assume conditional independence ofany two paths ?k and ?l given r or ?r.
Using Bayes?
rule yields2:( ) ( ) ( )( )( ) ( )( )mmkkmmmn PrPrPPrPrPrP????????
?,...,|,...,|,...,,...,| 1 ..1111,1?===(4)1This is not the case for paths in which the value of one edge, given the other edges, is corre-lated with the value of the end-to-end relation.
The exception does not apply for happens-before edges if there are other happens-before edges in the path, nor does it ever apply forany similar edges.2Here and afterward, the denominators must be non-zero; they are always so when we applythis model.Global Path-Based Refinement of Noisy Graphs Applied to Verb Semantics 797The above denominator can be rewritten as:( ) ( ) ( ) ( ) ( )( ) ( ) ( ) ( )??==??+=??+=mkkmkkmmmrPrPrPrPrPrPrPrPP..1..1111|||,...,|,...,,...,????????
(5)Using Bayes?
rule again, the expressions in the above products can be rewritten asfollows:( ) ( ) ( )( )rPPrPrPkkk ???
|| =  (6)( ) ( ) ( )( )( )( ) ( )( )rPPrPrPPrPrPkkkkk??=?
?=?1|1|| ?????
(7)Substituting into Eq.
5 the Eqs.
6 and 7 yields:( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )( ) ( )( )( )( ) ( )( )????=====???????????+????????=?
?+=mkkkmkkkmkkmkkmrPPrPrPrPPrPrPrPrPrPrPP..1..1..1..111|11|||,..., ????????
( )( ) ( )( )( )( )( )( )( ) ????????????+??=?==???
1..11..1..1 1|1|mmkkmmkkmkkrPrPrPrPP??
?Using the above for the denominator of Eq.
4, using Eq.
6 in the numerator of Eq.4, and simplifying, we have:( ) ( ) ( )( )( )( )( )( )( )( )( )( )( )( ) 1..11..11..11..111|1||,...,|,...,|?=?=?==?
?+== ???
?mmkkmmkkmmkkmmkkmrPrPrPrPrPrPPrPrPrP ???????
?which can be rewritten as( ) ( )( ) ( )( ) ( )( )???=?==??????????+=mkkmmkkmkkmrPrPrPrPrPrP..11..1..11|11||,...,|?????
(8)where P(r | ?k) is as in Eq.
2 and P(r) can be estimated empirically.3.3.3   Estimating from Supporting and Opposing PathsRecall that q denotes the opposite of r. The previous section has shown how to com-pute P(r | ?r) and, similarly, P(q | ?q).
We now derive how to estimate r given both?r, ?q:( )qrrP ??
,|  (9)We assume that r and q are disjoint, P(r,q)= P(r|q)= P(q|r)=0.
We also assume thatq is conditionally independent from ?r given ?r, i.e.,798 T. Chklovski and P. Pantel( ) ( )rqPrqP r ?=??
|,|  and ( ) ( )qqr rqPrqP ??=???
,|,,| , and similarly( ) ( )qrPqrP q ?=??
|,|  and ( ) ( )rqr qrPqrP ??=???
,|,,|We proceed by deriving the following, each consequent relying on the previous re-sult:LEMMA 1: P(q | ?r), in Eq.
10LEMMA 2: P(?q | ?r), in Eq.
12LEMMA 3: P(r | ?q, ?r) and P(q | ?r, ?q), in Eqs.
13 and 14THEOREM 1: P(r | ?r, ?q), in Eq.
18.LEMMA 1.
From P(r | q) = 0, we observe:( ) ( ) ( ) ( ) ( ) ( ) ( )rqPrPrqPrPrqPrPqP ??=?
?+= |||Solving for P(q | ?r), we obtain:( ) ( )( )rPqPrqP?=?|  (10)LEMMA 2.
Using an approach similar to that of Lemma 1 and noting that P(q | r, ?r) =P(q | r) = 0 yields:( ) ( ) ( ) ( ) ( ) ( ) ( )rrrrrrr rqPrPrqPrPrqPrPqP ????+=????+??=?
,||0,||,|||Invoking the assumption P(q | ?r, ?r) = P(q | ?r), we can simplify:( ) ( ) ( )rqPrPqPrr???=?
|||Substituting the result of Lemma 1 (Eq.
10) into the above yields:( ) ( ) ( )( )rPqPrPqP rr???=?
||  (11)And thus( ) ( ) ( ) ( )( )rPqPrPrPqP rr?????=??
||  (12)LEMMA 3.
We derive P(r | ?q, ?r), using P(?q | r, ?r) = 1:( ) ( )( )( ) ( )( ) ( )( )( )( )( )rrrrrrrrrrr qPrPqPqrPPqPPqrPqPqrPqrP???=????=??????=????=??
||||,||,,,,,|Substituting the result of Lemma 2 (Eq.
12) into the above yields:( ) ( ) ( )( ) ( ) ( )qPrPrPrPrPqrPrrr ??????=??
||,|  (13)Similarly,( ) ( ) ( )( ) ( ) ( )rPqPqPqPqPrqPqqq ??????=??
||,|(14)Global Path-Based Refinement of Noisy Graphs Applied to Verb Semantics 799THEOREM 3( ) ( ) ( ) ( )( )( ) ( )( ) ( ) ( )( ) ( ) ( )( )qPqPrPrPqPrPqPrPrPrPqrqrqr???????????=??
||11||,|P(r | ?r, ?q) can be derived using the above Lemmas, as follows:( ) ( ) ( ) ( ) ( )qrqrqrqrqr qrPqPqrPqPrP ??????+????=??
,,|,|,,|,|,|The assumption P(r | q) = 0 implies P(r | q, ?r, , ?q) = 0.
Also, since r is condi-tionally independent of ?q given ?q, we have P(r |?q, ?r, ?q) = P(r | ?q, ?r).
Thus,we can simplify:( ) ( ) ( ) ( )( ) ( )rqrrqrqr qrPqPqrPqPrP ?????=?????=??
,|,|1,|,|,|  (15)Similarly,( ) ( ) ( ) ( )( ) ( )qqrqqrqr rqPrPrqPrPqP ?????=?????=??
,|,|1,|,|,|  (16)Substituting, Eq.
16 into Eq.
15 yields:( ) ( )( ) ( )( ) ( )( ) ( )( ) ( ) ( ) ( )rqqrqrrqqrqrqrPrqPrPrqPqrPqrPrqPrPrP??????+?????=????????=?
?,|,|,|,|1,|,|,|,|11,|Solving for P(r | ?r, ?q), we get:( ) ( ) ( ) ( )( ) ( )qrqrrqrrqPqrPrqPqrPqrPrP????????????=?
?,|,|1,|,|,|,|  (17)Expanding and simplifying, we establish our Theorem 1:( ) ( ) ( ) ( )( )( ) ( )( ) ( ) ( )( ) ( ) ( )( )qPqPrPrPqPrPqPrPrPrPqrqrqr???????????=??
||11||,|  (18)4   Experimental ResultsIn this section, we evaluate our refinement framework on the temporal precedencerelations discovered by VERBOCEAN, and present some observations on applying therefinement to other VERBOCEAN relations.4.1   Experimental SetupFollowing Chklovski and Pantel [2], we studied 29,165 pairs of verbs obtained from aparaphrasing algorithm called DIRT [4].
We applied VERBOCEAN to the 29,165 verbpairs, which tagged each pair with the semantic tag happens-before, happens-afterand no temporal precedence3.3VERBOCEAN actually produces additional relations such as similarity, antonymy, strength andenablement.
For our purposes, we only consider the temporal relations.800 T. Chklovski and P. PantelFor our experiments, we randomly sampled 1000 of these verb pairs, and presentedthem to two human judges (without revealing the VERBOCEAN tag).
The judges wereasked to classify each pair among the following tags:Happens-before with entailmentHappens-before without entailmentHappens-after with entailmentHappens-after without entailmentAnother semantic relationNo semantic relationFor the purposes of our evaluation, tags a and b align with VERBOCEAN?s happens-before tag, tags c and d align with the happens-after tag, and tags e and f align withthe no temporal relation tag4.
The Kappa statistic [7] for the task was ?
= 0.78.4.2   Refinement ResultsTable 2 shows the overall accuracy of VERBOCEAN tags on the 1000 verb pairs ran-domly sampled from DIRT.
Each row represents a different refinement.
The numberin parentheses is Pmin, the threshold value for the strength of the relation from Section3.1.
As the threshold is increased, the refinement algorithm requires greater evidence(more supporting paths and absence of opposing evidence) to trigger a temporal rela-tion between a pair of verbs.Table 2.
Accuracy (95% confidence) of VERBOCEAN on a random sample of 1000 verb pairstagged by two judgesAccuracyJudge1 Judge2 TotalUnrefined80.7% 74.8% 77.7% ?
2.0%Refined (0.5) 66.0% 63.7% 64.8% ?
2.6%Refined (0.66) 75.4% 71.7% 73.5% ?
2.4%Refined (0.9) 83.1% 77.2% 80.2% ?
2.1%Refined (0.95) 84.5% 78.0% 81.3% ?
1.9%Refined (Combo)* 86.8% 81.3% 84.0% ?
2.4%* Combo combines the no temporal relation from the 0.5 and the happens-before andhappens-after from the and 0.95 refinements, where the reported accuracy is com-puted on the subset of 716 verb pairs for which the algorithm is most confident.Table 3 shows the reassignments due to refinement.
At the 0.5 level, the refinementleft 76 of 81 relations unchanged, revising 3 to happens-after and 2 to no temporalrelation.
Similarly, only two of the original happens-after relations were changedwith  refinement.
However,  of  the  849  originally  tagged  no temporal relation, the4In future work, we plan to use the judges?
classifications to evaluate the extraction of entail-ment relations using VERBOCEAN.Global Path-Based Refinement of Noisy Graphs Applied to Verb Semantics 801Fig.
3.
Refinement precision on all 1000 verbpairs vs. on the 819 verb pairs on which theannotators agree on tagOverall Precision vs.
Precision on Agreed Pairs6065707580859095100Unrefined R 0.5 R 0.66 R 0.9 R 0.95 R ComboRefinement AlgorithmPrecision(%)Overall Agreed PairsTable 3.
Allocation change between semantic tags due to refinementHappens-Before Happens-After No Temporal RelationUnrefined 81 70 849Refined (0.5) 190 180 630Refined (0.66) 118 124 758Refined (0.9) 53 66 881Refined (0.95) 40 46 914refinement moved 113 to happens-beforeand 109 to happens-after.
The precisionof the 0.5 refinement on the no temporalrelation tag increased by 4%; however,the precision on the temporal relationsdecreased by 5.7%.
At the 0.95 refine-ment level, 54 of the 81 relations origi-nally tagged happens-before and 45 ofthe 70 relations originally tagged hap-pens-after were changed to no temporalrelation.
Only 34 of the 849 no temporalrelations were changed.
At this level, theprecision of no temporal relation tagdecreased by 0.8% and the temporalrelations?
precision increased by 4%.Hence, at the 0.5 level, pairs classified as no temporal relation were improvedwhile at the 0.95 level, pairs classified as a temporal relation were improved.
To lev-erage benefits of the two, we applied both the 0.5 and 0.95 level refinements and kepthappens-before and happens-after classifications from the 0.95 level, and kept the notemporal relation classification from the 0.5 level.5 284 verb pairs were left unclassi-fied.
On the 716 classified verb pairs, refinement improved accuracy by 6.3%.5This combination is guaranteed to be free of conflicts in classification because it is impossi-ble for a relation to be classified as temporal at the 0.95 threshold level while being classifiedas non-temporal at the 0.5 level.Fig.
1.
Refinement precision on each semantictagPrecision of Semantic Tags020406080100Unrefined R 0.5 R 0.66 R 0.9 R 0.95 R ComboRefinement AlgorithmPrecision(%)Happens-Before Happens-AfterNo Temporal Relation OverallFig.
2.
Refinement recall on each semantic tagRecall of Semantic Tags020406080100Unrefined R 0.5 R 0.66 R 0.9 R 0.95 R ComboRefinement AlgorithmRecall(%)Happens-Before Happens-AfterNo Temporal Relation Overall802 T. Chklovski and P. PantelFigures 1 and 2 illustrate the refinement precision and recall for each semantic tag.Both annotators have agreed on 819 verb pairs, and we examined performance onthese.
Figure 3 shows a higher precision on these pairs as compared to the overall set,illustrating that what is easier for the annotators is easier for the system.4.3   Observations on Refining Other RelationsWe have briefly investigated refining other semantic relations in VERBOCEAN.
Theextent of the evaluation was limited by availability of human judgments.
We ran-domly sampled 100 pairs from DIRT and presented the classifications to three humanjudges for evaluation [2].Of the 100 pairs, 66 were identified to have a relation.
We applied our refinementalgorithm to VERBOCEAN and inspected the output.
On the 37 relations thatVERBOCEAN got wrong, our system identified six of them.
On the remaining 29 thatVERBOCEAN got correct, only one was identified as incorrect (false positive).
Hence,on the task of identifying incorrect relations in VERBOCEAN, our system has a preci-sion of 85.7%, where precision is defined as the percentage of correctly identifiederroneous relations.
However, it only achieved a recall of 16.2%, where recall is thepercentage of erroneous relations that our system identified.
Table 4 presents therelations that were refined by our system.
The first two columns show the verb pairwhile the next two columns show the original relation in VERBOCEAN.Table 4.
Seven relations in VERBOCEAN refined by a small test run on other relationsVerb 1 Verb 2VERBOCEANRelationRefinementRelationJudge 1 Relation Judge 2 Relation Judge 3 Relationattach usehappens-beforesimilarsimilar none none nonebounce get weaker than  stronger than none none nonedispatch defeat opposite none none none happens-beforedoom complicate opposite similar* none stronger-than stronger-thanflatten level stronger than no relation* similar similar similaroutlaw codify similar opposite none none oppositionprivatize improve happens-before none happens-before happens-before happens-before* only revision of relation to its opposite or ?none?
was attempted here4.4   DiscussionOur evaluation focused on the presence or absence of relations after refinement, with-out exploiting the fact that our framework also updates confidences in a given rela-tion.
The additional information about confidence can benefit probabilistic inferenceapproaches (e.g., [3]).Possible extensions to the algorithm include a more elaborate inference from graphstructure, for example treating the absence of certain paths as counter-evidence.
Sup-pose that relations A happens-before B and A similar A' were detected, but the rela-tion A' happens-before B was not.
Then, the absence of a pathGlobal Path-Based Refinement of Noisy Graphs Applied to Verb Semantics 803A similar A' happens-before Bsuggests the absence of A happens-before B.Other important avenues of future work include applying our framework to otherrelations (e.g., strength in VERBOCEAN) and to better characterize the refinementthresholds.5   ConclusionsWe presented a method for refining edges in graphs by leveraging the semantics ofmultiple noisy paths.
We re-estimated the presence of an edge between a pair of nodesfrom the evidence provided by multiple indirect paths between the nodes.
Our ap-proach applies to a variety of relation types: transitive symmetric, transitive asymmet-ric, and relations inducing equivalence classes.
We applied our model to refiningtemporal verb relations in a semantic resource called VERBOCEAN.
Experimentsshowed a 16.1% error reduction after refinement.
On the 72% refinement decisionsthat it was most confident, the error reduction was 28.3%.The usefulness of a semantic resource is highly dependent on its quality, which isoften poor in automatically mined resources.
With graph refinement frameworks suchas the one presented here, many of these resources may be improved automatically.References1.
Berland, M. and E. Charniak, 1999.
Finding parts in very large corpora.
In ACL-1999.
pp.57-64.
College Park, MD.2.
Chklovski, T., and Pantel, P. 2004.
VERBOCEAN: Mining the Web for Fine-GrainedSemantic Verb Relations.
In Proceedings of 2004 Conference on Empirical Methods inNatural Language Processing (EMNLP 2004), Barcelona, Spain, July 25-26.3.
Domingos, P. and Richardson, M. 2004.
Markov Logic: A unifying framework forstatistical relational learning.
In Proceedings of ICML Workshop on Statistical RelationalLearning and its Connections to Other Fields.
Banff, Canada.4.
Lin, D. and Pantel, P. 2001.
Discovery of inference rules for question answering.
NaturalLanguage Engineering, 7(4):343-360.5.
Pantel, P. and Ravichandran, D. 2004.
Automatically labeling semantic classes.
InProceedings HLT/NAACL-04.
pp.
321-328.
Boston, MA.6.
Shinzato, K. and Torisawa, K. 2004.
Acquiring hyponymy relations from web documents.In Proceedings of HLT-NAACL-2004.
pp.
73-80.
Boston, MA.7.
Siegel, S. and Castellan Jr., N. 1988.
Nonparametric Statistics for the Behavioral Sciences.McGraw-Hill.
