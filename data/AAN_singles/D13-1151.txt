Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1449?1454,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsAutomatically Identifying Pseudepigraphic TextsMoshe KoppelBar Ilan UniversityRamat-Gan, 52900, Israelmoishk@gmail.comShachar SeidmanBar Ilan UniversityRamat-Gan, 52900, Israelshachar9@gmail.comAbstractThe identification of pseudepigraphic texts ?texts not written by the authors to which theyare attributed ?
has important historical, fo-rensic and commercial applications.
We in-troduce an unsupervised technique for identi-fying pseudepigrapha.
The idea is to identifytextual outliers in a corpus based on the pair-wise similarities of all documents in the cor-pus.
The crucial point is that document simi-larity not be measured in any of the standardways but rather be based on the output of a re-cently introduced algorithm for authorship ve-rification.
The proposed method stronglyoutperforms existing techniques in systematicexperiments on a blog corpus.1 IntroductionThe Shakespeare attribution problem is centuriesold and shows no signs of abating.
Some scholarsargue that some, or even all, of Shakespeare?sworks were not actually written by him.
The mostmainstream theory ?
and the one that interests ushere ?
is that most of the works were written byShakespeare, but that several of them were not.Could modern methods of computational author-ship attribution be used to detect which, if any, ofthe works attributed to Shakespeare were not writ-ten by him?More generally, this paper deals with the unsu-pervised problem of detecting pseudepigrapha:documents in a supposedly single-author corpusthat were not actually written by the corpus?s pre-sumed author.
Studies as early as Mendenhall(1887), have observed that texts by a single authortend to be somewhat homogeneous in style.
If thisis indeed the case, we would expect that pseudepi-grapha would be detectable as outliers.Identifying such outlier texts is, of course, aspecial case of general outlier identification, one ofthe central tasks of statistics.
We will thus considerthe pseudepigrapha problem in the context of themore general outlier detection problem.Typically, research on textual outliers assumesthat we have a corpus of known authentic docu-ments and are asked to decide if a specified otherdocument is authentic or not (Juola and Stamata-tos, 2013).
One crucial aspect of our problem isthat we do not assume that any specific text in acorpus is known a priori to be authentic or pseude-pigraphic; we can assume only that most of thedocuments in the corpus are authentic.The method we introduce in this paper builds onthe approach of Koppel and Winter (2013) for de-termining if two documents are by the same au-thor.
We apply that method to every pair ofdocuments in a corpus and use properties of theresulting adjacency graph to identify outliers.
Inthe following section, we briefly outline previouswork.
In Section 3 we provide a framework foroutlier detection and in Section 4 we describe ourmethod.
In Section 5 we describe the experimentalsetting and give results and in Section 6 we presentresults for the plays of Shakespeare.2 Related WorkIdentifying outlier texts consists of two main stag-es: first, representing each text as a numerical vec-tor representing relevant linguistic features of thetext and second, using generic methods to identifyoutlier vectors.There is a vast literature on generic methods foroutlier detection, summarized in Hodge & Austin(2004) and Chandola et al(2009).
Since our prob-1449lem setup does not entail obtaining any labeledexamples of authentic or outlier documents, super-vised and semi-supervised methods are inapplica-ble.
The available methods are unsupervised,principally probabilistic or proximity-based me-thods.
A classical variant of such methods for un-ivariate normally distributed data uses the the z-score (Grubbs, 1969).
Such simple univariate out-lier detectors are, however, inappropriate for iden-tifying outliers in a high-dimensional textualcorpus.
Subsequent work, such as the Stahel-Donoho Estimator (Stahel, 1981; Donoho, 1982),PCout (Filzmoser et al 2008), LOF (Breunig andKriegel, 2000) and ABOD (Kriegel et al 2008)have generalized univariate methods to high-dimensional data points.In his comprehensive review of outlier detectionmethods in textual data, Guthrie (2008) compares avariety of vectorization methods along with a va-riety of generic outlier methods.
The vectorizationmethods employ a variety of lexical and syntacticstylistic features, while the outlier detection me-thods use a variety of similarity/distance measuressuch as cosine and Euclidean distance.
Similar me-thods have also been used in the field of intrinsicplagiarism detection, which involves segmenting atext and then identifying outlier segments (Stama-tatos, 2009; Stein et al 2010).3 Proximity MethodsFormally, the problem we wish to solve is definedas follows: Given a set of documents D ={d1,?,dn}, all or most of which were written byauthor A, which, if any, documents in D were notwritten by A?We begin by considering the kinds of proximitymethods for textual outlier detection considered byGuthrie (2008) and in the work on intrinsic plagiar-ism detection; these will serve as baseline methodsfor our approach.
The idea is simple: mark as anoutlier any document that is too far from the rest ofthe documents in the corpus.We briefly sketch the key steps:1.
Represent a document as a numerical vector.The kinds of measurable features that can beused to represent a document include frequen-cies of word unigrams, function words, parts-of-speech and character n-grams, as well ascomplexity measures such as type/token ratio,sentence and word length and so on.2.
Measure the similarity of two document vec-tors.We can use either inverses of distance meas-ures such as Euclidean distance or Manhattandistance, or else direct similarity measuressuch as cosine or min-max.3.
Use an aggregation method to measure thesimilarity of a document to a set of documents.One approach is to simply measure the dis-tance from a document to the centroid of allthe other documents (centroid method).Another approach is to first measure the simi-larity of a document to each other documentand then to aggregate the results by averagingall the obtained values (mean method):Alternatively, we can average the values onlyfor the k nearest neighbors (k-NN method):(where Dk = k nearest neighbors of di).Yet another method is to use median distance(median method).We note that the centroid method and meanmethod suffer from the masking effect (Bendreand Kale, 1987; Rousseeuw and Leroy, 2003):the presence of some outliers in the data cangreatly distort the estimator's results regardingthe presence of other outliers.
The k-NN me-thod and the median method are both muchmore robust.4.
Choose some threshold beyond which a docu-ment is marked as an outlier.Choosing the threshold is one of the central is-sues in statistical approaches.
For our purpos-es, however, the choice of threshold is simplya parameter trading off recall and precision.4 Second-Order SimilarityOur approach is to use an entirely different kind ofsimilarity measure in Step 2.
Rather than use afirst-order similarity measure, as is customary, weemploy a second-order similarity measure that isthe output of an algorithm used for the authorshipverification problem (Koppel et al2011), in whichwe need to determine if two, possibly short, docu-ments were written by the same author.That algorithm, known as the ?impostors me-thod?
(IM), works as follows.
Given two docu-1450ments, d1 and d2, generate an appropriate set ofimpostor documents, p1,?,pm and represent eachof the documents in terms of some large feature set(for example, the frequencies of various words orcharacter n-grams in the document).
For some ran-dom subset of the feature set, measure the similari-ty of d1 to d2 as well as to each of the documentsp1,?,pm and note if d1 is closer to d2 than to any ofthe impostors.
Repeat this k times, choosing a dif-ferent random subset of the features in each itera-tion.
If d1 is closer to d2 than to any of theimpostors (and likewise switching the roles of d1and d2) for at least ?% of iterations, then outputthat d2 and d1 are the same author.
(The parameter?
is used to trade-off recall and precision.
)Adapting that method for our purposes, we usethe proportion of iterations for which d1 is closer tod2 than to any of the impostors as our similaritymeasure (adding a small twist to make the measuresymmetric over d1 and d2, as can be seen in line2.2.2 of the algorithm).
More precisely, we do thefollowing:Given: Corpus D={d1,?,dn}1.
Choose a feature set FS for representing documents, afirst-order similarity measure sim, and an impostor set{p1,?,pm}.2.
For each pair of documents <di, dj> in set D:2.1.
Let sim2(di, dj) := 02.2.
Iterate K times:2.2.1.
Randomly choose 40% of features in FS2.2.2.
If sim(di, dj)2  >maxu?
{1,..,m}sim(di,  pu)*maxu?
{1,..,m}sim(dj, pu),then sim2(di, dj) ?
sim2(di, dj) + 1/K3.
For each document di in set D:3.1.
Compute sim2(di, D) = agg w?
{1,..,n}[sim2(di, dw)]where agg is some aggregation function3.2.
If sim2(di, D) < ?
(where ?
is a parameter),then mark di as outlier.The method for choosing the impostor set iscorpus-dependent, but quite straightforward: wesimply choose random impostors from the samegenre and language as the documents in question.The choice of feature set FS, first-order similaritymeasure sim, and aggregation function agg can bevaried.
For FS, we simply use bag-of-words(BOW).
As for sim and agg, we show below re-sults of experiments comparing the effectiveness ofvarious choices for these parameters.Using second-order similarity has several sur-face advantages over standard first-order measures.First, it is decisive: for most pairs, second-ordersimilarity will be close to 0 or close to 1.
Second, itis self-normalizing: scaling doesn?t depend on thesize of the underlying feature sets or the lengths ofthe documents.
As we will see, it is also simplymuch more effective for identifying outliers.5 ExperimentsWe begin by assembling a corpus consisting of3540 blog posts written by 156 different bloggers.The blogs are taken from the blog corpus assem-bled by Schler et al(2006) for use in authorshipattribution tasks.
Each of the blogs was written inEnglish by a single author in 2004 and each postconsists of 1000 words (excess is truncated).For our initial experiments, each trial consists of10 blog posts, all but p of which are by a singleblogger.
The number of pseudepigraphic docu-ments, p, is chosen from a uniform distributionover the set {0,1,2,3}.
Our task is to identifywhich, if any, documents in the set are not by themain author of the set.
The pseudepigraphic docu-ments might be written by a single author or bymultiple authors.To measure the performance of a given similari-ty measure sim, we do the following in each trial:1.
Represent each document in the trial set Din terms of BOW.2.
Measure the similarity of each pair of doc-uments in the trial set using the similaritymeasure sim.3.
Using some aggregation function agg,compute for each document di:sim(di, D) = agg w?
{1,..,n}[sim(di, dw)].4.
If sim (di, D) < ?, mark di as an outlier(where ?
is a parameter ).Our objective is to show that results usingsecond-order similarity are stronger than those us-ing first-order similarity.
Before we do this, weneed to determine the best aggregation function touse in our experiments.
In Figure 1, we show re-call-precision breakeven values (for the outlierclass) over 250 independent trials, for each of ourfour first-order similarity measures (inverse Eucli-dean, inverse Manhattan, cosine, min-max) used inconjunction with each of four aggregation func-tions (centroid, mean, k-NN mean, median).
As isevident, k-NN is the best aggregation function ineach case.
We will give these baseline methods anadvantage by using k-NN as our aggregation func-tion in all our subsequent experiments.1451Figure 1.
Breakeven values on first-order similaritymeasures with various aggregation functions.We are now ready to perform our main expe-riment.
We use BOW as our feature set and k-NNas our aggregation function.
We use 500 randomblog posts as our impostor set.
In Figure 2, weshow recall-precision curves for outlier documentsover 250 independent trials, as just described, us-ing four first-order similarity measures as well oursecond-order similarity measure using each of thefour as a base measure.
As can be seen, even theworst second-order similarity measure significantlyoutperforms all the standard first-order measures.In Figure 3, we show the breakeven values for eachmeasure, pairing each first-order measure with thesecond-order measure that uses it as a base.
Clear-ly, the mere use of a second-order method im-proves results, regardless of the base measure.Figure 2.
Recall-precision curves for four first-ordersimilarity measures and four second-order similaritymeasures, based on 250 trials of 10 documents each.Figure 3.
Breakeven values for first-order measures andcorresponding second-order measures.Thus far we have considered authorial corporaconsisting of only ten documents.
In Figures 4 and5, we repeat the experiment described in Figures 2and 3 above, but with each trial consisting of 50documents including any number of pseudepi-graphic documents in the range 0 to 15.
The samephenomenon is apparent: second-order similaritystrongly improves results over the correspondingfirst-order base similarity measure.Figure 4.
Recall-precision curves for four first-ordersimilarity measures and four second-order similaritymeasures, based on 250 trials of 50 documents each.1452Figure 5.
Breakeven values for first-order measures andcorresponding second-order measures6 Results on ShakespeareWe applied our methods to the texts of 42 plays byShakespeare (taken from Project Gutenberg).
Weincluded two plays by Thomas Kyd as sanitychecks.
In addition, we included three plays occa-sionally attributed to Shakespeare, but generallyregarded by authorities as pseudepigrapha (A York-shire Tragedy, The Life of Sir John Oldcastle andPericles Prince of Tyre).
We also included KingEdward III and King Henry VI (Part 1), both ofwhich are subjects of dispute among Shakespearescholars.
As impostors we used 39 works by con-temporaries of Shakespeare, including ChristopherMarlowe, Ben Jonson and John Fletcher.We found that the two plays by Thomas Kydand the three pseudepigraphic plays were allamong the seven furthest outliers, as one wouldexpect.
In addition, King Edward III was 9th fur-thest.
King Henry VI (Part 1) was not found to bean outlier at all.
Curiously, however, three undis-puted plays by Shakespeare were found to begreater outliers than King Edward III.
These areThe Merry Wives of Windsor, The Comedy of Er-rors and The Tragedy of Julius Caesar.
The MerryWives of Windsor is a particularly distant outlier,even further out than Oldcastle and Pericles.
Weleave it to Shakespeare scholars to explain the rea-sons for these anomalies.7 ConclusionIn this paper we defined the problem of unsuper-vised outlier detection in the authorship verifica-tion domain.
Our method combines standardoutlier detection methods with a novel inter-document similarity measure.
This similaritymeasure is the output of the impostors method re-cently developed for solving the authorship verifi-cation problem.
We have found that use of thekNN method for outlier detection in conjunctionwith this second-order similarity measure stronglyoutperforms methods based on any outlier detec-tion method used in conjunction with any standardfirst-order similarity measures.
This improvementproves to be robust, holding for various corpus siz-es and various underlying base similarity measuresused in the second-order similarity measure.The method can be used to resolve historicalconundrums regarding the authenticity of works inquestioned corpora, such as the Shakespeare cor-pus briefly considered here.
This is currently thesubject of our ongoing research.ReferencesS.
M. Bendre and B. K. Kale.
1987.
Masking effecton tests for outliers in normal samples, Biome-trika, 74(4):891-896.Markus M. Breunig,  Hans-Peter Kriegel,Raymond T. Ng and J?rg Sander.
2000.
LOF:Identifying Density-Based Local Outliers, ACMSIGMOD Conference Proceedings.Varun Chandola, Arindam Banerjee and VipinKumar.
2009.
Anomaly detection: a survey.ACM Computing Surveys 41, 3, Article 15.David L. Donoho.
1982.
Breakdown properties ofmultivariate location estimators.
Ph.D.qualifying paper, Harvard University.Peter Filzmoser, Ricardo Maronna and MarkWerner.
2008.
Outlier identification in highdimensions.
Computational Statistics and DataAnalysis, 52:1694-1711.David Guthrie.
2008.
Unsupervised Detection ofAnomalous Text.
PhD Thesis, University ofSheffield.Frank E. Grubbs.
1969.
Procedures for detectingoutlying observations in samples,Technometrics.V.J.
Hodge and J. Austin.
2004.
A survey of outlierdetection methodologies.
Artificial.
IntelligenceReview, 22 (2).
pp.
85-126.1453Patrick Juola and Efstathios Stamatatos.
2013.Overview of the Author Identification Task atPAN 2013.
P. Forner, R. Navigli, and D. Tufis(eds) CLEF 2013 Evaluation Labs andWorkshop ?Working Notes Papers.Moshe Koppel and Jonathan Schler 2004.Authorship verification as a one-classclassification problem.
In ICML ?04: Twenty-first International Conference on MachineLearning, New York, NY, USA.Moshe Koppel, Jonathan Schler, and ShlomoArgamon.
2011.
Authorship attribution in thewild.
Language Resources and Evaluation,45(1): 83?94.Moshe Koppel M. and Yaron Winter.
2013.Determining If Two Documents Are by the SameAuthor.
J.
Am.
Soc.
Inf.
Sci.
Technol.Frederick Mosteller and David L. Wallace.
1964.Inference and Disputed Authorship: TheFederalist.
Reading, Mass.
Addison Wesley.Hans-Peter Kriegel, Matthias S. Schubert andArthur Zimek.
2008.
Angle-based outlierdetection in high dimensional data.
Proc.
KDD.Thomas C. Mendenhall.
1887.
The characteristiccurves of composition, Science 9, 237-259.Sridhar Ramaswamy, Rajeev Rastogi and KyuseokShim.
2000.
Efficient Algorithms for MiningOutliers from Large Data Sets.
Proc.
ACMSIDMOD Int.
Conf.
on Management of Data.Peter J. Rousseeuw.
1984.
Least median of squaresregression.
Journal of the American StatisticalAssociation, 79(388):87-880.Peter J. Rousseeuw and Annick M. Leroy.
2003.Robust Regression and Outlier Detection.
JohnWiley & Sons.J.
Schler, M. Koppel, S. Argamon and J.Pennebaker.
2006.
Effects of Age and Gender onBlogging.
in Proceedings of 2006 AAAI SpringSymposium on Computational Approaches forAnalyzing Weblogs.Werner A. Stahel.
1981.
Breakdown of covarianceestimators.
Research Report 31, Fachgruppe f?urStatistik, Swiss Federal Institute of Technology(ETH), Zurich.Efstathios Stamatatos.
2009.
Intrinsic plagiarismdetection using character n-gram profiles.Proceedings of the SEPLN?09 Workshop onUncovering Plagiarism, Authorship and SocialSoftware Misuse.
pp.
38?46.Benno Stein B, Nedim Lipka and PeterPrettenhofer.
2010.
Intrinsic PlagiarismAnalysis.
Language Resources and Evaluation,1?20.
2010.Benno Stein B, Nedim Lipka and PeterPrettenhofer.
2010.
Intrinsic PlagiarismAnalysis.
Language Resources and Evaluation,1?20.
2010.1454
