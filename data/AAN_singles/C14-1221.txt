Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 2345?2354, Dublin, Ireland, August 23-29 2014.A context-based model for Sentiment Analysis in TwitterAndrea Vanzo and Danilo Croce and Roberto BasiliDepartment of Enterprise EngineeringUniversity of Roma Tor VergataVia del Politecnico 1, 00133 Roma Italy{vanzo,croce,basili}@info.uniroma2.itAbstractMost of the recent literature on Sentiment Analysis over Twitter is tied to the idea that the senti-ment is a function of an incoming tweet.
However, tweets are filtered through streams of posts,so that a wider context, e.g.
a topic, is always available.
In this work, the contribution of thiscontextual information is investigated.
We modeled the polarity detection problem as a sequen-tial classification task over streams of tweets.
A Markovian formulation of the Support VectorMachine discriminative model as embodied by the SVMhmmalgorithm has been here employedto assign the sentiment polarity to entire sequences.
The experimental evaluation proves that se-quential tagging effectively embodies evidence about the contexts and is able to reach a relativeincrement in detection accuracy of around 20% in F1 measure.
These results are particularlyinteresting as the approach is flexible and does not require manually coded resources.1 IntroductionSince in the Web 2.0 users can write about their life, personal experiences, share contents about facts andideas, Social Networks became valuable sources of opinions and sentiments.
This huge amount of datais crucial in the study of the interactions and dynamics of subjectivity on the Web, largely relevant formarketing tasks.
Twitter is one among these microblogging services that counts about a billion of activeusers and 500 million of daily messages1.
However, the analysis of this huge amount of information isstill challenging, as language is very informal, affected by misspelling and characterized by slang and#hashtags, i.e.
special user-generated tags used to contextualize different tweets around a specific topic.Researches focused on the computational study and automatic recognition of opinions and sentimentsas they are expressed in free texts.
It gave rise to what is currently known as Sentiment Analysis, a setof tasks aiming to detect the subjective attitude of a writer with respect to some topic.
Many SentimentAnalysis studies map sentiment detection in a Machine Learning (ML) setting (Pang and Lee, 2008),where labeled data, i.e.
known examples, allow to induce the detection function from real world exam-ples.
In general, sentiment detection in tweets has been generally treated as any other text classificationtask, as proved by most papers participating to the Sentiment Analysis in Twitter task in SemEval-2013challenge (Nakov et al., 2013): a computational representation for an incoming instance is generated byjust considering one tweet at a time.
The short length of the message and the resulting semantic ambi-guity are critical limitations and make the task very complex.
Let us consider the following example, inwhich a tweet from ColMustard cites SergGray:ColMustard : @SergGray Yes, I totally agree with you about the substitutions!
#Bayern #FreiburgThe tweet sounds like to be a reply to the previous one.
Notice how no lexical nor syntactic propertyallows to determine the sentiment polarity.
However, if we look at the entire conversation that follows:ColMustard : Amazing match yesterday!
!#Bayern vs. #Freiburg 4-0 #easyvictorySergGray : @ColMustard Surely, but #Freiburg wasted lot of chances to score.. wrong substitutions by#Guardiola during the 2nd half!
!ColMustard : @SergGray Yes, I totally agree with you about the substitutions!
#Bayern #FreiburgThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1http://expandedramblings.com/2345it is easy to establish that a first positive tweet has been produced, followed by a second negative one sothat the third tweet is negative as well.
It is the conversation that allows us here to disambiguate even avery short message and properly characterize it according to its author and posting time.We want here to capitalize such a richer set of observations (i.e.
entire conversations) and to definea context-sensitive SA model along two lines: first, by enriching a tweet representation to include theconversation information, and then introducing a more complex classification model that works over anentire tweet sequence and not on one tweet (i.e.
the target) at a time.
Accordingly, in the paper we willfirst focus on different representations of tweets that can be made available to the sentiment detectionprocess.
They will also account for contexts, that are conversations, as chains of tweets that are replyto the previous ones, and topics, built around hashtags.
These are in fact topics made explicit by users,such as events (#easyvictory) or people (#Guardiola).
It represents a wider notion of conversation thatenforces the sense of belonging to a community.
From a computational perspective, the polarity detectionof a tweet in a context is here modeled as a sequential classification task.
In fact, both conversation andtopic-based context are arbitrarily long sequences of messages, ordered according to time with the targettweet being the last.
The SVMhmmlearning algorithm (Altun et al., 2003) has been employed, as itallows to classify an instance (here, a tweet) within an entire sequence.
While SVM based classifiersallow to recognize the sentiments from one specific tweet at a time, the SVMhmmlearning algorithmcollectively labels all tweets in a sequence.
It is thus expected to capture patterns within a conversationand apply them in novel sequences, through a standard decoding task.While all the above contexts extend a tweet representation, they are still local to a specific notionof conversation.
In this work, we also explore the somehow more abstract notion of contexts givenby the emotional attitude shown by each user in his overall usage of Twitter.
In the above example,ColMustard shows a specific attitude while discussing about the Bayern Munchen.
We can imaginethat this feature characterizes most of its future messages at least about football.
We suggest to enrichthe tweet representation with features that synthesize a user?s profile, in order to catch possible biasestowards a particular sentiment polarity.
This is quite interesting as it has been shown that communitiesbehave in a coherent way and users tend to take stable standing points.
Experimental evaluation (Chapter4) proves the effectiveness of this proposed sequential tagging approach combined with the adoptedcontextual information, improving the percentage of correctly recognized tweets up to 12%.A survey of the existing approaches is presented into Section 2.
Then, Section 3 provides an accountof the context-based models: conversation, topic-based and user sentiment profiling.
The experimentalevaluation into Section 4 prove the positive impact of social dynamics on the SA task.2 Related WorkSentiment Analysis has been described as a Natural Language Processing task at many levels of gran-ularity.
Starting from being mapped into a document level classification task (Turney, 2002; Pang andLee, 2004), it has been also applied at sentence level (Hu and Liu, 2004; Kim and Hovy, 2004) and morerecently at the phrase level (Wilson et al., 2005; Agarwal et al., 2009).The spreading of microblog services where users post real-time opinions about ?everything?, posesnewer and different challenges.
Indeed, classical approaches to Sentiment Analysis (Pang et al., 2002;Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively largetexts, e.g.
movie or product reviews, tweets are very short and fine-grained lexical analysis is required.Nevertheless, the great prominence of Social Media during the last few years encouraged a focus onthe sentiment detection over a microblogging domain.
Recent works tried to model the sentiment intweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifetand Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011; Si et al.,2013; Agarwal et al., 2011).
Specific approaches and feature modeling are used to improve accuracylevels in tweet polarity recognition.
For example, the use of n-grams, POS tags, polarity lexicons andtweet specific features (e.g.
hashtags, re-tweets) are some of the component exploited by these works, incombination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g.Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in (Barbosa and Feng,23462010; Agarwal et al., 2011; Castellucci et al., 2013), are mostly employed.
An interesting perspective,where a kind of contextual information is studied, is presented in (Mukherjee and Bhattacharyya, 2012):the sentiment detection of tweets is here modeled according to lexical features as well as discourserelations like the presence of connectives, conditionals and semantic operators like modals and negations.Nevertheless, in all the above approaches, features are derived only from lexical resources or from thetweet itself and no contextual information is exploited.
However, given one tweet targeted for sentimentdetection, more awareness about its content is available to writers and readers by the entire stream ofrelated posts immediately preceding it.
In order to exploit this wider information, a Markovian extensionof a Kernel-based categorization approach is proposed in the next section.3 A context based model for Sentiment Analysis in TwitterAs discussed in the introduction, contextual information about one tweet stems from various aspects: anexplicit conversation, the user attitude or the overall set of recent tweets about a topic (for example anhastag like #Bayern).
As individual perspectives on the context are independent (a conversation mayor may not depend on user preference or cheer) and they also obey to different notion of analogies orsimilarity, we should avoid a unified feature vector, but employ independent representations.
A structuredview on a tweet can thus be provided by considering it as multifaceted entity where a set of vectors, eachone contributing to one aspect of the overall representation, exhibits a specific similarity metrics.
Noticehow this is exactly what Kernel-based learning supports, whereas the combination of the different Kernelfunctions can be easily made a Kernel function itself (Shawe-Taylor and Cristianini, 2004).
Kernelfunctions are used to capture specific aspects of the semantic relatedness between two tweets and areeasily integrated in various Machine Learning algorithms, such as SVM.3.1 Representing tweets through different Kernel functionsMany Machine Learning approaches for Sentiment Analysis in Twitter benefited by complex ways ofmodeling of individual tweets, as discussed in many works (Nakov et al., 2013).
The representation wepropose makes use of individual Kernels as models of different aspects usable within a SVM paradigm.Bag of Word Kernel (BoWK).
The simplest Kernel function describes the lexical overlap betweentweets, thus represented as vectors, whose dimensions correspond to the different words.
Componentsdenote the presence or not of the corresponding word in the text and Kernel function corresponds tothe cosine similarity between vector pairs.
Even if very simple, the BoW model is one of the mostinformative representation in Sentiment Analysis, as emphasized since (Pang et al., 2002).Lexical Semantic Kernel (LSK).
Lexical information in tweets can be very sparse, as we will alsoshow in the next Section 4.
In order to extend the BoW model, we provide a further vector representationaiming to generalize the lexical information.
It can be obtained for every term of a dictionary by aco-occurrence Word Space built according to the Distributional Analysis described in (Sahlgren, 2006).A word-by-context matrix, M , is built through large scale corpus analysis and then processed throughLatent Semantic Analysis (Landauer and Dumais, 1997).
The dimensionality of the space represented byM can be reduced through Singular Value Decomposition (SVD) (Golub and Kahan, 1965).
The originalstatistical information about M is captured by the new k-dimensional space, which preserves the globalstructure while removing low-variance dimensions, i.e.
distribution noise.
The result is that every wordis projected in the reduced Word Space and a vector for each tweet is represented through the linearcombination of the co-occurring word vectors (also called additive linear combination in (Mitchell andLapata, 2010)).
The resulting Kernel function is the cosine similarity between tweet vector pairs, in linewith (Cristianini et al., 2002).
Notice that the adoption of a distributional approach does not limit theoverall application, as it can be automatically applied without relying on any manually coded resource.User Sentiment Profile Context (USPK).
A source of evidence about a tweet is its author, with hisattitude towards some polarities.
Specific features based on the users?
previous tweets can be derived asfollows.
Let ti?
T be a tweet and i ?
N+its identifier.
The User Profile Context (Ui) can be defined asthe set of the lastH tweets posted by the author of ti, hereafter denoted by ui.
This information is a bodyof evidence about the opinion holder?s profile on which a further tweet representation can be defined.
Atweet tiis here mapped into a three dimensional vector ~?i=(?1i, ?2i, ?3i), where each component ?jiis2347the indicator of polarity inclination, i.e.
positive, negative and neutral, expressed through the conditionalprobability P (j | ui) for the polarity labels j ?
Y given the user ui.
We can suppose that, for eachtk?
Ui, its corresponding label ykis available either as a gold standard annotation or predicted in a semi-supervised fashion by trained classifiers.
The estimation of ?ji?
P (j | ui), is a ?-parameterized Laplacesmoothed version of the observations in Ui: ?ji=?|Ui|k=1(1{yk=j}(tk) + ?
)/(|Ui|+ ?|Y|) where ?
?
Ris the smoothing parameter, j ?
Y , i.e.
the set of polarity labels.
The Kernel function, called UserSentiment Profile Kernel (USPK), is the cosine similarity between two vectors (~?i, ~?m).The multiple Kernel approach.
Whenever the different Kernels are available, we can apply a lin-ear combination ?BoWK+?LSK or ?BoWK+?LSK+?USPK in order to exploit lexical and semanticproperties captured by BoWK and LSK, or user properties as captured by USPK.3.2 Modeling tweet conversation as a sequential tagging problemThe User Sentiment Profile Kernel (UPSK) can be seen as an implicit representation of a context de-scribing the writer.
However, contextual information is usually embodied by the stream of tweets inwhich the target one tiis immersed.
Usually, the stream is something available to a reader and includesan entire conversation (where links to the previous tweets are made explicit and are supposed to be allavailable) or a topic, i.e.
a hashtag, the reader has searched for.
In all cases, the stream give rise to anentire sequence on which sequence labeling can be applied: the target tweet is here always labeled withinthe entire sequence, where contextual constraints are provided by the preceding tweets.
More formally,two types of context are defined:Conversational context.
For every tweet ti?
T , let r(ti) : T ?
T be a function that returns eitherthe tweet to which tiis a reply to, or null if tiis not a reply.
Then, the conversation-based context ?C,liof tweet ti(i.e., the target tweet) is the sequence of tweet iteratively built by applying r(?
), until l tweetshave been selected or r(?)
= null.
In other words, l allows to limit the size of the input context.
Anexample of conversation-based context is given in Section 1.Topical context.
Hashtags allow to aggregate different tweets around a specific topic.
An entire tweetsequence can be derived including the n tweets preceding the target tithat contain the same hashtag set.This is usually the output of a search in Twitter and it is likely the source information that influencedthe writer?s opinion.
Let ti?
T be a tweet and h(i) : T ?
P(H) be a function that returns the entirehashtag set Hi?
H observed into ti.
Then, the hashtag-based context ?H,lifor a tweet ti(i.e., targettweet) is a sequence of the most recent l tweets tjsuch that Hj?Hi6= ?, i.e.
tjand tishare at least onehashtag, and tjhas been posted before ti.
As an example, the following hashtag-based context of size 4has been obtained about #Bayern:MrGreen : Fun fact: #Freiburg is the only #Bundesliga team #Pep has never beaten in his coaching career.
#BayernMrsPeacock : Young starlet Xherdan #Shaqiri fires #Bayern into a 2-0 lead.
Is there any hope for #Freiburg?pic.twitter.com/krzbFJFJyNProfPlum : It is clear that #Bayern is on a rampage leading by 4-0, the latest by Mandzukic... hoping foranother 2 goals from #bayernmunichMissScarlet : Noooo!
I cant believe what #Bayern did!It is clear that MissScarlet expressed an opinion, but the corresponding polarity is easily evidentwhen the entire stream is available about the #Bayern hashtag.
As well as in a conversational context,a specific context size n can be imposed by focusing only on the last n tweets of the sequence.
Oncedifferent representations and contexts are available a structured learning-based approach can be appliedto Sentiment Analysis.
Firstly, we will discuss a discriminative learning approach that follows the multi-classification schema proposed in (Joachims et al., 2009), namely SVMmulticlass.
Then a sequencelabeling approach, based on the SVMhmmlearning algorithm (Altun et al., 2003), will be introduced, asan explicit account of both conversational and topical contexts.The multi-class approach.
The SVMmulticlassschema described in (Joachims et al., 2009) is applied2to implicitly compare all polarity labels and select the most likely one, using the multi-class formulationdescribed in (Crammer and Singer, 2001).
The algorithm thus acquires a specific function fy(x) for2http://svmlight.joachims.org/svm multiclass.html2348each sentiment polarity label y ?
Y , where Y = {positive, negative, neutral}.
Given a feature vectorx ?
X representing a tweet ti, SVMmulticlassallows to predict a specific polarity y??
Y by applying thediscriminant function y?= arg maxy?Yfy(xi), where fy(x) = wy?
x is a linear classifier associated toeach label y.
Given a training set (x1, y1) .
.
.
(xn, yn), the learning algorithm determines each classifierparameters wyby solving the following optimization problem:min12?i=1...k?wi?2+Cn?i=1...n?is.t.
?i,?y ?
Y : xi?
wyi?
xi?
wy+ 100?
(yi, y)?
?iwhere C is a regularization parameter that trades off margin size and training error, while ?
(yi, y) is theloss function that returns 0 if yiequals y, and 1 otherwise.The markovian approach.
The sentiment prediction of a target tweet can be seen as a sequentialclassification task over a context, and the SVMhmmalgorithm can be thus applied.
Given an inputsequence x = (x1.
.
.
xl) ?
X , where x is a tweet context, e.g.
the conversational and the hashtag-basedone (i.e.
?C,liand ?H,li, respectively) and xiis a feature vector representing a tweet, the model predictsa tag sequence y = (y1.
.
.
yl) ?
Y+after learning a linear discriminant function F : P(X )?
Y+?
Rover input/output pairs.
The labeling f(x) is thus defined as: f(x) = arg maxy?Y+F (x,y;w).
It isobtained by maximizing F over the response variable, y, for a specific given input, x.
In these models,F is linear in some combined feature representation of inputs and outputs ?
(x,y), i.e.
F (x,y;w) =?w,?(x,y)?.
As ?
extracts meaningful properties from an observation/label sequence pair (x,y), inSVMhmmit is modeled through two types of features: interactions between attributes of the observationvectors xiand a specific label yi(i.e.
emissions of xiby yi) as well as interactions between neighboringlabels yialong the chain (transitions).
In other words, ?
is defined so that the complete labeling y =f(x) can be computed efficiently from F , using a Viterbi-like decoding algorithm, according to the lineardiscriminant functiony?= arg maxy?Y+{?i=1...l[?j=1...k(xi?
wyi?j... yi) + ?tr(yi?j, .
.
.
, yi) ?
wtr]}In the training phase, SVMhmmsolves the following optimization problem given training examples(x1,y1) .
.
.
(xn,yn) of sequences of feature vectors xjwith their correct tag sequences yjmin12?w?2+Cn?i=1...n?is.t.
?y, n : {?i=1...l(xni?
wyni) + ?tr(yni?1, yni) ?
wtr} ?
{?i=1...l(xni?
wyi) + ?tr(yi?1, yi) ?
wtr}+ ?
(yn, y)where ?
(yn, y) is the loss function, computed as the number of misclassified tags in the sequence,(xi?
wyi) represents the emissions and ?tr(yi?1, yi) the transitions.
Indeed, through SVMhmmlearningthe label for the target tweet is made dependent on its context history.
The markovian setting thusacquires patterns across tweet sequences to recognize sentiment even for truly ambiguous tweets.4 Experimental EvaluationThe aim of the experiments is to estimate the contribution of the proposed contextual models to theaccuracy reachable in different scenarios, whereas rich contexts (e.g.
popular hashtags) are possiblymade available or just singleton tweets, with no context, are targeted.We adopted the ?Sentiment Analysis in Twitter?
dataset3as it has been made available in the ACLSemEval-2013 (Nakov et al., 2013).
However, in order to rely on tweet identifiers (needed to retrievecontexts from Twitter servers), only the Training and Development portions of the data (11,338 exam-ples), for which id?s were made available, have been employed.
As about 10,045 tweets were availablefrom the servers,4a static split 80/10/10 in Training/Held-out/Test respectively, has been carried out asreported in Table 1.
As the performance evaluation is always carried out against one target tweet (inanalogy with the benchmark of SemEval-2013), the multi-classification may happen when no context isavailable (i.e.
there is no conversation nor hashtag to built the context from) or when a rich conversa-tional or topical context is available.
In Table 1 different datasets are shown in columns 2-4, 5-7 and 8-103http://www.cs.york.ac.uk/semeval-2013/task2/index.php?id=data4Several original messages were no longer reachable during the experiment time of March-June 20132349respectively: the entire corpus of 10,045 is represented in columns 2-4, while 5-7 and 8-10 representsthe subsets of target tweets for which a conversational or topical context, respectively, was available.Conversational contexts are available only for 1,391 tweets (columns 5-7), while hashtag-based contextsinclude 1,912 instances (columns 8-10).whole dataset conversation-filtered hashtag-filteredtrain dev test train dev test train dev testPositive 2984 359 387 454 51 56 621 83 66Negative 1271 147 142 197 31 24 245 28 22Neutral 3790 495 470 455 68 55 688 79 808045 1001 999 1106 150 135 1554 190 168Table 1: Whole dataset compositionAs tweets are noisy texts, a pre-processing phase has been applied to improve the quality of linguisticfeatures observable and reduce data sparseness.
In particular, a normalization step is applied to eachpost: fully capitalized words are converted in lowercase; reply marks are replaced with the pseudo-tokenUSER, hyperlinks by LINK, hashtags by HASHTAG and emoticons by special tokens5.
Afterwards, analmost standard NLP chain is applied through the Chaos parser (Basili et al., 1998; Basili and Zanzotto,2002).
In particular, each tweet, with its pseudo-tokens produced by the normalization step, is mappedinto a sequence of POS tagged lemmas.
Emoticons are treated as nouns.
In order to feed the LSK, lexicalvectors correspond to a Word Space derived from a corpus of about 1.5 million tweets, downloadedduring the experimental period and using the topic names from the trial material as query terms.
Everyword w in such corpus is represented as one co-occurrence vector as in (Sahlgren, 2006) with the settingdiscussed in (Croce and Previtali, 2010): left and right co-occurrence scores are obtained in a window ofsize n = ?5 around each w. Vector components wfcorrespond to Pointwise Mutual Information valuespmi(w, f) between the word w (the row) and the feature f .
Dimensionality reduction is applied to theco-occurrence matrix, through SVD, with a dimensionality cut of k = 250.Existing state-of-the-art approaches neglect the tweet context, so that datasets with labeled contextsare not available: USPK or the markovian approach would not be applicable.
The solution consistedin creating a semi-supervised Gold-Standard by training the multi-class classifier (not employing anycontext) fed through a combination of BoWK and LSK Kernel functions and get the classification of alltweets within the context of at least one target tweet.
Unfortunately, this can introduce noise, but it is arealistic solution to a cold-start approach, easily portable to other datasets.Performance scores report the classification accuracy in terms of Precision, Recall and standard F-measure.
However, in line with SemEval-2013, we also report the Fpnn1score as the arithmetic meanbetween the F1s of positive, negative and neutral classes.4.1 Experiment 1: Using contexts in a general tweet classification settingA first experiment has been run to validate the impact of contextual information over generic tweets,independently from the availability of the context.
In this case, the entire data set is used.
The differentsettings adopted are reported in independent rows, corresponding to different classification approaches:?
multi-class refers to the application of the multi-classification of SVMmulticlass, that does not requireany context and can be considered as a baseline for the employed Kernel combinations;?
conversation refers to the SVMhmmclassifier observing the conversation-based contexts.
The train-ing and testing of the classifier is here run with different context sizes, by parameterizing l in ?C,li;?
likewise, hashtag refers to the SVMhmmclassifier observing the topic-based contexts, when hash-tags are considered.
Different context sizes have been considered, by parameterizing l in ?H,li.In both conversation and hashtag models, when no context is available, the SVMhmmclassifier acts ona sequence of length one, and no transition is used.
Table 2 shows the empirical results over the wholetest dataset.
The first general outcome is that algorithmic baselines, i.e.
context-free models that useno contextual information, in the multi-class rows are better performing whenever richer representationsare provided.
The LSA information (+8.29%) as well as the user profiling (+10.73%) seem beneficial in5We normalized 113 well-known emoticons in 13 classes.2350Context size Precision Recall F1Fpnn1l pos neg neu pos neg neu pos neg neuBoWKmulti-class - .713 .496 .680 .649 .401 .770 .679 .444 .723 .615 ( - )conversation3 .761 .493 .695 .651 .465 .789 .702 .478 .739 .640 (+4.07%)6 .728 .500 .718 .677 .479 .768 .701 .489 .742 .644 (+4.72%)?
.723 .511 .722 .695 .472 .762 .709 .491 .741 .647 (+5.20%)hashtag3 .766 .533 .675 .633 .401 .821 .693 .458 .741 .631 (+2.60%)6 .727 .575 .711 .682 .514 .770 .704 .543 .740 .662 (+7.64%)16 .717 .561 .730 .693 .549 .755 .704 .555 .743 .667 (+8.46%)31 .717 .533 .738 .705 .570 .732 .711 .551 .735 .666 (+8.29%)BoWK+LSKmulti-class - .754 .595 .704 .674 .486 .804 .712 .535 .751 .666 ( - )conversation3 .759 .595 .712 .682 .486 .811 .718 .535 .758 .670 (+0.60%)6 .760 .536 .737 .713 .521 .781 .736 .529 .758 .674 (+1.20%)?
.774 .554 .717 .682 .542 .791 .725 .548 .752 .675 (+1.35%)hashtag3 .731 .541 .737 .729 .556 .732 .730 .549 .734 .671 (+0.75%)6 .770 .580 .736 .700 .585 .789 .733 .582 .762 .693 (+4.05%)16 .742 .519 .732 .693 .570 .751 .717 .544 .742 .667 (+0.15%)31 .751 .537 .729 .685 .556 .774 .716 .547 .751 .671 (+0.75%)BoWK+LSK+USPKmulti-class - .778 .612 .716 .680 .500 .830 .726 .550 .768 .681 ( - )conversation3 .771 .563 .689 .625 .507 .817 .690 .533 .748 .657 (-3.67%)6 .753 .654 .707 .693 .493 .806 .721 .562 .753 .679 (-0.29%)?
.767 .566 .713 .690 .514 .791 .727 .539 .750 .672 (-1.32%)hashtag3 .753 .556 .735 .693 .599 .766 .721 .576 .750 .683 (+0.29%)6 .747 .594 .735 .711 .556 .779 .728 .575 .756 .686 (+0.73%)16 .742 .519 .742 .700 .592 .745 .721 .553 .743 .672 (-1.32%)31 .738 .530 .739 .693 .556 .766 .715 .543 .752 .670 (-1.62%)Table 2: Evaluation results on whole dataset.their relative improvements with respect to the simple BoW Kernel accuracy.
Second, almost all context-driven models (i.e.
SVMhmmoperating on different context sizes) improve wrt their SVMmulticlasscoun-terpart.
Every polarity category benefits from the introduction of contexts, although this is particularlytrue for the negative (neg) case, where a 15.5% of the entire dataset examples are available: it seemsclear that contexts allow to compensate against poor training conditions.4.2 Experiment 2: Measuring the full impact of context-based models over rich contextsGiven the above outcomes, a second set of experiments has been run against the subset of the test datarestricted to tweets for which rich contexts are available, as introduced in Table 1.
In Figure 1, the per-formances of different learning paradigms and Kernels trained and tested over these corpora are shown.On the Left of the figure, the performance over the conversation-filtered corpus (Table 1) are reported:these tweets are characterized by rich conversational contexts of different increasing sizes on the X-axis.On the Right of Figure 1, the corresponding performances obtained over the hashtag-filtered corpusare reported.
As the number of available examples in both test corpora is much smaller, the baselinescorresponding to the SVMmulticlassapproach are lower.On the contrary, such poorer training evidence does not seem to afflict the contextual models in bothcorpora, as the markovian modeling seems to bring a straight benefit.
In particular, increasing amount ofcontextual information is usually beneficial to accuracy scores.
In general, the SVMhmmaccuracy plotsseem to increase up to a given context size, that is around 6 for conversational contexts vs. 16 previoustweets for topical contexts.
It seems that a wider context (i.e.
a window of 8 or 10 tweets) is not sobeneficial, as the generalization emphasized by LSK and USPK tends to diverge.
Different genres ofdiscussions seem to provide different useful contexts for sentiment detection.
The overall benefit reach-able by SVMhmmrelatively to the SVMmulticlassbaseline is striking as only rich contexts are used fortraining and testing.
The BoW Kernel over the conversation corpus has an overall relative improvementof 18.26% in Fpnn1, where the richer BoWK+LSK Kernel improves of about 5.94%.
Boosts in Fpnn1over topical contexts are more significant: 23.73% for the BoW Kernel vs. 17.93% for BoWK+LSK.This latter Kernel is optimal, suggesting that user profiling requires possibly a richer description that isnot entirely captured by the vectors of the user sentiment profile.
In fact USPK, when combined with23510,500,550,600,650,700 2 4 6 8 10 SVMmulti (BOWK) SVM-HMM (BOWK) SVMmulti (BOWK+LSK) SVM-HMM (BOWK+LSK) SVMmulti (BOWK+LSK+USPK) SVM-HMM (BOWK+LSK+USPK)0,500,550,600,650,700 5 10 15 20 25 30 SVMmulti (BOWK) SVM-HMM (BOWK) SVMmulti (BOWK+LSK) SVM-HMM (BOWK+LSK) SVMmulti (BOWK+LSK+USPK) SVM-HMM (BOWK+LSK+USPK)Figure 1: The Fpnn1measure of the different classifiers vs. different context sizes.
On the Left: perfor-mances when conversational contexts are employed.
On the Right: topical contexts are adopted.BOWK+LSK into the markovian approach, seems to not provide any useful contribution.
A clash be-tween the global information (as modeled by the USPK) and the local information (embedded in therecent tweets about a topic) is here observed: when these enter in an opposition, the contrast penalizesthe accuracy of the linear combination of Kernels.
In general, the improvements implied by contextualinformation are related to the treatment of particularly ambiguous tweets.
In a conversation, such asMrGreen : Cannot wait to meet @therealjuicyj and @RealWizKhalifa with @Hill GonzzNovember 29th #trippyniqqas (positive)ColMustard : @MrGreen where they gone be??
(neutral)MrGreen : @ColMustard New Orleans!!!
(positive)ColMustard : @MrGreen house of blues?
(neutral)MrGreen : @ColMustard no it?s at the UNO lakefront arena (neutral)ColMustard : @MrGreen I?m going Tuesday to the house of blues to see ASAP Rocky (neutral)the switch to a neutral mode characterizing the target tweet is a consequence of the entire sequence andcaptured as a pattern.
The contribution of the topical contexts is finally evident in the following example:... ... ... ... ... ...ProfPlum : Can?t wait to get out there with my boys Go Team!
#goeagles (positive)MrsPeacock : GO my awesome team @WestCoastEagles!!!!!
#goeagles #weflyhigh :D (positive)MissScarlet : Let?s go eagles :) #goeagles (positive)SergGray : keen for the eagles game today.
#goeagles (positive)5 ConclusionsIn this work the role of contextual information in supervised Sentiment Analysis over Twitter is investi-gated.
While the task is eminently linguistic, as resources and phenomena lie in the textual domain, othersemantic dimensions are worth to be explored.
In this work, three types of context for a target tweet havebeen studied.
Structured Learning through a markovian approach has been adopted to inject contextualevidence (e.g.
the history of preceding posts) in the classification of the most recent, i.e.
a target, tweet.The improvement of accuracy in the investigated task are striking as for the large applicability of theapproach that does not require additional manually coded resources.
The different employed contextsshow specific but systematic benefits.
On the one side, this proofs the correctness of the initial intuitions.Moreover, the observed relative improvements around 20% over tweets characterized by rich topical orconversational contexts (see Fig.
1) suggest that larger training datasets can even provide better results.In these first experiments, user modeling has only been partially explored, whereas the USPK modeldoes not seem very effective.
In fact, USPK seems to express a more static notion of context (i.e.
theattitude of the user as observed across a longer period than individual conversations) and two differentnotions (i.e.
information embedded into recent tweets) risk to be incompatible.
However, the learning ofthe optimal Kernel combination as well as a proper history size for the USPK are still worth of deeperinvestigation.
Finally, user interaction dynamics are particularly complex in social networks and deservebetter representations about reputation, authority and influence in future explorations.2352ReferencesApoorv Agarwal, Fadi Biadsy, and Kathleen R. Mckeown.
2009.
Contextual phrase-level polarity analysis usinglexical affect scoring and syntactic n-grams.
In Proceedings of the 12th Conference of the European Chapterof the Association for Computational Linguistics, EACL ?09, pages 24?32, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau.
2011.
Sentiment analysis oftwitter data.
In Proceedings of the Workshop on Languages in Social Media, LSM ?11, pages 30?38, Strouds-burg, PA, USA.
Association for Computational Linguistics.Y.
Altun, I. Tsochantaridis, and T. Hofmann.
2003.
Hidden Markov support vector machines.
In Proceedings ofthe International Conference on Machine Learning.Luciano Barbosa and Junlan Feng.
2010.
Robust sentiment detection on twitter from biased and noisy data.
InChu-Ren Huang and Dan Jurafsky, editors, COLING (Posters), pages 36?44.
Chinese Information ProcessingSociety of China.Roberto Basili and Fabio Massimo Zanzotto.
2002.
Parsing engineering and empirical robustness.
Nat.
Lang.Eng., 8(3):97?120, June.Roberto Basili, Maria Teresa Pazienza, and Fabio Massimo Zanzotto.
1998.
Efficient parsing for informationextraction.
In Proc.
of the European Conference on Artificial Intelligence, pages 135?139.Albert Bifet and Eibe Frank.
2010.
Sentiment knowledge discovery in twitter streaming data.
In Proceedingsof the 13th International Conference on Discovery Science, DS?10, pages 1?15, Berlin, Heidelberg.
Springer-Verlag.Giuseppe Castellucci, Simone Filice, Danilo Croce, and Roberto Basili.
2013.
Unitor: Combining syntactic andsemantic kernels for twitter sentiment analysis.
In Second Joint Conference on Lexical and ComputationalSemantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation(SemEval 2013), pages 369?374, Atlanta, Georgia, USA, June.
Association for Computational Linguistics.K.
Crammer and Y.
Singer.
2001.
On the algorithmic implementation of multi-class svms.
Journal of MachineLearning Research, 2:265?292.Nello Cristianini, John Shawe-Taylor, and Huma Lodhi.
2002.
Latent semantic kernels.
J. Intell.
Inf.
Syst.,18(2-3):127?152, March.Danilo Croce and Roberto Basili.
2012.
Grammatical feature engineering for fine-grained ir tasks.
In GiambattistaAmati, Claudio Carpineto, and Giovanni Semeraro, editors, IIR, volume 835 of CEUR Workshop Proceedings,pages 133?143.
CEUR-WS.org.Danilo Croce and Daniele Previtali.
2010.
Manifold learning for the semi-supervised induction of framenet pred-icates: An empirical investigation.
In Proceedings of the 2010 Workshop on GEometrical Models of NaturalLanguage Semantics, GEMS ?10, pages 7?16, Stroudsburg, PA, USA.
Association for Computational Linguis-tics.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.
Enhanced sentiment learning using twitter hashtags andsmileys.
In Chu-Ren Huang and Dan Jurafsky, editors, COLING (Posters), pages 241?249.
Chinese InformationProcessing Society of China.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twitter sentiment classification using distant supervision.
Pro-cessing, pages 1?6.G.
Golub and W. Kahan.
1965.
Calculating the singular values and pseudo-inverse of a matrix.
Journal of theSociety for Industrial and Applied Mathematics, 2(2).Minqing Hu and Bing Liu.
2004.
Mining and summarizing customer reviews.
In Proceedings of the Tenth ACMSIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ?04, pages 168?177, NewYork, NY, USA.
ACM.Thorsten Joachims, Thomas Finley, and Chun-Nam Yu.
2009.
Cutting-plane training of structural SVMs.
MachineLearning, 77(1):27?59.Soo-Min Kim and Eduard Hovy.
2004.
Determining the sentiment of opinions.
In Proceedings of the 20thInternational Conference on Computational Linguistics, COLING ?04, Stroudsburg, PA, USA.
Association forComputational Linguistics.2353Efthymios Kouloumpis, Theresa Wilson, and Johanna Moore.
2011.
Twitter sentiment analysis: The good thebad and the omg!
In Lada A. Adamic, Ricardo A. Baeza-Yates, and Scott Counts, editors, ICWSM.
The AAAIPress.T.
Landauer and S. Dumais.
1997.
A solution to plato?s problem: The latent semantic analysis theory of acquisi-tion, induction and representation of knowledge.
Psychological Review, 104(2):211?240.Jeff Mitchell and Mirella Lapata.
2010.
Composition in distributional models of semantics.
Cognitive Science,34(8):1388?1429.Subhabrata Mukherjee and Pushpak Bhattacharyya.
2012.
Sentiment analysis in twitter with lightweight discourseanalysis.
In Proceedings of COLING, pages 1847?1864.Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva, Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013.Semeval-2013 task 2: Sentiment analysis in twitter.
In Second Joint Conference on Lexical and ComputationalSemantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation(SemEval 2013), pages 312?320, Atlanta, Georgia, USA, June.
Association for Computational Linguistics.Alexander Pak and Patrick Paroubek.
2010.
Twitter as a corpus for sentiment analysis and opinion mining.In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC?10),Valletta, Malta, May.
European Language Resources Association (ELRA).Bo Pang and Lillian Lee.
2004.
A sentimental education: Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In Proceedings of the 42Nd Annual Meeting on Association for Computational Lin-guistics, ACL ?04, Stroudsburg, PA, USA.
Association for Computational Linguistics.Bo Pang and Lillian Lee.
2008.
Opinion mining and sentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135,January.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002.
Thumbs up?
sentiment classification using machinelearning techniques.
In Proceedings of EMNLP, pages 79?86.Magnus Sahlgren.
2006.
The Word-Space Model.
Ph.D. thesis, Stockholm University.John Shawe-Taylor and Nello Cristianini.
2004.
Kernel Methods for Pattern Analysis.
Cambridge UniversityPress, New York, NY, USA.Jianfeng Si, Arjun Mukherjee, Bing Liu, Qing Li, Huayi Li, and Xiaotie Deng.
2013.
Exploiting topic basedtwitter sentiment for stock prediction.
In ACL (2), pages 24?29.Peter D. Turney.
2002.
Thumbs up or thumbs down?
: Semantic orientation applied to unsupervised classificationof reviews.
In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ?02,pages 417?424, Stroudsburg, PA, USA.
Association for Computational Linguistics.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005.
Recognizing contextual polarity in phrase-level senti-ment analysis.
In Proceedings of the Conference on Human Language Technology and Empirical Methods inNatural Language Processing, HLT ?05, pages 347?354, Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Fabio M. Zanzotto, Marco Pennaccchiotti, and Kostas Tsioutsiouliklis.
2011.
Linguistic Redundancy in Twitter.In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 659?669,Edinburgh, Scotland, UK., July.
Association for Computational Linguistics.2354
