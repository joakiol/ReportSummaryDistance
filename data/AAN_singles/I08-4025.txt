Training a Perceptron with Global and Local Featuresfor Chinese Word SegmentationDong Song and Anoop SarkarSchool of Computing Science, Simon Fraser UniversityBurnaby, BC, Canada V5A1S6{dsong,anoop}@cs.sfu.caAbstractThis paper proposes the use of global fea-tures for Chinese word segmentation.
Theseglobal features are combined with local fea-tures using the averaged perceptron algo-rithm over N-best candidate word segmenta-tions.
The N-best candidates are producedusing a conditional random field (CRF)character-based tagger for word segmenta-tion.
Our experiments show that by addingglobal features, performance is significantlyimproved compared to the character-basedCRF tagger.
Performance is also improvedcompared to using only local features.
Oursystem obtains an F-score of 0.9355 on theCityU corpus, 0.9263 on the CKIP corpus,0.9512 on the SXU corpus, 0.9296 on theNCC corpus and 0.9501 on the CTB cor-pus.
All results are for the closed track inthe fourth SIGHAN Chinese Word Segmen-tation Bakeoff.1 IntroductionMost natural language processing tasks require thatthe input be tokenized into individual words.
Forsome languages, including Chinese, this is challeng-ing since the sentence is typically written as a stringof characters without spaces between words.
Wordsegmentation is the task of recovering the most plau-sible grouping of characters into words.
In this pa-per, we describe the system we developed for thefourth SIGHAN Chinese Word Segmentation Bake-off1.
We test our system in the closed track2 for allfive corpora: Academia Sinica (CKIP), City Uni-versity of Hong Kong (CityU), National Chinese1Further details at: www.china-language.gov.cn/bakeoff08/bakeoff-08 basic.html2We do not use any extra annotation, especially for punctu-ation, dates, numbers or English letters.Corpus (NCC), University of Colorado (CTB), andShanxi University (SXU).2 System DescriptionThe architecture of our system is shown in Figure 1.For each of the training corpora in the bakeoff, weproduce a 10-fold split: in each fold, 90% of the cor-pus is used for training and 10% is used to producean N-best list of candidates.
The N-best list is pro-duced using a character-based conditional randomfield (CRF) (Lafferty et al, 2001; Kudo et al, 2004)tagger.
The true segmentation can now be comparedwith the N-best list in order to train an averaged per-ceptron algorithm (Collins, 2002a).
This system isthen used to predict the best word segmentation froman N-best list for each sentence in the test data.Training CorpusWeight VectorN?best CandidatesTraining WithDecoding WithConditional RandomN?best CandidatesFieldLocal Features Global FeaturesAverage Perceptron Input SentenceAverage PerceptronOutputConditional RandomField(10?Fold Split)Figure 1: Outline of the segmentation process2.1 Learning AlgorithmGiven an unsegmented sentence x, the word seg-mentation problem can be defined as finding the143Sixth SIGHAN Workshop on Chinese Language Processingmost probable segmentation F (x) from a set of pos-sible segmentations of x.F (x) = argmaxy?GEN(x)?
(x, y) ?
w (1)The set of possible segmentations is given byGEN(x) and the na?
?ve method is to first generate allpossible segmented candidates.
For a long sentence,generating those candidates and picking the one withthe highest score is time consuming.In our approach, N-best candidates for each train-ing example are produced with the CRF++ soft-ware (Kudo et al, 2004).
The CRF is used as a tag-ger that tags each character with the following tags:for each multi-character word, its first character isgiven a B (Beginning) tag , its last character is as-signed an E (End) tag, while each of its remainingcharacters is provided an M (Middle) tag.
In addi-tion, for a single-character word, S (Single) is usedas its tag3.
Let c0 be the current character, c?1, c?2are the two preceding characters, and c1, c2 are thetwo characters to the right .
Using this notation, thefeatures used in our CRF models are: c0, c?1, c1,c?2, c2, c?1c0, c0c1, c?1c1, c?2c?1 and c0c2.We use the now standard method for producing N-best candidates in order to train our re-ranker whichuses global and local features: 10-folds of trainingdata are used to train the tagger on 90% of the dataand then produce N-best lists for the remaining 10%.This process gives us an N-best candidate list foreach sentence and the candidate that is most similarto the true segmentation, called yb.
We map a seg-mentation y to features associated with the segmen-tation using the mapping ?(?).
The score of a seg-mentation y is provided by the dot-product ?
(y) ?w.The perceptron algorithm (Fig.
2) finds the weightparameter vector w using online updates.
The pre-dicted segmentation y?i based on the current weightvector is compared to the the best candidate yb, andwhenever there is a mismatch, the algorithm updatesthe parameter vector by incrementing the parame-ter value for features in yb, and by decrementing thevalue for features in y?i.The voted perceptron (Freund and Schapire,1999) has considerable advantages over the standard3Note that performance of the CRF tagger could be im-proved with the use of other tagsets.
However, this does notaffect our comparative experiments in this paper.Inputs: Training Data ?
(x1, y1), .
.
.
, (xm, ym)?Initialization: Set w = 0Algorithm:for t = 1, .
.
.
, T dofor i = 1, .
.
.
,m doCalculate y?i, wherey?i = argmaxy?N-best Candidates?
(y) ?
wif y?i 6= yb thenw = w +?
(yb) ?
?
(y?i)end ifend forend forFigure 2: Training using a perceptron algorithm overN-best candidates.perceptron.
However, due to the computational is-sues with the voted perceptron, the averaged per-ceptron algorithm (Collins, 2002a) is used instead.Rather than using w, we use the averaged weightparameter ?
over the m training examples for futurepredictions on unseen data:?
=1mT?i=1..m,t=1..Twi,tIn calculating ?, an accumulating parameter vec-tor ?i,t is maintained and updated using w for eachtraining example; therefore, ?i,t =?wi,t.
Afterthe last iteration, ?i,t/mT produces the final para-meter vector ?.When the number of features is large, it is timeconsuming to calculate the total parameter ?i,t foreach training example.
To reduce the time complex-ity, we adapted the lazy update proposed in (Collins,2002b), which was also used in (Zhang and Clark,2007).
After processing each training sentence, notall dimensions of ?i,t are updated.
Instead, an up-date vector ?
is used to store the exact location (i, t)where each dimension of the averaged parametervector was last updated, and only those dimensionscorresponding to features appearing in the currentsentence are updated.
While for the last example inthe last iteration, each dimension of ?
is updated, nomatter whether the candidate output is correct.2.2 Feature TemplatesThe feature templates used in our system includeboth local features and global features.
For local fea-tures, we consider twomajor categories: word-based144Sixth SIGHAN Workshop on Chinese Language Processingfeatures and character-based features.
Five specifictypes of features from (Zhang and Clark, 2007) thatare shown in Table 1 were used in our system.
In ourinitial experiments, the other features used in (Zhangand Clark, 2007) did not improve performance andso we do not include them in our system.1 word w2 word bigram w1w23 single character word w4 space-separated characters c1 and c25 character bi-gram c1c2 in any wordTable 1: local feature templates.
Rows 1, 2 and 3are word-based and rows 4 and 5 are character-basedfeaturesIn our system, we also used two types of globalfeatures per sentence (see Table 2).
By global, wemean features over the entire segmented sentence.46 sentence confidence score7 sentence language model scoreTable 2: global feature templateThe sentence confidence score is calculated byCRF++ during the production of the N-best candi-date list, and it measures how confident each candi-date is close to the true segmentation.The sentence language model score for each seg-mentation candidate is produced using the SRILMtoolkit (Stolcke, 2002) normalized using the formulaP 1/L, where P is the probability-based languagemodel score and L is the length of the sentence inwords (not in characters).
For global features, thefeature weights are not learned using the perceptronalgorithm but are determined using a developmentset.3 Experiments and AnalysisOur system is tested on all five corpora provided inthe fourth SIGHAN Bakeoff, in the closed track.3.1 Parameter PruningFirst, the value of the parameter N, which is themaximum number of N-best candidates, was deter-mined.
An oracle procedure proceeds as follows:80% of the training corpus is used to train the CRF4It is important to distinguish this kind of global featurefrom another type of ?global?
feature that either enforces con-sistency or examines the use of a feature in the entire trainingor testing corpus.model, and produce N-best outputs for each sen-tence on the remaining 20% of the data.
Then theseN candidates are compared with the true segmen-tation, and for each training sentence, the candidateclosest to the truth is chosen as the final output.
Test-ing on different values of N, we chose N to be 20in all our experiments since that provided the besttradeoff between accuracy and speed.Next, the weight for sentence confidence scoreScrf and that for language model score Slm are de-termined.
To simplify the process, we assume thatthe weights for both Scrf and Slm are equal.
In thisstep, each training corpus is separated into a train-ing set (80% of the whole corpus) and a held-outset (20% of the corpus).
Then, the perceptron algo-rithm is applied on the training set with different Scrfand Slm values, and for various number of iterations.The weight values we test include 2, 4, 6, 8, 10, 20,30, 40, 50, 100 and 200.
From the experiments, theweights are chosen to be 100 for CKIP corpus, 10for CityU corpus, 30 for NCC corpus, 20 for CTBcorpus, and 10 for SXU corpus.While determining the weights for global fea-tures, the number of training iterations can be deter-mined as well.
Experiments show that, as the num-ber of iterations increases, the accuracy stabilizes inmost cases, reflecting the convergence of the learn-ing algorithm.
Analyzing the learning curves, we fixthe number of training iterations to be 5 for CKIPcorpus, 9 for NCC corpus, and 8 for the CityU, CTBand SXU corpora.3.2 Results on the Fourth SIGHAN BakeoffIn each experiment, F-score (F ) is used to evalu-ate the segmentation accuracy.
Table 3 shows theF-score on the fourth SIGHAN Bakeoff corpora.
Inthis table, we record the performance of our system,the score from the character-based CRF method andthe score from the averaged perceptron using onlylocal features.Our system outperforms the baseline character-based CRF tagger.
In addition, the use of globalfeatures in the re-ranker produces better results thanonly using local features.The only data set on which the performance ofour system is lower than the character-based CRFmethod is CKIP corpus.
For this data set during theparameter pruning step, the weight for Scrf and Slm145Sixth SIGHAN Workshop on Chinese Language ProcessingCKIP NCC CityU CTB SXUCharacter-based CRF method 0.9332 0.9248 0.9320 0.9468 0.9473Averaged Perceptron with onlylocal features0.9180 0.9125 0.9273 0.9450 0.9387Our System 0.9263 0.9296 0.9355 0.9501 0.9512Our System (With modifiedweight for global features)0.9354 ?
?
?
?Significance (p-value) ?
1.19e-12 ?
4.43e-69 ?
3.55e-88 ?
2.17e-18 ?
2.18e-38Table 3: F-scores on the Fourth SIGHAN Bakeoff Corporawas too large.
By lowering the weight from 100 to4, we obtains an F-score of 0.9354, which is signifi-cantly better than the baseline CRF tagger.The significance values in Table 3 were producedusing the McNemar?s Test (Gillick, 1989)5.
All ourresults are significantly better.4 Related WorkRe-ranking over N-best lists has been applied to somany tasks in natural language that it is not possi-ble to list them all here.
Closest to our approachis the work in (Kazama and Torisawa, 2007).
Theyproposed a margin perceptron approach for namedentity recognition with non-local features on an N-best list.
In contrast to their approach, in our sys-tem, global features examine the entire sentence in-stead of partial phrases.
For word segmentation,(Wang and Shi, 2006) implemented a re-rankingmethod with POS tagging features.
In their ap-proach, character-based CRF model produces the N-best list for each test sentence.
The Penn ChineseTreeBank is used to train a POS tagger, which isused in re-ranking.
However the POS tags are usedas local and not global features.
Note that we wouldnot use POS tags in the closed track.5 ConclusionWe have participated in the closed track of the fourthSIGHAN Chinese word segmentation bakeoff, andwe provide results on all five corpora.
We haveshown that by combining global and local features,we can improve accuracy over simply using localfeatures, and we also show improved accuracy overthe baseline CRF character-based tagger for wordsegmentation.5www.fon.hum.uva.nl/Service/Statistics/McNemars test.htmlReferencesM.
Collins.
2002.
Discriminative Training Methodsfor Hidden Markov Models: Theory and Experimentswith Perceptron Algorithms.
In Proc.
of the EmpiricalMethods in Natural Language Processing (EMNLP).MACL, 2002, 1?8, 2000.M.
Collins.
2002.
Ranking Algorithms for Named-Entity Extractions: Boosting and the Voted Percep-tron.
In Proc.
of ACL 2002.Y.
Freund and R. Schapire.
1999.
Large Margin Classi-fication using the Perceptron Algorithm.
In MachineLearning, 37(3): 277?296.L.
Gillick and S. Cox.
1989.
Some Statistical Issuesin the Comparison of Speech Recognition Algorithms.In Proc.
of IEEE Conf.
on Acoustics, Speech and Sig.Proc., Glasgow, 1989, 532?535.J.
Kazama and K. Torisawa.
2007.
A New PerceptronAlgorithm for Sequence Labeling with Non-local Fea-tures.
In Proc.
of EMNLP-CoNLL 2007 , pages 315?324.T.
Kudo, K. Yamamoto, and Y. Matsumoto.
2004.
Ap-pliying Conditional Random Fields to Japanese Mor-phological Analysis.
In Proc.
of EMNLP 2004.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Condi-tional Random Fields: Probabilistic Models for Seg-menting and Labeling Sequence Data.
In Proc.
ofICML-2001, pages 591?598.A.
Ratnaparkhi.
1996.
A Maximum Entropy Model forPart-of-Speech Tagging.
In Proc.
of EMNLP 1996.A.
Stolcke.
2002.
SRILM - An Extensible LanguageModeling Toolkit.
In Proc.
Intl.
Conf.
Spoken Lan-guage Processing, Denver, Colorado, September 2002.M.
Wang and Y. Shi.
2006.
A Maximum Entropy Modelfor Part-of-Speech Tagging.
In Proc.
of the FifthSIGHAN Workshop on Chinese Language Processing,Sydney, 2006, pages 205?208.Y.
Zhang and S. Clark.
2007.
Chinese Segmentation witha Word-based Perceptron Algorithm.
In Proc.
of ACL2007.146Sixth SIGHAN Workshop on Chinese Language Processing
