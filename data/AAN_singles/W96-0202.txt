Parsing Chinese wi th  an A lmost -Context -Free  GrammarXuanyin Xia and Deka i  WuHI( US TDepar tment  of Computer  ScienceUn ivers i ty  of Sc ience and Techno logyClear  Water  Bay, Hong Kong{ samxia, dekai}?cs, ust.
hkAbst ractWe describe a novel parsing strategy we areemploying for Chinese.
We believe progress inChinese parsing technology has been slowedby the excessive ambiguity that typicallyarises in pure context-free grammars.
Thisproblem has inspired a modified formalismthat enhances our ability to write and main-tain robust large grammars, by constrainingproductions with left/right contexts and/ornonterminal functions.
Parsing is somewhatmore expensive than for pure context-freeparsing, but is still efficient by both theoret-ical and empirical analyses.
Encouraging ex-perimental results with our current grammarare described.IntroductionChinese NLP is still greatly impeded by therelative scarcity of resources that have al-ready become commonplace for English andother European languages.
A strategy weare pursuing is the use of automatic meth-ods to aid in the acquisition of such resources(4, 5, 6).
However, we are also selectively en-gineering certain resources by hand, for bothcomparison and applications purposes.
Onesuch tool that we have been developing isa general-purpose bracketer for unrestrictedChinese text.
In this paper we describe anapproach to parsing that has evolved as a re-sult of the problems we have encountered inmaking the transition from English to Chineseprocessing.We have found that the primary obstaclehas been the syntactic flexibility of Chinese,coupled with an absence of explicit marking bymorphological inflections.
In particular, com-pounding is extremely flexible in Chinese, al-lowing both verb and noun constituents o bearbitrarily mixed.
This creates extraordinarydifficulties for grammar writers, since robustrules for such compound forms tend to alsoaccept many undesirable forms.
This createstoo many possible parses per sentence.
Weemploy probabilistic grammars, so that it ispossible to choose the Viterbi (most probable)parse, but probabilities alone do not compen-sate sufficiently for the inadequacy of struc-tural constraints.There are two usual routes: either (1)keep the context-free basis but introduce finer-grained categories, or (2) move to context-sensitive grammars.
The former strategy in-cludes feature-based grammars with weak uni-fication.
One disadvantage of this approach isthat some features can become obscure andcumbersome.
Moreover, the expressive powerremains restricted to that of a CFG, so certainconstraints simply cannot be expressed.
Thus,many systems opt for some variety of context-sensitive grammar.
However, it is easy forparsing complexity in such systems to becomeimpractical.We describe an approach that is not quitecontext-free, but still admits acceptably fastEarley-style parsing.
A benefit of this ap-proach is that the form of rules is natural andsimple to write.
We have found this approachto be very effective for constraining the typesof ambiguities that arise from the compound-ing flexibility in Chinese.In the remainder of this paper, we first de-scribe our grammar framework in Sections 2-4.
The parsing strategy is then described inSection 5, followed by current experimental re-sults in Section 6.13The Grammar  F rameworkWe have made two extensions to the form ofstandard context-free grammars:1.
Right-hand-side contexts2.
Nonterminal functionsWe would like to note at the outset thatfrom the formal anguage standpoint, he com-plications introduced by the form of our pro-duction rules have so far hindered theoreti-cal analyses of the formal expressiveness char-acteristics of this grammar.
Because of thenature of the constraints, it is unclear howthe expressiveness relates to, for example,the more powerful unification-based gram-mars that are widespread for English.At the same time, however, we will showthat the natural format of the rules has greatlyfacilitated the writing of robust large gram-mars.
Also, an efficient Earley-style parsercan be constructed as discussed below forgrammars of this form.
For our applica-tions, we therefore feel the effectiveness of thegrammar form compensates for the theoreticalcomplications.We now describe the extensions, but first de-fine some notation used throughout the paper.A traditional context-free grammar (CFG) is afour-tuple G = (N, ~, P, S), where N is a finiteset of nonterminal symbols, ~ is a finite set ofterminal symbols such that N N ~ = O, p is afinite set of productions and S E N is a spe-cial designated start symbol.
Productions in Pare denoted by symbol Pr, 1 < r < IPI, andhave the form Dr ~ Zr,I Z,.
2 " " " Zr,~r~ , ~'r ~ O,whereDr  ENandZr , j  E NU~,  l_~ j ~_~rr.Right-hand-side contextsWe introduce right-hand-side contexts to im-prove rule applicability decisions for complexcompounding phenomena.
The difficulty thatordinary CFGs have with complex compound-ing phenomena can be seen from the followingexample grammar fragment:1.
Re lPh~ NP vn ~(de)2.
Nom ~ NP vn ~J(de)3.
NP ~ Nom4.
NP ~ RelPh NP5.
NP ~ NP NPHere, RelPh is a relative phrase, Nom is anominalization (similar to a gerund), vn is lex-ical verb category requiring an NP argument,and ~J(de) is a genitive particle.The sequence(1) a.
~ ~L:~ ~J ~b.
j~ngwfichfi t~g6ng de dgdfic.
police provide - -  answerd.
the answer provided by policecan be parsed either by\ [ \ [ \ [~\ ]  Np\ [~, \ ]  vn ~\] RelPh \ [~\ ]  NP\] NPor by\ [ \ [ \ [ \ [~-~\ ]  Np [~.
\ ]  vn~J\] Nom\] NP\[ ~\ ]  NP\] NPHowever the latter parse is not linguisti-cally meaningful, and is rather an artifact ofthe overly general noun compounding rule 5.The problem is that it becomes quite cum-bersome in a pure CFG to specify accuratelywhich types of noun phrases are permitted tocompound, and this usually leads to excessiveproliferation of features and/or nonterminalcategories.Instead, the approach described here aug-ments the CFG rules with a restricted set ofcontextual applicability conditions.
A pro-duction in our extended formalism may haveleft and/or right context, and is denoted asPr = {L}Zr,lZr,2 "''Zr,Trr{R}, where L ,R  E(N U E)* and the left context condition L andthe right context condition R are of a formdescribed below.
These context conditionshelp cut the parser's search space by elimi-nating many possible parse trees, increasingboth parsing speed and accuracy.
Thoughambiguities remain, the smaller number ofparses per sentence makes it more likely thatmost-probable parsing can pick out the cor-rect parse.Nontermina l  funct ionsIn addition, a second extension is the intro-duction of a variety of nonterminal functionsthat may be attached to any nonterminal orterminal symbol3 These functions are de-1The term nonterminal \]unctions was chosenfor mnemonic purposes; it is actually a misnomersince they can be apphed to terminal symbols aswell.14signed to facilitate natural expression of con-ditions for reducing ambiguities.
Some of thefunctions are simply notational sugar for stan-dard CFGs, while others are context-sensitiveextensions.
These functions are list in the fol-lowing sections.
By convention, we will use aand b for symbols that can be either terminalsor nonterminals, c for terminal symbols only,d for the semantic domain of a terminal, andi for an integer index.The  not  funct ionThe not function is denoted as / !b ,  whichmeans any constituent not labeled b. Notethat this feature must not be used with rulesthat can cause circular derivations of the typeA =V* A, since this would lead to a logicalcontradiction.In the previous example, if we change rule2 toNom ~ NP vn ~ {/!NP)the new right condi t ion/ !NP prevents rule 2from being used within cases such as rule 5,where the immediately following constituentis an NP.
This causes the the correct parse tobe chosen:\ [ \ [ \ [~\ ]  Np\ [~, \ ]  vn\] RelPh \ [~\ ]  NP\] NPWe have only found this function usefulfor left and right contexts, rather than themain body of production right-hand-sides.The  exc luded-category  funct ionThe excluded-category function is denoted asa / !b  that means a constituent labeled a,which moreover cannot be labeled as b. Again,not to be used with rules that can cause cir-cular derivations.The main purpose of the excluded-category function is to improve robustnesswhen the grammar coverage inadequacies pre-vent a full parse tree from being found.
Insuch cases, our parser will instead return apartial parse tree, as discussed further in Sec-tion 5.
The excluded-category function canhelp improve the chances of choosing the cor-rect rules within the partial parse tree.For example, consider its use with theverb phrase constructionNP verb (Obj)which is known as the ~t~(ba)-construction.
Ifthe verb has part of speech vn, then it is mono-transitive and only one object is needed toform a VP, but if the verb is a ditransitivevnn, then a second object is needed to formthe VP.An example of the monotransitive case is ~(2) a .~ ~ yb.
b~ f?u ch~ lec.
- -  food eat - -d. have eaten the foodwhile an example of the ditransitive case is(3) a .
~ J ~  Tb.
b~t f?u sbng rdn lec.
- -  food give somebody - -d. give food to somebodyThe former phrase can be correctly parsed bythe monotransitive ruleVP ~ ~ NP vnSuppose that the parser is unable to find anyfull parse tree for some sentence that includesthe latter phrase.
The above monotransitiverule would still be considered by the parser,since it is performing partial parsing, and thisrule matches the subsequence ~\[~  ~.
In factthis is not the correct rule for the ditransitivephrase--the VP is not ~ ~ ~ but ratherg~ ~ J~ ~- -but  we would not be able to dis-tinguish the monotransitive and ditransitivecases ~ ~.~ ~g and ~\[~  ~,  because both ~gand ~ can have part of speech vn.
Thus themonotransitive subparse might incorrectly bechosen for the partial parse output (whetherthis happens depends rather arbitrarily on thepossible subparses found over the rest of thesentence).The key to eliminating the incorrect pos-sibility altogether is that only ~ can also havethe part of speech vnn.
We refine the rule withour excluded-category function:VP ~ ~ NP vn//vnn2For this and all subsequent examples, (a) isthe Chinese written form, (b) is its pronuncia-tion, (c) is its word gloss ( ' - - '  means there is nodirectly corresponding word in Engfish), and (d)is its approximate English translation.15The monotransitive phrase can still be parsedby this new rule since ~ cannot have the partof speech vnn: 3\[~\[~\[~\] Np\[~Y~\] vn\] Vp J'.But because ~ can be labeled as either vn orvnn, it does not match vn//vnn, and thereforethe rule cannot be applied to the ditransitivephrase.
This leaves the ditransitive produc-tionVP~ ~ NP vnn NPas the only possibility, forcing the correct sub-parse to be chosen here.
In a sense, this func-tion allows a measure of redundancy in thegrammar specification and thereby improvesrobustness.The  subst r ing - l ink ing  funct ionThe substring-linking function is denoted a/ i .This is used to remember the string that wasmatched to a constituent a, so that the stringcan be compared to a subsequent appearanceof a/i in the same production.
In general, wemay have several occurrences of the same non-terminal, and it is occasionally useful to beable to constrain those occurrences to matchexactly the same string.One important use of substring-linking inChinese is for reduplicative patterns.
Anotheruse can be seen in the following two sentences:(4) a.
~ ~ ~ f~ ~ ~ gb.
t~ zub bfl zu6 zh& ji~n sh\]c. he do not do this - -  thingd.
will he do this thing(5) a.
~ ~ :~ ~iJ ~ ~ ;~b.
ta zub bh d?o zh~ ji?n sh~c.
he do not do this - -  thingd.
he cannot do this thingLet us consider two sequences {~ ~ {~ and {~~I\] in (4) and (5) respectively, where {5 andill can both be labeled as vn, but they have adifferent role.
The former indicates a question,and the latter a negative declaration; clearlythe parses must differentiate these two cases.If the only rule in the grammar to handlethese examples is3The -~ character is an aspect particle.question_verb ~ vn ~ vnthen the two sequences will be parsed iden-tically.
However, with the substring-linkingfunction we can refine the rule toqueslion_verb ~ vn/1 Yg vn/1Now the first vn/1 is defined as (~ in bothcases when the first {~ is parsed.
For thefirst sequence, the second ~ matches the sec-ond vn/1 when it is compared to the earlier-defined value of vn/1.
Because the substringsmatch, the first sequence can be parsed by thisrule as\[\[?~\] vn~\[~\] n\] q=~io~_~rbIn contrast, for the second sequence, when ~sJis compared with the defined value of vn/1- -  f~ - -  they are different, and therefore thesecond sequence cannot be parsed by the rule.In this example, the defined value of anonterminal is only one word.
However, inthe general case it can be an arbitrarily longstring of words spanned by a nonterminal (vnlin this example).The semant ic -domain  funct ionThe semantic-domain function is denoted byc/$zd and designates a terminal c whose se-mantic domain is restricted to d. This is anordinary feature, that we use in conjunctionwith the BDC dictionary which defines eman-tic domains.Given two sentences,(6) a.
~ ~ "  ~ ~b.
zki gu~ngd6ngsh@ng de t6uz~c.
in Guangdong - -  investmentd.
the investment in Guangdong Province(7) a.
~ 'J'~E ~b.
z~i xi~ozh~ng de ji~c.
in XiaoZhang - -  housed.
in XiaoZhang's housethey have the same surface structureNP ~J NPbut they are quite different.
In (6), :~ ~-~ is the modifier of ~ .
In (7), tJx~ is amodifier of 5 ,  and they together form a NPas the object of ~ .16It is very hard to distinguish these twocases in general.
With traditional CFGs, thisis problematic because both ~-~i"  and , ' J~have the part of speech up, and both ~.~ andhave part of speech nc.
We can do a some-what better job by using the domain knowl-edge supplied by a dictionary with semanticclasses.The difference between the two phrases isthat although ~-~"  and ~ are both loca-tion nouns, not all NPs following a ~ can beformed into locative phrase--only if the headnoun of the NP is a location noun can it canbe parsed as a locative phrase.
(6) is parsedas\ [ \ [ \ [ :~\ [~\ ]  NP\] LocPh ~\] ModPh \ [~\ ]  NP\] NPbecause :~?
~g~"  is a locative phrase, whereLocPh stands for locative phrase, and ModPhstands for modifier phrase.
But in (7), theentire phrase :i~ dx~ ~J ~ forms a locativephrase, and is parsed as\[:~ \ [ \ [ \ [ ' J '~ NP~I'~\] ModPh \[~\] NP\] NP\] LocPhThe key point here is how to define a lo-cation noun.
We have rulesandlocalion_noun ---* np/gJGElocation_noun ---+ nc/g~GEwhere GE is the abbreviation of geology.
Be-cause the domain of ~ "  is GE, it is parsedas a location_noun, and together with theleader ~ is parsed as a locative phrase.
But~ J~ cannot be parsed as a locative phrasewith the leader ~ since its domain is notGE; instead it is parsed as the modifier of, at which point the parser will further checkwhether :i~ plus ~ J~ ~ ~ can be parsed as alocative phrase.The  has -subconst i tuent  funct ionThis function is denoted as a /@b,  whichmeans a constituent labeled a with any de-scendant of category b, where a is a nontermi-nal and b can be either a terminal or a nonter-minal.
In other words, this matches an inter-nal node labeled a, which has a subtree withroot labeled b.Consider the two sentences(s) a.
4~-~ 7 ~ ~ ~b.
t~ xu~ le li-~ng g~ :~ngq{c. he learn - -  two - -  weekd.
he has learned it for two weeks(9)b. t~ xu~ le li~ng pi~n k~w~nc.
he learn - -  two - -  lessond.
he has learned two lessonsIn Sentence (8), ~ ~ ~\ [~ is the comple-ment of-~-, while in Sentence (9), ~ ~ -~is the object of ~ .
However, both NPs~ ~ and ~ ~ ~ superficially havethe same structure, and the parser may assignSentence 8 the wrong parse tree\[\[~\] Np\[\[--~-\] vn T \[\[~ \ ]  ClPh \ [~ \] NP\] NP\] VP\] clauseinstead of the correct one\[\[~\] Np\[\[-~\] vn~ \[\[\[\[~ ~\]  CIPh\[\[~ \]time_particle\] NP\] NP\] TP\] Comp\] VP\] clausewhere ClPh stands for classifier phrase, TPstands for time phrase, and Comp stands forthe complement of a verb.The difference between them lies in that~ is a time particle, and therefore is parsedwith its classifier ~ ~ as a time phrase,whereas -~ is a general noun, and is parsedwith its classifier ~ ~ as a general NP.With the ruletime_phrase --~ NP/@time_particlewe can parse ~ ~ ~\ ]  as a time phrase, andsince it is a time phrase, it will be parsed asthe complement of ~a.
But becase ~ ~ ~5~is a just general NP, it can not be parsed withthis rule, and it will serve only as the objectof ~ .Ear ley  Pars ingWe use a generalization of the Earley algo-rithm (3, 2) to parse grammars of our form.Although the time complexity rises comparedto the Earley algorithm, it remains polynomialin the worst case.17AlgorithmThe key to modifying the Earley algorithm tohandle the left and right context conditions isthat our rules can be rewritten into a full formwhich includes all symbols including the con-texts, plus indices indicating the left and/orright context boundaries.
For example, letA~{L} B {R}andC~D E {R}betwoproduction rules.
They are rewritten respec-tively as A ~ L B R, start = 2, len = 1andC~D E R, start = 1, len=2.
Oncethis transformation has been made, the ma-chinery from the Earley algorithm carries overremarkably smoothly.The main loop of the parsing algorithmemploys the following schema.1.
Pop the first entry from the agenda; call thepopped entry c.2.
If c is already in chart, go to 1.3.
Add c to chart.4.
For all rules whose left corner is b, callmatch(b, c).
If the return value is 1, addan initial edge e for that rule to chart; forall the chart entries (subtrees) d beginningat end(e)?l,  if g is the active symbol in theRHS (right-hand-side) of e and match(g, c')returns 1, then call extend(e, cl).5.
If the edge e is finished, add an entry to theagenda.6.
For all edges d, if g is the active symbol inthe RHS of d and match(g, c) returns 1,then call extend(d, c) and add the resultingedge.7.
Go to 1.extend(e, c): (extends an edge c with the chartentry (subtree) c)1.
Create a new edge e'.2.
Set start(e') to start(e).3.
Set end(e') to end(e).4.
Set rule(e') to rule(e) with.
moved beyondC.5.
If the edge e / is finished (i.e., a subtree) thenadd e I to the agenda, else for all chart sub-trees c I beginning at end(el)+1, if g is theactive symbol in the RHS of e I and match(g,c') returns 1, call extend(e I, c').match(g,c): (checks whether a subtree c canbe matched by a symbol g)1.
If c's category does not equal to g's cate-gory, return 0.2.
Check whether g's associated functions aresatisfied by c - -(a) If g has the form a / !b  or / !b ,  check allthe entries in the chart that span thesame range as c, returning 0 if any havecategory b.
(b) If g has the form a/ i ,  if a/i is not defined,link it to c and return 1.
Otherwise, com-pare c with the defined value of aft; if notthe same, return 0.
(c) If g has the form c /&d,  if the semanticdomain of c is not d, return 0.
(d) If g has the form a /@b,  check all thenodes of the subtree c; if no node of cat-egory b is found, return 0.3.
Return 1.The difference from standard Earley pars-ing (aside from the rule transformation men-tioned above) lies is in match.
To checkwhether an entry matches the left corner of arule or whether an edge can be extended by anentry, we need to check not only that the cat-egory of the constituent is matched, but alsothat the attached function if any is satisfied.Recall that our application for the pars-ing algorithm is as the first stage of a ro-bust bracketer.
We therefore use an extensionof this parsing approach that permits partialparsing.
In this version, if the sentence cannotbe parsed, a minimum-size subset of subtreesthat cover the entire sentence is produced.In the following, we will use an examplesentence to demonstrate how the algorithmworks.
The sentence and the grammar we usehere are oversimplified, but show how a rightcontext is handled.The sentence to be parsed is(10) a.
~ ~ fl,~ :~b.
t~ m~i de y~ffic.
he buy - clothesd.
the clothes bought by himand the grammar is1.
NP ~ pron2.
NP---~ nc3.
RelPh---~ NP vn ~l~ (NP}4.
NP--~ RelPh NP185.
pron ~ ~6.
nc ~ ~7.
vn---~The first portion of the parsing for this ex-ample is identical to standard Earley parsing.We pop the first the entry from the agenda, ~, and since it is not already there we add it tothe chart.
The only initial edge to be addedispron ~ ~ -Since this edge is finished, we add it to theagenda.Next we pop pron from agenda, create aninitial edgeNP ~ pron ?and find it is also finished, and so add the NPto the agenda.Again we pop NP from the agenda, andcreate the initial edgeRelPh --~ NP  vn ~ { NP}We find this edge cannot be extended by anyentry and is not finished, so we go to step 1and pop the next entry ~ from the agenda.We continue this step until we pop :~from the agenda, and add nc and later NP tothe agenda.
Up to this point, all we are doingis standard Earley parsing.Now we pop NP which spans :~n~ fromthe agenda, and find that the edgeRelPh -+ NP  vn t\]'~ { NP}can be extended by this entry.
We find theextended edge is finished, so we add the RelPhto the agenda, then pop it, creating a new edgeNP ~ ReIPh NPAn entry (subtree) NP which spans ;iJ~\]~is already in the chart when the last edge iscreated.
Thus the last edge can be extended,creating a finished edge, so we have createdan subtree NP that spans the whole sentence.Since there is now a nonterminal that spansthe whole sentence, we can write down a parsetree of the sentence in a subscripted bracketform as\[\[\[\[~\]pr0 n\] Np\ [~\ ]  vn ~J\] RelPh \ [ \ [ :~ \ ]  n c\] NP\] NPWe do not yet have a tight upper-boundfor this parsing algorithm in the worst case.Clearly the algorithm will be more time con-suming than for CFGs because the match pro-cedure will need to check not only the cate-gories of the constituents, but also their asso-ciated functions, and this check will not tak@constant ime as for CFGs.But though the algorithm is clearly worsethan CFG in the worst case, in practice, thecomplexity in practice will depend heavily onparticular sentences and the grammar.
Thenumber and type of context conditions usedin the grammar, and the kind of nonterminalfunctions, will greatly affect the efficiency ofparsing.
Thus empirical performance is thetrue judge, and our experience as describednext has been quite encouraging.Resu l tsWe are currently developing a robust gram-mar of this form for the Chinese bracketingapplication.
Although the number of rules ischanging daily, the evaluation was performedon a version of the grammar containing 948rules.
The lexicon used was the BDC dictio-nary containing approximately 100,000 entrieswith 33 part of speech categories (1).To evaluate our progress, we have evalu-ated precision on a previously unseen sampleof 250 sentences drawn from our corpus, whichcontains Hong Kong legislative proceedings.The sentences were randomly selected in var-ious length ranges of 4-10, 11-20, 21-30, 31-40, and 41-50 words, such that each of thefive ranges contained 50 sentences.
All thosesentences were segmented by hand, though wewill use an automatic segmenter in the future.We evaluated three factors:..The percentage of labeled words.
A word isunlabeled if it can not form deeper structurewith at least one other word.
Unlabeledwords often indicate inadequacies with lex-icon coverage rather than the grammar.Weighted constituent precision, i.e., the per-centage of incorrectly identified syntacticconstituents.
A constituent is judged to becorrect only if both its bracketing and itssyntactic label are correct.Because we don't give a single parse tree ifthere is for a sentence at the current stage,we uniformly weight the precision over allthe parse trees for the sentence.
Thereforethis measure is a kind of weighted precision(6).19O: (final (clause (clause (advph (sadv ~ ) , ) (clause (nounph (nounph (noun (pron ~J~ )) (noun(nc ~fi~ )))) (verbph (zaiph ~ (nounph (modph (relph (nounph (noun (up ~ ))) (vppart (vn(vadv ~ ) (vn ~ ))) fl-~ )) (nounph (modph (aa (vil -~  ))) (nounph (noun (nc ~:~ )))))(locat_part ~ ))))) (punc , ) (clause (verbph (vn (auxvb (aux ~ )) (vn ~ )) (nounph (assocph(nounph (d ~.~ ) (nounph (noun (nc ~Ji~i )))) fl'~ ) (nounph (noun (nc ~P-4 ))))))) o )O: (final (clause (clause (advph (sadv :~}~ ) , ) (clause (nounph (nounph (noun (pron ~J~ )) (noun(nc ~ )))) (verbph (zaiph ~ (nounph (modph (relph (nounph (noun (up ~-~4~ ))) (vppart (vn(vadv ~1~-~ ) (vn ~{~ ))) t~J )) (nounph (modph (aa (vil -~-  ))) (nounph (noun (nc ~:~ )))))(locat_part ~ ))))) (punc, ) (clause (verbph (vn (auxvb (aux ~ )) (vn f~ )) (nounph (assocph(nounph (d ~ ) (nounph (noun (nc 9~ )))) ~ ) (nounph (noun (nc ~P-4 ))))))) o )O: (final (clause (clause (advph (sadv ~i~ ) , ) (clause (nounph (d ~\ ]  ) (nounph (noun (nc Jk ))))(cjs ~ ) (verbph (vn (vadv ~iE ) (vn ~ )) (nounph (noun (nc I~  )))))) (punc,) (clause (verbph(verbph (vn (vadv ~,\[1 ) (vn (auxvb (aux ~A )) (vn ~ ))) (nounph (noun (nc ~ )))) (verbph(vn ~ ) (nounph (noun (nc ~ ))))))) o )O: (final (clause (nounph (noun (nc iTi~ )))(clause (clause (nounph (clph (d ~ ) (cl(auxvb (aux o/)) (vn ~ )) (nounph (noun(verbph (vs (vadv ~ ) (vs (vadv ~:~ ) (vs ~ ))))) (nounph (noun (nc ~j~ )))) (verbph (verbph (vn(up ~&/~j )))) (verbph (vil ~g~ )))) ~ ))) ?
)(nounph (nounph (noun (nc ~)~ )) (noun (nc ~ )))) , (clause (nounph (pron ~J~ )) (verbph (vil(neg ~ ) (vil ~1\]~ )))) (verbph (covph (p ~ ) (nounph (pron ~J~ ))) (verbph (vn ~ ) (nounph(clph (d ~ ) (cl ~ )) (nounph (noun (nc I~  )))))) , (clause (verbph (vil (vadv ~:~ ) (vil (vadv) (v i l  ~ (vil ~ )))))) o(nounph (nounph (noun (nc ~1~ )) (noun (nc ~J~ )))) , (clause (advph (sadv ~ )) (clause(nounph (pron ~ )) (verbph (vv ~ ) (verbph (covph (p ~,~ ) (nounph (modph (relph (nounph (d) (nounph (noun (nc ~\]~ )))) (vppart (verbph (vn ~,-~\] ) (nounph (noun (up ~Jx~\]t  )) (noun (nc~ )))) (vn (vadv ~ ) (vn ~ ))) ~ )) (nounph (modph (aa (a --t)J ))) (nounph (noun (nc ~J3))))) (punc,)) (verbph (vnv ~ ) (nounph (d ~ ) (nounph (nounph (noun (nc (~ff~)) (noun (nc -~-))))) (verbph (vil (vadv ~ ) (vil ~ )))))))) o(nounph (assocph (nounph (q --~=~ ) (noun (nc ~l~ ))) (?3) (nounph (noun (nc 1\]~.~ )))) , (advph(sadv ffljPl:l )) (nounph (nounph (nounph (noun (nc ~ )) (noun (nc ~ )))) (cjw $~ ) (nounph(nounph (noun (nc ~Jk )) (noun (nc ~ ))))) , (clause (verbph (vn (vadv ~ ) (vn (auxvb (aux :~~ )) (vn i~l\] ))) (nounph (assocph (nounph (nounph (nounph (noun (pron ~J~ )) (noun (nc ,~'l~l)))) (locat_part ~ )) ~J ) (nounph (noun (nc x_k~ )))))) oO: (final (clause (clause (clause (nounph (q - -~ ) (noun (nc ,~,~=~ ))) (verbph (vn ~ ) (nounph(modph (relph (vppart (vn ~ )) (nounph (noun (nc ~E\] )) (noun (nc .-~-~ ))) ~ )) (nounph(nounph (nounph (noun (nc ~t  )) (noun (nc ~ ))) (noun (nc ~ ))))))) (punc , ) (clause(verbph (vs ~ ) (clause (nounph (pron ~J~ )) (verbph (covph (p ~ ) (nounph (d ~_ ) (nounph(noun (nc ~ ))))) (verbph (vn (vadv ~ ) (vn ~ )) (nounph (noun (nc ~t~ ))))))))) (punc, )(clause (verbph (vil (vadv ~:~ ) (vil (vadv ~ ) (vil ~:/~ )))))) o )(advph (sadv - -~- -~ ) , ) (clause (nounph (noun (up ~ ))) (verbph (vi2 ~/))) (verbph (covph (p) (nounph (modph (aa (a Zk ))) (nounph (nounph (noun (nc ~ )) (noun (nc ~ )))))) (verbph(vn ~t~/~ ) (nounph (modph (attrph (aa (vil ~:)k: )) ~ )) (nounph (noun (nc ~1\]~ )))))) , ~(nounph (d i_~ ) (nounph (noun (nc ~lJ~ )))) $ (clause (nounph (noun (nc ~i~ ))) (verbph (covph(p PA ) (nounph (noun (nc ~ )))) (verbph (vil ~ i l  )))) oFigure 1: Examples of parse output (see text).20(clause (nounph (nounph (noun (nc ~::~ )) (noun (nc ~ ))) (noun (nc .~  ))) (verbph (vi2 (neg) (vi2 (auxvb (aux ~ )) (vi2 ~ ))))) (nounph (assocph (nounph (nounph (noun (nc ~:~ ))(noun (up :~:~?d~ ))) (noun (nc),. )))
~ ) (nounph (noun (nc $lJ~ )))), (clause (verbph (covph (p ~) (nounph (modph (relph (vppart (vn ~fi~ )) (nounph (modph (aa (vil .~  ))) (nounph (noun (nc~'~3~ )))) f~9 )) (nounph (noun (nc ~ ))))) (verbph (vv 5~ ) (verbph (vn ~l~t ) (nounph (noun (nc~ ))))))) ~,~ o(clause (clause (clause (nounph (noun (up ~:~ ))) (verbph (is ~ ) (nounph (clph (q -- ) (cl ~I ))(nounph (modph (aa (vil ~ ))) (nounph (noun (nc ~*~ ))))))) (punc , ) (clause (verbph (vv ~1~) (verbph (vn (vadv ~ ) (vn ~ )) (nounph (modph (aa (vil ~jt~ ))) (nounph (noun (nc hJ~)))))))) (punc , ) (clause (verbph (vi2 (vadv ~ ) (vi2 ~ ))))) (clause (nounph (nounph (noun (up2R~ ))) (ejw ~ ) (nounph (noun (up li~/~P.~ )))) (verbph (vn ~ ) (nounph (modph (relph (vppart(vn ~j~ )) ~t.~ )) (nounph (nounph (noun (nc ~ )) (noun (ne W~ ))))))), (clause (nounph (modph(aa (a I~.  )))
(nounph (noun (nc A:\[= )))) (verbph (verbph (vi2 (vadv ~?~ ) (vi2 (vadv f~ ) (vi2g~ )))) (cjw ~ ) (verbph (vn (vadv ~t)J ) (vn ~J~ )) (nounph (assocph (nounph (noun (nc ~)) (noun (nc 7~ ))) ~J ) (nounph (noun (nc ~)~ ))))))) o(clause (clause (clause (nounph (noun (up *A  ))) (verbph (vnv {~ ) (nounph (noun (nc ~a )))(verbph (vv ~-~ ) (verbph (covph (p ~ ) (nounph (nounph (noun (nc ~- -~ )) (noun (nc ~))))) (verbph (vv 5~ ) (verbph (vn }~ ) (nounph (noun (he ~ ))))))))) (punc,) (clause (verbph(advph (sadv ~ )) (verbph (vn {@~ ) (nounph (noun (nc ~tJ~y~ ))))))) (punc,)' (clause (verbph (vnv{E ) (nounph (noun (nc ~t~ ))) (verbph (eovph (p ~ ) (nounph (noun (nc ~-~ )))) (verbph (vi2~ )))))) (nounph (noun (nc ~ ))), (clause (nounph (noun (nc Y/- ))) (verbph (vn \]J~ ) (nounph(noun (nc ~ ))))) (nounph (modph (attrph (aa (a i~  )) ~ )) (nounph (modph (aa (vil -~,.~))) (nounph (noun (nc .~.~ ))))) , (clause (verbph (verbph (vn ~ ) (nounph (noun (nc \]I.~ ))))(verbph (vn ~\] ) (nounph (assocph (nounph (noun (nc ~lJ ))) ~J ) (nounph (noun (nc {~ ))))))) o(clause (cjs ~ ) (clause (nounph (noun (up ~ ))) (verbph (is (vadv ~ ) (is ~ )) (nounph (modph(aa (vil 3E~ ))) (nounph (nounph (noun (nc I~  )) (noun (nc ~,~lJ )))))))) ~AgJ" fl'.J (nounph (noun(nc I~-Y~ ))) , (clause (nounph (modph (aa (vil (vadv I~l~ ) (vil ~ )))) (nounph (noun (nc ~ ))))(verbph (locph (locph (zaiph :~ (nounph (modph (relph (vppart (vn (neg ~ ) (vn ~ ))) (nounph(d ~l~l~{t~ ) (nounph (modph (aa (vil ~E~ ))) (nounph (nounph (noun (nc 212~ )) (noun (nc :I:~.~.))))))
fl,~ )) (nounph (noun (nc ~b~ )))) (locat_part ~ ))) (punc , )) (verbph (covph (p ~ ) (nounph(d ~l~I~{t~ ) (nounph (noun (nc ~J j  ))))) (verbph (vn -~:~\]~ ) (nounph (modph (attrph (aa (a ~9\[" ))~J )) (nounph (nounph (noun (nc AJ~ )) (noun (nc ~.  )))))))))
o(clause (clause (clause (clause (cjs ~ ) (clause (nounph (noun (nc '~ j  ))) (verbph (vv ~ )(verbph (vn ~)~d~ ) (nounph (modph (aa (a ~1~ ))) (nounph (noun (nc ~J~ )))))))) (punc,) (clause(nounph (modph (aa (vil (neg ~6 ) (vii ~ )))) (nounph (noun (up I~  )))) (verbph (verbph (vn-~J~.~ ) (nounph (noun (he ~ )))) (verbph (vi2 .~gJJ ))))) (punc,) (clause (verbph (vn (vaav ~ )(vn (auxvb (aux ~, )) (vn ~5~ ))) (nounph (clph (q -- ) (el ~ )) (nounph (modph (attrph (aa (vil~,~ )) ~J )) (nounph (noun (nc ~,~ )))))))) (punc , ) (clause (verbph (eovph (p ~ ) (nounph(nounph (noun (nc 2\[sdt!! )))
(cjw ~ ) (nounph (nounph (nounph (noun (nc ~jg\[- )) (noun (up 2E~))) (noun (nc),jJ= )))))) (verbph (vn ~IJ~i ) (nounph (modph (attrph (aa (vii \ [~  )) ~ )) (nounph(noun (nc ~.gS~ )))))))) (nounph (noun (nc ~li~ ))) , (clause (verbph (covph (p ~ ) (nounph (noun(up ~ )))) (verbph (vv (auxvb (aux ~A )) (vv ~-~ )) (verbph (vi2 ~-~ ))))) (nounph (noun (nc~)3 ))) oFigure 2: Examples of parse output (cont'd).21length of sentence 4-10 11-20 21-30 31-40 ~ 41-50% words labeled 83.10 99.61 95.67 94.82 95.45% correct constituents 85.41 83.57 81.23 80.20 78.85run time per sentence (secs.)
2.03 3.54 9.00 5.08 37.50Table 1: Evaluation results.In the future, we will give a single mostprobable parse tree for a sentence if it canbe parsed.
Note that the precision in thiscase is likely to be lower bounded by theweighted precision reported here, since wecurrently assign equal weight to all parses,even if they are improbable.3.
The average run time per sentence.Results are shown in Table 1.
We haveunfortunately found it impossible to performcomparison evaluations against other systems,due to the unavailability of Chinese parsersin general.
However, we believe these per-formance levels to be quite competitive andpromising.Meaningful baseline evaluations are cur-rently difficult to design for Chinese parsingbecause of the unavailability of comparisonstandards.
Examples of the Chinese outputstill give by far the most important indica-tion of parsing quality.
Some representativeexamples are shown in Figures 2 and 2.
Theparser produces two kinds of outputs.
If nocomplete parse tree is found for the input sen-tence, a partial parse is returned; such exam-ples are shown without a number precedingthe parse.
Otherwise, the first complete parsetree is shown, preceded by the number 0 (in-dicating that it was the first alternative pro-duced).Conc lus ionWe have described an extension to context-free grammars that admits a practical pars-ing algorithm.
We have found the notationand the increased expressiveness to be well-suited for writing large robust grammars forChinese, particularly for handling compound-ing phenomena without incurring the level ofparsing ambiguity common to pure context-free grammars.
Experiments how promisingperformance on Chinese sentences.With regard to the theme of this confer-ence, we are clearly emphasizing representa-tion over algorithms.
We have developed anew representation that neatly captures thedomain characteristics, and in our experience,greatly improves the coverage and accuracyof our bracketer.
Algorithms follow naturallyas a consequence of the representational fea-tures.
It will be interesting to explore the re-lationships between our grammar and othercontext-sensitive grammar formalisms, a topicwe are currently pursuing.Re ferences\[1\] BDC.
The BDC Chinese-English Elec-tronic Dictionary (version 2.0).
BehaviorDesign Corporation, 1992.\[2\] Eugene Charniak.
Statistical LanguageLearning.
MIT Press, Cambridge, MA,1993.\[3\] Jay Earley.
An efficient context-freeparsing algorithm.
Communications ofthe Association for Computing Machinery,13(2):94-102, 1970.\[4\] Dekai Wu.
An algorithm for simultane-ously bracketing parallel texts by aligningwords.
In Proceedings of the 33rd AnnualConference of the Association for Compu-tational Linguistics, pages 244-251, Cam-bridge, Massachusetts, June 1995.\[5\] Dekai Wu.
Trainable coarse bilingualgrammars for parallel text bracketing.
InProceedings of the Third Annual Workshopon Very Large Corpora, pages 69-81, Cam:bridge, Massachusetts, June 1995.\[6\] Dekai Wu and Xuanyin Xia.
Large-scale automatic extraction of an English-Chinese lexicon.
Machine Translation,9(3-4):285-313, 1995.22
