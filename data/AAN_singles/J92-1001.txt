Using Multiple Knowledge Sources forWord Sense DiscriminationSusan W. McRoy ?Artificial Intelligence ProgramGE Research and Development CenterThis paper addresses the problem of how to identify the intended meaning of individual words inunrestricted texts, without necessarily having access to complete representations of sentences.
Todiscriminate senses, an understander can consider adiversity of information, including syntactictags, word frequencies, collocations, semantic ontext, role-related expectations, and syntacticrestrictions.
However, current approaches make use of only small subsets of this information.Here we will describe how to use the whole range of information.
Our discussion will include howthe preference cues relate to general exical and conceptual knowledge and to more specializedknowledge of collocations and contexts.
We will describe amethod of combining cues on the basisof their individual specificity, rather than a fixed ranking among cue-types.
We will also discussan application of the approach in a system that computes sense tags for arbitrary texts, even whenit is unable to determine a single syntactic or semantic representation for some sentences.1.
IntroductionMany problems in applied natural anguage processing - -  including information re-trieval, database generation from text, and machine translation - -  hinge on relatingwords to other words that are similar in meaning.
Current approaches to these ap-plications are often word-based - -  that is, they treat words in the input as strings,mapping them directly to other words.
However, the fact that many words have mul-tiple senses and different words often have similar meanings limits the accuracy ofsuch systems.
An alternative is to use a knowledge representation, or interlingua, toreflect ext content, thereby separating text representation from the individual words.These approaches can, in principle, be more accurate than word-based approaches, buthave not been sufficiently robust o perform any practical text processing task.
Theirlack of robustness i generally due to the difficulty in building knowledge bases thatare sufficient for broad-scale processing.But a synthesis i possible.
Applications can achieve greater accuracy by workingat the level of word senses instead of word strings.
That is, they would operate ontext in which each word has been tagged with its sense.
Robustness need not be sacri-ficed, however, because this tagging does not require a full-blown semantic analysis.Demonstrating this claim is one of the goals of this paper.Here is an example of the level of analysis a sense tagger would provide to anapplication program.
Suppose that the input is (1):Correspondence should be addressed to the author at Department of Computer Science, University ofToronto, Toronto, Canada M5S lA4 or mcroy@ai.toronto.edu.
(~) 1992 Association for Computational LinguisticsComputational Linguistics Volume 18, Number 1Example 1The agreement reached by the state and the EPA provides for the safe storage of thewaste.The analysis would provide an application with the following information.?
agreement refers to a state resulting from concurrence, rather than an act,object, or state of being equivalent.?
reach is intended to mean 'achieve,' rather than 'extend an arm.'?
state refers to a government body, rather than an abstract state ofexistence.safe in this context is an adjective corresponding to 'secure,' rather than anoun corresponding to a container for valuables.The EPA and the state were co-agents in completing some agreementthat is instrumental in supplying a secure place to keep garbage, ratherthan there was some equivalence that extended its arm around the statewhile the EPA was busy filling safes with trash.Preliminary e;cidence suggests that having access to a sense tagging of the text im-proves the performance of information retrieval systems (Krovetz 1989).The primary goal of this paper, then, is to describe in detail methods and knowl-edge that will enable a language analyzer to tag each word with its sense.
To demon-strate that the approach is sufficiently robust for practical tasks, the article will alsodiscuss the incorporation of the approach into an existing system, TRUMP (Jacobs 1986,1987, 1989), and the application of it to unrestricted texts.
The principles that make upthe approach are completely general, however, and not just specific to TRUMP.An analyzer whose tasks include word-sense tagging must be able to take an in-put text, determine the concept hat each word or phrase denotes, and identify therole relationships that link these concepts.
Because determining this information accu-rately is knowledge-intensive, the analyzer should be as flexible as possible, requiringa minimum amount of customization for different domains.
One way to gain suchflexibility is give the system enough generic information about word senses and se-mantic relations so that it will be able to handle texts spanning more than a singledomain.While having an extensive grammar and lexicon is essential for any system's do-main independence, this increased flexibility also introduces degrees of ambiguity notfrequently addressed by current NLP work.
Typically, the system will have to choosefrom several senses for each word.
For example, we found that TRUMP's base of nearly10,000 root senses and 10,000 derivations provides an average of approximately foursenses for each word of a sentence taken from the Wall Street Journal.
The potentialfor combinatoric explosion resulting from such ambiguity makes it critical to resolveambiguities quickly and reliably.
It is unrealistic to assume that word sense discrimi-nation can be left until parsing is complete, as suggested, for example, by Dahlgren,McDowell, and Stabler (1989) and Janssen (1990).No simple recipe can resolve the general problem of lexical ambiguity.
Althoughsemantic context and selectional restrictions provide good cues to disambiguation,they are neither eliable enough, nor available quickly enough, to be used alone.
Theapproach to disambiguation that we will take below combines many different, strongSusan W. McRoy Using Multiple Knowledge Sourcessources of information: syntactic tags, word frequencies, collocations, semantic on-text (clusters), selectional restrictions, and syntactic ues.
The approach incorporates anumber of innovations, including:?
a hybridization of several exicons to help control which senses areconsidered:a static generic lexicona lexicon linked to collocationsw a lexicon linked to concretions (i.e., specializations of abstractsenses of words)m lexicons linked to specialized conceptual domains;?
a separate processing phase, prior to parsing, that eliminates omeambiguities and identifies baseline semantic preferences;?
a preference combination mechanism, applied during parsing andsemantic interpretation, that uses dynamic measures of strength basedon specificity, instead of a fixed, ordered set of rules.Although improvements o our system are ongoing, it already interprets arbitrary textand makes coarse word sense selections reasonably well.
(Section 6 will give somequantitative assessments.)
No other system, to our knowledge, has been as successful.We Will now review word sense discrimination and the determination of role re-lations.
In Section 3, we discuss some sources of knowledge relevant o solving theseproblems, and, in Section 4, how TRUMP's semantic interpreter uses this knowledgeto identify sense preferences.
Section 5 describes how it combines the preference in-formation to select senses.
Afterward, we will discuss the results of our methods andthe avenues for improvement that remain.2.
Cues to Word Sense DiscriminationThe problem of word sense discrimination is to choose, for a particular word in aparticular context, which of its possible senses is the "correct" one for the context.Information about senses can come from a wide variety of sources:?
the analysis of each word into its root and affixes, that is, its morphology;?
the contextually appropriate part or parts of speech of each word, that is,its syntactic tag or tags;?
for each sense of the word, whether the sense is preferred or deprecated- -  either in general, because of its frequency, or in the context, because itis the expected one for a domain;?
whether a word is part of a common expression, or collocation, such asa nominal compound (e.g., soda cracker) or a predicative relation (e.g., takeaction);?
whether a word sense is supported by the semantic ontext - -  forexample, by its association with other senses in the context sharing asemantic ategory, a situation, or a topic;?
whether the input satisfies the expectations created by syntactic ues(e.g., some senses only take arguments of a particular syntactic type);3Computational Linguistics Volume 18, Number 1whether it satisfies role-related expectations (i.e., expectations regardingthe semantic relations that link syntactically attached objects);whether the input refers to something already active in the discoursefocus.Of course, not all these cues will be equally useful.We have found that, in general, the most important sources of information forword sense discrimination are syntactic tags, morphology, collocations, and word as-sociations.
Role-related expectations are also important, but to a slightly lesser degree.Syntactic tags are very important, because knowing the intended part of speech is of-ten enough to identify the correct sense.
For example, according to our lexicon, whensafe is used as an adjective (as in Example 1), it always denotes the sense related tosecurity, whereas afe used as a noun always denotes a type of container for storingvaluables.Morphology is also a strong cue to discrimination because certain sense-affix com-binations are preferred, deprecated, or forbidden.
Consider the word agreement.
Theverb agree can mean either 'concur,' "benefit,' or 'be equivalent' and, in general, addingthe affix -ment o a verb creates a noun corresponding either to an act, or to its result,its object, or its associated state.
However, of the twelve possible combinations of rootsense and affix sense, in practice only four occur: agreement can refer only to the act,object, or result in the case of the 'concur' sense of agree or the state in the case of the'equivalence' sense of agree.
Furthermore, the last of these combinations i  deprecated.Collocations and word associations are also important sources of information be-cause they are usually "dead giveaways," that is, they make immediate and obvioussense selections.
For example, when paired with increase, the preposition in clearlydenotes a patient rather than a temporal or spatial ocation, or a direction.
Word as-sociations uch as bank~money similarly create a bias for the related senses.
Despitetheir apparent strength, however, the preferences created by these cues are not abso-lute, as other cues may defeat hem.
For example, although normally the collocationwait on means 'serve' (Mary waited on John), the failure of a role-related expectation,such as that the BENEFICIARY be animate, can override this preference (Mary waited onthe steps).
Thus, collocations and word associations are strong sources of informationthat an understander must weigh against other cues, and not just treat as rules forsense-filtering (as in Hirst 1987 or Dahlgren, McDowell, and Stabler 1989).The selection of a role relationship can both influence and be influenced by theselection of word senses, because preferences partially constrain the various combi-nations of a role, its holder, and the filler.
For example, the preposition from prefersreferring to the SOURCE role; transfers, such as give, prefer to have a DESTINATION role;and instances of colors, such as red, prefer to fill a COLOR role.
Approaches based onthe word disambiguation model tend to apply constraint satisfaction techniques tocombine these role preferences (Hirst 1987).
Preferences based on role-related expecta-tions are often only a weak cue because they are primarily for verbs and not normallyvery restrictive.Although generally a weak cue, role-related preferences are quite valuable for thedisambiguation f prepositions.
In our view, prepositions should be treated essentiallythe same as other words in the lexicon.
The meaning of a preposition either names arelation directly, as one of its core senses (Hirst \[1987\] also allows this), or indirectly,as a specialized sense triggered, for example, by a collocation or concretion.
Becausethe meaning of a preposition actually names a relation, relation-based cues are a goodsource of information for disambiguating them.
(References to objects in the discourse4Susan W. McRoy Using Multiple Knowledge Sourcesfocus can also be a strong cue for disambiguating prepositions, but this cue appearsfairly infrequently \[Whittemore, Ferrara, and Brunner 1990\].
)The problem of determining role relationships entangles word sense discriminationwith the problem of syntactic attachment.
The attachment problem is a direct resultof the ambiguity in determining whether a concept is related to an adjacent object,or to some enveloping structure that incorporates the adjacent object.
Most proposedsolutions to this problem specify a fixed set of ordered rules that a system applies un-til a unique, satisfactory attachment is found (Fodor and Frazier 1980; Wilks, Huang,and Fass 1985; Shieber 1983; Hirst 1987; Dahlgren, McDowell, and Stabler 1989).
Suchrules can be either syntactic, semantic, or pragmatic.
Syntactic rules attempt o solvethe attachment problem independent of the sense discrimination problem.
For exam-ple, a rule for Right Association (also known as Late Closure) says to prefer attachinga new word to the lowest nonterminal node on the rightmost branch of the currentstructure (i.e., in the same structure as the last word processed) (Kimball 1973).
Seman-tic rules, by contrast, intertwine the problems of discrimination and attachment; onemust examine all combinations of senses and attachments o locate the semanticallybest one.
Such rules normally also collapse the attachment problem into the conceptualrole filling problem.
For example, a lexical preference rule specifies that the preferencefor a particular attachment depends on how strongly or weakly the verb of the clauseprefers its possible arguments (Fodor 1978; Ford, Bresnan, and Kaplan 1982).
Pragmaticrules also intermingle sense discrimination and attachment, but consider the contextof the utterance.
For example, one suggested rule says to prefer to build structuresdescribing objects just mentioned (Crain and Steedman 1985; Altmann and Steedman1988).The accuracy of systems with fixed-order ules is limited by the fact that it isnot always possible to strictly order a set of rules independent of the context.
Forexample, Dahlgren, McDowell, and Stabler (1989) propose the rule "If the object ofthe preposition is an expression of time, then S-attach the PP" to explain the preferencefor assuming that "in the afternoon" modifies adjourn in Example 2:Example 2The judge adjourned the hearing in the afternoon.Although they admit this rule would fail for a sentence like John described the meetingon January 20th, where the NP has a lexical preference for a time modifier, lexical pref-erences are not always the determining factor either.
The existence of a conceptuallysimilar object in the context (such as "the morning trial") can also create an expectationfor the grouping "hearing in the afternoon," as in Example 3 below.Example 3The judge had to leave town for the day.
He found a replacement to take over hismorning trial, but couldn't find anyone else that was available.
He called the court-house and cancelled the hearing in the afternoon.Moreover, pragmatic effects are not always the determining factor either, leading manypeople to judge the following sentence as silly (Hirst 1987).Example 4The landlord painted all the walls with cracks (Rayner, Carlson, and Frazier 1983).Computational Linguistics Volume 18, Number 1The presence of different lexical items or different objects in the discourse focus maystrengthen or weaken the information provided by an individual rule.
Another possi-bility we will discuss in Section 5 is to weigh all preference information dynamically(cf.
Schubert 1986; McRoy and Hirst 1990).The system we will be describing in Section 4 will use many of the cues describedabove, including syntactic tags, morphology, word associations, and role-related ex-pectations.
But first, we need to discuss the sources of knowledge that enable a systemto identify these cues.3.
Sources of KnowledgeTo identify preference cues such as morphology, word frequency, collocations, eman-tic contexts, syntactic expectations, and conceptual relations in unrestricted texts, asystem needs a large amount of knowledge in each category.
In most cases, this justmeans that the understander's lexicon and conceptual hierarchy must include prefer-ence information, although processing concerns uggest moving some information outof these structures and into data modules pecific to a particular process, such as iden-tifying collocations.
TRUMP obtains the necessary knowledge from a moderately sizedlexicon (8,775 unique roots), specifically designed for use in language understanding,and a hierarchy of nearly 1,000 higher-level concepts, overlaid with approximately 40concept-cluster definitions.
It also uses a library of over 1,400 collocational patterns.We will consider each in turn.3.1 The LexiconDevelopment of TRUMP's current lexicon followed an experiment with a moderately-sized, commercially available lexicon (10,000 unique roots), which demonstrated manysubstantive problems in applying lexical resources to text processing.
Although the lex-icon had good morphological nd grammatical coverage, as well as a thesaurus-basedsemantic representation f word meanings, it lacked reasonable information for dis-criminating senses.
The current lexicon, although roughly the same size as the earlierone, has been designed to better meet the needs of producing semantic representa-tions of text.
The lexicon features a hierarchy of 1,000 parent concepts for encodingsemantic preferences and restrictions, ense-based morphology and subcategorization,a distinction between primary and secondary senses and senses that require particu-lar "triggers" or appear only in specific contexts, and a broad range of collocationalinformation.
(An alternative would have been to give up discriminating senses thatthe lexicon does not distinguish; cf.
Janssen \[1990\].)
At this time, the lexicon containsabout 13,000 senses and 10,000 explicit derivations.Each lexical entry provides information about he morphological preferences, ensepreferences, and syntactic ues associated with a root, its senses, and their possiblederivations.
An entry also links words to the conceptual hierarchy by naming theconceptual parent of each sense.
If necessary, an entry can also specify the compositionof common phrases, such as collocations, that have the root as their head.TRUMP's lexicon combines a core lexicon with dynamic lexicons linked to spe-cialized conceptual domains, collocations, and concretions.
The core lexicon containsthe generic, or context-independent, senses of each word.
The system considers thesesenses whenever a word appears in the input.
The dynamic lexicons contain wordsenses that normally appear only within a particular context; these senses are con-sidered only when that context is active.
This distinction is a product of experience;it is conceivable that a formerly dynamic sense may become static, as when militaryterms creep into everyday language.
The partitioning of the lexicon into static and6Susan W. McRoy Using Multiple Knowledge Sourcesdynamic components reduces the number of senses the system must consider in situ-ations where the context does not trigger some dynamic sense.
Although the idea ofusing dynamic lexicons is not new (see Schank and Abelson \[1977\], for example), ourapproach is much more flexible than previous ones because TRUMP's lexicon does notlink all senses to a domain.
As a result, the lexical retrieval mechanism never forcesthe system to use a sense just because the domain has preselected it.3.1.1 The Core Lexicon.
The core lexicon, by design, includes only coarse distinctionsbetween word senses.
This means that, for a task such as generating databases fromtext, task-specific processing or inference must augment he core lexical knowledge,but problems of considering many nuances of meaning or low-frequency senses areavoided.
For example, the financial sense of issue (e.g., a new security) falls under thesame core sense as the latest issue of a magazine.
The 'progeny' and 'exit' senses ofissue are omitted from the lexicon.
The idea is to preserve in the core lexicon only thecommon, coarse distinctions among senses (cf.
Frazier and Rayner 1990).Figure 1 shows the lexical entries for the word issue.
Each entry has a part ofspeech, :POS, and a set of core senses, :SENSES.
Each sense has a :TYPE field thatindicates *primary* for a preferred (primary) sense and *secondary* for a depre-cated (secondary) sense.
The general rule for determining the :TYPE of a sense is thatsecondary senses are those that the semantic interpreter should not select withoutspecific contextual information, such as the failure of some selectional restriction per-taining to the primary sense.
For example, the word yard can mean an enclosed area,a workplace, or a unit of measure, but in the empty context, the enclosed-area senseis assumed.
This classification makes clear the relative frequency of the senses.
This isin contrast o just listing them in historical order, the approach of many lexicons (suchas the Longman Dictionary of Contemporary English \[Procter 1978\]) that have been usedin computational pplications.The :PaR field links each word sense to its immediate parent in the semantic hier-archy.
(See Section 3.2.)
The parents and siblings of the two noun senses of issue, whichare listed in Figure 2, give an idea of the coverage of the lexicon.
In the figure, wordsenses are given as a root followed by a sense number; conceptual categories are desig-nated by atoms beginning with c-.
Explicit derivations, uch as "per iod - i c -a l -x , "  areindicated by roots followed by endings and additional type specifiers.
These deriva-tive lexical entries do "double duty" in the lexicon: an application program can usethe derivation as well as the semantics of the derivative form.The :ASS0C field, not currently used in processing, includes the lexicographer'schoice of synonym or closely related words for each sense.The :SYNTAX field encodes yntactic onstraints and subcategorizations for eachsense.
When senses share constraints (not the case in this example), they can be en-coded at the level of the word entry.
When the syntactic onstraints (such as io - rec ,one-obj,  and no-oh j) influence semantic preferences, they are attached to the senseentry.
For example, in this case, issue used as an intransitive verb (no-oh j) would favor'passive moving' even though it is a secondary sense.
The io - rec  subcategorizationin the first two senses means indirect object as recipient: the ditransitive form willfill the RECIPIENT role.
The grammatical knowledge base of the system relates thesesubcategories to semantic roles.The :G-DERIV and :S-DERIV fields mark morphological derivations.
The former,which is NIL in the case of issue to indicate no derivations, encodes the derivationsat the word root level, while the latter encodes them at the sense preference level.For example, the :S-DERIV constraint allows issuance to derive from either of the firsttwo senses of the verb, with issuer and issuable deriving only from the 'giving' sense.7Computational Linguistics Volume 18, Number 1( issue:POS noun:SENSES(( issue1:EXAMPLE (address important issues):TYPE *primary*:PAR (c-concern):ASS0C (subject) )( issue2:EXAMPLE ( is  that  the october issue?
):TYPE *secondary*:PAR (c-published-document):ASSOC (ed i t ion)  )))( issue:POS verb:G-DERIV nil:SENSES(( issuel:SYNTAX (one-obj io-rec):EXAMPLE (the stockroom issues supplies):TYPE *primary*:PAR (c-giving):ASS0C (supply):S-DERIV ((-able adj tr_ability)(-ance noun tr_act)(-er noun tr_actor)) )( issue2:SYNTAX (one-obj io-rec):EXAMPLE (I issued instructions):TYPE *primary*:PAR (c-informing):ASSOC (produce):S-DERIV ((-ance noun tr_act)) )( issue3:SYNTAX (one-obj no-obj):EXAMPLE (good smells issue from the cake):TYPE *secondary*:PAR (c-passive-moving) )))Figure 1The lexical entries for issue.The derivation triples encode the form of each affix, the resulting syntactic ategory(usually redundant), and the "semantic transformation" that applies between the coresense and the resulting sense.
For example, the triple ( -er  noun t r_actor)  in theentry for issue says that an issuer plays the ACTOR role of the first sense of the verbissue.
Because derivations often apply to multiple senses and often result in differentsemantic transformations (for example, the ending -ion can indicate the act of perform-ing some action, the object of the action, or the result of the action), a lexical entry canmark certain interpretations of a morphological derivation as primary or secondary.Susan W. McRoy Using Multiple Knowledge SourcesNOUN_ISSUE1:PARENT CHAIN: c-concern c-mental-obj c-objc-entity somethingSIBLINGS (all nouns):regardl realm2 puzzlel province2premonitionl pityl pet2 parameterlground3 goodwilll feeling2 enigmaldraw2 department2 concernl cause2carel business3 baby2 apprehend-ion-xNOUN_ISSUE2:PARENT CHAIN: c-published-document c-documentc-phys-obj c-obj c-entity somethingSIBLINGS (all nouns):week-ly-x volumel transcriptl tragedy2tomel thesaurusl supplement2 strip4source2 softwarel seriall scripturelromance2 publication2 profile2 period-ic-al-xpaperbackl paper3 paper2 pamphletlomnibusl obituaryl novell notice2month-ly-x memoirl mapl manuallmagazinel libraryl journall handbooklguidel grammarl gazettel fictionlfeature4 facsimilel epicl encyclopedialdissertationl directoryl digestl dictionarylcopy2 constitute-ion-xl comicl column2columnl cataloguel calendarl bulletinlbrochurel bookl blurbl biographylbibliographyl biblel atlasl articlelanthologylFigure 2The parents and siblings of two senses of issue.3.1.2 The Dynamic Lexicons.
Unlike the core lexicon, which lists senses active in allsituations, the dynamic lexicons contain senses that are active only in a particularcontext.
Although these senses require triggers, a sense and its trigger may occur justas frequently as a core sense.
Thus, the dynamic-static distinction is orthogonal to thedistinction between primary and secondary senses made in the core lexicon.Currently, TRUMP has lexicons linked to domains, collocations, and concretions.For example, TRUMP's military lexicon contains a sense of engage that means 'attack.
'However, the system does not consider this sense unless the military domain is active.Similarly, the collocational lexicon contains enses triggered by well-known patterns ofwords; for example, the sequence take effect activates a sense of take meaning 'transpire.
'(Section 3.3 discusses collocations and their representation in more detail.)
Concretionsactivate specializations of the abstract sense of a word when it occurs with an object ofa specific type.
For example, in the core lexicon, the verb project has the abstract sense'transfer'; however, if its object is a sound, the system activates a sense correspondingComputational Linguistics Volume 18, Number 1to a 'communication event,' as in She projected her voice.
Encoding these specializationsin the core lexicon would be problematic, because then a system would be forced toresolve such nuances of meaning even when there was not enough information to doso.
Dynamic lexicons can provide much finer distinctions among senses than the corelexicon, because they do not increase the amount of ambiguity when their triggeringcontext is inactive.Together, the core and dynamic lexicons provide the information ecessary to rec-ognize morphological preferences, ense preferences, and syntactic ues.
They alsoprovide some of the information required to verify and interpret collocations.
Sec-tions 3.2, 3.3, and 3.4, below, describe sources of information that enable a system torecognize role-based preferences, collocations, and the semantic ontext.3.2 The Concept HierarchyThe concept hierarchy serves several purposes.
First, it associates word senses thatare siblings or otherwise closely related in the hierarchy, thus providing a thesaurusfor information retrieval and other tasks (cf.
Fox et al 1988).
In a sense tagging sys-tem, these associations can help determine the semantic ontext.
Second, it suppliesthe basic ontology to which domain knowledge can be associated, so that each newdomain requires only incremental knowledge ngineering.
Third, it allows role-basedpreferences, wherever possible, to apply to groups of word senses rather than justindividual exical entries.To see howthe  hierarchy's concept definitions establish the basic ontology, con-sider Figure 3, the definition of the concept c-recording, c-recording is the parentconcept for activities involving the storage of information, namely, the following verbsenses:book2 cataloguel clock1 compile1date3 documentl enter3 indexlinputl keyl logl recordlIn a concept definition, the : PAR fields link the concept to its immediate parents in thehierarch~ The :ASSOC field links the derived instances of the given concept to theirplaces in the hierarchy.
For example, according to Figure 3, the object form derived(c-entFigure 3The conceptualc-recording:DESC (the storing of information):PAR (c-action):PAR (c-simple-occurrence:ROLE-PLAY (r-object r-patient)):ASSOC ((r-object c-information)):PREF ((r-patient c-information)))definition of c-recording.
(c-ent c-clothing:DESC (cloth materials for wearing):PAR (c-phys-obj):RELS ( (*modified-by*(c-fabric-material c-made-of-rel) ) ) )Figure 4The conceptual definition of c-clothing.10Susan W. McRoy Using Multiple Knowledge Sources(c-ent c-color-qual:DESC (qualities of the color of an entity):PAR (c-phys-prop-qual):RELS ((*transform* (c-state c-color-rel))(*modifier-of*(c-phys-obj c-color-rel))))Figure 5The conceptual definition ofc-color-qual .
(c-ent c-made-of-rel:DESC (a relationship between an object and what it is made of):PAR (c-phys-prop-rel):PREF ((r-statevalue c-phys-obj)(r-stateholder (or c-phys-obj c-whole))):RELS ((*held-by* c-phys-obj) ))Figure 6The conceptual definition of c-made-of-rel.from enter3  (i.e., entry) has the parent c - in format ion.The :ROLE-PLAY fields mark specializations of a parent's roles (or introduce newroles).
Each :ROLE-PLAY indicates the parent's name for a role along with the concept'sspecialization of it.
For example, c - record ing  specializes its inherited OBJECT role asPATIENT.The : REL8 and : PREF fields identify which combinations of concept, role, and filleran understander should expect (and hence prefer).
For example, the definition in Fig-ure 4 expresses that fabric materials are common modifiers of clothing (e.g., wool suit)and fill the clothing's MADE-OF role.
TRUMP's hierarchy also allows the specificationof such preferences from the perspective of the filler, where they can be made moregeneral.
For example, although colors are also common modifiers of clothing (e.g., bluesuit), it is better to associate this preference with the filler (c -co lo r -qua l )  because col-ors prefer to fill the COLOR role of any physical object.
(Figure 5 shows an encoding ofthis preference.)
The hierarchy also permits the specification of such preferences fromthe perspective of the relation underlying a role.
For example, the relation c-made-ofin Figure 6 indicates (in its :RELS) that physical objects normally have a MADE-OF roleand (in its : PREF) that the role is normally filled by some physical object.
Figure 7 givesa complete account of the use of the :RELS and :PREF fields and how they permit theexpression of role-related preferences from any perspective.3.3 Collocational PatternsCollocation is the relationship among any group of words that tend to co-occur in apredictable configuration.
Although collocations eem to have a semantic basis, manycollocations are best recognized by their syntactic form.
Thus, for current purposes,we limit the use of the term "collocation" to sense preferences that result from thesewell-defined syntactic onstructions} For example, the particle combination pick up1 Traditionally many of these xpressions have been categorized asidioms (see Cowie and Mackin 1975;Cowie, Mackin, and McCraig 1983), but as most are at least partly compositional and can be processedby normal parsing methods, we prefer to use the more general term "collocation."
This categorizationthus happily encompasses both the obvious idioms and the compositional expressions whose status asidioms is highly debatable.
Our use of the term is thus similar to that of Smadja nd McKeown, whopartition collocations into open compounds, predicative r lations, and idiomatic expressions (Smadjaand McKeown 1990).11Computational Linguistics Volume 18, Number 1PreferencePerspectiveholder filler relationholder NA:RELS ((*modifier-of*filler (holder) (relation)))relation: RELS ( ( *held-by* (holder))):PREF((r-stateholder (filler))):RELS ((*modifled-by*(filler) (relation))):PREF (((role) (filler)):)NA: PREF((r-statevalue (holder))):RELS ((*holder-of* (role))):PREF (((role) (finer))):RELS ((*modifier-of*(holder) (relation)))NAFigure 7The use of :PREF and :RELS.1.
249 profit take2.
205 take place3.
157 take act4.
113 say take5.
113 act take6.
99 take advantage7.
94 take effect8.
88 take profit9.
77 take step10.
76 take accountFigure 8The top ten co-occurences with take.and the verb-complement combination make the team are both collocation-inducingexpressions.
Excluded from this classification are unstructured associations amongsenses that establish the general semantic ontext, for example, courtroom~defendant.
(We will discuss this type of association i the next section.
)Collocations often introduce dynamic word senses, i.e., ones that behave composi-tionally, but occur only in the context of the expression, making it inappropriate for thesystem to consider them outside that context.
For example, the collocation hang fromtriggers a sense of from that marks an INSTRUMENT.
In other cases, a collocation simplycreates preferences for selected core senses, as in the pairing of the 'opportunity' senseof break with the 'cause-to-have' sense of give in give her a break.
There is also a classof collocations that introduce a noncompositional sense for the entire expression, forexample, the collocation take place invokes a sense 'transpire.
'To recognize collocations during preprocessing, TRUMP uses a set of patterns,each of which lists the root words or syntactic ategories that make up the collocation.For example, the pattern (TAKE (A) (ADd) BATH) matches the clauses take a hot bathand takes hot baths.
In a pattern, parentheses indicate optionality; the system encodesthe repeatability of a category, such as adjectives, procedurally.
Currently, there arepatterns for verb-particle, verb-preposition, and verb-object collocations, as well ascompound nouns.Initially, we acquired patterns for verb-object collocations by analyzing lists ofroot word pairs that were weighted for relative co-occurrence in a corpus of articles12Susan W. McRoy Using Multiple Knowledge Sourcesfrom the Dow Jones News Service (cf.
Church and Hanks 1990; Smadja and McKeown1990).
As an example of the kind of data that we derived, Figure 8 shows the tenmost frequent co-occurrences involving the root "take."
Note that the collocation "takeaction" appears both in its active form (third in the list), as well as its passive, actionswere taken (fifth in the list).From an examination of these lists and the contexts in which the pairs appeared inthe corpus, we constructed the patterns used by TRUMP to identify collocations.
Then,using the patterns as a guide, we added lexical entries for each collocation.
(Figure 9lists some of the entries for the compositional collocations associated with the verbtake; the entries pair a dynamic sense of take with a sense occurring as its complement.
)These entries link the collocations to the semantic hierarchy, and, where appropriate,provide syntactic onstraints hat the parser can use to verify the presence of a collo-cation.
For example, Figure 10 shows the entry for the noncompositional collocationtake place, which requires that the object (t -*tai l*)  be singular and determinerless.These entries differ from similar epresentations of collocations or idioms in Smadjaand McKeown (1990) and Stock (1989), in that they are sense-based rather than word-based.
That is, instead of expressing collocations as word-templates, the lexicon groupstogether collocations that combine the same sense of the head verb with particularsenses or higher-level concepts (cf.
Dyer and Zernik 1986).
This approach better ad-dresses the fact that collocations do have a semantic basis, capturing eneral formssuch as give him or her <some temporal object>, which underlies the collocations givemonth, give minute, and give time.
Currently, the system has entries for over 1700 suchcollocations.3.4 Cluster DefinitionsThe last source of sense preferences we need to consider is the semantic ontext.Work on lexical cohesion suggests that people use words that repeat a conceptualcategory or that have a semantic association to each other to create unity in text(Morris 1988; Morris and Hirst 1991; Halliday and Hasan 1976).
These associationscan be thought of as a class of collocations that lack the predictable syntactic structureof, say, collocations arising from verb-particle or compound noun constructions.
Sincelanguage producers select senses that group together semantically, a language analyzershould prefer senses that share a semantic association.
However, it is unclear whetherthe benefit of knowing the exact nature of an association would justify the cost ofdetermining it.
Thus, our system provides a cluster mechanism for representing andidentifying roups of senses that are associated in some unspecified way.A cluster is a set of the senses associated with some central concept.
The definitionof a cluster includes a name suggesting the central concept and a list of the cluster'smembers, as in Figure 11.
A cluster may contain concepts or other clusters.TRUMP's knowledge base contains three types of clusters: categorial, functional,and situational.
The simplest type of cluster is the categorial cluster.
These clusters con-sist of the sets of all senses haring aparticular conceptual parent.
Since the conceptualhierarchy already encodes these clusters implicitly, we need not write formal clusterdefinitions for them.
Obviously, a sense will belong to a number of categorial clusters,one for each element of its parent chain.The second type of cluster is the functional cluster.
These consist of the sets of allsenses haring a specified functional relationship.
For example, our system has a smallnumber of part-whole clusters that list the parts associated with the object named bythe cluster.
Figure 12 shows the part-whole cluster cl-egg for parts of an egg.The third type of cluster, the situational cluster, encodes general relationshipsamong senses on the basis of their being associated with a common setting, event,13Computational Linguistics Volume 18, Number 1( take:POS verb:SPECIAL(( take50:S-COMPOUNDS((vc (or (member c-verb_advise2-objc-act-of-verb_blamelc-act-of-verb_losel noun_profit2)c-giving))):EXAMPLE (take delivery):PAR (c-receiving) )( take51:S-COMPOUNDS ((vc (or (member noun_effort1)c-temporal-obj c-energy))):EXAMPLE (the job takes up time)):PAR (c-require-tel) )( take52:S-COMPOUNDS ((vc (member noun_news1noun_burden1 noun_load2 noun_pressure3noun_pressure2 noun_stress1 noun stress2c-act-of-verb_strain1))):EXAMPLE (he couldn't take the presssure):PAR (c-managing) )( take58:S-COMPOUNDS ((vc (or (member noun_office2noun_advantagel noun_charge1c-act-of-verb_control1 noun_command2noun_responsibility1) c-structure-telc-shape-tel))):EXAMPLE (they took advantage of the situation):PAR (c-contracting) )( ts_ke59:S-COMPOUNDS ((vc (member noun_effect1))):EXAMPLE (the new rules take effect today):PAR (c-transpire) )( take60:S-COMPOUNDS ((vc (or c-task))):EXAMPLE (he took the assignment):PAR (c-deciding) ))Figure 9Some compositional collocations involving take.
( take-place1: CTYPE vc:TAIL noun_place:PREF ((r-*tail* (and (fi l lerp number singular)(f i l lerp l imit null)))): PAR (c-transpire))Figure 10The entry for the noncompositional phrase take place from the collocational entry for take.14Susan W. McRoy Using Multiple Knowledge Sources(c-ent cl-business:PAR c-cluster-obj:CLUSTERS (c-business-group c-business-manager-humanc-business-org c-business-qual c-business-humanc-profession c-employment-action cl-financial))Figure 11The definition of the cluster cl-business.
(c-ent cl-egg:PAR c-cluster-obj:CLUSTERS (noun_albuminl)Figure 12The definition of the cluster cl-egg.noun_white4 noun_eggl noun_yolkl))(c-ent cl-courtroom:PAR c-cluster-obj:CLUSTERS (c-law-action c-law-obj verb_judgel noun_jurylverb_defendl noun_lawyerl noun_attorneylnoun_crimel noun_plaintiffl noun_justicelnoun_justice2 verb_prosecutel noun_baillnoun_pleal verb_objectl noun_finel noun_jaillnoun_prisonl noun_courtl noun testimonylverb_testifyl verb_try3 verb_swear2 noun_oathlnoun_truthl noun_bench2 verb perjurel))Figure 13The definition of the cluster cl-courtroom.or purpose.
Since a cluster's usefulness i inversely proportional to its size, these clus-ters normally include only senses that do not occur outside the clustered context orthat strongly suggest the clustered context when they occur with some other memberof the cluster.
Thus, situational clusters are centered upon fairly specific ideas andmay correspondingly bevery specific with respect to their elements.
It is not unusualfor a word to be contained in a cluster while its synonyms are not.
For example,the cluster cl-courtroom shown in Figure 13 contains ense verb_ tes t i fy l ,  but notverb_assertl.
Situational clusters capture the associations found in generic descrip-tions (cf.
Dahlgren, McDowell, and Stabler 1989) or dictionary examples (cf.
Janssen1990), but are more compact because clusters may include whole categories of objects(such as c-law-action) as members and need not specify relationships between themembers.
(As mentioned above, the conceptual hierarchy is the best place for encodingknown role-related expectations.
)The use of clusters for sense discrimination is also comparable to approaches thatfavor senses linked by marked paths in a semantic network (Hirst 1987).
In fact, clus-ters capture most of the useful associations found in scripts or semantic networks,but lack many of the disadvantages of using networks.
For example, because clustersdo not specify what the exact nature of any association is, learning new clusters frompreviously processed sentences would be fairly straightforward, in contrast to learningnew fragments of network.
Using clusters also avoids the major problem associatedwith marker-passing approaches, namely how to prevent he production of stupidpaths (or remove them from consideration after they have been produced) (Charniak15Computational Linguistics Volume 18, Number 11983).
The relevant difference is that a cluster is cautious because it must explicitlyspecify all its elements.
A marker passer takes the opposite stance, however, consid-ering all paths up, down, and across the network unless it is explicitly constrained.Thus a marker passer might find the following dubious path from the 'written object'sense of book to the 'part-of-a-plant' sense of leaf:\[book made-of paper\]\[paper made-from wood\]\[tree made-of wood\]\[tre~e has-part leaf\]whereas no cluster would link these entities, unless there had been some prior evidenceof a connection.
(The recommended solution to the production of such paths by amarker passer is to prevent he passing of marks through certain kinds of nodes \[Hirst1987; Hendler 1987\].
)From the lexical entries, the underlying concept hierarchy, and the specializedentries for collocation and clusters just described, a language analyzer can extract heinformation that establishes preferences among senses.
In the next section, we willdescribe how a semantic interpreter can apply knowledge from such a wide varietyof sources.4.
Using Knowledge to Identify Sense PreferencesThere is a wide variety of information about which sense is the correct one, and thechallenge is to decide when and how to use this information.
The danger of a combi-natorial explosion of possibilities makes it advantageous to try to resolve ambiguitiesas early as possible.
Indeed, efficient preprocessing of texts can elicit a number of cuesfor word senses, set up preferences, and help control the parse.
Then, the parse andsemantic interpretation of the text will provide the cues necessary to complete the taskof resolution.Without actually parsing a text, a preprocessor can identify for each word itsmorphology, 2 its syntactic tag or tags, 3 and whether it is part of a collocation; foreach sense, it can identify whether the sense is preferred or deprecated and whetherit is supported by a cluster.
These properties are all either retrievable directly from aknowledge base or computable from short sequences of words.
To identify whetherthe input satisfies the expectations created by syntactic ues or whether it satisfiesrole-related expectations, the system must first perform some syntactic analysis of theinput.
Identifying these properties must come after parsing, because recognizing themrequires both the structural cues provided by parsing and a semantic analysis of thetext.In our system, processing occurs in three phases: morphology, preprocessing, andparsing and semantic interpretation.
(See Figure 14.)
Analysis of a text begins withthe identification of the morphological features of each word and the retrieval ofthe (core) senses of each word.
Then, the input passes through a special preprocessorthat identifies parse-independent semantic preferences (i.e., syntactic tags, collocations,and clusters) and makes a preliminary selection of word senses.
This selection pro-cess eliminates those core senses that are obviously inappropriate and triggers certain2 This is at least true for English, although whether it is possible for morphologically complex oragglutinative languages such as Finnish remains to be seen.3 A similar caveat applies here.
(See Church \[1988\] or Zernik \[1990\] for statistical approaches to taggingEnglish words.
)16Susan W. McRoy Using Multiple Knowledge SourcesPreprocessor \ ]~Identification \[..Ildentification of of ~-~ clusters collocations Tagging '~-~Parser I_ >SemanticinterpreterFigure 14The system architecture.specialized senses.
In the third phase, TRUMP attempts to parse the input and at thesame time produce a "preferred" semantic interpretation for it.
Since the preferredinterpretation also fixes the preferred sense of each word, it is at this point that thetext can be given semantic tags, thus allowing sense-based information retrieval.In the next few subsections we will describe in greater detail the processes thatenable the system to identify semantic preferences: morphological nalysis, tagging,collocation identification, cluster matching, and semantic interpretation.
Afterward wewill discuss how the system combines the preferences it identifies.4.1 Morphological Analysis and Lexical RetrievalThe first step in processing an input text is to determine the root, syntactic features,and affixes of each word.
This information is necessary both for retrieving the word'slexical entries and for the syntactic tagging of the text during preprocessing.
Morpho-logical analysis not only reduces the number of words and senses that must be inthe lexicon, but it also enables a system to make reasonable guesses about the syntac-tic and semantic identity of unknown words so that they do not prevent parsing (seeRau, Jacobs, and Zernik 1989).
Once morphological nalysis of a word is complete, thesystem retrieves (or derives) the corresponding senses and establishes initial semanticpreferences for the primary senses.
For example, by default, the sense of agree mean-ing 'to concur' (agreed is preferred over its other senses.
The lexical entry for agreemarks this preference by giving it :TYPE *primary* (see Figure 15).
The entry alsosays that derivations (listed in the :S-DERIV field) agreel+ment and agree2+able arepreferred, derivations agreel+able and agree3+ment are deprecated, and all othersense-affix combinations (excepting inflections) have been disallowed.During morphological nalysis, the system retrieves only the most general senses.It waits until the preprocessor r the parser identifies upporting evidence beforeit retrieves word senses specific to a context, such as a domain, a situation, or acollocation.
In most cases this approach elps reduce the amount of ambiguity.
Theapproach is compatible with evidence discussed by Simpson and Burgess (1988) that17Computational Linguistics Volume 18, Number 1( agree:POS verb:G-DERIV nil:SENSES(( agreel:SYNTAX (one-obj no-obj thatcomp comp subj-equi):EXAMPLE (she agrees with me ?
they agreed to use forcethey agreed on 3 percent ?
they agreed that he was rightI agree it is true):TYPE ~primary~:PAK (c-agreeing):ASSOC (concur believe):S-DERIV ((-ment preferred noun tr_act tr_object tr_result)(-able secondary adj tr_ability)))( agree2:SYNTAX (one-obj):EXAMPLE (winter agrees with me):TYPE ~secondary~:PAK (c-abstract-relation):ASSOC (benefit):S-DERIV ((-able preferred adj tr ability)))( agree3:SYNTAX (no-obj):EXAMPLE (the two accounts do not agree):TYPE ~secondary~:PAR (c-equivalence-rel):ASSOC (correspond):S-DEKIV ((-ment secondary noun tr_state)))))Figure 15The lexical entry for the verb agree.
"multiple meanings are activated in frequency-coded order" and that low-frequencysenses are handled by a second retrieval process that accumulates evidence for thosesenses and activates them as necessary.4.2 TaggingOnce the system determines the morphological nalysis of each word, the next step inpreprocessing is to try to determine the correct part of speech for the word.
Our systemuses a tagging program, written by Uri Zernik (1990), that takes information aboutthe root, affix, and possible syntactic ategory for each word and applies stochastictechniques to select a syntactic tag for each word.
Stochastic taggers look at smallgroups of words and pick the most likely assignment of tags, determined by thefrequency of alternative syntactic patterns in similar texts.
Although it may not bepossible to completely disambiguate all words prior to parsing, approaches based on18Susan W. McRoy Using Multiple Knowledge Sourcesstochastic information have been quite successful (Church 1988; Garside, Leech, andSampson 1987; de Marcken 1990).
4To allow for the fact that the tagger may err, as part of the tagging process thesystem makes a second pass through the text to remove some systematic errors thatresult from biases common to statistical pproaches.
For example, they tend to prefermodifiers over nouns and nouns over verbs; for instance, in Example 5, the taggererroneously marks the word need as a noun.Example 5You really need the Campbell Soups of the world to be interested in your magazine.In this second pass, the system applies a few rules derived from our grammar andresets the tags where necessary.
For example, to correct for the noun versus verbovergeneralization, whenever a word that can be either a noun or a verb gets taggedas just a noun, the corrector lets it remain ambiguous unless it is immediately precededby a determiner (a good clue for nouns), or it is immediately preceded by a pluralnoun or a preposition, or is immediately followed by a determiner (three clues thatsuggest a word may be a verb).
The system is able to correct for all the systematicerrors we have identified thus far using just nine rules of this sort.After tagging, the preprocessor eliminates all senses corresponding to unselectedparts of speech.4.3 Identification of CollocationsFollowing the syntactic filtering of senses, TRUMP's preprocessor identifies colloca-tions and establishes semantic preferences for the senses associated with them.
In thisstage of preprocessing, the system recognizes the following types of collocations:?
verb+particle pairs such as take on;?
verb+preposition pairs such as invest in;?
verb+particle+preposition combinations such as break in on;?
verb+complement clauses uch as take a bath, their passives, as in actionswere taken, and hyphenated nominals, such as profit-taking;?
compound noun phrases uch as investment bank.To recognize a collocation, the preprocessor relies on a set of simple patterns, whichmatch the general syntactic ontext in which the collocation occurs.
For example, thesystem recognizes the collocation "take profit" found in Example 6 with the pattern(TAKE (DET) PROFIT).Example 6A number of stocks that have spearheaded the market's recent rally bore the brunt ofisolated profit-taking Tuesday.The preprocessor's strategy for locating a collocation is to first scan the text for trig-ger words, and if it finds the necessary triggers, then to try to match the completepattern.
(Triggers typically correspond to the phrasal head of a collocation, but for4 Magerman and Marcus (1990) do complete stochastic N-gram parsing.19Computational Linguistics Volume 18, Number 1more complex patterns, such as verb-complement clauses, both parts of the colloca-tion must be present.)
The system's matching procedures allow for punctuation andverb-complement i version.If the triggers are found and the match is successful, the preprocessor has a choiceof subsequent actions, depending on how cautious it is supposed to be.
In its aggressivemode, it updates the representations of the matched words, adding any triggered sensesand preferences for the collocated senses.
It also deletes any unsupported, eprecatedsenses.
In its cautious mode, it just adds the word senses associated with the patternto a dynamic store.
Once stored, these senses are then available for the parser to useafter it verifies the syntactic onstraints of the collocation; if it is successful, it will addpreferences for the appropriate senses.
Early identification of triggered senses enablesthe system to use them for cluster matching in the next stage.4.4 Identification of ClustersAfter the syntactic filtering of senses and the activation of senses triggered by col-locations, the next step of preprocessing identifies preferences for senses that invokecurrently active clusters (see Section 3.4).
A cluster is active if it contains any of thesenses under consideration for other words in the current paragraph.
The system mayalso activate certain clusters to represent the general topic of the text.The preprocessor's strategy for assessing cluster-based preferences i to take theset of cluster names invoked by each sense of each content word in the sentenceand locate all intersections between it and the names of other active clusters.
(Forpurposes of cluster matching, the sense list for each word will include all the specialand noncompositional senses activated uring the previous tage of preprocessing, aswell as any domain-specific senses that are not yet active.)
For each intersection thepreprocessor finds, it adds preferences for the senses that are supported by the clustermatch.
Then, the preprocessor activates any previously inactive senses it found to besupported by a cluster match.
This triggering of senses on the basis of conceptualcontext forms the final step of the preprocessing phase.4.5 Semantic InterpretationOnce preprocessing is complete, the parsing phase begins.
In this phase, TRUMPattempts to build syntactic structures, while calling on the semantic interpreter tobuild and rate alternative interpretations for each structure proposed.
These semanticevaluations then guide the parser's evaluation of syntactic structures.
They may alsoinfluence the actual progression of the parse.
For example, if a structure is found tohave incoherent semantics, the parser immediately eliminates it (and all structuresthat might contain it) from further consideration.
Also, whenever the semantics of aparse becomes ufficiently better than that of its competitors, the system prunes thesemantically inferior parses, reducing the number of ambiguities even further, sAs suggested above, the system builds semantic interpretations incrementally.
Foreach proposed combination of syntactic structures, there is a corresponding combi-nation of semantic structures.
It is the job of the semantic interpreter to identify thepossible relations that link the structures being combined, identify the preferences a so-ciated with each possible combination of head, role (relation), and filler (the argumentor modifier), and then rank competing semantic interpretations.5 A similar approach has been taken by Gibson (1990) and is supported by the psychologicalexperiments of Kurtzman (1984).20Susan W. McRoy Using Multiple Knowledge SourcesFor each proposed combination, knowledge sources may contribute the followingpreferences:?
preferences directly associated with the head or the filler, determinedrecursively from their components, beginning with preferences identifiedduring preprocessing.?
preferences associated with syntactic ues, such as the satisfaction ofrestrictions listed in the lexicon.
For example, a word may allow onlymodifiers of a particular syntactic form, or a modifier may modify only acertain syntactic form.
(For example, the sense meaning 'to care for,' inShe tends plants or She tends to plants occurs with an NP or PP object,whereas the sense of tend meaning 'to have a tendency' as in She tends tolose things requires a clausal object.)?
preferences associated with the semantic "fit" between any two of thehead, the role, and the filler, for example:filler and role e.g., foods make good fillers for the PATIENT role ofeating activities;filler and head e.g., colors make good modifiers of physical objects;head and role e.g., monetary objects expect o be qualified bysome QUANTITY.The conceptual hierarchy and the lexicon contain the information thatencodes these preferences.?
preferences triggered by reference resolution.
(Currently, our system doesnot make use of these preferences, but see Crain and Steedman \[1985\];Altmann and Steedman \[1988\]; Hirst \[1987\].
)How the semantic interpreter combines these preferences i the subject of the nextsection.5.
Combining Preferences to Select SensesGiven the number of preference cues available for discriminating word senses, anunderstander must face the question of what to do if they conflict.
For example, in thesentence Mary took a picture to Bob, the fact that photography does not normally havea destination (negative role-related information) should override the support for the'photograph' interpretation of took a picture given by collocation analysis.
A particularsource of information may also support more than one possible interpretation, but todifferent degrees.
For example, cigarette filter may correspond either to something thatfilters out cigarettes or to something that is part of a cigarette, but the latter relationis more likely.
Our strategy for combining the preferences described in the precedingsections is to rate most highly the sense with the strongest combination of supportingcues.
The system assigns each preference cue a strength, an integer value between +10and -10, and then sums these strengths to find the sense with the highest rating.The strength of a particular cue depends on its type and on the degree to whichthe expectations underlying it are satisfied.
For cues that are polar - -  for example,a sense is either low or high frequency - -  a value must be chosen experimentally,depending on the strength of the cue compared with others.
For example, the systemassigns frequency information (the primary-secondary distinction) a score close to21Computational Linguistics Volume 18, Number 1zero because this information tends to be significant only when other preferences areinconclusive.
For cues that have an inherent extent - -  for example, the conceptualcategory specified by a role preference subsumes a set of elements that can be counted- -  the cue strength is a function of the magnitude of the extent, that is, its specificity.TRUMP's specificity function maps the number of elements ubsumed by theconcept onto the range 0 to +10.
The function assigns concepts with few members ahigh value and concepts with many members a low w~lue.
For example, the conceptc-object,  which subsumes roughly half the knowledge base, has a low specificityvalue (1).
In contrast, the concept noun&after1, which subsumes only a single entity,has a high specificity value (10).
Concept strength is inversely proportional to conceptsize because a preference for a very general (large) concept often indicates that eitherthere is no strong expectation at all or there is a gap in the system's knowledge.
Ineither case, a concept hat subsumes only a few senses is stronger information than aconcept hat subsumes more.
The preference score for a complex concept, formed bycombining simpler concepts with the connectives AND, OR, and NOT, is a function ofthe number of senses ubsumed by both, either, or neither concept, respectively.
Simi-larly, the score for a cluster is the specificity of that cluster (as defined in Section 3.4).
(If a sense belongs to more than one active cluster, then only the most specific oneis considered.)
The exact details of the function (i.e., the range of magnitudes corre-sponding to each specificity class) necessarily depend on the size and organizationof one's concept hierarchy.
For example, one would assign specificity value 1 to anyconcept with more members than any immediate specialization of the most abstractconcept.When a preference cue matches the input, the cue strength is its specificity value;when a concept fails to match the input, the strength is a negative value whose magni-tude is usually the specificity of the concept, but it is not always this straightforward.Rating the evidence associated with a preference failure is a subtle problem, becausethere are different ypes of preference failure to take into account.
Failure to meet ageneral preference is always significant, whereas failure to meet a very specific pref-erence is only strong information when a slight relaxation of the preference does noteliminate the failure.
This presents a bit of a paradox: the greater the specificity of aconcept, the more information there is about it, but the less information there maybe about a corresponding preference.
The paradox arises because the failure of a veryspecific preference introduces ignificant uncertainty as to why the preference failed.Failing to meet a very general preference is always strong information because, inpractice, the purpose of such preferences i to eliminate the grossly inappropriate - -such as trying to use a relation with a physical object when it should only be appliedto events.
The specificity function in this case returns a value whose magnitude is thesame as the specificity of the complement of the concept (i.e., the positive specificity lessthe maximum specificity, 10.)
The result is a negative number whose absolute valueis greater than it would be by default.
For example, if a preference is for the conceptc-object,  which has a positive specificity of 1, and this concept fails to match theinput, then the preference value for the cue will be -9.On the other hand, a very specific preference usually pinpoints the expected entity,i.e., the dead giveaway pairings of role and filler.
Thus, it is quite common for thesepreferences tooverspecify the underlying constraint; for example, cut may expect a toolas an INSTRUMENT, but almost any physical object will suffice.
When a slight relaxationof the preference is satisfiable, a system should take the cautious route, and assumeit has a case of overspecification a d is at worst a weak failure.
Again, the specificityfunction returns a negative value with magnitude quivalent to the specificity of thecomplement of the concept, but this time the result will be a negative number whose22Susan W. McRoy Using Multiple Knowledge Sourcesabsolute value is less than it would be by defaulL When this approach fails, a systemcan safely assume that the entity under consideration is "obviously inappropriate" fora relatively strong expectation, and return the default value.
The default value for aconcept hat is neither especially general nor specific and that fails to match the inputis just -1 times the positive specificity of the concept.The strategy of favoring the most specific information has several advantages.This approach best addresses the concerns of an expanding knowledge base whereone must be concerned not only with competition between preferences but also withthe inevitable gaps in knowledge.
Generally, the more specific information there is,the more complete, and hence more trustworthy, the information is.
Thus, when thereis a clear semantic distinction between the senses and the system has the informationnecessary to identify it, a clear distinction usually emerges in the ratings.
When there isno strong semantic distinction, or there is very little information, preference scores areusually very close, so that the parser must fall back on syntactic preferences, uch asRight Association.
This result provides a simple, sensible means of balancing syntacticand semantic preferences.To see how the cue strengths of frequency information, morphological preferences,collocations, clusters, syntactic preferences, and role-related preferences interact withone another to produce the final ranking of senses, consider the problem of decidingthe correct sense of reached in Example 1 (repeated below):Example 1The agreement reached by the state and the EPA provides for the safe storage of thewaste.According to the system's lexicon, reached has four possible verb senses:?
reach1, as in reach a destination, which has conceptual parentsc-dest-occur ("destination occurrence") and c-arr iving;?
reach2, as in reach for a cookie, which has conceptual parentc-bodypart-act ion;?
reach3, as in reach her by telephone, which has conceptual parentc-comm-event ("communication event"); and?
reach4, as in reach a conclusion, which has conceptual parentc-cause-to-event-change.Figure 16 shows a tabulation of cue strengths for each of these interpretations ofreach in Example 1, when just information in the VP reached by the state and the EPA isconsidered.
The sense reach3 has the highest otal score.
From the table, we see that,at this point in the parse, the only strong source of preferences i  the role information(line 6 of Figure 16).
The derivation of these numbers is shown in Figures 17, 18,and 19, which list the role preferences associated with the possible interpretations ofthe preposition by for reach3, and its two nearest competitors, reach1 and reach4.Together, the data in the tables reveal the following sources of preference strength:The 'arrival' sense (reachl) gains support from the fact that there is asense of by meaning AGENT, which is a role that arrivals expect (line 3 ofcolumn 3 of Figure 17), and the state and the EPA make reasonably goodagents (line 5 of column 3 of Figure 17).23Computational Linguistics Volume 18, Number 1Cue StrengthCue Type  reach1 reach2 reach3 reach4c-dest-occur c-bodypart-action c-comm-event c~cause-to-event-changeFrequencyMorphologyCollocationClusterSyntaxRoles10000411000038-10000461000041TotM 42 39 45 42Figure 16Score tabulations for reached in the VP.reach1Role Preference StrengthPreference Type by1SPATIAL-PROXIMITYby3DIRECTIONRelation-Filler 0 0Filler-Holder 0 0Relation-Holder 0 0Syntax 1 1Strength of PP 37 35Total 38 36by4 by5AGENT INSTRUMENT0 -20 05 01 135 35141 \[ 34Figure 17Role-related preferences of reacht for the preposition by.?
The 'communication' sense (reach3) gains support from the fact thatthere is a sense of by corresponding to the expected role COMMUNICATOR(line 3 of column 3 of Figure 18) and the state and the EPA make verygood agents of communication events (communicators), in particular(line 1 of column 3 of Figure 18), as well as being good agents in general(line 5 of column 3 of Figure 18); however, reach3 is disfavored byfrequency information (line 1 of column 3 of Figure 16).?
The 'event change' (conclude) sense (reach4) gains support from the factthat there is a sense of by corresponding to the expected role CAUSE (line3 of column 3 of Figure 19) and from the fact that the state and the EPAmake good agents (line 5 of column 3 of Figure 19).Although the system favors the 'communication' sense of reach in the VP, for thefinal result, it must balance this information with that provided by the relationshipbetween agreement and the verb phrase.
By the end of the parse, the 'event-change'sense comes to take precedence:* The system completely eliminates the 'destination' sense fromconsideration because it is significantly weaker than all its competitors.24Susan W. McRoy Using Multiple Knowledge Sourcesreach3Role Preference StrengthPreference Type byl by3 by4 by5SPATIAL-PROXIMITY DIRECTION COMMUNICATOR INSTRUMENTRelation-Filler 0 0 5 0Filler-Holder 0 0 0 0Relation-Holder 0 0 5 0Syntax 1 1 1 1Strength of PP 37 35 35 35Total 38 36 46 36Figure 18Role-related preferences of reach3 for the preposition by.reach4Role Preference StrengthPreference Type by1 by3 by4 by5SPATIAL-PROXIMITY DIRECTION CAUSE (AGENT) INSTRUMENTRelation-Filler 0 0 0 0Filler-Holder 0 0 0 0Relation-Holder 0 0 5 0Syntax 1 1 1 1Strength of PP 37 35 35 35Total 38 36 41 36Figure 19Role-related preferences of reach4 for the preposition by.The main cause of this weakness is that (in our system) the role thatagreement would fill, DESTINATION, has no special preference for beingassociated with a c -dest -event  - -  many events allow a DESTINATIONrole.The 'communication' sense loses favor because it does not gain muchsupport from having agreement as either PATIENT or RECIPIENT.
The finalscore of this sense is 52.The 'event-change' sense gains support from having agreement fill itsAFFECTED role, enough that the final strength of the 'event-change' sense,55, ultimately surpasses the final strength of the 'communication' sense.By summing the cue strengths of each possible interpretation i this way andselecting the one with the highest total score, the system decides which sense is the"correct" one for the context.
The strengths of individual components of each inter-pretation contribute to, but do not determine, the strength of the final interpretation,because there are also strengths associated with how well the individual componentsfit together.
No additional weights are necessary, because the specificity values thesystem uses are a direct measure of strength.25Computational Linguistics Volume 18, Number 16.
Results and DiscussionOur goal has been a natural language system that can effectively analyze an arbitraryinput at least to the level of word sense tagging.
Although we have not yet fullyaccomplished this goal, our results are quite encouraging.
Using a lexicon of approx-imately 10,000 roots and 10,000 derivations, the system shows excellent lexical andmorphological coverage.
When tested on a sample of 25,000 words of text from theWall Street Journal, the system covered 98% of non-proper noun, non-abbreviated wordoccurrences (and 91% of all words).
Twelve percent of the senses the system selectedwere derivatives.The semantic interpreter is able to discriminate senses even when the parser cannotproduce a single correct parse.
Figure 20 gives an example of the sense tagging thatthe system gives to the following segment of Wall Street Journal text:Example 7The network also is changing its halftime show to include viewer participation, in anattempt o hold on to its audience through halftime and into the second halves ofgames.
One show will ask viewers to vote on their favorite all-time players throughtelephone polls.Each word is tagged with its part of speech and sense number along with a parentconcept.
For example, the tag \[changing verb_3 (c-replacing)\]  shows that the in-put word is changing, the preferred sense is number 3 of the verb, and this sense fallsunder the concept c-replacing in the hierarchy.
This tagging was produced eventhough the parser was unable to construct a complete and correct syntactic represen-tation of the text.
In fact, when tested on the Wall Street Journal texts (for which therehas been no adaptation or customization aside from processing by a company-namerecognizer \[Rau 1991\]), the system rarely produces a single correct parse; however,the partial parses produced generally cover most of the text at the clause level.
Sincemost semantic preferences appear at this level (and those that do not, do not dependon syntactic analysis), the results of this tagging are encouraging.This example also shows some of the limitations of our system in practice.
Thesystem is unable to recognize the collocation "hold on to" in the first sentence, becauseit lacks a pattern for it.
The system also lacks patterns for the collocations "vote on"and "alMime players" that occur in the second sentence, and as a result, mistakenlytags on as c-temporal-proxim?ty-rel rather than something more appropriate, suchas c-purpose-tel.
These difficulties point out the need for even more knowledge.It is encouraging tonote that, even if our encoding scheme is not entirely "correct"according to human intuition, as long as it is consistent, in theory it should lead tocapabilities that are no worse, with zero customization, than word-based methods forinformation retrieval.
However, having access to sense tags allows for easy improve-ment by more knowledge-intensive m thods.
Although this theory is still untested,there is some preliminary evidence that word sense tagging can improve informationretrieval system performance (Krovetz 1989).To date we have been unable to get a meaningful quantitative assessment of theaccuracy of the system's sense tagging.
We made an unsuccessful attempt at evaluat-ing the accuracy of sense-tagging over a corpus.
First, we discovered that a human"expert" had great difficulty identifying each sense, and that this task was far more te-dious than manual part-of-speech tagging or bracketing.
Second, we questioned whatwe would learn from the evaluation of these partial results, and have since turned our26Susan W. McRoy Using Multiple Knowledge Sources\[the det_l (c-definite-qual) \]\[network noun_2 (c-entertainment-obj c-business-org c-system) \]\[also adv_1 (c-numeric-qual) \]\[is *aux* \]\[changing verb_3 (c-replacing) \]\[ i ts ppnoun_l (c-obj) \]\[halftime noun_l (c-entity) \]\[show c-act-of-verb_showl (c-manifesting) \]\[to ~infl~ \]\[include verb_2 (c-grouping) \]\[viewer c-verb_view2-er (c-entity) \]\[participation c-result-of-being-verb_participatel (c-causal-state) \]\[~comma* *punct~ \]\[in prep_2Z (c-group-part) \]\[an det_l (c-definite-qual) \]\[attempt c-act-of-verb_attemptl (c-attempting) \]\[to *infl~ \]\[hold verb_4 (c-positioning) \]\[on adv_l (c-range-qual c-continuity-qual) \]\[to prep_l (c-destination-rel) \]\[its ppnoun_l (c-obj) \]\[audience noun_l (c-human-group) \]\[through prep_1 (c-course-rel) \]\[halftime noun_l (c-entity) \]\[and coordconj_l (c-conjunction) \]\[into prep_5 (e-engage-in) \]\[the det_l (c-definite-qual) \]\[second c-numword_twol-th (c-order-qual) \]\[halves noun_l (c-portion-part) \]\[of prep_8 (c-stateobject-rel) \]\[games noun_l (c-recreation-obj) \]\[*period~ ~punct~ \]\[one noun_1 (c-entity) \]\[show c-act-of-verb_showl (c-manifesting) \]\[will ~aux~ \]\[ask verb_2 (c-asking) \]\[viewers c-verb_view2-er (c-entity) \]\[to ~infl~ \]\[vote verb_1 (c-selecting) \]\[on prep_4 (c-temporal-proximity-rel) \]\[their ppnoun_1 (c-obj) \]\[favorite adj_l (c-importance-qual c-superiority-qual) \]\[all det_1 (c-quantifier) \]\[~hyphen~ ~punct~ \]\[time noun_1 (c-indef-time-period) \]\[players c-verb_playl-er (c-entity) \]\[through prep_l (c-course-rel) \]\[telephone noun_1 (c-machine) \]\[polls c-act-of-verb_poll1 (c-asking) \]\[~period~ *punct* \]Figure 20A sample sense coding.attention back to evaluating the system with respect o some task, such as informationretrieval.Improving the quality of our sense tagging requires a fair amount of straight-forward but time-consuming work.
This needed work includes filling a number of27Computational Linguistics Volume 18, Number 1gaps in our knowledge sources.
For example, the system needs much more informa-tion about role-related preferences and specialized semantic ontexts.
At present allthis information is collected and coded by hand, although recent work by Ravin (1990)and Dahlgren, McDowell, and Stabler (1989) suggests that the collection of role-relatedinformation may be automatable.Our next step is to evaluate the effect of text coding on an information retrievaltask, by applying traditional term-weighted statistical retrieval methods to the re-coded text.
One intriguing aspect of this approach is that errors in distinguishingsense preferences should not be too costly in this task, so long as the program is fairlyconsistent in its disambiguation f terms in both the source texts and the input queries.7.
ConclusionHaving access to a large amount of information and being able to use it effectivelyare essential for understanding unrestricted texts, such as newspaper articles.
We havedeveloped a substantial knowledge base for text processing, including a word sense-based lexicon that contains both core senses and dynamically triggered entries.
Wehave also created a number of concept-cluster definitions describing common semanticcontexts and a conceptual hierarchy that acts as a sense-disambiguated hesaurus.Our approach to word sense discrimination uses information drawn from theknowledge base and the structure of the text, combining the strongest, most obvioussense preferences created by syntactic tags, word frequencies, collocations, semanticcontext (clusters), selectional restrictions, and syntactic ues.
To apply this informationmost efficiently, the approach introduces a preprocessing phase that uses preferenceinformation available prior to parsing to eliminate some of the lexical ambiguity andestablish baseline preferences.
Then, during parsing, the system combines the baselinepreferences with preferences created by selectional restrictions and syntactic ues toidentify preferred interpretations.
The preference combination mechanism of the sys-tem uses dynamic measures of strength based on specificity, rather than relying onsome fixed, ordered set of rules.There are some encouraging results from applying the system to sense tagging ofarbitrary text.
We expect o evaluate our approach on tasks in information retrieval,and, later, machine translation, to determine the likelihood of achieving substantiveimprovements hrough sense-based semantic analysis.AcknowledgmentsI am grateful to Paul Jacobs for hiscomments and his encouragement of mywork on natural language processing at GE;to George Krupka for helping me integratemy work with TRUMP, and for continuingto improve the system; to Graeme Hirst forhis many comments and suggestions on thisarticle; and to Jan Wiebe and Evan Steeg fortheir comments on earlier drafts.I acknowledge the financial support of theGeneral Electric Company, the University ofToronto, and the Natural Sciences andEngineering Research Council of Canada.ReferencesAltmann, Gerry, and Steedman, Mark(1988).
"Interaction with context duringhuman sentence processing."
Cognition30(3): 191-238.Charniak, Eugene (1983).
"Passing markers:A theory of contextual influence inlanguage comprehension."
CognitiveScience 7(3): 171-190.Church, Kenneth W. (1988).
"A stochasticparts program and noun phrase parser forunrestricted text."
In Proceedings, SecondConference on Applied Natural LanguageProcessing.
Austin, Texas, 136-143.Church, Kenneth W., and Hanks, Patrick(1990).
"Word association norms, mutualinformation, and lexicography.
"Computational Linguistics 16(1): 22-29.Cowie, Anthony P., and Mackin, Ronald(1975).
Verbs with Prepositions and Particles.Volume 1 of Oxford Dictionary of Current28Susan W. McRoy Using Multiple Knowledge SourcesIdiomatic English.
Oxford: OxfordUniversity Press.Cowie, Anthony P.; Mackin, Ronald; andMcCraig, Isabel R. (1983).
Clause andSentence Idioms.
Volume 2 of OxfordDictionary of Current Idiomatic English.Oxford: Oxford University Press.Crain, Stephen, and Steedman, Mark (1985).
"On not being led up the garden path:The use of context by the psychologicalsyntax processor."
In Natural LanguageParsing: Psychological, Computational, ndTheoretical Perspectives, edited byD.
R. Dowty, L. Karttunen, andA.
M. Zwicky, 320-358.
Cambridge,England: Cambridge University Press.Dahlgren, Kathleen; McDowell, Joyce; andStabler, Edward (1989).
"Knowledgerepresentation forcommonsensereasoning with text."
ComputationalLinguistics 15(3): 149-170.De Marcken, Carl G. (1990).
"Parsing theLOB corpus."
In Proceedings, 28th AnnualMeeting of the Association for ComputationalLinguistics.
Pittsburgh, PA, 243-251.Dyer, Michael, and Zernik, Uri (1986).
"Encoding and acquiring meanings forfigurative phrases."
In Proceedings, 24thAnnual Meeting of the Association forComputational Linguistics.
New York, NY,106-111.Fodor, Janet Dean (1978).
"Parsing strategiesand constraints on transformations.
"Linguistic Inquiry 9(3): 427-473.Fodor, Janet Dean, and Frazier, Lyn (1980).
"Is the human sentence parsingmechanism an ATN?"
Cognition 8:417-459.Ford, Marilyn; Bresnan, Joan; and Kaplan,Ronald (1982).
"A competence-basedtheory of syntactic losure."
In The MentalRepresentation f Grammatical Relations,edited by Joan Bresnan, 727-796.Cambridge: The MIT Press.Fox, E.; Nutter, T.; Ahlswede, T.; Evens, M.;and Markowitz, J.
(1988).
"Building alarge thesaurus for information retrieval.
"In Proceedings, Second Conference on AppliedNatural Language Processing.
Austin, Texas,101-108.Frazier, Lyn, and Rayner, Keith (1990).
"Taking on semantic ommitments:Processing multiple meanings vs.multiple senses."
Journal of Memory andLanguage 29(2): 181-200.Garside, Roger; Leech, Geoffrey; andSampson, Geoffrey (1987).
TheComputational Analysis of English: ACorpus-Based Approach.
London: Longman.Gibson, Edward (1990).
"Memory capacityand sentence processing."
In Proceedings,28th Annual Meeting of the Association forComputational Linguistics.
Pittsburgh, PA,39-46.Halliday, Michael, and Hasan, Ruqaiya(1976).
Cohesion i  English.
London:Longman.Hendler, James A.
(1987).
IntegratingMarker-Passing and Problem Solving.Norwood, NJ: Lawrence ErlbaumAssociates.Hirst, Graeme (1987).
Semantic Interpretationand the Resolution of Ambiguity.
Cambridge:Cambridge University Press.Jacobs, Paul S. (1986).
"Language analysis innot-so-limited domains."
In Proceedings,Fall Joint Computer Conference.
Dallas, TX.Jacobs, Paul S. (1987).
"A knowledgeframework for natural languageanalysis."
In Proceedings, TenthInternational Joint Conference on ArtificialIntelligence.
Milan, Italy.Jacobs, Paul S. (1989).
"TRUMP: Atransportable language understandingprogram."
Technical Report CRD89/181,GE Research and Development Center,Schenectady, NY.Janssen, Sylvia (1990).
"Automatic sensedisambiguation with LDOCE: Enrichingsyntactically analyzed corpora withsemantic data."
In Theory and Practice inCorpus Linguistics, edited by Jan Aarts andWillem Meijs, 105-135.
Amsterdam:Rodopi.Kimball, John P. (1973).
"Seven principles ofsurface structure parsing in naturallanguage."
Cognition 2: 15-47.Krovetz, Robert (1989).
"Lexical acquisitionand information retrieval."
In FirstInternational Lexical Acquisition Workshop,edited by Uri Zernik.Kurtzman, Howard S. (1984).
"Studies insyntactic ambiguity resolution."
Doctoraldissertation, Department of Psychology,MIT.
Bloomington, IN: Indiana UniversityLinguistics Club.Magerman, David M., and Marcus,Mitchell P. (1990).
"Parsing a naturallanguage using mutual informationstatistics."
In AAAI-90 Proceedings, EighthNational Conference on Artificial Intelligence,Menlo Park, CA: AAAI Press/The MITPress, 984-989.McRoy, Susan W., and Hirst, Graeme (1990).
"Race-based syntactic attachment.
"Cognitive Science 14(3): 313-354.Morris, Jane (1988).
"Lexical cohesion, thethesaurus, and the structure of text.
"Technical Report CSRI-219, ComputerSystems Research Institute, University ofToronto, Toronto.Morris, Jane, and Hirst, Graeme (1991).29Computational Linguistics Volume 18, Number 1"Lexical cohesion computed by thesauralrelations as an indicator of the structureof text."
Computational Linguistics 17(1):21-48.Procter, Paul, editor (1978).
LongmanDictionary of Contemporary English.
Harlow:Longman Group Ltd.Rau, Lisa F. (1991).
"Extracting companynames from text."
In IEEE AI ApplicationsConference ( CAIA).Rau, Lisa E; Jacobs, Paul S.; and Zernik, Uri(1989).
"Information extraction and textsummarization using linguisticknowledge acquisition."
InformationProcessing and Management 25(4): 419-428.Ravin, Yael (1990).
"Disambiguating andinterpreting verb definitions."
InProceedings, 28th Annual Meeting of theAssociation for Computational Linguistics.Pittsburgh, PA, 260-267.Rayner, Keith; Carlson, Marcia; and Frazier,Lyn (1983).
"The interaction of syntax andsemantics during sentence processing: Eyemovements in the analysis of semanticallybiased sentences."
Journal of VerbalLearning and Verbal Behavior 22: 358-374.Schank, Roger C., and Abelson, Robert P.(1977).
Scripts, Plans, Goals, andUnderstanding.
Halsted, NJ: LawrenceErlbaum.Schubert, Lenhart (1986).
"Are therepreference trade-offs in attachmentdecisions?"
In Proceedings, NationalConference on Artificial Intelligence(AAAI-86).
Philadelphia, PA, 601-605.Shieber, Stuart M. (1983).
"Sentencedisambiguation by a shift-reduce parsingtechnique."
In Proceedings, 21st AnnualMeeting of the Association for ComputationalLinguistics.
Cambridge, MA, 113-118.Simpson, Greg B., and Burgess, Curt (1988).
"Implications of lexical ambiguityresolution for word recognition andcomprehension."
In Lexical AmbiguityResolution, edited by Steven L. Small,Garrison W. Cottrell, and MichaelK.
Tanenhaus, 271-288.
San Mateo, CA:Morgan Kaufmann Publishers.Smadja, Frank A., and McKeown,Kathleen R. (1990).
"Automaticallyextracting and representing collocationsfor language generation."
In Proceedings,28th Annual Meeting of the Association forCompuh~tional Linguistics.
Pittsburgh, PA,252-259.Stock, Oliviero (1989).
"Parsing withflexibility, dynamic strategies, and idiomsin mind."
Computational Linguistics 15(1):1-18.Whittemore, Greg; Ferrara, Kathleen; andBrunner, Hans (1990).
"Empirical study ofpredictive powers of simple attachmentschemes for post-modifier prepositionalphrases."
In Proceedings, 28th AnnualMeeting of the Association for ComputationalLinguistics.
Pittsburgh, PA, 23-30.Wilks, Yorick; Huang, Xiuming; and Fass,Dan (1985).
"Syntax, preference, and rightattachment."
In Proceedings, NinthInternational Joint Conference on ArtificialIntelligence.
Los Angeles, CA.Zernik, Uri (1990).
"Tagging word senses incorpus: The needle in the haystackrevisited."
Technical Report 90CRD198,GE Research and Development Center,Schenectedy, NY.
In Proceedings, AAAISymposium on Text-Based Intelligent Systems.Stanford, CA, 25-29.30
