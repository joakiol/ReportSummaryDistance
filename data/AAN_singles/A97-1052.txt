Automat ic  Extract ion of Subcategorizat ion from CorporaTed Br i scoe  John  Car ro l lComputer  Laboratory  Cognitive and Comput ing  SciencesUniversity of Cambridge University of SussexPembroke Street, Cambridge CB2 3QG, UK Br ighton BN1 9QH, UKe jb@cl ,  cam.
ac.
uk j otto.
car ro l l@cogs ,  susx .
ac .
ukAbst rac tWe describe a novel technique and imple-mented system for constructing a subcate-gorization dictionary from textual corpora.Each dictionary entry encodes the relativefrequency of occurrence of a comprehen-sive set of subcategorization classes for En-glish.
An initial experiment, on a sampleof 14 verbs which exhibit multiple comple-mentation patterns, demonstrates that thetechnique achieves accuracy comparable toprevious approaches, which are all limitedto a highly restricted set of subcategoriza-tion classes.
We also demonstrate hat asubcategorization dictionary built with thesystem improves the accuracy of a parserby an appreciable amount 1.1 Mot ivat ionPredicate subcategorization is a key component ofa lexical entry, because most, if not all, recent syn-tactic theories 'project' syntactic structure from thelexicon.
Therefore, a wide-coverage parser utilizingsuch a lexicalist grammar must have access to anaccurate and comprehensive dictionary encoding (ata minimum) the number and category of a predi-cate's arguments and ideally also information aboutcontrol with predicative arguments, emantic selec-tion preferences on arguments, and so forth, to allowthe recovery of the correct predicate-argument struc-ture.
If the parser uses statistical techniques to rankanalyses, it is also critical that the dictionary encodethe relative frequency of distinct subcategorizationclasses for each predicate.1This work was supported by UK DTI/SALTproject 41/5808 'Integrated Language Database', CECTelematics Applications Programme project LE1-211i'SPARKLE: Shallow PARsing and Knowledge xtractionfor Language Engineering', and by SERC/EPSRC Ad-vanced Fellowships to both authors.
We would like tothank the COMLEX Syntax development team for al-lowing us access to pre-release data (for an early exper-iment), and for useful feedback.Several substantial machine-readable subcatego-rization dictionaries exist for English, either builtlargely automatically from machine-readable v r-sions of conventional learners' dictionaries, or manu-ally by (computational) linguists (e.g.
the Alvey NLTools (ANLT) dictionary, Boguraev et al (1987);the COMLEX Syntax dictionary, Grishman et al(1994)).
Unfortunately, neither approach can yield agenuinely accurate or comprehensive computationallexicon, because both rest ultimately on the manualefforts of lexicographers / linguists and are, there-fore, prone to errors of omission and commissionwhich are hard or impossible to detect automatically(e.g.
Boguraev & Briscoe, 1989; see also section 3.1below for an example).
Furthermore, manual encod-ing is labour intensive and, therefore, it is costly toextend it to neologisms, information ot currentlyencoded (such as relative frequency of different sub-categorizations), or other (sub)languages.
Theseproblems are compounded by the fact that predi-cate subcategorization s closely associated to lexicalsense and the senses of a word change between cor-pora, sublanguages and/or subject domains (Jensen,1991).In a recent experiment with a wide-coverage pars-ing system utilizing a lexicalist grammatical frame-work, Briscoe & Carroll (1993) observed that halfof parse failures on unseen test data were causedby inaccurate subcategorization information in theANLT dictionary.
The close connection betweensense and subcategorization and between subject do-main and sense makes it likely that a fully accurate'static' subcategorization dictionary of a language isunattainable in any case.
Moreover, although Sch-abes (1992) and others have proposed 'lexicalized'probabilistic grammars to improve the accuracy ofparse ranking, no wide-coverage parser has yet beenconstructed incorporating probabilities of differentsubcategorizations for individual predicates, becauseof the problems of accurately estimating them.These problems uggest that automatic onstruc-tion or updating of subcategorization dictionariesfrom textual corpora is a more promising avenueto pursue.
Preliminary experiments acquiring a few356verbal subcategorization classes have been reportedby Brent (1991, 1993), Manning (1993), and Ush-ioda et al (1993).
In these experiments the max-imum number of distinct subcategorization classesrecognized is sixteen, and only Ushioda et al at-tempt to derive relative subcategorization frequencyfor individual predicates.We describe a new system capable of distinguish-ing 160 verbal subcategorization classes--a supersetof those found in the ANLT and COMLEX Syn-tax dictionaries.
The classes also incorporate infor-mation about control of predicative arguments andalternations uch as particle movement and extra-position.
We report an initial experiment whichdemonstrates that this system is capable of acquir-ing the subcategorization classes of verbs and therelative frequencies of these classes with compara-ble accuracy to the less ambitious extant systems.We achieve this performance by exploiting a moresophisticated robust statistical parser which yieldscomplete though 'shallow' parses, a more compre-hensive subcategorization class classifier, and a pri-or/ estimates of the probability of membership ofthese classes.
We also describe a small-scale x-periment which demonstrates that subcategorizationclass frequency information for individual verbs canbe used to improve parsing accuracy.2 Descr ip t ion  o f  the  System2.1 Overv iewThe system consists of the following six componentswhich are applied in sequence to sentences contain-ing a specific predicate in order to retrieve a set ofsubcategorization classes for that predicate:1.
A tagger ,  a first-order HMM part-of-speech(PoS) and punctuation tag disambiguator, isused to assign and rank tags for each word andpunctuation token in sequences ofsentences (El-worthy, 1994).2.
A lemmat izer  is used to replace word-tagpairs with lemma-tag pairs, where a lemma isthe morphological base or dictionary headwordform appropriate for the word, given the PoSassignment made by the tagger.
We use an en-hanced version of the GATE project stemmer(Cunningham et al, 1995).3.
A probabi l i s t ic  LR  parser ,  trained on a tree-bank, returns ranked analyses (Briscoe &: Car-roll, 1993; Carroll, 1993, 1994), using a gram-mar written in a feature-based unification gram-mar formalism which assigns 'shallow' phrasestructure analyses to tag networks (or 'lattices')returned by the tagger (Briscoe & Carroll, 1994,1995; Carroll & Briscoe, 1996).4.
A pat ternset  ext rac tor  which extracts ub-categorization patterns, including the syntac-tic categories and head lemmas of constituents,from sentence subanalyses which begin/end atthe boundaries of (specified) predicates.5.
A pat tern  classif ier which assigns patterns inpatternsets to subcategorization classes or re-jects patterns as unclassifiable on the basis ofthe feature values of syntactic categories andthe head lemmas in each pattern.6.
A pat ternsets  eva luator  which evaluates setsof patternsets gathered for a (single) predicate,constructing putative subcategorization e triesand filtering the latter on the basis of their re-liability and likelihood.For example, building entries for attribute, andgiven that one of the sentences in our data was (la),the tagger and lemmatizer return (lb).
(1) a He attributed his failure, he said, tono< blank> one buying his books.b he_PPHS1 attribute_VVD his_APP$ fail-ure_NN1 ,_, he_PPHS1 say_VVD ,_, to_IIno<blank>one_PN buy_ VVG his_APP$book_NN2(lb) is parsed successfully by the probabilistic LRparser, and the ranked analyses are returned.
Thenthe patternset extractor locates the subanalyses con-taining attribute and constructs a patternset.
Thehighest ranked analysis and pattern for this exampleare shown in Figure 12 .
Patterns encode the valueof the VSUBCAT feature from the VP rule and thehead lemma(s) of each argument.
In the case of PP(I)2) arguments, the pattern also encodes the value ofPSUBCAT from the PP rule and the head lemma(s)of its complement(s).
In the next stage of process-ing, patterns are classified, in this case giving thesubcategorization class corresponding to transitiveplus PP with non-finite clausal complement.The system could be applied to corpus data byfirst sorting sentences into groups containing in-stances of a specified predicate, but we use a differentstrategy since it is more efficient o tag, lemmatizeand parse a corpus just once, extracting patternsetsfor all predicates in each sentence; then to classifythe patterns in all patternsets; and finally, to sortand recombine patternsets into sets of patternsets,one set for each distinct predicate containing pat-ternsets of just the patterns relevant o that predi-cate.
The tagger, lemmatizer, grammar and parserhave been described elsewhere (see previous refer-ences), so we provide only brief relevant details here,concentrating on the description of the components2The analysis hows only category aliases rather thansets of feature-value pairs.
Ta represents a text adjunctdelimited by commas (Nunberg 1990; Briscoe ~ Carroll,1994).
Tokens in the patternset are indexed by sequen-tial position in the sentence so that two or more tokensof the same type can be kept distinct in patterns.357(Tp(V2 (N2 he_PPHSI)(Vl (V0 attribute_VVD)(N2 (DT his_APP$)(NI(NO (NO failure_NNl)(Ta (Pu ,_,)(V2 (N2 he_PPHSi)(Vl (VO say_VVD))) (Pu , _ , ) ) ) ) )(P2(PI (P0 to_II)(N2 no<blank>one_PN)(1 ( ( ( (he : l  PPHS1))(VSUBCAT NP_PP)( (a t t r ibute :6  VVD))( ( fa i lu re :8  NN1))((PSUBCAT SING)((to:9 II))((no<blank>one:lO PN))((buy:ll VVG))))i))(Vl (V0 buy_WG) (N2 (DT his_APP$) (N1 (NO book_NN2)))))))))Figure 1: Highest-ranked analysis and patternset for (lb)of the system that are new: the extractor, classifierand evaluator.The grammar consists of 455 phrase structurerule schemata in the format accepted by the parser(a syntactic variant of a Definite Clause Grammarwith iterative (Kleene) operators).
It is 'shallow' inthat no atof which thetempt is made to fully anal-yse unbounded ependencies.
However, the distinc-tion between arguments and adjuncts is expressed,following X-bar theory (e.g.
Jackendoff, 1977), byChomsky-adjunction t  maximal projections of ad-juncts (XP --* XP Adjunct) as opposed to 'govern-ment' of arguments (i.e.
arguments are sisters withinX1 projections; X1 ~ X0 Argl... ArgN).
Further-more, all analyses are rooted (in S) so the grammarassigns global, shallow and often 'spurious' analy-ses to many sentences.
There are 29 distinct val-ues for VSUBCAT and 10 for PSUBCAT; these areanalysed in patterns along with specific closed-classhead lemmas of arguments, uch as it (dummy sub-jects), whether (wh-complements), and so forth, toclassify patterns as evidence for one of the 160 sub-categorization classes.
Each of these classes can beparameterized for specific predicates by, for exam-ple, different prepositions or particles.
Currently,the coverage of this grammar--the proportion of sen-tences for which at least one analysis is found--is79% when applied to the Susanne corpus (Sampson,1995), a 138K word treebanked and balanced subsetof the Brown corpus.
Wide coverage is importantsince information is acquired only from successfulparses.
The combined throughput of the parsingcomponents on a Sun UltraSparc 1/140 is around50 words per CPU second.2.2 The Extractor~ Classifier and EvaluatorThe extractor takes as input the ranked analysesfrom the probabilistic parser.
It locates the subanal-yses around the predicate, finding the constituentsidentified as complements inside each subanalysis,and the subject clause preceding it.
Instances ofpassive constructions are recognized and treated spe-cially.
The extractor eturns the predicate, theVSUBCAT value, and just the heads of the comple-ments (except in the case of PPs, where it returnsthe PSUBCAT value, the preposition head, and theheads of the PP's complements).The subcategorization classes recognized by theclassifier were obtained by manually merging theclasses exemplified in the COMLEX Syntax andANLT dictionaries and adding around 30 classesfound by manual inspection of unclassifiable pat-terns for corpus examples during development of thesystem.
These consisted of some extra patterns forphrasM verbs with complex complementation a dwith flexible ordering "of the preposition/particle,some for non-passivizable patterns with a surfacedirect object, and some for rarer combinations ofgoverned preposition and complementizer combina-tions.
The classifier filters out as unclassifiablearound 15% of patterns found by the extractor whenrun on all the patternsets extracted from the Su-sanne corpus.
This demonstrates the value of theclassifier as a filter of spurious analyses, as well asproviding both translation between extracted pat-terns and two existing subcategorization dictionar-ies and a definition of the target subcategorizationdictionary.The evaluator builds entries by taking the pat-terns for a given predicate built from successfulparses and records the number of observations ofeach subcategorization class.
Patterns provide sev-eral types of information which can be used to rankor select between patterns in the patternset for agiven sentence xemplifying an instance of a pred-icate, such as the ranking of the parse from whichit was extracted or the proportion of subanalysessupporting a specific pattern.
Currently, we simplyselect he pattern supported by the highest rankedparse.
However, we are experimenting with alterna-tive approaches.
The resulting set of putative classesfor a predicate are filtered, following Brent (1993),358by hypothesis testing on binomial frequency data.Evaluating putative ntries on binomial frequencydata requires that we record the total number ofpatternsets n for a given predicate, and the numberof these patternsets containing a pattern support-ing an entry for given class m. These figures arestraightforwardly computed from the output of theclassifier; however, we also require an estimate of theprobability that a pattern for class i will occur witha verb which is not a member of subcategorizationclass i. Brent proposes estimating these probabili-ties experimentally on the basis of the behaviour ofthe extractor.
We estimate this probability more di-rectly by first extracting the number of verbs whichare members of each class in the ANLT dictionary(with intuitive estimates for the membership of thenovel classes) and converting this to a probability ofclass membership by dividing by the total number ofverbs in the dictionary; and secondly, by multiplyingthe complement of these probabilities by the proba-bility of a pattern for class i, defined as the numberof patterns for i extracted from the Susanne corpusdivided by the total number of patterns.
So, p(v -i),the probability of verb v not of class i occurring witha pattern for class i is:p(v -i) = (1-lanlt-verbs-in-elass-i l  Ipatterns-f ?r-illanlt_verbsl ) IpatternslThe binomial distribution gives the probability of anevent with probability p happening exactly m timesout of n attempts:n!P(m, n,p) - m!
(n - rn)!
pro(1 - p)n-mThe probability of the event happening m or moretimes is:P(m+,n,p)  = ~ P(i,n,p)i~mThus P(m,n,p(v -i)) is the probability that m ormore occurrences of patterns for i will occur witha verb which is not a member of i, given n occur-rences of that verb.
Setting a threshold of less thanor equal to 0.05 yields a 95% or better confidencethat a high enough proportion of patterns for i havebeen observed for the verb to be in class i 3.2.3 Discuss ionOur approach to acquiring subcategorization classesis predicated on the following assumptions:?
most sentences will not allow the application ofall possible rules of English complementation;?
some sentences will be unambiguous even giventhe indeterminacy of the grammar4;3Brent (1993:249-253) provides a detailed explana-tion and justification for the use of this measure.4In fact, 5% of sentences in Susanne are assigned onlya single analysis by the grammar.?
many incorrect analyses will yield patternswhich are unclassifiable, and are thus filteredout;?
arguments of a specific verb will occur withgreater frequency than adjuncts (in potentialargument positions);?
the patternset generator will incorrectly outputpatterns for certain classes more often than oth-ers; and?
even a highest ranked pattern for i is only aprobabilistic ue for membership of i, so mem-bership should only be inferred if there areenough occurrences of patterns for i in the datato outweigh the error probability for i.This simple automated, hybrid linguis-tic/statistical approach contrasts with the manuallinguistic analysis of the COMLEX Syntax lexicog-raphers (Meyers et al, 1994), who propose five cri-teria and five heuristics for argument-hood and sixcriteria and two heuristics for adjunct-hood, culledmostly from the linguistics literature.
Many of theseare not exploitable automatically because they reston semantic judgements which cannot (yet) be madeautomatically: for example, optional arguments areoften 'understood' or implied if missing.
Others aresyntactic tests involving diathesis alternation possi-bilities (e.g.
passive, dative movement, Levin (1993))which require recognition that the 'same' argument,defined usually by semantic lass / thematic role, isoccurring across argument positions.
We hope to ex-ploit this information where possible at a later stagein the development ofour approach.
However, recog-nizing same/similar arguments requires considerablequantities of lexical data or the ability to back-off tolexical semantic lasses.
At the moment, we exploitlinguistic information about the syntactic type, obli-gatoriness and position of arguments, as well as theset of possible subcategorization classes, and com-bine this with statistical inference based on the prob-ability of class membership and the frequency andreliability of patterns for classes.3 Exper imenta l  Eva luat ion3.1 Lex icon Eva luat ion  - MethodIn order to test the accuracy of our system (as de-veloped so far) and to provide empirical feedbackfor further development, we took the Susanne, SEC(Taylor & Knowles, 1988) and LOB corpora (Gar-side et al, 1987)--a total of 1.2 million words--andextracted all sentences containing an occurrence ofone of fourteen verbs, up to a maximum of 1000citations of each.
These verbs, listed in Figure 2,were chosen at random, subject to the constraintthat they exhibited multiple complementation pat-terns.
The sentences containing these verbs weretagged and parsed automatically, and the extractor,classifier and evaluator were applied to the resulting359successful analyses.
The citations from which entrieswere derived totaled approximately 70K words.The results were evaluated against a merged entryfor these verbs from the ANLT and COMLEX Syn-tax dictionaries, and also against a manual analysisof the corpus data for seven of the verbs.
The processof evaluating the performance of the system relativeto the dictionaries could, in principle, be reduced toan automated report of type precision (percentage ofcorrect subcategorization classes to all classes found)and recall (perCentage ofcorrect classes found in thedictionary entry).
However, since there are disagree-ments between the dictionaries and there are classesfound in the corpus data that are not contained ineither dictionary, we report results relative both to amanually merged entry from ANLT and COMLEX,and also, for seven of the verbs, to a manual anal-ysis of the actual corpus data.
The latter analysisis necessary because precision and recall measuresagainst he merged entry will still tend to yield in-accurate results as the system cannot acquire classesnot exemplified in the data, and may acquire classesincorrectly absent from the dictionaries.We illustrate these problems with reference toseem, where there is overlap, but not agreementbetween the COMLEX and ANLT entries.
Thus,both predict hat seem will occur with a sententialcomplement and dummy subject, but only ANLTpredicts the possibility of a 'wh' complement andonly COMLEX predicts the (optional) presence ofa PP\[to\] argument with the sentential complement.One ANLT entry covers two COMLEX entries giventhe different treatment of the relevant complementsbut the classifier keeps them distinct.
The corpusdata for seem contains examples of further classeswhich we judge valid, in which seem can take aPP\[to\] and infinitive complement, as in he seems tome to be insane, and a passive participle, as in heseemed depressed.
This comparison illustrates theproblem of errors of omission common to computa-tional lexicons constructed manually and also frommachine-readable dictionaries.
All classes for seemare exemplified in the corpus data, but for ask, forexample, eight classes (out of a possible 27 in themerged entry) are not present, so comparison onlyto the merged entry would give an unreasonably lowestimate of recall.3.2  Lex icon  Eva luat ion  - Resu l t sFigure 2 gives the raw results for the merged en-tries and corpus analysis on each verb.
It shows thenumber of true positives (TP), correct classes pro-posed by our system, false positives (FP), incorrectclasses proposed by our system, and false negatives(FN), correct classes not proposed by our system,as judged against he merged entry, and, for sevenof the verbs, against the corpus analysis.
It alsoshows, in the final column, the number of sentencesfrom which classes were extracted.360PrecisionRecallDictionary Corpus(14 verbs) (7 verbs)65.7% 76.6%35.5% 43.4%Figure 3: Type precision and recallRanking Accuracyask 75 .O%begin 100.0%believe 66.7%cause 100.0%give 70.0%seem 75.0%swing 83.3%Mean 81.4%Figure 4: Ranking accuracy of classesFigure 3 gives the type precision and recall ofour system's recognition of subcategorization classesas evaluated against he merged dictionary entries(14 verbs) and against he manually analysed cor-pus data (7 verbs).
The frequency distribution ofthe classes is highly skewed: for example for believe,there are 107 instances of the most common class inthe corpus data, but only 6 instances in total of theleast common four classes.
More generally, for themanually analysed verbs, almost 60% of the falsenegatives have only one or two exemplars each inthe corpus citations.
None of them are returned bythe system because the binomial filter always rejectsclasses hypothesised on the basis of such little evi-dence.In Figure 4 we estimate the accuracy with whichour system ranks true positive classes against thecorrect ranking for the seven verbs whose corpus in-put was manually analysed.
We compute this mea-sure by calculating the percentage ofpairs of classesat positions (n, m) s.t.
n < m in the system rank-ing that are ordered the same in the correct ranking.This gives us an estimate of the accuracy of the rel-ative frequencies of classes output by the system.For each of the seven verbs for which we under-took a corpus analysis, we calculate the token recallof our system as the percentage (over all exemplars)of true positives in the corpus.
This gives us an es-timate of the parsing performance that would resultfrom providing a parser with entries built using thesystem, shown in Figure 5.Further evaluation of the results for these sevenverbs reveals that the filtering phase is the weaklink in the systerri.
There are only 13 true negativeswhich the system failed to propose, each exemplifiedin the data by a mean of 4.5 examples.
On the otherhand, there are 67 false negatives upported by anestimated mean of 7.1 examples which should, ide-askbeginbelievecauseexpectfindgivehelplikemoveproduceprovideseemswingTotalsMerged EntryTP FP \[ FN9 0 184 1 74 4 112 3 66 5 35 7 155 2 116 3 83 2 74 3 92 1 33 2 68 1 44 0 1065 34 118Corpus DataTP FP FN9 0 104 1 74 4 82 3 55 2 58 1 44 0 836 11 47No.
ofSentences39031123095223645639223228217152217534454149Figure 2: Raw results for test of 14 verbsaskbeginbelievecausegiveseemswingMeanToken Recall78.5%73.8%34.5%92.1%92.2%84.7%39.2%80.9%Figure 5: Token recallally, have been accepted by the filter, and 11 falsepositives which should have been rejected.
The per-formance of the filter for classes with less than 10exemplars is around chance, and a simple heuris-tic of accepting all classes with more than 10 exem-plars would have produced broadly similar resultsfor these verbs.
The filter may well be performingpoorly because the probability of generating a sub-categorization class for a given verb is often lowerthan the error probability for that class.3.3 Parsing EvaluationIn addition to evaluating the acquired subcategoriza-tion information against existing lexical resources,we have also evaluated the information in the con-text of an actual parsing system.
In particular wewanted to establish whether the subcategorizationfrequency information for individual verbs could beused to improve the accuracy of a parser that usesstatistical techniques to rank analyses.The experiment used the same probabilistic parserand tag sequence grammar as are present in theacquisition system (see references above)--althoughthe experiment does not in any way rely on the'Baseline'LexicalisedMean Recall Precisioncrossings1.00 70.7% 72.3%0.93 71.4% 72.9%Figure 6: GEIG evaluation metrics for parser againstSusanne bracketingsparsers or grammars being the same.
We ran-domly selected a test set of 250 in-coverage sen-tences (of lengths 3-56 tokens, mean 18.2) from theSusanne treebank, retagged with possibly multipletags per word, and measured the 'baseline' accu-racy of the unlexicalized parser on the sentences us-ing the now standard PARSEVAL/GEIG evaluationmetrics of mean crossing brackets per sentence and(unlabelled) bracket recall and precision (e.g.
Gr-ishman et al, 1992); see figure 65.
Next, we col-lected all words in the test corpus tagged as possi-bly being verbs (giving a total of 356 distinct lem-mas) and retrieved all citations of them in the LOBcorpus, plus Susanne with the 250 test sentencesexcluded.
We acquired subcategorization and as-sociated frequency information from the citations,in the process uccessfully parsing 380K words.
Wethen parsed the test set, with each verb subcate-gorization possibility weighted by its raw frequencyscore, and using the naive add-one smoothing tech-nique to allow for omitted possibilities.
The GEIGmeasures for the lexicalized parser show a 7% im-provement in the crossing bracket score (figure 6).Over the existing test corpus this is not statisti-5Carroll & Briscoe (1996) use the same test set, al-though the baseline results reported here differ slightlydue to differences in the mapping from parse trees toSusanne-compatible racketings.361cally significant at the 95% level (paired t-test, 1.21,249 dr, p = 0.11)--although if the pattern of differ-ences were maintained over a larger test set of 470sentences it would be significant.
We expect hata more sophisticated smoothing technique, a largeracquisition corpus, and extensions to the system todeal with nominal and adjectival predicates wouldimprove accuracy still further.
Nevertheless, thisexperiment demonstrates that lexicalizing a gram-mar/parser with subcategorization frequencies canappreciably improve the accuracy of parse ranking.4 Re la ted  WorkBrent's (1993) approach to acquiring subcategoriza-tion is based on a philosophy of only exploiting un-ambiguous and determinate information in unanal-ysed corpora.
He defines a number of lexical pat-terns (mostly involving closed class items, such aspronouns) which reliably cue one of five subcatego-rization classes.
Brent does not report comprehen-sive results, but for one class, sentential complementverbs, he achieves 96% precision and 76% recall atclassifying individual tokens of 63 distinct verbs asexemplars or non-exemplars of this class.
He doesnot attempt to rank different classes for a given verb.Ushioda et al (1993) utilise a PoS tagged corpusand finite-state NP parser to recognize and calcu-late the relative frequency of six subcategorizationclasses.
They report an accuracy rate of 83% (254errors) at classifying 1565 classifiable tokens of 33distinct verbs in running text and suggest that in-correct noun phrase boundary detection accounts forthe majority of errors.
They report hat for 32 verbstheir system correctly predicts the most frequentclass, and for 30 verbs it correctly predicts the sec-ond most frequent class, if there was one.
Our sys-tem rankings include all classes for each verb, froma total of 160 classes, and average 81.4% correct.Manning (1993) conducts a larger experiment,also using a PoS tagged corpus and a finite-stateNP parser, attempting to recognize sixteen distinctcomplementation patterns.
He reports that for a testsample of 200 tokens of 40 verbs in running text, theacquired subcategorization dictionary listed the ap-propriate ntry for 163 cases, giving a token recall of82% (as compared with 80.9% in our experiment).He also reports a comparison of acquired entries forthe verbs to the entries given in the Oxford AdvancedLearner's Dictionary of Current English (Hornby,1989) on which his system achieves a precision of90% and a recall of 43%.
His system averages 3.48subentries (maximum 10)--less then half the num-ber produced in our experiment.
It is not clear whatlevel of evidence the performance of Manning's ys-tem is based on, but the system was applied to 4.1million words of text (c.f.
our 1.2 million words) andthe verbs are all common, so it is likely that consid-erably more exemplars of each verb were available.5 Conc lus ions  and  Fur ther  WorkThe experiment and comparison reported above sug-gests that our more comprehensive subcategoriza-tion class extractor is able both to assign classesto individual verbal predicates and also to rankthem according to relative frequency with compa-rable accuracy to extant systems.
We have alsodemonstrated that a subcategorization dictionarybuilt with the system can improve the accuracy of aprobabilistic parser by an appreciable amount.The system we have developed is straightfor-wardly extensible to nominal and adjectival pred-icates; the existing grammar distinguishes nominaland adjectival arguments from adjuncts tructurally,so all that is required is extension of the classi-fier.
Developing an analogous ystem for anotherlanguage would be harder but not infeasible; sim-ilar taggers and parsers have been developed for anumber of languages, but no extant subcategoriza-tion dictionaries exist to our knowledge, thereforethe lexical statistics we utilize for statistical filter-ing would need to be estimated, perhaps using thetechnique described by Brent (1993).
However, theentire approach to filtering needs improvement, asevaluation of our results demonstrates that it is theweakest link in our current system.Our system needs further refinement o nar-row some subcategorization classes, for example, tochoose between differing control options with pred-icative complements.
It also needs supplementingwith information about diathesis alternation pos-sibilities (e.g.
Levin, 1993) and semantic selectionpreferences on argument heads.
Grishman & Ster-ling (1992), Poznanski & Sanfilippo (1993), Resnik(1993), Ribas (1994) and others have shown that itis possible to acquire selection preferences from (par-tially) parsed ata.
Our system already gathers headlemmas in patterns, o any of these approaches couldbe applied, in principle.
In future work, we intend toextend the system in this direction.
The ability torecognize that argument slots of different subcatego-rization classes for the same predicate share seman-tic restrictions/preferences would assist recognitionthat the predicate undergoes pecific alternations,this in turn assisting inferences about control, equiand raising (e.g.
Boguraev & Briscoe, 1987).Re ferencesBoguraev, B.
& Briscoe, E. 1987.
Large lexiconsfor natural language processing: utilising the gram-mar coding system of the Longman Dictionary ofContemporary English.
Computational Linguistics13.4: 219-240.Boguraev, B.
& Briscoe, E. 1989.
Introduction.
InBoguraev, B.
& Briscoe, E. eds.
Computational Lex-icography for Natural Language Processing.
Long-man, London: 1-40.Boguraev, B., Briscoe, E., Carroll, J., Carter, D.362& Grover, C. 1987.
The derivation of a gram-matically-indexed lexicon from the Longman Dictio-nary of Contemporary English.
In Proceedings ofthe25th Annual Meeting of the Association for Compu-tational Linguistics, Stanford, CA.
193-200.Brent, M. 1991.
Automatic acquisition ofsubcatego-rization frames from untagged text.
In Proceedingsof the 29th Annual Meeting of the Association forComputational Linguistics, Berkeley, CA.
209-214.Brent, M. 1993.
From grammar to lexicon: unsu-pervised learning of lexical syntax.
ComputationalLinguistics 19.3: 243-262.Briscoe, E. & Carroll, J.
1993.
Generalised proba-bilistic LR parsing for unification-based grammars.Computational Linguistics 19.1: 25-60.Briscoe, E. & Carroll, J.
1994.
Parsing (with) punc-tuation.
Rank Xerox Research Centre, Grenoble,MLTT-TR-007.Briscoe, E. & Carroll, J.
1995.
Developing and eval-uating a probabilistic LR parser of part-of-speechand punctuation labels.
In Proceedings of the ~thA CL/SIGPARSE International Workshop on Pars-ing Technologies, Prague, Czech Republic.
48-58.Carroll, J.
1993.
Practical unification-based parsingof natural language.
Cambridge University Com-puter Laboratory, TR-224.Carroll, J.
1994.
Relating complexity to practicalperformance in parsing with wide-coverage unifica-tion grammars.
In Proceedings of the 32nd AnnualMeeting of the Association for Computational Lin-guistics, NMSU, Las Cruces, NM.
287-294.Carroll, J.
& Briscoe, E. 1996.
Apportioning de-velopment effort in a probabilistic LR parsing sys-tem through evaluation.
In Proceedings of the ACLSIGDAT Conference on Empirical Methods in Natu-ral Language Processing, University of Pensylvania,Philadelphia, PA. 92-100.Carroll, J.
& Grover, C. 1989.
The derivationof a large computational lexicon for English fromLDOCE.
In Boguraev, B. and Briscoe, E. eds.
Com-putational Lexicography for Natural Language Pro-cessing.
Longman, London: 117-134.Cunningham, H., Gaizauskas, R. & Wilks, Y.
1995.A general architecture for text engineering (GATE)- a new approach to language R~4D.
Research memoCS-95-21, Department of Computer Science, Univer-sity of Sheffield, UK.de Marcken, C. 1990.
Parsing the LOB corpus.
InProceedings of the 28th Annual Meeting of the As-sociation for Computational Linguistics, Pittsburgh,PA.
243-251.Elworthy, D. 1994.
Does Baum-Welch re-estimationhelp taggers?.
In Proceedings of the ~th Conf.
Ap-plied NLP, Stuttgart, Germany.Garside, R., Leech, G. & Sampson, G. 1987.
Thecomputational nalysis of English: A corpus-basedapproach.
Longman, London.Grishman, R., Macleod, C. & Meyers, A.
1994.Comlex syntax: building a computational lexi-con.
In Proceedings of the International Conferenceon Computational Linguistics, COLING-94, Kyoto,Japan.
268-272.Grishman, R., Macleod, C. & Sterling, J.
1992.Evaluating parsing strategies using standardizedparse files.
In Proceedings of the 3rd A CLConference on Applied Natural Language Process-ing, Trento, Italy.
156-161.Grishman, R. & Sterling, J.
1992.
Acquisition ofselectional patterns.
In Proceedings of the Inter-national Conference on Computational Linguistics,COLING-92, Nantes, France.
658-664.Jackendoff, R. 1977.
X-bar syntax.
MIT Press;Cambridge, MA..Jensen, K. 1991.
A broad-coverage natural anguageanalysis ystem.
In M. Tomita eds.
Current Issuesin Parsing Technology.
Kluwer, Dordrecht.Levin, B.
1993.
Towards a lexical organization ofEnglish verbs.
Chicago University Press, Chicago.Manning, C. 1993.
Automatic acquisition of a largesubcategorisation dictionary from corpora.
In Pro-ceedings of the 31st Annual Meeting of the Asso-ciation for Computational Linguistics, Columbus,Ohio.
235-242.Meyers, A., Macleod, C. & Grishman, R. 1994.Standardization of the complement adjunct distinc-tion.
New York University, Ms.Nunberg, G. 1990.
The linguistics of punctuation.CSLI Lecture Notes 18, Stanford, CA.Poznanski, V. & Sanfilippo, A.
1993.
Detecting de-pendencies between semantic verb subclasses andsubcategorization frames in text corpora.
In Pro-ceedings of the SIGLEX ACL Workshop on the Ac-quisition of Lexical Knowledge from Text, Boguraev,B.
& Pustejovsky, J. eds.Resnik, P. 1993.
Selection and information: a class-based approach to lexical relationships.
University ofPennsylvania, CIS Dept, PhD thesis.Ribas, P. 1994.
An experiment on learning ap-propriate selection restrictions from a parsed cor-pus.
In Proceedings of the International Conferenceon Computational Linguistics, COLING-94, Kyoto,Japan.Sampson, G. 1995.
English for the computer.
Ox-ford, UK: Oxford University Press.Schabes, Y.
1992.
Stochastic lexicalized tree ad-joining grammars.
In Proceedings of the Inter-national Conference on Computational Linguistics,COLING-92, Nantes, France.
426-432.Taylor, L. & Knowles, G. 1988.
Manual of informa-tion to accompany the SEC corpus: the machine-readable corpus of spoken English.
University ofLancaster, UK, Ms.Ushioda, A., Evans, D., Gibson, T. & Waibel, A.1993.
The automatic acquisition of frequencies ofverb subcategorization frames from tagged corpora.In Boguraev, B.
& Pustejovsky, J. eds.
SIGLEXA CL Workshop on the Acquisition of Lexical Knowl-edge from Text.
Columbus, Ohio: 95-106.363
