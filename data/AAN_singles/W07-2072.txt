Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 334?337,Prague, June 2007. c?2007 Association for Computational LinguisticsUA-ZBSA: A Headline Emotion Classification through Web InformationZornitsa Kozareva, Borja Navarro, Sonia Va?zquez, Andre?s MontoyoDLSI, University of AlicanteCarretera de San Vicente S/NAlicante, Spain03080zkozareva,borja,svazquez,montoyo@dlsi.ua.esAbstractThis paper presents a headline emotion clas-sification approach based on frequency andco-occurrence information collected fromthe World Wide Web.
The content words ofa headline (nouns, verbs, adverbs and adjec-tives) are extracted in order to form differentbag of word pairs with the joy, disgust, fear,anger, sadness and surprise emotions.
Foreach pair, we compute the Mutual Informa-tion Score which is obtained from the weboccurrences of an emotion and the contentwords.
Our approach is based on the hypoth-esis that group of words which co-occur to-gether across many documents with a givenemotion are highly probable to express thesame emotion.1 IntroductionThe subjective analysis of a text is becoming impor-tant for many Natural Language Processing (NLP)applications such as Question Answering, Informa-tion Extraction, Text Categorization among others(Shanahan et al, 2006).
The resolution of this prob-lem can lead to a complete, realistic and coher-ent analysis of the natural language, therefore ma-jor attention is drawn to the opinion, sentiment andemotion analysis, and to the identification of be-liefs, thoughts, feelings and judgments (Quirk et al,1985), (Wilson and Wiebe, 2005).The aim of the Affective Text task is to clas-sify a set of news headlines into six types of emo-tions: ?anger?, ?disgust?, ?fear?, ?joy?, ?sadness?and ?surprise?.
In order to be able to conductsuch multi-category analysis, we believe that firstwe need a comprehensive theory of what a humanemotion is, and then we need to understand how theemotion is expressed and transmitted within the nat-ural language.
These aspects rise the need of syn-tactic, semantic, textual and pragmatic analysis ofa text (Polanyi and Zaenen, 2006).
However, someof the major drawbacks in this field are related tothe manual or automatic acquisition of subjective ex-pressions, as well as to the lack of resources in termsof coverage.For this reason, our current emotion classificationapproach is based on frequency and co-occurrencebag of word counts collected from the World WideWeb.
Our hypothesis is that words which tend to co-occur across many documents with a given emotionare highly probable to express this emotion.The rest of the paper is organized as follows.
InSection 2 we review some of the related work, inSection 3 we describe our web-based emotion classi-fication approach for which we show a walk-throughexample in Section 4.
A discussion of the obtainedresults can be found in Section 5 and finally we con-clude in Section 6.2 Related workOur approach for emotion classification is based onthe idea of (Hatzivassiloglou and McKeown, 1997)and is similar to those of (Turney, 2002) and (Tur-ney and Littman, 2003).
According to Hatzivas-siloglou and McKeown (1997), adjectives with thesame polarity tended to appear together.
For exam-ple the negative adjectives ?corrupt and brutal?
co-334occur very often.The idea of tracing polarity through adjective co-occurrence is adopted by Turney (2002) for the bi-nary (positive and negative) classification of text re-views.
They take two adjectives, for instance ?ex-cellent?
and ?poor?
in a way that the first adjectiveexpresses positive meaning, meanwhile the secondone expresses negative.
Then, they extract all ad-jectives from the review text and combine them with?excellent?
and ?poor?.
The co-occurrences of thesewords are searched on the web, and then the MutualInformation score for the two groups of adjectivesis measured.
When the adjective of the review ap-pear more often with ?excellent?, then the review isclassified as positive, and when the adjectives appearmore often with ?poor?, then the review is classifiedas negative.Following Hatzivassiloglou and McKeown (1997)and Turney (2002), we decided to observe how oftenthe words from the headline co-occur with each oneof the six emotions.
This study helped us deduceinformation according to which ?birthday?
appearsmore often with ?joy?, while ?war?
appears moreoften with ?fear?.Some of the differences between our approachand those of Turney (2002) are mentioned below:?
objectives: Turney (2002) aims at binary textclassification, while our objective is six classclassification of one-liner headlines.
Moreover,we have to provide a score between 0 and 100indicating the presence of an emotion, and notsimply to identify what the emotion in the textis.
Apart from the difficulty introduced by themulti-category classification, we have to dealwith a small number of content words whileTurney works with large list of adjectives.?
word class: Turney (2002) measures polarityusing only adjectives, however in our approachwe consider the noun, the verb, the adverb andthe adjective content words.
The motivationof our study comes from (Polanyi and Zaenen,2006), according to which each content wordcan express sentiment and emotion.
In additionto this issue we saw that most of the headlinescontain only nouns and verbs, because they ex-press objectivity.?
search engines: Turney (2002) uses the Al-tavista web browser, while we consider andcombine the frequency information acquiredfrom three web search engines.?
word proximity: For the web searches, Tur-ney (2002) uses the NEAR operator and con-siders only those documents that contain theadjectives within a specific proximity.
In ourapproach, as far as the majority of the querywords appear in the documents, the frequencycount is considered.?
queries: The queries of Turney (2002) are madeup of a pair of adjectives, and in our approachthe query contains the content words of theheadline and an emotion.There are other emotion classification approachesthat use the web as a source of information.
Forinstance, (Taboada et al, 2006) extracted from theweb co-occurrences of adverbs, adjectives, nounsand verbs.
Gamon and Aue (2005) were lookingfor adjectives that did not co-occur at sentence level.
(Baroni and Vegnaduzzo, 2004) and (Grefenstetteet al, 2004) gathered subjective adjectives from theweb calculating the Mutual Information score.Other important works on sentiment analysis arethose of (Wilson et al, 2005) and (Wiebe et al,2005; Wilson and Wiebe, 2005), who used linguisticinformation such as syntax and negations to deter-mine polarity.
Kim and Hovy (2006) integrated verbinformation from FrameNet and incorporated it intosemantic role labeling.3 Web co-occurrencesIn order to determine the emotions of aheadline, we measure the Pointwise Mu-tual Information (MI) of ei and cwj asMI(ei, cwj) = log2 hits(ei,cwj)hits(ei)hits(cwj) , where ei ?
{anger, disgust, fear, joy, sadness, surprise}and cwj are the content words of the headline j.For each headline, we have six MI scores whichindicate the presence of the emotion.
MI is usedin our experiments because it provides informationabout the independence of an emotion and a bag ofwords.To collect the frequency and co-occurrence countsof the headline words, we need large and massive335data repositories.
To surmount the data sparsityproblem, we used as corpus the World Wide Webwhich is constantly growing and daily updated.Our statistical information is collected from threeweb search engines: MyWay1, AlltheWeb2 and Ya-hoo3.
It is interesting to note that the emotion dis-tribution provided by each one of the search enginesfor the same headline has different scores.
For thisreason, we decided to compute an intermediate MIscore as aMI =?ns=1 MI(ei,cwj)s .In the trail data, besides the MI score of an emo-tion and all headline content words, we have calcu-lated the MI for an emotion and each one of the con-tent words.
This allowed us to determine the mostsentiment oriented word in the headline and then weuse this predominant emotion to weight the associ-ation sentiment score for the whole text.
Unfortu-nately, we could not provide results for the test dataset, due to the high number of emotion-content wordpairs and the increment in processing time and re-turned responses of the search engines.4 Example for Emotion ClassificationAs a walk through example, we use the Mortar as-sault leaves at least 18 dead headline which is takenfrom the trial data.
The first step in our emotion clas-sification approach consists in the determination ofthe part-of-speech tags for the one-liner.
The non-content words are stripped away, and the rest of thewords are taken for web queries.
To calculate the MIscore of a headline, we query the three search en-gines combining ?mortar, assault, leave, dead?
withthe anger, joy, disgust, fear, sadness and surpriseemotions.
The obtained results are normalized in arange from 0 to 100 and are shown in Table 1.MyWay AllWeb Yahoo Av.
G.Stand.anger 19 22 24 22 22disgust 5 6 7 6 2fear 44 50 53 49 60joy 15 19 20 18 0sadness 28 36 36 33 64surprise 4 5 6 5 0Table 1: Performance of the web-based emotionclassification for a trail data headline1www.myway.com2www.alltheweb.com3www.yahoo.comAs can be seen from the table, the three searchengines provide different sentiment distribution forthe same headline, therefore in our final experimentwe decided to calculate intermediate MI.
Comparingour results to those of the gold standard, we can saythat our approach detects significantly well the fear,sadness and angry emotions.5 Results and DiscussionTable 2 shows the obtained results for the affectivetest data.
The low performance of our approachis explainable by the minimal knowledge we haveused.
An interesting conclusion deduced from thetrail and test emotion data is that the system detectsbetter the negative feelings such as anger, disgust,fear and sadness, in comparison to the positive emo-tions such as joy and surprise.
This makes us believethat according to the web most of the word-emotioncombinations we queried are related to the expres-sion of negative emotions.UA-ZBSA Fine-grained Coarse-grainedPearson Acc.
P. R.Anger 23.20 86.40 12.74 21.66Disgust 16.21 97.30 0.00 0.00Fear 23.15 75.30 16.23 26.27Joy 2.35 81.80 40.00 2.22Sadness 12.28 88.90 25.00 0.91Surprise 7.75 84.60 13.70 16.56Table 2: Performance of the web-based emotionclassification for the whole test data setIn the test run, we could not apply the emotion-word weighting, however we believe that it hasa significant impact over the final performance.Presently, we were looking for the distribution of allcontent words and the emotions, but in the future wewould like to transform all words into adjectives andthen conduct web queries.Furthermore, we would like to combine the re-sults from the web emotion classification with thepolarity information given by SentiWordNet4.
A-priory we want to disambiguate the headline contentwords and to determine the polarities of the wordsand their corresponding senses.
For instance, the ad-jective ?new?
has eleven senses, where new#a#3 andnew#a#5 express negativism, new#a#4 and new#a#9positivism and the rest of the senses are objective.4http://sentiwordnet.isti.cnr.it/336So far we did not consider the impact of valenceshifter (Polanyi and Zaenen, 2006) and we were un-able to detect that a negative adverb or adjectivetransforms the emotion from positive into negativeand vice versa.
We are also interested in studyinghow to conduct queries not as a bag of words butbind by syntactic relations (Wilson et al, 2005).6 ConclusionEmotion classification is a challenging and difficulttask in Natural Language Processing.
For our firstattempt to detect the amount of angry, fear, sadness,surprise, disgust and joy emotions, we have pre-sented a simple web co-occurrence approach.
Wehave combined the frequency count information ofthree search engines and we have measured the Mu-tual Information score between a bag of contentwords and emotion.According to the yielded results, the presented ap-proach can determine whether one sentiment is pre-dominant or not, and most of the correct sentimentassignments correspond to the negative emotions.However, we need to improve the approach in manyaspects and to incorporate more knowledge-rich re-sources, as well as to tune the 0-100 emotion scale.AcknowledgementsThis research has been funded by QALLME numberFP6 IST-033860 and TEX-MESS number TIN2006-15265-C06-01.ReferencesMarco Baroni and Stefano Vegnaduzzo.
2004.
Identi-fying subjective adjectives through web-based mutualinformation.
In Ernst Buchberger, editor, Proceedingsof KONVENS 2004, pages 17?24.Michael Gamon and Anthony Aue.
2005.
Automaticidentification of sentiment vocabulary: exploiting lowassociation with known sentiment terms.
In Proceed-ings of the Workshop on Feature Engineering for Ma-chine Learning in Natural Language Processing (ACL2005), pages 57?64.Gregory Grefenstette, Yan Qu, James G. Shanahana, andDavid A. Evans.
2004.
Coupling niche browsers andaffect analysis for an opinion mining application.
InProceeding of RIAO-04.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In Proceedings of the eighth conference on Eu-ropean chapter of the Association for ComputationalLinguistics (EACL).Soo-Min Kim and Eduard Hovy.
2006.
Extracting opin-ions, opinion holders, and topics expressed in onlinenews media text.
In Proceedings of the Workshop onSentiment and Subjectivity in Text, pages 1?8.Livia Polanyi and Annie Zaenen.
2006.
Contextual va-lence shifter.
In James G. Shanahan, Yan Qu, andJanyce Wiebe, editors, Computing Attitude and Affectin Text: Theory and Applications, chapter 1, pages 1?10.
Springer.R.
Quirk, S. Greenbaum, G. Leech, and J. Svartvik.
1985.A Comprehensive Grammar of the English Language.Longman.James G. Shanahan, Yan Qu, and Janyce Wiebe.
2006.Computing Attitude and Affect in Text: Theory and Ap-plications.
Springer.Maite Taboada, Caroline Anthony, and Kimberly Voll.2006.
Methods for creating semantic orientationdatabases.
In Proceeding of LREC-06, the 5th Interna-tional Conference on Language Resources and Evalu-ation, pages 427?432.Peter D. Turney and Michael L. Littman.
2003.
Measur-ing praise and criticism: Inference of semantic orien-tation from association.
ACM Transactions on Infor-mation Systems, 21(4):315?346.Peter D. Turney.
2002.
Thumbs up or thumbs down?semantic orientation applied to unsupervised classifi-cation of reviews.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguis-tics (ACL), pages 417?424.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.Annotating expressions of opinions and emotions inlanguage.
Language Resources and Evaluation (for-merly Computers and the Humanities), 39(2-3):165?210.Theresa Wilson and Janyce Wiebe.
2005.
Annotatingattributions and private states.
In Ann Arbor, editor,Proceedings of the Workshop on Frontiers in CorpusAnnotation II: Pie in the Sky, pages 53?60.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of the conferenceon Human Language Technology and Empirical Meth-ods in Natural Language Processing, pages 347?354.337
