A Language-Independent System for GeneratingFeature Structures from Interlingua RepresentationsMurat  Temizsoy Ilyas CicekliDepartment of Computer Engineering and Information Science,Bilkent University, 06533 Bilkent, Ankara, Turkey,e-maih temizsoy@cs.bilkent.edu.tr, ilyas@cs.bilkent.edu.trAbstractTwo main problems in natural language generation are lexical selection and syntactic?
structure determination.
In interlingua pproach to machine translation, determining sentencestructures becomes more difficult, especially when the interlingua does not contain any syntacticinformation, in this paper, a knowledge-based computational model which handles thesetwo problems in interlingua pproach is presented.
The developed system takes interlinguarepresentations of individual sentences, performs lexical selection, and produces frame-basedsyntactic structures.
The system takes all the information about the target language fromknowledge resources, in other words its architecture is language-independent.
The implementedsystem is tested with Turkish through small-sized resources such that its output can be fed intoa previously developed tactical generator to produce the final realizations of Turkish sentences.1 IntroductionInterlingua pproach to machine t.ranslation (MT) aims at achieving the translation task by usingan intermediate, language-independent meaning representation \[Nirenburg et al, 1992\].
The use?
of such an artificial language, interlingua, makes the design of analysis and generation componentsseparate in interlingua-based systems.
Analysis is responsible for representing the input sourcetext in interlingua, and generation produces the target text from those previously constructedrepresentations.
In other Words, the source and the target language are never in direct contact insuch systems.Generation in such systems should at least perform lexical selection, syntactic structurecreation, morpho!ogical inflection, and word order determination if planning (determination ofoverall text structure and sentence boundaries) is not considered.
One approach to the design of?
generation modul e in inter!ingua-ba.sed MT systems is to handle the first two tasks in a separatearchitecture, get a form of syntactica!ly represented target sentences, and achieve the last twotasks with a tactical generator.
In this way, only the interlingua dependen t tasks are handled inprocessing interlingua representations.The a im of this paper is t.o present a computational architecture for generat ion whichperforms the tasks of  lexical selection \[Dorr, 1993\] and syntactic structure ?
determination\[Mitamura nd Nyberg, 1992\] in interlingua approach.
The system is designed to take theinterlingua representations of indiv idual  sentences .and produce their frame-based syntacticrepresentations in which selected lexemes are included \[Temizsoy, 1997\].
A knowledge-basedapproach is utilized in the developed architecture such that information about, the t.arget language188is taken from knowledge resources.
In other words, its architecture is language-independent.
Theutilized interlingua is mainly based on an ontology, a hierarchical world model, to representpropositional content.
It also utilizes special frames to represent semantic and pragmaticphenomena encountered in analysis.
The arclfitecture uses Ontology while processing inter!inguarepresentation in addition to lexicon, map-rules (relation between interlingua nd.
target languagesyntactic structure), and target language's Syntax representation formalism.
The architecture ofthe designed system is given in Figure 1.. .
.
.
.
.
.~RL~O UA \]REPRESENTATION1DESIGNED SYSTEM1FEATURE STRUCTURE \]REPRESENTATIONTARGET LANGUAGE\[,~NOWLED GE RESO UCF_~S@~.~C R F-Er-,.t:5" :NT A ~.
.
.~Figure 1: Architecture of the Designed SystemThe implemented system is used to generate the syntactic structure representations ofTurkish sentences from their corresponding interlingua representations.
The syntax representationformalism of Turkish is taken from a Turkish tactical generator previously developed by Hakkani\[Hakkani, 1996\].
The output of the system can be directly fed into this generator to produce thefinal reafizations of Turkish sentences.
Although input resources do not providefull coverage ofTurkish, special consideration is givento linguistic phenomena encountered in Turkish such as freeword-order and narrative tense \[Temizsoy, 1997\].The rest of this paper is organized as follows.
In Section 2, the interlingua formalism utilized inthis work and its use of ontology is presented.
Then, knowledge resources that provide informationabout the target language to the developed model are described in Section 3.
Computationalarchitecture of the system is presented in Section 4, and some specific examples from Turkish aregiven to demonstrate the system usage in Section 5.
Finally, conclusion and and some possiblefuture works are given in Section 6,2 Interlingua and OntologyThe work described in this paper is based on interhngua pproach to hiT.
In this approach,the meaning conveyed in the source text is represented using a language-independent, ar ificiallanguage.
The  language formalism that is utilized in this paper is developed for MicroCosmosproject at New Mexico State University and it is called as text meaning representation (TMR)\[Mahesh and Nirenburg, 1996, Beale et al.
1995\].
Its formalism is based on two main knowledgeresources: speaker's world knowledge about entities, events, and their relationships which aredescribed in ontology, and linguistic information about semantic (aspect, modality, etc.)
andpragmatic (speech-act, stylistics, etc.)
issues.
In this section: first a brief description of the ontology189is given, and then the interlingua formalism is presented with a demonstrative example.The ontology used in this work is a hierarchical model of the real world \[Mahesh, 1996\].
Itis built upon proposed abstractions, concepts, about the world entities, events, and relations.
Theconcepts in the ontology are not designed to denote word senses ?
in a specific language, instead theyare defined to represent our common sense knowledge about the world.
Each concept is representedas a frame and the information about its abstraction is described through a set of features withtheir value domains.
For example, the concept HUMAN is defined to denote all human-beings inthe world and it corresponds to the words 'man', 'woman', 'child', 'John', etc, in English.
Theframe given below is the simplified description of HUMAN.concept HUMANtype.
| namedefinition ?
I gender?
I age\[ jobcommon/proper \]human-namesmale~female> 1 & <120teacher~engineer~..Representation f events in the ontology is somehow different from the entities since they aretreated as predicates over arguments.
So, an event concept provides extra information about itsthematic structure such that each thematic role can take a set of entity concepts as its values.
Allconcepts in the ontology are connected to others through a set of relations.
The main relation, is-a.provides the hierarchical interpretation i the ontology such that child concepts define a.dditiolialproperties and put  some constraints on the definition of their parent concepts.
So, a HUMAN is aMAMMAL, which is an ANIMAL, etc.
There are also other types of relations to provide additionalinformation like a MONITOR is-part-of a COMPUTER.The utilized language formalism, TMR, does not contain any specific information aboutthe source language like lexemes and syntactic structure.
It uses a frame-based notation and it isheavily based on the Ontology.
Th e concepts from the ontology are used to denote the propositionalcontent of the input sentences.
But since concepts are only abstractions, their features hould beinstantiated tO denote real things when used in TMR.
Although concept instances provide the?
information about the propositional content, semantic and pragmatic properties of the sentenceshould also bedescr ibed in TMR.
To facifitate this, TMR language provides special frames forrepresenting aspectual properties, temporal relations, speech-acts, tylistic factors, etc.
Instead ofdescribing the TMR language in full detail, an example representation is given to demonstrate itsformalism.
The TMR of the sentence "The man gave a book to the child" is given in Figure 2.Note that, although English words are used as concepts, they are not denoting English word?
senses, they are just generic abstractions.
Each frame in a TMR is indexed to differentiate betweenframes with the same name.
Both of the phrases 'the man' and 'the child' are represented withfraines of the same concept, HUMAN, but  their instantiated features are totally different.
Thegiven TMR simply denotes the event give(man, child, book) with its aspectual properties (aspecta)and its temporal relation with the time of utterance (temp-rell).
Information about the speechsituation is described with speech-act1 frame.
Observe that, there is nothing specific about theEnglish sentence that is represented in the given TMR.. 190HUMAN1typegenderagereferenceGIVExagent HUMAN1destination HU M AN~_theme BOO Kapolarity positiveaspect aspect 1time timel HU M AN~_typeaspecQ agephase perfect referenceduration momentaryiteration single BOOK1felicity false ?
referencecommonmale> 18de f iniLecomT~2on< 12definiteindefinite'speech-act1 ?
temp-relltype declarative type afterscope GIVE1 ar g l time2time ~ime~ arg~ timelFigure 2: TMR Representation Of "The man gave a book to the child"3 Knowledge ResourcesTile developed architecture is language-independent, it takes the information about the ?targetlanguage from three knowledge resources: lexicon, map-rules, and syntactic structure representationformalism of the target language.
Lexicon, besides its other usages, provides information about therelationship between concept instances and word senses of  tile target language \[Dorr, 1993\].
Map-rules define how the content of a TMR is related to the syntactic structure of the target language\[Mitamura and Nyberg, 1992\].
The last knowledge resource provides the information about thestructure of the syntactic representation formalism.The interface between concept instances in  TMR (denoting events and entit ies)and wordsenses of the target language is established using semantic and pragmatic properties O f lexemesthat are defined in the lexicon.
Since nouns denote entities and verbs denote events in a language,each word that belongs to one of these categories i also defined as a concept instance in the lexicon.So, for every TMR frame that is a concept instance, there is a set of candidate lexicon entries thatare defined using the same concept.
For example, if the previous example is considered, there areat least two candidates for an instantiated HUMAN, that are 'man' and 'child'.The meaning of every noun and verb is defined in the lexicon by constraining the abstractionprovided by the parent concept.
For example, one sense of 'man' can be defined as 'a male HUMANwhose age is greater than 17'.
Such definitions are the major source of information used in lexicalselection.
In addition to meaning definitions, pragmatic properties of word senses can also be definedin the lexicon.
For example, the preference Of 'guy' Over 'man' in  informal situations to ?expressa negative attitude can be encoded by attaching the necessary stylistic and attitude requirementsto the definition of 'guy'.
Note that, words belonging to adjective and adverb categories are notdefined as concept instances.
Instead, they are represented in TMRs as features of events andentities, and their realizations are achieved through map-rules in generation.191The syntactic structure formalism of the target language is represented using a frame-basednotation, like feature structures.
The developed system uses the syntax formalism through itscorresponding tree structures defined in the knowledge resource.
The relation between syntacticstructure and TMR is described using map-rules.
Each map-rule is related with either a conceptfrom the ontology or a special frame type used in the TMR language to encode certain semantic orpragmatic issues such as aspect, modality and speech-act.
Map-rules are utilized to relate thematicroles to grammatical counterparts, to create specific syntactic features uch as tense, voice, andmodifiers, and- to determine the syntactic onnection between events.
Map-rules defined for conceptsfollow the inheritance mechanism in the ontology and general syntactic properties are determinedin parent concepts.Each map-rule mainly provides two types of information: content conditions and updateoperations.
Content conditions hould be satisfied by the input TMR before update operations areapplied.
Since map-rules Should be TMR independent, making references to arbitrary frames in theinput  TMR is not allowed in the definitions of content conditions.
In fact, only three frames can bereferenced in conditions: current active frame, current event frame, and current speech-act frame.Content conditions are defined to check the existence of certain features and/or their values in theseframes.
Update operations change the constructed syntactic structure of the sentence when theyare applied.There are three types of update operations: feature addition such as add(tense, past),frame addition such as add(subject), and frame-to-frame mapping such as map(agent, subject).4 Computat iona l  ModelThe computational model is designed to process the TMR of a sentence as input and to constructthe syntactic structure of that sentence selecting lexical items for the constituents of that sentence.To achieve these tasks, the model makes use of ontology and knowledge resources developed forthe target language.
Although lexical selection and syntactic structure construction can work inparaUel during TMR processing, they Call also be handled in two independent submodules.
Lexicalselection is activated whenever the TMR frame is a concept instance, and it is based on the semanticand the pragmatic properties of the candidate lexemes.
Each TMR frame activates its attachedmap-rules to update the constructed syntactic structure.
Besides these tasks, the model shoulddetermine the process order of TMR framesSo, the main module decides On the processing orderand activates the lexical selection and the map-rule application submodules whenever necessary.The architecture is described in Figure 3.4.1 Lex ica l  Se lec t ion  Modu leLexical selection is performed for every TMR frame which is a concept instance.
Since there aregenerally more than one candidate lexeme for such a frame, the module should select the most near-perfect  word sense that carries the meaning residing in the TMR frame into the target sentence.So, lexical selection in this work is mainly based on the meaning distance between the frame beingprocessed and the candidate lexemes \[Temizsoy, 1997\].
The distance calculation is done throughassigning penalties to features that are not matched in the two definitions.
After calculating theproximities between the meaning in the TMR frame and the candidate lexemes, the module returnsthe closest one as the selected word sense.
Although proximity of meaning is the major Criterion.192!IIII!11IIiiiIIII!TEXT l,E.Pd,1~REPRESENTATIONO F A ~I ~ ,~- '~^'~o, .
,  I?
I o~^~.rE~.~ IKNOWLEDGE I~,O URCESFigure?
3: Computational Modelthere are cases in Which there are still ambiguity between candidates.
In such cases, in addition tothe semantic onstraints Of lexical items, their pragmatic properties are also taken into account.Lexical selection is achieved in three successive steps: first the candidates whosesubcategorization constraints are not satisfied in the TMR frame are removed from the list (context-dependent selection), then a distance is assigned to the remaining candidates by comparing themeaning residing in the TMR frame with their definitions in the lexicon (context-independentselection), and if it is still impossible to make a selection on those cMculated istances, the stylisticsand pragmatic properties of Candidates are utilized .
The architecture of lexical selection moduleis described as in Figure 4.WHOLE TMRlg ?/, '  I I ,?
4 , ~ I .E I lZM~ 2CDN'~ )0" I ~  Di~rl" ?.
!LSELECTED I.E XEIv~Figure 4: Lexical Selection ModuleThere are some heuristics that are utilized in calculating the distance between a TMR frameand a lexical item definition, and they can be summarized as follows:t93A penalty value is assigned to a feature that is in the lexeme definition, but not in the TMRframe, to nfinimize extraneous meaning introduction.Another penalty value is assigned to a feature that is in the TMR frame definition, but notin the lexeme definition, to reduce uncoverage of meaning.Match between two values from the same domain is proportional to the distance in orderedvalues a,nd the intersection sizes in ranges.The calculated match is normalized by the domain size of the feature to minimize distancesin larger domains.The final distance is rated by its importance on the overall meaning such that mismatches inless relevant features liave smaller influence over the fina !
proximity.4.2 Map-Ru le  App l i ca t ion .
Modu leThis module collects all the map-rules associated with the TMR framebeing processed and updatesthe Constructed syntactic structure for map-rules whose content conditions are satisfied.
The  map-rules developed for ontology concepts follow the inheritance mechanism provided in the ontology.So,  while processing a TMR frame which is an concept instance, this module should traverse tileontology in a bottom-up fashion to apply map-rules that are associated with the ancestor concept sof the concept instance.
Note that, since a lexical item can require some updates on the syntacticstructure, this module also applies the map=rules associated with the selected lexical item.
If theprocessed TMR frame is not  a concept instance, the map=rules associated with its frame typeareapplied to update the constructed syntactic structure.As mentioned, the syntax formalism of the target language is represented as tree structuresin which frames are the internal nodes and the features are the leaves.
Since frames and featuresin such a representation are used to describe distinct syntactic phenomena, unique names shouldbe given to them.
This.uniqueness property is utilized to find the place of a feature or a framedirectly in the tree structure without traversing.
So, feature or frame addition to the constructedtree is achieved by just finding its place, forming a partial tree through traversing the definedtree structure in a bottom-up fashion, and merging that partial tree to the previous constructedsyntactic structure.
Note that, tliese operations Can be done in logarithmic time \[Tenfizsoy.
!997\].Some syntactic constructs have the same form although their syntactic realizations aredifferent, like noun phrases.
So, generally their structure is defined under a common frame whichcan be the value of various features in the overall structure.
For example, noun phrases are thefillers of grammatical roles subject, direct-object, etc.
To utilize such a form, the representationformalism is allowed to have more than one tree in its definition (one for verbal phrases, another fornoun phrases, .etc.).
The tree representing verbal phrase is taken to be the main one, all constructedchildren trees should be attached to it.
The information about the attachment place of a child tree(noun phrase is t.he subject, place, etc.)
is obtained from previous frame-to-frame mapping rulessuch as map(agent, subject).a1944.3 Ma in  Modu leThe main module is responsible for determining the processing order of the TMR frames in theinput.
In this work, a depth-first strategy is used in ordering which is utilized in processing TMRsthat have more than one event.
Since verbal phrases are represented with the main tree in thesyntax formalism, trees constructed for supplementary events hould be attached to the tree builtfor the main event.
Since depth-first processing uarantees that all children frames together withtheir parent frame are processed before processing the other TMR frames, the algorithm can safelyconstructs the syntactic structures of supplementary events and connects them to the main tree.So, the main module first constructs a processing stack which contains the main event (scopeof the speech-act), relations or special frames (casual, temporal, textual relations, speech~acts,etc.
),.and other events in the given order \[Temizs0y, 1997\].
After creating the syntactic tree of asupplementary event, the algorithm finds the syntactic relation of that event to the main one.
Thisdetermines the attachment place of the child tree in the main tree.
There are three cases in whichevents are related to the main one:Another event is used to describe a thematic role of the main event, like in :'I wahl to read abook".
In this example; the phrase 'read a book' is processed individually by the algorithm, andits corresponding constructed tree is attached as the direct-object of the sentence (assumingthat map(theme, direct-object) is previously applied).The connection between two events is a relation (casual relations, conjunctions, etc.
), like in"'Since John did not study enough, he could not pas s the exam".
In this example, first themain event, PASS, is processed, then the frame which defines the relation is taken from theprocessing stack.
Since oneof  its arguments i not processed yet (the event STUDY in thisexample), the algoritl!m first constructs the tree structure of STUDY,  and.
then apply thesyntactic realization Of the relation to the constructed trees of PASS and STUD}'.Another event is introduced to give some additional information about the main event orOne of its components, like in "John, who came to Four birthday party last monlh, went toIstanbug'.
In this example, the algorithm first constructs the corresponding tree of GO, thenit processes the event COME, and finally finds its relation to GO (definition of subject) andmerges its constructed tree to the main one.5 Implementat ionThe implementation f the presented architecture is done in Prolog.
Currently, the implementedsystem is tested with Turkish.
Turkish synta.x formahsm is taken from a previously developedTurkish tactical generator \[Hakkani, 1996\] such that the successive xecution of the two systemsproduces real Turkish sentences from interhngua representations.
For example, when the TMRexample given in Figure 2 is fed into the developed system, the feature structure representation,which is shown in Figure 5, of the Turkish sentence "Adam kMma bir kitap verdi" is produced.Then, this feature structure is fed into the tactical generator to produce the surface form of thesentence.One of the prominent features of Turkish is its free word-order structure.
Changes in tb.edefault word-order generally serve to introduce pragmatic differences.
For example, the constituent195Feature Structure produced by the developed system:\[Is-form,finite\], \[clause-type,predicative\], \[speech-act,declarative\], \[voice,active\],\[verb, \[\[sense,positive\], \[mode,pasq, \[root,'ver'\], \[category,verb\]\]\],\[arguments,\[\[subject, \[\[referent, \[\[arg, \[\[root,'adam'\], \[category,noun\]\]\],\[agr, \[\[person,third\], \[number,singular\]\]\]\]\],\[specifier, \[\[quan,\[\[definite,positive\]\]\]\]\]\]\],\[goal, \[\[referent, \[\[arg, \[\[root,'liocuk'\], \[category, noun\]I\],\[agr, \[\[person,third\], \[number,singular\]I\]\]\],\[specifier, \[\[quan, \[\[definite,positive\]\]\]\]\]\] \],\[dir-obJect , \[\[referent, \[\[arg, \[\[root,'kitap'\], \[category,noun\]\]\],\[agr, \[\[person,third\], \[number,singular\]I\]\]\]\]\]\]\]Surface Form produced by the tactical generator:.
"Adam kadma bir kitap verdi"Figure 5: The Results of Generationwhich is placed right before the verb is the focused element in the sentence.
So, representing the"sentence "Carol Ali klrd?'
("it was Ali who broke the window") is achieved by attaching a saliency.
(importance the speaker attribute to) attitude Such that its value is greater than a predefinedvalue.-To process this information in TMR, a map-rule is associated to the ENTITY concept whichchecksthe .,dstence of such an attitude and perfoms the introduction of topic, focus, and backgroundinformation into the feature structure representation?
Topic indicates the sentence initial position,focus is the preverbal position, and background indicates the postverbal positions:6 Conc lus ionLexical selection and syntactic structure construction are two important asks to be handled ininterlingua.-based generation.
This paper presents a computational model which is designed toachieve these tasks in interlingua pproach.
It takes individuM sentences represented in a specificinterlingua formalism and produces frame-based syntactic structures of the target sentences.
Itutilizes a knowledge-based approach to this generation task to make its architecture language-independent.
It takes all the information about the target language from three knowledge resources:lexicon, map-rules, and target language syntax formMism.The implemented system is used to produce?
feature structure representations of Turkishsentences.
The  feature structure formalism is taken from a. tactical generator previously developedfor Turkish such that the output of our system can be fed into this generator to produce the finalrealizations of Turkish sentences.
By using these two systems, generation of Turkish sentences iachieved from the specific interlingua formalism.196iiI!iiiiIIiIiiII,IIIReferences\[Beale t al., 1995\] Beale, S., Nirenburg, S., and Mahesh, K. 1995.
Semantic analysis in the mikrokosmosmachine translation project.
In Proceedings of the 2nd Symposium on Natural Language Processing (SNLP-95), Bangkok, Thailand.\[Dorr, 1993\] Dorr, B. J.
1993.
The use of lexical semantics in interlingua machine translation.
MachineTranslation, 4:3:135-193.\[Hakkani, 1996\] Hakkani, D. Z.
1996.
Design and implementation f a tactical generator for turkish, a freeconstituent order language.
Master's thesis, Bilkent University, Ankara Turkey.\[Mahesh, 1996\] Mahesh, K. 1996.
Ontology development formachine translation: Ideology and methodology.In Memoranda in Computer and Cognitive Science MCCS:96-292, Las Crues, New MexicoState.University.\[Mahesh and Nirenburg, 1996\] Mahesh, K. and Nirenburg, S. 1996.
Meaning representation forknowledgesharing in practical machine translation.
In Proceedings of lhe FLAIRS-96.
Track on InformationInterchange, Florida AI Research Symposium, Key West, Florida:\[Mitamura and Nyberg, 1992\] Mitamura, T. and Nyberg, E. 1992.
Hierarchical exical structure andinterpretive mapping in ,nachine translation.
In Proceedings of COLING-92, Nantes, France.\[Nirenburg et al, 1992\] Nirenburg, S., Carbonell, J., To,nita, M., and Goodman, K. 1992.
MachineTra,,slalio~: A f(,,owlcdgc-Bascd Approach.
Morgan Kaufmann, San Mateo, California.\[Temizsoy, 1997\] Temizsoy, M. 1997.
Design and i,nplementation f a System for mapping text ineaningrepresentations to f-structures of turkish sentences.
Master's thesis, Bilkent University, Ankara Turkey.197
