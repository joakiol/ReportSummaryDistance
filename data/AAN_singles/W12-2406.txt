Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 47?55,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsAlignment-HMM-based Extraction of Abbreviations from Biomedical TextDana Movshovitz-AttiasCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213 USAdma@cs.cmu.eduWilliam W. CohenCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213 USAwcohen@cs.cmu.eduAbstractWe present an algorithm for extracting abbre-viation definitions from biomedical text.
Ourapproach is based on an alignment HMM,matching abbreviations and their definitions.We report 98% precision and 93% recall ona standard data set, and 95% precision and91% recall on an additional test set.
Our re-sults show an improvement over previously re-ported methods and our model has several ad-vantages.
Our model: (1) is simpler and fasterthan a comparable alignment-based abbrevia-tion extractor; (2) is naturally generalizable tospecific types of abbreviations, e.g., abbrevia-tions of chemical formulas; (3) is trained on aset of unlabeled examples; and (4) associates aprobability with each predicted definition.
Us-ing the abbreviation alignment model we wereable to extract over 1.4 million abbreviationsfrom a corpus of 200K full-text PubMed pa-pers, including 455,844 unique definitions.1 IntroductionAbbreviations and acronyms are commonly used inthe biomedical literature for names of genes, dis-eases and more (Ambrus, 1987).
Abbreviation def-initions are a source of ambiguity since they maychange depending on the context.
The ability to rec-ognize and extract abbreviations and map them toa full definition can be useful for Information Ex-traction tasks (Yu et al, 2007) and for the completeunderstanding of scientific biomedical text.Yu et al (2002) distinguish the two follow-ing uses of abbreviations: (1) Common abbrevia-tions are those that have become widely accepted assynonyms, such as ?DNA, deoxyribonucleic acid?or ?AIDS, acquired immunodeficiency syndrome?.These represent common fundamental and impor-tant terms and are often used, although not explic-itly defined within the text (Fred and Cheng, 2003).In contrast, (2) Dynamic abbreviations, are definedby the author and used within a particular article.Such definitions can often overlap, depending onthe context.
For example, the term PBS most com-monly abbreviates Phosphate Buffered Saline, butin other contexts may refer to the following: PainBehavior Scale, Painful Bladder Syndrome, PairedDomain-Binding Site, Particle Based Simulation,Partitioned Bremer Support, Pharmaceutical Bene-fits Scheme, and more.
Some abbreviations fall be-tween these two definitions in the sense that they arenormally defined in the text, however, they have be-come widely used, and therefore they do not nor-mally overlap with other abbreviations.
An exam-ple for this is the term ATP which, almost exclu-sively, abbreviates adenosine triphosphate, and isonly rarely used in different contexts in biomedicine.Gaudan et al (2005) define two similar con-cepts, distinguishing Global and Local abbrevia-tions.
Global abbreviations are not defined withinthe document, similar to common abbreviation.
Lo-cal abbreviations appear in the document alongsidethe long form, similar to dynamic abbreviations.The contextual ambiguity of dynamic, or local, ab-breviations makes them an important target for ab-breviation recognition tasks.There is a great deal of variation in the way thatdifferent authors produce abbreviations.
Our defini-tion of abbreviation is quite flexible and can best be47represented by the set of examples described in Ta-ble 1.
These include simple acronyms, in which thefirst letter of every word from the long form is rep-resented in the short form, as well as more complexcases such as: inner letter matches, missing shortform characters, and specific substitutions (such asof a chemical element and its symbol).
We gener-ally assume that the abbreviated form contains somecontraction of words or phrases from the full form.This definition is consistent with the one defined bymany other extraction systems (see e.g., (Schwartzand Hearst, 2002) and (Chang et al, 2002)).We describe a method for extracting dynamic ab-breviations, which are explicitly defined in biomed-ical abstracts.
For each of the input texts, the taskis to identify and extract ?short form, long form?pairs of the abbreviations defined within the text.
Wealso provide a mapping, formed as an alignment, be-tween the characters of the two forms, and the prob-ability of this alignment according to our model.Our approach is based on dividing the abbrevia-tion recognition task into the following stages: (1)Parsing the text and extracting candidate abbrevia-tion pairs (long and short forms) based on textualcues, such as parentheses; (2) Recovering a validalignment between the short and long form candi-dates (valid alignments are defined in Section 3.2).We perform a sequential alignment based on a pair-HMM; (3) Extracting a final short and long formfrom the alignment.We will show that our approach is fast and accu-rate: we report 98% precision and 93% recall on astandard data set, and 95% precision and 91% recallon a validation set.
The alignment model: (1) is sim-pler and faster than a comparable alignment-basedabbreviation extractor; (2) is naturally generalizableto specific types of abbreviations; (3) is trained on aset of unlabeled examples; and (4) associates a prob-ability with each predicted definition.2 Related WorkA wide variety of methods have been introducedfor recognizing abbreviations in biomedical context.Many utilize one of the following techniques: rule-based extraction, and extraction that relies on analignment of the abbreviation and full definition.Abbreviation extraction methods have been used intwo main contexts: to create online collections ofabbreviations, normally extracted from PubMed ab-stracts (Zhou et al, 2006; Gaudan et al, 2005; Adar,2004), and as part of larger learning frameworks,mainly for feature generation (Chowdhury et al,2010; Huang et al, 2011).Rule based extraction systems use a set of man-ually crafted pattern-matching rules to recognizeand extract the pair of abbreviation and defini-tion: Acrophile (Larkey et al, 2000) is an acronymrecognition system that exploits morphological rulesbased on the case of the characters in the definitions.Unlike many of the other available systems, it rec-ognized acronyms that are defined without paren-theses; The Alice system (Ao and Takagi, 2005) isbased on three extraction phases, each employingan elaborate set of over 15 rules, patterns and stopword lists.
Liu and Friedman (2003) use a set ofstatistical rules to resolve cases in which an abbre-viation is defined more than once with several dif-ferent definitions.
While these methods normallyachieve high performance results, their main draw-back is that they are difficult to implement and toextend.
Rule development is normally based on athorough investigation of the range of targeted ab-breviations and the resulting heuristic patterns con-tain subtleties that are hard to recreate or modify.Several extraction methods have been developedbased on some variant of the Longest Common Sub-sequence algorithm (LCS) (Schwartz and Hearst,2002; Chang et al, 2002; Taghva and Gilbreth,1999; Bowden et al, 1997).
These systems searchfor at least one possible alignment of an abbrevia-tion and a full form definition.The most widely used abbreviation extraction sys-tem is that presented by Schwartz and Hearst (2002).Their method scans the input text and extract pairsof candidate abbreviations from text surroundingparentheses.
The algorithm scans the candidate defi-nition from right to left, and searches for an implicitalignment of the definition and abbreviation basedon few ad-hoc rules.
This algorithm presents severalconstraints on the type of recognized abbreviations,the most restrictive being that every letter of the ab-breviation must be matched during the process ofscanning the definition.
Of the variety of availableextraction systems, this remains a popular choicedue to its simplicity and speed.
However, as the au-48Short Long Type of AbbreviationAMS Associated Medical Services Acronym using the first letter of each long-form word.PS postsynaptic Inner letters are represented in the abbreviation.NTx cross-linked N-telopeptides 1.
Phonetic substitution (cross?
x).2.
The short form is out-of-order.3.
Words from the long form are missing in the short form (linked).EDI-2 Eating Disorders Inventory Characters from the short form are missing in the long form (-2).NaB sodium butyrate Substitution of a chemical element by its symbol (sodium?
Na).MTIC 5-(3-N-methyltriazen-1-yl)-imidazole-4-carboxamideChemical formula.EBNA-1 Epstein-Barr virus (EBV) nuclearantigen 1Recursive definition, in which the long form contains another ab-breviation definition.3-D three-dimensional Substitution of a number name and symbol (three?
3).A&E accident and emergency Substitution of a word and symbol (and?
&).anti-Tac antibody to the alpha subunit of theIL-2 receptorSynonym: the short form commonly represents the long form, al-though it is not a direct abbreviation of it.R.E.A.L.
?Revised European-American Clas-sification of Lymphoid Neoplasms?The long- and/or short-forms contain characters that are not di-rectly related to the abbreviation (e.g., punctuation symbols).Table 1: Examples of biomedical abbreviations.thors report, this algorithm is less specific than otherapproaches and consequently results in lower recall.We will show that by performing an explicit align-ment of the abbreviation using an alignment-HMM,our model results in more accurate predictions, andthat the edit operations used in the alignment allowfor natural extensions of the abbreviations domain.Another frequently used alignment based ap-proach is that of Chang et al (2002), and it is closestto our approach.
After calculating an abbreviationalignment, they convert the set of aligned terms intoa feature vector which is scored using a binary logis-tic regression classifier.
Using a correct threshold onthe alignment scores produces a high performanceabbreviation extractor.
However this approach hasseveral drawbacks.
The run-time of this algorithmis fairly long (see Section 4.3), in part due to thesteps following the alignment recovery, i.e., calcu-lating a feature vector, and generating an alignmentscore.
Additionally, choosing a score threshold maydepend on the genre of text, and different thresh-olds lead to a variety of quality in the results.
Wewill show that presenting limitations on the range ofavailable alignments can produce correct alignmentsmore efficiently and quickly, maintaining high qual-ity results, without the need for threshold selection.Our alignment method distinguishes and penalizesinner and leading gaps in the alignment, and it ap-plies a set of constraints on the range of legal align-ments.
We will also show that relying solely on con-strained alignments still allows for flexibility in thedefinition of the range of desired abbreviations.Ristad and Yianilos (1998) proposed a single statealignment-HMM for learning string-edit distancebased on matched strings.
In later work, Bilenko andMooney (2003) extend this model to include affinegaps, by including in their model separate statesfor Matches, Deletions and Insertions.
McCallumet al (2005) describe a discriminative string editCRF, following a similar approach to that of Bilenkoand Mooney.
The CRF model includes two disjointsets of states, each representing either ?matching?
or?mismatching?
string pairs.
Each of the sets is sim-ilar to the model described by Bilenko and Mooney.All of these models require labeled training exam-ples, and the CRF approach also requires negativetraining examples, which train the ?mismatching?states of the model.
We describe an alignment HMMthat is suited for aligning abbreviation long and shortforms, and does not require any labeling of the inputtext or training examples.3 MethodIn the following sections we describe a method forextracting candidate abbreviation definitions fromtext, and an alignment model with affine gaps for49Description Resulti.
Input sentence: ?anti-sperm antibodies were studied by indirect mixed anti-globulin reaction test (MAR)?ii.
Candidate: ?MAR, by indirect mixed anti-globulin reaction test?iii.
Alignment:HMM StatesShort FormLong FormLG LG LG LG M M M M IG M M M IGM A Rby indirect mixed anti - globulin reaction testiv.
Abbreviation: ?MAR, mixed anti-globulin reaction test?Table 2: Example of the processing steps of a sample sentence.
(i) Input sentence containing a single abbreviation.
(ii) Candidate ?short form, long form?
pair extracted from the sentence (after truncating the long-form).
(iii) Themost likely (Viterbi) alignment of the candidate pair, using our alignment model.
Each state corresponds to a singleedit-operation, which consumed the corresponding short-form and long-form characters in the alignment.
(iv) Finalabbreviation, extracted from the alignment by removing leading gaps.matching the two forms of a candidate definition.Finally we describe how to extract the final abbre-viation prediction out of the alignment.3.1 Extracting candidate abbreviationsThe process described below scans the text for tex-tual cues and extracts a list of candidate abbreviationpairs, for every input document, in the form: ?shortform, long form?.
The following text also describesthe restrictions and conditions of what we considerto be valid candidate pairs.
The assumptions madein this work are generally less restrictive that thoseintroduced by previous extraction systems and theylead to a larger pool of candidate definitions.
Wewill later show that false candidates normally pro-duce invalid alignment of their short and long forms,according to our alignment model, and so they areremoved and do not affect the final results.The parsing process includes a search for bothsingle abbreviations, and abbreviation patterns.
Anexample of a sentence with a single abbreviationcan be seen in Table 2(i).
We consider the fol-lowing two cases of a single abbreviation defini-tion: (1) ?long form (short form)?, and (2) ?shortform (long form)?.
Note that in some cases, theterm within the parenthesis is parsed, e.g., in thefollowing text, ELISA is extracted from the paren-thesis, by removing the text beyond the ?;?
symbol:?.
.
.
human commercial enzyme-linked immunosor-bent assay (ELISA; BioGen, Germany) .
.
.
?.We also consider abbreviation patterns whichdefine multiple abbreviations simultaneously, asdemonstrated by these examples:?
?anti-sperm (ASA), anti-phospholipid (APA),and antizonal (AZA) antibodies?
?
The mainnoun (antibodies) follows the pattern.?
?Epithelial-mesenchymal transition (EMT)and interaction (EMI)?
?
The main noun(Epithelial-mesenchymal) is at the head of thepattern.Using textual cues (patterns and parentheses) weextract candidate short and long forms.
Wheneverpossible, we consider the term within the parenthe-sis as the short form, and the text to the left of theparenthesis (until the beginning of the sentence) asthe candidate long form.
We consider valid shortforms to be no longer than 3 words, having between1 and 15 characters, and containing at least one let-ter.
In the case that the candidate short form wasfound to be invalid by these definitions, we switchthe assignment of long and short forms.
The long-form string is truncated, following Park and Byrd(2001), to a length of min(|A|+ 5, |A| ?
2), where|A| is the length of the short form.The length of the candidate long form is estimatedusing the Park and Byrd formula, and it is thereforenormally the case that the resulting candidate longform contains some leading characters that are notpart of the abbreviation definition.
Next, we definean alignment between short and long form strings50<?CRF-BP?, ?ligands for the corticotrophin-releasing factor binding protein?>|  |   |  |   |  |C             | |R        | |F     | |-|B      | |P      | ligands|  |for|  |the|  |corticotrophin|-|releasing| |factor| | |binding| |protein|!
"#$"%"&$"'"Figure 1: Abbreviation alignment HMM model withstates: start (s), leading gaps (LG), match (M), inner gap(IG) and end (e).EditOperationSFMatchLFMatchValidStatesLF deletion  alpha-numericcharLG, IGLF deletion  punct.
symbol LG, MLF deletion  word LG, IGSF deletion digit or punct.
 IGMatch char (partial) word MMatch char char MSubstitution ?&?
?and?
MSubstitution ?1?-?9?
?one?-?nine?
MSubstitution chem.
symbol chemical name MTable 3: Edit operations used in the alignment HMMmodel including, long form (LF) and short form (SF)deletions, matches and substitutions.
We note the SF andLF characters consumed by each edit operation, and theHMM states in which it may be used.which detects possible segments that are missing inthe alignment in either string (gaps).3.2 Aligning candidate long and short formsFor each of the candidate pairs produced in the pre-vious step, we find the best alignment (if any) be-tween the short and the long form strings.
We de-scribe an alignment HMM that is suited for abbrevi-ation alignments.
The model is shown in Figure 1,and Table 2 shows the parsing process of a sam-ple sentence, including an alignment created for thissample using the model.3.3 Abbreviation Alignment with AffineLeading and Inner GapsAn alignment between a long and a short form of anabbreviation can be modeled as a series of edit oper-ations between the two strings, in which charactersfrom the short form may match a single or a seriesof characters from the long form.
In previous work,Bilenko and Mooney (2003) describe a generativemodel for string edit distance with affine gaps, andan Expectation Maximization algorithm for learningthe model parameters using a labeled set of match-ing strings.
We propose a similar model for aligningthe short and long form of an abbreviation, using anaffine cost model for gapscost(g) = s+ e ?
l (1)where s is the cost of starting a gap, e is the cost ofextending a gap and l is the length of the gap.
In ourmethod, we use extracted candidate pairs (candidateshort and long forms) as training examples.As described above, candidate long forms areformed by extracting text preceding parentheses andtruncating it to some length.
This process may leadto candidate long forms that contain leading charac-ters that do not belong to the abbreviation, whichwill result in leading gaps in the final alignment.For example, the candidate long form presented inTable 2(ii) contains the leading text ?by indirect ?.While extra leading text is expected as an artifact ofour candidates extraction method, inner alignmentgaps are not expected to commonly appear in abbre-viation alignments, and are usually an indication of abad alignment.
The example presented in Table 2 isof an abbreviation that does contain inner gaps (e.g.,globulin) despite being a valid definition.We distinguish leading and inner alignment gapsusing a model with five states: Leading Gap (LG),Match (M), Inner Gap (IG), and two ?dummy?
statesfor the beginning and end of an alignment (Figure 1).Since leading and inner gaps are represented by dif-ferent states, their penalization is not coupled, i.e.,they are associated with different s, e and l costs.We use the EM algorithm to learn the model param-eters, based on a set of unlabeled candidate pairs,following the assumption that many false-candidateswill not produce a valid alignment, and will not af-fect training.
This is in contrast to previous stringedit distance models, which require labeled trainingexamples.The main effort in developing a successful ab-breviation alignment model involves generating ameaningful set of edit operations.
The edit opera-tions used in our model,E = Ed?Em?Es, is shownin Table 3 and includes: Ed, deletions of charactersor words from the long form, or of single characters51from the short form; Em, matches of a full of par-tial word from the long form to a character in theshort form; and Es, word substitutions in which aword from the long form is replaced by a symbol inthe short form.
Note that: (1) while all types of dele-tions from the long form are valid, deletions from theshort form are limited to digits and punctuation sym-bols, and (2) deletion of non-alpha-numeric charac-ters from the long form is not considered as openinga gap but as a match, as it is common for non-alpha-numeric characters to be missing in an abbreviation(i.e., be ?matched?
with the empty string, ).Let x = x1 .
.
.
xT be the short form candidate,y = y1 .
.
.
yV be the long form candidate, anda = ?ap?np=1, ap = (ep, qp, ixp, jyp), be a pos-sible alignment of the strings x and y. a repre-sents as a sequence of HMM transitions, ap, whereep ?
E is an edit operation that consumes charac-ters from x (deletion from the long form), y (dele-tion from the short form), or both (match or substi-tution), up to position ixp in x and jyp in y, andis associated with a transition in the model to stateqp ?
{LG,M, IG, e}.
Let pi(q, q?)
be the transitionprobability between states q and q?, and let ?
(q, e)be the emission probability of the edit operation e atstate q.
Given a candidate abbreviation pair ?x, y?,and the model parameters pi and ?
, the probability ofan alignment is given byp(a|x, y, pi, ?)
=|a|?p=1pi(qp?1, qp) ?
?
(qp, ep) (2)where q0 is the start state.
This probability can becalculated efficiently using dynamic programmingwith the forward-backward algorithm, and the mostlikely alignment corresponds to the Viterbi distancebetween x and y.In our method, the model parameters, pi and ?
,are estimated using the EM algorithm on an unla-beled training set of candidate pairs that have beenextracted from the text, without any further process-ing.
At each EM iteration, we train on pairs that havevalid alignments (see below) with non-zero proba-bility under the model parameters at that iteration.3.3.1 Valid AlignmentsGiven the edit operations defined above, the onlyvalid way of matching a letter from the short formto the long form is by matching that letter to thebeginning of a full or partial word, or by matchingthat letter using a substitution operation.
There isno edit operation for deleting letters from the shortform (only digits and punctuation symbols can bedeleted).
This means that for some candidate pairsthere are no valid alignments under this model, inwhich case, no abbreviation will be predicted.3.3.2 Extracting the Final AbbreviationGiven a valid alignment a between the candi-date pair, x and y, we create a truncated alignment,a?, by removing from a initial transitions in whichqp = LG.
We consider a?
valid if the number ofmatches in a?
= ?a?p?n?p=1 is greater than the numberof deletions,n?
?p=1I(q?p = M) >n?
?p=1I(q?p = IG) (3)where I is an indicator function.The final abbreviation prediction is given by theportions of the x and y strings that are associatedwith a?, named x?
and y?, respectively.
These may betruncated compared to x and y, as leading alignmentgaps are removed.
The final alignment probability isgiven by p(a?|x?, y?, pi, ?
).3.4 Substitution Edit OperationsIn contrast to rule-based extraction algorithms, inour model, it is easy to introduce new types of editoperations, and adjust the model to recognize a va-riety of abbreviation types.
As an example, we haveadded a number of substitution operations (see Ta-ble 3), including an operation for the commonlyused convention of replacing a chemical elementname (e.g., Sodium) with its symbol (Na).
Thesetypes of operations are not available using simplermodels, such as that presented by Schwartz andHearst (2002), making it impossible to recognizesome important biomedical entities, such as chem-ical compounds (e.g., ?NaB, SodiumButyrate?
).In contrast, such additions are natural in our model.4 Evaluation4.1 Abbreviation Extraction AnalysisWe evaluated the alignment abbreviation model overtwo data sets (Table 4).
The method was tuned using52Data Set Name Abstracts Abbreviations Testing MethodDevelopment (D) Medstract 400 483 10-fold cross validation.Validation (V) PubMed Sample 50 76 Training on set D and testing on set V.Table 4: Evaluation Data Sets.Model D (average %) V (%)P R F1 P R F1Alignment HMM 98 93 96 95 91 93SH 96 88 91 97 83 89Chang 0.88 99 46 62 97 47 64Chang 0.14 94 89 91 95 91 93Chang 0.03 92 91 91 88 93 90Chang 0 49 92 64 53 93 67Table 5: Results on validation (V) and development (D)sets.
Average results are shown for D set, which wastested using 10-fold cross-validation (results rounded tonearest percent, all standard deviations were < 0.1)10 fold cross-validation over the publicly availableMedstract corpus (Pustejovsky et al, 2002) whichincludes 400 Medline abstracts.
The online versionof the corpus was missing the Gold Standard annota-tions throughout the development of our algorithm,nor was it possible to get them through communica-tion with the authors.
We therefore hand-annotatedthe Medstract data, yielding 483 abbreviation defi-nitions in the form of ?short form, long form?
pairs.In order to be consistent with previous evaluationsover Medstract, our annotations include only defini-tions in which either the short or the long form ap-pear in parenthesis, and it is assumed that there areno trailing gaps in the term preceding the parenthe-sis, although our model does detect such gaps.We compare our results with two algorithmsavailable for download: the Schwartz and Hearst(SH; (2002)) algorithm1, and the Chang et al (2002)algorithm2 used at three score cutoffs reported intheir paper (0.88, 0.14, 0.03).
We also use a fourthscore cutoff of 0 to account for any legal alignmentsproduced by the Chang model.In Table 5 we report precision (P), recall (R) and1Taken from http://biotext.berkeley.edu/software.html2Taken from http://abbreviation.stanford.eduF1 scores for all methods, calculated byP =correct predicted abbreviationsall predicted abbreviations(4)R =correct predicted abbreviationsall correct abbreviations(5)On the development set, our alignment modelachieves 98% precision, 93% recall and 96% F1 (av-erage values over cross-validation iterations, withstandard deviations all under 0.03).To test the final model we used a validationdataset consisting of 50 abstracts, randomly selectedout of a corpus of 200K full-text biomedical articlestaken from the PubMed Central Open Access Sub-set (extracted in October 2010)3.
These were hand-annotated, yielding 76 abbreviation definitions.On the validation set, we predicted 69 out of 76abbreviations, with 4 false predictions, giving 95%precision, 91% recall and 93% F1.
Our alignmentmodel results in higher F1 score over all baselinesin both datasets (with Chang0.14 giving equal resultson the validation set).
Our results are most compa-rable with the Chang model at a score cutoff of 0.14,though our model does not require selecting a scorecutoff, and as we will show, it is considerably faster.Interestingly, our model results in lower recall thanprecision on both data sets.
This may be due to alimited scope of edit operations.In order to evaluate the usability of our method,we used it to scan the 200K full-text documents ofthe PubMed Central Open Access Subset corpus.The process completed in under 3 hours, yieldingover 1.4 million abbreviations, including 455,844unique definitions.
A random sample of the ex-tracted abbreviations suggests a low rate of falsepositive predictions.4.2 Error AnalysisOur model makes 4 incorrect predictions on the val-idation set, 3 of which are partial matches to the3http://www.ncbi.nlm.nih.gov/pmc/53Description D VLetters in short form are missing (e.g., ?GlyRalpha2, glycine alpha2?)
5 3Abbreviation missed due to extraction rules.
6 1Abbreviation is a synonym (e.g., ?IRX-2, natural cytokine mixture?)
5 1Abbreviation letters are out-of-order (e.g., ?VSV-G, G glycoprotein of vesicular stomatitis virus?)
4 1Correct alignment was found but it is invalid due to many inner gaps (see Section 3.3.1).
5 0Abbreviations of chemical formulas or compounds.
4 0Table 6: Abbreviations missed in development (D) and validation (V) sets.correct definitions, e.g., we predict the pair ?GlOx,glutamate oxidase?
instead of ?GlOx, L-glutamateoxidase?.
On the development set, 3 out of 5 incor-rect predictions are partial matches.Our model did not extract 7 of the abbreviationsfrom the validation set and 33 from the developmentset.
Many of these abbreviations (6 from the valida-tion set and 29 from the development set) had oneof the properties described in Table 6.
The remain-ing 5 definitions have been missed due to miscel-laneous issues.
Note that while we added severalsubstitution operations for chemical formula recog-nition, the elaborate set of operations required forrecovering the full range of chemical formulas wasnot included in this work, leading to 4 chemical for-mula abbreviations being missed.4.3 Run-Time AnalysisWe provide an estimated comparison of the runtime of our method and the baseline algorithms.This analysis is especially interesting for cases inwhich an abbreviation extraction model is includedwithin a larger learning framework (Chowdhury etal., 2010; Huang et al, 2011), and may be used init in an online fashion.
Run time was evaluated onan Apple iMac with 4GB 1333 MHz RAM, and a3.06 GHz Core i3, double-core processor, by run-ning all models on a random set of 400 abstracts.In order to evaluate the run time contribution of thesubstitution operations introduced in our model weran it both with (88 docssec ) and without (98docssec ) theuse of substitution operations.
We find that usingsubstitutions did not have considerable effect on runtime, adding under 1 ms for processing each docu-ment.
We should note that the performance of thesubstitution-less model on this test data was similarto that of the original model, as substitutions wererelevant to only a smaller portion of the abbrevi-ations.
As expected, the SH algorithm is consid-erably faster (6451 docssec ) than our model, as it isbased on only a number of simple rules.
The Changmodel, however, is slower (4 docssec ) as it includesprocessing steps following the discovery of an ab-breviation alignment, which means that our modelprovides comparable results to the Chang model andruns an order-of-magnitude faster.5 Conclusions and DiscussionWe presented a method for extracting abbreviationdefinitions with high precision and high recall (95%precision, 91% recall and 93% F1 on a validationset).
Our model achieves higher F1 on both the de-velopment and validation data sets, when comparedwith two popular extraction methods.Our approach is based on a sequential genera-tive model, aligning the short and long form of anabbreviation.
Using the proposed method we ex-tracted 1.4 million abbreviations from a corpus of200K PubMed articles.
This data can be valuablefor Information Extraction tasks and for the full un-derstanding of biomedical scientific data.The alignment abbreviation extractor can be eas-ily extended by adding edit-operations over shortand long forms.
This was demonstrated by includingsubstitutions of chemical elements and their sym-bols, which facilitates recognition of chemical for-mulas and compounds.We have identified the main classes of abbrevia-tion definitions missed by our approach.
These in-clude out-of-order matches, synonym-like abbrevia-tions, and short forms with excess letters.
It may bepossible to address some of these issues by includ-ing ?global?
information on abbreviations, such asthe occurrence of frequent definitions.54AcknowledgmentsThis work was funded by grant 1R101GM081293from NIH, IIS-0811562 from NSF and by a gift fromGoogle.
The opinions expressed in this paper aresolely those of the authors.ReferencesE.
Adar.
2004.
Sarad: A simple and robust abbreviationdictionary.
Bioinformatics, 20(4):527?533.JL Ambrus.
1987.
Acronyms and abbreviations.
Journalof medicine, 18(3-4):134.H.
Ao and T. Takagi.
2005.
Alice: an algorithm to extractabbreviations from medline.
Journal of the AmericanMedical Informatics Association, 12(5):576?586.M.
Bilenko and R.J. Mooney.
2003.
Adaptive duplicatedetection using learnable string similarity measures.In Proceedings of the ninth ACM SIGKDD interna-tional conference on Knowledge discovery and datamining, pages 39?48.
ACM.P.R.
Bowden, P. Halstead, and T.G.
Rose.
1997.
Dic-tionaryless english plural noun singularisation usinga corpus-based list of irregular forms.
LANGUAGEAND COMPUTERS, 20:339?352.J.T.
Chang, H. Schu?tze, and R.B.
Altman.
2002.
Cre-ating an online dictionary of abbreviations from med-line.
Journal of the American Medical Informatics As-sociation, 9(6):612?620.M.
Chowdhury, M. Faisal, et al 2010.
Disease mentionrecognition with specific features.
In Proceedings ofthe 2010 Workshop on Biomedical Natural LanguageProcessing, pages 83?90.
Association for Computa-tional Linguistics.H.L.
Fred and T.O.
Cheng.
2003.
Acronymesis: theexploding misuse of acronyms.
Texas Heart InstituteJournal, 30(4):255.S.
Gaudan, H. Kirsch, and D. Rebholz-Schuhmann.2005.
Resolving abbreviations to their senses in med-line.
Bioinformatics, 21(18):3658?3664.M.
Huang, J. Liu, and X. Zhu.
2011.
Genetukit: a soft-ware for document-level gene normalization.
Bioin-formatics, 27(7):1032?1033.L.S.
Larkey, P. Ogilvie, M.A.
Price, and B. Tamilio.2000.
Acrophile: an automated acronym extractor andserver.
In Proceedings of the fifth ACM conference onDigital libraries, pages 205?214.
ACM.H.
Liu, C. Friedman, et al 2003.
Mining terminologicalknowledge in large biomedical corpora.
In Pac SympBiocomput, pages 415?426.A.
McCallum, K. Bellare, and F. Pereira.
2005.
A condi-tional random field for discriminatively-trained finite-state string edit distance.
In Conference on Uncer-tainty in AI (UAI).Y.
Park and R.J. Byrd.
2001.
Hybrid text mining for find-ing abbreviations and their definitions.
In Proceedingsof the 2001 conference on empirical methods in natu-ral language processing, pages 126?133.J.
Pustejovsky, J. Castano, R. Sauri, A. Rumshinsky,J.
Zhang, and W. Luo.
2002.
Medstract: creat-ing large-scale information servers for biomedical li-braries.
In Proceedings of the ACL-02 workshopon Natural language processing in the biomedicaldomain-Volume 3, pages 85?92.
Association for Com-putational Linguistics.E.S.
Ristad and P.N.
Yianilos.
1998.
Learning string-editdistance.
Pattern Analysis and Machine Intelligence,IEEE Transactions on, 20(5):522?532.A.S.
Schwartz and M.A.
Hearst.
2002.
A simplealgorithm for identifying abbreviation definitions inbiomedical text.
In Pacific Symposium on Biocomput-ing 2003: Kauai, Hawaii, 3-7 January 2003, page 451.World Scientific Pub Co Inc.K.
Taghva and J. Gilbreth.
1999.
Recognizing acronymsand their definitions.
International Journal on Docu-ment Analysis and Recognition, 1(4):191?198.H.
Yu, G. Hripcsak, and C. Friedman.
2002.
Map-ping abbreviations to full forms in biomedical articles.Journal of the American Medical Informatics Associa-tion, 9(3):262?272.H.
Yu, W. Kim, V. Hatzivassiloglou, and W.J.
Wilbur.2007.
Using medline as a knowledge source for dis-ambiguating abbreviations and acronyms in full-textbiomedical journal articles.
Journal of biomedical in-formatics, 40(2):150?159.W.
Zhou, V.I.
Torvik, and N.R.
Smalheiser.
2006.
Adam:another database of abbreviations in medline.
Bioin-formatics, 22(22):2813.55
