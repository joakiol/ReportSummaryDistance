Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 117?128,Paris, October 2009. c?2009 Association for Computational LinguisticsConstructing parse forests that include exactly the n-best PCFG treesPierre Boullier1, Alexis Nasr2 and Beno?
?t Sagot11.
Alpage, INRIA Paris-Rocquencourt & Universite?
Paris 7Domaine de Voluceau ?
Rocquencourt, BP 105 ?
78153 Le Chesnay Cedex, France{Pierre.Boullier,Benoit.Sagot}@inria.fr2.
LIF, Univ.
de la Me?diterranne?e163, avenue de Luminy - Case 901 ?
13288 Marseille Cedex 9, FranceAlexis.Nasr@lif.univ-mrs.frAbstractThis paper describes and compares two al-gorithms that take as input a shared PCFGparse forest and produce shared foreststhat contain exactly the n most likely treesof the initial forest.
Such forests aresuitable for subsequent processing, suchas (some types of) reranking or LFG f-structure computation, that can be per-formed ontop of a shared forest, but thatmay have a high (e.g., exponential) com-plexity w.r.t.
the number of trees containedin the forest.
We evaluate the perfor-mances of both algorithms on real-scaleNLP forests generated with a PCFG ex-tracted from the Penn Treebank.1 IntroductionThe output of a CFG parser based on dynamicprogramming, such as an Earley parser (Earley,1970), is a compact representation of all syntac-tic parses of the parsed sentence, called a sharedparse forest (Lang, 1974; Lang, 1994).
It can rep-resent an exponential number of parses (with re-spect to the length of the sentence) in a cubic sizestructure.
This forest can be used for further pro-cessing, as reranking (Huang, 2008) or machinetranslation (Mi et al, 2008).When a CFG is associated with probabilistic in-formation, as in a Probabilistic CFG (PCFG), itcan be interesting to process only the n most likelytrees of the forest.
Standard state-of-the-art algo-rithms that extract the n best parses (Huang andChiang, 2005) produce a collection of trees, los-ing the factorization that has been achieved by theparser, and reproduce some identical sub-trees inseveral parses.This situation is not satisfactory since post-parsing processes, such as reranking algorithmsor attribute computation, cannot take advantageof this lost factorization and may reproduce someidentical work on common sub-trees, with a com-putational cost that can be exponentally high.One way to solve the problem is to prune theforest by eliminating sub-forests that do not con-tribute to any of the n most likely trees.
But thisover-generates: the pruned forest contains morethan the n most likely trees.
This is particularlycostly for post-parsing processes that may requirein the worst cases an exponential execution timew.r.t.
the number of trees in the forest, such asLFG f-structures construction or some advancedreranking techniques.
The experiments detailedin the last part of this paper show that the over-generation factor of pruned sub-forest is more orless constant (see 6): after pruning the forest so asto keep the n best trees, the resulting forest con-tains approximately 103n trees.
At least for somepost-parsing processes, this overhead is highlyproblematic.
For example, although LFG parsingcan be achieved by computing LFG f-structureson top of a c-structure parse forest with a reason-able efficiency (Boullier and Sagot, 2005), it isclear that a 103 factor drastically affects the overallspeed of the LFG parser.Therefore, simply pruning the forest is not anadequate solution.
However, it will prove usefulfor comparison purposes.The new direction that we explore in this pa-per is the production of shared forests that con-tain exactly the n most likely trees, avoiding boththe explicit construction of n different trees andthe over-generation of pruning techniques.
Thiscan be seen as a transduction which is applied ona forest and produces another forest.
The trans-duction applies some local transformations on thestructure of the forest, developing some parts ofthe forest when necessary.The structure of this paper is the following.
Sec-tion 2 defines the basic objects we will be dealingwith.
Section 3 describes how to prune a shared117forest, and introduces two approaches for build-ing shared forests that contain exactly the n mostlikely parses.
Section 4 describes experiments thatwere carried out on the Penn Treebank and sec-tion 5 concludes the paper.2 Preliminaries2.1 Instantiated grammarsLet G = ?N ,T ,P, S?
be a context-free grammar(CFG), defined in the usual way (Aho and Ullman,1972).
Throughout this paper, we suppose that wemanipulate only non-cyclic CFGs,1 but they may(and usually do) include ?-productions.
Given aproduction p ?
P, we note lhs(p) its left-handside, rhs(p) its right-hand side and |p| the lengthof rhs(p).
Moreover, we note rhsk(p), with 1 ?k ?
|p|, the kth symbol of rhs(p).
We call A-production any production p ?
P of G such thatlhs(p) = A.A complete derivation of a sentence w =t1 .
.
.
t|w| (?i ?
|w|, ti ?
T ) w.r.t.
G is of the formS ??G,w?A?
?G,w?X1X2 .
.
.
Xr?
??G,ww.
By def-inition, A ?
X1X2 .
.
.
Xr is a production of G.Each of A, X1, X2, .
.
.
, Xr spans a unique oc-currence of a substring ti+1 .
.
.
tj of w, that canbe identified by the corresponding range, notedi..j.
A complete derivation represents a parse treewhose yield is w, in which each symbol X ofrange i..j roots a subtree whose yield is ti+1 .
.
.
tj(i.e., a derivation of the form X ?
?G,wti+1 .
.
.
tj).Let us define the w-instantiation operation (orinstantiation).
It can be applied to symbols andproductions of G, and to G itself, w.r.t.
a stringw.
It corresponds to the well-known intersectionof G with the linear automaton that correspondsto the string w. We shall go into further detail forterminology, notation and illustration purposes.An instantiated non terminal symbol is a triplenoted Ai..j where A ?
N and 0 ?
i ?
j ?
|w|.Similarly, an instantiated terminal symbol is atriple noted Ti..j where T ?
T and 0 ?
i ?
j =i + 1 ?
|w|.
An instantiated symbol, terminal ornon terminal, is noted Xi..j .
For any instantiatedsymbol Xi..j , i (resp.
j) is called its lower bound1Actually, cyclic CFG can be treated as well, but notcyclic parse forests.
Therefore, if using a cyclic CFG which,on a particular sentence, builds a cyclic parse forest, cycleshave to be removed before the algorithms descibed in the nextsections are applied.
This is the case in the SYNTAX system(see below).(resp.
upper bound), and can be extracted by theoperator lb() (resp.
ub()).An instantiated production (or instantiatedrule) is a context-free production Ai..j ?X1i1..j1X2i2..j2 .
.
.
Xrir ..jr whose left-hand side is aninstantiated non terminal symbol and whose right-hand side is a (possibly empty) sequence of in-stantiated (terminal or non terminal) symbols, pro-vided the followings conditions hold:1. the indexes involved are such that i = i1, j =jr , and ?l such that 1 ?
l < r, jl = il+1;2. the corresponding non-instantiated produc-tion A ?
X1X2 .
.
.
Xr is a production ofG.If lhs(p) = Ai..j , we set lb(p) = i and ub(p) = j.In a complete derivation S ??G,w?A?
?G,w?X1X2 .
.
.
Xr?
?
?G,ww, any symbol X that spansthe range i..j can be replaced by the instantiatedsymbols Xi..j .
For example, the axiom S can bereplaced by the instantiated axiom S0..|w| in thehead of the derivation.
If applied to the wholederivation, this operation creates an instantiatedderivation, whose rewriting operations define aparticular set of instantiated productions.
GivenG and w, the set of all instantiated productions in-volved in at least one complete derivation of w isunique, and noted Pw.
An instantiated derivationrepresents an instantiated parse tree, i.e., a parsetree whose node labels are instantiated symbols.In an instantiated parse tree, each node label isunique, and therefore we shall not distinguish be-tween a node in an instantiated parse tree and itslabel (i.e., an instantiated symbol).Then, the w-instantiated grammar Gw for Gand w is a CFG ?Nw,Tw,Pw, S0..|w|?
such that:1.
Pw is defined as explained above;2.
Nw is a set of instantiated non terminal sym-bols;3.
Tw is a set of instantiated terminal symbols.It follows from the definition of Pw that (instan-tiated) symbols of Gw have the following prop-erties: Ai..j ?
Nw ?
A ?
?G,w ti+1 .
.
.
tj , andTi..j ?
Tw ?
T = tj .The w-instantiated CFG Gw represents all parsetrees for w in a shared (factorized) way.
It is thegrammar representation of the parse forest of w118w.r.t.
G.2 In fact, L(Gw) = {w} and the setof parses of w with respect to Gw is isomorphicto the set of parses of w with respect to G, theisomorphism being the w-instantiation operation.The size of a forest is defined as the size of thegrammar that represents it, i.e., as the number ofsymbol occurrences in this grammar, which is de-fined as the number of productions plus the sum ofthe lengths of all right-hand sides.Example 1: First running example.Let us illustrate these definitions by an example.Given the sentence w = the boy saw a man with atelescope and the grammar G (that the reader hasin mind), the instantiated productions of Gw are:Det0..1 ?
the0..1 N1..2 ?
boy1..2NP0..2 ?
Det0..1 N1..2 V2..3 ?
saw2..3Det3..4 ?
a3..4 N4..5 ?
man4..5NP3..5 ?
Det3..4 N4..5 Prep5..6 ?
with5..6Det6..7 ?
a6..7 N7..8 ?
telescope7..8NP6..8 ?
Det6..7 N7..8 PP5..8 ?
Prep5..6 NP6..8NP3..8 ?
NP3..5 PP5..8 VP2..8 ?
V2..3 NP3..8VP2..5 ?
V2..3 NP3..5 VP2..8 ?
VP2..5 PP5..8S0..8 ?
NP0..2 VP2..8They represent the parse forest of w according toG.
This parse forest contains two trees, since thereis one ambiguity: VP2..8 can be rewritten in twodifferent ways.The instantiated grammar Gw can be repre-sented as an hypergraph (as in (Klein and Man-ning, 2001) or (Huang and Chiang, 2005)) wherethe instantiated symbols of Gw correspond to thevertices of the hypergraph and the instantiated pro-ductions to the hyperarcs.We define the extension of an instantiated sym-bol Xi..j , noted E(Xi..j), as the set of instantiatedparse trees that have Xi..j as a root.
The set of allparse trees of w w.r.t.
G is therefore E(S0..|w|).
Inthe same way, we define the extension of an in-stantiated production Xi..j ?
?
to be the subsetof E(Xi..j) that corresponds to derivations of theform Xi..j ?G,w ??
?G,wti+1 .
.
.
tj (i.e., trees rootedin Xi..j and where the daughters of the node Xi..jare the symbols of ?
).2.2 Forest traversalsLet us suppose that we deal with non-cyclicforests, i.e., we only consider forests that are rep-2In particular, if G is a binary grammar, its w-instantation(i.e., the parse forest of w) has a size O(|w|3), whereas it rep-resents a potentially exponential number of parse trees w.r.t|w| since we manipulate only non-cyclic grammars.resented by a non-recursive instantiated CFG.
Inthis case, we can define two different kinds of for-est traversals.A bottom-up traversal of a forest is a traversalwith the following constraint: an Ai..j-productionis visited if and only if all its instantiated right-hand side symbols have already been visited; theinstantiated symbol Ai..j is visited once all Ai..j-productions have been visited.
The bottom-upvisit starts by visiting all instantiated productionswith right-hand sides that are empty or containonly (instantiated) terminal symbols.A top-down traversal of a forest is a traversalwith the following constraint: a node Ai..j is vis-ited if and only if all the instantiated productionsin which it occurs in right-hand side have alreadybeen visited; once an instantiated production Ai..jhas been visited, all its Ai..j-productions are vis-ited as well.
Of course the top-down visit starts bythe visit of the axiom S0..|w|.2.3 Ranked instantiated grammarWhen an instantiated grammar Gw =?Nw,Tw,Pw, S0..|w|?
is built on a PCFG, ev-ery parse tree in E(S0..|w|) has a probability thatis computed in the usual way (Booth, 1969).
Wemight be interested in extracting the kth mostlikely tree of the forest represented by Gw,3 with-out unfolding the forest, i.e., without enumeratingtrees.
In order to do so, we need to add someextra structure to the instantiated grammar.
Theaugmented instantiated grammar will be called aranked instantiated grammar.This extra structure takes the form of n-best ta-bles that are associated with each instantiated nonterminal symbol (Huang and Chiang, 2005), thusleading to ranked instantiated non terminal sym-bols, or simply instantiated symbols when the con-text is non ambiguous.
A ranked instantiated nonterminal symbol is written ?Ai..j,T (Ai..j)?, whereT (Ai..j) is the n-best table associated with the in-stantiated symbol Ai..j .T (Ai..j) is a table of at most n entries.
Thek-th entry of the table, noted e, describes how tobuild the k-th most likely tree of E(Ai..j).
Thistree will be called the k-th extention of Ai..j , notedEk(Ai..j).
More precisely, e indicates the instanti-ated Ai..j-production p such that Ek(Ai..j) ?
E(p).It indicates furthermore which trees of the exten-3In this paper, we shall use the kth most likely tree and thetree of rank k as synonyms.119sions of p?s right-hand side symbols must be com-bined together in order to build Ek(Ai..j).We also define the m,n-extension of Ai..j asfollows: Em,n(Ai..j) = ?m?k?nEk(Ai..j).Example 2: n-best tables for the first runningexample.Let us illustrate this idea on our first running ex-ample.
Recall that in Example 1, the symbol VP2..8can be rewritten using the two following produc-tions :VP2..8 ?
V2..3 NP3..8VP2..8 ?
VP2..5 PP5..8T (VP2..8) has the following form:1 P1 VP2..8 ?
V2..3 NP3..8 ?1, 1?
12 P2 VP2..8 ?
VP2..5 PP5..8 ?1, 1?
1This table indicates that the most likely treeassociated with VP2..8 (line one) has probabilityP1 and is built using the production VP2..8 ?V2..3 NP3..8 by combining the most likely tree ofE(V2..3) (indicated by the first 1 in ?1, 1?)
with themost likely tree of E(NP3..8) (indicated by the sec-ond 1 in ?1, 1?).
It also indicates that the mostlikely tree of E(VP2..8) is the most likely tree ofE(VP2..8 ?
V2..3 NP3..8) (indicated by the pres-ence of 1 in the last column of entry 1) and thesecond most likely tree of E(VP2..8) is the mostlikely tree of E(VP2..8 ?
VP2..5 PP5..8).
This lastinteger is called the local rank of the entry.More formally, the entry T (Ai..j)[k] is definedas a 4-tuple ?Pk, pk, ~vk, lk?
where k is the rankof the entry, Pk is the probability of the treeEk(Ai..j), pk is the instantiated production suchthat Ek(Ai..j) ?
E(pk), ~vk is a tuple of |rhs(pk)|integers and lk is the local rank.The tree Ek(Ai..j) is rooted by Ai..j , and itsdaughters root N = |rhs(pk)| subtrees that areE ~vk[1](rhs1(pk)), .
.
.
, E ~vk [N ](rhsN (pk)).Given an instantiated symbol Ai..j and an in-stantitated production p ?
P (Ai..j), we definethe n-best table of p to be the table composedof the entries ?Pk, pk, ~vk, lk?
of T (Ai..j) such thatpk = p.Example 3: Second running example.The following is a standard PCFG (probabili-ties are shown next to the corresponding clauses).S ?
A B 1A ?
A1 0.7 A1 ?
a 1A ?
A2 0.3 A2 ?
a 1B ?
B1 0.6 B1 ?
b 1B ?
B2 0.4 B2 ?
b 1The instantiation of the underlying (non-probabilistic) CFG grammar by the input textw = a b is the following.S1..3 ?
A1..2 B2..3A1..2 ?
A11..2 A11..2 ?
a1..2A1..2 ?
A21..2 A21..2 ?
a1..2B2..3 ?
B12..3 B12..3 ?
b2..3B2..3 ?
B22..3 B22..3 ?
b2..3This grammar represents a parse forest that con-tains four different trees, since on the one hand onecan reach (parse) the instantiated terminal symbola1..2 through A1 or A2, and on the other hand onecan reach (parse) the instantiated terminal sym-bol b1..2 through B1 or B2.
Therefore, when dis-cussing this example in the remainder of the paper,each of these four trees will be named accordingly:the tree obtained by reaching a through Ai and bthrough Bj (i and j are 1 or 2) shall be calledTi,j .The corresponding n-best tables are trivial(only one line) for all instantiated symbols butA1..2, B2..3 and S1..3.
That of A1..2 is the follow-ing 2-line table.1 0.7 A ?
A1 ?1?
12 0.3 A ?
A2 ?1?
1The n-best table for B2..3 is similar.
The n-besttable for S1..3 is:1 0.42 S1..3 ?
A1..2 B2..3 ?1, 1?
12 0.28 S1..3 ?
A1..2 B2..3 ?1, 2?
23 0.18 S1..3 ?
A1..2 B2..3 ?2, 1?
34 0.12 S1..3 ?
A1..2 B2..3 ?2, 2?
4Thanks to the algorithm sketched in section 2.4,these tables allow to compute the following obvi-ous result: the best tree is T1,1, the second-besttree is T1,2, the third-best tree is T2,1 and the worsttree is T2,2.If n = 3, the pruned forest over-generates: allinstantiated productions take part in at least oneof the three best trees, and therefore the prunedforest is the full forest itself, which contains fourtrees.We shall use this example later on so as to il-lustrate both methods we introduce for buildingforests that contain exactly the n best trees, with-out overgenerating.2.4 Extracting the kth-best treeAn efficient algorithm for the extraction of the n-best trees is introduced in (Huang and Chiang,2005), namely the authors?
algorithm 3, which120is a re-formulation of a procedure originally pro-posed by (Jime?nez and Marzal, 2000).
Contrar-ily to (Huang and Chiang, 2005), we shall sketchthis algorithm with the terminology introducedabove (whereas the authors use the notion of hy-pergraph).
The algorithm relies on the n-best ta-bles described above: extracting the kth-best treeconsists in extending the n-best tables as much asnecessary by computing all lines in each n-best ta-ble up to those that concern the kth-best tree.4The algorithm can be divided in two sub-algorithms: (1) a bottom-up traversal of the for-est for extracting the best tree; (2) a top-downtraversal for extracting the kth-best tree providedthe (k ?
1)th-best has been already extracted.The extraction of the best tree can be seen as abottom-up traversal that initializes the n-best ta-bles: when visiting a node Ai..j , the best probabil-ity of each Ai..j-production is computed by usingthe tables associated with each of their right-handside symbols.
The best of these probabilities givesthe first line of the n-best table for Ai..j (the resultfor other productions are stored for possible lateruse).
Once the traversal is completed (the instanti-ated axiom has been reached), the best tree can beeasily output by following recursively where thefirst line of the axiom?s n-best table leads to.Let us now assume we have extracted all k?-besttrees, 1 ?
k?
< k, for a given k ?
n. We wantto extract the kth-best tree.
We achieve this recur-sively by a top-down traversal of the forest.
In or-der to start the construction of the kth-best tree, weneed to know the following:?
which instantiated production p must be usedfor rewriting the instantiated axiom,?
for each of p?s right-hand side symbols Ai..j ,which subtree rooted in Ai..j must be used;this subtree is identified by its local rankkAi..j , i.e., the rank of its probability amongall subtrees rooted in Ai..j.This information is given by the kth line of the n-best table associated with the instantiated axiom.If this kth line has not been filled yet, it is com-puted recursively.5 Once the kth line of the n-best4In the remainder of this paper, we shall use ?extractingthe kth-best tree?
as a shortcut for ?extending the n-best ta-bles up to what is necessary to extract the kth-best tree?
(i.e.,we do not necessarily really build or print the kth-best tree).5Because the k ?
1th-best tree has been computed, this n-best table is filled exactly up to line k?1.
The kth line is thentable is known, i.e., p and all kAi..j ?s are known,the rank k is added to p?s so-called rankset, noted?(p).
Then, the top-down traversal extracts recur-sively for each Ai..j the appropriate subtree as de-fined by kAi..j .
After having extracted the n-thbest tree, we know that a given production p is in-cluded in the kth-best tree, 1 ?
k ?
n, if and onlyif k ?
?
(p).3 Computing sub-forests that onlycontain the n best treesGiven a ranked instantiated grammar Gw, we areinterested in building a new instantiated grammarwhich contains exactly the n most likely trees ofE(Gw).
In this section, we introduce two algo-rithms that compute such a grammar (or forest).Both methods rely on the construction of newsymbols, obtained by decorating instantiated sym-bols of Gw.An empirical comparison of the two methods isdescribed in section 4.
In order to evaluate thesize of the new constructed grammars (forests),we consider as a lower bound the so-called prunedforest, which is the smallest sub-grammar of theinitial instantiated grammar that includes the nbest trees.
It is built simply by pruning produc-tions with an empty rankset: no new symbolsare created, original instantiated symbols are kept.Therefore, it is a lower bound in terms of size.However, the pruned forest usually overgenerates,as illustrated by Example 3.3.1 The ranksets methodThe algorithm described in this section builds aninstantiated grammar Gnw by decorating the sym-bols of Gw.
The new (decorated) symbols havethe form A?i..j where ?
is a set of integers calleda rankset.
An integer r is a rank iff we have1 ?
r ?
n.The starting point of this algorithm is set of n-best tables, built as explained in section 2.4, with-out explicitely unfolding the forest.computed as follows: while constructing the k?th-best treesfor each k?
between 1 and k?1, we have identified many pos-sible rewritings of the instantiated axiom, i.e., many (produc-tion, right-hand side local ranks) pairs; we know the proba-bility of all these rewritings, although only some of them con-situte a line of the instantiated axiom?s n-best table; we nowidentify new rewritings, starting from known rewritings andincrementing only one of their local ranks; we compute (re-cursively) the probability of these newly identified rewritings;the rewriting that has the best probability among all those thatare not yet a line of the n-best table is then added: it is its kthline.121A preliminary top-down step uses these n-besttables for building a parse forest whose non-terminal symbols (apart from the axiom) have theform A?i..j where ?
is a singleton {r}: the sub-forest rooted in A{r}i..j contains only one tree, thatof local rank r. Only the axiom is not decorated,and remains unique.
Terminal symbols are not af-fected either.At this point, the purpose of the algorithm is tomerge productions with identical right-hand sides,whenever possible.
This is achieved in a bottom-up fashion as follows.
Consider two symbols A?1i..jand A?2i..j , which differ only by their underlyingranksets.
These symbols correspond to two dif-ferent production sets, namely the set of all A?1i..j-productions (resp.
A?2i..j-productions).
Each ofthese production sets define a set of right-handsides.
If these two right-hand side sets are iden-tical we say that A?1i..j and A?2i..j are equivalent.
Inthat case introduce the rankset ?
= ?1 ?
?2 andcreate a new non-terminal symbol A?i..j .
We nowsimply replace all occurrences of A?1i..j and A?2i..jin left- and right-hand sides by A?i..j .
Of course(newly) identical productions are erased.
Aftersuch a transformation, the newly created symbolmay appear in the right-hand side of productionsthat now only differ by their left-hand sides; thefactorization spreads to this symbol in a bottom-up way.
Therefore, we perform this transforma-tion until no new pair of equivalent symbols isfound, starting from terminal leaves and percolat-ing bottom-up as far as possible.Example 4: Applying the ranksets method tothe second running example.Let us come back to the grammar of Example 3,and the same input text w = a b as before.
Asin Example 3, we consider the case when we areinterested in the n = 3 best trees.Starting from the instantiated grammar and then-best tables given in Example 3, the preliminarytop-down step builds the following forest (for clar-ity, ranksets have not been shown on symbols thatroot sub-forests containing only one tree):S1..3 ?
A{1}1..2 B{1}2..3S1..3 ?
A{1}1..2 B{2}2..3S1..3 ?
A{2}1..2 B{1}2..3A{1}1..2 ?
A11..2 A11..2 ?
a1..2A{2}1..2 ?
A21..2 A21..2 ?
a1..2B{1}2..3 ?
B12..3 B12..3 ?
b2..3B{2}2..3 ?
B22..3 B22..3 ?
b2..3In this example, the bottom-up step doesn?t fac-torize out any other symbols, and this is thereforethe final output of the ranksets method.
It con-tains 2 more productions and 3 more symbols thanthe pruned forest (which is the same as the origi-nal forest), but it contains exactly the 3 best trees,contrarily to the pruned forest.3.2 The rectangles methodIn this section only, we assume that the grammarG is binary (and therefore the forest, i.e., the gram-mar Gw, is binary).
Standard binarization algo-rithms can be found in the litterature (Aho and Ull-man, 1972).The algorithm described in this section per-forms, as the preceding one, a decoration of thesymbols of Gw.
The new (decorated) symbolshave the form Ax,yi..j , where x and y denote rankssuch that 1 ?
x ?
y ?
n. The semantics of thedecoration is closely related to the x, y extentionof Ai..j , introduced in 2.3:E(Ax,yi..j) = Ex,y(Ai..j)It corresponds to ranksets (in the sense of theprevious section) that are intervals: Ax,yi..j is equiv-alent to the previous section?s A{x,x+1,...,y?1,y}i..j .
Inother words, the sub-forest rooted with Ax,yi..j con-tains exactly the trees of the initial forest, rootedwith Ai..j , which rank range from x to y.The algorithm performs a top-down traversal ofthe initial instantiated grammar Gw.
This traver-sal also takes as input two parameters x and y. Itstarts with the symbol S0..|w| and parameters 1 andn.
At the end of the traversal, a new decorated for-est is built which contains exactly n most likelythe parses.
During the traversal, every instantiatedsymbol Ai..j will give birth to decorated instanti-ated symbols of the form Ax,yi..j where x and y aredetermined during the traversal.
Two different ac-tions are performed depending on whether we are122visiting an instantiated symbol or an instantiatedproduction.3.2.1 Visiting an instantiated symbolWhen visiting an instantiated symbol Ai..j withparameters x and y, a new decorated instan-tiated symbol Ax,yi,j is created and the traver-sal continues on the instantiated productions ofP (Ai..j) with parameters that have to be com-puted.
These parameters depend on how the el-ements of Ex,y(Ai..j) are ?distributed?
among thesets E(p) with p ?
P (Ai..j).
In other words, weneed to determine xk?s and yk?s such that:Ex,y(Ai..j) =?pk?P (Ai..j)Exk,yk(pk)The idea can be easily illustrated on an exam-ple.
Suppose we are visiting the instantiated sym-bol Ai..j with parameters 5 and 10.
Suppose alsothat Ai..j can be rewritten using the two instanti-ated productions p1 and p2.
Suppose finally thatthe 5 to 10 entries of T (Ai..j) are as follows6:5 p1 46 p2 27 p2 38 p1 59 p2 410 p1 6This table says that E5(Ai..j) = E4(p1) i.e.
the5th most likely analysis of E(Ai..j) is the 4th mostlikely analysis of E(p1) and E6(Ai..j) = E2(p2)and so on.
From this table we can deduce that:E5,10(Ai..j) = E4,6(p1) ?
E2,4(p2)The traversal therefore continues on p1 and p2with parameters 4, 6 and 2, 4.3.2.2 Visiting an instantiated productionWhen visiting an instantiated production p of theform Ai..j ?
Bi..l Cl..j with parameters x and y,a collection of q instantiated productions pr of theform Ax,yi..j ?
Bx1r,x2ri..l Cy1r ,y2rl..j , with 1 ?
r ?
q,are built, where the parameters x1r, x2r , y1r , y2r andq have to be computed.Once the parameters q and x1r, x2r , y1r , y2r with1 ?
r ?
q, have been computed, the traversalcontinues independently on Bi..l with parametersx1r and x2r and on Cl..j with parameters y1r and y2r .6Only the relevant part of the table have been kept in thefigure.The computation of the parameters x1r, x2r , y1rand y2r for 1 ?
r ?
q, is the most complex part ofthe algorithm, it relies on the three notions of rect-angles, q-partitions and n-best matrices, which aredefined below.Given a 4-tuple of parameters x1r , x2r, y1r , y2r ,a rectangle is simply a pairing of the form?
?x1r , x2r?, ?y1r , y2r ??.
A rectangle can be interpretedas a couple of rank ranges : ?x1r , y1r ?
and ?x2r , y2r?.It denotes the cartesian product[x1r, x2r]?
[y1r , y2r].Let ?
?x11, x21?, ?y11 , y21?
?, .
.
.
, ?
?x1q , x2q?, ?y1q , y2q ?
?be a collection of q rectangles.
It will be called aq-partition of the instantiated production p iff thefollowing is true:Ex,y(p) =?1?r?qE(Ax,yi..j ?
Bx1r,x2ri..l Cy1r ,y2rl..j )To put it differently, this definition means that?
?x11, x21?, ?y11 , y21?
?, .
.
.
, ?
?x1q , x2q?, ?y1q , y2q??
is a qpartition of p if any tree of E(Bx1r,x2ri..l ) combinedwith any tree of E(Cy1r ,y2rl..j ) is a tree of Ex,y(p) and,conversely, any tree of Ex,y(p) is the combinationof a tree of E(Bx1r,x2ri..l ) and a tree of E(Cy1r ,y2rl..j ).The n-best matrix associated with an instanti-ated production p, introduced in (Huang and Chi-ang, 2005), is merely a two dimensional represen-tation of the n-best table of p. Such a matrix, rep-resents how the n most likely trees of E(p) arebuilt.
An example of an n-best matrix is repre-sented in figure 1.
This matrix says that the firstmost likely tree of p is built by combining thetree E1(Bi..l) with the tree E1(Cl..j) (there is a 1in the cell of coordinate ?1, 1?).
The second mostlikely tree is built by combining the tree E1(Bi..l)and E2(Cl..j) (there is a 2 in the cell of coordinate?1, 2?)
and so on.1 23467891011121314 1516171820 2123524262 3 5 6234561941122 272528293031 32 34333536Cl..jBi..lFigure 1: n-best matrixAn n-best matrix M has, by construction, theremarkable following properties:123M(i, y) < M(x, y) ?i 1 ?
i < xM(x, j) < M(x, y) ?j 1 ?
j < yGiven an n-best matrix M of dimensions d =X ?
Y and two integers x and y such that 1 ?
x <y ?
d, M can be decomposed into three regions:?
the lower region, composed of the cellswhich contain ranks i with 1 ?
i < x?
the intermediate region, composed of thecells which contain ranks i with x ?
i ?
y?
the upper region, composed of the cellswhich contain ranks i such that y < i ?
d.The three regions of the matrix of figure 1, forx = 4 and y = 27 have been delimited with boldlines in figure 2.1 23467891011121314 1516171820 2123524262 3 5 6234561941122 272528293031 32 34333536Bi..lCl..jFigure 2: Decomposition of an n-best matrix intoa lower, an intermediate and an upper region withparameters 4 and 27.It can be seen that a rectangle, as introducedearlier, defines a sub-matrix of the n-best matrix.For example the rectangle ?
?2, 5?, ?2, 5??
definesthe sub-matrix which north west corner is M(2, 2)and south east corner is M(5, 5), as represented infigure 3.When visiting an instantiated production p, hav-ing M as an n-best matrix, with the two parame-ters x and y, the intermediate region of M , withrespect to x and y, contains, by definition, all theranks that we are interested in (the ranks rang-ing from x to y).
This region can be partitionedinto a collection of disjoint rectangular regions.Each such partition therefore defines a collectionof rectangles or a q-partition.The computation of the parameters x1r, y1r , x2rand y2r for an instantiated production p thereforeboils down to the computation of a partition of theintermediate region of the n-best matrix of p.910111213171820 21524262 525 19 22 2725Cl..jBi..lFigure 3: The sub-matrix corresponding to therectangle ?
?2, 5?, ?2, 5?
?We have represented schematically, in figure 4,two 4-partitions and a 3-partition of the interme-diate region of the matrix of figure 2.
The left-most (resp.
rightmost) partition will be called thevertical (resp.
horizontal) partition.
The middlepartition will be called an optimal partition, it de-composes the intermediate region into a minimalnumber of sub-matrices.         IIIIVIII         IIIIII         IIIIIIIVFigure 4: Three partitions of an n-best matrixThe three partitions of figure 4 will give birth tothe following instantiated productions:?
Vertical partitionA4,27i..j ?
B3,6i..l C1,1l..j A4,27i..j ?
B2,5i..l C2,2l..jA4,27i..j ?
B1,5i..l C3,5l..j A4,27i..j ?
B1,1i..l C6,6l..j?
Optimal partitionA4,27i..j ?
B1,1i..l C3,6l..j A4,27i..j ?
B2,5i..l C2,5l..jA4,27i..j ?
B3,6i..l C1,1l..j?
Horizontal partitionA4,27i..j ?
B1,1i..l C3,6l..j A4,27i..j ?
B2,2i..l C2,5l..jA4,27i..j ?
B3,5i..l C1,5l..j A4,27i..j ?
B6,6i..l C1,1l..jVertical and horizontal partition of the interme-diate region of a n-best matrix can easily be com-puted.
We are not aware of an efficient method thatcomputes an optimal partition.
In the implemen-tation used for experiments described in section 4,124a simple heuristic has been used which computeshorizontal and vertical partitions and keeps thepartition with the lower number of parts.The size of the new forest is clearly linked tothe partitions that are computed: a partition witha lower number of parts will give birth to a lowernumber of decorated instantiated productions andtherefore a smaller forest.
But this optimizationis local, it does not take into account the fact thatan instantiated symbol may be shared in the initialforest.
During the computation of the new forest,an instantiated production p can therefore be vis-ited several times, with different parameters.
Sev-eral partitions of p will therefore be computed.
Ifa rectangle is shared by several partitions, this willtend to decrease the size of the new forest.
Theglobal optimal must therefore take into account allthe partitions of an instantiated production that arecomputed during the construction of the new for-est.Example 5: Applying the rectangles method tothe second running example.We now illustrate more concretely the rectan-gles method on our second running example intro-duced in Example 3.
Let us recall that we are in-terested in the n = 3 best trees, the original forestcontaining 4 trees.As said above, this method starts on the instan-tiated axiom S1..3.
Since it is the left-hand sideof only one production, this production is visitedwith parameters 1, 3.
Moreover, its n-best table isthe same as that of S1..3, given in Example 3.
Weshow here the corresponding n-best matrix, withthe empty lower region, the intermediate region(cells corresponding to ranks 1 to 3) and the upperregion:41 232211A1..2B2..3As can be seen on that matrix, there are two op-timal 2-partitions, namely the horizontal and thevertical partitions, illustrated as follows:IIIII ILet us arbitrarily chose the vertical partition.
Itgives birth to two S 1..3-productions, namely:S 1,31..3 ?
A1,21..2 B1,12..3S 1,31..3 ?
A1,11..2 B2,22..3Since this is the only non-trivial step while apply-ing the rectangles algorithm to this example, wecan now give its final result, in which the axiom?s(unnecessary) decorations have been removed:S1..3 ?
A1,21..2 B{1,1}2..3S1..3 ?
A1,11..2 B{2,2}2..3A1,21..2 ?
A11..2 A11..2 ?
a1..2A1,21..2 ?
A21..2 A21..2 ?
a1..2B1,22..3 ?
B12..3 B12..3 ?
b2..3B2,22..3 ?
B22..3 B22..3 ?
b2..3Compared to the forest built by the ranksets algo-rithm, this forest has one less production and oneless non-terminal symbol.
It has only one moreproduction than the over-generating pruned for-est.4 Experiments on the Penn TreebankThe methods described in section 3 have beentested on a PCFG G extracted from the Penn Tree-bank (Marcus et al, 1993).
G has been extractednaively: the trees have been decomposed into bi-nary context free rules, and the probability of ev-ery rule has been estimated by its relative fre-quency (number of occurrences of the rule dividedby the number of occurrences of its left hand side).Rules occurring less than 3 times and rules withprobabilities lower than 3?
10?4 have been elim-inated.
The grammar produced contains 932 nonterminals and 3, 439 rules.7The parsing has been realized using the SYN-TAX system which implements, and optimizes, theEarley algorithm (Boullier, 2003).The evaluation has been conducted on the 1, 845sentences of section 1, which constitute our testset.
For every sentence and for increasing valuesof n, an n-best sub-forest has been built using therankset and the rectangles method.The performances of the algorithms have beenmeasured by the average compression rate they7We used this test set only to generate practical NLPforests, with a real NLP grammar, and evaluate the perfor-mances of our algorithms for constucting sub-forests thatcontain only the n-best trees, both in terms of compressionrate and execution time.
Therefore, the evaluation carried outhere has nothing to do with the usual evaluation of the pre-cision and recall of parsers based on the Penn Treebank.
Inparticular, we are not interested here in the accuracy of sucha grammar, its only purpose is to generate parse forests fromwhich n-best sub-forests will be built.1250e+001e+052e+053e+054e+055e+056e+057e+058e+059e+050  100  200  300  400  500  600  700  800  900 1000avg.nboftreesintheprunedforestnFigure 5: Overgeneration of the pruned n-best forest11010010001  10  100  1000compressionratenpruned forestrectanglesranksetsFigure 6: Average compression ratesachieve for different values of n. The compres-sion rate is obtained by dividing the size of then-best sub-forest of a sentence, as defined in sec-tion 2, by the size of the (unfolded) n-best forest.The latter is the sum of the sizes of all trees in theforest, where every tree is seen as an instantiatedgrammar, its size is therefore the size of the corre-sponding instantiated grammar.The size of the n-best forest constitutes a natu-ral upper bound for the representation of the n-besttrees.
Unfortunately, we have no natural lowerbound for the size of such an object.
Neverthe-less, we have computed the compression rates ofthe pruned n-best forest and used it as an imperfectlower bound.
As already mentioned, its imper-fection comes from the fact that a pruned n-bestforest contains more trees than the n best ones.This overgeneration appears clearly in Figure 5which shows, for increasing values of n, the av-erage number of trees in the n-best pruned forestfor all sentences in our test set.Figure 6 shows the average compression ratesachieved by the three methods (forest pruning,rectangles and ranksets) on the test set for increas-ing values of n. As predicted, the performances liebetween 1 (no compression) and the compressionof the n-best pruned forest.
The rectangle methodoutperforms the ranksets algorithm for every valueof n.The time needed to build an 100-best forest withthe rectangle and the ranksets algorithms is shownin Figure 7.
This figure shows the average parsing1260200400600800100012005  10  15  20  25  30  35  40  45timeinmillisecondssentence lengthparsingranksetsrectanglesFigure 7: Processing timetime for sentences of a given length, as well as theaverage time necessary for building the 100-bestforest using the two aforementioned algorithms.This time includes the parsing time i.e.
it is thetime necessary for parsing a sentence and build-ing the 100-best forest.
As shown by the figure,the time complexities of the two methods are veryclose.5 Conclusion and perspectivesThis work presented two methods to build n-best sub-forests.
The so called rectangle meth-ods showed to be the most promising, for it al-lows to build efficient sub-forests with little timeoverhead.
Future work will focus on computingoptimized partitions of the n-best matrices, a cru-cial part of the rectangle method, and adapting themethod to arbitrary (non binary) CFG.
Anotherline of research will concentrate on performingre-ranking of the n-best trees directly on the sub-forest.AcknowledgmentsThis research is supported by the French NationalResearch Agency (ANR) in the context of theSEQUOIA project (ANR-08-EMER-013).ReferencesAlfred V. Aho and Jeffrey D. Ullman.
1972.
TheTheory of Parsing, Translation, and Compiling, vol-ume 1.
Prentice-Hall, Englewood Cliffs, NJ.Taylor L. Booth.
1969.
Probabilistic representation offormal languages.
In Tenth Annual Symposium onSwitching and Automata Theory, pages 74?81.Pierre Boullier and Philippe Deschamp.
1988.Le syste`me SYNTAXTM - manuel d?utilisation.http://syntax.gforge.inria.fr/syntax3.8-manual.pdf.Pierre Boullier and Benot Sagot.
2005.
Efficient androbust LFG parsing: SXLFG.
In Proceedings ofIWPT?05, Vancouver, Canada.Pierre Boullier.
2003.
Guided Earley parsing.
In Pro-ceedings of IWPT?03, pages 43?54.Jay Earley.
1970.
An efficient context-free parsingalgorithm.
Communication of the ACM, 13(2):94?102.Liang Huang and David Chiang.
2005.
Better k-bestparsing.
In Proceedings of IWPT?05, pages 53?64.Liang Huang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings ofACL?08, pages 586?594.V?
?ctor M. Jime?nez and Andre?s Marzal.
2000.
Com-putation of the n best parse trees for weighted andstochastic context-free grammars.
In Proceedingsof the Joint IAPR International Workshops on Ad-vances in Pattern Recognition, pages 183?192, Lon-don, United Kingdom.
Springer-Verlag.Dan Klein and Christopher D. Manning.
2001.
Parsingand hypergraphs.
In Proceedings of IWPT?01.Bernard Lang.
1974.
Deterministic techniques for ef-ficient non-deterministic parsers.
In J. Loeckx, ed-itor, Proceedings of the Second Colloquium on Au-tomata, Languages and Programming, volume 14 ofLecture Notes in Computer Science, pages 255?269.Springer-Verlag.127Bernard Lang.
1994.
Recognition can be harder thenparsing.
Computational Intelligence, 10:486?494.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn treebank.
Computa-tional Linguistics, 19(2):313?330, June.Haitao Mi, Liang Huang, and Qun Liu.
2008.
Forest-based translation.
In Proceedings of ACL-08: HLT,pages 192?199.128
