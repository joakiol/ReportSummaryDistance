Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 301?310, Dublin, Ireland, August 23-29 2014.A Data Driven Approach for Person Name Disambiguation in Web SearchResultsAgust?
?n D. Delgado1, Raquel Mart?
?nez1, V?
?ctor Fresno1, Soto Montalvo21Universidad Nacional de Educaci?on a Distancia (UNED), Madrid, Spain2Universidad Rey Juan Carlos (URJC), M?ostoles, Spain1{agustin.delgado,raquel,vfresno}@lsi.uned.es,2soto.montalvo@urjc.esAbstractThis paper presents an unsupervised approach for the task of clustering the results of a searchengine when the query is a person name shared by different individuals.
We propose an algo-rithm that calculates the number of clusters and establishes the groups of web pages accordingto the different individuals without the need to any training data or predefined thresholds, asthe successful state of the art systems do.
In addition, most of those systems do not deal withsocial media web pages and their performance could fail in a real scenario.
In this paper wealso propose a heuristic method for the treatment of social networking profiles.
Our approach iscompared with four gold standard collections for this task obtaining really competitive results,comparable to those obtained by some approaches with supervision.1 IntroductionResolving the ambiguity of person names in web search results is a challenging problem becoming anarea of interest for Natural Language Processing (NLP) and Information Retrieval (IR) communities.This task can be defined informally as follows: given a query of a person name in addition to the resultsof a search engine for that query, the goal is to cluster the resultant web pages according to the differentindividuals they refer to.
Thus, the challenge of this task is estimating the number of different individualsand grouping the pages of the same individual in the same cluster.
The difficulty of this task resides inthe fact that a single person name can be shared by many people: according to the U.S. Census Bureau,90000 different names are shared by 100 million people (Artiles et al., 2007).
This problem has had animpact in the Internet and that is why several vertical search engines specialized in web people searchhave appeared in the last years, e.g.
spokeo.com or 123people.com.
This task should not be mixedup with entity linking (EL), which goal is to link name mentions of entities in a document collection toentities in a reference knowledge base (typically Wikipedia), or to detect new entities.The main difficulties of clustering web pages referring to the same individual come from their possibleheterogeneous nature.
For example, some pages may be professional sites, while others may be blogscontaining personal information.
In addition, the popularity of social networking services makes thesearch engine usually returns several social profiles belonging to different individuals sharing the samename, as much from the same social networking service as from different services.
These social pagesoften introduce noisy information and make the state of the art algorithms break down (Berendsen etal., 2012).
Due to these problems, the users have to refine the queries with additional terms.
This taskgets harder when the person name is shared by a celebrity or a historical figure, because the resultsof the search engines are dominated by that individual, making the search of information about otherindividuals more difficult.WePS1(Web People Search) evaluation campaigns proposed this task in a web searching scenarioproviding several corpora for evaluating the results of their participants, particularly WePS-1, WePS-2and WePS-3 campaigns.
This framework allows our approach to be compared with the state of the artThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1http://nlp.uned.es/weps/301systems.
We also evaluate our system with ECIR2012 corpus2, a data set that includes social networkingprofiles, providing a more real scenario for this task.The most successful state of the art systems have addressed this problem with some kind of supervi-sion.
This work proposes a data-driven method for this task with the aim of eliminating the elementsof human involvement in the process as much as possible.
The main contribution of this work is a newunsupervised approach for resolving person name ambiguity of web search results based on the use ofcapitalized n-grams.
In our approach the decision if two web pages have to be grouped only depends onthe information of both pages.
In addition, we also propose a heuristic method for the treatment of socialmedia profile web pages in this context.The paper is organized as follows: in Section 2 we discuss related work; Section 3 details the waywe represent the web pages, the algorithm and the heuristic for social pages; in Section 4 we describethe collections used for evaluating our method and we show our results making a comparison with othersystems; the paper ends with some conclusions and future work in Section 5.2 Related WorkSeveral approaches have been proposed for clustering search results for a person name query.
The maindifferences among all of them are the features they use to represent the web pages and the clusteringalgorithm.
However, the most successful of them have in common that they use some kind of supervision:learning thresholds and/or fixing manually the value of some parameters according to training data.Regarding the way of representing a web page, the most popular features used by the most success-ful state of the art approaches are Name Entities (NE) and Bag of Words (BoW) weighted by TF-IDFfunction.
In addition to such features, the systems usually use other kind of information.
Top systemsfrom WePS-1 and WePS-2 campaigns, CU COMSEM (Chen and Martin, 2007) and PolyUHK (Chen etal., 2009), distinguish several kind of tokens according to different schemes (URL tokens, title tokens,.
.
. )
and build a feature vector for each sort of tokens, using also information based on the noun phrasesappearing in the documents.
PolyUHK also adds pattern techniques, attribute extraction and detectionwhen a web page is written in a formal way.
A more recent system, HAC Topic (Liu et al., 2011), alsouses BoW of local and global terms weighted by TF-IDF.
It adds a topic capturing method to create a HitList of shared high weighted tokens for each cluster obtaining better results than WePS-1 participants.On the other hand, the WePS-3 best system, YHBJ (Chong and Shi, 2010), uses information extractedmanually from Wikipedia adding to BoW and NE weighted by TF-IDF.Regarding the clustering algorithms, looking at WePS campaigns results, the top ranked systems havein common the use of the Hierarchical Agglomerative Clustering algorithm (HAC) described in (Man-ning et al., 2008).
Different versions of this algorithm were used by (Chen and Martin, 2007; Chen etal., 2009; Elmacioglu et al., 2007; Liu et al., 2011; Balog et al., 2009; Chong and Shi, 2010).
(Berendsen et al., 2012) presented another gold standard for this task, ECIR2012, composed by Dutchperson names and social media profile web pages.
The system of the authors, UvA, distinguishes the webpages between social ones and non social ones, clusters each group separately and then combines bothclustering solutions.
They represent each web page as a BoW vector weighted by TF-IDF, and use cosinesimilarity for comparing web pages.
They use HAC algorithm for clustering non social web pages, whileuse a ?one in one?
policy for the social ones.
Finally, they mix both groups by means of an algorithmwhich penalizes clusters with social webs or simply taking the union of both clustering solutions.
Theyperform a partial parameter sweep on the WePS-2 data set to fix the clustering thresholds, while explorecombinations of other system parameters.The only system that does not use training data, DAEDALUS (Lana-Serrano et al., 2010), which usesk-Medoids, got poor results in WePS-3 campaign.
In short, the successful state of the art systems needsome kind of supervised learning using training data or fixing parameters manually.
In this paper weexplore and propose an approach to address this problem by means of data-driven techniques without theuse of any kind of supervision.2http://ilps.science.uva.nl/resources/ecir2012rdwps3023 Proposed ApproachWe distinguish two main phases in this clustering task: web page representation (Sections 3.1 and 3.2)and web page grouping (Sections 3.3 and 3.4).
In addition, we propose an heuristic to deal with socialprofiles web pages (Section 3.5).3.1 Feature SelectionThe aim of this phase is to extract relevant information that could identify an individual.
We assume themain following hypotheses:(i) Capitalized n-grams co-occurrence could be a reliable way for deciding when two web pagesrefer the same individual.
Capitalized n-grams usually are Named Entities (organizations and companynames, locations or other person names related with the individual) or information not detected by someNE recognizers as for example, the title of books, films, TV shows, and so on.
In a previous studywith WePS-1 training corpus using the Stanford NER3to annotate NE, we detected that only 55.78%of the capitalized tokens were annotated as NE or components of a NE by the NER tool.
So the useof capitalized tokens allows increase the number of features compared to the use of only NE.
We alsocompared the n-gram representation with capitalized tokens and with NE.
We found that 30.97% of the3-grams of capitalized tokens were also NE 3-grams, and 25.64% of the 4-grams of capitalized tokenswere also NE 4-grams.
So even in the case of n-grams the use of capitalized tokens increases the numberof features compared to the use of only NE.
Table 1 shows the differences in performance when usingn-grams representation with NE or with capitalized tokens.
(ii) If two web pages share capitalized n-grams, the higher is the value of n, the more probable the twoweb pages refer to the same individual.
In this case we define ?long enough n-grams?
as those composeby at least 3 capitalized tokens.Thus, a web page W is initially represented as the sequence of tokens starting in uppercase, in theorder as they appear in the web page.
In each step of the algorithm, a web pageW will be represented byits long enough n-grams, taking different values for n, as we describe in Section 3.4.
Notice that someweb pages could not be represented with this proposal because all their content was written in lowercase.In the case of the collections that we describe in Section 4.1, 0.63% of the web pages are not representedfor this reason.3.2 Weighting FunctionsWe test the well known TF and TF-IDF functions, and z-score (Andrade and Medina, 1998).
The z-scoreof a n-gram a in a web page Wiis defined as follows: z-score(a,Wi) =TF (a,Wi)??
?, where TF (a,Wi)is the frequency of the n-gram a in Wi; ?
is the mean frequency of the background set; and ?
is thestandard deviation of the background set.
In this context the background set is the set of web pages thatshare the person name.
This score gives an idea of the distance of the frequency of an n-gram in a webpage from the general distribution of this n-gram in the background set.3.3 Similarity FunctionsTo determine the similarity between two web pages we try the cosine distance, a widely measureused in clustering, and the weighted Jaccard coefficient between two bags of n-grams defined asW.Jaccard(Wni,Wnj) =?kmin(m(tnki,i),m(tnkj,j))?kmax(m(tnki,i),m(tnkj,j)), where the meaning of m(tnki, i) is explained in Sec-tion 3.4.
Since weighted Jaccard coefficient needs non-negative entries and we want the cosine similarityof two documents to range from 0 to 1, we translate the values of the z-score so that they are alwaysnon-negative.3.4 AlgorithmThe algorithm UPND (Unsupervised Person Name Disambiguator) can be seen in Algorithm 1.
Thedescription of this first algorithm does not take into account social profile web pages.3http://nlp.stanford.edu/software/CRF-NER.shtml303UPND algorithm receives as input a set of web documents with a mention to the same person name,let beW = {W1,W2, .
.
.
,WN}, and starts assigning a cluster Cifor each document Wi.
UPND alsoreceives as input a pair of positive integer values r1and r2, such that r2?
r1, specifying the range ofvalues of n in the n-grams extracted from each web document.
In each step of the algorithm we assign toeach web page Wia bag of n-grams Wni= {(tn1,m(tn1, i)), (tn2,m(tn2, i)), .
.
.
, (tnki,m(tnki, i))}, whereeach tnris a n-gram extracted from Wiand m(tnr, i) is the corresponding weight of the n-gram tnrinthe web page Wi, being r ?
{1, 2, .
.
.
, ki}.
In Algorithm 1 the function setNGrams(n,W) in line 6calculates for each web page in the set W its bag of n-grams representation.
Sim(Wni,Wnj) in line 9refers to the similarity between web pages Wiand Wj.To decide when two web pages refer the same individual we propose a threshold ?.
For each pairof web pages represented as bag of n-grams, let be Wniand Wnj, we compute the threshold as fol-lows: ?
(Wni,Wnj) =min(m,k)?shared(Wni,Wnj)max(m,k), where m and k are the number of n-grams of Wiand Wjrespectively, and shared(Wni,Wnj) is the number of n-grams shared by those web pages i.e.shared(Wni,Wnj) = |Wni?Wnj|.
Notice that shared(Wni,Wnj) is superiorly limited by min(m, k).This threshold holds two desirable properties: (i) The more n-grams are shared by Wiand Wj, thelower ?
(Wni,Wnj) is, so the clustering condition of the algorithm is less strict.
(ii) It avoids the penal-ization due to big differences between the size of the web pages.Thus, we decide that two web pages Wiand Wjrefer to the same person if Sim(Wni,Wnj) ??
(Wni,Wnj), so Ci= Ci?
Cj(lines 9, 10 and 11).We assume that we can get accurate and reliable information for disambiguating with n-grams of atleast size 3.
Thus, we propose to iterate this process for 3-grams and 4-grams, i.e.
UPND( W, 3, 4).We consider that selecting a value of n grater than 4 could lead to find few n-grams, so that many webpages could be under-represented.
On the other hand, previous experiments using also bigrams showedthat they are not suitable for this approach.
This algorithm is polynomial and has a computational costin O(N2), where N is the number of web pages.Algorithm 1 UPND(W, r1, r2)Require: Set of web pages that shared a person name W= {W1,W2, ...,WN}, r1, r2?
1 such thatr2?
r1Ensure: Set of clusters C = {C1, C2, ..., Cl}1: for n = 1 to N do2: Ci= {Wi}3: end for4: C = {C1, C2, ..., CN}.5: for n = r1to r2do6: setNGrams(n,W).7: for i = 1 to N do8: for j = i+ 1 to N do9: if Sim(Wni,Wnj) ?
?
(Wni,Wnj) then10: Ci= Ci?
Cj11: C = C \{Cj}12: end if13: end for14: end for15: end for16: return C3.5 Social Media TreatmentSocial networking services have increased their popularity and number of users in the last years.
Thisfact affects this task mainly in two ways.
On one hand, as a result of the success of this kind of platforms,304a lot of web pages contain terms related to them (e.g.
the name of these platforms: Twitter, Facebook,LinkedIn, etc.).
On the other hand, for a person name query in a search engine, it usually returns severalprofiles of such person name that are as much in the same as in different social networking services.These profiles usually are from different people sharing the same name, so they should be in differentclusters.
Most of the methods of the state of the art do not take into account this fact, usually taking asfeatures tokens from the URL or the title of each web page, which includes the name of these platforms.This practice could lead to add noise to the representation of the web pages.
(Berendsen et al., 2012) proposed the ?one in one?
baseline to deal with social platform web pages,which creates a singleton cluster for each social web page.
However, its main disadvantage is that it doesnot consider that a same individual could have accounts in several social platforms.
A search enginecould also return web pages from a social platform which are not profiles, as for example, a group pageof Facebook where a person expounds an opinion, in addition to the profile of the same individual in thatsocial platform.
In these cases the ?one in one?
baseline also fails.We propose a heuristic method that takes into account the limitations of the ?one in one?
heuristic,letting group social web pages from different platforms and also cluster social web pages from the samesocial platform.
The algorithm that implements our heuristic is SUPND (Social UPND).
This algorithmapplies UPND with the following restriction: two web pages assigned to the same social networkingservice cannot be compared.
This policy is taken because when a search engine returns several links fromthe same social platform, they usually refer to different individuals.
However, this does not necessarilyimply that two web pages belonging to the same social site cannot belong to the same cluster, becausethey would be compared to other webs pages separately, possibly ending up in the same cluster in atransitive way.
For example, giving two web pages from Facebook, let be FB1and FB2, and a non-social web page W , then FB1and FB2would not be compared, however each FBiwould be comparedwith W .
If SUPND decides to cluster each FBiwith W , then finally both web pages, from the sameplatform, would be in the same cluster.
To identify the social web pages we obtain a list of social mediaplatforms from Wikipedia4, so when looking at the URL of a web page, we can detect if it correspondsto any of those social media platforms.
If it is the case, we assign to that web page its social media site.The computational cost of SUPND is the same of UPND.4 ExperimentsIn this section we present the corpora of web pages used, the preprocessing of each web page, theexperiments carried out and the obtained results.4.1 Web People Search CollectionsWePS is a competitive evaluation campaign that proposes several tasks including resolution of disam-biguation on the Web data.
In particular, WePS-1, WePS-2 and WePS-3 campaigns provide an evaluationframework consisting in several annotated data sets composed of English person names.In these experiments we use WePS-1 (Artiles et al., 2007) test corpus composed by 30 English personnames and the top 100 search results from Yahoo!
search engine; WePS-2 (Artiles et al., 2009a) contain-ing 30 person names and the top 150 search results from Yahoo!
search engine; and WePS-3 (Artiles etal., 2010) containing 300 person names and the top 200 search results from Yahoo!
All WePS corporahave few social profile web pages, so the impact of this kind of pages in the results of the algorithms isinsignificant.
We also use the ECIR2012 corpus, which is composed by 33 Dutch person names selectedfrom query logs of a people search engine.
For each person name the web pages set is built retrievingseveral profiles from social media platforms as Facebook, Twitter or LinkedIn, and results returned byGoogle, Bing and Yahoo!
search engines.
This data set gives a more real scenario for this task than theWePS ones, because it includes social network profiles of several person sharing the same name.4en.wikipedia.org/wiki/Category:Social networking services3054.2 Corpus PreprocessingGiven a person name and a set of web pages, we first discard web pages that do not mention such nameusing several patterns that take into account the usual structure of person names.For each not discarded web page, we delete the name and the surname because they appear in all theremaining documents and are the object of the ambiguity.
We also delete stop words.4.3 Results and DiscussionWe present our results for all the corpora comparing them with the state of the art systems.
The figuresin the tables are macro-averaged, i.e., they are calculated for each person name and then averaged overall test cases.
For WePS data sets we get the same results for UPND and SUPND algorithms, becausethese collections include few social networking profiles.
The metrics used in this section are the BCubedmetrics defined in (Bagga and Baldwin, 1998): BCubed precision (BP ), BCubed recall (BR) and theirharmonic mean F0.5(BP/BR).
(Artiles, 2009) showed that these metrics are accurate for clusteringtasks, particularly for person name disambiguation in the Web.
We use the Wilcoxon test (Wilcoxon,1945) to detect statistical significance in the differences of the results considering a confidence levelof 95%.
In order to compare our algorithm with the WePS better results using the Wilcoxon test, thesamples consist in the pairs of values F?=0.5(BP/BR) of each system for each person name.First, Table 1 shows the results of UPND using n-grams of capitalized tokens and n-grams of NEwith WePS-1 training corpus.
Experiments include the three weighting functions and the two similarityfunctions.
The results of using n-grams of NE rank below those obtained with n-grams of capitalizedtokens in all cases.
The Wilcoxon test comparing the results of both representations shows that there aresignificant differences between them, except TF and TF-IDF with cosine.
So we can conclude that in ourapproach using n-grams of capitalized tokens outperforms the use of n-grams of NE, what confirms ourhypothesis.TF z-score TF-IDFRepresentation W. Jaccard Cosine W. Jaccard Cosine W. Jaccard CosineCapitalized n-gram 0.82 0.69 0.83 0.78 0.81 0.63NE (Stanford NER) 0.77 0.6 0.77 0.72 0.76 0.6Table 1: F0.5(BP/BR) results of UPND algorithm comparing capitalized n-gram and NE n-gramrepresentations with WePS-1 training corpus.In Table 2 we show the results of UPND for all WePS test data sets with the three weighting functionsand the two similarity measures.WePS-1 WePS-2 WePS-3BP BR F0.5(BP/BR) BP BR F0.5(BP/BR) BP BR F0.5(BP/BR)W. JaccardTF 0.73 0.77 0.74 0.82 0.82 0.81 0.46 0.70 0.50z-score 0.70 0.78 0.72 0.80 0.84 0.81 0.44 0.72 0.50TF-IDF 0.73 0.77 0.73 0.82 0.82 0.81 0.46 0.70 0.50CosineTF 0.92 0.61 0.72 0.95 0.61 0.73 0.75 0.45 0.51z-score 0.85 0.69 0.76 0.91 0.73 0.81 0.62 0.56 0.53TF-IDF 0.94 0.57 0.7 0.96 0.52 0.65 0.79 0.40 0.49Table 2: Results of UPND algorithm for WePS test data sets.The combination of z-score with cosine gets the best balance between the values of BP and BR,reaching the highest results of F?=0.5for the three WePS corpora.
The combination of TF-IDF withcosine gets the best BP results, but BR results are the lowest.
On the other hand, the combination ofz-score and Jaccard gets the best BR results, but the BP results are the lowest.Regarding the significance of the differences between the best results, the improvement between z-score with cosine and z-score with Jaccard is significant in WePS-1 and WePS-3, but not in WePS-2.The improvement between z-score with cosine and Jaccard with TF is significant only in WePS-3.306Thus, we select the combination of z-score as weight function and cosine as similarity function as themost suitable combination for our algorithm.
Therefore we use it in the following experiments.Table 3 shows the results of UPND with WePS-1 test, WePS-2 and WePS-3 corpora in addition tothe top ranking systems of the campaigns, and also the results obtained by HAC Topic system in thecase of WePS-1.
We include the results obtained by three unsupervised baselines called ALL IN ONE,ONE IN ONE and Fast AP.
ALL IN ONE provides a clustering solution where all the documents areassigned to a single cluster, ONE IN ONE returns a clustering solution where every document is assignedto a different cluster, and Fast AP applies a fast version of Affinity Propagation described in (Fujiwara etal., 2011) using the function TF-IDF to weight the tokens of each web page, and the cosine distance tocompute the similarity.System BP BR F0.5(BP/BR)WePS-1(+) HAC Topic 0.79 0.85 0.81 ?
(-) UPND 0.85 0.69 0.76 ?
(+)(*) CU COMSEM 0.61 0.83 0.70 ?
(+)(*) PSNUS 0.68 0.73 0.70 ?
(+)(*) IRST-BP 0.68 0.71 0.69 ?
(+)(*) UVA 0.79 0.50 0.61 ?
(+)(*) SHEF 0.54 0.74 0.62 ?
(-) ONE IN ONE 1.00 0.43 0.57 ?
(-) Fast AP 0.69 0.55 0.56 ?
(-) ALL IN ONE 0.18 0.98 0.25 ?WePS-2(+) ORACLE 1 0.89 0.83 0.85 ?
(+) ORACLE 2 0.91 0.81 0.85 ?
(+)(*) PolyUHK 0.87 0.79 0.82(+)(*) ITC-UT 1 0.93 0.73 0.81(-) UPND 0.91 0.73 0.81 ?
(+)(*) UVA 1 0.85 0.80 0.81(+)(*) XMEDIA 3 0.82 0.66 0.72 ?
(+)(*) UCI 2 0.66 0.84 0.71 ?
(-) ALL IN ONE 0.43 1.00 0.53 ?
(-) Fast AP 0.80 0.33 0.41 ?
(-) ONE IN ONE 1.00 0.24 0.34 ?WePS-3(+)(*) YHBJ 2 0.61 0.60 0.55(-) UPND 0.62 0.56 0.53 ?
(+)(*) AXIS 2 0.69 0.46 0.50 ?
(+)(*) TALP 5 0.40 0.66 0.44 ?
(+)(*) RGAI AE 1 0.38 0.61 0.40 ?
(+)(*) WOLVES 1 0.31 0.80 0.40 ?
(-)(*) DAEDALUS 3 0.29 0.84 0.39 ?
(-) Fast AP 0.73 0.30 0.38 ?
(-) ONE IN ONE 1.00 0.23 0.35 ?
(-) ALL IN ONE 0.22 1.00 0.32 ?Table 3: Results of UPND and the top state of the art systems with WePS corpora: (+) means systemwith supervision; (-) without supervision and (*) campaign participant.
Significant differences betweenUPND and other systems are denoted by (?
); (?)
means that in this case the statistical significance isnot evaluated.Our method UPND outperforms WePS-1 participants and all the unsupervised baselines describedbefore.
HAC Topic also outperforms the WePS-1 top participant systems and our algorithm.
This systemuses several parameters obtained by training with the WePS-2 data set: token weight according to thekind of token (terms from URL, title, snippets, .
.
. )
and thresholds used in the clustering process.
Notethat WePS-1 participants used the training corpus provided to the campaign, the WePS-1 training data,so in this case the best performance of HAC Topic could be not only because of the different approach,but also because of the different training data set.Our algorithm obtains significative better results than the WePS-1 top participant results, andHAC Topic obtains significative better results than it according to the Wilcoxon test.
UPND obtainssignificative better results than IRST-BP system (the third in the WePS-1 ranking), also based on theco-ocurrence of n-grams.Regarding WePS-2 we add in Table 3 two oracle systems provided by the organizers.
These systemsuse BoW of tokens (ORACLE 1) or bigrams (ORACLE 2) weighted by TF-IDF, deleting previouslystop words, and later apply HAC with single linkage with the best thresholds for each person name.
Wedo not include the results of the HAC Topic system since it uses this data set for training their algorithm.The significance test shows that the top WePS-2 systems PolyUHK, UVA 1 and ITC-UT 1 obtain307similar results than UPND, however they use some kind of supervision.
The results of all these systemsare the closest to the oracle systems provided by the organizers, which know the best thresholds for eachperson name.In the case of WePS-3, the organizers did not take into account the whole clustering solution providedby the systems like in previous editions, but only checks the accuracy of the clusters correspondingto two selected individuals per person name.
In this case, the first two systems YHBJ 2 and UPNDdo not have significant difference in their results.
Notice that YHBJ 2 system makes use of conceptsextracted manually from Wikipedia.
Note that UPND also obtains significative better results thanDAEDALUS 3, the only one participant that does not use training data.Regarding the experiments with the ECIR2012 corpus, which contains social profiles, Table 4 showsthe results of the two versions of our algorithm and the results of the system of the University of Ams-terdam (UvA).
As far as we know, no other systems have been tested with this gold standard.
SUPNDobtains significative better results than UPND due to its special treatment for social web pages.
TheUvA system outperforms our algorithm SUPND and this improvement is significative.
Note that theheuristic for social pages in SUPND outperforms UPND using the ?one in one?
heuristic.System BP BR F0.5(BP/BR)(+) UvA (best perf.)
0.90 0.80 0.83 ?
(-) SUPND 0.95 0.68 0.78 ?
(-) UPND (one in one) 0.98 0.62 0.74 ?
(-) UPND 0.74 0.74 0.72 ?Table 4: Results of SUPND and UPND algorithms for ECIR2012 corpus: (+) means system withsupervision and (-) without supervision.
Significant differences between SUPND and other systemsare denoted by (?
); (?)
means that in this case the statistical significance is not evaluated.After all these experiments, we can conclude that our approach gets the best results of all the com-pletely unsupervised approaches.
Moreover, the precision scores for all collections are very high andconfirm that our approach is accurate to get relevant information for characterizing an individual.
Wealso obtain competitive recall results, what lead to a competitive system that carries out person namedisambiguation in web search results with minimum human supervision.5 Conclusions and Future WorkWe present a new approach for person name disambiguation of web search results.
Our method doesnot need training data to calculate thresholds to determine the number of different individuals sharingthe same name, or whether two web pages refer to the same individual or not.
Although supervisedapproaches have been successful in many NLP and IR tasks, they require enough and representativetraining data to guaranty the results will be consistent for different data collections, which requires ahuge human effort.The two algorithms proposed provide a clustering solution for this task by means of data-driven meth-ods that do not need learning from data.
Our approach is not very expensive in computational cost,obtaining very competitive results in several data sets compared with the best state of the art systems.Our proposal is based on getting reliable information for disambiguating, particularly long n-gramscomposed by uppercase tokens.
According to our results, this hypothesis has shown successful, gettinghigh precision values and acceptable recall scores.
Anyway, we would like to improve recall resultswithout losing of precision, filter out noisy capitalized n-grams, and build an alternative representationfor web pages containing all their tokens in lowercase.We have observed that this task gets harder when we have to deal with social media profiles.
A systemthought for being used in a real scenario has to take into account this kind of web pages, since they areusually returned by search engines when a user introduces a person name as a query.
Most state of theart systems do not deal with this problem.
We have proposed in this paper a new heuristic method forprocessing social platforms profiles for this clustering task.308Person name disambiguation has been mainly addressed in a monolingual scenario, e.g.
WePS cor-pora are English data sets and Dutch the ECIR2012 collection.
We would like to address this task ina multilingual scenario.
Although search engines return their results taking into account the country ofthe user, with some queries we can get results written in several languages.
This scenario has not beenconsidered by the state of the art systems so far.AcknowledgementsThis work has been part-funded by the Spanish Ministry of Science and Innovation (MED-RECORDProject, TIN2013-46616-C2-2-R) and by UNED Project (2012V/PUNED/0004).ReferencesMiguel A. Andrade, and Alfonso Valencia.
1998.
Automatic extraction of keywords from scientific text: applica-tion to the knowledge domain of protein families.
Bioinformatics, 14:600-607, 1998.Javier Artiles, Julio Gonzalo and Satoshi Sekine.
2007.
The SemEval-2007 WePS Evaluation: Establishing aBenchmark for the Web People Search Task.
In Proceedings of the Fourth International Workshop on SemanticEvaluations (SemEval-2007), pages 64?69, Prague, Czech Republic, June 2007.
Association for ComputationalLinguistics.Javier Artiles.
2009.
Web People Search.
PhD Thesis, UNED University.Javier Artiles, Julio Gonzalo and Satoshi Sekine.
2009b.
Weps 2 Evaluation Campaign: Overview of the WebPeople Search Clustering Task.
In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWWConference, 2009.Javier Artiles, Andrew Borthwick, Julio Gonzalo, Satoshi Sekine and Enrique Amig?o .
2010.
WePS-3 EvaluationCampaign: Overview of the Web People Search Clustering and Attribute Extraction Tasks.
In Third Web PeopleSearch Evaluation Forum (WePS-3), CLEF 2010.Amit Bagga and Breck Baldwin.
1998.
Entity-Based Cross-Document Coreferencing Using the Vector SpaceModel.
In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17thInternational Conference on Computational Linguistics - Volume 1, ACL ?98, pages 79?85, Stroudsburg, PA,USA, 1998.
Association for Computational Linguistics.Krisztian Balog, Jiyin He, Katja Hofmann, Valentin Jijkoun, Christof Monz, Manos Tsagkias, Wouter Weerkamp,and Maarten de Rijke.
2009.
The University of Amsterdam at WePS-2.
In 2nd Web People Search EvaluationWorkshop (WePS 2009), 18th WWW Conference, 2009.Richard Berendsen, Bogomil Kovachev, Evangelia-Paraskevi Nastou, Maarten de Rijke, and Wouter Weerkamp.2012.
Result Disambiguation in Web People Search.
In Proceedings of the 34th European conference onAdvances in Information Retrieval, ECIR?12, pages 146?157, Berlin, Heidelberg, 2012.
Springer-Verlag.Ying Chen and James Martin.
2007.
CU-COMSEM: Exploring Rich Features for Unsupervised Web PersonalNamed Disambiguation.
In Proceedings of SemEval 2007, Assocciation for Computational Linguistics, pages125?128, 2007.Ying Chen, Sophia Yat Mei Lee and Chu-Ren Huang.
2009.
PolyUHK: A Robust Information Extraction Systemfor Web Personal Names.
In 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Confer-ence, 2009.Ergin Elmacioglu, Yee Fan Tan, Su Yan, Min-Yen Kan, and Dongwon Lee.
2007.
PSNUS: Web People NameDisambiguation by Simple Clustering with Rich Features.
In Proceedings of the 4th International Workshop onSemantic Evaluations, SemEval ?07, pages 268?271, Stroudsburg, PA, USA, 2007.
Association for Computa-tional Linguistics.Yasuhiro Fujiwara, Go Irie and Tomoe Kitahara.
2011.
Fast Algorithm for Affinity Propagation.
In Proceedings ofthe Twenty-Second International Joint Conference on Artificial Intelligence(IJCAI)- Volume Three, 2238?2243,Barcelona, Catalonia, Spain.Sara Lana-Serrano , Julio Villena-Rom?an , Jos?e Carlos Gonz?alez-Crist?obal.
2010.
Daedalus at WebPS-3 2010:k-Medoids Clustering using a Cost Function Minimization.
In Third Web People Search Evaluation Forum(WePS-3), CLEF 2010.309Zhengzhong Liu, Qin Lu, and Jian Xu.
2011.
High Performance Clustering for Web Person Name Disambiguationusing Topic Capturing.
In International Workshop on Entity-Oriented Search (EOS), 2011.Chong Long and Lei Shi.
2010.
Web Person Name Disambiguation by Relevance Weighting of Extended FeatureSets.
In Third Web People Search Evaluation Forum (WePS-3), CLEF 2010.Gideon S. Mann.
2006.
Multi-Document Statistical Fact Extraction and Fusion.
PhD thesis, Johns HopkinsUniversity, Baltimore, MD, USA, 2006.
AAI3213760.Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch?utze.
2008.
Introduction to Information Retrieval.Cambridge University Press, New York, NY, USA, 2008.Octavian Popescu and Bernardo Magnini.
2007.
IRST-BP: Web People Search Using Name Entities In InProceedings of SemEval 2007, Assocciation for Computational Linguistics, pages 195?198, 2007.Frank Wilcoxon.
1945.
Individual Comparisons by Ranking Methods, volume 1 (6).
Biometrics Bulletin, Decem-ber 1945.310
