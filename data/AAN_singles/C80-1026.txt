A PRODUCTION SYSTEM MODEL OF FIRST LANGUAGE ACQUISITIONPat LangleyDepartment of PsychologyCarnegie-Mellon UniversityPittsburgh, Pennsylvania USA 15213AbstractAMBER is a model of first languageacquisit ion that improves itsperformance through a process of errorrecovery.
The model is implemented inACTG, an adaptive production systemlanguage.
AMBER starts with the abil ityto say only one word at a time, but addsrules for inserting additional words inthe correct order, based on comparisonsbetween predicted and observedsentences.
These insertion rules may beoverly general and lead to errors ofcommission; in turn, these lead to moreconservative rules with additionalconditions.
AMBER's learning mechanismsaccount for many of the developmentsobserved in children's speech.IntroductionThe acquisit ion of language has beena popular topic among researchers inArtif icial Intelligence.
Impressivelanguage learning programs have beendeveloped by Siklossy \[i\], Hedrick \[2\],Anderson \[3\], Selfridge \[4\], and Berwick\[5\].
The general ity and power of thesesystems vary greatly, but they share onecharacteristic: none of the programsprovide a psychological ly plausiblemodel of children's language learning.In this paper I describe thebeginnings of a more realistic model offirst language acquisition.
This modelis called AMBER, an acronym forAcquisit ion Model Based on ErrorRecovery.
As its name implies, themodel simulates the incremental natureof the child's language learningprocess.
AMBER is concerned with theproduction component of children'sspeech, since most of the reliable datarelate to production rather than theunderstanding process.Below I summarize the majordevelopments found during this period.After this, I present an overview ofACTG, the production system language inwhich the model is stated.
Next Iconsider some assumptions about thechild's l inguistic knowledge at variousstages during the learning process.After considering the initial and finalstages of AMBER, I discuss the learningmechanisms leading to the transitionprocess.
Finally, I consider thel imitations of the model and proposedirections for future research.The Mayor PhenomenaChildren do not learn language in anall-or-none fashion.
They begin theirl inguistic careers uttering one word ata time, and slowly evolve through anumber of stages, each co~taining speechmore like that of the adult than the onebefore.
In this section I discuss thefeatures of the three stages which AMBERattempts to explain.
I discuss thesestages in their order of occurrence,dealing only with the major phenomena ineach case.The One-Word StageAround the age of one year, mostchildren begin to produce words inisolation, and continue this strategyfor some months.
Presumably tile childspends much of this period connectingparticular words to particular concepts;once this has been done, he can producethese words under the appropriatecircumstances.
AMBER does not attemptto explain the word-learning process.Like Anderson's LAS \[3\], it assumes thatlinks between words and concepts havealready been established.Bloom \[6\] has examined this period indetail, with an eye to understanding therelation between the one-word stage andthose which follow it.
Early in thisstage, successive one-word utterancesseem entirely disconnected; the childrandomly comments on anything thathappens to be in the environment.Later, he begins to name in successiondifferent aspects of the same event orobject; words are still separated bynoticeable pauses and no regular ordercan be detected, but conceptualcontinuity seems present.
Moreover,this development occurs only a fewmonths before the child begins tocombine words into very simplesentences.
AMBER's starting point liessomewhere within this later part of theone-word stage.-183Teleg \[.#phi c SpeechAround the age of 18 months, thechi ld begins to combine words intomeaningfu l  sequences.
In order -basedlanguages such as Engl ish, the chi ldusual ly  fo l lows the adult  order.In i t ia l ly  only pairs of words areproduced, but these are fol lowed bythree-word and later by four-wordutterances.
The simple sentencesoccurr ing in this stage consist  almostent i re ly  of content words.
Brown \[7\]has descr ibed speech during this periodas te legraphic,  s ince g rammaticalmorphemes such as tense endings andprepos i t ions  are absent, as they wouldbe in a telegram.Brown has also noted that themajor i ty  of two-word utterances expressa rather small set of pairwise semanticrelat ions.
AMBER assumes a small numberof case re lat ions such as agent,  action,and possess ion from which Brown'spairwise re lat ions can be derived.
Inaddit ion,  tile chi ld uses a few funct ionwords l ike "there", "more", and"al l -gone" to express s imple forms ofnominat ion,  recurrence,  and negation.AMBER attempts to learn the relat iveword orders for express ing theserecurr ing relat ions.The Acqu is i t ion  of Grammat ica l  MorphemesBrown \[7\] has also studied the periodfrom about 24 to 40 months, during whichthe chi ld masters  the grammat ica lmorphemes which were absent during theprevious stage.
Brown pointed out thatthese morphemes modulate  the majormeanings of sentences which areexpressed through content words.
AMBERref lects this d is t inct ion  byrepresent ing the informat ion expressedby contents  words and grammat ica lmorphemes in d i f ferent  ways.
Thesemorphemes are learned gradual ly;  thetime between the init ial  product ion of amorpheme and its mastery  (i.e., when itis correct ly  used in all requiredcontexts) may be as long as 16 months.In addit ion, Brown has examined theorder in which 14 Engl ish morphemes areacquired,  and has found this order to beremarkably  cons istent  across chi ldren.For example, present  progress ive(eating) and plural (dogs) were alwayslearned quite early, whi le third persons ingular (eats) and copulas (is, are)took longer.
He found that thesyntact ic  and semantic complex i t ies  ofthe morphemes were h ighly  corre latedwith their order of mastery.
Since thecurrent  vers ion of AMBER cannot dealwith except ions,  I wil l  consider onlyregular const ruct ions  in this paper.The ACTG Formal ismAMBER is implemented in ACTG, anadapt ive product ion system language.Below I present  an overv iew of AC%G,beginning with a d iscuss ion of itspropos i t ional  network.
After this Iconsider the representat ion  ofprocedures as product ions.
Final ly,  Iexamine ACTG's fac i l i t ies for changingits own behavior  through the creat ion ofnew product ions.The Propos i t ional  NetworkACTG stores its factual,  dec larat iveknowledge in a long-term propos i t ionalnetwork.
Individual  facts are stored aspropos i t ions ,  which may be arb i t raryl ist structures.
As we wil l  see in moredetai l  below, AMBER incorporates  twomain types of propos i t ions.
One sortexpresses a goal to say a part icularword in a certa in posit ion.
The secondtype of propos i t ion  expresses  var iouskinds of relat ions,  including facts l ikex possesses y, y is a *ball, and "ball"is the word for *ball (where conceptsare preceded by "*" to d is t ingu ish  themfrom their assoc iated words).At any given time, some subset of thepropos i t ional  network is active.
Manyof the act ive propos i t ions  have beenrecent ly  added to the network byproduct ions.
Others, after lyingdormant for a time, have beenreact ivated through their assoc iat ion(i.e., sharing of symbols) with otherrecent ly act ivated facts.
AMBER usesthis process of spreading act ivat ionpr imar i ly  to retr ieve informat ion aboutthe words assoc iated with part icu larconcepts.
The level of act ivat ion for apropos i t ion  natura l ly  decays over time,unless it is of fset  by other factors.The Product ion SystemACTG represents procedural  knowledgeas a set of cond i t ion -act ion  rulescal led product ions.
The condi t ions andact ions of these rules can be quitegeneral ,  s ince they may containvar iab les  that match against  arb i t rarystructures.
When all the condi t ions ofa product ion match against  some port ionof act ive memory, its act ions may becarr ied out.
These may interact withthe environment,  or add new propos i t ionsto the act ive part of the network.Structures matching var iab les  in thecondi t ions remain bound to thesevar iab les  in the actions.
After aproduct ion has been appl ied, the stateof memory is reexamined and the systemcycles.184-If two or more product ions  are foundto be true, one must be selected inpreference to the others.
Th is  dec is ionis based on the relat ive strength ~ ofthe product ions,  and on the summedact ivat ions of the propos i t ions  matchedby each.
The product  of these twonumbers is computed,  and the product ionwith the h ighest  value is selected.Since a s ingle product ion can matchagainst  a set of propos i t ions  ind i f ferent  ways, ties may somet imesoccur.
In such cases, one of thematches is selected at random.The ACTG Learning MechanismsACTG incorporates a powerful  set ofmechanisms for model ing learningphenomena.
The most basic of these isthe des ignat ion process, which al lowsthe creat ion of a new product ion  as oneof the act ions of an exist ing rule.Var iab les  bound in the condi t ions of thelearning rule are passed to theof fspr ing,  making the new rule morespeci f ic  than its creator.
Most ofAMBER'S learning heur is t ics  rely on thedes ignat ion  process.A second mechan ism leads to thest rengthening of a product ion each timeit is recreated.
Since the strength ofa rule plays an important role in theselect ion phase, product ions  which havebeen relearned many times will bepreferred.
On the other hand, thestrength of a rule can be decreased ifit leads to an error, lowering itschances for select ion.The d iscovery  of an error also leadsto a call on the d iscr iminat ion  process.Here the recent f i r ings of theresponsib le product ion are examined.
Ifone or more propos i t ions  have beenpresent  at successful  f i r ings and absentat faulty ones, they are added as extracondi t ions on a new, more conservat ivevers ion of the rule.
Together with thest rengthening and weakening processes,this mechanism gives ACTG the abi l i ty  torecover from overgenera l i zat ions .AMBER's  L inguist ic  KnowledgeLearning is the result of aninteract ion between a set of re lat ive lygeneral  techniques for acquir ingknowledge and the envi ronment  in whichthey find themselves.
In this sect ion Iconsider AMBER's representat ion of thatenvironment.
After this I examine theprocedures the model assumes at theoutset,  as well as the form of the rulesat which it eventual ly  arr ives.Represent ing SentencesBefore AMBER can learn how togenerate  legal sentences,  it must beexposed to examples of such sentences.One might  represent  a sentence as asimple l ist of words in the order theyare said.
However, though chi ldrenlearn to produce words in the correctorder very ear ly on, they also omit manywords that an adult  would include.
Forexample, the utterance "Daddy ball"omits informat ion about the act ion beingcarr ied out, as well as tenseinformation.
AMBER's  representat ion ofthe sentences it hears ref lects thisabi l i ty  to note order in the absence ofinformat ion about adjacency.The model represents the occurrenceof each morphem e as a separateproposi t ion,  each conta in ing informat ionabout the speaker, the word beingproduced, and the relat ive order ofoccurrence.
Thus, the fact that Mommysaid the sentence "Daddy bounces theball" would be stored as a set of sevenpropos i t ions:  (said 1 Mommy pause);(said 2 Mommy Daddy); (said 3 Mommybounce); (said 4 Mommy s) ; (said 5 Mommythe); (said 6 Mommy ball); and (said 7Mommy pause).
The first and lastpropos i t ions  act as de l imi tors  whichmark the beginning and end of thesentence.
This representat ion,  combinedwith ACTG's pat tern-match ing capabi l i ty ,a l lows the statement of learning ruleswhich focus on relat ive word order butignore ad jacency information.
Theresult ing product ion rules omit words,just as the chi ld does.Represent ing MeaningAdults  convers ing with a chi ld almostinvar iably  d iscuss recent or ongoingevents, so that the chi ld can associatesome event with every sentence he hears.The language acquis i t ion  process doesnot consist  solely of learning toproduce or parse legal wordcombinat ions;  it consists  of learningthe mapping between meanings and words.Accordingly ,  AMBER is presented not withisolated sentences as its data, but withsentence/meaning pairs.AMBER represents the meaning of asentence as a number of propos i t ions,each incorporat ing one of a small set ofrelat ions.
The most prevalent  of theseis the type relat ion, which connectstokens to the var ious concepts of whichthey are examples.
There is norestr ic t ion on the number of typerelat ions which may come off a token;-185---thus, the propos i t ions  (token-i typered) and (token-i type ball) state thatthe object  token-i  is both red and aball.
Events are represented withre lat ions such as a ~ ,  act ion, andobject.
The propos i t lons  (event-i agenttoken-2), (event-i act ion token-3),  and(event-i object token-4) represent anevent with an agent, action, and objectwhose types have yet to be specif ied.AMBER's  representat ion makes a strongd is t inct ion  between the main meaning ofa sentence as expressed through itscontent words and the modulat ions  ofthis meaning as expressed through itsgrammat ica l  morphemes.
The modelassumes that a type re lat ion point ing toa part icu lar  concept (e.g., *ball) ispresent  for every content word (e.g.,ball) found in the assoc iated sentence.Moreover,  a word- for  re lat ion is assumedpresent to establ ish the connect ionbetween word  and concept.
The presenceof these two relat ions tel ls AMBER whena word contr ibutes to the major meaningof a sentence.Modulat ions  on this meaning arerepresented by a d i f ferent  set ofrelat ions,  such as number,t ime-of -act ion,  possess ion,  and soforth.
Some of these relat ions connecttokens to var ious values, as in token-inumber singular) and token-2t ime-of -act ion  past).
Others, as in(token-4 possesses token-5) and token-5in token-6),  actua l ly  relate tokens.AMBER's  Init ial  Per formance SystemAMBER starts with the abi l i ty  toproduce single words in isolat ion.
Buteven at this stage, the model draws on aset of general  heur is t ics  for generat ingutterances which w i l l  sti l l  be usefulafter its learning is complete.
AMBERdoes not say words as soon as they  cometo mind; f irst there is an act iveplanning stage during which sequent ia lgoals  are set.The model starts with rules forin i t ia l iz ing and ending this p lanningphase, and for implement ing its plansonce they are complete (that is,actua l ly  saying the words in the plannedorder).
The goals  which result  from theplanning process look very l ike the datafrom which AMBER learns.
The two-wordutterance "Daddy ball" would berepresented by the propos i t ions  (goal 1AMBER pause),  (goal 2 AMBER Daddy),(goal 3 AMBER ball),  and (goal 4 AMBERpause), in which the model is thespeaker.At the outset,  AMBER has only asingle rule for insert ing such goals inmemory; stated in Engl ish for the sakeof c lar i ty  and with its var iab lesunderl ined,  it is:If you have no goals  yet,and you see vtoken with type v type,and vword is the word for vtype,then set up a goal to pause,fol lowed by a goal to say vwo~d,fol lowed by a goal to pause.This rule separates the goal utterancefrom others by init ial  and final pauses.Thus, even though success ive words maydescr ibe d i f ferent  aspects of the sameevent, they will be separated bynot iceable  gaps just as Bloom observed.Only after addit ional  rules have beenformed for insert ing sounds between theinit ial  word and the pauses canmul t i -word  utterances begin to occur.AMBER at Later StagesOn the basis of compar isons betweensentences it hears and those itpredicts,  AMBER creates and modi f iesrules for saying mul t ip le  words at atime.
These rules lead to the insert ionof new goals between exist ing ones.Thus, they are dependent  on the innaterules descr ibed above for in i t ia l iz ingthe goal insert ion process and forcarrying out goals  once they have beenset.Imagine a s i tuat ion in which AMBERsees Daddy bouncing a ball.
Alsosuppose that the one-word rule we sawabove happens to select "bounce" as theword that should be said.
This wouldlead to three goals: (goal 1 AMBERpause),  (goal 2 AMBER bounce),  and (goal3 AMBER pause).
After some exper iencewith English, the model will havegenerated a rule like:If you have a goal to pause,fol lowed by a goal to say vword2,and you have no intermediate goals,and vword2 is the word for vtype2,and vtoken2 is of type vtype2,and vtoken2 is the act ion of vevent,and vtokenl  is the agent of vevent,and Vtokenl  is of type vty~el,and vwordl  is the word for vtypel,then insert a goal to say vwordlbetween the other goa ls - -This rule would add a goal to say theagent "Daddy" after the f irst pause andbefore "bounce", using the propos i t ion(goal 1.5 AMBER Daddy).
S imi lar  ruleslead to the product ion of two- andthree-word sentences express ing themajor relat ions descr ibed by Brown.-186Later, AMBER also acquires rules forinserting grammatical morphemes.
Sincemost grammatical morphemes are adjacentto the word whose meaning they modulate,they are general ly inserted directlybefore or after the content word withwhich they occur.
For example, a rulefor regular plural ization might bestated:If you have a goal to say vword,and vword is the word for vtype,and vtoken is of type vtype,and vtoken is the agent of vevent,and the number of vtoken is plural,then insert a goal to say Sdirectly after vwordThis rule is specific to the agent of anevent, but similar rules could belearned for objects and locations.
Somemorphemes express a relation between twocontent words, such as the preposit ions"in" and "on" and the morpheme forpossession.
In these cases, themorpheme is inserted between the tworelated content words.The Acquisit ion ProcessFor a system to learn from itsmistakes, it must be able to compare itsown actions to the desired ~ones, notethe differences between them, and modifyits behavior accordingly.
In thissection I describe AMBER's errorcorrection mechanisms.
First I examinethe model's prediction mechanism and itsrelation to the goal structuresmentioned earlier.
Next I discussAMBER's response to errors of omission,first for content words and then forgrammatical morphemes.
Finally, Iconsider errors of commission and theresulting call on the discr iminationmechanism.The Equivalence of Goals and PredictionsAMBER learns by comparing itspredictions about what will be said in agiven situation to what it actuallyhears.
However, a learning system mustdo more than improve its abil ity topredict; it must also improve itsability to perform.
AMBER accomplishesthis by using the same productions formaking predictions and for planning itsspeech acts.
As we saw above, theserules add goal structures such as (goal3 AMBER bounce) when AMBER is thespeaker.
When another person is thespeaker, the resulting structures, suchas (goal 3 Mommy bounce) if Mommy is thespeaker, are treated as predictionsinstead of goals.
Learning occurs onlywhen someone else is speaking and thesystem is in prediction mode, whilesentences are produced only inperformance mode.Correcting Content Word OmissionsAMBER's transition from the one-wordto the multi-word stage is primari ly dueto the actions of a single learningheuristic.
This rule applies when acontent word is heard between two otherwords (or pauses) but was not predictedthere; the result is a new performancerule for inserting analogous words inanalogous positions in the future.AMBER knows enough about the nature oflanguage to generalize across theparticular words and concepts involved.However, it retains information aboutcase relations and shared tokens (e.g.,two of the words may have describedaspects of the same object).As an example, suppose AMBER seesDaddy bouncing a ball.
The modelpredicts the one-word sentence "Daddy"(preceded and followed by pauses), whileit actually hears "Daddy is bounce ingthe ball" (again bounded by pauses).Since the grammatical morphemes "is","ing", and "the" are not connected toconcepts by word-for links, they areignored by the current learningheuristic.
However, the words "bounce"and "ball" each have associated conceptswhich occurred in the observed event.An insertion rule is created for each,the first inserting the action wordafter the agent word and before thefinal pause.
The second is verysimilar, inserting the object word afterthe agent and before the pause.These rules give AMBER the abii ity togenerate agent-action and agent-objectcombinations, but no more.
The newrules cannot cooperate to produceagent-action-object combinations, foronce one of the rules has fired, theconditions of the other are no longermet.
But once this has happened, thesystem can learn additional insertionrules, such as that for inserting theobject word between the action and thefinal pause.
Yet even after this hasoccurred, the performance rules aredependent on the selection of the agentword as the initial goal.
Additionalinsertion rules must be learned to dealwith cases in which the action or objectis the first goal to be inserted.- 187--Correct ing Morpheme Omiss ionsAs it is improving its abi l i ty  toproduce str ings of content  words, AMBERis also learning to insert grammat ica lmorphemes.
Some of the morphemes whichmodi fy  a s ingle token, such as tense andp lu ra l i za t ion  endings,  occur after thewords descr ib ing the token.
Others,such as copulas (is, are, were) andart ic les  (a, the), occur before themodi f ied words.
Separate learningheur is t ics  are necessary  for these twocases, but there forms are near lyidentical .These learning rules are evoked whena part icu lar  morpheme is heard before orafter a content  word, but was notpredicted in that posit ion.
The resultis a per formance rule which inserts themorpheme either before or after wordsplaying s imi lar  roles in the future(e.g., "ing" after the word for theaction).
AMBER knows that thepart icu lar  content  word is i r re levant;however,  the case re lat ion f i l led bythat word and the morpheme are retained.AMBER also knows that several  contentwords may be used to descr ibe the sameobject  (e.g., "the big red ball s") , andthat these words wil l  occur together  inany legal sentence.
This is analogousto an assumpt ion made by Anderson 's  LAS\[3\], which he has cal led the 9raphdeformat ion  condit ion.
AMBER incorpor-ates this assumpt ion into its morphemeinsert ion rules, ensur ing that amorpheme will  be inserted either beforethe ear l iest  or after the latest  contentword descr ib ing a token (thus, "big thered s ball" would never be produced).The acqu is i t ion  of re lat ionalmorphemes,  such as those express ingpossess ion and locat ion,  is handled by ad i f ferent  rule.
This heur is t ic  isevoked in the same s i tuat ions  as theheur is t ic  for content  words, except thatthe unpredicted morpheme must not beassoc iated with any concept  via aword- for  link.
In addit ion,  the objectsdescr ibed by the two correct ly  predictedwords  must be d i rect ly  related (e.g., atoken of milk is on a token of table).The result ing per formance rule insertsthe morpheme between the sets of wordsdescr ib ing objects in the observedrelation.
Note that A~BER cannotacquire such re lat ional  morphemes untilit can cor rect ly  predict  the order ofthe words to be related.Correct ing Errors of Commiss ionOnce AMBER has learned a number ofrules for insert ing goals,  it can make anew sort of error: the model canincorrect ly  predict  that a word wil loccur in a certa in posit ion.
A s inglelearning heur ist ic  is suf f ic ient  to dealwith all such errors of commiss ion.
Itscondi t ion is simple, but in addi t ion toweakening the of fending rule, its act ioncal ls on the d i sc r iminat ion  mechan ism toproduce a more conservat ive  var iant.To reiterate,  this technique comparesthe last successfu l  app l i cat ion  of arule to the more recent faul tyapp l icat ion  in the hope of f indingaddit ional  condi t ions  to constra in  it inthe future.
Thus, if AMBER predictedthe sequence "ball red" when "red ball"was heard, the d i sc r iminat ion  processwould be evoked.
Compar ing this case toan ear l ier  one in which "blue block" wascor rect ly  predicted,  AMBER would notethat "blue" is a color whi le "ball" isnot.
Thus, the new rule would insertone word before another descr ib ing thesame object  only if the former were acolor l ike "blue" or "red"A l though d isc r iminat ion  is useful inlearning some content  word orders,  itsmajor import l ies with grammat ica lmorphemes.
Since the init ial rules fornonre lat iona l  morphmemes are toogeneral ,  their use qu ick ly  leads towrong predict ions.
For instance, if themorpheme "ed" was incor rect ly  expectedto fol low an act ion word, AMBER wouldnote that correct  pred ic t ions  of "ed"occurred only when the time of theact ion was past.
S imi lar ly,  AMBER wouldqu ick ly  learn to insert "s" after theword for the agent only when its numberwas plural.The condi t ions  under which somemorphemes are appl ied can be morecompl icated.
Thus, the morpheme "were"is inserted before the act ion word onlywhen the time of the act ion is past, andwhen the nu~er  of the agent assoc iatedwith that act ion is plural.
AMBER wouldbe forced to learn these condi t ions  intwo stages, f irst creat ing a var iantwith one condi t ion and later a vers ionincluding both.As a result, the more complex thecondi t ions  under which a morphemeoccurs,  the longer AMBER wil l  take tomaster  its use.
If one equates the188number of condi t ions with semanticcomplexity,  then the d isc r iminat ionprocess provides an elegant explanat ionof Brown's data on the order ofacquis i t ion for grammat ica l  morphemes.Semant ica l ly  more complex morphemes aremastered later because they require morecondit ions,  and these condi t ions can belearned only one at a time.Suggest ions  for Future ResearchIn summary, AMBER does a fine job ofaccount ing for the major phenomenadescr ibed at the beginning of the paper.However,  the model makes a number ofs impl i fy ing assumpt ions and stopsimproving after it has reached a certa inlevel of expert ise.
In this sect ion Isuggest  some d i rect ions in which AMBERshould be extended.Learning Word/Concept  Assoc iat ionsAMBER assumes that words and conceptsare a lready connected through word- forl inks stored in long- term dec larat ivememory.
These connect ions  play animportant  role in lett ing the systemd is t ingu ish  between content words andgrammat ica l  morphemes.
At least some ofthese connect ions  must be present  beforeany order ing rules can be learned, butthe model provides no explanat ion oftheir or igin.
Extending AMBER to let itmake its own word/concept  assoc iat ionsis c lear ly  a d i rect ion for future work.Select ing a Representat ionAMBER rel ies heavi ly  on therepresentat ional  d is t inct ion  betweenmajor meanings (expressed by type links)and modulat ions  of those meanings(expressed by others).
Unfor tunate lyfor the model,  some languages expressthrough content  words what othersexpress through grammat ica l  morphemes.This suggests that the child does notstart with a representat ion  likeAMBER's,  though it may arr ive at thesame point as the result  of exper iencewith a part icu lar  language.
Futureresearch should consider how the chi ldcomes to treat some meanings as majorand some as minor as a funct ion of hisnat ive language.Deal ing With Except ionsIn its current  version,  AMBER cannotdeal with i r regular  grammat ica lconstruct ions.
Some past forms, such as"ate", require a special  word for pastevents, but this cannot be expressed inthe current  formal ism for word/conceptassociat ions.
Some plural forms r.equired i f ferent  endings than most, such as"oxen".
These can be expressed inproduct ion form, but no condi t ions existto d is t inguish these s i tuat ions  from themajor i ty .
Future vers ions of AMBERshould have extended representat ionswhich address these issues.Expla in ing Later Stage sAMBER's  progress ion stops after ithas mastered the grammat ica l  morphemes.It never learns how to ask quest ions,  orhow to generate sentences with re lat iveclauses.
In fact, to present the modelwith other than simple dec larat ivesentences would be an inv i tat ion todisaster.
Future incarnat ions of thesystem should begin with the basicnot ions of recurs ion and t ransformat ion.Coupled with the exist ing learningmechanisms and the extens ions d iscussedabove, this should a l low AMBER toprogress far beyond its present level ofexpert ise,  and to become a true languageuser.References\[i\] S ik lossy,  L. Natural  languagelearning by computer.
In H. A. Simonand L. S ik lossy (eds.)
, Representat ionand Meaning: Exper iments  with Infor-mat ion Processing Systems.
EnglewoodCl i f fs,  N. J.: Prent ice-Hal l ,  1972.\[2\] Hedrick,  C. Dissertat ion,  Carnegie-Mel lon Univers i ty,  1974.\[3\] Anderson,  J. R. Induct ion ofaugmented transi t ion networks.
Cogni-tive Science, 1977, i, 125-157.\[4\] Sel fr idge,  M. Dissertat ion,  YaleUnivers i ty,  1979.\[5\] Berwick, R. Dissertat ion,  Massa-chusetts  Inst i tute of Technology,  1980.\[6\] Bloom, L. One Word at a Time.
TheHague: Mouton, 1976.\[7\] Brown, R. A First Language : TheEarly Stages.
Cambridge,  Massachusetts :Harvard Univers i ty  Press, 1973.AcknowledgementsThis research was supported by GrantsSPI-7914852 and IST-7918266 from theNational Science Foundation.
I wouldlike to thank John R. Anderson foruseful discussions which led to many ofthe ideas presented in this paper.189
