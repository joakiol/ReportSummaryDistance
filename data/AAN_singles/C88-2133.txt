S|,M~TIC AND Sg~A6TIC ~ 1 ~  OF ~ FUNCTIONKeh-Yih SU* and Jing-Shin CHANG***Department of Electrical EngineeringNational Tsing Hua University, Hsinehu, Taiwan, R.O.C.
**BTC R&D Center, P~D Road If, No.
28, 2nd FleerHsinchu Science-Based Industrial Park, Hsinchu, Taiwan, R.O.C.AbstractIn a Machine Translation System (MTS), the numberof possible analyses for a given sentence is largelydve to the ambiguous characteristics of the sourcelanguage.
In  this paper, a mechanism, called "ScoreFunction", is proposed for measuring the "quality" ofthe ambiguous syntax trees such that the one that bestfits interpretation by human is selected.
It isfeatured by incorporating the objectiveness of theprobability theory and the subjective expertise oflinguists.
The underlying uncertainty that is funda-mental to \]inguistic knowledge is also allowed to beincorporated into this system.
This feature proposesan easy resolution to select the best syntax tree andprovides some strategic advantages for scored parsing.The linguists can also be relieved of the necessity todescribe the language in strictly "correct" linguisticrules, which, if not impossible, is a very hard task.Mot ivat ionIn a Machine Translation System (Mrs), where theunderlying grammar is large, there are many sourceswhich may cause the system to become highly ambiguous.The system must choose a better syntax tree among allthe possible ones to reduce the load of the post-editor.
Some systems attack this problem by arrangingthe gram,~r rules in a descending order of their rela-tive frequency, following the .parsing paths in adepth-first manner, and selecting the first syntaxtree successfully parsed as the desired one.
However,rule ordering is just a locally preferred static scor-ing of the rule usage.
Therefore, the possibility issmall that the first tree selected is the correct one.Several MT systems based on the ATN formalism \[Wood70\] adopt another approach.
They impose conditioncheeks to prevent the parser from trying all possiblestates allowed by the underlying grammar.
Thisapproach has been widely accepted and is useful ineliminating the unnecessary trials.
However, there aretimes when legal paths are blocked inadvertently bycondition checks.
Therefore, the system must be tunedfre.~luently to achieve an equilibrium between theover-generative grammar and the over-restrictive con-dition checks.
This kind of "hard rejection" is obvi-ously too variant and too restrictive.A better solution is to adopt the "TruncationStrategy" (proposed by \[Su 87a, 87b\] for biT system) torestrict the number of parsing paths to be triedaccording to the relative preference of all the possi-ble paths.
The measuring mechanism of preference forthe truncation strategy is called the "Score Func-tion".
It bears similaritY to the select-by-preferencefound in other scored MT systems like the DIAGPCLMgrammar system \[Robi 82\] and METAL system \[Benn 82\].Under a scoring mechanism, the parsing paths are notrejected because of the over-restrictive conditionchecks but rather for their low scores.
This kind of"soft-rejection" prevents legal path from beingblocked too early because of unsuitable conditionchecks.
Different scoring mechanisms may be requiredat lexicon, syntax and semantics levels, and score canbe computed during parsing or after parsing.
In thispaper, we propose an approach to the semantic and syn-tactic aspects of the score function.642Cr i te r ia  fo r  Score  Funct ionIn  o rder  to  de f ine  a reasonab le  score  funct ion ,it is essential to set up some criteria first.
Eightbasic criteria are listed here.\[ I\] 'l~le score function should reflect the absolutedegree of preference of two ambiguous (sub)treesas well as their relative preferences.\[2\] A good score function should be applicable eitherlocally to a subtree or globally to a completetree.\[3\] The Score function should be compositional.
Thismeans the score of a tree should be directlyevaluated from the scores of its constituent sub-trees.\[4\] Relative rule application frequency should beincluded in the score function.
The rule that isused most frequently should receive a higherpreference.\[5\] The score function should also include the seman-tic information embedded in the sentence, so thatthe semantic preference can be involved in thescore function.
(Since our present translationunit is a single sentence, no discourse informa-tion need to be included)\[6\] The implementation of the score function shouldnot be too complicated.
In our case, it should bepractical for a large-scale bit system.\[7\] The database for score computation should be easyto build and easy to maintain.\[8\] The preference order of ambiguous trees assignedby the score function should match those assignedby the human.
In addition, the way the scores aregiven had better match the way that people givetheir preference to the ambiguous trees.
(i.e.
howpeople recognize the true meaning of a given sen-tence from several different interpretations)Keeping these criteria in mind, we define a scorefunction as follows.
The score function for a subtreeXo, with derivation sequence D of Xo(i,j) =D=>Xl(i,jl), X2(jI+I,j2) ... .
Xn(jn-l?l,j), .is :SCORE ( Xo )= SCsyn\[Xl ... Xn\]* SCsem\[(XI,KI(XI),KC(XI)) ... (Xn,KI(Xn),KC(Xn))\]In the above, Xo(i,j) is a subtree made up ofterminals X1 to Xnl i to j are the word index in thesentence; and SCORE is the score of the subtree Xo.SCsyn is the ttnweighted syntax score.
SCsem is thesemantic weighting.
KI is defined as the knowledgeabout the inherent properties of the nodes.
And KC isthe well-formedness condition, either syntactic orsemantic, of the Xi under the given syntactic con-struction.
To decrease the computational complexity,we can convert this multiplication equati'on into anaddition equation with logarithmic entries.l og (S~(Xo) )  = log(SCsyn) + log(SCsem)In order to obtain the score without excessivec~irputation and complicated algorithal, the probabilitymodel is probably one of the most c~n and promisingapproach.
Under this approach, the preference measure-ment in a scoring mechanism can be seen as a probabil-ity assigDment.
The best syntax tree should be theone with highest preference probability assigned toit.
This probability model c~m be divided into twoparts.
One is the syntactic score model, which isSCsyn, an~ the other is the semantic score model,which is SCsem.
The syntactic score model uses thesyntax probability as the base to generate anunweighted syntactic score for each syntax tree.
Thesemantic ~:core model then supplements the unweightedscore witl~ weights derived from the semanticblowledge.
Incorporation of semantic information isessential for a good score function because pure syn-t~tx probability can only provide partial informationfor sentence preference.Syntactic \[~zore Mode lFor a syntax tree given below, we define a phraselevel as a sequence of terminals and nonterminals thatare being reduced at a single step of "derivation, orreduction sequence".
The following example shows thereduction sequence of a bottom-up parsing.
Thesequence iE: indicated by the time series t\] .... t7 .
:.\ X8 = { A }\ \ \ t7  X7 = { B, C }X5 = { B, F, w4 }6 X4 = { B, W3, w4 }X3 = { D, E, w3, w4 }I ' X2 = { D, w2, w3, w4 }\[l t l l~ i2 ' '  t4 Ii X1 = { we, w2, w3, w4 } I t5'i~e unweighted score for this tree A is modeled as thefollowing conditional probability.SCsyn(A)= P(X81X7 .... Xl)*P(X7:X6,...XI)* ... *P(X2:XI)P(X8:X7)*P(X7:X6)*  .
.
.
*P(X2:XI )= P(A',BC)*P(BCIBFO)* .
.
.
*P(D,w2,w3,w41wl,w2,w3,w4)= P(A:P/~)*P(CIBFG)* ... *P(D:wl,w2,w3,w4\]An assumption was made in the above equation.
Weassumed terms like P(Xi:Xi-l, Xi-2, ... Xl) can besimplified into P(XilXi-l).
This is reasonable becauseat phrase level Xi-I it will contains most of theinformation percolated from lower levels and needed byXi.
So, extra information needed by Xi from Xi-2 islittle.
We completed a simulation for testing thism(xlel and also conducted several tests on the contextsensitivity of this probability model.
First, wechecked whether a left context (i.e.
L) is relevant tothe probability assignment.
Using theP(X3:X2)=P(E}D,w2,w3,w4) as an example, with D as theleft context of t/~e current derivation symbol w2, wechecked if P(X31X2)=P(E:D,w2) is true?
We also checkedwhether a )right context (i.e.
R) has influence on theassigrmlent ~ Or is P(X3 :X2 ) =P (E: w2, w3) true?
Othertest cases are LL, LR, RR, LRR, LLR, LLL, RRR, LLRRand LLLR.Semsnt ic  ~re  ModelThe we ight -ass ign ing  process  o f  the  semant icscore  can  /~ seen  as  an  exper t  task  whs '~ the  l ingu is ti s  g iv ing  ~he syntax  t ree  a d iagnos is .
The l ingu is t ,will assign a preference to a tree according to somelinguistic knowledge or heuristic rules.
Very oftenthese linguistic rules are not very precise.
There-fore, a good semantic score model must allow this typeof inexact knowledge.
Now, the problem is transformedinto building a rule-based expert system that can cal-culate sem~mtic scores (weightings) and handle inexactknowledge encountered during calculation.
We proposea model similar to the CF model (certainty factormodel } in MYCIN \[ Buch 85 \] system.
It has aknowledge-rule base where each rule has a certaintyfactor based on the degree of belief and disbelief.The confirmation of a hypothesis then is calculatedfrom the applicable rules and from other pieces ofevidence.
The CF of' a hypothesis is then accumulatedgradually with each additional evidence.Each tree node will have a we\]l-formedness factor(WFF), which is the CF for the derivation of thisnode, associated with it.
As the knowledge, which maycontain the word sense, syntactic category, attribute,etc., of leaf nodes propagates up along the syntaxstructure, every node's WFF will be calculated accord-ing to the rules stored in the lu~ow\]edge rule-base.This WFF then becomes the semantic score of the sub-tree.WFF(Xo) = SCsem\[ (XI,KI(XI),KC(XI) .. (Xn,KI(Xn),KC{Xn) \]where derivation sequence D : Xo =D=> XI, .. Xn.There are three major advantages of this scheme.First, linguists do not have to write a single exactrule to include all possible exceptions, because CFare given in accordance with its degree of confirma-tion or disconfirmation.
When an exception appears,all that needs to be done is to add necessary rulesand alter CF of certain existing rules.
Second, theCF model simplifies the implementation of "soft-rejection" for inexact knowledge.
For example, condi-tions (like those in A'I~) can be included for disambi-guation even if it is not absolute in its generality.
?l%lird, we can combine various traditiorml techniquesin analyzing semantics with CF model to construct auniform and flexible control strategy.
This allowsthe inclusion of uncertain factors like sen~mticmarker of lexicon, assignment of case ro\]e \[from casegra/mnar), and restriction of case filler.
Under thiscontrol strategy, word sense disamb~guation and struc--ture disambiguation are also possible.
The relativepreference will be given accerding to the CF associ-ated with different word sense and by the \] ~nguistJcrules from the knowledge base.All in all, with the score function defined asabove, it satisfies all eight criteria we had set ini-tially and it is a good systematic approach forassigning references to a set of ambiguous trees.Simulation l~esultA simulation, based on \[408 source sentences, wasconducted to test the syntactic score mode\].
The pro~bability assigned to the entries ,e.g.
P(E:w2,w3), inthe SCsyn equation is estimated with the relative fre-quency of these entries.
That is, we approximateP(E :w2,w3 ) by the ratio of the number of events{E,w2,w3} in the database and the number of events{w2,w3}.
Several tests are conducted to check theinfluence of the context on the probability assign-ment.
These tests include L, R, LL, LR, RR, LLL, LLR,LRR, RR~, LLRR and LLLR.
Table 1 is some of theresult of the simulation using sentences in the data-base as the test inputs.The number of entries in the t~ble is the numberof different conditional probability, e.g.
P(Elw2,w3),in the database.
F~ch entry is assigned a probabilityaccording to its usage frequency as we explainedbefore.
The preference of a tree is the parmneter thatwe want to estimate from these entries.
If the sizeof database is not large enough then these probability643Table 1 : Some results of the syntactic score simulation.+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.I s i ze  o f  database  (sentences) :  820I No.
of  sample  tes t  sentences  = 52+ ...... + ....... + ..........................Rank count accumulative percentage.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 42 80.77%2 8 96,15%6 2 100,00%context : LL No, of entries : 2966..........................................Rard\[ count accumulative percentagep .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 45 86.54%2 6 98,08%4 1 100.00%context : LRR No.
of entries : 4574..........................................Rank count accumulative percentage...... .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 45 86.54%2 6 98.08%4 1 100.00%, context : LLRR No.
of entries : 6285. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.+ ........................................I size of database (sentences): 1468: No.
of sample test sentences = 97+ ...... + ....... + .........................I Rank count accumulative percentage '.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 76 78.35%2 15 93.81%3 3 96.91%4 1 97.94%6 2 100.00%.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.context : LL No.
of entries : 4187.........................................Rank count accumulative percentageI .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 83 85.57%2 11 96.91%3 2 98,97%4 1 100.00%context : ~ No.
of entries : 6560.........................................Rank count accumulative percentage.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 85 87.63%2 9 96.91%3 2 98.97%4 1 100.00%.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.context  : LLI~ No.
of  ent r ies  : 9224 '.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.can not be approximated by the relative frequency.
Ingeneral, as %.he size of a database increases so is theaccuracy of approximation.
But how big should thedai~base be is diffJeu\]t to determine.
This leads usto built two databases, one having 1468 source sen-tences and the other having 820 sentences.
If thesimulation result from different base is close then wemay assume that the databdlse size is large enough.Comparing the results from these two databases, itsis apparent that the size is adequate for the presentsimulation.
Furthermore, it is also apparent that acontext-sensitive scoring function must be adopted fora good preference estimation.Two conclusions can be drawn from this simulationresu\]t. First, we should adopt three constituents inc~Iculating the probability.
The reason is thatalthough the result of LLRR case is better than thatof LRIt case, the size of entries required by LLRR isconsiderab\]e greater.
Second, approximately 85% ofsyntax trees is accurately selected with only syntac-tic information available.
Therefore, if we want toimprove this result further we must include the seman-tic information.Conclusion and PerspectiveIn a Machine Translation System, to reduce theload of the post-editor we must select the best syntaxtree from a set of ambiguous trees and pass it to thepost-editor.
There are systems that rely on a set ofordered grammar rules or on a set of restrictive con-dition checks to achieve this.
Unfortunately9 theyall }lave some drawbacks: one being too uncertain andthe  other being too restrictive.
In this paper wehave proposed a score mechanism for the truncationstrategy to perform disambiguation during parsing.
Thescore function, with the adoption of three contextsymbols, gives the power of context-sensitive grammarto an efficient context-free parser.
From our simula-tion, the score function with just syntactic informa-tion will achieve an accuracy rate of 85%.
In thenear future when the semantic information is included,this accuracy rate is expected to  increase.
Currently,two databases, one  for unweighted score computationand the other for linguistic rule base (for weightingassignment), are under the development at the BTC R&Dcenter.
After completion they will be incorporatedinto the truncation parsing algorithm for our thirdgeneration parser.AcknowledgmentWe would like to express our deepest appreciationto  Wen-t%~eh L i  and  Hsue-Hueh Hsu fo r  the i r  work on thesimulations, to the whole linguistic group at BTC R&I)center  fo r  the i r  work on the  database ,  and  Mei -Hui  Sufo r  her  ed i t ing .
Spec ia l  thanks  are  g iven  to  Behav iorTech.
Computer  Co. fo r  the i r  fu l l  f inanc ia l  suppor t  o fth i s  p ro jec t .Re ferences\[Benn 85\] Bennet t ,  W.S.
and J .
S locum, "The LRCMachine Trans la t ion  System~" Computat iona lLinguistics, vol.ll, No.
2-3, pp.
lll-ll9,ACL, Apr.-Sep. 1985.\[Buch 85\] Buchanan B.G.
and E,H.
Sortliffe(eds),RULE-BASED EXP~T SYSTEMS.
Reading, MA:Addison-Wesley, 1984.\[Robi 82\] Robinson, J.J., "DI~DRAM : A Grammar forDialogues," CAGM, voi.25, No.l, pp.27-47,ACM, Jan. 1982.\[Su 87a\] Su, K.Y., J.S.
Chang, and H.H.
Hsu, "APowerful Language Processing System forEnglish-Chinese Machine Translation," 1987Int.
Conf.
on Chinese and Oriental LanguageComputing, pp.260-264, Chicago, Ill, 1987.\[Su 87b\] Su, K.Y., J.N.
Wang, W.H.
Li, and J.S.Chang, "A New Parsing Strategy in NaturalLanguage Processing Based on the TruncationAlgorithm'*, pp.
580-586 Proc.
of Natl.
Com-puter Symposium (NCS) 19879 Taipei, H.O.C..\[Wood 70\] Woods, W.A., "Transition Network Grammarsfor Natural Language Analysis," CACM,vol.13., No.lO, pp.591-606, ACM, Oct. 1970.644
