Coling 2010: Poster Volume, pages 383?390,Beijing, August 2010Learning Phrase Boundariesfor Hierarchical Phrase-based TranslationZhongjun HE Yao MENG Hao YUFujitsu R&D Center CO., LTD.{hezhongjun, mengyao, yu}@cn.fujitsu.comAbstractHierarchical phrase-based models pro-vide a powerful mechanism to capturenon-local phrase reorderings for statis-tical machine translation (SMT).
How-ever, many phrase reorderings are arbi-trary because the models are weak on de-termining phrase boundaries for pattern-matching.
This paper presents a novelapproach to learn phrase boundaries di-rectly from word-aligned corpus withoutusing any syntactical information.
We usephrase boundaries, which indicate the be-ginning/ending of phrase reordering, assoft constraints for decoding.
Experi-mental results and analysis show that theapproach yields significant improvementsover the baseline on large-scale Chinese-to-English translation.1 IntroductionThe hierarchial phrase-based (HPB) model (Chi-ang, 2005) outperformed previous phrase-basedmodels (Koehn et al, 2003; Och and Ney, 2004)by utilizing hierarchical phrases consisting of bothwords and variables.
Thus the HPB model hasgeneralization ability: a translation rule learnedfrom a phrase pair can be used for other phrasepairs with the same pattern, e.g.
reordering infor-mation of a short span can be applied for a largespan during decoding.
Therefore, the model cap-tures both short and long distance phrase reorder-ings.However, one shortcoming of the HPB model isthat it is difficult to determine phrase boundariesfor pattern-matching.
Therefore, during decod-ing, a rule may be applied for all possible sourcephrases with the same pattern.
However, incorrectpattern-matching will cause wrong translation.Consider the following rule that is used to trans-late the Chinese sentence in Figure 1 into English:X ?
?XL de XR, XR in XL?
(1)The rule translates the Chinese word ?de?
intoEnglish word ?in?, and swaps the left sub-phrasecovered by XL and the right sub-phrase coveredby XR on the target side.
However, XL maypattern-match 5 spans on the left side of ?de?
andXR may pattern-match 3 spans on the right side.Therefore, the rule produces 15 different deriva-tions.
However, 14 of them are incorrect.The correct derivation Sc is shown in Figure 2,while one of the wrong derivations Si is shown inFigure 3.
We observe that the basic difference be-tween Sc and Si is the phrase boundary matchedby ?XR?.
In Sc, XR matches the span [7, 9] andmoves it as a whole unit.
While in Si, XR matchesthe span [7, 8] and left the last word [9, 9] be trans-lated separately.
Similarly, other incorrect deriva-tions are caused by inadequate pattern-matchingof XL and/or XR.Previous research showed that phrases shouldbe constrained to some extent for improving trans-lation quality.
Most of the existing approaches uti-lized syntactic information to constrain phrases torespect syntactic boundaries.
Chiang (2005) in-troduced a constituent feature to reward phrasesthat match a syntactic tree but did not yield signif-icant improvement.
Marton and Resnik (2008) re-vised this method by distinguishing different con-stituent syntactic types, and defined features foreach type to count whether a phrase matches orcrosses the syntactic boundary.
This led to a sub-stantial improvements.
Gimpel and Smith (2008)presented rich contextual features on the sourceside including constituent syntactical features forphrase-based translation.
Cherry (2008) utilizeda dependency tree as a soft constraint to detectsyntactic cohesion violations for a phrase-based383?1ta?2jiang??3chengwei??4yindu????5youshiyilai?6de??7shouwei?8n??
?9zongtongShe1 will2 become3 the4 first5 female6 president7 in8 India?s9 history10X[5,5]X[4,5]X[3,5]X[2,5]X[1,5]X[7,7]X[7,8]X[7,9]Figure 1: An example of Chinese-English translation.
The rule X ?
?XL de XR, XR in XL?pattern-matches 5 and 3 spans on the left and right of the Chinese word ?de?, respectively.Sc ?
?????
X, She will become X??
?????
X[4,5]?
X[7,9], She will become X[7,9] in X[4,5]??
?????
???????
??
?????
?,She will become the first female president in India?s history?Figure 2: The correct derivation with adequate pattern-matching of XR.Si ?
?????
X ?
?, She will become X president??
?????
X[4,5]?
X[7,8]?
?, She will become X[7,8] in X[4,5] president??
?????
???????
??
????
??
?,She will become the first female in India?s history president?Figure 3: A wrong derivation with inadequate pattern-matching of XR.system.
Xiong et al (2009) presented a syntax-driven bracketing model to predict whether twophrases are translated together or not, using syn-tactic features learned from training corpus.
Al-though these approaches differ from each other,the main basic idea is the utilization of syntacticinformation.In this paper, we present a novel approach tolearn phrase boundaries for hierarchical phrase-based translation.
A phrase boundary indicates thebeginning or ending of a phrase reordering.
Moti-vated by Ng and Low (2004) that built a classifierto predict word boundaries for word segmenta-tion, we build a classifier to predict phrase bound-aries.
We classify each source word into one of the4 boundary tags: ?b?
indicates the beginning of aphrase, ?m?
indicates a word appears in the mid-dle of a phrase, ?e?
indicates the end of a phrase,?s?
indicates a single-word phrase.We use phrase boundaries as soft constraints fordecoding.
To do this, we incorporate our classifieras a feature into the HPB model and propose anefficient decoding algorithm.Compared to the previous work, out approachhas the following advantages:?
Our approach maintains the strength of thephrase-based models since it does not re-quire any syntactical information.
There-fore, phrases do not need to respect syntacticboundaries.?
The training instances are directly learnedfrom a word-aligned bilingual corpus, ratherthan from manually annotated corpus.384?
The decoder outputs phrase segmentation in-formation as a byproduct, in addition totranslation result.We evaluate our approach on large-scaleChinese-to-English translation.
Experimental re-sults and analysis show that using phrase bound-aries as soft constraints achieves significant im-provements over the baseline system.2 Previous Work2.1 Learning Word BoundariesIn some languages, such as Chinese, words are notdemarcated.
Therefore, it is a preliminary task todetermine word boundaries for a sentence, whichis the so-called word segmentation.Ng and Low (2004) regarded word segmen-tation as a classification problem.
They labelledeach Chinese character with one of 4 possibleboundary tags: ?b?, ?m?, ?e?
respectively indi-cates the begin, the middle and the end of a word,and ?s?
indicates a single-character word.
Theirsegmenter was built within a maximum entropyframework and trained on manually segmentedsentences.Learning phrase boundaries is analogous toword boundaries.
The basic difference is thatthe unit for learning word boundaries is charac-ter while the unit for learning phrase boundariesis word.
In this paper, we adopt the boundarytags presented by Ng and Low (2004) and build aclassifier to predict phrase boundaries within max-imum entropy framework.
We train it directly on aword-aligned bilingual corpus, without any man-ually annotation and syntactical information.2.2 The Hierarchical Phrase-based ModelWe built a hierarchical phrase-based MT system(Chiang, 2007) based on weighted SCFG.
Thetranslation knowledge is represented by rewritingrules:X ?
?
?, ?,??
(2)where X is a non-terminal, ?
and ?
are source andtarget strings, respectively.
Both of them containwords and possibly co-indexed non-terminals.
?describes a one-to-one correspondence betweennon-terminals in ?
and ?.Chiang (2007) used the standard log-linearframework (Och and Ney, 2002) to combine var-ious features:Pr(e|f) ?
?i?ihi(?, ?)
(3)where hi(?, ?)
is a feature function and ?i isthe weight of hi.
Analogous to the previousphrase-based model, Chiang defined the follow-ing features: translation probabilities p(?|?)
andp(?|?
), lexical weights pw(?|?)
and pw(?|?
),word penalty, rule penalty, and a target n-gramlanguage model.In this paper, we integrate a phrase boundaryclassifier as an additional feature into the log-linear model to provide soft constraint for pattern-matching during decoding.
The feature weightsare optimized by MERT algorithm (Och, 2003).3 Learning Phrase BoundariesWe build a phrase boundary classifier (PBC)within a maximum entropy framework.
The PBCpredicts a boundary tag for each source word, con-sidering contextual features:Ptag(t|fj , F J1 ) =exp(?i ?ihi(t, fj , F J1 ))?t exp(?i ?ihi(t, fj , F J1 )(4)where, t ?
{b, m, e, s}, fj is the jth word insource sentence F J1 , hi is a feature function and?i is the weight of hi.To build PBC, we first present a method to rec-ognize phrase boundaries and extract training ex-amples from word-aligned bilingual corpus, thenwe define contextual feature functions.3.1 Phrase BoundaryDuring decoding, intuitively, words within aphrase should be translated or moved together.Therefore, a phrase boundary should indicate re-ordering information.
We assign one of theboundary tags (b,m, e, s) to each word in sourcesentences.
Thus the word with tag b, e or s is aphrase boundary.
One question is that how to as-sign boundary tag to a word?
In this paper, werecognize the largest source span which has themonotone translation.
Then we assign boundary385??
??
?jointly held by(a)??
?
?a short visit(b)Figure 4: Illustration for monotone span (a) andPM span (b).tags to each word in the source span, according totheir position.To do this, we first introduce some notations.Given a bilingual sentence (F J1 , EI1) together withword alignment matrix A, we use L(Aj) andH(Aj) to represent the lowest and highest tar-get word position which links to the source wordfj , respectively.
Since the word alignment for fjmaybe ?one-to-many?, all the corresponding tar-get words will appear in the span [L(Aj),H(Aj)].we define a source span [j1, j2] (1 ?
j1 ?
j2 ?J) a monotone span, iff:1.
?
(j, i) ?
A, j1 ?
j ?
j2 ?
L(Aj1) ?
i ?H(Aj2)2.
?k1, k2 ?
[j1, j2], k1 ?
k2 ?
H(Ak1) ?L(Ak2)The first condition indicates that(F j2j1 , EH(Aj2 )L(Aj1 )) is a phrase pair as describedpreviously in phrase-based SMT models.
Whilethe second condition indicates that the lowertarget bound linked to a source word cannot belower than any target word position linked to theprevious source word.
Therefore, a monotonespan does not contain crossed links or internalreorderings.Considering that word alignments could bevery noisy and complex in real-world data, we de-fine pseudo-monotone (PM) span by loosening thesecond condition:?k1, k2 ?
[j1, j2], k1 ?
k2 ?
L(Ak1) ?
L(Ak2)(5)This condition allows crossed links to some ex-tent by loosening the bound of Ak1 from upperto lower.
Figure 4 (a) shows an example ofmonotone span, in which the translation is mono-tone.
While Figure 4 (b) is not a monotone spanbecause there is a cross link between the upperbound of ????
and the lower bound of ???
?on the target side.
However, it is a PM span ac-cording to the definition.
Note that in some cases,a source word may not be contained in any phrasepair, therefore we consider a single word span asa PM span, specificly.An interesting feature of PM span is that if twoPM spans are consecutive on both source side andtheir corresponding target side, the two PM spanscan be combined as a larger PM span.
Formally,(F jj1 , Eii1)?
(F j2j+1, Ei2i+1) = (Fj2j1 , Ei2i1 ) (6)where [j1, j] and [j+1, j2] are PM spans, [i1, i]and [i + 1, i2] are the target spans correspondingto [j1, j] and [j+1, j2], respectively.
For example,Figure 4 (a) shows a PM phrase pair that consistsof two small PM pairs ??
?, jointly?
and ???
?, held by?.In this paper, we are interested in phrase re-ordering boundaries for a source sentence.
We de-fine translation span (TS) the largest possible PMspan.
A TS may consist of one or more PM spans.According to our definition, cross links may ap-pear within PM spans but do not appear betweenPM spans within a TS.
Therefore, TS is the largestpossible span that will be translated as a unit andphrase reorderings may occur between TSs duringdecoding.To obtain phrase boundary examples fromword-aligned bilingual sentences, we first find allpossible TSs and then assign boundary tags toeach word.
For a TS [j1, j2] (j1 < j2) that containmore than two words, we assign ?b?
to the firstword fj1 and ?e?
to the last word fj2 , and ?m?
tothe middle words fj (j1 < j < j2).
For a singleword span TS [j, j], we assign ?s?
to the word fj .Figure 5 shows an example of labelling sourcewords with boundary tags.
The source sentence issegmented into 4 TSs.
Using the phrase boundaryinformation to guide decoding, the decoder willproduce the correct derivation and translation asshown in Figure 2.386???????????????
?TAG b m e b e s b m eShewillbecomethe firstfemalepresidentinIndia?shistoryFigure 5: Illustration for labelling the sourcewords with boundary tags.
The solid boxespresent word alignments.
The bordered boxes areTSs.3.2 Feature DefinitionThe features we used for the PS model are anal-ogous to (Ng and Low, 2004).
For a word W0,we define the following contextual features with awindow of ?n?:?
The word feature Wn, which denotes the left(right) n words of the current word W0;?
The part-of-speech (POS) feature Pn, whichdenotes the POS tag of the word Wn.For example, the tag of the word ???
(be-come)?
in Figure 5 is ?e?, indicating that it isthe end of a phrase.
If we set the context windown = 2, the features of the word ???
(become)?are:?
W?2=?
W?1=?
W0=?
?
W1=?
?W2=?????
P?2=r P?1=d P0=v P1=ns P2=lWe collect TSs from bilingual sentences to-gether with the contextual features and used aMaxEnt toolkit (Zhang, 2004) to train a PBC.?
?
?
?b 0.78 0.10 1.2e-5m 6.4e-8 0.75 5.4e-5e 2.1e-8 0.11 0.87s 0.22 0.04 0.13Table 1: The TPM for a source sentence.
Thehighest probability of each word is in bold.4 Phrase Boundary ConstrainedDecodingGive a source sentence, we can assign boundarytags to each word by running the PBC.
Duringdecoding, a rule is prohibited to pattern-matchacross phrase boundaries.
By doing this, the PBCis integrated as a hard constraint.
However, thismethod will invalidate a large number of rules andthe decoder suffers from a risk that there are notenough rules to cover the source sentence.Alternatively, inspired by previous approaches,we integrate the phrase boundary classifier as asoft constraint by incorporating it as a feature intothe HPB model:hpbc(F J1 ) = log(J?j=1Ptag(t|fj , F J1 )) (7)To perform translation, for each word fj ina source sentence F J1 , we first compute all tagprobabilities Ptag(t|fj), where t ?
(b,m, e, s),j ?
[1, J ], according to Equation 4.
Therefore, webuild a 4?
J tag-word probability matrix (TPM).TPM [i, j] indicates the probability of the wordfj labelled with the tag ti.
Table 1 shows theTPM for a source text ?????
?.Then we select rule options from the rule ta-ble that can be used for translating the source text.Since each rule option (f?
, e?, a) 1 can be regardedas a bilingual sentence with word alignments, thuswe find all TS in f?
and assign an initial tag (IT)for each source word.
This procedure is analogousto label phrase boundary tags for a word-alignedbilingual sentence.
For example, the followingrules are used for translating the Chinese sentencein Table 1:1We keep word alignments of a rule when it is extractedfrom bilingual sentence.387X ?
?
?bX?1 , She X1?
(8)X1 ?
??b?
?e, will become?
(9)Since both the source sides of these two rulesare PM spans according to the word alignments,the IT sequences for rule (8) and (9) are ?b *?2and ?b e?, respectively.
According to Table 1,the initial hpbc score for these two rules can becomputed as follows:h(7)pbc = log(Ptag(b|?))
= log(TPM [1, 1]) (10)h(8)pbc = log(Ptag(b|?))
+ log(Ptag(e|??
))= log(TPM [1, 2]) + log(TPM [3, 3]) (11)Note that to keep the tag sequence valid, e.g.?m?
follows ?b?
rather than ?s?, the ITs maybeupdated during decoding.
The tag-updatingshould be consistent with the definition of TS asdescribed in Section 3.1.
Specifically, when thenon-terminal symbol X is derived from its cov-ered span f(X), the boundary tags should be up-dated.When a tag of word fj is updated from tk1 totk2 , the PBC score should also be updated accord-ing to TPM:?PBC = log(TPM [k2, j])?
log(TPM [k1, j])(12)The following is a derivation of the source sen-tence in Table 1:S ?
?
?bX?1 , She X1??
??b?b?m?
?e, She will become?When X1 is derived, the tag of its left boundaryword ???
is updated from ?b?
to ?m?.
The reasonis that after derivation, the combined span formsa larger PM span and the left boundary of f(X1)should be updated.As a result, the hpbc score is recomputed:hpbc(F 31 ) = h(7)pbc + h(8)pbc +?PBC (13)where,?PBC = log(TPM [2, 2])?
log(TPM [1, 2])(14)2We use ?*?
as a tag of the non-terminal symbol ?X1?since it has not been derived.The decoding algorithm is efficient since thecomputing of the PBC score is a procedure oftable-lookup.5 Experiments5.1 Experimental SetupOur experiments were on Chinese-to-Englishtranslation.
The training corpus (77M+81M) weused are from LDC 3.
The evaluation metric isBLEU (Papineni et al, 2002), as calculated bymteval-v11b.pl with case-insensitive matching ofn-grams, where n = 4.To obtain word alignments, we first ranGIZA++ (Och and Ney, 2002) in both translationdirections and then refined it by ?grow-diag-final?method (Koehn et al, 2003).For the language model, we used the SRI Lan-guage Modeling Toolkit (Stolcke, 2002) to traintwo 4-gram models on xinhua portion of Giga-Word corpus and the English side of the trainingcorpus.The NIST MT03 test set is used to tune the fea-ture weights of the log-linear model by MERT(Och, 2003).
We tested our system on the NISTMT06 and MT08 test sets.5.2 ResultsThe results are shown in Table 2.
We tested vari-ous settings of the context window.
It is observedthat the small values of n (n = 1, 2) drop theBLEU score, suggesting that perhaps there are notenough contextual information.
With more con-textual information is used, the BLEU scores areimproved over all test sets.
When n = 3, the mostsignificant improvements are obtained on MT06Gand MT08.
The improvements over the baselineare statistically significant at p < 0.01 by usingthe significant test method described in (Koehn,2004).
While for MT06N, the optimized contextwindow size is n = 4 but the improvement isnot statistically significant.
In most cases, withn larger than 3, we do not obtain further improve-ments because of the data sparseness for training3LDC2002E18, LDC2002L27, LDC2002T01,LDC2003E07, LDC2003E14, LDC2004T07, LDC2005E83,LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E24,LDC2006E26, LDC2006E34, LDC2006E86, LDC2006E92,LDC2006E93, LDC2004T08(HK News, HK Hansards).388System MT06G MT06N MT08baseline 14.66 34.42 26.29+PBC (n=1) 13.78 33.20 24.58+PBC (n=2) 14.34 34.21 25.87+PBC (n=3) 15.19* 34.63 27.25*+PBC (n=4) 14.76 34.73 26.70Table 2: Results on the test sets with different con-text window (n) of the phrase boundary classifier.The largest BLEU score on each test set is in bold.MT06G: MT06 GALE set.
MT06N: MT06 NISTset.
*: significantly better than the baseline atp < 0.01.the classifier.6 DiscussionThe experimental results show that the phraseboundary constrained method improves the BLEUscore over the baseline system.
Furthermore, weare interested in how the PBC affects the transla-tion results?
We compared the outputs generatedby the baseline and ?+PBC (n = 3)?
system andfound some interesting translations.
For example,the translations of a source sentence of NIST08are as follows 4:?
Src: ?b1 ?
?m2 ?m3 ?
?m4 ?
?e5 ??
?b6?m7 ?
?e8 ??b9??m10??e11?
Ref: US1 Treasury-Secretary2 Arrives-in3China4 for-a-Visit-with5 Environment6 and7Exchange-Rate8 as9 Focus10,11?
HPB: US1 Treasury2 in-environmental-protection6 and7 visit5 China4 is9 key11to-the-concern-of10 the-exchange-rate8?
+PBC: US1 Treasury2 arrived-in3 China4for-a-visit5 environmental-protection6 and7exchange-rate8 is9 concerned-about10 the-key11In the example, both ????
and ????
in thesource sentence are the concern of the ?visit?.Therefore, the source span [6, 8] indicates a co-hesive phrase, which should be translated as a4The co-indexes of the words on the source and targetsentence indicate word alignments.whole unit.
However, the baseline translates thespans [6, 7] and [8, 8] separately.
It moves [6, 7]before ?visit China?
and [8, 8] after ?concern?.This makes an mistake on phrase reordering.
Weobserve that the ?+PBC?
system produces a bet-ter translation.
After incorporating the PBC asa soft constraint, the system assigns a boundarytag to each source word and segments the sourcesentence into three TSs.
According to our defi-nition, TSs are encouraged as pseudo-monotonetranslation unit during decoding.
As a result, the?+PBC?
system discourages some arbitrary re-ordering rules and produces more fluent transla-tion.7 Conclusion and Future WorkThis paper presented a phrase boundary con-strained method for hierarchical phrase-basedtranslation.
A phrase boundary indicates beginor end of a phrase reordering.
We built a phraseboundary classifier within a maximum entropyframework and learned phrase boundary exam-ples directly from word-aligned bilingual corpus.We proposed an efficient decoding method to in-tegrate the PBC into the decoder as a soft con-straint.
Experiments and analysis show that thephrase boundary constrained method achieves sig-nificant improvements over the baseline system.The most advantage of the PBC is that it han-dles both syntactic and non-syntactic phrases.
Inthe future, We would like to try different meth-ods to determine more informative phrase bound-aries, e.g.
Xiong et al (2010) proposed a methodto learn translation boundaries from a hierarchicaltree that decomposed from word alignments usinga shift-reduce algorithm.
In addition, we will trymore features as described in (Chiang et al, 2008;Chiang et al, 2009), e.g.
the length of the phrasesthat covered by non-terminals.ReferencesCherry, Colin.
2008.
Cohesive phrase-based decodingfor statistical machine translation.
In Proceedingsof the 46rd Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies, page 72?80.Chiang, David, Yuval Marton, and Philip Resnik.3892008.
Online large-margin training of syntactic andstructural translation features.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, page 224?233.Chiang, David, Wei Wang, and Kevin Knight.
2009.11,001 new features for statistical machine trans-lation.
In Proceedings of Human Language Tech-nologies: the 2009 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, page 218?226.Chiang, David.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics, pages 263?270.Chiang, David.
2007.
Hierarchical phrase-basedtranslation.
Computational Linguistics, pages33(2):201?228.Gimpel, Kevin and Noah A. Smith.
2008.
Richsource-side context for statistical machine transla-tion.
In In Proceedings of the ACL-2008 Workshopon Statistical Machine Translation (WMT-2008),pages 9?17.Koehn, Philipp, Franz J. Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of HLT-NAACL 2003, pages 127?133.Koehn, Philipp.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofthe 2004 Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 388?395.Marton, Yuval and Philip Resnik.
2008.
Soft syntac-tic constraints for hierarchical phrased-based trans-lation.
In Proceedings of the 46rd Annual Meetingof the Association for Computational Linguistics:Human Language Technologies, pages 1003?1011.Ng, Hweetou and Jinkiat Low.
2004.
Chinese part-of-speech tagging: One-at-a-time or all-at-once?word-based or character-based?
In Proceedings ofthe 2004 Conference on Empirical Methods in Nat-ural Language Processing (EMNLP 2004), pages277?284.Och, Franz Josef and Hermann Ney.
2002.
Dis-criminative training and maximum entropy modelsfor statistical machine translation.
In Proceedingsof the 40th Annual Meeting of the Association forComputational Linguistics, pages 295?302.Och, Franz Josef and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
30:417?449.Och, Franz Josef.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofthe 41st Annual Meeting of the Association for Com-putational Linguistics, pages 160?167.Papineni, K., S. Roukos, T. Ward, and W.-J.
Zhu.2002.
Bleu: a method for automatic evaluation ofmachine translation.
In Proceedings of the 40th An-nual Meeting of the Association for ComputationalLinguistics, pages 311?318.Stolcke, Andreas.
2002.
SRILM ?
An extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken language Process-ing, volume 2, pages 901?904.Xiong, Deyi, Min Zhang, Aiti Aw, and Haizhou Li.2009.
A syntax-driven bracketing model for phrase-based translation.
In ACL-IJCNLP 2009, page315?323.Xiong, Deyi, Min Zhang, and Haizhou Li.
2010.Learning translation boundaries for phrase-baseddecoding.
In Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the ACL, page 136?144.Zhang, Le.
2004.
Maximum entropy model-ing toolkit for python and c++.
available athttp://homepages.inf.ed.ac.uk/s0450736/maxent too-lkit.html.390
