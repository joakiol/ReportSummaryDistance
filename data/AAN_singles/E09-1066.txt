Proceedings of the 12th Conference of the European Chapter of the ACL, pages 576?584,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsSyntactic and Semantic Kernels for Short Text Pair CategorizationAlessandro MoschittiDepartment of Computer Science and EngineeringUniversity of TrentoVia Sommarive 1438100 POVO (TN) - Italymoschitti@disi.unitn.itAbstractAutomatic detection of general relationsbetween short texts is a complex task thatcannot be carried out only relying on lan-guage models and bag-of-words.
There-fore, learning methods to exploit syntaxand semantics are required.
In this pa-per, we present a new kernel for the repre-sentation of shallow semantic informationalong with a comprehensive study on ker-nel methods for the exploitation of syntac-tic/semantic structures for short text paircategorization.
Our experiments with Sup-port Vector Machines on question/answerclassification show that our kernels can beused to greatly improve system accuracy.1 IntroductionPrevious work on Text Categorization (TC) hasshown that advanced linguistic processing for doc-ument representation is often ineffective for thistask, e.g.
(Lewis, 1992; Furnkranz et al, 1998;Allan, 2000; Moschitti and Basili, 2004).
In con-trast, work in question answering suggests thatsyntactic and semantic structures help in solvingTC (Voorhees, 2004; Hickl et al, 2006).
Fromthese studies, it emerges that when the categoriza-tion task is linguistically complex, syntax and se-mantics may play a relevant role.
In this perspec-tive, the study of the automatic detection of re-lationships between short texts is particularly in-teresting.
Typical examples of such relations aregiven in (Giampiccolo et al, 2007) or those hold-ing between question and answer, e.g.
(Hovy etal., 2002; Punyakanok et al, 2004; Lin and Katz,2003), i.e.
if a text fragment correctly responds toa question.In Question Answering, the latter problem ismostly tackled by using different heuristics andclassifiers, which aim at extracting the best an-swers (Chen et al, 2006; Collins-Thompson etal., 2004).
However, for definitional questions, amore effective approach would be to test if a cor-rect relationship between the answer and the queryholds.
This, in turns, depends on the structure ofthe two text fragments.
Designing language mod-els to capture such relation is too complex sinceprobabilistic models suffer from (i) computationalcomplexity issues, e.g.
for the processing of largebayesian networks, (ii) problems in effectively es-timating and smoothing probabilities and (iii) highsensitiveness to irrelevant features and processingerrors.
In contrast, discriminative models such asSupport Vector Machines (SVMs) have theoreti-cally been shown to be robust to noise and irrele-vant features (Vapnik, 1995).
Thus, partially cor-rect linguistic structures may still provide a rel-evant contribution since only the relevant infor-mation would be taken into account.
Moreover,such a learning approach supports the use of kernelmethods which allow for an efficient and effectiverepresentation of structured data.SVMs and Kernel Methods have recently beenapplied to natural language tasks with promisingresults, e.g.
(Collins and Duffy, 2002; Kudo andMatsumoto, 2003; Cumby and Roth, 2003; Shenet al, 2003; Moschitti and Bejan, 2004; Culottaand Sorensen, 2004; Kudo et al, 2005; Toutanovaet al, 2004; Kazama and Torisawa, 2005; Zhanget al, 2006; Moschitti et al, 2006).
In particular,in question classification, tree kernels, e.g.
(Zhangand Lee, 2003), have shown accuracy comparableto the best models, e.g.
(Li and Roth, 2005).Moreover, (Shen and Lapata, 2007; Moschittiet al, 2007; Surdeanu et al, 2008; Chali and Joty,5762008) have shown that shallow semantic informa-tion in the form of Predicate Argument Structures(PASs) (Jackendoff, 1990; Johnson and Fillmore,2000) improves the automatic detection of cor-rect answers to a target question.
In particular,in (Moschitti et al, 2007) kernels for the process-ing of PASs (in PropBank1 format (Kingsbury andPalmer, 2002)) extracted from question/answerpairs were proposed.
However, the relatively highkernel computational complexity and the limitedimprovement on bag-of-words (BOW) producedby this approach do not make the use of such tech-nique practical for real world applications.In this paper, we carry out a complete study onthe use of syntactic/semantic structures for rela-tional learning from questions and answers.
Wedesigned sequence kernels for words and Part ofSpeech Tags which capture basic lexical seman-tics and basic syntactic information.
Then, we de-sign a novel shallow semantic kernel which is farmore efficient and also more accurate than the oneproposed in (Moschitti et al, 2007).The extensive experiments carried out on twodifferent corpora of questions and answers, de-rived from Web documents and the TREC corpus,show that:?
Kernels based on PAS, POS-tag sequences andsyntactic parse trees improve the BOW approachon both datasets.
On the TREC data the improve-ment is interestingly high, e.g.
about 61%, makingits application worthwhile.?
The new kernel for processing PASs is more ef-ficient and effective than previous models so thatit can be practically used in systems for short textpair categorization, e.g.
question/answer classifi-cation.In the remainder of this paper, Section 2presents well-known kernel functions for struc-tural information whereas Section 3 describes ournew shallow semantic kernel.
Section 4 reportson our experiments with the above models and, fi-nally, a conclusion is drawn in Section 5.2 String and Tree KernelsFeature design, especially for modeling syntacticand semantic structures, is one of the most dif-ficult aspects in defining a learning system as itrequires efficient feature extraction from learningobjects.
Kernel methods are an interesting rep-resentation approach as they allow for the use of1www.cis.upenn.edu/?aceall object substructures as features.
In this per-spective, String Kernel (SK) proposed in (Shawe-Taylor and Cristianini, 2004) and the SyntacticTree Kernel (STK) (Collins and Duffy, 2002) al-low for modeling structured data in high dimen-sional spaces.2.1 String KernelsThe String Kernels that we consider count thenumber of substrings containing gaps shared bytwo sequences, i.e.
some of the symbols of theoriginal string are skipped.
Gaps modify theweight associated with the target substrings asshown in the following.Let?
be a finite alphabet, ??
=?
?n=0 ?n is theset of all strings.
Given a string s ?
?
?, |s| denotesthe length of the strings and si its compoundingsymbols, i.e s = s1..s|s|, whereas s[i : j] selectsthe substring sisi+1..sj?1sj from the i-th to thej-th character.
u is a subsequence of s if thereis a sequence of indexes !I = (i1, ..., i|u|), with1 ?
i1 < ... < i|u| ?
|s|, such that u = si1 ..si|u|or u = s[!I] for short.
d(!I) is the distance betweenthe first and last character of the subsequence u ins, i.e.
d(!I) = i|u| ?
i1 + 1.
Finally, given s1, s2?
?
?, s1s2 indicates their concatenation.The set of all substrings of a text corpus forms afeature space denoted by F = {u1, u2, ..} ?
?
?.To map a string s in R?
space, we can use thefollowing functions: ?u(s) =P!I:u=s[!I] ?d(!I) forsome ?
?
1.
These functions count the num-ber of occurrences of u in the string s and assignthem a weight ?d(!I) proportional to their lengths.Hence, the inner product of the feature vectors fortwo strings s1 and s2 returns the sum of all com-mon subsequences weighted according to theirfrequency of occurrences and lengths, i.e.SK(s1, s2) =Xu???
?u(s1) ?
?u(s2) =Xu??
?X!I1:u=s1[!I1]?d(!I1)X!I2:u=t[!I2]?d(!I2) =Xu??
?X!I1:u=s1[!I1]X!I2:u=t[!I2]?d(!I1)+d( !I2),where d(.)
counts the number of characters in thesubstrings as well as the gaps that were skipped inthe original string.2.2 Syntactic Tree Kernel (STK)Tree kernels compute the number of common sub-structures between two trees T1 and T2 withoutexplicitly considering the whole fragment space.Let F = {f1, f2, .
.
.
, f|F|} be the set of tree577SNPNNPAnxietyVPVBZisNPDaNdisease?VPVBZisNPDaNdiseaseVPVBZ NPDaNdiseaseVPVBZisNPD NdiseaseVPVBZisNPD NVPVBZisNPVPVBZ NPNPDaNdiseaseNPNNPAnxietyNNPAnxietyVBZisDaNdisease .
.
.Figure 1: A tree for the sentence ?Anxiety is a disease?
with some of its syntactic tree fragments.fragments and ?i(n) be an indicator function,equal to 1 if the target fi is rooted at node nand equal to 0 otherwise.
A tree kernel func-tion over T1 and T2 is defined as TK(T1, T2) =?n1?NT1?n2?NT2?
(n1, n2), where NT1 andNT2 are the sets of nodes in T1 and T2, respec-tively and ?
(n1, n2) =?|F|i=1 ?i(n1)?i(n2).?
function counts the number of subtreesrooted in n1 and n2 and can be evaluated as fol-lows (Collins and Duffy, 2002):1. if the productions at n1 and n2 are different then?
(n1, n2) = 0;2. if the productions at n1 and n2 are the same,and n1 and n2 have only leaf children (i.e.
theyare pre-terminal symbols) then ?
(n1, n2) = ?;3.
if the productions at n1 and n2 are the same, andn1 and n2 are not pre-terminals then ?
(n1, n2) =?Ql(n1)j=1 (1 + ?
(cn1(j), cn2(j))), where l(n1) is thenumber of children of n1, cn(j) is the j-th childof node n and ?
is a decay factor penalizing largerstructures.Figure 1 shows some fragments of the subtreeon the left part.
These satisfy the constraint thatgrammatical rules cannot be broken.
For exam-ple, [VP [VBZ NP]] is a valid fragment which hastwo non-terminal symbols, VBZ and NP, as leaveswhereas [VP [VBZ]] is not a valid feature.3 Shallow Semantic KernelsThe extraction of semantic representations fromtext is a very complex task.
For it, tradition-ally used models are based on lexical similarityand tends to neglect lexical dependencies.
Re-cently, work such as (Shen and Lapata, 2007; Sur-deanu et al, 2008; Moschitti et al, 2007; Mos-chitti and Quarteroni, 2008; Chali and Joty, 2008),uses PAS to consider such dependencies but onlythe latter three researches attempt to completelyexploit PAS with Shallow Semantic Tree Kernels(SSTKs).
Unfortunately, these kernels result com-putational expensive for real world applications.In the remainder of this section, we present ournew kernel for PASs and compare it with the pre-vious SSTK.PASA1DisorderrelcharacterizeA0fear(a)PASR-A0thatrelcausesA1anxiety(b)Figure 2: Predicate Argument Structure trees associatedwith the sentence: ?Panic disorder is characterized by unex-pected and intense fear that causes anxiety.
?.PASrelcharacterizeA0fearPASrelcharacterizePASA1 rel A0PASA1 relcharacterizePASrelcharacterizeA0Figure 3: Some of the tree substructures useful to captureshallow semantic properties.3.1 Shallow Semantic StructuresShallow approaches to semantic processing aremaking large strides in the direction of efficientlyand effectively deriving tacit semantic informa-tion from text.
Large data resources annotatedwith levels of semantic information, such as in theFrameNet (Johnson and Fillmore, 2000) and Prop-Bank (PB) (Kingsbury and Palmer, 2002) projects,make it possible to design systems for the auto-matic extraction of predicate argument structures(PASs) (Carreras and Ma`rquez, 2005).
PB-basedsystems produce sentence annotations like:[A1 Panic disorder] is [rel characterized] [A0 by unexpectedand intense fear] [R?A0 that] [relcauses] [A1 anxiety].A tree representation of the above semantic in-formation is given by the two PAS trees in Fig-ure 2, where the argument words are replaced bythe head word to reduce data sparseness.
Hence,the semantic similarity between sentences can bemeasured in terms of the number of substructuresbetween the two trees.
The required substructuresviolate the STK constraint (about breaking pro-duction rules), i.e.
since we need any set of nodeslinked by edges of the initial tree.
For example,interesting semantic fragments of Figure 2.a areshown in Figure 3.Unfortunately, STK applied to PAS trees cannotgenerate such fragments.
To overcome this prob-lem, a Shallow Semantic Tree Kernel (SSTK) wasdesigned in (Moschitti et al, 2007).3.2 Shallow Semantic Tree Kernel (SSTK)SSTK is obtained by applying two different steps:first, the PAS tree is transformed by adding a layer578of SLOT nodes as many as the number of possi-ble argument types, where each slot is assigned toan argument following a fixed ordering (e.g.
rel,A0, A1, A2, .
.
.
).
For example, if an A1 is foundin the sentence annotation it will be always posi-tioned under the third slot.
This is needed to ?arti-ficially?
allow SSTK to generate structures con-taining subsets of arguments.
For example, thetree in Figure 2.a is transformed into the first treeof Fig.
4, where ?null?
just states that there is nocorresponding argument type.Second, to discard fragments only containingslot nodes, in the STK algorithm, a new step 0 isadded and the step 3 is modified (see Sec.
2.2):0. if n1 (or n2) is a pre-terminal node and its childlabel is null, ?
(n1, n2) = 0;3.
?
(n1, n2) =Ql(n1)j=1 (1 +?
(cn1(j), cn2(j))) ?
1.For example, Fig.
4 shows the fragments gen-erated by SSTK.
The comparison with the idealfragments in Fig.
3 shows that SSTK well approx-imates the semantic features needed for the PASrepresentation.
The computational complexity ofSSTK is O(n2), where n is the number of the PASnodes (leaves excluded).
Considering that the treeincluding all the PB arguments contains 52 slotnodes, the computation becomes very expensive.To overcome this drawback, in the next section,we propose a new kernel to efficiently process PAStrees with no addition of slot nodes.3.3 Semantic Role Kernel (SRK)The idea of SRK is to produce all child subse-quences of a PAS tree, which correspond to se-quences of predicate arguments.
For this purpose,we can use a string kernel (SK) (see Section 2.1)for which efficient algorithms have been devel-oped.
Once a sequence of arguments is output bySK, for each argument, we account for the poten-tial matches of its children, i.e.
the head of theargument (or more in general the argument wordsequence).More formally, given two sequences of argu-ment nodes, s1 and s2, in two PAS trees andconsidering the string kernel in Sec 2.1, theSRK(s1, s2) is defined as:X!I1:u=s1[ !I1]!I2:u=s2[!I2]Yl=1..|u|(1 + ?
(s1[$I1l], s2[$I2l]))?d( !I1)+d(!I2), (1)where u is any subsequence of argument nodes,!Il is the index of the l-th argument node, s[!Il] isthe corresponding argument node in the sequences and ?
(s1[!I1l], s2[!I2l]) is 1 if the heads of the ar-guments are identical, otherwise is 0.Proposition 1 SRK computes the number of allpossible tree substructures shared by the two eval-uating PAS trees, where the considered substruc-tures of a tree T are constituted by any set of nodes(at least two) linked by edges of T .Proof The PAS trees only contain three node lev-els and, according to the proposition?s thesis, sub-structures contain at least two nodes.
The num-ber of substructures shared by two trees, T1 andT2, constituted by the root node (PAS) and thesubsequences of argument nodes is evaluated by?
!I1:u=s1[!I1],!I2:u=s2[!I2]?d(!I1)+d(!I2) (when ?
= 1).Given a node in a shared subsequence u, its child(i.e.
the head word) can be both in T1 and T2,originating two different shared structures (withor without such head node).
The matches on theheads (for each shared node of u) are combinedtogether generating different substructures.
Thusthe number of substructures originating from u isthe product,?l=1..|u|(1+?
(s1[!I1l], s2[!I2l])).
Thisnumber multiplied by all shared subsequencesleads to Eq.
1.
!We can efficiently compute SRK by following asimilar approach to the string kernel evaluation in(Shawe-Taylor and Cristianini, 2004) by definingthe following dynamic matrix:Dp(k, l) =kXi=1lXr=1?k?i+l?r ?
?p?1(s1[1 : i], s2[1 : r]),(2)where ?p(s1, s2) counts the number of shared sub-structures of exactly p argument nodes between s1and s2 and again, s[1 : i] indicates the sequenceportion from argument 1 to i.
The above matrix isthen used to evaluate ?p(s1a, s2b) =(?2(1 + ?
(h(a), h(b)))Dp(|s1|, |s2|) if a = b;0 otherwise.
(3)where s1a and s2b indicate the concatenation ofthe sequences s and t with the argument nodes, aand b, respectively and ?
(h(a), h(b)) is 1 if thechildren of a and b are identical (e.g.
same head).The interesting property is that:Dp(k, l) = ?p?1(s1[1 : k], s2[1 : l]) + ?Dp(k, l ?
1)+ ?Dp(k ?
1, l)?
?2Dp(k ?
1, l ?
1).
(4)To obtain the final kernel, we need to con-sider all possible subsequence lengths.
Letm be the minimum between |s1| and |s2|,SRK(s1, s2) =mXp=1?p(s1, s2).579PASSLOTrelcharacterizeSLOTA0fear*SLOTA1disorder*SLOTnull.
.
.PASSLOTrelcharacterizeSLOTA0fear*SLOTnull.
.
.PASSLOTrelcharacterizeSLOTnullSLOTnull.
.
.PASSLOTrelSLOTA0SLOTA1.
.
.PASSLOTrelcharacterizeSLOTA1SLOTnull.
.
.Figure 4: Fragments of Fig.
2.a produced by the SSTK (similar to those of Fig.
3).Regarding the processing time, if ?
is the max-imum number of arguments in a predicate struc-ture, the worst case computational complexity ofSRK is O(?3).3.4 SRK vs. SSTKA comparison between SSTK and SRK suggeststhe following points: first, although the computa-tional complexity of SRK is larger than the oneof SSTK, we will show in the experiment sectionthat the running time (for both training and test-ing) is much lower.
The worse case is not reallyinformative since as shown in (Moschitti, 2006),we can design fast algorithm with a linear averagerunning time (we use such algorithm for SSTK).Second, although SRK uses trees with onlythree levels, in Eq.1, the function ?
(defined togive 1 or 0 if the heads match or not) can be sub-stituted by any kernel function.
Thus, ?
can re-cursively be an SRK (and evaluate Nested PASs(Moschitti et al, 2007)) or any other potential ker-nel (over the arguments).
The very interesting as-pect is that the efficient algorithm that we provide(Eqs 2, 3 and 4) can be accordingly modified toefficiently evaluate new kernels obtained with the?
substitution2.Third, the interesting difference between SRKand SSTK (in addition to efficiency) is that SSTKrequires an ordered sequence of arguments to eval-uate the number of argument subgroups (argu-ments are sorted before running the kernel).
Thismeans that the natural order is lost.
SRK instead isbased on subsequence kernels so it naturally takesinto account the order which is very important:without it, syntactic/semantic properties of pred-icates cannot be captured, e.g.
passive and activeforms have the same argument order for SSTK.Finally, SRK gives a weight to the predicatesubstructures by considering their length, whichalso includes gaps, e.g.
the sequence (A0, A1) ismore similar to (A0, A1) than (A0, A-LOC, A1),in turn, the latter produces a heavier match than(A0, A-LOC, A2, A1) (please see Section 2.1).2For space reasons we cannot discuss it here.This is another important property for modelingshallow semantics similarity.4 ExperimentsOur experiments aim at studying the impact of ourkernels applied to syntactic/semantic structures forthe detection of relations between short texts.
Inparticular, we first show that our SRK is far moreefficient and effective than SSTK.
Then, we studythe impact of the above kernels as well as se-quence kernels based on words and Part of SpeechTags and tree kernels for the classification of ques-tion/answer text pairs.4.1 Experimental SetupThe task used to test our kernels is the classifi-cation of the correctness of ?q, a?
pairs, where ais an answer for the query q.
The text pair ker-nel operates by comparing the content of ques-tions and the content of answers in a separate fash-ion.
Thus, given two pairs p1 = ?q1, a1?
andp2 = ?q2, a2?, a kernel function is defined asK(p1, p2) =??
K?
(q1, q2) +??
K?
(a1, a2),where ?
varies across different kernel functionsdescribed hereafter.As a basic kernel machine, we used ourSVM-Light-TK toolkit, available at disi.unitn.it/moschitti (which is based on SVM-Light(Joachims, 1999) software).
In it, we imple-mented: the String Kernel (SK), the Syntactic TreeKernel (STK), the Shallow Semantic Tree Kernel(SSTK) and the Semantic Role Kernel (SRK) de-scribed in sections 2 and 3.
Each kernel is associ-ated with the above linguistic objects: (i) the linearkernel is used with the bag-of-words (BOW) or thebag-of-POS-tags (POS) features.
(ii) SK is usedwith word sequences (i.e.
the Word Sequence Ker-nel, WSK) and POS sequences (i.e.
the POS Se-quence Kernel, PSK).
(iii) STK is used with syn-tactic parse trees automatically derived with Char-niak?s parser; (iv) SSTK and SRK are applied totwo different PAS trees (see Section 3.1), automat-ically derived with our SRL system.It is worth noting that, since answers often con-580020406080100120140160180200220240200 400 600 800 1000 1200 1400 1600 1800TimeinSecondsTraining Set SizeSRK (training) SRK (test)SSTK (test) SSTK (training)Figure 5: Efficiency of SRK and SSTKtain more than one PAS, we applied SRK or SSTKto all pairs P1 ?
P2 and sum the obtained contri-bution, where P1 and P2 are the set of PASs of thefirst and second answer3.
Although different ker-nels can be used for questions and for answers, weused (and summed together) the same kernels ex-cept for those based on PASs, which are only usedon answers.4.1.1 DatasetsTo train and test our text QA classifiers, weadopted the two datasets of question/answer pairsavailable at disi.unitn.it/?silviaq, contain-ing answers to only definitional questions.
Thedatasets are based on the 138 TREC 2001 testquestions labeled as ?description?
in (Li and Roth,2005).
Each question is paired with all the top20 answer paragraphs extracted by two basic QAsystems: one trained with the web documents andthe other trained with the AQUAINT data used inTREC?07.The WEB corpus (Moschitti et al, 2007) of QApairs contains 1,309 sentences, 416 of which arepositive4 answers whereas the TREC corpus con-tains 2,256 sentences, 261 of which are positive.4.1.2 Measures and ParameterizationThe accuracy of the classifiers is provided by theaverage F1 over 5 different samples using 5-foldcross-validation whereas each plot refers to a sin-gle fold.
We carried out some preliminary experi-ments of the basic kernels on a validation set and3More formally, let Pt and Pt?
be the sets of PASs ex-tracted from text fragments t and t?
; the resulting kernel willbe Kall(Pt, Pt?)
=Pp?PtPp?
?Pt?SRK(p, p?
).4For instance, given the question ?What are inverte-brates?
?, the sentence ?At least 99% of all animal speciesare invertebrates, comprising .
.
.
?
was labeled ?-1?
, while?Invertebrates are animals without backbones.?
was labeled?+1?.we noted that the F1 was maximized by using thedefault cost parameters (option -c of SVM-Light),?
= 0.04 (see Section 2).
The trade-off parame-ter varied according to different kernels on WEBdata (so it needed an ad-hoc estimation) whereasa value of 10 was optimal for any kernel on theTREC corpus.4.2 Shallow Semantic Kernel EfficiencySection 2 has illustrated that SRK is applied tomore compact PAS trees than SSTK, which runson large structures containing as many slots asthe number of possible predicate argument types.This impacts on the memory occupancy as wellas on the kernel computation speed.
To empiri-cally verify our analytical findings (Section 3.3),we divided the training (TREC) data in 9 bins ofincreasing size (200 instances between two con-tiguous bins) and we measured the learning andtest time5 for each bin.
Figure 5 shows that inboth the classification and learning phases, SRKis much faster than SSTK.
With all training data,SSTK employs 487.15 seconds whereas SRK onlyuses 12.46 seconds, i.e.
it is about 40 times faster,making the experimentation of SVMs with largedatasets feasible.
It is worth noting that to imple-ment SSTK we used the fast version of STK andthat, although the PAS trees are smaller than syn-tactic trees, they may still contain more than halfmillion of substructures (when they are formed byseven arguments).4.3 Results for Question/AnswerClassificationIn these experiments, we tested different kernelsand some of their most promising combinations,which are simply obtained by adding the differentkernel contributions6 (this yields the joint featurespace of the individual kernels).Table 1 shows the average F1?
the standard de-viation7 over 5-folds on Web (and TREC) data ofSVMs using different kernels.
We note that: (a)BOW achieves very high accuracy, comparable tothe one produced by STK, i.e.
65.3 vs 65.1; (b)the BOW+STK combination achieves 66.0, im-5Processing time in seconds of a Mac-Book Pro 2.4 Ghz.6All adding kernels are normalized to have a sim-ilarity score between 0 and 1, i.e.
K?
(X1,X2) =K(X1,X2)?K(X1,X1)?K(X2,X2).7The Std.
Dev.
of the difference between two classifierF1s is much lower making statistically significant almost allour system ranking in terms of performance.581WEB CorpusBOW POS PSK WSK STK SSTK SRK BOW+POS BOW+STK PSK+STK WSK+STK STK+SSTK STK+SRK65.3?2.9 56.8?0.8 62.5?2.3 65.7?6.0 65.1?3.9 52.9?1.7 50.8?1.2 63.7?1.6 66.0?2.7 65.3?2.4 66.6?3.0 (+WSK) 68.0?2.7 (+WSK) 68.2?4.3TREC Corpus24.2?5.0 26.5?7.9 31.6?6.8 14.0?4.2 33.1?3.8 21.8?3.7 23.6?4.7 31.9?7.1 30.3?4.1 36.4?7.0 23.7?3.9 (+PSK) 37.2?6.9 (+PSK) 39.1?7.3Table 1: F1 ?
Std.
Dev.
of the question/answer classifier according to several kernels on the WEB andTREC corpora.proving both BOW and STK; (c) WSK (65.7) im-proves BOW and it is enhanced by WSK+STK(66.6), demonstrating that word sequences andSTKs are very relevant for this task; and fi-nally, WSK+STK+SSTK is slightly improved byWSK+STK+SRK, 68.0% vs 68.2% (not signifi-cantly) and both improve on WSK+STK.The above findings are interesting as the syntac-tic information provided by STK and the semanticinformation brought by WSK and SRK improveon BOW.
The high accuracy of BOW is surprisingif we consider that at classification time, instancesof the training models (e.g.
support vectors) arecompared with different test examples since ques-tions cannot be shared between training and testset8.
Therefore the answer words should be dif-ferent and useless to generalize rules for answerclassification.
However, error analysis reveals thatalthough questions are not shared between train-ing and test set, there are common words in theanswers due to typical Web page patterns whichindicate if a retrieved passage is an incorrect an-swer, e.g.
Learn more about X.Although the ability to detect these patterns isbeneficial for a QA system as it improves its over-all accuracy, it is slightly misleading for the studythat we are carrying out.
Thus, we experimentedwith the TREC corpus which does not containWeb extra-linguistic texts and it is more complexfrom a QA task viewpoint (it is more difficult tofind a correct answer).Table 1 also shows the classification results onthe TREC dataset.
A comparative analysis sug-gests that: (a) the F1 of all models is much lowerthan for the Web dataset; (b) BOW shows the low-est accuracy (24.2) and also the accuracy of itscombination with STK (30.3) is lower than theone of STK alone (33.1); (c) PSK (31.6) improvesPOS (26.5) information and PSK+STK (36.4) im-proves on PSK and STK; and (d) PAS adds further8Sharing questions between test and training sets wouldbe an error from a machine learning viewpoint as we cannotexpect new questions to be identical to those in the trainingset.information as the best model is PSK+STK+SRK,which improves BOW from 24.2 to 39.1, i.e.
61%.Finally, it is worth noting that SRK provides ahigher improvement (39.1-36.4) than SSTK (37.2-36.4).4.4 Precision/Recall CurvesTo better study the benefit of the proposed linguis-tic structures, we also plotted the Precision/Recallcurves (one fold for each corpus).
Figure 6 showsthe curve of some interesting kernels applied tothe Web dataset.
As expected, BOW shows thelowest curves, although, its relevant contributionis evident.
STK improves BOW since it pro-vides a better model generalization by exploit-ing syntactic structures.
Also, WSK can gener-ate a more accurate model than BOW since it usesn-grams (with gaps) and when it is summed toSTK, a very accurate model is obtained9.
Finally,WSK+STK+SRK improves all the models show-ing the potentiality of PASs.Such curves show that there is no superiormodel.
This is caused by the high contributionof BOW, which de-emphasize all the other mod-els?s result.
In this perspective, the results onTREC are more interesting as shown by Figure 7since the contribution of BOW is very low makingthe difference in accuracy with the other linguis-tic models more evident.
PSK+STK+SRK, whichencodes the most advanced syntactic and semanticinformation, shows a very high curve which out-performs all the others.The analysis of the above results suggests that:first as expected, BOW does not prove very rel-evant to capture the relations between short textsfrom examples.
In the QA classification, whileBOW is useful to establish the initial ranking bymeasuring the similarity between question and an-swer, it is almost irrelevant to capture typical rulessuggesting if a description is valid or not.
Indeed,since test questions are not in the training set, theirwords as well as those of candidate answers willbe different, penalizing BOW models.
In these9Some of the kernels have been removed from the figuresso that the plots result more visible.582010203040506070809010030 40 50 60 70 80 90 100PrecisionRecallSTKWSK+STKWSK+STK+SRKBOWWSKFigure 6: Precision/Recall curves of some kernelcombinations on the WEB dataset.010203040506070809010010 15 20 25 30 35 40 45 50 55 60PrecisionRecallSTKPSK+STK"PSK+STK+SRK"BOWPSKFigure 7: Precision/Recall curves of some kernelcombinations on the TREC dataset.conditions, we need to rely on syntactic structureswhich at least allow for detecting well formed de-scriptions.Second, the results show that STK is importantto detect typical description patterns but also POSsequences provide additional information sincethey are less sparse than tree fragments.
Such pat-terns improve on the bag of POS-tags by about 6%(see POS vs PSK).
This is a relevant result consid-ering that in standard text classification bigrams ortrigrams are usually ineffective.Third, although PSK+STK generates a very richfeature set, SRK significantly improves the classi-fication F1 by about 3%, suggesting that shallowsemantics can be very useful to detect if an an-swer is well formed and is related to a question.Error analysis revealed that PAS can provide pat-terns like:- A0(X) R-A0(that) rel(result) A1(Y)- A1(X) rel(characterize) A0(Y),where X and Y need not necessarily be matched.Finally, the best model, PSK+STK+SRK, im-proves on BOW by 61%.
This is strong evidencethat complex natural language tasks require ad-vanced linguistic information that should be ex-ploited by powerful algorithms such as SVMsand using effective feature engineering techniquessuch as kernel methods.5 ConclusionIn this paper, we have studied several typesof syntactic/semantic information: bag-of-words(BOW), bag-of-POS tags, syntactic parse treesand predicate argument structures (PASs), for thedesign of short text pair classifiers.
Our learn-ing framework is constituted by Support VectorMachines (SVMs) and kernel methods appliedto automatically generated syntactic and semanticstructures.In particular, we designed (i) a new SemanticRole Kernel (SRK) based on a very fast algorithm;(ii) a new sequence kernel over POS tags to en-code shallow syntactic information; (iii) many ker-nel combinations (to our knowledge no previouswork uses so many different kernels) which allowfor the study of the role of several linguistic levelsin a well defined statistical framework.The results on two different question/answerclassification corpora suggest that (a) SRK for pro-cessing PASs is more efficient and effective thanprevious models, (b) kernels based on PAS, POS-tag sequences and syntactic parse trees improve onBOW on both datasets and (c) on the TREC datathe improvement is remarkably high, e.g.
about61%.Promising future work concerns the definitionof a kernel on the entire argument information(e.g.
by means of lexical similarity between all thewords of two arguments) and the design of a dis-course kernel to exploit the relational informationgathered from different sentence pairs.
A closerrelationship between questions and answers can beexploited with models presented in (Moschitti andZanzotto, 2007; Zanzotto and Moschitti, 2006).Also the use of PAS derived from FrameNet andPropBank (Giuglea and Moschitti, 2006) appearsto be an interesting research line.AcknowledgmentsI would like to thank Silvia Quarteroni for herwork on extracting linguistic structures.
Thiswork has been partially supported by the EuropeanCommission - LUNA project, contract n. 33549.583ReferencesJ.
Allan.
2000.
Natural Language Processing for InformationRetrieval.
In NAACL/ANLP (tutorial notes).X.
Carreras and L. Ma`rquez.
2005.
Introduction to theCoNLL-2005 shared task: SRL.
In CoNLL-2005.Y.
Chali and S. Joty.
2008.
Improving the performance ofthe random walk model for answering complex questions.In Proceedings of ACL-08: HLT, Short Papers, Columbus,Ohio.Y.
Chen, M. Zhou, and S. Wang.
2006.
Reranking answersfrom definitional QA using language models.
In ACL?06.M.
Collins and N. Duffy.
2002.
New ranking algorithms forparsing and tagging: Kernels over discrete structures, andthe voted perceptron.
In ACL?02.K.
Collins-Thompson, J. Callan, E. Terra, and C. L.A. Clarke.2004.
The effect of document retrieval quality on factoidQA performance.
In SIGIR?04.Aron Culotta and Jeffrey Sorensen.
2004.
Dependency TreeKernels for Relation Extraction.
In ACL04, Barcelona,Spain.C.
Cumby and D. Roth.
2003.
Kernel Methods for Rela-tional Learning.
In Proceedings of ICML 2003, Washing-ton, DC, USA.J.
Furnkranz, T. Mitchell, and E. Rilof.
1998.
A case studyin using linguistic phrases for text categorization on thewww.
In Working Notes of the AAAI/ICML, Workshop onLearning for Text Categorization.D.
Giampiccolo, B. Magnini, I. Dagan, and B. Dolan.
2007.The third pascal recognizing textual entailment challenge.In Proceedings of the ACL-PASCAL Workshop, Prague.A.-M. Giuglea and A. Moschitti.
2006.
Semantic role label-ing via framenet, verbnet and propbank.
In Proceedingsof ACL 2006, Sydney, Australia.A.
Hickl, J. Williams, J. Bensley, K. Roberts, Y. Shi, andB.
Rink.
2006.
Question answering with lccs chaucer attrec 2006.
In Proceedings of TREC?06.E.
Hovy, U. Hermjakob, C.-Y.
Lin, and D. Ravichandran.2002.
Using knowledge to facilitate factoid answer pin-pointing.
In Proceedings of Coling, Morristown, NJ,USA.R.
Jackendoff.
1990.
Semantic Structures.
MIT Press.T.
Joachims.
1999.
Making large-scale SVM learning prac-tical.
In B. Scho?lkopf, C. Burges, and A. Smola, editors,Advances in Kernel Methods.C.
R. Johnson and C. J. Fillmore.
2000.
The framenet tagsetfor frame-semantic and syntactic coding of predicate-argument structures.
In ANLP-NAACL?00, pages 56?62.J.
Kazama and K. Torisawa.
2005.
Speeding up Train-ing with Tree Kernels for Node Relation Labeling.
InProceedings of EMNLP 2005, pages 137?144, Toronto,Canada.P.
Kingsbury and M. Palmer.
2002.
From Treebank to Prop-Bank.
In LREC?02.T.
Kudo and Y. Matsumoto.
2003.
Fast Methods for Kernel-Based Text Analysis.
In Erhard Hinrichs and Dan Roth,editors, Proceedings of ACL.T.
Kudo, J. Suzuki, and H .Isozaki.
2005.
Boosting-basedparse reranking with subtree features.
In Proceedings ofACL?05, US.D.
D. Lewis.
1992.
An evaluation of phrasal and clusteredrepresentations on a text categorization task.
In Proceed-ings of SIGIR-92.X.
Li and D. Roth.
2005.
Learning question classifiers: therole of semantic information.
JNLE.J.
Lin and B. Katz.
2003.
Question answering from the webusing knowledge annotation and knowledge mining tech-niques.
In CIKM ?03.A.
Moschitti and R. Basili.
2004.
Complex linguistic fea-tures for text classification: A comprehensive study.
InECIR, Sunderland, UK.A.Moschitti and C. Bejan.
2004.
A semantic kernel for pred-icate argument classification.
In CoNLL-2004, Boston,MA, USA.A.
Moschitti and S. Quarteroni.
2008.
Kernels on linguisticstructures for answer extraction.
In Proceedings of ACL-08: HLT, Short Papers, Columbus, Ohio.A.
Moschitti and F. Zanzotto.
2007.
Fast and effective ker-nels for relational learning from texts.
In Zoubin Ghahra-mani, editor, Proceedings of ICML 2007.A.
Moschitti, D. Pighin, and R. Basili.
2006.
Semantic rolelabeling via tree kernel joint inference.
In Proceedings ofCoNLL-X, New York City.A.
Moschitti, S. Quarteroni, R. Basili, and S. Manandhar.2007.
Exploiting syntactic and shallow semantic kernelsfor question/answer classification.
In ACL?07, Prague,Czech Republic.A.
Moschitti.
2006.
Making Tree Kernels Practical for Nat-ural Language Learning.
In Proceedings of EACL2006.V.
Punyakanok, D. Roth, and W. Yih.
2004.
Mapping depen-dencies trees: An application to question answering.
InProceedings of AI&Math 2004.J.
Shawe-Taylor and N. Cristianini.
2004.
Kernel Methodsfor Pattern Analysis.
Cambridge University Press.D.
Shen and M. Lapata.
2007.
Using semantic roles to im-prove question answering.
In Proceedings of EMNLP-CoNLL.L.
Shen, A. Sarkar, and A. k. Joshi.
2003.
Using LTAGBased Features in Parse Reranking.
In EMNLP, Sapporo,Japan.M.
Surdeanu, M. Ciaramita, and H. Zaragoza.
2008.
Learn-ing to rank answers on large online QA collections.
InProceedings of ACL-08: HLT, Columbus, Ohio.K.
Toutanova, P. Markova, and C. Manning.
2004.
The LeafPath Projection View of Parse Trees: Exploring StringKernels for HPSG Parse Selection.
In Proceedings ofEMNLP 2004, Barcelona, Spain.V.
Vapnik.
1995.
The Nature of Statistical Learning Theory.Springer.E.
M. Voorhees.
2004.
Overview of the trec 2001 questionanswering track.
In Proceedings of the Thirteenth TextREtreival Conference (TREC 2004).F.
M. Zanzotto and A. Moschitti.
2006.
Automatic learningof textual entailments with cross-pair similarities.
In Pro-ceedings of the 21st Coling and 44th ACL, Sydney, Aus-tralia.D.
Zhang and W. Lee.
2003.
Question classification usingsupport vector machines.
In SIGIR?03, Toronto, Canada.ACM.M.
Zhang, J. Zhang, and J. Su.
2006.
Exploring SyntacticFeatures for Relation Extraction using a Convolution treekernel.
In Proceedings of NAACL, New York City, USA.584
