Content-Oriented Categorization of Document ImagesTakehiro NakayamaFX Palo A l to  Laboratory,  Inc.3400 H i l lv iew AvenuePalo Alto, CA  94304 USAnakaymrm@pal .xerox .comAbstractWe have developed a technique that catego-rizes document images based on their con-tent.
Unlike conventional methods that useoptical character recognition (OCR), we con-vert document images into word shapetokens, a shape-based representation ofwords.
Because we have only to recognizesimple graphical features from image, thisprocess is much faster than OCR.
Althoughthe mapping between word shape tokens andwords is one-to-many, they are a rich sourceof information for content characterization.Using a vector space classifier with ascanned ocument image database, we showthat the word shape token-based approach isquite adequate for content-oriented categori-zation in terms of accuracy compared withconventional OCR-based approaches.1 IntroductionThe number of documents available on the network isincreasing with the development of the computationalinfrastructure.
Accordingly, information retrieval hasbecome one of the most important research topics innatural language processing (NLP).
In the digital net-work world, documents are usually distributed ineither text file or image format, where the former is asequence of character codes (e.g., ASCII) and the lat-ter is a bitmap.
Although only text files are nmchine-readable and convenient from the viewpoint of infor-marion retrieval, many documents are available asimages alone.
They are easily generated by scanninghard-copy documents which the real world is mas-sively using.While most information retrieval systems havebeen designed for text files, there are some systemsproposed for images.
They convert images into textfiles using optical character recognition (OCR) to uti-lize existing NLP techniques.
Even though state-of-the-art OCR creates noisy output with recognitionerrors (Rice, et al, 1995), prior work has shown thatOCR output is satisfactory for retrieval purposes (Itt-her, et al, 1995; Mittendorf, et al, 1995; Myers andMulgaonkar, 1995; Wenzel and Hoch, 1995).
Theinaccuracy of OCR can be largely mitigated.
How-ever, little attention has been paid to reducing thecomputational expense of OCR.
OCR is a major bot-tleneck for information retrieval systems in terms ofspeed.
For example, Myers and Mulgaonkar reportedin their OCR-based information extraction systemthat the total processing time was dominated by char-acter and word recognition processes (Myers andMulgaonkar, 1995).
This suggests an important ques-tion: "how much NLP can be done without characterrecognition (Church, et al, 1994)?
"As an alternative technique to OCR, there is wordshape token processing which converts images into ashape-based representation.
It recognizes coarsecharacter shape classes (character shape codes) ratherthan character codes.
Because the number of charac-ter shape codes is small and they are defined by sim-ple graphical features, their recognition from imagesis inexpensive.
Word shape token processing hasbeen proven to be of use for European language iden-tification (Nakayama and Spitz, 1993; Sibun andSpitz, 1994).
Also, its feasibility for content charac-terization has been discussed with the use of con-trolled (noise-free) on-line data set (Nakayama, 1994;Nakayama 1995; Sibun and Farrar, 1994).
However,no analysis has been done with real document images,which are usually degraded in quality.
In addition, acomparative valuation between the word shapetoken-based and the OCR-based approach is needed.We have developed a technique which automati-cally categorizes document images into pre-definedclasses based on their content.
It employs a vectorspace classifier drawn from many robust statisticaltechniques in information retrieval (see Salton, 1991).We show in this paper that our technique can catego-rize as accurately as the conventional OCR-basedapproach, while it can process much faster.In the next section, we describe the definition ofcharacter shape codes and word shape tokens, andtheir generation from document images.
In section 3,we outline the automated categorization system whichwe developed.
In section 4, with the use of a topic-tagged ocument image database, we show the wordshape token-based approach is quite adequate for con-tent-oriented categorization in comparison with a con-ventional OCR-based system.
In section 5, wediscuss the experimental results and future work.8182 Character  Shape  Code and  WordShape TokenA character shape code is a machine-readable codewhich represents a set of graphically similar charac-ters.
A word shape token is a sequence of one o1"more character shape codes which represents a word.Character shape codes are defined differently by theselection of graphical features.
In this paper, we con-sider the number of connected components, verticallocation, and deep concavity as graphical features toclassify characters.
First, we identify the positions ofthe text lines as shown in figure 1.
Second, we iden-tify the character cells, and count the number of con-nected components in each character cell.
Third, wenote their position with respect to the text lines.Finally, we identify the presence of a deep eastward/southward concavity.
In figure 1, vertical locationclassifies characters into three groups--{"l"} {"g"}{"a", "n", "u", "e"}; characters that occupy the spacebetween the top and the baseline, characters thatoccupy the space between the x-height line and thebottom, and characters that occupy the space betweenthe x-height line and the baseline, respectively.
Thelast one is further classified by presence or absence ofa deep eastward/southward concavity.
Resultantgroups are {"a", "u"} {"e"} {"n"}.The defined character classes and the members forthe ASCII character set are shown in Table 1.
Onceclassification has been performed, the resulting char-acter shape codes are grouped by word boundary andused as word shape tokens for the downstream pro-cessing.
Figure 2 gives an example of generated wordshape token representation with its original documentimage.x-.eig.,,,?e TooFigure 1 : text  line parameter positions (above)and comlected components (below)'Fable 1: character shape code membershipcharacter menlbers shape codeA A-Zbdfhk l t0 -9#$&@x amorsuvwxze con 13i ig gPqYJ J' - .
:=  !l " - , .
: ;=!?
( ) /<>\ [ \ ]  { } IThere are many different languages incommonuse around the world and many different scriptsin which these languages are typeset.AAexe xxe xxng AIAAexenA Axngxxgex In exxxxnxxe xxxxnA AAe xxxAA xnA xxAg AIAAexenA xexigAxIn xAleA AAexe Axngxxgex xxe AggexeA.Figure 2: document image (above) and generatedword shape tokens (below)note: there is all error (many - xxAg) in thesecond line due to a small ink dropOur character shape code recognition doesn'trequire a complicated image analysis.
For example,distinguishing "c" from "e" is a difficult task for OCRthat requires a considerable computational expense(Ho and Baird, 1994), whereas they are in the sameclass in our representation (Table 1).
Also, our pro-cess is free from font identification which is manda-tory for OCR (for font identification complexity, seeZramdini and Ingold, 1993).
As a result, the processof word shape token generation from images is muchfaster than current OCR technology.While we save a computational expense, we losesome information which original document imageshave.
Table 1 shows that the mapping between char-acter shape codes and original characte~ is one-to-many--we use only seven character shape codes {A xe n i g j }1 to represent all alphabetical characters.1.
We use boldface to represent the charactershape codes.819This would seem to be very ambiguous.
However,when used for mapping between word shape tokensand original words, the ambiguity is much reduced.We show this using a lexicon of 122,545 distinct word(surface-form) entries.
When we transformed the lex-icon into word shape token representation, the numberof distinct entries was reduced to 89,065.
This meansone word shape token mapped to 1.38 words on aver-age.
Next, we extracted nouns, which are importantcontent-representing words for information retrieval,from the lexicon.
We were then left with 75,043 dis-tinct word entries.
Similarly, we obtained 57,049 dis-tinct word shape tokens from them.
This time, oneword shape token mapped to 1.32 words.
Moreimportantly, most of them--49,953 of 57,049 wordshape tokens (87.6%)--mapped to a single word.of topic-tagged document images.
The system usesthe cosine measure to compute the similarity:tE (WikWjk)sim(D i'D ")l = k = 12 Wik 2.1 1The greater the value of sim(Di, Dj), the more thesimilarity between Di and Dj.
For each prepared cate-gory profile, the system computes the similarity toassign the test document to the most similar cate-gory 1 .3 Categorization SystemWe implemented a content-oriented categorizationsystem to evaluate the word shape token-basedapproach in comparison with the OCR-basedapproach.
The system, which uses the vector spaceclassifier, consists of three main processes as shownin figure 3.First, the system transforms the test documentimage into a sequence of word shape tokens asdescribed in the previous ection, where conventionalsystems perform OCR to generate a sequence ofASCII encoded words.Next, it generates a document profile through thefollowing stages:Stage 1.
The system removes punctuation marks.Note that they are distinguishable from alphabeti-cal characters in the character shape code repre-sentation (Table 1).Stage 2.
The system removes word shape tokenscorresponding to stop-words.
In this process, itmay also remove some non stop-words becauseof the one-to-many mapping between word shapetokens and words.
In the OCR-based approach, itremoves top-words.Stage3.
The system computes frequencies ofword shape tokens to generate a document pro-file.
The document profile D i is represented asavector of numeric weights,De =(Wil, Wi2 ..... Wik ..... wit ) ,where Wik isthe weight given the kth word shape token in theith document, and t is the number of distinct wordshape tokens of the ith document.
We use the rel-ative frequency between 0 and 1 as the weight.As for the OCR-based approach, read word shapetoken as word.Finally, the system measures the degree of similar-ity between the document profile and a category pro-file.
The category profile Dj is also represented asavector derived in the same manner from a collection~\ [ \ [ \ ]  test document.
.
.
.
t~ .
.
.
.
I, image (bitmap)hard-copy scannerdocument (word shape token hk,,generafion \] OCR/ /word shape tokens /ASCII encoded wordscategory profiles(training data)< profile generation.
)( z~imilarity ~ ~ document profilek,,measurement J Jcategory assignmentFigure 3: categorization process4 Performance AssessmentWe have constructed a document image database tocompare our categorization approach with the con-ventional OCR-based approach.
First, we carefullychose ten topic categories with strong boundaries.
Ingeneral, the accuracy of an automated categorizationsystem is evaluated by contrast with the expert judge-ments.
However, experts don't always agree on thejudgements.
For an unbiased comparative xperi-ments between the two approaches, we chose rela-tively specific topics.
Resultant topic categories areaffirmative action, Internet, stock market, local traffic,1.
In this paper, documents are alwaysassigned to a single category.820Presidential race, Athletics (MLB), Giants (MLB),PGA golf, Tokyo subway attack, and food recipe.Second, we manually collected the body potion of 50newswire articles for each category; 500 documentsin total.
They were clearly relevant to a single cate-gory and much less relevant o the other categories.Third, we printed them using a 300-dpi laser printer,and made nth generation photo-copies from them todegrade images by quality.
In the photo-copy pro-cess, documents were degraded ue to spreadingtoner, low print contrast, paper placement angle,paper flaws, and so on.
Finally, we scanned the hard-copy documents of the first, the third, and the fifthgeneration with a 300-dpi scanner.
As a result, weobtained 500 topic-tagged document images for eachnth generation photo-copies (n = 1, 3, 5).
Figure 4shows scanned image samples.
The average size ofthe original documents was 647, and ranged from 63to 2,860 words.
The standard eviation was 377.n=lThere are many different languages incommon tn=3\[ There are many different languages in common \[n=5I-There are many different languages in commonFigure 4: scanned image samples from nthgeneration photo-copyWe transformed the document images into wordshape tokens and ASCII encoded words, where werandomly took 30 inlages for each category (300 intotal) as training data to generate category profiles,and tested the remaining 20 images (200 in total).We used ScanWorX OCR (Xerox hnaging Systems) 1for the ASCII encoding.
'Fable 2 shows the processing thne for the u'ansfor-marion of all images on a SPARCstation 10 (SunMicrosystems).
Although it had not been optimized,word shape token generation was 8 to 52 times fasterthan OCR.
The difference increased with progressionof n (n = 1, 3, 5).
The OCR speed was highly depen-dent on image quality.
Also, its word recognitionaccuracy was affected by image quality--96.3%,92.8%, and 80.7% for the first, the third, and the fifthgeneration copies, respectively.
It is well understoodthat OCR is slower and generates numerous elxors forlower quality images (Taghva, et al, 1994).
O11 the1.
This is one of the state-of-the-art OCRs interms of speed and accuracy, see Rice, etal., 1995.other hand, word shape token generation was a littlefaster for lower quality images.
This mffavorableresult was mainly caused by the lack of character seg-mentation function.
Some characters touched eachother in lower quality images, and were treated as asingle character in the process of word shape tokengeneration.
Consequently, the number of charactersto process became small.
'Fable 2: processing time (second) Ior word shapetoken (WST) generation and OCRWSTOCRimage quality (nth generation photo-copies)n=l1860n=31814n=5170215408 32322 87986Our system categorized the test documents in wordshape token and ASCII format as described in the pre-vious section.
As shown in Table 3, the accuracy ofthe word shape token-based approach for higher qual-ity images (n = 1, 3) was nearly equal to that of theOCR-based approach.
For lower quality images (n =5), the former was significantly lower than the latter.Table 4 and 5 show the accuracy of the twoapproaches a  a function of the size of test documents.When images were in higher quality (n = 1, 3), therewas little correlation between the accuracy and thesize.
When they were in lower quality (n = 5), theOCR-based approach had stronger correlationbetween the accuracy and the size than the wordshape token-based approach.
This can be explainedas follows: In the statistical categorization, it is gener-ally difficult o get good accuracy when the size of thetest document is small.
In the OCR-based approachwith the first and the third generation copies (n = 1, 3),the test documents were large enough for this catego-rization task.
When the OCR encountered the fifthgeneration copies (n = 5), it garbled ninny words.Most of them were transformed into ill-formed(unl~lown) words 2 rather than mistaken for otherwords.
These ill-formed words were ignored in oursinfilarity measurement.
Thus, they didn't act as anegative factor, but virtually made the size of the testdocument smaller.
On the other hand, in the wordshape token-based approach with the first and thethird generation copies (n = 1, 3), the test documentswere similarly large enough.
When it encountered thefifth generation copies (n = 5), it also garbled manywords.
But, this time, they were mistaken for otherword shape tokens (e.g., many - xxAg in Fig.
2), andacted as a negative factor to reduce the accuracy.2.
ScanWorX outputs aword with a rejectmark when it is unable to recognize or isunsure in recognition (e.g., meterii~g).821Table 3: categorization accuracy for the wordshape token-based and the OCR-basedapproach (number of correctly assigneddocuments / number of test documents)WSTOCRimage quality (nth generation photo-copies)n=l  n=3 n=5193/200 192/200 154/200(97%) (96%) (77%)196/200 196/200 189/200(98%) (98%) (95%)Table 4: accuracy of the word shape token-basedcategorization as a function of the size of testdocnmeutssize of test documents (number of words)0 - 400 400 - 800 800 -n = 1 50/51 (98%) 84/86 (98%) 59/63 (94%)n = 3 51/51(100%) 81/86 (94%) 60/63 (95%)n = 5 39/51 (76%) 62/86 (72%) 53/63 (84%)Table 5: accuracy of the OCR-basedcategorization as a function of the size of testdocnments0 - 400 400 - 800 800 -n = 1 50/51 (98%) 85/86 (99%) 61/63 (97%)n = 3 50/51 (98%) 85/86 (99%) 61/63 (97%)n = 5 44/51 (86%) 84/86 (98%) 61/63 (97%)5 D iscuss ionFrom the experimental results in the previous ection,our hypothesis that word shape token-based approachis quite adequate for content-oriented categorizationwas strongly supported at least for the documentimages from first and third generation photo-copies.This means that the mapping ambiguity between wordshape tokens and original words was acceptable forthe categorization purpose.
The accuracy dropobserved with the fifth generation photo-copies wasnot due to the mapping ambiguity but was caused byrecognition errors.
Unlike OCR which attempts tocorrectly recognize ach word using lexical informa-tion, word shape token generation is only faithful tothe original image, Thus, it makes many errors withlow quality images, whereas OCR indicates illegiblecharacters.
Indicating diffidence is better than incor-rect recognition for categorization.
It would be possi-ble to utilize lexical information in word shape tokenrepresentation for reducing errors.
However, we mustpay attention to its computational expense.Although it is arguable whether word stemmingalgorithms contribute to improving the categorizationaccuracy (Riloff, 1995), we desire to develop an algo-rithm for word shape token representation.
It wouldbe of use for other information retrieval applicationssuch as word-spotting.
We feel the word shape tokenrepresentation is sufficient for locating some suffixeswith accuracy.
For example, 1,651 words were withsuffix "-tion" in the lexicon of 122,545 distinct wordentries.
We obtained a set of word shape tokens fromthem.
The set mapped to only 25 words without thesuffix 1.
Similarly, word shape tokens from all 8,077words with suffix "-ing" mapped to only 20 wordswithout he suffix 2.Because all capital etters map to A (Table 1), it isdifficult to identify words with only capital letters,which are sometimes important content-representingwords (e.g., acronyms).
We need to find a graphicalfeature to distinguish some capital etters from others,considering the complexity of image analysis.When we extend the word shape token processingto other applications, it is important to note that theword shape token representation is only meaningfulfor the computer and hardly human-friendly.
Thus, itshould be used in unsupervised systems with nohuman interaction required.
Our technique would beuseful for an automated incoming fax sorting by thecontent.
Also, it would be used as an automated dic-tionary selector for the OCR which uses domain-spe-cific dictionaries.6 Conc lus ionSeveral studies have suggested that OCR output issatisfactory for information retrieval in terms of accu-racy.
However, OCR is a major bottleneck for infor-mation retrieval systems in terms of speed.We have described a technique to generate wordshape tokens from document images, and have shownthat this shape-based representation can be generatedmuch faster than current OCR technology.
Further,we have shown how word shape token processing canbe applied to content-oriented categorization.
In spiteof the mapping ambiguity between word shape tokensand words, we have shown that the word shape token-based approach can categorize document images ingood quality with nearly the same accuracy as theconventional OCR-based approach.
When images are1.
e.g., AxxAixn-fashion, exxeAixn-comedian2.
e.g., AexAing-destiny, Aing-tiny822in poor quality, the accuracy drops significantly due tomisrecognition of word shape tokens as opposed toOCR which indicates illegible charactel~ rather thanmaking errors.AcknowledgmentsWe would like to thank Dan Kuokka for his com-ments, Ron Maim for his progranmfing assistance,and Arlene Holloway for her constxucting our docu-ment image database.ReferencesKemleth W. Church, William A. Gale, Jonathan I.Helfman, and David D. Lewis.
1994.
Fax: analternative to SGML.
In Proceedings oJ the 15thbtternational Cot!ference on Computational Lin-guistics, pages 525-529, Kyoto, Japan.Tin Kam Ho and Henry Baird.
1994.
Asymptoticaccuracy of two-class discrimination.
In t'roceedings of the Third Annual Symposium on Document Analysis attd Information Retrieval, pages275-288, Las Vegas, Nevada.David J. IttneL David D. Lewis, and David D. Ahn.1995 Text categorization f low quality images.In Proceedings ~ the Fourth Annual Synq~osiumon Document Analysis and hzformationRetrieval, pages 301-315, Las Vegas, Nevada.Elke Mittendorf, Peter Schauble, and Paraic Sheridan.1995.
Applying probabilistic term weighting toOCR text in the case of a large alphabetic librarycatalogue.
In Proceedings of the 18th Annuallnternatiot~al ACM SIGIR Cot(\[~'rence onResearch and Development in h!formationRetrieval, pages 328-335, Seattle, Washington.Gregory K. Myers and Prasanna G. Mulgaonkar.1995.
Automatic extraction of information fromprinted ocuments.
In Proceedings ~?
'the FourthAnnual Symposium on Document Analysis andlnforntation Retrieval, pages 81-88, Las Vegas,Nevada.Takehiro Nakayama nd A. Lawrence Spitz.
1993.European language detemfination from image InProceedings ~( the Second International Cot!fer-ettce on Document Analysis and Recognition,pages 159-162, Tsukuba Science City, Japan.Takehiro Nakayama.
1994.
Modeling content idenfi-fication from document images.
In Proceedingsof the Fourth ACL Cot~'erence (mApplied Natural Language Processing, pages 22-27, Stuttgart,Germany.Takehiro Nakayama.
1995.
Text categorization usingword shape tokens, In Proceedings of the SecondConference of the Pacijic Association for Co,qmrational Linguistics, pages 207-217, Brisbane,Australia,.Stephen V. Rice, Frank R. Jenkins, and Thomas A.Nartker.
1995.
The tburth mmual test of OCRaccuracy, lnfiv'mation Science Research Institute1993 Atmual Research Report, University ofNevada, Las ?
'gas, pages 11-50.Ellen Riloff.
1995.
Little words can make a big dif-ference for text classification, In Proceedings ofthe 18th Annual Imernational ACM SIGIR Confemnce on Research attd Development in lnformation Retrieval, pages 130-136, Seattle,Washington.Gerard Salton.
1991.
Developments in automatic textretfeval, Science, Vol.
253, pages 974-980.Penelope Sibun and David.
S. Farrar.
1994.
Contentcharacterization using word shape tokens, In Pro-ceedings of the 15th International Cot~'erettce onComputational Linguistics.
pages 686-690,Kyoto, Japan.Penelope Sibun and A. Lawrence Spitz.
1994.
Lan-guage determination: natural language processingfrom scmmed ocument images.
In Proceedingsof the Fourth ACL Cot!\[~,rence on Applied Natural Language Processing, pages 15-21, Stuttgart,Germany.Kazem Taghva, Julie Borsack, Allen Condit, andSrinivas Erva.
1994.
The effects of noisy data ontext retrieval.
,hmrnal of the American Socie(vfly" lt~'ormation Science.
45, pages 50-58.Claudia Wenzel and Rainer Hoch.
1995.
Text catego-rization of scanned ocmnents applying a rule-based approach.
In Proceedings ~" the FourthAnnual 3~,q~osium r  Document Analysis andh~&mation Retrieval, pages 333-346, Las Vegas,Nevada.Abdelwahab Zramdini and Rolf Ingold.
1993.
Opti-cal font recognition fl'om projection profiles.Electronic Publishing, Vol.
6(3), pages 249-260.823
