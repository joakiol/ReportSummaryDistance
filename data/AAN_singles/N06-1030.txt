Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 232?239,New York, June 2006. c?2006 Association for Computational LinguisticsLearning Pronunciation DictionariesLanguage Complexity and Word Selection StrategiesJohn Kominek Alan W BlackLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{jkominek,awb}@cs.cmu.eduAbstractThe  speed  with  which  pronunciation  dictio-naries can be bootstrapped depends on the ef-ficiency of learning algorithms and on the or-dering of words presented to the user.
This pa-per presents an active-learning word selectionstrategy that is mindful of human limitations.Learning rates approach that of an oracle sys-tem that knows the final LTS rule set.1 IntroductionThe  construction  of  speech-to-speech  translationsystems is difficult, complex, and prohibitively ex-pensive for all but handful of major languages.
De-veloping  systems  for  new  languages  is  a  highlyskilled job requiring considerable effort, as is theprocess of training people to acquire the necessarytechnical knowledge.Ideally, a native speaker of a (minor) language ?with the right tools ?
should be able to develop aspeech  system with  little  or  no technical  knowl-edge  of  speech  recognition,  machine  translation,dialog management, or speech synthesis.
Rapid de-velopment of machine translation, for example, isthe goal  of  (Lavie  et  al.,  2003).
Similarly,  com-bined  development  of  speech  recognition  andspeech synthesis is the stated goal of (Engelbrechtand Schultz, 2005).Here  we  concentrate  on  lexicon  creation  forsynthesis and recognition tasks, with the affiliatedproblem  of  letter-to-sound  rule  inference.
Twocentral  questions of dictionary  building are: whatletter-to-sound rule representation lends itself wellto incremental learning?
?
and which words shouldbe presented to the user,  in what order?In this paper we investigate various approachesto the word ordering problem, including an activelearning algorithm.
An ?active learner?
is a classof machine learning algorithms that choose the or-der  in  which  it  is  exposed  to  training  examples(Auer,  2000).
This is valuable when there isn't apre-existing set of training data and when the costof  acquiring such data is high.
When humans areadding dictionary entries the time and accuracy de-pends on the selected word (short words are easierthan long; familiar are easier than unfamiliar), andon how quickly the learner's error rate drops (longwords  are  more  informative  than  short).
Also,mindful  that  no  answer  key  exists  for  new lan-guages ?
and that humans easily become impatient?
we would like to know when a language's letterto sound rule system is, say, 90% complete.
Thisturns out to be surprising elusive to pin down.The next section outlines our working assump-tions and issues we seek to address.
Section 3 de-scribes our LTS learning framework, an elabora-tion  of (Davel and Barnard,  2003).
The learningbehavior on multiple test languages is documentedin Section 4, followed in Section 5 by a compari-son of several word selection strategies.2 Assumptions and IssuesIn  designing  language  technology  developmenttools we find it helpful to envision our target user,whom may  be  characterized  as  ?non-technical.
?Such a person speaks, reads, and writes the targetlanguage, is able to enumerate the character set ofthat  language,  distinguish  punctuation  fromwhitespace,  numerals,  and  regular  letters  orgraphemes,  and  specify  if  the  language  distin-guishes upper and lower casing.
When presented232with the pronunciation of a word (as a synthesizedwavefile),  the user can say whether it  is  right orwrong.
In addition, such a person has basic com-puter fluency, can record sound files, and can navi-gate the  HTML interface of our software tools.
Ifthese latter requirements present a barrier then weassume the  availability of a field agent to config-ure the computer, familiarize the user, plus trans-late the English instructions, if necessary.Ideally, our  target  user  need not  have explicitknowledge of their  own language's phoneme set,nor even be aware that a word can be transcribedas a sequence of phonemes (differently from let-ters).
The ability to reliably discover a workablephoneme set from an unlabeled corpus of speechis not yet at hand, however.
Instead we elicit a lan-guage's phoneme set during an initialization stageby presenting examples  of  IPA wavefiles  (Wellsand House, 1995).Currently, pronunciations are spelled out usinga romanized phonetic alphabet.
Following the rec-ommendation of (Davel and Barnard, 2005) a can-didate pronunciation is accompanied with a wave-file generated from a phoneme-concatenation syn-thesizer.
Where possible, more than one pronunci-ation is generated for each word presented, underthat assumption that it is easier for a listener to se-lect from among a small  number of choices thancorrect a wrong prediction.2.1 Four Questions to Address1.
What  is  our  measure  of  success?
Ultimately,the time to build a lexicon of a certain coverageand correctness.
As a proxy for time we use thenumber of characters presented.
(Not words, asis typically the case, since long words containmore information than short, and yet are harderfor a human to verify.)2.
For  a  given  language,  how many words  (let-ters) are needed to learn its LTS rule system?The true,  yet not too useful  answer  is  ?it  de-pends.?
The  complexity  of  the  relation  be-tween  graphemic  representation  and  acousticrealization varies greatly across languages.
Thatbeing the case, we seek a useful measure of alanguage's degree of  complexity.3.
Can the asymptote  of the LTS system be esti-mated,  so  that  one  can  determine  when  thelearned rules are 90 or 95% complete?
In Sec-tion 4 we present evidence that this may not bepossible.
The  fall-back position  is  percentagecoverage of the supplied corpus.4.
Which words should be presented to the user,and  in  what  order?
Each  additional  wordshould maximize the marginal information gainto the system.
However, short words are easierfor humans to contend with than long.
Thus alength-based weighting needs to be considered.3 LTS Algorithm BasicsA wide variety of approaches have been applied tothe problem of letter-to-sound rule induction.
Dueto simplicity of representation and ease of manipu-lation, our LTS rule learner follows the Default &Refine  algorithm  of  Davel  (Davel  and  Barnard,2004).
In this framework, each letter  c is assigneda default production p1-p2... denoting the sequenceof zero or  more phonemes most  often associatedwith that letter.
Any exceptions to a letter's defaultrule is explained in terms of the surrounding con-text  of  letters.
The  default  rules  have  a  contextwidth of one (the letter itself), while each addition-al letter increases the width of the context window.For example, if we are considering the first occur-rence of  's'  in  the  word  basics, the  context  win-dows are as listed in Table 1.
By convention, theunderscore  character  denotes  the  predicted  posi-tion, while the hash represents word termination.width context sets ordered by increasing width1 {_}2 {a_ , _i}3 {ba_ , a_i , _ic}4 (#ba_ , ba_i , a_ic , _ics}5 {#ba_i , ba_ic , a_ics , _ics#}6 {#ba_ic , ba_ics , a_ics#}7 {#ba_ics , ba_ics#}8 {#ba_ics#}Table 1.
Letter contexts for the first 's' in basics.In this position there are 20 possible explanatorycontexts.
The order in which they are visited de-fines an algorithm's search strategy.
In the class ofalgorithms knows as ?dynamically expanding con-text (DEC)?, contexts are considered top-down asdepicted in Table 1.
Within one row, some algo-rithms follow a fixed order (e.g.
center, left, right).Another variant tallies the instances of productions233associated  with  a  candidate  context  and  choosesthe  one  with  the  largest  count.
For  example,  inSpanish the letter 'c' may generate K (65%), or THwhen followed by e or i (32%), or CH when fol-lowed by h (3%).
These are organized by frequen-cy into a ?rule chain.
?Rule rank RHS Context Frequency1 K _ 65.1%2 TH _i 23.6%3 TH _e 8.5%4 CH _h 2.8%If desired,  rules  2 and 3 in  this  example  can becondensed into 'c' ?
TH /_{i,e}, but in general areleft separated for sake of simplicity.In our variant, before adding a new rule all pos-sible contexts  of all  lengths are considered whenselecting the best one.
Thus the rule chains do notobey a strict order of expanding windows, thoughshorter  contexts generally  precede longer ones inthe rule chains.One  limitation  of  our  representation is  that  itdoes not support gaps in the letter context.
Consid-er  the  word  pairs  tom/tome,  top/tope,  tot/tote.
ACART tree can represent this pattern with the rule:if (c-1 = 't' and c0='o' and c2='e') then ph=OW.
In prac-tice, the inability to skip letters is not a handicap.3.1 Multiple Pronunciation PredictionsGiven a word, finding the predicted pronunciationis easy.
Rule chains are indexed by the letter to bepredicted, and possible contexts are scanned start-ing from the most specific until a match is found.Continuing  our  example,  the  first  letter  in  theSpanish word ciento fails rule 4, fails rule 3, thenmatches rule 2 to yield TH.
For additional pronun-ciations the search continues until another match isfound: here, the default rule 'c' ?
K /_.
This proce-dure  is  akin  to  predicting  from  progressivelysmoother models.
In a complex language such asEnglish,  a  ten  letter  word  can  readily  generatedozens  of  alternate  pronunciations,  necessitatingan ordering policy to keep the total manageable.4 Language CharacterizationEnglish is notorious for having a highly irregularspelling  system.
Conversely,  Spanish  is  admiredfor its simplicity.
Most others lie somewhere in be-tween.
To estimate  how many words  need to  beseen in order  to acquire 90% coverage of a lan-guage's LTS rules, it helps to have a quantitativemeasure.
In  this  section  we  offer  a  perplexity-based measure of LTS regularity and present mea-surements of several  languages with varying cor-pus  size.
These  measurements  establish,  surpris-ingly,  that  a  rule  system's  perplexity  increaseswithout bound as the number of training words in-creases.
This  holds  true  whether  the  language issimple  or  complex.
In  response,  we  resort  to  aheuristic  measure  for  positioning languages  on ascale of relative difficulty.4.1 A Test Suite of Seven LanguagesOur test suite consists of pronunciation dictionar-ies from seven languages, with English consideredunder two manifestations.English.
Version  0.6d of  CMU-DICT,  consid-ered without stress (39 phones) and with two levelstress marking (58 phones).
German.
The Celexdictionary of 321k entries (Burnage, 1990).
Dutch.The  Fonilex  dictionary  of  218k entries  (Mertensand  Vercammen,  1998).
Fonilex  defines  an  ab-stract  phonological  level  from which  specific di-alects  are specified.
We tested on the ?standard?dialect.
Afrikaans.
A 37k dictionary developed lo-cally.
Afrikaans is a language of South Africa andis  a  recent  derivative  of  Dutch.
Italian.
A 410kdictionary  distributed  as  part  of  a  free  Festival-based  Italian  synthesizer  (Cosi,  2000).
Spanish.Generated by applying a set of hand written rulesto a 52k lexicon.
The LTS rules are a part of thestandard Festival Spanish distribution.
Telugu.
An8k locally  developed dictionary.
In its  native or-thography, this language of India possess a highlyregular  syllabic  writing system.
We've adopted  aversion  of  the  Itrans-3  transliteration  scheme(Kishore 2003) in which sequences of two to fourEnglish letters map onto Telugu phonemes.4.2 Perplexity as a Measure of DifficultyA useful  way of considering letter  to sound pro-duction is as a Markov process in which the gener-ator passes through a sequence of  states (letters),each  probabilistically  emitting  observation  sym-bols  (phonemes)  before  transitioning  to  the  nextstate  (following letter).
For a letter  c,  the unpre-dictability  of  phoneme  emission  is  its  entropyH ?c?=??
?
pi log pi?
or equivalently its perplexityP ?c?=eH ?c?
.
The perplexity can be interpreted as234the average number of  output  symbols  generatedby a letter.
The production perplexity of the char-acter set is the sum of each individual letter's per-plexity weighted by its unigram probability pc.
(1)Continuing with our Spanish example, the letter 'c'emits the observation symbols (K, TH, CH) with aprobability distribution of (.651, .321, .028), for aperplexity  of  2.105.
This  computation applieswhen each letter is assigned a single probabilisticstate.
The process of LTS rule discovery effective-ly splits the state 'c' into four context-defined sub-states:  (-,c,-),  (-,c,i),  (-,c,e),  (-,c,h).
Each of thesestates emits only a single symbol.
Rule addition istherefore an entropy reduction process;  when therule set is complete the letter-to-sound system hasa perplexity of 1, i.e.
it is perfectly predictable.The ?price paid?
for perfect  predictability is acomplex set of rule chains.
To measure rule com-plexity we again associate a single state with eachletter.
But, instead of phonemes, the  rules  are theemission  symbols.
Thus  the  letter  'c'  emits  thesymbols (K/_, TH/_i, TH/_e, CH/_h) with a distri-bution of (.651, .236, .085, .028), for a perplexityof 2.534.
Applying equation (1) to the full set ofrules defines the LTS system's average perplexity.4.3 Empirical MeasurementsIn  the  Default  & Refine  representation,  the  rulechain for each letter is is initialized with its mostprobably  production.
Additional  context-depen-dent rules are appended to cover additional letterproductions, with the rule offering the greatest in-cremental  coverage  being  added  first.
(Ties  arebroken in an implementation-dependent way.
)Figure 1 uses Spanish to illustrate a characteris-tic  pattern:  the  increase  in  coverage as  rules  areadded one at  a time.
Since the figure of merit  isletter-based, the upper curve (% letters correct) in-creases monotonically, while the middle curve (%words correct) can plateau or decrease briefly.In the lower curve of Figure 1 the growth proce-dure is constrained such that all width 1 rules areadded before width 2 rules, which in turn must beexhausted  before  width  3  rules  are  considered.This  constraint  leads  to  its  distinctive  scallopedshape.
The upper limit of the W=1 region showsthe performance of the unaided default rules (68%words correct).Figure 1.
Coverage of Spanish (52k corpus) as afunction of rule size.
For the lower curve, W indi-cates the rule context window width.
The middle(blue) curve tracks near-optimal performance im-provement with the introduction of new rules.For more complex languages the majority of ruleshave a context width in the range of 3 to 6.
This isseen in Figure 2 for English, Dutch, Afrikaans, andItalian.
However, a larger rule set does not meanthat the average context width is greater.
In Table2, below, compare Italian to Dutch.Language Number of Rules Average WidthEnglish 40k  19231 5.06Dutch 40k  10071 4.35Afrikaans 37k  5993 4.66Italian 40k  3385 4.78Spanish 52k  76 1.66Table 2.
Number of LTS rules for five languageand their average context width.Figure  2.
Distribution  of  LTS  rules  by  contextwindow width for four languages: English, Dutch,Afrikaans, and Italian.Perave=?cpc e?
?ipi log piWindow Width2 4 6 8 10NumberofRules0100020003000400050006000 LTS Rule Count vs Window WidthLegendEnglish 40kDutch 40kAfrikaans 37kItalian 40kLegendChars CorrectWords CorrectWords CorrectNumber of Rules0 10 20 30 40 50 60PercentCorrect020406080100 Spanish LTS Ruleset PerformanceW=3W=2W=1235Beyond a window width of 7, rule growth tapersoff  considerably.
In  this  region  most  new  rulesserve  to  identify  particular  words  of  irregularspelling, as it is uncommon for long rules to gener-alize beyond a single instance.
Thus when traininga  smoothed  LTS rule  system it  is  fair  to  ignorecontexts larger than 7, as is done for example inthe Festival synthesis system (Black, 1998).Figure 2 contrasts four languages with trainingdata of around 40k words, but says nothing of howrule sets grow as the corpus size increases.
Figure3 summarizes measurements taken on eight encod-ings of seven languages (English twice, with andwithout stress marking), tested from a range of 100words  to  over  100,000.
Words  were  subsampledfrom each alphabetized lexicon at equal spacings.The results are interesting, and for us, unexpected.Figure 3.
Rule system growth as the corpus size isincreased,  for  seven languages.
From top to bot-tom:  English  (twice),  Dutch,  German,  Afrikaans,Italian, Telugu, Spanish.
The Telugu lexicon usesan Itrans-3 encoding into roman characters, not thenative  script,  which  is  a  nearly  perfect  syllabictranscription.
The context window has a maximumwidth of 9 in these experiments.Within  this  experimental  range  none  of  the  lan-guages  reach  an  asymptotic  limit,  though  somehint  at  slowed  growth  near  the  upper  end.
Astraight line on a log-log graph is characteristic ofgeometric growth, to which a power law functiony=axb+c is an appropriate parametric fit.
For diffi-cult  languages the growth rates  (power  exponentb) vary between 0.5 and 0.9, as summarized in Ta-ble 3.
The language with the fastest growth is En-glish, followed, not by Dutch, but Italian.
Italian isnonetheless the simpler of these two, as indicatedby the smaller multiplicative factor a.Language a bEnglish (stressed) 2.97 0.88English (plain)  3.27 0.85Dutch  12.6 0.64German  39.86 0.49Afrikaans  15.34 0.57Italian  2.16 0.69Table 3.
Parameters a and b for the power law fity=axb+c to the growth of LTS system size.It would be good if a tight ceiling could be estimat-ed from partial data in order to know (and report tothe lexicon builder) that  with  n rules defined thesystem is m percent complete.
However, this trendof  geometric  growth  suggests  that  asking  ?howmany letter-to-sound rules does a given  languagehave??
is an ill-posed question.In light of this, two questions are worth asking.First, is the geometric trend particular to our rulerepresentation?
And  second,  is  ?total  number  ofrules?
the  right  measure  of  LTS complexity?
Toanswer the first  question we repeated the experi-ments with the  CART tree builder available fromthe Festival  speech  synthesis  toolkit.
As it  turnsout  ?
see  Table  4  ?
a  comparison  of  contextualrules and node counts for Italian  demonstrate thata CART tree representation also exhibits geometricgrowth with respect to lexicon size.Num Wordsin LexiconContextualLTS RulesCART TreeNodes100 80 145250 131 272500 198 3991000 283 6012500 506 11695000 821 188810,000 1306 284020,000 2109 464240,000 3385 758280,000 5524 13206Table 4.
A comparison of rule system growth forItalian as the corpus size is increased.
CART treenodes (i.e.
questions) are the element comparableto LTS rules used in letter context chains.
The fit-ted parameters to the  CART data are  a=2.29 andb=0.765.
This compares to  a=2.16 and b=0.69.Num Words in Lexicon100 1000 10000 100000NumLTSRules100100010000LTS Rules vs. Lexicon SizeLegendEnglish (w/stress)English (no stress)DutchGermanAfrikaansItalianTelugu (itrans-3)Spanish236If geometric growth and lack of an obvious asymp-tote  is  not  particular  to  expanding  context  rulechains,  then  what  of  the  measure?
The  measureproposed in Section 4.2 is average chain perplexi-ty.
The hypothesis is that a system close to satura-tion will still add new rules, but that the averageperplexity levels off.
Instead, the data shows littlesign of saturation (Figure 4).
In contrast, the aver-age  perplexity  of  the  letter-to-phoneme  distribu-tions remains level with corpus size (Figure 5).Figure 4.
Growth of average rule perplexity as afunction  of lexicon size.
Except  for  Spanish andTelugu,  the  average  rule  system  perplexity  notonly grows, but grows at an accelerating rate.Figure  5.
Growth  of  average  letter-to-phonemeproduction perplexity as a function of lexicon size.Considering  these  observations  we've resorted  tothe following heuristic to measure language com-plexity: a) fix the window width to 5, b) measurethe average rule perplexity at lexicon sizes of 10k,20k,  and  40k,  then  c)  take  the  average  of  thesethree  values.
Fixing  the  window  width  to  5  issomewhat arbitrary, but is intended to prevent thesystem from learning an unbounded suite of excep-tions.
Available values are contained in Table 5.Language Ave LetterPerplexityHeuristicPerplexityPerplexityRatioEnglish 3.25 50.11 15.42Dutch  2.73 16.80 6.15German  2.41 16.70 6.93Afrikaans  2.32 11.48 8.32Italian  1.38 3.52 2.55Spanish  1.16 1.21 1.04Table 5.
Perplexity measures  for  six languages.The  third  (rightmost)  column is  the  ratio  of  thesecond divided by the first.
A purely phonetic sys-tem has a heuristic perplexity of one.From these measurements we conclude, for exam-ple, that Dutch and German are equally difficult,that English is 3 times more complex than either ofthese, and that English is 40 times more complexthan Spanish.5 Word Selection StrategiesA selection strategy is  a method for choosing anordered  list  of  words  from a lexicon.
It  may bebased on an estimate of expected maximum return,or be as simple as random selection.
A good strate-gy should enable rapid learning, avoid repetition,be robust, and not overtax the human verifier.This  section  compares  competing  selectionstrategies on a single lexicon.
We've chosen a 10kItalian lexicon as a problem of intermediate diffi-culty, and focus on early stage learning.
To pro-vide a useful frame of reference, Figure 6 showsthe results of running 5000 experiments in whichthe word sequence has been chosen randomly.
Thex-axis is number of letters examined.Figure 6.
Random sampling of Italian 10k corpus.LegendEnglish (w/stress)English (no stress)DutchGermanAfrikaansItalianTeluguSpanishNum Words in Lexicon100 1000 10000 100000LTSRulePerplexity0.05.010.015.020.025.030.0 LTS Rule Perplexity vs Lexicon SizeLegendEnglish (no stress)DutchGermanAfrikaansItalianTelugu (itrans)Spanish37k4k170k1kAve Productions per Letter0 2 4 6 8 10 12Ave ProductionPerplexity0.00.51.01.52.02.53.03.54.0 Letter to Phoneme PerplexitySpanishIraqiPhonetic alphabet1k 40k80kTeluguItalianNum Letters Examined0 1000 2000 3000 4000 5000 6000Words Correct(%)1020304050607080 Word Accuracy, Random SelectionItalian, 10k dict, maxwin=5237Figure 7 compares average random performance tofour deterministic strategies.
They are:  alphabeti-cal word ordering, reverse alphabetical, alphabeti-cal sorted by word length (groups of single charac-ter  words first,  followed by two character  words,etc.
), and a greedy ngram search.
Of the first three,reverse alphabetical performs best because it intro-duces  a  greater  variety  of  ngrams  more  quicklythan the others.
Yet, all of these three are substan-tially  worse  than  random.
Notice  that  groupingwords  from short  to  long degrades  performance.This implies that strategies tuned to the needs ofhumans will incur a machine learning penalty.Figure 7.
Comparison of three simple word order-ings  to  the  average  random  curve,  as  well  asgreedy ngram search.It might be expected that selecting words contain-ing the most popular ngrams first  would out-per-forms random, but as is seen in Figure 7, greedyselection  closely  tracks  the  random  curve.
Thisleads  us to investigate  active  leaning algorithms,which we treat as variants of ngram selection.5.1 Algorithm DescriptionLet W = {w1,w2,...} be the lexicon word set, having A ={'a', 'b',...} as the alphabet of letters.
We seek an orderedlist V = (... wi ...) s.t.
score(wi) ?
score (wi+1).
V is initial-ly empty and is extended one word at a time with wb, the?best?
new word.
Let g=c1c2...cn ` A* be an ngram oflength n, and Gw={gi}, gi ` w are all the ngrams found inword w. Then GW =  5 Gw,  w  `  W, is  the set  of  allngrams in the lexicon W, and GV = 5 Gw, w ` Vis the setof all ngrams in the selected word list V. The number ofoccurrences of g in W is score(g), while score(w) =  ?score(g) st.  g  `  w and g  v GV.
The scored ngrams aresegmented  into separately sorted  lists,  forming an  or-dered list of queues Q = (q1,q2,...qN) where qn containsngram of length n and only n.Algorithmfor q in Qg = pop(q)for L = 1 to |longest word in W|Wg,L = {wi} s.t.
|wi| = L, g ` wi and wi v Vwb = argmax score(Wg,L)if score (wb) > 0 thenV = V + wbGV = GV 4 Gwbreturn wbIn this search the outer loop orders ngrams by length,while the inner loop orders words by length.
For selec-tion based on ngram coverage, the queue Q is computedonly once for the given lexicon W. In our active learner,Q is re-evaluated after each word is selected, based onthe ngrams present in the current LTS rule contexts.
LetGLTS = {gi} s.t.
gi ` some letter context in the LTS rules.Initially GLTS,0 = {}.
Then, at any iteration k, GLTS,k arethe ngrams present in the rules, and G'LTS,k+1 is an ex-panded set of candidate ngrams that constitute the ele-ments of Q. G' is formed by prepending each letter c ofA to each g in G, plus appending each c to g. That is,G'LTS,k+1 = A%GLTS,k 4 GLTS,k%A where % is the Cartesianproduct.
Executing the algorithm returns wb and yieldsGLTS,k+1 the set of ngrams covered by the expanded ruleset.
In  this  way knowledge  of  the  current  LTS  rulesguides the search for maximally informative new words.5.2 Active Learner PerformanceFigure  8  displays  the  performance  of  our  activelearner  on  the  Italian  10k corpus,  shown  as  theblue  curve.
For  the  first  500  characters  encoun-tered,  the  active  learner's  performance  is  almosteverywhere better  than average random, typicallyone half to one standard deviation above this refer-ence level.Two  other  references  are  shown.
Immediatelyabove the active learner curve is ?Oracle?
word se-lection.
The Oracle has access to the final LTS sys-tem  and  selects  words  that  maximally  increasescoverage of the known rules.
The topmost curve isfor  a  ?Perfect  Oracle.?
This  represents  an  evenmore unrealistic  situation in which each letter  ofeach  word  carries  with  it  information  about  thecorresponding production rule.
For example,  that'g' yields /F/ 10% of the time, when followed bythe letter 'h' (as in ?laugh?)
.
Carrying complete in-formation with each letter allows the  LTS systemto be constructed directly and without mistake.
Incontrast,  the  non-perfect  oracle  makes  mistakessequencing rules  in each  letter's  rule  chain.
Thisdecreases performance.Italian, 10k dict, maxwin=5Num Letters Examined0 1000 2000 3000 4000 5000 6000WordsCorrect(%)1020304050607080 Word Accuracy, Simple StrategiesLegendAverage randomn-gram coverageReverse alphabeticAlphabetic orderLength, alpha order238Figure 8.
From top to bottom: a perfect Oracle, aword selection Oracle, our active learner, and av-erage random performance.
The perfect Oracle de-marcates  (impossibly  high)  optimal  performance,while  Oracle  word  selection  suggests  near-opti-mality.
For  comparison,  standard  deviation  errorbars are added to the random curve.Encouragingly, the active learning algorithm strad-dles  the  range  in  between  average  random  (thebaseline) and Oracle word selection (near-optimal-ity).
Less favorable is the non-monotonicity of theperformance curve; for example, when the numberof  letters  examined  is  135,  and  210.
Analysisshows that these drops occur when a new letter-to-sound  production  is  encountered  but  more  thanone  context  offers  an  equally  likely  explanation.Faced  with  a  tie,  the  LTS  learner  sometimeschooses incorrectly.
Not being aware of this mis-take  it  does  not  seek  out  correcting  words.
Flatplateaus occur when  additional words (containingthe next most popular ngrams) do not contain pre-viously unseen letter-to-sound productions.6 ConclusionsWhile this work does not definitively answer thequestion of ?how may words to learn the rules,?we  have  developed  ways  of  characterizing  lan-guage  complexity,  which  can  guide  developers.We've devised a word selection  strategy that  ap-pears to perform better than the (surprisingly high)standard  set  by  randomly  selection.
Further  im-provements  are  possible  by incorporating knowl-edge of  word  alignment  and rule  sequencing  er-rors.
By  design,  our  strategy  is  biased  towardsshort words over long, thereby being ?nice?
to lex-icon developers ?
our original objective.AcknowledgmentsThis material is in part based upon work supported bythe  National  Science Foundation  under  Grant  No.0415201.
Any opinions, findings, and conclusions orrecommendations expressed in this material are thoseof the authors and do not necessarily reflect the viewsof the National Science Foundation.ReferencesPeter  Auer, 2000.
Using upper confidence bounds foronline learning.
Proceedings of the 41st Annual Sym-posium on Foundations of Computer Science, pp.Alan W Black, Kevin Lenzo, and Vincent Pagel, 1998.Issues in Building General Letter to Sound Rules.
3rdESCA Workshop on Speech Synthesis, Australia.Gavin Burnage, 1990.
CELEX ?
A Guide for Users.
Hi-jmegen: Centre for Lexical Information, University ofNijmegen.Piero Cosi,  Roberto Gretter, Fabio Tesser, 2000.
Festi-val  parla  italiano.
Proceedings of  GFS2000,  Gior-nate del Gruppo di Fonetica Sperimentale, Padova.Marelie Davel and Etienne Barnard,  2003.
Bootstrap-ping in Language Resource Generation.
Proceedingsof the 14th Symposium of the Pattern Recognition As-sociation of South Africa, pp.
97-100.Marelie Davel and Etienne Barnard,  2004.
A default-and-refine  approach  to  pronunciation  prediction,Proceedings of  the 15th  Symposium of the PatternRecognition Association of South Africa.Marelie Davel and Etienne Barnard,  2005.
Bootstrap-ping  Pronunciation  Dictionaries:  Practical  Issues.Proceedings  of  the  9th International  Conference  onSpoken Language Processing, Lisbon, Portugal.Herman Engelbrecht,  Tanja  Schultz,  2005.
Rapid  De-velopment of an Afrikaans-English Speech-to-SpeechTranslator, International Workshop on  Spoken Lan-guage Translation, Pittsburgh, PA. pp.169-176.S P Kishore and Alan W Black, 2003.
Unit Size in UnitSelection Speech Synthesis.
Proceedings of the 8th Eu-ropean Conference on Spoken Language Processing,Geneva, Switzerland.Alon Lavie, et al 2003.
Experiments with a Hindi-to-English Transfer-based MT System under a MiserlyData  Scenario,  ACM Transactions  on  Asian  Lan-guage Information Processing, 2(2).Piet Mertens and Filip Vercammen, 1998.
Fonilex Man-ual, Technical Report, K. U. Leuven CCL.John Wells  and Jill  House,  1995.
Sounds of  the IPA.http://www.phon.ucl.ac.uk/shop/soundsipa.php.Italian, 10k dict, maxwin=5LegendPerfect OracleOracle word selectionActive learnerAverge randomNum Letters Examined0 100 200 300 400 500Words Correct(%)020406080100 Word Accuracy, Active Learner239
