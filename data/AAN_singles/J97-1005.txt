Discourse Segmentation by Human andAutomated MeansRebecca J. Passonneau*Bellcore and Columbia UniversityDiane J. L i tman tAT&T Labs-ResearchThe need to model the relation between discourse structure and linguistic features of utterancesis almost universally acknowledged in the literature on discourse.
However, there is only weakconsensus on what the units of discourse structure are, or the criteria for recognizing and gener-ating them.
We present quantitative r sults of a two-part study using a corpus of spontaneous,narrative monologues.
The first part of our paper presents a method for empirically validatingmultiutterance units referred to as discourse segments.
We report highly significant results ofsegmentations performed by naive subjects, where a commonsense notion of speaker intention isthe segmentation criterion.
In the second part of our study, data abstracted from the subjects"segmentations serve as a target for evaluating two sets of algorithms that use utterance f aturesto perform segmentation.
On the first algorithm set, we evaluate and compare the correlation ofdiscourse segmentation with three types of linguistic ues (referential noun phrases, cue words,and pauses).
We then develop asecond set using two methods: error analysis and machine learn-ing.
Testing the new algorithms on a new data set shows that when multiple sources of linguisticknowledge are used concurrently, algorithm performance improves.1.
IntroductionEach utterance of a discourse contributes to the communicative import of precedingutterances, or constitutes the onset of a new unit of meaning or action that subse-quent utterances may add to.
The need to model the relation between the structure ofsuch units (referred to here as discourse segment structure) and linguistic features ofutterances I is almost universally acknowledged in the literature on discourse.
How-ever, natural language systems rarely exploit the relation between discourse segmentstructure and linguistic devices because there is very little data about how they con-strain one another.
We have been engaged in a two-part study addressing this gap.We report on a method for empirically validating discourse segments, and on ourdevelopment and evaluation of algorithms to identify these segments from linguisticfeatures of discourse.
We show that human subjects can reliably perform discoursesegmentation using speaker intention as a criterion.
We also show that when multiplesources of linguistic knowledge are used (referential noun phrases, cue words, andpauses), algorithm performance approaches human performance.The excerpt in Figure 1 illustrates the two aspects of discourse that our studyaddresses.
2 The first pertains to an abstract structure consisting of meaningful dis-course segments and their interrelations.
The utterances in segments X and Z of Fig-?
445 South Street, Morristown, NJ 07960 (E-mail: beck@bellcore.com); Department of Computer Science,New York, NY 10027 (E-mail: becky@cs.columbia.edu)600 Mountain Avenue, Murray Hill, NJ 07974 (E-mail: diane@research.att.com)1 By the term utterance we mean the spoken or written use of a sentence or other linguistic unit,2 This excerpt is taken from a corpus of spoken narratives (Chafe 1980) described below.
@ 1997 Association for Computational LinguisticsComputational Linguistics Volume 23, Number 1okay.SEGMENT X Meanwhile,there are three little boys,up on the road a little bit,and they see this little accident.And u-h they come over,and they help \ ]h im~and you know,help Ih iml  pick up the pears and everything.SEGMENT Y A-nd the one thing that struck me about the- three little boys that were there,is that one had ay uh I don't know what you call them,but it's a paddle,and a ball-,is attached to the paddle,and you know you bounce it?And that sound was really prominent.SEGMENT Z Well anyway,so- u-m tsk all the pears are picked up,and I he \]'s on his way again,Figure 1Discourse segment structure and linguistic devices.ure 1--which describe how three boys come to the aid of another boy who fell offof a bike --are more closely related to one another than to those in the interveningsegment Y--which describe the paddleball toy owned by one of the three boys.
Thesecond discourse feature of interest is that the usage of a wide range of lexicogram-matical devices seems to constrain or be constrained by this more abstract structure.Consider the interpretation of the referent of the boxed pronoun he in segment Z. Thereferent of the underlined noun phrase one in segment Y is the most recently mentionedmale referent: without the segmentation, the reasoning required to reject it in favor ofthe intended referent of he is quite complex.
However, segment Z begins with certainfeatures that indicate a resumption of the speaker goals associated with segment X,such as the use of the phrase well anyway, and the repeated mention of the event ofpicking up the pears.
In terms of the segmentation shown here, the referents intro-duced in segment X are more relevant for interpreting the pronoun in segment Z. Notealso that cue words (italicized) explicitly mark the boundaries of all three segments.Our work is motivated by the hypothesis that natural anguage technologies can moresensibly interpret discourse, and can generate more comprehensible discourse, if theytake advantage of this interplay between segmentation and linguistic devices.In Section 2, we give a brief overview of related work.
In Section 3, we present ouranalysis of segmentation data collected from a population of naive subjects.
Our resultsdemonstrate an extremely significant pattern of agreement on segment boundaries.
InSection 4, we use boundaries abstracted from the data produced by our subjects toquantitatively evaluate algorithms for segmenting discourse.
In Section 4.1, we discussthe coding and evaluation methods.
In Section 4,2, we test an initial set of algorithmsfor computing segment boundaries from a particular type of linguistic feature, eitherreferential noun phrases, cue phrases, or pauses.
In Section 4.3.1, we analyze the errorsof our initial algorithms in order to identify a set of enriched input features, and todetermine how to combine information from the three linguistic knowledge sources.In Section 4.3.2, we use machine learning to automatically construct segmentationalgorithms from large feature sets.
Our results suggest hat it is possible to approachhuman levels of performance, given multiple knowledge sources.
In Section 5, wediscuss the significance of our results and briefly highlight our current directions.104Passonneau and Litman Discourse Segmentation2.
Related WorkThere is much debate about what to define discourse segments in terms of, and whatkinds of relations to assign among segments.
The nature of any hypothesized interac-tion between discourse structure and linguistic devices depends both on the model ofdiscourse that is adopted, and on the types of linguistic devices that are investigated.Here we briefly review previous work on characterizing discourse segments, and oncorrelating discourse segments with utterance features.
We conclude each review bysummarizing the differences between our study and previous work.2.1 Characterizing the Notion of a SegmentA number of alternative proposals have been presented, which relate segments to in-tentions (Grosz and Sidner 1986), Rhetorical Structure Theory (RST) relations (Mannand Thompson 1988) or other semantic relations (Polanyi 1988; Hobbs 1979).
The lin-guistic structure of Grosz and Sidner's (1986) discourse model consists of multiutter-ance segments and structural relations among them, yielding a discourse tree structure.The hierarchical relations of their linguistic structure are isomorphic with the two otherlevels of their model, intentional structure and attentional state.
Rhetorical relations donot play a role in their model.
In Hobbs (1979) and Polanyi (1988), segmental structureis an artifact of coherence relations among utterances, uch as elaboration, evaluation,cause, and so on.
Their coherence relations are similar to those posited in RST (Mannand Thompson 1988), which informs much work in generation.
Polanyi (1988) dis-tinguishes among four types of Discourse Constituent Units (DCUs) based on dif-ferent types of structural relations (e.g., sequence).
As in Grosz and Sidner's (1986)model, Polanyi (1988) proposes that DCUs (analogous to segments) are structured as atree, and in both models, the tree structure of discourse constrains how the discourseevolves, and how referring expressions are processed.
Recent work (Moore and Paris1993; Moore and Pollack 1992) has argued that to account for explanation dialogues,it is necessary to independently model both RST relations and intentions.Researchers have begun to investigate the ability of humans to agree with one an-other on segmentation, and to propose methodologies for quantifying their findings.The types of discourse units being coded and the relations among them vary.
Severalstudies have used trained coders to locally and globally structure spontaneous or readspeech using the model of Grosz and Sidner (1986), including Grosz and Hirschberg1992; Nakatani, Hirschberg, and Grosz 1995; Stifleman 1995; Hirschberg and Nakatani1996.
In Grosz and Hirschberg (1992), percent agreement (see Section 3.2) among 7coders on 3 texts under two conditions--text plus speech or text alone--is reported atlevels ranging from 74.3% to 95.1%.
In Hirschberg and Nakatani (1996), average relia-bility (measured using the kappa coefficient discussed in Carletta \[1996\]) of segment-initial labels among 3 coders on 9 monologues produced by the same speaker, labeledusing text and speech, is .8 or above for both read and spontaneous speech; valuesof at least .8 are typically viewed as representing high reliability (see Section 3.2).Reliability labeling from text alone is .56 for read and .63 for spontaneous speech.Other notions of segment have also been used in evaluating naive or trainedcoders.
Hearst (1993) asked naive subjects to place boundaries between paragraphsof running text, to indicate topic changes.
Hearst reports agreement of greater than80%, and indicates that significance results were found that were similar to thosereported in Passonneau and Litman (1993).
Flammia and Zue (1995) asked subjectsto segment textual transcriptions of telephone task-oriented dialogues, using minimalsegmentation i structions based on a notion of topic: 18 dialogues were segmentedby 5 coders (with varying levels of expertise in discourse), with an average pairwise105Computational Linguistics Volume 23, Number 1kappa coefficient of .45.
To evaluate hierarchical aspects of segmentation, Flammia andZue also developed a new measure derived from the kappa coefficient.
Swerts (1995)asked 38 subjects to mark "paragraph boundaries" in transcriptions of 12 spontaneousspoken monologues; half of the subjects egmented from text alone and half fromtext plus speech.
However, no quantitative valuation of the results were reported.Swerts and Ostendorf (1995) also empirically derived discourse structure, using aspoken corpus of database query interactions.
Although the labelers had high levelsof agreement, he segmentations were fairly trivial.Isard and Carletta (1995) presented 4 naive subjects and 1 expert coder with tran-scripts of task-oriented dialogues from the HCRC Map Task Corpus (Anderson et al1991).
Utterance-like units referred to as moves were identified in the transcripts, andsubjects were asked to identify transaction boundaries.
Since reliability was lower thanthe .80 threshold, they concluded that their coding scheme and instructions requiredimprovement.Moser and Moore (1995) investigated the reliability of various features defined inRelational Discourse Analysis (Moser, Moore, and Glendening 1995), based in part onRST.
Their corpus consisted of written interactions between tutors and students, using3 different utors.
Two coders were asked to identify segments, the core utterance ofeach segment, and certain intentional and informational relations between the coreand the other contributor utterances.
As reported in their talk (not in the paper),reliability on segment structure and core identification was well over the .80 threshold.Reliability on intentional and informational relations was around .75, high enough tosupport entative conclusions.Finally, a method for segmenting dialogues based on a notion of control was usedin Whittaker and Stenton (1988) and Walker and Whittaker (1990).
Utterances wereclassified into four types, each of which was associated with a rule that assigned acontroller; the discourse was then divided into segments, based on which speaker hadcontrol.
Neither study presented any quantitative analysis of the ability to reliablyperform the initial utterance classification.
However, in Whittaker and Stenton (1988),a higher level of discourse structure based on topic shifts was agreed upon by at least4 of 5 judges for 46 of the 56 control shifts.In sum, relatively few quantitative mpirical studies have been made of how toannotate discourse corpora with features of discourse structure, and those recent onesthat exist use various models such as the Grosz and Sidner model (1986), an informalnotion of topic (Hearst 1994; Flammia and Zue 1995), transactions (Isard and Carletta1995), Relational Discourse Analysis (Moser and Moore 1995), or control (Whittakerand Stenton 1988; Walker and Whittaker 1990).
The modalities of the corpora inves-tigated include dialogic or monologic, written, spontaneous or read, and the genresalso vary.
Quantitative valuations of subjects' annotations using notions of agree-ment, interrater reliability, and/or significance show that good results can be difficultto achieve.
As discussed in Section 3, our initial aim was to explore basic issues aboutsegmentation, thus we used naive subjects on a highly unstructured task.
Our corpusconsists of transcripts of spontaneous spoken monologues, produced by 20 differentspeakers.
We use an informal notion of communicative intention as the segmentationcriterion, motivated by Grosz and Sidner (1986) and Polanyi (1988), who argue thatdefining a segment as having a coherent goal is more general than establishing a reper-toire of specific types of segment goals.
We do not, however, ask coders to identifyhierarchical relations among segments.
The hypothesis that discourse has a tree struc-ture has frequently been questioned (Dale 1992; Moore and Pollack 1992; Hearst 1994;Walker 1995), and the magnitude of our segmentation task precludes asking subjectsto specify hierarchical relations.
Finally, we quantify our results using a significance106Passonneau and Litman Discourse Segmentationtest, a reliability measure, and, for purposes of comparison with other work, percentagreement.2.2 Correlation of Segmentation with Utterance FeaturesThe segmental structure of discourse has been claimed to constrain and be constrainedby disparate phenomena, e.g., cue phrases (Hirschberg and Litman 1993; Grosz andSidner 1986; Reichman 1985; Cohen 1984), plans and intentions (Carberry 1990; Lit-man and Allen 1990; Grosz and Sidner 1986), prosody (Hirschberg and Pierrehum-bert 1986; Butterworth 1980), nominal reference (Webber 1991; Grosz and Sidner 1986;Linde 1979), and tense (Webber 1988; Hwang and Schubert 1992; Song and Cohen1991).
However, just as with the early proposals regarding segmentation, many ofthese proposals are based on fairly informal studies.
It is only recently that attemptshave been made to quantitatively evaluate how utterance features correlate with in-dependently justified segmentations.
Many of the studies discussed in the preced-ing subsection take this approach.
The types of linguistic features investigated in-dude prosody (Grosz and Hirschberg 1992; Nakatani, Hirschberg, and Grosz 1995;Hirschberg and Nakatani 1996; Swerts 1995; Swerts and Ostendorf 1995), term repeti-tion (Hearst 1994), cue words (Moser and Moore 1995; Whittaker and Stenton 1988),and discourse anaphora (Walker and Whittaker 1990).Grosz and Hirschberg (1992) investigate the prosodic structuring of discourse.The correlation of various prosodic features with their independently obtained con-sensus codings of segmental structure (codings on which all labelers agreed) is an-alyzed using t-tests; the results support the hypothesis that discourse structure ismarked intonationally in read speech.
For example, pauses tended to precede phrasesthat initiated segments (independent of hierarchical structure) and to follow phrasesthat ended segments.
Similar results are reported in Nakatani, Hirschberg, and Grosz(1995) and Hirschberg and Nakatani (1996) for spontaneous speech as well.
Grosz andHirschberg (1992) also use the classification and regression tree system CART (Brie-man et al 1984) to automatically construct and evaluate decision trees for classifyingaspects of discourse structure from intonational feature values.The studies of Swerts (1995) and Swerts and Ostendorf (1995) also investigate theprosodic structuring of discourse.
In Swerts (1995), paragraph boundaries are empiri-cally obtained as described above.
The prosodic features pitch range, pause duration,and number of low boundary tones are claimed to increase continuously with bound-ary strength (the proportion of subjects identifying a boundary).
However, there is noanalysis of the statistical significance of these correlations.
In Swerts and Ostendorf(1995), prosodic as well as textual features are shown to be correlated with their in-dependenfly obtained (but fairly trivial) discourse segmentations of travel-planninginteractions, with statistical significance.Hearst's (1994) TextTiling algorithm structures expository text into sequential seg-ments based on term repetition.
Hearst (1994) uses information retrieval metrics (seeSection 4.1) to evaluate two versions of TextTiling against independently derived seg-mentations produced by at least three of seven human judges.
Precision was .66 forthe best version, compared with .81 for humans; recall was .61 compared with .71 forhumans.
The use of term repetition (and a related notion of lexical cohesion) is notunique to Hearst's work; related studies include Morris and Hirst (1991), Youmans(1991), Kozima (1993), and Reynar (1994).
Unlike Hearst's work, these studies eitheruse segmentations that are not empirically justified, or present only qualitative analy-ses of the correlation with linguistic devices.After identifying segments, and core and contributor relations within segments,Moser and Moore (1995) investigate whether cue words occur, where they occur, and107Computational Linguistics Volume 23, Number 1what word occurs.
In their talk, they presented results showing that the occurrenceand placement of a discourse usage of a cue word correlates with relative order ofcore versus contributor utterances.
For example, a discourse cue is more likely to occurwhen the contributor precedes the core utterance (p < .001).Finally, Whittaker and Stenton (1988) examined a wide variety of means for sig-naling discourse structure.
Prompts, repetitions, and summaries rather than cue wordsmore often signaled control-based discourse segment boundaries.
No statistical anal-ysis of the significance of the differences was presented, however.
By statistically an-alyzing distributions of discourse anaphora with respect o control-based iscoursesegments, Walker and Whittaker (1990) showed that shifts of attentional state (Groszand Sidner 1986) occurred when shifts in control were accepted by all dialogue par-ticipants.In sum, relatively few studies correlate linguistic devices with empirically justifieddiscourse segmentations.
Quantitative valuations of the correlations include the useof statistical measures and information retrieval metrics.
As discussed in Section 4, wederive discourse segmentations based on the statistical significance of the agreementamong our subjects.
In contrast to studies investigating a single feature, we investigatethree types of linguistic devices--referential noun phrases, prosody, and cue phrases.In addition, we are concerned with the extra step of developing segmentation algo-rithms rather than with the demonstration of statistical correlations.
We first developalgorithms using each type of linguistic device in isolation, motivated by existing hy-potheses in the literature.
Then we propose and evaluate methods for combining them.We use measures from information retrieval to quantify and evaluate our results.3.
Intention-Based SegmentationHere we present he results of a study investigating the ability of naive subjects toidentify the same segments in a corpus of spoken narrative discourse.
Our first goal ispurely exploratory.
Despite the wide agreement that discourse structure and linguis-tic form are mutually constraining, there is little agreement on how to determine thestructure of any particular discourse.
Thus we do not assume that there are "correct"segmentations against which to judge subjects' responses.
Also, as discussed in ourprevious work (Passonneau and Litman 1996), the subjects' performance suggests thatsegmentation is a fuzzy phenomenon.
Because our study is exploratory, we took theconservative approach of defining a very open-ended segmentation task that allowedsubjects great freedom in the number and size of the segments to identify.
Our statisti-cal results indicate that, despite the freedom of the task, naive subjects independentlyperform surprisingly similar segmentations of the same discourse.
We also show byexample that subjects' segmentations reflect the presumed episode structure of thenarrative.We ask subjects to segment discourse using a nonlinguistic riterion in order toavoid circularity when we later investigate the correlation of linguistic devices withsegments derived from the segmentation task results.
Abstracting statistically signif-icant results from the subjects' responses i thus the second goal of our study of thesegmentation task.
Here we briefly review our statistical results and summarize themotivation for our method of abstracting a single segmentation for a given narrativefrom a set of subjects' responses.
As noted below, more detailed discussion of thestatistic we use is presented elsewhere.
What we also discuss here, which has notbeen presented in previous work, is a preliminary evaluation of the reliability of ourmethod where we give a conservative lower bound suggesting that the method isreliable.108Passonneau and Litman Discourse Segmentation3.1 Methodology: Empirically Derived SegmentationThe claim has been made that different people (investigators or subjects) are likelyto assign similar segment boundaries or segment relations to a discourse (Grosz andSidner 1986; Reichman 1985; Mann and Thompson 1988), but it has also been observedthat discourse structure can be ambiguous (Pierrehumbert and Hirschberg 1987).
Stud-ies asking subjects to assign topical units to sample discourses have shown that theresulting segments vary widely in both size and location (Rotondo 1984).
Yet untilrecently, there has been little attempt o quantify the degree of variability among sub-jects in performing such a task.
Here we present he results of our study of naivesubjects performing a relatively unstructured segmentation task on a corpus of similardiscourses.
Full details are presented in Passonneau and Litman (1996).The corpus consists of 20 spoken narrative monologues known as the Pear stories,originally collected by Chafe (1980).
Chafe recorded and transcribed subjects who hadbeen asked to view the same movie and describe it to a second person.
The moviecontained 7 sequential episodes about a man picking pears.
Chafe identified threetypes of prosodic phrases from graphic displays of intonation contours, as describedin Section 4.1.
The corpus contains just over 2,000 prosodic phrases with roughly 13,500words.For our study, each narrative was segmented by seven naive subjects (as opposedto trained researchers or trained coders), using an informal notion of communicativeintention as the segmentation criterion.
Except in rare cases, no subject segmented morethan I narrative.
As discussed above, a variety of criteria for identifying discourse unitshave been proposed.
Our decision to use a commonsense notion of intention as thecriterion is aimed at giving the subjects the freedom to choose their own segmentationcriteria, and to modify the criteria to fit the evolving discourse.Two structural constraints were also imposed on the content units that subjectswere asked to identify.
First, subjects were asked to perform a linear rather than ahierarchical segmentation, where a linear segmentation simply consists of dividing anarrative into sequential units.
Second, subjects were restricted to placing boundariesbetween the prosodic phrases identified by Chafe (1980).
Subjects were presented withtranscripts of the narratives formatted so that each non-indented new line was thebeginning of a new prosodic phrase.
The pause locations and durations transcribedby Chafe (see Section 4.1.2) were omitted, but otherwise all lexical and nonlexicalarticulations were retained.
The instructions given to the subjects were designed tohave as little bias as possible regarding segment size, and total number of segments.
3As we discuss further below, both the rate at which subjects assigned boundaries andthe size of segments varied widely.Figure 2 shows the subjects' responses for the excerpt corresponding to Figure 1.The potential boundary sites are between the text lines corresponding to prosodicphrases.
The left column shows the prosodic phrase numbers, which are explainedlater.
There are 19 phrases, hence 18 boundary sites.
The seven subjects are differ-entiated by distinct letters of the alphabet.
Note that a majority of subjects agreedon only 3 of the 18 possible boundary sites, corresponding to the segmentation illus-trated in Figure 1.
In general, subjects assigned boundaries at quite distinct rates, thusagreement among subjects is necessarily imperfect.
All subjects assigned boundariesrelatively infrequently.
On average, subjects assigned boundaries at only 16.1% of thepotential boundary sites (min = 5.5%; max = 41.3%) in any one narrative.
Boundary3 These instructions will be made available at the web site for the Discourse Resource Initiative (DRI),currently at http://www.georgetown.edu/luperfoy/Discourse-Treebank/dri-home.html.109Computational Linguistics Volume 23, Number 1ii.
'2 okay.
'16 SUBJECTS (a, b, c, e, f, g) li J22.1 Meanwhile,22.2 there are three little boys,22.3 up on the road a little bit,22.4 and they see this little accident.23.1 And u-h they come over,23.2 and they help him,23.3 and you know,\[ 1 SUBJECT (c) \]23.4 help him pick up the pears and everything.\[ 5 SUBJECTS (a, d, e, f, g) l24.1 A-nd the one thing that struck me about the- three little boys that were there,\[1 SUBJECT (b)\]24.2 is that one had ay uh I don't know what you call them,24.3 but it's a paddle,24.4 and a ball-,24,5 is attached to the paddle,24.6 and you know you bounce it?\[ 2 SUBJECTS (a, d)\]25.1 And that sound was really prominent.14 SUBJECTS (d, e, f, g)\]26.1 Well anyway,\[2 SUBJECTS (b, c) l26.2 so- u-m tsk all the pears are picked up,26.3 and he's on his way again,Figure 2Sample of subjects' responses.locations were relatively independent of one another, as shown by the the fact thatsegments varied in size from 1 to 49 phrases in length (Avg.
= 5.9).
The assumptionof independence is important for motivating statistical analyses of how probable theobserved istributions are.Figure 3 shows two bar charts.
The one on the left gives the results for the fullnarrative excerpted in Figure 1.
The x-axis is the number of subjects, from 0 to 7.The y-axis, from top to bottom, corresponds to the potential boundary locations, withprosodic phrase locations numbered as in Figure 2.
Each horizontal bar thus representsthe number of subjects assigning aboundary at a particular interphrase location.
Inter-estingly, there were 6 segment boundaries identified by at least five subjects, yielding7 segments that correspond closely to the 7 sequential episodes that Chafe (1980) usedto describe the movie.
The first 5 segments correspond to the first 5 episodes.
The 6thsegment corresponds to the 6th episode plus the beginning of the 7th, while the 7thsegment corresponds to the end of the 7th episode.The large proportion of white space to black space in the left bar chart of Fig-ure 3 illustrates graphically that subjects assign boundaries relatively infrequently.
Thelarge regions of white space separated by very wide bars shows a striking consensuson certain segments (white space) and segment boundaries (wide black bars).
To il-lustrate graphically the improbability of the occurrence of wide bars (high-consensusboundaries), we also show a typical random distribution for a parallel data set in theright-hand bar chart of Figure 3.
To create this data, we repeatedly performed thefollowing experiment, and randomly selected one result.
First we created seven hypo-thetical subjects, each of whom assigns the same number of boundaries as one of the110Passonneau and Litman Discourse Segmentation4i015192023262729Lmmmm __mmumm3 2.
3.
4 5.Number ofSegmenlers6.
7 .L__4.3\]10.115.119.1~20.923.4~:::::::26.1m27.129 ~=.I 2 3Figure 3Bar chart of subjects' responses on one narrative (showing narrative pisodes), compared torandom distribution.Frequency4(3(2(lO7 6 5 4 3 2 1 0 Number  of Sub jectsFigure 4Frequency that N subjects identify any boundary slot as a boundary.real subjects from the same number of potential boundary slots.
The hypothetical sub-jects assign boundaries randomly (but with no repetition).
In the random distribution,there are few bars of width 3, and none of any greater width.We show below that, given the loosely structured task, the probability of theobserved istribution depicted in Figure 3 is extremely low, hence highly significant.111Computational Linguistics Volume 23, Number 1The statistical test we use identifies x ~ 3 as the threshold separating insignificantboundaries from significant ones.
The large scattering of narrow bars (1 < x ~ 2)illustrates the inherent noisiness of the data arising from the fact that subjects assignboundaries at varying rates.
The histogram in Figure 4 gives a different view of thesame point, showing the relative frequency of cases where N subjects place a boundaryat a given location, for N from 0 to 7.
The y-axis is normalized to represent the averagenarrative length of 100 phrases, thus the bar at N = 0 indicates that on average, 47.8of the 100 phrases were not classified as boundaries.
4 The large majority of responses(80%) fall within the bars for N = 0 (47.8%), N = 1 (23.0%), and N = 2 (10.0%), forminga rapidly descending curve.
For N = 3 and above, the slope of the curve suddenlybecomes linear, and much less steep, corresponding toa much more gradual decreasein frequency as values of N go to 7.
That there should be any cases where six orseven subjects identify the same boundary is highly improbable, but on average, thishappens 4.5 times per narrative.
Summing the heights of the bars for N = 3 throughN = 7 indicates that for an average narrative whose length is 100 phrases, there willbe about 20 boundaries identified by three or more subjects.3.2 Results3.2.1 Evaluation Metrics.
Again, our first goal in evaluating the segmentation datafrom our subjects is to explore the possibility that subjects given as little guidanceas possible might yet recognize rather similar segments in the narrative corpus.
Tomake this evaluation, we first use a significance test of the null hypothesis that thedistributions could have arisen by chance.
We then analyze the distributions in moredetail to determine what aspects of the distribution are significant, and thereby to ab-stract significant data for use in defining segmentations foreach narrative.
The resultsindicate that the observed istributions are highly significant, i.e., unlikely to havearisen by chance.
In Section 3.2.2, we briefly review Cochran's Q (1950), the statisticthat we use, and the test of the null hypothesis.
We then partition Cochran's Q to de-termine the lowest value on the x-axis in Figure 3 at which agreements on boundariesbecome statistically significant.
The results indicate significance arises when at leastthree subjects agree on a boundary.Reliability metrics (Krippendorff 1980; Carletta 1996) are designed to give a robustmeasure of how well distinct sets of data agree with, or replicate, one another.
Theyare sensitive to the relative proportion of the different data types (e.g., boundariesversus nonboundaries), but insensitive to the statistical likelihood that agreementswill occur.
We have already discussed how variable the subjects' responses are, bothin number and placement of segment boundaries, o we know that our subjects arenot replicating the same behavior.
However, all 20 narratives show the same pattern ofresponses as illustrated in Figure 3: certain boundaries are identified by large numbersof subjects.
For any one narrative, we should expect a new set of seven subjects toyield roughly the same set of segment boundaries.
In other words, our method forabstracting a single set of boundaries from the responses of multiple subjects houldbe reproducible.
In Section 3.2.3, we evaluate our method by using Krippendorff's c~to evaluate the reliability of boundaries derived from one set of subjects comparedwith those derived from another set of subjects on the same narrative.4 Since the narratives vary in length and in relative frequency of boundaries placed by subjects, wenormalized the data before averaging across narratives.
Where L is the length of a narrative i, theactual frequency of cases where N subjects agree in narrative i is multiplied by 100/L, where 100 is theaverage narrative length.112Passonneau and Litman Discourse SegmentationTable 1Matrix representation f boundary data.Subject Potential Boundary Sites21.2 22.1 22.2 22.3 22.4 23.1 23.2 23.3 23.4 24.1 24.222.1 22.2 22.3 22.4 23.1 23.2 23.3 23.4 24.1 24.2 24.3a 1 1b 1 1c 1 1d 1e 1 1f 1 1g 1 1Total 6 0 0 0 0 0 0 1 5 1 0Finally, for purposes of comparison with other studies of segmentation, we reportpercent agreement.
Percent agreement is high, but as argued in Krippendorff (1980),percent agreement is relatively uninformative because it fails to take into accountthe response rate of individual subjects, a factor built into both Cochran's Q andKrippendorff 's a.3.2.2 Significance.
The segmentation data from the 20 narratives can be represented asa set of 20 i x j matrices, each of the form shown in Table 1.
Each matrix has a heightof i -- 7 subjects and width of j = n prosodic phrases less 1.
(Table 1 is a partial matrixof width j = 11.)
The value in a cell Ci,j is a 1 if the ith subject assigned a boundaryat site j, and blank if they did not.
We use Cochran's Q to evaluate the significanceof the distributions in the matrices.
5 Cochran's test evaluates the null hypothesis thatthe sums of ls in the columns, representing the total number of subjects assigning aboundary at the jth site (Tj), are randomly distributed.
It does so by evaluating thesignificance of the differences in column totals (Tj) across the matrix, with each rowtotal ui (or total number of boundaries assigned by subject i) assumed to be fixed.Where the average column total is T, the statistic is given by:Q =j(j - 1) ~(Tj - 7) 2j(Y\] ui) - (Y\] u 2)Our results indicate that the agreement among subjects is extremely significant.
Forthe 20 narratives, the probabilities that the observed istributions could have arisenby chance range from p = .1 x 10 -6 to p = .6 x 10 -9.We now turn to the second question addressed in the segmentation study, how toabstract a set of empirically justified boundaries from the data.
We do this by selectingthe statistically significant response data.
Recall the large amounts of white space inFigure 3, contrasting with the few sharp peaks where many subjects identify the sameboundary, which suggests that the significance of Q owes most to the cases wherecolumns have many l's.
The question is, how many l 's is significant?
We address thisquestion by partitioning Q into distinct components for each possible value of Tj (0 to7), based on partitioning the sum of squares in the numerator of Q into distinct samples5 We thank Julia Hirschberg for suggesting this test.113Computational Linguistics Volume 23, Number 1(Cochran 1950).
Partitioning Q by the 8 values of Tj shows that Qj is significant at thep = .0001 level for each distinct Tj > 4 across all narratives.
Probabilities become moresignificant for higher levels of Tj, and the converse.
At Tj = 3, p is significant at the.01 level on 19 narratives, and for the remaining narrative p = .0192.
When we lookat correlation of segment boundaries with linguistic features, we use both thresholdsTj >_ 4, and Tj > 3 to select a set of empirically justified boundaries.
On average, thisgives us 12 (Tj >_ 4) or 20 (Tj >_ 3) boundaries for a 100-phrase narrative.3.2.3 Reliability.
Reliability metrics provide a measure of the reproducibility of adata set, for example, across conditions or across subjects.
Recently, discourse studieshave used reliability metrics designed for evaluating classification tasks to determinewhether coders can classify various phenomena in discourse corpora, as discussed inSection 2.1.
The segmentation task reported here is not properly a classification task,in that we do not presume that there is a given set of segment boundaries that subjectsare likely to identify.
Given the freedom of the task and the use of untrained subjects, areliability test would be relatively uninformative: it can be expected to range from verylow to very high.
In fact, sorting the 140 subjects into comparable pairs (i.e., subjectsassigning a similar number of boundaries), a reliability metric that ranges between1 for perfect reliability and -1 for perfect unreliability (Krippendorff's a, discussedbelow) gives a wide spread of reliability values (from -.3 to .9; average = .34).
Ourmethod aims at abstracting away from the absolute differences across multiple subjectsper narrative (N = 7) to derive a statistically significant set of segment boundaries.Thus, an appropriate test of whether our method is statistically reliable would be tocompare two repetitions of the method on the same narratives to see if the results arereproducible.Although we do not have enough subjects on any single narrative to comparetwo distinct sets of seven subjects, we do have four narratives with data from eightdistinct subjects.
For each set of eight subjects, we created two randomly selectedpartitions (A and B) with four distinct subjects in each.
Then we assessed reliabilityby comparing the boundaries produced by partitions A and B on the four narratives(using a boundary threshold of at least three subjects).
Because we only have foursubjects within each partition, this necessarily produces fewer significant boundariesthan our method.
In other words, this test can only give us a conservative lowerbound for reliability.
(Recall that significance of a boundary increases exponentiallywith the number of subjects who agree on a boundary.)
But even with this conservativeevaluation, reliability is fairly good on two narratives, and promising on average.A reliability measure indicates how reproducible a data set is by quantifying sim-ilarity across subjects in terms of the proportion of times that each response categoryoccurs.
This differs from a significance test of the null hypothesis (e.g., our use ofCochran's Q), where observed ata is compared to random distribution.
We use Krip-pendorff's a (1980) to evaluate the reliability of the two data sets from partitions A andB.
The general formula for a is 1 - D_o_o where Do and DE are observed isagreements DE 'and expected isagreements.
Computation of a is described below.Krippendorff's a reports to what degree the observed number of matches couldbe expected to arise by chance.
Again in contrast with Cochran's Q, it is simply aratio rather than a point on a distribution curve with known probabilities.
Valuesrange from 1 to -1, with 0 representing that there are no more agreements observedin the data than would happen by chance.
A value of .5 would indicate that theobserved number of agreements is halfway between chance and perfect agreement.Negative values indicate the degree to which observed isagreements differ fromchance.
In principle, a is computed from the same type of matrix shown in Table 1,114Passonneau and Litman Discourse SegmentationTable 2Krippendorff's a comparing boundaries derived from twosets of 4 subjects on 4 narratives.Boundary Threshhold Narrative2 4 7 15 AverageTj _> 3 .50 .60 .73 .50 .58and can be applied to multivalued variables that are quantitative or qualitative.
Herewe summarize computation of a simplified formula for ~ used for comparing twodata sets with a single, dichotomous variable.
To exemplify the computation, we usethe first two rows of Table 1, giving a matrix of size i = 2 x j = 11.
The value of Do(proportion of observed isagreements) i  then simply ~, where M is the total numberof mismatches (j being the potential number of matches).
In our example, Do has avalue of 2 (.18).
Where nl is the total number of l 's and no is the total number oflSx4 (.31).
The detailed formula blanks, DE is given by j(2j-1)'~ In our example, DE isfor c~ then simplifies to:(2 j -  1)(M)c~--1n0nlThis gives ~ -- .42, meaning that the observed case of one agreement out of twopotential agreements on boundaries in our example is not quite halfway betweenchance and perfect agreement.
Consider a case where two subjects had 12 responseseach (j = 12), each subject responded with 1 half the time (nl = no -- 12), andwherever one put a 1, the other did not (M = 12).
The data contains the maximumnumber of disagreements, yet ~ = -0.92, or somewhat less than -1,  meaning that asmall proportion of the observed isagreement would have arisen by chance.Table 2 presents the reliability results from a comparison of boundaries found bytwo distinct partitions of subjects' responses on four narratives.
An ~ of .80 using twopartitions of seven subjects would represent very good reproducibility, with valuesabove .67 being somewhat good (Krippendorff 1980).
Note that reliability on narrative7 (.73) is good despite the small number of subjects.
Since, as noted above, we wouldexpect reliability to be much higher if there were seven subjects, we believe that valuesabove .5 for N = 4 subjects indicate reproducibility.
On average c~ = .58 and the spreadis low (or = .09).3.2.4 Percent Agreement.
Both significance and reliability can stand alone as evalua-tion metrics, unlike percent agreement.
However, we also report percent agreement inorder to compare results with other studies.
As defined in Gale, Church, and Yarowsky(1992), percent agreement is the ratio of observed agreements with the majority opinionto possible agreements with the majority opinion.
As detailed in Passonneau and Lit-man (1996), the average percent agreement for our subjects on all 20 narratives i  89%(max.
= 92%; rain.
= 82%).
On average, percent agreement is highest on nonbound-aries (91%; max.
= 95%; rain.
= 84%) and lowest on boundaries (73%; max.
= 80%;min.
= 60%), reflecting the fact that nonboundaries greatly outnumber boundaries.These figures compare with other studies (74% to 95% in Grosz and Hirschberg \[1992\],depending upon discourse feature, and greater than 80% in Hearst \[1993\]).115Computational Linguistics Volume 23, Number 13.2.5 Discussion.
We have shown that an atheoretical notion of speaker intention isunderstood sufficiently uniformly by naive subjects to yield highly significant agree-ment across subjects on segment boundaries in a corpus of spoken narratives.
Prob-abilities of the observed istributions range from .6 x 10 -9 to .1 x 10 -6 as given byCochran's Q.
The result is all the more striking given that we used naive coders on aloosely defined task.
Subjects were free to assign any number of boundaries, and tolabel their segments with anything they judged to be the narrator's communicativeintention.
Partitioning Cochran's Q shows that the proportion of boundaries identifiedby at least three subjects was significant across all 20 narratives (p < .02).
Significanceincreases exponentially as the number of subjects agreeing on a boundary increases.A conservative means for estimating a lower bound for the reliability of our method,using Krippendorff's c~ as a metric, suggests that the method is reliable.
The reliabilityevaluation is conservative in part because it uses fewer subjects to derive boundaries.Note that it is conservative also because it is based on the proportion of identicalmatches between two data sets.
This type of metric ignores the inherent fuzziness ofsegment location, as discussed in Passonneau and Litman (1996).
We conclude thatboundaries identified by at least three of seven subjects most likely reflect he validityof the underlying notion that utterances in discourse can be grouped into more-or-less coherent segments.
What remains is the question of whether linguistic featurescorrelate at all well with these segments.4.
Algorithmic Identification of Segment Boundaries using Linguistic CuesAs discussed in Section 2, there has been little work on examining the use of linguisticcues for recognizing or generating segment boundaries, 6 much less on evaluating thecomparative utility of different ypes of information.
In this section we present andevaluate a collection of algorithms that identify discourse segment boundaries, whereeach relies on a different ype of linguistic information.
We first introduce our method-ology (Section 4.1), then evaluate three initial algorithms, each based on the use of asingle linguistic device frequently proposed in the literature: pauses, cue words andreferential noun phrases, respectively (Section 4.2).
7 Each algorithm was developedprior to any acquaintance with the narratives in our corpus.
We evaluate ach algo-rithm by examining its performance in segmenting an initial test set of 10 of our 20narratives.
We also evaluate a simple method for combining algorithms.
These initialevaluations allow us to quantify the performance of existing hypotheses, to comparethe utility of three very different ypes of linguistic knowledge, and to begin investi-gating the utility of combining knowledge sources.
We then present wo methods forenhancing performance: rror analysis, and machine learning (Section 4.3).
8 Here weuse the 10 narratives previously used for testing as training data.
The resulting algo-rithms are then tested on 5 new narratives.
By using enriched linguistic informationand by allowing more complex interactions among linguistic devices, both methodsachieve results that approach uman performance.4.1 Methodology4.1.1 Algorithm Input and Output.
Each algorithm is designed to replicate the sub-jects' segmentation task (break up a narrative into contiguous egments, with segmentbreaks falling between prosodic phrases).
The input to each algorithm is a set of po-6 A notable exception is the literature on pauses.7 This section draws from Passonneau and Litman (1993).8 This section draws from Litman and Passonneau (1995a).116Passonneau and Litman Discourse Segmentation21.222.122.222.322.423.123.223.323.424.124.224.324.424.524.625.126.126.226.3okay.
(boundary)\[.5 \[.2\] Meanwhile\],(nonboundary)there are three little boys,(nonboundary)\[.15\] up on the road a little bit,(nonboundary)and they see this little accident.
(nonboundary)\[1.6 \[.55\] And u-h\] they come over,(nonboundary)and they help him,(nonboundary)\[.4?
and \[.2\]\] you know,( nonboundary )help him pick up the pears and everything.
(boundary)\[2.7 |1.0\] A-nd \[1.15\]\] the one thing that struck me about the- \[.3\] three little boys that were there,is that one had ay uh \[.4\] I don't know what you call them,but it's a paddle,and a ball-,\[.2\] is attached to the paddle,and you know you bounce it?..
And that sound was really prominent.\[4.55 Well anyway,\[.45\] so- u-m \[.11 throat clearing \[.451 tsk \[1.15\]\] all the pears are picked up,and.. he's on his way again,Figure 5Excerpt from narrative 9, with boundaries.
(nonboundary)(nonboundary)(nonboundary)(nonboundary)(nonboundary)(nonboundary)(boundary)(nonboundary)(nonboundary)tential boundary sites, coded with respect to a wide variety of linguistic features.
Theoutput is a classification of each potential boundary site as either boundary or non-boundary.
In the target output, we classify a potential boundary site as boundary if itwas identified as such by at least i of the seven subjects in our empirical study, wherewe use two values of i.
Otherwise it is classified as nonboundary.
In our experiments,we investigate the correlation of linguistic cues with boundaries identified by bothi = 3 and i = 4 subjects.Figure 5 is a modified version of Figure 2, showing the classification of the sta-tistically validated boundaries in the same narrative excerpt.
(The bracketed numbersrepresent pauses, as explained below.)
The boxes in the figure show the subjects' re-sponses at each potential boundary site; if no box is shown, none of the seven subjectsplace a boundary at the site.
The italicized parentheticals at each potential boundarysite show the resulting boundary classification.
Only 3 of the 18 possible boundarysites are classified as boundary, for both i = 3 and i = 4.4.1.2 Coding of Linguistic Features.
Given a narrative of n prosodic phrases, thereare n - 1 potential boundary sites between each pair of prosodic phrases Pi and Pi+l,i from 1 to n - 1.
Each potential boundary site in our corpus is coded for featuresrepresenting the three different sources of linguistic information of interest: prosody,117Computational Linguistics Volume 23, Number 1Prosodic Features?
before:+sentence.f inal .contour,-sentence.f inal .contour.?
after: +sentence.final.contour,-sentence.final.contour.o pause: true, false.?
duration: continuous.Cue Phrase Featureso cue1: t rue,  false.?
word1: also, and, anyway, basically, because, but, finally, first, like, meanwhile, no, now, oh, okay, only,or, see, so, then, well, where, NA.?
cue2: t rue,  false.?
word2: and, anyway, because, boy, but, now, okay, or, right, so, still, then, NA.Noun Phrase Featureso coref: +coref, -coref, NA.o infer: +infer, -infer, NA.o global.pro: +global.pro, -global.pro, NA.Combined Feature?
cue-prosody: complex, true, false.Figure 6Features and their range of values.cue phrases, and referential noun phrases.
The linguistic features used in our twosets of experiments are shown in Figure 6.
Our initial experiments use only the fea-tures marked as "o," while our later experiments use the full feature set, along withmodifications to the noun phrase features.Values for the prosodic features are obtained by automatic analysis of the tran-scripts, whose conventions are defined in Chafe (1980) and illustrated in Figure 5:.,3..."."
and "?"
indicate falling versus rising sentence-final intonationalcontours"," indicates phrase-final but not sentence-final intonation"\[X\]" indicates a pause lasting X seconds (measured to an accuracy ofabout .05 seconds)"\[W \[Y\] lexical material \[Z\]\]" indicates a sequence lasting W secondswhere a Y second pause is followed by lexical material then a pause of Zseconds".." indicates a break in timing too short to be measured as a pause(The values in the transcripts are based in part on an analysis of displays of fundamen-tal frequency contours.)
The features before and after depend on the final punctuationof the phrases Pi and Pi+l, respectively.
The value is +sentence.final.contour if "."
or"?
", -sentence.final.contour if ",".
Pause is assigned true if Pi+l begins with \[X\] (con-vention 3) (or with \[W \[Y\] for convention 4), false otherwise.
Duration is assignedX (convention 3) (or Y for convention 4) if pause is true, 0 otherwise.
The prosodicfeatures were motivated by previous results in the literature.
For example, phrases be-ginning discourse segments were correlated with preceding pause duration in Groszand Hirschberg (1992).
These and other studies (e.g., Hirschberg and Litman \[1993\])also found it useful to distinguish between sentence-final and non-sentence-final into-national contours.118Passonneau and Litman Discourse SegmentationThe cue phrase features are also obtained by automatic analysis of the transcripts.Cue1 is assigned true if the first lexical item in Pi+l is a member of the set of cuewords summarized in Hirschberg and Litman (1993).
Word1 is assigned this lexicalitem if cue1 is true, NA (not applicable) otherwise.
9 Cue2 is assigned true if cue1 istrue and the second lexical item is also a cue word.
Word2 is assigned the secondlexical item if cue2 is true, NA otherwise.
As with the pause features, the cue phrasefeatures were motivated by previous results in the literature.
Initial phrase position(cue1) was correlated with discourse signaling uses of cue words in Hirschberg andLitman (1993).
A potential correlation between discourse signaling uses of cue wordsand adjacency patterns between cue words (cue2) was also suggested.
Finally, Litman(1996) found that treating cue phrases individually rather than as a class (word1, word2)enhanced the results of Hirschberg and Litman (1993).Two of the noun phrase (NP) features are hand coded, along with FunctionallyIndependent Clause Units (FICUs; see below), following Passonneau (1994).
The twoauthors coded independently and merged their results.
Coding was performed onautomatically created coding sheets for each narrative, consulting transcripts that werespecially formatted to show prosodic phrase boundaries and numbers, but which wereotherwise identical to Chafe's (1980) original transcriptions.
Boundary data, whichhad been collected but not analyzed, was not available.
Comprehensive operationaldefinitions for recognition of reference features (coref and infer) are documented inPassonneau (1994).
The last NP feature, global.pro, is computed from the coding ofother features and of previously occurring boundaries.All three NP features are applied in the context of FICUs (Passonneau 1994).
AnFICU contains a single tensed clause that is neither a verb argument nor a restrictiverelative clause, potentially with sentence fragments or repairs.
If a new FICU (Cj)begins in prosodic phrase Pi+I, then NPs in Cj are compared with NPs in previousFICUs and the feature values assigned as follows: m1.
corer = +coref if any NPs in Cj and Cj-1 corefer; else corer = -coref2.
infer = +infer if the referent of an NP in Cj can be inferred from Cj-1 onthe basis of a pre-defined set of inference relations; else infer = -infer3.
global.pro = +globaLpro if the referent of a definite pronoun in Cj ismentioned in a previous utterance, but not prior to the last time aboundary was assigned; else global.pro = -global.proNote that the global.pro feature is defined in a manner that depends on incrementalassignment of boundaries and coding of features.
To evaluate global.pro for an utteranceCj requires that all boundaries occurring prior to Cj have been assigned.
If a newFICU is not initiated in Pi+I, values for all three features are NA.
The NP featuresreflect Passonneau's hypotheses that adjacent utterances are more likely to containexpressions that corefer, or that are inferentially linked, if they occur within the samesegment; and that a definite pronoun is more likely than a full NP to refer to anentity that was mentioned in the current segment, if not in the previous utterance.These hypotheses are inspired by centering theory (Grosz, Joshi, and Weinstein 1995),psycholinguistic research (Marslen-Wilson, Levy, and Tyler 1982; Levy 1984), and pilot9 The cue phrases that occur in the corpus are shown as potential values in Figure 6.10 The NP algorithm can assign multiple boundaries within one prosodic phrase if the phrase containsmultiple clauses; these very rare cases are normalized (Passonneau nd Litman 1993).
A total of 5boundaries are eliminated in3 of the 10 test narratives (out of 213 in all 10).119Computational Linguistics Volume 23, Number 122.4 and they/see this little accident.23.1 \[1.6 \[.55\] And u-h\] they/come over,23.2 and they/help himj,23.3 \[.4?
and \[.2\]\] you know,23.4 (ZERO/) help himj pick up the pears and everything.Site before after pause duration cue1 wordl cue2 word2 corer infer globaLpro cue-prosody(22.4,23.1) + t 0.55 t and f(23.1,23.2) f 0 t and f(23.2,23.3) t 0 t and f(23.3,23.4) + f 0 f NA fFigure 7Example feature coding of potential boundary sites.NA + + tNA + + fNA NA NA NA tNA + + fstudies on data from corpora (Passonneau 1993) or published excerpts (Grosz 1977;Grosz and Sidner 1986).
Unlike the cue and pause features, the NP features were thusnot directly based on simplifications of existing results.Cue-prosody, which encodes a combination of prosodic and cue word features, wasmotivated by an analysis of errors on our training data, as described in Section 4.3.1.Cue-prosody is assigned complex if:1. before = +sentence.final.contour2.
pause -- true3.
And either:(a)(b)cue1 = true, word1 ~ andcue1 -- true, word1 = and, cue2 = true, word2 ~ andElse, cue-prosody has the same values as pause.Figure 7 illustrates how four example boundary sites in Figure 5 would be codedusing the features in Figure 6.
The subscripting on noun phrases indicates coreference.The ability of humans to reliably code linguistic features imilar to those codedin Figure 7 has been demonstrated in various studies.
Evaluation of prosodic labelingusing TOBI, a prosodic transcription system somewhat similar to that used in the Pearcorpus, has been found to be quite reliable between transcribers (Pitrelli, Beckman, andHirschberg 1994).
The results of a study of 953 spoken cue phrases howed that twojudges agreed on whether cue phrases illustrated a discourse signaling usage or not in878 (92.1%) cases (Hirschberg and Litman 1993).
For these 878 cases, an algorithm thatassigned iscourse signaling usages to cues if they were the first lexical item in theirintermediate intonational phrase performed with 75% accuracy (Litman 1994), whichis analogous to the method used here to assign the value true to the feature cue1.
Whencoding involves either relatively objective phenomena or a well-defined ecision pro-cedure, one can expect good interrater eliability among different coders (see Duncanand Fiske \[1977\] and Mokros \[1984\]).
The corer feature falls into this category.
In ad-dition, preliminary data from a third coder provides good evidence that coref can becoded reliably.
A feasibility study of the parsers CASS (Abney 1990) and FIDDITCH(Hindle 1983) showed that coding FICUs on this data could be automated, n Subjectiv-ity in coding the infer feature was eliminated by providing operational definitions of11 Specif icat ions for adapt ing  the parser  and  incorporat ing  it into cod ing  sof tware were  formulated,  butnever  imp lemented .120Passonneau and Litman Discourse SegmentationSubjectsAlgorithm Boundary NonboundaryBoundary a b Recall - ~ Fa l lout  = ~ 0 (a -c) (b+d)Nonboundary c d Precision = (a+b)a Error ---- __.._(b+C)(a+b+c+d)F igure  8Information retrieval metrics.a small set of types of inferential links, also fully documented in Passonneau (1994),where infer occurs only if one or more of the bridging inferences occurs.4.1.3 Evaluation.
The segmentation algorithms presented in Section 4.2 are evaluatedby quantifying their performance in segmenting a test set of 10 narratives from ourcorpus.
As discussed above, there is no training data for the algorithms in this section,which are derived from the literature.
These initial results provide us with a baselinefor quantifying improvements resulting from distinct modifications to the algorithms.In contrast, the algorithms presented in section 4.3 are developed using the 10narratives previously used for testing as a training set of narratives.
The algorithms inthis section are developed by tuning the previous algorithms (e.g., by considering bothnew and modified linguistic features) such that performance on the training set is in-creased.
The resulting algorithms are then evaluated by examining their performanceon a separate test set of 5 more narratives.
(The remaining 5 of the 20 narrativesin the corpus are reserved for future research.)
The 10 training narratives range inlength from 51 to 162 phrases (Avg.=101.4), or from 38 to 121 clauses (Avg.=76.8).The 5 test narratives range in length from 47 to 113 phrases (Avg.=87.4), or from 37to 101 clauses (Avg.=69.0).
The ratios of test to training data measured in narratives,prosodic phrases, and clauses, respectively, are 50.0%, 43.1%, and 44.9%.
For the ma-chine learning algorithm we also estimate performance using cross-validation (Weissand Kulikowski 1991), as detailed in Section 4.3.2.
The evaluations in this section allowus to compare the utility of two tuning methods: error analysis, and machine learning.To quantify algorithm performance, we use the information retrieval metrics hownin Figure 8.
Recall is the ratio of correctly hypothesized boundaries to target bound-aries.
Precision is the ratio of hypothesized boundaries that are correct o the totalhypothesized boundaries.
(See Figure 8 for fallout and error.)
These metrics assumethat ideal behavior would be to identify all and only the target boundaries: the valuesfor b and c in Figure 8 would thus both equal 0, representing no errors, u The idealvalues for recall, precision, fallout, and error are 1, 1, 0, and 0, while the worst valuesare 0, 0, 1, and 1.
To get an intuitive summary of overall performance, we also sumthe deviation of the observed value from the ideal value for each metric: (1 - recall)+ (1-precision) + fallout + error.
The summed eviation for perfect performance isthus 0.Finally, to interpret our quantitative r sults, we use the performance ofour humansubjects as a target for the performance ofour algorithms (Gale, Church, and Yarowsky1992).
Table 3 shows the average human performance for both the training and test setsof narratives, for both boundaries identified by at least three and four subjects.
Notethat human performance is basically the same for both sets of narratives.
However, twofactors prevent his performance from being closer to ideal (e.g., recall and precision12 Elsewhere we have discussed problems with the use of IR metrics, given that segmentation is a fuzzyphenomenon.
However, they provide a rough (lower bound) measure of performance.121Computational Linguistics Volume 23, Number 1Table 3Average human performance.Recall Precision Fallout Error Summed DeviationBoundary Threshold = 3Training Set .63 .72 .06 .12 .83Standard Deviation .17 .17 .05 .05 .31Test Set .64 .68 .07 .11 .86Standard Deviation .19 .20 .06 .06 .42Boundary Threshold = 4Training Set .74 .55 .09 .11 .91Standard Deviation .19 .16 .06 .05 .33Test Set .73 .55 .09 .10 .91Standard Deviation .20 .21 .06 .06 .43of 1).
The first is the wide variation in the number of boundaries that subjects used,as discussed above.
The second is the inherently fuzzy nature of boundary location.We discuss this second issue at length in Passonneau and Litman (1996).
In Litmanand Passonneau (1995b), we also present relaxed IR metrics that penalize near missesless heavily (cases where an algorithm does not place a boundary at a statisticallyvalidated boundary location, but does place one within one phrase of the validatedboundary).4.2 Initial HypothesesIn principle, the process of determining whether the statistically validated segmentboundaries correlate with linguistic devices requires a complex search through a largespace of possibilities, depending on what set of linguistic devices one examines, andwhat features are used to recognize and classify them.
Rather than developing amethod to search blindly through the space of possibilities, we first provide an initialevaluation of three linguistic devices whose distribution or surface form has frequentlybeen hypothesized to be conditioned by segmental structure: referential noun phrases,cue words, and pauses.
We evaluate three algorithms, each of which uses featurespertaining to only one of these linguistic devices, in order to see whether linguisticassociations proposed in the literature can be used by natural anguage processingsystems to perform segmentation, and to compare the utility of different knowledgesources.
Unlike most previous work, which typically considers each linguistic devicein isolation, we also evaluate a simple additive method for combining linguistic de-vices, in which a boundary is proposed if each separate algorithm proposes a bound-ary.
As we will see, the performance of our algorithms improves with the amountof knowledge xploited.
The recall of the three algorithms is comparable to humanperformance, the precision much lower, and the fallout and error of only the nounphrase algorithm comparable.
Furthermore, the results on combining algorithms ug-gests that with more sophisticated methods, results approaching human performancecan be achieved.4.2.1 Pauses.
Several studies have demonstrated various correlations between pausesand discourse segment boundaries (Grosz and Hirschberg 1992; Hirschberg and122Passonneau and Litman Discourse Segmentationif pause ~ true then boundaryelse nonboundaryFigure 9Pause algorithm.Site before after pause duration cue1 word1 cue2 word2 corer infer global.pro cue-prosody(22.4,23.1) + t 0.55 t and f NA + + t(23.1,23.2) f 0 t and f NA + + f(23.2,23.3) t 0 t and f NA NA NA NA t(23.3,23.4) + f 0 f NA f NA + + fSite BOUNDARY PAUSE CUE NP EA ML(22.4,23.1) + +(23.1,23.2) +(23.2,23.3) + +(23.3,23.4)Figure 10Statistically validated versus algorithmically derived boundaries.Nakatani 1996; Swerts 1995).
For example, segment-initial phrases have been corre-lated with longer preceding pause durations.
As shown in Figure 9, we used a sim-plification of these results to develop an algorithm for identifying boundaries in ourcorpus using pauses.
13 If a pause occurs at the beginning of the prosodic phrase afterthe potential boundary site, the potential boundary site is classified as boundary andthe phrase is taken to be the beginning of a new segment.Figure 10 shows boundaries assigned by the pause algorithm (PAUSE) for theboundary slot codings from Figure 7, repeated at the top of the figure.
For example,the pause algorithm assigns a boundary between prosodic phrases 22.4 and 23.1, butnot between phrases 23.1 and 23.2.Table 4 shows the average performance of the pause algorithm for statisticallyvalidated boundaries at the .0001 level (those boundaries proposed by at least foursubjects).
Recall is 92% (o = .008; max ~ 1; rain -~ .73), precision is 18% (or = .002;max = .25; rain = .09), fallout is 54% (or = .004; max = .65; rain = .45), and error is49% (o = .004 max = .61; min = .41).
Our algorithm thus performs with recall higherthan human performance.
14 However, precision is low, and both fallout and error arequite high.
The summed deviatio n metric, which takes all the metrics into account,shows that on the whole performance is considerably worse than humans.4.2.2 Cue Words.
Cue words (e.g., now) are words that are sometimes used to explicitlysignal the structure of a discourse.
Hirschberg and Litman (1993) examined a large setof cue words proposed in the literature and showed that certain prosodic and structuralfeatures, including a position of first in prosodic phrase, are highly correlated withthe discourse uses of these words.
As shown in Figure 11, we developed a baselinesegmentation algorithm based on a simplification of these results, using the value ofthe single cue phrase feature cue1.
That is, if a cue word occurs at the beginning of theprosodic phrase after the potential boundary site, the usage is assumed to be discourse.13 Our  init ial  a lgor i thm does not  take the durat ion  of the pause  into account;  pause  durat ion  iscons idered in the a lgor i thms presented  in Section 4.3.2, however .
In addi t ion,  s ince our  segmentat iontask is not  hierarchical ,  we  do not  note  whether  phrases  begin,  end,  suspend,  or resume segments .14 Note that the humans  d id  not  have  access to pause  informat ion.
Other  s tud ies  have  shown that whenboth  speech and  text are ava i lab le  to labelers,  segmentat ion  is clearer (Swerts 1995) and  re l iabi l i tyimproves  (H i rschberg and  Nakatan i  1996).123Computational Linguistics Volume 23, Number 1Table 4Evaluation for Tj >_ 4.Recall Precision Fallout Error Summed DeviationPAUSE .92 .18 .54 .49 1.93CUE .72 .15 .53 .50 2.16NP .50 .31 .15 .19 1.53Humans .74 .55 .09 .11 .91if cue1 = true then boundaryelse nonboundaryFigure 11Cue word algorithm.For (FICUi_I ,  FICUi):i f  (corer = -coref and infer = -infer and global.pro = -global.pro) then boundaryelse nonboundaryFigure 12Referential NP algorithm.Thus the potential boundary site is classified as boundary and the phrase is taken tobe the beginning of a new segment.
Figure 10 shows boundaries (CUE) assigned bythe algorithm.Table 4 shows the average performance of the cue word algorithm.
Recall is 72%(or = .027; max = .88; min = .40), precision is 15% (or = .003; max = .23; min = .04),fallout is 53% (or = .006 max = .60; rain = .42) and error is 50% (o = .005 max = .60;min = .40).
While recall is quite comparable to human performance (row 4), theprecision is low while fallout and error are quite high.4.2.3 Referential Noun Phrases.
The last segmentation algorithm we describe takesas input information about referential NPs.
We refer to this algorithm as NP.
Unlikethe previous algorithms, in NP the potential boundaries are first computed as orderedpairs of adjacent functionally independent clauses (FICUi,FICUi+I; see section 4.1.2)then normalized to ordered pairs of prosodic phrases (see note 10).
NP operates onthe principle that if an NP in the current FICU provides a referential link to thecurrent segment, the current segment continues.
However, NPs and pronouns aretreated ifferently based on the assumption that the referent of a third person definitepronoun is more prominently in focus (cf.
Passouneau \[1994\]).
A third person definitepronoun provides a referential link if its index occurs anywhere in the current segment.Any other NP type provides a referential link if its index occurs in the immediatelypreceding FICU.
Figure 12 illustrates the two decisions made by NP for each pair ofadjacent FICUs.
As described in Section 4.1.2, the corer feature is -coref if no NP inFICUi corefers with an NP in the FICUi_I; the infer feature is -infer if no NP in FICUiis inferentially linked to an NP in FICUi_I; the global.pro feature is -global.pro if FICUicontains no third person definite pronoun coreferring with an NP in any prior FICUup to the last boundary assigned by the algorithm.
If any feature has a positive value,no boundary is assigned; if all have negative values, (FICUi_I,FICUi) is classified as aboundary.124Passonneau and Litman Discourse SegmentationTable 5Additive algorithms.Recall Precision Fallout Error Summed DeviationPAUSE/CUE .69 .29 .29 .29 1.66PAUSE/NP .47 .42 .08 .13 1.42CUE/NP .36 .34 .09 .15 1.59PAUSE/CUE/NP .34 .47 .05 .12 1.43The column headed NP in Figure 10 indicates boundaries assigned by the NPalgorithm.
No boundaries are assigned by NP.
The first three phrases in Figure 7correspond irectly to three consecutive FICUs, and each FICU has an NP coreferringwith an NP in the next; likewise the global.pro feature is present.
However, phrase23.3 is the onset of an FICU that continues through 23.4, so phrase 23.3 is not codedfor NP features.
The coref and global.pro features are present in the FICU that ends in23.4, due to coreference of a pronominal NP with an NP in the preceding FICU (fromphrase 23.2).Table 4 shows the average performance of the referring expression algorithm (rowlabeled NP) on the four measures we use here.
Recall is .50 (?
= .17; max = .71;min = .18), precision is .31 (?
= .097; max = .50; min = .20), fallout is .15 (?
= .06;max = .27; min -- .07) and error rate is 0.19 (~r = .06; max = .31; min = .12).
Recall isworse than PAUSE, CUE and human performance, and precision is better than PAUSEand CUE but worse than human performance.
Note that the error rate and fallout,which in a sense are more robust measures of inaccuracy than precision, are both muchbetter than CUE and PAUSE.4.2.4 Addit ive Algorithms.
We report here evaluation of a simple additive methodfor combining the three algorithms described above.
That is, a boundary is proposedif some combination of the algorithms proposed a boundary.
We tested all pairwisecombinations, and the combination of all three algorithms, as shown in Table 5.
Preci-sion is the most likely metric to be improved.
For a composite algorithm, recall cannotbe increased: if neither NP, PAUSE, nor CUE found a boundary, then no combinationof them can.
However, the composite algorithms use narrower criteria for boundaries,which should reduce the number of false positives.
The precision of the additive al-gorithms is indeed higher than any of the algorithms alone.
PAUSE/NP has the bestadditive algorithm performance as measured by the summed deviation.4.2.5 Discussion.
By using average human performance as a baseline against whichto evaluate algorithms, we are asking whether algorithms perform in a manner thatreflects an abstraction over a population of humans, rather than whether they performlike a typical human.
No algorithm or combination of algorithms performs as well asthis baseline.
The referring expression algorithm (NP) performs better than the otherunimodal algorithms (PAUSE and CUE), and a combination of PAUSE and NP per-forms best.
Our results thus suggest hat accurately predicting discourse segmentationinvolves far more than directly using known linguistic differences between discourseboundaries and nonboundaries, i  Here we analyze some of the likely reasons for our15 Whittaker and Stenton (1988) also show that cue phrases are not reliable for predicting segmentboundaries, and similarly argue for the use of multiple linguistic devices.
In addition, our training data125Computational Linguistics Volume 23, Number 1results, to motivate the methodologies for algorithm improvement presented in thenext section.First, we must take into account the dimensions along which the three algorithmsdiffer, apart from the different types of linguistic information used.
As shown in Fig-ures 9, 11, and 12, NP uses more knowledge than PAUSE and CUE.
PAUSE and CUEeach depend on only a single feature, while NP relies on three features.
Unsurpris-ingly, NP performs most like humans.
For both PAUSE and CUE, the recall is relativelyhigh, but the precision is very low, and the fallout and error rate are both poor.
For NP,recall and precision are not as different, precision is higher than PAUSE and CUE, andfallout and error rate are both relatively low.
These results, as well as the improvedperformance of the additive algorithms, uggest that performance an be improved byconsidering more features.
The algorithms presented in Section 4.3 indeed use morefeatures, as shown in Figure 6.A second dimension to consider in comparing performance is that humans andNP assign boundaries based on a global criterion, in contrast o PAUSE and CUE.Our subjects typically use a relatively gross level of speaker intention.
By default, NPassumes that the current segment continues, and assigns a boundary under relativelynarrow criteria.
However, PAUSE and CUE rely on cues that are relevant at the localas well as the global evel, and consequently assign boundaries more often.
This leadsto a preponderance of cases where PAUSE and CUE propose a boundary but where amajority of humans did not.
However, when either PAUSE or CUE is combined withthe more global NP, as in PAUSE/NP and CUE/NP, we see that performance im-proves.
These results uggest that another way to improve performance is to considermore sophisticated methods for combining features across the three types of linguisticdevices.4.3 Developing New Hypotheses by Combining Multiple Knowledge SourcesIn this section we present wo methods for developing segmentation algorithms thatcombine the features of multiple linguistic devices in more complex ways than sim-ply combining the outputs of independent algorithms.
Our first method relies on ananalysis of the errors made by the best-performing algorithm.
Our second methoduses machine learning tools to automatically construct segmentation algorithms froma large set of input features: features used in our previous experiments, enhancementsto hand-coded features, and new features obtainable automatically from our tran-scripts.
Both methods consider much more knowledge than previously considered byourselves or others, and result in algorithms that exhibit marked improvements in per-formance.
We present our results using two sets of statistically validated boundaries:those derived using a significance level of .0001 (corresponding to Tj ~ 4 subjects,as in the previous ection), and those derived using a less conservative l vel of .02(corresponding to Tj ~ 3 subjects).4.3.1 Error Analysis.
To improve performance, we analyzed the two types of IR errors,defined in Figure 8 above, made by the original NP algorithm on the training data (Pas-sonneau and Litman 1993).
Type "b" errors, misclassification f nonboundaries, werereduced by redefining the coding features pertaining to clauses and NPs.
Most "b"(like previous research) shows that pauses preceding boundaries have average longer durations.
ForTj ~ 3, the average pause duration is.64 (?
= .65) before boundaries, and .39 (rr = 1.70) beforenonboundaries; for Tj ~ 4, the average durations are .72 (?
= .67) and .39 (?
= 1.64), respectively.
Aswill be seen in Section 4.3.2, this correlation does not translate into any high-performing al orithmbased primarily on pause duration.126Passonneau and Litman Discourse SegmentationCI.
Phr.6 3.01 \[1.1 \[.7\] A-nd\] he's not really., doesn't seem to be paying all that much attention7 \[.55?
because \[.45\]\] you know the pearsfalli,8 3.02 and.. he doesn't really notice (f~i),Figure 13Inferential link due to implicit argument.errors correlated with one of two kinds of the information used in the NP algorithm:identification of clauses (FICUs) and of inferential links.
The redefinition of FICU mo-tivated by error analysis led to fewer clauses.
For example, FICU assignment dependsin part on filtering out clausal interjections, utterances that have the syntactic form ofclauses but that function as interjections.
These include phrases like let's see, let me see,I don't know when they occur with no overt or implied verb phrase argument.
The ex-tensional definition of clausal interjections was expanded, thus certain utterances wereno longer classed as FICUs under the revised coding.
Other changes to the definitionof FICUs pertained to sentence fragments, unexpected clausal arguments, and embed-ded speech.
Because the algorithm assigns boundaries between FICUs, reducing thenumber of FICUs in a narrative can reduce the number of proposed boundaries.Error analysis also led to a redefinition of infer, and to the inclusion of new typesof inferential relations that an NP referent might have to prior discourse.
Previously,infer was a relation between the referent of an NP in one utterance, and the referent ofan NP in a previous utterance.
This was loosened to include referential links betweenan NP referent and referents mentioned in, or inferable from, any part of the previousutterance.
For example, discourse deixis (demonstrative reference to a referent deriv-able from prior discourse \[Passonneau 1993; Webber 1991\]) was added to the typesof inferential links to code for.
In the second utterance of The storm is still raging, andthat's why the plane is grounded, the demonstrative pronoun that illustrates an exampleof discourse deixis.
Expanding the definition of infer also reduces the number of pro-posed boundaries: recall that the algorithm does not assign a boundary if there is aninferential link between an NP in the current utterance unit and the prior utteranceunit.Three types of inference relations linking successive clauses (Ci-1, Ci) were added(originally there were five types \[Passonneau 1994\]).
Now, a pronoun (e.g., it, that, this)in Ci referring to an action, event, or fact inferable from Ci-1 provides an inferentiallink.
So does an implicit argument, as in Figure 13, where the missing argument ofnotice is inferred to be the event of the pears falling.
The third case is where an NPin Ci is described as part of an event that results directly from an event mentionedin Ci-1.Misclassification fboundaries ("c" type errors; see Figure 8) often occurred whereprosodic and cue features conflicted with NP features.
The original NP algorithmassigned boundaries wherever the three values -coref, -infer, -global.pro co-occurred.Experiments led to the hypothesis that the most improvement came by assigning aboundary if the cue-prosody feature had the value complex, even if the algorithm wouldnot otherwise assign a boundary, as shown in Figure 14.
See Figure 10 for boundariesassigned by the resulting algorithm (EA, for error analysis).Table 6 presents the average IR scores across the narratives in the training set forthe NP and EA algorithms.
The top half of the table reports results for boundaries thatat least three subjects agreed upon (T = 3), and the lower half for boundaries using athreshold value of 4 (T = 4), where NP duplicates the figures from Table 4.
Going bythe summed eviations, the overall performance is about he same, although variationaround the mean is lower for T = 4.
The figures illustrate a typical tradeoff between127Computational Linguistics Volume 23, Number 1if (corer = -coref and infer ~- -infer and global.pro = -global.pro) then boundaryelseif cue-prosody ~ complex then boundaryelse nonboundaryFigure 14EA algorithm.Table 6Performance on training set.Average Recall Precision Fallout Error Summed DeviationBoundary Threshold = 3NP .42 .40 .14 .22 1.54Standard Deviation .18 .12 .06 .07 .34EA .58 .62 .08 .14 1.02Standard Deviation .14 .10 .04 .05 .18Boundary Threshold = 4NP .50 .31 .15 .19 1.53Standard Deviation .17 .10 .06 .06 .23EA .70 .47 .10 .12 1.05Standard Deviation .16 .06 .04 .03 .15Table 7Performance on test set.Average Recall Precision Fallout Error Summed DeviationBoundary Threshold = 3NP .44 .29 .16 .21 1.64Standard Deviation .18 .17 .07 .05 .32EA .50 .44 .11 .17 1.34Standard Deviation .21 .06 .03 .04 .29Boundary Threshold = 4NP .56 .25 .16 .20 1.55Standard Deviation .29 .15 .08 .05 .23EA .60 .37 .11 .15 1.30Standard Deviation .20 .05 .03 .02 .17precision and recall; where one goes up, the other goes down.
All scores are better forEA.Table 7 shows the results of the tuned algorithm on the 5 randomly selected testnarratives for NP and EA.
Performance on the test set is slightly better overall forT = 4, as shown by lower summed deviations.
The NP results are very similar to thetraining set except hat precision is worse.
Thus, despite the high standard eviations,10 narratives eems to have been a sufficient sample size for evaluating the initial NPalgorithm.
EA results are better than NP in Table 7 or Table 6.
This is strong evidencethat the tuned algorithm is a better predictor of segment boundaries than the original128Passonneau and Litman Discourse SegmentationNP algorithm.
The test results of EA are, of course, worse than the correspondingtraining results, particularly for precision (.44 versus .62).
This confirms that the tunedalgorithm is over calibrated to the training set.
Using summed deviations as a sum-mary metric, EA's improvement is about 1/3 of the distance between NP and humanperformance.The standard deviations in Tables 6 and 7 are often close to 1/4 or 1/3 of thereported averages.
This indicates a large amount of variability in the data, reflectingwide differences across narratives (speakers) in the training set with respect o thedistinctions recognized by the algorithm.
Although the high standard eviations howthat the tuned algorithm is not well fitted to each narrative, it is likely that it is overspecialized to the training sample in the sense that test narratives are likely to exhibitfurther variation.4.3.2 Machine Learning.
While error analysis is a useful method for refining an ex-isting feature representation, it does not facilitate experimentation with large sets ofmultiple features imultaneously.
To address this, we turned to machine learning toautomatically develop algorithms from large numbers of both training examples andfeatures.We use the machine learning program C4.5 (Quinlan 1993) to automatically de-velop segmentation algorithms from our corpus of coded narratives, where each po-tential boundary site has been classified and represented as a set of linguistic features.The first input to C4.5 specifies the names of the classes to be learned (boundary andnonboundary), and the names and potential values of a fixed set of coding features(Figure 6).
The second input is the training data, i.e., a set of examples for which theclass and feature values (as in Figure 7) are specified.
Our training set of 10 narrativesprovides 1004 examples of potential boundary sites.
The output of C4.5 is a classifi-cation algorithm expressed as a decision tree, which predicts the class of a potentialboundary given its set of feature values.Because machine learning makes it convenient to induce decision trees undervarious conditions, we have performed numerous experiments varying the number offeatures used, the definitions used for classifying a potential boundary site as boundaryor nonboundary and the options available for running the C4.5 program.
Figure 15shows one of the highest-performing learned decision trees from our experiments.This decision tree was learned under the following conditions: all of the featuresshown in Figure 6 were used to code the training data, boundaries were classifiedusing a threshold of three subjects, and C4.5 was run using only the default options.
16The decision tree predicts the class of a potential boundary site based on the featuresbefore, after, duration, cue1, wordt, corer, infer, and global.pro.
Note that although not allavailable features are used in the tree, the included features represent three of the fourgeneral types of knowledge (prosody, cue phrases, and noun phrases).
Each level ofthe tree specifies a test on a single feature, with a branch for every possible outcome of16 The manually derived segmentation algorithm evaluates boundary assignment incrementally, i.e.,utterance-by-utterance, after computing the features for the current utterance (or FICU).
This allowsrelative information about previous boundaries to be used in deriving the global.pro feature.
Byallowing machine learning to use global.pro, we are testing whether characterizing the use of referringexpressions (certain pronouns) in terms of relative knowledge about segments (whether the currentreferent was already mentioned in the current segment) is useful for classifying the current boundarysite.
Although none of the other features are derived using classification knowledge of any otherpotential boundary sites, note that global.pro does not encode the boundary/nonboundary classification ofthe particular site in question.
Furthermore, ven when machine learning does not use global.pro (aswith the "Learning 2" algorithm discussed below), performance does not suffer.129Computational Linguistics Volume 23, Number 1if before = -sentence.final.contour then nonboundaryelseif before = +sentence.final.contour thenif corer ~ NA then nonboundaryelseif corer = +coref theni f  after = +sentence.final.contour theni f  duration < 1.3 then nonboundaryelseif duration > 1.3 then boundaryelseif after = -sentence.final.contour theni f  word1 E {also,basically, because,finally, first,like,meanwhile,no,oh,okay, only, see,so,well,where,NA }then nonboundaryelseif word1 C {anyway, but,now, or, then} then boundaryelseif word 1 = and theni f  duration < 0.6 then nonboundaryelseif duration > 0.6 then boundaryelseif corer = -coref theni f  infer = +infer then nonboundaryelseif infer = NA then boundaryelseif infer ~ -infer theni f  after = -sentence.final.contour then boundaryelseif after = +sentence.final.contour thenif cue1 = true theni f  global.pro ~ NA then boundaryelseif global.pro = -global.pro then boundaryelseif global.pro = +global.pro thenif duration < 0.65 then nonboundaryelseif duration > 0.65 then boundaryelseif cuel = false thenif duration > 0.5 then nonboundaryelseif duration < 0.5 theni f  duration < O.35 then nonboundaryelseif duration > 0.35 then boundaryFigure 15Learned decision tree for segmentation.the test} 7A branch can either lead to the assignment of a class, or to another test.
Forexample, the tree initially branches based on the value of the feature before.
If the valueis -sentence.final.contour then the first branch is taken and the potential boundary siteis assigned the class nonboundary.
If the value of before is +sentence.final.contour thenthe second branch is taken and the feature coref is tested.
Figure 10 illustrates sampleoutput of this algorithm (ML).The performance of this learned decision tree averaged over the 10 training narra-tives is shown in Table 8, on the line labeled "Learning 1".
The line labeled "Learning2" shows the results from another machine learning experiment, in which one of thedefault C4.5 options used in "Learning 1" is overridden.
The default C4.5 approach cre-ates a separate subtree for each possible feature value; as detailed in Quinlan (1993),this approach might not be appropriate when there are many values for a feature,which is true for features such as word1 and word2.
In "Learning 2" C4.5 allows featurevalues to be grouped into one branch of the decision tree.
While the "Learning 2"tree is more complex than the tree of Figure 15, it does have slightly better perfor-mance.
The "Learning 2" decision tree predicts the class of a potential boundary sitebased on the features before, duration, cue1, word1, word2, corer, infer, and cue-prosody.At T = 3, "Learning 1" performance is comparable to human performance (Table 3),and "Learning 2" is slightly better than humans; at T = 4, both learning conditionsare superior to human performance.
The results obtained via machine learning arealso better than the results obtained using error analysis (EA in Table 6), primarily17 The actual tree branches on every  va lue of word1; the figure merges  these branches for clarity.130Passonneau and Litman Discourse SegmentationTable 8Performance on training set.Average Recall Precision Fallout Error Summed DeviationBoundary Threshold = 3Learning 1 .54 .76 .04 .11 .85Standard Deviation .18 .12 .02 .04 .28Learning 2 .59 .78 .03 .10 .76Standard Deviation .22 .12 .02 .04 .29Boundary Threshold = 4Learning 1 .47 .84 .01 .07 .77Standard Deviation .26 .18 .02 .04 .42Learning 2 .53 .77 .02 .07 .79Standard Deviation .23 .18 .02 .03 .35due to better precision.
In general, the machine learning results have slightly greatervariation around the average.The performance ofthe learned ecision trees averaged over the 5 test narratives ishown in Table 9.
Comparison of Tables 8 and 9 shows that, as with the error analysisresults (and as expected), average performance is worse when applied to the testingrather than the training data, particularly with respect to precision.
However, the bestmachine learning performance is an improvement over our previous best results (EAin Table 7).
For T ~ 3, "Learning 1" is comparable to EA while "Learning 2" is better.For T = 4, EA is better than "Learning 1", but "Learning 2" is better still.
However,as with the training data, EA has somewhat less variation around the average.We also use the resampling method of cross-validation (Weiss and Kulikowski1991) to estimate performance, which averages results over multiple partitions of asample into test versus training data.
We performed 10 runs of the learning program,each using 9 of the 10 training narratives for that run's training set (for learning thetree) and the remaining narrative for testing.
Note that for each iteration of the cross-validation, the learning process begins from scratch and thus each training and testingset are still disjoint.
While this method oes not make sense for humans, computers cantruly ignore previous iterations.
For sample sizes in the hundreds (our 10 narrativesprovide 1004 examples) 10-fold cross-validation ften provides a better performanceestimate than the hold-out method (Weiss and Kulikowski 1991).
Results using cross-validation are shown in Table 10, and are better than the estimates obtained using thehold-out method (Table 9), with tlle major improvement coming from precision.Finally, Table 11 shows the results from a set of additional machine learning ex-periments, in which more conservative definitions of boundary are used.
For example,using a threshold of seven subjects yields the set of consensus boundaries, as definedin Hirschberg and Nakatani (1996).
Comparison with Table 9 shows that for T = 5,"Learning 1" rather than "Learning 2" is the better performer.
However, the moreinteresting result is that for T = 6 and T = 7, the learning approach as an importantlimitation with respect o the boundary classification task.
In particular, the way inwhich C4.5 minimizes error rate is not an effective strategy when the distribution ofthe classes is highly skewed.
For both T = 6 and T = 7, extremely few of the 1004training examples are classified as boundary (40 and 19 examples, respectively).
C4.5131Computational Linguistics Volume 23, Number 1Table 9Performance on test set.Average Recall Precision Fallout Error Summed DeviationBoundary Threshold = 3Learning 1 .43 .48 .08 .16 1.34Standard Deviation .21 .13 .03 .05 .36Learning 2 .47 .50 .09 .16 1.27Standard Deviation .18 .16 .04 .07 .42Boundary Threshold = 4Learning 1 .31 .41 .06 .13 1.47Standard Deviation .29 .15 .08 .05 .23Learning 2 .39 .52 .05 .11 1.24Standard Deviation .20 .05 .03 .02 .17Table 10Using 10-fold cross-validation.Average Recall Precision Fallout Error Summed DeviationBoundary Threshold = 3Learning 1 .43 .63 .05 .15 1.14Standard Deviation .19 .16 .03 .03 .24Learning 2 .46 .61 .07 .15 1.15Standard Deviation .20 .14 .04 .03 .21Boundary Threshold = 4Learning 1 .30 .71 .02 .10 1.11Standard Deviation .15 .19 .02 .03 .26Learning 2 .35 .52 .04 .11 1.28Standard Deviation .19 .24 .02 .04 .40minimizes the error rate by always predicting nonboundary.
For example, for T -= 6,because only 4% of the training examples are boundaries, C4.5 achieves an error rateof 4% by always predicting nonboundary.
However,  this low error rate is achieved atthe expense of the other metrics.
Using the terminology of Figure 8, since the algo-r ithm never predicts the class boundary, it is necessarily the case that a = 0, b = 0,recall = 0, and precision is undefined ("-" in Table 11).
In addition, for T = 7, 2 of the5 test sets happen to contain no boundaries; for these cases c = 0 and thus the value ofrecall is also sometimes undefined.
The problem of unbalanced ata is not unique tothe boundary  classification task.
Current work in machine learning is exploring waysto induce patterns relevant o the minority class, for example, by allowing users toexplicitly specify different penalties for false positive and false negative errors (Lewisand Catlett 1994).
(In contrast, C4.5 assumes that both types of errors are penalizedequally.)
Other researchers (e.g., Hirschberg \[1991\]) have proposed sampling the ma-jority class examples in a training set in order to produce a more balanced trainingsample.132Passonneau and Litman Discourse SegmentationTable 11Performance on test set for higher boundary thresholds.Average Recall Precision Fallout Error Summed DeviationBoundary Threshold = 5Learning 1 .31 .46 .03 .08 1.35Standard Deviation .11 .30 .02 .02 .43Learning 2 .28 .39 .04 .08 1.46Standard Deviation .17 .24 .03 02 .45Boundary Threshold = 6Learning 1 0 0 .04Standard Deviation 0 0 .02Learning 2 0 0 .04Standard Deviation 0 0 .02Boundary Threshold = 7Learning 1 0 .02Standard Deviation 0 .02Learning 2 0 .02Standard Deviation 0 .02Table 12Paired comparison of EA and automated algorithmresults, using Student's T (df=4).Boundary Threshold = 4Comparison Metric ProbabilityEA with Learning 1 Recall p < .20EA with Learning 1 Fallout p < .10EA with Learning 2 Recall p < .25EA with Learning 2 Error p < .20Boundary Threshold = 3EA with Learning 1 Precision p < .0005EA with Learning 1 Error p < .104.3.3 Discussion.
We have presented two methods for developing segmentation hy-potheses using multiple linguistic features.
The first method, error analysis, tunesfeatures and algorithms based on analysis of training errors.
The second method, ma-chine learning, automatically induces.decision trees from coded corpora.
Both methodsrely on an enriched set of input features compared to our previous work.
With eachmethod, we have achieved marked improvements in performance compared to ourprevious work and are approaching human performance.
Quantitatively, the machinelearning versus EA methods differ only on certain metrics, and bear a somewhat in-verse relation to one another for boundaries defined by T _ 4 versus T ~ 3.
Table 12,which shows comparisons between EA and the two machine learning conditions, in-dicates which differences are statistically significant by indicating the probabil ity of133Computational Linguistics Volume 23, Number 1a paired comparison on each of the 5 test narratives using Student's t test.
For theT = 4 boundaries, the superior recall of EA compared with conditions 1 and 2 ofthe automated algorithms is significant.
Conversely, the superior fallout of condition1 and superior error rate of condition 2 are significant.
For the T = 3 boundaries,the differences are not statistically significant for condition 2, but for condition 1, pre-cision and error rate are both superior, and the difference as compared with EA isstatistically significant.
The largest and the most statistically significant difference isthe higher precision of the condition 1 automated algorithm.
Qualitatively, the algo-rithms produced by error analysis are more intuitive and easier to understand thanthose produced by machine learning.
Furthermore, note that the machine learning al-gorithm used the changes to the coding features that resulted from the error analysis.This suggests that error analysis is a useful method for understanding how to bestcode the data, while machine learning provides a cost-effective (and automatic) wayto produce an optimally performing algorithm given a good feature representation.5.
Conclusion and Future DirectionsOur initial hypotheses regarding discourse segmentation were that multiutterance s g-ment units reflect discourse coherence, and that while the semantic dimensions of thiscoherence may vary, it arises partly from consistency in the speaker's communica-tive goals (Grosz and Sidner 1986; Polanyi 1988).
The results from the first part ofour study (Section 3) support hese hypotheses.
On a relatively unconstrained linearsegmentation task, the number of times different naive subjects identify the same seg-ment boundaries in a given narrative transcript is extremely significant.
Across the20 narratives, statistical significance arises where at least three or four out of sevensubjects agree on the same boundary location, depending on an arbitrary choice be-tween probabilities of .02 versus .0001 as the significance threshold.
We conclude thatthe segment boundaries identified by at least three or four of our subjects provide astatistically validated annotation to the narrative corpus corresponding to segmentshaving relatively coherent communicative goals.Before making concluding remarks on part two of our study, we mention a fewquestions for future work on segmentation.
We believe our results confirm the utilityof abstracting from the responses of relatively many naive subjects (our method), andindicate a strong potential for developing coding protocols using smaller numbersof trained coders (as in Nakatani, Hirschberg, and Grosz \[1995\], and Hirschberg andNakatani \[1996\]).
The use of an even larger number of naive subjects might yield afiner-grained set of segments (cf.
Rotondo \[1984\], Swerts, \[1995\]).
This is an importantdimension of difference between the two sets of segments we use: segments identifiedby a minimum of four subjects are larger and fewer in number than those identifiedby a minimum of three.
In addition, performance can be improved by taking intoaccount hat some segment boundary locations may be relatively fuzzy, as we discussin Passonneau and Litman (1996).
Finally, differences in segmentation may reflectdifferent interpretations of the discourse, as we pointed out in Passonneau and Litman(1996), based on observations of our subjects' segment descriptions.The second part of our study (Section 4) concerned the algorithmic identificationof segment boundaries based on various combinations of three types of linguistic in-put: referential noun phrases, cue phrases, and pauses.
We first evaluated an initialset of three algorithms, each based on a single type of linguistic input, and their addi-tive combinations.
Our results showed that the algorithms performed quite differentlyfrom one another on boundaries identified by at least four subjects on a test set of10 narratives from our corpus.
In particular, the NP algorithm (which used three fea-134Passonneau and Litman Discourse Segmentationtures) outperformed both the cue phrase and pause algorithms (each of which usedonly a single feature).
While none of the algorithms approached human performance,the fact that performance improved with the number of features coded, and by com-bining algorithms in a simple additive way, suggested irections for improvement.
Weapplied two training methods, error analysis and machine learning, to the previoustest set of 10 narratives.
Richer linguistic input and more sophisticated methods ofcombining linguistic data led to significant improvements in performance when thenew algorithms were evaluated on a test set of 5 new narratives.
The best-performingalgorithm resulted from the machine learning experiment in which certain default op-tions were overridden ("Learning 2" in Table 9).
For the T = 4 boundary set, "Learning2" recall was 53% as good as humans, precision was 95% as good, fallout was betterthan humans, and error (11%) was almost as low as that of humans (10%).
Thus themain need for improvement is in recall.A comparison of results on two sets of boundaries, those identified by at leastthree, versus those identified by at least four subjects, shows roughly comparableperformance.
The "Learning 1" algorithm performs better on the set defined by T = 3(Table 9); Error Analysis (Table 7) and "Learning 2" (Table 9) perform better on theT = 4 set.
We have not yet determined what causes these differences, although in anearly paper on our pilot study, we reported that there is a strong tendency for recallto increase and precision to decrease as boundary strength increases (Passonneau andLitman 1993).
On the one hand, performance was consistently improved by enrichingthe linguistic input.
On the other hand, there is wide performance variation around themean.
Despite this variation, as we pointed out in Litman and Passonneau (1995a),there are certain narratives that the NP, EA, and both machine learning algorithmsperform similarly well, or poorly, on.
These observations indicate a need for furtherresearch regarding the interaction among variation in speaker style, granularity ofsegmentation, and richness of the linguistic input.Finally, while our results are quite promising, how generally applicable are they,and do results such as ours have any practical import?
As discussed in Section 2, theability both to segment discourse and to correlate segmentation with linguistic deviceshas been demonstrated in dialogues and monologues, using both spoken and writtencorpora, across a wide variety of genres (e.g., task-oriented, advice-giving, information-query, expository, directions, and newspapers).
Studies such as these suggest hat ourmethodologies and/or results have the potential of being applicable to more thanspontaneous narrative monologues.As for the utility of our work, even though the algorithms in this paper were pro-duced using some features that were manually coded, once developed, they could beused in reverse to enhance the comprehensibility of text generation systems or the nat-uralness of text-to-speech systems that already attempt o convey discourse structure(e.g., systems uch as Moore and Paris \[1993\], and Hirschberg \[1990\]).
For example,given the algorithm shown in Figure 14, a generation system could better convey itsdiscourse boundaries by constructing associated utterances where the values of corer,infer, and global.pro are as shown in the first line of the figure, or, for a spoken lan-guage system, where the value of cue-prosody is complex.
In related work, we havetested the hypothesis that the use of a discourse focus structure based on the Pearsegmentation data improves performance of a generation algorithm, thus providing aquantitative measure of the utility of the segmentation data (Passonneau 1996).
Therewe present results of an evaluation of an NP generation algorithm under various con-ditions.
The input to the algorithm consisted of semantic information about utterancesin a Pear narrative, such as the referents mentioned in the utterance.
Output was eval-uated against what the human narrator actually said.
When the input to the algorithm135Computational Linguistics Volume 23, Number 1included a grouping of discourse referents into focus spaces derived from discoursesegments, performance improved by 50%.In addition, if our results were fully automated, they could also be used to en-hance the ability of understanding systems to recognize discourse structure, which inturn improves tasks such as information retrieval (Hearst 1994) and plan recognition(Litman and Allen 1990).
Recent results suggest hat many of our manually codedfeatures have the promise of being automatically coded.
Given features largely out-put by a speech recognition system, Wightman and Ostendorf (1994) automaticallyrecognize prosodic phrasing with 85-86% accuracy; this accuracy is only slightly lessthan human-human accuracy.
Similarly, although our spoken corpus was manuallytranscribed, this could have been automated using speech recognition (although thiswould introduce further sources of error).
In Aone and Bennett (1995), machine learn-ing is used to automatically derive anaphora resolution algorithms from automaticallyproduced feature representations; the learned algorithms outperform a manually de-rived system (whose average recall and precision was 66.5% and 72.9%, respectively).Finally, the results of Litman (1996) show that there are many alternatives to the cuephrase algorithm used here, including some that use feature sets that can be fullycoded automatically.AcknowledgmentsThe authors wish to thank J. Catlett,W.
Chafe, K. Church, W. Cohen, J. DuBois,B.
Gale, V. Hatzivassiloglou, M. Hearst,J.
Hirschberg, D. Lewis, K. McKeown, andE.
Siegel for helpful comments, references,and resources.
We wholeheartedly thank theanonymous reviewers for their verythorough commentary.
Both authors' workwas partially supported by DARPA andONR under contract N00014-89-Jq782;Passonneau was also partly supported byNSF grants IRI-91-13064 and IRI-95-28998.Passonneau's work was not conductedunder Bellcore auspices.ReferencesAbney, Steven P. 1990.
Rapid incrementalparsing with repair.
In Proceedings ofthe6th New OED Conference: Electronic TextResearch, pages 1-9.Anderson, Anne H., M. Bader, E. G. Bard,E.
Boyle, G. Doherty, S. Garrod, S. Isard,J.
Kowtko, J. McAllister, J. Miller,C.
Sotillo, H. S. Thompson, andR.
Weinert.
1991.
The HCRC Map Taskcorpus.
Language and Speech, 34:351-366.Aone, Chinatsu and Scott W. Bennett.
1995.Evaluating automated and manualacquisition of anaphora resolutionstrategies.
In Proceedings ofthe 33rd AnnualMeeting, pages 122-129.
Association forComputational Linguistics.Brieman, Leo, J. Friedman, R. Olshen, andC.
Stone.
1984.
Classij~'cation a d RegressionTrees.
Wadsworth and Brooks.Butterworth, Brian.
1980.
Evidence frompauses in speech.
In Brian Butterworth,editor, Language Production.
AcademicPress, London, pages 155-176.Carberry, Sandra.
1990.
Plan Recognition iNatural Language Dialogue.
MIT Press,Cambridge, MA.Carletta, Jean.
1996.
Assessing agreement onclassification tasks: The kappa statistic.Computational Linguistics, 22(2):249-254.Chafe, Wallace L. 1980.
The Pear Stories:Cognitive, Cultural and Linguistic Aspects ofNarrative Production.
Ablex PublishingCorporation, Norwood, NJ.Cochran, William G. 1950.
The comparisonof percentages in matched samples.Biometrika, 37:256-266.Cohen, Robin.
1984.
A computational theoryof the function of clue words in argumentunderstanding.
In Proceedings ofCOLING84, pages 251-258, Stanford.Dale, Robert.
1992.
Generating ReferringExpressions.
MIT Press, Cambridge, MA.Duncan, Starkey D. and Donald W. Fiske.1977.
Face-to-face Interaction.
LawrenceErlbaum Associates, Hillside, NJ.Flammia, Giovanni and Victor Zue.
1995.Empirical evaluation of humanperformance and agreement in parsingdiscourse constituents in spokendialogue.
In Eurospeech 1995.Gale, William, Ken W. Church, and DavidYarowsky.
1992.
Estimating upper andlower bounds on the performance ofword-sense disambiguation programs.
InProceedings ofthe 30th Annual Meeting,pages 249-256, Newark, DE.
Associationfor Computational Linguistics.Grosz, Barbara J.
1977.
The Representation a d136Passonneau and Litman Discourse SegmentationUse of Focus in Dialogue Understanding.Ph.D.
thesis, University of California,Berkeley.Grosz, Barbara and Julia Hirschberg.
1992.Some intonational characteristics ofdiscourse structure.
In Proceedings oftheInternational Conference on Spoken LanguageProcessing (ICSLP).Grosz, Barbara J., Aravind K. Joshi, andScott Weinstein.
1995.
Centering: Aframework for modeling the localcoherence of discourse.
ComputationalLinguistics, 21(2):203-226.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions and thestructure of discourse.
ComputationalLinguistics, 12:175-204.Hearst, Marti A.
1993.
TextTiling: Aquantitative approach to discoursesegmentation.
Technical Report 93/24,Sequoia 2000 Technical Report, Universityof California, Berkeley.Hearst, Marti A.
1994.
Multi-paragraphsegmentation f expository text.
InProceedings ofthe 32nd Annual Meeting,pages 9-16.
Association forComputational Linguistics.Hindle, Donald.
1983.
Deterministic parsingof syntactic non-fluencies.
In Proceedings ofthe 21st Annual Meeting, pages 123-128.Association for ComputationalLinguistics.Hirschberg, Julia.
1990.
Accent anddiscourse context: Assigning pitch accentin synthetic speech.
In Proceedings oftheEighth National Conference on ArtificialIntelligence (AAAD, pages 952-957.Hirschberg, Julia.
1991.
Using text analysisto predict intonational boundaries.
InProceedings ofthe Second EuropeanConference on Speech Communication a dTechnology.Hirschberg, Julia and Diane Litman.
1993.Empirical studies on the disambiguationof cue phrases.
Computational Linguistics,19(3):501-530.Hirschberg, Julia and Christine H. Nakatani.1996.
A prosodic analysis of discoursesegments in direction-giving monologues.In Proceedings ofthe 34th Annual Meeting,pages 286-293.
Association forComputational Linguistics.Hirschberg, Julia and Janet Pierrehumbert.1986.
The intonational structuring ofdiscourse.
In Proceedings ofthe 24th AnnualMeeting, pages 136-144.
Association forComputational Linguistics.Hobbs, Jerry R. 1979.
Coherence andcoreference.
Cognitive Science, 3(1):67-90.Hwang, Chung H. and Lehnart K. Schubert.1992.
Tense trees as the 'fine structure' ofdiscourse.
In Proceedings ofthe 30th AnnualMeeting, pages 232-240.
Association forComputational Linguistics.Isard, Amy and Jean Carletta.
1995.Replicability of transaction and actioncoding in the Map Task Corpus.
In AAAI1995 Spring Symposium Series: EmpiricalMethods in Discourse Interpretation andGeneration, pages 60-66.Kozima, Hideki.
1993.
Text segmentationbased on similarity between words.
InProceedings ofthe 31st Annual Meeting(Student Session), pages 286-288.Association for ComputationalLinguistics.Krippendorff, Klaus.
1980.
Content Analysis.Sage Publications, Beverly Hills, CA.Levy, Elena.
1984.
Communicating ThematicStructure in Narrative Discourse: The Use ofReferring Terms and Gestures.
Ph.D. thesis,University of Chicago.Lewis, David D. and Jason Catlett.
1994.Heterogeneous ncertainty sampling forsupervised learning.
In W. W. Cohen andH.
Hirsh, editors, Proceedings oftheEleventh International Conference on MachineLearning (ML-94), pages 148-156.
MorganKaufmann.Linde, Charlotte.
1979.
Focus of attentionand the choice of pronouns in discourse.In T. Giv6n, editor, Syntax and Semantics:Discourse and Syntax.
Academic Press,New York, pages 337-354.Litman, Diane J.
1994.
Classifying cuephrases in text and speech using machinelearning.
In Proceedings ofthe 12th NationalConference on Artificial Intelligence (AAAI),pages 806-813.Litman, Diane J.
1996.
Cue phraseclassification using machine learning.Journal of Arti~'cial Intelligence Research,5:53-94.Litman, Diane J. and James Allen.
1990.Discourse processing and commonsenseplans.
In P. R. Cohen, J. Morgan, andM.
E. Pollack, editors, Intentions inCommunication.
MIT Press, Cambridge,MA.Litman, Diane J. and Rebecca J. Passonneau.1995a.
Combining multiple knowledgesources for discourse segmentation.
IProceedings ofthe 33rd Annual Meeting,pages 108-115.
Association forComputational Linguistics.Litman, Diane J. and Rebecca J. Passonneau.1995b.
Developing algorithms fordiscourse segmentation.
I  AAAI 1995Spring Symposium Series: Empirical Methodsin Discourse Interpretation and Generation,pages 85-91.Mann, William C. and Sandra Thompson.137Computational Linguistics Volume 23, Number 11988.
Rhetorical structure theory: towardsa functional theory of text organization.TEXT, 8:243-281.Marslen-Wilson, William, Elena Levy, andLorraine K. Tyler.
1982.
Producinginterpretable discourse: The establishmentand maintenance of reference.
In R. J.Jarvella and W. Klein, editors, Speech,Place and Action.
John Wiley and SonsLtd., New York, pages 339-378.Mokros, Hartmut B.
1984.
Patterns ofPersistence and Change in the Sequencing ofNonverbal Actions.
Ph.D. thesis, Universityof Chicago.Moore, Johanna D. and Cecile Paris.
1993.Planning text for advisory dialogues:Capturing intentional and rhetoricalinformation.
Computational Linguistics,19:652-694.Moore, Johanna D. and Martha E. Pollack.1992.
A problem for RST: The need formultMevel discourse analysis.Computational Linguistics, 18(4):537-544.Morris, Jane and Graeme Hirst.
1991.Lexical cohesion computed by thesauralrelations as an indicator of the structureof text.
Computational Linguistics, 17:21-48.Moser, Megan and Johanna Moore.
1995.Investigating cue selection and placementin tutorial discourse.
In Proceedings ofthe33rd Annual Meeting, pages 130-135.Association for ComputationalLinguistics.Moser, Megan, Johanna D. Moore, and ErinGlendening.
1995.
Instructions for codingSherlock explanations: Identifyingsegments, relations and minimal units.Technical Report 96-17, University ofPittsburgh, Department of ComputerScience.Nakatani, Christine H., Julia Hirschberg,and Barbara J. Grosz.
1995.
Discoursestructure in spoken language: Studies onspeech corpora.
In AAAI 1995 SpringSymposium Series: Empirical Methods inDiscourse Interpretation and Generation,pages 106-112.Passonneau, Rebecca J.
1993.
Getting andkeeping the center of attention.
InR.
Weischedel and M. Bates, editors,Challenges inNatural Language Processing.Cambridge University Press.Passonneau, Rebecca J.
1994.
Protocol forcoding discourse referential noun phrasesand their antecedents.
Technical report,Columbia University.Passonneau, Rebecca J.
1996.
Usingcentering to relax Gricean informationalconstraints on discourse anaphoric nounphrases.
Language and Speech, 39:229-264.Passonneau, Rebecca J. and Diane J. Litman.1993.
Intention-based segmentation:Human reliability and correlation withlinguistic cues.
In Proceedings ofthe 31stAnnual Meeting, pages 148-155.Association for ComputationalLinguistics.Passonneau, Rebecca J. and Diane J. Litman.1996.
Empirical analysis of threedimensions of spoken discourse:Segmentation, coherence and linguisticdevices.
In E. Hovy and D. Scott, editors,Computational nd Conversational Discourse.Springer Verlag, Berlin.Pierrehumbert, Janet and Julia Hirschberg.1987.
The meaning of intonationalcontours in the interpretation ofdiscourse.
Technical Report TM11225-870325-07, AT&T Bell Laboratories.Pitrelli, J., Mary Beckman, and JuliaHirschberg.
1994.
Evaluation of prosodictranscription labeling reliability in theToBI framework.
In Proceedings oflCSLP.Polanyi, Livya.
1988.
A formal model ofdiscourse structure.
Journal of Pragmatics,12:601-638.Quinlan, John Ross.
1993.
C4.5: Programs forMachine Learning.
Morgan Kaufmann.Reichman, Rachel.
1985.
Getting Computers toTalk Like You and Me.
MIT Press,Cambridge, MA.Reynar, Jeffrey C. 1994.
An 'automaticmethod of finding topic boundaries.
InProceedings ofthe 32nd Annual Meeting(Student Session), pages 331-333.Association for ComputationalLinguistics.Rotondo, John A.
1984.
Clustering analysisof subject partitions of text.
DiscourseProcesses, 7:69-88.Song, Fei and Robin Cohen.
1991.
Tenseinterpretation i  the context of narrative.In Proceedings ofthe 9th AAAI, pages131-136.Stifleman, Lisa J.
1995.
A discourse analysisapproach to structured speech.
In AAAI1995 Spring Symposium Series: EmpiricalMethods in Discourse Interpretation andGeneration, pages 162-167.Swerts, Marc.
1995.
Combining statisticaland phonetic analyses of spontaneousdiscourse segmentation.
I  Proceedings ofthe 12th International Congress of PhoneticSciences (ICPhS 95), volume 4, pages208-211.Swerts, Marc and Mari Ostendorf.
1995.Discourse prosody in human-machineinteractions.
In ESCA Workshop on SpokenDialogue Systems, pages 205-208.Walker, Marilyn A.
1995.
Limited attentionand discourse structure.
ComputationalLinguistics, 22(2):255-264.138Passonneau and Litman Discourse SegmentationWalker, Marilyn and Steve Whittaker.
1990.Mixed initiative in dialogue: Aninvestigation i to discourse segmentation.In Proceedings ofthe 28th Annual Meeting,pages 70-78.
Association forComputational Linguistics.Webber, Bonnie L. 1988.
Tense as discourseanaphor.
Computational Linguistics,14:113-122.Webber, Bonnie L. 1991.
Structure andostension in the interpretation ofdiscourse deixis.
Language and CognitiveProcesses, 6.2:107-135.Weiss, Sholom M. and Casimir Kulikowski.1991.
Computer Systems that Learn:Classification and Prediction Methods fromStatistics, Neural Nets, Machine Learning,and Expert Systems.
Morgan Kaufmann.Whittaker, Steve and Phil Stenton.
1988.Cues and control in expert-clientdialogues.
In Proceedings ofthe 26th Annu'alMeeting, pages 123-130.
Association forComputational Linguistics.Wightman, Colin W. and Mari Ostendorf.1994.
Automatic labeling of prosodicpatterns.
IEEE Transactions on Speech andAudio Processing, 2(4):469-481, October.Youmans, Gilbert.
1991.
A new tool fordiscourse analysis: The vocabularymanagement profile.
Language,67(4):763-790.139
