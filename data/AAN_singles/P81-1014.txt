Language Production: the Source ofthe DictionaryDavid D. McDonaldUniversity of Massachusetts at AmherstApril 1980AbstractUltimately in any natural language production system the largest amount ofhuman effort will go into the construction of the dictionary: the data basethat associates objects and relations in the program's domain with the wordsand phrases that could be used to describe them.
This paper describes atechnique for basing the dictionary directly on the semantic abstractionnetwork used for the domain knowledge itself, taking advantage of theinheritance and specialization machanisms of a network formalism such asr,L-ON~ The technique creates eonsidcrable economies of scale, and makespossible the automatic description of individual objects according to theirposition in the semantic net.
Furthermore, because the process of decidingwhat properties to use in an object's description is now given over to acommon procedure, we can write general-purpose rules to, for example,avoid redundancy or grammatically awkward constructionS.Regardless of its design, every system for natural !anguageproduction begins by selecting objects and relations from the speaker'sinternal model of the world, and proceeds by choosing an English phrase todescribe ach selected item, combining them according to the properties ofthe phrases and the constraints of the language's grammar and rhetoric.
TOdo this, the system must have a data base of some sort, in which the objectsit will talk about are somewhow associated with the appropriate word orphrase (or with procedures that will construct them).
1 will refer to such adata base as a dictionary.Evcry production system has a dictionary in one form or another, andits compilation is probably the single most tedious job that the humandesigner must perform.
In the past.
typically every object and relation hasbeen given its own individual "lex" property with the literal phrase to beused; no attempt was made to share criteria or sub-phrases betweenproperties; and there was a tacit a~umtion that the phrase would have theright form and content in any of the contexts that the object will bementioned.
(For a review of this literature, see r~a .)
However,dictionaries built in this way become increasingly harder to maintain asprograms become larger and their discourse more sophisticated.
We wouldlike instead some way to de the extention of the dictionary direcdy to theextention of the program's knowledge base; then, as the knowledge baseexpands the dictionary will expand with it with only a minimum ofadditional cffort.This paper describes a technique for adapting a semantic abstractionhierarchy of thc sort providcd by ~d~-ONE ~:1.\] to function directly as adictionary for my production system MUMIII.I~ \ [ ,q '~ .
.
Its goal is largelyexpositional in the sense that while the technique is fully spocificd andproto-types have been run, many implementation questions remain to beexplored and it is thus premature to prescnt it as a polished system forothers to use; instead, this paper is intended as a presentation of theissues--potcntial economicw---that he technique is addressing.
Inparticular, given the intimate relationship between the choice ofarchitecture in the network formalism used and the ability uf the dictionaryto incorporate linguistically useful generalizations and utilities, thispresentation may suggest additional criteria for networ k design, namely tomake it easier to talk about he objects the networkThe basic idea of "piggybacking" the dictionary onto the speaker'sregular semantic net can be illustrated very simply: Consider the KL.ONEnetwork in figure one, a fragment taken from a conceptual taxonomy foraugmented transition ets (given in \[klune\]).
The dictionary will providethe means to describe individual concepts (filled ellipses) on the basis oftheir links to generic concepts lempty ellipses) and their functional roles(squar~s), as shown there for the individual concept "C205".
The defaultEnglish description of C205 (i.e.
"the jump arc fi'om S /NP  to S/DCL") iscreated recursiveiy from dL.~riptions of the three network relations thatC205 participates in: its "supercuneept" link to the concept "jump-are".
andits two role-value relations: "source-stateIC205)=S/NP" and "next-state(C205)=S/t:~Ct.".
Intuitively.
we want to associate each of thenetwork objects with an English phrase: the concept "art'" with the word"art"', the "source-state" role relation with the phrase "C205 comes fromS/NF" (note the embedded references), and so on.
The machinery thatactually brings about this ~sociation is, of course, much more elaborate,involving three different recta-level networks describing the whole of theoriginal, "domain" network, as well as an explicit representation f theEnglish grammar (i.e.
it Ls itsclf expressed in rd,-oN~).role links ~ ?
~ test~ act ion  value-.restriction linksIL_value links"The jump arc from S./NP to S/DCL"Figure One: the speaker's original networkWhat does this rather expensive I computational machinery purchase?There are numrous benefits: The most obvious is the economy of scalewithin the dictionary that is gained by drawing directly on the economies\[.
What is cxpensive to represcnt in an explicit, declarative structure neednot be expensive wllen translated into pn~ccdurai forth.
\] do not seriouslyexpect anyone to implement suctl a dicti()nary by interpreting the Y-.I.-ON,~,structures themselves; given tmr present hardware such a tact would behopelessly inel\]icient.
Instead, a compilation pnx:css will in effective"compact" the explicit version of thc dictionary in~t~ an expeditious,, space.-expensive (i.e.
heavily redundant} version that pc:rfbrms each inheritanceonly once and fl~eu runs as an efficient, self-contained procedure.57alr,,:.~dy prcsent in the network: a one-time liuguistic annotation of thenctwork's generic concepts aod relations can be passed own to describearbitrary numbcrs of instantiating individuals by following general rulesbased on the geography of thc network.
At thc same time.
the dictionary"cmr~ " \['or a object in the nctwork may be ~pcciaiizcd and hand-tailored, ifdesired, in order to take advantage of special words or idiomadc phrases orit may inherit partial dct'auk reali~ation~ e.g.
just \['or determiners orad~erbia| modifiers, while specializing, its uther parts.
More generally.because we ha~c now retried the procc~ of collecting the "raw material" ofLhe production process (i.e.
scanning the nctw(,rk), we c:m imp(vse rules andconstraints on it just ,xs thougi~ it were another part of the productionplanning process; we can develop a dictionary gnmm~ur entirely analogousto our gramm.
'~r of l'nglish.
This allows us to filter or mmsform thecollection pnx:css under contextual cuntnd according to general nlles, andthereby, among edict things, automatically avoid rcdundancics ur violationso\[' grammatical constraints such as complex-NP.In order to adapt a semantic net for use a~ a dictionary we mustdctermthe three points: (1) What type of linguistic annotation to use--justwhat is to be associated with the nodes ufa network?
(2) How annotationsfrom individual nodes are to be accumulatcd~what dictates the pattern inwhich the network is scanned?
(3) How the accumulation process is madesensitive to context.
'lllese will be the ft~us of the rest oft he paper.l'hc three points of the desigu arc.
of course, mutually dcpendcnt,and are \['urther dependent on the requirements of the dictionary'scmploye~, the planning and \[inguLstic realization componants or" theproduc'3on system, in the interests of space I will not go into the details ofthese components in this paper, especially as this dictionary desigu appearsto be ,~ful I%r more than lust my own particular production system.
Myassumptions are: (t) that the output ot the dictionary (the Input to myrealization component) is a representation of  a natural language phrase asdefined by the grammar and with both words and other objects from thedomain network as its terminals (the embedded domain objects correspondto the variable parts of'the phrase, i.e.
the arguments to the original networkrelation): and (2) that the planning process (the component that decideswhat to say) will specify that network objects be described either as acomposition era set of other network relations that it has explicitly selected,or else will leave the de~:riptiun to a default given in the dictionary.Meta- level  annotat ion"\]'he basis of the dictionary is a meta-/evel network constructed so as toshadow the domain network used by the rest of the speaker's cognitiveprocesses.
"\['his "dictionary network" describes the domain network fromthe point of view of d1?
accumulation procedure and the linguisticannotation.
\[t is itself an abstraction hierarchy, and is also expressed in xL.ON"~ (though see the earlier \['ootuot?).
Objects in the regular network areconnected hy recta-links to their corresponding dictionary "entries".
Theseentries are represcntaUons of English phra.
?x.~ (either a single phrase or wordor a cluster of alternative phrases with some decision-criteria to s?lcetamong them at run dine).
When we want to describe an object, we followout its recta-link inzo the dictionary network and then realize the word orphrase that we find.Special izing Generic Phrases"\['he nu'y for an objcct may itself have a hicrarcifical structure thatparallels point fi)r point the I~ierarehical sU'ucture of the object's deseriptionin the domain.
Figure two slzows the section of the dicti:mary network thatannotates the supen:oncept chain front "jump-an:" to "object"; comparabledictionary networks can be built \[.or hierarchies of roles or other hierarchicalnetwork structures.
Noticc how the use of an inheritance m~hanisrn withinthe dictionary network (denoted by the vcrticat \[inks betwccn roles) allowsus on the one hand to state the determiner decision (show, bern only as acloud) once and for all at thc level of the domain conccpt "object", while atthe same time we can vo:umulate or supplant lexk:al material as we movedown to more specific levels in the domain nctwork.Rgure Two: the recta-level dictionary networkAfter all the inhent*n~c is factored in.
dt?
entry for.
e.g., the genericconcept "lump-ate" will de~:.ribe a noun phrase (represented by anthdiviual ?oilcept in K.i..O~t;) ~,,hose head position, is filled lly the word"arc', classifier position by "jump", and whose determiner will becalculated (at run time) by die same roudne that calculated detemlinen \['orobjects in general (e.g.
it will react Io whedlcr 'Jt?
reference is to a generic oran individual to how.
many other objects have the same dcseription, towhether any spec~ contrustive effects are intended, etc.
see \[q'~ !
).Should the planner d,'x:ide to use this entry by itself, say to produce"C205 is\[ajump arc\]", this dccripdon from the dictionary nctwork wouldbe eonvercd to a proper constituent structure and integrated with the restof the utterance under production.
However.
the entry will often be used inconjunction with the entries for several other domain objects, in whichit is first manipulated as a deseription--constraint s atement--in order todetermine what 8ramroadcal consuuction(s) would realize the objects as agroup.The notion of crea~ng a consolidated English phrase out of thephr~ t'or several different objects is central to the power of thisdictionary.
'\['he designer is only expected to explicitly designate words forthe generic objects in the domain network; the entries for the individualobjects that the geueric objecLs de,scribe :rod cvcn the entries for ahicntrehical chain such as in figure two should typically be constructablo bydefault by fullowing general-purpo,Je linguistic rules and combinationheud=ies.58t "Large entries out of small onesFigure three shows a sketch of the combination process, Here weneed a dictionary entry to describe the relationship between the specificjump-arc C205 and the state it leads to, S/DCL, i.e.
we want something likethe sentence "(6"205) goes to (S/DCL)".
where the refercnces in anglebrackets would be ultimately replaced by their own English phrases.
Whenthe connecdng role relation ("next-state") can bc rendered into English by aconventional pattern, wc can use an automatic combination technique as inthe figure to construct a linguistic relationship for the domain onc by usinga conventional dictionary entry for the concept-role-value relations asspecialized by the specific entry for thc role "next-state".The figure shows diagramaiically thc relationship between thedomain network relation, its recta-level description as an object in thenetwork fomlalism (i.e.
it is an instance of a concept linked to one of itsroles linked in turn to the roic value), and finally the correspondingconventional linguistic construction.
The actoal Zl,.O~t; reprcscntation ofthis relation is considerably more elaborate since the links themselves arereified, however this sketch shows the rclevant level of detail as regardswhat kinds of knowledge arc nccded in or'tier to assemble the entryR \[raducable-v~ goes to IJUMP-ARCblV:CONCEPT__ROt _V*LUE); ; \CaAS'C-CLAUS J"Figure Three: Combining Entries by Network Relationsprocedurally.
First the domain reladon is picked out and categorized: herethis was done by a the conventional recta-level description of the relation interms of the VJ,.ONE primitives it was built from, below we will see how acomparable categorization can be done on a purely linguistic basis.
Withthe relation categorized, we can associated it with an entry in the dictionarynetwork, in this ease an instance of a "basic-clause" (i.e.
one without anyadjuncts or rom-transfomaations).
We now have determined a mappingfrom the entries for the components of the original domain relation tolinguistic roles within a clause and have.
in effect, created the relation'sentry which we could then compile for efficiency.There is much more to be said about how the "embedded entries"can be controlled, how, for example, the planner can arrange to say either"C205 goes to S/DCL" or "There is a jump arc going to S/DCL" bydynamically specializing the description of the clause, however it would betaking us too far afield: the interested reader is referred to \[thesisl.
Thepoint to be made here is just that the writer of the dictionary has an optioneither to write specific dictionary entries for domain relations, or to leavethem to general "macro entries" that will build them out of the entries forthe objects involved as just sketched.
Using the macro entries of coursemeau that less effort v, ill be needed over all, but using specific entriespermits one to rake advantage of special idioms or variable phrases that areeither not productive nough or not easy enough to pick out in a standardrecta-level description of the domain network to be worth writing macroentries for.
A simple example would be a special entry for when one plansto describe an arc in terms of both its source and its nexi states: in this casethere is a nice compaction available by using die verb "connect" in a singleclause (instead of one clause for each role).
Since the ~I,-O~F.
formalism hasno transparent means of optionally bundling two roles into one, thiscompound rcladon has to be given its own dictionary entry by hand.Mak ing  co lnbinat ions l inguist ical lyUp to this point, we have been looking at associations between"organic" objects or relations in the domain network and their dictionaryentries for production.
It is often the case however, that the speech plannerwill want to talk about combinations of objects or complex relations thathave been assembled just for the occasion of one conversation and have nonatural counterpart within the regular domain network.
In a case like thisthere wuuld not already be an entry in the dictionary for the new relation;however, in most eases we can still produce an integrated phrase by lookingat how the components of the new relation can combine linguistically.These linguistic ombinations are not so much the provence of thedictionary as of my linguistic realization component.
MuMnI,E.
~.IUSIBLEhas the ability to perform what in the early days of transformationalgenerative grammar were referred to as "gcneraliT.ed transformations": thecombining of two or more phrases into a single phrase on the basis of theirlinguistic descriptions.
We have an example of this in the original exampleof the default description ofC205 as "the jump arc fram S /N  P to S/DC L".This phrase was produced by having the default planner construct anexpression indicating which network relations to combine (or moreprecisely, which phrases to combine, the phrases being taken from theentries of the relations), and then pass the expression to MI.MnLE whichproduces the "compound" phrase on the basis of the linguistic descriptionof the argument phrases.
The expression would look roughly like this: 1(descr ibe  C205 as (and \[np Ihejumparcl\[clau:~ C205 \[rcdueable-vp Comes from S/NP \] }\[clause C205 \[rcducable'~p goes lo S/OCL I \]MUMBLE's task is the production of  an object description front the rawmaterial o f  a noun phrase and two clauses.
To do this, it will have to matchdie three phrases against one of its known linguistic ombination patterns,just as the individual concept, role, and value were matched by a patternfrom the Itt,.ONl.
: representation formalism.
In this case, it characterizes thetrio as combinable through the adjunction of.
the two clauses to the nounphrase as qualifiers.
Additionally.
the rhetorical label "rcdueable-vp" in theclauses indicates that their verbs can be omitted without losing significant1.
A "phrase" in a dictionary entry does not cnnsist simply of  a string ofwords, They are actually schemata specifying the grammatical andrl~etorical relationships that the words and argument d(unain objectsparticipate in according to their functional n~/cs.
The bracketed CXl)rcssiousshown in the cxprc.~ion are fur expository purposes only and are modeledon the usual representation ft~r iJhraso structure.
I-mbedded objects uch as"C205" or "S/NP" will be replaced by their own English phrasesincrementally asthe containing phrases i  realized,59intbrmation, triggering a stylistic transformation co shorten and simplify thephrase.
At this point MUMIIU': h;LS a linguistic reprcsenmtion of  its decisionwhich is turned ovcr to the normal realization pruccss For completion.Exauszivc details of  these operations may be found in \["1~ .Contextual EffectsThe mechanisms of the dictionary per se perform two ~ncdons: (l)the association of the "ground level" linguistic phrases with the objeets ofthe domain network, and (2) the proper paczeros for accumulating thelinguistic dcscriptions of other parts of the domain network so as to describecomplex generic relatioos or to describe individual concepts in terms oftheir specific rela0ons and thcir generic description (as widt C205).
On  topof these two levels is graRcd a third lcvcl of contextually-triggered ffects;these effects are carried out by MUMI|IJ."
{the component hat is maintainingthe linguistic context that is the source of the uiggcrs).
~ting at the pointwhere combinations are submitted to it as just described.Tu best illustrate the contextual cffec~ wc should mm, e to a slightlymore complex example, o,c that is initiated by the speaker's planningprocess rathcr by than a defnuiL Suppose that the speaker is talking about.the A r.~ state "SI(")CL" and wants to say in effect that it is part of thedomain relation "ncxt-s~ite(C205)=SIIX~L".
The default way to expressthis reladon is as a Fact about the jump arc C"205: but what we ~r?
doingnow is to use it as Fact about S /DCL which will require the production of  aquite different ph~Lse.
The planning process expresses this intention toMU.MIn.E with the ~\[Iowing expression:(say-about C205 that (next-state C205 S/DCL))The operator "say-about" is responsible for detcnnining, on the basisof  the dictionary's description of the "neat-state" rcladon, what \[-~ngiishconstruction to use in order to express the ~peaker's intentcd focus.
Whenthe dictionary contains several possible renlizating phrases for a relation (Forexample "next-.,4a~C'~5) L~ the nezI slate after soun~J, au~C'z~)" Of%e.,.-s~u~C205) ~ the target o f  C2o.s").
then "say-about" will have to choo~between the reafiz~tions on the basis either of  some stylistic criteria, Forexample whether one of the contained relations had been mentionedrecently or ~me default (e.g.
"sm~-~,~C'..0~").
Let us suppose for presentpurposes that the only phrase listed in dictionary for the next-state relationis the one from the first example, Le.Now.
"say-about"s goal is a sentence that has S/DCL as its subje=.It can tell from the dictionary's annotauon and its English grammar that thephrase as it stands will not permit this since the verb "go to" does notpassiviz?
; however, the phrase is amenable to a kind of  deffiogtransformation that would yield the text: "S/DCL L~ where C205 goe~ to'.
"Say-about" arraogcs for this consu'uccion by building the structure belowas its representation o f i~ decision, passing it on to .~R:),mu.
: for realizatiou.Note ~at this structure :'- .,.,.,.,.,.,.,.,.,~sentialy a linguistic constituent structure of the.sual sort, describing the (annotated) surtace sU-ucture of dze intended textco the depth that "say-abouC' has planned it,60dllu~\[sul~-ctl \[prmlte~ml\[rea~,~-~l \[wn.trac-IFigure Four:.
the output of the "say-about" operatorThe ~nctional labels marking the constituent positions (i.e.
"subject", "verb", ccc.)
control the options for the realization of thedomain-network objects they initially con=in.
(The objects will besubscquendy replaced by the phrases that reafizc thcm.
processing from leRto righc) Thus the first instance of  S/I)CI_ in the subject position, isrealized without contextual effects as the name ".V/DCL": while the secondinstance, acting as the reladve pronoun fur the cleft, is realized as theinterrogative pronoun "where": and the final instance, embedded within the"next-state" relation, is suprcsscd entirely even though the rest of therelation is expre.~cd normally.
These cnutextoal variations are all entirelytransparent o the dictionary mechanisms and demonstrate how we canincrea~ the utility of  the phrases by carefully annotating them in thedictionary and using general purpose operations chat are ~ggered by thedescriptions of the phrases alone, therefore not needing to know anythingabout their semant~ content.This example was of contextual effects that applied aRer the domainobjects had been embedded in a linguistic structure, l.inguis~c ontext canhave its effect eadier as well by monitoring the aecumuladon p~occ~ andappiyiog its effects at that level.
Considering how the phrase for the jumpare C2.05 would be fonned in this same example.
Since the planner'soriginal insmaction (i.e.
"(say-abm,t_ )" did not mention C205 spccifcally,the description of that ubjec~ will be IeR to the default precis discussedearlier.
In the original example, C205 was dc~ribed in issoladon, her= it L~part of an ongoing dJscou~e context which muse be allowed ru influence theproton.The default description employed all three of  the domain-networkrelations that C205 is involved in.
In this discourse context, however, one ofthose relations, "neat-smte(c2OS)=SIDCL".
has already be given in thetext: were we to include it in this realization of  C'205.
the result would begarishly redundant and quite unnatural, i.e.
"3/DCL ~ where the jump arcfrom S/NP Io S/DCL goes to".
To rule out this realization, we can filterttmoriginal set of three relations, eliminating the redundant relation bemuse weknow that it is already mentioned in the CCXL Doing this en~ils (1) havingsome way to recognize when a relauon is already given in the text.
and (2) apredictable point in the preec~ when the filtering can be done.
rha  secondis smaight fo~arcL the "describe-as" fimetion is the interface between theplanner and the re',dization components; we simply add a cheek in t~tfunction to scan through the list of  relation-entries to bc combined andarrange for given relations to be filtered ouc.As fi)r the definition of "given".
MUMBLE maintains a multi-purposerecord of  the cunmnt discourse context which, like the dictionary, is a recta-level network describing the original speaker's network from yet this otherpoint of view.
Nlem-links connect relations in the speaker's network withthe mics they currendy play in ~be ongoing discourse, as illustrated in figurefive.
l~te definition of "give n" in terms of properties defined by discou~eroles such as these in conjunction with hcuristics about how much of theearlier text i~ likcly to still be rcmcmbered.ureo.state.
.
.
.Current  Discourse Conte~ ~s /ocL  ~,h~l , "current-clausJ he /ad(cu rront- relative-clause) subject(cu frent.sentence)Figure Four:  us ing the d iscourse-context  as a fi lterOnce able to refer to a rich, linguistically annotated description of thecontext, the powers of the dictionary can be extended still further toincorporate contextually-triggered transformations to avoid stylisticallyawkward or ungrammatical linguistic combinations.
This part of thedictionary design is still being elaborated, so l will say only what sort ofeffects are trying to be achieved.Consider what was done earlier by the "say-about' function: therethe planner proposed to say Something about one object by saying a relationin which the object was involved, the text choosen for the relation beingspecially transformed to insure that its thematic subject was the object inquestion, in these situations, the planner decides to use the relatinos it doeswithout any particular regard for their potential linguistic structure.
Thismeans that there is a certain potential for linguistic disaster.
Suppose wewanted to use our earlier trio of relations about C205 as the basis of aquestion about S/DCI,; that is, suppose our planner is a program that isbuilding up an augmented transition et in response to a description fed toit by its human user and that it has reached a point where it knows thatthere is a sub-network of the ATN that begins with the state S/DCI.
but itdoes not yet know how that sub-network is reached.
(This would be as ifthe network of figure one had the "unknown-state" in place of S/NP.
)Such a planner would be motivated to ask its user:(what <state> is-.~Jeh-thnt next-state(C20S)=<state>)Realizing this question will mean coming up with a description ofC205.
that name being one made up by the planner ather than the user.
Itcan of course be described in terms of its properties as already shown;however, if dais description were done without appreciating that it oecuredin the middle of a question, it would be possible to produce the nonsensesentence:" where does the jump arc from lead to S/DCL?
'Here the embedded reference to the "unknown-state" (part of the relation,"source-state(C205)=unknown-state") appearcd in the text as a rclativeclause qualiF/ing the reference to "the jump arc".
Buc because "unknown-state" was being questioncd the English grammar automatically suppressediL This lead R) the nonsense result shown because, as linguists have noted,in English one cannot question a noun phrase out of a relative clause--thatwould be a violation of an "island constraint" C?.
~..Tlle problem is, of course, that the critical relation ended up in arelative clause rather than in a different part of the sentence where issuppression would have been normal, It was not inevitable that thenonsense form was chosen; there are equally expressive ~ersions of thesame content, e.g.
"where does the jump arc to S/DCI.
come from?
', theproblem is how is a planner who knows nothing about grammaticalprinciples and does not maintain a linguistic description of the currentcontext o know not to choose tile nonsense form when confronted withostensibly synomous alternatives.
The answer as \[ see it is that the selectionshould not be the planner's problem--that we can leave the job to thelinguistic realization component which already maintains the necessaryknowledge base.
What we do is to make the violation of a grammaticalconstraint such ,as this one of the criteria for filtering out realizations when adictionary entry provides several synonomous choices, \[n dais case, thechoice was made by a general transformation already within the realizationcomponent and the alternative would be taken from a knowledge oflinguistically equivalent ways to ajoin the relations.A grammatical dictionary filter like this one for island-constraintScould also be use for the maintaince of discourse focus or for stylisticheuristics uch as wheth(:r to omit a reducable verb.
In general, anydecision criteria that is common to all of the dictionary entries hould beamenable to being abstracted out into a mechanism such as this at whichpoint they can act transparendy to the planner and thereby gain animportant modularity of linguistic and conceptual/pragmatic cr teria.
"\['hepotential problems with this technique involve questions of how muchinformation the planner can rcasenably be expected to supply the linguisticcomponenL The above filter would be impossible, for example, if themacro-entry where it is applied were not able to notice that the embeddeddescription of C205 could mention the "unknown-state" before itcommitted itself to ),he overall structure of the question.
The sort ofindexing required to do this does not seem unreasonable to me as long asthe indexes are passed up with the ground dictionary entries to the macro-entries.
Exactly how to do this is one of the pending questions ofimplementation.61t ?
?The dictionaries of other production systems in the literature havetypically been either trivial.
~,nconditionai object to word mappi.gs Cf3,C'~3 , orelse been encoded in uncxtcndable procedures CZ.3.
Anotable exception is the decision tree technique of\[goldman\] and as refinedby researchers atthe Yale Artificial Intelligence Protect.
The improvementsof' the present echnique over decision trees (which it otherwise resembles)can be found (1) in the sophistication of its representation or" the targetEnglish phrases, whereby abstract descriptions of tile rhetorical andsyntactic structure of the phrases may be manipulated by general rules thatneed not know anything about their pragmatic content: and (2) in its abilityto compile decision criteria and candidate phrases dynamically for newobjects or relations in terms of r.hc criteria and phrases from their genericdescriptions.l'hc dictionary described in this paper is not critically dependent onthe details of" the \[ingui'~tic reali~,.ation component or planning component iis used in conjunction with.
It is designed, however, to make maximum useor" whatever constraints ,nay be available f'n)m the linguistic context(broadly construed) or from parallel intentional goals.
Consequcndy.componcnts that do not cmploy MI.
'3,IBI.E'$ tc~hniquc of represcnting theplanned and already spoken parts of.
thc utterance explicitly along with itslinguistic structure ,nay bc unable to use it optimally.References\[I\] Brachman (\]979) Rcseareh in Natural Language Understanding.Quarterly "\['echnicai Progress Rcport No.
7.
\[k~It Beranek andNewman inc.\[2\] Davcy (1974) Discourse Production Ph.D. Dissertation.
-EdinburghUniversity.\[3\] Goldman (1974) Compnter Generation of Natural I.anguage from aDeep Conceptual I'lase.
memo AIM-247, Stanford ArtificialIntelligence Laboratory.\[41 McDonald.
D.I).
(1980) \[.angu:tge Production as a Process ofDecision-making Under Constraints.
Ph.D. Di~cmttion.
MIT, toappcar as a technical report from the MIT Artificial Intelligence Lab.\[5\] (in preparation) "1 .anguage Production in A.\].
- a review",manuscript being revised ,'or publication.\[6\] Ross (1%8) Constraints on Vari-lMes in Syntax.
Ph.D. Dissertation,Mrr.\[7\] Swat,out (\]977) A Digitalis Therapy Advisor with F-xplanatlons Mastcr,JDissertation, MIT.\[8\] Winograd 0.973) Understanding Natund language Academic Press.62
