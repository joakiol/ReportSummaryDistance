Proceedings of NAACL HLT 2009: Short Papers, pages 269?272,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsScore Distribution Based Term Specific ThresholdingforSpoken Term DetectionDog?an Can and Murat Sarac?larElectrical & Electronics Engineering DepartmentBog?azic?i UniversityI?stanbul, Turkey{dogan.can, murat.saraclar}@boun.edu.trAbstractThe spoken term detection (STD) task aimsto return relevant segments from a spokenarchive that contain the query terms.
This pa-per focuses on the decision stage of an STDsystem.
We propose a term specific threshold-ing (TST) method that uses per query poste-rior score distributions.
The STD system de-scribed in this paper indexes word-level lat-tices produced by an LVCSR system usingWeighted Finite State Transducers (WFSTs).The target application is a sign dictionarywhere precision is more important than recall.Experiments compare the performance of dif-ferent thresholding techniques.
The proposedapproach increases the maximum precision at-tainable by the system.1 IntroductionThe availability of vast multimedia archives callsfor solutions to efficiently search this data.
Multi-media content also enables interesting applicationswhich utilize multiple modalities, such as speechand video.
Spoken term detection (STD) is a sub-field of speech retrieval, which locates occurrencesof a query in a spoken archive.
In this work, STDis used as a tool to segment and retrieve the signsin news videos for the hearing impaired based onspeech information.
After the location of the queryis extracted with STD, the sign video correspond-ing to that time interval is displayed to the user.In addition to being used as a sign language dic-tionary this approach can also be used to automat-ically create annotated sign databases that can beutilized for training sign recognizers (Aran et al,2008).
For these applications the precision of thesystem is more important than its recall.The classical STD approach consists of convert-ing the speech to word transcripts using large vocab-ulary continuous speech recognition (LVCSR) toolsand extending classical information retrieval tech-niques to word transcripts.
However, retrieval per-formance is highly dependent on the recognition er-rors.
In this context, lattice indexing provides ameans of reducing the effect of recognition errorsby incorporating alternative transcriptions in a prob-abilistic framework.
A system using lattices can alsoreturn the posterior probability of a query as a de-tection score.
Various operating points can be ob-tained by comparing the detection scores to a thresh-old.
In addition to using a global detection thresh-old, choosing term specific thresholds that optimizethe STD evaluation metric known as Term-WeightedValue (TWV) was recently proposed (Miller et al,2007).
A similar approach which trains a neural net-work mapping various features to the target classeswas used in (Vergyri et al, 2007).The rest of the paper is organized as follows.In Section 2 we explain the methods used for spo-ken term detection.
These include the indexing andsearch framework based on WFSTs and the detec-tion framework based on posterior score distribu-tions.
In Section 3 we describe our experimentalsetup and present the results.
Finally, in Section 4we summarize our contributions and discuss possi-ble future directions.2692 MethodsThe STD system used in this study consists of fourstages.
In the first stage, an LVCSR system is usedto generate lattices from speech.
In the second stagethe lattices are indexed for efficient retrieval.
Whena query is presented to the system a set of candidatesranked by posterior probabilities are obtained fromthe index.
In the final stage, the posterior probabil-ities are compared to a threshold to decide whichcandidates should be returned.2.1 Indexing and Retrieval using Finite-StateAutomataGeneral indexation of weighted automata (Allauzenet al, 2004) provides an efficient means of index-ing for STD (Parlak and Sarac?lar, 2008; Can et al,2009), where retrieval is based on the posterior prob-ability of a term in a given time interval.
In thiswork, the weighted automata to be indexed are thepreprocessed lattice outputs of the ASR system.
Theinput labels are phones, the output labels are quan-tized time-intervals and the weights are normalizednegative log probabilities.
The index is representedas a WFST where each substring (factor) leads to asuccessful path over the input labels whenever thatparticular substring was observed.
Output labels ofthese paths carry the time interval information fol-lowed by the utterance IDs.
The path weights givethe probability of each factor occurring in the spe-cific time interval of that utterance.
The index is op-timized by WFST determinization and minimizationso that the search complexity is linear in the sum ofthe query length and the number of times the queryappears in the index.2.2 Decision MechanismOnce a list of candidates ranked with respect to theirposterior probabilities are determined using the in-dex, the candidates exceeding a threshold are re-turned by the system.
The threshold is computedto minimize the Bayes risk.
In this framework, weneed to specify a cost function, prior probabilitiesand likelihood functions for each class.
We choosethe cost of a miss to be 1 and the cost of a false alarmto be a free parameter, ?.
The prior probabilities andthe likelihood functions are estimated from the pos-terior scores of the candidate results for each query.The likelihood functions are found by fitting para-metric models to the score distributions (Manmathaet al, 2001).
In this study, the score distributionsare modeled by exponential distributions.
When thesystem returns a score, we do not know whetherit belongs to the correct or incorrect group, so weuse a mixture of two exponential distributions tomodel the posterior scores returned by the system.The exponential mixture model (EMM) parametersare determined via unsupervised estimation usingthe Expectation-Maximization (EM) algorithm.
Fig-ure 1 shows the normalized histogram of posteriorscores and the EM estimate given by our method foran example query.0 0.2 0.4 0.6 0.8 1051015Posterior ScorenIncorrect Class DistributionCorrect Class DistributionIncorrect Class EM EstimateCorrect Class EM EstimateFigure 1: The normalized histogram of posterior scoresand the EM estimates for correct and incorrect detectionsgiven an example query.If we denote the posterior score of each candidateby x, incorrect class by c0 and correct class by c1,we havep(x) = P (c0)p(x|c0) + P (c1)p(x|c1)where the incorrect class likelihoodp(x|c0) = ?0e?
?0x and correct class like-lihood p(x|c1) = ?1e??1(1?x).
The modelparameters ?0, ?1, P (c0), P (c1) are estimatedusing the EM algorithm given the scores xi fori = 1, .
.
.
, N .
Each iteration consists of firstcomputing P (cj |xi) = P (cj)p(xi|cj)/p(xi) forj = 1, 2 and then updatingP (cj) = 1N?iP (cj |xi),?0 =?i P (c0|xi)?i P (c0|xi)xi ,270?1 =?i P (c1|xi)?i P (c1|xi)(1?
xi) .After the mixture parameters are estimated, we as-sume that each mixture represents a class and mix-ture weights correspond to class priors.
Then, theMinimum Bayes Risk (MBR) detection thresholdfor x is given as:?1 + log(?0/?1) + log(P (c0)/P (c1)) + log?
?0 + ?1 .3 Experiments3.1 Data and ApplicationTurkish Radio and Television Channel 2 (TRT2)broadcasts a news program for the hearing impairedwhich contains speech as well as signs.
We havecollected 11 hours (total speech time) of test ma-terial from this broadcast and performed our ex-periments on this data with a total of 10229 sin-gle word queries extracted from the reference tran-scriptions.
We used IBM Attila speech recognitiontoolkit (Soltau et al, 2007) at the back-end of oursystem to produce recognition lattices.
The ASRsystem is trained on 100 hours of speech and tran-scription data collected from various TV and radiobroadcasts including TRT2 hearing impaired news,and a general text corpus of size 100 million words.Our application uses the speech modality to re-trieve the signs corresponding to a text query.
Re-trieved results are displayed as video demonstrationsto support the learning of sign language.
Since theapplication acts like an interactive dictionary of signlanguage, primary concern is to return correct resultsno matter how few they are.
Thus high precision isappreciated much more than high recall rates.3.2 Evaluation MeasuresIn our experiments, we use precision and recall asthe primary evaluation metrics.
For a set of queriesqk, k = 1, .
.
.
, Q,Precision = 1Q?kC(qk)A(qk) Recall =1Q?kC(qk)R(qk)where:R(qk): Number of occurences of query qk,A(qk): Total no.
of retrieved documents for qk,C(qk): No.
of correctly retrieved documents for qk.We obtain a precision/recall curve by changingthe free parameter associated with each thresholdingmethod to simulate different decision cost settings.Right end of these curves fall into the high precisionregion which is the main concern in our application.For the case of global thresholding (GT), the samethreshold ?
is used for all queries.
TWV basedterm specific thresholding (TWV-TST) (Miller et al,2007) aims to maximize the TWV metric introducedduring NIST 2006 STD Evaluations (NIST, 2006).TWV = 1?
1QQ?k=1{Pmiss(qk) + ?.PFA(qk)}Pmiss(qk) = 1?C(qk)R(qk) ,PFA(qk) =A(qk)?
C(qk)T ?
C(qk)where T is the total duration of the speech archiveand ?
is a weight assigned to false alarms that isproportional to the prior probability of occurence ofa specific term and its cost-value ratio.
This methodsets individual thresholds for each query term con-sidering per query expected counts and the tuningparameter ?.
In the proposed method ?
plays thesame role as ?
and allows us to control the decisionthreshold for different cost settings.3.3 Results0.8 0.85 0.9 0.95 10.20.30.40.50.60.70.80.91PrecisionRecallGlobal ThresholdingTerm Specific Thresholding (TWV)EMM + EM + MBR DetectionCheat + EMM + MBR DetectionFigure 2: The precision and recall curves for variousthresholding techniques.Figure 2 compares GT, TWV-TST, and the pro-posed method that utilizes score distributions to de-rive an optimal decision threshold.
For GT andTWT-TST, last precision/recall point in the figurecorresponds to the limit threshold value which is 1.0.Both the TWV-TST and the proposed method out-perform GT over the entire region of interest.
WhileTWV-TST provides better performance around the271knees of the curves, proposed method achieveshigher maximum precision values which coincideswith the primary objective of our application.Figure 2 also provides a curve of what happenswhen the correct class labels are used to estimatethe parameters of the exponential mixture model in asupervised manner instead of using EM.
This curveprovides an upper bound on the performance of theproposed method.4 DiscussionIn this paper, we proposed a TST scheme for STDwhich works almost as good as TWV-TST.
Extrapo-lating from the cheating experiment, we believe thatthe proposed method has potential for outperform-ing the TWV-TST over the entire region of interestgiven better initial estimates for the correct and in-correct classes.A special remark goes to the performance in thehigh precision region where our method clearly out-performs the rest.
While GT and TWV-TST meth-ods are bounded around 96.5% precision value, ourmethod reaches at higher precision figures.
For GT,this behavior is due to the inability to set differ-ent thresholds for different queries.
For TWT-TST,in the high precision region where ?
is large, thethreshold is very close to 1.0 value no matter whatthe expected count of the query term is, thus it es-sentially acts like a global threshold.Our current implementation of the proposedmethod does not make use of training data to es-timate the initial parameters for the EM algorithm.Instead, it relies on some loose assumptions aboutthe initial parameters of the likelihood functions anduses uninformative prior distributions.
The signifi-cant difference between the upper bound and the ac-tual performance of the proposed method indicatesthat the current implementation can be improved bybetter initial estimates.Our assumption about the parametric form of thelikelihood function may not be valid at all times.Maximizing the likelihood with mismatched mod-els degrades the performance even when initialparameters are close to the optimal values.
In thefuture, other parametric forms can be utilized to bet-ter model the posterior score distributions.Maximum likelihood estimation with insufficientdata is prone to overtraining.
This is a common sit-uation with the STD task at hand.
With the currentdata, three or less results are returned for half of thequeries.
Bayesian methods can be used to introducepriors on the model parameters in order to make theestimation more robust.AcknowledgmentsThis study was supported in part by Bog?azic?i Uni-versity Research Fund (BAP) under the project num-ber 05HA202, TU?BI?TAK under the project number105E102 and Turkish State Planning Organization(DPT) under the project number DPT2007K120610.ReferencesC.
Allauzen, M. Mohri, and M. Sarac?lar.
2004.
General-indexation of weighted automata-application to spo-ken utterance retrieval.
In Proc.
Workshop on Inter-disciplinary Approaches to Speech Indexing and Re-trieval at HLT-NAACL, pages 33?40, March.O.
Aran, I.
Ar?, E. Dikici, S. Parlak, P. Campr, M. Hruz,L.
Akarun, and M. Sarac?lar.
2008.
Speech and slid-ing text aided sign retrieval from hearing impaired signnews videos.
Journal on Multimodal User Interfaces,2(1):117?131, November.D.
Can, E. Cooper, A. Sethy, C.M.
White, B. Ramabhad-ran, and M. Saraclar.
2009.
Effect of pronunciationson oov queries in spoken term detection.
In ICASSP,April.R.
Manmatha, T. Rath, and F. Feng.
2001.
Modelingscore distributions for combining the outputs of searchengines.
In SIGIR ?01, pages 267?275, New York, NY,USA.
ACM.D.
R. H. Miller, M. Kleber, C. Kao, O. Kimball,T.
Colthurst, S. A. Lowe, R. M. Schwartz, and H. Gish.2007.
Rapid and accurate spoken term detection.
InProc.
Interspeech, pages 314?317, August.NIST.
2006.
The spoken term detection (STD) 2006evaluation plan http://www.nist.gov/speech/tests/std/.S.
Parlak and M. Sarac?lar.
2008.
Spoken term detectionfor Turkish broadcast news.
In Proc.
ICASSP, pages5244?5247, April.H.
Soltau, G. Saon, D. Povey, L. Mangu, J. Kuo,M.
Omar, and G. Zweig.
2007.
The IBM 2006 GALEArabic ASR system.
In Proc.
ICASSP 2007, Hon-olulu, HI, USA.D.
Vergyri, I. Shafran, A. Stolcke, R. R. Gadde, M. Ak-bacak, B. Roark, and W. Wang.
2007.
The SRI/OGI2006 spoken term detection system.
In Proc.
Inter-speech, pages 2393?2396, August.272
