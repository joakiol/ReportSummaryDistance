Mining metalinguistic activity in corpora to create lexical resources usingInformation Extraction techniques: the MOP systemCarlos Rodr?guez PenagosLanguage Engineering Group, Engineering InstituteUNAM, Ciudad Universitaria A.P.
70-472Coyoac?n 04510  Mexico City, M?xicoCRodriguezP@iingen.unam.mxAbstractThis paper describes and evaluates MOP, anIE system for automatic extraction ofmetalinguistic information from technical andscientific documents.
We claim that such asystem can create special databases to boot-strap compilation and facilitate update of thehuge and dynamically changing glossaries,knowledge bases and ontologies that are vitalto modern-day research.1 IntroductionAvailability of large-scale corpora has made itpossible to mine specific knowledge from free orsemi-structured text, resulting in what many con-sider by now a reasonably mature NLP technolo-gy.
Extensive research in Information Extraction(IE) techniques, especially with the series of Mes-sage Understanding Conferences of the nineties,has focused on tasks such as creating and updatingdatabases of corporate join ventures or terroristand guerrilla attacks, while the ACQUILEX pro-ject used similar methods for creating lexical da-tabases using the highly structured environment ofmachine-readable dictionary entries and other re-sources.
Gathering knowledge from unstructuredtext often requires manually crafting knowledge-engineering rules both complex and deeply de-pendent of the domain at hand, although somesuccessful experiences using learning algorithmshave been reported (Fisher et al, 1995; Chieu etal., 2003).Although mining specific semantic relationsand subcategorization information from free-texthas been successfully carried out in the past(Hearst, 1999; Manning, 1993), automatically ex-tracting lexical resources (including terminologi-cal definitions) from text in special domains  hasbeen a field less explored, but recent experiences(Klavans et al, 2001; Rodr?guez, 2001; Cartier,1998) show that compiling the extensive resourcesthat modern scientific and technical disciplinesneed in order to manage the explosive growth oftheir knowledge, is both feasible and practical.
Agood example of this NLP-based processing needis the MedLine abstract database maintained bythe National Library of Medicine1 (NLM), whichincorporates around 40,000 Health Sciences pa-pers each month.
Researchers depend on theseelectronic resources to keep abreast of their rapid-ly changing field.
In order to maintain and updatevital indexing references such as the Unified Me-dical Language System (UMLS) resources, theMeSH and SPECIALIST vocabularies, the NLMstaff needs to review 400,000 highly-technicalpapers each year.
Clearly, neology detection, ter-minological information update and other taskscan benefit from applications that automaticallysearch text for information, e.g., when a new termis introduced or an existing one is modified due todata or theory-driven concerns, or, in general,when new information about sublanguage usage isbeing put forward.
But the usefulness of robustNLP applications for special-domain text goesbeyond glossary updates.
The kind of categoriza-tion information implicit in many definitions canhelp improve anaphora resolution, semantic ty-ping or acronym identification in these corpora, aswell as enhance ?semantic rerendering?
of spe-cial-domain ontologies and thesaurii (Pustejovskyet al, 2002).In this paper we describe and evaluate theMOP2 IE system, implemented to automaticallycreate Metalinguistic Information Databases(MIDs) from large collections of special-domain1 http://www.nlm.nih.gov/2 Metalinguistic Operation Processorresearch papers.
Section 2 will lay out the theory,methodology and the empirical research groun-ding the application, while Section 3 will describethe first phase of the MOP tasks: accurate locationof good candidate metalinguistic sentences forfurther processing.
We experimented both withmanually coded rules and with learning algo-rithms for this task.
Section 4 focuses on the pro-blem of identifying and organizing into a usefuldatabase structure the different linguistic consti-tuents of the candidate predications, a phase simi-lar to what are known in the IE literature asNamed-Entity recognition, Element and Scenariotemplate fill-up tasks.
Finally, Section 5 discussesresults and problems of our experiments, as wellas future lines of research.2 Metalanguage and term evolution in scien-tific disciplines2.1 Explicit Metalinguistic OperationsPreliminary empirical work to explore how re-searchers modify the terminological framework oftheir highly complex conceptual systems, includedmanual review of a corpus of 19 sociology articles(138,183 words) published in various British,American and Canadian academic journals withstrict peer-review policies.
We look at how termmanipulation was done as well as how metalin-guistic activity was signaled in text, both by lexi-cal and paralinguistic means.
Some of theindicators found included verbs and verbal phra-ses like called, known as, defined as, termed, co-ined, dubbed, and descriptors such as term andword.
Other non-lexical markers included quota-tion marks, apposition and text formatting.A collection of potential metalinguistic patternsidentified in the exploratory Sociology corpus wasexpanded (using other verbal tenses and forms) to116 queries sent to the scientific and learned do-mains of the British National Corpus.
The resul-ting 10,937 sentences were manually classified asmetalinguistic or otherwise, with 5,407 (49.6% oftotal) found to be truly metalinguistic sentences.The presence of three components described be-low (autonym, informative segment and mar-kers/operators) was the criteria for classification.Reliability of human subjects for this task has notbeen reported in the literature, and was not eva-luated in our experiments.Careful analysis of this extensive corpus presen-ted some interesting facts about what we havetermed ?Explicit Metalinguistic Operations?
(orEMOs) in specialized discourse:A) EMOs usually do not follow the genus-differentia scheme of aristotelian definitions, norconform to the rigid and artificial structure of dic-tionary entries.
More often than not, specific in-formation about language use and term definitionis provided by sentences such as: (1) This meansthat they ingest oxygen from the air via finehollow tubes, known as tracheae, in which theterm trachea is linked to the description finehollow tubes in the context of a globally non-metalinguistic sentence.
Partial and heterogeneousinformation, rather that a complete definition, aremuch more common.B) Introduction of metalinguistic information indiscourse is highly regular, regardless of the spe-cific domain.
This can be credited to the fact thatthe writer needs to mark these sentences for spe-cial processing by the reader, as they dissectacross two different semiotic levels: a metalan-guage and its object language, to use the termino-logy of logic where these concepts originate.3 Itsconstitutive markedness means that most of thetimes these sentences will have at least two indi-cators present, for example a verb and a descrip-tor, or quotation marks, or even have precedingsentences that announce them in some way.
Theseformal and cognitive properties of EMOs facilitatethe task of locating them accurately in text.C) EMOs can be further analyzed into 3 distinctcomponents, each with its own properties and lin-guistic realizations:i) An autonym (see note 3): One or more self-referential lexical items that are the logical orgrammatical subject of a predication that needsnot be a complete grammatical sentence.3 At a very basic semiotic level natural language hasto be split (at least methodologically) into two distinctsystems that share the same rules and elements: a meta-language, which is a language that is used to talk aboutanother one, and an object language, which in turn canrefer to and describe objects in the mind or in thephysical world.
The two are isomorphic and this ac-counts for reflexivity, the property of referring to itself,as when linguistic items are mentioned instead of beingused normally in an utterance.
Rey-Debove (1978) andCarnap (1934) call this condition autonymy.ii) An informative segment: a contribution ofrelevant information about the meaning, status,coding or interpretation of a linguistic unit.
In-formative segments constitute what we stateabout the autonymical element.iii) Markers/Operators: Elements used to markor made prominent whole discourse operation,on account of its non-referential, metalinguis-tic nature.
They are usually lexical, typograp-hic or pragmatic elements that articulateautonyms and informative segments into apredication.Thus, in a sentence such as (2), the [autonym] ismarked in square brackets, the {informationalsegment} in curly brackets and the <marker-operators> in angular brackets:(2) {The bit sequences representing quanta ofknowledge} <will be called ?>[Kenes]<?>, {aneologism intentionally similar to 'genes'}.2.2 Defaults, knowledge and knowledge oflanguageThe 5,400 metalinguistic sentences from ourBNC-based test corpus (henceforth, the EMOcorpus) reflect an important aspect of scientificsublanguages, and of the scientific enterprise ingeneral.
Whenever scientists and scholars advancethe state of the art of a discipline, the languagethey use has to evolve and change, and this build-up is carried out under metalinguistic control.Previous knowledge is transformed into newscientific common ground and ontological com-mitments are introduced and defended when se-mantic reference is established.
That is why whenwe want to structure and acquire new knowledgewe have to go through a resource-costly cognitiveprocess that integrates, within coherent conceptualstructures, a considerable amount of new and verycomplex lexical items and terms.It has to be pointed out that non-specializedlanguage is not abundant4 in these kinds of meta-linguistic exchanges because (unless in the con-text of language acquisition) we usually rely on alexical competence that, although subsequentlymodified and enhanced, reaches the plateau of ageneralized lexicon relatively early in our adultlife.
Technical terms can be thought of as seman-tic anomalies, in the sense that they are ad hoc4 Our study shows that they represent between 1 and6% of all sentences across different domains.constructs strongly bounded to a model, a domainor a context, and are not, by definition, part of thefar larger linguistic competence from a first nativelanguage.
The information provided by EMOs isnot usually inferable from previous one availableto the speaker?s community or expert group, anddoes not depend on general language competenceby itself, but nevertheless is judged important andrelevant enough to warrant the additional proces-sing effort involved.Conventional resources like lexicons and dic-tionaries compile established meaning definitions.They can be seen as repositories of the default,core lexical information of words or terms used bya community (that is, the information available toan average, idealized speaker).
A MetalinguisticInformation Database (MID), on the other hand,compiles the real-time data provided by metalan-guage analysis of leading-edge research papers,and can be conceptualized as an anti-dictionary: alisting of exceptions, special contexts and specificusage, of instances where meaning, value orpragmatic conditions have been spotlighted bydiscourse for cognitive reasons.
The non-defaultand highly relevant information from MIDs couldprovide the material for new interpretation rules inreasoning applications, when inferences won?tsucceed because the states of the lexico-conceptual system have changed.
When interpre-ting text, regular lexical information is applied bydefault under normal conditions, but more specificpragmatic or discursive information can overrideit if necessary, or if context demands so (Lascari-des & Copestake, 1995).
A neologism or a wordin an unexpected technical sense could stump aNLP system that assumes it will be able to usedefault information from a machine-readable dic-tionary.3 Locating metalinguistic information intext: two approachesWhen implementingan IE application to minemetalinguistic information from text, the first is-sue to tackle is how to obtain a reliable set of can-didate sentences from free text for input into thenext phases of extraction.
From our initial corpusanalysis we selected 44 patterns that showed thebest reliability for being EMO indicators.
We startour processing5  by tokenizing  text, which then is5 Our implementation is Python-based, using therun through a cascade of finite-state devices basedon identification patterns that extract a candidateset for filtering.
Our filtering strategies in effectdistinguish between useful results such as (3)from non-metalinguistic instances like (4):(3) Since the shame that was elicited by the co-ding procedure was seldom explicitly mentio-ned by the patient or the therapist, Lewiscalled it unacknowledged shame.
(4) It was Lewis (1971;1976) who called attentionto emotional elements in what until then hadbeen construed as a perceptual phenomenon .For this task, we experimented with two strate-gies: First, we used corpus-based collocations todiscard non-metalinguistic instances, for examplethe presence of attention in sentence (4) next tothe marker called.
Since immediate co-text seemsimportant for this classification task, we also im-plemented learning algorithms that were trainedon a subset from our EMO corpus, using as vec-tors either POS tags or word forms, at 1, 2, and 3positions adjacent before and after our markers.These approaches are representative of wider pa-radigmatic approaches to NLP: symbolic and sta-tistic techniques, each with their own advantagesand limitations.
Our evaluations of the MOP sys-tem are based on test runs over 3 document sets:a) our original exploratory corpus of sociologyresearch papers [5581 sentences, 243 EMOs]; b)an online histology textbook [5146 sentences, 69EMOs] ; and c) a small sample from the MedLineabstract database [1403 sentences, 10 EMOs].Using collocational information, our first ap-proach fared very well, presenting good precisionnumbers, but not so encouraging recall.
The so-ciology corpus, for example, gave 0.94 precision(P) and 0.68 recall (R), while the histology onepresented 0.9 P and 0.5 R. These low recall num-bers reflect the fact that we only selected a subsetof the most reliable and common metalinguisticpatterns, and our list is not exhaustive.
Example(5) shows one kind of metalinguistic sentence(with a copulative structure) attested in corpora,NLTK toolkit (nltk.sf.net) developed by E. Loper andS.
Byrd  at the University of Pennsylvania, although wehave replaced stochastic POS taggers with an imple-mentation of the Brill algorithm by Hugo Liu at MIT.Our output files follow XML standards to ensuretransparency, portability and accessibilitybut that the system does not attempt to extract orprocess:(5) ?Intercursive?
power , on the other hand , ispower in Weber's sense of constraint by an ac-tor or group of actors over others.In order to better compare our two strategies,we decided to also zoom in on a more limited sub-set of verb forms for extraction (namely, calls,called, call), which presented ratios of metalin-guistic relevance in our MOP corpus, rangingfrom 100% positives (for the pattern so called +quotation marks) to 77% (called, by itself) to 31%(call).
Restricted to these verbs, our metrics showprecision and recall rates of around 0.97, and anoverall F-measure of 0.97.6 Of 5581 sentences (96of which were metalinguistic sentences signaledby our cluster of verbs), 83 were extracted, with13 (or 15.6% of candidates) filtered-out by collo-cations.For our learning experiments (an approach wehave called contextual feature language models),we selected two well-known algorithms that sho-wed promise for this classification task.7 The nai-ve Bayes (NB) algorithm estimates the conditionalprobability of a set of features given a label, usingthe product of the probabilities of the individualfeatures given that label.
The Maximum Entropymodel establishes a probability distribution thatfavors entropy, or uniformity, subject to the cons-traints encoded in the feature-label correlation.When training our ME classifiers, Generalized(GISMax) and Improved Iterative Scaling (IIS-Max) algorithms are used to estimate the optimalmaximum entropy of a feature set, given a corpus.1,371 training sentences were converted into la-beled vectors, for example using 3 positions andPOS tags: ('VB WP NNP', 'calls', 'DT NN NN')/'YES'@[102].
The different number of positionsconsidered to the left and right of the markers inour training corpus, as well as the nature of thefeatures selected (there are many more word-typesthan POS tags) ensured that our 3-part vector in-troduced a wide range of features against our 2possible YES-NO labels for processing by ouralgorithms.
Although our test runs using only co-llocations showed initially that structural regulari-6 With a ?
factor of 1.0, and within the sociologydocument set7 see Ratnaparkhi (1997) and Berger et al (1996) fora formal description of these algorithmsties would perform well, both with our restrictedlemma cluster and with our wider set of verbs andmarkers, our intuitions about improvement withmore features (more positions to the right of leftof the markers) or a more controlled and gramma-tically restricted environment (a finite set of su-rrounding POS tags), turned out to be overlyoptimistic.
Nevertheless, stochastic approachesthat used short range features did perform verywell, in line with the hand-coded approach.The results of the different algorithms, re-stricted to the lexeme call, are presented in Table1, while Figures 1 and 2 present best results in thelearning experiments for the complete set of pat-terns used in the collocation approach, over two ofour evaluation corpora.Type Positions Tags/WordsFeatures Accuracy Precision RecallGISMax 1 W 1254 0.97 0.96 0.98IISMax 1 T 136 0.95 0.96 0.94IISMax 1 W 1252 0.92 0.97 0.9GISMax 1 T 138 0.91 0.9 0.96GISMax 2 T 796 0.88 0.93 0.92IISMax 2 T 794 0.86 0.95 0.89IISMax 3 W 4290 0.87 0.85 0.98GISMax 3 W 4292 0.87 0.85 0.98IISMax 2 W 3186 0.86 0.87 0.95GISMax 2 W 3188 0.86 0.87 0.95NB 1 T 136 0.88 0.97 0.84NB 2 T 794 0.87 0.96 0.84NB 3 W 4290 0.73 0.86 0.77Table 1.
Best metrics for ?call?
lexemesorted by F-measure and classifier accuracyFigure 1.
Best metrics for Sociology corpus0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95PRFNB (3/T)IIS (1/W)GIS (1/W)Figure 2.
Best metrics for Histology corpus0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95PRFNB (3/W)IIS (3/W)GIS (1/W)Figures 1 & 2.
Best results forfiltering algorithms.8Both Knowledge-Engineering and supervisedlearning approaches can be adequate for extrac-tion of metalinguistic sentences, although learningalgorithms can be helpful when procedural ruleshave not been compiled; they also allow easiertransport of systems to new thematic domains.
Weplan further research into stochastic approaches tofine tune them for the task.One issue that merits special attention is whysome of the algorithms and features work wellwith one corpus, but not so well with another.This fact is in line with observations in Nigam etal.
(1999) that naive Bayes and Maximum Entro-py do not show fundamental baseline superiori-ties, but are dependent on other factors.
A hybridapproach that combines hand-crafted collocationswith classifiers customized to each pattern?s be-havior and morpho-syntactic contexts in corporamight offer better results in future experiments.4 Processing EMOs to compile metalinguis-tic information databasesOnce we have extracted candidate EMOs, theMOP system conforms to a general processingarchitecture shown in Figure 3.
POS tagging isfollowed by shallow parsing that attempts limitedPP-attachment.
The resulting chunks are then tag-ged semantically as Autonyms, Agents, Markers,Anaphoric elements or simply as Noun Chunks,8 Legend: P: Precision; R: Recall; F:  F-Measure.
NB: na-?ve Bayes; IIS: Maximum Entropy trained with ImprovedIterative Scaling; GIS: Maximum Entropy trained with Gen-eralized Iterative Scaling.
(Positions/Feature type)using heuristics based on syntactic, pragmatic andargument structure observation of the extractionpatterns.Next, a predicate processing phase selects themost likely surface realization of informationalsegments, autonyms and makers-operators, andproceeds to fill the templates in our databases.This was done by following different processingroutes customized for each pattern using corpusanalysis as well as FrameNet data from Nameconferral and Name bearing frames to establishrelevant arguments and linguistic realizations.Figure 3.
MOP ArchitectureAs mentioned earlier, informational segmentspresent many realizations that distance them fromthe clarity, completeness and conciseness of lexi-cographic entries.
In fact, they may show up asfull-fledged clauses (6), as inter- or intra-sentential anaphoric elements (7 and 8, the firstone a relative clause), supply a categorization de-scriptor (9), or even (10) restrict themselves se-mantically to what we could call a sententially-unrealized ?existential variable?
(with logicalform ?x) indicating only that certain discourseentity is being introduced.
(6) In 1965 the term soliton was coined to descri-be waves with this remarkable behaviour.
(7) This leap brings cultural citizenship in linewith what has been called the politics of citi-zenship .
(8) They are called ?endothermic compounds.?
(9) One of the most enduring aspects of all socialtheories are those conceptual entities knownas structures or groups.
(10) A ?x so called cell-type-specific TF can beused by closely related cells, e.g., in erythro-cytes and megakaryocytes.We have not included an anaphora-resolutionmodule in our present system, so that instances 7,8 and 10 will only display in the output as unre-solved surface element or as existential variableplace-holders,9 but these issues will be explored infuture versions of the system.
Nevertheless, muchmore common occurrences as in (11) and (12) areenough to create MIDs quite useful for lexicogra-phers and for NLP lexical resources.
(11) The Jovian magnetic field exerts an influ-ence out to near a surface, called the"magnetopause".
(12) Here we report the discovery of a solubledecoy receptor, termed decoy receptor 3(DcR3)...The correct database entry for example 12 ispresented in Table 4.Reference:  MedLine sample # 6Autonym:  decoy receptor 3 (DcR3)Information a soluble decoy receptorMarkers/Operators:termedTable 4.
Sample entry of MIDThe final processing stage presents metricsshown in Figure 4, using a ?
factor of 1.0 to esti-mate F-measures.
To better reflect overall perfor-mance in all template slots, we introduced athreshold of similarity of 65% for comparisonbetween a golden standard slot entry and the oneprovided by the application.
Thus, if the autonymor the informational segment is at least 2/3 of thecorrect response, it is counted as a positive, inmany cases leveling the field for the expectederrors in the prepositional phrase- or acronym-attachment algorithms, but accounting for a (basi-cally) correct selection of superficial sentencesegments.9 For sentence (8) the system would retrieve a previ-ous sentence: (?A few have positive enthalpies of for-mation?).
to define ?endothermic compounds?.Corpus TokenizationCandidate extractionMIDCandidate FilteringCollocations  ?
LearningPOS tagging &Partial parsingSemantic labelingDatabasetemplate fillup5 Results, comparisons and discussionThe DEFINDER system (Klavans et al 2001) atColumbia University is, to my knowledge, theonly one fully comparable with MOP, both inscope and goals, but some basic differences be-tween them exist.
First, DEFINDER examinesuser-oriented documents that are bound to containfully-developed definitions for the layman, as thegeneral goal of the PERSIVAL project is to pre-sent medical information to patients in a less tech-nical language than the one of reference literature.MOP focuses on leading-edge research papers thatpresent the less predictable informational templa-tes of highly technical language.
Secondly, by thevery nature of DEFINDER?s goals their qualitati-ve evaluation criteria include readability, useful-ness and completeness as judged by lay subjects,criteria which we have not adopted here.
Neitherhave we determined coverage against existing on-line dictionaries, as they have done.
Taking intoaccount the above-mentioned differences betweenthe two systems?
methods and goals, MOP com-pares well with the 0.8 Precision and 0.75 Recallof DEFINDER.
While the resulting MOP ?defini-tions?
generally do not present high readability orcompleteness, these informational segments arenot meant to be read by laymen, but used by do-main lexicographers reviewing existing glossariesfor neological change, or, for example, in machi-ne-readable form by applications that attempt au-tomatic categorization for semantic rerendering ofan expert ontology, since definitional contextsprovide sortal information as a natural part of theprocess of precisely situating a term or conceptagainst the meaning network of interrelated lexi-cal items.
The Metalinguistic Information Databa-ses in their present form are not, in full justice,lexical knowledge bases comparable with thehighly-structured and sophisticated resources thatuse inheritance and typed features, like LKB (Co-pestake et al, 1993).
MIDs are semi-structuredresources (midway between raw corpora andstructured lexical bases) that can be further pro-cessed to convert them into usable data sources,along the lines suggested by Vossen and Copesta-ke (1993) for the syntactic kernels of lexicograp-hic definitions, or by Pustejovsky et al (2002)using corpus analytics to increase the semantictype coverage of the NLM UMLS ontology.
An-other interesting possibility is to use a dynami-cally-updated MID to trace the conceptual andterminological evolution of a discipline.We believe that low recall rates in our tests arein part due to the fact that we are dealing with thewider realm of metalinguistic information, as op-posed to structured definitional sentences thathave been distilled by an expert for consumer-oriented documents.
We have opted in favor ofexploiting less standardized, non-default metalin-guistic information that is being put forward intext because it can?t be assumed to be part of thecollective expert-domain competence (Section2.1).
In doing so, we have exposed our system tothe less predictable and highly charged lexicalenvironment of leading-edge research literature,the cauldron where knowledge and terminologicalsystems are forged in real time, and where scienti-Figure 4.
Metrics for 3 corpora(# of Records/Global F-Measure)0.60.70.80.91Precision Recall Precision Recall Precision RecallGlobal Informational Segments AutonymsHistology (35/0.71) Sociology (143/0.77) MedLine (10/0.78)fic meaning and interpretation are constantly de-bated, modified and agreed.
We have not per-formed major customization of the system (likeenriching the tagging lexicon with medical terms),in order to preserve the ability to use the systemacross different domains.
Domain customizationmay improve metrics, but at a cost for portability.The implementation we have described hereundoubtedly shows room for improvement in so-me areas, including: adding other patterns for bet-ter overall recall rates, deeper parsing for moreaccurate semantic typing of sentence arguments,etc.
Also, the issue of which learning algorithmscan better perform the initial filtering of EMOcandidates is still very much an open question.Applications that can turn MIDs into truly usefullexical resources by further processing them needto be written.
We plan to continue development ofour proof-of-concept system to explore those ar-eas.
DEFINDER and MOP both show great poten-tial as robust lexical acquisition systems capableof handling the vast electronic resources availabletoday to researchers and laymen alike, helping tomake them more accessible and useful.
In doingso, they are also fulfilling the promise of NLPtechniques as mature and practical technologies.ReferencesACQUILEX projects, final report available at:http://www.cl.cam.ac.uk/Research/NL/acquilex/Berger, A., S. Della Pietra  et al, 1996.
A Maxi-mum Entropy Approach to Natural LanguageProcessing.
Computational Linguistics, vol.
22,no.
1.Carnap, R. 1934.
The Logical Syntax of Lan-guage.
Routledge and Kegan, Londres 1964.Cartier, E. 1998.
Analyse Automatique des textes:l?example des informations d?finitoires.
RIFRA1998.
Sfax, Tunisia.Chieu, Hai Leong, Ng, Hwee Tou, & Lee, YoongKeok.
2003.
Closing the Gap: Learning-BasedInformation Extraction Rivaling Knowledge-Engineering Methods.
41st ACL.
Sapporo, Ja-pan.Copestake, A., Sanfilippo, A., Briscoe, T. and dePavia, V. 1993.
The ACQUILEX LKB: An in-troduction.
In: Inheritance, Defaults and theLexicon.
Cambridge University Press.Fisher, D., S. Soderland, J. McCarthy, F. Feng,and W. Lehnert.
1995.
Description of theUMass system as used for MUC-6.
In Proceed-ings of MUC-6Hearst, M. 1998.
Automated discovery of wordnetrelations.
In Christiane Fellbaum, editor,WordNet: An Electronic Lexical Database.
MITPress, Cambridge, MAKlavans, J. and S. Muresan.
2001.
Evaluation ofthe DEFINDER System for Fully AutomaticGlossary Construction, proceedings of theAmerican Medical Informatics AssociationSymposium 2001Lascarides, A. and Copestake A.
1995.
The Prag-matics of Word Meaning, Proceedings of theAAAI Spring Symposium Series: Representa-tion and Acquisition of Lexical Knowledge:Polysemy, Ambiguity and Generativity, Stan-ford CA.Manning, Ch.
1993.
Automatic acquisition of alarge subcategorization dictionary from cor-pora, In Proceedings of the 31st ACL, Colum-bus, OH.Nigam, K., Lafferty, J., and McCallum, A.
1999.Using Maximum Entropy for Text Classifica-tion, IJCAI-99 Workshop on Machine Learningfor Information Filtering, pp.
61-67Pustejovsky J., A. Rumshisky and J. Casta?o.2002.
Rerendering Semantic Ontologies: Auto-matic Extensions to UMLS through CorpusAnalytics.
LREC 2002 Workshop on Ontologiesand Lexical Knowledge Bases.
Las Palmas, Ca-nary Islands, Spain.Ratnaparkhi A.
1997.
A Simple Introduction toMaximum Entropy Models for Natural Lan-guage Processing, TR 97-08, Institute for Re-search in Cognitive Science, University ofPennsylvaniaRey-Debove, J.
1978.
Le M?talangage.
Le Robert,Paris.Rodr?guez, C. 2001.
Parsing MetalinguisticKnowledge from Texts,  Selected papers fromCICLING-2000 Collection in Computer Science(CCC); National Polytechnic Institute (IPN),Mexico.Vossen, P. and Copestake, A.
1993.
UntanglingDefinition Structure into Knowledge Represen-tation.
In: Inheritance, Defaults and the Lexi-con.
