Proceedings of the 6th Workshop on Statistical Machine Translation, pages 92?98,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsApproximating a Deep-Syntactic Metric for MT Evaluation and Tuning?Matous?
Macha?c?ek and Ondr?ej BojarCharles University in PragueFaculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostranske?
na?me?st??
25, Prague{bojar,machacek}@ufal.mff.cuni.czAbstractSemPOS is an automatic metric of machinetranslation quality for Czech and English fo-cused on content words.
It correlates wellwith human judgments but it is computation-ally costly and hard to adapt to other lan-guages because it relies on a deep-syntacticanalysis of the system output and the refer-ence.
To remedy this, we attempt at approxi-mating SemPOS using only tagger output anda few heuristics.
At a little expense in corre-lation to human judgments, we can evaluateMT systems much faster.
Additionally, we de-scribe our submission to the Tunable MetricsTask in WMT11.1 IntroductionSemPOS metric for machine translation quality wasintroduced by Kos and Bojar (2009).
It is inspiredby a set of metrics relying on various linguistic fea-tures on syntactic and semantic level introduced byGime?nez and Ma?rquez (2007).
One of their bestperforming metrics was Semantic role overlapping:the candidate and the reference translation are rep-resented as bags of words and their semantic roles.The similarity between the candidate and the refer-ence is calculated using a general similarity measurecalled Overlapping.
The formal definition may befound in Section 4.?
This work has been supported by the grants EuroMa-trixPlus (FP7-ICT-2007-3-231720 of the EU and 7E09003 ofthe Czech Republic), P406/10/P259, P406/11/1499, and MSM0021620838.Instead of semantic role labels (not available forCzech), Kos and Bojar (2009) use TectoMT frame-work (Z?abokrtsky?
et al, 2008) to assign a seman-tic part of speech defined by Sgall et al (1986).
Inaddition they use t-lemmas (deep-syntactic lemmas)instead of surface word forms, which most impor-tantly means that the metric considers content wordsonly.
In the following, we will use ?sempos?
to de-note the semantic part of speech and ?SemPOS?
todenote the whole metric by Kos and Bojar (2009).SemPOS correlates well with human judgmentson system level, see Section 2 for a brief summaryof how the correlation is computed.
The main draw-back of SemPOS is its computational cost becauseit requires full parsing up to the deep syntactic levelto obtain t-lemmas and semposes.
In Section 3 wepropose four methods which approximate t-lemmasand semposes without the deep syntactic analysis.These methods require only part-of-speech taggingand therefore they are not only faster but also eas-ier to adapt for other languages, not requiring moreadvanced linguistic tools.Gime?nez and Ma?rquez (2007) and Bojar et al(2010) used different formulas to calculate the finaloverlapping.1 In Section 4, we examine variationsof the formula, adding one version of our own.By combining one of the approximation tech-niques with one of the overlapping formulas, we ob-1In fact, Gime?nez and Ma?rquez (2007) released two versionsof the paper.
Both of them are nearly identical except for theformula for overlapping, so we asked the authors which of thetwo versions is correct.
It turns out that Bojar et al (2010),unaware of the second version of the paper, used the wrong onebut still obtained good results.
We therefore (re-)examine bothversions.92Workshop Filename Sentences To English from To Czech fromWMT08 test2008 2000 de, es, fr ?WMT08 nc-test2008 2028 cs enWMT08 newstest2008 2051 cs, de, es, fr enWMT09 newstest2009 2525 cs, de, es, fr enWMT10 newssyscombtest2010 2034 cs, de, es, fr enTable 1: Datasets used to evaluate the correlation with human judgments.
For example: the testset ?test2008?
wasused for translation to English from German, Spanish and French and it was not used for any translation to Czech.tain a variant of our metric.
The performance of theindividual variants is reported in Section 5.Section 6 is devoted to our submission to the Tun-able Metrics shared task of the Sixth Workshop onStatistical Machine Translation (WMT11).2 Method of EvaluationOur primary objective is to create a good metricfor automatic MT evaluation and possibly also tun-ing.
We are not interested much in how close is ourproposed approximation to the (automatic or man-ual) semposes and t-lemmas.
Therefore, we evaluateonly how well do our metrics (the pair of a chosenapproximation and a chosen formula for the overlap-ping) correlate with human judgments.2.1 Test DataWe use the data collected during three Workshops onStatistical Machine Translation: WMT08 (Callison-Burch et al, 2008), WMT09 (Callison-Burch et al,2009) and WMT10 (Callison-Burch et al, 2010).
Sofar, we study only Czech and English as the targetlanguages.
Our test sets are summarized in Table 1:we have four sets with Czech as the target languageand 16 sets with English as the target language.Each testset in each translation direction gives usfor each sentence one hypothesis for each participat-ing MT system.
Human judges (repeatedly) rankedsubsets of these hypotheses comparing at most 5 hy-potheses at once and indicating some ordering ofthe hypotheses.
The ordering may include ties.
InWMT, these 5-fold rankings are interpreted as ?sim-ulated pairwise comparisons?
: all pairwise compar-isons are extracted from each ranking.
The HUMANSCORE for each system is then the percentage ofpairs where the system was ranked better or equalto its competitor.2.2 Correlation with Human JudgmentsFor each metric we examine, the correlation to hu-man judgments is calculated as follows: given oneof the test sets (the hypotheses and reference transla-tions), the examined metric provides a single-figurescore for each system.
We use Spearman?s rank cor-relation coefficient between the human scores andthe scores of the given metric to see how well themetric matches human judgments.
Because tiedranks do not exist, the correlation coefficient is givenby:?
= 1?6?i(pi ?
qi)2n(n2 ?
1)(1)Human scores across different test sets are notcomparable, so we compute correlations for eachtest set separately and average them.3 Approximations of SemPOSWe would like to obtain t-lemmas and semantic partsof speech without deep syntactic analysis, assumingonly automatic tagging and lemmatization.Except for one option (Section 3.4), we approxi-mate t-lemmas simply by surface lemmas.
For themajority of content words, this works perfectly, butthere are several regular classes of words where thet-lemma differs.
In such cases, the t-lemma usu-ally consists of the lemma of the main content wordand an auxiliary word that significantly changes themeaning of the content word.
These are e.g.
Englishphrasal verbs (?blow up?
should have the t-lemma?blow up?)
and Czech reflexive verbs (?sma?t se?
).The approximation of semantic part of speech de-serves at least some minimal treatment.
The follow-ing sections describe four variations of the approxi-mation.93Morph.
Tag Sempos Rel.
Freq.NN n.denot 0.989VBZ v 0.766VBN v 0.953JJ adj.denot 0.975NNP n.denot 0.999PRP n.pron.def.pers 0.999VB v 0.875VBP v 0.663VBD v 0.810WP n.pron.indef 1.000NNS n.denot 0.996JJR adj.denot 0.813Table 2: A sample of the mapping from English morpho-logical tags to semposes, including the relative frequency,e.g.
count(NN,n.denot)count(NN) .3.1 Sempos from TagWe noticed that the morphological tag determinesalmost uniquely the semantic part of speech.
We usethe Czech-English sentence-parallel corpus CzEng(Bojar and Z?abokrtsky?, 2009) to create a simple dic-tionary which maps morphological tags to most fre-quent semantic parts of speech.
Some morpholog-ical tags belong almost always to auxiliary wordswhich do not have a corresponding deep-syntacticnode at all, so the t-lemma and sempos are not de-fined for them.
We include these morphological tagsin the dictionary and map them to a special semposvalue ?-?.
Ultimately, words with such sempos arenot included in the overlapping at all.Table 2 shows a sample of this dictionary.
Thehigh relative frequencies indicate that we are not los-ing too much of the accuracy: overall 93.6 % forEnglish and 88.4 % for Czech on CzEng e-test.The first approximation relies just on this(language-specific) dictionary.
The input text is au-tomatically tagged, the morphological tags are de-terministically mapped to semposes using the dictio-nary and words where the mapping led to the specialvalue of ?-?
are removed.In the following, we label this method as APPROX.3.2 Exclude Stop-WordsBy definition, the deep syntactic layer we use repre-sents more or less only content words.
Most aux-iliary words become only attributes of the deep-syntactic nodes and play no role in the overlappingbetween the hypothesis and the reference.Our first approximation technique (Section 3.1)identifies auxiliary words only on the basis of themorphological tag.
We attempt to refine the re-call by excluding a certain number of most frequentwords in each language.
The frequency list was ob-tained from the Czech and English sides of the cor-pus CzEng.
We choose the exact cut-off for stop-words in each language separately: 100 words inEnglish and 220 words in Czech.
See Section 5.1below.In the following, the method is called APPROX-STOPWORDS.3.3 Restricting the Set of Examined SemposesWe noticed that the contribution of each sempos tothe overall performance of the metric in terms of cor-relation to human judgments can differ a lot.
Oneof the underlying reasons may be e.g.
greater orlower tagging accuracy of certain word classes, an-other reason may be that translation errors in certainword classes may be more relevant for human judgesof MT quality.Tables 3 and 4 report the correlation to humanjudgments if only words in a given sempos are con-sidered in the overlapping.
Based on these obser-vations, we assume that some sempos types raisethe correlation of the overlapping with human judg-ments and some lower it.
We therefore try one morevariant of the approximation which considers only(language-specific) subset of semposes.The approximation called APPROX-RESTR con-siders only these sempos tags in Czech: v, n.denot,adj.denot, n.pron.def.pers, n.pron.def.demon, adv.-denot.ngrad.nneg, adv.denot.grad.nneg.
The consid-ered sempos tags for English are: v, n.denot, adj.-denot, n.pron.indef.3.4 T-lemma and Sempos TaggingOur last approximation method differs a lot from theprevious three approximations.
We use the sequencelabeling algorithm (Collins, 2002) as implementedin Featurama2 to choose the t-lemma and sempostag.
The CzEng corpus (Bojar and Z?abokrtsky?,2009) serves to train two taggers: one for Czech and2http://sourceforge.net/projects/featurama/94Tag R. Fr.
Min.
Max.
Avg.v 0.236 0.403 1.000 0.735n.denot 0.506 0.189 1.000 0.728adj.denot 0.124 0.264 0.964 0.720n.pron.indef 0.019 0.224 1.000 0.639n.quant.def 0.039 -0.084 0.893 0.495n.pron.def.pers 0.068 -0.500 0.975 0.493adv.pron.indef 0.005 -0.382 1.000 0.432adv.denot.grad.neg 0.003 -1.000 0.904 0.413Table 3: English semposes and their performance interms of correlation with human judgments if only wordsof the given sempos in APPROX are checked for matchwith the reference.
Averaged across all testsets.
Over-lapping CAP is used, see Section 4 below.
Column R. Fr.reports relative frequency of each sempos in the testsets.Tag R. Fr.
Min.
Max.
Avg.n.pron.def.pers 0.030 0.406 0.800 0.680n.pron.def.demon 0.026 0.308 1.000 0.651adj.denot 0.156 0.143 0.874 0.554adv.denot.ngrad.nneg 0.047 0.291 0.800 0.451adv.denot.grad.nneg 0.001 0.219 0.632 0.445adj.quant.def 0.004 -0.029 0.800 0.393n.denot.neg 0.037 0.029 0.736 0.391adv.denot.grad.neg 0.018 -0.371 0.800 0.313n.denot 0.432 -0.200 0.720 0.280adv.pron.def 0.000 -0.185 0.894 0.262adj.pron.def.demon 0.000 0.018 0.632 0.241n.pron.indef 0.027 -0.200 0.423 0.112adj.quant.grad 0.006 -0.225 0.316 0.079v 0.180 -0.600 0.706 0.076adj.quant.indef 0.002 -0.105 0.200 0.052adv.denot.ngrad.neg 0.000 -0.883 0.775 0.000n.quant.def 0.000 -0.800 0.713 -0.085Table 4: Czech semposes.
See Table 3 for explanation.one for English.
At each token, each of the taggersuses the word form, morphological tag and surfacelemma (of the current and the previous two tokens)to choose one pair of t-lemma and sempos tag froma given set.The set of possible t-lemma and sempos pairs iscreated as follows.
At first the sempos set is ob-tained.
We simply use all semposes being seen withthe given morphological tag in the corpus.
Then wefind possible t-lemmas for each sempos.
For mostsemposes we consider surface lemma as the onlyt-lemma.
For the sempos tag ?v?
we also add t-lemmas composed of the surface lemma and someauxiliary word present in the sentence (?blow up?,?sma?t se?).
For some other sempos tags we add spe-cial t-lemmas for negation and personal pronouns(?#Neg?, ?#PersPron?
).The overall accuracy of the tagger on the e-test is97.9 % for English and 94.9 % for Czech, a better re-sult on a harder task (t-lemmas also predicted) thanthe deterministic tagging in Section 3.1.We call this approximation method TAGGER.4 Variations of OverlappingThe original Overlapping defined by Gime?nez andMa?rquez (2007) is given in Equations 2 and 3:O(t) =?w?ricnt(w, t, ci)?w?ri?cimax(cnt(w, t, ri), cnt(w, t, ci))(2)where ci and ri denotes the candidate and refer-ence translation of sentence i and cnt(w, t, s) de-notes number of times t-lemma w of type (sempos)t appears in sentence s. For each sempos type t,Overlapping O(t) calculates the proportion of cor-rectly translated items of type t. In this paper wewill call this overlapping BOOST.Equation 3 describes Overlapping of all types:O(?)
=?t?T?w?ricnt(w, t, ci)?t?T?w?ri?cimax(cnt(w, t, ri), cnt(w, t, ci))(3)where T denotes the set of all sempos types.
Wewill call this Overlapping BOOST-MICRO because itmicro-averages the overlappings of individual sem-pos types.Kos and Bojar (2009) used a slightly differentOverlapping formula, denoted CAP in this paper:O(t) =?w?rimin(cnt(w, t, ri), cnt(w, t, ci))?w?ricnt(w, t, ri)(4)To calculate Overlapping of all types, Kos andBojar (2009) used ordinary macro-averaging.
Wecall the method CAP-MACRO:O(?)
=1|T |?t?TO(t) (5)The difference between micro- and macro-average is that in macro-average all types have95Reduction Overlapping Min.
Max.
Avg.approx cap-micro 0.409 1.000 0.804orig cap-macro 0.536 1.000 0.801approx cap-macro 0.420 1.000 0.799approx-restr cap-macro 0.476 1.000 0.798tagger cap-micro 0.409 1.000 0.790orig cap-micro 0.391 1.000 0.784approx-restr cap-micro 0.391 1.000 0.782approx-stopwords cap-micro 0.391 1.000 0.754sempos-bleu 0.374 1.000 0.754approx-stopwords cap-macro 0.280 1.000 0.724tagger boost-micro 0.306 1.000 0.717orig boost-micro 0.324 1.000 0.711approx-stopwords boost-micro 0.133 1.000 0.697approx-restr boost-micro 0.126 1.000 0.688approx boost-micro 0.224 1.000 0.686tagger cap-macro 0.118 1.000 0.669bleu -0.143 1.000 0.628Table 5: Metric correlations for English as a target lan-guagethe same weight regardless of count.
For exam-ple O(n.denot) and O(adv.denot.grad.nneg) wouldhave the same weight, however there are manymore items of type n.denot than items of typeadv.denot.grad.nneg (see Tables 3 and 4).
We con-sider this unnatural and we suggest a new Overlap-ping formula CAP-MICRO:O(?)
=?t?T?w?rimin(cnt(w, t, ri), cnt(w, t, ci))?t?T?w?ricnt(w, t, ri)(6)In sum, we have three Overlappings which shouldbe evaluated: BOOST-MICRO (Equation 3), CAP-MACRO (Equation 5), and CAP-MICRO (Equation 6).5 ExperimentsTable 5 shows the results for English as the targetlanguage.
The first two columns denote the combi-nation of an approximation method and an overlap-ping formula.
For conciseness, we report only theminimum, maximum and average value among cor-relations of all test sets.To compare metrics to original SemPOS, the ta-ble includes non-approximated variant ORIG wherethe t-lemmas and semposes are assigned by the Tec-toMT framework.
For the purposes of compari-son, we also report the correlations of BLEU (Pa-pineni et al, 2002) and a linear combination of AP-Reduction Overlapping Min.
Max.
Avg.approx-restr cap-macro 0.400 0.800 0.608tagger cap-macro 0.143 0.800 0.428orig cap-macro 0.143 0.800 0.423approx-restr cap-micro 0.086 0.769 0.413tagger cap-micro 0.086 0.769 0.413orig cap-micro 0.086 0.741 0.406approx-stopwords cap-micro 0.086 0.790 0.368approx cap-micro 0.086 0.734 0.354approx-stopwords cap-macro 0.086 0.503 0.347sempos-bleu 0.086 0.676 0.340approx cap-macro 0.086 0.469 0.338tagger boost-micro 0.086 0.664 0.337bleu 0.029 0.490 0.279orig boost-micro -0.200 0.692 0.273approx-stopwords boost-micro -0.200 0.685 0.271approx boost-micro -0.200 0.664 0.266approx-restr boost-micro -0.200 0.664 0.266Table 6: Metric correlations for Czech as a target lan-guagePROX+CAP-MICRO and BLEU (even weights) underthe name SEMPOS-BLEU since this metric was usedin Tunable Metric Task (Section 6).The best performing metric is the combinationof approximation APPROX and overlapping CAP-MICRO.
It actually slightly outperforms all non-approximated metrics.
In general, the reductionsAPPROX and ORIG combined with CAP-MICROor CAP-MACRO perform very well.
ReductionsAPPROX-STOPWORDS and APPROX-RESTR do notimprove on APPROX.The TAGGER approximation correlates similarlyto ORIG when micro-average is used.Table 6 contains the results for Czech as the targetlanguage.
The best performing metric for Czech isAPPROX-RESTR together with CAP-MACRO.
In gen-eral approximation APPROX-RESTR is better thanAPPROX-STOPWORDS which is slightly better thanAPPROX.The success of overlapping CAP-MACRO in Czechis due to the higher contribution of less frequentsemposes to the overall correlation.
While in En-glish the best correlating semposes are also very fre-quent (Table 3), this does not hold for Czech (Ta-ble 4).
The underlying reasons have yet to be ex-plained.In both languages, the overlapping BOOST-MICRO has a very low correlation.
We thereforeconsider this overlapping not suitable for any met-960.620.640.660.68 0.70.720.740.760.78 0.80.82050100150200250300cap-microcap-macroboost-microFigure 1: Correlation vs. the number of most frequentwords which are thrown away for English.
The big dropfor lengths 109 and 110 is caused by the words ?who?
and?how?.ric based on semposes.On the other hand, most of the examined com-binations are on average better than the baselineBLEU, sometimes by a very wide margin.5.1 Dependency of Correlation on StopwordsList LengthWe tried various stopwords list lengths for theapproximation APPROX-STOPWORDS.
Figure 5.1shows the dependency of the correlation on stop-words list length for all overlappings in English.
Wesee that the best correlation arises when no wordsare thrown away.
One possible explanation is thatauxiliary words are recognized by the morphologi-cal tag well enough anyway and stopwords lists re-move also important content words, decreasing theoverall accuracy of the overlapping.6 Tunable Metric WMT11 Shared TaskThe goal of the tunable metric task in WMT11 wasto use the custom metric in MERT optimization(Och, 2003).
The target language was English.
Wechoose APPROX + CAP-MICRO since this combina-tion correlates best with human judgments.Based on the experience of Bojar and Kos (2010),we combine this metric with BLEU.
In our opin-ion, the SemPOS metric and its variants alone areare good at comparing systems?
outputs where sen-tence fluency has been already ensured.
On the otherhand, they fail in ranking sentences in n-best listsWeights Devset scoresBLEU APPROX BLEU APPROX1 0 0.246 0.5460.75 0.25 0.242 0.5840.5 0.5 0.229 0.5940.25 0.75 0.215 0.6020 1 0.025 0.631Table 7: Results of MERT optimization.
The last twocolumns contain metric scores of the last iteration of theMERT process with given combination weights.in MERT optimization because they observe onlyt-lemmas and don?t penalize wrong morphologicalforms of words.
We thus use BLEU to establishsentence fluency and our metrics to prefer sentenceswith correctly translated content words.We have tried several weights for the linear com-bination of BLEU and the chosen approximation.See Table 7 for details.
We have submitted the vari-ant with equal weights.The preliminary results of manual evaluation (seethe WMT11 overview paper) indicate that our sys-tem is fairly distinct from others: we won under the?> others?
metric but we were the fifth of 8 systemsin the official ??
others?
(the percentage of pairswhere the system was ranked better or equal to itscompetitor).7 ConclusionsWe have introduced and evaluated several approx-imations of a deep-syntactic MT evaluation metricSEMPOS.
This allows us to reduce the computa-tional load by far, use only shallow tagging and stillreach reasonable correlation scores.For English, our combination of APPROX andCAP-MICRO performs even marginally better thanthe original SEMPOS.
For Czech, it is APPROX-RESTR and TAGGER approximations with CAP-MACRO that outperform the original SEMPOS.The applicability of these metrics (in link withBLEU) in model optimization was confirmed bythe manual judgments for the Tunable Metrics Task.Our submission was surprisingly different from oth-ers: the best one in the score excluding ties andmediocre in the score where ties are rewarded.97ReferencesOndrej Bojar and Kamil Kos.
2010.
2010 Failures inEnglish-Czech Phrase-Based MT.
In Proceedings ofthe Joint Fifth Workshop on Statistical Machine Trans-lation and MetricsMATR, pages 60?66, Uppsala, Swe-den, July.
Association for Computational Linguistics.Ondr?ej Bojar and Zdene?k Z?abokrtsky?.
2009.
CzEng0.9:Large Parallel Treebank with Rich Annotation.Prague Bulletin of Mathematical Linguistics, 92. inprint.Ondr?ej Bojar, Kamil Kos, and David Marec?ek.
2010.Tackling Sparse Data Issue in Machine TranslationEvaluation.
In Proceedings of the ACL 2010 Con-ference Short Papers, pages 86?91, Uppsala, Sweden,July.
Association for Computational Linguistics.Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,Christof Monz, and Josh Schroeder.
2008.
Furthermeta-evaluation of machine translation.
In Proceed-ings of the Third Workshop on Statistical MachineTranslation, pages 70?106, Columbus, Ohio, June.Association for Computational Linguistics.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Josh Schroeder.
2009.
Findings of the 2009Workshop on Statistical Machine Translation.
InProceedings of the Fourth Workshop on StatisticalMachine Translation, pages 1?28, Athens, Greece,March.
Association for Computational Linguistics.Chris Callison-Burch, Philipp Koehn, Christof Monz,Kay Peterson, Mark Przybocki, and Omar Zaidan.2010.
Findings of the 2010 joint workshop on sta-tistical machine translation and metrics for machinetranslation.
In Proceedings of the Joint Fifth Workshopon Statistical Machine Translation and MetricsMATR,pages 17?53, Uppsala, Sweden, July.
Association forComputational Linguistics.
Revised August 2010.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: theory and experi-ments with perceptron algorithms.
In EMNLP ?02:Proceedings of the ACL-02 conference on Empiricalmethods in natural language processing, pages 1?8,Morristown, NJ, USA.
Association for ComputationalLinguistics.Jesu?s Gime?nez and Llu?
?s Ma?rquez.
2007.
LinguisticFeatures for Automatic Evaluation of HeterogenousMT Systems.
In Proceedings of the Second Work-shop on Statistical Machine Translation, pages 256?264, Prague, June.
Association for Computational Lin-guistics.Kamil Kos and Ondr?ej Bojar.
2009.
Evaluation of Ma-chine Translation Metrics for Czech as the Target Lan-guage.
Prague Bulletin of Mathematical Linguistics,92.Franz Josef Och.
2003.
Minimum Error Rate Training inStatistical Machine Translation.
In Proc.
of the Asso-ciation for Computational Linguistics, Sapporo, Japan,July 6-7.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In ACL 2002, Proceed-ings of the 40th Annual Meeting of the Association forComputational Linguistics, pages 311?318, Philadel-phia, Pennsylvania.Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.
1986.The Meaning of the Sentence and Its Semantic andPragmatic Aspects.
Academia/Reidel PublishingCompany, Prague, Czech Republic/Dordrecht, Nether-lands.Zdene?k Z?abokrtsky?, Jan Pta?c?ek, and Petr Pajas.
2008.TectoMT: Highly modular MT system with tectogram-matics used as transfer layer.
In ACL 2008 WMT: Pro-ceedings of the Third Workshop on Statistical MachineTranslation, pages 167?170, Columbus, OH, USA.Association for Computational Linguistics.98
