Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 96?106,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsComparing Computational Cognitive Models of Generalization in aLanguage Acquisition TaskLibby Barak, Adele E. Goldberg,Psychology DepartmentPrinceton UniversityPrinceton, NJ, USA{lbarak,adele}@princeton.eduSuzanne StevensonDepartment of Computer ScienceUniversity of TorontoToronto, Canadasuzanne@cs.toronto.eduAbstractNatural language acquisition relies on appro-priate generalization: the ability to producenovel sentences, while learning to restrict pro-ductions to acceptable forms in the language.Psycholinguists have proposed various prop-erties that might play a role in guiding appro-priate generalizations, looking at learning ofverb alternations as a testbed.
Several com-putational cognitive models have explored as-pects of this phenomenon, but their results arehard to compare given the high variability inthe linguistic properties represented in theirinput.
In this paper, we directly compare tworecent approaches, a Bayesian model and aconnectionist model, in their ability to repli-cate human judgments of appropriate gener-alizations.
We find that the Bayesian modelmore accurately mimics the judgments due toits richer learning mechanism that can exploitdistributional properties of the input in a man-ner consistent with human behaviour.1 IntroductionNative speakers of a language are mostly able togeneralize appropriately beyond the observed datawhile avoiding overgeneralizations.
A testbed areafor studying generalization behavior in language ac-quisition is verb alternations ?
i.e., learning the pat-terns of acceptability of alternative constructions forexpressing similar meanings.
For example, Englishspeakers readily use a new verb like text in both thedouble-object (DO) construction (?text me the de-tails?)
and the prepositional-dative (PD) (?text thedetails to me?)
?
an instance of the dative alterna-tion.
However, speakers avoid overgeneralizing theDO construction to verbs such as explain that resistits use (?
?explain me the details?
), even though theyoccur with analogous arguments in the PD alterna-tive (?explain the details to me?).
Psycholinguis-tic studies have focused on the possible propertiesof natural language that enable such generalizationwhile constraining it to acceptable forms.Initially, children are linguistically conservative:they generally use verbs in constructions that arevery close to exemplars in the input (Lieven et al,1997; Akhtar, 1999; Tomasello, 2003; Boyd andGoldberg, 2009).
Children reach adult-like com-petence by gradually forming more general as-sociations of constructions to meaning that allowthem to extend verb usages to unwitnessed forms.Much work has emphasized the role of verb classesthat capture the regularities across semantically-similar verbs, enabling appropriate generalization(e.g., Pinker, 1989; Fisher, 1999; Levin, 1993; Am-bridge et al, 2008).
Usage-based approaches haveargued that such class-based behaviour can arise inlearning through the clustering of observed usagesthat share semantic and syntactic properties (e.g.,Bybee, 2010; Tomasello, 2003; Goldberg, 2006).A number of studies also reveal that the statisticalproperties of the language play a central role in lim-iting generalization (e.g., Bresnan and Ford, 2010;Ambridge et al, 2012, 2014).
Individual verbs of-ten show statistical biases that favor their appear-ance in one construction over another (Ford et al,1982; MacDonald et al, 1994; Garnsey et al, 1997;Trueswell et al, 1993; Losiewicz, 1992; Gahl andGarnsey, 2004).
For example, while both give andpush can occur in either DO or PD constructions,96give strongly favors the DO construction (?give methe box?
), while push strongly favors the PD (?pushthe box to me?)
(Wasow, 2002).
Generally, themore frequent a verb is overall, the less likely speak-ers are to extend it to an unobserved construction(Braine and Brooks, 1995).
In addition, when a verbrepeatedly occurs in one construction when an al-ternative construction could have been appropriate,speakers appear to learn that the verb is inappropri-ate in the alternative, regardless of its overall fre-quency (Goldberg, 2011).Given these observations, it has been argued thatboth the semantic and statistical properties of averb underlie its degree of acceptability in alternat-ing constructions (e.g., Braine and Brooks, 1995;Theakston, 2004; Ambridge et al, 2014).
Recently,Ambridge and Blything (2015) propose a computa-tional model designed to study the role of verb se-mantics and frequency in the acquisition of the da-tive alternation.
However, they only evaluate theirmodel preferences for one of the two constructions,which does not provide a full picture of the alterna-tion behaviour; moreover, they incorporate certainassumptions about the input that may not match theproperties of naturalistic data.In this paper, we compare the model of Ambridgeand Blything (2015) to the Bayesian model of Baraket al (2014) that offers a general framework of verbconstruction learning.
We replicate the approachtaken in Ambridge and Blything (2015) in order toprovide appropriate comparisons, but we also extendthe experimental settings and analysis to enable amore fulsome evaluation, on data with more natu-ralistic statistical properties.
Our results show thatthe Bayesian model provides a better fit to the psy-cholinguistic data, which we suggest is due to itsricher learning mechanism: its two-level clusteringapproach can exploit distributional properties of theinput in a manner consistent with human generaliza-tion behaviour.2 Related WorkAcquisition of the dative alternation ?
use of the DOand PD constructions with analogous semantic argu-ments ?
has been studied in several computationalcognitive models because it illustrates how peoplelearn to appropriately generalize linguistic construc-tions in the face of complex, interacting factors.As noted by Ambridge et al (2014), such modelsshould capture influences of the verb such as its se-mantic properties, its overall frequency, and its fre-quency in various constructions.A focus of computational models has been toshow under what conditions a learner generalizesto the DO construction having observed a verb inthe PD, and vice versa.
For example, the hierar-chical Bayesian models of Perfors et al (2010) andParisien and Stevenson (2010) show the ability togeneralize from one construction to the other.
How-ever, both models are limited in their semantic repre-sentations.
Perfors et al (2010) use semantic prop-erties that directly (albeit noisily) encode the knowl-edge of the alternating and non-alternating (DO-only or PD-only) classes.
The model of Parisien andStevenson (2010) addresses this limitation by learn-ing alternation classes from the data (including thedative), but it uses only syntactic slot features thatcan be gleaned automatically from a corpus.
In ad-dition, both models use batch processing, failing toaddress how learning to generalize across an alter-nation might be achieved incrementally.Alishahi and Stevenson (2008) presents an in-cremental Bayesian model shown to capture vari-ous aspects of verb argument structure acquisition(Alishahi and Pyykkon?en, 2011; Barak et al, 2012,2013b; Matusevych et al, 2016), but the modelis unable to mimic alternation learning behaviour.Barak et al (2014) extends this construction-learning model to incrementally learn both construc-tions and classes of alternating verbs, and show therole of the classes in learning the dative.
However,like Parisien and Stevenson (2010), the input to themodel in this study is limited to syntactic properties,not allowing for a full analysis of the relevant factorsthat influence acquisition of alternations.Ambridge and Blything (2015) propose the firstcomputational model of this phenomenon to includea rich representation of the verb/construction seman-tics, drawn from human judgments.
In evaluation,however, they only report the ability of the modelto predict the DO usage (i.e., only one pair of thealternation), which does not give the full picture ofthe alternation behaviour.
Moreover, their assump-tions about the nature of the input ?
including theuse of raw vs. log frequencies and the treatment of97Figure 1: A visual representation of the feed-forwardnetwork used by the AB model.
(The figure is adaptedfrom output of the OXlearn package of Ruh and West-ermann (2009).)
The input nodes correspond to the se-mantic properties of the verbs, the verb lexemes, and a?transfer?
node (explained in the text).
The output nodescorrespond to the target constructions.non-dative construction usages ?
differ from earliermodels, making it difficult to compare the results.In this paper, we compare the models of Am-bridge and Blything (2015) and Barak et al (2014),using the same input settings for each, so that, forthe first time, two computational models of this gen-eralization phenomenon can be directly compared.Moreover, in contrast to Ambridge and Blything(2015) and in line with the other studies mentionedabove, we evaluate the ability of the models to gen-erate both the DO and the PD alternates, on a perverb basis, in order to more accurately assess the fitto human judgments.3 The Computational ModelsIn this section, we give an overview of the con-nectionist model of Ambridge and Blything (2015),hereafter the AB model, and the Bayesian model ofBarak et al (2014), hereafter the BFS model, fol-lowed by a comparison of their relevant properties.3.1 Overview of the Connectionist ModelThe AB connectionist model of Ambridge and Bly-thing (2015) aims to predict the preference of a verbfor each of three target constructions, on the basisof verb semantics and the observed distribution ofverbs in those constructions in the input.
Figure 1provides an illustration of the 3-layer feed-forwardnetwork, trained using backpropagation.
Each inputto the model consists of lexical and semantic fea-tures of a verb and its usage.
The target output isa 1-hot pattern across output nodes, each of whichrepresents the use of the verb in the associated con-struction.
The possible constructions are DO, PD, orother, representing all other constructions the verbappears in.
Training presents the slate of input fea-tures with the appropriate output node activated rep-resenting the construction the verb appears in.
In afull sweep of training, the model observes all verbsin proportion to their frequency in the input; for eachverb, the proportion of training trials with 1 in eachof the output nodes corresponds to the frequency ofthe verb in each of those constructions.
During test-ing, only the input nodes are activated (correspond-ing to a verb and its semantics), and the activationof output nodes reveals the learned proportional ac-tivation rate corresponding to the degree of verb biastoward either the DO or the PD (or other).The structure of the AB model encodes some as-sumptions regarding the information and learningmechanisms available to the learner.
The model in-corporates awareness of individual verbs by having anode per verb in the input to distinguish the usage ofeach verb and its accompanying features.
Each verbis also represented by a vector of semantic featuresthat capture properties relevant to its meaning whenused in one of the two dative constructions (basedon elicited human judgments from Ambridge et al,2014).
The ?transfer?
input node encodes the abil-ity to distinguish the semantic properties of the da-tive constructions from other constructions: i.e., thisnode is set to 1 for a DO or PD usage, and to 0 oth-erwise.
Representing the construction of the inputusage (DO, PD, or other) on the output nodes re-flects the formalization of the learning as an associa-tion of semantic and lexical features with a syntacticpattern, and the knowledge of the model is demon-strated by activating the construction output nodesin response to a lexical/semantic input.3.2 Overview of the Bayesian ModelThe BFS of model Barak et al (2014) is a Bayesianclustering model that simultaneously and incremen-tally learns both constructions and verb classes in atwo-level design; see Figure 2 for an illustration ofeach level.
In learning, the model processes an inputsequence of verb usages, represented as collectionsof semantic and syntactic features, one usage at atime.
The first step of processing each input aims to98Figure 2: A visual representation of the the Bayesianmodel, with sample input features for verb usages, con-struction level, and verb class level.find the best cluster at level one as:BestCluster(Fi) = argmaxk?ClustersP (k|Fi) (1)where Fi is the set of features for input i, and kranges over all existing clusters and a new one.
Thenumber of possible clusters is not set in advanced,and thus at any step the best choice may be to start anew cluster (of size 1) with this input.Using Bayes rule:P (k|Fi) =P (k)P (Fi|k)P (Fi)?
P (k)P (Fi|k) (2)The prior probability of a cluster P (k) is propor-tional to the number of verb usages clustered to kso far, thus assigning a higher prior to larger clus-ters.
The likelihood P (Fi|k) is estimated based onthe match of feature values in the current verb usageto those aggregated in the cluster, where the qualityof the match depends on the frequency and vectorsimilarity of the two sets of features.The clusters at this level correspond to construc-tions of the language ?
i.e., probabilistic associa-tions of form and meaning.
For example, a clus-ter emerges from semantically-similar verbs like telland ask, in a particular syntax, such as the DO.
Cre-ating a new cluster ?
forming a new construction ?depends on both the likelihood and the prior.
Earlyon, the P (Fi|k) term has more influence and differ-ences in feature values between a new usage and ex-isting clusters will often trigger a new cluster.
Later,the model will favour adding a new input to an ex-isting cluster ?
even if it makes it more heteroge-neous ?
because the P (k) term prefers larger clus-ters as the number of observed inputs increases.
Thismechanism mimics human language learning behav-ior of moving from more verb-specific constructionsto more general constructions (Tomasello, 2003).Each verb can occur in several clusters in the firstlevel based on its association with various seman-tic and syntactic features.
For instance, the alternat-ing verb give can occur in one cluster associatinga transfer meaning with PD syntax and in a secondcluster associating a transfer meaning with DO syn-tax.
To capture the common behaviour of such al-ternating verbs ?
where verbs with similar meaningsoccur across the same set of clusters ?
the model rep-resents the similarity in distributional properties ofthe verbs in a second level of representation, whichcaptures such verb class behaviours.Formally, after each clustering decision in the firstlevel, the model calculates the current frequency dis-tribution of the input verb over all level-one clus-ters.
This distribution vector is used as input for thesecond level: the model measures the similarity ofthis vector to the weighted average distribution rep-resented by each second-level cluster, adding the in-put verb?s distribution to the most similar one:BestClass(dvt) = argmaxc?Classes(1?DJS(dc?dvt))(3)where dvt is the current distribution of the verb vover the clusters (i.e., at time t), c ranges over all theclasses in the second level, dc is the weighted aver-age of c given the distributions of its member verbtokens, and DJS is the Jensen?Shannon divergence.As in the first level, the model may create a new clus-ter in the second level if none of the existing clustersis similar enough to dvt .The resulting second-level clusters capture verbclass behavior by grouping verbs that share a pat-tern of usages across constructions, e.g., alternatingverbs that occur with the DO and PD syntax.
Theseclusters encode a snapshot of the distribution of eachverb each time it occurs in the input, reflecting theneed of the language learner to incrementally updatetheir knowledge of the distributional behavior of theverb across constructions.3.3 Comparison of the ModelsBoth models capture the semantic and statisticalproperties of language proposed as possible fac-tors in the ability to learn an alternation appropri-99ately ?
i.e., to generalize to new uses but not over-generalize to inappropriate verbs.
Semantic influ-ences are reflected in the use of meaning features,and each model incorporates the key idea behindstatistical preemption (Goldberg, 1995), namelythat semantically-appropriate constructions competewith one another.
The statistical effects of over-all verb frequency and of frequency of the verb-in-construction are captured by inputting each verb inproportion to its frequency with each construction.The models have a crucial difference in how theyreflect the influence of the various features in learn-ing alternations.
As a feed-forward network, theAB model learns the weight of the semantic featuresgiven the entire set of input, and uses these weight-ings to shape the prediction of a verb?s preferencefor each of the syntactic constructions (representedby the target output nodes).
The BFS model does notexplicitly weight features, but the influence of a fea-ture is determined by its local context within a clus-ter.
For example, if the value of a feature has highfrequency in a cluster ?
e.g., the cluster records us-ages with only the DO syntax ?
the predictions basedon this cluster would strongly prefer matching us-ages based on this feature value; a less-frequent fea-ture would have less influence on this cluster?s pre-dictions, but could have more influence in a clusterwhere it is more represented.
This property, alongwith the representation of an open-ended set of con-structions (level one clusters) and verb classes (leveltwo clusters), enables the model to capture rich in-teractions among the lexical, semantic, and syntacticfeatures.
We evaluate the role of these differences inthe fit of each model to the task.4 Experimental Setup4.1 Input and TrainingWe base the learning and evaluation on the 281 dis-tinct verbs used in Ambridge and Blything (2015),which had been determined to occur in the dou-ble object (DO) and/or the preposition-dative (PD)(Pinker, 1989; Levin, 1993).
Following Ambridgeand Blything (2015), we consider a third (artificial)construction labeled as other that corresponds to allnon-DO and non-PD usages of a verb.
The mod-els are trained on usages of the verbs in proportionto their frequencies in the British National CorpusRaw freq Log freq#Verbs DO PD other DO PD otherPD 101 0 93 9964 0 3 5DO 7 49 0 877 2 0 4Alt 75 325 1144 13332 3 3 7Uns 98 0 0 716 0 0 4Table 1: Frequency data for the dative verbs in theBNC for non-alternating PD-only and DO-only verbs,ALTernating verbs, and UNSeen dative-taking verbs thatdo not occur with the dative constructions in the BNC.
(BNC) (Leech, 1992).
Table 1 summarizes the per-construction frequency data for the verbs.1 Note that98 of the verbs can occur in the DO and/or PD buthave no such occurrences in the BNC; these verbsunseen in the dative are important for judging theappropriate generalization behavior of the models.The input to the models include: the lexeme ofthe verb, the semantic features of the verb, a ?trans-fer?
feature marking the common meaning of the da-tive constructions, and (in training only) a syntacticfeature.
The syntactic feature indicates whether averb is used with the DO, PD, or other construc-tion; in the AB model, this is given as the targetoutput node in training.
The verb semantic featuresare those used in Ambridge and Blything (2015).These vectors are based on the ratings of each verbon 18 meaning properties relevant to use of the verbin the dative (e.g., ?The verb specifies the means oftransfer?
Ambridge et al, 2014), subject to Princi-pal Component Analysis by Ambridge and Blything(2015), yielding a vector of 7 dimensions.
The trans-fer feature is 1 for a verb usage in one of the two da-tive constructions, and 0 for the other construction,to indicate the shared transfer meaning conveyed bythe DO and the PD.
The input to each model is gen-erated automatically to correspond to the BNC fre-quencies of each verb in each of the constructions.It should be noted that, while we adopt the se-mantic features of Ambridge and Blything (2015),they reflect the meaning within the two dative con-structions and may be less applicable to the otherconstruction.
In addition, we found that there arealternating and non-alternating verbs that have verysimilar semantic vectors, indicating that these fea-1The full list of verbs and their frequencies can be found inAmbridge and Blything (2015).100tures may not sufficiently distinguish the alternationbehaviours.The models are trained with sufficient input toconverge on stable behavior.
We follow Ambridgeand Blything (2015) in training and testing the ABmodel using the OXlearn MATLAB package (Ruhand Westermann, 2009); the input is generated us-ing a random seed, in random input order withoutreplacements, and the model is trained with a learn-ing rate of 0.01 for 1K sweeps for log frequencies;100K sweeps for raw frequencies.
We train the BFSmodel using the input generation method describedby Barak et al (2014), with the features as above.The model is trained on 5K input verb usages (inproportion to their frequencies in the constructions).4.2 Evaluation of the ModelsAs in Ambridge and Blything (2015), to test themodel preferences for the DO or PD, the models arepresented with an input consisting of a verb lexeme,its semantic features, and the transfer feature set to 1(i.e., this is a ?transfer?
semantics suitable for a da-tive construction).
For the AB model, we measurepreferences for each construction as the activationrate of each of the corresponding output nodes, as inAmbridge and Blything (2015).
In the BFS model,the preference for each construction is measured asits likelihood over the learned clusters given the verband its semantic features.
Formally, the prediction inthe Bayesian model is:P (s|Ftest) =?k?ClustersP (s|k)P (k|Ftest) (4)where s is the predicted syntactic construction (DOor PD) and Ftest is the set of test features represent-ing a verb v and its corresponding semantic features.P (s|k) is the probability of the syntactic pattern fea-ture having the value s in cluster k, calculated as theproportional occurrences of s in k. P (k|Ftest) is theprobability of cluster k given test features Ftest, cal-culated as in Eqn.
(2).
Following Barak et al (2014),we calculate P (k|Ftest) in two ways, using just theconstructions (level one) or both the classes (leveltwo) and the constructions, to see whether verb classknowledge improves performance.
Using solely theconstruction level, the probability of k reflects thefrequency with which usages of verb v occur in clus-ter k. Using the verb class level in addition, the dis-tribution of the verb over classes in the second levelis combined with the distribution of those classesover the constructions in level one, to get the like-lihood of k.These model preferences of the verbs for a da-tive construction are compared, using Pearson cor-relation, to the DO/PD acceptability judgment datacollected from adult participants by Ambridge et al(2014).
Note that Ambridge and Blything (2015)only evaluate their model?s preferences for verbs totake the DO construction.
To fully understand thepreference and generalization patterns, we also an-alyze the results for the PD preference.
Even moreimportantly, we calculate the difference between thepreferences for the DO and the PD constructions perverb, and compare these to analogous scores for thehuman data, as suggested by Ambridge et al (2014).The DO?PD difference scores, which we will referto as the verb bias score, are crucial because, as inthe human data, it is these scores that accurately cap-ture a learner?s relative preference for a constructiongiven a particular verb.5 Experiments and Analysis of ResultsWe examine the ability of each model to matchthe dative construction preferences of human judg-ments, as described just above, under two differentexperimental scenarios.
In Section 5.1, we followthe experimental settings of Ambridge and Blything(2015).
We replicate their results on the AB modelshowing correlation with human DO preferences,but find that only the BFS model achieves a signifi-cant correlation with the crucial verb bias score thatappropriately assesses per-verb preference.
We ad-just the experimental settings in Section 5.2 to usemore naturalistic input data ?
by training in propor-tion to raw frequencies and excluding the artificialother construction ?
achieving an improvement inthe verb bias score for both models.5.1 Exp 1: Log Freq Input; 3 ConstructionsResults.
We first evaluated the models under theexperimental conditions of Ambridge and Blything(2015), providing input corresponding to the verbsin 3 constructions (DO, PD, and other), in propor-tion to their log frequencies; see Table 2.
We repli-cate the positive correlation of the AB model over101AB (Connectionist) BFS (Bayesian)Level 1 Level 2DO 0.54 0.24 0.29PD 0.39 0.30 0.50DO-PD [-0.02] 0.48 0.53Table 2: Pearson correlation values between human andmodel preferences for each construction and the verb-bias score (DO?PD); training on log frequencies and 3constructions.
All correlations significant with p-value< 0.001, except the one value in square brackets.
Bestresult for each row is marked in boldface.the ratings for the DO construction found in Am-bridge and Blything (2015).
In addition, our analy-sis shows that the AB model produces a significantpositive correlation with the PD acceptability rating.However, the AB model has no correlation with theverb bias score.
Although the model ranks the sep-arate verb preferences for DO and PD similarly tohumans, the model does not produce the same rel-ative preference for individual verbs.
For exam-ple, the human data rank give with high acceptabil-ity in both the DO and the PD, with a higher valuefor the DO construction.
Although the AB modelhas a high preference for both constructions for give(compared with other verbs), the model erroneouslyprefers give in the PD construction.The BFS model also produces preferences forverbs in each construction that have a significantpositive correlation with human judgments.
Whilethe AB model shows better correlation with the DOjudgments, the BFS model correlates more stronglywith the PD judgments.
Importantly, in contrast tothe AB model, the verb bias score of the BFS modelalso significantly correlates with the judgment data.That is, the BFS model provides a better predictionof the preference per verb, which is key to producinga verb in the appropriate syntax.Analysis.
We can explain these results by look-ing more closely at the properties of the input andthe differences in the learning mechanisms of eachmodel.
Following Ambridge and Blything (2015),the input presents an artificial other construction inproportion to the frequency of the verbs with all non-dative constructions.
The very high frequency of thissingle artificial construction (see other in Table 1)results in higher predictions of it for any of the verbs,even though the ?transfer?
feature in test inputs hasa value intended to signal one of the dative construc-tions.
As a result, the preferences for the dative con-structions in both models have a very small range ofvalues, showing relatively small differences.The BFS model is also affected by the relativelycompressed semantic space of the input, which isexacerbated by the use of log frequencies to guidethe input.
As noted earlier, we found that the se-mantic features of alternating verbs can be highlysimilar to non-alternating verbs ?
e.g., give (alternat-ing) and pull (PO-only) have similar semantic vec-tors.
With such input, the model cannot form suf-ficiently distinct first-level clusters based on the se-mantics, particularly when the data is presented withsuch a flat distribution (note the small differences inlog frequencies in Table 1).
Visual inspection re-veals that these clusters in the model largely formaround syntactic constructions, with mixed seman-tic properties.
Despite this, the first-level clusterscapture a strong enough association between indi-vidual verbs and their constructions to yield a goodcorrelation of the verb bias score with human judg-ments, and drawing on the second-level (verb-class)clusters improves the results.Conclusions.
The use of an artificial high-frequency non-dative construction (other), and theuse of log frequencies, seem to mask the influ-ence of the semantic and syntactic properties onlearning the verb-bias for each verb.
Previous psy-cholinguistic data and computational models havefound that a skewed naturalistic distribution of theinput is helpful in learning constructions, due tothe high-frequency verbs establishing appropriateconstruction-meaning associations (Casenhiser andGoldberg, 2005; Borovsky and Elman, 2006; Baraket al, 2013b; Matusevych et al, 2014).
To allowa more direct analysis of the role of statistical andsemantic properties in learning and generalizing thedative, we adjust the input to the models in the nextsection.5.2 Exp 2: Raw Freq Input; 2 ConstructionsResults.
Here we perform the same type of experi-ments, but using input in proportion to the raw fre-quencies of the verbs (instead of log frequencies)over occurrences only in the two dative construc-tions (with no other construction).
Since 98 of the281 verbs do not occur with either dative construc-102AB (Connectionist) BFS (Bayesian)Level 1 Level 2DO [0.06] 0.23 0.25PD 0.33 0.38 0.32DO-PD 0.39 0.53 0.59Table 3: Pearson correlation values between human andmodel preferences for each construction and the verb-biasscore; training on raw frequencies and 2 constructions.All correlations significant with p-value < 0.001, exceptthe one value in square brackets.
Best result for each rowis marked in boldface.tion in the BNC, this also allows us to more strin-gently test the generalization ability of the models,by considering their behavior when ?1/3 of the verbsare unseen in training.Table 3 presents the correlation results for thetwo models?
preferences for each construction andthe verb bias score; we also show the correlationplots for the verb bias score in Figure 3.
The ABmodel does not correlate with the judgments for theDO.
However, the model produces significant posi-tive correlations with the PD judgments and with theverb bias score.
The BFS model, on the other hand,achieves significant positive correlations on all mea-sures, by both levels.
As in the earlier experiments,the best correlation with the verb bias score is pro-duced by the second level of the BFS model, as Fig-ure 3 demonstrates.Analysis.
As shown by Barak et al (2013b),the Bayesian model is better at learning the distri-bution pattern of each verb class given a skeweddistribution, as in the raw frequencies here.
Themodel learns an association of each construction tothe frequently-observed meaning of high-frequencyverbs.
For example, the semantics of the DO is moststrongly influenced by the semantics of its most fre-quently occurring instance: give.
The accuracy ofpreference judgments benefits from the entrench-ment of the relevant meaning with the construction.This supports appropriate generalization ?
e.g., be-cause reward is semantically similar to give, it hasa good fit to the human preference judgments eventhough it is unseen with the dative (see Figure 3).But the same factor can serve to limit generaliza-tion ?
e.g., because the unseen verb mail is semanticdissimilar to a frequent PD-only verb like pull, itspreference for the PD syntax is limited, giving it a(a) AB model(b) BFS model - construction level(c) BFS model - verb class levelFigure 3: Correlation of the dative verbs with the verbbias score of each model in Exp.
2: (a) the AB model (r =0.39), (b) the first level of the BFS model (r = 0.53), and(c) the second level of the BFS model (r = 0.59).good match to human judgments by preventing itsovergeneralization (see Figure 3).The AB model can also take advantage of highfrequency verbs biasing the preference toward thefrequently observed association.
However, the se-mantic similarity across verbs within alternating ornon-alternating classes is less effective in this model.The representation of the lexemes as 281 nodesin the input (compared to less than a dozen othernodes) make the learning more verb specific, reduc-ing the ability of the model to generalize to the unat-tested verbs.Conclusions.
The success of the BFS model,and especially the results using both constructionsand classes, point to the role of probabilistic con-structions and verb classes in generalizing exist-103ing knowledge while avoiding overgeneralizations.Moreover, the use of a skewed distribution revealsthe role of the high verb-in-construction frequencyin guiding the association of construction and mean-ing (see Ambridge et al, 2014, for discussion).
Yetboth models would benefit from a richer seman-tic representation that better captures the distinctiveproperties of verbs across various constructions.6 DiscussionThis paper presents a comparative analysis of twocomputational cognitive models on the sample taskof learning the dative alternation.
This study en-ables an evaluation of the psycholinguistic plausi-bility of each model for the given task when facingidentical input and experimental settings.
Adoptingthe semantic representation of Ambridge and Bly-thing (2015), our input incorporates both seman-tic and syntactic properties over a large number ofverbs.
By providing the first direct comparison be-tween two existing models of this phenomenon, weare the first to demonstrate the complex interac-tion of various linguistic properties in the input, andhow rich learning mechanisms are required in or-der to achieve generalizations compatible with hu-man judgments in this area.
Moreover, comparisonof learning mechanisms and of input properties caninform CL/NLP more generally by shedding light onpotential factors in achieving humanlike behaviours.We find that the Bayesian model of BFS signifi-cantly correlates with human judgments on the 3 keyevaluation measures.
Importantly, this model out-performs the connectionist model of AB in the cor-relation with the verb-bias score (the per-verb differ-ence between DO and PD preference), which pointsto its advantage in choosing the more appropriateconstruction per verb.
We argue that the fit of themodel relies on a rich learning mechanism that ex-ploits distributional properties of naturalistic input.The AB model has a streamlined design to sup-port learning a particular semantic-syntactic associ-ation underlying the dative alternation.
While theBFS model is richer computationally, its propertieswere motivated in earlier work explaining many hu-man behaviours.
When we consider more natural in-put, the simple input[semantics]?output[syntax] as-sociation mechanism of the AB model is unable tocapture the necessary interactions among the verbsemantic properties, the syntactic usages, and theirpatterns across different types of verbs.
By con-trast, the two-level design of the BFS model capturesthese interactions.
The first level learns the verb-semantics-syntax associations as clusters of similarconfigurations of those features.
The second levelcaptures the commonalities of behaviour of sets ofverbs by forming classes of verbs that have simi-lar distributional patterns over the first-level clus-ters.
We also observe that the replication of adult-like language competence relies on several naturalis-tic properties of the input: skewed distribution, and arich semantic representation combined with syntac-tic information.
The skewed input enables the for-mation of clusters representing more entrenched as-sociations, which are biased towards high-frequencyverbs associated with certain semantic and syntacticfeatures.Given the role of these linguistic properties, theresults here call for additional analysis and develop-ment of the input to computational cognitive models.The predictions may be improved given more real-istic syntactic and semantic information about theverb usages.
On the syntax side, the input shouldreflect the distribution of verbs across more syntac-tic constructions, as statistical patterns over such us-ages can indirectly indicate aspects of a verb?s se-mantics (cf.
Barak et al, 2013a).
In the future,we aim to analyze the role of fuller syntactic dis-tributions in restricting overgeneralization patterns.Moreover, the semantic annotations used here repli-cate the settings originally tested for the AB model,which correspond to the verb as used in the rele-vant constructions.
This contrasts with typical au-tomated extractions of verb-meaning representation(e.g., word2vec, Mikolov et al, 2013), which cap-ture a more general verb meaning across all its us-ages.
In preliminary experiments, we have found anadvantage in using word2vec representations in ad-dition to the semantic properties reported here.
Weaim to further analyze manual and automated meth-ods for semantic feature extraction in future work.AcknowledgmentsWe are grateful to Ben Ambridge for helpful discus-sion of his model and for sharing his data with us.104ReferencesNameera Akhtar.
1999.
Acquiring basic word order:Evidence for data-driven learning of syntacticstructure.
Journal of child language, 26(02):339?356.Afra Alishahi and Pirita Pyykkon?en.
2011.
The on-set of syntactic bootstrapping in word learning:Evidence from a computational study.
In Pro-ceedings of the 33st Annual Conference of theCognitive Science Society.Afra Alishahi and Suzanne Stevenson.
2008.
A com-putational model of early argument structure ac-quisition.
Cognitive Science, 32(5):789?834.Ben Ambridge and Ryan P Blything.
2015.
Aconnectionist model of the retreat from verb ar-gument structure overgeneralization.
Journal ofchild language, pages 1?32.Ben Ambridge, Julian M Pine, Caroline F Rowland,and Franklin Chang.
2012.
The roles of verb se-mantics, entrenchment, and morphophonology inthe retreat from dative argument-structure over-generalization errors.
Language, 88(1):45?81.Ben Ambridge, Julian M Pine, Caroline F Row-land, Daniel Freudenthal, and Franklin Chang.2014.
Avoiding dative overgeneralisation errors:Semantics, statistics or both?
Language, Cogni-tion and Neuroscience, 29(2):218?243.Ben Ambridge, Julian M Pine, Caroline F Row-land, and Chris R Young.
2008.
The effect ofverb semantic class and verb frequency (entrench-ment) on childrens and adults graded judgementsof argument-structure overgeneralization errors.Cognition, 106(1):87?129.Libby Barak, Afsaneh Fazly, and Suzanne Steven-son.
2012.
Modeling the acquisition of mentalstate verbs.
In Proceedings of the 3rd Workshopon Cognitive Modeling and Computational Lin-guistics (CMCL 2012).Libby Barak, Afsaneh Fazly, and Suzanne Steven-son.
2013a.
Acquisition of desires before beliefs:A computational investigation.
In Proceedings ofCoNLL-2013.Libby Barak, Afsaneh Fazly, and Suzanne Steven-son.
2013b.
Modeling the emergence of an exem-plar verb in construction learning.
In Proceedingsof the 35rd Annual Meeting of the Cognitive Sci-ence Society.Libby Barak, Afsaneh Fazly, and Suzanne Steven-son.
2014.
Learning verb classes in an incremen-tal model.
In Proceedings of the 5th Workshopon Cognitive Modeling and Computational Lin-guistics (CMCL 2014).
Association for Computa-tional Linguistics.Arielle Borovsky and Jeff Elman.
2006.
Languageinput and semantic categories: A relation betweencognition and early word learning.
Journal ofchild language, 33(04):759?790.Jeremy K Boyd and Adele E Goldberg.
2009.
Inputeffects within a constructionist framework.
TheModern Language Journal, 93(3):418?429.Martin DS Braine and Patricia J Brooks.
1995.
Verbargument structure and the problem of avoid-ing an overgeneral grammar.
Beyond names forthings: Young children?s acquisition of verbs,pages 353?376.Joan Bresnan and Marilyn Ford.
2010.
Predictingsyntax: Processing dative constructions in ameri-can and australian varieties of english.
Language,86(1):168?213.Joan Bybee.
2010.
Language, usage and cognition.Cambridge University Press.David Casenhiser and Adele E. Goldberg.
2005.
Fastmapping between a phrasal form and meaning.Developmental Science, 8(6):500?508.Cynthia Fisher.
1999.
From form to meaning: Arole for structural alignment in the acquisition oflanguage.
Advances in child development and be-havior, 27:1?53.Marilyn Ford, Joan W Bresnan, and Ronald Kaplan.1982.
A competence-based theory of syntacticclosure.
American Journal of Computational Lin-guistics, 8(1):49.Susanne Gahl and Susan M Garnsey.
2004.
Knowl-edge of grammar, knowledge of usage: Syntacticprobabilities affect pronunciation variation.
Lan-guage, pages 748?775.Susan M Garnsey, Neal J Pearlmutter, Elizabeth My-ers, and Melanie A Lotocky.
1997.
The contri-butions of verb bias and plausibility to the com-105prehension of temporarily ambiguous sentences.Journal of Memory and Language, 37(1):58?93.Adele E. Goldberg.
1995.
Constructions, A Con-struction Grammar Approach to Argument Struc-ture.
{Chicago University Press}.Adele E Goldberg.
2006.
Constructions at work:The nature of generalization in language.
OxfordUniversity Press on Demand.Adele E Goldberg.
2011.
Corpus evidence of theviability of statistical preemption.
Cognitive Lin-guistics, 22(1):131?153.Geoffrey Leech.
1992.
100 million words of english:the british national corpus (BNC).
Language Re-search, 28(1):1?13.Beth Levin.
1993.
English verb classes and alterna-tions: A preliminary investigation, volume 348.University of Chicago press Chicago, IL.Elena VM Lieven, Julian M Pine, and Gillian Bald-win.
1997.
Lexically-based learning and earlygrammatical development.
Journal of child lan-guage, 24(01):187?219.Beth L Losiewicz.
1992.
The effect of frequency onlinguistic morphology.
University of Texas.Maryellen C MacDonald, Neal J Pearlmutter, andMark S Seidenberg.
1994.
The lexical nature ofsyntactic ambiguity resolution.
Psychological re-view, 101(4):676.Yevgen Matusevych, Afra Alishahi, and Ad Backus.2014.
Isolating second language learning factorsin a computational study of bilingual construc-tion acquisition.
In Proceedings of the 36th An-nual Conference of the Cognitive Science Society,pages 988?994.Yevgen Matusevych, Afra Alishahi, and Ad Backus.2016.
The impact of first and second languageexposure on learning second language construc-tions.
Bilingualism: Language and Cognition,pages 1?22.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg SCorrado, and Jeff Dean.
2013.
Distributed repre-sentations of words and phrases and their com-positionality.
In C. J. C. Burges, L. Bottou,M.
Welling, Z. Ghahramani, and K. Q. Wein-berger, editors, Advances in Neural InformationProcessing Systems 26, pages 3111?3119.
CurranAssociates, Inc.Christopher Parisien and Suzanne Stevenson.
2010.Learning verb alternations in a usage-basedbayesian model.
In Proceedings of the 32nd an-nual meeting of the Cognitive Science Society.Amy Perfors, Joshua B. Tenenbaum, and ElizabethWonnacott.
2010.
Variability, negative evidence,and the acquisition of verb argument construc-tions.
Journal of Child Language, 37(03):607?642.Steven Pinker.
1989.
Learnability and cognition:The acquisition of argument structure.
The MITPress.Nicolas Ruh and Gert Westermann.
2009.
Oxlearn:A new matlab-based simulation tool for con-nectionist models.
Behavior research methods,41(4):1138?1143.Anna L Theakston.
2004.
The role of entrenchmentin childrens and adults performance on grammat-icality judgment tasks.
Cognitive Development,19(1):15?34.Michael Tomasello.
2003.
Constructing a language:A usage-based theory of language acquisition.Harvard University Press.John C Trueswell, Michael K Tanenhaus, andChristopher Kello.
1993.
Verb-specific con-straints in sentence processing: separating effectsof lexical preference from garden-paths.
Journalof Experimental Psychology: Learning, Memory,and Cognition, 19(3):528.Thomas Wasow.
2002.
Postverbal behavior.
Stan-ford Univ Center for the Study.106
