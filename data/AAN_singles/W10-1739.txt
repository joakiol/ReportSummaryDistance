Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 271?275,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsMANY : Open Source MT System Combination at WMT?10Lo?
?c BarraultLIUM, University of Le MansLe Mans, France.FirstName.LastName@lium.univ-lemans.frAbstractLIUM participated in the System Combi-nation task of the Fifth Workshop on Sta-tistical Machine Translation (WMT 2010).Hypotheses from 5 French/English MTsystems were combined with MANY, anopen source system combination softwarebased on confusion networks currently de-veloped at LIUM.The system combination yielded signifi-cant improvements in BLEU score whenapplied on WMT?09 data.
The same be-havior has been observed when tuning isperformed on development data of thisyear evaluation.1 IntroductionThis year, the LIUM computer science labora-tory has participated in the French-English sys-tem combination task at WMT?10 evaluation cam-paign.
The system used for this task is MANY1(Barrault, 2010), an open source system combina-tion software based on Confusion Networks (CN).Several improvements have been made in order tobeing able to combine many systems outputs in adecent time.The focus has been put on the tuning step, andmore precisely how to perform system parametertuning.
Two methods have been experimented cor-responding to two different representations of sys-tem combination.
In the first one, system combi-nation is considered as a whole : fed by systemhypotheses as input and generating a new hypoth-esis as output.
The second method considers thatthe alignment module is independent from the de-coder, so that the parameters from each modulecan be tuned separately.1MANY is available at the following address http://www-lium.univ-lemans.fr/?barrault/MANYThose tuning approaches are described in sec-tion 3.
Before that, a quick description of MANY,including recent developments, can be found insection 2.
Results on WMT?09 data are pre-sented in section 4 along results of tuning onnewssyscombtune2010.2 System descriptionMANY is a system combination software (Bar-rault, 2010) based on the decoding of a latticemade of several Confusion Networks (CN).
This isa widespread approach in MT system combination(Rosti et al, 2007); (Shen et al, 2008); (Karakoset al, 2008).
MANY can be decomposed in twomain modules.
The first one is the alignment mod-ule which actually is a modified version of TERp(Snover et al, 2009).
Its role is to incrementallyalign the hypotheses against a backbone in order tocreate a confusion network.
Those confusion net-works are then connected together to create a lat-tice.
This module uses different costs (which cor-responds to a match, an insertion, a deletion, a sub-stitution, a shift, a synonym and a stem) to com-pute the best alignment and incrementally builda confusion network.
In the case of confusionnetwork, the match (substitution, synonyms, andstems) costs are considered when the word in thehypothesis matches (is a substitution, a synonymsor a stems of) at least one word of the consideredconfusion sets in the CN, as shown in Figure 1.The second module is the decoder.
This decoderis based on the token pass algorithm and it acceptsas input the lattice previously created.
The proba-bilities computed in the decoder can be expressedas follow :log(PW ) =Len(W )?n=0{?1logPws(n) + ?2logPlm(n)+?3Lpen(n) + ?4Npen(n)}(1)where Len(W ) is the length of the hypothesis,271Isthe dinnerincluded ?Do you dinnercalculated ?haveIs the dinner included ?isSupper ?includedParaphrase{MatchIs the dinner included?NULLsupperMatchMatchMatchSubSubInsSubDo youNULLsuppercalculatedhaveNULLMatchFigure 1: Incremental alignment with TERp re-sulting in a confusion network.Pws(n) is the score of the nth word in the lattice,Plm(n) is its LM probability, Lpen(n) is the lengthpenalty (which apply when Wn is not a null-arc),Npen(n) is the penalty applied when crossing anull-arc, and the ?i are the features weights.MultithreadingOne major issue with system combination con-cerns scaling.
Indeed, in order to not lose infor-mation about word order, all system hypothesesare considered as backbone and all other hypothe-ses are aligned to it to create a CN.
Consequently,if we consider N system outputs, then to build Nconfusion networks, N ?
(N ?
1) alignments withmodified TERp have to be performed.
Moreover,in order to get better results, the TERp costs haveto be optimized, which requires a lot of iterations,all of which calculate N ?
(N ?
1) alignments.However, the building of a CN with system i asbackbone does not depend on the building of CNwith other system as backbone.
Therefore multi-threading has been integrated into MANY so thatmultiple CNs can be created in parallel.
From nowon, the number of thread can be specified in theconfiguration file.3 TuningAs mentioned before, MANY is made of two mainmodules : the alignment module based on a modi-fied version of TERp and the decoder.
Considering10 systems, 19 parameters in total have to be op-timized in order to get better results.
By default,TERp costs are set to 0.0 for match and 1.0 foreverything else.
These costs are not correct, sincea shift in that case will hardly be possible.
TERpcosts, system priors, fudge factor, null-arc penalty,length penalty are tuned with Condor (a global op-timizer based on the Powell?s algorithm, (Berghenand Bersini, 2005)).Two ways of tuning have been experimented.The first one consists in optimizing the whole setof parameters together (see section 3.1).
The sec-ond one rely on the (maybe likely) independenceof the TERp parameters towards those of the de-coder and consists in tuning TERp parameters ina first step and then using the optimized TERpcosts when tuning the decoder parameters (seesection 3.2).3.1 Tuning all parameters togetherCondor is an optimizer which aims at minimizinga certain objective function.
In our case, the ob-jective function is the whole system combination.As input, it takes the whole set of parameters (i.e.TERp costs except match costs (which is alwaysset to 0), system priors, the fudge factor, and null-arc and length penalty) and outputs -BLEU score.The BLEU score is one of the most robust met-rics as presented in (Leusch et al, 2009), which isconsequently an obvious target for optimization.Such a tuning protocol has the disadvantageto be slower as all the confusion networks haveto be regenerated at each step because the TERpcosts provided by the optimizer will hardly be thesame for two iterations (thus, confusion networkscomputed during previous iterations can hardly bereused).
Another issue with this approach is that itis hard to converge when the parameter set is thatlarge.
This is mainly due to the fact that we can-not guarantee the convexity of the problem.
How-ever, one advantage is that the possible correlationbetween all parameters are taken into account dur-ing the optimization process, which is not the casewhen optimizing in several steps.3.2 Two-step tuningTuning TERp parameters : In order to opti-mize TERp parameters (i.e.
del, ins, sub, shift,stem and syn costs), we have to determine whichmeasure to use to evaluate a certain configuration.We naturally considered the minimization of theTERp score.
To do so, the confusion networks arebuilt using the set of parameters given by the op-timizer.
TERp scores are then calculated betweenthe reference and each CN, and summed up.The goal of this step is to guide the confusionnetworks generation process to produce sentences272similar to the reference.
Consequently, if the con-fusion networks generated at this step have a lowerTERp score, then this means that the decoder ismore likely to find a better hypothesis inside.Tuning decoder parameters : Based on theTERp configuration determined at the previousstep, this step aims at finding good parameter val-ues.
Those parameters control the final hypothe-sis size and the importance given to the languagemodel probabilities compared to the translationscores (occurring on words).
The metric which isminimized is -BLEU for the same reasons men-tioned in section 3.1.4 Experiments and ResultsDuring experiments, data from last year evaluationcampaign are used for testing the tuning approach.news-dev2009a is used as development set, andnews-dev2009b as internal test, these corpora aredescribed in Table 1.NAME #sent.
#words #toknews-dev2009a 1025 21583 24595news-dev2009b 1026 21837 24940Table 1: WMT?09 corpora : number of sentences,words and tokens calculated on the reference.For the sake of speed and simplicity, the fivebest systems (ranking given by score on dev) areconsidered only.
Baseline systems performanceson dev and test are presented in Table 2.Corpus Sys0 Sys1 Sys2 Sys3 Sys4Dev 18.20 17.83 20.14 21.06 17.72Test 18.53 18.33 20.43 21.35 18.15Table 2: Baseline systems performance onWMT?09 data (%BLEU).When tuning all parameters together, the set ob-tained is presented in Table 3.
The 2-step tuningCosts : Del Stem Syn Ins Sub Shift0.89 0.94 1.04 0.98 0.94 0.94Dec.
: Fudge Nullpen Lenpen0.01 0.25 1.46Weights : Sys0 Sys1 Sys2 Sys3 Sys40.04 0.04 0.16 0.26 0.04Table 3: Parameters obtained with 1-step tuning.protocol applied on news-dev2009a provides theset of parameters presented in Table 4.Costs : Del Stem Syn Ins Sub Shift9e-6 0.89 1.22 0.26 0.44 1.76Dec.
: Fudge Nullpen Lenpen0.1 0.27 2.1Weights : Sys0 Sys1 Sys2 Sys3 Sys40.07 0.09 0.09 0.09 0.11Table 4: Parameters obtained with 2-step tuning.Results on development corpus of WMT?09(used as test set) are presented in Table 5.
WeSystem Dev TestBest single 21.06 21.35MANY 22.08 22.28MANY-2steps 21.94 22.09Table 5: System Combination results on WMT?09data.can observe that 2-step tuning provides almost 0.9BLEU point improvement on development corpuswhich is well reflected on test set with a gain ofmore than 0.7 BLEU.
The best results are obtainwhen tuning all parameters together, which givemore than 1 BLEU point improvement on dev andmore than 0.9 on test.4.1 DiscussionChoosing a measure to optimize the TERp costs isnot something easy.
One important remark is thatdefault (equal) costs are not suitable to get goodconfusion networks.
The goal of the confusionnetworks is to make possible the generation of anew hypothesis which can be different from thoseprovided by each individual system.In these experiments, TERp calculated betweenthe CNs and the reference is used as the distanceto be minimized by the optimizer.
We can no-tice that for the 2-step optimization, the deletioncost is very small.
This is probably not a valuewhich is expected, because in this case, this meansthat deletions can occur in an hypothesis withoutpenalizing it a lot.
However, this parameter sethas a beneficial impact on the system combinationperformance.
Another comment is that the sys-tem weights are not directly proportional to the re-sults.
This suggests that some phrases proposedby weaker systems can have a higher importancefor system combination.By contrast, optimizing parameters all togetherprovides more fair weights, according to the re-273sults of the single systems.4.2 2010 evaluation campaignFor this year system combination tasks, a de-velopment corpus (syscombtune) and the test(syscombtest), described in Table 6, were pro-vided to participants.NAME #sentences #words #words toksyscombtune 455 9348 10755syscombtest 2034 - -Table 6: Description of WMT?10 corpora.Language model : The English target languagemodels has been trained on all monolingual dataprovided for the translation tasks.
In addition,LDC?s Gigaword collection was used for both lan-guages.
Data corresponding to the developmentand test periods were removed from the Gigawordcollections.Tuning on syscombdev2010 corpus producedthe parameter set presented in Table 7Costs : Del Stem Syn Ins Sub ShiftDec.
: Fudge Nullpen Lenpen0.01 0.33 1.6Weights : Sys0 Sys1 Sys2 Sys3 Sys40.11 0.21 0.04 0.15 0.15Table 7: Parameters obtained with tuning.The result provided by the system with this con-figuration can be compared to the single systemsin Table 8.System newssyscombtune2010Sys0 27.74Sys1 27.26Sys2 27.15Sys3 27.06Sys4 27.04MANY 28.63Table 8: Baseline systems performance onWMT?10 development data (%BLEU).A behavior comparable to WMT?09 evaluationcampaign is observed, which suggests that the ap-proach is correct.5 Conclusion and future workWe have shown that tuning all parameters togetheris better than 2-step tuning.
However, the secondmethod has not been fully explored.
Tuning TERpparameters targeting minimum TERp score is notsatisfying.
Therefore, an alternative measure, likengram agreement which would be more related toBLEU, can be considered in order to obtain betterparameters.Further improvement for MANY will be con-sidered like case insensitive combination then re-casing the output using majority vote on the con-fusion networks.
This is currently a work inprogress.6 AcknowledgementThis work has been partially funded by the Eu-ropean Union under the EuroMatrix Plus project(http://www.euromatrixplus.net, IST-2007.2.2-FP7-231720)ReferencesBarrault, L. (2010).
MANY : Open source ma-chine translation system combination.
PragueBulletin of Mathematical Linguistics, SpecialIssue on Open Source Tools for Machine Trans-lation, 93:147?155.Berghen, F. V. and Bersini, H. (2005).
CON-DOR, a new parallel, constrained extension ofPowell?s UOBYQA algorithm: Experimentalresults and comparison with the DFO algo-rithm.
Journal of Computational and AppliedMathematics, 181:157?175.Karakos, D., Eisner, J., Khudanpur, S., andDreyer, M. (2008).
Machine translation sys-tem combination using ITG-based alignments.In 46th Annual Meeting of the Association forComputational Linguistics: Human LanguageTechnologies., pages 81?84, Columbus, Ohio,USA.Leusch, G., Matusov, E., and Ney, H. (2009).The RWTH system combination system forWMT 2009.
In Proceedings of the FourthWorkshop on Statistical Machine Translation,pages 61?65, Athens, Greece.Rosti, A.-V., Matsoukas, S., and Schwartz, R.(2007).
Improved word-level system combina-tion for machine translation.
In Association forComputational Linguistics, pages 312?319.274Shen, W., Delaney, B., Anderson, T., and Slyh,R.
(2008).
The MIT-LL/AFRL IWSLT-2008MT System.
In International Workshop on Spo-ken Language Translation, Hawaii, U.S.A.Snover, M., Madnani, N., Dorr, B., andSchwartz, R. (2009).
TER-Plus: Para-phrase, semantic, and alignment enhancementsto translation edit rate.
Machine TranslationJournal.275
