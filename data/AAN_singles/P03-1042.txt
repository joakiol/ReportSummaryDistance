Uncertainty Reduction in Collaborative Bootstrapping:Measure and AlgorithmYunbo CaoMicrosoft Research Asia5F Sigma Center,No.49 Zhichun Road, HaidianBeijing, China, 100080i-yucao@microsoft.comHang LiMicrosoft Research Asia5F Sigma Center,No.49 Zhichun Road, HaidianBeijing, China, 100080hangli@microsoft.comLi LianComputer Science DepartmentFudan UniversityNo.
220 Handan RoadShanghai, China, 200433leelix@yahoo.comAbstractThis paper proposes the use of uncertaintyreduction in machine learning methodssuch as co-training and bilingual boot-strapping, which are referred to, in a gen-eral term, as ?collaborative bootstrapping?.The paper indicates that uncertainty re-duction is an important factor for enhanc-ing the performance of collaborativebootstrapping.
It proposes a new measurefor representing the degree of uncertaintycorrelation of the two classifiers in col-laborative bootstrapping and uses themeasure in analysis of collaborative boot-strapping.
Furthermore, it proposes a newalgorithm of collaborative bootstrappingon the basis of uncertainty reduction.
Ex-perimental results have verified the cor-rectness of the analysis and havedemonstrated the significance of the newalgorithm.1 IntroductionWe consider here the problem of collaborativebootstrapping.
It includes co-training (Blum andMitchell, 1998; Collins and Singer, 1998; Nigamand Ghani, 2000) and bilingual bootstrapping (Liand Li, 2002).Collaborative bootstrapping begins with a smallnumber of labelled data and a large number ofunlabelled data.
It trains two (types of) classifiersfrom the labelled data, uses the two classifiers tolabel some unlabelled data, trains again two newclassifiers from all the labelled data, and repeatsthe above process.
During the process, the twoclassifiers help each other by exchanging the la-belled data.
In co-training, the two classifiers havedifferent feature structures, and in bilingual boot-strapping, the two classifiers have different classstructures.Dasgupta et al(2001) and Abney (2002) con-ducted theoretical analyses on the performance(generalization error) of co-training.
Their analyses,however, cannot be directly used in studies of co-training in (Nigam & Ghani, 2000) and bilingualbootstrapping.In this paper, we propose the use of uncertaintyreduction in the study of collaborative bootstrap-ping (both co-training and bilingual bootstrapping).We point out that uncertainty reduction is an im-portant factor for enhancing the performances ofthe classifiers in collaborative bootstrapping.
Here,the uncertainty of a classifier is defined as the por-tion of instances on which it cannot make classifi-cation decisions.
Exchanging labelled data inbootstrapping can help reduce the uncertainties ofclassifiers.Uncertainty reduction was previously used inactive learning.
We think that it is this paper whichfor the first time uses it for bootstrapping.We propose a new measure for representing theuncertainty correlation between the two classifiersin collaborative bootstrapping and refer to it as?uncertainty correlation coefficient?
(UCC).
Weuse UCC for analysis of collaborative bootstrap-ping.
We also propose a new algorithm to improvethe performance of existing collaborative boot-strapping algorithms.
In the algorithm, one classi-fier always asks the other classifier to label themost uncertain instances for it.Experimental results indicate that our theoreti-cal analysis is correct.
Experimental results alsoindicate that our new algorithm outperforms exist-ing algorithms.2 Related Work2.1 Co-Training and Bilingual BootstrappingCo-training, proposed by Blum and Mitchell(1998), conducts two bootstrapping processes inparallel, and makes them collaborate with eachother.
More specifically, it repeatedly trains twoclassifiers from the labelled data, labels someunlabelled data with the two classifiers, and ex-changes the newly labelled data between the twoclassifiers.
Blum and Mitchell assume that the twoclassifiers are based on two subsets of the entirefeature set and the two subsets are conditionallyindependent with one another given a class.
Thisassumption is called ?view independence?.
In theiralgorithm of co-training, one classifier always asksthe other classifier to label the most certain in-stances for the collaborator.
The word sense dis-ambiguation method proposed in Yarowsky (1995)can also be viewed as a kind of co-training.Since the assumption of view independencecannot always be met in practice, Collins andSinger (1998) proposed a co-training algorithmbased on ?agreement?
between the classifiers.As for theoretical analysis, Dasgupta et al(2001) gave a bound on the generalization error ofco-training within the framework of PAC learning.The generalization error is a function of ?dis-agreement?
between the two classifiers.
Dasguptaet als result is based on the view independenceassumption, which is strict in practice.Abney (2002) refined Dasgupta et als result byrelaxing the view independence assumption with anew constraint.
He also proposed a new co-trainingalgorithm on the basis of the constraint.Nigam and Ghani (2000) empirically demon-strated that bootstrapping with a random featuresplit (i.e.
co-training), even violating the view in-dependence assumption, can still work better thanbootstrapping without a feature split (i.e., boot-strapping with a single classifier).For other work on co-training, see (Muslea et al200; Pierce and Cardie 2001).Li and Li (2002) proposed an algorithm forword sense disambiguation in translation betweentwo languages, which they called ?bilingual boot-strapping?.
Instead of making an assumption on thefeatures, bilingual bootstrapping makes an assump-tion on the classes.
Specifically, it assumes that theclasses of the classifiers in bootstrapping do notoverlap.
Thus, bilingual bootstrapping is differentfrom co-training.Because the notion of agreement is not involvedin bootstrapping in (Nigam & Ghani 2000) andbilingual bootstrapping, Dasgupta et alandAbney?s analyses cannot be directly used on them.2.2 Active LearningActive leaning is a learning paradigm.
Instead ofpassively using all the given labelled instances fortraining as in supervised learning, active learningrepeatedly asks a supervisor to label what it con-siders as the most critical instances and performstraining with the labelled instances.
Thus, activelearning can eventually create a reliable classifierwith fewer labelled instances than supervisedlearning.
One of the strategies to select critical in-stances is called ?uncertain reduction?
(e.g., Lewisand Gale, 1994).
Under the strategy, the most un-certain instances to the current classifier are se-lected and asked to be labelled by a supervisor.The notion of uncertainty reduction was notused for bootstrapping, to the best of our knowl-edge.3 Collaborative Bootstrapping and Un-certainty ReductionWe consider the collaborative bootstrapping prob-lem.Let  denote a set of instances (feature vectors)and let denote a set of labels (classes).
Given anumber of labelled instances, we are to construct afunction  ?
:h .
We also refer to it as a classi-fier.In collaborative bootstrapping, we consider theuse of two partial functions 1h  and 2h , which eitheroutput a class label or a special symbol ?
denoting?no decision?.Co-training and bilingual bootstrapping are twoexamples of collaborative bootstrapping.In co-training, the two collaborating classifiersare assumed to be based on two different views,namely two different subsets of the entire featureset.
Formally, the two views are respectively inter-preted as two functions )(1 xX and )x(X2 , ?x .Thus, the two collaborating classifiers 1h  and 2h  inco-training can be respectively represented as))(( 11 xXh  and ))(( 22 xXh .In bilingual bootstrapping, a number of classifi-ers are created in the two languages.
The classes ofthe classifiers correspond to word senses and donot overlap, as shown in Figure 1.
For example, theclassifier )E|x(h 11  in language 1 takes sense 2and sense 3 as classes.
The classifier )C|x(h 12  inlanguage 2 takes sense 1 and sense 2 as classes,and the classifier )C|x(h 22  takes sense 3 andsense 4 as classes.
Here we use 211 ,, CCE to de-note different words in the two languages.
Collabo-rative bootstrapping is performed between theclassifiers )(h ?1  in language 1 and the classifiers)(h ?2  in language 2.
(See Li and Li 2002 for de-tails).For the classifier )E|x(h 11 in language 1, weassume that there is a pseudo classifier)C,C|x(h 212 in language 2, which functions as acollaborator of )E|x(h 11 .
The pseudo classifier)C,C|x(h 212  is based on )C|x(h 12  and)C|x(h 22 , and takes sense 2 and sense 3 as classes.Formally, the two collaborating classifiers (onereal classifier and one pseudo classifier) in bilin-gual bootstrapping are respectively represented as)|(1 Exh  and )|(2 Cxh , ?x .Next, we introduce the notion of uncertainty re-duction in collaborative bootstrapping.Definition 1 The uncertainty )(hU of a classi-fier h is defined as:}),)(|({)( ?=?= xxhxPhU(1)In practice, we define )(hU  as}),  ,))((|({)(  ??
?<== xyyxhCxPhU ?
(2)where ?
denotes a predetermined threshold and)(?C denotes the confidence score of the classifierh.Definition 2 The conditional uncer-tainty )|( yhU of a classifier h given a class y isdefined as:)|},)(|({)|( yYxxhxPyhU =?=?=   (3)We note that the uncertainty (or conditional un-certainty) of a classifier (a partial function) is anindicator of the accuracy of the classifier.
Let usconsider an ideal case in which the classifierachieves 100% accuracy when it can make a classi-fication decision and achieves 50% accuracy whenit cannot (assume that there are only two classes).Thus, the total accuracy on the entire data space is)(5.01 hU??
.Definition 3 Given the two classifiers 1h and 2hin collaborative bootstrapping, the uncertainty re-duction of 1h  with respect to 2h   (denoted as)\( 21 hhUR ), is defined as}),)(,)(|({)\( 2121 ??
?=?= xxhxhxPhhUR  (4)Similarly, we have}),)(,)(|({)\( 2112 ?=??
?= xxhxhxPhhURUncertainty reduction is an important factor fordetermining the performance of collaborative boot-strapping.
In collaborative bootstrapping, the morethe uncertainty of one classifier can be reduced bythe other classifier, the higher the performance canbe achieved by the classifier (the more effectivethe collaboration is).4 Uncertainty Correlation CoefficientMeasure4.1 MeasureWe introduce the measure of uncertainty correla-tion coefficient (UCC) to collaborative bootstrap-ping.Definition 4 Given the two classifiers 1h and 2h ,the conditional uncertainty correlation coefficient(CUCC) between 1h and 2h given a class y (denotedas yhhr 21 ), is defined as)|)(()|)(()|)(,)((21 2121yYxhPyYxhPyYxhxhPyhhr ==?==?==?=?=(5)Definition 5 The uncertainty correlation coeffi-cient (UCC) between 1h and 2h  (denoted as 21hhR ),is defined as=yyhhhh r)y(PR 2121  (6)UCC represents the degree to which the uncer-Figure 1:  Bilingual Bootstrappingtainties of the two classifiers are related.
If UCC ishigh, then there are a large portion of instanceswhich are uncertain for both of the classifiers.
Notethat UCC is a symmetric measure from both classi-fiers?
perspectives, while UR is an asymmetricmeasure from one classifier?s perspective (ei-ther )\( 21 hhUR or )\( 12 hhUR ).4.2 Theoretical AnalysisTheorem 1 reveals the relationship between theCUCC (UCC) measure and uncertainty reduction.Assume that the classifier 1h can collaboratewith either of the two classifiers 2h and 2'h .
Thetwo classifiers 2h and 2h?
have equal conditionaluncertainties.
The CUCC values between 1h and2h?
are smaller than the CUCC values between 1hand 2h .
Then, according to Theorem 1, 1h shouldcollaborate with 2h?
, because 2h ?
can help reduce itsuncertainty more, thus, improve its accuracy more.Theorem 1 Given the two classifier pairs),( 21 hh and ),( 21 hh ?
, if ??
?
yrr yhhyhh ,2121 and),|()|( 22 yhUyhU ?=  ?y , then we have)\()\( 2121 hhURhhUR ?
?Proof:We can decompose the uncertainty )( 1hU of 1h  asfollows:)())|},)(,)(|({)|},)(,)(|({()()|},)(|({)(212111yYPyYxxhxhxPyYxxhxhxPyYPyYxxhxPhUyy==???=?+=?=?=?===?=?=)())|},)(,)(|({)|},)(|({)|},)(|({(212121yYPyYxxhxhxPyYxxhxPyYxxhxPryyhh==???=?+=?=??=?=?=)())|},)(,)(|({)|()|((212121yYPyYxxhxhxPyhUyhUryyhh==???=?+=})),)(,)(|({)()|()|((212121??
?=?+==xxhxhxPyYPyhUyhUryyhhThus, =?=??
?=?=yyhh yYPyhUyhUrhUxxhxhxPhhUR)()|()|()(}),)(,)(|({)\(211212121Similarly we have =??=?
?yyhh yYPyhUyhUrhUhhUR )()|()|()()\( 21121 21Under the conditions, yhhyhh rr 2121 ??
, ?y  and),|()|( 22 yhUyhU ?= ?y , we have)\()\( 2121 hhURhhUR ??
Theorem 1 states that the lower the CUCC val-ues are, the higher the performances can beachieved in collaborative bootstrapping.Definition 6 The two classifiers in co-trainingare said to satisfy the view independence assump-tion (Blum and Mitchell, 1998), if the followingequations hold for any class y.
)|(),|()|(),|(221122112211yYxXPxXyYxXPyYxXPxXyYxXP============Theorem 2 If the view independence assump-tion holds, then 0.121=yhhr holds for any class y.Proof:According to (Abney, 2002), view independenceimplies classifier independence:)|(),|()|(),|(212121yYvhPuhyYvhPyYuhPvhyYuhP============We can rewrite them as)|()|()|,,( 2121 yYvhPyYuhPyYvhuhP ========Thus, we have)|})(|({)|},)(|({)|},)(,)(|({2121yYxxhxPyYxxhxPyYxxhxhxP=?=?=?=?==?=?=?It means?
?= yr yhh     ,0.121  Theorem 2 indicates that in co-training withview independence, the CUCC values( ?
?yr yhh ,21 ) are small, since by defini-tion ?<< yhhr 210 .
According to Theorem 1, it iseasy to reduce the uncertainties of the classifiers.That is to say, co-training with view independencecan perform well.How to conduct theoretical evaluation on theCUCC measure in bilingual bootstrapping is stillan open problem.4.3 Experimental ResultsWe conducted experiments to empirically evaluatethe UCC values of collaborative bootstrapping.
Wealso investigated the relationship between UCCand accuracy.
The results indicate that the theoreti-cal analysis in Section 4.2 is correct.In the experiments, we define accuracy as thepercentage of instances whose assigned labelsagree with their ?true?
labels.
Moreover, when werefer to UCC, we mean that it is the UCC value onthe test data.
We set the value of ?
in Equation (2)to 0.8.Co-Training for Artificial Data ClassificationWe used the data in (Nigam and Ghani 2000) toconduct co-training.
We utilized the articles fromfour newsgroups (see Table 1).
Each group had1000 texts.By joining together randomly selected textsfrom each of the two newsgroups in the first row aspositive instances and joining together randomlyselected texts from each of the two newsgroups inthe second row as negative instances, we created atwo-class classification data with view independ-ence.
The joining was performed under the condi-tion that the words in the two newsgroups in thefirst column came from one vocabulary, while thewords in the newsgroups in the second columncame from the other vocabulary.We also created a set of classification datawithout view independence.
To do so, we ran-domly split all the features of the pseudo texts intotwo subsets such that each of the subsets containedhalf of the features.We next applied the co-training algorithm to thetwo data sets.We conducted the same pre-processing in thetwo experiments.
We discarded the header of eachtext, removed stop words from each text, and madeeach text have the same length, as did in (Nigamand Ghani, 2000).
We discarded 18 texts from theentire 2000 texts, because their main contents werebinary codes, encoding errors, etc.We randomly separated the data and performedco-training with random feature split and co-training with natural feature split in five times.
Theresults obtained (cf., Table 2), thus, were averagedover five trials.
In each trial, we used 3 texts foreach class as labelled training instances, 976 textsas testing instances, and the remaining 1000 textsas unlabelled training instances.From Table 2, we see that the UCC value of thenatural split (in which view independence holds) islower than that of the random split (in which viewindependence does not hold).
That is to say, innatural split, there are fewer instances which areuncertain for both of the classifiers.
The accuracyof the natural split is higher than that of the randomsplit.
Theorem 1 states that the lower the CUCCvalues are, the higher the performances can beachieved.
The results in Table 2 agree with theclaim of Theorem 1.
(Note that it is easier to useCUCC for theoretical analysis, but it is easier touse UCC for empirical analysis).Table 2: Results with Artificial DataFeature Accuracy  UCCNatural Split  0.928 1.006Random Split 0.712 2.399We also see that the UCC value of the naturalsplit (view independence) is about 1.0.
The resultagrees with Theorem 2.Co-Training for Web Page ClassificationWe used the same data in (Blum and Mitchell,1998) to perform co-training for web page classifi-cation.The web page data consisted of 1051 web pagescollected from the computer science departmentsof four universities.
The goal of classification wasto determine whether a web page was concernedwith an academic course.
22% of the pages wereactually related to academic courses.
The featuresfor each page were possible to be separated intotwo independent parts.
One part consisted of wordsoccurring in the current page and the other partconsisted of words occurring in the anchor textspointed to the current page.We randomly split the data into three subsets:labelled training set, unlabeled training set, and testset.
The labelled training set had 3 course pagesand 9 non-course pages.
The test set had 25% ofthe pages.
The unlabelled training set had the re-maining data.Table 3: Results with Web Page Data and Bilin-gual Bootstrapping DataData Accuracy UCCWeb Page 0.943 1.147bass 0.925 2.648drug 0.868 0.986duty 0.751 0.840palm 0.924 1.174plant 0.959 1.226space 0.878 1.007Word Sense Dis-ambiguationtank 0.844 1.177We used the data to perform co-training andweb page classification.
The setting for theTable 1: Artificial Data for Co-TrainingClass Feature Set A Feature Set BPos comp.os.ms-windows.misc talk.politics.miscNeg comp.sys.ibm.pc.hardware talk.politics.gunsexperiment was almost the same as that of Nigamand Ghani?s.
One exception was that we did notconduct feature selection, because we were notable to follow their method from their paper.We repeated the experiment five times andevaluated the results in terms of UCC and accuracy.Table 3 shows the average accuracy and UCCvalue over the five trials.Bilingual BootstrappingWe also used the same data in (Li and Li, 2002) toconduct bilingual bootstrapping and word sensedisambiguation.The sense disambiguation data were related toseven ambiguous English words, each having twoChinese translations.
The goal was to determinethe correct Chinese translations of the ambiguousEnglish words, given English sentences containingthe ambiguous words.For each word, there were two seed words usedas labelled instances for training, a large number ofunlabeled instances (sentences) in both English andChinese for training, and about 200 labelled in-stances (sentences) for testing.
Details on data areshown in Table 4.We used the data to perform bilingual boot-strapping and word sense disambiguation.
The set-ting for the experiment was exactly the same asthat of Li and Li?s.
Table 3 shows the accuracy andUCC value for each word.From Table 3 we see that both co-training andbilingual bootstrapping have low UCC values(around 1.0).
With lower UCC (CUCC) values,higher performances can be achieved, according toTheorem 1.
The accuracies of them are indeed high.Note that since the features and classes for eachword in bilingual bootstrapping and those for webpage classification in co-training are different, it isnot meaningful to directly compare the UCC val-ues of them.5 Uncertainty Reduction Algorithm5.1 AlgorithmWe propose a new algorithm for collaborativebootstrapping (both co-training and bilingual boot-strapping).In the algorithm, the collaboration between theclassifiers is driven by uncertainty reduction.
Spe-cifically, one classifier always selects the most un-certain unlabelled instances for it and asks theother classifier to label.
Thus, the two classifierscan help each other more effectively.There exists, therefore, a similarity between ouralgorithm and active learning.
In active learningthe learner always asks the supervisor to label theTable 4: Data for Bilingual BootstrappingUnlabelled instances WordEnglish ChineseSeed words Test instancesbass 142 8811 fish / music 200drug 3053 5398 treatment / smuggler 197duty 1428 4338 discharge / export 197palm 366 465 tree / hand 197plant 7542 24977 industry / life 197Space 3897 14178 volume / outer 197tank 417 1400 combat / fuel 199Total 16845 59567 - 1384Input: A set of labeled instances and a set of unla-belled instances.Loop while there exist unlabelled instances{Create classifier 1h using the labeled instances;Create classifier 2h using the labeled instances;For each class ( yY = ){Pick up yb  unlabelled instances whose labels( yY = ) are most certain for 1h and are mostuncertain for 2h , label them with 1h and addthem into the set of labeled instances;Pick up yb  unlabelled instances whose labels( yY = ) are most certain for 2h and are mostuncertain for 1h , label them with 2h  and addthem into the set of labeled instances;}}Output: Two classifiers 1h and 2hFigure 2: Uncertainty Reduction Algorithmmost uncertain examples for it, while in our algo-rithm one classifier always asks the other classifierto label the most uncertain examples for it.Figure 2 shows the algorithm.
Actually, ournew algorithm is different from the previous algo-rithm only in one point.
Figure 2 highlights thepoint in italic fonts.
In the previous algorithm,when a classifier labels unlabeled instances, it la-bels those instances whose labels are most certainfor the classifier.
In contrast, in our new algorithm,when a classifier labels unlabeled instances, it la-bels those instances whose labels are most certainfor the classifier, but at the same time most uncer-tain for the other classifier.As one implementation, for each class y, 1h firstselects its most certain ya instances, 2h  next se-lects from them its most uncertain yb  instances( yy ba ?
), and finally 1h labels the yb instanceswith label y (Collaboration from the opposite di-rection is performed similarly.).
We use this im-plementation in our experiments described below.5.2 Experimental ResultsWe conducted experiments to test the effectivenessof our new algorithm.
Experimental results indi-cate that the new algorithm performs better thanthe previous algorithm.
We refer to them as ?new?and ?old?
respectively.Co-Training for Artificial Data ClassificationWe used the artificial data in Section 4.3 and con-ducted co-training with both the old and new algo-rithms.
Table 5 shows the results.We see that in co-training the new algorithmperforms as well as the old algorithm when UCC islow (view independence holds), and the new algo-rithm performs significantly better than the old al-gorithm when UCC is high (view independencedoes not hold).Co-Training for Web Page ClassificationWe used the web page classification data in Sec-tion 4.3 and conducted co-training using both theold and new algorithms.
Table 6 shows the results.We see that the new algorithm performs as well asthe old algorithm for this data set.
Note that hereUCC is low.Table 6: Accuracies with Web Page DataAccuracy Data Old New UCCWeb Page 0.943 0.943 1.147Bilingual BootstrappingWe used the word sense disambiguation data inSection 4.3 and conducted bilingual bootstrappingusing both the old and new algorithms.
Table 7shows the results.
We see that the performance ofthe new algorithm is slightly better than that of theold algorithm.
Note that here the UCC values arealso low.We conclude that for both co-training and bi-lingual bootstrapping, the new algorithm performssignificantly better than the old algorithm whenUCC is high, and performs as well as the old algo-rithm when UCC is low.
Recall that when UCC ishigh, there are more instances which are uncertainfor both classifiers and when UCC is low, there arefewer instances which are uncertain for both classi-fiers.Note that in practice it is difficult to find asituation in which UCC is completely low (e.g., theview independence assumption completely holds),and thus the new algorithm will be more usefulthan the old algorithm in practice.
To verify this,we conducted an additional experiment.Again, since the features and classes for eachword in bilingual bootstrapping and those for webpage classification in co-training are different, it isnot meaningful to directly compare the UCC val-ues of them.Co-Training for News Article ClassificationIn the additional experiment, we used the dataTable 5: Accuracies with Artificial DataAccuracy Feature Old New UCCNatural Split 0.928 0.924 1.006Random Split 0.712 0.775 2.399Table 7: Accuracies with Bilingual BootstrappingDataAccuracy Word Old New UCCbass 0.925 0.955 2.648drug 0.868 0.863 0.986duty 0.751 0.
797 0.840palm 0.924 0.914 1.174plant 0.959 0.944 1.226space 0.878 0.888 1.007tank 0.844 0.854 1.177Average 0.878 0.888 -from two newsgroups (comp.graphics andcomp.os.ms-windows.misc) in the dataset of(Joachims, 1997) to construct co-training and textclassification.There were 1000 texts for each group.
Weviewed the former group as positive class and thelatter group as negative class.
We applied the newand old algorithms.
We conducted 20 trials in theexperimentation.
In each trial we randomly splitthe data into labelled training, unlabeled trainingand test data sets.
We used 3 texts per class as la-belled instances for training, 994 texts for testing,and the remaining 1000 texts as unlabelled in-stances for training.
We performed the same pre-processing as that in (Nigam and Ghani 2000).Table 8 shows the results with the 20 trials.
Theaccuracies are averaged over each 5 trials.
Fromthe table, we see that co-training with the new al-gorithm significantly outperforms that using theold algorithm and also ?single bootstrapping?.
Here,?single bootstrapping?
refers to the conventionalbootstrapping method in which a single classifierrepeatedly boosts its performances with all the fea-tures.The above experimental results indicate that ournew algorithm for collaborative bootstrapping per-forms significantly better than the old algorithmwhen the collaboration is difficult.
It performs aswell as the old algorithm when the collaboration iseasy.
Therefore, it is better to always employ thenew algorithm.Another conclusion from the results is that wecan apply our new algorithm into any single boot-strapping problem.
More specifically, we can ran-domly split the feature set and use our algorithm toperform co-training with the split subsets.6 ConclusionThis paper has theoretically and empirically dem-onstrated that uncertainty reduction is the essenceof collaborative bootstrapping, which includesboth co-training and bilingual bootstrapping.The paper has conducted a new theoreticalanalysis of collaborative bootstrapping, and hasproposed a new algorithm for collaborative boot-strapping, both on the basis of uncertainty reduc-tion.
Experimental results have verified thecorrectness of the analysis and have indicated thatthe new algorithm performs better than the existingalgorithms.ReferencesS.
Abney, 2002.
Bootstrapping.
In Proceedings of the40th Annual Meeting of the Association for Compu-tational Linguistics.A.
Blum and T. Mitchell, 1998.
Combining LabeledData and Unlabelled Data with Co-training.
In Pro-ceedings of the 11th Annual Conference on Compu-tational learning Theory.M.
Collins and Y.
Singer, 1999.
Unsupervised Modelsfor Named Entity Classification.
In Proceedings ofthe 1999 Joint SIGDAT Conference on EmpiricalMethods in Natural Language Processing and VeryLarge Corpora.S.
Dasgupta, M. Littman and D. McAllester, 2001.
PACGeneralization Bounds for Co-Training.
In Proceed-ings of Neural Information Processing System, 2001.T.
Joachims, 1997.
A Probabilistic Analysis of the Roc-chio Algorithm with TFIDF for Text Categorization.In Proceedings of the 14th International Conferenceon Machine Learning.D.
Lewis and W. Gale, 1994.
A Sequential Algorithmfor Training Text Classifiers.
In Proceedings of the17th International ACM-SIGIR Conference on Re-search and Development in Information Retrieval.C.
Li and H. Li, 2002.
Word Translation Disambigua-tion Using Bilingual Bootstrapping.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics.I.
Muslea, S.Minton, and C. A. Knoblock 2000.
Selec-tive Sampling With Redundant Views.
In Proceed-ings of the Seventeenth National Conference onArtificial Intelligence.K.
Nigam and R. Ghani, 2000.
Analyzing the Effective-ness and Applicability of Co-Training.
In Proceed-ings of the 9th International Conference onInformation and Knowledge Management.D.
Pierce and C. Cardie 2001.
Limitations of Co-Training for Natural Language Learning from LargeDatasets.
In Proceedings of the 2001 Conference onEmpirical Methods in Natural Language Processing(EMNLP-2001).D.
Yarowsky, 1995.
Unsupervised Word Sense Disam-biguation Rivaling Supervised Methods.
In Proceed-ings of the 33rd Annual Meeting of the Associationfor Computational Linguistics.Table 8:  Accuracies with News DataCollaborative Boot-strapping Average AccuracySingle Boot-strapping Old  NewTrial 1-5 0.725 0.737 0.768Trial 6-10 0.708 0.702 0.793Trial 11-15 0.679 0.647 0.769Trial 16-20 0.699 0.689 0.767All 0.703 0.694 0.774
