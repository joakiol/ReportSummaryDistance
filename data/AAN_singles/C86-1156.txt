Discourse, anaphora and parsing1.
IntroductionMark JohnsonCenter for the Study of Language and Informationand Dept.
of LinguisticsStanford UniversityAbstractDiscourse Representation Theory, as formulated by Hans Kamp and others, provides amodel of inter- and intra-sentential naphoric dependencies in natural language.
In thispaper, we present a reformulation of the model which, unlike Kamp's, is specified eelara-lively.
Moreover, it uses the same rule formalism for building both syntactic and semanticstructures.
The model has been implemented in an extension of PROLOG, and runs on aVAX 11/750 computer.The study of anaphora has been a central issue in boththeoretical nd computational linguistics.
Studies of anaphorain theoretical linguistics usually concentrate on describing theconstraints on sentence-internal anaphora (e.g.
(Reinhart1983)).
However, recent work by Hans Kamp (Kamp 1981)suggests that it is possible to describe some important aspectsof inter-sentential naphora while still respecting the con-straints of intra-sentential anaphora.
In this paper we con-struct a model of anaphorie dependencies which is based onKamp's theory of Discourse Representation (DRT), butexpressed in the same declarative formalism that we use fordescribing syntactic structure.
Unlike the standard DRTapproach to constructing discourse representations, our modelavoids any iaention of left-to-right processing.
Note that weare not denying that there arc left-to-right dependencies inanaphora, nor are we denying that these dependencies ulti-mately arise from the fact that earlier parts of a discourse areprocessed before later parts of that discourse.
Rather, weclaim that such dependencies should not be stated implicitly inthe specification of the processing strategy, but are betterexpressed as part of the formal description of the model.The idea of separating a computer program into two distinctparts: a logical specification of the problem to be solved, anda proof procedure that "interprets" this specification to actu-ally solve the problem has been a prominent idea in recentwork on logle programming, especially in the work of Kowal-ski.
We connect directly into this tradition, in that our specif-ication of DRS theory is provided in the form of an extendedHorn-clause logic formalism.Our system thus consists of two parts: a logical specificationof DRS theory, written in a language that we have dubbedPrAtt (for Prolog with Attributes), and a simple theoremprover (interpreter) which is capable of deducing the DRSsthat correspond to various input sentences using the logicalspecification of DRS theory.In terms of Kowalski's (Kowalski 1979b) famous maxim"Algorithm = Logic + Control", the logical specification ofthe DRS theory corresponds to the "Logic", while the infer-ence technique used by the inference ngine corresponds tothe "Control".
Currently our inference ngine uses a simpletop-down proof technique (inherited from Prolog, in whichThe research reported in this paper was conducted atthe The (;enter for the Study of Language and Information,and was made possible in part by a gift from the SystemDevelopment foundation, we gratefully acknowledge financialsupport from the National Science Foundation (grant BNS-8309780); and Klein also acknowledges financial support fromthe U.K. Science and Engineering Research Council (Ad-vanced FeUowship).
Earlier versions of this paper werepresented at at the Summer Meeting of the Association forSymbolic Logic, July 15-20 1985, Stanford University, and theAutumn Meeting of the Linguistics Association for Great Bri-tain, September 18-20 1985, University of Liverpool.We would like to express our appreciation for comments andsuggestions from Jo Calder, Glyn Morrill, Carl Pollard, Fcr-nando Percira, John Perry, Ivan Sag, Stuart Shieber, andHenk Zeevat.Ewan KleinCentre for Cognitive Science\[formerly School of Epistemics\]Edinburgh Universitythe inference ngine is written), so the system as a whole (=logical specification of DRS theory + top-down theoremprover) functions essentially as a top-down predictive parser.However, this top-down behaviour is a property of thetheorem prover only, and one could replace the theoremprover component with a more sophisticated proof techniquesuch as Earley deduction (Pcreira and Warren 1983) resultingin a system that used a generalization of Earley's parsingalgorithm.
Such a change would be a change to the theorem-prover only, since both systems would use the same logicalspecification of DRT.2.
A naive model of anaphorlc dependencyIn this section we give a brief overview of the basic ideasinvolved in the model.
We do this by presenting a "naive"model provides the core of the analysis developed in section5, but which ignores the complexity of syntactic structure andquantifier binding.
The naive model enables us to exolain ourstance, independent of these complicating factors, on matterssuch as the changing natm'e of the discourse context overtime, the mectlanisms used to describe reference, semantlegender agreement, etc.The following diagram (1) illustrates a naive declarativemodel of anaphoric dependency, where all that is required tolicense an anaphoric pronoun is the presence of a possibleantecedent to its left.
(1) { } {w} {w} {w,m} {w,m} {w,m} {w,m}Awoman kissed aman.
He J touched her.
\]In the naive model we conceive of a discourse context as sim-ply consisting of a set of individual names, or reference mark-ers.
These represent the entities which are available to betalked about in the discourse, and play a similar role in ourframework as the discourse entities of (Webber 1979).
Inparticular, they provide tile set of possible antecedents foranaphorie noun phrases.
We make the simplifying assump-tion that the only way for a reference marker to find its wayinto tile context is by courtesy of an indefinite description.We assume that reference markers are typed, and we adoptthe convention of using 'f' as a marker for female gender enti-ties, 'm' for male gender entities, and 'x' for neuter orindeterminate g nder entitie.s.
1The vertical bars in (I) represent moments of time in theanalysis of the discourse; each moment is associated with adiscourse context.
In this way, we can characterize a develop-ing discourse context as a series of discrete states, each ofwhich is localized at specific point in time and unchangingduring the course of the parse.
2 In the diagram above, theseI These three types of reference marker correspond tothe genders available for pronominal agreement in English.However, it seems plausible that a more complicated accountof agreement would be required for those languages (e.g.French and German) in which gender marking is semanticallyarbitrary.669contexts are shown above the bar that corresponds to thepoint of time at which they hold.
Thus, at the beginning ofthe discourse the context was empty (i.e.
the null set), whileafter the phrase a woman was uttered the context containedthe single reference marker f. Consequently, { f } serves asthe context for kissed.We view the meaning of a linguistic expression a as a relationbetween the context hat preeeeds a and the context hat fol-lows ~.
That is, the meaning of ot has the general formshown in (2):(2) Preceding-Context \[ ~t \[ Following-ContextConsequently, in the naive model the discourse context isdetermined by a series of equations relating the context whichimmediately precedes a lexical item to the context whichimmediately follows that item.
For individual words, thisrelation is part of the lexical specification.
To illustrate, thesemantic ontribution of woman is given here by (3a), or moregenerally, as (3b).
(3a) {} I woman \[{f}(3b) C I woman I C U { f }The anaphoric pronoun her behaves in a very differentfashion to indefinite noun phrases.
Rather than adding areference marker to the following context, it looks in thepreceding context for a reference marker of the right sort (i.e.one that agrees with it in number and gender).
If there is nosuch antecedent marker, the pronoun cannot be interpreted asanaphoric.
The meaning of anaphoric her is the relation in(4).
(4) C lher lC i f f f ?Cwhere f is the reference marker associated with herA sequence of discourse contexts is well-formed for a string ifall of the relations associated with the lexieal items in thestring hold; i.e.
the discourse contexts arc a solution to therelational equations.
Sometimes these equations wiil have asingle solution; in that case, the discourse is unambiguous.However, usually the equations have multiple solutions, whichmeans, in effect, that the discourse has many interpretations.This arises, in the present discussion, when a pronoun hasseveral possible antecedents.
3 On the other hand, it is alsopossible that the equations have no solution at all.
This casearises when a pronoun is used in a discourse context hat con-tains no appropriate reference marker at all.At a more abstract level, we can view this model as one inwhich the context is a stream of reference markers, which isthreaded from one lexical item to the next.
The equationsassociated with individual iexical items act as (possibly non-deterministic) operators on their input stream to produce anoutput stream, which serves as the input to the following lexi-eel item.One of the main virtues of this simple picture is that it invitescomparison with other ideas.
Our proposed notion of mean-ing is clearly reminiscent of the claim in (Barwise and Perry1983) that meaning is a relation between different types ofsituation, though it also has its roots in earlier work on indexi-cal semantics, such as (Stalnaker 1972).
Second, it is also2 It seems that this technique of factoring a single non-monotonic representation into a series of monotonic ones isapplicable in many areas other than the one discussed here.At an abstract level it is similar to the technique discussed by(Kowalski 1979a).
It is also similar to the use of differencelists in logic programming, since the "content" of a particularelement is the difference bewteen its "output" and its "input".s In such a case, our program merely enumerates all pos-sible interpretations, which results in the familiar combinatori-al explosion of solutions.
A better technique, which we can-not explore here, would be factor out the ambiguity and local-ize it in the representation.670reminiscent of the technique used in logic programmingknown as difference lists (Pereira 1985) or threading.3.
Discourse Representation TheoryThe naive model presented in the last section ignored all syn-tactic and lexical interactions with the "left-to-right" nature ofanaphoric dependency.
The fatal flaw of this account is thatis fails to explain the anaphoric propeties of universally quan-tified NPs.
The data which shows this is well known, andsome illustrative cases are given in (5) to (7).
(5) a.
A woman i went home.
She.
was tired 1b.
Every woman i went home.
She i was tired.
(6) a.
Every man i thought he i was ill.b.
Lee gave every woman i her t prize.
(7) a.
Every man saw a woman t. She i was going home.b.
Every woman who klssed a man I loved him 1.
(5) shows that a universal NP does not normally act as anantecedent for pronouns in a following sentence.
4 Accordingto the variable-binding paradigm of anaphora, this followsbecause a universal can only enter into an anaphorie relationwith pronouns that are in its scope.
For our current purposes,it is not important whether scope is determined in terms of atree-geometrical notion like e-command (Reinhart 1983), or interms of function-argument structure, as proposed by(Ladusaw 1980) and (Bach and Partee 1980); in either case, itis clear that the scope of the universal in (5) is that portion ofthe first sentence that we have italicised.
Examples (6) illus-trate cases where a universal does enter into an anaphoricrelation with a pronoun in its scope (again indicated by italiei-sation).
(7) is intended to indicate the interaction betweenindefinites and universals.
In (7a), the indefinite has narrowerscope than the universal, and it is thereby incapable of actingas an antecedent for a pronoun such as the following shewhich is outsid the scope of the universal.
By contrast, whenboth the indefinite and the pronoun fall within the scope of auniversal, as in (7b), an anaphorie link is permissible.
Notethat (7b) is a so-called 'donkey' sentence.The study of these syntactic and lexieal effects has been a cen-tral theme of modern theoretical linguistics, but most workwithin this paradigm has concentrated almost exclusively onintra-sentential naphora.
However, recently (Kamp 1981),(Helm 1982) and (Haik 1984) have developed theories capableof providing a unified account of the main properties of intra-and inter-sentential naphora.
We will base our account onKamp's Discourse Representation Theory, and in this section,we briefly outline those aspects of Kemp's model which are ofmost relevance to us.DRT is intended to explicitly capture the distinctions in ana-phoric potential exhibited by (ga) and (gb), while simultane-ously providing a basis for truth-conditional semantic interpre-tation.
Thus (ga) would be associated with a DRS of the form(8).
(g) fwoman(f)went-home( f )tired( f )4 Sentences like (i) are exceptions to this generalization:(i) Every man wil l  l ike this car.
He' l l  certainly want todrive it.Rather than abandoning the generalization altogether, itseems more fruitful to adopt the hypothesis that suchdiscourses involve 'modal subordination' (Roberts 1986) ofthe second sentence to the first.
However,  we do not under-stand the precise mechanics of this process.A discourse representation has two parts: a 'universe' consist-ing of set of discourse markers (in this case a singleton set)and set of conditions.
The sentenee A woman went homelicences the introduction of the reference marker f into theuniverse of the DRS, and this marker is also entered as theargument of tile predicate went-home.
When She was tired isanalyzed, the pronoun can be interpreted as anaphorie on apreceding NPs if the marker licensed by that NP is 'aecessiobit ' ;  i.e.
if tile marker belongs to the universe of the immedi-ately enclosing DR or a superordinate one.
Since f is accessi-ble, the prouoan her can be identified with it to yield the con-dition tired(f).Before turning to sentences involving universal NPs, it will beuseful to consider in a little more detail the procedure for con-structing a Dlt  like (8) proposed by (Kamp 1981/.
Karnp'srules pivot on the noun phrases in a sentence, and dependparticularly on any determiners in the noun phrases.
It is use?ful to think of every determiner as having a semantic restrictorand a semantic scope.
The determiner will bind an argumentposition in each of these.
Thus, in a simple intransitive sen-tence like tlu~ first sentence of (5), the restrictor of a iswoman(), while its scope is went home(), where the emptyparentheses indicate an open argument position.
Given anexisting (possibly empty) DRS K, a sentence of the form \[\[aRes\] Scope\] is "processed" in the following manner:(i) add a new reference marker x to the universe of K;(ii) fill the argument slot in Res by x, and add the resultingclause to the conditions of K; and(iii) fill the argument slot in Scope by x, and recursively callany applicable construction rules to process the resultingstring.Let us turn now to sentences involving universals.
The DRassociated with (5b) is i l lustrated in (9).
(9)f-\[ w?~mfan(f ) 1 "  l went-h?me(f~ltired( f" )The universal quantifier every triggers the introduction of twosubordinate DRSs, l inked by the relation =>;  thiscorresponds roughly to implication in first order logic.
Whenwe come to analyze the second sentence of the discourse, Shewas tired the reference marker licensed by every woman istrapped in the subordinate DRS; it is not accessible at the toplevel of the discourse.
Consequently, the only option is totreat the pronoun she as non-anaphorie, which we have indi-cated here by associating it with a distinct reference marker.When we consider sentence-internal anapbora, theantecedent-introducing potential of every and a converge.
Forexample, in both of the following sentences, he can be ana-phoric to the subject NP:(6a) t?,very man i thought he i was ill.(10) A man i thought he i was ill.Although it may not be obvious from the examples given sofar, DR theory correctly predicts that the reference markersassociated with an indefinite or universal NP in subject posi-tion will be anaphorically accessible to pronouns that it c-commands.
5 To see why, we need to consider in a little more5 It might be argued that DR theory fails to provide anadequate semantic distinction between a 'c-command binding'relation and a 'discourse anaphora' relation, as proposed forexample by (Rcinhart 1983) in order to account for thestrict/sloppy ambiguity in VP ellipsis.
Whether this criticismis justified or not depends in large part on the appropriateanalysis of such ellipsis phenomena in the DR framework.For some discussion, see (van Eijck 1985), (Klein 1985),(Roberts 1984).detail tile way in which DR's are coustructcd on g~amp'sapproach.Construction rules apply to sentences on a top-down, left-tooright basis.
Given a sentence like (6a) or (10), the first con-stituent o be processed is tile subject NP.
We either stay inthe current DR, if tile determiner is a, or 'push down' to anembedded DR if the determiner is every.
(This embeddedDR is, therefore, the antecedent box of tile conditional l ikethat displayed in (9).)
A discourse marker x i is introducedinto the universe of whatever is now the current DR, and x ialso becomes the argument of the subject nominal (e.g.man(rot)) and the first argument of the predicate VP (e.g.
m tthought he was ill).
When tile VP is processed, there areagain two cases, depending on whether tile subject determinerwas a or every.
In tile first ,:;ase, we enter tile new conditionslicensed by the VP into the current DR. Ill the second case,we close off the current (antecedent) DR, and open a newembedded DR which forms the conseqent box of the condi-tional.
Kamp claims that the reference markers accessible asantecedents to a given pronoun occurrence consist of thosereference markers which are present in the universe of eitherthe current DR or of any DR.'s which are superordinate o thecurrent DR. Of two DR's K 1 and K2, K 1 is superordinate toI{ 2 if:(i) K 2 is embedded in K1, or(ii) if K 1 is the anteeedeut of a conditional of which K 2 istile consequent, or(iii) if there is some K~ such that K 1 is superordiaate o K 3and K 3 is I;uperordmate o K 2.This is i l lustrated in (11) diagram below, where tile lightlyshaded boxes arc all superordinate o the darkly shaded box.
(II) ==============================================================================IConsider now what follows when we come to process the NPhe in either (6a) or (10).
It can be anaphorically l inked to anyreference marker which is accessible to it, and this will ofcourse include the marker x i introduced by the subject NP.Let us now attempt o summarise the salient features of DRT.Note, first, that every noun phrase is associated with a'space '6 in a Discourse Representation.
Referential terms -which we take to include definite and indefinite descriptions,proper names, and definite pronouns - are entered into anexisting space.
By contrast, universally quantified NPs inducea new subspace~Second, the space associated with an NP represents both thequantificational scope of the NP and its anaphoric domain.Third, the boundaries of these spaces are not coterminouswith clause or sentence boundaries.
A clause containinguniversal NPs will induce a number of subspaces; conversely,the space associated with a referential NP can encompassindefinitely many sentences of a given discourse.Fourth, the space of an indefinite NP which occurs within thescope of a uniw~rsal NP is the same as the space of the univer-sal.4.
The flow of anaphorlc InformationIn the last section we showed how DRT is able to simultane-ously describe both the semantics of quantification and tileanaphorie 'range' of referential noun phrases in terms of asingle discourse representatkm.
The standard version of DRTdepends crucially on processing notions in order to explain thefailure of anaphora in examples like (12).671(12) He i l iked a boy i.Since the reference marker for a boy is not introduced into theDR until after the pronoun he is introduced, it is unavailableas a possible antecedent.
That is, the failure of anaphora isexplained by assuming that the pronoun's antecedent isassigned at the time at which it is introduced into the DRS,and that the reference marker for the noun phrase is intro-duced after the pronoun was introduced.In a declarative framework, an explanation in terms of pro-cessing order is impermissible hence we represent left-to-rightdependencies by explicit equations.
Although these equationsare in principle non-directional, it can be helpful to think ofthem as providing a means for transmitting information fromone node in the syntactic structure to another.Bottom-up information flow is central to syntax-drlven com-positional semantles of the familiar sort: semantic values areassociated with the leaves of the syntax tree, and the semanticvalue of a complex constituent is determined as a function ofthe semantic values of the constituents daughters.
Thediagram in (13) shows this direction of information flow.
(13) S kissed'( a'(boy9 )(a'(girl') )NP a'(girl') VP kissed'(a'(boy') )Det a" N girl" V kissed" NP a'(boy')i !, Jsed a gi Det a" N boy"Although this approach as proven to be extremely powerful,it is awkward and intuitively unsatisfactory as a means fordealing with anaphorie dependencies.
Even if much semanticinformation is indeed composed on a bottom-up regime, itseems highly plausible that anaphorie information - that is,information about the set of available antecedents - flows ina left-to-right direction.
We have already seen that a simpleleft-to-rlght model of this information flow can be constructedby regarding meaning as a relation between contexts, but wehave also seen that such a model is inadequate for dealingwith the facts of bound anaphora.
A more satisfactory modelcan be constructed by reflecting on the principles involved inconstructing Discourse Representations.
As we pointed out inthe previous section, Kamp's construction rules centre on thedeterminers a and every, since they trigger the introduction ofreference markers, the binding of argument positions, and theintroduction of sub-spaces.
What we shall suggest, therefore,is that information about possible antecedents flows from adeterminer to the determiner's restrietor, and from the restrie-tot to the determiner's cope.
The following diagram (14)illustrates how this top-down, left-to-right flow is integratedwith the orthodox phrase marker of a girl kissed a boy.
(14) {L {b,g}I I I a g'~\[l '~x ki!sed L ~  {b,g}a Is This term is intended to be reminiscent of work by Fau-connier (1985) on mental spaces, and by Reichman-Adar(1984) on context spaces, though considerable work needs tobe done in showing that these ideas are in fact compatible.672The light, incoming lines on the left-hand side of a node indi-cate incoming information about the set of possibleantecedents.
This set wil l  be encoded in something we call the"in-list".
The light lines on the right-hand side of a node indi-cate outgoing ~ information about antecedents, encoded in theform of an "out-list".
In general, the out-list of any node willbe its in-list plus any additional information added by thatnode.
Circled nodes mark constituents that supplement theirin-list with new reference markers.
The in-list and the out-listtogether form a difference list, in that the content added byany item is the difference between its in-list and out-list.Alternatively, one can view the in-lists and the out-lists ofnodes as streams along which information about antecedentsflows: this anaphoric information is threaded through the syn-tactic tree structure.
Notice that we assume the sentence as awhole wil l  be fed an in-list which is supplied by the precedingdiscourse.
Moreover, the sentence as a whole will also a pro-duce an out-list, which will provide potential antecedents forfollowing discourse.The next diagram (15) il lustrates the flow of information forevery girl kissed a boy.1 ~, {} {}:very git~ kissed -~_.?d.
J " "~ ~K~) {b,g}!
JBy contrast with (14), the out-list from the VP, containingreference markers for gtrl and boy, is "trapped" at that levelrather than percolating up to the S node.
The out-list for thesentence as a whole is just the sentence's in-list.
This capturesthe idea from binding theory that the scope of a quantifier isnormally l imited to its e-command domain (Reinhart1981, Reinhart 1983); In terms of DRT, it corresponds to theclosed subspace that is associated with universal NPs.Let us summarize our claims so far.
We have suggested thatthere is a contrast between the bottom-up information flow ofcompositional semantics, on the one hand, and the top-downflow that is naturally associated with anaphoric information.We have also suggested that top-down flow is largely deter-mined, according to the principles of DRT, by the lexical pro-perties of determiners and their structural position in the sen-tence.One possible implementation of this analysis would be to fac-tor out anaphoric, contextual information from the rest ofsemantics, and to use two distinct mechanisms for building thetwo kinds of representation.
However, such an approach failsto explain why the spaces in a DR, and the list ofcontextually-divan tecedents always covary; that is, when anew DR subspace is opened, a new context list begins, andwhen a DR subspace is closed, a context list is simply"dropped", ie.
it does not serve as the in-list to any otherexpression.
Indeed, the fact that a DRS in Kamp's theoryconsists of a universe, corresponding to our context list, and aset of conditions, corresponding roughly to compositionalsemantic information, suggests that it out to be possible toenrich the notion of a context from being just a list ofantecedents o being a whole DR structure.In our analysis, then, we thread a list through the syntacticstructure which contains both conventional semantic informa-tion and information about available antecedents, o that anexpression mapping an incoming context into an outgoing con-text does more than incrementing the set of possibleantecedents: it also adds conditions to the context thatcorrespond to its truth-conditional semantics.It is necessary that the context be structured, rather than asimple list, as it was  in the naive model, and as discussedabove.
This is because we need to be able to incorporate thesemantic structures associated with all expressions, even thosethat are anaphorically opaque to following anaphora.
In themodel described immediately above, we accounted for theanaphoric opacity of an expression by "dropping" its contextlist after it had been processed, but such "dropping" in a sys-tem where the context lists also contain "compositional"semantic information would result in that semantic informa-tion also being lost.Rather, we structure the context list as an ordered list of thecurrently open DR spaces, starting at the most embeddedspace, and working upward through the superordinate spaces.For example, the context list for an item located in DR spaceK 1 in (11) would be \[ K .
,  K~, K~, K-\] ,  where each K. is a 1 z 4 1set of reference markers and eon~tions, the current contentsof the corresponding space.
The first space on the context listis the most embedded space, ie.
the current space, and identi-ties the place where new conditions and reference markers areto be added.
Since the context list consists of the active spaceplus all of the spaces snperordinate to it, any reference mark-ers contained in these spaces are possible antecedents for ana-phora in the active space.5.
The GrammarWe turn now to considering the induction of DRSs.
In thissection we describe a simplif ied version of ttle grammar thatwe have implemented.
The grammar presented here is theactual input to the proof procedure: the parser is nothingmore than a declarative statement of the well-formedness con-ditions of an utterance, plus a proof procedure capable ofdetermining whether or not these conditions actually hold of agiven utterance.The rules are written in DCG format (Clocksin and Mellish1984) in a superset of Prolog that we developed in this pro-ject.
This language, which we have dubbed PrAtt (for Prologwith Attributes), allows an attribute-value notation as well asthe standard position-value notation of Prolog.
For example,the expression "N:syn:index" refers to the value of the Indexattribute of the syn attribute of the variable N.We make heavy use of the attribute-value notation torepresent feature bundles associated with constituents.
Twoattributes that are present on every constituent are syn (for"syntax") and sam (for "semantics").
The sam:in and sam:outattributes contain the context in-lists and out-lists respectively,while the syn attribute holds information used to construct thefunction-argument structure of the clause.Expressions act on the context list by opening or closingspaces (ie.
pushing or poping spaces from the context list),adding reference markers and conditions to the active space,and looking through all of the spaces in the context list forantecedents for anaphora.Consider, for example, the common noun woman.
It inserts areference marker f and a condition woman(f) into the activespace.
Using our earl ier relational notation, we can expressits meaning as follows: 7(16) \[ActiveJSuper\] I woman I \[if, woman(f) ~Active\]~uper\]In our implementation, this would be written as in (17).
(17) n (N) - ->  \[woman\],{ N:syn:index = w,N:sem:in = \[ Current I Super \],N:sem:out = \[ \[ w, woman(w) \[ Current \] I Super \] }.7 We use standard Proiog notation here: variables beginwith a capital etter, constants with a lower-case letter, "ix,y\]"is the list that contains x and y, and "\[x~\]" is the list that con-sists of x CONScd onto y.Tile hracketted equations are conditions that must be satisfiedin rewriting an N to the lcxical item woman.
The first equa-tion assigns a reference marker to the lexieal item, s thesecond equation analyses the incoming context list into twoparts, the current space (Current) and a list of the superordi-nate spaces (Super), while the third equation requires theactive space of the outgoing context list to contain the refer-enco marker and the condition associated with the noun.A sample entry for a verb is shown in (18).
Again, the equa-tions associated with the lexieal entry dissect the incomingcontext into the current space and a list of superordinatespaces, and place the condition associated with the verb intothe outgoing context.
(18)v(V)--> \[saw\],{ V:sem:in = \[ Current I Super \] ,V:sem:out =\[ \[ saw(V:syn:argl,  V:syn:arg2) I Current \] I Super \] }.One interesting property of this rule is that it is responsiblefor placing a condition into the context that in essencerepresents the compositional semantics of the entire clause.The ~yn attributes of constituents are used to councct the NParguments of the verb with the verb itself; thus the necessaryinformation to build tile condition associated with the entireclause is available at the verb.
One can view the equations inthe phrase structure rules associated with the syn attribute asdirecting information from the NP arguments inward anddownward to the verb.The crux of the grammar is located in the lexical entries fordeterminers, as hinted earlier.
(19) contains tim lexical entryfor the indefinite artlele a.
(19) det(Det).
.
-> \[a\],{ Det:sem:res:in = Det:sem:in,Det:sem:scope:in = Det:sem:res:out,Det:sem:out = Det:sem:scope:out }.As we shall see later, the phrase structure rules are written insuch a way that the value of the elauses's am attribute isequal to its subject's determiner's am attribute, and thesemantics attribute of the restrictor and the scope of a clauseare placed in that determiner's sem:res and sam:scope attri.butes respectively.
As noted earlier, an indefinite determinerdoes not cause the creation of any additional subspaces, ratherthe restrietor and the scope are simply placed into the currentactive space.
Therefore, the equations associated with theindefinite determiner simply connect the in-list asssociatedwith the sentence to the restrictor's in-list, feed the restrietor'sout-list to the scope's in-list, and take the out-list from thescope as the out-list for the clause as a whole.The lexical entry associated with the universal quantifier everyis a little more complicated.
It must create two new spaces,one for the restrictor, the other for the scope, and the finallyclose off both spaces, and huild the structure associated withthe clause as a whole.
(20) det (Det) - -> \[every\],{ Det:sem:res:in =\[ \[\] \] Det:sem:in \],Det:sem:scope:in =\[ \[\] I Det:sem:res:out \],Det:sem:seope:out =\[ Scope, Res I \[ Current \[ Super \] \],Det:sem:out =\[ \[ ( Res ==> Scope) ICurrent \] \]Super \] }.S For simplicity here we have reference markers directlyto lexieal entries; however more correctly the reference mark-ers should be assigned to lexieal tokens, allowing two occu-rances of the same lexical entry to refer to different objects inthe world.673The first equation in (20) pushes a new, empty space onto thedeterminer's in-list as the active space, and makes that list therestrictor's in-list.
The second equation takes the restrictor'sout-list pushes another new, empty space onto it, and makesthe resulting list the scope's in-llst.
The final equation takesthe scope's out-list, removes the two spaces that were addedfor the restrietor and the scope, and produces a new list inwhich the original active space has a complex condition addedto it representing the whole universally quantified expression.This last list serves as the outqist for the determiner, andhence for the clause as a whole.Below are the phrase structure rules responsible for connect-ing the various attributes of the constituents as describedabove.
(21) np(NP) --> { NP:sem = Det:sem,Det:sem:res = N:sem,NP:syn = N:syn },det(Det), n(N).
(22) vp(VP) --> { VP:sem = NP:sem,NP:sem:scope = V:sem,VP:syn:arg2 = NP:syn:index,VP:syn = V:syn},v(V), np(NP).
(23) s(S) --> { S:sem = NP:sem,S:syn = VP:syn,NP:sem:seope = VP:sem,VP:syn:argl  = NP:syn:index},np(NP), vp(VP).It remains only to give the lexical entry associated with pro-nouns, and our fragment is complete.
This is given in (24).
(24) np(NP) - ->  \[her\],{ member(Space, NP:sem:in),member(NP:syn:index, Space),type(NP:syn:index,feminine),NP:sem:scope:in = NP:sem:in,NP:sem:out = NP:sem:scope:ont }.The first three equations require that there be some spacecontaining a reference marker of feminine type with which thepronoun's reference marker can unify: 9 the last two equationstake account of the fact that an anaphoric pronoun, while notadding any conditions of its own to the context, can appear insubject position, and thus can have a scope expression.We have now completely described our declarative formula-tion of DRS theory.
This formulation (together with phrasestructure rules that analyse a discourse as a series of sen-tences) suffices to obtain the analyses hown be low)  ?
(25) Every woman chased a donkey.DRS = \[\[w,woman(w)\]= =>\[chased(w,d) ,d,donkey(d)\]\](26) A woman chased a donkey.
Every boy saw her.DRS = l ib,boy(b)\]= >\ [saw(h ,w) \ ] ,\[d,donkey(d)\] = = > \[ehased(w ,d)\],w,woman(w)l9 The definition of member used here is the conventionalone used in Prolog (albeit interpreted by the PrAtt  inter-preter, while the type predicate is a set of clauses of the formtype(w,feminlne)., etc.l0 Note that because later elements are pushed onto thefront of a DR space, the order of the elements in the DRspaces is the reverse of their "normal" pr.~'~entation.
Thisdoes not affect their truth conditional semantics, however.674We have also implemented a more complex version of thisgrammar incorporating a treatment of unbounded ependen-cies, and obtained analyses like the following:(27) Every man who owns a donkey beats it.DRS = \[ \[man(m),owns(m,d),d,donkey(d),m\]= = > \[beats(re,d)\]\]Tile parser indicates i l l-formedness of its input in the standardProlog fashion, viz.
it fails to find a well-formed DRS for theinput sentence.
(28) A woman who loves every man kissed him.no6.
ConclusionThe declarative reformulation of DRS theory proposed here isrelatively faithful to Kamp's original formulation, but has theadvantage that it inherits a fully specified declarative and pro-cednral semantics from the underlying Prolog system.
Itemphasises tlle view that expressions of the language can beviewed as relations between preceding and following contexts,and shows how these relations can be specified in a formallyprecise way.This model opens up several important questions.
Kampshowed that the treatment of anaphorie dependencies, nor-mally viewed as a left to right phenomenon, can be integratedwith the treatment of the "conventional" truth-conditionalsemantics of clauses: we have shown that both of these can beintegrated into an extended unification-based model of gram-mar.
This integration allows one to be precise about thenature of the syntax/semantics/discourse interface(s), and alsoallows experimentation with respect o the analysis of specificlinguistic phenomena.
For example, in our larger grammar(not presented here) we capture strong and weak cross-overphenomena by introducing the reference marker associatedwith a relative clause NP when the corresponding ap isreached.
We are thus analysing what is usually thought of asa syntactic phenomenon in terms of the accessibility of refer-ence markers, a discourse property.From a computational point of view, there is a delicateinteraction between the specific rules adopted in declarativeformulation of the theory and the "power" of the inferenceprocedure needed to determine the well-formedness of a par-t itular utterance with respect o them.
The top-down left-to-right inference procedure inherited from Prolog suffices forthe grammar presented here, but one can easily write gram-mars in PrAtt  for which this inference procedure may fail toterminate.
We are investigating other inference procedures,such as Earley Deduction (Pereira and Warren 1983) and LeftCorner parsing to see if they have better termination proper-ties.
Essentially, the problem is one of arranging the equa-tions in the grammar to be applied in an order such that thesearch space is finite: thus research on various coroutiningstrategies, such as the use of the freeze predicate is relevanthere.7.
ReferencesBach, E. and Partce, B.
(1981) Anaphora and semanticstructure.
In Masek, C. S., Hendrick, R. A. andMiller, M. F.
(eds.)
Papers from the Parasession onLanguage and Behavior at the Seventeenth RegionalMeeting of the Chicago Linguistics Society, Chicago,May 1-2, 1981, ppl-28.Barwise, J. and Perry, J.
(1983) Situations and Attitudes.Cambridge, Mass.
: MIT Press.Fauconnier, G. (1985) Mental Spaces: Aspects of Meanb~gConstruction in Natural Language.
MIT.Haik, I.
(1984) Indirect Binding.
Linguistic Inquiry, 15, 185-223.Helm, I.
(1982) The Semantics of Definite and IndefiniteNoun Phrases.
PhD Thesis, University ofMassachusetts.
Distributed by Graduate LinguisticsStudent Association.Kamp, H. (1981) A Theory of Truth and SemanticRepresentation.
In Groenendijk, J.
A. G., Janssen, T.M.
V. and Stokhof, M. B. J.
(eds.)
Formal Methods inthe Study of Language, Volume 136, pp277-322.Amsterdam: Mathematical Centre Tracts.Klein, E. (1985) VP Ellipsis in DR Theory.
In Groenendijk,J.
and Stokhof, M.
(eds.)
Fifth Amsterdam Colloquium,Amsterdam, 1985.
To appear.Kowalski, R. A.
(1979) Logic for Problem Solving.Amsterdam: North Holland.Kowalski, R. (1979) Algorithm = Logic + Control.Communications of the ACM, 22, 424-436.Ladusaw, W. A.
(1980) Polarity Sensitivity as Inherent ScopeRelations.Pereira, F. C. N. and Warren, D. H. D. (1983) Parsing asDeduction.
In Proceedings of the 21st Annual Meeting ofthe Association for Computational Linguistics,Massachusetts Institute of Technology, Cambridge,Mass., June, 1983, pp137-144.Pereira, F. C. N. (1985) A Structure-Sharing Representationfor Unification-Based Grammar Formalisms.
InProceedings of the 23rd Annual Meeting of theAssociation for Computational Linguistics, University ofChicago, Chicago, Illinois, 8-12 July, 1985, pp137-144.Reiehman-Adar, R. (1984) Extended Person-MachineInterface.
Artificial Intelligence, 22, 157-218.Reinhart, T, (1981) Definite NP anaphora nd C-CommandDomains.
Linguistic Inquiry, 12,605-631.Reinhart, T. (1983) Coreference and bound anaphora: Arestatement of the anaphora questions.
Linguistics andPhilosophy, 6, 47-88.Roberts, C. (1984) Anaphora, eoreference and the bindingtheory.
Unpublished paper, University ofMassachusetts, Amherst.Stalnaker, R. C. (1972) Pragmatics.
In Davidson, D. andHarman, G.
(eds.)
Semantics of Natural Language,Synthese Library, pp380-397.
Dordrecht: D. Reidel.van Eijck, J.
(1985) Aspects of Quantification in NaturalLanguage.
PhD Thesis, University of Groniugeu.Unpublished PhD Thesis.Wcbber, B. L. (1979) A Formal Approach to DiscourseAnaphora.
London: Garland Publishing.675
