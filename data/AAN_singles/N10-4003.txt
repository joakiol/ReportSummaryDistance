Proceedings of the NAACL HLT 2010: Tutorial Abstracts, pages 5?6,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsNoisy Text AnalyticsL.
Venkata Subramaniam, IBM Research IndiaText produced in informal settings (email, blogs, tweet, SMS, chat) and text whichresults from processing (speech recognition, OCR, machine translation, historical text)is inherently noisy.
This tutorial will cover the efforts of the computational linguisticscommunity in moving beyond traditional techniques to contend with the noise.1.
OverviewText produced by processing signals intended for human use is often noisy forautomated computer processing.
Digital text produced in informal settings such asonline chat, SMS, emails, tweets, message boards, newsgroups, blogs, wikis and webpages contain considerable noise.
Also processing techniques like Automatic SpeechRecognition, Optical Character Recognition and Machine Translation introduceprocessing noise.
People are adept when it comes to pattern recognition tasks involvingtypeset or handwritten documents or recorded speech, machines less-so.Noise can manifest itself at the earliest stages of processing in the form of degradedinputs that our systems must be prepared to handle.
Many downstream applications usetechniques meant for clean text.
It is only recently that with the increase in noisy text,these techniques are being adapted to handle noisy text.
This tutorial will focus on theproblems encountered in analyzing such noisy text coming from various sources.
Noiseintroduces challenges that need special handling, either through new methods orimproved versions of existing ones.
For example, missing punctuation and the use ofnon-standard words can often hinder standard natural language processing techniquessuch as part-of-speech tagging and parsing.
Further downstream applications such asInformation Retrieval, Information Extraction and Text mining have to explicitly handlenoise in order to return useful results.
Often, depending on the application, the noisecan be modeled and it may be possible to develop specific strategies to immunize thesystem from the effects of noise and improve performance.
This tutorial will cover:* Various sources of noise and their characteristics as well as typical metrics used tomeasure noise.
* Methods to handle noise by moving beyond traditional natural language processingtechniques.
* Methods to overcome noise in specific applications like IR, IE, QA, MT, etc.2.
OutlineThe tutorial will have three parts:* What is Noiseo Detecting Noise5o Classifying Noiseo Quantifying Noise* Processing and/or Correcting Noiseo Spelling Correctiono Natural Language Processing of Noisy Text: Segmentation, Parsing, POSo Learning underlying language models in presence of noise* Effect of Noise on Downstream Applicationso Information Retrieval from Noisy Texto Information Extraction from Noisy Texto Classification of Noisy Texto Summarization of Noisy Texto Machine Translation of Noisy Text3.
Target AudienceThis tutorial is designed for students and researchers in Computer Science andComputational Linguistics.
Elementary knowledge of text processing is assumed.
Thistopic is expected to be of wide interest given its relevance to the computationallinguistics community.
Since noisy data is also the main theme of NAACL HLT 2010,good audience participation can be expected.4.
Speaker?s BioL Venkata Subramaniam manages the information processing and analytics group atIBM Research ?
India.
He received his PhD from IIT Delhi in 1999.
His research focuseson unstructured information management, statistical natural language processing, noisytext analytics, text and data mining, information theory, speech and image processing.He often teaches and guides student thesis at IIT Delhi on these topics.
He co foundedthe AND (Analytics for Noisy Unstructured Text Data) workshop series and also co-chaired the first three workshops, 2007-2009.
He was guest co-editor of two specialissues on Noisy Text Analytics in the International Journal of Document Analysis andRecognition in 2007 and 2009.6
