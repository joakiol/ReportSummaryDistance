Proceedings of the Second Workshop on Computational Linguistics for Literature, pages 32?40,Atlanta, Georgia, June 14, 2013. c?2013 Association for Computational LinguisticsThe desirability of a corpus of online book responsesPeter BootHuygens INGPO Box 907542509 HT The HagueThe  Netherlandspeter.boot@huygens.knaw.nlAbstractThis position paper argues the need for acomprehensive corpus of online book re-sponses.
Responses to books (in traditionalreviews, book blogs, on booksellers?
sites,etc.)
are important for understanding howreaders understand literature and how literaryworks become popular.
A sufficiently large,varied and representative corpus of online re-sponses to books will facilitate research intothese processes.
This corpus should includecontext information about the responses andshould remain open to additional material.Based on a pilot study for the creation of acorpus of Dutch online book response, thepaper shows how linguistic tools can finddifferences in word usage between responsesfrom various sites.
They can also reveal re-sponse type by clustering responses based onusage of either words or their POS-tags, andcan show the sentiments expressed in the re-sponses.
LSA-based similarity between bookfragments and response may be able to revealthe book fragments that most affected read-ers.
The paper argues that a corpus of bookresponses can be an important instrument forresearch into reading behavior, reader re-sponse, book reviewing and literary appre-ciation.1 IntroductionThe literary system does not consist of authorsand works alone.
It includes readers (or listeners)and their responses to literary works.
Researchinto reception is an important subfield of literarystudies (e.g.
Goldstein and Machor, 2008).
Sharedattention to stories may have evolved as way oflearning to understand others and to increasebonding (Boyd, 2009).
Discussing literature maythus be something that we are wired to do, andthat we do indeed wherever possible: today onAmazon, on weblogs, and on Twitter, and in ear-lier days in newspapers and letters.
These re-sponses to books are important both asdocumentation of the ways literary works are readand understood, and because they help determineworks?
short- and long-term success.This position paper argues that what we need,therefore, is a large and representative corpus ofbook responses.
?Book response?
in this paperincludes any opinion that responds to a book, i.e.traditional book reviews, book-based discussion,opinions given on booksellers?
sites, on Twitter,thoughtful blog posts, and the like.
The word?books?
here is meant to refer to all genres, in-cluding literature as well as more popular genressuch as fantasy, thrillers, comics, etc.
Section 2 ofthe paper discusses the importance and researchpotential of book responses.
Section 3 reviewsrelated research.
In section 4, I outline the proper-ties that this corpus should have.
Section 5 de-scribes a Dutch pilot corpus and shows someaspects of this corpus that lend themselves toanalysis with linguistic and stylometric tools.Section 6 presents conclusions and directions forfuture work.The author of this paper is not a computationallinguist, but has a background in literary studiesand digital humanities.
The intention is to create adialogue between literary studies and computa-tional linguistics about fruitful ways to investigatebook responses, their relations to the books they32respond to and their effects on short-term or long-term appreciation.2 Book responses and their importanceEvaluating books and talking about our responseis a very natural thing to do (Van Peer, 2008).
In aprofessionalized form, the discipline of literarycriticism has a long and distinguished tradition(Habib, 2005).
But ?ordinary?
readers too havealways talked about their reading experiences(Long, 2003; Rehberg Sedo, 2003).
The writtenoutput of these reflections and discussions hasbeen an important source for reading and recep-tion studies.
Proof of this importance is e.g.
theexistence of the Reading Experience Database(RED) that collects experiences of reading asdocumented in letters, memoirs and other historicmaterial (Crone et al 2011).
Halsey (2009) e.g.shows how this database can help study changesin stylistic preferences over time.One reason for the importance of written bookresponses is that they provide documentation ofhow works affect their readers: they show whatelements of the reading experience readers con-sider important enough to write down and sharewith friends and fellow-readers.
To some extent atleast this will be determined by the elements ofthe book that were most significant to the readerand that he or she is most likely to remember.Unlike in earlier historic periods, this sort of evi-dence today is plentiful and researchers shouldtake advantage of this.
Spontaneous written re-sponses to reading are not the only way of as-sessing the effects of (literary) reading.Experimental research (Miall, 2006) and otherapproaches have an important place.
Today?sonline book responses, however, are unique inthat they are produced spontaneously by ordinaryreaders and have an ecological validity that otherresearch data lack.
(Which does, of course, notimply we should take everything that people writeonline at face value).A second reason for the importance of writtenbook responses is that their role as (co-)deter-miners, or at least predictors, of literary success iswell-documented.
In the wake of a large body ofresearch on movie reviews (e.g.
Liu, 2006), thiswas established for reviews on booksellers?
sitesby (Chevalier and Mayzlin, 2006).
For traditional(newspaper) reviews, their effects on long-termsuccess (canonization) have been shown in e.g.
(Ekelund and B?rjesson, 2002; Rosengren, 1987).If reading responses are that important for thestudy of literature and its effects, it follows weneed to understand them better.
We need toolsthat can analyze their style, rhetorical structure,topics, and sentiment, and these tools should besensitive to the many different sorts of readers,responses and response sites that form part of thelandscape of online book discussion.
We alsoneed tools that can help us see relationships be-tween the responses and the works that they re-spond to, in terms of topics and narrative (whatcharacters and plot developments do reviewersrespond to), as well as at higher (cognitive, emo-tional and moral) levels.
An important step to-wards such tools is the creation of a representativecorpus that can provide a test bed for tool devel-opment.3 Related researchOnline book discussion is a wide field that can bestudied from many different angles.
I discuss firsta number of studies that do not use computationalmethods.
Online book reviewing has often beendiscussed negatively in its relation to traditionalreviews (McDonald, 2007; Pool, 2007).
Certainlyproblematic aspects of online reviews are thepossibilities of plagiarism and fraud (David andPinch, 2006).
Verboord (2010) uses a question-naire to investigate the perceived legitimacy ofinternet critics.
Online critics?
role in canonizationwas investigated in (Grafton, 2010).
That onlinereviews do have an influence on books sales wasestablished by (Chevalier and Mayzlin, 2006),and specifically for books by women and popularfiction in (Verboord, 2011).
Many librarians havelooked at what online book discussion sites canmean for the position of the library, library cata-loguing and book recommendations (Pera and Ng,2011; Pirmann, 2012).
Online book discussion asan extension of the reading group is discussed ine.g.
(Fister, 2005).
A look at the whole field, froma genre perspective, is given in (Boot, 2011).Steiner (2010) looks specifically at Swedish web-logs; (Steiner, 2008) discusses Amazon reviews,as does (Domsch, 2009).
Gutjahr (2002) sent outa survey to posters of Amazon reviews.
Finally,(Miller, 2011) investigates how book blogs can33help develop the habits of mind required for liter-ary reading.Researchers that have used more or less so-phisticated linguistic technology to investigateonline book responses have done so with a num-ber of different questions in mind.
(Boot et al2012) sought to characterize responses from dif-ferent site types based on word usage.
Much ef-fort has gone into the analysis of reviewsentiment, which has clear practical applicationsin marketing.
(Taboada et al 2011) use a lexicon-based approach; (Okanohara and Tsujii, 2005) amachine learning approach.
(De Smedt andDaelemans, 2012a) create a Dutch sentiment lexi-con based on reviews at an online bookseller.
Thehelpfulness of online reviews has been investigat-ed by e.g.
(Tsur and Rappoport, 2009) while(Mukherjee and Liu, 2012) have modeled reviewcomments.
From an information retrieval perspec-tive, the INEX social book search competition hasexplored the use of online reviews from Amazonand LibraryThing to create book recommenda-tions (Koolen et al 2012).
A proposal for usingtext mining and discourse analysis techniques onpre-internet reviews is (Taboada et al 2006).
(Finn, 2011) used named entity recognition inreviews of a single writer in order to explore the?ideational network?
associated with her work.It does not seem unfair to say that most of thecomputer-based linguistic research done intoonline book responses has been motivated bypractical, if not commercial aims.
Much of it waspublished in marketing journals.
Computationallinguistic research as a tool for understanding thevariety of online book response is still at a veryearly stage of development.4 A corpus of book responsesA corpus of book responses should present re-searchers with a varied, representative, and suffi-ciently large collection of book responses.
Itshould not be a closed corpus but continue togrow.
It should contain not just response texts butalso include the metadata that describes and con-textualizes the responses.Varied: the responses should be taken from aswide a selection of sites as is possible.
Sites arevery different with regards to the active review-ers, their audience, the books that are discussed,the responses?
function and the explicit and im-plicit expectations about what constitutes a properresponse (Boot, 2011).
Pragmatic aspects of theresponse (e.g.
a response given on a weblogwhere the responder is the main author vs. a re-sponse in a forum where the responder is just oneparticipant in a group discussion) obviously helpdetermine both content and style of the responseand tools that analyze responses should take ac-count of these differences in setting.Another respect in which variety is importantis book genre.
Much has been written about dif-ferences in book appreciation between e.g.
read-ers of popular fiction and ?high?
literature (VonHeydebrand and Winko, 1996).
A response cor-pus should present researchers with a large bodyof responses from readers of a wide selection ofgenres (popular fiction, literature, non-fiction,essays, poetry, etc.
), irrespective of its medium ofpublication (paper, e-book, online).Representative: there is no need for this corpusto be strictly proportional with respect to site typeor book genre.
Still, it is important for all typesand genres to be represented.
Given the need torequest permission from copyright holders, it willprobably be impossible to achieve a truly repre-sentative corpus.Sufficiently large: the required size of the cor-pus will depend on the sort of analysis that onetries to do.
It is clear that analysis that goes be-yond the collection level, e.g.
at the book genrelevel, or at the level of individual reviewers, willneed substantial amounts of text.
A rule of thumbmight be that collections should preferably con-tain more than a thousand responses and morethan a million words.Open: As new forms of computer-mediatedcommunication continue to evolve, the ways ofresponding to and talking about books will alsochange.
The corpus should facilitate research intothese changes, and be regularly updated with col-lections from new site types.Metadata: book response text acquires a largepart of its meaning from its context.
To facilitateresearch into many aspects of these responses it isimportant for the corpus to store informationabout that context.
That information should in-clude at least the site that the response was takenfrom, the response date, whatever can be knownabout the author of the response, and, if available,the book that the response responds to.
Figure1shows the relevant entities.34We will not discuss the data model in detail.Sites can contain multiple collections of respons-es, with different properties.
Some sites for in-stance contain both commissioned reviews anduser reviews.
Weblogs contains posts by the blogowner and responses to those posts.
Book themesites often carry review sections and discussionforums.
When analyzing a response, it is im-portant to be aware what section the responsebelongs to.
Book responses can also be written inresponse to other posts, be it in a discussion fo-rum, on Twitter, or on a book-based social net-working site.
Book responses can be tagged, andthe tags may carry valuable information aboutbook topics, book appreciation or other book in-formation.
Responses are written by persons,sometimes unknown, who may own a site (as withblogs) or be among many people active on a site,or perhaps on multiple sites.
Reviewers some-times write profile texts about themselves thatalso discuss their book preferences.
On some sites(book SNS?s, Twitter) reviewers may strike upfriendships or similar relationships.
Some sitesalso allow people to list the books they ownand/or their favorite books.
Finally, meaningfuluse of book level data will often require beingable to group multiple versions (manifestations)of the same work.Figure 1.
Book response corpus data modelFor most collections, extracting the informationcarried by the respective entities mentioned is nota trivial task.
Book shop review pages will proba-bly contain an ISBN somewhere near the review,but forums probably will not and a tweet with anISBN number is certainly unusual.
And even if aresponse is ostensibly about book A, it may verywell also discuss book B. Reviewer informationwill also be hard to obtain, as many reviews (e.g.on booksellers?
sites) are unsigned.5 Pilot studyFor a pilot study that explores the research poten-tial of online book response, I have been collect-ing Dutch-language book responses from anumber of sites.
The size of the pilot corpus andits subcollections is given in table 1.
The pilotcorpus contains responses from a number of web-logs, from online review magazine 8Weekly,book-based social network site watleesjij.nu(?whatareyoureading.now)?, book publicity, re-views  and user reviews from thriller site Crime-zone, a collection of print reviews (from multiplepapers and magazines) about Dutch novelist Ar-non Grunberg, print reviews from Dutch newspa-per NRC and publicity from the NRC web shop.The collection should be extended with responsesfrom other site types (e.g.
forums, twitter,bookseller reviews) other book genres (e.g.
fanta-sy, romance, poetry) and perhaps other text genres(e.g.
book news, interviews).Collection ArticlegenreRes-ponsecountWordcount(*1000)8weekly  review 2273 1512weblogs blog post  6952 3578watleesjij.nu user review 28037 2515crimezone book desc publicity 3698 462crimezone review review 3696 1622crimezone userrev user review 9163 1537grunberg print review 196 187NRC web shop publicity 1345 198NRC reviews print review 1226 1133Total 56586 12744Table 1.
Present composition of pilot corpus ofresponsesI have done a number of experiments in order toexplore the potential for computational linguisticanalysis of book responses.355.1 Measure response style and approachusing LIWCAs a first test, I investigated word usage in thebook responses using LIWC (Pennebaker et al2007; Zijlstra et al 2004).
Figure 2 shows theusage of first person pronouns on the respectivesite types.
The pattern conforms to what onewould expect: on the book SNS watleesjij.nu,where readers give personal opinions, ?I?
predom-inates, as it does in the Crimezone user reviews,and to a lesser extent in the weblogs.
In the com-missioned reviews both in print (NRC newspaperand Grunberg collection) and online (8Weekly)?we?
prevails, as reviewers have to maintain anobjective stance.
Interestingly, the Crimezonebook descriptions manage to avoid first personpronouns almost completely.Figure 2.
Normalized frequencies first person singularand first person plural pronounsFigure 3.
Positive and negative emotion word frequen-ciesA similar result appears when we chart positiveand negative emotion words (Figure 3).
Especial-ly positive emotions are often expressed on wat-leesjij.nu and in the Crimezone user reviews.
Inthis case the group of informal sites does not in-clude the weblogs, perhaps because the weblogsincluded in the pilot corpus are blogs at the intel-lectual end of the spectrum.
Also interesting is thehigh proportion of negative emotion in the Crime-zone book descriptions, perhaps because in thecase of thrillers emotions like fear and anxiety canfunction as recommendations.From these examples it is clear that word us-age on the respective sites shows meaningful var-iation that will profit from further research.Investigation into these patterns at the level ofindividual reviewers (e.g.
bloggers) should beginto show individual styles of responding to litera-ture.5.2 Site stylistic similaritiesAs a second test, I looked into writing style, ask-ing whether the styles on the respective sites aresufficiently recognizable to allow meaningfulclustering.
For each of the collections, except forthe weblogs, I created five files of 20000 wordseach and used the tools for computational stylom-etry described in (Eder and Rybicki, 2011) toderive a clustering, based on the 300 most fre-quent words.
Figure 4 shows the results.It is interesting to note that all except the wat-leesjij.nu (book SNS) samples are stylisticallyconsistent enough to be clustered by themselves.It is even more interesting to note that the bookdescriptions from the NRC (newspaper) shopcluster with the descriptions taken from theCrimezone site, that the reviews in online maga-zine 8Weekly cluster with the printed reviews,and that the Crimezone reviews, commissionedand user-contributed, cluster with the wat-leesjij.nu reviews.
This may be related to the factthat there are a large number of thriller aficiona-dos on watleesjij.nu, or to Crimezone reviewsbeing significantly different from traditional re-views.
Again, this seems a fruitful area for furtherinvestigation, only possible in the context of alarge corpus containing different text types.In order to exclude the possibility that thisclustering is based on content words (e.g.
wordsrelated to crime), I repeated the experiment usingbi-grams of the words?
POS-tags, as derived bythe Pattern toolset (De Smedt and Daelemans,2012b).
The resulting figure, not reproduced here,is very similar to Figure 4.
This result leads toanother question: what sort of syntactic construc-0123456negemoposemo36tions are specific to which site types?
And can weconnect these stylistic differences to the approachto literature that these sites take?Figure 4.
Clustering of 20000-word review texts basedon 300 most frequent words.5.3 Response sentiment analysisIn a third experiment, I applied the sentimentlexicon embedded in the Pattern toolset to theresponses in those collections that include ratings.I predict a positive rating (i.e.
above or equal tothe collection median) when the sentiment asmeasured by Pattern is above 0.1, and computeprecision, recall and F1-value for this prediction(see Figure 5).
Results on the book SNS wat-leesjij.nu are similar to the results reported by (DeSmedt and Daelemans, 2012a) for reviews frombookseller bol.com, perhaps because the respons-es on the two sites are similar.
As expected, theresults are considerably worse for the longer re-views on 8Weekly and NRC.
That precisionshould be as high as .84 for the Crimezone re-views is somewhat of a mystery.While it is not unexpected that the sentimentprediction quality should be higher for the siteswith simpler reviews, this does imply a challengefor researchers of sentiment analysis.
Withoutaccurately gauging response sentiment (and manyother response properties) measuring literary im-pact from responses will remain illusory.Figure 5.
Prediction of positive or negative rating:precision, recall and F-score5.4 Semantic similarities between bookfragments and responsesA final experiment is based on the assumptionthat the semantics of book response texts to someextent reflect the semantics of the books theyrespond to.
If that is true, it should be possible todetermine the chapters that most impressed read-ers by comparing the book?s and the reviews?semantic content.
In order to test the assumption,I used Latent Semantic Analysis (LSA) (Landaueret al 2007; ?eh?
?ek and Sojka, 2010) to measurethe distances between 400-word fragments takenfrom the novel Tirza by Dutch novelist ArnonGrunberg and 60 reviews of the book taken frombook SNS watleesjij.nu.
In order to compensatefor potential similarities between book fragmentsand any reviews, rather than with reviews specifi-cally of this book, I also measured semantic dis-tances between the book?s fragments and a set ofrandom reviews from the same site, and subtract-ed those from the distances with the Tirza re-views.
In order to test how these distances relate0,50,60,70,80,9PRF37to the book?s content, I computed LIWC scoresfor the fragments and then correlations betweenthese LIWC scores and the LSA distances.
Fore.g.
LIWC category ?family?, a very importantsubject for this book, the correlation is positiveand highly significant (.34, p< .0001).Further experimentation with other books, oth-er review collections and other LSA models isclearly needed.
It is too early to say whether LSAindeed offers a viable approach for determiningthe book fragments most closely related to reviewtexts, but this is clearly a promising result.
Beingable to connect measurable aspects of books withimpact in reviews would help us understand howbooks affect their readers.6 ConclusionThis paper adopts a broad conception of the ob-ject of literary studies, taking it to include theindividual and social responses that literatureelicits.
I argued here that the (plentifully availa-ble) online book responses are important to liter-ary studies, both as evidence (because theydocument the reception of literary works) and asobjects (because they help determine works?
shortand long term popularity).
If only because of thenumbers of these responses, we need computa-tional linguistic tools in order to analyze and un-derstand them.
Because the responses publishedon the various response platforms are in manyrespects very different, potential tools would needto be developed with these differences in mind.
Agood way to ensure this is to create an appropri-ately large and representative corpus of onlinebook response.
On the basis of a Dutch pilot cor-pus we saw that existing linguistic tools can re-veal some of the differences between therespective platforms.
They are currently unable,however, to perform any deeper analysis of thesedifferences, let ale a deeper analysis of the rela-tions between responses and books.Naturally, written book response can only in-form us about the reading experience of those thattake the trouble of writing down and publishingtheir response.
Even though those who providebook response are by no means a homogeneousgroup, it is clear that the proposed corpus wouldnecessarily be selective, and should not be ouronly method of studying reader response.
This isless of an issue when studying how books becomepopular and eventually canonized, as those whodon?t participate in the discussions will, for thatvery reason, be less influential.With these caveats, there are a number of areasthat a corpus of online book response would helpinvestigate.
Among these are:?
the responses themselves and their respectiveplatforms: what language is used, what topicsare discussed, what is their structure?
Whatdo they reveal about the literary norms that(groups of) readers apply??
the relations between responses: we should beable to answer the questions about influence.What sort of discussions are going on aboutliterature on which platforms?
Which partici-pants are most influential?
Can responsestyles reveal these influences??
what the responses show about the readingexperience: we?d like to know how books(both books in general and specific books) af-fect people, what attracts people in books,what they remember from books, what theylike about them, etc.
What passages do theyquote from the books they respond to?
Whatcharacteristic words do they adopt??
what the responses show about readers: as thecorpus should facilitate selection by respond-er, we should be able to investigate the role ofthe reader in book response.
Do responders?writing styles predict their ratings?
Do peoplewho like, say, James Joyce dislike science fic-tion?
And can their book responses tell uswhy?Many of these phenomena are interesting at mul-tiple levels.
They are interesting at the level of theindividual reader, for whom reading in generaland specific books are important.
They are inter-esting at a sociological level, as discussions helpdetermine books?
popularity or even canonization.Finally, at the level of the book, study of bookresponses can show what readers, individuallyand in groups, take away from a book.
In thisrespect especially, study of book responses is anecessary complement to study of the literarytext.38ReferencesBoot, Peter.
2011.
Towards a Genre Analysis of OnlineBook Discussion: socializing, participationand publication in the Dutch booksphere.Selected Papers of Internet Research IR 12.0.Boot, Peter, Van Erp, Marieke, Aroyo, Lora, andSchreiber, Guus.
2012.
The changing face ofthe book review.
Paper presented at WebScience 2012, Evanston (IL).Boyd, Brian.
2009.
On the origin of stories: Evolution,cognition, and fiction.
Cambridge MA:Harvard University Press.Chevalier, Judith A., and Mayzlin, Dina.
2006.
Theeffect of word of mouth on sales: Online bookreviews.
Journal of Marketing Research43:345-354.Crone, Rosalind, Halsey, Katry, Hammond, Mary, andTowheed, Shafquat.
2011.
The ReadingExperience Database 1450-1945 (RED).
InThe history of reading.
A reader, eds.Shafquat Towheed, Rosalind Crone and KatryHalsey, 427-436.
Oxon: Routledge.David, Shay, and Pinch, Trevor.
2006.
Six degrees ofreputation: The use and abuse of onlinereview and recommendation systems.
FirstMonday 11.De Smedt, Tom, and Daelemans, Walter.
2012a.
?Vreselijk mooi!?
(terribly beautiful): ASubjectivity Lexicon for Dutch Adjectives.Paper presented at Proceedings of the 8thLanguage Resources and EvaluationConference (LREC?12).De Smedt, Tom, and Daelemans, Walter.
2012b.Pattern for Python.
The Journal of MachineLearning Research 13:2031-2035.Domsch, Sebastian.
2009.
Critical genres.
Genericchanges of literary criticism in computer-mediated communication.
In Genres in theInternet: issues in the theory of genre, eds.Janet Giltrow and Dieter Stein, 221-238.Amsterdam: John Benjamins PublishingCompany.Eder, Maciej, and Rybicki, Jan. 2011.
Stylometry withR.
In Digital Humanities 2011: ConferenceAbstracts, 308-311.
Stanford University,Stanford, CA.Ekelund, B. G., and B?rjesson, M. 2002.
The shape ofthe literary career: An analysis of publishingtrajectories.
Poetics 30:341-364.Finn, Edward F. 2011.
The Social Lives of Books:Literary Networks in Contemporary AmericanFiction, Stanford University: PhD.Fister, Barbara.
2005.
Reading as a contact sport.Reference & User Services Quarterly 44:303-309.Goldstein, Philip, and Machor, James L. 2008.
Newdirections in American reception study.
NewYork: Oxford University Press, USA.Grafton, Kathryn.
2010.
Paying attention to publicreaders of Canadian literature: popular genresystems, publics, and canons, University ofBritish Columbia: PhD.Gutjahr, Paul C. 2002.
No Longer Left Behind:Amazon.com, Reader-Response, and theChanging Fortunes of the Christian Novel inAmerica.
Book History 5:209-236.Habib, M. A. R. 2005.
A history of literary criticism:from Plato to the present.
Malden, MA:Blackwell.Halsey, Katie.
2009.
?Folk stylistics?
and the history ofreading: a discussion of method.
Languageand Literature 18:231-246.Koolen, Marijn, Kamps, Jaap, and Kazai, Gabriella.2012.
Social Book Search: ComparingTopical Relevance Judgements and BookSuggestions for Evaluation.
In CIKM?12,October 29?November 2, 2012.
Maui, HI,USA.Landauer, T. K., McNamara, D. S., Dennis, S., andKintsch, W. 2007.
Handbook of latentsemantic analysis: Lawrence Erlbaum.Liu, Yong.
2006.
Word of Mouth for Movies: ItsDynamics and Impact on Box OfficeRevenue.
Journal of Marketing 70:74-89.Long, Elizabeth.
2003.
Book clubs: Women and theuses of reading in everyday life.
Chicago:University of Chicago Press.McDonald, R?n?n.
2007.
The death of the critic.London, New York: Continuum InternationalPublishing Group.Miall, David S. 2006.
Literary reading: empirical &theoretical studies.
New York: Peter LangPublishing.Miller, Donna L. 2011.
Talking with Our Fingertips:An Analysis for Habits of Mind in Blogsabout Young Adult Books, Arizona StateUniversity: PhD.Mukherjee, Arjun, and Liu, Bing.
2012.
ModelingReview Comments.
In Proceedings of 50thAnunal Meeting of Association forComputational Linguistics (ACL-2012).
Jeju(Korea).Okanohara, Daisuke, and Tsujii, Jun?ichi.
2005.Assigning polarity scores to reviews usingmachine learning techniques.
NaturalLanguage Processing?IJCNLP 2005:314-325.Pennebaker, J. W., Booth, R. J., and Francis, M. E.2007.
Linguistic Inquiry and Word Count(LIWC2007).
Austin, TX.Pera, Maria Soledad, and Ng, Yiu-Kai.
2011.
With aLittle Help from My Friends: Generating39Personalized Book Recommendations UsingData Extracted from a Social Website.
Paperpresented at Web Intelligence and IntelligentAgent Technology (WI-IAT), 2011.Pirmann, Carrie.
2012.
Tags in the Catalogue: InsightsFrom a Usability Study of LibraryThing forLibraries.
Library Trends 61:234-247.Pool, Gail.
2007.
Faint praise: the plight of bookreviewing in America.
Columbia, MO:University of Missouri Press.Rehberg Sedo, DeNel.
2003.
Readers in ReadingGroups.
An Online Survey of Face-to-Faceand Virtual Book Clubs.
Convergence 9:66-90.?eh?
?ek, Radim, and Sojka, Petr.
2010.
Softwareframework for topic modelling with largecorpora.
Paper presented at Proceedings ofLREC 2010 workshop New Challenges forNLP Frameworks, Valletta, Malta.Rosengren, Karl Erik.
1987.
Literary criticism: Futureinvented.
Poetics 16:295-325.Steiner, Ann.
2008.
Private Criticism in the PublicSpace: Personal writing on literature inreaders' reviews on Amazon.
Participations 5.Steiner, Ann.
2010.
Personal Readings and PublicTexts: Book Blogs and Online Writing aboutLiterature.
Culture unbound 2:471-494.Taboada, Maite, Gillies, Mary Ann, and McFetridge,Paul.
2006.
Sentiment ClassificationTechniques for Tracking Literary Reputation.In Proceedings of LREC 2006 Workshop?Towards Computational Models of LiteraryAnalysis?.Taboada, Maite, Brooke, Julian, Tofiloski, Milan, Voll,Kimberly, and Stede, Manfred.
2011.Lexicon-based methods for sentimentanalysis.
Computational Linguistics 37:267-307.Tsur, Oren, and Rappoport, Ari.
2009.
Revrank: Afully unsupervised algorithm for selecting themost helpful book reviews.
Paper presented atInternational AAAI Conference on Weblogsand Social Media.Van Peer, Willie.
2008.
Introduction.
In The quality ofliterature: linguistic studies in literaryevaluation, 1-14.
Amsterdam: JohnBenjamins Publishing Co.Verboord, Marc.
2010.
The Legitimacy of Book Criticsin the Age of the Internet andOmnivorousness: Expert Critics, InternetCritics and Peer Critics in Flanders and theNetherlands.
European Sociological Review26:623-637.Verboord, Marc.
2011.
Cultural products go online:Comparing the internet and print media ondistributions of gender, genre and commercialsuccess.
Communications 36:441-462.Von Heydebrand, Renate, and Winko, Simone.
1996.Einf?hrung in die Wertung von Literatur:Systematik, Geschichte, Legitimation.Paderborn: Sch?ningh.Zijlstra, Hanna, van Meerveld, Tanja, van Middendorp,Henri?t, Pennebaker, James W., and Geenen,Rinie.
2004.
De Nederlandse versie van de?Linguistic Inquiry and Word Count?
(LIWC).Gedrag & Gezondheid 32:271-281.40
