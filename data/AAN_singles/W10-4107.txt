Reducing the False Alarm Rate of Chinese Character Error Detectionand CorrectionShih-Hung Wu, Yong-Zhi ChenChaoyang University of Technol-ogy, Taichung Countryshwu@cyut.edu.twPing-che Yang, Tsun KuInstitute for information industry,Taipei Citymaciaclark@iii.org.tw,cujing@iii.org.twChao-Lin LiuNational Chengchi Universi-ty, Taipei Citychaolin@nccu.edu.twAbstractThe main drawback of previous Chinese cha-racter error detection systems is the high falsealarm rate.
To solve this problem, we proposea system that combines a statistic method andtemplate matching to detect Chinese charactererrors.
Error types include pronunciation-related errors and form-related errors.
Possibleerrors of a character can be collected to form aconfusion set.
Our system automatically gene-rates templates with the help of a dictionaryand confusion sets.
The templates can be usedto detect and correct errors in essays.
In thispaper, we compare three methods proposed inprevious works.
The experiment results showthat our system can reduce the false alarm sig-nificantly and give the best performance on f-score.1 IntroductionSince many Chinese characters have similar formsand similar or identical pronunciation, improperlyused characters in Chinese essays are hard to be de-tectted.
Previous works collected these hard-to-distinguish characters and used them to form confu-sion sets.
Confusion sets are critical for detecting andcorrecting improperly used Chinese characters.
Aconfusion set of a Chinese character consists of cha-racters with similar pronunciation, similar forms, andsimilar meaning.
Most Chinese character detectionsystems were built based on confusion sets and a lan-guage model.
Ren et.al proposed a rule-based methodthat was also integrated with a language model todetect character errors in Chinese (Ren, Shi, & Zhou,1994).
Chang used confusion sets to represent allpossible errors to reduce the amount of computation.A language model was also used to make decisions.The confusion sets were edited manually.
Zhang et alproposed a way to automatically generate confusionsets based on the Wubi input method (Zhang, Zhou,Huang, & Sun, 2000).
The basic assumption was thatcharacters with similar input sequences must havesimilar forms.
Therefore, by replacing one code in theinput sequence of a certain character, the systemcould generate characters with similar forms.
In thefollowing work, Zhang et al designed a Chinese cha-racter detection system based on the confusion sets(Zhang, Zhou, Huang, & Lu, 2000).
Another inputmethod was also used to generate confusion sets.
Linet al used the Cangjie input method to generate con-fusion sets (Lin, Huang, & Yu, 2002).
The basic as-sumption was the same.
By replacing one code in theinput sequence of a certain character, the systemcould generate characters with similar forms.
Sincethe two input methods have totally different represen-tations of the same character, the confusion set of anygiven character will be completely different.In recent years, new systems have been incorporat-ing more NLP technology for Chinese character errordetection.
Huang et al proposed that a word segmen-tation tool can be used to detect character error inChinese (Huang, Wu, & Chang, 2007).
They used anew word detection function in the CKIP word seg-mentation toolkit to detect error candidates (CKIP,1999).
With the help of a dictionary and confusion set,the system can decide whether a new word is a cha-racter error or not.
Hung et al proposed a system thatcan detect character errors in student essays and thensuggest corrections (Hung & Wu, 2008).
The systemwas based on common error templates which weremanually edited.
The precision of this system is thehighest, but the recall remains average.
The maindrawback of this approach is the cost of editing com-mon error templates.
Chen et al proposed an automat-ic method for common error template generation(Chen, Wu, Lu, & Ku, 2009).
The common errorswere collected from a large corpus automatically.
Thetemplate is a short phrase with one error in it.
Theassumption is the frequency of a correct phrase mustbe higher than the frequency of the correspondingtemplate, with one error character.
Therefore, a statis-tical test can be used to decide weather there is acommon error or not.The main drawback of previous systems is the highfalse alarm rate.
The drawback is found by comparingthe systems with sentences without errors.
As we willshow in our experiments, the systems in previousworks tent to report more errors in an essay than thereal ones, thus, cause false alarms.In this paper, we will further improve upon theChinese character checker using a new error modeland a simplified common error template generationmethod.
The idea of error model is adopted from thenoise channel model, which is used in many naturallanguage processing applications, but never on Chi-nese character error detection.
With the help of errormodel, we can treat the error detection problem as akind of translation, where a sentence with errors canbe translated into a sentence without errors.
The sim-plified template generation is based on given confu-sion sets and a lexicon.The paper is organized as follows.
We introducebriefly the methods in previous works in section 2.Section 3 reports the necessary language resourcesused to build such systems.
Our approach is describedin section 4.
In section 5, we report the experimentsettings and results of our system, as well as give thecomparison of our system to the three previous sys-tems.
Finally, we give the conclusions in the finalsection.2 Previous worksIn this paper, we compare our method to previousworks.
Since they are all not open source systems, wewill reconstruct the systems proposed by Chang(1995), Lin, Huang, & Yu (2002), and Huang, Wu, &Chang (2007).
We cannot compare our system to thesystem proposed by Zhang, Zhou, Huang, & Sun(2000), since the rule-based system is not available.We describe the systems below.Chang?s system (1995) consists of five steps.
First,the system segments the input article into sentences.Second, each character in the sentence is replaced bythe characters in the corresponding confusion set.Third, the probability of a sentence is calculated ac-cording to a bi-gram language model.
Fourth, theprobability of the sentences before and after replace-ment is compared.
If the replacement causes a higherprobability, then the replacement is treated as a cor-rection of a character error.
Finally, the results areoutputted.
There are 2480 confusion sets used in thissystem.
Each confusion set consists of one to eightcharacters with similar forms or similar pronunciation.The system uses OCR results to collect characterswith similar forms.
The average size of the confusionsets was less than two.
The language model was builtfrom a 4.7 million character news corpus.The system proposed by Lin, Huang, & Yu (2002)has two limitations.
First, there is only one spellingerror in one sentence.
Second, the error was caused bythe Cangjie input method.
The system also has fivesteps.
First, sentences are inputted.
Second, a search ismade of the characters in a sentence that have similarinput sequences.
Third, a language model is used todetermine whether the replacement improves theprobability of the sentence or not.
Fourth, the threesteps for all input sentences are repeated.
Finally, theresults are outputted.
The confusion sets of this sys-tem were constructed from the Cangjie input method.Similarity of characters in a confusion set is rankedaccording to the similarity of input sequences.
Thelanguage model was built from a 59 million byte newscorpus.The system by Huang, Wu, & Chang (2007) con-sists of six steps.
First, the input sentences are seg-mented into words according to the CKIP word seg-mentation toolkit.
Second, each of the characters inthe new words is replaced by the characters in theconfusion sets.
Third, a word after replacementchecked in the dictionary.
Fourth, a language model isused to assess the replacement.
Fifth, the probabilityof the sentence before and after replacement is com-pared.
Finally, the result with the highest probabilityis outputted.
The confusion set in this system, whichalso consists of characters with similar forms or simi-lar pronunciation, was edited manually.Since the test data in the papers were all differenttest sets, it is improper to compare their results direct-ly, therefore; there was no comparison available in theliterature on this problem.
To compare these systemswith our method, we used a fixed dictionary, inde-pendently constructed confusion sets, and a fixed lan-guage model to reconstruct the systems.
We per-formed tests on the same test set.3 Data in Experiments3.1 Confusion setsConfusion sets are a collection of sets for each indi-vidual Chinese character.
A confusion set of a certaincharacter consists of phonologically or logographical-ly similar characters.
For example, the confusion setof ???
might consist of the following characters withthe same pronunciation?????????
or withsimilar forms??????????????????????.
In this study, we use the confusion setsused by Liu, Tien, Lai, Chuang, & Wu (2009).
Thesimilar Cangjie (SC1 and SC2) sets of similar forms,and both the same-sound-same-tone (SSST) andsame-sound-different-tone (SSDT) sets for similarpronunciation were used in the experiments.
Therewere 5401 confusion sets for each of the 5401 highfrequency characters.
The size of each confusion setwas one to twenty characters.
The characters in eachconfusion set were ranked according to Google searchresults.3.2 Language modelSince there is no large corpus of student essays, weused a news corpus to train the language model.
Thesize of the news corpus is 1.5 GB, which consists of1,278,787 news articles published between 1998 and2001.
The n-gram language model was adopted tocalculate the probability of a sentence p(S).
The gen-eral n-gram formula is:)|()( 1 1?+?= n Nnn wwpSp    (1)Where N was set to two for bigram and N was set toone for unigram.
The Maximum Likelihood Estima-tion (MLE) was used to train the n-gram model.
Weadopted the interpolated Kneser-Ney smoothing me-thod as suggested by Chen & Goodman (1996).
Asfollowing:)()1()|()|(11intwpwwpwwpunigramibigramierpolate??
?+= ??
(2)To determine whether a replacement is good or not,our system use the modified perplexity:NSpPerplexity /))(log(2?=   (3)Where N is the length of a sentence and p(S) is the bi-gram probability of a sentence after smoothing.3.3 Dictionary and test setWe used a free online dictionary provided by Tai-wan?s Ministry of Education, MOE (2007).
We fil-tered out one character words and used the remaining139,976 words which were more than one character asour lexicon in the following experiments.The corpus is 5,889 student essays collected from aprimary high school.
The students were 13 to 15 yearsold.
The essays were checked by teachers manually,and all the errors were identified and corrected.
Sinceour algorithm needed a training set, we divided theessays into two sets to test our method.
The statisticsis given in Table 1.
There are less than two errors inan essay on average.
We find that most (about 97%)of characters in the essays were among the 5,401 mostcommon characters, and most errors were charactersof similar forms or pronunciation.
Therefore, the5,401 confusion sets constructed according to formand pronunciation were suitable for error detection.Table 2 shows the error types of errors in students?essays.
More than 70% errors are characters withsimilar pronunciation, 40% errors are characters withsimilar form, and there are 20% errors are characterswith both similar pronunciation and similar form.Only 10% errors are in other types.
Therefore, in thisstudy, our system aimed to identify and correct theerrors of the two common types.Table 1.
Training set and test set statistics# of EssaysAveragelengthof essayAverage# oferrors% ofcommoncharactersTrainingset 5085 403.18 1.76 96.69%Test set 804 387.08 1.2 97.11%Table 2.
Error type analysisSimilar form Similar pronunciation Both OtherTraining set 41.54% 72.60% 24.24% 10.10%Test set 40.36% 76.98% 27.66% 10.30%4 System Architecture4.1 System flowchartFigure 1 shows the flowchart of our system.
First, theinput essays are segmented into words.
Second, thewords are sent to two different error detection mod-ules.
The first one is the template module, which candetect character errors based on the stored templatesas in the system proposed by Chen, Wu, Lu, & Ku,(2009).
The second module is the new language mod-el module, which treats error detection as a kind oftranslation.
Third, the results of the two modules canbe merged to get a better system result.
The detailswill be described in the following subsections.Figure 1.
System flowchart4.2 Word segmentationThe first step in our system uses word segmentation tofind possible errors.
In this study, we do not use theCKIP word segmentation tool (CKIP, 1999) as Huang,Wu, & Chang (2007) did, since it has a mergealgorithm that might merge error charactersto formnew words (Ma & Chen, 2003).
We use a backwardlongest first approach to build our system.
The lex-icon is taken from an online dictionary (MOE, 2007).We consider an input sentence with an error, ???????????????
?, as an example.
Thesentence will be segmented into ??|??|??|???|?|?|?|?|???.
The sequence of singlecharacters will be our focus.
In this case, it is ??????.
These kinds of sequences will be the output ofthe first step and will be sent to the following twomodules.
The error character can be identified andcorrected by a ????-????
template.4.3 Template ModuleThe template module in this study is a simplified ver-sion of a module from a previous work (Chen, Wu,Lu, & Ku, 2009), which collects templates from acorpus.
The simplified approach replaces onecharacter of each word in a dictionary with onecharacter in the corresponding confusion set.
Forexample, a correct word ????
might be written withan error character ????
since ??(bian4)?
is in theconfusion set of ??(ban4)??.
This method generatesall possible error words with the help of confusionsets.
Once the error template ????
is matched in anessay, our system can conclude that the character is anerror and make a suggestion on correction ???
?based on the ????-????
template.4.4 Translate moduleTo improve the n-gram language model method, weuse a statistical machine translation formula (Brown,1993) as a new way to detect character error.
We treatthe sentences with/without errors as a kind of transla-tion.
Given a sentence S that might have charactererrors in the sentence in the source language, the out-put sentence C~is the sentence in the target languagewith the highest probability of different replacementsC.
The replacement of each character is treated as atranslation without alignment.
)|(maxarg~SCpCc=   (4)From the Bayesian rule and when the fixed value ofp(w) is ignored, this equation can be rewritten as (5):)()|(maxarg)()()|(maxarg~CpCSpSpCpCSpCcc?=(5)The formula is known as noisy channel model.
Wecall p(S|C) an ?error model?, that is,  the probabilitywhich a character can be incorrect.
It can be definedas the product of the error probability of each charac-ter in the sentence.
?==nijiij cspCWp1)|()|(    (6)where n is the length of the sentence S, and si ith cha-racter of input sentence S. Cj is the jth replacementand cij.is the ith character at the jth replacement.
Theerror model was built from the training set of studentessays.
Where p(C) is the n-gram language model aswas described in section 3.2.
Note that the number ofreplacements is not fixed, since the number of re-placements depends on the size of all possible errorsin the training set.For example, consider a segmented sentence withan error: ??|??|?|?|?|??
?, we will use theerror model to evaluate the replacement of each cha-racter in the subsequence: ?????.
Here p(?|?
)and p(?|?)
are 0.0456902 and 0.025729 respective-ly, which are estimated according to the training cor-pus.
And in training corpus, no one write the character?, therefore, there is no any replacement.
Therefore,the probability of our error model and the n-gram lan-guage model can be shown in the following table.
Oursystem then multiplies the two probabilities and getsthe perplexity of each replacement.
The replacement?????
gets the lowest perplexity, therefore, it isthe output of our system and is both a correct errordetection and correction.Table 3.
An example of calculating perplexityaccording the new error modelError Model LM multiply Perplexity???
0.025728988 1.88E-05 4.83E-07 127.442812???
0.001175563 1.05E-04 1.24E-07 200.716961???
1 2.09E-09 2.09E-09 782.669809???
0.045690212 1.17E-08 5.34E-10 1232.67144.5 Merge correctionsSince the two modules detect errors using an inde-pendent information source, we can combine the deci-sions of the two modules to get a higher precision or ahigher recall on the detection and correction of errors.We designed two working modes, the Precision Mode(PM) and the Detection Mode (DM).
The output ofPM is the intersection of the output of the templatemodule and translation module, while the output ofDM is the union of the two modules.5 Experiment Settings and ResultsSince there is no open source system in previousworks and the data in use is not available, we repro-duced the systems with the same dictionary, the sameconfusion set, and the same language model.
Then weperformed a test on the same test set.
Since the confu-sion sets are quite large, to reduce the number ofcombinations during the experiment, the size must belimited.
Since Liu?s experiments show that it takesabout 3 candidates to find the correct character, weuse the top 1 to top 10 similar characters as the candi-dates only in our experiments.
That is, we take 1 to 10characters from each of the SC1, SC2, SSST, andSSDT sets.
Thus, the size of each confusion set islimited to 4 for the top 1 mode and 40 for the top 10mode.The evaluation metrics is the same as Chang?s(1995).
We also define the precision rate, detectionrate, and correction rate as follows:Precision = C / B * 100%  (7)Detection = C / A * 100%  (8)Correction = D / A * 100%  (9)where A is the number of all spelling errors, B isthe number of errors detected by be system, C is thenumber of errors detected correctly by the system, andD is the number of spelling errors that is detected andcorrected.
Note that some errors can be detected butcannot be corrected.
Since the correction is more im-portant in an error detection and correction system,we define the corresponding f-score as:CorrectionPrecisionCorrection*Precision*2scoreF +=?
(10)Figure 2.
The comparison of different methods onfull test set5.1 Results of our initial systemTable 4 shows the initial results of the template mod-ule (TM), the translation module (LMM) and thecombined results of the precision mode (PM) anddetection mode (DM).
We find that the precisionmode gets the highest precision and f-score, while thedetection mode gets the highest correction rate, asexpected.
The precision and detection rate improveddramatically.
The precision improved from 14.28% to61.68% for the best setting and to 58.82% for the bestf-score setting.
The detection rate improved from58.06% to around 72%.
The f-score improved from22.28% to 43.80%.
The result shows that combiningtwo independent methods yield better performancethan each single method does.5.2 Results of our system when more know-ledge and enlarged training sets are addedThe templates used in the initial system were the sim-plified automatic generated templates, as described insection 4.3.
Since there were many manually editedtemplates in previous works, we added the 6,701 ma-nually edited templates and the automatically generat-ed templates into our system.
The results are shown inTable 5.
All the performance increased for both thetemplate module and the translation module.
The bestf-score increased from 43.80% to 45.03%.
We believethat more knowledge will increase the performance ofour system.5.3 Results of methods in previous worksWe compared the performance of our method to themethods in previous works.
The result is shown inTable 6.
Chang?s method has the highest detectionrate, at 91.79%.
Note that the price of this high detec-tion rate is the high false alarm.
The correspondingprecision is only 0.94%.
The precision mode in ourmethod has the highest precision, correction, and f-score.
The comparison is shown in Figure 2.
The ho-rizontal axis is the size of confusion sets in our expe-riment.
We can find that the performances converge.That is, the size of confusion sets is large enough todetect and correct errors in students?
essays.5.4 Comparison to methods in previous worksrelated to sentences with errorsThe numbers in Table 6 are much lower than that inthe original paper.
The reason is the false alarms insentences without any errors, since most previousworks tested their systems on sentences with errorsonly.
In addition, our test set was built on real essays,and there were only one or two errors in an essay.Most of the sentences contained no errors.
The pre-vious methods tend to raise false alarms.To clarify this point, we designed the last experimentto test the methods on sentences with at least one er-ror.
We extracted 949 sentences from our test set.Among them, 883 sentences have one error, 61 sen-tences have two errors, 2 sentences have three errors,0%10%20%30%40%50%60%70%1 2 3 4 5 6 7 8 9 10Top N of Confusion setsPrecisionChang Lin Huang PM DM10%20%30%40%50%60%70%80%90%100%1 2 3 4 5 6 7 8 9 10Top N of Confusion setsDetection0%10%20%30%40%50%60%70%1 2 3 4 5 6 7 8 9 10Top N of Confusion setsCorrection0%5%10%15%20%25%30%35%40%45%50%1 2 3 4 5 6 7 8 9 10Top N of Confusion setsF-Scoreand 3 sentences that have four errors.
The result isshown in Table 7.
All the methods have better per-formance.
The precision of Chang?s method rose from3% to 43%.
The precision of Lin?s method rose from3.5% to 61%.
The precision of Huang?s method rosefrom 27% to 84%, while PM?s precision rose from60% to 97% and DM?s precision rose from 7% to62%.
The detection mode of our system still has thehighest f-score.The differences of performances in Table 7 and Table6 show that, systems in previous works tent to havefalse alarms in sentences without errors.5.5 Processing time comparisonProcessing complexity was not discussed in previousworks.
Since all the systems require different re-sources, it is hard to compare the time or space com-plexity.
We list the average time it takes to process anessay for each method on our server as a reference.The processing time is less than 0.5 second for bothour method and Huang?s method.
Lin?s method re-quired 3.85 sec and Chang?s method required morethan 237 seconds.6 ConclusionsIn this paper, we proposed a new Chinese characterchecker that combines two kinds of technology andcompared it to three previous methods.
Our systemachieved the best F-score performance by reducingthe false alarm significantly.
An error model adoptedfrom the noisy channel model was proposed to makeuse of the frequency of common errors that we col-lected from a training set.
A simplified version ofautomatic template generation was also proposed toprovide high precision character error detection.
Finetuning of the system can be done by adding moretemplates manually.The experiment results show that the main draw-back of previous works is false alarms.
Our systemshave fewer false alarms.
The combination of two in-dependent methods gives the best results on realworld data.
In the future, we will find a way to com-bine the independent methods with theoretical foun-dation.AcknowledgementThis study is conducted under the ?Intelligent Web -enabled Service Research and Development Project?of the Institute for Information Industry which is sub-sidized by the Ministry of Economy Affairs of theRepublic of China.ReferencesBrown, Peter F., Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
(1993).
The ma-thematics of statistical machine translation: Parame-ter estimation.
Computational Linguistics 19 (pp.263-311).Chang, C.-H. (1995).
A New Approach for AutomaticChinese Spelling Correction.
In Proceedings ofNatural Language Processing Pacific Rim Sympo-sium, (pp.
278-283).
Korea.Chen, S. F., & Goodman, J.
(1996).
An EmpiricalStudy of Smoothing Techniques for LanguageModeling.
Proc.
of the 34th annual meeting on As-sociation for Computational Linguistics, (pp.
310-318).
Santa Cruz, California.Chen, Y.-Z., Wu, S.-H., Lu, C.-C., & Ku, T. (2009).Chinese Confusion Word Set for Automatic Gen-eration of Spelling Error Detecting Template.
The21th Conference on Computational Linguistics andSpeech Processing (Rocling 2009), (pp.
359-372).Taichung.CKIP.
(1999).
AutoTag.
Academia Sinica.Huang, C.-M., Wu, M.-C., & Chang, C.-C. (2007).Error Detection and Correction Based on ChinesePhonemic Alphabet in Chinese Text.
Proceedings ofthe Fourth Conference on Modeling Decisions forArtificial Intelligence (MDAI IV), (pp.
463-476).Hung, T.-H., & Wu, S.-H. (2008).
Chinese Essay Er-ror Detection and Suggestion System.
Taiwan E-Learning Forum.Lin, Y.-J., Huang, F.-L., & Yu, M.-S. (2002).
ACHINESE SPELLING ERROR CORRECTIONSYSTEM.
Proceedings of the Seventh Conferenceon Artificial Intelligence and Applications (TAAI).Liu, C.-L., Tien, K.-W., Lai, M.-H., Chuang, Y.-H., &Wu, S.-H. (2009).
Capturing errors in written Chi-nese words.
Proceedings of the Forty Seventh An-nual Meeting of the Association for ComputationalLinguistics (ACL'09), (pp.
25-28).
Singapore.Liu, C.-L., Tien, K.-W., Lai, M.-H., Chuang, Y.-H., &Wu, S.-H. (2009).
Phonological and logographic in-fluences on errors in written Chinese words.
Pro-ceedings of the Seventh Workshop on Asian Lan-guage Resources (ALR7), the Forty Seventh An-nual Meeting of the Association for ComputationalLinguistics (ACL'09), (pp.
84-91).
Singapore.Ma, W.-Y., & Chen, K.-J.
(2003).
A Bottom-upMerging Algorithm for Chinese.
Proceedings ofACL workshop on Chinese Language Processing,(pp.
31-38).MOE.
(2007).
MOE Dictionary new edition.
Taiwan:Ministry of Education.Ren, F., Shi, H., & Zhou, Q.
(1994).
A hybrid ap-proach to automatic Chinese text checking and er-ror correction.
In Proceedings of the ARPA Workshop on Human Language Technology, (pp.
76-81).Zhang, L., Zhou, M., Huang, C., & Lu, M. (2000).Approach in automatic detection and correction oferrors in Chinese text based on feature and learning.Proceedings of the 3rd world congress on Intelli-gent Control and Automation, (pp.
2744-2748).
He-fei.Zhang, L., Zhou, M., Huang, C., & Sun, M. (2000).Automatic Chinese Text Error Correction ApproachBased-on Fast Approximate Chinese Word-Matching Algorithm.
Proceedings of the 3rd worldcongress on Intelligent Control and Automation, (pp.2739-2743).
Hefei.Table 4.
Results of our initial systemTop 1 2 3 4 5 6 7 8 9 10TMP 5.74% 5.63% 5.21% 5.02% 4.90% 4.65% 4.36% 4.12% 4.06% 3.95%D 29.23% 41.25% 45.36% 49.17% 52.00% 53.47% 54.94% 55.13% 56.79% 57.09%C 26.00% 36.75% 40.08% 43.40% 45.65% 46.33% 46.92% 46.82% 48.00% 48.58%F 9.40% 9.76% 9.23% 8.99% 8.85% 8.46% 7.99% 7.58% 7.49% 7.31%LMMP 14.28%D 58.06%C 50.63%F 22.28%PMP 55.52% 60.03% 60.60% 61.58% 60.65% 61.68% 60.51% 61.19% 58.82% 59.03%D 21.60% 29.52% 31.28% 32.74% 34.21% 34.31% 34.31% 33.91% 35.19% 34.79%C 21.60% 29.42% 31.18% 32.64% 34.01% 34.11% 34.01% 33.62% 34.89% 34.50%F 31.10% 39.49% 41.17% 42.67% 43.58% 43.93% 43.55% 43.40% 43.80% 43.55%DMP 7.32% 6.15% 5.64% 5.33% 5.11% 4.87% 4.62% 4.42% 4.30% 4.19%D 62.75% 65.59% 67.44% 69.40% 70.38% 71.06% 71.94% 72.23% 72.62% 72.72%C 54.05% 56.69% 58.16% 59.62% 60.60% 60.99% 61.68% 61.77% 61.58% 61.68%F 12.89% 11.10% 10.28% 9.79% 9.43% 9.02% 8.60% 8.25% 8.04% 7.85%Table 5.
Results of our system after adding more knowledge and enlarged the train setTop 1 2 3 4 5 6 7 8 9 10TMP 7.31% 6.45% 5.73% 5.41% 5.12% 4.83% 4.51% 4.26% 4.20% 4.08%D 37.93% 47.70% 50.15% 53.18% 54.45% 55.62% 56.89% 57.09% 58.75% 59.04%C 34.70% 43.21% 44.87% 47.41% 47.70% 48.48% 48.88% 48.78% 49.95% 50.54%F 12.08% 11.23% 10.17% 9.70% 9.25% 8.79% 8.26% 7.84% 7.74% 7.55%LMMP 14.03%D 63.14%C 55.52%F 22.40%PMP 59.95% 62.72% 62.50% 62.88% 60.66% 61.72% 59.51% 60.29% 58.08% 58.54%D 27.66% 34.21% 35.19% 36.26% 35.58% 35.77% 35.77% 35.48% 36.85% 36.85%C 27.66% 34.11% 35.09% 36.16% 35.48% 35.67% 35.58% 35.28% 36.65% 36.65%F 37.85% 44.19% 44.95% 45.92% 44.77% 45.21% 44.53% 44.51% 44.94% 45.08%DMP 7.76% 6.46% 5.85% 5.51% 5.28% 5.04% 4.78% 4.57% 4.45% 4.33%D 69.50% 71.26% 72.04% 73.50% 74.48% 75.26% 75.95% 76.05% 76.34% 76.34%C 60.50% 62.17% 62.65% 63.73% 64.71% 65.29% 65.78% 65.68% 65.39% 65.39%F 13.76% 11.70% 10.70% 10.14% 9.76% 9.36% 8.91% 8.55% 8.33% 8.12%Table 6.
Results of methods in previous worksTop 1 2 3 4 5 6 7 8 9 10ChangP 2.82% 1.95% 1.63% 1.43% 1.25% 1.13% 1.07% 0.98% 0.94% 0.91%D 72.04% 81.72% 84.55% 88.27% 89.54% 90.32% 91.50% 91.50% 91.79% 91.59%C 27.66% 39.10% 43.30% 45.45% 44.77% 45.16% 46.33% 45.26% 43.30% 44.28%F 5.11% 3.71% 3.14% 2.77% 2.43% 2.21% 2.08% 1.92% 1.83% 1.77%LinP 3.59% 3.19% 2.93% 2.82% 2.60% 2.51% 2.39% 2.35% 2.32% 2.31%D 25.12% 28.93% 29.91% 31.18% 30.98% 31.37% 31.18% 31.57% 32.16% 32.74%C 19.45% 25.51% 26.78% 27.95% 28.05% 28.15% 28.25% 28.25% 28.73% 29.42%F 6.06% 5.67% 5.28% 5.12% 4.76% 4.61% 4.41% 4.34% 4.29% 4.28%HuangP 27.02% 25.81% 25.02% 24.05% 23.30% 22.54% 22.04% 21.16% 20.98% 20.62%D 10.75% 17.79% 23.06% 26.00% 28.54% 30.49% 31.37% 31.86% 33.33% 33.43%C 8.30% 12.02% 15.54% 17.00% 17.39% 18.57% 19.64% 18.76% 17.69% 18.27%F 12.70% 16.40% 19.17% 19.92% 19.92% 20.36% 20.77% 19.89% 19.20% 19.37%Table 7.
Results of methods in previous works on sentences with errorsTop 1 2 3 4 5 6 7 8 9 10ChangP 42.94% 37.21% 33.30% 31.18% 29.31% 27.19% 25.98% 24.48% 23.61% 23.14%D 72.33% 81.62% 84.55% 88.26% 89.63% 90.51% 91.78% 91.79% 92.08% 91.89%C 27.95% 39.58% 43.98% 46.23% 45.65% 46.04% 47.31% 46.14% 44.28% 45.26%F 33.86% 38.36% 37.90% 37.24% 35.70% 34.19% 33.54% 31.99% 30.80% 30.62%LinP 60.59% 59.33% 57.32% 57.19% 55.10% 55.35% 54.27% 53.88% 53.80% 53.97%D 25.70% 29.52% 30.59% 31.86% 31.67% 32.35% 32.25% 32.55% 33.13% 33.82%C 19.55% 25.80% 27.37% 28.64% 29.03% 29.52% 29.61% 29.52% 30.00% 30.69%F 29.56% 35.96% 37.05% 38.17% 38.03% 38.50% 38.32% 38.14% 38.52% 39.13%HuangP 84.16% 76.99% 78.51% 76.11% 73.66% 74.07% 73.21% 70.19% 66.23% 66.66%D 9.87% 16.03% 20.72% 23.36% 25.70% 27.37% 28.05% 28.54% 29.91% 29.91%C 7.62% 10.85% 14.17% 15.64% 15.83% 16.71% 17.79% 17.20% 16.12% 16.61%F 13.97% 19.02% 24.01% 25.95% 26.06% 27.27% 28.62% 27.63% 25.93% 26.59%PMP 96.72% 96.66% 96.76% 96.57% 96.51% 96.54% 96.54% 96.23% 96.11% 96.10%D 25.90% 31.09% 32.16% 33.04% 32.45% 32.75% 32.75% 32.45% 33.82% 33.72%C 25.90% 30.98% 32.06% 32.94% 32.36% 32.65% 32.55% 32.26% 33.63% 33.53%F 40.86% 46.92% 48.16% 49.13% 48.46% 48.80% 48.69% 48.32% 49.82% 49.71%DMP 61.83% 58.45% 56.46% 54.75% 54.21% 53.48% 52.80% 51.53% 51.15% 50.45%D 69.20% 70.97% 71.74% 73.22% 74.19% 74.98% 75.66% 75.76% 76.05% 76.05%C 55.62% 57.28% 57.77% 58.84% 59.82% 60.41% 60.90% 60.80% 60.51% 60.51%F 58.56% 57.86% 57.11% 56.72% 56.88% 56.73% 56.56% 55.78% 55.44% 55.03%
