Parsing for Semidirectional Lambek Grammar is NP-CompleteJochen Df r reI ns t i tu t  ffir masch ine l le  Sprachverarbe i tungUn ivers i ty  of S tu t tgar tAbstractWe study the computational complexityof the parsing problem of a variant ofLambek Categorial Grammar that we callsemidirectional.
In semidirectional Lambekcalculus SD\[ there is an additional non-directional abstraction rule allowing theformula abstracted over to appear any-where in the premise sequent's left-handside, thus permitting non-peripheral ex-traction.
SD\[ grammars are able to gen-erate each context-free language and morethan that.
We show that the parsing prob-lem for semidireetional Lambek Grammaris NP-complete by a reduction of the 3-Partition problem.Key  words: computational complexity,Lambek Categorial Grammar1 In t roduct ionCategorial Grammar (CG) and in particular LambekCategorial Grammar (LCG) have their well-knownbenefits for the formal treatment of natural languagesyntax and semantics.
The most outstanding ofthesebenefits is probably the fact that the specific way,how the complete grammar is encoded, namely interms of 'combinatory potentials' of its words, givesus at the same time recipes for the construction ofmeanings, once the words have been combined withothers to form larger linguistic entities.
Althoughboth frameworks are equivalent in weak generativecapacity - -  both derive exactly the context-free lan-guages --,  LCG is superior to CG in that it can copein a natural way with extraction and unbounded e-pendency phenomena.
For instance, no special cate-gory assignments need to be stipulated to handle arelative clause containing a trace, because it is an-alyzed, via hypothetical reasoning, like a tracelessclause with the trace being the hypothesis to be dis-charged when combined with the relative pronoun.Figure 1 illustrates this proof-logical behaviour.
No-tice that this natural-deduction-style proof in thetype logic corresponds very closely to the phrase-structure tree one would like to adopt in an analysiswith traces.
We thus can derive Bi l l  misses ~ asan s from the hypothesis that there is a "phantom"np in the place of the trace.
Discharging the hypoth-esis, indicated by index 1, results in B i l l  missesbeing analyzed as an s/np from zero hypotheses.
Ob-serve, however, that such a bottom-up synthesis of anew unsaturated type is only required, if that typeis to be consumed (as the antecedent of an impli-cation) by another type.
Otherwise there would bea simpler proof without this abstraction.
In our ex-ample the relative pronoun has such a complex typetriggering an extraction.A drawback of the pure Lambek Calculus !_ is that itonly allows for so-called 'peripheral extraction', i.e.,in our example the trace should better be initial orfinal in the relative clause.This inflexibility of Lambek Calculus is one of thereasons why many researchers study richer systemstoday.
For instance, the recent work by Moortgat(Moortgat 94) gives a systematic in-depth study ofmixed Lambek systems, which integrate the systemsL, NL, NLP, and LP.
These ingredient systems areobtained by varying the Lambek calculus along twodimensions: adding the permutation rule (P) and/ordropping the assumption that the type combinator(which forms the sequences the systems talk about)is associative (N for non-associative).Taken for themselves these variants of I_ are of lit-tle use in linguistic descriptions.
But in Moortgat'smixed system all the different resource managementmodes of the different systems are left intact in thecombination and can be exploited in different partsof the grammar.
The relative pronoun which would,for instance, receive category (np\np)/(np --o s)with --o being implication in LP, 1 i.e., it requires1The Lambek calculus with permutation I_P is alsocalled the "nondirectional Lambek calculus" (Ben-them 88).
In it the leftward and rightward implication95(the book) which(np\np)/(s/np)misses e(n;\8)/n;Bill ~ ~np np\s8Is/nplnp\npFigure 1: Extraction as resource-conscious hypothetical reasoningas an argument "an s lacking an np somewhere" .2.The present paper studies the computational com-plexity of a variant of the Lambek Calculus that liesbetween / and tP, the Semidirectional Lambek Cal-culus SDk.
3 Since tP  derivability is known to be NP-complete, it is interesting to study restrictions on theuse of the I_P operator -o.
A restriction that leavesits proposed linguistic applications intact is to admita type B -o A only as the argument ype in func-tional applications, but never as the functor.
Statedprove-theoretically for Gentzen-style systems, thisamounts to disallowing the left rule for -o. Surpris-ingly, the resulting system SD\[.
can be stated with-out the need for structural rules, i.e., as a monolithicsystem with just one structural connective, becausethe ability of the abstracted-over formula to permutecan be directly encoded in the right rule for --o.
4Note that our purpose for studying SDI_ is not thatit might be in any sense better suited for a theory ofgrammar (except perhaps, because of its simplicity),but rather, because it exhibits a core of logical be-haviour that any richer system also needs to include,at least if it should allow for non-peripheral extrac-tion.
The sources of complexity uncovered here arethus a forteriori present in all these richer systemsas well.collapse.2Morrill (Morrill 94) achieves the same effect with apermutation modality /k apphed to the np gap: (s/Anp)SThis name was coined by Esther K6nig-Baumer, whoemploys avariant of this calculus in her LexGram system(KSnig 95) for practical grammar development.4It should be pointed out that the resource manage-ment in this calculus is very closely related to the han-dhng and interaction of local valency and unboundeddependencies in HPSG.
The latter being handled withset-valued features SLASH, QUE and KEL essentially emu-lates the permutation potential of abstracted categoriesin semidirectional Lambek Grammar.
A more detailedanalysis of the relation between HPSG and SD\[ is givenin (KSnig 95).2 Semid i rec t iona l  Lambek  Grammar2.1 Lambek ca lcu lusThe semidirectional Lambek calculus (henceforthSDL) is a variant of J. Lambek's original (Lam-bek 58) calculus of syntactic types.
We start bydefining the Lambek calculus and extend it to ob-tain SDL.Formulae (also called "syntactic types") are builtfrom a set of propositional variables (or "primitivetypes") B = {bl, b2,...} and the three binary con-nectives ?
, \ , / ,  called product, left implication, andright implication.
We use generally capital etters A,B, C , .
.
.
to denote formulae and capitals towards theend of the alphabet T, U, V, .
.
.
to denote sequencesof formulae.
The concatenation of sequences U andV is denoted by (U, V).The (usual) formal framework of these logics is aGentzen-style sequent calculus.
Sequents are pairs(U, A), written as U =~ A, where A is a type and Uis a sequence of types.
5 The claim embodied by se-quent U =~ A can be read as "formula A is derivablefrom the structured database U".
Figure 2 showsLambek's original calculus t.First of all, since we don't need products to obtainour results and since they only complicate matters,we eliminate products from consideration i  the se-quel.In Semidirectional Lambek Calculus we add as ad-ditional connective the \[_P implication --% but equipit only with a right rule.U, B, V :=~ A (-o R) if T = (U, Y) nonempty.
T :~ B --o A5In contrast o Linear Logic (Girard 87) the orderof types in U is essential, since the structural rule ofpermutation is not assumed to hold.
Moreover, the factthat only a single formula may appear on the right of ~ ,make the Lambek calculus an intuitionistic fragment ofthe multiplicative fragment of non-commutative propo-sitional Linear Logic.96(Ax)T~B U,A ,V=~CU, A/B,  T, V =~ C (/L)U,B ~AU ::~ A /B  (/1~) if U nonemptyT ::v B U,A, V =v CU, T, B\A,  V =~ C (\L)B ,U~AU =~ B\A  (\R) if U nonemptyU,A,B, V =~ C (.L)U, AoB,  V =~ CUsA V~B (.R)U,V =~ A .BT~A U,A,V=?,C (Cut)U, T, V =~ UFigure 2: Lambek calculus LLet us define the polarity of a subformula of a se-quent A1, ?
?., Am ::~ A as follows: A has positive po-larity, each of Ai have negative polarity and if B/Cor C\B has polarity p, then B also has polarity pand C has the opposite polarity of p in the sequent.A consequence of only allowing the (-o R) rule,which is easily proved by induction, is that in anyderivable sequent --o may only appear in positivepolarity.
Hence, -o may not occur in the (cut) for-mula A of a (Cut) application and any subformulaB -o A which occurs somewhere in the prove mustalso occur in the final sequent.
When we assume thefinal sequent's RHS to be primitive (or --o-less), thenthe (-o R) rule will be used exactly once for each(positively) occuring -o-subformula.
In other words,(-o R) may only do what it is supposed to do: ex-traction, and we can directly read off the categoryassignment which extractions there will be.We can show Cut Elimination for this calculus by astraight-forward adaptation of the Cut eliminationproof for L. We omit the proof for reasons of space.Proposition 1 (Cut Elimination) EachSDL-derivable sequent has a cut-free proof.The cut-free system enjoys, as usual for Lambek-likelogics, the Subformula Property: in any proof onlysubformulae of the goal sequent may appear.In our considerations below we will make heavy useof the well-known count invariant for Lambek sys-tems (Benthem 88), which is an expression of theresource-consciousness of these logics.
Define #b(A)(the b-count of A), a function counting positive andnegative occurrences of primitive type b in an arbi-97trary type A, to beif A= bif A primitive and A ~ b#b(A)= #b(B) -#b(C) i fA=B/CorA=V\Bor A=C-o  B\ [ .#b(B) + #b(C) i fA  = B .
CThe invariant now states that for any primitive b,the b-count of the RHS and the LHS of any derivablesequent are the same.
By noticing that this invariantis true for (Ax) and is preserved by the rules, weimmediately can state:Proposition 2 (Count Invariant) If I-sb L U ==~A, then #b(U) = #b(A) fo~ any b ~ t~.Let us in parallel to SDL consider the fragment of itin which (/R) and (\R) are disallowed.
We call thisfragment SDL-.
Remarkable about this fragment isthat any positive occurrence of an implication mustbe --o and any negative one must be / or \.2.2 Lambek GrammarDefinition 3 We define a Lambek grammar to be aquadruple (E, ~r, bs, l) consisting of the finite alpha-bet of terminals E, the set jr of all Lambek formulaegenerated from some set of propositional variableswhich includes the distinguished variable s, and thelezical map l : ~, --* 2 7 which maps each terminal toa finite subset o f f .We extend the lexical map l to nonempty stringsof terminals by setting l (wlw2.. .w~) := l(wl) ?l(w~) x ... x l(w,) for wlw2.
.
.wn E ~+.The language generated by a Lambek grammar G =(~,~',bs, l )  is defined as the set of all stringswlw~.. .wn E ~+ for which there exists a sequencex==~xx==~xB~, B2, C~, C2, c n+l, b n+l => y (*)B~, B2, C~, C2, c n, b n ~ c --o (b --o y)A2, B\[ ,  B2, C~, C2, c n, b n =* xn--1 A 1 , A2, B~, B2, C~, C2, c, b =v xA~ -1, A2, B~', B2, C~, C2 =~ c -0 (b -0 x)A?, A2, B~, B2, C{ ~, C2 ==> xFigure 3: Proof of A~, A2, B~, B2, C~, C2 =~ z2x(-on)(\]L)2x(--on)(/L)of types U E l (wlw2.
.
.wn) and k k U ~ bs.
Wedenote this language by L(G).An SDL-grammar is defined exactly like a Lambekgrammar, except hat kSD k replaces kl_.Given a grammar G and a string w = WlW2... wn,the parsing (or recognition) problem asks the ques-tion, whether w is in L(G).It is not immediately obvious, how the generativecapacity of SDL-grammars relate to Lambek gram-mars or nondirectional Lambek grammars (basedon calculus LP).
Whereas Lambek grammars gener-ate exactly the context-free languages (modulo themissing empty word) (Pentus 93), the latter gen-erate all permutation closures of context-free lan-guages (Benthem 88).
This excludes many context-free or even regular languages, but includes somecontext-sensitive ones, e.g., the permutation closureof a n b n c n .Concerning SD\[, it is straightforward to show thatall context-free languages can be generated by SDL-grammars?P ropos i t ion  4 Every context-free language is gen-erated by some SDL-grammar.Proof .
We can use a the standard transformationof an arbitrary cfr.
grammar G = (N, T, P, S) to acategorial grammar G'.
Since -o does not appearin G' each SDl_-proof of a lexical assignment mustbe also an I_-proof, i.e.
exactly the same strings arejudged grammatical by SDL as are judged by L. DNote that since the {(Ax), (/L), (\L)} subset of I_already accounts for the cfr.
languages, this obser-vation extends to SDL-.Moreover, some languages which are not context-freecan also be generated.Example .
Consider the following grammar G forthe language anbnc n. We use primitive types B ={b, c, x, y, z} and define the lexical map for E =98{a, b, c} as follows:l(a) := { x/(c ---o (b -o x)), xl(c ---o (b -o y)) }= )41 = A2----CI = C2The distinguished primitive type is x?
To simplifythe argumentation, we abbreviate types as indicatedabove?Now, observe that a sequent U =~ x, where U is theimage of some string over E, only then may have bal-anced primitive counts, if U contains exactly one oc-currence of each of A2, B2 and C2 (accounting for theone supernumerary x and balanced y and z counts)and for some number n >_ 0, n occurrences of eachof A1, B1, and C1 (because, resource-oriented speak-ing, each Bi and Ci "consume" a b and c, resp., andeach Ai "provides" a pair b, c).
Hence, only stringscontaining the same number of a's, b's and c's maybe produced.
Furthermore, due to the SubformulaProperty we know that in a cut-free proof of U ~ x,the mMn formula in abstractions (right rules) mayonly be either c -o (b --o X) or b -o X, whereX E {x,y}, since all other implication types haveprimitive antecedents.
Hence, the LHS of any se-quent in the proof must be a subsequence of U, withsome additional b types and c types interspersed.But then it is easy to show that U can only be ofthe formAnl, A2, B~, B2, C~, C2,since any / connective in U needs to be introducedvia (/L).It remains to be shown, that there is actually a prooffor such a sequent?
It is given in Figure 3.The sequent marked with * is easily seen to be deriv-able without abstractions.A remarkable point about SDL's ability to cover thislanguage is that neither L nor LP can generate it.Hence, this example substantiates the claim made in(Moortgat 94) that the inferential capacity of mixedLambek systems may be greater than the sum ofits component parts.
Moreover, the attentive readerwill have noticed that our encoding also extends tolanguages having more groups of n symbols, i.e., tolanguages of the form n n n al a2 .
.
.
a k ?Finally, we note in passing that for this grammar therules ( /R )  and (\R) are irrelevant, i.e.
that it is atthe same time an SOL- grammar.3 NP-Completeness of the ParsingProblemWe show that the Parsing Problem for SDL-grammars is NP-complete by a reduction of the3-Partition Problem to it.
6 This well-known NP-complete problem is cited in (GareyJohnson 79) asfollows.Instance: Set ,4 of 3m elements, a bound N EZ +, and a size s(a) E Z + for eacha E `4 such that ~ < s(a) < ~- and~o~ s (a )  = mN.Question: Can ` 4 be partitioned into m disjointsets ` 41,`42 , .
.
.
,Am such that, for1 < i < m, ~ae.a  s(a) = N (notethat each `4i must 'therefore containexactly 3 elements from ` 4)?Comment: NP-complete in the strong sense.Here is our reduction.
Let F = (`4, m,N,s )  bea given 3-Partition instance.
For notational conve-nience we abbreviate ( .
.
.
( (A /B I ) /B~) / .
.
. )
/Bn  byA/B~ ?
.
.
.
?
B2 ?
B1 and similarly B,  -o ( .
.
.
(B1 --oA) .
.
. )
by Bn ?
.
.
.
?
B2 ?
B1 --o A, but note that thisis just an abbreviation i the product-free fragment.Moreover the notation A k stands forAoAo .
.
.
oAk t~mesWe then define the SDL-grammar Gr  = (~, ~, bs, l)as follows:p, := {v, wl,.
.
.
,  warn}5 t" := all formulae over primit ive typesm b B = {a ,d}UUi=,{  i,c,:}bs :--= a?for l< i<3rn- l :l(wi) := UJ.<./<m d/d  ?
bj ?
c: (~')6A similar reduction has been used in (LincolnWin-kler 94) to show that derivability in the multiplicativefragment of propositional Linear Logic with only the con-nectives --o and @ (equivalently Lambek calculus withpermutation LP) is NP-complete.99The word we are interested in is v wl w2.
.
.w3m.We do not care about other words that might begenerated by Gr.
Our claim now is that a given3-Partition problem F is solvable i f  and  on ly  i fv wl .
.
.
w3m is in L(Gr).
We consider each directionin turn.Lemma 5 (Soundness)  I f  a 3-Partit ion problemF = (A ,m,N,s )  has a solution, then vwl .
.
.w3m isin / (Gr ) .Proof .
We have to show, when given a solution to F,how to choose a type sequence U ~ l (vwl .
.
.wzm)and construct an SDL proof for U ==~ a. Suppose`4 = {al ,a2, .
.
.
,a3m}.
From a given solution (setof triples) A1,`4~,.. .
,-Am we can compute in poly-nomial time a mapping k that sends the index ofan element o the index of its solution triple, i.e.,k(i) = j iff ai e `4j.
To obtain the required sequenceU, we simply choose for the wi terminals the type?
cS(a3"~) ?
c ~("~) (resp.
d/bk(3m) k(3m) for W3m).
d id  ?
bk(i) k(i)Hence the complete sequent o solve is:N d) a/ (b  3 ?b  3 ?
.
.
.
?
b3m ac  N ?c  N ?
.
.
.
?
c  m -odid ?
bko) ?
%(1)cS(a3, .
-1)  (*) d id  ?
bk(3m-1) ?
k(am-1)dlb ?
cS(a3") / k(3m) k(zm)Let a/Bo,  B1 , .
.
.B3m ~ a be a shorthand for (*),and let X stand for the sequence of primitive typesc~(,,~,.)
c~(,~.,,-~) c~(,~,) bk(3m), k(3m),bk(3m-l), k(3,~_ l ) , .
.
.bko) ,  k(1)"Using rule ( /L )  only, we can obviously proveB1, .
.
.
B3m , X ::~ d. Now, applying (--o R) 3m + N mtimes we can obtain B1, .
.
.B3m =~ B0, since thereare in total, for each i, 3 bi and N ci in X.
As finalstep we haveBI, .
.
.B3m ~ B0 a ~ aa/Bo,  B I , .
.
.
B3m ~ a ( /L )which completes the proof.
\[\]Lemma 6 (Completeness)  Let F = ( .4,  m,  N ,  s )be an arbitrary 3-Partit ion problem and Gr  the cor-responding SDL-grammar as defined above.
Then Fhas a solution, i f  v w l .
.
.
w3m is in L(Gr).P roof .
Let v w l .
.
.
W3m 6 L(Gr)  andN d), B1,.
?
?
Bsm ~ a a/(b?
.
.
.
.
.em -obe a witnessing derivable sequent, i.e., for 1 < i <3m, Bi E l(wi).
Now, since the counts of this se-quent must be balanced, the sequence B1, .
.
.B3mmust contain for each 1 _< j < m exactly 3 bj andexactly N cj as subformulae.
Therefore we can readoff the solution to F from this sequent by includingin Aj (for 1 < j < m) those three ai for which Bihas an occurrence of bj, say these are aj(1), aj(2) andaj(3).
We verify, again via balancedness of the prim-itive counts, that s(aj(1)) ?
s(aj(2)) + s(aj(3)) = Nholds, because these are the numbers of positive andnegative occurrences of cj in the sequent.
This com-pletes the proof.
\[\]The reduction above proves NP-hardness of the pars-ing problem.
We need strong NP-completeness of3-Partition here, since our reduction uses a unaryencoding.
Moreover, the parsing problem also lieswithin NP, since for a given grammar G proofs arelinearly bound by the length of the string and hence,we can simply guess a proof and check it in polyno-mial time.
Therefore we can state the following:Theorem 7 The parsing problem for SDI_ is NP-complete.Finally, we observe that for this reduction the rules(/R) and (\R) are again irrelevant and that we canextend this result to SDI_-.4 Conc lus ionWe have defined a variant of Lambek's original cal-culus of types that allows abstracted-over categoriesto freely permute.
Grammars based on SOl- cangenerate any context-free language and more thanthat.
The parsing problem for SD\[, however, wehave shown to be NP-complete.
This result indi-cates that efficient parsing for grammars that al-low for large numbers of unbounded ependenciesfrom within one node may be problematic, even inthe categorial framework.
Note that the fact, thatthis problematic case doesn't show up in the correctanalysis of normal NL sentences, doesn't mean thata parser wouldn't have to try it, unless some arbi-trary bound to that number is assumed.
For practi-cal grammar engineering one can devise the mottoavoid accumulation of unbounded ependencies bywhatever means.On the theoretical side we think that this result forS01 is also of some importance, since SDI_ exhibitsa core of logical behaviour that any (Lambek-based)logic must have which accounts for non-peripheralextraction by some form of permutation.
And hence,this result increases our understanding of the nec-essary computational properties of such richer sys-tems.
To our knowledge the question, whether theLambek calculus itself or its associated parsing prob-lem are NP-hard, are still open.ReferencesJ.
van Benthem.
The Lambek Calculus.
In R. T. O.et al (Ed.
), Categorial Grammars and Natural Lan-guage Structures, pp.
35-68.
Reidel, 1988.M.
R. Garey and D. S. Johnson.
Computersand Intractability--A Guide to the Theory of NP-Completeness.
Freeman, San Francisco, Cal., 1979.J.-Y.
Girard.
Linear Logic.
Theoretical ComputerScience, 50(1):1-102, 1987.E.
Khnig.
LexGram - a practical categorial gram-mar formalism.
In Proceedings of the Workshop onComputational Logic for Natural Language Process-ing.
A Joint COMPULOGNET/ELSNET/EAGLESWorkshop, Edinburgh, Scotland, April 1995.J.
Lambek.
The Mathematics of Sentence Struc-ture.
American Mathematical Monthly, 65(3):154-170, 1958.P.
Lincoln and T. Winkler.
Constant-Only Multi-plicative Linear Logic is NP-Complete.
TheoreticalComputer Science, 135(1):155-169, Dec. 1994.M.
Moortgat.
Residuation in Mixed Lambek Sys-tems.
In M. Moortgat (Ed.
), Lambek Calculus.
Mul-timodal and Polymorphic Extensions, DYANA-2 de-liverable RI.I.B.
ESPRIT, Basic Research Project6852, Sept. 1994.G.
Morrill.
Type Logical Grammar: Categorial Logicof Signs.
Kluwer, 1994.M.
Pentus.
Lambek grammars are context free.
InProceedings of Logic in Computer Science, Montreal,1993.100
