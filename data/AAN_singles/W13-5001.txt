Proceedings of the TextGraphs-8 Workshop, pages 1?5,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsEvent-Centered Information Retrieval Using Kernels on Event GraphsGoran Glavas?
and Jan S?najderUniversity of ZagrebFaculty of Electrical Engineering and ComputingUnska 3, 10000 Zagreb, Croatia{goran.glavas,jan.snajder}@fer.hrAbstractTraditional information retrieval models as-sume keyword-based queries and use unstruc-tured document representations.
There isan abundance of event-centered texts (e.g.,breaking news) and event-oriented informa-tion needs that often involve structure thatcannot be expressed using keywords.
Wepresent a novel retrieval model that uses a struc-tured event-based representation.
We struc-ture queries and documents as graphs of eventmentions and employ graph kernels to measurethe query-document similarity.
Experimentalresults on two event-oriented test collectionsshow significant improvements over state-of-the-art keyword-based models.1 IntroductionThe purpose of an information retrieval (IR) system isto retrieve the documents relevant to user?s informa-tion need expressed in the form of a query.
Many in-formation needs are event-oriented, while at the sametime there exists an abundance of event-centered texts(e.g., breaking news, police reports) that could satisfythese needs.
Furthermore, event-oriented informationneeds often involve structure that cannot easily beexpressed with keyword-based queries (e.g., ?Whatare the countries that President Bush has visited andin which has his visit triggered protests??).
Tradi-tional IR models (Salton et al 1975; Robertson andJones, 1976; Ponte and Croft, 1998) rely on shal-low unstructured representations of documents andqueries, making no use of syntactic, semantic, ordiscourse level information.
On the other hand, mod-els utilizing structured event-based representationshave not yet proven useful in IR.
However, signifi-cant advances in event extraction have been achievedin the last decade as the result of standardization ef-forts (Pustejovsky et al 2003) and shared evaluationtasks (Verhagen et al 2010), renewing the interestin structured event-based text representations.In this paper we present a novel retrieval modelthat relies on structured event-based representationof text and addresses event-centered queries.
Wedefine an event-oriented query as a query referringto one or more real-world events, possibly includ-ing their participants, the circumstances under whichthe events occurred, and the temporal relations be-tween the events.
We account for such queries bystructuring both documents and queries into eventgraphs (Glavas?
and S?najder, 2013b).
The eventgraphs are built from individual event mentions ex-tracted from text, capturing their protagonists, times,locations, and temporal relations.
To measure thequery-document similarity, we compare the corre-sponding event graphs using graph kernels (Borg-wardt, 2007).
Experimental results on two news storycollections show significant improvements over state-of-the-art keyword-based models.
We also show thatour models are especially suitable for retrieval fromcollections containing topically similar documents.2 Related WorkMost IR systems are a variant of the vector spacemodel (Salton et al 1975), probabilistic model(Robertson and Jones, 1976), or language model(Ponte and Croft, 1998), which do not account forassociations between query terms.
Recent models in-troduce co-occurrence-based (Park et al 2011) andsyntactic (Shinzato et al 2012) dependencies.
How-ever, these dependencies alone in most cases cannotcapture in sufficient detail the semantics of events.A more comprehensive set of dependencies can bemodeled with graph-based representations.
Graph-1based IR approaches come in two flavors: (1) theentire document collection is represented as a sin-gle graph in which queries are inserted as additionalvertices (Mihalcea and Tarau, 2004); (2) each queryand each document are represented as graphs of con-cepts, and the relevance of a document for a query isdetermined by comparing the corresponding graphs(Montes-y Go?mez et al 2000).
Our approach fitsinto the latter group but we represent documents asgraphs of events rather than graphs of concepts.
InNLP, graph kernels have been used for question typeclassification (Suzuki, 2005), cross-lingual retrieval(Noh et al 2009), and recognizing news stories onthe same event (Glavas?
and S?najder, 2013b).Event-based IR is addressed explicitly by Lin etal.
(2007), who compare predicate-argument struc-tures extracted from queries to those extracted fromdocuments.
However, queries have to be manuallydecomposed into semantic roles and can contain onlya single predicate.
Kawahara et al(2013) propose asimilar approach and demonstrate that ranking basedon semantic roles outperforms ranking based on syn-tactic dependencies.
Both these approaches target theproblem of syntactic alternation but do not considerthe queries made of multiple predicates, such as thoseexpressing temporal relations between events.3 Kernels on Event GraphsOur approach consists of two steps.
First, we con-struct event graphs from both the document and thequery.
We then use a graph kernel to measure thequery-document similarity and rank the documents.3.1 Event GraphsAn event graph is a mixed graph in which vertices rep-resent the individual event mentions and edges repre-sent temporal relations between them.
More formally,an event graph is a tuple G = (V,E,A,m, r), whereV is the set of vertices, E is the set of undirectededges, A is the set of directed edges, m : V ?
Mmaps the vertices to event mentions, and r : E ?
Rassigns temporal relations to edges.We use a generic representation of a factual eventmention, which consists of an event anchor and eventarguments of four coarse types (agent, target, time,and location) (Glavas?
and S?najder, 2013a; Glavas?and S?najder, 2013b).
We adopt the set of temporalrelations used in TempEval-2 (Verhagen et al 2010)(before, after, and overlap), with additional temporalequivalence relation (equal).To build an event graph, we first extract the eventmentions and then extract the temporal relations be-tween them.
To extract the event anchors, we usea supervised model based on a rich feature set pro-posed by Glavas?
and S?najder (2013b), performingat 80% F1-score.
We then use a robust rule-basedapproach from Glavas?
and S?najder (2013a) to extractevent arguments.
Finally, we extract the temporalrelations using a supervised model with a rich fea-ture set proposed by Glavas?
and S?najder (2013b).Relation classification performs at 60% F1-score.To compute the product graph kernels, we mustidentify event mentions from the query that coreferwith mentions from the document.
To this end, weemploy the model from Glavas?
and S?najder (2013a),which compares the anchors and four types of argu-ments between a pair of event mentions.
The modelperforms at 67% F-score on the EventCorefBankdataset (Bejan and Harabagiu, 2008).3.2 Product Graph KernelsGraph kernels provide an expressive measure of sim-ilarity between graphs (Borgwardt, 2007).
In thiswork, we use product graph kernel (PGK), a type ofrandom walk graph kernel that counts the commonwalks between two graphs (Ga?rtner et al 2003).Product graph.
The graph product of two labeledgraphs, G and G?, denoted GP = G?G?, is a graphwith the vertex setVP ={(v, v?)
| v ?
VG, v?
?
VG?
, ?
(v, v?
)}where predicate ?
(v, v?)
holds iff vertices v and v?
areidentically labeled (Hammack et al 2011).
Verticesof event graphs have the same label if the event men-tions they denote corefer.
The edge set of the productis conditioned on the type of the graph product.
In thetensor product, an edge exists in the product iff thecorresponding edges exist in both input graphs andhave the same label, i.e., denote the same temporalrelation.
In the conormal product, an edge is intro-duced iff the corresponding edge exists in at least oneinput graph.
A conormal product may compensatefor omitted temporal relations in the input graphs butmay introduce spurious edges that do not represent2(a) Query graph (b) Document graph (c) Tensor product (d) Conormal productFigure 1: Examples of event graphs and their productstrue overlap between queries and documents.
Fig.
1shows an example of input graphs and their products.PGK computation.
The PGK for input graphs Gand G?
is computed askPG(G,G?)
=|VP |?i,j=1[(I ?
?AP )?1]ijprovided ?
< 1/d , where d is the maximum vertexdegree in the product graph GP with the adjacencymatrix AP .
In experiments, we set ?
to 1/(d+ 1) .PGK suffers from tottering (Mahe?
et al 2005), a phe-nomenon due to the repetition of edges in a randomwalk.
A walk that totters between neighboring ver-tices produces an unrealistically high similarity score.To prevent tottering between neighboring vertices,Mahe?
et al(2005) transform the input graphs beforecomputing the kernel score on their product: eachedge (vi, vj) is converted into a vertex ve; the edge it-self gets replaced with edges (ve, vi) and (ve, vj).
Weexperiment with Mahe?
extension for PGK, account-ing for the increased probability of one-edge-cycletottering due the small size of query graphs.4 ExperimentsTest Collections and Queries.
To the best of ourknowledge, there is no standard test collection avail-able for event-centered IR that we could use to evalu-ate our models.
Thus, we decided to build two suchtest collections, with 50 queries each: (1) a generalcollection of topically diverse news stories and (2) atopic-specific collection of news on Syria crisis.
Thefirst collection contains 25,948 news stories obtainedfrom EMM News Brief, an online news clusteringservice.1 For the topic-specific collection, we se-lected from the general collection 1387 documentsthat contain the word ?Syria?
or its derivations.1http://emm.newsbrief.euGeneral collection (news stories)q1: An ICT giant purchased the phone maker after thegovernment approved the acquisitionq2: The warship tried to detain Chinese fishermen butwas obstructed by the Chinese vesselsTopic-specific collection (Syria crisis)q3: Syrian forces killed civilians, torched houses, andransacked stores, overrunning a farmer villageq4: Rebels murdered many Syrian soldiers and the gov-ernment troops blasted the town in central SyriaTable 1: Example queries from the test collectionFor each collection we asked an annotator to com-pile 50 queries.
She was instructed to select at ran-dom a document from the collection, read the docu-ment carefully, and compile at least one query con-sisting of at least two event mentions, in such a waythat the selected document is relevant for the query.Example queries are shown in Table 1.
For instance,query q1 (whose corresponding event graph is shownin Fig.
1a) was created based on the following docu-ment (whose event graph is shown in Fig.
1b):Google Inc. won approval from Chinese regula-tors for its $12.5 billion purchase of MotorolaMobility Holdings Inc., clearing a final hurdlefor a deal that boosts its patents portfolio.
.
.Relevance judgments.
To create relevance judg-ments, we use the standard IR pooling method withtwo baseline retrieval models ?
a TF-IDF weightedvector space model (VSM) and a language model.Our graph-based model was not used for pooling be-cause of time limitations (note that this favors thebaseline models because pool-based evaluation isbiased against models not contributing to the pool(Bu?ttcher et al 2007)).
Given that EMM News Briefbuilds clusters of related news and that most EMM3CollectionModel General SpecificBaselines TF-IDF VSM 0.335 0.199Hiemstra LM 0.300 0.175In expC2 0.341 0.188DFR BM25 0.332 0.192Graph-based Tensor 0.502 0.407Conormal 0.434 0.359Mahe?
Tensor 0.497 0.412Mahe?
Conormal 0.428 0.362Table 2: Retrieval performance (MAP)clusters contain less than 50 news stories, we esti-mate that there are at most 50 relevant documents perquery.
To get an even better estimate of recall, foreach query we pooled the union of top 75 documentsretrieved by each of the two baseline models.One annotator made the relevance judgments forall queries.
We asked another annotator to providejudgments for two randomly chosen queries and ob-tained perfect agreement, which confirmed our intu-ition that determining relevance for complex event-centered queries is not difficult.
The average numberof relevant documents per query in the general andtopic-specific collection is 12 and 8, respectively.2Results.
Table 2 shows the mean average preci-sion (MAP) on both test collections for four graphkernel-based models (tensor/conormal product andwith/without Mahe?
extension).
We compare ourmodels to baselines from the three traditional IRparadigms: a TF-IDF-weighted cosine VSM, thelanguage model of Hiemstra (2001), and the best-performing models from the probabilistic Divergencefrom Randomness (DFR) framework (In expC2 andDFR BM25) (Amati, 2003; Ounis et al 2006).
Weevaluate these models using the Terrier IR platform.3Overall, all models perform worse on the topic-specific collection, in which all documents are topi-cally related.
Our graph kernel models outperformall baseline models (p<0.01 for tensor models andp<0.05 for conormal models; paired student?s t-test)on both collections, with a wider margin on topic-specific than on the general collection.
This result2Available at http://takelab.fer.hr/data3http://terrier.org[?1;?0.1](?0.1; 0] (0; 0.1] (0.1; 0.3] (0.3; 1]051015Figure 2: Histogram of AP differencessuggests that the graph-based models are especiallysuitable for retrieval over topic-specific collections.There is no significant difference between the ten-sor product and conormal product models, indicatingthat the conormal product introduces spurious edgesmore often than it remedies for incorrect extractionof temporal relations.
The performance differencesdue to Mahe?
extension are not significant, providingno conclusive evidence on the effect of tottering.To gain more insights into the performance of ourevent graph-based model, we analyzed per querydifferences in average precision between our best-performing model (Tensor) and the best-performingbaseline (In expC2) on queries from the general col-lection.
Fig.
2 shows the histogram of differences.Our graph kernel-based model outperforms the base-line on 42 out of 50 queries.
A closer inspectionof the eight queries on which our model performsworse than the baseline reveals that this is due to (1)an important event mention not being extracted fromthe query (2 cases) or a (2) failure in coreferenceresolution between an event mention from the queryand a mention from the document (6 cases).5 Conclusion and PerspectivesWe presented a graph-based model for event-centeredinformation retrieval.
The model represents queriesand documents as event graphs and ranks the docu-ments based on graph kernel similarity.
The experi-ments demonstrate that for event-based queries ourgraph-based model significantly outperforms state-of-the-art keyword-based retrieval models.
Our modelsare especially suitable for topic-specific collections,on which traditional IR models perform poorly.An interesting topic for further research is the ex-tension of the model with other types of dependen-cies between events, such as entailment, causality,4and structural relations.
Another direction concernsthe effective integration of event graph-based andkeyword-based models.
We will also consider ap-plications of event graphs on other natural languageprocessing tasks such as text summarization.Acknowledgments.
This work has been supportedby the Ministry of Science, Education and Sports,Republic of Croatia under the Grant 036-1300646-1986.
We thank the reviewers for their comments.ReferencesGiambattista Amati.
2003.
Probability models for infor-mation retrieval based on divergence from randomness.Ph.D.
thesis, University of Glasgow.Cosmin Adrian Bejan and Sanda Harabagiu.
2008.
Alinguistic resource for discovering event structures andresolving event coreference.
In Proc.
of the LREC2008.Karsten Michael Borgwardt.
2007.
Graph Kernels.
Ph.D.thesis, Ludwig-Maximilians-Universita?t Mu?nchen.Stefan Bu?ttcher, Charles LA Clarke, Peter CK Yeung, andIan Soboroff.
2007.
Reliable information retrievalevaluation with incomplete and biased judgements.
InProc.
of the ACM SIGIR, pages 63?70.
ACM.Thomas Ga?rtner, Peter Flach, and Stefan Wrobel.
2003.On graph kernels: Hardness results and efficient alterna-tives.
In Learning Theory and Kernel Machines, pages129?143.
Springer.Goran Glavas?
and Jan S?najder.
2013a.
Exploring coref-erence uncertainty of generically extracted event men-tions.
In Proc.
of the CICLing 2013, pages 408?422.Springer.Goran Glavas?
and Jan S?najder.
2013b.
Recognizing iden-tical events with graph kernels.
In Proc.
of the ACL2013, pages 797?803.Richard Hammack, Wilfried Imrich, and Sandi Klavz?ar.2011.
Handbook of Product Graphs.
Discrete Mathe-matics and Its Applications.
CRC Press.Djoerd Hiemstra.
2001.
Using language models for infor-mation retrieval.
Taaluitgeverij Neslia Paniculata.Daisuke Kawahara, Keiji Shinzato, Tomohide Shibata, andSadao Kurohashi.
2013.
Precise information retrievalexploiting predicate-argument structures.
In Proc.
ofthe IJCNLP 2013.
In press.Chia-Hung Lin, Chia-Wei Yen, Jen-Shin Hong, SamuelCruz-Lara, et al2007.
Event-based textual documentretrieval by using semantic role labeling and corefer-ence resolution.
In IADIS International ConferenceWWW/Internet 2007.Pierre Mahe?, Nobuhisa Ueda, Tatsuya Akutsu, Jean-LucPerret, and Jean-Philippe Vert.
2005.
Graph kernelsfor molecular structure-activity relationship analysiswith support vector machines.
Journal of ChemicalInformation and Modeling, 45(4):939?951.Rada Mihalcea and Paul Tarau.
2004.
TextRank: Bring-ing order into texts.
In Proc.
of the EMNLP 2004,volume 4.
Barcelona, Spain.Manuel Montes-y Go?mez, Aurelio Lo?pez-Lo?pez, andAlexander Gelbukh.
2000.
Information retrieval withconceptual graph matching.
In Database and ExpertSystems Applications, pages 312?321.
Springer.Tae-Gil Noh, Seong-Bae Park, Hee-Geun Yoon, Sang-JoLee, and Se-Young Park.
2009.
An automatic transla-tion of tags for multimedia contents using folksonomynetworks.
In Proc.
of the ACM SIGIR 2009, pages492?499.
ACM.Iadh Ounis, Gianni Amati, Vassilis Plachouras, Ben He,Craig Macdonald, and Christina Lioma.
2006.
Terrier:A high performance and scalable information retrievalplatform.
In Proceedings of the OSIR Workshop, pages18?25.Jae Hyun Park, W Bruce Croft, and David A Smith.
2011.A quasi-synchronous dependence model for informa-tion retrieval.
In Proc.
of the 20th ACM InternationalConference on Information and Knowledge Manage-ment, pages 17?26.
ACM.Jay Ponte and Bruce Croft.
1998.
A language modelingapproach to information retrieval.
In Proc.
of the ACMSIGIR, pages 275?281.
ACM.James Pustejovsky, Jose?
Castano, Robert Ingria, RoserSauri, Robert Gaizauskas, Andrea Setzer, Graham Katz,and Dragomir Radev.
2003.
TimeML: Robust specifi-cation of event and temporal expressions in text.
NewDirections in Question Answering, 3:28?34.Stephen E Robertson and K Sparck Jones.
1976.
Rele-vance weighting of search terms.
Journal of the Ameri-can Society for Information science, 27(3):129?146.Gerard Salton, Anita Wong, and Chung-Shu Yang.
1975.A vector space model for automatic indexing.
Commu-nications of the ACM, 18(11):613?620.Keiji Shinzato, Tomohide Shibata, Daisuke Kawahara,and Sadao Kurohashi.
2012.
Tsubaki: An open searchengine infrastructure for developing information ac-cess methodology.
Journal of Information Processing,20(1):216?227.Jun Suzuki.
2005.
Kernels for structured data in naturallanguage processing.
Doctor Thesis, Nara Institute ofScience and Technology.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
SemEval-2010 Task 13:TempEval-2.
In Proc.
of the SemEval 2010, pages57?62.5
