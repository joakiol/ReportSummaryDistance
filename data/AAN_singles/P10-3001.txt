Proceedings of the ACL 2010 Student Research Workshop, pages 1?6,Uppsala, Sweden, 13 July 2010.c?2010 Association for Computational LinguisticsNon-Cooperation in DialogueBrian Pl?ussCentre for Research in ComputingThe Open UniversityMilton Keynes, UKb.pluss@open.ac.ukAbstractThis paper presents ongoing research oncomputational models for non-cooperativedialogue.
We start by analysing differ-ent levels of cooperation in conversation.Then, inspired by findings from an em-pirical study, we propose a technique formeasuring non-cooperation in political in-terviews.
Finally, we describe a researchprogramme towards obtaining a suitablemodel and discuss previous accounts forconflictive dialogue, identifying the differ-ences with our work.1 IntroductionMost approaches to modeling conversation arebased on a strong notion of cooperation be-tween the dialogue participants (DPs).
Traditionalmodels using intentions (Cohen and Levesque,1991), dialogue games (Power, 1979), sharedplans (Grosz and Sidner, 1990) or collaborativeproblem-solving (Blaylock and Allen, 2005) ex-plain dialogue situations in which DPs recogniseeach other?s intentions and, at least to a certain ex-tent, accept each other?s goals when deciding ontheir actions.
These assumptions are theoreticallygrounded, as most work in linguistics has consid-ered situations in which DPs share a common goaland cooperate to achieve it by means of conver-sation (Grice, 1975; Clark and Schaefer, 1989).They are also practically sound: dialogue modelsare usually implemented in the form of dialoguesystems, built for the purpose of providing a ser-vice to their users (e.g., TRAINS (Allen and Schu-bert, 1991)).
In this scenario, failure to cooperate,either on the side of the system or of the user, isagainst the premises on which the system is con-ceived and used.In everyday conversation, however, a greatmany situations escape the arguments above.
Con-sider the following example1:(1) PAXMAN [1]: (interrupting) Did you threaten to over-rule him?HOWARD [2]: I, I, was not entitled to instruct DerekLewis, and I did not instruct him.PAXMAN [3]: Did you threaten to overrule him?HOWARD [4]: The truth of the matter is that Mr. Mar-riott was not suspended.
I. .
.PAXMAN [5]: (overlappling) Did you threaten tooverrule him?HOWARD [6]: .
.
.
did not overrule Derek Lewis.PAXMAN [7]: Did you threaten to overrule him?HOWARD [8]: I took advice on what I could or couldnot do.
.
.PAXMAN [9]: (overlappling) Did you threaten tooverrule him, Mr. Howard?HOWARD[10]: .
.
.
and I acted scrupulously in accor-dance with that advice, I did not over-rule Derek Lewis.
.
.PAXMAN [11]: (overlapping) Did you threaten to over-rule him?HOWARD[12]: .
.
.
Mr. Marriott was not suspended.PAXMAN [13]: Did you threaten to overrule him?HOWARD[14]: (pauses) I have accounted for my deci-sion to dismiss Derek Lewis.
.
.PAXMAN [15]: (overlapping) Did you threaten to over-rule him?HOWARD[16]: .
.
.
in great detail, before the House ofCommons.PAXMAN [17]: I note that you?re not answering thequestion of whether you threatened tooverrule him.
(Newsnight, BBC, 1997)We take it for granted that, at some level, Pax-man and Howard are sharing a goal, for otherwisethey would not be having an interview.
Still, theexchange is clearly conflictive, to the point thattheir behaviour compromises the flow of the con-versation.Heritage (1998) analyses the distinctive roles ofDPs in news interviews:1BBC presenter Jeremy Paxman questions former UKHome Secretary Michael Howard with respect to a meetingin 1995 between Howard and the head of the Prison Service,Derek Lewis, about the dismissal of the governor of ParkhurstPrison, John Marriott, due to repeated security failures.
Thecase was given considerable attention in the media, as a resultof accusations by Lewis that Howard had instructed him, thusexceeding the powers of his office.1?the participants -IRs [=interviewers] and IEs[=interviewees]- exclude themselves from a widevariety of actions that they are normally free todo in the give and take of ordinary conversa-tion.
If IRs restrict themselves to asking ques-tions, then they cannot - at least overtly - expressopinions, or argue with, debate or criticize the in-terviewees?
positions nor, conversely, agree with,support or defend them.
Correspondingly, if IEsrestrict themselves to answers (or responses) toquestions, then they cannot ask questions (of IRsor other IEs), nor make unsolicited comments onprevious remarks, initiate changes of topic, or di-vert the discussion into criticisms of the IR or thebroadcasting organization.?
(Heritage, 1998, p.8)Now, consider the fragment below2:(2) PAXMAN [1]: Can you clear up whether or not youdid threaten to overrule Derek Lewiswhen you were Home Secretary?HOWARD[2]: Oh, come on, Jeremy, you are reallygoing to go back over that again?
As...PAXMAN [3]: (overlapping) You?ve had seven yearsto think about it!HOWARD[4]: (overlapping).
.
.
as, as it happens, Ididn?t.
Are you satisfied now?PAXMAN [5]: Thank you.
Why didn?t you say that atthe time?HOWARD[6]: I, well, we?ve been over this many,many times.
I, I, I knew that everyonewas crawling over every syllable I saidabout that, and I wanted to check verycarefully what I said before answeringyour question.
(Newsnight, BBC, 2004)On this occasion, Howard provides an answeralmost immediately and the flow of the conver-sation contrasts noticeably with that in (1).
Theinvestigation reported in this article aims at shed-ding light on the nature of non-cooperation in dia-logue, by capturing the intuitions that allow us todifferentiate between both conversations in termsof participant behaviour.Dialogue games supporters could say that thereis a game that describes the interaction in the firstexample.
While this might be true, such an ap-proach would force us, in the limit, to define onegame for each possible conversation that wouldnot fit a certain standard.
Walton and Krabbe(1995) attempt a game-based approach in theirstudy of natural argumentation.
They claim thata rigorous model of conversational interaction isuseful, but accept that most of the huge variety ofeveryday conversation escapes it.
Dialogue gamesare based on strict rules that capture typical dia-logue situations while leaving out considerable de-tail.
As example (1) shows, DPs behaviour can2This exchange took place seven years after (1), whenpublic awareness of the 1995 affair had dissipated.divert from the typical case in unexpected ways,falling outside the characterisation3.Nevertheless, the rules and patterns captured bygame models are useful, as they describe the ex-pected behaviour of the DPs under a certain con-versational scenario.
In our research, we aim atreconciling two worlds, using the insights from di-alogue games to provide a description of expectedbehaviour in the form of social obligations, butlooking at naturally occurring cases that deviatefrom the norm.
This, in turn, calls for a techniqueto measure non-cooperation in dialogue and in thispaper we provide one that is theoretically soundand supported by empirical evidence.The following section discusses levels of co-operation in dialogue; Section 3 presents an em-pirical study and a practical measure of non-cooperation in political interviews; in Section 4 wediscuss related work, our working hypothesis anda methodology; and Section 5 has the conclusions.2 Linguistic and Non-LinguisticCooperationCooperation in dialogue can happen at differentlevels.
In most cases, conversation supports a so-cial activity that constrains the behaviour accept-able or expected from the participants.
In addi-tion, conversational behaviour determines how co-operatively participants engage in a social activity.However, cooperation at the conversational leveldoes not necessarily translate to the social level.Consider, for instance, a witness under interroga-tion in a U.S. trial refusing to answer a question byappealing to the Fifth Amendment of the Constitu-tion4.
Such behaviour will be accepted in the con-versational setting as established by law, althoughit is not cooperative in relation with the goals ofthe trial.
Non-cooperation at the conversationallevel, on the other hand, usually results in lack ofcooperation at the social level.
Take as an exam-ple, the same witness remaining silent, rather thananswering or appealing to the Fifth Amendment.To illustrate further, consider a fictional alter-native to (1), where Howard replies by saying ?Iwill not answer that question, as it is not relevantto whether I exceeded the powers of my office?.3Consider, for instance, Giznburg?s QUD model(Ginzburg, 1996) when applied to dialogue (1), in whichHoward repeatedly fails to either accept or reject Paxman?squestion.4?No person shall (.
.
. )
be compelled in any criminal caseto be a witness against himself ?.2This is not cooperative for the interview, but it isso at the linguistic level.
It would help in preserv-ing the flow of the conversation, e.g., by triggeringa sub-dialogue to solve the disagreement.The distinction between linguistic and non-linguistic (also called task-related, high-level orsocial) cooperation has been addressed before.
At-tardo (1997) revisits Gricean pragmatics, relat-ing non-linguistic cooperation to participants?
be-haviour towards realising task-related goals, andlinguistic cooperation to assumptions on their re-spective behaviour in order to encode and decodeintended meaning.
From a computational perspec-tive, Bunt (1994) relies on a similar distinction fordefining dialogue acts.
Also, Traum and Allen(1994) introduce discourse obligations as an alter-native to joint intentions and shared plans, to al-low for models of dialogues in which participantsdo not share the same high-level goals and wherebehaviour is also determined by ?a sense of obli-gation to behave within limits set by the society?
(Traum and Allen, 1994, p.2).Walton and Krabbe (1995) proposed a typologyof dialogue based on the initial situation trigger-ing the exchange and participants?
shared aims andindividual goals.
Based on their work, Reed andLong (1997) distinguish cases where participantsfollow a common set of dialogue rules and staywithin a mutually acknowledged framework froma stronger notion in which their individual goalsare in the same direction.
Borrowing from the lat-ter, in the rest of the paper, we will speak of collab-oration when DPs share the same task-level goals,and use cooperation when participants follow theconversational obligations imposed by the socialactivity (i.e., linguistic cooperation as discussedabove).
We will not deal with collaboration here,though, as our focus is on non-cooperation.3 An Empirical StudyIn this section, we describe an empirical pilotstudy aimed at identifying a set of features thatdistinguish cooperative from non-cooperative con-versational behaviour and at establishing a suitabledomain in which to focus our work.3.1 The CorpusWe collected the transcripts of 10 adversarial di-alogues: 4 political interviews, 2 entertainmentinterviews, 1 parliamentary inquiry, 1 courtroomconfrontation, 1 courtroom interrogation and 1dispute.
The corpus includes 2 collaborative polit-ical interviews for result comparison and is nearly14,500 words long5.In a first analysis, we identified those surfacefeatures that characterised each conversation asconflictive: e.g., interruptions, short turns, unfin-ished adjacency pairs, verbatim repetition.
Next,looking for a better understanding, we preformedan in-depth case study of one of the examples, ap-proaching the analysis from different angles.By studying, e.g., the observance of turn-takingrules, the implicatures of the participants and,more extensively, how the case fitted within thenormative framework proposed by Walton andKrabbe (1995), we were able to better identify thenature of non-cooperative features present in thedialogue and establish a formalisable frameworkfor approaching non-cooperative dialogue.As for the domain, the wealth of interesting con-versational situations that arise in political inter-views make a suitable context for this research.
Inthe English-speaking world, journalists are well-known for their incisive approach to public ser-vants.
At the same time, politicians are usuallywell trained to deliver a set of key messages whenspeaking in public, and to avoid issues unfavorableto their image.
We will only consider naturally oc-curring (i.e.
non-scripted) two-party interviews.3.2 Degrees of Non-CooperationBased on the analysis described above, we pro-pose a technique for measuring non-cooperation inpolitical interviews using a set of non-cooperativefeatures (NCFs).
The number of occurrences ofthese features will determine the degree of non-cooperation (DNC) of an exchange.We grouped NCFs following three aspects ofconversation: turn-taking, grounding and speechacts (see Table 1 for a complete list).Turn-taking rules (Sacks et al, 1974) estab-lish that speakers make their contributions at ad-equate places and in particular ways.
Interlocu-tors in a political interview are expected to respecttransition-relevance places, openings and closingsaccording to social conventions.
Failing to do so(e.g., by interrupting each other) constitutes a non-cooperative feature.Grounding (Clark and Schaefer, 1989) refersto participants?
acknowledgement of each other?s5These resources are available at http://www.open.ac.uk/blogs/brianpluss/pilot-study/.3Turn-TakingFor both speakers:?
interrupting?
overlapping?
ending the exchange abruptlyGrounding Interviewer fails to either:?
ask next relevant question?
move to next topical issue?
state irrelevance of answerInterviewee fails to either:?
give relevant answer?
reject questionSpeechActsInterviewer either:?
expresses personal opinion?
argues, debates with or criticisesinterviewee?s position subjectively?
agrees with, supports or defendsinterviewee?s position subjectivelyInterviewee either:?
asks (non-CR) question?
makes irrelevant comment?
initiates change of topic?
criticises interviewerTable 1: NCFs for political interviewscontributions by providing evidence of under-standing (e.g, continued attention, relevant nextcontribution).
In political interviews a question isacknowledged by rejecting it or by providing a di-rect answer.
Likewise, answers are acknowledgedby rejecting their relevance, by asking a next rel-evant question or by moving on to a new topicalissue.
Failing to provide sufficient evidence of un-derstanding is also a non-cooperative feature.Speech Act theory (Searle, 1979) classifies ut-terances according to their associated force andpropositional content.
Going back to Heritage?scomment, in a political interview participants canfail to restrict their speech acts to the force andcontent expected for their role.
Non-cooperativefeatures related to speech acts include the inter-viewer expressing a personal opinion or criticisingsubjectively the interviewee?s positions and the in-terviewee asking questions (except for clarifica-tion requests) or making irrelevant comments.We define the degree of non-cooperation (DNC)of a dialogue as the proportion of utterances withone of more occurrences of these non-cooperativefeatures6.
Furthermore, the DNC could be thuscomputed for the whole conversation and also foreach participant, by counting only occurrences offeatures and utterances from each DP.As an example, consider an extended fragment6At this stage, all NCFs are weighted equally.
This isa simplifying assumption we will remove in the future sothat, e.g., an interviewee attempting a change of topic hasa stronger impact on the DNC than, say, one interrupting.of (1) annotated with non-cooperative features (O:overlap; GF: grounding failure; UC: unsolicitedcomment; I: interruption; TC: topic change):(3) P [11] : Uir.1 (overlapping) Did you threaten tooverrule him?OH[12] : Uie.1 .
.
.
Mr. Marriot was not suspended.
GFP [13] : Uir.2 Did you threaten to overrule him?
GFH[14] : Uie.2 (pauses) I have accounted for my de-cision to dismiss Derek Lewis.
.
.P [15] : Uir.3 (overlapping) Did you threaten tooverrule him?OH[16] : Uie.2 .
.
.
in great detail before the House ofCommons.UCP [17] : Uir.4 I note that you?re not answering thequestion whether you threatened tooverrule him.H[18] : Uie.3 Well, the important aspect of thiswhich it?s very clear to bear inmind.
.
.GFP [19] : Uir.5 (interrupting) I?m sorry, I?m going tobe frightfully rude but.
.
.IH[20] : Uie.4 Yes, you can.
.
.P [21] : Uir.6 (overlapping) I?m sorry.
.
.
OH[22] : Uie.4 (overlapping) .
.
.
you can put thequestion and I will give you, I willgive you an answer.OP [23] : Uir.7 .
.
.
it?s a straight yes-or-no questionand a straight yes-or-no answer:Uir.8 did you threaten to overrule him?H[24] : Uie.5 I discussed the matter with DerekLewis.Uie.6 I gave him the benefit of my opinion.Uie.7 I gave him the benefit of my opin-ion in strong language, but I did notinstruct him because I was not, er,entitled to instruct him.UCUie.8 I was entitled to express my opinionand that is what I did.UCP [25] : Uir.9 With respect, that is not answeringthe question of whether you threat-ened to overrule him.H[26] : Uie.9 It?s dealing with the relevant pointwhich was what I was entitled to doand what I was not entitled to do,TCUie.10 and I have dealt with this in detailbefore the House of Commons andbefore the select committee.UCTable 2 summarises non-cooperative features,utterances and the degree of non-cooperation foreach participant and for the whole fragment.P (ir) H (ie) FragmentInterruptions 1 0 1Overlaps 3 1 4Grounding Failure 1 2 3Unsolicited Comments 0 4 4Topic Change 0 1 1Total NCFs 5 8 13Utterances 9 10 19DNC 0.56 0.80 0.68Table 2: Computing the DNC for dialogue (3)The DNC was computed for all the political in-terviews in the corpus.
Table 3 shows the val-4Table 3: DNC of political interviews in the corpusues obtained.
Adversarial interviews have a largenumber of NCFs, thus a high value for the DNC.On the other hand, collaborative exchanges havelow occurrence of NCFs (or none at all)7.4 DiscussionThere have been previous approaches to modelingdialogue on the basis that participants are not al-ways fully cooperative.
Jameson (1989) presentsan extensive study for modeling bias, individualgoals, projected image and belief ascription inconversation.
User-model approaches are flexi-ble to account for intricate situations but, as notedby Taylor et al (1996), can lead to problems likeinfinite regress in nested beliefs.
Taylor (1994)addressed non-cooperative dialogue behaviour byimplementing CYNIC, a dialogue system able togenerate and recognise deception; a notion of non-cooperation weaker than the one we address.More recently, Traum (2008) brought attentionto the need for computational accounts of dia-logue situations in which a broader notion of co-operation is not assumed: e.g., intelligent tutoringsystems, bargaining agents, role-playing training7These results and the validity of DNC measure need fur-ther evaluation.
We are currently performing two studies: oneto determine inter-annotator agreement of the coding schemefor NCFs, and another to test how NCFs correlate to humanjudgements of non-cooperative conversational behaviour.agents8.
Traum?s work on conflictive dialogue ismainly aimed at creating virtual humans with abil-ities to engage in adversarial dialogue.
Traum etal.
(2008) present a model of conversation strate-gies for negotiation, that includes variables repre-senting trust, politeness and emotions, and a set ofconversational strategies.
Despite being adversar-ial in nature, the conversational scenarios are mod-eled by means of rules, that are followed by theinterlocutors, according to the values of some ofthe variables.
Hence, the dialogues are adversar-ial, but cooperative under our characterisation oflinguistic non-cooperation, and it is not clear howeffectively the model accounts for cases in whichparticipants fail to follow the rules of a scenario.4.1 Working HypothesisFinding a suitable model of non-cooperative dia-logue involves bridging the gap between the the-oretical aspects mentioned so far and the evi-dence in the empirical data of the previous section.Following Traum and Allen (1994), we base onthe hypothesis that non-cooperative features resultfrom decisions that participants make during theconversation, by considering the obligations im-posed by the social activity and their individualgoals, with an adequate configuration of the pri-orities for goals and obligations.Thus, a participant with high priorities for in-dividual goals might compromise the workings ofa conversation by choosing contributions that goagainst the norms of the social activity.
On theother hand, participants with higher priorities as-sociated with obligations will favour contributionsconsistent with the rules of the social activity.4.2 Research MethodologyFor the next steps of the project, we will constructa model based on the hypothesis and test it bymeans of simulation9.The construction of the model is a formaliza-tion of the working hypothesis, including rules forpolitical interviews, goals, obligations, prioritiesand a dialogue management component.
At the8Traum also provides a list of ?behaviours of interest?,along the lines of the NCFs we identified above: e.g., uni-lateral topic shifts or topic maintenance, unhelpful criticism,withholding of information, lying, deception, antagonism.9The use of simulation in dialogue modeling was pio-neered by Power (1979).
It suits our project better than al-ternatives (e.g., Wizard-of-Oz, dialogue systems), by makingit easier to introduce modifications, do re-runs, and generatea large number of cases with different parameter settings.5moment of writing, we are investigating the lineof research on obligation-driven dialogue model-ing, initiated by Traum and Allen (1994) and de-veloped further by Poesio and Traum (1998) andKreutel and Matheson (2003).For the simulation, DPs will be autonomousconversational agents with a cognitive state con-sisting of goals, a notion of their expected be-haviour in a political interview, priorities, andsome knowledge of the world.
We are currentlyimplementing a prototype based on EDIS (Mathe-son et al, 2000).5 ConclusionsIn this paper we presented an attempt to shed lighton non-cooperation in dialogue by proposing apractical measure of the degree of linguistic non-cooperation in political interviews and a method-ology towards a suitable computational model.AcknowledgmentsWe would like to thank the NLG group at TheOpen University (especially Paul Piwek, RichardPower and Sandra Williams) for helpful dis-cussion and comments on previous versions ofthis paper; and three anonymous reviewers forthoughtful feedback and suggestions.ReferencesJ.F.
Allen and L.K.
Schubert.
1991.
The TRAINSproject.
TRAINS Technical Note 91-1.
ComputerScience Dept.
University of Rochester.S.
Attardo.
1997.
Locutionary and perlocutionary co-operation: The perlocutionary cooperative principle.Journal of Pragmatics, 27(6):753?779.N.
Blaylock and J. Allen.
2005.
A collaborativeproblem-solving model of dialogue.
In Proceedingsof the 6th SIGdial Workshop on Discourse and Dia-logue, pages 200?211, Lisbon, Portugal.Harry Bunt.
1994.
Context and dialogue control.THINK Quarterly, 3.H.H.
Clark and E.F. Schaefer.
1989.
Contributing todiscourse.
Cognitive science, 13(2):259?294.P.R.
Cohen and H.J.
Levesque.
1991.
Confirmationsand joint action.
In Proceedings of the 12 th Inter-national Joint Conference on Artificial Intelligence,pages 951?957.J.
Ginzburg.
1996.
Interrogatives: Questions, facts anddialogue.
The handbook of contemporary semantictheory, 5:359?423.H.
P. Grice.
1975.
Logic and conversation.
Syntax andSemantics, 3:41?58.B.J.
Grosz and C.L.
Sidner.
1990.
Plans for discourse.Intentions in communication, pages 417?444.J.
Heritage.
1998.
Conversation analysis and insti-tutional talk.
Analyzing distinctive turn-taking sys-tems.
In Proceedings of the 6th InternationalCongress of IADA, Tubingen, Niemeyer.A.
Jameson.
1989.
But what will the listener think?Belief ascription and image maintenance in dialog.User Models in Dialog Systems.
Springer-Verlag,pages 255?312.J.
Kreutel and C. Matheson.
2003.
Incremental in-formation state updates in an obligation-driven dia-logue model.
Logic Journal of IGPL, 11(4):485.C.
Matheson, M. Poesio, and D. Traum.
2000.
Mod-elling grounding and discourse obligations using up-date rules.
In Proceedings of the 1st NAACL confer-ence, pages 1?8, San Francisco, CA, USA.M.
Poesio and D. Traum.
1998.
Towards an ax-iomatization of dialogue acts.
In Proceedings ofthe Twente Workshop on the Formal Semantics andPragmatics of Dialogues, pages 207?222.R.
Power.
1979.
The organisation of purposeful dia-logues.
Linguistics, 17:107?152.C.
Reed and D. Long.
1997.
Collaboration, cooper-ation and dialogue classification.
Working Notes ofthe IJCAI97 Workshop on Collaboration, Cooper-ation and Conflict in Dialogue Systems, IJCAI 97,pages 73?78.H.
Sacks, E.A.
Schegloff, and G. Jefferson.
1974.
Asimplest systematics for the organization of turn-taking for conversation.
Language, pages 696?735.J.R.
Searle.
1979.
A Taxonomy of lllocutionary Acts.Expression and meaning: studies in the theory ofspeech acts, pages 1?29.J.
A. Taylor, J. Carletta, and C. Mellish.
1996.
Re-quirements for belief models in cooperative dia-logue.
User Modeling and User-Adapted Interac-tion, 6(1):23?68.J.A.
Taylor.
1994.
A multi-agent planner for mod-elling dialogue.
Ph.D. Thesis, School of Cognitiveand Computing Sciences, University of Sussex.D.R.
Traum and J.F.
Allen.
1994.
Discourse obli-gations in dialogue processing.
In Proceedings ofthe 32nd annual meeting of ACL, pages 1?8.
Mor-ristown, NJ, USA.D.
Traum, W. Swartout, J. Gratch, and S. Marsella.2008.
A virtual human dialogue model for non-teaminteraction.
Recent Trends in Discourse and Dia-logue.
Springer.D.
Traum.
2008.
Extended Abstract: ComputationalModels of Non-cooperative dialogue.
In Proceed-ings of LONDIAL 2008, the 12th Workshop on theSemantics and Pragmatics of Dialogue, pages 11?14, London, UK.D.
Walton and E. Krabbe.
1995.
Commitment in di-alogue: Basic concepts of interpersonal reasoning.State University of New York Press.6
