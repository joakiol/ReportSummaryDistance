Book ReviewsIntroducing Speech and Language ProcessingJohn Coleman(University of Oxford)Cambridge University Press (Cambridge introductions to language andlinguistics), 2005, xi+301 pp; hardbound, ISBN 0-521-82365-X, $90.00; paperbound,ISBN 0-521-53069-5, $39.99Reviewed byMary HarperPurdue UniversityIn October 2003, a group of multidisciplinary researchers convened at the Symposiumon Next Generation Automatic Speech Recognition (ASR) to consider new directions inbuilding ASR systems (Lee 2003).
Although the workshop?s goal of ?integrating multi-disciplinary sources of knowledge, from acoustics, speech, linguistics, cognitive science,signal processing, human computer interaction, and computer science, into every stageof ASR component and system design?
is an important goal, there remains a divideamong these communities that can only be addressed through the educational process.The book Introducing Speech and Language Processing by John Coleman represents a boldeffort to educate students in speech science about some of the important methods usedin speech and natural language processing (NLP).
This book represents an importantfirst step for forging effective collaborations with the speech and language processingcommunities.Coleman states in chapter 1 of his book that ?This is a first, basic, elementary andshort textbook in speech and natural language processing for beginners with little or noprevious experience of computer programming?
(page 2).
Coleman targets the book atstudents in a variety of disciplines, including arts, humanities, linguistics, psychology,and speech science, as well as early science and engineering students who want aglimpse into natural language and speech processing.
However, since it assumes priorknowledge of basic linguistics, the text is likely to be less accessible to traditionalscience and engineering students.
Coleman?s motivation for writing this book is thatthe currently available textbooks in NLP and speech require knowledge that studentsfrom more of a humanities background would not have (e.g., programming, signalprocessing).
The author also astutely points out that there tends to be a divide betweenthe areas of signal processing and computational linguistics, although in recent yearswith ubiquity of statistical modeling and machine learning techniques in both areas,this divide is becoming much smaller.
The author?s motivation for this book is excellent:?a refusal to let the old sociological divide between arts and sciences stand in the wayof a new wave of spoken language researchers with a foot in both camps?
(page 4).The textbook covers a variety of techniques in speech and natural language process-ing, along with computer programs implementing many of them in either C or Prolog,and it capitalizes on Coleman?s insights from courses offered to graduate linguisticsstudents.
It comes with a companion CD containing software needed to compile and/orexecute the programs in the book, as well as source code for all of the describedimplementations.
The readme file on the CD contains helpful installation notes, whilethe text describes how to compile and use each of the programs.
Chapter 1 containsComputational Linguistics Volume 32, Number 1a comprehensive list of topics that are covered from ?first principles,?
provides de-tails about the computational environment that is needed to compile and execute theprograms provided on the CD, and a listing of computer skills one would need toget started.
Coleman encourages the reader/student (I will use student henceforth) notjust to run the programs but to also to ?tinker?
with them in order to gain a deeperunderstanding of the way they work.
Chapter 1 also lays out the structure of the textgraphically in order to depict the dependencies among the chapters.
In addition to thebook chapters, there is an appendix on ASCII characters, a helpful glossary, a list ofreferences, and a comprehensive index.
Importantly, there is also a companion websitewith errata, solutions to selected exercises, bug reports, software updates, additionalprograms, links to third-party software, and some nice bibliography links.
Presumably,this page will be updated over time.The overall chapter organization of the book is quite nice.
Each chapter begins witha preview and a list of key terms (allowing the student an opportunity to look up thedefinitions prior to beginning to read the chapter content) and ends with a chaptersummary, a set of exercises that are helpful for developing a deeper understanding ofthe materials discussed in the chapter, suggestions for further reading, and suggestionsfor readings to prepare for the next chapter.
I will discuss chapters 2 through 9 in turn.Chapter 2 discusses issues related to the digital representation of a signal with afocus on the composition of a sound file and how such a file can be loaded into a sound-editing program for audio display.
The chapter starts off by guiding the student throughthe process of listening to a cosine waveform and then viewing the same file using asound editing program such as Cool Edit 2000.
The student is asked to fill in a worksheetwith values for a cosine function and then plot the values.
Coleman then presentsimportant information on the digital representation of sound and on sampling theory.Given this knowledge, the student is walked through the process of generating andplaying a cosine wave.
The chapter contains a just-in-time introduction to C sufficientfor a student to read and comprehend the cosine wave generation program coswave.c.Various computing terms (e.g., bit, compilation, machine code) are defined, followedby a discussion of C numeric data types and differences in representation across ar-chitecture.
The C code presented in this chapter makes concrete Coleman?s discussionof loops, arrays, calculation of mathematical expressions, overall program layout, andfile output.
The chapter ends with several helpful exercises.
The first provides a verydetailed set of instructions for compiling and executing the coswave program and thenplaying the generated output signal in Cool Edit 2000.
It should be noted that Cool Edit2000 is not a public-domain package and is no longer available through the originaldevelopers.
Alternatives mentioned on the text?s Web site (e.g., wavesurfer, Praat) canbe used instead, although no details are offered about using them for the exercises.Students may face some challenges in opening and playing raw data files with thesealternatives.Chapter 3 introduces methods for modifying the digital representations of sound; inparticular, the concept of filtering is introduced, followed by a very brief discussion ofhow filters are employed in a Klatt formant synthesizer.
The chapter first discusses howoperations can be applied to number sequences in C to set the stage for discussion ofseveral speech-processing applications.
RMS energy is then defined and a correspond-ing C program is discussed in detail.
Next, a moving-average program is presented asan example of a low-pass filter.
The concept of recursion is next introduced in order topave the way for a discussion of IIR (Infinite Impulse Response) filters.
High-, low-, andband-pass filters are defined and tables of coefficients for various filters are provided.An implementation of an IIR filter is discussed quite briefly; here the author relies on the138Book Reviewsfact that there is similarity to the earlier moving-average program.
Finally, after the basicintroduction to filters, the Klatt synthesizer is discussed and a schematic diagram for thesystem is presented together with a brief discussion of the control parameters that areused to synthesize sound.
IIR filters are tied in because they are used for modeling theglottal wave and filter-specific frequency components in order to obtain the resonantfrequencies of the vocal tract required for the sound to be synthesized.
A consonant?vowel example is used to demonstrate the synthesizer in action.
There is a series ofthree exercises at the end of the chapter that should help the student get a better senseof filters and the type of sound generated by the Klatt synthesizer.
The synthesizerexercises have a cookbook feel to them and give only a glimpse of what is needed toactually synthesize speech.
At the end of the chapter, no further readings on filters areprovided, although readings are recommended for the Klatt synthesizer and methodsfor estimating its parameters.Chapter 4 discusses several programs to extract acoustic parameters from a speechsignal.
First up is the fast Fourier transform (FFT), for which a C implementation ispresented and described in detail.
The student is asked to apply the compiled codeto an example speech file in order to generate its spectrum, which is then plotted inExcel or Matlab for comparison to the spectral analysis obtained using Cool Edit.
Giventhis example, there is a discussion of the types of peaks found in the spectrum, theresonances of the vocal tract, and the harmonics, as a prelude to the discussion ofcepstral analysis.
Coleman first provides a high-level discussion of cepstral analysis,which employs an inverse FFT, followed by the discussion of its C implementation andan example using the executable.
Cepstral analysis is then used to build a rudimentarypitch tracker, which is applied to a speech example.
This leads to the discussion ofa voicing detection algorithm.
Next, the autocorrelation method for pitch tracking ispresented together with its C implementation.
Finally, the chapter discusses linearpredictive coding (LPC) and various applications.
The chapter ends with exercises tocompare the cepstral and autocorrelation pitch trackers, to modify the output of the LPCprogram, and to analyze the vowels in a speech sample and use the LPC spectrum toestimate their formants.
Additional readings are provided on the algorithms presentedin this chapter.Chapter 5 offers a change of pace as the book introduces finite-state machines(FSMs) with a focus initially on symbolic language applications.
There is a shift fromC to Prolog, although it would have been perhaps more coherent to stick with C. Thediscussion of the peculiarities of Prolog could be distracting to a novice programmer.Furthermore, the representation of an FSM in Prolog is tedious to read, and it maybe difficult for the uninitiated to observe correspondences between the Prolog codeand depictions of corresponding models.
Simple examples are used to introduce theconcept of, rather than a formal definition of, FSMs.
Issues of coverage, over-generation,determinism, and nondeterminism of an FSM are discussed briefly.
Although Colemanmakes clear that backtracking is an issue for a nondeterministic FSM and notes thatthere are methods for converting such an FSM to a representationally equivalent deter-ministic form, existing tools that could be used for carrying out this conversion (e.g., theAT&T FSM library) are not discussed.
Coleman next presents a Prolog implementationof an interesting English-like monosyllable FSM.
A box is used to introduce a collectionof facts about Prolog, and then there is a walk-through of the code.
A nice set of exercisesfollows in which the student loads the FSM program and executes it in various ways,followed by a discussion of some examples of using the FSM to generate strings withparticular constraints.
A more formal presentation of FSMs is then provided togeth-er with a discussion of the state-transition-table representation.
The chapter ends by139Computational Linguistics Volume 32, Number 1introducing the concept of finite-state transducers and providing several examples fromvarious levels of processing, including phonetics, phonology, orthography, and syntax.Exercises at the end of the chapter build nicely upon the Prolog code already discussed.The suggested additional readings are appropriate, but perhaps too broad, as many aretextbooks.Chapter 6 turns to the topic of automatic speech recognition.
Coleman providesa general discussion of knowledge-based and pattern-recognition approaches to ASRwithout a historical perspective.
The knowledge-based method with its focus on fea-ture extraction and knowledge integration is described at a very high level withoutthe benefit of any hands-on exercises.
Coleman uses dynamic time warping (DTW)to exemplify the pattern-matching approach, as it is a fairly straightforward dynamicprogramming algorithm of which the student can gain some understanding by fillingin tables of distances.
The chapter also contains a nice discussion on the sources ofvariability in speech, although no insights are offered on how they would be addressedby the two approaches to ASR.
Only two exercises are found in this chapter, one to fillin matrices used by the dynamic time-warping algorithm and one asking the student tothink about pitfalls of the pattern-matching approach.
The chapter does not discuss theimplementation of any of the methods discussed, although I believe a C implementationof DTW could have been added to good effect.
There are some helpful recommendedreadings on ASR techniques, many of which are textbooks or edited books of papers.Chapter 7 introduces probabilistic finite-state approaches, bringing together acous-tic analysis with finite-state models.
The chapter begins with a discussion of Markovmodels and the use of probabilistic methods for coping with uncertainty.
Part-of-speechn-gram models are introduced together with a very brief discussion of probabilitiesand Markov models (along with a few simple exercises).
Coleman then provides aninformal discussion of the hidden Markov model (HMM), followed by a discussion oftrigram models, data incompleteness, and backoff.
Finally, the three basic problems forHMMs (Rabiner 1989; Rabiner and Juang 1993) are discussed, providing the studentwith a clearer understanding of the kinds of questions that can be addressed with them.There are two very short sections on using HMMs for part-of-speech tagging and speechrecognition, but there are no code or exercises associated with them.
The chapter endswith a discussion of Chomsky?s objections to Markov models and a response to each.The only exercises appearing in this chapter concern probability and Markov models.The chapter does not discuss implementations of any of the approaches discussed, andyet it would seem that the student would gain a deeper understanding of many of thetopics presented in this chapter by playing, for example, with a simple part-of-speechtagger.
There are many publicly available resources that could be used to fill in thishole.Chapter 8 moves on to parsing, building upon the knowledge of Prolog gainedin chapter 5.
A simple definite-clause grammar is introduced, followed by an intuitivediscussion of parsing and recursive descent parsers.
A second grammar, dog grammar.pl,is then discussed together with difference lists in Prolog so that the grammar can beupdated to produce a tree structure.
Coleman then provides an example grammarthat breaks phoneme sequences into syllables.
The chapter ends with a very briefintroduction to various parsing algorithms, chart parsing, issues of search, deterministicparsing, and parallel parsing.
The chapter would have been improved by the additionof exercises; however, the student could load the grammars discussed in the chapterinto Prolog and play with them.
Several textbooks are recommended for additionalreading, although the novice might gain a richer perspective by consulting the chapterson parsing of Allen (1994).140Book ReviewsChapter 9, the final chapter in the book, discusses the incorporation of probabilityinto a context-free parsing algorithm.
Coleman begins with a discussion about why aprobabilistic approach is useful in computational linguistics, ranging from the fact thathuman judgments of grammaticality are gradient and at times uncertain of providing agood mechanism to account for collocations and the learnability of grammars.
A simpleprobabilistic context-free grammar (CFG) is then presented, along with a discussion ofhow to obtain the grammar rules and estimate their probabilities.
The chapter ends bydiscussing limitations of probabilistic CFGs and briefly introducing two alternative ap-proaches, tree-adjoining grammars and data-oriented parsing.
This chapter contains noexercises for the student.
However, it does provide a list of materials to assist the studentin learning more about C programming, digital signal processing, the Klatt synthesizer,speech recognition, Prolog, computational linguistics, and probabilistic grammars.Overall, Coleman has written a textbook that more than adequately fulfills his goalof introducing the uninitiated to a variety of techniques in speech and language process-ing.
Due to its broad coverage, the text is unable to delve deeply into many of the details,although this is mitigated in part by the fact that he provides additional readings forstudents with an interest in a particular topic.
The reading list on the companion websitewould be improved by including more modern sources, pointers to current conferencesand journals in speech and natural language processing (e.g., Bird 2005), and links tohelpful resources available on the Internet (e.g., DISC 1999; Hunt 1997; Jamieson 2002;Kita 2000; Krauwer 2005; Manning 2005; Picone 2005).
Additionally, although the bookis not aimed at students with a strong background in mathematics or computer science,they would benefit from additional readings in these areas.
The book would benefitfrom additional editing, as it contains errors that could easily confuse a novice, as wellas from the addition of more hands-on exercises, particularly in Chapters 6 through 9.Quibbles aside, if the book builds bridges between the communities Coleman desires,it will have a broad impact that could be felt for years to come.
I believe education is animportant first step to building multidisciplinary solutions to some of the most pressingproblems in speech and natural language processing.
It would be wonderful to see morebooks with Coleman?s vision.ReferencesAllen, James.
1994.
Natural LanguageUnderstanding.
The Benjamin/CummingsPublishing Company Inc., RedwoodCity, CA.Bird, Steven, editor.
2005.
ACL Anthology:A digital archive of research papers incomputational linguistics.acl.ldc.upenn.edu/.DISC.
1999.
A survey of existing methodsand tools for developing andevaluation of speech synthesis andof commercial speech synthesissystems.
www.disc2.dk/tools/SGsurvey.html.Hunt, Andrew.
1997.
CompS?peechfrequently asked questions.fife.speech.cs.cmu.edu/comp.speech/.Jamieson, Leah H. 2002.
Notes for EE649lectures: Speech processing bycomputer.
shay.ecn.purdue.edu/ee649/notes/.Kita, Kenji.
2000.
Speech and language Webresources.
www-a2k.is.tokushima-u.ac.jp/member/kita/NLP/.Krauwer, Steven.
2005.
Tools for NLP andspeech.
www.elsnet.org/toolslist.html.Lee, Chin-Hui.
2003.
NSF Symposium onNext Generation ASR.users.ece.gatech.edu/chl/ngasr03/.Manning, Christopher.
2005.
Linguistics,natural language, and computationallinguistics meta-index.
www-nlp.stanford.edu/ links/ linguistics.html.Picone, Joseph.
2005.
Automatic speechrecognition.
www.cavs.msstate.edu/hse/ies/projects/speech/.Rabiner, Lawrence R. 1989.
A tutorial onhidden Markov models and selectedapplications in speech recognition.Proceedings of the IEEE, 77(2):257?286.Rabiner, Lawrence and Biing-Hwang Juang.1993.
Fundamentals of Speech Recognition.Prentice-Hall, Inc., Upper Saddle River, NJ.141Computational Linguistics Volume 32, Number 1Mary Harper joined the faculty of Purdue University in 1989, where she holds the rank of Professorin the School of Electrical and Computer Engineering.
She recently finished a term of slightlymore than three years as the Program Director for the Human Language and CommunicationProgram at the National Science Foundation with the goal of advancing research in speech, nat-ural language, and multimodal processing.
Her research focuses on computer modeling of humancommunication with a focus on methods for incorporating multiple types of knowledge sources,including lexical, syntactic, prosodic, and, most recently, visual sources.
Harper is currently at theCenter for Advanced Study of Language, University of Maryland, College Park, MD 20742-0025;e-mail: harper@purdue.edu, mharper@casl.umd.edu; URL: yara.ecn.purdue.edu/?harper.142
