Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1598?1607,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsJoint Graphical Models for Date Selection in Timeline SummarizationGiang TranL3S Research CenterLeibniz-University Hannovergtran@l3s.deEelco HerderL3S Research CenterLeibniz-University Hannoverherder@l3s.deKatja MarkertL3S Research CenterLeibniz-University Hannoverand School of ComputingUniversity of Leedsmarkert@l3s.deAbstractAutomatic timeline summarization (TLS)generates precise, dated overviews over(often prolonged) events, such as wars oreconomic crises.
One subtask of TLS se-lects the most important dates for an eventwithin a certain time frame.
Date selec-tion has up to now been handled via su-pervised machine learning approaches thatestimate the importance of each date sepa-rately, using features such as the frequencyof date mentions in news corpora.
This ap-proach neglects interactions between dif-ferent dates that occur due to connectionsbetween subevents.
We therefore suggesta joint graphical model for date selection.Even unsupervised versions of this modelperform as well as supervised state-of-the-art approaches.
With parameter tuning ontraining data, it outperforms prior super-vised models by a considerable margin.1 IntroductionMajor events (such as the Egypt revolution startingin 2011) often last over a long period of time andhave impact for a considerable time afterwards.
Inorder to find out what happened when during suchan event, time-related queries to search engines areoften insufficient as traditional IR does not handletime-related queries well (Foley and Allan, 2015).To provide readers with comprehensive overviewsof long events, many news outlets employ time-line summaries: a timeline summary is a list ofselected dates with a few sentences describing themost important events on each date.
An examplecan be seen in Table 1.
Timelines allow the readerto gain a quick overview over a complex event andto answer questions such as: How and when didthe event start?
What were the main consequencesof the initial events?
What happened to the mainprotagonists in the event?
In addition, timelinesare frequent means in education (such as historyteaching) so that their generation is relevant foreducation as well as journalism.
(a1) 2011-01-25Egyptians hold nationwide demonstrations against the au-thoritarian rule of Hosni Mubarak, who has led the countryfor nearly three decades.
(a2) 2011-01-26A large security force moves into Cairo?s Tahrir Square(a3) 2011-01-28Protesters burn down the ruling party?s headquarters, andthe military is deployed.
(a4) 2011-02-11Mubarak steps down and turns power over to the military.
(a5) 2011-03-19In the first post Mubarak vote, Egyptians cast ballots onconstitutional amendments .
.
.
, including scheduling thefirst parliamentary and presidential elections(a8) 2012-04-20The presidential campaign officially begins.
(a10) 2012-06-24Election officials declare Morsi the winner(a26) 2013-07-03Egypt?s military chief says Morsi has been replaced by AdlyMansour, the chief justice of constitutional court.Table 1: A timeline about the Egypt revolution published bythe Associated Press (AP).
We leave out intermediate datesdue to space constraints.
The whole timeline includes 30dates between 2011-01-25 and 2013-07-07.Though convenient for the reader, the manualcreation of a timeline can take a long time evenfor experts.
For example, the creator of the start-up Timeline says that it initially took a multi-person team a full work day to create a singletimeline.1Therefore, automatic timeline summa-rization (TLS) has emerged as an NLP task in thepast few years (Tran et al, 2013a; Kessler et al,2012; Nguyen et al, 2014; Yan et al, 2011b; Yanet al, 2011a; Wang et al, 2012; Tran et al, 2013b;Tran et al, 2015).
TLS has been divided into twosubtasks: (i) ranking the dates between beginning1http://www.niemanlab.org/2015/02/timeline-is-providing-historical-context-to-the-news-but-is-there-a-business-model-to-support-it/.1598and end of the timeline in order of importance, toachieve date selection and (ii) generating a gooddaily summary for each of the selected dates.
Inthis paper, we tackle the first task.
Date selectionis challenging, as normally only a small set of theavailable dates is chosen for inclusion in the time-line (see Table 1).
Date selection may be partiallysubjective: different journalists might include dif-ferent dates.2Existing approaches to date selection (Kessleret al, 2012; Tran et al, 2013a) use supervised ma-chine learning, where each date receives a scorefor ranking the dates.
Features used (such as fre-quency of date mention) are extracted from a cor-pus of event-related newspaper articles.
Thoughthe features are well-explored, the models scoreeach date independently of other dates.In contrast, we argue that interaction betweendates should be taken into account.
Timelinesummaries tend to include ?substories?
in whichthe majority of selected dates are part of a chainof events that share major actors or demonstratecause-effect.
Table 1 shows at least two suchchains: the (a1-4-5) chain of protests leading toMubarak?s resignation and the necessity of newelections, as well as the similar (a8-10-26) chainon Mursi.
These chains can also be observed in thecorresponding news articles.
For example, somebackground articles on Mubarak?s step-down willlikely explain the reasons behind it.
However, ex-tracting such causal information can be difficult,as demonstrated by the still low results for dis-course relation extraction (Lin et al, 2014; Braudand Denis, 2014).
Instead, we use date referencegraphs, which model which date refers to whichother date.
In our example, articles published onMubarak?s resignation date might refer to the datewhen the protest started.
Although weaker thandirect causal links, these links are easy to extractand we will show that they are very useful.
In ad-dition, references from important dates (such asMubarak?s resignation date) should be weightedhigher than other references.
This is akin to IRmodels such as PageRank, which weigh links frompopular pages higher than links from less popularpages.The main contributions of this work are: (i)we leverage interaction between dates via date ref-erence graphs as a basis for date selection in TLS2Note that the date selection task uses dates as proxies forimportant events on that date.
(ii) we provide a novel random walk model on thisgraph that incorporates both topical importance ofreferring sentences as well as frequency and tem-poral distance of references.
We propose both un-supervised as well as supervised versions of thismodel.We show that the proposed date selectionapproach outperforms previous approaches withevaluations on four real-life, long-term newsevents.
We also discuss variations in timeline con-struction over different events, as well as by dif-ferent journalists.2 Related WorkTimeline summarization is a special case of multi-document summarization (MDS).
As TLS orga-nizes events by date, timelines can be generatedby MDS systems (such as (Radev et al, 2004b;Radev et al, 2004a; McKeown et al, 2003; Erkanand Radev, 2004; Metzler and Kanungo, 2008;Hong and Nenkova, 2014) by applying their sum-marization techniques on news articles for everyindividual date to create corresponding daily sum-maries.
However, manually written timelines nor-mally only include a small number of dates; inaddition, the temporal component imposes con-straints on sentence selection for timeline sum-marization, such as the preference for little over-lap between sentences selected for different dates(Yan et al, 2011b).Many studies specific to timeline summariza-tion, such as (Swan and Allan, 2000; Allan et al,2001; Chieu and Lee, 2004; Yan et al, 2011b;Tran et al, 2015), focus on the extraction of salientsentences or headlines for generating the textualcontent of timelines.
They assume either that thedates are given in advance or they use simple mea-sures such as burstiness (Chieu and Lee, 2004;Yan et al, 2011b) for date selection, where bursti-ness relies on the number of date mentions.Prior approaches dedicated specifically to dateselection are Tran et al (2013a) and Kessler etal.
(2012).3They use supervised machine learn-ing methods that score dates independently ofeach other.
Features are extracted from a cor-pus of event-related newspaper articles, includingfrequency-based features (such as how often thedate is referred to in the corpus), temporal distancefeatures (such as how long into the future a date3Kessler et al (2012) is also used in Nguyen et al (2014)?ssystem.1599keeps being referred to) and topical features (suchas whether the date mention is associated with themost significant keywords of the event).
We, how-ever, score dates jointly, making use of interac-tions between dates in a graphical model.
Thisimproves substantially over prior approaches.
Wealso propose unsupervised variations that performcompetitively to prior supervised models.3 Problem Definition and ApproachSimilar to Kessler et al (2012) and Tran et al(2013a), we use the day as the timeline time unit(so, for example, we exclude hourly timelines).3.1 Problem DefinitionGiven a main event and a time window [t1, t2]within the event duration, our task is to select thetop k dates (d1, d2, ..., dk) ?
[t1, t2], when themost important (sub)events occurred.
Therefore,timelines of variable length can be constructed.Like (Kessler et al, 2012; Tran et al, 2013a), wealso assume that we have a corpus C, consistingof news articles about the main event.
This corpusgives evidence about the dates in [t1, t2].3.2 Proposed ApproachWe build a date reference graph, which is a fullydirected graph G = (V, E), where V is the set ofdates mentioned in any text in corpus C, includingpublication dates.
The edges E = {e(di, dj)} in-dicate that at least one text published on direfersto the date dj.We represent each such link asa multi-value tuple e(di, dj) =(Mij, freq(di, dj), Itemporal(di, dj), Itopical(di, dj))to integrate different measures of date importance.The first value, Mij=1Nexpresses the priorstochastic transitional probability between 2dates where N = |V|.
The others express thestrength of the connection between diand djmodelled by the following aspects: frequency(freq), temporal influence (Itemporal) and topicalinfluence (Itopical).
We also suggest differentcombinations of these parameters.Then we introduce a random walk model thatuses these perspectives to rank the collection ofdates.Frequency of References.
When a date djis re-ferred to from either a past or future news article(published on di), it is likely involved in the eventsthat are reported in that article.
An example pub-lished on Mubarak?s resignation date and referringback to the protest start can be seen below:(1) On January 25, an uprising of Egyptians erupted callingfor Mubaraks resignation as president.
Protests contin-ued to grow .
.
.
(CBS Detroit, 2011-02-11)We hypothesize that the more frequent suchreferences are, the stronger this involvement is.Hence, we compute freq(di, dj) as the numberof references to djfrom news articles publishedon di.
While prior work (Kessler et al, 2012)uses aggregate frequency of references to djoverthe whole corpus as a feature, they do not handlethe interaction between dates and can therefore notscore dates jointly.Topical Influence.
In Example 1 above, the ref-erence sentence mentions only major actors in theEgypt crisis (Mubarak, Egyptians) as well as onlymajor subevents (uprising, protests).
This makesfor a link between 2011-02-11 (publication date)and 2011-01-25 (referred date) that is relevant tothe main event and emphasises the importance ofthe referred date.
In contrast, Example 2 also talksabout less salient entities in context of the Egyptrevolution and makes for a less topical link be-tween 2011-02-02 (publication date) and 2011-01-25 (referred date).
(2) Mr Ghonim is Google?s head of marketing for Mid-dle East and North Africa and was in Egypt when theprotests started on Jan 25 (DailyMail, 2011-02-02).We quantify the topical influence between datesas follows: Let Si?j= {sij} be the set of sen-tences that are published in diand refer to dj.
Weare interested in how relevant this connection is tothe overall news event, looking at the content inSi?j.
To do so, we represent the overall contentof the news collection by a set of keywords Q ={q1, q2, ..., qn}, which are computed via TextRank(Mihalcea and Tarau, 2004).4We compute a rel-evance score for each sentence sijin Si?jby thefamous Okapi BM25 function (Robertson et al,1994), which ranks a sentence more topical if itcontains more as well as more of the most salientcollection keywords Q.5We compute topical in-fluence (Itopical) as either the maximum value orthe sum value of the relevance scores of all sij.Imax topical(di, dj) = maxsij?Si?jBM25(sij, Q) (3)Ifreq?topical(di, dj) =?sij?Si?jBM25(sij, Q) (4)4We set n=20 in practice.5We use the standard BM25 parameter settings k1= 1.2and b = 0.751600Intuitively, Ifreq?topical(di, dj) is proportionalto the size of Si?jas well as to the relevancescores of its sentences whereas Imax topical(di, dj)does not consider reference frequency at all.When djis not mentioned by any articles pub-lished on di, the value of the topical influence isequal to zero.Temporal Influence.
The longer ago an eventhappened the more likely it is to have been for-gotten.
Only very important events are referred toover long time frames.
We therefore hypothesisethat a date djis more influential (for another datedi) if dimentions djand the temporal distancebetween the two dates is high.
Overall, djgath-ers importance with several long-term references.Ex.
5 showcases an example:(5) Military generals took over power from Mubarak whenhe stepped down on February 11 last year.
(Daily Mail,2012-01-25).We define the temporal influence of an existingedge Itemporal(di, dj) as either the absolute valueof temporal distance between the two dates or bythe product of the temporal distance with the num-ber of references freq(di, dj).
In the second com-putation, the temporal influence between two datesincreases when direferences djmore than once.I|temporal|(di, dj) = ?t = |di?
dj| (6)Ifreq?temporal(di, dj) = freq(di, dj) ?
|di?
dj| (7)When djis not mentioned by any articles pub-lished on di, the temporal influence is set as zero.Random Walk Model for Date Ranking.
Arandom walk on a given graph is a Markov pro-cess, where each node represents a state and awalk transiting from one state to another state isbased on a transition probability matrix.
One well-known random walk algorithm is PageRank (Pageet al, 1999), which models web surfer behavior todetermine the importance of web pages with thefollowing formula:xt(j) = ?
?i?L?jMijxt?1(i) + (1?
?
)vj, (8)where Mijis the stochastic transition probabilityfrom page pito pj, xt(j) is the importance scoreof page pjat step t, ?
is a damping factor thatcontrols how often the walker jumps to an arbi-trary node, vjis the initial probabilistic impor-tance score (generally set to 1/N , where N is thenumber of nodes in the graph), and L?iis the setof incoming links of page pi.
When t is iteratedenough, the importance score vector reaches a sta-tionary distribution that can be used for rankingpages.The traditional PageRank process in Eq.
8 cap-tures only the observed linking characteristics ofnodes but ignores other sources of informationwhich can be indicators for their importance.We extend the model by introducing aninfluence-based random walk model (IRW) thatallows the random walker to take into accountmultiple sources of information and perform vot-ing more effectively.
The random walk process wepropose can be defined by the following formula:xt(j) = ?
?i?L?jI(i, j) ?Mij?
xt?1(i) + (1?
?
)vj(9)where I(i, j) is the normalized influence factorthat indicates how influential the edge di?
djisin the global context of the event.
The normaliza-tion is done by scaling the range of value from [0,1].
M is the stochastic transitional matrix.
In ourcase, I(i, j) can be just the value of freq(di, dj),Itopical(di, dj) , Itemporal(di, dj) alone or a lin-ear combination of them.
Note that, (I ?
M ) inmost case is not stochastic and must not be trans-formed into a stochastic transitional matrix, as thetransformation will collapse the global context ofI.
IRW is different to PageRank on weightedgraph, weighted or personalized PageRank andtheir variations e.g, (Xing and Ghorbani, 2004;Haveliwala, 2002), among others.
In particu-lar, weighted PageRank integrates influence scoresinto the stochastic transitional matrix.
Thus, therandom walker contributes the voting impact of anode X to its neighbor with an influence score nor-malized by the sum of scores on all outgoing con-nections.
That process leverages how good thisconnection is in the sub-graph (G*) which consistsof X and its outgoing neighbors.
In contrast, ourproposed model uses the non-normalized value ofthe influence score to leverage how good this con-nection is on the entire graph instead of G*.
Togive an example, if date X1 mentions only X2 witha raw temporal distance score of 20 and X3 men-tions only X4 with a score of 100, then in weightedPage Rank both would be normalized to a weightone, losing the information that X4 is mentionedafter a much longer time period than X2.
The pro-cess for combination in our model is defined as thefollowing:1601xt(j) = ??
?i?L?jW1(i, j) ?Mij?
xt?1(i)+ ?(1?
?
)?i?L?jW2(i, j) ?Mij?
xt?1(i)+ (1?
?
)vj(10)where W1(i, j) =Itopical(di,dj)maxuvItopical(du,dv)isthe normalized value for topical influence, andW2(i, j) =Itemporal(di,dj)maxuvItemporal(du,dv)is the normalizedvalue for temporal influence.6Here, the hyper-parameter 0 ?
?
?
1 controlsthe proportion of the topical influence from ditodj.
When ?
= 0, no topical influence is takeninto account.
No temporal influence is consideredwhen ?
= 1.
Intuitively, at every step, the randomwalker can follow the outgoing nodes and eithercarry topical influence (the first part) or temporalinfluence (the second part) to contribute to the rankof the outgoing nodes.
Otherwise, it teleports to anarbitrary node with probability (1?
?
).Convergence Property.
Starting from Eq.
10,we now show that the IRW model converges to astationary distribution.Let ?
and ?
?be the matrix with elementsW1(i, j) and W2(ij) respectively, with any edge(di, dj), I be the n ?
n identity matrix, and v bethe transpose of 1 ?
n uniform stochastic vector.M denotes the transitional matrix for G.Proposition 1.
(I??(wMT?
+ (1??)MT??
))is invertible for all M,?,?
?, ?, ?.Proof.
Let P = wMT?
+ (1??)MT?
?, we need to provethat I?
?P is invertible.
Equivalently, we prove its transposeI ?
?PTis invertible, which can be proved by showing that(I?
?PT)y = 0 only has the trivial solution y = 0.(I?
?PT)y = 0y = ?PTyyi= ?
?jPjiyj= ?
?j((?W1(i, j) + (1?
?
)W2(i, j))Mijyj).
(11)Let u = arg maxjyj.
When i == u, Eq.
11 infers,yu?
?
?j((?W1(u, j) + (1?
?
)W2(u, j))Mujyu).yu?
?yu?j((?W1(u, j) + (1?
?
)W2(u, j))Mujyu(1?
?Fu) ?
0.
(12)where Fu=?j((?W1(u, j) + (1 ?
?
)W2(u, j))Muj.Clearly, Fu?
1 because W1(u, j) ?
1 and W2(u, j) ?
16In the case of linear combinations we incorporate fre-quency into topical or temporal influence as described above.and?jMuj= 1.
Since ?
< 1 and Fu?
1, (1?
?Fu) > 0.Therefore yu?
0.
Similarly, let v = arg minjyjwe havethat yv?
0.
As yv?
yu, this implies yu= yv= 0 to satisfyall inequalities.
Consequently, yi= 0 for all i, or y = 0.Thus, I ?
?PTinvertible.
Equivalently,(I ?
?(?MT?
+(1?
?)MT??))
is invertible.Proposition 2.
The iteration in Eq.
9 converges to(1?
?)(I?
?(?MT?
+ (1?
?)MT??))?1v.Proof.
We can re-write Eq.
9 in matrix form:xt= ?Pxt?1+ (1?
?
)v= (?P)tx0+ (1?
?
)(t?i=1(?P)i?1)v(13)We will show that limt?
?xt= (1?
?
)(I ?
?P)?1v.
?i(?P )tij=?i?k(?P )ik(?P )t?1kj=?k(?P )t?1kj?i(?P )ik=?k(?P )t?1kj?(Fk)?
?k(?P )t?1kj??
(?
)t(14)Here,Fk=?i((?W1(k, i)+(1??
)W2(k, i))Mki?
1(proof similarly to Proposition 1Because ?
< 1, this column sum converges to zero whent ?
?.
We then derive limt??
(?P)tx0= 0.
When t?
?,given Proposition 1 and Neumann series, Eq.
13 becomes:xt= (?P)tx0+ (1?
?
)(I ?
?P)?1vhence, limt?
?xt= (1??)(I??P)?1v.
Convergence proved.4 Experiments4.1 Ground Truth and Data PreprocessingKessler et al (2012) use 91 timelines from AFPas ground truth along with the AFP news corpusfor feature extraction.
However, their dataset isnot publically available.
In addition, although theyconsider a wide spread of events, each event isonly represented by a single timeline from a sin-gle source, making that method somewhat vul-nerable to journalism bias (as discussed by them-selves in their paper).
The data collected by uspreviously (Tran et al, 2013a) is publically avail-able at http://l3s.de/?gtran/timeline/ andhas since been extended by us (Tran et al, 2015).Similar to Kessler et al (2012), it contains groundtruth timelines as well as a corpus of news articlescovering each event.
The dataset is suitable for ourpurpose because of the following reasons: (1) it isa heterogeneous dataset which contains news arti-cles and expert timeline summaries from differentnews agencies.
Thus, it is more likely to avoidthe issue of bias.
Also, each event is represented1602by more than one timeline; (2) it covers long-termstories that have been happening since 2011, mak-ing the date selection problem non trivial for anysystem.Timelines.
The groundtruth contains 21 time-lines for 4 main events (Egypt Revolution, LibyaWar, Syria War, Yemen Crisis), created by profes-sional journalists.
Table 2 shows statistics aboutthe timelines.
Only a small number of all pos-sible dates in a time range is included in at leastone timeline (for example, only 122 dates amonga possible 918 dates for the Egypt Revolution).News Corpus.
The news articles have been col-lected from 24 well-known news outlets by query-ing Google with the event name together withthe outlets?
sitename and time range specification.The crawl time range starts from the first of themonth of the earliest event in any timeline (for ex-ample, 2011-01-01 for the Egypt revolution) andends at crawl date.
The top-ranked 300 news ar-ticles from each news site were collected, if stillavailable.
The article creation date is parsed fromthe answers returned by Google.
The corpus con-tains 15,534 news articles.
Its statistics are sum-marised in Table 3.
The overlap between time-line date ranges and news corpus date ranges isonly partial: on the one hand, the corpora havemany articles published after the timelines end; onthe other hand, sometimes the corpus has no ar-ticles published near the beginning of the time-line (Syria War).
The distribution of documentfrequency leans towards the end date of the newscollection.
The reason could be that most searchengines rank recent documents higher than thosepublished longer ago.Story Time Range #NewsEgypt 2011/01/11 - 2013/11/10 3869Libya 2011/02/16 - 2013/07/18 3994Syria 2011/11/17 - 2013/07/26 4071Yemen 2011/01/15 - 2013/07/25 3600Table 3: Overview of the news corpusPreprocessing.
Accurate date extraction includ-ing both implicit (like last Friday) and explicit(like 11 Feb ) temporal expressions is vital toour approach as well as for competitor systems.We use the Heideltime state-of-the art toolkit(Str?otgen and Gertz, 2010) for this task.4.2 Experimental settingsAs can be seen from Table 2, different timelinesfor the same event can contain varying dates, dueto different ranges timelines might cover but alsodue to selection preferences by individual writers.Therefore, we consider the union of all timelinesfor an event.
The set of input dates for ranking areall dates from the start t1and end t2of the unionof timelines.7We call that input time range T Re,depending on main event e.We consider two evaluation settings:relaxed setting: A date from T Reselected byan algorithm is counted as correct if it is includedin the union of timelines, therefore in at least oneindividual timeline.strict setting: A date from T Reselected by analgorithm is counted as correct if it is included inat least two individual timelines.The first setting is the one used in previous worksuch as (Kessler et al, 2012; Tran et al, 2013a).It is also the only one that can be used if only onetimeline per event is considered as in Kessler etal.
(2012).
We therefore include it for compari-son purposes.
However, we think it is better toconsider several timelines as it allows us to con-sider agreement between timeline writers.
If morethan one writer agrees on a date being importantwe have more evidence that a system should findthat date.
Finding dates that only a single writerincludes is less important and could even be dueto bias or system overfitting.
Therefore, our sec-ond setting is preferable as it emphasizes highlyimportant dates selected by multiple journalists.Each system selects the top k dates during theinput time range.
We evaluate the systems byMean Average Precision at k (MAP@k) for k =5, 10, 15, 20 over all four events.4.3 Systems.Baseline.
We use three unsupervised baselines.The baseline Document Frequency ranks dates ac-cording to the number of news articles publishedon that date.
Our assumption is that on a datewhere one or more important events happened,there would be a spread of information over dif-ferent news agencies in the world.
Therefore, thisdate has more news articles published.
This base-line is related to the burstiness date selection usedby Yan et al (2011b).The baseline MaxLength ranks dates by themaximum article length of all articles published onthat date.
Our hypothesis is that important events7Prior work also uses start and end date of timelines fordelimiting input (Kessler et al, 2012; Tran et al, 2013a).1603Story #TL #atLeastOnce #atLeastTwice avgL maxL minL Time Range #datesEgypt 4 122 18 36 57 24 2011/01/01 - 2013/07/07 918Libya 7 118 56 34 62 22 2011/02/14 - 2011/11/22 281Syria 5 106 17 60 26 13 2011/03/15 - 2013/07/06 844Yemen 5 81 26 24 42 10 2011/01/22 - 2012/02/27 401Number of timelines (#TL), number of dates occurring in at least one timeline (#atLeastOnce), number of dates that appearin at least 2 timelines, average (avgL), max (maxL) and min (minL) length of timelines; the Time Range of the union oftimelines and all potential dates (#dates) within the time range.Table 2: Overview of groundtruth timelinesoften receive more attention from writers, leadingto longer articles.Date Frequency ranks a date d by the total num-ber of sentences referring to d that are not pub-lished on d. This is a simple measure of d?s influ-ence without joint scoring of dates or integrationof temporal distance or topic.Competitors.
We reimplement Kessler et al(2012)?s model.
It first detects all sentences withdate references and filters out certain types of sen-tences according to linguistic features (such aspresence of modality as this can put the factual-ity of the event into question).
Then, the impor-tance score of a date is determined by the prod-uct of the Lucene score of referring sentences andan ML-predicted score that takes into account datereference frequencies, temporal distance of datereferences and topical importance of referring sen-tences.
To use the same setting as for our systems,we use the list of keywords extracted by TextRank(Mihalcea and Tarau, 2004) to formulate a topicquery for the Lucene index.We reimplement Tran et al (2013a) who use asupervised ML approach based on a more detailedconsideration of date reference frequencies.Both Kessler et al (2012) and Tran et al(2013a) are retrained and tested via 4-fold cross-validation on events.
In addition, we noted thatthe two supervised systems could profit from thefact that for certain dates in T Reno publishednews articles exist in the news collection and thatthey are therefore a priori unlikely to be relevant.We therefore also run those systems with a stricterinput time range, which intersects T Rewith thedates that are the publication date of at least onearticle in the news collection.
We indicate thesesystems as Kessler et al (2012) (Pub) and Tran etal.
(2013a) (Pub).Our Approach.
Our system builds graphs withall dates referenced in the news corpus for an eventas nodes.
We select the top k highest ranked nodesthat also fall within T Re.
We measure the perfor-mance with different strategies for the Influencefactor I.
We use the following five unsupervisedstrategies, where we just set the damping factor ?to 0.85 as suggested by Page et al (1999).8IRWfreqonly uses the frequency aspect.
Thiscorresponds to a joint modelling version of theDate Frequency baseline.IRWmax topicaluses topical influence, disre-garding frequency aspect in its computation.IRWfreq?topicaluses topical influence, incor-porating the frequency aspect in its computation.IRW|temporal|uses temporal influence, disre-garding the frequency aspect.IRWfreq?temporaluses temporal influence in-corporating the frequency aspect.Furthermore, we are interested in combiningtopical and temporal influence (with or withoutfrequency aspects).
Here, our model is parame-terized by ?
which controls the impact of topi-cal influence vs. temporal influence.
This param-eter is tuned on the training set via 4-fold cross-validation and, therefore, the next two modelshave a small element of supervision.IRWmax topical+freq?temporalcombines topicaland temporal influence, integrating the frequencyaspect into temporal influence.IRWfreq?topical+|temporal|combines topicaland temporal influence, integrating the frequencyaspect into topical influence.4.4 Analysis of date reference graphsTable 4 shows an analysis of the four date refer-ence graphs.
In this Table, #sent provides the totalnumber of sentences from all news articles while#hasRef shows the number of sentences that re-fer to a date (around 15%), suggesting a sustain-able part of data can be helpful for the interaction-based approach.
The number of nodes shows theunique dates that are involved in a date referencelink.
The number of edges is equivalent to thenumber of date reference links (di, dj) that in-dicate that there exist sentences published on dibut referring to dj.
toStrict and toRelaxed is the8We could make these models supervised by tuning thedamping factor via cross-validation.
However, we found itencouraging that we were able to achieve competitive resultswithout tuning ?
similar to links between web pages in thetraditional PageRank algorithm, links between dates seem toembody strong relations, making the same damping factorsuitable.1604#sent #hasRef(%) #nodes #Edges toStrict reachStrict toRelaxed reachRelaxedEgypt 143,096 26,428 (18.5) 939 2784 15.55% 100.00% 35.99% 89.34%Libya 140,753 22,166 (15.7) 971 1797 33.78% 98.21% 56.98% 99.15%Syria 162,305 26,992 (16.6) 812 1555 7.14% 88.24% 31.00% 73.58%Yemen 140,156 21,606 (15.4) 1106 1608 18.28% 100.00% 37.00% 100.00%Table 4: Interaction-based analysis on experimental news collectionsproportion of the edges that link to groundtruthdates in the strict setting and relaxed setting.Those edges cover almost all the groundtruth dates(i.e, reachStrict and reachRelaxed), i.e almost allgroundtruth dates are indeed referenced at leastonce in our corpus.4.5 ResultsTable 5 shows the average performance of differ-ent systems over our four events.
Several generalobservations stand out.
First, we notice that thescores wrt.
relaxed setting of all systems are higherthan those wrt.
strict setting.
That is expected, asin relaxed setting, a selected date has a higher like-lihood to be one of the milestones in the timelineof at least one expert.
Second, simple baselinessuch as Document Frequency and MaxLength per-form reasonably well in the relaxed-setting.
Thatconfirms our assumptions that important dates of-ten possess more published news articles and arelikely to have at least one article of substantiallength.
However, these baselines are not enoughto distinguish highly important dates (which areselected by more than one journalist) as shown bytheir performance in the strict setting (around 0.3MAP@k only).Using Date Frequency leads to a substan-tial performance improvement in the strict set-ting comapred to the publication-based baselines.Therefore, highly important dates are more likelyto be kept mentioning in the future and that sup-ports our research direction to better leverage dateinteraction for ranking date importance.
Thisis further confirmed by the performance of theIRWfreqsystem which is the joint modelling ver-sion of the DateFrequency baseline and outper-foms the baseline without inclusion of any furtherinformation such as topical salience.
It can evencompete with prior supervised competitors whentheir input time range is not modified.Our supervised competitors (Kessler et al,2012; Tran et al, 2013a) perform overall well andboth profit from modifying their input time rangeas suggested in the Pub versions.
However, the un-supervised versions of our system IRWmax topicaland IRWfreq?topicalperform very comparably tothe supervised competitors in the strict and relaxedsetting, respectively.The last two lines of Table 5 show the re-sults of our proposed method when using a lin-ear combination of the different influence fac-tors, and the hyperparameter ?
having been tunedon the training set.
IRWmax topical+freq?temporalshows the result of our system with ?
= 0.2 andIRWfreq?topical+|temporal|with ?
= 0.1 Thesesystems outperform the state-of-the-art systemsclearly in the strict setting and for most measuresin the relaxed setting.Stability.
We also investigated the stability ofthe performance of different systems by look-ing into their results on each event.
Table 6presents the performance of our best systemIRWmax topical+freq?temporaland its best super-vised competitors Tran et al (2013a) (Pub) andKessler et al (2012) (Pub).
All systems performworse on the Syria story although our dropoff isless than the one of prior systems.We speculate that the competitor systems aremore sensitive to the amount of available pub-lished content on a target date than ours.
In partic-ular, Tran et al (2013a) use the frequency of pub-lished dates and sentences as one of their features,and Kessler et al (2012) rely on the returned re-sults from Lucene index which tends towards sub-stories from the publication periods.
Different toothers, the time range for the Syria news collectiondoes not include the time range for the Syria time-lines fully or almost fully (see Tables 2 and 3).
Wetherefore are not as dependent on an exact matchbetween timeline dates and news collection datesand can use news articles from later dates moreeffectively.5 Conclusion and Future WorkThis paper addresses the problem of date selec-tion for timeline summarization.
Our approachleverages the interactions between dates via a jointmodel based on a date reference graph, improvingon individual scoring of dates.We capture the interactions between dates fromthe number of cross-references between dates, and1605System strict setting relaxed-settingMAP@5 MAP@10 MAP@15 MAP@20 MAP@5 MAP@10 MAP@15 MAP@20Document Frequency 0.312 0.303 0.299 0.299 0.509 0.550 0.564 0.560MaxLength 0.349 0.335 0.311 0.287 0.647 0.594 0.566 0.533Date Frequency 0.555 0.498 0.457 0.427 0.597 0.626 0.625 0.613(Kessler et al, 2012) 0.567 0.546 0.519 0.491 0.790 0.740 0.723 0.704(Kessler et al, 2012) (Pub) 0.701 0.620 0.571 0.524 0.912 0.807 0.759 0.731(Tran et al, 2013a) 0.668 0.565 0.522 0.488 0.740 0.717 0.700 0.673(Tran et al, 2013a) (Pub) 0.710 0.601 0.551 0.506 0.792 0.771 0.746 0.716IRWfreq0.646 0.535 0.471 0.431 0.861 0.770 0.711 0.687IRWmax topical0.763 0.647 0.564 0.510 0.887 0.794 0.724 0.685IRWfreq?topical0.737 0.576 0.498 0.448 0.945 0.836 0.762 0.709IRW|temporal|0.724 0.587 0.522 0.484 0.699 0.597 0.570 0.564IRWfreq?temporal0.724 0.588 0.527 0.486 0.712 0.622 0.581 0.559IRWmax topical+freq?temporal0.879 0.760 0.658 0.587 0.897 0.842 0.775 0.730IRWfreq?topical+|temporal|0.818 0.677 0.596 0.536 0.928 0.866 0.801 0.745Table 5: Average MAP@k scores of different systems on 4 news collectionsEgypt Libya Syria YemenIRWmax topical+freq?temporalMAP@5 0.960 1.000 0.713 0.843MAP@10 0.738 0.969 0.598 0.735MAP@15 0.600 0.854 0.503 0.676MAP@20 0.520 0.776 0.433 0.619Kessler et al (2012) (Pub)MAP@5 0.703 0.843 0.257 1.000MAP@10 0.566 0.759 0.203 0.952MAP@15 0.507 0.697 0.187 0.894MAP@20 0.450 0.659 0.171 0.816Tran et al (2013a) (Pub)MAP@5 0.960 0.910 0.257 0.713MAP@10 0.803 0.836 0.224 0.541MAP@15 0.665 0.799 0.227 0.514MAP@20 0.569 0.758 0.212 0.484Table 6: Stability of our systems vs. competitorstheir temporal and topical influences.
We present anovel random walk model that incorporates theseperspectives into connectivity-based computation.Experimental results on four news events that spana long time period show that the proposed modelsoutperform state-of-the art approaches.
Even un-supervised versions of the model perform on a parwith previous supervised methods.
We also drawattention to the necessity to take personal bias intoaccount, which leads to differences between man-ually created timelines for the same event ?
weencourage future work to always consider severaltimelines per event in the way that other NLP workuses several annotators to create ground truth.In future work, we will consider a wider rangeof events and event types.
This will also leadto considering timelines where the day as unit ofgranularity might not be appropriate or where theunit of granularity might be varying across thetimeline.
We will also explore in depth the effectof size and type of news corpus on resulting time-lines, research further into the issue of human dis-agreement in timeline creation and explore humanevaluation of timeline summarization.AcknowledgmentsThe work was partially funded by the Eu-ropean Commission for the FP7 projectEUMSSI (611057) and the ERC AdvancedGrant ALEXANDRIA (339233).ReferencesJames Allan, Rahul Gupta, and Vikas Khandelwal.2001.
Temporal summaries of new topics.
In Pro-ceedings of SIGIR?01, pages 10?18.Chlo?e Braud and Pascal Denis.
2014.
Combin-ing natural and artificial examples to improve im-plicit discourse relation identification.
In COL-ING 2014: Technical Papers.
Dublin, Ireland, pages1694?1705.Hai Leong Chieu and Yoong Keok Lee.
2004.
Querybased event extraction along a timeline.
In Proceed-ings of SIGIR?04, pages 425?432.G?unes Erkan and Dragomir R. Radev.
2004.
Lexrank:graph-based lexical centrality as salience in textsummarization.
J. Artif.
Int.
Res., 22(1):457?479.John Foley and James Allan.
2015.
Retrieving timefrom scanned books.
In Advances in InformationRetrieval, pages 221?232.
Springer.Taher H. Haveliwala.
2002.
Topic-sensitive pagerank.In WWW, pages 517?526.Kai Hong and Ani Nenkova.
2014.
Improvingthe estimation of word importance for news multi-document summarization.
In Proceedings of EACL2014, pages 712?721.Remy Kessler, Xavier Tannier, Caroline Hag`ege,V?eronique Moriceau, and Andr?e Bittar.
2012.
Find-ing salient dates for building thematic timelines.
InProceedings of ACL.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014.A pdtb-styled end-to-end discourse parser.
NaturalLanguage Engineering, 20(2):151?184.1606Kathleen McKeown, Regina Barzilay, John Chen,David K. Elson, David Kirk Evans, Judith Klavans,Ani Nenkova, Barry Schiffman, and Sergey Sigel-man.
2003.
Columbia?s newsblaster: New featuresand future directions.
In HLT-NAACL.Donald Metzler and Tapas Kanungo.
2008.
Ma-chine learned sentence selection strategies for query-biased summarization.
In Proceedings of the 2008ACM SIGIR LR4IR Workshop.Rada Mihalcea and Paul Tarau.
2004.
Textrank:Bringing order into text.
In EMNLP, pages 404?411.Kiem-Hieu Nguyen, Xavier Tannier, and V?eroniqueMoriceau.
2014.
Ranking multidocument event de-scriptions for building thematic timelines.
In COL-ING 2014, pages 1208?1217.Lawrence Page, Sergey Brin, Rajeev Motwani, andTerry Winograd.
1999.
The pagerank citation rank-ing: Bringing order to the web.
Technical report,Stanford InfoLab, November.
Previous number =SIDL-WP-1999-0120.Dragomir R. Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda Celebi, StankoDimitrov, Elliott Drbek, Ali Hakim, Wai Lam,Danyu Liu, Jahna Otterbacher, Hong Qi, HoracioSaggion, Simone Teufel, Michael Topper, AdamWinkel, and Zhu Zhang.
2004a.
Mead - a platformfor multidocument multilingual text summarization.In Proceedings of LREC?04.Dragomir R. Radev, Hongyan Jing, Magorzata Sty, andDaniel Tam.
2004b.
Centroid-based summarizationof multiple documents.
pages 919?938.Stephen E. Robertson, Steve Walker, Susan Jones,Micheline Hancock-Beaulieu, and Mike Gatford.1994.
Okapi at trec-3.
In TREC.Jannik Str?otgen and Michael Gertz.
2010.
Heideltime:High quality rule-based extraction and normaliza-tion of temporal expressions.
In Proceedings of theSemEval ?10 Workshop, pages 321?324.Russell C. Swan and James Allan.
2000.
Timemine:visualizing automatically constructed timelines.
InSIGIR, page 393.Binh Giang Tran, Mohammad Alrifai, and DatQuoc Nguyen.
2013a.
Predicting relevant newsevents for timeline summaries.
In WWW?2013.Giang Binh Tran, Tuan A. Tran, Nam-Khanh Tran,Mohammad Alrifai, and Nattiya Kanhabua.
2013b.Leveraging learning to rank in an optimizationframework for timeline summarization.
In SIGIR2013 Workshop TAIA.Giang Tran, Mohammad Alrifai, and Eelco Herder.2015.
Timeline summarization from relevent head-lines.
In Proceedings of ECIR?2015.Dingding Wang, Tao Li, and Mitsunori Ogihara.
2012.Generating pictorial storylines via minimum-weightconnected dominating set approximation in multi-view graphs.
In Proceedings of AAAI?2012.Wenpu Xing and Ali A. Ghorbani.
2004.
Weightedpagerank algorithm.
In CNSR, pages 305?314.Rui Yan, Jian-Yun Nie, and Xiaoming Li.
2011a.
Sum-marize what you are interested in: An optimizationframework for interactive personalized summariza-tion.
In Proceedings of EMNLP?11.Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,Xiaoming Li, and Yan Zhang.
2011b.
Evolution-ary timeline summarization: a balanced optimiza-tion framework via iterative substitution.
In Pro-ceedings of SIGIR?11, pages 745?754.1607
