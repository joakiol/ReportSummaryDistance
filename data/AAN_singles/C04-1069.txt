Document Re-ranking Based on Automatically AcquiredKey Terms in Chinese Information RetrievalYang Lingpeng, Ji Donghong, Tang LiInstitute for Infocomm Research21, Heng Mui Keng TerraceSingapore, 119613{lpyang,dhji,tangli}@i2r.a-star.edu.sgAbstractFor Information Retrieval, users are moreconcerned about the precision of top rankingdocuments in most practical situations.
In thispaper, we propose a method to improve theprecision of top N ranking documents byreordering the retrieved documents from theinitial retrieval.
To reorder documents, we firstautomatically extract Global Key Terms fromdocument set, then use extracted Global KeyTerms to identify Local Key Terms in a singledocument or query topic, finally we make useof Local Key Terms in query and documents toreorder the initial ranking documents.
Theexperiment with NTCIR3 CLIR dataset showsthat an average 10%-11% improvement and2%-5% improvement in precision can beachieved at top 10 and 100 ranking documentslevel respectively.1 IntroductionInformation retrieval (IR) is used to retrieverelevant documents from a large document setfor a given query where the query is a simpledescription by natural language.
In mostpractical situations, users concern more on theprecision of top ranking documents than recallbecause users want to acquire relevantinformation from the top ranking documents.Traditionally, IR system uses a one-stage ora two-stage mechanism to retrieve relevantdocuments from document set.
For one stagemechanism, IR system only does an initialretrieval.
For two-stage mechanism, besidesthe initial retrieval, IR system will make use ofthe initial ranking documents to automaticallydo query expansion to form a new query andthen use the new query to retrieve again to getthe final ranking documents.
The effectivenessof query expansion mainly depends on theprecision of top N (N<50) ranking documentsin initial retrieval because almost all proposedautomatic query expansion algorithms makeuse of the information in the top N retrieved.Figure 1 demonstrates the general processes ofa two-stage IR system.In this paper, we propose a method toimprove the precision of top N rankingdocuments by reordering the initially retrieveddocuments in the initial retrieval.
To reorderdocuments, we first automatically extractGlobal Key Terms from the document set, thenuse the extracted Global Key Terms to identifyLocal Key Terms in a single document or querytopic, finally we make use of the Local KeyTerms in queries and documents to reorder theinitial ranking documents.Although our method is general and canapply to any languages, in this paper we?ll onlyfocus on the research on Chinese IR system.F i g .
1  T r a d i t i o n a l  P r o c e s s  o f  t w o - s t a g e s  I RO r i g i n a l  Q u e r yE x p a n d e d   Q u e r yI n i t i a l  R e t r i e v a lF i n a l  R e t r i e v a lQ u e r y   E x p a n s i o nD o c u m e n tS e tI n i t i a l  R a n k i n gD o c u m e n t sF i n a l  R a n k i n gD o c u m e n t sThe rest of this paper is organized asfollowing.
In section 2, we give an overallintroduction of our proposed method.
Insection 3, we talk about what are Global KeyTerms and what are Local Key Terms and howto acquire them.
In section 4, we describe howthese terms apply to Chinese IR system toimprove the precision and quality of IRsystem.
In section 5, we evaluate theperformance of our proposed method and givesome result analysis.
In section 6, we presentthe conclusion and some future work.2 Overview of Document Reorderingin Chinese IRFor Chinese IR, many retrieval models,indexing strategies and query expansionstrategies have been studied and successfullyused in IR.
Chinese Character, bi-gram, n-gram (n>2) and word are the most usedindexing units.
(Li.
P. 1999) gives out manyresearch results on the effectiveness of singleChinese Character as   indexing unit and howto improve the effectiveness of single ChineseCharacter as indexing unit.
(K.L.
Kwok.
1997)compares three kinds of indexing units (singleCharacter, bigram and short-words) and theireffectiveness.
It reports that single characterindexing is good but not sufficientlycompetitive, while bi-gram indexing workssurprisingly well and it?s as good as short-word indexing in precision.
(J.Y.
Nie, J. Gao,J.
Zhang and M. Zhou.
2000) suggests thatword indexing and bi-gram indexing canachieve comparable performance but if weconsider the time and space factors, then it ispreferable to use words (and characters) asindexes.
It also suggests that a combination ofthe longest-matching algorithm with singlecharacter is a good method for Chinese and ifthere is unknown word detection, theperformance can be further improved.
Manyother papers in literature (Palmer, D. andBurger, J, 1997; Chien, L.F, 1995) give similarconclusions.
Although there are still differentvoices on if bi-gram or word is the bestindexing unit, bi-gram and word are bothconsidered as the most important top twoindexing units in Chinese IR and they are usedin many reported Chinese IR systems andexperiences.There are mainly two kinds of retrievalmodels: Vector Space Model (G. Salton andM.
McGill, 1983) and Probabilistic Retrieval(N. Fuhr, 1992).
They are both used in a lot ofexperiments and applications.For query expansion, almost all of theproposed strategies make use of the top Ndocuments in initial ranking documents in theinitial retrieval.
Generally, query expansionstrategy selects M indexing units (M<50) fromthe top N (N<25) documents in initial rankingdocuments according to some kind of measureand add these M indexing units to originalquery to form a new query.
In such process ofquery expansion, it?s supposed that the top Ndocuments are related with original query, butin practice, such an assumption is not alwaystrue.
The Okapi approach (S.E.
Roberson andS.Walker, 2001) supposes that the top Rdocuments are related with query and it selectsN indexing unit from the top R documents toform a new query, for example, R=10 andN=25.
(M.
Mitra., Amit.
S. and Chris.
B, 1998)did an experiment on different query topicsand it is reported the effectiveness of queryexpansion mainly depends on the precision ofthe top N ranking documents.
If the top Nranking documents are highly related with theoriginal query, then query expansion canimprove the final result.
But if the top Ndocuments are less related with the originalquery, query expansion cannot improve thefinal result or even reduces the precision offinal result.
These researches conclude thatwhether query expansion is successful or notmainly depends on the quality of top N rankingdocuments in the initial retrieval.The precision of top N documents in theinitial ranking documents depends on indexingunit and retrieval models and mainly dependson indexing unit.
As discussed above, bi-gramand word both are the most effective indexingunits in Chinese IR.Other effort has been done to improve theprecision of top N documents.
(Qu.
Y, 2002)proposed a method to re-rank initial relevantdocuments by using individual thesaurus butthe thesaurus must be constructed manuallyand depends on each query topic.In this paper, we propose a new method toimprove the precision of top N rankingdocuments in initial ranking documents byreordering the top M (M > N and M < 1000)ranking documents in initially retrieveddocuments.
To reorder documents, we try tofind long terms (more than 2 Chinesecharacters) that generally represent somecomplete concepts in query and documents,then we make use of these long terms to re-weight the top M documents in initial rankingdocuments and reorder them by re-weightedvalue.
We adopt a two-stage approach toacquire such kinds of long terms.
Firstly, weacquire Global Key Terms from the wholedocument set; secondly, we use Global KeyTerms to acquire Local Key Terms in a queryor a document.
After we have acquired LocalKey Terms, we use them to re-weight the top Mdocuments in initial ranking documents.
Figure2 demonstrates the processes of an IR systemthat integrates with this new method.F i g .
2  E n h a n c e d  P r o c e s s  o f  I RO r i g i n a l  Q u e r yE x p a n d e d  Q u e r yI n i t i a l  R e t r i e v a lF i n a l  R e t r i e v a lQ u e r y  E x p a n s i o nD o c u m e n tS e tI n i t i a l  R a n k i n gD o c u m e n t sF i n a l  R a n k i n gD o c u m e n t sD o c u m e n tR e - O r d e rK e y  T e r mE x t r a c t i o nK e y  T e r m s  R e - O r d e r e dD o c u m e n t s3 Global/Local Key Term ExtractionThe Global /Local Key Term extractionconcerns the problem of what is a key term.Intuitively, key terms in a document are someconceptual terms that are prominent indocument and play main roles indiscriminating the document from otherdocuments.
In other words, a key term in adocument can represent part of the content ofthe document.
Generally, from the point of theview of conventional linguistic studies, KeyTerms may be some NPs, NP-Phrases or somekind of VPs, adjectives that can represent somespecific concepts in document contentrepresentation.We define two kinds of Key Terms: GlobalKey Terms which are acquired from the wholedocument set and Local Key Terms which areacquired from a single document or a query.We adopt a two-stage approach toautomatically acquire Global Key Terms andLocal Key Terms.
In the first stage, we acquireGlobal Key Terms from document set by usinga seeding-and-expansion method.
In the secondstage, we make use of acquired Global KeyTerms to find Local Key Terms in a singledocument or a query.3.1  Global Key TermsGlobal Key Terms are terms which areextracted from the whole document set andthey can be regarded to represent the mainconcepts of document set.Although the definition of Global KeyTerms is difficult, we try to give someassumptions about a Global Key Term.
Beforewe give these assumptions, we first give outthe definition of Seed and Key Term in adocument (or document cluster) d.The concept Seed is given to reflect theprominence of a Chinese Character in adocument (or document cluster) in some way.Suppose r is the reference document set(reference document set including documentset and other statistical large documentcollection), d is a document (or a documentset), w is an individual Chinese Character in d,let Pr(w) and Pd(w) be the probability of woccurring in r and d respectively, we adopt 1),relative probability or salience of w in d withrespect to r (Schutze.
1998), as the criteria forevaluation of Seed.1) Pd(w) / Pr(w)We call w a Seed if Pd(w) / Pr(w)??
(?>1).Now we give out the assumptions about aKey Terms in document d.i) a Key Term contains at least a Seed.ii) a Key Term occurs at least N (N>1) times in d.iii) the length of a Key Term is less than L (L<30).iv) a maximal character string meeting i), ii) and iii) is aKey Term.v) for a Key Term, a real maximal substring meeting i),ii) and iiI) without considering their occurrence in allthose Key Terms containing it is also a Key Terms.Here a maximal character string meeting i), ii)and iii) refers to a adjacent Chinese characterstring meeting i), ii) and iii) while no otherlonger Chinese character strings containing itmeet i), ii) and iii).
A real maximal substringmeeting i), ii) and iii) refers to a real substringmeeting i), ii), and iii) while no other longerreal substrings containing it meet i), ii) and iii).We use a kind of seeding-and-expansion-based statistical strategy to acquire Key Termsin document (or document cluster), in whichwe first identify seeds for a Key Term thenexpand from it to get the whole Key Term.Fig.
3 describes the procedure to extractKey Terms from a document (or documentcluster) d.let Fd(t) represents the frequency of t in d;let N is a given threshold (N>1);K = {};collect Seeds in d into S;for all c?S{let Q = {t: t contains c and Fd(t)?N};while Q ?
NIL{max-t  ?
the longest string in Q;K ?
K + { max-t };Remove max-t  from Q;for all other t in Q{if t is a substring of max-t{    Fd(t)?
Fd(t)- Fd(max-t);if Fd(t)<Nremoving t from Q;}}}}return K as Key Terms in document d;Fig.
3 Key Term Extraction from document dTo acquire Global Key Terms, we firstroughly cluster the whole document set r intoK (K<2000) document clusters, then we regardeach document cluster as a large document andapply our proposed Key Term Extractionalgorithm (see Fig.
3) on each documentcluster and respectively get Key Terms in eachdocument cluster.
All these Key Terms fromdocument clusters form Global Key Terms.There are many document clusteringapproaches to cluster document set.
K-Meansand hierarchical clustering are the two usuallyused approaches.
In our algorithm, we don?tneed to use complicated clustering approachesbecause we only need to roughly clusterdocument set r into K document clusters.
Herewe use a simple K-Means approach to clusterdocument set.
Firstly, we pick up randomly10*K documents from document set r;secondly, we use K-Means approach to clusterthese 10*K documents into K documentclusters; finally, we insert every otherdocument into one of the K document clusters.Fig.
4 describes the general process to clusterdocument set r into K document clusters.let K is the number of documnet clusters to get;T?10*K documents randomly pickuped from r;cluster T into K clusters {Kj} by using K-Means;for any document d in {r-T}{Ki?
document cluster which has the maximalsimilarity with d;insert d to document cluster Ki;}return K document clusters {Kj|1<=j<=K};Fig.
4 Cluster document set r into K clustersFig.
5 describes the procedure to acquire Global KeyTerms from document set r.roughly cluster document set r to K document clusters{Kj|1<=j<=K} (See Fig.
4);G = {};for each Kj{extract Key Terms g from Kj ; (See Fig.
3)G ?
G + g;}return G as Global Key Terms in document set r;Fig.
5 Global Key Terms AcquisitionIn the processing of Global Key Termsacquisition, the frequency of each Global KeyTerm is also recorded for further use inidentifying Local Key Terms - terms in a singledocument or query.3.2 Local Key TermsUnlike Global Key Terms, Local Key Termsare not extracted by using Key Term extractionalgorithm from single document or query, theyare identified based on Global Key Terms andtheir frequencies.Fig.6 describes the procedure of Local KeyTerms acquisition from a single document orquery d.Given threshold M (M>10), N (N>100) and document d;L = {};collect Global Key Terms occurred in d and theirfrequency in document set r into S = <c, tf>;for all <c, tf>?S{if  tf  < Mremove <c, tf> from S;};for all <c, tf>?S{if  c = c1c2  and  <c1, tf1>?S and <c2, tf2>?Sif (tf1 > tf *N  and tf2 >> tf*N)remove <c, tf> from S;};while S ?
NIL{let Q = {<t, tf>: t is the longest string is S};find <max-c,max-tf>in Q where max-tf has themaximum value;remove <max-t, max-tf>  from S;if max-t occurs in d{  L ?
L + max-t;remove all occurrance of max_t in d;for all <b, tf-b>?S where b is a substring of  max-t;if tf-b < max-tf  remove <b,tf-b>  from S;}};return L as Local Key Terms in document d;Fig.
6 Local Key Terms AcquisitionFollowing are some examples of Global KeyTerms and Local Key Terms in a query.Example:Query:   (Find information of the exhibition "Art and Culture ofthe Han Dynasty" in the National Palace Museum)Global Key Terms occurred in Query and theirfrequencies in document set: (Cha2 Xun2)?
4948(Gu4 Gong1)?
3456(Gu4 Gong1 Bo2 Wu4 Yuan4)?
727(Bo2 Wu4 Yuan4) ?
772 (Yuan4 Suo3) ?
2991	 (Zhu3 Ban4) ?
38698(Qian1 Xi3)?
11510 (Han4 Dai4) ?
411 (Han4 Dai4 Wen3 Wu4) - 173 (Han4 Dai4 Wen3 Wu4 Da4 Zhan3) ?133 (Wen3 Wu4) ?
7088 (Wen3 Wu4 Da4 Zhan3) ?
158 (Da4 Zhan3) ?
2270 (Xiang3 Guan3) ?
67990  (Xiang3 Guan3 Nei3 Rong2) ?
148 (Nei3 Rong2) ?
31165Local Key Terms in Query: (Han4 Dai4 Wen3 Wu4 Da4 Zhan3) (Han4 Dai4 Wen3 Wu4) (Wen3 Wu4) (Da4 Zhan3)(Gu4 Gong1 Bo2 Wu4 Yuan4)(Bo2 Wu4 Yuan4)(Gu4 Gong1) (Xiang3 Guan3) (Nei3 Rong2)	 (Zhu3 Ban4)(Qian1 Xi3)  (Cha2 Xun2)From the example, we can see the differencebetween Global Key Terms and Local KeyTerms.
For example,  (Yuan4 Suo3)  andff (Wen3 Wu4 Da4 Zhan3) are GlobalKey Terms, but they are not the Local KeyTerms of query.4 Document ReorderingAfter we have acquired Global Key Terms indocument set and Local Key Terms in everydocument and query, we make use of them toreorder the top M (M<=1000) documents ininitial ranking documents.
Suppose q is a query,Fig.
7 is the algorithm to reorder top Mdocuments in initial ranking documents wherew(t) is the weight assigned to Local Key Term t.w(t) can be assigned different value bydifferent measures.
For example,i) w(t) = the length of t;ii) w(t) = the number of Chinese Characters in t;iii) w(t) = square root of the length of t;iv) w(t) = square root of the number of ChineseCharacters in t; (default)for each document d in top M ranking documentssim ?
similary value between d and q;w  ?
0;for each Local Key Term t in query q;{  if t is a Local Key Term of dw ?
w + weight(t) };if (w > 0){ sim ?
sim * w;set sim as the new similary between d and q };reorder top M documents by their new similarityvalues with query q;Fig.
7 Process of Document Reordering5 Experience & EvaluationWe make use of the Chinese document setCIRB011 (132,173 documents) and CIRB20(249,508 documents) and D-run type querytopic set (42 topics) of CLIR in NTCIR3 (seehttp://research.nii.ac.jp/ntcir-ws3/work-en.htmlfor more information) to evaluate our proposedmethod.
We use vector space model as ourretrieval model and use cosine to measure thesimilarity between document and query.
Forindexing units, we use bigrams and wordsrespectively.
To measure the effectiveness ofIR, we use the same two kinds of relevantmeasures: relax-relevant and rigid-relevant.
Adocument is rigid-relevant if it?s highlyrelevant or relevant with a query, and adocument is relax-relevant if it is high relevantor relevant or partially relevant with a query.We also use PreAt10 and PreAt100 torepresent the precision of top 10 rankingdocuments and top 100 ranking documents.When we use our proposed method andalgorithm to extract Global Key Terms fromdocument set r, we set al kinds of algorithmparameters as following:?
10000 documents from r to do initial documentclustering; (Fig.
4)?
1000 document clusters; (Fig.
4)?
maximal length of Key Terms:30; (Fig.
3)?
minimal occurrence of Key Terms:2; (Fig.
3)?
minimum salience of seed:2; (Fig.
3)?
reorder the top 1000 documents;?
We also set  M =10, N= 100 for the algorithm toacquire Local Key Terms.
(Fig.
6)Table 1 lists the normal results and enhancedresults based on bigram indexing.
Theenhanced results are acquired by using ourmethod to enhance the effectiveness.
PreAt10is the average precision of 42 queries inprecision of top 10 ranking documents, whilePreAt100 is the average precision of 42 queriesin precision of top 100 ranking documents.Column 2 (normal) displays the precision ofnormal retrieval, column 3 (Enhanced)displays the precision of using our proposedapproach, and column 4 (ratio) displays theratio of column 3 (enhanced) compared withcolumn 2 (normal).
Table 2 lists the normalresults and our enhanced results based on wordindexing.Normal Enhanced RatioPreAt10(Relax) 0.3642 0.4052 1.11258PreAt100(Relax) 0.1886 0.1926 1.02121PreAt10(Rigid) 0.2595 0.2871 1.10636PreAt100(Rigid) 0.1278 0.133 1.04069Table 1 Precision (bigram as indexing unit)Normal Enhanced RatioPreAt10(Relax) 0.3761 0.4119 1.09519PreAt100(Relax) 0.1983 0.2074 1.04589PreAt10(Rigid) 0.269 0.2952 1.0974PreAt100(Rigid) 0.1381 0.1419 1.02752Table 2 Precision (word as indexing unit)From table 1, we can see that comparedwith bigrams as indexing units, our proposedmethod can improve PreAt10 by 11% from0.3642 to 0.4052 in relax relevant measureand improve 11% from 0.2595 to 0.2871 inrigid relevant measure.
Even in PreAt100level, our method can improve 2% and 4% inrelax relevant and rigid relevant measure.
Fig.8 displays the PreAt10 values of each queryin relax relevant measure based on bigramindexing where the red lines represent theprecision enhanced with our method while theblack lines represent the normal precision.Among the 42 query topics, there are only 5queries whose enhanced precisions are worsethan normal precisions, the precisions ofother 37 queries are all improved.From table 2, using words as indexing units(we use a dictionary which contains 80000Chinese items to segment Chinese documentand query), our method can improve PreAt10by 10% from 0.3761 to 0.4119 in relaxrelevant measure and improve 10% from0.269 to 0.2952 in rigid relevant measure.Even in PreAt100 level, our method canimprove 3% and 5% in rigid and relaxrelevant measure.                            Fig.
8 PreAt10 of all queries in relax judgmentIn our experiments, compared with themost important and effective Chineseindexing units: bigram and words, ourproposed method improves the averageprecision of all queries in top 10 measurelevels for about 10%.
What lies behind ourproposed method is that in most case, properlong terms may contain more information(position and Chinese Character dependence)and such information can help us to focus onrelevant documents.
Our experiment alsoshows improper long terms may decrease theprecision of top documents.
So it?s veryimportant to extract right and proper terms indocuments and queries.6 ConclusionIn this paper, we proposed a new method toimprove the precision of top N initial rankingdocuments in Chinese IR.
We try to findproper and important long terms in queries anddocuments, then we make use of theseinformation to reweight the similarity betweenqueries and documents and finally reorder thetop M (M>N) documents by their newsimilarities with query.
Our experiences basedon bigram as indexing and word as indexingboth show that our method can improve theperformance of Chinese IR by 10%-11% at top10 documents measure level and 2%-5% at top100 documents document measure level.
Forthe further work, we will try to improve thequality of Global Key Terms and Local KeyTerms, and we will apply  our method toEnglish IR and other languages IR systems.ReferencesChien, L.F. Fast and quasi-natural languagesearch for gigabytes of Chinese texts.
In: Proc.18th ACM SIGIR Conf.
On R&D in IR.
Fox, E.,Ingwersen, P. & Fidel, R.
(eds.)
ACM: NY, NY.Pp.112-120.G.
Salton and M. McGill.
Introduction to ModernInformation Retrieval, McGraw-Hill, 1983.H.
Schutze.
1998.
The hypertext concordance: abetter back-of-the-book index.
Proceedings ofFirst Workshop on Computational Terminology.pp: 101-104.J.Y.
Nie, J. Gao, J. Zhang and M. Zhou.
2000.
Onthe Use of Words and N-grams for ChineseInformation Retrieval.
In Proceedings of theFifth International Workshop on InformationRetrieval with Asian Languages, IRAL-2000, pp.141-148K.L.
Kwok.
1997.
Comparing Representation inChinese Information Retrieval.
In Proceedings ofthe ACM SIGIR-97, pp.
34-41.Li.
P. 1999.Research on Improvement of SingleChinese Character Indexing Method, Journal ofthe China Society for Scientific and TechnicalInformation, Vol.
18 No.
5.M.
Mitra., Amit.
S. and Chris.
B. ImprovingAutomatic Query Expansion.
In Proc.
ACMSIGIR?98, Aug. 1998.N.
Fuhr.
Probabilistic Models in InformationRetrieval.
The Computer Journal.
35(3), 1992.Palmer, D. and Burger, J. Chinese WordSegmentation and Information Retrieval.
AAAISpring Symposium on Cross-Language Text andSpeech Retrieval, 1997Qu Y., Xu G. and Wang J. Rerank Method based onIndividual Thesaurus.
In NTCIR Workshop 2.S.E.
Robertson and S. Walker.
MicrosoftCambridge at TREC-9: Filtering track: In theEight Text Retrieval Conference (TREC-8),pages 151-161, Gaithersburg, MD, 2001.
