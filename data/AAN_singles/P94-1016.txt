INTERLEAVING SYNTAX AND SEMANTICS  INAN EFF IC IENT BOTTOM-UP PARSER*J ohn  Dowding ,  Rober t  Moore ,  F ranqo is  Andry~ and  Doug las  MoranSRI  In ternat iona l333 Ravenswood AvenueMenlo  Park ,  CA 94025{dowding ,bmoore ,andry ,  moran)@ai .
s r i .
comAbstractWe describe an efficient bottom-up arser that in-terleaves yntactic and semantic structure build-ing.
Two techniques are presented for reducingsearch by reducing local ambiguity: Limited left-context constraints are used to reduce local syn-tactic ambiguity, and deferred sortal-constraintapplication is used to reduce local semantic am-biguity.
We experimentally evaluate these tech-niques, and show dramatic reductions in bothnumber of chart edges and total parsing time.The robust processing capabilities of the parserare demonstrated in its use in improving the ac-curacy of a speech recognizer.INTRODUCTIONThe parsing problem is typically framed as arecognition problem: Given a grammar and a wordstring, determine if the word string is a member ofthe language described by the grammar.
For someapplications, notably robust natural-language pro-cessing and spoken-language understanding, thisis insufficient, since many utterances will not beaccepted by the grammar, because of nonstandardlanguage, inadequate grammatical coverage, or er-rors made in speech recognition.
In these cases,it is still desirable to determine what well-formedphrases occurred {n the word string, even whenthe entire string is not recognized.
The goal of theparser described here is to construct a chart, as ef-ficiently as possible, that contains all the syntacti-cally well-formed semantically meaningful phrases*This research was supported by the Advanced Re-search Projects Agency under Contract ONR N00014-90-C-0085 with the Office of Naval Research.
Theviews and conclusions contained in this document arethose of the authors and should not be interpreted asnecessarily representing the official policies, either ex-pressed or implied, of the Advanced Research ProjectsAgency of the U.S. Government.tCurrent address: CAP GEMINI Innovation, 86-90 Rue Thiers, 92513-Boulogne Billancourt, France,andry@capsoget i. fr .that occur in the word string.The most efficient practical context-freeparsers (Earley, 1970; Graham, Harrison, andRuzzo, 1980) are left-corner parsers, which gainefficiency by their ability to constrain the searchto find only phrases that might contribute to asentence that starts at the left edge of the stringbeing parsed.
These strong left-context syntac-tic constraints can prevent he parser from findingsome phrases that are well-formed, however.
Thisis a problem for us that is avoided by bottom-up parsers (Kasami, 1965;Younger, 1967), but atthe expense of creating many more edges, whichcan lead to dramatic increases in parse time.Since our goal is to find only the phrases thatare semantically meaningful as well as syntacti-cally well-formed, we also need to compute se-mantic constraints for every syntactic phrase weconstruct.
This requires making finer distinctionsthan syntax-only parsing, which can introduce ad-ditional ambiguity, multiplying the number of dis-tinct phrases found and increasing parse time.We describe two special techniques for speed-ing up bottom-up arsing by reducing local am-biguity without sacrificing completeness.
Onetechnique, "limited left-context checking," reduceslocal syntactic ambiguity; the other, "deferredsortal-constraint application," reduces local se-mantic ambiguity.
Both techniques are applied tounification-based grammars.
We analyze the per-formance of these techniques on a 194-utterancesubset of the AP~PA ATIS corpus (MADCOW,1992), using a broad-coverage rammar of English.Finally, we present results using the output of theparser to improve the accuracy of a speech recog-nizer in a way that takes advantage of our abilityto find all syntactically well-formed semanticallymeaningful phrases.SYNTACTIC  PARSINGThe parsing algorithm described here is imple-mented in the Gemini spoken-language under-110standing system (Dowding et al, 1993), whichfeatures a broad-coverage unification-based gram-mar of English, with independent syntactic, se-mantic and lexical components, in the style ofthe SRI Core Language Engine (Alshawi, 1992).Although we describe the syntactic parsing algo-rithm as though it were parsing purely context-free grammars, the ideas extend in a natural wayto unification-based grammar parsing.
While thechart for a context-free grammar contains edgeslabeled by atomic nonterminal symbols, the chartfor a unification-based grammar contains edges la-beled by complex feature-structure nonterminals.For efficiency, we maintain edges in the chartin only their most general form--new edges areadded to the chart only if they are more generalthan existing edges, and we delete existing edgesthat are less general than the new edge.
Like theCore Language Engine, we use a technique calledpacking to prevent local ambiguity from multiply-ing out into distinct edges at higher levels in thetree.
Packing is implemented by collapsing phrasalanalyses that share the same parent nonterminaland using only the parent for further processing.L imi ted  Le f t -Context  Check ingThe motivation behind limited left-context check-ing is the observation that most of the phrasesfound by a pure bottom-up arser using our uni-fication grammar contain syntactic gaps not li-censed by any possible gap filler.
In a purebottom-up arser, syntactic gaps must be hypoth-esized between every pair of words and lead tomany spurious phrases being built.
Earlier work(Moore and Dowding, 1991) showed that over 80%of the edges built by a bottom-up arser using ourgrammar were in this class.
Since these phrasesare semantically incomplete, they are of no inter-est if they cannot be tied to a gap filler, even in therobust processing applications we are concernedwith.
Our approach is to use left-context check-ing in a limited way to restrict he construction ofonly this class of phrases.We partition the set of grammatical cate-gories in our grammar into two groups, context-independent and context-dependent.
Context-independent phrases will be always be constructedbottom-up whenever possible.
Context-dependentphrases will only be constructed if they are pre-dicted by previously constructed phrases to theleft.
For our purposes, the set of context-dependent phrases are those that contain a syn-tactic gap with no gap filler, and the context-independent set is everything else.
Note, how-ever, that there is no constraint on the algorithmthat forces this.
If every grammatical categoryis context-dependent, then this algorithm reducesto a left-corner parser, and if every category iscontext-independent, then this algorithm reducesto a pure bottom-up arser.
One caveat is thatfor the algorithm to work correctly, the set ofcontext-dependent ca egories must be closed un-der the possible-left-corner-of relation.The question remains of how to produce pre-dictions for only those phrases in the context-dependent set.
As in Earley's algorithm, pre-dictions are implemented as dotted grammarrules.
Unlike Earley's algorithm, however, predic-tions are used only to license the construction ofcontext-dependent ca egories.
Predictions are notcreated for context-independent ca egories, andthey are not used in a completion phase to findnew reductions.Predictions deriving from rules that createcontext-dependent ca egories must themselves bepredicted.
Thus, predictions are also dividedinto context-independent a d context-dependent.A context-independent prediction will always beadded to the chart after the first child on the right-hand side has been found.
A context-dependentprediction will only be added to the chart when thefirst child on the right-hand side has been found,and the head of the rule has been previously pre-dicted or is a possible left corner of a category thathas been previously predicted.
Tables contain-ing the possible context-dependent and context-independent predictions are constructed at com-pile time.An outline of the parser algorithm is given inFigure 1.
The algorithm is basically an all-paths,left-to-right, bottom-up arser, with the modifica-tions that (1) the edge resulting from a reductionis added to the chart only if it is either a context-independent phrase or is predicted, and (2) pre-dictions are added at each point in the input forthe context-dependent phrases that are licensedat that point.
Some details of the parser havebeen omitted, particularly those related to pars-ing unification-based grammars that do not arisewhen parsing context-free grammars.
In addition,the parser maintains a skeletal copy of the chart inwhich edges are labeled only by the nonterminalsymbols contained in their context-free backbone,which gives us more efficient indexing of the fullgrammar ules.
Other optimizations include us-ing one-word look-ahead before adding new pre-dictions, and using restrictors (Shieber, 1985) toincrease the generality of the predictions.Compar i son  w i th  Other  ParsersTable 1 compares the average number of edges,average number of predictions, and average parsetimes 1 (in seconds) per utterance for the limited1All parse times given in this paper were producedon a Sun  SPARCstat ion  10/51,  running Quintus Pro-111For grammar with start symbol ~, phrase struc-ture rules P, lexicon L, context-independent ca e-gories CI, and context-dependent categories CD;and for word string w = wl...wn:Variant Edges Preds SecsBottom-Up 1191 0 14.6Limited Left-Context 203 25 1.0Left-Corner 112 78 4.0Table h Comparison of Syntax-Only Parsersif ~ E CD,  predict(T, 0);add_empty_categories (0) ;for i from I to n doforeach C such that C--+wi EL  doadd_edge_to_chart(C, i-- i, i) ;make_new_predictions(C, i -  i, i) ;f ind_new-reductions(C, i -  l,i)endadd_empty_categories (i) ;endsub f indmew-reduct ions(B ,  j, k) {fo reach  A and a such that  A-~ ~B 6 P doforeach i such that i = match((~, j) doif A 6 CD and predicted(A,i) or A 6 CIadd_edge_to_chart(A, i, k);make_new_predictions(A, i, k) ;find_new_reductions(A, i, k) ;endend}sub add_empty_categories(i) {foreach A such that A -+ e E P doif A 6 CD and predicted(A,/) or A 6 CIadd_edge_to_chart(A, i, i) ;make_new_predictions(A, i, i) ;find_new_reductions(A, i, i) ;end}sub make_new_predictions(A, i, j) {foreach Aft E Predictions\[i\] dopredict (fl, j )endforeach H -+ A~Bf l  6 P such thatH 6 CI and B E CD and fl 6 CI* dopredict (~B, j)endforeach H --+ A(~B$ 6 P such thatH E CD and B E CD and fl E CI*and predicted(H,  i) orH left-corner-of C and predicted(C, i) dopredict (~B, j)endFigure 1: Limited Left-Context Algorithmleft-context parser with those for a variant equiv-alent to a bottom-up arser (when all categoriesare context independent) and for a variant equiva-lent to a left-corner parser (when all categories arecontext dependent).
The tests were performed ona set of 194 utterances chosen at random from theARPA ATIS corpus (MADCOW, 1992), using abroad-coverage syntactic grammar of English hav-ing 84% coverage of the test set.The limited left-context parser can be thoughtof as at a midway point between the pure bottom-up parser and the left-corner parser, constructinga subset of the phrases found by the bottom-upparser, and a superset of the phrases found by theleft-corner parser.
Using limited left-context oconstrain categories containing syntactic gaps re-duces the number of phrases by more than a fac-tor of 5 and is almost 15 times faster than thepure bottom-up arser.
The limited left-contextparser builds 81% more edges than the left-cornerparser, but many fewer predictions.
Somewhatsurprisingly, this results in the limited left-contextparser being 4 times faster than the left-cornerparser.
We conjecture that this is due to the factthat context-independent phrases are licensed bya static table that is quicker to check against handynamic predictions.
This results in a lower av-erage time per edge for the limited left-contextparser (0.005 seconds) than the left-corner parser(0.036 seconds).
Some additional penalty may alsohave been incurred by not using dotted grammarrules to generate reductions, as in standard left-corner parsing algorithms.
2There are important differences between thetechnique for limited prediction in this parser,and other techniques for limited prediction suchas Shieber's notion of restriction (Shieber, 1985)(which we also use).
In methods uch as Shieber's,predictions are weakened in ways that can re-sult in an overall gain in efficiency, but predic-tions nevertheless must be dynamically generatedfor every phrase that is built bottom-up.
In ourlog version 3.1.4.2Other than this, we do not believe that thebottom-up and left-corner algorithms we tested suf-fered from any unnecessary overheads from being im-plemented as special cases of our general algorithm, aswe removed calls to subroutines that were unnecessaryfor those special cases.112method, no predictions need to be generated forthe context-independent ca egories; from anotherpoint of view, context-independent ca egories arepredicted statically, at compile time, for all pointsin the input, rather than dynamically at run time.Time is saved both because the predictions do nothave to be generated at run time, and because theprocess of checking these static predictions i  sim-pler.In previous work (Moore and Dowding, 1991),we compared limited left-context checking to someother methods for dealing with empty categories ina bottom-up arser.
Standard grammar transfor-mation techniques (Hopcroft and Ullman, 1980)can be used to eliminate empty nonterminals.This approach is useful to eliminate some edges,but still allows edges that dominate empty cat-egories to be created.
We found that using thistechnique was faster than pure bottom-up pars-ing, but still significantly slower than limited left-context checking.
A further efinement is to trans-form the grammar to eliminate both empty andnonbranching rules.
I.n the case of our grammar,however, this resulted in such a large" increase ingrammar size as to be impractical.An alternative method for making left-cornerparsers more robust is to explicitly add predictionsfor start categories at every point in the input.
Ifevery context-independent ca egory is a possibleleft corner of a start category, this approach willresult in the same set of edges in the chart thatthe limited left-context approach builds, but atthe added expense of creating many more predic-tions.
Since increasing the total number of pre-dictions increases parse time, we expect that thistechnique would be significantly slower than lim-ited left-context checking, although we have notcarried out any experiments on this approach.The technique of precompiling the left-daughter-of table is not unique to this parser, andhas appeared in both the GHR, parser (Graham,Harrison, and Russo, 1980) and the Core Lan-guage Engine parser (Alshawi, 1992).INTERLEAVED SEMANTICPROCESSINGThe Gemini system allows either syntax-only pars-ing or parsing with syntactic and semantic pro-cessing fully interleaved.
In interleaved processing,whenever a syntax rule successfully creates a newsyntactic phrase, corresponding semantic rules areapplied to construct possible logical forms for thephrase, 3 the logical forms are checked to verify3As a possible optimization, we tried combining thesyntactic and semantic rules at compile time.
Thisturned out to be slower than checking all syntacticthat they satisfy semantic sortal constraints, andedges for interpretations that pass all constraintsare added to the chart.
In general, this leads tofewer syntactically distinct analyses being presentin the chart (since phrases that have no inter-pretation satisfying sortal constraints do not pro-duce edges), but semantic ambiguity can lead toa greater total number of semantically distinctedges.
As is the case in syntax-only parsing, in-terleaved processing uses packing to collapse anal-yses for later processing.
Analyses are collapsed ifthey have the same parent nonterminal, incorpo-rating both syntactic and semantic features, andthe same semantic sortal properties.Defer red  Sor ta l -Const ra in t  App l i ca t ionIn Gemini, there are two sources of semantic am-biguity to be considered when interleaving syntaxand semantics in parsing: semantic rule ambiguityand sortal ambiguity.
For every syntactic rule ofthe form:Rulename: A,vn ~ B, vn, C, vnthere are one or more semantic rules indexed onthe same rule name:Rulename:( LFA, A,,,n) ~ ( LFB, B,e,n), ( LF?
, C,,m)Here, LFA, LFB and LFc are logical form expres-sions indicating how the logical form LFA is tobe constructed from the logical forms of its chil-dren LFB and LFc, and A, B, and C are categoryexpressions that are unified.The second source of semantic ambiguity issortal ambiguity.
Every atom in a logicM formexpression is assigned one or more semantic sorts.For example, in the logical form fragmentexists ( (A ; \[flight\] ),\[and,\[flight, (A; \[flight\] )\] ; \[prop\],\[to, (A; \[flight\] ),('BOSTOn' ; \[city\] )\] ; \[prop\]\] ;\[prop\] ) ;\[prop\]the atoms exists, and, flight, to and 'BOSTON'have sort assignments (sorts are printed as theright-hand side of the ';' operator).
Someatoms like 'BOSTON' are assigned atomic sortslike \ [c i ty \ ] ,  while other atoms like to are as-signed more complex sorts, for instance, a func-constraints first, at least for our grammar at the time.We speculate that this is due to unifying multiple vari-ants of the same syntactic pattern against he chart incases where one syntactic rule has several correspond-ing semantic rules, and that applying syntactic rulesfirst provides an effective filter for faster matching.113tion from flights and cities to propositions, rep-resented as ( \[ \ [ f l i ght \ ] ,  \ [c i ty \ ]  ,  \[prop\] ).
Sortsfor nonatomic logical form expressions are thenconstructed recursively from the subexpressionsthey contain.
For instance, the expression \ [ to,(A; \ [ f l i ght \ ]  ), ('BOSTON'; \ [c i ty \ ]  )\] is assignedthe sort \[prop\] because there is a possible sortassignment for to consistent with the relation toholding between something of sort \ [ f l i ght \ ]  andsomething of sort \ [c i ty \ ] .If an atom within a logical form expressionhas more than one possible sort assignment, henthe expression may be ambiguous if the other sortsin the expression do not further constrain it; if alogical form expression associated with a syntacticedge is ambiguous, then new edges are added tothe chart for each of the possible semantic read-ings.
This is very common with sort assignmentsfor logical form functors.
If all the arguments ofthe functor have already been found at the pointwhen the functor is first encountered in a logi-cal form expression, then usually only one possi-ble sort assignment for the functor will apply, andthe resulting semantic edge will be sortally unam-biguous.
If the functor is encountered in a phrasewhere one or more of its arguments have not yetbeen encountered, such as a verb phrase before ithas been combined with its ?ubject, edges for allpossible sorts for the missing arguments will behypothesized, creating local sort ambiguities.
Ascan be seen in Table 2, there is a modest increasein the number of edges created per utterance dueto semantic rule ambiguity, but a much more dra-matic increase due to sortal ambiguity.The approach we have taken to deal with thisproblem is to prevent sortal ambiguity from mul-tiplying out into distinct edges in the chart, bydeferring the application of sortal constraints ineases where sortal ambiguities would be created.To implement this approach, we associate with ev-ery semantic edge a set (possibly empty) of de-ferred sort assignments.
In order to construct thisset for an edge, we create deferred sort assignmentsfor any logical form atoms introduced by the se-mantic rule or lexical entry that created the edgethat have more than one possible sort, given allthe information we have at that edge (such as thesorts of the arguments of a functor).
For a phrasaledge, we add to this any deferred sort assignmentsinherited from the daughters of the edge.Once the set of deferred sorts has been con-structed, but before the new edge is added to thechart, the set is analyzed to determine whether itis consistent, and to remove any deferred sort as-signments that have become unambiguous becauseof unifications performed in creating the edge.Since the deferred sort assignments can share logicvariables, it is possible that even though each de-farted assignment is ambiguous, there is no assign-ment of sorts that can satisfy all constraints at thesame time, in which case the edge is rejected.
Theincorporation of additional information from sib-ling nodes can result in a sortal ambiguity becom-ing resolved when an edge is constructed, in whichcase the resulting sort assignment is applied andremoved from the set of deferred sort assignments.Finally, we check whether the deferred sort assign-ments, although individually ambiguous, jointlyhave a unique solution.
In this case, that assign-ment of values is applied, and the set of deferredsort assignments becomes the empty set.Type ofProcessingSyntax OnlyPlus Semantic RulesPlus SortsWith Deferred SortsEdges/ Sees/ Sees/Utt Edge Utt203 0.005 0.98209 0.006 1.20357 0.011 4.04194 0.007 1.33Table 2: Results of Deferring Sortal ConstraintsThe effectiveness of this technique is demon-strated by Table 2, which compares the averagenumber of edges per utterance, average parse timeper edge, and average parse time per utterancefor four different modes of processing: syntax-only parsing, interleaving syntax and semanticswithout applying sortal constraints, interleavingsyntax and semantics while immediately apply-ing sortal constraints, and interleaving syntax andsemantics while deferring ambiguous ortal con-straints.
We can see that the total number ofsemantic edges is reduced significantly, resultingin a decrease in the total syntax+semantics+sortstime by a factor of 3.
Note that despite the addi-tion of semantic rule ambiguity, the total numberof edges built during interleaved syntactic and se-mantic processing is less than the number of edgesbuilt using syntax alone, demonstrating that wein fact succeed in using semantic information toprune the syntactic search space.IMPROVING ACCURACY INSPEECH RECOGNIT IONOne of our prime motivations in designing a parserto find all syntactically well-formed semanticallymeaningful phrases in a word string was to beable to use it for the robust application of natural-language constraints in speech recognition.
Mostattempts to apply natural-language constraints inspeech recognition have relied on finding a com-plete parse for a recognition hypothesis.
Manyhave worked by simply picking as the preferredhypothesis the string with the highest recognition114score that can be completely parsed and inter-preted.It seems virtually impossible, however, tocreate a natural-language rammar that modelsspontaneous spoken language accurately enoughto avoid introducing more errors than it corrects,if applied in this way.
A state-of-the-art natural-language grammar for a problem such as theARPA ATIS task might fail to find a completeanalysis for 10% or more of test utterances.
In thiscase, a substantial recognition error rate would beintroduced, because of the correct utterances thatwould be completely excluded, and it is extremelyunlikely that the grammar would result in enoughreduction of the recognition errors of a state-of-the-art speech recognizer on other utterances toovercome the errors it introduces.We have taken a different approach based onthe observation that, even when our grammar failsto provide a complete analysis of an utterance, it isusually possible to find a small number of semanti-cally meaningful phrases that span the utterance.We therefore use our parser to find the minimalnumber of semantically meaningful phrases neededto span a recognition hypothesis and to computea natural-language score for the hypothesis basedon this number.
Having a parser that finds allsyntactically well-formed semantically meaningfulphrases is an obvious prerequisite to taking suchan approach.We have applied this idea in a system combin-ing Gemini with SRI's DECIPHER TM speech rec-ognizer (Murveit et al, 1993), which was tested inthe December 1993 ARPA ATIS benchmark evalu-ation (Pallet et al, 1994).
The following examplefrom the evaluation test set illustrates the basicapproach:hypothesis: \[list flights\]\[of fare code\]\[a\]\[q\]reference: \[list flightsl\[of fare code of q\]These two word strings represent the recognizer'sfirst hypothesis for the utterance and the referencetranscription of the utterance, each bracketed ac-cording to the best analysis that Gemini was ableto find as a sequence of semantically meaningfulphrases.
Because of a missing sortal possibility,Gemini did not allow the preposition of to re-late a noun phrase headed by flights to a nounphrase headed by fare code, so it was not possi-ble to find a single complete analysis for eitherword string.
Gemini was, however, able to find asingle phrase spanning of fare code of q, but re-quired three phrases to span of fare code a q, so itstill strongly preferred the reference transcriptionof the utterance over the recognizer's first hypoth-esis.The integration of Gemini and DECIPHERwas implemented by combining a Gemini scorewith the recognition score for each of the rec-ognizer's N-top hypotheses and selecting the hy-pothesis with the best overall score.
4 The Geminiscore was computed as a somewhat ad hoc combi-nation of the number of phrases needed to coverthe hypothesis, a bonus if the hypothesis could beanalyzed as a single sentence (as opposed to anyother single grammatical phrase), and penaltiesfor using certain "dispreferred" grammar rules.This score was then scaled by an empirically op-timized parameter and added to the recognitionscore.We carried out a detailed analysis of thepreliminary results of the December 1993 ARPAATIS benchmark evaluation to determine the ef-fect of incorporating natural-language informationinto recognition in this way.
Overall, the worderror rate improved from 6.0% to 5.7% (5.0% im-provement), and the utterance rror rate improvedfrom 29.6% to 27.8% (6.1% improvement).
Theseimprovements, while modest, were measured to bestatistically significant at the 95% confidence l velaccording to the rhatched-pair sentence segment(word error) test and the McNemar (sentence r-ror) test.In more detail, the first hypothesis of the rec-ognizer was correct for 704 of 995 utterances forwhich the natural-language rammar was used.
Ofthese, the natural-language rammar failed to findcomplete analysis for 62.
The combined systemnevertheless chose the correct hypothesis in 57 ofthese cases; thus, only 5 correct hypotheses werelost due to lack of grammar coverage.
On theother hand, use of the natural-language rammarresulted in correcting 22 incorrect recognizer firsthypotheses.
Moreover, 4 of these were not com-pletely analyzable by the natural-language ram-mar, but were chosen because they received a bet-ter analysis as a sequence of phrases than the firsthypothesis of the recognizer.We also analyzed which of the natural-language factors incorporated in the Gemini scorewere responsible for the corrections and errors rel-ative to the performance of the recognizer alone.For the 22 utterances that were corrected, in 18cases the correction was due to the preference forfewer fragments, in 3 cases the correction was dueto the preference for complete sentences, and inonly one case did the correction result from agrammar rule preference.
Of the 5 utterance rrorsintroduced by Gemini, 3 turned out to be casesin which the reference transcription was incorrectand the hypothesis elected by Gemini was actu-4The value of N was variable, but sufficiently large(typically hundreds) that a limit on N was never afactor in which hypothesis was chosen.115ally correct, one was due to inadequate grammat-ical coverage resulting in a larger number of frag-ments for the correct hypothesis, and one was dueto a grammatical rule preference.
We concludedfrom this that the preference for fewer fragmentsis clearly useful and the preference for completesentences seems to be somewhat useful, but thereis no evidence that the current system of rule pref-erences is of any benefit in speech recognition.
Amore systematic approach to rule preferences, uchas one based on a statistical grammar, may be ofmore benefit, however.CONCLUSIONSWe have described an efficient parser that oper-ates bottom-up to produce syntactic and semanticstructures fully interleaved.
Two techniques com-bine to reduce the total ambiguity represented inthe chart.
Limited left-context constraints reducelocal syntactic ambiguity, and deferred sortal-constraint application reduces local semantic am-biguity.
We have expermentally evaluated thesetechniques, and shown order-of-magnitude reduc-tions in both number of chart edges and total pars-ing time.
The robust processing capabilities of theparser have also been shown to be able to providea small but significant increase in the accuracy ofa speech recognizer.ACKNOWLEDGMENTSWe would like to thank Mark Gawron for helpfulcomments on earlier drafts, and the SRI speechgroup, particularly Harry Bratt, for help perform-ing the speech recognition experiments.REFERENCESAlshawi, H.
(ed.).
1992.
The Core Language En-gine.
MIT Press, Cambridge, Massachusetts.Dowding, J., Garwon, J., Appelt, D., Bear, 3,Cherny, L., Moore, R., and Moran, D. 1993.GEMINI: A Natural Language Understand-ings System for Spoken-Language Understand-ing, in 31st Annual Meeting of the Associationfor Computational Linguistics, Columbus, Ohio(June), pp.
54-61.Earley, J.
1970.
An Efficient Context-Free ParsingAlgorithm, Communications of the ACM, 31,2(Feb.), pp.
94-102.Graham, S., Harrison, M., and Ruzzo, W. 1980.An Improved Context-Free Recognizer, ACMTransactions on Programming Languages andSystems, 2,3 (July), pp.
415-462.Hopcroft, J. and Ullman, J.
1980.
Introduc-tion to Automata Theory, Languages, and Com-putation, Addison-Wesley Publishing, Reading,Massachusetts.Kasami, T. 1965.
An Efficient Recognition andSyntax Algorithm for Context-Free Languages,Scientific Report AFCRL-65-758, Air ForceCambridge Research Laboratory, Bedford, Mas-sachusetts.MADCOW 1992.
Multi-site Data Collection for aSpoken Language Corpus, in Proceedings of theDARPA Speech and Natural Language Work-shop, February 23-26, pp.
7-14.Moore, R., and Dowding, J.
1991.
EfficientBottom-Up Parsing, in Proceedings of theDARPA Speech and Natural Language Work-shop, February 19-22, pp.
200-203.Murveit, H., Butzberger, J., Digalakis, V. andWeintraub, M. 1993.
Large-Vocabulary Dicta-tion Using SRI's DECIPHER TM Speech Recog-nition System: Progressive-Search Techniques,in Proceedings of the IEEE International Con-ference on Acoustics, Speech and Signal Process-ing, Minneapolis, Minnesota (April), pp.
II-319-II-322.Pallet, D. et al 1994.
1993 Benchmark Testsfor the ARPA Spoken Language Program, inProceedings of the ARPA Workshop on HumanLanguage Technology, March 8-11.Shieber, S. 1985.
Using Restriction to Ex-tend Parsing Algorithms for Complex-Feature-Based Formalisms, in 23rd Annual Meeting ofthe Association for Computational Linguistics,Chicago, Illinois (July), pp.
145-152.Younger, D. 1967.
Recognition and Parsing ofContext-Free Languages in Time n a, Informa-tion and Control, 10, 2, pp.
189-208.116
