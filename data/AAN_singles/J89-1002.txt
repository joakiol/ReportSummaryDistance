SYNTACTIC GRAPHS: A REPRESENTATION FORAMBIGUOUS PARSE TREESTHE UNION OF ALLJungyun SeoRobert F. SimmonsArtificial Intell igence LaboratoryUniversity of Texas at Aust inAustin, TX 78712-1188In this paper, we present a new method of representing the Surface syntactic structure of a sentence.Trees have usually been used in linguistics and natural language processing to represent syntacticstructures of a sentence.
A tree structure shows only one possible syntactic parse of a sentence, but inorder to choose a correct parse, we need to examine all possible tree structures one by one.
Syntacticgraph representation makes it possible to represent all possible surface syntactic relations in one directedgraph (DG).
Since a syntactic graph is expressed in terms of a set of triples, higher level semanticprocesses can access any part of the graph directly without navigating the whole structure.
Further-more, since a syntactic graph represents the union of all possible syntactic readings of a sentence, it isfairly easy to focus on the syntactically ambiguous points.
In this paper, we introduce the basic idea ofsyntactic graph representation and discuss its various properties.
We claim that a syntactic graphcarries complete syntactic information provided by a parse forestmthe set of all possible parse trees.1 INTRODUCTIONIn natural anguage processing, we use several rules andvarious items of knowledge to understand a sentence.Syntactic processing, which analyzes the syntactic re-lations among constituents, is widely used to determinethe surface structure of a sentence, because it is effec-tive to show the functional relations between constitu-ents and is based on well-developed linguistic theory.Tree structures, called parse trees, represent syntacticstructures of sentences.In a natural anguage understanding system in whichsyntactic and semantic processes are separated, thesemantic processor usually takes the surface syntacticstructure of a sentence from the syntactic analyzer asinput and processes it for further understanding.
~ Sincethere are many ambiguities in natural anguage parsing,syntactic processing usually generates more than oneparse tree.
Therefore, the higher level semantic proces-sor should examine the parse trees one by one to choosea correct one.
2 Since possible parse trees of sentencesin ordinary expository text often number in the hun-dreds, it is impractical to check parse trees one by onewithout knowing where the ambiguous points are.
Wehave tried to reduce this problem by introducing a newstructure, the syntactic graph, that can represent allpossible parse trees effectively in a compact form forfurther processing.
As we will show in the rest of thispaper, since all syntactically ambiguous points are keptin a syntactic graph, we can easily focus on those pointsfor further disambiguation.Furthermore, syntactic graph representation can benaturally implemented in efficient, parallel, all-pathparsers.
One-path parsing algorithms, like the DCG(Pereira and Warren 1980), which enumerates all possi-ble parse trees one by one with backtracking, usuallyhave exponential complexity.
All-path parsing algo-rithms explore all possible paths in parallel withoutbacktracking (Early 1970; Kay 1980; Chester 1980;Tomita 1985).
In these algorithms, it is efficient togenerate all possible parse trees.
This kind of algorithmhas complexity O(N 3) (Aho and Ullman 1972; Tomita1985).We use an all-path parsing algorithm to parse asentence.
Triples, each of which consists of two nodesand an arc name, are generated while parsing a sen-tence.
The parser collects all correct triples and con-structs an exclusion matrix, which shows co-occurrenceconstraints among arcs, by navigating all possible parseCopyright 1989 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/89/010019-32503.00Computational Linguistics, Volume 15, Number 1, March 1989 19Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Trees.
,  J l  \[I'se''vl I vtp .
_ .
.
.
_ ~/ .I"... .
,, , i i , .
, .
, .
.
.o.
.o, II dotSentence: I saw a man on the hill with a telescope.
I\[8,a,artl \[Figure 1: Syntactic Graph of the Example Sentence.trees in a shared, packed-parse forest) We claim that asyntactic graph represented by the triples and an exclu-sion matrix contains all important syntactic informationin the parse forest.In the next section, we motivate this work with anexample.
Then we briefly introduce X (X-bar) theorywith head projection, which provides the basis of thegraph representation, and the notation of graph repre-sentation in Section 3.
The properties of a syntacticgraph are detailed in Section 4.
In Section 5, weintroduce the idea of an exclusion matrix to limitpossible tree interpretations of a graph representation.In Section 6, we will present the definition of complete-ness and soundness of the syntactic graph representa-tion compared to parse trees by showing an algorithmthat enumerates all syntactic readings using the exclu-sion matrix from a syntactic graph.
We claim that thosereadings include all the possible syntactic readings ofthe corresponding parse forest.
Finally, after discussingrelated work, we will ~uggest future research and drawsome conclusions.2 MOTIVATIONAL EXAMPLEWe are currently investigating a model of natural an-guage text understanding in which syntactic and seman-tic processors are separated.
4 Ordinarily, in this model,a syntactic processor constructs a surface syntacticstructure of an input sentence, and then a higher levelsemantic processor processes it to understand the sen-tence---i.e., syntactic and semantic processors are pipe-lined.
If the semantic processor fails to understand thesentence with a given parse tree, the semantic processorshould ask the syntactic processor for another possibleparse tree.
This cycle of processing will continue untilthe semantic processor finds the correct parse tree withwhich it succeeds in understanding the sentence.Let us consider the following sentences, from Waltz(1982):I saw a man on the hill with a telescope.I cleaned the lens to get a better view.When we read the first sentence, we cannot determinewhether the man has a telescope or the telescope isusedto see the man.
This is known as the PP-attachmentproblem, and many researchers have proposed variousways to solve it (Frazier and Fodor 1979; Shubert 1984,1986; Wilks et.
al 1985).
In this sentence, however, it isimpossible to choose a correct syntactic reading insyntactic processing---even with commonsense knowl-edge.
The ambiguities must remain until the systemextracts more contextual knowledge from other inputsentences.The problems of tree structure representation in thepipelined, natural anguage processing model are thefollowing:First, since the number of parse trees of a typicalsentence inreal text easily grows to several hundreds,and it is impossible to resolve syntactic ambiguitiesby the syntactic processor itself, a semantic processormust check all possible parse trees one by one until itis satisfied by some parse tree.
5Second, since there is no information about where theambiguous points are in a parse tree, the semanticprocessor should check all possibilities before accept-ing the parse tree.Third, although the semantic processor might besatisfied with a parse tree, the system should keep thestatus of the syntactic processor for a while, becausethere is a fair chance that the parse tree may becomeunsatisfactory after the system processes everalmore sentences.
For example, attaching the preposi-tional phrase (PP) "with a telescope" to "hill" or"man" would be fine for the semantic processor,since there is nothing semantically wrong with theseattachments.
However, these attachments becomeunsatisfactory after the system understands the next20 Computational Linguistics, Volume 15, Number 1, March 1989Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Treessentence.
Then, the semantic processor would haveto backtrack and request from the syntactic processoranother possible parse tree for the earlier sentence.We propose the syntactic graph as the output structureof a syntactic processor.
The syntactic graph of the firstsentence in the previous example is shown in Figure 1.In this graph, nodes consist of the positions, the rootforms, and the categories of words in the sentence.Each node represents a constituent whose head word isthe word in the node.
Each arc shows a dominator-modifier elationship between two nodes.
The name ofeach arc is uniquely determined according to the gram-mar rule used to generate the arc.
For example, the snparc is generated from the grammar rule, SNT ~ NP VP,vpp is from the rule, VP ~ VP PP, and ppn from therule, PP ~ Prep NP, etc.As we can see in Figure 1, all syntactic readings arerepresented in a directed graph in which every ambigu-ity--lexical ambiguities from words with multiple syn-tactic categories and structural ambiguities from theambiguous grammar--is kept.
The nodes which arepointed to by more than one arc show the ambiguouspoints in the sentence, so the semantic processor canfocus on those points to resolve the ambiguities.
Fur-thermore, since a syntactic graph is represented bya setof triples, a semantic processor can directly access anypart of a graph without traversing the whole.
Finally,syntactic graph representation is compact enough to bekept in memory for a while.
63 X THEORY AND SYNTACTIC GRAPHSBX theory was proposed by Chomsky (1970) to explainvarious linguistic structural properties, and has beenwidely accepted in linguistic theories.
In this notation,the head of any phrase is termed X, the phrasal categorycontaining X is termed_X, and the phrasal categorycontaining X is termed X.
For example, the head of anoun__phrase is N (noun), N is an intermediate category,and N corresponds to noun phrase (NP).
The generalform of the phrase structure rules for X theory isroughly as follows:?
~ '~ ~*  X?
X---> XZ * , where * is a Kleene star.Yis the phrase that specifies X, and Z is the phrase thatmodifies X.
7 The properties of the head word of aphrase are projected onto the properties of the phrase.We can express agrammar with X conventions tocovera wide range of English.Since, in X theory, a syntactic phrase consists of thehead of the phrase and the specifiers and modifiers ofthe head, if there are more than two constituents in theright-hand side of a grammar ule, then there aredominator-modifier (DM) relationships between thehead word and the specifier or modifier words in theComputational Linguistics, Volume 15, Number 1, March 1989phrase.
Tsukada (1987) discovered that the DM rela-tionship is effective for keeping all the syntactic ambi-guities in a compact and handy structure without enu-merating all possible syntactic parse trees.
Hisrepresentation, however, is too simple to maintain someimportant information about syntactic structure thatwill be discussed in detail in this paper, and hence failsto take full advantage of the DM-relationship represen-tation.We use a slightly different representation to maintainmore information in head-modifier relations.
Eachhead-modifier relation is kept in a triple that is equiva-lent to an arc between two nodes (i.e., words) in asyntactic graph.
The first element of a triple is the arcname, which represents he relation between the headand modifier nodes.
The second element is the lexicalinformation of the head node, and the third element isthat of the modifier node.
The direction of an arc isalways from a head to a modifier node.
For example,the triple \[snp, \[1,see,v\], [0~t~\]\] represents the arcsnp between the two nodes \[1,aoo,v\] and \[0,t~_\] inFigure 1.Since many words have more than one lexical entry,we have to keep the lexical information of each word ina triple so that we can distinguish different usages of aword in higher level processing.
The triples correspond-ing to some common grammar rules are as follows:1.
N--* Det N ?=~ \[det,\[\[nl,Rl\]lLl\],\[\[n2,R2\]lL2\] \]2.
N -*  Adj N ?=~ \[mod,\[\[n3,R3\]lL3\],\[\[n4,R4\]ll4\] \]3.
N --~ N Prep ?=> \[npp,\[\[n5,R5\]lLs\],\[\[n6,R61L6\] \]Each ni represents he position, each Ri represents heroot form, and each Li represents a list of the lexicalinformation including the syntactic ategory of eachword in a sentence.
Parentheses signify optionality andthe asterisk (*) allows repetition.Figure 2 shows the set of triples representing thesyntactic graph in Figure I and the grammar rules usedto parse the sentence.
The sentence in Figure 2 has fivepossible parse trees in accordance with the grammarrules.
All of the dependency information in those fiveparses is represented in the 12 triples.
Those 12 triplesrepresent all possible syntactic readings of the sentencewith the grammar rules.
Not all triples can co-occur inone syntactic reading in the case of an ambiguoussentence.The pointers of each triple are the list of the indicesthat are used as the pointers pointing to that triple.
Forexample, Triple 2 in Figure 2 has a list of three indicesas the pointers.
Each of those indices can be used as apointer to access the triple.
These indices are actuallyused as the names of the triple.
One triple may havemore than one index.
The issues of why and how toproduce indices of triples will be discussed later in thissection.Triple 3 in Figure 2 represents he vnp arc in FigureI between two nodes, \[1,aoo,v\] and \[3,ma, n n\].
Thenode \[1,8oo,v\] represents a VP with head word21Jungyun See and Robert F. Simmons Syntactic Graphs: ,% Representation for the Union of All Ambiguous Parse TreesGRAMMAR RULES AND CORRESPONDING TRIPLES:Grammar rules arc-name head modifieri.
SNT--~NP VP snp header  VP head of NP2.
NP--,art NP det head of NP art3.
NP--,N' head of N'4.
N' --,N' PP npp head of N' head of PP5.
N' - *noun noun6.
PP--*prep NP ppn prep headofNP7.
VP--~V' head of V'8.
V ' - *V '  NP vnp headef  V' head of NP9.
V'--*V' PP vpp head of V' head of PPI0.
V'--~verb verbSENTENCE:1.2.3.4.5.6.7.8.9.10.11.12.I SAW AMANON THE HILLTr ip les for the Input Sentence\[snp, \ [ \ [ l ,see\] ,categ,verb,tns,past \ ]\[ \[O, i \] ,categ,noun.
nbr,sing\] \]\[det, \ [ \ [3,man\] ,categ,noun,nbr,s ing\]\ [ \ [2 ,a \ ] , ca teg ,ar t , ty , indef \ ]  \]\[vnp, \ [ \ [1 ,see\ ] ,categ,verb, tns ,past \ ]\[\[3,man\],categ,noun,nbr,sing\]\[vpp.
\ [ \ [1 ,see\ ] ,categ,verb, tns .past \ ]\[\[4,on\],categ,prep\] \]\[npp, \ [ \ [3 ,man\ ] , ca teg ,  noun ,nbr , s ing \ ] ,\ [ \ [4 ,on \ ] , ca teg ,prep \ ]  \]\ [det ,  \ [ \ [6 ,h i l l \ ] ,categ,noun,nbr ,s ing\] ,\ [ \ [5 , the \ ] , ca teg ,  a r t , ty ,de f \ ]  \]\[ppn, \[ \[4,on\],categ,prep\],\ [ \ [6,h i l l \ ] ,categ,noun,nbr,s ing\]  \]\[vpp, \ [ \ [1,see\] ,categ, verb, tns ,past \ ] ,\ [ \ [7 ,w i th \ ] , ca teg ,prep \ ]  \]\[npp, \ [ \ [6 ,h i l l \ ] ,categ,noun,nbr ,s ing\] ,\[ \[7,with\],categ,prep\] \]\[npp, \[\[3,man\],categ.noun,nbr,sing\],\ [ \ [7 ,w?th \ ] , ca teg ,prep \ ]  \]\ [det ,  \ [ \ [9,telescope\] ,categ,noun.nbr,s ing\] ,\ [ \ [8 ,a \ ] ,categ,ar t , ty , indef \ ]  \]\[ppn, \ [ \ [7,with\] ,categ,prep\] ,\ [ \ [9,teleseope\] ,categ,noun.nbr,s ing\]  \] \[15\]Figure 2 Grammar Rules and Example triples.WITH A TELESCOPEPointers\[22\]\[02, 09, 20\]\[03, zo, 2l\]\[13, 24\]\[08, 19\]\[06, 17\]\[07, 18\]\[28\]\[18\]\[25\]\[14\]\[1,see,v\], and the node \[34"aan,n\] represents an NPwith head word \[3,ma, n,n\].
\[ 1,see,v\] becomes the headword, and \[3,rna, u,u\] becomes the modifier word, ofthis triple.
The number 1 in r 1,sea,v\] is the position ofthe word "see" in the sentence, and v (verb) is thesyntactic category of the word.
Since a word mayappear in several positions in a sentence, and one wordmay have multiple categories, the position and thecategory of a word must be recorded to distinguish thesame word in different positions or with different cate-gories.A meaningful relation name is assigned to each pairof head and modifier constituents in a grammar rule.Some of these are shown at the top of Figure 2.
Rulesfor generating triples augment each correspondinggrammar rule.
Some grammar rules in Prolog syntaxused to build syntactic graphs are shown in Figure 3.An informal description of the algorithm for generat-ing triples of a syntactic graph using the grammar rulesin Figure 3 is the following: The basic algorithm of theparser is an all-path, bottom-up, chart parser that con-structs a shared, packed-parse forest.
Unlike an ordi-nary chart parser, the parser uses two charts, one for~ i. snt--*np + vpgr(\[snt, Vhd\],\[\[np, Nhd\], ~vp.
Vhd\]\],( true ),\[\[snp, Vhd, Nhd\]\]).~ 2. np~ar t i c le  + nplgr(\[np.
Nhd\].\[\[art, Det\], \[npl, Nhd\]\].
( true ),\[\[act, Nhd, Det\]\]).~ 3. np--~nplgr(\[np, Nhd\],\[\[npl.
Nhd\]\].
(true),\[ \]).~ 4. vp~be_aux + vpgr(Ivp, Aux\],category and head of LHS of rule.categories and heads of RHS.constraints, in this case, nonelist of triples generatedVhd is head word, Nhd is modifier.Nhd, the head of npl, becomes new headNhd is head and Det is modifier.since there is only one constituent% in hereno triple will be generated inthis rule(be + vp) either passive or progressive\[\[beaux.
Aux\], \[vp, Vhd\]\],( mempr(\[inflection, INFL\], Vhd).
( INFL = paprt ~ if inflection of vp is passive--~ ~ participle, thenTriples = \[\[beaux, Aux.
Vhd\], \[voice, Vhd, passive\]\]: ~ otherwise,( INFL = prprt ~ if inflection is present participle-~ ~ then,Triples = \[\[be_aux, Aux, Vhd\], progressive, Vhd, yes\]\]; ~ otherwise,fail ) ) ), ~ this rule cannot be applied.Triples).Figure 3 Augmented grammar ules for triple generation.constituents and the other for triples.
Whenever theparser builds a constituent and its triple, the parsergenerates an index for the triple, 9 and records the tripleon the chart of triples using the index.
Then it recordsthe constituent with the index of the triple on the chartof constituents.We use Rule 4 in Figure 3 to illustrate the parser.Rule 4 states that if there are two adjacent constituents,a be-aux followed by a vp, execute the procedure in thethird argument position of the rule.
The procedurecontains the constraints that must be satisfied to makethe rule to be fired.
If the procedure succeeds, theparser records a new constituent \[vp,Vhd\]~the firstargument of the rule---on the chart.
Before the parserrecords the constituent, it must check the triples for theconstituent.
The procedure in the third argument posi-tion also contains the processes to produce the triplesfor the constituent.The fourth argument of a grammar rule is a list oftriples produced by executing the augmenting proce-dure at the third argument position of the rule.
If theconstraints in the procedure are satisfied, the triples arealso produced.
The parser generates a unique index foreach triple, records the triples on the chart of triples,and adds to the new constituent, the indices of the newtriples.
Then, the new constituent is recorded on thechart of constituents.
In this example, the head of thenew constituent is the same as that of be-aux; i.e., thebe-aux dominates the vp.After finishing the construction of the shared,packed-parse forest of an input sentence, the parsernavigates the parse forest to collect the triples that22 Computational Linguistics, Volume 15, Number 1, March 1989Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Treespointer \[category, head, list ofchildnodesandindex1047 \[snt,1002 \[np,i001 \[npl,I000 \[n.1046 \[vp,1045 \[vpl1027 \[vpl,1013 \[vpl,1004 \[vpl,i003 \[verb,1012 \[np,1008 \[art,I011 \[np,i010 \[npl.1009 \[noun,1023 \[pp,1017 \[prep,1022 \[np,1018 \[art,1021 \[np,1020 \[npl,I019 \[noun.1026 \[np.1025 \[np,1024 \[npl,1037 \[pp,1031 \[prep,1036 \[np,1032 \ [art ,1035 \[np,1034 \[npl,1033 \[noun,1041 \[pp,1040 \[np,1039 \[np,1038 \[npl,1044 \[np,1043 \[np,1042 \[npl,of triple\]\[1,see\].
\[\[1002, 1046\], 22\] \]\ [0 , i \ ] ,  \[\[1001\], not r ip le \ ]  \]\ [O, i \ ] ,  \[\[1000\], not r ip le \ ]  \]\[0, i \] ,  \[\]\]\[1,see\], \[\[i045\], notriple\] \]\[l,see\], \[\[i004, i044\], 21\],\[\[1013, 1041\], 24\],\[\[1027, 1037\], 26\] \]l,see\], \[\[1004, i026\], i0\],\[\[lO13, lO23\], 13\] \ ]\[l,see\], \[\[1004, i012\], 03\] \]\[l,see\], \[\[i003\], notriple\] \]\[1,see\], \[\] \]\[3,man\], \[\[1008, i011\], 02\] \]\ [2,a\ ] ,  \[\] \]\[3,man\], \[\[i010\], notriple\] \]\[3,man\], \[\[1009\], notriple\] \]\[3,man\], \[\] \]\[4,on\], \[\[1017, I022\], 07\] \]\[4,on\], \[\]\]\ [e ,h i l l \ ] ,  \[\[1018.
1021\], 06\] \]\[5.the\], \[\] \]\[6,hill\], \[\[I020\], notriple\] \]\[6,hill\], \[\[i019\], notrlple\] \]I S ,h i l l \ ] ,  \[\] \]\[3.man\], \[\[i008, i025\], 09\] \]\[3,man\], \[\[i024\], notriple\] \]\[3,man\], \[\[i010, i023\], 08\] \]\[7,wlth\], \[\[1031, i036\], 15\] \]\[7,with\], \[\] \]\ [9,telescope\] ,  \[\[1032, 1035\], 14\] \]\[8,a\], \[\] \]\[9,telescope\], \[\[i034\], notriple\] \]\[9,telescope\].
\[\[i033\], notriple\] \]\[9,telescope\], \[\] \]\[4.on\], \[\[1017, 1040\], 18\] \]\ [6 ,h i l l \ ] ,  \[\[1018, 1039\], 17\] \]\[6,hill\], \[\[i038\], notriple\] \]\ [6 ,h i l l \ ] .
\[\[1020, 1037\], 18\] \]\[3,man\], \[\[1008, i043\], 20\] \]\[3,man\], \[\[i042\], notriple\] \]\[3,man\], \[\[i010, i041\], 19\],\[\[1024, 1037\], 25\] \]A packed node contains several nodes, each of whichcontains the category of the node, its head word, andthe list of the pointers to its child nodes and the indicesof the triples of the node.
Node 1045 in Figure 4 is apacked node in which three different constituents arepacked.
Those three constituents have the same cate-gory, vpl, span the same terminals, (from \[ 1,see,v\] to\[9,telescope.n\] ), with the same head word, (\[ 1,see,v\]),but with different internal substructures.Note that several constituents may have differentindices that point to the same triple.
For example, inFigure 4, the first vpl in the packed node 1045 has theindex 21, the first vpl in the packed node 1027 has theindex 10, and the vpl node in the packed node 1013 hasthe index 13 as the indices of their triples.
Actually,these three indices represent he same triple, Triple 3 inFigure 2.
Those three constituents have the same cate-gory, vpl, the same head, \[1,see,v\], and the samemodifier, \[3,man,n\], but have different inside struc-tures of the modifying constituent, np, whose head is\[3arian,n\].
The modifying constituent, np, may spanfrom \[2,a\] to \[3maan\], from \[2,a\] to \[6~hill\], or from\[2,a\] to \[9,telescope\].There are different types of triples that do not havehead-modifier elations.
These types of triples are forsyntactic haracteristics of a sentence such as mood andvoice of verbs.
For example, grammar rule 4 in Figure3 generates not only triples of head-modifier elations,but also triples that have the information about thevoice or progressiveness of the head word of the VP,depending on the type of inflection of the word.
Thiskind of information can be determined in syntacticprocessing and is used effectively in higher level seman-tic processing.Figure 4 Shared, Packed-Parse Forest.
4 PROPERTIES OF SYNTACTIC GRAPHSparticipate in each correct syntactic analysis of thesentence.
The collecting algorithm is explained in Sec-tion 5.2 in detail.The representation of the shared, packed-parse for-est for the example in Figure 2 is in figures 4 and 5.
'o Itis important to notice that the shared, packed-parseforest generated in this parser is different from that ofother parsers.
In the shared, packed-parse forest de-fined by Tomita (1985), any constituents that have thesame category and span the same terminal nodes areregarded as the same constituent and packed into onenode.
In the parser for syntactic graphs, the packingcondition is slightly different in that each constituent isidentified by the head word of the constituent as well asthe category and the terminals it spans.
Therefore,although two nodes might have the same category andspan the same terminals, if the nodes have differenthead words, then they cannot be packed together.We first define several terms used frequently in the restof the paper.Definition 1: An in-arc of a node in a syntactic graphis an arc which points to the node, and an out-arc ofa node points away from the node.Since, in the syntactic graph representation, arcs pointfrom dominator to modifier nodes, a node with an in-arcis the modifier node of the arc, and a node with anout-arc is the dominator node of the arc.Definition 2: A reading of the syntactic graph of asentence is one syntactic interpretation of the sen-tence in the syntactic graph.Since a syntactic graph is a union of syntactic analysesof a sentence, one reading of a syntactic graph isanalogous to one parse tree of a parse forest.Definition 3: A root node of one reading of a syntacticgraph is a node which has no in-arc in the reading.In most cases, the root node of a reading of the syntacticgraph of a sentence is the head verb of the sentence inthat syntactic interpretation.
In a syntactically ambigu-Computational Linguistics, Volume 15, Number 1, March 1989 23Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Trees:1002:1047vplvpl vpl:1046vpl vpl I :1045:104/4n~l npl I :1042PPnplvplIVsawnplPPnpnplartappn P art n P art nman on  the  h i l l  w i th  a te lescopeFigure 5 Shared, Packed-Parse Forest-A Diagram.ous sentence, different syntactic analyses of the sen-tence may have different head verbs; thus there may bemore than one root node in a syntactic graph.
Forexample, in the syntactic graph of one famous andhighly ambiguous sentence--"Time flies like anarrow"Dshown in Figure 6, there are three differentroot nodes.
These roots are \[O,tlmo,v\], [ 1,fly,v\], and\[ 2 rUke ,v \ ]  11 .Definition 4: The position of a node is the position ofthe word which is represented by the node, in asentence.Since a word may have several syntactic ategories,there may be more than one node with the same positionin a syntactic graph.
For example, since the word"time" in Figure 6, which appeared as the first word inthe sentence, has two syntactic ategories, noun andverb, there are two nodes, \[O,tame,n\] and \[O,Ume,v\], inthe syntactic graph, and the position of the two nodes is0.One of the most noticeable features of a syntactic24graph is that ambiguities are explicit, and can be easilydetected by semantic routines that may use fu~herknowledge to resolve them.
The following propertyexplains how syntactically ambiguous points can beeasily determined in a syntactic graph.Property 1: In a syntactic tree, each constituentexcept he root must by definition be dominated by asingle constituent.
Since a syntactic graph is theunion of aU syntactic trees that the grammar derivesfrom a sentence, some graph nodes may be domi-nated by more than one node; such nodes withmultiple dominators have multiple in-arcs in thesyntactic graph and show points at which the nodeparticipates in more than one syntactic tree interpre-tation of a sentence.
In a graph resulting from asyntactically unambiguous entence, no node hasmore than a single in-arc, and the graph is a tree withthe head verb as its root.According to Property 1, no pair of arcs which point tothe same node can co-occur in any one syntacticComputational Linguistics, Volume 15, Number 1, March 1989Jungyun Seo and Robert F. Simmom Syntactic Graphs: A Representation for the Union of All Ambiguous parse TreesIvpp rood npp \[4,arrow,Nl I \f I 11Sentence: Time flies like an arrow.Figure 6 Graph Representation a d Parse Trees of a Highly Ambiguous Sentence.reading, because ach node can be a modifier node onlyonce in one reading.
Therefore, we can focus on thearcs pointing to the same node as ambiguous points.
Interms of triples, any two triples with identical modifierterms reveal a point of ambiguity, where a modifier termis dominated by more than one node.In the example in Figure 1, the syntactic ambiguitiesare found in two arcs pointing to \[4,on,p\] and in threearcs pointing to \[7,w-it, la,p\].
The PP with head \[4,on\]modifies the VP whose head is \[1,see\] and it alsomodifies the NP with head \[3,ma~\].
Similarly threedifferent in-arcs to the node \[7,wit~\] show that thereare three possible choices to which Node 7 can beattached.
The semantic processor can focus on thesethree possibilities (or on the earlier two possibility set),using semantic information, to choose one dominator.Lacking semantic information, the ambiguities will re-main in the graph until they can be resolved by addi-tional knowledge from the context.Property 2: Since all words in a sentence must beused in every syntactic interpretation of the sentenceand no word can have multiple categories in oneinterpretation, one and only one node from eachposition must participate in every reading of a syn-tactic graph.
In other words, each syntactic readingderived from a syntactic graph must contain one andonly one node from every position.Since every node, except the root node, must beattached to another node as a modifier node, we canconclude the following property from properties 1and2.Property 3: In any one reading of a syntactic graph,the following facts must hold:I.
No two triples with the same modifier node canco-occur.2.
One and only one node from each position,except he root node of the reading, must appearas a modifier node.Another advantage of the syntactic graph representa-tion is that we can easily extract he intersection of allpossible syntactic readings from it.
Since one node fromeach position must participate in every syntactic read-ing of a syntactic graph, every node which is not a rootnode and has only one in-arc, must always be includedin every syntactic reading.
Such unambiguous nodes arecommon to the intersections of all possible readings.When we know the exact locations of several pieces ina jigsaw puzzle, it is much easier to place the otherpieces.
Similarly, if a semantic processor knows whicharcs must hold in every reading, it can use these arcs toconstrain inferences to understand and disambiguate.Property 4: There is no information in a syntacticgraph about the range of terminals panned by eachtriple, so one triple may represent several constitu-ents which have the same head and modifying terms,with the same relation name, but which span differ-ent ranges of terminals.The compactness and handiness of a graph representa-tion is based on this property.
One arc between twonodes in a syntactic graph can replace several compli-cated structures in the tree representation, and multipledominating arcs can replace a parse forest.For example, the arc vnp from \[1,see,v\] to\[3,man,n\] in Figure I represents three different con-stituents.
Those constituents have the same category,vpl, the same head, \[1,soo,v\], and the same modifier,\[3~nan,n\], but have different inside structures of themodifying constituent, np, whose head is \[3,man,n\].The modifying constituent, np, may span from \[2,a\] to\[3,ma~\], from \[2,a\] to \[6,hfll\], or from \[2,a\] to\[9,telescope\].
Actually, in the exclusion matrix de-scribed below, each triple with differing constituentstructure is represented by multiple subscripts to avoidthe generation of trees that did not occur in the parseforest.Another characteristic of a syntactic graph is that thenumber of nodes in a graph is not always the same asthat of the words in a sentence.
Since some words mayhave several syntactic ategories, and each categorymay lead to a syntactically correct parse, one word mayrequire several nodes.
For example, there are eightComputational Linguistics, Volume 15, Number 1, March 1989 2SJungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Treesnodes in the syntactic graph in Figure 6, while there areonly five words in the sentence.5 EXCLUSION MATRIXA syntactic graph is clearly more compact than a parseforest and provides a good way of representing allpossible syntactic readings with an efficient focusingmechanism for ambiguous points.
However, since onetriple may represent several constituents, and there isno information about the relationships between triples,it is possible to lose some important syntactic informa-tion.This section consists of two parts.
\]in Section 5.
I, weinvestigate a co-occurrence problem of arcs in a syntac-tic graph and suggest the exclusion matrix, to avoid theproblem.
The algorithms to collect riples of a syntacticgraph and to construct an exclusion matrix are pre-sented in Section 5.2.5.1 CO-OCCURRENCE PROBLEM BETWEEN ARCSOne of the most important syntactic displays in a treestructured parse, but not in a syntactic graph, is theco-occurrence r lationship between constituents.
Sinceone parse tree represents one possible syntactic readingof a sentence, we can see whether any two constituentscan co-occur in some reading by checking all parse treesone by one.
However, since the syntactic graph keepsall possible constituents as a set of triples, it is some-times difficult to determine whether two triples canco-occur.If a syntactic graph does not carry the informationabout exclusive arcs, its representation f all possiblesyntactic structures may include interpretations notallowed by the grammar and cause extra overhead.
Forexample, after a syntactic processor generates the tri-ples, a semantic processor will focus on the ambiguouspoints such as triples 4 and 5, and triples 8, 9, and 10 inFigure 2 to resolve the ambiguities.
In this case, if thesemantic processor has a strong clue to choose Triple 4over Triple 5, it should not consider Triple 10 as acompeting triple with triples 8 and 9 since I0 is exclu-sive with 4.Some of the co-occurrence problems can be detectedeasily.
For example, due to Property 1, since there canbe only one in-arc to any node in any one reading of asyntactic graph, the arcs that point to the same nodecannot co-occur in any reading.
Triples including thesearcs are called exclusive triples.
The following propertiesof the syntactic graph representation show several caseswhen arcs cannot co-occur.
These cases, however, arenot exhaustive.Property 5: No two crossing arcs can co-occur.
Moreformally, i f  an arc has n t -th and n'- -th words as ahead and a modifier, and another arc has m I -th andm e -th words as a head and a modifier node, then, ifn l<mz<n2<m 2 or ml<nt<m2<n 2, the two arcs can-not co-occur.IN INConj................................. "1\[3,W3, prep\] \[5, Wl, nl 19, W2, conjlFigure 7 II\]ega| Parse Tree from Exclusive Arcs.In the syntactic graph in Figure 1, the arcs vpp from\[1,see,v\] to \[4,on,p\] and npp from \[3,ma,n,n\] to\[7,wita'x,p\] cannot co-occur in any legal parse treesbecause they violate the rule that branches in a parsetree cannot cross each other.The following property shows another case of exclu-sive arcs which cross each other.Property 6: In a syntactic graph, any modifier wordwhich is on the right side o f  its head word cannot bemodified by any word which is on the left side o f  thehead word in a sentence.
More formally, let an archave a head word W t and a modifier word W 2 whosepositions are n t and n 2 respectively, and nz<n 2.
Thenif another arc has W 2 as a head word and a modifierword with position n~ where n3<-nl, then those twoarcs cannot co-occur.Assume that there are two arcs---one is \[npp,\[5,Wl,noun\], \[9,W2,eonj \]\], and the other is \[eonjpp,\[9,W2,eor~\], \[3,W3,prep\]\].
The first arc said that thephrase with head word W2 is attached to the noun inposition 5.
The other triple said that the phrase withhead word W3 is attached to the conjunction.
Thisattachment causes crossing branches.
The correspond-ing parse tree for these two triples is in Figure 7.
As wecan see, since there is a crossing branch, these two arcscannot co-occur in any parse tree.The following property shows the symmetric case ofProperty 6.Property 7: In a syntactic graph, any modifier wordwhich is on the left side o f  its head word cannot bemodified by any word which is on the right side o f  thehead word in a sentence.Other exclusive arcs are due to lexical ambiguity.Definition 5: I f  two nodes, W i and Wj , in a syntacticgraph have the same word and the same position butwith different categories, W i is in conflict with Wj.
,and we say the two nodes are conflicting nodes.Property 8: Since words cannot have more than onesyntactic' category in one reading, any two arcswhich have conflicting nodes as either a head or amodifier cannot co-occur.26 Computational Linguistics, Volume 15, Number 1, March 1989Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse TreesThe example of exclusive arcs involves the vpp arc from\[ 1,flTC,v\] to \[2~lce,la \] nd the vnp arc from \[0,time,v\] to\[1,fly,n\] in the graph in Figure 6.
Since the two arcshave the same word with the same position, but withdifferent categories, they cannot co-occur in any syn-tactic reading.
By examination of Figure 6, we candetermine that there are 25 pairwise combinations ofexclusive arcs in the syntactic graph of that five wordsentence.The above properties how cases of exclusive arcsbut are not exhaustive.
Since the number of pairs ofexclusive arcs is often very large in real text (syntacti-cally ambiguous sentences), if we ignore the co-occur-rence information among triples, the overhead cost tothe semantic processor may outweigh the advantagegained from syntactic graph representation.
Thereforewe have to constrain the syntactic graph representationto include co-occurrence information.We introduce the exclusion matrix for triples (arcs)to record constraints o that any two triples whichcannot co-occur in any syntactic tree, cannot co-occurin any reading of a syntactic graph.
The exclusionmatrix provides an efficient ool to decide which triplesshould be discarded when higher level processes chooseone among ambiguous triples.
For an exclusion matrix(Ematrix), we make an N x N matrix, where N is thenumber of indices of triples.
If Ematrix(ij) = 1 then thetriples with the indices i and j cannot  co-occur in anysyntactic reading.
If Ematrix(ij) = 0 then the tripleswith the indices i and j can  co-occur in some syntacticreading.5.2 AN ALGORITHM TO CONSTRUCT THE EXCLUSIONMATRIXSince the several cases of exclusive arcs shown in theprevious ection are not exhaustive, they are not suffi-cient to construct a complete xclusion matrix from asyntactic graph.
A complete xclusion matrix can beguaranteed by navigating the parse forest when thesyntactic processor collects the triples in the forest toconstruct a syntactic graph.As we have briefly described in Section 3, when theparser constructs a shared, packed forest, triples arealso produced, and their indices are kept in the corre-sponding nonterminal nodes in the forest.
12 The parsernavigates the parse forest o collect he triples--in fact,pointers pointing to the triples--and to build an exclu-sion matrix.As we can see in the parse forest in Figure 5, theremay be several nonterminal nodes in one packed node.For each packed node, the parser collects all indices oftriples in the subforests whose root nodes are thenonterminal nodes in the packed node, and then recordsthose indices to the packed node.
After the parserfinishes collecting the indices of the triples in the parseforest, each packed node in the forest has a pointer tothe list of collected indices from its subforest.
There-fore, the root node of a parse forest has a pointer to theie" 'lsubforest"-El--Eli,?, vo, vo, Drnj,, ' .
; ; ~' .
!~  .~.
.t i,. '
,  ? '
,.
i?
t ~ 'l s?
?
?
t .
.
.
.
.
J /.- .
.
.
.
.
.
.
d e. .
.
.
.
.
"-subfores t  subforest subforestD : packed node==\]~ : list of all triples below this nodei ?
triples of this node %.1~"=~ : pointer to the list of pointers pointing to triplesF igure  8 Parse Forest Augmented with Triples.list of all indices of all possible triples in the wholeforest, and those triples represent the syntactic graph ofthe forest.Figure 8 shows the upper part of the parse forest inFigure 5 after collecting triples.
A hooked arrow of eachnonterminal node points to the list of the indices of thetriples that were added to the node in parsing.
Forexample, pointer 2 contains the indices of the triplesadded to the node snt by the grammar rule:snt ~ np + vpA simple arrow for each packed node points to the listof all indices of the triples in the forest of which it is theroot.
This list is generated and recorded after theprocessor collects all indices of triples in its subnodes.Therefore the arrow of the root node of the wholeforest, Pointer 1, contains the list of all indices of thetriples in the whole forest.Since several indices may represent the same triple,after collecting all the indices of the triples in the parseforest, the parser emoves duplicating triples in the finalrepresentation f the syntactic graph of a sentence.Collecting pointers to triples in the subforest of apacked node and constructing the Ematrix is donerecursively as follows: First, Ematrix(i j) is initialized to1, which means all arcs are marked exclusive of eachother.
Later, if any two arcs indexed with i and jComputat iona l  L ingu is t i cs ,  Vo lume 15,  Number  1, March  1989 27Jungyun See and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Treesfunction collect_triple(Packed_node)if Packed node.
Collectedif the indices of triples are already collectedthen return(Packednode.
Triplelndex) ~ collected then.
returnthe collected indiceselse Packed node.
TripleIndex := eollectl(Packed_node)else collected themPacked node.
Collected := true ~ set flag Collected.return?Packed_node.
TriplsIndex) ~ return collected indices.function collectl(Packed_node)Triple_Indices: = { }for each Node in Packed node doTRiple Indices := me~ge(Node.TripleIndex.
Triple_Indices)case Node.Child node num0 (do nothing)1 Temp := collecttriple(Node.
Childnode)Triple_Indices := msrge(Temp, Triple_Indices)co-occuri(Node.TripleIndex, Temp)2 Templ := collect_triple(Node.Left_child)Temp2 := collect_triple(Node.Right_child)Triple_Indices := merge(Tempi.
Temp2.
Triple_Indices)co-occur2(Node.TripleIndex, Templ, Temp2)end-doreturn(Triples)function cooccurl(Tr ipl .
Trip2)fully cooccur(Tr ipl)cc-occur3(Tripl ,  Trip2)function cooccur2(Tr ipl ,  Trip2, Trip3)fu l ly_cooccur(Tr ip l )cooccur3(Tripl ,  Trip2)cooccur3(Tripl ,  Trip3)cooccur3(Trip2, Trip3)funct ioncooccur3(Tr ip l ,  Trip2)for each index i in Tripl  dofo reach  index j in Tr ip2 doEmatrix(i ,  j ) :=  0Ematrix(j .
i ) :=  0 / *Ematr ix i ssymmetr ic* /function fu l ly_cooccur(Tr ip les)for each pair of indices i and j in Tr ip les doEmatrix(i ,  j ) :=  0Figure 10 An Algorithm to Construct the Exclusion Matrix.Figure 9 An Algorithm to Collect Triples.co-occur in some parse tree, then the value of Ematrix,E(ij), is set to 0.
For each nonterminal node in a packednode, the parser collects every index appearing belowthe nonterminal node--i.e., the index of the triples of itssubnodes.
If a subnode of the nonterminal node waspreviously visited, and its indices were already col-lected, then the subnode already has the pointer to thelist of collected indices.
Therefore the parser does notneed to navigate the same subforests again, but it takesthe indices using the pointer.
The algorithm in pseudo-PASCAL code is in Figure 9.After the parser collects the indices of the triplesfrom the subnodes of the nonterminal node, it adjuststhe values in the exclusion matrix according to thefollowing cases:I.
If the nonterminal node has one child node, itsown triples can co-occur with each other, andwith every collected triple from its subforest.2.
If the nonterminal node has two child nodes, itsown triples can co-occur with each other andwith the triples collected from both left and rightchild nodes, and the triples from the left childnode can co-occur with the triples from the rightone.This algorithm is described in Figure I0.For example, the process tarts to collect he indicesof the triples from SNT node in Figure 8.
Then, itcollects the indices in the left subforest whose root isnp.
After all indices of triples in the subforest of np arecollected, those indices and the indices of the triples ofthe node in 6 are recorded in 5.
Similarly all indices in 7and 4 are recorded in 3 as the indices of the triples in theright subforest of the snt node.
The indices in 5 and 3and the indices in 2 are recorded in I as the indices ofthe triples of the whole parse forest.
In packed nodeswith more than one nonterminal node, like vpl, allindices of the triples in the three subforests of vpl and28the indices in 8, 9, and 10 are collected and recorded in7.By the first case in the above rule, every triplerepresented by the indices in 4 can co-occur with eachother, and every triple represented by the indices in 4can co-occur with every triple represented by the indi-ces in 7.
One example of the second case is that everytriple represented by the indices in 2 can co-occur witheach other, and every triple represented by the indicesin 2 can co-occur with every triple represented by theindices in 5 and 3.
Every triple represented by theindices in 5 can co-occur with the triples represented bythe indices in 3.
Whenever the process finds a pair ofco-occurring triples it adjusts the value of Ematrixappropriately.6 COMPLETENESS AND SOUNDNESS OF THE SYNTACTICGRAPHIn this section, we will discuss completeness and sound-ness of a syntactic graph with an exclusion matrix as analternative for tree representation f syntactic informa-tion of a sentence.Definition 6: A syntactic graph of a sentence iscomplete and sound compared to the parse forest ofthe sentence iff there is an algorithm that enumeratessyntactic readings from the syntactic graph of thesentence and satisfies the following conditions:1.
For every parse tree in the forest, there is asyntactic reading from the syntactic graph that isstructurally equivalent to that parse tree.
(complete-ness)2.
For every syntactic reading from the syntacticgraph, there is a parse tree in the forest that isstructurally equivalent o that syntactic reading.
(soundness)To show the completeness and soundness of the syn-tactic graph representation, we present he algorithmthat enumerates all possible syntactic readings from asyntactic graph using an exclusion matrix.
This algo-Computational Linguistics, Volume 15, Number 1, March 1989Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse TreesThe following data are initial input.Partition I = a l i s t  of triples which have the I - thwordas  amodifier.Sen_length = the position of the last word inasentence.RootList = a list of root triples.gen_subgraph(RootList, Sen_length, Graphs, Al l_readings): -( RootList = \[\] ~ if all root triple in RootList had been tried-*All_readings = Graphs ~ then return Graphs as all readings,otherwise, find all readings with a RootTriple; RootList = \[RootTripleIRootListl\],gen_subgraphl(RootTriple, Sen_length, Sub_graphs),append(Graphs, Sub graphs, Graphsl),gen_subgraph(RootListl, Graphsl, All_readings)).gen_subgraphl(RootTriple, Sen length, Sub_graphs) : -Rh = Position of the head node inRootTriple %i.e., position of the root nodeRm = Position of the modifier node in RootTriple,Wlist = \[RootTriple\],setof(Graph, gen_subl(Rh, Rm, Sen length, Wlist, Graph, 0), Sub_graphs).gen_subl(Rh, Rm, Sen_length, Wlist, Graph, N) : -(N>Sen length ~ i f i t  takeat r ip le  from all partitions-*Graph = Wlist ~ then return Wlist as one reading of a syntactic graph,otherwise, pick one triple from partition N.; ( ( Rh = N ~Don't  pick up any triple from root node position.
; Rm = N) ~ A triple from partition Rm is already picked in Wlist.-*true; get_triple(N, Triple), ~ take a triple(in fact, an index of the triple) from partition N.not_exclusive(Wlist, Triple), ~ check exclusiveness of Triple with other triples in Wlist.N1 is N + l, ~ go to the next partition.gen_subl(Rh, Rm, \[Triple\[Wlist\], Graph, NI))).Figure 11 Algorithm that Generates All and Only Readings ~om an SG.rithm constructs subgraphs of the syntactic graph, oneat a time.
Each of these subgraphs i equivalent to onereading of the syntactic graph.
Since no node canmodify itself, each of these subgraphs is a directedacyclic graph (DAG).
Furthermore, since every node ineach of these subgraphs can have no more than onein-arc, the DAG subgraph is actually a tree.Before going into detail, we give an intuitive descrip-tion of the algorithm.
The algorithm has two lists oftriples as input: a list of triples of a syntactic graph anda list of root triples.
A root triple is a triple thatrepresents he highest level constituent in a parse--i.e.,ant (sentence) in the grammar in Figure 2.
The headnode of a root triple is usually the head verb of asentence reading.According to Property 3 in Section 4, one reading ofa syntactic graph must include one and only one nodefrom every position, except the position of the rootnode, as a modifier node.
This is a necessary require-ment for any subgraph of a syntactic graph to be onereading of the graph.
One of the simplest ways to makea subgraph of a syntactic graph that satisfies thisrequirement is:Make partitions among triples according to theposition of the modifier node of the triples, e.g.,triples in Partition 0 have the first word in a sentenceas the modifier nodes.
Then take one triple from eachpartition.
Here, the algorithm must know the positionof the root node so that it can exclude the partition inwhich triples have the root node as a modifier.
WhenComputational Linguistics, Volume 15, Number 1, March 1989it chooses a triple, it also must check the exclusionmatrix.
If a triple from a partition is exclusive withany of the triples already chosen, the triple cannot beincluded in that reading.
The algorithm must tryanother triple in that partition.
Since the exclusionmatrix is based on the indices of the triples, when itchooses atriple, it actually chooses an index in the listof indices of the triple.Note that any subgraphs produced in this way satisfyProperty 3, and all triples in each subgraph are inclusivewith each other according to the exclusion matrix.
Thetop level procedures of the algorithm in Prolog areshown in Figure 11.13We do not have a rigorous proof of the correctness ofthe algorithm, but we present an informal discussionabout how this algorithm can generate all and only thecorrect syntactic readings from a syntactic graph.Since the syntactic graph of a sentence is explicitlyconstructed as a union of all parse trees in the parseforest of the sentence, the triples of the syntactic graphimply all the parse trees.
This fact is due to thealgorithm that constructs a syntactic graph from a parseforest.
Therefore, ifwe can extract all possible syntacticreadings from the graph, these readings will include allpossible (and more) parse trees in the forest.
Intuitively,the set of all subgraphs of a syntactic graph includes allsyntactic readings of a syntactic graph.In fact, this algorithm generates all possible sub-graphs of a syntactic graph that meets the necessaryconditions imposed by Property 3.
The predicate29Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation f r the Union of All Ambiguous Parse Treesgen sub1 generates one reading with a given roottriple.
All readings with a root triple are exhaustive-ly collected by the predicate gen subgraphl  usingthe setof predicate--a meta predicate in Prolog.
Allreadings of a syntactic graph are produced by thepredicate gen subgraph, which calls the predicategen subgraphl  for each root triple in RootList.
There-fore,this algorithm generates all subgraphs of a syntac-tic graph that satisfy Property 3 and that are consistentwith the exclusion matrix.
Hence, the set of subgraphsgenerated by the algorithm includes all parse trees in theforest.The above algorithm checks the exclusion matrixwhen it generates subgraphs from the syntactic graph,so all triples in each subgraph generated by the algo-rithm are guaranteed to co-occur with each other in theexclusion matrix.
Unfortunately, it does not appearpossible to prove that if triples, say T1 and T2, T2 andT3, and T1 and T3, all co-occur in pairs, that they mustall three co-occur in the same tree!
So, although empir-ically all of our experiments have generated only treesfrom the forest, the exclusion matrix does not providemathematical assurance of soundness.If subsequent experience with our present statisti-cally satisfactory, but unsound exclusion matrix re-quires it, we can produce, instead, an inclusion matrixthat guarantees soundness.
The columns of this matrixare I.D.
numbers for each parse tree; the rows aretriples.
The following procedure constructs the matrix.1.
Navigate the parse forest o extract a parse tree,I, and collect riples appearing in that parse tree.2.
Mark matrix(Tindex, I) = 1, for each triple withthe index Tindex appearing in the I-th parse tree.Backtrack to step 1 to extract another possibleparse tree until all parse trees are exhausted.Then, given a column number i, all triples marked inthat column co-occur in the i-th parse tree.
Since thisalgorithm must navigate all possible parse trees one byone, it is less efficient han the algorithm for construct-ing the exclusion matrix.
But if our present systemeventually proves unsound, this inclusion matrix guar-antees that we can test any set of constituents todetermine unequivocally if they occur in a single parsetree from the forest.Therefore, we claim that syntactic graphs enable usto enumerate all and only the syntactic readings given ina parse forest, and that syntactic graph representation iscomplete and sound compared to tree representations ofthe syntactic structure of a sentence.7 RELATED WORKSSeveral researchers have proposed variant representa-tions for syntactic structure.
Most of them, however,concentrated on how to use the new structure in theparsing process.
Syntactic graph representation in thiswork does not affect any parsing strategy, but is con-structed after the syntactic processor finishes generat-ing a parse \]Forest using any all path parser.Marcus et.
al.
(1983) propose a parsing representa-tion that is also different from tree representation.
Theyuse the new representation fora syntactic structure of asentence to preserve information, while modifying thestructure during parsing, so that they can solve theproblems of a deterministic parser (Marcus 1980)--i.e.,parsing arden path sentences.
Marcus's representationconsists of dominator-modifier r lationships betweentwo nodes.
It is, however, doubtful that a correct parsetree can be derived from the final structure, whichconsists of only domination relationships.
They do notrepresent all possible syntactic readings in one struc-ture.Barton and Berwick (1985) also discuss the possibil-ity of a different representation, an "assertion set", asan alternative for trees, and show various advantagesexpected from the new structure.
As in Marcus's work,they use the assertion set to preserve information asparsing progresses, o that they can make a determin-istic parser to be partially noncommittal, when theparser handles ambiguous phrases.
Their representationconsists of sets of assertions.
Each assertion that rep-resents a constituent is a triple that has the categoryname and the range of terminals that the constituentspans.
It is unclear how to represent dominance rela-tionships between constituents with assertion sets, andwhether the final structure represents all possible parsesor parts of the parses.Rich et.
al.
(1987) also propose a syntactic represen-tation in which all syntactic ambiguities are kept.
In thiswork.
the ambiguous points are represented as onemodifier with many possible dominators.
Since, how-ever, this work also does not consider possible prob-lems of exclusive attachments, their representationloses some information present in a parse forest.Tomita (1985) also suggests a disambiguation pro-cess, using his shared, packed-parse forest, in which allpossible syntactic ambiguities are stored.
The disambig-uation process navigates a parse forest, and asks a userwhenever it meets an ambiguous packed node.
It does a"shaving-a-forest" operation, which traverses the parseforest to delete ambiguous branches.
Deleting one arcaccomplishes the "shave" in the syntactic graph repre-sentation.
Furthermore, in a parse forest, the ambigu-ous points can be checked only by navigating the forestand are not explicit.Since a parse forest does not allow direct access to itsinternal structure, a semantic processor would have totraverse the forest whenever it needed to check internalrelations to generate case relations and disambiguatewithout a user's guidance.
Syntactic graph representa-tion provides a more concise and efficient structure forhigher level processes.30 Computational Linguistics, Volume 15, Number 1, March 1989Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Trees8 CONCLUSIONIn this paper, we propose the syntactic graph with anexclusion matrix as a new representation f the surfacesyntactic structure of a sentence.
Several properties ofsyntactic graphs are examined.
An algorithm that enu-merates all and only the correct syntactic readings fromsyntactic graph is also presented.
Therefore, we claimthat syntactic graph representation provides a conciseway to represent all possible syntactic readings in onestructure without losing any useful information con-tained in the tree structured representation.To further justify that syntactic graph representationis a suitable formalism for an output format of syntacticprocesses, we need to investigate methods for usingsyntactic graphs to make correct decisions in higherlevel processes.
The exclusion matrix is an efficient toolto help semantic processes make correct choices.Because of its conciseness, the syntactic graphmakes it possible to store temporarily the syntacticstructure of sentences that already have been proc-essed.
A text understanding process is very likely tofind contradicting evidence between a current sentenceand the context of the previous entences.
If we did notkeep alternative analyses of previous entences the onlything we could do is backtracking, which is computa-tionally too expensive.
Furthermore, since the searchspace of the syntactic processor is different from that ofthe semantic processor, it is very important for thesyntact i c  p rocess  to  commit  to  a f ina l  resu l t .
We arecur rent ly  invest igat ing  how to  use  syntact i c  g raphs  o fp rev ious  sentences  to mainta in  a cont inuous  contextwhose  ambigu i ty  is success ive ly  reduced by  add i t iona lincoming  sentences .ACKNOWLEDGMENTSThis work is sponsored by the Army Research Off?ce under contractDAAG29-84-K-0060.
The authors are grateful to Olivier Winghart forhis critical review of an earlier draft of this paper.REFERENCESAho, A. V. and Ullman, J. D. 1972 The Theory of Parsing, Translationand Compiling 1.
Prentice-Hall, Englewood Cliffs, NJ.Barton, G. E. and Berwick, R. C. 1985 "Parsing with Assertion Setsand Information Monotonicity."
In Proceedings of InternationalJoint Conference on Artificial Intelligence-85 (IJCAI-85): 769-771.Birnbaum, L. and Selfridge, M. 1981 "Conceptual analysis of naturallanguage."
In R. Schank and C. Riesbeck, eds., Inside ComputerUnderstanding.
Lawrence Erlbaum, Hillsdale, NJ.Chester, D. 1980 "A Parsing Algorithm that extends Phrases.
"American Journal of Computational Linguistics 6 (2): 87-96.Chomsky, N. 1970 "Remarks on nominalization."
In R. Jacobs andP.
S. Rosenbaum, Eds., Readings in English TransformationalGrammar.
Waltham, MA- Ginn & Co.Chomsky, N. 1981 Lectures on Government and Binding.
Foris,Dordrecht, Holland.Early, J.
1970 "An Efficient Context-free Parsing algorithm."
CommACM 13, (2): 94-102.Frazier, L. and Fodor, J.
1979 "The Sausage Machine: A NewTwo-Stage Parsing Model."
Cognition 6: 41-58.Computational Linguistics, Volume 15, Number 1, March 1989Kay, M. 1980 "Algorithm Schemata nd Data Structures in SyntacticProcessing."
Xerox Corporation, Technical Report Number CSL-80-12, Palo Alto, CA.Lytinen, S. L. 1986 "Dynamically Combining syntax and semantics innatural anguage processing."
In Proceedings of The AmericanAssociation for Artificial ntelligence-86(AAAI-86): 574-578.Marcus, M. P. 1980 A Theory of Syntactic Recognition for NaturalLanguage.
MIT Press, Cambridge, MA.Marcus, M. P.; Hindle, D.; and Fleck, M. M. 1983 "D-Theory:Talking about Talking about Trees."
In Proceedings of 21stAnnual Meeting of the Association for Computational Linguistics:129--136.Pereira, F. C. N. and Warren, D. H. 1980 "Definite Clause Grammars- -  A survey of the formalism and a Comparison with AugmentedTransition Network."
Artificial Intelligence, 13:231-278.Rich, A.; Barnett, J.; Wittenburg, K.; and Wroblewski, D. 1987"Ambiguity Procrastination."
In Proceedings of AAAI--87: 571-576.Shubert, L. K. 1984 "On Parsing Preferences."
In Proceedings of theConference on Computational Linguistics 84 Stanford, CA: 247-250.Shubert, L. K. 1986 "Are There Preference Trade-Offs in AttachmentDecision?"
In Proceedings of AAAI-86: 601-605.Tomita, M. 1985 Efficient Parsing for Natural Language.
KluwerAcademic Publishers, Boston, MA.Tsukada, D. 1987 "Using Dominator-Modifier Relations to Disam-biguate a Sentence" (master's thesis), Department of ComputerSciences, University of Texas at Austin.Waltz, D. L. 1982 "The State of the Art in Natural LanguageUnderstanding."
In W. Lehnert and M. Ringle (eds.
), Strategiesfor Natural Language Processing, Lawrence Erlbaum Associates,Inc., Hillsdale, NJ.W~lks, Y.; Huang, X.; and Fass, D. 1985 "Syntax, Preference andRight Attachment."
In Proceedings of lnternational Joint Confer-ence on Artificial Intelligence-85 (IJCAI-85): 779--784.Winghart, O. J.
1986 "A Processing Model for Recognition ofDiscourse Coherence Relations" (unpublished Ph.D proposal),Department of Computer Sciences, University of Texas at Austin.NOTES!.
Since we are discussing the syntactic representation, weuse theterm "semantic processor" for all higher level processors in-cluding the semantic, coherence, and discourse processors.2.
By "correct" is meant semantically correct.
Here, semanticshas a broad meaning including pragmatics.3.
Borrowing a term from Tomita's (1985) system.
Although wepresent an example of a shared, packed-parse forest in Section 3,we refer readers to (Tomita 1985) for more detailed iscussionand examples.4.
There are different views of text processing in which syntacticand semantic processors are integrated (Birnbaum and Selfridge1981; Lytinen 1986; Winghart 1986).
However detailed discus-sion of other control flows is beyond the scope of this work.5.
For the sentence, "It is transmitted by eating shellfish such asoysters living in infected waters, or by drinking infected water,or by dirt from soiled fingers", there are 1433 parses from ourcontext-free grammar.6.
In our experience, a graph representing several hundred parsetrees may take less than three times the number of triples as onerepresenting a single interpretation graph for the sentence.7.
In a syntactic graph, however, we call both modifier andspecifier nodes modifier nodes.8.
From now on, we will use the terms node and word, as well asarc and triple, interchangeably.9.
A unique index can be generated using the special functiongensym which returns a unique symbol whenever it is called.31Jungyun Seo and Robert F. Simmons Syntactic Graphs: A Representation for the Union of All Ambiguous Parse Trees10.11.Due to the complexity of the diagram, some of the details areomitted.Not all different readings of a syntactic graph have different rootnodes.
In this example, \[0,t, imo,v\] is the root node of twodifferent readings of the graph with simple grammar rules.
Theequivalent parse trees of the two readings are:\[snt,\[vp,\[verb,\[time\]\],\[np,\[np,\[noun,\[flies\]\]\],\[pp,\[prep,\[like\]\],\[np,\[det,\[an\] \] , \[noun, \[arrow\]\]\]\]\]\]\]\[snt,\[vp,\[vp,\[verb,\[time\]\],\[np,\[noun,\[flies\]\[\]\],\[pp,\[prep,\[like\]\],\[np,\[det,\[an\] \],\[noun,\[arrow\]\]\]\]\]\]12.
The: node in a forest is different from the node in a syntacticgraph.
A non-terminal node in a forest with two children nodeshas one \]head-modifier relation, and hence the non-terminalwith two children in a forest represents one arc in a syntacticgyaph.13.
We use the syntax of Quintus-Prolog version 2 on SUN systems.The special predicate, ( Cond ---> Then ; Else ), in the algorithmcan be interpreted as; if Cond is true, then call Then.
Otherwise,call Else.32 Computational Linguistics, Volume 15, Number 1, March 1989
