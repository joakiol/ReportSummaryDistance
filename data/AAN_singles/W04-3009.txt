Using Higher-level Linguistic Knowledge for Speech Recognition ErrorCorrection in a Spoken Q/A DialogMinwoo JeongDepartment of ComputerScience and Engineering,POSTECH, Pohang, Koreastardust@postech.ac.krByeongchang KimDivision of Computer andMultimedia Engineering,Uiduk University,Gyeongju, Koreabckim@uiduk.ac.krGary Geunbae LeeDepartment of ComputerScience and Engineering,POSTECH, Pohang, Koreagblee@postech.ac.krAbstractSpeech interface is often required in manyapplication environments such as telephone-based information retrieval, car navigation sys-tems, and user-friendly interfaces, but the lowspeech recognition rate makes it difficult to ex-tend its application to new fields.
Several ap-proaches to increase the accuracy of the recog-nition rate have been researched by error cor-rection of the recognition results, but previ-ous approaches were mainly lexical-orientedones in post error correction.
We suggestan improved syllable-based model and a newsemantic-oriented approach to correct both se-mantic and lexical errors, which is also moreaccurate for especially domain-specific speecherror correction.
Through extensive experi-ments using a speech-driven in-vehicle telem-atics information retrieval, we demonstratethe superior performance of our approach andsome advantages over previous lexical-orientedapproaches.1 IntroductionNew application environments such as telephone-basedretrieval, car navigation systems, and mobile informationretrieval, often require speech interface to convenientlyprocess user queries.
In these environments, keyboardinput is inconvenient or sometimes impossible becauseof spatial limitation on mobile devices and instability inmanipulating the devices.However, because of the low recognition rate in currentspeech recognition systems, the performance of speechapplications such as speech-driven information retrieval(IR) and question answering (QA), and speech dialoguesystems is very low.
The performance of the serially con-nected spoken QA system, based on the QA system fromtext input which has 76% performance and the output ofthe ASR which operated at a 30% WER, was only 7%(Harabagiu et al, 2002).
(Harabagiu et al, 2002) ex-poses several fundamental flaws of this simple combina-tion of an automatic speech recognition (ASR) and QAsystem, including the importance of named entity infor-mation, and the inadequacies of current speech recogni-tion technology based on n-gram language models.The major problem of speech-driven IR and QA is thedecreasing of the performance due to the recognition er-rors in ASR systems.
Erroneously recognized spokenqueries drop the precision and recall of IR and QA sys-tem.
Some authors investigated the relation of ASR er-rors and precision of IR (Barnett et al, 1997; Crestani,2000).
They evaluated the effectiveness of the IR systemsthrough various error rates using 35 queries of TREC.Their researches show that the increasing word error rate(WER) quickly decreases the precision of IR.
Anothergroup investigated the performance of spoken queries inNTCIR collections (Fujii et al, 2002A).
They evaluateda variety of speakers, and calculated the error rate withrespect to a query term, which is a keyword used for theretrieval.
They showed that the WER of the query termswas generally higher than that of the general words ir-respective of the speakers.
In other words, recognitionof content words related to the IR and QA performancewas more difficult than that of normal words.
So, theyintroduced a method to improve the precision of speech-driven IR by suggesting a new type of IR system tightly-integrated with a speech input interface (Fujii et al,2002B).
In their system, document collection provides anadaptation of the language model of the ASR, which re-sults in a drop of the word error rate.For this reason, some appropriate adaptation tech-niques are required for overcoming speech recognitionerrors such as post error correction.
ASR error correc-tion can be one of the domain adaptation techniques toimprove the recognition accuracy, and the primary advan-Figure 1: Adaptation via Post Error Correctiontage of the error correction approach is its independenceof the specific speech recognizer.
If the speech recog-nizer can be regarded as a black-box, we can perform ro-bust and flexible domain adaptation through the post errorcorrection process.
Figure 1 shows the paradigm of thispost error correction approach.One approach in post error correction, which is astraightforward and intuitive method to robustly handlemany kinds of recognition errors, was rule-based ap-proach (Kaki et al, 1998).
(Kaki et al, 1998) collectedmany lexical error patterns that occurred in a speechtranslation system in Japanese.
They could correct anytype of errors by matching the strings in the transcriptionwith lexical error patterns in the database.
However, theirapproach has a disadvantage in that the correction is onlyfeasible to the trained (or collected) lexical error patterns.Another approach has been based on a statisticalmethod utilizing the probabilistic information of wordsin a spoken dialogue situation and the language modelsadapted to the application domain (Ringger and Allen,1996).
(Ringger and Allen, 1996) applied the noisy chan-nel model to the correction of the errors in speech recog-nition.
They simplified a statistical machine translation(MT) model called an IBM model (Brown et al, 1990),and tried to construct a general post-processor that cancorrect errors generated by any speech recognizer.
Themodel consists of two parts: a channel model, which ac-counts for errors made by the ASR, and the languagemodel, which accounts for the likelihood of a sequence ofwords being uttered.
They trained the channel model andthe language model both using some transcriptions fromTRAINS-95 dialogue system which is a train travelingplanning system (Allen et al, 1996).
Here, the channelmodel has the distribution that an original word may berecognized as an erroneous word.
They use the proba-bility of mistakenly recognized words, the co-occurrenceinformation extracted from the words and their neighbor-ing words, and the tagged word bi-grams, which are alllexical clues in error strings.Such approaches based on lexical information of wordshave shown some successful results, but they still havemajor drawbacks; The performance of such systems de-pends on the size and the quality of speech recognitionresult, or on the database of collected error strings sincethey are directly dependent on lexical items.
The errorpatterns constructed are available but not enough, be-cause it is expensive to collect them; so in many cases,they fail to recover the original strings from the lexicalspecific error patterns.
Also, since they are sensitive tothe error patterns, they occasionally mis-identify a cor-rect word as an error word.We suggest a more improved and robust semantic-oriented error correction approach, which can be in-tegrated into previous fragile lexical-based approaches.In our approach, in addition to lexical information, weuse high level syntactic and semantic information of thewords in a speech transcription.
We obtain semantic in-formation from a knowledge base such as general the-sauri and a special domain dictionary that we constructby ourselves to contain some domain specific knowledgeto the target application.In the next section, we first describe a general noisychannel model for ASR error correction and discuss someproblems with them.
We then introduce our improvedchannel model especially for Korean language in section3.
We also propose a new high-level error correctionmodel using syntactic and semantic knowledge in section4.
We prove the feasibility of our approach through someexperiments in section 5, and draw some conclusions insection 6.2 Noisy Channel Error Correction ModelThe noisy channel error correction framework has beenapplied to a wide range of problems, such as spellingcorrection, statistical machine translation, and ASR errorcorrection (Brill and Moore, 2000; Brown et al, 1990;Ringger and Allen, 1996).
The key idea of noisy chan-nel model is that we can model some channel propertiesthrough estimating the posterior probabilities.The problem of ASR error correction can be statedin this model as follows: For an input sentence, O =o1, o2, .
.
.
, on produced as the output sequence of ASR,find the best word sequence,W?
= w1, w2, .
.
.
, wn, thatmaximizes the posterior probability P (W |O).
Then, ap-plying Bayes?
rule and dropping the constant denomina-tor, we can rewrite as:W?
= arg maxWP (W |O) = arg maxWP (W )P (O|W ) (1)Now, we have a noisy channel model for ASR er-ror correction, with two components, the source modelP (W ) and the channel model P (O|W ).
The probabilityP(W) is given by the language model and can be decom-posed as:P (W ) =?iP (wi|w1,i?1) (2)Figure 2: Example of Word-based Channel ModelThe distribution P (W ) can be defined using n-grams,structured language model (Chelba, 1997), or any othertool in the statistical language modeling.Next, the conditional probability, P (O|W ) reflects thechannel characteristics of the ASR environment.
If we as-sume that the output word sequence produced under ASRare independent of one another, we have the followingformula:P (O|W ) =?iP (o1,i|w1,i) =?iP (oi|wi) (3)So,W?
= arg maxWP (W )P (O|W )= arg maxW(?iP (wi|w1,i?1)?iP (oi|wi))(4)However, this simple one-to-one model is not suitableto handling split or merged errors, which frequently ap-pear in an ASR output, because we assume that the out-put word sequence are independent of one another.
Forexample, 1figure 2 shows a split or a merged error prob-lem.
To solve this problem, Ringger and Allen used thefertility of pre-channel word (Ringger and Allen, 1996).Following (Brown et al, 1990), we refer to the num-ber of post-channel words oi produced by a pre-channelword wi as a fertility.
They simplified the fertility modelof IBM statistical MT model-4, and permitted the fer-tility within 2 windows such as P (oi?1, oi|wi) for two-to-one channel probability, and P (oi|wi, wi+1) for one-to-two channel probability.
So, the fertility model candeal with (TO LEAVE, TOLEDO) substitution.
But thisimproved fertility model only slightly increased the ac-curacy in experiments (Ringger and Allen, 1996), andwe think the major reason is due to the data-sparsenessproblem.
Because substitution probability is based on thewhole word-level, this fertility model requires enormoustraining data.
We call the model a word-based channelmodel, because this model is based on the word-to-wordtransformation.
The word-based model focused on inter-word substitutions, so it requires enough results of ASRand transcription pairs.
Considering the cost of buildingthe enough amount of correction pairs, we need a smallerunit than a word for overcoming the data-sparseness.1This example is from (Ringger and Allen, 1996).3 Syllable-based Channel ModelWe suggest an improved channel model for smaller train-ing data.
If we can use smaller unit such as letter,phoneme or syllable than word, relatively smaller trainingset is needed.
For dealing with intra-word transformation,we suggest a syllable-based channel model, which candeal with syllable-to-syllable transformation.
This modelis especially reasonable for Korean.
In some agglutina-tive languages such as Korean, syllable is a basic unit ofwritten form like a Chinese character.
In Korean, the av-erage number of syllables in one word is about three orfour.3.1 The ModelSuppose S = s1, s2, .
.
.
, sn is a syllable sequence ofASR output and W = w1, w2, .
.
.
, wm is a source wordsequence, then our purpose is to find the best word se-quence W?
as follows:W?
= arg maxWP (W |S) (5)We can apply the same Bayes?
rule and decompose thesyllable-to-word channel model into syllable-to-syllablechannel model.P (w|s) = P (s|w)P (w)P (s) ?
P (s|w)P (w)?
P (s|x)P (x|w)P (w) (6)So, final formula can be written as:W?
= arg maxW(P (W )P (X|W )P (S|X)) (7)Here, P (S|X) is the probability of a syllable-to-syllable transformation, where X = x1, x2, .
.
.
, xn isa source syllable sequence.
P (X|W ) is a word model,which can convert syllable lattice into word lattice.
Theconversion can be done efficiently by dictionary look-up.This model is similar to a standard hidden markovmodel (HMM) of continuous speech recognition.
Inspeech recognition system, P (S|X) can be an acousticmodel in signal-to-phoneme level, and P (X|W ) can bea pronunciation dictionary.
Then, we applied the fertilityinto our syllable-to-syllable channel model.
We set themaximum 2-fertility of syllable, which was determinedexperimentally.3.2 Training the ModelTo train the model, we need a training data consistingof {X,S} pairs which are manually transcribed stringsand ASR outputs.
And, we align the pair based on mini-mizing the edit distance between xi and si by dynamicFigure 3: Example of Syllable-based Channel Modelprogramming.
2Figure 3 shows an alignment for thesyllable-model (For understanding, we use an English ex-ample and a letter-to-letter alignment.
In Korean, eachsyllable is clearly distinguished much like a letter in En-glish.).
For example, (TO LEAVE, TOLEDO) pair in pre-vious section can be divided into (TO, TO), (L, L), (EA,E), and (VE, DO) with fertility 2.We can then calculate the probability of each sub-stitution P (si|xi) by Maximum-Likelihood Estimation(MLE).
Let C(xi) be the frequency of source syllable,and C(xi, si) be the frequency of events where xi substi-tute si.
Then,PMLE(si|xi) =C(xi, si)C(xi)(8)The total number of theoretical unique syllables isabout ten thousands in Korean, but the number of syl-lables, which appeared at least one time, is about 2,300in a corpus which has about 3 billion syllables.
Thus, weused Witten-Bell method for smoothing unseen substitu-tions (Witten and Bell, 1991).
Let T (xi) be the numberof substitution types, and N be the number of syllables ina training data.
For Witten-Bell discounting, we shoulddefine Z(xi), which is the number of syllable xi withcount zero.
Then, we can write as follows:PWB(si|xi) =T (xi)Z(xi)(N + T (xi)), if C(xi, si) = 0 (9)3.3 Decoding the ModelGiven a syllable sequence S, we want to findarg maxW (P (W )P (X|W )P (S|X)).
This will be to re-turn an N-best list of candidates according to the models,and then rescore these candidates by taking into accountthe language model probabilities.
To rescore the candi-dates, we used Viterbi search algorithm to find the bestsequence.
For implementation of candidate generation,we store the syllable channel probabilities P (si|xi) as ahash-table to pop them easily and fast.
The system cangenerate a candidate word sequence network using sylla-ble channel model and a lexicon.
And then, we can findoptimal sequence which has the best probability throughViterbi decoding by including a language model.2We omitted detail character-level match lines to simplify.The whole word match is depicted in bold lines, while no-linemeans character-level match errors.Figure 4: Common semantic category values4 Using Syntactic and SemanticKnowledgeIn some similar areas such as spelling error correctionor optical character recognition (OCR) error correction,NLP researchers traditionally identified five levels of er-rors in a text: (1) a lexical level, (2) a syntactic level,(3) a semantic level, (4) a discourse structure level, and(5) a pragmatic level (Kukich, 1992).
In spelling cor-rection and OCR error correction problem, correctionschemes mainly have focused on non-word errors at thelexical level, which is an isolated word correction prob-lem.
However, errors of speech recognition tend to becontinuous word errors which should be better classi-fied into syntactic and semantic level errors, because therecognizer only produces word sequences existing in alexicon.
So, this section presents a more syntax andsemantic-oriented approach to correct erroneous outputsof a speech recognizer using a domain knowledge whichprovides syntactic and semantic information.
We fo-cus on continuous word error detection and correction,using syntactic and semantic knowledge, and pipelinethis high-level error correction method with the syllable-based channel model.4.1 Lexico-Semantic PatternA lexico-semantic pattern (LSP) is a structure where lin-guistic entries and semantic types are used in combina-tion to abstract certain sequences of the words in a text.It has been used in the area of natural language interfacefor database (NLIDB) (Jung et al, 2003) and a TRECQA system for the purpose of matching the user querywith the appropriate answer types at syntax/semanticlevel (Kim et al, 2001; Lee et al, 2001).
In an LSP,linguistic entries consist of words, phrases and part-of-speech (POS) tags, such as ?YMCA,?
?Young Men?sChristian Association,?
and ?NNP.
?3 Semantic types con-3Part-of-speech tag denoting a proper noun which is used inPenn TreeBank (Marcus et al, 1994).Phrases LSPReading trainerFairy tale trainer %hobby @positionRecreation coachTable 1: Example of a template abstracted by LSPsist of common semantic classes and domain-specific (oruser-defined) semantic classes.
The common semantictags again include attribute-values in databases, such as?@corp?
for a company name like ?IBM,?
and pre-define83 semantic category values, such as ?@location?
for lo-cation names like ?New York?
(Jung et al, 2003).
Fig-ure 4 shows an example of predefined common semanticcategory values which will be used in an ontology dictio-nary.In domain-specific application, well defined semanticconcepts are required, and the domain-specific seman-tic classes represent these requirements.
The domain-specific semantic classes include special attribute namesin databases, such as ?%action?
for ?active?
and ?inac-tive,?
and semantic category names, such as ?%hobby?
for?reading?
and ?recreation,?
for which the user wants a spe-cific meaning in the application domain.
Moreover, weused the classes to abstract out several synonyms into asingle concept.
For example, a domain-specific semanticclass ?%question?
represents some words, such as ?ques-tion?, ?query?, ?asking?, and ?answer.
?The domain dictionary is a subset of the general se-mantic category dictionary, and focuses only on the nar-row extent of the knowledge it concerns, since it is im-possible to cover all the knowledge of the world in imple-menting an application.
On the other hand, the ontologydictionary for common semantic classes reflects the puregeneral knowledge of the world; hence it performs a sup-plementary role to extract semantic information.
The do-main dictionary provides the specific vocabulary which isused in semantic representation tasks of a user query andthe template database.4.2 Construction of a Domain KnowledgeFor semantic-oriented error correction, we constructed adomain knowledge, which consists of a domain dictio-nary, an ontology dictionary, and template queries thatare similar to question types in a QA system (Lee etal., 2001).
Query sentences are semantically abstractedby LSP?s and are automatically collected for the templatedatabase.Because Fujii et al (Fujii et al, 2002B) have shownthe importance of the language model which well de-scribes the domain knowledge, we reflect the domaininformation with a template database: database of tem-plate queries of the source statements which are usedFigure 5: Process of Semantic-oriented Error Correctionfor the actual error detection and correction task afterspeech recognition.
The template queries are automati-cally acquired by the Query-to-LSP translation from thesource statements using two semantic category dictionar-ies: domain dictionary and an ontology dictionary.
As-suming that some speech statements for a specific targetdomain are predefined, a record of the template databaseis composed of a fixed number of LSP elements, such asPOS tags, semantic tags, and domain-specific semanticclasses.
Table 1 shows an example of template abstractedby LSP conversion in a predefined domain of ?on-line ed-ucation.
?Query-to-LSP translation transforms a given query intoa corresponding LSP, and the LSP?s enhance the cov-erage of extraction by information abstraction throughmany-to-one mapping between queries and an LSP.
Thewords in a query sentence are converted into the LSPthrough several steps.
First, a morphological analysis isperformed, which segments a sentence of words into mor-phemes, and adds POS tags to the morphemes (Lee et al,2002).
NE recognition discovers all the possible seman-tic types for each word by consulting a domain dictionaryand an ontology dictionary.
NE tagging selects a seman-tic type for each word so that a sentence can be mappedinto a suitable LSP sequence by searching several typesin the semantic dictionaries (An et al, 2003).4.3 Semantic-oriented Error Correction ProcessNow, we will show the working mechanism of post errorcorrection of a speech recognition result using the domainknowledge of template database and domain-specific dic-tionary.
Figure 5 is a schematic diagram of the post errorcorrection process.The overall process is divided into two stages: a syn-tactic/semantic recovery and a lexical recovery stage.
Inthe semantic error detection stage, a recognized query isconverted into the corresponding LSP.
The converted LSPmay be ill-formed depending on the errors in the rec-ognized query.
Semantic error correction is performedby replacing these syntactic and/or semantic errors us-ing a semantic confusion table.
We used a pre-collectedtemplate database to recover the semantic level errors,and the technique for searching most similar templatesare based on a minimum edit distance dynamic program-ming search, which has been used as a similarity searchin many areas such as spelling correction, OCR post cor-rection, and DNA sequence analysis (Wagner and Fis-cher, 1974).
The semantic confusion table provides thematching cost, which can be semantic similarity, to thedynamic programming search process.
The ?minimumedit distance?
between two words is originally defined asthe minimum number of deletions, insertions, and sub-stitutions required to transform one word into the other.We compute the minimum edit distances between the er-roneous LSP?s and the template LSP?s in the templatedatabase using the similarity cost functions at the seman-tic level, and select, as the final template query, the onewhich has the minimum distance among them.
At thisstage, replaced LSP elements can provide some clues ofthe recognition errors and the original query?s meaningto the next lexical recovery stage.
Moreover, candidateerror boundary can also be detected by this procedure.After this procedure, lexical recovery is performed inthe next stage.
Recovered semantic tags and the erro-neous queries produced by ASR are the clues of lexi-cal recovery.
Erroneous query and recovered templatequery are aligned by dynamic programming again, afterwhich some lexical candidates are generated by our im-proved syllable-based channel model.
Figure 6 4 showsan example of semantic error correction process using thesame data in TRAIN-95 (Allen et al, 1996).5 Experiments5.1 Experimental SetupWe performed several experiments on the domain of in-vehicle telematics IR related to navigation question an-swering services.
The speech transcripts used in the ex-periments were composed of 462 queries, which werecollected by 1 male speaker in a real application.
Wealso used two Korean speech recognizers: a speech rec-ognizer made by LG-Elite (LG Electronics Institute ofTechnology) and a Korean commercial speech recog-nizer, ByVoice (refer to http://www.voicetech.co.kr).
For4In corrected sentence, note that word ?A?
is not recoveredbecause this word is meaningless functional word.Figure 6: Example of Semantic-oriented Error Correctionour semantic-oriented error correction, we constructed adomain knowledge for our target domain.
We constructed3,195 entries of domain dictionary, 13,154 entries of on-tology dictionary, and 436 semantic templates generatedautomatically using domain dictionary and ontology dic-tionary.We implemented both word-based and syllable-basedmodel for comparison, and combined the system ofsyllable-based lexical correction with the LSP-based se-mantic error correction.
For experiments, we use trigramslanguage model generated by SRILM toolkit (Stolcke,2002), and a training program for channel model madeby ourselves.
And, we divided the 462 queries into 6 dif-ferent sets, and evaluated the results of 6-fold cross vali-dation for each model.5.2 ResultsTo measure error correction performance, we use worderror rate (WER) and term error rate (TER):WER = |Sw| + |Iw| + |Dw||Wtruth|(10)TER = |St| + |It| + |Dt||Ttruth|(11)|Wtruth| is the number of original words, and |Ttruth|is the number of query term (or keyword) in originalwords, that is, an error rate of content words directly re-lated to the performance of IR and QA system (Fujii etal., 2002A).Table 2, 3 present the experiments results of WER ofbaseline ASR, word-based channel model, our syllable-based channel model and combined syllable-based chan-nel model with the LSP semantic correction model.
Theperformances of baseline systems were about 79% ?81% on the utterances in in-vehicle telematics IR domain.This result shows that the semantic error correction ofTest set 1 2 3 4 5 6 AVG.Baseline 18.1% 21.6% 19.4% 22.8% 19.9% 19.2% 20.17%Word-based 12.8% 20.3% 15.5% 17.5% 16.7% 17.7% 16.75%Syllable-based 10.6% 16.0% 11.5% 16.1% 14.0% 10.6% 13.13%Syllable + LSP 9.7% 14.9% 10.4% 15.3% 13.0% 10.7% 12.33%Table 2: Result of LG-Elite RecognizerTest set 1 2 3 4 5 6 AVG.Baseline 20.5% 18.8% 19.8% 17.0% 16.9% 17.8% 18.47%Word-based 19.9% 14.8% 18.4% 16.2% 15.3% 15.1% 16.75%Syllable-based 16.7% 13.8% 17.0% 13.3% 12.7% 12.2% 14.28%Syllable + LSP 15.3% 13.4% 15.8% 12.9% 11.3% 11.8% 13.42%Table 3: Result of ByVoicespeech recognition result is a viable approach to improvethe performance.Using both baseline ASR systems, we achieved 39%and 27% of error reduction rate.
In comparison with theprevious word-based model, our new approaches havemore accurate error correction performance in this do-main.
Table 4 shows the result of the experiments forTER.
The result of TER shows that baseline ASR systemsalone are not appropriate to process the user?s queries inspeech-driven IR, QA or dialog understanding system.However, with a post error correction, the error reduc-tion rate of TER is much higher than that of WER.
Andwe achieved better performance than word-based model.With this result, our methods are considered to be moreappropriate in speech-driven IR and QA applications.Compared with the word-based noisy channel model thathas been the best approach in the error correction so far,our semantic-oriented error correction suggests alterna-tive more successful methods for speech recognition errorcorrection.Baseline Word-basedSyllable-basedSyllable+ LSPLG-Elite 56.4 % 31.5% 30.1% 26.7%ByVoice 64.1% 34.1% 32.8% 27.6%Table 4: Result of Term Error Rate6 Conclusion and Future WorksWe proposed an improved syllable-based noisy channelmodel and combined higher level linguistic knowledgefor semantic-oriented approach in a speech recognitionerror correction, which shows a superior performance indomain-specific IR applications.The previous works only focused on inter-word levelerror correction, commonly depending on a large amountof training corpus for the error correction model and thelanguage model.
So, previous approaches require enor-mous results of ASR and are dependent on specific speak-ers and environments.
On the other hand, our methodtakes in far smaller training corpus, and it is possible toimplement the method easily and in a short time to ob-tain the better error correction rate because it utilizes thesemantic information of the application domain.And our semantic-oriented approach has more advan-tages over lexical based ones, since it is less sensitive toeach error pattern.
Also, the approach has a broader cov-erage of error patterns, since several similar common er-ror strings in the semantic ground can be reduced to onesemantic error pattern, which enables us to improve theprobability of recovering from erroneous recognition re-sults.And, because the LSP scheme transforms pure lexicalentries into abstract semantic categories, the size of theerror pattern database can be reduced remarkably, andit also increases the coverage and robustness comparedwith the previous pure lexical entries that can only dealwith the morphological variants.With all these facts, the LSP correction has a highpossibility of generating semantically correct correctiondue to the massive use of semantic contexts.
Hence, itshows a high performance, especially when combinedwith domain-specific speech-driven natural language IRand QA systems.Future work should include the end-performance ex-periments with IR or QA application for our error correc-tion model.7 AcknowledgementsThis work was partly supported by Jungki KeoJeomProject (MOCIE, ITEP), and by 21C Frontier Project(MOST).ReferencesJames F. Allen, Bradford W. Miller, Eric K. Ringger, andTeresa Sikorski.
1996.
A Robust System for NaturalSpoken Dialogue.
In Proceedings of the 34th AnnualMeeting of the ACLJuhui An, Seungwoo Lee, and Gary Geunbae Lee.
2003.Automatic acquisition of Named Entity tagged corpusfrom World Wide Web.
In Proceedings of the 41st an-nual meeting of the ACL (poster presentation).J.
Barnett, S. Anderson, J. Broglio, M. Singh, R. Hud-son, and S.W.
Kuo.
1997.
Experiments in spokenqueries for documents retrieval.
In Proceedings of Eu-rospeech, (3):1323-1326.Eric Brill and Robert C. Moore.
2000.
An ImprovedError Model for Noisy Channel Spelling Correction.ACL2000, 286-293.P.
F. Brown, J. Cocke, S. A. Della Pietra, V. J. DellaPietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P.S.
Roossin.
1990.
A Statistical Approach to MachineTranslation.
Computational Linguistics, 16(2):79-85Ciprian Chelba.
1997.
A Structured Language Model.
InProceedings of the Thirty-Fifth Annual Meeting of theACL and Eighth Conference of the European Chapterof the ACL, 498-503.F.
Crestani.
2000.
Word recognition errors and relevancefeedback in spoken query processing In Proceedingsof the 2000 Flexible Query Answering Systems Confer-ence, 267-281.Atsushi Fujii, Katunobu Itou, and Tetsuya Ishikawa.2002A.
Speech-driven Text Retrieval: Using TargetIR Collections for Statistical Language Model Adapta-tion in Speech Recognition.
Anni R. Coden and EricW.
Brown and Savitha Srinivasan (Eds.)
InformationRetrieval Techniques for Speech Application (LNCS2273), 94-104.Atsushi Fujii, Katunobu Itou, and Tetsuya Ishikawa.2002B.
A method for open-vocabulary speech-driventext retrieval.
In Proceedings of the 2002 conferenceon Empirical Methods in Natural Language Process-ing, 188-195.Sanda Harabagiu, Dan Moldovan, and Joe Picone.
2002.Open-Domain Voice-Activated Question Answering.COLING2002, (1):321-327, Taipei.Hanmin Jung, Gary Geunbae Lee, Wonseug Choi,KyungKoo Min, and Jungyun Seo.
2003.
Multi-lingual question answering with high portability on re-lational databases.
IEICE transactions on informationand systems, E-86D(2):306-315.Satoshi Kaki, Eiichiro Sumita, and Hitoshi Iida.
1998.A Method for Correcting Speech Recognition Usingthe Statistical features of Character Co-occurrence.COLING-ACL?98, 653-657.Haksoo Kim, Kyungsun Kim, Gary Geunbae Lee, andJungyun Seo.
2001.
MAYA: A Fast Question-Answering System Based on a Predictive Answer In-dexer.
In Proceedings of the 39th Annual Meet-ing of the Association for Computational Linguistics(ACL?01), Workshop on Open-Domain Question An-sweringK.
Kukich.
1992.
Techniques for automatically cor-recting words in text.
ACM Computing Surveys,24(4):377-439.Geunbae Lee, Jungyun Seo, Seungwoo Lee, HanminJung, Bong-Hyun Cho, Changki Lee, Byung-KwanKwak, Jeongwon Cha, Dongseok Kim, JooHui An,Harksoo Kim, and Kyungsun Kim.
2001.
SiteQ: Engi-neering High Performance QA System Using Lexico-Semantic Pattern Matching and Shallow NLP.
In Pro-ceedings of the 10th Text Retrieval Conference (TREC-10), Washington D.C.Gary Geunbae Lee, Jeongwon Cha, and Jong-HyeokLee.
2002.
Syllable pattern-based unknown mor-pheme segmentation and estimation for hybrid part-of-speech tagging of Korean.
Computational Linguistics,28(1):53-70.Mitchell P. Marcus and Beatrice Santorini and Mary AnnMarcinkiewicz.
1994.
Building a Large AnnotatedCorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2):313-330.Eric K. Ringger and James F. Allen.
1996.
A fertilitymodel for post correction of continuous speech recog-nition ICSLP?96, 897-900.Andreas Stolcke 2002.
SRILM - An Extensible Lan-guage Modeling Toolkit.
In Proceedings of Intl.
Conf.on Spoken Language Processing, (2):901-904, Denver,Co.
(http://www.speech.sri.com/projects/srilm/)Robert A. Wagner and Michae J. Fischer.
1974.
TheString-to-String Correction Problem.
Journal of theACM, 21(1):168-173.I.
Witten and T. Bell.
1991.
The Zero-Frequency Prob-lem: Estimating the Probabilities of Novel Events inAdaptive Text Compression.
In IEEE Transactions onInformation Theory, 37(4).
