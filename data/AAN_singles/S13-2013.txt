Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 78?82, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsSUTIME: Evaluation in TempEval-3Angel X. ChangStanford Universityangelx@cs.stanford.eduChristopher D. ManningStanford Universitymanning@cs.stanford.eduAbstractWe analyze the performance of SUTIME, atemporal tagger for recognizing and normal-izing temporal expressions, on TempEval-3Task A for English.
SUTIME is available aspart of the Stanford CoreNLP pipeline and canbe used to annotate documents with temporalinformation.
Testing on the TempEval-3 eval-uation corpus showed that this system is com-petitive with state-of-the-art techniques.1 IntroductionThe importance of modeling temporal informationis increasingly apparent in natural language appli-cations, such as information extraction and ques-tion answering.
Extracting temporal information re-quires the ability to recognize temporal expressions,and to convert them from text to a normalized formthat is easy to process.
Temporal tagging systemsare designed to address this problem.
In this paper,we evaluate the performance of the SUTIME (Changand Manning, 2012) rule-based temporal taggingsystem.We evaluate the performance of SUTIME on ex-tracting temporal information in TempEval-3 (Uz-Zaman et al 2013), which requires systems to auto-matically annotate documents with temporal infor-mation using TimeML (Pustejovsky et al 2003).The TempEval-3 training data contains gold humanannotated data from TimeBank, AQUAINT, and anew dataset of silver data automatically annotatedusing a combination of TipSem (Llorens et al 2010)and TRIOS (UzZaman and Allen, 2010), two of thebest performing systems from TempEval-2 (Verha-gen et al 2010).2 System DescriptionWe use the Stanford CoreNLP1 pipeline with SU-TIME to identify and normalize TIMEX32 ex-pressions.
SUTIME is incorporated into StanfordCoreNLP as part of the Named Entity Recognitionannotator.
For TempEval-3, we use the standard setof rules provided with SUTIME.
Since SUTIME canalso recognize temporal expressions whose valuesare not specified by TIMEX3, we ran SUTIME ina TIMEX3 compatible mode.32.1 SUTimeSUTIME is a rule-based temporal tagger built onregular expression patterns over tokens.
Tempo-ral expressions are bounded in their complexity, somany of them can be captured using finite automata.As shown by systems such as FASTUS (Hobbs etal., 1997), a cascade of finite automata can be veryeffective at extracting information from text.
WithSUTIME, we follow a similar staged strategy of(i) building up patterns over individual words tofind numerical expressions; then (ii) using patternsover words and numerical expressions to find sim-ple temporal expressions; and finally (iii) formingcomposite patterns over the discovered temporal ex-pressions.SUTIME recognizes Time, Duration, Interval,and Set according to the TIMEX3 specification.
In1nlp.stanford.edu/software/corenlp.shtml2www.timeml.org3sutime.restrictToTimex3 = true78addition, it recognizes nested time expressions andduration ranges.
To achieve this it uses a temporalpattern language defined over tokens (a regular ex-pression language for expressing how tokenized textshould be mapped to temporal objects).
SUTIME isbuilt on top of TOKENSREGEX,4 a generic frame-work included in Stanford CoreNLP for defininingpatterns over text and mapping to semantic objects.With TOKENSREGEX we have access to any anno-tations provided by the Stanford CoreNLP system,such as the part-of-speech tag or the lemma.
The fullspecification of the pattern language is available atnlp.stanford.edu/software/sutime.shtml.To recognize temporal expressions, SUTIME ap-plies three types of rules, in the following order: 1)text regex rules: mappings from simple regular ex-pressions over characters or tokens to temporal rep-resentations; 2) compositional rules: mappings fromregular expressions over chunks (both tokens andtemporal objects) to temporal representations and3) filtering rules: in which ambiguous expressionsthat are likely to not be temporal expressions are re-moved from the list of candidates (such as fall andspring by themselves).
The compositional rules areapplied repeatedly until the final list of time expres-sions stablizes.After all the temporal expressions have been rec-ognized, each temporal expression is associated witha temporal object.
Each temporal object is resolvedwith respect to the reference date using heuristicrules.
In this step, relative times are converted toan absolute time, and composite time objects aresimplified as much as possible.
The final resolutionof relative temporal expressions is currently limiteddue to the usage of simple hard-coded rules (e.g.
rel-ative to document date with local context inform-ing before and after heuristics).
Finally, SUTIMEwill take the internal time representation and pro-duce a TIMEX3 annotation for each temporal ex-pression.
SUTIME currently only handles English.It can however, be extended to other languages bycreating sets of rules for additional languages.3 EvaluationWe evaluated SUTIME?s performance on theTempEval-3 Task A for English.
Task A consists4nlp.stanford.edu/software/tokensregex.shtmlof determining the extent of time expressions as de-fined by the TimeML TIMEX3 tag, as well as pro-viding normalized attributes for type and value.
Ex-tracted temporal expressions from the system andthe gold are matched, and precision, recall, and F1are computed.
For the evaluation of extents, thereare two metrics: a relaxed match score for identi-fying a matching temporal expression, and a strictmatch that requires the text to be matched exactly.For example, identifying the twentieth century whenthe gold is twentieth centry will give a relaxed matchbut not a strict match.
For the type and value at-tributes, an accuracy and a measure of the F1 withrespect to the relaxed match is given.We compare SUTIME?s performance with severalother top systems on the English TempEval-3 TaskA.
We also include TIPSem which was used to cre-ate the silver data for TempEval-3 as a baseline.
Ofthe systems that prepared multiple runs, we selectedthe best performing run to report.
Table 1 gives theresults for these systems on the TempEval-3 evalu-ation set.
Interestingly, NavyTime which uses SU-TIME for Task A, actually did better than SUTIMEin the value normalization and is effectively the 2ndbest system in Task A.
The performance of Navy-Time is otherwise identical to SUTIME.
In Navy-Time the normalization was tuned to the TimeBankannotation whereas the SUTIME submission wasuntuned.
SUTIME has the highest recall in discov-ering temporal expressions.
It also has the high-est overall relaxed F1, slightly higher than Heidel-Time (Stro?tgen and Gertz, 2010) (cleartk had thehighest strict F1 of 82.71).
Not surprisingly, the sys-tem used to generate the silver data, TIPSem, hadthe highest precision when extracting temporal ex-pressions.
For normalization, HeidelTime had theoverall best performance on value and type.
BothSUTIME and HeidelTime are rule-based, indicatingthe effectiveness of using rules for this domain.
An-other top performing system, ManTime used condi-tional random fields, a machine learning approach,for identifying temporal expressions and rules fornormalization.79Identification NormalizationRelaxed Strict Value TypeSystem F1 P R F1 P R F1 Accuracy F1 AccuracySUTime 90.32 89.36 91.30 79.57 78.72 80.43 67.38 74.60 80.29 88.90NavyTime 90.32 89.36 91.30 79.57 78.72 80.43 70.97 78.58 80.29 88.90HeidelTime 90.30 93.08 87.68 81.34 83.85 78.99 77.61 85.95 82.09 90.91ManTime 89.66 95.12 84.78 74.33 78.86 70.29 68.97 76.92 77.39 86.31TIPSem 84.90 97.20 75.36 81.63 93.46 72.46 65.31 76.93 75.92 89.42Table 1: TempEval-3; English Platinum Test set.4 Error AnalysisGiven the small size of the platinum data set, wewere able to perform thorough error analysis of theerrors made by SUTIME on the data set.Table 2 shows the number of temporal expres-sions marked by the evaluation script as being in-correct.
The errors can be grouped into three broadcategories: i) those proposed by the system but notin the gold (relaxed precision errors), ii) those in thegold but not identified by the system (relaxed recallerrors), and iii) temporal expressions with the wrongvalue (and sometimes type) normalization.Of the 14 precision errors, many of the temporalexpressions suggested by the system are reasonable.For instance, current is identified by the system.
Afew of the errors are not actual temporal expres-sions.
For example, in the phrase British SummerTime, Summer was identified as a temporal expres-sion which is not correct.Given SUTime?s high recall, only a few temporalexpressions in the gold are not found by the system.In most cases, the temporal expressions missed bySUTIME do not have a well defined value associatedwith them (e.g.
?digital age?, ?each season?
).Performance using the strict match metric is notas good as some other systems.
SUTIME wasderived from GUTime (Mani, 2004) and focuseson matching longer time expressions as per ear-lier guidelines.
Thus it is less conformant to themore current TimeML guidelines of having minimalblocks.
For instance, SUTIME treats 2009-2010 asa range, whereas the gold standard treats it as twoseparate dates.
This results in an incorrect value nor-malization and a recall error.We now examine the cases where the SUTIMEnormalization differed from the gold.
Table 3 showsa further breakdown of these errors.Error type CountSystem not in gold (precision) 14Gold not in system (recall) 12Wrong value 32Table 2: Summary of errors made by SUTIME on theplatinum data setError type CountValue incorrectly resolved wrt to DCT 7Value should not be resolved wrt to DCT 5DURATION resolved to DATE 6DATE misidentified as DURATION 3Wrong granularity 4Wrong normalization for set 2Different normalization 3Other 2Table 3: Break down of value errors made by SUTime onthe platinum data setOne weakness of SUTIME is that temporal ex-pressions are always resolved with respect to thedocument creation time (DCT).
While this heuris-tic works fairly well in most cases, and SUTime canachieve reasonable performance, there are obviouslimitations with this approach.
For instance, some-times it is more appropriate to resolve the tempo-ral expression with respect to nearby dates or eventsin the text.
As an example, in the test documentCNN 20130322 1003 there is the sentence Call meSunday night at 8 PM at the resort that is part ofan email of an unknown date.
In this case, SUTIMEstill attempts to resolve the temporal expression Sun-day night at 8 PM using the document creation timewhich is incorrect.There can be inherent ambiguity as to which timepoint a time expression refers to.
For instance, givena reference date of 2011-09-19, a Monday, it is un-80clear whether Friday refers to 2011-09-16 or 2011-09-23.
SUTIME will normally resolve to the closestdate/time with respect to the reference date.
SU-TIME also has some rules that will use the verb tenseof the surrounding words to attempt to resolve theambiguity.
For instance, if a verb close to the tem-poral expression has a POS tag of VBD (past tenseverb) then the expression will be resolved so that itoccurs before the document date.Most of the type errors are due to confusions be-tween DATE and DURATION.
Often SUTIME willattempt to resolve a DURATION as a DATE.
Forinstance, given the phrase ?the following decade?,SUTIME will attempt to resolve that as a DATE withvalue 202X (using a DCT of 2013-03-22).
Whilethis can be desirable in some cases, this is not whatthe gold annotation contains: type of DURATIONand value of P1DE.
In some other cases, SUTIMEmisidentifies DURATION as a DATE.
For instance,it lacks rules to parse the 3:07:35 in finishing in3:07:35 as a duration.Another problem faced by SUTIME is in figuringout the correct granularity to use.
Given a documentdate of 2013-03-22, it will identify two years ago asbeing 2011-03-22.
However, since these expressionsindicate a less precise date, the gold annotation is asimple 2011.SUTIME also provided the wrong normalizationfor SET in several cases.
For the expression everymorning, SUTIME reported a value of TMO whenthe gold annotation was XXXX-XX-XXTMO.
Inother cases, SUTIME offered an alternative normal-ization, for instance, a value of 19XX for the 20thcentury instead of just 19.
And PTXM instead ofPXM for minutes.
In this case, the PTXM is morecorrect as the T is required by ISO-8601 to differ-entiate between M for month, and M for minutes.The remaining errors are due to lacking rules suchas SUTIME?s inability to handle time zones in cer-tain cases.5 DiscussionAs a rule-based system, SUTIME is limited by thecoverage of its rule set for the different types oftemporal expressions it can recognize.
Many of theerrors in SUTIME can be resolved by adding morerules to the system.One key to improving the normalization of thevalue is to have better resolution of ambiguous tem-poral expressions.
Identifying when temporal ex-pressions should not be resolved using the documentcreation time, and how the temporal expression re-lates to other temporal expressions or events withinthe document is also critical.
This suggests that nor-malization can benefit from being able to performTempEval-3 Task C well.Another approach to improving the system wouldbe to provide different modes of use: a mode for endusers that would like complex temporal expressionsto be identified, or a mode for more basic temporalexpressions that can be used as input for other tem-poral systems.
Allowing for nested TIMEXes wouldalso benefit the system?s performance.
For example,2009-2010 should be a range, with a nested timexfor 2009 and 2010.Another interesting direction to explore wouldbe to evaluate the performance of SUTIME on do-mains other than current news.
Since SUTIME alsosupports temporal expressions such as holidays andmore distant dates such as 400 B.C., it would be in-teresting to see how well SUTIME can extract thesedifferent types of temporal expressions.6 ConclusionWe have evaluated SUTIME by participating inTempEval-3 Task A and have shown that it is acompetitive system for extracting time expressions.By providing it as part of the Stanford CoreNLPpipeline, we hope that it can be easily used as a basiccomponent for building temporally aware systems.AcknowledgementsWe would like to acknowledge Justin Heermann,Jonathan Potter, Garrett Schlesinger and John Bauerfor helping to implement parts of the system forTempEval-3.ReferencesAngel X. Chang and Christopher D. Manning.
2012.SUTIME: A library for recognizing and normalizingtime expressions.
In 8th International Conference onLanguage Resources and Evaluation (LREC 2012).Jerry R. Hobbs, Douglas E. Appelt, John Bear, David Is-rael, Megumi Kameyama, Mark Stickel, and Mabry81Tyson.
1997.
FASTUS: A cascaded finite-statetransducer for extracting information from natural-language text.
Finite State Devices for Natural Lan-guage Processing, pages 383?406.Hector Llorens, Estela Saquete, and Borja Navarro.2010.
TIPSem (English and Spanish): EvaluatingCRFs and semantic roles in TempEval-2.
In Proceed-ings of the 5th International Workshop on SemanticEvaluation, pages 284?291.
Association for Compu-tational Linguistics.Inderjeet Mani.
2004.
Recent developments in temporalinformation extraction.
In Proceedings of RANLP03,pages 45?60.James Pustejovsky, Jos Castao, Robert Ingria, RoserSaur, Robert Gaizauskas, Andrea Setzer, and GrahamKatz.
2003.
TimeML: Robust specification of eventand temporal expressions in text.
In in Fifth Interna-tional Workshop on Computational Semantics (IWCS-5.Jannik Stro?tgen and Michael Gertz.
2010.
HeidelTime:High quality rule-based extraction and normalizationof temporal expressions.
In Proceedings of the 5th In-ternational Workshop on Semantic Evaluation, pages321?324.Naushad UzZaman and James F Allen.
2010.
TRIPS andTRIOS system for TempEval-2: Extracting temporalinformation from text.
In Proceedings of the 5th In-ternational Workshop on Semantic Evaluation, pages276?283.
Association for Computational Linguistics.Naushad UzZaman, Hector Llorens, Leon Derczynski,Marc Verhagen, James Allen, and James Pustejovsky.2013.
SemEval-2013 Task 1: TempEval-3: Evaluat-ing time expressions, events, and temporal relations.In Proceedings of the 7th International Workshop onSemantic Evaluation, SemEval ?13.Marc Verhagen, Roser Saur?
?, Tommaso Caselli, andJames Pustejovsky.
2010.
SemEval-2010 task 13:TempEval-2.
In Proceedings of the 5th Interna-tional Workshop on Semantic Evaluation, SemEval?10, pages 57?62.
Association for Computational Lin-guistics.82
