Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 58?67,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsInducing Example-based Semantic Framesfrom a Massive Amount of Verb UsesDaisuke Kawahara?Daniel W. Peterson?Octavian Popescu?Martha Palmer?
?Kyoto University, Kyoto, Japan?University of Colorado at Boulder, Boulder, CO, USA?Fondazione Bruno Kessler, Trento, Italydk@i.kyoto-u.ac.jp, {Daniel.W.Peterson, Martha.Palmer}@colorado.edu, popescu@fbk.euAbstractWe present an unsupervised method for in-ducing semantic frames from verb uses ingiga-word corpora.
Our semantic framesare verb-specific example-based framesthat are distinguished according to theirsenses.
We use the Chinese Restau-rant Process to automatically induce theseframes from a massive amount of verb in-stances.
In our experiments, we acquirebroad-coverage semantic frames from twogiga-word corpora, the larger comprising20 billion words.
Our experimental resultsindicate the effectiveness of our approach.1 IntroductionSemantic frames are indispensable knowledge forsemantic analysis or text understanding.
In thelast decade, semantic frames, such as FrameNet(Baker et al., 1998) and PropBank (Palmer et al.,2005), have been manually elaborated.
Theseresources are effectively exploited in many nat-ural language processing (NLP) tasks, includ-ing not only semantic parsing but also ma-chine translation (Boas, 2002), information ex-traction (Surdeanu et al., 2003), question answer-ing (Narayanan and Harabagiu, 2004), paraphraseacquisition (Ellsworth and Janin, 2007) and recog-nition of textual entailment (Burchardt and Frank,2006).There have been many attempts to automati-cally acquire frame knowledge from raw corporawith the goal of either adding frequency informa-tion to an existing resource or of inducing simi-lar frames for other languages.
Most of these ap-proaches, however, focus on syntactic frames, i.e.,subcategorization frames (e.g., (Manning, 1993;Briscoe and Carroll, 1997; Korhonen et al., 2006;Lippincott et al., 2012; Reichart and Korhonen,2013)).
Since subcategorization frames representargument patterns of verbs and are purely syn-tactic, expressions that have the same subcatego-rization frame can have different meanings (e.g.,metaphors).
Semantics-oriented NLP applicationsbased on frames, such as paraphrase acquisitionand machine translation, require consistency in themeaning of each frame, and thus these subcatego-rization frames are not suitable for these semantictasks.Recently, there have been a few studies on au-tomatically acquiring semantic frames (Materna,2012; Materna, 2013).
Materna induced seman-tic frames (called LDA-Frames) from triples of(subject, verb, object) in the British NationalCorpus (BNC) based on Latent Dirichlet Allo-cation (LDA) and the Dirichlet Process.
LDA-Frames capture limited linguistic phenomena ofthese triples, and are defined across verbs basedon probabilistic topic distributions.This paper presents a method for automati-cally building verb-specific semantic frames froma large raw corpus.
Our semantic frames are verb-specific like PropBank and semantically distin-guished.
A frame has several syntactic case slots,each of which consists of words that are eligible tofill the slot.
For example, let us show three seman-tic frames of the verb ?observe?
:1observe:1nsubj:{we, author, ...} dobj:{effect, result, ...}prep in:{study, case, ...} ...observe:2nsubj:{teacher, we, ...} dobj:{child, student, ...}prep in:{classroom, school, ...} ...observe:3nsubj:{child, people, ...} dobj:{bird, animal, ...}prep at:{range, time, ...} ...1In this paper, we use the dependency relation namesof the Stanford collapsed dependencies (de Marneffe et al.,2006) as the notations of case slots.
For instance, ?nsubj?means a nominal subject, ?dobj?
means a direct object, ?iboj?means an indirect object, ?ccomp?
means a clausal comple-ment and ?prep *?
means a preposition.58Frequencies, which are not shown in the above ex-amples, are attached to each semantic frame, caseslot and word, and can be effectively exploited forthe applications of these semantic frames.
The fre-quencies of words in each case slot become goodsources of selectional preferences.Our novel contributions are summarized as fol-lows:?
induction of semantic frames based on theChinese Restaurant Process (Aldous, 1985)from only automatic parses of a web-scalecorpus,?
exploitation of the assumption of one senseper collocation (Yarowsky, 1993) to make thecomputation feasible,?
providing broad-coverage knowledge for se-lectional preferences, and?
evaluating induced semantic frames by us-ing an existing annotated corpus with verbclasses.2 Related WorkThe most closely related work to our semanticframes are LDA-Frames, which are probabilisticsemantic frames automatically induced from a rawcorpus (Materna, 2012; Materna, 2013).
He used amodel based on LDA and the Dirichlet Process tocluster verb instances of a triple (subject, verb, ob-ject) to produce semantic frames and slots.
Bothof these are represented as a probabilistic distri-bution of words across verbs.
He applied thismethod to the BNC and acquired 427 frames and144 slots (Materna, 2013).
These frames are over-generalized across verbs and might be difficultto provide with fine-grained selectional prefer-ences.
In addition, Grenager and Manning (2006)proposed a method for inducing PropBank-styleframes from Stanford typed dependencies ex-tracted from raw corpora.
Although these framesare based on typed dependencies and more seman-tic than subcategorization frames, they are not dis-tinguished in terms of the senses of words filling acase slot.There are hand-crafted semantic frames in thelexicons of FrameNet (Baker et al., 1998) andPropBank (Palmer et al., 2005).
Corpus PatternAnalysis (CPA) frames (Hanks, 2012) are anothermanually created repository of patterns for verbs.Each pattern represents a prototypical word usageas extracted by lexicographers from the BNC.
Cre-ating CPA is time consuming, but our proposedmethod may be employed to assist in the creationof this type of resource, as shown in Section 4.4.Our task can be regarded as clustering of verbinstances.
In this respect, the models of Parisienand Stevenson are related to our method (Parisienand Stevenson, 2009; Parisien and Stevenson,2010).
Parisien and Stevenson (2009) proposeda Dirichlet Process model for clustering usagesof the verb ?get.?
Later, Parisien and Stevenson(2010) proposed a Hierarchical Dirichlet Processmodel for jointly clustering argument structures(i.e., subcategorization frames) and verb classes.However, their argument structures are not seman-tic but syntactic, and also they did not evaluate theresulting frames.
There have also been related ap-proaches to clustering verb types (Vlachos et al.,2009; Sun and Korhonen, 2009; Falk et al., 2012;Reichart and Korhonen, 2013).
These methods in-duce verb clusters in which multiple verbs partic-ipate, and do not consider the polysemy of verbs.Our objective is different from theirs.Another line of related work is unsupervisedsemantic parsing or semantic role labeling (Poonand Domingos, 2009; Lang and Lapata, 2010;Lang and Lapata, 2011a; Lang and Lapata, 2011b;Titov and Klementiev, 2011; Titov and Klemen-tiev, 2012).
These approaches basically clus-ter predicates and their arguments to distinguishpredicate senses and semantic roles of arguments.Modi et al.
(2012) extended the model of Titov andKlementiev (2012) to jointly induce semantic rolesand frames using the Chinese Restaurant Process,which is also used in our approach.
However,they did not aim at building a lexicon of semanticframes, but at distinguishing verbs that have dif-ferent senses in a relatively small annotated cor-pus.
Applying this method to a large corpus couldproduce a frame lexicon, but its scalability wouldbe a big problem.For other languages than English, Kawaharaand Kurohashi (2006a) proposed a method for au-tomatically compiling Japanese semantic framesfrom a large web corpus.
They applied con-ventional agglomerative clustering to predicate-argument structures using word/frame similaritybased on a manually-crafted thesaurus.
SinceJapanese is head-final and has case-marking post-positions, it seems easier to build semantic frameswith it than with other languages such as English.They also achieved an improvement in depen-dency parsing and predicate-argument structure59analysis by using their resulting frames (Kawaharaand Kurohashi, 2006b).3 Method for Inducing Semantic FramesOur objective is to automatically induce verb-specific example-based semantic frames.
Each se-mantic frame consists of a partial set of syntacticslots: nsubj, dobj, iobj, ccomp and prep *.
Eachslot consists of words with frequencies, whichcould provide broad-coverage selectional prefer-ences.Frames for a verb should be semantically distin-guished.
That is to say, each frame should consistof predicate-argument structures that have consis-tent usages or meanings.Our procedure to automatically generate seman-tic frames from verb usages is as follows:1. apply dependency parsing to a raw corpusand extract predicate-argument structures foreach verb from the automatic parses,2.
merge the predicate-argument structures thathave presumably the same meaning based onthe assumption of one sense per collocationto get a set of initial frames, and3.
apply clustering to the initial frames basedon the Chinese Restaurant Process to producethe final semantic frames.Each of these steps is described in the followingsections in detail.3.1 Extracting Predicate-argumentStructures from a Raw CorpusWe first apply dependency parsing to a large rawcorpus.
We use the Stanford parser with Stanforddependencies (de Marneffe et al., 2006).2Col-lapsed dependencies are adopted to directly extractprepositional phrases.Then, we extract predicate-argument structuresfrom the dependency parses.
Dependents that havethe following dependency relations to a verb areextracted as arguments:nsubj, xsubj, dobj, iobj, ccomp, xcomp,prep ?Here, we do not distinguish adjuncts from argu-ments.
All extracted dependents of a verb are han-dled as arguments.
This distinction is left for fu-ture work, but this will be performed using slot2http://nlp.stanford.edu/software/lex-parser.shtmlSentences:They observed the effects of ...This statistical ability to observe an effect ...We did not observe a residual effect of ...He could observe the results at the same time ...My first opportunity to observe the results of ...You can observe beautiful birds ...Children may then observe birds ......Predicate-argument structures:nsubj:they observe dobj:effectobserve dobj:effectnsubj:we observe dobj:effectnsubj:he observe dobj:result prep at:timeobserve dobj:resultnsubj:you observe dobj:birdnsubj:child observe dobj:bird...Initial frames:nsubj:{they, we, ...} observe dobj:{effect}nsubj:{he, ...} observe dobj:{result} prep at:{time}nsubj:{you, child, ...} observe dobj:{bird}...Figure 1: Examples of predicate-argument struc-tures and initial frames for the verb ?observe.
?frequencies in the applications of semantic framesor the method proposed by Abend and Rappoport(2010).We apply the following processes to extractedpredicate-argument structures:?
A verb and an argument are lemmatized, andonly the head of an argument is preserved forcompound nouns.?
Phrasal verbs are also distinguished fromnon-phrasal verbs.
For example, ?look up?has independent frames from ?look.??
The passive voice of a verb is distinguishedfrom the active voice, and thus these have in-dependent frames.
Passive voice is detectedusing the part-of-speech tag ?VBN?
(pastparticiple).
The alignment between frames ofactive and passive voices will be done afterthe induction of frames using the model ofSasano et al.
(2013) in the future.?
?xcomp?
(open clausal complement) is re-named to ?ccomp?
(clausal complement) and?xsubj?
(controlling subject) is renamed to?nsubj?
(nominal subject).
This is because60these usages as predicate-argument structuresare not different.?
A capitalized argument with the part-ofspeech ?NNP?
(singular proper noun) or?NNPS?
(plural proper noun) is general-ized to ?name?.
Similarly, an argument of?ccomp?
is generalized to ?comp?
since thecontent of a clausal complement is not impor-tant.Extracted predicate-argument structures arecollected for each verb and the subsequent pro-cesses are applied to the predicate-argument struc-tures of each verb.
Figure 1 shows examples ofpredicate-argument structures for ?observe.
?3.2 Constructing Initial Frames fromPredicate-argument StructuresA straightforward way to produce semantic framesis to cluster the extracted predicate-argumentstructures directly.
Since our objective is to com-pile broad-coverage semantic frames, a massiveamount of predicate-argument structures shouldbe fed into the clustering.
It would take prohibitivecomputational costs to conduct the sampling pro-cedure, which is described in the next section.To make the computation feasible, we merge thepredicate-argument structures that have the sameor similar meaning to get initial frames.
These ini-tial frames are the input of the subsequent cluster-ing process.
For this merge, we assume one senseper collocation (Yarowsky, 1993) for predicate-argument structures.For each predicate-argument structure of a verb,we couple the verb and an argument to make a unitfor sense disambiguation.
We select an argumentin the following order by considering the degree ofeffect on the verb sense:3dobj, ccomp, nsubj, prep ?, iobj.This selection of a predominant argument orderabove is justified by relative comparisons of thediscriminative power of the different slots for CPAframes (Popescu, 2013).
If a predicate-argumentstructure does not have any of the above slots, it isdiscarded.Then, the predicate-argument structures thathave the same verb and argument pair (slot and3If a predicate-argument structure has multiple preposi-tional phrases, one of them is randomly selected.word, e.g., ?dobj:effect?)
are merged into an ini-tial frame (Figure 1).
After this process, we dis-card minor initial frames that occur fewer than 10times.For example, we have 732,292 instances(predicate-argument structures) for the verb ?ob-serve?
in the web corpus that is used in our exper-iment (its details are described in Section 4.1).
Asthe result of this merging process, we obtain 6,530initial frames, which become an input for the clus-tering.
This means that this process accelerates thespeed of clustering more than 100 times.The precision of this process will be evaluatedin Section 4.3.3.3 Clustering using Chinese RestaurantProcessWe cluster initial frames for each verb to producefinal semantic frames using the Chinese Restau-rant Process (Aldous, 1985).
We regard each ini-tial frame as an instance in the usual clustering ofthe Chinese Restaurant Process.We calculate the posterior probability of a se-mantic frame fjgiven an initial frame vias fol-lows:P (fj|vi) ?{n(fj)N+??
P (vi|fj) fj?= new?N+??
P (vi|fj) fj= new,(1)where N is the number of initial frames for thetarget verb and n(fj) is the current number of ini-tial frames assigned to the semantic frame fj.
?is a hyper-parameter that determines how likelyit is for a new semantic frame to be created.
Inthis equation, the first term is the Dirichlet processprior and the second term is the likelihood of vi.P (vi|fj) is defined based on the Dirichlet-Multinomial distribution as follows:P (vi|fj) =?w?VP (w|fj)count(vi,w), (2)where V is the vocabulary in all case slots cooc-curring with the verb.
It is distinguished bythe case slot, and thus consists of pairs of slotsand words, e.g., ?nsubj:child?
and ?dobj:bird.
?count(vi, w) is the number of w in the initialframe vi.P (w|fj) is defined as follows:P (w|fj) =count(fj, w) + ?
?t?Vcount(fj, t) + |V | ?
?, (3)61where count(fj, w) is the current number of w inthe frame fj, and ?
is a hyper-parameter of Dirich-let distribution.
For a new semantic frame, thisprobability is uniform (1/|V |).We use Gibbs sampling to realize this cluster-ing.4 Experiments and Evaluations4.1 Experimental SettingsWe use two kinds of large-scale corpora: a webcorpus and the English Gigaword corpus.To prepare a web corpus, we first crawled theweb.
We extracted sentences from each webpage that seems to be written in English basedon the encoding information.
Then, we selectedsentences that consist of at most 40 words, andremoved duplicated sentences.
From this pro-cess, we obtained a corpus of one billion sen-tences, totaling approximately 20 billion words.We focused on verbs whose frequency was morethan 1,000.
There were 19,649 verbs, includ-ing phrasal verbs, and separating passive and ac-tive constructions.
We extracted 2,032,774,982predicate-argument structures.We also used the English Gigaword corpus(LDC2011T07; English Gigaword Fifth Edition)to induce semantic frames.
This corpus consistsof approximately 180 million sentences, which to-taling four billion words.
There were 7,356 verbsafter applying the same frequency threshold as theweb corpus.
We extracted 423,778,278 predicate-argument structures from this corpus.We set the hyper-parameters ?
in (1) and ?
in(3) to 1.0.
The frame assignments for all the com-ponents were initialized randomly.
We took 100samples for each initial frame and selected theframe assignment that has the highest probability.These parameters were determined according to apreliminary experiment to manually examine thequality of resulting frames.4.2 Experimental ResultsWe executed the per-verb clustering tasks on a PCcluster.
It finished within a few hours for mostverbs, but it took a couple of days for very frequentverbs, such as ?get?
and ?say.?
The clustering pro-duced an average number of semantic frames perverb of 15.2 for the web corpus and 18.5 for theGigaword corpus.
Examples of induced semanticframes from the web corpus are shown in Table 1.slot instancesnsubj i:5850, we:5201, he:3796, you:3669, ...dobj what:7091, people:2272, this:2262, ...observe:1prep in way:254, world:204, life:194, ......nsubj we:11135, you:1321, i:1317, ...dobj change:5091, difference:2719, ...observe:2prep in study:622, case:382, cell:362, ......nsubj student:3921, i:2240, we:2174, ...dobj child:2323, class:2184, student:2025, ...observe:3prep in classroom:555, action:509, ......nsubj we:44833, i:6873, order:4051, ...dobj card:28835, payment:22569, ...accept:1prep for payment:1166, convenience:1147, ......nsubj i:10568, we:9300, you:5106, ...dobj that:14180, this:12061, it:7756, ...accept:2prep as part:1879, fact:1085, truth:926, ......nsubj people:7459, he:6696, we:5515, ...dobj christ:13766, jesus:6528, it:5612, ...accept:3prep as savior:5591, lord:597, one:469, ......Table 1: Examples of resulting frames for the verb?observe?
and ?accept?
induced from the web cor-pus.
The number following an instance word rep-resents its frequency.4.3 Evaluation of Induced Semantic FramesWe evaluate precision and coverage of induced se-mantic frames.
To measure the precision of in-duced semantic frames, we adopt the purity met-ric, which is usually used to evaluate clustering re-sults.
However, the problem is that it is impossibleto assign gold-standard classes to the huge num-ber of instances.
To automatically measure thepurity of the induced semantic frames, we makeuse of the SemLink corpus (Loper et al., 2007), inwhich VerbNet classes (Kipper-Schuler, 2005) andPropBank/FrameNet frames are assigned to eachinstance.
We make a test set that contains 157 pol-ysemous verbs that occur 10 or more times in theSemLink corpus (sections 02-21 of the Wall StreetJournal).
We first add these instances to the in-stances from a raw corpus and apply clustering tothese merged instances.
Then, we compare the in-duced semantic frames of the SemLink instanceswith their gold-standard classes.
We adopt Verb-Net classes and PropBank frames as gold-standardclasses.For each group of verb-specific semanticframes, we measure the purity of the frames as thepercentage of SemLink instances belonging to themajority gold class in their respective cluster.
Let62PU CO F1Mac Mic Mac Mic Mac Micagainst One frame 0.799 0.802 0.917 0.952 0.854 0.870VerbNet Initial frames 0.985 0.982 0.755 0.812 0.855 0.889Induced sem frames 0.900 0.901 0.886 0.928 0.893 0.914against One frame 0.901 0.872 ?
?
0.909 0.910PropBank Initial frames 0.994 0.993 ?
?
0.858 0.893Induced sem frames 0.965 0.949 ?
?
0.924 0.939Table 2: Evaluation results of semantic frames from the web corpus against VerbNet classes and Prop-Bank frames.
?Mac?
means a macro average and ?Mic?
means a micro average.PU CO F1Mac Mic Mac Mic Mac Micagainst One frame 0.799 0.804 0.855 0.920 0.826 0.858VerbNet Initial frames 0.985 0.981 0.666 0.758 0.795 0.855Induced sem frames 0.916 0.909 0.796 0.880 0.852 0.894against One frame 0.901 0.874 ?
?
0.877 0.896PropBank Initial frames 0.994 0.993 ?
?
0.798 0.859Induced sem frames 0.968 0.953 ?
?
0.874 0.915Table 3: Evaluation results of semantic frames from the Gigaword corpus against VerbNet classes andPropBank frames.
?Mac?
means a macro average and ?Mic?
means a micro average.N denote the total number of SemLink instancesof the target verb, Gjthe set of instances belong-ing to the j-th gold class and Fithe set of instancesbelonging to the i-th frame.
The purity (PU) canthen be written as follows:PU =1N?imaxj|Gj?
Fi|.
(4)For example, a frame of the verb ?observe?
con-tains 11 SemLink instances, and eight out of thembelong to the class SAY-37.7, which is the ma-jority class among these 11 instances.
PU is cal-culated by summing up such counts over all theframes of this verb.Usually, inverse purity or collocation is usedto measure the recall of normal clustering tasks.However, these recall measures do not fit our task.This is because it is not a real error to have similarseparate frames.
Instead, we want to avoid hav-ing so many frames that we cannot provide broad-coverage selectional preferences due to sparsity.To judge this aspect, we measure coverage.The coverage (CO) measures to what extentpredicate-argument structures of the target verb ina test set are included in one of frames of the verb.We use the predicate-argument structures of theabove 157 verbs from the SemLink corpus, whichare the same ones used in the evaluation of PU.We judge a predicate-argument structure as cor-rect if all of its argument words (of the target slotdescribed in Section 3.1) are included in the corre-sponding slot of a frame.
If the clustering gets bet-ter, the value of CO will get higher, because merg-ing instances by clustering alleviates data sparsity.These per-verb scores are aggregated into anoverall score by averaging over all verbs.
We usetwo ways of averaging: a macro average and a mi-cro average.
The macro average is a simple av-erage of scores for individual verbs.
The microaverage is obtained by weighting the scores for in-dividual verbs proportional to the number of in-stances for that verb.
Finally, we use the harmonicmean (F1) of purity and coverage as a single mea-sure of clustering quality.For comparison, we adopt the following twobaseline methods:One frame a frame into which all the instancesfor a verb are mergedInitial frames the initial frames without cluster-ing (described in Section 3.2)Table 2 and Table 3 list evaluation results forsemantic frames induced from the web corpus andthe Gigaword corpus, respectively.4Note that COdoes not consider gold-standard classes, and thusthe values of CO are the same for the VerbNet4We did not adopt inverse purity, but its values for theinduced semantic frames range from 0.42 to 0.49.63and PropBank evaluations.
The induced framesoutperformed the two baseline methods in termsof F1in most cases.
While the coverage of theweb frames was higher than that of the Giga-word frames, as expected, the purity of the webframes was slightly lower than that of the Giga-word frames.
This degradation might be causedby the noise in the web corpus.The purity of the initial frames was around98%-99%, which means that there were few casesthat the one-sense-per-collocation assumption wasviolated.Modi et al.
(2012) reported a purity of 77.9%for the assignment of FrameNet frames to theFrameNet corpus.
We also conducted the abovepurity evaluation against FrameNet frames for 140verbs.5We obtained a macro average of 92.9%and a micro average of 89.2% for the web frames,and a macro average of 93.2% and a micro averageof 89.8% for the Gigaword frames.
It is difficultto directly compare these results with Modi et al.
(2012), but our frame assignments seem to havehigher accuracy.4.4 Evaluation against CPA FramesCorpus Pattern Analysis (CPA) is a technique forlinking word usage to prototypical syntagmaticpatterns.6The resource was built manually by in-vestigating examples in the BNC, and the set ofcorpus examples used to induce each pattern isgiven.
For example, the following three patternsdescribe the usage of the verb ?accommodate.?
[Human 1] accommodate [Human 2][Building] accommodate [Eventuality][Human] accommodate [Self] to [Eventuality]In this paper, we use CPA to evaluate the qualityof the automatically induced frames.
By compar-ing the induced frames to CPA patterns, we canevaluate the correctness and relevance of this ap-proach from a human point of view.
To do that,we associate semantic features to the set of wordsin each slot in the frames, using SUMO (Nilesand Pease, 2001).
For example, take the follow-ing frame for the verb ?accomplish?
:accomplish:1nsubj:{you, leader, employee, ...}dobj:{developing, progress, objective, ...}.5Since FrameNet frames are not assigned to all the verbsof SemLink, the number of verbs is different from the evalu-ations against VerbNet and PropBank.6http://deb.fi.muni.cz/pdev/all K-meansEntropy (E) 0.790 0.516Recovery Rate (RC) 0.347 0.630Purity (P ) 0.462 0.696Table 4: CPA Evaluation.Using SUMO, we map this frame to the following:nsubj: [Human]dobj: [SubjectiveAssessmentAttribute],which corresponds to pattern 3 for ?accomplish?in CPA.We also associate SUMO attributes to the CPApatterns with more than 10 examples (716 verbs).There are many patterns of SUMO attributes forany CPA frame or induced frame, since eachfiller word in a particular slot can have morethan one SUMO attribute.
We filter out thenon-discriminative SUMO attributes following thetechnique described in Popescu (2013).
Usingthis, we obtain SUMO attributes for both CPAclusters and induced frames, and we can use thestandard entropy-based measures to evaluate thematch between the two types of patterns: E ?
en-tropy, RC ?
recovery rate, and P ?
purity (Li etal., 2004):E =K?j=1mjm?
ej, RC = 1 ?K,L?j,i=1pijmi, (5)P =K?j=1mjm?
pj, pj= maxipij, (6)ej=L?i=1pijlog2pij, pij=mijmi, (7)where mjis the number of induced frames corre-sponding to topic j, mijis the number of inducedframes in cluster j and annotated with the CPApattern i, m is the total number of induced frames,L is the number of CPA patterns, and K is thenumber of induced frames.We also consider a K-means clustering process,with K set as 2 or 3 depending on the number ofSUMO-attributed patterns.
The K-means evalu-ation is carried out considering only the centroidof the cluster, which corresponds to the prototypi-cal induced semantic frame with SUMO attributes.We compute E, RC and P using formulae (5) -(7) for each verb and then compute the macro av-erage, considering all the frames and only the K-means centroids, respectively.
The results for theinduced web frames are displayed in Table 4.64The evaluation method presented here over-comes some of the drawbacks of the previous ap-proaches (Materna, 2012; Materna, 2013).
First,we did not limit the evaluation to the most frequentpatterns.
Second, the mapping was carried out au-tomatically and not by hand.
The results abovecompare favorably with the previous approaches,especially considering that no filtering procedureswere applied to the induced frames.
We anticipatethat the results based on the prototypical inducedframes with SUMO attributes would be competi-tive.
Our post-analysis revealed that the entropycan be lowered further if an automatic filteringbased on frequencies is applied.4.5 Evaluation of the Quality of SelectionalPreferencesWe also investigated the quality of selectionalpreferences within the induced semantic frames.The only publicly available test data for selectionalpreferences, to our knowledge, is from Chambersand Jurafsky (2010).
This data consists of quadru-ples (verb, relation, word, confounder) and doesnot contain their context.7A typical way for using our semantic frames isto select an appropriate frame for an input sen-tence and judge the eligibility of the word usesagainst the selected frame.
However, due to thelack of context for the above data, it is difficult toselect a corresponding semantic frame for a testquadruple and thus the induced semantic framescannot be naturally applied to this data.
To in-vestigate the potential for selectional preferencesof the semantic frames, we approximately matcha quadruple with each of the semantic frames ofthe verb and select the frame that has the highestprobability as follows:P (w) = maxiP (w|v, rel, fi), (8)where w is the word or confounder, v is the verb,rel is the relation and fiis a semantic frame.
Bycomparing the probabilities of the word and theconfounder, we select either of them according tothe higher probability.
For tie breaking in the casethat no frames are found for the verb or both theword and confounder are not found in the case slot,we randomly select either of them in the same wayas Chambers and Jurafsky (2010).We use the ?neighbor frequency?
set, which isthe most difficult among the three sets included7A document ID of the English Gigaword corpus is avail-able, but it is difficult to recover the context of each instancefrom this information.in the data.
It contains 6,767 quadruples and therelations consist of three classes: subject, objectand preposition, which has no distinction of ac-tual prepositions.
To link these relations with ourcase slots, we manually aligned the subject withthe nsubj (nominal subject) slot, the object withthe dobj (direct object) slot and the prepositionwith prep * (all the prepositions) slots.
For thepreposition relation, we choose the highest prob-ability among all the preposition slots in a frame.To match the generalized ?name?
with the word ina quadruple, we change the word to ?name?
if it iscapitalized and not a capitalized personal pronoun.Our semantic frames from the Gigaword corpusachieved an accuracy of 81.7%8and those fromthe web corpus achieved an accuracy of 80.2%.This slight deterioration seems to come from thenoise in the web corpus.
The best performancein Chambers and Jurafsky (2010) is 81.7% onthis ?neighbor frequency?
set, which was achievedby conditional probabilities with the Erk (2007)?ssmoothing method calculated from the English Gi-gaword corpus.
Our approach for selectional pref-erences does not use smoothing like Erk (2007),but it achieved equivalent performance to the pre-vious work.
If we applied our semantic frames to averb instance with its context, a more precise judg-ment of selectional preferences would be possiblewith appropriate frame selection.5 ConclusionThis paper has described an unsupervised methodfor inducing semantic frames from instances ofeach verb in giga-word corpora.
This method isclustering based on the Chinese Restaurant Pro-cess.
The resulting frame data are open to the pub-lic and also can be searched by inputting a verb viaour web interface.9As applications of the resulting frames, we planto integrate them into syntactic parsing, semanticrole labeling and verb sense disambiguation.
Forinstance, Kawahara and Kurohashi (2006b) im-proved accuracy of dependency parsing based onJapanese semantic frames automatically inducedfrom a large raw corpus.
It is valuable and promis-ing to apply our semantic frames to these NLPtasks.8Since the dataset was created from the NYT 2001 portionof the English Gigaword Corpus, we built semantic framesagain from the Gigaword corpus except this part.9http://nlp.ist.i.kyoto-u.ac.jp/member/kawahara/cf/crp.en/65AcknowledgmentsThis work was supported by Kyoto UniversityJohn Mung Program and JST CREST.
We grate-fully acknowledge the support of the National Sci-ence Foundation Grant NSF 1116782 - RI: Small:A Bayesian Approach to Dynamic Lexical Re-sources for Flexible Language Processing.
Anyopinions, findings, and conclusions or recommen-dations expressed in this material are those of theauthors and do not necessarily reflect the views ofthe National Science Foundation.ReferencesOmri Abend and Ari Rappoport.
2010.
Fully unsuper-vised core-adjunct argument classification.
In Pro-ceedings of the 48th Annual Meeting of the Associa-tion for Computational Linguistics, pages 226?236.David Aldous.
1985.
Exchangeability and related top-ics.
?Ecole d?
?Et?e de Probabilit?es de Saint-Flour XIII?1983, pages 1?198.Collin Baker, Charles J. Fillmore, and John Lowe.1998.
The Berkeley FrameNet Project.
In Pro-ceedings of the 36th Annual Meeting of the Associ-ation for Computational Linguistics and 17th Inter-national Conference on Computational Linguistics,pages 86?90.Hans C. Boas.
2002.
Bilingual framenet dictionariesfor machine translation.
In Proceedings of the 3rdInternational Conference on Language Resourcesand Evaluation, pages 1364?1371.Ted Briscoe and John Carroll.
1997.
Automatic ex-traction of subcategorization from corpora.
In Pro-ceedings of the 5th Conference on Applied NaturalLanguage Processing, pages 356?363.Aljoscha Burchardt and Anette Frank.
2006.
Approx-imating textual entailment with LFG and FrameNetframes.
In Proceedings of the 2nd PASCAL Recog-nizing Textual Entailment Workshop, pages 92?97.Nathanael Chambers and Daniel Jurafsky.
2010.
Im-proving the use of pseudo-words for evaluating se-lectional preferences.
In Proceedings of the 48thAnnual Meeting of the Association for Computa-tional Linguistics, pages 445?453.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of the 5th International Conference onLanguage Resources and Evaluation, pages 449?454.Michael Ellsworth and Adam Janin.
2007.
Mu-taphrase: Paraphrasing with framenet.
In Proceed-ings of the ACL-PASCAL Workshop on Textual En-tailment and Paraphrasing, pages 143?150.Katrin Erk.
2007.
A simple, similarity-based modelfor selectional preferences.
In Proceedings of the45th Annual Meeting of the Association of Compu-tational Linguistics, pages 216?223.Ingrid Falk, Claire Gardent, and Jean-Charles Lamirel.2012.
Classifying french verbs using french and en-glish lexical resources.
In Proceedings of the 50thAnnual Meeting of the Association for Computa-tional Linguistics, pages 854?863.Trond Grenager and Christopher D. Manning.
2006.Unsupervised discovery of a statistical verb lexicon.In Proceedings of the 2006 Conference on EmpiricalMethods in Natural Language Processing, pages 1?8.Patrick Hanks.
2012.
How people use words to makemeanings: Semantic types meet valencies.
Input,Process and Product: Developments in Teachingand Language Corpora, pages 54?69.Daisuke Kawahara and Sadao Kurohashi.
2006a.Case frame compilation from the web using high-performance computing.
In Proceedings of the 5thInternational Conference on Language Resourcesand Evaluation, pages 1344?1347.Daisuke Kawahara and Sadao Kurohashi.
2006b.
Afully-lexicalized probabilistic model for Japanesesyntactic and case structure analysis.
In Proceedingsof the Human Language Technology Conference ofthe NAACL, pages 176?183.Karin Kipper-Schuler.
2005.
VerbNet: A Broad-Coverage, Comprehensive Verb Lexicon.
Ph.D. the-sis, University of Pennsylvania.Anna Korhonen, Yuval Krymolowski, and Ted Briscoe.2006.
A large subcategorization lexicon for naturallanguage processing applications.
In Proceedings ofthe 5th International Conference on Language Re-sources and Evaluation, pages 345?352.Joel Lang and Mirella Lapata.
2010.
Unsuper-vised induction of semantic roles.
In Human Lan-guage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 939?947.Joel Lang and Mirella Lapata.
2011a.
Unsupervisedsemantic role induction via split-merge clustering.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 1117?1126.Joel Lang and Mirella Lapata.
2011b.
Unsupervisedsemantic role induction with graph partitioning.
InProceedings of the 2011 Conference on EmpiricalMethods in Natural Language Processing, pages1320?1331.Tao Li, Sheng Ma, and Mitsunori Ogihara.
2004.Entropy-based criterion in categorical clustering.
InProceedings of the 21st International Conference onMachine Learning, volume 4, pages 536?543.66Thomas Lippincott, Anna Korhonen, and Diarmuid?O S?eaghdha.
2012.
Learning syntactic verb framesusing graphical models.
In Proceedings of the 50thAnnual Meeting of the Association for Computa-tional Linguistics, pages 420?429.Edward Loper, Szu-Ting Yi, and Martha Palmer.
2007.Combining lexical resources: mapping betweenPropBank and VerbNet.
In Proceedings of the 7thInternational Workshop on Computational Linguis-tics.Christopher Manning.
1993.
Automatic acquisitionof a large subcategorization dictionary from corpora.In Proceedings of the 31st Annual Meeting of the As-sociation for Computational Linguistics, pages 235?242.Ji?r??
Materna.
2012.
LDA-Frames: An unsupervisedapproach to generating semantic frames.
In Alexan-der Gelbukh, editor, Proceedings of the 13th Inter-national Conference CICLing 2012, Part I, volume7181 of Lecture Notes in Computer Science, pages376?387.
Springer Berlin / Heidelberg.Ji?r??
Materna.
2013.
Parameter estimation for LDA-Frames.
In Proceedings of the 2013 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, pages 482?486.Ashutosh Modi, Ivan Titov, and Alexandre Klementiev.2012.
Unsupervised induction of frame-semanticrepresentations.
In Proceedings of the NAACL-HLTWorkshop on the Induction of Linguistic Structure,pages 1?7.Srini Narayanan and Sanda Harabagiu.
2004.
Ques-tion answering based on semantic structures.
InProceedings of the 20th International Conference onComputational Linguistics, pages 693?701.Ian Niles and Adam Pease.
2001.
Towards a standardupper ontology.
In Proceedings of the InternationalConference on Formal Ontology in Information Sys-tems, pages 2?9.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31(1):71?106.Christopher Parisien and Suzanne Stevenson.
2009.Modelling the acquisition of verb polysemy in chil-dren.
In Proceedings of the CogSci2009 Workshopon Distributional Semantics beyond Concrete Con-cepts, pages 17?22.Christopher Parisien and Suzanne Stevenson.
2010.Learning verb alternations in a usage-basedBayesian model.
In Proceedings of the 32nd annualmeeting of the Cognitive Science Society.Hoifung Poon and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing, pages 1?10.Octavian Popescu.
2013.
Learning corpus patterns us-ing finite state automata.
In Proceedings of the 10thInternational Conference on Computational Seman-tics, pages 191?203.Roi Reichart and Anna Korhonen.
2013.
Improvedlexical acquisition through DPP-based verb cluster-ing.
In Proceedings of the 51st Annual Meetingof the Association for Computational Linguistics,pages 862?872.Ryohei Sasano, Daisuke Kawahara, Sadao Kurohashi,and Manabu Okumura.
2013.
Automatic knowl-edge acquisition for case alternation between thepassive and active voices in Japanese.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, pages 1213?1223.Lin Sun and Anna Korhonen.
2009.
Improving verbclustering with automatically acquired selectionalpreferences.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 638?647.Mihai Surdeanu, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using predicate-argumentstructures for information extraction.
In Proceed-ings of the 41st Annual Meeting of the Associationfor Computational Linguistics, pages 8?15.Ivan Titov and Alexandre Klementiev.
2011.
ABayesian model for unsupervised semantic parsing.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 1445?1455.Ivan Titov and Alexandre Klementiev.
2012.
ABayesian approach to unsupervised semantic role in-duction.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 12?22.Andreas Vlachos, Anna Korhonen, and ZoubinGhahramani.
2009.
Unsupervised and constraineddirichlet process mixture models for verb cluster-ing.
In Proceedings of the Workshop on Geomet-rical Models of Natural Language Semantics, pages74?82.David Yarowsky.
1993.
One sense per collocation.
InProceedings of the Workshop on Human LanguageTechnology, pages 266?271.67
