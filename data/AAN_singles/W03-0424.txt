Language Independent NER using a Maximum Entropy TaggerJames R. Curran and Stephen ClarkSchool of InformaticsUniversity of Edinburgh2 Buccleuch Place, Edinburgh.
EH8 9LW{jamesc,stephenc}@cogsci.ed.ac.ukAbstractNamed Entity Recognition (NER) systems needto integrate a wide variety of information foroptimal performance.
This paper demonstratesthat a maximum entropy tagger can effectivelyencode such information and identify namedentities with very high accuracy.
The taggeruses features which can be obtained for a vari-ety of languages and works effectively not onlyfor English, but also for other languages suchas German and Dutch.1 IntroductionNamed Entity Recognition1 (NER) can be treated as atagging problem where each word in a sentence is as-signed a label indicating whether it is part of a namedentity and the entity type.
Thus methods used for partof speech (POS) tagging and chunking can also be usedfor NER.
The papers from the CoNLL-2002 sharedtask which used such methods (e.g.
Malouf (2002),Burger et al (2002)) reported results significantly lowerthan the best system (Carreras et al, 2002).
However,Zhou and Su (2002) have reported state of the art resultson the MUC-6 and MUC-7 data using a HMM-based tagger.Zhou and Su (2002) used a wide variety of features,which suggests that the relatively poor performance of thetaggers used in CoNLL-2002 was largely due to the fea-ture sets used rather than the machine learning method.We demonstrate this to be the case by improving on thebest Dutch results from CoNLL-2002 using a maximumentropy (ME) tagger.
We report reasonable precision andrecall (84.9 F-score) for the CoNLL-2003 English testdata, and an F-score of 68.4 for the CoNLL-2003 Ger-man test data.1We assume that NER involves assigning the correct label toan entity as well as identifying its boundaries.Incorporating a diverse set of overlapping featuresin a HMM-based tagger is difficult and complicates thesmoothing typically used for such taggers.
In contrast, aME tagger can easily deal with diverse, overlapping fea-tures.
We also use a Gaussian prior on the parameters foreffective smoothing over the large feature space.2 The ME TaggerThe ME tagger is based on Ratnaparkhi (1996)?s POS tag-ger and is described in Curran and Clark (2003) .
Thetagger uses models of the form:p(y|x) =1Z(x)exp(n?i=1?ifi(x, y))(1)where y is the tag, x is the context and the fi(x, y) arethe features with associated weights ?i.
The probabilityof a tag sequence y1 .
.
.
yn given a sentence w1 .
.
.
wn isapproximated as follows:p(y1 .
.
.
yn|w1 .
.
.
wn) ?n?i=1p(yi|xi) (2)where xi is the context for word wi.
The tagger usesbeam search to find the most probable sequence given thesentence.The features are binary valued functions which pair atag with various elements of the context; for example:fj(x, y) ={1 if word(x) = Moody & y = I-PER0 otherwise(3)word(x) = Moody is an example of a contextual predi-cate.Generalised Iterative Scaling (GIS) is used to estimatethe values of the weights.
The tagger uses a Gaussianprior over the weights (Chen et al, 1999) which allows alarge number of rare, but informative, features to be usedwithout overfitting.Condition Contextual predicatefreq(wi) < 5 X is prefix of wi, |X| ?
4X is suffix of wi, |X| ?
4wi contains a digitwi contains uppercase characterwi contains a hyphen?wi wi = Xwi?1 = X , wi?2 = Xwi+1 = X , wi+2 = X?wi POSi = XPOSi?1 = X , POSi?2 = XPOSi+1 = X , POSi+2 = X?wi NEi?1 = XNEi?2NEi?1 = XYTable 1: Contextual predicates in baseline system3 The DataWe used three data sets: the English and German datafor the CoNLL-2003 shared task (Tjong Kim Sang andDe Meulder, 2003) and the Dutch data for the CoNLL-2002 shared task (Tjong Kim Sang, 2002).
Each word inthe data sets is annotated with a named entity tag plus POStag, and the words in the German and English data alsohave a chunk tag.
Our system does not currently exploitthe chunk tags.There are 4 types of entities to be recognised: persons,locations, organisations, and miscellaneous entities notbelonging to the other three classes.
The 2002 data usesthe IOB-2 format in which a B-XXX tag indicates the firstword of an entity of type XXX and I-XXX is used for sub-sequent words in an entity of type XXX.
The tag O in-dicates words outside of a named entity.
The 2003 datauses a variant of IOB-2, IOB-1, in which I-XXX is usedfor all words in an entity, including the first word, unlessthe first word separates contiguous entities of the sametype, in which case B-XXX is used.4 The Feature SetTable 1 lists the contextual predicates used in our base-line system, which are based on those used in theCurran and Clark (2003) CCG supertagger.
The first setof features apply to rare words, i.e.
those which appearless than 5 times in the training data.
The first two kindsof features encode prefixes and suffixes less than length 5,and the remaining rare word features encode other mor-phological characteristics.
These features are importantfor tagging unknown and rare words.
The remaining fea-tures are the word, POS tag, and NE tag history features,using a window size of 2.
Note that the NEi?2NEi?1feature is a composite feature of both the previous andprevious-previous NE tags.Condition Contextual predicatefreq(wi) < 5 wi contains periodwi contains punctuationwi is only digitswi is a numberwi is {upper,lower,title,mixed} casewi is alphanumericlength of wiwi has only Roman numeralswi is an initial (X.
)wi is an acronym (ABC, A.B.C.
)?wi memory NE tag for wiunigram tag of wi+1unigram tag of wi+2?wi wi in a gazetteerwi?1 in a gazetteerwi+1 in a gazetteer?wi wi not lowercase and flc > fuc?wi unigrams of word typebigrams of word typestrigrams of word typesTable 2: Contextual predicates in final systemTable 2 lists the extra features used in our finalsystem.
These features have been shown to be use-ful in other NER systems.
The additional ortho-graphic features have proved useful in other systems,for example Carreras et al (2002), Borthwick (1999) andZhou and Su (2002).
Some of the rows in Table 2 de-scribe sets of contextual predicates.
The wi is only digitspredicates apply to words consisting of all digits.
Theyencode the length of the digit string with separate pred-icates for lengths 1?4 and a single predicate for lengthsgreater than 4.
Titlecase applies to words with an ini-tial uppercase letter followed by all lowercase (e.g.
Mr).Mixedcase applies to words with mixed lower- and up-percase (e.g.
CityBank).
The length predicates encodethe number of characters in the word from 1 to 15, with asingle predicate for lengths greater than 15.The next set of contextual predicates encode extra in-formation about NE tags in the current context.
Thememory NE tag predicate (see e.g.
Malouf (2002))records the NE tag that was most recently assigned tothe current word.
The use of beam-search taggingmeans that tags can only be recorded from previoussentences.
This memory is cleared at the beginningof each document.
The unigram predicates (see e.g.Tsukamoto et al (2002)) encode the most probable tagfor the next words in the window.
The unigram probabil-ities are relative frequencies obtained from the trainingdata.
This feature enables us to know something aboutthe likely NE tag of the next word before reaching it.Most systems use gazetteers to encode informationabout personal and organisation names, locations andtrigger words.
There is considerable variation in the sizeof the gazetteers used.
Some studies found that gazetteersdid not improve performance (e.g.
Malouf (2002)) whilstothers gained significant improvement using gazetteersand triggers (e.g.
Carreras et al (2002)).
Our system in-corporates only English and Dutch first name and lastname gazetteers as shown in Table 6.
These gazetteersare used for predicates applied to the current, previousand next word in the window.Collins (2002) includes a number of interesting con-textual predicates for NER.
One feature we have adaptedencodes whether the current word is more frequently seenlowercase than uppercase in a large external corpus.
Thisfeature is useful for disambiguating beginning of sen-tence capitalisation and tagging sentences which are allcapitalised.
The frequency counts have been obtainedfrom 1 billion words of English newspaper text collectedby Curran and Osborne (2002).Collins (2002) also describes a mapping from words toword types which groups words with similar orthographicforms into classes.
This involves mapping characters toclasses and merging adjacent characters of the same type.For example, Moody becomes Aa, A.B.C.
becomesA.A.A.
and 1,345.05 becomes 0,0.0.
The classesare used to define unigram, bigram and trigram contex-tual predicates over the window.We have also defined additional composite featureswhich are a combination of atomic features; for exam-ple, a feature which is active for mid-sentence titlecasewords seen more frequently as lowercase than uppercasein a large external corpus.5 ResultsThe baseline development results for English using thesupertagger features only are given in Table 3.
The fullsystem results for the English development data are givenin Table 7.
Clearly the additional features have a signifi-cant impact on both precision and recall scores across allentities.
We have found that the word type features areparticularly useful, as is the memory feature.
The perfor-mance of the final system drops by 1.97% if these fea-tures are removed.
The performance of the system if thegazetteer features are removed is given in Table 4.
Thesizes of our gazetteers are given in Table 6.
We haveexperimented with removing the other contextual pred-icates but each time performance was reduced, except forthe next-next unigram tag feature which was switched offfor all final experiments.The results for the Dutch test data are given in Table 5.These improve upon the scores of the best performingsystem at CoNLL-2002 (Carreras et al, 2002).English DEV PRECISION RECALL F?=1LOCATION 90.78% 90.58% 90.68MISC 85.80% 81.24% 83.45ORGANISATION 82.24% 80.09% 81.15PERSON 92.02% 92.67% 92.35OVERALL 88.53% 87.41% 87.97Table 3: Baseline C&C results for English DEV dataEnglish DEV PRECISION RECALL F?=1LOCATION 91.69% 93.14% 92.41MISC 88.15% 83.08% 85.54ORGANISATION 83.48% 85.53% 84.49PERSON 94.40% 95.11% 94.75OVERALL 90.13% 90.47% 90.30Table 4: No external resources results for Eng.
DEV dataDutch TEST PRECISION RECALL F?=1LOCATION 84.42% 81.91% 83.15MISC 78.46% 74.89% 76.64ORGANISATION 77.35% 68.93% 72.90PERSON 80.13% 90.71% 85.09OVERALL 79.91% 79.35% 79.63Table 5: Results for the Dutch TEST dataGazetteer ENTRIESFIRST NAME 6,673LAST NAME 89,836freqLC > freqUC LIST 778,791Table 6: Size of GazetteersThe final results for the English test data are given inTable 7.
These are significantly lower than the results forthe development data.
The results for the German devel-opment and test sets are given in Table 7.
For the GermanNER we removed the lowercase more frequent than up-percase feature.
Apart from this change, the system wasidentical.
We did not add any extra gazetteer informationfor German.6 ConclusionOur NER system demonstrates that using a large varietyof features produces good performance.
These featurescan be defined and extracted in a language independentmanner, as our results for German, Dutch and Englishshow.
Maximum entropy models are an effective wayof incorporating diverse and overlapping features.
Ourmaximum entropy tagger employs Gaussian smoothingwhich allows a large number of sparse, but informative,features to be used without overfitting.Using a wider context window than 2 words may im-prove performance; a reranking phase using global fea-tures may also improve performance (Collins, 2002).AcknowledgementsWe would like to thank Jochen Leidner for help collectingthe Gazetteers.
This research was supported by a Com-monwealth scholarship and a Sydney University Trav-elling scholarship to the first author, and EPSRC grantGR/M96889.ReferencesAndrew Borthwick.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
Ph.D. thesis,New York University.John D. Burger, John C. Henderson, and William T. Mor-gan.
2002.
Statistical Named Entity Recogizer Adap-tation.
In Proceedings of the 2002 CoNLL Workshop,pages 163?166, Taipei, Taiwan.Xavier Carreras, Lluis Ma`rquez, and Lluis Padro?.
2002.Named Entity Recognition using AdaBoost.
In Pro-ceedings of the 2002 CoNLL Workshop, pages 167?170, Taipei, Taiwan.John Chen, Srinivas Bangalore, and K. Vijay-Shanker.1999.
New Models for Improving Supertag Disam-biguation.
In Proceedings of the 9th Meeting of EACL,Bergen, Norway.Michael Collins.
2002.
Ranking Algorithms for Named-Entity Extraction: Boosting and the Voted Perceptron.In Proceedings of the 40th Meeting of the ACL, pages489?496, Philadelphia, PA.James R. Curran and Stephen Clark.
2003.
InvestigatingGIS and Smoothing for Maximum Entropy Taggers.In Proceedings of the 11th Meeting of the EuropeanChapter of the ACL, Budapest, Hungary.James R. Curran and Miles Osborne.
2002.
A very verylarge corpus doesn?t always yield reliable estimates.
InProceedings of the 2002 CoNLL Workshop, pages 126?131, Taipei, Taiwan.Robert Malouf.
2002.
Markov models for language-independent named entity recognition.
In Proceedingsof the 2002 CoNLL Workshop, pages 187?190, Taipei,Taiwan.Adwait Ratnaparkhi.
1996.
A Maximum Entropy Part-Of-Speech Tagger.
In Proceedings of the EMNLPConference, pages 133?142, Philadelphia, PA.English devel.
Precision Recall F?=1LOC 91.75% 93.20% 92.47MISC 88.34% 82.97% 85.57ORG 83.54% 85.53% 84.52PER 94.26% 95.39% 94.82Overall 90.15% 90.56% 90.35English test Precision Recall F?=1LOC 84.97% 90.53% 87.66MISC 76.77% 75.78% 76.27ORG 79.60% 79.41% 79.51PER 91.64% 90.79% 91.21Overall 84.29% 85.50% 84.89German devel.
Precision Recall F?=1LOC 67.59% 70.11% 68.83MISC 71.87% 48.81% 58.14ORG 71.85% 50.60% 59.39PER 81.69% 64.03% 71.79Overall 73.29% 58.89% 65.31German test Precision Recall F?=1LOC 70.91% 71.11% 71.01MISC 68.51% 46.12% 55.13ORG 68.43% 50.19% 57.91PER 88.04% 72.05% 79.25Overall 75.61% 62.46% 68.41Table 7: Full system results for the English and Germandevelopment and test data sets.Erik F. Tjong Kim Sang and Fien De Meulder.2003.
Introduction to the CoNLL-2003 Shared Task:Language-Independent Named Entity Recognition.
InWalter Daelemans and Miles Osborne, editors, Pro-ceedings of CoNLL-2003, Edmonton, Canada.Erik F. Tjong Kim Sang.
2002.
Introduction to theCoNLL-2002 Shared Task: Language-IndependentNamed Entity Recognition.
In Proceedings of CoNLL-2002, Taipei, Taiwan.Koji Tsukamoto, Yutaka Mitsuishi, and Manabu Sassano.2002.
Learning with Multiple Stacking for Named En-tity Recognition.
In Proceedings of the 2002 CoNLLWorkshop, pages 191?194, Taipei, Taiwan.GuoDong Zhou and Jian Su.
2002.
Named EntityRecognition using an HMM-based Chunk Tagger.
InProceedings of the 40th Annual Meeting of the ACL,pages 473?480, Philadelphia, PA.
