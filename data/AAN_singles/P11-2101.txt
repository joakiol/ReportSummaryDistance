Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 575?580,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsIdentifying Noun Product Features that Imply OpinionsLei Zhang Bing LiuUniversity of Illinois at Chicago University of Illinois at Chicago851 South Morgan Street 851 South Morgan StreetChicago, IL 60607, USA Chicago, IL 60607, USAlzhang3@cs.uic.edu liub@cs.uic.eduAbstractIdentifying domain-dependent opinionwords is a key problem in opinion miningand has been studied by several researchers.However, existing work has been focusedon adjectives and to some extent verbs.Limited work has been done on nouns andnoun phrases.
In our work, we used thefeature-based opinion mining model, and wefound that in some domains nouns and nounphrases that indicate product features mayalso imply opinions.
In many such cases,these nouns are not subjective but objective.Their involved sentences are also objectivesentences and imply positive or negativeopinions.
Identifying such nouns and nounphrases and their polarities is verychallenging but critical for effective opinionmining in these domains.
To the best of ourknowledge, this problem has not beenstudied in the literature.
This paper proposesa method to deal with the problem.Experimental results based on real-lifedatasets show promising results.1 IntroductionOpinion words are words that convey positive ornegative polarities.
They are critical for opinionmining (Pang et al, 2002; Turney, 2002; Hu andLiu, 2004; Wilson et al, 2004; Popescu andEtzioni, 2005; Gamon et al, 2005; Ku et al, 2006;Breck et al, 2007; Kobayashi et al, 2007; Ding etal., 2008; Titov and McDonald, 2008; Pang andLee, 2008; Lu et al, 2009).
The key difficulty infinding such words is that opinions expressed bymany of them are domain or context dependent.Several researchers have studied the problem offinding opinion words (Liu, 2010).
The approachescan be grouped into corpus-based approaches(Hatzivassiloglou and McKeown, 1997; Wiebe,2000; Kanayama and Nasukawa, 2006; Qiu et al,2009) and dictionary-based approaches (Hu andLiu 2004; Kim and Hovy, 2004; Kamps et al,2004; Esuli and Sebastiani, 2005; Takamura et al,2005; Andreevskaia and Bergler, 2006; Dragut etal., 2010).
Dictionary-based approaches aregenerally not suitable for finding domain specificopinion words as dictionaries contain little domainspecific information.Hatzivassiloglou and McKeown (1997) did thefirst work to tackle the problem for adjectivesusing a corpus.
The approach exploits someconjunctive patterns, involving and, or, but, either-or, or neither-nor, with the intuition that theconjoining adjectives subject to linguisticconstraints on the orientation or polarity of theadjectives involved.
Using these constraints, onecan infer opinion polarities of unknown adjectivesbased on the known ones.
Kanayama andNasukawa (2006) improved this work by using theidea of coherency.
They deal with both adjectivesand verbs.
Ding et al (2008) introduced theconcept of feature context because the polarities ofmany opinion bearing words are sentence contextdependent rather than just domain dependent.
Qiuet al (2009) proposed a method called doublepropagation that uses dependency relations toextract both opinion words and product features.575However, none of these approaches handle nounsor noun phrases.
Although Zagibalov and Carroll(2008) noticed the issue, they did not study it.Esuli and Sebastiani (2006) used WordNet todetermine polarities of words, which can includenouns.
However, dictionaries do not containdomain specific information.Our work uses the feature-based opinion miningmodel in (Hu and Liu, 2004) to mine opinions inproduct reviews.
We found that in someapplication domains product features which areindicated by nouns have implied opinions althoughthey are not subjective words.This paper aims to identify such opinionatednoun features.
To make this concrete, let us see anexample from a mattress review: ?Within a month,a valley formed in the middle of the mattress.
?Here ?valley?
indicates the quality of the mattress(a product feature) and also implies a negativeopinion.
The opinion implied by ?valley?
cannotbe found by current techniques.Although Riloff et al (2003) proposed a methodto extract subjective nouns, our work is verydifferent because many nouns implying opinionsare not subjective nouns, but objective nouns, e.g.,?valley?
and ?hole?
on a mattress.
Those sentencesinvolving such nouns are usually also objectivesentences.
As much of the existing opinion miningresearch focuses on subjective sentences, webelieve it is high time to study objective words andsentences that imply opinions as well.
This paperrepresents a positive step towards this direction.Objective words (or sentences) that implyopinions are very difficult to recognize becausetheir recognition typically requires thecommonsense or world knowledge of theapplication domain.
In this paper, we propose amethod to deal with the problem, specifically,finding product features which are nouns or nounphrases and imply positive or negative opinions.Our experimental results show promising results.2 The Proposed MethodWe start with some observations.
For a productfeature (or feature for short) with an impliedopinion, there is either no adjective opinion wordthat modifies it directly or the opinion word thatmodify it usually have the same opinion.Example 1: No opinion adjective word modifiesthe opinionated product feature (?valley?
):?Within a month, a valley formed in the middleof the mattress.
?Example 2: An opinion adjective modifies theopinionated product feature:?Within a month, a bad valley formed in themiddle of the mattress.
?Here, the adjective ?bad?
modifies ?valley?.
It isunlikely that a positive opinion word will modify?valley?, e.g., ?good valley?
in this context.
Thus,if a product feature is modified by both positiveand negative opinion adjectives, it is unlikely to bean opinionated product feature.Based on these examples, we designed thefollowing two steps to identify noun productfeatures which imply positive or negative opinions:1.
Candidate Identification: This step determinesthe surrounding sentiment context of each nounfeature.
The intuition is that if a feature occursin negative (respectively positive) opinioncontexts significantly more frequently than inpositive (or negative) opinion contexts, we caninfer that its polarity is negative (or positive).
Astatistical test is used to test the significance.This step thus produces a list of candidatefeatures with positive opinions and a list ofcandidate features with negative opinions.2.
Pruning: This step prunes the two lists.
Theidea is that when a noun product feature isdirectly modified by both positive and negativeopinion words, it is unlikely to be anopinionated product feature.Basically, step 1 needs the feature-based sentimentanalysis capability.
We adopt the lexicon-basedapproach in (Ding et al 2008) in this work.2.1 Feature-Based Sentiment AnalysisTo use the lexicon-based sentiment analysismethod, we need a list of opinion words, i.e., anopinion lexicon.
Opinion words are words thatexpress positive or negative sentiments.
As notedearlier, there are also many words whose polaritiesdepend on the contexts in which they appear.Researchers have compiled sets of opinionwords for adjectives, adverbs, verbs and nounsrespectively, called the opinion lexicon.
In thispaper, we used the opinion lexicon complied byDing et al (2008).
It is worth mentioning that ourtask is to find nouns which imply opinions in aspecific domain, and such nouns do not appear inany general opinion lexicon.5762.1.1.
Aggregating Opinions on a FeatureUsing the opinion lexicon, we can identify opinionpolarity expressed on each product feature in asentence.
The lexicon based method in (Ding et al2008) basically combines opinion words in thesentence to assign a sentiment to each productfeature.
The sketch of the algorithm is as follows.Given a sentence s which contains a productfeature f, opinion words in the sentence are firstidentified by matching with the words in theopinion lexicon.
It then computes an orientationscore for f. A positive word is assigned thesemantic orientation (polarity) score of +1, and anegative word is assigned the semantic orientationscore of -1.
All the scores are then summed upusing the following score formula:,),(.)(:????
?Lwsww iiiii fwdisSOwfscore  (1)where wi is an opinion word, L is the set of allopinion words (including idioms) and s is thesentence that contains the feature f, and dis(wi, f) isthe distance between feature f and opinion word wiin s. wi.SO is the semantic orientation (polarity) ofword wi.
The multiplicative inverse in the formulais used to give low weights to opinion words thatare far away from the feature f.If the final score is positive, then the opinion onthe feature in s is positive.
If the score is negative,then the opinion on the feature in s is negative.2.1.2.
Rules of OpinionsSeveral language constructs need special handling,for which a set of rules is applied (Ding et al,2008; Liu, 2010).
A rule of opinion is animplication with an expression on the left and animplied opinion on the right.
The expression is aconceptual one as it represents a concept, whichcan be expressed in many ways in a sentence.Negation rule.
A negation word or phraseusually reverses the opinion expressed in asentence.
Negation words include ?no,?
?not?, etc.In this work, we also discovered that whenapplying negation rules, a special case needs extracare.
For example, ?I am not bothered by the humpon the mattress?
is a sentence from a mattressreview.
It expresses a neutral feeling from theperson.
However, it also implies a negative opinionabout ?hump,?
which indicates a product feature.We call this kind of sentences negated feelingresponse sentences.
A sentence like this normallyexpresses the feeling of a person or a group ofpersons towards some items which generally havepositive or negative connotations in the sentencecontext or the application domain.
Such a sentenceusually consists of four components: a nounrepresenting a person or a group of persons (whichincludes personal pronoun and proper noun), anegation word, a feeling verb, and a stimulus word.Feeling verbs include ?bother,?
?disturb,?
?annoy,?etc.
The stimulus word, which stimulates thefeeling, also indicates a feature.
In analyzing sucha sentence, for our purpose, the negation is notapplied.
Instead, we regard the sentence bearingthe same opinion about the stimulus word as theopinion of the feeling verb.
These opinion contextswill help the statistical test later.But clause rule.
A sentence containing ?but?also needs special treatment.
The opinion before?but?
and after ?but?
are usually the opposite toeach other.
Phrases such as ?except that?
and?except for?
behave similarly.Deceasing and increasing rules.
These rulessay that deceasing or increasing of some quantitiesassociated with opinionated items may change theorientations of the opinions.
For example, ?Thedrug eased my pain?.
Here ?pain?
is a negativeopinion word in the opinion lexicon, and thereduction of ?pain?
indicates a desirable effect ofthe drug.
We have compiled a list of such words,which include ?decease?, ?diminish?, ?prevent?,?remove?, etc.
The basic rules are as follows:Decreased Neg ?
PositiveE.g: ?My problem have certainly diminished?Decreased Pos ?
NegativeE.g: ?These tires reduce the fun of driving.
?Neg and Pos represent respectively a negativeand a positive opinion word.
Increasing rules donot change opinion directions (Liu, 2010).2.1.3.
Handing Context-Dependent OpinionsAs mentioned earlier, context-dependent opinionwords (only adjectives and adverbs) must bedetermined by its contexts.
We solve this problemby using the global information rather than onlythe local information in the current sentence.
Weuse a conjunction rule.
For example, if someonewrites a sentence like ?This camera is very niceand has a long battery life?, we can infer that577?long?
is positive for ?battery life?
because it isconjoined with the positive word ?nice.?
Thisdiscovery can be used anywhere in the corpus.2.2 Determining Candidate Noun ProductFeatures that Imply OpinionsUsing the sentiment analysis method in section 2.1,we can identify opinion sentences for each productfeature in context, which contains both positive-opinionated sentences and negative-opinionatedsentences.
We then determine candidate productfeatures implying opinions by checking thepercentage of either positive-opinionated sentencesor negative-opinionated sentences among allopinionated sentences.
Through experiments, wemake an empirical assumption that if either thepositive-opinionated sentence percentage or thenegative-opinionated sentence percentage issignificantly greater than 70%, we regard this nounfeature as a noun feature implying an opinion.
Thebasic heuristic for our idea is that if a noun featureis more likely to occur in positive (or negative)opinion contexts (sentences), it is more likely to bean opinionated noun feature.
We use a statisticmethod test for population proportion to performthe significant test.
The details are as follows.
Wecompute the Z-score statistic with one-tailed test.nppppZ )1( 000???
(2)where p0 is the hypothesized value (0.7 in ourcase), p is the sample proportion, i.e., thepercentage of positive (or negative) opinions in ourcase, and n is the sample size, which is the totalnumber of opinionated sentences that contain thenoun feature.
We set the statistical confidence levelto 0.95, whose corresponding Z score is -1.64.
Itmeans that Z score for an opinionated feature mustbe no less than -1.64.
Otherwise we do not regardit as a feature implying opinion.2.3 Pruning Non-Opinionated FeaturesMany of candidate noun features with opinionsmay not indicate any opinion.
Then, we need todistinguish features which have implied opinionsand normal features which have no opinions, e.g.,?voice quality?
and ?battery life.?
For normalfeatures, people often can have different opinions.For example, for ?voice quality?, people can say?good voice quality?
or ?bad voice quality.
?However, for features with context dependentopinions, people often have a fixed opinion, eitherpositive or negative but not both.
With thisobservation in mind, we can detect features withno opinion by finding direct modification relationsusing a dependency parser.
To be safe, we use onlytwo types of direct relations:Type1: O  ?
O-Dep ?
FIt means O depends on F through a relation O-Dep.
E.g: ?This TV has a good picture quality.
?Type 2: O ?
O-Dep ?
H ?
F-Dep ?
FIt means both O and F depends on H throughrelation O-Dep and F-Dep respectively.
E.g:?The springs of the mattress are bad.
?Here O is an opinion word, O-Dep / F-Dep is adependency relation, which describes a relationbetween words, and includes mod, pnmod, subj, s,obj, obj2 and desc (detailed explanations can befound in http://www.cs.ualberta.ca/~lindek/minipar.htm).
F is a noun feature.
H means anyword.
For the first example, given feature ?picturequality?, we can extract its modification opinionword ?good?.
For the second example, givenfeature ?springs?, we can get opinion word ?bad?.Here H is the word ?are?.Among these extracted opinion words for thefeature noun, if some belong to the positiveopinion lexicon and some belong to the negativeopinion lexicon, we conclude the noun feature isnot an opinionated feature and is thus pruned.3 ExperimentsWe conducted experiments using four diverse real-life datasets of reviews.
Table 1 shows the domains(based on their names) of the datasets, the numberof sentences, and the number of noun features.
Thefirst two datasets were obtained from a commercialcompany that provides opinion mining services,and the other two were crawled by us.Product Name Mattress    Drug Router Radio# Sentences 13191 1541 4308 2306# Noun features 326 38 173 222Table 1.
Experimental datasetsAn issue for judging noun features implyingopinions is that it can be subjective.
So for the goldstandard, a consensus has to be reached betweenthe two annotators.578For comparison, we also implemented a baselinemethod, which decides a noun feature?s polarityonly by its modifying opinion words (adjectives).If its corresponding adjective is positive-orientated,then the noun feature is positive-orientated.
Thesame goes for a negative-orientated noun feature.Then using the same techniques in section 2.3 forstatistical test (in this case, n in equation 2 is thetotal number of sentences containing the nounfeature) and for pruning, we can determine nounfeatures implying opinions from the data corpus.Table 2 gives the experimental results.
Theperformances are measured using the standardevaluation measures of precision and recall.
FromTable 2, we can see that the proposed method ismuch better than the baseline method on both therecall and precision.
It indicates many nounfeatures that imply opinions are not directlymodified by adjective opinion words.
We have todetermine their polarities based on contexts.ProductNameBaseline Proposed MethodPrecision Recall Precision RecallMattress 0.35 0.07 0.48 0.82Drug 0.40 0.15 0.58 0.88Router 0.20 0.45 0.42 0.67Radio 0.18 0.50 0.31 0.83Table 2.
Experimental results for noun featuresTable 3 and Table 4 give the results of nounfeatures implying positive and negative opinionsseparately.
No baseline method is used here due toits poor results.
Because for some datasets, there isno noun feature implying a positive/negativeopinion, their precision and recall are zeros.Product Name Precision RecallMattress 0.42 0.95Drug 0.33 1.0Router 0.43 0.60Radio 0.38 0.83Table 3.
Features implying positive opinionsProduct Name Precision RecallMattress 0.56 0.72Drug 0.67 0.86Router 0.40 1.00Radio 0 0Table 4.
Features implying negative opinionsFrom Tables 2 - 4, we observe that the precisionof the proposed method is still low, although therecalls are good.
To better help the user find suchwords easily, we rank the extracted featurecandidates.
The purpose is to rank correct nounfeatures that imply opinions at the top of the list, soas to improve the precision of the top-rankedcandidates.
Two ranking methods are used:1. rank based on the statistical score Z in equation2.
We denote this method with Z-rank.2.
rank based on negative/positive sentence ratio.We denote this method with R-rank.Tables 5 and 6 show the ranking results.
We adoptthe rank precision, also called the precision@N,metric for evaluation.
It gives the percentage ofcorrect noun features implying opinions at the rankposition N. Because some domains may notcontain positive or negative noun features, wecombine positive and negative candidate featurestogether for an overall ranking for each dataset.Mattress Drug Router RadioZ-rank 0.70 0.60 0.60 0.70R-rank 0.60 0.60 0.50 0.40Table 5.
Experimental results: Precision@10Mattress Drug Router RadioZ-rank 0.66  0.46 0.53R-rank 0.60  0.46 0.40Table 6.
Experimental results: Precision@15From Tables 5 and 6, we can see that theranking by statistical value Z is more accurate thannegative/positive sentence ratio.
Note that in Table6, there is no result for the Drug dataset because nonoun features implying opinions were foundbeyond the top 10 results because there are notmany such noun features in the drug domain.4 ConclusionsThis paper proposed a method to identify nounproduct features that imply opinions.
Conceptually,this work studied the problem of objective nounsand sentences with implied opinions.
To the best ofour knowledge, this problem has not been studiedin the literature.
This problem is important becausewithout identifying such opinions, the recall ofopinion mining suffers.
Our proposed methoddetermines feature polarity not only by opinionwords that modify the features but also by itssurrounding context.
Experimental results showthat the proposed method is promising.
Our futurework will focus on improving the precision.579ReferencesAndreevskaia, A. and S. Bergler.
2006.
MiningWordNet for fuzzy sentiment: Sentiment tagextraction from WordNet glosses.
Proceedings ofEACL 2006.Eric Breck, Yejin Choi, and Claire Cardie.
2007.Identifying Expressions of Opinion in Context.Proceedings of IJCAI 2007.Xiaowen Ding, Bing Liu and Philip S. Yu.
2008 AHolistic Lexicon-Based Approach to OpinionMining.
Proceedings of WSDM 2008.Eduard C. Dragut, Clement Yu, Prasad Sistla, andWeiyi Meng.
2010.
Construction of a sentimentalword dictionary.
In Proceedings of CIKM2010.Andrea Esuli and Fabrizio Sebastiani.
2005.Determining the Semantic Orientation of Termsthrough Gloss Classification.
Proceedings of CIKM2005.Andrea Esuli and Fabrizio Sebastiani.
2006.SentiWorkNet: A Publicly Available LexicalResource for Opinion Mining.
Proceedings of LREC2006.Michael Gamon.
2004.
Sentiment Classification onCustomer Feedback Data: Noisy Data, Large FeatureVectors and the Role of Linguistic Analysis.Proceedings of COLING 2004.Murthy Ganapathibhotla.
and Bing Liu.
2008.
Miningopinions in comparative sentences.
Proceedings ofCOLING 2008.Vasileios Hatzivassiloglou and Kathleen, McKeown.1997.
Predicting the Semantic Orientation ofAdjectives.
Proceedings of ACL 1997.Minqing Hu and Bing Liu.
2004.
Mining andSummarizing Customer Reviews.
Proceedings ofKDD 2004.Jaap Kamps, Maarten Marx, Robert J, Mokken andMaarten de Rijke.
2004.
Proceedings of LREC 2004.Hiroshi Kanayama, Tetsuya Nasukawa 2006.
FullyAutomatic Lexicon Expansion for Domain-OrientedSentiment Analysis.
Proceedings of EMNLP 2006.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-ofrelations in opinion mining.
Proceedings of EMLP2007Soo-Min Kim and Eduard Hovy.
2004.
Determining theSentiment of Opinions.
Proceedings of COLING2004.Lun-Wei Ku,Yu-Ting Liang, and Hsin-Hsi Chen.
2006.Opinion extraction, summarization and tracking innews and blog corpora.
Proceedings of AAAI-CAAW2006.Bing Liu.
2010.
Sentiment analysis and subjectivity.
Achapter in Handbook of Natural LanguageProcessing, Second edition.Yue Lu, Chengxiang Zhai, and Neel Sundaresan.
2009.Rated aspect summarization of short comments.Proceedings of WWW 2009.Bo Pang and Lillian Lee.
2008.
Opinion Mining andsentiment Analysis.
Foundations and Trends inInformation Retrieval 2(1-2), 2008.Bo Pang,  Lillian Lee and Shivakumar  Vaithyanathan.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
Proceedings ofEMNLP 2002.Ana-Maria Popescu and Oren Etzioni.
2005.
ExtractingProduct Features and Opinions from Reviews.Proceedings of EMNLP 2005.Guang Qiu, Bing Liu, Jiajun  Bu and Chun Chen.
2009.Expanding Domain Sentiment Lexicon throughDouble Propagation.
Proceedings of IJCAI 2009.Ellen Riloff, Janyce Wiebe, and Theresa Wilson.
2003.Learning subjective nouns using extraction patternbootstrapping.
Proceedings of CoNLL 2003.Hiroya Takamura, Takashi Inui and Manabu Okumura.2007.
Extracting Semantic Orientations of Phrasesfrom Dictionary.
Proceedings of HLT-NAACL 2007.Ivan Titov and Ryan McDonald.
2008.
A joint model oftext and aspect ratings for sentiment summarization.In Proceedings of ACL 2008.Peter D. Turney.
2002.Thumbs Up or Thumbs Down?
Semantic OrientationApplied to Unsupervised Classification of Reviews.Proceedings of ACL 2002.Janyce Wiebe.
2000.
Learning Subjective Adjectivesfrom Corpora.
Proceedings of AAAI 2000.Theresa Wilson, Janyce Wiebe, Rebecca Hwa.
2004.Just how mad are you?
Finding strong and weakopinion clauses.
Proceedings of AAAI 2004.Taras Zagibalov and John Carroll.
2008.
UnsupervisedClassification of Sentiment and Objectivity inChinese Text.
Proceedings of IJCNLP 2008.580
