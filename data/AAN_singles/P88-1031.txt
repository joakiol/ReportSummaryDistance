Graph-structured Stack and Natural Language ParsingMasaru TomltaCenter for Machine TranslationandComputer Science DepartmentCamegie-MeUon UniversityPittsburgh, PA 15213AbstractA general device for handling nondeterminism in stackoperations is described.
The device, called aGraph-structured Stack, can eliminate duplication ofoperations throughout he nondeterministic processes.This paper then applies the graph-structured stack tovarious natural language parsing methods, includingATN, LR parsing, categodal grammar and principle-based parsing.
The relationship between the graph-structured stack and a chart in chart parsing is alsodiscussed.1.
IntroductionA stack plays an important role in natural languageparsing.
It is the stack which gives a parser context-free (rather than regular) power by permittingrecursions.
Most parsing systems make explicit useof the stack.
Augmented Transition Network (ATN)\[10\] employs a stack for keeping track of retumaddresses when it visits a sub-network.
Shift-reduceparsing uses a stack as a pdmary device; sentencesare parsed only by pushing an element onto the stackor by reducing the  stack in accordance withgrammatical rules.
Implementation of pdnciple-basedparsing \[9, 1, 4\] and categodal grammar \[2\] also oftenrequires a stack for stodng partial parses already builLThose parsing systems usually introduce backtrackingor pseudo parallelism to handle nondeterminism,taking exponential time in the worst case.This paper describes a general device, agraph-structured stack.
The graph-structured stackwas originally introduced in Tomita's generalized LRparsing algorithm \[7, 8\].
This paper applies the graph-structured stack to various other parsing methods.Using the graph-structured stack, a system isguaranteed not to replicate the same work and canrun in polynomial time.
This is true for all of theparsing systems mentioned above; ATN, shift-reduceparsing, principle-based parsing, and perhaps anyother parsing systems which employ a stack.The next section describes the graph-structurestack itself.
Sections 3, 4, 5 and 6 then describe theuse of the graph-structured stack in shift-reduce LRparsing, ATN, Categorlal Grammars, and principle-based parsing, respectively.
Section 7 discusses therelationship between the graph-structured stack andchart \[5\], demonstrating that chart parsing may beviewed as a special case of shift-reduce parsing witha graph-structured stack.2.
The Graph-structured StackIn this section, we describe three key notions of thegraph-structured stack: splitting, combining and localambiguity packing.?
2.1.
SpUttlngWhen a stack must be reduced (or popped) in morethan one way, the top of the stack is split.
Supposethat the stack is in the following state.
The left-mostelement, A, is the bottom of the stack, and the right-most element, E, is the top of the stack.
In a graph-structured stack, there can be more than one top,whereas there can be only one bottom.#,- - -  n - - -  C - - -  D - - -  ZSuppose that the stack must be reduced in thefollowing three different ways.F <- -  D \]~G <- -  D IBH<- -  C D 1Then after the three reduce actions, the stack looks249like:A - - -  B lom\\\- - i  F//C .
.
.
.
Gl f l2.2.
CombiningWhen an element needs to be shifted (pushed)onto two or more tops of the stack, it is done onlyonce by combining the tops of the stack.
Forexample, if "1" is to be shifted to F, G and H in theabove example, then the stack will look like:/ - -  r - - \/ \/ \A - - -  B - - -  C .
.
.
.
G .
.
.
.
Z\ /\ /\ a - - /2.3.
Local Ambiguity PackingIf two or more branches of the stack turned out tobe Identical, then they represent local ambiguity; theIdentical state of stack has been obtained in two ormore different ways.
They are merged and treated asa single branch.
Suppose we have two rules:J< - -F  ZJ<- -  G ZAfter applying these two rules to the example above,the stack will look like:A - - - a  .
.
.
.
c - - - o\\\ - -  x - - -  zThe branch of the stack, "A-B-C-J', has beenobtained in two ways, but they are merged and onlyone is shown in the stack.3.
Graph-structured Stack andShift-reduce LR ParsingIn shift-reduce parsing, an input sentence is parsedfrom left to dght.
The parser has a stack, and thereare two basic operations (actions) on the stack: shiftand reduce.
The shift action pushes the next word inthe input sentence onto the top of the stack.
Thereduce action reduces top elements of the stackaccording to a context-free phrase structure rule in thegrammar.One of the most efficient shift-reduce parsingalgorithms is LR parsing.
The LR parsing algodthmpre-compiles a grammar into a parsing table; at runtime, shift and reduce actions operating on the stackare deterministically guided by the parsing table.
Nobacktracking or search is involved, and the algodthmruns in linear time.
This standard LR parsingalgorithm, however, can deal with only a small subsetof context-free grammars called LR grammars, whichare often sufficient for programming languages butcleady not for natural languages.
If, for example, agrammar is ambiguous, then its LR table would havemultiple entries, and hence deterministic parsingwould no longer be possible.Figures 3-1 and 3-2 show an example of a non-LRgrammar and its LR table.
Grammar symbols startingwith " represent pre-terminals.
Entdes "sh n" in theactton table (the left part of the table) Indicate that theaction is to "shift one word from input buffer onto thestack, and go to state n'.
Entries "re n" Indicate thatthe action is to "reduce constituents on the stack usingrule n'.
The entry "acc" stands for the action "accept',and blank spaces represent "error'.
The goto table(the dght part of the table) decides to which state theparser .should go  after a reduce action.
The LRparsing algorithm pushes state numbers (as well asconstituents) onto the stack; the state number on thetop of the stack Indicates the current state.
The exactdefinition and operation of the LR parser can be foundin Aho and UIIman \[3\].We can see that there are two multiple entries inthe action table; on the rows of state 11 and 12 at thecolumn labeled "prep'.
Roughly speaking, this is thesituation where the parser encounters a preposition ofa PP right after a NP.
If this PP does not modify theNP, then the parser can go ahead to reduce the NP toa higher nonterminal such as PP or VP, using rule 6or 7, respectively (re6 and re7 in the multiple entries).If, on the other hand, the PP does modify the NP, then250(1) S - -> NP VP(2) S - -> S PP(3) NP - -> *n(4) NP - -> *det *n(5) NP - -> NP PP(6) PP - -> *prep NP(7) VP - -> *v NPFigure 3-1: An Example Ambiguous GrammarState  *det *n *v *prep $ NP PP VP S012345689I01112sh3 sh4shl0sh3 sh4sh3 sh4sh7re32 1sh6 acc 5sh6 9 8re3 re3re2 re21112re1 re1re5 re5 re5re4 re4 re4re6 re6, sh6 re6 9re7 ,sh6  re7 9Figure 3-2: LR Parsing Table with Multiple Entries(dedved from the grammar in fig 3-1) .I .
.
.
.
.
.
.
.
s .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1 .
.
.
.
.
.
.
.
\I \I .
.
.
.
.
.
.
.
.
.
.
.
.
s, I .
.
.
.
.
.
\ \I \ \I I .
.
.
.
.
.
.
.
=re .
.
.
.
.
.
12  .
.
.
.
.
.
.
\ \I I \ \o~- -m, - -2 - - -v - - - ' /~- -~e- -12- -~p- - -6~- -m, - -11- - -p - - -6 - - -ae -~11- -~p- - -6\ .
.
.
.
.
s .
.
.
.
I .
.
.
.
\ - .
I \ ~-e .
.
.
.
.
.
.
.
.
I I\ I\ - , - - .
.
.
.
.
~re .
.
.
.
.
.
.
.
.
.
.
.
.
.
6 IFlgure 3-3: A Graph-structured Stack251the parser must wait (sh6) until the PP is completedso it can build a higher NP using rule 5.With a graph-structured stack, these non-deterministic phenomena can be handled efficiently inpolynomial time.
Figure 3-3 shows the graph-structured stack right after shifting the word "with" inthe sentence "1 saw a man on the bed in theapartment with a telescope."
Further description ofthe generalized LR parsing algorithm may be found inTomita \[7, 8\].4.
Graph-structured Stack and ATNAn ATN parser employs a stack for saving localregisters and a state number when it visits asubnetwork recursively.
In general, an ATN isnondeterministic, and the graph-structured stack isviable as may be seen in the following example.Consider the simple ATN, shown in figure 4-1, for thesentence "1 saw a man with a telescope.
"After parsing "1 saw", the parser is in state $3 andabout to visit the NP subnetwork, pushing the currentenvironment (the current state symbol and allregisters) onto the stack.
After parsing "a man', thestack is as shown in figure 4-2 (the top of the stackrepresents the current environment).Now, we are faced with a nondeterministic choice:whether to retum from the NP network (as state NP3is final), or to continue to stay in the NP network,expecting PP post nominals.
In the case of returningfrom NP, the top element (the current environment) ispopped from the stack and the second element of thestack is reactivated as the current environment.
TheDO register is assigned with the result from the NPnetwork, and the current state becomes $4.At this moment, two processes (one in state NP3and the other in state $4) are alivenondeterministically, and both of them are looking fora PP.
When "with" is parsed, both processes visit thePP network, pushing the current environment onto thestack.
Since both processes are to visit the samenetwork PP, the current environment is pushed onlyonce to both NP3 and $4, and the rest of the PP isparsed only once as shown in figure 4-3.Eventually, both processes get to the final state $4,and two sets of registers are produced as its finalresults (figure 4-4).5.
Graph-structured Stack and categorialgrammarParsers based on categodal grammar can beimplemented as shift-reduce parsers with a stack.Unlike phrase-structure rule based parsers,information about how to reduce constituents isencoded in the complex category symbol of eachconstituent with functor and argument features.Basically, the parser parses a sentence strictly fromleft to dght, shiffing words one-by-one onto the stack.In doing so, two elements from the top of the stack areInspected to see whether they can be reduced.
Thetwo elements can be reduced in the following cases:?
x/'z x -> x (Forward FunctionalApplication)?
Y x \x  -> x (Backward FunctionalApplication)?
x /x  x /z  -> x /z  (Forward FunctionalComposition)?
x \ z  x /x  ->  x\z (BackwardFunctional Composition)When it reduces a stack, it does so non-destnJctively;that is, the original stack is kept alive even after thereduce action.
An example categodal grammar ispresented in figure 5-1.zsaw (s\~e)/,~?
~I~nusn Nw~th ( .r~\~)/m,,  ((s\m,) \ (s\m,))/m,?
I~ /Nte lescope  NFigure 5-1: An Example Categodal GrammarThe category, (S\NP), represents a verb phrase, asit becomes S if there is an NP on its left.
Thecategories, (NP~NP) and (S\NP)\(S\NP), represent aprepositional phrase, as it becomes a noun phrase ora verb phrase if there is a noun phrase or a verbphrase on its left, respectively.
Thus, a prepositionsuch as "with" has two complex categodas as in the252PP/ .
.
.
.
\v ~ / I(S l )  .
.
.
.
.
.
> (S2) .
.
.
.
.
.
.
> (S3) .
.
.
.
.
.
> \ [S4 \ ]  < .
.
.
.
/PP/ .
.
.
.
\det  n / J(NP1) .
.
.
.
.
> (HP2) .
.
.
.
.
> \ [NP3\]  < .
.
.
.
/\\ p :on\ .
.
.
.
.
> \ [ .
rP4\ ]p NP(PP1) .
.
.
.
.
> (PIP2) .
.
.
.
.
> \ [PP3\]SI-NP-S252-v-53S3-NP-S4S4-PP-S4NPI-det-NP2NP2-n-NP3NP3-PP-NP3NPI-pEon-NP4PPI-p-PP2PP2-NP-PP3A:  Sub:) <- -  *C: (Sub j -ve :b -ag :eement  )A:  MY<- -  *A:  DO<- -  *A:  \]~:x:\[8 <=m *A: Det  <--  *A :  Head  <- -  .A :  Qua1 <- -  *A :  Head  <- -  *A :  Prep  <--  *A :  P:el~:)b:) <- -  *\ [ \ ] :  f ina l  s ta tes( ) :  non- f ina l  s ta tesF igure  4-1: A Simple ATN for "1 saw a man with a telescope"bot to~ S3 N~3\ [Sub:) :  Z \ [Det :  aMV: Head:\ [=oat :  : sea  \[=oat= : mantense :  past \ ] \ ]  Hum: 8Ang le \ ] \ ]F igure  4-2: Graph-structured Stack in ATN Parsing "1 saw a man"bot tom\\\\ .\\\S3 NP3\ [Sub:) :  X \ [Det :  a\ ]~:  Head:  man\]\ [=oat :  seetense :  pas t \ ] \ ]S4\ [Sub: ) :  zMV: \ [?oot :  seetense :  past \ ]DO: \ [Det :  aHead:  man\ ] \ ]PP2\[Pr~p: with \ ]// .///F igure  4-3: Graph-structured Stack in ATN Parsing "1 saw a man with a"\]NrP2\ [Det  : a \ ]253bot t~ s4\[sub:) : zMV: \ [=got :  see1Cerise : past \ ]IX): \ [Det :  aHead: man\]Mods: \ [P=ep: w i thP:epOb:): \ [Det :  aHead: t :e lescope\ ]  \]\](sub::): zMV: \[=oo'c : seetense :  pas t \ ]IX): \ [Det :  eHead: man\]Qua1: \[P=ep : w i thP :epObj :  \ [Det :  a\]Bead: te lescope\ ]  \] \]Figure 4-4: Graph-structured Stack in ATN Parsing "1 saw a man with a telescope"/ - .
( s \~m) /~/Figure 5-1: Graph-structured Stack in CG parsing"1 saw a"/ .
.
.
.
.
.
.
.
.
.
.
.
.
.
(S\Ne)/H .
.
.
.
.
\/ \bot tom .
.
.
.
m~ .
.
.
.
( s \~)  In  .
.
.
.
~/a  .
.
.
.
.
.\ \ \\ \ \ m~\ \\ \, s \~\\ sFigure 5-2: Graph-structured Stack in CG parsing "1 saw a man"/ .
.
.
.
.
.
.
.
(sXsP)/s .
.
.
.
.
\/ \bot to~ - - -  ~ - - -  ( s \~) / l ce  - - -  mP/m - - -  H - - \\ \ \ \ / - -  (mP\~)  INs\ \ \ we .
.
.
.
\ I\ \ I .
.
.
.
((s\mP) / ( s \Ne) )  INs\ \, s \~m -- I\ /\ s - - - IFigure 5-3: Graph-structured Stack in CG parsing "1 saw a man with"254example above.
Nondeterminism in this formalismcan be similarly handled with the graph-structuredstack.
After parsing "1 saw a', there is only one way toreduce the stack; (S\NP)/NP and NP/N into(S\NP)/N with Forward Functional Composition.
Thegraph-structured stack at this moment is shown infigure 5-1.After parsing "man', a sequence of reductions takesplace, as shown in figure 5-2.
Note that S\NP isobtained in two ways (S\NP)/N N --> S\NP and(S\NP)/NP NP --> S\NP), but packed into one nodewith Local Ambiguity Packing described in section 2.3.The preposition "with" has two complex categories;both of them are pushed onto the graph-structuredstack, as in figure 5-3.This example demonstrates that CategodalGrammars can be implemented as shift-reduceparsing with a graph-structured stack, it Is interestingthat this algorithm is almost equivalent o "lazy chartparsing" descdbed in Paraschi and Steedman \[6\].The relationship between the graph-structured stackand a chart in chad parsing is discussed in section 7.6.
Graph-structured Stack andPrinciple-based ParsingPdnciple-based parsers, such as one based on theGB theory, also use a stack to temporarily store partialtrees.
These parsers may be seen as shift-reduceparsers, as follows.
Basically, the parser parses asentence strictly from left to dght, shifting a word ontothe stack one-by-one.
In doing so, two elements fromthe top of the stack are always inspected to seewhether there are any ways to combine them with oneof the pdnciplas, such as augment attachment,specifier attachment and pre- and post-head adjunctattachment (remember, there are no outside phrasestructure rules in principle-based parsing).Sometimes these principles conflict and there ismore than one way to combine constituents.
In thatcase, the graph-structure stack is viable to handlenondeterminism without repetition of work.
Althoughwe do not present an example, the implementation ofpdnciple-based parsing with a graph-structured stackis very similar to the Implementation of CategodalGrammars with a graph-structured stack.
Only thedifference is that, in categodal grammars, Informationabout when and how to reduce two constItuents onthe top of the graph-structured stack is explicitelyencoded in category symbols, while in principle-basedparsing, it is defined implicitely as a set of pdnciplas.7.
Graph-structured Stack and ChartSome parsing methods, such as chart parsing, donot explicitly use a stack.
It Is Interesting toinvestigate the relationship between such parsingmethods and the graph-structured stack, and thissection discusses the correlation of the chart and thegraph-structured stack.
We show that chad parsingmay be simulated as an exhaustive version of shift-reduce parsing with the graph-structured stack, asdescribed Informally below.1.
Push the next word onto the graph-structured stack.2.
Non-destructively reduce the graph-structured stack in all possible ways withall applicable grammar rules; repeatuntil no further reduce action isapplicable.3.
Go to 1.A snapshot of the graph-structured stack in theexhaustive shift-reduce parsers after parsing "1 saw aman on the bed in the apartment with" is presented infigure 7-1 (slightly simplified, ignodng determiners, forexample).
A snapshot of a chart parser alter parsingthe same fragment of the sentence is also shown infigure 7-2 (again, slightly simplified).
It is clear that thegraph-structured stack in figure 7-1 and the chart infigure 7-2 are essentially the same; in fact they aretopologically Identical if we ignore the word boundarysymbols, "*', in figure 7-2.
It is also easy to observethat the exhaustive version of shitt-reduce parsing isessentially a version of chart parsing which parses asentence from left to dght.255/ .
.
.
.
.
s .
.
.
.
.
.
.
.
\/ \/ .
.
.
.
.
.
.
.
.
.
.
.
.
s .
.
.
.
.
.
.
.
.
.
.
\ \/ \ \I I .
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
\ \/ I \ \bot t~ .
.
.
.
.
~ .
.
.
.
.
v .
.
.
.
.
.
~ .
.
.
.
.
.
p .
.
.
.
.
.
~ .
.
.
.
.
.
p .
.
.
.
.
.
~ .
.
.
.
.
.
p\ \ I \  I\ .
.
.
.
.
s .
.
.
.
.
.
\ ,  I \ .
.
.
.
.
.
.
.
.
~ I\ /\ .
.
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
IF igure  7 .1 :  A Graph-structured Stack in an  Exhaust ive  Sh i f t -Reduce Parser"1 saw a man on the bed in the apar tment  with"/ I I I I I I I I I l l l I l~ '  .
I I I I I I I I I I I I I I l  I I~I \I .
.
.
.
.
.
.
.
.
.
.
.
.
s .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
\ \I \ \I I .
.
.
.
.
.
.
.
m,  .
.
.
.
.
.
.
.
.
.
.
\ \I I \ \- - - -~- - - * - - - .
- - - ' - - - IqP - - - * - - -p - - - ' - - -NP- - - * - - -p - - - * - - -We- - - * - - -p - - - *\ \ I \ I\ .
.
.
.
.
s .
.
.
.
.
.
.
.
.
.
\ .
.
.
.
I \ ,we .
.
.
.
.
.
.
.
.
.
I\ I\ m~ .
.
.
.
.
.
.
.
.
.
.
I"Z"  " laW"  "a  I "  "On"  " th l  ~d"  "4n"  " the  apt"  "w4th"F igure  7 .2 :  Chart  in Chart  Pars ing"1 saw a man on the bed in the apar tment  with"2568.
SummaryThe graph-structured stack was introduced in theGeneralized LR parsing algorithm \[7, 8\] to handlenondeterminism in LR parsing.
This paper extendedthe general idea to several other parsing methods:ATN, principle-based parsing and categodal grammar.We suggest considering the graph-structure stack forany problems which employ a stacknondeterministically.
It would be interesting to seewhether such problems are found outside the area ofnatural language parsing.\[9\]\[lO\]Wehdi, E.A Government-Binding Parser for French.Working Paper 48, Institut pour les EtudesSemantiquas et Cognitives, Unlversite deGeneve, 1984.Woods, W. A.Transition Network Grammars for NaturalLanguage Analysis.CACM 13:pp.591-606, 1970.9.
Bibliography\[I\] Abney, S. and J. Cole.A Govemment-Blnding Parser.In Proceedings of the North Eastern LinguisticSociety.
XVI, 1985.\[2\] Ades, A. E. and Steedman, M. J.On the Order of Words.Linguistics and Philosophy 4(4):517-558,1982.\[3\] Aho, A. V. and UIIman, J. D.Principles of Compiler Design.Addison Wesley, 1977.\[4\] Barton, G. E. Jr.Toward a Principle-Based Parser.A.I.
Memo 788, MITAI Lab, 1984.\[5\] Kay, M.The MIND System.Natural Language Processing.'
Algodthmics Press, New York, 1973, pagespp.155-188.\[6\] Pareschi, R. and Steedman, M.A Lazy Way to Chart-Parse with CategodalGrammars.25th Annual Meeting of the Association forComputational Linguistics :81-88, 1987.\[7\] Tomita, M.Efficient Parsing for Natural Language.Kluwer Academic Publishers, Boston, MA,1985.\[8\] Tomita, M.An Efficient Augmented-Context-Free ParsingAlgorithm.Computational Linguistics 13(1-2):31-46,January-June, 1987.257
