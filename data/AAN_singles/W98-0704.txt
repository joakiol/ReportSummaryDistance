The Use of  WordNet  in Information Retr ievalRi la  Manda la ,  Tokunaga Takenobu,  and  Tanaka  HozumiDepartment of Computer ScienceTokyo Institute of Technology{rila, take, t anaka}@cs, t itech, ac.
j pAbstractWordNet has been used in information retrievalresearch by many researchers, but failed to im-prove the performance of their retrieval system.Thereby in this paper we investigate why theuse of WordNet has not been successful.
Basedon this analysis we propose a method of makingWordNet more useful in information retrievalapplications.
Experiments using several stan-dard information retrieval test collections howthat our method results in a significant improve-ment of information retrieval performance.1 In t roduct ionDevelopment of WordNet began in 1985 atPrinceton University (Miller, 1990).
A teamlead by Prof. George Miller aimed to createa source of lexical knowledge whose organiza-tion would reflect some of the recent findings ofpsycholinguistic research into the human lexi-con.
WordNet has been used in numerous nat-ural language processing, such as part of speechtagging (Segond et al, 97), word sense disam-biguation (Resnik, 1995), text categorization(Gomez-Hidalgo and Rodriguez, 1997), infor-mation extraction (Chai and Biermann, 1997),and so on with considerable success.
Howeverthe usefulness of WordNet in information re-trieval applications has been debatable.Information retrieval is concerned with lo-cating documents relevant to a user's infor-mation needs from a collection of documents.The user describes his/her information eedswith a query which consists of a number ofwords.
The information retrieval system com-pares the query with documents in the collec-tion and returns the documents that are likelyto satisfy the user's information requirements.A fundamental weakness of current informationretrieval methods is that the vocabulary thatsearchers use is often not the same as the one bywhich the information has been indexed.
Queryexpansion is one method to solve this problem.The query is expanded using terms which havesimilar meaning or bear some relation to thosein the query, increasing the chances of matchingwords in relevant documents.
Expanded termsare generally taken from a thesaurus.Obviously, given a query, the information re-trieval system must present all useful articles tothe user.
This objective is measured by recall,i.e.
the proportion of relevant articles retrievedby the system.
Conversely, the information re-trieval system must not present any useless ar-ticle to the user.
This criteria is measured byprecision, i.e.
the proportion of retrieved arti-cles that are relevant.Voorhees used WordNet as a tool for queryexpansion (Voorhees, 1994).
She conducted ex-periments using the TREC collection (Voorheesand Harman, 1997) in which all terms in thequeries were expanded using a combination ofsynonyms, hypernyms, and hyponyms.
She setthe weights of the words contained in the orig-inal query to 1, and used a combination of 0.1,0.3, 0.5, 1, and 2 for the expansion terms.
Shethen used the SMART Information RetrievalSystem Engine (Salton, 1971) to retrieve thedocuments.
Through this method, Voorheesonly succeeded in improving the performanceon short queries and a tittle with no significantimprovement for long queries.
She further triedto use WordNet as a tool for word sense dis-ambiguation (Voorhees, 1993) and applied it totext retrieval, but the performance of retrievalwas degraded.Stairmand (Stairmand, 1997) used WordNetto compute lexical cohesion according to themethod suggested by Morris (Morris and Hirst,199 I), and applied this to information retrieval.31!
!I!IIIIiIIIIIIIIIHe concluded that his method could not be ap-plied to a fully-functional information retrievalsystem.Smeaton (Smeaton and Berrut, 1995) triedto expand the queries of the TREC-4 collec-tion with various trategies of weighting expan-sion terms, along with manual and automaticword sense disambiguation techniques.
Unfor-tunately all strategies degraded the retrievalperformance.Instead of matching terms in queries and doc-uments, Richardson (Richardson and Smeaton,1995) used WordNet to compute the semanticdistance between concepts or words and thenused this term distance to compute the similar-ity between a query and a document.
Althoughhe proposed two methods to compute seman-tic distances, neither of them increased the re-trieval performance.2 What ' s  wrong  w i th  WordNet?In this section we analyze why WordNet hasfailed to improve information retrieval perfor-mance.
We run exact-match retrieval against9 small standard test collections in order toobserve this phenomenon.
An information re-trieval test collection consists of a collection ofdocuments along with a set of test queries.
Theset of relevant documents for each test queryis also given, so that the performance of theinformation retrieval system can be measured.We expand queries using a combination of syn-onyms, hypernyms, and hyponyms in WordNet.The results are shown in Table 1.In Table 1 we show the name of the test col-lection (Collection), the total number of docu-ments (#Doc) and queries (#Query), and allrelevant documents for all queries (#Rel) inthat collection.
For each document collection,we indicate the total number of relevant docu-ments retrieved (Rel-ret), the recall (~) ,the total number of documents retrieved (Ret-docs), and the precision t Rel-ret ~ for each of Ret-docs jno expansion (Base), expansion with synonyms(Exp.
I), expansion with synonyms and hyper-nyms (Exp.
II), expansion with synonyms andhyponyms (Exp.
III), and expansion with syn-onyms, hypernyms, and hyponyms (Exp.
IV).From the results in Table 1, we can concludethat query expansion can increase recall per-formance but unfortunately degrades precision32performance.
We thus turned to investigation ofwhy all the relevant documents could not be re-trieved with the query expansion method above.Some of the reasons are stated below :?
Two terms that seem to be interrelatedhave different parts of speech in WordNet.This is the case between stochastic (adjec-tive) and statistic (noun).
Since words inWordNet are grouped on the basis of partof speech in WordNet, it is not possible tofind a relationship between terms with dif-ferent parts of speech.?
Most of relationships between two termsare not found in WordNet.
For examplehow do we know that Sumitomo Bank is aJapanese company ??
Some terms are not included in WordNet(proper name, etc).To overcome all the above problems, we pro-pose a method to enrich WordNet with an au-tomatically constructed thesaurus.
The ideaunderlying this method is that an automati-cally constructed thesaurus could complementthe drawbacks of WordNet.
For example, aswe stated earlier, proper names and their inter-relations among them are not found in Word-Net, but if proper names and other terms havesome strong relationship, they often cooccur inthe document, so that their relationship may bemodelled by an automatically constructed the-saurus .Polysemous words degrade the precision of in-formation retrieval since all senses of the origi-nal query term are considered for expansion.
Toovercome the problem of polysemous words, weapply a restriction in that queries are expandedby adding those terms that are most similar tothe entirety of query terms, rather than select-ing terms that are similar to a single term inthe query.In the next section we describe the details ofour method3 Method3.1 Co-occurrence-based ThesaurusThe general idea underlying the use of term co-occurrence data for thesaurus construction isthat words that tend to occur together in doc-uments are likely to have similar, or related,CollectionADITable 1: Term Expansion Experiment#Doc #Query i #Rel,82 35 170 Rel-retRecallRet-docsPrecisionResults using WordNetCACM 3204 64 796 Rel-retRecallRet-docsPrecisioniCISI 1460 112 3114 Rel-retRecallRet-docsPrecisionCRAN 1398 225i 1838' Rel-ret!
Recall,~ Ret-docsPrecisionJ iINsPEc 12684 84 2543 Rel-reti RecallRet-docsPrecisionI iLISA 6004 35 " 339 Rel-retRecallRet-docsPrecisionI IME\[) 1033 30 696 - Rel-retRecallRet-docsi PrecisionI iNPL 11429 100 2083 Rel-retRecallRet-docsPrecisionTh'vIEi423 24 324 i Rel-retRecallRet-docsPrecisionBase1570.92352,0630.07617380.927167,9500.01092,9520.947987,8950.03361,7690.9625199,4690.00892,5080.9862564,8090.00443391.0000148,5470.00236390.918112,0210.05322,0610.9894267,1580.00773241.00023,0140.0141Exp.
I1590.93532,2950.06937560.949786,5520.008730150.968298,8440.03051,8010.9799247,2120.00732,5310.9953735,9310.00343391.0000171,8080.00206620.951116,7580.03952,0710.9942395,2800.00523241.00029,9120.0108Exp.
II1660.97652,5420.06537660.9623101,1540.00763,0760.9878106,2750.02891,8230.9918284,0260.00642,5380.9980852,0560.00303391.0000184,1010.00186700.962622,3160.03002,0730.9952539,0480.00383241.00033,6500.0096Exp.
III1690.99412,7370.06177730.9711109,3910.00703,1040.9968108,9700.02841,8150.9875287,0280.00632,5360.9972869,3640.00293391.0000188,2890.00186710.964022,8660.02932,0720.9942577,0330.00363241.00032,6960.0095Exp.
IV1690.99412,7820.06077730.9711116,0010.00673,1060.9974109,6740.02831,8270.9940301,3140.00602,5420.9996912,8100.00283391.0000189,7840.00186730.967025,2500.02672,0740.9957678,8280.00313241.00034,4430.0094meanings.
Co-occurrence data thus provides astatistical method for automatically identifyingsemantic relationships that are normally con-tained in a hand-made thesaurus.
Suppose twowords (A and B) occur fa and fb times, respec-tively, and cooccur fc times, then the similaritybetween A and B can be calculated using a sim-ilarity coefficient such as the Dice Coefficient :2xf3.2 Pred icate -Argument -basedThesaurusIn contrast with the previous section, thismethod attempts to construct a thesaurus ac-cording to predicate-argument structures.
Theuse of this method for thesaurus constructionis based on the idea that there are restrictionson what words can appear in certain environ-ments, and in particular, what words can be ar-guments of a certain predicate.
For example, acat may walk, bite, but can not fly.
Each nounmay therefore be characterized according to the33verbs or adjectives that it occurs with.
Nounsmay then be grouped according to the extent owhich they appear in similar constructions.First, all the documents are parsed using theApple Pie Parser, which is a probabilistic hartparser developed by Satoshi Sekine (Sekine andGrisbman, 1995).
Then the following syntacticstructures are extracted :?
Subject-Verb?
Verb-Object?
Adjective-NounEach noun has a set of verbs and adjectivethat it occurs with, and for each such relation-ship, a dice coefficient value is calculated.2Xh.b(vi,n i) Csub(Vi, nj) -- l(v~)+L,b(nj)'where fsub(Vi, nj) is the frequency of nounnj occurring as the subject of verb vi,fsub(nj) is the frequency of the noun nj oc-curring as subject of any verb, and f(vi) isthe frequency of the verb viCobj(Vi, n3) = 2?/obj(.,,~)f(vl)+fobj (n j ) 'where fobi(vi, ni) is the frequency of nounn i occurring as the object of verb vi,fobj(nj) is the frequency of the noun nj oc-curring as object of any verb, and f(vi) isthe frequency of the verb vi?
C~aj(a~,n3)= 2?/od~(.,,.~)f(ai)' l 'fadj(nj) 'where f(ai, nj) is the frequency of nounnj occurring as argument of adjective ai,fadi(nj) is the frequency of the noun n i oc-curring as argument of any adjective, andf(a 0 is the frequency of the adjective aiWe define the object similarity of two nouoswith respect o one predicate, as the minimumof each dice coefficient with respect to thatpredicate, i.e.SI~'t/I, ub(Vi, rlj, nk)=min{C.ub(Vi, nj), C.ub(Vi, nk)}SIMobi(vi, n i, n~)=rnin{Cobj (vi, nj), Cob1 (vi, nh) }$IM~dj(ai, n i, nk)=min{C~dj(a~, n j) C~dj(a,, nk)}Finally the overall similarity between twonouns is defined as the average of all the similar-ities between those two nouns for all predicate-argument structures.343.3 Expans ion  Term Weight ing  MethodA query q is represented by a vector -~ =(ql, q2, ..., qn), where the qi's are the weights ofthe search terms ti contained in query q.The similarity between a query q and a termtj can be defined as belows :simqt(q, tj) = ~ qi * sirn(ti, tj)ti E qWhere the value of sim(ti, tj) can be de-fined as the average of the similarity values inthe three types of thesaurus.
Since in Word-Net there are no similarity weights, when thereis a relation between two terms in WordNet,their similarity is taken from the average of thesimilarity between those two terms in the co-occurrence-based and in predicate-argument-based thesauri.With respect o the query q, all the terms inthe collection can now be ranked according totheir simqt.
Expansion terms are terms tj withhigh simqt(q, tj).The weight(q, tj) of an expansion term tj isdefined as a function of simqt(q, tj):weight(q, tj) = simqt(q, tj)t, eq qiwhere 0 _< weight(q, tj) <_ 1.An expansion term gets a weight of 1 if itssimilarity to all the terms in the query is 1.
Ex-pansion terms with similarity 0 to all the termsin the query get a weight of 0.
The weight of anexpansion term depends both on the entire re-trieval query and on the similarity between theterms.
The weight of an expansion term canbe interpreted mathematically as the weightedmean of the similarities between the term tj andall the query terms.
The weight of the originalquery terms are the weighting factors of thosesimilarities.Therefore the query q is expanded by addingthe following query :~e = (al, a2, ..., at)where aj is equal to weight(q, tj) i ft j  belongs tothe top r ranked terms.
Otherwise ai is equalto 0.The resulting expanded query is :where the o is defined as the concatenation op-erator.The method above can accommodate the pol-ysemous word problem, because an expansionterm which is taken f~om a different sense to theoriginal query term is given very low weight.4 Exper imental  ResultsIn order to evaluate the effectiveness of the pro-posed method in the previous section we con-ducted experiments using the WSJ, CACM,  IN-SPEC, CISI, Cranfield, NPL, and LISA test col-lections.
The WSJ  collection comprises part ofthe TREC collection (Voorhees and Harman,1997).
As a baseline we used SMART (Salton,1971) without expansion.
SMART is an in-formation retrieval engine based on the vectorspace model in which term weights are calcu-lated based on term frequency, inverse docu-ment frequency and document length normal-ization.
The results are shown in Table 2.
Thistable shows the average of 11 point uninterpo-lated recall-precision for each of baseline, expan-sion using only WordNet, expansion using onlypredicate-argument-based thesaurus, expansionusing only cooccurrence-based thesaurus, andexpansion using all of them.
For each methodwe give the percentage of improvement over thebaseline.
It is shown that the performance us-ing the combined thesauri for query expansionis better than both SMART and using just onetype of thesaurus.Table 2:ThesauriExperiment Result using CombinedCoU Ba~e WordNetonlywsJ  0.245 o.28z(+2.0%)CACM 0.269 0.281~+4.5%)INSPEC 0.273 0.283(+3.7%)czsz 0.2is 0.23z(+7 2%)Cran 0.412 -0.421~+= 3%)NPL 0.201 0.210(+4.2%)LISA i 0.304 0.313I , (+3,1%)Expand~l  w i thPred-ar$ Cooccuronly0.258(+5.2%)0.29\[(+8.3%)0.284(+4.3%)O.
238(+9.4%)0.441(+7.0%)0.217(+8.t%)0.327(+7.o%)Combinedonly0.294 0.384(+t0.8%) (+58.7%)0.297 0.533(+zo.8%) (+98.2%)0.328 0.472(+20.4%) (+73.1%)0.262 0.301(+21.8%) (+81.3%)0.487 0.667(+zs.3%) (+82.z%)0.238 0.333(+Z7.5%) (+65.5%)0.369 0,485(+21.4%) (+~9.7%)355 Discuss ionsIn this section we discuss why our method ofusing WordNet is able to improve the perfor-mance of information retrieval.
The importantpoints of our method are :?
the coverage of WordNet is broadened?
weighting methodThe three types of thesaurus we used havedifferent characteristics.
Automatically con-structed thesauri add not only new terms butalso new relationships not found in WordNet.If two terms often cooccur together in a docu-ment then those two terms are likely bear somerelationship.
Why not only use the automati-cally constructed thesauri ?
The answer to thisis that some relationships may be missing inthe automatically constructed thesauri.
For ex-ample, consider the words tumor and turnout.These words certainly share the same context,but would never appear in the same document,at least not with a frequency recognized by acooccurrence-based method.
In general, dif-ferent words used to describe similar conceptsmay never be used in the same document, andare thus missed by the cooccurrence methods.However their relationship may be found in theWordNet thesaurus.The second point is our weighting method.As already mentioned before, most attempts atautomatically expanding queries by means ofWordNet have failed to improve retrieval effec-tiveness.
The opposite has often been true: ex-panded queries were less effective than the orig-inal queries.
Beside the "incomplete" natureof WordNet, we believe that a further problem,the weighting of expansion terms, has not beensolved.
All weighting methods described in thepast researches of query expansion using Word-Net have been based on "trial and error" or ad-hoc methods.
That is, they have no underlyingjustification.The advantages ofour weighting method are:?
the weight of each expansion term considersthe similarity of that term with all terms inthe original query, rather than to just oneor some query terms.?
the weight of the expansion term accom-modates the po\[ysemous word problem.This method can accommodate he polysemousword problem, because an expansion term takenfrom a different sense to the original query termsense is given very low weight.
The reason forthis is that, the weighting method depends onall query terms and all of the thesauri.
For ex-ample, the word bank has many senses in Word-Net.
Two such senses are the financial institu-tion and the river edge senses.
In a documentcollection relating to financial banks, the riversense of bank will generally not be found in theeooccurmnce-based thesaurus because of a lackof articles talking about rivers.
Even though(with small possibility) there may be some doc-uments in the collection talking about rivers, ffthe query contained the finance sense of bankthen the other terms in the query would alsoconcerned with finance and not rivers.
Thusrivers would only have a relationship with thebank term and there would be no relationshipswith other terms in the original query, resultingin a low weight.
Since our weighting methoddepends on both query in its entirety and sim-ilarity in the three thesauri, the wrong senseexpansion terms are given very low weight.6 Re la ted  ResearchSmeaton (Smeaton and Berrut, 1995) andVoorhees (Voorhees, 1994) have proposed an ex-pansion method using WordNet.
Our methoddiffers from theirs in that we enrich the cover-age of WordNet using two methods of automaticthesatmm construction, and we weight the ex-pausion term appropriately so that it can ac-commodate the polysemous word problem.Although Stairmand (Stairmand, 1997) andRichardson (Richardson and Smeaton, 1995)have proposed the use of WordNet in informa-tion retrieval, they did not used WordNet in thequery expansion framework.Our predicate-argument structure-based the-satmis is based on the method proposed by Hin-die (Hindle, 1990), although Hindle did not ap-ply it to information retrieval.
Instead, he usedmutual information statistics as a Similarity co-efficient, wheras we used the Dice coefficient fornormalization purposes.
Hindle only extractedthe subject-verb and the object-verb predicate-arguments, while we also extract adjective-nounpredicate-arguments.Our weighting method follows the Qiu36method (Qiu and Frei, 1993), except that Qiuused it to expand terms only from a single auto-matically constructed thesarus and did not con-sider the use of more than one thesaurus.7 Conc lus ionsThis paper analyzed why the use of WordNethas failed to improve the retrieval effectivenessin information retrieval applications.
We foundthat the main reason is that most relationshipsbetween terms are not found in WordNet, andsome terms, such as proper names, are not in-eluded in WordNet.
To overcome this problemwe proposed a method to enrich the WordNetwith automatically constructed thesauri.Another problem in query expansion is thatof polysemous words.
Instead of using a wordsense disambiguation method to select he apro-priate sense of each word, we overcame thisproblem with a weighting method.
Experimentsproved that our method of using WordNet inquery expansion could improve information re-trieval effectiveness.Future work will include experiments onlarger test collections, and the use of WordNetin methods other than query expansion in infor-mation retrieval.8 AcknowledgementsThe authors would like to thank Mr. TimothyBaldwin (TIT, Japan) for his comments on theearlier version of this paper, Dr. Chris Buck-Icy (Cornell Univesity) for the SMART support,and Mr. Satoshi Sekine (New York University)for the Apple Pie Parser support.Re ferencesJ.Y.
Chai and A. Biermann.
1997.
The use oflexical semantics in information extraction.In Proceedings of the Workshop in AutomaticInformation Extraction and Building of Lez-ical Semantic Resources, pages 61-70.J.M.
Gomez-Hidalgo and M.B.
Rodriguez.1997.
Integrating a lexical database and atraining collection for text categorization.
InProceedings o?
the Workshop in AutomaticInformation Extraction and Building o?
Lez-ical Semantic Resources, pages 39-44.D.
Hindle.
1990.
Noun classification frompredicate-argument structures.
In Proceed-IIIIII.IIIIIIIIIIIIIings of 28th Annual Meeting of the ACL,pages 268-275.G.A Miller.
1990.
Special issue, wordnet: Anon-line lexical database.
International Jour-nal of Lezicography, 3(4).J.
Morris and G. Hirst.
1991.
Lexical cohesioncomputed by thesaural relations as an indica-tor of the structure of text.
In Proceedings ofA CL Conference, pages 21--45.Qiu and H.P.
Frei.
1993.
Concept based queryexpansion.
In Proceedings of the 16th A CMSIGIR Conference, pages 160--169.P Pa~nik.
1995.
Disambiguating oun groupingwith respect o wordnet senses.
In Proceed-ings of 3rd Workshop on Very Large Corpora.R.
Richardson and A.F.
Smeaton.
1995.
Us-ing wordnet in a knowledge-based approachto information retrieval.
Technical ReportCA-0395, School of Computer Applications,Dublin City University..G. Salton.
1971.
The SMART Retrieval Sys-tem: Experiments in Automatic DocumentProcessing.
Prentice-Hall.F.
Segond, A. Schiller, G. Grefenstette, andJ.
Chanod.
97.
An experiment in semantictagging using hidden markov model tagging.In Proceedings ofthe Workshop in AutomaticInformation Extraction and Building of Lex-ical Semantic Resources, pages 78-81.S.
Sekine and R. Grishman.
1995.
A corpus-based probabilistic gr~rnrnar with only twonon-terminals.
In Proceedings of the Interna-tional Workshop on Parsing Technologies.A.F.
Smeaton and C. Berrut.
1995.
Runningtree-4 experiments: A chronological reportof query expansion experiments carried outas part of tree-4.
Technical Report CA-2095,School of Comp.
Science, Dublin City Univer-sity.M.A.
Stairmand.
1997.
Textual context analy-sis for information retrieval.
In Proceedings ofthe ~Oth A CM-SIGIR Conference, pages 140--147.E.M.
Voorhees and D. Harman.
1997.
Overviewof the fifth text retrieval conference (trec-5).
In Proceedings ofthe Fifth Text REtrievalConference, pages 1-28.
NIST Special Publi-cation 500-238.E.M.
Voorhees.
1993.
Using wordnet to disarn-biguate word senses for text retrieval.
In Pro-ceedings of the 16th A CM-SIGIR Conference,pages 171-180.E.M.
Voorhees.
1994.
Query expansion usinglexical-semantic relations.
In Proceedings ofthe 17th ACM-SIGIR Conference, pages 61-69.37
