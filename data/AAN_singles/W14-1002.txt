Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 2?6,Gothenburg, Sweden, April 27, 2014.c?2014 Association for Computational LinguisticsUsing Hypothesis Selection Based Features for Confusion Network MTSystem CombinationSahar GhannayLIUM, University of Le MansLe Mans, FranceSahar.Gannay.Etu@univ-lemans.frLo?
?c BarraultLIUM, University of Le MansLe Mans, Franceloic.barrault@lium.univ-lemans.frAbstractThis paper describes the development op-erated into MANY, an open source sys-tem combination software based on con-fusion networks developed at LIUM.
Thehypotheses from Chinese-English MT sys-tems were combined with a new version ofthe software.
MANY has been updated inorder to use word confidence score and toboost n-grams occurring in input hypothe-ses.
In this paper we propose either touse an adapted language model or addingsome additional features in the decoder toboost certain n-grams probabilities.
Ex-perimental results show that the updatesyielded significant improvements in termsof BLEU score.1 IntroductionMANY (Barrault, 2010) is an open source systemcombination software based on Confusion Net-works (CN).
The combination by confusion net-works generates an exponential number of hy-potheses.
Most of these hypotheses contain n-grams do not exist in input hypotheses.
Some ofthese new n-grams are ungrammatical, despite thepresence of a language model.
These novel n-grams are due to errors in hypothesis alignmentand the confusion network structure.
In section3 we present two methods used to boost n-gramspresent in input hypotheses.Currently, decisions taken by the decodermainly depend on the language model score,which is deemed insufficient to precisely evaluatethe hypotheses.
In consequence, it is interestingto estimate a score for better judging their qual-ity.
The challenge of our work is to exploit certainparameters defined by (Almut Siljaand and Vogel,2008) to calculate word confidence score.
Thesefeatures are detailed in section 4.
The approach isevaluated on the internal data of the BOLT project.Some experiments have been performed on theChinese-English system combination task.
Theexperimental results are presented in section 5.Before that, a quick description of MANY, includ-ing recent developments can be found in section 2.2 System descriptionMANY is a system combination software (Bar-rault, 2010) based on the decoding of a latticemade of several Confusion Networks (CN).
Thisis a widespread approach in MT system combina-tion, see e.g.
(Antti-Veikko I.Rosti and Schwartz,2007; Damianos Karakos and Dreyer, 2008; Shenet al., 2008; Antti-Veikko I. Rosti and Schw,2009).
MANY can be decomposed in two mainmodules.
The first one is the alignment modulewhich is a modified version of TERp (MatthewG.
Snover and Schwartz, 2009).
Its role is to in-crementally align the hypotheses against a back-bone in order to create a confusion network.
1-besthypotheses from all M systems are aligned in or-der to build M confusion networks (one for eachsystem considered as backbone).
These confusionnetworks are then connected together to create alattice.
This module uses different costs (whichcorresponds to a match, an insertion, a deletion,a substitution, a shift, a synonym and a stem)to compute the best alignment and incrementallybuild a confusion network.
In the case of confu-sion network, the match (substitution, synonym,and stem) costs are considered when the word inthe hypothesis matches (is a substitution, a syn-onym or a stem of) at least one word of the consid-ered confusion sets in the CN.
The second moduleis the decoder.
This decoder is based on the tokenpass algorithm and it accepts as input the latticepreviously created.
The probabilities computed inthe decoder can be expressed as follow :2log(Pw) =?i?ilog(hi(t)) (1)where t is the hypothesis, the ?iare the weights ofthe feature functions hi.The following features are considered for de-coding:?
The language model probability: the proba-bility given by a 4-gram language model.?
The word penalty: penalty depending on thesize (in words) of the hypothesis.?
The null-arc penalty: penalty depending onthe number of null-arcs crossed in the latticeto obtain the hypothesis.?
System weights: each system receives aweight according to its importance.
Eachword receives a weight corresponding to thesum of the weights of all systems which pro-posed it.Our goal is to include the following ones:?
Word confidence score: each word is given ascore, which is the combination of the threescores described in section 4 (equation 7).?
n-gram count: number of n-grams present ininput hypotheses for each combined hypoth-esis.In most cases, the new features have bestweights according to MERT (e.g.
the bestdecoding weights of these features by com-bining two systems are: lm-weight: 0.049703,word-penalty: 0.0605602, null-penalty: 0.319905,weight-word-score: -0.378226, weight-ngram-count: -0.11687, priors: 0.0141794#-0.0605561).3 boost n-gramsWe defined two methods to boost n-grams presentin input hypotheses.
The first one is adding thecount of bi or tri-grams like a new feature to thedecoder as mentioned in Section 2.
The secondmethod is using an adapted language model (LM)to decode the lattice, in order to modify n-gramsprobabilities, that have been observed in input hy-potheses.Language modelsThree 4-gram language models named LM-Web,LM-Tune and LM-Test, are used to interpolate theadapted LM.
They were trained respectively on theEnglish web Corpus and the system outputs : de-velopment and test sets (except their references)involved in system combination, using the SRILMToolkit (Stolcke, 2002).
The resulting model fromthe interpolation of LM-Tune and LM-Test is in-terpolated linearly with the LM-Web to build theadapted LM.
These models are tuned to minimizethe perplexity on the tune reference.4 Word confidence scoreThe best hypothesis selection relies on severalfeatures.
In (Barrault, 2011) decisions taken bythe decoder depend mainly on a n-gram languagemodel, but it is sometimes insufficient to evaluatecorrectly the quality of the hypotheses.
In orderto improve these decisions, some additional infor-mation should be used.
Several researches pre-sented some studies of confidence scores at wordand sentence level, such as (Almut Siljaand andVogel, 2008) and (Ueffing and Ney, 2007).
A largeset of confidence scores were calculated over then-best list.
(Almut Siljaand and Vogel, 2008) de-fines several features extracted from n-best lists (atthe sentence level) to select the best hypothesis ina combination approach via hypothesis selection.The challenge of our work is to exploit these fea-tures to estimate a confidence score at the wordlevel and injecting it into the confusion networks.The following features are considered:Word agreement score based on a windowof size t around position iThis score represents the relative frequency of hy-potheses in the n-best lists containing the word ein a window of size t around the position i.
It iscomputed as follows:WAk(ei,t) =1NkNk?p=0f(ep,i+tp,i?t, e) (2)whereNKis the number of hypotheses in the n-best list for the corresponding source sentence k,t={0, 1 or 2} and f(Sji, w) =1 if w appears in theword sequence Sji.When t equals 0, this means that i = t, then thisscore only depends on words at the exact positioni.
The agreement score is calculated accordingly:3WAk(ei) =1NkNk?p=0f(ep,i, e) (3)The two equations described above, are handledin our contribution, thus the final word agreementscore is the average between them if WAk(ei) 6= 0otherwise it is equal to WAk(ei,t) score.Position independent n-best List n-gramAgreementThis score represents the percentage of hypothe-ses in the n-best lists that contain the n-grameii?
(n?1), independently of its position in the sen-tence, as shown in Equation 4.
For each hypothe-sis the n-gram is counted only once.NAk(eii?
(n?1)) =1NkNk?p=0f(eii?
(n?1), eI1,p) (4)where f(eii?
(n?1), eI1,p) = 1 if the n-grameii?
(n?1)exists in the pthhypothesis of the n-bestlist.
We use n-gram lengths of 2 and 3 as two sep-arate features.The position independent n-best list word agree-ment is the average count of n-grams that containthe word e. It is computed as:NAk(ei) =1NngNng?n=0NAk(eii?
(n?1)) (5)Were Nngis the number of n-grams of hypothesisk.N-best list n-gram probabilityThis score is a traditional n-gram language modelprobability.
The n-gram probability for a targetword eigiven its history ei?1i?
(n?1)is defined as:NPk(ei|ei?1i?
(n?1)) =C(eii?(n?1))C(ei?1i?
(n?1))(6)Where C(eii?
(n?1)) is the count of the n-grameii?
(n?1)in the n-best list for the hypothesis k.The n-best list word probability NPk(ei) is the av-erage of the n-grams probabilities that contain theword e.The word confidence score is computed usingthese three features as follows:Sk(ei) =WAk(ei) +?j?NGNAk(ei)j+ NPk(ei)j1 + 2 ?
|NG|(7)where NG is the set of n-gram order, experimen-tally defined as NG={2-gram, 3-gram} and t = 2.Each n-gram order in the set NG is considered asa separate feature.5 ExperimentsDuring experiments, data from the BOLT projecton the Chinese to English translation task are used.The outputs (200-best lists) of eight translationsystems were provided by the partners.
The bestsix systems were used for combination.
Syscom-tune is used as development set and Dev as internaltest, these corpora are described in Table 1:NAME #sent.
#words.Syscomtune 985 28671Dev 1124 26350Table 1: BOLT corpora : number of sentences and wordscalculated on the reference.To explore the impact of each new feature onthe results, they are tested one by one (added oneby one in the decoder) then both, given that, theoldest ones are used in all cases.
These testsare named respectively boost-ngram, CS-ngram andBoost-ngram+CS-ngram later.The language model is used to guide the decod-ing in order to improve translation quality, there-fore we evaluated the baseline combination systemand each test (described above) with two LMs namedLM-Web and LM-ad and compared their perfor-mance in terms of BLEU.
By comparing their per-plexities, that are respectively 295.43 and 169.923,we observe a relative reduction of about 42.5%,that results in an improvement of BLEU score.Figure 1 shows the results of combining thebest systems (up to 6) using these models, thatachieved respectively an improvement of 0.85 and1.17 %BLEU point relatively to the best singlesystem.
In the remaining experiments we assumethat MANY-LM-Web is the baseline.Figure 2 shows interesting differences in howapproaches to boost n-gram estimates behavewhen the number of input systems is varied.
Thisis due to the fact that results are conditioned by thenumber and quality of n-grams added to the lattice42 3 4 5 614,514,751515,2515,515,7516 LM-Web LM-adSystemsBleuFigure 1: Performance (%BLEU-cased) of MANY afterreassessment by LM-Web and LM-ad on the test set.when the number of systems is varied, that pro-vides varied outputs.
In consequence, we observethat using the adapted LM is better than n-gramcount feature to boost n-grams, indeed it guaran-tees n-grams quality.2 3 4 5 614,514,751515,2515,515,7516 LM-WebLead Syyste2m aBebLelu?Syyste3m aBebLelu??
?stuBsS?u?Figure 2: Comparison of n-gram boost approaches.2 3 4 5 614,514,6314,7514,LL1515,1315,2515,3L15,515,6315,7515,LL16 M-W2eWb-WadS M-W2eyb-Wst M-W3eWb-WadSM-W3eyb-Wst ms dBlud?
?
?d?
?mBd?Figure 3: The impact of confidence score on the resultswhen using LM-Web and LM-ad for decoding.The 200-best lists are operated to estimate theword confidence score that contributes the most tothe improvement of results when several (up to 6)systems are combined, as described in Figure 3,whatever the language model used, compared tothe baseline.
In addition, it seems that the confi-dence score performs better with the adapted LMthan LM-Web.Systems BLEUBest single 14.36Sys2 14.21Sys3 13.76Sys4 13.52Sys5 13.36Sys6 12.99MANY+LM-Web(baseline) 15.14Boost-2gram+LM-Web 15.25Boost-3gram+LM-Web 15.50CS-2gram+LM-Web 15.32CS-3gram+LM-Web 15.26Boost-2gram+CS-2gram+LM-Web 15.39Boost-3gram+CS-3gram+LM-Web 15.78MANY+LM-ad 15.49Boost-2gram+LM-ad 15.24Boost-3gram+LM-ad 15.32CS-2gram+LM-ad 15.72CS-3gram+LM-ad 15.85Boost-2gram+CS-2gram+LM-ad 15.61Boost-3gram+CS-3gram+LM-ad 15.74Table 2: Impact of new features and the adapted LM on thecombination result of six systems.Table 2 summarizes the best experiments re-sults by combining the best six systems on the testset.
We observe that new features yield signifi-cant improvements in term of BLEU score what-ever the language model used for decoding.
Butit is clear that the adapted LM performs rela-tively well in comparison with LM-Web, so thebest gains achieved over the best single system andthe baseline are respectively 1.49 and 0.71 for CS-3-gram+LM-ad.6 ConclusionSeveral technical improvements have been per-formed into the MT system combination MANY,that are evaluated with the BOLT project data.An adapted LM and new features gave significantgains.
Previous experimental results show thatusing the adapted LM in rescoring together withword confidence score and the oldest features im-proves results in term of BLEU score.
This evenresults in better translations than using a classi-cal LM (LM-Web) trained on a monolingual trainingcorpus.5ReferencesHildebrand Almut Siljaand and Stephan Vogel.
2008.Combination of Machine Translation Systems viaHypothesis Selection from Combined N-Best Lists.Proceedings of the Eighth Conference of the Asso-ciation for Machine Translation in the Americas,pages 254?261.Spyros Matsoukas Antti-Veikko I. Rosti, Bing Zhangand Richard Schw.
2009.
Incremental Hypothe-sis Alignment with Flexible Matching for BuildingConfusion Networks: BBN System Description forWMT09 System Combination Task.
StatMT ?09Proceedings of the Fourth Workshop on StatisticalMachine Translation, pages 61?65.Spyros Matsoukas Antti-Veikko I.Rosti and RichardSchwartz.
2007.
Improved Word-Level SystemCombination for Machine Translation.
Proceedingsof the 45th Annual Meeting of the Association ofComputational Linguistics, pages 312?319.Lo?
?c Barrault.
2010.
MANY Open Source MachineTranslation System Combination.
The Prague Bul-letin of Mathematical Linguistics, pages 147?155.Lo?
?c Barrault.
2011.
MANY improvements forWMT?11.
Proceedings of the Sixth Workshop onStatistical Machine Translation, pages 135?
139.Sanjeev Khudanpur Damianos Karakos, Jason Eisnerand Markus Dreyer.
2008.
Machine TranslationSystem Combination using ITG-based Alignments.In 46th Annual Meeting of the Association for Com-putational Linguistics, pages 81?84.Bonnie Dorr Matthew G. Snover, Nitin Madnani andRichard Schwartz.
2009.
TER-Plus: Paraphrase,semantic, and alignment enhancements to transla-tion edit rate.
Machine Translation journal, pages117?127.Wade Shen, Brian Delaney, Tim Anderson, and RaySlyh.
2008.
The MIT-LL/AFRL IWSLT-2008 MTSystem.
In Internationnal Workshop on SpokenLanguage Translation, pages 69?76.Andreas Stolcke.
2002.
Srilm-an extensible lan-guage modeling toolkit.
In Proceedings Interna-tional Conference for Spoken Language Processing,Denver, Colorado.Nicola Ueffing and Hermann Ney.
2007.
Word-Level Confidence Estimation for Machine Transla-tion.
Computational Linguistics journal, pages 9?40.6
