Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 737?740,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsBitext-Based Resolution of German Subject-Object AmbiguitiesFlorian Schwarck Alexander FraserInstitute for Natural Language ProcessingUniversity of Stuttgart{koehlefn,fraser}@ims.uni-stuttgart.deHinrich Schu?tzeAbstractWe present a method for disambiguating syn-tactic subjects from syntactic objects (a fre-quent ambiguity) in German sentences takenfrom an English-German bitext.
We exploitthe fact that subject and object are usually eas-ily determined in English.
We show that asimple method disambiguates some subject-object ambiguities in German, while makingfew errors.
We view this procedure as the firststep in automatically acquiring (mostly) cor-rect labeled data.
We also evaluate using it toimprove a state of the art statistical parser.1 IntroductionAmbiguity of grammatical role is a problem whenparsing a number of natural languages.
In German,subject-object ambiguities are frequent.
The sen-tence ?Die Maus jagt die Katze?
?the ?
mouse ?chases ?
the ?
cat?
exhibits such an ambiguity.
Be-cause word order is freer in German than in English,the sentence has two possible meanings: (i) The catis chasing the mouse and (ii) the mouse is chasingthe cat.
We exploit the fact that such ambiguities aremuch less frequent in languages that possess a lessflexible syntax than German.
In English, the trans-lation of the sentence ?Die Maus jagt die Katze?
isnot ambiguous.
If we have access to this translation,we can use this information to disambiguate the Ger-man sentence.
The English translation is viewed asa surrogate for both contextual knowledge from thetext and for world knowledge.We present a method for disambiguating the sub-ject and object roles in German sentences.
We usean English-German bitext and exploit the fact thatsubject and object roles are rarely ambiguous in En-glish.
Using a new gold standard we created weshow that our method disambiguates a significantproportion of subject-object ambiguities in Germanwith high precision.
We view this procedure as thefirst step in automatically acquiring (mostly) correctlabeled data for training a statistical disambiguatorthat can be used on German text (even when notranslation is available).
In addition to measuringalgorithm performance directly, we present experi-ments on improving the disambiguation of BitPar, astate of the art statistical parser.2 AlgorithmData and Word Alignment.
We use the alignedEnglish and German sentences in Europarl (Koehn,2005) for our experiments.
The corpus contains longand complex sentences.
To establish translationalcorrespondence between parallel sentences we useGIZA++ (Och and Ney, 2003).
Its input is a tok-enized parallel corpus.
We lemmatized the text priorto aligning it.Procedure.
Figure 1 shows the architecture ofour system.
The boxes signify data sets, while thelines are processes applied to the data sets.
The pa-per presents two applications.
The first is the cre-ation of a set of disambiguated German sentences(which involves word alignments in the upper rightcorner, and the use of parsers in the middle of thegraphic).
We also present a reranking of the N -bestparses produced by BitPar (Schmid, 2004), a state ofthe art statistical parser (bottom of the graphic).For processing of German we chose FSPar737Figure 1: System Architecture(Schiehlen, 2003), a fast shallow dependency parser.FSPar has extensive lexical knowledge which helpsit to find subject-object ambiguities with high accu-racy, but it does not try to resolve such ambiguities.The key to our approach is to project syntacticroles from English text.
For English parsing we usedMINIPAR (Lin, 1998).Based on FSPar?s analysis, all German sentenceswith a subject-object ambiguity (about a third) wereselected from EuroParl.
The parallel English sen-tences were parsed with MINIPAR.Words marked as ambiguous by FSPar were thenprocessed using our algorithm.
If an ambiguousGerman word was aligned to an English word thatMINIPAR had (unambiguously) assigned the gram-matical role of subject or object, then the syntacticrole of the German word was defined by this infor-mation, see Figure 2.Figure 2: Disambiguation AlgorithmWe used standard heuristics for improving wordalignment (Och and Ney, 2003; Koehn et al, 2003),but there were many misalignments of ambiguousGerman words.
In order for the procedure to work,we require that the German word to be disam-biguated be aligned to the English subject or object.For this reason, we implemented second guessingbased on a dictionary that lists for every Germanword the 10 most frequently aligned English words(found using the word alignment of all of Europarl).If an ambiguous German word was either unalignedor not aligned to the English subject or object, it waschecked whether a dictionary translation was part ofthe parallel sentence and marked as subject or ob-ject by MINIPAR.
If so, this dictionary word wasused for disambiguation.3 EvaluationGold Standard.
We had access to a small set ofgold standard parses (Pado?
and Lapata, 2009), butdecided to create a larger corpus.
We found that FS-Par had acceptable performance for finding subject-object ambiguities1.
The syntactic roles of wordsmarked as ambiguous by FSPar were annotated.Four annotators annotated the syntactic roles in 4000sentences using a graphical user interface (GUI).The GUI showed the ambiguous words in contextand gave the annotator four different subject-objectlabels to choose from for each ambiguous word:subject, object, expletive es and none.
Because thesyntactic expletive ?es?
(English gloss: ?it?)
is fre-quent in German, as in ?es scheint zu regnen?
?itappears to be raining,?
we created a separate labelfor expletive ?es?, which is not treated as a subject.2The statistics are shown in table 1.1000 sentences were annotated by all four an-notators.
Inter-annotator agreement was sufficient(?
= 0.77 on average (Carletta, 1996)).Evaluation Measures.
The output of our algo-rithm labels each word that FSPar classified as am-biguous with one of the three possible labels subject,1FSPar has a very high precision in detecting subject-objectambiguities, as can be seen in Table 1 (approximately 0.955,the sum of two left columns divided by sum of all cells).
Wetried to get an idea of recall using the smaller gold standard.We made conservative assumptions about recall errors whichwe manually checked on a small sample, details are omitted.Using these assumptions led to an estimate for recall of 0.733,but true recall is likely higher.2German ?es?
is also frequently used as a non-expletive,where it can take a syntactic role.738subj obj expl es noneAnnotator1 4152 3210 115 150Annotator2 4472 3359 92 226Annotator3 4444 3584 42 155Annotator4 4027 3595 9 650Table 1: Annotator decisions on the full gold standardDE2EN Refined GDFA IntersectionnosgP 0.8412 0.8381 0.8353 0.8551R 0.4436 0.3856 0.3932 0.3380F1 0.5809 0.5282 0.5347 0.4845sgP 0.7404 0.7307 0.7310 0.7240R 0.5564 0.4873 0.4946 0.4528F1 0.6353 0.5847 0.5900 0.5571filter-nosgP 0.9239 0.9203 0.9192 0.9277R 0.3940 0.3397 0.3461 0.2984F1 0.5524 0.4962 0.5028 0.4515filter-sgP 0.8458 0.8358 0.8369 0.8290R 0.4839 0.4213 0.4279 0.3898F1 0.6156 0.5602 0.5662 0.5302Table 2: Precision, Recall and F1 of the algorithm.object and no decision3.
We use the standard evalua-tion metrics Precision (P , the percentage of subjectand object labelings in our hypothesis that are cor-rect), Recall (R, the percentage of subject and ob-ject labelings in the gold standard that are correctlylabeled in the hypothesis), and balanced F (F1).4 ExperimentsAlgorithm Performance.
Table 2 shows the perfor-mance of our algorithm when evaluated against themanual annotation4.
The lines nosg, sg, filter-nosgand filter-sg denote different configurations of the al-gorithm: Second guessing (section 2) was (?sg?)
orwas not (?nosg?)
applied and filtering was (?filter?
)or was not applied.
The filter increases precision byonly keeping labels of subjects and objects that oc-cur in the default order (e.g., the subject is to theleft of the object in the main clause).
As an aid tothe user, FSPar presents such a determination of de-fault order depending on its classification of clausetype5.
The columns indicate the heuristic postpro-3If expletive es or none was annotated, the system is correctif it does not make a decision.4Because of problems with BitPar caused by preprocessingfor FSPar, we use 11,279 sentences of the 13,000 annotated.5Using this determination alone results in P 0.7728 R 0.8206F 0.7960, very high recall but low precision.configuration P R F11 top-1 (no change) 0.8088 0.8033 0.80602 relabeling nosg 0.7998 0.8176 0.80863 relabeling filter-nosg 0.8229 0.8344 0.82864 reranking nosg 0.8082 0.8123 0.81025 reranking filter-nosg 0.8145 0.8143 0.8144Table 3: Precision, Recall and F1 of changing BitPar de-cisions, DE2EN alignmentcessing we applied to GIZA++?s alignment.
DE2ENis the 1-to-N alignment calculated using German asthe source language and English as the target lan-guage (i.e., each English word is linked to exactlyzero or one German words).As we see in table 2, with the most strict setup,filter-nosg, the algorithm resolves subject-objectambiguities with a precision of more than 92%but the best recall is only 39.4%, obtained usingDE2EN.
Second guessing increases recall but leadsto losses in precision.
The best precision result with-out the filter is 85.5%.Improving BitPar?s Subject-Object Decisions.For improving BitPar (which always tries to disam-biguate subject-object), our baseline is the accuracyof the most probable parse shown in table 3, row 1.Using the most probable parse from BitPar, werelabel a word ?subject?
or ?object?
if our systemindicates to do so.
With the algorithm alone we areable to improve recall (table 3, row 2).
When we addthe filter both precision and recall are improved (row3).
This experiment measures the improvement pos-sible if our syntactic role information were directlyintegrated as a hard constraint into a parser (see sec-tion 5).We now perform a simple reranking experiment,using BitPar?s 100-best parses.
For each sentencewe choose the parse which agrees with as many ofthe subject/object decisions of the algorithm as pos-sible (once again ignoring words where the algo-rithm chooses no decision).
In case of ties in thenumber of agreements, we take the most probableparse.
The results are in rows 4?5.
Reranking in-creases F1 by about 0.8%.5 Related WorkSyntactic projection has been used to bootstrap tree-banks in resource poor languages (Yarowsky and739Ngai, 2001; Hwa et al, 2005).
In contrast with suchwork, we are addressing subject-object ambiguity inGerman.
German parsers have no access to the con-textual and world knowledge necessary to resolvethis ambiguity.Work on projecting semantic roles (Pado?
and La-pata, 2009; Fung et al, 2007) requires both syntac-tic parsing and semantic role labeling and is con-cerned with filling in the complete information in asemantic frame.
Our approach is simpler and con-cerned only with syntactic disambiguation, not se-mantic projection.
We focus only on difficult casesof subject-object ambiguity and although we do notalways make a prediction, we obtain levels of pre-cision that projection approaches making no use ofknowledge of German syntax cannot achieve.In bitext parsing, Burkett and Klein (2008) andFraser et al (2009) used feature functions defined ontriples of (parse tree in language 1, parse tree in lan-guage 2, word alignment), combined in a log-linearmodel trained to maximize parse accuracy, requir-ing translated treebanks.
We focus only on subject-object disambiguation in German, and annotated anew gold standard.
We work on sentences that apartial parser has determined to be ambiguous.
Fos-sum and Knight (2008) and Huang et al (2009) im-prove English prepositional phrase attachment usingfeatures from an unparsed Chinese sentence.
Thelatter work integrated the PP-attachment constraint(detected from the Chinese translation) directly intoan English shift-reduce parser.
As we have shownin the labeling experiment, integrating our subject-object disambiguation into BitPar could result in fur-ther increases beyond 100-best reranking.6 ConclusionWe demonstrated the utility of bitext-based disam-biguation of grammatical roles.
We automaticallycreated a large corpus of 164,874 disambiguatedsubject-object decisions with a precision of over92%.
This corpus will be of use in future researchon syntactic role preferences and for the trainingof monolingual subject-object disambiguators.
Wepresented a prototype application of subject-objectdisambiguation through a simple reranking of the100-best list output by BitPar, and showed a possiblefurther improvement if integrated in the parser.
Thenew gold standard, which is publicly available, willhopefully be useful for work on both monolingualand bitext-based disambiguation.AcknowledgmentsThis work was supported by Deutsche Forschungs-gemeinschaft grants SFB 732 and MorphoSynt.ReferencesDavid Burkett and Dan Klein.
2008.
Two languages arebetter than one (for syntactic parsing).
In EMNLP.Jean Carletta.
1996.
Assessing agreement on classifi-cation tasks: The kappa statistic.
Computational Lin-guistics, 22.Victoria Fossum and Kevin Knight.
2008.
Using bilin-gual Chinese-English word alignments to resolve PP-attachment ambiguity in English.
In AMTA.Alexander Fraser, Renjing Wang, and Hinrich Schu?tze.2009.
Rich bitext projection features for parse rerank-ing.
In EACL.Pascale Fung, Zhaojun Wu, Yongsheng Yang, and DekaiWu.
2007.
Learning bilingual semantic frames: Shal-low semantic parsing vs. semantic role projection.
InTMI.Liang Huang, Wenbin Jiang, and Qun Liu.
2009.Bilingually-constrained (monolingual) shift-reduceparsing.
In EMNLP.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Nat.
Lang.
Eng., 11(3).Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In HLT-NAACL.Philipp Koehn.
2005.
Europarl: a parallel corpus forstatistical machine translation.
In MT Summit X.Dekang Lin.
1998.
Dependency-based evaluation ofMINIPAR.
In Workshop on Eval of Parsing Systems.Franz J. Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1).Sebastian Pado?
and Mirella Lapata.
2009.
Cross-lingualannotation projection of semantic roles.
Journal of Ar-tificial Intelligence Research, 36:307?340.Michael Schiehlen.
2003.
A cascaded finite-state parserfor German.
In Research Notes (EACL).Helmut Schmid.
2004.
Efficient parsing of highly am-biguous context-free grammars with bit vectors.
InCOLING.David Yarowsky and Grace Ngai.
2001.
Inducing multi-lingual POS taggers and NP bracketers via robust pro-jection across aligned corpora.
In NAACL.740
