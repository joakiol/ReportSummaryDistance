Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 2205?2216, Dublin, Ireland, August 23-29 2014.Limitations of MT Quality Estimation Supervised Systems:The Tails Prediction ProblemErwan MoreauCNGL and Computational Linguistics GroupCentre for Computing and Language StudiesSchool of Computer Science and StatisticsTrinity College DublinDublin 2, Irelandmoreaue@cs.tcd.ieCarl VogelComputational Linguistics GroupCentre for Computing and Language StudiesSchool of Computer Science and StatisticsTrinity College DublinDublin 2, Irelandvogel@cs.tcd.ieAbstractIn this paper we address the question of the reliability of the predictions made by MT QualityEstimation (QE) systems.
In particular, we show that standard supervised QE systems, usuallytrained to minimize MAE, make serious mistakes at predicting the quality of the sentences in thetails of the quality range.
We describe the problem and propose several experiments to clarifytheir causes and effects.
We use the WMT12 and WMT13 QE Shared Task datasets to prove thatour claims hold in general and are not specific to a dataset or a system.1 IntroductionMachine Translation (MT) Quality Estimation (QE) has become an important subject of study in the pastfew years (Callison-Burch et al., 2012; Bojar et al., 2013).
This follows directly from the erratic qualityof MT output in general: although MT is now widely used in professional contexts, it is still prone tomany errors; therefore a careful post-editing stage, performed by human experts, is usually needed.
Inthis context, QE can help carrying out this process more efficiently, and more specifically to help inthe decision process between the automatic and the manual stages: if a reliable indication of quality isprovided for every machine-translated sentence, the human effort can be reduced.
For example, a verybad translation is worthless because the translator usually has to spend more time fixing it than she or hewould have spent translating the sentence from scratch; thus it makes more sense in such cases to eithersend the sentence back to an alternative MT system (e.g.
trained on a different corpus), or simply leaveit untranslated for the translator.
Clearly the advantage of using a QE system depends on the reliabilityof its predictions.
If it makes too many errors, then it only confuses the translation workflow; in this casethe translators would perform better without it.The quality of an (automatic) QE system cannot be perfect, but it should be at least controllable.
Thatis, it should be possible to assess the reliability of the predictions made by a system, for instance byestimating the level of confidence of the predictions.
Hopefully, QE systems will progress towards thiskind of behaviour, but currently the evaluation methods are not entirely satisfactory from this perspective.In particular, after describing our experimental setting in ?2, we will observe in ?3 that the use of theMean Absolute Error1(MAE) as a global evaluation measure hides huge discrepancies in the distributionof errors among the range of scores.
More precisely, supervised systems optimized to minimize the MAEhave intrinsic flaws in the way they assess the tails of the quality range, i.e.
the ?very good?
and the ?verybad?
sentences.
In ?4 we propose different ways to evaluate the impact of this problem, and also clarifywhat might be an important misunderstanding in what a QE system actually does (?4.2).
Finally wepropose in ?5 several experiments: in ?5.1 we show that the problem is not system-specific, and we testtwo ways to circumvent it in ?5.2 and ?5.3, but the price to pay in global performance is high.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/1The MAE is defined as the mean over all instances of the absolute error, where the absolute error is the absolute value ofthe difference between the predicted and the actual value of the instance.
Thus, the MAE score depends on the range of possiblevalues (i.e., two datasets using different ranges cannot be compared).22052 Experimental Setup2.1 DataIn this paper we use the three datasets from the WMT12 and WMT13 QE Shared Task (Callison-Burchet al., 2012; Bojar et al., 2013) which are intended to predict the quality of individual machine-translatedsentences: the WMT12 task and the WMT13 task 1.1 and 1.3.
The last two datasets are renamed wmt13aand wmt13b in the rest of this paper.
These three datasets differ by the way quality is measured:?
wmt12: effort scores, which have been assigned by three professional post-editors according topredefined guidelines; scores range from 1: ?the MT output is incomprehensible [..]?
to 5: ?theMT output is perfectly clear [..]?.
The dataset was cleaned to avoid the cases with a high level ofdisagreement, and the scores were post-processed to harmonize the scale between the judges.?
wmt13a: HTER scores, which measure the distance between the MT output and the post-editedsentence (Snover et al., 2006).?
wmt13b: post-editing time, that is, the time that the post-editor has spent correcting the MT output.As a consequence, the set of scores have different characteristics: in wmt12, the distribution is highlydiscrete due to the integer values assigned by the judges.
In wmt13a the distribution is more dense,whereas in wmt13b some values are spread extremely far from the mean.2General statistics for thedatasets are given in table 1.
In all datasets the input and MT output sentences are available to the system;the post-edited version of the sentences is also available, but it cannot be used by the QE systems (thetest set post-edited sentences were provided only after the end of the task).
We focus on predictingan absolute indication of quality rather than only ranking the sentences by quality; this is why we usethe Mean Absolute Error (MAE) as the main evaluation measure rather than Spearman?s correlation orDeltaAvg (Callison-Burch et al., 2012).2.2 Supervised QE SystemIn the observations and experiments described in this paper we use a QE system which follows a standardsupervised learning approach: it was trained on the full training set for every task considered; when theperformance on the training set is observed, it was assessed using 10-fold cross-validation (thus obtaininga prediction for every sentence in the train set based on a 90% subset).
We have used Quest3(Shah etal., 2013), an open-source tool for QE, to compute the 17 ?black box features?
which are also used in theWMT QE ?baseline?
system (see below).
We have used Weka (Hall et al., 2009) (version 3.6.10), andafter testing several options4we found that using the SMOreg algorithm (Smola and Sch?olkopf, 2004;Shevade et al., 2000) with an RBF kernel5was optimal with respect to the performance on the threedatasets.We did not perform any feature selection or parameter tuning, because our main goal was to build ageneric system.
Additionally we favor the ease of reproducibility over optimal performance, which is outof the scope of this paper.
We want our system to be as generic as possible (but still performing decently,of course), because we need it to be fairly representative of standard, state-of-the-art, supervised learningQE systems.
This is very important, since our observations and experiments are supposed to generalizeto the current most common approaches in QE.Our task of making the system representative of state-of-the-art QE systems has been greatly facilitatedby the fact that the organizers of the WMT12 and WMT13 QE Shared Task provide for every task theperformance of a so-called ?baseline system?.
We can use exactly the same set of features and comparethe results of our system against these obtained by this baseline system, which in turn does not deserve2This is why we exclude the most striking outlier from the training set: 1115.906, line 294.
The test set is left unchanged.3http://staffwww.dcs.shef.ac.uk/people/L.Specia/projects/quest.html ?
last verified 05/14.4In particular, M5P regression trees generally achieve nearly as good performance as SVM regression.
We have alsoobserved that at least the most important characteristics reported in this paper for an SVM system hold for M5P regression aswell.5With the default value C=1 and standardization of the features values.2206its name since it has actually always performed well in every task: it ranked 8th out of 20 in the WMT12official ranking, 12th out of 17 in WMT13a, and 6th out of 14 in WMT13b (MAE ranking).
Thus, wecan simply check that our system performs as well as this baseline system to ensure that it is equivalent,and therefore probably reasonably similar to the other supervised systems submitted to the Shared Taskswhich perform similarly.6Table 1 shows that our system performs roughly the same as the baselinesystem on the three datasets.Range Statistics Performance (test set)Dataset of Quality Train set Test set Our system Baseline systemvalues direction instances mean std.
dev.
instances mean std.
dev.
cor.
MAE cor.
MAEwmt12 [1, 5] ?
1832 3.44 0.88 422 3.29 0.98 0.56 0.69 0.58 0.69wmt13a [0, 1] ?
2254 0.32 0.17 500 0.26 0.19 0.44 0.15 0.46 0.15wmt13b [0,+ inf[ ?
802 95.6 84.2 284 116.9 108.3 0.70 50.9 0.70 51.9Table 1: Datasets: statistics and performance.
Quality direction: ?
means that the quality is betterwhen the score is higher,?
means the opposite; ?cor.?
is the Spearman?s correlation.3 The Tails Prediction ProblemIn this section we mostly observe the training set (using cross-validation), in order to dismiss the possi-bility that the observed phenomenon is caused by the differences in the distributions of scores betweenthe training set and the test set.
Since it is easier for a supervised learning algorithm to annotate somedata from the set it was trained on than from a different dataset, problems which appear with the formerare very likely to appear as well (possibly accentuated) with the latter.23451 2 3 4 5goldpredict(a) wmt12.
Spearman cor.
: 0.530.20.30.40.50.00 0.25 0.50 0.75 1.00goldpredict(b) wmt13a.
Spearman cor.
: 0.3701002000 100 200 300 400 500goldpredict(c) wmt13b.
Spearman cor.
: 0.62Figure 1: Scatter plots showing how predicted scores differ from gold scores (test set).
Every point(X,Y) corresponds to one sentence for which X is the gold score and Y the predicted score.
Darkerareas correspond to more dense areas; the vertical and horizontal lines indicate the frontiers of 20%-quantiles for both variables (for instance, the points which are on the right side of the rightmost verticalline account for the 20% highest gold scores).
Remark: a few outliers are not visible on the wmt13b plot(their gold scores are higher than 500, and their predicted scores are lower than 250).Figure 1 shows that the points are very scattered and do not follow the diagonal very closely, butalso that the range of predicted scores is significantly different from the range of gold scores: no sen-tence is predicted below 2 for wmt12, above 0.55 for wmt13a and above 260 for wmt13b, whereas thecorresponding range of gold scores is much wider.
Figure 2, which shows the distribution of gold vs.predicted scores for the training sets, gives a more precise picture of this difference: in all three datasets,the predicted scores tend to belong to a smaller set of values centered approximately around the mean.There are clearly more predicted values than gold values in this area, and this is confirmed by the muchsmaller standard deviation for the predicted scores.It is possible to obtain a clearer picture by ?flattening?
the distribution, that is, instead of drawinghistograms in which points with the same value (or a close value) are accumulated, we represent every6In section 5.1 we also check more specifically that our observations hold for most of the systems submitted to WMT12.220701002003001 2 3 4 5scorecount groupgoldpredict(a) wmt12.
?G= 0.88, ?P= 0.5001002003004000.00 0.25 0.50 0.75 1.00scorecount groupgoldpredict(b) wmt13a.
?G= 0.17, ?P= 0.070501001500 200 400 600scorecount groupgoldpredict(c) wmt13b.
?G= 84.2, ?P= 46.5Figure 2: Combined distributions of the gold scores and predicted scores on the training set for thethree datasets.
?G(resp.
?P) is the standard deviation for gold (resp.
predicted) scores.point on the X axis and sort the values on this axis, so that their actual value can be observed on the Y axis,as shown on figure 3.
This figure shows that, in all three cases, the predicted scores are tightly clusteredaround the median, which is the point where the two curves cross each other.
If the system predictedscores according to the distribution it observed on the training set, the two curves would be close; instead,they clearly diverge from each other as the distance to the median increases.
This means that the modeltends globally to overestimate the points below the median and, symmetrically, underestimate the pointsabove the median (though the symmetry is degraded in 3c, since the range is unbound to the right).In figure 3 the two sets of points are sorted independently: the sentence (x, y) on the curve of goldscores is different from the one with the same x on the curve of predicted scores.
Yet this observationof ?tightened?
predicted scores cannot be fully understood without taking into account the risk of errorin the prediction process, as it was visible on the scatter plots in figure 1.
Thus it is also useful to lookat the sorted scores, but with their corresponding predicted score (for the same sentence) plotted on thesame x coordinate; this what is shown on figure 4, for the wmt13a dataset only (because the phenomenonis the most accentuated in this dataset, and scores conveniently belong to [0, 1]).
On figure 4a one cansee that the set of predicted scores are mostly contained in a slightly inclined rectangle; clearly they donot follow the curve of gold scores, but here one can see why: the fact that there are many points at thesame level on the Y axis along the whole X axis shows that the algorithm cannot make a clear distinctionbetween the different levels of quality.
For example, there are approximately as many scores predictedaround 0.3 which correspond to actually very good (rank near 0) and very bad sentences (rank near 1).From a different perspective, figure 4b shows very clearly that the farther the gold score of a sentence isfrom the mean (0.32), the more likely it is to be predicted with a large error.23450.00 0.25 0.50 0.75 1.00rankscore seriesgoldpredict(a) wmt120.000.250.500.751.000.00 0.25 0.50 0.75 1.00rankscore seriesgoldpredict(b) wmt13a01002003004000.00 0.25 0.50 0.75 1.00rankscore seriesgoldpredict(c) wmt13bFigure 3: Sorted gold and predicted scores for the three datasets.
The two sets of scores are sortedindependently.
The X axis is the normalized rank (0 to 1 instead of 1 to the total number of sentences),so that it is easier to observe the quantiles.
Example: for wmt13a, the lowest fourth of gold scores rangesfrom 0 to around 0.20, whereas the lowest fourth of predicted scores ranges from 0.125 to around 0.27.Remark: on the wmt13b plot the scores higher than 400 are not visible (all are gold scores).22080.000.250.500.751.000.00 0.25 0.50 0.75 1.00rankscore groupgoldpredict(a) Gold scores as reference.
Sentences are sorted by theirgold score; the X axis gives their corresponding rank; thepredicted score of a sentence is plotted on the same abscissa,thus showing both the gold (in red) and predicted score (inblue) of the sentence on the Y axis.
The predicted scoreswhich appear on the same vertical line correspond to differentsentences which have the same (or very close) gold scores.0.000.250.500.751.000.00 0.25 0.50 0.75 1.00rankscore groupabsErrgold(b) Absolute error as reference.
Sentences are sorted bytheir absolute error; the X axis gives their correspondingrank; the gold score of a given sentence is plotted on the sameabscissa, thus showing both the error (in red) and gold score(in blue) of the sentence on the Y axis.
The gold scores whichappear on the same vertical line correspond to different sen-tences which have the same (or a very close) absolute error.Figure 4: wmt13a, training set: sentences sorted by gold score (left) or absolute error (right).The issue is constant among the datasets, but with a variable impact.
To some extent, it could besummarized in the following way: it appears that the system does not try to predict the actual qualityof the sentences, but instead applies a simple optimization strategy; since a large majority of sentencesbelong to a relatively small range of values in the middle of the full possible range of scores, predictingany score outside this range is taking a big risk.
Consequently it is safer, in order to minimize the errorrate, to ignore (or barely take into account) the rare cases which belong to the tails.
Hence the systemends doing the opposite of what is usually expected from a quality estimation system: the most commoncases are rather accurately recognized, but the most striking anomalies are left undetected or poorlylabelled as such.
This behaviour can be explained by the following reasons:7?
The supervised learning optimization criterion is very often the minimization of the MAE,8as in our system.
This leads the algorithm to favor the interval of scores where there are manyinstances, since their weight is more important in the average.?
The datasets are unbalanced, which is certainly realistic in terms of application, but it also en-courages the algorithm to assign scores in the interval which would be the ?default class?
in aclassification problem; that is, without any clear indication in the features, it is strategically wiserto bet on the most probable answer.?
The risk is lower with respect to MAE to assign a score in the middle of the range of possiblevalues rather than at the extremes.
For instance if the range is [1, 5] the maximum absolute error at3 is 2, whereas it is 4 at 1 or 5.
However, at least for wmt13a, the data shows that, if this hypothesishad a real impact, the predicted scores would be closer to 0.5 than to the mean 0.32.4 Detecting and Evaluating the Tails Quality4.1 Possible MeasuresWe propose below different measures intended to evaluate the impact of the tails prediction problem.Since it can be defined as an increased level of error for sentences which are far from the mean, a simplefirst measure is the correlation between the distance from the gold score to the mean and the absoluteerror: this value reflects whether the errors are higher in the tails than close to the mean and to whatextent (in other words, it measures how strong the divergence observed on the right part of figure 4b is).Table 2 shows how high Pearson?s correlation is in our data.A simple way to measure the performance locally in the tails is to consider the task as a binary classi-fication problem, as if we were only interested in recognizing whether a sentence belongs to a particular7The first two reasons are actually closely related, they only show different aspects of the same problem.8Especially in the WMT QE tasks, since this is the main evaluation measure for the scoring task.2209wmt12 wmt13a wmt13btrain test train test train testall > 0 < 0 all > 0 < 0 all > 0 < 0 all > 0 < 0 all > 0 < 0 all > 0 < 00.58 0.54 0.64 0.62 0.64 0.65 0.82 0.84 0.78 0.76 0.86 0.76 0.80 0.89 -0.18 0.83 0.91 -0.01Table 2: Correlation between the absolute error and the distance to the mean of the gold score.
?> 0?
(resp.
?< 0?)
is the correlation when taking only into account the scores above (resp.
below) themean; this gives a more precise picture for the top/bottom quality scores.
For example, in wmt13b thetop quality (lowest) scores are very well predicted, as opposed to the bottom quality (highest) scores.subset of scores.
For example, the frontier between the classes can be fixed between the 90% lowestscores (negative) and the 10% highest (positive): it is then possible to observe the last 10% using thestandard evaluation measures: precision (proportion of true positive among the sentences labeled aspositive), recall (proportion of sentences labeled as positive among all positive sentences) and F1-score(harmonic mean of the precision and recall).9The values of these measures are given for three thresh-olds in table 3.
As expected, the recall is extremely low in the tails; it is even 0 in most cases for the5% threshold, which means that the system does not assign any score in the 5% top/bottom of the rangeobserved on the training data.Data+tail 5% 10% 20%limit P R F1 limit P R F1 limit P R F1wmt12 B ?
2.0 ?
0.0 ?
?
2.3 0.33 0.01 0.02 ?
2.7 0.73 0.16 0.26T ?
5.0 ?
0.0 ?
?
4.7 0.50 0.02 0.04 ?
4.2 0.65 0.18 0.28wmt13a B ?
0.62 ?
0.0 ?
?
0.54 ?
0.0 ?
?
0.47 0.62 0.11 0.19T ?
0.06 ?
0.0 ?
?
0.11 ?
0.0 ?
?
0.17 0.50 0.01 0.01wmt13b B ?
272 ?
0.0 ?
?
186 0.76 0.26 0.39 ?
134 0.71 0.43 0.54T ?
18.2 0.5 0.05 0.09 ?
24.8 0.18 0.06 0.10 ?
35.7 0.52 0.30 0.38Table 3: Local classification measures (test set).
?T?
(resp.
?B?)
refers to the top (resp.
bottom)quality tail; P/R/F1 are the standard Precision/Recall/F1-score.10Example: 10% of the scores for thewmt12 training data are higher than 4.7 (top quality tail); among the gold scores in the test set which arehigher than this 4.7 threshold, only 2% are predicted as higher than 4.7 (recall); and among the scorespredicted as higher than 4.7, exactly 50% are actually higher than 4.7 (precision).Additionally, we have separately proposed a measure which aims to evaluate the ranking error locally(Moreau and Vogel, 2013).
The same idea can be applied to scoring errors: the Local MAE (LMAE)can be computed on a particular range of scores.
The difference with global MAE is that, for a givensentence, the gold score or the predicted score can belong to the range while the other does not.
This iswhy there are two versions of this measure: gold-based LMAE and prediction-based LMAE, which, astheir names suggest, take into account only the gold scores (resp.
predicted scores) which belong to therange in the absolute difference | gold?
predicted |, as defined in definition 4.1.Definition 1 (Local MAE (LMAE)).
Let S be a set of sentences, and D the interval of possible scores:9In the observations which follow we choose to set the limits (5%, etc.)
based on the training set even though the test setis observed.
In other words, the absolute score corresponding to the percentage is calculated using the training set gold scores,which might differ from the value calculated from the test set.
The disadvantage is that the number of values in the test set inthe corresponding range does not necessarily correspond to the percentage, but this way the limits do not depend on the test set,so that values obtained on different test sets would be comparable.10We consider theN% limits computed from the range of gold scores, and not from the range of predicted scores: this makesmore sense because otherwise the system is not evaluated against the actual scores in the tails, but since the range of predictedscores is actually smaller than the range of gold scores, sometimes there are no predicted scores at all in this range of values(especially for the lowest values of N , e.g.
5%).
For example in the wmt12 dataset 5% of the gold scores are below 2, but thesystem does not predict any value below 2.
In such a case we consider that this is equivalent to a classifier which decides not tolabel any instance in a given category.
Since there are no instances labelled as positive at all, the precision is undefined, whichmakes the F1-score undefined as well.
The corresponding cells are marked as ???
in tables 3 and 6.2210for every sentence s ?
S, predicted(s) ?
D, gold(s) ?
D. For any subinterval I ?
D:11LMAEgold= mean( {??gold(s)?
predicted(s)????
?s such that gold(s) ?
I} )LMAEpred= mean( {??gold(s)?
predicted(s)????
?s such that predicted(s) ?
I} )To some extent, the gold-based LMAE (resp.
prediction-based) is similar to a recall measure (resp.precision) because it takes into account the true positive and the false negative (resp.
the true positive andthe false positive) with respect to the range.
This can be observed in table 4, which gives the values ofthese two measures for three thresholds on the three datasets: LMAEgoldis almost always much higherthan the global MAE, whereas there LMAEpredis often close to or lower than the global MAE.
This isbecause, compared to the gold scores, the top or bottom predicted scores are closer to the centre of therange.
Therefore the sentences taken into account include some actual ?tails sentences?
(for which theabsolute error is high), but they can also contain many sentences which actually belong to the area (forwhich the absolute error is low).5% 10% 20%Data+tail (Global) MAE LMAEgoldLMAEpredLMAEgoldLMAEpredLMAEgoldLMAEpredwmt12 B0.691.37 0.47 1.02 0.57 1.02 0.62T 1.08 0.68 1.08 0.67 0.89 0.68wmt13a B0.150.35 0.18 0.28 0.18 0.19 0.17T 0.28 0.12 0.28 0.13 0.24 0.13wmt13b B50.9264 154 192 129 135 90.3T 26.1 22.9 24.5 27.4 27.4 25.2Table 4: Local MAE evaluation (test set).
?T?
(resp.
?B?)
refers to the top (resp.
bottom) quality tail.Example: for the wmt13b data, among the 10% actual top quality sentences (i.e.
the 10% lowest goldscores), the mean absolute error is 26.1.
This is lower than the global MAE (50.9), as opposed to allthe other cases; this confirms that the top quality tail in wmt13b is particularly well predicted (this iscertainly a consequence of the strongly skewed distribution in this dataset).4.2 The Post-edited Sentences TestA good way to evaluate the discrepancies in the reliability of the quality scores in the tails is to applythe QE system to a set of very good or very bad sentences.
Thankfully the post-edited versions of thesentences were provided with the WMT datasets; since by definition their quality is perfect, they makea perfect case for such a test.12In theory, all these sentences should be assigned a score close to topquality.13For every dataset we run the same QE system, i.e., we compute the features for the post-editedsentences using Quest, then apply the model built with the regular training data to these features.
Wetried with both the post-edited version of the training set and test set, when provided.14Our original goal was to observe how high the error rate was globally, but it turned out that the pre-dicted scores follow a distribution which is very similar to the one followed by the MT output (the meansare very close as well, which implies that the MAE is very high).
This led us to observe how the MT out-put scores and the post-edited version scores are correlated.
In most cases the two scores are very close,as shown on figure 5.
This is obviously a very serious issue, since it means that, in general, the system isnot able to distinguish between a sentence which needs correction and the same sentence after correction.11Remark: if I = D, LMAEgold= LMAEpred= MAE.12Independent assessment of the post-edited sentences is, of course, not guaranteed to yield the judgement that they wouldnot benefit from further editing, though.13That is, 5 for the wmt12 dataset and 0 for the wmt13a dataset (since HTER scores measure the distance against the post-edited version, and here we compare the post-edited sentence against itself); the wmt13b dataset is based on post-edited time,so there is no exact value corresponding to perfect sentences but the scores should very low.14The post-edited version was not available for the wmt13b test set.221123452 3 4 5MT.output.predictposted.predict(a) wmt12, train set;cor.=0.977;mean diff.=-0.03=-0.03?3452 3 4 5MT.output.predictposted.predict(b) wmt12, test set;cor.=0.986;mean diff.=-0.02=-0.02?0.10.20.30.40.50.60.2 0.3 0.4 0.5 0.6MT.output.predictposted.predict(c) wmt13a, train set;cor.=0.962;mean diff.=0.004=0.02?0.20.30.40.50.2 0.3 0.4 0.5MT.output.predictposted.predict(d) wmt13a, test set;cor.=0.987;mean diff.=0.002=0.01?01002003000 100 200 300MT.output.predictposted.predict(e) wmt13b, train set;cor.=0.985;mean diff.=3.14=0.04?Figure 5: MT output predicted scores vs. post-edited predicted scores ?mean diff.?
is the mean of thedifference between the post-edited score and the MT output score; it is also expressed as a multiple of ?,where ?
is the standard deviation of the MT output gold scores (specific to each particular dataset).It is however able to see a slight difference at the document level: we have performed a paired Student?stest for each dataset, which shows that the mean of the scores predicted for the post-edited sentencesis significantly lower in the wmt12 case and higher in the wmt13a and wmt13b cases (as expected bythe definition of scores) than the scores predicted for the MT output sentences.
Nevertheless, the meandifference is extremely low (see figure 5), never higher than 0.04 standard deviations.Furthermore, there is no visible impact of the quality of the MT output, although one would expect thecorrelation to be lower for low quality sentences: by definition, there are more differences between theMT output and the post-edited version for these sentences, so it should be easier for the system to detectthe different level of quality between the two.
In other words, it is quite understandable that the systemdoes not detect the difference for an MT output of relatively good quality, but the fact the post-editedversion of the really bad translations are also rated as really bad is a major issue.
It must be rememberedthat we are not refering to a flaw solely in our own system, but nearly across the board in the state of theart systems.These observations, which hold for every dataset, show that QE systems do not capture the actualquality of the sentences: instead, it seems that what they measure is probably the difficulty of machine-translating a sentence.
Indeed, the set of Quest features that we use contains many features which dependonly on the source sentences.
Moreover, this conclusion is consistent with the fact that Bic?ici et al.
(2013)obtain very good results on the WMT12 dataset using only the source sentences.Explaining this observation with precision would require a more detailed analysis which is out of thescope of this paper.
Nevertheless, it is fairly clear that the features which are used fail to capture thesubtlety and/or the diversity of the difference between a faulty sentence and its corrected version; thismight be because a single sentence does not offer enough clues for the system to make such a fine-graineddistinction, in which case it would be necessary to rethink the definition of the QE problem.In other work, we examine linguistic quality of items in relation to reference corpora (Moreau andVogel, 2013; ?).
By comparison to the supervised learning studied here, such work is weakly supervisedsince there is no use of absolute scores.
This yields a version of the QE problem that may be deemed toorelativistic, but does represent an alternative approach.
Unfortunately, because of the very difference inthe use of absolute scores, they cannot be directly compared on this.
Thus, we focus here on empiricalexploration of the nature of the problem in estimating quality in the case of supervised learning.5 ExperimentsIn this section we devise several experiments intended to explore different aspects of the problem in moredetail.
In particular, we try to evaluate the impact of the possible causes described in ?3: first we showin ?5.1 that it affects most QE systems, especially those optimized to minimize MAE.
Then in ?5.2 and?5.3 we confirm that the distribution of the training set is a major cause of the issue by showing thatalternative distributions have different effects.22125.1 Tails Prediction for WMT12 Participating SystemsIn order to test if the tails prediction problem is general to most supervised QE systems, we apply the localperformance measures to the scores predicted on the test set by the participating systems in WMT12.15Table 5 shows some detailed results for the four best systems at WMT12.
It confirms that the predictionsmade for the tails are generally significantly worse than they are globally, and especially that the systemstend to predict very few values at the ends of the range of values: recall in the 10% bottom or top scoresis never higher than 12%.16It is also worth noticing that the first system, which performs significantlybetter than the others, is the only one which was not optimized to minimize the MAE but to maximizethe DeltaAvg score (Soricut et al., 2012).
In particular, this system obtains a recall higher than the othersin most cases (especially in the 5% and 10% tails), which is certainly due to the fact that it assignsmore scores far from the mean (in other words, this system takes more risk).
This tends to confirm ourhypothesis that the minimization of the MAE as learning criterion is one of the causes of the problem.Correlation Bottom TopSystem ID Global dist.mean.
5% 10% 20% 5% 10% 20%MAE vs abs.err.
R G-LMAE R G-LMAE R G-LMAE R G-LMAE R G-LMAE R G-LMAESDLLW M5PbestDeltaAvg 0.61 0.49 0.05 1.02 0.07 0.76 0.32 0.76 0.02 0.96 0.12 0.99 0.26 0.84UU best 0.64 0.53 0.0 1.21 0.07 0.91 0.26 0.91 0.0 1.02 0.04 1.01 0.22 0.81SDLLW SVM 0.64 0.55 0.0 1.33 0.0 0.98 0.17 0.98 0.02 0.89 0.06 0.91 0.32 0.75UU bltk 0.64 0.58 0.0 1.22 0.06 0.91 0.27 0.91 0.0 1.07 0.02 1.05 0.27 0.83Table 5: Tails prediction quality for the 4 best systems at WMT12 (test set).
The second columncontains the correlation between the distance to the mean and the absolute error; the columns R andG-LMAE contain respectively the recall and the gold-based local MAE scores (see ?4.1).5.2 Adding the Post-edited Sentences to the Training SetIn this experiment we use the post-edited sentences again (see ?4.2), but this time adding them to thetraining set in order to observe the impact on the test set.17These instances are progressively added tothe official training set (in random order).
We focus on the top quality tail, since it is the one which isexpected to benefit from adding sentences with top scores to the training set.
Figure 6 shows how thelocal MAE scores improve as post-edited instances are added.
Only the gold-based LMAE scores arerepresented, because these provide a recall-like information and the observations show that recall (in thetails) is the main weakness of QE systems (see ?4.1).As expected, in all cases adding top quality sentences to the training set makes the system decreasethe error rate in the top quality tail.
Of course this local improvement comes at the price of degradingthe global performance, although for the wmt13a dataset (fig.
6b) the global error even improves untilalmost half of the sentences have been added.
In the case of the wmt13b dataset (fig.
6c), since the QEsystem was already very good in predicting the top quality sentences (the LMAE is even better than theglobal MAE), the improvement is smaller and proportionally more costly for the global performance.5.3 Balancing the Training SetIn this final experiment, we resample the training set (with replacement), in order to balance the goldscores over the full range of values.
Since we can only use the discrete gold scores provided with theoriginal training set, we compute a (random) uniform distribution but select the closest available score(randomly picking an instance among those with this score).
The resulting distribution is not uniform,and the training set contains many duplicate instances; therefore, the resulting training set is unlikely toyield very good results in general, but it is no longer subject to the ?statistical attraction?
towards themean that we have observed.15These values were kindly provided by the organizers of the WMT12 QE Shared Task.16This is true for all but 3 participating systems, and these exceptions correspond to systems which performed worse globally.17We assign perfect scores to all these sentences: 5 for wmt12, 0 for wmt13a; for wmt13b, we use the mean of the time spentfor the sentences in the training set which were left unmodified: there are 23 such sentences, and the mean is 16.19s.2213l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l0.40.81.20% 25% 50% 75% 100%sentencesLMAE proportionl 0.050.10.2global(a) wmt12.l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l0.10.20% 25% 50% 75% 100%sentencesLMAE proportionl 0.050.10.2global(b) wmt13a.l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l l204060800% 25% 50% 75% 100%sentencesLMAE proportionl 0.050.10.2global(c) wmt13b.Figure 6: Improvement of gold-based LMAE as post-edited sentences are added to the train set.Example: in wmt12, the gold-based LMAE for the top 20% sentences is higher than 0.8 when the systemis trained only on the official train set (0% of the post-edited sentences added), but reaches 0.4 whenabout half of the post-edited sentences are added to the training set.
However the global MAE (whichtakes all the sentences into account) increases from 0.7 (0%) to 0.9 (50% of the post-edited sentencesadded): since the system assigns more scores in the top tail, it makes larger errors globally.
Remark: theMAE and LMAE values are measured on the same set of sentences for every percentage on the X axis.The model obtained from the balanced training set has been applied to the original test set.
Table 6gives the local results observed in the tails: in most cases, the recall increases drastically compared tousing the regular training set, or is at least identical,18causing a great increase in the F1-scores as well.The LMAE scores do not show such an improvement, in fact the mean error is often higher than with theregular training set.
This is due to the fact that the system is forced to assign scores far from the ?easycases?
around the mean, therefore makes much bigger mistakes than in the previous case.
As expected,the global MAE scores for wmt13a and wmt13b are much higher than the original MAE values (0.27 and110.7 respectively, i.e.
about twice the original values).
Interestingly, the MAE stays almost constant(0.71 instead of 0.69) for wmt12.
The correlation between the distance to the mean and the mean absolutedecreases to 0.42, 0.05 and 0.26 for wmt12, wmt13a and wmt13b, respectively.Classification measures Local MAE measuresData+tail 5% 10% 20% 5% 10% 20%limit P R F1 limit P R F1 limit P R F1 gold pred.
gold pred.
gold pred.wmt12 B ?
2.0 0.31 0.18 0.23 ?
2.3 0.49 0.20 0.28 ?
2.7 0.66 0.46 0.54 0.94 0.82 0.73 0.75 0.73 0.67T ?
5.0 ?
0.0 ?
?
4.7 0.50 0.02 0.04 ?
4.2 0.69 0.19 0.29 1.28 0.72 1.26 0.65 1.07 0.71wmt13a B ?
0.62 0.15 0.70 0.24 ?
0.54 0.17 0.75 0.28 ?
0.47 0.21 0.83 0.33 0.14 0.60 0.13 0.55 0.14 0.49T ?
0.06 ?
0.0 ?
?
0.11 ?
0.0 ?
?
0.17 0.67 0.02 0.04 0.58 0.11 0.57 0.14 0.44 0.15wmt13b B ?
272 0.15 0.55 0.23 ?
186 0.27 0.78 0.41 ?
134 0.38 0.91 0.54 156 243 118 235 101 199T ?
18.2 0.20 0.20 0.20 ?
24.8 0.30 0.19 0.24 ?
35.7 0.55 0.26 0.35 128 61 114 45 110 41Table 6: Local evaluation of the test set using a balanced training set.
Cells in bold show an im-provement over the corresponding value with the original training set, as given in tables 3 and 4.
Theclassification limits were computed on the original training set.6 Conclusion and Future WorkTo conclude, we have shown that there are very serious issues with the way supervised QE systemsare built: they tend to be unable to reliably evaluate both the worst and the best quality sentences.Furthermore, they cannot distinguish between a faulty MT output sentence and its post-edited version.We have also shown that it is possible to improve the detection of the best/worst sentences by alteringthe distribution of the training set; however the question whether this can be achieved while maintaininga decent level of global performance remains open.
But even if the cost in global performance is high,18The only exception is the 20% top quality recall of the wmt13b dataset.
This is certainly due to the very particulardistribution of scores in this dataset, and to the fact that the top quality tail was already predicted reliably in the regular version.2214the techniques that we have tested could be useful in some specific applications of QE (for example, ifthe recall in the tails is more important than the precision).We think that these observations raise questions about the definition of the QE problem.
It mightactually be necessary to define different kinds of QE tasks: depending on the targeted application (e.g.estimating post-editing time, retraining the MT model, discarding the worst sentences, etc.
), there couldbe a specific setting which is more appropriate in terms of supervised/unsupervised learning, evaluationmeasure, precision/recall trade-off, etc.
For instance, minimizing the MAE does not seem compatiblewith detecting anomalies, but might be relevant for estimating the cost of post-editing.
Similarly, underthe hypothesis that the sentence level is not sufficiently rich in information in order to obtain accuratepredictions, an intermediate level of granularity might be considered (e.g.
at paragraph level).Finally, another great challenge with respect to the reliability of QE systems is their consistency whenapplied to different test sets, or more generally their dependency on the training set: in the perspective ofapplications, it is very important to know what level of confidence can be expected when applying a QEsystem or model to a new document.AcknowledgementsWe are grateful to Lucia Specia, Radu Soricut and Christian Buck, the organizers of the WMT 2012 and2013 Shared Task on Quality Estimation, for releasing all the data related to the competition, includingpost-edited sentences, features sets, etc.This research is supported by Science Foundation Ireland (Grant 12/CE/I2267) as part of the Centrefor Next Generation Localisation (www.cngl.ie) funding at Trinity College, University of Dublin.The graphics in this paper were created with R (R Core Team, 2012), using the ggplot2 library(Wickham, 2009).ReferencesErgun Bic?ici, Declan Groves, and Josef Genabith.
2013.
Predicting sentence translation quality using extrinsicand language independent features.
Machine Translation, 27(3-4):171?192.Ondrej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, ChristofMonz, Matt Post, Radu Soricut, and Lucia Specia.
2013.
Findings of the 2013 Workshop on Statistical MachineTranslation.
In Eighth Workshop on Statistical Machine Translation, WMT-2013, pages 1?44, Sofia, Bulgaria.Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia.
2012.
Findingsof the 2012 workshop on statistical machine translation.
In Proceedings of the Seventh Workshop on StatisticalMachine Translation, Montreal, Canada, June.
Association for Computational Linguistics.M.
Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I.H.
Witten.
2009.
The weka data miningsoftware: an update.
ACM SIGKDD Explorations Newsletter, 11(1):10?18.Erwan Moreau and Carl Vogel.
2013.
Weakly supervised approaches for quality estimation.
Machine Translation,27(3):pp 257?280, September.R Core Team, 2012.
R: A Language and Environment for Statistical Computing.
R Foundation for StatisticalComputing, Vienna, Austria.
ISBN 3-900051-07-0.Kashif Shah, Eleftherios Avramidis, Ergun Bic?ici, and Lucia Specia.
2013.
Quest - design, implementation andextensions of a framework for machine translation quality estimation.
Prague Bull.
Math.
Linguistics, 100:19?30.S.K.
Shevade, SS Keerthi, C. Bhattacharyya, and K.R.K.
Murthy.
2000.
Improvements to the SMO algorithm forSVM regression.
Neural Networks, IEEE Transactions on, 11(5):1188?1193.A.J.
Smola and B. Sch?olkopf.
2004.
A tutorial on support vector regression.
Statistics and computing, 14(3):199?222.Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul.
2006.
A study of transla-tion edit rate with targeted human annotation.
In In Proceedings of Association for Machine Translation in theAmericas, pages 223?231.2215Radu Soricut, Nguyen Bach, and Ziyuan Wang.
2012.
The SDL Language Weaver systems in the WMT12Quality Estimation shared task.
In Proceedings of the Seventh Workshop on Statistical Machine Translation,pages 145?151, Montr?eal, Canada, June.
Association for Computational Linguistics.Hadley Wickham.
2009. ggplot2: elegant graphics for data analysis.
Springer New York.2216
