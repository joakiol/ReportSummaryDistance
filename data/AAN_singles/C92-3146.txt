TOWARDS A NEW GENERATION OF TERMINOLOGICAL RESOURCES:AN EXPERIMENT IN BUILDING A TERMINOLOGICAL KNOWLEDGE BASEINGRID MEYER, DOUGLAS SKUCE, LYNNE BOWKER AND KAREN ECKArtificial Intelligence Laboratory, University of Ottawa, Ottawa, Canadaixmal@acadvml.uottawa.caABSTRACTThis paper describes a project o construct a termi-nological knowledge base, called COGNITERM.First, we position our research framework in rela-tionship to recent developments in computationallexicology and knowledge ngineering.
Second,we describe the COGNITERM prototype and dis-cuss its advantages over conventional term banks.Finally, we outline some of the methodological is-sues that have emerged from our work.0 INTRODUCTIONThe discipline of terminology I has receivedsurprisingly little focussed attention i  the literatureof computational linguistics - an unfortunate situa-tion given that NLP systems eem to be most suc-cessful when applied to specialized omains.
Wesay focussed attention because when specializedlexical items are discussed in the literature, the re-search problems are often not clearly differentiatedfrom the problems of non-specialized lexical items.A fundamental ssumption of our research is that,while terminology can certainly benefit fromadvances in computational exicology, itnonetheless has its own non-trivial research prob-lems, which are ultimately related to the quantityand types of specialized world knowledge thatterminological repositories must contain.At the Artificial Intelligence Laboratory of theUniversity of Ottawa, we .are constructing a newtype of terminological repository, COGNITERM,which is essentially a hybrid between a term bankand a knowledge base, or a terminological knowl-edge base (TKB).
COGNITERM is a bilingual(French/English) TKB constructed using a genericknowledge ngineering tool (CODE) that has beenused in terminology, software engineering anddatabase design applications.
The COGNITERMProject (1991-94) is focussing on the domain ofoptical storage technologies (e.g.
optical discs,drives, processes, etc.
).In Section 1 of the paper, we position our re-search in relation to recent developments in com-1 Slmce constraints preclude even a brief description ofthediscipline of terminology.
Cf.
Sager 1990.putational lexicology and knowledge ngineering;in Section 2, we describe the structure ofCOGN1TERM as well as some of its advantagesover conventional term banks; in Section 3, weoutline some methodological issues that haveemerged from our work.1 RESEARCH ISSUES INCOMPUTATIONAL TERMINOLOGY1.1 Terminological vs .
LexiealKnowledge BasesMuch of the world's terminological data isstored in large terminological databases (TDBs)such as Canada's TERMIUM III, which containsover one million bilingual records.
These TDBsare useful only to humans, and even then to only asmall subset of potential users: translators remainthe principal user category, even though TDBshave obvious applications in technical writing,management i formation and domain learning, notto mention awide variety of machine uses such asinformation retrieval, machine translation and ex-pert systems.
A major weakness of TDBs is thatthey provide mainly linguistic information aboutterms (e.g.
equivalents in other languages, mor-phological information, style labels); conceptualinformation is sparse (limited to definitions andsometimes contexts), unstructured, inconsistentand implicit.Given these problems, a growing number ofterminology researchers are calling for the evolu-tion of TDBs into a new generation of terminologi-cal repositories that are knowledge-based.
Sincethis vision of a TKB has been recently paralleled incomputational lexicology by the vision of a lexicalknowledge base or LKB (e.g.
Atkins 1991,Boguraev and Levin 1990, Pustejovsky andBergler 1991), we would like to briefly positionour research framework in relation to these devel-opments.The LKB projected by Boguraev and Levin1990 differs from an LDB in two ways: 1) theLDB states lexical characteristics on a word-by-word basis, while the LKB permits generaliza-tions; and 2) the LKB permits inferencing, andthus the possibility of dynamically extending theAc'rr~s DE COLING-92.
NANTES.
23-28 AOt~T 1992 95 6 Paoc.
OF COLING-92, NANTEs.
AUG. 23-28, 1992lexicon to accommodate n w senses.
Both charac-teristics are extremely important for the TKB aswell: 1) a capacity for supporting eneralisations isparticularly relevant to terminology since termino-logical repositories have an important eachingfunction2; and 2) the accommodation of newsenses is even more crucial to terminology than tothe general exicon since specialized languagesgrow so rapidly.
While the TKB must share thesecharacteristics, it differs from the LKB in one im-portant way, which derives from the fundamentaldifference between general and specialized lexicalitems.
This difference can be summarized in thefollowing two principles:?
an LKB must make explicit what a native speakerknows about concepts denoted by general lexicalitems?
a TKB must make explicit what a native speakerwho is also a domain ex_oert knows about con-cepts denoted by specialized lexical iterrL~While the lexicographer's ultimate source oflexieal knowledge is his/her own intuition, theterminologist's challenge is to model experts' ter-minological intuitions, which stem in large partfrom their domain knowledge.
The acquisition ofdomain knowledge, therefore, has traditionallybeen the starting point for any practical terminol-ogy project; only when the knowledge structuresof a domain are systematized to some degree canterminologists proceed with term extraction, defi-nition construction, analysis of synonymy andpolysemy, identification of equivalents in otherlanguages, etc.
The crucial importance of model-ling domain knowledge in a TKB necessitates aconceptual framework and technology which, inour view, should derive partly from recent insightsin knowledge ngineering.1.2 Terminology and KnowledgeEngineeringAt the heart of the relationship between ter-minology and knowledge ngineering is the factthat practitioners of both disciplines function asintermediaries in a knowledge communication con-text involving experts on the one hand and aknowledge processing technology on the other.This type of knowledge communication contextentails three principal activities:Knowledge acquis i t ion.
Acquisition ofknowledge, whether by elicitation from a human2 Most TDB users are not domain experts, and thus hope toacquire some domain knowledge when they look up a term.expert or extraction from texts, is complicated bythe fact that domain expertise consists of three el-ements - performance, understanding and com-munication - that require the expert to play theroles of practitioner, scientist and teacher, espec-tively (Gaines 1990).
Unfortunately, experts varywidely in their teaching skills: they may not havethe linguistic ability to express knowledge clearly;they may not provide xactly the knowledge that isrequired; etc.
As well, they may vary in their un-derstanding of the field, presenting the knowledgeengineer/terminologist w th problems of inconsis-tency and contradiction,Knowledge fo rmal i za t ion .
Knowledgedoes not come "off the shelf, prepackaged, readyfor use" (Hayes-Roth 1987:293).
As already men-tioned, it can be inconsistent and contradictory.
Itcan be multidimensional, since experts' under-standing of a conceptual system can depend ontheir point of view.
It may be hard to "capture",since it is constantly changing, and since emergentknowledge can be incomplete and unclear.
Finally,from the knowledge ngineer/terminologist's pointof view, it will exist in various degrees of"clarity"and "depth": since knowledge acquisition isincremental, certain concepts will be more clearlyor deeply understood than others at any giventime.Knowledge re f inement .
Once formal-ized, knowledge may be refined in two ways: 1) itmay be validated by testing the knowledge-basedsystem on the intended application, and/or 2) itmay be periodically updated, for example, as theknowledge ngineer/terminologist's understandingof the field deepens or expands, when the field it-self changes, or when the system needs moreknowledge due to changes in the application.Knowledge refinement may again entail knowl-edge acquisition and formalization, making theknowledge ngineering cycle a continuous pro-cess.Over the last three years, we have developedand tested a knowledge ngineering tool calledCODE (Conceptually Oriented DescriptionEnvironment), which is designed to assist a userwho may or may not be a domain expert in acquir-ing, formalizing and refining specialized knowl-edge.
Although genetic by design, CODE empha-sizes linguistic and particularly terminological sup-port, which we feel is crucial to all knowledge n-gineering applications.
From 1987 to 1990, aworking prototype was developed and tested inthree terminology-intensive applications: term bankconstruction, software engineering and databaseACIES DE COLING-92, NAbrlES, 23-28 AO~r 1992 9 S 7 PROC.
OF COLING-92, NA/C~'ES, AUG. 23-2.8, 1992design 3.
Our research as now entered a secondthree-year phase, with the goal of using CODE tohelp us develop a clearer concept of a TKB and ofan associated methodology.2 COGNITERM: ATERMINOLOGICAL KNOWLEDGEBASE2.1 General DescriptionCOGNITERM is essentially designed as ahybrid between aconventional TDB and a knowl-edge base.
Each concept is represented in a frame-like structure called a concept descriptor (CD),which has two main information categories.
TheConceptual Information category is the knowledgebase component, listing conceptual characteristicsand their values.
CDs are normally, though notnecessarily, arranged in inheritance hierarchies.The Linguistic Information category is the TDBcomponent, providing all the strictly linguistic in-formation ormally found in conventional TDBs.The TKB can be visualized graphically in avariety of semantic net displays.
Both hierarchical(e.g.
generic-specific, part-whole) and non-hierar-chical relations can be graphed.
Since knowledgeacquisition typically proceeds one subdomain at atime, subwindows may show only a restricted partof the knowledge structure (i.e.
a subtree).
Thereis also a masking capability which, for example,can show only concepts that fall within a given"dimension" of reality.As an aid to definition construction, andspecifically to assist in determining the differentiat-ing characteristics, CODE offers a CharacteristicComparison Matrix that presents the union of allcharacteristics of coordinate concepts 4, with theexclusion of those that are identical in all coordi-nates.Finally, navigation through COGNITERM isfacilitated by CODE's Browser, which allows theknowledge to be accessed either by names of con-cepts or names of their characteristics, both ofwhich can be presented in a conceptual (i.e.
hierar-3 This first phase of our research has already beendocumented lsewhere: ageneral technical description ofCODE can be found in Skuce (in press b); an analysis ofthe relationship between terminology and knowledgeengineering can be found in Meyer 1991 and (in press); thethree terminology-intensive applications are described inSkuce and Meyer 1990a/b (term bank construction), Skuce(in preparation) (software ngineering), and Downs et al1991 (database d sign).4 By coordinate concepts we mean concepts hat share thesame parent in a hierarchy.chical) or alphabetical order.
A variety of maskscan be applied to restrict the knowledge.2 .2  Advantages of a TKB over a TDBThe differences between a conventional TDBand a TKB can be examined from three points ofview: 1) the information itself, 2) support for ac-quiring and systematizing the information and 3)facilities for retrieving the information.
A brief de-scription 5 of each is found below.The information.
In a TDB, conceptualinformation is encoded implicitly in the form ofdefinitions, contexts, indication of domain(s), etc.In a TKB, it is encoded explicitly.
The resultantdegree of structure imposed on the information hasthree important by-products.
First, it allows for anexplicit representation f conceptual relations (asopposed to implicit representations i  TDB defini-tions or contexts).
Second, it facilitates consis-tency: since generic concepts are explicitly indi-cated, for example, definitions of all coordinateconcepts must have the same genus term; sincecharacteristics inherit to subeoncepts, they willcorrespond from one coordinate concept o an-other.
Third, an explicit representation f concep-tual relations facilitates graphical representations ofknowledge structures; this aspect is particularlyemphasized in the COGNITERM Project sincegraphical representations aid learning, providingthe kind of conceptual "map" advocated by numer-ous educational psychologists 6.Acquisit ion and systematization ofinformation.
Unlike conventional TDBs, a TKBsuch as COGNITERM provides not only amedium for storing information, but also mecha-nisms to assist in acquiring and systematizing theinformation in the fast place.
Inheritance mecha-nisms play an important role in this regard: on thesimplest level, they free the terminologist from re-peating information from one hierarchical level toanother, and allow the possibility of "what-if" ex-periments; on a more interesting level, inheritancecan be associated (as it is in CODE) with mecha-nisms for signalling conflicts when changes to onehierarchical level "percolate" through the knowl-edge structures.
A browsing mechanism such aswe have implemented provides additional supportfor acquisition, as it allows the kind of hypertext-like "navigation" through the knowledge structuresthat is needed to ferret out compatible knowledge"spaces" for a new concept.
Other implemented5 A much more detailed description, illustrated withexamples ofCOGNITERM output, can be found in Meyeret al 1992 (in press).6 C?
Sowa 1991 (in press).AcrEs DE COLING-92, NANTES, 23-28 AOt3T 1992 9 5 8 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992user interface features, such as masks, theCharacteristic Comparison Matrix, and a highlydeveloped graphical display, are just some exam~pies of the potential facilities of a TKB environ-ment designed to help terminologists "get theknowledge straight" throughout the acquisitionprocess.Retrieval of information.
ConventionalTDBs are severely handicapped by their funda-mental term-to-concept orientation: knowing ateml, one can expect he TDB to indicate (to somedegree, at least) what it means, what its synonymsare, etc.
Terminological research, however, is veryoften concept-to-term oriented: for example, "real-life" terminology is typified by questions like"What do you call the machine with function W?
","What do you call the material that has physicalcharacteristics X, Y, and Z?"
The inability of con-ventional TDBs to answer these kinds of questionsleads to the proliferation of synonyms and quasi-synonyms, one of the greatest impediments tocommunication i  specialized omains.
Users ofCOGN1TERM can access its data through anyconceptual characteristic todetermine whether theconcept they have in mind already has a name.3 METHODOLOGICAL ISSUESIn deciding on a preliminary methodologyfor our work, we naturally turned to the literatureof both computational lexicology and knowledgeengineering for inspiration, with little success.Even the world's largest knowledge acquisitionproject, CYC (Lenat and Guha 1990), providesonly sparse methodological guidance (Skuce inpress a).
To date, our methodology has remainedessentially grounded in that traditionally used byterminologists (Sager 1990), a reasonable startingpoint when one considers that, although terminol-ogists have traditionally not built TKBs, concep-tual analysis has always been a central part of theftwork 7 nonetheless.
Tenninologists are keenlyaware of the importance of a certain depth of do-main knowledge, and many of the conceptualanalysis techniques that are advocated in theknowledge ngineering literature - e.g.
describingconceptual characteristics through attribute-valuepairs, sketching concept networks - have been partof the terminological methodology for years.The methodology we have developed can bevery superficially described as follows8: 1) Afterintroductory reading on the domain, the principal7 A detailed analysis of the role of conceptual nalysis interminology can be found in Meyer (in press).8 A detailed escription fthe methodology can be found inMeyer et al 1992 (in press).conceptual relations are sketched out, with thegoals of establishing the boundaries of the domainand identifying the subdomains, from which themost fundamental is selected for further analysis.2) A template of conceptual characteristics is es-tablished for the selected subdomain; it is used as aguide to the knowledge acquisition process, andinherits to lower levels of the conceptual hierarchy,where it can also be specialized.
3) Conceptual ndlinguistic information are entered into the systemas they are acquired (mainly from the corpus).
Aconcept is integrated into a hierarchy whenever itssuperconcept is known; when it is not, or whenthere is some doubt, the concept is labelled"unclassified" (unchtssified concepts can occur atany level in a hieraa~'hy, i.e.
there can be different"degrees" of classification).
4) Intensional defini-tions are constructed with the help of theCharacteristic Comparison Matrix.
Steps 2-4 arethen repeated for the next subdomain, until all sub-domains have been completed.A number of the more troublesome method-ological issues with which we are currently grap-pling are briefly outlined below.Knowledge acquisition "paths".Knowledge acquisition is not a journey down astraight path: there is no visible "goal".
Althoughwe have followed traditional terminology method~ology in adopting asubdomain-oriented, top-downapproach to acquisition, it often seems desirable todeviate from the principal subdomain when oneencounters elated te.rms in a neighbouring subdo-main or field, and to work bottom-up as well astop-down within the principal subdomain.
Whilethe subdomains we have investigated so far (themajority of the concepts belonging to the semanticclass of artefacts) are dominated by generic-spe-cific and part-whole relations, subdomains relatedto other semantic lasses may be more amenable toanalysis based on different relations, as has beenpointed out, for example, in the literature on theWordNet project (Miller 1991, Fellbaum 1991).Multidimensionality.
While terminolo-gists are well aware that a given domain can besubdivided in different ways, depending on theexpert's point of view, they have not traditionallyattempted to account for it in any serious way,since this is difficult to do with pencil-and-papertechniques.
Some problems that arise are howsuch "multidimensionality" affects knowledge ac-quisition "paths", how the technology can bettersupport he maintenance of conceptual clarity asthe number of dimensions grows (for example,through masking facilities of the kind we haveimplemented), how multidimensionality can be re-flected in definition construction, etc.ACRES DE COLING-92, NANTES, 23-28 Ao~r 1992 9 S 9 PROC.
OF COLING-92, NANq ES, Aua.
23-28, 1992Validation.
Validation by experts and otherterminologists, which has always been an impor-tant part of terminology work, is complicated inour approach by the fact that our TKB is veryhypertext-like, and thus requires revision tech-niques that go beyond those normally applied to"flat" texts such as conventional terminologyrecords.
We need to investigate further at whichpoints validators hould be consulted, what elicita-tion techniques should be used at each point, howto handle inconsistencies in opinion, etc.Increased automat ion.
To date, our re-search efforts are oriented towards facilitating (andnot automating) the knowledge acquisition processfor developing and implementing our concept of aTKB.
This is consistent with the majority ofknowledge acquisition projects in the world, in-cluding CYC.
As the concept of a TKB becomesclearer, however, we hope that TKB and LKB re-searchers will collaborate in exploring possibilitiesfor a more automated approach to acquisition.ACKNOWLEDGEMENTSThe COGNITERM Project is supported by theSocial Sciences and Humanities Research Councilof  Canada (SSHRC) and Research Services of theUniversity of Ottawa.
Development of  CODE issupported by the Natural Sciences and EngineeringResearch Council  of  Canada (NSERC), theUniversity Research Incentives Fund of theGovernment of Ontario, Bell Northern Researchand Research Services o f  the University ofOttawa.REFERENCESATKINS, B.T.S.
1991.
"Building a Lexicon: TheContribution of Lexicography".
International Journal ofLexicography, Vol.
4, No.
3.BOGURAEV, Branimir and LEVIN, Beth.
1990.
"Models for Lexical Knowledge Bases".
Proceedings of theSixth Annual Conference of the UW Centre for the NewOxford English Dictionary and Text Research.
Waterloo:University of Waterloo.DOWNS, Mary, GREENE, Reid and RISHEL,Diane.
1991.
"Conceptual Data Modeling in a MaterialsR&D Organization".
29th Annual Symposium of theNational Institute of Standards and Technology.Washington, D.C.FELLBAUM, Christiane.
1991.
"English Verbs as aSemantic Net".
International Journal of Lexicography, Vol.3, No.
4.GAINES, Brian.
1990.
"Knowledge AcquisitionSystems".
Knowledge Engineering (Vol.
1: Fundamentals),Ed.
Hojjat Adeli.
New York: McGraw-Hill.HAYES-ROTH, F. 1987.
"Expert Systems".Encyclopedia of Artificial Intelligence.
Ed.
Stuart Shapiro.New York: John Wiley and Sons.LENAT, D. and GUHA, R. 1990.
Building LargeKnowledge-Based Systems.
Reading, MA: Addison Wesley.LEVIN, Beth.
1991.
"Building a Lexicon: TheContribution of Linguistics".
International Journal ofLexicography, Vol.
4, No.
3.MEYER, Ingrid.
(in press).
"Concept Managementfor Terminology: A Knowledge Engineering Approach".Proceedings of the Symposium on StandardizingTerminology for Better Communication: Practice, AppliedTheory and Results (Cleveland, Ohio, June 1991).
SpecialTechnical Publication of the American Society for TestingMaterials (ASTM).MEYER, Ingrid.
1991.
"Knowledge Management forTerminology-Intensive Applications: Needs and Tools".Proceedings of the ACL SIG Workshop on LexicalSemantics and Knowledge Representation.
(To appear as abook edited by J. Pustejovsky and S. Bergler and publishedby Springer Verlag.
)MEYER, Ingrid, BOWKER.
Lynne and ECK, Karen.1992 (in press).
"COGNITERM: An Experiment inBuilding a Terminological Knowledge Base".
Proceedings ofthe Fifth Euralex International Congress.MILLER, George.
1991.
"Nouns in WordNet: ALexical Inheritance System".
International Journal ofLexicography.
Vol.
3, No.
4.PUSTEJOVSKY, James and BERGLER, Sabine(Eds.).
1991.
Proceedings of the ACL SIG Workshop onLexical Semantics and Knowledge Representation.
froappear as a book published by Springer Vetiag.
)SAGER, Juan.
1990.
A Practical Course inTerminology Processing.
Amsterdam/Philadelphia: JohnBenjamins.SKUCE, Douglas.
(in press a).
"A Review of:Building Large Knowledge-Based Systems (Leant andGuha)".
The Journal of Artificial Intelligence.SKUCE, Douglas.
(in press b).
"A Wide SpectrumKnowledge Management System".
Knowledge Acquisition.SKUCE.
Douglas.
(in preparation).
"ManagingSoftware Design Knowledge: A Too1 and an Experiment".SKUCE, Douglas and MEYER, lngrid.
1990a.
"Concept Analysis and Terminology: A Knowledge-BasedApproach to Documentation".
Proceedings of the Tlu'rteenthInternational Conference on Computational Linguistics(COLING 90).SKUCE, Douglas and MEYER, Ingrid.
1990b.
"Computer-Assisted Concept Analysis: An EssentialComponent of a Terminologist's Workstation".
Proceedingsof the Second International Congress on Terminology andKnowledge Engineering Applications.
Frankfurt: IndeksVerlag.SOWA, John.
1991 (in press).
"Conceptual Analysisas a Basis for Knowledge Acquisition".
In The Cognition ofExperts: Psychological Research and Empirical .41, Ed.
R.R.
Hoffman.
Berlin: Springer Vedag.ACTas DE COLING-92, NANTES, 23-28 AOtJT 1992 9 6 0 PROC.
OF COL1NG-92, NANTES, AUG. 23-28, 1992
