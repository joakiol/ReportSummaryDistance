Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 62?70,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEvaluation of Unsupervised Emotion Modelsto Textual Affect RecognitionSunghwan Mac KimSchool of Electricaland Information EngineeringUniversity of SydneySydney, Australiaskim1871@uni.sydney.edu.auAlessandro ValituttiDepartment of Cognitive Scienceand EducationUniversity of TrentoTrento, Italya.valitutti@email.unitn.itRafael A. CalvoSchool of Electricaland Information EngineeringUniversity of SydneySydney, Australiarafa@ee.usyd.edu.auAbstractIn this paper we present an evaluation of newtechniques for automatically detecting emo-tions in text.
The study estimates categoricalmodel and dimensional model for the recogni-tion of four affective states: Anger, Fear, Joy,and Sadness that are common emotions inthree datasets: SemEval-2007 ?AffectiveText?, ISEAR (International Survey on Emo-tion Antecedents and Reactions), and child-ren?s fairy tales.
In the first model, WordNet-Affect is used as a linguistic lexical resourceand three dimensionality reduction techniquesare evaluated: Latent Semantic Analysis(LSA), Probabilistic Latent Semantic Analysis(PLSA), and Non-negative Matrix Factoriza-tion (NMF).
In the second model, ANEW (Af-fective Norm for English Words), a normativedatabase with affective terms, is employed.Experiments show that a categorical model us-ing NMF results in better performances forSemEval and fairy tales, whereas a dimension-al model performs better with ISEAR.1 IntroductionSupervised and unsupervised approaches havebeen used to automatically recognize expressionsof emotion in text such as happiness, sadness,anger, etc?
Supervised learning techniqueshave the disadvantage that large annotated data-sets are required for training.
Since the emotionalinterpretations of a text can be highly subjective,more than one annotator is needed, and thismakes the process of the annotation very timeconsuming and expensive.
For this reason, unsu-pervised methods are normally preferred in therealm of Natural Language Processing (NLP)and emotions.Supervised and unsupervised techniques havebeen compared before.
(Strapparava and Mihal-cea 2008) describe the comparison between asupervised (Na?ve Bayes) and an unsupervised(Latent Semantic Analysis - LSA) method forrecognizing six basic emotions.These techniques have been applied to manyareas, particularly in improving Intelligent Tutor-ing Systems.
For example, (D?Mello, Craig et al2008) used LSA but for detecting utterance typesand affect in students?
dialogue within Autotutor.
(D'Mello, Graesser et al 2007) proposed fivecategories for describing the affect states in stu-dent-system dialogue.Significant differences arise not only betweenthese two types of techniques but also betweendifferent emotion models, and these differenceshave significant implications in all these areas.While considering emotions and learning, (Kort,Reilly et al 2001) proposed (but provided noempirical evidence) a model that combines twoemotion models, placing categories in a valence-arousal plane.
This mixed approach has also beenused in other domains such as blog posts where(Aman and Szpakowicz 2007) studied how toidentify emotion categories as well as emotionintensity.
To date, many researchers have, how-ever, utilized and evaluated supervised methods,mainly based on the categorical emotion model.In this study, the goal is to evaluate the meritsof two conceptualizations of emotions (a cate-gorical model and a dimensional model) inwhich an unsupervised approach is used.
Theevaluation incorporates three dimensionality re-62duction methods and two linguistic lexical re-sources.The rest of the paper is organized as follows:In Section 2 we present representative researchof the emotion models used to capture the affec-tive states of a text.
Section 3 describes the tech-niques of affect classification utilizing lexicalresources.
More specifically, it describes the roleof emotion models and lexical resources in theaffect classification.
In addition, we give anoverview of the dimension reduction methodsused in the study.
In Section 4 we go over theaffective datasets used.
Section 5 provides theresults of the evaluation, before coming to ourdiscussion in Section 6.2 Emotion ModelsThere are two significantly different models forrepresenting emotions: the categorical model anddimensional model (Russell 2003).The categorical model assumes that there arediscrete emotional categories such as Ekman?ssix basic emotions - anger, disgust, fear, joy,sadness, and surprise - (Ekman 1992).
There area number of primary and unrelated emotions inthe model.
Each emotion is characterized by aspecific set of features, expressing eliciting con-ditions or responses.
Some researchers have ar-gued that a different set of emotions is requiredfor different domains.
For instance, the followingemotion classes are used in the field of teachingand education: boredom, delight, flow, confusion,frustration, and surprise.
The advantage of sucha representation is that it represents human emo-tions intuitively with easy to understand emotionlabels.A second approach is the dimensional model,which represents affects in a dimensional form(Russell 2003).
Emotional states are related eachother by a common set of dimensions (e.g.
va-lence or arousal) and are generally defined in atwo or three dimensional space.
Each emotionoccupies some location in this space.
A valencedimension indicates positive and negative emo-tions on different ends of the scale.
The arousaldimension differentiates excited vs. calm states.Sometimes a third, dominance dimension is usedto differentiate if the subject feels in control ofthe situation or not.The categorical model and the dimensionalmodel have two different methods for estimatingthe actual emotional states of a person.
In theformer, a person is usually required to chooseone emotion out of an emotion set that representsthe best feeling.
On the other hand, the latter ex-ploits rating scales for each dimension like theSelf Assessment Manikin (SAM) (Lang 1980),which consists of pictures of manikins, to esti-mate the degree of valence, arousal, and domi-nance.3 Automatic Affect Classification3.1 Categorical classification with featuresderived from WordNet-AffectWordNet-Affect (Strapparava and Valitutti 2004)is an affective lexical repository of words refer-ring to emotional states.
WordNet-Affect extendsWordNet by assigning a variety of affect labelsto a subset of synsets representing affective con-cepts in WordNet (emotional synsets).
In addi-tion, WordNet-Affect has an additional hierarchyof affective domain labels.
There are publiclyavailable lists relevant to the six basic emotioncategories extracted from WordNet-Affect andwe used four of the six lists of emotional wordsamong them for our experiment.In addition to WordNet-Affect, we exploited aVector Space Model (VSM) in which terms andtextual documents can be represented through aterm-by-document matrix.
More specifically,terms are encoded as vectors, whose componentsare co-occurrence frequencies of words in corpo-ra documents.
Frequencies are weighted accord-ing to the log-entropy with respect to a tf-idfweighting schema (Yates and Neto 1999).
Final-ly, the number of dimensions is reduced throughthe dimension reduction methods.The vector-based representation enables words,sentences, and sets of synonyms (i.e.
WordNetsynsets) to be represented in a unifying way withvectors.
VSM provides a variety of definitions ofdistance between vectors, corresponding to dif-ferent measures of semantic similarity.
In par-ticular, we take advantage of cosine angle be-tween an input vector (input sentence) and anemotional vector (i.e.
the vector representing anemotional synset) as similarity measures to iden-tify which emotion the sentence connotes.3.2 Dimension Reduction MethodsThe VSM representation can be reduced withtechniques well known in Information Retrieval:LSA, Probabilistic LSA (PLSA), or the Non-negative Matrix Factorization (NMF) representa-tions.Cosine similarities can be defined in these re-presentations, and here, as other authors havedone, we use a rule that if the cosine similarity63does not exceed a threshold, the input sentence islabeled as ?neutral?, the absence of emotion.Otherwise, it is labeled with one emotion asso-ciated with the closest emotional vector havingthe highest similarity value.
We use a predeter-mined threshold (t = 0.65) for the purpose of va-lidating a strong emotional analogy between twovectors (Penumatsa, Ventura et al 2006).If we define the similarity between a given in-put text, I, and an emotional class,  !
, assim(I,   !
), the categorical classification result,CCR, is more formally represented as follows:CCR(")= #arg  max!
$sim%", !
&'  if sim(", ! )
( )"neutral"                        if sim(", ! )
< )*One class with the maximum score is selected asthe final emotion class.Dimensionality reduction in VSM reduces thecomputation time and reduces the noise in thedata.
This enables the unimportant data to dissi-pate and underlying semantic text to becomemore patent.
We will review three statistical di-mensionality reduction methods (LSA, PLSA,and NMF) that are utilized in a category-basedemotion model.Latent Semantic Analysis (LSA) is the earliestapproach successfully applied to various textmanipulation areas (Landauer, Foltz et al 1998).The main idea of LSA is to map terms or docu-ments into a vector space of reduced dimensio-nality that is the latent semantic space.
The map-ping of the given terms/document vectors to thisspace is based on singular vector decomposition(SVD).
It is known that SVD is a reliable tech-nique for matrix decomposition.
It can decom-pose a matrix as the product of three matrices.+ = ,-./  0 ,1-1.1/ = +1 (1)where Ak is the closest matrix of rank k to theoriginal matrix.
The columns of Vk represent thecoordinates for documents in the latent space.Probabilistic Latent Semantic Anlaysis (PLSA)(Hofmann 2001) has two characteristics distin-guishing it from LSA.
PLSA defines properprobability distributions and the reduced matrixdoes not contain negative values.
Based on thecombination of LSA and some probabilistic theo-ries such as Bayes rules, the PLSA allows us tofind the latent topics, the association of docu-ments and topics, and the association of termsand topics.
In the equation (2), z is a latent classvariable (i.e.
discrete emotion category), while wand d denote the elements of term vectors anddocument vectors, respectively.2(3,4) =  52(6)2(4|6)2(3|6)6 (2)where P(w|z) and P(d|z) are topic-specific worddistribution and document distribution, indivi-dually.
The decomposition of PLSA, unlike thatof LSA, is performed by means of the likelihoodfunction.
In other words, P(z), P(w|z), and P(d|z)are determined by the maximum likelihood esti-mation (MLE) and this maximization is per-formed through adopting the Expectation Max-imization (EM) algorithm.
For document similar-ities, each row of the P(d|z) matrix is consideredwith the low-dimensional representation in thesemantic topic space.Non-negative Matrix Factorization (NMF)(Lee and Seung 1999) has been successfully ap-plied to semantic analysis.
Given a non-negativematrix A, NMF finds non-negative factors W andH that are reduced-dimensional matrices.
Theproduct WH can be regarded as a compressedform of the data in A.+ 0 78 =  578 (3)W is a basis vector matrix and H is an encodedmatrix of the basis vectors in the equation (3).NMF solves the following minimization problem(4) in order to obtain an approximation A bycomputing W and H in terms of minimizing theFrobenius norm of the error.9:;7,8 <+ =78<>2 , ?.
).
7,8 ( 0 (4)where W, H  0 means that all elements of W andH are non-negative.
This non-negative peculiari-ty is desirable for handling text data that alwaysrequire non-negativity constraints.
The classifi-cation of documents is performed based on thecolumns of matrix H that represent the docu-ments.3.3 Three-dimensional estimation with fea-tures derived from ANEWDimensional models have been studied by psy-chologists often by providing a stimulus (e.g.
aphoto or a text), and then asking subjects to re-port on the affective experience.
ANEW (Brad-ley and Lang 1999) is a set of normative emo-tional ratings for a collection of English words(N=1,035), where after reading the words, sub-jects reported their emotions in a three dimen-sional representation.
This collection providesthe rated values for valence, arousal, and domin-ance for each word rated using the Self Assess-ment Manikin (SAM).
For each word w, thenormative database provides coordinates 4@ in anaffective space as:644@ = (ABCD;ED,BFGH?BC,3G9:;B;ED)= +I 7(4) (5)The occurrences of these words in a text canbe used, in a na?ve way, to weight the sentence inthis emotional plane.
This is a na?ve approachsince words often change their meaning or emo-tional value when they are used in different con-texts.As a counterpart to the categorical classifica-tion above, this approach assumes that an inputsentence pertains to an emotion based on theleast distance between each other on the Va-lence-Arousal-Dominance (VAD) space.
Theinput sentence consists of a number of words andthe VAD value of this sentence is computed byaveraging the VAD values of the words:?D;)D;EDJJJJJJJJJJJJ =  - 4@;:=1; (6)where n is the total number of words in the inputsentence.Since not many words are available in thisnormative database, a series of synonyms fromWordNet-Affect are used in order to calculatethe position of each emotion.
These emotionalsynsets are converted to the 3-dimensional VADspace and averaged for the purpose of producinga single point for the target emotion as follows:D9G):G;JJJJJJJJJJJ =  - 4@1:=11 (7)where k denotes the total number of synonyms inan emotion.
Anger, fear, joy, and sadness emo-tions are mapped on the VAD space.
Let Ac, Fc,Jc, and Sc be the centroids of four emotions.
Thenthe centroids, which are calculated by the equa-tion (7), are as follows: Ac = (2.55, 6.60, 5.05), Fc= (3.20, 5.92, 3.60), Jc = (7.40, 5.73, 6.20), andSc = (3.15, 4.56, 4.00).
Apart from the four emo-tions, we manually define neutral to be (5, 5, 5).If the centroid of an input sentence is the mostapproximate to that of an emotion, the sentenceis tagged as the emotion (with the nearest neigh-bor algorithm).
The centroid ?D;)D;EDJJJJJJJJJJJJ might beclose to an D9G):G;JJJJJJJJJJJ on the VAD space, even ifthey do not share any terms in common.
We de-fine the distance threshold (empirically set to 4)to validate the appropriate proximity like the ca-tegorical classification.4 Emotion-Labeled DataThree emotional datasets, with sentence-levelemotion annotations, were employed for theevaluation described in the next section.
The firstdataset is ?Affective Text?
from the SemEval2007 task (Strapparava and Mihalcea 2007).
1We also use the ISEAR (International Surveyon Emotion Antecedents and Reactions) dataset,which consists of 7,666 sentences (Scherer andWallbott 1994), with regard to our experiments.This dataset consists of news headlines excerptedfrom newspapers and news web sites.
Headlinesare suitable for our experiments because head-lines are typically intended to express emotionsin order to draw the readers?
attention.
This data-set has six emotion classes: anger, disgust, fear,joy, sadness and surprise, and is composed of1,250 annotated headlines.
The notable characte-ristics are that SemEval dataset does not onlyallow one sentence to be tagged with multipleemotions, but the dataset alo contains a neutralcategory in contrast to other datasets.2The annotated sentences of the third datasetare culled from fairy tales (Alm 2009).
Emotionsare particularly significant elements in the lite-rary genre of fairy tales.
The label set with fiveemotion classes is as follows: angry-disgusted,fearful, happy, sad and surprised.
There are 176stories by three authors: B. Potter, H.C. Ander-sen, and Grimm?s.
The dataset is composed ofonly sentences with affective high agreements,which means that annotators highly agreed uponthe sentences (four identical emotion labels).For building the ISEAR, 1,096 participants whohave different cultural backgrounds completedquestionnaires about experiences and reactionsfor seven emotions including anger, disgust, fear,joy, sadness, shame and guilt.Emotion SemEval ISEAR Fairy tales TotalAnger 62 2,168 218 2,448Fear 124 1,090 166 1,380Joy 148 1,090 445 1,683Sadness 145 1,082 264 1,491Table 1: Number of sentences for each emotionIn our study, we have taken into account fouremotion classes (Anger, Fear, Joy and Sadness)which are in the intersection among three data-sets (SemEval, ISEAR and Fairy tales).
Thenumber of sentences for each emotion and each1 The dataset is publicly available athttp://www.cse.unt.edu/~rada/affectivetext.2 Available athttp://www.unige.ch/fapse/emotion/databanks/isear.html65dataset used in our experiment is shown in Table1.
In addition, sample sentences from the anno-tated corpus appear in Table 2.Dataset Sentences tagged with Sadness/SadSemEval Bangladesh ferry sink, 15 dead.ISEAR When I left a man in whom I reallybelieved.FairytalesThe flower could not, as on the pre-vious evening, fold up its petals andsleep; it dropped sorrowfully.Table 2: Sample sentences labeled with sadness/sadfrom the datasets5 Experiments and ResultsThe goal of the affect classification is to predict asingle emotional label given an input sentence.Four different approaches were implemented inMatlab.
A categorical model based on a VSMwith dimensionality reduction variants, (LSA,PLSA, and NMF), and a dimensional model,each with evaluated with two similarity measures(cosine angle and nearest neighbor).
Stopwordswere removed in all approaches.
A Matlab tool-kit (Zeimpekis and Gallopoulos 2005), was usedto generate the term-by-sentence matrix from thetext.The evaluation in Table 3 shows MajorityClass Baseline (MCB) as the baseline algorithm.The MCB is the performance of a classifier thatalways predicts the majority class.
In SemEvaland Fairy tales the majority class is joy, whileanger is the majority emotion in case of ISEAR.The five approaches were evaluated on the data-set of 479 news headlines (SemEval), 5,430 res-ponses to questions (ISEAR), and 1,093 fairytales?
sentences.
We define the following acro-nyms to identify the approaches:CLSA: LSA-based categorical classificationCPLSA: PLSA-based categorical classifica-tionCNMF: NMF-based categorical classificationDIM: Dimension-based estimationThe measure of accuracies used here were:Cohen?s Kappa (Cohen 1960), average precision,recall, and F-measure.
While the kappa scoresare useful in obtaining an overview of the relia-bility of the various classification approaches,they do not provide any insight on the accuracyat the category level for which precision, recall,and F-measure are necessary.Data set SemEval ISEAR Fairy talesEmotion Prec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1Anger MCB 0.000 0.000 - 0.399 1.000 0.571 0.000 0.000 -CLSA 0.089 0.151 0.112 0.468 0.970 0.631 0.386 0.749 0.510CPLSA 0.169 0.440 0.244 0.536 0.397 0.456 0.239 0.455 0.313CNMF 0.294 0.263 0.278 0.410 0.987 0.579 0.773 0.560 0.650DIM 0.161 0.192 0.175 0.708 0.179 0.286 0.604 0.290 0.392Fear MCB 0.000 0.000 - 0.000 0.000 - 0.000 0.000 -CLSA 0.434 0.622 0.511 0.633 0.038 0.071 0.710 0.583 0.640CPLSA 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000CNMF 0.525 0.750 0.618 0.689 0.029 0.056 0.704 0.784 0.741DIM 0.404 0.404 0.404 0.531 0.263 0.351 0.444 0.179 0.255Joy MCB 0.309 1.000 0.472 0.000 0.000 - 0.407 1.000 0.579CLSA 0.455 0.359 0.402 0.333 0.061 0.103 0.847 0.637 0.727CPLSA 0.250 0.258 0.254 0.307 0.381 0.340 0.555 0.358 0.436CNMF 0.773 0.557 0.648 0.385 0.005 0.010 0.802 0.761 0.781DIM 0.573 0.934 0.710 0.349 0.980 0.515 0.661 0.979 0.789Sadness MCB 0.000 0.000 - 0.000 0.000 - 0.000 0.000 -CLSA 0.472 0.262 0.337 0.500 0.059 0.106 0.704 0.589 0.642CPLSA 0.337 0.431 0.378 0.198 0.491 0.282 0.333 0.414 0.370CNMF 0.500 0.453 0.475 0.360 0.009 0.017 0.708 0.821 0.760DIM 0.647 0.157 0.253 0.522 0.249 0.337 0.408 0.169 0.240Table 3: Emotion identification results665.1 Precision, Recall, and F-measureClassification accuracy is usually measured interms of precision, recall, and F-measure.
Table3 shows these values obtained by five approach-es for the automatic classification of four emo-tions.
The highest results for a given type ofscoring and datasets are marked in bold for eachindividual class.
We do not include the accuracyvalues in our results due to the imbalanced pro-portions of categories (see Table 1).
The accura-cy metric does not provide adequate information,whereas precision, recall, and F-measure can ef-fectively evaluate the classification performancewith respect to imbalanced datasets (He and Gar-cia 2009).As can be seen from the table, the perfor-mances of each approach hinge on each datasetand emotion category, respectively.
In the caseof the SemEval dataset, precision, recall and F-measure for CNMF and DIM are comparable.DIM approach gives the best result for joy,which has a relatively large number of sentences.In ISEAR, DIM generally outperforms other ap-proaches except for some cases, whereas CNMFhas the best recall score after the baseline for theanger category.
Figure 1 indicates the results of3-dimensional and 2-dimensional attribute evalu-ations for ISEAR.
When it comes to fairy tales,CNMF generally performs better than the othertechniques.
Joy also has the largest number ofdata instances in fairy tales and the best recallignoring the baseline and F-measure are obtainedwith the approach based on DIM for this affectcategory.
CNMF gets the best emotion detectionperformance for anger, fear, and sadness interms of the F-measure.Figure 2 and Table 4 display results amongdifferent approaches obtained on the three differ-ent datasets.
We compute the classification per-formance by macro-average, which gives equalweight to every category regardless of how manysentences are assigned to it.33 Macro-averaging scores are defined as:This measurementprevents the results from being biased given theimbalanced data distribution.
From this summa-rized information, we can see that CPLSA per-forms less effectively with several low perfor-mance results across all datasets.
CNMF is supe-rior to other methods in SemEval and Fairy tales2m = 1K- L:K:=1 ,Mm =  1K- F:K:=1 ,>m = 1K- N:K:=1where C is total number of categories, and pi, ri, and fistand for precision, recall, and F-measure, respective-ly, for each category i.datasets, while DIM surpasses the others inISEAR.
In particular, CPLSA outperformsCLSA and CNMF in ISEAR because their per-formances are relatively poor.
The result impliesthat statistical models which consider a proba-bility distribution over the latent space do notalways achieve sound performances.
In addition,we can infer that models (CNMF and DIM) withnon-negative factors are appropriate for dealingwith these text collections.Another notable result is that the precision, re-call, and F-measure are generally higher in fairytales than in the other datasets.
These sentencesin the fairy tales tend to have more emotionalterms and the length of sentences is longer.
Thenature of fairy tales makes unsupervised modelsyield better performance (see Table 2).
In addi-tion, affective high agreement sentence is anoth-er plausible contributing reason for the encourag-ing experimental results.In summary, categorical NMF model and di-mensional model show the better emotion identi-fication performance as a whole.5.2 Cohen?s KappaThe kappa statistic measures the proportion ofagreement between two raters with correction forchance.
The kappa score is used as the metric tocompare the performance of each approach.
Fig-ure 3 graphically depicts the mean kappa scoresand its standard errors obtained from the emotionclassification.
Comparisons between four ap-proaches are shown across all three datasets.MCB is excluded in the comparison because themean kappa score of MCB is 0.Let MKCLSA, MKCPLSA, MKCNMF, and MKDIM bethe mean kappa scores of four methods.
Thehighest score (MKCNMF = 0.382) is achieved bythe CNMF when the dataset is SemEval.
In fairytales, the CNMF method (MKCNMF = 0.652) alsodisplays better result than the others (MKCLSA =0.506, MKDIM = 0.304).
On the contrary, theachieved results are significantly different in thecase of the ISEAR dataset in comparison withthe aforementioned datasets.
The DIM (MKDIM =0.210) clearly outperforms all methods.
The kap-pa score of the CPLSA approach (MKCPLSA =0.099) is quantitatively and significantly higherthan the CLSA (MKCLSA = 0.031) and CNMF(MKCNMF = 0.011).
Kappa score for the NMF-based methods is remarkably lower than the oth-er three approaches.According to (Fleiss and Cohen 1973), a kap-pa value higher than 0.4 means a fair to goodlevel of agreement beyond chance alone and it is67SemEval and Fairy tales datasets, while DIMsurpasses the others in ISEAR dataset.
OurPLSA conducted in all experiments is inferior toNMF, DIM as well as LSA.
The result impliesthat statistical models which consider a proba-bility distribution over the latent space do notalways leads to sound performances.
In addition,we can infer that models (NMF and DIM) withnon-negative factors are appropriate for dealingwith text collections.
Another interesting noticefrom overall results is that the precision, recall,and F-measure are higher in fairy tales than intwo other datasets.
The sentences in fairy taleshave ampler emotional terms and the length ofsentences is longer in comparison with those inother datasets.
The nature of fairy tales makesunsupervised models yield better performance(see Table 2).
In summary, categorical NMFmodel and dimensional model show the betteremotion identification performance as a whole.1.1 Cohen?s KappaThe kappa score is used as the metric to evaluatethe performance of each approach.
Figure 4graphically depicts the mean kappa scores and itsstandard errors obtained from the emotion classi-fication.
Comparisons between four approachesare shown and there are statistically significantdifferences in the kappa scores across all threedatasets.
MCB is excluded in the comparisonbecause the mean kappa score of MCB is 0.Let MKLSA, MKPLSA, MKNMF, and MKDIM be themean kappa scores of four methods.
The highestscore (MKNMF = 0.382) is achieved by the NMFwhen the dataset is SemEval.
In fairy tales, theNMF method (MKNMF = 0.652) also displays bet-ter result than the others (MKLSA = 0.506, MKDIM= 0.304).
Note that the achieved results aresomewhat different in case of ISEAR dataset incomparison with the aforementioned experimentwhich used precision, recall, and F-measure.
TheDIM (MKDIM = 0.210) clearly outperforms allmethods like section 5.1.
On the contrary, thekappa score of the PLSA approach (MKPLSA =0.099) is quantitatively and significantly higherthan the LSA (MKLSA = 0.031) and NMF (MKNMF= 0.011).
Kappa score for the NMF-based me-thods is remarkably lower than the other threeapproaches.
Nevertheless, we can observe thatNMF-based categorical model and dimensionalmodel got good grades on the whole.1.2 Cohen?s KappaThe most frequent words used in ISEAR datasetfor each emotion are shown in Table 4.
NMF andFigure 1: Distribution of the ISEAR dataset in the 3-dimensional and 2-dimensional sentiment space.
Thblue ?x?
denotes the location of one sentence corresponding to valence, arousal, and d minance.
(a)                    (b)                   (c)Figure 2: Comparisons of Precision, Recall, and F-measure: (a) SemEval; (b) ISEAR; (c) Fairy tales.Data set SemEval ISEAR Fairy talesPrec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1MCB 0.077 0.250 0.118 0.100 0.250 0.143 0.102 0.250 0.145CLSA 0.363 0.348 0.340 0.484 0.282 0.228 0.662 0.640 0.630CPLSA 0.189 0.282 0.219 0.260 0.317 0.270 0.282 0.307 0.280CNMF 0.523 0.506 0.505 0.461 0.258 0.166 0.747 0.731 0.733DIM 0.446 0.422 0.386 0.528 0.417 0.372 0.530 0.404 0.419Table 4: Overall average results(a) (b) (c)Figure 3: Comparisons of Mean Kappa: (a) SemEval; (b) ISEAR; (c) Fairy tales.68an acceptable level of agreement.
On the basis ofthis definition, the kappa score obtained by ourbest classifier (MKCNMF = 0.652) would be rea-sonable.
Most of the values are too low to saythat two raters (human judges and computer ap-proaches) agreed upon the affective states.
How-ever, we have another reason with respect to thismetric in the experiment.
We make use of thekappa score as an unbiased metric of the relia-bility for comparing four methods.
In otherwords, these measures are of importance in termsof the relative magnitude.
Hence, the kappa re-sults are meaningful and interpretable in spite oflow values.
We can observe that the NMF-basedcategorical model and the dimensional modelboth experienced higher performance.5.3 Frequently occurring wordsThe most frequent words used in fairy tales foreach emotion are listed in Table 5.
We choosethis dataset since there are varying lexical itemsand affective high agreement sentences, as men-tioned in Section 5.1.
Stemming is not used be-cause it might hide important differences as be-tween ?loving?
and ?loved?.
CNMF and DIMwere selected for the comparison with the GoldStandard because they were the two methodswith the better performance than the others.
GoldStandard is the annotated dataset by human ratersfor the evaluation of algorithm performance.
Thewords most frequently used to describe angeracross all methods include: cried, great, tears,king, thought, and eyes.
Those used to describefear include: heart, cried, mother, thought, man,and good.
Joy contains happy, good, and criedwhereas sadness has only cried for three methods.There is something unexpected for the wordfrequencies.
We can observe that the associationbetween frequently used words and emotion cat-egories is unusual and even opposite.
For in-stance, a ?joy?
is one of the most frequent wordsreferred to for sadness in the Gold Standard.
InCNMF and DIM, a ?good?
is employed frequent-ly with regard to fear.
Moreover, some wordsoccur with the same frequency in more catego-ries.
For example, the word ?cried?
is utilized toexpress anger, fear, and joy in the Gold Standard,CNMF, and DIM.
In order to find a possible ex-planation in the complexity of language used inthe emotional expression, some sentences ex-tracted from fairy tales are listed below:?The cook was frightened when he heard the or-der, and said to Cat-skin, You must have let ahair fall into the soup; if it be so, you will have agood beating.?
?
which expresses fear?When therefore she came to the castle gate shesaw him, and cried aloud for joy.?
?
which is theexpression for joy?Gretel was not idle; she ran screaming to hermaster, and cried: You have invited a fine guest!??
which is the expression for angry-disgustedFrom these examples, we can observe that inthese cases the affective meaning is not simplypropagated form the lexicon, but is the effect ofthe linguistic structure at a higher level.6 ConclusionWe compared the performances of three tech-niques, based on the categorical representation ofemotions, and one based on the dimensional rep-resentation.
This paper has highlighted that theNMF-based categorical classification performsModel Emotion Top 10 wordsGold Standard Anger king, thought, eyes, great, cried, looked, joy, mother, wife, tearsFear great, cried, good, happy, thought, man, heart, poor, child, motherJoy thought, mother, good, cried, man, day, wept, beautiful, back, happySadness cried, fell, father, mother, back, joy, dead, danced, wife, tearsCNMF Anger great, cried, eyes, mother, poor, joy, king, heart, thought, tearsFear cried, king, happy, good, man, heart, thought, father, boy, motherJoy mother, thought, cried, king, day, great, home, joy, good, childSadness thought, cried, good, great, looked, mother, man, time, king, heartDIM Anger eyes, fell, heart, tears, cried, good, stood, great, king, thoughtFear king, cried, heart, mother, good, thought, looked, man, child, timeJoy eyes, man, children, danced, cried, good, time, happy, great, weddingSadness cried, thought, great, king, good, happy, sat, home, joy, foundTable 5: Most frequent 10 words from fairy tales69the best among categorical approaches to classi-fication.
When comparing categorical againstdimensional classification, the categorical NMFmodel and the dimensional model have betterperformances.
Nevertheless, we cannot general-ize inferences on which of these techniques is thebest performer because results vary among data-sets.
As a future work, we aim at performing afurther investigation on this connection in orderto identify more effective strategies applicable toa generic dataset.
Furthermore, we aim at explor-ing improvements in the methodology, employedin this work, and based on the combination ofemotional modeling and empirical methods.AcknowledgmentsThis research is partially sponsored by a NormanI.
Price Scholarship from the University of Syd-ney.ReferencesC.
O. Alm (2009).
Affect in Text and Speech, VDMVerlag Dr. M?ller.S.
Aman and S. Szpakowicz (2007).
Identifying ex-pressions of emotion in text.
Text, Speech and Di-alogue.M.
M. Bradley and P. J. Lang (1999).
Affectivenorms for English words (ANEW): Instructionmanual and affective ratings.
University of Flori-da: The Center for Research in Psychophysiology.J.
Cohen (1960).
A coefficient of agreement for no-minal scales.
Educational and psychological mea-surement 20(1): 37-46.S.
D'Mello, A. Graesser, and R. W. Picard (2007).Toward an affect-sensitive AutoTutor.
IEEE Intel-ligent Systems 22(4): 53-61.S.
D?Mello, S. Craig, A. Witherspoon, B. Mcdaniel,and A. Graesser (2008).
Automatic detection oflearner?s affect from conversational cues.
UserModeling and User-Adapted Interaction 18(1): 45-80.P.
Ekman (1992).
An argument for basic emotions.Cognition & Emotion 6(3): 169-200.J.
L. Fleiss and J. Cohen (1973).
The equivalence ofweighted kappa and the intraclass correlation.Educational and psychological measurement 33:613-619.H.
He and E. A. Garcia (2009).
Learning from Imba-lanced Data.
IEEE Transactions on Knowledgeand Data Engineering 21(9): 1263.T.
Hofmann (2001).
Unsupervised learning by proba-bilistic latent semantic analysis.
Machine Learning42(1): 177-196.B.
Kort, R. Reilly, and R. W. Picard (2001).
An affec-tive model of interplay between emotions andlearning: Reengineering educational pedagogy-building a learning companion.
IEEE InternationalConference on Advanced Learning Technologies,2001.
Proceedings.T.
K. Landauer, P. W. Foltz, and D. Laham (1998).An introduction to latent semantic analysis.
Dis-course processes, Citeseer.
25: 259-284.P.
J. Lang (1980).
Behavioral treatment and bio-behavioral assessment: Computer applications.Technology in mental health care delivery sys-tems: 119-137.D.
D. Lee and H. S. Seung (1999).
Learning the partsof objects by non-negative matrix factorization.Nature 401(6755): 788-791.P.
Penumatsa, M. Ventura, A.C. Graesser, M. Lou-werse, X. Hu, Z. Cai, and D.R.
Franceschetti(2006).
The Right Threshold Value: What Is theRight Threshold of Cosine Measure When UsingLatent Semantic Analysis for Evaluating StudentAnswers?
International Journal on Artificial Intel-ligence Tools, World Scientific Publishing.J.
A. Russell (2003).
Core affect and the psychologi-cal construction of emotion.
Psychological review110(1): 145-172.K.
R. Scherer and H. G. Wallbott (1994).
Evidencefor universality and cultural variation of differen-tial emotion response patterning.
Journal of Perso-nality and Social Psychology 66: 310-328.C.
Strapparava and R. Mihalcea (2007).
Semeval-2007 task 14: Affective text.
Proceedings of the4th International Workshop on Semantic Evalua-tions, Association for Computational Linguistics.C.
Strapparava and R. Mihalcea (2008).
Learning toidentify emotions in text.
SAC '08: Proceedings ofthe 2008 ACM symposium on Applied computing,Fortaleza, Ceara, Brazil, ACM.C.
Strapparava and A. Valitutti (2004).
WordNet-Affect: an affective extension of WordNet.
Pro-ceedings of LREC.R.
B. Yates and B. R. Neto (1999).
Modern informa-tion retrieval.
ACM P.Zeimpekis D. and E. Gallopoulos (2005).
TMG: AMATLAB toolbox for generating term-documentmatrices from text collections.
Grouping multidi-mensional data: Recent advances in clustering:187-210.70
