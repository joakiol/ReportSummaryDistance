Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 579?584,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsWeakly Supervised Part-of-speech Tagging Using Eye-tracking DataMaria Barrett?Joachim Bingel?Frank Keller?Anders S?gaard?
?Centre for Language Technology, University of CopenhagenNjalsgade 140, 2300 Copenhagen S, Denmark{barrett, bingel, soegaard}@hum.ku.dk?School of Informatics, University of Edinburgh10 Crichton Street, Edinburgh EH8 9AB, UKkeller@inf.ed.ac.ukAbstractFor many of the world?s languages, thereare no or very few linguistically annotatedresources.
On the other hand, raw text, andoften also dictionaries, can be harvestedfrom the web for many of these languages,and part-of-speech taggers can be trainedwith these resources.
At the same time,previous research shows that eye-trackingdata, which can be obtained without ex-plicit annotation, contains clues to part-of-speech information.
In this work, webring these two ideas together and showthat given raw text, a dictionary, and eye-tracking data obtained from naive partici-pants reading text, we can train a weaklysupervised PoS tagger using a second-order HMM with maximum entropy emis-sions.
The best model use type-level ag-gregates of eye-tracking data and signifi-cantly outperforms a baseline that does nothave access to eye-tracking data.1 IntroductionAccording to Ethnologue, there are around 7,000languages in the world.1For most of these lan-guages, no or very little linguistically annotatedresources are available.
This is why over thepast decade or so, NLP researchers have focusedon developing unsupervised algorithms that learnfrom raw text, which for many languages is widelyavailable on the web.
An example is part-of-speech (PoS) tagging, in which unsupervised ap-proaches have been increasingly successful (seeChristodoulopoulos et al (2010) for an overview).The performance of unsupervised PoS taggers canbe improved further if dictionary information isavailable, making it possible to constrain the PoS1http://www.ethnologue.com/worldtagging process.
Again, dictionary informationcan be harvested readily from the web for manylanguages (Li et al, 2012).In this paper, we show that PoS tagging perfor-mance can be improved further by using a weaklysupervised model which exploits eye-tracking datain addition to raw text and dictionary informa-tion.
Eye-tracking data can be obtained by get-ting native speakers of the target language to readtext while their gaze behavior is recorded.
Read-ing is substantially faster than manual annota-tion, and competent readers are available for lan-guages where trained annotators are hard to findor non-existent.
While high quality eye-trackingequipment is still expensive, $100 eye-trackerssuch as the EyeTribe are already on the market,and cheap eye-tracking equipment is likely to bewidely available in the near future, including eye-tracking by smartphone or webcam (Skovsgaard etal., 2013; Xu et al, 2015).Gaze patterns during reading are strongly in-fluenced by the parts of speech of the words be-ing read.
Psycholinguistic experiments show thatreaders are less likely to fixate on closed-classwords that are predictable from context.
Read-ers also fixate longer on rare words, on words thatare semantically ambiguous, and on words that aremorphologically complex (Rayner, 1998).
Thesefindings indicate that eye-tracking data should beuseful for classifying words by part of speech,and indeed Barrett and S?gaard (2015) show thatword-type-level aggregate statistics collected fromeye-tracking corpora can be used as features forsupervised PoS tagging, leading to substantialgains in accuracy across domains.
This leads usto hypothesize that gaze data should also improveweakly supervised PoS tagging.In this paper, we test this hypothesis by ex-perimenting with a PoS tagging model that usesraw text, dictionary information, and eye-tracking579zi-2 zi-1 zixi-2 xi-1 xiFigure 1: Second-order HMM.
In addition tothe transitional probabilities of the antecedentstate zi?1in first-order HMMs, second-order mod-els incorporate transitional probabilities from thesecond-order antecedent state zi?2.data, but requires no explicit annotation.
We startwith a state-of-the-art unsupervised PoS taggingmodel, the second-order hidden Markov modelwith maximum entropy emissions of Li et al(2012), which uses only textual features.
We aug-ment this model with a wide range of features de-rived from an eye-tracking corpus at training time(type-level gaze features).
We also experimentwith token-level gaze features; the use of thesefeatures implies that eye-tracking is available bothat training time and at test time.
We find that eye-tracking features lead to a significant increase inPoS tagging accuracy, and that type-level aggre-gates work better than token-level features.2 The Dundee TreebankThe Dundee Treebank (Barrett et al, 2015) is aUniversal Dependency annotation layer that hasrecently been added to the world?s largest eye-tracking corpus, the Dundee Corpus (Kennedy etal., 2003).
The English portion of the corpus con-tains 51,502 tokens and 9,776 types in 2,368 sen-tences.
The Dundee Corpus is a well-known andwidely used resource in psycholinguistic research.The corpus enables researchers to study the read-ing of contextualized, running text obtained un-der relatively naturalistic conditions.
The eye-movements in the Dundee Corpus were recordedwith a high-end eye-tracker, sampling at 1000 Hz.The corpus contains the eye-movements of ten na-tive English speakers as they read the same twentynewspaper articles from The Independent.
The1 5 10 15 20 25 30 35 40 45 50Number of iterations747576777879808182Dev.tagging accuracyfullbaselineFigure 2: Tagging accuracy on development data(token-level) as a function of number of iterationson baseline and full model.corpus was augmented with Penn Treebank PoSannotation by Frank (2009).
When construct-ing the Dundee Treebank, this PoS annotationwas checked and corrected if necessary.
In thepresent paper, we use Universal PoS tags (Petrovet al, 2011), which were obtained by automati-cally mapping the original Penn Treebank annota-tion of the Dundee Treebank to Universal tags.3 Type-constrained second-order HMMPoS taggingWe build on the type-constrained second-orderhidden Markov model with maximum entropyemissions (SHMM-ME) proposed by Li et al(2012).
This model is an extension of thefirst-order max-ent HMM introduced by Berg-Kirkpatrick et al (2010).
Li et al (2012) de-rive type constraints from crowd-sourced tag dic-tionaries obtained from Wiktionary.
Using typeconstraints means confining the emissions for agiven word to the tags specified by the Wiktionaryfor that word.
Li et al (2012) report a con-siderable improvement over state-of-the-art unsu-pervised PoS tagging models by using type con-straints.
In our experiments, we use the tag dictio-naries they made available2to facilitate compari-son.
Li et al?s model was evaluated across ninelanguages and outperformed a model trained onthe Penn Treebank tagset, as well as a models thatuse parallel text.
We follow Li et al?s approach, in-cluding the mapping of the Penn Treebank tags to2https://code.google.com/archive/p/wikily-supervised-pos-tagger/580EARLYFirst fixation durationw-1 fixation probabilityw-1 fixation durationFirst pass durationLATETotal regression-to durationn long regressions to wn refixationsRe-read probabilityn regressions to wBASICTotal fixation durationMean fixation durationn fixationsFixation probabilityREGFR.n regressions from wn long regressions from wTotal regression-from durationCONTEXTw+1 fixation probabilityw+1 fixation durationw+2 fixation probabilityw+2 fixation durationw-2 fixation probabilityw-2 fixation probabilityNOGAZEB.Word lengthBNC log frequencyw-1 BNC log frequencyBNC forward transitional log probabilityBNC backward transitional log probabilityNOGAZED.Word lengthDundee log frequencyw-1 Dundee log frequencyDundee forward transitional log probabilityDundee backward transitional log probabilityTable 1: Features in feature selection groups.the Universal PoS tags (Petrov et al, 2011).
Fig-ure 1 shows a graphical representation of a second-order hidden Markov model.Li et al explore two aspects of type-constrainedHMMs for unsupervised PoS tagging: the use of asecond-order Markov model, and the use of textualfeatures modeled by maximum entropy emissions.They find that both aspects improve tagging accu-racy and report the following results for Englishusing Universal PoS tags on the Penn Treebank:first-order HMM 85.4, first-order HMM with max-ent emissions 86.1, second-order HMM 85.0, andsecond-order HMM with max-ent emissions 87.1.Li et al employ a set of basic textual features forthe max-ent versions, which encode word identity,presence of a hyphen, a capital letter, or a digit,and word suffixes of two to three letters.4 ExperimentsFeatures Based on the eye-movement data inthe Dundee Corpus, we compute token-level val-ues for 22 features pertaining to gaze and comple-Features TANOGAZEDUN 81.03NOGAZEBNC 80.69BASIC 80.30EARLY 79.96LATE 79.87REGFROM 79.62CONTEXT 79.53Best Group Comb (All) 81.37Best Gaze-Only Comb (BASIC-LATE) 80.45Table 2: Tagging accuracy on the development set(token-level) for all individual feature groups, forthe best combination of groups and for the bestgaze-only combination of groups.ment them with another nine non-gaze features.Word length and word frequency are known tocorrelate and interact with gaze features.
We usefrequency counts from both a large corpus (theBritish National Corpus, BNC) and the DundeeCorpus itself.
From these corpora, we also ob-tain forward and backward transitional probabil-ities, i.e., the conditional probabilities of a wordgiven the previous or next word.All gaze features are averaged over the ten read-ers and normalized linearly to a scale between 0and 1.
We divide the set of 31 features, which welist in Table 1, into the following seven groups inorder to examine for their individual contribution:1.
EARLY measures of processing such as first-pass fixation duration.
Fixations on previouswords are included in this group due to pre-view benefits.
Early measures capture lexicalaccess and early syntactic processing.2.
LATE measures of processing such as numberof regressions to a word and re-fixation prob-ability.
These measures reflect late syntacticprocessing and disambiguation in general.3.
BASIC word-level features, e.g., mean fixa-tion duration and fixation probability.
Thesemetrics do not belong explicitly to early orlate processing measures.4.
REGFROM includes a small selection of mea-sures based on regressions departing from atoken.
It also includes counts of long regres-sions3.
The token of departure of a regression3defined as saccades going further back than wi?2581System TABaseline (Li et al, 2012) 79.77NoTextFeats 74.61NoTextFeats + Best Group Comb (token) 79.56NoTextFeats + Best Group Comb (type) 81.94*Token-level featuresBest Gaze Group (BASIC) 80.42*Best Gaze-Only Comb (BASIC+LATE) 80.45*Best Single Group (NOGAZEDUN) 80.61*Best Group Comb (All) 81.00*Type-averaged featuresBest Gaze Group (BASIC) 81.28*Best Gaze-Only Comb (BASIC+LATE) 81.38*Best Group (NOGAZEDUN) 81.52*Best Group Comb (All) 82.44*Table 3: Tagging accuracy for the baseline, formodels with no text features and for our gaze-enriched models using type and token gaze fea-tures.
Significant improvements over the baselinemarked by * (p < 10?3, McNemar?s test).can have syntactic relevance, e.g., in gardenpath sentences.5.
CONTEXT features of the surrounding to-kens.
This group contains features relating tothe fixations of the words in near proximity ofthe token.
The eye can only recognize wordsa few characters to the left, and seven to eightcharacters to the right of the fixation (Rayner,1998).
Therefore it is useful to know the fix-ation pattern around the token.6.
NOGAZEBNC includes word length andword frequency obtained from the British Na-tional Corpus, as well as forward and back-ward transitional probabilities.
These werecomputed using the KenLM language model-ing toolkit (Heafield, 2011) with Kneser-Neysmoothing for unseen bigrams.7.
NOGAZEDUN includes the same features asNOGAZEBNC, but computed on the DundeeCorpus.
They were extracted using CMU-Cambridge language modeling toolkit.4Setup The Dundee Corpus does not include astandard train-development-test split, so we di-4http://www.speech.cs.cmu.edu/SLM/toolkit.htmlFeature groups Accuracy ?All groups 81.00?NOGAZEBNC 80.80 ?0.20?NOGAZEDUN 80.28 ?0.52*?BASIC 80.20 ?0.08?EARLY 79.78 ?0.42*?LATE 79.53 ?0.25?REGFROM 79.24 ?0.29*?CONTEXT (Baseline) 79.77 +0.53*Table 4: Results of an ablation study over fea-ture groups on the test set on token-level features.Significant differences with previous model aremarked by * (p < 0.05, McNemar?s test).vided it into a training set containing 46,879 to-kens/1,896 sentences, a development set contain-ing 5,868 tokens/230 sentences, and a test set of5,832 tokens/241 sentences.To tune the number of EM iterations requiredfor the SHMM-ME model, we ran several exper-iments on the development set using 1 through50 iterations.
The result is fairly consistent forboth the baseline (the original model of Li et al(2012)) and the full model (which includes all fea-ture groups in Table 1).
Tagging accuracy as afunction of number of iterations is graphed in Fig-ure 2.
The best number of iterations on the fullmodel is five, which we will use for the remainingexperiments.We perform a grid search over all combinationsof the seven feature groups, using five EM iter-ations for training, evaluating the resulting mod-els on token-level features of the development set.We observe that the best single feature group isNOGAZEDUN, the best single group of gaze fea-tures is BASIC, the best gaze-only group combi-nation is BASIC-LATE and the best group combi-nation is obtained by including all seven featuregroups.
Using all feature groups outperforms anyindividual feature group on development data.
Theperformance of all the individual groups and of thebest group combinations can be seen in Table 2.We run experiments on the test set and report re-sults using the best single group (NOGAZEDUN),the best single gaze group (BASIC), the best gaze-only group combination (BASIC-LATE) and thebest group combination (all features).Following Barrett and S?gaard (2015), we con-trast the token-level gaze features with features ag-582gregated at the type level.
Type-level aggregationwas used by Barrett and S?gaard (2015) for super-vised PoS tagging: A lexicon of word types wascreated and the features values were averaged overall occurrences of each type in the training data.As our baseline, we train and evaluate the origi-nal model proposed by Li et al (2012) on the train-test split described above, and compare it to themodels that make use of eye-tracking measures.To get an estimate of the effect of the textualfeatures of Li et al, we train a model without thesefeatures, labeled NOTEXTFEATS.
We also aug-ment this model with the best combination of fea-ture groups.Results The main results are presented in Ta-ble 3.
We first of all observe that both type-and token-level gaze features lead to significantimprovements over Li et al (2012), but type-level features perform better than token-level.
Weobserve that the best individual feature group,NOGAZEDUN, performs better than the best in-dividual gaze feature group, BASIC and the bestgaze-only feature group, BASIC+LATE.
This istrue on both type and token-level.
Using thebest combination of feature groups (All features)works best for both type- and token-level features.Also when excluding the textual feature modelgaze helps and type-level features also work bet-ter than token-level here.A feature ablation study (see Table 4) supportsthe hierarchical ordering of the features based onthe development set results (see Table 1).5 Related WorkThe proposed approach continues the work of Bar-rett and S?gaard (2015) by augmenting an unsu-pervised baseline PoS tagging model instead of asupervised model.
Our work also explores the po-tentials of token-level features.
Zelenina (2014)is the only work we are aware of that uses gazefeatures for unsupervised PoS tagging.
Zelenina(2014) employs gaze features to re-rank the outputof a standard unsupervised tagger.
She reports asmall improvement with gaze features when evalu-ating on the Universal PoS tagset, but finds no im-provement when using the Penn Treebank tagset.6 DiscussionThe best individual feature group is NOGAZE-DUN, indicating that just using word length andword frequency, as well as transitional probabili-ties, leads to a significant improvement in taggingaccuracy.
However, performance increases furtherwhen we add gaze features, which supports ourclaim that gaze data is useful for weakly supervis-ing PoS induction.Type-level features work noticeably better thantoken-level features, suggesting that access to eye-tracking data at test time is not necessary.
On thecontrary, our results support the more resource-efficient set-up of just having eye-tracking dataavailable at training time.
We assume that thisfinding is due to the fact that eye-movement datais typically quite noisy; averaging over all tokensof a type reduces the noise more than just averag-ing over the ten participants that read each token.Thus token-level aggregation leads to more reli-able feature values.Our finding that the best model includes allgroups of gaze features, and that the best gaze-only group combination works better than the bestindividual gaze group suggest that different eye-tracking features contain complementary informa-tion.
A broad selection of eye-movement featuresis necessary for reliably identifying PoS classes.7 ConclusionsWe presented the first study of weakly super-vised part-of-speech tagging with eye-trackingdata, using a type-constrained second-order hid-den Markov model with max-ent emissions.
Weperformed experiments adding a broad selectionof eye-tracking features at training time (type-level features) and at test time (token-level fea-tures).
We found significant improvements overthe baseline in both cases, but type averagingworked better than token-level features.
Our re-sults indicate that using traces of human cognitiveprocessing, such as the eye-movements made dur-ing reading, can be used to augment NLP models.This could enable us to bootstrap better PoS tag-gers for domains and languages for which man-ually annotated corpora are not available, in par-ticular once eye-trackers become widely availablethrough smartphones or webcams (Skovsgaard etal., 2013; Xu et al, 2015).AcknowledgmentsThis research was partially funded by the ERCStarting Grant LOWLANDS No.
313695, as wellas by Trygfonden.583ReferencesMaria Barrett and Anders S?gaard.
2015.
Reading be-havior predicts syntactic categories.
CoNLL 2015,pages 345?349.Maria Barrett,?Zeljko Agi?c, and Anders S?gaard.
2015.The dundee treebank.
In The 14th InternationalWorkshop on Treebanks and Linguistic Theories(TLT 14), pages 242?248.Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cote,John DeNero, , and Dan Klein.
2010.
Painless un-supervised learning with features.
In Proceedings ofNAACL, pages 582?590.Christos Christodoulopoulos, Sharon Goldwater, andMark Steedman.
2010.
Two decades of unsuper-vised POS induction: How far have we come?
InProceedings of EMNLP, pages 575?584.Stefan L. Frank.
2009.
Surprisal-based comparison be-tween a symbolic and a connectionist model of sen-tence processing.
In Proceedings of the 31st annualConference of the Cognitive Science Society, pages1139?1144.Kenneth Heafield.
2011.
KenLM: faster and smallerlanguage model queries.
In Proceedings of theEMNLP 2011 Sixth Workshop on Statistical Ma-chine Translation, pages 187?197.Alan Kennedy, Robin Hill, and Jo?el Pynte.
2003.
Thedundee corpus.
In Proceedings of the 12th Europeanconference on eye movement.Shen Li, Jo?ao Grac?a, and Ben Taskar.
2012.
Wiki-ly supervised part-of-speech tagging.
In EMNLP,pages 1389?1398.Slav Petrov, Dipanjan Das, and Ryan McDonald.2011.
A universal part-of-speech tagset.
CoRRabs/1104.2086.Keith Rayner.
1998.
Eye movements in reading andinformation processing: 20 years of research.
Psy-chological bulletin, 124(3):372?422.Henrik Skovsgaard, John Paulin Hansen, and EmilieM?llenbach.
2013.
Gaze tracking through smart-phones.
In Gaze Interaction in the Post-WIMPWorld CHI 2013 One-day Workshop.P.
Xu, K. A. Ehinger, Y. Zhang, A. Finkelstein, S. R.Kulkarni, , and J. Xiao.
2015.
TurkerGaze: Crowd-sourcing saliency with webcam based eye tracking.arXiv:1504.06755.Maria Zelenina.
2014.
Part of speech induction withgaze features.
Master?s thesis, University of Edin-burgh, United Kingdom.584
