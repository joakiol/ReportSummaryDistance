COMMON HEURISTICS FORPARSING, GENERATION, AND WHATEVER.
.
.HASIDA.
K6itiIr/stitute for New Generation Computer Technology (ICOT)Mita Kokusai Bldg.
21F.
1-4-28 Mita, Minato-ku, Tokyo 108 JAPANTel: -4-81-3-3456-3069, E-mail: hasida@icot.or.jpABSTRACTThis paper discussers general hem'istics to controlcomputation on symbolic constraints represented interms of first-order logic programs.
These heuristicsare totally independen!
of specific domains and tasks.Efficient computation for sentence parsing and genera-tion naturally emerge fi'om these heuristics, capturingthe essence of standar d parsing procedures and seman-tic head-driven generat:ion.
Thus.
the same representa-tion of knowledge, inclfiding grammar and lexicon, canbe exploited in a multi-directional manner in variousaspects of language use.r1 IntroductionOne lesson to learn from the repeated failure to designlarge AI systems in general is that the information flowin the cognitive systems is too complex and diverse tostipulate in the design of these AI systems.
To capturethis diversity of information flow.
therefore.
At systeinsmust be designed at a more abstract level where direc-tion of information flow is not explicit,.This is where constrai~t paradigm comes in.
Sinceconstraints do not stipulate the direction of informa-tion flow or processing Order, constraint-based systemscould be tailored to halve tractable complexity, unlikeprocedural systems, which stipulate information flowand thus quickly become too colnplex for human de-signers to extend or maintain.Naturally, the key issue in the constraint-based ap-proach is how to control information flow.
A very gen-eral control schema independent of any specific domainor task is vitally Ile('essal'y for the success of this ap-proach.The present paper introduces a system of constraintin a \[o,-m of logic progi'am, and a set of very generalheuristics to control symbolic operation on the con-straints.
The sS'mboli( I operations herr are r('gar(h'das Iransforming logic programs.
"lhcv are quite per-missivr operations as a whole, allowing very diverseinformation processing involving top-down, bottom-upand other directions of informal ion flow.
The heuristicscontrol this computation so that only relevant infor-mation should be exploited and the resuhing represen-tation should be compact.
Parsing and generation ofsentences are shown to be efficiently done under theseheuristics, and a standard parsing algorithm and thesemantic head-driven generation \[8\] naturally emergethereof.The rest of the paper is organized as follows.
Sec-tion 2 describes the syntax of our system of constraint.Section 3 defines the symbolic computation on theseconstraints, and proposes a set of general heuristics tocontrol computation.
Section 4 and Section 5 showhow sentence parsing and generation are executed effi-ciently by those heuristics.
Finally, Section 6 concludesthe paper.8.1.2 Const ra in t  NetworkA program is a set of clauses.
A clause is a set of lit-erals.
A literal is an atomic constraint with a sign infront, of it.
The sign is a '+', ' - ' ,  or nil.
A literal witha sign '+' or nil is called a positive literal and one witha sign "-' is a negative literal.
An atomic constraint isan atomic formula such as p(X,Y,Z), a bindin 9 such asX=f(Y), a feature specification such as a(X,Y), or anequality such as X=Y.
Names beginning with capital et-ters represent variables, and the other names predicatesand functions.
A feature specification may be regardedas an atomic formula with a special binary predicatecalled a feature.
A feature is a partial function from thefirst argument to the second argument: that is, if a isa feature and both a(X,Y) and a(X,Z) hold, then Y=Zmust also hold.
The other atomic constraints may beunderstood in the standard fashion.
The atomic con-straints other than equalities are called proper atomicconstraints.A clause is written as a sequence of literals it containsfollowed by a semicolon.
The order among literals isnot significant.
So (1) is a clause, which may also bewritten as (2).
(I) -p(U,Y) +q(Z) -U=f(X) -X=Z;(2) +q(Z) -p(f(Z),Y);A clause containing a literal with null sign is a defini-tion clause of the predicate of that literal.
A predicatehaving definition clauses are called defined predicate,and its meaning is defned in terms of completion basedon the definition clauses.
For instance, if the definitionclauses of predicate p are those in (3), the declarativemeaning of p is given by (4).
(3) p(X) -q(X,a); p(f(X)) -r(X);(4) VA{p(A) ?0 {3Y(q(A,Y)  AY  = a)V3X(A = f (X )  A r(X))}}A predicate which is not a defined predicate is called afree' predicate.
There is a special 0-ary defined predicatet rue.
Its definition clauses are called top clauses.
Atop clause corresponds to the query clause of Prolog.although the latter has fa l se  instead of t rue.Programs are regarded as constraint networks.
Forinstance, the following program is a network as in Fig-ure 1.
(i) t rue -member(a,X);(ii) member(A, \[AIS\] ) ;(iii) member(A, \[B IS\]) -member(A,S) ;Figure 1: Constraint NetworkIn graphical representations like Figure 1, a '," oftenrepresents an argument, of an atomic constraint.
Thereare two types of nodes: arguments, and proper atomicconstraints, An argument is involved in at most oneproper atomic constraint, but in any number of equal-ities.
An argument bound to a constant is identifiedwith that constant.
That is, the first argument of abinding ,=a.
for instance, is represented simply by a.A link, represented as a curve, connects two nodes.
Forany two (possibly the same) nodes, there is at mostone link connecting them.
A link connecting two argu-ments is an equality between them.
A link connectingtwo proper atomic constraints is called an inferencelink.
No link connects an argument and an atomicconstraint.
Although often not explicitly shown, aninference link accompanies equalities between the cor-responding arguments of the two proper atomic con-straints.
A clausal domain of clause ~ is the part of theconstraint network consisting of the atomic constraintsreferred to as literals in ?
except equalities concerningconstants.
A clausal domain is depicted by a closedcurve enclosing the included atomic constraints.
Theshort thick arrows indicate the references to the atomicconstraints as positive literals in clauses.
A predicatedomain of predicate 7r consists of all the proper atomicconstraints with r (binding X=f (Y) is regarded as hav-ing binary free predicate =:f, for instance), inferencelinks among them, and equalities accompanying theseinference links.The instantiation possibilities of the constraint net-work is defined by regarding nodes and links as sets.Those sets are disjoint of each other.
An instance ofan argument corresponds to an individual in the do-main of interpretation, and an instance of an atomicconstraint corresponds to an atomic proposition.
Con-stants (bindings to constants) and 0-ary atomic formu-las are singleton sets.
A link ~ between nodes o andstands for a symmetric relation.
That is, ,~ = R U R -1for some relation R C o x'8.
We call {z 6 ol3y x6y} theo-domain of 6.
Every link in a clausal domain or thepredicate domain of a defined predicate is of the formR U R -1 for some bijection R. Let ~ be the transitiveclosure of the union of all the links, x~y means thatx and y correspond to the same object in the domainof interpretation if x and y belong to arguments, andthat they correspond to the same atomic proposition ifthey belong to proper atomic constraints.
We say thatnode o subsumes node/9 when a/~ D '8/,~; that is, forevery y 6 j3 there exists x 6 o such that xAy.
For eachpair of a proper atomic constraint o and an argument'3 of o, there is a bijection p from o to ,8, such that xpyholds iff y 6 '3 is an argument of x 6 o. p is called arole assignment.Consider a part T' of the constraint network andthe minimum equivalence relation including the linksand the role assingments in "P. A layer of T' is anequivalence class with respect o this relation.
A split-ting domain is a part S of the network in which everylink is of the form R \[3 R -1 where R is the union of(o n f )  x (,8 n ?)
over all the layers f of S and oand ,8 are the two endnodes of that link.
Thus, if alink in a splitting domain splits into two links sharingan endnode o and having disjoint s-domains, then theentire splitting domain splits into two separate splittingdomains each containing one of these two links.
Theclausal domains and predicate domains are assumed tobe splitting domains.A joint is a part of a node which connects the nodewith a link or more.
Figure 2 shows some joints.
Thefigures below illustrate the instantiation possibilities ofthe networks hown above by depicting each node as anellipse enclosing its instances, and each link as a bundleof curves representing the pairs belonging to the link.A joint J of node o is depicted as an arc convex towardso crossing the links involved in J .
A joint involving justone link, as in (a) and (b), is called a unitary joint, andone containing several inks, as in (c) and (d), is calleda multiple joint.
Distinct links involved in the samemultiple joint on node o have disjoint a-domains.
Ajoint is partial if it stretches out of the involved links,as in (b) and (d).
and total otherwise, as in (a) and(c).
The union of o-domains of the links involved inthe same joint on node o is equal to o.
A total unitaryjoint as in (a) is not explicitly shown as an arc.
Partialjoints on node o are complementary when the unionof the a-domains of the links involved in them is o.Complementary joints are indicated by a dashed arccrossing these links.
So the union of the s-domains ofthe three links is o in (e), When node o and ~3 areconnected by link 6 and the joint of '8 involving 6 istotal and unitary, o and 6 are said to dominate ~.The initial structures of predicate domains are shownin Figure 3.
Such structures, as well as the otherstructures, will change as computation proceeds.3 Computat ionHere we introduce a method of symbolic computationtogether with some general control heuristics for con-trolling computation.
There are two types of symbolicoperation: subsumption and deletion.
Here we chiefly82O~ CE CE Ct Ctj )(a) (b) (c) (d) (e)Figure 2: Joints between Nodes and Linksp(...) )(...)p(...)/p(...))(...) p(...)Bound Predicate Free PredicateFigure 3: Predicate Domains!concern ourselves with subsumption.3.1 Subsumpti0n'Subsumption" means two things: subsumption rela-tion.
which we defined above, and subsumption opera-tion.
which we discuss below.The purpose of a subsumption is to let informationflow from a node.
A node o may have probes, c~ iscalled the origin of these probeR.
Each probe is placedon a link and directed tbwards an endnode.
The originof a probe subsumes the' node behind the probe.
Probestransmit information of their origins across the networkvia subsumptions.
The origin of probes has its scope.The scope of node o is the part S of the constraintnetwork satisfying the following conditions.?
$ is a connected graph containing a.?
A node 13 is behind a probe r on link 6 and withorigin a, iff/3 is in 5" but 6 is not.?
(~ subsumes every node in $.So the scope of a may be illustrated as in Figure 4,where arrows are probes, which just cover the boundaryFigure 4: Scope of Nodeof the scope.Every node a can just once create probes on all thelinks connected to a so that a is behind these probes.Subsumption extends the scope of a node by advancingprobes, while preserving the instantiation possibilitiesof the network described above.
We consider a sub-sumption from node iota to node ~ along link 6.
~, ~,and 6 are called the input node, the target node, and theaxis, respectively, of this subsumption.
The joint J ofinvolving/f is called the target joint.
This subsump-tion extends the scopes of the origins of the probes on6 directed towards ~.
It proceeds as follows.First, the set II of the probes on 6 towards ~ is de-tached from 6, and 6 is shifted from J to another jointJ ' ,  as illustrated in Figure 5.
J!
is a copy of J andis on a node ~' which is a copy of ~.
J '  and ~' may becreated here and now, but may also have been made ina previous subsumption, as mentioned below.
Belowwe proceed so as to make ~0 = ~1 O ~' A ~1 n ~' = @83 Oit.-J "..~.?..8.........
Z G202-Z(Figure 5: Shifting of Link and Augmentation of Foldabilitytrue, where ~0 and (1 stand for ~ before and after thissubsumption, respectively.A joint may be foldable to another joint by a set oforigins of probes.
Each joint, involved here, called afoldable joint, is one obtained by copying zero or moretimes a multiple joint in the initial state of computa-tion.
Typically, a foldable joint is one involving links inthe predicate domain of a defined predicate.
No joint.just created is foldable to any joint.
For any joint Gand set.
O of nodes, there is at most one joint H suchthat (; is foldable to H by O.Let E be the set of origins of the probes in II.
If J isfoldable, then for each joint G the foldability relationextends in the following way, as illustrated in Figure,5, where the foldability relation is depicted by dashedarrows.?
.l is foldable to J '  by E.?
If G is foldable to J by O, then G is foldable toJ '  by O U E.?
If ,1 is foldable to G by O such that O D Z, thenJ '  is foldable to G by O - E.If there has already been a joint to which d is fold-;Lble by E. then J '  is that joint, ~' is the node on J',J '  becomes a total multiple joint, and tile foldabilityrelation remains unchanged.
Otherwise, J '  and ~' arenewly created, 6 dominates ~', and the foldability re-lation is augmented.
We call the former case folding,and the latter unfolding.If c~ is a proper atomic constraint or an argument ofa proper atomic constraint, then & stands for the setwhose elements are this proper atomic constraint andits arguments; otherwise dr = {a}.In the case of unfolding, each node v in ~ is copied tov', and each link a (a y~ ~) connecting v and r/is copiedto a' connecting v' and some node r/'.
71' is the copy ofr/ if r/ E ~ and r/' = r I otherwise.
Relevant Joints arecopied accordingly so a~s to preserve the instantiationpossibilities of the network.There are two cases, splittin 9 and non-splitting,about how to create ~r'.
In the former, it is guaran-teed that no layer of the splitting domain including abefore the copy overlaps with both v and v' after thecopy.
Such a guarantee is obtained iff c~ = R U R -1 forsome bijection R or (inclusive) 6 and a belong to thesame splitting domain.
There is no such guarantee inthe non-splitting case.In the splitting case.
as is illustrated in Figure 6, ther/-domains of a and a'  are disjoint when r/' = r/.v13~O!
~-~OI eV V tnFigure 6: Copy of Links (Splitting)In the non-splitting case, as is illustrated in Figure7, if a was a loop, v and v' is connected by an addi-V o/Tv)  (v 'nFigure 7: Copy of Links (Non-Splitting)tional link representing a relation pertaining to the lay-ers overlapping both v and v'.
Further if a was involvedin a multiple joint of 7/, then a subsumption along o" to7/must be done before creating o"; otherwise the rightinstantiation possibilities cannot be represented.In both splitting and non-splitting cases, the probesthat v had, if any, are deleted, and v and v' are licensedto generate new probes.
Then every remaining probeon a is copied to a probe on a',  towards v', and the sameorigin.
Further, each probe in II is advanced through~' onto every link r (# ~5) connected with ~' so that ~'should be behind the probe.
If there is another probeon r towards ~' and with the same origin, then bothprobes are deleted.Finally, in both folding and unfolding, if ~5 dominatedbefore this subsumption, ~ is deleted because it hasbecome the empty set now.
This deletion propagatesacross links and nodes until possibly non-empty sets84are encountered: that is.
until you come across par-tial or multiple joints of remaining nodes.
1 Now thesubsumption is done.To properly split splitting domains, we must aug-ment this subsumption procedure so that.
a probe maycarry, instead of origin., some information about whichlayers of the relevant splitting domain are involved inthe node behind the probe.
Such probes are transmit-ted from proper atomic constraints to their argumentsand vice versa.
A link is deleted if it contains twoprobes with opposite directions and associated withdisjoint sets of layers.
Further details are omitted dueto the space limitation.So far we have dischssed subsumption in general.Below we describe thee particularities of subsump-tions along equalities and subsumptions along inferencelinks.A subsumption along an equality is triggered by adependency between arguments.
We say that there is adependency between two arguments, when they com-pete with each other and are connected by a dependencypath.
Nodes o and '3 Compete with each other whenthe5" are the first arguments of?
two bindings (as in (=f ( , )  and q=g(,) ) .?
a binding and a feature specification, or?
two feature specifications with the same feature.A dependency path connecting o and 3 is a sequence61~2 ' " /5 ,  of strong equhlities uch that the endpointsof ~i are a,-a and c~i (1 <_ i <_ n), 6i and ~i+x areinvolved in different joihts of c~; one of which is total(1 _< i < n).
a0 = a and o,, = '3.
An equality is strongwhen it belongs to a claiuse or the predicate domain ofa defined predicate, or g'hen a subsumption has takenplace along that equality.A probe r on an equality ~ might trigger a subsump-tion to advance rr, when: there is a dependency betweenthe origin c~ of rr and another node/3 and 3 is includedin a dependency path connecting ~ and /3.Suppose the scope of o includes another node L3 com-peting with a.
If the proper atomic constraints A andB, each involving ~ and '3 as the first argument, re-spectively, are connected by an inference link 6. then/5absorbs B, as shown in, Figure 8.
That is, the jointo~=f(.)
~=f(-)13=f(,) 13=f(.
)Figure 8: Absorption by Linkof B involving /~ is modified so that, /3 dominates /3,because A has turned out to subsume B.
Any otherinference link involved in this joint is deleted, becauseIThis combination of copy and deletion is vacuous and thusmay be omitted in actual implementation for the unfolding cases.The deletion of probes in the splitting case may also be avoidedin such a situation.it has turned out to be the empty set.
Of course eachequality accompanying 6 must absorb its endnode in Bat the same time.
If there is no inference link between Aand B, then B is deleted.
Deletions of links and nodespropagate so long as the empty set is encountered, assaid before.A subsumption along an inference link may be trig-gered by cost assigned to the input node.
Each literalin a clause may be assigned a cost.
Similarly to the as-sumability cost of Hobbs et al \[5\], the cost of a literalcorresponds to the difficulty to abductively assume itsnegation.
For instance, if you want to assume atomicconstraint ~ by using a clause backwards whereas thecost of the literal -~  in this clause is not zero, then youare to do something in order to cancel the cost.
In thissense, an atomic constraint with a cost is regarded as agoal to achieve, and the abductive usage of the clausewhich gives rise to the goal is regarded as the motiva-tion to set up that goal.
A cost may be canceled bymaking the atomic constraint subsume another whichis more readily believable.
That is, a goal is fulfilledwhen it is established by some reason other than itsmotivation.The input node of a subsumption along an inferencelink is th e goal atomic constraint in the rest of thepaper.
2 Such a subsumption eliminates the cost if thetarget node has been derived from the top clause with-out recourse to that very subsumption.
Otherwise thecost is inherited into the clause which contains the out-put node.
In a Horn clause normally used with all theatomic constraints therein being true, the head literalinherits the cost from a body atomic constraint, andthe body atomic constraints inherit the cost from thehead literal.
We neglect the cost inheritance amongbody atomic constraints.3.2 Heur ist icsSubsumptions along equalities and those along infer-ence links both encompass top-down and bottom-upinformation flow.
Some heuristics are necessary to con-trol such an otherwise promiscuous system of computa-tion so that more relevant pieces of information shouldbe exploited with greater preferences.Each heuristic for a subsumption along an equalityis that one of the following conditions raises the pref-erence of such a subsumption.
(H1) The origin of a probe on the axis is close to (typ-ically included in) the top clause or is a constant.
(tI2) A dependency path involving the axis and con-necting an argument with the origin of a probeon the axis is short.Both these conditions are regarded as indicating thatthe transmitted information (about the origin) is highlyrelevant o the destination of this transmission.
In thisconnection, a subsumption along an equality is unlikelyto happen if the axis belongs to the predicate domainof a free predicate and the target joint is partial, sincethe conveyed information would not be very relevantto the target node.~Subsumptions for checking consistency need not be triggeredby cost.85As for subsumptions along inference links, the fol-lowing conditions each raise the preference.
(H3) Corresponding arguments of the input node andthe target node are connected via short depen-dency paths with the same node.
(That is, thosearguments are 'shared.
')(H4) The target node has already been derived fromthe top clause.
(H3) raises the possibility for instances of the two ar-guments to coincide in the domain of interpretation.
(H3) amounts to a generalization (or relaxation) of thecondition on which an inference link absorbs one of itsendnodes.
(I-14) guarantees that the subsumption inquestion will lead to an immediate limination of thecost.
of the input node.
Probably (H4) could be relaxedto be a graded condition.4 ParsingLet us consider a simple case of context-free parsingbased on the following grammar.P~ap---~ ppA parsing based on this grammar is formulated by theprogram as follows.
(5) t rue  -p(Ao,B) -Ao=\[alA1\] -Ai=\[aIA2\] .
- ' ;(?)
p(\[alX\]  ,X) ;(q/) p(X,Z) -p(X,Y) -p(Y,Z) ;I)epicted in Figure 9 are the four types of clauses cre-(a) (b)(c) (d)Figure 9: Clauses Produced through Parsingated by this parsing process.
A *= \[a I*\] is a shorthandrepresentation for a .=\[* l*\]  plus an equality betweenthe second argument and (the argument bound by) a.
(a) is a copy of clause ?
in (5), and the other clauses arecopies of ~.
A label i of a link means that the relevantpart of the network is in the scope of argument Ai.
Thereason why only these types of clauses are generatedis that in this case every dependency arises between a*= \[a I*\] in the top clause and another .= \[a I*\] some-where else and the first argument of the former is theorigin of the subsumptions to resolve that dependency.A strict proof will be obtained by mathematical induc-tion.
Since the number of these clauses is O(n 3) due to(d) and each of them may be generated in a constanttime, the time complexity of the entire parsing is 0(773).where n is the sentence length.
Each clause is guaran-teed to be generated in a constant ime, because achfoldability test can be performed in a constant ime, asdiscussed later.
By employing a general optimizationtechnique, we can eliminate the clauses of type (d), sothat the space complexity is reduced to O(n2).
Thus,our general control scheme naturally gives rise to stan-dard parsing procedures such as Eaxley's algorithm andchart parsing.
(5) is graphically represented as Figure 10.
We,,,...--"' -P-true ~ .Figure 10: Parsing (1)omit the links involved in the predicate domain of afree predicate, until they are modified as in Figure 8.Thus no links among ,=\ [a le \ ] s  axe shown in Figure10.
Here is a dependency between the first .=\ [a lo \ ]  inthe top clause and the o=\[alo\] in ~, as indicated bythe dependency paths, which consist of thick links.
Tolet information flow from the top clause following theabove heuristic (H1), we are to do the two subsump-tions indicated by the two thin arrows.Those subsumptions copy # to ~1 and ?
to ~l ,  re-suiting in Figure 11.
For expository convenience, we-h-trueFigure lh  Parsing (2)86assume here without loss of generality that copying of aclause produces a separate clause rather than one shar-ing atomic constraints with the original clause.
Notethat the first argument of the *=\[al*\] in ?1 is sub-sumed by h0.Computation goes on into the same direction, andthe two subsumptions are to happen as shown in Fig-ure 11.
Folding takes place this time, and the result isto shift the two inference links upwards, as in Figure12.
Now the first *=\[al*\] in the top clause dominates/......f'-"~ ..m.-true0 1?
: L2M rLY 'Figure 42: Parsing (3)the *=\[al*\] in ~1 as indicated by the inference linkbetween them.
becaus e, as indicated by number 0 in~l, the first argument of the former is within the scopeof the first argument of the latter.
Now the equalityin the right-hand side of ~1 is within the scope of A1,as indicated in the figure.
This subsumption also en-genders a new set of dependencies between the firstargument of the second .= \[a I*\] in the top clause andthat of .= \[a \] o3 in ~, as indicated again by thick linksin Figure 12.
By executing the indicated subsumptionfollowing (H1), 31 is copied to q"2. so that we obtainFigure 13.
Further advancing subsumptions as shownthere, we get Figure 14.
Computation goes on in thesimilar way.As mentioned above, we are able to assume that eachfoldability test is perfo~:med in a constant ime.
Thisassumption is justified by, for instance, sorting the fold-ability information from each joint in the chronical or-der of the first subsumption which advanced probeswith the relevant origin.
In the present parsing exam-pie.
this order happens to be the increasing order ofthe suffix i of Ai.It.
is straightforward to integrate such a phrase-structure parsing with computation on internal struc-tures of grammatical ca~tegories represented in terms offeature bundles, for instance.
See \[2, 3\] for further de-tails in this regard.
Note that the above derivation ofthe parsing process is more general than the parsing-as-deduction approaches \[6, 7\], because it is free fromstipulation of the left-to-right and to-down processingdirection and also from task-dependency with regardto parsing or context-free grammar.87i/......i--"~-- -D-trueFigure 13: Parsing (4)Figure 14: Parsing (5)5 Generat ionHere we consider how to verbalize the following seman-tic content in English.S~laughed,k im~This means that Kim laughed, based on SituationTheory \[1\].
That is, in some situation S there is anevent which is of the sort laughed and whose agentis kira.
So a sentence we might want to generate is'Kim laughed."
S may be interpreted as, for instance,the speaker's model of the hearer's model of the world.A state of affairs ((laughed, kira)) will be regarded asvariable L1 constrained by two feature specificationsrel (Ll,laughed) and agt (Li ,kim).The initial state of computation could be formulatedin terms of a program including the following clauses.among much more others.
(A) true -s(SEM,WO,WI) -S~SEM -say(WO)-SELl  $, -rel(Ll,laughed) $-agt(Ll,kim) $ ...;(B) s(SEM,X,Z) -np(SBJSEM,X,Y)vp(SEM,SBJSEM,Y,Z) ;(C) np(kim,X,Y) -X=\['kim 'IY\]$;(D) vp(L,AGT,X,Y) -X=\['laughed'IY\] $-rel (L, laughed) -agt (L, AGT) ;say(W0) means that the utterance beginning at W0should be actually uttered.
S~SEM and SELl seper-at, ely exist, in (A), because the next utterance neednot directly refer to L1.
For instance, one can meanthat Kim laughed by saving "Do you know that.
Kimlaughed?'
instead of just 'Kim laughed,' or by doingsomething other than utterance.
One might even justgive up the goal and say something quite different.A '$" attached to an atomic constraint represents acost, so that the atomic constraint is a goal.
The threegoals in (A) altogether amount o a macroscopic goalto make a state of affairs ((laughed, kim)) hold in sit-uation S.What we would like to demonstrate below is againthat the control heuristics described in Section 3 tendto trigger the right operations depending upon the com-putational context, provided that the current goal is tobe reached by some linguistic means; that is, by eventu-ally uttering some sentence.
Below we pay attention toonly one maximal consistent structure of the sentenceat a time just for the sake of simplicity, but the actualgeneration process may involve OR-parallel computa-tion similar to that in parsing of the previous ection.Figure 15 graphically represents clauses (A) and(C).
A proper atomic constraint with a binary pred-icate, possibly together with equalities involving thetwo arguments, is represented here as an arrow from(an argument equalized with.)
the first argument to (anargument equalized with) the second argument.
Linksin predicate domains are selectively displayed for ex-pository simplicity.The most.
probable operations to take place hereare subsumptions involving one of these three goals.There should be innumerable combinations for such~?.
~/ ....... subsumli~n.
.
.
"laughed'Figure 15: Generation (1)subsumptions, because the speaker's lexicon must in-clude a large number of atomic constraints of the form?
~ ?
,  re l ( .
, . )
and agt ( ?
, ? )
,  even though subsump-tions with extralinguistic parts of the constraints areexcluded ue to the above provision that the currentgoal is to be fulfilled by linguistic means.However, two of such subsumptions are preferred tothe others.
One is the subsumption concerning thetwo ?~?s  in (A), and the other is from the re l (#, ?
)in (A) to that in (D).
In both cases, the two atomicconstraints share the same argument for the same ar-gument place, which raises the preference due to (H3).Let us tentatively choose just the latter subsumptionin this particular presentation.
No big difference wouldfollow in the long run, even if the former subsumptionor both were chosen instead.By the subsumption concerning the two re l ( .
,e )s ,we obtain the structure shown in Figure 16.
We havei rpd?nsubsumption- ...... ~"laughed'Figure 16: Generation (2)88icopied clause (D) to (D!).
because the re l ( ,  , , )  in (A)is a goal.
Now in Figure 16. vp( , , , , , , , )  in (D') isa goal.
by inheriting the cost from re l ( , , , )  of (A).The cost of ,= \ [ , \ [ , \ ]  in (D') is inherent, as indicatedin (D).
Now the most probable next computation isthe sequence of subsumptlons along the thick hnk(s)constituting a dependency path.
Following the heuris-tic (Hi).
those subsumptions propagate from the topclause.
After that.
the inference link between the twoagt ( , , , ) s  absorbs the 6tie in (B).This gives us Figure '17.
(D') has not.
been dupli-ikimlaughed)n ')"laughed'Figure 17; Generation (3)cated here.
because thd above subsumptions did notactually duplicate any clause.
In this context, the sub-sumption concerning the two vp ( .
, .
, .
,  .)
s is possible,since the one in (D') is a goal.
Due to (H3), this sub-sumption is more prefera~ble than the others concerningtwo vp( .
, .
, .
,  e)s, because their first arguments areboth connected to kim (that is, the first argument of?
=kim) via.
short dependency paths.
As a result, (B)is copied to (B') and the vp( .
, .
, .
, . )
in (B') is domi-nated by that.
in (D'), aS in Figure 18.Now that s ( .
, .
, . )
in (B') is anew goal, it is causedto subsume another s(* ,* ,* )  in (A).
According to(H4), this subsumption:, is particularly preferable be-cause (A) is the top clause.
On tile other hand.
thesubsumption from the first argument of np( .
, .
, . )
in(B') to the first argument of np( .
, .
, . )
in (C) couldtake place here, to resolve the cyclic dependency about.kim referred to from (N) and (C).
This subsumptionis the most probable operation concerning this depen-dency in this context, because it is along the shortestrelevant dependency patch.
We assume that the direc-tion of this subsumption~ is downwards, as indicated inFigure 18.
It will be the'same in the long rnn if it werein the opposite direction'.The mentioned computation in Figure 18 takes usto Figure 19.
We have a new top clause (A'), whichshares most part of itself with (A).
except, the copyof s(* ,* ,*) .
Some of the previous goals have disap-peared due to the subsumption concerning s ( .
, .
, . )
s .Now the remaining oals are .=\[ .
I*\]s in (C') and (D')suhgumnt innFigure 18: Generation (4)execution subsumptionFigure 19: Generation (5)89and the .~ .
in the intersection of (A) and (C').
Wemight do a subsumption concerning the two .~.s ,  be-cause they share both the arguments.
This subsump-tion could have happened earlier, of course, particu-larly ever since both arguments came to be shared inFigure 16 via (B) and (D').
As mentioned before, how-ever, it would have caused no essential difference ven-tually.
At the same time we could execute the proce-dure say(*) to realize the goal *=\[*1.\] in (C').
It isreasonable to assume that this computation is triggeredby the fact that the argument of say( . )
subsumes thefirst argument of this .=\ [ .
I , \ ] .
This heuristic for fir-ing procedures looks generally applicable not only toutterance but also to every other output procedure.Thus we move to a new computational context inFigure 20.
The execution of say( . )
has created a newexecution .......... .Figure 20: Generation (6)?
=\[.
I .
\].
so that 'Kim' has been spoken aloud.
This?
-- \[* I o\] dominates the ,--- \[.
Io\] in (C'), as indicated bythe thick link.
Generation of 'Kim laughed' completesif say( , )  is executed one step further.Note that this generation process captures thebottom-up feature of semantic head-driven generation\[8\], especially when we move from Figure 15 throughFigure 18.
The subsumption concerning the argumentsof np ( .
,  o, o)s happening between Figure 18 and Figure19 captures the top-down aspect as well.6 Concluding RemarksWe have introduced a set of general heuristics for con-trolling symbolic omputation on logic constraints, anddemonstrated that sentence parsing and generation areattributed to these heuristics.
In the above presenta-tion, parsing is for the most part based on truth main-tenance (resolution of dependencies among arguments)90controlled by heuristics (H1) and (H2), whereas gener-ation is more dependent on goal satisfaction controlledby (H3) and (H4).
In more realistic cases, however.both processes would involve both kinds of computa-tion in a more intertwined way.A related nice feature of our framework is that, inprinciple, all the types of constraints - -  syntactic, se-mantic, pragmatic and extralinguistic - -  are treateduniformly and integrated naturally, though a really ef-ficient implementation f such an integrated system re-quires further esearch.
In this connection, we have un-dertaken to study how to implement the above heuris-tics in a more principled and flexible way, based on anotion of potential energy \[4\], but the present paperlacks the space for discussing the details.In this paper we have discussed only task-independent aspects of control heuristics.
Our conjec-ture is that we will be able to dispense with domain-dependent and task-dependent control heuristics alto-gether.
The domain/task-dependent characteristics ofinformation processing will be captured in terms of theassignment of energy functions to the relevant con-straints.
The resulting system will still be free fromstipulation of the directions of information flow, allow-ing multi-directional information processing, since nei-ther the symbolic component nor the analog compo-nent (that is, energy) of the constraint refers explicitlyto information flow.References\[1\] Barwise, J.
(1990) The Situation in Logic, CSLILecture Notes No.
17.\[2\] Hasida, K. (1990) 'Sentence Processing as Con-straint Transformation,' Proceedings of ECAI '#0.\[3\] Hasida, K. and Tsuda, H. (1991) 'Parsing withoutParser,' International Workshop on Parsing Tech-nologies, pp.
1-10, Cancun.\[4\] Hasida, K. (in preparation) Potential Energy ofCombinatorial Constraints.\[5\] Hobbs, J., Stickel, M., Martin, P., and Edwards,D.
(1988) 'Interpretation as Abduction,' Proceed-ings of the ~O6th Annual Meeting of ACL, pp.95-103.\[6\] Pereira, F.C.N.
and Warren, D.H.D.
(1983)'Parsing as Deduction,' Proceedings of the 21stAnnual Meeting of ACL, pp.
137-144.\[7\] Shieber, S.M.
(1988)'A Uniform Architecture forParsing and Generation,' Proceedings of the 12thCOLING, pp.
614-619.\[8\] Shieber, S.M., van Noord, G., and Moore, R.C.
(1989) 'A Semantic-Head-Driven Generation Al-gorithm for Unification-Based Formalisms,' Pro-ceedings of the 27th Annual Meeting of A CL, pp.
7-17.
