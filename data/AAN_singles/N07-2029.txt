Proceedings of NAACL HLT 2007, Companion Volume, pages 113?116,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsHybrid Document Indexing with Spectral EmbeddingIrina MatveevaDepartment of Computer ScienceUniversity of ChicagoChicago, IL 60637matveeva@cs.uchicago.eduGina-Anne LevowDepartment of Computer ScienceUniversity of ChicagoChicago, IL 60637levow@cs.uchicago.eduAbstractDocument representation has a large im-pact on the performance of document re-trieval and clustering algorithms.
Wepropose a hybrid document indexingscheme that combines the traditional bag-of-words representation with spectral em-bedding.
This method accounts for thespecifics of the document collection andalso uses semantic similarity informationbased on a large scale statistical analysis.Clustering experiments showed improve-ments over the traditional tf-idf represen-tation and over the spectral methods basedsolely on the document collection.1 IntroductionCapturing semantic relations between words in adocument representation is a difficult problem.
Dif-ferent approaches tried to overcome the term inde-pendence assumption of the bag-of-words represen-tation (Salton and McGill, 1983) for example by us-ing distributional term clusters (Slonim and Tishby,2000) and expanding the document vectors withsynonyms, see (Levow et al, 2005).
Since contentwords can be combined into semantic classes therehas been a considerable interest in low-dimensionalterm and document representations.Latent Semantic Analysis (LSA) (Deerwester etal., 1990) is one of the best known dimensionalityreduction algorithms.
In the LSA space documentsare indexed with latent semantic concepts.
LSAshowed large performance improvements over thetraditional tf-idf representation on small documentcollections (Deerwester et al, 1990) but often doesnot perform well on large heterogeneous collections.LSA maps all words to low dimensional vectors.However, the notion of semantic relatedness is de-fined differently for subsets of the vocabulary.
In ad-dition, the numerical information, abbreviations andthe documents?
style may be very good indicators oftheir topic.
However, this information is no longeravailable after the dimensionality reduction.We use a hybrid approach to document indexingto address these issues.
We keep the notion of la-tent semantic concepts and also try to preserve thespecifics of the document collection.
We use a low-dimensional representation only for nouns and rep-resent the rest of the document?s content as tf-idfvectors.The rest of the paper is organized as follows.
Sec-tion 2 discusses our approach.
Section 3 reports theexperimental results.
We conclude in section 4.2 Hybrid Document IndexingThis section gives the general idea of our approach.We divide the vocabulary into two sets: nouns andthe rest of the vocabulary.
We use a method of spec-tral embedding, as described below and compute alow-dimensional representation for documents usingonly the nouns.
We also compute a tf-idf represen-tation for documents using the other set of words.Since we can treat each latent semantic concept inthe low-dimensional representation as part of the vo-cabulary, we combine the two vector representationsfor each document by concatenating them.1132.1 Spectral EmbeddingSpectral methods comprise a family of algorithmsthat use a matrix of pair-wise similarities S and per-form its spectral analysis, such as the eigenvalue de-composition, to embed terms and documents in alow-dimensional vector space.
S = U?UT , wherethe columns of U are its eigenvectors and ?
is a di-agonal matrix with the eigenvalues.If we have a matrix of pair-wise word similaritiesS, its first k eigenvectors Uk will be used to repre-sent the words in the latent semantic space.
Seman-tically related words will have high association withthe same latent concepts and their correspondingvectors will be similar.
Moreover, the vector similar-ity between the word vectors will optimally preservethe original similarities (Cox and Cox, 2001).We use two approaches to compute spectral em-bedding for nouns.
Latent Semantic Analysis(LSA) (Deerwester et al, 1990) and Generalized La-tent Semantic Analysis (GLSA) (Matveeva et al,2005).
For both we used the eigenvalue decomposi-tion as the embedding step.
The difference is in thesimilarities matrix which we are trying to preserve.2.2 Distributional Term SimilarityLSA and GLSA begin with a matrix of pair-wiseterm similarities S, compute its eigenvectors U anduse the first k of them to represent terms and doc-uments, for details see (Deerwester et al, 1990;Matveeva et al, 2005).
The main difference in ourimplementation of these algorithms is the matrix ofpair-wise word similarities.
Since our representationwill try to preserve them it is important to have a ma-trix of similarities which is linguistically motivated.LSA uses the matrix of pair-wise similaritieswhich is based on document vectors.
For two wordswi and wj in the document collection containing ndocuments dk, the similarity is computed asS(wi, wj) =?k=1:ntf(wi, dk)idf(wi) ?
tf(wj , dk)idf(wj),where tf(wi, dk) is the term frequency for wi indk and idf(wi) is the inverse document frequencyweight for wi.
LSA is a special case of spectral em-bedding restricted to one type of term similaritiesand dimensionality reduction method.GLSA (Matveeva et al, 2005) generalizes theidea of latent semantic space.
It proposes to usedifferent types of similarity matrix and spectral em-bedding methods to compute a latent space which iscloser to true semantic similarities.
One way to doso is to use a more appropriate similarities matrix S.PMI We use point-wise mutual information (PMI)to compute the matrix S. PMI between random vari-ables representing the words wi and wj is computedasPMI(wi, wj) = logP (Wi = 1,Wj = 1)P (Wi = 1)P (Wj = 1).Thus, for GLSA, S(wi, wj) = PMI(wi, wj).Co-occurrence Proximity An advantage of PMIis the notion of proximity.
The co-occurrence statis-tics for PMI are typically computed using a slidingwindow.
Thus, PMI will be large only for wordsthat co-occur within a small fixed context.
Our ex-periments show that this is a better approximation totrue semantic similarities.2.3 Document IndexingWe have two sets of the vocabulary terms: a set ofnouns, N , and the other words, T .
We compute tf-idfdocument vectors indexed with the words in T :~di = (?i(w1), ?i(w2), ..., ?i(w|T |)),where ?i(wt) = tf(wt, di) ?
idf(wt).We also compute a k-dimensional representationwith latent concepts ci as a weighted linear combi-nation of LSA or GLSA term vectors ~wt:~di = (c1, ..., ck) =?t=1:|T |?i(wt) ?
~wt,We concatenate these two representations to gener-ate a hybrid indexing of documents:~di = (?i(w1), ..., ?i(w|T |), c1, ...ck)3 ExperimentsWe performed document clustering experiments tovalidate our approach.114Subset m-n #topics min #d max #d av.
#d5-10 19 6 10 8.250-150 21 55 150 94.7500-1000 2 544 844 694.01000-5000 3 1367 2083 1792.3Table 1: TDT2 topic subsets containing between mand n documents: the number of topics per subset,the minimum, the maximum and the average numberof documents per topic in each subset.IndexingAll words Nouns Hybridtf-idf, LSA tf-idfNGLSA, GLSA local GLSAN tf-idf+GLSANTable 2: Indexing schemes: with full vocabulary(All), only nouns (Nouns) and the combination.Data We used the TDT2 collection1 of news arti-cles from six news agencies in 1998.
We used only10,329 documents that are assigned to one topic.TDT2 documents are distributed over topics veryunevenly.
We used subsets of the TDT2 topics thatcontain between m and n documents, see Table 1.We used the Lemur toolkit2 with stemming and stopwords list for the tf-idf indexing, Bikel?s parser3 toobtain the set of nouns and the PLAPACK pack-age (Bientinesi et al, 2003) to compute the eigen-value decomposition.Global vs. Local Similarity To obtain the PMIvalues for GLSA we used the TDT2 collection, de-noted as GLSAlocal.
Since co-occurrence statisticsbased on larger collections gives a better approxima-tion to linguistic similarities, we also used 700,000documents from the English GigaWord collection,denoted as GLSA and GLSAN .
We used a windowof size 8.Representations For each document we com-puted 7 representations, see Table 2.
The vocabularysize we used with the tf-idf indexing was 114,127.For computational reasons we used the set of wordsthat occurred in at least 20 documents with our spec-tral methods.
We used 17,633 words for index-1http://nist.gov/speech/tests/tdt/tdt98/2http://www.lemurproject.org/3http://www.cis.upenn.edu/ dbikel/software.htmling with LSA and GLSAlocal and 17,572 words forGLSA.
We also indexed documents using only the15,325 nouns: tf-idfN and GLSAN .
The hybrid rep-resentation was computed using the tf-idf indexingwithout nouns and the GLSAN nouns vectors.Evaluation We used the minimum squaredresidue co-clustering algorithm 4.
We report twoevaluation measures: accuracy and the F1-score.The clustering algorithm assigns each document toa cluster.
We map the cluster id?s to topic labelsusing the Munkres assignment algorithm (Munkres,1957) and compute the accuracy as the ratio of thecorrectly assigned labels.The F1 score for cluster ci labeled with topic ti iscomputed using F1 = 2(p?r)(p+r) where p is precisionand r is recall.
For clusters C = (c1, ..., cn) andtopics T = (t1, ..., tn) we compute the total score:F1(C, T ) =?t?TNtN maxc?C F1(c, t).Nt is the number of documents belonging to thetopic t and N is the total number of documents.
Thismeasure accounts for the topic size and also correctsthe topic assignments to clusters by using the max.4 Results and ConclusionTable 3 shows that the spectral methods outperformthe tf-idf representations and have smaller variance.We report the performance for four subsets.
Thesubset 5?10 has a large number of topics, each witha similar number of documents.
The subset 50?150has a large number of topics with a less even distri-bution of documents.
500 ?
1000 and 1000 ?
5000have a couple of large topics.
We ran the clusteringover 30 random initializations.
To eliminate the ef-fect of the initial conditions on the performance wealso used one document per cluster to seed the initialassignment for the 5?
10 subset.All methods have the worst performance for the5?10 subset.
The best performance is for the subset500?1000.
LSA and GLSAlocal indexing are com-puted based on the TDT2 collection.
GLSAlocal hasbetter average performance which confirms that theco-occurrence proximity is important for distribu-tional similarity.
The GLSA indexing computed us-ing a large corpus performs significantly worse than4http://www.cs.utexas.edu/users/dml/Software/cocluster.html115All words LSA GLSAlocal GLSA onlyN GLSAN Hybrid5-10 acc 0.56(0.11) 0.69(0.07) 0.78(0.05) 0.60(0.05) 0.63(0.05) 0.76(0.05) 0.82(0.05)F1 0.60(0.09) 0.73(0.05) 0.81(0.04) 0.64(0.05) 0.67(0.05) 0.80(0.04) 0.85(0.04)50-150 acc 0.75(0.05) 0.73(0.06) 0.80(0.05) 0.70(0.04) 0.68(0.04) 0.80(0.04) 0.87(0.04)F1 0.80(0.04) 0.78(0.05) 0.84(0.04) 0.75(0.04) 0.75(0.03) 0.84(0.04) 0.90(0.03)500-1000 acc 0.95(0.03) 0.98(0.00) 0.99(0.00) 0.97(0.00) 0.97(0.00) 0.99(0.00) 1.00(0.00)F1 0.95(0.03) 0.98(0.00) 0.99(0.00) 0.97(0.00) 0.97(0.00) 0.99(0.00) 1.00(0.00)1000-5000 acc 0.86(0.11) 0.88(0.04) 0.88(0.13) 0.92(0.08) 0.82(0.06) 0.92(0.00) 0.96(0.07)F1 0.88(0.07) 0.88(0.03) 0.90(0.09) 0.93(0.06) 0.82(0.04) 0.92(0.00) 0.97(0.05)5-10s acc 0.932 0.919 0.986 0.932 0.980 0.980 0.992F1 0.933 0.927 0.986 0.932 0.979 0.979 0.992Table 3: Clustering accuracy (first row) and F1 score (second row) for each indexing scheme.
The measuresare averaged over 30 random initiations of the clustering algorithm, the standard deviation is shown inbrackets.
For the last experiment, 5-10s, we used one document per cluster as the initial assignment.GLSAlocal on the heterogeneous 5?10 and 50?150subsets and performs similarly for the other two.
Itsupports our intuition that the document?s style andword distribution within the collection are importantand may get lost, especially if we use a documentcollection with a different word distribution to esti-mate the similarities matrix S.The tf-idf indexing with nouns only, onlyN , hasgood performance compared to the all-words index-ing.
The semantic similarity between nouns seemsto be collection independent.
The GLSAN index-ing is significantly better than onlyN and tf-idf inmost cases and performs similar to GLSAlocal.
Byusing GLSAN we computed the embedding formore nouns that we could keep in the GLSAlocaland GLSA representations.
Nouns convey impor-tant topic membership information and it is advan-tageous to use as many of them as possible.We observed the same performance relation whenwe used labels to make the initial cluster assign-ment, see 5?
10s in Table 3. tf-idf, GLSA and LSAperformed similarly, GLSAlocal and GLSAN per-formed better with the hybrid scheme being the best.The hybrid indexing significantly outperforms tf-idf, LSA and GLSA on three subsets.
This shows thebenefits of using the spectral embedding to discoverthe semantic relations between nouns and keepingthe rest of the document content as tf-idf representa-tion to preserve other indicators of its topic member-ship.
By combining two representations the hybridindexing scheme defines a more complex notion ofsimilarity between documents.
For nouns it uses thesemantic proximity in the space of latent semanticclasses and for other words it uses term-matching.ReferencesPaolo Bientinesi, Inderjit S. Dhilon, and Robert A. van deGeijn.
2003.
A parallel eigensolver for dense sym-metric matrices based on multiple relatively robustrepresentations.
UT CS Technical Report TR-03-26.Trevor F. Cox and Micheal A. Cox.
2001.
Multidimen-sional Scaling.
CRC/Chapman and Hall.Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-dauer, George W. Furnas, and Richard A. Harshman.1990.
Indexing by latent semantic analysis.
Jour-nal of the American Society of Information Science,41(6):391?407.Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.2005.
Dictionary-based techniques for cross-languageinformation retrieval.
Information Processing andManagement: Special Issue on Cross-language Infor-mation Retrieval.Irina Matveeva, Gina-Anne Levow, Ayman Farahat, andChristian Royer.
2005.
Generalized latent semanticanalysis for term representation.
In Proc.
of RANLP.J.
Munkres.
1957.
Algorithms for the assignment andtransportation problems.
SIAM, 5(1):32?38.Gerard Salton and Michael J. McGill.
1983.
Introductionto Modern Information Retrieval.
McGraw-Hill.Noam Slonim and Naftali Tishby.
2000.
Document clus-tering using word clusters via the information bottle-neck method.
In Research and Development in Infor-mation Retrieval, pages 208?215.116
