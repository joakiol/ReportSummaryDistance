Robust Models of Human ParsingFrank KellerSchool of InformaticsUniversity of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, UKkeller@inf.ed.ac.uk1 Robustness and Human ParsingA striking property of the human parser is its effi-ciency and robustness.
For the vast majority of sen-tences, the parser will effortlessly and rapidly de-liver the correct analysis.
In doing so, it is robust tonoise, i.e., it can provide an analysis even if the inputis distorted, e.g., by ungrammaticalities.
Further-more, the human parser achieves broad coverage:it deals with a wide variety of syntactic construc-tions, and is not restricted by the domain, genre, ormodality of the input.Current research on human parsing rarely investi-gates the issues of efficiency, robustness, and broadcoverage, as pointed out by Crocker and Brants(2000).
Instead, most researchers have focussed onthe difficulties that the human parser has with cer-tain types of sentences.
Based on the study of gar-den path sentences (which involve a local ambiguitythat makes the sentence hard to process), theorieshave been developed that successfully explain howthe human parser deals with ambiguities in the in-put.
However, garden path sentences are arguablya pathological case for the parser; garden paths arenot representative of naturally occurring text.
Thismeans that the corresponding processing theoriesface a scaling problem: it is not clear how they canexplain the normal behavior of the human parser,where sentence processing is highly efficient andvery robust (see Crocker and Brants 2000 for detailson this scalability argument).This criticism applies to most existing theoriesof human parsing, including the classical gardenpath model advanced by Frazier and Rayner (1982)and Frazier (1989), and more recent lexicalist pars-ing frameworks, of which MacDonald et al (1994)and MacDonald (1994) are representative examples.Both the garden path model and the lexicalist modelare designed to deal with idealized input, i.e., withinput that is (locally) ambiguous, but fully well-formed.
A real life parser, however, has to copewith a large amount of noise, which often rendersthe input ungrammatical or fragmentary, due to er-rors such as typographical mistakes in the case oftext, or slips of the tongue, disfluencies, or repairsin the case of speech.
A quick search in the PennTreebank (Marcus et al, 1993) shows that about17% of all sentences contain parentheticals or othersentence fragments, interjections, or unbracketableconstituents.
Note that this figure holds for carefullyedited newspaper text; the figure is likely to be muchhigher for speech.
The human parser is robust tosuch noise, i.e., it is able to assign an (approximate)analysis to a sentence even if it is ungrammatical orfragmentary.2 Probabilistic Parsing ModelsIn computational linguistics, probabilistic ap-proaches to language processing play a centralrole.
Significant advances toward robust, broad-coverage parsing models have been made based onprobabilistic techniques such as maximum likeli-hood estimation or expectation maximization (foran overview, see Manning and Schu?tze, 1999).An example of a simple probabilistic pars-ing model are probabilistic context-free grammars(PCFGs), which extend the formalism of context-free grammars (CFGs) by annotating each rule witha probability.
PCFGs constitute an efficient, well-understood technique for assigning probabilities tothe analyses produced by a context-free grammar.They are commonly used for broad-coverage gram-mars, as CFGs large enough to parse unrestrictedtext are typically highly ambiguous, i.e., a singlesentence will receive a large number of parses.
Theprobabilistic component of the grammar can then beused to rank the analyses a sentence might receive,and improbable ones can be eliminated.In the computational linguistics literature, a num-ber of highly successful extensions to the basicPCFG model have been proposed.
Of particular in-terest are lexicalized parsing models such as theones developed by Collins (1996, 1997) and Carrolland Rooth (1998).In the human parsing literature, a PCFG-basedmodel has been proposed by Jurafsky (1996) andNarayanan and Jurafsky (1998).
This model showshow different sources of probabilistic information(such as subcategorization information and rule fre-quencies) can be combined using Bayesian infer-ence.
The model accounts for a range of disam-biguation phenomena in linguistic processing.
How-ever, the model is only small scale, and it is not clearif it can be extended to provide robustness and cov-erage of unrestricted text.This problem is addressed by Brants and Crocker(2000) and Crocker and Brants (2000), who pro-pose a broad-coverage model of human parsingbased on PCFGs.
This model is incremental, i.e.,it makes word-by-word predictions, thus mimick-ing the behavior of the human parser.
Also, Brantsand Crocker?s (2000) model imposes memory re-strictions on the parser that are inspired by findingsfrom the human sentence processing literature.3 Robust Models of Human ParsingThe main weakness of both the Narayanan/Jurafskyand the Crocker/Brants model (discussed in the pre-vious section) is that they have not been evaluatedsystematically.
The authors only describe the per-formance of their models on a small set of hand-picked example sentences.
No attempts are madeto test the models against a full set of experimentalmaterials and the corresponding reading times, eventhough a large amount of suitable data are availablein the literature.
This makes it very hard to obtain arealistic estimate of how well these models achievethe aim of providing robust, broad coverage mod-els of human parsing.
This can only be assessed bytesting the models against realistic samples of unre-stricted text or speech obtained from corpora.In this talk, we will present work that aimsto perform such an evaluation.
We train a se-ries of increasingly sophisticated probabilistic pars-ing models on an identical training set (the PennTreebank).
These models include a standard un-lexicalized PCFG parser, a head-lexicalized parser(Collins, 1997), and a maximum-entropy inspiredparser (Charniak, 2000).
We test all three modelson the Embra corpus, a corpus of newspaper textsannotated with eye-tracking data from 23 subjects(McDonald and Shillcock, 2003).
A series of re-gression analyses are conducted to determine if per-sentence reading time measures correlate with sen-tence probabilities predicted by the parsing models.Three baseline models are also included in the eval-uation: word frequency, bigram and trigram prob-ability (as predicted by a language model), andpart of speech (POS) probability (as predicted bya POS tagger).
Models based on n-grams have al-ready been used successfully to model eye-trackingdata, both on a word-by-word basis (McDonald andShillcock, 2003) and for whole sentences (Keller,2004).Our results show that for all three parsing models,sentence probability is significantly correlated withreading times measures.
However, the models differas to whether they predict early or late measures:the PCFG and the Collins model significantly pre-dict late reading time measures (total time and gazeduration), but not early measures (first fixation timeand skipping rate).
The Charniak model is able tosignificantly predict both early and late measures.An analysis of the baseline models shows thatword frequency and POS probability only predictearly measures, while bigram and trigram probabil-ity only predict late measures.
This indicates thatthe Charniak model is able to predict both early andlate measures because it successfully combines lex-ical information (word frequencies and POS proba-bilities) with phrasal information (as modeled by aPCFG).
This finding is in line with Charniak?s ownanalysis, which shows that the high performance ofhis model is due to the fact that it combines a third-order Markov grammar with sophisticated phrasaland lexical features (Charniak, 2000).4 ImplicationsThe results reported in the previous section have in-teresting theoretical implications.
Firstly, there is amethodological lesson here: simple baseline mod-els based on n-gram or POS probabilities performsurprisingly well as robust, broad coverage modelsof human language processing.
This is an importantpoint that has not been recognized in the literature,as previous models have not been tested on realis-tic corpus samples, and have not been compared toplausible baselines.A second point concerns the role of lexical in-formation in human parsing.
We found that thebest performing model was Charniak?s maximumentropy-inspired parser, which combines lexical andphrasal information, and manages to predict bothearly and late eye-tracking measures.
A number ofexisting theories of human parsing incorporate lexi-cal information (MacDonald et al, 1994; MacDon-ald, 1994), but have so far failed to demonstratehow the use of such information can be scaled upto yield robust, broad coverage parsing models thatcan be tested on realistic data such as the Embraeye-tracking corpus.Finally, a major challenge that remains is thecrosslinguistic aspect of human parsing.
Virtuallyall existing computational models have only beenimplemented and tested for English data.
However,a wide range of interesting problems arise for otherlanguages.
An examples are head-final languages, inwhich the probabilistic information associated withthe head becomes available only at the end of thephrase, which poses a potential problem for incre-mental parsing models.
Some initial results on alimited dataset have been obtained by Baldeweinand Keller (2004) for head-final constructions inGerman.ReferencesBaldewein, Ulrike and Frank Keller.
2004.
Mod-eling attachment decisions with a probabilisticparser: The case of head final structures.
In Pro-ceedings of the 26th Annual Conference of theCognitive Science Society.
Chicago.Brants, Thorsten and Matthew W. Crocker.
2000.Probabilistic parsing and psychological plausi-bility.
In Proceedings of the 18th Interna-tional Conference on Computational Linguistics.Saarbru?cken/Luxembourg/Nancy.Carroll, Glenn and Mats Rooth.
1998.
Valence in-duction with a head-lexicalized PCFG.
In Pro-ceedings of the Conference on Empirical Meth-ods in Natural Language Processing.
Granada,pages 36?45.Charniak, Eugene.
2000.
A maximum-entropy-inspired parser.
In Proceedings of the 1st Con-ference of the North American Chapter of the As-sociation for Computational Linguistics.
Seattle,WA, pages 132?139.Collins, Michael.
1996.
A new statistical parserbased on bigram lexical dependencies.
In Pro-ceedings of the 34th Annual Meeting of the As-sociation for Computational Linguistics.
SantaCruz, CA, pages 184?191.Collins, Michael.
1997.
Three generative, lexi-calised models for statistical parsing.
In Pro-ceedings of the 35th Annual Meeting of theAssociation for Computational Linguistics andthe 8th Conference of the European Chapter ofthe Association for Computational Linguistics.Madrid, pages 16?23.Crocker, Matthew W. and Thorsten Brants.
2000.Wide-coverage probabilistic sentence processing.Journal of Psycholinguistic Research 29(6):647?669.Frazier, Lynn.
1989.
Against lexical generation ofsyntax.
In William D. Marslen-Wilson, editor,Lexical Representation and Process, MIT Press,Cambridge, Mass., pages 505?528.Frazier, Lynn and Keith Rayner.
1982.
Makingand correcting errors during sentence comprehen-sion: Eye movements in the analysis of struc-turally ambiguous sentences.
Cognitive Psychol-ogy 14:178?210.Jurafsky, Daniel.
1996.
A probabilistic model oflexical and syntactic access and disambiguation.Cognitive Science 20(2):137?194.Keller, Frank.
2004.
The entropy rate principle asa predictor of processing effort: An evaluationagainst eye-tracking data.
In Dekang Lin andDekai Wu, editors, Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing.
Barcelona.MacDonald, Maryellen C. 1994.
Probabilistic con-straints and syntactic ambiguity resolution.
Lan-guage and Cognitive Processes 9:157?201.MacDonald, Maryellen C., Neal J. Pearlmutter, andMark S. Seidenberg.
1994.
Lexical nature of syn-tactic ambiguity resolution.
Psychological Re-view 101:676?703.Manning, Christopher D. and Hinrich Schu?tze.1999.
Foundations of Statistical Natural Lan-guage Processing.
MIT Press, Cambridge, MA.Marcus, Mitchell P., Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Building a largeannotated corpus of English: The Penn Treebank.Computational Linguistics 19(2):313?330.McDonald, Scott A. and Richard C. Shillcock.2003.
Low-level predictive inference in reading:The influence of transitional probabilities on eyemovements.
Vision Research 43:1735?1751.Narayanan, Srini and Daniel Jurafsky.
1998.Bayesian models of human sentence processing.In Morton A. Gernsbacher and Sharon J. Derry,editors, Proceedings of the 20th Annual Confer-ence of the Cognitive Science Society.
LawrenceErlbaum Associates, Mahwah, NJ.
