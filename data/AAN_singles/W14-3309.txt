Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97?104,Baltimore, Maryland USA, June 26?27, 2014.c?2014 Association for Computational LinguisticsEdinburgh?s Phrase-based Machine Translation Systems for WMT-14Nadir Durrani Barry Haddow Philipp KoehnSchool of InformaticsUniversity of Edinburgh{dnadir,bhaddow,pkoehn}@inf.ed.ac.ukKenneth HeafieldComputer Science DepartmentStanford Universityheafield@cs.stanford.eduAbstractThis paper describes the University of Ed-inburgh?s (UEDIN) phrase-based submis-sions to the translation and medical trans-lation shared tasks of the 2014 Work-shop on Statistical Machine Translation(WMT).
We participated in all languagepairs.
We have improved upon our 2013system by i) using generalized represen-tations, specifically automatic word clus-ters for translations out of English, ii) us-ing unsupervised character-based modelsto translate unknown words in Russian-English and Hindi-English pairs, iii) syn-thesizing Hindi data from closely-relatedUrdu data, and iv) building huge languageon the common crawl corpus.1 Translation TaskOur baseline systems are based on the setup de-scribed in (Durrani et al., 2013b) that we usedfor the Eighth Workshop on Statistical MachineTranslation (Bojar et al., 2013).
The notable fea-tures of these systems are described in the follow-ing section.
The experiments that we carried outfor this year?s translation task are described in thefollowing sections.1.1 BaselineWe trained our systems with the following set-tings: a maximum sentence length of 80, grow-diag-final-and symmetrization of GIZA++ align-ments, an interpolated Kneser-Ney smoothed 5-gram language model with KenLM (Heafield,2011) used at runtime, hierarchical lexicalized re-ordering (Galley and Manning, 2008), a lexically-driven 5-gram operation sequence model (OSM)(Durrani et al., 2013a) with 4 count-based sup-portive features, sparse domain indicator, phraselength, and count bin features (Blunsom and Os-borne, 2008; Chiang et al., 2009), a distortion limitof 6, maximum phrase-length of 5, 100-best trans-lation options, Minimum Bayes Risk decoding(Kumar and Byrne, 2004), Cube Pruning (Huangand Chiang, 2007), with a stack-size of 1000during tuning and 5000 during test and the no-reordering-over-punctuation heuristic (Koehn andHaddow, 2009).
We used POS and morphologi-cal tags as additional factors in phrase translationmodels (Koehn and Hoang, 2007) for German-English language pairs.
We also trained target se-quence models on the in-domain subset of the par-allel corpus using Kneser-Ney smoothed 7-grammodels.
We used syntactic-preordering (Collinset al., 2005) and compound splitting (Koehn andKnight, 2003) for German-to-English systems.We used trivia tokenizer for tokenizing Hindi.The systems were tuned on a very large tun-ing set consisting of the test sets from 2008-2012,with a total of 13,071 sentences.
We used news-test 2013 for the dev experiments.
For Russian-English pairs news-test 2012 was used for tuningand for Hindi-English pairs, we divided the news-dev 2014 into two halves, used the first half fortuning and second for dev experiments.1.2 Using Generalized Word RepresentationsWe explored the use of automatic word clustersin phrase-based models (Durrani et al., 2014a).We computed the clusters with GIZA++?s mkcls(Och, 1999) on the source and target side of theparallel training corpus.
Clusters are word classesthat are optimized to reduce n-gram perplexity.By generating a cluster identifier for each out-put word, we are able to add an n-gram model97over these identifiers as an additional scoring func-tion.
The inclusion of such an additional factoris trivial given the factored model implementation(Koehn and Hoang, 2007) of Moses (Koehn et al.,2007).
The n-gram model is trained in the similarway as the regular language model.
We traineddomain-specific language models separately andthen linearly interpolated them using SRILM withweights optimized on the tuning set (Schwenk andKoehn, 2008).We also trained OSM models over cluster-ids(?).
The lexically driven OSM model falls back tovery small context sizes of two to three operationsdue to data sparsity.
Learning operation sequencesover cluster-ids enables us to learn richer trans-lation and reordering patterns that can generalizebetter in sparse data conditions.
Table 1 showsgains from adding target LM and OSM modelsover cluster-ids.
Using word clusters was foundmore useful translating from English-to-*.from English into EnglishLang B0+Cid ?
B0+Cid ?de 20.60 20.85 +0.25 27.44 27.34 -0.10cs 18.84 19.39 +0.55 26.42 26.42 ?0.00fr 30.73 30.82 +0.09 31.64 31.76 +0.12ru 18.78 19.67 +0.89 24.45 24.63 +0.18hi 10.39 10.52 +0.13 15.48 15.26 -0.22Table 1: Using Word Clusters in Phrase-based andOSM models ?
B0= System without Clusters,+Cid = with ClusterWe also trained OSM models over POS andmorph tags.
For the English-to-German sys-tem we added an OSM model over [pos, morph](source:pos, target:morph) and for the German-to-English system we added an OSM model over[morph,pos] (source:morph, target:pos), a config-uration that was found to work best in our previousexperiments (Birch et al., 2013).
Table 2 showsgains from additionally using OSM models overPOS/morph tags.Lang B0+OSMp,m?en-de 20.44 20.60 +0.16de-en 27.24 27.44 +0.20Table 2: Using POS and Morph Tags inOSM models ?
B0= Baseline, +OSMp,m=POS/Morph-based OSM1.3 Unsupervised Transliteration ModelLast year, our Russian-English systems performedbadly on the human evaluation.
In comparisonother participants that used transliteration did well.We could not train a transliteration system dueto unavailability of a transliteration training data.This year we used an EM-based method to in-duce unsupervised transliteration models (Durraniet al., 2014b).
We extracted transliteration pairsautomatically from the word-aligned parallel dataand used it to learn a transliteration system.
Wethen built transliteration phrase-tables for trans-lating OOV words and used the post-decodingmethod (Method 2 as described in the paper) totranslate these.Pair Training OOV B0+Tr?ru-en 232K 1356 24.63 25.06 +0.41en-ru 232K 681 19.67 19.91 +0.24hi-en 38K 503 14.67 15.48 +0.81en-hi 38K 394 11.76 12.83 +1.07Table 3: Using Unsupervised TransliterationModel ?
Training = Extracted Transliteration Cor-pus (types), OOV = Out-of-vocabulary words (to-kens) B0= System without Transliteration, +Tr= Transliterating OOVsTable 3 shows the number (types) of translit-eration pairs extracted using unsupervised min-ing, number of OOV words (tokens) in each pairand the gains achieved by transliterating unknownwords.1.4 Synthesizing Hindi Data from UrduHindi and Urdu are closely related language pairsthat share grammatical structure and have a largeoverlap in vocabulary.
This provides a strongmotivation to transform any Urdu-English paral-lel data into Hindi-English by translating the Urdupart into Hindi.
We made use of the Urdu-Englishsegment of the Indic multi-parallel corpus (Postet al., 2012) which contains roughly 87K sentencepairs.
The Hindi-English segment of this corpusis a subset of parallel data made available for thetranslation task but is completely disjoint from theUrdu-English segment.We initially trained a Urdu-to-Hindi SMT sys-tem using a very tiny EMILLE1corpus (Baker1EMILLE corpus contains roughly 12000 sentences ofHindi and Urdu comparable data.
From these we were ableto sentence align 7000 sentences to build an Urdu-to-Hindisystem.98et al., 2002).
But we found this system to be use-less for translating the Urdu part of Indic data dueto domain mismatch and huge number of OOVwords (approximately 310K tokens).
To reducesparsity we synthesized additional phrase-tablesusing interpolation and transliteration.Interpolation: We trained two phrase transla-tion tables p(u?i|e?i) and p(e?i|?hi), from Urdu-English (Indic corpus) and Hindi-English (Hin-dEnCorp (Bojar et al., 2014)) bilingual cor-pora.
Given the phrase-table for Urdu-Englishp(u?i|e?i) and the phrase-table for English-Hindip(e?i|?hi), we estimated a Urdu-Hindi phrase-tablep(u?i|?hi) using the well-known convolution model(Utiyama and Isahara, 2007; Wu and Wang, 2007):p(u?i|?hi) =?e?ip(u?i|e?i)p(e?i|?hi)The number of entries in the baseline Urdu-to-Hindi phrase-table were approximately 254K.
Us-ing interpolation we were able to build a phrase-table containing roughly 10M phrases.
This re-duced the number of OOV tokens from 310K toapproximately 50K.Transliteration: Urdu and Hindi are written indifferent scripts (Arabic and Devanagri respec-tively).
We added a transliteration componentto our Urdu-to-Hindi system.
An unsupervisedtransliteration model is learned from the word-alignments of Urdu-Hindi parallel data.
We wereable to extract around 2800 transliteration pairs.To learn a richer transliteration model, we addi-tionally fed the interpolated phrase-table, as de-scribed above, to the transliteration miner.
Wewere able to mine additional 21000 translitera-tion pairs and built a Urdu-Hindi character-basedmodel from it.
The transliteration module canbe used to translate the 50K OOV words butprevious research (Durrani et al., 2010; Nakovand Tiedemann, 2012) has shown that translit-eration is useful for more than just translatingOOV words when translating closely related lan-guage pairs.
To fully capitalize on the large over-lap in Hindi?Urdu vocabulary, we transliteratedeach word in the Urdu test-data into Hindi andproduced a phrase-table with 100-best transliter-ations.
The two synthesized (triangulated andtransliterated) phrase-tables are then used alongwith the baseline Urdu-to-Hindi phrase-table ina log-linear model.
Detailed results on Urdu-to-Hindi baseline and improvements obtained fromusing transliteration and triangulated phrase-tablesare presented in Durrani and Koehn (2014).
Usingour best Urdu-to-Hindi system, we translated theUrdu part of the multi-indic corpus to form Hindi-English parallel data.
Table 4 shows results fromusing the synthesized Hindi-English corpus in iso-lation (Syn) and on top of the baseline system(B0+ Syn).Pair B0Syn ?
B0+ Syn ?hi-en 14.28 10.49 -3.79 14.72 +0.44en-hi 10.59 9.01 -1.58 11.76 +1.17Table 4: Evaluating Synthesized (Syn) Hindi-English Parallel Data, B0= System without Syn-thesized Data1.5 Huge Language ModelsOur unconstrained submissions use an additionallanguage model trained on web pages from the2012, 2013, and winter 2013 CommonCrawl.2The additional language model is the only differ-ence between the constrained and unconstrainedsubmissions; we did not use additional paralleldata.
These language models were trained on textprovided by the CommonCrawl foundation, whichthey converted to UTF-8 after stripping HTML.Languages were detected using the Compact Lan-guage Detection 23and, except for Hindi wherewe lack tools, sentences were split with the Eu-roparl sentence splitter (Koehn, 2005).
All textwas then deduplicated, minimizing the impact ofboilerplate, such as social media sharing buttons.We then tokenized and truecased the text as usual.Statistics are shown in Table 5.
A full descriptionof the pipeline, including a public data release, ap-pears in Buck et al.
(2014).Lang Lines (B) Tokens (B) Bytesen 59.13 975.63 5.14 TiBde 3.87 51.93 317.46 GiBfr 3.04 49.31 273.96 GiBru 1.79 21.41 220.62 GiBcs 0.47 5.79 34.67 GiBhi 0.01 0.28 3.39 GiBTable 5: Size of huge language model training dataWe built unpruned modified Kneser-Ney lan-guage models using lmplz (Heafield et al., 2013).2http://commoncrawl.org3https://code.google.com/p/cld2/99Pair B0+Lnewstest 2013 2014 2013 2014en-de 20.85 20.10 ?
20.61 +0.51en-cs 19.39 21.00 20.03 +0.64 21.60 +0.60en-ru 19.90 28.70 20.80 +0.90 29.90 +1.20en-hi 11.43 11.10 12.83 +1.40 12.50 +1.40hi-en 15.48 13.90 ?
14.80 +0.90Table 6: Gains obtained by using huge languagemodels ?
B0= Baseline, +L = Adding Huge LMWhile the Hindi and Czech models are smallenough to run directly, models for other languagesare quite large.We therefore created a filter that op-erates directly on files in KenLM trie binary for-mat, preserving only n-grams whose words all ap-pear in the target side vocabulary of at least onesource sentence.
For example, an English lan-guage model trained on just the 2012 and 2013crawls takes 3.5 TB without any quantization.
Af-ter filtering to the Hindi-English tuning set, themodel fit in 908 GB, again without quantization.We were then able to tune the system on a machinewith 1 TB RAM.
Results are shown in Table 6; wedid not submit to English-French because the sys-tem takes too long to tune.1.6 MiscellaneousHindi-English: 1) A large number of Hindi sen-tences in the Hindi-English parallel corpus wereending with a full-stop ?.
?, although the end-of-the-sentence marker in Hindi is ?Danda?
(|).
Re-placing full-stops with Danda gave improvementof +0.20 for hi-en and +0.40 in en-hi.
2) UsingWiki subtitles did not give any improvement inBLEU and were in fact harmful for the en-hi di-rection.Russian-English: We tried to improve word-alignments by integrating a transliteration sub-model into GIZA++ word aligner.
The probabil-ity of a word pair is calculated as an interpola-tion of the transliteration probability and transla-tion probability stored in the t-table of the differ-ent alignment models used by the GIZA++ aligner.This interpolation is done for all iterations of allalignment models (See Sajjad et al.
(2013) for de-tails).
Due to shortage of time we could only run itfor Russian-to-English.
The improved alignmentsgave a gain of +0.21 on news-test 2013 and +0.40on news-test 2014.Pair GIZA++ Fast Align ?de-en 24.02 23.89 ?.13fr-en 30.78 30.66 ?.12es-en 34.07 34.24 +.17cs-en 22.63 22.44 ?.19ru-en 31.68 32.03 +.35en-de 18.04 17.88 ?.16en-fr 28.96 28.83 ?.13en-es 34.15 34.32 +.17en-cs 15.70 16.02 +.32avg +.03Table 7: Comparison of fast word alignmentmethod (Dyer et al., 2013) against GIZA++(WMT 2013 data condition, test on new-stest2012).
The method was not used in the officialsubmission.Pair Baseline MSD Hier.
MSD Hier.
MSLRde-en 27.04 27.10 +.06 27.17 +.13fr-en 31.63 - 31.65 +.02es-en 31.20 31.14 ?.06 31.25 +.05cs-en 26.11 26.32 +.21 26.26 +.15ru-en 24.09 24.01 ?.08 24.19 +.11en-de 20.43 20.34 ?.09 20.32 -.11en-fr 30.54 - 30.52 ?.02en-es 30.36 30.44 +.08 30.51 +.15en-cs 18.53 18.59 +.06 18.66 +.13en-ru 18.37 18.47 +.10 18.19 ?.18avg + .035 +.045Table 8: Hierarchical lexicalized reordering model(Galley and Manning, 2008).Fast align: In preliminary experiments, wecompared the fast word alignment method byDyer et al.
(2013) against our traditional use ofGIZA++.
Results are quite mixed (Table 7), rang-ing from a gain of +.35 for Russian-English to aloss of ?.19 for Czech-English.
We stayed withGIZA++ for all of our other experiments.Hierarchical lexicalized reordering model:We explored the use of the hierarchical lexicalizedreordering model (Galley and Manning, 2008)in two variants: using the same orientations asour traditional model (monotone, discontinuous,swap), and one that distinguishes the discontin-uous orientations to the left and right.
Table 8shows slight improvements with these models, sowe used them in our baseline.Threshold filtering of phrase table: We exper-imented with discarding some phrase table entrydue to their low probability.
We found that phrasetranslations with the phrase translation probability100?
(f |e)<10?4can be safely discarded with almostno change in translations.
However, discardingphrase translations with the inverse phrase transla-tion probability ?
(e|f)<10?4is more risky, espe-cially with morphologically rich target languages,so we kept those.1.7 SummaryTable 9 shows cumulative gains obtained from us-ing word classes, transliteration and big languagemodels4over the baseline system.
Our German-English constrained systems were used for EU-Bridge system combination, a collaborative effortto improve the state-of-the-art in machine transla-tion (See Freitag et al.
(2014) for details).from English into EnglishLang B0B1?
B0B1?de 20.44 20.85 +0.41 27.24 27.44 +0.20cs 18.84 20.03 +1.19 26.42 26.42 ?0.00fr 30.73 30.82 +0.09 31.64 31.76 +0.12ru 18.78 20.81 +2.03 24.45 25.21 +0.76hi 9.27 12.83 +3.56 14.08 15.48 +1.40Table 9: Cumulative gains obtained for each lan-guage ?
B0= Baseline, B1= Best System2 Medical Translation TaskFor the medical translation task, the organiserssupplied several medical domain corpora (detailedon the task website), as well some out-of-domainpatent data, and also all the data available for theconstrained track of the news translation task waspermitted.
In general, we attempted to use all ofthis data, except for the LDC Gigaword languagemodel data (for reasons of time) and we dividedthe data into ?in-domain?
and ?out-of-domain?corpora.
The data sets are summarised in Tables10 and 11.In order to create systems for the medical trans-lation tasks, we used phrase-based Moses with ex-actly the same settings as for the news translationtask, including the OSM (Durrani et al., 2011),and compound splitting Koehn and Knight (2003)for German source.
We did not use word clusters(Section 1.2), as they did not give good results onthis task, but we have yet to find a reason for this.For language model training, we decided not tobuild separate models on each corpus as there was4Cumulative gains do not include gains obtain from biglanguage models for hi-en and en-de.Data Set cs-en de-en fr-encoppa-in n n yPatTR-in-claims n y yPatTR-in-abstract n y yPatTR-in-titles n y yUMLS y y yMuchMore n y nEMEA y y yWikiTitles y y yPatTR-out n y ycoppa-out n n yMultiUN n n yczeng y n neuroparl y y ynews-comm y y ycommoncrawl y y yFrEnGiga n n yTable 10: Parallel data sets used in the medicaltranslation task.
The sets above the line were clas-sified as ?in-domain?
and those below as ?out-of-domain?.Data Set cs de en frPIL n n y nDrugBank n n y nWikiArticles y y y yPatTR-in-description n y y yGENIA n n y nFMA n n y nAACT n n y nPatTR-out-description n y y yTable 11: Additional monolingual data used inthe medical translation task.
Those above the linewere classified as ?in-domain?
and the one belowas ?out-of-domain?.
We also used the target sidesof all the parallel corpora for language modelling.a large variation in corpus sizes.
Instead we con-catenated the in-domain target sides with the in-domain extra monolingual data to create trainingdata for an in-domain language model, and simi-larly for the out-of-domain data.
The two languagemodels were interpolated using SRILM, minimis-ing perplexity on the Khresmoi summary develop-ment data.During system development, we only had 500sentences of development data (SUMMARY-DEV)from the Khresmoi project, so we decided to se-lect further development and devtest data from theEMEA corpus, reasoning that it was fairly closein domain to SUMMARY-DEV.
We selected a tun-ing set (5000 sentence pairs, which were added toSUMMARY-DEV) and a devtest set (3000 sentencepairs) from EMEA after first de-duplicating it, andignoring sentence pairs which were too short, or101contained too many capital letters or numbers.
TheEMEA contains many duplicated sentences, andwe removed all sentence pairs where either sidewas a duplicate, reducing the size of the corpusto about 25% of the original.
We also removedEMEA from Czeng, since otherwise it would over-lap with our selected development sets.We also experimented with modified Moore-Lewis (Moore and Lewis, 2010; Axelrod et al.,2011) data selection, using the EMEA corpus asthe in-domain corpus (for the language model re-quired in MML) and selecting from all the out-of-domain data.When running on the final test set (SUMMARY-TEST) we found that it was better to tune just onSUMMARY-DEV, even though it was much smallerthan the EMEA dev set we had selected.
All buttwo (cs-en, de-en) of our submitted systems usedthe MML selection, because it worked better onour EMEA devtest set.
However, as can be seenfrom Table 12, systems built with all the data gen-erally perform better.
We concluded that EMEAwas not a good representative of the Khresmoidata, perhaps because of domain differences, orperhaps just because of the alignment noise thatappears (from informal inspection) to be presentin EMEA.from English into Englishin in+20 in+out in in+20 in+outde 18.59 20.88 ?
36.17 ?
38.57cs 18.78 23.45 23.77 30.12 ?
36.32fr 35.24 40.74 41.04 45.15 46.44 46.58Table 12: Results (cased BLEU) on the khresmoisummary test set.
The ?in?
systems include allin-domain data, the ?in+20?
systems also include20% of the out-of-domain data and the ?out?
sys-tems include all data.
The submitted systems areshown in italics, except for de-en and cs-en wherewe submitted a ?in+out?
systems.
For de-en, thiswas tuned on SUMMARY-DEV plus the EMEA devset and scored 37.31, whilst for cs-en we includedLDC Giga in the LM, and scored 36.65.For translating the Khresmoi queries, we usedthe same systems as for the summaries, except thatgenerally we did not retune on the SUMMARY-DEVdata.
We added a post-processing script to stripout extraneous stop words, which improved BLEU,but we would not expect it to matter in a real CLIRsystem as it would do its own stop-word removal.AcknowledgmentsThe research leading to these results has re-ceived funding from the European Union Sev-enth Framework Programme (FP7/2007-2013) un-der grant agreements n?287658 (EU-BRIDGE),n?287688 (MateCat) and n?288769 (ACCEPT).Huge language model experiments made use ofthe Stampede supercomputer provided by theTexas Advanced Computing Center (TACC) atThe University of Texas at Austin under NSFXSEDE allocation TG-CCR140009.
We also ac-knowledge the support of the Defense AdvancedResearch Projects Agency (DARPA) Broad Op-erational Language Translation (BOLT) programthrough IBM.
This publication only reflects theauthors?
views.ReferencesAxelrod, A., He, X., and Gao, J.
(2011).
Domainadaptation via pseudo in-domain data selection.In Proceedings of the 2011 Conference on Em-pirical Methods in Natural Language Process-ing, pages 355?362, Edinburgh, Scotland, UK.Association for Computational Linguistics.Baker, P., Hardie, A., McEnery, T., Cunningham,H., and Gaizauskas, R. J.
(2002).
EMILLE,a 67-million word corpus of indic languages:Data collection, mark-up and harmonisation.
InLREC.Birch, A., Durrani, N., and Koehn, P. (2013).
Ed-inburgh SLT and MT system description for theIWSLT 2013 evaluation.
In Proceedings of the10th International Workshop on Spoken Lan-guage Translation, pages 40?48, Heidelberg,Germany.Blunsom, P. and Osborne, M. (2008).
Probabilis-tic inference for machine translation.
In Pro-ceedings of the 2008 Conference on Empiri-cal Methods in Natural Language Processing,pages 215?223, Honolulu, Hawaii.
Associationfor Computational Linguistics.Bojar, O., Buck, C., Callison-Burch, C., Feder-mann, C., Haddow, B., Koehn, P., Monz, C.,Post, M., Soricut, R., and Specia, L. (2013).Findings of the 2013 workshop on statisticalmachine translation.
In Eighth Workshop onStatistical Machine Translation, WMT-2013,pages 1?44, Sofia, Bulgaria.Bojar, O., Diatka, V., Rychl?y, P., Stra?n?ak, P.,Tamchyna, A., and Zeman, D. (2014).
Hindi-102English and Hindi-only Corpus for MachineTranslation.
In Proceedings of the Ninth In-ternational Language Resources and Evalua-tion Conference (LREC?14), Reykjavik, Ice-land.
ELRA, European Language ResourcesAssociation.
in prep.Buck, C., Heafield, K., and van Ooyen, B.
(2014).N-gram counts and language models from thecommon crawl.
In Proceedings of the LanguageResources and Evaluation Conference, Reyk-jav?
?k, Iceland.Chiang, D., Knight, K., and Wang, W. (2009).11,001 New Features for Statistical MachineTranslation.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Confer-ence of the North American Chapter of the As-sociation for Computational Linguistics, pages218?226, Boulder, Colorado.
Association forComputational Linguistics.Collins, M., Koehn, P., and Kucerova, I.
(2005).Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting of the Association for ComputationalLinguistics (ACL?05), pages 531?540, Ann Ar-bor, Michigan.
Association for ComputationalLinguistics.Durrani, N., Fraser, A., Schmid, H., Hoang, H.,and Koehn, P. (2013a).
Can markov mod-els over minimal translation units help phrase-based SMT?
In Proceedings of the 51st An-nual Meeting of the Association for Computa-tional Linguistics, Sofia, Bulgaria.
Associationfor Computational Linguistics.Durrani, N., Haddow, B., Heafield, K., and Koehn,P.
(2013b).
Edinburgh?s machine translationsystems for european language pairs.
In Pro-ceedings of the Eighth Workshop on StatisticalMachine Translation, Sofia, Bulgaria.
Associa-tion for Computational Linguistics.Durrani, N. and Koehn, P. (2014).
Improving ma-chine translation via triangulation and transliter-ation.
In Proceedings of the 17th Annual Con-ference of the European Association for Ma-chine Translation (EAMT), Dubrovnik, Croatia.Durrani, N., Koehn, P., Schmid, H., and Fraser,A.
(2014a).
Investigating the usefulness ofgeneralized word representations in SMT.
InProceedings of the 25th Annual Conference onComputational Linguistics (COLING), Dublin,Ireland.
To Appear.Durrani, N., Sajjad, H., Fraser, A., and Schmid,H.
(2010).
Hindi-to-urdu machine translationthrough transliteration.
In Proceedings of the48th Annual Meeting of the Association forComputational Linguistics, pages 465?474, Up-psala, Sweden.
Association for ComputationalLinguistics.Durrani, N., Sajjad, H., Hoang, H., and Koehn, P.(2014b).
Integrating an unsupervised translit-eration model into statistical machine transla-tion.
In Proceedings of the 15th Conference ofthe European Chapter of the ACL (EACL 2014),Gothenburg, Sweden.
Association for Compu-tational Linguistics.Durrani, N., Schmid, H., and Fraser, A.
(2011).A joint sequence translation model with inte-grated reordering.
In Proceedings of the 49thAnnual Meeting of the Association for Compu-tational Linguistics: Human Language Tech-nologies, pages 1045?1054, Portland, Oregon,USA.Dyer, C., Chahuneau, V., and Smith, N. A.
(2013).A simple, fast, and effective reparameterizationof ibm model 2.
In Proceedings of the 2013Conference of the North American Chapter ofthe Association for Computational Linguistics:Human Language Technologies, pages 644?648, Atlanta, Georgia.
Association for Compu-tational Linguistics.Freitag, M., Peitz, S., Wuebker, J., Ney, H., Huck,M., Sennrich, R., Durrani, N., Nadejde, M.,Williams, P., Koehn, P., Herrmann, T., Cho,E., and Waibel, A.
(2014).
EU-BRIDGE MT:combined machine translation.
In Proceedingsof the ACL 2014 Ninth Workshop on StatisticalMachine Translation, Baltimore, MD, USA.Galley, M. and Manning, C. D. (2008).
A sim-ple and effective hierarchical phrase reorder-ing model.
In Proceedings of the 2008 Con-ference on Empirical Methods in Natural Lan-guage Processing, pages 848?856, Honolulu,Hawaii.Heafield, K. (2011).
Kenlm: Faster and smallerlanguage model queries.
In Proceedings of theSixth Workshop on Statistical Machine Trans-lation, pages 187?197, Edinburgh, Scotland,United Kingdom.Heafield, K., Pouzyrevsky, I., Clark, J. H., andKoehn, P. (2013).
Scalable modified Kneser-Ney language model estimation.
In Proceedings103of the 51st Annual Meeting of the Associationfor Computational Linguistics, Sofia, Bulgaria.Huang, L. and Chiang, D. (2007).
Forest rescor-ing: Faster decoding with integrated languagemodels.
In Proceedings of the 45th AnnualMeeting of the Association of ComputationalLinguistics, pages 144?151, Prague, Czech Re-public.
Association for Computational Linguis-tics.Koehn, P. (2005).
Europarl: A parallel corpus forstatistical machine translation.
In Proceedingsof MT Summit.Koehn, P. and Haddow, B.
(2009).
Edinburgh?sSubmission to all Tracks of the WMT 2009Shared Task with Reordering and Speed Im-provements to Moses.
In Proceedings of theFourth Workshop on Statistical Machine Trans-lation, pages 160?164, Athens, Greece.
Associ-ation for Computational Linguistics.Koehn, P. and Hoang, H. (2007).
Factored trans-lation models.
In Proceedings of the 2007Joint Conference on Empirical Methods in Nat-ural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL),pages 868?876, Prague, Czech Republic.
Asso-ciation for Computational Linguistics.Koehn, P., Hoang, H., Birch, A., Callison-Burch,C., Federico, M., Bertoldi, N., Cowan, B.,Shen, W., Moran, C., Zens, R., Dyer, C., Bo-jar, O., Constantin, A., and Herbst, E. (2007).Moses: Open source toolkit for statistical ma-chine translation.
In ACL 2007 Demonstrations,Prague, Czech Republic.Koehn, P. and Knight, K. (2003).
Empirical meth-ods for compound splitting.
In Proceedings ofMeeting of the European Chapter of the Associ-ation of Computational Linguistics (EACL).Kumar, S. and Byrne, W. J.
(2004).
Mini-mum bayes-risk decoding for statistical ma-chine translation.
In HLT-NAACL, pages 169?176.Moore, R. C. and Lewis, W. (2010).
Intelligentselection of language model training data.
InProceedings of the ACL 2010 Conference ShortPapers, pages 220?224, Uppsala, Sweden.
As-sociation for Computational Linguistics.Nakov, P. and Tiedemann, J.
(2012).
Combiningword-level and character-level models for ma-chine translation between closely-related lan-guages.
In Proceedings of the 50th AnnualMeeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pages301?305, Jeju Island, Korea.
Association forComputational Linguistics.Och, F. J.
(1999).
An efficient method for deter-mining bilingual word classes.
In Ninth Confer-ence the European Chapter of the Associationfor Computational Linguistics (EACL), pages71?76.Post, M., Callison-Burch, C., and Osborne, M.(2012).
Constructing parallel corpora for six in-dian languages via crowdsourcing.
In Proceed-ings of the Seventh Workshop on Statistical Ma-chine Translation, pages 401?409, Montr?eal,Canada.
Association for Computational Lin-guistics.Sajjad, H., Smekalova, S., Durrani, N., Fraser, A.,and Schmid, H. (2013).
QCRI-MES submis-sion at wmt13: Using transliteration mining toimprove statistical machine translation.
In Pro-ceedings of the Eighth Workshop on StatisticalMachine Translation, Sofia, Bulgaria.
Associa-tion for Computational Linguistics.Schwenk, H. and Koehn, P. (2008).
Large and di-verse language models for statistical machinetranslation.
In International Joint Conferenceon Natural Language Processing, pages 661?666.Utiyama, M. and Isahara, H. (2007).
A compar-ison of pivot methods for phrase-based statis-tical machine translation.
In 2007 Meeting ofthe North American Chapter of the Associationfor Computational Linguistics (NAACL), pages484?491.Wu, H. and Wang, H. (2007).
Pivot languageapproach for phrase-based statistical machinetranslation.
In Proceedings of the 45th AnnualMeeting of the Association of ComputationalLinguistics, pages 856?863, Prague, Czech Re-public.
Association for Computational Linguis-tics.104
