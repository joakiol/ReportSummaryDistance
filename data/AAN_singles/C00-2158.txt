MT and Topic-Based Techniques to Enhance Speech RecognitionSystems for Professional TranslatorsYevgeny Ludovik and Ron ZacharskiComputing Research LaboratoryNew Mexico State UniversityLas Cruces, New Mexico{ eugene, raz } @crl.nmsu.eduAbstractOur principle objective was to reduce theerror rate of speech recognition systemsused by professional translators.
Our workconcentrated on Spanish-to-English trans-lation.
In a baseline study we estimated theerror rate o1' an off-the-shelf recognizer tohe 9.98%.
in this paper we describe twoindependent methods ot' improving speechrecognizers: a machine translation (MT)method and a topic-based one.
Anevaluation of the MT method suggests thatthe vocabulary used for recognition cannotbe completely restricted to the set oftranslations produced by the MT system anda more sophisticated constraint system mustbe used.
An ewduation of the topic-basedmethod showed significanl error ratereduction, to 5.07%.IntroductionOur goal is to improve tim throughput ofprofessional translators by using speechrecognition.
The problem with using current off-the-shelf speech recognition systems is thatthese systems have high error rates for similartasks.
If the task is simply to recognize thespeech of a person reading out loud, the errorrate is relatively low; the error rate of largevocabulary research systems (20,000-60,000word vocahularies) performing such a task is, atbest, around 10% (see, for example, Robinsonand Christie 1998, Renals and Hochberg 1996,Hochberg et al 1995 and Siegler and Stern1995).
The popular press has reported slightlylower results for commercial systems.
Forexample, PC Magazine (Poor 1998) comparedDragon's NaturallySpeaking and IBM'sViaVoice (both continuous peech recognitionsystems with approximately 20,000 wordvocabularies).
They evaluated these systems byhaving five speakers read a 350 word text at aslow pace (1.2 words/second) after completing ahalf hour training session with each system.
Theaverage recognition error rate was 11.5% (about40 errors in the 350 word text).
An evahmtion ofthe same two systems without training resultedin a recognition error rate of 34% (Keizer 1998).If the task is more difficult than recognizing thespeech of a person reading, the error rateincreases dramatically.
For example, Ringger(1995) reports an average error rate of 30% forrecognizing careful, spontaneous speech on aspecific topic.
However, the error rate of pacedspeech can be as low as 5% if the vocahulary isseverely limited or if the text is highlypredictable and the system is tuned to thatparticular genre.
Unfortunately, the speech ofexpert ranslators producing spoken translationsf r  " ~ '  does not fall into any of the "easy to rcc%nlzecategories.In many translation tasks the source doctunent isin electronic form and the obvious question toask is if an analysis of the source documentcould lead to a reduction of the speechrecognition error rate.
For example, suppose wehave a robust machine translation system anduse it to generate all the possible translations ofa given source text.
We could then use this setof translations to help predict what the translatoris swing.
We describe this approach in ?1below.
A simpler approach is to identify thetopic o1' the source text and use that topic to aidin speech recognition.
Such as approach isdescribed in ?2.
Both methods were tested in aSpanish-to-English translation task.1061This research rests on two crucial ideas.
Thefirst is that lexical and translation knowledgeextracted from source documents by automatednatural anguage processing can be utilized in alarge-vocabulary, continuous peech recognizerto achieve low word-error ates.
The secondidea is that the translator should be able todictate a translation and correct the resultingtranscription i  much less time than if they hadto type the translation themselves or rely on atranscribedtypist.1.
Us ing  mach ine  t rans la t ionThe difference between a typical speechdictation system and the situation describedabove, is that the translator is viewing thesource text on a computer--that is, the text isavailable online.
This source text can beanalyzed using a machiue translation (MT)component.
Hopefully, this analysis will cutdown on the recognition perplexity by havingthe recognizer make choices only from the set ofpossible renderings in the target language of thewords in the source language.
In this section wedescribe the MT subsystem in detail.The function of this subsystem is to takeSpanish senteuces as input and produce a set ofEnglish words that are likely to occur intranslations of these sentences.
For example, il'the Spanish text is1.
Bulros Ghali propone v\[a diplomdtica parasolucionar crisis haitianawe would expect the translation set to includethe words (among others):{ Boutros, Ghali, proposes, diplomatic, route, to,settle, Haitian, crisis}Hopefully, this translation set will be a goodpredictor of what the translator actually said.1.1 The MT subsystemThe MT subsystem consists of 4 components:the Spanish morphological analyzer, thedictionary lookup component, the lexicaltransfer component, and the Englishmorphological generator.
These components arebriefly described in this section.1.1.1 Spanish molphological nalyzerThe morphology analyzer takes Spanish wordsas input and outputs a set of possiblemorphological analyses for those words.
Eachanalysis consists of the root word and a set offeature structures representing the inl'ormationobtained t'rom inl'lectional morphology.Examples are given below.WordC(I\[}~Speqtte~apodrfaFeature structure((root card) (cat n) (number plural))((root pequefio)(cat dj)(gender 1))((root podrir) (cat v)(tense imperfect indicative)(person 3)(number singular))1.1.2 Dictionaries and dictionao, lookupThe dictionary lookup component takes afeature structure produced by the morphologicalanalyzer, looks up the root-word/part-of-speechpair in the dictionary, and adds information tothe existing feature structure.
The words in thedictionary were derived l'rom doing a corpusanalysis of a set of 20 Spanish test documents.All the unique words in this corpus, includingproper uouns, were included in the dictionary(approximately 1,500 words).
A few examplesare shown below.activMad ((root actividad) (cat n) (transactivity energy) (gender 1))comenzar ((root comenzar)(cat v)(trans beginstart) (verbtype irregular 129))cuestion ((root cucstion) (cat n) (lrans ?lUeStiondispute problem issue)(gender 1))1.1.3 The lexical trcmffer componentAt the cud of the dictionary lookup phase, \[breach word in the Spanish sentence we have afeature structure containing the information inthe dictionary entry along with the parametervalues that were gained from morphologicalanalysis.
One feature, trans, contains thepossible English translations o1' that Spanishword.
The lexical transl'er component convertsthis Spanish feature structure to one or moreEnglish feature structures; one feature structureis created lbr each value in the trans field.
Forexample, the feature structure associated with aninstance of actividad encountered in some text1062will be 'transferred' to two English featurestructures: one for activity and one for energy.Similarly, encountering a cuestion in some text,will result in the creation of four featurestructures; those representing the English wordsquestion, diaT)ute, problem, and issue.
Inaddition, the transfer component converts otherlbatures in the Spanish feature structure tofeatures recognizable lo the Englishmorl)hological generator.1.1.4 The English morphological generatorWe used an English Morphological genenttordeveloped at the Colnputing ResearchLaboratory at New Mexico State University bySteve Beale.
The morphological generator takesfeature structures as input and producescorrectly inflected English words.
Examples ofthe feature structures used as input and theirassociated output are illustrated below:((root run) (cal v) (hum arertmningphlral)(forrn l)rogressive))((root run) (cat v) (tense will bermmingfuture) (f(wm progressive))((root nlan) (cat n) (nurnbcr menp\] tlral))1.2 EvaluationSut)pose we wish to have a user dictate anEnglish translation of a Spanish sentence flintappears on a computer screen.
This Spanishsentence is input to the MT system and theoutput is a set o1' English words.
In the idealcase, tlle words in the English sentence thetranslator dictates are contained in lhis set.
Ifone could offer a sort of guarantee that thewords o1' any reasonable translation of theSpanish sentence are contained within this set,then incorporating the MT subsystem into aspeech recognition system would be relativelystraight forward; the vocabulary at any givenmoment would be restricted to this word set.
I1,on the other hand,  such a gt la l 'at l tee CtUlllOt bemade then this approach will not work.
Theevahmtion of the natural hmguage subsystem isdesigned to test whether easonable translationsare contained within this set of words.The test lnaterial consisted of 10 Spanishnewspaper articles.
Tim articles were translatedinto English by two independent translators.
Thefollowing table shows that roughly 1/3 of thewords in tim translations the professionaltranslators produced are not in lhe set ol: wordsproduced by the natural anguage subsystem (T1and T2 are the two different Englishtranslations):Table 1 : % of words in translal ion ot in word setI)oculnent T 1 T 2l l l l l l l|)er1 3o.4 26.782 30.08 33.163 37.88 32.664 32.03 39.215 27.69 23.796 31.3 27.797 32.85 30.258 34.84 31.329 43.8 40.0510 34.95 34.5Average: 32.77The next experiment augmented the word setconstructed by the approach described abovewith lhe 800 most frequent words in a 2 millionword corpus Hf English.
The results areillustrated in the lbllowing table.Tal)le 2 : % of words in translation that are not in iheword set: frequent wordlist & illorp1 12.72 16.893 19.224 - 10.685 13.856 13.337 15.418 19.19 17.4710 19.42Average: 15.46%mlogical analysis _14.2115.0518.6216.05I2.5312.3914.0116.3815.2516.61The reason this combined method was testedwas that often English open class lexical itemsare added to the translation.
For example in onedocument, the phrase sohtcionar crMs haitianais translated as "resolution of Haitian crisis",and the English of does not have a directcorrelate in the Spanish phrase.
Wlfile liftscombined method appears to work moderatelywell, it still does not have sufficient coverage tofunction as a method for generating the1063complete recognition vocabulary.
That is, itcannot guarantee that the words o1' anyreasonable translation of a Spanish sentencewould be contained in the set o1' English wordsgenerated from that sentence.
Since we cannotuse an MT system to constrain the recognitionvocabulary we evaluated a different method--one that uses topic recognition.2.
Topic recognition methodThe basic idea behind the topic recognitionapproach is to identify the topic of the sourcelanguage text and then use that topic to alter thelanguage model for speech recognition.2.1 Topic recognition of  source textWe used a na'fve Bayes classifier to identify thetopic of Spanish online newspaper texts.
Weeliminated the common words in the text underthe rubric that these words are unlikely to serveas cues to the topic of the text.
For example inEnglish, the, of, with, and a provide littleinformation as to the topic of the text.
Weconstructed this common word list bycomputing the most frequent words in a onemillion word corpus of Spanish newspaper text.This list was edited to remove potential topiccues.
For example, Pinochet was the 46 m mostfrequent word and Clinton was the 65 th mostfrequent, but they serve as potential topic cues.We evaluated this topic identification techniqueby examining its performance on identifyingfour topics: Pinochet, the crisis in Paraguay, thecrisis in Kosovo, and Clinton's ixnpeachment.For each topic we had a 500k training corpus(roughly 60,000-75,000 words).
The test datafor each topic consisted of 20 articles from web-based newspapers.
The average size of thesearticles was 335 words.
The recognition resultsare shown in the following table:Table 3 : Accuracy of topic recognitiouWords used Pinochet Paraguay Kosovo Clintoninrecognitionall 100 100 100 100100 100 100 95 10050 95 100 95 10025 90 95 9O 95We also evaluated an enhanced version of thealgorithm on a corpus of 20 newsgroups.
~ Forthis evaluation we used a different method ofcreating a common word list.
For each workencountered in any training document wecomputed the entropy o1' the distribution of atopic given the word, and picked up 100 wordshaving the highest entropy.
No manual editingof this list was done.
High entropy for a givenword meant hat this word could not be a goodtopic cue.
In this evaluation for each value ofthe number of words used in recognition wecarried out two sets of experiments.
In the first,the first 500 documents of each topic were usedas training data, and the last 500 as test data; inthe second, the last 500 documents were used astraining data and the first 500 as test.
Therecognitioin results are presented in thefollowing table.Table 4:  Topic recognition results for 20newsgroups : 100 common words excludedWords used in Recognition raterecognitionall 76.76100 53.1550 48.4125 44.232.2 Using topic language modelsIn the previous section we have described arobnst topic recognition system and describehow the system perl'ormed in identifying thetopic of Spanish texts.
Once we have identifiedthe topic of the text to he translated we use thattopic to identify which language models wewish to use in recognizing the text.
We haveconstructed topic language models using IBM'sViaVoice Topic Factory, which allows allowsdevelopers to construct specialized languagemodels that augment the main recognitionlanguage model.
To construct hese models wemanually collected half million word corporafor both the crisis in Kosovo and Clinton'simpeachment.
These corpora were collectedfrom a variety of online news sites including1 from Tom M. Mitchell's websitehttp://www.cs.cmu.cdu/afs/cs/projcct/thco- 11/www/naive-bayes.html1064CNN, the Washington Post, the New YorkTimes, the New York l)aily News, and theMilwaukee Journal Sentinel.
One significantquestion is whether a language model as smallas a half a million words will have any impacton the error rate for speech recognition.
Weevaluated this approach by comparing the errorrate in dictating 8 texts.
The results are shown illthe table below.
(The 'without' row is using therecognizer without our topic system and the'with' row uses it with topic identification.
)Table 4: Dictation error ratesIcxt # without8.598.6710.16with5.626.154.464 8.88 4.755 12.07 5.266 13.47 6.157 8.17 4.938 9.8 3.27avorltero, 9.98 5.07As this table shows the topic-based methodreduces the average rror rate by approximately49%.
This is rather remarkable given thesimplicity of the method and the extremelysmall training corpus t'or the hmguage model.ConclusionIn tiffs paper we reviewed two methods forreducing speech recognition errors rates.
Thefirst method used a word-for-word MT systemto constrain recognition vocabulary.
Results o1'an evah, ation of this method suggest hat an MTsystem cannot adequately predict what wordswill be used in an actual translation and a moresophisticated method of incorporating MT into arecognizer is needed.
For example, we couldextend our MT system to construct a set ofpossible translations for the entire sourcelanguage sentence.
We could then use tiffs set o1'English sentences to train a small languagemodel, which would be used to recognize thesentences the translator produced.Alternatively, we could use a translationmemory approach to MT to construct he set ofEnglish sentences (Webb 1992).
The secondmethod we described recognized the topic of thesource document and used a language modelassociated with that topic for speechrecognition.
Using this approach, tim error ratewas reduced from 9.98 to 5.07%.
This means,for example, that for a short, I page, 500 worddocument, this method has saved the translatorthe time it would take to go back and manuallycorrect 25 errors.AcknowledgementsThis work was partially funded by NSF grantDMI-9860308 to Onyx Consulting, Inc. in LasCruces, New Mexico.
We would like to thankSergei Nirenburg and Jim Cowie t'or theirassistance.ReferencesItochberg, M. Renals, S., Robinson, A. and Cook, G.(1995) Recent inq~rovements to the Abbot LargeVocabulary CSR System.
Proceedings of theInternational Conference on Acoustics, Speech,and Signal Processing, 69-72.Kcizer, Gregg.
1998.
The gift of gab: CNETcompares lhe top speech recognition apps.
(http://204.162.80.182/Contenl/Reviews/Comparc/Speech/).Poor, Richard.
1998.
Speech recognition: watch whatyou say.
PC Magazine on-line (http://home.zdnet.com/pcmag/features/sl~ecch/index.html).P, cnals, S and ltochberg, M. (1996) Efficientcwdualion of llle LVCSR search space using theNOWAY decoder.
Proceedings of the InternationalConference on Speech and Language Processing,149-152.Ringger, Eric K. (1995) A robust loose coupling forspeech recognition and natural languageunderstanding.
Teclmical Report 592.
Universityof Rochester Computer Science Department.Robinson, T. and Christie, J.
(1998) Time-firstsearch for large vocabulary speech recognition.Proceedings of the International Conference onAcoustics, Speech, and Signal Processing.Siegler, M. and Stern R. (1995) On the effects ofspeech rate in large vocabulary speech recognitionsystems.
Proceedings of the InternationalConference on Acoustics, Speech, and SignalProcessing.Webb, L. (1992) Advantages and disadvantages oftranslation memory: a cost/benefit analysis.Monterey Institute of International Studies MAThesis.1065
