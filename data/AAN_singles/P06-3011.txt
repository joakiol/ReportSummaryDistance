Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 61?66,Sydney, July 2006. c?2006 Association for Computational LinguisticsOn2L - A Framework for Incremental Ontology Learning in SpokenDialog SystemsBerenike LoosEuropean Media Laboratory GmbHSchloss-Wolfsbrunnenweg 3369118 Heidelberg, Germanyberenike.loos@eml-d.villa-bosch.deAbstractAn open-domain spoken dialog system hasto deal with the challenge of lacking lexi-cal as well as conceptual knowledge.
Asthe real world is constantly changing, it isnot possible to store all necessary knowl-edge beforehand.
Therefore, this knowl-edge has to be acquired during the runtime of the system, with the help of theout-of-vocabulary information of a speechrecognizer.
As every word can have var-ious meanings depending on the contextin which it is uttered, additional contextinformation is taken into account, whensearching for the meaning of such a word.In this paper, I will present the incrementalontology learning framework On2L.
Thedefined tasks for the framework are: thehypernym extraction from Internet textsfor unknown terms delivered by the speechrecognizer; the mapping of those and theirhypernyms into ontological concepts andinstances; and the following integration ofthem into the system?s ontology.1 IntroductionA computer system, which has to understand andgenerate natural language, needs knowledge aboutthe real world.
As the manual modeling and main-tenance of those knowledge structures, i.e.
ontolo-gies, are both time and cost consuming, there ex-ists a demand to build and populate them automat-ically or at least semi automatically.
This is possi-ble by analyzing unstructured, semi-structured orfully structured data by various linguistic as wellas statistical means and by converting the resultsinto an ontological form.In an open-domain spoken dialog system the au-tomatic learning of ontological concepts and cor-responding relations between them is essential,as a complete manual modeling of them is nei-ther practicable nor feasible as the real world andits objects, models and processes are constantlychanging and so are their denotations.This work assumes that a viable approach tothis challenging problem is to learn ontologicalconcepts and relations relevant for a certain user- and only those - incrementally, i.e.
at the timeof the user?s inquiry.
Hypernyms1 of terms thatare not part of the speech recognizer lexicon, i.e.out-of-vocabulary (OOV) terms, and hence lack-ing any mapping to the employed knowledge rep-resentation of the language understanding compo-nent, should be found in texts from the Internet.That is the starting point of the proposed ontol-ogy learning framework On2L (On-line OntologyLearning).
With the found hypernym On2L canassign the place in the system?s ontology to addthe unknown term.So far the work described herein refers to theGerman language only.
In a later step, the goal isto optimize it for English as well.2 Natural Language and OntologyLearningBefore describing the actual ontology learningprocess it is important to make a clear distinctionbetween the two fields involved: this is on the onehand natural language and on the other hand onto-logical knowledge.As the Internet is a vast resource of up-to-date1According to Lyons (1977) hyponymy is the relationwhich holds between a more specific lexeme (i.e.
a hyponym)and a more general one (i.e.
a hypernym).
E.g.
animal is ahypernym of cat.61information, On2L employs it to search for OOVterms and their corresponding hypernyms.
Thenatural language texts are rich in terms, which canbe used as labels of concepts in the ontology andrich in semantic relations, which can be used asontological relations.The two areas which are working on similartopics but are using different terminology needto be distinguished, so that the extraction of se-mantic information from natural language is sep-arated from the process of integrating this knowl-edge into an ontology.Figure 1: Natural Language and Ontology Learn-ingFigure 1 shows the process of ontology learningfrom natural language text.
On the left side naturallanguage lexemes are extracted.
During a transfor-mation process nouns, verbs and proper nouns areconverted into concepts, relations and instances ofan ontology2.3 Related WorkThe idea of acquiring knowledge exactly at thetime it is needed is new and became extremelyuseful with the emergence of open-domain dia-log systems.
Before that, more or less completeontologies could be modeled for the few domainscovered by a dialog system.
Nonetheless, manyontology learning frameworks exist, which alle-viate the work of an ontology engineer to con-struct knowledge manually, e.g.
ASIUM (Faureand Nedellec, 1999), which helps an expert in ac-quiring knowledge from technical text using syn-tactic analysis for the extraction, a semantic simi-larity measure and a clustering algorithm for the2In our definition of the term ontology not only conceptsand relations are included but also instances of the real world.conceptualization.
OntoLearn (Missikoff et al,2002) uses specialized web site texts as a corpusto extract terminology, which is filtered by statis-tical techniques and then used to create a domainconcept forest with the help of a semantic interpre-tation and the detection of taxonomic and similar-ity relations.
KAON Text-To-Onto (Maedche andStaab, 2004) applies text mining algorithms forEnglish and German texts to semi-automaticallycreate an ontology, which includes algorithms forterm extraction, for concept association extractionand for ontology pruning.Pattern-based approaches to extract hy-ponym/hypernym relationships range fromhand-crafted lexico-syntactic patterns (Hearst,1992) to the automatic discovery of such patternsby e.g.
a minimal edit distance algorithm (Pantelet al, 2004).The SmartWeb Project into which On2L will beintegrated as well, aims at constructing an open-domain spoken dialog system (Wahlster, 2004)and includes different techniques to learn ontolog-ical knowledge for the system?s ontology.
Thosemethods work offline and not at the time of theuser?s inquiry in contrast to On2L:C-PANKOW (Cimiano et al, 2005) puts anamed entity into several linguistic patterns thatconvey competing semantic meanings.
The pat-terns, which can be matched most often on the webindicate the meaning of the named entity.RelExt (Schutz and Buitelaar, 2005) automat-ically identifies highly relevant pairs of conceptsconnected by a relation over concepts from anexisting ontology.
It works by extracting verbsand their grammatical arguments from a domain-specific text collection and computing correspond-ing relations through a combination of linguisticand statistical processing.4 The ontology learning frameworkThe task of the ontology learning frameworkOn2L is to acquire knowledge at run time.
AsOn2L will be integrated into the open-domain di-alog system Smartweb (Wahlster, 2004), it will benot only useful for extending the ontology of thesystem, but to make the dialog more natural andtherefore user-friendly.Natural language utterances processed by anopen-domain spoken dialog system may containwords or parts of words which are not recognizedby the speech recognizer, as they are not contained62in the recognizer lexicon.
The words not containedare most likely not represented in the word-to-concept lexicon as well3.
In the presented ontol-ogy learning framework On2L the correspondingconcepts of those terms are subject to a search onthe Internet.
For instance, the unknown term Auer-stein would be searched on the Internet (with thehelp of a search engine like Google).
By applyingnatural language patterns and statistical methodspossible hypernyms of the term can be extractedand the corresponding concept in the ontology ofthe complete dialog system can be found.
Thisprocess is described in Section 4.5.As a term often has more than one meaningdepending on the context in which it is uttered,some information about this context is added forthe search4 as shown in Section 4.4.Figure 2 shows the life cycle of the On2L frame-work.
In the middle of the diagram the questionexample by a supposed user is: How do I get tothe Auerstein?
The lighter fields in the figure markcomponents of the dialog system, which are onlyutilized by On2L, whereas the darker fields are es-pecially built to complete the ontology learningtask.Figure 2: The On2L Life CycleThe sequential steps shown in Figure 2 are de-scribed in more detail in the following paragraphsstarting with the processing of the user?s utteranceby the speech recognizer.4.1 Speech RecognitionThe speech recognizer classifies all words of theuser?s utterance not found in the lexicon as out-3In case the speech recognizer of the system and the word-to-concept lexicon are consistent.4Of course, even in the same context a term can have morethan one meaning as discussed in Section 4.6.of-vocabulary (OOV).
That means an automaticspeech recognition (ASR) system has to processwords, which are not in the lexicon of the speechrecognizer (Klakow et al, 2004).
A solutionfor a phoneme-based recognition is the establish-ment of corresponding best rated grapheme-chainhypotheses (Gallwitz, 2002).
These grapheme-chains are constructed with the help of statisticalmethods to predict the most likely grapheme orderof a word, not found in the lexicon.
Those chainsare then used for a search on the Internet in thefinal version of On2L.
To evaluate the frameworkitself adequately so far only a set of correctly writ-ten terms is subject to search.4.2 Language UnderstandingIn this step of the dialog system, all correctlyrecognized terms of the user utterance are mappedto concepts with the help of a word-to-concept lex-icon.
Such a lexicon assigns corresponding nat-ural language terms to all concepts of an ontol-ogy.
This is not only a necessary step for the di-alog system, but can assist the ontology learningframework in a possibly needed semantic disam-biguation of the OOV term.Furthermore the information of the concepts ofthe other terms of the utterance can help to evalu-ate results: when there are more than one conceptproposal for an instance (i.e.
on the linguistic sidea proper noun like Auerstein) found in the system?sontology, the semantic distance between each pro-posed concept and the other concepts of the user?squestion can be calculated5 .4.3 PreprocessingA statistical part-of-speech tagging method de-cides on the most probable part-of-speech of thewhole utterance with the help of the sentence con-text of the question.
In the On2L frameworkwe used the language independent tagger qtag6,which we trained with the hand-tagged Germancorpus NEGRA 27.5E.g.
with the single-source shortest path algorithm ofDijkstra (Cormen et al, 2001).6qtag exists as a downloadable JAR file andcan therefore be integrated into a platform inde-pendent JAVA program.
For more information, seehttp://www.english.bham.ac.uk/staff/omason/software/qtag.html(last access: 21st February 2006).7The NEGRA corpus version 2 consists of 355,096 to-kens (20,602 sentences) of German newspaper text, takenfrom the Frankfurter Rundschau.
For more informationvisit: http://www.coli.uni-saarland.de/projects/sfb378/negra-corpus/negra-corpus.html (last access: 21st February 2006).63With the help of this information, the part-of-speech of the hypernym of the OVV term can bepredicted.
Furthermore, the verb(s) of the utter-ance can anticipate possible semantic relations forthe concept or instance to be integrated into theontology.4.4 Context ModuleTo understand the user in an open-domain dialogsystem it is important to know the extra-linguisticcontext of the utterances.
Therefore a contextmodule is applied in the system, which can giveinformation on the discourse domain, day andtime, current weather conditions and location ofthe user.
This information is important for On2Las well.
Here we make use of the location of theuser and the discourse domain so far, as this infor-mation is most fruitful for a more specific searchon the Internet.
The location is delivered by a GPScomponent and the discourse domain is detectedwith the help of the pragmatic ontology PrOnto((Porzel et al, 2006)).
Of course, the discoursedomain can only be detected for domains modeledalready in the knowledge base (Rueggenmann andGurevych, 2004).The next section will show the application of thecontext terms in more detail.4.5 Hypernym extraction from the InternetWe apply the OOV term from the speech recog-nizer as well as a context term for the search ofthe most likely hypernym on the Internet.For testing reasons a list of possible queries wasgenerated.
Here are some examples to give anidea:(1) Auerstein ?
Heidelberg(2) Michael Ballack ?
SportsDiscourse(3) Lord of the Rings ?
CinemaDiscourseOn the left side of the examples 1 to 3 is theOOV term and on the right side the correspondingcontext term as generated by the context module.For searching, the part ?Discourse?
is pruned.The reason to lay the main focus of the evalu-ation searches on proper nouns is, that those aremost likely not in the recognizer lexicon and notas instances in the system?s ontology.4.5.1 Global versus Local OOVsTo optimize results we make a distinction be-tween global OOVs and local OOVs.In the case of generally familiar proper nounslike stars, hotel chains or movies (so to say globalOOVs), a search on Wikipedia can be quite suc-cessful.In the case of proper nouns, only common ina certain country region, like Auerstein (Restau-rant), Bierbrezel (Pub) and Lux (Cinema), whichare local OOVs, a search with Wikipedia is gener-ally not fruitful.
Therefore it is searched with thehelp of the Google API.As one can not know the kind of OOV before-hand, the Wikipedia search is started before theGoogle search.
If no results are produced, theGoogle search will deliver them hopefully.
If re-sults are found, Google search will be used to testthose.4.5.2 Wikipedia SearchThe structure of Wikipedia8 entries is preas-signed.
That means, the program can know, whereto find the most suitable information beforehand.In the case of finding hypernyms the first sentencein the encyclopedia description is most useful.
Togive an example, here is the first sentence for thesearch entry Michael Ballack:(4) Michael Ballack (born September 26,1976 in Grlitz, then East Germany) IS AGerman football player.With the help of lexico-syntactic patterns, thehypernym can be extracted.
Those so-calledHearst patterns (Hearst, 1992) occur frequently inlexicons for describing a term.
In example 4 thepattern X is a Y would be matched and the hyper-nym football player9 of the term Michael Ballackcould be extracted.4.5.3 Google SearchThe search parameters in the Google API canbe adjusted for the corresponding search task.
Thetasks we used for our framework are a search inthe titles of the web pages and a search in the textof the web pages.Adjusting the Google parameters The as-sumption was, that depending on the task theGoogle parameters should be adjusted.
Four pa-rameters were tested with the two tasks (Title and8Wikipedia is a free encyclopedia, which is editable onthe Internet: www.wikipedia.org (last access: 22nd February2006)9In German compounds generally consist of only oneword, therefore it is easier to extract them than in the caseof English ones.64Page Search, as described in the next paragraphs)and a combination thereof.
The parameter defaultis used, when no other parameters are assigned; in-title is set, in case the search term should be foundin the title of the returned pages; allintext, whenthe search term should be found in the text of thepages; and inurl, when the search term should befound in the URL.In Figure 3 the outcome of the evaluation isshown.
The evaluation was done by students, whoscored the titles and pages with 1, when a possiblehypernym could be found and 0 if not.
Surpris-ingly, the default value delivered the best resultsfor all tasks, followed by the allintext parameter.Figure 3: Evaluation of the Google parametersTitle Search To search only in the titles of theweb pages has the advantage, that results can begenerated relatively fast.
This is important as timeis a relevant factor in spoken dialog systems.
Asthe titles often contain the hypernym but do notconsist of a full sentence, Hearst patterns cannotbe found.
Therefore, an algorithm was imple-mented, which searches for nouns in the title, ex-tracts them and counts the occurrences.
The nounmost frequently found in all the titles deliveredby Google is regarded as the hypernym.
For thecounting we applied stemming and clustering al-gorithms to group similar terms.Page Search For Page Search Hearst patterns asin Wikipedia Search were applied.
In contrast toencyclopedia entries the recall of those patternswas not so high in the texts from the web pages.Thus, we searched in the text surrounding of thesearched term for nouns.
Equally to Title Searchwe counted the occurrence of nouns.
Differentevaluation steps showed, that the window size offour words in front and after the term is most suc-cessful.With the help of machine learning algorithmsfrom the WEKA10 library we did a text mining to10http://www.cs.waikato.ac.nz/ml/weka (last access: 21stameliorate the results as shown in Faulhaber et al(2006).4.5.4 ResultsOf all 100 evaluated pages for Google parame-ters only about 60 texts and about 40 titles con-tained possible hypernyms (as shown in Figure 3).This result is important for the evaluation of thetask algorithms as well.
The outcome of the eval-uation setup was nearly the same: 38 % precicionfor Title Search and about 58 % for Page Search(see Faulhaber (2006)).
These scores where eval-uated with the help of forms asking students: Is Xa hypernym of Y?.4.6 Disambiguation by the userIn some cases two or more hypernyms are scoredwith the same ?
or quite similar ?
weights.
An ob-vious reason is, that the term in question has morethan one meaning in the same context.
Here, onlya further inquiry to the user can help to disam-biguate the OOV term.
In the example from thebeginning a question like ?Did you mean the hotelor the restaurant??
could be posed.
Even thoughthe system would show the user that it did not per-fectly understand him/her, the user might be morecontributory than in a question like ?What did youmean??.
The former question could be posed bya person familiar with the place, to disambiguatethe question of someone in search for Auerstein aswell and would therefore mirror a human-humandialog leading to more natural dialogs with themachine.4.7 Integration into the ontologyThe foundational ontology (Cimiano et al, 2004)integrated into the dialog system Smartweb isbased on the highly axiomatized Descriptive On-tology for Linguistic and Cognitive Engineering(DOLCE) 11.
It features various extensions calledmodules, e.g.
Descriptions & Situations (Gangemiand Mika, 2003).
Additional to the foundationalontology a domain-independent layer is includedwhich consists of a range of branches from the lessaxiomatic SUMO (Suggested Upper Merged On-tology (Niles and Pease, 2001)), which is knownfor its intuitive and comprehensible structure.
Cur-rently, the dialog system features several domainFebruary 2006).11More information on this descriptive and reductionisticapproach is found on the WonderWeb Project Homepage:wonderweb.semanticweb.org.65ontologies, i.e.
a SportEvent-, a Navigation-, aWebCam-, a Media-, and a Discourse-Ontology.According to this, it is possible that in somecases there exists the corresponding concept to ahypernym.
This can be found out with the helpof a so-called term widening.
The concept labelsin the SmartWeb Ontology are generally Englishterms.
Therefore the found German hypernym hasto be translated into English.
An English thesaurusis used to increase the chance of finding the rightlabel in the ontology.5 Future WorkThe work described here is still in process and notevaluated in detail so far.
Therefore, our goal isto establish a task-oriented evaluation setup and toameliorate the results with various techniques.As natural language texts are not only rich in hi-erarchical relations but in other semantic relationsas well, it is advantageous to extend the ontologyby those relations.As user contexts are an important part of a dia-log system, we are planning to learn new user con-texts, which can be represented in the ontology bythe DOLCE module Descriptions and Situations.Furthermore our goal is, to integrate the on-tology learning framework into the open-domainspoken dialog system Smartweb.ReferencesPhilipp Cimiano, Andreas Eberhart, Daniel Hitzler,Pascal Oberle, Steffen Staab, and Rudi Studer.2004.
The smartweb foundational ontology.SmartWeb Project Report.Philipp Cimiano, Gu?nter Ladwig, and Steffen Staab.2005.
Gimme?
the context: Context-driven auto-matic semantic annotation with c-pankow.
In Pro-ceedings of the 14th World Wide Web Conference.ACM Press.Thomas H. Cormen, Charles E. Leiserson, Ronald L.Rivest, and Clifford Stein.
2001.
Section 24.3:Dijkstra?s algorithm.
In Introduction to Algorithms,Second Edition, pages 595?601.
MIT Press andMcGraw-Hill.Arndt Faulhaber, Berenike Loos, Robert Porzel, andRainer Malaka.
2006.
Towards understanding theunknown: Open-class named entity classification inmultiple domains.
In Proceedings of the OntolexWorkshop at LREC.
Genoa, Italy.David Faure and Claire Nedellec.
1999.
Knowledgeacquisition of predicate argument structures fromtechnical texts using machine learning: The systemasium.
In EKAW ?99: Proceedings of the 11th Eu-ropean Workshop on Knowledge Acquisition, Mod-eling and Management, London, UK.
Springer-Verlag.Florian Gallwitz.
2002.
Integrated Stochastic Modelsfor Spontaneous Speech Recognition.
Logos, Berlin.Aldo Gangemi and Peter Mika.
2003.
Understand-ing the semantic web through descriptions and situ-ations.
In Proceedings of the ODBASE Conference.Springer.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofCOLING, Nantes, France.Dietrich Klakow, Georg Rose, and Xavier Aubert.2004.
Oov-detection in a large vocabulary sys-tem using automatically defined word-fragments asfiller.
In Proceedings of EUROSPEECH?99, Bu-dapest, Hungary.John Lyons.
1977.
Semantics.
University Press, Cam-bridge, MA.Alexander Maedche and Steffen Staab.
2004.
Ontol-ogy learning.
In Steffen Staab and Rudi Studer, ed-itors, Handbook on Ontologies, International Hand-books on Information Systems.
Springer.Michele Missikoff, Roberto Navigli, and Paola Velardi.2002.
Integrated approach to web ontology learningand engineering.
In IEEE Computer - November.Ian Niles and Adam Pease.
2001.
Towards a standardupper ontology.
In Chris Welty and Barry Smith,editors, Workshop on Ontology Management, Ogun-quit, Maine.
Proceedings of the 2nd InternationalConference on Formal Ontology in Information Sys-tems (FOIS-2001).Patrick Pantel, Deepak Ravichandran, and EduardHovy.
2004.
Towards terascale semantic acquisi-tion.
In Proceedings of Coling, Geneva, Switzer-land.
COLING.Robert Porzel, Hans-Peter Zorn, Berenike Loos, andRainer Malaka.
2006.
Towards a separation of prag-matic knowledge and contextual information.
InProceedings of ECAI-06 Workshop on Contexts andOntologies, Lago di Garda, Italy.Klaus Rueggenmann and Iryna Gurevych.
2004.
As-signing domains to speech recognition hypotheses.In Proceedings of HLT-NAACL Workshop on SpokenLanguage Understanding for Conversational Sys-tems and Higher Level Linguistic Knowledge forSpeech Processing.
Boston, USA.Alexander Schutz and Paul Buitelaar.
2005.
Relext: Atool for relation extraction in ontology extension.
InProceedings of the 4th International Semantic WebConference.
Galway, Ireland.Wolfgang Wahlster.
2004.
SmartWeb: Mobile appli-cations of the semantic web.
In Proceedings of In-formatik, Ulm, Germany.66
