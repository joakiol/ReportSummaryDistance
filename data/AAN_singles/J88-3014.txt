DIST INGUISHING USER MODELS FROM DISCOURSE MODELSWolfgang WahlsterDepartment of Computer ScienceUniversity of SaarbriickenWest Germany1 INTRODUCTIONIn the discussion about the relationship between usermodels (UMs) and discourse models (DMs) so far, atleast three positions have been stated explicitly:P1.
the DM is a part of the UM (e.g., Schuster)P2.
the DM intersects the UM (e.g., Chin)P3.
the DM and the UM are distinct (e.g., Wahlster1986, Cohen)Of course, the interpretation f these positions dependson the definition of the terms involved and the under-lying notion of the "part-of", "intersect", and "dis-tinct" relations.
The relationships cannot simply beinterpreted in a set-theoretic sense, since all definitionsfor UMs and DMs proposed so far depend not only onrepresentation structures, but also on processes usedfor the construction, maintenance, and exploitation ofthese structures.Since this is a terminological, and not an empirical,discussion, as I pointed out in Wahlster (1986), P1-P3are primarily normative statements.
So, P3, for in-stance, must be interpreted as "The terms UM and DMshould be defined in such a way, that they do notoverlap".This view seems not to be shared by all participantsin the discussion.
Schuster, for example, tries to proveher position (PI) in a set-theoretic sense.
First, sheargues that "the user model contains information thatdoes not appear in the discourse model" and then she"proves" that "any information i the discourse modelis also in the user model".I disagree not only with the form, but also with thecontent of Schuster's argumentation.
She writes "onlyif the discourse model is part of the user model can thesystem take it into account in its responses and itsreasoning about the users".
By considering an isomor-phic argumentation like "only if a tomato is part ofcheese, can one use it to prepare pizza" it becomesclear that this proof is flawed.Also, Morik points out correctly that if one followsSchuster's argumentation e should "view the gram-mar as part of the user model, because the grammar isnecessary for understanding and producing utter-ances".Today, it is a standard hypothesis n AI and compu-tational linguistics that models for the language under-standing and generation process must exploit variousknowledge sources, including in many cases a DM anda UM.
For example, in Jameson and Wahlster (1982) wedescribed the NP generator of the HAM-ANS system,in which the generation of a definite or indefinite des-cription was influenced both by the UM and the DM.But this in no way means that one must be included inthe other.As long as there is no definitive vidence (e.g., frompsychology or the neurosciences) for a particular struc-ture, content, and use (or even existence) of UMs andDMs in the human information processing system, in AIthe notions of UM and DM are concepts that help on theone hand to construct a theory of natural languagedialog behavior, and on the other hand to structure thesoftware systems that realize natural language systems.From the second point of view, which is the engi-neering perspective, the question of whether P1, P2, orP3 holds, is easy to decide so far.
In most of theimplemented systems the data structures and proce-dures labeled UM and DM are completely distinct.Even the recent GUMS package (Finin 1988), a generaluser modeling component, contains no specific repre-sentation structures or processes for discourse model-ing.Since the discussion above suggests that we view therelation between the UM and the DM mainly as aterminological problem, in the next section we focus onpossible definitions for UMs and DMs.
Although oftenterminological discussions become quite tedious, at thispoint it seems to be important to define these conceptsas precisely as possible, since many researchers arediscovering interesting relationships between discourseand user models.Copyright 1988 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is granted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/88/0100o-o$03.00Computational Linguistics, Volume 14, Number 3, September 1988 101Wolfgang Wahlster Distinguishing User Models from Discourse Models2 DEFINING USER MODELS AND DISCOURSE MODPLSSome authors define user models imply as informationthat the system has about its users (e.g., Schuster).
Ithink this definition is too broad.
Consider an NLinterface to a data base, which contains the followingrelation:26 Jones 32 40When Mr. Jones happens to be the user of this systemand asks, "What is my bonus?
", the system shouldrespond "40".
In this case, the system has informationabout the user, but one would not like to say that itsresponse was based on a user model.Even if one restricts the definition above to "infor-mation about he user put to use" (see Sparck Jones), itis not strong enough.
If a deductive data base in additionto the relation above includes a rule like " I f  AGE(X) >30 and BONUS(X) > 35 then STATUS(X) = 10" andMr.
Jones asks, '?What is my status?"
the systemshould respond "10".
Even though the deductiveDBMS uses information about he user to instantiate heinference rule, such a system should not be construed ashaving a user model.I propose the following joint definitions of user modeland user modeling component (see Wahlster and Kobsa1988) as well as discourse model and discourse model-ing component in the context of NL dialog systems:A user model is a knowledge source that containsexplicit assumptions on all aspects of the user that maybe relevant for the dialog behavior of the system.
A usermodeling component is that part of a dialog systemwhose function is to?
incrementally build up a user model;?
store, update, and delete entries in it;?
maintain the consistency of the model; and?
supply other components of the system with assump-tions about the user.A discourse model is a knowledge source that containsthe system's description of the syntax, semantics, andpragmatics of a dialog as it proceeds.
A discoursemodeling component is that part of a dialog systemwhose function is to?
incrementally build up a discourse model;?
store and update ntries in it; and?
supply other components of the system with informa-tion about the structure and content of the previoussegments of the dialog.While it seems commonly agreed upon that a DMshould contain a syntactic and semantic description ofdiscourse segments, a record of the discourse ntitiesmentioned, the attentional structure of the dialog in-cluding a focus space stack, anaphoric links, and de-scriptions of individual utterances on the speech actlevel, there seem to be many other ingredients neededfor a good discourse representation which are not yetworked out in current computational discourse theory.Therefore, I prefer to refer only to the abstract levels ofnecessary discourse representation i the definitionabove.3 SOME DIFFERENCES AND SIMILARITIES BETWEEN USERMODELS AND DISCOURSE MODELSAn important difference between a discourse model anda user model is that entries in the user model often mustbe explicitly deleted or updated, whereas in the dis-course model entries describing the structure and con-tent of utterances of the ongoing dialog are neverdeleted (except for forgetting phenomena, which arebeyond the scope of the current discussion).
Thus,according to our definition above, a belief revisioncomponent is an important part of a user modelingcomponent.Consider the following dialog with a hypotheticaltutoring system in the SCHOLAR tradition.System: (1) Tell me about California.User: (2) San Francisco is the capital ofCalifornia.System: (3) No, that's wrong.User: (4) I see.
So, that's not the capital.
(5) Then, what is its capital?System: (6) Sacramento.
(7) Now, tell me why you mentioned SanFrancisco first, when you began to talkabout California.A simple consequence of the user's response (2) is anentry in the system's user model, which represents hefact, that the system believes that the user believes(B1).
After (3), and certainly after (4) the user modelshould contain (BI').
(B1) capital(California, San-Francisco)(B 1') not(capital(California, S n-Francisco))(B2) capital(California, Sacramento)This means that the user modeling component has toremove (B1) from the user model (in a reason mainte-nance system this causes (B1) to be added to the set ofbeliefs, which are currently "out").
After (6) the user'sbelief (B2) should be added to the system's user model.If the apriori user model contains "For each state thereexists one and only one capital" as a mutual believedfact, then the user modeling component can also re-move (BI') after adding (B2).In the discourse model, of course, the fact that theuser uttered sentence (2) should not be deleted.
Forexample, the system could go on and ask the user aquestion like (7), which explicitly refers to the fact that(2) was the first reaction to (I).
What this simply meansis that the fact that the user made a particular assertion102 Computational Linguistics, Volume 14, Number 3, September 1988Wolfgang Wahlster Distinguishing User Models from Discourse Modelsremains true even if the user's belief changes and hewithdraws his previous assertion.Even a metacommunicative act like (9) should notdelete entries in the discourse model, as the successfulanaphoric reference in (10) to a discourse ntity intro-duced in (8) suggests.
But it is obvious that in the usermodel the corresponding representation f the user'swants has to be changed.User:(8) I don't want to travel with my kids.
(9) Forget what I just said.
(10) I want to travel with them.This does not imply that the discourse model is staticand the user model is dynamic.
The discourse model isalso highly dynamic (consider, e.g., focus shifting), butit lacks the notion of logical consistency, which isimportant for belief revision and default reasoning in auser modeling component.
In my view, the discoursemodel is like an annotated trace of the various levels ofthe system's processing involved in understanding theuser's utterances and generating its own dialog contri-butions.Let's consider another example to emphasize thedifferences between a UM and a DM.
Suppose that thesystem plays the role of a travel agent, who wants to selltrips to the well-known holiday places A and B, forwhich it has some reasonably priced offers.
When theuser asks, "What are your cheapest trips?"
the systemlists A and B first, followed by a hastily presented list ofeight other places with names, which it assumes aretotally unfamiliar to the user.
In the system's DM all tenplaces appear, but the user modeling component of thesystem explicitly assumes that the user only believes"cheap-trip-to(A)", cheap-trip-to(B)" together withthe belief that there are some other cheap trips avail-able.
This is exactly the aim of the uncooperativebehavior of the travel agent: Now, it is likely that theuser wants to know more about the offers A and B,which the agent wants to sell.
But if the user later findsout that a trip to one of the other places is much cheaperand better, and complains to the travel agent, "Whydidn't you suggest this trip right at the beginning?
", thetravel agent can refer back to his DM and say, "Imentioned this place among my first suggestions".Some authors claim that the discourse model expiresat the end of a dialog, while parts of the user model maybe saved for further use (e.g., Chin).
I think that iswrong.
Often a dialog participant is able to paraphrase asegment of a previous dialog without remembering whothe dialog partner was and at what time and location thedialog took place.
While he may not be able to recon-struct the exact phrasing, he has access to a represen-tation of the semantics and pragmatics of the interac-tion.
Furthermore, I think that often conversationalrules and tactics are learned by induction over a largeset of interaction patterns extracted from discoursemodels, which were partially saved in episodic memory,where they are not necessarily associated with a long-term user model.
In order to learn how to use a languageit seems to be important o not always discard thecomplete discourse model after the end of a conversa-tion.On the other hand, one often has many assumptionsabout the beliefs, plans, and goals of a dialog partnerbefore a new dialog begins (cf.
Wahlster and Kobsa1988), without having a clear idea from which actualdialogs the assumptions in this user model were de-rived.
Thus I agree with Morik that the short-term/long-term criterion cannot be used to distinguish usermodels and discourse models.
If one prefers to restrictthe term discourse model to an ongoing conversationand to define the saved portions of it as part of the worldknowledge, then one should do the same for the termuser model, so that again the criterion does not discrim-inate.While in many cases the UM component and the DMcomponent process the same input (e.g., a meaningrepresentation f the last utterance), and their output isused by the same processes, I would suggest that bothcomponents be kept separate.
Even if there is someinformation, which should be present in both models, itwill be represented in another form, since, as I pointedout above, the functionality and the type of processingof the UM and DM components are so different.
In thiscase we have a multiple knowledge representation in theUM and the DM, which is quite common in complex A1systems.As I remarked in the beginning, in asking who is rightin this discussion, one must carefully evaluate thecorresponding definitions for UM and DM proposed bythe respective authors.
In this paper, I introduced andmotivated efinitions, under which a UM and a DM areseparate, but related to each other.REFERENCESFinin, T. W. 1988 GUMS: A General User Modeling Shell.
In Kobsa,A.
and Wahlster, W.
(eds.
), User Models in Dialog Systems.Springer-Verlag, Berlin--New York.Jameson, A. and Wahlster, W. 1982 User Modeling in AnaphoraGeneration: Ellipsis and Definite Description.
In Proceedings ofthe 1982 European Conference on Artificial Intelligence, Orsay,France; 222-227.Wahlster, W. 1986 Some Terminological Remarks on User Modeling.Paper presented at the International Workshop on User Modeling,Maria Laach, W. Germany.Wahlster, W. and Kobsa, A.
1988 User Models in Dialog Systems.
InKobsa, A. and Wahlster, W.
(eds.
), User Models in DialogSystems.
Springer-Verlag, Berlin--New York.Computational Linguistics, Volume 14, Number 3, September 1988 103
