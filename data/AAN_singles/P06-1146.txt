Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1161?1168,Sydney, July 2006. c?2006 Association for Computational LinguisticsOptimal Constituent Alignment with Edge Covers for Semantic ProjectionSebastian Pad?Computational LinguisticsSaarland UniversitySaarbr?cken, Germanypado@coli.uni-sb.deMirella LapataSchool of InformaticsUniversity of EdinburghEdinburgh, UKmlap@inf.ed.ac.ukAbstractGiven a parallel corpus, semantic projec-tion attempts to transfer semantic role an-notations from one language to another,typically by exploiting word alignments.In this paper, we present an improvedmethod for obtaining constituent align-ments between parallel sentences to guidethe role projection task.
Our extensionsare twofold: (a) we model constituentalignment as minimum weight edge cov-ers in a bipartite graph, which allows us tofind a globally optimal solution efficiently;(b) we propose tree pruning as a promisingstrategy for reducing alignment noise.
Ex-perimental results on an English-Germanparallel corpus demonstrate improvementsover state-of-the-art models.1 IntroductionRecent years have witnessed increased interest indata-driven methods for many natural languageprocessing (NLP) tasks, ranging from part-of-speech tagging, to parsing, and semantic role la-belling.
The success of these methods is due partlyto the availability of large amounts of training dataannotated with rich linguistic information.
Unfor-tunately, such resources are largely absent for al-most all languages except English.
Given the datarequirements for supervised learning, and the cur-rent paucity of suitable data for many languages,methods for generating annotations (semi-)auto-matically are becoming increasingly popular.Annotation projection tackles this problem byleveraging parallel corpora and the high-accuracytools (e.g., parsers, taggers) available for afew languages.
Specifically, through the use ofword alignments, annotations are transfered fromresource-rich languages onto low density ones.The projection process can be decomposed intothree steps: (a) determining the units of projection;these are typically words but can also be chunksor syntactic constituents; (b) inducing alignmentsbetween the projection units and projecting anno-tations along these alignments; (c) reducing theamount of noise in the projected annotations, oftendue to errors and omissions in the word alignment.The degree to which analyses are parallel acrosslanguages is crucial for the success of projectionapproaches.
A number of recent studies rely onthis notion of parallelism and demonstrate that an-notations can be adequately projected for parts ofspeech (Yarowsky and Ngai, 2001; Hi and Hwa,2005), chunks (Yarowsky and Ngai, 2001), and de-pendencies (Hwa et al, 2002).In previous work (Pad?
and Lapata, 2005) weconsidered the annotation projection of seman-tic roles conveyed by sentential constituents suchas AGENT, PATIENT, or INSTRUMENT.
Semanticroles exhibit a high degree of parallelism acrosslanguages (Boas, 2005) and thus appear amenableto projection.
Furthermore, corpora labelled withsemantic role information can be used to trainshallow semantic parsers (Gildea and Jurafsky,2002), which could in turn benefit applications inneed of broad-coverage semantic analysis.
Exam-ples include question answering, information ex-traction, and notably machine translation.Our experiments concentrated primarily on thefirst projection step, i.e., establishing the rightlevel of linguistic analysis for effecting projec-tion.
We showed that projection schemes basedon constituent alignments significantly outperformschemes that rely exclusively on word alignments.A local optimisation strategy was used to find con-stituent alignments, while relying on a simple fil-tering technique to handle noise.The study described here generalises our earliersemantic role projection framework in two impor-tant ways.
First, we formalise constituent projec-tion as the search for aminimum weight edge coverin a weighted bipartite graph.
This formalisation1161efficiently yields constituent alignments that areglobally optimal.
Second, we propose tree prun-ing as a general noise reduction strategy, which ex-ploits both structural and linguistic information toenable projection.
Furthermore, we quantitativelyassess the impact of noise on the task by evaluatingboth on automatic and manual word alignments.In Section 2, we describe the task of role-semantic projection and the syntax-based frame-work introduced in Pad?
and Lapata (2005).
Sec-tion 3 explains how semantic role projection canbe modelled with minimum weight edge covers inbipartite graphs.
Section 4 presents our tree prun-ing strategy.
We present our evaluation frameworkand results in Section 5.
A discussion of relatedand future work concludes the paper.2 Cross-lingual Semantic Role projectionSemantic role projection is illustrated in Figure 1using English and German as the source-targetlanguage pair.
We assume a FrameNet-style se-mantic analysis (Fillmore et al, 2003).
In thisparadigm, the semantics of predicates and theirarguments are described in terms of frames, con-ceptual structures which model prototypical situ-ations.
The English sentence Kim promised to beon time in Figure 1 is an instance of the COM-MITMENT frame.
In this particular example, theframe introduces two roles, i.e., SPEAKER (Kim)and MESSAGE (to be on time).
Other possible,though unrealised, roles are ADDRESSEE, MES-SAGE, and TOPIC.
The COMMITMENT frame canbe introduced by promise and several other verbsand nouns such as consent or threat.We also assume that frame-semantic annota-tions can be obtained reliably through shallowsemantic parsing.1 Following the assignment ofsemantic roles on the English side, (imperfect)word alignments are used to infer semantic align-ments between constituents (e.g., to be on timeis aligned with p?nktlich zu kommen), and therole labels are transferred from one language tothe other.
Note that role projection can only takeplace if the source predicate (here promised ) isword-aligned to a target predicate (here versprach )evoking the same frame; if this is not the case(e.g., in metaphors), projected roles will not begenerally appropriate.We represent the source and target sentencesas sets of linguistic units, Us and Ut , respectively.1See Carreras and M?rquez (2005) for an overview of re-cent approaches to semantic parsing.Kim versprach, p?nktlich zu kommenKim promised to be on timeSSNPNPCommitmentMessageSpeakerCommitmentSpeakerMessageFigure 1: Projection of semantic roles from En-glish to German (word alignments as dotted lines)The assignment of semantic roles on the sourceside is a function roles : R ?
2Us from roles tosets of source units.
Constituent alignments areobtained in two steps.
First, a real-valued func-tion sim : Us ?Ut ?
R estimates pairwise simi-larities between source and target units.
To makeour model robust to alignment noise, we use onlycontent words to compute the similarity func-tion.
Next, a decision procedure uses the similar-ity function to determine the set of semanticallyequivalent, i.e., aligned units A?Us?Ut .
Once Ais known, semantic projection reduces to transfer-ring the semantic roles from the source units ontotheir aligned target counterparts:rolet(r) = {ut |?us ?
roles(r) : (us,ut) ?
A}In Pad?
and Lapata (2005), we evaluated twomain parameters within this framework: (a) thechoice of linguistic units and (b) methods for com-puting semantic alignments.
Our results revealedthat constituent-based models outperformed word-based ones by a wide margin (0.65 Fscorevs.
0.46), thus demonstrating the importance ofbracketing in amending errors and omissions inthe automatic word alignment.
We also com-pared two simplistic alignment schemes, back-ward alignment and forward alignment.
Thefirst scheme aligns each target constituent to itsmost similar source constituent, whereas the sec-ond (A f ) aligns each source constituent to its mostsimilar target constituent:A f = {(us,ut) |ut = argmaxu?t?Utsim(us,u?t)}1162An example constituent alignment obtained fromthe forward scheme is shown in Figure 2 (leftside).
The nodes represent constituents in thesource and target language and the edges indicatethe resulting alignment.
Forward alignment gener-ally outperformed backward alignment (0.65 Fs-core vs. 0.45).
Both procedures have a time com-plexity quadratic in the maximal number of sen-tence nodes: O(|Us||Ut |) = O(max(|Us|, |Ut |)2).A shortcoming common to both decision proce-dures is that they are local, i.e., they optimise thealignment for each node independently of all othernodes.
Consider again Figure 2.
Here, the for-ward procedure creates alignments for all sourcenodes, but leaves constituents from the target setunaligned (see target node (1)).
Moreover, localalignment methods constitute a rather weak modelof semantic equivalence since they allow one tar-get node to correspond to any number of sourcenodes (see target node (3) in Figure 2, which isaligned to three source nodes).
In fact, by allow-ing any alignment between constituents, the lo-cal models can disregard important linguistic in-formation, thus potentially leading to suboptimalresults.
We investigate this possibility by propos-ing well-understood global optimisation modelswhich suitably constrain the resulting alignments.Besides matching constituents reliably, poorword alignments are a major stumbling blockfor achieving accurate projections.
Previous re-search addresses this problem in a post-processingstep, by reestimating parameter values (Yarowskyand Ngai, 2001), by applying transformationrules (Hwa et al, 2002), by using manually la-belled data (Hi and Hwa, 2005), or by relying onlinguistic criteria (Pad?
and Lapata, 2005).
In thispaper, we present a novel filtering technique basedon tree pruning which removes extraneous con-stituents in a preprocessing stage, thereby disasso-ciating filtering from the alignment computation.In the remainder of this paper, we present thedetails of our global optimisation and filteringtechniques.
We only consider constituent-basedmodels, since these obtained the best performancein our previous study (Pad?
and Lapata, 2005).3 Globally optimal constituent alignmentWe model constituent alignment as a minimumweight bipartite edge cover problem.
A bipartitegraph is a graph G = (V,E) whose node set V ispartitioned into two nonempty sets V1 and V2 insuch a way that every edge E joins a node in V1to a node in V2.
In a weighted bipartite graph aweight is assigned to each edge.
An edge cover isa subgraph of a bipartite graph so that each node islinked to at least one node of the other partition.
Aminimum weight edge cover is an edge cover withthe least possible sum of edge weights.In our projection application, the two parti-tions are the sets of source and target sentenceconstituents, Us and Ut , respectively.
Each sourcenode is connected to all target nodes and each tar-get node to all source nodes; these edges can bethought of as potential constituent alignments.
Theedge weights, which represent the (dis)similaritybetween nodes us and ut are set to 1?
sim(us,ut).2The minimum weight edge cover then representsthe alignment with the maximal similarity be-tween source and target constituents.
Below, wepresent details on graph edge covers and a morerestricted kind, minimum weight perfect bipartitematchings.
We also discuss their computation.Edge covers Given a bipartite graph G, a min-imum weight edge cover Ae can be defined as:Ae = argminEdge cover E?(us,ut)?E1?
sim(us,ut)An example edge cover is illustrated in Figure 2(middle).
Edge covers are somewhat more con-strained compared to the local model describedabove: all source and target nodes have to take partin some alignment.
We argue that this is desirablein modelling constituent alignment, since impor-tant linguistic units will not be ignored.
As can beseen, edge covers allow one-to-many alignmentswhich are common when translating from one lan-guage to another.
For example, an English con-stituent might be split into several German con-stituents or alternatively two English constituentsmight be merged into a single German constituent.In Figure 2, the source nodes (3) and (4) corre-spond to target node (4).
Since each node of eitherside has to participate in at least one alignment,edge covers cannot account for insertions arisingwhen constituents in the source language have nocounterpart in their target language, or vice versa,as is the case for deletions.Weighted perfect bipartite matchings Per-fect bipartite matchings are a more constrainedversion of edge covers, in which each node has ex-actly one adjacent edge.
This restricts constituent2The choice of similarity function is discussed in Sec-tion 5.11632345612341UsUtr1r2r2r1r22345612341UsUtr1r2r2r1r22345612341UsUtr1r2r2r1r2ddFigure 2: Constituent alignments and role projections resulting from different decision procedures(Us,Ut : sets of source and target constituents; r1,r2: two semantic roles).
Left: local forward alignment;middle: edge cover; right: perfect matching with dummy nodesalignment to a bijective function: each sourceconstituent is linked to exactly one target con-stituent, and vice versa.
Analogously, a minimumweight perfect bipartite matching Am is a mini-mum weight edge cover obeying the one-to-oneconstraint:Am = argminMatching M?(us,ut)?M1?
sim(us,ut)An example of a perfect bipartite matching isgiven in Figure 2 (right), where each node has ex-actly one adjacent edge.
Note that the target sidecontains two nodes labelled (d), a shorthand for?dummy?
node.
Since sentence pairs will oftendiffer in length, the resulting graph partitions willhave different sizes as well.
In such cases, dummynodes are introduced in the smaller partition toenable perfect matching.
Dummy nodes are as-signed a similarity of zero with all other nodes.Alignments to dummy nodes (such as for sourcenodes (3) and (6)) are ignored during projection.Perfect matchings are more restrictive modelsof constituent alignment than edge covers.
Beingbijective, the resulting alignments cannot modelsplitting or merging operations at all.
Insertionsand deletions can be modelled only indirectly byaligning nodes in the larger partition to dummynodes on the other side (see the source side in Fig-ure 2 where nodes (3) and (6) are aligned to (d)).Section 5 assesses if these modelling limitationsimpact the quality of the resulting alignments.Algorithms Minimum weight perfect match-ings in bipartite graphs can be computed effi-ciently in cubic time using algorithms for net-work optimisation (Fredman and Tarjan, 1987;timeO(|Us|2 log |Us|+ |Us|2|Ut |)) or algorithms forthe equivalent linear assignment problem (Jonkerand Volgenant, 1987; time O(max(|Us|, |Ut |)3)).Their complexity is a linear factor slower than thequadratic runtime of the local optimisation meth-ods presented in Section 2.The computation of (general) edge covers hasbeen investigated by Eiter and Mannila (1997) inthe context of distance metrics for point sets.
Theyshow that edge covers can be reduced to minimumweight perfect matchings of an auxiliary bipar-tite graph with two partitions of size |Us|+ |Ut |.This allows the computation of general minimumweight edge covers in time O((|Us|+ |Ut |)3).4 Filtering via Tree PruningWe introduce two filtering techniques which effec-tively remove constituents from source and targettrees before alignment takes place.
Tree pruning asa preprocessing step is more general and more effi-cient than our original post-processing filter (Pad?and Lapata, 2005) which was embedded into thesimilarity function.
Not only does tree pruning notinterfere with the similarity function but also re-duces the size of the graph, thus speeding up thealgorithms discussed in the previous section.We present two instantiations of tree pruning:word-based filtering, which subsumes our earliermethod, and argument-based filtering, which elim-inates unlikely argument candidates.Word-based filtering This technique re-moves terminal nodes from parse trees accord-ing to certain linguistic or alignment-based crite-ria.
We apply two word-based filters in our ex-periments.
The first removes non-content words,i.e., all words which are not adjectives, adverbs,verbs, or nouns, from the source and target sen-1164Kim versprach, p?nktlich zu kommen.VPSVPSFigure 3: Filtering of unlikely arguments (predi-cate in boldface, potential arguments in boxes).tences (Pad?
and Lapata, 2005).
We also use anovel filter which removes all words which remainunaligned in the automatic word alignment.
Non-terminal nodes whose terminals are removed bythese filters, are also pruned.Argument filtering Previous work in shal-low semantic parsing has demonstrated that notall nodes in a tree are equally probable as seman-tic roles for a given predicate (Xue and Palmer,2004).
In fact, assuming a perfect parse, there isa ?set of likely arguments?, to which almost allsemantic roles roles should be assigned to.
Thisset of likely arguments consists of all constituentswhich are a child of some ancestor of the pred-icate, provided that (a) they do not dominate thepredicate themselves and (b) there is no sentenceboundary between a constituent and its predicate.This definition covers long-distance dependenciessuch as control constructions for verbs, or supportconstructions for nouns and adjectives, and can beextended slightly to accommodate coordination.This argument-based filter reduces target treesto a set of likely arguments.
In the example in Fig-ure 3, all tree nodes are removed except Kim andp?nktlich zu kommen.5 Evaluation Set-upData For evaluation, we used the parallel cor-pus3 from our earlier work (Pad?
and Lapata,2005).
It consists of 1,000 English-German sen-tence pairs from the Europarl corpus (Koehn,2005).
The sentences were automatically parsed(using Collin?s 1997 parser for English andDubey?s 2005 parser for German), and manuallyannotated with FrameNet-like semantic roles (seePad?
and Lapata 2005 for details.
)Word alignments were computed with theGIZA++ toolkit (Och and Ney, 2003), using the3The corpus can be downloaded from http://www.coli.uni-saarland.de/~pado/projection/.entire English-German Europarl bitext as trainingdata (20M words).
We used the GIZA++ defaultsettings to induce alignments for both directions(source-target, target-source).
Following commonpractise in MT (Koehn et al, 2003), we consideredonly their intersection (bidirectional alignmentsare known to exhibit high precision).
We also pro-duced manual word alignments for all sentencesin our corpus, using the GIZA++ alignments as astarting point and following the Blinker annotationguidelines (Melamed, 1998).Method and parameter choice The con-stituent alignment models we present are unsu-pervised in that they do not require labelled datafor inferring correct alignments.
Nevertheless, ourmodels have three parameters: (a) the similaritymeasure for identifying semantically equivalentconstituents; (b) the filtering procedure for remov-ing noise in the data (e.g., wrong alignments); and(c) the decision procedure for projection.We retained the similarity measure introducedin Pad?
and Lapata (2005) which computes theoverlap between a source constituent and its can-didate projection, in both directions.
Let y(cs) andy(ct) denote the yield of a source and target con-stituent, respectively, and al(T ) the union of allword alignments for a token set T :sim(cs,ct) =|y(ct)?al(y(cs))||y(cs)||y(cs)?al(y(ct))||y(ct)|We examined three filtering procedures (see Sec-tion 4): removing non-aligned words (NA), re-moving non-content words (NC), and removingunlikely arguments (Arg).
These were combinedwith three decision procedures: local forwardalignment (Forward), perfect matching (Perf-Match), and edge cover matching (EdgeCover)(see Section 3).
We used Jonker and Vol-genant?s (1987) solver4 to compute weighted per-fect matchings.In order to find optimal parameter settings forour models, we split our corpus randomly into adevelopment and test set (both 50% of the data)and examined the parameter space exhaustivelyon the development set.
The performance of thebest models was then assessed on the test data.The models had to predict semantic roles for Ger-man, using English gold standard roles as input,and were evaluated against German gold standard4The software is available from http://www.magiclogic.com/assignment.html.1165Model Prec Rec F-scoreWordBL 45.6 44.8 45.1Forward 66.0 56.5 60.9PerfMatch 71.7 54.7 62.1NoFilterEdgeCover 65.6 57.3 61.2UpperBnd 85.0 84.0 84.0Model Prec Rec F-scoreWordBL 45.6 44.8 45.1Forward 74.1 56.1 63.9PerfMatch 73.3 62.1 67.2NAFilterEdgeCover 70.5 62.9 66.5UpperBnd 85.0 84.0 84.0Model Prec Rec F-scoreWordBL 45.6 44.8 45.1Forward 64.3 47.8 54.8PerfMatch 73.1 56.9 64.0NCFilterEdgeCover 67.5 57.0 61.8UpperBnd 85.0 84.0 84.0Model Prec Rec F-scoreWordBL 45.6 44.8 45.1Forward 69.9 60.7 65.0PerfMatch 80.4 48.1 60.2ArgFilterEdgeCover 69.6 60.6 64.8UpperBnd 85.0 84.0 84.0Table 1: Model comparison using intersective alignments (development set)roles.
To gauge the extent to which alignment er-rors are harmful, we present results both on inter-sective and manual alignments.Upper bound and baseline In Pad?
and La-pata (2005), we assessed the feasibility of seman-tic role projection by measuring how well anno-tators agreed on identifying roles and their spans.We obtained an inter-annotator agreement of 0.84(F-score), which can serve as an upper bound forthe projection task.
As a baseline, we use a sim-ple word-based model (WordBL) from the samestudy.
The units of this model are words, and thespan of a projected role is the union of all targetterminals aligned to a terminal of the source role.6 ResultsDevelopment set Our results on the develop-ment set are summarised in Table 1.
We show howperformance varies for each model according todifferent filtering procedures when automaticallyproduced word alignments are used.
No filteringis applied to the baseline model (WordBL).Without filtering, local and global models yieldcomparable performance.
Models based on perfectbipartite matchings (PerfMatch) and edge covers(EdgeCover) obtain slight F-score improvementsover the forward alignment model (Forward).
Itis worth noticing that PerfMatch yields a signifi-cantly higher precision (using a ?2 test, p < 0.01)than Forward and EdgeCover.
This indicates that,even without filtering, PerfMatch delivers ratheraccurate projections, however with low recall.Model performance seems to increase with treepruning.
When non-aligned words are removed(Table 1, NA Filter), PerfMatch and EdgeCoverreach an F-score of 67.2 and 66.5, respectively.This is an increase of approximately 3% over thelocal Forward model.
Although the latter modelyields high precision (74.1%), its recall is sig-nificantly lower than PerfMatch and EdgeCover(p < 0.01).
This demonstrates the usefulness offiltering for the more constrained global modelswhich as discussed in Section 3 can only representa limited set of alignment possibilities.The non-content words filter (NC filter) yieldssmaller improvements.
In fact, for the Forwardmodel, results are worse than applying no filter-ing at all.
We conjecture that NC is an overlyaggressive filter which removes projection-criticalwords.
This is supported by the relatively low re-call values.
In comparison to NA, recall dropsby 8.3% for Forward and by almost 6% for Perf-Match and EdgeCover.
Nevertheless, both Perf-Match and EdgeCover outperform the local For-ward model.
PerfMatch is the best performingmodel reaching an F-score of 64.0%.We now consider how the models behave whenthe argument-based filter is applied (Arg, Table 1,bottom).
As can be seen, the local model benefitsmost from this filter, whereas PerfMatch is worstaffected; it obtains its highest precision (80.4%) aswell as its lowest recall (48.1%).
This is somewhatexpected since the filter removes the majority ofnodes in the target partition causing a proliferationof dummy nodes.
The resulting edge covers arerelatively ?unnatural?, thus counterbalancing theadvantages of global optimisation.To summarise, we find on the development setthat PerfMatch in the NA Filter condition obtainsthe best performance (F-score 67.2%), followedclosely by EdgeCover (F-score 66.5%) in the same1166Model Prec Rec F-scoreWordBL 45.7 45.0 43.3Forward (Arg) 72.4 63.2 67.5PerfMatch (NA) 75.7 63.7 69.2EdgeCover (NA) 73.0 64.9 68.7IntersectiveUpperBnd 85.0 84.0 84.0Model Prec Rec F-scoreWordBL 62.1 60.7 61.4Forward (Arg) 72.2 68.6 70.4PerfMatch (NA) 75.7 67.5 71.4EdgeCover (NA) 71.9 69.3 70.6ManualUpperBnd 85.0 84.0 84.0Table 2: Model comparison using intersective andmanual alignments (test set)condition.
In general, PerfMatch seems less sensi-tive to the type of filtering used; it yields best re-sults in three out of four filtering conditions (seeboldface figures in Table 1).
Our results further in-dicate that Arg boosts the performance of the localmodel by guiding it towards linguistically appro-priate alignments.5A comparative analysis of the output of Perf-Match and EdgeCover revealed that the two mod-els make similar errors (85% overlap).
Disagree-ments, however, arise with regard to misparses.Consider as an example the sentence pair:The Charter is [NP an opportunity tobring the EU closer to the people.
]Die Charta ist [NP eine Chance], [S dieEU den B?rgern n?herzubringen.
]An ideal algorithm would align the English NPto both the German NP and S. EdgeCover, whichcan model one-to-many-relationships, acts ?con-fidently?
and aligns the NP to the German S tomaximise the overlap similarity, incurring both aprecision and a recall error.
PerfMatch, on theother hand, cannot handle one-to-many relation-ships, acts ?cautiously?
and aligns the English NPto a dummy node, leading to a recall error.
Thus,even though EdgeCover?s analysis is partly right,it will come out worse than PerfMatch, given thecurrent dataset and evaluation method.Test set We now examine whether our resultscarry over to the test data.
Table 2 shows the5Experiments using different filter combinations did notlead to performance gains over individual filters and are notreported here due to lack of space.performance of the best models (Forward (Arg),PerfMatch (NA), and EdgeCover (NA)) on auto-matic (Intersective) and manual (Manual) align-ments.6 All models perform significantly betterthan the baseline but significantly worse than theupper bound (both in terms of precision and recall,p < 0.01).
PerfMatch and EdgeCover yield betterF-scores than the Forward model.
In fact, Perf-Match yields a significantly better precision thanForward (p < 0.01).Relatively small performance gains are ob-served when manual alignments are used.
The F-score increases by 2.9% for Forward, 2.2% forPerfMatch, and 1.9% for EdgeCover.
Also notethat this better performance is primarily due to asignificant increase in recall (p < 0.01), but notprecision.
This is an encouraging result indicatingthat our filters and graph-based algorithms elim-inate alignment noise to a large extent.
Analysisof the models?
output revealed that the remain-ing errors are mostly due to incorrect parses (noneof the parsers employed in this work were trainedon the Europarl corpus) but also to modelling de-ficiencies.
Recall from Section 3 that our globalmodels cannot currently capture one-to-zero cor-respondences, i.e., deletions and insertions.7 Related workPrevious work has primarily focused on the pro-jection of grammatical (Yarowsky and Ngai, 2001)and syntactic information (Hwa et al, 2002).
Anexception is Fung and Chen (2004), who alsoattempt to induce FrameNet-style annotations inChinese.
Their method maps English FrameNetentries to concepts listed in HowNet7, an on-lineontology for Chinese, without using parallel texts.The present work extends our earlier projectionframework (Pad?
and Lapata, 2005) by proposingglobal methods for automatic constituent align-ment.
Although our models are evaluated on thesemantic role projection task, we believe they alsoshow promise in the context of statistical ma-chine translation.
Especially for systems that usesyntactic information to enhance translation qual-ity.
For example, Xia and McCord (2004) exploitconstituent alignment for rearranging sentences inthe source language so as to make their word or-6Our results on the test set are slightly higher in compar-ison to the development set.
The fluctuation reflects naturalrandomness in the partitioning of our corpus.7See http://www.keenage.com/zhiwang/e_zhiwang.html.1167der similar to that of the target language.
Theylearn tree reordering rules by aligning constituentsheuristically using a naive local optimisation pro-cedure analogous to forward alignment.
A simi-lar approach is described in Collins et al (2005);however, the rules are manually specified and theconstituent alignment step reduces to inspection ofthe source-target sentence pairs.
The global opti-misation models presented in this paper could beeasily employed for the reordering task commonto both approaches.Other approaches treat rewrite rules not as apreprocessing step (e.g., for reordering sourcestrings), but as a part of the translation modelitself (Gildea, 2003; Gildea, 2004).
Constituentalignments are learnt by estimating the probabil-ity of tree transformations, such as node deletions,insertions, and reorderings.
These models have agreater expressive power than our edge cover mod-els; however, this implies that approximations areoften used to make computation feasible.8 ConclusionsIn this paper, we have proposed a novel methodfor obtaining constituent alignments between par-allel sentences and have shown that it is use-ful for semantic role projection.
A key aspect ofour approach is the formalisation of constituentalignment as the search for a minimum weightedge cover in a bipartite graph.
This formalisationprovides efficient mechanisms for aligning con-stituents and yields results superior to heuristic ap-proaches.
Furthermore, we have shown that tree-based noise filtering techniques are essential forgood performance.Our approach rests on the assumption that con-stituent alignment can be determined solely fromthe lexical similarity between constituents.
Al-though this allows us to model constituent align-ments efficiently as edge covers, it falls short ofmodelling translational divergences such as substi-tutions or insertions/deletions.
In future work, wewill investigate minimal tree edit distance (Bille,2005) and related formalisms which are definedon tree structures and can therefore model diver-gences explicitly.
However, it is an open ques-tion whether cross-linguistic syntactic analyses aresimilar enough to allow for structure-driven com-putation of alignments.Acknowledgments The authors acknowledgethe support of DFG (Pad?
; grant Pi-154/9-2) andEPSRC (Lapata; grant GR/T04540/01).ReferencesP.
Bille.
2005.
A survey on tree edit distance and relatedproblems.
Theoretical Computer Science, 337(1-3):217?239.H.
C. Boas.
2005.
Semantic frames as interlingual represen-tations for multilingual lexical databases.
InternationalJournal of Lexicography, 18(4):445?478.X.
Carreras, L. M?rquez, eds.
2005.
Proceedings of theCoNLL shared task: Semantic role labelling, Boston, MA,2005.M.
Collins, P. Koehn, I. Kuc?erov?.
2005.
Clause restructur-ing for statistical machine translation.
In Proceedings ofthe 43rd ACL, 531?540, Ann Arbor, MI.M.
Collins.
1997.
Three generative, lexicalised models forstatistical parsing.
In Proceedings of the ACL/EACL, 16?23, Madrid, Spain.A.
Dubey.
2005.
What to do when lexicalization fails: pars-ing German with suffix analysis and smoothing.
In Pro-ceedings of the 43rd ACL, 314?321, Ann Arbor, MI.T.
Eiter, H. Mannila.
1997.
Distance measures for point setsand their computation.
Acta Informatica, 34(2):109?133.C.
J. Fillmore, C. R. Johnson, M. R. Petruck.
2003.
Back-ground to FrameNet.
International Journal of Lexicogra-phy, 16:235?250.M.
L. Fredman, R. E. Tarjan.
1987.
Fibonacci heaps andtheir uses in improved network optimization algorithms.Journal of the ACM, 34(3):596?615.P.
Fung, B. Chen.
2004.
BiFrameNet: Bilingual frame se-mantics resources construction by cross-lingual induction.In Proceedings of the 20th COLING, 931?935, Geneva,Switzerland.D.
Gildea, D. Jurafsky.
2002.
Automatic labeling of seman-tic roles.
Computational Linguistics, 28(3):245?288.D.
Gildea.
2003.
Loosely tree-based alignment for machinetranslation.
In Proceedings of the 41st ACL, 80?87, Sap-poro, Japan.D.
Gildea.
2004.
Dependencies vs. constituents for tree-based alignment.
In Proceedings of the EMNLP, 214?221,Barcelona, Spain.C.
Hi, R. Hwa.
2005.
A backoff model for bootstrappingresources for non-english languages.
In Proceedings ofthe HLT/EMNLP, 851?858, Vancouver, BC.R.
Hwa, P. Resnik, A. Weinberg, O. Kolak.
2002.
Evaluationof translational correspondence using annotation projec-tion.
In Proceedings of the 40th ACL, 392?399, Philadel-phia, PA.R.
Jonker, T. Volgenant.
1987.
A shortest augmenting pathalgorithm for dense and sparse linear assignment prob-lems.
Computing, 38:325?340.P.
Koehn, F. J. Och, D. Marcu.
2003.
Statistical phrase-basedtranslation.
In Proceedings of the HLT/NAACL, 127?133,Edmonton, AL.P.
Koehn.
2005.
Europarl: A parallel corpus for statisticalmachine translation.
In Proceedings of the MT Summit X,Phuket, Thailand.I.
D. Melamed.
1998.
Manual annotation of translationalequivalence: The Blinker project.
Technical Report IRCSTR #98-07, IRCS, University of Pennsylvania, 1998.F.
J. Och, H. Ney.
2003.
A systematic comparison of variousstatistical alignment models.
Computational Linguistics,29(1):19?52.S.
Pad?, M. Lapata.
2005.
Cross-lingual projectionof role-semantic information.
In Proceedings of theHLT/EMNLP, 859?866, Vancouver, BC.F.
Xia, M. McCord.
2004.
Improving a statistical MT systemwith automatically learned rewrite patterns.
In Proceed-ings of the 20th COLING, 508?514, Geneva, Switzerland.N.
Xue, M. Palmer.
2004.
Calibrating features for seman-tic role labeling.
In Proceedings of the EMNLP, 88?94,Barcelona, Spain.D.
Yarowsky, G. Ngai.
2001.
Inducing multilingual textanalysis tools via robust projection across aligned corpora.In Proceedings of the HLT, 161?168, San Diego, CA.1168
