Backwards PhonologyJohn BearArtificial Intelligence CenterSRI InternationalAbst rac tThis paper constitutes an investigation i to the gener-ative capabilities of two-level phonology with respectto unilevel generative phonological rules.
Proponentsof two-level phonology have claimed, but not demon-strated, that two-level rules and grammars of two-level rules are reversible and that grammars ofnnilevelrules are not.
This paper makes "reversibility" ex-plicit and demonstrates by means of examples fromTunica and Klamath that two-level phonology doeshave certain desirable cababilities that are not foundin grammars of unilevel rules.1 In t roduct ionSince Koskenniemi proposed using two-level phonol-ogy in computational morphological nalysis in 1983,it has enjoyed considerable popularity \[Koskenniemi,1983\].
It seems to be both expressiyely powerfidand computationaily tractable.
Two-level phonologi-cal granntmars have been written for a dozen or morelanguages, and written in a form that is interpretableby a program.
One question that arises fairly fre-quently however, at least in the context of discussionabout two-level morphology, is roughly, "Why don'tyou use normal generative phonological rules?"
i.e.,rules of the type that are taught in elementary linguis-tics classes.
A slightly more positive way to ask thequestion is, "In what way or ways does Koskenniemi'snotion of two-level pholmlogical rule represent a the-oretical advance?"
This paper addresses that ques-tion by extending the notion of unilevel rule systemto cope with tim same types of phenomena that two-level rule systems were designed to handle, and thencontrasting the two different systems.At the annual meeting of the Linguistic Society ofAmerica (LSA) in 1981, Ron Kaplan and Martin Kaypresented a paper describing results about equiva-lences between what they call a cascade of finite-statetransducers and a set of normal, ordered phonologi-cal rules \[Kaplan and Kay, 1981\].
At the I, SA's 1987annual meeting, Lauri Karttunen gave a paper at-tempting to show that, when viewed a certain way,Koskenniemi's two-level rules possess a certain ele-gance that cannot be ascribed to ordered sets of rules,namely their independence from order per se \[Kartotunen, 1986\].In spite of Karttunen's paper and Koskenniemi's,and perhaps to some extent because of Kaplan andKay's paper, it is still not obvious to people who areinterested in this field what, if anything, two-levelphonology offers that cannot already be found in tilelinguistic literature under the heading of generativephonology.
Koskenniemi has made some claims aboutgrammars of two-level rules being reversible whereassets of ordered rules are not.
However these claimsare not backed up by solid argumentation, and theKaplan and Kay paper seems to argue otherwise.From a linguistic point of view, there may be goodreason to think that people use two different sets ofrules or procedures for generation and recognition.From a computational point of view, however, it isinteresting to ask, "What needs to be done in orderto use the same grammar for generation and recogni-tion; does a single reversible grammar lead to moreor less work in terms of writing the grammar and interms of run-time speed; and finally, does a reversiblegrammar lead to a more or less elegant presentationof the phenomena?"
Another reason for asking aboutreversibility is to make a comparison of these two ruleformalisms possible.
The main novelty in Kosken-niemi's system is the reversibility of the system, so wemay well question what would be necessary to viewunilevel rules as reversible.In short, there are very.
good reasons for being inter-ested in properties of reversibility, and these proper-ties will serve as the basis tot this paper's comparisonbetween the two different ypes of phonological ruleformalisms mentioned above.
The discussion here willfocus more on concrete xamples of generative capac-ity, and much less on issues of what is involved inbuilding an acceptable linguistic theory.
\[For more onglobal concerns of linguistic theory, see, for example,Ellasson, 1985\].
The questions addressed here will be,"What assumptions need to be made to use a gram-mar of unilevel generative rules to do recognition?
"1 13and "Ilow does tim resulting combination of grammarplus rules-of-interpretation compare with a two-levelstyle grammar?
"2 Revers ib i l i ty  of Uni levelRule Sys temsThe question of grammar eversibility involves twointerrelated but separate issues.
The first is whetherthe notational or descriptive devices of  a grammarare in general amenable to being reversed, and whatis involved in the reversal.
The second is whetherindividual accounts of the phenomena" of a particu-lar language are reversible, and, again, if so, what isinvolved in the reversal.Tim remarks in this paper are mainly concernedwith the general paradigm of generative phonology,in particular, segmental phonology as is described inelementary texts - e.g., Kenstowicz arid Kisseberth(1979), IIalle and Ciements (1983), Schane (1973),Mohanan (1986) - rather than any particular linguis-tic theory.
The main techniques discussed are rewriterules, orderings of rules, features, and variables forfeature values (e.g., the alpha and beta of assimila-tion rules).
The problems of suprasegmental phonol-ogy will be left for another paper.3 Backwards RulesI shall start by making explicit what it means to applya phonological rule in the backwards direction.
Thebasic idea is extremely straightforward and will be, Ithink, uncontroversial.a-+ b / ot_f l  (1)A rule like the one in (I) transforms the string/o~afl/into the string /abfl/.
Here c~ and fl are strings ofcharacters over some alphabet, e.g., the phonemes ofa language.
I take it that such a rule can also be in-terpreted as mapping the string/o~bfl/into he string/o~afll, when it is applied backwards.To take a more linguistically realistic rule, let usconsider the simple rule in (2).. / _ g (2)From a recognition point of view, this means thatif we have the sequence trig\] in a surface form of aword, then the underlying sequence could be /n g/.In slightly more general terms, we look for the seg-ment on the right side of the arrow to see whether itappears in the context given in the rule.
If so, we cantransform that segment into the segment on the leftside of the arrow.4 Obl igatory Versus OptionalThe rule in (2) says nothing about whether it is op-tional or obligatory in the backwards direction.
Op-tionality in the backwards direction is entirely inde-pendent of optionality in the forward direction.
InEnglish the rule in (2) seems to be obligatory in thereverse direction, i.e., every surface \[t3\] seems to comefrom an under ly ing/n/ .
In the forward direction, itdoes not always apply.
This is demonstrated by thepair: co\[~l\]gress v .
co\[n\]gressional, lIn a language that had phonemic / I j /and /n / ,  therule might be obligatory in the forward direction andoptional in the backward direction.
9" That is, if \[rj\]on the surface can come from e i ther /n /o r / ( I / ,  thenthe rule would necessarily be optional in the reversedirection.The point here then is that one needs to specify inthe grammar not just whether a rule is obligatory oroptional in the forward direction, but also whether itis obligatory or optional in the backwards direction.5 Revers ib i l i ty  and Rule Or-deringThe previous example describes the case of a singlerule and points out that attention must be paid towhether a rule is optional or obligatory in the back-wards direction as well as in the forward direction.The following case of rule ordering shows that thereis more to the issue of reversibility than the distinc-tion between "optional" and "obligatory.
"There is a beautiful example in the Problem Bookin Phonology by lIalle and Clements (1983) of the ele-gance of rule ordering.
In this section I will show thatthe device of ordered rules is not generally reversibleusing their example from Klamath.Tile data from Kiamath together with five rulesare taken from llalle and Clements (1983), who inturn give their source as being Klamath Grammar byBarker (1964):IMohanan (1986) p. 151.2That obligatory rules need not be obligatory when appliedin the backwards direction has been pointed out by Ron l(aplan(in a course at tile LSA Summer Institute at Stanford, 1987)14 2nl ---+ II/honli:na/--+ holli:na `flies along the bank'hi.
~ ih/hon!y / --+ holhi '\]ties into'nl' --} I?\[honl'a : l'a\[ ---, hoi?a : i'a 'flies into the fire'i t --+ lh/pa : I~a/--+ pa : iha 'dries on'!1' --+ I?/yalyal i ' i / - -~ yalyal?i 'clear'Halle and Clements also say that Barker assumesthat all phonological rules are unordered and that allrules apply simultaneously to underlying representa-tions to derive surface representations.
3 They thengive the following exercise: "Show how Barker's et ofrules can be simplified by abandoning these \[Barker's\]assumptions and assuming that phonological rules ap-ply in order, each rule applying to the output of thepreceding rule in the list of ordered rules.
Write therules sufficient o describe the above data, and statethe order in which they apply.
''4,The rules that one is supposed to arrive at areroughly these:(} n --.
i / _ } (3)t.-, h / l _  (4)?
/ l _  (5)The ordering to impose is that Rule (3) applies be-fore Rules (4) and (5), and that Rules (4) and (5)are unordered with respect o each other.
The readercan verify that the rules give the correct results whenapplied in the forward (generative) direction.
In thebackwards (recognition) direction, the derivations forthe five forms are as given below.
The rule numbersare superscripted with a minus one to indicate thatthese rules are inverses of the rules listed above.holli:na -+ honli:naRule 3 - Iholhi -+ boll) -+ hon{i 5Rule 4 -1  Rule 5 -13ltalle and Clements (1983) p. 1134 Ibid.holfa:l'a ---+ holi'a:l'a ~ honl'a:l'aRule 5 -1 Rule 3 -1pa:lha -4 pa:il.a ---+ *pa:nlaRule d - t  Rule 3 - tyalgal?i ---* yalyali'i --4 *yalyani'iRule 5 -1 Rule 3 -1What we~see here is that in order to recognize theform holli:na correctly, Rule (3) must be obligatoryin the reverse direction.
However, in order to get thecorrect results for the forms pa:lha and yalyalfi, Rule(3) may not apply at all; i.e., it is not correct o saythat the results can be obtained by correctly stipulat-ing whether a rule is optional or obligatory.
Rule (3)works well in the forward irection, but gives incorrectresults when applied in the backwards direction.
Inshort, the elegant set of ordered rules makes incorrectpredictions about recognition.
In contrast, Barker'soriginal unordered set of rules correctly describes thedata regardless of direction of application (i.e., gener-ation vs. recognition).This is a result about ordering of rules.
I have notshown that a set of ordered rules is never reversible,only that such a set is not necessarily reversible.6 Var iab les  and  De le t ionThe previous example used extremely plain rules: nofeatures, no alphas or betas, and no deletion.
Thenext example I shall present involves some of thesecommonly used devices.
I shall try to make clear whenthey can be used in a reversible way (though they neednot be), and when they just do not seem amenableto reversal.
Before discussing reversal further, I willpresent he data and the set of rules for describingthe data ill the generative framework.
The data andanalysis were taken from Kenstowicz and Kisseberth(1979).
6 Their data come from the language Tunica.The rules and data deal with two phenomena: vowelassimilation and syncope.
The rules, given below, areordered, with (6) occurring before (7).
\[Note on tran-scription: the question mark represents glottal stop.\]SThls is correct modulo the change of i back into y whichHalle and Clements assure us is not, part  of the issue at hand.For purposes of discussing reversibil ity it merely provides moresupport  for the argument hat  unilcvel rules are not  easilyreversed.6p.
292.
They cite their source as IIaas (1940).3 15--* a back .
?+low /~ round fl round --(6)+ / - "  / syllabic 1 0 ?
- stress i -- "Rule (7) says (or was meant to say) that unstressedvowels are deleted before glottal stops.
Rule (6) wasintended to mean that /a/ assimilates to \[el or \[hiwhen it is separated by a glottal stop from a preceding/ i /  or /u /  respectively.In addition to the two rules just given, Kenstowiczand Kisseberth mention but do not formulate a rule ofRight Destressing that follows both rules.
The rulesare in accord with the following data, also taken fromKenstowicz and Kisseberth.
The following forms showassimilation.To verb He verbs She verbs She is v-ing Glosspd pdfuhki p6C.aki p6hk~, aki lookp~ pf?uhki p#eki pfhkfaki emergeyd yd ?uhki yd ?aki ydhk ?aki do~d 6d?uhki  ~d?aki  ~dhk?aki takeThese forms show syncope and assimilation.To verb He verbs She verbs She is v-ing Glosshdra hdr?uhki hdr?aki hdrahk?dki singh(pu h(p?uhki h~paki h\[pnhkfdki dancendgi ndgfuhki ndg?eki ndgihkfdki leadAs a sample derivation, Kenstowicz and Kisseberthgive the following:/ndgifdki/1ndgiC, gki1ndg?
(ki1For the purpose of going through a backwards deriva-tion, 1 will make explicit a few assumptions.
First, 1assume that the Vowel Assimilation rule is really asin (8) below.Vowel Assimilation (Modified)Vowel AssimilationSyncopeRight Destressing\[+svU+low \]+syli+lowa backround /\[ 1 ot back f round(a)It is a matter of style that the features \[ + syll, + low\]were left out of the feature bundle to the right of tilearrow in Kenstowicz and Kisseberth's formulation oftile rule.
Although it is considered good style to doso, the omission of such information makes it unclearhow the rule should be applied for recognition.
HenceI have included this information in Rule (8).
vAnother assumption I will make is that the unfor-mulated rule of Right Destressing lends nothing to myargument herd.
I assume that the rule when appliedin the reverse direction puts stress on the appropriatesyllable and nowhere else.
sFinally, I will spell out what I consider to be areasonable interpretation of how to use the rules forrecognition.
When interpreted backwards, Rule (8)says that a low vowel that is separated by a glottalstop from another vowel with which it agrees in back-heSS and rounding might have come from some otherlow vowel.
The syncope rule in (7), when interpretedbackwards, says to insert an unstressed vowel beforeglottal stops.
As was pointed out.
before, there is noway to deduce whether these rules are obligatory oroptional in the reverse direction.
Indeed, it is not atall obvious what "obligatory" even means in terms ofthe assimilation rule t~ken backwards.Given these assumptions, we can now produce areverse derivation for \[na's?ekq.\[n~?eki\] ~ nfi~?~ki/n~i?Ek i/n~i?~k i~ i \ ]/ Xnfisi?Ski/ /n~?~k i/ /n~E?gk i  ~n~?~ki/ /  n~?5k i~/n~a?gki~--  nfi~a?~ki\ '~ nfi~u?~ki\x n ~o?~ki~n~?~kiFirst Reverse Destressing is applied to give ndg?gki.Then Reverse Syncope applies to insert various hy-pothesized vowels in forms in the column to the right.Finally, the rightmost column shows the results of7Presumably Kenstowlcz and Kisseberth want to treat \[?\]as being \[+ low\] to keep the rule simple and still contrast \[elwith \[i\].
If they treat \[e\] as \[- low\] and \[a\] as \[+ low\], theassimilation rule becomes messier.
This assumption about \[elbecomes important later.sit seems clear that segmental ccounts will fall short whendealing with suprasegmental issues like stress.
The goal ofthis paper is to contrast wo different ways of doing segmentalphonology.
Both would presumably benefit from autosegmentalextensions.164applying the reverse of the Assimilation rule to thepreceding forms.
A box is drawn around the correctunderlying form.What we end up with are 14 or 15 possible forms- clearly too many.
One problem is that the assim-ilation rule in (6) and (8) was formulated with onlygeneration in mind.
If we change it slightly, addingthe features \[+back, -round\] to the bundle to the leftof the arrow as in (9),+syll +syll--* c~back ?+back c~back ~round --- round flr ound(9)we have a better rnle.
Now it says that \[e\] and \[~\],when they result from assimilation, come specificallyf rom/a / .
This makes the results better.
The previousversion of the rule just mentions low vowels, of whichthere are three that we know about: s ,a ,  ~.s Whenwe specify that of these three we always want /a/ ,we have a more accurate grammar.
Now instead ofrecognizing 14 or 15 possible underlying forms for theword ndg?eki, the grammar only recognizes ten.There iis a very simple but subtle point at issuehere, havihlg to do with writing reversible rules.
Thegrammar writers knew when they were formulatingthe assimilation rule that \[e\] and \[3\] were never go-ing to come up as input to the rule because these twovowels do not exist in the underlying representations.They also knew that there were no other rules ap-plying before the assimilation rule which would intro-duce \[?\] or \[~\].
Hence they did not need to distinguishbetween tim various possibilities for low vowels.
Inshort, the grammar writers made use of fairly subtleinformation to write a rule which was as pared downas possible.
Leaving out the features in (9), as Ken-stowicz and Kisseberth do, looks elegant, but turnsthe two-way rule into a one-way rule that works onlyfor generation.
This is a case where leaving out somefeatures obscures the content of the rule and preventsone from correctly applying the rule for recognition.In short, this is a case where the rule could have beenwritten in a way that was reversible, or at least morereversible, but in the name of "brevity" or "elegance"it was not.The vowels \[e\] and \[~\] also provide complications forthe revcrqal of the vowel deletion rule.
We have noreason to believe from the data given that the deletedvowel is ever \[~\] or N.  IIowever there is not a goodway of saying, using standard rule writing techniques,that any vowel that is introduced in the recognition9As mentioned in an earlier footnote, Kenstowicz and Kisse-berth seem t,o treat \[e,\] as \[+ low\].must be one of the underlying ones.
In ordered sets ofrules, there is not lypically a distinction made betweenthe segments that can occur as input to a rule andsegments that can only occur as output.
One of theunhappy consequences is that \[e\] and \[~\] have the samestatus with respect o the rules of Tunica as the other,underlying, vowels in the language.An even more serious problem revealed by this Tu-nica example is the inability of the standard genera-tire rule-writing mechanism to specify the interrela-tionship between rules.
The rules apply based only onstrings of characters they get as input, not oll whatrules came before.
In the case at hand, however, wewould like to be able to relate the two rules to oneanother.
What we would really like to be able tosay is that when in the course of recognition it be-comes necessary to reintroduce the deleted vowel, ifthere iu an \[e\] on the surface the reintroduced vowelmust be \[i\], and if there is an \[~\] the reintroducedvowel must be \[u\] or \[o\].
This is a problem with alpha(assimilation) rvdes.
There is no way to say that ifthere is an Is\] or \[~1 on the surface, then the reverseof the syncope rule must apply, when doing recogni-tion, and, furthermore, that it must apply in such away that the assimilation rule can then apply (againin reverse) and, lastly, that the reverse of the assim-ilation rule must then apply.
In simpler terms, thereis no way to say that if there is an \[~\] (respectively\[~\]) on the surface, then it must be preceded by anunder ly ing / i / ( respect ive ly /u /or /o / ) .When dealing with cases of deletion, and mergersin general, it is not generally possible to write a set ofrules that maps surface forms unambiguously to a sin-gle underlying form.
In the ease of the ~hmica voweldeletion, there are occurrences of surface forms inwhich the phonological rules cannot tell which vowelto reintroduce when doing recognition.
There are,however, cases where it is clear which vowel should bereintroduced, e.g., the case above, and in these cases,both the grammar formalism and the individual anal-ysis should be able to express this information.
Themechanism of using alphas and betas, for instance inassimilation rules, does not appear to have this ex-pressive capacity.The problem could be ameliorated by writing lesselegant rules.
For instance, the syncope rule in (7)could be written as in (1O).+syllabic \]+underlying --* 0 / _  q.
(10)-stressThis would ensure that the nommderlying vowels \[~\]and \[.~\] would not be introduced when applying therules in the reverse direction.
It still would not be as5 17restrictive as one could be using two-level rules.One could argue that all one needs to do is use thelexicon to weed out the forms that are wrong.
Yetone would not consider suggesting the same thing if agrammar generated too many surface forms, althoughone could imagine using a surface lexicon as a filter.The technique of using the lexicon to weed out theforms that are wrong is a perfectly good efficiencymeasure, but has no bearing on the question of howwell a formalism maps underlying forms to surfaceforms and vice versa.In the rest of this paper I will present and dis-cuss two-level accounts of phonological phenomenadescribed earlier, and show the merits of such an ap-proach.7 Two- level  RulesIn the two-level accounts that have been proposed\[Koskenniemi 1983, Karttunen and Wittenburg 1983,Bear 1986, etc.\], there are two alphabets of segments,underlying and surface.
There are constraint-rulesabout which underlying segments may b'e realized aswhich surface segments, and vice versa, based on con-text.
The rules' contexts are strings of pairs of seg-ments, each underlying segment paired with a sur-face segment.
Deletions and insertions are handledby pairing a segment with a null segment.
What iscrucial about the rules is that each element of a con-text is actually a pair of segments, an underlying anda surface segment.
The ability to refer to both sur-face and underlying contexts in a rule allows the rulewriter to describe phenomena that are handled withordered rules in the unilevel approach.The other powerful device in two-level phonology isan explicit listing of the two alphabets and the feasiblemappings between them.
These mappings are simplypairs of segments, one surface segment paired withone underlying segment.
This list of feasible pairstypically contains many pairs of identical segmentssuch as (a,a) or (b,b), representing that there are seg-nmnts that are the same underlyingly as on the sur-face.
The list also contains pairs representing change.For the Tunica example, (a,?)
and (ao) would be inthe list, but (a,u) and (i,u) for example would not be.The feasible pairs can be thought of as machinery forgenerating strings of pairs of segments that the ruleseither accept or reject.
An accepted string of segmentpairs constitutes a mapping from an underlying formto a surface form and from surface to underlying form.8 Rule OrderingIn a paper presented at the 1986 annual meeting ofthe Linguistic Society of America, Lauri Karttunenproposed this solution for the Klamath data above: 1?I i':= }, - , i l _  l..= (11)i?
:_h / =:t_ (12)I'--, ?
/= : l _  (13)The contexts of tile rules should be read as follows.Each pair separated by a colon is a lexical segmentfollowed by a surface segment.
The equals sign isa place holder used when the rule writer does notwant to make any commitment about what some seg-ment must be.
So, for instance, 1':= is an underlying/1 ' /paired with some surface segment, and the ruledoesn't care which.
Similarly, =:1 is a way of stil~u-lating that there is a surface \[I\] in the context, andwe don't care, for the purposes of this rule, whichunderlying segment it corresponds to.
The right ar-row, ---~, is being used in the way described in Bear\[1986, 1988 a,b\].
For example, Rule (11) should beconstrued as allowing the pair of segments n:!
(un-derlying n corresponding to surface l) to occur in therule's environment, while disallowing the pair n:n. Al-though the right arrow rule is reminiscent of' the arrowin unilevei rules, this interpretation is nondirectional.There are two other kinds of constraints to allow oneto deal effectively with the asymmetries involved inpairing underlying forms with surface forms.
In Bear\[1986, 1988\] the two other kinds of constraints are(1) to allow a pair of segments to occur in a certaincontext without disallowing the default pair (e.g.
n:nin the previous example is a default pair), and (2) todisallow a pair in some context without allowing someother pair.
For example, the rule types in (14) and(15) are allowed.a:b allowed here: a _ fl (14)a:b disallowed here: a _ fl (15)In Koskenniemi \[1983, 1984\] tile constraints areslightly different, but have roughly the same func-tionality.
I!1 Koskenniemi's ystem, one may stipu-late that if a lexical segment occurs in some context,then it must correspond to some particular surfacesegment.
One may also stipulate that a certain lexi-cal/surface segment pair may only occur in a certainenvironment.1?I'm using an amalgamation f notations from Koskenniemi,Karttunen and Wittenburg, and Bear.186Karttunen \[1986\] pointed out that the three rules in( l l ) ,  (12), and (13) work correctly to give the right re-suits when generating surface forms from underlyingforms, and made the point that they do so without re-course to the device of rule ordering.
Another point hecould have made about these rules which I will makehere is that they are just as effective in producingthe right underlying forms from surface forms.
Thereis not the problem of multiple intermediate l vels ofrepresentation, where one is faced with the choice ofwhether to continue applying \[reversed\] rules or tostop and call the form a result.9 Combining AssimilationWith DeletionOne solution for the Tunica data is given below) 1Vowel-stress \]?_a --, ~1  i:= .~ _- -~  V/7  where Vowel e {(16)(17)(18)Kules (16) and (17) say that /a /ass imi lates  to theunderlying vowel preceding it, with a glottal stop in-tervening.
One other crucial element of the two-levelway of doing things is that in addition to rules, agrammar contains a list of feasible segment pairs.
Forthis Tunica case, there presumably would not be afeasible pair/e/:\[e\], nor would there be /~/:\[~\] since\[el and \[3\] do not seem to occur as underlying vowels.Itence the surface Is\] in our example word \[ndg?ekz\]would be forced unambiguously to correspond to anunderly ing/a/ .
This is exactly what we want.Rule (18) specifies that unstressed vowels aredeleted when they occur before a glottal stop.
Therule makes clear that only the four vowels i, a, o, andu are deleted, and also that when doing recognition,only those vowels are allowed to be inserted.These rules make it clear that the underlying formfor \[ndg?ekt\] must be/ndgi?dki /modulo details of therule of Right Destressing.10 Analysis by SynthesisThere is one system for doing computational morphol-ogy, specifically for recognizing Turkish, which uses11 It is a common abbreviatory convention that any pair ofidendical segments, e.g., a:a, can be written simply as a singlesegment, e.g., a.
So, in these rules the glottal stop characterrepresents he pair: ?
:?.unilevel rules \[Hankamer, 1986\].
The system first in-vokes an ad hoc procedure to find the first heavy syl-lable of a Turkish word.
This substring and perhapsa few carefully constructed variants of it are consid- 'ered as possible stems for the word.
Next, based onthe morphotactic information about the stem foundin the lexicon, assuming one of the possible stems isin the lexicon, several possible suffixes are proposedas possible.
A set of phonological rules is appliedto the hypothesized underlying forms consisting ofstem+suffix.
Whichever of them results in a stringthat matches the input surface form is considered tobe right.
The process is repeated until the entirestring is analyzed.Since "l~lrkish is exclusively suffixing and has strongphonotactic onstraints on what can be a stem, it ispossible to write an ad hoc routine to pick the stemout.
It remains to be seen how this method of anal-ysis can be made general enough to be applied suc-cessfully to other languages.
While Hankamer's paperis interesting in its own right, it would be a mistaketo construe it ms demonstrating anything very generalabout reversibility of unilevel rule systems.11 ConclusionThe question has been asked, "What is so good aboutKoskenniemi's two-level phonology?"
The answer isthat it allows one to write reversible, nonproceduraldescriptions of phonological phenomena with muchmore accuracy than does the conventional unilevelformalism.
The point I have stressed here is the re-versibility.
From a computational point of view, thisrepresents a step forward.
There are no publishedaccounts of reversible grammars written in a unilevelformalism so far as I know and there are many writtenin two-level rules.
Koskenniemi's proposal was madewith computation ill mind as opposed to linguistictheory.
It may, in the long run, have an impact onlinguistic theory.
It definitely has had a large impacton computational morphology.AcknowledgementsThe bulk of this work was done while I was a visit-ing scientist at the IBM LILOG project in Stuttgart,Federal Republic of Germany, in the summer of 1988.This work was also made possible by a gift from theSystem Development Foundation as part of a coordi-nated research effort with tile Center for the Studyof Language and Information, Stanford University.
Iwould like to thank the people at IBM, Stuttgart, SRI,and CSLI for supporting this work.
I would also like7 19to thank the following people for many helpful discus-sions and comments: Meg Withgott, Martin Emele,Mary Dalrymple, Petra Steffens, Bob Mugele, andIIans Uszkoreit.I would not have been able to produce this paperhad it not been for Emma Pease who has done con-siderable work defining phonetic fonts and graphicsmacros for "l~X which she made available.
I wouldalso like to thank Mary Dalrymple for helping me withIbTEX.References\[1\] Barker, M.A.R.
(1964) Klamath Grammar, Uni-versity of California Press, Berkeley and Los Ange-les, Calilbrnia.\[2\] Bear, John (1985) "Interpreting Two-Level RulesDirectly," presented at a Stanford workshop onfinite-state morphology.\[3\] Bear, John (1986) "A Morphological Recognizerwith Syntactic and Phonological Rules," COLING86, pp.
272-276.\[4\] Bear, John (1988) "Two-Level Rules and NegativeRule Features," COLING 88, pp.
28-31.\[5\] Eliasson, Stig (1985) "Turkish k-Deletion: Sim-plicity vs. Retrieval," in Folia Linguistiea )(IX, 3-4,pp.
289-311, Mouton Publishers, The IIague.\[6\] Gazdar, Gerald (1985) "Finite State Morphology:A Review of Koskenniemi (1983)," Technical Re-port No.
CSLI-85-32 of the Center for the Studyof Language and Information, Stanford University,Stanford, California.\[7\] Ilaas, Mary (1940) Tunica.
Handbook of Ameri-can Indian Languages, Vol.
4.
Smithsonian I stitu-tion, Bureau of American Ethnography, Washing-ton, D.C.\[8\] lialle, Morris, and G.N.
Clements (1983) ProblemBook in Phonology: A Workbook for IntroductoryCourses in Linguistics and in Modern Phonology,The MIT Press, Cambridge, Massachusetts, andLondon, England.\[9\] IIankamer, Jorge (1986) "Finite State Morphol-ogy and Left-to-Right Phonology," in Proceedingsof the West Coast Conference on Formal Linguis-tics, published by Stanford Linguistics Association,Stanford, California.\[10\] Kaplan, Ronaid, and Martin Kay (1981) Paperpresented at the annual meeting of the LinguisticSociety of America.\[11\] Karttunen, Lauri (1983) "Kimmo: A GeneralMorphological Processor," in Texas Linguist.ic Fo-rum #22, Dairymple t al., eds., Linguistics De-partment, University of Texas, Austin, Texas.\[12\] Karttunen, Lauri (1986) "Compilation of Two-Level Phonological Rules," presented at the AnnualMeeting of the Linguistic Society of America in SanFrancisco, California.\[13\] Karttunen, Lauri, Kimmo Koskenniemi andRonald Kaplan (1987) "TWOL: A Compiler forTwo-Level Phonological Rules," distributed at the1987 Summer Linguistic Institute at Stanford Uni-versity, Stanford, California.\[14\] Karttunen, Lauri and Kent Wittenburg (1983)"A Two-Level Morphological Analysis Of English,"in Texas Linguistic Forum #22, Dalrymple t al.,eds., Linguistics Department, University of Texas,Austin, Texas.\[15\] Kay, Martin (1983) "When Meta-rules are notMeta-rules," in K. Sparck-Jones, and Y. Wilks, eds.Automatic Natural Language Processing, John Wi-ley and Sons, New York, New York.\[16\] Kay, Martin (1987) "Nonconcatenative Finite-State Morphology," paper presented at a workshopon Arabic Morphology, Stanford University, Stan-ford, California.\[17\] Kennstowicz, Michael, and Charles Kisseherth(1979) Generative Phonology, Academic Press, Inc.,IIarcourt, Brace, Jovanovich, Publishers, Orlando,San Diego, New York, Austin, Boston, London,Sydney, Tokyo, Toronto.\[18\] Koskenniemi, Kimmo (1983) Two-Level Mor-phology: A General Computational Model forWord-form Recognition and Production.
Publica-tion No.
11 of the University of IIelsinki Depart-ment of General Linguistics, tIelsinki, Finland.\[19\] Koskenniemi, Kimmo (1983) "Two-Level Modelfor Morphological Analysis," IJCAI 83, pp.
683-685.\[20\] Koskenniemi, Kimmo (1984) "A General Com-putational Model for Word-form Recognition andProduction," COLING 84, pp.
178-181.\[21\] Mohanan, K.P.
(1987) A Theory of LexicalPhonology, D. Reidel Publishing Company, Dor-drecht, Itolland.\[22\] Schane, Sanford (1973) Generative Phonology,Prentice Hall, Englewood Cliffs, New Jersey.20 8
