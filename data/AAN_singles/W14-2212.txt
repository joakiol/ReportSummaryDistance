Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 86?90,Baltimore, Maryland, USA, 26 June 2014.c?2014 Association for Computational LinguisticsShort-term projects, long-term benefits:Four student NLP projects for low-resource languagesAlexis Palmer and Michaela RegneriDepartment of Computational LinguisticsSaarland UniversitySaarbr?ucken, Germany{apalmer,regneri}@coli.uni-saarland.deAbstractThis paper describes a local effort tobridge the gap between computational anddocumentary linguistics by teaching stu-dents and young researchers in computa-tional linguistics about doing research anddeveloping systems for low-resource lan-guages.
We describe four student softwareprojects developed within one semester.The projects range from a front-end forbuilding small-vocabulary speech recogni-tion systems, to a broad-coverage (morethan 1000 languages) language identifi-cation system, to language-specific sys-tems: a lemmatizer for the Mayan lan-guage Uspanteko and named entity recog-nition systems for both Slovak and Per-sian.
Teaching efforts such as these are anexcellent way to develop not only tools forlow-resource languages, but also computa-tional linguists well-equipped to work onendangered and low-resource languages.1 IntroductionThere is a strong argument to be made for bring-ing together computational and documentary lin-guistics in order to support the documentation anddescription of endangered languages (Abney andBird, 2010; Bird, 2009).
Documentation, de-scription, and revitalization work for endangeredlanguages, as well as efforts to produce digi-tal and machine-readable resources for languagescurrently lacking such data, benefit from techno-logical support in many different ways.
Here wefocus on support via (a) tools facilitating more effi-cient development of resources, with easy learningcurves, and (b) linguistic analysis tools.Various meetings and workshops in recent yearshave helped to bring the two fields closer to-gether, but a sizeable gap remains.
We?ve comefar enough to, for example, have a relevant work-shop at a major computational linguistics confer-ence, but not so far that issues around language en-dangerment are well-known to even a large subsetof the computational linguistics community.
Oneway to get computational linguists thinking aboutissues related to endangered languages is for themto get their hands dirty ?
to work directly on re-lated projects.
In this paper we describe our ownlocal effort to bridge this gap: a course for Mas-ter?s and Bachelor?s students in computational lin-guistics in which small teams of students each pro-duced working, non-trivial natural language pro-cessing (NLP) tools for low-resource languages(LRLs) over the span of a single semester.
Theindividual projects are described in Section 3.Such a course benefits the students in a num-ber of ways.
They get hands-on experience insystem building, they learn about a new subfieldwithin computational linguistics, with a differentset of concerns (some of these are discussed inSection 2), and, in some cases, they get the op-portunity to develop tools for their own native lan-guages.
From the perspective of computationalwork on endangered languages, the positive out-comes are not only a new set of NLP tools, butalso a group of students and young researchersarmed with experience working on low-resourcelanguages and better equipped to take on similarprojects in the future.2 Teaching NLP for LRLsWorking on LRLs from a computational perspec-tive requires training beyond the typical compu-tational linguistics curriculum.
It is not the casethat the most widely-used methods from computa-tional linguistics can be straightforwardly adaptedfor any arbitrarily-selected language.
Thus an im-portant part of our teaching agenda in this contextis to familiarize students with the challenges inher-ent to NLP for LRLs as well as some of the main86approaches for addressing these same challenges.This section briefly surveys some of the relevantissues, with pointers to representative studies.The first and most obvious concern is data spar-sity.
Many of the most successful and widely-taught methods and models in computational lin-guistics rely on either large amounts of labeleddata or massive amounts of unlabeled data.
Meth-ods and models explicitly addressing LRLs needto maximize the utility of available data.
Ap-proaches for addressing data sparsity range fromdata collection proposals (Abney and Bird, 2010)to leveraging high-resource languages (Xia andLewis, 2007) to maximizing annotation effort(Garrette and Baldridge, 2013).
A second con-cern is model suitability.
Many existing modelsin computational linguistics implicitly encode orexpect characteristics of high-resource languages(Bender, 2011); for example, much work on com-putational syntax uses models that exploit linearordering of elements in utterances.
Such modelsare not straightforwardly applicable for languageswith free or flexible word order, nor for highlyagglutinative languages where, for example, com-plete utterances are encoded as single words.
Ap-proaches to this issues include adaptation of mod-els using linguistic knowledge and/or universals(Boonkwan and Steedman, 2011; Naseem et al.,2010).
The third issue to note is the difficultyof evaluation.
The output of systems or toolsperforming automated analysis are predictions ofanalyses for new data; these predictions mustbe evaluated against a ground truth or human-supplied analysis of the same data.
Evaluationis difficult in the low-resource setting, both be-cause of limited availability of expert-labeled dataand because, in some cases, the ground truthisn?t known, or analyses are shifting as knowledgeabout the language develops.We began the course with a discussion of theseissues, as well as an introduction to a range of ex-isting tools, projects and resources.
We did notexplicitly teach programming skills in the course,but we also did not require extensive program-ming background.
Rather, we aimed to balancethe teams such that each contained a mix of back-grounds: a bit more than half of the studentshad previous experience with software develop-ment, and the rest had at least taken one intro-ductory programming course.
The projects werescoped such that there were clear ways for stu-dents without programming experience to con-tribute.
For example, in some cases, students withextensive background in linguistics performed lin-guistic analysis of the data which informed the de-sign of the system.Evaluation of students was designed to empha-size three objectives: production of a working sys-tem, communication of challenges faced and so-lutions to those challenges, and personal devel-opment of professionally-relevant skills.
Studentswere graded on their weekly progress (more detailin Section 3), one 15-20 minute talk per student,individual written reports detailing specific contri-butions to the project, and a conference-style end-of-semester poster and demo session.
Systemswere required to be working and demonstratableboth at the midway point of the semester (as a sim-plified prototype) and at the end of the semester.3 Four projects in four monthsThe course described here (?NLP tools for Low-Resource Languages?)
was offered as part of theregular curriculum for undergraduate and gradu-ate students in the Computational Linguistics de-partment at Saarland University.
We started with10 students and formed four teams (based on pref-erences for general topics and programming lan-guages).
The teams could choose their own projector select from a set of proposed topics.During the teaching period, we regularly moni-tored the student?s progress by using some meth-ods of agile software development.1For eachweekly meeting, each team had to set three goalswhich constituted their homework.
Goals could beminor tasks (fixing a certain bug), bigger chunks(choosing and implementing a strategy for datastandardization) or course requirements (prepar-ing a talk).
Not fulfilling a (project-related) goalwas acceptable, but students had to analyze whythey missed the goal and to learn from the experi-ence.
They were expected over the course of thesemester to become better both at setting reach-able goals and at estimating how long they wouldneed to meet each goal.
Under this obligation tomake continuous, weekly progress, each team hada working system within three months.
At the endof month four, systems were suitable for demon-stration at the poster session.The projects differ according to their scopes andgoals, as well as their immediate practical utility.1http://en.wikipedia.org/wiki/Agile_software_development87One project (3.1) makes previous research accessi-ble to users by developing an easy-to-use frontend;a second project (3.2) aims to extend the num-ber of languages addressed for an existing multi-lingual classification task; and the remaining two(3.3 and 3.4) implement language-specific solu-tions for individual language processing tasks.
Weadditionally required that each project be open-source; the public code repositories are linked inthe respective sections.3.1 Small-vocabulary ASR for any languageThis project2builds on existing research for small-vocabulary (up to roughly 100 distinct words)speech recognition.
Such technology is desirablefor, among other things, developing speech inter-faces to mobile applications (e.g.
to deliver med-ical information or weather reports; see Sherwani(2009)), but dedicated speech recognition enginesare available only for a relatively small numberof languages.
For small-vocabulary applications,though, an existing recognizer for a high-resourcelanguage can be used to do recognition in the tar-get language, given a pronunciation lexicon map-ping the relevant target language words into se-quences of sounds in the high-resource language.This project produces the required lexicon.Building on the algorithms developed by Qiaoet al.
(2010) and Chan and Rosenfeld (2012), twostudents developed an easy-to-use interface thatallows a user with no knowledge of speech tech-nologies to build and test a system to recognizewords spoken in the target language.
In its cur-rent implementation, the system uses the English-language recognizer from the freely-available Mi-crosoft Speech Platform;3for this reason, the sys-tem is available for Windows only.
To build a rec-ognizer for a target language, a user needs onlyto specify a written form and upload one or moreaudio samples for each word in the vocabulary;generally, the more audio samples per word, thebetter the performance.
The students additionallyimplemented a built-in recorder; this means a usercan spontaneously make recordings for the desiredwords.
Finally, the system includes implementa-tions of two different variants of the algorithm andan evaluation module, thus facilitating use for bothresearch and development purposes.The main challenges for this project involvedmanaging the interaction between the algorithm2https://github.com/lex4all/lex4all3http://msdn.microsoft.com/en-us/library/hh361572and the Microsoft speech recognition platform, aswell as getting familiar with development in Win-dows.
The practical utility of this project is imme-diately evident: any user with a Windows machinecan install the necessary components and have aworking small-vocabulary recognizer within sev-eral hours.
Of course, more time and data maybe required to improve performance of the rec-ognizer, which currently reaches in the mid-70swith five audio samples per word.
These results,as well as further details about the system (includ-ing where to download the code, and discussionof substituting other high-resource language rec-ognizers), are described in Vakil et al.
(2014).3.2 Language ID for many languagesThis project4addresses the task of language iden-tification.
Given a string of text in an arbitrary lan-guage, can we train a system to recognize whatlanguage the text is written in?
Excellent classifi-cation rates have been achieved in previous work,but for a relatively small number of languages, andthe task becomes noticeably more difficult as thenumber of languages increases (Baldwin and Lui,2010; Lui and Baldwin, 2012, for example).
Withfew exceptions (Brown, 2013; Xia et al., 2010; Xiaet al., 2009), existing systems have only attemptedto distinguish between fewer than 200 of the thou-sands of written languages currently in use.
Thisteam of three students aimed to expand coverageof language identification systems as much as pos-sible given existing sources of data.To do this, they first needed to gather and stan-dardize data from various sources.
They targetedthree sources of data: the Universal Declarationof Human Rights, Wikipedia,5ODIN (Lewis andXia, 2010), and some portions of the data avail-able from Omniglot.5The challenges faced by thisgroup lay primarily in two areas: issues involv-ing data and those involving classification.
In thefirst area, they encountered expected and well-known issues such as clean-up and standardizationof data, dealing with encoding issues, and manag-ing large amounts of data.
The second set of chal-lenges have to do with the high degree of skewin the data collected.
Though their system coversover 1000 languages, the amount of data per lan-guage ranges from a single sentence to hundredsof thousands of words.
Along the way, the stu-dents realized that this collection of data in a stan-4https://github.com/alvations/SeedLing5http://www.wikipedia.com,http://www.omniglot.com88dard, machine-readable form is useful for manyother purposes.
The corpus and how to access itare described in Emerson et al.
(2014).
A secondpaper presenting the language identification re-sults (including those for low-resource languages)is planned for later this year.3.3 A lemmatizer for UspantekoThe third project6involved implementing a lem-matizer for the Mayan language Uspanteko.
Us-ing data that had been cleaned, standardized (asdescribed in Palmer et al.
(2010)), and made avail-able through the Archive of Indigenous Languagesof Latin America,7these three students imple-mented a tool to identify the citation form for in-flected word forms in texts.
The lemmatizationalgorithm is based on longest common substringmatching: the closest match for an inflected formis returned as the lemma.
Additionally, a table forirregular verb inflections was generated using theannotated source corpus (roughly 50,000 words)and an Uspanteko-Spanish dictionary (Can Pix-abaj et al., 2007), to map inflected forms translatedwith the same Spanish morpheme.This group more than any other faced the chal-lenge of evaluation.
Not all lemmas covered inthe texts appear in the dictionary, and the Uspan-teko texts, though fully analyzed with morphologi-cal segmentation and glossing, part of speech tags,and translation into Spanish, do not include cita-tion forms.
Manual evaluation of 100 sentences,for which a linguist on the team with knowledgeof Spanish determined citation forms, showed ac-curacy of 59% for the lemmatization algorithm.3.4 NER for Slovak & PersianFinally, the fourth project8(two students) choseto tackle the task of named entity recognition(NER): identifying instances of named entities(NEs, e.g.
people, locations, geopolitical entities)in texts and associating them with appropriate la-bels.
The students developed a single platform todo NER in both Slovak and Persian, their nativelanguages.
The approach is primarily based on us-ing gazetteers (for person names and locations), aswell as regular expressions (for temporal expres-sions).
The students collected the gazeteers for thetwo languages as part of the project.
Their sys-tem builds on a modular design; one can swap out6https://code.google.com/p/mayan-lemmatizer/7http://www.ailla.utexas.org8https://code.google.com/p/named\-entity\-tagger/gazetteers and a few language-specific heuristiccomponents to perform NER in a new language.In this project, resource acquisition and evalua-tion were the main challenges.
The students usedsome existing resources for both languages, butalso devoted quite some time to producing newgazetteers.
For Slovak, additional challenges werepresented by the language?s large number of in-flectional cases and resulting variability in form.For example, some inflected forms used to re-fer to people from a given location are string-identical to the names of the locations with a dif-ferent case inflection.
In Persian, the main chal-lenges were detection of word boundaries (manynames are multi-word expressions) and frequentNE/proper noun ambiguities.
For evaluation, thestudents hand-labeled over 35,000 words of Slo-vak (with 545 NE instances) and about 600 para-graphs of Persian data (306 NE instances).
Perfor-mace varies across named entity category: tempo-ral expression matching is most reliable (f-score0.96 for Slovak, 0.89 for Persion), followed bylocations (0.78 Slovak, 0.92 Persian) and personnames (0.63 Slovak, 0.87 Persian).
Note that forPersian, only NEs with correctly matched bound-aries are counted (which are 50% for persons).4 ConclusionIn this paper we have presented four student soft-ware projects, each one addressing a differentNLP task relevant for one or more low-resourcelanguages.
The successful outcomes of the fourprojects show that much progress can be madeeven with limited time and limited prior expe-rience developing such systems.
Local teach-ing efforts such as these can be highly success-ful in building a group of young researchers whoare both familiar with issues surrounding low-resource and endangered languages and preparedto do research and development in this area in thefuture.
We think of this as planting seeds for anearly harvest: with one semester?s combined effortbetween instructors and students, we reap the re-wards of both new tools and new researchers whocan continue to work on closing the gap betweencomputational and documentary linguistics.Course materials are publicly available from thecourse homepage,9and from the project reposito-ries linked from the descriptions in Section 3.9http://www.coli.uni-saarland.de/courses/cl4lrl-swp/89AcknowledgementsFirst of all, we want to thank the students who par-ticipated in our course and put so much effort andpassion in their projects.
They are (in alphabeti-cal order): Christine Bocionek, Guy Emerson, Su-sanne Fertmann, Liesa Heuschkel, Omid Moradi-annasab, Michal Petko, Maximilian Paulus, Alek-sandra Piwowarek, Liling Tan and Anjana Vakil.Further, we want to thank the anonymous review-ers for their helpful comments.
The second authorwas funded by the Cluster of Excellence ?Multi-modal Computing and Interaction?
in the GermanExcellence Initiative.ReferencesSteven Abney and Steven Bird.
2010.
The HumanLanguage Project: Building a universal corpus of theworld?s languages.
In Proceedings of the 48th An-nual Meeting of the Association for ComputationalLinguistics, pages 88?97.
Association for Computa-tional Linguistics.Timothy Baldwin and Marco Lui.
2010.
Languageidentification: The long and the short of the matter.In Human Language Technologies: The 2010 An-nual Conference of the North American Chapter ofthe Association for Computational Linguistics, HLT?10, pages 229?237, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Emily M Bender.
2011.
On achieving and evaluatinglanguage-independence in NLP.
Linguistic Issues inLanguage Technology, 6(3):1?26.Steven Bird.
2009.
Natural language processingand linguistic fieldwork.
Computational Linguis-tics, 35(3):469?474.Prachya Boonkwan and Mark Steedman.
2011.
Gram-mar induction from text using small syntactic proto-types.
In IJCNLP, pages 438?446.Ralf D Brown.
2013.
Selecting and weighting n-gramsto identify 1100 languages.
In Text, Speech, and Di-alogue, pages 475?483.
Springer.Telma Angelina Can Pixabaj, Oxlajuuj Keej Maya?Ajtz?iib?
(Group) Staff, and Centro Educativo y Cul-tural Maya Staff.
2007.
Jkemiix yalaj li uspanteko.Cholsamaj Fundacion, Guatemala.Hao Yee Chan and Roni Rosenfeld.
2012.
Discrimi-native pronunciation learning for speech recognitionfor resource scarce languages.
In Proceedings of the2nd ACM Symposium on Computing for Develop-ment, page 12.
ACM.Guy Emerson, Liling Tan, Susanne Fertmann, AlexisPalmer, and Michaela Regneri.
2014.
SeedLing:Building and using a seed corpus for the HumanLanguage Project.
In Proceedings of ACL Workshopon the use of computational methods in the study ofendangered languages (ComputEL).Dan Garrette and Jason Baldridge.
2013.
Learning apart-of-speech tagger from two hours of annotation.In Proceedings of NAACL-HLT, pages 138?147.William D Lewis and Fei Xia.
2010.
DevelopingODIN: A multilingual repository of annotated lan-guage data for hundreds of the world?s languages.Literary and Linguistic Computing, 25(3):303?319.Marco Lui and Timothy Baldwin.
2012.
Langid.py:An off-the-shelf language identification tool.
InProceedings of the ACL 2012 System Demonstra-tions, ACL ?12, pages 25?30, Stroudsburg, PA,USA.
Association for Computational Linguistics.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowl-edge to guide grammar induction.
In Proceedings ofthe 2010 Conference on Empirical Methods in Nat-ural Language Processing, pages 1234?1244.
Asso-ciation for Computational Linguistics.Alexis Palmer, Taesun Moon, Jason Baldridge, KatrinErk, Eric Campbell, and Telma Can.
2010.
Compu-tational strategies for reducing annotation effort inlanguage documentation.
Linguistic Issues in Lan-guage Technology, 3.Fang Qiao, Jahanzeb Sherwani, and Roni Rosenfeld.2010.
Small-vocabulary speech recognition forresource-scarce languages.
In Proceedings of theFirst ACM Symposium on Computing for Develop-ment, page 3.
ACM.Jahanzeb Sherwani.
2009.
Speech interfaces for in-formation access by low literate users.
Ph.D. thesis,SRI International.Anjana Vakil, Max Paulus, Alexis Palmer, andMichaela Regneri.
2014. lex4all: A language-independent tool for building and evaluating pronun-ciation lexicons for small-vocabulary speech recog-nition.
In Proceedings of ACL2014 Demo Session.Fei Xia and William Lewis.
2007.
Multilingual struc-tural projection across interlinear text.
In Proceed-ings of HLT/NAACL 2007, Rochester, NY.Fei Xia, William D Lewis, and Hoifung Poon.
2009.Language ID in the context of harvesting languagedata off the web.
In Proceedings of the 12th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 870?878.
Associ-ation for Computational Linguistics.Fei Xia, Carrie Lewis, and William D Lewis.
2010.The problems of language identification withinhugely multilingual data sets.
In LREC.90
