Semantics of Conceptual GraphsJohn F. SowaIBM Systems Research Institute205 East 42nd StreetNew York, NY 10017ABSTRACT: Conceptual graphs are both a language forrepresenting knowledge and patterns for constructing models.They form models in the AI sense of structures that approxi-mate some actual or possible system in the real world.
Theyalso form models in the logical sense of structures for whichsome set of axioms are true.
When combined with recentdevelopments in nonstandard logic and semantics, conceptualgraphs can form a bridge between heuristic techniques of AIand formal techniques of model theory.I .
Surface ModelsSemantic networks are often used in AI for representingmeaning.
But as Woods (1975) and McDermott (1976) ob-served, the semantic networks themselves have no well-definedsemantics.
Standard predicate calculus does have a preciselydefined, model theoretic semantics; it is adequate for describ-ing mathematical theories with a closed set of axioms.
But thereal world is messy, incompletely explored, and full of unex-pected surprises.
Furthermore, the infinite sets commonlyused in logic are intractable both for computers and for thehuman brain.To develop a more realistic semantics, Hintikka (1973)proposed surface models as incomplete, but extendible, finiteconstructions:Usually, models are thought of as being given through a specifi-cation of a number of properties and relations defined on thedomain.
If the domain is infinite, this specification (as well asmany operations with such entities) may require non-trivial set-theoretical assumptions.
The process is thus often non-finitistic.It is doubtful whether we can realistically expect such structuresto be somehow actually involved in our understanding of a sen-tence or in our contemplation of its meaning, notwithstanding thefact that this meaning is too often thought of as being determinedby the class of possible worlds in which the sentence in questionis true.
It seems to me much likelier that what is involved inone's actual understanding of a sentence S is a mental anticipa-tion of what can happen in one's step-by-step investigation of aworld in which S is true.
(p. 129)The  first stage of constructing a surface model  begins with theentities occurring in a sentence or story.
During the construc-tion, new facts may he asserted that block certain extensionsor facilitate others.
A standard model  is the limit of a surfacemodel that has been extended infinitely deep, but such infiniteprocesses are not a normal part of understanding.This paper adapts Hintikka's surface models to the formal-ism of conceptual graphs (Sowa 1976, 1978).
Conceptualgraphs serve two purposes: like other forms of semantic net-works, they can be used as a canonical representation f mean-ing in natural language; but they can also be used as buildingblocks for constructing abstract structures that serve as modelsin the model-theoretic sense.?
Understanding a sentence begins with a translation of thatsentence into a conceptual graph.?
During the translation, that graph may be joined to frame-like (Minsky 1975) or script-like (Schank & Ahelson1977) graphs that help resolve ambiguities and incorporatebackground information.?
The resulting graph is a nucleus for constructing models ofpossible worlds in which the sentence is true.?
Laws of the world behave like demons or triggers thaimonitor the models and block illegal extensions.?
If a surface model could be extended infinitely deep, theresult would be a complete standard model.This approach leads to an infinite sequence of algorithmsranging from plausible inference to exact deduction; they areanalogous to the varying levels of search in game playing pro-grams.
Level 0 would simply translate a sentence into a con-ceptual graph, but do no inference.
Level I would do frame-like plausible inferences in joining other background graphs.Level 2 would check constraints by testing the model againstthe laws.
Level 3 would join more background graphs.
Level4 would check further constraints, and so on.
If the const-raints at level n+l  are violated, the system would have tobacktrack and undo joins at level n. If at some level, all possi-ble extensions are blocked by violations of the laws, then thatmeans the original sentence (or story) was inconsistent withthe laws.
If the surface model is infinitely extendible, then theoriginal sentence or story was consistent.Exact inference techniques may let the surface modelsgrow indefinitely; but for many applications, they are as im-practical as letting a chess playing program search the entiregame tree.
Plausible inferences with varying degrees of confi-dence are possible by stopping the surface models at differentlevels of extension.
For story understanding, the initial surfacemodel would be derived completely from the input story.
Forconsistency checks in updating a data base, the initial modelwould be derived by joining new information to the pre-existing data base.
For question-answering, a query graphwould be joined to the data base; the depth of search permit-ted in extending the join would determine the limits of com-plexity of the questions that are answerable.
As a result ofthis theory, algorithms for plausible and exact inference can becompared within the same framework; it is then possible tomake informed trade-offs of speed vs. consistency in data baseupdates or speed vs. completeness in question answering.2.
Conceptual GraphsThe following conceptual graph shows the concepts andrelationships in the sentence "Mary hit the piggy hank with ahammer."
The boxes are concepts and the circles are concep-tual relations.
Inside each box or circle is a type label thatdesignates the type of concept or relation.
The conceptualrelations labeled AONI".
INST.
and PTNT represent the linguisticcases agent, instrument, and patient of case grammar.39PERSON: MaryConceptual graphs are a kind of semantic network.
SeeFindler (1979) for surveys of a variety of such networks thathave been used in AI.
The diagram above illustrates somefeatures of the conceptual graph notation:?
Some concepts are generic.
They have only a type labelinside the box, e.g.
mT or HAMMEa?
Other concepts are individuaL They have a colon after thetype label, followed by a name (Mary) or a unique identifi-er called an individual marker ( i22103).To keep the diagram from looking overly busy, the hierarchyof types and subtypes is not drawn explicitly, but is determinedby a separate partial ordering of type labels.
The type labelsare used by the formation rules to enforce selection constraintsand to support the inheritance of properties from a supertypeto a subtype.For convenience, the diagram could be linearized by usingsquare brackets for concepts and parentheses for conceptualrelations:\[ PERSON:Mary\]-.~ AGNT)-~( HIT:c I \]~--4 INST).~-(HAMMEI~.\]\[HIT:c I \]4--( PTNT).~---\[P\[ GO Y-B A NK:i22 I03\]Linearizing the diagram requires a coreference index, el ,  on thegeneric concept HiT.
The index shows that the two occur-rences designate the same act of hitting.
If mT had been anindividual concept, its name or individual marker would besufficient to indicate the same act.Besides the features illustrated in the diagram, the theoryof conceptual graphs includes the following:?
For any particular domain of discourse, a specially desig-nated set of conceptual graphs called the canon,?
Four canonical formation rules for deriving new canonicalgraphs from any given canon,?
A method for defining new concept types: some canonicalgraph is specified as the differentia and a concept in thatgraph is designated the genus of the new type,?
A method for defining new types of Conceptual relations:some canonical graph is specified as the relator and one ormore concepts in that graph are specified as parameters,?
A method for defining composite entities as structureshaving other entities as parts,?
Optional quantifiers on generic concepts,?
Scope of quantifiers specified either by embedding theminside type definitions or by linking them with functionaldependency arcs,?
Procedural attachments associated with the functionaldependency arcs,?
Control marks that determine when attached proceduresshould be invoked.These features have been described in the earlier papers; forcompleteness, the appendix recapitulates the axioms and defi-nitions that are explicitly used in this paper.Heidorn's (1972, 1975) Natural Language Processor(NLP) is being used to implement he theory of conceptualgraphs.
The NLP system processes two kinds of AugmentedPhrase Structure rules: decoding rules parse language inputsand create graphs that represent heir meaning, and encodingru/es scan the graphs to generate language output.
Since theNLP structures are very similar to conceptual graphs, much ofthe implementation amounts to identifying some feature orcombination of features in NLP for each construct in concep-tual graphs.
Constructs that would be difficult or inefficient oimplement directly in NLP rules can be supported by LISPfunctions.
The inference algorithms in this paper, however,have not yet been implemented.3.
Log/caJ Connect/yesCanonical formation rules enforce the selection constraintsin linguistics: they do not guarantee that all derived graphsare true, but they rule out semantic anomalies.
In terms ofgraph grammars, the canonical formation rules are context-free.
This section defines logical operations that are context-sensitive, They enforce tighter constraints on graph deriva-tions, but they require more complex pattern matching.
For-marion rules and logical operations are complementary mecha-nisms for building models of possible worlds and checking theirconsistency,Sowa (1976) discussed two ways of handling logical oper-ators in conceptual graphs: the abstract approach, which treatsthem as functions of truth values, and the direct approach,which treats implications, conjunctions, disjunctions, and nega-tions as operations for building, splitting, and discarding con-ceptual graphs.
That paper, however, merely mentioned theapproach; this paper develops a notation adapted fromOantzen's sequents (1934),  but with an interpretation basedon Beinap's conditional assertions (1973) and with computa-tional techniques similar to Hendrix's partit ioned semanticnetworks (1975, 1979).
Deliyanni and Kowalski (1979) useda similar notation for logic in semantic networks, but with thearrows reversed.Definition: A seq~nt is a collection of conceptual  graphsdivided into two sets, called the conditions ut ..... Un and theanergons vt,...,v,,, It is written Ul,...,Un "* vl,...,Vm.
Sever-al special cases are distinguished:?
A simple assertion has no conditions and only oneassertion: -.. v.?
A disjunction has no conditions and two or moreasser t ions :  ..m. PI,.
.
.
,Vm.?
A simple denial has only one condition and noassertions: u -....?
A compound enial has two or more conditions and noassertions: ut,...,un -...?
A conditianal assertion has one or more conditions andone or more assertions: ut,...,un .... Vl....,v~?
An empty clause has no conditions or assertions: --.,.?
A Horn clo,ue has at most one assertion; i.e.
it is el-ther an empty clause, a denial, a simple assertion, or aconditional assertion of the form ut ..... ,% --4, v.For any concept a in an assertion vi, there may be a con-cept b in a condition u/ that is declared to be coreferentwith a.Informally, a sequent states that if all of the conditions aretrue, then at least one of the assertions must be true.
A se.quent with no conditions is an unconditional assertion; if there40are two or more assertions, it states that one must be true, hutit doesn't say which.
Multiple asserth)ns are necessary forgeneral ity, but in deduct ions,  they may cause a model to splitinto models  of multiple altei'native worlds.
A sequent with noassert ions denies that the combinat ion of condit ions can everoccur.
The empty clause is an uncondit ional denial; it is self-contradictory.
Horn clauses are special cases for which deduc-t ions are simplif ied: they have no dis junct ions that causemodels of the world to split into multiple alternatives.Definit ion: Let C be a collection of canonical graphs,  and let sbe the sequent  ut .
.
.
.
.
Un - ' ,  vl .
.
.
.
.
vm.?
If every condition graph is covered by some graph inC, then the condit ions are said to be sa l i s f ied .?
If some condition graph is not covered by any graph inC, then the sequent s is said to be i napp l i cab le  to C.If n---0 (there are no condit ions),  then the condit ions aretrivially satisfied.A sequent is like a conditional assertion in Belnap's sense:When its condit ions are not satisfied, it asserts nothing.
Butwhen they are satisfied, the assert ions must be added to thecurrent  context.
The next axiom states how they are added.Axiom: Let C be a collection of canonical graphs, and let s bethe sequent  ul ..... u ,  -,- v~ ..... v,,,.
If the condit ions of s aresatisfied by C, then s may be app l ied  to C as follows:?
If m,=l) (a denial or the empty clause),  the collectionC is said to be b locked .?
If m=l  (a Horn clause),  a copy of each graph ui isjoined to some graph in C by a covering join.
Thenthe assertion v is added to the resulting collection C'.?
If m>2,  a copy of each graph ui is joined to somegraph in C by a covering join.
Then all graphs in theresulting collection C' are copied to make m disjointc~)llections identical to C'.
Finally, for each j from Ito rn, whe assertion v I is added to the j -th copy of C'.After an assertion v is added to one of the collections C',each concept in v that was declared to be coreferent withsome concept b in one of the condit ions ui is joined to thatconcept to which b was joined.When a collection of graphs is inconsistent with a sequent,they are blocked by it.
If the sequent represents a fundamen-tal law about the world, then the collection represents animpossible situation.
When there is only one assertion in anapplicable sequent,  the collection is extended.
But when thereare two or more assertions, the collection splits into as manysuccessors as there are assert ions; this splitting is typical ofalgorithms for dealing with disjunctions.
The rules for apply-ing sequents are based on Beth's semantic tableaux f1955) ,but the computat ional  techniques are similar to typical AImethods of production rules, demons,  triggers, and monitors.Deliyanni and Kowalski (1979)  relate their algorithms forlogic in semantic networks to the resolution principle.
Thisrelationship is natural because a sequent whose condit ions andassert ions are all atoms is equivalent to the standard clauseform for resolution.
But since the sequents def ined in thispaper may be arbitrary conceptual  graphs, they can package amuch larger amount  of information in each graph than the lowlevel atoms of ordinary resolution.
As a result, many fewersteps may be needed to answer  a quest ion or do plausibleinferences.4.
Laws, Facts, and Possible WorldsInfinite families of p~ssible worlds are computat iona l lyintractable, hut Dunn (1973) showed that they are not neededfor the semantics of modal logic.
He considered each possibleworld w to be characterized by two sets of propositions: lawsL and facts F. Every law is also a fact, but some facts aremerely contingently true and are not considered laws.
A prop-osition p is necessarily true in w if it follows from the laws ofw, and it is possible in w if it is consistent with the laws of w.Dunn proved that semantics in terms of laws and facts isequivalent to the possible worlds semantics.Dunn's approach to modal logic can be combined withHintikka's surface models and AI methods for handling de-faults.
Instead of dealing with an infinite set of possibleworlds, the system can construct finite, but extendible surfacemodels.
The basis for the surface models is a canon thatcontains the blueprints for assembling models and a set of lawsthat must be true for each model.
The laws impose obligatoryconstraints on the models, and the canon contains commonbackground information that serves as a heuristic for extendingthe models.An initial surface model would start as a canonical graphor collection of graphs that represent a given set of facts in asentence or story.
Consider the story,Mary hit the piggy bank with a hammer.
She wanted to go to themovies with Janet.
but she wouldn't get her allowance untilThursday.
And today was only Tuesday.The first sentence would be translated to a conceptual  graphlike the one in Section 2.
Each of the following sentenceswould be translated into other conceptual  graphs and joined tothe original graph.
But the story as stated is not understanda-ble without a lot of background information: piggy banksnormally contain money; piggy banks are usually made ofpottery that is easily broken; going to the movies requiresmoney; an allowance is money; and Tuesday precedes Thurs-day.Charniak (1972)  handled such stories with demons  thatencapsulate  knowledge: demons  normal ly lie dormant ,  butwhen their associated patterns occur in a story, they wake upand apply their piece of knowledge to the process of under-standing.
Similar techniques are embodied in production sys-tems, languages like PLANNER (Hewitt  1972) ,  and knowl-edge representat ion systems like KRL (Bobrow & Winograd1977).
But the trouble with demons  is that they are uncon-strained: anything can happen when a demon wakes up, notheorems are possible about what a collection of demons  canor cannot  do, and there is no way of relating plausible reason-ing with demons to any of 'the techniques of standard or non-standard logic.With conceptual  graphs,  the computat ional  overhead isabout the same as with related AI  techniques, but the advan-tage is that the methods can be analyzed by the vast body oftechniques that have been developed in logic.
The graph for"Mary hit the piggy-bank with a hammer" is a nucleus aroundwhich an infinite number of possible worlds can be built.
Twoindividuals, Mary and rlcc~Y-a^NK:iZzloL are fixed, but theparticular act of hitting, the hammer Mary used, and all othercircumstances are undetermined.
As the story continues, someother individuals may be named, graphs from the canon maybe joined to add default information, and laws of the world in41the form of sequents may be triggered (like demons) to en-force constraints.
The next definition introduces the notion ofa world bas~ that provides the building material (a canon) andthe laws (sequents) for such a family of possible worlds.Definition: A world basis has three components: a canon C, afinite set of sequents L called laws, and one or more finitecollections of canonical graphs {Ct ..... Co} called contexts.No context C~ may be blocked by any law in L.A world basis is a collection of nuclei from which completepossible worlds may evolve.
The contexts are like Hintikka'ssurface models: they are finite, but extendible.
The graphs inthe canon provide default or plausible information that can bejoined to extend the contexts, and the laws are constraints onthe kinds of extensions that are possible.When a law is violated, it blocks a context as a candidatefor a possible world.
A default, however, is optional; if con-tradicted, a default must be undone, and the context restoredto the state before the default was applied.
In the samplestory, the next sentence might continue: "The piggy bank wasmade of bronze, and when Mary hit it, a genie appeared andgave her two tickets to Animal House."
This continuationviolates all the default assumptions; it would be unreasonableto assume it in advance, but once given, it forces the system toback up to a context before the defaults were applied and jointhe new information to it.
Several practical issues arise: howmuch backtracking is necessary, how is the world basis used todevelop possible worlds, and what criteria are used to decidewhen to stop the (possibly infinite) extensions.
The next sec-tion suggests an answer.5.
Game T h ~  Se~md~The distinction between optional defaults and obligatorylaws is reminiscent of the AND-OR trees that often arise inAI, especially in game playing programs.
In fact, Hintikka(1973, 1974) proposed a game theoretic semantics for testingthe truth of a formula in terms of a model and for elaboratinga surface model in which that formula is true.
Hintikka'sapproach can be adapted to elaborating a world basis in muchthe same way that a chess playing program explores the gametree:?
Each context represents a position in the game.?
The canon defines \[Sossible moves by the current player,?
Conditional assertions are moves by the opponent.?
Denials are checkmating moves by the opponent.?
A given context is consistent with the laws if there exists astrategy for avoiding checkmate.By following this suggestion, one can adapt the techniquesdeveloped for game playing programs to other kinds of reason-ing in AI.Definition: A game over a world basis W is defined by thefollowing rules:?
There are two participants named Player and Oppo-m~nt.?
For each context in W, Player has the first move.?
Player moves in context C either by joining two graphsin C or by selecting any graph in the canon of W thatis joinable to some graph u in C and joining it maxi-really to u.
If no joins are possible, Player passes.Then Opponent  has the right to move in context C.?
Opponent  moves by checking whether any denials inW are satisfied by C. If so, context C is blocked andis deleted from W. If no denials are satisfied, Oppo-nent may apply any other sequent that is satisfied in C.If no sequent is satisfied, Opponent  passes.
ThenPlayer has the right to move in context C.?
If no contexts are left in W,  Player loses.?
If both Player and Opponent pass in succession, Playerwins.Player wins this game by building a complete model that isconsistent with the laws and with the initial information in theproblem.
But like playing a perfect game of chess, the cost ofelaborating a complete model is prohibitive.
Yet a computercan play chess as well as most people do by using heuristics tochoose moves and terminating the search after a few levels.To develop systematic heuristics for choosing which graphs tojoin, Sown (1976) stated rules similar to Wilks' preferencesemantics ( 1975).The amount of computation required to play this gamemight be compared to chess: a typical middle game in chesshas about 30 or 40 moves on each side, and chess playingprograms can consistently beat beginners by searching only 3levels deep; they can play good games by searching 5 levels.The number of moves in a world basis depends on the numberof graphs in the canon, the number of laws in L, and the num-ber of ~aphs  in each context.
But for many common applica-tions, 30 or 40 moves is a reasonable stimate at any givenlevel, and useful inferences are possible with just a shallowsearch.
The scripts applied by Schank and Abelson (1977),for example, correspond to a game with only one level oflook-ahead; a game with two levels would provide the plausibleinformation of scripts together with a round of consistencychecks to eliminate obvious blunders.By deciding how far to search the game tree, one canderive algor ithm for plausible inference with varying levels ofconfidence.
Rigorous deduction similar to model elimination(Loveland 1972) can be performed by starting with laws and acontext hat correspond to the negation of what is to be provedand showing that Opponent has a winning strategy.
By similartransformations, methods of plausible and exact inference canbe related as variations on a general method of reasoning.6.
Appendix: Summary of the FormalismThis section summarizes axioms, definitions, and theorems aboutconCeptual graphs that are used in this paper.
For a more complete discus-sion and for other features of the theory that are not used here, see theeartier articles by Sown (1976, 1978).Definition 1: A comcepm~ gmmp& is a finite, connected, bipartite graphwith nodes of the first kind called concepu and nodes of the secondkind called conceptual relatWn$.Definition 2: Every conceptual relation has one or more arc~, each ofwhich must be attached to a concept.
If the relation has n arcs.
it issaid to be n-adic, and its arcs are labeled I, 2 ..... n.The most common conceptual relations are dyadic (2-adic), but thedefinition mechanisms can create ones with any number of arcs.
Althoughthe formal defin/tion says that the arcs are numbered, for dyadic relations.arc I is drawn as an arrow pointin8 towards the circle, and arc 2 as anarrow point/aS away from the circle.42Axiom I: There is a set T of type labeLv and a function type.
which mapsconcepts and conceptual relations into T.?
If rypefa)=type(b), then a and b are said to be of the same tXpe.?
Type labels are partially ordered: if (vpe(a)<_typefhL then a issaid to be a subtype of b.?
Type labels of concepts and conceptual relations arc disjoint,noncomparable subsets nf T: if a is a concept and ?
is a concep-tual relation, then a and r may never he of the same type, normay one be a subtype of the other.Axiom 2: There is a set I= \ [ i l ,  i2, i3 .
.
.
.  }
whose elements are calledindividual markers.
The function referent applies to concepts:If a is a concept, then referentla) is either an individual marker inI or the symbol @, which may be read any.?
When referentla) ~" l, then a is said to be an individual concept.?
When referent(a)=@, then a is said to be a genertc oncept.In diagrams, the referent is written after the type label, ~parated  by acolon.
A concept of a particular cat could be written as ICAT:=41331.
Agenetic concept, which would refer to any cat, could be written ICA'r:tiiH orsimply \[CATI.
In data base systems, individual markers correspond to thesurrogates (Codd 1979).
which serve as unique internal identif iers forexternal entities.
The symbol @ is Codd's notation for null or unknownvalues in a data base.
Externally printable or speakable names are relatedto the internal surrogates by the next axiom.Axiom 3: There is a dyadic conceptual relation with type label NAME.
Ifa relation of type NAME occurs in a conceptual graph, then the con-cept attached to arc I must be a subtype of WORD, and the conceptattached to arc 2 must be a subtype of ENTITY.
If the second conceptis individual, then the first concept is called a name of that individual.The following graph states that the word "Mary"  is the name of aparticular person: \["Mary"\]-.=.tNAME)-=.lPERSON:i30741.
i f there is only oneperson named Mary in the context, the graph could be abbreviated to just\[PERSON:Mary\],Axiom 4: The conformity ?elation :: relates type labels in T to individualmarkers in I.
If teT, tel.
and t::i. then i is said to conform to t.?
If t~gs and t::i. then s::i.?
For any type t, t::@.?
For any concept c. type(c)::referentfc).The conformity relation says that the individual for which the markeri is a surrogate is of type t. In previous papers, the terms permissible orapplicable were used instead of conforms to.
but the present term and thesymbol :: have been adopted from ALGOL-68.
Suppose the individualmarker i273 is a surrogate for a beagle named Snoopy.
Then BEAGLE::i273is true.
By extension, one may also write the name instead of the marker,as BEAGLE=Snoopy.
By axiom 4, Snoopy also conforms to at\] supertypes ofBEAGLE.
such as DOG::Snoopy, ANIMAL=Snoopy.
or ENTITY::Snoopy.Definition 3: A star graph is a conceptual graph consisting of a singleconceptual relation and the concepts attached to each of its arcs.
(Two or more arcs of the conceptual relation may be attached to thesame concept.
)Definition 4: Two concepts a and b are said to be joinable i f  both of thefollowing properties are true:?
They are of the same type: type(a)-typefb).?
Either referent(a)=referent(b), referent(a)=.
@, or referent(b)=.
@.Two star graphs with conceptual relations r and s are said to bejoinable if ?
and s have the same number of arcs, type(r),=rype(s), andfor each i. the concept attached to arc i of r is joinable to the conceptattached to arc i of s.Not all combinations of concepts and conceptual relations are mean-ingful.
Yet to say that some graphs are meaningful and others are not isbegging the question, because the purpose of conceptual graphs is to formthe basis of a theory of meaning, To  avoid prejudging the issue, the termcanonical is used for those graphs derivable from a designated set calledthe canon.
For any given domain of discourse, a canon is dcl'incd thatrules out anomalous combinations.Definition 5: A canon has thrcc components:?
A partially ordered ~et T of type labels.?
A set I of individual marker~, with a conformily relation ::.?
A finite set of conceptual graphs with type or c~Jnccl)lS andconceptual relations in T and wilh referents either let *~r markersin I.The number of possible canonical graphs may be infinite, but thecanon contains a finite number from which all the others can be derived.With an appropriate canon, many undesirable graphs are ruled out asnoncanonical, but the canonical graphs are not necessari!y true.
T~) ensurethat only truc graphs are derived from true graphs, the laws discussed inSection 4 eliminate incnnsistcnt combinations.Axiom 5: A conceptual graph is called canontrol eithcr if it is in the c:tnq)nor if it is derivable from canonical graphs by ()ne of the followingcanonic'a/formation ?ules.
I,et u and v be canonical graphs (u and vmay be the same graph).?
Copy: An exact copy of u is canonical.?
Restrict: Let a be a concept in u, and let t be a type label wheret<_typela) and t::referenrfa).
Then the graph obtained by changingthe type label of a to t and leaving ?eferent(a) unchanged is can-onical.?
Join on aconcept: Let a be aconcept in u, and baconcept  in vIf a and b are joinable, then the graph derived by the followin~steps is canonical: First delete b from v; then attach to a all arcsof conceptual relations that had been attached to b.
If re/'eremfa)e I, then referent(a) is unchanged; otherwise, referent(a) is re-placed by referent(b).?
Join on a star: Let r be a conceptual relation in u. and x a con-ceptual relation in v. If the star graphs of r and s are joinable.then the graph derived by the following steps is canonical: Firstdelete s and its arcs from v; then for each i. join the conceptattached to arc i of ?
to the concept that had been attached toarc i of s.Restriction replaces a type label in a graph by the label of a subtype:this rule lets subtypes inherit the structures that apply to more generaltypes.
Join on a concept combines graphs that have concepts of the sametype: one graph is overlaid on the other so that two concepts of the sametype merge into a single concept; as a result, all the arcs that had beenconnected to either concept arc connected to the single merged concept.Join on a star merges a conceptual relation and all of its attached conceptsin a single operation.Definition 6: Let v be a conceptual graph, let v, be a subgraph of v inwhich every conceptual relation has exactly the same arcs as in v. andlet u be a copy of v, in which zero or more concepts may be restrictedto subtypes.
Then u is called a projection of v. and ?, is called aprojective ortgin of u in v.The main purpose of projections is to define the rule of join on acommon projection, which is a generalization of the rules for joining on aconcept or a star.Definition 7: If a conceptual graph u is a projection of both v and w. it iscalled a common projection of v and w,Theorem l: If u is a common projection of canonical graphs t, and w, thenv and w may be joined on the common projection u to form a canonicalgraph by the following steps:?
Let v' be a projective origin of u in v. and let w, be a projectiveorigin of u in w.?
Restrict each concept of v, and ~ to the type label of the corre-sponding concept in u.?
Join each concept of v, to the corresponding concept of w,.?
Join each star graph of ?
to the corresponding star of ~43The concepts and conceptual relations in the resulting raph consist ofthose in v-t~, w-~,  and a copy of u.Definition 8: If v and w are joined on a common projection u. then allconcepts and conceptual relations in the projective origin of u in v andthe projective origin of u in ~v are said to be covered by the join.
inparticular, if the projective origin of u in v includes all of v. then theentire graph v is covered by the join.
and the join is called a coveringjoin of v by w,Definition 9: Let v and w be joined on a common projection u.
The joinis called extendible if there exist some concepts a in v and b in w withthe following properties:?
The concepts a and b were joined to each other.?
a is attached to a conceptual relation ?
that was not covered bythe join.?
b is attached to a conceptual relation s that was not covered bythe join.?
The star graphs of r and s are joinable.If a join is not extendible, it is called mn.ximal.The definition of maximal join given here is simpler than the onegiven in Sown (1976), but it has the same result.
Maximal joins have theeffect of Wilks' preference rules (1975) in forcing a maximum connectivityof the graphs.
Covering joins are used in Section 3 in the rules for apply-ing sequeots.Theorem 2: Every covering join is maximal.Sown (1976) continued with further material on quantifiers andprocedural attachments, and Sown (1978) continued with mechanisms fordefining new types of concepts, conceptual relations, and compositeentities that have other entities as parts.
Note that the terms sort, aubaort,and well-formed in Sown (1976) have now been replaced by the terms type,subtype, and canonical.7.
AcknowledgmentI would like to thank Charles Bontempo, Jon Handel, and GeorgeHeidorn for helpful comments on earlier versions of this paper.8.
ReferencesBelnap, Nuei D., Jr. (1973) "Restricted QuanUfication and ConditionalAssertion."
in Leblanc (1973) pp.
48-75.Beth.
E. W. (1955) "Semantic Entailment and Formal Derivability,"reprinted in J. Hintikka, ed., The Philoaapky of  Mathematk~s, OxfordUniversity Press, 1969. pp.
9-41.Bobrow.
D. G.. & T. Winograd (1977) "An Overview of K\]RL-O, a Knowl-edge Representation Language," Cognitive $cicnca, voL 1, pp.
3-46.Charniak, Eugene (1972) Toward~ a Model of Chiid~n's Story Coml~ehen-rion.
AI Memo No.
266, MIT Project MAC, Cambridge, Mall.Codd.
E. F. (1979) "Extending the Data Base Relational Model to Cap-ture More Meaning," to appear in Transactions on Dataha~ $yst#ma.Dellyanni.
Amaryllis.
& Robert A. Kowalski (1979) "Logic and SemanticNetworks."
Communications of the ACM, voL 22, no.
3, pp.
184--192.Dunn.
J. Michael (1973) "A Truth Value Semantics for Modal Logic," inLeblanc (1973) pp.
87-100.Findler, Nicholas V., ed.
(1979) Associative Networks, Academic Press,New York.Gentzen.
Gerhard (1934) "Investigations into Logical Deduction," reprint-ed in M. E. Szabo, ed., The Collected Papers of Gerhard Gentxon.North-Holland.
Amsterdam, 1969. pp.
68-131.Heidorn.
George E. (1972) Natural LangUage \[nput~ to a SimulationProgramming System.
Technical Report NPS-55HD72101A, NavalPostgraduate School.
Monterey.Heidorn, George E. (1975) "Augmented Phrase Structure Grammar."
inR.
Schank & B. L, Nash-Webber.
eds..
Theoretical Issues in NaturalLunguage Processing, pp.
1-5.Hendrix, Gary G. (1975) "Expanding the Utility of Semantic Networksthrough Partitioning," in proc.
of the Fourth IJCAi, Tbilisi, Georgia,USSR, pp.
115-121.Hendrix.
Gary G. (1979) "Encoding Knowledge in Partitioned Networks,"in Findler (1979) pp.
51-92.Hewitt, Carl (1972) Description and Theoretical Analys~ (Using Schemata)o\[ PLANNER.
AI Memo No.
251, MIT Project MAC, Cambridge.Mass.Hintiid~a.
Jaakko (1973) "Surface Semantics: Definition and its Motiva-tion," in Leblanc (1973) pp.
128-147.Hintikka, Jaakko (1974) "Quantifiers vs. Quantification Theory," Lingu/a-tic Inq,,~ry, vol.
5, no.
2. pp.
153-177.Hintikka, Jaakko.
& Esa Saarinen (1975) "Semantical Games and theBach-Peters Paradox."
Theoretical Linguistics.
vol.
2, pp.
1-20.Leblanc.
Hughes, ed.
(1973) Truth.
Syntax.
and Modaliry, North-HollandPublishing Co.. Amsterdam.Loveland.
D. W. (1972) "A Unifying View of Some Linear HerbrandProcedures," Journal of the ACM, voi.
19, no.
2, pp.
366-384.McDermott, Drew V. (I 976) "Artificial Intelligence Meets Natural Stupid-ity," SIGART Newalerler.
No.
57, pp.
4-9.Minsky, Marvin (1975) "A Framework for Representing Knowledge."
inWinston, P. H., ed..
The Psychology of Computer Vision.
McGraw-Hill,New York.
pp.
211-280.Schank, Roger, & Robert Abelson (1977) Scripts.
Pla~, Goals and Under-standing, Lawrence Eribeum Associates, Hillsdale.
N. J.Sown, John F. (1976) "Conceptual Graphs for a Data Base Interface,"\[BM Jaurnal of Research & Development, vol.
20, pp.
336-357.Sown, John F. (1978) "Definitional Mechanisms for Conceptual Graphs,"presented at the International Workshop on Graph Grammars, BadHormef, Germany, Nov. 1978.Wilks, Yorick (1975) "Preference Semantics," in E. L. Keenan, ed.,Formal Semantics of Nazurol Language.
Cambridge University Press,pp.
329-348.Woods, William A.
(1975) "What's in a Link: Foundations for SemanticNetworks," in D. G. Bobrow & A. Collins.
eds., Rapraenmtion andUnabnmnding, Academic PresS.
New York.44
