Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 150?154,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsToward Using Morphology in French-English Phrase-based SMTMarine CarpuatCenter for Computational Learning SystemsColumbia University475 Riverside Drive, New York, NY 10115marine@ccls.columbia.eduAbstractWe describe the system used in our sub-mission to the WMT-2009 French-Englishtranslation task.
We use the Moses phrase-based Statistical Machine Translation sys-tem with two simple modications of thedecoding input and word-alignment strat-egy based on morphology, and analyzetheir impact on translation quality.1 IntroductionIn this first participation to the French-Englishtranslation task at WMT, our goal was to build astandard phrase-based statistical machine transla-tion system and study the impact of French mor-phological variations at different stages of trainingand decoding.Many strategies have been proposed to inte-grate morphology information in SMT, includingfactored translation models (Koehn and Hoang,2007), adding a translation dictionary containinginflected forms to the training data (Schwenk etal., 2008), entirely replacing surface forms byrepresentations built on lemmas and POS tags(Popovic?
and Ney, 2004), morphemes learned inan unsupervised manner (Virpojia et al, 2007),and using Porter stems and even 4-letter prefixesfor word alignment (Watanabe et al, 2006).
Innon-European languages, such as Arabic, heavyeffort has been put in identifying appropriate in-put representations to improve SMT quality (e.g.,Sadat and Habash (2006))As a first step toward using morphology infor-mation in our French-English SMT system, thissubmission focused on studying the impact of?The author was partially funded by GALE DARPA Con-tract No.
HR0011-06-C-0023.
Any opinions, findings andconclusions or recommendations expressed in this materialare those of the authors and do not necessarily reflect theviews of the Defense Advanced Research Projects Agency.different input representations for French basedon the POS and lemmatization provided by theTreetagger tool (Schmid, 1994).
In the WMT09French-English data sets, we observe that morethan half of the words that are unknown in thetranslation lexicon actually occur in the trainingdata under different inflected forms.
We show thatcombining a lemma backoff strategy at decodingtime and improving alignments by generalizingacross verb surface forms improves OOV rates andtranslation quality.2 Translation system2.1 Data setsWe use a subset of the data made available for theofficial French to English translation task.
Theevaluation test set consists of French news datafrom September to October 2008, however thebulk of the training data is not from the same do-main.
The translation model was trained on theEuroparl corpus (europarl-v4) and the small newscommentary corpus (news-commentary09).
Fol-lowing De?chelotte et al (2008), we learn a sin-gle phrase table and reordering model rather thanone for each domain, as it was found to yield bet-ter performance in a very similar setting.
Thelanguage model was trained on the English sideof these parallel corpora augmented with non-parallel English news data (news-train08.en).
Pa-rameter tuning was performed on the designateddevelopment data, which is also in the news do-main: news-dev2009a was used as the develop-ment set and news-dev2009b as the test set.Using those data sets, there is therefore a mis-match between the training and evaluation do-mains, as in the domain adaptation tasks of theprevious WMT evaluations.
A large automaticallyextracted parallel corpus was made available, butwe were not able to use it due to time constraints.Additional use of this in-domain data would im-150prove coverage and translation quality.2.2 PreprocessingFrench and English corpora processing followedthe same three steps:First, long sentences are resegmented usingsimple punctuation-based heuristics.Second, tokenization, POS tagging and lemma-tization are performed with Treetagger (Schmid,1994) using the standard French and English pa-rameter files1.
Treetagger is based on HiddenMarkov Models where transition probabilities areestimated with decision trees.
The POS tag setconsists of 33 tags which capture tense informa-tion for verbs, but not gender and number.Third, sentence-initial capitalized words arenormalized to their most frequent form as reportedby Zollmann et al (2006).2.3 Core systemWe use the Moses phrase-based statistical machinetranslation system (Koehn et al, 2007) and followstandard training, tuning and decoding strategies.The translation model consists of a stan-dard Moses phrase-table with lexicalized reorder-ing.
Bidirectional word alignments obtained withGIZA++ are intersected using the grow-diag-finalheuristic.
Translations of phrases of up to 7 wordslong are collected and scored with translation pro-bilities and lexical weighting.The English language model is a 4-gram modelwith Kneser-Ney smoothing, built with the SRIlanguage modeling toolkit (Stolcke, 2002).The loglinear model feature weights werelearned using minimum error rate training(MERT) (Och, 2003) with BLEU score (Papineniet al, 2002) as the objective function.Other decoding parameters were selected man-ually on an earlier version of the system trainedand evaluated on the single-domain Europarl data.While the configuration achieved competitive re-sults on the previous, it is not be optimal for thisdomain adaptation task.We will first conduct an analysis of this coreSMT system, and experiment with two modifi-cations of input representation for decoding andalignment respectively.1www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/OOV verbs w/ surfaceform intrainingcorpusw/ lemma+POS intrainingcorpusdev2009a 21 (28%) 48 (63%)dev2009b 16 (24%) 33 (49%)Table 1: Unknown verbs statistics3 Many unknown words are (almost)seen in trainingOur baseline system is set up to copy unknownwords to the output.
This is a helpful strategy totranslate unknown names and cognates, but is farfrom optimal.
In this section, we take a closer lookat those unknown words.About 25% of the dev and test set sentencescontain at least one unknown token.
After elim-inating number expressions, which can be handledwith translation rules, the majority of unknownwords are content words, nouns, verbs and adjec-tives.
As reported in Table 1, we find that many ofthe verbs that are not in the phrase-table vocabu-lary were actually seen in the training data in theexact same form: they are therefore out of vocabu-lary due to alignment errors.
In addition, for morethan half of the unknown verb occurrences, an-other inflexion form for the same lemma and POStag are observed in the training corpus.Using only the surface form of words thereforeleads us to ignore potentially useful informationavailable in our training corpus.
Additional train-ing data would naturally improve coverage, butwill not cover all possible morphological varia-tions of all verbs, especially for tenses and personsthat are not used frequently in news coverage.
Itis therefore necessary to generalize beyond wordsurface forms.4 Using morphological information indecodingA simple strategy for handling unknown wordsat decoding time consists in replacing their oc-currences in the test set with their lemma, whenit is part of the translation lexicon vocabulary.Unlike with factored models (Koehn and Hoang,2007) or additional translation lexicons (Schwenket al, 2008), we do not generate the surface formback from the lemma translation, which meansthat tense, gender and number information are151news-dev2009a representation OOV % METEOR BLEU NISTbaseline surface form only 2.24 49.05 20.45 6.135decoding lemma backoff 2.13 49.12 20.44 6.143word alignmentlemma+POS for all 2.24 48.87 20.36 6.145lemma+POS for adj 2.25 48.94 20.46 6.131lemma+POS for verbs 2.21 49.05 20.47 6.137decoding + alignmentbackoff + all 2.10 48.97 20.36 6.147backoff + adj 2.12 49.05 20.48 6.140backoff + verbs 2.08 49.15 20.50 6.148news-dev2009b representation OOV % METEOR BLEU NISTbaseline surface form only 2.52 49.60 21.10 6.211decoding lemma backoff 2.43 49.66 21.02 6.210word alignmentlemma+POS for all 2.53 49.56 21.03 6.199lemma+POS for adj 2.52 49.74 21.00 6.213lemma+POS for verbs 2.47 49.73 21.10 6.217decoding+alignmentbackoff + all 2.44 49.59 20.92 6.194backoff + adj 2.43 49.80 21.03 6.217backoff + verbs 2.39 49.80 21.03 6.217Table 2: Evaluation of the decoding backoff strategy, the modified word alignment strategy and theircombinationInput Me?me s?il de?missionnait, la situation ne changerait pas.Baseline even if it de?missionnait, the situation will not change.Lemma backoff even if it resign, the situation will not change.Reference even if he resigned, the situation would remain the same.Input Tant que tu gagnes, on te laisse en paixBaseline As you gagnes, it leaves you in peaceLemma backoff As you win, it leaves you in peaceReference As Long as You Gain, We Let YouInput Le groupe a re?agi comme il faut, il a sorti un nouveau et meilleur disque.Baseline The group has reacted properly, it has emerged a new and better records.Lemma+POS for verbs The group has reacted properly, it has produced a new and better records.Reference The group responded with a new and even better CD.Input Un trader qui ne prend pas de vacances est un trader qui ne veut pas laisser son book a` un autre?,conclut Kerviel.Baseline A senior trader which does not take holiday is a senior trader which does not allow his book to another,?
concludes Kerviel.Lemma+POS for verbs A senior trader which does not take holiday is a senior trader who do not wish to leave his book toanother, ?
concludes Kerviel.Reference A broker who does not take vacations is a broker who does not want anybody to look into his records,?Kerviel concluded.Table 3: Examples of improved translations by morphological analysisInput 54 pour cent ne font pas du tout confiance au premier ministre et 27 pour cent au pre?sident du Fidesz.Baseline 54% are not all confidence to Prime Minister and the President of Fidesz 1.27%.Backoff + verbs 54% do not all confidence to Prime Minister and 27% to the President of Fidesz.Reference Fifty-four percent said they did not trust the PM, while 27 percent said they mistrusted the Fideszchairman.Input Le prsident Va?clav Klaus s?est nouveau prononc sur la proble?matique du rchauffement plantaire.Baseline President Va?clav Klaus has once again voted on the problem of global warming.Backoff+verbs President Va?clav Klaus has again pronounced on the problem of global warming.Reference President Va?clav Klaus has again commented on the problem of global warming.Input Mais les supe?rieurs e?taient au courant de tout, ou pluto?t, ils s?en doutaient.Baseline But superiors were aware of everything, or rather, they knew.Backoff+verbs But superiors were aware of everything, or rather, they doubted.Reference But his superiors are said to have known, or rather suspected the whole thing.Table 4: Examples of translations that are not improved morphological analysis152lost.
However, imperfect lemma translations canbe more useful to understand the meaning of theinput sentence than copying the unknown word tothe output.We report the impact of this strategy on auto-matic evaluation scores in the decoding section ofTable 2.
Since only a small subset of the test sen-tences are affected by the change, the score vari-ation is small, but the OOV rate decreases andtranslation quality is not degraded.
In additionto the BLEU and NIST n-gram precision metricswhich only count exact matches between systemoutput and reference, we report METEOR scoreswhich take into account matches after lemmatiza-tion using both the Porter stemmer and the Word-Net lemmas (Banerjee and Lavie, 2005).
The im-provement in METEOR scores results from morematches with the references, yielding both im-proved precision and recall.Manual inspection of the output sentencesshows that the translations are better to the humaneye and potentially more useful to subsequent textunderstanding applications (Table 3).5 Using morphological information inword-alignmentIn this experiment, we would like to use morpho-logical analysis to alleviate the alignment errorsbecause of which some words from the parallelcorpus are not in the phrase-table.
We adopt atwo-step approach: (1) before word alignment, re-place surface forms by lemma and POS tags.
Inour experiments, this replacement is performed for3 categories of words: verbs only, adjectives onlyand all words.
(2) the phrase-table and reorder-ing models are learned as usual using word surfaceforms, but with the alignment links from step 1.In constrast with Watanabe et al (2006), we at-tempt to generalize for specific word categoriesonly, rather than use lemmas across all surfaceforms, as we found in earlier experiments that thisapproach did not help translation quality in ourparticular setting.Unlike other approaches which use morpholog-ical analysis to change the representation of theinput (e.g., Popovic?
and Ney (2004), Sadat andHabash (2006), Virpojia et al (2007)), our systemstill uses word surface forms as input during de-coding.
This is a constraint imposed by the rela-tively coarse analysis given by the default Treetag-ger lemmas and POS tags.
Since they do not cap-ture information that is crucial in translation suchas number and gender, we need to keep surfaceforms as the input for translation.The impact of this strategy on automatic eval-uation metrics is reported in the word alignmentsection of Table 2.
Note that all experiments wereperformed using the parameters learned by MERTon news-dev2009a using the baseline configura-tion.
Again the impact in numbers is small, butdoes not degrade translation quality.
The ME-TEOR score is slightly improved on the real testset.
As expected given our POS tag set, it seemsbetter to restrict the modifications of the input forword alignment to verbs or adjectives.This simple modification of the training proce-dure improves the coverage of the phrase-table,but the OOV rate remains higher than with thelemma backoff strategy.
For the news-dev2009btest set, 1186 additional phrases are available inthe phrase-table after replacing verb surface formsby their lemma and POS combination.
About halfof the test sentences are changed.
As reflected bythe scores, most of the changes are small and donot yield significantly different sentences.
How-ever, some translations are improved as can beseen in Table 3.The impact of both strategies combined is re-ported in the decoding + alignment section of Ta-ble 2.
Tables 3 and 4 show positive and negativeexamples of translations using the best combina-tion.6 ConclusionWe have described the system used for our sub-mission, which is based on Moses with two sim-ple modifications of the decoding input and word-alignment strategy in order to improve coveragewithout using additional training data.
Whilethe improvements on automatic metrics are small,manual inspection suggests that better morpholog-ical analysis for the French side has potential toimprove translation quality.
In future work, weplan to improve the core model by including thenew large in-domain parallel corpus in training,and to further experiment with French input rep-resentations at different stages of training and de-coding using more expressive POS tags such asthe MULTITAG tag set (Allauzen and Bonneau-Maynard, 2008).153ReferencesAlexandre Allauzen and He?le`ne Bonneau-Maynard.
Training and evaluation of postaggers on the french multitag corpus.
InEuropean Language Resources Association(ELRA), editor, Proceedings of the Sixth Inter-national Language Resources and Evaluation(LREC?08), Marrakech, Morocco, may 2008.Satanjeev Banerjee and Alon Lavie.
METEOR:An automatic metric for MT evaluation withimproved correlation with human judgement.In Proceedings of Workshop on Intrinsic andExtrinsic Evaluation Measures for MT and/orSummarization at the 43th Annual Meeting ofthe Association of Computational Linguistics(ACL-2005), Ann Arbor, Michigan, June 2005.Daniel De?chelotte, Gilles Adda, Alexandre Al-lauzen, He?le`ne Bonneau-Maynard, Olivier Gal-ibert, Jean-Luc Gauvain, Philippe Langlais, andFranc?ois Yvon.
LIMSIs statistical translationsystems for WMT08.
In Proceedings of theThird Workshop on Statistical Machine Trans-lation, pages 107?110, Columbus, Ohio, 2008.Philipp Koehn and Hieu Hoang.
Factored trans-lation models.
In Proceedings of the 2007Joint Conference on Empirical Methods in Nat-ural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL),pages 868?876, 2007.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen,Christine Moran, Richard Zens, Chris Dyer,Ondrej Bojar, Alexandra Constantin, and EvanHerbst.
Moses: Open source toolkit for statisti-cal machine translation.
In Annual Meeting ofthe Association for Computational Linguistics(ACL), demonstration session, Prague, CzechRepublic, June 2007.Franz Josef Och.
Minimum error rate training instatistical machine translation.
In Proceedingsof the 41st Annual Meeting of the Associationfor Computational Linguistics, pages 160?167,2003.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
BLEU: a method for automaticevaluation of machine translation.
In Proceed-ings of the 40th Annual Meeting of the Associa-tion for Computational Linguistics, 2002.Maja Popovic?
and Hermann Ney.
Towards the useof word stems and suffixes for statistical ma-chine translation.
In Proceedings of the 4th In-ternational Conference on Language Resourcesand Evaluation (LREC-2004), 2004.Fatiha Sadat and Nizar Habash.
Combination ofarabic preprocessing schemes for statistical ma-chine translation.
In ACL-44: Proceedings ofthe 21st International Conference on Computa-tional Linguistics and the 44th annual meetingof the Association for Computational Linguis-tics, pages 1?8, Morristown, NJ, USA, 2006.Association for Computational Linguistics.Helmut Schmid.
Probabilistic part?of?speech tag-ging using decision trees.
In Proceedings of theConference on New Methods in Language Pro-cessin, pages 44?49, Manchester, UK, 1994.Holger Schwenk, Jean-Baptiste Fouet, and JeanSenellart.
First steps towards a general pur-pose French/English statistical machine transla-tion system.
In Proceedings of the Third Work-shop on Statistical Machine Translation, pages119?122, Columbus, Ohio, June 2008.
Associ-ation for Computational Linguistics.Andreas Stolcke.
SRILM?an extensible lan-guage modeling toolkit.
In International Con-ference on Spoken Language Processing, Den-ver, Colorado, September 2002.Sami Virpojia, Jaako J. Va?yrynen, Mathias Creutz,and Markus Sadeniemi.
Morphology-aware sta-tistical machine translation based on morphs in-duced in an unsupervised manner.
In MachineTranslation Summit XI, pages 491?498, Copen-hagen, Denmark, September 2007.Taro Watanabe, Hajime Tsukada, and HidekiIsozaki.
Ntt system description for the wmt2006shared task.
In Proceedings on the Workshopon Statistical Machine Translation, pages 122?125, New York City, June 2006.
Association forComputational Linguistics.Andreas Zollmann, Ashish Venugopal, StephanVogel, and Alex Waibel.
The CMU-UKA Syn-tax Augmented Machine Translation Systemfor IWSLT-06.
In Proceedings of the Interna-tional Workshop on Spoken Language Transla-tion, pages 138?144, Kyoto, Japan, 2006.154
