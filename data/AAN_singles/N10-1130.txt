Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 876?884,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsWhy Synchronous Tree Substitution Grammars?Andreas MalettiUniversitat Rovira i Virgili, Departament de Filologies Roma`niquesAvinguda de Catalunya 35, 43002 Tarragona, Spainandreas.maletti@urv.catAbstractSynchronous tree substitution grammars are atranslation model that is used in syntax-basedmachine translation.
They are investigated ina formal setting and compared to a competi-tor that is at least as expressive.
The competi-tor is the extended multi bottom-up tree trans-ducer, which is the bottom-up analogue withone essential additional feature.
This modelhas been investigated in theoretical computerscience, but seems widely unknown in natu-ral language processing.
The two models arecompared with respect to standard algorithms(binarization, regular restriction, composition,application).
Particular attention is paid to thecomplexity of the algorithms.1 IntroductionEvery machine translation system uses a transla-tion model, which is a formal model that describesthe translation process.
Either this system is hand-crafted (in rule-based translation systems) or it istrained with the help of statistical processes.
Brownet al (1990) discuss automatically trainable transla-tion models in their seminal paper on the latter ap-proach.
The IBM models of Brown et al (1993) arestring-based in the sense that they base the transla-tion decision on the words and the surrounding con-text.
In the field of syntax-based machine transla-tion, the translation models have access to the syntax(in the form of parse trees) of the sentences.
Knight(2007) presents a good exposition to both fields.In this paper, we focus on syntax-based transla-tion models, and in particular, synchronous tree sub-stitution grammars (STSGs), or the equally pow-erful (linear and nondeleting) extended (top-down)tree transducers of Graehl et al (2008).
Chiang andKnight (2006) gives a good introduction to STSGs,which originate from the syntax-directed transla-tion schemes of Aho and Ullman (1972) [nowadaysmore commonly known as synchronous context-freegrammars].
Roughly speaking, an STSG has rulesin which a nonterminal is replaced by two trees con-taining terminal and nonterminal symbols.
In addi-tion, the nonterminals in the two trees are linked anda rule is only applied to linked nonterminals.Several algorithms for STSGs have been dis-cussed in the literature.
For example, we can?
train them [see Graehl et al (2008)],?
attempt to binarize them using the methods of(Zhang et al, 2006; Huang et al, 2009; DeNeroet al, 2009b),?
parse them [see DeNero et al (2009a)], or?
attempt to compose them.However, some important algorithms are partial be-cause it is known that the construction might not bepossible in general.
This is the case, for example,for binarization and composition.In the theoretical computer science community,alternative models have been explored.
Sucha model is the multi bottom-up tree transducer(MBOT) of Arnold and Dauchet (1982) and Lilin(1981), which essentially is the bottom-up analogueof STSGs with the additional feature that nontermi-nals can have an arbitrary rank (the rank of a non-terminal of an STSG can be considered to be fixedto 1).
This model is even more expressive thanSTSGs, but still offers good computational proper-ties.
In this contribution, we will compare STSGsand MBOTs with respect to some standard algo-rithms.
Generally, MBOTs offer algorithmic ben-efits over STSG, which can be summarized as fol-876lows:?
Every STSG can be transformed into an equiv-alent MBOT in linear time.?
MBOTs can be fully binarized in lineartime whereas only partial binarizations (orasynchronous binarizations) are possible forSTSGs.?
The input language of an MBOTM can be reg-ularly restricted in O(|M | ?
|S|3), whereas thecorresponding construction for an STSG M isin O(|M | ?
|S|2 rk(M)+5) where rk(M) is themaximal number of nonterminals in a rule ofthe STSG M .?
MBOTs can be composed, whereas this cannotbe achieved for STSGs.Overall, we thus conclude that, from an algorith-mic perspective, it would be beneficial to work withMBOTs instead of STSGs.
However, the full powerof MBOTs should not be tapped because, in gen-eral, MBOTs have the finite-copying property [seeEngelfriet et al (1980)], which complicates the al-gorithms for forward and backward application (seeSection 7).2 Preliminary definitionsAn alphabet is a finite set of symbols.
Our weighteddevices use real-number weights, but the resultstranslate easily to the more general setting of com-mutative semirings [see Golan (1999)].
A weightedstring automaton as in Schu?tzenberger (1961) andEilenberg (1974) is a system (S,?, I, ?, F ) where?
S and ?
are alphabets of states and input sym-bols, respectively,?
I, F : S ?
R assign initial and final weights,respectively, and?
?
: S ?
?
?
S ?
R assigns a weight to eachtransition.Let w = ?1 ?
?
?
?k ?
??
be an input string oflength k. A run on w is r : {0, .
.
.
, k} ?
S. Theweight of the run r is wt(r) =?ki=1 ?
(ri?1, ?i, ri).The semantics of the automaton A then assigns to wthe weightA(w) =?r run on wI(r0) ?
wt(r) ?
F (rk) .A good introduction to weighted string automata canbe found in Mohri (2009) and Sakarovitch (2009).To simplify the theoretical discussion, we as-sume that each symbol that we use in trees has afixed rank, which determines the number of chil-dren of each node with that label.
A ranked alpha-bet ?
=?k?0 ?k is an alphabet whose symbolshave assigned ranks.
The set ?k contains all sym-bols of rank k. The set T?
(V ) of ?-trees indexedby a set V is the smallest set such that V ?
T?
(V )and ?
(t1, .
.
.
, tk) ?
T?
(V ) for every ?
?
?k andt1, .
.
.
, tk ?
T?
(V ).
The size |t| of the tree t ?
T?is the number of occurrences of symbols from ?
?Vthat appear in t. A context c is a tree of T??
{}(V ),in which the nullary symbol  occurs exactly once.The set of all such contexts is C?
(V ).
The tree c[t]is obtained from c by replacing the symbol  by t.A weighted synchronous tree substitution gram-mar (STSG) is a system (N,?,?, I, P ) where?
N is an alphabet of nonterminals,?
?
and ?
are ranked alphabets of input and out-put symbols, respectively,?
I : N ?
R assigns initial weights, and?
P is a finite set of productions n : ta?
u withn ?
N , t ?
T?
(N), a ?
R, and u ?
T?
(N)such that?
every n?
?
N that occurs in t occurs ex-actly once in u and vice versa, and?
t /?
N or u /?
N .Note that our distinction between nonterminals andterminals is rather uncommon for STSG [see Chi-ang (2005)], but improves the generative power.
Wechose the symbol ???
because STSG productionsare symmetric.
The size |n : ta?
u| of a produc-tion is |t| + |u|, and the size |M | of the STSG M is?p?P |p|.
It is a weighted tree substitution grammar(TSG) if t = u for all productions n : ta?
u ?
P .Further, it is in normal form if for every productionn : ta?
u ?
P there exist ?
?
?k, ?
?
?k, andnonterminals n1, .
.
.
, nk, n?1, .
.
.
, n?k ?
N such thatt = ?
(n1, .
.
.
, nk) and u = ?
(n?1, .
.
.
, n?k).
A de-tailed exposition to STSGs and STSGs in normalform (also called synchronous context-free gram-mars) can be found in Chiang (2005).
Further detailson TSGs can be found in Berstel and Reutenauer(1982) and Fu?lo?p and Vogler (2009).Equal nonterminals in t and u of a produc-tion n : ta?
u ?
P are linked.
To keep the pre-sentation simple, we assume that those links are re-877SNP1 @V NP2?SV @NP1 NP2SNPx1@Vx2NPx3?SSx2 @x1 x3Figure 1: STSG production (top) and correspondingMBOT rule (bottom) where @ is an arbitrary symbol thatis introduced during binarization.membered also in sentential forms.
In addition, weassume that N ?
?
= ?.
For every c, c?
?
C?
(N)and n ?
N , let (c[n], c?[n])a?
(c[t], c?
[u]) if?
there is a production n : ta?
u ?
P , and?
the explicit (the ones replacing ) occurrencesof n in c[n] and c?
[n] are linked.Left-most derivations are defined as usual, and theweight of a derivation D : ?0a1?
?
?
?ak?
?k iswt(D) =?ki=1 ai.
The weight assigned by thegrammar M to a pair (t, u) ?
T?
?
T?
isM(t, u) =?n?NI(n) ?
?D left-most derivationfrom (n, n) to (t, u)wt(D) .The second restriction on productions ensures thatderivations are of finite length, and thus that thesums in the definition of M(t, u) are finite.In the following, we will use syntactic simplifica-tions such as?
several occurrences of the same nonterminal ina tree (disambiguated by decoration).?
symbols that are terminals (of ?
and ?)
andnonterminals.
We will print nonterminals initalics and terminal symbols upright.?
omission of the nonterminal n (or the weight a)of a rule n : ta?
u if the terminal n occurs atthe root of t and u (or a = 1).?
na?
t instead of n : ta?
t if it is a TSG.A sample STSG production (using those simplifica-tions) is displayed in Figure 1.
Our STSGs are es-sentially equivalent to the (nondeleting and linear)extended tree transducers of Graehl et al (2008) andMaletti et al (2009).
@Vx2NPx3?Ux2 x3SNPx1Ux2 x3?U ?x2 @x1 x3U ?x1 x2?SSx1 x2Figure 2: Sample MBOT rules in one-symbol normalform.3 Multi bottom-up tree transducersAs indicated in the Introduction, we will compareSTSGs to weighted multi bottom-up tree transduc-ers, which have been introduced by Arnold andDauchet (1982) and Lilin (1981).
A more detailed(and English) presentation can be found in Engel-friet et al (2009).
Let us quickly recall the formaldefinition.
We use a fixed set X = {x1, x2, .
.
.
}of (formal) variables.
For a ranked alphabet S andL ?
T?
(X) we letS(L) = {s(t1, .
.
.
, tk) | s ?
Sk, t1, .
.
.
, tk ?
L}and we treat elements of S(L) like elementsof T?
?S(X).Definition 1 A weighted multi bottom-up tree trans-ducer (MBOT) is a system (S,?,?, F,R) where?
S, ?, and ?
are ranked alphabets of states, in-put symbols, and output symbols, respectively,?
F : S1 ?
R assigns final weights, and?
R is a finite set of rules la?
r where a ?
R,l ?
T?
(S(X)), and r ?
S(T?
(X)) such that?
every x ?
X that occurs in l occurs ex-actly once in r and vice versa, and?
l /?
S(X) or r /?
S(X).Roughly speaking, an MBOT is the bottom-upversion of an extended top-down tree transducer, inwhich the states can have a rank different from 1.
Wechose the symbol ???
because rules have a distin-guished left- and right-hand side.
The size |la?
r| of878SNPt1@Vt2NPt3?SNPt1Ut2 t3?U ?t2 @t1 t3?SSt2 @t1 t3Figure 3: Derivation using the MBOT rules of Fig.
2.a rule is |l|+ |r|, and the size |M | of an MBOTM is?r?R|r|.
Again the second condition on the ruleswill ensure that derivations will be finite.
Let uscontinue with the rewrite semantics for the MBOT(S,?,?, F,R).
To simplify the presentation, weagain assume that S ?
(?
?
?)
= ?.
We needthe concept of substitution.
Let ?
: X ?
T?
andt ?
T?(X).
Then t?
is the tree obtained by replac-ing every occurrence of x ?
X in t by ?
(x).Definition 2 Let c ?
C?
(S(X)) and ?
: X ?
T?.Then c[l?]a?
c[r?]
if la?
r ?
R. The weight of aderivation D : ?0a1?
?
?
?ak?
?k is wt(D) =?ki=1 ai.The weight assigned by the MBOT M to a pair(t, u) ?
T?
?
T?
isM(t, u) =?s?S1F (s) ?
?D left-most derivationfrom t to s(u)wt(D) .We use the simplifications already mentioned inthe previous section also for MBOTs.
Figures1 and 2 display example rules of an MBOT.
Therules of Figure 2 are applied in a derivation in Fig-ure 3.
The first displayed derivation step uses thecontext S(NP(t1),) and any substitution ?
suchthat ?
(x2) = t2 and ?
(x3) = t3.It is argued by Chiang (2005) and Graehl etal.
(2008) that STSGs (and extended tree trans-ducers) have sufficient power for syntax-based ma-chine translation.
Knight (2007) presents a detailedoverview that also mentions short-comings.
Sinceour newly proposed device, the MBOT, should beat least as powerful as STSGs, we quickly demon-strate how each STSG can be coded as an MBOT.An STSG production and the corresponding MBOTrule are displayed in Figure 1.
Since the correspon-dence is rather trivial, we omit a formal definition.Theorem 3 For every STSG M , an equivalentMBOT can be constructed in time O(|M |).4 BinarizationWhenever nondeterminism enters the playfield, bi-narization becomes an important tool for efficiencyreasons.
This is based on the simple, yet powerfulobservation that instead of making 5 choices from aspace of n in one instant (represented by n5 rules),it is more efficient (Wang et al, 2007) to make themone-by-one (represented by 5n rules).
Clearly, thiscannot always be done but positive examples exist inabundance; e.g., binarization of context-free gram-mars [see CHOMSKY normal form in Hopcroft andUllman (1979)].Binarization of tree language devices typicallyconsists of two steps: (i) binarization of the involvedtrees (using the auxiliary symbol @) and (ii) adjust-ment (binarization) of the processing device to workon (and fully utilize) the binarized trees.
If success-ful, then this leads to binarized derivation trees forthe processing device.
In Figure 4 we show the bi-narization of the trees in an STSG production.
An-other binarization of the rule of Figure 4 is displayedin Figure 1.
The binarization is evident enough, sowe can assume that all trees considered in the fol-lowing are binarized.The binarization in Figure 1 is unfortunate be-cause the obtained production cannot be factor-ized such that only two nonterminals occur in eachrule.
However, the binarization of Figure 4 allowsthe factorization into S(U ,NP) ?
S(U ,NP) andU : @(NP ,V )?
@(V ,NP), which are fully bina-rized productions.
However, in general, STSGs (orSCFGs or extended tree transducers) cannot be fullybinarized as shown in Aho and Ullman (1972).Zhang et al (2006) and Wang et al (2007) showthe benefits of fully binarized STSGs and present alinear-time algorithm for the binarization of binariz-able STSGs.
We show that those benefits can bereaped for all STSGs by a simple change of model.879SNP1 V NP2?SV NP1 NP2S@NP1 VNP2 ?S@V NP1NP2Figure 4: Binarization of trees in an STSG production.Top: Original ?
Bottom: Binarized trees.We have already demonstrated that every STSG canbe transformed into an equivalent MBOT in lineartime.
Next, we discuss binarization of MBOTs.An MBOT is in one-symbol normal form if thereis at most one input and at most one output symbol,but at least one symbol in each rule (see Figure 2).Raoult (1993) and Engelfriet et al (2009) prove thatevery MBOT can be transformed into one-symbolnormal form.
The procedure presented there runs inlinear time in the size of the input MBOT.
Conse-quently, we can transform each STSG to an equiv-alent MBOT in one-symbol normal form in lineartime.
Finally, we note that a MBOT in one-symbolnormal form has binarized derivation trees, whichproves that we fully binarized the STSG.Theorem 4 For every STSG M an equivalent, fullybinarized MBOT can be constructed in O(|M |).The construction of Engelfriet et al (2009) is il-lustrated in Figure 2, which shows the rules of anMBOT in one-symbol normal form.
Those rules areconstructed from the unlucky binarization of Fig-ure 1.
In the next section, we show the benefit of thefull binarization on the example of the BAR-HILLELconstruction.5 Input and output restrictionA standard construction for transformation devices(and recognition devices alike) is the regular restric-tion of the input or output language.
This con-struction is used in parsing, integration of a lan-guage model, and the computation of certain metrics[see Nederhof and Satta (2003), Nederhof and Satta(2008), and Satta (2010) for a detailed account].
Theconstruction is generally known as BAR-HILLELconstruction [see Bar-Hillel et al (1964) for theoriginal construction on context-free grammars].STSGs (and extended tree transducers) are sym-metric, so that input and output can freely beswapped.
Let M be an STSG and A a weightedstring automaton with states S. In the BAR-HILLELconstruction for M and A, the maximal rank rk(M)of a symbol in the derivation forest ofM enters as anexponent into the complexityO(|M | ?
|S|2 rk(M)+5).Since full binarization is not possible in general, themaximal rank cannot be limited to 2.
In contrast,full binarization is possible for MBOTs (with onlylinear overhead), so let us investigate whether wecan exploit this in a BAR-HILLEL construction forMBOTs.Let M = (S,?,?, F,R) be an MBOT in one-symbol normal form.
The symbols in ?
?
?
haverank at most 2.
Moreover, let G = (N,?,?, I, P )be a TSG in normal form.
We want to construct anMBOT M ?
such that M ?
(t, u) = M(t, u) ?G(t) forevery t ?
T?
and u ?
T?.
In other words, eachinput tree should be rescored according to G; in theunweighted case this yields that the translation ofMis filtered to the set of input trees accepted by G.We occasionally write the pair (a, b) in angledparentheses (???
and ???).
In addition, we use thecenter line ellipsis ??
??
(also with decoration) like avariable (especially for sequences).Definition 5 The input product Prod(M,G) is theMBOT Prod(M,G) = (S?N,?,?, F ?, R?)
where?
F ?
(?s, n?)
= F (s) ?
I(n) for every s ?
S andn ?
N ,?
for every rule s(?
?)a?
s?(?
??)
?
R withs, s?
?
S and every n ?
N , there exists a rule?s, n?(?
?)a?
?s?, n?(?
??)
?
R?
,?
for every rule ?(s1(?
?1), .
.
.
, sk(?
?k))a?
s(?
?
)in R with ?
?
?k and s, s1, .
.
.
, sk ?
S, andevery production nb?
?
(n1, .
.
.
, nk) ?
P , thefollowing rule is in R?:?
(?s1, n1?(?
?1), .
.
.
, ?sk, nk?(?
?k))ab?
?s, n?(?
?)
.The first type of rule (second item) does not in-volve an input symbol, and thus the nonterminalof G is just forwarded to the new state.
Since nostep with respect to G is made, only the weight ofthe rule of M is charged.
The second type of rule(third item) uses a rule of R with the input symbol ?880s1 s3s1 s2 s2 s3??s1,s3???(?s1,s2?,?s2,s3?
)s1 s2s1 s2??s1,s2???(?s1,s2?
)s1 ?
s2?
(s1, ?, s2)?s1,s2??(s1,?,s2)?
?Figure 5: Constructing a TSG from a weighted string au-tomaton.and a production of P that also contains ?.
The ruleand the production are executed in parallel in the re-sulting rule and its weight is thus the product of theweights of the original rule and production.
Over-all, this is a classical product construction, which issimilar to other product constructions such as Bor-chardt (2004).
A straightforward proof shows thatM ?
(t, u) = M(t, u) ?
G(t) for every t ?
T?
andu ?
T?, which proves the correctness.Next, let us look at the complexity.
The MBOTProd(M,G) can be obtained in time O(|M | ?
|G|).Furthermore, it is known [see, for example, Malettiand Satta (2009)] that for every weighted string au-tomaton A with states S, we can construct a TSG Gin normal form, which has size O(|?| ?
|S|3) andrecognizes each tree of T?
with the weight that theautomaton A assigns to its yield.
The idea of thisconstruction is illustrated in Figure 5.
Consequently,our BAR-HILLEL construction has the well-knowncomplexityO(|M | ?
|S|3).
This should be comparedto the complexity of the corresponding constructionfor an STSG M , which is in O(|M | ?
|S|2 rk(M)+5)where rk(M) is the maximal number of (different)nonterminals in a production of M .
Thus, the STSGshould be transformed into an equivalent MBOT inone-symbol normal form, which can be achievedin linear time, and the BAR-HILLEL constructionshould be performed on this MBOT.Since STSGs are symmetric, our approach canalso be applied to the output side of an STSG.However, it should be noted that we can apply itonly to one side (the input side) of the MBOT.
Aconstruction for the output side of the MBOT canbe defined, but it would suffer from a similarlyhigh complexity as already presented for STSGs.More precisely, we expect a complexity of roughlyO(|M | ?
|S|2 rk(M)+2) for this construction.
Thesmall gain is due to the one-symbol normal form andbinarization.6 CompositionAnother standard construction for transformations is(relational) composition.
Composition constructs atranslation from a language L to L??
given transla-tions from L to L?
and from L?
to L??.
Formally,given transformations M ?
: T?
?
T?
?
R andM ??
: T??T?
?
R, the composition ofM ?
andM ?
?is a tranformation M ?
;M ??
: T?
?
T?
?
R with(M ?
;M ??
)(t, v) =?u?T?M ?
(t, u) ?M ??
(u, v)for every t ?
T?
and v ?
T?.
Mind that the sum-mation might be infinite, but we will only considercompositions, in which it is finite.Unfortunately, Arnold and Dauchet (1982) showthat the composition of two transformations com-puted by STSGs cannot necessarily be computed byan STSG.
Consequently, there cannot be a generalcomposition algorithm for STSGs.Let us consider the problem of composition forMBOTs.
Essentially, we will follow the unweightedapproach of Engelfriet et al (2009) to obtain a com-position construction, which we present next.
LetM ?
= (S?,?,?, F ?, R?)
andM ??
= (S?
?,?,?, F ?
?, R??
)be MBOTs in one-symbol normal form.
We ex-tend the rewrite semantics (see Definition 2) totrees that include symbols foreign to a MBOT.
Inother words, we (virtually) extend the input andoutput alphabets to contain all used symbols (inparticular also the states of another MBOT).
How-ever, since we do not extend the set of rules, theMBOT cannot process foreign symbols.
Neverthe-less it can perform rewrite steps on known sym-bols (or apply rules that do not contain input sym-bols).
We use ?R?
and ?R??
for derivation steps881s?s?
?1t1 ?
?
?
tm?
?
?
s?
?ku1 ?
?
?
un?=s??s?
?1, .
.
.
, s?
?k?t1 ?
?
?
tm ?
?
?
u1 ?
?
?
unFigure 6: Identification in sentential forms.that exclusively use rules ofR?
andR?
?, respectively.In addition, we identify s?(s??1(?
?1), .
.
.
, s??k(?
?k))with s??s?
?1, .
.
.
, s??k?(?
?1, .
.
.
, ?
?k) for s?
?
S?
ands?
?1, .
.
.
, s?
?k ?
S??.
This identification is illustratedin Figure 6.Definition 6 The MBOT M ?
;M ??
= (S,?,?, F,R)is such that?
for every s?
?
S?k and s?
?1 ?
S?
?`1 , .
.
.
, s?
?k ?
S?
?`kwe have s??s?
?1, .
.
.
, s??k?
?
S`1+??
?+`k ,?
F (s??s??)
= F ?(s?)
?
F ??(s??)
for every s?
?
S?1and s??
?
S?
?1 , and?
the rules la?
r of R, all of which are such thatthe variables in l occur in order (x1, .
.
.
, xk)from left-to-right, are constructed in 3 ways:?
l a?R?
r by a single rule of R?,?
l a?R??
r by a single rule of R?
?, or?
la1?R?
?a2?R??
r with a = a1 ?
a2 andthe applied rule of R?
contains an outputsymbol.If a rule la?
r can be constructed in severalways (with exactly weight a), then the weightsof all possibilities are added for the weight ofthe new rule.Intuitively, a single rule ofR?
without output sym-bols is used in the first type (because otherwiser would have the wrong shape).
In the second type, asingle rule of R??
without input symbols is used.
Fi-nally, in the third type, first a rule ofR?
that producesan output symbol of ?
is used and then this symbolis processed by a single rule of R??.
Note that everyrule of R?
can produce at most one output symboland the rules of R??
either process none or one inputsymbol due to the assumption that M ?
and M ??
arein one-symbol normal form.
We illustrate a rule ofthe first in Figure 7.original rule:?q1x1 x2q2x3a?qx3 x1 x2constructed rule:?q1p1x1 x2p2x3q2p3x4 x5a?qp3x4 x5p1x1 x2p2x3Figure 7: Example of a constructed rule of type 1.The correctness proof of this construction can es-sentially (i.e., for the unweighted case) be found inEngelfriet et al (2009).
Before we can extend it tothe weighted case, we need to make sure that thesum in the definition of composition is finite.
Weachieve this by requiring that?
for every t ?
T?
and s ?
S?1 there are finitelymany u ?
T?
such that ta1?
?
?
?an?
s(u), or?
for every v ?
T?
and s ?
S?
?1 there are finitelymany u ?
T?
such that ua1?
?
?
?an?
s(v).In other words,M ?
may not have cyclic input ?-rulesor M ??
may not have cyclic output ?-rules.
Now wecan state the main theorem.Theorem 7 For all MBOTs M ?
and M ??
with theabove restriction the composition M ?
; M ??
of theirtransformations can be computed by another MBOT.This again shows an advantage of MBOTs.
Thecomposition result relies essentially on the one-symbol normal form (or full binarization), whichcan always be achieved for MBOTs, but cannot forSTSGs.
Consequently, MBOTs can be composed,whereas STSGs cannot be composed in general.
In-deed, STSGs in one-symbol normal form, which canbe defined as for MBOTs, can be composed as well,which shows that the one-symbol normal form is thekey for composition.Finally, let us discuss the complexity of compo-sition.
Let rk(M ?)
be the maximal rank of a statein S?.
Then there are?
O(|M ?| ?
|S??|rk(M?))
rules of type 1,?
O(|M ?
?| ?
|S??|rk(M?))
rules of type 2, and882?
O(|M ?| ?
|M ?
?| ?
|S??|rk(M?))
rules of type 3.Each rule can be constructed in linear time in the sizeof the participating rules, so that we obtain a finalcomplexity ofO(|M ?| ?
|M ?
?| ?
|S??|rk(M?)).
Note thatifM ?
is obtained from an STSGM (via Theorem 4),then rk(M ?)
?
rk(M).
This shows that binarizationdoes not avoid the exponent for composition, but atleast enables composition in the general case.
More-over, the complexity could be slightly improved bythe observation that our construction only relies on(i)M ?
having at most one output symbol per rule and(ii) M ??
having at most one input symbol per rule.7 Forward and backward applicationWe might want to apply a transformation not just toa single tree, but rather to a set of trees, which are,in some cases, already weighted.
In general, the setof trees is given by a TSG G and we expect the re-sult to be represented by a TSG as well.
Forwardand backward application amount to computing theimage and pre-image of G under the transformation,respectively.
Since STSG are symmetric, we need tosolve only one of the problems if the transformationis given by an STSG.
The other problem can then besolved by inverting the STSG (exchanging input andoutput) and using the method for the solved prob-lem.
We chose to address forward application here.Forward application can be reduced to the prob-lem of computing the co-domain (or range) with thehelp of a product construction for STSG, which issimilar to the one presented in Definition 5.
The co-domain codM of the tranformation computed by anSTSG M assigns to each t ?
T?
the weightcodM (t) =?u?T?M(t, u) .This sum might not be well-defined.
However, ifu /?
N for all productions n : ta?
u of the STSG,then the sum is well-defined and the output-sideTSG (i.e., for every production n : ta?
u in theSTSG there is a production na?
u in the TSG)computes the co-domain.
The restriction ?u /?
N?guarantees that the output side is a TSG.
Overall, do-main, co-domain, and forward and backward appli-cations (using the product construction) can be com-puted given such minor new requirements.Also for transformations computed by MBOTswe can reduce the problem of forward applica-tion to the problem of computing the co-domainwith the help of the product construction of Defi-nition 5.
However, the co-domain of an MBOT isnot necessarily representable by a TSG, which isnot due to well-definedness problems but rather thefinite-copying property (Engelfriet et al, 1980) ofMBOTs.
This property yields that the co-domainmight not be a regular tree language (or context-freestring language).
Consequently, we cannot com-pute forward or backward applications for arbitraryMBOT.
However, if the MBOT is equivalent to anSTSG (for example, because it was constructed bythe method presented before Theorem 3), then for-ward and backward application can be computed es-sentially as for STSG.
This can be understood asa warning.
MBOT can efficiently be used (withcomputational benefits) as an alternative represen-tation for transformations computed by STSG (orcompositions of STSG).
However, MBOT can alsocompute transformations, of which the domain orrange cannot be represented by a TSG.
Thus, if wetrain MBOT directly and utilize their full expressivepower, then we might not be able to perform forwardand backward application.In the unweighted case, backward application canalways be computed for MBOT.
Moreover, it can bedecided using (E?sik, 1984) whether all forward ap-plications can be represented by TSGs.
However, fora given specific TSG, it cannot be decided whetherthe forward application is representable by a TSG,which was proved by Fu?lo?p (1994).
A subclassof transformations computable by MBOT (that stillcontains all transformations computable by STSG),which allows all forward and backward applications,has been identified by Raoult (1993).Conclusion and acknowledgementWe compared STSGs and MBOTs on several stan-dard algorithms (binarization, regular restriction,composition, and application).
We prove thatMBOTs offer computational benefits on all men-tioned algorithms as long as the original transforma-tion is computable by an STSG.The author was financially supported by the Min-isterio de Educacio?n y Ciencia (MEC) grants JDCI-2007-760 and MTM-2007-63422.883ReferencesAlfred V. Aho and Jeffrey D. Ullman.
1972.
The Theoryof Parsing, Translation, and Compiling.
Prentice Hall.Andre?
Arnold and Max Dauchet.
1982.
Morphismeset bimorphismes d?arbres.
Theoret.
Comput.
Sci.,20(1):33?93.Y.
Bar-Hillel, M. Perles, and E. Shamir.
1964.
On for-mal properties of simple phrase structure grammars.In Language and Information: Selected Essays ontheir Theory and Application, pages 116?150.
Addi-son Wesley.Jean Berstel and Christophe Reutenauer.
1982.
Recog-nizable formal power series on trees.
Theoret.
Com-put.
Sci., 18(2):115?148.Bjo?rn Borchardt.
2004.
A pumping lemma and decid-ability problems for recognizable tree series.
Acta Cy-bernet., 16(4):509?544.Peter F. Brown, John Cocke, Stephen A. Della Pietra,Vincent J. Della Pietra, Fredrick Jelinek, John D. Laf-ferty, Robert L. Mercer, and Paul S. Roossin.
1990.
Astatistical approach to machine translation.
Computa-tional Linguistics, 16(2):79?85.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
Mathematics ofstatistical machine translation: Parameter estimation.Computational Linguistics, 19(2):263?311.David Chiang and Kevin Knight.
2006.
An introductionto synchronous grammars.
In Proc.
ACL tutorial.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proc.
ACL, pages263?270.John DeNero, Mohit Bansal, Adam Pauls, and Dan Klein.2009a.
Efficient parsing for transducer grammars.
InProc.
NAACL, pages 227?235.John DeNero, Adam Pauls, and Dan Klein.
2009b.Asynchronous binarization for synchronous gram-mars.
In Proc.
ACL, pages 141?144.Samuel Eilenberg.
1974.
Automata, Languages, andMachines.
Academic Press.Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki.1980.
Tree transducers, L systems, and two-way ma-chines.
J. Comput.
System Sci., 20(2):150?202.Joost Engelfriet, Eric Lilin, and Andreas Maletti.
2009.Extended multi bottom-up tree transducers: Composi-tion and decomposition.
Acta Inform., 46(8):561?590.Zolta?n E?sik.
1984.
Decidability results concerning treetransducers II.
Acta Cybernet., 6(3):303?314.Zolta?n Fu?lo?p and Heiko Vogler.
2009.
Weighted tree au-tomata and tree transducers.
In Handbook of WeightedAutomata, chapter IX, pages 313?403.
Springer.Zolta?n Fu?lo?p.
1994.
Undecidable properties of determin-istic top-down tree transducers.
Theoret.
Comput.
Sci.,134(2):311?328.Jonathan S. Golan.
1999.
Semirings and their Applica-tions.
Kluwer Academic, Dordrecht.Jonathan Graehl, Kevin Knight, and Jonathan May.
2008.Training tree transducers.
Computational Linguistics,34(3):391?427.John E. Hopcroft and Jeffrey D. Ullman.
1979.
Intro-duction to Automata Theory, Languages and Compu-tation.
Addison Wesley.Liang Huang, Hao Zhang, Daniel Gildea, and KevinKnight.
2009.
Binarization of synchronouscontext-free grammars.
Computational Linguistics,35(4):559?595.Kevin Knight.
2007.
Capturing practical natu-ral language transformations.
Machine Translation,21(2):121?133.Eric Lilin.
1981.
Proprie?te?s de clo?ture d?une extensionde transducteurs d?arbres de?terministes.
In CAAP, vol-ume 112 of LNCS, pages 280?289.
Springer.Andreas Maletti and Giorgio Satta.
2009.
Parsing algo-rithms based on tree automata.
In Proc.
IWPT, pages1?12.Andreas Maletti, Jonathan Graehl, Mark Hopkins, andKevin Knight.
2009.
The power of extended top-downtree transducers.
SIAM J.
Comput., 39(2):410?430.Mehryar Mohri.
2009.
Weighted automata algorithms.In Handbook of Weighted Automata, pages 213?254.Springer.Mark-Jan Nederhof and Giorgio Satta.
2003.
Probabilis-tic parsing as intersection.
In Proc.
IWPT, pages 137?148.Mark-Jan Nederhof and Giorgio Satta.
2008.
Compu-tation of distances for regular and context-free prob-abilistic languages.
Theoret.
Comput.
Sci., 395(2?3):235?254.Jean-Claude Raoult.
1993.
Recursively defined treetransductions.
In Proc.
RTA, volume 690 of LNCS,pages 343?357.
Springer.Jacques Sakarovitch.
2009.
Rational and recognisablepower series.
In Handbook of Weighted Automata,chapter IV, pages 105?174.
Springer.Giorgio Satta.
2010.
Translation algorithms by means oflanguage intersection.
Manuscript.Marcel Paul Schu?tzenberger.
1961.
On the definition ofa family of automata.
Information and Control, 4(2?3):245?270.Wei Wang, Kevin Knight, and Daniel Marcu.
2007.
Bi-narizing syntax trees to improve syntax-based machinetranslation accuracy.
In Proc.
EMNLP-CoNLL, pages746?754.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous binarization for machinetranslation.
In Proc.
NAACL-HLT, pages 256?263.884
