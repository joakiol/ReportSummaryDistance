A Machine Translation Systemfor Foreign News in Satellite BroadcastingTeruaki Aizawa, Terumasa Ehara**, Noriyoshi Uratani, Hideki Tanaka,Naoto Kato, Sumio Nakase*, Norikazu Aruga*, and Takeo Matsuda*NHK Science and TechnicalResearch Laberatofies1-10-11, Kinuta, Setagaya-ku,Tokyo 157, Japan**Current Address: ATR InterpretingTelephony Research Laboratories*Catena-ResourceLaboratories Inc.Ichibancho-27 Bldg.27, Ichibancho, Chiyoda-ku,Tokyo 102, JapanA machine translation system of English to Japanese is described, which has been used in 24-hour direct satellite broadcasting byNHK to translate "World News.
"In order to treat a wide scope of news sentences, the system is provided with more than I00,000lexical entries as well as about 3,000 grammatical rules which can robustly analyze various types ofundefined words.
It is also effective in translation of news sentences topreprocess proper nouns, toresolve structural mbiguities by weighting rammatical rules, and to select appropriate words usingsemantic markers.
The operational experiments on machine translation i satellite broadcasting arebriefly discusse~1 IntroductionSince December 1986, NHK, the Japan BroadcastingCorporation, has been conducting two-channel, directsatellite broadcasting using Japan's BS-2b broadcastingsatellite.
The two satellite channels now have 24-hournationwide TV broadcasting services.
The core of theservices on Channel I is "World News," in which newsfrom across the globe is broadcast.The languages poken in NHK's World News areEnglish, French, German, Italian, Russian, Korean, andChinese.
Urgent and important news has simultaneousinterpretation services.
In usual cases, however, ser-vices only superimpose Japanese subtitles on the TVscreen.
Actually, more than 50 bilingual translatorsprepare amanuscript by transcribing and translating theoriginal news.
All the work must be done in a limitedtime, even at midnight due to the time difference be-tween Japan and other countries.A machine translation system was introduced tomake easier this daily work.
As a first step, the EnglishWorld News has been experimentarily broadcast, about 5minutes a day, using the Japanese translation providedby the MT system.
We think this is cultivating a newpossibility of machine translation i Japan \[1\].2 Satellite Broadcasting and MachineTranslationUsually the generation of the subtitles proceeds asfollows:1) a bilingual translator prepares a manuscript bytranscribing and translating the original news;2) a supervisor examines the manuscript; and3) an operator inputs the final manuscript into theprocessing equipment.Our MT system was introduced in step 1, First ofall, the original news is greatly summarized in Englishsince the length of a subtitle script is at most 30Japanese characters per a display screen.
Preediting isalso carried out in this step to provide a better input forthe MT system.
After postediting, the final result isgiven to step 2.The system is based on the STAR machine transla-tion system \[2\], and works basically by a transfermethod.
The translation process can be divided into 4main steps: morphological nalysis, syntactic analysis,transfer, and generation.
The morphological nalysisidentifies words as well as locally fixed sequences ofwords.
In the syntactic analysis, all the possible surfacestructures for an input sentence are derived, and then thebest candidates are chosen by using the "weight mecha-nism" described below.At present, the size of the dictionary is about100,000 entries, and the grammar has about 3,000CFG-type rules.
The system can translate a sentencehaving 11 words on average within 2 seconds using a 3MIPS UNIX computer.
Further characteristics of thesystem are discussed below.3 Characteristics of the MachineTranslation System for News Sentences3.1 Characteristics of News SentencesExamining alarge body of English news consistingof more than 3.5 million words from the World Newsand the basic news service of AP (Associated Press),wecan summarize the linguistic properties of Ihe news sen-tences as follows:I) About 75,000 different words are used, and they aredifficult o classify by news fields.3o8 12) Various types of proper nouns such as human, nationand location names appear frequently.
Human namesare often with related words like titles.3) Many verbs having human subjects are used.Among others, "say," "call," "report," "talk," "ask,""think," "want," and "feel" ate often found.4) Many kinds of numeral expressions come out.
Someof them are too complex to translate.51) Colloquial expressions appear frequently.3~2 Local Preprocessor  for Proper  NounsIn order to treat the above-mentioned characteristics1) and 2) of the news sentences, our MT system has apreprocess called "Local Context Translation"(LOC~I),which constitutes the second part of the morphologicalanalysis.
Its main role is to identify and translate vari-ou.~ types of locally fixed ~quences of words such as"U.S. President George Bush,""July 14th, 1789,""The Metropolitan Museum of Art, New York," etc.Rules for hu_.m_m'4~ names with the tille of thepositionhuman --> khnlnan namekhuman --> (FORMER) rankrank --> STATE PRESIDENT-~> CttINESE PRESIDENT;\[=>" I*-1 ;* ~rN"\]--> party PRESIDENT; \ [=>"~ "\]--> finn PRESIDENT;\[=>"~?5~"\]FORMER --> former,acting,etc.S~A'f E --> U.S.,French,and etc;nation n,'wnes except "Chinese"CHINESE --> Chineseparty --> ...;party namesfinn --> ...;company namesRules for defiff~tlg the hum~t~.a~iIl~,name --> HNAME;for defined words--> (R_NAME)+;for undefined wordsHNAME --> ...;names defined in the lexiconRNAME --> \[A-Z\]\[a-z\]+;names defined from the inputFigure 1 Ru les  for the Loca l  ContextTrans la t ion .The LOCT can perform translation of human nameswith related words like titles, identification of undefinedproper nouns, and selection of words.
To analyze localpatterns, the LOCT has a set of CFG-rules, differentfrom the global analysis rules, as shown in Figure 1.By these rules, "President" can be translated if-ferently into Japanese depending on the previous word,R NAME picks up an undefined proper noun from theinput text as a sequence of one capital letter and somesmall letters.3.3 Robust  P rocess ing  of  Undef ined  WordsIn addition to a large dictionary, our system has apowerful processor tor undefined words to cover a widescope of news sentences.
The processor estimates thelexical items of undefined words, and gives them to thesyntactic analyzer.The main processing functions are:1) ~ t ~ ~ :  As explainedin 3.2, the LOCT can estimate the grammaticalvalues for undefined words by identifying localpatterns.2) E~ i n h n in ,  form o f ~ :  ManyEnglish words have their own ending formscorresponding to grammatical values.
For exmnple,a word ending with "4ion(s)," "-ly," or "+able" canbe.
estimated as a noun, an adverb, or an adjective,respectively.3) ~ :  The processor has some heuristic rulesfor a word starting with a capital etter, a short word,a sequence of numeral digits.3.4 S t ructura l  D isambignat ion  byWeight ing  Grammat ica l  RulesThe syntactic ,analysis consists of two steps.1) All the possible surface structures for an inputsentence are derived as an AND/OR graph \[3\].2) The best candidates are extracted from this graphusing our "weight mechanism," which can beformulated as a ~arch problem for an AND/ORgraph having nodes with costs.I25@;@' "3v@ 26.5,;Q.
....
;?
(Ite) is teachhag the girl t~glish grammar.
: 9 VP --> (+2 aux) vtl NP: 5 VP --> (+2 aux) vt2 1.5 : NP NP: 2 NP --> (art) (+1 nou) * nouF igure 2 AND/OR graph for a VPFigure 2 gives an AND/OR graph for a verb phrase:"(lie) is teaching the girl English grammar."
where2 309italicized numerals how the weights of words given bythe lexicon.
The weight of the other node is calculatedfrom those of the daughter nodes and the correspondingrule.
For example, the weight of VP3-node is calcu-lated by using the second rule in Figure 2 as follows:2(aux)+3(vt2)+ 1.5*7(NP2)+4(NPS)+5+ 2= 26.5Among three VP candidates in this example, VP2 ischosen as the best one, since it has the smallest weight.The weight represents some kind of"incomprchensibility," "complexity," or" rareness" of aword, a phrase, or a sentence.
All the words and rules inour system have been assigned their own weights.
Ourexperiments on machine translation i  satellite broad-casting show that the best candidates arc chosen forabout 78% of the successfully analyzed World Newssentences.3.5 Word Selection by Semantic MarkersSemantic markers are employed for Japanese wordselection.
Their effectiveness has been shown particu-larly in the areas mentioned below.1) Selection of a Japanese translation of"they"The word "they" quite often appears in news sen-tences.
It has two major Japanese translafions:"karera"and "sorera" which refer to objects with will and objectswithout will, respectively.
The confusion between thetwo intolerably degrades Japanese translation.A simple strategy that uses semantic markers andverb characteristics can make a proper selection in manycases without pronoun analysis.
As mentioned in 3.1,verbs having human subjects are frequently utilized innews sentences.
Meanwhile, verbs like "melt" take sub-ject nouns that have no will.
If "karera" has a marker\[HIWILL\] (objects with high will) and "sorera" hasnothing, translation control of "they" is realized byspecifying the subject of a verb as \[HIWILL\] or noth-ing.2) Basic verb's translation word selectionVerbs frequently used in news sentences are basic andthus have various meanings.
To select a properJapanese translation of a basic verb, we have set somespecial markers for news sentences.
One of them is\[CRIMINAL\] which is utilized to obtain a special trmas-lation of "catch."
Consider the sentence:"The police caught he assailant, who has a historyof mental illness.
"The word "catch" was successfully translated as"taiho-suru (arres0," since "assailant" has the marker\[CRIMINAL\] and the translation description of "catch"defined its lapanese as "taiho-suru" when it took an ob-ject noun that belongs to \[CRIMINAL\].4 Results,  Considerations, and ProblemsThe following resuhs were obtained for 1,393 WorldNews sentences which were input to our MT systemduring the three months of our trials.On a strict judgment, he number of successfuUy an-alyzed sentences was 898 (64.5%), of which 698 sen-tences (78%) were properly translated as first candidatesby our weight mechanism.
As far as these sentenceswere concerned, the mechanism was very effective.About 30% of the failure in analysis was due to errorsin the input sentences such as misspelling or grammarmistakes.
Colloquial expressions were alto difficult toanalyze.Examole of translation"Mrs. Nishi, with the help of a lawyer, is tryingto collect workman's compensation for her hus-band's death.
"~ >" - - J~c) -~z~09~J J~ J7~7o Nishi :5I~.A.~ ?,5 Concluding RemarksWe described a practical machine translation systemof English to Japanese which has been utilized in satel-lite broadcasting by NHK to translate the World News.Toward the second stage of application to broadcast-ing from April 1990, we are now trying to improve oursystem specifically in treatments ofnumeral expressionsand colloquial expressions which have not yet been fullyconsidered though they are major characteristics of newssentences.We also started a design of a French-Japanese ma-chine translation system based on a similar structure toour present English-Japanese ystem.References\[1\] M. Nagao et al: A Japanese view of machine trans-lation in light of the considerations andrecommendations reported by ALPAC, U.S.A.,Machine Translation System Research Commitee,JEIDA (1989).\[2\] S. Nakase: On syntactic analysis technique inEnglish-Japanese machine translation, SIGNLMeeting of IPSJ, 69-7 (1988).\[3\] A. Martelli and U. Montanari: Optimizing decisiontrees through euristically guided search, CACM,21(12), 1025-1039 (1978).3103
