Coling 2008: Companion volume ?
Posters and Demonstrations, pages 79?82Manchester, August 2008Generation under Space ConstraintsC?cile Paris, Nathalie Colineau,Andrew LampertCSIRO ?
ICT CentreLocked Bag 17North Ryde, NSW 1670, AustraliaFirstName.LastName@csiro.auJoan Giralt DuranBarcelona School of InformaticsTechnical University of CataloniaBarcelona, Spainjoangi@gmail.comAbstractReasoning about how much to generatewhen space is limited is a challenge forgeneration systems.
This paper presentstwo algorithms that exploit the discoursestructure to decide which content to dropwhen there are space restrictions, in thecontext of producing documents frompre-authored text fragments.
We analysethe effectiveness of both algorithms andshow that the second is near optimal.1 IntroductionMany organisations employ content managementsystems to store information, typically at theparagraph level.
The use of such systems enablesthe application of NLG techniques without thecost of acquiring a knowledge base or formingtext from first principles.
But it brings its ownchallenge: how to produce a coherent and wellstructured text satisfying specific spacerequirements when a system has no control overthe text at the sentence level?The ability to reason about space constraintsbecomes more pressing as the amount ofavailable information increases and deliverychannels become more diverse in terms of spacerequirements (e.g., web browsers, email, PDAs).We, as humans, address this problem by short-ening our sentences or restricting the content weinclude.
We achieve the former by manipulatingvocabulary and syntax.
This requires careful at-tention to the text at sentence level and oftendoes not reclaim significant amount of space.?
CSIRO 2008.
Licensed under the Creative Com-mons Attribution-Noncommercial-Share Alike 3.0Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.We achieve the latter by dropping those pieces ofcontent whose contribution to the communicativegoal is most limited.
This approach can reduce atext?s length significantly but requires anunderstanding of the text?s discourse structure.In our application domain, we answer people?sinformation needs by retrieving content from arepository of pre-authored text fragments anddelivering that content via a variety of media(e.g., web, paper, email), each with their ownspace constraints.
In this paper, we show how weexploit the discourse structure to determine whatshould be realised to best fit some specific space.In particular, we present two algorithms that per-form this reasoning and analyse their compara-tive performance.2 Related WorkNLG systems have exploited the discourse struc-ture for a number of tasks ?
e.g., to generate ap-propriate cue phrases (e.g., Scott and de Souza,1990) or reason about layout (e.g., Bateman etal., 2001).
Our system uses the discoursestructure to reason about how much to realise tofit a specific space.
It produces one discourse treethat is then realised for different delivery chan-nels, each with its own space requirements.Like other systems (e.g., Moore and Paris,1993), our system specifies the RST relations(Mann and Thompson, 1988) that hold betweentext spans during discourse planning.
It then ex-ploits the RST principle of nuclearity to decidewhat to realise.
The intuition is that nuclei areimportant while satellites can be dropped.
Thisintuition has been exploited in some systems toproduce summaries (e.g., Sparck-Jones, 1993;Marcu, 1998).
Our purpose is different, however.We do not aim to produce a summary but a textthat fits into some space requirements,79Figure 1.
A brochure generated by our systempotentially only slightly shortening a text.
Ourtask brings new challenges, e.g., filling the spaceoptimally and producing a balanced text.Our system exploits the notion that some rela-tions are more important than others.
O?Donnell(1997) used this principle to produce documentsof variable length.
In his approach, sentencefragments were manually marked up with RSTand the text was manipulated at or below the sen-tence level.
In our work, we cannot manipulatetext at sentence level nor manually mark up thedocuments to be shortened.3 Reasoning about Space ConstraintsWe focus on applications in which the generatedtext is delivered through several channels.
Onesuch application is SciFly, which producestailored brochures about our organisation.
Givena query from a user (topic(s) of interest), thesystem consults a staff directory and a repositoryof text fragments to gather relevant information.The fragments, written by our marketing team,are self contained and comprised of one or twoparagraphs.
SciFly integrates all the relevantinformation into a coherent whole (see Figure 1)using the meta-data describing each fragment?scontent.
A text fragment can be used with differ-ent rhetorical relations in different brochures.The system produces a 2-page paper brochure, aweb output, and a PDF version of the paper bro-chure is emailed to the user with a summary inthe email body.
All outputs are generated fromthe same discourse structure by our algorithm.Our need to deliver the brochure via multiplechannels led us to design algorithms that reasonabout the content to be expressed and the spaceavailable for each channel.
The system follows atwo-stage approach: during discourse planning,content and organisation are selected, and a dis-course tree is built.
The tree includes the toplevel communicative goal, intermediate goalsand the rhetorical relations that exist betweentext spans, encoding both the purpose of eachfragment and how they relate to each other.
Then,at the presentation stage, the system reasonsabout this structure  to decide what to realisewhen there is too much content for some channel.We implemented and tested two algorithmsfor this reasoning.
Both algorithms embody theprinciple of nuclearity and exploit the notion thatsome relations are more important than others.An importance value is assigned to relationsbased on their contribution to the communicativegoal.
Table 1 shows our assignments, which arebased on judgments from our marketing staff.To explain the algorithms, we represent thediscourse tree using an abstract view, as shownin Figure 2.
Each node is a communicative goal.White nodes indicate nuclei.
Satellites are shadedin grey corresponding to the importance of therhetorical relation linking them to the nucleus.The number inside each node is the approximateamount of content that node produces (in lines).80Shading Discourse Relations ImportanceBlack Illustration, Background,Circumstance, ElaborationLowLow-MediumDarkGreyContext, Motivation,Evidence, Summary ,Justification,MediumLightGreyPreparation, Enablement Medium-HighHighTable 1.
Importance score for some relations1Each node is the root of a subtree (empty if thenode is a leaf) which generates some content.
Inboth algorithms, the system computes for eachnode an approximation of the space required forthat content in number of lines (an approximationas it depends on style, line-wrapping and otherformatting attributes in the final output).
This iscomputed bottom-up in an iterative manner bylooking at the retrieved content at each node.Figure 2.
Discourse tree with space annotations3.1 Simple AlgorithmThe first algorithm is simple.
It checks whetherthe top level node would result in too muchcontent given the space requirements of theoutput channel (e.g., lines of content per page).
Ifyes, the system traverses the tree, selects satel-lites with the lowest importance value and dropsthem with their sub-trees.
The algorithm repeatsthis process until the total amount of content fitsthe required space.
We deployed the SciFlysystem with this algorithm at a trade fair in 2005and 2006 and measured the experience visitorshad with the system.
On average, people ratedthe system positively but noted that there wassometimes a lot of blank space in the brochures,when they felt that more information could havebeen included.
This is because our simplealgorithm drops many sub-trees at once, thuspotentially deleting a lot of content in each step.This led us to our enhanced algorithm.1 In our system, we consider 5 levels of importance.
Wehave merged levels here to avoid too many shades of grey.3.2 Enhanced AlgorithmWe redesigned the algorithm to take into accountthe depth of a node in addition to its rhetoricalstatus.
We assign each node a weight, computedby adding the weight of the node?s parent and thepenalty score of the rhetorical relation, which is(inversely) related to its importance score.
Pen-alty scores range from 1 to 6, in increments of 1:A nucleus has a score of 1 to take the tree depthinto account, high importance relations have ascore of 2, and low importance relations have ascore of 6.
In a discourse tree, a child node isalways heavier than its parent.
The larger theweight, the less important the node is to theoverall comunicative goal.
The system orders thenodes by their weight, and the heaviest nodes aredropped first.
Thus, nodes deeper in the tree andlinked by discourse relations with lowerimportance get removed first.
Nodes are droppedone by one, until the top level node has anamount of content that satisfies the spaceconstraint.
This provides finer control over theamount of realised content and avoids thelimitation of the first algorithm.Figure 3.
Ordered list of (satellite) cluster nodesSometimes, a discourse structure containsparallel sub-structures (e.g., bulletted points)that, if pruned unevenly, result in unbalanced textthat seems odd.
In such cases, the discoursestructure typically contains several sub-trees withthe same structure.
In SciFly, such parallelstructures occur when describing a list ofprojects.
These are generated during discourseplanning by a plan containing a foreachstatement, e.g., (foreach project in project-list(describe project)).
To address this situation, thesystem annotates all sub-structures issued fromsuch a foreach statement.
When constructing theordered list of satellites, nodes at the same depthin the sub-structures are clustered together, asshown in Figure 3, taking into account theirrelationship to the nucleus.
When dropping81nodes, the whole cluster is deleted toegether,rather than node by node.
So, in Figure 3, thewhole cluster of weight 10 is dropped first, thenthe cluster of weight 8, etc.
This prevents onesub-structure from being pruned more than itssibling structures and ensures the resultingbrochure is balanced.4 EvaluationWe evaluated the algorithms to assess theircomparative effectiveness, based on a test set of1507 automatically generated brochures aboutrandomly selected topics.
We observed that82.5% of the brochures generated with theenhanced algorithm filled over 96% of theavailable space (leaving at most 8 lines of emptyspace), compared to 29% of brochures generatedwith the simple algorithm.
In addition, 96.5% ofthe brochures generated with the new algorithmfilled at least 90% of the space, compared with44.5% of brochures with the simple algorithm.We also found that 75% of brochures includedmore content using the enhanced algorithm (anaverage of 32 additional lines), but 12% of thebrochures contained less content.
We examinedthe latter in detail and found that, for these cases,the difference was on average 4 lines, and thatthe reduction was due to our treatment of paralleldiscourse structures, thus representing a desirableloss of content to create balanced brochures.We also performed a user evaluation to verifythat the improvement in space usage had not de-creased users?
satisfaction.
We asked users tocompare pairs of brochures (simple algorithm vs.enhanced algorithm), indicating their preferenceif any.
Seventeen users participated in theevaluation and were presented with seven pairsof brochures.
To control any order effect, thepairs were randomly presented from user to user,and, in each pair, each brochure was randomlyassigned a left-right configuration.
Participantsmostly preferred the brochures from the en-hanced algorithm, or found the brochures equiva-lent, thus showing that our more effective use ofspace had not decreased users?
satisfaction.Overall, our results show that our enhancedalgorithm is close to optimal in terms ofconveying a message appropriately while fillingup the space and producing a coherent andbalanced text.5 ConclusionsReasoning about how much to generate whenspace is limited presents an important challengefor generation systems.
Most systems eithercontrol their generation process to avoidproducing large amounts of text at the onset, orcontrol the generation at the sentence level.
Inour application, we cannot resort to any of theseapproaches as we generate text reusing existingtext fragments and need to produce one discoursetree with all the appropriate available content andthen select what to realise to output on severaldelivery channels.
To satisfy space constraints,we implemented and tested two algorithms thatembody the notions of nuclearity and importanceof information to decide which content to keepand which to withhold.
Our approach producesdocuments that fill most of the available spacewhile maintaining users?
satisfaction.AcknowledgementsWe thank M. Raji for her work on the user ex-periment, the members of our group and K.Vander Linden for their input, and everyone whoparticipated in our evaluation.ReferencesJohn Bateman, T. Kamps, K. K. Reichenberger, K.and J. Kleinz.
2001.
Constructive text, diagram andlayout generation for information presentation: theDArt_bio system.
Computational Linguistics, 27(3): 409?449.William C. Mann and Sandra A. Thompson.
1988.Rhetorical Structure Theory: Toward a functionaltheory of text organisation.
Text 8(3):243?281.Daniel Marcu.
1998.
To build text summaries of highquality, nuclearity is not sufficient.
In WorkingNotes of the AAAI-98 Spring Symposium on Intelli-gent Text Summarization, Stanford, CA, 1?8.Johanna D. Moore and C?cile L. Paris.
1993.
PlanningText for Advisory Dialogues: Capturing Intentionaland Rhetorical Information.
ComputationalLinguistics, 19 (4):651?694, Cambridge, MA.Donia R. Scott and Clarisse S. de Souza.
1990.Getting the message across in RST-based textgeneration.
In Dale, Mellish & Zock (eds).
CurrentResearch in NLG.
London: Academic Press.
119?128.Mick O?Donnell (1997).
Variable Length On-LineDocument Generation.
Proceedings of EWNLG.Gerhard-Mercator University, Duisburg, Germany.Karen Spark Jones (1993).
What might be in asummary?
Information Retrieval 93: Von derModellierung zur Anwendung.
(Ed: Knorz, Krauseand Womse-Hacker), Konstanz: UniversitatsverlagKonstanz, 9?26.82
