Sentence  ext rac t ion  as a c lass i f icat ion taskS imone Teufe lCentre  for Cogn i t ive  Scienceand  Language Techno logy GroupUn ivers i ty  of  E&nburghS.
Teufel@ed.
ac.
ukMarc  MoensLanguage Technology GroupUnivers i ty  of  Ecb.nburghM.
Moens@ed.
ac.
ukAbst rac tA useful first step m document summau-sation is the selection of a small number of'meamngful'  sentences from a larger textKupiec et al(1995) describe t im as a clas-mficatlon task on the basis of a corpus oftechnical papers with summaries writtenby professional abstractors, their systemldent~fies those sentences m the text whichalso occur in the summary, and then ac-quires a model of the 'abstract-worthiness'of a sentence as a combination of a hmltednumbel of properties of that sentenceWe report on a rephcatlon of thin exper-nnent with different data summaries forour documents were not written by pro-fessional abstractors, but by the authorsthemselves Tins produced fewer allguablesentences to tram on We use alternative'meaningful' sentences (selected by a hu-man judge) as training and evaluation ma-terial, because tlns has advantages for thesubsequent automatic generation of moreflexible abstracts We quantitatively com-pare the two ?hfferent strategies for trainingand evaluation (vm ahgnment vs humanjudgement), we also chscnss qualitative chf-ferences and consequences for the genera-tlon of abstracts1 In t roduct ionA useful first step m the automatic or semi-automatic generation of abstracts from source textsm the selection of a small number of 'meamngful'sentences from the source text To achieve tins,each sentence m the source text is scored accordingto some measure of importance, and the best-ratedsentences are selected Thin results m collections ofthe N most 'meamngful' sentences, m the order mwlnch they appeared m the source text - we will callthese excerpts An excerpt can be used to give read-ers an idea of what the longer text m about, or It canbe used as input into a process to .produce a morecoherent abstractIt has been argued for almost 40 years that it mposmble to automatically create xcerpts which meetbamc reformation compresmon needs (Luhn, 1958)Since then, different measurements for the impor-tance of a sentence have been suggested, m partic-ular stochastic measurements for the mgmficance of-key words or phrases (Lulm, 1058, Zechner, 1995)Other research, starting with (Edmundson, 1969),stressed the Importance of heuristics for the locationof the candidate sentence m the source text (Baxen-dale, 1958) and for the occurrence of cue phrases(Palce and Jones, 1993, Johnson et al,  1993)Single heunstms tend to work well on documentsthat resemble ach other m style and content Forthe more robust creation of excerpts, combinationsof these heuristics can be used The eruclal ques-tion m how to combine the ?hfferent heuristics Inthe past, the relative usefulness of single methodshad to be balanced manually Kupmc et al(1095)use supervised learnmg to automatically adjust fea-ture w~ghts, using a corpus of research papers andcorresponding summariesHumans have good intuition about what makesa sentence 'abstract-worthy', I e suitable for inclu-sion in a summary Abstract-worthiness m a lugh-level quality, comprising notions such as semanticcontent, relative importance and appropriateness forrepresenting the contents of a document ?
.For theautomatic evaluation of the quality of machine gen-erated excerpts, one has to find an operational ap-proximation to this subjective notion of abstract-worthiness, 1e a defuntlon of a desired result Wewill call the criteria of what constitutes success thegold standard, and the set of sentences that fulfill58!I!Ii!iIIii1ltI!liI.IIIII!IIIiIiiiII!|these criteria the gold standard sentences Apartfrom evaluation, a gold standard m also needed forsupervmed learningIn Kupiec et al(1995), a gold standard sentenceis a sentence m the source text that zs matched rutha summary sentence on the basra of semantic andsyntactic snnflanty In thear corpus of 188 engineer-mg papers with summaries written by professionalabstractors, 79% of sentences occurred m both sum-mary and source text with at most minor moddica~tzonsHowever, our collection of papers, whose abstractswere written by the authors themselves, shows aszgnh~cant difference these abstracts have $1~nl~-.cantly fewer ahgnable sentences (31 7%) This does.not mean that there are fewer .abstract-worthy sen-tenees m the source text We used a simple (labour-intensive) way of defimng thin alternative gold stan-dard, vzz aslang a human judge to identify addi-tional abstract-worthy sentences in the source textOur mare question was whether Kuplec et a l ' smethodology could be used for our kind of gold stan-dard sentences also, and if there was a fundamentalchfference in extraction performance between sen-tences in both gold standards or between documentswith higher or lower alignment We also conductedan experiment to see how additional training mate-hal would influence the statistical modelThe remainder of this paper is organized as fol-lows in the next section, we s-mmanze Kuplec eta l ' s  method and results Then, we describe ourdata and dmcuss the results from three experimentswith dflferent evaluation strategies and tralmng ma-terial Differences between our and Kuplec et a l ' sdata with respect to the ahgnablhty of documentand summary sentences, and consequences thereofare conmdered m the discussion2 Sentence select ion as classif icationIn Kupzec et a l ' s  experiment, the gold standardsentences are those summary sentences that can bealigned with sentences m the source texts Oncethe alignment has been carried out, the system triesto determine the characteristic properties of ahgnedsentences according to a number of features, wzpresence of particular cue phrases, location in thetext, sentence length, occurrence of thematic words,and occurrence of proper names Each documentsentence receives cores for each of the features, re-suiting m an estimate for the sentence's probabihtyto also occur m the summary This probabihty iscalculated as follows59P(8 ~ SlFi,P(a ~ SIFt,e{, ~ s)P(F,I, ~ S)P(F,)kF,, Fk )  ~ p(,~s) N~=, P{P,l,~s).1\[I;., pcF,~, Fj) Probablhty that sentences m the source text m mcluded111 ~lmmary S, given Its featurevvlues,compressmn rate (constant),probablhty of feature-value pair oc-curnng m a sentence winch m m thesummary,probabihty that the feature-valuepair occurs uncon&tzonally,?
number of feature-valus pairs,j-th feature-value pairAseummg statmtmal independence of the features,P(~ls E S) and P(Fj) can be estnnated from thecorpusEvaluatmn rches on ccross-vahdatmn The modelm trmned on a training set of documents, having onedocument out at a tune (the cu~ent test document)The model is then used to extract can&date sen-tences from the test document, allowing evaluationof precision (sentences selected correctly over totalnumber of sentences selected) and recall (sentencesselected correctly over ahgnable sentences m sum-mary) Since from anygrven test text as many sen-tences are selected as there are ahgnable sentencesm the summary, precamon and recall are always thesameKupiec et alreports that preasion of the m&wd-ual hetmstles ranges between 20-33%, the highestcumulative result (44%) was adaeved using para.graph, fixed phrases and length cut-off eatures3 Our exper iment3.1 Data  and gold s tandardsOur corpus m a collection of 202 papers from dif-ferent areas of computational lmgtusties, with sum-maries written by the authors 1 The average lengthof the summaries m4 7 sentences, the average l ngthof the documents 210 sentencesWe seml-aut0matlcally marked up the followingstructural reformation title, summary, headings,paragraph structure and sentences Tables, equa-tions, figures, captious, references and cross refer-ences were removed and replaced by place holders1The corpus was drawn from the computataon andlanguage arcinve (h t tp  //xxx lan3..gov/cmp-lg), con-vetted from DTF~ source into HTML m order to ex-tract raw text and ramlmal structure automatically, thentransformed into our SGML format with a perl script,and manually corrected Data colinctlen took place col-laboratavely with Byron Georgantopolous" :'i 310senmm:e~ " .
.
~ T m ~  l ~ s e .
~  " "Amhof'mmman~s GoM ~,~lsTranung set 140 documenm~8888~ 21%Auth~rmmmmnea Gold~-,,~Mds Authorsmmmanes Gold standardsTraining set 2 Trammg set 342 documJnts 42 documentsFigure 1 Composition of gold standards for trmnmg setsUm~ Gold madard A At~sabt~ ,.umry Gold ~-d,,d B non-ahxnab~ b~ mkvml sea~.,nces (tram jDdgm~m)We decided to use two gold standards?
Go ld  s tandard  A: AHgnment .
Gold stan-dard sentences are those occurring m both au-thor  summary and source text, m line with Ku-pmcet a l ' s  gold standard?
Gold  s tandard  B :  Human Judgement .Gold standard sentences are non:ahgnablesource text sentences which a human judgeidentified as relevant, 1e mchcatlve of the con-tents of the source text Exactly how manyhuman-selected sentence candidates were cho-sen was the human judge's decisionAhgnment between summary and document sen-fences was assmted by a simple surface snmlarltymeasure (longest common subsequence of non-stop-list words) Final ahgnment was declded by a hu-man judge The cxlterlon was snnllanty of semanticcontents of the compared sentences The followingsentence palr illustrates a dsrect  match  - .Summary:  /n understand~ a reference, anagent detexmmes his confidence m Its ade-quacy as a means of identifying the referentDocument:  An agent understands a refer-ence once he is com~dent m the adequacy ofits (referred) p/an as a means of  Identifyingthe referentOur data show an important chfference wlth Ku-.plec et als data we have slgnn~cantly lower ahgn-ment rates Only 17 8% of the summary sentencesIn our corpus could be automatlcally ahgned wltha document sentence wlth a certain degree of reh-ablhty, and only 3% of all summary sentences areIdentlcal matches wlth document sentencesWe created three chfferent sets of trmnmg mate-halTrain ing set I: The 40 documents with thehighest rate of overlap, 84% of the summarysentences could be semi-antomatlcally ah~nedwith a document sentenceTraining set 2 :42  documents from the year1994 were arbitrarily chosen out of the re-mmnmg 163 documents and seml-automatlcallyahgned They showed amuch lower rate of over-lap, only 36% of summary sentences could bemapped into a document sentenceTraining set 3 :42  documents from the year1995 were arhitranly chosen out of the remain-mg documents and serm-automahcally ahgnedAgain, the overlap was rather low 42%Training set 123: Conjunctlon of training setsI, 2 and 3 The average document length m 194sentences, the average summary length m 4 7sentences?
A human judge provlded a mark-up of addltlonalabstract-worthy sentences for these 3 trmnmg sets(124 documents) The remaining 78 documentsremain as unseen test data Figure 1 shows thecompomtlon of gold standards for our training setsGold standard sentences for trmmng set I consmt ofan approximately balanced mixture of ahgned andhuman-selected candidates, whereas training set 2contains three times as many human-selected asahgned gold standard sentences, training set 3 evenfour times as many Each document m trmmng set 1is associated with an average of 7 75 gold standardsentences (A+B), compared to an average of 7 07gold standard sentences m trmnmg set 2, and anaverage of 9 14 gold standard sentences m trammgset 36OIII1!I1II,|i1m.II .IIiIII!IIIli3.2 Heur ist icsWe ~ employed 5 chfferent heuristics 4 of the meth-ods used by Kuplec et al(1995), viz cue phrasemethod, locatlon metli6d, sentence length methodand thematic word method, and another well-knownmethod m the hterature, viz title method1.
Cue phrase method:  The cue phrase methodseeks to filter out met~-dtscourse from subject mat-ter  We advocate the cue phrase method as our maremethod because of the ad&tmnal 'rhetorical' contextthese meta-lmgmstlc markers make available Thlscontext of the extracted sentences - along with theirproposmunal content - can be used to generate moreflexible abstractsWe use a hst of 1670 negative and positive cuesand indicator phrases or formulalc expressions, 707of which occur m our training sets For sLmphcltyand efficiency, these cue phrases are fixed stringsOur cue phrase hst was manually created by acycle of Inspection of extracted sentences, ldentlfi-cat!on of as yet unaccounted-for expressmns, ad&-tlon of these expressions to the cue phrase hst, andpossibly inclusion of overlooked abstract-worthy sen-tences m the gold standard Cue phrases were man-ually classtfied mto 5 classes, whlch we expected tocorrespond to the hkehbood of a sentence containingthe glvcu cue to be included m the summary a scoreo f -1  means 'very unhkely', -~3 means 'very hkelyto be included m a summary' 2 We found ~t usefulto assist the dec~un process with corpus frequen-cies For each cue phrase, we compded ~ts relativefrequency m the gold standard sentences and m theoverall corpus If a cue phrase proved general {\] e~t had a high relative corpus frequency) and dtstmc-t~ve (~ e \]t had a high frequency within the goldstandard sentences), we gave ~t a high score, andincluded other phrases that are syntactically and se-manhcally sirmlar to \]t mr0 the cue hst We scannedthe data and found the following tendencies?
Certain communlcat~ve verbs are typically usedto describe the overall goals, they occur fre-quently m the gold-standard sentences (ar-gue, propane, develop and attempt) Othersare predonnnantly used for describing com-munlcattve sub-goals (detaded steps and sub-arguments) and should therefore be m a dif-ferent equivalence class (prove, show and con-clude) W~tlnn the class of commumcat~veverbs, tense and mode seem to be relevantfor abstract-worthinesS Verbs m past tense~We experimented w~th larger and smaller numberso f  classes, but obtained best results with the 5-way&stmct~on61or present pedect {as used m the conclumon)are more hkely to refer to global achieve-ments/goals,, and thus to be included m the?
summary In the body of the text, present andfuture forms tend to be used to introduce sub-tasksGenre specific nominal phrases hke this paperare more distractive when they occur at the be-gmmng of the sentence (as an approxLmatlon tosubject/topic potation)than their non-subjectcounterpartsExphclt summansatlon markers hke m sum,concluding chd occur frequently, but quite un-expectedly almost always m combination withcommumcatlve sub-tasks They were thereforeless useful at slgnalhng abstrac~worthy mate-halSentences m the source text are matched againstexpresslous m the hst Matching sentences are clas-sified into the correspundmg class, and sentencesnot contaunng cue phrases are clsssflied as 'neutral'(score 0) Sentences with competing cue phrases areclassflied as members of the class with the lnghernumerical score, unless one of the competing classesis negativeSentences occurnng directly after hsadmgs hke In-troductson or Results are valuable indicators of thegeneral subject area of papers Even though onermght argue that ttns property should be handledwithin the location method, we percetve tlas refor-mation as meta-hngmstlc (and thus logically belong-mg to the cue phrase method) Thus, scores for thesesentences recelve aprior score of +2 ('hkely to occurm a summary')In a later section, we show how tins method per-forms on unseen data of the same land (viz texts mthe genre of computational lmgulshcs research pa-pers of about .~6--8 pages long) Even though thecue phrase method is well tuned to these data, weare aware that the hst of phrases .we collected mlghtnot generahze toother genres Some land of automa-tion seems desirable to assist a possible adaptation2.
Locat ion method.
Paragraphs at the startand end of a document are more hksly to containmaterial that Is useful for a summary, as papers areorganized hierarchically Paragraphs are also orga-razed hierarchically, with crucial reformation at thebeginning and the end of paragraphs Therefore,sentences m document peripheral paragraphs shouldbe good can&dates, and even more so If they occurm the periphery of the paragraphOur algunthm assigns non-zero values only to sen-tences winch are m document penpheral sections,sentences in the middle of the document receive a0 score The algorithm is sensitive to prototypl-cal heachngs (IntrOdact:on), if such hendmgs cannotbe found, it uses a fixed range of paragraphs (first7 and last 3 paragraphs) Within these documentperipheral paragraphs, the values 'l_f' and 'm' (forparagraph initial-or-final nd paragraph medial sen-tences, respectively) are assigned3.
Sentence Length  method.
All sentences un-der a certain length (current threshold 15 tokens in-cluding punctuation) receive a 0 score, all sentencesabove the threshold a 1 scoreKuplec et almention tins method as useful forfiltering out captious, titles and headings In ourexperiment, hin was not necessary as our formatencodes headings and titles as such, and captions areremoved As expected, it turns out that the sentencelength method Is our least effective method ?4.
Themat ic  word method.
Tins method triesto identify key words that are characteristic forthe contents of the document I t  concentrates onnon-stop-hst words winch occur frequently m thedocument, but rarely m the overall collection Intheory, sentences cont.~mg (clusters of) such the-matlc words should be characteristic for the docu-ment We use a standard tenn-frequency*mverse-doenment-frequency (tf*ldf) method, loy\[l??
*N~ ,core(w) = ~oo cT;r~-,..floe frequency of word w m documentfgt,~ number of documents contmnmg word wN number of documents m collectaonThe 10 top-scoring words are chosen as the-matlc words, sentence scores are then computedas a weighted count of thematic word m sentence,meaned by sentence length The 40 top-rated sen-tences get score 1, all others 05.
T i t le  method.
Words occurring in the tit leare good candidates for document specific onceptsThe title method score of a sentence m the meanfrequency of title word occurrences (excluding stop-lint words) The 18 top-sconng sentences receivethe value 1, all other sentences 0 We also exper-imented with taking words occurring m all headingsinto account (these words were scored accorchng tothe tffldf method) but received better esults for tl-tle words onlyMethod 1 (cue)Method 2 ( locat ion)Method 3 ( length)Method 4 (t f* idf)Method  5 (t i t le)Basel ineIndiv.
Cumul.552 55232 1 65 328 9 66 317 1 66 521 7 68 428 0Figure 2 First experiment Impact of mdlvtdualhennstlcs, training set 123, gold standards A+BCue Phrase MethodHeurist ics Combinat ionBasefineSeen Unseen60 9 54 971 6 65 3291Figure 3 First Experiment DLfference betweenunseen and seen data, training set 3, gold stan-dards A+B3.3 ResultsTraining and evaluation took place as m Kuplec etal 's  experiment As a basehne we chose sentencesfrom the begmmng of the source text, winch o~tamed a recall and preczmon of 28 0% on trainingset 123 Tins from-top baseline (winch zs also usedby Kuplec et al) ?
is a more conservative basehnethan random order it zs more dn~cult o beat, asprototyplcal document structure places a Ingh per-centage of relevant reformation m the beginning3.3.1 First  exper imentFigure 2 summarizes the contribution of the in-dividual methods 8 Using the cue phrase method(method 1) Is Clearly the strongest single heuris-tic Note that the contribution of a method cannotbe judged by the individual precision/recall for thatmethod For example, the sentence length method(method 3) voth a recall and preczslon over the base-line contributes hardly anything to the end resul Lwhereas the title method (method 5), winch is be~low the basehne If regarded mchvldually, performsmuch better m combination with methods 1 and 2than method 3 does (67 3% for heuristics 1, 2 and5, not to be seen from thin table) The reason fortins is the relative independence of the methods Ifmethod 5 identifies a successful canchdate, It is lesslikely that tins can&date has also been Identified bymethod I or 2 Method 4 (tf*ldf) decreased resultsshghtly m some of the expernnents, but not  m theSAll figures m tables are preamon percentagesIII1I62!IiiIiIIm,!I!i!i1iiIcomb cue baseTS1  661 490 296TS2  622 i 545 249TS3  71-6 ~ 609 291TS 123 684 i 55 2 28 0Figure 4 First experiment Baseline, best singlehennstxc and combination, gold standards A+Bexperiments with our final/largest training set 123where tt led to a (non-mgmficant) increaseWe also checked how much precision and recalldecrease for unseen data This decrease apphes onlyto the cue phrase method, because the other henrm-tics are fixed and would not change by seeing moredata After the manual mark-up of gold standardsentences and additions to the cue phrase hst fortraining set 3, we treated traunng set 3 as ff it wasunseen we used only those 1423 cue phrases for ex-traction that were compded from training set I and2 A comparxson of fins 'unseen' result to the endresult (Figure 3) shows that our cue phrase hst, eventhough hand-crafted, xsrobust and general enoughfor our purposes, it generahzes reasonably well totexts of a mmflar kindFigure 4 shows mean precmion and recall for ourdifferent raining sets for three dflferent extractionmethods a combination of all 5 methods ('comb '),the best single heuristic ('cue'), and the baseline('base') We used both gold standards A+B Theseresults reconfirm the usefulness of Kupiec et al'smethod of heunst4c ombination The method m-creases precmlon for the best method by around20% It m worth pointing out that thin method pro-duces very short excerpts, wxth compresmous a  Inghas 2-5%, and with a preczslon equal to the recallThus tins xs a different task from producing long ex-cerpts, e g with a compres~on bf25%, as usually re-ported m the literature Usmg tins compresmon, weachieved a recall of 96 0% (gold standard A), 98 0%(gold standard B) and 97 3% (gold standards A+B)for training set 123 For comparmon, Kuplee et alreport a 85% recall3.3.2 Second exper imentIn order to see how the chfferent gold standardsc?ntnbute to the results, we used only one gold stan-dard (A or B) at a time for trmmng and for extrac-tion Figure 5 summarizes the resultsLooking at Gold standard A, we see that trmnmgset 1 m the only training set winch obtains a recallthat is comparable to Kuplec et al's  Incidentally,tratmng set 1 is also the only tratmng set that IsEvaluation strategy .Gold standard A Gold startdard BTS  comb cue base comb cue base1 369 275 214 453 : 30'4 ~108250 184 92  538 479 i 2033 271 135 "135 643 544 ~' 257123 316 232 163 572 467\[  20463Figure 5 Second expenment Impact of type of goldstandard70%60%-50%"40%"30%"comparable to Kuplec et al's data vnth respect oallgnablhty The bad performance of tratmng set 2and 3 under evaluation w3th gold standard A m not~-surprmmg, as there are too few aligned g01d standard"sentences to tram on 50% of the documents mthesetraining sets contain o or only one ahgned sentencepremxon/recallC, mld standards A+B.
G o l d ~~~Id  mndm'd A compressiono~1 o~ o~ o~ o~5 ~Figure 6 Second expernnent Impact of type of goldstandard on preclswn and recall, as a function ofcompresmonOverall, performance s ems to correspond to theratio of gold standard sentences to source text sen-tences, x e the compresmon of the task 4 The de-pendency between prectston/recaU nd compresmonm depicted m Figure 6 Taking both gold stan-dards into account increases performance onmder-ably compared to either of the gold standards alone,because of the lower compresmon As we don't havetraining sets with exactly the same number of goldstandard A and B sentences, we cannot directly com-pare the performance, but the graph m suggestive ofa mmdar behavlour of both gold standards The re-sults for training set 123 ,failbetween the results ofthe mchvxdual training sets (symbolL~ed by the largedata points)4The chiference mperformance between trmmug setsm the first expenment Is thus probably meanly att.-tnbutable to ~hfferences m compresmon between thetrmmn~ setsTS1Tra in ing  23123Extraction1 2 3 123~661 612 697!
663658" 622 695 660651 i 629 .716 661664 \ [629  i708  684Figure 7 Thtrd experiment Impact of training ma-tenal on prec~mon and recall, gold standards A+BFrom tins second experiment we conclude that forour task, them m no dnq~erence b tween gold stan-dard A and B The crucial factor that preclmon andrecall depends on ms the compression of the task3.3.3 Th i rd  exper imentIn order to evaluate the impact of the trainingmaterial on preclslon and recall, we computed eachpossible pair of training and evaluation material (cffigure 7)In tins experiment, all documents of the tram-mg set are used to trmn.
the model, thin model mthen evaluated against each document in the testset, and the mean preclslon and recall is reportedImportantly, m thin experiment none of the otherdocuments in the test set m used for tr~tmmgThese expernnents show a surprising umfonmtywztlnn test sets overall extraction results for eachtrmnmg set are very mxmlar T rmnmg on differentdata does not change the statmtical model much Inmost cases, extraction for each training set workedbest when the model was trmned on the training setitself, rather than on more data Thus, the dflYerencein results between mchvldual trammg sets m not an-effect of data' sparseness at the level of heuristicscombmatlonWe conclude from thin third experm~ent that im-provement m the overall results can primarily beachieved by improwng tangle hsurlstlcs, and not byproviding more training data for our simple statmtl-cal model4 DiscussionCompanng our experiment to Kuplec et al,s themost obvlous dn~erence m the dfiYerence m dataOur texts are likely to be more heterogeneous,coming from areas of computational hngumtlcs with.
different methodologles and thus having an arg u-mentative, experimental, or irnplementatlonal ormn-tatlon Also, as they are not journal artlcles, theyare not heavdy edited There is also less of a pro-totyplcal article structure in computational hnguls-tics than m experimental dmciphnes like chemicalen~neenng Thin makes our texts more dn~cult oextract fromThe major difference, however, m that we use sum-manes winch are not written by trained abstractore,but by the authors themselves In only around 20% "of  documents m our ongjnal corpus, sentence selec-tion had been used as a method for sununazy gen-eration, whereas profesmonal bstractors ely moreheavily and systematically onsentences mthe sourcetext when creating their abstractsUsing ahgned sentences as gold-standard has twomare advantages First, it makes the defimtlon ofthe gold standard less labour mtenmve Second, i tprowdes a lngher de~ee of objeetwlty It m a muchshmpler task for a human judge to dsclds if two sen-tences convey, the same propositional content, thanto decide if a sentence is qualdied for mclumon m asummary or notHowever, using alignment as the sole definition forgold standard lmphes that a sentence isonly a goodextraction candidate if its equivalent occurs m thesummary, an assumption we beheve to be too restric-tive Document sentences other than the aligned.ones m~ht  have been sumlar in quality to the chosensentences, but wdl be trmned on as a negative xam-ple with Kupmc et a l ' s  method Kupmc et alalsorecognize that there m not only one optmlal excerpt,and mention Bath et a l ' s  (1961) research winch nn-phes that the agreement between human judges israther low We argue that It makes ense to comple-ment ahgned sentences with manually determmedsupplementary can&dates Tins m not solely moti-vated by the data we work with but also by the factthat we envtsage a different ask than Kupmc et al(who use the excerpts as mchcative abstracts) Wesee the extraction of a set of sentences as an interme-diate step towards the eventual generation of moreflemble and coherent abstracts of variable lengthFor tins task, a whole range of sentences other thanjust the summary sentences might quahfy as goodcandidates for further processing ~ One importantsubgoal m the reconstruction of approximated docu-ment structure (cf rhetorical structure, as defined inRST (Mann et al,  1992)) One of the reasons whywe concentrated on cue phrases was that we behevethat cue phrases are anobvious and easily accessiblesource of rhetorical informationAnother nnportant question was ff there wereother properties foUowmg from the mmn differencebetween our training sets, ahgnablhty Are docu-ments with a Ingh degree of ahgnablhty :nherently5Tlns m nurrored by the fact that m our gold stan-dards, the number of human-selected sentence canch-dates outwelghed ahgned sentences by far64!
!more statable for abstraction by our algorithm ~ Itmight be suspected that ahgnahhty m correlatedw i tha  better internal structure of the papers, butour experiments suggest that, for the purpose of sen-tence extraction, thin m eather not the case or notrelevant Our results show that our training sets 1,2 and 3 behave ~ery slrmlarly under evaluation tak-ing ahgned gold standards or human-selected goldstandards into account The only definite factor m-fiuencmg the results was the compression rate Withrespect o the quahty of abstracts, tins imphes thatthe strategy which authors use for summary gen-erahon - be it sentence selection or complete re-generation of the summary from semanhc represen-tahon - m a matter of authonal chmce and not anmchcator of style, text ~quahty, or any aspect thatour extraction program is particularly senmhve toThin means that Kupmc et a l ' s  method of clasmfi-catory sentence selection m not restricted to textswhich have hlgh-quahty summaries created by hu-man abstractors We claim that adding human-selected gold standards wdl be useful for generationof more flembie and coherent abstracts, than tram-mg on just a fixed number of author-provldsd um-mary sentences would allow5 Conclus ionsWe have rephcated Kuplec et a l ' s  experiment forautomatic sentence extraction using several rode-pendent heurmtlcs and superwsed learning Thesummaries for our documents were not written byprofessional abstractors, but by the authors them-selves As a result, our data demonstrated conmd-erably lower overlap between sentences m the sum-mary and sentences m the mare text We used analternative valuation that mL~ed ahgned sentenceswith other good can&dates for extraction, as iden-tified by a human judgeWe obtained a 68 4% recall and preclmon on ourtext material, compared to a 28 0% baseline and abest mdlvldual method of 55 2% Combimng m&-vldually weaker methods results m an increase ofaround 20% of the best method, m line with Kupmcet als results Thin shows the ~mefulness.
of Ku-plec et als methodology for a different type of dataand evaluation strategy We found that there wasno difference m performance between our evaluationstrategies (alignment or human judgement), apartfrom external constraints on the task hke the com-pression rate We also show that increased trmmngdid not slgmficantly improve the sentence extractionresults, and conclude that there m more room for im-provement m the extraction methods themselvesWith respect o our ultimate goal of generatmg ofhigher quahty abstracts (more coherent, more flex-ible variable-length abstracts), we argue that theuse of human-selected xtraction can&dates m ad-?
Vantageous to the task Our favounte heurmhc in-cludes meta-lmgmstic cue phrases, because they canbe used to detect rhetorical structure m the docu-ment, and because they provide a rhetoncal contextfor each extracted sentence m addition to its propo-mhonal content6 AcknowledgementsThe authors would hke to thank Chrm Brew, JanetHttzeman and two anonymous referees for commentson earher drafts of the paper The first author msupported by an EPSRC studentshpReferencesBaxendale, P (1958) Man-made mdex for techmcal ht-erature - an experiment IBM3ournal on research anddevelopment, 2(4)Edmundson, H (1969) New methods m automahc ex-tracting Journal of the ACM, 16(2)Johnson, F C,  Peace, C D, Black, W J ,  and Neal,A P (1993) The apphcataon ofhngumtac processingto automata?
abstract generation Journal of Docu-ment and Tezt Management, 1(3) 215-42Kupmc, J ,  Pedersen, J  and Chen, F (1995) A tram-able document ~rnmea'lzer In Proceedings of the ISthA UM-SIGIR ConferenceLulm, H P (1958) The automatac creation ofhteratureabstracts IBM Journal o\] Research and Development,2(2)Mann, W C, Matthesen, C M I M, and Thompson,S A (1992) Rhetorical structure theory and textA.Mysm In Mann, W G and Thompson, S A, ed-itors, Discourse descnphon J Benj~mm~ Pub Co,AmsterdAmPeace, C D and Jones, A P (1993) The ldentdicatlonof important concepts m highly structured techmcalpapers In Proceedings of the Stzteenth Annual In.ternatsonal ACM SIGIR conference on research anddevelopment m IRZechner, K (1995) Automa~c text abstracting by se-lecting relevant passages Master's thems, Centre forCogmt, ve Science, Umvermty of Edinburgh65
