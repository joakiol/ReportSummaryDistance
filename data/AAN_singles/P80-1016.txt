PROBLEM SOLVING APPLIED TO LANGUAGEGENERATIONDouglas I~: AppeltStanford University, Stanfo,d, CaliforldaSR I International 111enlo Park.
CaliforniaThis research was supported at SRI htternational by theDefense Advanced Reseat~ch Projects Agency under contractN00039-79-C-0118 ~?ith the Naval Electronic SystemsCommaw t The views and conchtsions contained in thisdocument are those of the author and should not be interpretedas representative of the official policiex either expressed orbnplied, of the Defense Advanced Research Projects Agency, orthe U. S. Goverttment.
The author is gratefid to Barbara Grosz,Gary ttendrix and Terry Winograd for comments on an earlierdraa of this paper.I.
IntroductionPrevious approaches to designing language understanding systems haveconsidered language generation to be tile activity of a highly specializedlinguistic facility that is largely indcpendcnt of other cognitive capabilities.All the requisite knowlcdge for gencration is embodicd in a "gcnerationmodule" which, with appropriate modifications to the lexicon, istransportable bctween different domains and applications.
Applicationprograms construct "messages" in some internal representation, such as firstorder predicate calculus or scmantic nctworks, and hand them to thegeneration module to be translated into aatoral anguage.
The applicationprogram decides what to say; the gencration module decides how to say it.In contrast with this previous work.
this papcr proposes an approach todesigning a language generation systcm that builds on the view of languageas action which has cvolvcd from speech act theory (see Austin \[2l andScarle \[11\]).
According to this vicw, linguistic actions are actions planncdto satisfy particular goals of the spcakcr, similar to other actions likemoving and looking.
Language production is integrated with a spcakcr'sproblcm solving processes.
This approach is fi~unded on the hypothesisthat planning and pcrforming linguistic ,actions is an activity that is notsubstantially different from planning and pcrforming othcr kinds ofphysical actions.
The process of pro/lucing an uttcrance involves, planningactions to satisfy a numbcr of diffcrent kinds of goals, and then el~cicntlycoordinating the actions that satisfy these goals.
In the resultingframework, dlere is no distinction between deciding what to say anddeciding how to say it.This rcsearch has procceded through a simultaneous, intcgrated effort intwo areas.
The first area of re.arch is the thcoretieal problcm ofidentifying the goals and actions that occur in human communication andthen characterizing them in planning terms.
The ~cond is the moreapplied task of developing machine--based planning methods that areadequate to form plans based on thc characterization dcveloped as part ofthe work in the first area.
The eventual goal is to merge the results of thetwo areas of effort into a planning system that is capable of producingEnglish sentences.Rather than relying on a specialized generation module, languagegeneration is performed by a general problcm-.-solving system that has agreat deal of knowlcdge about language.
A planning system, named K^MI'(Knowlcdge and Modalitics Planncr), is currently under development thatcan take a high-lcvel goal-and plan to achieve it through both linguisticand non-linguistic actions.
Means for satisfying multple goals can beintegrated into a single utterance.Thi.~ paper examines the goals that arise in a dialog, and what actionssatisfy those goals.
It then discusses an example of a sentcnee whichsatisfies several goals simultaneously, and how K^MP will be able toproduce this and similar utterances.
This system represents an extension toCohen's work on planning speech acts \[3\].
However, unlikc Cohen'ssystem which plans actions on thc level of informing and requesting, butdoes not actually generate natural anguage sentences, KAMP applies generalproblcm-solving techniqucs to thc entire language gencration process,including the constructiun of the uttcrance.1I.
GoaLs and Actions used in Task Oriented DialoguesThe participants in a dialogue have four different major types of goalswhich may be satisfied, either directly or indirectly, through utterances.Physical goals, involve the physical state of the world.
The physical statecan only be altered by actions that have physical effects, and so speech actsdo not serve directly to achieve these goals.
But since physical goals giverise to other types of goals as subgoals, which may in turn be satisfied byspeech acts, they are important to a language planning system.
Goals thatbear directly on the utterances themselves are knowledge slate goals.discourse goals, and social goalxAny goal of a speaker can fit into one of these four categories.
However,each category has many sob--categories, with the goals in each sub--categorybeing satisfied by actions related to but different from those satisfying thegoals of other sub--categories.
Delineating the primary categorizations ofgoals and actions is one objective of this research.Knowledge state goals involve changes in tile beliefs and wants held by thespeaker or the hearer.
Thcy may be satisfied by several different kinds ofactions.
Physical actions affect knowledge, since ,as a minimum the agentknows he has performed the action.
There are also actions that affect onlyknowledge and do not change the state o?
the world - -  for example.reading, looking and speech acts.
Speech acts are a special case ofknowledge-producing actions because they do not produce knowledgedirectly, like looking at a clock.
Instead, the effects of speech acts manifestthcmselves through the recognition of intention.
The effect of a speech act,according to Searle.
is that the hearer recognizes the speaker's intention toperform the act.
The hcarer then knows which spceeh act has beenperformcd, and because of rules governing the communication processes,such as the Gricean maxims \[4\].
the hearer makes inferences about thcspeaker's beliefs.
Thcse inferences all affect the heater's own beliefs.Discourse goals are goals dial involve maintaining or changing the sthte ofthe discourse.
For example, a goal of focusing on a different concept is atype of discourse goal \[5, 9, 12\].
The utterance Take John.
for instanceserves to move the participants' focusing from a general subject to aspecific example.
Utterances of this nature seem to be explainable only interms of the effects they have, and not in terms of a formal specification oftheir propositional contentConcept activation goals are a particular category of discourse goals.
Theseare goals of bringing a concept of some object, state, or event into theheater's immediate coneiousness so that he understands its role in theutterance.
Concept activation is a general goal that subsumes differentkinds of speaker eference.
It is a low-level goal that is not considereduntil the later stages of the planning process, but it is interesting because ofthe large number of interactions between it and higher-level goals and thelarge number of options available by which concept activations can beperformed.59Social goals also play an important part in the planning of utterances.Thc,:e goals are fimdamentally different from other goals in that freqnentlythey are not effeCts to be achieved ~a~ much as constraiots on the possiblebehavior that is acceptable in a given situation.
Social goals relate topoliteness, and arc reflected in the surface form and content of tileutterance.
However, there is no simple "formula" that one can follow toconstruct polite utterances.
Do you know what time it Ls?
may ~ a politeway to ask the time, but Do you know your phone number?
is not verypolite in most situations, but Could you tell me your phone number?
is.What is important in this example is the exact propositional content of theutterance.
People are expected to know phone numbers, but notnecessarily what time it is.
Using an indirect speech act is not a sufficientcondition for politen?~.
This example illustrates how a social goal canmtluence what is said, as well as how it is expressed.Quite often the knowledge state goals have been ssragned a specialpriviliged status among all these goals.
Conveying a propsition was viewedas the primary reason for planning an utterance, and the task of a languagegenerator was to somehow construct an utterance that would be appropriatein the current context.
In contrast, this rosen:oh attempts to take Halliday'sclaim \[7\] seriously in the design of a computer system:"We do not.
in' fact,  first decide what we want to sayindependcndy of the setting a,ld then dress it up in a garb thatis appropriate to it in the context .
.
.
.
The 'content' is part ofthe total planning that takes place.
"lhere is no clear linebetween the "what' and the 'how' .
.
.
"The complexity that arises from the interactions of these different ypes ofgoals leads to situations where the content of an utterance is dictated bythe requirement that it tit into the current context.
For example, a speakermay plan to inform a bearer of a particular fact.
Tbc context of thed i scou~ may make it impossible for the speaker to make an abrupttransition from the current opic to the topic that includes that proposition,To make this transition according to the communicative rules may requireplanning another utterance, Planning this utterance will in turn generateother goals of inforoting, concept activation and focusing.
The actions usedto satisfy these goals may affect the planning of the utterance that gave riseto the subgoal.
In this situation, there is no clear dividing line between"what to say" and "how to say it".IlL An Integrated Approach to Planning Speech ActsA probem--solving system that plans utterances must have lhe ability todescribe actions at different levels of abstraction, the ability to speCify apartial ordering among sequences of actions, and the ability to consider aplan globally to discover interactions and constraints among the actionsalready planned.
It must have an intelligent method for maintainingalternatives, and evaluating them comparatively.
Since reasoning aboutbelief is very important in planning utterance, the planning system musthave a knowledge representation that is adequate for representing factsabout belief, and a deduction system that is capable of using thatrepresentauon efficiently.
I Ach ieve(P)  / 'KAMI' is a planning system, which is currently beiug implemented, th:Kbuilds on the NOAII planning system of Saccrdoti \[10\].
\]t uses apossible-worlds semantics approach to reasoning about belief" and theeffects that various actions have on belief \[8\] and represents actions in adata structure called a procedural network.
The procedural network consistsof nt~es representing actions at somc level of abstraction, along with splitnodes, which specify several parually urdercd sequences of actions that canbe performed in any order, or perhaps even in parallel, and choice nodeswhich specify alternate actions, any one of which would achieve the goal.Figure 1 is an examplc of a simple procedural network that represents thefollowing plan: The top--level goal is to achieve P. The downward linkfrom that node m the net points to an expansion of actions and subgoals,which when performcd or achieved, will make P true in the resultingworld.
The plan consists of a choice betwcen two alternatives.
In tile firstthe agent A does actions At and A2.
and no commitment has been made tothe ordering of these two parts of thc plan.
After both of  those parts havcbeen complctcly planned and executed, thcn action A\] is performed in thcr~sulting world.
The other alternative is for agent B to perform action A4.It is an important feature of KAMP that it can represent actions at severallevels of abstraction.
An INFORM action can be considered as a high levelaction, which is expanded at a lower level of abstraction into conceptactivation and focusing actions.
After each expansion to a lower level ofabstraction, ~.^MP invokes a set of procedures called critics that cxa,ninctile plan globally, considering the interactions bctwccn its parts, resolvingconflicts, making the best choice among availab;e alternatives, and noticingredundant acuons or actions that could bc subsumed by minor alterationsin another part of the plan.
Tile control structure could bc described as aloop that makes a plan, expands it.
criticizes thc result, and expands itagain, until thc entirc plan consists of cxccutablc actions.The following is an example of the type of problem that KAMP has beentested on: A robot namcd Rob and a man namcd John arc in a room thatis adjacent o a hallway containing a clock.
Both Rob and John arecapable of moving, reading clocks, and talking to each other, and they eachknow that the other is capable of performing these actions.
They bothknow that they are in the room, and they both know where tile hallway is.Neither Rob nor John knows what time it is.
Suppose that Rob knows thatthe clock is in the I'tall, but John does not.
Suppose further that Johnwants to know what time it is.
and Rob knows he does.
Furthermore, Rubis helpful, and wants to do what he can to insure that John achieves hisgoal.
Rob's planning system must come up with a plan, perhaps involvingactions by both Rob and John.
that will result in John knowing what timeit is.Rob can devise a plan using KAMP that consists of a choice between twoalternalives, First, i f  John could find out where the clock is.
he could goto the clock and read it, and in the resulting state would know the time.So.
Rob can tell John where the clock is, "asoning that this information issufficient for John to form and execute a plan that would achieve his goal.
'~"  DO(A t A t )DO(A t A2}DO(B, A4) JFigu re 1A S imple  P rocedura l  NetworkDo(A ,  A3) I60fActlieve(Oetached(Bracel, Como))I ActtievelLoo.se(Boltl II i jAchieve(KnowWhaOs(Aoor.
E\]oltl))ciaieve( KnowWhalls( AI)l~r.
Loosen(Bolt I .Wfl)))chieve(t(nowWhatls L - -~  ' Achieve(Has.=,.=,\[ Acllieve(Know(Ap,r.On(Tat,le.Wrl))) ' ~ Oo(Aoor.
Get(Wrl.
Tattle;)F igure  2A Plan to Remove a BoltThe second alternative is t'or Rob to movc into the hall and read the clockhimself, move back into the room.
and tcU John the time.As of the time of this writing.
KAMP has been implemented and tested onproblems involving the planning of high level speech act descriptions, andpcrfonns tasks comparable to the planner implcmcntcd by Cohen.
A morecomplete description of this planner, and the motivation for its design canbe found in \[\],\].
The following example is intended to give the reader afeeling for how the planner will prncced in a typical situation involvinglinguistic planning, but is not a description of a currently working system.An expert and an apprentice are cooperating in the task of repairing an aircompressor.
The expert is assumed to be a computer system that hascomplete knowledge of all aspects of the task, but has no means ofmanipulating the world except by requesting the apprentice to do things.and furnishit~g him or her with the knowledge necdcd to complete the task.Figure 2 shows a partially completed procedural network.
The node at thehighest level indicates the planner's top-level goal.
which in this case isOo(Ap,r.Loosen(Bolt1.
Wrll)Assume that the apprentice knows that rite part is to be removed, andwants to do the removal, but does not know of a procedure \['or doing it.This situation would hold if the goal marked with an asterisk in figure 2were unsatisfied.
The expert must plan an action to inform ri~e apprenticeof what the desired action is.
This goal expands into an INFORM action.The expert also beiicv~ that the apprentice does not know where thewrench is, and plans another \[NI:ORM action to tell him where it is located.The planner tests d~c ACIIIt:,VE goals to see if it bclicves d~at any of themarc ,already true in die current state of the world.
In the case we arcconsidering Y.AMFS model of the hearer should indicate that he ktlowswhat the bolt is.
and what the wrench is, but doesn't know what the actionis.
i.e.
that he should use that particular wrench to loosen that bolt, and hedoesn't know the location of the wrench.
\[ f  informing actions ~e plannedto satisfy those goals that are not already satisfied; then that part of theplan looks like Figure 3.Each of the INFORM actions is a high-level action that can be expanded.The planner has a set of standard expansions for actions of this type.
Inremoving a particular object (BRACEI) from an air compressor, \[t knowsthat this goal can be achieved by the apprentice xecuting a particularunfastening operation involving a specific wrench and a specific bolt, "ll~eexpert knows that the apprentice can do the action if he knows what theobjects involved in the cask are.
and knows what the action is (i.e.
that heknows how to do the ,action).
This is reflected in the second goal in thesplit path in the procedural network.
Since the plan also requires obtaininga wrench and using it, a goal is also established that tile apprentice knowswhere the wrench is: hence the goal ^ CIllEvE(Know(Apprentice.
On(Table.Wr\].
))).NOAII, these actions were written in SOUP code.
In this planner, they arerepresented in situation-action rules.
The conditional of  the rule involvestests on the type of action to be performed, the hearer's knowledge, andsocial goals.
The action is to select a particular strategy for expanding theaction.
In this case, a rule such as / \[you are expanding an inform of  whatan action involving the hearer as agent is.
then use an IMPERATIVE syntacticconstruct to describe the action.
The planner then inserts the expansionshown in Figure 4 into the plan.~ ~Achilve(KnowWhatls(Al~Dr.Lo~m~(Bolt 1 .Wrl)))IDO( E xoer t.lnformval(A 130r.L0osen(Bo~t I ,Wr 1 )))"%~Acilieve( KnowWhatis ~ Achieve(HgsI II./J Ac hieve(Kn?w('~ pot 'On(Table'Wr I )))III O~( Exp.lntor m(A~pr.OnlTahle.Wr IllI IF igure  3P lann ing  to In fo rmDo(Agtor.
Get(We I)) I61I Dot ExD,int ormV~d(AnDr,Loosen(BoUl .Wrl ))) I)DolExpert.
,~V( "Loo~n "l)Do(Expert, CACT(AgDf.
Wfl)) IN~fF igure  4Expand ing  the  INFORM ActThis sub-plan is marked by a tag indicating that it is to be realized by anUnpcrative.
The split specifics which h)wer level acuons arc performed bythe utterance of the imperative.
At some point, a critic will choose anordering for the actions.
Without further information the scntcncc ouldbe realizcd in any of the following ways, some of which sound strangewhen spoken in islolation:Loosen Boltl with Wrl.With Wrl loosen BOltl.Boltl loosen with Wrl.The first sentence above sounds natural in isolation.
\]'he other two mightbe chosen i f  a critic notic~ a need to realize a focnsmg action that hasbeen plauncd.
For example, the second sentence shiftS thc focus to thewrench instead of the bolt` and would be useful in organizing a series ofinstructions around what tools to use.
The third would be used in adiscourse organized around what object to manipulate aexLUp to this point` the phmning process ilas been quite :;traighdorward, sincenone of the critics have come into piny.
However, since there arc twoINFORM actions on two branches of the same split, thc COMBINE-CONCEPT-ACTIVATION critic is invoked.
This critic is invoked whenever a plancontains a concept activation on one branch of the split, and an inform ofsome property of the activated object on the other branch.
Sometimes theplanner can combine the two informing actions into one by including theproperty description of one of the intbrmmg actS into the description thatis being used for the concept activation.In this particular example, ~ critic would av.,'~h to the Do(Expe~CACT(Appr.. Wri)) action the copetraint that one of the realizing descriptorsmust be ON(Wri.
Table).
and the goal that the apprentice knows thewrench is on the table is marked as already satisfied.Another critic, the REDUNDANT-PATII critic, notices when portions of  twobrances of  a split contain identical actions, and collapses the two branchesinto one.
This critic, when applied to utterance plans will oRen result in asentence with an and conjunction.
The critic is not restricted to apply onlym linguistic actions, and may apply to other types of actions as well.Or.her critics know about acuon subsumption, and what kinds of  focusingactions can be realized in terms of which linguistic choices.
One of theseaction subsumption critics can make a decision about the ordering of theconcept activations, and can mark discourse goals as pha,.
")ms. in U isexample, there are no spccific discourse goalS, so it is pussibtc to chose thedefault verb-object?instrument ordering.On the next next expansion cycle, the concept activations must beexpanded into uttcrances.
This means planning descriptors for the objects.Planning the risht description requires reasoning about what the hearerbelieves about the object` describing it as economically as possible, andthen adding the additional descriptors recommended by the actionsubsumption critic.
The final step is realizing the descriptors in naturallanguage.
Some descriptors have straightforward realizations ,as lexicalitems.
Otbers may require planning a prepositional phrnsc or a relativeclause.IV.
Formally dcfi,ing H);guistic actionsIf actions are to be planned by a planning system, thcy must be definedformally so they can bc used by the system.
This means explicitly statingthe preconditions and effects of each action.
Physical actions havc receivedattention in the literature on planning, but one ~pect of physical actionsLhat has been ignored arc thcir cffccts on kuowlcdgc.
Moorc \[8\] suggestSan approach to formalizing, the km)wicdgc cffccL'; of physEal actions, so \[will not pursue Lhat further at this time.A fairly large amount of work has been done on the formal specification ofspeech acts un the level of informing and requesting, etc.
Most of thiswork has bccn done by Scaric till, and has been incorporatcd into aplanning system by Cohen \[3\].Not much has been done to formally specify the actions of focusing andconcept activation.
Sidncr \[12\] has developed a set of  formal rules fordetecting focus movement in a discourse, and has suggested that these rulescould be translated into an appropriate set of actions that a generationsystem could use.
Since there are a number of well defined strategies thatspeakers use to focus on different topics.
I suggest that the preconditionsand effectS of these strategies could be defined precisely and they can bcincorporated as operators in a planning systcm.
Reichmann \[9J describes anumber of focusing strategies and the situations in which they areapplicable.
The focusing mechanism is driven by the spcakcr's goal thatthe bearer know what is currently being focused on.
Tbis particular typeof knowledge state goal is satisfied by a varicty of different actions.
Theseactions have preconditions which depend on what the current state of thediscourse is, and what type of shift is taking place.Consider the problem of moving the focus back to the previous topic ofdiscussion after a brief digression onto a diEerent hut related topic.Reichmaon pointS out that several actions arc available.
Onc soch action isthe utterance of "anyway'* which signals a more or tcss expected focus~hffL.
She claims that the utterance of  "but" can achieve a similar effect,but is used where the speaker believes that the hearer believes that adiscu~ion on the current topic will continue, and Lhat presupposition needsto be countered.
Each of these two actions will be defincd in the planningsystem as operator.
The ?
'but" operator will have as an additionalprecondition that the hearer believes that the speaker's next uttorance willbe part of the current context.
Both operators will hay= the effect that thehearer believes that the speaker is focusing on the prcvious topic ofdiscussion.Other operators that are available includc cxplicity labeled shifts.
Thisoperator exp.
~ds rata planning an INFORM of a fOCUS shil l  The previousexample of Take John.
for instance, is an example of such an action.The prccLsc logical axiomiuzation of focusing and the prccisc definitions ofeach of these actions is a topic of curre..t research.
The point being madehere is that these focusing actions can bc spccificd formally, One goal ofthis research is to formally describe linguistic actions and other knowledgeproducing actions adequately enough to demonstrate the fcasibility of alanguage plmming system.V.
Current StatusThe K^MP planner described in this paper is in the early stages ofimplementation.
It can solve interesting problems in finding multiple agentplans, and plans involving acquiring and using knowlcge.
It has not bee.applied directly to language yet` but this is the next stcp in research.62Focusing actions need to be described formally, and critics have to bedefined precisely and implemented.
This work is currendy in progress.Although still in its early stages, this approach shows a great deal ofpromise for developing a computer system that is capable of producingutterances that approach the richness that is apparent in even the simplesthuman communication.REFERENCES\[1\] Appelt, Douglas, A Planner for Reasoning about Knowledge mid Belief,Proceedings of the First Conference of the American Association forArtificial Intelligence, 1980.\[2\] Austin, J., How to Do Things with Words, J. O. Urmson (ed.
), OxfordUniversity Pre~ 1962\[3\] Cohen, Philip, On Knowing What to Say: Planning Spech Acts,Technical Report #118.
University of Toronto.
1.978\[4\] Gricc, H. P., Logic and Coversation, in Davidson, cd., The Logic ofGrammar., Dickenson Publishing Co., Encino, California, \[975.\[5\] Grosz, Barbara J., Focusing and Description in Natural LanguageDialogs, in Elements of Discoursc Understanding: Proccedings of aWorkshop on Computational Aspects of Linguistic Structure and DiscourseSetting, A. K. Joshi et al eds., Cambridge University Press.
Cambridge.Ealgland.
1980.\[6\] Halliday, M. A. K., Language Structure and Language Ftmctiol~ inLyons, cd., Ncw Horizons in Linguistics.\[7\] Halliday, M. A. K., Language as Social Semiotic, University Park Press,Baltimore, Md., 1978.\[8\] Moore.
Robert C., Reasoning about Knowledge and Action.
Ph.D.thesis, Massachusetts Institute of Technology.
1979\[9\] Reichman.
Rachel.
Conversational Coherency.
Center for Research inComputing Technology Tochnical Rcport TR-17-78.
Harvard University.1978.\[10\] Sacerdod, Earl, A Structure for Plans and Behavior.
Elsevier North-Holland, Inc.. Amsterdam, The Nedlcriands, 1.977\['l_l\] Searte, John, Speech Acts, Cambridge Univcrsiy Press, 1969\[12\] Sidner, Candace L. Toward a Computational Theory of DefiniteAnaphora Comprehension i English Discourse.
Massichusetts Institute ofTechnology Aritificial Intelligence Laboratory technical note TR-537, 1979.63
