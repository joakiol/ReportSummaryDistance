An Annotat ion  Scheme for Free Word Order LanguagesWojciech Skut, Brigitte Krenn, Thorsten Brants, Hans UszkoreitUniversit /~t des Saar landes66041 Saarbr f icken,  Germa,ny{ skut, krenn, brant s, uszkore?t }@col ?.
un?- sb.
deAbst ractWe describe an annotation scheme and atool developed for creating linguisticallyannotated corpora for non-configurationallanguages.
Since the requirements for sucha formalism differ from those posited forconfigurational languages, several featu-res have been added, influencing the ar-chitecture of the scheme.
The resultingscheme reflects a stratificational notion oflanguage, and makes only minimal assump-tions about the interrelation of the particu-Jar representational strata.1 In t roduct ionThe work reported in this paper aims at provi-ding syntactically annotated corpora ('treebanks')for stochastic grammar induction.
In particular, wefocus on several methodological issues concerningthe annotation of non-configurational l nguages.In section 2, we examine the appropriateness ofexisting annotation schemes.
On the basis of theseconsiderations, we formulate several additional re-quirements.
A formMism conrplying with these re-quirements i described in section 3.
Section 4 dealswith the treatment of selected phenomena.
For adescription of the annotation tool see section 5.2 Mot ivat ion2.1 L inguist ica l ly  In terpreted  CorporaCombining raw language data with linguistic intor-mation offers a promising basis for the developmentof new efficient and robust NLP methods.
Real-world texts annotated with difihrent strata of lin-guistic information can be used for grarninar indue-tion.
The data-drivenness of this approach presentsa clear advantage over tile traditional, idealised no-tion of competence grammar.2.2 Ex is t ing  Treebank  FormatsCorpora annotated with syntactic structures arecommonly referred to as trt:tbauk.~.
Existing tree-bank annotation schemes exhibit a fairly uniformarchitecture, as they all have to meet the same basicrequirements, namely:Descr ip t iv i ty :  GrammaticM phenomena re to bedescribed rather than explained.Theory - independence:  Annotations should notbe influenced by theory-specific considerations.Nevertheless, different heory-specific represen-tations shMl be recoverable from the annota-tion, cf.
(Marcus et al, 1994).Mu l t i - s t ra ta l  representat ion :  Clear separationof different description levels is desirable.Data -dr ivenness :  The scheme must provide repre-sentational means for all phenomena occurringin texts.
Disambiguation is based on humanprocessing skills (cf.
(Marcus et at., 1994),(Sampson, 1995), (Black et al , 1996)).The typical treebank architecture is as follows:S t ructures :  A context-free backboI~e is augmentedwith trace-filler epresentations of non-local de-pendencies.
The underlying argum~.nt s ructureis not represented directly, but can be recoveredfrom the tree and trace-filler ammtations.Syntact i c  category  is encoded in node IM:,els.Gralnmatical  f inctioxls constitute a complex la-bel system (cf.
(Bies et al, 1995), (Sampson,1995)).Par t -o f -Speech  is annotated at word level.Thus the context-li'ee constituent backbone playsa pivotal role in the annotation scherne.
Due tothe substantial differences between existing modelsof constituent structure, tile question arises of howthe theory indcp~ndcnc~, requirement can be satis-fied.
At this point the mlportance of the underlyingargument struc~ur?
: is emphasised (cf.
(Lehmaim etal., 1996), (Marcus et al, 1994), (Sampson, 1995)).2.3 Language-Spec i f i c  FeaturesTreebanks of the tbrmat described ill tile M)ove sec-tion have been designed tbr English.
Tllereff)re, the88solutions they offer are not always optirnal for otherlanguage types.
As for free word order languages,the following features may cause problems:?
local a,nd ram-local dependencies tbrm a con-tinuum rather than clear-cut classes of pheno-mena;?
there exists a rich inventory of discontinuousconstituency types (topicalisation, scrambling,clause union, pied piping, extraposition, splitNPs and PPs);?
word order variation is sensitive to many fac-tors, e.g.
category, syntactic flmction, focus;?
the gramrn~ticMity of different word permuta-tions does not fit the tr~,ditional binary 'right-wrong' pattern; it, rather tbrms a gradual tran-sition between the two poles.In light of these facts, serious difficulties can be ex-pected arising from the structurM component of theexisting formalisms.
Due to the frequency of discon-tinuous constituents in non-eonfigurational l ngua.-ges, the filler-trace mechanism would be used veryoften, yielding syntactic trees fairly different fromthe underlying predicate-argument structures.Consider the German sentence(1) d;tra.n wird ihn Anna.
erkennen, da.t\] er weintat-it will him Anita.
recognise tha.t he cries'Anna.
will recognise Iron a.t his cry'A sample constituent structure is given below:S~S#tAdv~ V NP#2 NP I I V / \daran e#1 wird ihn Anna e#e e#.~ erkennen, dass erweintThe fairly short sentence contains three non-localdependencies, marked by co-references between tra-ces and the corresponding nodes.
This hybrid repre-sentation makes the structure less transparent, andtherefore more difficult to annotate.Apart from this rather technical problem, two fur-ther arguments speak against phrase structure as thestructural pivot of the annotation scheme:?
Phrase structure models stipulated tbr non-configura.tionM languages differ strongly fromeach other, presenting a challenge to the inten-ded theory-independence of the schelne.?
Constituent structure serves as an exl)la.natorydevice for word order variation, which is difficultto reconcile with the descriptivity requirement.Finally, the structural handling of free word or-der means stating well-formedness constraints onstructures involving many trace-filler dependencies,which ha:s proved tedious.
Since most methods ofhandling discontinuous constituents make the for-naalism more powerfifl, the efficiency of processingdeteriorates, too.An Mternative solution is to make argurnent struc-ture the main structural component of the forma-lism.
This assumption underlies a growing num-ber of recent syntactic theories which give up thecontext-free constituent ba.ckbone, cf.
(McCawley,1987), (Dowty, 1989), (Reape, 1993), (Kathol andPollard, 1995).
These approaches provide an ade-quate explanation for several issues problematic ibrphrase-structure grammars (clause union, extrapo-sition, diverse second-position phenomena).2.4 Annotat ing  Argument  S t ructureArgument structure can be represented in terms ofunordered trees (with crossing branches).
In order toreduce their ambiguity potential, rather simple, 'flat'trees should be employed, while more informationcan be expressed by a rich system of function labels.Furthermore, the required theory-independencemeans that the form of syntactic trees should notreflect theory-specific assumptions, e.g.
every syn-tactic structure has a unique hea.d.
Thus, notionssuch as head should be distinguished at the level ofsyntactic flmctions rather than structures.
This re-quirement speaks against he traditional sort of d~:-pendency  trees, in which heads are represented asnon-terminal nodes, cf.
(Hudson, 1984).A tree meeting these requirements i  given below:( , , ) - - -IAdv V NP NP V CPL NP Vdaran wird ihn Anna erkennen, &tss er weintSuch a word order independent representation hasthe advantage of all structural ini'orrrlation being en-coded in a single data structure.
A unifbrm repre-sentation of local and non-local dependencies makesthe structure more transparent 1 .3 The  Annotat ion  Scheme3.1 Arch i tec tureYVe distinguish the tbllowmg levels of representation:1A context-Kee constituent backboIm ca.it still be re-covered fl'mn tile surfa,ce string a.nd a.rgmnent structureby rea, tta,ching 'extra.cted' structures to ;t higher node.89Argument  s t ruc ture ,  represented in terms of un-ordered trees.Grammat ica l  funct ions ,  encoded in edge labels,e.g.
SB (subject), MO (modifier), HD (head).Syntact i c  categor ies ,  expresse(l by category la-bels assigned to non-terminal nodes and bypart-of-speech tags assigned to terlninals.3.2 Argulnent St ructureA structure for (2) is shown in fig.
2.
(2) schade, dM~ kein Arzt anwesend ist, tierpity that no doctor present is whosich auskenntis competent'Pity that no competent doctor is here'Note that the root node does not have a head de-scendant (HD) as the sentence is a predicative con-struction consisting of a subject (SB) and a predi-cate (PD) without a copula.
The subject is itself asentence in which the copula (is 0 does occur and isassigned the tag HD 2.The tree resembles traditional constituent struc-tures.
The difference is its word order independence:structural units ("phrases") need not be contiguoussubstrings.
For instance, the extraposed relativeclause (RC) is still treated as part of the subjectNP.As the annotation scheme does not distinguish dif-ferent bar levels or any similar intermediate catego-ries, only a small set of node labels is needed (cur-rently 16 tags, S, NP, AP .
.
. )
.3.3 Grammat ica l  Funct ionsDue to the rudimentary character of the argumentstructure representations, a great deal of reformationhas to be expressed by gramnlatical functions.
Theirfurther classification must reflect different kinds oflinguistic information: morphology (e.g., case, in-flection), category, dependency type (complementa-tion vs. modification), thematic role, etc.
3However, there is a trade-off between the granu-larity of information encoded in the labels and thespeed and accuracy of annotation.
In order to avoidinconsistencies, the corpus is annotated in two sta-ges: basic annotalion and r'efincment.
While in thefirst phase each annotator has to annotate structuresas well as categories and functions, the refinementcan be done separately for each representation level.During the first, phase, the focus is on almotatingcorrect structures and a coarse-grained classificationof grammatical  functions, which represent the follo-wing areas of information:2CP stands for conwlementizer, OA for accusativeobject and RC for relative clause.
NK denotes a 'kernelNP' component (v. section 4.1).aFor an extensive use of gr;tnllnaticM functions Cf.
(K~trlsson et al, 1995), (Voutilainen, 1994).Dependency  type: complemcnls are fllrther clas-sified according to features su(:h as categoryand case: clausal complements (OC), accusa-tive objects (OA), datives (DA), etc.
Modifiersare assigned the label MO (further classificationwith respect to thematic roles is planned).
Se-parate labels are defined for dependencies thatdo not fit the complement/modifier dichotomy,e.g., pre- (GL) and postnominal genitives (GR).Headedness  versus  non-headedness :Headed and non-headed structures are distin-guished by the presence or absence of a branchlabeled HD.Morpho log ica l  in fo rmat ion :  Another set of la-bels represents morphological information.
PMstands for moTThological partich, a label tbrGerman infinitival zu aml superlative am.
Se-parable verb prefixes are labeled SVP.During the second annotation stage, the annota-tion is enriched with information about, thematic ro-les, quantifier scope and anaphoric ret)rence.
As al-ready mentioned, this is done separately for each ofthe three information areas.3.4 St ructure  Shar ingA phrase or a lexical item can perform multiple func-tions in a sentence.
Consider ~.qui verbs where thesubject of the infinitival VP is not realised syntac-tically, but co-referent with the subject or object ofthe matrix equi verb:(3) er bat reich ZU kolnlnenhe asked me to come(mich is the imderstood subject of komm~.u.).
In suchcases, an additional edge is drawn from tim embed-(led VP node to the controller, thus changing thesyntactic tree into a graph.
We call such additionaledges secondary links and represent hem as dottedlines, see fig.
4, showing the structure of (3).4 Treatment  of Se lected PhenomenaAs theory-independence is one of our objectives, theannotation scheme incorporates a number of widelyaccepted linguistic analyses, especially ill the areaof verbal, adverbial and adjectival syntax.
However,some other s~andard analyse.s turn out to be proMe-marie, mainly due to the partial, idealised characterof competence grammars, which often margmaliseor ignore such important phenolnena s 'deficient'(e.g.
headless) constructions, apl)ositions, temporalexpressions, etc.In the following paragraphs, we give annotationsfor a number of such phenomena.4.1 Noun PhrasesMost linguistic theories treat NPs as structures hea-(led by a unique lexical item (no,m) However, this90idealised model needs severa.l additional assumpti-ons in order to account for such important pheno-mena as complex norninal NP components (cf.
(4))or nominalised a.djectives (of.
(5)).
(4) my uncle Peter Smith(5) tier sehr (41iicklichethe very lta.ppy'tire very ha.pl)y one'In (4), different theories make different headednesspredictions.
In (5), either a lexical nominalisationrule for the adjective Gliicklichc is stipulated, or theexistence of an empty nominal head.
Moreover, theso-called DP analysis views the article der as thehead of the phrase.
Further differences concern thea.ttachment of the degree modifier ,ehr.Because of the intended theory-independence ofthe scheme, we annotate only the cornmon rnini-mum.
We distinguish an NP kernel consisting ofdeterminers, a.djective phrases and nouns.
All com-ponents of this kernel are assigned the label NK amltrea.ted as sibling nodes.The diff>rence between the particular NK's lies inthe positional and part-of-speech information, whichis also sufficient o recover theory-specific structuresfrorn our 'underspecified' representations.
For in-stance, the first determiner among the NK's can betreated as the specifier of the phrase.
The head ofthe phrase can be determined in a similar way ac-cording to theory-specific assumptions.In addition, a number of clear-cut NP componentscan be defined outside that juxtapositional kernel:pre- and postnorninal genitives (GL, GR), relativeclauses (RC), clausal and sentential complements(OC).
They are all treated as siblings of NK's re-gardless of their position (in situ or extraposed).4.2 At taeh lnent  A inbigui t iesAdjunct attachment often gives rise to structuralambiguities or structural uncertainty.
However, fillor partial disambiguation takes place in context, andthe annotators do not consider unrealistic readings.In addition, we have adopted a simple conventionfor those cases in which context information is insuf-ficient f~)r total disaml~iguat,ion: the highest possibleattachment site is chosen.A similar convention has been adopted ibr con-structions in which scope ambiguities ha.ve syntac-tic effe, cts but a. one-to-one correspondence b tweenscope a.nd attachment does not seem reasonable, cf.focus particles such a.s only or also.
If the scope ofsuch a word does not directly correspond to a treenode, the word is attached to the lowest node domi-nating all subconstituents a.pl)earing ill its scope.4.3 Coord inat ionA problem for the rudimentary a.rgument structurerepresentations is tile use of incomplete structuresin natural language, i.e.
t)henornena such as coor-dination and ellipsis.
Since a precise structural de-scription of non-constituent coordination would re-quire a rich inventor.
), of incomplete phrase types, wehave agreed on a sort of nnderspecified representa-tions: the coordinated units are assigned structuresin which missing lexical material is not representedat the level of primary links.
Fig.
3 shows the re-presentation of the sentence:(6) sie wurde van preuliischen Truppen besetztsite was by Prussiaa, troops occupiedund 1887 dem preutlischen Staat angegliedertand 1887 to-the Prussia.n state incorporated'it was occupied by Prussian troops and incorpo-rated into Prussia i,t 1887'The category of the coordination is labeled CVPhere, where C stands for coordination, and VP tarthe actual category.
This extra, marking makes iteasy to distinguish between 'normal' and coordina-ted categories.Multiple coordination as well a.s enumerations areannotated in the same way.
An explicit coordinatingconjunction eed not be present.Structure-sharing is expressed using secondarylinks.5 The  Annotat ion  Too l5.1 RequirenlentsThe development of linguistically interpreted cor-pora, presents a laborious and time-consuming task.In order to make the annotation process more effi-cient, extra effort has been put into the developmentof an annotation tool.The tool supports immediate graphical feedbackand automatic error checking.
Since our scheme per-mits crossing edges, visualisa.tion as bracketing andindentation would be insufficient.
Instead, the con>plete structure should be represented.The tool should also permit a convenient hand-ling of node and edge hd)els.
In particular, variabletagsets and label collections hould be allowed.5.2 Imp lementat io l lAs the need for certain flmctionalities becomes ob-vious with growing annota.tion experience, we havedecided to iml)lement he tool in two stages.
In thefirst phase, the ma.in flmctionality for buihling anddisplaying unordered trees is supplied.
In the se-cond phase, secondary links and additional structu-ral flmctions are supported.
The implementation fthe first phase as described in the following para-graphs is completed.As keyboard input is rnore efficient than mouseinput (cf.
(Lehmalm et al, 1!
)95)) rnost effort hasbeen put in developing an efficient keyboard inter-lace.
Menus are supported as a. usefld way of getting91help on commands and labels.
In addition to pureannotation, we can attach conlments to structures.Figure 1 shows a screen dump of the tool.
Thelargest part of the window contains the graphical re-presentation of tim structure being annot, ate(t. Thetbllowing commands are available:?
group words and/or phrases to a new phrase;?
ungroup a phrase;?
change the name of a phrase or an edge;?
re-attach a node;?
generate the postscript output of a sentence.The three tagsets used by the annotation tool(for words, phrases, and edges) are variable and arestored together with the corpus.
This allows easymodification if needed.
The tool checks the appro-priateness of the input.For the implementation, we used Tc l /Tk  Version4.1.
The corpus is stored in a SQL database.5.3 Automat ionThe degree of automation i creases with the amountof data available.
Sentences annotated in previoussteps are used as training material for further pro-cessing.
We distinguish five degrees of automation:0) Completely manual annotation.1) The user determines phrase boundaries andsyntactic ategories (S, NP, etc.).
The programautomatically assigns grammatical fimetion la-bels.
The annotator can alter the assigned tags.2) The user only determines the conrponents of anew phrase, the program determines its syntac-tic category and the grammatical functions ofits elements.
Again, the annotator has the op-tion of altering the assigned tags.3) Additionally, the program performs simplebracketing, i.e., finds 'kernel' phrases.4) Tile tagger suggests partial or cornplete parses.So far, about 1100 sentences of our corpus havebeen annotated.
This amount of data suffices astraining material to reliably assign the grammaticalfunctions if the user determines the elements of aphrase and its type (step 1 of the list above).5.4 Ass ign ing  GramInat ica l  Funct ionLabelsGrammatical  functions are assigned using standardstatistical part-of-speech tagging methods (cf.
e.g.
(Cutting et al, 1992) and (Feldweg, 1995)).For a phrase Q with children of type T .
.
.
.
.
.
T~:and grammatical fimctions G , , .
.
.
,  (7~:, we use thelexical probabilitiesPO(GiITi)and the contextual (trigram) probabilitiesPQ(T; \[Ti-,, Ti-~ )92The lexical and contextual probabilities are deter-mined separately for each type of phrase.
Duringannotation, the highest rated granmlatical fimctionlabels Gi a.re calculated using the Viterbi algorithnrand a.ssigned to the structure, i.e., we.
<'Mculatekargma.x H PQ(T, IT,-1, ~_~,) .
PQ(G, IT,).G i=1To keep the human annotator from missing errorsmade by the tagger, we additionally calculate thestrongest competitor for each label Gi.
If its pro-bability is close to the winner (closeness is definedby a threshold on the quotient), the assignment isregarded as unreliable, and the annotator is askedto confirm the assignment.For evaluation, the already annota.ted sentenceswere divided into two disjoint sets, one tbr training(90% of the corpus), the other one tbr testing (10%).The procedure was repeated 10 times with differentpartitionings.The tagger ates 90% of all assignments as reliableand carries them out fully automatically.
Accuracyfor these cases is 97%.
Most errors are due to wrongidentification of the subject and different kinds ofobjects in sentences and VPs.
Accuracy of the unre-liable 10% of assignments i  75%, i.e., the annotatorhas to alter the choice in 1 of 4 cases when asked ibrconfirmation.
Overall accuracy of the tagger is 95%.Owing to the partial automation, the average an-notation efficiency improves by 25% (from around 4minutes to 3 minutes per sentence).6 Conc lus ionAs the annotation scheme described ill this paper fo-cusses on annotating argunlent structure rather thanconstituent trees, it differs from existing treebanks inseveral aspects.
These differences can be illustratedby a comparison with the Penn Treeba.nk annotationscheme.
The following features of our fornlMisrn a.rethen of particular importance:* simpler (i.e.
'fiat') representation structures?
complete absence of ernl.
)ty categories?
no special nlechanisnls tbr handling disconti-nuous constituencyThe current tagset conlprises only 16 node labelsand 34 function tags, yet a. finely grained cla.ssifica-tion will take place in the nea.r future.We have argued that the selected approach is bet-ter suited for producing higl, quality interpreted co lpora m languages exhil)iting free constituent order.In general, the resulting interpreted ata also arecloser to semantic annotation and more netltra.l withrespect o particular synta, ctic theories.As modern linguistics is a.lso becorning rnore awareof the irnportance of larger sets of m~turally occur-- General:_Corpus: \[RefCorpus Teslkopie.
IE\]Editor: IThorsten JB, _Parser \ [ -~1 ~ei0ad- Sentence:No.
: 4 / 1269Comment: IOrigin: refcorp.ttLast edited: Thorsten, 07/02/97, 17:39:29lEs o spieltPPER VVFIN509\[~S11eben 2 keine 3 Rolle 's ob die 7 MusR 8 gef"allig 9 ist -,~ nuq2 etwasaADV PlAT NN $, KOUS ART NN ADJD VAFIN $( ADV PlAT6 105O5+Neues mu",, 14 15 16Move:Matches: 0F_Dependency:/ Selection: I !/~ommand:L~i  .__1\[ ~\]I\[ i x.ou,, i-- Paren tlabel:Node no.
:Parent!abel:IlNext I I  Prey 1\ [ '~  JB\[ Switching to sentence no.
4...
Done.
JFigure 1: Screen dump of the annotation toolring data, interpreted corpora, are a valuable re-source for theoreticzd and descriptive linguistic re-search.
In a.ddition the a.t~proach provides empiri-cal material lot psycholinguistic investigation, sincepreferences for the choice of certain syntactic con-structions, linea.rizations, and atta.chments that havebeen observed in online experiments of language pro-duction and comprehension can now be put in rela-tion with the frequency of these alterna,tives m la.rgeramounts of texts.Syntactically a.nnotated corpora of German hazebeen missing until now.
In the second phase of theproject Verbnmbi\] a. treebank for 30,000 Germanspoken sentences a.s well a.s for the S~tllle anlounl, ofEnglish ~md .\]apanese ntences will be created.
Wewill closely coordinate the further develolmlent ofour corpus with the annotation work in Verbmobiland with other German efforts in corpus annotation.Since the combinatorics of syntactic onstructionscrea.tes a demand tbr very large corpora, efficiency ofannotation is an important criterion tbr the successof the developed methodology a.nd tools.
Our anno-tation tool supplies efficient ma.nipulation and im-mediate visualization of argument structures.
Par-tial automation included it, the current version si-gnificantly reduces the manual effort.
Its extensionis subject to fllrther investigations.7 AcknowledgementsThis work is part of the DFG Somlerforschungs-bereich 378 Re.~o'urc~-Adaptrm Coguitiv~, Proc~:s.~e~,Project (;3 Conc,:r'r~',.t Gramm.ar Proces.~ug.We wish to thank Ta,nia, Avgustinova, BertholdCrysmann, La.rs Konieczny, Stephan Oepen, KarelOliva, Christian Wei6 and two anonymous reviewers{'or their help:\[ul comments on the content of thispaper.
We also wish to thank Robert Maclntyreand Ann Taylor for valualde discussions on the PennTreebank annotation.
Special thanks go to Oliver93Plaehn, who implemented the annotation tool, andto our fearless annotators Roland Hendriks, KerstinK15ckner, Thomas Schulz, and Bernd-Paul Simon.ReferencesAnn Bies et al 1995.
BTuck~t, ing Guidelin~:.~ forTreebank H Slyh' Penn Treebank Project.
Techni-cal report, University of Pennsylvania.Ezra Black et al 1996.
Beyond Skeleton Par-sing: Producing a Comprehensive Large-ScaleGeneral-English Treehank With Full Grammati-cal Analysis.
In Th.~: 16th Int.~:rnational Confe-rence on Computal, ional Linguistics, pages 107 -113, Copenhagen, Denmark.Doug Cutting, Julian Kupiec, Jan Pedersen, and Pe-nelope Sibun.
1992.
A practical part-of-speechtagger.
In Procteding~ o.f th( 3rd Confer~nc, ouApplied Natural Language Proc?.ssing (ACL), pa-ges 133-140.David Dowty.
1989.
Towards a minimalist heoryof syntactic structure.
In Tilburg Conference onDiscontinuous Constituency.Helmut Feldweg.
1995.
Implementation a d evalua-tion of a German HMM for POS disambiguation.In Proceedings of EACL-SIGDAT-95 Workshop,Dublin, Ireland.Richard Hudson.
1984.
Word Grammar.
BasilBlackwell Ltd.Fred Karlsson, Atro Voutilainen, J uha Heikkila, andArto Anttila.
1995.
(,'onstrai,.~ G'rammar.
ALanguage-Independent System for Parsing Unre,-slricted Text.
Mouton de Gruyter, Berlin, NewYork.Kathol, Andreas and Carl Pollard.
1995.
Extra.po-sition via Complex Domain Formation.
In P~v-ceedings of the 33 ''~ Annual M~.eting of the: ACL,pages 174-180, C, ambridge, MA.
Association forComputational Linguistics.Sabine Lehmann et al 1996.
TSNLP - Test Sui-tes for Natural Language Processing.
In Th~ 16thlnle't'national (:onf~renc~ on Computational Li~.-guistics, pages 711 - 717, Copenhagen, Denmark.Mitchell Marcus et al 1994.
The Penn Treebank:Annotating Predicate Argument Structure.
InProceedings of lhe Haman Language Technolog:t IWorkshop, San Francisco.
Morgan Kaufmann.James McCawley.
1987.
Some additional evidencefor discontimfity.
In Huck and Ojeda (eds.
), Dis-continuous Const.iluency: Synl.a.v and Semanf.ies,pp 185-200.
New York, Academic Press.Mike Reape.
1993.
A Formal Theory o\] Word Or-d~:r: A Ca.s~ ,gtudy iTt W~st.
G~.r'm.,nw.
PhD.
the-sis, University of Edinburgh.Geoffrey Sampson.
1995.
E,gli.~h \]'or th~ Compu-ter.
The SUSANNE Corp',..~ and Analytic 5'cheme.Clarendon Press, Oxford.Atro Voutilainen.
1994.
Designing a Parsing Gram-mar.
University of Helsinki, Dept.
of General Lin-guistics.
Publications No.
22.94SiePPERE~SchadeADJDwurdeVAFINE~?da"s$.
KOUSFigure 2:ffE Ekein Arzl anwesend ist der sichPlAT NN ADJD VAFIN $, PRELS PRFHeaded a,nd non-hea,ded structures, ext, ral.
)ositionauskennlVVFINvon preu'sischenAPPR ADJA?Truppen besetzt undNN VVPP KON1887 dem preu"sischenCARD ART ADJA+StaatsverbandNNtangegliededWPPFigure.
3: (',oordina,tionEFPPERbatVVFINIIIIreich zu kommenPPER PTKZU VVINFFigure 4: Equi construction95
