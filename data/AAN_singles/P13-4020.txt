Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 115?120,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDevelopment and Analysis of NLP Pipelines in ArgoRafal Rak, Andrew Rowley, Jacob Carter, and Sophia AnaniadouNational Centre for Text MiningSchool of Computer Science, University of ManchesterManchester Institute of Biotechnology131 Princess St, M1 7DN, Manchester, UK{rafal.rak,andrew.rowley,jacob.carter,sophia.ananiadou}@manchester.ac.ukAbstractDeveloping sophisticated NLP pipelinescomposed of multiple processing toolsand components available through differ-ent providers may pose a challenge interms of their interoperability.
The Un-structured Information Management Ar-chitecture (UIMA) is an industry stan-dard whose aim is to ensure such in-teroperability by defining common datastructures and interfaces.
The architec-ture has been gaining attention from in-dustry and academia alike, resulting in alarge volume of UIMA-compliant process-ing components.
In this paper, we demon-strate Argo, a Web-based workbench forthe development and processing of NLPpipelines/workflows.
The workbench isbased upon UIMA, and thus has the poten-tial of using many of the existing UIMAresources.
We present features, and showexamples, of facilitating the distributed de-velopment of components and the analysisof processing results.
The latter includesannotation visualisers and editors, as wellas serialisation to RDF format, which en-ables flexible querying in addition to datamanipulation thanks to the semantic querylanguage SPARQL.
The distributed devel-opment feature allows users to seamlesslyconnect their tools to workflows runningin Argo, and thus take advantage of boththe available library of components (with-out the need of installing them locally) andthe analytical tools.1 IntroductionBuilding NLP applications usually involves a se-ries of individual tasks.
For instance, the ex-traction of relationships between named entitiesin text is preceded by text segmentation, part-of-speech recognition, the recognition of named enti-ties, and dependency parsing.
Currently, the avail-ability of such atomic processing components isno longer an issue; the problem lies in ensur-ing their compatibility, as combining componentscoming from multiple repositories, written in dif-ferent programming languages, requiring differentinstallation procedures, and having incompatibleinput/output formats can be a source of frustrationand poses a real challenge for developers.Unstructured Information Management Archi-tecture (UIMA) (Ferrucci and Lally, 2004) is aframework that tackles the problem of interoper-ability of processing components.
Originally de-veloped by IBM, it is currently an Apache Soft-ware Foundation open-source project1 that is alsoregistered at the Organization for the Advance-ment of Structured Information Standards (OA-SIS)2.
UIMA has been gaining much interest fromindustry and academia alike for the past decade.Notable repositories of UIMA-compliant toolsinclude U-Compare component library3, DKPro(Gurevych et al 2007), cTAKES (Savova etal., 2010), BioNLP-UIMA Component Reposi-tory (Baumgartner et al 2008), and JULIE Lab?sUIMA Component Repository (JCoRe) (Hahn etal., 2008).In this work we demonstrate Argo4, a Web-based (remotely-accessed) workbench for collabo-rative development of text-processing workflows.We focus primarily on the process of developmentand analysis of both individual processing com-ponents and workflows composed of such compo-nents.The next section demonstrates general featuresof Argo and lays out several technical details about1http://uima.apache.org2http://www.oasis-open.org/committees/uima3http://nactem.ac.uk/ucompare/4http://argo.nactem.ac.uk115UIMA that will ease the understanding of the re-maining sections.
Sections 3?5 discuss selectedfeatures that are useful in the development andanalysis of components and workflows.
Section 6mentions related efforts, and Section 7 concludesthe paper.2 Overview of ArgoArgo comes equipped with an ever-growing li-brary of atomic processing components that can beput together by users to form meaningful pipelinesor workflows.
The processing components rangefrom simple data serialisers to complex text an-alytics and include text segmentation, part-of-speech tagging, parsing, named entity recognition,and discourse analysis.Users interact with the workbench through agraphical user interface (GUI) that is accessibleentirely through a Web browser.
Figure 1 showstwo views of the interface: the main, resourcemanagement window (Figure 1(a)) and the work-flow diagramming window (Figure 1(b)).
Themain window provides access to emphdocuments,workflows, and processes separated in easily ac-cessible panels.The Documents panel lists primarily user-owned files that are uploaded (through the GUI)by users into their respective personal spaces onthe remote host.
Documents may also be gener-ated as a result of executing workflows (e.g., XMLfiles containing annotations), in which case theyare available for users to download.The Workflows panel lists users?
workflows,i.e., the user-defined arrangements of processingcomponents together with their settings.
Userscompose workflows through a flexible, graphi-cal diagramming editor by connecting the com-ponents (represented as blocks) with lines signi-fying the flow of data between components (seeFigure 1(b)).
The most common arrangement is toform a pipeline, i.e., each participating componenthas at most one incoming and at most one out-going connection; however, the system also sup-ports multiple branching and merging points in theworkflow.
An example is shown in Figure 2 dis-cussed farther in text.
For ease of use, componentsare categorized into readers, analytics, and con-sumers, indicating what role they are set to play ina workflow.
Readers are responsible for deliveringdata for processing and have only an outgoing port(represented as a green triangle).
The role of an-(a) Workflow management view(b) Worflow diagram editor viewFigure 1: Screenshots of Argo Web browser con-tent.alytics is to modify incoming data structures andpass them onto following components in a work-flow, and thus they have both incoming and outgo-ing ports.
Finally, the consumers are responsiblefor serialising or visualising (selected or all) anno-tations in the data structures without modification,and so they have only an incoming port.The Processes panel lists resources that are cre-ated automatically when workflows are submit-ted for execution by users.
Users may follow theprogress of the executing workflows (processes) aswell as manage the execution from this panel.
Theprocessing of workflows is carried out on remoteservers, and thus frees users from using their ownprocessing resources.2.1 Argo and UIMAArgo supports and is based upon UIMA and thuscan run any UIMA-compliant processing compo-nent.
Each such component defines or importstype systems and modifies common annotationstructures (CAS).
A type system is the represen-116tation of a data model that is shared between com-ponents, whereas a CAS is the container of datawhose structure complies with the type system.
ACAS stores feature structures, e.g., a token withits text boundaries and a part-of-speech tag.
Fea-ture structures may, and often do, refer to a sub-ject of annotation (Sofa), a structure that (in text-processing applications) stores the text.
UIMAcomes with built-in data types including primitivetypes (boolean, integer, string, etc.
), arrays, lists,as well as several complex types, e.g., Annotationthat holds a reference to a Sofa the annotation isasserted about, and two features, begin and end,for marking boundaries of a span of text.
A devel-oper is free to extend any of the complex types.2.2 ArchitectureAlthough the Apache UIMA project provides animplementation of the UIMA framework, Argoincorporates home-grown solutions, especially interms of the management of workflow processing.This includes features such as workflow branchingand merging points, user-interactive components(see Section 4), as well as distributed processing.The primary processing is carried out on amulti-core server.
Additionally, in order to in-crease computing throughput, we have incorpo-rated cloud computing capabilities into Argo,which is designed to work with various cloudcomputing providers.
As a proof of concept,the current implementation uses HTCondor, anopen-source, high-throughput computing softwareframework.
Currently, Argo is capable of switch-ing the processing of workflows to a local clusterof over 3,000 processor cores.
Further extensionsto use the Microsoft Azure5 and Amazon EC26cloud platforms are also planned.The Argo platform is available entirely us-ing RESTful Web services (Fielding and Taylor,2002), and therefore it is possible to gain accessto all or selected features of Argo by implement-ing a compliant client.
In fact, the ?native?
Webinterface shown in Figure 1 is an example of sucha client.3 Distributed DevelopmentArgo includes a Generic Listener component thatpermits execution of a UIMA component that isrunning externally of the Argo system.
It is pri-5http://www.windowsazure.com6http://aws.amazon.com/ec2marily intended to be used during the develop-ment of processing components, as it allows a de-veloper to rapidly make any necessary changes,whilst continuing to make use of the existing com-ponents available within Argo, which may other-wise be unavailable if developing on the devel-oper?s local system.
Any component that a userwishes to deploy on the Argo system has to un-dergo a verification process, which could lead toa slower development lifecycle without the avail-ability of this component.Generic Listener operates in a reverse mannerto a traditional Web service; rather than Argo con-necting to the developer?s component, the compo-nent connects to Argo.
This behaviour was de-liberately chosen to avoid network-related issues,such as firewall port blocking, which could be-come a source of frustration to developers.When a workflow, containing a Generic Lis-tener, is executed within Argo, it will continueas normal until the point at which the GenericListener receives its first CAS object.
Argo willprompt the user with a unique URL, which mustbe supplied to the client component run by theuser, allowing it to connect to the Argo workflowand continue its execution.A skeleton Java project has been provided to as-sist in the production of such components.
It con-tains a Maven structure, Eclipse IDE project files,and required libraries, in addition to a number ofshell scripts to simplify the running of the compo-nent.
The project provides both a command-lineinterface (CLI) and GUI runner applications thattake, as arguments, the name of the class of the lo-cally developed component and the URL providedby Argo, upon each run of a workflow containingthe remote component.An example of a workflow with a Generic Lis-tener is shown in Figure 2.
The workflow is de-signed for the analysis and evaluation of a solu-tion (in this case, the automatic extraction of bio-logical events) that is being developed locally bythe user.
The reader (BioNLP ST Data Reader)provides text documents together with gold (i.e.,manually created) event annotations prepared forthe BioNLP Shared Task7.
The annotations areselectively removed with the Annotation Removerand the remaining data is sent onto the GenericListener component, and consequently, onto thedeveloper?s machine.
The developer?s task is to7http://2013.bionlp-st.org/117Figure 2: Example of a workflow for development,analysis, and evaluation of a user-developed solu-tion for the BioNLP Shared Task.connect to Argo, retrieve CASes from the run-ning workflow, and for each CAS recreate the re-moved annotations as faithfully as possible.
Thedeveloper can then track the performance of theirsolution by observing standard information ex-traction measures (precision, recall, etc.)
com-puted by the Reference Evaluator component thatcompares the original, gold annotations (comingfrom the reader) against the developer?s annota-tions (coming from the Generic Listener), andsaves these measures for each document/CAS intoa tabular-format file.
Moreover, the differencescan be tracked visually though the interactive BratBioNLP ST Comparator component, discussed inthe next section.4 Annotation Analysis and ManipulationTraditionally, NLP pipelines (including existingUIMA-supporting platforms), once set up, areexecuted without human involvement.
One ofthe novelties in Argo is an introduction of user-interactive components, a special type of analyticthat, if present in a workflow, cause the execu-tion of the workflow to pause.
Argo resumes theexecution only after receiving input from a user.This feature allows for manual intervention in theotherwise automatic processing by, e.g., manipu-lating automatically created annotations.
Exam-ples of user-interactive components include Anno-tation Editor and Brat BioNLP ST Comparator.The Brat BioNLP ST Comparator componentFigure 3: Example of an annotated fragment ofa document visualised with the Brat BioNLP STComparator component.
The component high-lights (in red and green) differences between twosources of annotations.Figure 4: Example of manual annotation with theuser-interactive Annotation Editor component.expects two incoming connections from compo-nents processing the same subject of annotation.As a result, using brat visualisation (Stenetorp etal., 2012), it will show annotation structures bylaying them out above text and mark differencesbetween the two inputs by colour-coding missingor additional annotations in each input.
A sam-ple of visualisation coming from the workflow inFigure 2 is shown in Figure 3.
Since in this par-ticular workflow the Brat BioNLP ST Comparatorreceives gold annotations (from the BioNLP STData Reader) as one of its inputs, the highlighteddifferences are, in fact, false positives and falsenegatives.Annotation Editor is another example of a user-interactive component that allows the user to add,delete or modify annotations.
Figure 4 shows theeditor in action.
The user has an option to cre-ate a span-of-text annotation by selecting a textfragment and assigning an annotation type.
Morecomplex annotation types, such as tokens withpart-of-speech tags or annotations that do not re-fer to the text (meta-annotations) can be createdor modified using an expandable tree-like struc-ture (shown on the right-hand side of the figure),which makes it possible to create any annotation118(a) Select queryneAText neACat neBText neBCat countKi-67 Protein p53 Protein 85DC CellType p53 Protein 61DC CellType KCOT Protein 47(b) Results (fragment)(c) Insert queryFigure 5: Example of (a) a SPARQL query that returns biological interactions; (b) a fragment of retrievedresults; and (c) a SPARQL query that creates new UIMA feature structures.
Namespaces and data typesare omitted for brevity.structure permissible by a given type system.5 Querying Serialised DataArgo comes with several (de)serialisation com-ponents for reading and storing collections ofdata, such as a generic reader of text (DocumentReader) or readers and writers of CASes in XMIformat (CAS Reader and CAS Writer).
One ofthe more useful in terms of annotation analysisis, however, the RDF Writer component as wellas its counterpart, RDF Reader.
RDF Writer se-rialises data into RDF files and supports severalRDF formats such as RDF/XML, Turtle, and N-Triple.
A resulting RDF graph consists of both thedata model (type system) and the data itself (CAS)and thus constitutes a self-contained knowledgebase.
RDF Writer has an option to create a graphfor each CAS or a single graph for an entire collec-tion.
Such a knowledge base can be queried withlanguages such as SPARQL8, an official W3CRecommendation.Figure 5 shows an example of a SPARQL querythat is performed on the output of an RDF Writerin the workflow shown in Figure 1(b).
This work-flow results in several types of annotations in-cluding the boundaries of sentences, tokens withpart-of-speech tags and lemmas, chunks, as wellas biological entities, such as DNA, RNA, cellline and cell type.
The SPARQL query is meantto retrieve pairs of seemingly interacting biolog-ical entities ranked according to their occurrencein the entire collection.
The interaction here is(na?
?vely) defined as co-occurrence of two entitiesin the same sentence.
The query includes pat-terns for retrieving the boundaries of sentences(syn:Sentence) and two biological entities(sem:NamedEntity) and then filters out thecrossproduct of those by ensuring that the two en-8http://www.w3.org/TR/2013/REC-sparql11-overview-20130321/119tities are enclosed in a sentence.
As a result, thequery returns a list of biological entity pairs ac-companied by their categories and the number ofappearances, as shown in Figure 5(b).
Note thatthe query itself does not list the four biological cat-egories; instead, it requests their common seman-tic ancestor sem:NamedEntity.
This is one ofthe advantages of using semantically-enabled lan-guages, such as SPARQL.SPARQL also supports graph manipulation.Suppose a user is interested in placing the re-trieved biological entity interactions from our run-ning example into the UIMA structure Relation-ship that simply defines a pair of references toother structures of any type.
This can be accom-plished, without resorting to programming, by is-suing a SPARQL insert query shown in Figure5(c).
The query will create triple statements com-pliant with the definition of Relationship.
The re-sulting modified RDF graph can then be read backto Argo by the RDF Reader component that willconvert the new RDF graph back into a CAS.6 Related WorkOther notable examples of NLP platforms thatprovide graphical interfaces for managing work-flows include GATE (Cunningham et al 2002)and U-Compare (Kano et al 2010).
GATE isa standalone suite of text processing and annota-tion tools and comes with its own programminginterface.
In contrast, U-Compare?similarly toArgo?uses UIMA as its base interoperabilityframework.
The key features of Argo that distin-guish it from U-Compare are the Web availabil-ity of the platform, primarily remote processingof workflows, a multi-user, collaborative architec-ture, and the availability of user-interactive com-ponents.7 ConclusionsArgo emerges as a one-stop solution for develop-ing and processing NLP tasks.
Moreover, the pre-sented annotation viewer and editor, performanceevaluator, and lastly RDF (de)serialisers are in-dispensable for the analysis of processing tasksat hand.
Together with the distributed develop-ment support for developers wishing to create theirown components or run their own tools with thehelp of resources available in Argo, the workbenchbecomes a powerful development and analyticalNLP tool.AcknowledgmentsThis work was partially funded by the MRC TextMining and Screening grant (MR/J005037/1).ReferencesW A Baumgartner, K B Cohen, and L Hunter.
2008.An open-source framework for large-scale, flexibleevaluation of biomedical text mining systems.
Jour-nal of biomedical discovery and collaboration, 3:1+.H Cunningham, D Maynard, K Bontcheva, andV Tablan.
2002.
GATE: A framework and graphicaldevelopment environment for robust NLP tools andapplications.
In Proceedings of the 40th Anniver-sary Meeting of the Association for ComputationalLinguistics.D Ferrucci and A Lally.
2004.
UIMA: An Ar-chitectural Approach to Unstructured InformationProcessing in the Corporate Research Environment.Natural Language Engineering, 10(3-4):327?348.R T Fielding and R N Taylor.
2002.
Principled de-sign of the modern Web architecture.
ACM Trans.Internet Technol., 2(2):115?150, May.I Gurevych, M Mu?hlha?user, C Mu?ller, J Steimle,M Weimer, and T Zesch.
2007.
Darmstadt knowl-edge processing repository based on uima.
In Pro-ceedings of the First Workshop on UnstructuredInformation Management Architecture, Tu?bingen,Germany.U Hahn, E Buyko, R Landefeld, M Mu?hlhausen,M Poprat, K Tomanek, and J Wermter.
2008.
AnOverview of JCORE, the JULIE Lab UIMA Compo-nent Repository.
In Language Resources and Eval-uation Workshop, Towards Enhanc.
InteroperabilityLarge HLT Syst.
: UIMA NLP, pages 1?8.Y Kano, R Dorado, L McCrochon, S Ananiadou, andJ Tsujii.
2010.
U-Compare: An integrated languageresource evaluation platform including a compre-hensive UIMA resource library.
In Proceedings ofthe Seventh International Conference on LanguageResources and Evaluation, pages 428?434.G K Savova, J J Masanz, P V Ogren, J Zheng, S Sohn,K C Kipper-Schuler, and C G Chute.
2010.
Mayoclinical Text Analysis and Knowledge ExtractionSystem (cTAKES): architecture, component evalua-tion and applications.
Journal of the American Med-ical Informatics Association, 17(5):507?513.P Stenetorp, S Pyysalo, G Topic?, T Ohta, S Ananiadou,and J Tsujii.
2012. brat: a web-based tool for nlp-assisted text annotation.
In Proceedings of the 13thConference of the European Chapter of the Associa-tion for Computational Linguistics, pages 102?107,Avignon, France.120
