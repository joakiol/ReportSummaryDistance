Felix Bildhauer & Roland Sch?fer (eds.
), Proceedings of the 9th Web as Corpus Workshop (WaC-9) @ EACL 2014, pages 29?35,Gothenburg, Sweden, April 26 2014.c?2014 Association for Computational Linguistics{bs,hr,sr}WaC ?
Web corpora of Bosnian, Croatian and SerbianNikola Ljube?si?cUniversity of ZagrebIvana Lu?ci?ca 3, 10000 Zagreb, Croatianljubesi@ffzg.hrFilip Klubi?ckaUniversity of ZagrebIvana Lu?ci?ca 3, 10000 Zagreb, Croatiafklubick@ffzg.hrAbstractIn this paper we present the constructionprocess of top-level-domain web corporaof Bosnian, Croatian and Serbian.
Forconstructing the corpora we use the Spi-derLing crawler with its associated toolsadapted for simultaneous crawling andprocessing of text written in two scripts,Latin and Cyrillic.
In addition to the mod-ified collection process we focus on twosources of noise in the resulting corpora:1. they contain documents written in theother, closely related languages that cannot be identified with standard languageidentification methods and 2. as most webcorpora, they partially contain low-qualitydata not suitable for the specific researchand application objectives.
We approachboth problems by using language mod-eling on the crawled data only, omittingthe need for manually validated languagesamples for training.
On the task of dis-criminating between closely related lan-guages we outperform the state-of-the-artBlacklist classifier reducing its error to afourth.1 IntroductionBuilding web corpora for various NLP tasks hasbecome quite a standard approach, especially iffunding is limited and / or there is need for largeamounts of textual data.Although off-the-shelf solutions for compilingweb corpora have emerged recently, there are stillspecific challenges that have to be addressed inmost corpus construction processes.
One suchchallenge that we face while constructing the cor-pora described in this paper is simultaneous us-age of two scripts on two out of three top-leveldomains (TLDs) crawled.Additionally, there are still many open ques-tions and possibilities for improvement in theprocess of collecting data as well as data post-processing.
We address two of the latter kind ?discrimination between similar, neighboring lan-guages that are used on all selected TLDs, andthe question of text quality in corpora collected insuch a fully automated fashion.In the paper we present the process of buildingweb corpora of Bosnian, Croatian and Serbian bycrawling the .ba, .hr and .rs TLDs.
The threelanguages belong to the South Slavic languagebranch and are very similar to each other.
Thebiggest differences between Croatian and Serbianare the proto-Slavic vowel jat (Croatian ?covjekvs.
Serbian ?covek), way of handling proper nouns(Croatian New York vs. Serbian Nju Jork), specificsyntactic constructions (Croatian ho?cu raditi vs.Serbian ho?cu da radim) and a series of lexical dif-ferences (Croatian mrkva vs. Serbian ?sargarepa).Bosnian is mostly seen as a mixture of those twoand allows, beside its own lexical specificities, so-lutions from one or both languages.1This paper is structured as follows: in Section2 we give an overview of related work regardingexisting (web) corpora of the languages in ques-tion, language identification and web text qualityestimation.
Section 3 shows the process of col-lecting the three TLD corpora with emphasis onthe problem of collecting data written in variousscripts, while in Section 4 we describe the linguis-tic annotation layers added to the corpora.
Section5 depicts our approach to discriminating betweenvery similar languages while in Section 6 we de-scribe our approach to identifying documents oflow text quality, and both approaches use recentlycrawled data only.1A more thorough comparison of the three lan-guages is available at http://en.wikipedia.org/wiki/Comparison_of_standard_Bosnian,_Croatian_and_Serbian292 Related workThe only two South Slavic languages for whichweb corpora were previously built are Croatianand Slovene (Ljube?si?c and Erjavec, 2011).
TheCroatian corpus presented in this paper is actuallyan extension of the existing corpus, representingits second version.
hrWaC v1.0 was, until now,the biggest available corpus of Croatian.For Bosnian, almost no corpora are availableexcept the SETimes corpus2, which is a 10-languages parallel corpus with its Bosnian sideconsisting of 2.2 million words, and The OsloCorpus of Bosnian Texts3, which is a 1.5 mil-lion words corpus consisting of different genres oftexts that were published in the 1990s.For the Serbian language, until now, the largestcorpus was the SrpKor corpus4, consisting of 118million words that are annotated with part-of-speech information (16 tags) and lemmatized.
Thecorpus is available for search through an interfacefor non-commercial purposes.Until now, no large freely downloadable cor-pora of Bosnian and Serbian were available, andthis was one of the strongest motivations for ourwork.Multiple pipelines for building web corporawere described in many papers in the last decade(Baroni et al., 2009; Ljube?si?c and Erjavec, 2011;Sch?afer and Bildhauer, 2012), but, to the best ofour knowledge, only one pipeline is freely avail-able as a complete, ready-to-use tool: the Brnopipeline (Suchomel and Pomik?alek, 2012), con-sisting of the SpiderLing crawler5, the Chared en-coding detector6, the jusText content extractor7and the Onion near-deduplicator8.
Although wehave our own pipeline set up (this is the pipelinethe first versions of hrWaC and slWaC were builtwith), we decided to compile these versions ofweb corpora with the Brno pipeline for two rea-sons: 1. to inspect the pipeline?s capabilities, and2.
to extend the Croatian web corpus as much aspossible by using a different crawler.Although language identification is seen as a2http://nlp.ffzg.hr/resources/corpora/setimes/3http://www.tekstlab.uio.no/Bosnian/Corpus.html4http://tinyurl.com/mocnzna5http://nlp.fi.muni.cz/trac/spiderling6https://code.google.com/p/chared/7http://code.google.com/p/justext/8http://code.google.com/p/onion/solved problem by many, the recently growing in-terest for it indicates the opposite.
Recently, re-searchers focused on improving off-the-shelf toolsfor identifying many languages (Lui and Bald-win, 2012), discriminating between similar lan-guages where standard tools fail (Tiedemann andLjube?si?c, 2012), identifying documents written inmultiple languages and identifying the languagesin such multilingual documents (Lui et al., 2014).Text quality in automatically constructed webcorpora is quite an underresearched topic, with theexception of boilerplate removal / content extrac-tion approaches that deal with this problem implic-itly (Baroni et al., 2008; Kohlsch?utter et al., 2010),but quite drastically, by removing all content thatdoes not conform to the criteria set.
A recent ap-proach to assessing text quality in web corpora inan unsupervised manner (Sch?afer et al., 2013) cal-culates the weighted mean and standard deviationof n most frequent words in a corpus sample andmeasures how much a specific document deviatesfrom the estimated means.
This approach is in itsbasic idea quite similar to ours because it assumesthat most of the documents in the corpus containcontent of good quality.
The main difference inour approach is that we do not constrain ourselvesto most frequent words as features, but use char-acter and word n-grams of all available text.3 Corpus constructionFor constructing the corpora we used the Spi-derLing crawler9along with its associated toolsfor encoding guessing, content extraction, lan-guage identification and near-duplicate removal(Suchomel and Pomik?alek, 2012).
Seed URLsfor Bosnian and Serbian were obtained via theGoogle Search API queried with bigrams of mid-frequency terms.
Those terms were obtained fromcorpora that were built with focused crawls ofnewspaper sites as part of our previous research(Tiedemann and Ljube?si?c, 2012).
For Croatianseed URLs, we used the home pages of web do-mains obtained during the construction of the firstversion of the hrWaC corpus.
The number of seedURLs was 8,388 for bsWaC, 11,427 for srWaCand 14,396 for hrWaC.
Each TLD was crawled for21 days with 16 cores used for document process-ing.Because Serbian ?
which is frequently used onthe Serbian and Bosnian TLDs ?
uses two scripts9http://nlp.fi.muni.cz/trac/spiderling30?
Latin and Cyrillic ?
we had to adjust the stan-dard corpus construction process to cope with bothscripts.
This was done by 1. building new two-script models for encoding guessing with Chared,2.
defining stop-words used in content extractionin both scripts and 3. transforming extracted textfrom Cyrillic to Latin with serbian.py10beforeperforming language identification and duplicateremoval.
We kept all content of the final corpora inthe Latin script to simplify further processing, es-pecially because linguistic annotation layers wereadded with models developed for Croatian whichuses the Latin script exclusively.
The informationabout the amount of Cyrillic text in each documentis still preserved as an attribute of the <doc> el-ement.
Overall the percentage of documents writ-ten >90% in the Cyrillic script was 3.2% on theBosnian TLD and 16.7% on the Serbian TLD.Near-duplicate identification was performedboth on the document and the paragraph level.The document-level near-duplicates were removedfrom the corpus cutting its size in half, whileparagraph-level near-duplicates were labeled bythe neardupe binary attribute in the <p> el-ement enabling the corpus users to decide whatlevel of near-duplicate removal suits their needs.The resulting size of the three corpora (in mil-lions of tokens) after each of the three duplicate re-moval stages is given in Table 1.
Separate numbersare shown for the new crawl of the Croatian TLDand the final corpus consisting of both crawls.PHYS DOCN PARNbsWaC 1.0 722 429 288hrWaC new 1,779 1,134 700hrWaC 2.0 2,686 1,910 1,340srWaC 1.0 1,554 894 557Table 1: Size of the corpora in Mtokens after phys-ical duplicate (PHY), document near-duplicate(DOCN) and paragraph near-duplicate removal(PARN)At this point of the corpus construction processthe <doc> element contained the following at-tributes:?
domain ?
the domain the document is pub-lished on (e.g.
zkvh.org.rs)?
url ?
the URL of the document10http://klaus.e175.net/code/serbian.py?
crawl_date ?
date the document wascrawled?
cyrillic_num ?
number of Cyrillic let-ters in the document?
cyrillic_perc ?
percentage of lettersthat are Cyrillic4 Corpus annotationWe annotated all three corpora on the level oflemmas, morphosyntactic description (675 tags)and dependency syntax (15 tags).
Lemmatiza-tion was performed with the CST?s Lemmatiser11(Jongejan and Dalianis, 2009), morphosyntactictagging with HunPos12(Hal?acsy et al., 2007) anddependency syntax with mate-tools13(Bohnet,2010).
All models were trained on the Croa-tian 90k-token annotated corpus SETimes.HR14(Agi?c and Ljube?si?c, 2014) that we recently ex-panded with 50k additional tokens from vari-ous newspaper domains (at this point we callit simply SETimes.HR+).
Although the anno-tated training corpora are Croatian, previous re-search (Agi?c et al., 2013a; Agi?c et al., 2013b) hasshown that on this level of tagging accuracy onin-domain test sets (lemma?96%, morphosyntac-tic description (MSD) ?87%, labeled attachmentscore (LAS) ?73%), annotating Serbian text withmodels trained on Croatian data produced perfor-mance loss of only up to 3% on all three levelsof annotation, while on out-of-domain test sets(lemma ?92%, MSD ?81%, LAS ?65%) therewas no loss in accuracy.We nevertheless performed an intervention inthe SETimes.HR+ corpus before training the mod-els used for annotating the Bosnian and the Ser-bian TLD corpora.
Namely, on the morphosyn-tactic level the tagsets of Croatian and Serbianare identical, except for one subset of tags forthe future tense which is present in Serbian andnot present in Croatian.
This is because Croatianuses the complex, analytic future tense consistingof the infinitive of the main verb and the presenttense of the auxiliary verb have (radit ?cemo) whileSerbian uses both the analytic and the syntheticform where the two words are conflated into one(radi?cemo).11https://github.com/kuhumcst/cstlemma12https://code.google.com/p/hunpos/13https://code.google.com/p/mate-tools/14http://nlp.ffzg.hr/resources/corpora/setimes-hr/31To enable models to correctly handle both theanalytic and synthetic form of the future tense,we simply repeated the sentences containing theanalytic form that we automatically transformedto the synthetic one.
By annotating the bsWaCand srWaC corpora with the models trained onthe modified SETimes.HR+ corpus, we annotated610k word forms in srWaC and 115k word formsin bsWaC with the synthetic future tense.
Manualinspection showed that most of the tokens actuallydo represent the future tense, proving that the in-tervention was well worth it.The lemmatization and morphosyntactic anno-tation of all three corpora took just a few hourswhile the full dependency parsing procedure on 40server grade cores took 25 days.5 Language identificationBecause each of the three languages of interest isused to some extent on each of the three TLDs and,additionally, these languages are very similar, dis-criminating between them presented both a neces-sity and a challenge.In previous work on discriminating betweenclosely related languages, the Blacklist (BL) clas-sifier (Tiedemann and Ljube?si?c, 2012) has shownto be, on a newspaper-based test set, 100% accu-rate in discriminating between Croatian and Ser-bian, and 97% accurate on all three languages ofinterest.Our aim at this stage was twofold: 1. to put theexisting BL classifier on a realistic test on (noisy)web data and 2. to propose an alternative, simple,data-intense, but noise-resistant method which canbe used for discriminating between closely relatedlanguages or language varieties that are predomi-nantly used on specific sections of the Web.Our method (LM1) uses the whole content ofeach of the three TLD web corpora (so largeamounts of automatically collected, noisy data) tobuild unigram-level language models.
Its advan-tage over the BL classifier is that it does not re-quire any clean, manually prepared samples fortraining.
The probability estimate for each word wgiven the TLD, using add-one smoothing is this:?P (w|TLD) =c(w, TLD) + 1?wi?V(c(wi, TLD) + 1)(1)where c(w, TLD) is the number of times word woccurred on the specific TLD and V is the vocab-ulary defined over all TLDs.We perform classification on each document asa maximum-a-posteriori (MAP) decision, i.e.
wechoose the language of the corresponding TLD(l ?
TLD) that produces maximum probabilitywith respect to words occurring in the document(w1...wn):lmap= argmaxl?TLD?i=1..n?P (wi|l) (2)We should note here that our approach is identi-cal to using the Na?
?ve Bayes classifier without thea priori probability for each class, i.e.
language.Speaking in loose terms, what we do is that foreach document of each TLD, we identify, on theword level, to which TLD data collection the doc-ument corresponds best.Because Bosnian is mostly a mixture of Croat-ian and Serbian and actually represents a contin-uum between those two languages, we decidedto compare the BL and the LM1 classifier on amuch more straight-forward task of discriminat-ing between Croatian and Serbian.
The results ofclassifying each document with both classifiers aregiven in Table 2.
They show that both classifiersagree on around 75% of decisions and that around0.4 percent of documents from hrWaC are identi-fied as Serbian and 1.5 percent of document fromsrWaC as Croatian.BL LM1 agreementhrWaC 0.42% 0.3% 73.15%srWaC 1.93 % 1.28% 80.53%Table 2: Percentage of documents identified byeach classifier as belonging to the other languageWe compared the classifiers by manually in-specting 100 random documents per corpus wherethe two classifiers were not in agreement.
The re-sults of this tool-oriented evaluation are presentedin Table 3 showing that the LM1 classifier pro-duced the correct answer in overall 4 times morecases than the BL classifier.If we assume that the decisions where the twoclassifiers agree are correct (and manual inspec-tion of data samples points in that direction) wecan conclude that our simple, data-intense, noise-resistant LM1 method cuts the BL classificationerror to a fourth.
We consider a more thoroughevaluation of the two classifiers, probably by pool-ing and annotating documents that were identified32BL LM1 NAhrWaC 18% 62% 20%srWaC 10% 48% 42%Table 3: Percentage of correct decisions of eachclassifier on documents where the classifiers dis-agreed (NA represents documents that are a mix-ture of both languages)as belonging to the other TLD language by someclassifier, as future work.Due to the significant reduction in error by theLM1 classifier, we annotated each document in thehrWaC and srWaC corpora with the LM1 binaryhr-sr language identifier while on bsWaC we usedthe LM1 ternary bs-hr-sr classifier.
This decisionis based on the fact that discriminating between allthree languages is very hard even for humans andthat for most users the hr-sr discrimination on thetwo corpora will be informative enough.
In eachdocument we encoded the normalized distributionof log-probabilities for the considered languages,enabling the corpus user to redefine his own lan-guage criterion.The percentage of documents from each corpusbeing identified as a specific language is given inTable 4.bs hr srbsWaC 78.0% 16.5% 5.5%hrWaC - 99.7% 0.3%srWaC - 1.3% 98.7%Table 4: Distribution of identified languagesthroughout the three corporaAdditional attributes added to the <doc> ele-ment during language identification are these:?
lang ?
language code of the language iden-tified by maximum-a-posteriori?
langdistr ?
normalized distri-bution of log probabilities of lan-guages taken under consideration (e.g.bs:-0.324|hr:-0.329|sr:-0.347for a document from bsWaC)6 Identifying text of low qualityFinally, we tackled the problem of identifying doc-uments of low text quality in an unsupervisedmanner by assuming that most of the content ofeach web corpus is of good quality and that lowquality content can be identified as data pointsof lowest probability regarding language modelsbuilt on the whole data collection.
We pragmati-cally define low quality content as content not de-sirable for a significant number of research or ap-plication objectives.For each TLD we calculated character n-gramand word n-gram language models in the samemanner as in the previous section (Equation 1) forlanguage identification.
We scored each TLD doc-ument with each language model that was built onthat TLD.
To get a probability estimate which doesnot depend on the document length, we calculatedprobabilities of subsequences of identical lengthand computed the average of those.We manually inspected documents with lowprobability regarding character n-gram modelsfrom level 1 to level 15 and word n-gram mod-els from level 1 to level 5.
Word n-gram mod-els proved to be much less appropriate for cap-turing low quality documents by lowest probabil-ity scores than character n-gram models.
Amongcharacter n-gram models, 3-gram models wereable to identify documents with noise on the tokenlevel while 12-gram models assigned low proba-bilities to documents with noise above the tokenlevel.The most frequent types of potential noisefound in lowest scored documents in all three cor-pora are the following:?
3-gram models?
non-standard usage of uppercase, lower-case and punctuation?
URL-s?
uppercase want ads?
formulas?
12-gram models?
words split into multiple words (due tosoft hyphen usage or HTML tags insidewords)?
enumerated and bulleted lists?
uppercase want ads?
non-standard text (slang, no uppercasedwords, emoticons)?
dialects?
lyric, epic, historical texts33The character 3-gram method has additionallyproven to be a very good estimate of text quality onthe lexical level by strongly correlating (0.74) withthe knowledge-heavy method of calculating lexi-cal overlap of each document with a morphologi-cal dictionary which is available for Croatian15.An interesting finding is that word-level modelsperform much worse for this task than character-level models.
We hypothesize that this is due tofeature space sparsity on the word level which ismuch lower on the character level.We decided to postpone any final decisions (likediscretizing these two variables and defining oneor two categorical ones) and therefore encodedboth log-probabilities as attributes in each doc-ument element in the corpus leaving to the fi-nal users to define their own cut-off criteria.
Tomake that decision easier, for each document andeach character n-gram method we computed thepercentage of documents in the corpus that havean equal or lower result of that character n-grammethod.
This makes removing a specific percent-age of documents with lowest scores regarding amethod much easier.We also computed one very simple estimate oftext quality ?
the percentage of characters that arediacritics.
Namely, for some tasks, like lexicon en-richment, working on non-diacritized text is not anoption.
Additionally, it is to expect that lower us-age of diacritics points to less standard languageusage.
The distribution of this text quality esti-mate in the hrWaC corpus (all three corpora fol-low the same pattern) is depicted in Figure 1 show-ing that the estimate is rather normally distributedwith a small peak at value zero representing non-diacritized documents.In each <doc> element we finally encoded 5attributes regarding text quality:?
3graph ?
average log-probability on 100-character sequences regarding the character3-gram model trained on the whole TLD cor-pus?
3graph_cumul ?
percentage of documentswith equal or lower 3graph attribute value?
12graph ?
same as 3graph, but computedwith the character 12-gram model?
12graph_cumul ?
like 3graph_cumul,but for the 12graph attribute15http://bit.ly/1mRjMrPPercentage of diacriticsFrequency0.00 0.02 0.04 0.06 0.08 0.10050000100000150000Figure 1: Distribution of the percentage of charac-ters of a document being diacritics?
diacr_perc ?
percentage of non-whitespace characters that are diacriticsWe plan to perform extrinsic evaluation of thethree estimates of text quality on various NLPtasks such as language modeling for statisticalmachine translation, morphological lexicon induc-tion, distributional lexicon induction of closely re-lated languages and multi-word expression extrac-tion.7 ConclusionIn this paper we described the process of con-structing three TLD corpora of Bosnian, Croatianand Serbian.After presenting the construction and annota-tion process of the largest existing corpora foreach of the three languages, we focused on theissue that all three languages are to some extentused on all three TLDs.
We presented a methodfor discriminating between similar languages thatis based on unigram language modeling on thecrawled data only, which exploits the fact that themajority of the data published on each TLD iswritten in the language corresponding to that TLD.We reduced the error of a state-of-the-art classifierto a fourth on documents where the two classifiersdisagree on.We dealt with the problem of identifying lowquality content as well, again using language mod-eling on crawled data only, showing that documentprobability regarding a character 3-gram model isa very good estimate of lexical quality, while low34character 12-gram probabilities identify low qual-ity documents beyond the word boundary.We encoded a total of 12 attributes in the docu-ment element and the paragraph-near-duplicate in-formation in the paragraph element enabling eachuser to search for and define his own criteria.We plan on experimenting with those attributeson various tasks, from language modeling for sta-tistical machine translation, to extracting variouslinguistic knowledge from those corpora.AcknowledgementThe research leading to these results has re-ceived funding from the European Union Sev-enth Framework Programme FP7/2007-2013 un-der grant agreement no.
PIAP-GA-2012-324414(project Abu-MaTran).References[Agi?c and Ljube?si?c2014]?Zeljko Agi?c and NikolaLjube?si?c.
2014.
The SETimes.HR linguisticallyannotated corpus of Croatian.
In Proceedings ofLREC 2014.
[Agi?c et al.2013a]?Zeljko Agi?c, Nikola Ljube?si?c, andDanijela Merkler.
2013a.
Lemmatization and mor-phosyntactic tagging of Croatian and Serbian.
InProceedings of the 4th Biennial International Work-shop on Balto-Slavic Natural Language Processing,pages 48?57, Sofia, Bulgaria, August.
Associationfor Computational Linguistics.
[Agi?c et al.2013b]?Zeljko Agi?c, Danijela Merkler, andDa?sa Berovi?c.
2013b.
Parsing Croatian and Serbianby using Croatian dependency treebanks.
In Pro-ceedings of the Fourth Workshop on Statistical Pars-ing of Morphologically Rich Languages (SPMRL2013).
[Baroni et al.2008] Marco Baroni, Francis Chantree,Adam Kilgarriff, and Serge Sharoff.
2008.Cleaneval: a competition for cleaning web pages.In Proceedings of the Sixth International LanguageResources and Evaluation (LREC?08), Marrakech,Morocco.
European Language Resources Associa-tion (ELRA).
[Baroni et al.2009] Marco Baroni, Silvia Bernardini,Adriano Ferraresi, and Eros Zanchetta.
2009.
TheWaCky wide web: a collection of very large linguis-tically processed web-crawled corpora.
LanguageResources and Evaluation, pages 209?226.
[Bohnet2010] Bernd Bohnet.
2010.
Very high accuracyand fast dependency parsing is not a contradiction.In The 23rd International Conference on Computa-tional Linguistics (COLING 2010).
[Hal?acsy et al.2007] P?eter Hal?acsy, Andr?as Kornai, andCsaba Oravecz.
2007.
HunPos: an open sourcetrigram tagger.
In Proceedings of the 45th An-nual Meeting of the ACL on Interactive Poster andDemonstration Sessions, ACL ?07, pages 209?212,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.
[Jongejan and Dalianis2009] Bart Jongejan and Her-cules Dalianis.
2009.
Automatic training of lemma-tization rules that handle morphological changes inpre-, in- and suffixes alike.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP, pages145?153.
[Kohlsch?utter et al.2010] Christian Kohlsch?utter, PeterFankhauser, and Wolfgang Nejdl.
2010.
Boilerplatedetection using shallow text features.
In Brian D.Davison, Torsten Suel, Nick Craswell, and Bing Liu,editors, WSDM, pages 441?450.
ACM.
[Ljube?si?c and Erjavec2011] Nikola Ljube?si?c andToma?z Erjavec.
2011. hrWaC and slWac: Com-piling Web Corpora for Croatian and Slovene.
InText, Speech and Dialogue - 14th InternationalConference, TSD 2011, Pilsen, Czech Republic,Lecture Notes in Computer Science, pages 395?402.Springer.
[Lui and Baldwin2012] Marco Lui and Timothy Bald-win.
2012. langid.py: An off-the-shelf languageidentification tool.
In ACL (System Demonstra-tions), pages 25?30.
[Lui et al.2014] Marco Lui, Jey Han Lau, and TimothyBaldwin.
2014.
Automatic detection and languageidentification of multilingual documents.
Transac-tions of the Association for Computational Linguis-tics.
[Sch?afer and Bildhauer2012] Roland Sch?afer and FelixBildhauer.
2012.
Building large corpora from theweb using a new efficient tool chain.
In Proceed-ings of the Eight International Conference on Lan-guage Resources and Evaluation (LREC?12), Istan-bul, Turkey.
European Language Resources Associ-ation (ELRA).
[Sch?afer et al.2013] Roland Sch?afer, Adrien Barbaresi,and Felix Bildhauer.
2013.
The good, the bad, andthe hazy: Design decisions in web corpus construc-tion.
In Proceedings of the 8th Web as Corpus Work-shop (WAC8).
[Suchomel and Pomik?alek2012] V?
?t Suchomel and JanPomik?alek.
2012.
Efficient web crawling for largetext corpora.
In Serge Sharoff Adam Kilgarriff, edi-tor, Proceedings of the seventh Web as Corpus Work-shop (WAC7), pages 39?43, Lyon.
[Tiedemann and Ljube?si?c2012] J?org Tiedemann andNikola Ljube?si?c.
2012.
Efficient discrimination be-tween closely related languages.
In Proceedings ofCOLING 2012, pages 2619?2634, Mumbai, India.35
