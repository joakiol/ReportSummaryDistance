Workshop on Monolingual Text-To-Text Generation, pages 1?9,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1?9,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsLearning to Simplify Sentences Using WikipediaWilliam CosterComputer Science DepartmentPomona Collegewpc02009@pomona.eduDavid KauchakComputer Science DepartmentPomona Collegedkauchak@cs.pomona.eduAbstractIn this paper we examine the sentence sim-plification problem as an English-to-Englishtranslation problem, utilizing a corpus of137K aligned sentence pairs extracted byaligning English Wikipedia and Simple En-glish Wikipedia.
This data set contains thefull range of transformation operations includ-ing rewording, reordering, insertion and dele-tion.
We introduce a new translation modelfor text simplification that extends a phrase-based machine translation approach to includephrasal deletion.
Evaluated based on threemetrics that compare against a human refer-ence (BLEU, word-F1 and SSA) our new ap-proach performs significantly better than twotext compression techniques (including T3)and the phrase-based translation system with-out deletion.1 IntroductionIn this paper we examine the sentence simplifica-tion problem: given an English sentence we aim toproduce a simplified version of that sentence withsimpler vocabulary and sentence structure whilepreserving the main ideas in the original sentence(Feng, 2008).
The definition what a ?simple?
sen-tence is can vary and represents a spectrum of com-plexity and readability.
For concreteness, we useSimple English Wikipedia1 as our archetype of sim-plified English.
Simple English Wikipedia arti-cles represent a simplified version of traditional En-glish Wikipedia articles.
The main Simple English1http://simple.wikipedia.orgWikipedia page outlines general guidelines for cre-ating simple articles:?
Use Basic English vocabulary and shorter sen-tences.
This allows people to understand nor-mally complex terms or phrases.?
Simple does not mean short.
Writing in SimpleEnglish means that simple words are used.
Itdoes not mean readers want basic information.Articles do not have to be short to be simple;expand articles, add details, but use basic vo-cabulary.The data set we examine contains aligned sen-tence pairs of English Wikipedia2 with Simple En-glish Wikipedia (Coster and Kauchak, 2011; Zhuet al, 2010).
We view the simplification problemas an English-to-English translation problem: givenaligned sentence pairs consisting of a normal, un-simplified sentence and a simplified version of thatsentence, the goal is to learn a sentence simplifica-tion system to ?translate?
from normal English tosimplified English.
This setup has been successfullyemployed in a number of text-to-text applications in-cluding machine translation (Och and Ney, 2003),paraphrasing (Wubben et al, 2010) and text com-pression (Knight and Marcu, 2002; Cohn and Lap-ata, 2009).Table 1 shows example sentence pairs from thealigned data set.
One of the challenges of text sim-plification is that, unlike text compression where theemphasis is often on word deletion, text simplifica-2http://en.wikipedia.org/1a.
Normal: Greene agreed that she could earn more by breaking away from 20th Century Fox.Simple: Greene agreed that she could earn more by leaving 20th Century Fox.b.
Normal: The crust and underlying relatively rigid mantle make up the lithosphere.Simple: The crust and mantle make up the lithosphere.c.
Normal: They established themselves here and called that port Menestheus?s port.Simple: They called the port Menestheus?s port.d.
Normal: Heat engines are often confused with the cycles they attempt to mimic.Simple: Real heat engines are often confused with the ideal engines or cycles they attemptto mimic.e.
Normal: In 1962 , Steinbeck received the Nobel Prize for Literature.Simple: Steinbeck won the Nobel Prize in Literature in 1962.Table 1: Example aligned sentences from English Wikipedia and Simple English Wikipedia.
Normal refers an EnglishWikipedia sentence and Simple to a corresponding Simple English Wikipedia sentence.tion involves the full range of transformation opera-tions:deletion: ?underlying relatively rigid?
in b., ?es-tablished themselves here and?
in c. and the commain d.rewording: ?breaking away from?
?
?leaving?
ina.
and ?received?
?
?won?
in e.reordering: in e. ?in 1962?
moves from the be-ginning of the sentence to the end.insertion: ?ideal engines or?
in d.Motivated by the need to model all of these dif-ferent transformations, we chose to extend a statis-tical phrase-based translation system (Koehn et al,2007).
In particular, we added phrasal deletion to theprobabilistic translation model.
This addition broad-ens the deletion capabilities of the system since thebase model only allows for deletion within a phrase.As Kauchak and Coster (2011) point out, deletion isa frequently occurring phenomena in the simplifica-tion data.There are a number of benefits of text simplifica-tion research.
Much of the current text data avail-able including Wikipedia, news articles and mostweb pages are written with an average adult readeras the target audience.
Text simplification can makethis data available to a broader range of audiences in-cluding children, language learners, the elderly, thehearing impaired and people with aphasia or cogni-tive disabilities (Feng, 2008; Carroll et al, 1998).Text simplification has also been shown to improvethe performance of other natural language process-ing applications including semantic role labeling(Vickrey and Koller, 2008) and relation extraction(Miwa et al, 2010).2 Previous WorkMost previous work in the area of sentence simpli-fication has not been from a data-driven perspec-tive.
Feng (2008) gives a good historical overviewof prior text simplification systems including earlyrule-based approaches (Chandrasekar and Srinivas,1997; Carroll et al, 1998; Canning et al, 2000) anda number of commercial approaches.
Vickrey andKoller (2008) and Miwa et al (2010) employ textsimplification as a preprocessing step, though bothuse manually generated rules.Our work extends recent work by Zhu et al(2010) that also examines Wikipedia/Simple En-glish Wikipedia as a data-driven, sentence simpli-fication task.
They propose a probabilistic, syntax-based approach to the problem and compare againsta baseline of no simplification and a phrase-basedtranslation approach.
They show improvementswith their approach on target-side only metrics in-cluding Flesch readability and n-gram languagemodel perplexity, but fail to show improvements fortheir approach on evaluation metrics that compareagainst a human reference simplification.
In con-trast, our approach achieves statistically significantimprovements for three different metrics that com-pare against human references.Sentence simplification is closely related to the2problem of sentence compression, another English-to-English translation task.
Knight and Marcu(2002) were one of the first to formalize textcompression as a data-driven problem and pro-posed a probabilistic, noisy-channel model and de-cision tree-based model for compression.
Galleyand McKeown (2007) show improvements to thenoisy-channel approach based on rule lexicaliza-tion and rule Markovization.
Recently, a numberof approaches to text compression have been pro-posed that score transformation rules discrimina-tively based on support vector machines (McDonald,2006; Cohn and Lapata, 2009) and conditional ran-dom fields (Nomoto, 2007; Nomoto, 2008) insteadof using maximum likelihood estimation.
With theexception of Cohn and Lapata (2009), all of thesetext compression approaches make the simplifyingassumption that the compression process happensonly via word deletion.
We provide comparisonswith some of these systems, however, for text sim-plification where lexical changes and reordering arefrequent, most of these techniques are not appropri-ate.Our proposed approach builds upon approachesemployed in machine translation (MT).
We intro-duce a variant of a phrase-based machine translationsystem (Och and Ney, 2003; Koehn et al, 2007) fortext simplification.
Although MT systems that em-ploy syntactic or hierarchical information have re-cently shown improvements over phrase-based ap-proaches (Chiang, 2010), our initial investigationwith syntactically driven approaches showed poorerperformance on the text simplification task and wereless robust to noise in the training data.Both English Wikipedia and Simple EnglishWikipedia have received recent analysis as a pos-sible corpus by for both sentence compression andsimplification.
Yamangil and Nelken (2008) exam-ine the history logs of English Wikipedia to learnsentence compression rules.
Yatskar et al (2010)learn a set of candidate phrase simplification rulesbased on edit changes identified in both Wikipediasrevision histories, though they only provide a listof the top phrasal rules and do not utilize them inan end-to-end simplification system.
Napoles andDredze (2010) provide an analysis of the differencesbetween documents in English Wikipedia and Sim-ple English Wikipedia, though they do not view thedata set as a parallel corpus.3 Text Simplification CorpusFew data sets exist for text simplification and datasets for the related task of sentence compressionare small, containing no more than a few thousandaligned sentence pairs (Knight and Marcu, 2002;Cohn and Lapata, 2009; Nomoto, 2009).
For this pa-per, we utilized a sentence-aligned corpus generatedby aligning English Wikipedia with Simple EnglishWikipedia resulting in 137K aligned sentence pairs.This data set is larger than any previously examinedfor sentence simplification and orders of magnitudelarger than those previously examined for sentencecompression.We give a brief overview of the corpus generationprocess here.
For more details and an analysis of thedata set, see (Coster and Kauchak, 2011).
Through-out this article we will refer to English Wikipediaarticles/sentences as normal and Simple EnglishWikipedia articles as simple.We aligned the normal and simple articles at thedocument level based on exact match of the title andthen removed all article pairs that were stubs, dis-ambiguation pages, meta-pages or only contained asingle line.
Following a similar approach to pre-vious monolingual alignment techniques (Barzilayand Elhadad, 2003; Nelken and Shieber, 2006), wethen aligned each simple paragraph to any normalparagraph that had a normalized TF-IDF cosine sim-ilarity above a set threshold.
These aligned para-graphs were then aligned at the sentence level usinga dynamic programming approach, picking the bestsentence-level alignment from a combination of thefollowing sentence-level alignments:?
normal sentence inserted?
normal sentence deleted?
one normal sentence to one simple sentence?
two normal sentences to one simple sentence?
one normal sentence to two simple sentenceFollowing Nelken and Shieber (2006), we used TF-IDF cosine similarity to measure the similarity be-tween aligned sentences and only kept aligned sen-tence pairs with a similarity threshold above 0.5.
We3found this thresholding approach to be more intu-itive than trying to adjust a skip (insertion or dele-tion) penalty, which has also been proposed (Barzi-lay and Elhadad, 2003).4 Simplification ModelGiven training data consisting of aligned normal-simple sentence pairs, we aim to produce a trans-lation system that takes as input a normal Englishsentence and produces a simplified version of thatsentence.
Motivated by the large number and im-portance of lexical changes in the data set, we choseto use a statistical phrase-based translation system.We utilized a modified version of Moses, which wasoriginally developed for machine translation (Koehnet al, 2007).Moses employs a log-linear model, which can beviewed as an extension of the noisy channel modeland combines a phrase-based translation model, ann-gram language model, as well as a number of othermodels/feature functions to identify the best transla-tion/simplification.
The key component of Mosesis the phrase-based translation model which decom-poses the probability calculation of a normal sen-tence simplifying to a simple sentence as the productof individual phrase translations:p(simple|normal) =m?i=1p(s?i|n?i)where each s?i is a phrase (one or more contigu-ous words) in the simple sentence and s?1, s?2, ..., s?mexactly cover the simple sentence.
n?i are simi-larly defined over the normal sentence.
p(s?i|n?i)denotes the probability of a normal phrase beingtranslated/simplified to the corresponding simpli-fied phrase.
These phrasal probabilities are ex-tracted from the sentence pairs based on an EM-learned word alignment using GIZA++ (Och andNey, 2000).Phrase-based models in machine translation of-ten require that both phrases in the phrasal prob-abilities contain one or more words, since phrasaldeletion/insertion is rare and can complicate the de-coding process.
For text simplification, however,phrasal deletion commonly occurs: 47% of the sen-tence pairs contain deletions (Coster and Kauchak,2011).
To model this deletion, we relax the restric-tion that the simple phrase must be non-empty andinclude in the translation model probabilistic phrasaldeletion rules of the form p(NULL|n?i) allowing forphrases to be deleted during simplification.To learn these phrasal deletions within Moses,we modify the original word alignment output fromGIZA++ before learning the phrase table entries intwo ways:1.
If one or more contiguous normal words areunaligned in the original alignment, we alignthem to NULL appropriately inserted on thesimple side2.
If a set of normal words N all align to a singlesimple word s and there exists an n ?
N wheren = s then for all n?
?
N : n?
6= n we alignthem to NULL.This second modification has two main benefits.Frequently, if a word occurs in both the normal andsimple sentence and it is aligned to itself, no otherwords should be aligned to that word.
As othershave noted, this type of spurious alignment is partic-ularly prevalent with function words, which tend tooccur in many different contexts (Chen et al, 2009).Second, even in situations where it may be appro-priate for multiple words to align to a single word(for example, in compound nouns, such as PresidentObama ?
Obama), removing the alignment of theextra words, allows us to delete those words in othercontexts.
We lose some specificity with this adap-tation because some deletions can now occur inde-pendent of context, however, empirically this modi-fication provides more benefit than hindrance for themodel.
We conjecture that the language model helpsavoid these problematic cases.Table 2 shows excerpts from an example sentencepair before the alignment alteration and after.
In theoriginal alignment ?, aka Rodi?
is unaligned.
Af-ter the alignment processing, the unaligned phraseis mapped to NULL allowing for the possibility oflearning a phrasal deletion entry in the phrase table.We also modified the decoder to appropriately han-dle NULL mappings during the translation process.Table 3 shows a sample of the phrasal deletionrules learned.
These rules and probabilities werelearned by the original phrase-table generation code4Normal: Sergio Rodriguez Garcia , aka Rodri , is a spanish footballer ...Simple: Sergio Rodriguez Garcia is a spanish football player ...Modified Simple: Sergio Rodriguez Garcia NULL is a spanish football player ...Table 2: Example output from the alignment modification step to capture phrasal deletion.
Words that are verticallyaligned are aligned in the word alignment.Phrase-table entry prob, ?
NULL 0.057the ?
NULL 0.033of the ?
NULL 0.0015or ?
NULL 0.0014however , ?
NULL 0.00095the city of ?
NULL 0.00034generally ?
NULL 0.00033approximately ?
NULL 0.00025, however , ?
NULL 0.00022, etc ?
NULL 0.00013Table 3: Example phrase-table entries learned from thedata and their associated probability.of Moses after the word alignment was modified.The highest probability rules tend to delete punctua-tion and function words, however, other phrases alsoappeared.
0.5% of the rules learned during trainingare deletion rules.5 ExperimentsWe compared five different approaches on the textsimplification task:none: Does no simplification.
Outputs the normal,unsimplified sentence.K & M: Noisy-channel sentence compression sys-tem described in Knight and Marcu (2002).T3: Synchronous tree substitution grammar,trained discriminatively (Cohn and Lapata, 2009).Moses: Phrase-based, machine translation ap-proach (Koehn et al, 2007).Moses+Del: Our approach described in Section 4which is a phrase-based approach with the additionof phrasal deletion.From the aligned data set of 137K sentence pairs,we used 124K for training and 1,300 for testingwith the remaining 12K sentences used during de-velopment.
We trained the n-gram language modelused by the last four systems on the simple side ofthe training data.3 T3 requires parsed data whichwe generated using the Stanford parser (Klein andManning, 2003).
Both Moses and Moses+Del weretrained using the default Moses parameters and weused the last 500 sentence pairs from the training setto optimize the hyper-parameters of the log-linearmodel for both Moses variants.
T3 was run with thedefault parameters.Due to runtime and memory issues, we were un-able to run T3 on the full data set.4 We thereforepresent results for T3 trained on the largest train-ing set that completed successfully, the first 30Ksentence pairs.
This still represents a significantlylarger training set than T3 has been run on previ-ously.
For comparison, we also provide results be-low for Moses+Del trained on the same 30K sen-tences.5.1 EvaluationSince there is no standard way of evaluating textsimplification, we provide results for three differentautomatic methods, all of which compare the sys-tem?s output to a reference simplification.
We usedBLEU (Papineni et al, 2002), which is the weightedmean of n-gram precisions with a penalty for brevity.It has been used extensively in machine translationand has been shown to correlate well with humanperformance judgements.We also adopt two automatic measures that havebeen used to evaluate text compression that com-pare the system?s output to a reference translation3See (Turner and Charniak, 2005) for a discussion of prob-lems that can occur for text compression when using a languagemodel trained on data from the uncompressed side.4On 30K sentences T3 took 4 days to train.
On the full dataset, we ran T3 for a week and at that point the discriminativetraining was using over 100GB of memory and we terminatedthe run.5System BLEU word-F1 SSAnone 0.5937 0.5967 0.6179K & M 0.4352 0.4352 0.4871T3* 0.2437 0.2190 0.3651Moses 0.5987 0.6076 0.6224Moses+Del 0.6046 0.6149 0.6259Table 4: Performance of the five approaches on the testdata.
All differences in performance are statistically sig-nificant.
* - T3 was only trained on 30K sentence pairsfor performance reasons.
(Clarke and Lapata, 2006): simple string accuracymeasure (a normalized version of edit distance, ab-breviated SSA) and F1 score calculated over words.We calculated F1 over words instead of grammaticalrelations (subject, direct/indirect object, etc.)
sincefinding the relation correspondence between the sys-tem output and the reference is a non-trivial task forsimplification data where reordering, insertions andlexical changes can occur.
Clarke and Lapata (2006)showed a moderate correlation with human judge-ment for SSA and a strong correlation for the F1measure.To measure whether the difference between sys-tem performance is statistically significant, we usebootstrap resampling with 100 samples with the t-test (Koehn, 2004).5.2 ResultsTable 4 shows the results on the test set for the dif-ferent evaluation measures.
All three of the evalu-ation metrics rank the five systems in the same or-der with Moses+Del performing best.
All differ-ences between the systems are statistically signifi-cant for all metrics at the p = 0.01 level.
One of thechallenges for the sentence simplification problemis that, like sentence compression, not making anychanges to the system produces reasonable results(contrast this with machine translation).
In the testset, 30% of the simple sentences were the same asthe corresponding normal sentence.
Because of this,we see that not making any changes (none) performsfairly well.
It is, however, important to leave thesesentences in the test set, since not all sentences needsimplification and systems should be able to handlethese sentences appropriately.Both of the text compression systems performpoorly on the text simplification task with resultsthat are significantly worse than doing nothing.
Bothof these systems tended to bias towards modifyingthe sentences (T3 modified 77% of the sentences andK & M 96%).
For K & M, the poor results are notsurprising since the model only allows for deletionoperations and is more tailored to the compressiontask.
Although T3 does allow for the full range ofsimplification operations, it was often overly aggres-sive about deletion, for example T3 simplified:There was also a proposal for an extensionfrom Victoria to Fulham Broadway stationon the district line , but this was not in-cluded in the bill .to ?it included .?
Overall, the output of T3 aver-aged 13 words per sentence, which is significantlylower than the gold standard?s 21 words per sen-tence.
T3 also suffered to a lesser extent from inap-propriately inserting words/phrases, which other re-searchers have also noted (Nomoto, 2009).
Some ofthese issues were a results of T3?s inability to copewith noise in the test data, both in the text or theparses.Both Moses and Moses+Del perform better thanthe text compression systems as well as the baselinesystem, none.
If we remove those sentences in thetest set where the simple sentence is the same as thenormal sentence and only examine those sentenceswhere a simplification should occur, the differencebetween the phrase-based approaches and none iseven more significant with BLEU scores of 0.4560,0.4723 and 0.4752, for none, Moses and Moses+Delrespectively.If we compare Moses and Moses+Del, the ad-dition of phrasal deletion results in a statisticallysignificant improvement.
The phrasal deletion wasa common operation in the simplifications madeby Moses+Del; in 8.5% of the test sentences,Moses+Del deleted at least one phrase.
To better un-derstand this performance difference, Table 5 showsthe BLEU scores for sentences where each respec-tive system made a change (i.e.
the output simpli-fication is different than the input).
In both cases,when the systems make simplifications on sentencesthat should be simplified, we see large gains in theoutput over doing nothing.
While Moses improvesover the baseline of doing nothing by 0.047 BLEU,6BLEUSystem Case none outputMosescorrect change 0.4431 0.4901incorrect change 1 0.8625Moses+Delcorrect change 0.4087 0.4788incorrect change 1 0.8706Table 5: BLEU scores for Moses and Moses+Del on sen-tences where the system made a change.
?correct change?shows the score where a change was made by the systemas well as in the reference and ?incorrect change?
wherea change was made by the system, but not the reference.we see an even larger gain by Moses+Del with a dif-ference of 0.07 BLEU.For completeness, we also trained Moses+Del onthe same 30K sentences used to train the T3 sys-tem.5 Using this training data, Moses+Del achieveda BLEU score of 0.5952.
This is less than the scoreachieved when using the full training data, but is sig-nificantly better than T3 and still represents a smallimprovement over none.Table 6 shows example simplifications made byMoses+Del.
In many of the examples we see phrasaldeletion during the simplification process.
The out-put also contains a number of reasonable lexicalchanges, for example in a, d and e. Example bcontains reordering and e shows an example of asplit being performed where the normal sentence isturned into two simplified sentences.
This is not un-common in the data, but can be challenging to modelfor current syntactic approaches.
The examples alsohighlight some of the common issues with the ap-proach.
Examples a and f are not grammatically cor-rect and the simplification in f does not preserve theoriginal meaning of the text.
As an aside, the normalsentence of example d also contains an omission er-ror following ?as?
due to preprocessing of the data,resulting from ill-formed xml in the articles.5.3 OracleIn the previous section, we looked at the perfor-mance of the systems based on the best translationssuggested by the systems.
For many approaches, wecan also generate an n-best list of possible transla-tions.
We examined the simplifications in this n-5To be completely consistent with T3, we used the first29,700 pairs for training and the last 300 for parameter tuning.BLEUSystem original oracleMoses 0.5987 0.6317Moses+Del 0.6046 0.6421Table 7: BLEU score for the original system versus thebest possible ?oracle?
translations generated by greedilyselecting the best translation from an n-best list based onthe reference simplification.best list to measure the potential benefit of rerankingtechniques, which have proved successful in manyNLP applications (Och et al, 2004; Ge and Mooney,2006), and to understand how well the underlyingmodel captures the phenomena exhibited in the data.For both of the phrase-based approaches, we gener-ated an n-best list of size 1000 for each sentence inthe test set.
Using these n-best lists, we generatedan ?oracle?
simplification of the test set by greed-ily selecting for each test sentence the simplificationin the n-best list with the best sentence-level BLEUscore.Table 7 shows the BLEU scores for the originalsystem output and the system?s oracle output.
In allcases, there is a large difference between the sys-tem?s current output and the oracle output, suggest-ing that utilizing some reranking technique could beuseful.
Also, we again see the benefit of the phrasaldeletion rules.
The addition of the phrasal dele-tion rule gives the system an additional dimensionof flexibility, resulting in a more varied n-best listand an overall higher oracle BLEU score.6 Conclusions and Future WorkIn this paper, we have explored a variety of ap-proaches for learning to simplify sentences fromWikipedia.
In contrast to prior work in the relatedfield of sentence compression where deletion playsthe dominant role, the simplification task we exam-ined has the full range of text-to-text operations in-cluding lexical changes, reordering, insertions anddeletions.We implemented a modified phrase-based sim-plification approach that incorporates phrasal dele-tion.
Our approach performs significantly betterthan two different text compression approaches, in-cluding T3, and better than previous approaches ona similar data set (Zhu et al, 2010).
We also showed7a.
normal: Critical reception for The Wild has been negative.simplified: Reviews for The Wild has been negative.b.
normal: Bauska is a town in Bauska county , in the Zemgale region of southern Latvia .simplified: Bauska is a town in Bauska county , in the region of Zemgale .c.
normal: LaBalme is a commune in the Ain department in eastern France .simplified: LaBalme is a commune .d.
normal: Shadow of the Colossus , released in Japan as , is a Japanese-developed action-adventure video game developed and published by Sony computer entertainmentfor the Playstation 2.simplified: Shadow of the Colossus is a Japanese-developed action-adventure video gamemade by Sony computer entertainment for the Playstation 2.e.
normal: Nicolas Anelka is a French footballer who currently plays as a striker for Chelseain the English premier league .simplified: Nicolas Anelka is a French football player .
He plays for Chelsea .f.
normal: Each edge of a tesseract is of the same length.simplified: Same edge of the same length.Table 6: Example simplifications.
?normal?
is the the unsimplified input sentence and ?simplified?
the simplificationmade by Moses+Del.that the incorporation of phrasal deletion into thesimplification process results in statistically signif-icant improvements over a traditional phrase-basedapproach.While we obtained positive results using a phrase-based approach, we still believe that incorporatingsome additional hierarchical structure will help thesimplification process, particularly since one of thegoals of simplification is to reduce the grammaticalcomplexity of the sentence.
Also, as seen in someof the examples above, the phrase-based model canproduce output that is not grammatically correct.Though T3 did not perform well, many other syntax-based models exists that have been successful in ma-chine translation.There are a number of research questions moti-vated by this work in related areas including the scal-ability of discriminative trained rule sets, the impactof the language model training source (simple vs.normal English), document-level simplification andapplications of text simplification.
Our hope is thatthis new simplification task will spur a variety of re-lated research inquiries.AcknowledgmentsWe?d like to thank Dan Feblowitz for his insightsand discussions, and for generating the results forthe K & M implementation.ReferencesRegina Barzilay and Noemie Elhadad.
2003.
Sentencealignment for monolingual comparable corpora.
InProceedings of EMNLP.Yvonne Canning, John Tait, Jackie Archibald, and RosCrawley.
2000.
Cohesive generation of syntacticallysimplified newspaper text.
In Proceedings of TSD.John Carroll, Gido Minnen, Yvonne Canning, SiobhanDevlin, and John Tait.
1998.
Practical simplificationof English newspaper text to assist aphasic readers.
InProceedings of AAAI Workshop on Integrating AI andAssistive Technology.Raman Chandrasekar and Bangalore Srinivas.
1997.
Au-tomatic induction of rules for text simplification.
InKnowledge Based Systems.Yu Chen, Martin Kay, and Andreas Eisele.
2009.
Inter-secting multilingual data for faster and better statisticaltranslations.
In Proceedings of HLT/NAACL.David Chiang.
2010.
Learning to translate with sourceand target syntax.
In Proceedings of ACL.James Clarke and Mirella Lapata.
2006.
Models forsentence compression: A comparison across domains,training requirements and evaluation measures.
InProceedings of ACL.Trevor Cohn and Mirella Lapata.
2009.
Sentence com-pression as tree transduction.
Journal of Artificial In-telligence Research.8Will Coster and David Kauchak.
2011.
Simple EnglishWikipedia: A new simplification task.
In Proceedingsof ACL (Short Paper).Lijun Feng.
2008.
Text simplification: A survey.
CUNYTechnical Report.Michel Galley and Kathleen McKeown.
2007.
Lexical-ized Markov grammars for sentence compression.
InProceedings of HLT/NAACL.Ruifang Ge and Raymond Mooney.
2006.
Discrimina-tive reranking for semantic parsing.
In Proceedings ofCOLING.Dan Klein and Christopher Manning.
2003.
Accurateunlexicalized parsing.
In Proceedings of ACL.Kevin Knight and Daniel Marcu.
2002.
Summarizationbeyond sentence extraction: A probabilistic approachto sentence compression.
Artificial Intelligence.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP.Ryan McDonald.
2006.
Discriminative sentence com-pression with soft syntactic evidence.
In Proceedingsof EACL.Makoto Miwa, Rune Saetre, Yusuke Miyao, and Jun?ichiTsujii.
2010.
Entity-focused sentence simplication forrelation extraction.
In Proceedings of COLING.Courtney Napoles and Mark Dredze.
2010.
Learn-ing simple Wikipedia: A cogitation in ascertainingabecedarian language.
In Proceedings of HLT/NAACLWorkshop on Computation Linguistics and Writing.Rani Nelken and Stuart Shieber.
2006.
Towards robustcontext-sensitive sentence alignment for monolingualcorpora.
In Proceedings of AMTA.Tadashi Nomoto.
2007.
Discriminative sentence com-pression with conditional random fields.
In Informa-tion Processing and Management.Tadashi Nomoto.
2008.
A generic sentence trimmer withCRFs.
In Proceedings of HLT/NAACL.Tadashi Nomoto.
2009.
A comparison of model free ver-sus model intensive approaches to sentence compres-sion.
In Proceedings of EMNLP.F.J.
Och and H. Ney.
2000.
Improved statistical align-ment models.
In Proceedings of ACL.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och, Kenji Yamada, Stanford U, Alex Fraser,Daniel Gildea, and Viren Jain.
2004.
A smorgasbordof features for statistical machine translation.
In Pro-ceedings of HLT/NAACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of ACL.Jenine Turner and Eugene Charniak.
2005.
Supervisedand unsupervised learning for sentence compression.In Proceedings of ACL.David Vickrey and Daphne Koller.
2008.
Sentence sim-plification for semantic role labeling.
In Proceedingsof ACL.S.
Wubben, A. van den Bosch, and E. Krahmer.
2010.Paraphrase generation as monolingual translation:Data and evaluation.
In Proceedings of the Interna-tional Workshop on Natural Language Generation.Elif Yamangil and Rani Nelken.
2008.
MiningWikipedia revision histories for improving sentencecompression.
In ACL.Mark Yatskar, Bo Pang, Critian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
For the sake of sim-plicity: Unsupervised extraction of lexical simplifica-tions from Wikipedia.
In Proceedings of HLT/NAACL(Short Paper).Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.2010.
A monolingual tree-based translation model forsentence simplification.
In Proceedings of COLING.9
