TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 81?88,Rochester, April 2007 c?2007 Association for Computational LinguisticsHow Difficult is it to Develop a Perfect Spell-checker?A Cross-linguistic Analysis through Complex Network ApproachMonojit Choudhury1, Markose Thomas2, Animesh Mukherjee1,Anupam Basu1, and Niloy Ganguly11Department of Computer Science and Engineering, IIT Kharagpur, India{monojit,animeshm,anupam,niloy}@cse.iitkgp.ernet.in2Google Inc. Bangalore, Indiamarkysays@gmail.comAbstractThe difficulties involved in spelling er-ror detection and correction in a lan-guage have been investigated in this workthrough the conceptualization of SpellNet?
the weighted network of words, whereedges indicate orthographic proximity be-tween two words.
We construct SpellNetsfor three languages - Bengali, English andHindi.
Through appropriate mathemati-cal analysis and/or intuitive justification,we interpret the different topological met-rics of SpellNet from the perspective ofthe issues related to spell-checking.
Wemake many interesting observations, themost significant among them being thatthe probability of making a real word errorin a language is propotionate to the aver-age weighted degree of SpellNet, which isfound to be highest for Hindi, followed byBengali and English.1 IntroductionSpell-checking is a well researched area in NLP,which deals with detection and automatic correc-tion of spelling errors in an electronic text docu-ment.
Several approaches to spell-checking havebeen described in the literature that use statistical,rule-based, dictionary-based or hybrid techniques(see (Kukich, 1992) for a dated but substantial sur-vey).
Spelling errors are broadly classified as non-word errors (NWE) and real word errors (RWE).
Ifthe misspelt string is a valid word in the language,then it is called an RWE, else it is an NWE.
For ex-ample, in English, the word ?fun?
might be misspeltas ?gun?
or ?vun?
; while the former is an RWE, thelatter is a case of NWE.
It is easy to detect an NWE,but correction process is non-trivial.
RWE, on theother hand are extremely difficult to detect as it re-quires syntactic and semantic analysis of the text,though the difficulty of correction is comparable tothat of NWE (see (Hirst and Budanitsky, 2005) andreferences therein).Given a lexicon of a particular language, howhard is it to develop a perfect spell-checker for thatlanguage?
Since context-insensitive spell-checkerscannot detect RWE and neither they can effectivelycorrect NWE, the difficulty in building a perfectspell-checker, therefore, is reflected by quantitiessuch as the probability of a misspelling being RWE,probability of more than one word being orthograph-ically closer to an NWE, and so on.
In this work,we make an attempt to understand and formalizesome of these issues related to the challenges ofspell-checking through a complex network approach(see (Albert and Baraba?si, 2002; Newman, 2003)for a review of the field).
This in turn allows us toprovide language-specific quantitative bounds on theperformance level of spell-checkers.In order to formally represent the orthographicstructure (spelling conventions) of a language, weconceptualize the lexicon as a weighted network,where the nodes represent the words and the weightsof the edges indicate the orthoraphic similarity be-tween the pair of nodes (read words) they connect.We shall call this network the Spelling Network orSpellNet for short.
We build the SpellNets for threelanguages ?
Bengali, English and Hindi, and carryout standard topological analysis of the networksfollowing complex network theory.
Through appro-priate mathematical analysis and/or intuitive justi-81fication, we interpret the different topological met-rics of SpellNet from the perspective of difficultiesrelated to spell-checking.
Finally, we make sev-eral cross-linguistic observations, both invariancesand variances, revealing quite a few interesting facts.For example, we see that among the three languagesstudied, the probability of RWE is highest in Hindifollowed by Bengali and English.
A similar obser-vation has been previously reported in (Bhatt et al,2005) for RWEs in Bengali and English.Apart from providing insight into spell-checking,the complex structure of SpellNet alo reveals theself-organization and evolutionary dynamics under-lying the orthographic properties of natural lan-guages.
In recent times, complex networks havebeen successfully employed to model and explainthe structure and organization of several naturaland social phenomena, such as the foodweb, pro-tien interaction, formation of language invento-ries (Choudhury et al, 2006), syntactic structure oflanguages (i Cancho and Sole?, 2004), WWW, socialcollaboration, scientific citations and many more(see (Albert and Baraba?si, 2002; Newman, 2003)and references therein).
This work is inspired bythe aforementioned models, and more specificallya couple of similar works on phonological neigh-bors?
network of words (Kapatsinski, 2006; Vite-vitch, 2005), which try to explain the human per-ceptual and cognitive processes in terms of the orga-nization of the mental lexicon.The rest of the paper is organized as follows.
Sec-tion 2 defines the structure and construction pro-cedure of SpellNet.
Section 3 and 4 describes thedegree and clustering related properties of Spell-Net and their significance in the context of spell-checking, respectively.
Section 5 summarizes thefindings and discusses possible directions for futurework.
The derivation of the probability of RWE in alanguage is presented in Appendix A.2 SpellNet: Definition and ConstructionIn order to study and formalize the orthographiccharacteristics of a language, we model the lexicon?
of the language as an undirected and fully con-nected weighted graph G(V,E).
Each word w ?
?is represented by a vertex vw ?
V , and for everypair of vertices vw and vw?
in V , there is an edgeFigure 1: The structure of SpellNet: (a) the weightedSpellNet for 6 English words, (b) Thresholded coun-terpart of (a), for ?
= 1(vw, vw?)
?
E. The weight of the edge (vw, vw?
), isequal to ed(w,w?)
?
the orthographic edit distancebetween w and w?
(considering substitution, dele-tion and insertion to have a cost of 1).
Each nodevw ?
V is also assigned a node weight WV (vw)equal to the unigram occurrence frequency of theword w. We shall refer to the graph G(V,E) as theSpellNet.
Figure 1(a) shows a hypothetical SpellNetfor 6 common English words.We define unweighted versions of the graphG(V,E) through the concept of thresholding asdescribed below.
For a threshold ?, the graphG?(V,E?)
is an unweighted sub-graph of G(V,E),where an edge (vw, vw?)
?
E is assigned a weight 1in E?
if and only if the weight of the edge is less thanor equal to ?, else it is assigned a weight 0.
In otherwords, E?
consists of only those edges in E whoseedge weight is less than or equal to ?.
Note that allthe edges in E?
are unweighted.
Figure 1(b) showsthe thresholded SpellNet shown in 1(a) for ?
= 1.2.1 Construction of SpellNetsWe construct the SpellNets for three languages ?Bengali, English and Hindi.
While the two Indianlanguages ?
Bengali and Hindi ?
use Brahmi derivedscripts ?
Bengali and Devanagari respectively, En-glish uses the Roman script.
Moreover, the orthog-raphy of the two Indian languages are highly phone-mic in nature, in contrast to the morpheme-based or-thography of English.
Another point of disparity liesin the fact that while the English alphabet consistsof 26 characters, the alphabet size of both Hindi andBengali is around 50.82The lexica for the three languages havebeen taken from public sources.
For En-glish it has been obtained from the websitewww.audiencedialogue.org/susteng.html; for Hindiand Bengali, the word lists as well as the unigramfrequencies have been estimated from the mono-lingual corpora published by Central Institute ofIndian Languages.
We chose to work with the mostfrequent 10000 words, as the medium size of thetwo Indian language corpora (around 3M wordseach) does not provide sufficient data for estimationof the unigram frequencies of a large numberof words (say 50000).
Therefore, all the resultsdescribed in this work pertain to the SpellNetscorresponding to the most frequent 10000 words.However, we believe that the trends observed do notreverse as we increase the size of the networks.In this paper, we focus on the networks at threedifferent thresholds, that is for ?
= 1, 3, 5, and studythe properties of G?
for the three languages.
Wedo not go for higher thresholds as the networks be-come completely connected at ?
= 5.
Table 1 re-ports the values of different topological metrics ofthe SpellNets for the three languages at three thresh-olds.
In the following two sections, we describe indetail some of the topological properties of Spell-Net, their implications to spell-checking, and obser-vations in the three languages.3 Degree DistributionThe degree of a vertex in a network is the number ofedges incident on that vertex.
Let Pk be the prob-ability that a randomly chosen vertex has degree kor more than k. A plot of Pk for any given networkcan be formed by making a histogram of the degreesof the vertices, and this plot is known as the cumu-lative degree distribution of the network (Newman,2003).
The (cumulative) degree distribution of a net-work provides important insights into the topologi-cal properties of the network.Figure 2 shows the plots for the cumulative de-gree distribution for ?
= 1, 3, 5, plotted on a log-linear scale.
The linear nature of the curves in thesemi-logarithmic scale indicates that the distributionis exponential in nature.
The exponential behaviouris clearly visible for ?
= 1, however at higher thresh-olds, there are very few nodes in the network withlow degrees, and therefore only the tail of the curveshows a pure exponential behavior.
We also observethat the steepness (i.e.
slope) of the log(Pk) with re-spect to k increases with ?.
It is interesting to notethat although most of the naturally and socially oc-curring networks exhibit a power-law degree distri-bution (see (Albert and Baraba?si, 2002; Newman,2003; i Cancho and Sole?, 2004; Choudhury et al,2006) and references therein), SpellNets feature ex-ponential degree distribution.
Nevertheless, similarresults have also been reported for the phonologicalneighbors?
network (Kapatsinski, 2006).3.1 Average DegreeLet the degree of the node v be denoted by k(v).
Wedefine the quantities ?
the average degree ?k?
and theweighted average degree ?kwt?
for a given networkas follows (we drop the subscript w for clarity ofnotation).?k?
= 1N?v?Vk(v) (1)?kwt?
=?v?V k(v)WV (v)?v?V WV (v)(2)where N is the number of nodes in the network.Implication: The average weighted degree ofSpellNet can be interpreted as the probability ofRWE in a language.
This correlation can be derivedas follows.
Given a lexicon ?
of a language, it canbe shown that the probability of RWE in a language,denoted by prwe(?)
is given by the following equa-tion (see Appendix A for the derivation)prwe(?)
=?w???w??
?w 6=w??ed(w,w?
)p(w) (3)Let neighbor(w, d) be the number of words in ?whose edit distance from w is d. Eqn 3 can be rewrit-ten in terms of neighbor(w, d) as follows.prwe(?)
=?w???
?d=1?d neighbor(w, d)p(w) (4)Practically, we can always assume that d is boundedby a small positive integer.
In other words, thenumber of errors simultaneously made on a wordis always small (usually assumed to be 1 or a83English Hindi Bengali?
= 1 ?
= 3 ?
= 5 ?
= 1 ?
= 3 ?
= 5 ?
= 1 ?
= 3 ?
= 5M 8.97k 0.70M 8.46M 17.6k 1.73M 17.1M 11.9k 1.11M 13.2M?k?
2.79 140.25 1692.65 4.52 347.93 3440.06 3.38 223.72 2640.11?kwt?
6.81 408.03 1812.56 13.45 751.24 4629.36 7.73 447.16 3645.37rdd 0.696 0.480 0.289 0.696 0.364 0.129 0.702 0.389 0.155?CC?
0.101 0.340 0.563 0.172 0.400 0.697 0.131 0.381 0.645?CCwt?
0.221 0.412 0.680 0.341 0.436 0.760 0.229 0.418 0.681?l?
7.07 3.50 N.E 7.47 2.74 N.E 8.19 2.95 N.ED 24 14 N.E 26 12 N.E 29 12 N.ETable 1: Various topological metrics and their associated values for the SpellNets of the three languagesat thresholds 1, 3 and 5.
Metrics: M ?
number of edges; ?k?
?
average degree; ?kwt?
?
average weighteddegree; ?CC?
?
average clustering coefficient; ?CCwt?
- average weighted clustering coefficient; rdd ?Pearson correlation coefficient between degrees of neighbors; ?l?
?
average shortest path; D ?
diameter.N.E ?
Not Estimated.
See the text for further details on definition, computation and significance of themetrics.1e-040.0010.010.110  10  20  30  40  50  60P kDegreeThreshold 1EnglishHindiBengali1e-040.0010.010.110  500  1000  1500  2000  2500P kDegreeThreshold 3EnglishHindiBengali1e-040.0010.010.110  1000 2000 3000 4000 5000 6000 7000 8000P kDegreeThreshold 5EnglishHindiBengaliFigure 2: Cumulative degree distribution of SpellNets at different thresholds presented in semi-logarithmicscale.slowly growing function of the word length (Kukich,1992)).
Let us denote this bound by ?.
Therefore,prwe(?)
??w???
?d=1?d neighbor(w, d)p(w) (5)Since ?
< 1, we can substitute ?d by ?
to get anupper bound on prwe(?
), which givesprwe(?)
< ??w???
?d=1neighbor(w, d)p(w) (6)The term ?
?d=1 neighbor(w, d) computes thenumber of words in the lexicon, whose edit distancefrom w is atmost ?.
This is nothing but k(vw), i.e.the degree of the node vw, in G?.
Moreover, the termp(w) is proportionate to the node weight WV (vw).Thus, rewriting Eqn 6 in terms of the network pa-rameters for G?, we get (subscript w is dropped forclarity)prwe(?)
< ?
?v?V k(v)WV (v)?v?V WV (v)(7)Comparing Eqn 2 with the above equation, we candirectly obtain the relationprwe(?)
< C1?kwt?
(8)where C1 is some constant of proportionality.
Notethat for ?
= 1, prwe(?)
?
?kwt?.
If we ignorethe distribution of the words, that is if we assumep(w) = 1/N , then prwe(?)
?
?k?.Thus, the quantity ?kwt?
provides a good estimateof the probability of RWE in a language.Observations and Inference: At ?
= 1, the av-erage weighted degrees for Hindi, Bengali and En-glish are 13.81, 7.73 and 6.61 respectively.
Thus, theprobability of RWE in Hindi is significantly higher8411010010  100  1000  10000 100000 1e+06DegreeFrequencyThreshold 111010010001000010  100  1000 10000 100000 1e+06DegreeFrequencyThreshold 311010010001000010  100  1000 10000 100000 1e+06DegreeFrequencyThreshold 5Figure 3: Scatter-plots for degree versus unigramfrequency at different ?
for Hindithan that of Bengali, which in turn is higher thanthat of English (Bhatt et al, 2005).
Similar trendsare observed at all the thresholds for both ?kwt?
and?k?.
This is also evident from Figures 2, which showthe distribution of Hindi to lie above that of Bengali,which lies above English (for all thresholds).The average degree ?k?
is substantially smaller(0.5 to 0.33 times) than the average weighted de-gree ?kwt?
for all the 9 SpellNets.
This suggeststhat the higher degree nodes in SpellNet have highernode weight (i.e.
occurrence frequency).
Indeed, asshown in Figure 3 for Hindi, the high unigram fre-quency of a node implies higher degree, though thereverse is not true.
The scatter-plots for the otherlanguages are similar in nature.3.2 Correlation between Degrees of NeighborsThe relation between the degrees of adjacent wordsis described by the degree assortativity coefficient.One way to define the assortativity of a network isthrough the Pearson correlation coefficient betweenthe degrees of the two vertices connected by an edge.Each edge (u, v) in the network adds a data itemcorresponding to the degrees of u and v to two datasets x and y respectively.
The Pearson correlationcoefficient for the data sets x and y of n items eachis then defined asr = n?xy ??x?
y?
[n?x2 ?
(?x)2][n?
y2 ?
(?
y)2]Observation: r is positive for the networks inwhich words tend to associate with other words ofsimilar degree (i.e.
high degree with high degreeand vice versa), and it is negative for networks inwhich words associate with words having degreesin the opposite spectrum.
Refering to table 1, wesee that the correlation coefficient rdd is roughly thesame and equal to around 0.7 for all languages at?
= 1.
As ?
increases, the correlation decreases asexpected, due to the addition of edges between dis-similar words.Implication: The high positive correlation coeffi-cients suggest that SpellNets feature assortative mix-ing of nodes in terms of degrees.
If there is an RWEcorresponding to a high degree node vw, then dueto the assortative mixing of nodes, the misspellingw?
obtained from w, is also expected to have a highdegree.
Since w?
has a high degree, even after detec-tion of the fact that w?
is a misspelling, choosing theright suggestion (i.e.
w) is extremely difficult un-less the linguistic context of the word is taken intoaccount.
Thus, more often than not it is difficult tocorrect an RWE, even after successful detection.4 Clustering and Small World PropertiesIn the previous section, we looked at some of the de-gree based features of SpellNets.
These features pro-vide us insights regarding the probability of RWE ina language and the level of difficulty in correctingthe same.
In this section, we discuss some of theother characteristics of SpellNets that are useful inpredicting the difficulty of non-word error correc-tion.4.1 Clustering CoefficientRecall that in the presence of a complete list of validwords in a language, detection of NWE is a trivialtask.
However, correction of NWE is far from triv-ial.
Spell-checkers usually generate a suggestion listof possible candidate words that are within a smalledit distance of the misspelling.
Thus, correction be-comes hard as the number of words within a givenedit distance from the misspelling increases.
Sup-pose that a word w ?
?
is transformed into w?
dueto some typing error, such that w?
/?
?.
Also assumethat ed(w,w?)
?
?.
We want to estimate the numberof words in ?
that are within an edit distance ?
ofw?.
In other words we are interested in finding outthe degree of the node vw?
in G?, but since there isno such node in SpellNet, we cannot compute thisquantity directly.
Nevertheless, we can provide an85approximate estimate of the same as follows.Let us conceive of a hypothetical node vw?
.
Bydefinition of SpellNet, there should be an edge con-necting vw?
and vw in G?.
A crude estimate ofk(vw?)
can be ?kwt?
of G?.
Due to the assortativenature of the network, we expect to see a high corre-lation between the values of k(vw) and k(vw?
), andtherefore, a slightly better estimate of k(vw?)
couldbe k(vw).
However, as vw?
is not a part of the net-work, it?s behavior in SpellNet may not resemblethat of a real node, and such estimates can be grosslyerroneous.One way to circumvent this problem is to lookat the local neighborhood of the node vw.
Let usask the question ?
what is the probability that tworandomly chosen neighbors of vw in G?
are con-nected to each other?
If this probability is high, thenwe can expect the local neighborhood of vw to bedense in the sense that almost all the neighbors ofvw are connected to each other forming a clique-likelocal structure.
Since vw?
is a neighbor of vw, it isa part of this dense cluster, and therefore, its degreek(vw?)
is of the order of k(vw).
On the other hand,if this probability is low, then even if k(vw) is high,the space around vw is sparse, and the local neigh-borhood is star-like.
In such a situation, we expectk(vw?)
to be low.The topological property that measures the prob-ability of the neighbors of a node being connectedis called the clustering coefficient (CC).
One of theways to define the clustering coefficient C(v) for avertex v in a network isC(v) = number of triangles connected to vertex vnumber of triplets centered on vFor vertices with degree 0 or 1, we put C(v) = 0.Then the clustering coefficient for the whole net-work ?CC?
is the mean CC of the nodes in the net-work.
A corresponding weighted version of the CC?CCwt?
can be defined by taking the node weightsinto account.Implication: The higher the value ofk(vw)C(vw) for a node, the higher is the probabilitythat an NWE made while typing w is hard to correctdue to the presence of a large number of ortho-graphic neighbors of the misspelling.
Therefore,in a way ?CCwt?
reflects the level of difficulty incorrecting NWE for the language in general.Observation and Inference: At threshold 1,the values of ?CC?
as well as ?CCwt?
is higherfor Hindi (0.172 and 0.341 respectively) and Ben-gali (0.131 and 0.229 respectively) than that of En-glish (0.101 and 0.221 respectively), though forhigher thresholds, the difference between the CCfor the languages reduces.
This observation furtherstrengthens our claim that the level of difficulty inspelling error detection and correction are languagedependent, and for the three languages studied, it ishardest for Hindi, followed by Bengali and English.4.2 Small World PropertyAs an aside, it is interesting to see whether the Spell-Nets exhibit the so called small world effect that isprevalent in many social and natural systems (see(Albert and Baraba?si, 2002; Newman, 2003) for def-inition and examles).
A network is said to be a smallworld if it has a high clustering coefficient and if theaverage shortest path between any two nodes of thenetwork is small.Observation: We observe that SpellNets indeedfeature a high CC that grows with the threshold.
Theaverage shortest path, denoted by ?l?
in Table 1, for?
= 1 is around 7 for all the languages, and reducesto around 3 for ?
= 3; at ?
= 5 the networks arenear-cliques.
Thus, SpellNet is a small world net-work.Implication: By the application of triangle in-equality of edit distance, it can be easily shown that?l?
?
?
provides an upper bound on the average editdistance between all pairs of the words in the lexi-con.
Thus, a small world network, which implies asmall ?l?, in turn implies that as we increase the errorbound (i.e.
?
), the number of edges increases sharplyin the network and soon the network becomes fullyconnected.
Therefore, it becomes increasingly moredifficult to correct or detect the errors, as any wordcan be a possible suggestion for any misspelling.
Infact this is independently observed through the ex-ponential rise in M ?
the number of edges, and fallin ?l?
as we increase ?.Inference: It is impossible to correct very noisytexts, where the nature of the noise is random andwords are distorted by a large edit distance (say 3 ormore).865 ConclusionIn this work, we have proposed the network of ortho-graphic neighbors of words or the SpellNet and stud-ied the structure of the same across three languages.We have also made an attempt to relate some of thetopological properties of SpellNet to spelling errordistribution and hardness of spell-checking in a lan-guage.
The important observations of this study aresummarized below.?
The probability of RWE in a language canbe equated to the average weighted degree ofSpellNet.
This probablity is highest in Hindifollowed by Bengali and English.?
In all the languages, the words that are moreprone to undergo an RWE are more likely to bemisspelt.
Effectively, this makes RWE correc-tion very hard.?
The hardness of NWE correction correlateswith the weighted clustering coefficient of thenetwork.
This is highest for Hindi, followed byBengali and English.?
The basic topology of SpellNet seems to be aninvariant across languages.
For example, allthe networks feature exponential degree distri-bution, high clustering, assortative mixing withrespect to degree and node weight, small worldeffect and positive correlation between degreeand node weight, and CC and degree.
However,the networks vary to a large extent in terms ofthe actual values of some of these metrics.Arguably, the language-invariant properties ofSpellNet can be attributed to the organization ofthe human mental lexicon (see (Kapatsinski, 2006)and references therein), self-organization of ortho-graphic systems and certain properties of edit dis-tance measure.
The differences across the lan-guages, perhaps, are an outcome of the specific or-thographic features, such as the size of the alphabet.Another interesting observation is that the phonemicnature of the orthography strongly correlates withthe difficulty of spell-checking.
Among the threelanguages, Hindi has the most phonemic and En-glish the least phonemic orthography.
This corre-lation calls for further investigation.Throughout the present discussion, we have fo-cussed on spell-checkers that ignore the context;consequently, many of the aforementioned results,especially those involving spelling correction, arevalid only for context-insensitive spell-checkers.Nevertheless, many of the practically useful spell-checkers incorporate context information and thecurrent analysis on SpellNet can be extended forsuch spell-checkers by conceptualizing a networkof words that capture the word co-occurrence pat-terns (Biemann, 2006).
The word co-occurrencenetwork can be superimposed on SpellNet and theproperties of the resulting structure can be appro-priately analyzed to obtain similar bounds on hard-ness of context-sensitive spell-checkers.
We deemthis to be a part of our future work.
Another wayto improve the study could be to incorporate a morerealistic measure for the orthographic similarity be-tween the words.
Nevertheless, such a modificationwill have no effect on the analysis technique, thoughthe results of the analysis may be different from theones reported here.Appendix A: Derivation of the Probabilityof RWEWe take a noisy channel approach, which is a com-mon technique in NLP (for example (Brown et al,1993)), including spellchecking (Kernighan et al,1990).
Depending on the situation.
the channel maymodel typing or OCR errors.
Suppose that a word w,while passing through the channel, gets transformedto a word w?.
Therefore, the aim of spelling cor-rection is to find the w?
?
?
(the lexicon), whichmaximizes p(w?|w?
), that isargmaxw??p(w|w?)
= argmaxw?
?p(w?|w)p(w)(9)The likelihood p(w?|w) models the noisy channel,whereas the term p(w) is traditionally referred toas the language model (see (Jurafsky and Martin,2000) for an introduction).
In this equation, as wellas throughout this discussion, we shall assume a uni-gram language model, where p(w) is the normalizedfrequency of occurrence of w in a standard corpus.We define the probability of RWE for a word w,87prwe(w), as followsprwe(w) =?w??
?w 6=w?p(w?|w) (10)Stated differently, prwe(w) is a measure of the prob-ability that while passing through the channel, wgets transformed into a form w?, such that w?
?
?and w?
6= w. The probability of RWE in the lan-guage, denoted by prwe(?
), can then be defined interms of the probability prwe(w) as follows.prwe(?)
=?w?
?prwe(w)p(w) (11)=?w???w??
?w 6=w?p(w?|w)p(w)In order to obtain an estimate of the likelihoodp(w?|w), we use the concept of edit distance (alsoknown as Levenstein distance (Levenstein, 1965)).We shall denote the edit distance between two wordsw and w?
by ed(w,w?).
If we assume that the proba-bility of a single error (i.e.
a character deletion, sub-stitution or insertion) is ?
and errors are independentof each other, then we can approximate the likeli-hood estimate as follows.p(w?|w) = ?ed(w,w?)
(12)Exponentiation of edit distance is a common mea-sure of word similarity or likelihood (see for exam-ple (Bailey and Hahn, 2001)).Substituting for p(w?|w) in Eqn 11, we getprwe(?)
=?w???w??
?w 6=w??ed(w,w?
)p(w) (13)ReferencesR.
Albert and A. L. Baraba?si.
2002.
Statistical mechan-ics of complex networks.
Reviews of Modern Physics,74:47?97.Todd M. Bailey and Ulrike Hahn.
2001.
Determinants ofwordlikeness: Phonotactics or lexical neighborhoods?Journal of Memory and Language, 44:568 ?
591.A.
Bhatt, M. Choudhury, S. Sarkar, and A. Basu.
2005.Exploring the limits of spellcheckers: A compara-tive study in bengali and english.
In Proceedings ofthe Symposium on Indian Morphology, Phonology andLanguage Engineering (SIMPLE?05), pages 60?65.C.
Biemann.
2006.
Unsupervised part-of-speech tag-ging employing efficient graph clustering.
In Pro-ceedings of the COLING/ACL 2006 Student ResearchWorkshop, pages 7?12.P.
F. Brown, S. A. D. Pietra, V. J. D. Pietra, and R. L.Mercer.
1993.
The mathematics of statistical machinetranslation: Parameter estimation.
Computational Lin-guistics, 19(2):263?312.M.
Choudhury, A. Mukherjee, A. Basu, and N. Ganguly.2006.
Analysis and synthesis of the distribution ofconsonants over languages: A complex network ap-proach.
In Proceedings of the COLING/ACL MainConference Poster Sessions, pages 128?135.G.
Hirst and A. Budanitsky.
2005.
Correcting real-wordspelling errors by restoring lexical cohesion.
NaturalLanguage Engineering, 11:87 ?
111.R.
Ferrer i Cancho and R. V. Sole?.
2004.
Patterns insyntactic dependency networks.
Physical Review E,69:051915.D.
Jurafsky and J. H. Martin.
2000.
An Introductionto Natural Language Processing, Computational Lin-guistics, and Speech Recognition.
Prentice Hall.V.
Kapatsinski.
2006.
Sound similarity relations inthe mental lexicon: Modeling the lexicon as a com-plex network.
Speech research Lab Progress Report,27:133 ?
152.M.
D. Kernighan, K. W. Church, and W. A. Gale.
1990.A spelling correction program based on a noisy chan-nel model.
In Proceedings of COLING, pages 205?210, NJ, USA.
ACL.K.
Kukich.
1992.
Technique for automatically correctingwords in text.
ACM Computing Surveys, 24:377 ?
439.V.
I. Levenstein.
1965.
Binary codes capable of cor-recting deletions, insertions and reversals.
DokladyAkademii Nauk SSSR, 19:1 ?
36.M.
E. J. Newman.
2003.
The structure and function ofcomplex networks.
SIAM Review, 45:167?256.M.
S. Vitevitch.
2005.
Phonological neighbors in a smallworld: What can graph theory tell us about word learn-ing?
Spring 2005 Talk Series on Networks and Com-plex Systems, Indiana University.88
