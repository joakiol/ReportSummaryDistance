Robust Knowledge Discovery from Parallel Speech andText SourcesF.
Jelinek, W. Byrne, S. Khudanpur, B. Hladka?.
CLSP, Johns Hopkins University, Baltimore, MD.H.
Ney, F. J. Och.
RWTH Aachen University, Aachen, GermanyJ.
Cur???n.
Charles University, Prague, Czech Rep.J.
Psutka.
University of West Bohemia, Pilsen, Czech Rep.1.
INTRODUCTIONAs a by-product of the recent information explosion, the samebasic facts are often available from multiple sources such as the In-ternet, television, radio and newspapers.
We present here a projectcurrently in its early stages that aims to take advantage of the re-dundancies in parallel sources to achieve robustness in automaticknowledge extraction.Consider, for instance, the following sampling of actual newsfrom various sources on a particular day:CNN: James McDougal, President Bill Clinton?s former businesspartner in Arkansas and a cooperating witness in the White-water investigation, died Sunday while serving a federal prisonterm.
He was 57.MSNBC: Fort Worth, Texas, March 8.
Whitewater figure JamesMcDougal died of an apparent heart attack in a private com-munity hospital in Fort Worth, Texas, Sunday.
He was 57.ABC News: Washington, March 8.
James McDougal, a key figurein Independent Counsel Kenneth Starr?s Whitewater investi-gation, is dead.The Detroit News: Fort Worth.
James McDougal, a key witnessin Kenneth Starr?s Whitewater investigation of President Clin-ton and First Lady Hillary Rodham Clinton, died of a heartattack in a prison hospital Sunday.
He was 57.San Jose Mercury News: James McDougal, the wily Arkansasbanking rogue who drew Bill Clinton and Hillary RodhamClinton into real estate deals that have come to haunt them,died Sunday of cardiac arrest just months before he hoped tobe released from prison.
He was 57.The Miami Herald: Washington.
James McDougal, the wilyArkansas financier and land speculator at the center of theoriginal Whitewater probe against President Clinton, diedSunday..StoryAlignmentSpeechRecognitionSpeech SourcesBasic Models:acousticlexicallanguageTopic specificacoustic and languagemodelsstoriesAligned SentenceretrievalRankedAnswersQueryText sourcesFigure 1: Information Flow in Alignment and ExtractionWe propose to align collections of stories, much like the exam-ple above, from multiple text and speech sources and then developmethods that exploit the resulting parallelism both as a tool to im-prove recognition accuracy and to enable the development of sys-tems that can reliably extract information from parallel sources.Our goal is to develop systems that align text sources and rec-ognize parallel speech streams simultaneously in several languagesby making use of all related text and speech.
The initial systemswe intend to develop will process each language independently.However, our ultimate and most ambitious objective is to align textsources and recognize speech using a single, integrated multilin-gual ASR system.
Of course, if sufficiently accurate automatic ma-chine translation (MT) techniques ([1]) were available, we couldaddress multilingual processing and single language systems in thesame way.
However MT techniques are not yet reliable enoughthat we expect all words and phrases recognized within languagesto contribute to recognition across languages.
We intend to developmethods that identify the particular words and phrases that both canbe translated reliably and also used to improve story recognition.As MT technology improves it can be incorporated more exten-sively within the processing paradigm we propose.
We considerthis proposal a framework within which successful MT techniquescan eventually be used for multilingual acoustic processing.2.
PROJECT OBJECTIVESThe first objective is to enhance multi-lingual information sys-tems by exploiting the processing capabilities for resource-rich lan-guages to enhance the capabilities for resource-impoverished lan-guage.
The second objective is to advance information retrieval andknowledge information systems by providing them with consider-ably improved multi-lingual speech recognition capabilities.
Ourresearch plan proceeds in several steps to (i) collect and (ii) alignmulti-lingual parallel speech and text sources, (iii) exploit paral-lelism for improving ASR within a language, and to (iv) exploitparallelism for improving ASR across languages.
The main infor-mation flows involved in aligning and exploiting parallel sourcesare illustrated in Figure 1.
We will initially focus on German, En-glish and Czech language sources.
This section summarizes themajor components of our project.2.1 Parallel Speech and Text SourcesThe monolingual speech and text collections that we will useto develop techniques to exploit parallelism for improving ASRwithin a language are readily available.
For instance, the NorthAmerican News Text corpus of parallel news streams from 16 USnewspapers and newswire is available from LDC.
A 3-year periodyields over 350 million words of multi-source news text.In addition to data developed within the TIDES and other HLTprograms, we are in the process of identifying and creating our ownmultilingual parallel speech and text sources.FBIS TIDES Multilingual Newstext CollectionFor the purposes of developing multilingual alignment techniques,we intend to use the 240 day, contemporaneous, multilingual newstext collection made available for use to TIDES projects by FBIS.This corpus contains news in our initial target languages of English,German, and Czech.
The collections are highly parallel, in thatmuch of the stories are direct translations.Radio Prague Multilingual Speech and Text CorpusSpeech and news text from Radio Prague was collected under thedirection of J. Psutka with the consent of Radio Prague.
The col-lection contains speech and text in 5 languages: Czech, English,German, French, and Spanish.
The collection began June 1, 2000and continued for approximately 3 months.
The text collection con-tains the news scripts used for the broadcast; the broadcasts moreor less follow the scripts.
The speech is about 3 minutes per dayin each language, which should yield a total of about 5 hours ofspeech per language.Our initial analysis of the Radio Prague corpus suggest that onlyapproximately 5% of the stories coincide in topic, and that thereis little, if any, direct translation of stories.
We anticipate that thissparseness will make this corpus significantly hard to analyze thananother, highly-parallel corpus.
However, we expect this is thesort of difficulty that will likely be encountered in processing ?real-world?
multilingual news sources.2.2 Story-level AlignmentOnce we have the multiple streams of information we must beable to align them according to story.
A story is the description ofone or more events that happened in a single day and that are re-ported in a single article by a daily news source the next day.
Weexpect that we will use the same techniques used in the Topic De-tection (TDT) field ([5]).
Independently of the specific details ofthe alignment procedure, there is now substantial evidence that re-lated stories from parallel streams can be identified using standardstatistical Information Retrieval (IR) techniques.Sentence Alignment As part of the infrastructure needed to in-corporate cross-lingual information into language models, we areemploying statistical MT systems to generate English/German andEnglish/Czech alignments of sentences in the FBIS Newstext Col-lection.
For the English/German sentence and single-word basedalignments, we plan to use statistical models ([4]) [3] which gen-erate both sentence and word alignments.
For English/Czech sen-tence alignment, we will employ the statistical models trained aspart of the Czech-English MT system developed during the 1999Johns Hopkins Summer Workshop ([2]).2.3 Multi-Source Automatic SpeechRecognitionThe scenario we propose is extraction of information from paral-lel text followed by repeated recognition of parallel broadcasts, re-sulting in a gradual lowering the WER.
The first pass is performedin order to find the likely topics discussed in the story and to iden-tify the topics relevant to the query.
In this process, the acousticmodel will be improved by deriving pronunciation specificationsfor out-of-vocabulary words and fixed phrases extracted from theparallel stories.
The language model will be improved by extendingthe coverage of the underlying word and phrase vocabulary, and byspecializing the model?s statistics to the narrow topic at hand.
Aslong as a round of recognition yields new information, the corre-sponding improvement is incorporated into the recognizer modulesand bootstrapping of the system continues.Story-specific Language Models from Parallel Speech and TextOur goal is to create language models combining specific but sparsestatistics, derived from relevant parallel material, with reliable butunspecific statistics obtainable from large general corpora.
We willcreate special n-gram language models from the available text, re-lated or parallel to the spoken stories.
We can then interpolatethis special model with a larger pre-existing model, possibly de-rived from training text associated to the topic of the story.
Ourrecent STIMULATE work demonstrated success in construction oftopic-specific language models on the basis of hierarchically topic-organized corpora [8].Unlike building models from parallel texts, the training of storyspecific language models from recognized speech is also affectedby recognition errors in the data which will be used for languagemodeling.
Confidence measures can be used to estimate the cor-rectness of individual words or phrases on the recognizer output.Using this information, n-gram statistics can be extracted from therecognizer output by selecting those events which are likely to becorrect and which can therefore be used to adjust the original lan-guage model without introducing new errors to the recognition sys-tem.Language Models with Cross-Lingual Lexical TriggersA trigger language model ([6], [7]) will be constructed for the tar-get language from the text corpus, where the lexical triggers are notfrom the word-history in the target language, but from the alignedrecognized stories in the source language.
The trigger informa-tion becomes most important in those cases in which the baselinen-gram model in the target language does not supply sufficient in-formation to predict a word.
We expect that content words in thesource language are good predictors for content words in the targetlanguage and that these words are difficult to predict using the tar-get language alone, and the mutual information techniques used toidentify trigger pairs will be useful here.Once a spoken source-language story has been recognized, thewords found here there will be used as triggers in the languagemodel for the recognition of the target-language news broadcasts.3.
SUMMARYOur goal is to align collections of stories from multiple text andspeech sources in more than one language and then develop meth-ods that exploit the resulting parallelism both as a tool to improverecognition accuracy and to enable the development of systems thatcan reliably extract information from parallel sources.
Much likea teacher rephrases a concept in a variety of ways to help a classunderstand it, the multiple sources, we expect, will increase the po-tential of success in knowledge extraction.
We envision techniquesthat will operate repeatedly on multilingual sources by incorporat-ing newly discovered information in one language into the modelsused for all the other languages.
Applications of these methods ex-tend beyond news sources to other multiple-source domains suchas office email and voice-mail, or classroom materials such as lec-tures, notes and texts.4.
REFERENCES[1] P. F. Brown, S. A. DellaPietra, V. J. D. Pietra, and R. L.Mercer.
The mathematics of statistical translation.Computational Linguistics, 19(2), 1993.
[2] K. K. et al Statistical machine translation, WS?99 FinalReport, Johns Hopkins University, 1999.http://www.clsp.jhu.edu/ws99/projects/mt.
[3] F. J. Och and H. Ney.
Improved statistical alignment models.In ACL?00, pages 440?447, 2000.
[4] F. J. Och, C. Tillmann, and H. Ney.
Improved alignmentmodels for statistical machine translation.
In EMNLP/VLC?99,pages 20?28, 1999.
[5] Proceedings of the Topic Detection and Tracking workshop.University of Maryland, College Park, MD, October 1997.
[6] C. Tillmann and H. Ney.
Selection criteria for word triggerpairs in language modelling.
In ICGI?96, pages 95?106, 1996.
[7] C. Tillmann and H. Ney.
Statistical language modeling andword triggers.
In SPECOM?96, pages 22?27, 1996.
[8] D. Yarowsky.
Exploiting nonlocal and syntactic wordrelationships in language models for conversational speechrecognition, a NSF STIMULATE Project IRI9618874, 1997.Johns Hopkins University.
