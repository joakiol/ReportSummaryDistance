Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 435?442, Vancouver, October 2005. c?2005 Association for Computational LinguisticsCluster-specific Named Entity TransliterationFei HuangSchool of Computer ScienceCarnegie Mellon University, Pittsburgh, PA 15213fhuang@cs.cmu.eduAbstractExisting named entity (NE) transliterationapproaches often exploit a general model totransliterate NEs, regardless of their origins.As a result, both a Chinese name and aFrench name (assuming it is already trans-lated into Chinese) will be translated intoEnglish using the same model, which oftenleads to unsatisfactory performance.
In thispaper we propose a cluster-specific NEtransliteration framework.
We group nameorigins into a smaller number of clusters,then train transliteration and language mod-els for each cluster under a statistical ma-chine translation framework.
Given a sourceNE, we first select appropriate models byclassifying it into the most likely cluster,then we transliterate this NE with the corre-sponding models.
We also propose a phrase-based name transliteration model, which ef-fectively combines context information fortransliteration.
Our experiments showedsubstantial improvement on the translitera-tion accuracy over a state-of-the-art baselinesystem, significantly reducing thetransliteration character error rate from50.29% to 12.84%.1 IntroductionNamed Entity (NE) translation and transliterationare very important to many multilingual naturallanguage processing tasks, such as machine trans-lation, crosslingual information retrieval and ques-tion answering.
Although some frequentlyoccurring NEs can be reliably translated using in-formation from existing bilingual dictionaries andparallel or monolingual corpora (Al-Onaizan andKnight, 2002; Huang and Vogel, 2002; Lee andChang, 2003), less frequently occurring NEs, espe-cially new names, still rely on machine translitera-tion to generate their translations.NE machine transliteration generates a phoneti-cally similar equivalent in the target language for asource NE, and transliteration patterns highly de-pend on the name?s origin, e.g., the country or thelanguage family this name is from.
For example,when transliterating names 1  from Chinese intoEnglish, as shown in the following example, thesame Chinese character ???
is transliterated intodifferent English letters according to the origin ofeach person.???
--- Jin Renqing (China)???
--- Kim Dae-jung (Korea)??
??
?
--- Martin Luther King (USA)???
--- Kanemaru Shin (Japan)??
??
???
--- Jose Joaquin Brunner (Chile)Several approaches have been proposed forname transliteration.
(Knight and Graehl, 1997)proposed a generative transliteration model totransliterate foreign names in Japanese back toEnglish using finite state transducers.
(Stalls andKnight, 1998) expanded that model to Arabic-English transliteration.
(Meng et al 2001) devel-oped an English-Chinese NE transliteration tech-nique using pronunciation lexicon and phoneticmapping rules.
(Virga and Khudanpur, 2003) ap-plied statistical machine translation models to?translate?
English names into Chinese charactersfor Mandarin spoken document retrieval.
All theseapproaches exploit a general model for NE trans-literation, where source names from different ori-gins or language families are transliterated into thetarget language with the same rules or probabilitydistributions, which fails to capture their different1 Assuming foreign names are already transliterated into Chi-nese.435transliteration patterns.
Alternatively, (Qu and Gre-fenstette, 2004) applied language identification ofname origins to select language-specific translit-erations when back-transliterating Japanese namesfrom English to Japanese.
However, they onlyclassified names into three origins: Chinese, Japa-nese and English, and they used the Unihan data-base to obtain the mapping between kenjicharacters and romanji representations.Ideally, to explicitly model these transliterationdifferences we should construct a transliterationmodel and a language model for each origin.
How-ever, some origins lack enough name translationpairs for reliable model training.
In this paper wepropose a cluster-specific NE transliterationframework.
Considering that several origins fromthe same language family may share similar trans-literation patterns, we group these origins into onecluster, and build cluster-specific transliterationand language models.Starting from a list of bilingual NE translationpairs with labeled origins, we group closely relatedorigins into clusters according to their languageand transliteration model perplexities.
We traincluster-specific language and transliteration modelswith merged name translation pairs.
Given a sourcename, we first select appropriate models by classi-fying it into the most likely cluster, then we trans-literate the source name with the correspondingmodels under the statistical machine translationframework.
This cluster-specific transliterationframework greatly improves the transliteration per-formance over a general transliteration model.
Fur-ther more, we propose a phrase-basedtransliteration model, which effectively combinescontext information for name transliteration andachieves significant improvements over the tradi-tional character-based transliteration model.The rest of the paper is organized as following:in section 2 we introduce the NE clustering andclassification schemes, and we discuss the phrase-based NE transliteration in section 3.
Experimentsettings and results are given in section 4, which isfollowed by our conclusion.2 Name Clustering and ClassificationProvided with a list of bilingual name translationpairs whose origins are already labeled, we want tofind the origin clusters where closely related ori-gins (countries sharing similar languages or cul-tural heritages) are grouped together.We define the similarity measure between twoclusters as their LM and TM perplexities.
Let)},{( iii EFS = denote a set of name translationpairs from origin i , from which model i?
is trained:),,( )(it)()( ieici PPP=?
.
Here and are N-gramcharacter language models (LM) for source andtarget languages, and is a character translationmodel trained based on IBM translation model 1(Brown et.al.
1993).
The distance between origin iand origin)(icP )(ieP)(itPj  can be symmetrically defined as:)|(log||1)|(log||1),( ijjjiiSPSSPSjid ??
?
?= ,where, assuming name pairs are generated inde-pendently,)]|()()|()(log[)|()()(||1)()(titijttijeSttitijttijcjiEFPEPFEPFPSPi?=+?
?We calculate the pair-wise distances amongthese origins, and cluster them with group-averageagglomerative clustering.
The distance betweenclusters and is defined as the average dis-tance between all origin pairs in each cluster.
Thisclustering algorithm initially sets each origin as asingle cluster, then recursively merges the closestcluster pair into one cluster until an optimal num-ber of clusters is formed.iC jCAmong all possible cluster configurations, weselect the optimal cluster number based on themodel perplexity.
Given a held-out data set L, a listof name translation pairs from different origins, theprobability of generating L from a cluster configu-ration ??
is the product of generating each namepair from its most likely origin cluster:??=??=??==?||1)()(||1)()()(max)()|,(max)|(LtjtjetjcjLtjjttjPEPFPPEFPLP?????
?We calculate the language model perplexity:||/1)|(log||1)|(2),( LLPL LPLpp ???
?==?
??
?,and select the model configuration with the small-est perplexity.
We clustered 56K Chinese-Englishname translation pairs from 112 origins, and evalu-ate the perplexities of different models (number of436Figure 1.
Perplexity value of LMs with differentnumber of clustersAfghanistan, Algeria, Egypt, Iran, Iraq,Jordan, Kuwait, Pakistan, Palestine,clusters) with regard to a held-out 3K name pairs.As shown in Figure 1, the perplexity curve reachesits minimum when .
This indicates that theoptimal cluster number is 45.45=nTable 1 lists some typical origin clusters.
Onemay notice that countries speaking languages fromthe same family are often grouped together.
Thesecountries are either geographically adjacent or his-torically affiliated.
For example, in the Englishcluster, the Netherlands (Dutch) seems an abnor-mality.
In the clustering process it was firstgrouped with the South Africa, which was colo-nized by the Dutch and the English in the seven-teenth century.
This cluster was further groupedinto the English-speaking cluster.
Finally, someorigins cannot be merged with any other clustersbecause they have very unique names and transla-tion patterns, such as China and Japan, thus theyare kept as single origin clusters.For name transliteration task, given a sourcename F we want to classify it into the most likelycluster, so that the appropriate cluster-specificmodel can be selected for transliteration.
Notknowing F?s translation E, we cannot apply thetranslation model and the target language modelfor name origin classification.
Instead we train aBayesian classifier based on N-gram source char-acter language models, and assign the name to thecluster with the highest LM probability.
Assuminga source name is composed of a sequence of sourcecharacters: .
We want to find thecluster such that},...,,{ 21 lfffF =*j(1))()(maxarg)|()(maxarg)|(maxarg)(*FPPFPPFPjjcjjjjjjj???
?===where )( jP ?
is the prior probability of cluster j,estimated based on its distribution in all the train-ing data, and is the probability of generat-ing this source name based on cluster)()( FP jcj ?s characterlanguage model.3 Phrase-Based Name TransliterationStatistical NE transliteration is similar to the statis-tical machine translation in that an NE translationpair can be considered as a parallel sentence pair,where ?words?
are characters in source and targetlanguages.
Due to the nature of name translitera-tion, decoding is mostly monotone.Arabic Saudi Arabia, Sudan, Syria, Tunisia,Yemen, ?Spanish-PortugueseAngola, Argentina, Bolivia, Brazil,Chile, Colombia, Cuba, Ecuador, Mex-ico, Peru, Portugal, Spain, Venezuela,?English Australia, Canada, Netherlands, New Zealand, South Africa, UK, USA, ?Russian Belarus, Kazakhstan, Russia, UkraineEast Euro-peanBosnia and Herzegovina, Croatia,YugoslaviaFrench(African)Benin, Burkina Faso, Cameroon, Cen-tral African Republic, Congo, Gabon,Ivory CoastGerman Austria, Germany, SwitzerlandFrench Belgium, France, HaitiKorean North Korea, South KoreaDanish-Swedish Denmark, Norway, SwedenSingle Clus-tersChinaJapanIndonesiaIsrael?
?Table 1 Typical name clusters (n=45)437NE transliteration process can be formalized as:)()|(maxarg)|(maxarg* EPEFPFEPE EE ==where *E is the most likely transliteration for thesource NE F, P(F|E) is the transliteration modeland P(E) is the character-based target languagemodel.
We train a transliteration model and a lan-guage model for each cluster, using the nametranslation pairs from that cluster.3.1 Transliteration ModelA transliteration model provides a conditionalprobability distribution of target candidates for agiven source transliteration unit: a single characteror a character sequence, i.e., ?phrase?.
Givenenough name translation pairs as training data, wecan select appropriate source transliteration units,identify their target candidates from a characteralignment path within each name pair, and estimatetheir transliteration probabilities based on their co-occurrence frequency.A naive choice of source transliteration unit is asingle character.
However, single characters lackcontextual information, and their combinationsmay generate too many unlikely candidates.
Moti-vated by the success of phrase-based machinetranslation approaches (Wu 1997, Och 1999,Marcu and Wong 2002 and Vogel et.
al., 2003), weselect transliteration units which are long enoughto capture contextual information while flexibleenough to compose new names with other units.We discover such source transliteration phrasesbased on a character collocation likelihood ratiotest (Manning and Schutze 1999).
This test acceptsor rejects a null hypothesis that the occurrence ofone character is independent of the other, , bycalculating the likelihood ratio between the inde-pendent ( ) and dependent ( ) hypotheses:1f 2f0H 1H),,(log),,(log),,(log),,(log)()(loglog211221112112211210pcNccLpccLpcNccLpccLHLHL?????
?+==?L is the likelihood of getting the observed charactercounts under each hypothesis.
Assuming the char-acter occurrence frequency follows a binomial dis-tribution,        knk xxknxnkL ?????????
?= )1(),,( ,1221 ,, ccc  are the frequencies of , and ,and1f 2f 21 ^ ffN is the total number of characters.
andare defined as:1, pp2pNcp 2= ,2121 ccp = ,11222 cNccp ?
?= .We calculate the likelihood ratio for any adja-cent source character pairs, and select those pairswhose ratios are higher than a predefined threshold.Adjacent character bigrams with one characteroverlap can be recursively concatenated to formlonger source transliteration phrases.
All thesephrases and single characters are combined to con-struct a cluster-specific phrase segmentation vo-cabulary list, T. For each name pair in that cluster,we1.
Segment the Chinese character sequenceinto a source transliteration phrase se-quence based on maximum string match-ing using T;2.
Convert Chinese characters into their ro-manization form, pinyin, then align thepinyin with English letters via phoneticstring matching, as described in (Huang et.al., 2003);3.
Identify the initial phrase alignment pathbased on the character alignment path;4.
Apply a beam search around the initialphrase alignment path, searching for theoptimal alignment which minimizes theoverall phrase alignment cost, defined as:?
?=AaaiAiiefDA ),(minarg* .Here is the i th source phrase in F, is its tar-get candidate under alignment A.
Their alignmentcost D is defined as the linear interpolation of thephonetic transliteration cost log  and semantictranslation cost log :if iaetrlPtransP)|(log)1()|(log),( fePfePefD transtrl ??
?+= ,where is the trlP product of the letter transliterationprobabilities over aligned pinyin-English letterpairs, transP is the phrase translation probabilitycalculated from word translation probabilities,where a ?word?
refers to a Chinese character or aEnglish letter.
More details about these costs aredescribed in (Huang et.
al., 2003).
?
is a cluster-438specific interpolation weight, reflecting the relativecontributions of the transliteration cost and thetranslation cost.
For example, most Latin languagenames are often phonetically translated into Chi-nese, thus the transliteration cost is usually thedominant feature.
However, Japanese names areoften semantically translated when they containcharacters borrowed from Chinese, therefore thetranslation cost is more important for the Japanesemodel ( ?
=0 in this case).
We empirically selectthe interpolation weight for each cluster, based ontheir transliteration performance on held-out namepairs, and the combined model with optimal inter-polation weights achieves the best overall perform-ance.We estimate the phrase transliteration probabil-ity according to their normalized alignment fre-quencies.
We also include frequent sub-nametranslations (first, middle and last names) in thetransliteration dictionary.
Table 2 shows sometypical transliteration units (characters or phrases)from three clusters.
They are mostly names or sub-names capturing cluster-specific transliterationpatterns.
It also illustrates that in different clustersthe same character has different transliterationcandidates with different probabilities, which justi-fies the cluster-specific transliteration modeling.????
mohamed????
abdul????
ahmed Arabic?
: yo (0.27)  y(0.19)  you(0.14)???
john??
william??
peter English?
: u(0.25)  you(0.38)  joo(0.16)??????
vladimir????
ivanov-???
-yevich Russian??
yu(0.49)  y(0.08)  iu(0.07)?Table 2.
Transliteration units examples from threename clusters.3.2 Language model and decodingFor each cluster we train a target character lan-guage model from target NEs.
We use the N-grammodels with standard smoothing techniques.During monotone decoding, a source NE issegmented into a sequence of transliteration units,and each source unit is associated with a set of tar-get candidate translations with corresponding prob-abilities.
A transliteration lattice is constructed togenerate all transliteration hypotheses, amongwhich the one with the minimum transliterationand language model costs is selected as the finalhypothesis.4 Experiment ResultsWe selected 62K Chinese-English person nametranslation pairs for experiments.
These origin-labeled NE translation pairs are from the nameentity translation lists provided by the LDC 2(including the who?swho (china) and who?swho(international) lists), and devided into three parts:system training (90%), development (5%) andtesting (5%).
In the development and test data,names from each cluster followed the samedistribution as in the training data.4.1 NE Classification EvaluationWe evaluated the source name classification ac-curacy, because classification errors will lead toincorrect model selection, and result in badtransliteration performance in the next step.
Wetrained 45 cluster-specific N-gram source characterlanguage models, and classified each source nameinto the most likely cluster according to formula 1.We evaluated the classification accuracy on a held-out test set with 3K NE pairs.
We also experi-mented with different N values.
Table 3 shows theclassification accuracy, where the 3-gram modelachieves the highest classification accuracy.
A de-tailed analysis indicates that some classificationerrors are due to the inherent uncertainty of somenames, e. g, ????
(Gary Locke)?, a ChineseAmerican, was classified as a Chinese name basedon its source characters while his origin was la-beled as USA.Table 3.
Source name origin classification accura-cies2 http://www.ldc.upenn.eduN=2 N=3 N=4 N=5 N=6 N=783.62 84.88 84.00 84.04 83.94 83.944394.2 NE Transliteration EvaluationWe first evaluated transliteration results for eachcluster, then evaluated the overall results on thewhole test set, where a name was transliteratedusing the cluster-specific model in which it wasclassified.
The evaluation metrics are:?
Top1 accuracy (Top1), the percentagethat the top1 hypothesis is correct, i.e.,the same as the reference translation;?
Top 5 accuracy (Top5), the percentagethat the reference translation appears inthe generated top 5 hypotheses;?
Character error rate (CER), the percent-age of incorrect characters (inserted, de-leted and substituted English letters)when the top 1 hypothesis is aligned tothe reference translation.Our baseline system was a character-basedgeneral  transliteration model, where 56K NE pairsfrom all clusters were merged to train a generaltransliteration model and a language model(CharGen).
We compare it with a character-basedcluster-specific model (CharCls) and a phrase-based cluster-specific model (PhraCls).
The CERsof several typical clusters are shown in Table 4.Because more than half of the training namepairs are from Latin language clusters, the generaltransliteration and language models adopted theLatin name transliteration patterns.
As a result, itobtained reasonable performance (20-30% CERs)on  Latin language names, such as Spanish,English and French names, but strikingly high(over 70%) CERs on oriental language names suchas Chinese and Japanese names, even though theChinese cluster has the most training data.When applying the character-based cluster-specific models, transliteration CERs consistentlydecreased for all clusters (ranging from 6.13%relative reduction for the English cluster to 97%for the Chinese cluster).
As expected, the orientallanguage names obtained the most significant errorreduction because the cluster-specific models wereable to represent their unique transliterationpatterns.
When we applied the phrased-basedtransliteration models, CERs were further reducedby 23% ~ 51% for most clusters, because thecontext information were encapsulated in thetransliteration phrases.
An exception was theChinese cluster, where names were often translatedaccording to the pinyin of single characters, thusphrase-based transliteration slightly decreased theperformance.The transliteration performance of differentclusters varied a lot.
The Chinese cluster achieved96.09% top 1 accuracy and 1.69% CER with thecharacter-based model, and other clusters hadCERs ranging from 7% to 30%.
This was partlybecause of the lack of training data (e.g, for theJapanese cluster), and partly because of uniquetransliteration patterns of different languages.
Wetry to measure this difference using the averagenumber of translations per source phrase(AvgTrans), as shown in Table 4.
This featurereflected the transliteration pattern regularity, andseemed linearly correlated with the CERs.
Forexample, compared with the English cluster,Russian names have more regular translationpatterns, and its CER is only 1/3 of the Englishcluster, even with only half size of training data.In Table 5 we compared translation examplesfrom the baseline system (CharGen), the phrase-based cluster-specific system (PhraCls) and aonline machine translation system, the BabelFish3.The CharGen system transliterated every name inthe Latin romanization way, regardless of eachname?s original language.
The BabelFish systeminappropriately translated source characters basedon their semantic meanings, and the results weredifficult to understand.
The PhraCls modelcaptured cluster-specific contextual information,and achieved the best results.We evaluated three models?
performances on allthe test data, and showed the result in Table 6.
TheCharGen model performed rather poorlytransliterating oriental names, and the overall CERwas around 50%.
This result was comparable toother state-of-the-art statistical name transliterationsystems (Virga and Khudanpur, 2003).
TheCharCls model significantly improved the top1and top 5 transliteration accuracies from 3.78% to51.08%, and from 5.84% to 56.50%, respectively.Consistently, the CER was also reduced from50.29% to 14.00%.
Phrase-based transliterationfurther increased the top 1 accuracy by 9.3%, top 5accuracy by 10.7%, and reduced the CER by 8%,relatively.
All these improvements werestatistically significant.3 http://babelfish.altavista.com/440Table 4.
Cluster-specific transliteration comparisonTable 5.
Transliteration examples from some typical clustersCluster Training data sizeCharGen(CER)CharCls(CER)PhraCls(CER) AvgTransArabic 8336 22.88 18.93 14.47 4.58Chinese 27093 76.45 1.69 1.71 3.43English 8778 31.12 29.21 17.27 5.02French 2328 27.66 18.81 9.07 3.51Japanese 2161 86.94 38.65 29.60 7.57Russian 4407 29.17 9.62 6.55 3.64Spanish 8267 18.87 15.99 10.33 3.61Cluster Source  Reference CharGen PhraCls BabelFishArabic??
??????
?Nagui SabriAhmedNaji SaburiAhamedNaji SabriAhmedIn natrium ??
clothAihamaideChinese ???
Fan Zhilun Van Tylen Fan zhilun Fan ZhilunEnglish???????
?RobertSteadwardRobertStdwadRobertSterdewardRobert SteadWarderFrench?-????
?Jean-lucCretierJean-lukCreteJean-lucCretierLet - Lu Kekelei JieJapanese ????
Kobayashi Ryoji FelinongeKobayashiTakajiXiaolin pros-perous gov-ernsRussian??????????VladimirSamsonovFrakimirSamsonofVladimirSamsonov???
milsum ropeKnoffSpanish?????
?RodolfoCardosoRudoufCardosoRodolfoCadozoRudolph cardmulti- ropes441Model Top1 (%) Top5 (%) CER (%)CharGen 3.78?0.69 5.84?0.88 50.29?1.21CharCls 51.08?0.84 56.50?0.87 14.00?0.34PhraCls 56.00?0.84 62.66?0.91 12.84?0.41Table 6 Transliteration result comparison5 ConclusionWe have proposed a cluster-specific NE translit-eration framework.
This framework effectivelymodeled the transliteration differences of sourcenames from different origins, and has demon-strated substantial improvement over the baselinegeneral model.
Additionally, phrase-based translit-eration further improved the transliteration per-formance by a significant margin.ReferencesY.
Al-Onaizan and K. Knight.
2002.
Translatingnamed entities using monolingual and bilingualresources.
In Proceedings of the ACL-2002,pp400-408, Philadelphia, PA, July, 2002.F.
Huang and S. Vogel.
2002.
Improved NamedEntity Translation and Bilingual Named EntityExtraction, Proceedings of the ICMI-2002.Pittsburgh, PA, October 2002F.
Huang, S. Vogel and A. Waibel.
2003.
Auto-matic Extraction of Named Entity TranslingualEquivalence Based on Multi-feature Cost Mini-mization.
Proceedings of the ACL-2003, Work-shop on Multilingual and Mixed LanguageNamed Entity Recognition.
Sapporo, Japan.K.
Knight and J. Graehl.
1997.
Machine Translit-eration.
Proceedings of the ACL-1997.
pp.128-135, Somerset, New Jersey.C.
J. Lee and J. S. Chang.
2003.
Acquisition ofEnglish-Chinese Transliterated Word Pairs fromParallel-Aligned Texts using a Statistical Ma-chine Transliteration Model.
HLT-NAACL 2003Workshop: Building and Using Parallel Texts:Data Driven Machine Translation and Beyond.pp96-103, Edmonton, Alberta, Canada.C.
D. Manning and H. Sch?tze.
1999.
Foundationsof Statistical Natural Language Processing.
MITPress.
Boston MA.H.
Meng, W. K. Lo, B. Chen and K. Tang.
2001.Generating Phonetic Cognates to Handle NamedEntities in English-Chinese Cross-LanguageSpoken Document Retrieval.
Proceedings of theASRU-2001, Trento, Italy, December.2001D.
Marcu and W. Wong.
A Phrase-Based, JointProbability Model for Statistical Machine Trans-lation.
Proceedings of EMNLP-2002, Philadel-phia, PA, 2002F.
J. Och, C. Tillmann, and H. Ney.
ImprovedAlignment Models for Statistical MachineTranslation.
pp.
20-28; Proc.
of the Joint Conf.of Empirical Methods in Natural LanguageProcessing and Very Large Corpora; Universityof Maryland, College Park, MD, June 1999.Y.
Qu, and G. Grefenstette.
Finding IdeographicRepresentations of Japanese Names Written inLatin Script via Language Identification andCorpus Validation.
ACL 2004: 183-190P.
Virga and S. Khudanpur.
2003.
Transliterationof Proper Names in Cross-Lingual InformationRetrieval.
Proceedings of the ACL-2003 Work-shop on Multi-lingual Named Entity RecognitionJapan.
July 2003.S.
Vogel, Y. Zhang, F. Huang, A. Tribble, A.Venogupal, B. Zhao and A. Waibel.
The CMUStatistical Translation System, Proceedings ofMT Summit IX New Orleans, LA, USA, Sep-tember 2003D.
Wu.
Stochastic Inversion Transduction Gram-mars and Bilingual Parsing of Parallel Corpora.Computational Linguistics 23(3):377-404, Sep-tember 1997.442
