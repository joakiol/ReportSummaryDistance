Recognition of synonyms by a lexical graphPeter Siniakovsiniakov@inf.fu-berlin.deDatabase and Information Systems Group, Freie Universita?t BerlinTakustr.
9, 14195 Berlin, GermanyAbstractSemantic relationships between wordscomprised by thesauri are essential fea-tures for IR, text mining and informa-tion extraction systems.
This paper in-troduces a new approach to identifica-tion of semantic relations such as syn-onymy by a lexical graph.
The graphis generated from a text corpus by em-bedding syntactically parsed sentencesin the graph structure.
The verticesof the graph are lexical items (words),their connection follows the syntacticstructure of a sentence.
The struc-ture of the graph and distances be-tween vertices can be utilized to definemetrics for identification of semanticrelations.
The approach has been eval-uated on a test set of 200 German syn-onym sets.
Influence of size of the textcorpus, word generality and frequencyhas been investigated.
Conducted ex-periments for synonyms demonstratethat the presented methods can be ex-tended to other semantic relations.1 IntroductionOnce predominantly used by human authorsto improve their style avoiding repetitions ofwords or phrases, thesauri now serve as an im-portant source of semantic and lexical infor-mation for automatic text processing.
Theelectronic online thesauri such as WordNet(2005) and OpenThesaurus (2005) have beenincreasingly employed for many IR and NLPproblems.
However, considerable human ef-fort is required to keep up with the evolvinglanguage and many subdomains are not suffi-ciently covered (Turney, 2001).
Many domain-specific words or word senses are not included;inconsistency and bias are often cited as fur-ther major deficiencies of hand-made thesauri(Curran and Moens, 2002), (Senellart andBlondel, 2003).
There is a continuous demandfor automatic identification of semantic rela-tions and thesaurus generation.
Such toolsdo not only produce thesauri that are moreadapted to a particular application in a cer-tain domain, but provide also assistance forlexicographers in manual creation and keepingthe hand-written thesauri up to date.
Numer-ous applications in IR (e.g.
query expansion)and text mining (identification of relevant con-tent by patterns) underline their usefulness.2 Related workIdentification of semantic relations has beenapproached by different communities as a com-ponent of a knowledge management system orapplication of a developed NLP framework.Many approaches are guided by the assump-tion that similar terms occur in similar contextand obtain a context representation of termsas attribute vectors or relation tuples (Cur-ran and Moens, 2002), (Ruge, 1997), (Lin,1998).
A similarity metric defined on the con-text representations is used to cluster similarterms (e.g.
by the nearest neighbor method).The actual definitions of context (whole doc-ument (Chen and Lynch, 1992), textual win-dow, some customized syntactic contexts, cf.
(Senellart and Blondel, 2003)) and similar-ity metric (cf.
(Manning and Schu?tze, 1999),(Curran and Moens, 2002)) are the essentialdistinguishing features of the approaches.A pattern-based method is proposed byHearst (Hearst, 1998).
Existing relations inthe WordNet database are used to discoverregular linguistic patterns that are character-istic for these relations.
The patterns containlexical and syntactic elements and are acquired32from a text corpus by identifying common con-text of word pairs for which a semantic rela-tion holds.
Identified patterns are applied to alarge text corpus to detect new relations.
Themethod can be enhanced by applying filteringsteps and iterating over new found instances(Phillips and Riloff, 2002).Lafourcade and Prince base their approachon reduction of word semantics to conceptualvectors (vector space is spanned by a hierarchyof concepts provided by a thesaurus, (Lafour-cade, 2001)).
Every term is projected in thevector space and can be expressed by the linearcombination of conceptual vectors.
The anglebetween the vectorial representations of twoterms is used in calculation of thematic close-ness (Lafourcade and Prince, 2001).
The ap-proach is more closely related to our approachsince it offers a quantitative metric to measurethe degree of synonymy between two lexicalitems.In contrast, Turney (Turney, 2001) tries tosolve a quite simpler ?TOEFL-like?
task of se-lecting a synonym to a given word from a setof words.
Mutual information related to theco-occurrence of two words combined with in-formation retrieval is used to assess the degreeof their statistical independency.
The least in-dependent word is regarded synonymous.Blondell et al (Blondel et al, 2004) encodea monolingual dictionary as a graph and iden-tify synonyms by finding subgraphs that aresimilar to the subgraph corresponding to thequeried term.The common evaluation method for similar-ity metrics is comparing their performance onthe same test set with the same context repre-sentations with some manually created seman-tic source as the gold standard (Curran andMoens, 2002).
Abstracting from results forconcrete test sets, Weeds et al (2004) try toidentify statistical and linguistic properties onthat the performance of similarity metrics gen-erally depends.
Different bias towards wordswith high or low frequency is recognized as onereason for the significant variance of k-nearestneighbors sets of different similarity metrics.3 Construction of the lexical graphThe assumption that similar terms occur insimilar context leads to the establishing of ex-plicit context models (e.g.
in form of vectors orrelation tuples) by most researchers.
We buildan implicit context representation connectinglexical items in a way corresponding to the sen-tence structure (as opposed to (Blondel et al,2004)), where a term is linked to every wordin its definition).
The advantage of the graphmodel is its transitivity: not only terms in theimmediate context but also semantically re-lated terms that have a short path to the ex-amined term (but perhaps have never occurredin its immediate context) can contribute toidentification of related terms.
The similaritymetric can be intuitively derived from the dis-tance between the lexical vertices in the graph.Figure 1: Main steps during graph construc-tionTo construct the lexical graph articles fromfive volumes of two German computer jour-nals have been chunk-parsed and POS taggedusing TreeTagger (2004).
To preserve the se-mantic structure of the sentences during thegraph construction, i.e.
to connect words thatbuild the actual statement of the sentence,parsed sentences are preprocessed before be-ing inserted in the graph (fig.
1).
The punc-tuation signs and parts of speech that do notcarry a self-contained semantics (such as con-junctions, pronouns, articles) are removed ina POS filtering step.
Tokenization errors areheuristically removed and the words are re-placed by their normal forms (e.g.
infinitiveform for verbs, nominative singular for nouns).German grammar is characterized by a veryfrequent use of auxiliary and modal verbs thatin most cases immediately precede or followthe semantically related sentence parts suchas direct object or prepositional phrase whilethe main verb is often not adjacent to therelated parts in a sentence.
Since the directedge between the main verb and non-adjacentrelated sentence parts cannot be drawn, the33sentence is syntactically reorganized by replac-ing the modal or auxiliary verbs by the corre-sponding main verb.
Another syntactic rear-rangement takes place when detachable pre-fixes are attached to the corresponding mainverb.
In German some prefixes of verbs aredetached and located at the end of the mainclause.
Since verbs without a prefix have adifferent meaning prefixes have to be attachedto the verb stem.
The reorganized sentenceFigure 2: An example of a sentence trans-formed in a lexical graphcan be added to the graph inserting the nor-malized words in a sentence as vertices andconnecting the adjacent words by a directededge.
However, some adjacent words are notsemantically related to each other, thereforethe lexical graph features two types of edges(see an example in fig.
2).
A property edgelinks the head word of a syntactic chunk (verbor noun phrase) with its modifiers (adverbs oradjectives respectively) that characterize thehead word and is bidirectional.
A sequentialedge connects the head words (e.g.
main verbs,head nouns) of syntactic chunks reflecting the?semantic backbone?
of the sentence.The length of an edge represents how strongtwo lexical items are related to each other anddepends therefore on the frequency of theirco-occurrence.
It is initialized with a maxi-mum length M .
Every time an existing edgeis found in the currently processed sentence,its current length CurLen is modified accord-ing to CurLen = MMCurLen+1; hence the lengthof an edge is inversely proportional to the fre-quency of co-occurrence of its endpoints.After all sentences from the text corpushave been added to the lexical graph, vertices(words) with a low frequency (?
?)
are re-moved from the graph to primarily acceler-ate the distance calculation.
Such rarely oc-curring words are usually proper nouns, ab-breviations, typos etc.
Because of the lowfrequency semantic relations for these wordscannot be confidently identified.
Thereforeremoving such vertices reduces the size ofthe graph significantly without performancepenalty (the graph generated from 5 journalvolumes contained ca.
300000 vertices and52191 after frequency filtering with ?
= 8).Experimental results feature even a slightlybetter performance on filtered graphs.
To pre-serve semantic consistency of the graph andcompensate removal of existing paths the con-nections between the predecessors and succes-sors of removed vertices have to be taken intoaccount: the edge length e(p, s) between thepredecessor p to the successor s of the re-moved vertex r can incorporate the length ofthe path length(p, r, s) from p to s throughr by calculating the halved harmonic mean:e(p, s) = e(p,s)?lprse(p,s)+lprs .
e(p, s) is the more re-duced the smaller length(p, r, s) is and if theyare equal, e(p, s) is half as long after merging.Beside direct edges an important indicationof semantic closeness is the distance, i.e.
thelength of the shortest path between two ver-tices.
Distances are calculated by the Dijk-stra algorithm with an upper threshold ?.Once the distances from a certain vertex reachthe threshold, the calculation for this vertexis aborted and the not calculated distancesare considered infinite.
Using the thresholdreduces the runtime and space considerablywhile the semantic relation between the ver-tices with distances > ?
is negligible.The values of M , ?
and ?
depend onthe particular text corpus and are chosento keep the size of the graph feasible.
?can be determined experimentally increment-ing it as long as the results on the test setare improving.
The resulting graph gener-ated from five computer journals volumes withM = 220, ?
= 8, ?
= 60000 con-tained 52191 vertices, 4,927,365 edges and376,000,000 distances.4 Identification of synonymsThe lexical graph is conceived as an instru-ment to identify semantic relations such assynonymy and hypernymy between lexicalitems represented by its vertices.
The main34focus of our research was finding synonyms al-beit some results can be immediately trans-ferred for identification of hyponyms.
To pro-vide a quantitative measure of synonymy dif-ferent similarity metrics were defined on thelexical graph.
Given a word, the system usesthe metric to calculate the closest vertices tothe vertex that represents this word.
The re-sult is a ranked list of words sorted by the de-gree of synonymy in descending order.
Everymetric sim is normalized to be a probabilitymeasure so that given a vertex vi the valuesim(vi, vj) can be interpreted as the probabil-ity of vj being synonym to vi.
The normaliza-tion is performed for each metric sim by thefollowing functions:nmin(sim(vi, vj)) = min(sim(vi,v1),...,sim(vi,vn))sim(vi,vj)for metrics that indicate maximum similarityto a vertex vi by a minimum value andnmax(sim(vi, vj)) = sim(vi,vj)max(sim(vi,v1),...,sim(vi,vn))for metrics that indicate maximum similarityto a vertex vi by a maximum value, wherev1 .
.
.
vn are the set of graph vertices.
In bothcases the top-ranked word has the maximumlikelihood of 1 to be a synonym of vi.
Thenormalized ranked lists are used for the com-parison of different metrics and the evaluationof the approach (see sec.
5).A similarity metric is supposed to assess thesemantic similarity between two vertices of thelexical graph.
Since the distance metric Dis-tanceM used for calculation of distances be-tween the vertices in the graph indicates howsemantically related two vertices are, it can beused as a similarity metric.
As the graph is di-rected, the distance metric is asymmetric, i.e.the distance from vj to vi does not have tobe equal to the distance from vi to vj .
Themajor drawback of the DistanceM is that ittakes into account only one path between theexamined vertices.
Even though the shortestpath indicates a strong semantic relation be-tween the vertices, it is not sufficient to con-clude synonymy that presupposes similar wordsenses.Therefore more evidence for strong seman-tic relation with the particular aspect of sim-ilar word senses should be incorporated inthe similarity metric.
The property neigh-bors of a vertex vi (adjacent vertices connectedwith vi by the property edge) play significantrole in characterizing similar senses.
If twoterms share many characteristic properties,there is a strong evidence of their synonymy.A shared property can be regarded as a witnessof the similarity of two word senses.
Thereare other potential witnesses, e.g.
transitiveverbs shared by their direct objects; however,we restricted this investigation to the propertyneighbors as the most reliable witnesses.The simple method to incorporate the con-cept of the witnesses into the metric is todetermine the number of common propertyneighbors:NaivePropM(vi, vj) = |prop(vi) ?
prop(vj)|where prop(vi) = {vk|e(i, k) is a property edge}This method disregards, however, the differentdegree of correlation between the vertices andtheir property neighbors that is reflected bythe length of property edges.
A property is themore significant, the stronger the correlationbetween the property and the vertex is, thatis the shorter the property edge is.
The degreeof synonymy of two terms depends thereforeon the number of common properties andthe lengths of paths between these termsleading through the properties.
Analogouslyto the electric circuit one can see the singlepaths through different shared properties aschannels in a parallel connection and pathlengths as ?synonymy resistances?.
Since abigger number of channels and smaller singleresistances contribute to the decreasing of thetotal resistance (i.e.
the evidence of synonymyincreases), the idea of WeiPropM metric is todetermine the similarity value analogously tothe total resistance in a parallel connection:WeiPropM ?
(vi, vj) =( n?k=11length(vi, pk, vj))?1where length(vi, pk, vj) = e(vi, pk) + e(pk, vj)is the length of the path from vi to vj throughpk and pk ?
prop(vi) ?
prop(vj).Another useful observation is that someproperties are more valuable witnesses thanthe others.
There are very general propertiesthat are shared by many different terms and35some properties that are characteristic onlyfor certain word senses.
Thus the number ofproperty neighbors of a property can be re-garded as a measure of its quality (in the senseof characterizing the specific word meaning).WeiPropM integrates the quality of a prop-erty by weighting the paths leading through itby the number of its property neighbors:WeiPropM(vi, vj) =( n?k=11(e(vi, pk) + e(pk, vj)) ?
|prop(pk)|)?1where pk ?
prop(vi) ?
prop(vj).WeiPropM measures the correlation be-tween two terms based on the path lengths.Frequently occurring words tend to be rankedhigher because the property edge lengths indi-rectly depend on the absolute word frequency.Because of high absolute frequency of wordsthe frequency of their co-occurrence with dif-ferent properties is generally also higher andthe property edges are shorter.
Therefore tocompensate this deficiency (i.e.
to eliminatethe bias discussed in (Weeds et al, 2004))an edge length from a property to a rankedterm e(pk, vj) is weighted by the square rootof its absolute frequency?freq(vj).
Usingthe weighted edge length between the propertyand the ranked term we cannot any longer cal-culate the path length between vi and vj as thesum length(vi, pk, vj) = e(vi, pk) + e(pk, vj) ?
?freq(vj) because the multiplied second com-ponent significantly outweighs the first sum-mand.
Relative path length can be used in-stead where both components are adequatelytaken into account and added relativelyto the minimum of the respective compo-nent: let min1 be min(e(vi, pa), .
.
.
, e(vi, pn))where pk ?
prop(vi) and min2 =min(.
.
.
, e(pk, vj) ?
?freq(vj), .
.
.)
wherepk ?
prop(vi)?
prop(vj).
Relative path lengthwould be e(vi,pk)min1 +e(pk,vj)?
?freq(vj)min2 .
Furtherexperimental observation suggests that whensearching for synonyms of vi the connectionbetween vi and the property is more signifi-cant than the second component of the path ?the connection between the property and theranked term vj .
Therefore when calculatingthe relative path length the first componenthas to be weighted stronger (the examined ra-tio was 2:1).
The corresponding metric can bedefined as follows:FirstCompM(vi, vj) =(?nk=11RelPathLength(k)?
?|prop(pk)|)?1where RelPathLength(x) =23 ?e(vi, px)min1 +13 ?e(px, vj) ?
?freq(vj)min2As opposed to NaivePropM and WeiPropMFirstCompM is not symmetric because of theemphasis on the first component.5 ExperimentsFor evaluation purposes a test corpus of200 synonym sets was prepared consulting(OpenThesaurus, 2005).
The corpus con-sists of 75 everyday words (e.g.
?Pra?sident?
(president), ?Eingang?
(entrance) ?Gruppe?
(group)), 60 abstract terms (e.g.
?Ursache?
(reason), ?Element?, ?Merkmal?
(feature))and 65 domain-specific words (e.g.
?Software?,?Prozessor?
(CPU)).
The evaluation strat-egy is similar to that pursued in(Curran andMoens, 2002).
The similarity metrics do notdistinguish between different word senses re-turning synonyms of all senses of the polyse-mous words in a single ranked list.
Thereforethe synonym set of a word in the test cor-pus is the union of synonym sets of its senses.To provide a measure for overall performanceand to compare the different metrics a func-tion measuring the similarity score (SimS) wasdefined that assigns a score to a metric forcorrectly found synonyms among the 25 top-ranked.
The function assigns 25 points tothe correctly found top-ranked synonym of vi(SimS(0, vi) = 25) and 1 point to the syn-onym with the 25th rank (SimS(25, vi) = 1).The rank of a synonym is decreased only byfalse positives that are ranked higher (i.e.
eachof correctly identified top n synonyms has rank0).
In order to reward the top-ranked syn-onyms stronger the scoring function features ahyperbolic descent.
For a synonym of vi withthe rank x:SimS(x, vi) =??
?0, if x /?
synset(vi)24??26(?26?1)?
?x+1 + 1?24?26?1??
?36To compare performance of differentmetrics the SimS values of the top 25words in the ranked list were summedfor each word of a test corpus.
The to-tal score of a similarity metric Sim is?200i=1?25j=1 SimS(rank(RankedList(vi, j)), vi)where RankedList(vi, j) returns the word atthe position j from the ranked list producedby Sim for vi and v1, .
.
.
, v200 are the wordsof the test corpus.Besides, a combined precision and recallmeasure ?
was used to evaluate the rankedlists.
Given the word vi, we examined the firstn words (n = 1, 5, 25, 100) of the ranked listreturned by a similarity metric for vi whetherthey belong to the synset(vi) of the test cor-pus.
?
(n) will measure precision if n is lessthan the size of the synset(vi) because themaximum recall can not be reached for suchn and recall otherwise because maximum pre-cision cannot be reached for n > |synset(vi)|.The ?
values were averaged over 200 words.Table 1 presents the result of evaluating thesimilarity metrics introduced in sec.
4.
Theresults of DistanceM confirm that regardingdistance between two vertices alone is notsufficient to conclude their synonymy.
Dis-tanceM finds many related terms ranking gen-eral words with many outgoing and incomingedges higher, but it lacks the features pro-viding the particular evidence of synonymy.NaivePropM is clearly outperformed by theboth weighted metrics.
The improvement rel-ative to the DistanceM and acceptable pre-cision of the top-ranked synonyms ?
(1) showthat considering shared properties is an ad-equate approach to recognition of synonyms.Ignoring the strength of semantic relation in-dicated by the graph and the quality of prop-erties is the reason for the big gap in thetotal score and recall value (?(100)).
Bothweighted metrics achieved results comparablewith those reported by Curran and Moensin (Curran and Moens, 2002) and Turney in(Turney, 2001).
Best results of FirstCompMconfirm that the criteria identified in sec.
4such as generality of a property, abstractionfrom the absolute word frequency etc.
are rel-evant for identification of synonyms.
First-CompM performed particularly better in find-ing synonyms with the low frequency of occur-rence.In another set of experiments we investi-gated the influence of the size of the text cor-pus (cf.
fig.
3).
The plausible assumptionis the more texts are processed, the betterthe semantic connections between terms arereflected by the graph, the more promising re-sults are expected.
The fact that the num-ber of vertices does not grow proportionallyto the size of text corpus can be explained byword recurrence and growing filtering thresh-old ?.
However, the number of edges increaseslinearly and reflects the improving semanticcoverage.
As expected, every metric performsconsiderably better on bigger graphs.
WhileNaivePropM seems to converge after threevolumes, the both weighted metrics behavestrictly monotonically increasing.
Hence animprovement of results can be expected on big-ger corpora.
On the small text corpora the re-sults of single metrics do not differ significantlysince there is not sufficient semantic informa-tion captured by the graph, i.e.
the edge andpath lengths do not fully reflect the seman-tic relations between the words.
The scoresof both weighted metrics grow, though, muchfaster than that of NaivePropM.
FirstCompMachieves the highest gradient demonstratingthe biggest potential of leveraging the grow-ing graph for finding synonymy.Figure 3: Influence of the size of the text cor-pus.To examine the influence of the word cat-egories results on the subsets of the text cor-pus corresponding to a category are compared.All metrics show similar behavior, thereforewe restrict the analysis to the ?
values of37Metric Score ?
(1) ?
(5) ?
(25) ?
(100)DistanceM 2990.7 0.20 0.208 0.199 0.38NaivePropM 6546.3 0.415 0.252 0.271 0.440WeiPropM 9411.7 0.54 0.351 0.398 0.607FirstCompM 11848 0.575 0.412 0.472 0.637Table 1: Results of different metrics on the test corpusFirstCompM (fig.
4).
Synonyms of domain-specific words are recognized better than thoseof abstract and everyday words.
Their se-mantics are better reflected by the technicallyoriented texts.
The ?
values for abstractand everyday words are pretty similar exceptfor the high precision of top-ranked abstractsynonyms.
Everyday words suffer from thefact that their properties are often too gen-eral to uniquely characterize them, which in-volves loss of precision.
Abstract words canbe extremely polysemous and have many sub-tle aspects that are not sufficiently covered bythe texts of computer journals.Figure 4: Dependency of ?
(n) on word cate-gory (results of FirstCompM metric)To test whether the metrics perform bet-ter for the more frequent words the test setwas divided in 9 disjunctive frequency clus-ters (table 2).
FirstCompM achieved consid-erably better results for very frequently occur-ring words (?
4000 occurrences).
This con-firms indirectly the better results on the big-ger text corpora: while low frequency does notexclude random influence, frequent occurrenceinvolves adequate capturing of the word se-mantics in the graph by inserting and adjust-ing all relevant property edges.
These resultsdo not contradict the conclusion that First-CompM is not biased towards words with acertain frequency because the mentioned biaspertains to retrieval of synonyms with a cer-tain frequency, whereas in this experiment theperformance for different word frequencies ofqueried words is compared.6 ConclusionWe have introduced the lexical graph as aninstrument for finding semantic relations be-tween lexical items in natural language cor-pora.
The big advantage of the graph in com-parison to other context models is that it cap-tures not only the immediate context but es-tablishes many transitive connections betweenrelated terms.
We have verified its effective-ness searching for synonymy.
Different met-rics have been defined based on shortest pathlengths and shared properties.
Similarity met-ric FirstCompM that best leverages the graphstructure achieved the best results confirmingthe significant role of number of shared proper-ties, frequency of their co-occurrence and thedegree of their generality for detecting of syn-onymy.
Significantly improving results for big-ger text corpora and more frequently occurringwords are encouraging and promising for de-tection of other semantic relations.
New meth-ods that increasingly employ the graph struc-ture e.g.
regarding the lengths and numberof short paths between two terms or extend-ing the witness concept to other morphologicaltypes are the subject of further research.AcknowledgementsI would like to thank Heiko Kahmann forthe valuable assistance in implementation andevaluation of the approach.
This research issupported by NaFo?G scholarship of the fed-eral state Berlin.ReferencesVincent D. Blondel, Anah Gajardo, Maureen Hey-mans, Pierre Senellart, and Paul Van Dooren.38Frequency 9-249 250-499 500-999 1000-1499 1500-2499 2500-3999 4000-5499 5500-7499 >7500Words/cluster 27 25 44 30 27 15 11 8 13Aver.
score 53.23 51.52 45.80 60.75 56.51 58.75 97.21 106.11 73.85?
(1) 0.556 0.52 0.432 0.567 0.667 0.667 0.818 0.75 0.615?
(5) 0.381 0.392 0.342 0.395 0.393 0.413 0.600 0.675 0.503?
(25) 0.447 0.432 0.446 0.494 0.474 0.419 0.531 0.550 0.600?
(100) 0.561 0.645 0.618 0.610 0.690 0.623 0.705 0.642 0.748Table 2: Influence of word frequency on the results of FirstCompM metric2004.
A measure of similarity between graphvertices.
With applications to synonym extrac-tion and web searching.
In SIAM Review, pages647?666.Hsinchun Chen and Kevin J. Lynch.
1992.
Auto-matic construction of networks of concepts char-acterizing document databases.
In IEEE Trans-actions on Systems, Man and Cybernetics, vol-ume 22(5), pages 885?902.James R. Curran and Marc Moens.
2002.
Improve-ments in automatic thesaurus extraction.
InProceedings of the Workshop of the ACL SpecialInterest Group on the Lexicon (SIGLEX), pages59?66.
Association for Computational Linguis-tics.M.
A. Hearst.
1998.
Automated discovery ofWordnet relations.
In C. Fellbaum, editor,Wordnet An Electronic Lexical Database, pages131?151.
MIT Press, Cambridge, MA.Mathieu Lafourcade and Violaine Prince.
2001.Relative synonymy and conceptual vectors.
InProceedings of the NLPRS, Tokyo, Japan.Mathieu Lafourcade.
2001.
Lexical sorting andlexical transfer by conceptual vectors.
In Pro-ceedings of the First International Workshop onMultiMedia Annotation, Tokyo, Japan.Dekang Lin.
1998.
An information-theoreticdefinition of similarity.
In Proceedings of theFifteenth International Conference on MachineLearning, pages 296?304, Madison, WI.Christopher D. Manning and Hinrich Schu?tze.1999.
Foundations of Statistical Natural Lan-guage Processing.
MIT Press, Cambridge, MA2000.OpenThesaurus.
2005.
OpenThesaurus- Deutscher Thesaurus.
http://www.openthesaurus.de.William Phillips and Ellen Riloff.
2002.
Exploit-ing strong syntactic heuristics and co-trainingto learn semantic lexicons.
In Proceedings of the2002 Conference on Empirical Methods in NLP.Gerda Ruge.
1997.
Automatic detection of the-saurus relations for information retrieval appli-cations.
Foundations of Computer Science: Po-tential - Theory - Cognition, LNCS 1337:499?506.Pierre P. Senellart and Vincent D. Blondel.
2003.Automatic discovery of similar words.
InMichael Berry, editor, Survey of Text Mining.Clustering, classification, and retrieval, pages25?44.
Springer Verlag, Berlin.TreeTagger.
2004. http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/.Peter D. Turney.
2001.
Mining the Web for syn-onyms: PMI?IR versus LSA on TOEFL.
Lec-ture Notes in Computer Science, 2167:491?502.Julie Weeds, David Weir, and Diana McCarthy.2004.
Characterising measures of lexical distri-butional similarity.WordNet.
2005. http://wordnet.princeton.edu/w3wn.html.39
