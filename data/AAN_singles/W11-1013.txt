Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 116?125,ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational LinguisticsCombining statistical and semantic approaches to the translation ofontologies and taxonomiesJohn McCraeAG Semantic ComputingUniversita?t BielefeldBielefeld, Germanyjmccrae@cit-ec.uni-bielefeld.deMauricio EspinozaUniversidad de CuencaCuenca, Ecuadormauricio.espinoza@ucuenca.edu.ecElena Montiel-Ponsoda, Guadalupe Aguado-de-CeaOntology Engineering GroupUniversidad Polite?cnica de MadridMadrid, Spain{emontiel, lupe}@fi.upm.esPhilipp CimianoAG Semantic ComputingUniversita?t BielefeldBielefeld, Germanycimiano@cit-ec.uni-bielefeld.deAbstractOntologies and taxonomies are widely used toorganize concepts providing the basis for ac-tivities such as indexing, and as backgroundknowledge for NLP tasks.
As such, trans-lation of these resources would prove use-ful to adapt these systems to new languages.However, we show that the nature of theseresources is significantly different from the?free-text?
paradigm used to train most sta-tistical machine translation systems.
In par-ticular, we see significant differences in thelinguistic nature of these resources and suchresources have rich additional semantics.
Wedemonstrate that as a result of these linguisticdifferences, standard SMT methods, in partic-ular evaluation metrics, can produce poor per-formance.
We then look to the task of leverag-ing these semantics for translation, which weapproach in three ways: by adapting the trans-lation system to the domain of the resource;by examining if semantics can help to predictthe syntactic structure used in translation; andby evaluating if we can use existing translatedtaxonomies to disambiguate translations.
Wepresent some early results from these experi-ments, which shed light on the degree of suc-cess we may have with each approach.1 IntroductionTaxonomies and ontologies are data structures thatorganise conceptual information by establishing re-lations among concepts, hierarchical and partitiverelations being the most important ones.
Nowadays,ontologies have a wide range of uses in many do-mains, for example, finance (International Account-ing Standards Board, 2007), bio-medicine (Col-lier et al, 2008) (Ashburner et al, 2000) and li-braries (Mischo, 1982).
These resources normallyattach labels in natural language to the concepts andrelations that define their structure, and these la-bels can be used for a number of purposes, suchas providing user interface localization (McCrae etal., 2010), multilingual data access (Declerck et al,2010), information extraction (Mu?ller et al, 2004)and natural language generation (Bontcheva, 2005).It seems natural that for applications that use suchontologies and taxonomies, translation of the natu-ral language descriptions associated with them is re-quired in order to adapt these methods to new lan-guages.
Currently, there has been some work onthis in the context of ontology localisation, suchas Espinoza et al (2008) and (2009), Cimiano etal.
(2010), Fu et al (2010) and Navigli and Pen-zetto (2010).
However, this work has focused on thecase in which exact or partial translations are foundin other similar resources such as bilingual lexica.Instead, in this paper we look at how we may gain anadequate translation using statistical machine trans-lation approaches that also utilise the semantic in-formation beyond the label or term describing theconcept, that is relations among the concepts in theontology, as well as the attributes or properties thatdescribe concepts, as will be explained in more de-tail in section 2.Current work in machine translation has shownthat word sense disambiguation can play an im-portant role by using the surrounding words ascontext to disambiguate terms (Carpuat and Wu,2007) (Apidianaki, 2009).
Such techniques have116been extrapolated to the translation of taxonomiesand ontologies, in which the ?context?
of a taxon-omy or ontology label corresponds to the ontologystructure that surrounds the label in question.
Thisstructure, which is made up of the lexical informa-tion provided by labels and the semantic informa-tion provided by the ontology structure, defines thesense of the concept and can be exploited in the dis-ambiguation process (Espinoza et al, 2008).2 Definition of Taxonomy and OntologyTranslation2.1 Formal DefinitionWe define a taxonomy as a set of concepts, C, withequivalence (synonymy) links, S, subsumption (hy-pernymy) links, H , and a labelling function l thatmaps each concept to a single label from a language??.
Formally we define a taxonomy, T , as a set oftuples (C, S,H, l) such that S ?
P(C ?
C) andH ?
P(C ?
C) and l is a function in C ?
??.
Wealso require that S is a transitive, symmetric and re-flexive relation, and H is transitive.
While we notehere that this abstraction does not come close to cap-turing the full expressive power of many ontologies(or even taxonomies), it is sufficient for this paper tofocus on the use of only equivalence and subsump-tion relationships for translation.2.2 Analysis of ontology labelsAnother important issue to note here is that thekind of language used within ontologies and tax-onomies is significantly different from that foundwithin free text.
In particular, we observe that theterms used to designate concepts are frequently justnoun phrases and are significantly shorter than ausual sentence.
In the case of the relations betweenconcepts (dubbed object properties) and attributesof concepts (data type properties), these are occa-sionally labelled by means of verbal phrases.
Wedemonstrate this by looking at three widely used on-tologies/taxonomies.1.
Friend of a friend: The Friend of a Friend(FOAF) ontology is used to describe socialnetworks on the Semantic Web (Brickley andMiller, 2010).
It is a small taxonomy with veryshort labels.
Labels for concepts are compoundwords made up of up to three words.2.
Gene Ontology: The Gene Ontology (Ash-burner et al, 2000) is a very large database ofterminology related to genetics.
We note thatwhile some of the terms are technical and donot require translation, e.g., ESCRT-I, the ma-jority do, e.g., cytokinesis by cell plate forma-tion.3.
IFRS 2009: The IFRS taxonomy (InternationalAccounting Standards Board, 2007) is used forproviding electronic financial reports for audit-ing.
The terms contained within this taxon-omy are frequently long and are entirely nounphrases.We applied tokenization and manual phrase anal-ysis to the labels in these resources and the resultsare summarized in table 1.
As can be observed,the variety of types of labels we may come acrosswhen linguistically analysing and translating ontol-ogy and taxonomy labels is quite large.
We canidentify the two following properties that may influ-ence the translation process of taxonomy and ontol-ogy labels.
Firstly, the length of terms ranges fromsingle words to highly complex compound phrases,but is still generally shorter than a sentence.
Sec-ondly, terms are frequently about highly specializeddomains of knowledge.For properties in the ontology we also identifyterms which consist of:?
Noun phrases identifying concepts.?
Verbal phrases that are only made up of theverb with an optional preposition.?
Complex verbal phrases that include the predi-cate.?
Noun phrases that indicate possession of a par-ticular characteristic (e.g., interest meaning Xhas an interest in Y).3 Creation of a corpus for taxonomy andontology translationFor the purpose of training systems to work on thetranslation of ontologies and taxonomies, it is nec-essary to create a corpus that has similar linguisticstructure to that found in ontologies and taxonomies.We used the titles of Wikipedia1 for the following1http://www.wikipedia.org117Size Mean tokens per label Noun Phrases Verb PhrasesFOAF 79 1.57 94.9% 8.9%Gene Ontology 33795 4.45 100.0% 0.0%IFRS 2009 2757 8.39 100.0% 0.0%Table 1: Lexical Analysis of labelsLink Direct Fragment BrokenGerman 487372 484314 1735 1323Spanish 347953 346941 330 682Table 2: Number of translation for pages in Wikipediareasons:?
Links to articles in different languages can beviewed as translations of the page titles.?
The titles of articles have similar properties tothe ontologies labels mentioned above with anaverage of 2.46 tokens.?
There are a very large number of labels.
In factwe found that there were 5,941,8902 articles ofwhich 3,515,640 were content pages (i.e., notspecial pages such as category pages)We included non-content pages (in particular, cat-egory pages) in the corpus as they were generallyuseful for translation, especially the titles of cat-egory pages.
In table 2 we see the number oftranslations, which we further grouped according towhether they actually corresponded to pages in theother languages, as it is also possible that the trans-lations links pointed to subsections of an article orto missing pages.Wikipedia also includes redirect links that allowfor alternative titles to be mapped to a given con-cept.
These can be useful as they contain synonyms,but also introduce a lot more noise into the corpusas they also include misspelled and foreign terms.To evaluate the effectiveness of including these datafor creating a machine translation corpus, we tooka random sample of 100 pages which at least onepage redirects to (there are 1,244,647 of these pagesin total).
We found that these pages had a totalof 242 extra titles from the redirect page of which2All statistics are based on the dump on 17th March 2011204 (84.3%) where true synonyms, 19 (7.9%) weremisspellings, 8 (3.3%) were foreign names for con-cepts (e.g., the French name for ?Zeebrugge?
), and11 (4.5%) were unrelated.
As such, we concludethat these extra titles were useful for constructing thecorpus, increasing the size of the corpus by approx-imately 50% across all languages.
There are sev-eral advantages to deriving a corpus fromWikipedia,for example it is possible to provide some hierarchi-cal links by the use of the category that a page be-longs to, such as has been performed by the DBpediaproject (Auer et al, 2007).4 Evaluation metrics for taxonomy andontology translationGiven the linguistic differences in taxonomy andontology labels, it seems necessary to investigatethe effectiveness of various metrics for the evalua-tion of translation quality.
There are a number ofmetrics that are widely used for evaluating trans-lation.
Here we will focus on some of the mostwidely used, namely BLEU (Papineni et al, 2002),NIST (Doddington, 2002), METEOR (Banerjee andLavie, 2005) and WER (McCowan et al, 2004).However, it is not clear which of these methods cor-relate best with human evaluation, particularly forthe ontologies with short labels.
To evaluate thiswe collected a mixture of ontologies with short la-bels on the topics of human diseases, agriculture,geometry and project management, producing 437labels.
These were translated with web transla-tion services from English to Spanish, in particu-lar Google Translate3, Yahoo!
BabelFish4 and SDLFreeTranslation5.
Having obtained translations foreach label in the ontology we calculated the evalua-tion scores using the four metrics mentioned above.We found that the source ontologies had an average3http://translate.google.com4http://babelfish.yahoo.com5http://www.freetranslation.com118BLEU NIST METEOR WEREvaluator 1,Fluency 0.108 0.036 0.134 0.122Evaluator 1,Adequacy 0.209 0.214 0.303 0.169Evaluator 2,Fluency 0.183 0.062 0.266 0.164Evaluator 2,Adequacy 0.177 0.111 0.251 0.194Evaluator 3,Fluency 0.151 0.067 0.210 0.204Evaluator 3,Adequacy 0.143 0.129 0.221 0.120Table 3: Correlation between manual evaluation resultsand automatic evaluation scoreslabel length of 2.45 tokens and the translations gen-erated had an average length of 2.16 tokens.
We thencreated a data set by mixing the translations from theweb translation services with a number of transla-tions from the source ontologies, to act as a control.We then gave these translations to 3 evaluators, whoscored them for adequacy and fluency as describedin Koehn (2010).
Finally, we calculated the Pearsoncorrelation coefficient between the automatic scoresand the manual scores obtained.
These are presentedin table 3 and figure 1.As we can see from these results, one metric,namely METEOR, seems to perform best in evaluat-ing the quality of the translations.
In fact this is notsurprising as there is a clear mathematical deficiencythat both NIST and BLEU have for evaluating trans-lations for very short labels like the ones we havehere.
To illustrate this, we recall the formulation ofBLEU as given in (Papineni et al, 2002):BLEU = BP ?
exp(N?n=1wn log pn)WhereBP is a brevity penalty, wn a weight valueand pn represents the n-gram precision, indicatinghow many times a particular n-gram in the sourcetext is found among the target translations.
We note,however, that for very short labels it is highly likelythat pn will be zero.
This creates a significant issue,as from the equation above, if any of the values of pnare zero, the overall score, BLEU, will also be zero.Figure 1: Correlation between manual evaluation resultsand automatic evaluation scoresFor the results above we chose N = 2, and cor-rected for single-word labels.
However, the scoreswere still significantly worse, similar problems af-fect the NIST metric.
As such, for the taxonomyand ontology translation task we do not recommendusing BLEU or NIST as an evaluation metric.
Wenote that METEOR is a more sophisticated methodthan WER and, as expected, performs better.5 Approaches for taxonomy and ontologytranslation5.1 Domain adaptationIt is generally the case that many ontologies and tax-onomies focus on only a very specific domain, thusit seems likely that adaptation of translation systemsby use of an in-domain corpus may improve trans-lation quality.
This is particularly valid in the caseof ontologies which frequently contain ?subject?
an-notations6 for not only the whole data structure butoften individual elements.
To demonstrate this wetried to translate the IFRS 2009 taxonomy usingthe Moses Decoder (Koehn et al, 2007), which wetrained on the EuroParl corpus (Koehn, 2005), trans-lating from Spanish to English.
As the IFRS taxon-omy is on the topic of finance and accounting, we6For example from the Dublin Core vocabulary: see http://dublincore.org/119Baseline With domain adaptationWER?
0.135 0.138METEOR 0.324 0.335NIST 1.229 1.278BLEU 0.090 0.116Table 4: Results of domain-adapted translation.
?LowerWER scores are betterchose all terms from our Wikipedia corpus whichbelonged to categories containing the words: ?fi-nance?, ?financial?, ?accounting?, ?accountancy?,?bank?, ?banking?, ?economy?, ?economic?, ?in-vestment?, ?insurance?and ?actuarial?
and as suchwe had a domain corpus of approximately 5000terms.
We then proceeded to recompute the phrasetable using the methodology as described in Wu etal, (2008), computing the probabilities as follows forsome weighting factor 0 < ?
< 1:p(e|f) = ?p1(e|f) + (1?
?
)pd(e|f)Where p1 is the EuroParl trained probability and pdthe scores on our domain subset.
The evaluation forthese metrics is given in table 4.
As can be seenwith the exception of the WER metric, the domainadaption does seem to help in translation, which cor-roborates the results obtained by other authors.5.2 Syntactic AnalysisOne key question to figure out is: if we have a se-mantic model can this be used to predict the syntac-tic structure of the translation to a significant degree?As an example of this we consider the taxonomicterm ?statement?, which is translated by GoogleTranslate7 to German as ?Erkla?rung?, whereas theterm ?annual statement?
is translated as ?Jahresab-schluss?.
However, if the taxonomy contains a sub-sumption (hypernymy) relationship between theseterms we can deduce that the translation ?Erkla?rung?is not correct and the translation ?Abschluss?
shouldbe preferred.
We chose to evaluate this idea on theIFRS taxonomy as the labels it contains are muchlonger and more structured than some of the otherresources.
Furthermore, in this taxonomy the origi-nal English labels have been translated into ten lan-guages, so that it is already a multilingual resource7Translations results obtained 8th March 2011P (syn|s) P (syn|p) P (syn|n)English 0.147 0.012 0.001Dutch 0.137 0.011 0.001German 0.125 0.007 0.001Spanish 0.126 0.012 0.001Table 5: Probability of syntactic relationship given a se-mantic relationship in IFRS labelsthat can be used as gold standard.
Regarding thesyntax of labels, it is often the case that one term isderived from another by addition of a complemen-tary phrase.
For example the following terms all ex-ist in the taxonomy:1.
Minimum finance lease payments receivable2.
Minimum finance lease payments receivable, atpresent value3.
Minimum finance lease payments receivable, atpresent value, end of period not later than oneyear4.
Minimum finance lease payments receivable, atpresent value, end of period later than one yearand not later than five yearsA high-quality translation of these terms wouldideally preserve this same syntactic structure in thetarget language.We attempt to answer how usefulontological structure is by trying to deduce if thereis a semantic relationship between terms then is itmore likely that there is a syntactic relationship.
Westarted by simplifying the idea of syntactic depen-dency to the following: we say that two terms aresyntactically related if one label is a sub-string ofanother, so that in the example above the first labelis syntactically related to the other three and the sec-ond is related to the last two.
For English, we foundthat there were 3744 syntactically related terms ac-cording to this criteria, corresponding to 0.1% of alllabel pairs within the taxonomy, for all languages.For ontology structure we used the number of rela-tions indicated in the taxonomy, of which there are1070 indicating a subsumption relationship and 987indicating a partitive relationship8.
This means that8IFRS includes links for calculating certain values, i.e., that?Total Assets?
is a sum of values such as ?Total Assets in Prop-120e ?
f P (synf |syne, s) P (synf |syne, p) P (synf |syne, n)English ?
Spanish 0.813 ?
0.059 0.750 ?
0.205 0.835 ?
0.013English ?
German 0.835 ?
0.062 0.417 ?
0.212 0.790 ?
0.013English ?
Dutch 0.875 ?
0.063 0.833 ?
0.226 0.898 ?
0.013Average 0.841 ?
0.035 0.665 ?
0.101 0.841 ?
0.008Table 6: Probability of cross-lingual preservation of syntax given semantic relationship in IFRS.
Note here s refers tothe source language and t to the target language.
Error values are 95% of standard deviation.0.08% of label pairs were semantically related.
Wethen examined if the semantic relation could predictwhether there was a syntactic relationship betweenthe terms in a single language.
We define Ns as thenumber of label pairs with a subsumption relation-ship and similarly define Np, Nn and Nsyn for parti-tive, semantically unrelated and syntactically relatedpairs.
We also define Ns?syn, Np?syn and Nn?synfor label pairs with both subsumption, partitive or nosemantic relation and a syntactic relationships.
Assuch we define the following valuesP (syn|s) = Ns?synNsSimilarly we define P (syn|p) and P (syn|n) andpresent these values in table 5 for four languages.As we can see from these results, it seems thatboth subsumption and partitive relationships arestrongly indicative of syntactic relationships as wemight expect.
The second question is: is it morelikely that we see a syntactic dependency in trans-lation if we have a semantic relationship, i.e., is thesyntax more likely to be preserved if these terms aresemantically related.
We define Nsyne as the valueof Nsyn for a language e, e.g., Nsynen is the num-ber of syntactically related English label pairs in thetaxonomy.
As each label has exactly one transla-tion we can also define Nsyne?synf?s as the numberof concepts whose labels are syntactically related inboth language e and f and are semantically relatedby a subsumption relationship; similarly we defineNsyne?synf?p and Nsyne?synf?n.
Hence we can de-fineP (synf |syne, s) =Nsynf?syne?sNsyne?serty, Plant and Equipment?, we view such a relationship as se-mantically indicative that one term is part of another, i.e., aspartitive or meronymicAnd similarly define P (synf |syne, p) andP (synf |syne, n).
We calculated these values onthe IFRS taxonomies, the results of which arerepresented in table 6.The partitive data was very sparse, due to the factthat only 15 concepts in the source taxonomy had apartitive relationship and were syntactically related,so we cannot draw any strong conclusions from it.For the subsumption relationship we have a clearerresult and in fact averaged across all language pairswe found that the likelihood of the syntax being pre-served in the translation was nearly exactly the samefor semantically related and semantically unrelatedconcepts.
From this result we can conclude thatthe probability of syntax given either subsumptive orpartitive relationship is not very large, at least fromthe reduced syntactic model we used here.
Whileour model reduces syntax to n-gram overlap, webelieve that if there was a stronger correlation us-ing a more sophisticated syntactic model, we wouldstill see some noticable effect here as we did mono-lingually.
We also note that we applied this to onlyone taxonomy and it is possible that the result maybe different in a different resource.
Furthermore,we note there is a strong relationship between se-mantics and syntax in a mono-lingual context andas such adaption of a language model to incorporatethis bias may improve the translation of ontologiesand taxonomies.5.3 Comparison of ontology structureOur third intuition in approaching ontology trans-lation is that the comparison of ontology or taxon-omy structures containing source and target labelsmay help in the disambiguation process of transla-tion candidates.
A prerequisite in this sense is theavailability of equivalent (or similar) ontology struc-tures to be compared.121Figure 2: Two approaches to translate ontology labels.From a technical point of view, we consider thetranslation task as a word sense disambiguation task.We identify two methods for comparing ontologystructures, which are illustrated in Figure 2.The first method relies on a multilingual resource,i.e., a multilingual ontology or taxonomy.
The on-tology represented on the left-hand side of the fig-ure consists of several monolingual conceptualiza-tions related to each other by means of an inter-lingual index, as is the case in the EuroWordNet lex-icon (Vossen, 1999).
For example, if the originallabel is chair for seat in English, several translationsfor it are obtained in Spanish such as: silla (for seat),ca?tedra (for university position), presidente (for per-son leading a meeting).
Each of these correspondto a sense in the English WordNet, and hence eachtranslation selects a hierachical structure with En-glish labels.
The next step is to compare the inputstructure of the original ontology containing chairagainst the three different structures in English rep-resenting the several senses of chair and obtain thecorresponding label in Spanish.The second method relies on a monolingual re-source, i.e., on monolingual ontologies in the tar-get language, which means that we need to comparestructures documented with labels in different lan-guages.
As such we obtain a separate translated on-tologies for each combination of label translationssuggested by the baseline system.
Selecting the cor-rect translations is then clearly a hard optimizationproblem.For the time being, we have only experimentedwith the first approach using EuroWordNet.
Sev-eral solutions have been proposed in the context ofontology matching in a monolingual scenario (see(Shvaiko and Euzenat, 2005) or (Giunchiglia et al,2006)).
The ranking method we use to comparestructures relies on an equivalence probability mea-sure between two candidate structures, as proposedin (Trillo et al, 2007).We assume that we have a taxonomy or ontologyentity o1 and we wish to deduce if it is similar toanother taxonomy or ontology entity o2 from a ref-erence taxonomy or ontology (i.e., EuroWordNet) inthe same language.
We shall make a simplifying as-sumption that each ontology entity is associated witha unique label, e.g., lo1 .
As such we wish to deduceif o1 represents the same concept as o2 and hence iflo2 is a translation for lo1 .
Our model relies on theVector Space Model (Raghavan and Wong, 1986)to calculate the similarity between different labels,which essentially involves calculating a vector fromthe bag of words contained within each labels andthen calculating the cosine similarity between thesevectors.
We shall denotes this as v(o1, o2).
We thenuse four main features in the calculation of the sim-ilarity?
The VSM-similarity between the labels of enti-ties, o1, o2.?
The VSM-similarity between any glosses (de-scriptions) that may exist in the source or refer-ence taxonomy/ontology.?
The hypernym similarity given to a fixed depthd, given that set of hypernyms of an entity oi isgiven as a sethO(oi) = {h|(oi, h) ?
H}Then we calculate the similarity for d > 1 re-cursively as122sh(o1, o2, d) =?h1?hO(o1),h2?hO(o2) ?
(h1, h2, d)|hO(o1)||hO(o2)|?
(h1, h2, d) = ?v(h1, h2)+(1??
)sh(h1, h2, d?1)And for d = 1 it is given assh(o1, o2, 1) =?h1?hO(o1),h2?hO(o2) v(h1, h2)|hO(o1)||hO(o2)|?
The hyponym similarity, calculated as the hy-pernym similarity but using the hyponym setgiven byHO(oi) = {h|(h, oi) ?
H}We then incorporate these factors into a vector xand calculate the similarity of two entities ass(o1, o2) = wTxWhere w is a weight vector of non-negative realsand satisfies ||w|| = 1, which we set manually.We then applied this to the FOAF ontol-ogy (Brickley and Miller, 2010), which was manu-ally translated to give us a reference translation.
Af-ter that, we collected a set of candidate translationsobtained by using the web translation resources ref-erenced in section 3, along with additional candi-dates found in our multilingual resource.
Finally,we used EuroWordNet (Vossen, 1999) as the refer-ence taxonomy and ranked the translations accord-ing to the score given by the metric above.
In table7, we present the results where our system selectedthe candidate translation with the highest similarityto our source ontology entity.
In the case that wecould not find a reference translation we split the la-bel into tokens and found the translation by select-ing the best token.
We compared these results to abaseline method that selected one of the referencetranslations at random.These results are in all cases significantly strongerthan the baseline results showing that by compar-ing the structure of ontology elements it is possibleto significantly improve the quality of translation.These results are encouraging and we believe thatmore research is needed in this sense.
In particular,we would like to investigate the benefits of perform-ing a cross-lingual ontology alignment in which wemeasure the semantic similarity of terms in differentlanguages.Baseline Best TranslationWER?
0.725 0.617METEOR 0.089 0.157NIST 0.070 0.139BLEU 0.103 0.187Table 7: Results of selecting translation by structuralcomparison.
?Lower WER scores are better6 ConclusionIn this paper we presented the problem of ontologyand taxonomy translation as a special case of ma-chine translation that has certain extra characteris-tics.
Our examination of the problem showed thatthe main two differences are the presence of struc-tured semantics and shorter, hence more ambiguous,labels.
We demonstrated that as a result of this lin-guistic nature, some machine translation metrics donot perform as well as they do in free-text trans-lations.
We then presented the results of early in-vestigations into how we may use the special fea-tures of taxonomy and ontology translation to im-prove quality of translation.
The first of these wasdomain adaptation, which in line with other authorsis useful for texts in a particular domain.
We also in-vestigated the possibility of using the link betweensyntactic similarity and semantic similarity to help,however although we find that mono-lingually therewas a strong correspondence between syntax and se-mantics, this result did not seem to extend well to across-lingual setting.
As such we believe there mayonly be slight benefits of using techniques, howeverfurther investigation is needed.
Finally, we looked atusing word sense disambiguation by comparing thestructure of the input ontology to that of an alreadytranslated reference ontology.
We found this methodto be very effective in choosing the best translations.However it is dependent on the existence of a mul-tilingual resource that already has such terms.
Assuch, we view the topic of taxonomy and ontologytranslation as an interesting sub-problem of machinetranslation and believe there is still much fruitfulwork to be done to obtain a system that can cor-rectly leverage the semantics present in these datastructures in a way that improves translation quality.123ReferencesMarianna Apidianaki.
2009.
Data-driven semantic anal-ysis for multilingual WSD and lexical selection intranslation.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL).Michael Ashburner, Catherine Ball, Judith Blake, DavidBotstein, Heather Butler, J. Michael Cherry, AllanDavis, et al 2000.
Gene ontology: tool for the uni-fication of biology.
The Gene Ontology Consortium.Nature genetics, 25(1):25?29.So?ren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, and Zachary Ives.
2007.Dbpedia: A nucleus for a web of open data.
The Se-mantic Web, 4825:722?735.Satanjeev Banerjee and Alon Lavie.
2005.
METEOR:An automatic metric for MT evaluation with improvedcorrelation with human judgments.
Intrinsic and Ex-trinsic Evaluation Measures for Machine Translationand/or Summarization, page 65.Kalina Bontcheva.
2005.
Generating tailored textualsummaries from ontologies.
In The Semantic Web:Research and Applications, pages 531?545.
Springer.Dan Brickley and Libby Miller, 2010.
FOAF VocabularySpecification 0.98.
Accessed 3 December 2010.Marine Carpuat and Dekai Wu.
2007.
Improving Sta-tistical Machine Translation using Word Sense Disam-biguation.
In Proceedings of the 2007 Joint Confer-ence on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing (EMNLP-CoNLL 2007).Philipp Cimiano, Elena Montiel-Ponsoda, Paul Buite-laar, Mauricio Espinoza, and Asuncio?n Go?mez-Pe?rez.2010.
A note on ontology localization.
Journal of Ap-plied Ontology (JAO), 5:127?137.Nigel Collier, Son Doan, Ai Kawazoe, Reiko MatsudaGoodwin, Mike Conway, Yoshio Tateno, Quoc-HungNgo, Dinh Dien, Asanee Kawtrakul, Koichi Takeuchi,Mika Shigematsu, and Kiyosu Taniguchi.
2008.
Bio-Caster: detecting public health rumors with a Web-based text mining system.
Oxford Bioinformatics,24(24):2940?2941.Thierry Declerck, Hans-Ullrich Krieger, Susan MarieThomas, Paul Buitelaar, Sean O?Riain, Tobias Wun-ner, Gilles Maguet, John McCrae, Dennis Spohr, andElena Montiel-Ponsoda.
2010.
Ontology-based Mul-tilingual Access to Financial Reports for Sharing Busi-ness Knowledge across Europe.
In Jo?zsef Roo?z andJa?nos Ivanyos, editors, Internal Financial Control As-sessment Applying Multilingual Ontology Framework,pages 67?76.
HVG Press Kft.George Doddington.
2002.
Automatic evaluation of ma-chine translation quality using n-gram co-occurrencestatistics.
In Proceedings of the second interna-tional conference on Human Language TechnologyResearch, pages 138?145.
Morgan Kaufmann Publish-ers Inc.Mauricio Espinoza, Asuncio?n Go?mez-Pe?rez, and Ed-uardo Mena.
2008.
Enriching an Ontology withMultilingual Information.
In Proceedings of the 5thAnnual of the European Semantic Web Conference(ESWC08), pages 333?347.Mauricio Espinoza, Elena Montiel-Ponsoda, andAsuncio?n Go?mez-Pe?rez.
2009.
Ontology Local-ization.
In Proceedings of the 5th InternationalConference on Knowledge Capture (KCAP09), pages33?40.Bo Fu, Rob Brennan, and Declan O?Sullivan.
2010.Cross-Lingual Ontology Mapping and Its Use on theMultilingual Semantic Web.
In Proceedings of the1st Workshop on the Multilingual Semantic Web, atthe 19th International World Wide Web Conference(WWW 2010).Fausto Giunchiglia, Pavel Shvaiko, and Mikalai Yatske-vich.
2006.
Discovering missing background knowl-edge in ontology matching.
In Proceeding of the 17thEuropean Conference on Artificial Intelligence, pages382?386.International Accounting Standards Board, 2007.
Inter-national Financial Reporting Standards 2007 (includ-ing International Accounting Standards (IAS) and In-terpretations as at 1 January 2007).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, et al 2007.
Moses: Open source toolkit for sta-tistical machine translation.
In Proceedings of the 45thAnnual Meeting of the ACL on Interactive Poster andDemonstration Sessions, pages 177?180.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of theTenth Machine Translation Summit.Philipp Koehn.
2010.
Statistical Machine Translation.Cambridge University Press.Iain McCowan, Darren Moore, John Dines, DanielGatica-Perez, Mike Flynn, Pierre Wellner, and Herve?Bourlard.
2004.
On the use of information retrievalmeasures for speech recognition evaluation.
Technicalreport, IDIAP.John McCrae, Jesu?s Campana, and Philipp Cimiano.2010.
CLOVA: An Architecture for Cross-LanguageSemantic Data Querying.
In Proceedings of the FirstMutlilingual Semantic Web Workshop.William Mischo.
1982.
Library of Congress SubjectHeadings.
Cataloging & Classification Quarterly,1(2):105?124.124Hans-Michael Mu?ller, Eimear E Kenny, and Paul WSternberg.
2004.
Textpresso: An ontology-based in-formation retrieval and extraction system for biologi-cal literature.
PLoS Biol, 2(11):e309.Roberto Navigli and Simone Paolo Ponzetto.
2010.
Ba-belnet: Building a very large multilingual semanticnetwork.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics,pages 216?225.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of the40th annual meeting on association for computationallinguistics, pages 311?318.
Association for Computa-tional Linguistics.V.Vijay Raghavan and S.K.M.
Wong.
1986.
A criti-cal analysis of vector space model for information re-trieval.
Journal of the American Society for Informa-tion Science, 37(5):279?287.Pavel Shvaiko and Jerome Euzenat.
2005.
A survey ofschema-based matching approaches.
Journal on DataSemantics IV, pages 146?171.Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum.2007.
Yago: a core of semantic knowledge.
In Pro-ceedings of the 16th international conference on WorldWide Web, pages 697?706.Raquel Trillo, Jorge Gracia, Mauricio Espinoza, and Ed-uardo Mena.
2007.
Discovering the semantics of userkeywords.
Journal of Universal Computer Science,13(12):1908?1935.Piek Vossen.
1999.
EuroWordNet a multilingualdatabase with lexical semantic networks.
Computa-tional Linguistics, 25(4).Hua Wu, Haifeng Wang, and Chengqing Zong.
2008.Domain adaptation for statistical machine translationwith domain dictionary and monolingual corpora.
InProceedings of the 22nd International Conferenceon Computational Linguistics-Volume 1, pages 993?1000.
Association for Computational Linguistics.125
