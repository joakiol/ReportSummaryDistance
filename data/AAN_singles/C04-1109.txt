1Discriminative Slot Detection Using Kernel MethodsShubin Zhao, Adam Meyers, Ralph GrishmanDepartment of Computer ScienceNew York University715 Broadway, New York, NY 10003shubinz, meyers, grishman@cs.nyu.eduAbstractMost traditional information extractionapproaches are generative models that assumeevents exist in text in certain patterns and thesepatterns can be regenerated in various ways.These assumptions limited the syntactic cluesbeing considered for finding an event andconfined these approaches to a particularsyntactic level.
This paper presents adiscriminative framework based on kernel SVMsthat takes into account different levels ofsyntactic information and automaticallyidentifies the appropriate clues.
Kernels are usedto represent certain levels of syntactic structureand can be combined in principled ways as inputfor an SVM.
We will show that by combining alow level sequence kernel with a high levelkernel on a GLARF dependency graph, the newapproach outperformed a good rule-basedsystem on slot filler detection for MUC-6.1 IntroductionThe goal of Information Extraction (IE) is toextract structured facts of interest from text andpresent them in databases or templates.
Much ofthe IE research was promoted by the USGovernment-sponsored MUCs (MessageUnderstanding Conferences).
The techniques usedby Information Extraction depend greatly on thesublanguage used in a domain, such as financialnews or medical records.
The training data for anIE system is often sparse since the target domainchanges quickly.
Traditional IE approaches try togenerate patterns for events by various meansusing training data.
For example, the FASTUS(Appelt et al, 1996) and Proteus (Grishman, 1996)systems, which performed well for MUC-6, usedhand-written rules for event patterns.
The symboliclearning systems, like AutoSlog (Riloff, 1993) andCRYSTAL (Fisher et al, 1996), generated patternsautomatically from specific examples (textsegments) using generalization and predefinedpattern templates.
There are also statisticalapproaches (Miller et al, 1998) (Collins et al,1998) trying to encode event patterns in statisticalCFG grammars.
All of these approaches assumeevents occur in text in certain patterns.
Howeverthis assumption may not be completely correct andit limits the syntactic information considered bythese approaches for finding events, such asinformation on global features from levels otherthan deep processing.
This paper will show that asimple bag-of-words model can give us reliableinformation about event occurrence.
When trainingdata is limited, these other approaches may also beless effective in their ability to generate reliablepatterns.The idea for overcoming these problems is toavoid making any prior assumption about thesyntactic structure an event may assume; instead,we should consider all syntactic features in thetarget text and use a discriminative classifier todecide that automatically.
Discriminativeclassifiers make no attempt to resolve the structureof the target classes.
They only care about thedecision boundary to separate the classes.
In ourcase, we only need criteria to predict eventelements from text using the syntactic featuresprovided.
This seems a more suitable solution forIE where training data is often sparse.This paper presents an approach that uses kernelfunctions to represent different levels of syntacticstructure (information).
With the properties ofkernel functions, individual kernels can becombined freely into comprehensive kernels thatcross syntactic levels.
The classifier we chose touse is SVM (Support Vector Machine), mostly dueto its ability to work in high dimensional featurespaces.
The experimental results of this approachshow that it can outperform a hand-crafted rulesystem for the MUC-6 management successiondomain.2 Background2.1 Information ExtractionThe major task of IE is to find the elements of anevent from text and combine them to formtemplates or populate databases.
Most of theseelements are named entities (NEs) involved in theevent.
To determine which entities in text areinvolved, we need to find reliable clues aroundeach entity.
The extraction procedure starts with2text preprocessing, ranging from tokenization andpart-of-speech tagging to NE identification andparsing.
Traditional approaches would use variousmethods of analyzing the results of deeppreprocessing to find patterns.
Here we propose touse support vector machines to identify cluesautomatically from the outputs of different levelsof preprocessing.2.2 Support Vector MachineFor a two-class classifier, with separable trainingdata, when given a set of n labeled vector examples}1,1{),,(),...,,(),,( 2211 ?+?inn yyXyXyX ,a support vector machine (Vapnik, 1998) producesthe separating hyperplane with largest marginamong all the hyperplanes that successfullyclassify the examples.
Suppose that all theexamples satisfy the following constraint:1),( ?+><?
bXWy iiIt is easy to see that the margin between the twobounding hyperplanes 1, ?=+>< bXW i is2/||W||.
So maximizing the margin is equivalent tominimizing ||W||2 subject to the separationconstraint above.
In machine learning theory, thismargin relates to the upper bound of the VC-dimension of a support vector machine.
Increasingthe margin reduces the VC-dimension of thelearning system, thus increasing the generalizationcapability of the system.
So a support vectormachine produces a classifier with optimalgeneralization capability.
This property enablesSVMs to work in high dimensional vector spaces.2.3 Kernel SVMThe vectors in SVM are usually feature vectorsextracted by a certain procedure from the originalobjects, such as images or sentences.
Since theonly operator used in SVM is the dot productbetween two vectors, we can replace this operatorby a function ),( ji SS?
on the object domain.
Inour case, Si and Sj are sentences.
Mathematicallythis is still valid as long as ),( ji SS?
satisfiesMercer?s condition 1 .
Function ),( ji SS?
is oftenreferred to as a kernel function or just a kernel.Kernel functions provide a way to compute thesimilarity between two objects withouttransforming them into features.The kernel set has the following properties:1The matrix must be positive semi-definite1.
If ),(1 yxK  and ),(2 yxK are kernels on YX ?
,0, >??
, then ),(),( 21 yxKyxK ??
+  is a kernelon YX ?
.2.
If ),(1 yxK  and ),(2 yxK are kernels on YX ?
,then ),(),( 21 yxKyxK ?
is a kernel on YX ?
.3.
If ),(1 yxK  is a kernel on YX ?
and),(2 vuK  is a kernel on VU ?
, then),(),()),(),,(( 21 vuKyxKvyuxK += is a kernelon )()( VYUX ???
.When we have kernels representing informationfrom different sources, these properties enable usto incorporate them into one kernel.
The generalkernels such as RBF or polynomial kernels (M?lleret al, 2001), which extend features nonlinearlyinto higher dimensional space, can also be appliedto either the combination kernel or to eachcomponent kernel individually.2.4 Related WorkThere have been a number of SVM applicationsin NLP using particular levels of syntacticinformation.
(Lodhi et al, 2002) compared a word-based string kernel and n-gram kernels at thesequence level for a text categorization task.
Theexperimental results showed that the n-gramkernels performed quite well for the task.
Althoughstring kernels can capture common wordsubsequences with gaps, its geometric penaltyfactor may not be suitable for weighting the longdistance features.
(Collins et al, 2001) suggestedkernels on parse trees and other structures forgeneral NLP tasks.
These kernels count smallsubcomponents multiple times so that in practiceone has to be careful to avoid overfitting.
This canbe achieved by limiting the matching depth orusing a penalty factor to downweight largecomponents.
(Zelenko et al, 2003) devised a kernel onshallow parse trees to detect relations betweennamed entities, such as the person-affiliationrelation between a person name and anorganization name.
The so-called relation kernelmatches from the roots of two trees and continuesrecursively to the leaf nodes if the types of twonodes match.All the kernels used in these works were appliedto a particular syntactic level.
This paper presentsan approach for information extraction that useskernels to combine information from differentlevels and automatically identify whichinformation contributes to the task.
Thisframework can also be applied to other NLP tasks.33 A Discriminative FrameworkThe discriminative framework proposed here iscalled ARES (Automated Recognition of EventSlots).
It makes no assumption about the textstructure of events.
Instead, kernels are used torepresent syntactic information from varioussyntactic sources.
The structure of ARES is shownin Fig 1.
The preprocessing modules include apart-of-speech tagger, name tagger, sentence parserand GLARF parser, but are not limited to these.Other general tools can also be included, which arenot shown in the diagram.
The triangles in thediagram are kernels that encode the correspondingsyntactic processing result.
In the training phase,the target slot fillers are labeled in the text so thatSVM slot detectors can be trained through thekernels to find fillers for the key slots of events.
Inthe testing phase, the SVM classifier will predictthe slot fillers from unlabeled text and a mergingprocedure will merge slots into events if necessary.The main kernel we propose to use is on GLARF(Meyers et al, 2001) dependency graphs.Fig 1.
Structure of the discriminative modelThe idea is that an IE model should not commititself to any syntactic level.
The low levelinformation, such as word collocations, may alsogive us important clues.
Our experimentation willshow that for the MUC-6 management successiondomain, even bag-of-words or n-grams can give ushelpful information about event occurrence.3.1 Syntactic KernelsTo make use of syntactic information fromdifferent levels, we can develop kernel functions orsyntactic kernels to represent a certain level ofsyntactic structure.
The possible syntactic kernelsinclude?
Sequence kernels: representing sequencelevel information, such as bag-of-words, n-grams, string kernel, etc.?
Phrase kernel: representing information atan intermediate level, such as kernelsbased on multiword expressions, chunks orshallow parse trees.?
Parsing kernel: representing detailedsyntactic structure of a sentence, such askernels based on parse trees or dependencygraphs.These kernels can be used alone or combinedwith each other using the properties of kernels.They can also be combined with high-order kernelslike polynomial or RBF kernels, either individuallyor on the resulting kernel.As the depth of analysis of the preprocessingincreases, the accuracy of the result decreases.Combining the results of deeper processing withthose of shallower processing (such as n-grams)can also give us a back-off ability to recover fromerrors in deep processing.In practice each kernel can be tested for the taskas the sole input to an SVM to determine if thislevel of information is helpful or not.
Afterfiguring out all the useful kernels, we can try tocombine them to make a comprehensive kernel asfinal input to the classifier.
The way to combinethem and the parameters in combination can bedetermined using validation data.4 Introduction to GLARFGLARF (Grammatical and Logical ArgumentRegularization Framework) [Meyers et al, 2001] isa  hand-coded system that produces comprehensiveword dependency graphs from Penn TreeBank-II(PTB-II) parse trees to facilitate applications likeinformation extraction.
GLARF is designed toenhance PTB-II parsing to produce more detailedinformation not provided by parsing, such asinformation about object, indirect object andappositive relations.
GLARF can capture moreregularization in text by transforming non-canonical (passive, filler-gap) constructions intotheir canonical forms (simple declarative clauses).This is very helpful for information extractionwhere training data is often sparse.
It alsorepresents all syntactic phenomena in uniformtyped PRED-ARG structures, which is convenientfor computational purposes.
For a sentence,GLARF outputs depencency triples derivedautomatically from the GLARF typed featurestructures [Meyers et al, 2001].
A directeddependency graph of the sentence can also beconstructed from the depencency triples.
Thefollowing is the output of GLARF for the sentence?Tom Donilon, who also could get a senior job?
?.<SBJ,   get,  Tom Donilon><OBJ,  get,   job><ADV,  get,  also><AUX,  get,  could><T-POS,  job, a>TextsInputOutputTemplatesPOSTaggerSentParserGlarfParserNameTaggerSGMLParser EventMergerSlotDetectorDocuments4<A-POS,  job,  senior>.
.
.GLARF can produce logical relations in additionto surface relations, which is helpful for IE tasks.
Itcan also generate output containing the base formof words so that different tenses of verbs can beregularized.
Because of all these features, our mainkernels are based on the GLARF dependencytriples or dependency graphs.5 Event and Slot KernelsHere we will introduce the kernels used by ARESfor event occurrence detection (EOD) and slotfiller detection (SFD).5.1 EOD KernelsIn Information Extraction, one interesting issueis event occurrence detection, which is determiningwhether a sentence contains an event occurrence ornot.
If this information is given, it would be mucheasier to find the relevant entities for an event fromthe current sentence or surrounding sentences.Traditional approaches do matching (for slotfilling) on all sentences, even though most of themdo not contain any event at all.
Event occurrencedetection is similar to sentence level informationretrieval, so simple models like bag-of-words or n-grams could work well.
We tried two kernels to dothis, one is a sequence level n-gram kernel and theother is a GLARF-based kernel that matchessyntactic details between sentences.
In thefollowing formulae, we will use an identityfunction ),( yxI that gives 1 when yx ?
and 0otherwise, where x and y are strings or vectors ofstrings.1.
N-gram kernel ),( 21 SSN?
that counts commonn-grams between two sentences.
Given twosentence: >=<1,..., 211 NwwwS , and >=< 2,..., 211 NwwwS ,a bigram kernel ),( 21 SSbi?
is??
?=++?=><><11111121),,,(NjjjiiNiwwwwI .Kernels can be inclusive, in other words, thetrigram kernel includes bigrams and unigrams.
Forthe unigram kernel a stop list is used that removeswords other than nouns, verbs, adjectives andadverbs.2.
Glarf kernel ),( 21 GGg?
: this kernel is basedon the GLARF dependency result.
Given the tripleoutputs of two sentences produced byGLARF: },,{1 ><= iii aprG , 11 Ni ??
and},,{2 ><= jjj aprG , 21 Nj ??
, where ri, pi, aicorrespond to the role label, predicate word andargument word respectively in GLARF output, itmatches the two triples, their predicates andarguments respectively.
So ),( 21 GGg?
equals)),(),(),,,,,((2111?
?==++><><NjjijijjjiiiNiaaIppIapraprI ?
?In our experiments, ?
and ?
were set to 1.5.2 SFD KernelsSlot filler detection (SFD) is the task ofdetermining which named entities fill a slot insome event template.
Two kernels were proposedfor SFD: the first one matches local contexts oftwo target NEs, while the second one combines thefirst one with an n-gram EOD kernel.1.
),(1 jiSFD GG?
: This kernel was also definedon a GLARF dependency graph (DG), a directedgraph constructed from its typed PRED-ARGoutputs.
The arcs labeled with roles go frompredicate words to argument words.
This kernelmatches local context surrounding a name in aGLARF dependency graph.
In preprocessing, allthe names of the same type are translated into onesymbol (a special word).
The matching starts fromtwo anchor nodes (NE nodes of the same type) inthe two DG?s and recursively goes from thesenodes to their successors and predecessors, untilthe words associated with nodes do not match.
Inour experiment, the matching depth was set to 2.Each node n contains a predicate word wandrelation pairs },{ >< ii ar , pi ?
?1  representingits p arguments and the roles associated with them.A matching function ),( 21 nnC  is defined as?
?==+><><2111)),(),,,((pjjijjiipirrIararI .Then ),(1 jiSFD GG?
: can be written as???????
?++jijjiijijjiinnEednEednjinnESuccnESuccnjiji nnCnnCEEC)(Pr)(Pr)()(),(),(),(where Ei and Ej are the anchor nodes in the twoDG?s; ji nn ?
is true if the predicate wordsassociated with them match.
Functions Succ(n) andPred(n) give the successor and predecessor nodeset of a node n. The reason for setting a depth limitis that it covers most of the local syntax of a node(before matching stops); another reason is that thecycles currently present in GLARF dependencygraph prohibit unbounded recursive matching.2.
),(2 jiSFD SS?
: This kernel combines linearlythe n-gram event kernel and the slot kernel above,5in the hope that the general event occurrenceinformation provided by EOD kernel can help theslot kernel to ignore NEs in sentences that do notcontain any event occurrence.
),(),(),( 12 jiSFDjiNjiSFD GGSSSS ?????
+= ,where ??
, were set to be 1 in our experiments.The Glarf event kernel was not used, simplybecause it uses information from the same sourceas ),(1 jiSFD GG?
.
The n-gram kernel was chosento be the trigram kernel, which gives us the bestEOD performance among n-gram kernels.We also tried the dependency graph kernelproposed by (Collins et al, 2001), but it did notgive us better result.6 Experiments6.1 CorpusThe experiments of ARES were done on theMUC-6 corporate management succession domainusing the official training data and, for the finalexperiment, the official test data as well.
Thetraining data was split into a training set (80%) andvalidation set (20%).
In ARES, the text waspreprocessed by the Proteus NE tagger andCharniak sentence parser.
Then the GLARFprocessor produced dependency graphs based onthe parse trees and NE results.
All the names weretransformed into symbols representing their types,such as #PERSON# for all person names.
Thereason is that we think the name itself does notprovide a significant clue; the only thing thatmatters is what type of name occurs at certainposition.Two tasks have been tried: one is EOD (eventoccurrence detection) on sentences; the other isSFD (slot filler detection) on named entities,including person names and job titles.
EOD is todetermine whether a sentence contains an event ornot.
This would give us general information aboutsentence-level event occurrences.
SFD is to findname fillers for event slots.
The slots weexperimented with were the person name and jobtitle slots in MUC-6.
We used the SVM packageSVMlight in our experiments, embedding our ownkernels as custom kernels.6.2 EOD ExperimentsIn this experiment, ARES was trained on theofficial MUC-6 training data to do eventoccurrence detection.
The data contains 1940sentences, of which 158 are labeled as positiveinstances (contain an event).
Five-fold crossvalidation was used so that the training and test setcontain 80% and 20% of the data respectively.Three kernels defined in the previous section weretried.
Table 1 shows the performance of eachkernel.
Three n-gram kernels were tested: unigram,bigram and trigram.
Subsequences longer thantrigrams were also tried, but did not yield betterresults.The results show that the trigram kernelperformed the best among n-gram kernels.
GLARFkernel did better than n-gram kernels, which isreasonable because it incorporates detailed syntaxof a sentence.
But generally speaking, the n-gramkernels alone performed fairly well for this task,which indicates that low level text processing canalso provide useful information.
The mix kernelthat combines the trigram kernel with GLARFkernel gave the best performance, which mightindicate that the low level information providesadditional clues or helps to overcome errors indeep processing.Kernel Precision Recall F-scoreUnigram 66.0% 66.5% 66.3%Bigram 73.9% 60.3% 66.4%Trigram 77.5% 61.5% 68.6%GLARF 77.5% 63.9% 70.1%Mix 81.5% 66.4% 73.2%Table 1.
EOD performance of ARES usingdifferent kernels.
The Mix kernel is a linearcombination of the trigram kernel and the Glarfkernel.6.3 SFD ExperimentsThe slot filler detection (SFD) task is to find thenamed entities in text that can fill thecorresponding slots of an event.2 We treat job titleas a named entity throughout this paper, although itis not included in the traditional MUC namedentity set.
The slots we used for evaluation werePERSON_IN (the person who took a position),PERSON_OUT (the person who left a position)and POST (the position involved).
We generatedthe two person slots from the official MUC-6templates and the corresponding filler strings intext were labeled.
Three SVM predictors weretrained to find name fillers of each slot.
Twoexperiments have been tried on MUC-6 trainingdata using five-fold cross validation.The first experiment of ARES used slot kernel),(1 jiSFD GG?
alone, relying solely on local2We used this task for evaluation, rather than theofficial MUC template-filling task, in order to assess thesystem?s ability to identify slot fillers separately from itsability to combine them into templates.6context around a NE.
From the performance table(Table 2), we can see that local context can give afairly good clue for finding PERSON_IN andPOST, but not for PERSON_OUT.
The mainreason is that local context might be not enough todetermine a PERSON_OUT filler.
It often requiresinference or other semantic information.
Forexample, the sentence ?Aaron Spelling, thecompany's vice president, was named president.
?,indicates that ?Aaron Spelling?
left the position ofvice president, therefore it should be aPERSON_OUT.
But the sentence ?Aaron Spelling,the company's vice president, said ?
?, which isvery similar to first one in syntax, has no suchindication at all.
In complicated cases, a person caneven hold two positions at the same time.Accuracy Precision Recall F-scorePER_IN 63.6% 62.5% 63.1%PER_OUT 54.8% 54.2% 54.5%POST 64.4% 55.2% 59.4%Table 2.
SFD performance of ARES using kernel),(1 jiSFD GG?
.In this experiment, the SVM predictorconsidered all the names identified by the NEtagger; however, most of the sentences do notcontain an event occurrence at all, so NEs in thesesentences should be ignored no matter what theirlocal context is.
To achieve this we need generalinformation about event occurrence, and this is justwhat the EOD kernel can provide.
In our secondexperiment, we tested the kernel ),(2 jiSFD SS?
,which is a linear combination of the trigram EODkernel and the SFD kernel ),(1 jiSFD GG?
.
Table 3shows the performance of the combination kernel,from which we can see that there is clearperformance improvement for all three slots.
Wealso tried to use the mix kernel which gave us thebest EOD performance, but it did not yield a betterresult.
The reason we think is that the GLARFEOD kernel and SFD kernel are from the samesyntactic source, so the information was repeated.Accuracy Precision Recall F-scorePER_IN 86.6% 60.5% 71.2%PER_OUT 69.2% 58.2% 63.2%POST 68.5% 68.9% 68.7%Table 3.
SFD performance of ARES using kernel),(2 jiSFD SS?
.
It combines the Glarf SFD kernelwith trigram EOD kernel.
For PER_OUT,unigram EOD kernel was used.Since five-fold cross validation was used, ARESwas trained on 80% of the MUC-6 training data inthese two experiments.6.4 Comparison with MUC-6 SystemThis experiment was done on the official MUC-6 training and test data, which contain 50K wordsand 40K words respectively.
ARES used theofficial corpora as training and test sets, except thatin the training data, all the slot fillers weremanually labeled.
We compared the performanceof ARES with the NYU Proteus system, a rule-based system that performed well for MUC-6.
Toscore the performance for these three slots, wegenerated the slot-filler pairs as keys for adocument from the official MUC-6 templates andremoved duplicate pairs.
The scorer matches thefiller string in the response file of ARES to thekeys.
The response result for Proteus wasextracted in the same way from its template output.Table 4. shows the result of ARES using thecombination kernel in the previous experiment.Accuracy Precision Recall F-scorePER_IN 77.3% 62.2% 68.9%PER_OUT 58.9% 69.7% 63.9%POST 77.1% 71.5% 73.6%Table 4.
Slot performance ARES using kernel),(2 jiSFD SS?
on MUC-6 test data.Table 5 shows the test result of the Proteussystem.
Comparing the numbers we can see thatfor slot PERSON_IN and POST, ARESoutperformed the Proteus system by a few points.The result is promising considering that this modelis fully automatic and does not involve any post-processing.
As for the PERSON_OUT slot, theperformance of ARES was not as good.
As wehave discussed before, relying purely on syntaxmight not help us much;  we may need aninference model to resolve this problem.Accuracy Precision Recall F-scorePER_IN 85.7% 51.2% 64.1%PER_OUT 78.4% 58.6% 67.1%POST 83.3% 59.7% 69.5%Table 5.
Slot performance of the rule-basedProteus system for MUC-6.7 Related Work(Chieu et al, 2003) reported a feature-basedSVM system (ALICE) to extract MUC-4 events of7terrorist attacks.
The Alice-ME systemdemonstrated competitive performance with rule-based systems.
The features used by Alice aremainly from parsing.
Comparing with ALICE, oursystem uses kernels on dependency graphs toreplace explicit features, an approach which isfully automatic and requires no enumeration offeatures.
The model we proposed can combineinformation from different syntactic levels inprincipled ways.
In our experiments, we used bothword sequence  information and parsing levelsyntax information.
The training data for ALICEcontains 1700 documents, while for our system itis just 100 documents.
When data is sparse, it ismore difficult for an automatic system tooutperform a rule-based system that incorporatesgeneral knowledges.8 Discussion and Further WorksThis paper describes a discriminative approachthat can use syntactic clues automatically for slotfiller detection.
It outperformed a hand-craftedsystem on sparse data by considering differentlevels of syntactic clues.
The result also shows thatlow level syntactic information can also come intoplay in finding events, thus it should not be ignoredin the IE framework.For slot filler detection, several classifiers weretrained to find names for each slot and there is nocorrelation among these classifiers.
However,entity slots in events are often strongly correlated,for example the PER_IN and POST slots formanagement succession events.
Since theseclassifiers take the same input and producedifferent results, correlation models can be used tointegrate these classifiers so that the identificationof slot fillers might benefit each other.It would also be interesting to experiment withthe tasks that are more difficult for patternmatching, such as determining the on-the-jobstatus property in MUC-6.
Since events often spanmultiple sentences, another direction is to explorecross-sentence models, which is difficult fortraditional approaches.
For our approach it ispossible to extend the kernel from one sentence tomultiple sentences, taking into account thecorrelation between NE?s in adjacent sentences.9 AcknowledgementsThis research was supported in part by theDefense Advanced Research Projects Agency aspart of the TIDES program, under Grant N66001-001-1-8917 from the Space and Naval WarfareSystems Center, San Diego, and by the NationalScience Foundation under Grant ITS-0325657.This paper does not necessarily reflect the positionof the U.S. Government.ReferencesD.
Appelt, J. Hobbs, J.
Bear, D. Israel, M. Kameyama,A.
Kehler, D. Martin, K. Meyers, and M. Tyson1996.
SRI International FASTUS system: MUC-6 testresults and analysis.
In Proceedings of the SixthMessage Understanding Conference.H.
L. Chieu, H. T. Ng, & Y. K. Lee.
2003.
Closing theGap: Learning-Based Information ExtractionRivaling Knowledge-Engineering Methods.
InProceedings of the 41st Annual Meeting of theAssociation for Computational Linguistics.M.
Collins and S. Miller.
1998.
Semantic Tagging usinga Probabilistic Context Free Grammar, InProceedings of the Sixth Workshop on Very LargeCorpora.M.
Collins and N. Duffy.
2001.
Convolution Kernels forNatural Language, Advances in Neural InformationProcessing Systems 14, MIT Press.D.
Fisher, S. Soderland, J. McCarthy, F. Feng and W.Lehnert.
1996.
Description of The UMass System AsUsed For MUC-6.
In Proceedings of the SixthMessage Understanding Conference.R.
Grishman.
1996.
The NYU System for MUC-6 orWhere's the Syntax?.
In Proceedings of the SixthMessage Understanding Conference.H.
Lodhi, C. Sander, J. Shawe-Taylor, N. Christianiniand C. Watkins.
2002.
Text Classification usingString Kernels.
Journal of Machine LearningResearch.A.
Meyers, R. Grishman, M. Kosaka and S. Zhao.
2001.Covering Treebanks with GLARF.
In Proceedings ofof the ACL Workshop on Sharing Tools andResources.S.
Miller, M. Crystal, H. Fox, L. Ramshaw, R.Schwartz, R. Stone, and R. Weischedel.
1998.
BBN:Description of The SIFT System As Used For MUC-7, In Proceedings of the Seventh MessageUnderstanding Conference.K.-R. M?ller, S. Mika, G. Ratsch, K. Tsuda, B.Scholkopf.
2001.
An introduction to kernel-basedlearning algorithms, IEEE Trans.
Neural Networks,12, 2, pages 181-201.E.
Riloff.
1993.
Automatically constructing a dictionaryfor information extraction tasks.
In Proceedings ofthe 11th National Conference on ArtificialIntelligence, 811-816.V.
N. Vapnik.
1998.
Statistical Learning Theory.
Wiley-Interscience Publication.D.
Zelenko, C. Aone and A. Richardella.
2003.
Kernelmethods for relation extraction.
Journal of MachineLearning Research.
