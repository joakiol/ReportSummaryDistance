Proceedings of the SIGDIAL 2013 Conference, pages 294?303,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsTacit Contracts for WheelchairsDaniel Couto ValeSFB/TR8 Spatial CognitionUniversity of Bremendanielvale@uni-bremen.deVivien MastSFB/TR8 Spatial CognitionUniversity of Bremenviv@tzi.deAbstractIn this paper, we propose a novel approachto infer dialogue acts using the notion oftacit contracts.
We describe the interper-sonal linguistic features that our analysisgrammar can identify in uttered texts andpresent an inference procedure that strictlyseparates the semantic and pragmatic stepsof utterance understanding, thereby meet-ing a higher degree of modularity, a pre-requisite for extending robot functionality.Keywords: Dialogue System; DialogueAct; Attitude; Stance1 IntroductionJohn is reading ?Merlin?, when the door bell rings.He cannot walk, but his intelligent wheelchair Rol-land is nearby.
He says: ?Rolland, I need to openthe door.
Can you take me there??
Rolland re-sponds ?Sure, I?m coming!
?, comes to him, waitsfor him to sit comfortably, and then says ?Let?sgo!?
before driving him to the door side whereJohn is able to reach the door handle.So seamless are the interactions in our Wizard-of-Oz experiment (Anastasiou et al 2012; Valeand Mast, 2012b) yet so difficult for an intelligentwheelchair.
How is it to know that ?I need to openthe door?
and ?Can you take me there??
shouldnot be understood separately as a statement and aquestion but together as a command to move to-wards the door for enabling the user to open it?Each utterance is an action that affects the inter-active situation.
Not only does it construe events,but it also constitutes exchanges between interac-tants such as stating the speaker?s need of perform-ing an action and asking about the listener?s capa-bility of providing a service.All speaking robots need some method of cop-ing with this dual character of situated utterances.A frequent approach is Dialogue Act Detection,a family of statistical methods trained on human-annotated corpora (Allen and Core, 1997; Juraf-sky et al 1997; Jurafsky et al 1997; Jekat et al1995).
An alternative approach is Plan Recogni-tion, which consists of using a planner having lin-guistic meaning and a domain model as inputs.
Wedepart from this tradition by proposing a contrac-tual approach in which semantic and pragmatic as-pects of understanding are symbolically exploredin separate steps of inference.The main rationale for not pursuing the detec-tion of dialogue acts as patterns in the uttered textis that the intended effect of an utterance is not tobe found in the wording (Marcu, 1997); and therationale for not taking construed events directlyas plan steps is that the functional roles of inter-actants in cooperative work are decisive for inter-preting attitudes.In this paper, we present an automatic seman-tic analysis of the interpersonal features of lin-guistic units and propose a compatible three-stepprocedure consisting of transformation, contex-tualization and inference to enable an intelligentwheelchair to understand implied dialogue acts.In the following two sections, we describe priorapproaches to understanding interpersonal mean-ing and discuss their relevance for our approach.Then we introduce a classification of interper-sonal linguistic features and explain how we re-express these implicit features of language explic-itly in a standardised format.
Finally, we describethe procedure used by the pragmatic module ofour wheelchair in order to contextualise utterancemeaning and infer implied dialogue acts.2 Dialogue Act DetectionDialogue act detection is the most frequently usedapproach for dealing with the interpersonal aspectof dialogue.
In this section, we review two frame-works for dialogue act detection: the annotationstandard DAMSL (Allen and Core, 1997) and the294dialogue act component of the successful applica-tion Verbmobil (Jekat et al 1995).2.1 DAMSL and DerivatesThe tagging system of Dialogue Act Markup inSeveral Layers (DAMSL) is a tag system forspeaker?s intention.
It uses binary decision treesfor tagging utterances with up to four attributes(layers) of the speaker?s intention: communicativestatus, information level, backward- and forward-looking functions.
DAMSL has been thoroughlytested for annotation (Core and Allen, 1997; Ju-rafsky et al 1997; Ivanovic, 2005; Stolcke etal., 2000) with inter-annotator agreement reach-ing approx.
70-85%.
Recent attempts to au-tomatise DAMSL dialogue act detection using sta-tistical methods (Core, 1997; Rosset and Lamel,2004; Rangarajan Sridhar et al 2007; Rosset etal., 2008; Rangarajan Sridhar et al 2009) reachsimilar accuracy.However, high accuracy scores need to be rel-ativized, as precision and recall may be very lowfor most tags?
Rangarajan Sridhar et al(2009)report <1% for all but the two most frequent tags.Moreover, agreement rates tell nothing about theseverity of mistagging for application usage.The second and most compromising issue lies inthe annotation scheme itself.
Context-dependentdecision trees turn utterance tagging into guesswork, since utterances map differently to worldmodels in different situations.
For instance, thereis danger ?of annotators confusing surface formwith [contextual] speaker intent, for instance la-belling an info-request in the form of a statementas an other-statement?
(Stent, 2000).The third issue concerns applicability.
TheDAMSL research community has built annotatedcorpora and automated dialogue act detection.Only lately, there has been research on automaticlearning of dialogue act flow patterns on largemanually annotated corpora of dialogue.
Whetherthese dialogue act flows will be usable in real ap-plied systems is yet to be determined.2.2 VerbmobilA different approach to Dialogue Act Detection isfollowed by Verbmobil, a successful applied dia-logue system for travel booking.
It uses 55 typesof dialogue act, tailored to the particular appli-cation domain of travel booking, e.g.
Request-Suggest-Duration.
Classification of utterances isachieved by detecting keywords and syntactic pat-terns in the word sequence of the utterance andmatching them against keyword and pattern listswhich are typical for each dialogue act type.
Am-biguity is solved by using a context-based prefer-ence order learnt from a large annotated corpus.This approach works with a caveat: embeddingdomain content like stay duration in dialogue acttypes may cause an explosion of categories forless restricted domains and, while easily recognis-able, such tailored categories are domain specific.Therefore, they are not reusable when creating anapplication for a new domain.2.3 Detection Trade-OffIn short, we argue that statistical methods of di-alogue act detection do not scale.
This approachalways leads to a trade-off between suboptimalinter-annotator agreement as in DAMSL or lackof reusability as in Verbmobil.The reason for this trade-off is that two issuesof different natures are tackled at the same time:semantics and pragmatics.
The lack of a strati-fied linguistic theory with semantic and pragmaticsteps behind these classifications is the cause of abad fit between categories and grammatical struc-ture in the case of DAMSL.
This shortcoming canbe partially overcome through the usage of tai-lored categories at the expense of large annotatedtraining corpora and a low reusability.Tailoring is particularly expensive when experi-mental data is not easily obtainable as for human-wheelchair interaction.
Therefore we need a dif-ferent approach that separates text analysis fromutterance contextualisation (see Section 4).3 Belief-Desire-Intention ApproachThe formal theory of rational interaction (FTRI)is a plan-based approach to dialogue managementthat divides user mental representations into be-liefs, desires and intentions (BDI).
The dialoguemanager keeps track of which planned tasks arefeasible for, assigned to and/or completed by par-ticular agents (Sadek, 1992; Sadek, 1994; Sadeket al 1996; Sadek et al 1997).
Logical infer-ences are made with respect to interactant?s mentalstates in order to plan the next verbal action of thedialogue system.
The interpersonal features of thelinguistic model are very simple.
User utterancesare classified into one of 3 categories of syntacticpatterns (directive, interrogative, or affirmative),295and are used in combination with spotted verbs inorder to determine the beliefs, desires, and inten-tions of the user.
Lists of implications are usedin order to infer actions from certain combinationsof intentions and beliefs.
An example for such animplication is: If a user u intends (I) to have anaction a DONE, u intends (I) her/his utterance tohave the same rational effect RE as performing aby her/himself; in other words, by informing thesystem about her or his intention to have a taskperformed, the user delegates the performance ofthis task to the system.
The formal theory of ratio-nal interaction along with similar theories have re-ceived strong criticism.
They lack a formalizationof linguistic meaning (structural meaning) capableof encapsulating the richness and flexibility of lin-guistic systems.
Moreover, ?
[BDI p]lan-based ap-proaches [to dialogue management] are also criti-cised as being more opaque, especially given thelarge amount of procedural processing and lackof a well-founded semantics for plan-related op-erations?
(Traum et al 1999).
Improving uponBDI plan-based approaches, Traum?s work takesinto account dialogue acts (Traum and Hinkelman,1992) and obligations (Traum and Allen, 1994).Reflecting Traum et als critique of the BDI ap-proach, the present work can be understood asa step towards the theoretical conceptualizationof some of BDI?s opaque operations within aninformation-state approach to dialogue manage-ment.4 Contract-Supported InteractionOur work is supported by automatic functionaltext analysis (parsing) with Combinatory Catego-rial Grammar (CCG) (Steedman and Baldridge,2011) using Systemic Functional Theory (Hall-iday and Matthiessen, 2004).
This enables usto detect personal stances and attitude automati-cally in the syntactic structure of the utterance (seeSection 4.1).
Based on these detected concepts,we generate a standardised typed feature struc-ture, which captures the commonalities of differ-ent utterance types with respect to the implied ex-pectations from the addressee.
Rather than hy-pothesizing about the user?s mental states, we areable to base our interpretation solely on what islinguistically expressed as required from the ad-dressee.
Our usage of inference is somewhat sim-ilar to the one proposed by FTRI; however, withthe formalised concept of tacit contracts?furtherformalizing the update operations in the dialoguesystem of Matheson et al(2000)., we gain situ-ational flexibility which is of great value, becausetacit contracts are not universally valid, but dependon the roles of the interactants in a given situation.4.1 Interpersonal Upper ModelOn the semantic level, we adopt the most compre-hensive linguistic description of the interpersonalcomponent of human languages, which is foundin the Systemic Functional Grammar of English(Halliday and Matthiessen, 2004).
We created anontology of linguistic units, the Interpersonal Up-per Model, covering all interpersonal features ofSystemic Functional Theory with minor adjust-ments and extensions.
Using this classification oflinguistic units, we implemented a CombinatoryCategorial Grammar for German to parse a cor-pus collected in a Wizard-of-Oz experiment whereusers gave commands to an intelligent wheelchairin order to perform simple domestic tasks likewashing their hands or opening the door (Anasta-siou et al 2012; Vale and Mast, 2012b; Vale andMast, 2012a).For an intelligent wheelchair to understand theutterances of the user, first it must cope with thevarious ways in which interpersonal meaning isexpressed in language.
For example, by utter-ing either of the clauses ?I want you to leave.
?or ?Leave!
?, the speaker commands the addresseeto perform the action of leaving.
Although theyshare this interpersonal function, the first makesthe command explicit by referring to the requirerand performer of the service while the secondleaves it implicit in the structure of the clause.Halliday and Matthiessen (2004) call such ex-pression pairs, where different wordings representthe same interpersonal meaning, interpersonallyagnate expressions.
In their work, grammaticalmetaphor is defined as the process whereby con-cepts which are usually implicit in the structure ofclauses are re-expressed with more explicit refer-ential representations.It must be noted that this analysis relies strictlyon utterance semantics, i.e.
the information thatcan be gained from automatically analyzing theutterance alone, without relying on linguistic orsituational context.
By relying on parsing ratherthan string-level methods such as POS-tagging,keyword spotting and statistical utterance classi-fication, we have the advantage of retaining the296rich information contained in the structure of theutterance.
For our approach, we rely on pars-ing with Categorial Combinatory Grammar (CCG)(Steedman and Baldridge, 2011) based on Sys-temic Functional Theory.
This methodology pro-vides us with a systematic, theory-based way ofretrieving features of the linguistic structure of anutterance that are relevant for human-computer in-teraction.
When parsing with a functional gram-mar, syntactic units are classified according totheir function.
Therefore, the segmentation of theutterance into constituents is based on the compo-sitionality of semantic units.In the remainder of this section, we will explainin detail the two main characters of interpersonalmeaning, attitude and stance and how they arerecognised in linguistic structure.
In the follow-ing section, we will proceed to demonstrate howwe turn the concept of grammatical metaphors intoa method for representing interpersonal linguisticfeatures explicitly in a standardised manner.4.1.1 AttitudeAttitudes (or direct speech acts) specify the kind ofthing negotiated: a mercative attitude indicates anexchange of goods (?A beer, please!?
), an impera-tive attitude an exchange of services (?Please takeme to the kitchen!?
), and a declarative attitude anexchange of information (?Is the door closed??
).They also specify the orientation of the exchangebetween the interactants: whether the speaker isoffering something to the addressee (?Your beer!??
offertive attitude) or demanding something fromthem (?A beer please!?
?
mandative).By classifying attitudes in these two dimen-sions, we have a clear separation of exchange ori-entation (speaker to addressee or vice-versa) andexchange stock (good, service, or information).The combination of these options yielding six dif-ferent attitudes1, as shown in Table 1.Table 1: Orientation ?
Stock?
AttitudeOrientation ?
Stock Attitudedemand info mandative ?
declarative interrogativeoffer info offertive ?
declarative affirmativedemand service mandative ?
imperative directiveoffer service offertive ?
imperative preemptivedemand good mandative ?
mercative questiveoffer good offertive ?
mercative donative1The full ontology contains more distinctions that are ig-nored here for the sake of brevity.As Example (1) shows, a mercative attitude (ex-change of goods) is usually expressed by noungroups with modifiers such as ?please?.
There isno constituent for Process nor Subject.
Impera-tive attitudes (exchange of services) are usuallyexpressed by predicates, that is, they have no Sub-ject constituent as shown in Example (2).
Finally,declarative attitudes (exchange of information) areusually expressed by full predications 2, as in Ex-amples (3) and (4).
(1) ?A beer, please!?
(mercative)(2) ?Please take me to the kitchen!?
(imperative)(3) ?The door is closed.?
(declarative)(4) ?Is the door closed??
(declarative)Because there is a mapping between the syntacticlevel of an utterance structure and the kind of stockbeing exchanged (goods, services or information),we can automatically detect which attitude eachutterance has.4.1.2 StanceStance (or modality) ?construe[s] the region ofcognitive uncertainty that lies between ?yes?
and?no??
(Halliday and Matthiessen, 2004).
There aretwo primary kinds of stance: control determineswhether someone wants something (inclination,e.g.
?is keen to?, ?wants?)
or is wanted for some-thing (regulation, e.g.
?is supposed to?, ?must?
),and conviction determines how likely somethingis (likelihood, e.g.
?it?s likely to rain?, ?it?s def-initely not going to rain?
), or how often it occurs(usuality, e.g.
?It often rains in summer.
?, ?it neverrains in the desert.?).
Because Systemic Func-tional Theory works by delimiting semanticallyclassified syntactic units based on possible seman-tic oppositions, combinatory categorial parsing ofexpressions is straight forward.4.2 Grammatical MetaphorAs discussed in the previous section, attitude hasan orientation from the speaker to the addresseeor vice versa (offering or demanding).
The ser-vice requirer and/or provider are not explicitlymentioned, but determined by the syntactic struc-ture used and the roles of the interactants in thedialogue, speaker and addressee.
Halliday andMatthiessen (2004) call this interpersonal orien-tation .
Stance provides a linguistic tool to explic-itly express the source and target of orientation,detaching them from the interactional situation.2i.e.
association between a subject and a predicate297For instance, ?Leave!?
is a service demand withan interpersonal orientation from the addressee tothe speaker.
If one rephrases this with ?must?
asin ?you must leave.?
or ?he must leave.
?, one ob-tains a personal stance, that is, an orientation fromthe speaker to the provider of the service which isexplicitly expressed by a reference such as ?you?or ?he?.
By rephrasing the utterance again with?require?
as in ?you are required by me?
or ?youare required by law?, one obtains an impersonalstance, that is, both requirer and service performerare referred to explicitly and not assumed from theorientation of the linguistic exchange.It is possible to express the same interpersonalmeaning with an impersonal orientation as with aninterpersonal orientation.
For example, ?You arerequired by me to leave.
?, just like ?Leave!
?, takesthe speaker as the requirer and the addressee as theperformer of the required action of leaving, there-fore these two expressions are agnate, making thefirst a grammatical metaphor of the second.Table 2: Possible orientations.Interpers.
Personal Impersonalleave you must leave you are required by me to leavehe must leave he is required by me to leaveyou are required by law to leavehe is required by law to leave4.2.1 Addressee-centered perspectiveEach attitude brings about a required responsefrom the addressee: offertive attitudes, by offer-ing a stock, pose a requirement to receive thisstock and mandative attitudes, by demanding astock, pose a requirement to give one.
These re-quired responses can be expressed explicitly inmore metaphorical agnate expressions.
For ex-ample, the attitude of offering goods (offertive?
mercative ?
donative) is represented by theprocess ?take?
in agnate expressions with the ad-dressee as the subject as in ?Take some cookies.
?.Table 3 shows the mapping of all 6 main attitudesonto their corresponding requirements from theaddressee.With mappings from the less metaphoricalexpressions to more metaphorical ones, thewheelchair can construe a standardised semanticrepresentation to work with.
This explicitationmethod enables us to capture the semantic com-monalities of a broad variety of different linguis-tic expressions.
Examples (5) and (6) show twodifferent utterances whose standardised represen-Table 3: Mapping of attitudes onto requirementsfrom the addresseeAttitude Required Reaction Processdonative receive goods takequestive give goods handpreemptive receive services assigndirective give services performaffirmative receive information knowinterrogative give information saytations are highly similar.
Example (5) is an in-formation offer, re-expressed as a requirement toknow a given information.
Agnately, Example (6)is a service demand, re-expressed as a requirementto perform the service of being aware of the sameinformation, a particular way of knowing it3.
(5) ?it?s snowing?LINGUISTIC MEANING:Speaker offers to Addressee information thatit?s snowingADDRESSEE-CENTERED MEANING:Speaker requires Addresseeto know thatit?s snowing(6) ?be aware that it?s snowing?LINGUISTIC MEANING:Speaker demands from Addressee serviceof being aware thatit?s snowingADDRESSEE-CENTERED MEANING:Speaker requires Addresseeto performbeing aware thatit?s snowingSpeaker requires Addresseeto be aware thatit?s snowingThe standardised semantic representation has theadvantage that the wheelchair needs to treat re-quirements in only the most explicit representationwhen deciding which action it is expected to per-form.
In the following section, we will explain theconcept of tacit contracts, and how they are usedby our interpersonal calculus in order to extractthe dialogue act from the user utterance as repre-sented by the addressee-centered semantic repre-sentation and the situation model.4.3 Tacit ContractsWhile the addressee-centered semantic treatmentenables an intelligent wheelchair to deal with ut-terances such as (7) and the more metaphorical (8)in a standardised manner independent of the situ-ation, there is a further step of processing needed3As performing an action is the same as acting, in Exam-ple (6), ?requiring to perform being aware?
can be simplifiedto ?requiring to be aware?.298in order to deal with the full scope of utterancescollected in our usability experiment.
(7) ?Take me to the kitchen.?
(8) ?I want you to take me to the kitchen.?
(9) ?I must go to the kitchen.
?For instance, the wheelchair needs to understandthat utterance (9) is, in the dialogue situation, notonly an offering of information of a need of theuser, but a more polite variant to Examples (7)and (8) (Vale and Mast, 2012a).
The meaningthe speaker intends to convey goes beyond whatis said.
Grice (1975) called this kind of pragmaticinference conversational implicature.
They arisefrom the the understanding of a set of conversa-tional maxims which humans can be expected toobserve in conversation in combination with fea-tures of the interactional situation in which it is ut-tered.
In contrast, conventional implicatures arisefrom the meaning of the uttered sentence and themaxims of communication, without any influencefrom the interactional situation.
Re?canati (1991)improved the Gricean model of maxims, but fortheoretical reasons accepted no linguistic formal-ism, which makes his model impossible to applyin intelligent wheelchair design.Relevance Theory (Sperber and Wilson, 1995;Carston, 1998) further develops the concept of in-ference in a cognitive paradigm by replacing max-ims of communication with a balance between thecognitive effort needed to make an inference andits positive cognitive effect under the principle ofrelevance.
Like Re?canati, they establish the lin-guistic meaning as the boundary between seman-tics and pragmatics and divide the inferential pro-cess into the two subprocesses enrichment (result-ing in the explicatum) and deduction (resulting inthe implicatum).As the main aim of this theory is to explain hu-man cognition and not to design artificial intelli-gence, it is not directly translatable into a methodfor automation in applied robotics.
One prob-lem for automation is the assumption that inter-actants access and use all kinds of information, asneeded.
The inherently open nature of this theorymakes its operationalization as a general frame-work impossible.
In addition, assessing the rele-vance and cognitive effort of every item of infor-mation and process of reasoning makes it compu-tationally too complex for practical applications.Moreover, Relevance Theory is not backed by agrammatical theory, and therefore lacks a com-prehensive set of interpersonal linguistic featuressuch as attitudes and stances.In our approach, we follow the principle of sep-arating meaning into linguistic meaning, explica-tum, and implicatum, as proposed by RelevanceTheory.
Instead of the general effort-effect bal-ance, we propose the concept of tacit contractswhich operate on the pragmatic deduction step ofcommunication in the Relevance Theory frame-work.
Tacit contracts also differ from Grice?s sys-tem of conversational maxims, which is not spe-cific enough to distinguish which inferences areexpected from particular individuals in their cur-rent functional roles.Rather than general maxims of communication,tacit contracts are specific agreements entered intoby two or more parties that establish obligationsbetween those parties.
These contracts determinethe services that a party is required to performin given situations.
Therefore they determine theservices that the speaker can expect from the ad-dressee when he or she causes these situations tohappen.
For example, a contract such as ?yourwish is my command?
only applies to interactantsoccupying a given role in the interaction, such ascaregiver, waiter, etc., and only for a given set ofactions that correspond to this role.
If Karl is sit-ting in a cafe?
and says to the waiter ?I would likesteak for the main course.
?, the waiter would treatthis wish as a command to serve the desired food,because bringing food is part of his tacit contractas a waiter.
If Karl were to state ?I would like tohave your hat.
?, the waiter would not consider thisa command, but a statement, because, although hewould be capable to do so, providing the hat is notpart of his contract as a waiter.Politeness, in this perspective, is a manner ofobtaining a stock whereby a speaker replaces hisor her requirement for an addressee to give out astock with an exchange of information about thecurrent situation.
The new information triggersa tacit contract which then enables the addresseeto infer the contractual requirement for the currentsituation in a separate step of deduction.4.3.1 Interactional SituationFor inferring implicata it is also important to dif-ferentiate two types of businesses: stocks and is-sues.
For instance, in the afore-mentioned table-attending situation, let?s suppose Karl had saidthe same utterance to his friend Hanna ?I would299like steak for the main course.
Because Hannacannot give a steak to Karl, the business of thisinteraction, providing a steak, is an issue andnot a stock?they cannot exchange it, but onlytalk about it.
The difference to the hat exampleabove is that the waiter can provide his hat, but isnot required to do so by any applicable contract,whereas Hanna may want to provide the steak, butis not able to4.By classifying businesses into stocks and issues,it is possible to trim down the inferential processfurther to avoid undesired implicatures.
For in-stance, a wheelchair should treat the following twoutterances differently: 1.
?I would like to go to thekitchen?
and 2.
?I would like to open the door?.Taking someone to the kitchen is a stock in thisinteraction?a service that the wheelchair can per-form and that the user can assign to it.
Opening thedoor, on the other hand, is not in the range of thewheelchair?s capabilities and therefore an issue.In the following subsection, we will explainhow contracts and business kinds are used in theinferential calculus for generating an implicatumout of the explicatum.
Then we will proceed topresent the specific contracts relevant for the in-teraction with an intelligent wheelchair.4.3.2 Contractual CalculusReference resolution and all other situational at-tachments of meaning are dealt with in the en-riching step of the inferential process.
Example(10) shows the enrichment of an utterance in thewheelchair scenario.
(10)?I would like to go to the kitchen?ADDRESSEE-CENTERED MEANING:Speaker requires Addresseeto know thatSpeaker would liketo go to the kitchenEXPLICATUM:JOHN requires ROLLANDto know thatJOHN is keento go to KITCHEN#1After enrichment, the contractual phase is entered.Contracts may be triggered by a requirement to-wards the wheelchair to say or know.
This is thenre-interpreted as a polite requirement to give or re-ceive goods, services, or information dependingon the contract.The process for selecting applicable tacit con-tracts is the following: once a declarative re-quirement has been detected, the system checks4Notice that this reasoning constraint is similar to the Fea-sibility predicate of FTRI.Table 4: SurrogationUser: ?I need to go to the kitchen.
?I need to go to the kitchenSubject Finite ?
?Actor ?
Process DestinationMedium ?
?
?Wheelchair: ?Ok, I?ll take you there.
?I ?ll take you thereSubject Finite ?
?
?Actor ?
Process Action-Goal DestinationAgent ?
?
Medium ?whether the speaker is the requirer and the ad-dressee the provider of the impersonal stance.If so, for each known contract, it is determinedwhether the contract applies for the given requirerand provider in their current functional roles.
Foreach applicable contract, the contract script is per-formed, as will be shown in the following section.4.3.3 Wheelchair ContractsHere we present the contracts needed for un-derstanding the utterances that occurred in ourwheelchair-usage corpus.
All user utterances inthe corpus, except for three cases, can be under-stood appropriately with the given contracts.Surrogation is the contract whereby a statementby the speaker of their inclination or obligation toperform an action is interpreted as a demand ofa service.
For example, if the user puts a bottleon the intelligent wheelchair and tells it ?I need totake this bottle to Hannah?, the wheelchair shouldtreat this as a command to take the bottle to Han-nah, assuming she is close by (similar to the im-plication in FTRI discussed in section 3).For a non-affecting action such as ?going?, theentity that undergoes change as a result of the ac-tion (the Medium) is the Actor.
In an affecting ac-tion such as ?put?, on the other hand, the Mediumis the Action-Goal or action target?the thing be-ing put.
If a person states that they need to per-form an action, the wheelchair needs to performa service in which it is the Actor and which im-poses the same result on the Medium.
As Table4 shows, this entails substituting a non-affectingaction (?go?)
with an affecting action (?take?
).Example (11) shows the performance of a con-tractual implicature in the deductive process.
(11)?I need to go to the kitchen?EXPLICATUM:JOHN requires ROLLANDto know that300JOHN is requiredto go to the kitchenIMPLICATUM:JOHN politely requires ROLLANDto take JOHN to the kitchenSupply is a contract whereby requiring X to saywhether X will do should be interpreted as requir-ing X to do.Need gleaning is a contract whereby the ad-dressee is required to interpret a question about theavailability of a stock as a statement of its need bythe speaker.
This contract is used together withSurrogation to create polite commands.
Example(12) shows the inference of first applying the con-tract need gleaning, interpreting a requiring X tosay whether X can do Y as a requiring X to knowthat Y needs to be done, and then applying the con-tract surrogation, as described above.
(12)?Can you take me to the kitchen?
?EXPLICATUM:JOHN requires ROLLANDto say whetherROLLAND cantake JOHN to the kitchenIMPLICATUM: NEED GLEANINGJOHN politely requires ROLLANDto know thatJOHN needsto be taken to the kitchenIMPLICATUM: SURROGATIONJOHN requires ROLLAND very politelyto take JOHN to the kitchenSupport is a contract whereby the statement ofthe speaker?s inclination or obligation to performan action is understood as a command to offer thestock that serves to fulfill the preconditions forperforming his or her intended or required action.As Example (13) shows, requiring X to know thatY is keen to is interpreted as requiring X to performan action that enables Y to.
(13)?I?d like to open the door!
?EXPLICATUM:JOHN requires ROLLANDto know thatJOHN is keento open the doorIMPLICATUM: SUPPORTJOHN politely requires ROLLANDto take JOHN to a placewhere JOHN can open the doorThis contract is dependent on the classification ofentities by affordances and usage preconditions.
Awheelchair can only decide where to take the userwho says ?I would like to do a mouth wash?, if itknows that doing a mouth wash requires the userto be at a certain position in front of a wash basin.In addition, in order to distinguish whether toapply the contract support or the contract surro-gate, the distinction between stock and issue iscentral.
If the desired action of the speaker is astock, i.e.
a service that can be performed by thewheelchair, the contract surrogate should be ap-plied.
If it is an issue, the contract support shouldbe applied instead.5 Discussion and OutlookWe have presented the main linguistic features ofour Enactment Upper Model and shown how to in-fer dialogue acts by using tacit contracts.
With thisprocedure, we are able to determine automaticallywhich actions the wheelchair is expected to do formost utterances of our corpus.
From a theoreticalpoint of view, we proposed a method of deducingimplicata by applying contractual scripts that com-bine a linguistic and a philosophical approach withthe strict purpose of automation and, in specific,of controlling an intelligent wheelchair.
In doingso, we fill the gap between a linguist?s set of lexi-cogrammatical features with requiring force and aphilosopher?s set of axioms from which it can bededuced whether the user made a request.On a robot design perspective, we have sparedthe text analysis component from creating specificspeech acts for a number of clause structures suchas ?can you...?
and ?will you...?
and so on, whichwould otherwise be necessary, and spared the dia-logue manager from managing a large number ofuser?s dialogue-related intentions and from deal-ing with the otherwise present ambiguity of con-textually interpretable utterances such as ?I needto open the door?.
In addition, our approach en-ables adjustment for new wheelchair functionalitywithout rewriting the whole text analysis compo-nent and allows for an easy addition of new tacitcontracts with corresponding scripts.The approach presented in this paper provides aprincipled way for inferring dialogue acts that usesthe structural information present in the clause andtherefore enables high accuracy and reusabilityboth on the semantic and on the pragmatic level.In order to gain a full understanding of the scala-bility of this approach, further investigation of ap-plicable contracts in different application domainsis necessary.AcknowledgmentsWe gratefully acknowledge the support of the DeutscheForschungsgemeinschaft (DFG) through the CollaborativeResearch Center SFB/TR8 Spatial Cognition.
We also thankDimitra Anastasiou for collaboration in designing and con-ducting the experiment.301ReferencesJames F. Allen and Mark G. Core.
1997.
Draft ofDAMSL: Dialog Act Markup in Several Layers.
re-trieved from: http://www.cs.rochester.edu/research/speech/damsl/RevisedManual/, July 16th 2013.Dimitra Anastasiou, Cui Jian, and Desislava Zhekova.2012.
Speech and Gesture Interaction in an AmbientAssisted Living Lab.
In SMIAE ?12 Proceedings ofthe 1st Workshop on Speech and Multimodal Inter-action in Assistive Environments, pages 18?27, Jeju,Republic of Korea.
Association for ComputationalLinguistics.Robyn Carston.
1998.
The Semantics/Pragmatics Dis-tinction: A View from Relevance Theory.
UCLWorking Papers in Linguistics, 10:303?329.Mark G. Core and James F. Allen.
1997.
Coding Di-alogs with the DAMSL Annotation Scheme.
Tech-nical report.Mark G. Core.
1997.
Analyzing and Predicting Pat-terns of DAMSL Utterance Tags.
In Working notesAAAI spring symposium on applying machine learn-ing to discourse processing, pages 18?24.Herbert P. Grice.
1975.
Logic and Conversation.
Syn-tax and Semantics 3: Speech arts, pages 41?58.Michael A. K. Halliday and Christian M. I. M.Matthiessen.
2004.
Introduction to Systemic Func-tional Grammar.
Arnold, London, 3 edition.Edward Ivanovic.
2005.
Dialogue Act Tagging forInstant Messaging Chat Sessions.
In Proceedingsof the ACL Student Research Workshop, pages 79?84, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Susanne Jekat, Alexandra Klein, Elisabeth Maier, IlonaMaleck, Marion Mast, and J. Joachim Quantz.
1995.Dialogue Acts in VERBMOBIL.
Technical report.Daniel Jurafsky, Elizabeth Shriberg, and Debra Bi-asca.
1997.
Switchboard SWBD-DAMSL Shallow-Discourse-Function Annotation Coders Manual,August.Daniel Marcu.
1997.
Perlocutions: The Achilles?
Heelof Speech Act Theory.
Journal of Pragmatics.Colin Matheson, Massimo Poesio, and David Traum.2000.
Modelling Grounding and Discourse Obliga-tions Using Update Rules.
In Proceedings of the 1stNorth American chapter of the Association for Com-putational Linguistics conference, pages 1?8.
Asso-ciation for Computational Linguistics.Vivek K. Rangarajan Sridhar, Srinivas Bangalore, andShrikanth Narayanan.
2007.
Exploiting ProsodicFeatures for Dialog Act Tagging in a Discrimina-tive Modeling Framework.
In Proceedings of Inter-Speech, pages 150?153, Antwerp, Belgium.Vivek K. Rangarajan Sridhar, Srinivas Bangalore, andShrikanth Narayanan.
2009.
Combining Lexical,Syntactic and Prosodic Cues for Improved OnlineDialog Act Tagging.
Computer Speech & Lan-guage, 23(4):407?422.Franc?ois Re?canati.
1991.
The Pragmatics of What isSaid.
In Steven Davis, editor, Pragmatics: a reader,pages 97?120.
Oxford University Press, New York.Sophie Rosset and Lori Lamel.
2004.
Automatic De-tection of Dialog Acts Based on Multi-level Infor-mation.
In in ICSLP, Jeju Island, pages 540?543.Sophie Rosset, Delphine Tribout, and Lori Lamel.2008.
Multi-level information and automatic dia-log act detection in human-human spoken dialogs.Speech Communication, 50(1):1?13.M.
David Sadek, A. Ferrieux, A. Cozannet, PhilippeBretier, Franck Panaget, and J. Simonin.
1996.
Ef-fective Human-Computer Cooperative Spoken Dia-logue: the AGS Demonstrator.
In Spoken Language,1996.
ICSLP 96.
Proceedings., Fourth InternationalConference on, pages 546?549 vol.1.M.
David Sadek, Philippe Bretier, and Franck Panaget.1997.
ARTIMIS: Natural Dialogue Meets Ratio-nal Agency.
In in Proceedings of IJCAI-97, pages1030?1035.
Morgan Kaufmann.M.
David Sadek.
1992.
A Study in the Logic of Inten-tion.
In Proceedings of the 3rd International Con-ference on Principles of Knowledge Representationand Reasoning (KR?92).
Cambridge, MA, October25-29, 1992, pages 462?473.
Morgan Kaufmann.M.
David Sadek.
1994.
Communication Theory = Ra-tionality Principles + Communicative Act Models.In In: Proc.
of AAAI 94 Workshop on Planning forInteragent Comm.Dan Sperber and Deirdre Wilson.
1995.
Relevance.Communication and Cognition.
Wiley-Blackwell.Mark Steedman and Jason Baldridge.
2011.
Combina-tory Categorial Grammar.Amanda J. Stent.
2000.
The Monroe Corpus.
Techni-cal report.Andreas Stolcke, Noah Coccaro, Rebecca Bates, PaulTaylor, Carol Van Ess-Dykema, Klaus Ries, Eliz-abeth Shriberg, Daniel Jurafsky, Rachel Martin,and Marie Meteer.
2000.
Dialogue Act Mod-eling for Automatic Tagging and Recognition ofConversational Speech.
Computational Linguistics,26(3):339?373.David R. Traum and James F. Allen.
1994.
DiscourseObligations in Dialogue Processing.
In Proceedingsof the 32nd annual meeting on Association for Com-putational Linguistics, pages 1?8.
Association forComputational Linguistics.302David R. Traum and Elizabeth A. Hinkelman.
1992.Conversation Acts in Task-oriented Spoken Dia-logue.
Computational intelligence, 8(3):575?599.David Traum, Johan Bos, Robin Cooper, Staffan Lars-son, Ian Lewin, Colin Matheson, and Massimo Poe-sio.
1999.
A Model of Dialogue Moves and Infor-mation State Revision.
Technical report.Daniel Couto Vale and Vivien Mast.
2012a.
Key In-terpersonal Communication Skills for Wheelchairs.In CogInfoCom ?12 Proceedings of the 3rd IEEE In-ternational Conference on Cognitive Infocommuni-cations, pages 421?426, Kosice, Slovakia.
IEEE.Daniel Couto Vale and Vivien Mast.
2012b.
UsingFoot-Syllable Grammars to Customize Speech Rec-ognizers for Dialogue Systems.
In TSD ?12 Lec-ture Notes in Artificial Intelligence vol.
7499, Brno,Czech Republic.
Springer.303
