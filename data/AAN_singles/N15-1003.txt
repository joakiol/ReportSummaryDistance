Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 21?31,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsImproving unsupervised vector-space thematic fit evaluationvia role-filler prototype clusteringClayton Greenberg, Asad Sayeed and Vera DembergComputational Linguistics and Phonetics / M2CI Cluster of ExcellenceSaarland University66123 Saarbr?ucken, Germany{claytong,asayeed,vera}@coli.uni-saarland.deAbstractMost recent unsupervised methods in vectorspace semantics for assessing thematic fit (e.g.Erk, 2007; Baroni and Lenci, 2010; Sayeedand Demberg, 2014) create prototypical role-fillers without performing word sense disam-biguation.
This leads to a kind of sparsityproblem: candidate role-fillers for differentsenses of the verb end up being measured bythe same ?yardstick?, the single prototypicalrole-filler.In this work, we use three different featurespaces to construct robust unsupervised mod-els of distributional semantics.
We show thatcorrelation with human judgements on the-matic fit estimates can be improved consis-tently by clustering typical role-fillers andthen calculating similarities of candidate role-fillers with these cluster centroids.
The sug-gested methods can be used in any vectorspace model that constructs a prototype vec-tor from a non-trivial set of typical vectors.1 IntroductionThematic fit estimations can be quite useful formany NLP applications and also for cognitive mod-els of human language processing difficulty, sincehuman processing difficulty is highly sensitive tosemantic plausibilities (Ehrlich and Rayner, 1981).For example, we expect that after the word mash,banana would be easier to process because it fitswell as the patient, or direct object, of mash, butmilk would be harder to process because it does notfit well.A common method for estimating the thematic fitbetween a verb and a proposed role filler involvescomputing a centroid, or vector average, over themost typical role fillers for that verb, and then cal-culating the cosine similarity between this centroidand the proposed role filler (Baroni and Lenci, 2010;Blacoe and Lapata, 2012; Erk, 2012).
For instance,we use the cosine of the angle between the bananavector and a vector average of the 20 nouns that,according to training data, are most likely to bemashed as a score for how well banana fits as thepatient of mash.
Hopefully, the banana vector willbe closer to the centroid than milk, so banana willhave a higher cosine similarity to the centroid, andthus a higher thematic fit score, than milk.This conceptualization assumes that the most typ-ical fillers for a verb-role will all be variants of asingle prototype, i.e.
distributionally similar to eachother.
However, such an assumption may not betrue for ambiguous verbs.
A verb with many dif-ferent senses may have typical fillers for each sense,which fit relatively equally well, but are distribution-ally very different from one another.
This means thatthe calculated prototypical filler will be a mixtureof the arguments that are typical role fillers for themain senses of the verb.
For example, consider theverb serve, for which the 24 most typical preposi-tional arguments related via the preposition with fallinto three different senses, as illustrated in Figure 1.Supposing that the centroid occupies a part of thevector space between two typical role fillers, but isrelatively far from any one of the typical role fillersfrom which it was composed, as in Figure 1, none ofthe original typical role fillers will achieve high the-21overall??centroid?regiment?Verb?serve,??with?-??preposi?onal?object?ba?alion?squadron?
army?no?e?order?sauce?salad?meal?wine?
cluster?3?centroid?cluster?2?centroid?cluster?1?centroid?Figure 1: Illustration of TypeDM centroid for with-PParguments of the verb serve.matic fit scores.
Also, verbs will be ?penalized?
forhaving many senses in that it will seem as though norole filler fits as well as they do with unambiguousverbs.
This may produce inconsistent judgementswhen comparing one verb that is highly polysemouswith a second, more restrictive verb whose mean-ing overlaps with the most dominant meanings ofthe first verb.
For example, cut can be used in thesense of ?cutting costs,?
which carries with it re-strictions on instruments, locations, and so on thatsomewhat overlap with eliminate as in ?eliminatingcosts.?
Things that are plausible to be eliminatedare also plausible to be cut.
But cut is also used inthe sense of ?cutting a cake?
or ?cutting (editing) afilm.?
Without taking word sense into account, costswould be judged by the model as being less appro-priate as a patient of cut than it should, and also itsscore for filling the patient role of eliminate wouldbe infelicitously higher than its score for filling thepatient role of cut.One possible solution to this problem would beto do full word sense disambiguation on the re-sources from which these vector spaces are con-structed.
Then, there would be separate entries inthe space for each meaning.
This would howeverincrease the overall size of the vector space by a sig-nificant factor and also cause an additional burdenon corpus construction and annotation, even if auto-matic.In this paper, we will approach the verb-role senseproblem by clustering the most typical role-fillervectors and calculating the maximal cosine similar-ity for a candidate role filler with respect to eachcluster prototype vector.
So, to estimate the the-matic fit of salad as an item with which somethingis served, in the vector space represented by Fig-ure 1, we would use the cosine similarity with thenearest cluster centroid, the cluster 1 centroid.
Fora thematic fit task, the correlation between calcu-lated estimates and human judgements can be ex-pected to improve.
In particular, good role fillersthat are very different from one another and belongto different senses of a verb can all be assigned the-matic fit scores as high as those of good role fillersof monosemous verbs.We will evaluate our system using three distribu-tional spaces: TypeDM (Baroni and Lenci, 2010),which is based on a syntactic dependency parser,SDDM (Sayeed and Demberg, 2014), which usesfeatures obtained from the semantic role labellerSENNA (Collobert et al, 2011), and SDDMX , anovel extension of SDDM .
This way, we can drawconclusions about feature space-specific and featurespace-general trends.The effects of clustering and choice of distri-butional space will be evaluated against the Pad?o(2007) and McRae et al (1998) datasets of hu-man judgements on thematic fit of agent and patientroles, and the Ferretti et al (2001) datasets of humanjudgements on thematic fit of instrument and loca-tion roles.
These different roles are conceptually in-teresting to compare, as instruments tend to be morestrongly constrained by verbs than locations.2 Background and related work2.1 Thematic fitThe fit of a filler of a thematic role can be character-ized as a semantic constraint on what can fill poten-tially available syntactic slots for a given predicate.For example, not every noun can satisfy the agentor patient roles of the typically transitive verb eat.There must be a valid ?eater?
for the agent and avalid ?eatee?
for the patient.
Some nouns are simplymore plausible than others in these positions: lunchis eaten, but rarely ever eats.
But there can also beoptional role assignments: there are certain utensilswith which one is more or less likely to eat (i.e.,appropriate instrument role-fillers) and even placeswhere one is more or less likely to eat (i.e., locationroles).22Verb Noun Semantic role Scoreadvise doctor agent 6.8advise doctor patient 4.0confuse baby agent 3.7confuse baby patient 6.0eat lunch agent 1.1eat lunch patient 6.9kill lion agent 2.7kill lion patient 4.9kill man agent 3.4kill man patient 5.4Table 1: Sample of judgements from Pad?o (2007).In order to model thematic roles, we use the in-sight that thematic fit correlates with human plau-sibility judgements (Pad?o et al, 2009; Vandekerck-hove et al, 2009).
Therefore, we can use datasetsof human plausibility judgements to evaluate com-putational thematic fit estimates.
One such datasetby Pad?o (2007) includes 18 verbs with up to 12 can-didate nominal arguments and totals 414 verb-noun-role triples.
The words were chosen based on theirfrequencies in the Penn Treebank and FrameNet.Human participants were asked to rate the appropri-ateness of given nouns as agents and as patients forgiven verbs on a scale from 1 to 7.
The judgementswere then averaged.
We provide a small sample ofthese judgements in Table 1.We use three other datasets as well.
Ferretti et al(2001) provide two datasets, one with 248 verb-instrument pairs and one with 274 verb-locationpairs.
Additionally, McRae et al (1998) give adataset of 1444 more agent/patient judgements.
Wewrite agent/patient as such because like Pad?o (2007),the agent plausibility and patient plausibility aregiven in the same dataset, albeit separately.
Onceagain, human participants were asked to rate the ap-propriateness of given nouns as locations, instru-ments, and agents/patients, respectively, of the verbsin each dataset on a scale from 1 to 7.
We will makeuse of these in our evaluation in order to see howwell the models and algorithms we propose apply tovarious thematic roles, not just the most commonlytested and to-date most accurately estimated roles ofagent and patient.2.2 Distributional Semantics2.2.1 Distributional MemoryOur semantic modeling technique comes fromBaroni and Lenci (2010), who developed an explic-itly multifunctional, i.e.
not tightly bound to a par-ticular task, framework for recording distributionalinformation about linguistic co-occurrence.
Distri-butional Memory (DM) records frequency informa-tion about links between words in a sentence as athird order tensor, in which words or lemmata arerepresented as two of the tensor axes and the syntac-tic or semantic link between them is the third axis.The following corpora were used to construct theBaroni and Lenci (2010) version of DM:?
ukWaC, a corpus of about two billion wordscollected by crawling the .uk web domain(Ferraresi et al, 2008).?
WackyPedia, a snapshot selection of Wikipediaarticles.?
The British National Corpus (BNC), a 100-million word corpus including documents suchas books and periodicals.The sentences from these sources were first runthrough MaltParser (Nivre et al, 2007).
Thedependency links (e.g.
SBJ, NMOD) were runthrough a set of hand-crafted patterns to identifyhigher-level lexicalized links (e.g.
as-long-as,in-a-kind-of).
They then counted link type fre-quencies, so that links that involve the same lexi-cal item (e.g.
long, kind, as in the lexicalizedlinks just mentioned) were collapsed into a singlelink, and the number of surface form realizationswas used as the frequency count.
All words werelemmatized and stored with basic part of speech in-formation.All these counts were then adjusted by Local Mu-tual Information (Baroni and Lenci, 2010), which isgiven byLMI(i, j, k) = OijklogOijkEijk(1)where i, j are words, k is the link between them,O is the observed frequency, and E is the expectedfrequency under independence.
Tuples with nonpos-itive LMI values were removed.
They called thistensor TypeDM .232.2.2 DM Based on Semantic Role LabelsIn order to create a competitor to the muchless manually pruned cousin of TypeDM namedDepDM, Sayeed and Demberg (2014) based SDDM(short for SENNA-DepDM) on similar corpora butused alternative features.
Namely, this tensor wasbuilt from ukWaC and BNC, but the features camefrom a semantic role labelling (SRL) system calledSENNA (Collobert and Weston, 2007; Collobertet al, 2011).
SENNA uses a multi-layer neural net-work architecture that learns in a sliding windowover token sequences working on raw text instead ofsyntactic parses, as other semantic role labellers do(Bohnet, 2010).
SENNA extracts word features re-lated to identity, capitalization, and suffix/tense (ap-proximated by the last two characters of the word).From these features, in a process similar to decod-ing a conditional random field, the network derivesfeatures related to verb position, part of speech, andchunk membership.SENNA was trained on PropBank and largeamounts of unlabelled data.
It achieves a role la-belling F-score of 75.49% (in this case, tested onCoNNL 2005 data), which is slightly lower thanstate of the art SRL systems which use parse treesas input.SDDM was built by running the sentences fromthe input corpora through SENNA and using the rolelabels as links between predicates and role-fillers.Unlike TypeDM , SDDM required almost no fur-ther processing; the raw frequency counts of tripleswere used in the LMI calculation.In this paper, we present SDDMX , an extendedversion of the SDDM model1.
SDDMX containsthe same links as SDDM and also contains links be-tween nouns that belong to the same predicate in-stance, using the predicate as a link label.
For exam-ple, supposing that during training the system en-countered the man eats a donut with a role link be-tween man and eat and another role link betweendonut and eat, then in SDDMX , a link was cre-ated between man and donut.
This link was labelledwith the verb lemma for the 400 most frequent verbs(eat in our example), and vb otherwise.Sayeed and Demberg (2014) found that although1We provide SDDM and SDDMX athttp://rollen.mmci.uni-saarland.de/.the donutwaseatenbyBobNMODSBJVCLGSPMODthe donutwaseatenbyBobARG1VARG0Figure 2: The same sentence with MaltParser (above)and SENNA (below) labels.
Sayeed and Demberg (2014)used a simplified approach similar to the head percola-tion table of Magerman (1994) to find head nouns fromSENNA annotation.SDDM is an arguably simpler DM model thanTypeDM , it performs nearly as well as TypeDM ona thematic fit estimation task using the Pad?o (2007)and McRae et al (1998) agent/patient datasets.
Theyalso found that averaging the thematic fit scoresof SDDM with those of TypeDM outperformsTypeDM alone and nearly reaches the performanceof a supervised model (Herda?gdelen and Baroni,2009).
This suggests that TypeDM and SDDMcover different aspects of the corpora on whichthey were trained.
Links generated by SENNAmay directly access semantic role features thatthe MaltParser-based TypeDM must infer throughhand-crafted rules, such as tagging the subject as apatient instead of an agent in passive-voice contexts.Figure 2 illustrates the differences between the la-belling approaches.We make use of the SDDM , SDDMX , andTypeDM tensors in our experiments to demonstratehow our techniques improve performance in the-matic fit modelling across different feature spaces.2.2.3 Centroid-based thematic fit calculation inDMInvestigating alternative ways to calculate the-matic fit over the DM framework is a major goal ofthis work, so we now describe the baseline process.Baroni and Lenci (2010) used the following ap-proach to estimate thematic fit on the Pad?o (2007)agent/patient dataset: To assess the fit of a noun w1in a role r for a verb w2, they construct a centroidfrom the 20 highest-ranked fillers for r with w2se-lected by LMI, using the relevant syntactic depen-dency links, such as subject and object, instead of24thematic roles.
To illustrate, in order to determinehow well workshop fits as a location for eat, theywould construct a centroid of other locations for eatthat appear in the DM, e.g.
kitchen, restaurant, cafe-teria up to 20.Each of these top 20 represent a ?slice?
of the ten-sor along one of the word axes.
One such slice, cor-responding to w1, is a matrix of links and words towhichw1is connected.
This tensor slice is collapsedinto a vector whose components are word-link pairs.This is the vector of w1.All 20 such vectors are added up and the sum isthe centroid that represents, e.g., the typical loca-tions of eat.
Then a vector is constructed from theslice of the tensor corresponding to workshop.
Thethematic fit score is the cosine of the location cen-troid of eat and the vector of workshop.Accessing thematic roles in SDDM andSDDMX is straightforward, as the links in thesemodels are PropBank roles.
Agent is ARG0, patientis ARG1, location is ARGM-LOC, and we use acombination of ARGM-MNR, ARG2, and ARG3 torepresent instruments, based on a translation ofthe roles used by Ferretti et al (2001).
The rolemapping for TypeDM involves a combination ofsbj tr and subj intr (transitive and intran-sitive subjects) for agents, obj for patients, theprepositional links in, at, and on for locations,and with for instruments.2.3 Word Sense Disambiguation inDistributional ModelsWhile distributional models carry important infor-mation about the relative frequencies of word us-ages, and perhaps even phrase usages, they oftenmust collapse such usages into one representation.For example, suppose within the domain of cookingrecipes, serve occurs in its food sense (see cluster1 in Figure 1) 97% of the time.
The other senseswill have negligible effect on the representation ofserve because their frequencies are so much lower.But in a web crawl, the distribution is quite likely tobe more uniform, which means the senses will ?splitthe difference?
in the representation and end up notbeing that similar to any instance of serve.Many systems work to alleviate this problem byperforming manipulations on words as they occur intraining corpora (e.g., Thater et al, 2011).
Namely,the base vector for the potentially ambiguous wordis contextualized, as in scaled element-wise, by thevectors of the neighboring words for that instance.This is quite intuitive because if serve and cake oc-cur next to each other, the chance that a non-foodsense of the word serve was intended would be ex-tremely small, in fact much smaller than a corpus-wide distribution would predict.
These systems havebeen effective at improving correlation with humanjudgements for a verb-object composition model,i.e.
approximating a vector for serve cake givena vector for serve and a vector for cake (Kartsak-lis et al, 2014), and also reducing noise in simi-larity scores for a nearest neighbor-based preposi-tional phrase attachment disambiguator (Greenberg,2014).It remains a choice of the system whether to storeexplicit senses separately, and relatedly, whether toconsult a knowledge base for the number of sensesfor each word, or even for meaning representationsof those senses.
Using a task-general knowledgebase, in addition to the inherent cost of buildingone, is not particularly suited for our task becausethe items to be disambiguated are verb-role pairs, asopposed to just verbs, and usually such knowledgebases do not handle individual thematic roles sepa-rately.
For instance, it may be optimal to analyzeserve as having three senses with respect to instru-ments, two senses with respect to patients, and onesense with respect to agents.Assigning semantic categories to the slots of averb subcategorization frame harks back to work byResnik (1996) and Rooth et al (1999).
Resnik?swork presupposes predefined noun classes obtainedfrom WordNet.
Rooth et al induced latent role-fillerclasses via expectation maximization.
Erk et al(2010) found that neither are good models of the-matic fit.
Pad?o et al (2009) provided thematic fitscores that take into account verb class using a su-pervised model.
In the vector space context, in-ducing different vectors for multiple verb senses hasbeen investigated recently by Reisinger and Mooney(2010), Huang et al (2012), and Neelakantan et al(2014), although these were not focused on role-fillers for verbs.
Our contribution is to make use of alarge-scale, unsupervised vector space model to pro-vide thematic fit scores after inducing implicit verbsense classes relative to thematic role.253 MethodsWe begin our discussion of sense disambiguation forthematic fit with the following insight: the baseline(Centroid ) method takes as input a set of typicalrole-fillers, the highest-ranked ones according to theDM, and returns a single prototype vector.
How-ever, if we allow the system to return a set of proto-type vectors, then the framework gains the capacityto handle multiple senses of the verb-role pair.The first choice is how to handle the output.
Nowinstead of one cosine similarity, we would have a setof cosines corresponding to the similarities betweenthe test role-filler and each prototype vector in theset.
But if we make the theoretical assumption thateach prototype corresponds to a sense, then roughlyonly one should apply at a time.
So, we choose touse the one that is most relevant, i.e.
similar, to thetest role-filler.
Therefore, we use the maximum ofthe cosine similarities as the thematic fit score.3.1 One best or nearestIn the extreme case, we can just use the unaltered setof highly-ranked role-fillers as our set of prototypes.For example, if we query TypeDM for the top fourinstrument-fillers of eat, we would retrieve spoon,hand, bread, and sauce.
Then, to assign a thematicfit score for fork as an instrument-filler, we computethe cosine similarities of (fork, spoon), (fork, hand),(fork, bread), and (fork, sauce).
The cosine simi-larity of (fork, spoon) is the highest, so this cosinedetermines the score.
We refer to this method asOneBest .
Note that OneBest requires the calcu-lation of a large number of cosines, which is a rel-atively expensive operation given the sparse repre-sentations of words in DM spaces.The number of retrieved top role-fillers (n) ap-pears to be the only parameter for OneBest .
Yet,this method poses a few theoretical questions.
First,there most likely should be an upper bound on thenumber of role-fillers that the system can retrieve atonce.
Mathematically, allowing the system to re-trieve the entire relevant cross-section of the ten-sor would be equivalent to reducing the thematic fitevaluation task to a binary decision, i.e.
whether theverb-role has occurred with the test role-filler in thetraining data.
So, we would not be able to model anygraded effect on the fit of two seen role-fillers, evenif one of them fits with the verb-role better than theother.
Also, psycholinguistically, it seems implausi-ble that one must remember all of the times that onehas encountered a word in order to use it.
Therefore,we impose 50 as an arbitrary upper bound on n. Wealso set a lower bound of 10 on n because valuessmaller than this generated quite erratic sets of toprole-fillers.Second, OneBest might return a cosine of 1.0 ifthe DM retrieves the test role-filler itself as one ofthe top role-fillers.
This could unfairly help the cor-relation between the cosines returned by the systemand human judgements because the good role-fillerswould all have the same cosine value, thus reducingthe effect of the cosine ratings produced for the moredistant (interesting) role-fillers.
Therefore, we pro-hibit our system from returning any cosines of 1.0.The test role-filler thus achieves a high score by hav-ing a closely related role-filler in the prototype set,not by being present itself.3.2 ClusteringIn order to reduce noise from OneBest , we clustersimilar top role-fillers together, calculate centroidsfor each cluster, and use these cluster centroids asthe prototype set.
This way, the presence of ananomalous vector in the centroid set has less effect.We use the group average agglomerative clusteringpackage within NLTK (Bird et al, 2009).
This algo-rithm works by initializing each top role-filler in itsown cluster and iteratively combining the two mostsimilar clusters.For the stopping criterion, which determines thefinal number of clusters for the verb-role, we use theVariance Ratio Criterion (V RC) method (Cali?nskiand Harabasz, 1974).
Let c be the baseline centroidof all top role-fillers retrieved, f be a top role-filler,and cfbe the cluster centroid of the cluster to whichf is assigned.
Then, this method works by (a) calcu-lating the V RC metric for each number of clusters(k), given byV RC(k) =SSBk ?
1/SSWn?
k(2)where we defineSSB=?f(1?
cos2(cf, c)) (3)26andSSW=?f(1?
cos2(f, cf)) (4)and then (2) choosing the final number of clusterssuch that?k= (V RCk+1?
V RCk)?
(V RCk?
V RCk?1)(5)is minimized.
Intuitively, this procedure is meantto find the number of clusters for which addinganother cluster does not explain significantly morevariance in the data.
Also, note that the V RC metricis equivalent to the F-score in a one way ANOVA.The main drawback of the V RC method is that itcannot evaluate fewer than three clusters, due to hav-ing both a V RCk+1and a V RCk?1term in Equa-tion (5).
However, as long as enough top role-fillersare retrieved, it should not hurt the system.
Equiva-lently, we set V RC0and V RC1equal to V RC2.
Toexamine the effect of this choice, we evaluate twoclustering methods: 2Clusters , which chooses twoclusters for every verb-role, and kClusters , whichdynamically chooses a number of clusters between3 and 10 based on the above criterion.Once again, the system is prohibited from return-ing a cosine of 1.0.
This means that if the DM re-trieves the test role-filler itself as one of the top role-fillers, the system would skip comparing the testrole-filler against itself if it were in a singleton clus-ter, but would not skip it if it were a member of acluster of size two or greater.
The alternative to thiswould have been removing the test role-filler beforeclustering, but we saw these role-filler-specific par-titions as a form of supervision.3.3 Evaluation procedureThe Centroid , OneBest , 2Clusters , and kClustersmethods each determine their own prototype vectorset for a verb-role, and then return the maximum co-sine similarity value for each test role-filler.
Proto-type sets are stored in a dictionary so they can bereused.
It is necessary to expand the sparse datastructure of each vector in order to efficiently com-pute all of the necessary cosine similarities.
Finally,we calculate Spearman?s ?
values to measure thecorrelations between these sets of thematic fit scoresand the four datasets of human judgements.Dataset SDDM (X ) TypeDMPad?o (2007) 98.6 100.0McRae et al (1998) 96.0 95.2Ferretti et al (2001) inst.
94.0 93.1Ferretti et al (2001) loc.
99.6 98.9Table 2: Coverage (%) by dataset for each DM model.10 20 30 40 500.200.300.40Role?fillers retrieved (n)Spearman's rhoSDDMX CentroidSDDMX OneBestSDDMX kClustersTypeDM CentroidTypeDM OneBestTypeDM kClustersFigure 3: Spearman?s ?
values for Ferretti et al (2001)instruments vs. the number of vectors retrieved.For our main experiment, we always retrieve thetop 20 highest-ranked role-fillers for the verb-rolepair to compute the prototype set.
This allows ourwork to be more directly comparable with other im-plementations.
Also, choosing a value of n thatmaximizes ?
would make this unsupervised systemmore supervised.
However, it is useful to knowhow the number of top role-fillers retrieved affectsthe correlation with human judgements, so as afollow-up experiment, we evaluate versions of theCentroid , OneBest , and kClusters methods, withthe SDDMX and TypeDM models, retrieving from10 to 50 top role-fillers, against the Ferretti et al(2001) instruments dataset.4 ResultsIn Table 2, we report the coverage percentages forthe DM models on each of the thematic fit datasets.Note that since SDDM and SDDMX differ only inthe additional links added between existing pairs ofwords, their coverages are the same.Figure 3 shows the relationship between the num-ber of vectors retrieved from the DM model and thecorrelation of the system with human judgements.27Pad?o (2007) agents McRae et al (1998) agents Ferretti et al (2001) instrumentsSDDM SDDMX TypeDM SDDM SDDMX TypeDM SDDM SDDMX TypeDMCentroid 0.515 0.528 0.535 0.371 0.394 0.359 0.193 0.274 0.357OneBest 0.321 0.324 0.464 0.375 0.376 0.431 0.274 0.336 0.3942Clusters 0.489 0.412 0.522 0.367 0.373 0.370 0.252 0.331 0.388kClusters 0.281 0.322 0.460 0.396 0.394 0.416 0.335 0.344 0.422Pad?o (2007) patients McRae et al (1998) patients Ferretti et al (2001) locationsSDDM SDDMX TypeDM SDDM SDDMX TypeDM SDDM SDDMX TypeDMCentroid 0.511 0.505 0.525 0.133 0.131 0.343 0.187 0.248 0.230OneBest 0.447 0.467 0.509 0.214 0.233 0.307 0.234 0.276 0.2442Clusters 0.526 0.498 0.551 0.175 0.166 0.353 0.294 0.249 0.235kClusters 0.401 0.428 0.555 0.212 0.227 0.350 0.293 0.326 0.289All from Pad?o (2007) All from McRae et al (1998) All datasetsSDDM SDDMX TypeDM SDDM SDDMX TypeDM SDDM SDDMX TypeDMCentroid 0.512 0.521 0.530 0.237 0.251 0.325 0.258 0.296 0.354OneBest 0.385 0.395 0.482 0.273 0.287 0.345 0.275 0.304 0.3592Clusters 0.508 0.458 0.532 0.252 0.256 0.336 0.287 0.289 0.366kClusters 0.343 0.375 0.503 0.287 0.294 0.359 0.294 0.317 0.385Table 3: Spearman?s ?
for each method on each dataset and on all datasets together, using the 20 highest ranked wordsper verb-role.The first six sections of Table 3 give the Spear-man?s ?
values for our four centroid set constructionmethods evaluated against the four datasets of hu-man judgements, organized by thematic role, all us-ing the 20 highest-ranked words per verb-role.
Wenote that the ?
value for the Pad?o (2007) dataset us-ing TypeDM and the Centroid method is slightlyhigher than the value reported in Baroni and Lenci(2010) due to correcting some transpositions in theoriginal file.
Finally, the last three sections of Table3 give the performance of each method on the twowhole agent/patient datasets (for comparison withprevious work), as well as on all datasets mergedtogether.5 DiscussionWhile SDDM and SDDMX have marginally bet-ter coverage than TypeDM , we do not expect thatthis had an effect on our results.
Figure 3 showsthat for the various numbers of vectors retrievedfrom the DM models, kClusters consistently out-performs OneBest , which consistently outperformsCentroid on the Ferretti et al (2001) instrumentsdataset.
So, using just a single centroid that is a mix-ture of all possible good role-fillers for a verb leadsto problems due to conflating different word mean-ings.
But at the other extreme, we see how the ?values for the OneBest method peak (at n = 13 forSDDMX and n = 34 for TypeDM ) and then de-crease instead of increasing monotonically.
This isbecause we disallowed cosines of 1.0 and becauseas we increase the number of vectors retrieved, theeasier it becomes to be close to one of the prototypevectors, regardless of thematic fit distinctions withinthe prototype set.For the model comparison, we see that whileTypeDM generally performs better than SDDMXon instruments, clustering reduces the gap consider-ably.
Also SDDMX outperforms TypeDM for allmethods on locations as shown in Table 3.
This dif-ference suggests that locations appear in sufficientlydiverse syntactic configurations such that the hand-crafted rules from TypeDM do not work well.From the All datasets section of Table 3, we seethat both OneBest and kClusters improve the ?
val-ues over the Centroid baseline for all three DMmodels.
This holds, too, for the individual instru-ments and locations datasets.
Also, the two cluster-ing methods perform better than Centroid on Pad?o(2007) patients with all DM models and on McRaeet al (1998) patients with TypeDM .
The fact thatCentroid performs best on Pad?o (2007) agents con-28firms previous analyses that have shown that the dis-tribution of objects is more sensitive to verb sensethan subjects.
kClusters outperforming OneBestin a majority of cases suggests that clustering hassuccessfully smoothed the top role-fillers, thus cap-turing sense-like patterns in the verb-roles.As an example of the effect of the kClustersmethod, we obtained the following top 20instrument-fillers for the verb ?eat?
in 4 clusters us-ing TypeDM :?
gusto, relish?
family, friend?
chopstick, finger, fork, hand, knife, spoon?
appetite, bread, butter, cheese, food, meal,meat, mouth, rice, sauceThe V RC method selected 7 to 9 clusters a littlemore often than 3 to 6, which is perhaps more clus-ters than the number of senses we could expect froma task general knowledge base.
We can see from thisexample that the four clusters do not all correspondto separate senses, but instead, they rather nicelyseparate out noise from true instruments.
Note thatsince these role-fillers came from TypeDM , they ap-peared as the object of ?with,?
as a proxy for findinginstruments.
The true instruments ended up all in thethird cluster, which created a cluster centroid that isless affected by noise and errors from the syntacticor semantic parse.
So, the higher number of sensesseems appropriate for this task and data.We attribute the differences in results betweenthe Pad?o (2007) and McRae et al (1998) datasetsto the differences in how these datasets were con-structed.
First, the Pad?o (2007) dataset contains onlyfrequent verbs and most, but not all, of the verb-role pairs contain well-fitting and poorly-fitting role-fillers.
The latter point is especially important be-cause if the range of human judgements is smallfor a certain verb, then it is much more difficult toachieve a large ?
value regardless of the general per-formance level of the system.
McRae et al (1998),however, selected role-fillers much more automat-ically for their psycholinguistic study, so the datapoints do not necessarily reflect a typical sample ofthematic role fitness decisions that occur in natu-ralistic language samples.
So, it makes sense thatthe McRae et al (1998) ?
values are systematicallylower than those of Pad?o (2007).
In fact, the Pad?o(2007) ?
values approach the ceiling of 0.6 as ap-proximated by the supervised system.Lastly, the effect of clustering was larger on in-struments and locations than on agents and patients.A possible explanation is that instruments and lo-cations are less-precisely defined thematic roles andbetter explained by several subclasses, i.e.
clusters.In addition it could be that clustering helps to com-bat SRL inconsistencies.6 Conclusions and future workWe show that clustering verb-roles into ?senses?within a vector space framework achieves a highercorrelation with human judgements on thematic fitover pure Centroid and OneBest methods.
Whilewe demonstrated this using the Distributional Mem-ory technique by Baroni and Lenci (2010), themethod will also be applicable to other vector spacemodels.This task has also been useful for comparingamong DM models and the different thematic fitdatasets.
In particular, we can qualitatively eval-uate how reliable syntax can be for determiningthe semantic notion of thematic fit, and the rela-tive strength of human intuitions on verb-imposedrestrictions on the various roles (agent, patient, in-strument, and location).In future work, we can investigate more sophisti-cated methods of vector clustering (such as expec-tation maximization and non-negative matrix factor-ization), interactions with verb and noun frequency,and interactions with number of word senses froma task-general knowledge-base such as WordNet.
Itwould be especially useful to evaluate this systemof a dataset of human judgements with verbs thatsystematically vary in polysemy, as this would moreclearly expose the general trends we wish to modelcomputationally.AcknowledgmentsThis research was funded by the German ResearchFoundation (DFG) as part of SFB 1102: ?Informa-tion Density and Linguistic Encoding.?
Also, the au-thors wish to thank the three anonymous reviewerswhose valuable ideas contributed to this paper.29ReferencesBaroni, M. and Lenci, A.
(2010).
Distribu-tional memory: A general framework for corpus-based semantics.
Computational Linguistics,36(4):673?721.Bird, S., Klein, E., and Loper, E. (2009).
NaturalLanguage Processing with Python.
O?Reilly Me-dia.Blacoe, W. and Lapata, M. (2012).
A comparison ofvector-based representations for semantic compo-sition.
In Proceedings of the 2012 Joint Confer-ence on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, pages 546?556, Jeju Island, Korea.
As-sociation for Computational Linguistics.Bohnet, B.
(2010).
Very high accuracy and fast de-pendency parsing is not a contradiction.
In Pro-ceedings of the 23rd International Conference onComputational Linguistics, COLING ?10, pages89?97, Stroudsburg, PA, USA.
Association forComputational Linguistics.Cali?nski, T. and Harabasz, J.
(1974).
A dendritemethod for cluster analysis.
Communicationsin Statistics-Simulation and Computation, 3(1):1?27.Collobert, R. and Weston, J.
(2007).
Fast semanticextraction using a novel neural network architec-ture.
In Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics,pages 560?567, Prague, Czech Republic.
Associ-ation for Computational Linguistics.Collobert, R., Weston, J., Bottou, L., Karlen, M.,Kavukcuoglu, K., and Kuksa, P. (2011).
Naturallanguage processing (almost) from scratch.
TheJournal of Machine Learning Research, 12:2493?2537.Ehrlich, S. F. and Rayner, K. (1981).
Contextual ef-fects on word perception and eye movements dur-ing reading.
Journal of verbal learning and verbalbehavior, 20(6):641?655.Erk, K. (2007).
A simple, similarity-based modelfor selectional preferences.
In Proceedings of the45th Annual Meeting of the Association of Com-putational Linguistics, pages 216?223, Prague,Czech Republic.
Association for ComputationalLinguistics.Erk, K. (2012).
Vector space models of word mean-ing and phrase meaning: A survey.
Language andLinguistics Compass, 6(10):635?653.Erk, K., Pad?o, S., and Pad?o, U.
(2010).
A flexi-ble, corpus-driven model of regular and inverseselectional preferences.
Computational Linguis-tics, 36(4):723?763.Ferraresi, A., Zanchetta, E., Baroni, M., and Bernar-dini, S. (2008).
Introducing and evaluatingukwac, a very large web-derived corpus of en-glish.
Proceedings of the 4th Web as CorpusWorkshop (WAC-4) Can we beat Google, pages47?54.Ferretti, T. R., McRae, K., and Hatherell, A.
(2001).Integrating verbs, situation schemas, and thematicrole concepts.
Journal of Memory and Language,44(4):516?547.Greenberg, C. (2014).
Disambiguating prepositionalphrase attachment sites with sense informationcaptured in contextualized distributional data.
InProceedings of the ACL 2014 Student ResearchWorkshop, pages 71?77, Baltimore, Maryland,USA.
Association for Computational Linguistics.Herda?gdelen, A. and Baroni, M. (2009).
BagPack:A general framework to represent semantic rela-tions.
In Proceedings of the Workshop on Ge-ometrical Models of Natural Language Seman-tics, pages 33?40, Athens, Greece.
Associationfor Computational Linguistics.Huang, E. H., Socher, R., Manning, C. D., and Ng,A.
Y.
(2012).
Improving word representations viaglobal context and multiple word prototypes.
InProceedings of the 50th Annual Meeting of theAssociation for Computational Linguistics: LongPapers - Volume 1, ACL ?12, pages 873?882,Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Kartsaklis, D., Kalchbrenner, N., and Sadrzadeh, M.(2014).
Resolving lexical ambiguity in tensor re-gression models of meaning.
In Proceedings ofthe 52nd Annual Meeting of the Association forComputational Linguistics (Vol.
2: Short Papers),pages 212?217, Baltimore, USA.
Association forComputational Linguistics.30Magerman, D. M. (1994).
Natural Lagnuage Pars-ing as Statistical Pattern Recognition.
PhD thesis,Stanford University.McRae, K., Spivey-Knowlton, M. J., and Tanen-haus, M. K. (1998).
Modeling the influence ofthematic fit (and other constraints) in on-line sen-tence comprehension.
Journal of Memory andLanguage, 38(3):283?312.Neelakantan, A., Shankar, J., Passos, A., and Mc-Callum, A.
(2014).
Efficient non-parametric esti-mation of multiple embeddings per word in vectorspace.
In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Process-ing (EMNLP), pages 1059?1069.
Association forComputational Linguistics.Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryigit,G., K?ubler, S., Marinov, S., and Marsi, E. (2007).Maltparser: A language-independent system fordata-driven dependency parsing.
Natural Lan-guage Engineering, 13(2):95?135.Pad?o, U.
(2007).
The integration of syntax and se-mantic plausibility in a wide-coverage model ofhuman sentence processing.
PhD thesis, SaarlandUniversity.Pad?o, U., Crocker, M. W., and Keller, F. (2009).A probabilistic model of semantic plausibil-ity in sentence processing.
Cognitive Science,33(5):794?838.Reisinger, J. and Mooney, R. J.
(2010).
Multi-prototype vector-space models of word meaning.In Human Language Technologies: The 2010 An-nual Conference of the North American Chapterof the Association for Computational Linguistics,HLT ?10, pages 109?117, Stroudsburg, PA, USA.Association for Computational Linguistics.Resnik, P. (1996).
Selectional constraints: Aninformation-theoretic model and its computa-tional realization.
Cognition, 61(1):127?159.Rooth, M., Riezler, S., Prescher, D., Carroll, G., andBeil, F. (1999).
Inducing a semantically anno-tated lexicon via em-based clustering.
In Pro-ceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics on Com-putational Linguistics, ACL ?99, pages 104?111,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Sayeed, A. and Demberg, V. (2014).
Combiningunsupervised syntactic and semantic models ofthematic fit.
In Proceedings of the first ItalianConference on Computational Linguistics (CLiC-it 2014).Thater, S., F?urstenau, H., and Pinkal, M. (2011).Word meaning in context: A simple and effec-tive vector model.
In Proceedings of 5th Inter-national Joint Conference on Natural LanguageProcessing, pages 1134?1143, Chiang Mai, Thai-land.
Asian Federation of Natural Language Pro-cessing.Vandekerckhove, B., Sandra, D., and Daelemans, W.(2009).
A robust and extensible exemplar-basedmodel of thematic fit.
In EACL 2009, 12th Con-ference of the European Chapter of the Associa-tion for Computational Linguistics, Proceedingsof the Conference, Athens, Greece, March 30 -April 3, 2009, pages 826?834.31
