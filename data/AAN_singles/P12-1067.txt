Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 638?646,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsThe Creation of a Corpus of English MetalanguageShomir Wilson*Carnegie Mellon UniversityPittsburgh, PA 15213, USAshomir@cs.cmu.eduAbstractMetalanguage is an essential linguisticmechanism which allows us to communicateexplicit information about language itself.However, it has been underexamined inresearch in language technologies, to thedetriment of the performance of systems thatcould exploit it.
This paper describes thecreation of the first tagged and delineatedcorpus of English metalanguage, accompaniedby an explicit definition and a rubric foridentifying the phenomenon in text.
Thisresource will provide a basis for further studiesof metalanguage and enable its utilization inlanguage technologies.1 IntroductionIn order to understand the language that we speak,we sometimes must refer to the language itself.Language users do this through an understandingof the use-mention distinction, as exhibited by themechanism of metalanguage: that is, language thatdescribes language.
The use-mention distinction isillustrated simply in Sentences (1) and (2) below:(1) I watch football on weekends.
(2) Football may refer to one of several sports.A reader understands that football in Sentence (1)refers to a sporting activity, while the same word inSentence (2) refers to the term football itself.Evidence suggests that human communicationfrequently employs metalanguage (Anderson et al2002), and the phenomenon is essential for manyactivities, including the introduction of new* This research was performed during a prior affiliation withthe University of Maryland at College Park.vocabulary, attribution of statements, explanationof meaning, and assignment of names (Saka 2003).Sentences (3) through (8) below further illustratethe phenomenon, highlighted in bold.
(3) This is sometimes called tough love.
(4) I wrote ?meet outside?
on the chalkboard.
(5) Has is a conjugation of the verb have.
(6) The button labeled go was illuminated.
(7) That bus, was its name 61C?
(8) Mississippi is fun to spell.Recognizing a wide variety of metalinguisticconstructions is a skill that humans take for grantedin fellow interlocutors (Perlis, Purang & Andersen1998), and it is a core language skill that childrendemonstrate at an early age (Clark & Schaefer1989).
Regardless of context, topic, or mode ofcommunication (spoken or written), we are able torefer directly to language, and we expect others torecognize and understand when we do so.The study of the syntax and semantics ofmetalanguage is well developed for formallanguages.
However, the study of the phenomenonin natural language is relatively nascent, and itsincorporation into language technologies is almostnon-existent.
Parsing the distinction is difficult, asshown in Figure 1 below: go does not function as averb in Sentence (6), but it is tagged as such.Delineating an instance of metalanguage withquotation marks is a common convention, but thisoften fails to ameliorate the parsing problem.Quotation marks, italic text, and bold text?threecommon conventions used to highlightmetalanguage?are inconsistently applied and arealready ?overloaded?
with several distinct uses.Moreover, applications of natural languageprocessing generally lack the ability to recognizeand interpret metalanguage (Anderson et al 2002).638Systems using sentiment analysis are affected, assentiment-suggestive terms appearing inmetalanguage (especially in quotation, a form ofthe phenomenon (Maier 2007)) are not necessarilyreflective of the writer or speaker.
Applications ofnatural language understanding cannot processmetalanguage without detecting it, especially whenupstream components (such as parsers) mangle itsstructure.
Interactive systems that could leverageusers?
expectations of metalanguage competencycurrently fail to do so.
Figure 2 below shows afragment of conversation with the Let?s Go!
(Rauxet al 2005) spoken dialog system, designed to helpusers plan trips on Pittsburgh?s bus system.
(ROOT(S(NP(NP (DT The) (NN button))(VP (VBN labeled)(S(VP (VB go)))))(VP (VBD was)(VP (VBN illuminated)))(.
.
)))Figure 1.
Output of the Stanford Parser (Klein &Manning 2003) for Sentence (6).
Adding quotationmarks around go alters the parser output slightly(not shown), but go remains labeled VB.Let?s Go!
: Where do you wish to departfrom?User: Arlington.Let?s Go!
: Departing from AlleghenyWest.
Is this right?User: No, I said ?Arlington?.Let?s Go!
: Please say where you areleaving from.Figure 2: A conversation with Let?s Go!
in whichthe user responds to a speech recognition error.The exchange shown in Figure 2 isrepresentative of the reactions of nearly all dialogsystems: in spite of the domain generality ofmetalanguage and the user?s expectation of itsavailability, the system does not recognize it andinstead ?talks past?
the user.
In effect, languagetechnologies that ignore metalanguage arediscarding the most direct source of linguisticinformation that text or utterances can provide.This paper describes the first substantial study tocharacterize and gather instances of Englishmetalanguage.
Section 2 presents a definition and arubric for metalanguage in the form of mentionedlanguage.
Section 3 describes the procedure usedto create the corpus and some notable properties ofits contents, and Section 4 discusses insightsgained into the phenomenon.
The remainingsections discuss the context of these results andfuture directions for this research.2 Metalanguage and the Use-MentionDistinction1Although the reader is likely to be familiar with theterms use-mention distinction and metalanguage,the topic merits further explanation to preciselyestablish the phenomenon being studied.Intuitively, the vast majority of utterances areproduced for use rather than mention, as the rolesof language-mention are auxiliary (albeitindispensible) to language use.
This paper willadopt the term mentioned language to describe theliteral, delineable phenomenon illustrated inexamples thus far.
Other forms of metalanguageoccur through deictic references to linguisticentities that do not appear in the relevant statement.
(For example, consider ?That word wasmisspelled?
where the referred-to word residesoutside of the sentence.)
For technical tractability,this study focuses on mentioned language.2.1 DefinitionAlthough the use-mention distinction has enjoyed along history of theoretical discussion, attempts toexplicitly define one or both of the distinction?sdisjuncts are difficult (or impossible) to find.Below is the definition of mentioned languageadopted by this study, followed by clarifications.Definition: For T a token or a set of tokens in asentence, if T is produced to draw attention to aproperty of the token T or the type of T, then T isan instance of mentioned language.Here, a token is the specific, situated (i.e., asappearing in the sentence) instantiation of alinguistic entity: a letter, symbol, sound, word,phrase, or another related entity.
A property might1  The definition and rubric in this section were originallyintroduced by Wilson (2011a).
For brevity, their fulljustifications and the argument for equivalence between thetwo are not reproduced here.639be a token?s spelling, pronunciation, meaning (fora variety of interpretations of meaning), structure,connotation, original source (in cases of quotation),or another aspect for which language is shown ordemonstrated.
The type of T is relevant in mostinstances of mentioned language, but the tokenitself is relevant in others, as in the sentence below:(9) ?The?
appears between quote marks here.Constructions like (9) are unusual and are oflimited practical value, but the definitionaccommodates them for completeness.The adoption of this definition was motivated bya desire to study mentioned language with precise,repeatable results.
However, it was too abstract toconsistently apply to large quantities of candidatephrases in sentences, a necessity for corpuscreation.
A brief attempt to train annotators usingthe definition was unsuccessful, and instead arubric was created for this purpose.2.2 Annotation RubricA human reader with some knowledge of the use-mention distinction can often intuit the presence ofmentioned language in a sentence.
However, tooperationalize the concept and move toward corpusconstruction, it was necessary to create a rubric forlabeling it.
The rubric is based on substitution, andit may be applied, with caveats described below, todetermine whether a linguistic entity is mentionedby the sentence in which it occurs.Rubric: Suppose X is a linguistic entity in asentence S. Construct sentence S' as follows:replace X in S with a phrase X' of the form "that[item]", where [item] is the appropriate term for Xin the context of S (e.g., "letter", "symbol", "word","name", "phrase", "sentence", etc.).
X is aninstance of mentioned language if, when assumingthat X' refers to X, the meaning of S' is equivalentto the meaning of S.To further operationalize the rubric, Figure 3shows it rewritten in pseudocode form.
To verifythe rubric, the reader can follow a positive exampleand a negative example in Figure 4.To maintain coherency, minor adjustments insentence wording will be necessary for somecandidate phrases.
For instance, Sentence (10)below must be rewritten as (11):(10) The word cat is spelled with three letters.
(11) Cat is spelled with three letters.This is because S?
for (10) and (11) arerespectively (12) and (13):(12) The word that word is spelled with threeletters.
(13) That word is spelled with three letters.Given S a sentence and X a copy of alinguistic entity in S:(1) Create X': the phrase ?that [item]?,where [item] is the appropriate termfor linguistic entity X in thecontext of S.(2) Create S': copy S and replace theoccurrence of X with X'.
(3) Create W: the set of truthconditions of S.(4) Create W': the set of truthconditions of S', assuming that X'in S' is understood to referdeictically to X.
(5) Compare W and W'.
If they are equal,X is mentioned language in S. Else,X is not mentioned language in S.Figure 3: Pseudocode equivalent of the rubric.Positive ExampleS: Spain is the name of a Europeancountry.X: Spain.
(1) X': that name(2) S': That name is the name of aEuropean country.
(3) W: Stated briefly, Spain is the nameof a European country.
(4) W': Stated briefly, Spain is thename of a European country.
(5) W and W' are equal.
Spain ismentioned language in S.Negative ExampleS: Spain is a European country.X: Spain.
(1) X': that name(2) S': That name is a European country.
(3) W: Stated briefly, Spain is aEuropean country.
(4) W': Stated briefly, the name Spainis a European country.
(5) W and W' are not equal.
Spain is notmentioned language in S.Figure 4: Examples of rubric application using thepseudocode in Figure 3.Also, quotation marks around or inside of acandidate phrase require special attention, sincetheir inclusion or exclusion in X can alter themeaning of S?.
For this discussion, quotation marks640and other stylistic cues are considered informalcues which aid a reader in detecting mentionedlanguage.
Style conventions may call for them, andin some cases they might be strictly necessary, buta competent language user possesses sufficientskill to properly discard or retain them as eachinstance requires (Saka 1998).3 The Mentioned Language Corpus?Laboratory examples?
of mentioned language(such as the examples thus far in this paper) onlybegin to illustrate the variation in the phenomenon.To conduct an empirical examination of mentionedlanguage and to study the feasibility of automaticidentification, it was necessary to gather a large,diverse set of samples.
This section describes theprocess of building a series of three progressivelymore sophisticated corpora of mentioned language.The first two were previously constructed byWilson (2010; 2011b) and will be described onlybriefly.
The third was built with insights from thefirst two, and it will be described in greater detail.This third corpus is the first to delineate mentionedlanguage: that is, it identifies precise subsequencesof words in a sentence that are subject to thephenomenon.
Doing so will enable analysis of thesyntax and semantics of English metalanguage.3.1 ApproachThe article set of English Wikipedia2 was chosen asa source for text, from which instances were minedusing a combination of automated and manualefforts.
Four factors led to its selection:1) Wikipedia is collaboratively written.
Since anyregistered user can contribute to articles,Wikipedia reflects the language habits of a largesample of English writers (Adler et al 2008).2) Stylistic cues that sometimes delimit mentionedlanguage are present in article text.Contributors tend to use quote marks, italic text,or bold text to delimit mentioned language3, thusfollowing conventions respected across manydomains of writing (Strunk & White 1979;Chicago Editorial Staff 2010; AmericanPsychological Association.
2001).
Discussion2 Described in detail athttp://en.wikipedia.org/wiki/English_Wikipedia.3 These conventions are stated in Wikipedia?s style manual,though it is unclear whether most contributors read the manualor follow the conventions out of habit.boards and other sources of informal languagewere considered, but the lack of consistent (orany) stylistic cues would have made candidatephrase collection untenably time-consuming.3) Articles are written to introduce a wide varietyof concepts to the reader.
Articles are writteninformatively and they generally assume thereader is unfamiliar with their topics, leading tofrequent instances of mentioned language.4) Wikipedia is freely available.
Various languagelearning materials were also considered, butlegal and technical obstacles made themunsuitable for creating a freely available corpus.To construct each of the three corpora, a generalprocedure was followed.
First, a set of currentarticle revisions was downloaded from Wikipedia.Then, the main bodies of article text (excludingdiscussion pages, image captions, and otherperipheral text) were scanned for sentences thatcontained instances of highlighted text (i.e., textinside of the previously mentioned stylistic cues).Since stylistic cues are also used for other languagetasks, candidate instances were heuristicallyfiltered and then annotated by human readers.3.2 Previous EffortsIn previous work, a pilot corpus was constructed toverify the fertility of Wikipedia as a source formentioned language.
From 1,000 articles, 1,339sentences that contained stylistic cues wereexamined by a human reader, and 171 were foundto contain at least one instance of mentionedlanguage.
Although this effort verified Wikipedia?sviability for the project, it also revealed that thehand-labeling procedure was time-consuming, andprior heuristic filtering would be necessary.Next, the ?Combined Cues?
corpus wasconstructed to test the combination of stylisticfiltering and a new lexical filter for selectingcandidate instances.
A set of 23 ?mention-significant?
words was gathered informally fromthe pilot corpus, consisting of nouns and verbs:Nouns: letter, meaning, name, phrase,pronunciation, sentence, sound, symbol, term, title,wordVerbs: ask, call, hear, mean, name, pronounce,refer, say, tell, title, translate, writeInstances of highlighted text were onlypromoted to the hand annotation stage if theycontained at least one of these words within thethree-word phrase directly preceding the641highlighted text.
From 3,831 articles, a set of 898sentences were found to contain 1,164 candidateinstances that passed the combination of stylisticand lexical filters.
Hand annotation of thosecandidates yielded 1,082 instances of mentionedlanguage.
Although the goal of the filters was onlyto ease hand annotation, it could be stated that thefilters had almost 93% precision in detecting thephenomenon.
It did not seem plausible that the setof mention-significant words was complete enoughto justify that high percentage, and concerns wereraised that the lexical filter was rejecting manyinstances of mentioned language.3.3 The ?Enhanced Cues?
CorpusThe construction of the present corpus (referred toas the ?Enhanced Cues?
Corpus) was similar toprevious efforts but used a much-enlarged set ofmention-significant nouns and verbs gathered fromthe WordNet (Fellbaum 1998) lexical ontology.For each of the 23 original mention-significantwords, a human reader started with its containingsynset and followed hypernym links until a synsetwas reached that did not refer to a linguistic entity.Then, backtracking one synset, all lemmas of alldescendants of the most general linguistically-relevant synset were gathered.
Figure 5 illustratesthis procedure with an example.Figure 5: Gathering mention-significant wordsfrom WordNet using the seed noun ?term?.
Here,?Language unit?, ?word?, ?syllable?, ?anagram?,and all their descendants are gathered.Using the combination of stylistic and lexicalcues, 2,393 candidate instances were collected, andthe researcher used the rubric and definition fromSection 2 to identify 629 instances of mentionedlanguage 4 .
The researcher also identified fourcategories of mentioned language based on thenature of the substitution phrase X?
specified bythe rubric.
These categories will be discussed inthe following subsection.
Figure 6 summarizes thisprocedure and the numeric outcomes.Figure 6: The procedure used to create theEnhanced Cues Corpus.3.4 Corpus CompositionAs stated previously, categories for mentionedlanguage were identified based on intuitiverelationships among the substitution phrasescreated for the rubric (e.g., ?that word?, ?that title?,?that symbol?).
The categories are:1) Words as Words (WW): Within the context ofthe sentence, the candidate phrase is used torefer to the word or phrase itself and not what itusually refers to.4 This corpus is available athttp://www.cs.cmu.edu/~shomir/um_corpus.html.xterm.n.01part.n.01word.n.01language unit.n.01 language unit.n.01word.n.01Automated masscollection of hyponymsanagram.n.01syllable.n.01629 instances of mentioned language1,764 negative instances5,000 Wikipedia articles (in HTML)Main body text of articles17,753 sentences containing25,716 instances of highlighted textArticle section filteringand sentence tokenizerStylistic cue filter andheuristicsHuman annotator1,914 sentences containing2,393 candidate instancesMention word proximityfilter100 instances labeled by threeadditional human annotatorsRandom selectionprocedure for100 instances23 hand selectedmention words8,735 mentionwords andco-locationsWordNetcrawlManual search forrelevant hypernyms6422) Names as Names (NN): The sentence directlyrefers to the candidate phrase as a proper name,nickname, or title.3) Spelling or Pronunciation (SP): The candidatetext appears only to illustrate spelling,pronunciation, or a character symbol.4) Other Mention/Interesting (OM): The candidatephrase is an instance of mentioned language thatdoes not fit the above three categories.5) Not Mention (XX): The candidate phrase is notmentioned language.Table 1 presents the frequencies of each categoryin the Enhanced Cues corpus, and Table 2 providesexamples for each from the corpus.
WW was byfar the most common label to appear, which isperhaps an artifact of the use of Wikipedia as thetext source.
Although Wikipedia articles containmany names, NN was not as common, andinformal observations suggested that names andtitles are not as frequently introduced viametalanguage.
Instead, their referents areintroduced directly by the first appearance of thereferring text.
Spelling and pronunciation wereparticularly sparse; again, a different source mighthave yielded more examples for this category.
TheOM category was occupied mostly by instances ofspeech or language production by an agent, asillustrated by the two OM examples in Table 2.Category Code FrequencyWords as Words WW 438Names as Names NN 117Spelling or Pronunciation SP 48Other Mention/Interesting OM 26Not Mention XX 1,764Table 1: The by-category composition of candidateinstances in the Enhanced Cues corpus.In the interest of revealing both lexical andsyntactic cues for mentioned language, part-of-speech tags were computed (using NLTK (Loper& Bird 2002)) for words in all of the sentencescontaining candidate instances.
Tables 3 and 4 listthe ten most common words (as POS-tagged) inthe three-word phrases before and after(respectively) candidate instances.
Although theheuristics for collecting candidate instances werenot intended to function as a classifier, figures forprecision are shown for each word: these representthe percentage of occurrences of the word whichwere associated with candidates identified asmentioned language.
For example, 80% ofappearances of the verb call preceded a candidateinstance that was labeled as mentioned language.Code ExampleWW The IP Multimedia Subsystem architectureuses the term transport plane to describe afunction roughly equivalent to the routingcontrol plane.The material was a heavy canvas known asduck, and the brothers began making workpants and shirts out of the strong material.NN Digeri is the name of a Thracian tribementioned by Pliny the Elder, in TheNatural History.Hazrat Syed Jalaluddin Bukhari'sdescendants are also called Naqvi al-Bukhari.SP The French changed the spelling tobataillon, whereupon it directly enteredinto German.Welles insisted on pronouncing the wordapostles with a hard t.OM He kneels over Fil, and seeing that hiseyes are open whispers: brother.During Christmas 1941, she typed The endon the last page of Laura.XX NCR was the first U.S. publication towrite about the clergy sex abuse scandal.Many Croats reacted by expelling allwords in the Croatian language that had, intheir minds, even distant Serbian origin.Table 2: Two examples from the corpus for eachcategory.
Candidate phrases appear underlined,with the original stylistic cues removed.Many of these words appeared as mention wordsfor the Combined Cues corpus, indicating thatprior intuitions about framing metalanguage werecorrect.
In particular, call (v), word(n), and term (n)were exceptionally frequent and effective atassociating  with mentioned language.
In contrast,the distribution of frequencies for the wordsfollowing candidate instances exhibited a ?longtail?, indicating greater variation in vocabulary.643Rank Word Freq.
Precision (%)1 call (v) 92 802 word (n) 68 95.83 term (n) 60 95.24 name (n) 31 67.45 use (v) 17 70.86 know (v) 15 88.27 also (rb) 13 59.18 name (v) 11 1009 sometimes (rb) 9 81.910 Latin (n) 9 69.2Table 3: The top ten words appearing in the three-word sequences before candidate instances, withprecisions of association with mentioned language.Rank Word Freq.
Precision (%)1 mean (v) 31 83.42 name (n) 24 63.23 use (v) 11 554 meaning (n) 8 57.15 derive (v) 8 806 refers (n) 7 87.57 describe (v) 6 608 refer (v) 6 54.59 word (n) 6 5010 may (md) 5 62.5Table 4: The top ten words appearing in the three-word sequences after candidate instances, withprecisions of association with mentioned language.3.5 Reliability and Consistency of AnnotationTo provide some indication of the reliability andconsistency of the Enhanced Cues Corpus, threeadditional expert annotators were recruited to labela subset of the candidate instances.
Theseadditional annotators received guidelines forannotation that included the five categories, andthey worked separately (from each other and fromthe primary annotator) to label 100 instancesselected randomly with quotas for each category.Calculations first were performed to determinethe level of agreement on the mere presence ofmentioned language, by mapping labels WW, NN,SP, and OM to true and XX to false.
All fourannotators agreed upon a true label for 46instances and a false label for 30 instances, with anaverage pairwise Kappa (computed via NTLK) of0.74.
Kappa between the primary annotator and ahypothetical ?majority voter?
of the threeadditional annotators was 0.90.
These results weretaken as moderate indication of the reliability of?simple?
use-mention labeling.However, the per-category results showedreduced levels of agreement.
Kappa was calculatedto be 0.61 for the original coding.
Table 5 showsthe Kappa statistic for binary re-mapping for eachof the categories.
This was done similarly to the?XX versus all others?
procedure described above.Code Frequency KWW 17 0.38NN 17 0.72SP 16 0.66OM 4 0.09XX 46 0.74Table 5: Frequencies of each category in the subsetlabeled by additional annotators and the values ofthe Kappa statistic for binary relabelings.The low value for remapped OM was expected,since the category was small and intentionally notwell-defined.
The relatively low value for WWwas not expected, though it seems possible that theredaction of specific stylistic cues made annotatorsless certain when to apply this category.
Overall,these numbers suggest that, although annotatorstend to agree whether a candidate instance ismentioned language or not, there is less of aconsensus on how to qualify positive instances.4 DiscussionThe Enhanced Cues corpus confirms some of thehypothesized properties of metalanguage andyields some unexpected insights.
Stylistic cuesappear to be strongly associated with mentionedlanguage; although the examination of candidatephrases was limited to ?highlighted?
text, informalperusal of the remainder of article text confirmedthis association.
Further evidence can be seen inexamples from other texts, shown below with theiroriginal stylistic cues intact:?
Like so many words, the meaning of ?addiction?has varied wildly over time, but the trajectorymight surprise you.55 News article from CNN.com:http://www.cnn.com/2011/LIVING/03/23/addicted.to.addiction/index.html644?
Sending a signal in this way is called a speechact.6?
M1 and M2 are Slashdot shorthand for?moderation?
and ?metamoderation,?respectively.7?
He could explain foreordination thoroughly, andhe used the terms ?baptize?
and ?Athanasian.?8?
They use Kabuki precisely because they andeveryone else have only a hazy idea of theword?s true meaning, and they can use it purelyon the level of insinuation.9However, the connection between mentionedlanguage and stylistic cues is only valuable whenstylistic cues are available.
Still, even in theirabsence there appears to be an association betweenmentioned language and a core set of nouns andverbs.
Recurring patterns were observed in howmention-significant words related to mentionedlanguage.
Two were particularly common:?
Noun apposition between a mention-significantnoun and mentioned language.
An example ofthis appears in Sentence (5), consisting of thenoun verb and the mentioned word have.?
Mentioned language appearing in appropriatesemantic roles for mention-significant verbs.Sentence (3) illustrates this, with the verb callassigning the label tough love as an attribute ofthe sentence subject.With further study, it should be possible to exploitthese relationships to automatically detectmentioned language in text.5 Related WorkThe use-mention distinction has enjoyed a longhistory of chiefly theoretical discussion.
Beyondthose authors already cited, many others haveaddressed it as the formal topic of quotation(Davidson 1979; Cappelen & Lepore 1997; Garc?a-Carpintero 2004; Partee 1973; Quine 1940; Tarski1933).
Nearly all of these studies have eschewedempirical treatments, instead hand-pickingillustrations of the phenomenon.6 Page 684 of Russell and Norvig?s 1995 edition of ArtificialIntelligence, a textbook.7 Frequently Asked Questions (FAQ) list on Slashdot.org:http://slashdot.org/faq/metamod.shtml8 Novel Elmer Gantry by Sinclair Lewis.9 Opinion column on Slate.com:http://www.slate.com/id/2250081/One notable exception was a study by Andersonet al (2004), who created a corpus ofmetalanguage from a subset of the British NationalCorpus, finding that approximately 11% of spokenutterances contained some form (whether explicitor implicit) of metalanguage.
However, limitationsin the Anderson corpus?
structure (particularly lackof word- or phrase-level annotations) and content(the authors admit it is noisy) served as compellingreasons to start afresh and create a richer resource.6 Future WorkAs explained in the introduction, the long-termgoal of this research program is to apply anunderstanding of metalanguage to enhancelanguage technologies.
However, the moreimmediate goal for creating this corpus was toenable (and to begin) progress in research onmetalanguage.
Between these long-term andimmediate goals lies an intermediate step: methodsmust be developed to detect and delineatemetalanguage automatically.Using the Enhanced Cues Corpus, a two-stageapproach to automatic identification of mentionedlanguage is being developed.
The first stage isdetection, the determination of whether a sentencecontains an instance of mentioned language.Preliminary results indicate that approximately70% of instances can be detected using simplemachine learning methods (e.g., bag of words inputto a decision tree).
The remaining instances willrequire more advanced methods to detect, such asword sense disambiguation to validate occurrencesof mention-significant words.
The second stage isdelineation, the determination of the subsequenceof words in a sentence that functions as mentionedlanguage.
Early efforts have focused on theassociations discussed in Section 5 betweenmentioned language and mention-significant words.The total number of such associations appears tobe small, making their collection a tractableactivity.AcknowledgementsThe author would like to thank Don Perlis andScott Fults for valuable input.
This research wassupported in part by NSF (under grant#IIS0803739), AFOSR (#FA95500910144), andONR (#N000140910328).645ReferencesAdler, B. Thomas, Luca de Alfaro, Ian Pye &Vishwanath Raman.
2008.
Measuring authorcontributions to the Wikipedia.
In Proc.
of WikiSym'08.
New York, NY, USA: ACM.American Psychological Association.
2001.
PublicationManual of the American Psychological Association.5th ed.
Washington,  DC: American PsychologicalAssociation.Anderson, Michael L, Yoshi A Okamoto, DarsanaJosyula & Donald Perlis.
2002.
The use-mentiondistinction and its importance to HCI.
In Proc.
ofEDILOG 2002.
21?28.Anderson, Michael L., Andrew Fister, Bryant Lee &Danny Wang.
2004.
On the frequency and types ofmeta-language in conversation: A preliminary report.In Proc.
of the 14th Annual Conference of the Societyfor Text & Discourse.Cappelen, H & E Lepore.
1997.
Varieties of quotation.Mind 106(423).
429 ?450.Chicago Editorial Staff.
2010.
The Chicago Manual ofStyle.
16th ed.
University of Chicago Press.Clark, Herbert H. & Edward F. Schaefer.
1989.Contributing to discourse.
Cognitive Science 13(2).259?294.Davidson, Donald.
1979.
Quotation.
Theory andDecision 11(1).
27?40.Fellbaum, Christiane.
1998.
WordNet: An ElectronicLexical Database.
Cambridge: MIT Press.Garc?a-Carpintero, Manuel.
2004.
The deferredostension theory of quotation.
No?s 38(4).
674?692.Klein, Dan & Christopher D. Manning.
2003.
Fast exactinference with a factored model for natural languageparsing.
Advances in Neural Information ProcessingSystems 15.Loper, Edward & Steven Bird.
2002.
NLTK: TheNatural Language Toolkit.
In Proceedings of theACL-02 Workshop on Effective Tools andMethodologies for Teaching Natural LanguageProcessing and Computational Linguistics 1.
63?70.Association for Computational Linguistics.Maier, Emar.
2007.
Mixed quotation: Between use andmention.
In Proc.
of LENLS 2007.Partee, Barbara.
1973.
The syntax and semantics ofquotation.
In Stephen Anderson & Paul Kiparsky(eds.
), A Festschrift for Morris Halle.
New York:Holt, Rinehart, Winston.Perlis, Donald, Khemdut Purang & Carl Andersen.1998.
Conversational adequacy: Mistakes are theessence.
International Journal of Human-ComputerStudies 48(5).
553?575.Quine, W. V. O.
1940.
Mathematical Logic.
Cambridge,MA: Harvard University Press.Raux, Antoine, Brian Langner, Dan Bohus, Alan WBlack & Maxine Eskenazi.
2005.
Let?s Go public!Taking a spoken dialog system to the real world.
InProc.
of Interspeech 2005.Saka, Paul.
1998.
Quotation and the use-mentiondistinction.
Mind 107(425).
113 ?135.Saka, Paul.
2003.
Quotational constructions.
BelgianJournal of Linguistics 17(1).Strunk, Jr. & E. B.
White.
1979.
The Elements of Style,Third Edition.
Macmillan.Tarski, Alfred.
1933.
The concept of truth in formalizedlanguages.
In J. H. Woodger (ed.
), Logic, Semantics,Mathematics.
Oxford: Oxford University Press.Wilson, Shomir.
2010.
Distinguishing use and mentionin natural language.
In Proc.
of the NAACL HLT2010 Student Research Workshop, 29?33.Association for Computational Linguistics.Wilson, Shomir.
2011a.
A Computational Theory of theUse-Mention Distinction in Natural Language.
Ph.D.dissertation, University of Maryland at College Park.Wilson, Shomir.
2011b.
In search of the use-mentiondistinction and its impact on language processingtasks.
International Journal of ComputationalLinguistics and Applications 2(1-2).
139?154.646
