ACL Lifetime Achievement AwardThe Dawn of Statistical ASR and MTFrederick Jelinek?Johns Hopkins UniversityI am very grateful for the award you have bestowed on me.
To understand yourgenerosity I have to assume that you are honoring the leadership of three innovativegroups that I headed in the last 47 years: at Cornell, IBM, and now at Johns Hopkins.You know my co-workers in the last two teams.
The Cornell group was in InformationTheory and included Toby Berger, Terrence Fine, and Neil J.
A. Sloane (earlier my Ph.D.student), all of whom earned their own laurels.I was told that I should give an acceptance speech and was furnished with exampletexts by previous recipients.
They wrote about the development and impact of theirideas.
So I will tell you about my beginnings and motivations and then focus on thecontributions of my IBM team.
In this way the text will have some historical value andmay clear up certain widely held misconceptions.1.
BeginningsInformation Theory seemed to be one of the most prestigious disciplines during myyears as a student at MIT (1954?1962).
The faculty included the founders of the field?Shannon, Fano, Elias, and others.
Some of my contemporaries were Viterbi, Jacobs,Kleinrock (founders of Qualcom), Gallagher, Kailath, and Massey.
Not daring to ap-proach Shannon himself, I asked Professor Fano to be my thesis adviser.
I was makingslow progress when in 1961, after three years of trying, I succeeded in extricating myfuture wife Milena from communist Czechoslovakia (how this was accomplished isanother story) and married her.
One problem we needed to solve was how she shouldoccupy herself during the long hours I was spending in the underground stacks of theMIT library.
At the time the famous linguist Roman Jacobson was simultaneously aUniversity Professor at Harvard and an Institute Professor at MIT.
Russian by origin,he spent 18 inter-war years (1920?1938) in Czechoslovakia, where he became one ofthe founders of the Prague Linguistic Circle.
He had a Czech wife, the anthropologistSvatava Pirkova.
He continued to maintain his connections with Czechs, and evenyoung Czechs.
I was invited to dinner at his house several times, once also with thenewly arrived Milena.
Jacobson was well known to have an eye for beautiful youngwomen and he was reputed to enjoy exercising his influence.
When my wife asked himfor advice as to what to do, he suggested that she take up a fellowship at MIT which hewould arrange for her to get.
As promised, she got the fellowship and enrolled in thePh.D.
program of the Linguistics department.
It should be appreciated that Jacobsondid not interview her in a non-social setting and was aware that her previous schooling?
Center for Language and Speech Processing, Johns Hopkins University, 320 Barton Hall, 3400 N. CharlesStreet, Baltimore, MD 21218, USA.
E-mail: jelinek@jhu.edu.
This article is the text of the talk given onreceipt of the ACL?s Lifetime Achievement Award in 2009.?
2009 Association for Computational LinguisticsComputational Linguistics Volume 35, Number 4in Prague consisted only of one year of Slavic studies followed by two years at the FilmAcademy.So Milena started attending lectures, several of them taught by Noam Chomsky.
Isat in with her and got the crazy notion that I should switch from Information Theory toLinguistics.
I went so far as to explore this notion with Professor Chomsky.
Of course,word got around to my adviser Fano, whom it really upset.
He declared that I couldcontemplate switching only after I had received my doctorate in Information Theory.
Ihad no choice other than to obey.
Soon thereafter, my thesis almost finished, I startedinterviewing at universities for a faculty position.
After my job talk at Cornell I wasapproached by the eminent linguist Charles Hockett, who said that he hoped that Iwould accept the Cornell offer and help develop his ideas on how to apply InformationTheory to Linguistics.
That decided me.
Surprisingly, when I took up my post in the fallof 1962, there was no sign of Hockett.
After several months I summoned my courageand went to ask him when he wanted to start working with me.
He answered that hewas no longer interested, that he now concentrated on composing operas.Discouraged a second time, I devoted the next ten years to Information Theory.
Thiswas the golden period of government support for science and technology.
It seemedeasy to get grants.
Perhaps that was the reason I neglected to make any arrangementsfor work during the coming summer of 1972.
I phoned Joe Raviv (whom I knew as acolleague from my sabbatical at IBM in 1968?69) to ask if I could spend three months inhis group in Yorktown Heights.
His answer was ?Certainly, the sooner you arrive thebetter.
We are starting to work on speech recognition.
?By the time I arrived to take up that summer job, Raviv was promoted to managerof the IBM Scientific Center in Haifa, and IBM was negotiating with Professor JonathanAllen of MIT to take over the speech group.
These negotiations were not successful, andseveral weeks later the job was offered to me.
I requested Cornell to grant me a leave ofabsence; they did, and I joined IBM (the following year I asked for and got another year,but when I tried to carry out the same maneuver in 1974, I was turned down).Why did IBM start research in speech recognition?
Believe it or not, IBM wasworried that, with the advance of computing power, there might soon come a timewhen all the need for further improvements would disappear, and IBM business woulddry up.
Somebody came up with the suggestion that speech recognition would requirelots of computing cycles.
A task force was put together in 1971 to study the matter.The group included John Cocke (inventor of RISC machines), Herman Goldstine (righthand of von Neumann in research leading to ENIAC) and others.
It recommended thata Continuous Speech Recognition group be established in the Research Division.So the CSR group was started in early 1972 under the management of Joe Raviv.At the time IBM had a small speech group in one of its development laboratories inRaleigh, NC.
(Actually, IBM ?had?
speech recognition even earlier.
At the 1964 World?sFair in New York, Ernest Nassimbene demonstrated an isolated digits recognizer ?ina shoe box.?)
Its three main members, Das, Dixon, and Tappert, were transferred fromRaleigh to the Research Division in Yorktown.
High management concluded that to getgoing the speech group would need the help of linguists.
It transferred temporarilyFred Damerau, Stan Petrick, and Jane Robinson from linguistics to CSR.
The staffing ofthe group was then completed by volunteers from the Computer Sciences Department:Lalit Bahl, Raimo Bakis, George Nagy, and others (later Jim and Janet Baker joined aswell).
But at the time only Bakis, Das, Dixon, and Tappert knew anything about speech.Towards the end of the summer I took over the direction of the group and received a giftfrom heaven: the freshly graduated physicist Robert Mercer, who in the spring acceptedan IBM job in a group that was abolished before he arrived in September.484Jelinek The Dawn of Statistical ASR and MTTable 1Sentences from the Resource Management language.Show locations and C-ratings for all deployed subs that were in their home ports April 5.List the cruisers in Persian Sea that have casualty reports earlier than Jarrett?s oldest one.How many ships were in Galveston May 3rd?Is Puffer?s remaining fuel sufficient to arrive in port at the present speed?How many long tuns is the average displacement of ships in Bering Strait?2.
The CompetitionIn 1971, parallel to the work of the IBM task force, ARPA established a project in SpeechUnderstanding.
I don?t know what led to that decision, but the main forces behind itwere Allen Newell and J. C. R. Licklinder.
Funds were provided to Carnegie Mellon,Systems Development Corporation, Bolt Beranek & Newman, and probably SRI,Sperry-Univac, University of Pennsylvania, UC Berkeley, and UCLA.
Not all of theseinstitutions were to field complete systems.
For instance, Ohio, UCLA, and Berkeleyprovided consulting by linguists (Peter Ladefoged, Vicky Fromkin, John Ohala, MichaelO?Malley, and June Shoup).Here are the names of some other researchers who attended the meetings organizedby the new project: Raj Reddy, Dennis Klatt, L. D. Erman, V. Lesser, Bruce Lowerry,Bonnie Nash-Webber, George White, Fil Alleva, Wayne Ward, Don Walker, Victor Zue,Stephanie Sennef, Bill Woods, John Makhoul, Wayne Lea, Beatrice Oshika, and Janetand Jim Baker.
IBM was invited to attend the meetings, but we did not compete.
ARPAwas a six-year project which was supposed to recognize (and interpret?)
sentences froma ?Resource Management?
grammar; for an example of the sentences generated, seeTable 1.
At the end of the six-year period the project was declared a success because it?met its goals.
?Clearly the best of the constructed recognizers was the Dragon System (Baker 1975)implemented by the Bakers, graduate students at CMU.
It used Hidden Markov models(HMMs) whereas the rest of the ARPA participants based their work on templates,Dynamic Time Warping (DTW), and hand-written rules.
The best of these latter systemswas Harpy, developed by another CMU graduate student, Bruce Lowerry.3.
IBM?s Initial FormulationFor our first task we decided to recognize sentences generated by the so-called NewRaleigh grammar, a finite?state device whose schematic is shown in Figure 1.
Thegrammar is actually a Hidden Markov Model.
State transitions generate words andare taken with uniform probability.
Generation starts in the initial state, a transition istaken, and a word from the list associated with that transition is selected with uniformprobability; then one of the transitions out of the new state is taken (again with uniformprobability), a word corresponding to that transition is again selected at random, a newstate is reached, and so on.
The process continues until one arrives at the final state.
Thegrammar generates such bizarre sentences as are shown in Table 2.11 Note that, from a syntactic point of view, all the sentences generated are structurally English, eventhough the vast majority make no sense.485Computational Linguistics Volume 35, Number 4Figure1TheNewRaleighgrammar.486Jelinek The Dawn of Statistical ASR and MTTable 2Sentences generated by the New Raleigh grammar.Each distant town disturbed the telephone during the purpose.Some matters survive never between those systems.Should important grounds be the radio over the concern?Some matters rejected the radio during the capitol.One recognition condition proposes only across those engineers.Figure 2Schematic of statistical speech recognition.The generated sentences were read (as naturally as possible) by native Americanspeakers and were recorded in a special sound-proofed room.
The recorded speechsignal was transformed into a string A of symbols (one symbol per centisecond)chosen from an ?alphabet?
A of size 200.
The alphabet A itself was extracted by vectorquantization from a training sample of the speech signal.Our formulation of the combined generation/recognition process is seen in Fig-ure 2.
The entire operation can be regarded as transmission through a noisy channel,the basic problem of Information Theory.2 Its corresponding mathematical formula is?W = arg maxW?SP(W|A) = arg maxW?SP(A|W)P(W)where W denotes a string of words, A denotes the acoustic signal observed by therecognizer, and S is the set of sentences that can be generated by the grammar.
Theformula calls for a statistical approach.
The noisy channel of Figure 2 has input W andoutput A and is characterized by the probability P(A|W).
The designer of the recognizermust attempt to estimate the channel probabilities P(A|W) and the a priori probabilityP(W) that the speaker will utter the word string W. Once the models ?P(A|W) and ?P(W)32 No wonder that we immediately hit upon the diagram: Both Lalit Bahl and I wrote Information TheoreticPh.D.
theses.3 ?P(A|W) is called the acoustic model and ?P(W) is called the language model.
Both these terms, now usedthroughout the field, were ?invented?
at IBM, as was the term perplexity, denoting an InformationTheoretic measure of the difficulty of the recognition task.487Computational Linguistics Volume 35, Number 4are established, the recognizer when it observes A can conduct a search leading to themaximizing word string ?W.In the case of an artificial grammar, such as the New Raleigh grammar, the model?P(W) is in fact equal to the actual probability P(W).
Furthermore, because the set S ofword strings W over which we maximize can be listed, the difficulty of the task canbe measured approximately (because the acoustic similarity of words is not taken intoaccount) by entropy:H(W)  ?
?WSP(W) log P(W)However, because the participants in the ARPA project introduced the false measure?branching factor?
(which was the arithmetic mean of the out-of-state branching oftheir finite?state grammar), we replaced H(W) as a measure of difficulty by perplexity,defined byPP  2H(W)It turned out that the New Raleigh grammar had approximate perplexity 7 whereas theResource Management grammar had 2.The early IBM approach was described in three papers: Jelinek, Bahl, and Mercer(1975), Bahl and Jelinek (1975), and Jelinek (1976).4.
The TangoraIn 1978 (or so), we thought it was time to abandon artificial grammars and to startrecognizing ?natural?
speech.
We settled on a 5,000-word vocabulary and set ourselvesthe task of recognizing read sentences from an IBM internal correspondence corpus.Our ambition was to use a combination of IBM array processors to achieve essentiallyreal-time performance.
We fulfilled a promise to the management to achieve it by 1984.To make things easier on ourselves we limited the recognizer to the transcription ofdiscrete speech, where sentences were spoken with pauses between words.
We got ridof the sound room and recorded the readings on close-talking microphones.
The systemwas to be speaker-sensitive, that is, acoustic models were trained for each individualreader separately.It is worth noting that during this time we persuaded the IBM management to hireJim and Janet Baker, who were not to receive their Ph.D.s from Carnegie Mellon untila year later.
At the same time, ?our?
three linguist helpers returned to their originalgroup.When handling natural speech, the main question was how to estimate the languagemodel ?P(W).
There was no simple way of achieving this.
We thought that the rightapproach ought to be somehow related to English grammar.
The linguist Stan Petrick,while he still was with us, said ?Don?t worry, I will just make a little grammar.?
Ofcourse he never did, and the phrase acquired a mythical status in the manner of ?famouslast words.
?488Jelinek The Dawn of Statistical ASR and MTSo at John Cocke?s suggestion we decided to model English by trigrams.
That is, weused the approximation?P(W) = P(w1,w2,w3...wk) ?
?P(w1,w2) ?P(w3|w1,w2) ?P(w4|w2,w3)....?P(wk|wk?2,wk?1)But this decision did not dispose of the problem.
How should we estimate the basicbuilding blocks P(wk|wk?2,wk?1)?
It was clear that the estimate would have to be basedon trigram counts C(wk?2,wk?1,wk) assembled from some appropriate text (the one thatprovided us with the read speech).
But relative frequenciesf (wk|wk?2,wk?1) C(wk?2,wk?1,wk)C(wk?2,wk?1)would not suffice.
Indeed, the speech would frequently involve trigrams wk?2,wk?1,wkwhose count C(wk?2,wk?1,wk) in the training corpus equalled 0.
Then if wk?2,wk?1,wkwere uttered by the speaker (reader), the recognizer would necessarily make anerror.
What was required was smoothing, and the type we chose at first was linearinterpolation:?P(wk|wk?2,wk?1) = ?3 f (wk|wk?2,wk?1) + ?2 f (wk|wk?1) + ?1 f (wk)where ?
?j s would be non-negative, would satisfy ?3 + ?2 + ?1 = 1, and would beoptimally chosen (we knew how).Just as in the initial phase of IBM CSR research, the acoustics A input to therecognizer were a string of centisecond symbols chosen from an alphabet A whichitself was derived by vector quantization.
This discretization of speech allowed for aneasier estimate of parameters defining the acoustic processor model ?P(A|W).
The latterwas implemented as a concatenation of HMMs, one for each word of the string W.An example of such an HMM (itself a concatenation of HMMs as prescribed by thepronunciation lexicon) is shown in Figure 3.Having defined the signal processing leading to the string A, and the structures ofthe acoustic and language models ?P(A|W) and ?P(W), it remains to discuss the searchfor the recognizer output ?W implicit in the formula?W = arg maxW?P(A|W) ?P(W)Figure 3HMM for the word v realized by phone sequence ?1?2 ?
?
?
?lv .489Computational Linguistics Volume 35, Number 4We used the appropriately modified Viterbi algorithm version of dynamic program-ming (Viterbi 1967), a decision we took in spite of the fact that the algorithm wouldcarry out a sub-optimal search.We called the system Tangora after Albert Tangora who, during a 1923 businessshow in New York, ran off a total of 8,840 correctly spelled words in one hour ofnonstop typing, a rate of 147 words per minute.
Incredibly, it was estimated that Tangoraexecuted an average of twelve-and-a-half strokes per second!5.
Some ASR FirstsDuring my time at IBM, my colleagues and I pioneered various techniques that werelater taken over by the entire field.
Here are some examples: We replaced the discrete signal processing leading to A by directlymodeling the real input as a mixture of Gaussians.
Also, the resultingHMM now generated outputs from states instead of from transitions. We introduced pronunciation modeling by triphones, thereby modelingphones as influenced by context.
That is, in our pronunciation lexicon eachword was first transformed into a string of symbols roughlycorresponding to phones.
The HMM model of a word then became aconcatenation of triphone models.
Here is an example:table =?
T EI B L =?
# T EI T EI B EI B L B L # The phone alphabet was of the order of 50.
That would necessitate503 = 125, 000 models (one for each triphone), an intolerable number touse and/or estimate parameters for.
To reduce this number meantcategorizing the context into equivalence classes.
This was accomplishedby clustering carried out by decision trees. We tried to move from the simple trigram language model to a moresophisticated one.
Slava Katz designed a back-off model (Katz 1987)relying on Good-Turing probability estimation.
It was an improvementwhich moved the state of the art forward, but it was later superseded byKneser-Ney smoothing.
Because language modeling is a search forequivalence classification, we tried several methods based on decisiontrees.
These were an improvement, but the attendant complication inimplementation was not deemed justified, particularly now that enormousamounts of text are available from the Internet. Aware that a Viterbi search for the maximizing word string ?W is notoptimal, Lalit Bahl developed a multi-stack search algorithm inspired bythe stack algorithm of Information Theory (Jelinek 1969).
The procedurewas later formalized and cleaned up by Doug Paul of Lincoln Laboratories(Paul 1992).
The multi-stack algorithm required the invention of a FastAcoustic Match which suggested word candidates for detailedexamination on the basis of a parallel, crude acoustic-fit test. Many problems of probability estimation involve simultaneousconsideration of influence by disparate phenomena.
We found thatMaximum Entropy estimation is a method suitable for treating the490Jelinek The Dawn of Statistical ASR and MTsituation.
This method facilitated the development by the summer internRonnie Rosenfeld of a Trigger Language Model that allowed the discoursetopic to influence word prediction (Rosenfeld 1996). It was hoped that language modeling could be strengthened by includingconsideration of the parts-of-speech of words preceding the prediction.This unfortunately did not turn out to be the case.
Nevertheless, Bahl andMercer pioneered a method of part-of-speech tagging by HMM (Bahl andMercer 1976) that is now widely used in various applications of NaturalLanguage Processing.6.
IBM Influence on the Speech and Language FieldThe success of the statistical formulation of the speech recognition problem led toinvitations to share our methods with a wider audience.
We presented several coursesteaching our data-centric approach.
In 1980 we gave a course in Udine, Italy, organizedby CISM (International Centre for Mechanical Sciences); in 1983 a two-week courseat MIT; and finally in 1986 a course in Oberlech, Austria, organized by IBM ScientificCenters.
Furthermore, I was invited to give a keynote speech at the 1990 ACL Meetingin Pittsburgh, PA.We were not satisfied with the crude n-gram language model we were using andwere ?sure?
that an appropriate grammatical approach would be better.
Because wewanted to stick to our data-centric philosophy, we thought that what was needed astraining material was a large collection of parses of English sentences.
We found outthat researchers at the University of Lancaster had hand-constructed a ?treebank?under the guidance of Professors Geoff Leach and Geoff Sampson (Garside, Leech,and Sampson 1987).
Because we wanted more of this annotation, we commissionedLancaster in 1987 to create a treebank for us.
Our view was that what we neededabove all was quantity, possibly at some expense of quality: We wanted to extract thegrammatical language model statistically and so a large amount of data was required.Another belief of ours was that the parse annotation should be carried out by intelligentnative speakers of English, not by linguistic experts, and that any inaccuracies wouldnaturally cancel each other.
Indeed, the work was done by Lancaster housewives ledby a high school drop-out.Meanwhile, Geoff Leech set out to assemble the British National Corpus and wethought that the United States should have something like that as well.
So in 1987I arranged to visit Jack Schwartz, who was the boss of Charles Wayne at DARPA,and I explained to him what was needed and why.
He immediately entrusted Charleswith the creation of the appropriate organization.
One of the problems was where theeventual corpus should reside.
Deep-pocketed IBM would be unsuitable: Possessors ofdesirable corpora would charge immoderate sums for the acquisition of rights.
I thoughtthat only a university would do.
So I inquired of Aravind Joshi and Mitch Marcus (andperhaps even Mark Liberman) at the 1988 Conference of Applied Natural LanguageProcessing in Austin whether the required site could be the University of Pennsylvania.My colleagues were interested, and Charles Wayne invited appropriate people to ameeting at the Lake Mohunk Mountain House to discuss the matter.
That is how theLinguistic Data Consortium was born.Once the commissioned treebank was delivered, we started to experiment withparsers.
Jointly with the University of Pennsylvania we applied for and received an491Computational Linguistics Volume 35, Number 4Figure 4Schematic of statistical machine translation.NSF grant for grammatical development.
The eventual result was SPATTER, imple-mented by David Magerman.
It used statistics, decision trees, and a history-basedoperation.
The University of Pennsylvania graduate student Eric Brill developed histransformation-based learning (Brill 1992) that he applied to part-of-speech taggingand grammar derivation.
Ezra Black of IBM organized a committee whose aim wasthe specification of a metric suitable for evaluation of parser performance.
The resultwas the PARSEVAL measure.7.
Machine TranslationEven though the problem of speech recognition remains unsolved to this day, someof us started to wonder in the mid 1980s whether our ASR methods could be success-fully applied to new fields.
Bob Mercer and I spent many of our after-lunch ?periphery?walks discussing possible candidates.
We soon came up with two: machine transla-tion and stock market modeling.
It is probably only coincidence that Bob eventuallyended up investigating the possibilities of stock value prediction.
Indeed, he and PeterBrown departed IBM in 1993 to work for the phenomenally successful hedge fundRenaissance Technologies.
Eventually at least 10 former members of the IBM CSR groupwere to be employed by that same company.
The performance of the Renaissance fundis legendary, but I have no idea whether any methods we pioneered at IBM haveever been used.
My former colleagues will not tell me: Theirs is a very hush-hushoperation!On the other hand, we did start working on machine translation (MT) in 1987.
Asexpected, we formulated the problem statistically.
The basic diagram of MT, shownin Figure 4, is practically identical to that of ASR.
In fact, even the basic formulas areidentical except for a change in the letters that designate the variables:?E = arg maxEP(F|E)P(E)This formula assumes translation from the foreign language4 F into English E. Theformulation pretends that the speaker?s mind works in English, the generated textis then translated by him into the foreign language F, and the task of the machinetranslator is to ferret out the speaker?s original thought ?E.That we wanted to translate into English was a given?not because of the utilityof the task, but because our knowledge of English would allow us to judge the quality4 Originally F stood for French.492Jelinek The Dawn of Statistical ASR and MTof the translation.
We wanted to make the problem real, yet as easy as possible.
So welooked for a language F that was relatively close to English.
The answer was French.Because we wanted the process to be data-centric, we searched for a pair of corpora Fand E that would be translations of each other.
Luck was with us: The Canadian par-liament Hansards (proceedings) were maintained in English and French.5 So statisticallanguage translation was born (Brown et al 1990), and the descendants of our originalmethods are being continually improved.When we started, none of us spoke French, so we decided to learn it.
We uncovereda small institute whose location was opposite New York Grand Central Station on42nd Street.
The institute advertised that it would teach French to anybody in two (!
)weeks of intensive immersion.
We didn?t believe it, of course, but because the costs andlocation were convenient, we started on our daily commute.
I will not go into the semi-fraudulent aspects of the operation, but Lalit Bahl, Peter Brown, Bob Mercer, and I hada lot of fun and did advance considerably our knowledge of French.When we had our first results we submitted them to Coling 1988.
Here is a part ofthe rejection review we received:The validity of a statistical (information theoretic) approach to MT has indeed beenrecognized, as the authors mention, by Weaver as early as 1949.
And was universallyrecognized as mistaken by 1950 (cf.
Hutchins, MT ?
Past, Present, Future, EllisHorwood, 1986, p. 30ff and references therein).
The crude force of computers is notscience.
The paper is simply beyond the scope of COLING.Anonymous Coling review, 1 March 19888.
ConclusionResearch in both ASR and MT continues.
The statistical approach is clearly dominant.The knowledge of linguists is added wherever it fits.
And although we have madesignificant progress, we are very far from solving the problems.
That is a good thing:We can continue accepting new students into our field without any worry that they willhave to search, in the middle of their careers, for new fields of action.ReferencesBahl, L. R. and F. Jelinek.
1975.
Decodingfor channels with insertions, deletions,and substitutions with applicationsto speech recognition.
IEEE Transactionson Information Theory, IT-21:404?411.Bahl, L. R. and R. L. Mercer.
1976.
Partof speech assignment by a statisticalalgorithm.
In IEEE International Symposiumon Information Theory, pp.
88?89,Ronneby, June.Baker, J. K. 1975.
The dragon system: anoverview.
IEEE Transactions on Acoustics,Speech, and Signal Processing,ASSP-23(1):24?29.Brill, E. 1992.
A simple rule-based partof speech tagger.
In Proceedings of theThird Conference on Applied NaturalLanguage Processing, pages 152?155,Trento, Italy.
ACL.Brown, P. F., J. Cocke, S. A. DellaPietra,V.
DellaPietra, F. Jelinek, J. D. Lafferty,R.
L. Mercer, and P. Roosin.
1990.A statistical approach to machinetranslation.
Computational Linguistics,16(2):79?85.Garside, R., G. Leech, and G. Sampson.1987.
Computational Analysis of English:A Corpus-Based Approach.
Longman,London.5 Every sentence spoken by a deputy in one language was faithfully translated into the other.493Computational Linguistics Volume 35, Number 4Jelinek, F. 1969.
A fast sequential decodingalgorithm using a stack.
IBM Journal ofResearch and Development, 13:675?685.Jelinek, F. 1976.
Continuous speechrecognition by statistical methods.
IEEEProceedings, 64(4):532?556.Jelinek, F., L. R. Bahl, and R. L. Mercer.
1975.Design of a linguistic statistical decoderfor the recognition of continuous speech.IEEE Transactions on Information Theory,IT-21:250?256.Katz, S. 1987.
Estimation of probabilitiesfrom sparse data for the language modelcomponent of a speech recognizer.
IEEETransactions on Acoustics, Speech, and SignalProcessing, ASSP-35(3):400?401.Paul, D. B.
1992.
An essential a?
stackdecoder algorithm for continuousspeech recognition with a stochasticlanguage model.
In Proceedings of the1992 International Conference on Acoustics,Speech, and Signal Processing, pages 25?28,San Francisco.Rosenfeld, R. 1996.
A maximum entropyapproach to adaptive statistical languagemodeling.
Computer Speech and Language,10(3):187?228.Viterbi, A. J.
1967.
Error bounds forconvolutional codes and anasymmetrically optimum decodingalgorithm.
IEEE Transactions on InformationTheory, IT-13:260?267.494
