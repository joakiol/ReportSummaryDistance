Proceedings of the 6th Workshop on Statistical Machine Translation, pages 351?357,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsStochastic Parse Tree Selection for an Existing RBMT SystemChristian FedermannDFKI GmbHLanguage Technology LabSaarbru?cken, Germanycfedermann@dfki.deSabine HunsickerDFKI GmbHLanguage Technology LabSaarbru?cken, Germanysabine.hunsicker@dfki.deAbstractIn this paper we describe our hybrid machinetranslation system with which we participatedin the WMT11 shared translation task for theEnglish?German language pair.
Our systemwas able to outperform its RBMT baseline andturned out to be the best-scored participatingsystem in the manual evaluation.
To achievethis, we extended an existing, rule-based MTsystem with a module for stochastic selectionof analysis parse trees that allowed to bettercope with parsing errors during the system?sanalysis phase.
Due to the integration into theanalysis phase of the RBMT engine, we areable to preserve the benefits of a rule-basedtranslation system such as proper generationof target language text.
Additionally, we useda statistical tool for terminology extraction toimprove the lexicon of the RBMT system.We report results from both automated metricsand human evaluation efforts, including exam-ples which show how the proposed approachcan improve machine translation quality.1 IntroductionRule-based machine translation (RBMT) systemsthat employ a transfer-based translation approach,highly depend on the quality of their analysis phaseas it provides the basis for its later processingphases, namely transfer and generation.
Any parsefailures encountered in the initial analysis phase willproliferate and cause further errors in the followingphases.
Very often, bad translation results can betraced back to incorrect analysis trees that have beencomputed for the respective input sentences.
Hence-forth, any improvements that can be achieved forthe analysis phase of a given RBMT system directlylead to improved translation output which makes thisan interesting topic in the context of hybrid MT.In this paper we present a study how the rule-based analysis phase of a commercial RBMT systemcan be supplemented by a stochastic parser.
Thesystem under investigation is the rule-based engineLucy LT.
This software uses a sophisticated RBMTtransfer approach with a long research history; it isexplained in more detail in (Alonso and Thurmair,2003).The output of its analysis phase is a parse forestcontaining a small number of tree structures.
Forour hybrid system we investigated if the existing rulebase of the Lucy LT system chooses the best treefrom the analysis forest and how the selection of thisbest tree out of the set of candidates can be improvedby adding stochastic knowledge to the rule-basedsystem.The remainder of this paper is structured in thefollowing way: in Section 2 we first describe thetransfer-based architecture of the rule-based LucyLT engine, giving special focus to its analysis phasewhich we are trying to optimize.
Afterwards,we provide details on the implementation of thestochastic selection component, the so-called ?treeselector?
which allows to integrate knowledge froma stochastic parser into the analysis phase of therule-based system.
Section 3 reports on the resultsof both automated metrics and manual evaluationefforts, including examples which show how theproposed approach has improved or degraded MTquality.
Finally, we conclude and provide an outlookon future work in this area.351S$$CLSCLSNPNOPRNTheyADVPADVBADValsoPREDVBVSTwereVBVSTprotestingPPPREPPPREPagainstNPAPAASTbadNONONSTpayNONSTconditionsCONJPCONJandCLSNPNOPRNTheyPREDVBVSTallegedNPNONSTpersecution$PNCT.Figure 1: Original analysis tree from the rule-based MT system2 System Architecture2.1 Lucy LT ArchitectureThe Lucy LT engine is a renowned RMBT systemwhich follows a ?classical?, transfer-based machinetranslation approach.
The system first analyses thegiven source sentence creating a forest of severalanalysis parse trees.
One of these parse trees is thenselected (as ?best?
analysis) and transformed in thetransfer phase into a tree structure from which thetarget text (i.e.
the translation) can be generated.It is clear that any errors that occur during theinitial analysis phase proliferate and cause negativeside effects on the outcome of the final translationresult.
As the analysis phase is thus of very specialimportance, we have investigated it in more detail.The Lucy LT analysis consists of several phases:1.
The input is tokenised with regards to thesystem?s source language lexicon.2.
The resulting tokens undergo a morphologicalanalysis, which is able to identify possiblecombinations of allomorphs for a token.3.
This leads to a chart which forms the basis forthe actual parsing, using a head-driven strat-egy1.
Special handling is performed for theanalysis of multi-word expressions and also forverbal framing.At the end of the analysis, there is an extra phasenamed phrasal analysis which is called whenever1grammar formalism + number of rulesthe grammar was not able to construct a legal con-stituent from all the elements of the input.
This hap-pens in several different scenarios:?
The input is ungrammatical according to theLT analysis grammar.?
The category of the derived constituent is notone of the allowed categories.?
A grammatical phenomenon in the sourcesentence is not covered.?
There are missing lexical entries for the inputsentence.During the phrasal analysis, the LT engine collectsall partial trees and greedily constructs an overall in-terpretation of the chart.
Based on our findings frommany experiments with the Lucy LT engine, phrasalanalyses are performed for more than 40% of thesentences from our test sets and very often result inbad translations.Each resulting analysis parse tree, independentof whether it is a grammatical or a result from thephrasal analysis, is also assigned an integer score bythe grammar.
The tree with the highest score is thenhanded over to the transfer phase, thus pre-definingthe final translation output.2.2 The ?Tree Selector?An initial evaluation of the translation quality basedon the tree selection of the analysis phase showedthat there is potential for improvement.
The integerscore assigned by the analysis grammar provides a352S$$CLSNPNOPRNTheyADVPADVBADValsoPREDVBVSTwereVBVSTprotestingPPPREPPPREPagainstNPNPAPAASTbadNONONSTpayNONSTconditionsCONJPCONJandNPAPAASTallegedNONSTpersecution$PNCT.Figure 2: Improved analysis tree resulting from stochastic parse selectiongood indication of which trees lead to good transla-tions, as is depicted in Table 1.
Still, in many casesan alternative tree would have lead to a better trans-lation.As additional feature, we chose to use the treeedit distance of each analysis candidate to a stochas-tic parse tree.
An advantage of stochastic parsinglies in the fact that parsers from this class can dealvery well even with ungrammatical or unknown out-put, which we have seen is problematic for a rule-base parser.
We decided to make use of the StanfordParser as described in (Klein and Manning, 2003),which uses an unlexicalised probabilistic context-free grammar that was trained on the Penn Tree-bank2.
We parse the original source sentence withthis PCFG grammar to get a stochastic parse tree thatcan be compared to the trees from the Lucy analysisforest.In our experiments, we compare the stochasticparse tree with the alternatives given by Lucy LT.Tree comparison is implemented based on the TreeEdit Distance, as originally defined in (Zhang andShasha, 1989).
In analogy to the Word Edit or Lev-2Further experiments with different grammars are currentlyon-going.Best Analysis Tree PercentageDefault (id=1) 42 (61.76%)Alternative (id=2-7) 26 (38.24%)Table 1: Evaluation of Analysis Forestsenshtein Distance, the distance between two treesis the number of editing actions that are required totransform the first tree into the second tree.
The TreeEdit Distance knows three actions:?
Insertion?
Deletion?
Renaming (substitution in Levenshtein Distance)Since the Lucy LT engine uses its own tag set,a mapping between this proprietary and the PennTreebank tag set was created.
Our implementation,called ?Tree Selector?
uses a normalised version ofthe Tree Edit Distance to estimate the quality of thetrees from the Lucy analysis forest, possibly over-riding the analysis decision taken by the unmodifiedRBMT engine.
The integration of the Tree Selectorhas been possible by using an adapted version of therule-based MT system which allowed to communi-cate the selection result from our external process tothe Lucy LT kernel which would then load the re-spective parse tree for all further processing steps.2.3 LiSTEX Terminology ExtractionThe LiSTEX extension of the Lucy RBMT engineallows to improve the system?s lexicon; the approachis described in more detail in (Federmann et al,2011).
To extend the lexicon, terminology lists areextracted from parallel corpora.
These lists are thenenriched with linguistic information, such as part-of-speech tag, internal structure of multi-word expres-353sions and frequency.
For English and German, about26,000 terms were imported using this procedure.2.4 Named Entity HandlingNamed entities are often handled incorrectly andwrongly translated, such as George Bush?
GeorgeBusch.
To reduce the frequency of such errors, weadded a pre- and post-processing modules to dealwith named entities.
Before translation, the inputtext is scanned for named entities.
We use bothHeiNER (Wolodja Wentland and Hartung (2008))and the OpenNLP toolkit3.
HeiNER is a dictionarycontaining named entities extracted from Wikipedia.This provides us with a wide range of well-translatedentities.
To increase the coverage, we also use thenamed entity recogniser in OpenNLP.
These entitieshave to be translated using the RBMT engine.
Wesave the named entity translations and insert place-holders for all NEs.
The modified text is translatedusing the hybrid set-up described above.
After thetranslation is finished, the placeholders are replacedby their respective translations.3 Evaluation3.1 Shared Task SetupFor the WMT11 shared translation task, we submit-ted three different runs of our hybrid MT system:1.
Hybrid Transfer (without the Tree Selector, butwith the extended lexicon)2.
Full Hybrid (with both the Tree Selector andthe extended lexicon)3.
Full Hybrid+Named Entities (full hybrid andnamed entity handling)Our primary submission was run #3.
All three runswere evaluated using BLEU (Papineni et al (2001))and TER (Snover et al (2006)).
The results fromthese automated metrics are reported in Table 2.Table 2: Automatic metric scores for WMT11System BLEU TERHybrid Transfer 13.4 0.792Full Hybrid 13.1 0.796Full Hybrid+Named Entities 12.8 0.8003http://incubator.apache.org/opennlp/Table 3 shows that we were able to outperformthe original Lucy version.
Furthermore, it turned outthat our hybrid system was the best-scoring systemfrom all shared task participants.Table 3: Manual evaluation scores for WMT11System Normalized ScoreFull Hybrid+Named Entities 0.6805Original Lucy 0.65993.2 Error AnalysisThe selection process following the decision factorsas explained in Section 2.2 may fail due to wrongassumptions in two areas:1.
The tree with the lowest distance does notresult in the best translation.2.
There are several trees associated with the low-est distance, but the tree with the highest scoredoes not result in the best translation.To calculate the error rate of the Tree Selector, weran experiments on the test set of the WMT10 sharedtask and evaluated a sample of 100 sentences withregards to translation quality.
To do so, we createdall seven possible translations for each of the phrasalanalyses and checked whether the Tree Selector re-turned a tree that led to exactly this translation.
Incase it did not, we investigated the reasons for this.Sentences for which all trees created the same trans-lation were skipped.
This sample contains bothexamples in which the translation changed and inwhich the translation stayed the same.Table 4 shows the error rate of the Tree Selectorwhile Table 5 contains the error analysis.
As onecan see, the optimal tree was chosen for 56% of thesentences.
We also see that the minimal tree editdistance seems to be a good feature to use for com-parisons, as it holds for 71% of the trees, includingthose examples where the best tree was not scoredhighest by the LT engine.
This also means that addi-tional features for choosing the tree out of the groupof trees with the minimal edit distance are required.Even for the 29% of sentences, in which the opti-mal tree was not chosen, little quality was lost: in75.86% of those cases, the translations didn?t change354Best Translation Returned 56%Other Translation Returned 44%Best Tree has Minimal Edit Distance 71%Best Tree has Higher Distance 29%Table 4: Error Rate of the Tree Selectorat all (obviously the trees resulted in equal transla-tion output).
In the remaining cases the translationswere divided evenly between slight degradations andand equal quality.Other Translation: Selected TreeTree 1 (Default) 31Tree 2-7 (Alternatives) 13Reasons for SelectionSource contained more than 50 tokens 16Time-out before best tree is reached 13Chosen tree had minimal distance 15Table 5: Evaluation of Tree Selector ErrorsIn the cases when the best tree was not chosen,the first tree (which is the default tree) was selectedin 70.45% .
This is due to a combinations of ro-bustness factors that are implemented in the RBMTsystem and have been beyond our control in the ex-periments.
The LT engine has several different indi-cators which may throw a time-out exception, if, forexample, the analysis phase takes too long to pro-duce a result.
To avoid getting time-out errors, onlysentences with up to 50 tokens are treated with theTree Selector.
Additionally the Tree Selector itselfchecks the processing time and returns intermediateresults, if this limit is reached.
This ensures that wereceive a proper translation for all sentences.43.3 ExamplesUsing our stochastic selection component, we areable to fix errors which can be found in translationoutput generated by the original Lucy engine.Table 6 shows several examples including sourcetext, reference text, and translations from both theoriginal Lucy engine (A) and our hybrid system (B).We will briefly discuss our observations for theseexamples in the following section.4We are currently working on eliminating this time-out issueas it prevents us from driving our approach to its full potential.1.
Translation A is the default translation.
Theparse tree for this translation can be seen inFigure 1.
Here the adjective alleged is wronglyparsed as a verb.
By contrast, Figure 2 showsthe tree selected by our hybrid implementation,which contains the correct analysis of allegedand results in a correct translation.2.
Word order is improved in the Example 2.3.
Lexical items are associated with a domain areain the lexicon of the rule-based system.
Itemsthat are contained within a different domainthan the input text are still accessible, but itemsin the same domain are preferred.
In Exam-ple 3, this may lead to the incorrect disam-biguation of multi-word expressions: the trans-lation of to blow up as in die Luft fliegen wasnot preferred in Translation A due to the cho-sen domain and a more superficial translationwas chosen.
This problem is fixed in Transla-tion B.
Our system chose a tree leading to thecorrect idiomatic translation.4.
Something similar happens in Example 4where the choice of preposition is improved.5.
These changes remain at a rather local scope,but we also have instances where the sentenceimproves globally: Example 5 illustrates thiswell.
In translation A, the name of the book,?After the Ice?, has been moved to an entirelydifferent place in the sentence, removing itfrom its original context.6.
The same process can be observed in Exam-ple 6, where the translation of device wasmoved from the main clause to the sub clausein Translation A.7.
An even more impressive example is Exam-ple 7.
Here, translation A was not even a gram-matically correct sentence.
This is due to theheuristics of the Lucy engine, although theycould also create a correct translation B.These examples show that our initial goal ofimproving the given RMBT system has beenreached and that a hybrid MT system with anarchitecture similar to what we have described inthis paper does in fact perform quite well.355Table 6: Translation Examples for Original (A) and Improved (B) Lucy1 Source: They were also protesting against bad pay conditions and alleged persecution.Reference: Sie protestierten auch gegen die schlechten Zahlungsbedingungen und angebliche Schikanen.Translation A: Sie protestierten auch gegen schlechte Soldbedingungen und behaupteten Verfolgung.Translation B: Sie protestierten auch gegen schlechte Soldbedingungen und angebliche Verfolgung.2 Source: If the finance minister can?t find the money elsewhere, the project will have to be aborted andsanctions will be imposed, warns Janota.Reference: Sollte der Finanzminister das Geld nicht anderswo finden, mu?sste das Projekt gestoppt wer-den und in diesem Falle kommen Sanktionen, warnte Janota.Translation A: Wenn der Finanzminister das Geld nicht anderswo finden kann, das Projekt abgebrochenwerden mu?ssen wird und Sanktionen auferlegt werden werden, warnt Janota.Translation B: Wenn der Finanzminister das Geld nicht anderswo finden kann, wird das Projekt abgebrochenwerden mu?ssen und Sanktionen werden auferlegt werden, warnt Janota.3 Source: Apparently the engine blew up in the rocket?s third phase.Reference: Vermutlich explodierte der Motor in der dritten Raketenstufe.Translation A: Offenbar blies der Motor hinauf die dritte Phase der Rakete in.Translation B: Offenbar flog der Motor in der dritten Phase der Rakete in die Luft.4 Source: As of January, they should be paid for by the insurance companies and not compulsory.Reference: Ab Januar soll diese von den Versicherungen bezahlt und freiwillig sein.Translation A: Ab Januar sollten sie fu?r von den Versicherungsgesellschaften und nicht obligatorisch bezahltwerden.Translation B: Ab Januar sollten sie von den Versicherungsgesellschaften und nicht obligatorisch gezahltwerden.5 Source: In his new book, ?After the Ice?, Alun Anderson, a former editor of New Scientist, offersa clear and chilling account of the science of the Arctic and a gripping glimpse of how thefuture may turn out there.Reference: In seinem neuen Buch ?Nach dem Eis?
(Originaltitel ?After the Ice?)
bietet Alun Anderson,ein ehemaliger Herausgeber des Wissenschaftsmagazins ?New Scientist?, eine klare und be-unruhigende Beschreibung der Wissenschaft der Arktis und einen packenden Einblick, wiedie Zukunft sich entwickeln ko?nnte.Translation A: In seinem neuen Buch bietet Alun Anderson, ein fru?herer Redakteur von Neuem Wis-senschaftler, ?Nach dem Eis?
einen klaren und kalten Bericht u?ber die Wissenschaft derArktis und einen spannenden Blick davon an, wie die Zukunft sich hinaus dort drehen kann.Translation B: In seinem neuen Buch, ?Nach dem Eis?, bietet Alun Anderson, ein fru?herer Redakteur vonNeuem Wissenschaftler, einen klaren und kalten Bericht u?ber die Wissenschaft der Arktisund einen spannenden Blick davon an, wie die Zukunft sich hinaus dort drehen kann.6 Source: If he does not react, and even though the collision is unavoidable, the device exerts the maxi-mum force to the brakes to minimize damage.Reference: Falls der Fahrer nicht auf die Warnung reagiert und sogar wenn der Zusammenstoss schonunvermeidlich ist, u?bt der Bremsassistent den maximalen Druck auf die Bremsen aus, um aufdiese Weise die Scha?den so gering wie mo?glich zu halten.Translation A: Wenn er nicht reagiert, und das Gera?t auch wenn der Zusammensto?
unvermeidlich ist, diegro?
?tmo?gliche Kraft zu den Bremsen ausu?bt, um Schaden zu bagatellisieren.Translation B: Wenn er nicht reagiert, und auch wenn der Zusammensto?
unvermeidlich ist, u?bt das Gera?tdie gro?
?tmo?gliche Kraft zu den Bremsen aus, um Schaden zu bagatellisieren.7 Source: For the second year, the Walmart Foundation donated more than $150,000 to purchase, andtransport the wreaths.Reference: Die Walmart-Stiftung spendete zum zweiten Mal mehr als 150.000 Dollar fu?r Kauf undTransport der Kra?nze.Translation A: Fu?r das zweite Jahr, die Walmart-Gru?ndung, mehr gespendet al $150,000, um die Kra?nze zukaufen, und zu transportieren.Translation B: Fu?r das zweite Jahr spendete die Walmart-Gru?ndung mehr als $150,000, um die Kra?nze zukaufen, und zu transportieren.3564 Conclusion and OutlookThe analysis phase proves to be crucial for the over-all quality of the translation in rule-based machinetranslation systems.
Our hybrid approach indicatesthat it is possible to improve the analysis resultsof such a rule-based engine by a better selectionmethod of the trees created by the grammar.
Ourevaluation shows that the selection itself is no trivialtask, as our initial experiments deliver results ofvarying quality.
The degradations we have observedin our own manual evaluation can be fixed by amore fine-grained selection mechanism, as we al-ready know that better trees exist, i.e.
the defaulttranslations.While the work reported on in this paper is adedicated extension of a specific rule-based machinetranslation system, the overall approach can be usedwith any transfer-based RBMT system.
Future workwill concentrate on the circumvention of e.g.
thetime-out errors that prevented a better performanceof the stochastic selection module.
Also, we willmore closely investigate the issue of decreased trans-lation quality and experiment with other decisionfactors that may help to alleviate the negative effects.The LiSTEX module provides us with high qual-ity entries for the lexicon, increasing the coverageof the lexicon and fluency of the translation.
As aside-effect, the new terms also help to reduce parsingerrors, as formerly unknown multiword expressionsare now properly recognised and treated.
Furtherwork is being carried out to increase the precisionof the extracted terminology lists.The addition of stochastic knowledge into anexisting rule-based machine translation system isan example of a successful, hybrid combination ofdifferent MT paradigms into a joint system.
Oursystem turned out to be the winning system forthe English?German language pair of the WMT11shared task.AcknowledgementsThe work described in this paper was supportedby the EuroMatrixPlus project (IST-231720) whichis funded by the European Community under theSeventh Framework Programme for Research andTechnological Development.ReferencesJuan A. Alonso and Gregor Thurmair.
2003.
The Com-prendium Translator system.
In Proceedings of theNinth Machine Translation Summit.Christian Federmann, Sabine Hunsicker, Petra Wolf, andUlrike Bernardi.
2011.
From statistical term extrac-tion to hybrid machine translation.
In Proceedings ofthe 15th Annual Conference of the European Associa-tion for Machine Translation.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stAnnual Meeting of the ACL, pages 423?430.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a method for automatic eval-uation of machine translation.
IBM Research ReportRC22176(W0109-022), IBM.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and John Makhoul.
2006.
A study of trans-lation edit rate with targeted human annotation.
In InProceedings of Association for Machine Translation inthe Americas, pages 223?231.Carina Silberer Wolodja Wentland, Johannes Knopp andMatthias Hartung.
2008.
Building a multilingual lexi-cal resource for named entity disambiguation, transla-tion and transliteration.
In European Language Re-sources Association (ELRA), editor, Proceedings ofthe Sixth International Language Resources and Eval-uation (LREC?08), Marrakech, Morocco, may.K.
Zhang and D. Shasha.
1989.
Simple fast algorithmsfor the editing distance between trees and related prob-lems.
SIAM J.
Comput., 18:1245?1262, December.357
