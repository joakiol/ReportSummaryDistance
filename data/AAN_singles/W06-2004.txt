Improving Name Discrimination: A Language Salad ApproachTed Pedersen and Anagha KulkarniDepartment of Computer ScienceUniversity of Minnesota, DuluthDuluth, MN 55812 USA{tpederse,kulka020}@d.umn.eduRoxana AnghelutaAttentio SAB-1030 Brussels, Belgiumroxana@attentio.comZornitsa KozarevaDept.
de Lenguajes y Sistemas Informa?ticosUniversity of Alicante03080 Alicante, Spainzkozareva@dlsi.ua.esThamar SolorioDepartment of Computer ScienceUniversity of Texas at El PasoEl Paso, TX 79902 USAtsolorio@utep.eduAbstractThis paper describes a method of discrim-inating ambiguous names that relies uponfeatures found in corpora of a more abun-dant language.
In particular, we discrim-inate ambiguous names in Bulgarian, Ro-manian, and Spanish corpora using infor-mation derived from much larger quan-tities of English data.
We also mix to-gether occurrences of the ambiguous namefound in English with the occurrences ofthe name in the language in which we aretrying to discriminate.
We refer to this asa language salad, and find that it often re-sults in even better performance than whenonly using English or the language itselfas the source of information for discrimi-nation.1 IntroductionName ambiguity is a problem that is increasingin complexity and scope as online informationsources grow and expand their coverage.
Likewords, names are often ambiguous and can referto multiple underlying entities or concepts.
Websearches for names can often return results asso-ciated with multiple people or organizations in adisorganized and unclear fashion.
For example,the top 10 results of a Google search for GeorgeMiller includes a mixture of entries for two dif-ferent entities, one a psychology professor fromPrinceton University and the other the director ofthe film Mad Max.1Name discrimination takes some number ofcontexts that include an ambiguous name, and di-vides them into groups or clusters, where the con-1Search conducted January 4, 2006.texts in each cluster should ideally refer to thesame underlying entity (and each cluster shouldrefer to a different entity).
Thus, if we are given10,000 contexts that include the name John Smith,we would want to divide those contexts into clus-ters corresponding to each of the different under-lying entities that share that name.We have developed an unsupervised method ofname discrimination (Pedersen et al, 2005).
Wehave shown the method to be language indepen-dent (Pedersen et al, 2006), which is to say wecan apply it to English contexts as easily as wecan apply it to Romanian or French.
However,we have observed that there are situations wherethe number of contexts in which an ambiguousname occurs is relatively small, perhaps becausethe name itself is unusual, or because the quantityof data available for language is limited in general.These problems of scarcity can make it difficult toapply these methods and discriminate ambiguousnames, especially in languages with fewer onlineresources.This paper presents a method of name discrim-ination is based on using a larger number of con-texts in English that include an ambiguous name,and applying information derived from these con-texts to the discrimination of that name in anotherlanguage, where there are many fewer contexts.We also show that mixing English contexts withthe contexts to be discriminated can result in aperformance improvement over only using the En-glish or the original contexts alone.2 Discrimination by Clustering ContextsOur method of name discrimination is described inmore detail in (Pedersen et al, 2005), but in gen-eral is based on an unsupervised approach to wordsense discrimination introduced by (Purandare and25Pedersen, 2004), which builds upon earlier workin word sense discrimination, including (Schu?tze,1998) and (Pedersen and Bruce, 1997).Our method treats each occurrence of an am-biguous name as a context that is to be clusteredwith other contexts that also include the samename.
In this paper, each context consists of about50 words, where the ambiguous name is generallyin the middle of the context.
The goal is to clustersimilar contexts together, based on the presump-tion that the occurrences of a name that appearin similar contexts will refer to the same underly-ing entity.
This approach is motivated by both thedistributional hypothesis (Harris, 1968) and thestrong contextual hypothesis (Miller and Charles,1991).2.1 Feature SelectionThe contexts to be clustered are represented bylexical features which may be selected from eitherthe contexts being clustered, or from a separatecorpus.
In this paper we use both approaches.
Wecluster the contexts based on features identified inthose very same contexts, and we also cluster thecontexts based on features identified in a separateset of data (in this case English).
We explore theuse of a mixed feature selection strategy where weidentify features both from the data to be clusteredand the separate corpus of English text.
Thus, ourfeature selection data may come from one of threesources: the contexts to be clustered (which wewill refer to as the evaluation contexts), Englishcontexts which include the same name but are notto be clustered, and the combination of these two(our so-called Language Salad or Mix).The lexical features we employ are bigrams,that is consecutive words that occur together in thecorpora from which we are identifying features.
Inthis work we identify bigram features using Point-wise Mutual Information (PMI).
This is defined asthe log of the ratio of the observed frequency withwhich the two words occur together in the featureselection data, to the expected number of timesthe two words would occur together in a corpus ifthey were independent.
This expected value is es-timated simply by taking the product of the num-ber of times the two words occur individually, anddividing this by the total number of bigrams in thefeature selection data.
Thus, larger values of PMIindicate that the observed frequency of the bigramis greater than would be expected if the two wordswere independent.In these experiments we take the top 500 rankedbigrams that occur five or more times in the featureselection data.
We also exclude any bigram fromconsideration that is made up of one or two stopwords, which are high frequency function wordsthat have been specified in a manually created list.Note that with smaller numbers of contexts (usu-ally 200 or fewer), we lower the frequency thresh-old to two or more.In general PMI is known to have a bias towardspairs of words (bigrams) that occur a small num-ber of times and only with each other.
In this workthat is a desirable quality, since that will tend toidentify pairs of words that are very strongly as-sociated with each other and also provide uniquediscriminating information.2.2 Context RepresentationOnce the bigram features have been identified,then the contexts to be clustered are representedusing second order co-occurrences that are de-rived from those bigrams.
In general a secondorder co-occurrence is a pair of words that maynot occur with each other, but that both occur fre-quently with a third word.
For example, gardenand fire may not occur together often, but bothcommonly occur with hose.
Thus, garden hoseand fire hose represent first order co?occurrences,and garden and fire represent a second order co?occurrence.The process of creating the second order repre-sentation has several steps.
First, the bigram fea-tures identified by PMI (the top ranked 500 bi-grams that have occurred 5 or more times in thefeature selection data) are used to create a wordby word co?occurrence matrix.
The first word ineach bigram represents a row in the matrix, and thesecond word in each bigram represents a column.The cells in the matrix contain the PMI scores.Note that this matrix is not symmetric, and thatthere are many words that only occur in either arow or a column (and not both) because they tendto occur as the first or second word in a bigram.For example, President might tend to be a firstword in a bigram (e.g., President Clinton, Presi-dent Putin), whereas last names will tend to be thesecond word.Once the co?occurrence matrix is created, thenthe contexts to be clustered can be represented.Each word in the context is checked to see if it26has a corresponding row (i.e., vector) in the co?occurrence matrix.
If it does, that word is replacedin the context by the row from the matrix, so thatthe word in the context is now represented by thevector of words with which it occurred in the fea-ture selection data.
If a word does not have a corre-sponding entry in the co?occurrence matrix, thenit is simply removed from the context.
After allthe words in the context are checked, then all ofthe vectors that are selected are averaged togetherto create a vector representation of the context.Then these contexts are clustered into a pre?specified number of clusters using the k?meansalgorithm.
Note that we are currently develop-ing methods to automatically select the number ofclusters in the data (e.g., (Pedersen and Kulkarni,2006)), although we have not yet applied them tothis particular work.3 The Language SaladIn this paper, we explore the creation of a secondorder representation for a set of evaluation con-texts using three different sets of feature selectiondata.
The co?occurrence matrix may be derivedfrom the evaluation contexts themselves, or froma separate set of contexts in a different language,or from the combination of these two (the Salad orMix).For example, suppose we have 100 Romanianevaluation contexts that include an ambiguousname, and that same name also occurs 10,000times in an English language corpus.2 Our goalis to cluster the 100 Romanian contexts, whichcontain all the information that we have about thename in Romanian.
While we could derive a sec-ond order representation of the contexts, the re-sulting co?occurrence matrix would likely be verysmall and sparse, and insufficient for making gooddiscrimination decisions.
We could instead relyon first order features, that is look for frequentwords or bigrams that occur in the evaluation con-texts, and try and find evaluation contexts thatshare some of the same words or phrases, and clus-ter them based on this type of information.
How-ever, again, the small number of contexts availablewould likely result in very sparse representationsfor the contexts, and unreliable clustering results.Thus, our method is to derive a co?occurrencematrix from a language for which we have many2We assume that the names either have the same spellingin both languages, or that translations are readily available.occurrences of the ambiguous name, and then usethat co?occurrence matrix to represent the evalua-tion contexts.
This relies on the fact that the eval-uation contexts will contain at least a few namesor words that are also used in the larger corpus (inthis case English).
In general, we have found thatwhile this is not always true, it is often the case.We have also experimented with combining theEnglish contexts with the evaluation contexts, andbuilding a co?occurrence matrix based on thiscombined or mixed collection of contexts.
Thisis the language salad that we refer to, a mixture ofcontexts in two different languages that are used toderive a representation of the evaluation contexts.4 Experimental DataWe use data in four languages in these experi-ments, Bulgarian, English, Romanian, and Span-ish.4.1 Raw CorporaThe Romanian data comes from the 2004 archivesof the newspaper Adevarul (The Truth)3.
This is adaily newspaper that is among the most popular inRomania.
While Romanian normally has diacrit-ical markings, this particular newspaper does notinclude those in their online edition, so the alpha-bet used was the same as English.The Bulgarian data is from the Sega 2002 newscorpus, which was originally prepared for theCLEF competition.4 This is a corpus of news arti-cles from the Newspaper Sega5, which is based inSofia, Bulgaria.
The Bulgarian text was translit-erated (phonetically) from Cyrillic to the Romanalphabet.
Thus, the alphabet used was the sameas English, although the phonetic transliterationleads to fewer cognates and borrowed Englishwords that are spelled exactly the same as in En-glish text.The Spanish corpora comes from the Spanishnews agency EFE from the year 1994 and 1995.This collection was used in the Question Answer-ing Track at CLEF-2003, and also for CLEF-2005.This text is represented in Latin-1, and includesthe usual accents that appear in Spanish.The English data comes from the GigaWordcorpus (2nd edition) that is distributed by the Lin-guistic Data Consortium.
This consists of more3http://www.adevarulonline.ro/arhiva4http://www.clef-campaign.org5http://www.segabg.com27than 2 billion words of newspaper text that comesfrom five different news sources between the years1994 and 2004.
In fact, we subdivide the Englishdata into three different corpora, where one is from2004, another from 2002, and the third from 1994-95, so that for each of the evaluation languages(Bulgarian, Spanish, and Romanian) we have anEnglish corpus from the same time period.4.2 Evaluation ContextsOur experimental data consists of evaluation con-texts derived from the Bulgarian, Romanian, andSpanish corpora mentioned above.
We also haveEnglish corpora that includes the same ambiguousnames as found in the evaluation contexts.In order to quickly generate a large volume ofexperimental data, we created evaluation contextsfrom the corpora for each of our four languagesby conflating together pairs of well known namesor places, and that are generally not highly am-biguous (although some might be rather general).For example, one of the pairs of names we con-flate is George Bush and Tony Blair.
To do that,every occurrence of both of these names is con-verted to an ambiguous form (GB TB, for exam-ple), and the discrimination task is to cluster thesecontexts such that their original and correct nameis re?discovered.
We retain a record of the orig-inal name for each occurrence, so as to evaluatethe results of our method.
Of course we do not usethis information anywhere in the process outsideof evaluation.The following pairs of names were conflated inall four of the languages: George Bush-Tony Blair,Mexico-India, USA-Paris, Ronaldo-David Beck-ham (2002 and 2004), Diego Maradona-RobertoBaggio (1994-95 only), and NATO-USA.
Notethat some of these names have different spellingsin some of our languages, so we look for and con-flate the native spelling of the names in the differ-ent language corpora.
These pairs were selectedbecause they occur in all four of our languages,and they represent name distinctions that are com-monly of interest, that is they represent ambiguityin names of people and places.
With these pairswe are also following (Nakov and Hearst, 2003)who suggest that if one is introducing ambiguityby creating pseudo?words or conflating names,then these words should be related in some way(in order to avoid the creation of very sharp or ob-vious sense distinctions).4.3 DiscussionFor each of the three evaluation languages (Bul-garian, Romanian, and Spanish) we have contextsfor five different name conflate pairs that we wishto discriminate.
We have corresponding Englishcontexts for each evaluation language, where thedates of both are approximately the same.
Thistemporal consistency between the evaluation lan-guage and English is important because the con-texts in which a name is used may change overtime.
In 1994, for example, Tony Blair was notyet Prime Minister of England (he became PM in1997), and references to George Bush most likelyrefer to the US President who served from 1988until 1992, rather than the current US President(who began his term in office in 2001).
In 1994the current (as of 2006) US President had just beenelected governor of Texas, and was not yet a na-tional figure.
This points out that George Bush isan example of an ambiguous name, but our ob-servation has been that in the 2002 and 2004 data(Romanian and Bulgarian) nearly all occurrencesare associated with the current president, and thatmost of the occurrences in 1994-95 (Spanish) re-fer to the former US President.
This illustratesan important point: it is necessary to consider theperspective represented by the different corpora.There is little reason to expect that news articlesfrom Spain in 1994 and 1995 would focus muchattention on the newly elected governor of Texasin the United States.Tables 1, 2, and 3 show the number of contextsthat have been collected for each name conflatepair.
For example, in Table 1 we see that there are746 Bulgarian contexts that refer to either Mex-ico or India, and that of these 51.47% truly re-fer to Mexico, and 48.53% to India.
There are149,432 English contexts that mention Mexico orIndia, and the Mix value shown is simply the sumof the number of Bulgarian and English contexts.In general these tables show that the Englishcontexts are much larger in number, however,there are a few exceptions with the Spanish data.This is because the EFE corpus is relatively largeas compared to the Bulgarian and Romanian cor-pora, and provides frequency counts that are insome cases comparable to those in the English cor-pus.285 Experimental MethodologyFor each of the three evaluation languages (Bul-garian, Romanian, Spanish) there are five nameconflate pairs.
The same name conflate pairsare used for all three languages, except forDiego Maradona-Roberto Baggio which is onlyused with Spanish, and Ronaldo-David Beckham,which is only used with Bulgarian and Romanian.This is due to the fact that in 1994-95 (the eraof the Spanish data) neither Ronaldo nor DavidBeckham were as famous as they later became, sothey were mentioned somewhat less often than inthe 2002 and 2004 corpora.
The other four nameconflate pairs are used in all of the languages.For each name conflate pair we create a secondorder representation using three different sourcesof features selection data: the evaluation contextsthemselves, the corresponding English contexts,and then the mix of the evaluation contexts and theEnglish contexts (the Mix).
The objective of theseexperiments is to determine which of these sourcesof feature selection data results in the highest F-Measure, which is the harmonic mean of the pre-cision and recall of an experiment.The precision of each experiment is the num-ber of evaluation contexts clustered correctly, di-vided by the number of contexts that are clustered.The clustering algorithm may choose not to assignevery context to a cluster, which is why that de-nominator may not be the same as the number ofevaluation contexts.
The recall of each experimentis the the number of correctly clustered evaluationcontexts divided by the total number of evaluationcontexts.
Note that for each of the three variationsfor each name conflate pair experiment exactly thesame evaluation language contexts are being dis-criminated, all that is changing in each experimentis the source of the feature selection data.
Thus theF-measures for a name conflate pair in a particularlanguage can be compared directly.
Note howeverthat the F-measures across languages are harder tocompare directly, since different evaluation con-texts are used, and different English contexts areused as well.There is a simple baseline that can be used as apoint of comparison, and that is to place all of thecontexts for each name conflate pair into one clus-ter, and say that there is no ambiguity.
If that isdone, then the resulting F-Measure will be equalto the majority percentage of the true underlyingentity as shown in Tables 1, 2, and 3.
For exam-ple, for Bulgarian, if the 746 Bulgarian contextsfor Mexico and India are all put into the same clus-ter, the resulting F-Measure would be 51.47%, be-cause we would simply assign all the contexts inthe cluster to the more common of the two entities,which is Mexico in this case.6 Experimental ResultsTables 1, 2, and 3 show the results for our exper-iments, language by language.
Each table showsthe results for the 15 experiments done for eachlanguage: five name conflate pairs, each withthree different sources of feature selection data.The row labeled with the name of the evalua-tion language reports the F-Measure for the eval-uation contexts (whose number of occurrences isshown in the far right column) when the fea-ture selection data is the evaluation contexts them-selves.
The rows labeled English and Mix reportthe F-Measures obtained for the evaluation con-texts when the feature selection data is the Englishcontexts, or the Mix of the English and evaluationcontexts.6.1 Bulgarian ResultsThe Bulgarian results are shown in Table 1.
Notethat the number of contexts for English is consid-erably larger than for Bulgarian for all five nameconflate pairs.
The Bulgarian and English datacame from 2002 news reports.The Mix of feature selection data results in thebest performance for three of the five name con-flate pairs: George Bush - Tony Blair, Ronaldo -David Beckham, and NATO - USA.
For remain-ing two name conflate pairs, just using the Bul-garian evaluation contexts results in the highest F-Measure (Mexico-India, USA-Paris).We believe that this may be partially due to thefact that the two cases where Bulgarian leads to thebest results are for very general or generic underly-ing entities: Mexico and India, and then the USAand Paris.
In both cases, contexts that mentionthese entities could be discussing a wide range oftopics, and the larger volumes of English data maysimply overwhelm the process with a huge num-ber of second order features.
In addition, it maybe that the English and Bulgarian corpora containdifferent content that reflects the different interestsof the original readership of this text.
For example,news that is reported about India might be ratherdifferent in the United States (the source of most29Table 1: Bulgarian Results (2002): Feature Selec-tion Data, F-Measure, and Number of ContextsGeorge Bush (73.43) - Tony Blair (26.57)Mix 68.37 11,570Bulgarian 55.78 651English 36.15 10,919Mexico (51.47) - India (48.53)Bulgarian 70.97 746Mix 55.01 150,178English 48.15 149,432USA (79.53) - Paris (20.47)Bulgarian 58.67 3,283Mix 51.68 56,044English 49.66 52,761Ronaldo (61.25) - David Beckham (38.75)Mix 64.88 8,649Bulgarian 52.75 320English 48.11 8,329NATO (87.37) - USA (12.63)Mix 75.44 54,193Bulgarian 65.92 3,770English 60.44 50,423of the English data) than in Bulgaria.
Thus, theuse of the English corpora might not have beenas helpful in those cases where the names to bediscriminated are more global figures.
For exam-ple, Tony Blair and George Bush are probably inthe news in the USA and Bulgaria for many of thesame reasons, thus the underlying content is morecomparable than that of the more general entities(like Mexico and India) that might have much dif-ferent content associated with them.We observed that Bulgarian tends to have fewercognates or shared names with English than doRomanian and English.
This is due to the factthat the Bulgarian text is transliterated.
This mayaccount for the fact that the English-only resultsfor Bulgarian are very poor, and it is only in com-bination with the Bulgarian contexts that the En-glish contexts show any positive effect.
This sug-gests that there are only a few words in the Bulgar-ian contexts that also occur in English, but thosethat do have a positive impact on clustering per-formance.6.2 Romanian ResultsThe Romanian results are shown in Table 2.
TheRomanian and English contexts come from 2004.Table 2: Romanian Results (2004): Feature Selec-tion Data, F-Measure, and Number of ContextsTony Blair (72.00) - George Bush (28.00)English 64.23 11,616Mix 54.31 11,816Romanian 50.75 200India (53.66) - Mexico (46.34)Romanian 50.93 82English 47.30 88,247Mix 42.55 88,329USA (60.29) - Paris (39.71)English 59.05 45,346Romanian 58.76 700Mix 57.91 46,046David Beckham (55.56) - Ronaldo (44.44)Mix 81.00 4,365English 70.85 4,203Romanian 52.47 162NATO (58.05) - USA (41.95)Mix 60.48 43,508Romanian 51.20 1,168English 38.91 42,340The Mix of Romanian and English contexts forfeature selection results in improvements for twoof the five pairs (David Beckham - Ronaldo, andNATO - USA).
The use of English contexts onlyprovides the best results for two other pairs (TonyBlair - George Bush, and USA - Paris, although inthe latter case the difference in the F-Measures thatresult from the three sources of data is minimal).There is one case (Mexico-India) where using theRomanian contexts as feature selection data re-sults in a slightly better F-measure than when us-ing English contexts.The improvement that the Mix shows for DavidBeckham-Ronaldo is significant, and is perhapsdue to fact that in both English and Romanian text,the content about Beckham and Ronaldo is simi-lar, making it more likely that the mix of Englishand Romanian contexts will be helpful.
However,it is also true that the Mix results in a significantimprovement for NATO-USA, and it seems likelythat the local perspective in Romania and the USAwould be somewhat different on these two entities.However, NATO-USA has a relatively large num-ber of contexts in Romanian as well as English, soperhaps the difference in perspective had less ofan impact in those cases where the number of Ro-30Table 3: Spanish Results (1994-95): Feature Se-lection Data, F-Measure, and Number of ContextsGeorge Bush (75.58) - Tony Blair (24.42)Mix 78.59 2,353Spanish 64.45 1,163English 54.29 1,190D.
Maradona (51.55) - R. Baggio (48.45)English 67.65 1,588Mix 61.35 3,594Spanish 60.70 2,006India (92.34) - Mexico (7.66)English 72.76 19,540Spanish 66.57 2,377Mix 61.54 21,917USA (62.30) - Paris (37.70)Spanish 69.31 1,000English 64.30 17,344Mix 59.40 18,344NATO (63.86) - USA (36.14)Spanish 62.04 2,172Mix 58.47 27,426English 56.00 25,254manian contexts is much smaller (as is the case forBeckham and Ronaldo).6.3 Spanish ResultsThe Spanish results are shown in Table 3.
TheSpanish and English contexts come from 1994-1995, which puts them in a slightly different his-torical era than the Bulgarian and Romanian cor-pora.Due to this temporal difference, we used DiegoMaradona and Roberto Baggio as a conflated pair,rather than David Beckham and Ronaldo, whowere much younger and somewhat less famous atthat time.
Also, Ronaldo is a highly ambiguousname in Spanish, as it is a very common first name.This is true in English text as well, although casualinspection of the English text from 2002 and 2004(where the Ronaldo-Beckham pair was includedexperimentally) reveals that Ronaldo the soccerplayer tends to occur more so than any other singleentity named Ronaldo, so while there is a bit morenoise for Ronaldo, there is not really a significantambiguity.For the Spanish results we only note one pair(George Bush - Tony Blair) where the Mix of En-glish and Spanish results in the best performance.This again suggests that the perspective of theSpanish and English corpora were similar with re-spect to these entities, and their combination washelpful.
In two other cases (Maradona-Baggio,India-Mexico) English only contexts achieve thehighest F-Measure, and then in the two remainingcases (USA-Paris, NATO-USA) the Spanish con-texts are the best source of features.Note that for Spanish we have reasonably largenumbers of contexts (as compared to Bulgarianand Romanian).
Given that, it is especially inter-esting that English-only contexts are the most ef-fective in two of five cases.
This suggests that thisapproach may have merit even when the evalua-tion language does not suffer from problems of ex-treme scarcity.
It may simply be that the informa-tion in the English corpora provides more discrim-inating information than does the Spanish, and thatit is somewhat different in content than the Span-ish, otherwise we would expect the Mix of Englishand Spanish contexts to do better than being mostaccurate for just one of five cases.7 DiscussionOf the 15 name conflate experiments (five pairs,three languages), in only five cases did the use ofthe evaluation contexts as a source of feature se-lection data result in better F-Measure scores thandid either using the English contexts alone or as aMix with the evaluation language contexts.
Thus,we conclude that there is a clear benefit to usingfeature selection data that comes from a differentlanguage than the one for which discrimination isbeing performed.We believe that this is due to the volume ofthe English data, as well as to the nature of thename discrimination task.
For example, a per-son is often best described or identified by observ-ing the people he or she tends to associate with,or the places he or she visits, or the companieswith which he or she does business.
If we ob-serve that George Miller and Mel Gibson occurtogether, then it seems we can safely infer thatGeorge Miller the movie director is being referredto, rather than George Miller the psychologist andfather of WordNet.This argument might suggest that first orderco?occurrences would be sufficient to discrimi-nate among the names.
That is, simply group theevaluation contexts based on the features that oc-cur within them, and essentially cluster evaluation31contexts based on the number of features they havein common with other evaluation contexts.
In fact,results on word sense discrimination (Purandareand Pedersen, 2004) suggest that first order rep-resentations are more effective with larger numberof context than second order methods.
However,we see examples in these results that suggests thismay not always be the case.
In the Bulgarian re-sults, the largest number of Bulgarian contexts arefor NATO-USA, but the Mix performs quite a bitbetter than Bulgarian only.
In the case of Roma-nian, again NATO-USA has the largest number ofcontexts, but the Mix still does better than Roma-nian only.
And in Spanish, Mexico-India has thelargest number of contexts and English-only doesbetter.
Thus, even in cases where we have an abun-dant number of evaluation contexts, the indirectnature of the second order representation providessome added benefit.We believe that the perspective of the news or-ganizations providing the corpora certainly has animpact on the results.
For example, in Romanian,the news about David Beckham and Ronaldo isprobably much the same as in the United States.These are international figures that are both ex-ternal to countries where the news originates, andthere is no reason to suppose there would be aunique local perspective represented by any of thenews sources.
The only difference among themmight be in the number of contexts available.
Inthis situation, the addition of the English contextsmay provide enough additional information to im-prove discrimination performance in another lan-guage.For example, in the 162 Romanian contextsfor Ronaldo-Beckham, there is one occurrence ofPosh, which was the stage name of Beckham?swife Victoria.
This is below our frequency cut-off threshold for feature selection, so it would bediscarded when using Romanian?only contexts.However, in the English contexts Posh is men-tioned 6 times, and is included as a feature.
Thus,the one occurrence of Posh in the Romanian cor-pus can be well represented by information foundin the English contexts, thus allowing that Roma-nian context to be correctly discriminated.8 ConclusionsThis paper shows that a method of name discrim-ination based on second order context representa-tions can take advantage of English contexts, andthe mix of English and evaluation contexts, in or-der to perform more accurate name discrimination.9 AcknowledgmentsThis research is supported by a National Sci-ence Foundation Faculty Early CAREER Devel-opment Award (#0092784).
All of the experimentsin this paper were carried out with version 0.71SenseClusters package, which is freely availablefrom http://senseclusters.sourceforge.net.ReferencesZ.
Harris.
1968.
Mathematical Structures of Lan-guage.
Wiley, New York.G.A.
Miller and W.G.
Charles.
1991.
Contextual cor-relates of semantic similarity.
Language and Cogni-tive Processes, 6(1):1?28.P.
Nakov and M. Hearst.
2003.
Category-based pseu-dowords.
In Companion Volume to the Proceedingsof HLT-NAACL 2003 - Short Papers, pages 67?69,Edmonton, Alberta, Canada, May 27 - June 1.T.
Pedersen and R. Bruce.
1997.
Distinguishing wordsenses in untagged text.
In Proceedings of the Sec-ond Conference on Empirical Methods in NaturalLanguage Processing, pages 197?207, Providence,RI, August.T.
Pedersen and A. Kulkarni.
2006.
Selecting ther?ightn?umber of senses based on clustering criterionfunctions.
In Proceedings of the Posters and DemoProgram of the Eleventh Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics, Trento, Italy, April.T.
Pedersen, A. Purandare, and A. Kulkarni.
2005.Name discrimination by clustering similar contexts.In Proceedings of the Sixth International Conferenceon Intelligent Text Processing and ComputationalLinguistics, pages 220?231, Mexico City, February.T.
Pedersen, A. Kulkarni, R. Angheluta, Z. Kozareva,and T. Solorio.
2006.
An unsupervised language in-dependent method of name discrimination using sec-ond order co-occurrence features.
In Proceedingsof the Seventh International Conference on Intelli-gent Text Processing and Computational Linguistics,pages 208?222, Mexico City, February.A.
Purandare and T. Pedersen.
2004.
Word sense dis-crimination by clustering contexts in vector and sim-ilarity spaces.
In Proceedings of the Conference onComputational Natural Language Learning, pages41?48, Boston, MA.H.
Schu?tze.
1998.
Automatic word sense discrimina-tion.
Computational Linguistics, 24(1):97?123.32
