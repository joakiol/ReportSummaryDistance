Squibs and DiscussionsEfficient Parsing for Korean and English:A Parameterized Message-Passing ApproachBonnie J. Dorr*University of MarylandJye-hoon Lee~University of MarylandDekang Lin tUniversity of Manitoba-WinnipegSungki Suh~Seoul National University1.
IntroductionThis article presents an efficient, implemented approach to cross-linguistic parsingbased on Government Binding (GB) Theory (Chomsky 1986) and followers.
One of thedrawbacks to alternative GB-based parsing approaches i  that they generally adopta filter-based paradigm.
These approaches typically generate all possible candidatestructures of the sentence that satisfy X theory, and then subsequently apply filtersin order to eliminate those structures that violate GB principles.
(See, for example,Abney 1989; Correa 1991; Dorr 1993; Fong 1991.)
The current approach provides analternative to filter-based esigns that avoids these difficulties by applying principlesto descriptions of structures without actually building the structures themselves.
Ourapproach is similar to that of Lin (1993) in that structure-building is deferred untilthe descriptions satisfy all principles; however, the current approach differs in thatit provides a parameterization mechanism along the lines of Dorr (1994) that allowsthe system to be ported to languages other than English.
We focus particularly on theproblem of processing head-final languages such as Korean.We are currently incorporating the parser into a machine translation (MT) systemcalled PRINCITRAN.
l In general, parsers of existing principle-based interlingual MTsystems are exceedingly inefficient, since they tend to adopt he filter-based paradigm.We combine the benefits of the message-passing paradigm with the benefits of theparameterized approach to build a more efficient, but easily extensible system, thatwill ultimately be used for MT.
The algorithm has been implemented in C++ andsuccessfully tested on well-known, translationally divergent sentences.We present a general framework for parsing by message passing and describe ourimplementation f GB principles as attribute-value constraints.
We then present heparameterization framework, demonstrating the feasibility of handling cross-linguisticvariation within the message-passing framework.
A technique for automatic precom-pilation of parameter settings is described.
Finally, we compare the efficiency of the* Department of Computer Science, University of Maryland, College Park, Maryland 20742.
E-mail:bonnie@cs.umd.edut Department of Computer SciencG University of Manitoba, Winnipeg, Manitoba, Canada, R3T 2N2.E-mail: lindek@cs.umanitoba.ca:~ Department of Computer Science, University of Maryland, College Park, MD 20742.
E-mail:jlee@cs.umd.edu?
Language Research Institute, Seoul National University, Seoul, 151-742, Korea.
E-maihsksuh@alliant.snu.ac.kr1 The name PRINCITRAN is derived from the names of two systems, UNITRAN (Door 1993) andPRINCIPAR (Lin 1993).~) 1995 Association for Computational LinguisticsComputational Linguistics Volume 21, Number 2,,', ,, Cbar ...../ ', ', C .
".,At"  ~.
1~1 " , "-..N IN I  ~ : Vk '  ./ i .
...............  \............................. UY-"English Grammar Network Korean Grammar Networkn   .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ :~ head domina e adjunct dominance complement dominance7 .
.
.
.
.
.
.
.
.
:~" mspecial izat i  specifier dominance barr ierFigure 1Network representation f English and Korean grammar.parser to that of the original CFG algorithm as well as Tomita's algorithm (Tomita1986) on a test suite of representative s ntences.
We argue that the efficiency of thesystem is not simply a side effect of using an efficient programming language (i.e.,C++), but that the algorithm is inherently efficient, independent of the programminglanguage used for the implementation.2.
Message Passing ParadigmThere has been a great deal of interest in exploring new paradigms of parsing, es-pecially nontraditional parallel architectures for natural language processing (Abney1989; Cottrell 1989; Selman and Hirst 1985, among many others).
Recent work (Steven-son 1994) provides a survey of symbolic, nonsymbolic, and hybrid approaches.
Steven-son's model comes the closest in design to the current principle-based message-passingmodel in that it uses distributed message passing as the basic underlying mechanismand it encodes GB principles directly (i.e., there are precise correspondences betweenfunctional components and linguistic principles).
However, the fundamental goals ofthe two approaches are different: Stevenson's objective concerns the modeling of hu-man processing behavior and producing a single parse at the end.
Her system in-corporates,a number of psycholinguistic-based processing mechanisms for handlingambiguity and making attachment decisions.
Our model, on the other hand, is moreconcerned with efficiency issues, broad-scale coverage, and cross-linguistic applica-bility; we produce all possible parse alternatives wherever disambiguation requiresextra-sentential nformation.We provide a language-independent processing mechanism that accommodates256Dorr et al Efficient Parsing for Korean and Englishstructurally different languages (e.g., head-initial vs. head-final) with equally efficientrun times.
The grammar for each language is encoded as a network of nodes thatrepresent grammatical categories (e.g., NP, Nbar, N) or subcategories, such as V:NP(i.e., a transitive verb that takes an NP as complement).
Figure 1 depicts portions ofthe grammar networks used for English and Korean.There are two types of links in the network: subsumption links (e.g., V to V:NP)and dominance links (e.g., Nbar to N).
A dominance link from c~ to fl is associatedwith an integer id that determines the linear order between fl and other categoriesimmediatelydominated by c~, and a binary attribute to specify whether fl is optionalor obligatory.
2Input sentences are parsed by passing messages in the grammar network.
Thenodes in the network are computing agents that communicate with each other bysending messages in the reverse direction of the links.
Each node locally stores a set ofitems.
An item is a triplet that represents an X structure ~: <surface-string, attribute-values, source-messages>, where surface-string is an integer interval \[i,j\] denoting thei'th to j'th word in the input sentence; attribute-values specifies syntactic features ofthe root node (fl); and source-messages is a set of messages that represent immediateconstituents of fl and from which this item is combined.
Each node has a completionpredicate that determines whether an item at the node is "complete," in which casethe item is sent as a message to other nodes.When a node receives an item, it attempts to form new items by combining itwith items from other nodes.
Two items, <\[il,jl\], A1, $1> and <\[i2,j2\], A2, $2>, canbe combined if: (1) their surface strings are adjacent to each other: i2 = jr+l; (2) theirattribute values A1 and A2 are unifiable; and (3) the source messages come via differentlinks: links(S1) N links(S2) = 0, where links(S) is a function that, given a set of messages,returns the set of links via which the messages arrived.
The result of the combinationis a new item, <\[il,j2\], unify(A1, A2), $1 t3 $2>.
Once a sentence has been parsed, thecorresponding parse trees are retrieved from a parse forest one by one.
Details aregiven in Lin (1993).3.
Implementation of PrinciplesGB principles are implemented as local constraints attached to nodes and percolationconstraints attached to links.
All items at a node must satisfy the node's local con-straint.
A message can be sent across a link only if it satisfies the link's percolationconstraint.
3 We will discuss three examples to illustrate the general idea of how GBprinciples are interpreted as local and percolation constraints.
See Lin (1993) for moredetails.3.1 X TheoryThe central idea behind X theory is that a phrasal constituent has a layered structure.Every phrasal constituent is considered to have a head (X ?
= X), which determines the2 For the purpose of readability, we have omitted integer id's in the graphical representation f thegrammar network.
Linear ordering is indicated by the starting points of links.
For example, C precedesIP in the English network of Figure 1.3 The idea of constraint application through feature passing among nodes is analogous to techniquesapplied in the TINA spoken language system (Seneff 1992) except hat, in our design, the grammarnetwork is a static data structure; it is not dynamically modified uring the parsing process.
Thus, weachieve a reduction space requirements.
Moreover, our design achieves a reduction in timerequirements because we do not retrieve a structure until the resulting parse descriptions satisfy all thenetwork constraints.257Computational Linguistics Volume 21, Number 2properties of the phrase containing it.
A phrase potentially contains a complement,resulting in a one-bar level (X = Xbar) projection; it may also contain a specifier (ormodifier), resulting in a double-bar level (X = XP) projection.
The phrasal representa-tion assumed in the current framework is the following:1.
\[xP Specifier \[Xbar Complement X\]\]We implement the relative positioning of Specifier, Complement, and Head constituentsby means of dominance links as shown in each of the networks of Figure 1.
In addi-tion, adjuncts are associated with the Xbar level by means of an adjunct-dominancelink in the grammar network.
The structure in I represents he relative order observedin Korean.3.2 Trace TheoryA trace represents a position from which some element has been extracted.
4 The mainconstraint of Trace Theory is the Subjacency Condition, which prohibits movementacross "too many" barriers.
(The notion of "too many" is specified on a per-languagebasis, as we will see shortly.
)An attribute named barr ier  is used to implement this principle.
A message con-taining the attribute value -barr ier  is used to represent an X structure containing aposition out of which a wh-constituent has moved, but without yet crossing a barrier.The value +barrier means that the movement has already crossed one barrier.
Certaindominance links in the network are designated as barrier links (indicated in Figure 1by solid rectangles).
The Subjacency condition is implemented by the percolation con-straints attached to the barrier links, which block any message with +barrier andchanges -barr ier  to +barrier (i.e., it allows the message to pass through).3.3 Case TheoryCase theory requires that every NP be assigned abstract case.
The Case Filter rules outsentences containing an NP with no case.
Case is assigned structurally to a syntacticposition governed by a case assigner.
Roughly, a preposition assigns Oblique Case toa prepositional object NP; a transitive verb assigns Accusative Case to a direct objectNP; and tensed Infl(ection) assigns Nominative Case to a subject NP.The implementation f case theory in our system is based on the following at-tribute values: ca, govern, era.
The attribute values +ca and +govern are assigned bylocal constraints to items representing phrases whose heads are case assigners (e.g.,tensed I) and governors (e.g., V), respectively.
A Case Filter violation is detected if anitem containing -cm is combined with another item containing -ca +govern.4.
Implementation of ParametersWhile the principles described in the previous ection are intended to be language-independent, the structure of each grammar network in Figure 1 is too language-specific to be applicable to languages other than the one for which it is designated.The most obvious language-specific feature is the ordering of head links with respectto complement links; in the graphical representation, link ordering of this type isindicated by the starting points of links, e.g., C precedes IP under Cbar since thelink leading to C is to the left of the link leading to IP.
In the English network, all4 A trace is represented as ti, where i is a unique index referring to an antecedent.258Dorr et al Efficient Parsing for Korean and Englishphrasal heads precede their complements.
In head-final anguages uch as Korean,the reverse order is required.
In order to capture this distinction, we incorporate theparameterization approach of Dorr (1994) into the message-passing framework so thatgrammar networks can be automatically generated on a per-language basis.The reason the message-passing paradigm is so well-suited to a pararneterizedmodel of language parsing is that, unlike head-driven models of parsing, the mainmessage-passing operation is capable of combining two nodes (in any order) in thegrammar network.
The result is that a head-final language such as Korean is as ef-ficiently parsed as a head-initial language such as English.
What is most interestingabout this approach is that the parameterized model is consistent with experimentalresults (see, for example, Suh \[1993\]) that suggest hat constituent structure is com-puted prior to the appearance of the head in Korean.We will first present our approach to parameterization f each subtheory of gram-mar and then describe the automatic onstruction of grammar networks for Englishand Korean using the parameter settings.4.1 X TheoryX theory assumes that a constituent order parameter is used for specifying phrasalordering on a per-language basis:.
Constituent Order: The relative order between the head and itscomplement can vary, depending on whether the language in question is(i) head-initial or (ii) head-final.The structure above represents the relative order observed in Korean, i.e., the head-final parameter setting (ii).
In English, the setting of this parameter is (i).
This orderinginformation is encoded in the grammar network by virtue of the relative ordering ofinteger id's associated with network links.4.2 Trace TheoryIn general, adjunct nodes are considered to be barriers to movement.
However, Koreanallows the head noun of a relative clause to be construed with the empty categoryacross more than one intervening adjunct node (CP), as shown in the following:.
\[CP \[CP tl t2 kyengyengha-ten\] hoysa2-ka manghayperi-n\] Billl-unyocum uykisochimhay issta\[cp \[cp managed-Rel\] company-Nora is bankrupt-Rel\] Bill-Topthese days depressed is'Bill, who is such a person that the company he was managing has beenbankrupt, is depressed these days'The subject NP 'Bill' is coindexed with the trace in the more deeply embeddedrelative clause.
If we assume, following Chomsky (1986), that relative clause formationinvolves movement from an inner clause into an outer subject position, then the gram-maticality of the above example suggests that the Trace theory must be parameterizedso that crossing more than one barrier is allowed in Korean.
Our formulation of thisparametric distinction is as follows:.
Barriers: (i) only one crossing permitted; (ii) more than one crossingpermitted.259Computational Linguistics Volume 21, Number 2In English the setting would be (i); in Korean the setting would be (ii).4.3 Case TheoryIn general, it is assumed that the relation between a case assigner and a case assignee isbiunique.
However, this assumption rules out so-called multiple subject constructions,which are commonly used in Korean:.
John-i phal-i pwureciessta-Nom arm-Nom was broken'John is in the situation that his arm has been broken'The grammaticality of the above example suggests that nominative case in Koreanmust be assigned by something other than tensed Infl(ection).
Thus, we parameterizecase assignment as follows:.
Case Assignment: Accusative case is assigned by transitive V;Nominative case is assigned by (i) tensed Infl(ection); (ii) IP predication.In a biunique case-assignment language such as English, the setting for Nomina-tive case assignment would be (i); in Korean, the settings would be (i) and (ii).4.4 Construction of Grammar Network from Parameter SettingsWe have just seen that certain types of syntactic parameterization may be captured inthe grammar network.
In addition to these, there are syntactic parameters that mustbe programmed into the message-passing mechanism itself, not just into the gram-mar network.
Our focus is on the automatic onstruction of the Korean and Englishgrammar networks from X parameter settings.
The grammar network constructionalgorithm consists of two steps: the first defines the basic structural description (i.e.,bar-level nodes); and the second defines the satellites (i.e., adjunct and specifier nodes).The English and Korean grammar networks in Figure 1 are the result of executing thisalgorithm on the Korean X parameter settings.5.
Results of Time Test ComparisonsAs a broad-coverage system, PRINCITRAN is very efficient.
The parsing component(PRINCIPAR) processes real-world sentences 20-30 words long from sources suchas the Wall Street Journal within a couple of seconds.
The complexity of the currentversion of the system has not yet been formally determined.
However, we claim thatthe efficiency of the system is not purely a result of using an efficient programminglanguage (C++); this has been achieved by running experiments that compare theperformance of the parser with two alternative CFG parsers.
Since PRINCIPAR has amuch broader coverage than these alternative approaches, the absolute measurementsdo not provide a complete picture of how these three systems compare.
However,the most interesting point is that the trends of the three performance l vels relative tosentence l ngth are essentially the same.
If PRINCIPAR had an average case complexitythat was exponential relative to sentence length, but had only managed to be efficientbecause of the implementation language, the sentence length vs. performance curvewould clearly be different from the curves for CFG parsers, which are known to havea worst case complexity that is polynomial relative to sentence length.The two CFG parsers used for comparison are: a C implementation of Tomita'sparser by Mark Hopkins (University of Wisconsin-Milwaukee, 1993) and the CFG260Dorr et al Efficient Parsing for Korean and English8.007.006.005.004.003.002.001.000.00\[\]5 10\[\]~ ?D ??
* 1 t *  \[\]?
nW~?
\[\]I I I15 20 25Sentence lengthI I30 35?
Principar \[\] Tomita ?
Lin-Goebel \]Figure 2Adjusted timings of three paTsers.parser in Lin and Goebel (1993).
The test sentences are from Tomita (1986).
There are40 of them.
The sentence lengths vary from 1 to 34 words with an average of 15.18.Both CFG parsers use the Grammar III in Tomita (1986, pp.
172-6), which contains 220rules, and a small lexicon containing only the words that appear in the test sentences.The lexicon in PR1NCIPAR, on the other hand, contains about 90,000 entries extractedfrom machine-readable dictionaries.Tomita's parser runs about 10 times faster than PRINCIPAR; Lin and Goebel'sruns about twice as fast.
To make the parsing time vs. sentence length distributionof these three parsers more comparable, we normalized the curves; the parsing timeof each of the CFG parses was multiplied by a constant so that they would have thesame average time as PRINCIPAR.
The adjusted timings are plotted in Figure 2.
Theseresults show that PRINCIPAR compares quite well with both CFG parsers.6.
Imp l i ca t ions  for  Mach ine  Trans lat ionOur ultimate objective is to incorporate the parameterized parser into an interlingualMT system.
The current framework is well suited to an interlingual design, since thelinking rules between the syntactic representations given above and the underlyinglexical-semantic representation are well defined.
We adopt Lexical Conceptual Struc-ture (LCS) and use a parameter-setting approach to handle well-known, translationallydivergent sentences.261Computational Linguistics Volume 21, Number 2Consider the following English and Korean sentences: 5...Structural Divergence:E: John married SallyK: John-i Sally-wa kyelhonhayssta-Nom -with married'John married with Sally'Conflational Divergence:E: John helped BillK: John-i Bill-eykey towum-ul cwuessta-Nom -Dative help-Acc gave'John gave help to Bill'Categorial Divergence:E: John is fond of musicK: John-un umak-ul coahanta-Nom music-Acc like'It is John (who) likes music'.15 seconds.12 seconds.10 seconds.19 seconds.12 seconds.07 secondsIn general, the times demonstrate a speedup of two to three orders of magnitude overprevious principle-based parsers on analogous examples uch as those given in Dorr(1993).
Even more significant is the negligible difference in processing time betweenthe two languages, despite radical differences in structure, particularly with respect ohead-complement positioning.
This is an improvement over previous parameterizedapproaches in which cross-linguistic divergences frequently induced timing discrep-ancies of one to two orders of magnitude due to the head-initial bias that underliesmost parsing designs.7.
Future Work and ConclusionsThree areas of future work are relevant o the current framework: (1) scaling up theKorean dictionary, which currently has only a handful of entries for testing purposes; 6(2) the installation of a Kimmo-based processor for handling Korean morphology; and(3) the incorporation of nonstructural parameterization (i.e., parameters not pertainingto X theory such as barriers and case assignment).A preliminary investigation has indicated that the message-passing paradigm isuseful for generation as well as parsing, thus providing a suitable framework forbidirectional translation.
Our algorithm for generation is similar to that of parsing inthat both construct a syntactic parse tree over an unstructured or partially structuredset of lexical items.
The difference is characterized as follows: in parsing, the inputsare sequences of words and the output is a structure produced by combining twoadjacent rees into a single tree at each processing step; in generation, the inputs area set of unordered words with dependency relationships derived from the interlingua5 The results hown above were obtained from running the program on a Sparcstation ELC.
These arenot necessarily geared toward demonstrating the full capability of the parser, which handles manytypes of syntactic phenomena, including complex movement types.
(See Lin \[1993\] for more details.
)Rather, these examples are intended to illustrate that the parser is able to handle translationallycontrastive sentences qually efficiently.6 Our English dictionary has 90,000 entries, constructed automatically by applying a set of conversionroutines to OALD entries.
We have begun negotiations with the LDC for the acquisition of a KoreanMRD, for which we intend to construct similar routines.262Dorr et al Efficient Parsing for Korean and English(LCS).
The generation algorithm must produce structures that satisfy the same set ofprinciples and constraints as the parsing algorithm.In summary, we have shown that the parametric message-passing design is an ef-ficient and portable approach to parsing.
We have automated the process of grammar-network construction and have demonstrated that the system handles well-known,translationally divergent sentences.AcknowledgmentsBonnie Dorr and her students, Jye-hoon Leeand Sungki Suh, have been partiallysupported by the Army Research Officeunder contract DAAL03-91-C-0034 throughBattelle Corporation, by the NationalScience Foundation under grant IRI-9120788and NYI IRI-9357731, and by the ArmyResearch Institute under contractMDA-903-92-R-0035 throughMicroelectronics and Design, Inc.Dekang Lin has been supported by NaturalSciences and Engineering Research Councilof Canada grant OGP121338.ReferencesAbney, S. (1989).
"A computational modelof human parsing."
Journal ofPsycholinguistic Research, 18(1), 129-144.Chomsky, N. (1986).
Knowledge of Language:Its Nature, Origin and Use.
MIT Press.Correa, N. (1991).
"Empty categories, chains,and parsing."
In Principle-Based Parsing:Computation and Psycholinguistics, editedby R. Berwick, S. Abney, and C. Tenny,83-121.
Kluwer Academic Publishers.Cottrell, G. (1989).
A Connectionist Approachto Word Sense Disambiguation.
MorganKaufmann.Dorr, B.
(1993).
Machine Translation: A Viewfrom the Lexicon.
MIT Press.Dorr, B.
(1994).
"Machine translationdivergences: A formal description andproposed solution."
ComputationalLinguistics, 20(4), 597-633.Fong, S. (1991).
"The computationalimplementation f principle-basedparsers."
In Principle-Based Parsing:Computation and Psycholinguistics, editedby R. Berwick, S. Abney, and C. Tenny,65-82.
Kluwer Academic Publishers.Lin, D. (1993).
"Principle-based parsingwithout overgeneration."
In Proceedings,ACL-93.
Columbus, Ohio, 112-120.Lin, D., and Goebel, R. (1993).
"Context-freegrammar parsing by message passing."
InProceedings, PACLING-93.
Vancouver, BC.Selman, B., and Hirst, G. (1985).
"Arule-based connectionist parsing system.
"In Proceedings, Seventh Annual Conference ofthe Cognitive Science Society.
212-219.Seneff, S. (1992).
"Tina: A natural anguagesystem for spoken language applications.
"Computational Linguistics, 18(1), 61-86.Stevenson, S. (1994).
A competitive attachmentmodel for resolving syntactic ambiguities innatural language parsing.
Doctoraldissertation, University of Maryland,College Park, MD.Suh, S. (1993).
"How to process constituentstructure in head final languages: Thecase of Korean."
In Proceedings, ChicagoLinguistic Society, No.
29.Tomita, M. (1986).
Efficient Parsing for NaturalLanguage.
Kluwer Academic Publishers.263
