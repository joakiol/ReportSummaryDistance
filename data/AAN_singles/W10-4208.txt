Towards a Programmable Instrumented GeneratorChris MellishComputing ScienceUniversity of AberdeenAB24 3UE, UKc.mellish@abdn.ac.ukAbstractIn this paper, we propose a general way of con-structing an NLG system that permits the system-atic exploration of the effects of particular systemchoices on output quality.
We call a system devel-oped according to this model a Programmable In-strumented Generator (PIG).
Although a PIG couldbe designed and implemented from scratch, it islikely that researchers would also want to createPIGs based on existing systems.
We therefore pro-pose an approach to ?instrumenting?
an NLG sys-tem so as to make it PIG-like.
To experiment withthe idea, we have produced code to support the?instrumenting?
of any NLG system written inJava.
We report on initial experiments with ?in-strumenting?
two existing systems and attemptingto ?tune?
them to produce text satisfying complexstylistic constraints.1 IntroductionExisting NLG systems are often fairly impenetra-ble pieces of code.
It is hard to see what an NLGsystem is doing and usually impossible to drive itin any way other than what was originally envis-aged.
This is particularly unfortunate if the systemis supposed to produce text satisfying complex sty-listic requirements.
Even when an NLG systemactually performs very well, it is hard to see whythis is or how particular generator decisions pro-duce the overall effects.
We propose a way ofbuilding systems that will permit more systematicexploration of decisions and their consequences, aswell as better exploitation of machine learning tomake these decisions better.
We call a system builtin this way a Programmable Instrumented Genera-tor (PIG).
As an initial exploration of the PIG idea,we have developed a general way of partially in-strumenting any NLG system written in Java andhave carried out two short experiments with exist-ing NLG systems.2 Controlling an NLG System: ExamplesNLG systems are frequently required to produceoutput that conforms to particular stylistic guide-lines.
Often conformance can only be tested at theend of the NLG pipeline, when a whole number ofcomplex strategic and tactical decisions have beenmade, resulting in a complete text.
A number ofrecent pieces of work have begun to address thequestion of how to tune systems in order to makethe decisions that lead to the most stylistically pre-ferred outputs.Paiva and Evans (2005) (henceforth PE) investi-gate controlling generator decisions for achievingstylistic goals, e.g.
choices between:The patient takes the two gram dose of the pa-tient?s medicine twice a day.andThe dose of the patient?s medicine is takentwice a day.
It is two grams.In this case, a stylistic goal of the system is ex-pressed as goal values for features SSi,  where eachSSi  expresses something that can be measured inthe output text, e.g.
counting the number of pro-nouns or passives.
The system learns to control thenumber of times specific binary generator deci-Figure 1: Example PERSONAGE rulesions are made (GDj), where these decisions in-volve things like whether to split the input into 2sentences or whether to generate an N PP clause.
Aprocess of offline training is first used to establishcorrespondences between counts of generator deci-sions and the values of the stylistic features.
Thisworks by running the system with multiple outputs(making decisions in many possible ways) andkeeping track of both the counts of the decisionsand also the values of the stylistic featuresachieved.
From this data the system then learnscorrelations between these:To actually generate a text given stylistic goals SSi,the system then uses an online control regime.
Ateach choice point, it considers making GDj versusnot GDj.
For each of these two, it estimates all theSSi that will be obtained for the complete text, us-ing the learned equations.
It prefers the choice thatminimises the sum of absolute differences betweenthese and the goal SSi, but is prepared to backtrackif necessary (best-first search).Mairesse and Walker (2008) (henceforth MW) usea different method for tuning their NLG system(?PERSONAGE?
), whose objective is to producetexts in the styles of writers with different person-ality types.
In this case, the system performancedepends on 67 parameters, e.g.
REPETITIONS(whether to repeat existing propositions), PERIOD(leave two sentences connected just with ?.
?, ratherthan any other connective) and NEGATION (ne-gate a verb and replace it by its antonym).
ForMW, offline training involves having the programgenerate a set of outputs with random values for allthe parameters.
Human judges estimate values forthe ?big five?
personality traits (e.g.
extroversion,neuroticism) for each output.
Machine learning isthen used to generate rules to predict how the pa-rameter values depend on the big five numbers.For instance, Figure 1 shows the rule predicting theSTUTTERING parameter.Once these rules are learned, online control to pro-duce text according to a given personality (speci-fied by numerical values for the big five traits)uses the learned models to set the parameters,which then determine NLG system behaviour.Human judges indeed recognise these personalitiesin the texts.3 Towards a PIGLooking at the previous two examples, one candetect some common features which could be usedin other situations:?
An NLG system able to generate random (orall possible) outputs?
Outputs which can be evaluated (by human ormachine)?
The logging of key NLG parameters/choices?
Learning of connections between parametersand output qualityjjjestii GDxxSSSS .0 ?+=?This then being used to drive the system to achievespecific goals more efficiently than before.PE and MW both constructed special NLG systemsfor their work.
One reason for this was that bothwanted to ensure that the underlying NLG systemallowed the kinds of stylistic variation that wouldbe relevant for their applications.
But also, in orderto be able to track the choices made by a generator,Paiva and Evans had to implement a new systemthat kept an explicit record of choices made.
Thisnew system also had to be able to organise thesearch through choices according to a best-firstsearch (it was possibly the first NLG system to bedriven in this way).
The only possibility for themwas to implement a new special purpose generatorfor their domain with the desired control character-istics.NLG systems are not usually immediately suitablefor tuning of this kind because they make choicesthat are not exposed for external inspection.
Alsothe way in which choices are made and the overallsearch strategy is usually hardwired in a way thatprevents easy changing.
It seems plausible that theapproaches of PE and MW would work to someextent for any NLG system that can tell you aboutits choices/ parameter settings, and for any stylisticgoal whose success can be measured in the text.Morever, these two are not the only ways onemight train/guide an NLG system from such in-formation (for instance, Hovy?s (1990) notion of?monitoring?
would be an alternative way of usinglearned rules to drive the choices of an NLG sys-tem).
It would be revealing if one could easilycompare different control regimes in a single ap-plication (e.g.
monitoring for PE?s task or best-firstsearch for MW?s), but this is currently difficultbecause the different systems already have particu-lar control built in.This discussion motivates the idea of developing ageneral methodology for the development of NLGsystems that permits the systematic exploration oflearning and control possibilities.
We call a systembuilt in such a way a Programmable InstrumentedGenerator (PIG).1  A PIG would be an NLG sys-1If one had a sufficiently expressive PIG then perhaps onecould train it for any testable stylistic goals ?
a kind of ?uni-versal?
NLG system?tem that implements standard NLG algorithms andcompetences but which is organised in a way thatpermits inspection and reuse.
It would be instru-mented, in that one would be able to track thechoices made in generating a text or texts, in orderto tune the performance.
It would also be pro-grammable in that it would be possible to drive thesystem in different ways according to a learned (orotherwise determined) ?policy?, e.g.
to:?
Generate all solutions (overgeneration)?
Generate solutions with some choicesfixed/constrained?
Generate solutions with user control of somedecisions?
Generate solutions using an in-built choicemechanism?
Generate solutions according to some globalsearch strategy (e.g.
monitoring, best-firstsearch)4 Using a PIGA general way of using a PIG is shown in Figure 2.A PIG interacts with a (conceptually) separateprocessing component, which we call the ?oracle?.This applies a policy to make choices for the gen-erator and receives evaluations of generated texts.It logs the choices made and (using machine learn-ing) can use this information to influence the pol-icy.There are two main modes in which the PIG can berun, though mixtures are also possible.
In (offline)training mode, the system is run on multiple inputsand uses random or exhaustive search to samplethe space of generatable texts.
The choices madeFigure 2: Using a PIGare logged, as is the quality of the outputs gener-ated.
In (online) execution mode, the PIG is run asa normal generator, running on a single input andmaking choices according to a learned policy.To support this, the PIG itself needs minimally tosupport provide external access to the followingfunction:generate(input:InputSpec) returns text:Stringwhich produces a text, from a given input specifi-cation.
On the other hand, the Oracle needs to pro-vide external access to at least the following (usedby the PIG):choice(question:String, suggestion:int,possibilities:ListOfString, state:String)returns decision:int  or RESTARToutcome(state:String, value:Float) (no return value)where question represents a choice to be made(with possible answers possibilities), suggestionis the index of a suggested choice and decision isthe index of the choice made.
state is a representa-tion of generator state, in some standard format(e.g.
ARFF (Hall et al2009)) and outcome (givingthe final state and the text quality) is called as thelast action of generating a text.
RESTART is aspecial value that by convention causes the systemto return to a state where it can be asked to gener-ate another text.To support the above, the PIG needs to maintainsome representation of program state.
Also the ora-cle needs to implement a training/testing algorithmthat involves providing the PIG with example in-puts, restarting the PIG on the current or a newexample, implementing a policy, logging resultsand possibly interacting with a user.The above model of how to use a PIG is partly mo-tivated by existing approaches to monitoring andtesting complex electronic equipment.
Testing isoften carried out by attaching ?automatic testequipment?
to the unit under test.
This automatictest equipment is akin to our ?oracle?
in that itdrives the unit through special test sequences andautomatically records what is going on.5 The PIG panelThere is a practical question of how best to buildPIGs and what resources there might be to supportthis.
Given their concern with explicit representa-tion of choices, NLG models based on SystemicGrammar (Bateman 1997) might well be promisingas a general framework here.
But in reality, NLGsystems are built using many different theoreticalapproaches, and most decisions are hard-coded in aconventional programming language.
In order toinvestigate the PIG concept further, therefore, wehave developed a general way of ?instrumenting?in a limited way any NLG system written in Java(giving rise to a PIGlet).
We have also imple-mented a general enough oracle for some initialexperiments to be made with a couple of PIGlets.This experimental work is in line with the APIgiven above but implemented in a way specific tothe Java language.In order to instrument the client generator, one hasto identify places where interesting choices aremade.
This is obviously best done by someonewith knowledge of the system.
There are a numberof ways to do this, but the simplest basically re-places a construct of the form:if (<condition>) <action>byif (Oracle.condRec(<name>,<condition>)) <action>where <name> is a string naming this particularchoice.
This allows the oracle to intervene whenthe choice is made, but possibly taking into ac-count the suggested answer (<condition>).The implemented oracle (the ?PIG panel?)
sup-ports a kind of ?single stepping?
of the generator(between successive choices), manual control ofchoices and restarting.
It has built in policies whichinclude random generation, following the choicessuggested by the PIGlet, systematic generation ofall possibilities (depth-first) and SARSA, a kind ofreinforcement learning (Sutton and Barto 1998).
Itprovides simple statistics about the evaluations ofthe texts generated using the current policy and auser interface (Figure 3).For the oracle to be able to control the PIGlet, itneeds to be provided with a ?connector?
whichrepresents it through a standard API (specifyinghow to generate a text, how to evaluate a text, whatexamples can be used, etc.).
This also includes aspecification of how to derive the ?state?
informa-tion about the generator which is logged for ma-chine learning process.
State information caninclude the number of times particular choices aremade (as in PE), the most recent choices made andother generator-specific parameters which arecommunicated to the oracle (as in MW).Finally the PIGlet and oracle are linked via a ?har-ness?
which specifies the basic mode of operation(essentially training vs execution).In the following sections, we describe two tentativeexperiments which produced PIGlets from existingNLG systems and investigated the use of the PIGpanel to support training of the system.
It is impor-tant to note that for these systems the instrument-ing was done by someone (the author) with limitedknowledge of the underlying NLG system and witha notion of text quality different from that used bythe original system.
Also, in both cases the limitedavailability of example data meant that testing hadto be performed on the training data (and so anypositive results may be partly due to overfitting).6 Experiment 1: Matching human textsFor this experiment, we took an NLG system thatproduces pollen forecasts and was written by RossTurner (Turner et al2006).
Turner collected 68examples of pollen prediction data for Scotland(each consisting of 6 small integers and a charac-terisation of the previous trend) with human-written forecasts, which we took as both our train-ing and test data.
We evaluated text quality bysimilarity to the human text, as measured by theMeteor metric (Lavie and Denkowski 2009).
Notethat the human forecasters had access to morebackground knowledge than the system, and so thisis not a task that the system would be expected todo particularly well on.The notion of program ?state?
that the oraclelogged took the form of the 6 input values, togetherwith the values of 7 choices made by the system(relating to the inclusion of trend information,thresholds for the words ?high?
and ?low?,whether to segment the data and whether to includehay fever information).The system was trained by generating about 10000random texts (making random decisions for ran-domly selected examples).
For each, the numericaloutcome (Meteor score) and state information wasrecorded.
The half of the resulting data with high-est outcomes was extracted and used to predictrules for the 7 choices, given the 6 input parame-ters (we used Weka (Hall et al2009) with the JRipalgorithm).
The resulting rules were transcribedinto a specific ?policy?
(Java class) for the oracle.Applied to the 68 examples, trying random genera-tion for 3 times on each, the system obtained anaverage Meteor score of 0.265.
Following theoriginal system?s suggestions produced an averagescore of 0.279.
Following the learned policy, thesystem also obtained an average of 0.279.
The dif-ference between the learned behaviour and randomgeneration is significant (p =0.002) according to a ttest.7 Experiment 2: Text length controlA challenging stylistic requirement for NLG is thatof producing a text satisfying precise length re-quirements (Reiter 2000).
For this experiment, wetook the EleonPlus NLG system developed byHien Nguyen.
This combines the existing Eleonuser interface for domain authoring (Bilidas et al2007) with a new NLG system that incorporatesthe SimpleNLG realiser (Gatt and Reiter 2009).Figure 3: PIG Panel interfaceThe system was used for a simple domain of textsabout university buildings.
The data used was theauthored information about 7 university buildingsand associated objects.
We evaluated texts using asimple (character) length criterion, where the idealtext was 250 characters, with a steeply increasingpenalty for texts longer than this and a slowly in-creasing penalty for texts that are shorter.The notion of ?state?
that was logged took accountof the depth of the traversal of the domain data, themaximum number of facts per sentence and an ag-gregation decision.Following the previous successful demonstrationof reinforcement learning for NLG decisions (Rie-ser and Lemon 2006), we decided to use theSARSA approach (though without function ap-proximation) for the training.
This involves re-warding individual states for their (direct orindirect) influence on outcome quality as the sys-tem actually performs.
The policy is a mixture ofrandom exploration and the choosing of the cur-rently most promising states, according to thevalue of a numerical parameter ?.Running the system on the 7 examples with 3 ran-dom generations for each produced an average textquality of -2514.
We tried a SARSA training re-gime with 3000 random examples at ?=0.1, fol-lowed by 2000 random examples at ?=0.001.Following this, we looked at performance on the 7examples with ?=0.
The average text quality was -149.
This was exactly the same quality as thatachieved by following the original NLG system?spolicy.
Even though there is a large difference inaverage quality between random generation andthe learned policy, this is, however, not statisticallysignificant (p = 0.12) because of the small numberof examples and large variation between text quali-ties.8 Conclusions and Further WorkEach of our initial experiments was carried out bya single person in less than a week of work, (whichincluded some concurrent development of the PIGpanel software and some initial exploration of theunderlying NLG system).
This shows that it is rela-tively quick (even with limited knowledge of theoriginal NLG system) for someone to instrumentan existing NLG system and to begin to investigateways of optimizing its performance (perhaps withdifferent goals than it was originally built for).This result is probably more important than theparticular results achieved (though it is promisingthat some are statistically significant).Further work on the general software could focuson the issue of the visualization of choices.
Here itmight be interesting to impose a Systemic networkdescription on the interdependencies betweenchoices, even when the underlying system is builtwith quite a different methodology.More important, however, is to develop a betterunderstanding of what sorts of behaviour in anNLG system can be exposed to machine learningto optimize the satisfaction of what kinds of stylis-tic goals.
Also we need to develop methodologiesfor systematically exploring the possibilities, interms of the characterization of NLG system stateand the types of learning that are attempted.
It is tobe hoped that software of the kind we have devel-oped here will help to make these tasks easier.Finally, this paper has described the developmentand use of PIGs mainly from the point of view ofmaking the best of NLG systems rather like whatwe already have.
The separation of logic and con-trol supported by the PIG architecture couldchange the way we think about NLG systems inthe first place.
For instance, a PIG could easily bemade to overgenerate (in the manner, for instance,of HALOGEN (Langkilde-Geary 2003)), in theconfidence that an oracle could later be devisedthat appropriately weeded out non-productivepaths.AcknowledgmentsThis work was supported by EPSRC grantEP/E011764/1.
The ideas here have benefited par-ticularly from discussions with Graeme Ritchie andRoger Evans.
We also acknowledge the helpfulcomments of two anonymous reviewers.ReferencesJohn Bateman.
1997.
Enabling technology for multilin-gual natural language generation: the KPML devel-opment environment.
Natural Language Engineering3(1):15-55.Dimitris Bilidas,   MariaTheologou and VangelisKarkaletsis.
2007.
Enriching OWL Ontologies withLinguistic and User-Related Annotations: TheELEON System.
Proceedings of the IEEE Interna-tional Conference on Tools with Artificial Intelli-gence (ICTAI), Patra, Greece.Albert Gatt and Ehud Reiter.
2009.
SimpleNLG: A re-alisation engine for practical applications.
Proceed-ings of ENLG-2009.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann and Ian H. Witten.2009.
The WEKA Data Mining Software: An Up-date; SIGKDD Explorations, Volume 11, Issue 1.Eduard H. Hovy.
1990.
Pragmatics and Natural Lan-guage Generation.
Artificial Intelligence 43(2), pp.153?198.Alon Lavie and Michael Denkowski.
2009.
TheMETEOR Metric for Automatic Evaluation of Ma-chine Translation.
Machine Translation, publishedonline 1st November 2009.Irene Langkilde-Geary.
2003.
A foundation for general-purpose natural language generation: sentence reali-zation using probabilistic  models of language.
PhDthesis,  University of Southern California, Los Ange-les, USA.Fran?ois Mairesse and Marilyn Walker.
2008.
TrainableGeneration of Big-Five Personality Styles throughData-driven Parameter Estimation.
In Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics (ACL), Columbus.Daniel Paiva and Roger Evans.
2005.
Empirically-basedcontrol of natural language generation.
Proceedingsof the 43rd Annual Meeting of the ACL, pages 58-65.Ehud Reiter.
2000.
Pipelines and Size Constraints.
Com-putational Linguistics.
26:251-259.Verena Rieser and Oliver Lemon.
2006.
Using MachineLearning to Explore Human Multimodal ClarificationStrategies.
Procs of  ACL 2006.Richard S. Sutton and Andrew G. Barto.
1998.
Rein-forcement Learning: An Introduction.
MIT Press,Cambridge, MA.Ross Turner, Yaji Sripada, Ehud Reiter and Ian Davy.2006.
Generating Spatio-Temporal Descriptions inPollen Forecasts.
Proceedings of EACL06 Compan-ion Volume.
