Extending corpus-based identification of light verb constructionsusing a supervised learning frameworkYee Fan Tan, Min-Yen Kan and Hang CuiDepartment of Computer ScienceNational University of Singapore3 Science Drive 2, Singapore 117543{tanyeefa, kanmy, cuihang}@comp.nus.edu.sgAbstractLight verb constructions (LVCs), such as?make a call?
in English, can be saidto be complex predicates in which theverb plays only a functional role.
LVCspose challenges for natural language un-derstanding, as their semantics differ fromusual predicate structures.
We extend theexisting corpus-based measures for iden-tifying LVCs between verb-object pairsin English, by proposing using new fea-tures that use mutual information and as-sess other syntactic properties.
Our workalso incorporates both existing and newLVC features into a machine learning ap-proach.
We experimentally show that us-ing the proposed framework incorporat-ing all features outperforms previous workby 17%.
As machine learning techniquesmodel the trends found in training data,we believe the proposed LVC detectionframework and statistical features is easilyextendable to other languages.1 IntroductionMany applications in natural language processingrely on the relationships between words in a docu-ment.
Verbs play a central role in many such tasks;for example, the assignment of semantic rolesto noun phrases in a sentence heavily dependson the verb that link the noun phrases together(as in ?Pierre Vinken/SUBJ, will join/PRED, theboard/OBJ?
).However, verb processing is difficult because ofmany phenomena, such as normalization of ac-tions, verb particle constructions and light verbconstructions.
Applications that process verbsmust handle these cases effectively.
We focus onthe identification of light verb constructions (alsoknown as support verb constructions) in English,as such constructions play a prominent and pro-ductive role in many other languages (Butt andGeuder, 2001; Miyamoto, 2000).
Although theexact definition of a LVC varies in the literature,we use the following operational definition:A light verb construction (LVC) is averb-complement pair in which the verbhas little lexical meaning (is ?light?)
andmuch of the semantic content of the con-struction is obtained from the comple-ment.Examples of LVCs in English include ?give aspeech?, ?make good (on)?
and ?take (NP) intoaccount?.
In the case in which the complement is anoun, it is often a deverbal noun and, as such, canusually be paraphrased using the object?s root verbform without (much) loss in its meaning (e.g., takea walk ?
walk, make a decision ?
decide, give aspeech ?
speak).We propose a corpus-based approach to de-termine whether a verb-object pair is a LVC.Note that we limit the scope of LVC detection toLVCs consisting of verbs with noun complements.Specifically, we extend previous work done byothers by examining how the local context of thecandidate construction and the corpus-wide fre-quency of related words to the construction playan influence on the lightness of the verb.A second contribution is to integrate our newfeatures with previously reported ones under a ma-chine learning framework.
This framework op-timizes the weights for these measures automati-cally against a training corpus in supervised learn-ing, and attests to the significant modeling im-49provements of our features on our corpus.
Ourcorpus-based evaluation shows that the combina-tion of previous work and our new features im-proves LVC detection significantly over previouswork.An advantage gained by adopting a machinelearning framework is that it can be easily adaptedto other languages that also exhibit light verbs.While we perform evaluations on English, lightverbs exist in most other languages.
In some ofthese languages, such as Persian, most actions areexpressed as LVCs rather than single-word verbs(Butt, 2003).
As such, there is currently a un-met demand for developing an adaptable frame-work for LVC detection that applies across lan-guages.
We believe the features proposed in thispaper would also be effective in identifying lightverbs in other languages.We first review previous corpus-based ap-proaches to LVC detection in Section 2.
In Section3, we show how we extend the use of mutual infor-mation and employ context modeling as featuresfor improved LVC detection.
We next describe ourcorpus processing and how we compiled our goldstandard judgments used for supervised machinelearning.
In Section 4, we evaluate several featurecombinations before concluding the paper.2 Related WorkWith the recent availability of large corpora, statis-tical methods that leverage syntactic features are acurrent trend.
This is the case for LVC detectionas well.Grefenstette and Teufel (1995) considered asimilar task of identifying the most probable lightverb for a given deverbal noun.
Their approach fo-cused on the deverbal noun and occurrences of thenoun?s verbal form, arguing that the deverbal nounretains much of the verbal characteristics in theLVCs.
To distinguish the LVC from other verb-object pairs, the deverbal noun must share similarargument/adjunct structures with its verbal coun-terpart.
Verbs that appear often with these char-acteristic deverbal noun forms are deemed lightverbs.
They approximate the identification of ar-gument/adjunct structures by using the prepositionhead of prepositional phrases that occur after theverb or object of interest.Let n be a deverbal noun whose most likelylight verb is to be found.
Denote its verbal form byv?, and let P be the set containing the three mostfrequently occurring prepositions that occur afterv?.
The verb-object pairs that are not followed bya preposition in P are filtered out.
For any verbv, let g(v, n) be the count of verb-object pairs v-nthat remain after the filtering step above.
Grefen-stette and Teufel proposed that the light verb for nbe returned by the following equation:GT95(n) = argmaxvg(v, n) (1)Interestingly, Grefenstette and Teufel indicatedthat their subsequent experiments suggested thatthe filtering step may not be necessary.Whereas the GT95 measure centers on the de-verbal object, Dras and Johnson (1996) also con-sider the verb?s corpus frequency.
The use of thiscomplementary information improves LVC iden-tification, as it models the inherent bias of someverbs to be used more often as light verbs than oth-ers.
Let f(v, n) be the count of verb-object pairsoccurring in the corpus, such that v is the verb, nis a deverbal noun.
Then, the most probable lightverb for n is given by:DJ96(n) = argmaxvf(v, n)?nf(v, n) (2)Stevenson et al (2004)?s research examines ev-idence from constructions featuring determiners.They focused on expressions of the form v-a-nand v-det-n, where v is a light verb, n is a de-verbal noun, a is an indefinite determiner (namely,?a?
or ?an?
), and det is any determiner other thanthe indefinite.
Examples of such constructions are?give a speech?
and ?take a walk?.
They employmutual information which measures the frequencyof co-occurrences of two variables, corrected forrandom agreement.
Let I(x, y) be the mutual in-formation between x and y.
Then the followingmeasure can be used:SFN04(v, n) = 2?
I(v, a-n)?
I(v, det-n), (3)where higher values indicate a higher likelihood ofv-a-n being a light verb construction.
Also, theysuggested that the determiner ?the?
be excludedfrom the development data since it frequently oc-curred in their data.Recently, Fazly et al (2005) have proposed astatistical measure for the detection of LVCs.
Theprobability that a verb-object pair v-n (where v is alight verb) is a LVC can be expressed as a productof three probabilities: (1) probability of the object50n occurring in the corpus, (2) the probability that nis part of any LVC given n, and (3) the probabilityof v occurring given n and that v-n is a LVC.
Eachof these three probabilities can then be estimatedby the frequency of occurrence in the corpus, us-ing the assumption that all instances of v?-a-n is aLVC, where v?
is any light verb and a is an indefi-nite determiner.To summarize, research in LVC detectionstarted by developing single measures that utilizedsimple frequency counts of verbs and their com-plements.
From this starting point, research hasdeveloped in two different directions: using moreinformed measures for word association (specifi-cally, mutual information) and modeling the con-text of the verb-complement pair.Both the GT95 and DJ96 measures suffer fromusing frequency counts directly.
Verbs that are notlight but occur very frequently (such as ?buy?
and?sell?
in the Wall Street Journal) will be marked bythese measures.
As such, given a deverbal noun,they sometimes suggest verbs that are not light.We hypothesize that substituting MI for frequencycount can alleviate this problem.The SFN04 metric adds in the context providedby determiners to augment LVC detection.
Thismeasure may work well for LVCs that are markedby determiners, but excludes a large portion ofLVCs that are composed without determiners.
Todesign a robust LVC detector requires integratingsuch specific contextual evidence with other gen-eral evidence.Building on this, Fazly et al (2005) incorpo-rate an estimation of the probability that a cer-tain noun is part of a LVC.
However, like SFN04,LVCs without determiners are excluded.3 Framework and FeaturesPrevious work has shown that different measuresbased on corpus statistics can assist in LVC detec-tion.
However, it is not clear to what degree thesedifferent measures overlap and can be used to re-inforce each other?s results.
We solve this problemby viewing LVC detection as a supervised clas-sification problem.
Such a framework can inte-grate the various measures and enable us to testtheir combinations in a generic manner.
Specifi-cally, each verb-object pair constitutes an individ-ual classification instance, which possesses a setof features f1, .
.
.
, fn and is assigned a class labelfrom the binary classification of {LV C,?LV C}.In such a machine learning framework, each of theaforementioned metrics are separate features.In our work, we have examined three differentsets of features for LVC classification: (1) base,(2) extended and (3) new features.
We start by de-riving three base features from key LVC detectionmeasures as described by previous work ?
GT95,DJ96 and SFN04.
As suggested in the previoussection, we can make alternate formulations of thepast work, such as to discard a pre-filtering step(i.e.
filtering of constructions that do not includethe top three most frequent prepositions).
Thesemeasures make up the extended feature set.
Thethird set of features are new and have not beenused for LVC identification before.
These includefeatures that further model the influence of context(e.g.
prepositions after the object) in LVC detec-tion.3.1 Base FeaturesThese features are based on the original previ-ous work discussed in Section 2, but have beenadapted to give a numeric score.
We use the ini-tials of the original authors without year of publi-cation to denote our derived base features.Recall that the aim of the original GT95 andDJ96 formulae is to rank the possible supportverbs given a deverbal noun.
As each of these for-mulae contain a function which returns a numericscore inside the argmaxv, we use these functionsas two of our base features:GT(v, n) = g(v, n) (4)DJ(v, n) = f(v, n)?nf(v, n) (5)The SFN04 measure can be used without modifi-cation as our third base feature, and it will be re-ferred to as SFN for the remainder of this paper.3.2 Extended FeaturesSince Grefenstette and Teufel indicated that thefiltering step might not be necessary, i.e., f(v, n)may be used instead of g(v, n), we also have thefollowing extended feature:FREQ(v, n) = f(v, n) (6)In addition, we experiment with the reverse pro-cess for the DJ feature, i.e., to replace f(v, n) inthe function for DJ with g(v, n), yielding the fol-lowing extended feature:DJ-FILTER(v, n) = g(v, n)?ng(v, n) (7)51In Grefenstette and Teufel?s experiments, theyused the top three prepositions for filtering.
Wefurther experiment with using all possible prepo-sitions.3.3 New FeaturesIn our new feature set, we introduce features thatwe feel better model the v and n components aswell as their joint occurrences v-n. We also intro-duce features that model the v-n pair?s context, interms of deverbal counts, derived from our under-standing of LVCs.Most of these new features we propose are notgood measures for LVC detection by themselves.However, the additional evidence that they givecan be combined with the base features to createa better composite classification system.Mutual information: We observe that a verb vand a deverbal noun n are more likely to appearin verb-object pairs if they can form a LVC.
Tocapture this evidence, we employ mutual informa-tion to measure the co-occurrences of a verb anda noun in verb-object pairs.
Formally, the mutualinformation between a verb v and a deverbal nounn is defined asI(v, n) = log2P (v, n)P (v)P (n) , (8)where P (v, n) denotes the probability of v and nconstructing verb-object pairs.
P (v) is the prob-ability of occurrence of v and P (n) representsthe probability of occurrence of n. Let f(v, n)be the frequency of occurrence of the verb-objectpair v-n and N be the number of all verb-objectpairs in the corpus.
We can estimate the aboveprobabilities using their maximum likelihood esti-mates: P (v, n) = f(v,n)N , P (v) =Pn f(v,n)N andP (n) =Pv f(v,n)N .However, I(v, n) only measures the local in-formation of co-occurrences between v and n. Itdoes not capture the global frequency of verb-object pair v-n, which is demonstrated as effectiveby Dras and Johnson (1996).
As such, we needto combine the local mutual information with theglobal frequency of the verb-object pair.
We thuscreate the following feature, where the log func-tion is used to smooth frequencies:MI-LOGFREQ = I(v, n)?
log2f(v, n) (9)Deverbal counts: Suppose a verb-object pair v-n is a LVC and the object n should be a dever-bal noun.
We denote v?
to be the verbalized formof n. We thus expect that v-n should express thesame semantic meaning as that of v?.
However,verb-object pairs such as ?have time?
and ?haveright?
in English scored high by the DJ and MI-LOGFREQ measures, even though the verbalizedform of their objects, i.e., ?time?
and ?right?, donot express the same meaning as the verb-objectpairs do.
This is corroborated by Grefenstette andTeufel claim that if a verb-object pair v-n is aLVC, then n should share similar properties withv?.
Based on our empirical analysis on the corpususing a small subset of LVCs, we believe that:1.
The frequencies of n and v?
should not differvery much, and2.
Both frequencies are high given the fact thatLVCs occur frequently in the text.The first observation is true in our corpus wherelight verb and verbalized forms are freely inter-changable in contexts.
Then, let us denote the fre-quencies of n and v?
to be f(n) and f(v?)
respec-tively.
We devise a novel feature based on the hy-potheses:min(f(n), f(v?
))max(f(n), f(v?))
?min(f(n), f(v?))
(10)where the two terms correspond to the above twohypotheses respectively.
A higher score from thismetric indicates a higher likelihood of the com-pound being a LVC.Light verb classes: Linguistic studies of lightverbs have indicated that verbs of specific seman-tic character are much more likely to participate inLVCs (Wang, 2004; Miyamoto, 2000; Butt, 2003;Bjerre, 1999).
Such characteristics have beenshown to be cross-language and include verbs thatindicate (change of) possession (Danish give, togive, direction (Chinese guan diao to switch off),aspect and causation, or are thematically incom-plete (Japanese suru, to do).
As such, it makessense to have a list of verbs that are often usedlightly.
In our work, we have predefined a lightverb list for our English experiment as exactlythe following seven verbs: ?do?, ?get?, ?give?,?have?, ?make?, ?put?
and ?take?, all of whichhave been studied as light verbs in the literature.We thus define a feature that considers the verb inthe verb-object pair: if the verb is in the prede-fined light verb list, the feature value is the verbitself; otherwise, the feature value is another de-fault value.52One may ask whether this feature is necessary,given the various features used to measure the fre-quency of the verb.
As all of the other metrics arecorpus-based, they rely on the corpus to be a repre-sentative sample of the source language.
Since weextract the verb-object pairs from the Wall StreetJournal section of the Penn Treebank, terms like?buy?, ?sell?, ?buy share?
and ?sell share?
occurfrequently in the corpus that verb-object pairs suchas ?buy share?
and ?sell share?
are ranked high bymost of the measures.
However, ?buy?
and ?sell?are not considered as light verbs.
In addition,the various light verbs have different behaviors.Despite their lightness, different light verbs com-bined with the same noun complement often givesdifferent semantics, and hence affect the lightnessof the verb-object pair.
For example, one may saythat ?make copy?
is lighter than ?put copy?.
Incor-porating this small amount of linguistic knowledgeinto our corpus-based framework can enhance per-formance.Other features: In addition to the above fea-tures, we also used the following features: the de-terminer before the object, the adjective before theobject, the identity of any preposition immediatelyfollowing the object, the length of the noun object(if a phrase) and the number of words between theverb and its object.
These features did not improveperformance significantly, so we have omitted adetailed description of these features.4 EvaluationIn this section, we report the details of our exper-imental settings and results.
First, we show howwe constructed our labeled LVC corpus, used asthe gold standard in both training and testing un-der cross validation.
Second, we describe the eval-uation setup and discuss the experimental resultsobtained based on the labeled data.4.1 Data PreparationSome of the features rely on a correct sentenceparse.
In order to minimize this source of error,we employ the Wall Street Journal section in thePenn Treebank, which has been manually parsedby linguists.
We extract verb-object pairs from thePenn Treebank corpus and lemmatize them usingWordNet?s morphology module.
As a filter, we re-quire that a pair?s object be a deverbal noun to beconsidered as a LVC.
Specifically, we use Word-Net to check whether a noun has a verb as one ofits derivationally-related forms.
A total of 24,647candidate verb-object pairs are extracted, of which15,707 are unique.As the resulting dataset is too large for completemanual annotation given our resources, we sam-ple the verb-object pairs from the extracted set.As most verb-object pairs are not LVCs, randomsampling would provide very few positive LVC in-stances, and thus would adversely affect the train-ing of the classifier due to sparse data.
Our aim inthe sampling is to have balanced numbers of po-tential positive and negative instances.
Based onthe 24,647 verb-object pairs, we count the corpusfrequencies of each verb v and each object n, de-noted as f(v) and f(n).
We also calculate the DJscore of the verb-object pair DJ(v, n) by countingthe pair frequencies.
The data set is divided into5 bins using f(v) on a linear scale, 5 bins usingf(n) on a linear scale and 4 bins using DJ(v, n)on a logarithmic scale.1 We cross-multiply thesethree factors to generate 5 ?
5 ?
4 = 100 bins.Finally, we uniformly sampled 2,840 verb-objectpairs from all the bins to construct the data set forlabeling.4.2 AnnotationAs noted by many linguistic studies, the verb ina LVC is often not completely vacuous, as theycan serve to emphasize the proposition?s aspect,its argument?s semantics (cf., ?
roles) (Miyamoto,2000), or other function (Butt and Geuder, 2001).As such, previous computational research had pro-posed that the ?lightness?
of a LVC might be bestmodeled as a continuum as opposed to a binaryclass (Stevenson et al, 2004).
We have thus anno-tated for two levels of lightness in our annotationof the verb-object pairs.
Since the purpose of thework reported here is to flag all such constructions,we have simplified our task to a binary decision,similar to most other previous corpus-based work.A website was set up for the annotation task,so that annotators can participate interactively.For each selected verb-object pair, a question isconstructed by displaying the sentence where theverb-object pair is extracted, as well as the verb-object pair itself.
The annotator is then askedwhether the presented verb-object pair is a LVCgiven the context of the sentence, and he or shewill choose from the following options: (1) Yes,1Binning is the process of grouping measured data intodata classes or histogram bins.53(2) Not sure, (3) No.
The following three sen-tences illustrate the options.
(1) Yes ?
A Compaq Computer Corp.spokeswoman said that the companyhasn?t made a decision yet, although ?it isn?tunder active consideration.?
(2) Not Sure ?
Besides money, criminals havealso used computers to steal secrets and in-telligence, the newspaper said, but it gave nomore details.
(3) No ?
But most companies are too afraid totake that chance.The three authors, all natural language process-ing researchers, took part in the annotation task,and we asked all three of them to annotate on thesame data.
In total, we collected annotations for741 questions.
The average correlation coefficientbetween the three annotators is r = 0.654, whichindicates fairly strong agreement between the an-notators.
We constructed the gold standard databy considering the median of the three annotationsfor each question.
Two gold standard data sets arecreated:?
Strict ?
In the strict data set, a verb-objectpair is considered to be a LVC if the medianannotation is 1.?
Lenient ?
In the lenient data set, a verb-object pair is considered to be a LVC if themedian annotation is either 1 or 2.Each of the strict and lenient data sets have 741verb-object pairs.4.3 ExperimentsWe have two aims for the experiments: (1) to com-pare between the various base features and the ex-tended features, and (2) to evaluate the effective-ness of our new features.Using the Weka data mining toolkit (Wittenand Frank, 2000), we have run a series of ex-periments with different machine learning algo-rithms.
However, since our focus of the exper-iments is to determine which features are usefuland not to evaluate the machine learners, we re-port the results achieved by the best single clas-sifier without additional tuning, the random for-est classifier (Breiman, 2001).
Stratified ten-foldcross-validation is performed.
The evaluation cri-teria used is the F1-measure on the LV C class,which is defined asF1=2PRP + R, (11)where P and R are the precision and recall for theLV C class respectively.4.3.1 Base and Extended FeaturesRegarding the first aim, we make the followingcomparisons:?
GT (top 3 prepositions) versus GT (all prepo-sitions) and FREQ?
DJ versus DJ-FILTER (top 3 prepositions andall prepositions)Feature Strict LenientGT (3 preps) 0.231 0.163GT (all preps) 0.272 0.219FREQ 0.289 0.338DJ 0.491 0.616DJ-FILTER (3 preps) 0.433 0.494DJ-FILTER (all preps) 0.429 0.503SFN 0.000 0.000Table 1: F1-measures of base features and ex-tended features.We first present the results for the base featuresand the extended features in Table 1.
From theseresults, we make the following observations:?
Overall, DJ and DJ-FILTER perform betterthan GT and FREQ.
This is consistent withthe results by Dras and Johnson (1996).?
The results for both GT/FREQ and DJ showthat filtering using preposition does not im-pact performance significantly.
We believethat the main reason for this is that the fil-tering process causes information to be lost.163 of the 741 verb-object pairs in the corpusdo not have a preposition following the objectand hence cannot be properly classified usingthe features with filtering.?
The SFN metric does not appear to work withour corpus.
We suspect that it requires a farlarger corpus than our corpus of 24,647 verb-object pairs to work.
Stevenson et al (2004)54have used a corpus whose estimated size is atleast 15.7 billion, the number of hits returnedin a Google search for the query ?the?
as ofFebruary 2006.
The large corpus requirementis thus a main weakness of the SFN metric.4.3.2 New FeaturesWe now evaluate the effectiveness of our classof new features.
Here, we do not report results ofclassification using only the new features, becausethese features alone are not intended to constitute astand-alone measure of the lightness.
As such, weevaluate these new features by adding them on topof the base features.
We first construct a full fea-ture set by utilizing the base features (GT, DJ andSFN) and all the new features.
We chose not to addthe extended features to the full feature set becausethese extended features are not independent to thebase features.
Next, to show the effectiveness ofeach new feature individually, we remove it fromthe full feature set and show the performance ofclassifier without it.Feature(s) Strict LenientGT (3 preps) 0.231 0.163DJ 0.491 0.616SFN 0.000 0.000GT (3 preps) + DJ + SFN 0.537 0.676FULL 0.576 0.689- MI-LOGFREQ 0.545 0.660- DEVERBAL 0.565 0.676- LV-CLASS 0.532 0.640Table 2: F1-measures of the various feature com-binations for our evaluation.Table 2 shows the resulting F1-measures whenusing various sets of features in our experiments.2We make the following observations:?
The combinations of features outperform theindividual features.
We observe that using in-dividual base features alone can achieve thehighest F1-measure of 0.491 on the strict dataset and 0.616 on the lenient data set respec-tively.
When applying the combination ofall base features, the F1-measures on both2For the strict data set, the base feature set has a preci-sion and recall of 0.674 and 0.446 respectively, while the fullfeature set has a precision and recall of 0.642 and 0.523 re-spectively.
For the lenient data set, the base feature set has aprecision and recall of 0.778 and 0.598 respectively, while thefull feature set has a precision and recall of 0.768 and 0.624respectively.data sets increased to 0.537 and 0.676 respec-tively.Previous work has mainly studied individ-ual statistics in identifying LVCs while ig-noring the integration of various statistics.The results demonstrate that integrating dif-ferent statistics (i.e.
features) boosts the per-formance of LVC identification.
More impor-tantly, we employ an off-the-shelf classifierwithout special parameter tuning.
This showsthat generic machine learning methods can beapplied to the problem of LVC detection.
Itprovides a sound way to integrate various fea-tures to improve the overall performance.?
Our new features boost the overall perfor-mance.
Applying the newly proposed fea-tures on top of the base feature set, i.e., us-ing the full feature set, gives F1-measuresof 0.576 and 0.689 respectively (shown inbold) in our experiments.
These yield a sig-nificant increase (p < 0.1) over using thebase features only.
Further, when we removeeach of the new features individually fromthe full feature set, we see a correspondingdrop in the F1-measures, of 0.011 (deverbalcounts) to 0.044 (light verb classes) for thestrict data set, and 0.013 (deverbal counts)to 0.049 (light verb classes) for the lenientdata set.
It shows that these new featuresboost the overall performance of the classi-fier.
We think that these new features aremore task-specific and examine intrinsic fea-tures of LVCs.
As such, integrated with thestatistical base features, these features can beused to identify LVCs more accurately.
It isworth noting that light verb class is a simplebut important feature, providing the highestF1-measure improvement compared to othernew features.
This is in accordance with theobservation that different light verbs have dif-ferent properties (Stevenson et al, 2004).5 ConclusionsMultiword expressions (MWEs) are a major obsta-cle that hinder precise natural language processing(Sag et al, 2002).
As part of MWEs, LVCs remainleast explored in the literature of computationallinguistics.
Past work addressed the problem ofautomatically detecting LVCs by employing singlestatistical measures.
In this paper, we experiment55with identifying LVCs using a machine learningframework that integrates the use of various statis-tics.
Moreover, we have extended the existing sta-tistical measures and established new features todetect LVCs.Our experimental results show that the inte-grated use of different features in a machine learn-ing framework performs much better than usingany of the features individually.
In addition, weexperimentally show that our newly-proposed fea-tures greatly boost the performance of classifiersthat use base statistical features.
Thus, our systemachieves state-of-the-art performance over previ-ous approaches for identifying LVCs.
As such, wesuggest that future work on automatic detection ofLVCs employ a machine learning framework thatcombines complementary features, and examineintrinsic features that characterize the local con-text of LVCs to achieve better performance.While we have experimentally showed the ef-fectiveness of the proposed framework incorporat-ing existing and new features for LVC detectionon an English corpus, we believe that the featureswe have introduced are generic and apply to LVCdetection in other languages.
The reason is three-fold:1.
Mutual information is a generic metric formeasuring co-occurrences of light verbs andtheir complements.
Such co-occurrences areoften an obvious indicator for determininglight verbs because light verbs are often cou-pled with a limited set of complements.
Forinstance, in Chinese, directional verbs, suchas xia (descend) and dao (reach), which areoften used lightly, are often co-located with acertain class of verbs that are related to peo-ple?s behaviors.2.
For LVCs with noun complements, most ofthe semantic meaning of a LVC is expressedby the object.
This also holds for other lan-guages, such as Chinese.
For example, inChinese, zuo xuanze (make a choice) andzuo jueding (make a decision) has the wordzuo (make) acting as a light verb and xuan-ze (choice) or jueding (decision) acting as adeverbal noun (Wang, 2004).
Therefore, thefeature of deverbal count should also be ap-plicable for other languages.3.
It has been observed that in many languages,light verbs tend to be a set of closed classverbs.
This allows us to use a list of pre-defined verbs that are often used lightly as afeature which helps distinguish between lightand non-light verbs when used with the samenoun complement.
The identity of such verbshas been shown to be largely independent oflanguage, and corresponds to verbs that trans-mit information about possession, direction,aspect and causation.ReferencesT.
Bjerre.
1999.
Event structure and support verbconstructions.
In 4th Student Session of EuropeanSummer School on Logic, Language and Informa-tion 1999.
Universiteit Utrecht Press, Aug, 1999.L.
Breiman.
2001.
Random forests.
Machine Learn-ing, 45(1):5?32, Oct, 2001.M.
Butt and W. Geuder.
2001.
On the (semi)lexicalstatus of light verbs.
In Semi-lexical Categories,pages 323?370.
Mouton de Gruyter.M.
Butt.
2003.
The light verb jungle.
In Workshop onMulti-Verb Constructions.M.
Dras and M. Johnson.
1996.
Death and light-ness: Using a demographic model to find supportverbs.
In 5th International Conference on the Cog-nitive Science of Natural Language Processing.A.
Fazly, R. North, and S. Stevenson.
2005.
Automat-ically distinguishing literal and figurative usages ofhighly polysemous verbs.
In ACL 2005 Workshopon Deep Lexical Acquisition, pages 38?47.G.
Grefenstette and S. Teufel.
1995.
A corpus-basedmethod for automatic identification of support verbsfor nominalizations.
In EACL ?95.T.
Miyamoto.
2000.
The Light Verb Construction inJapanese.
The role of the verbal noun.
John Ben-jamins.I.
Sag, T. Baldwin, F. Bond, A. Copestake, andD.
Flickinger.
2002.
Multiword expressions: A painin the neck for NLP.
In Lecture Notes in ComputerScience, volume 2276, Jan, 2002.S.
Stevenson, A. Fazly, and R. North.
2004.
Statisti-cal measures of the semi-productivity of light verbconstructions.
In 2nd ACL Workshop on MultiwordExpressions: Integrating Processing, pages 1?8.L.
Wang.
2004.
A corpus-based study of mandarinverbs of doing.
Concentric: Studies in Linguistics,30(1):65?85, Jun, 2004.I.
Witten and E. Frank.
2000.
Data Mining: Practicalmachine learning tools with Java implementations.Morgan Kaufmann.56
