NEW POSSIB IL IT IES  INMACHINE TRANSLAT IONEduard H. HovyInformation Sciences Institute of USC4676 Admiralty WayMarina del Rey, CA 90292-6695Tel: 213-822-1511Email: HOVY~ISI.EDIABSTRACTThere is a growing need for language translation of documents in commerce, government, science, andinternational organizations.
At the same time, translation by computer (MT) is reaching the stage whereit can deliver significant cost savings (systems are being sold in Japan that reputedly reduce the timerequired for translation by up to 50%).
Although fully automated high-quality translation is technicallynot feasible today or in the near future, a number of recent theoretical developments make possibleMT systens that are more powerful and effective than existing ones.
These developments include: betterrepresentation techniques, a clearer understanding of semantics for translation, more complete grammars,and better generation and parsing technology.
By making optimal use of existing technology, new MTprojects can reach a sophisticated level of performance within a short time.
This paper provides reasonsfor starting a new MT program and recommends the establishment of three small MT projects thataddress the same domain but use different heoretical frameworks.INTRODUCTIONThe possibility of using computers to perform the translation of documents among various languageswas one of the earliest goals of Natural Language Processing and, indeed, one of the earliest of ArtificialIntelligence.
In the typical approach taken in the sixties, a parser program was equipped with a grammarand lexicon of the source language and a generator program with a grammar and lexicon of the targetlanguage, and the remainder consisted of a set of rules of correspondences among syntactic structuresor lexical items.
These approaches were soon proved naive by translations such as the now-famous "thevodka is strong but the meat is rotten" from "the spirit is willing but the flesh is weak".
It was apparentthat semantic information had somehow to be taken seriously (at least to the point of knowing that, forexample, "spirit" may indeed be "vodka", but not when used as an active agent who can be "willing").Since the early 60's, Machine Translation (MT) as a field of inquiry has largely lain dormant in the U.S.,with the exception of a few large projects (such as at the University of Texas, Austin \[Bennett 82\]) and afew smaller projects (such as at Yale University \[Lytinen 84\]).
In recent years, however, especially underthe impetus of Japanese and European efforts at addressing the problem, U.S. interest in MT researchhas been on the increase.The principal reason for the increase is the ongoing development of tools and techniques that enablethe performance of certain tasks with more thoroughness and success than was possible earlier (see,99for example, \[Carbonell et al 81, Carbonell & Tomita 87, Nirenburg 87, Arnold 86, Nakamura et al 88,Laubsch et al 84, Amano 86\]).
There has been a steady growth of the capabilities of parsers and genera-tors, the coverage of grammars, and the power and sophistication fknowledge representation techniques.In addition, two recent developments have the nature of breakthroughs that will greatly enhance futureMT systems: the incorporation of disjunction in KL-ONE-Iike representation systems, and the develop-ment of general-purpose language-based taxonomic ontologies of representation.Overall, the field has grown wiser since the 60's: the newer MT projects are all less ambitious in scope thanthe early ones.
Though nobody today would promise to deliver a system that performs perfect ranslationin even a relatively restricted omain, researchers feel comfortable about proposing systems that performthe first pass of a translation, producing a rough copy of the text in the target language, which wouldthen be edited for stylistic smoothness and fluent cadence by a human editor.
Such systems are calledMachine-Aided Translation (MAT) systems.
Since such systems ignificantly reduce the problems andcosts of translation, they are in high demand in industry and industrial research throughout the world.For example, three MAT systems currently in use in Japan reputedly reduce the time of translation oftechnical documents by about 50%; two of them are commercially available for under $70,000 \[Time 89\].The following passage from the invitation to an international seminar on MT organized by IBM (held inMunich, West Germany, in August 1989) summarizes the point:There is a growing need for translation (estimated at 15-25 percent per annum) in com-merce, science, governments, and international organizations.
This is due to increased inter-national cooperation and competition, an ever-growing volume of text to be communicated,often in multiple languages, world-wide lectronic ommunication, and more emphasis n coun-tries on the use of national language in documents and systems.
The opening of the Europeanmarket in 1992 will add significantly to these factors.At the same time, automated machine translation of natural language is reaching the stagewhere it can deliver significant cost savings in translation production, and vastly increase thescope of information retrieval, although fully automated high-quality translation is technicallynot feasible today and in the near future.\[H. Lehmann and P. Newman, IBM Scientific Centers in Heidelberg and Los Angeles,1989.\]This paper presents a case for the establishment of a modest MAT program under Darpa support.
Afterproviding some background and describing new technological capabilities, it discusses a framework inwhich a few small MAT projects could be brought into existence for a modest investment and motivatedtoward achieving a high level of performance in five years.MT SYSTEMS:  COMPONENTS AND APPROACHESTHE COMPONENTS OF AN MT SYSTEMIn order to build an MT system, the following program modules or components are needed:* A Parser* A Generatori00SourceTextrSourceParserI SourceLexiconKnowledgeBaseTextRepresentationTransferRulesrTargetGeneratorTargetLexiconTargetTextFigure h The Modules of an MT or MAT System.?
Grammars for each language?
Lexicons for each language?
A semantic Knowledge Base?
Interlanguage Translation Rules (in systems without an interlingua)In all MT systems, these modules are related essentially as shown in Figure 1.
We briefly discuss eachmodule below.Parser:  Sentences of the source text are parsed into some internal form by the parser.
In almost allcurrent MT systems, the internal form represents both syntactic and semantic aspects of the input.Inter language Translat ion Rules: Many MT systems contain a set of rules that transform certainaspects of the internal representation f the input to make them conform to the requirements of thetarget language.
Such MT systems are known as transfer-based.
An alternative approach is to build MTsystems without ransfer ules, using a single intermediate r presentation form called an interlingua; thegenerality and power of such systems depends on the expressiveness of the interlingua used.Generator:  The (modified) internal representation f the input is generated as sentence(s) of the targetlanguage by the generator.
The output must express the semantic ontent of the internal form, and ifpossible should use syntactic forms equivalent to those present in the input.Grammars :  In some systems, the grammars (syntactic information) are intrinsic parts of the parserand generator; in others, the grammars can be separated from the procedural mechanism.
In bidirec-tional systems, the parser and generator use the same grammar to analyze and produce ach language.Such systems are desirable because they do not duplicate syntactic information and are therefore morei 01maintainable.
True bidirectional grammars have proven hard to build, not least because xisting knowl-edge representation formalisms do not provide some capabilities ( uch as inference over disjunction.)
thatfacilitate parsing and generation.Semantic Knowledge Base: All sophisticated MT systems make heavy use of a knowledge base(representing underlying semantic information) containing the ontology of the application domain: theentities and their possible interrelationships.
Among other uses, the parser requires these entities toperform semantic disambiguation a d the generator uses them to determine acceptable paraphrases whereexact 'literal' formulations are not possible.Lexicons: All MT systems require a lexicon for the source language and one for the target language.In simple systems, corresponding entries in the two lexicons are directly linked to each other; in moresophisticated systems, lexicon entries are either accessed by entities represented in the knowledge base,or are indexed by characteristic collections of features (as built up by the parser).APPROACHESTO MTUsing these basic modules, a number of different approaches to the problem of MT are possible.The Lexical Approach: Many of the early MT systems, as well as some existing projects, base theirapproach on the lexicon to a large extent.
Typically, in such systems one finds a proliferation of highlyspecific translation rules spread throughout the lexicon; in fact, the size and complexity of lexical entriescan be used as a touchstone for the degree to which the system is lexically based or not.
While thisapproach may work for a time for any specific domain, it lacks the power that comes from a general, well-founded theoretical underpinning.
This is the reason such systems tend to become larger and seeminglyless defined as they grow, while not necessarily exhibiting reatly increased performance.The Inter l lngua Approach: The second approach is to use an interlingua s a language into which toparse and from which to generate.
Early attempts at an interlingua (such as the Conceptual Dependencyrepresentation \[Schank 75\]) did not lead to much success primarily due to the difficulty of dealing withterms on a very primitive (in the sense of basic or fundamental) level: sentences, when parsed, had to bedecomposed into configurations of the basic elements, and to be generated, had to be reassembled again.Given the basic level of the elements used at the time, this task was too complex to support successfulMT.The Transfer Approach: Many later systems relied less on translation rules hidden in the lexiconand more on representation-transforming rules associated with representational features.
This approachgained popularity when early experiments with interlinguas failed due to researchers' inability to developpowerful enough language-neutral epresentation terms.
However, the approach also suffers from a pro-liferation of rules, especially when more than two languages are present: for n languages, O(n 2) sets oftranslation rules are required.At present, no single approach is the clear winner.
The systems with the most practical utility at present,the commercially available Japanese systems, all use a relatively crude lexical approach and derive theirpower from the brute force provided by tens of thousands of rules.
Most promising for newer more generalsystems eems to be a mixture of the interlingua nd transfer approaches.102WHY A NEW ATTEMPT AT MAT?The time is ripe for a new initiative in the investigation of MAT in the U.S.A.
The principal reasonsfor this are both strategic and technical.
In the first instance, a large amount of MT work is beingdone in Europe (including such multinational projects as the EEC-wide EUROTRA) and Japan, withincreasing success; little MT work is done in the U.S. (most of which is funded by Japanese money).In the second instance, recent echnical breakthroughs, coupled with the steady advances of the past 25years, make possible the establishment of small MAT projects and their rapid growth to achieve a highlevel of sophistication.These advances, discussed in more detail below, are the following:* Advances in the theory of representation languages* The maturation of a representation scheme which enables the melding of the best features of theinterlingua nd transfer approaches?
Steady advances in grammar development?
Steady advances in generation and parsing technologyRepresentation Languages:Advances have been made in the theory of representation languages which make possible a new integratedtreatment of syntax and semantics.
Usually, semantic knowledge is represented in knowledge representa-tion languages such as those of the KL -ONE family.
Syntactic knowledge, on the other hand, is hardlyever (if at all) represented in these languages, and neither are the numerous intcrrnediate structures builtby parsers.
This is because disjunction (the logical operator OR)  has generally not been included in thelanguage capabilities.
The result is a serious problem, since parsers necessarily deal with multiple optionsdue to the structural and semantic ambiguities inherent in language.
The inability to represent bothsyntactic and semantic knowledge in the same system has precluded the development of parsers using asingle inferencing technique to perform their work in a homogeneous and unified manner.
Thus the lackof a general framework for computing with disjunctive knowledge structures has always been a hindranceto the development of parsing technology.Work is currently under way to incorporate inference over disjunctions into Loom \[MacGregor & Bates 87\],a newly developed exemplar of the KL-ONE-Iike languages, at ISI.
This work extends the capabilitiesof earlier methods for handling disjunctive descriptions in unification-based parsers (see \[Kasper 87,Kaspcr 88\]).
It is expected to be completed by the end of 1989.
This breakthrough will have two majoreffects: greatly simplified parsers and enhanced processing speed and efficiency.In more detail, this innovation makes possible, in a single KL-ONE-Iike representation system, the rep-resentation of both semantic and syntactic knowledge.
In this scheme, the automatic concept classifierwill be used as a powerful resource to perform simultaneous syntactic and semantic-based classificatoryinference under control of the parser.
Until now, the flow of control between syntactic and semanticprocessing has always been a vexing question for parsers: for semantic processing, they have used clas-sificatory inference of various kinds, and for syntactic processing, a variety of other methods, includingunification.
Since syntactic ambiguities are often resolved by semantic information, and vice versa, itis important to make the results of each type of processing available to the other as soon as possible.103Difficulties in doing so have always meant hat one or the other process is made to perform more work (insome cases significantly more) than necessary, requiring the maintenance of numerous alternatives of in-terpretation.
Under the new scheme, the representation f syntactic and semantic knowledge in the samerepresentation system simplifies the parsing process considerably, since there is then only one inferenceprocess and its results are represented in a single formalism.
Also, the speed and efficiency of the parseris increased, since each type of processing can be performed as soon as possible and no additional workneed be done.
This new integrated approach, enabled by the ability to handle inference over disjunction,has not been developed before.Melding interl ingua nd transfer approaches:A second breakthrough is the maturation of a representation scheme which enables the melding of thebest features of the interlingua nd transfer approaches.
Problems arise with the interlingua pproacheither when the interlingua is too 'shallow' to capture more than the surface form of the source text(and hence requires nuance-specific translation rules) or when it is too 'deep' to admit easy parsing andgeneration, as is the case with Conceptual Dependency \[Schank 75\].Knowledge representation experience over the past 15 years has resulted in a much better understandingof the different ypes of representation schemes and of the ways to define representation terms thatsupport he tasks at hand (the literature contains much work in this regard; see for example \[Hobbs 85,Hobbs et al 86\]).
However, the organization ofsuch terms to facilitate optimal anguage translation hasbeen a problem until the recent recognition that a taxonomy of abstract generalizations of linguisticallymotivated classes can be used as a type of generalized transfer ule.
It has become clear that, using theabstract conceptual categories necessary to support he generation of the source and target languages(such as the Upper Model for English in the Penman system; see \[Bateman et al 89c\]), it is possible toexploit the commonalities across languages to bypass the need for numerous transfer ules.
To the extentthat English shares with the other languages a linguistically motivated underlying ontology of the world(especially at the more abstract levels, taxonomizing the world into objects, qualities, and processes uchas actions, events, and relations), such a conceptual model can act as a type of interlingua in an MATsystem, where differences are taken care of by transfer ules of the normal type.
For example, the factthat actions have actors is general enough to be part of the generalized 'interlingua', while particularitiesof tenses in various languages i not.By building a suitable taxonomic organization of these terms, both the abovementioned problems canbe avoided: by defining enough specific terms in the taxonomy, nuances present in the domain can berepresented; and by basing the terms of the taxonomy on linguistically derived generalizations (insteadof, say, on notions about the underlying reality of the physical universe as in the case of CD), the ease ofparsing and generation can be guaranteed.
The use of such a taxonomy for MAT has been investigated;a pilot study is reported in \[Bateman et al 89a, Bateman et al 89b\].
The central ideas are described insome considerable detail in \[Bateman 89\].
This semi-interlingua approach is preferable to the lexicallybased and pure transfer approaches, ince it minimizes the number of special-purpose rules required tocustomize the system to a new domain, and hence increases the power and portability of the MAT system.Grammar  development:One of the steady advances in the field of Natural Language Processing is the development of morecomplete grammars.
There exist today computational grammars that cover English (and other languagessuch as German, Chinese, Japanese, and French) far more extensively than the most comprehensivegrammars of 20 years ago did.
Modern MAT system developers thus need spend much less effort ongrammar development and can concentrate on less understood issues.Generat ion and parsing technology:Another advance is in generation and parsing technology.
The issues in single-sentence parsing and104generation have been studied to the point where a number of well-established paradigms and algorithmsexist, each with known strengths and weaknesses (in fact, in the last 5 years a number of general-purpose generators have been distributed, including Penman \[Penman 88\], MUMBLE \[Meteer et al 87\],and SEMSYN \[RSsner 88\]).
Obviously, this situation greatly facilitates the construction of new MATsystems.Knowledge about Machine Translation:The amount of knowledge about MT available today is much larger than it was 20 years ago.
Morethan one journal is devoted to the topic (for example, Computers and Translation).
Books on the subjectinclude \[Nirenburg 87, Slocum 88, Hutchins 86\].
Some larger MT systems developed over the past decadeare the EEC-sponsored EUROTRA project \[Arnold ,~ des Tombe 87, Arnold 86\], the METAL project\[Bennett 82\], the Japanese-German SEMTEX-SEMSYN project \[RSsner 88\].
Two current MT projectsin the U.S. are KBMT \[Nirenburg etal.
89\] and a project at the CRL (New Mexico State University).WHAT WOULD AN MAT PROGRAM INVOLVE?The three cornerstones ofan MT system are the parser, the generator, and the knowledge representationsystem.
Computational Linguistics research as developed far enough today that there are available inthe world at least four general-purpose language generators, two of them English-based, and a numberof limited-purpose parsers.
A number of knowledge representation systems are also available, some ofwhich commercially (such as KEE, manufactured by Intellicorp), and others in the public domain (suchas NIKL and Loom \[Kaczmarek t al.
86, MacGregor & Bates 87\]).In essence, an MAT project under the new effort would perform six steps:Step 1: The selection of an approach, and the resultant development (in transfer and lexicon-based systems) of the transfer ules.
The success of a translation system can depend greatly on thetheoretical pproach taken, which can hinder the principal task of identifying the major bottlenecksfor MT.Step 2: The selection or development of parsing and generation mechanisms, together with auxiliaryinformation sources uch as lexicons and knowledge representation systems.
Given the existing workin Natural Language Processing at various centers in the U.S., and the general availability of parsingand generation technology, multiple options are available to the projects.Step 3: The development of the grammars of the various languages involved, and their incorporationwith the parser and generator.
This task can be more difficult, depending on the availability ofexperts in the languages.
However, international collaborations, or the use of grammars builtoverseas, can greatly facilitate the task.Step 4: The selection of an application domain and the representation f its elements.
Given thatthe primary goal of the program is to produce prototype machine-aided translation systems thatidentify MT bottlenecks, this task should be addressed with care.Step 5: The actual parsing and generation of texts to constitute the translation.Step 6: The evaluation of the results.
This task is very important in order to compare the strengthsof the various approaches and to identify the major problems facing MT.
A standard set of MTtests should be applied at various tages of the program.105A SCENARIO FOR AN MAT PROGRAMThis section outlines how a solid MAT capability can be achieved in the next five years for a relativelysmall investment.WHAT SHOULD THE PROGRAM A IM FOR?The program should aim at establishing a small MAT program in the U.S. to conduct good research onthe basic issues, to stay abreast of the developments happening elsewhere in the world, to develop andexploit current breakthroughs in the technology in the form of prototypes that perform machine-aidedtranslation, and to foster collaborations among the various Darpa-supported NLP projects.
Its goalsshould be:1. to stimulate development and incorporation of the newest echniques in order to identify and pushthe limits of MT possible today,2.
to focus on technologies that provide general, extensible capabilities, thereby surpassing less generalforeign efforts,3.
to develop rototype systems that exemplify this work in limited domains,.
to use the tests developed by various other MT projects (such as the EEC project EUROTRA)to measure the progress and success of the current technology, and to identify its most seriousbottlenecks and limitations,5.
to stimulate collaborations and software sharing among various groups developing appropriate NLP-related software and theories in this country.The program should not aim at the development ofsingle-sentence translation systems with wide cover-age of narrow domains that possess little generality (as proven by the commercially available Japanesesystems, this can be achieved by brute force).
It should instead aim at the development of prototypesystems that illustrate the translation of multipage texts, and that are general, easily portable, and ac-commodate new domains and languages with a minimum of effort.
That is, generality and feasibility arethe properties that will propel this effort beyond current echnology.OVERVIEW OF THE PROPOSED PROGRAMThis subsection describes ome important facets of the proposed MAT program.Given the amount of existing NLP technology, a relatively small investment can result in a significanteffort in MAT over a period of 5 years.
By making use of existing parsers and generators and grammars,individual projects can be kept reasonably small in manpower (on the order of four to five people perproject).Limiting project size enables the support of a greater number of projects.
This is important because,due to differences in their theoretical pproach, systems can be variously successful simply by virtue of106the limitations of the theory they embody, and can thus hinder the principal task, which is to identifythe major bottlenecks of MT.
Therefore the program should encourage two or three different heoreticalapproaches in order to help find the best one and to promote the development of technology which willdeliver near-term machine-aided translation and lay the foundation for full machine translation in thelong run.The program should specify a domain of application for the MAT systems which is easily modeled andrepresented, and for which the language typically used is clear and relatively unambiguous.
A populardomain for existing MAT systems is that of technical documents such as computer manuals, descriptionsof computer architectures or operating systems, etc.
Another alternative domain is intelligence reports.Beyond the obvious advantages of such domains is the fact that evaluation techniques and tests havealready been developed for translated technical documents by such projects as EUROTRA.In order to ensure that the systems developed are reasonably flexible and general, they should be encour-aged to be more than bilingual.
This can be achieved by developing the systems first to handle Englishand one other language and then to incorporate a third afterward.
This suggests a 5-year plan brokeninto three phases: a startup phase of one year for English-to-English paraphrasing, a second phase oftwo years to include a second language, and a final phase of two years to refine the second language andinclude a third language.This scenario involves a 5-year plan, at an investment of between $1 million and $2.5 million per year, asfollows:?
Year  1 :$1  million - -  startup (phase 1) (paraphrase)?
Year  2:$1.5 mi l l i on -  construction of phase 2 of system (bilingual ranslation)?
Year  3 :$2  million - -  completion and demonstration of phase 2?
Year  4:$2.2 million - -  refinement of phase 2, construction of phase 3 (trilingual translalion)?
Year  5:$2.4 million - -  further refinement, demonstration, and evaluation of final systemThis money should support three groups of between 3 and 5 people per group.
At various times, eachgroup would use the services of a parser specialist, a generator specialist, a knowledge representationspecialist, and a text specialist, as well as of programmers.
Since it is unlikely that any single groupwill have available such depth of experience, this requirement would foster collaborations among NLPresearch projects in this country.PROGRAM T IMETABLEIn order to minimize the amount of wasted effort, projects under this program should be encouraged touse as much existing NLP technology as possible.
This is to some degree nforced by the requirement of ademonstration after 3 years, which is quite reasonable given the availability of general-purpose g nerators,parsing techniques, and knowledge representation systems.
An additional saving of effort can be achievedby using, as second and third languages, grammars that have been developed by grammarians andcomputational linguists in other countries.
It is suggested that German be used as the second language,since a number of computational grammars of German exist in the public domain, and since German isstructurally very close to English.
The third language could be the choice of individual projects so asto allow them to capitalize on their strengths, but should be a language structurally quite different fromEnglish (such as Japanese or Chinese), so as to test the generality of the underlying theoretical approach.Thus the program can be structured as follows:107Year 1:?
Selection and adaptation of a parser.
* Selection and adaptation of a generator.?
Selection and incorporation of the English grammar(s).?
Representation f the domain, construction of a domain model.?
Selection and establishment of the English lexicon.?
Demonstration f the first stage of the system by a limited paraphrase task: parsing English textsand then generating English paraphrases of them.Year 2:?
Selection and initial incorporation of the German grammar.?
Selection and incorporation of the German lexicon.?
Integration of the initial German grammar with the parser and generator.?
Demonstration of the second stage of the system by parsing some German texts and generatingEnglish equivalents and vice versa.Year 3:?
Refinement of the German grammar.?
Refinement of the German lexicon.?
Completion of additional data sources uch as domain models, transfer ules, etc.?
Integration of the completed German grammar with the parser and generator.?
Demonstration of the third stage of the system by parsing German texts and generating Englishequivalents and vice versa.?
Establishment of a prototype English-German MAT system.Year 4:?
Selection and incorporation of the third language grammar (e.g.
Japanese)?
Selection and incorporation of the third language lexicon.?
Refinement of the English-German translations by development ofadditional techniques and trans-fer rules.?
Demonstration f the refined English-German MAT system.Year 5:?
Completion of the third language grammar.?
Completion of the third language lexicon.108?
Completion of additional data sources uch as domain models, transfer ules, etc.?
Integration of the completed third language grammar with the parser and generator.?
Demonstration f the final stage of the system, comprising translation in all six directions betweenEnglish, German, and the third language.?
Evaluation of the coverage and sophistication of the translations using the test and measures de-veloped by EUROTRA, as applicable to the domain.?
Reports of the major shortcomings and bottlenecks that stand in the way of more complete MT.The program should encourage evaluation of the prototype systems at every stage, using a well-conceivedset of measures such as those of the EUROTRA project.
One measure of evaluation is to count he numberof sentences translated correctly (i.e., without requiring other than stylistic changes by the editor).
Thismeasure can be subdivided according to the type(s) of error made: syntactic, semantic, lexical, unknownword (lexical), unknown concept (semantic), etc.
The projects should aim at a 50% correct sentencerate by the end of phase 2 and for a 75% rate for the German translation by the end of the program.Another measure is to compare the time required to translate a piece of text by a human alone with thetime taken by a human in conjunction with the system.
Existing commercial systems, using brute-forcetechniques, claim a speedup rate of 50%, establishing a bottom line which the projects' prototypes canstrive to improve.CONCLUSIONThe time is ripe for a new program in machine-aided translation of natural language.
New technology fromthe fields of generation, parsing, and knowledge representation can be brought ogether into prototypeMAT systems that can lead the way for working commercial systems (just as MT technology developedin the early 60's is currently being embodied and sold in Japan).A number of technical reasons make this an opportune time to start such a program.
They are develop-ments of the following kind:* Better representation techniques, uch as the ability to handle disjunction in KL-ONE-Iike repre-sentation languages.?
Clearer understanding of semantics, including the development of very general conceptual tax-onomies to capture generalized transfer ules.?
More complete grammars.?
Better existing generation and parsing technology.?
Greatly enhanced MT experience and developed evaluation techniques.As outlined in this document, a very moderate investment over 5 years can result in the creation of threedistinct MAT prototype systems, each supporting translations between English, German, and one otherlanguage.
This is an opportunity which should be seized before the breakthrough technology currentlybeing developed in the U.S. is copied and taken further elsewhere.109The benefit to Darpa and the Natural Language Computational community is clear.
For relatiw~ly littleexpense, a major new MAT effort will come into being in the next few years.
Much leverage will be gainedfrom the collaborations among projects in the research community~ utilizing the existing generation andparsing capabilities to optimal effect.AcknowledgmentsFor ideas and help thanks to John Bateman, Bob Kasper, Ron Ohlander, and Richard Whitney.References\[Amano 86\] Amano, S. The Toshiba Machine Translation System.
In Japan Computer Quarterly, Vol.
64,'Machine Translation - -  Threat or Tool', pp.
32-35, 1986.\[Arnold 86\] Arnold, D. Eurotra: A European Perspective on MT.
In Proceedings of the IEEE, Vol.
74, pp.979-992, 1986.\[Arnold & des Tombe 87\] Arnold, D.J.
and des Tombe, L. Basic theory and methodology in EUROTRA.
In Ma-chine Translation?
Theoretical nd Methodologicai Issues, Nirenburg, S. (ed), Cambridge UniversityPress, Cambridge, 1987.\[Bateman 89\] Bateman, J.A.
Upper Modeling for Machine Translation: A level of abstraction for preservingmeaning.
Unpublished Penman Project document, ISI/USC, Marina del Rey, 1989.\[Bateman et al 89a\] Bateman, J.A., Kasper, R.T., Schfitz, J. and Steiner, E. A New View on the Process ofTranslation.
In Proceedings of the European ACL Conference, Manchester, 1989.\[Bateman et al 89b\] Bateman, J.A., Kasper, R.T., Schfitz, J. and Steiner, E. Interfacing an English Text Genera-tor with a German MT Analysis.
To be published as Proceedings ofthe Gesellschaftfiir linguistischeDatenverarbeitung, Springer, 1989.\[Bateman et al 89c\] Bateman, J.A., Kasper, R.T., Moore, J.D.
and Whitney, R.A.
The Penman Upper Model.Unpublished Penman Project document, ISI/USC, Marina del Rey, 1989.\[Bennett 82\] Bennett, W.S.
The linguistic component of METAL.
Working paper, Linguistic Research Center,University of Texas at Austin, 1982.\[Carbonell et al 81\] Carbonell, J.G., Cullingford, R.E.
and Gershman, A.V.
Steps towards Knowledge-BasedMachine Translation.
In 1EEE Transactions on Pattern Analysis and Machine Intelligence, Vol.
3,pp.
376-392, 1981.\[Carbonell & Tomita 87\] Carbonell, J.G.
and Tomita, M. Knowledge-Based Machine Translation, the CMU Ap-proach.
In Machine Translation: Theoretical nd Methodological Issues, Nirenburg, S. (ed), Cam-bridge University Press, Cambridge, 1987.\[Hobbs 85\] Hobbs, J.R. Ontological Promiscuity.
In Proceedings ofthe Conference of the Association for Com-putational Linguistics (ACL), Chicago, 1985.\[Hobbs et al 86\] Hobbs, J.R., Croft, W., Davies, T., Edwards, D. and Laws, K. Commonsense Metaphysicsand Lexical Semantics.
In Proceedings of the Conference of the Association for ComputationalLinguistics (ACL), New York, 1986.\[Hutchins 86\] Hutchins, W. (ed).
Machine Translation: Past, Present, Future.
Ellis Horwood Ltd, Chichister,1986.\[Kaczmarek t al.
86\] Kaczmarek, T.S., Bates, R. and Robins, G. Recent Developments in NIKL.
In Proceedingsof the 5th AAAI Conference, Philadelphia, 1986.\[Kasper 87\] Kasper, R.T. A Unification Method for Disjunctive Feature Descriptions.
In Proceedings of the 25thAnnual Conference of the Association for Computational Linguistics, Stanford, 1987.ii0\[Kasper 88\] Kasper, R.T.
Conditional Descriptions in Functional Unification Grammar.
In Proceedings of the26th Annual Conference of the Association for Computational Linguistics , Buffalo, 1988.\[Laubsch et al 84\] Laubsch, J., R6sner, D., Hanakata, K. and Lesniewski, A.
Language Generation from Con-ceptual Structure: Synthesis of German in a Japanese/German MT Project.
In Proceedings ofCOLING 84, Stanford, 1984.\[Lytinen 84\] Lytinen, S.L.
The Organization of Knowledge in a Multi-Lingual, Integrated Parser.
Ph.D. disser-tation, Yale University Research Report # 340, 1984.\[MacGregor & Bates 87\] MacGregor, R. and Bates, R. The Loom Knowledge Representation Language.
InProceedings of the Knowledge-Based Systems Workshop, St. Louis, 1987.
Also available asUSC/Information Sciences Institute Research Report RS-87-188, 1987.\[Meteer et al 87\] Meteer, M., McDonald, D.D., Anderson, S., Foster, D., Gay, L., Huettner, A. and Sibun, P.Mumble-86: Design and implementation.
University of Massachusetts Technical Report COINS-87-87, 1987.\[Nakamura et al 88\] Nakamura, J., Tsujii, J. and Nagao, M. GRADE: A Software Environment for MachineTranslation.
In Computers and Translation, Vol.
3:1, pp.
69-82, 1988.\[Nirenburg 87\] Nirenburg, S. (ed).
Machine Translation: Theoretical and Methodological lssues.
Cambridge Uni-versity Press, Cambridge, 1987.\[Nirenburg et\[Penman 88\]\[RSsner 88\]\[Schank 75\]\[Slocum 88\]\[Time 89\]al.
89\] Nirenburg, S., Tomita, T., Carbonell, J., Nyberg, E. and others.
KBMT-89 Project Report.Center for Machine Translation, CMU, Pittsburgh, 1989.The Penman Primer, User Guide, and Reference Manual.
Unpublished USC/ISI documentation,1988.R6sner, D. The generation system of the SEMSYN project: Toward a task-independent generatorfor German.
In Zock, M. and Sabah, G. (eds), Advances in Natural Language Generation: AnInterdisciplinary Perspective, Frances Pinter, London, 1988.Schank, R.C.
Conceptual Information Processing.
North-Holland Press, Amsterdam, 1975.Slocum, J.
(ed).
Machine Translation Systems.
Cambridge University Press, Cambridge, 1988.Hillenbrand, B.
Trying to decipher Babel.
In Time Magazine, July 24, 1989.iii
