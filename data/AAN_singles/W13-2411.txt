Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 69?77,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsIdentifying False Friends between Closely Related LanguagesNikola Ljubes?ic?Faculty of Humanities and Social SciencesUniversity of ZagrebIvana Luc?ic?a 310000 Zagreb, Croatianikola.ljubesic@ffzg.hrDarja Fis?erFaculty of ArtsUniversity of LjubljanaAs?kerc?eva 21000 Ljubljana, Slovenijadarja.fiser@ff.uni-lj.siAbstractIn this paper we present a corpus-based ap-proach to automatic identification of falsefriends for Slovene and Croatian, a pairof closely related languages.
By takingadvantage of the lexical overlap betweenthe two languages, we focus on measuringthe difference in meaning between iden-tically spelled words by using frequencyand distributional information.
We ana-lyze the impact of corpora of different ori-gin and size together with different associ-ation and similarity measures and comparethem to a simple frequency-based base-line.
With the best performing settingwe obtain very good average precision of0.973 and 0.883 on different gold stan-dards.
The presented approach works onnon-parallel datasets, is knowledge-leanand language-independent, which makes itattractive for natural language processingtasks that often lack the lexical resourcesand cannot afford to build them by hand.1 IntroductionFalse friends are words in two or more languagesthat are orthographically or semantically similarbut do not have the same meaning, such as thenoun burro, which means butter in Italian but don-key in Spanish (Allan, 2009).
For that reason, theyrepresent a dangerous pitfall for translators, lan-guage students as well as bilingual computer tools,such as machine translation systems, which wouldall benefit greatly from a comprehensive collectionof false friends for a given language pair.False friends between related languages, suchas English and French, have been discussed bylexicographers, translators and language teachersfor decades (Chaco?n Beltra?n, 2006; Granger andSwallow, 1988; Holmes and Ramos, 1993).
How-ever, they have so far played a minor role in NLPand have been almost exclusively limited to par-allel data (Inkpen et al 2005; Nakov and Nakov,2009).
In this paper we tackle the problem of auto-matically identifying false friends in weakly com-parable corpora by taking into account the distri-butional and frequency information collected fromnon-parallel texts.Identifying false friends automatically has thesame prerequisite as the problem of detectingcognates ?
identifying similarly (and identically)spelled words between two languages, which is farfrom trivial if one takes into account the specificityof inter-language variation of a specific languagepair.
In this contribution we focus on the prob-lem of false friends on two quite similar languageswith a high lexical overlap ?
Croatian and Slovene?
which enables us to circumvent the problem ofidentifying similarly spelled words and use identi-cal words only as the word pair candidate list forfalse friends.Our approach to identifying false friends relieson two types of information extracted from cor-pora.
The first one is the frequency of a false friendcandidate pair in the corresponding corpora wherethe greater the difference in frequency, the morecertain one can be that the words are used in dif-ferent meanings.
The second information source isthe context from corresponding corpora where thecontext dissimilarity of the two words in questionis calculated through a vector space model.The paper is structured as follows: in Section 2we give an overview of the related work.
In Sec-tion 3 we describe the resources we use and in Sec-tion 4 we present the gold standards used for eval-uation.
Section 5 describes the experimental setupand Section 6 reports on the results.
We concludethe paper with final remarks and ideas for futurework.692 Related WorkAutomatic detection of false friends was initiallylimited to parallel corpora but has been extendedto comparable corpora and web snippets (Nakov etal., 2007).
The approaches to automatically iden-tify false friends fall into two categories: those thatonly look at orthographic features of the sourceand the target word, and those that combine ortho-graphic features with the semantic ones.Orthographic approaches typically rely on com-binations of a number of orthographic similaritymeasures and machine learning techniques to clas-sify source and target word pairs to cognates, falsefriends or unrelated words and evaluate the differ-ent combinations against a manually compiled listof legitimate and illegitimate cognates.
This hasbeen attempted for English and French (Inkpen etal., 2005; Frunza and Inkpen, 2007) as well asfor Spanish and Portuguese (Torres and Alu?
?sio,2011).Most of the approaches that combine ortho-graphic features with the semantic ones have beenperformed on parallel corpora where word fre-quency information and alignments at paragraph,sentence as well as word level play a crucial role atsingling out false friends, which has been tested onBulgarian and Russian (Nakov and Nakov, 2009).Work on non-parallel data, on the other hand, of-ten treats false friend candidates as search queries,and considers the retrieved web snippets for thesequeries as contexts that are used to establish thedegree of semantic similarity of the given wordpair (Nakov and Nakov, 2007).Apart from the web snippets, comparable cor-pora have also been used to extract and clas-sify pairs of cognates and false friends betweenEnglish and German, English and Spanish, andFrench and Spanish (Mitkov et al 2007).
Intheir work, the traditional distributional approachis compared with the approach of calculating n-nearest neighbors for each false friend candidate inthe source language, translating the nearest neigh-bors via a seed lexicon and calculating the set in-tersection to the N nearest neighbors of the falsefriend candidate from the target language.A slightly different setting has been investigatedby Schultz et al(2004) who built a medical do-main lexicon from a closely related language pair(Spanish-Portuguese) and used the standard distri-butional approach to filter out false friends fromcognate candidates by catching orthographicallymost similar but contextually most dissimilar wordpairs.The feature weighting used throughout the re-lated work is mostly plain frequency with onecase of using TF-IDF (Nakov and Nakov, 2007)whereas cosine is the most widely used similar-ity measure (Nakov and Nakov, 2007; Nakov andNakov, 2009; Schulz et al 2004) while Mitkovet al(2007) use skew divergence which is verysimilar to Jensen-Shannon divergence.The main differences between the work we re-port on in this paper and the related work are:1. we identify false friends on a language pairwith a large lexical overlap ?
hence we canlook for false friends only among identicallyspelled words, such as boja, which meansbuoy in Slovene but colour in Croatian, andnot among similarly spelled words, such asthe Slovene adjective buc?en (made of pump-kins and noisy) and its Croatian counterpartbuc?an (only noisy);2. we inspect multiple association and similaritymeasure combinations on two different cor-pora pairs, which enables us to assess the sta-bility of those parameters in the task at hand;3. we work on two different corpora pairs whichwe have full control over (that is not the casewith web snippets), and are therefore able toexamine the impact of corpus type and corpussize on the task;4. we use three categories for the identicallyspelled words:(a) we use the term true equivalents (TE)to refer to the pairs that have the samemeaning and usage in both languages(e.g.
adjective bivs?i, which means for-mer in both languages),(b) the term partial false friends (PFF) de-scribes pairs that are polysemous andare equivalent in some of the senses butfalse friends in others (e.g.
verb draz?iti,which can mean either irritate or makemore expensive in Slovene but only irri-tate in Croatian), and(c) we use the term false friends (FF) forword pairs which represent differentconcepts in the two languages (e.g.
nounslovo, which means farewell in Sloveneand letter of the alphabet in Croatian)70By avoiding the problem of identifying relevantsimilarly spelled words prior to the identificationof false friends, in this paper we focus only on thelatter and avoid adding noise from the precedingtask.3 Resources UsedIn this paper we use two types of corpora:Wikipedia corpora (hereafter WIKI) which havegained in popularity lately because of their sim-ple construction and decent size and web corpora(hereafter WAC) which are becoming the standardfor building big corpora.We prepared the WIKI corpora from the dumpsof the Croatian and Slovene Wikipedias by ex-tracting their content, tokenizing and annotat-ing them with morphosyntactic descriptions andlemma information.
The web corpora of Croat-ian and Slovene were built in previous work ofLjubes?ic?
and Erjavec (2011).
They were createdby crawling the whole top-level Slovene and Croa-tian domains and applying generic text extraction,language identification, near-duplicate removal,linguistic filtering and morphosyntactic annotationand lemmatization.In terms of content, it is to expect that web cor-pora are much richer genre-wise while articles inWikipedia corpora all belong to the same genre.As far as topics are concerned, web corpora arebelieved to be more diverse but contain a less uni-form topic distribution than Wikipedia corpora.Finally, it is to expect that Wikipedia corpora con-tain mostly standard language while web corporacontain a good portion of user-generated contentand thereby non-standard language as well.Some basic statistical information on the cor-pora is given in Table 1.CORPUS MWORDS MTOKENS DOC #HR.WIKI 31.21 37.35 146,737SL.WIKI 23.47 27.85 131,984HRWAC 787.23 906.81 2,550,271SLWAC 450.06 525.55 1,975,324Table 1: Basic statistics about the corpora usedBoth types of corpora are regularly used in to-day?s NLP research and one of the tasks of thispaper is to compare those two not only in relationto the specific task of false friends identification,but on a broader scale of exploiting their contex-tual and frequency information as well.4 Gold StandardsThe gold standards for this research were builtfrom identically spelled nouns, adjectives andverbs that appeared with a frequency equal orhigher than 50 in the web corpora for both lan-guages.The false friend candidates were categorized inthe three categories defined in Section 2: falsefriends, partial false friends and true equivalents.Manual classification was performed by threeannotators, all of them linguists.
Since identify-ing false friends is hard even for a well-trained lin-guist, all of them consulted monolingual dictionar-ies and corpora for both languages before makingthe final decision.The first annotation session was performed by asingle annotator only.
Out of 8491 candidates, hemanaged to identify 117 FFs, 110 PFFs and 8264(97.3%) TEs.
All the identified FFs and PFFs aswell as 380 TEs were then given to two more an-notators, shrinking the dataset to be annotated bythe other two annotators down to 607 entries, i.e.to only 7% of the initial dataset.
The agreementbetween all three annotators on the smaller datasetis given in Table 2.ANNOTATORS INTERSECTION KAPPAA1 A2 0.766 0.549A1 A3 0.786 0.598A2 A3 0.743 0.501average 0.765 0.546Table 2: Inter-annotator agreement on building thegold standardsThe obtained average kappa inter-annotatoragreement is considered moderate and proves theproblem to be quite complex, even for humanswell trained in both languages with all the avail-able resources at hand.
Since we did not havesufficient resources for all the annotators to re-vise their divergent annotations, we proceeded bybuilding the following two gold standards:1. the first gold standard (GOLD1) contains onlyFFs and TEs on which all the three annotatorsagreed (60 FFs and 324 TEs) and2.
the second gold standard (GOLD2) containsall entries where at least the first and one ofthe other two annotators agreed (81 FFs, 33PFFs and 351 TEs).71We consider GOLD1 to be simpler and cleanerwhile GOLD2 contains the full complexity of thetask at hand.5 Experimental SetupWe experimented with the following parameters:corpus type, corpus size, association measure forfeature weighting, similarity measure for compar-ing context vectors and gold standard type.We ran our experiments on two pairs of corpora:1. one pair originating from local Wikipediadumps (WIKI) and2.
one pair originating from the top-level-domain web corpora of the two languages(WAC)We took under consideration the following as-sociation measures:1.
TF-IDF (TF-IDF) is well known from infor-mation retrieval but frequently applied onother problems as well; we consider contextvectors to be information entities and calcu-late the IDF statistic for a term t and vectorset V as follows:IDF (t, V ) = log|V ||{v ?
V : t ?
v}|2.
log-likelihood (LL) (Dunning, 1993) whichhas proven to perform very well in a num-ber of experiments on lexicon extraction i.e.finding words with the most similar context,performing similarity well as TF-IDF and3.
discounted log-odds (LO) first used in lexiconextraction by Laroche and Langlais (2010),showing consistently better performance thanLL; it is calculated from contingency table in-formation as follows:LO = log(O11 + 0.5)(O22 + 0.5)(O12 + 0.5)(O21 + 0.5)The following similarity measures were takeninto account:1. the well-known cosine measure (COSINE),2. the Dice measure (DICE), defined in (Otero,2008) as DiceMin, which has proven to bevery good in various tasks of distributionalsemantics (v1f is the feature weight of featuref in vector v1):DICE(v1, v2) =2 ?
?f min(v1f , v2f )?f v1f + v2f3.
and the Jensen-Shannon divergence (JEN-SHAN) which shows consistent performanceon various tasks:JS(v1, v2) =KL(v1|v2)2+KL(v2|v1)2KL(v1|v2) =?fv1f logv1fv1f + v2fWe used the standard approach for extractingcontext and building context vectors and calcu-lated the frequency distribution of three contentwords to the left and to the right of the head-word without encoding their position.
We did notperform any cross-lingual feature projection via aseed lexicon or similar, but relied completely onthe lexical overlap between the two similar lan-guages.Apart from the context and its dissimilarity,there is another, very fundamental source of in-formation that can be used to assess the differencein usage and therefore meaning ?
the frequencyof the word pair in question in specific languages.That is why we also calculated pointwise mutualinformation (PMI) between candidate pairs.PMI(w1, w2) = logp(w1, w2)p(w1) ?
p(w2)We estimated the joint probability of the twowords by calculating the maximum likelihood esti-mate of the identically spelled word on the mergedcorpora.
We considered this measure to be a strongbaseline.
For a weak baseline we took a randomordering of pairs of words (RANDOM).Since the result of the procedure of identifyingfalse friends in this setting is a single ranked listof lemma pairs where the ranking is performedby contextual or frequency dissimilarity, the sameevaluation method can be applied as to evaluatinga single query response in information retrieval.That is why we evaluated the output of each settingwith average precision (AP), which averages overall precisions calculated on lists of false friendcandidates built from each positive example up-wards.72As three categories were encoded in the GOLD2gold standard, we weighted FFs with 1, TEs with0 and PFFs with 0.5.
In the GOLD1 gold standardFFs were, naturally, weighted with 1 and TEs with0.6 ResultsIn our initial set of experiments we ran a Cartesianproduct on the sets of corpora types, gold stan-dards, association measures and similarity mea-sures.
The results of those experiments are givenin Table 3.WIKIGOLD1 COSINE DICE JENSHANTF-IDF 0.326 0.349 0.337LL 0.333 0.401 0.355LO 0.340 0.539 0.434PMI 0.634GOLD2 COSINE DICE JENSHANTF-IDF 0.376 0.392 0.380LL 0.390 0.440 0.406LO 0.442 0.561 0.470PMI 0.581WACGOLD1 COSINE DICE JENSHANTF-IDF 0.777 0.757 0.739LL 0.773 0.934 0.880LO 0.973 0.324 0.903PMI 0.629GOLD2 COSINE DICE JENSHANTF-IDF 0.694 0.714 0.659LL 0.714 0.828 0.782LO 0.883 0.384 0.837PMI 0.600RANDOM GOLD1 0.267RANDOM GOLD2 0.225Table 3: Average precision obtained over corporatypes, gold standards, association measures andsimilarity measuresThe first observation is that the overall resultson the WAC corpus pair are about twice as highas the results obtained on the WIKI corpus pair.Since the first is more than 20 times larger thanthe second, we assumed the amount of informa-tion available to be the main cause for such drasticdifference.We then analyzed the difference in the resultsobtained on the two gold standards.
As expected,the results are better on PMI baselines, the RAN-DOM baseline and in the distributional approachon the WAC corpus pair.
The reverse result wasobtained with the distributional approach on theWIKI corpus pair and at this point we assumed thatit is the result of chance since the results are quitelow and close to each other.6.1 The BaselinesAll the results outperformed the weak RANDOMbaseline.
On the contrary, the strong PMI baseline,which uses only frequency information, proved tobe a better method for identifying false friends inthe WIKI corpus pair, while it was outperformedby distributional methods on the WAC corpus pair.An important observation regarding PMI in gen-eral is that its results relies solely on frequenciesof words and having more information than nec-essary to make good frequency estimates for allthe words analyzed cannot improve the results anyfurther.
This is the reason why the PMI scores onboth corpora pairs regarding the specific gold stan-dard are so close to each other (0.634 and 0.629 onGOLD1, 0.581 and 0.600 on GOLD2), regardless ofthe much larger size of the WAC corpora pair.
Thisshows that both corpora pairs are large enough forgood frequency estimates of the gold standard en-tries.Since frequency was not directly encoded in thedistributional approach, it seemed reasonable tocombine the PMI results with those obtained by thedistributional approach.
We therefore performedlinear combinations of the PMI baseline and var-ious distributional results.
They yielded no im-provements except in the case of TF-IDF, whichstill performed worse than most other distribu-tional approaches.The conclusion regarding PMI is that if onedoes not have access to a large amount of textualdata, pointwise mutual information or some otherfrequency-based method could be the better wayto approach the problem of false friend identifi-cation.
However, having a lot of data does giveadvantage to distributional methods.
We will lookinto the exact amount of the data needed to outper-form PMI in subsection 6.5.6.2 Document Alignments on the WIKI PairSince PMI performed so well, especially on theWIKI corpus pair on which we have access todocument alignments as well, we decided to per-form another experiment in which we use that73additional information.
We calculated the jointprobability p(w1, w2) not by calculating the maxi-mum likelihood estimate of the identically spelledwords in a merged corpus but by taking into ac-count the number of co-occurrences of the iden-tically spelled words in aligned documents only.Naturally, this produced much lower joint proba-bilities than our initial PMI calculation.The results of this experiment showed to beas low as the random baseline (0.189 on GOLD1and 0.255 on GOLD2).
The reason was that low-frequency lemmas, many of which are TEs, neveroccurred together in aligned documents givingthose pairs the lowest possible score.
When re-moving the entries that never co-occur, the resultsdid rise slightly over the initial PMI score (0.669on GOLD1 and 0.549 on GOLD2), but roughly halfof the lemma pairs were excluded from the calcu-lation.To conclude, identifying false friends with asimple measure like pointwise mutual informationin case of a limited amount of available data can-not benefit from the additional structure like theWikipedia document alignments.
Having muchmore data, which would be the case in largerWikipedias, or applying a more sophisticated mea-sure that would be resistant to scarce data, couldprove to be beneficial and is considered a direc-tion for future work.6.3 Association and Similarity MeasuresWe continued our analysis by observing the inter-play of association and similarity measures.
First,we performed our analysis on the much better re-sults obtained on the WAC corpus pair.
DICE andLL turned out to be a once-again winning combi-nation.
TF-IDF underperformed when comparedto LL, showing that LL is the superior associa-tion measure in this problem as well.
JENSHANshowed a very high consistency, regardless of theassociation measure used, which is an interestingproperty, but it never obtained the highest score.The big surprise was the LO association mea-sure.
On the WAC corpus pair it resulted in theoverall best score when used with COSINE, butfailed drastically when combined with DICE.
Thesituation got even more puzzling once we com-pared these results with those obtained on theWIKI corpus pair where DICE and LO gave the bestoverall result.
Laroche and Langlais (2010) reportto get slightly better or identical results when us-ing LO with COSINE in comparison to DICE.Trying to find an explanation for such variableresults of the LO association measure, we decidedto analyze the strongest features in the context vec-tors of both LO and LL on both corpora pairs.
Wepresent our findings in Table 4 on the example ofthe word gripa which means flu in both languages.We analyzed the 50 strongest features and classi-fied them in one of the following categories: typo,foreign name, rare term and expected term.The presented data does shed light on the un-derlying situation, primarily on the LO associationmeasure, and secondly on the difference betweenthe corpora pairs.
LL is a very stable associationmeasure that, regardless of the noise present in thecorpora, gave the highest weight to the featuresone would associate with the concept in question.On the contrary, LO is quite good at emphasizingthe noise from the corpora.
Since more noise ispresent in web corpora than in Wikipedia corpora,LO got very good results on the WIKI corpus pairbut failed on the WAC corpus pair.WIKISL-LO SL-LL HR-LO HR-LLtypo 0.24 0.00 0.56 0.16foreign 0.06 0.00 0.22 0.08rare 0.10 0.00 0.04 0.00ok 0.60 1.00 0.18 0.76WACSL-LO SL-LL HR-LO HR-LLtypo 0.62 0.00 0.72 0.12foreign 0.20 0.00 0.26 0.00rare 0.04 0.00 0.00 0.00ok 0.14 1.00 0.02 0.88Table 4: Results of the analysis of the 50 strongestfeatures in the eight different LL and LO vectorsThis still did not offer an explanation why LOperformed as well as it did on the WAC corpus pairwhen it was paired with COSINE, or to a smallerextent with JENSHAN.
The reason for such behav-ior lies in the primary difference between DICEand the remaining similarity measures: the lattertake into account only the features defined in bothvectors while DICE works on a union of the fea-tures.
Transforming DICE in such a way that ittakes into account only the intersection of the de-fined features did improve the results when usingit with LO (from 0.324 and 0.384 to 0.575 and0.591), but the results deteriorated when used with740.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0gold1recallprecisionWaC.lo.cosineWaC.ll.diceWaC.pmiwp.pmi0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0gold2recallprecisionWaC.lo.cosineWaC.ll.diceWaC.pmiwp.pmiFigure 1: Precision-recall curve of chosen settings on both gold standardsLL (0.934 and 0.828 to 0.768 and 0.719).We can conclude that LL is a much more stableassociation measure than LO, but LO performs ex-tremely well as long as the corpora are not noisyor it is not combined with a similarity score thatcalculates the similarity on a union of the definedfeatures.6.4 Precision-Recall CurvesWe visualized the results obtained with best per-forming and most interesting settings in Figure 1with two precision-recall curves, one for each goldstandard.The PR curves stressed the similarity of the re-sults of the PMI method on same gold standardsbetween corpora pairs along the whole precision-recall trade-off spectrum.
They also emphasizedthe significance of the higher quality of the re-sults obtained by the distributional approach onthe large WAC corpus pair.Although somewhat unpredictable, the LO as-sociation measure, when coupled with the correctsimilarity measure, consistently outperformed LLon the whole spectrum on both gold standards.6.5 Corpus SizeWe performed a final set of experiments, whichfocused on experimenting with the parameter ofcorpus size.
In general, we were interested inthe learning curves on different corpora pairs withbest performing settings.
We also looked for thepoint where the distributional approach overtakesthe frequency approach and a direct comparisonbetween the two corpora pairs.The learning curves, calculated on random por-tions of both corpora pairs on GOLD1, are pre-sented in Figure 2.
Both PMI learning curvesproved our claim that with a sufficient amount ofinformation required to make good frequency es-timates, no further improvement can be achieved.On these datasets good estimates were obtained on5 million words (both languages combined).
ThePMI learning curve on the WAC corpus pair wassteady on the whole scale and we identified thepoint up to which PMI is more suitable for iden-tifying false friends than distributional methodssomewhere around 130 million words (both cor-pora combined) from where distributional meth-ods surpass the ?
0.63 plain frequency result.The WIKI.LL.DICE and the WAC.LL.DICEcurves on the left plot enabled us to compare thesuitability of the two corpora pairs for the task ofidentifying false friends and distributional tasks ingeneral.
At lower corpus sizes the results werevery close, but from 10 million words onwards,the WAC corpus pair outperformed the WIKI cor-pus pair, consistently pointing toward the conclu-sion that web corpora are more suitable for distri-butional approaches than Wikipedia corpora.The performance of the two distributional ap-proaches depicted on the second graph evened out750 10 20 30 400.00.20.40.60.81.0wikicorpus pair size (Mwords)averageprecisionwiki.lo.dicewiki.ll.dicewiki.pmiWaC.ll.dice0 200 400 600 800 1000 12000.00.20.40.60.81.0WaCcorpus pair size (Mwords)averageprecisionWaC.lo.cosineWaC.ll.diceWaC.pmiFigure 2: Learning curve on both corpora pairs on GOLD1around the 500 million word mark, showing thataround 250 million words per language shouldsuffice for this task.
Having lower-frequency en-tries in the gold standard would, naturally, callfor more data.
However, the criterion of 50 oc-currences in 500+ million tokens web corpora weused for constructing our gold standards shouldcover most cases.Finally, let us point out that the WIKI.LO.DICEcurve on the left graph climbed much faster thanthe WIKI.LL.DICE curve, showing faster learningwith the LO association measure in comparison toLL.
An interesting observation is that the LO curveobtained its maximum slightly after the 20 millionwords mark, after which it started a slow decline.Although it could be surprising to see a learn-ing curve declining, this is in line with our previ-ous insights regarding the LO association measurenot responding well to many new low-frequencyfeatures included in the vector space making theLO+DICE combination struggle.
This is one ad-ditional reminder that the LO association measureshould be used with caution.7 ConclusionIn this paper we compared frequency-basedand distributional approaches to identifying falsefriends from two frequently used types of corporapairs ?
Wikipedia and web corpora.
We have usedthe PMI method for frequency-based ranking andthree association and three similarity measures fordistributional-based ranking.The PMI method has proven to be a very goodmethod if one does not have more than 75 mil-lion words available per language, in which case itoutperformed the more complex distributional ap-proach.
Good frequency estimates for PMI wereobtained on 2.5 million words per language, afterwhich introducing more data did not yield any fur-ther improvement.Using document alignments from Wikipedia asan additional source for the frequency-based ap-proach did not perform well because of the smallsize of the Wikipedias in question (slightly above100,000 articles), often producing zero joint prob-abilities for non-false friends.
A more thought-through approach that could resist data sparsity orusing larger Wikipedias is one of our future re-search directions.The DICE+LL similarity and association mea-sures proved to be a very stable combination as isthe case on the opposite task of translation equiv-alence extraction (Ljubes?ic?
et al 2011).The LO association measure gave excellent re-sults, but only if it was paired with a similaritymeasure that takes into account only the intersec-tion of the features or if the context vectors werecalculated on very clean corpora since LO tends tooveremphasize low frequency features.
We wouldrecommend using this association measure in dis-76tributional approaches, but only if one of the abovecriteria is satisfied.The amount of data on which the distributionalapproach stopped benefitting from more data onthis task was around 250 million words per lan-guage.Overall, web corpora showed to be better can-didates for distributional methods than Wikipediacorpora for two reasons: 1. the WAC learningcurve is steeper, and 2. there are few languageswhich contain 75 million words per language thatare necessary to outperform the frequency-basedapproach and even fewer for which there are 250million words per language needed for the learn-ing curve to even out.Our two primary directions for future researchare 1. preceding this procedure with identifyinglanguage-pair-specific similarly spelled words and2.
including additional language pairs such asCroatian and Czech or Slovene and Czech.AcknowledgmentsThe research leading to these results has receivedfunding from the European Union Seventh Frame-work Programme FP7/2007-2013 under grantagreement no.
PIAP-GA-2012-324414 (projectAbu-MaTran) and from the Slovene nationalresearch programme no.
P6-0215.We would like to thank Das?a Berovic?
and JelenaTus?ek for their help in annotating the datasets.ReferencesKeith Allan, editor.
2009.
Concise Encyclopedia ofSemantics.
Elsevier Science.Rube?n Chaco?n Beltra?n.
2006.
Towards a typologicalclassification of false friends (Spanish-English).
Re-vista Espan?ola de Lingu?
?stica Aplicada, 19:29?39.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
Comput.
Linguist.,19(1):61?74.Oana Frunza and Diana Inkpen.
2007.
A tool for de-tecting French-English cognates and false friends.In Proceedings of the 14th conference TraitementAutomatique des Langues Naturelles, TALN?07,,Toulouse.Sylviane Granger and Helen Swallow.
1988.
Falsefriends: a kaleidoscope of translation difficulties.Langage et l?Homme, 23(2):108?120.John Holmes and Rosinda Guerra Ramos.
1993.
Falsefriends and reckless guessers: Observing cognaterecognition strategies.
In Thomas Huckin, Mar-got Haynes, and James Coady, editors, Second Lan-guage Reading and Vocabulary Learning.
Norwood,New Jersey: Ablex.Diana Inkpen, Oana Frunza, and Grzegorz Kondrak.2005.
Automatic identification of cognates and falsefriends in French and English.
In Proceedings ofthe International Conference on Recent Advances inNatural Language Processing (RANLP 2005), pages251?257.Audrey Laroche and Philippe Langlais.
2010.
Re-visiting context-based projection methods for term-translation spotting in comparable corpora.
InProceedings of the 23rd International Conferenceon Computational Linguistics, COLING ?10, pages617?625, Stroudsburg, PA, USA.
Association forComputational Linguistics.Nikola Ljubes?ic?
and Tomaz?
Erjavec.
2011. hrWaC andslWac: Compiling Web Corpora for Croatian andSlovene.
In Ivan Habernal and Va?clav Matousek,editors, Text, Speech and Dialogue - 14th Interna-tional Conference, TSD 2011, Pilsen, Czech Repub-lic, September 1-5, 2011.
Proceedings, volume 6836of Lecture Notes in Computer Science, pages 395?402.
Springer.Nikola Ljubes?ic?, Darja Fis?er, S?pela Vintar, and SenjaPollak.
2011.
Bilingual lexicon extraction fromcomparable corpora: A comparative study.
In FirstInternational Workshop on Lexical Resources, AnESSLLI 2011 Workshop, Ljubljana, Slovenia - Au-gust 1-5, 2011.Ruslan Mitkov, Viktor Pekar, Dimitar Blagoev, and An-drea Mulloni.
2007.
Methods for extracting andclassifying pairs of cognates and false friends.
Ma-chine Translation, 21(1):29?53.Svetlin Nakov and Preslav Nakov.
2007.
Cognate orfalse friend?
Ask the Web.
In Proceedings of theRANLP?2007 workshop: Acquisition and manage-ment of multilingual lexicons.Svetlin Nakov and Preslav Nakov.
2009.
Unsupervisedextraction of false friends from parallel bi-texts us-ing the web as a corpus.
In Proceedings of the6th International Conference on Recent Advancesin Natural Language Processing (RANLP?09), pages292?298.Stefan Schulz, Korne?l Marko?, Eduardo Sbrissia, PercyNohama, and Udo Hahn.
2004.
Cognate mapping- A heuristic strategy for the semi-supervised acqui-sition of a Spanish lexicon from a Portuguese seedlexicon.
In Proceedings of the 20th InternationalConference on Computational Linguistics.Lianet Sepu?lveda Torres and Sandra Maria Alu??sio.2011.
Using machine learning methods to avoidthe pitfall of cognates and false friends in Spanish-Portuguese word pairs.
In Proceedings of the 8thBrazilian Symposium in Information and HumanLanguage Technology, STIL?11.77
