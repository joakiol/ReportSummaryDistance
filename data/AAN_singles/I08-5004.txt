Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages, pages 17?24,Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language ProcessingA Hybrid Approach for Named Entity Recognition in Indian LanguagesSujan Kumar Saha Sanjay Chatterji Sandipan DandapatIndian Institute of Technology Indian Institute of Technology Indian Institute of TechnologyKharagpur, West Bengal Kharagpur, West Bengal Kharagpur, West BengalIndia - 721302 India - 721302 India - 721302sujan.kr.saha@gmail.com sanjay chatter@yahoo.com sandipan@cse.iitkgp.ernet.inSudeshna Sarkar Pabitra MitraIndian Institute of Technology Indian Institute of TechnologyKharagpur, West Bengal Kharagpur, West BengalIndia - 721302 India - 721302shudeshna@gmail.com pabitra@gmail.comAbstractIn this paper we describe a hybrid systemthat applies Maximum Entropy model (Max-Ent), language specific rules and gazetteersto the task of Named Entity Recognition(NER) in Indian languages designed for theIJCNLP NERSSEAL shared task.
Startingwith Named Entity (NE) annotated corporaand a set of features we first build a base-line NER system.
Then some language spe-cific rules are added to the system to recog-nize some specific NE classes.
Also we haveadded some gazetteers and context patternsto the system to increase the performance.As identification of rules and context pat-terns requires language knowledge, we wereable to prepare rules and identify contextpatterns for Hindi and Bengali only.
For theother languages the system uses the MaxEntmodel only.
After preparing the one-levelNER system, we have applied a set of rulesto identify the nested entities.
The systemis able to recognize 12 classes of NEs with65.13% f-value in Hindi, 65.96% f-value inBengali and 44.65%, 18.74%, and 35.47%f-value in Oriya, Telugu and Urdu respec-tively.1 IntroductionNamed entity recognition involves locating and clas-sifying the names in text.
NER is an importanttask, having applications in Information Extraction(IE), Question Answering (QA), Machine Transla-tion (MT) and in most other NLP applications.This paper presents a Hybrid NER system for In-dian languages which is designed for the IJCNLPNERSSEAL shared task competition, the goal ofwhich is to perform NE recognition on 12 typesof NEs - person, designation, title-person, organiza-tion, abbreviation, brand, title-object, location, time,number, measure and term.In this work we have identified suitable featuresfor the Hindi NER task.
Orthography features, suf-fix and prefix information, morphology informa-tion, part-of-speech information as well as informa-tion about the surrounding words and their tags areused to develop a MaxEnt based Hindi NER sys-tem.
Then we realized that the recognition of someclasses will be better if we apply class specific lan-guage rules in addition to the MaxEnt model.
Wehave defined rules for time, measure and numberclasses.
We made gazetteers based identification fordesignation, title-person and some terms.
Also wehave used person and location gazetteers as featuresof MaxEnt for better identification of these classes.Finally we have built a module for semi-automaticextraction of context patterns and extracted contextpatterns for person, location, organization and title-object classes and these are added to the baselineNER system.The shared task was defined to build the NER sys-tems for 5 Indian languages - Hindi, Bengali, Oriya,Telugu and Urdu for which training data was pro-17vided.
Among these 5 languages only Bengali andHindi are known to us but we have no knowledge forother 3 languages.
So we are unable to build rulesand extract context patterns for these languages.
TheNER systems for these 3 languages contain onlythe baseline system i.e.
the MaxEnt system.
Alsoour baseline MaxEnt NER system uses morphologi-cal and parts-of-speech (POS) information as a fea-ture.
Due to unavailability of morphological ana-lyzer and POS tagger for these 3 languages, these in-formation are not added to the systems.
Among the3 languages, only for Oriya NER system we haveused small gazetteers for person, location and des-ignation extracted from the training data.
For Ben-gali and Hindi the developed systems are completehybrid systems containing rules, gazetteers, contextpatterns and the MaxEnt model.The paper is organized as follows.
A brief sur-vey of different techniques used for the NER taskin different languages and domains are presented inSection 2.
Also a brief survey on nested NE recog-nition system is presented here.
A discussion onthe training data is given in Section 3.
The MaxEntbased NER system is described in Section 4.
Vari-ous features used in NER are then discussed.
Nextwe present the experimental results and related dis-cussions in Section 8.
Finally Section 9 concludesthe paper.2 Previous WorkA variety of techniques has been used for NER.
Thetwo major approaches to NER are:1.
Linguistic approaches.2.
Machine Learning (ML) based approaches.The linguistic approaches typically use rules man-ually written by linguists.
There are several rule-based NER systems, containing mainly lexicalizedgrammar, gazetteer lists, and list of trigger words,which are capable of providing 88%-92% f-measureaccuracy for English (Grishman, 1995; McDonald,1996; Wakao et al, 1996).The main disadvantages of these rule-based tech-niques are that these require huge experience andgrammatical knowledge of the particular languageor domain and these systems are not transferable toother languages or domains.ML based techniques for NER make use of alarge amount of NE annotated training data to ac-quire high level language knowledge.
Several MLtechniques have been successfully used for the NERtask of which Hidden Markov Model (HMM) (Bikelet al, 1997), Maximum Entropy (MaxEnt) (Borth-wick, 1999), Conditional Random Field (CRF) (Liand Mccallum, 2004) are most common.
Combina-tions of different ML approaches are also used.
Sri-hari et al (2000) combines MaxEnt, Hidden MarkovModel (HMM) and handcrafted rules to build anNER system.NER systems use gazetteer lists for identifyingnames.
Both the linguistic approach (Grishman,1995; Wakao et al, 1996) and the ML based ap-proach (Borthwick, 1999; Srihari et al, 2000) usegazetteer lists.Linguistic approach uses handcrafted rules whichneeds skilled linguistics.
Some recent approachestry to learn context patterns through ML which re-duce amount of manual labour.
Talukder et al(2006)combined grammatical and statistical techniques tocreate high precision patterns specific for NE extrac-tion.
An approach to lexical pattern learning for In-dian languages is described by Ekbal and Bandopad-hyay (2007).
They used seed data and annotated cor-pus to find the patterns for NER.The NER task for Hindi has been explored byCucerzan and Yarowsky in their language indepen-dent NER work which used morphological and con-textual evidences (Cucerzan and Yarowsky, 1999).They ran their experiment with 5 languages - Roma-nian, English, Greek, Turkish and Hindi.
Amongthese the accuracy for Hindi was the worst.
ForHindi the system achieved 41.70% f-value with avery low recall of 27.84% and about 85% precision.A more successful Hindi NER system was devel-oped by Wei Li and Andrew Mccallum (2004) usingConditional Random Fields (CRFs) with feature in-duction.
They were able to achieve 71.50% f-valueusing a training set of size 340k words.
In Hindithe maximum accuracy is achieved by Kumar andBhattacharyya, (2006).
Their Maximum EntropyMarkov Model (MEMM) based model gives 79.7%f-value.All the NER systems described above are ableto detect one-level NEs.
In recent years, the inter-est in detection of nested NEs has increased.
Here18we mention few attempts for nested NE detection.Zhou et al (2004) described an approach to iden-tify cascaded NEs from biomedical texts.
They de-tected the innermost NEs first and then they derivedrules to find the other NEs containing these as sub-strings.
Another approach, described by McDonaldet al (2005), uses structural multilevel classifica-tion to deal with overlapping and discontinuous enti-ties.
B. Gu (2006) has treated the task of identifyingthe nested NEs a binary classification problem andsolved it using support vector machines.
For eachtoken in nested NEs, they used two schemes to setits class label: labeling as the outermost entity or theinner entities.3 Training DataThe data used for the training of the systems wasprovided.
The annotated data uses Shakti StandardFormat (SSF).
For our development we have con-verted the SSF format data into the IOB formattedtext in which a B ?
XXX tag indicates the firstword of an entity type XXX and I?XXX is usedfor subsequent words of an entity.
The tag O indi-cates the word is outside of a NE.
The training datafor Hindi contains more than 5 lakh words, for Ben-gali about 160K words and about 93K, 64K and 36Kwords for Oriya, Telugu and Urdu respectively.In time of development we have observed thatthe training data, provided by the organizers of theshared task, contains several types of errors in NEtagging.
These errors in the training corpora affectsbadly to the machine learning (ML) based models.But we have not made corrections of the errors inthe training corpora in time of our development.
Allthe results shown in the paper are obtained using theprovided corpora without any modification in NEannotation.4 Maximum Entropy Based ModelWe have used MaxEnt model to build the baselineNER system.
MaxEnt is a flexible statistical modelwhich assigns an outcome for each token based onits history and features.
Given a set of features and atraining corpus, the MaxEnt estimation process pro-duces a model.
For our development we have useda Java based open-nlp MaxEnt toolkit1 to get the1www.maxent.sourceforge.netprobability values of a word belonging to each class.That is, given a sequence of words, the probabilityof each class is obtained for each word.
To find themost probable tag corresponding to each word of asequence, we can choose the tag having the highestclass conditional probability value.
But this methodis not good as it might result in an inadmissible as-signment.Some tag sequences should never happen.
Toeliminate these inadmissible sequences we havemade some restrictions.
Then we used a beamsearch algorithm with a beam of length 3 with theserestrictions.4.1 FeaturesMaxEnt makes use of different features for identify-ing the NEs.
Orthographic features (like capitaliza-tion, decimal, digits), affixes, left and right context(like previous and next words), NE specific triggerwords, gazetteer features, POS and morphologicalfeatures etc.
are generally used for NER.
In En-glish and some other languages, capitalization fea-tures play an important role as NEs are generallycapitalized for these languages.
Unfortunately thisfeature is not applicable for the Indian languages.Also Indian person names are more diverse, lots ofcommon words having other meanings are also usedas person names.
Li and Mccallum (2004) used theentire word text, character n-grams (n = 2, 3, 4),word prefix and suffix of lengths 2, 3 and 4, and 24Hindi gazetteer lists as atomic features in their HindiNER.
Kumar and Bhattacharyya (2006) used wordfeatures (suffixes, digits, special characters), contextfeatures, dictionary features, NE list features etc.
intheir MEMM based Hindi NER system.
In the fol-lowing we have discussed about the features we haveidentified and used to develop the Indian languageNER systems.Static Word Feature: The previous and nextwords of a particular word are used as features.
Theprevious m words (wi?m...wi?1) to next n words(wi+1...wi+n) can be considered.
During our exper-iment different combinations of previous 4 to next 4words are used.Context Lists: Context words are defined as thefrequent words present in a word window for a par-ticular class.
We compiled a list of the most frequentwords that occur within a window of wi?3...wi+319of every NE class.
For example, location con-text list contains the words like ?jAkara2?
(go-ing to), ?desha?
(country), ?rAjadhAnI?
(capital)etc.
and person context list contains ?kahA?
(say),?pradhAnama.ntrI?
(prime minister) etc.
For agiven word, the value of this feature correspond-ing to a given NE type is set to 1 if the windowwi?3...wi+3 around the wi contains at last one wordfrom this list.Dynamic NE tag: Named Entity tags of the pre-vious words (ti?m...ti?1) are used as features.First Word: If the token is the first word of asentence, then this feature is set to 1.
Otherwise, itis set to 0.Contains Digit: If a token ?w?
contains digit(s)then the feature ContainsDigit is set to 1.Numerical Word: For a token ?w?
if the wordis a numerical word i.e.
a word denoting a number(e.g.
eka (one), do (two), tina (three) etc.)
then thefeature NumWord is set to 1.Word Suffix: Word suffix information is helpfulto identify the NEs.
Two types of suffix featureshave been used.
Firstly a fixed length word suffix ofthe current and surrounding words are used as fea-tures.
Secondly we compiled lists of common suf-fixes of person and place names in Hindi.
For ex-ample, ?pura?, ?bAda?, ?nagara?
etc.
are locationsuffixes.
We used binary features corresponding tothe lists - whether a given word has a suffix from aparticular list.Word Prefix: Prefix information of a word mayalso be helpful in identifying whether it is a NE.
Afixed length word prefix of current and surroundingwords are treated as features.Root Information of Word: Indian languagesare morphologically rich.
Words are inflected in var-ious forms depending on its number, tense, person,case etc.
Identification of NEs becomes difficult forthese inflections.
The task becomes easier if insteadof the inflected words, corresponding root words arechecked whether these are NE or not.
For that taskwe have used morphological analyzers for Hindi andBengali which are developed at IIT kharagpur.Parts-of-Speech (POS) Information: The POSof the current word and the surrounding words may2All Hindi words are written in italics using the ?Itrans?transliterationbe useful feature for NER.
We have accessed toHindi and Bengali POS taggers developed at IITKharagpur which has accuracy about 90%.
Thetagset of the tagger contains 28 tags.
We have usedthe POS values of the current and surrounding to-kens as features.We realized that the detailed POS tagging is notvery relevant.
Since NEs are noun phrases, the nountag is very relevant.
Further the postposition follow-ing a name may give a clue to the NE type for Hindi.So we decided to use a coarse-grained tagset withonly three tags - nominal (Nom), postposition (PSP)and other (O).The POS information is also used by defining sev-eral binary features.
An example is the NomPSPbinary feature.
The value of this feature is definedto be 1 if the current token is nominal and the nexttoken is a PSP.5 Language Specific RulesAfter building of the MaxEnt model we have ob-served that only a small set of rules are able to iden-tify the classes like number, measure, time, more ef-ficiently than the MaxEnt based model.
Then wehave tried to define the rules for these classes.
Therule identification is done manually and requires lan-guage knowledge.
We have defined the requiredrules for Bengali and Hindi but we are unable to dothe same for other 3 languages as the languages areunknown to us.
In the following we have mentionedsome example rules which are defined and used inour system.?
IF ((Wi is a number or numeric word) AND(Wi+1 is an unit))THEN (Wi Wi+1) bigram is a measure NE.?
IF ((Wi is a number or numeric word) AND(Wi+1 is a month-name) AND (Wi+2 is a 4digit number))THEN (Wi Wi+1 Wi+2) trigram is a time NE.?
IF ((Wi denotes a day of a week) AND (Wi+1is a number or numeric word) AND (Wi+2 is amonth name))THEN (Wi Wi+1 Wi+2) trigram is a time NE.We have defined 36 rules in total for time, mea-sure and number classes.
These rules use some lists20which are built.
These lists contain correspond-ing entries both in the target language and in En-glish.
For example the months names list containsthe names according to the English calender and thenames according to the Indian calender.
In the fol-lowing we have mentioned the lists we have pre-pared for the rule-based module.?
Names of months.?
Names of seasons.?
Days of a week.?
Names of units.?
Numerical words.5.1 Semi-automatic Extraction of ContextPatternsSimilar to the rules defined for time, measure anddate classes, if efficient context patterns (CP) canbe extracted for a particular class, these can helpin identification of NEs of the corresponding class.But extraction of CP requires huge labour if donemanually.
We have developed a module for semi-automatically extraction of context patterns.
Thismodule makes use of the most frequent entities ofa particular class as seed for that class and finds thesurrounding tokens of the seed to extract effectivepatterns.
We mark a pattern as ?effective?
if the pre-cision of the pattern is very high.
Precision of a pat-tern is defined as the ratio of correct identificationand the total identification when the pattern is usedto identify NEs of a particular type from a text.For our task we have extracted patterns for per-son, location, organization and title-object classes.These patterns are able to identify the NEs of a spe-cific classes but detection of NE boundary is notdone properly by the patterns.
For boundary detec-tion we have added some heuristics and used POSinformation of the surrounding words.
The patternsfor a particular class may identify the NEs of otherclasses also.
For example the patterns for identify-ing person names may also identify the designationor title-persons.
These need to be handled carefullyat the time of using patterns.
In the following someexample patterns are listed which are able to identifyperson names for Hindi.?
<PER> ne kahA ki?
<PER> kA kathana he.n?
mukhyama.ntrI <PER> Aja?
<PER> ne apane gra.ntha?
<PER> ke putra <PER>6 Use of Gazetteer ListsLists of names of various types are helpful in nameidentification.
Firstly we have prepared the lists us-ing the training corpus.
But these are not sufficient.Then we have compiled some specialized name listsfrom different web sources.
But the names in theselists are in English, not in Indian languages.
So wehave transliterated these English name lists to makethem useful for our NER task.Using transliteration we have constructed severallists.
Which are, month name and days of the week,list of common locations, location names list, firstnames list, middle names list, surnames list etc.The lists can be used in name identification in var-ious ways.
One way is to check whether a token is inany list.
But this approach is not good as it has somelimitations.
Some words may present in two or moregazetteer lists.
Confusions arise to make decisionsfor these words.
Some words are in gazetteer listsbut sometimes these are used in text as not-name en-tity.
We have used these gazetteer lists as features ofMaxEnt.
We have prepared several binary featureswhich are defined as whether a given word is in aparticular list.7 Detection of Nested EntitiesThe training corpora used for the models, are notannotated as nested.
The maximal entities are an-notated in the training corpus.
For detection of thenested NEs, we have derived some rules.
For exam-ple, if a particular word is a number or numeric wordand is a part of a NE type other than ?number?, thenwe have made the nesting.
Again, if any common lo-cation identifier word like, jilA (district), shahara(town) etc.
is a part of a ?location?
entity then wehave nested there.
During one-level NE identifica-tion, we have generated lists for all the identified lo-cation and person names.
Then we have searchedother NEs containing these as substring to make the21nesting.
After preparing the one-level NER system,we have applied the derived rules on it to identifythe nested entities.8 EvaluationThe accuracies of the system are measured in termsof the f-measure, which is the weighted harmonicmean of precision and recall.
Nested, maximal andlexical accuracies are calculated separately.
Thetest data for all the five languages are provided.The size of the shared task test files are: Hindi- 38,704 words, Bengali - 32,796 words, Oriya -26,988 words, Telugu - 7,076 words and Urdu -12,805 words.We have already mentioned that after preparinga one-level NER system, the rule-based module isused to modify it to a nested one.
A number of ex-periments are conducted considering various combi-nations of features to identify the best feature set forIndian language NER task.
It is very difficult andtime consuming to conduct experiments for all thelanguages.
During the development we have con-ducted all the experiments on Hindi and Bengali.
Wehave prepared a development test data composed of24,265 words for Hindi and 10,902 word for Ben-gali and accuracies of the system are tested on thedevelopment data.
The details of the experiments onHindi data for the best feature selection is describedin the following section.8.1 Best Feature Set SelectionThe performance of the system on the Hindi datausing various features are presented in Table 1.They are summarized below.
While experimentingwith static word features, we have observed that awindow of previous two words to next two words(Wi?2...Wi+2) gives best results.
But when sev-eral other features are combined then smaller win-dow (Wi?1...Wi+1) performs better.
Similarly wehave experimented with suffixes of different lengthsand observed that the suffixes of length ?
2 givesthe best result for the Hindi NER task.
In usingPOS information, we have observed that the coarse-grained POS tagger information is more effectivethan the finer-grained POS values.
The most in-teresting fact we have observed that more complexfeatures do not guarantee to achieve better results.For example, a feature set combined with currentand surrounding words, previous NE tag and fixedlength suffix information, gives a f-value 64.17%.But when prefix information are added the f-valuedecreased to 63.73%.
Again when the context listsare added to the feature set containing words, previ-ous tags, suffix information, digit information andthe NomPSP binary feature, the accuracy has de-creased to 67.33% from 68.0%.Feature OverallF-valueWord, NE Tag 58.92Word, NE Tag, Suffix (?
2) 64.17Word, NE Tag, Suffix (?
2),Prefix63.73Word, NE Tag, Digit, Suffix 66.61Word, NE Tag, Context List 63.57Word, NE Tag, POS (full) 61.28Word, NE Tag, Suffix (?
2),Digit, NomPSP68.60Word, NE Tag, Suffix (?
2),Digit, Context List, NomPSP67.33Word, NE Tag, Suffix (?2), Digit, NomPSP, Linguis-tic Rules73.40Word, NE Tag, Suffix (?
2),Digit, NomPSP, Gazetteers72.08Word, NE Tag, Suffix (?2), Digit, NomPSP, Linguis-tic Rules, Gazetteers74.53Table 1: Hindi development set f-values for differentfeaturesThe feature set containing words, previoustags, suffix information, digit information and theNomPSP binary feature is the identified best featureset without linguistic rules and gazetteer informa-tion.
Then we have added the linguistic rules, pat-terns and gazetteer information to the system and thechanges in accuracies are shown in the table.8.2 Results on the Test DataThe best identified feature set is used for the de-velopment of the NER systems for all the five lan-guages.
We have already mentioned that for onlyfor Bengali and Hindi we have added linguistic rules22and gazetteer lists in the MaxEnt based NER sys-tems.
The accuracy of the system on the shared tasktest data for all the languages are shown in Table 2.Lan-guageType Preci-sionRecall F-measureBengaliMaximal 52.92 68.07 59.54Nested 55.02 68.43 60.99Lexical 62.30 70.07 65.96HindiMaximal 75.19 58.94 66.08Nested 79.58 58.61 67.50Lexical 82.76 53.69 65.13OriyaMaximal 21.17 26.92 23.70Nested 27.73 28.13 27.93Lexical 51.51 39.40 44.65TeluguMaximal 10.47 9.64 10.04Nested 22.05 13.16 16.48Lexical 25.23 14.91 18.74UrduMaximal 26.12 29.69 27.79Nested 27.99 29.21 28.59Lexical 37.58 33.58 35.47Table 2: Accuracy of the system for all languagesThe accuracies of Oriya, Telugu and Urdu lan-guages are poor compared to the other two lan-guages.
The reasons are POS information, mor-phological information, language specific rules andgazetteers are not used for these languages.
Also thesize of training data for these languages are smaller.To mention, for Urdu, size of the training data is onlyabout 36K words which is very small to train a Max-Ent model.It is mentioned that we have prepared a set of ruleswhich are capable of identifying the nested NEs.Once the one-level NER system has built, we haveapplied the rules on it.
In Table 3 we have shownthe f-values of each class after addition of the nestedrules.
The detailed results for all languages are notshown.
In the table we have shown only the resultsof Bengali and Hindi.For both the languages ?title-person?
and ?desig-nation?
classes are suffering from poor accuracies.The reason is, in the training data and also in theannotated test data, these classes contains many an-notation errors.
Also the classes being closely re-lated to each other, the system fails to distinguishthem properly.
The detection of the ?term?
class isHindi BengaliClass Maximal Nested Maximal NestedPerson 70.87 71.00 77.45 79.09Desig-nation48.98 59.81 26.32 26.32Organi-zation47.22 47.22 41.43 71.43Abbre-viation- 72.73 51.61 51.61Brand - - - -Title-person- 60.00 5.19 47.61Title-object41.32 40.98 72.97 72.97Location 86.02 87.02 76.27 76.27Time 67.42 67.42 56.30 56.30Number 84.59 85.13 40.65 40.65Measure 59.26 55.17 62.50 62.50Term 48.91 50.51 43.67 43.67Table 3: Comparison of maximal and nested f-values for different classes of Hindi and Bengalivery difficult.
In the test files amount of ?term?
en-tity is large, for Bengali - 434 and for Hindi - 1080,so the poor accuracy of the class affects badly to theoverall accuracy.
We have made rule-based identi-fication for ?number?, ?measure?
and ?time?
classes;the accuracies of these classes proves that the rulesneed to be modified to achieve better accuracy forthese classes.
Also the accuracy of the ?organiza-tion?
class is not high, because amount of organiza-tion entities is not sufficient in the training corpus.We have achieved good results for other two mainclasses - ?person?
and ?location?.8.3 Comparison with Other Shared TaskSystemsThe comparison of the accuracies of our systemand other shared task systems is given in Table 4.From the comparison we can see that our systemhas achieved the best accuracies for most of the lan-guages.9 ConclusionWe have prepared a MaxEnt based system for theNER task in Indian languages.
We have also added23Lan-guageOur S2 S6 S7Bengali 65.96 39.77 40.63 59.39Hindi 65.13 46.84 50.06 33.12Oriya 44.65 45.84 39.04 28.71Telugu 18.74 46.58 40.94 4.75Urdu 35.47 44.73 43.46 35.52Table 4: Comparison of our lexical f-measure accu-racies with the systems : S2 - Praveen P.(2008), S6 -Gali et al(2008) and S7 - Ekbal et al(2008)rules and gazetteers for Bengali and Hindi.
Also ourderived rules need to be modified for improvementof the system.
We have not made use of rules andgazetteers for Oriya, Telugu and Urdu.
As the sizeof training data is not much for these 3 languages,rules and gazetteers would be effective.
We haveexperimented with MaxEnt model only, other MLmethods like HMM, CRF or MEMM may be ableto give better accuracy.
We have not worked muchon the detection of nested NEs.
Proper detection ofnested entities may lead to further improvement ofperformance and is under investigation.ReferencesBikel Daniel M., Miller Scott, Schwartz Richard andWeischedel Ralph.
1997.
Nymble: A High Perfor-mance Learning Name-finder.
In Proceedings of theFifth Conference on Applied Natural Language Pro-cessing, 194?201.Borthwick Andrew.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
Ph.D. thesis,Computer Science Department, New York University.Cucerzan Silviu and Yarowsky David.
1999.
LanguageIndependent Named Entity Recognition CombiningMorphological and Contextual Evidence.
In Proceed-ings of the Joint SIGDAT Conference on EMNLP andVLC 1999, 90?99.Ekbal A. and Bandyopadhyay S. 2007.
Lexical PatternLearning from Corpus Data for Named Entity Recog-nition.
In Proceedings of International Conference onNatural Language Processing (ICON), 2007.Ekbal A., Haque R., Das A., Poka V. and Bandyopad-hyay S. 2008.
Language Independent Named EntityRecognition in Indian Languages In Proceedings ofIJCNLP workshop on NERSSEAL.
(Accepted)Gali K., Surana H., Vaidya A., Shishtla P. and MisraSharma D. 2008.
Named Entity Recognition throughCRF Based Machine Learning and Language SpecificHeuristics In Proceedings of IJCNLP workshop onNERSSEAL.
(Accepted)Grishman Ralph.
1995.
The New York University Sys-tem MUC-6 or Where?s the syntax?
In Proceedings ofthe Sixth Message Understanding Conference.Gu B.
2006.
Recognizing Nested Named Entities in GE-NIA corpus.
In Proceedings of the BioNLP Workshopon Linking Natural Language Processing and Biologyat HLT-NAACL 06, pages 112-113.Kumar N. and Bhattacharyya Pushpak.
2006.
NamedEntity Recognition in Hindi using MEMM.
In Techni-cal Report, IIT Bombay, India..Li Wei and McCallum Andrew.
2004.
Rapid Develop-ment of Hindi Named Entity Recognition using Condi-tional Random Fields and Feature Induction (Short Pa-per).
In ACM Transactions on Computational Logic.McDonald D. 1996.
Internal and external evidence in theidentification and semantic categorization of propernames.
In B. Boguraev and J. Pustejovsky, editors,Corpus Processing for Lexical Acquisition, 21?39.McDonald R., Crammer K. and Pereira F. 2005.
Flexibletext segmentation with structured multilabel classifica-tion.
In Proceedings of EMNLP05.Praveen P. 2008.
Hybrid Named Entity Recogni-tion System for South-South East Indian Languages.InProceedings of IJCNLP workshop on NERSSEAL.
(Accepted)Srihari R., Niu C. and Li W. 2000.
A Hybrid Approachfor Named Entity and Sub-Type Tagging.
In Proceed-ings of the sixth conference on Applied natural lan-guage processing.Talukdar Pratim P., Brants T., Liberman M., and PereiraF.
2006.
A context pattern induction methodfor named entity extraction.
In Proceedings of theTenth Conference on Computational Natural Lan-guage Learning (CoNLL-X).Wakao T., Gaizauskas R. and Wilks Y.
1996.
Evaluationof an algorithm for the recognition and classificationof proper names.
In Proceedings of COLING-96.Zhou G., Zhang J., Su J., Shen D. and Tan C. 2004.Recognizing Names in Biomedical Texts: a MachineLearning Approach.
Bioinformatics, 20(7):1178-1190.24
