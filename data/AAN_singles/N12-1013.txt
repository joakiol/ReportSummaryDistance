2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 120?130,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsMinimum-Risk Training of Approximate CRF-Based NLP SystemsVeselin Stoyanov and Jason EisnerHLTCOE and Center for Language and Speech ProcessingJohns Hopkins UniversityBaltimore, MD 21218{ves, jason}@cs.jhu.eduAbstractConditional Random Fields (CRFs) are a pop-ular formalism for structured prediction inNLP.
It is well known how to train CRFs withcertain topologies that admit exact inference,such as linear-chain CRFs.
Some NLP phe-nomena, however, suggest CRFs with morecomplex topologies.
Should such models beused, considering that they make exact infer-ence intractable?
Stoyanov et al (2011) re-cently argued for training parameters to min-imize the task-specific loss of whatever ap-proximate inference and decoding methodswill be used at test time.
We apply theirmethod to three NLP problems, showing that(i) using more complex CRFs leads to im-proved performance, and that (ii) minimum-risk training learns more accurate models.1 IntroductionConditional Random Fields (CRFs) (Lafferty et al,2001) are often used to model dependencies amonglinguistic variables.
CRF-based models have im-proved the state of the art in a number of naturallanguage processing (NLP) tasks ranging from part-of-speech tagging to information extraction and sen-timent analysis (Lafferty et al, 2001; Peng and Mc-Callum, 2006; Choi et al, 2005).Robust and theoretically sound training proce-dures have been developed for CRFs when themodel can be used with exact inference and de-coding.1 However, some NLP problems seem to1?Inference?
typically refers to computing posteriormarginal or max-marginal probability distributions of outputrandom variables, given some evidence.
?Decoding?
derivesa single structured output from the results of inference.call for higher-treewidth graphical models in whichexact inference is expensive or intractable.
These?loopy?
CRFs have cyclic connections among theoutput and/or latent variables.
Alas, standard learn-ing procedures assume exact inference: they do notcompensate for approximations that will be used attest time, and can go surprisingly awry if approxi-mate inference is used at training time (Kulesza andPereira, 2008).While NLP research has been consistently evolv-ing toward more richly structured models, one mayhesitate to add dependencies to a graphical model ifthere is a danger that this will end up hurting per-formance through approximations.
In this paper weillustrate how to address this problem, even for ex-tremely interconnected models in which every pairof output variables is connected.Wainwright (2006) showed that if approximate in-ference will be used at test time, it may be beneficialto use a learning procedure that does not converge tothe true model but to one that performs well underthe approximations.
Stoyanov et al (2011) argue forminimizing a certain non-convex training objective,namely the empirical risk of the entire system com-prising the CRF together with whatever approximateinference and decoding procedures will be used attest time.
They regard this entire system as sim-ply a complex decision rule, analogous to a neu-ral network, and show how to use back-propagationto tune its parameters to locally minimize the em-pirical risk (i.e., the average task-specific loss ontraining data).
Stoyanov et al (2011) show thaton certain synthetic-data problems, this frequentisttraining regimen significantly reduced test-data loss120compared to approximate maximum likelihood esti-mation (MLE).
However, this method has not beenevaluated on real-world problems until now.We will refer to the Stoyanov et al (2011) ap-proach as ?ERMA?
?Empirical Risk Minimizationunder Approximations.
ERMA is attractive for NLPbecause the freedom to use arbitrarily structuredgraphical models makes it possible to include latentlinguistic variables, predict complex structures suchas parses (Smith and Eisner, 2008), and do collec-tive prediction in relational domains (Ji and Grish-man, 2011; Benson et al, 2011; Dreyer and Eis-ner, 2009).
In training, ERMA considers not onlythe approximation method but also the task-specificloss function.
This means that ERMA is careful touse the additional variables and dependencies onlyin ways that help training set performance.
(Overfit-ting on the enlarged parameter set should be avoidedthrough regularization.
)We have developed a simple syntax for specify-ing CRFs with complex structures, and a softwarepackage (available from http://www.clsp.jhu.edu/?ves/software.html) that allowsERMA training of these CRFs for several popularloss functions (e.g., accuracy, mean-squared error,F-measure).
In this paper, we use these tools to re-visit three previously studied NLP applications thatcan be modeled naturally with approximate CRFs(we will use approximate CRFs to refer to CRF-based systems that are used with approximations ininference or decoding).
We show that (i) natural lan-guage can be modeled more effectively with CRFsthat are not restricted to a linear structure and (ii)that ERMA training represents an improvement overprevious learning methods.The first application, predicting congressionalvotes, has not been previously modeled with CRFs.By using a more principled probabilistic approach,we are able to improve the state-of-the-art accuracyfrom 71.2% to 78.2% when training to maximize theapproximate log-likelihood of the training data.
Byswitching to ERMA training, we improve this resultfurther to 85.1%.The second application, information extractionfrom seminar announcements, has been modeledpreviously with skip-chain CRFs (Sutton and Mc-Callum, 2005; Finkel et al, 2005).
The skip-chainCRF introduces loops and requires approximate in-ference, which motivates minimum risk training.Our results show that ERMA training improves F-measures from 89.5 to 90.9 (compared to 87.1 forthe model without skip-chains).Finally, for our third application, we perform col-lective multi-label text classification.
We follow pre-vious work (Ghamrawi and McCallum, 2005; Finleyand Joachims, 2008) and use a fully connected CRFto model all pairwise dependencies between labels.We observe similar trends for this task: switchingfrom a maximum entropy model that does not modellabel dependencies to a loopy CRF leads to an im-provement in F-measure from 81.6 to 84.0, and us-ing ERMA leads to additional improvement (84.7).2 Preliminaries2.1 Conditional Random FieldsA conditional random field (CRF) is an undirectedgraphical model defined by a tuple (X ,Y,F , f, ?
).X = (X1, X2, .
.
.)
is a set of random variables andY = (Y1, Y2, .
.
.)
is a set of output random vari-ables.2 We use x = (x1, x2, .
.
.
), to denote a possi-ble assignment of values to X , and similarly for y,with xy denoting the joint assignment.
Each ?
?
Fis a subset of the random variables, ?
?
X ?
Y ,and we write xy?
to denote the restriction of xy to?.
Finally, for each ?
?
F , the CRF specifies afunction ~f?
that extracts a feature vector ?
Rd fromthe restricted assignment xy?.
We define the over-all feature vector ~f(x,y) =???F~f?(xy?)
?
Rd.The model defines conditional probabilitiesp?
(y|x) =exp ~?
?
~f(x,y)?y?
exp~?
?
~f(x,y?
)(1)where ~?
?
Rd is a global weight vector (to belearned).
This is a log-linear model; the denomina-tor (traditionally denoted Zx) sums over all possibleoutput assignments to normalize the distribution.Provided that all probabilities needed at trainingor test time are conditioned on an observation of theform X = x, CRFs can include arbitrary overlap-ping features of the input without having to explic-itly model input feature dependencies.2Stoyanov et al (2011) distinguished some of the Y vari-ables as latent (i.e., unsupervised and ignored by the loss func-tion).
We omit this possibility, to simplify the notation.1212.2 Inference in CRFsInference in general CRFs is intractable (Koller andFriedman, 2009).
Nevertheless, there exist severalapproximate algorithms that have theoretical moti-vation and tend to exhibit good performance in prac-tice.
Those include variational methods such asloopy belief propagation (BP) (Murphy et al, 1999)and mean-field, as well as Markov Chain MonteCarlo methods.ERMA training is applicable to any approxima-tion that corresponds to a differentiable function,even if the function has no simple closed form but iscomputed by an iterative update algorithm.
In thispaper we select BP, which is exact when the fac-tor graph is a tree, such as a linear-chain CRF, butwhose results can be somewhat distorted by loopsin the factor graph, as in our settings.
BP computesbeliefs about the marginal distribution of each ran-dom variable using iterative updates.
We standardlyapproximate the posterior CRF marginals given theinput observations by running BP over a CRF thatenforces those observations.2.3 DecodingConditional random fields are models of probabil-ity.
A decoder is a procedure for converting theseprobabilities into system outputs.
Given x, the de-coder would ideally choose y to minimize the loss`(y,y?
), where ` compares a candidate assignmenty to the true assignment y?.
But of course we do notknow the truth at test time.
Instead we can averageover possible values y?
of the truth:argminy?y?p(y?
| x) ?
`(y,y?)
(2)This is the minimum Bayes risk (MBR) principlefrom statistical decision theory: choose y to mini-mize the expected loss (i.e., the risk) according tothe CRF?s posterior beliefs given x.In the NLP literature, CRFs are often decoded bychoosing y to be the maximum posterior probabil-ity assignment (e.g., Sha and Pereira (2003), Suttonet al (2007)).
This is the MBR procedure for the0-1 loss function that simply tests whether y = y?.For other loss functions, however, the correspondingMBR procedure is preferable.
For some loss func-tions it is tractable given the posterior marginals ofp, while in other cases approximations are needed.In our experiments we use MBR decoding (or atractable approximation) but substitute the approx-imate posterior marginals of p as computed by BP.For example, if the loss of y is the number of incor-rectly recovered output variables, MBR says to sep-arately pick the most probable value for each outputvariable, according to its (approximate) marginal.3 Minimum-Risk CRF TrainingThis section briefly describes the ERMA training al-gorithm from Stoyanov et al (2011) and compares itto related structured learning methods.
We assumea standard ML setting, with a set of training inputsxi and corresponding correct outputs yi?.
All themethods below are regularized in practice, but weomit mention of regularizers for simplicity.3.1 Related Structured Learning MethodsWhen inference and decoding can be performed ex-actly, the CRF parameters ~?
are often trained bymaximum likelihood estimation (MLE):argmax?
?ilog p?(yi?
| xi) (3)The gradient of each summand log p?(yi?
| xi)can be computed by performing inference in two set-tings, one with xi,yi?
observed and one with onlythe conditioning events xi observed.
The gradientemerges as the difference between the feature ex-pectations in the two cases.
If exact inference isintractable, one can compute approximate featureexpectations by loopy BP.
Computing the approx-imate gradient in this way, and training the CRFwith some gradient-based optimization method, hasbeen shown to work relatively well in practice (Vish-wanathan et al, 2006; Sutton and McCallum, 2005).The above method takes into account neither theloss function that will be used for evaluation, northe approximate algorithms that have been selectedfor inference and decoding at test time.
Other struc-ture learning methods do consider loss, though it isnot obvious how to make them consider approxima-tions.
Those include maximum margin (Taskar etal., 2003; Finley and Joachims, 2008) and softmax-margin (Gimpel and Smith, 2010).
The idea ofmargin-based methods is to choose weights ~?
so thatthe correct alternative yi?
always gets a better score122than each possible alternative yi ?
Y .
The loss isincorporated in these methods by requiring the mar-gin (~?
?
~f(xi,yi?)?
~?
?
~f(xi,yi)) ?
`(yi,yi?
), withpenalized slack in these constraints.
The softmax-margin method uses a different criterion?it resem-bles MLE but modifies the denominator of (1) toZx =?y?
?Y exp(~?
?
~f(x,y?)
+ `(y?,y?
)).In our experiments we compare against MLEtraining (which is common) and softmax-margin,which incorporates loss and which Gimpel andSmith (2010) show is either better or competitivewhen compared to other margin methods on an NLPtask.
We adapt these methods to the loopy case inthe obvious way, by replacing exact inference withloopy BP and keeping everything else the same.3.2 Minimum-Risk TrainingWe wish to consider the approximate inference anddecoding algorithms and the loss function that willbe used during testing.
Thus, we want ?
to minimizethe expected loss under the true data distribution P :argmin?Exy?P [`(??
(x),y)] (4)where ??
is the decision rule (parameterized by ?
),which decodes the results of inference under p?.In practice, we do not know the true data distri-bution, but we can do empirical risk minimization(ERM), instead averaging the loss over our sampleof (xi,yi) pairs.
ERM for structured prediction wasfirst introduced in the speech community (Bahl etal., 1988) and later used in NLP (Och, 2003; Kakadeet al, 2002; Suzuki et al, 2006; Li and Eisner, 2009,etc.).
Previous applications of risk minimization as-sume exact inference, having defined the hypothe-sis space by a precomputed n-best list, lattice, orpacked forest over which exact inference is possible.The ERMA approach (Stoyanov et al, 2011)works with approximate inference and computes ex-act gradients of the output loss (or a differentiablesurrogate) in the context of the approximate infer-ence and decoding algorithms.
To determine the gra-dient of `(??
(xi),yi) with respect to ?, the methodrelies on automatic differentiation in the reversemode (Griewank and Corliss, 1991), a general tech-nique for sensitivity analysis in computations.
Theintuition behind automatic differentiation is that theentire computation is a sequence of elementary dif-ferentiable operations.
For each elementary opera-tion, given that we know the input and result values,and the partial derivative of the loss with respect tothe result, we can compute the partial derivative ofthe loss with respect to the inputs to the step.
Dif-ferentiating the whole complicated computation canbe carried out in backward pass in this step-by-stepmanner as long as we record intermediate resultsduring the computation of the function (the forwardpass).
At the end, we accumulate the partials of theloss with respect to each parameter ?i.ERMA is similar to back-propagation used in re-current neural networks, which involve cyclic up-dates like those in belief propagation (Williams andZipser, 1989).
It considers an ?unrolled?
version ofthe forward pass, in which ?snapshots?
of a vari-able at times t and t + 1 are treated as distinct vari-ables, with one perhaps influencing the other.
Theforward pass computes `(??
(xi),yi) by performingapproximate inference, then decoding, then evalu-ation.
These steps convert (xi, ?)
?
marginals ?decision?
loss.
The backward pass rewinds the en-tire computation, differentiating each phase in term.The total time required by this algorithm is roughlytwice the time of the forward pass, so its complexityis comparable to approximate inference.In this paper, we do not advocate any particulartest-time inference or decoding procedures.
It is rea-sonable to experiment with several choices that mayproduce faster or more accurate systems.
We sim-ply recommend doing ERMA training to match eachselected test-time condition.
Stoyanov et al (2011)specifically showed how to train a system that willuse sum-product BP for inference at test time (un-like margin-based methods).
This may be advanta-geous for some tasks because it marginalizes over la-tent variables.
However, it is popular and sometimesfaster to do 1-best decoding, so we also include ex-periments where the test-time system returns a 1-best value of y (or an approximation to this if theCRF is loopy), based on max-product BP inference.Although 1-best systems are not differentiable func-tions, we can approach their behavior during ERMtraining by annealing the training objective (Smithand Eisner, 2006).
In the annealed case we evaluate(4) and its gradient under sum-product BP, exceptthat we perform inference under p(?/T ) instead of p?.123We gradually reduce the temperature T ?
R from 1to 0 as training proceeds, which turns sum-productinference into max-product by moving all the prob-ability mass toward the highest-scoring assignment.4 Modeling Natural Language with CRFsThis section describes three NLP problems that canbe naturally modeled with approximate CRFs.
Thefirst problem, modeling congressional votes, has notbeen previously modeled with a CRF.
We show thatby switching to the principled CRF framework wecan learn models that are much more accurate whenevaluated on test data, though using the same (or lessexpressive) features as previous work.
The othertwo problems, information extraction from semi-structured text and collective multi-label classifica-tion, have been modeled with loopy CRFs before.For all three models, we show that ERMA trainingresults in better test set performance.34.1 Modeling Congressional VotesThe Congressional Vote (ConVote) corpus was cre-ated by Thomas et al (2006) to study whether votesof U.S. congressional representatives can be pre-dicted from the speeches they gave when debatinga bill.
The corpus consists of transcripts of con-gressional floor debates split into speech segments.Each speech segment is labeled with the represen-tative who is speaking and the recorded vote of thatrepresentative on the bill.
We aim to predict a highpercentage of the recorded votes correctly.Speakers often reference one another (e.g., ?Ithank the gentleman from Utah?
), to indicate agree-ment or disagreement.
The ConVote corpus manu-ally annotates each phrase such as ?the gentlemanfrom Utah?
with the representative that it denotes.Thomas et al (2006) show that classification us-ing the agreement/disagreement information in thelocal context of such references, together with therest of the language in the speeches, can lead to sig-nificant improvement over using either of these two3We also experimented with a fourth application, joint POStagging and shallow parsing (Sutton et al, 2007) and observedthe same overall trend (i.e., minimum risk training improvedperformance significantly).
We do not include those experi-ments, however, because we were unable to make our baselineresults replicate (Sutton et al, 2007).sources of information in isolation.
The original ap-proach of Thomas et al (2006) is based on trainingtwo Support Vector Machine (SVM) classifiers?one for classifying speeches as supporting/opposingthe legislation and another for classifying referencesas agreement/disagreement.
Both classifiers rely onbag-of-word (unigram) features of the document andthe context surrounding the link respectively.
Thescores produced by the two SVMs are used to weighta global graph whose vertices are the representa-tives; then the min-cut algorithm is applied to par-tition the vertices into ?yea?
and ?nay?
voters.While the approach of Thomas et al (2006)leads to significant improvement over using the firstSVM alone, it does not admit a probabilistic in-terpretation and the two classifiers are not trainedjointly.
We also remark that the min-cut techniquewould not generalize beyond binary random vari-ables (yea/nay).We observe that congressional votes together withreferences between speakers can be naturally mod-eled with a CRF.
Figure 1 depicts the CRF con-structed for one of the debates in the developmentpart of the ConVote corpus.
It contains a randomvariable for each representative?s vote.
In addition,each speech is an observed input random variable:it is connected by a factor to its speaker?s vote andencourages it to be ?yea?
or ?nay?
according to fea-tures of the text of the speech.
Finally, each ref-erence in each speech is an observed input randomvariable connected by a factor to two votes?thoseof the speaker and the referent?which it encouragesto agree or disagree according to features of the textsurrounding the reference.
Just as in (Thomas et al,2006), the score of a global assignment to all votes isdefined by considering both kinds of factors.
How-ever, unlike min-cut, CRF inference finds a proba-bility distribution over assignments, not just a sin-gle best assignment.
This fact allows us to train thetwo kinds of factors jointly (on the set of trainingdebates where the votes are known) to predict thecorrect votes accurately (as defined by accuracy).As Figure 1 shows, the reference factors introducearbitrary loops, making exact inference intractableand thus motivating ERMA.
Our experiments de-scribed in section 5.2 show that switching to a CRFmodel (keeping the same features) leads to a sizableimprovement over the previous state of the art?124Figure 1: An example of a debate structure from the Con-Vote corpus.
Each black square node represents a factorand is connected to the variables in that factor, shownas round nodes.
Unshaded variables correspond to therepresentatives?
votes and depict the output variables thatwe learn to jointly predict.
Shaded variables correspondto the observed input data?
the text of all speeches of arepresentative (in dark gray) or all local contexts of refer-ences between two representatives (in light gray).and that ERMA further significantly improves per-formance, particularly when it properly trains withthe same inference algorithm (max-product vs. sum-product) to be used at test time.Baseline.
As an exact baseline, we compareagainst the results of Thomas et al (2006).
Theirtest-time Min-Cut algorithm is exact in this case: bi-nary variables and a two-way classification.4.2 Information Extraction fromSemi-Structured TextWe utilize the CMU seminar announcement corpusof Freitag (2000) consisting of emails with seminarannouncements.
The task is to extract four fields thatdescribe each seminar: speaker, location, start timeand end time.
The corpus annotates the documentwith all mentions of these four fields.Sequential CRFs have been used successfully forsemi-structured information extraction (Sutton andMcCallum, 2005; Finkel et al, 2005).
However,they cannot model non-local dependencies in thedata.
For example, in the seminar announcementscorpus, if ?Sutner?
is mentioned once in an emailin a context that identifies him as a speaker, it isSutnerSWho:OProf.SKlausSwillOProf.SSutnerS?
??
?Figure 2: Skip-chain CRF for semi-structured informa-tion extraction.likely that other occurrences of ?Sutner?
in the sameemail should be marked as speaker.
Hence Finkel etal.
(2005) and Sutton and McCallum (2005) proposeadding non-local edges to a sequential CRF to repre-sent soft consistency constraints.
The model, calleda ?skip-chain CRF?
and shown in Figure 2, containsa factor linking each pair of capitalized words withthe same lexical form.
The skip-chain CRF modelexhibits better empirical performance than its se-quential counterpart (Sutton and McCallum, 2005;Finkel et al, 2005).The non-local skip links make exact inferenceintractable.
To train the full model, Finkel et al(2005) estimate the parameters of a sequential CRFand then manually select values for the weights ofthe non-local edges.
At test time, they use Gibbssampling to perform inference.
Sutton and McCal-lum (2005) use max-product loopy belief propaga-tion for test-time inference, and compare a train-ing procedure that uses a piecewise approximationof the partition function against using sum-productloopy belief propagation to compute output variablemarginals.
They find that the two training regimensperform similarly on the overall task.
All of thesetraining procedures try to approximately maximizeconditional likelihood, whereas we will aim to mini-mize the empirical loss of the approximate inferenceand decoding procedures.Baseline.
As an exact (non-loopy) baseline, wetrain a model without the skip chains.
We give twobaseline numbers in Table 1?for training the exactCRF with MLE and with ERM.
The ERM setting re-sulted in a statistically significant improvement evenin the exact case, thanks to the use of the loss func-tion at training time.4.3 Multi-Label ClassificationMulti-label classification is the problem of assign-ing multiple labels to a document.
For example, anews article can be about both ?Libya?
and ?civil125war.?
The most straightforward approach to multi-label classification employs a binary classifier foreach class separately.
However, previous work hasshown that incorporating information about label de-pendencies can lead to improvement in performance(Elisseeff and Weston, 2001; Ghamrawi and McCal-lum, 2005; Finley and Joachims, 2008).For this task we follow Ghamrawi and McCallum(2005) and Finley and Joachims (2008) and modelthe label interactions by constructing a fully con-nected CRF between the output labels.
That is, forevery document, we construct a CRF that containsa binary random variable for each label (indicatingthat the corresponding label is on/off for the doc-ument) and one binary edge for every unique pairof labels.
This architecture can represent dependen-cies between labels, but leads to a setting in whichthe output variables form one massive clique.
Theresulting intractability of inference (and decoding)motivates the use of ERMA training.Baseline.
We train a model without any of thepairwise edges (i.e., a separate logistic regressionmodel for each class).
We report the single bestbaseline number, since MLE and ERM training re-sulted in statistically indistinguishable results.5 Experiments5.1 Learning MethodologyFor all experiments we split the data intotrain/development/test sets using the standard splitswhen available.
We tune optimization algorithm pa-rameters (initial learning rate, batch size and meta-parameters ?
and ?
for stochastic meta descent) onthe training set based on training objective conver-gence rates.
We tune the regularization parameter?
(below) on development data when available, oth-erwise we use a default value of 0.1?performancewas generally robust for small changes in the valueof ?.
All statistical significance testing is performedusing paired permutation tests (Good, 2000).Gradient-based Optimization.
Gradient infor-mation from the back-propagation procedure can beused in a local optimization method to minimize em-pirical loss.
In this paper we use stochastic metadescent (SMD) (Schraudolph, 1999).
SMD is asecond-order method that requires vector-Hessianproducts.
For computing those, we do not need tomaintain the full Hessian matrix.
Instead, we applymore automatic differentiation magic?this time inthe forward mode.
Computing the vector-Hessianproduct and utilizing it in SMD does not add to theasymptotic runtime, it requires about twice as manyarithmetic operations, and leads to much faster con-vergence of the learner in our experience.
See Stoy-anov et al (2011) for details.Since the empirical risk objective could overfitthe training data, we add an L2 regularizer ?
?j ?2jthat prefers parameter values close to 0.
This im-proves generalization, like the margin constraints inmargin-based methods.Training Procedure Stoyanov et al (2011) ob-served that the minimum-risk objective tends to behighly non-convex in practice.
The usual approx-imate log likelihood training objective appeared tobe smoother over the parameter space, but exhibitedglobal maxima at parameter values that were rela-tively good, but sub-optimal for other loss functions.Mean-squared error (MSE) also gave a smoother ob-jective than other loss functions.
These observationsmotivated Stoyanov et al (2011) to use a contin-uation method.
They optimized approximate log-likelihood for a few iterations to get to a good part ofthe parameter space, then switched to using the hy-brid loss function ?`(y, y?)+(1??
)`MSE(y, y?).
Thecoefficient ?
changed gradually from 0 to 1 duringtraining, which morphs from optimizing a smootherloss to optimizing the desired bumpy test loss.
Wefollow the same procedure.Experiments in this paper use two evaluation met-rics: percentage accuracy and F-measure.
For bothof these losses we decode by selecting the mostprobable value under the marginal distribution ofeach random variable.
This is an exact MBR de-code for accuracy but an approximate one for theF-measure; our ERMA training will try to compen-sate for this approximate decoder.
This decodingprocedure is not differentiable due to the use of theargmax function.
To make the decoder differen-tiable, we replace argmax with a stochastic (soft-max) version during training, averaging loss over allpossible values v in proportion to their exponenti-ated probability p(yi = v | x)1/Tdecode .
This de-coder loses smoothness and approaches an argmax126Problem Congressional Vote Semi-structured IE Multi-label class.Loss function Accuracy Token-wise F-score F-scoreNon-loopy Baseline 71.2 86.2 (87.1) 81.6Loopy CRF models INFERENCE:TRAINING: maxprod sumprod maxprod sumprod maxprod sumprodMLE 78.2 78.2 89.0 89.5 84.2 84.0Softmax-margin 79.0 79.0 90.1 90.2 84.3 83.8Min-risk (maxprod) 85.1 80.1 90.9 90.7 84.5 84.4Min-risk (sumprod) 83.6 84.5 90.3 90.9 84.7 84.6Table 1: Results.
The top of the table lists the loss function used for each problem and the score for the best exactbaseline.
The bottom lists results for the full models used with loopy BP.
Models are tested with either sum-productBP (sumprod) or max-product BP (maxprod) and trained with MLE or the minimum risk criterion.
Min-risk trainingruns are either annealed (maxprod), which matches max-product test, or not (sumprod), which matches sum-producttest; grey cells in the table indicate matched training and test settings.
In each column, we boldface the best result aswell as all results that are not significantly worse (paired permutation test, p < 0.05).decoder as Tdecode decreases toward 0.
For simplic-ity, our experiments just use a single fixed value of0.1 for Tdecode.
Annealing the decoder slowly did notlead to significant differences in early experimentson development data.5.2 ResultsTable 1 lists results of our evaluation.
For all threeof our problems, using approximate CRFs resultsin statistically significant improvement over the ex-act baselines, for any of the training procedures.But among the training procedures for approximateCRFs, our ERMA procedure?minimizing empiri-cal risk with the training setting matched to the testsetting?improves over the two baselines, namelyMLE and softmax-margin.
MLE and softmax-margin training were statistically indistinguishablein our experiments with the exception of semi-structured IE.
ERMA?s improvements over them arestatistically significant at the p < .05 level for theCongressional Vote and Semi-Structured IE prob-lems and at the p < .1 level for the Multi-label clas-sification problem (comparing each matched min-risk setting shown in a gray cell in Table 1 vs. MLE).When minimizing risk, we also observe thatmatching training and test-time procedures can re-sult in improved performance in one of the threeproblems, Congressional Vote.
For this problem, thematched training condition performs better than thealternatives (accuracy of 85.1 vs. 83.6 for the an-nealed max-product testing and 84.5 vs 80.1 for thesum-product setting), significant at p < .01).
Weobserve the same effect for semi-structured IE whentesting using max-product inference.
For the otherremaining three problem setting training with eitherminimal risk training regiment.Finally, we hypothesized that sum-product infer-ence may produce more accurate results in certaincases as it allows more information about differ-ent parts of the model to be exchanged.
How-ever, our results show that for these three problems,sum-product and max-product inference yield statis-tically indistinguishable results.
This may be be-cause the particular CRFs we used included no la-tent variables (in constrast to the synthetic CRFsin Stoyanov et al (2011)).
As expected, we foundthat max-product BP converges in fewer iterations?sum-product BP required as many as twice the num-ber of iterations for some of the runs.Results in this paper represent a new state-of-the-art for the first two of the problems, CongressionalVote and Semi-structured IE.
For Multi-Label classi-fication, comparing against the SVM-based methodof Finley and Joachims (2008) goes beyond thescope of this paper.6 Related WorkMinimum-risk training has been used in speechrecognition (Bahl et al, 1988), machine translation(Och, 2003), and energy-based models generally(LeCun et al, 2006).
In graphical models, methodshave been proposed to directly minimize loss in tree-127shaped or linear chain MRFs and CRFs (Kakade etal., 2002; Suzuki et al, 2006; Gross et al, 2007).All of the above focus on exact inference.
Ourapproach can be seen as generalizing these methodsto arbitrary graph structures, arbitrary loss functionsand approximate inference.Lacoste-Julien et al (2011) also consider the ef-fects of approximate inference on loss.
However,they assume the parameters are given, and modifythe approximate inference algorithm at test time toconsider the loss function.Using empirical risk minimization to train graph-ical models was independently proposed by Domke(2010; 2011).
Just as in our own paper (Stoy-anov et al, 2011), Domke took a decision-theoreticstance and proposed ERM as a way of calibratingthe graphical model for use with approximate infer-ence, or for use with data that do not quite match themodeling assumptions.4In particular, (Domke, 2011) is similar to (Stoy-anov et al, 2011) in using ERMA to train model pa-rameters to be used with ?truncated?
inference thatwill be run for only a fixed number of iterations.
Fora common pixel-labeling benchmark in computer vi-sion, Domke (2011) shows that this procedure im-proves training time by orders of magnitude, andslightly improves accuracy if the same number ofmessage-passing iterations is used at test time.Stoyanov and Eisner (2011) extend the ERMAobjective function by adding an explicit runtimeterm.
This allows them to tune model parametersand stopping criteria to learn models that obtain agiven speed-accuracy tradeoff.
Their approach im-proves this hybrid objective over a range of coeffi-cients when compared to the traditional way of in-ducing sparse structures through L1 regularization.Eisner and Daume?
III (2011) propose the same lin-ear combination of speed and accuracy as a rein-forcement learning objective.
In general, our pro-posed ERMA setting resembles the reinforcementlearning problem of trying to directly learn a policythat minimizes loss or maximizes reward.We have been concerned with the fact that ERMAtraining objectives may suffer from local optima andnon-differentiability.
Stoyanov et al (2011) studied4However, he is less focused than we are on matching train-ing conditions to test conditions (by including the decoder andtask loss in the ERMA objective).several such settings, graphed the difficult objective,and identified some practical workarounds that areused in the present paper.
Although these methodshave enabled us to get strong results by reducing theempirical risk, we suspect that ERMA training ob-jectives will benefit from more sophisticated opti-mization methods.
This is true even when the ap-proximate inference itself is restricted to be some-thing as simple as a convex minimization.
Whilethat simplified setting can make it slightly more con-venient to compute the gradient of the inference re-sult with respect to the parameters (Domke, 2008;Domke, 2012), there is still no guarantee that follow-ing that gradient will minimize the empirical risk.Convex inference does not imply convex training.7 ConclusionsMotivated by the recently proposed method of Stoy-anov et al (2011) for minimum-risk training ofCRF-based systems, we revisited three NLP do-mains that can naturally be modeled with approx-imate CRF-based systems.
These include appli-cations that have not been modeled with CRFsbefore (the ConVote corpus), as well as applica-tions that have been modeled with loopy CRFstrained to minimize the approximate log-likelihood(semi-structured information extraction and collec-tive multi-label classification).
We show that (i)the NLP models are improved by moving to richerCRFs that require approximate inference, and (ii)empirical performance is always significantly im-proved by training to reduce the loss that would beachieved by approximate inference, even comparedto another state-of-the-art training method (softmax-margin) that also considers loss and uses approxi-mate inference.
The general software package thatimplements the algorithms in this paper is avail-able at http://www.clsp.jhu.edu/?ves/software.html.AcknowledgmentsThis material is based upon work supported by theNational Science Foundation under Grant #0937060to the Computing Research Association for theCIFellows Project.128ReferencesL.
Bahl, P. Brown, P. de Souza, and R. Mercer.
1988.A new algorithm for the estimation of hidden Markovmodel parameters.
In Proceedings of ICASSP, pages493?496.E.
Benson, A. Haghighi, and R. Barzilay.
2011.
Eventdiscovery in social media feeds.
In Proceedings ofACL-HLT, pages 389?398.Y.
Choi, C. Cardie, E. Riloff, and S. Patwardhan.
2005.Identifying sources of opinions with conditional ran-dom fields and extraction patterns.
In Proceedings ofHLT/EMNLP, pages 355?362.J.
Domke.
2008.
Learning convex inference ofmarginals.
In Proceedings of UAI.J.
Domke.
2010.
Implicit differentiation by perturba-tion.
In Advances in Neural Information ProcessingSystems, pages 523?531.J.
Domke.
2011.
Parameter learning with truncatedmessage-passing.
In Proceedings of the IEEE Con-ference on Computer Vision and Pattern Recognition(CVPR).J.
Domke.
2012.
Generic methods for optimization-based modeling.
In Proceedings of AISTATS.M.
Dreyer and J. Eisner.
2009.
Graphical models overmultiple strings.
In Proceedings of EMNLP, pages101?110.J.
Eisner and Hal Daume?
III.
2011.
Learning speed-accuracy tradeoffs in nondeterministic inference al-gorithms.
In COST: NIPS 2011 Workshop on Com-putational Trade-offs in Statistical Learning, SierraNevada, Spain, December.A.
Elisseeff and J. Weston.
2001.
Kernel methods formulti-labelled classification and categorical regressionproblems.
In Advances in Neural Information Pro-cessing Systems, pages 681?687.J.R.
Finkel, T. Grenager, and C. Manning.
2005.
In-corporating non-local information into information ex-traction systems by Gibbs sampling.
In Proceedings ofACL, pages 363?370.T.
Finley and T. Joachims.
2008.
Training structuralSVMs when exact inference is intractable.
In Proceed-ings of ICML, pages 304?311.D.
Freitag.
2000.
Machine learning for informationextraction in informal domains.
Machine learning,39(2).N.
Ghamrawi and A. McCallum.
2005.
Collective multi-label classification.
In Proceedings of CIKM, pages195?200.K.
Gimpel and N.A.
Smith.
2010.
Softmax-marginCRFs: Training log-linear models with cost functions.In Proceedings of ACL, pages 733?736.P.
I.
Good.
2000.
Permutation Tests.
Springer.A.
Griewank and G. Corliss, editors.
1991.
AutomaticDifferentiation of Algorithms.
SIAM, Philadelphia.S.
Gross, O. Russakovsky, C. Do, and S. Batzoglou.2007.
Training conditional random fields for maxi-mum labelwise accuracy.
Advances in Neural Infor-mation Processing Systems, 19:529.H.
Ji and R. Grishman.
2011.
Knowledge base popula-tion: Successful approaches and challenges.
In Pro-ceedings of ACL-HLT, pages 1148?1158.S.
Kakade, Y.W.
Teh, and S. Roweis.
2002.
An alternateobjective function for Markovian fields.
In Proceed-ings of ICML, pages 275?282.D.
Koller and N. Friedman.
2009.
Probabilistic Graph-ical Models: Principles and Techniques.
The MITPress.A.
Kulesza and F. Pereira.
2008.
Structured learningwith approximate inference.
In Advances in NeuralInformation Processing Systems, pages 785?792.S.
Lacoste-Julien, F. Huszr, and Z. Ghahramani.2011.
Approximate inference for the loss-calibratedBayesian.
In Proceedings of AISTATS.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proceedingsof ICML, pages 282?289.Y.
LeCun, S. Chopra, R. Hadsell, M.A.
Ranzato, and F.-J.
Huang.
2006.
A tutorial on energy-based learning.In G. Bakir, T. Hofman, B. Schlkopf, A. Smola, andB.
Taskar, editors, Predicting Structured Data.
MITPress.Z.
Li and J. Eisner.
2009.
First- and second-orderexpectation semirings with applications to minimum-risk training on translation forests.
In Proceedings ofEMNLP, pages 40?51.K.
P. Murphy, Y. Weiss, and M. I. Jordan.
1999.
Loopybelief propagation for approximate inference: An em-pirical study.
In Proceedings of UAI.F.
Och.
2003.
Minimum error rate training in statisti-cal machine translation.
In Proceedings of ACL, pages160?167.F.
Peng and A. McCallum.
2006.
Information extractionfrom research papers using conditional random fields.Information Processing & Management, 42(4):963?979.N.N.
Schraudolph.
1999.
Local gain adaptation instochastic gradient descent.
In Proceedings of ANN,pages 569?574.F.
Sha and F. Pereira.
2003.
Shallow parsing with con-ditional random fields.
In Proceedings of ACL/HLT,pages 134?141.D.A.
Smith and J. Eisner.
2006.
Minimum risk annealingfor training log-linear models.
In Proceedings of theCOLING/ACL, pages 787?794.129D.
Smith and J. Eisner.
2008.
Dependency parsing bybelief propagation.
In Proceedings of EMNLP, pages145?156.V.
Stoyanov and J. Eisner.
2011.
Learning cost-aware,loss-aware approximate inference policies for proba-bilistic graphical models.
In COST: NIPS 2011 Work-shop on Computational Trade-offs in Statistical Learn-ing, Sierra Nevada, Spain, December.V.
Stoyanov, A. Ropson, and J. Eisner.
2011.
Empiricalrisk minimization of graphical model parameters givenapproximate inference, decoding, and model structure.In Proceedings of AISTATS.C.
Sutton and A. McCallum.
2005.
Piecewise trainingof undirected models.
In Proceedings of UAI, pages568?575.C.
Sutton, A. McCallum, and K. Rohanimanesh.
2007.Dynamic conditional random fields: Factorized proba-bilistic models for labeling and segmenting sequencedata.
The Journal of Machine Learning Research,8:693?723.J.
Suzuki, E. McDermott, and H. Isozaki.
2006.
Train-ing conditional random fields with multivariate eval-uation measures.
In Proceedings of COLING/ACL,pages 217?224.B.
Taskar, C. Guestrin, and D. Koller.
2003.
Max-marginMarkov networks.
Proceedings of NIPS, pages 25?32.M.
Thomas, B. Pang, and L. Lee.
2006.
Get out the vote:Determining support or opposition from congressionalfloor-debate transcripts.
In Proceedings of EMNLP,pages 327?335.S.
Vishwanathan, N. Schraudolph, M. Schmidt, andK.
Murphy.
2006.
Accelerated training of conditionalrandom fields with stochastic gradient methods.
InProceedings of ICML, pages 969?976.M.
Wainwright.
2006.
Estimating the ?wrong?
graphi-cal model: Benefits in the computation-limited setting.Journal of Machine Learning Research, 7:1829?1859,September.R.J.
Williams and D. Zipser.
1989.
A learning algo-rithm for continually running fully recurrent neuralnetworks.
Neural Computation, 1(2):270?280.130
