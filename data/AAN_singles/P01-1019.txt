An Algebra for Semantic Construction in Constraint-based GrammarsAnn CopestakeComputer LaboratoryUniversity of CambridgeNew Museums SitePembroke St, Cambridge, UKaac@cl.cam.ac.ukAlex LascaridesDivision of InformaticsUniversity of Edinburgh2 Buccleuch PlaceEdinburgh, Scotland, UKalex@cogsci.ed.ac.ukDan FlickingerCSLI, Stanford University andYY SoftwareVentura Hall, 220 Panama StStanford, CA 94305, USAdanf@csli.stanford.eduAbstractWe develop a framework for formaliz-ing semantic construction within gram-mars expressed in typed feature struc-ture logics, including HPSG.
The ap-proach provides an alternative to thelambda calculus; it maintains much ofthe desirable flexibility of unification-based approaches to composition, whileconstraining the allowable operations inorder to capture basic generalizationsand improve maintainability.1 IntroductionSome constraint-based grammar formalisms in-corporate both syntactic and semantic representa-tions within the same structure.
For instance, Fig-ure 1 shows representations of typed feature struc-tures (TFSs) for Kim, sleeps and the phrase Kimsleeps, in an HPSG-like representation, looselybased on Sag and Wasow (1999).
The semanticrepresentation expressed is intended to be equiv-alent to r name(x,Kim) ?
sleep(e, x).1 Note:1.
Variable equivalence is represented by coin-dexation within a TFS.2.
The coindexation in Kim sleeps is achievedas an effect of instantiating the SUBJ slot inthe sign for sleeps.3.
Structures representing individual predicateapplications (henceforth, elementary predi-cations, or EPs) are accumulated by an ap-pend operation.
Conjunction of EPs is im-plicit.1The variables are free, we will discuss scopal relation-ships and quantifiers below.4.
All signs have an index functioning some-what like a ?-variable.A similar approach has been used in a largenumber of implemented grammars (see Shieber(1986) for a fairly early example).
It is in manyways easier to work with than ?-calculus basedapproaches (which we discuss further below) andhas the great advantage of allowing generaliza-tions about the syntax-semantics interface to beeasily expressed.
But there are problems.
Theoperations are only specified in terms of the TFSlogic: the interpretation relies on an intuitive cor-respondence with a conventional logical represen-tation, but this is not spelled out.
Furthermorethe operations on the semantics are not tightlyspecified or constrained.
For instance, althoughHPSG has the Semantics Principle (Pollard andSag, 1994) this does not stop the composition pro-cess accessing arbitrary pieces of structure, so itis often not easy to conceptually disentangle thesyntax and semantics in an HPSG.
Nothing guar-antees that the grammar is monotonic, by whichwe mean that in each rule application the seman-tic content of each daughter subsumes some por-tion of the semantic content of the mother (i.e.,no semantic information is dropped during com-position): this makes it impossible to guaranteethat certain generation algorithms will work ef-fectively.
Finally, from a theoretical perspective,it seems clear that substantive generalizations arebeing missed.Minimal Recursion Semantics (MRS: Copes-take et al(1999), see also Egg (1998)) tight-ens up the specification of composition a little.It enforces monotonic accumulation of EPs bymaking all rules append the EPs of their daugh-ters (an approach which was followed by Sagand Wasow (1999)) but it does not fully spec-Kim?????????SYN?
?npHEAD nounSUBJ< >COMPS< >??SEM??
?INDEX 5 ref-indRESTR<[RELN R NAMEINSTANCE 5NAME KIM]>????????????sleeps????????????SYN???
?HEAD verbSUBJ<[SYN npSEM[INDEX 6RESTR 7]]>COMPS< >????SEM??
?INDEX 15 eventRESTR<[RELN SLEEPSIT 15ACT 6]>??????????????
?Kim sleeps?????????
?SYN[HEAD 0 verb]SEM??
?INDEX 2 eventRESTR 10 <[RELN R NAMEINSTANCE 4NAME KIM]> ?
11 <[RELN SLEEPSIT 2 eventACT 4]>??
?HEAD-DTR.SEM[INDEX 2RESTR 10]NON-HD-DTR.SEM.RESTR 11?????????
?Figure 1: Expressing semantics in TFSsify compositional principles and does not for-malize composition.
We attempt to rectify theseproblems, by developing an algebra which givesa general way of expressing composition.
Thesemantic algebra lets us specify the allowableoperations in a less cumbersome notation thanTFSs and abstracts away from the specific fea-ture architecture used in individual grammars, butthe essential features of the algebra can be en-coded in the hierarchy of lexical and construc-tional type constraints.
Our work actually startedas an attempt at rational reconstruction of se-mantic composition in the large grammar imple-mented by the LinGO project at CSLI (availablevia http://lingo.stanford.edu).
Se-mantics and the syntax/semantics interface haveaccounted for approximately nine-tenths of thedevelopment time of the English Resource Gram-mar (ERG), largely because the account of seman-tics within HPSG is so underdetermined.In this paper, we begin by giving a formal ac-count of a very simplified form of the algebra andin ?3, we consider its interpretation.
In ?4 to ?6,we generalize to the full algebra needed to capturethe use of MRS in the LinGO English ResourceGrammar (ERG).
Finally we conclude with somecomparisons to the ?-calculus and to other workon unification based grammar.2 A simple semantic algebraThe following shows the equivalents of the struc-tures in Figure 1 in our algebra:Kim: [x2]{[]subj , []comp}[r name(x2,Kim)]{}sleeps: [e1]{[x1]subj , []comp}[sleep(e1, x1)]{}Kim sleeps: [e1]{[]subj , []comp}[sleep(e1, x1),r name(x2,Kim)]{x1 = x2}The last structure is semantically equivalent to:[sleep(e1, x1), r name(x1,Kim)].In the structure for sleeps, the first part, [e1], isa hook and the second part ([x1]subj and []comp)is the holes.
The third element (the lzt) is a bagof elementary predications (EPs).2 Intuitively, thehook is a record of the value in the semantic en-tity that can be used to fill a hole in another entityduring composition.
The holes record gaps in thesemantic form which occur because it representsa syntactically unsaturated structure.
Some struc-tures have no holes, such as that for Kim.
Whenstructures are composed, a hole in one structure(the semantic head) is filled with the hook of theother (by equating the variables) and their lzts areappended.
It should be intuitively obvious thatthere is a straightforward relationship betweenthis algebra and the TFSs shown in Figure 1, al-though there are other TFS architectures whichwould share the same encoding.We now give a formal description of the alge-bra.
In this section, we simplify by assuming thateach entity has only one hole, which is unlabelled,and only consider two sorts of variables: eventsand individuals.
The set of semantic entities isbuilt from the following vocabulary:2As usual in MRS, this is a bag rather than a set becausewe do not want to have to check for/disallow repeated EPs;e.g., big big car.1.
The absurdity symbol ?.2.
indices i1, i2, .
.
., consisting of two subtypesof indices: events e1, e2, .
.
.
and individualsx1, x2, .
.
..3. n-place predicates, which take indices as ar-guments4.
=.Equality can only be used to identify variables ofcompatible sorts: e.g., x1 = x2 is well formed,but e = x is not.
Sort compatibility correspondsto unifiability in the TFS logic.Definition 1 Simple Elementary Predications(SEP)An SEP contains two components:1.
A relation symbol2.
A list of zero or more ordinary variable ar-guments of the relation (i.e., indices)This is written relation(arg1, .
.
.
,argn).
For in-stance, like(e, x, y) is a well-formed SEP.Equality Conditions: Where i1 and i2 are in-dices, i1 = i2 is an equality condition.Definition 2 The Set ?
of Simple semantic Enti-ties (SSEMENT)s ?
?
if and only if s = ?
or s = ?s1, s2, s3, s4?such that:?
s1 = {[i]} is a hook;?
s2 = ?
or {[i?]}
is a hole;?
s3 is a bag of SEPs(the lzt)?
s4 is a set of equalities between variables(the eqs).We write a SSEMENT as: [i1][i2][SEPs]{EQs}.Note for convenience we omit the set markers {}from the hook and hole when there is no possibleconfusion.
The SEPs, and EQs are (partial) de-scriptions of the fully specified formulae of firstorder logic.Definition 3 The Semantic AlgebraA Semantic Algebra defined on vocabulary V isthe algebra ?
?, op?
where:?
?
is the set of SSEMENTs defined on the vo-cabulary V , as given above;?
op : ?
?
?
??
?
is the operation of se-mantic composition.
It satisfies the follow-ing conditions.
If a1 = ?
or a2 = ?
orhole(a2) = ?, then op(a1, a2) = ?.
Other-wise:1. hook(op(a1, a2)) = hook(a2)2. hole(op(a1, a2)) = hole(a1)3. lzt(op(a1, a2)) = lzt(a1) ?
lzt(a2)4. eq(op(a1, a2)) = Tr(eq(a1)?eq(a2)?hook(a1) = hole(a2)})where Tr stands for transitive closure(i.e., if S = {x = y, y = z}, thenTr(S) = {x = y, y = z, x = z}).This definition makes a2 the equivalent of a se-mantic functor and a1 its argument.Theorem 1 op is a functionIf a1 = a3 and a2 = a4, then a5 = op(a1, a2) =op(a3, a4) = a6.
Thus op is a function.
Further-more, the range of op is within ?.
So ?
?, op?
isan algebra.We can assume that semantic composition al-ways involves two arguments, since we can de-fine composition in ternary rules etc as a sequenceof binary operations.
Grammar rules (i.e., con-structions) may contribute semantic information,but we assume that this information obeys all thesame constraints as the semantics for a sign, soin effect such a rule is semantically equivalent tohaving null elements in the grammar.
The corre-spondence between the order of the arguments toop and linear order is specified by syntax.We use variables and equality statements toachieve the same effect as coindexation in TFSs.This raises one problem, which is the need toavoid accidental variable equivalences (e.g., acci-dentally using x in both the signs for cat and dogwhen building the logical form of A dog chaseda cat).
We avoid this by adopting a conventionthat each instance of a lexical sign comes froma set of basic sements that have pairwise distinctvariables.
The equivalent of coindexation withina lexical sign is represented by repeating the samevariable but the equivalent of coindexation thatoccurs during semantic composition is an equalitycondition which identifies two different variables.Stating this formally is straightforward but a littlelong-winded, so we omit it here.3 InterpretationThe SEPs and EQs can be interpreted with respectto a first order model ?E,A, F ?
where:1.
E is a set of events2.
A is a set of individuals3.
F is an interpretation function, which as-signs tuples of appropriate kinds to the pred-icates of the language.The truth definition of the SEPs and EQs(which we group together under the term SMRS,for simple MRS) is as follows:1.
For all events and individuals v, [v]?M,g?
=g(v).2.
For all n-predicates Pn,[Pn]?M,g?
= {?t1, .
.
.
, tn?
: ?t1, .
.
.
, tn?
?F (Pn)}.3.
[Pn(v1, .
.
.
, vn)]?M,g?
= 1 iff?
[v1]?M,g?, .
.
.
, [vn]?M,g??
?
[Pn]?M,g?.4.
[?
?
?]?M,g?
= 1 iff[?]?M,g?
= 1 and [?]?M,g?
= 1.Thus, with respect to a modelM , an SMRS can beviewed as denoting an element of P(G), whereG is the set of variable assignment functions (i.e.,elements ofG assign the variables e, .
.
.
and x, .
.
.their denotations):[smrs]M = {g : g is a variable assignmentfunction and M |=g smrs}We now consider the semantics of the algebra.This must define the semantics of the operation opin terms of a function f which is defined entirelyin terms of the denotations of op?s arguments.
Inother words, [op(a1, a2)] = f([a1], [a2]) forsome function f .
Intuitively, where the SMRSof the SEMENT a1 denotes G1 and the SMRS ofthe SEMENT a2 denotes G2, we want the seman-tic value of the SMRS of op(a1, a2) to denote thefollowing:G1 ?G2 ?
[hook(a1) = hole(a2)]But this cannot be constructed purely as a func-tion of G1 and G2.The solution is to add hooks and holes to thedenotations of SEMENTS (cf.
Zeevat, 1989).
Wedefine the denotation of a SEMENT to be an ele-ment of I ?
I ?
P(G), where I = E ?
A, asfollows:Definition 4 Denotations of SEMENTsIf a 6= ?
is a SEMENT, [[a]]M = ?
[i], [i?
], G?where:1.
[i] = hook(a)2.
[i?]
= hole(a)3.
G = {g : M |=g smrs(a)}[[?
]]M = ?
?, ?, ?
?So, the meanings of SEMENTs are ordered three-tuples, consisting of the hook and hole elements(from I) and a set of variable assignment func-tions that satisfy the SMRS.We can now define the following operation fover these denotations to create an algebra:Definition 5 Semantics of the Semantic Con-struction Algebra?I ?
I ?
P(G), f?
is an algebra, where:f(?
?, ?, ?
?, ?
[i2], [i?2], G2?)
= ?
?, ?, ??f(?
[i1], [i?1], G1?, ?
?, ?, ??)
= ?
?, ?, ??f(?
[i1], [i?1], G1?, ?
[i2], ?, G2?
= ?
?, ?, ??f(?
[i1], [i?1], G1?, ?
[i2], [i?2], G2?)
=?
[i2], [i?1], G1 ?G2 ?G?
?where G?
= {g : g(i1) = g(i?2)}And this operation demonstrates that semanticconstruction is compositional:Theorem 2 Semantics of Semantic Constructionis CompositionalThe mapping [[]] : ?
?, op?
??
?
?I, I,G?, f?is a homomorphism (so [[op(a1, a2)]] =f([[a1]], [[a2]])).This follows from the definitions of [], op and f .4 Labelling holesWe now start considering the elaborations neces-sary for real grammars.
As we suggested earlier,it is necessary to have multiple labelled holes.There will be a fixed inventory of labels for anygrammar framework, although there may be somedifferences between variants.3 In HPSG, comple-ments are represented using a list, but in generalthere will be a fixed upper limit for the numberof complements so we can label holes COMP1,COMP2, etc.
The full inventory of labels for3For instance, Sag and Wasow (1999) omit the distinctionbetween SPR and SUBJ that is often made in other HPSGs.the ERG is: SUBJ, SPR, SPEC, COMP1, COMP2,COMP3 and MOD (see Pollard and Sag, 1994).To illustrate the way the formalization goeswith multiple slots, consider opsubj :Definition 6 The definition of opsubjopsubj(a1, a2) is the following: If a1 = ?
or a2 =?
or holesubj(a2) = ?, then opsubj(a1, a2) = ?.And if ?l 6= subj such that:|holel(a1) ?
holel(a2)| > 1then opsubj(a1, a2) = ?.
Otherwise:1. hook(opsubj(a1, a2)) = hook(a2)2.
For all labels l 6= subj:holel(opsubj(a1, a2)) = holel(a1) ?holel(a2)3. lzt(opsubj(a1, a2)) = lzt(a1) ?
lzt(a2)4. eq(opsubj(a1, a2)) = Tr(eq(a1) ?
eq(a2)?
{hook(a1) = holesubj(a2)})where Tr stands for transitive closure.There will be similar operations opcomp1,opcomp2 etc for each labelled hole.
Theseoperations can be proved to form an algebra?
?, opsubj , opcomp1, .
.
.?
in a similar way to theunlabelled case shown in Theorem 1.
A lit-tle more work is needed to prove that opl isclosed on ?.
In particular, with respect toclause 2 of the above definition, it is necessaryto prove that opl(a1, a2) = ?
or for all labels l?,|holel?
(opl(a1, a2))| ?
1, but it is straightforwardto see this is the case.These operations can be extended in a straight-forward way to handle simple constituent coor-dination of the kind that is currently dealt within the ERG (e.g., Kim sleeps and talks and Kimand Sandy sleep); such cases involve daughterswith non-empty holes of the same label, andthe semantic operation equates these holes in themother SEMENT.5 Scopal relationshipsThe algebra with labelled holes is sufficient todeal with simple grammars, such as that in Sagand Wasow (1999), but to deal with scope, more isneeded.
It is now usual in constraint based gram-mars to allow for underspecification of quantifierscope by giving labels to pieces of semantic in-formation and stating constraints between the la-bels.
In MRS, labels called handles are associ-ated with each EP.
Scopal relationships are rep-resented by EPs with handle-taking arguments.If all handle arguments are filled by handles la-belling EPs, the structure is fully scoped, but ingeneral the relationship is not directly specifiedin a logical form but is constrained by the gram-mar via additional conditions (handle constraintsor hcons).4 A variety of different types of condi-tion are possible, and the algebra developed hereis neutral between them, so we will simply userelh to stand for such a constraint, intending it tobe neutral between, for instance, =q (qeq: equal-ity modulo quantifiers) relationships used in MRSand the more usual ?
relationships from UDRT(Reyle, 1993).
The conditions in hcons are accu-mulated by append.To accommodate scoping in the algebra, wewill make hooks and holes pairs of indices andhandles.
The handle in the hook corresponds tothe LTOP feature in MRS.
The new vocabulary is:1.
The absurdity symbol ?.2.
handles h1, h2, .
.
.3. indices i1, i2, .
.
., as before4.
n-predicates which take handles and indicesas arguments5.
relh and =.The revised definition of an EP is as in MRS:Definition 7 Elementary Predications (EPs)An EP contains exactly four components:1. a handle, which is the label of the EP2.
a relation3.
a list of zero or more ordinary variable ar-guments of the relation (i.e., indices)4. a list of zero or more handles correspondingto scopal arguments of the relation.4The underspecified scoped forms which correspond tosentences can be related to first order models of the fullyscoped forms (i.e., to models of WFFs without labels) viasupervaluation (e.g., Reyle, 1993).
This corresponds to stip-ulating that an underspecified logical form u entails a base,fully specified form ?
only if all possible ways of resolvingthe underspecification in u entails ?.
For reasons of space,we do not give details here, but note that this is entirely con-sistent with treating semantics in terms of a description ofa logical formula.
The relationship between the SEMENTSof non-sentential constituents and a more ?standard?
formallanguage such as ?-calculus will be explored in future work.This is written h:r(a1, .
.
.
,an,sa1, .
.
.
,sam).
Forinstance, h:every(x, h1, h2) is an EP.5We revise the definition of semantic entities toadd the hcons conditions and to make hooks andholes pairs of handles and indices.H-Cons Conditions: Where h1 and h2 arehandles, h1relhh2 is an H-Cons condition.Definition 8 The Set ?
of Semantic Entitiess ?
?
if and only if s = ?
or s =?s1, s2, s3, s4, s5?
such that:?
s1 = {[h, i]} is a hook;?
s2 = ?
or {[h?, i?]}
is a hole;?
s3 is a bag of EP conditions?
s4 is a bag of HCONS conditions?
s5 is a set of equalities between variables.SEMENTs are: [h1, i1]{holes}[eps][hcons]{eqs}.We will not repeat the full composition def-inition, since it is unchanged from that in ?2apart from the addition of the append operationon hcons and a slight complication of eq to dealwith the handle/index pairs:eq(op(a1, a2)) = Tr(eq(a1) ?
eq(a2)?
{hdle(hook(a1)) = hdle(hole(a2)),ind(hook(a1)) = ind(hole(a2))})where Tr stands for transitive closure as beforeand hdle and ind access the handle and index ofa pair.
We can extend this to include (several) la-belled holes and operations, as before.
And theserevised operations still form an algebra.The truth definition for SEMENTS is analogousto before.
We add to the model a set of la-bels L (handles denote these via g) and a well-founded partial order ?
on L (this helps interpretthe hcons; cf.
Fernando (1997)).
A SEMENT thendenotes an element of H?
.
.
.H?P(G), wherethe Hs (= L?
I) are the new hook and holes.Note that the language ?
is first order, andwe do not use ?-abstraction over higher or-der elements.6 For example, in the standardMontagovian view, a quantifier such as every5Note every is a predicate rather than a quantifier inthis language, since MRSs are partial descriptions of logicalforms in a base language.6Even though we do not use ?-calculus for composition,we could make use of ?-abstraction as a representation de-vice, for instance for dealing with adjectives such as former,cf., Moore (1989).is represented by the higher-order expression?P?Q?x(P (x), Q(x)).
In our framework, how-ever, every is the following (using qeq conditions,as in the LinGO ERG):[hf , x]{[]subj , []comp1, [h?, x]spec, .
.
.
}[he : every(x, hr, hs)][hr =q h?
]{}and dog is:[hd, y]{[]subj , []comp1, []spec, .
.
.
}[hd : dog(y)][]{}So these composes via opspec to yield every dog:[hf , x]{[]subj , []comp1, []spec, .
.
.
}[he : every(x, hr, hs), hd : dog(y)][hr =q h?]{h?
= hd, x = y}This SEMENT is semantically equivalent to:[hf , x]{[]subj , []comp1, []spec, .
.
.
}[he : every(x, hr, hs), hd : dog(x)][hr =q hd]{}A slight complication is that the determiner isalso syntactically selected by the N?
via the SPRslot (following Pollard and Sag (1994)).
How-ever, from the standpoint of the compositionalsemantics, the determiner is the semantic head,and it is only its SPEC hole which is involved: theN?
must be treated as having an empty SPR hole.In the ERG, the distinction between intersectiveand scopal modification arises because of distinc-tions in representation at the lexical level.
Therepetition of variables in the SEMENT of a lexicalsign (corresponding to TFS coindexation) and thechoice of type on those variables determines thetype of modification.Intersective modification: white dog:dog: [hd, y]{[]subj , []comp1, .
.
.
, []mod}[hd : dog(y)][]{}white: [hw, x]{[]subj , []comp1, .., [hw, x]mod}[hw : white(x)][]{}white dog: [hw, x]{[]subj , []comp1, .
.
.
, []mod}(opmod) [hd : dog(y), hw : white(x)][]{hw = hd, x = y}Scopal Modification: probably walks:walks: [hw, e?
]{[h?, x]subj , []comp1, .
.
.
, []mod}[hw : walks(e?, x)][]{}probably: [hp, e]{[]subj , []comp1, .
.
.
, [h, e]mod}[hp : probably(hs)][hs =q h]{}probably [hp, e]{[h?, x]subj , []comp1, .
.
.
, []mod}walks: [hp:probably(hs), hw:walks(e?, x)](opmod) [hs =q h]{hw = h, e = e?
}6 Control and external argumentsWe need to make one further extension to allowfor control, which we do by adding an extra slot tothe hooks and holes corresponding to the externalargument (e.g., the external argument of a verbalways corresponds to its subject position).
Weillustrate this by showing two uses of expect; notethe third slot in the hooks and holes for the exter-nal argument of each entity.
In both cases, x?e isboth the external argument of expect and its sub-ject?s index, but in the first structure x?e is also theexternal argument of the complement, thus givingthe control effect.expect 1 (as in Kim expected to sleep)[he, ee, x?e]{[hs, x?e, x?s]subj , [hc, ec, x?e]comp1, .
.
.
}[he : expect(ee, x?e, h?e)][h?e =q hc]{}expect 2 (Kim expected that Sandy would sleep)[he, ee, x?e]{[hs, x?e, x?s]subj , [hc, ec, x?c]comp1, .
.
.
}[h : expect(ee, x?e, h?e)][h?e =q hc]{}Although these uses require different lexical en-tries, the semantic predicate expect used in thetwo examples is the same, in contrast to Montago-vian approaches, which either relate two distinctpredicates via meaning postulates, or require anadditional semantic combinator.
The HPSG ac-count does not involve such additional machinery,but its formal underpinnings have been unclear:in this algebra, it can be seen that the desired re-sult arises as a consequence of the restrictions onvariable assignments imposed by the equalities.This completes our sketch of the algebra neces-sary to encode semantic composition in the ERG.We have constrained accessibility by enumeratingthe possible labels for holes and by stipulating thecontents of the hooks.
We believe that the han-dle, index, external argument triple constitutes allthe semantic information that a sign should makeaccessible to a functor.
The fact that only thesepieces of information are visible means, for in-stance, that it is impossible to define a verb thatcontrols the object of its complement.7 Althoughobviously changes to the syntactic valence fea-tures would necessitate modification of the holelabels, we think it unlikely that we will need to in-crease the inventory further.
In combination with7Readers familiar with MRS will notice that the KEY fea-ture used for semantic selection violates these accessibilityconditions, but in the current framework, KEY can be re-placed by KEYPRED which points to the predicate alone.the principles defined in Copestake et al(1999)for qeq conditions, the algebra presented here re-sults in a much more tightly specified approachto semantic composition than that in Pollard andSag (1994).7 ComparisonCompared with ?-calculus, the approach to com-position adopted in constraint-based grammarsand formalized here has considerable advantagesin terms of simplicity.
The standard Montaguegrammar approach requires that arguments bepresented in a fixed order, and that they be strictlytyped, which leads to unnecessary multiplicationof predicates which then have to be interrelatedby meaning postulates (e.g., the two uses of ex-pect mentioned earlier).
Type raising also addsto the complexity.
As standardly presented, ?-calculus does not constrain grammars to be mono-tonic, and does not control accessibility, since thevariable of the functor that is ?-abstracted overmay be arbitrarily deeply embedded inside a ?-expression.None of the previous work on unification-based approaches to semantics has consideredconstraints on composition in the way we havepresented.
In fact, Nerbonne (1995) explicitlyadvocates nonmonotonicity.
Moore (1989) isalso concerned with formalizing existing prac-tice in unification grammars (see also Alshawi,1992), though he assumes Prolog-style unifica-tion, rather than TFSs.
Moore attempts to for-malize his approach in the logic of unification,but it is not clear this is entirely successful.
Hehas to divorce the interpretation of the expres-sions from the notion of truth with respect to themodel, which is much like treating the semanticsas a description of a logic formula.
Our strategyfor formalization is closest to that adopted in Uni-fication Categorial Grammar (Zeevat et al 1987),but rather than composing actual logical forms wecompose partial descriptions to handle semanticunderspecification.8 Conclusions and future workWe have developed a framework for formallyspecifying semantics within constraint-based rep-resentations which allows semantic operations ina grammar to be tightly specified and which al-lows a representation of semantic content whichis largely independent of the feature structure ar-chitecture of the syntactic representation.
HPSGscan be written which encode much of the algebradescribed here as constraints on types in the gram-mar, thus ensuring that the grammar is consistentwith the rules on composition.
There are some as-pects which cannot be encoded within currentlyimplemented TFS formalisms because they in-volve negative conditions: for instance, we couldnot write TFS constraints that absolutely preventa grammar writer sneaking in a disallowed coin-dexation by specifying a path into the lzt.
There isthe option of moving to a more general TFS logicbut this would require very considerable researchto develop reasonable tractability.
Since the con-straints need not be checked at runtime, it seemsbetter to regard them as metalevel conditions onthe description of the grammar, which can any-way easily be checked by code which converts theTFS into the algebraic representation.Because the ERG is large and complex, we havenot yet fully completed the exercise of retrospec-tively implementing the constraints throughout.However, much of the work has been done andthe process revealed many bugs in the grammar,which demonstrates the potential for enhancedmaintainability.
We have modified the grammarto be monotonic, which is important for the chartgenerator described in Carroll et al(1999).
Achart generator must determine lexical entries di-rectly from an input logical form: hence it willonly work if all instances of nonmonotonicity canbe identified in a grammar-specific preparatorystep.
We have increased the generator?s reliabilityby making the ERG monotonic and we expect fur-ther improvements in practical performance oncewe take full advantage of the restrictions in thegrammar to cut down the search space.AcknowledgementsThis research was partially supported by the Na-tional Science Foundation, grant number IRI-9612682.
Alex Lascarides was supported by anESRC (UK) research fellowship.
We are gratefulto Ted Briscoe, Alistair Knott and the anonymousreviewers for their comments on this paper.ReferencesAlshawi, Hiyan [1992] (ed.)
The Core LanguageEngine, MIT Press.Carroll, John, Ann Copestake, Dan Flickingerand Victor Poznanski [1999] An Efficient ChartGenerator for Lexicalist Grammars, The 7th In-ternational Workshop on Natural Language Gen-eration, 86?95.Copestake, Ann, Dan Flickinger, Ivan Sagand Carl Pollard [1999] Minimal Recursion Se-mantics: An Introduction, manuscript at www-csli.stanford.edu/?aac/newmrs.psEgg, Marcus [1998] Wh-Questions in Under-specified Minimal Recursion Semantics, Journalof Semantics, 15.1:37?82.Fernando, Tim [1997] Ambiguity in ChangingContexts, Linguistics and Philosophy, 20.6: 575?606.Moore, Robert C. [1989] Unification-based Se-mantic Interpretation, The 27th Annual Meetingfor the Association for Computational Linguistics(ACL-89), 33?41.Nerbonne, John [1995] ComputationalSemantics?Linguistics and Processing, ShalomLappin (ed.)
Handbook of ContemporarySemantic Theory, 461?484, Blackwells.Pollard, Carl and Ivan Sag [1994] Head-Driven Phrase Structure Grammar, University ofChicago Press.Reyle, Uwe [1993] Dealing with Ambiguitiesby Underspecification: Construction, Represen-tation and Deduction, Journal of Semantics, 10.1:123?179.Sag, Ivan, and Tom Wasow [1999] SyntacticTheory: An Introduction, CSLI Publications.Shieber, Stuart [1986] An Introduction toUnification-based Approaches to Grammar,CSLI Publications.Zeevat, Henk [1989] A Compositional Ap-proach to Discourse Representation Theory, Lin-guistics and Philosophy, 12.1: 95?131.Zeevat, Henk, Ewan Klein and Jo Calder[1987] An introduction to unification categorialgrammar, Nick Haddock, Ewan Klein and GlynMorrill (eds), Categorial grammar, unificationgrammar, and parsing: working papers in cogni-tive science, Volume 1, 195?222, Centre for Cog-nitive Science, University of Edinburgh.
