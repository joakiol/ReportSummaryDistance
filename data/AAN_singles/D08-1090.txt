Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 857?866,Honolulu, October 2008. c?2008 Association for Computational LinguisticsLanguage and Translation Model Adaptation using Comparable CorporaMatthew Snover and Bonnie DorrLaboratory for Computational Linguisticsand Information ProcessingInstitute for Advanced Computer StudiesDepartment of Computer ScienceUniversity of MarylandCollege Park, MD 20742{snover, bonnie}@umiacs.umd.eduRichard SchwartzBBN Technologies10 Moulton StreetCambridge, MA 02138, USAschwartz@bbn.comAbstractTraditionally, statistical machine translationsystems have relied on parallel bi-lingual datato train a translation model.
While bi-lingualparallel data are expensive to generate, mono-lingual data are relatively common.
Yet mono-lingual data have been under-utilized, havingbeen used primarily for training a languagemodel in the target language.
This paper de-scribes a novel method for utilizing monolin-gual target data to improve the performanceof a statistical machine translation system onnews stories.
The method exploits the exis-tence of comparable text?multiple texts inthe target language that discuss the same orsimilar stories as found in the source languagedocument.
For every source document that isto be translated, a large monolingual data setin the target language is searched for docu-ments that might be comparable to the sourcedocuments.
These documents are then usedto adapt the MT system to increase the prob-ability of generating texts that resemble thecomparable document.
Experimental resultsobtained by adapting both the language andtranslation models show substantial gains overthe baseline system.1 IntroductionWhile the amount of parallel data available to train astatistical machine translation system is sharply lim-ited, vast amounts of monolingual data are generallyavailable, especially when translating to languagessuch as English.
Yet monolingual data are generallyonly used to train the language model of the trans-lation system.
Previous work (Fung and Yee, 1998;Rapp, 1999) has sought to learn new translations forwords by looking at comparable, but not parallel,corpora in multiple languages and analyzing the co-occurrence of words, resulting in the generation ofnew word-to-word translations.More recently, Resnik and Smith (2003)and Munteanu and Marcu (2005) have exploitedmonolingual data in both the source and targetlanguages to find document or sentence pairs thatappear to be parallel.
This newly discovered bilin-gual data can then be used as additional training datafor the translation system.
Such methods generallyhave a very low yield leaving vast amounts of datathat is only used for language modeling.These methods rely upon comparable corpora,that is, multiple corpora that are of the same gen-eral genre.
In addition to this, documents can becomparable?two documents that are both on thesame event or topic.
Comparable documents occurbecause of the repetition of information across lan-guages, and in the case of news data, on the fact thatstories reported in one language are often reportedin another language.
In cases where no direct trans-lation can be found for a source document, it is of-ten possible to find documents in the target languagethat are on the same story, or even on a related story,either in subject matter or historically.
Such docu-ments can be classified as comparable to the origi-nal source document.
Phrases within this compara-ble document are likely to be translations of phrasesin the source document, even if the documents them-selves are not parallel.Figure 1 shows an excerpt of the reference trans-lation of an Arabic document, and figure 2 shows a857Cameras are flashing and reporters are following up, forHollywood star Angelina Jolie is finally talking to the pub-lic after a one-month stay in India, but not as a movie star.The Hollywood actress, goodwill ambassador of the UnitedNations high commissioner for refugees, met with the In-dian minister of state for external affairs, Anand Sharma,here today, Sunday, to discuss issues of refugees and chil-dren.
... Jolie, accompanied by her five-year-old son, Mad-dox, visited the refugee camps that are run by the KhalsaDiwan Society for social services and the high commis-sioner for refugees Saturday afternoon after she arrived inDelhi.
Jolie has been in India since October 5th shootingthe movie ?A Mighty Heart,?
which is based on the life ofWall Street Journal correspondent Daniel Pearl, who waskidnapped and killed in Pakistan.
Jolie plays the role ofPearl?s wife, Mariane.Figure 1: Excerpt of Example Reference Translation ofan Arabic Source Documentcomparable passage.1 In this case, the two new sto-ries are not translations of each other and were notreported at the same time?the comparable passagebeing an older news story?but both discuss actressAngelina Jolie?s visit to India.
Many phrases andwords are shared between the two, including: thename of the movie, the name and relationship of theactress?
character, the name and age of her son andmany others.
Such a pairing is extremely compara-ble, although even less related document pairs couldeasily be considered comparable.We seek to take advantage of these comparabledocuments to inform the translation of the sourcedocument.
This can be done by augmenting the ma-jor components of the statistical translation system:the Language Model and the Translation Model.This work is in the same tradition as Kim andKhudanpur (2003), Zhao et al (2004), and Kim(2005).
Kim (2005) used large amounts of compa-rable data to adapt language models on a document-by-document basis, while Zhao et al (2004) usedcomparable data to perform sentence level adapta-tion of the language model.
These adapted lan-guage models were shown to improve performance1This is an actual source document from the tuning set usedin our experiments, and the first of a number of similar passagesfound by the comparable text selection system described in sec-tion 2.Actress Angelina Jolie hopped onto a crowded Mumbaicommuter train Monday to film a scene for a movie aboutslain journalist Daniel Pearl, who lived and worked in In-dia?s financial and entertainment capital.
Hollywood actorDan Futterman portrays Pearl and Jolie plays his wife Mar-iane in the ?A Mighty Heart?
co-produced by Plan B, a pro-duction company founded by Brad Pitt and his ex-wife, ac-tress Jennifer Aniston.
Jolie and Pitt, accompanied by theirthree children ?
Maddox, 5, 18-month-old Zahara and 5-month-old Shiloh Nouvel ?
arrived in Mumbai on Saturdayfrom the western Indian city Pune where they were shootingthe movie for nearly a month.
...Figure 2: Excerpt of Example Comparable Documentfor both automatic speech recognition as well as ma-chine translation.In addition to language model adaptation wealso modify the translation model, adding additionaltranslation rules that enable the translation of newwords and phrases in both the source and target lan-guages, as well as increasing the probability of ex-isting translation rules.
Translation adaptation us-ing the translation system?s own output, known asSelf-Training (Ueffing, 2006) has previously showngains by augmenting the translation model with ad-ditional translation rules.
In that approach however,the translation model was augmented using paralleldata, rather than comparable data, by interpolatinga translation model trained using the system outputwith the original translation model.Translation model adaptation using comparableout-of-domain parallel data, rather than monolingualdata was shown by Hildebrand et al (2005) to yieldsignificant gains over a baseline system.
The trans-lation model was adapted by selecting comparablesentences from parallel corpora for each of the sen-tences to be translated.
In addition to selecting out-of-domain data to adapt the translation model, com-parable data selection techniques have been used toselect and weight portions of the existing trainingdata for the translation model to improve translationperformance (Lu et al, 2007).The research presented in this paper utilizes a dif-ferent approach to translation model adaptation us-ing comparable monolingual text rather than paralleltext, exploiting data that would otherwise be unused858for estimating the translation model.
In addition,this data also informs the translation system by in-terpolating the original language model with a newlanguage model trained from the same comparabledocuments.We discuss the selection of comparable text formodel adaptation in section 2.
In sections 3.1and 3.2, we describe the model adaptation for thelanguage model and translation model, respectively.Experimental results describing the application ofmodel adaptation to a hierarchical Arabic-to-EnglishMT system are presented in section 4.
Finally wedraw conclusions in sections 5.2 Comparable Text SelectionComparable text is selected for every source doc-ument from a large monolingual corpus in the tar-get language.
In practice, one could search theWorld Wide Web for documents that are compara-ble to a set of source documents, but this approachpresents problems for ensuring the quality of the re-trieved documents.
The experiments in this paperuse comparable text selected from a collection ofEnglish news texts.
Because these texts are all flu-ent English, and of comparable genre to the test set,they are also used for training the standard languagemodel training.The problem of selecting comparable text hasbeen widely studied in the information retrievalcommunity and cross-lingual information retrieval(CLIR) (Oard and Dorr, 1998; Levow et al, 2005)has been largely successful at the task of selectingcomparable or relevant documents in one languagegiven a query in another language.
We use CLIR toselect a ranked list of documents in our target lan-guage, English in the experiments described in thispaper, for each source document, designated as thequery in the CLIR framework, that we wish to trans-late.The CLIR problem can be framed probabilisti-cally as: Given a query Q, find a document D thatmaximizes the equation Pr(D is rel|Q).
This equa-tion can be expanded using Bayes?
Law as shownin equation 1.
The prior probability of a documentbeing relevant can be viewed as uniform, and thusin this work, we assume Pr(D is rel) is a constant.22In fact, it can be beneficial to use features of the documentThe Pr(Q) is constant across all documents.
There-fore finding a document to maximize Pr(D is rel|Q)is equivalent to finding a document that maximizesPr(Q|D is rel).Pr(D is rel|Q) =Pr(D is rel) Pr(Q|D is rel)Pr(Q)(1)A method of calculating the probability of a querygiven a document was proposed by (Xu et al, 2001)3and is shown in Equation 2.
In this formulation, eachforeign word, f , in the query is generated from theforeign vocabulary with probability ?
and from theEnglish document with probability 1 ?
?, where ?is a constant.4 The probability of f being generatedby the general foreign vocabulary, F , is Pr(f |F ) =freq(f, F )/|F |, the frequency of the word f in thevocabulary divided by the size of the vocabulary.The probability of the word being generated by theEnglish document is the sum of the probabilities of itbeing generated by each English word, e, in the doc-ument which is the frequency of the English word inthe document, (Pr(e|D) = freq(e,D)/|D|) multi-plied by the probability of the translation of the En-glish word to the foreign word, Pr(f |e).Pr(Q|D) =?f?Q(?Pr(f |F )+ (2)(1?
?
)?ePr(e|D) Pr(f |e))This formulation favors longer English docu-ments over shorter English documents.
In addition,many documents cover multiple stories and topics.For the purposes of adaptation, shorter, fully com-parable documents are preferred to longer, only par-tially comparable documents.
We modify the CLIRsystem by taking the 1000 highest ranked target lan-guage documents found by the CLIR system foreach source document, and dividing them into over-lapping passages of approximately 300 words.5 Sen-to estimate Pr(D is rel) (Miller and Schwartz, 1998) but wehave not explored that here.3Xu et al (2001) formulated this for the selection of foreigndocuments given an English query.
We reverse this to selectEnglish documents given a foreign query.4As in Xu et al (2001), a value of 0.3 was used for ?.5The length of 300 was chosen as this was approximatelythe same length as the source documents.859tence boundaries are preserved when creating pas-sages, insuring that the text is fluent within each pas-sage.
These passages are then scored again by theCLIR system, resulting in a list of passages of about300 words each for each source document.
Finally,we select the top N passages to be used for adapta-tion.The N passages selected by this method are notguaranteed to be comparable and are often largelyunrelated to the story or topic in the source docu-ment.
We shall refer to the set of passages selectedby the CLIR system as the bias text to differentiateit from comparable text, as the adaptation methodswill use this text to bias the MT system so that itsoutput will be more similar to the bias text.While we have not conducted experiments usingother CLIR systems, the adaptation methods pre-sented in this paper could be applied without modifi-cation using another CLIR system, as the adaptationmethod treats the CLIR system as a black box.
Withthe exception of running a second pass of CLIR, weuse the algorithm of Xu et al (2001) without anysignificant modification, including the use of a stopword list for both the English and foreign texts.
Theparameters for Pr(f |F ) and Pr(f |e) were estimatedusing the same parallel data that our translation sys-tem was trained on.The bias text selected for a source document isused to adapt the language model (described in sec-tion 3.1) and the translation model (described in sec-tion 3.2) when translating that source document.3 Model AdaptationWe use the same bias text to adapt both the lan-guage model and the translation model.
For lan-guage model adaptation, we increase the probabilityof the word sequences in the bias text, and for trans-lation model adaptation we use additional phrasaltranslation rules.
The adaptations can be done in-dependently and while they can augment each otherwhen used together, this is not required.
It is notnecessary to use the same number of passages forboth forms of adaptation, although doing so makesit more likely both that the English side of the newtranslation rule will be assigned a high probabilityby the adapted language model, and that the transla-tion model produces the English text to which thelanguage model has been adapted.
Bias text thatis used by one adaptation but not the other will re-ceive no special treatment by the other model.
Thiscould result in new translation rules that produce textto which the language assigns low probability, or itcould result in the language model being able to as-sign a high probability to a good English translationthat cannot be produced by the translation model dueto a lack of necessary translation rules.While both adaptation methods are integrated intoa hierarchical translation model (Chiang, 2005),they are largely implementation independent.
Lan-guage model adaptation could be integrated into anystatistical machine translation that uses a languagemodel over words, while translation model adapta-tion could be added to any statistical machine trans-lation that can utilize phrasal translation rules.3.1 Language Model AdaptationFor every source document, we estimate a new lan-guage model, the bias language model, from the cor-responding bias text.
Since this bias text is short, thecorresponding bias language model is small and spe-cific, giving high probabilities to those phrases thatoccur in the bias text.
The bias language model isinterpolated with the generic language model thatwould otherwise be used for translation if no LMadaptation was used.
The new bias language modelis of the same order as the generic language model,so that if a trigram language model is used for theMT decoding, then the biased language model willalso be a trigram language model.
The bias lan-guage model is created using the same settings asthe generic language model.
In our particular im-plementation however, the generic language modeluses Kneser-Ney smoothing, while the biased lan-guage model uses Witten-Bell smoothing due to im-plementation limitations.
In principle the biased lan-guage model can be smoothed in the same manner asthe generic language model.We interpolate the bias language model andthe generic language model as shown in equa-tion 3, where Prg and Prb are the probabilitiesfrom the generic language model and the bias lan-guage model, respectively.
A constant interpolationweight, ?
is used to weight the two probabilities forall documents.
While a value for ?
could be cho-sen that minimizes perplexity on a tuning set, in a860similar fashion to Kim (2005), it is unclear that sucha weight would be ideal when the interpolated lan-guage model is used as part of a statistical translationsystem.
In practice we have observed that weightsother than one that minimizes perplexity, typically alower weight, can yield better translation results onthe tuning set.Pr(e) = (1?
?)
Prg(e) + ?Prb(e) (3)The resulting interpolated language model is thenused in place of the generic language model in thetranslation process, increasing the probability thatthe translation output will resemble the bias text.
Itis important to note that, unlike the translation modeladaptation described in section 3.2, no new infor-mation is added to the system with language modeladaptation.
Because the bias text is extracted fromthe same monolingual corpus that the generic lan-guage model was estimated from, all of the word se-quences used for training the bias language modelwere also used for training the generic languagemodel.
Language model adaptation only increasesthe weight of the portion of the language model datathat was selected as comparable.3.2 Translation Model AdaptationIt is frequently the case in machine translation thatunknown words or phrases are present in the sourcedocument, or that the known translations of sourcewords are based on a very small number of oc-currences in the training data.
In other cases,translations may be known for individual words inthe source document, but not for longer phrases.Translation model adaptation seeks to generate newphrasal translation rules for these source words andphrases.
The bias text for a source document may,if comparable, contain a number of English wordsand phrases that are the English side of these desiredrules.Because the source data and the bias text arenot translations of each other and are not sen-tence aligned, conventional alignment tools, such asGIZA++ (Och and Ney, 2000), cannot be used toalign the source and bias text.
Because the passagesin the bias text are not translations of the source doc-ument, it will always be the case that portions of thesource document have no translation in the bias text,and portions of the bias text have no translation inthe source document.
In addition a phrase in oneof these texts might have multiple, differing transla-tions in the other text.Unlike language model adaptation, the entirety ofthe bias text is not used for translation adaptation.We extract those phrases that occur in at least Mof the passages in the bias texts.
A phrase is onlycounted once for every passage in which it occurs,so that repeated use of a phrase within a passagedoes not affect whether it used to generate new rules.Typically, passages selected by the CLIR tend to bevery similar to each other if they are comparableto the source document and are very different fromeach other if they are not comparable to the sourcedocument.
Phrases that are identical across passagesare the ones that are most likely to be comparable,whereas a phrase or word that occurs in only onepassage is likely to be present only by chance or ifthe passage it is in is not comparable.
Filtering thetarget phrases to those that occur in multiple pas-sages therefore serves not only to reduce the totalnumber of rules, but also to filter out phrases frompassages that are not comparable.For each phrase in the source document we gener-ate a new translation to each of the phrases selectedfrom the bias text, and assign it a low uniform prob-ability.6 For each translation rule we also have alexical translation probability that we estimate cor-rectly from the trained word model.
These new rulesare then added to the phrase table of the existingtranslation model when translating the source doc-ument.
Rather than adding probability to the ex-isting generic rules, the new rules are marked asbias rules by the system and given their own fea-ture weight.
While the vast majority of these rulesare incorrect translations, these incorrect rules willbe naturally biased against by the translation sys-tem.
If the source side of a translation already has anumber of observed translations, then the low prob-ability of the new bias rule will cause it to not beselected by the translation system.
If the new trans-lation rules would produce garbled English, then itwill be biased against by the language model.
Whenthis is combined with the language model adapta-6A probability of 1/700 is arbitrarily used for the bias rulesalthough it is then weighted by the bias translation rule weight.861tion, a natural pressure is exerted to use the bias rulesfor source phrases primarily when it would cause theoutput to look more like the bias text.4 Experimental ResultsWe evaluated the performance of language andtranslation model adaptation with our translationsystem on two conditions, the details of which arepresented in section 4.1.
One condition involved asmall amount of parallel training, such as one mightfind when translating a less commonly taught lan-guage (LCTL).
The other condition involved the fullamount of training available for Arabic-to-Englishtranslation.
In the case of LCTLs we expect ourtranslation model to have the most deficiencies andbe most in need of additional translation rules.
So,it is under such a condition we would expect thetranslation model adaptation to be the most bene-ficial.
We evaluate the system?s performance underthis condition in section 4.2.
The effectiveness ofthis technique on state-of-the-art systems, and its ef-ficiency when used with a well trained generic trans-lation model is presented in section 4.3.4.1 Implementation DetailsBoth language-model and translation-model adap-tation are implemented on top of a hierarchicalArabic-to-English translation system with string-to-dependency rules as described in Shen et al (2008).While generalized rules are generated from the par-allel data, rules generated by the translation modeladaptation are not generalized and are used only asphrasal rules.
A trigram language model was usedduring decoding, and a 5-gram language model wasused to re-score the n-best list after decoding.
In ad-dition to the features described in Shen et al (2008),a new feature is added to the model for the biasrule weight, allowing the translation system to ef-fectively tune the probability of the rules added bytranslation model adaptation in order to improve per-formance on the tuning set.Bias texts were selected from three mono-lingual corpora: the English Gigaword cor-pus (2,793,350,201 words), the FBIS corpus(28,465,936 words), and a collection of news archivedata collected from the websites of various on-line, public news sites (828,435,409 words).
Allthree corpora were also part of the generic languagemodel training data.
Language model adaptationon both the trigram and 5-gram language modelsused 10 comparable passages with an interpolationweight of 0.1.
Translation model adaptation used 10comparable passages for the bias text and a value of2 for M .Each selected passage contains approximately300 words, so in the case where 10 comparable pas-sages are used to create a bias text, the resulting textwill be 3000 words long on average.
The languagemodels created using these bias texts are very spe-cific giving large probability to n-gram sequencesseen in those texts.The construction of the bias texts increases theoverall run-time of the translation system, althoughin practice this is a small expenditure.
The most in-tensive portion is the initial indexing of the monolin-gual corpus, but this is only required once and can bereused for any subsequent test set that is evaluated.This index can then be quickly searched for com-parable passages.
When considering research envi-ronments, test sets are used repeatedly and bias textsonly need to be built once per set, making the build-ing cost negligible.
Otherwise, the time required tobuild the bias text is still small compared to the ac-tual translation time.All conditions were optimized using BLEU (Pap-ineni et al, 2002) and evaluated using both BLEUand Translation Edit Rate (TER) (Snover et al,2006).
BLEU is an accuracy measure, so highervalues indicate better performance, while TER is anerror metric, so lower values indicate better perfor-mance.
Optimization was performed on a tuning setof newswire data, comprised of portions of MTEval2004, MTEval 2005, and GALE 2007 newswire de-velopment data, a total of 48921 words of Englishin 1385 segments and 173 documents.
Results weremeasured on the NIST MTEval 2006 Arabic Evalu-ation set, which was 55578 words of English in 1797segments and 104 documents.
Four reference trans-lations were used for scoring each translation.Parameter optimization method was done using n-best optimization, although the adaptation processis not tied to this method.
The MT decoder is runon the tuning set generating an n-best list (wheren = 300), on which all of the translation features(including bias rule weights) are optimized using862Powell?s method.
These new weights are then usedto decode again, repeating the whole process, usinga cumulative n-best list.
This continues for severaliterations until performance on the tuning set stabi-lizes.
The resulting feature weights are used whendecoding the test set.
A similar, but simpler, methodis used to determine the feature weights after 5-gramrescoring.
This n-best optimization method has sub-tle implications for translation model adaptation.
Inthe first iteration, few bias rules are used in decodingthe 300-best, and those that are used frequently help,although the overall gain is small due to the smallnumber of bias rules used.
This causes the opti-mizer to greatly increase the weight of the bias rules,causing the decoder to overuse the bias rules in thenext iteration causing a sharp decrease in translationquality.
Several iterations are needed for the cumu-lative n-best to achieve sufficient diversity and sizeto assign a weight for the bias translation rules thatresults in an increase in performance over the base-line.
Alternative optimization methods could likelycircumvent this process.
Language model adapta-tion does not suffer from this phenomenon.4.2 Less Commonly Taught LanguageSimulationIn order to better examine the nature of translationmodel adaptation, we elected to work with a transla-tion model that was trained on only 5 million wordsof parallel Arabic-English text.
Limiting the trans-lation model training in this way simulates the prob-lem of translating less commonly taught languages(LCTL) where less parallel text is available, a situa-tion that is not the case for Arabic.
Since the modelis trained on less parallel data, it is lacking a largenumber of translation rules, which is expected to beaddressed by the translation model adaptation.
Byworking in an environment with a more deprivedbaseline translation model, we are giving the trans-lation model adaptation more room to assist.The experiments described below use a 5 millionword Arabic parallel text corpus constructed fromthe LDC2004T18 and LDC2006E25 corpora.
Thefull monolingual English data were used for the lan-guage model and for selection of comparable doc-uments.
Unless otherwise specified no languagemodel adaptation was used.We first establish an upper limit on the gain us-ing translation model adaptation, using the referencedata to adapt the translation system.
These referencedata can be considered to be extremely comparable,better than could ever be hoped to gain by compara-ble document selection.
We first aligned this datausing GIZA++ to the source data, simulating theideal case where we can perfectly determine whichsource words translate to which comparable words.Because our translation model adaptation system as-signs uniform probability to all bias rules, we ignorethe correct rule probabilities that we could extractfrom word alignment and assign uniform probabil-ity to all of the bias translation rules.
As expected,this gives a large gain over the baseline.We also examine limiting these new translationrules to those rules whose target side occurs in thetop 100 passages selected by CLIR, thus minimiz-ing the adaption to those rules that it theoreticallycould learn from the bias text.
On average, 50% ofthe rules were removed by this filtering, resulting ina corresponding 50% decrease in the gain over thebaseline.
The results of these experiments and anunadapted baseline are shown in table 1.Test Set TM Adaptation TER BLEUTune None 0.4984 0.4080Aligned Reference 0.3692 0.5841Overlapping Only 0.4179 0.5138MT06 None 0.5516 0.3468Aligned Reference 0.4517 0.5216Overlapping Only 0.4899 0.4335Table 1: LCTL Aligned Reference Adaptation ResultsThe fair translation model adaptation system,however, does not align source phrases to the cor-rect bias text phrases in such a fashion, and insteadaligns all source words to all target words.
To in-vestigate the effect of this over production of rules,we again used the reference translations as if theywere comparable data, but we ignored the align-ments learned by GIZA++, and instead allowed allsource phrases to translate to all English phrases inthe reference text, with uniform probability.
Thisstill shows large gains in translation quality over thebaseline, as measured by TER and BLEU.
Again,we also examined limiting the text used for transla-tion model adaptation to those phrases that occur in863both the reference text and the top 100 comparablepassages selected the CLIR system.
While this de-creased performance, the system still performs sig-nificantly better than the baseline, as shown in thefollowing table 2.Test Set TM Adaptation TER BLEUTune None 0.4984 0.4080Unaligned Ref.
0.4492 0.4566Overlapping Only 0.4808 0.4313MT06 None 0.5516 0.3468Unaligned Ref.
0.5254 0.3990Overlapping Only 0.5390 0.3695Table 2: LCTL Unaligned Reference Adaptation ResultsApplying translation model and language modeladaptation fairly, using only bias text from the com-parable data selection, yields smaller gains on boththe tuning and MT06 sets, as shown in table 3.The combination of language-model and translation-model adaptation exceeds the gains that would beachieved over the baseline by either method sepa-rately.Test Set Adaptation TER BLEUTune None 0.4984 0.4080LM 0.4922 0.4140TM 0.4916 0.4169LM & TM 0.4888 0.4244MT06 None 0.5516 0.3468LM 0.5559 0.3490TM 0.5545 0.3478LM & TM 0.5509 0.3536Table 3: LCTL Fair Adaptation Results4.3 Full Parallel Training ResultsWhile the simulation described in section 4.2 usedonly 5 million words of parallel training, 230 mil-lion words of parallel data from 18.5 million seg-ments were used for training the full Arabic-to-English translation system.
This parallel data in-cludes the LDC2007T08 ?ISI Arabic-English Auto-matically Extracted Parallel Text?
corpus (Munteanuand Marcu, 2007), which was created from monolin-gual corpora in English and Arabic using the algo-rithm described in Munteanu and Marcu (2005), asthe techniques used in that work are separate andindependent from the adaptation methods we de-scribe in this paper.7 Language model adaptationand translation model adaptation were applied bothindependently and jointly to the translation system,and the results were evaluated against an unadaptedbaseline, as shown in table 4.While gains from language model adaptationwere substantial on the tuning set, on the MT06 testset they are reduced to a 0.65% gain on BLEU anda negligible improvement in TER.
The translationmodel adaptation performs better with 1.37% im-provement in BLEU and a 0.26% improvement inTER.
This gain increases to a 2.07% improvementin BLEU and a 0.64% improvement in TER whenlanguage adaptation is used in conjunction with thetranslation model adaptation, showing the impor-tance of using both adaptation methods.
While itcould be expected that a more heavily trained trans-lation model might not require the benefit of lan-guage and translation model adaptation, a more sub-stantial gain over the baseline can be seen when bothforms of adaptation are used than in the case withless parallel training?a difference of 2.07% BLEUversus 0.68% BLEU.Test Set Adaptation TER BLEUTune None 0.4339 0.4661LM 0.4227 0.4857TM 0.4351 0.4657LM & TM 0.4245 0.4882MT06 None 0.5146 0.3852LM 0.5140 0.3917TM 0.5120 0.3989LM & TM 0.5082 0.4059Table 4: Full Training Adaptation ResultsOf the comparable passages selected by the CLIRsystem for the MT06 test set in the full trainingexperiment, 16.3% were selected from the News7The two methods are not directly comparable, and so wedo not make any attempt to do so.
Munteanu and Marcu (2005)creates new parallel corpora from two monolingual corpora.This new parallel data is generally applicable for training atranslation model but does not target any particular test set.
Ouradaptation method does not generate new parallel data, but cre-ates a new specific translation model for a test document that isbeing translated.864Archive corpus, 81.2% were selected from the En-glish GigaWord corpus and 2.5% were selected fromthe FBIS corpus.
A slightly different distributionwas found for the Tuning set, where 17.8% of thepassages were selected from the News Archive cor-pus, 77.1% were selected from the English Giga-Word corpus, and 5.1% were selected from the FBIScorpus.5 DiscussionThe reuse of a monolingual corpus that was alreadyused by a translation system for language modeltraining to perform both language and translationmodel adaptation shows large gains over an un-adapted baseline.
By leveraging off of a CLIR sys-tem, which itself contains no information not al-ready given to the translation system,8 potentiallycomparable passages can be found which allow im-proved translation.
Surprisingly, these gains arelargest when the baseline model is better trained, in-dicating that a strong reliance of the adaptation onthe existing models.One explantation for these counter-intuitiveresults?larger gains in the full training scenario ver-sus the LCTL scenario?is that the lexical probabili-ties are better estimated in the former case.
The biasrules all have equal translation probability and onlyvary in probability according to the lexical proba-bility of the rules.
Better estimates of these lexicalprobabilities may enable the translation system tomore clearly distinguish between helpful and harm-ful bias rules.There are many clear directions for the improve-ment of these methods.
The current adaptationmethod does not utilize the probabilities from theCLIR system and treats the top-ranked passages allas equally comparable regardless of the probabil-ity assigned.
Variable weighting of passages couldprove beneficial to both language model adaptation,where the passages could be weighted proportion-ally to the probability of the passage being relevant,and translation model adaptation, where the require-ment on repetition of phrases across passages couldbe weighted, as could the probability of the new8The probabilistic parameters of the CLIR system are esti-mated from the same parallel corpora that is used to train thegeneric translation model.rules produced by the translation system.
In ad-dition, the CLIR score, among other possible fea-tures such as phrase overlap, could be used to de-termine those documents where no comparable pas-sage could be detected and where it would be bene-ficial to not adapt the models.A clear limitation of using comparable documentsto adapt the language and translation model is thatcomparable documents must be found.
For manysource documents, none of the top passages foundby the CLIR system were comparable.
We suspectthat while this will always occur to some extent, thisbecomes more common as the monolingual data be-comes less like the source data, such as when there isa large time gap between the two.
The full extent ofthis and the effect of the level of document compa-rability on translation remains an open question.
Inaddition, while newswire is an excellent source ofcomparable text, it is unclear how well this methodcan be used on newsgroups or spoken data, wherethe fluency of the source text is diminished.
Whentranslating news stories, this technique is not lim-ited to major news events.
While many of the eventsdiscussed in the source data receive world-wide at-tention, many are local events that are unreportedin the English comparable data used in our experi-ments.
Events of a similar nature or events involvingmany of the same people often do occur in the En-glish comparable data, allowing improvement evenwhen the stories are quite different.The adaptation methods described in this paperare not limited to a particular framework of statis-tical machine translation, but have applicability toany statistical machine translation system that usesa language model or translation rules.AcknowledgmentsThis work was supported, in part, by BBN Tech-nologies under the GALE Program, DARPA/IPTOContract No.
HR0011-06-C-0022.
Any opinions,findings, and conclusions or recommendations ex-pressed in this material are those of the authors anddo not necessarily reflect the views of the sponsor.We are very grateful to all three reviewers for theircareful and thoughtful reviews.865ReferencesDavid Chiang.
2005.
A Hierarchical Phrase-BasedModel for Statistical Machine Translation.
In Pro-ceedings of ACL, pages 263?270.Pascale Fung and Lo Yuen Yee.
1998.
An IR Approachfor Translating New Words from Nonparallel, Compa-rable Texts.
In Proceedings of COLING-ACL98, pages414?420, August.Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,and Alex Waibel.
2005.
Adaptation of the TranslationModel for Statistical Machine Translation based on In-formation Retrieval.
In Proceedings of EAMT 2005,Budapest, Hungary, May.Woosung Kim and Sanjeev Khudanpur.
2003.
Cross-Lingual Lexical Triggers in Statistical Language Mod-eling.
In 2003 Conference on Empirical Methods inNatural Language Processing (EMNLP 2003), pages17?24, July.Woosung Kim.
2005.
Language Model Adaptation forAutomatic Speech Recognition and Statistical MachineTranslation.
Ph.D. thesis, The Johns Hopkins Univer-sity, Baltimore, MD.Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.2005.
Dictionary-based cross-language retrieval.
In-formation Processing and Management, 41:523?547.Yajuan Lu, Jin Huang, and Qun Liu.
2007.
ImprovingStatistical Machine Translation Performance by Train-ing Data Selection and Optimization.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL), pages343?350.T.
Leek Miller and Richard Schwartz.
1998.
BBN atTREC7: Using Hidden Markov Models for Informa-tion Retrieval.
In TREC 1998, pages 80?89, Gaithers-burg, MD.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving Machine Translation Performance by Exploit-ing Non-Parallel Corpora.
Computational Linguistics,31:477?504.Dragos Stefan Munteanu and Daniel Marcu.
2007.
Isiarabic-english automatically extracted parallel text.Linguistic Data Consortium, Philadelphia.Douglas W. Oard and Bonnie J. Dorr.
1998.
Evaluat-ing Cross-Language Text Retrieval Effectiveness.
InGregory Grefenstette, editor, Cross-Language Infor-mation Retrieval, pages 151?161.
Kluwer AcademicPublishers, Boston, MA.F.
J. Och and H. Ney.
2000.
Improved Statistical Align-ment Models.
In Proceedings of the 38th Annual Con-ference of the Association for Computational Linguis-tics, pages 440?447, Hongkong, China.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Method for Automatic Eval-uation of Machine Traslation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated english and german cor-pora.
In Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics, pages519?526.Philip Resnik and Noah Smith.
2003.
The Web as aParallel Corpus.
Computational Linguistics, 29:349?380.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
ANew String-to-Dependency Machine Translation Al-gorithm with a Target Dependency Language Model.In Proceedings of the 46th Annual Meeting of the As-sociation for Computational Linguistics (ACL), June.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Studyof Translation Edit Rate with Targeted Human An-notation.
In Proceedings of Association for MachineTranslation in the Americas.Nicola Ueffing.
2006.
Using Monolingual Source-Language to Improve MT Performance.
In Proceed-ings of IWSLT 2006.Jinxi Xu, Ralpha Weischedel, and Chanh Nguyen.
2001.Evaluating a Probabilistic Model for Cross-lingual In-formation Retrieval.
In Proceedings of SIGIR 2001Conference, pages 105?110.Bing Zhao, Matthias Eck, and Stephan Vogel.
2004.Language Model Adaptation for Statistical MachineTranslation via Structured Query Models.
In Proceed-ings of Coling 2004, pages 411?417, Geneva, Switzer-land, Aug 23?Aug 27.
COLING.866
