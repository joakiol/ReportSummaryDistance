Noun Phrase  Coreference as C luster ingCla i re  Card ie  and  K i r i  Wagsta f fDepar tment  of Computer  ScienceCornel l  Univers i tyI thaca,  NY  14853E-mai l :  card ie ,wkir i@cs.cornel l .eduAbst ractThis paper introduces a new, unsupervised algo-rithm for noun phrase coreference r solution.
It dif-fers from existing methods in that it views corer-erence resolution as a clustering task.
In an eval-uation on the MUC-6 coreference resolution cor-pus, the algorithm achieves an F-measure of 53.6%~placing it firmly between the worst (40%) and best(65%) systems in the MUC-6 evaluation.
More im-portantly, the clustering approach outperforms theonly MUC-6 system to treat coreference r solutionas a learning problem.
The clustering algorithm ap-pears to provide a flexible mechanism for coordi-nating the application of context-independent a dcontext-dependent constraints and preferences foraccurate partitioning of noun phrases into corefer-ence equivalence classes.1 In t roduct ionMany natural language processing (NLP) applica-tions require accurate noun phrase coreference r so-lution: They require a means for determining whichnoun phrases in a text or dialogue refer to the samereal-world entity.
The vast majority of algorithmsfor noun phrase coreference combine syntactic and,less often, semantic ues via a set of hand-craftedheuristics and filters.
All but one system in theMUC-6 coreference performance evaluation (MUC,1995), for example, handled coreference resolutionin this manner.
This same reliance on complicatedhand-crafted algorithms i true even for the narrowertask of pronoun resolution.
Some exceptions exist,however.
Ge et al (1998) present a probabilisticmodel for pronoun resolution trained on a small sub-set of the Penn Treebank Wall Street Journal corpus(Marcus et al, 1993).
Dagan and Itai (1991) developa statistical filter for resolution of the pronoun "it"that selects among syntactically viable antecedentsbased on relevant subject-verb-object cooccurrences.Aone and Bennett (1995) and McCarthy and Lehn-ert (1995) employ decision tree algorithms to handlea broader subset of general noun phrase coreferenceproblems.This paper presents a new corpus-based approachto noun phrase coreference.
We believe that itis the first such unsupervised technique developedfor the general noun phrase coreference task.
Inshort, we view the task of noun phrase coreferenceresolution as a clustering task.
First, each nounphrase in a document is represented as a vectorof attribute-value pairs.
Given the feature vectorfor each noun phrase, the clustering algorithm coor-dinates the application of context-independent a dcontext-dependent coreference constraints and pref-erences to partition the noun phrases into equiv-alence classes, one class for each real-world entitymentioned in the text.
Context-independent corefer-ence constraints and preferences are those that applyto two noun phrases in isolation.
Context-dependentcoreference decisions, on the other hand, considerthe relationship of each noun phrase to surroundingnoun phrases.In an evaluation on the MUC-6 coreference r so-lution corpus, our clustering approach achieves anF-measure of 53.6%, placing it firmly between theworst (40%) and best (65%) systems in the MUC-6 evaluation.
More importantly, the clustering ap-proach outperforms the only MUC-6 system to viewcoreference resolution as a learning problem: TheRESOLVE system (McCarthy and Lehnert, 1995)employs decision tree induction and achieves an F-measure of 47% on the MUC-6 data set.
Further-more, our approach has a number of importantadvantages over existing learning and non-learningmethods for coreference r solution:?
The approach is largely unsupervised, so no an-notated training corpus is required.?
Although evaluated in an information ex-traction context, the approach is domain-independent.?
As noted above, the clustering approach pro-vides a flexible mechanism for coordinat-ing context-independent a dcontext-dependentcoreference constraints and preferences for par-titioning noun phrases into coreference equiva-lence classes.82!As a result, we believe that viewing noun phrasecoreference as clustering provides a promising frame-work for corpus-based coreference resolution.The remainder of the paper describes the details ofour approach.
The next section provides a concretespecification of the noun phrase coreference resolu-tion task.
Section 3 presents the clustering algo-rithm.
Evaluation of the approach appears in Sec-tion 4.
Qualitative and quantitative comparisons torelated work are included in Section 5.2 Noun Phrase  Core ferenceIt is commonly observed that a human speaker orauthor avoids repetition by using a variety of nounphrases to refer to, the same entity.
While humanaudiences have little trouble mapping a collectionof noun phrases onto the same entity, this task ofnoun phrase (NP) coreference r solution can presenta formidable challenge to an NLP system.
Fig-ure I depicts a typical coreference r solution system,which takes as input an arbitrary document and pro-duces as output the appropriate coreference equiva-lence classes.
The subscripted noun phrases in thesample output constitute two noun phrase corefer-ence equivalence classes: Class JS contains the fivenoun phrases that  refer to John Simon, and classPC contains the two noun phrases that representPrime Corp.
The figure also visually links neigh-boring coreferent noun phrases.
The remaining (un-bracketed) noun phrases have no coreferent NPs andare considered singleton equivalence classes.
Han-dling the JS class alone requires recognizing corefer-ent NPs in appositive and genitive constructions aswell as those that occur as proper names, possessivepronouns, and definite NPs.3 Core ference  as  C lus ter ingOur approach to the coreference task stems fromthe observation that each group of coreferent nounphrases defines an equivalence class 1.
Therefore, itis natural to view the problem as one of partitioning,or clustering, the noun phrases.
Intuitively, all of thenoun phrases used to describe a specific concept willbe "near" or related in some way, i.e.
their concep-tual "distance" will be small.
Given a descriptionof each noun phrase and a method for measuringthe distance between two noun phrases, a cluster-ing algorithm can then group noun phrases together:Noun phrases with distance greater than a cluster-ing radius r are not placed into the same partitionand so are not considered coreferent.The subsections below describe the noun phrase1The coreference 'relation is symmetric, transitive, andreflexive.John Simon, Chief Financial Officer ofPrime Corp. since 1986, saw his pay jump20%, to $1.3 million, as the 37-year-old alsobecame the financial-services ompany'spresident.\[Js John Simon\], \[Js Chief Financial Officer\]~,~of\[R: Prime Corp.\] since 1986, s g..x~i,\[j s fiis\]..Jpay jump 20 , ~ ,  a~..\[js ~e 37 -(year-old\] also became \[pc ~ l -services company\]'s [J president\].Figure 1: Coreference Systemrepresentation, the distance metric, and the cluster-ing algorithm in turn.3.1 Instance Representat ionGiven an input text, we first use the Empire nounphrase finder (Cardie and Pierce, 1998) to locateall noun phrases in the text.
Note that Empireidentifies only base noun phrases, i.e.
simple nounphrases that contain no other smaller noun phraseswithin them.
For example, Chief Financial Officerof Prime Corp. is too complex to be a base nounphrase.
It contains two base noun phrases: ChiefFinancial Officer and Prime Corp.Each noun phrase in the input text is then repre-sented as a set of 11 features as shown in Table 1.This noun phrase representation is a first approxi-mation to the feature vector that would be requiredfor accurate coreference resolution.
All feature val-ues are automatically generated and, therefore, arenot always perfect.
In particular, we use very sim-ple heuristics to approximate the behavior of morecomplex feature value computations:Ind iv idua l  Words .
The words contained in thenoun phrase are stored as a feature.Head noun.
The last word in the noun phrase isconsidered the head noun.Posit ion.
Noun phrases are numbered sequentially,starting at the beginning of the document.Pronoun Type.
Pronouns are marked as one ofNOMinative, ACCusative, POSSessive, or AMBigUOUS(you and it).
All other noun phrases obtain the value83Words.
Head Noun(in bold)J ohn  S imonCh ie f  F inanc ia lOfficerPrime Corp.1986hispay20%$1.3 millionthe 37-year-oldthe financial-servicescompanypresidentPosi-tion12PronounTypeNONENONE3 NONE4 NONE5 POSS6 NONE7 NONE8 NONE9 NONE10 NONE11 NONEArticleNONENONEAppos-itiveNONONONE NONONE NONONE NONONE NONONE NONONE NODEF NODEF NONONE NONumber Proper SemanticName ClassSING YES HUMANSING NO HUMANSING NO COMPANYPLURAL NO NUMBERSING NO HUMANSING NO PAYMENTPLURAL NO PERCENTPLURAL NO MONEYSING NO HUMANSING NO COMPANYSING NO HUMANGenderMASCEITHERNEUTERNEUTERMASCNEUTERNEUTERNEUTEREITHERNEUTEREITHERAnimacyANIMANIMINANIMINANIMANIMINANIMINANIMINANIMANIMINANIMANIMTable 1: Noun Phrase Instance Representation For All Base NPs in the Sample TextNONE for this feature.Art ic le.
Each noun phrase is marked INDEFinite(contains aor an), DEFinite (contains the), or NONE.Appos i t ive .
Here we use a simple, overly restric-tive heuristic to determine whether or not the nounphrase is in a (post-posed) appositive construction:If the noun phrase is surrounded by commas, con-tains an article, and is immediately preceded by an-other noun phrase, then it is marked as an apposi-tive.Number .
If the head noun ends in an 's', thenthe noun phrase is marked PLURAL; otherwise, it isconsidered SINGular.
Expressions denoting money,numbers, or percentages are also marked as PLURAL.P roper  Name.
Proper names are identified bylooking for two adjacent capitalized words, option-ally containing a middle initial.Semant ic  Class.
Here we use WordNet (Fellbaum,1998) to obtain coarse semantic information for thehead noun.
The head noun is characterized as oneOf  T IME,  C ITY ,  AN IMAL ,  HUMAN,  o r  OB JECT .
If noneof these classes pertains to the head noun, its imme-diate parent in the class hierarchy is returned as thesemantic lass, e.g.
PAYMENT for the head noun payin NP6 of Table 1.
A separate algorithm identifiesNUMBERS,  MONEY,  and COMPANYs .Gender .
Gender (MASCUline, FEMinine, EITHER,or NEUTER) is determined using WordNet and (forproper names) a list of common first names.An imacy.
Noun phrases classified as HUMAN or AN-IMAL are marked ANIM; all other NPs are consideredINANIM.3.2  D is tance  Metr icNext, we define the following distance metric be-tween two noun phrases:d is t (NP i ,  NP j )  ----~ f e F W f * incompatibi l i ty f (N P i, N P y )where F corresponds to the NP feature set de-scribed above; incompatibilityf is a function thatreturns a value between 0 and l inclusive and in-dicates the degree of incompatibility of f for NPiand NPj ;  and wf denotes the relative importanceof compatibility w.r.t, feature f.  The incompatibil-ity functions and corresponding weights are listed inTable 2.
2 In general, weights are chosen to representlinguistic knowledge about coreference.
Terms witha weight of cc represent filters that rule out impossi-ble antecedents: Two noun phrases can never coreferwhen they have incompatible values for that term'sfeature.
In the current version of our system, theNUMBER,  PROPER NAME,  SEMANTIC  CLASS,  GEN-DER,  and ANIMACY features operate as coreferencefilters.
Conversely, terms with a weight of - c~ forcecoreference between two noun phrases with compat-ible values for that term's feature.
The APPOSITIVEand WORDS-SUBSTRING terms operate in this fash-ion in the current distance metric.Terms with a weight of r - -  the clustering ra-dius threshold - -  implement a preference that twoNPs not be coreferent if they are incompatible w.r.t.that term's feature.
As will be explained below,however, two such NPs can be merged into thesame equivalence class by the clustering algorithmif there is enough other evidence that they are sim-ilar (i.e.
there are other, coreferent noun phrase(s)sufficiently close to both).All other terms obtain weights selected using thedevelopment corpus.
Although additional testing2Note that there is not currently a one-to-one correspon-dence between NP features and distance metric terms: Thedistance metric contains two terms that make use of theWORDS feature of the noun phrase representation.84Feature  fWordsHead NounPositionPronounArticleWords-SubstringAppositiveNumberProper NameSemantic ClassGenderAnimacyWeight Incompatibility function10.0 (~ of mismatching words a) / (~- of words in longer NP)1.0 1 if the head nouns differ; else 05.0 (difference in position) / (maximum difference in document)r 1 if NP~ is a pronoun and NPj is not; else 0r 1 if NPj is indefinite and not appositive; else 0-~  1 if NPi subsumes (entirely includes as a substring) NPj;-~  1 if NPj is appositive and NPi is its immediate predecessor; else 0o?
1 if they do not match in number; else 0co 1 if both are proper names, but mismatch on every word; else 01 if they do not match in class; else 0c~ 1 if they do not match in gender (allows EITHER to match MASC or  FEM);  else 0c~ 1 if they do not match in animacy; else 0aPronouns are handled as gender-specific "wild cards".Table 2: Incompatibi l ity Functions and Weights for Each Term in the Distance MetricWords, Head: Posi- Pronoun Article Appos- Number Proper Class I Gender AnimacyNoun tion tive NameThe cha i rman 1 NONE DEF NO SING NO HUMAN E ITHER ANIMMs.
Whi te  2 NONE NONE NO SING YES HUMAN FEM ANIMHe 3 NOM NONE NO SING NO HUMAN MASC ANIMTable 3: Instance Representation for Noun Phrases in The chairman spoke with Ms. White yesterday.
He...is required, our current results indicate that theseweights are sensitive to the distance metric, butprobably not to the corpus.When computing a sum that involves both oc and-c~,  we choose~the more conservative route, andthe oc distance takes precedence (i.e.
the two nounphrases are not considered coreferent).
An exampleof where this might occur is in the following sentence:\[1 Reardon Steel Co.\] manufactures severalthousand tons of \[2 steed each week.Here, NP1 subsumes NP2, giving.them a distanceof -c<) via the word substring term; however, NPi'ssemantic class is COMPANY, and NP2's class is OB-JECT, generating a distance of cx) via the semanticclass feature.
Therefore, dist(NP1,NP2) = oc andthe two noun phrases are not considered coreferent.The coreference distance metric is largely context-independent in {hat it determines the distance be-tween two noun ~ phrases using very little, if any, oftheir intervening or surrounding context.
The clus-tering algorithm described below is responsible forcoordinating these local coreference decisions acrossarbitrarily long contexts and, thus, implements a se-ries of context-dependent coreference decisions.3.3 Clustering AlgorithmThe clustering algorithm is given in Figure 2.
Be-cause noun phrases generally refer to noun phrasesthat precede them, we start at the end of the doc-ument and work backwards.
Each noun phrase iscompared to all preceding noun phrases.
If the dis-tance between two noun phrases is less than theclustering radius r, then their classes are consideredfor possible merging.
Two coreference quivalenceclasses can be merged unless there exist any incom-patible NPs in the classes to be merged.It is useful to consider the application of our al-gorithm to an excerpt from a document:\[1 The chairman\] spoke with \[2 Ms. White\]yesterday.
\[~ He\] ...The noun phrase instances for this fragment areshown in Table 3.
Initially, NP1, NP2, and NP3are all singletons and belong to coreference classescl, c2, and c3, respectively.
We begin by consid-ering NP3.
Dist(NP2,NP3) = oc due to a mis-match on gender, so they are not considered forpossible merging.
Next, we calculate the distancefrom NP1 to NP3.
Pronouns are not expected tomatch when the words of two noun phrases are com-pared, so there is no penalty here for word (or headnoun) mismatches.
The penalty for their differencein position is dependent on the length of the docu-ment.
For illustration, assume that this is less thanr.
Thus, dist(NP1,NP3) < r. Their coreferenceclasses, Cl and c3, are then considered for merging.Because they are singleton classes, there is no addi-tional possibility for conflict, and both noun phrasesare merged into cl.85COREFERENCE_CLUSTERING ( N P~ , N P,-1 .
.
.
.
.
N Pi )1.
Let r be the clustering radius.2.
Mark each noun phrase NPi as belonging to its ownclass, c~: c, = {NP~}.3.
Proceed through the noun phrases from the docu-ment in reverse order, NP~.
NP,.-1 .
.
.
.
.
NP1.
Foreach noun phrase NPj encountered, consider eachpreceding noun phrase NPi.
(a) Let d = dist(NF~, NP  i).
(b) Let c~ = class_ofNPi and cj = class_ofNPj.
(c) If d < r and ALL_NPs_COMPATIBLE (ei, cj)then cj = c~ O cj.ALL_NPs_COMPATIBLE (c~, c/)1.
For all NP~ E cj(a) For all NPb E c~i.
If dist(NPa, NPb) = cothen Return FALSE.2.
Return TRUE.Figure 2: Clustering AlgorithmThe algorithm then considers NP2.D is t (NP i ,NP2)  = 11.0 plus a small penaltyfor their difference in position.
If this distance is> r, they will not be considered coreferent, andthe resulting equivalence classes will be: {{Thechairman, he}, {Ms. White}}.
Otherwise, thedistance is < r, and the algorithm considers cl andc~ for merging.
However, cl contains NP3, and, ascalculated above, the distance from NP2 to NP3 isoc.
This incompatibility prevents the merging of c~and c2, so the resulting equivalence classes wouldstill be {{The chairman, he}, {Ms. White}}.In this way, the equivalence classes grow in aflexible manner.
In particular, the clustering al-gorithm automatically computes the transitive clo-sure of the coreference relation.
For instance, ifd is t (NP i ,NP j )  < r and d is t (NP j ,NPk)  < rthen (assuming no incompatible NPs), NPi ,  NP j ,and NPk will be in the same class and consid-ered mutually coreferent.
In fact, it is possible thatdist(NPi ,  NPk)  > r, according to the distance mea-sure; but as long as that distance is not c~, NPican be in the same class as NPk.
The distancemeasure operates on two noun phrases in isolation,but the clustering algorithm can and does make useof intervening NP information: intervening nounphrases can form a chain that links otherwise dis-tant NPs.
By separating context-independent andcontext-dependent computations, the noun phraserepresentation a d distance metric can remain fairlysimple and easily extensible as additional knowledgesources are made available to the NLP system forcoreference resolution.4 Evaluat ionWe developed and evaluated the clustering ap-proach to coreference resolution using the "dry run"and "formal evaluation" MUC-6 coreference cot-pora.
Each corpus contains 30 documents that havebeen annotated with NP coreference links.
We usedthe dryrun data for development of the distancemeasure and selection of the clustering radius r andreserved the formal evaluation materials for testing.All results are reported using the standard men-sures of recall and precision or F-measure (whichcombines recall and precision equally).
They werecalculated automatically using the MUC-6 scoringprogram (Vilaln et al, 1995).Table 4 summarizes our results and comparesthem to three baselines.
For each algorithm, weshow the F-measure for the dryrun evaluation (col-umn 2) and the formal evaluation (column 4).
(The"adjusted" results are described below.)
For thedryrun data set, the clustering algorithm obtains48.8% recall and 57.4% precision.
The formal eval-uation produces similar scores: 52.7% recall and54.6% precision.
Both runs use r = 4, which was ob-tained by testing different values on the dryrun cor-pus.
Table 5 summarizes the results on the dryrundata set for r values from 1.0 to 10.0.
3 As expected,increasing r also increases recall, but decreases pre-cision.
Subsequent tests with different values for ron the formal evaluation data set alo obtained op-timal performance with r= 4.
This provides partialsupport for our hypothesis that r need not be recal-culated for new corpora.The remaining rows in Table 4 show the perfor-mance of the three baseline algorithms.
The firstbaseline marks every pair of noun phrases as coref-erent, i.e.
all noun phrases in the document form oneclass.
This baseline is useful because it establishesan upper bound for recall on our clustering algo-rithm (67% for the dryrun and 69% for the formalevaluation).
The second baseline marks as corefer-ent any two noun phrases that have a word in com-mon.
The third baseline marks as coreferent any twonoun phrases whose head nouns match.
Althoughthe baselines perform better one might expect (theyoutperform one MUC-6 system), the clustering al-gorithm performs ignificantly better.In part because we rely on base noun phrases, ouraNote that r need not be an integers especially when thedistance metric is returning non-integral values.86IAlgorithm \] Dryrun Data SetOfficial AdjustedCluster ing 52.8 64.9All One Class 44.8 50.2Match Any Word 44.1 52.8Match Head Noun 46.5 56.9Formal Run Data SetOfficial Adjusted53.6 63.541.5 45.741.3 48.845.7 54.9Table 4: F-measure Results for the Clustering Algorithm and Baseline Systems on the MUC-6 Data Setsrecall levels are fairly low.
The "adjusted" figuresof Table 4 reflect this upper bound on recall.
Con-sidering only coreference links between base nounphrases, the clustering algorithm obtains a recall of72.4% on the dryrun, and 75.9% on the formal eval-uation.
Another Source of error is inaccurate andinadequate NP feature vectors.
Our procedure forcomputing semantic lass values, for example, is re-sponsible for many errors - -  it sometimes returnsincorrect values and the coarse semantic lass dis-tinctions are often inadequate.
Without a betternamed entity finder, computing feature vectors forproper nouns is difficult.
Other errors result from alack of thematic and grammatical role information.The lack of discourse-related topic and focus infor-mation also limits System performance.
In addition,we currently make no special attempt o handle re-flexive pronouns and pleonastic "it".Lastly, errors arise from the greedy nature of theclustering algorithm.
Noun phrase NPj is linkedto every preceding noun phrase NP~ that is com-patible and within the radius r, and that link cannever be undone.
We are considering three possibleways to make the algorithm less aggressively greedy.First, for each NPj, instead of considering everyprevious noun phrase, the algorithm could stop onfinding the first compatible antecedent.
Second, foreach NPj, the algorithm could rank all possible an-tecedents and then choose the best one and link onlyto that one.
Lastly,: the algorithm could rank all pos-sible coreference links (all pairs of noun phrases inthe document) and then proceed through them inranked order, thus progressing from the links it ismost confident about to those it is less certain of.Future work will include a more detailed error anal-ysis.5 Re la ted  WorkExisting systems for noun phrase coreference reso-lution can be broadly characterized as learning andnon-learning approaches.
All previous attempts toview coreference as a learning problem treat coref-erence resolution as a classification task: the algo-rithms classify a pair of noun phrases as coreferentor not.
Both MLR (Aone and Bennett, 1995) andRESOLVE (McCarthy and Lehnert, 1995), for ex-r Recall1 34.62 44.73 47.34 48.85 49.16 49.87 50.38 50.79 50.910 50.9Precision F-measure69.3 46.161.4 51.758.5 52.357.4 52.856.8 52.755.0 52.353.8 52.053.0 51.852.5 51.752.1 51.5Table 5: Performance on the Dryrun Data Set forDifferent rample, apply the C4.5 decision tree induction al-gorithm (Quinlan, 1992) to the task.
As super-vised learning algorithms, both systems require afairly large amount of training data that has beenannotated with coreference resolution information.Our approach, on the other hand, uses unsuper-vised learning 4 and requires no training data.
5 Inaddition, both MLR and RESOLVE require an ad-ditional mechanism to coordinate the collection ofpairwise coreference decisions.
Without this mech-anism, it is possible that the decision tree classifiesNPi and NPj as coreferent, and NPj and NPk ascoreferent, but NPi and NPk as not coreferent.
Inan evaluation on the MUC-6 data set (see Table 6),RESOLVE achieves an F-measure of 47%.The MUC-6 evaluation also provided results for alarge number of non-learning approaches to corefer-ence resolution.
Table 6 provides a comparison ofour results to the best and worst of these systems.Most implemented a series of linguistic constraintssimilar in spirit to those employed in our system.The main advantage of our approach is that all con-straints and preferences are represented neatly inthe distance metric (and radius r), allowing for sim-ple modification of this measure to incorporate new4Whether or not clustering can be considered a "learning"approach is unclear.
The algorithm uses the existing parti-tions to process each successive NP, but the partitions gener-ated for a document are not useful for processing subsequentdocuments.OWe do use training data to tune r, but as noted above, itis likely that r need not be recalculated for new corpora.87Algorithm RecallClustering 53RESOLVE 44Best MUC-6 59Worst MUC-6 36Precision F-measure55 5451 !
4772 6544 40Table 6: Results on the MUC-6 Formal Evaluationknowledge sources.
In addition, we anticipate beingable to automatically learn the weights used in thedistance metric.There is also a growing body of work on the nar-rower task of pronoun resolution.
Azzam et al(1998), for example, describe a focus-based approachthat incorporates discourse information when re-solving pronouns.
Lappin and Leass (1994) makeuse of a series of filters to rule out impossible an-tecedents, many of which are similar to our oo-incompatibilities.
They also make use of more exten-sive syntactic information (such as the thematic roleeach noun phrase plays), and thus require a fullerparse of the input text.
Ge et al (1998) presenta supervised probabilistic algorithm that assumes afull parse of the input text.
Dagan and Itai (1991)present a hybrid full-parse/unsupervised l arningapproach that focuses on resolving "it".
Despite alarge corpus (150 million words), their approach suf-fers from sparse data problems, but works well whenenough relevant data is available.
Lastly, Cardie(1992a; 1992b) presents a case-based learning ap-proach for relative pronoun disambiguation.Our clustering approach differs from this previouswork in several ways.
First, because we only requirethe noun phrases in any input text, we do not requirea fifll syntactic parse.
Although we would expect in-creases in performance if complex noun phrases wereused, our restriction to base NPs does not reflect alimitation of the clustering algorithm (or the dis-tance metric), but rather a self-imposed limitationon the preprocessing requirements of the approach.Second, our approach is unsupervised and requiresno annotation of training data, nor a large corpus forcomputing statistical occurrences.
Finally, we han-dle a wide array of noun phrase coreference, beyondjust pronoun resolution.6 Conc lus ions  and  Future  WorkWe have presented a new approach to noun phrasecoreference resolution that treats the problem asa clustering task.
In an evaluation on the MUC-6 coreference resolution data set, the approachachieves very promising results, outperforming theonly other corpus-based learning approach and pro-ducing recall and precision scores that place it firmlybetween the best and worst coreference systems inthe evaluation.
In contrast o other approaches tocoreference r solution, ours is unsupervised and of-fers several potential advantages over existing meth-ods: no annotated training data is required, the dis-tance metric can be easily extended to account foradditional linguistic information as it becomes avail-able to the NLP system, and the clustering approachprovides a flexible mechanism for combining a vari-ety of constraints and preferences to impose a parti-tioning on the noun phrases in a text into coreferenceequivalence classes.Nevertheless, the approach can be improved in anumber of ways.
Additional analysis and evaluationon new corpora are required to determine the gen-erality of the approach.
Our current distance met-ric and noun phrase instance representation are onlyfirst, and admittedly very coarse, approximations tothose ultimately required for handling the wide va-riety of anaphoric expressions that comprise nounphrase coreference.
We would also like to make useof cues from centering theory and plan to explore thepossibility of learning the weights associated witheach term in the distance metric.
Our methods forproducing the noun phrase feature vector are alsooverly simplistic.
Nevertheless, the relatively strongperformance of the technique indicates that cluster-ing constitutes a powerful and natural approach tonoun phrase coreference r solution.7 AcknowledgmentsThis work was supported in part by NSF Grant IRI-9624639 and a National Science Foundation Graduatefellowship.
We would like to thank David Pierce for hisformatting and technical advice.Re ferencesChinatsu Aone and William Bennett.
1995.
Eval-uating Automated and Manual Acquisition ofAnaphora Resolution Strategies.
In Proceedings ofthe 33rd Annual Meeting of the ACL, pages 122-129.
Association for Computational Linguistics.S.
Azzam, K. Humphreys, and R. Gaizauskas.
1998.Evaluating a Focus-Based Approach to AnaphoraResolution.
In Proceedings of the 36th AnnualMeeting of the ACL and COLING-98, pages 74-78.
Association for Computational Linguistics.C.
Cardie and D. Pierce.
1998.
Error-Driven Prun-ing of Treebank Grammars for Base Noun PhraseIdentification.
In Proceedings of the 36th AnnualMeeting of the ACL and COLING-98, pages 218-224.
Association for Computational Linguistics.C.
Cardie.
1992a.
Corpus-Based Acquisition of Rel-ative Pronoun Disambiguation Heuristics.
In Pro-ceedings off the 30th Annual Meeting off the ACL,88pages 216-223, University of Delaware, Newark,DE.
Association for Computational Linguistics.C.
Cardie.
1992b.
Learning to Disambiguate Rel-ative Pronouns.
In!
Proceedings of the Tenth Na-tional Conference on Artificial Intelligence, pages38-43, San Jose, CA.
AAAI Press / MIT Press.I.
Dagan and A. Itai.
1991.
A Statistical Filterfor Resolving Pron0un References.
In Y.
A. Feld-man and A. Bruckstein, editors, Artificial Intelli-gence and Computer Vision, pages 125-135.
Else-vier Science Publishers, North Holland.C.
Fellbaum.
1998.
WordNet: An Electronical Lex-ical Database.
The MIT Press, Cambridge, MA.N.
Ge, J. Hale, and E\] Charniak.
1998.
A StatisticalApproach to Anaphora Resolution.
In Charniak,Eugene, editor, Proceedings ofthe Sixth Workshopon Very Large Corpora, pages 161-170, Montreal,Canada.
ACL SIGDAT.S.
Lappin and H. Leass.
1994.
An Algorithm forPronominal Anaphbra Resolution.
ComputationalLinguistics, 20(4):5'35-562.M.
Marcus, M. Marcinkiewicz, and B. Santorini.1993.
Building a Large Annotated Corpus of En-glish: The Penn Treebank.
Computational Lin-guistics, 19(2):313-:330.J.
McCarthy and W. Lehnert.
1995.
Using DecisionTrees for Coreference Resolution.
In C. Mellish,editor, Proceedings iof the Fourteenth InternationalConference on Art!ficial Intelligence, pages 1050-1055.1995.
Proceedings of the Sixth Message Understand-ing Conference (MUC-6).
Morgan Kaufmann,San Francisco, CA.J.
R. Quinlan.
1992.
C~.5: Programs for MachineLearning.
Morgan Kaufmaan, San Mateo, CA.M.
Vilaim J. Burger, J. Aberdeen, D. Connolly,and L. Hirschman.
~1995.
A model-theoretic coref-erence scoring scheme.
In Proceedings of theSixth Message Understanding Conference (MUC-6), pages 45-52, San Francisco, CA.
Morgan Kauf-mann.89
