~IST IC  PROSL~ IN ~JLTILINfiUAL HOI~(-DLOGICAL ~J~O~:~OSITIONG.ThurmairSiemens AGZT ZTIOtto-Hahn-Ring 6Munich 83West-GermanyABSTRACTAn algorithm for the morphological decompositionof words into morphemes is presented.
Theapplication area is information retrieval, and thepurpose is to find morphologically related termsto a given search term.
First, the parsingframework is presented, then several linguisticdecisions are discussed: morpheme selection andsegmentation, morpheme classes, morpheme grammar,allomorph handling, etc.
Since the system worksin several languages, language-specific phenomenaare mentioned.I BAC~GRO~I.
Application domainIn Information Retrieval (documentretrieval), the usual way of searching documentsis to use key words (descriptors).
In most of theexistent systems, these descriptors are extractedform the texts automatically and by no meansstandardised; this means that the searcher mustknow the exact shape of the descriptor (pluralform, compound word etc.~, which he doesn't;therefore the search results are often poor andmeager.To improve them, we have developedseveral analysis systems, based on linguistictechniques.
One of them is the MorphologicalAnalysis for Retrieval Support (MARS).
It expandsthe terms of search questions morphologically andreturns an expanded set of tokens containing thesame root as the search term.
This is donethrough analysis of a set of documents: Each wordin a document is decomposed into its morphemes,the roots are extracted, allomorphes are broughtto the same morpheme representation, and themorphemes are inverted in a way that they areconnected to all the words they occur in (seefig.l).
Retrieval is done by evaluating theseinverted files.
As a result, the searcher isindependent of the morphological shape of the termhe wants to search with.
From a pure linguisticpoint of view, the aim is to find themorphological structure of each word as well asthe information about which morpheme occurs inwhich word.The system has been developed forseveral languages: We took 36000 english tokens(from the Food Science Technology Abstractsdocument files), 53000 German tokens (from theGerman Patent Office document files) and 35000Spanish tokens (from several kinds of texts: shortstories, telephone maintenance, newspapers etc.
).In 95-97% of the tokens, the correct roots wereextracted; the retrieval results could be improvedby overall 70% (for the English version; theGerman version is currently being tested).Since the kernel part of the systemconsists of a morphological decomposition algo-rithm, it can also be used for the handling ofother phenomena below the lexical level, e.g.handling of lexical gaps.2.
The decomposition algorithmThe parser works essentially languageindependent (see below for language-specificpoints), using a morpheme list an a morphologicalgr~,~r of the language in question.First of all, a preprocessing transformsthe input string in order to eliminate some kindsof allomorphes (see below); its operations arejust grapheme insertion, deletion and changing;therefore it can be developed language-independent.
The transformation conditions andcontents, of course, differ for the languages.Then the transformed string is trans-ferred to the parser.
The decomposition worksin a left-to-right bredth-first manner.
It buildsup a network graph consisting of possiblemorphemes.
At a certain state in the graph, thealgorithm searches for possible successors: ItFig.l: System structureMorphemel ( ~ IAllomorph iLexicon| ~ List l~ I  Decomposition ~ '  Inverte~Parsin~ ~ ~ Scoring I~  ~I  Root fil~Grammar  J _174identifies possible morphemes by looking them upin the morpheme list, and checks if they can holdtheir current position in the word; this is doneby means of a morpheme grammar.
The morphemegr~mm~r contains the possible sequences ofmorpheme classes and is represented as a state-transition automaton.
If the new morpheme isaccepted it is stored in a morpheme chart andconnected with the network graph.
If the wholeinput string is processed, the graph is evaluatedand put out.Since the morpheme list and the morphemegrammar are language-specific, they are separatedfrom the parser and stored in files; so thedecomposition itself to a large extent is languageindependent.In a number of cases (owing both to themorpheme gr~mm~r and to true ambiguities innatural language), the parser produces more thanone possible result; this means that additionalstrategies have to be applied to select the mostplausible decomposition.
The system scores thebest result highest and puts it on the top of thedecomposition list; nevertheless it keeps theothers, because different decompositions may becorrect, e.g.
for different parts of speech; butthis goes beyond pure morphology.The scored decomposition results areused to extract the root(s) and to disambiguatesome morphs.
The roots are inverted in such a waythat they point to the set of tokens they belongto.
Allomorphes of the same morphemes areinverted to the same set of tokens, which meansthat in searching with any allomorph of a word thesystem nevertheless will come up with the correctset of tokens.II LINGUISTIC ISSUES IN DECOMPOSITIONDealing with large amounts of data, somelinguistic problems arise which not only influencethe claim that the system should be languageindependent, but also concern pure morphology.Some of them are presented in the followingsections.I.
Morpheme definitionThe first problem is to set up rules todefine possible morphemes.
One crucial point isthe morpheme selection: What about proper names(BAGDAD, TOKYO)?
What about special terminology(e.g.
chemical terms which need special suffix-ation rules)?
What about foreign words andmorphemes, which are used quite frequently andhave to be considered if the language is seen as asynchronic system?
As a result, a pure single-language morphology is highly artificial from thelanguage system point of view, and there is somearbitrariness in selecting morphemes for themorpheme lexicon.We decided not to deal with proper namesand to pick up the morphemes which are quitefrequent (with respect to the number of tokensthey occur in) and which have many differentderivations.
So, the morphology of one language(e.g.
German) has to be mixed up with themorphology of other languages (Latin, Greek,English) in order to cover a broad variety of thesynchronic language system.
In addition to this,it has been found that the resulting morphemelists differ depending on what topic the documentswe analyse deal with: Some special vocabulary hasto be added to the morpheme list, e.g.
withrespect to food science.
The vocabulary which isconsidered as basic to all topics consists ofapprox.
4-5000 morphemes, the rest is specialvocabulary.
With this morpheme selection, we goterror rates (words which could not be decomposed)of 4-8%; most of them were proper names or typingerrors.Another crucial point is morphemesegmentation.
As the analysis should be syn-chronic, no diachronic segmentation is done.Diachronic issues sometimes occur but are nottaken into account.
But there are two criteriathat lead to different segmentations: Purely dis-tributional based segmentation reduces semant-ically quite different morphemes to the same root(e.g.
English ABROAD vs. BROAD, German VERZUGvs.
ZUG) and sometimes creates artificial over-lappings (e.g.
Spanish SOL-O vs. SOL vs. SOL-AR); on the other hand some clear derivations arenot recoghised because of gaps in the distributionof the lexical material (e.g.
-LICH in GermanOEFFENTLICH).
On the other hand, semanticallyoriented segmentation sometimes leads to a loss ofmorphological information, e.g.
in German prefix-ation: If the prefixes (VER-LUST, VER-ZUG) aretaken as a part of the root, which is correct froma semantic point of view, some information aboutderivational behaviour gets lost.We decided to base morpheme segmentationon the semantic criterion to distinguish themeanings of the roots as far as possible, and tosegment the morphemes according to theirdistribution as far as possible: We take thelongest possible string which is common to all itsderivations even if it contains affixes from adiachronical (and partly derivational) point ofview.
Since there is some intuition used withrespect to which derivations basically carry thesame meaning and which affixes should belong tothe root (i.e.
should be part of a morpheme), themorpheme list is not very elegant from atheoretical point of view; but it must be statedthat the language data often don't fit thecriteria of morphologists.These problems are common to the threelanguages and sometimes lead to irregularities inthe morpheme list.
The resulting lists consist of8000 to 10000 morphemes.2.
Morpheme cate~orisationEvery morpheme has some categorialinformation attached to it, namely morpheme class,morpheme part of speech, allomorph information,morphological idiosyncrasies and inflectionalbehaviour.175All this information is languagedependent: In English, some morphemes duplicatetheir last consonant in derivation (INFER -INFERRING), and there seems to be phonological butno morphological regularity in that behaviour, sothis information has to be explicitly stored.Get-man and Spanish need quite more inflectionalinformation than English does, etc.
All thisinformation can be stored within the same datastructure for the different languages, but theinterpretation of these data has to be programmedseparately.The morpheme classes also depend on thelanguage.
Affix classes don't differ very much:Prefixes, suffixes an inflections are common toall the languages considered; but there arefillers in German compound words that don't existin Spanish, and there are doubleing consonants inEnglish.
More differences are found within thelexical morphemes: The three languages have incommon the basic distinction between bound andunbound morphemes, but there are specialsubcategories e.g.
within the bound ones: Someneed suffixes (THEOR-), some need inflections (thebound version of Spanish SOL-, German SPRACH-),some need doubleing consonants.
With respect tothis, information about possible succeedingmorphemes is stored; but to be able to analyse newor unknown derivations, no additional informationshould be used: an unbound morpheme can or cannottake a suffix, it can or cannot form a compoundword, etc.3.
The morpheme ~ranm~arIn this automaton, the sequences ofpossible morphemes are fixed.
Fop each languageit specifies which morpheme class may be followedby which other one: E.g.
a prefix may be followedby a bound or unbound lexical morpheme or byanother prefix, but not by a suffix or aninflection.
The grammar automaton is stored in afile and interpreted by the parser; so the parsercan handle different languages.
The automatonrestricts the number of morphemes that can occurin a given input word (see fig.
2).Nevertheless, the most effectiveconstraints work on the subclass level: A prefixcan be followed by another one, but not everycombination is allowed.
An unbound morpheme can befollowed by an inflection, but the inflection mustfit to the inflectional properties of the morpheme(e.g.
verb endings to a noun).
All theseconstraints are written in procedures attached tothe transitions between possible morpheme grammarstates; these procedures are highly language-specific.
In fact, this is the biggest problemwhen talking about language-independency.4.
Allomorph handlin~There are several kinds of allomorphes:Some are quite regular and can be eliminated in apreprocessing step: English RELY vs. RELIES,Spanish CUENTA vs. CONTAR are transformed beforethe decomposition goes on; this is pure stringtransformation, which can be performed by a quitesimilar procedure in each language.Other allomorphes can not be handledautomatically; so we attach the allomorphinformation to the lexical entry of the morphem inquestion.
This is done with strong verbs, withGerman derivatlonal and inflectional vowelmutations, with some kinds of Greek and Latinmorphemes (eg.
ABSORB- ING vs. ABSORP-TION,which in fact is regular but ineffective to dealwith automatically), etc.
Different spellings ofmorphemes (CENTRE vs. CENTER) also have to behandled as allomorphes.In our system, the allomorph stems pointto the same set of words they occur in, so thatthe user searching with FOOD will also find wordswith FEED or FED.On the other hand, artificialoverlappings (Spanish SOL vs. SOL-O, English PINvs.
PINE) should point to different sets of wordsin order to disambiguate these morphemes; this canbe done by looking at the morphological context ofthe morph in question; but this is not alwayssufficient for disambiguation.
These kinds ofoverlappings are very common in Spanish, lessfrequent in English and rather seldom in German.5.
Selection strategiesIn 55% of all cases, the decompositioncomes up with only one possible result.
This, inover 99% of the cases, is a correct result.
Inover 40%, however, the result is ambiguous: From amorphological point of view, several decom-positions of a word are acceptable.
Since thesystem has no syntactical or semantic knowledge,it cannot find out the correct one (e.g.
GermanDIEN-ST is correct for a verb, DIENST for a noun;similar English BUILD-ING (verb) vs. BUILDING(noun)).
We decided not to integrate a scoringalgorithm into the decomposition itself but tocompare ambiguous results and try to find the mostplausible decomposition.To do this, we apply several strategies:First, we compare the sequences of morphemeclasses: Suffixation is more frequent thancompounding: The compound LINGUISTIC-ALLYtherefore is less plausible than the suffixationLINGUISTIC-AL-LY.
The morpheme class sequenceinformation can partly be collected statistically176(by evaluating the decompositions with one correctresult); nevertheless it has do be optim~\]isedmanually by evaluating several thousands ofdecomposition results.
(The statistics partlydepend on the type of the text considered).This strategy works with differentresults for the different languages.
If theaffixes of a language are very ambiguous (as it isin German), this strategy is too poor and has tobe supported by several others we are justdeveloping.
In English and Spanish, however, theresults are quite satisfactory: The first 10 ofthe morpheme class sequences in English cover 60%,the first 50 over 80% of the tokens.If the morpheme class sequence strategyfalls below a threshold (which mostly happens withlong compounds), the strategy is switched tolongest matching: The decomposition with thefewest morphemes is scored best.As a result, the disambiguation returnscorrect roots in 90-94% of the cases; in German,the ambiguous affixes don't influence the rootextraction, although the decompositions as a wholeare correct only in 85% of the tokens.
Togetherwith the decompositions with only one correctresult, the whole system works correctly in about96% of the input words.morphemes.
Words which are morphologicallyrelated, like German ZUG vs. BEZUG vs. VERZUG,LUST vs. VERLUST, DAMM vs. VERDAMMEN, arecompletely different from a semantical point ofview.
This could mean that the semantic formationrules do not correspond to the morphologicalones.
But considering large amounts of data, upto now no certain rules can be given how wordmeaning could be derived from the "basic units ofmeaning" (what the morphemes claim to be).Semantically and even syntactically regularbehaviour can be observed at the level of wordsrather than morphemes.
The result of our researchon morphemes tends to support those who stress thestatus of the word as the basic unit of linguistictheory.ACKNOWLEDGEMENTSThe work which was described here was done byA.Baumer, M.Streit, G.Thurmair (German),I.Buettel, G.Th.Niedermair, Ph.Hoole (English) andM.Meya (Spanish).Ill L~ITATIOgSAlthough the morphological decompositionworks quite well and is useful with respect toinformation retrieval problems, there are someproblems concerning the integration of such analgorithm into a whole natural language system.The reason is, that some information neededtherefore is not easily available; this is theinformation which goes beyond morphology and isbased on the interpretation of decompositionresults.
Two examples should be mentioned here.I.
Parts of speechIt is not easy to derive the part ofspeech of a word out of its decomposition.
InGerman, the prefix VER- forms verb-derivations,but the derivation VER-TRAUEN from the verb TRAUENis also a noun, whereas the same derivationVER-TRETEN form the verb TRETEN does not, and thederivation VER-LEGEN (from the verb LEGEN) is alsoan adJectiv.
The past participle GE-F~I.U~ (fromthe verb FAI.L~N) is also a noun, the samederivation from LAUFEN (GE-LAUFEN) is not.
Thisfact is due to the diachronic development of thelanguage which led to a structure of thevocabulary that followed rather the needs of usagethan morphological consistency.REFERENCESMeya,M.
: Morpheme Grammar.
Proc.
of 11th Int.Conference of ALLC, April 1984, Louvain-La-NeuveNiedermair,G.Th., Thurmalr,G., Buettel,I.
:MARS: A retrieval tool on the basis ofMorphological Analysis.
Proc.
of the ACMConference on Research and Development inInformation Retrieval, July 1984, CambridgeHunnicut,S.
: A new Morph Lexicon for English.Proc.
of the COLING Conference, 1976Karttunen, L. : K I lO  - a general morphologicalProcessor.
Texas Linguistic Forum 22, 1983.Koskenniemi,K.
: Two-level model for morphologicalanalysis.
Proc.
of the 8th Intern.
JointConference on Artificial Intelligence, 1983.2.
S~m~nticsThere is some evidence that the meaningof a word can not be predicted out of its177
