Unification and Some New Grammatical FormalismsAravind K. JoshiDepartment of Computer and Information ScienceUniversity of PennsylvaniaI have organized my comments around some of the questions posed by the panel chair,Fernando Pereira.The key idea in the unification-based approaches to grammar is that we deal withinformational structures (called feature structures) which encode a variety of linguisticinformation (lexical, syntactic, semantic, discourse, perhaps even cross-linguistic) in a uniformway and then manipulate (combine) these structures by means of a few (one, if possible) well-defined operations (unification being the primary one).
The feature structures consist of featuresand associated values, which can be atomic or complex i.e., feature structures themselves.
Inother'words, the values can be from a structured set.
The unification operation builds newstructures and together with some string combining operation (concatenation being the primaryone) pairs the feature structures with strings (Schieber, 1986).How does the unification formalism differ from the s tandard context-freegrammar  formalism?In a pure CFG one has only a flrfite number of nonterminals, which are the categorysymbols.
In a CFG based grammar one associates with each category symbol a complex offeatures that are exploited by the grammar in a variety of ways.
In the unification formalismthere is really no such separation between the category symbols and the features.
Featurestructures are the only elements to deal with.
Of course, the traditional category symbols showup as values of a feature (cat) in the feature structures.
The notion of nonterminal symbol isflexible now.
If we multiply out all features and their values down to the atomic values, we willhave a very large number (even infinite under certain circumstances) of nonterminal symbols.Of course, this means trouble for parsing.
Clearly, the standard parsing algorithms for parsingCFG's cannot be extended to unification formalism because of the exponential blowup of45computational complexity, including the possibility of nontermination.
One could focus only onparts of feature structures, not necessarily the same parts for different feature structures, andthereby, have a flexible notion of nonterminal on the one hand and, perhaps, control thecomputational complexity on the other hand.
This aspect of unification formalism has notreceived much attention yet, except in the very interesting work of Schieber (1985).To what extent has the unification formalism been motivated by processingconsiderations?First of all, we should distinguish at least two meanings of processing considerations.
Onehas to do with the efficiency of computation and the other has to do with computationalformalisms, which are well-defined and whose semantics (i.e., the semantics of the formalism)also can be well-defined.
Although the unification formalism has been developed largely byresearchers who are, no doubt, interested in the efficiency of computation, the primarymotivation for the formalism has to do with the second meaning of processing considerations.The standard CFG based formalisms (augmented in a variety of ways) can do all thecomputations that a unification based, formalism can do and vice-versa, however, the semanticsof the formalism (not of the language described by the grammar) is not always well understood.The same is, of course, true of the ATN formalism.
The unification formalism does give anopportunity to provide a well-def'med semantics because of its algebraic haracterization (Pereiraand Schieber, 1984).
How this understanding can be cashed into efficient algorithms forprocessing is still very much an open question.
Good engineering is based on good theory -therein lies the hope.Are we converging to some class of formalisms that are relevant to processingand, if so, how can this class be characterized in a theoretical manner?Most of the grammatical formalisms, especially those of the so-called nontransformationalflavor, have been motivated, at least in part, by processing considerations, for example, parsingcomplexity.
We could say that these formalisms are converging if convergence is defined alongseveral dimensions.
GPSG, LFG, HG, HPSG 1 all have a context-free grammar explicitly or1CFG: context=free grammar, GPSG: generalized phrase structure grammar, LFG: lexical functional grammar,HG: head grammar, TAG: tree adjoining rammar, HPSG: head driven phrase structure grammar, FUG: functionalunification grammar, CG: categorial grammar, PARR: parsing and translation46implicitly, use feature structures of some sort or another, and the lexicon.
Unification formalismby itself is not a grammatical theory but a formalism in which different grammatical theories canbe instantiated.
Some of these grammatical theories explicitly incorporate unification formalismas one component of the grammar (e.g., GPSG, LFG, HPSG, FUG, PATR based grammars, etc.
),while some others (e.g.
TAG, HG, CG, etc. )
do not explicitly incorporate unification formalism,as the feature checking component is not explicitly specified in these grammars as they areformulated at present.
The unification formalism is a nice way of incorporating this featurechecking component in these grammars, in fact, the string combining operations (in HG and CG)and the tree combining operation (in TAG) can themselves be formulated within the unificationformalism generating feature structures in an appropriate manner.
In fact, these differentgrammatical theories differ with respect o the domain of locality over which the unifications (ala Schieber), i.e., a set of constraints across a set of feature structures, are defined.
For example,for a CFG based unification formalism, the domain of locality are the context-free rules, e.g., X 0---> X 1 X 2.
The unifications are defined over feature structures associated with X0, X1, and X 2.For a tree adjoining rammar, the domain of locality are the elementary trees (structures, in thegeneral case), both initial and auxiliary.
These domains of locality define the unifications acrossthe feature structures associated with the components of the domain, and thereby, determine howinformation flows among these feature smactures.
These domains also determine the kinds ofword order patterns describable by these different grammatical formalisms.
In this sense, allthese grammatical formalisms could be said to converge.
This is not surprising as the unificationformalism is a very powerful formalism, in fact, equivalent to a Turing machine.
As far as I cansee, any reasonable grammatical formalism can be instantiated in the unification formalism, as itis unconstrained in the sense described above.
The particular constraints come from theparticular grammatical formalism that is being instantiated.There is another sense of convergence we can talk about.
Here we are concerned with theweak generative capacity, strong generative capacity, parsing complexity, and other formallanguage and automata theoretic properties.
It appears that a proper subclass of indexedgrammars with at least he following properties may characterize adequately a class of grammarssuitable for describing natural language structures, a class called "mildly context- sensitive " inIoshi (1985), (MEG: mildly context-sensitive grammars, MCL: languages of MCGs).
Theproperties are: 1) context-free languages are properly contained in MCL, 2) languages in MCL47can be parsed in polynomial time, 3) MCG's capture only certain kinds of dependencies, e.g.nested ependencies and certain limited kinds of crossing dependencies (e.g.
in the subordinateclause constructions in Dutch, but not in the so-called MIX (or Bach) language, which consistsof equal number of a's, b's, and o's in any order), and 4) languages in MCL have constantgrowth property, i.e., if the strings of the language are arranged in increasing order of length thenany two consecutive l ngths do not differ by arbitrarily large amounts, in fact, any given lengthcan be described as a linear combination of a finite set of fixed lengths.
These properties do notprecisely define MCG, but rather give only a rough characterization, asthe properties are onlynecessary conditions and further, some of the properties are properties of structural descriptionsrather than the languages, hence, difficult to characterize precisely.
TAG, FIG, some restrictedIG 2, and certain types of CG all appear to belong to this class.
Moreover, certain equivalenceshave been established between these grammars, for example, between TAG and FIG (Vijay-Shanker, Weir, and Joshi, 1986).
Some natural extensions of TAG also seem to belong to thisclass.
The processing implications of this convergence are not at all clear, because thepolynomial time complexity, first of all, is only a worst case measure, and secondly, it has to beconsidered along with the constant of proportionality, which depends on the grammar.4Do processing considerations and results show that such systems whenimplemented can be neutral between analysis and production?The pure unification formalism (i.e., with unification as the only operation and no non-monotonic aspects in the feature structures) is bidirectional, in the sense that the order in whichunifications are performed oes not matter.
In this sense, they can be considered neutral betweenanalysis and production.
However, as soon as one adds operators that are not commutative orassociative or add values to feature structure which exhibit non-monotonic behavior, we nolonger have this bidirectionality (and also, perhaps, disallowing the possibility of giving well-defined semantics).
The proponents of unification formalism hope to keep these amendmentsunder control.
How successfully this can be done is very much an open problem.To the extent a formalism is declarative (and this applies equally well to the particulargrammatical theories instantiated in a unification formalism) it can be neutral between analysis2IG: indexed grammar48and production.
The processes which manipulate these formalisms may or may not differ foranalysis and production.
Neutrality between analysis and production is a property shared by avariety of grammatical formalisms.
This kind of neutrality is not the key selling point forunification formalism, in my judgement.Is it a real advance or just a Hollywood term?We have already stated the difference between a CFG based formalism using featurecomplexes in a variety of ways and the unification based formalis.
A well-defined formalismwhose mathematical properties (syntactic, semantic, and computational) are well understood isalways an advance, even though some earlier theories may have used the same pieces ofinformation i  some informal manner.
Clearly, before the advent of the CFG formalism, peoplehad worked with related ideas (e.g., immediate constituant analysis, even part of Panini'sgrammar arc in a CFG style!
); however, no one would say that CFG is just a Hollywood term (ora Broadway term, given the location where CFG's were born).
The mathematical ndcomputational insights that CFG has provided has immensely helped linguistics as well ascomputational linguistics.
The unification formalism shows similar possibilities although themathematical or computational results are not yet at the level corresponding to the CFGformalism.
So in this sense, it is not a Hollywood term, it is an advance.
How big an advance?We will have to wait for an answer to this question until we know more about its mathematicaland computational properties.
Personally, I would like to see some results on some constrainedunification formalisms, in the sense that the flow of information between feature structures iconstrained in some systematic manner.
Such results, if obtainable, could give us more insightsinto the computational properties of these formalisms and their suitability (not just theiradequacy) for describing natural language structures.AcknowledgementsThis work is partially supported by DARPA grants NOOO14-85-K-0018 andNOOO14-85-K-0807, NSF grants MCS8219196-CER, MCS-82-07294, 1 RO1-HL-29985-01, U.S. Army grants DAA6-29-84-K-0061, DAAB07-84-K-F077, U.S. AirForce grant 82-NM-299, AI Center grants NSF-MCS-83-05221.References49Joshi, A.K.
1985.
Tree Adjoining Grammars: How much context sensitivity isrequired to provide reasonable structural descriptions?
In Natural Language Processing(Eds.
D. Dowty, L. Karttunen, and A. Zwicky), Cambridge University Press, Cambridge.Pereira, F.C.N.
and Schieber, S.M.
1984.
"The semantics of grammar formalismsseen as computer languages".
In Proceedings of the Tenth International Conference onComputational Linguistics, Stanford University, Stanford, CA, August.Schieber, S.M.
1985.
"Using restrictions to extend parsing algorithms for complex-feature-based formalisms".
In Proceedings of the 22nd Annual Meeting of theAssociation for Computational Linguistics, University of Chicago, Chicago, Illinois,June.Schieber, S.M.
1986.
An Introduction to Unification-Based Approaches toGrammar.
Center for the Study of Language and Information, Stanford University,Stanford, CA.Vijay-Shanker, K., Weir, D., and Joshi, A.K.
1986.
"Tree adjoining and headwrapping", in Proceedings of the International Conference on Computational Linguistics(COLING) Bonn, August 1986.50
