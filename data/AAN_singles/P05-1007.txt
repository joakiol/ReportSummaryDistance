Proceedings of the 43rd Annual Meeting of the ACL, pages 50?57,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsAggregation improves learning:experiments in natural language generation for intelligent tutoring systemsBarbara Di Eugenio and Davide Fossati and Dan YuUniversity of IllinoisChicago, IL, 60607, USA{bdieugen,dfossa1,dyu6}@uic.eduSusan HallerUniversity of Wisconsin - ParksideKenosha, WI 53141, USAhaller@cs.uic.eduMichael GlassValparaiso UniversityValparaiso, IN, 46383, USAMichael.Glass@valpo.eduAbstractTo improve the interaction between studentsand an intelligent tutoring system, we devel-oped two Natural Language generators, that wesystematically evaluated in a three way com-parison that included the original system aswell.
We found that the generator which intu-itively produces the best language does engen-der the most learning.
Specifically, it appearsthat functional aggregation is responsible forthe improvement.1 IntroductionThe work we present in this paper addresses threeissues: evaluation of Natural Language Generation(NLG) systems, the place of aggregation in NLG,and NL interfaces for Intelligent Tutoring Systems.NLG systems have been evaluated in variousways, such as via task efficacy measures, i.e., mea-suring how well the users of the system perform onthe task at hand (Young, 1999; Carenini and Moore,2000; Reiter et al, 2003).
We also employed taskefficacy, as we evaluated the learning that occursin students interacting with an Intelligent TutoringSystem (ITS) enhanced with NLG capabilities.
Wefocused on sentence planning, and specifically, onaggregation.
We developed two different feedbackgeneration engines, that we systematically evaluatedin a three way comparison that included the orig-inal system as well.
Our work is novel for NLGevaluation in that we focus on one specific com-ponent of the NLG process, aggregation.
Aggrega-tion pertains to combining two or more of the mes-sages to be communicated into one sentence (Reiterand Dale, 2000).
Whereas it is considered an es-sential task of an NLG system, its specific contri-butions to the effectiveness of the text that is even-tually produced have rarely been assessed (Harveyand Carberry, 1998).
We found that syntactic aggre-gation does not improve learning, but that what wecall functional aggregation does.
Further, we ran acontrolled data collection in order to provide a moresolid empirical base for aggregation rules than whatis normally found in the literature, e.g.
(Dalianis,1996; Shaw, 2002).As regards NL interfaces for ITSs, research on thenext generation of ITSs (Evens et al, 1993; Litmanet al, 2004; Graesser et al, 2005) explores NL asone of the keys to bridging the gap between cur-rent ITSs and human tutors.
However, it is still notknown whether the NL interaction between studentsand an ITS does in fact improve learning.
We areamong the first to show that this is the case.We will first discuss DIAG, the ITS shell we areusing, and the two feedback generators that we de-veloped, DIAG-NLP1and DIAG-NLP2 .
Since thelatter is based on a corpus study, we will briefly de-scribe that as well.
We will then discuss the formalevaluation we conducted and our results.2 Natural Language Generation for DIAGDIAG (Towne, 1997) is a shell to build ITSs basedon interactive graphical models that teach students totroubleshoot complex systems such as home heatingand circuitry.
A DIAG application presents a studentwith a series of troubleshooting problems of increas-ing difficulty.
The student tests indicators and triesto infer which faulty part (RU) may cause the abnor-mal states detected via the indicator readings.
RUstands for replaceable unit, because the only courseof action for the student to fix the problem is to re-place faulty components in the graphical simulation.50Figure 1: The furnace systemFig.
1 shows the furnace, one subsystem of the homeheating system in our DIAG application.
Fig.
1 in-cludes indicators such as the gauge labeled WaterTemperature, RUs, and complex modules (e.g., theOil Burner) that contain indicators and RUs.
Com-plex components are zoomable.At any point, the student can consult the tutorvia the Consult menu (cf.
the Consult button inFig.
1).
There are two main types of queries: Con-sultInd(icator) and ConsultRU.
ConsultInd queriesare used mainly when an indicator shows an ab-normal reading, to obtain a hint regarding whichRUs may cause the problem.
DIAG discusses theRUs that should be most suspected given the symp-toms the student has already observed.
ConsultRUqueries are mainly used to obtain feedback on the di-agnosis that a certain RU is faulty.
DIAG respondswith an assessment of that diagnosis and providesevidence for it in terms of the symptoms that havebeen observed relative to that RU.The original DIAG system (DIAG-orig) uses verysimple templates to assemble the text to present tothe student.
The top parts of Figs.
2 and 3 show thereplies provided by DIAG-orig to a ConsultInd onthe Visual Combustion Check, and to a ConsultRuon the Water Pump.The highly repetitive feedback by DIAG-origscreams for improvements based on aggregationtechniques.
Our goal in developing DIAG-NLP1and DIAG-NLP2 was to assess whether simple,rapidly deployable NLG techniques would lead tomeasurable improvements in the student?s learning.Thus, in both cases it is still DIAG that performscontent determination, and provides to DIAG-NLP1and DIAG-NLP2 a file in which the facts to be com-municated are written ?
a fact is the basic unit ofinformation that underlies each of the clauses in areply by DIAG-orig .
The only way we altered theinteraction between student and system is the ac-tual language that is presented in the output win-dow.
In DIAG-NLP1 we mostly explored using syn-tactic aggregation to improve the feedback, whereasDIAG-NLP2 is corpus-based and focuses on func-tional aggregation.
In both DIAG-NLP1 and DIAG-NLP2 , we use EXEMPLARS (White and Cald-well, 1998), an object-oriented, rule-based genera-tor.
The rules (called exemplars) are meant to cap-ture an exemplary way of achieving a communica-tive goal in a given context.
EXEMPLARS selectsrules by traversing the exemplar specialization hi-erarchy and evaluating the applicability conditionsassociated with each exemplar.The visual combustion check is igniting which is abnormal(normal is combusting).Oil Nozzle alwaysproduces this abnormality when it fails.Oil Supply Valve alwaysproduces this abnormality when it fails.Oil pump alwaysproduces this abnormality when it fails.Oil Filter alwaysproduces this abnormality when it fails.System Control Module sometimesproduces this abnormality when it fails.Ignitor Assembly neverproduces this abnormality when it fails.Burner Motor alwaysproduces this abnormality when it fails.The visual combustion check indicator is igniting.This is abnormal.Normal is combusting.Within the furnace system,this is sometimes caused ifthe System Control Module has failed.Within the Oil Burnerthis is never caused ifthe Ignitor Assembly has failed.In contrast, this is always caused ifthe Burner Motor, Oil Filter, Oil Pump,Oil Supply Valve, or Oil Nozzle has failed.The combustion is abnormal.In the oil burner, check the units along the path of the oil andthe burner motor.Figure 2: Answers to ConsultInd by DIAG-orig ,DIAG-NLP1and DIAG-NLP251Water pump is a very poor suspect.Some symptoms you have seen conflict with that theory.Water pump sound was normal.This normal indication never results when this unit fails.Visual combustion check was igniting.This abnormal indication never results when this unit fails.Burner Motor RMP Gauge was 525.This normal indication never results when this unit fails.The Water pump is a very poor suspect.Some symptoms you have seen conflict with that theory.The following indicators never display normallywhen this unit fails.Within the furnace system,the Burner Motor RMP Gauge is 525.Within the water pump and safety cutoff valve,the water pump sound indicator is normal.The following indicators never display abnormallywhen this unit fails.Within the fire door sight hole,the visual combustion check indicator is igniting.The water pump is a poor suspect since the water pumpsound is ok.You have seen that the combustion is abnormal.Check the units along the path of the oil and the electricaldevices.Figure 3: Answers to ConsultRu by DIAG-orig ,DIAG-NLP1 and DIAG-NLP22.1 DIAG-NLP1 : Syntactic aggregationDIAG-NLP1 1 (i) introduces syntactic aggregation(Dalianis, 1996; Huang and Fiedler, 1996; Reapeand Mellish, 1998; Shaw, 2002) and what we callstructural aggregation, namely, grouping parts ac-cording to the structure of the system; (ii) gener-ates some referring expressions; (iii) models a fewrhetorical relations; and (iv) improves the format ofthe output.The middle parts of Figs.
2 and 3 show the revisedoutput produced by DIAG-NLP1 .
E.g., in Fig.
2 theRUs of interest are grouped by the system modulesthat contain them (Oil Burner and Furnace System),and by the likelihood that a certain RU causes theobserved symptoms.
In contrast to the original an-swer, the revised answer highlights that the IgnitorAssembly cannot cause the symptom.In DIAG-NLP1 , EXEMPLARS accesses theSNePS Knowledge Representation and ReasoningSystem (Shapiro, 2000) for static domain informa-tion.2 SNePS makes it easy to recognize structural1DIAG-NLP1 actually augments and refines the first feed-back generator we created for DIAG, DIAG-NLP0 (Di Eugenioet al, 2002).
DIAG-NLP0 only covered (i) and (iv).2In DIAG, domain knowledge is hidden and hardly acces-similarities and use shared structures.
Using SNePS,we can examine the dimensional structure of an ag-gregation and its values to give preference to aggre-gations with top-level dimensions that have fewervalues, to give summary statements when a dimen-sion has many values that are reported on, and tointroduce simple text structuring in terms of rhetor-ical relations, inserting relations like contrast andconcession to highlight distinctions between dimen-sional values (see Fig.
2, middle).DIAG-NLP1 uses the GNOME algorithm (Kib-ble and Power, 2000) to generate referential expres-sions.
Importantly, using SNePS propositions canbe treated as discourse entities, added to the dis-course model and referred to (see This is ... causedif ... in Fig.
2, middle).
Information about lexicalrealization, and choice of referring expression is en-coded in the appropriate exemplars.2.2 DIAG-NLP2 : functional aggregationIn the interest of rapid prototyping, DIAG-NLP1was implemented without the benefit of a corpusstudy.
DIAG-NLP2 is the empirically groundedversion of the feedback generator.
We collected23 tutoring interactions between a student using theDIAG tutor on home heating and two human tutors,for a total of 272 tutor turns, of which 235 in re-ply to ConsultRU and 37 in reply to ConsultInd (thetype of student query is automatically logged).
Thetutor and the student are in different rooms, sharingimages of the same DIAG tutoring screen.
Whenthe student consults DIAG, the tutor sees, in tabularform, the information that DIAG would use in gen-erating its advice ?
the same ?fact file?
that DIAGgives to DIAG-NLP1and DIAG-NLP2?
and typesa response that substitutes for DIAG?s.
The tutor ispresented with this information because we wantedto uncover empirical evidence for aggregation rulesin our domain.
Although we cannot constrain the tu-tor to mention only the facts that DIAG would havecommunicated, we can analyze how the tutor usesthe information provided by DIAG.We developed a coding scheme (Glass et al,2002) and annotated the data.
As the annotation wasperformed by a single coder, we lack measures ofintercoder reliability.
Thus, what follows should betaken as observations rather than as rigorous find-ings ?
useful observations they clearly are, sincesible.
Thus, in both DIAG-NLP1 and DIAG-NLP2 we had tobuild a small knowledge base that contains domain knowledge.52DIAG-NLP2 is based on these observations and itslanguage fosters the most learning.Our coding scheme focuses on four areas.
Fig.
4shows examples of some of the tags (the SCM is theSystem Control Module).
Each tag has from one tofive additional attributes (not shown) that need to beannotated too.Domain ontology.
We tag objects in the domainwith their class indicator, RU and their states, de-noted by indication and operationality, respectively.Tutoring actions.
They include (i) Judgment.
Thetutor evaluates what the student did.
(ii) Problemsolving.
The tutor suggests the next course of ac-tion.
(iii) The tutor imparts Domain Knowledge.Aggregation.
Objects may be functional aggre-gates, such as the oil burner, which is a system com-ponent that includes other components; linguisticaggregates, which include plurals and conjunctions;or a summary over several unspecified indicators orRUs.
Functional/linguistic aggregate and summarytags often co-occur, as shown in Fig.
4.Relation to DIAG?s output.
Contrary to all othertags, in this case we annotate the input that DIAGgave the tutor.
We tag its portions as included / ex-cluded / contradicted, according to how it has beendealt with by the tutor.Tutors provide explicit problem solving directionsin 73% of the replies, and evaluate the student?s ac-tion in 45% of the replies (clearly, they do both in28% of the replies, as in Fig.
4).
As expected, theyare much more concise than DIAG, e.g., they nevermention RUs that cannot or are not as likely to causea certain problem, such as, respectively, the ignitorassembly and the SCM in Fig.
2.As regards aggregation, 101 out of 551 RUs, i.e.18%, are labelled as summary; 38 out of 193 indica-tors, i.e.
20%, are labelled as summary.
These per-centages, though seemingly low, represent a consid-erable amount of aggregation, since in our domainsome items have very little in common with others,and hence cannot be aggregated.
Further, tutors ag-gregate parts functionally rather than syntactically.For example, the same assemblage of parts, i.e., oilnozzle, supply valve, pump, filter, etc., can be de-scribed as the other items on the fuel line or as thepath of the oil flow.Finally, directness ?
an attribute on the indica-tor tag ?
encodes whether the tutor explicitly talksabout the indicator (e.g., The water temperaturegauge reading is low), or implicitly via the objectto which the indicator refers (e.g., the water is toocold).
110 out of 193 indicators, i.e.
57%, aremarked as implicit, 45, i.e.
41%, as explicit, and 2%are not marked for directness (the coder was free toleave attributes unmarked).
This, and the 137 occur-rences of indication, prompted us to refer to objectsand their states, rather than to indicators (as imple-mented by Steps 2 in Fig.
5, and 2(b)i, 3(b)i, 3(c)i inFig.
6, which generate The combustion is abnormaland The water pump sound is OK in Figs.
2 and 3).2.3 Feedback Generation in DIAG-NLP2In DIAG-NLP1 the fact file provided by DIAG isdirectly processed by EXEMPLARS.
In contrast, inDIAG-NLP2 a planning module manipulates the in-formation before passing it to EXEMPLARS.
Thismodule decides which information to include ac-cording to the type of query the system is respond-ing to, and produces one or more Sentence Structureobjects.
These are then passed to EXEMPLARSthat transforms them into Deep Syntactic Structures.Then, a sentence realizer, RealPro (Lavoie and Ram-bow, 1997), transforms them into English sentences.Figs.
5 and 6 show the control flow in DIAG-NLP2 for feedback generation for ConsultInd andConsultRU.
Step 3a in Fig.
5 chooses, among allthe RUs that DIAG would talk about, only thosethat would definitely result in the observed symp-tom.
Step 2 in the AGGREGATE procedure in Fig.
5uses a simple heuristic to decide whether and how touse functional aggregation.
For each RU, its possi-ble aggregators and the number n of units it coversare listed in a table (e.g., electrical devices covers4 RUs, ignitor, photoelectric cell, transformer andburner motor).
If a group of REL-RUs contains kunits that a certain aggregator Agg covers, if k < n2 ,Agg will not be used; if n2 ?
k < n, Agg precededby some of will be used; if k = n, Agg will be used.DIAG-NLP2 does not use SNePS, but a relationaldatabase storing relations, such as the ISA hierarchy(e.g., burner motor IS-A RU), information about ref-erents of indicators (e.g., room temperature gaugeREFERS-TO room), and correlations between RUsand the indicators they affect.3 EvaluationOur empirical evaluation is a three group, between-subject study: one group interacts with DIAG-orig ,53[judgment [replaceable?unit the ignitor] is a poor suspect] since [indication combustion is working] during startup.
The problem isthat the SCM is shutting the system off during heating.
[domain?knowledge The SCM reads [summary [linguistic?aggregate input signals from sensors]] and uses the signals to determinehow to control the system.
][problem?solving Check the sensors.
]Figure 4: Examples of a coded tutor reply1.
IND?
queried indicator2.
Mention the referent of IND and its state3.
IF IND reads abnormal,(a) REL-RUs?
choose relevant RUs(b) AGGR-RUs?
AGGREGATE(REL-RUs)(c) Suggest to check AGGR-RUsAGGREGATE(RUs)1.
Partition REL-RUs into subsets by system structure2.
Apply functional aggregation to subsetsFigure 5: DIAG-NLP2 : Feedback generation forConsultIndone with DIAG-NLP1 , one with DIAG-NLP2 .
The75 subjects (25 per group) were all science or engi-neering majors affiliated with our university.
Eachsubject read some short material about home heat-ing, went through one trial problem, then continuedthrough the curriculum on his/her own.
The curricu-lum consisted of three problems of increasing dif-ficulty.
As there was no time limit, every studentsolved every problem.
Reading materials and cur-riculum were identical in the three conditions.While a subject was interacting with the system,a log was collected including, for each problem:whether the problem was solved; total time, and timespent reading feedback; how many and which in-dicators and RUs the subject consults DIAG about;how many, and which RUs the subject replaces.
Wewill refer to all the measures that were automaticallycollected as performance measures.At the end of the experiment, each subject was ad-ministered a questionnaire divided into three parts.The first part (the posttest) consists of three ques-tions and tests what the student learned about thedomain.
The second part concerns whether subjectsremember their actions, specifically, the RUs theyreplaced.
We quantify the subjects?
recollections interms of precision and recall with respect to the logthat the system collects.
We expect precision and re-call of the replaced RUs to correlate with transfer,namely, to predict how well a subject is able to ap-ply what s/he learnt about diagnosing malfunctions1.
RU?
queried RUREL-IND?
indicator associated to RU2.
IF RU warrants suspicion,(a) state RU is a suspect(b) IF student knows that REL-IND is abnormali.
remind him of referent of REL-IND andits abnormal stateii.
suggest to replace RU(c) ELSE suggest to check REL-IND3.
ELSE(a) state RU is not a suspect(b) IF student knows that REL-IND is normali.
use referent of REL-IND and its normal stateto justify judgment(c) IF student knows of abnormal indicators OTHER-INDsi.
remind him of referents of OTHER-INDsand their abnormal statesii.
FOR each OTHER-INDA.
REL-RUs?
RUs associated with OTHER-INDB.
AGGR-RUs?
AGGREGATE(REL-RUs)?
AGGR-RUsiii.
Suggest to check AGGR-RUsFigure 6: DIAG-NLP2 : Feedback generation forConsultRUto new problems.
The third part concerns usability,to be discussed below.We found that subjects who used DIAG-NLP2had significantly higher scores on the posttest, andwere significantly more correct (higher precision)in remembering what they did.
As regards perfor-mance measures, there are no so clear cut results.As regards usability, subjects prefer DIAG-NLP1 /2to DIAG-orig , however results are mixed as regardswhich of the two they actually prefer.In the tables that follow, boldface indicates sig-nificant differences, as determined by an analysis ofvariance performed via ANOVA, followed by post-hoc Tukey tests.Table 1 reports learning measures, average acrossthe three problems.
DIAG-NLP2 is significantlybetter as regards PostTest score (F = 10.359, p =0.000), and RU Precision (F = 4.719, p =0.012).
Performance on individual questions in the54DIAG-orig DIAG-NLP1 DIAG-NLP2PostTest 0.72 0.69 0.90RU Precision 0.78 0.70 0.91RU Recall .53 .47 .40Table 1: Learning ScoresFigure 7: Scores on PostTest questionsPostTest3 is illustrated in Fig.
7.
Scores in DIAG-NLP2 are always higher, significantly so on ques-tions 2 and 3 (F = 8.481, p = 0.000, and F =7.909, p = 0.001), and marginally so on question 1(F = 2.774, p = 0.069).4D-Orig D-NLP1 D-NLP2Total Time 30?17?
28?34?
34?53?RU Replacements 8.88 11.12 11.36ConsultInd 22.16 6.92 28.16Avg.
Reading Time 8?
14?
2?ConsultRU 63.52 45.68 52.12Avg.
Reading Time 5?
4?
5?Table 2: Performance MeasuresTable 2 reports performance measures, cumula-tive across the three problems, other than averagereading times.
Subjects don?t differ significantly inthe time they spend solving the problems, or in thenumber of RU replacements they perform.
DIAG?sassumption (known to the subjects) is that there isonly one broken RU per problem, but the simula-tion allows subjects to replace as many as they wantwithout any penalty before they come to the correctsolution.
The trend on RU replacements is oppositewhat we would have hoped for: when repairing areal system, replacing parts that are working shouldclearly be kept to a minimum, and subjects replace3The three questions are: 1.
Describe the main subsystemsof the furnace.
2.
What is the purpose of (a) the oil pump (b)the system control module?
3.
Assume the photoelectric cell iscovered with enough soot that it could not detect combustion.What impact would this have on the system?4The PostTest was scored by one of the authors, followingwritten guidelines.fewer parts in DIAG-orig .The next four entries in Table 2 report the numberof queries that subjects ask, and the average time ittakes subjects to read the feedback.
The subjectsask significantly fewer ConsultInd in DIAG-NLP1(F = 8.905, p = 0.000), and take significantly lesstime reading ConsultInd feedback in DIAG-NLP2(F = 15.266, p = 0.000).
The latter result isnot surprising, since the feedback in DIAG-NLP2 ismuch shorter than in DIAG-orig and DIAG-NLP1 .Neither the reason not the significance of subjectsasking many fewer ConsultInd of DIAG-NLP1 areapparent to us ?
it happens for ConsultRU as well,to a lesser, not significant degree.We also collected usability measures.
Althoughthese are not usually reported in ITS evaluations,in a real setting students should be more willing tosit down with a system that they perceive as morefriendly and usable.
Subjects rate the system alongfour dimensions on a five point scale: clarity, useful-ness, repetitiveness, and whether it ever misled them(the scale is appropriately arranged: the highest clar-ity but the lowest repetitiveness receive 5 points).There are no significant differences on individualdimensions.
Cumulatively, DIAG-NLP2 (at 15.08)slightly outperforms the other two (DIAG-orig at14.68 and DIAG-NLP1 at 14.32), however, the dif-ference is not significant (highest possible rating is20 points).prefer neutral dispreferDIAG-NLP1 to DIAG-orig 28 5 17DIAG-NLP2 to DIAG-orig 34 1 15DIAG-NLP2 to DIAG-NLP1 24 1 25Table 3: User preferences among the three systemsprefer neutral dispreferConsult Ind.
8 1 16Consult RU 16 0 9Table 4: DIAG-NLP2 versus DIAG-NLP1natural concise clear contentfulDIAG-NLP1 4 8 10 23DIAG-NLP2 16 8 11 12Table 5: Reasons for system preferenceFinally,5 on paper, subjects compare two pairs ofversions of feedback: in each pair, the first feedback5Subjects can also add free-form comments.
Only few did55is generated by the system they just worked with,the second is generated by one of the other two sys-tems.
Subjects say which version they prefer, andwhy (they can judge the system along one or moreof four dimensions: natural, concise, clear, content-ful).
The first two lines in Table 3 show that subjectsprefer the NLP systems to DIAG-orig (marginallysignificant, ?2 = 9.49, p < 0.1).
DIAG-NLP1and DIAG-NLP2 receive the same number of pref-erences; however, a more detailed analysis (Table 4)shows that subjects prefer DIAG-NLP1 for feed-back to ConsultInd, but DIAG-NLP2 for feedbackto ConsultRu (marginally significant, ?2 = 5.6, p <0.1).
Finally, subjects find DIAG-NLP2 more nat-ural, but DIAG-NLP1 more contentful (Table 5,?2 = 10.66, p < 0.025).4 Discussion and conclusionsOur work touches on three issues: aggregation, eval-uation of NLG systems, and the role of NL inter-faces for ITSs.In much work on aggregation (Huang and Fiedler,1996; Horacek, 2002), aggregation rules and heuris-tics are shown to be plausible, but are not based onany hard evidence.
Even where corpus work is used(Dalianis, 1996; Harvey and Carberry, 1998; Shaw,2002), the results are not completely convincing be-cause we do not know for certain the content to becommunicated from which these texts supposedlyhave been aggregated.
Therefore, positing empir-ically based rules is guesswork at best.
Our datacollection attempts at providing a more solid em-pirical base for aggregation rules; we found that tu-tors exclude significant amounts of factual informa-tion, and use high degrees of aggregation based onfunctionality.
As a consequence, while part of ourrules implement standard types of aggregation, suchas conjunction via shared participants, we also intro-duced functional aggregation (see conceptual aggre-gation (Reape and Mellish, 1998)).As regards evaluation, NLG systems have beenevaluated e.g.
by using human judges to assess thequality of the texts produced (Coch, 1996; Lesterand Porter, 1997; Harvey and Carberry, 1998); bycomparing the system?s performance to that of hu-mans (Yeh and Mellish, 1997); or through task ef-ficacy measures, i.e., measuring how well the usersso, and the distribution of topics and of evaluations is too broadto be telling.of the system perform on the task at hand (Young,1999; Carenini and Moore, 2000; Reiter et al,2003).
The latter kind of studies generally contrastdifferent interventions, i.e.
a baseline that does notuse NLG and one or more variations obtained by pa-rameterizing the NLG system.
However, the evalu-ation does not focus on a specific component of theNLG process, as we did here for aggregation.Regarding the role of NL interfaces for ITSs, onlyvery recently have the first few results become avail-able, to show that first of all, students do learn wheninteracting in NL with an ITS (Litman et al, 2004;Graesser et al, 2005).
However, there are very fewstudies like ours, that evaluate specific features ofthe NL interaction, e.g.
see (Litman et al, 2004).
Inour case, we did find that different features of the NLfeedback impact learning.
Although we contend thatthis effect is due to functional aggregation, the feed-back in DIAG-NLP2 changed along other dimen-sions, mainly using referents of indicators instead ofindicators, and being more strongly directive in sug-gesting what to do next.
Of course, we cannot ar-gue that our best NL generator is equivalent to a hu-man tutor ?
e.g., dividing the number of ConsultRUand ConsultInd reported in Sec.
2.2 by the numberof dialogues shows that students ask about 10 Con-sultRus and 1.5 ConsultInd per dialogue when in-teracting with a human, many fewer than those theypose to the ITSs (cf.
Table 2) (regrettably we did notadminister a PostTest to students in the human datacollection).
We further discuss the implications ofour results for NL interfaces for ITSs in a compan-ion paper (Di Eugenio et al, 2005).The DIAG project has come to a close.
We aresatisfied that we demonstrated that even not overlysophisticated NL feedback can make a difference;however, the fact that DIAG-NLP2 has the best lan-guage and engenders the most learning prompts usto explore more complex language interactions.
Weare pursuing new exciting directions in a new do-main, that of basic data structures and algorithms.We are investigating what distinguishes expert fromnovice tutors, and we will implement our findingsin an ITS that tutors in this domain.Acknowledgments.
This work is supported by the Officeof Naval Research (awards N00014-99-1-0930 and N00014-00-1-0640), and in part by the National Science Foundation (awardIIS 0133123).
We are grateful to CoGenTex Inc. for makingEXEMPLARS and RealPro available to us.56ReferencesGiuseppe Carenini and Johanna D. Moore.
2000.
An em-pirical study of the influence of argument concisenesson argument effectiveness.
In Proceedings of the 38thAnnual Meeting of the Association for ComputationalLinguistics, Hong Kong.Jose?
Coch.
1996.
Evaluating and comparing three text-production techniques.
In COLING96, Proceedings ofthe Sixteenth International Conference on Computa-tional Linguistics, pages 249?254Hercules Dalianis.
1996.
Concise Natural LanguageGeneration from Formal Specifications.
Ph.D. thesis,Department of Computer and Systems Science, Sto-cholm University.
Technical Report 96-008.Barbara Di Eugenio, Michael Glass, and Michael J. Tro-lio.
2002.
The DIAG experiments: Natural Lan-guage Generation for Intelligent Tutoring Systems.
InINLG02, The Third International Natural LanguageGeneration Conference, pages 120?127.Barbara Di Eugenio, Davide Fossati, Dan Yu, SusanHaller, and Michael Glass.
2005.
Natural languagegeneration for intelligent tutoring systems: a casestudy.
In AIED 2005, the 12th International Confer-ence on Artificial Intelligence in Education.M.
W. Evens, J. Spitkovsky, P. Boyle, J.
A. Michael, andA.
A. Rovick.
1993.
Synthesizing tutorial dialogues.In Proceedings of the Fifteenth Annual Conference ofthe Cognitive Science Society, pages 137?140.Michael Glass, Heena Raval, Barbara Di Eugenio, andMaarika Traat.
2002.
The DIAG-NLP dialogues: cod-ing manual.
Technical Report UIC-CS 02-03, Univer-sity of Illinois - Chicago.A.C.
Graesser, N. Person, Z. Lu, M.G.
Jeon, and B. Mc-Daniel.
2005.
Learning while holding a conversationwith a computer.
In L. PytlikZillig, M. Bodvarsson,and R. Brunin, editors, Technology-based education:Bringing researchers and practitioners together.
Infor-mation Age Publishing.Terrence Harvey and Sandra Carberry.
1998.
Inte-grating text plans for conciseness and coherence.
InACL/COLING 98, Proceedings of the 36th AnnualMeeting of the Association for Computational Linguis-tics, pages 512?518.Helmut Horacek.
2002.
Aggregation with strong regu-larities and alternatives.
In International Conferenceon Natural Language Generation.Xiaoron Huang and Armin Fiedler.
1996.
Paraphrasingand aggregating argumentative text using text struc-ture.
In Proceedings of the 8th International Workshopon Natural Language Generation, pages 21?30.Rodger Kibble and Richard Power.
2000.
Nominal gen-eration in GNOME and ICONOCLAST.
Technical re-port, Information Technology Research Institute, Uni-versity of Brighton, Brighton, UK.Beno?
?t Lavoie and Owen Rambow.
1997.
A fast andportable realizer for text generation systems.
In Pro-ceedings of the Fifth Conference on Applied NaturalLanguage Processing.James C. Lester and Bruce W. Porter.
1997.
Developingand empirically evaluating robust explanation genera-tors: the KNIGHT experiments.
Computational Lin-guistics, 23(1):65?102.D.
J. Litman, C. P.
Rose?, K. Forbes-Riley, K. VanLehn,D.
Bhembe, and S. Silliman.
2004.
Spoken versustyped human and computer dialogue tutoring.
In Pro-ceedings of the Seventh International Conference onIntelligent Tutoring Systems, Maceio, Brazil.Mike Reape and Chris Mellish.
1998.
Just what is ag-gregation anyway?
In Proceedings of the EuropeanWorkshop on Natural Language Generation.Ehud Reiter and Robert Dale.
2000.
Building Natu-ral Language Generation Systems.
Studies in NaturalLanguage Processing.
Cambridge University Press.Ehud Reiter, Roma Robertson, and Liesl Osman.
2003.Lessons from a failure: Generating tailored smokingcessation letters.
Artificial Intelligence, 144:41?58.S.
C. Shapiro.
2000.
SNePS: A logic for natural lan-guage understanding and commonsense reasoning.
InL.
M. Iwanska and S. C. Shapiro, editors, NaturalLanguage Processing and Knowledge Representation.AAAI Press/MIT Press.James Shaw.
2002.
A corpus-based analysis for the or-dering of clause aggregation operators.
In COLING02,Proceedings of the 19th International Conference onComputational Linguistics.Douglas M. Towne.
1997.
Approximate reasoning tech-niques for intelligent diagnostic instruction.
Interna-tional Journal of Artificial Intelligence in Education.Michael White and Ted Caldwell.
1998.
Exemplars: Apractical, extensible framework for dynamic text gen-eration.
In Proceedings of the Ninth InternationalWorkshop on Natural Language Generation, pages266?275, Niagara-on-the-Lake, Canada.Ching-Long Yeh and Chris Mellish.
1997.
An empir-ical study on the generation of anaphora in Chinese.Computational Linguistics, 23(1):169?190.R.
Michael Young.
1999.
Using Grice?s maxim of quan-tity to select the content of plan descriptions.
ArtificialIntelligence, 115:215?256.57
