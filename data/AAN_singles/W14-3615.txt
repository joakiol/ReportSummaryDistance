Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 121?126,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsArabic Spelling Correction using Supervised LearningYoussef HassanDept Computer EngineeringCairo UniversityGiza, Egyptyoussefhassan13@gmail.comMohamed AlyDept Computer EngineeringCairo UniversityGiza, Egyptmohamed@mohamedaly.infoAmir AtiyaDept Computer EngineeringCairo UniversityGiza, Egyptamir@alumni.caltech.eduAbstractIn this work, we address the problemof spelling correction in the Arabic lan-guage utilizing the new corpus providedby QALB (Qatar Arabic Language Bank)project which is an annotated corpus ofsentences with errors and their corrections.The corpus contains edit, add before, split,merge, add after, move and other errortypes.
We are concerned with the first fourerror types as they contribute more than90% of the spelling errors in the corpus.The proposed system has many models toaddress each error type on its own and thenintegrating all the models to provide anefficient and robust system that achievesan overall recall of 0.59, precision of 0.58and F1 score of 0.58 including all the errortypes on the development set.
Our systemparticipated in the QALB 2014 shared task?Automatic Arabic Error Correction?
andachieved an F1 score of 0.6, earning thesixth place out of nine participants.1 IntroductionThe Arabic language is a highly inflected naturallanguage that has an enormous number of possi-ble words (Othman et al., 2003).
And although itis the native language of over 300 million people,it suffers from the lack of useful resources as op-posed to other languages, specially English anduntil now there are no systems that cover the widerange of possible spelling errors.
Fortunately theQALB corpus (Zaghouani et al., 2014) will helpenrich the resources for Arabic language generallyand the spelling correction specifically by provid-ing an annotated corpus with corrected sentencesfrom user comments, native student essays, non-native data and machine translation data.
In thiswork, we are trying to use this corpus to build anerror correction system that can cover a range ofspelling errors.This paper is a system description paper that issubmitted in the EMNLP 2014 conference sharedtask ?Automatic Arabic Error Correction?
(Mohitet al., 2014) in the Arabic NLP workshop.
Thechallenges that faced us while working on this sys-tem was the shortage of contribution in the areaof spelling correction in the Arabic language.
Buthopefully the papers and the work in this sharedtask specifically and in the workshop generallywill enrich this area and flourish it.Our system targets four types of spelling errors,edit errors, add before errors, merge errors andsplit errors.
For each error type, A model is builtto correct erroneous words detected by the errordetection technique.
Edit errors and add beforeerrors are corrected using classifiers with contex-tual features, while the merge and split errors arecorrected by inserting or omitting a space betweenwords and choosing the best candidate based onthe language model score of each candidate.The rest of this paper is structured as follows.In section 2, we give a brief background on re-lated work in spelling correction.
In section 3, weintroduce our system for spelling correction withthe description of the efficient models used in thesystem.
In section 4, we list some experimental re-sults on the development set.
In section 5, we givesome concluding remarks.2 Related WorkThe work in the field of spelling correction in theArabic language is not yet mature and no sys-tem achieved a great error correction efficiency.Even Microsoft Word, the most widely used Ara-bic spelling correction system, does not achievegood results.
Our work was inspired by a num-ber of papers.
(Shaalan et al., 2012) addressedthe problem of Arabic Word Generation for spellchecking and they produced an open source and121large coverage word list for Arabic containing 9million fully inflected surface words and appliedlanguage models and Noisy Channel Model andknowledge-based rules for error correction.
Thisword list is used in our work besides using lan-guage models and Noisy Channel Model.
(Shaalan et al., 2010) proposed another sys-tem for cases in which the candidate genera-tion using edit algorithm only was not enough,in which candidates were generated based ontransformation rules and errors are detected usingBAMA (Buckwalter Arabic Morphological Ana-lyzer)(Buckwalter, 2002).
(Khalifa et al., 2011) proposed a system for textsegmentation.
The system discriminates betweenwaw wasl and waw fasl, and depending on thisit can predict if the sentence to be segmented atthis position or not, they claim that they achieved97.95% accuracy.
The features used in this workinspired us with the add before errors correction.
(Schaback, 2007) proposed a system for the En-glish spelling correction, that is addressing the editerrors on various levels: on the phonetic level us-ing Soundex algorithm, on the character level us-ing edit algorithm with one operation away, on theword level using bigram language model, on thesyntactic level using collocation model to deter-mine how fit the candidate is in this position andon the semantic level using co-occurrence modelto determine how likely a candidate occurs withinthe given context, using all the models output ofcandidate word as features and using SVM modelto classify the candidates, they claim reaching re-call ranging from 90% for first candidate and 97%for all five candidates presented and outperform-ing MS Word, Aspell, Hunspell, FST and Google.3 Proposed SystemWe propose a system for detecting and correct-ing various spelling errors, including edit, split,merge, and add before errors.
The system consistsof two steps: error detection and error correction.Each word is tested for correctness.
If the wordis deemed incorrect, it is passed to the correctionstep, otherwise it remains unchanged.
The correc-tion step contains specific handling for each typeof error, as detailed in subsection 3.3.3.1 ResourcesDictionary: Arabic wordlist for spell checking1is a free dictionary containing 9 million Ara-bic words.
The words are automatically generatedfrom the AraComLex2open-source finite statetransducer.The dictionary is used in the generationof candidates and using a special version ofMADAMIRA3(Pasha et al., 2014) created for theQALB shared task using a morphological databasebased on BAMA 1.2.14(Buckwalter, 2002).
Fea-tures are extracted for each word of the dictionaryto help in the proposed system in order that eachcandidate has features just like the words in thecorpus.Stoplist: Using stop words list available onsourceforge.net5.
This is used in the collocationalgorithm described later.Language Model: We use SRILM (Stolcke,2002) to build a language model using the AjdirCorpora6as a corpus with the vocabulary fromthe dictionary stated above.
We train a languagemodel containing unigrams, bigrams, and trigramsusing modified Kneser-Ney smoothing (James,2000).QALB Corpus: QALB shared task offers anew corpus for spelling correction.
The corpuscontains a large dataset of manually corrected Ara-bic sentences.
Using this corpus, we were ableto implement a spelling correction system thattargets the most frequently occurring error typeswhich are (a) edit errors where a word is replacedby another word, (b) add before errors wherea word was removed, (c) merge errors where aspace was inserted mistakenly and finally (d) spliterrors where a space was removed mistakenly.The corpus provided also has three other errortypes but they occur much less frequently happenwhich are (e) add after errors which is like theadd before but the token removed should be put af-ter the word, (f) move errors where a word shouldbe moved to other place within the sentence and(g) other errors where any other error that does1http://sourceforge.net/projects/arabic-wordlist/2http://aracomlex.sourceforge.net/3MADAMIRA-release-20140702-1.04AraMorph 1.2.1 - http://sourceforge.net/projects/aramorph/5http://sourceforge.net/projects/arabicstopwords/6http://aracorpus.e3rab.com/argistestsrv.nmsu.edu/AraCorpus/122not lie in the six others is labeled by it.3.2 Error DetectionThe training set, development set and test set pro-vided by QALB project come with the ?columnsfile?
and contains very helpful features generatedby MADAMIRA.
Using the Buckwalter morpho-logical analysis (Buckwalter, 2002) feature, wedetermine if a word is correct or not.
If the wordhas no analysis, we consider the word as incorrectand pass it through the correction process.3.3 Edit Errors CorrectionThe edit errors has the highest portion of total er-rors in the corpus.
It amounts to more than 55% ofthe total errors.
To correct this type of errors, wetrain a classifier with features like the error modelprobability, collocation and co-occurrence as fol-lows:Undiacriticized word preprocessed: Utilizingthe MADAMIRA features of each word, the undi-acriticized word fixes some errors like hamzas, thepair of haa and taa marboutah and the pair of yaaand alif maqsoura.We apply some preprocessing on the undiacrit-icized word to make it more useful and fix the is-sues associated with it.
For example we removethe incorrect redundant characters from the worde.g (?
@@ @ Ag.Q?
@ ?
?Ag.Q?
@, AlrjAAAAl ?
AlrjAl).We also replace the Roman punctuation marks bythe Arabic ones e.g (?
?
?
).Language Model: For each candidate, A un-igram, bigram and trigram values from the lan-guage model trained are retrieved.
In addition to afeature that is the product of the unigram, bigramand trigram values.Likelihood Model: The likelihood model istrained by iterating over the training sentencescounting the occurrences of each edit with thecharacters being edited and the type of edit.
Theoutput of this is called a confusion matrix.The candidate score is based on the NoisyChannel Model (Kernighan et al., 1990) which isthe multiplication of probabilty of the proposededit using the confusion matrix trained which iscalled the error model, and the language modelscore of that word.
The language model used isunigram, bigram and trigram with equal weights.Add-1 smoothing is used for both models in thecounts.Score = p(x|w).p(w)where x is the wrong word and w is the candidatecorrection.For substitution edit candidates, we give higherscore for substitution of a character that is close onthe keyboard or the substitution pair belongs to thesame group of letter groups (Shaalan et al., 2012)by multiplying the score by a constant greater thanone.,(h., h , p) ,(H.,H ,H ,?
, ?)
,(@ ,@ , @,@),(?
,?)
,(?
,?)
,(?
,?)
,(P ,P) ,(X ,X).
(?, ?)
,(?
,?)
,( ?
,?)
,(?
,?)
,(?
,?
)(|, < , >, A), (y, n, v, t, b), (x, H, j), (*, d), (z, r),($, s), (D, S), (Z, T), (g, E), (q, f), (p h), (&, w),(Y, y)For each candidate , the likelihood score is com-puted and added to the feature vector of the candi-date.Collocation: The collocation model targets thelikelihood of the candidate inside the sentence.This is done using the lemma of the word and thePOS tags of words in the sentence.We use the algorithm in (Schaback, 2007) fortraining the collocation model.
Specifically, by re-trieving the 5,000 most occurring lemmas in thetraining corpus and put it in list L. For each lemmain L, three lists are created, each record in the listis a sequence of three POS tags around the targetlemma.
For training, we shift a window of threePOS tags over the training sentence.
If a lemmabelongs to L, we add the surrounding POS tags tothe equivalent list of the target lemma dependingon the position of the target lemma within the threePOS tags.Given a misspelled word in a sentence, for eachcandidate correction, if it is in the L list, we countthe number of occurrences of the surrounding POStags in each list of the three depending on the po-sition of of the candidate.The three likelihoods are stored in the featurevector of the candidate in addition to the productof them.Co-occurrence: Co-occurrence is used to mea-sure how likely a word fits inside a context.
WhereL is the same list of most frequent lemmata fromcollocation.We use the co-occurrence algorithm in (Sch-aback, 2007).
Before training the model, we trans-form each word of our training sentence into itslemma form and remove stop-words.
For exam-ple, consider the original text:123A?E@ A??.?J?Am?'@????m?'@?
PA?
?J?B@?K.?Q?BIJkHyv l>frq byn AlAstEmAr wAlHkwmpAlHAlyp bmA >nhAAfter removing stop-words and replacing theremaining words by their lemma form we end upwith:??Ag???
?k PA??J?@?Q?
@>frq AstEmAr Hkwmp HAlywhich forms C.From that C, we get all lemmata that appear inthe radius of 10 words around the target lemmab where b belongs to L. We count the number ofoccurrences of each lemma in that context C.By using the above model, three distances arecalculated for target lemma b: d1, the ratio of ac-tually found context words in C and possibly find-able context words.
This describes how similar thetrained context and the given context are for can-didate b; d2considers how significant the foundcontext lemmata are by summing the normalizedfrequencies of the context lemmata.
As a third fea-ture; d3(b) that simply measures how big the vec-tor space model for lemma b is.For each candidate, the model is applied and thethree distances are calculated and added to the fea-ture vector of that candidate.The Classifier: After generating the candidatecorrections within 1 and 2 edit operations (insert,delete, replace and transpose) distance measuredby Levenshtein distance (Levenshtein, 1966), werun them through a Naive-Bayes classifier usingpython NLTK?s implementation to find out whichone is the most likely to be the correction for theincorrect word.The classifier is trained using the training setprovided by QALB project.
For each edit correc-tion in the training set, all candidates are gener-ated for the incorrect word and a feature vector(as shown in table1) is calculated using the tech-niques aforementioned.
If the candidate is the cor-rect one, the label for the training feature vector iscorrect else it is incorrect.Then using the trained classifier, the same isdone on the development set or the test set wherewe replace the incorrect word with the word sug-gested by the classifier.3.4 Add before Errors CorrectionThe add before errors are mostly punctuation er-rors.
A classifier is trained on the QALB trainingTable 1: The feature set used by the edit errorsclassifier.Feature nameLikelihood model probabilityunigram probabilityprevious bigram probabilitynext bigram probabilitytrigram probabilitylanguage model productcollocation leftcollocation rightcollocation midcollocation productcooccurrence distance 1cooccurrence distance 2cooccurrence distance 3previous genderprevious numbernext gendernext numbercorpus.
A classifier is implemented with contex-tual features C. C is a 4-gram around the token be-ing investigated.
Each word of these four has thetwo features: The token itself and Part-of-speechtag and for the next word only pregloss becauseif the word?s pregloss is ?and?
it is more prob-able that a new sentence began.
Those featuresare available thanks to MADAMIRA features pro-vided with the corpus and the generated for dictio-nary words.The classifier is trained on the QALB trainingset.
We iterate over all the training sentences wordby word and getting the aforementioned features(as shown in table 2) and label the training withthe added before token if there was a matching addbefore correction for this word or the label will bean empty string.For applying the model, the same is done on theQALB development sentences after removing allpunctuations as they are probably not correct andthe output of the classifier is either empty or sug-gested token to add before current word.3.5 Merge Errors CorrectionThe merge errors occurs due to the insertion ofa space between two words by mistake.
The ap-proach is simply trying to attach every word withits successor word and checking if it is a valid124Table 2: The feature set used by the add beforeerrors classifier.Feature namebefore previous wordbefore previous word POS tagprevious wordprevious word POS tagnext wordnext word POS tagnext word preglossafter next wordafter next POS tagArabic word and rank it with the language modelscore.3.6 Split Errors CorrectionThe split errors occurs due to the deletion of aspace between two words.
The approach is sim-ply getting all the valid partitions of the word andtry to correct both partitions and give them a rankusing the language model score.
The partition is atleast two characters long.4 Experimental ResultsIn order to know the contribution of each errortype models to the overall system performance, weadopted an incremental approach of the models.We implemented the system using python7andNLTK8(Loper and Bird, 2002) toolkit.
The mod-els are trained on the QALB corpus training setand the results are obtained by applying the trainedmodels on the development set.
Our goal was toachieve high recall but without losing too muchprecision.
The models were evaluated using M2scorer (Dahlmeier and Ng, 2012).First, we start with only the preprocessed un-diacriticized word, then we added our edit errorclassifier.
Adding the add before classifier was agreat addition to the system as the system was ableto increase the number of corrected errors signif-icantly, notably the add before classifier proposedtoo many incorrect suggestions that decreased theprecision.
Then we added the merging correctiontechnique.
Finally we added the split error cor-rection technique.
The system corrects 9860 errorsversus 16659 golden error corrections and pro-7https://www.python.org/8http://www.nltk.org/posed 17057 correction resulting in the final sys-tem recall of 0.5919, precision of 0.5781 and F1score of 0.5849.
Details are shown in Table 3.Table 3: The incremental results after adding eacherror type model and applying them on the devel-opment set.Model name Recall Precision F1 scoreUndiacriticized 0.32 0.833 0.4715+ Edit 0.3515 0.7930 0.5723+ Add before 0.5476 0.5658 0.5567+ Merge 0.5855 0.5816 0.5836+ Split 0.5919 0.5781 0.5849We tried other combinations of the models byremoving one or more of the components to get thebest results possible.
Noting that all the systemsresults are using the undiacriticized word.
Detailsare shown in Table 4Table 4: The results of some combinations of themodels and applying them on the development set.The models are abbreviated as Edit E, Merge M,Split S, and Add before A.Model name Precision Recall F1 scoreM Only 0.8441 0.3724 0.5167S Only 0.7838 0.338 0.5167A Only 0.6008 0.4887 0.539E Only 0.8143 0.3472 0.4868M & S 0.8121 0.3814 0.5191E & S 0.62 0.3542 0.4508M & E 0.6184 0.5403 0.5767S & M & A 0.6114 0.5396 0.5733M & E & A 0.6186 0.5404 0.5768E & S & A 0.5955 0.507 0.5477E & S & M 0.6477 0.3969 0.4922E & S & M & A 0.5919 0.5781 0.58495 Conclusion and Future WorkWe propose an all-in-one system for error detec-tion and correction.
The system addresses fourtypes of spelling errors (edit, add before, mergeand split errors).
The system achieved promis-ing results by successfully getting corrections forabout 60% of the spelling errors in the develop-ment set.
Also, There is still a big room for im-provements in all types of error correction models.We are planning to improve the current systemby incorporating more intelligent techniques andmodels for split and merge.
Also, the add beforeclassifier needs much work to improve the cov-erage as the errors are mostly missing punctua-tion marks.
For the edit classifier, real-word errorsneed to be addressed.125ReferencesTim Buckwalter.
2002.
Buckwalter arabic morpholog-ical analyzer version 1.0.
November.Daniel Dahlmeier and Hwee Tou Ng.
2012.
Bet-ter evaluation for grammatical error correction.
InProceedings of the 2012 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,NAACL HLT ?12, pages 568?572, Stroudsburg, PA,USA.
Association for Computational Linguistics.Frankie James.
2000.
Modified kneser-ney smoothingof n-gram models.
RIACS.Mark D. Kernighan, Kenneth W. Church, andWilliam A. Gale.
1990.
A spelling correction pro-gram based on a noisy channel model.
In Proceed-ings of the 13th Conference on Computational Lin-guistics - Volume 2, COLING ?90, pages 205?210,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Iraky Khalifa, Zakareya Al Feki, and AbdelfatahFarawila.
2011.
Arabic discourse segmentationbased on rhetorical methods.VI Levenshtein.
1966.
Binary Codes Capable of Cor-recting Deletions, Insertions and Reversals.
vol-ume 10, page 707.Edward Loper and Steven Bird.
2002.
NLTK: TheNatural Language Toolkit.Behrang Mohit, Alla Rozovskaya, Nizar Habash, Wa-jdi Zaghouani, and Ossama Obeid.
2014.
The FirstQALB Shared Task on Automatic Text Correctionfor Arabic.
In Proceedings of EMNLP Workshop onArabic Natural Language Processing, Doha, Qatar,October.Eman Othman, Khaled Shaalan, and Ahmed Rafea.2003.
A chart parser for analyzing modern standardarabic sentence.
In To appear in In proceedings ofthe MT Summit IX Workshop on Machine Transla-tion for Semitic Languages: Issues and Approaches,Louisiana, U.S.A.Pasha, Arfath, Mohamed Al-Badrashiny, Mona Diab,Ahmed El Kholy, Ramy Eskander, Nizar Habash,Manoj Pooleery, Owen Rambow, and Ryan M. Roth.2014.
Madamira: A fast, comprehensive tool formorphological analysis and disambiguation of ara-bic.
In In Proceedings of the Language Resourcesand Evaluation Conference (LREC), Reykjavik, Ice-land.Johannes Schaback.
2007.
Multi-level feature extrac-tion for spelling correction.
Hyderabad, India.K.
Shaalan, R. Aref, and A Fahmy.
2010.
An approachfor analyzing and correcting spelling errors for non-native arabic learners.
In Informatics and Systems(INFOS), 2010 The 7th International Conference on,pages 1?7, March.Khaled Shaalan, Mohammed Attia, Pavel Pecina,Younes Samih, and Josef van Genabith.
2012.
Ara-bic word generation and modelling for spell check-ing.
In Nicoletta Calzolari (Conference Chair),Khalid Choukri, Thierry Declerck, Mehmet UurDoan, Bente Maegaard, Joseph Mariani, AsuncionMoreno, Jan Odijk, and Stelios Piperidis, editors,Proceedings of the Eight International Conferenceon Language Resources and Evaluation (LREC?12),Istanbul, Turkey, may.
European Language Re-sources Association (ELRA).A.
Stolcke.
2002.
Srilm ?
an extensible language mod-eling toolkit.
In Proc.
Intl.
Conf.
on Spoken Lan-guage Processing, Denver,U.S.A.Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-sama Obeid, Nadi Tomeh, Alla Rozovskaya, NouraFarra, Sarah Alkuhlani, and Kemal Oflazer.
2014.Large scale arabic error annotation: Guidelines andframework.
In Proceedings of the Ninth Interna-tional Conference on Language Resources and Eval-uation (LREC?14), Reykjavik, Iceland, May.
Euro-pean Language Resources Association (ELRA).126
