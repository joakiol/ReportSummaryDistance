Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 58?66,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsDirect Parsing of Discontinuous Constituents in GermanWolfgang MaierSFB 833, University of Tu?bingenNauklerstr.
3572074 Tu?bingen, Germanywmaier@sfs.uni-tuebingen.deAbstractDiscontinuities occur especially frequently inlanguages with a relatively free word order,such as German.
Generally, due to the long-distance dependencies they induce, they liebeyond the expressivity of Probabilistic CFG,i.e., they cannot be directly reconstructed bya PCFG parser.
In this paper, we use aparser for Probabilistic Linear Context-FreeRewriting Systems (PLCFRS), a formalismwith high expressivity, to directly parse theGerman NeGra and TIGER treebanks.
In bothtreebanks, discontinuities are annotated withcrossing branches.
Based on an evaluation us-ing different metrics, we show that an outputquality can be achieved which is comparableto the output quality of PCFG-based systems.1 IntroductionLanguages with a rather free word order, like Ger-man, display discontinuous constituents particularlyfrequently.
In (1), the discontinuity is caused by anextraposed relative clause.
(1) wiederagaintreffenmatchalleallAttributeattributeszu,VPARTdiewhichauchalsosonstotherwiseimmeralwayspassenfit?Again, the same attributes as always apply.
?Another language with a rather free word order isBulgarian.
In (2), the discontinuity is caused by top-icalization.
(2) Himikali1Pens1azIkupuvambuysamoonlyevtiniexpensivet1t1?As for pens, I only buy expensive ones.
?In most constituency treebanks, sentence annota-tion is restricted to having the shape of trees with-out crossing branches, and the non-local dependen-cies induced by the discontinuities are modeled byan additional mechanism.
In the Penn Treebank(PTB) (Marcus et al, 1994), e.g., this mechanismis a combination of special labels and empty nodes,establishing implicit additional edges.
In the Ger-man Tu?Ba-D/Z (Telljohann et al, 2006), additionaledges are established by a combination of topolog-ical field annotation and special edge labels.
As anexample, Fig.
1 shows a tree from Tu?Ba-D/Z withthe annotation of (1).
Note here the edge label ON-MOD on the relative clause which indicates that thesubject of the sentence (alle Attribute) is modified.Figure 1: A tree from Tu?Ba-D/ZHowever, in a few other treebanks, such as theGerman NeGra and TIGER treebanks (Skut et al,1997; Brants et al, 2002), crossing branches are al-lowed.
This way, all dependents of a long-distancedependency can be grouped under a single node.58Fig.
2 shows a tree from NeGra with the annotationof (3).
(3) NochYetnieneverhabehaveichIsosovielmuchgewa?hltchosen?Never have I had that much choice.
?Note the direct annotation of the discontinuous VP.NochADVnieADVhabeVAFIN1.Sg.Pres.IndichPPER1.Sg.
*.NomsoADVvielADVgew?hltVVPP.$.MO HDAVPMO HDAVPMO MO HDVPOCHD SBSFigure 2: A tree from NeGraSince in general, the annotation mechanisms fornon-local dependencies lie beyond the expressivityof Context-Free Grammar, non-local information isinaccessible for PCFG parsing and therefore gener-ally discarded.
In NeGra/TIGER annotation, e.g.,tree transformation algorithms are applied beforeparsing in order to resolve the crossing branches.See, e.g., Ku?bler et al (2008) and Boyd (2007) fordetails.
If one wants to avoid the loss of annotationinformation which is implied with such transforma-tions, one possibility is to use a probabilistic parserfor a formalism which is more expressive than CFG.In this paper, we tackle the question if qualita-tively good results can be achieved when parsingGerman with such a parser.
Concretely, we use aparser for Probabilistic Linear Context-Free Rewrit-ing Systems (PLCFRS) (Kallmeyer and Maier,2010).
LCFRS (Vijay-Shanker et al, 1987) are anatural extension of CFG in which a single non-terminal node can dominate more than one contin-uous span of terminals.
We can directly interpretNeGra-style trees as its derivation structures, i.e., wecan extract grammars without making further lin-guistic assumptions (Maier and Lichte, 2009) (seeSect.
2.3), as it is necessary for other formalismssuch as Probabilistic Tree Adjoining Grammars(Chiang, 2003).
Since the non-local dependenciesare immediately accessible in NeGra and TIGER,we choose these treebanks as our data source.
Inorder to judge parser output quality, we use four dif-ferent evaluation types.
We use an EVALB-stylemeasure, adapted for LCFRS, in order to compareour parser to previous work on parsing German tree-banks.
In order to address the known shortcomingsof EVALB, we perform an additional evaluation us-ing the tree distance metric of Zhang and Shasha(1989), which works independently of the fact ifthere are crossing branches in the trees or not, and adependency evaluation (Lin, 1995), which has alsobe applied before in the context of parsing German(Ku?bler et al, 2008).
Last, we evaluate certain diffi-cult phenomena by hand on TePaCoC (Ku?bler et al,2008), a set of sentences hand-picked from TIGER.The evaluations show that with a PLCFRS parser,competitive results can be achieved.The remainder of the article is structured as fol-lows.
In Sect.
2, we present the formalism, theparser, and how we obtain our grammars.
InSect.
3, we discuss the evaluation methods we em-ploy.
Sect.
4 contains our experimental results.Sect.
5 is dedicated to related work.
Sect.
6 con-tains the conclusion and presents some possible fu-ture work.2 A Parser for PLCFRS2.1 Probabilistic Linear Context-FreeRewriting SystemsLCFRS are an extension of CFG where the non-terminals can span not only single strings but, in-stead, tuples of strings.
We will notate LCFRS withthe syntax of simple Range Concatenation Gram-mars (SRCG) (Boullier, 1998), a formalism that isequivalent to LCFRS.A LCFRS (Vijay-Shanker et al, 1987) is a tupleG = (N,T, V, P, S) wherea) N is a finite set of non-terminals with a func-tion dim: N ?
N that determines the fan-outof each A ?
N ;b) T and V are disjoint finite sets of terminals andvariables;c) S ?
N is the start symbol with dim(S) = 1;d) P is a finite set of rewriting rulesA(?1, .
.
.
, ?dim(A)) ?
A1(X(1)1 , .
.
.
, X(1)dim(A1))?
?
?Am(X(m)1 , .
.
.
, X(m)dim(Am))59for m ?
0 where A,A1, .
.
.
, Am ?
N , X(i)j ?
Vfor 1 ?
i ?
m, 1 ?
j ?
dim(Ai) and ?i ?
(T ?V )?
for 1 ?
i ?
dim(A).
For all r ?
P , it holdsthat every variable X occurring in r occurs exactlyonce in the left-hand side (LHS) and exactly once inthe right-hand side (RHS).The fan-out of an LCFRS G is the maximal fan-out of all non-terminals in G. Furthermore, the RHSlength of a rewriting rules r ?
P is called the rankof r and the maximal rank of all rules in P is calledthe rank of G. An LCFRS is called ordered if forevery r ?
P and every RHS non-terminal A in r andeach pair X1, X2 of arguments of A in the RHS ofr, X1 precedes X2 in the RHS iff X1 precedes X2in the LHS.Borrowed from SRCG, we specify the languageof an LCFRS based on the notion of ranges.
Forsome input word w = w1 ?
?
?wn, a range is a pair?i, j?
of integers with 0 ?
i ?
n denoting the sub-string wi+1 ?
?
?wj .
Note that a range denotes ?
iffi = j.
Only consecutive ranges can be concatenatedinto new ranges.
We can replace the variables andterminals of the rewriting rules with ranges.
E.g.,A(?g, h?)
?
B(?g + 1, h ?
1?)
is a replacement ofthe clauseA(aX1b) ?
B(X1) if the input wordw issuch that wg+1 = a and wh = b.
A rewriting rule inwhich all elements of all arguments have been con-sistently replaced by ranges is called an instantiatedrule.
A derivation is built by successively rewritingthe LHSs of instantiated rules with its RHSs.
Thelanguage L(G) of some LCFRS G consists of allwords w = w1 ?
?
?wn for which it holds that there isa rule with the start symbol on the LHS which canbe instantiated to ?0, n?
and rewritten to ?.A probabilistic LCFRS (PLCFRS) is a tu-ple ?N,T, V, P, S, p?
such that ?N,T, V, P, S?
is aLCFRS and p : P ?
[0..1] a function such that forall A ?
N : ?A(~x)?~?
?P p(A(~x) ?
~?)
= 1.
Thereare possibly other ways to extend LCFRS with prob-abilities.
This definition is supported by the fact thatprobabilistic MCFGs1 have been defined in the sameway (Kato et al, 2006).1MCFGs are equivalent to LCFRSs and SRCGs (Boullier,1998).Scan: 0 : [A, ?
?i, i+ 1??]
A POS tag ofwi+1Unary: in : [B, ~?
]in+ |log(p)| : [A, ~?]
p : A(~?)
?
B(~?)
?
PBinary: inB : [B, ~?B], inC : [C, ~?C ]inB + inC + log(p) : [A, ~?A]where p : A( ~?A) ?
B( ~?B)C( ~?C) is an instantiated rule.Goal: [S, ?
?0, n??
]Figure 3: Weighted CYK deduction system2.2 A CYK Parser for PLCFRSWe use the parser of Kallmeyer and Maier (2010).It is a probabilistic CYK parser (Seki et al, 1991),using the technique of weighted deductive parsing(Nederhof, 2003).
While for symbolic parsing, otherelaborate algorithms exist (Kallmeyer and Maier,2009), for probabilistic parsing, CYK is a naturalchoice.It is assumed for the parser that our LCFRSs areof rank 2 and do not contain rules where some of theLHS components are ?.
Both assumptions can bemade without loss of generality since every LCFRScan be binarized (Go?mez-Rodr?
?guez et al, 2009)and ?-components on LHS of rules can be removed(Boullier, 1998).
We make the assumption that POStagging is done before parsing.
The POS tags arespecial non-terminals of fan-out 1.
Consequently,the rules are either of the form A(a) ?
?
where Ais a POS tag and a ?
T or of the formA(~?)
?
B(~x)or A(~?)
?
B(~x)C(~y) where ~?
?
(V +)dim(A), i.e.,only the rules for POS tags contain terminals in theirLHSs.The parser items have the form [A, ~?
], with A ?N and ~?
a vector of ranges characterizing all com-ponents of the span of A.
We specify the setof weighted parse items via the deduction rules inFig.
3.Parsing time can be reduced by reordering theagenda during parsing such that those items are pro-cessed first which lead to a complete parse morequickly than others (Klein and Manning, 2003a).The parser uses for this purpose an admissible, butnot monotonic estimate called LR estimate.
It gives(relative to a sentence length) an estimate of the out-side probability of some non-terminal A with a spanof a certain length (the sum of the lengths of all the60components of the span), a certain number of ter-minals to the left of the first and to the right of thelast component and a certain number of terminalsgaps in between the components of the A span, i.e.,filling the gaps.
A discussion of other estimates ispresented at length in Kallmeyer and Maier (2010).2.3 LCFRS for Modeling DiscontinuitiesWe use the algorithm from Maier and S?gaard(2008) to extract LCFRS rules from our data sets.For all nonterminals A0 with the children A1 ?
?
?Am(i.e., for all non-terminals which are not pretermi-nals), we create a clause ?0 ?
?1 ?
?
?
?m with ?i,0 ?
i ?
m, labeled Ai.
The arguments of each?i, 1 ?
i ?
m, are single variables, one for eachof the continuous yield part dominated by the nodeAi.
The arguments of ?0 are concatenations of thesevariables that describe how the discontinuous partsof the yield of A0 are obtained from the yields of itsdaughters.
For all preterminals A dominating someterminal a, we extract a production A(a) ?
?.
Sinceby definition, a label is associated with a certainfan-out, we distinguish the labels by correspond-ing subscripts.
Note that this extraction algorithmyields only ordered LCFRS.
Furthermore, note thatfor trees without crossing branches, this algorithmyields a PLCFRS with fan-out 1, i.e., a PCFG.As mentioned before, the advantage of usingLCFRS is that grammar extraction is straight-forward and that no separate assumptions must bemade.
Note that unlike, e.g., Range ConcatenationGrammar (RCG) (Boullier, 1998), LCFRS cannotmodel re-entrancies, i.e., nodes with more than oneincoming edge.
While those do not occur in NeGra-style annotation, some of the annotation in the PTB,e.g., the annotation for right node raising, can be in-terpreted as re-entrancies.
This topic is left for fu-ture work.
See Maier and Lichte (2009) for furtherdetails, especially on how treebank properties relateto properties of extracted grammars.Before parsing, we binarize our grammar.
We firstmark the head daughters of all non-terminal nodesusing Collins-style head rules based on the NeGrarules of the Stanford Parser (Klein and Manning,2003b) and the reorder the RHSs of all LCFRS rulessuch that sequence of elements to the right of thehead daughter is reversed and moved to the begin-ning of the RHS.
From this point, the binarizationworks like the transformation into Chomsky NormalForm for CFGs.
For each rule with an RHS of length?
3, we introduce a new non-terminal which cov-ers the RHS without the first element and continuesuccessively from left to right.
The rightmost newrule, which covers the head daughter, is binarized tounary.We markovize the grammar as in the CFG case.To the new symbols introduced during the binariza-tion, a variable number of symbols from the verticaland horizontal context of the original rule is added.Following the literature, we call the respective quan-tities v and h. As an example, Fig.
4 shows the out-put for the production for the VP in the left tree inFig.
2.After extraction and head marking:VP2(X1,X2X3) ?
AVP1(X1) AVP1(X2) VVPP1?
(X3)After binarization and markovization with v = 1, h = 2:VP2(X1,X2) ?
AVP1(X1) @-VP2v-AVP1h-VVPP1h(X2)@-VP2v-AVP1h-VVPP1h(X1X2)?
AVP1(X1) @-VP2v-VVPP1h(X2)@-VP2v-VVPP1h(X1) ?
VVPP1(X1)After binarization and markovization with v = 2, h = 1:VP2(X1,X2) ?
AVP1(X1) @-VP2v-S2v-AVP1h(X2)@-VP2v-S2v-AVP1h(X1X2)?
AVP1(X1) @-VP2v-S2v-VVPP1h(X2)@-VP2v-S2v-VVPP1h(X1) ?
VVPP1(X1)Figure 4: Grammar extraction and binarization exampleThe probabilities are then computed based on thenumber of occurrences of rules in the transformedtreebank, using a Maximum Likelihood estimator.3 Evaluation methodsWe assess the quality of our parser output using dif-ferent methods.The first is an EVALB-style metric (henceforthEVALB), i.e., we compare phrase boundaries.
Inspite of its shortcomings (Rehbein and van Gen-abith, 2007), it allows us to compare to previ-ous work on parsing NeGra.
In the context ofLCFRS, we compare sets of tuples of the form[A, (i1l , i1r), .
.
.
, (ikl , ikr )], where A is a non-terminalin some derivation tree with dim(A) = k and each(iml , imr ), 1 ?
m ?
k, is a tuple of indices denot-ing a continuous sequence of terminals dominatedbyA.
One set is obtained from the parser output, and61B<B CB t3 B >B t4t1 t2 z t1 t2 zx y x yFigure 5: TDIST exampleone from the corresponding treebank trees.
Usingthese tuple sets, we compute labeled and unlabeledrecall (LR/UR), precision (LP/UP), and the F1 mea-sure (LF1/UF1) in the usual way.
Note that if k = 1,our metric is identical to its PCFG version.EVALB does not necessarily reflect parser outputquality (Rehbein and van Genabith, 2007; Emms,2008; Ku?bler et al, 2008).
One of its major prob-lems is that attachment errors are penalized toohard.
As the second evaluation method, we there-fore choose the tree-distance measure (henceforthTDIST) (Zhang and Shasha, 1989), which levitatesthis problem.
It has been proposed for parser evalu-ation by Emms (2008).
TDIST is an ideal candidatefor evaluation of the output of a PLCFRS, since it thefact if trees have crossing branches or not is not rel-evant to it.
Two trees ?k and ?A are compared on thebasis of T -mappings from ?k to ?A.
A T -mappingis a partial mapping ?
of nodes of ?k to nodes of ?Awhere all node mappings preserve left-to-right or-der and ancestry.
Within the mappings, node inser-tion, node deletion, and label swap operations areidentified, represented resp.
by the sets I , D andS .
Furthermore, we consider the set M represent-ing the matched (i.e., unchanged) nodes.
The cost ofa T -mapping is the total number of operations, i.e.|I|+ |D|+ |S|.
The tree distance between two trees?K and ?A is the cost of the cheapest T -mapping.Fig.
5, borrowed from Emms, shows an example fora T -mapping.
Inserted nodes are prefixed with >,deleted nodes are suffixed with <, and nodes withswapped labels are linked with arrows.
Since in to-tal, four operations are involved, to this T -mapping,a cost of 4 is assigned.
For more details, especiallyon algorithms which compute TDIST, refer to Bille(2005).
In order to convert the tree distance measureinto a similarity measure like EVALB, we use themacro-averaged Dice and Jaccard normalizations asdefined by Emms.
Let ?K and ?A be two trees with|?K | and |?A| nodes, respectively.
For a T -mapping?
from ?K to ?A with the sets D, I , S and M, wecompute them as follows.dice(?)
= 1?
|D|+ |I|+ |S||?K |+ |?A|jaccard (?)
= 1?
|D|+ |I|+ |S||D|+ |I|+ |S|+ |M|where, in order to achieve macro-averaging, we sumthe numerators and denominators over all tree pairsbefore dividing.
See Emms (2008) for further de-tails.The third method is dependency evaluation(henceforth DEP), as described by Lin (1995).
Itconsists of comparing dependency graphs extractedfrom the gold data and from the parser output.
Thedependency extraction algorithm as given by Lindoes also not rely on trees to be free of crossingbranches.
It only relies on a method to identify thehead of each phrase.
We use our own implementa-tion of the algorithm which is described in Sect.
4of Lin (1995), combined with the head finding algo-rithm of the parser.
Dependency evaluation abstractsaway from another bias of EVALB.
Concretely, itdoes not prefer trees with a high node/token ratio,since two dependency graphs to be compared neces-sarily have the same number of (terminal) nodes.
Inthe context of parsing German, this evaluation hasbeen employed previously by Ku?bler et al (2008).Last, we evaluate on TePaCoC (TestingParser Performance on Complex GrammaticalConstructions), a set of particularly difficult sen-tences hand-picked from TIGER (Ku?bler et al,2008).4 ExperimentsOur data sources are the German NeGra (Skut etal., 1997) and TIGER (Brants et al, 2002) tree-banks.
In a preprocessing step, following commonpractice, we attach all punctuation to nodes withinthe tree, since it is not included in the NeGra an-notation.
In a first pass, using heuristics, we at-tach all nodes to the in each case highest availablephrasal node such that ideally, we do not introducenew crossing branches.
In a second pass, paren-theses and quotation marks are preferably attachedto the same node.
Grammatical function labels are62discarded.
After this preprocessing step, we createa separate version of the data set, in which we re-solve the crossing branches in the trees, using thecommon approach of re-attaching nodes to higherconstituents.
We use the first 90% of our data setsfor training and the remaining 10% for testing.
Dueto memory limitations, we restrict ourselves to sen-tences of a maximal length of 30 words.
Our TIGERdata sets (TIGER and T-CF) have 31,568 sentencesof an average length of 14.81, splitted into 31,568sentences for training and 3,508 sentences for test-ing.
Our NeGra data sets (NeGra and N-CF) have18,335 sentences, splitted into 16,501 sentences fortraining and 1,834 sentences for testing.We parse the data sets described above with acti-vated LR estimate.
For all our experiments, we usethe markovization settings v = 2 and h = 1, whichhave proven to be successful in previous work onparsing NeGra (Rafferty and Manning, 2008).
Weprovide the parser with the gold tagging.
Fig.
6shows the average parsing times for all data sets onan AMD Opteron node with 8GB of RAM (pureJava implementation), Tab.
1 shows the percentageof parsed sentences.0.010.11101005  10  15  20  25timeinsec.
(logscale)Sentence lengthNeGraTIGERN-CFT-CFFigure 6: Parsing timesNeGra TIGER N-CF T-CFtotal 1834 3508 1834 3508parsed 1779(97.0%)3462(98.7%)1804(98.4%)3462(98.7%)Table 1: Parsed sentences4.1 Evaluation Using EVALBTab.
2 shows the evaluation of the parser output us-ing EVALB, as described in the previous section.We report labeled and unlabeled precision, recalland F1 measure.LP LR LF1 UP UR UF1NeGra 72.39 70.68 71.52 76.01 74.22 75.10TIGER 74.97 71.95 73.43 78.58 75.42 76.97N-CF 74.85 73.26 74.04 78.11 76.45 77.28T-CF 77.51 73.73 75.57 80.59 76.66 78.57Table 2: EVALB resultsNot surprisingly, reconstructing discontinuities ishard.
Therefore, when parsing without crossingbranches, the results are slightly better.
In order tosee the influence of discontinuous structures duringparsing on the underlying phrase structure, we re-solve the crossing branches in the parser output ofNeGra and TIGER and compare it to the respectivegold test data of N-CF and T-CF.
Tab.
3 shows theresults.LP LR LF1 UP UR UF1NeGra 72.75 71.04 71.89 76.38 74.58 75.47TIGER 75.28 72.25 73.74 78.81 75.64 77.20Table 3: EVALB results (resolved crossing branches)The results deteriorate slightly in comparisonwith N-CF and T-CF, however, they are slightlyhigher than for than for NeGra and TIGER.
Thisis due to the fact that during the transformation,some errors in the LCFRS parses get ?corrected?
:Wrongly attached phrasal nodes are re-attached tounique higher positions in the trees.In order to give a point of comparison with previ-ous work on parsing TIGER and NeGra, in Tab.
4,we report some of the results from the literature.
Allof them were obtained using PCFG parsers: Ku?bler(2005) (Tab.
1, plain PCFG for NeGra), Ku?bler et al(2008) (Tab.
3, plain PCFG and Stanford parser withmarkovization v = 2 and h = 1 for TIGER), andPetrov and Klein (2007) (Tab.
1, Berkeley parser, la-tent variables).
We include the results for N-CF andT-CF.Our results are slightly better than for the plainPCFG models.
We would expect the result for T-CF to be closer to the corresponding result for theStanford parser, since we are using a comparable63plain this work markov.
latentNeGra 69.94 74.04 ?
80.1TIGER 74.00 75.57 77.30 ?Table 4: PCFG parsing of NeGra, Labeled F1model.
This difference is mostly likely due to lossesinduced by the LR estimate.
All items to which theestimate assigns an outside log probability estimateof ??
get blocked and are not put on the agenda.This blocking has an extremely beneficial effect onparser speed.
However, it is paid by a worse recall,as experiments with smaller data sets have shown.A complete discussion of the effects of estimates, aswell as a discussion of other possible optimizations,is presented in Kallmeyer and Maier (2010).Recall finally that LCFRS parses are more infor-mative than PCFG parses ?
a lower score for LCFRSEVALB than for PCFG EVALB does not necessarilymean that the PCFG parse is ?better?.4.2 Evaluation Using Tree DistanceTab.
5 shows the results of evaluating with TDIST,excluding unparsed sentences.
We report the diceand jaccard normalizations, as well as a summaryof the distribution of the tree distances between goldtrees and trees from the parser output (see Sect.
3).tree distance distrib.dice jaccard 0 ?
3 ?
10NeGra 88.86 79.79 31.65 53.77 15.08TIGER 89.47 80.84 29.87 56.78 18.18N-CF 92.50 85.99 33.43 61.92 6.71T-CF 92.70 86.46 31.80 63.81 4.56Table 5: Tree distance evaluationAgain, we can observe that parsing LCFRS isharder than parsing PCFG.
As for EVALB, the re-sults for TIGER are slightly higher than the ones forNeGra.
The distribution of the tree distances showsthat about a third of all sentences receive a com-pletely correct parse.
More than a half, resp.
a thirdof all parser output trees require ?
3 operations to bemapped to the corresponding gold tree, and a only asmall percentage requires ?
10 operations.To our knowledge, TDIST has not been used toevaluate parser output for NeGra and TIGER.
How-ever, Emms (2008) reports results for the PTB usingdifferent parsers.
Collins?
Model 1 (Collins, 1999),e.g., lies at 93.62 (Dice) and 87.87 (Jaccard).
Forthe Berkeley Parser (Petrov and Klein, 2007), 94.72and 89.87 is reported.
We see that our results lie inthem same range.
However, Jaccard scores are lowersince this normalization punishes a higher numberof edit operations more severely than Dice.
In or-der to meaningfully interpret which treebank prop-erties are responsible for the fact that between thegold trees and the trees from the parser, the Germandata requires more tree edit operations than the En-glish data, a TDIST evaluation of the output of anoff-the-shelf PCFG parser would be necessary.
Thisis left for future work.4.3 Dependency EvaluationFor the dependency evaluation, we extract depen-dency graphs from both the gold data and the testdata and compare the unlabeled accuracy.
Tab.
6shows the results.
We report unlabeled attachmentscore (UAS).UASNeGra 76.50TIGER 77.84N-CF 77.52T-CF 78.67Table 6: Dependency evaluationThe dependency results are consistent with theprevious results in as much as the scores for PCFGparsing are again higher.
The dependency re-sults reported in Ku?bler et al (2008) however aremuch higher (85.6 UAS for the markovized Stan-ford parser).
While a part of the losses can againbe attributed to the LR estimate, another reason liesundoubtedly in the different dependency conversionmethod which we employ, and in further treebanktransformations which Ku?bler et al perform.
In or-der to get a more fine grained result, in future work,we will consider graph modifications as proposed byLin (1995) as well as including annotation-specificinformation from NeGra/TIGER in our conversionprocedure.4.4 TePaCoCThe TePaCoC data set (Ku?bler et al, 2008) provides100 hand-picked sentences from TIGER which con-tain constructions that are especially difficult to64parse.
Out of these 100 sentences, we only consider69.
The remaining 31 sentences are either longerthan 30 words or not included in the TIGER 2003release (Ku?bler et al use the 2005 release).
Thedata is partitioned in groups of sentences with extra-posed relative clauses (ERC), forward conjunctionreduction (FCR), noun PP attachment (PPN), verbPP attachment (PPV), subject gap with finite/frontedverbs (SGF) and coordination of unlike constituents(CUC).
Tab.
7 shows the EVALB results for the (dis-continuous) TePaCoC.
We parse these sentences us-ing the same training set as before with all TePaCoCsentences removed.LP LR LF1 UP UR UF1ERC 59.34 61.36 60.34 64.84 67.05 65.92FCR 78.03 76.70 77.36 82.66 81.25 81.95PPN 72.15 72.15 72.15 75.95 75.95 75.95PPV 73.33 73.33 73.33 76.66 76.66 76.66CUC 58.76 57.58 58.16 69.07 67.68 68.37SGF 82.67 81.05 81.85 85.33 83.66 84.49all 72.27 71.83 72.05 77.26 76.78 77.02Table 7: EVALB scores for TePaCoCWhile we cannot compare our results directlywith the PCFG results (using grammatical functionlabels) of Ku?bler et al, their results nevertheless givean orientation.We take a closer look at all sentence groups.
Ourresult for ERC is more than 15 points worse thanthe result of Ku?bler et al The relative clause itselfis mostly recognized as a sentence (though not ex-plicitly marked as a relative clause, since we do notconsider grammatical functions).
However, it is al-most consistently attached too high (on the VP oron clause level).
While this is correct for Ku?bler etal., with crossing branches, it treated as an error andpunished especially hard by EVALB.
FCR is parsedmostly well and with comparable results to Ku?bleret al There are too few sentences to make a strongclaim about PP attachment.
However, in both PPNand PPV flat phrases seem to be preferred, whichhas as a consequence that in PPN, PPs are attachedtoo high and in PPV too low.
Our output confirmsthe claim of Ku?bler et al?s that unlike coordinationsis the most difficult of all TePaCoC phenomena.
Theconjuncts themselves are correctly identified in mostcases, however then coordinated at the wrong level.SGF is parsed best.
Ku?bler et al report for this grouponly 78.6 labeled F1 for the Stanford Parser.
Ouroverall results are slightly worse than the results ofKu?bler et al, but show less variance.To sum up, not surprisingly, getting the right at-tachment positions seems to be hard for LCFRS,too.
Additionally, with crossing branches, the out-put is rated worse, since some attachments are notpresent anymore without crossing branches.
Sinceespecially for the relative clauses, attachment posi-tions are in fact a matter of discussion from a syntac-tic point of view, we will consider in future studiesto selectively resolve some of the crossing branches,e.g., by attaching relative clauses to higher positions.5 Related WorkThe use of formalisms with a high expressivity hasbeen explored before (Plaehn, 2004; Levy, 2005).To our knowledge, Plaehn is the only one to re-port evaluation results.
He uses the formalism ofDiscontinuous Phrase Structure Grammar (DPSG).Limiting the sentence length to 15, he obtains 73.16labeled F1 on NeGra.
Evaluating all sentences ofour NeGra data with a length of up to 15 words re-sults, however, in 81.27 labeled F1.
For a compari-son between DPSG and LCFRS, refer to Maier andS?gaard (2008).6 Conclusion and Future WorkWe have investigated the possibility of using Prob-abilistic Linear Context-Free Rewriting Systems fordirect parsing of discontinuous constituents.
Conse-quently, we have applied a PLCFRS parser on theGerman NeGra and TIGER treebanks.
Our evalu-ation, which used different metrics, showed that aPLCFRS parser can achieve competitive results.In future work, all of the presented evaluationmethods will be investigated to greater detail.
Inorder to do this, we will parse our data sets withcurrent state-of-the-art systems.
Especially a moreelaborate dependency conversion should enable amore informative comparison between the output ofPCFG parsers and the output of the PLCFRS parser.Last, since an algorithm is available which extractsLCFRSs from dependency structures (Kuhlmannand Satta, 2009), the parser is instantly ready forparsing them.
We are currently performing the cor-responding experiments.65ReferencesPhilip Bille.
2005.
A survey on tree edit distance andrelated problems.
Theoretical Computer Science, 337.Pierre Boullier.
1998.
A Proposal for a Natural Lan-guage Processing Syntactic Backbone.
Technical Re-port 3342, INRIA.Adriane Boyd.
2007.
Discontinuity revisited: An im-proved conversion to context-free representations.
InThe Linguistic Annotation Workshop at ACL 2007.Sabine Brants, Stefanie Dipper, Silvia Hansen, WolfgangLezius, and George Smith.
2002.
The TIGER Tree-bank.
In Proceedings of Treebanks and LinguisticTheories.David Chiang.
2003.
Statistical parsing with an automat-ically extracted Tree Adjoining Grammar.
In Data-Oriented Parsing.
CSLI Publications.Michael Collins.
1999.
Head-driven statistical modelsfor natural language parsing.
Ph.D. thesis, Universityof Pennsylvania.Martin Emms.
2008.
Tree Distance and some other vari-ants of Evalb.
In Proceedings of LREC 08.Carlos Go?mez-Rodr?
?guez, Marco Kuhlmann, GiorgioSatta, and David Weir.
2009.
Optimal reduction ofrule length in linear context-free rewriting systems.
InProceedings of NAACL-HLT.Laura Kallmeyer and Wolfgang Maier.
2009.
An in-cremental earley parser for simple range concatenationgrammar.
In Proceedings of IWPT 09.Laura Kallmeyer and Wolfgang Maier.
2010.
Data-driven parsing with probabilistic linear context-freerewriting systems.
Unpublished Manuscript.Yuki Kato, Hiroyuki Seki, and Tadao Kasami.
2006.RNA pseudoknotted structure prediction usingstochastic multiple context-free grammar.
IPSJDigital Courier, 2.Dan Klein and Christopher D. Manning.
2003a.
A* Pars-ing: Fast Exact Viterbi Parse Selection.
In Proceed-ings of NAACL-HLT.Dan Klein and Christopher D. Manning.
2003b.
Fastexact inference with a factored model for natural lan-guage parsing.
In In Advances in Neural InformationProcessing Systems 15 (NIPS).
MIT Press.Sandra Ku?bler, Wolfgang Maier, Ines Rehbein, and Yan-nick Versley.
2008.
How to compare treebanks.
InProceedings of LREC 08.Sandra Ku?bler.
2005.
How do treebank annotationschemes influence parsing results?
Or how not to com-pare apples and oranges.
In Proceedings of RANLP2005.Marco Kuhlmann and Giorgio Satta.
2009.
Treebankgrammar techniques for non-projective dependencyparsing.
In Proceedings of EACL.Roger Levy.
2005.
Probabilistic Models of Word Or-der and Syntactic Discontinuity.
Ph.D. thesis, Stan-ford University.Dekang Lin.
1995.
A dependency-based method forevaluating broad-coverage parsers.
In Proceedings ofIJCAI 95.Wolfgang Maier and Timm Lichte.
2009.
Characterizingdiscontinuity in constituent treebanks.
In Proceedingsof Formal Grammar 2009.Wolfgang Maier and Anders S?gaard.
2008.
Treebanksand mild context-sensitivity.
In Proceedings of FormalGrammar 2008.Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,Robert MacIntyre, Ann Bies, Mark Ferguson, KarenKatz, and Britta Schasberger.
1994.
The Penn Tree-bank: Annotating predicate argument structure.
InProceedings of HLT.Mark-Jan Nederhof.
2003.
Weighted Deductive Parsingand Knuth?s Algorithm.
Computational Linguistics,29(1).Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of HLT-NAACL 2007.Oliver Plaehn.
2004.
Computing the most probable parsefor a discontinuous phrase-structure grammar.
In Newdevelopments in parsing technology.
Kluwer.Anna Rafferty and Christopher D. Manning.
2008.
Pars-ing three German treebanks: Lexicalized and unlexi-calized baselines.
In Proceedings of the Workshop onParsing German at ACL 2008.Ines Rehbein and Josef van Genabith.
2007.
Evaluatingevaluation measures.
In Proceedings of NODALIDA2007.Hiroyuki Seki, Takahashi Matsumura, Mamoru Fujii, andTadao Kasami.
1991.
On multiple context-free gram-mars.
Theoretical Computer Science, 88(2).Wojciech Skut, Brigitte Krenn, Thorten Brants, and HansUszkoreit.
1997.
An annotation scheme for free wordorder languages.
In Proceedings of ANLP.Heike Telljohann, Erhard Hinrichs, Sandra Ku?bler, andHeike Zinsmeister.
2006.
Stylebook for the Tu?bingenTreebank of Written German (Tu?Ba-D/Z).
Technis-cher Bericht, Universita?t Tu?bingen.K.
Vijay-Shanker, David J. Weir, and Aravind K. Joshi.1987.
Characterizing structural descriptions producedby various grammatical formalisms.
In Proceedings ofACL.Kaizhong Zhang and Dennis Shasha.
1989.
Simple fastalgorithms for the editing distance between trees andrelated problems.
SIAM Journal of Computing, 18.66
