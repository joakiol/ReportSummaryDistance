Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1192?1202,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsNeural Semantic Role Labeling with Dependency Path EmbeddingsMichael Roth and Mirella LapataSchool of Informatics, University of Edinburgh10 Crichton Street, Edinburgh EH8 9AB{mroth,mlap}@inf.ed.ac.ukAbstractThis paper introduces a novel model forsemantic role labeling that makes useof neural sequence modeling techniques.Our approach is motivated by the obser-vation that complex syntactic structuresand related phenomena, such as nestedsubordinations and nominal predicates,are not handled well by existing models.Our model treats such instances as sub-sequences of lexicalized dependency pathsand learns suitable embedding representa-tions.
We experimentally demonstrate thatsuch embeddings can improve results overprevious state-of-the-art semantic role la-belers, and showcase qualitative improve-ments obtained by our method.1 IntroductionThe goal of semantic role labeling (SRL) is toidentify and label the arguments of semantic predi-cates in a sentence according to a set of predefinedrelations (e.g., ?who?
did ?what?
to ?whom?).
Se-mantic roles provide a layer of abstraction be-yond syntactic dependency relations, such as sub-ject and object, in that the provided labels are in-sensitive to syntactic alternations and can also beapplied to nominal predicates.
Previous work hasshown that semantic roles are useful for a widerange of natural language processing tasks, withrecent applications including statistical machinetranslation (Aziz et al, 2011; Xiong et al, 2012),plagiarism detection (Osman et al, 2012; Pauland Jamal, 2015), and multi-document abstractivesummarization (Khan et al, 2015).The task of semantic role labeling (SRL) waspioneered by Gildea and Jurafsky (2002).
InSystem Analysismate-tools *He had [troubleA0] raising [fundsA1].mateplus *He had [troubleA0] raising [fundsA1].TensorSRL *He had trouble raising [fundsA1].easySRL *He had trouble raising [fundsA1].This work [HeA0] had trouble raising [fundsA1].Table 1: Outputs of SRL systems for the sentenceHe had trouble raising funds.
Arguments of raiseare shown with predicted roles as defined in Prop-Bank (A0: getter of money; A1: money).
Asterisksmark flawed analyses that miss the argument He.their work, features based on syntactic constituenttrees were identified as most valuable for labelingpredicate-argument relationships.
Later work con-firmed the importance of syntactic parse features(Pradhan et al, 2005; Punyakanok et al, 2008)and found that dependency parse trees provide abetter form of representation to assign role labelsto arguments (Johansson and Nugues, 2008).Most semantic role labeling approaches to daterely heavily on lexical and syntactic indicator fea-tures.
Through the availability of large annotatedresources, such as PropBank (Palmer et al, 2005),statistical models based on such features achievehigh accuracy.
However, results often fall shortwhen the input to be labeled involves instances oflinguistic phenomena that are relevant for the la-beling decision but appear infrequently at trainingtime.
Examples include control and raising verbs,nested conjunctions or other recursive structures,as well as rare nominal predicates.
The difficultylies in that simple lexical and syntactic indicatorfeatures are not able to model interactions trig-gered by such phenomena.
For instance, con-1192sider the sentence He had trouble raising fundsand the analyses provided by four publicly avail-able tools in Table 1 (mate-tools, Bj?orkelund etal.
(2010); mateplus, Roth and Woodsend (2014);TensorSRL, Lei et al (2015); and easySRL, Lewiset al (2015)).
Despite all systems claiming state-of-the-art or competitive performance, none ofthem is able to correctly identify He as the agentargument of the predicate raise.
Given the com-plex dependency path relation between the predi-cate and its argument, none of the systems actuallyidentifies He as an argument at all.In this paper, we develop a new neural networkmodel that can be applied to the task of seman-tic role labeling.
The goal of this model is to bet-ter handle control predicates and other phenomenathat can be observed from the dependency struc-ture of a sentence.
In particular, we aim to modelthe semantic relationships between a predicate andits arguments by analyzing the dependency pathbetween the predicate word and each argumenthead word.
We consider lexicalized paths, whichwe decompose into sequences of individual items,namely the words and dependency relations on apath.
We then apply long-short term memory net-works (Hochreiter and Schmidhuber, 1997) to finda recurrent composition function that can recon-struct an appropriate representation of the full pathfrom its individual parts (Section 2).
To ensurethat representations are indicative of semantic re-lationships, we use semantic roles as target labelsin a supervised setting (Section 3).By modeling dependency paths as sequences ofwords and dependencies, we implicitly address thedata sparsity problem.
This is the case because weuse single words and individual dependency rela-tions as the basic units of our model.
In contrast,previous SRL work only considered full syntacticpaths.
Experiments on the CoNLL-2009 bench-mark dataset show that our model is able to out-perform the state-of-the-art in English (Section 4),and that it improves SRL performance in otherlanguages, including Chinese, German and Span-ish (Section 5).2 Dependency Path EmbeddingsIn the context of neural networks, the term embed-ding refers to the output of a function f within thenetwork, which transforms an arbitrary input intoa real-valued vector output.
Word embeddings, forinstance, are typically computed by forwarding aROOTheA0hadtroubleraisingraise.01fundsA1SBJ OBJNMODOBJFigure 1: Dependency path (dotted) between thepredicate raising and the argument he.one-hot word vector representation from the inputlayer of a neural network to its first hidden layer,usually by means of matrix multiplication and anoptional non-linear function whose parameters arelearned during neural network training.Here, we seek to compute real-valued vectorrepresentations for dependency paths between apair of words ?wi,wj?.
We define a dependencypath to be the sequence of nodes (representingwords) and edges (representing relations betweenwords) to be traversed on a dependency parse treeto get from node wito node wj.
In the example inFigure 1, the dependency path from raising to heis raisingNMOD????
troubleOBJ???hadSBJ?
?he.Analogously to how word embeddings are com-puted, the simplest way to embed paths wouldbe to represent each sequence as a one-hot vec-tor.
However, this is suboptimal for two reasons:Firstly, we expect only a subset of dependencypaths to be attested frequently in our data andtherefore many paths will be too sparse to learnreliable embeddings for them.
Secondly, we hy-pothesize that dependency paths which share thesame words, word categories or dependency re-lations should impact SRL decisions in similarways.
Thus, the words and relations on the pathshould drive representation learning, rather thanthe full path on its own.
The following sectionsdescribe how we address representation learningby means of modeling dependency paths as se-quences of items in a recurrent neural network.2.1 Recurrent Neural NetworksThe recurrent model we use in this work is a vari-ant of the long-short term memory (LSTM) net-work.
It takes a sequence of items X = x1, ...,xnas input, recurrently processes each item xt?
X ata time, and finally returns one embedding state enfor the complete input sequence.
For each time1193he N had V trouble Nraising V. .
.subjobjnmodx1xnennext layerFigure 2: Example input and embedding compu-tation for the path from raising to he, given thesentence he had trouble raising funds.
LSTM timesteps are displayed from right to left.step t, the LSTM model updates an internal mem-ory state mtthat depends on the current input aswell as the previous memory state mt?1.
In or-der to capture long-term dependencies, a so-calledgating mechanism controls the extent to whicheach component of a memory cell state will bemodified.
In this work, we employ input gates i,output gates o and (optional) forget gates f. Weformalize the state of the network at each timestep t as follows:it= ?
([Wmimt?1]+Wxixt+bi) (1)ft= ?
([Wmfmt?1]+Wxfxt+bf) (2)mt= it(Wxmxt)+ ftmt?1+bm(3)ot= ?
([Wmomt]+Wxoxt+bo) (4)et= ot?
(mt) (5)In each equation, W describes a matrix ofweights to project information between two lay-ers, b is a layer-specific vector of bias terms, and?
is the logistic function.
Superscripts indicatethe corresponding layers or gates.
Some modelsdescribed in Section 3 do not make use of forgetgates or memory-to-gate connections.
In case noforget gate is used, we set ft= 1.
If no memory-to-gate connections are used, the terms in squarebrackets in (1), (2), and (4) are replaced by zeros.2.2 Embedding Dependency PathsWe define the embedding of a dependency pathto be the final memory output state of a recur-rent LSTM layer that takes a path as input, witheach input step representing a binary indicator fora part-of-speech tag, a word form, or a dependencyrelation.
In the context of semantic role labeling,we define each path as a sequence from a predicateto its potential argument.1Specifically, we definethe first item x1to correspond to the part-of-speechtag of the predicate word wi, followed by its actualword form, and the relation to the next word wi+1.The embedding of a dependency path correspondsto the state enreturned by the LSTM layer afterthe input of the last item, xn, which corresponds tothe word form of the argument head word wj.
Anexample is shown in Figure 2.The main idea of this model and representationis that word forms, word categories and depen-dency relations can all influence role labeling de-cisions.
The word category and word form of thepredicate first determine which roles are plausibleand what kinds of path configurations are to be ex-pected.
The relations and words seen on the pathcan then manipulate these expectations.
In Fig-ure 2, for instance, the verb raising complementsthe phrase had trouble, which makes it likely thatthe subject he is also the logical subject of raising.By using word forms, categories and depen-dency relations as input items, we ensure that spe-cific words (e.g., those which are part of com-plex predicates) as well as various relation types(e.g., subject and object) can appropriately influ-ence the representation of a path.
While learn-ing corresponding interactions, the network is alsoable to determine which phrases and dependencyrelations might not influence a role assignment de-cision (e.g., coordinations).2.3 Joint Embedding and Feature LearningOur SRL model consists of four components de-picted in Figure 3: (1) an LSTM component takeslexicalized dependency paths as input, (2) an ad-ditional input layer takes binary features as input,(3) a hidden layer combines dependency path em-beddings and binary features using rectified linearunits, and (4) a softmax classification layer pro-duces output based on the hidden layer state as in-put.
We therefore learn path embeddings jointlywith feature detectors based on traditional, binaryindicator features.Given a dependency path X , with steps xk?
{x1, ...,xn}, and a set of binary features B as in-put, we use the LSTM formalization from equa-tions (1?5) to compute the embedding enat time1We experimented with different sequential orders andfound this to lead to the best validation set results.1194(1)x1Input from path X. .
.xni1m0f1LSTM cellm1o1e1.
.
.enVector of binary indicatorfeatures B(2)(3)h(4)sclasslabelcFigure 3: Neural model for joint learning of pathembeddings and higher-order features: The pathsequence x1.
.
.xnis fed into a LSTM layer, a hid-den layer h combines the final embedding enandbinary input features B, and an output layer s as-signs the highest probable class label c.step n and formalize the state of the hidden layer hand softmax output scfor each class category c asfollows:h = max(0,WBhB+Wehen+bh) (6)sc=Wescen+Whsch+bsc?i(Wesien+Whsih+bsi)(7)3 System ArchitectureThe overall architecture of our SRL system closelyfollows that of previous work (Toutanova et al,2008; Bj?orkelund et al, 2009) and is depicted inFigure 4.
We use a pipeline that consists of the fol-lowing steps: predicate identification and disam-biguation, argument identification, argument clas-sification, and re-ranking.
The neural-networkcomponents introduced in Section 2 are used inthe last three steps.
The following sub-sections de-scribe all components in more detail.3.1 Predicate Identification andDisambiguationGiven a syntactically analyzed sentence, the firsttwo steps in an end-to-end SRL system are to iden-tify and disambiguate the semantic predicates inthe sentence.
Here, we focus on verbal and nom-inal predicates but note that other syntactic cate-gories have also been construed as predicates inthe NLP literature (e.g., prepositions; Srikumarand Roth (2013)).
For both identification and dis-ambiguation steps, we apply the same logistic re-He had trouble raising funds.PREDICATEIDENTIFICATIONPREDICATEDISAMBIGUATIONraise.01senseARGUMENTIDENTIFICATIONARG?ARG?2nd best arg1st best argARGUMENTCLASSIFICATIONA0 A1A0best labelbest label2ndbestRERANKERhe funds funds fundsraise.01 raise.01 raise.01A0A1best overall scoring structurescore scoreOUTPUTHeA0had trouble raising fundsA1.Figure 4: Pipeline architecture of our SRL system.gression classifiers used in the SRL componentsof mate-tools (Bj?orkelund et al, 2010).
The clas-sifiers for both tasks make use of a range of lexico-syntactic indicator features, including predicateword form, its predicted part-of-speech tag as wellas dependency relations to all syntactic children.3.2 Argument Identification andClassificationGiven a sentence and a set of sense-disambiguatedpredicates in it, the next two steps of our SRL sys-tem are to identify all arguments of each pred-icate and to assign suitable role labels to them.For both steps, we train several LSTM-based neu-ral network models as described in Section 2.
Inparticular, we train separate networks for nomi-nal and verbal predicates and for identification andclassification.
Following the findings of earlierwork (Xue and Palmer, 2004), we assume that dif-ferent feature sets are relevant for the respectivetasks and hence different embedding representa-tions should be learned.
As binary input features,we use the following sets from the SRL literature(Bj?orkelund et al, 2010).1195Argument labeling step forget gate memory?gates |e| |h| alpha dropout rateIdentification (verb) ?
+ 25 90 0.0006 0.42Identification (noun) ?
+ 16 125 0.0009 0.25Classification (verb) + ?
5 300 0.0155 0.50Classification (noun) ?
?
88 500 0.0055 0.46Table 2: Hyperparameters selected for best models and training proceduresLexico-syntactic features Word form and wordcategory of the predicate and candidate argument;dependency relations from predicate and argumentto their respective syntactic heads; full depen-dency path sequence from predicate to argument.Local context features Word forms and wordcategories of the candidate argument?s and pred-icate?s syntactic siblings and children words.Other features Relative position of the candi-date argument with respect to the predicate (left,self, right); sequence of part-of-speech tags of allwords between the predicate and the argument.3.3 RerankerAs all argument identification (and classification)decisions are independent of one another, weapply as the last step of our pipeline a globalreranker.
Given a predicate p, the reranker takesas input the n best sets of identified arguments aswell as their n best label assignments and predictsthe best overall argument structure.
We implementthe reranker as a logistic regression classifier, withhidden and embedding layer states of identifiedarguments as features, offset by the argument la-bel, and a binary label as output (1: best predictedstructure, 0: any other structure).
At test time, weselect the structure with the highest overall score,which we compute as the geometric mean of theglobal regression and all argument-specific scores.4 ExperimentsIn this section, we demonstrate the usefulness ofdependency path embeddings for semantic role la-beling.
Our hypotheses are that (1) modeling de-pendency paths as sequences will lead to betterrepresentations for the SRL task, thus increasinglabeling precision overall, and that (2) embeddingswill address the problem of data sparsity, lead-ing to higher recall.
To test both hypotheses, weexperiment on the in-domain and out-of-domaintest sets provided in the CoNLL-2009 shared task(Haji?c et al, 2009) and compare results of oursystem, henceforth PathLSTM, with systems thatdo not involve path embeddings.
We computeprecision, recall and F1-score using the officialCoNLL-2009 scorer.2The code is available athttps://github.com/microth/PathLSTM.Model selection We train argument identifica-tion and classification models using the XLBPtoolkit for neural networks (Monner and Reg-gia, 2012).
The hyperparameters for each stepwere selected based on the CoNLL 2009 devel-opment set.
For direct comparison with previ-ous work, we use the same preprocessing mod-els and predicate-specific SRL components as pro-vided with mate-tools (Bohnet, 2010; Bj?orkelundet al, 2010).
The types and ranges of hyperparam-eters considered are as follows: learning rate ?
?
[0.00006,0.3], dropout rate d ?
[0.0,0.5], and hid-den layer sizes |e| ?
[0,100], |h| ?
[0,500].
In addi-tion, we experimented with different gating mech-anisms (with/without forget gate) and memory ac-cess settings (with/without connections betweenall gates and the memory layer, cf.
Section 2).
Thebest parameters were chosen using the Spearminthyperparameter optimization toolkit (Snoek et al,2012), applied for approx.
200 iterations, and aresummarized in Table 2.Results The results of our in- and out-of-domainexperiments are summarized in Tables 3 and 5, re-spectively.
We present results for different systemconfigurations: ?local?
systems make classificationdecisions independently, whereas ?global?
systemsinclude a reranker or other global inference mech-anisms; ?single?
refers to one model and ?ensem-ble?
refers to combinations of multiple models.In the in-domain setting, our PathLSTM modelachieves 87.7% (single) and 87.9% (ensemble) F1-score, outperforming previously published best re-2Some recently proposed SRL models are only evaluatedon the CoNLL 2005 and 2012 data sets, which lack nomi-nal predicates or dependency annotations.
We do not list anyresults from those models here.1196System (local, single) P R F1Bj?orkelund et al (2010) 87.1 84.5 85.8Lei et al (2015) ?
?
86.6FitzGerald et al (2015) ?
?
86.7PathLSTM w/o reranker 88.1 85.3 86.7System (global, single) P R F1Bj?orkelund et al (2010) 88.6 85.2 86.9Roth and Woodsend (2014)3?
?
86.3FitzGerald et al (2015) ?
?
87.3PathLSTM 90.0 85.5 87.7System (global, ensemble) P R F1FitzGerald et al 10 models ?
?
87.7PathLSTM 3 models 90.3 85.7 87.9Table 3: Results on the CoNLL-2009 in-domaintest set.
All numbers are in percent.PathLSTM P (%) R (%) F1(%)w/o path embeddings 65.7 87.3 75.0w/o binary features 73.2 33.3 45.8Table 4: Ablation tests in the in-domain setting.sults by 0.4 and 0.2 percentage points, respec-tively.
At a F1-score of 86.7%, our local model(using no reranker) reaches the same performanceas state-of-the-art local models.
Note that dif-ferences in results between systems might origi-nate from the application of different preprocess-ing techniques as each system comes with its ownsyntactic components.
For direct comparison, weevaluate against mate-tools, which use the samepreprocessing techniques as PathLSTM.
In com-parison, we see improvements of +0.8?1.0 per-centage points absolute in F1-score.In the out-of-domain setting, our systemachieves new state-of-the-art results of 76.1% (sin-gle) and 76.5% (ensemble) F1-score, outperform-ing the previous best system by Roth and Wood-send (2014) by 0.2 and 0.6 absolute points, respec-tively.
In comparison to mate-tools, we observeabsolute improvements in F1-score of +0.4?0.8%.Discussion To determine the sources of indi-vidual improvements, we test PathLSTM modelswithout specific feature types and directly com-pare PathLSTM and mate-tools, both of which use3Results are taken from Lei et al (2015).System (local, single) P R F1Bj?orkelund et al (2010) 75.7 72.2 73.9Lei et al (2015) ?
?
75.6FitzGerald et al (2015) ?
?
75.2PathLSTM w/o reranker 76.9 73.8 75.3System (global, single) P R F1Bj?orkelund et al (2010) 77.9 73.6 75.7Roth and Woodsend (2014)3?
?
75.9FitzGerald et al (2015) ?
?
75.2PathLSTM 78.6 73.8 76.1System (global, ensemble) P R F1FitzGerald et al 10 models ?
?
75.5PathLSTM 3 models 79.7 73.6 76.5Table 5: Results on the CoNLL-2009 out-of-domain test set.
All numbers are in percent.the same preprocessing methods.
Table 4 presentsin-domain test results for our system when spe-cific feature types are omitted.
The overall lowresults indicate that a combination of dependencypath embeddings and binary features is required toidentify and label arguments with high precision.Figure 5 shows the effect of dependency pathembeddings at mitigating sparsity: if the path be-tween a predicate and its argument has not beenobserved at training time or only infrequently,conventional methods will often fail to assign arole.
This is represented by the recall curveof mate-tools, which converges to zero for argu-ments with unseen paths.
The higher recall curvefor PathLSTM demonstrates that path embeddingscan alleviate this problem to some extent.
For un-seen paths, we observe that PathLSTM improvesover mate-tools by an order of magnitude, from0.9% to 9.6%.
The highest absolute gain, from12.8% to 24.2% recall, can be observed for depen-dency paths that occurred between 1 and 10 timesduring training.Figure 7 plots role labeling performance forsentences with varying number of words.
Thereare two categories of sentences in which the im-provements of PathLSTM are most noticeable:Firstly, it better handles short sentences that con-tain expletives and/or nominal predicates (+0.8%absolute in F1-score).
This is probably due to thefact that our learned dependency path representa-tions are lexicalized, making it possible to model1197(Nested) subject controlCoordinations involving A1Relative clausesCoordinations involving A0Complements of nominal predicatestreasuryA0?s threat to trashthe firmA1, which was involvedKeatingA0has conceded attempted to buytradingA1was stoppedand did not resume?
A0 ?
A1Figure 6: Dots correspond to the path representation of a predicate-argument instance in 2D space.White/black color indicates A0/A1 gold argument labels.
Dotted ellipses denote instances exhibitingrelated syntactic phenomena (see rectangles for a description and dotted rectangles for linguistic exam-ples).
Example phrases show actual output produced by PathLSTM (underlined).01?10?102?103?104>104100110Number of training instances with same pathRecall(%)PathLSTMmate-tools0.99.624.212.836.430.149.676.488.3Figure 5: Results on in-domain test instances,grouped by the number of training instances thathave an identical (unlexicalized) dependency path.argument structures of different nominals and dis-tinguishing between expletive occurrences of ?it?and other subjects.
Secondly, it improves perfor-mance on longer sentences (up to +1.0% absolutein F1-score).
This is mainly due to the handling ofdependency paths that involve complex structures,such as coordinations, control verbs and nominalpredicates.We collect instances of different syntactic phe-nomena from the development set and plot thelearned dependency path representations in theembedding space (see Figure 6).
We obtain a pro-jection onto two dimensions using t-SNE (Van derMaaten and Hinton, 2008).
Interestingly, we can1?1011?1516?2021?2526?3031?858687888990Number of wordsF1-score(%)PathLSTMmate-tools89.390.1 (+0.8)86.187.1 (+1.0)87.587.9 (+0.4)Figure 7: Results by sentence length.
Improve-ments over mate-tools shown in parentheses.see that different syntactic configurations are clus-tered together in different parts of the space andthat most instances of the PropBank roles A0 andA1 are separated.
Example phrases in the figurehighlight predicate-argument pairs that are cor-rectly labeled by PathLSTM but not by mate-tools.Path embeddings are essential for handling thesecases as indicator features do not generalize wellenough.Finally, Table 6 shows results for nominal andverbal predicates as well as for different (gold)role labels.
In comparison to mate-tools, we cansee that PathLSTM improves precision for all ar-gument types of nominal predicates.
For ver-bal predicates, improvements can be observed in1198Predicate POS Improvement& Role Label PathLSTM over mate-toolsP (%) R (%) P (%) R (%)verb / A0 90.8 89.2 ?0.4 +1.8verb / A1 91.0 91.9 +0.0 +1.1verb / A2 84.3 76.9 +1.5 +0.0verb / AM 82.2 72.4 +2.9 ?2.0noun / A0 86.9 78.2 +0.8 +3.3noun / A1 87.5 84.4 +2.6 +2.2noun / A2 82.4 76.8 +1.0 +2.1noun / AM 79.5 69.2 +0.9 ?2.8Table 6: Results by word category and role label.terms of recall of proto-agent (A0) and proto-patient (A1) roles, with slight gains in precisionfor the A2 role.
Overall, PathLSTM does slightlyworse with respect to modifier roles, which it la-bels with higher precision but at the cost of recall.5 Path Embeddings in other LanguagesIn this section, we report results from additionalexperiments on Chinese, German and Spanishdata.
The underlying question is to which extentthe improvements of our SRL system for Englishalso generalize to other languages.
To answer thisquestion, we train and test separate SRL mod-els for each language, using the system architec-ture and hyperparameters discussed in Sections 3and 4, respectively.We train our models on data from theCoNLL-2009 shared task, relying on the samefeatures as one of the participating systems(Bj?orkelund et al, 2009), and evaluate with theofficial scorer.
For direct comparison, we rely onthe (automatic) syntactic preprocessing informa-tion provided with the CoNLL test data and com-pare our results with the best two systems for eachlanguage that make use of the same preprocessinginformation.The results, summarized in Table 7, indicatethat PathLSTM performs better than the system byBj?orkelund et al (2009) in all cases.
For Germanand Chinese, PathLSTM achieves the best overallF1-scores of 80.1% and 79.4%, respectively.6 Related WorkNeural Networks for SRL Collobert et al(2011) pioneered neural networks for the task ofChinese P R F1PathLSTM 83.2 75.9 79.4Bj?orkelund et al (2009) 82.4 75.1 78.6Zhao et al (2009) 80.4 75.2 77.7German P R F1PathLSTM 81.8 78.5 80.1Bj?orkelund et al (2009) 81.2 78.3 79.7Che et al (2009) 82.1 75.4 78.6Spanish P R F1Zhao et al (2009) 83.1 78.0 80.5PathLSTM 83.2 77.4 80.2Bj?orkelund et al (2009) 78.9 74.3 76.5Table 7: Results (in percentage) on the CoNLL-2009 test sets for Chinese, German and Spanish.semantic role labeling.
They developed a feed-forward network that uses a convolution func-tion over windows of words to assign SRL labels.Apart from constituency boundaries, their systemdoes not make use of any syntactic information.Foland and Martin (2015) extended their modeland showcased significant improvements when in-cluding binary indicator features for dependencypaths.
Similar features were used by FitzGerald etal.
(2015), who include role labeling predictionsby neural networks as factors in a global model.These approaches all make use of binary fea-tures derived from syntactic parses either to indi-cate constituency boundaries or to represent fulldependency paths.
An extreme alternative hasbeen recently proposed in Zhou and Xu (2015),who model SRL decisions with a multi-layeredLSTM network that takes word sequences as in-put but no syntactic parse information at all.Our approach falls in between the two extremes:we rely on syntactic parse information but ratherthan solely making using of sparse binary features,we explicitly model dependency paths in a neuralnetwork architecture.Other SRL approaches Within the SRL litera-ture, recent alternatives to neural network archi-tectures include sigmoid belief networks (Hender-son et al, 2013) as well as low-rank tensor models(Lei et al, 2015).
Whereas Lei et al only makeuse of dependency paths as binary indicator fea-tures, Henderson et al propose a joint model forsyntactic and semantic parsing that learns and ap-1199plies incremental dependency path representationsto perform SRL decisions.
The latter form of rep-resentation is closest to ours, however, we do notbuild syntactic parses incrementally.
Instead, wetake syntactically preprocessed text as input andfocus on the SRL task only.Apart from more powerful models, most recentprogress in SRL can be attributed to novel fea-tures.
For instance, Deschacht and Moens (2009)and Huang and Yates (2010) use latent variables,learned with a hidden markov model, as featuresfor representing words and word sequences.
Zapi-rain et al (2013) propose different selection pref-erence models in order to deal with the sparsenessof lexical features.
Roth and Woodsend (2014)address the same problem with word embeddingsand compositions thereof.
Roth and Lapata (2015)recently introduced features that model the influ-ence of discourse on role labeling decisions.Rather than coming up with completely newfeatures, in this work we proposed to revisit somewell-known features and represent them in a novelway that generalizes better.
Our proposed modelis inspired both by the necessity to overcome theproblems of sparse lexico-syntactic features andby the recent success of SRL models based on neu-ral networks.Dependency-based embeddings The idea ofembedding dependency structures has previouslybeen applied to tasks such as relation classifica-tion and sentiment analysis.
Xu et al (2015) andLiu et al (2015) use neural networks to embed de-pendency paths between entity pairs.
To identifythe relation that holds between two entities, theirapproaches make use of pooling layers that detectparts of a path that indicate a specific relation.
Incontrast, our work aims at modeling an individ-ual path as a complete sequence, in which everyitem is of relevance.
Tai et al (2015) and Ma et al(2015) learn embeddings of dependency structuresrepresenting full sentences, in a sentiment classifi-cation task.
In our model, embeddings are learnedjointly with other features, and as a result prob-lems that may result from erroneous parse treesare mitigated.7 ConclusionsWe introduced a neural network architecture forsemantic role labeling that jointly learns embed-dings for dependency paths and feature combina-tions.
Our experimental results indicate that ourmodel substantially increases classification perfor-mance, leading to new state-of-the-art results.
In aqualitive analysis, we found that our model is ableto cover instances of various linguistic phenomenathat are missed by other methods.Beyond SRL, we expect dependency path em-beddings to be useful in related tasks and down-stream applications.
For instance, our represen-tations may be of direct benefit for semantic anddiscourse parsing tasks.
The jointly learned fea-ture space also makes our model a good startingpoint for cross-lingual transfer methods that relyon feature representation projection to induce newmodels (Kozhevnikov and Titov, 2014).Acknowledgements We thank the three anony-mous ACL referees whose feedback helped tosubstantially improve the present paper.
Thesupport of the Deutsche Forschungsgemeinschaft(Research Fellowship RO 4848/1-1; Roth) andthe European Research Council (award number681760; Lapata) is gratefully acknowledged.ReferencesWilker Aziz, Miguel Rios, and Lucia Specia.
2011.Shallow semantic trees for smt.
In Proceedings ofthe Sixth Workshop on Statistical Machine Transla-tion, pages 316?322, Edinburgh, Scotland.Anders Bj?orkelund, Love Hafdell, and Pierre Nugues.2009.
Multilingual semantic role labeling.
In Pro-ceedings of the Thirteenth Conference on Compu-tational Natural Language Learning: Shared Task,pages 43?48, Boulder, Colorado.Anders Bj?orkelund, Bernd Bohnet, Love Hafdell, andPierre Nugues.
2010.
A high-performance syn-tactic and semantic dependency parser.
In Coling2010: Demonstration Volume, pages 33?36, Beijing,China.Bernd Bohnet.
2010.
Top accuracy and fast depen-dency parsing is not a contradiction.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics, pages 89?97, Beijing, China.Wanxiang Che, Zhenghua Li, Yongqiang Li, YuhangGuo, Bing Qin, and Ting Liu.
2009.
Multilin-gual dependency-based syntactic and semantic pars-ing.
In Proceedings of the Thirteenth Conference onComputational Natural Language Learning: SharedTask, pages 49?54, Boulder, Colorado.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
The Journal of Machine Learning Re-search, 12:2493?2537.1200Koen Deschacht and Marie-Francine Moens.
2009.Semi-supervised semantic role labeling using theLatent Words Language Model.
In Proceedings ofthe 2009 Conference on Empirical Methods in Nat-ural Language Processing, pages 21?29, Singapore.Nicholas FitzGerald, Oscar T?ackstr?om, KuzmanGanchev, and Dipanjan Das.
2015.
Semantic rolelabeling with neural network factors.
In Proceed-ings of the 2015 Conference on Empirical Methodsin Natural Language Processing, pages 960?970,Lisbon, Portugal.William Foland and James Martin.
2015.Dependency-based semantic role labeling us-ing convolutional neural networks.
In Proceedingsof the Fourth Joint Conference on Lexical andComputational Semantics, pages 279?288, Denver,Colorado.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3):245?288.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, et al 2009.
The CoNLL-2009shared task: Syntactic and semantic dependenciesin multiple languages.
In Proceedings of the Thir-teenth Conference on Computational Natural Lan-guage Learning: Shared Task, pages 1?18, Boulder,Colorado.James Henderson, Paola Merlo, Ivan Titov, andGabriele Musillo.
2013.
Multilingual joint pars-ing of syntactic and semantic dependencies with alatent variable model.
Computational Linguistics,39(4):949?998.Sepp Hochreiter and J?urgen Schmidhuber.
1997.Long short-term memory.
Neural Computation,9(8):1735?1780.Fei Huang and Alexander Yates.
2010.
Open-domainsemantic role labeling by modeling word spans.
InProceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, pages 968?978, Uppsala, Sweden.Richard Johansson and Pierre Nugues.
2008.
The ef-fect of syntactic representation on semantic role la-beling.
In Proceedings of the 22nd InternationalConference on Computational Linguistics, pages393?400, Manchester, United Kingdom.Atif Khan, Naomie Salim, and Yogan Jaya Kumar.2015.
A framework for multi-document abstrac-tive summarization based on semantic role labelling.Applied Soft Computing, 30:737?747.Mikhail Kozhevnikov and Ivan Titov.
2014.
Cross-lingual model transfer using feature representationprojection.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Lin-guistics, pages 579?585, Baltimore, Maryland.Tao Lei, Yuan Zhang, Llu?
?s M`arquez, Alessandro Mos-chitti, and Regina Barzilay.
2015.
High-order low-rank tensors for semantic role labeling.
In Proceed-ings of the 2015 Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics: Human Language Technologies, pages1150?1160, Denver, Colorado.Mike Lewis, Luheng He, and Luke Zettlemoyer.
2015.Joint A* CCG parsing and semantic role labelling.In Proceedings of the 2015 Conference on Empiri-cal Methods in Natural Language Processing, pages1444?1454, Lisbon, Portugal.Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou,and Houfeng Wang.
2015.
A dependency-basedneural network for relation classification.
In Pro-ceedings of the 53rd Annual Meeting of the Associ-ation for Computational Linguistics and the 7th In-ternational Joint Conference on Natural LanguageProcessing, pages 285?290, Beijing, China.Mingbo Ma, Liang Huang, Bowen Zhou, and Bing Xi-ang.
2015.
Dependency-based convolutional neuralnetworks for sentence embedding.
In Proceedingsof the 53rd Annual Meeting of the Association forComputational Linguistics and the 7th InternationalJoint Conference on Natural Language Processing,pages 174?179, Beijing, China.Derek Monner and James A Reggia.
2012.
A general-ized LSTM-like training algorithm for second-orderrecurrent neural networks.
Neural Networks, 25:70?83.Ahmed Hamza Osman, Naomie Salim, Mo-hammed Salem Binwahlan, Rihab Alteeb, andAlbaraa Abuobieda.
2012.
An improved plagiarismdetection scheme based on semantic role labeling.Applied Soft Computing, 12(5):1493?1502.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31(1):71?106.Merin Paul and Sangeetha Jamal.
2015.
An im-proved SRL based plagiarism detection techniqueusing sentence ranking.
Procedia Computer Sci-ence, 46:223?230.Sameer Pradhan, Kadri Hacioglu, Wayne Ward,James H. Martin, and Daniel Jurafsky.
2005.
Se-mantic role chunking combining complementarysyntactic views.
In Proceedings of the Ninth Confer-ence on Computational Natural Language Learning,pages 217?220, Ann Arbor, Michigan.Vasin Punyakanok, Dan Roth, and Wen-tau Yih.
2008.The importance of syntactic parsing and inference insemantic role labeling.
Computational Linguistics,34(2):257?287.Michael Roth and Mirella Lapata.
2015.
Context-aware frame-semantic role labeling.
Transactionsof the Association for Computational Linguistics,3:449?460.1201Michael Roth and Kristian Woodsend.
2014.
Com-position of word representations improves seman-tic role labelling.
In Proceedings of the 2014 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 407?413, Doha, Qatar.Jasper Snoek, Hugo Larochelle, and Ryan P. Adams.2012.
Practical bayesian optimization of machinelearning algorithms.
In Advances in Neural Infor-mation Processing Systems, pages 2951?2959, LakeTahoe, Nevada.Vivek Srikumar and Dan Roth.
2013.
Modeling se-mantic relations expressed by prepositions.
Trans-actions of the Association for Computational Lin-guistics, 1:231?242.Kai Sheng Tai, Richard Socher, and Christopher D.Manning.
2015.
Improved semantic representa-tions from tree-structured long short-term memorynetworks.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on Nat-ural Language Processing, pages 1556?1566, Bei-jing, China.Kristina Toutanova, Aria Haghighi, and ChristopherManning.
2008.
A global joint model for se-mantic role labeling.
Computational Linguistics,34(2):161?191.Laurens Van der Maaten and Geoffrey Hinton.
2008.Visualizing data using t-SNE.
Journal of MachineLearning Research, 9:2579?2605.Deyi Xiong, Min Zhang, and Haizhou Li.
2012.
Mod-eling the translation of predicate-argument structurefor smt.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics, pages 902?911, Jeju Island, Korea.Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng,and Zhi Jin.
2015.
Classifying relations via longshort term memory networks along shortest depen-dency paths.
In Proceedings of the 2015 Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 1785?1794, Lisbon, Portugal.Nianwen Xue and Martha Palmer.
2004.
Calibrat-ing features for semantic role labeling.
In Proceed-ings of the 2004 Conference on Empirical Meth-ods in Natural Language Processing, pages 88?94,Barcelona, Spain.Be?nat Zapirain, Eneko Agirre, Llu?
?s M`arquez, and Mi-hai Surdeanu.
2013.
Selectional preferences for se-mantic role classification.
Computational Linguis-tics, 39(3):631?663.Hai Zhao, Wenliang Chen, Jun?ichi Kazama, KiyotakaUchimoto, and Kentaro Torisawa.
2009.
Multi-lingual dependency learning: Exploiting rich fea-tures for tagging syntactic and semantic dependen-cies.
In Proceedings of the Thirteenth Confer-ence on Computational Natural Language Learning(CoNLL 2009): Shared Task, pages 61?66, Boulder,Colorado.Jie Zhou and Wei Xu.
2015.
End-to-end learning ofsemantic role labeling using recurrent neural net-works.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on Nat-ural Language Processing, pages 1127?1137, Bei-jing, China.1202
