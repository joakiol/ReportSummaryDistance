Statistical Machine Translation Using Coercive Two-Level SyntacticTransductionCharles Schafer and David YarowskyCenter for Language and Speech Processing / Department of Computer ScienceJohns Hopkins UniversityBaltimore, MD 21218 USA{cschafer,yarowsky}@cs.jhu.eduAbstractWe define, implement and evaluate a novel model forstatistical machine translation, which is based on shal-low syntactic analysis (part-of-speech tagging and phrasechunking) in both the source and target languages.
Itis able to model long-distance constituent motion andother syntactic phenomena without requiring a full parsein either language.
We also examine aspects of lexicaltransfer, suggesting and exploring a concept of transla-tion coercion across parts of speech, as well as a transfermodel based on lemma-to-lemma translation probabili-ties, which holds promise for improving machine trans-lation of low-density languages.
Experiments are per-formed in both Arabic-to-English and French-to-Englishtranslation demonstrating the efficacy of the proposedtechniques.
Performance is automatically evaluated viathe Bleu score metric.1 IntroductionIn this work we define, implement and evaluate a novelmodel for statistical machine translation (SMT).Our goal was to produce a SMT system for translat-ing foreign languages into English which utilizes somesyntactic information in both the foreign language andEnglish without, however, requiring a full parse in eitherlanguage.
Some advantages of not relying on full parsesinclude that (1) there is a lack of availability of parsersfor many languages of interest; (2) parsing time com-plexity represents a potential bottleneck for both modeltraining and testing.Intuitively, the explicit modeling of syntactic phenom-ena should be of benefit in the machine translation task;the ability to handle long-distance motion in an intelli-gently constrained way is a salient example of such abenefit.
Allowing unconstrained translation reorderingsat the word level generates a very large set of permu-tations that pose a difficult search problem at decodingtime.
We propose a model that makes use of shallowparses (text chunking) to support long-distance motionof phrases without requiring deeper analysis of syntax.The resources required to train this system on a new lan-guage are minimal, and we gain the ability to modellong-distance movement and some interesting proper-ties of lexical translation across parts of speech.
One ofthe source languages we examine in this paper, Arabic,has a canonical sentence-level order of Verb-Subject-Object, which means that translation into English (witha standard ordering of Subject-Verb-Object) commonlyrequires motion of entire phrasal constituents, which isnot true of French-to-English translation, to cite one lan-guage pair whose characteristics have wielded great in-fluence in the history of work on statistical machinetranslation.
A key motivation for and objective of thiswork was to build a translation model and feature spaceto handle the above-described phenomenon effectively.2 Prior WorkStatistical machine translation, as pioneered by IBM(e.g.
Brown et al, 1993), is grounded in the noisy chan-nel model.
And similar to the related channel problemsof speech and handwriting recognition, the original SMTlanguage pair French-English exhibits a relatively closelinear correlation in source and target sequence.
Muchcommon local motion that is observed for French, suchas adjective-noun swapping, is adequately modeled bythe relative-position-based distortion models of the clas-sic IBM approach.
Unfortunately, these distortion mod-els are less effective for languages such as Japanese orArabic, which have substantially different top-level sen-tential word orders from English, and hence longer dis-tance constituent motion.Wu (1997) and Jones and Havrilla (1998) have soughtto more closely tie the allowed motion of constituentsbetween languages to those syntactic transductions sup-ported by the independent rotation of parse tree con-stituents.
Yamada and Knight (2000, 2001) and Alshawiet al (2000) have effectively extended such syntactictransduction models to fully functional SMT systems,based on channel model tree transducers and finite statehead transducers respectively.
While these models arewell suited for the effective handling of highly divergentsentential word orders, the above frameworks have a lim-itation shared with probabilistic context free grammarsthat the preferred ordering of subtrees is insufficientlyconstrained by their embedding context, which is espe-cially problematic for very deep syntactic parses.In contrast, Och et al (1999) have avoided the con-straints of tree-based syntactic models and allow the rel-atively flat motion of empirically derived phrasal chunks,which need not adhere to traditional constituent bound-aries.Our current paper takes a middle path, by groundingmotion in syntactic transduction, but in a much flatter 2-level model of syntactic analysis, based on flat embed-ded noun-phrases in a flat sentential constituent-basedchunk sequence that can be driven by syntactic brack-eters and POS tag models rather than a full parser, facili-tating its transfer to lower density languages.
The flatter2-level structures also better support transductions condi-tioned to full sentential context than do deeply embeddedtree models, while retaining the empirically observed ad-vantages of translation ordering independence of noun-phrases.Another improvement over Och et al and Yamada andKnight is the use of the finite state machine (FSM) mod-elling framework (e.g.
Bangalore and Riccardi, 2000),which offers the considerable advantage of a flexibleframework for decoding, as well as a representationwhich is suitable for the fixed two-level phrasal mod-elling employed here.Finally, the original cross-part-of-speech lexical coer-cion models presented in Section 4.3.3 have related workin the primarily-syntactic coercion models utilized byDorr and Habash (2002) and Habash and Door (2003),although their induction and modelling are quite differ-ent from the approach here.3 ResourcesAs in other SMT approaches, the primary training re-source is a sentence-aligned parallel bilingual corpus.We further require that each side of the corpus be part-of-speech (POS) tagged and phrase chunked; our labhas previously developed techniques for rapid trainingof such tools (Cucerzan and Yarowsky, 2002).
Our trans-lation experiments were carried out on two languages:Arabic and French.
The Arabic training corpus was asubset of the United Nations (UN) parallel corpus whichis being made available by the Linguistic Data Consor-tium.
For French-English training, we used a portion ofthe Canadian Hansards.
Both corpora utilized sentence-level alignments publicly distributed by the LinguisticData Consortium.POS tagging and phrase chunking in English weredone using the trained systems provided with the fnTBLToolkit (Ngai and Florian, 2001); both were trainedfrom the annotated Penn Treebank corpus (Marcus et al,1993).
French POS tagging was done using the trainedFrench lexical tagger also provided with the fnTBL soft-ware.
For Arabic, we used a colleague?s POS tagger andtokenizer (clitic separation was also performed prior toPOS tagging), which was rapidly developed in our lab-oratory.
Simple regular-expression-based phrase chun-kers were developed by the authors for both Arabic andFrench, requiring less than a person-day each using ex-isting multilingual learning tools.A further input to our system is a set of word alignmentlinks on the parallel corpus.
These are used to computeword translation probabilities and phrasal alignments.The word alignments can in principle come from anysource: a dictionary, a specialized alignment program,or another SMT system.
We used alignments generatedby Giza++ (Och and Ney, 2000) by running it in both di-rections (e.g., Arabic ?
English and English ?
Arabic)on our parallel corpora.
The union of these bidirectionalalignments was used to compute cross-language phrasecorrespondences by simple majority voting, and for pur-poses of estimating word translation probabilities, eachlink in this union was treated as an independent instanceof word translation.4 Translation ModelNow we turn to a detailed description of the proposedtranslation model.
The exposition will give a formalspecification and also will follow a running examplethroughout, using one of the actual Arabic test set sen-tences.
This example, its gloss, system translation andreference human translation are shown in Table 1.The translation model (TM) we describe is trained di-rectly from counts in the data, and is a direct model, nota noisy channel model.
It consists of three nested com-ponents: (1) a sentence-level model of phrase correspon-dence and reordering, (2) a model of intra-phrase trans-lation, and (3) models of lexical transfer, or word transla-tion.
We make a key assumption in our construction thattranslation at each of these three levels is independent ofthe others.4.1 Sentence TranslationAs mentioned, both the foreign language and Englishcorpora are input with ?hard?
phrase bracketings and la-beled with ?hard?
phrase types (e.g., NP, VP1, PPNP2,etc.)
as given by the output of the phrase chunker.
Theseare denoted in the top-level model presentation in Table2(1).
Given word alignment links, as described in Sec-tion 2, we compute phrasal alignments on training data.We contrain these to have cardinality(foreign)N ?
1(English).
Next, we collect counts overaligned phrase sequences and use the relative frequen-cies to estimate the probability distribution in Table 2(2).Particularly for smaller training corpora, unseen foreign-language phrase sequences are a problem, so we imple-mented a simple backoff method which assigns proba-bility to translations of unseen foreign-language phrasesequences.
Table 2(3) encapsulates the remainder of thetranslation model, which is described below.As an example, Table 3 shows the most probablealigned English phrase sequence generations given anArabic simple sentence having the canonical VSO or-dering.
Also, note that all probabilities in the following1VP in our parlance is perhaps more properly called a verb chunk:it consists of a verb, its auxiliaries, and contiguous adverbs.2PPNP consists of a NP with its prepositional head attached.Arabic Example Sentence From Test Set(ARABIC) twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp b- AEtmAd m$rwE Al- mqrr Al- tAly :(PHR.-BRACKETED AR.)
[twSy] [Al- ljnp Al- sAdsp] [Al- jmEyp Al- EAmp] [b- AEtmAd m$rwE Al- mqrr Al- tAly] [:](AN ENG.
GLOSS) [recommends] [the committee the sixth] [the assembly the general] [to adoption draft the decision the following] [:](ENG.
MT OUTPUT) [the sixth committee] [recommends] [the general assembly] [in the adoption of the following draft resolution] [:](REFERENCE TRANS.)
the sixth committee recommends to the general assembly the adoption of the following draft decision :Table 1: An Arabic translation from the test set.
We revisit portions of this example throughout the text.
All Arabicstrings in this paper are rendered in the reversible Buckwalter transliteration.
In addition, all words or symbols referringto Arabic and French in this paper are italicized.figures and tables are from the actual Arabic and Frenchtrained systems.Arabic Phrase Aligned English Prob.Sequence Phrase SequenceVP1 NP2 NP3 NP2 VP1 NP3 0.23VP1 NP2 NP3 VP1 NP2 PP3 0.10VP1 NP2 NP3 NP3 VP1,2 0.06Table 3: Top learned sentence-level reorderings for Ara-bic, for canonical Arabic simple sentence structure VP(verb) NP (subject) NP (object).
Subscripts in Englishphrase sequence are alignments to positions in the corre-sponding Arabic phrase sequence.4.2 Phrase TranslationGiven an Arabic test sentence, a distribution of alignedEnglish phrase sequences is proposed by the sentence-level model described in the previous section and in Ta-ble 2.
Each proposed English phrase in each of the phrasesequence possibilities, therefore, comes to the middlelevel of the translation model with access to the identityof the French phrases aligned to it.
Phrase translation isimplemented as shown in Table 4.
The phrase transla-tion model is structured with several levels of backoff: ifno observations exist from training data for a particularlevel, the model backs off to the next-more-general level.In all cases, generation of an English phrase is condi-tioned on the foreign phrase as well as the type(NP, VP, etc.)
of the English phrase.Table 4 (1) describes the initial phrase translationmodel.
It comes into play if the precise sequence offoreign words has been observed aligning to an En-glish phrase of the appropriate type.
In the example,we are trying to generate an NP given the Arabic wordstring ?Al- ljnp Al- sAdsp?
(literally: ?the committee thesixth?).
If this has been observed in data, then that rela-tive frequency distribution serves as the translation prob-ability distribution.
Table 11 contains examples of someof these literal phrase translations from the French data.The next stage of backoff from the above, literal levelis a model that generates aligned English POS tag se-quences given foreign POS tag sequences: details andan example can be found in Table 4(2).
The sequencealignments determine the position in English phrase andthe part-of-speech into which we translate the foreignword.
Again, translation is also conditioned on the En-glish phrase type.
Table 5 and Table 6 show the mostprobable aligned English sequence generations for twoof the phrases in the example sentence.If there were no counts for (foreign-POS-sequence,english-phrase-type) then we back off to countscollected over (foreign-coarse-POS-sequence, english-phrase-type), where a coarse POS is, for example, N in-stead of NOUN-SG.
This is shown in Table 4(3).In case further backoff is needed, as shown in Table4(4), we begin stripping POS-tags off the ?less signifi-cant?
(non-head) end of the foreign POS-sequence untilwe are left with a phrase sequence that has been seen intraining, and from this a corresponding English phrasedistribution is observable.
We define the ?less signifi-cant?
end of a phrase to be the end if it is head-initial,or the beginning if it is head-final, and at this point ig-nore issues such as nested structure in French and ArabicNP?s.Aligned English POS-tag Sequence Translation Probabilities(conditioned on Arabic POS-tag sequence from NP in example)P ( DT?
JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.22P ( JJ4 NN1 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.20P ( DT?
NN1 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13P ( DT?
VBN4 NNS2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13P ( DT1 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.04P ( DT3 JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03P ( DT1 VBN4 NNS2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03P ( DT?
NN4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02P ( JJ4 NNS2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02P ( DT1 JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02P ( NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02P ( NN4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02Table 5: From the running Arabic example, top EnglishNP generations given an Arabic phrase DET NOUN-SGDET ADJ.
Note: ?
denotes a null alignment (generationfrom null).
Generation from a null alignment is allowedfor specified parts of speech, such as determiners andprepositions.4.3 Lexical Transfer4.3.1 The Basic ModelIn the basic model of word generation, phrases may betranslated directly as single atomic entities (as in Table4(1)), or via phrasal decomposition to individual wordstranslated independently, conditioned only on the sourceword and target POS.
Word translation in the latter caseTop-level Definition of Translation ModelExample Instantiation of Model Variables Model DescriptionP ( the sixth committee recommends the general assembly .. | P ( english words | foreign words ) =twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. ) =P ( [twSy]V P1 [Al- ljnp Al- sAdsp]NP1 [Al- jmEyp Al- EAmp]NP2 .. | (1) P ( foreign bracketing , foreign phrase sequence | foreign words )twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. )?P ( NP2 VP1 NP3 PPNP4 PUNC5 | (2) P ( english phrase sequence , phrase alignment matrix |VP1 NP2 NP3 PPNP4 PUNC5 ) foreign phrase sequence )?P ( [the sixth committee]NP2 [recommends]V P1 (3) P ( english words , english bracketing , english phrase sequence |[the general assembly]NP3 .. | foreign words , foreign bracketing , foreign phrase sequence ,[twSy]V P1 [Al- ljnp Al- sAdsp]NP1 [Al- jmEyp Al- EAmp]NP2 .. , english phrase sequence , phrase alignment matrix )NP2 VP1 NP3 PPNP4 PUNC5 )Table 2: Statement of the translation model at top level..Phrase Translation Model with Backoff PathwaysExample Instantiations Model StatementP ( the sixth committee | Al- ljnp Al- sAdsp , NP ) =P ( the sixth committee | Al- ljnp Al- sAdsp , NP ) (1) P ( WE1 WE2 .. WEn | WF1 WF2 .. WFm , phr typeE )?
?
(backoff if C( WF1 WF2 .. WFm , phr typeE) = 0)P ( DT1 JJ4 NN2 | DET1 NOUN-SG2 DET3 ADJ4 , NP ) (2) P ( TfineE1TfineE2.. TfineEn, ?i | TfineF1TfineF2.. TfineFm, phr typeE ).
?P ( the | Al- , DT ) .
?P ( WE1 | WF?i(1), TfineE1).
?P ( committee | ljnp , NN ) .
?P ( WE2 | WF?i(2), TfineE2).
?P ( sixth | sAdsp , JJ ) .
?..
?
P ( WEn | WF?i(n), TfineEn)?
?
(backoff if C( TfineF1TfineF2.. TfineFm, phr typeE) = 0)P ( DT1 JJ4 NN2 | D1 N2 D3 A4 , NP ) (3) P ( TfineE1TfineE2.. TfineEn, ?i | TcoarseF1TcoarseF2.. TcoarseFm, phr typeE ).
?P ( the | Al- , DT ) .
?P ( WE1 | WF?i(1), TfineE1).
?P ( committee | ljnp , NN ) .
?P ( WE2 | WF?i(2), TfineE2).
?P ( sixth | sAdsp , JJ ) .
?..
?
P ( WEn | WF?i(n), TfineEn)?
?
(backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm , phr typeE ) = 0)P ( ?
| D1 N2 D3 , NP ) (4) P ( TfineE1TfineE2.. TfineEn, ?i | TcoarseF1TcoarseF2.. TcoarseFm?1, phr typeE ).
* ?
* .. * ?
.
* ?
* .. * ??
?
(backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm?1 , phr typeE) = 0)P ( ?
| D1 N2 , NP ) (4) P ( TfineE1TfineE2.. TfineEn, ?i | TcoarseF1TcoarseF2.. TcoarseFm?2, phr typeE ).
* ?
* .. * ?
.
* ?
* .. * ??
?
(backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm?2 , phr typeE) = 0).... ....Table 4: The phrase translation model, with backoff.
Examples on the left side are from one of the Arabic testsentences.
(1) is the direct, lexical translation level.
(2) - (4) constitute the backoff path to handle detailed phenomenaunseen in the training set.
(2) is a model of fine POS-tag reordering and lexical generation; (3) is similar, but conditionsgeneration on coarse POS-tag sequences in the foreign language.
(4) is a model for progressively stripping off POS-tags from the ?less significant?
end of a foreign sequence.
The idea is to do this until we reach a subsequence that hasbeen seen in training data, and which we therefore have a distribution of valid generatons for.
The term ?i in (2) - (4)is a position alignment matrix.
At all times, we generate not just an English POS-tag sequence, but rather an alignedsequence.
Similarly, in the lexical transfer probabilities shown in this table, there is a function ?i() which takes anEnglish sequence position index and returns the (unique) foreign word position to which it is aligned4.Aligned English POS-tag Sequence Translation Probabilities(conditioned on Arabic POS-tag sequence from VP in example)P ( VBZ1 | VERB-IMP1 , VP ) = .28P ( VBP1 | VERB-IMP1 , VP ) = .17P ( VBD1 | VERB-IMP1 , VP ) = .09...P ( MD?
VB1 | VERB-IMP1 , VP ) = .06Table 6: From the Arabic example, top English VP gen-erations given an Arabic phrase VERB-IMP.is done in the context that the model has already pro-posed a sequence of POS tags for the phrase.
Thus weknow the English POS of the word we are trying to gen-erate in addition to the foreign word that is generating it.Consequently, we condition translation on English POSas well as the foreign word.
Table 7 describes the backoffpath for basic lexical transfer and presents a motivatingexample in the French word droit.
Translation probabili-ties for one of the words in the example Arabic sentencecan be found in Table 8.4.3.2 Generation via a Lemma ModelTo counter sparse data problems in estimating wordtranslation probabilities, we also implemented a lemma-Word GenerationExamples Model with Backoff PathwaysP (WE | droit , NNS) P (WE |WF , TfineE )rights 0.4389 p(rights | droit , NNS)benefits 0.0690people 0.0533laws 0.0188?
(backoff if C(WF , TfineE ) = 0)P (WE | droit , N) P (WE |WF , TcoarseE )right 0.4970law 0.1318rights 0.0424 p(rights | droit , N)property 0.0115?
(backoff if C(WF , TcoarseE ) = 0)P (WE | droit) P (WE |WF )right 0.2919entitled 0.0663law 0.0652the 0.0249to 0.0240rights 0.0210 p( rights | droit )?
(backoff if C(WF ) = 0)p( UNKNOWN WORD |WF ) = 1Table 7: Description of the conditioning for different lev-els of backoff in the lexical transfer model.
The exam-ple shows translations for the French word droit (?right?
)conditioned on decreasingly specific values.
The pro-gressively lower ranking of the correct translation as wemove from fine, to coarse, to no POS, illustrates the ben-efit of conditioning generation on the English part ofspeech.Arabic Word English POS English Wd.
Prob.ljnp NN committee 0.591ljnp NN commission 0.233ljnp NN subcommittee 0.035ljnp NN acc 0.013ljnp NN report 0.005ljnp NN ece 0.004ljnp NN icrc 0.004ljnp NN aalcc 0.004ljnp NN escap 0.004ljnp NN escwa 0.004ljnp NN eca 0.003ljnp NNS members 0.088ljnp NNS recommendations 0.033ljnp NNS copuos 0.033ljnp NNS questions 0.027ljnp NNS representatives 0.024ljnp N committee 0.577ljnp N commission 0.227ljnp N subcommittee 0.035Table 8: From running example, translation probabilities for Arabicnoun ljnp, ?committee?.based model for word translation.
Under this model,translation distributions are estimated by counting wordalignment links between foreign and English lemmas, as-suming a lemmatization of both sides of the parallel cor-pus as input.
The form of the model is illustrated below:P ( WE | WF ,TcoarseF ,TfineE ) =P ( WE | lemmaE , TcoarseF , TfineE )?P ( lemmaE | lemmaF , TcoarseF , TfineE )?P ( lemmaF | WF , TcoarseF , TfineE )?
approximated byP ( WE | lemmaE , TfineE )?P ( lemmaE | lemmaF , TcoarseE )?P ( lemmaF | WF , TcoarseF )First, note that P ( lemmaF | WF , TcoarseF ) is verysimply a hard lemma assignment by the foreign lan-guage lemmatizer.
Second, English word generationfrom English lemma and coarse POS (P ( WE | lemmaE, TfineE )) is programmatic, and can be handled bymeans of rules in conjunction with a lookup table forirregular forms.
The only distribution here that must beestimated from data is P ( lemmaE | lemmaF , TcoarseE).
This is done as described above.
Furthermore, givenan electronic translation dictionary, even this distributioncan be pre-loaded: indeed, we expect this to be anadvantage of the lemma model, and an example ofa good opportunity for integrating compiled humanknowledge about language into an SMT system.
Someexamples of the lemma model combating sparse dataproblems inherent in the basic word-to-word models canbe found in Table 9.4.3.3 CoercionLexical coercion is a phenomenon that sometimes occurswhen we condition translation of a foreign word on theword and the English part-of-speech.
We find that thesystem we have described frequently learns this behav-ior: specifically, the model learns in some cases howto generate, for instance, a nominal form with similarmeaning from a French adjective, or an adjectival real-ization of a French verb?s meaning; some examples ofthis phenomenon are shown in Table 10.
We find thiscoercion effect to be of interest because it identifies in-teresting associations of meaning.
For example, in Table10 ?willing?
and ?ready?
are both sensible ways to re-alize the meaning of the action ?to accept?
in a passive,descriptive mode.
droit behaves similarly.
Though theEnglish verb ?to right?
or ?to be righted?
does not havethe philosophical/judicial entitlement sense of the noun?right?, we see that the model has learned to realize themeaning in an active, verbal form: e.g., VBG ?receiving?and VB ?qualify?.5 DecodingDecoding was implemented by constructing finite-statemachines (FSMs) per evaluation sentence to encoderelevant portions (for the individual sentence in ques-tion) of the component translation distributions describedabove.
Operations on these FSMs are performed usingthe AT&T FSM Toolkit (Mohri et al, 1997).
The FSMconstructed for a test sentence is subsequently composedwith a FSM trigram language model created via the SRILanguage Modeling Toolkit (Stolcke, 2002).
Thus weuse the trigram language model to implement rescoringof the (direct) translation probabilities for the Englishword sequences in the translation model lattice.We found that using the finite-state framework and thegeneral-purpose AT&T toolkit greatly facilitates decoderdevelopment by freeing the implementation from detailsof machine composition and best-path searching, etc.The structure of the translation model finite-state ma-chines is as illustrated in Figure 1.
The sentence-level(aligned phrase sequence generation) and phrase-level(aligned intra-phrase sequence generation) translationprobabilities are encoded on epsilon arcs in the ma-chines.
Word translation probabilities are placed ontoarcs emitting the word as an output symbol (in the fig-ure, note the arcs emitting ?committee?, ?the?, etc.).
TheFSM in Figure 1 corresponds to the Arabic example sen-tence used throughout this paper.
In the portion of themachine shown, the (best) path which generated the ex-ample sentence is drawn in bold.
Finally, Figure 2 isa rendering of the actual FSM (aggressively pruned fordisplay purposes) that generated the example Arabic sen-tence; although labels and details are not visible, it mayprovide a visual aid for better understanding the structureof the FSM lattices generated here.As a practical matter in decoding, during translationmodel FSM construction we modified arc costs for out-put words in the following way: a fixed bonus was as-signed for generating a ?content?
word translating to a?content?
word.
Determining what qualifies as a con-tent word was done on the basis of a list of content POStags for each language.
For example, all types of nouns,verbs and adjectives were listed as content tags; deter-miners, prepositions, and most other closed-class parts ofspeech were not.
This implements a reasonable penaltyon undesirable output sentence lengths.
Without such apenalty, translation outputs tend to be very short: longsentence hypotheses are penalized de facto merely bycontaining many word translation probabilities.
An ad-ditional trick in decoding is to use only the N-best trans-lation options for sentence-level, phrase-level, and word-level translation.
We found empirically (and very consis-tently) in dev-test experiments that restricting the syntac-tic transductions to a 30-best list and word translations toa 15-best list had no negative impact on Bleu score.
Thebenefit, of course, is that the translation lattices are dra-matically reduced in size, speeding up composition andsearch operations.......etc ...... next phrase,......SP(the | NULL)P(an | NULL) P(committee | ljnp)P(commission | ljnp)NULLP( DT       NN      |   NOUN?SG    )11 1P(NP    VP    NP  .. |VP   NP   NP  .. )32"commission""committee""the""an"12 3Figure 1: An illustration of the translation model structure for anArabic test sentence.319 321W__:the/-001S__:<s>/5.4112S__:<s>/5.6293S__:<s>/5.8354S__:<s>/5.8685S__:<s>/5.9406S__:<s>/6.2267S__:<s>/6.3818S__:<s>/6.3859S__:<s>/6.39610S__:<s>/6.52911S__:<s>/6.54612S__:<s>/6.62013S__:<s>/6.65714S__:<s>/6.69815S__:<s>/6.71116S__:<s>/6.71717S__:<s>/6.74818S__:<s>/6.82519S__:<s>/6.87520S__:<s>/6.94221S__:<s>/6.946116137W__:committee/-0224247P__ADJP:<epsilon>/-0412 439T__-:<epsilon>/0.129702714W__:of/1.969W__:in/2.21522P__NP:<epsilon>/-0117138G__:<epsilon>/-0225 248G__:<epsilon>/-0272 273W__:general/-0413440T__recommends:<epsilon>/0.227474501W__:the/1.188W__:a/1.736W__:this/2.266703715W__:on/2.917W__:of/1.969W__:against/4.731W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:after/4.880W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:between/4.602W__:like/4.665W__:during/4.572W__:whether/4.697W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410W__:within/4.766521555W__:of/1.969558590W__:the/0.132631630W__:rapporteur/0.699W__:decision/1.00023P__NP:<epsilon>/-0118139G__:<epsilon>/-0226227W__:committee/-0322W__:assembly/-0414 441T__recommends:<epsilon>/0.227522 556W__:of/1.969W__:in/2.215525559P__O:<epsilon>/-024P__NP:<epsilon>/-0119 140P__O:<epsilon>/-0249G__:<epsilon>/-0415442T__2:<epsilon>/0.631443T__2#xslax/NULL:<epsilon>/1.194632 647P__NP:<epsilon>/-0367G__:<epsilon>/-0523557W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410592T__::<epsilon>/0.028704716W__:of/1.969W__:in/2.215W__:that/2.614W__:for/2.66025P__O:<epsilon>/-0228 229W__:sixth/-0416444T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545445T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133446T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895475 502G__:<epsilon>/-0633648P__VP:<epsilon>/-0120141P__NP:<epsilon>/-0560561W__:the/-0705717P__O:<epsilon>/-026P__NP:<epsilon>/-0417 447T__-:<epsilon>/0.129476 503P__NP:<epsilon>/-0634635W__:draft/0.404W__:project/1.841121142G__:<epsilon>/-0230251P__VP:<epsilon>/-0323325W__:by/-027P__NP:<epsilon>/-0524W__:of/1.969W__:in/2.215593W__:sixth/-0122 143G__:<epsilon>/-0324 W__:to/-0477504W__:adoption/0.711W__:provision/1.929532G__:<epsilon>/-60706718W__:police/-028P__ADJP:<epsilon>/-0231252G__:<epsilon>/-0418448W__:-/-0526T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.871T__sixth#committee:<epsilon>/1.871562534W__:by/-0123 144P__O:<epsilon>/-029P__NP:<epsilon>/-0232253W__:adoption/0.711W__:provision/1.929527 T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085563T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254 W__:to/-0636 649P__ADJP:<epsilon>/-0327W__:the/-0419 W__:2/-030P__NP:<epsilon>/-0124 145P__O:<epsilon>/-0528 565T__-:<epsilon>/0.129573W__:-/-0637650W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:that/4.161W__:with/1.853W__:for/3.134W__:as/2.616326328W__:the/-0420 449W__:2/-0707696W__:in/-031P__NP:<epsilon>/-032P__VP:<epsilon>/-033P__SBAR:<epsilon>/-0529 566W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:from/3.270W__:as/3.201W__:about/3.426594W__:the/1.188W__:that/2.597W__:a/1.736W__:this/2.266638 651W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:that/4.161W__:with/1.853W__:for/3.134W__:as/2.616125146G__:<epsilon>/-0421450W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.61634P__NP:<epsilon>/-0329T__the/NULL#general#assembly:<epsilon>/0.938369T__had#decided:<epsilon>/2.442370T__will#consider:<epsilon>/2.442639652W__:in/1.425708 719W__:world/-0104 126G__:<epsilon>/-0422451W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616530 567W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:from/3.270W__:as/3.20135P__NP:<epsilon>/-0330W__:decided/-0478505W__:adoption/0.711W__:provision/1.929640653W__:on/2.046W__:by/1.908W__:in/1.425W__:with/1.853709 720P__VP:<epsilon>/-0423452W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.61636P__NP:<epsilon>/-0233254W__:adoption/0.711W__:provision/1.929331W__:consider/-0531 568W__:on/2.917W__:of/1.969W__:by/2.975W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660641654W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:that/4.161W__:with/1.853W__:for/3.134W__:as/2.616710721P__O:<epsilon>/-0147P__VP:<epsilon>/-0148P__PPNP:<epsilon>/-0424453W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.61637P__O:<epsilon>/-0332307W__:to/-0533 570T__accountable:<epsilon>/0.693571T__present/NULL:<epsilon>/0.693642655W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.853127P__PPNP:<epsilon>/-0149P__NP:<epsilon>/-0425454W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.61638P__O:<epsilon>/-0333 371W__:with/-0537W__:the/-0711722W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:every/4.241W__:another/4.082128 P__VP:<epsilon>/-0426455W__:in/1.42539P__O:<epsilon>/-0535538W__:the/-0595W__:following/0.227129 150P__O:<epsilon>/-0334372W__:next/1.854W__:following/0.227427456W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616643656T__to/NULL#2/NULL:<epsilon>/1.299T__to/NULL#2:<epsilon>/2.397657T__with/NULL#article/NULL#2:<epsilon>/2.397658T__under/NULL#review/NULL:<epsilon>/3.091659T__by/NULL#2#police/NULL#officers/NULL:<epsilon>/3.091660T__in/NULL#only/NULL#2:<epsilon>/3.091661T__in/NULL#order/NULL:<epsilon>/3.091662T__for/NULL#just/NULL#2:<epsilon>/3.091663T__on/NULL#2:<epsilon>/3.091664T__at/NULL#2:<epsilon>/3.091665T__with/NULL#regard/NULL:<epsilon>/3.091666T__for/NULL#2:<epsilon>/3.091667T__to/NULL#2.7/NULL#in/NULL:<epsilon>/3.091668T__in/NULL#document:<epsilon>/3.091669T__into/NULL#the/NULL#world/NULL#economy/NULL:<epsilon>/3.09140P__NP:<epsilon>/-0479506W__:adoption/0.711W__:provision/1.929428457W__:in/1.425536 572W__:the/-041P__PPNP:<epsilon>/-0130 151P__NP:<epsilon>/-0234255W__:adoption/0.711W__:provision/1.929429458W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.20142P__VP:<epsilon>/-0131152G__:<epsilon>/-0539574W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201644 670T__-:<epsilon>/0.12943P__NP:<epsilon>/-0132153P__PPNP:<epsilon>/-0645646W__:the/-044P__NP:<epsilon>/-0133154P__VP:<epsilon>/-0480508W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18235257P__NP:<epsilon>/-0335373W__:rapporteur/0.699W__:decision/1.000W__:the/0.13245T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87146T__sixth#committee:<epsilon>/1.871134155P__NP:<epsilon>/-0671W__:sixth/-0236258P__NP:<epsilon>/-047T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87148T__sixth#committee:<epsilon>/1.871135156G__:<epsilon>/-0430459W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201336374W__:2/-049T__2:<epsilon>/0.63150T__2#xslax/NULL:<epsilon>/1.194136157G__:<epsilon>/-0237259G__:<epsilon>/-0337375W__:2/-051T__-:<epsilon>/0.129T__-/NULL:<epsilon>/2.988158G__:<epsilon>/-0238260G__:<epsilon>/-0569P__O:<epsilon>/-0287338W__:sixth/-0672T__2:<epsilon>/0.631673T__2#xslax/NULL:<epsilon>/1.19452T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87153T__sixth#committee:<epsilon>/1.871159P__VP:<epsilon>/-0239261G__:<epsilon>/-0596T__::<epsilon>/0.028376W__:committee/-0674T__recommends:<epsilon>/0.22754T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87155T__sixth#committee:<epsilon>/1.871160P__VP:<epsilon>/-0240262P__PPNP:<epsilon>/-0481509W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18W__:accountable/-0431460W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:some/3.097W__:this/2.266W__:these/3.201540575W__:next/1.854W__:following/0.22756T__asean/NULL:<epsilon>/1.09857T__imf-2:<epsilon>/1.09858T__concerned/NULL#with/NULL:<epsilon>/1.098161T__-:<epsilon>/0.129241263P__NP:<epsilon>/-0339377W__:committee/-0W__:present/-059T__2:<epsilon>/0.63160T__2#xslax/NULL:<epsilon>/1.194162T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.871163T__sixth#committee:<epsilon>/1.871242264T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085T__by/NULL#the#general#assembly:<epsilon>/2.725265T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254T__to/NULL#the#general#assembly:<epsilon>/2.748266T__with/NULL#general#assembly#decision/NULL:<epsilon>/3.313340 342W__:the/-0W__:general/-0675T__asean/NULL:<epsilon>/1.098676T__imf-2:<epsilon>/1.098677T__concerned/NULL#with/NULL:<epsilon>/1.09861T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87162T__sixth#committee:<epsilon>/1.871164P__VP:<epsilon>/-0243267P__VP:<epsilon>/-0341343W__:the/-0W__:assembly/-0678W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:every/4.241W__:another/4.08263T__728#xslax/NULL:<epsilon>/1.42164T__the/NULL#committee:<epsilon>/1.981 65T__the/NULL#advisory#committee:<epsilon>/2.26866T__729#xslax/NULL:<epsilon>/2.674165P__VP:<epsilon>/-0244268P__NP:<epsilon>/-0564W__:wish/-0344 346W__:the/-067T__recommends:<epsilon>/0.227166T__-:<epsilon>/0.129245269P__NP:<epsilon>/-0432461W__:the/1.188345347W__:the/-0597G__:<epsilon>/-0712723W__:next/1.854W__:following/0.22768T__that:<epsilon>/-0167T__-:<epsilon>/0.129246270T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.122271T__the/NULL#assembly:<epsilon>/1.941433462W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:that/4.161W__:with/1.853W__:for/3.134W__:as/2.616482510W__:adoption/0.711348368W__:accountable/-0598W__:next/1.854W__:following/0.22769T__2:<epsilon>/0.63170T__2#xslax/NULL:<epsilon>/1.194168P__VP:<epsilon>/-0274T__accountable:<epsilon>/0.693275T__present/NULL:<epsilon>/0.693434463W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:that/4.161W__:with/1.853W__:for/3.134W__:as/2.616483511W__:adoption/0.711W__:provision/1.929349 W__:present/-072T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87173T__sixth#committee:<epsilon>/1.871169T__the/NULL#sixth#committee:<epsilon>/0.154170T__will#establish:<epsilon>/1.945276P__PPNP:<epsilon>/-0435464W__:in/1.425350380W__:2/-0541W__:the/0.132679W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:every/4.241W__:another/4.08274T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.12275T__the/NULL#assembly:<epsilon>/1.941171T__by/NULL#the/NULL#sixth#committee:<epsilon>/0.490T__by/NULL#the/NULL#sixth/NULL#committee:<epsilon>/1.589436465W__:in/1.425277P__NP:<epsilon>/-0351W__:article/-078T__-:<epsilon>/0.129172T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.871173T__sixth#committee:<epsilon>/1.871437466W__:on/2.046W__:of/2.238W__:by/1.908W__:under/3.942W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616250W__:committee/-0352W__:review/-071T__-:<epsilon>/0.129438467W__:in/1.425W__:with/1.853278G__:<epsilon>/-0353381W__:2/-079T__-:<epsilon>/0.129174T__-:<epsilon>/0.129468W__:-/-0599W__:rapporteur/0.699W__:decision/1.000T__the/NULL#general#assembly:<epsilon>/0.938279T__had#decided:<epsilon>/2.442280T__will#consider:<epsilon>/2.442354 W__:only/-080T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.871 81T__sixth#committee:<epsilon>/1.871175T__2:<epsilon>/0.631176T__2#xslax/NULL:<epsilon>/1.194W__:recommends/-0484512W__:adoption/0.711281P__PPNP:<epsilon>/-0355 W__:order/-082T__to/NULL#2/NULL:<epsilon>/1.299177P__VP:<epsilon>/-0469W__:recommends/-0485514W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410576600W__::/-0680W__:the/1.188282W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:per/3.988356 W__:just/-0507542P__O:<epsilon>/-083T__add:<epsilon>/1.70484T__take/NULL:<epsilon>/2.397178T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545179T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133180T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895470W__:2/-0577601W__:next/1.854W__:following/0.227681W__:the/1.188W__:a/1.736T__::<epsilon>/0.02885T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87186T__sixth#committee:<epsilon>/1.871181T__add:<epsilon>/1.704182T__take/NULL:<epsilon>/2.397283W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:per/3.988471W__:2/-0357 W__:regard/-0486515W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:per/3.988543W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.20187T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.87188T__sixth#committee:<epsilon>/1.871183T__2:<epsilon>/0.631184T__2#xslax/NULL:<epsilon>/1.194472W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.853W__:as/2.616284W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:from/3.270W__:as/3.201W__:about/3.426W__:if/3.704682W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:another/4.082W__:the/-0185P__VP:<epsilon>/-0358 382W__:2.7/-0473W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.853W__:as/2.616487516W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:per/3.988W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075186P__VP:<epsilon>/-0286T__the/NULL#sixth#committee:<epsilon>/0.454359 W__:document/-0W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.85389W__:sixth/-0488517W__:of/1.969187P__VP:<epsilon>/-0288T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.871289T__sixth#committee:<epsilon>/1.871360383W__:the/-0W__:-/-0W__:the/-0490519W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18188T__recommends:<epsilon>/0.227189T__recommended:<epsilon>/2.759290P__NP:<epsilon>/-0361384G__:<epsilon>/-0G__:<epsilon>/-0578602W__:rapporteur/0.699W__:decision/1.000713 724W__:the/1.18890W__:sixth/-0190T__recommends:<epsilon>/0.227191T__recommended:<epsilon>/2.759192T__recommend:<epsilon>/3.200291P__NP:<epsilon>/-0362W__:xslax/-0W__:xslax/-0580 604W__:sponsors/1.13191W__:2/-0193W__:-/-0292P__ADJP:<epsilon>/-0683W__:the/1.188W__:a/1.736725W__:following/0.227363385W__:assembly/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.20192W__:2/-0W__:the/-0293T__to/NULL#2/NULL:<epsilon>/1.299T__to/NULL#2:<epsilon>/2.397294T__with/NULL#article/NULL#2:<epsilon>/2.397295T__under/NULL#review/NULL:<epsilon>/3.091296T__by/NULL#2#police/NULL#officers/NULL:<epsilon>/3.091297T__in/NULL#only/NULL#2:<epsilon>/3.091298T__in/NULL#order/NULL:<epsilon>/3.091299T__for/NULL#just/NULL#2:<epsilon>/3.091300T__on/NULL#2:<epsilon>/3.091301T__at/NULL#2:<epsilon>/3.091302T__with/NULL#regard/NULL:<epsilon>/3.091303T__for/NULL#2:<epsilon>/3.091304T__to/NULL#2.7/NULL#in/NULL:<epsilon>/3.091305T__in/NULL#document:<epsilon>/3.091306T__into/NULL#the/NULL#world/NULL#economy/NULL:<epsilon>/3.091579 603W__:following/0.227364386G__:<epsilon>/-0W__:the/0.132W__:a/3.06693W__:-/-0T__2:<epsilon>/0.631308T__2#xslax/NULL:<epsilon>/1.194309T__it/NULL:<epsilon>/3.818581 605W__:2/-0194W__:sixth/-0W__:by/-0582 606W__:2/-0W__:to/-0W__:the/-0195T__recommends:<epsilon>/0.227316317W__:general/-0491520W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18W__:to/-0583607W__:rapporteur/0.699W__:decision/1.000685W__:with/-0196T__recommends:<epsilon>/0.227197T__recommended:<epsilon>/2.759365W__:assembly/-094W__:sixth/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:some/3.097W__:this/2.266W__:these/3.201198W__:-/-0544W__:next/1.854W__:following/0.227584608W__:implications/2.139W__:sponsors/1.131W__:projects/2.972686W__:under/-0W__:the/-0310W__:with/-0387G__:<epsilon>/-0199W__:-/-0687W__:by/-0311T__recommends:<epsilon>/0.227312T__recommended:<epsilon>/2.759313T__recommend:<epsilon>/3.200320W__:general/-0585586W__:draft/0.40495W__:sixth/-0200T__recommends:<epsilon>/0.227688W__:in/-0314T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.122315T__the/NULL#assembly:<epsilon>/1.941366W__:assembly/-0587 610G__:<epsilon>/-096W__:asean/-0201W__:the/-0689W__:in/-0318T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.122T__the/NULL#assembly:<epsilon>/1.941588611W__:next/1.854W__:following/0.227W__:imf-2/-0202W__:will/-0388G__:<epsilon>/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:an/2.837W__:some/3.097W__:this/2.266492W__:adoption/0.711690W__:for/-0W__:the/-097W__:concerned/-0203W__:by/-0389P__PPNP:<epsilon>/-0493W__:adoption/0.711W__:on/-0W__:the/-098W__:2/-0494 W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18W__:at/-0W__:the/-099W__:2/-0W__:accountable/-0W__:general/-0691W__:with/-0W__:the/-0 204W__:sixth/-0W__:present/-0W__:assembly/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:for/-0205W__:-/-0T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085T__by/NULL#the#general#assembly:<epsilon>/2.725T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254T__to/NULL#the#general#assembly:<epsilon>/2.748692W__:to/-0100W__:sixth/-0390G__:<epsilon>/-0589612W__:rapporteur/0.699W__:decision/1.000W__:2/-0T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.122T__the/NULL#assembly:<epsilon>/1.941693W__:in/-0101W__:728/-0W__:the/0.132206W__:2/-0P__VP:<epsilon>/-0391W__:had/-0545 W__:following/0.227613W__:following/0.227694W__:into/-0102W__:the/-0207T__recommends:<epsilon>/0.227392W__:will/-0495W__:adoption/0.711546W__:the/0.132591614W__:sponsors/1.131684W__:-/-0103W__:the/-0W__:had/-0208W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201496 P__NP:<epsilon>/-0726T__::<epsilon>/0.028W__:729/-0W__:will/-0695W__:committee/-0209W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616497 P__PPNP:<epsilon>/-0615W__::/-0W__:officers/-0105W__:recommends/-0T__to/NULL#2/NULL:<epsilon>/1.299T__to/NULL#2:<epsilon>/2.397T__with/NULL#article/NULL#2:<epsilon>/2.397W__:article/-0W__:2/-0210W__:on/2.046W__:of/2.238W__:by/1.908W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616498 P__O:<epsilon>/-0106W__:that/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:some/3.097W__:this/2.266W__:these/3.201 393W__:rapporteur/0.699W__:decision/1.000616W__:committee/-0697W__:2/-0W__:economy/-0211W__:add/-0107W__:2/-0499 W__:adoption/0.711W__:provision/1.929W__:recommends/-0728T__recommends:<epsilon>/0.227W__:take/-0394W__:implications/2.139W__:sponsors/1.131W__:projects/2.972W__:of/-0108W__:2/-0W__:asean/-0727T__-:<epsilon>/0.129T__-/NULL:<epsilon>/2.988212W__:2/-0W__:the/1.188W__:the/-0395G__:<epsilon>/-0W__:imf-2/-0729W__:next/1.854W__:following/0.227213W__:2/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201500W__:adoption/0.711W__:provision/1.929617W__:following/0.227W__:xslax/-0698W__:concerned/-0110W__:sixth/-0214T__recommends:<epsilon>/0.227396G__:<epsilon>/-0699W__:adoption/0.711W__:provision/1.929W__:approval/3.758W__:appropriation/3.108W__:accreditation/3.18W__:dependence/3.758W__:reliance/3.74676W__:the/-0215T__recommends:<epsilon>/0.227W__:adoption/0.711547 W__:the/0.132397G__:<epsilon>/-0513 548P__NP:<epsilon>/-0618W__:rapporteur/0.699W__:decision/1.00077W__:the/-0216T__recommends:<epsilon>/0.227W__:general/-0T__2:<epsilon>/0.631T__2#xslax/NULL:<epsilon>/1.194217W__:recommends/-0P__ADJP:<epsilon>/-0619W__::/-0112W__:-/-0378W__:assembly/-0W__:the/1.188549W__:next/1.854W__:following/0.227W__:recommended/-0W__:next/1.854W__:following/0.227T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.122T__the/NULL#assembly:<epsilon>/1.941T__the#assembly:<epsilon>/3.641T__the/NULL#wish/NULL#of/NULL#the/NULL#general#assembly:<epsilon>/3.421109W__:-/-0W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18218W__:recommends/-0398G__:<epsilon>/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:per/3.988113W__:-/-0620P__PPNP:<epsilon>/-0730W__:rapporteur/0.699W__:decision/1.000W__:recommended/-0W__:general/-0W__:the/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:per/3.988621W__:rapporteur/0.699W__:decision/1.000W__:recommend/-0379W__:assembly/-0731W__:following/0.227700W__:adoption/0.711W__:provision/1.929W__:approval/3.758W__:appropriation/3.108W__:accreditation/3.18W__:dependence/3.758W__:reliance/3.746114W__:sixth/-0219G__:<epsilon>/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:from/3.270W__:as/3.201W__:about/3.426W__:if/3.704622W__:implications/2.139W__:sponsors/1.131W__:projects/2.972732W__:sponsors/1.131399G__:<epsilon>/-0W__:to/-0220W__:committee/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:between/4.602W__:during/4.572W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410550W__:rapporteur/0.699W__:decision/1.000623G__:<epsilon>/-0W__:add/-0221W__:recommends/-0400G__:<epsilon>/-0W__:adoption/0.711W__:provision/1.929624W__:rapporteur/0.699W__:decision/1.000733W__::/-0W__:take/-0222W__:recommends/-0W__:the/0.132551W__:following/0.227W__:the/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410625W__:implications/2.139W__:sponsors/1.131W__:projects/2.972W__:recommended/-0401W__:police/-0552 W__::/-0W__:recommends/-0115W__:sixth/-0223G__:<epsilon>/-0553W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:draft/0.404W__:-/-0W__:the/-0G__:<epsilon>/-0W__:of/1.969626W__:of/1.969701W__:adoption/0.711734W__:rapporteur/0.699W__:decision/1.000W__:recommends/-0W__:in/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:into/3.971W__:about/3.426W__:if/3.704W__:than/4.147W__:per/3.988627G__:<epsilon>/-0W__:adoption/0.711W__:sixth/-0W__:sixth/-0W__:adoption/0.711W__:provision/1.929W__:xslax/-0735W__:articles/3.975W__:implications/2.139W__:sponsors/1.131W__:projects/2.972W__:co-sponsors/3.808402W__:world/-0W__:of/1.969W__:adoption/0.711W__:provision/1.929W__:appropriation/3.108W__:accreditation/3.18W__:committee/-0W__:establish/-0256285P__NP:<epsilon>/-0W__:draft/0.404W__:project/1.841403P__O:<epsilon>/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:draft/0.404W__:the/-0T__2:<epsilon>/0.631T__2#xslax/NULL:<epsilon>/1.194W__:committee/-0489G__:<epsilon>/-60736W__:of/1.969W__:in/2.215W__:that/2.614W__:for/2.660W__:the/-0W__:decision/-0G__:<epsilon>/-0W__:committee/-0 737G__:<epsilon>/-0W__:the/-0404P__NP:<epsilon>/-0W__:xslax/-0G__:<epsilon>/-0609W__:of/1.969405P__PPNP:<epsilon>/-0W__:adoption/0.711G__:<epsilon>/-0W__:sixth/-0W__:rapporteur/0.699W__:draft/0.404W__:resolution/3.339W__:project/1.841W__:xslax/-0406P__PPNP:<epsilon>/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201T__the/NULL#general#assembly:<epsilon>/0.530T__the#general#assembly:<epsilon>/2.122T__the/NULL#assembly:<epsilon>/1.941628P__NP:<epsilon>/-0W__:committee/-0W__:recommends/-0407T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545408T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133409T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895410T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049W__:adoption/0.711G__:<epsilon>/-60T__the/NULL#general#assembly:<epsilon>/0.530T__the/NULL#assembly:<epsilon>/1.941629W__:rapporteur/0.699W__:decision/1.000W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:some/3.097W__:this/2.266W__:these/3.201411P__PPNP:<epsilon>/-0W__:committee/-0T__accountable:<epsilon>/0.693T__present/NULL:<epsilon>/0.693W__:decided/-0W__:implications/2.139W__:sponsors/1.131W__:projects/2.972W__:co-sponsors/3.808W__:article/-0G__:<epsilon>/-0W__:to/-0W__:consider/-0W__:review/-0W__:with/-0W__:draft/0.404W__:rapporteur/0.699W__:decision/1.000W__:with/-0554W__:next/1.854W__:following/0.227W__:2/-0W__:draft/0.404W__:project/1.841W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:of/1.969W__:in/2.215G__:<epsilon>/-0W__:under/-0W__:only/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:some/3.097W__:this/2.266W__:these/3.201W__:next/1.854W__:following/0.227G__:<epsilon>/-0W__:xslax/-0W__:by/-0G__:<epsilon>/-60W__:order/-0738/0<epsilon>:</s>/-0G__:<epsilon>/-0W__:in/-0W__:just/-0W__:committee/-0W__:rapporteur/0.699W__:decision/1.000W__:in/-0P__O:<epsilon>/-0W__:xslax/-0W__:implications/2.139W__:sponsors/1.131W__:for/-0W__:regard/-0W__:committee/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:an/2.837W__:some/3.097W__:this/2.266P__VP:<epsilon>/-0W__:on/-0W__:the/1.188G__:<epsilon>/-0W__:advisory/-0P__VP:<epsilon>/-0W__:2.7/-0W__:at/-0W__:the/1.188T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NGEN+IN#NN:<epsilon>/4.443T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049P__NP:<epsilon>/-0W__:document/-0G__:<epsilon>/-0W__:with/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:those/3.154W__:all/3.201W__:an/2.837W__:no/3.547W__:any/3.434W__:some/3.097W__:this/2.266W__:these/3.201W__:draft/0.404W__:project/1.841P__PPNP:<epsilon>/-0W__:the/-0G__:<epsilon>/-0W__:for/-0G__:<epsilon>/-0P__O:<epsilon>/-0G__:<epsilon>/-60G__:<epsilon>/-0G__:<epsilon>/-0W__:to/-0W__:officers/-0W__:the/0.132G__:<epsilon>/-0W__:xslax/-0G__:<epsilon>/-0W__:in/-0P__PPNP:<epsilon>/-0G__:<epsilon>/-0G__:<epsilon>/-0W__:xslax/-0W__:into/-0W__:economy/-0W__:draft/0.404W__:project/1.841W__:xslax/-0W__:recommends/-0W__:2/-0T__-:<epsilon>/0.129T__-/NULL:<epsilon>/2.988W__:the/1.188W__:the/1.188W__:committee/-0W__:recommends/-0W__:2/-0W__:following/0.227G__:<epsilon>/-60W__:general/-0T__2:<epsilon>/0.631T__2#xslax/NULL:<epsilon>/1.194G__:<epsilon>/-0W__:recommends/-0W__:it/-0W__:with/-0111W__:assembly/-0T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895W__:the/0.132G__:<epsilon>/-0G__:<epsilon>/-0W__:on/2.917W__:of/1.969W__:against/4.731W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:after/4.880W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:up/5.208W__:without/5.054W__:since/5.054W__:so/5.103W__:through/4.435W__:into/3.971W__:about/3.426W__:between/4.602W__:like/4.665W__:during/4.572W__:whether/4.697W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410W__:within/4.766W__:upon/5.054W__:across/5.208T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049W__:rapporteur/0.699G__:<epsilon>/-0W__:general/-0G__:<epsilon>/-0G__:<epsilon>/-0W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616P__O:<epsilon>/-0G__:<epsilon>/-0W__:recommends/-0W__:xslax/-0W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616G__:<epsilon>/-0W__:recommended/-0W__:the/1.188W__:that/2.597W__:a/1.736W__:this/2.266W__:the/0.132P__PPNP:<epsilon>/-0W__:on/2.046W__:of/2.238W__:by/1.908W__:at/3.536W__:in/1.425W__:with/1.853W__:for/3.134W__:as/2.616518P__O:<epsilon>/-0W__:recommend/-0W__:on/2.917W__:of/1.969W__:against/4.731W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:after/4.880W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:without/5.054W__:since/5.054W__:through/4.435W__:into/3.971W__:about/3.426W__:between/4.602W__:like/4.665W__:during/4.572W__:whether/4.697W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410W__:within/4.766W__:upon/5.054W__:committee/-0G__:<epsilon>/-0W__:in/1.425T__::<epsilon>/0.028W__:the/-0T__the/NULL#sixth#committee:<epsilon>/0.454T__the#sixth#committee:<epsilon>/1.871T__sixth#committee:<epsilon>/1.871G__:<epsilon>/-0T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NGEN+IN#NN:<epsilon>/4.443T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049W__:on/2.917W__:of/1.969W__:against/4.731W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:between/4.602W__:like/4.665W__:during/4.572W__:whether/4.697W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410W__:within/4.766W__:the/-0W__:draft/0.404W__:project/1.841G__:<epsilon>/-0W__:the/1.188W__:a/1.736W__:this/2.266W__:committee/-0W__:the/-0G__:<epsilon>/-60P__NP:<epsilon>/-0W__:on/2.917W__:of/1.969W__:by/2.975W__:under/4.248W__:at/3.201W__:in/2.215W__:that/2.614W__:before/4.435W__:with/3.075W__:for/2.660W__:because/4.073W__:from/3.270W__:as/3.201W__:through/4.435W__:into/3.971W__:about/3.426W__:between/4.602W__:like/4.665W__:during/4.572W__:whether/4.697W__:if/3.704W__:than/4.147W__:over/4.385W__:per/3.988W__:out/4.410W__:of/1.969W__:in/2.215Figure 2: A portion of the translation model for an Arabic test sen-tence, compacted and aggressively pruned by path probability for dis-play purposes.6 EvaluationResults Tables A and B below list evaluation results fortranslation on the Arabic and French test sets respec-tively.
In each case, results for a comparison system ?the Giza++ IBM Model 4 implementation (Och and Ney,2000) with the ReWrite decoder (Marcu and Germann,2002) ?
are included as a benchmark.
Results were gen-erated for training corpora of varying sizes.
For Arabic,we ran our system on two large subsets of the UN cor-pus and evaluated on a 200-sentence held-out set (referto Results Table A below).
For the 150K sentence Ara-bic training set, Giza++ and the shallow syntax modelachieved very similar performance.
We were unable toobtain evaluation numbers for Giza++/ReWrite on thelarge Arabic training set, however, since its languagemodel component has a vocabulary size limit which wasexceeded in the larger corpus.
In French we observed thesystems to perform similarly on the small training setswe used (Results Table B).
We performed some exper-iments in classifier combination using the two compat-ible (150K-training-sentence) Arabic systems, whereina small devtest set was used to identify simple systemcombination parameters based on model confidence andsentence length.
In situations where our system was con-fident we used its output, and used Giza++ output other-wise.
We achieved a 3% boost in Bleu score over Giza++performance on the evaluation set with these very sim-ple classifier combination techniques, and anticipate thatresearch in this direction ?
classifier combination of di-versely trained SMT systems ?
could yield significantperformance improvements.Bleu ScoreSystem 150K 500KTrn.
Sent.
Trn.
Sent.Giza++/ReWrite Decoder 0.17 *2-level Syntax Model 0.17 0.18Results Table A: Results comparison for Arabic to Englishtranslation on the UN corpus, with a 200-sentence evaluationset.
Note that Giza++/ReWrite cannot be run for the 500Ksentence training set; the CMU Language Modeling Toolkit,which ReWrite uses, has a vocabulary size limit which isexceeded in the 500K corpus.Bleu ScoreSystem 5K 20KTrn.
Sent.
Trn.
Sent.Giza++/ReWrite Decoder 0.08 0.112-level Syntax Model 0.08 0.09Results Table B: Results comparison for French to Englishtranslation on the Canadian Hansards corpus (200-sentenceevaluation set).7 ConclusionsWe have described and implemented an original syntax-based statistical translation model that yields baseline re-sults which compete successfully with other state-of-the-art SMT models.
This is particularly encouraging in thatthe authors are not well-versed in Arabic or French andit appears that the quality of the rule-based phrase chun-kers we developed in a single person-day offers substan-tial room for improvement.
We expect to be able to at-tain improved bracketings from native speakers and, inaddition, via translingual projection of existing brack-eters.
Secondly, the lemma model we have proposed forlexical transfer provides an efficient framework for in-tegrating electronic dictionaries into SMT models.
Al-though we have at this time no large electronic dictionar-ies for either Arabic or French, efforts are underway toacquire electronic or scanned paper dictionaries for thispurpose.
We did evaluate the lemma models in isola-tion for French and Arabic without dictionary inclusion,but in each experiment the results did not differ signifi-cantly from the word-specific lexical transfer models, de-spite their substantially reduced dimensionality.
We an-ticipate that the relatively seamless direct incorporationof dictionaries into the lemma-based models will be par-ticularly effective for translating low-density languages,which suffer from data sparseness in the face of limitedparallel text.
Finally, we incorporated lexical translationcoercion models into this full SMT framework, the in-duction of which is a phenomenon of interest in its ownright.8 AcknowledgementsThis work was supported in part by NSF grant number IIS-9985033.
Inaddition, we owe many thanks to colleagues who generously lent theirtime and insights.
David Smith shared his tools for Arabic part-of-speech tagging and morphological analysis and answered many ques-tions about the Arabic language.
Thanks to Skankar Kumar and San-jeev Khudanpur for numerous helpful discussions.9 ReferencesH.
Alshawi, S. Bangalore, and S. Douglas.
2000.
Learning depen-dency translation models as collections of finite state head transducersComputational Linguistics, 26(1), 45?60.S.
Bangalore and G. Riccardi.
2000.
Stochastic finite-state models forspoken language machine translation.
In Proceedings of the Workshopon Embedded Machine Translation Systems., pp.
52?59.P.
Brown, S. Della Pietra, V. Della Pietra and R. Mercer.
1993.
Themathematics of statistical machine translation: Parameter estimation.Computational Linguistics, 12(2), 263?312.S.
Cucerzan and D. Yarowsky.
2002.
Bootstrapping a MultilingualPart-of-speech Tagger in One Person-day.
Proceedings of the SixthConference on Natural Language Learning (CoNLL), Taipei, 2002.B.
Dorr and N. Habash.
2002.
Interlingua approximation: Ageneration-heavy approach.
In Proceedings of AMTA-2002.W.
A. Gale and K. W. Church.
1991.
A Program for AligningSentences in Bilingual Corpora.
In 29th Annual Meeting of the ACL,Berkeley, CA.N.
Habash and B. Dorr.
2003.
A categorial variation database forEnglish.
In Proceedings of NAACL-HLT 2003D.
Jones and R. Havrilla.
1998.
Twisted pair grammar: Support forrapid development of machine translation for low density languages.In Proceedings of AMTA98, pp.
318?332.D.
Marcu and U. Germann.
2002.
The ISI ReWrite Decoder Release0.7.0b.
http://www.isi.edu/licensed-sw/rewrite-decoder/.M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.
Building alarge annotated corpus of English: the Penn Treebank.
ComputationalLinguistics, Vol.
19.M.
Mohri, F. Pereira, and M. Riley.
1997.ATT General-purpose finite-state machine software tools.http://www.research.att.com/sw/tools/fsm/.G.
Ngai and R. Florian.
Transformation-based learning in the fast lane.In Proceedings of North Americal ACL 2001, pages 40-47, June 2001.F.
J. Och and H. Ney.
2000.
Improved statistical alignment models.In Proceedings of the 38th Annual Meeting of the Association forComputational Linguistics, pages 440?447.F.J.
Och, C. Tillmann, H. Ney.
Improved Alignment Models forStatistical Machine Translation.
In Proceedings of EMNLP 1999, pp.20-28.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2001.
Bleu: a methodfor automatic evaluation of machine translation.
Technical ReportRC22176 (W0109-022), IBM Research Division.A.
Stolcke.
2002.
SRILM - an extensible language modelingtoolkit.
In Proceedings of the International Conference on Spo-ken Language Processing, pages 901-904.
Denver, CO, USA.http://www.speech.sri.com/projects/srilm/.D.
Wu.
1997.
Stochastic inversion transduction grammars andbilingual parsing of parallel corpora.
Computational Linguistics,23(3), 377?404.K.
Yamada and K. Knight.
2001.
A syntax-based statistical translationmodel.
In Proceedings of ACL-2001, pp.
523?529.K.
Yamada and K. Night.
2002.
A decoder for syntax-based statisticalMT In Proceedings of ACL-2002, pp.
303?310.Word Translation ProbabilitiesWord translation for mangeait conditioned onFrench Word, EnglishPOSmangeait VBG eating 1.00mangeait VB go 0.50mangeait VB anticipate 0.50mangeait VBD were 1.00mangeait VBP knelt 1.00mangeait NN bill 1.00Word translation for mangeait conditioned onFrench Word, English Coarse POSmangeait V eating 0.44mangeait V were 0.22mangeait V knelt 0.11mangeait V go 0.11mangeait V anticipate 0.11mangeait N bill 1.00Word translation for mangeait conditioned onFrench Word onlymangeait eating 0.29mangeait were 0.14mangeait go 0.07mangeait bill 0.07Word translation for mangeantconditioned on French Word, EnglishPOSmangeant RB mostly 1.00mangeant JJ final 1.00mangeant VBN obtained 1.00mangeant VBG eating 1.00mangeant WP who 1.00mangeant IN through 1.00mangeant NN lard 1.00mangeant VBZ eats 0.50mangeant VBZ comes 0.50Lemma Translation ProbabilitiesGeneration of a verb lemma given mangermanger V eat 0.60manger V feed 0.05manger V have 0.04Generation of a noun lemma given mangermanger N meal 0.06manger N trough 0.04manger N loaf 0.04manger N food 0.04Generation of an adj.
lemma given mangermanger J hungry 0.33Raw lemma translation probabilities(ignoring English Coarse POS)manger eat 0.28manger to 0.03manger feed 0.03manger out 0.02manger have 0.02manger are 0.02manger , 0.02manger you 0.01manger meal 0.01Table 9: Direct generation (word-to-word translation probabilitiesat the various levels of backoff) is contrasted with lemma generation.Manger (?to eat?)
is a relatively rare word in the Hansards.
Note thatdue to low counts, the desired verb POS (target of generation) for ?eat?may not have been observed as a translation in training data.
In addi-tion, in this situation, noisy word alignments may cause an incorrecttranslation to have similar estimated translation probability.
This prob-lem is addressed by the lemma model; note the much sharper probabil-ity distribution for verb lemmas given manger.
Generation of Englishinflections given lemma and target POS is algorithmic (and irregularexceptions are handled via a lookup table).French Wd.
Eng.
POS Eng.
Wd.
Prob.accepter JJ unacceptable 0.12accepter JJ acceptable 0.12accepter JJ willing 0.11accepter JJ ready 0.03accepter NN acceptance 0.09accepter NN amendment 0.03droit VBN entitled 0.66droit VBN allowed 0.09droit VBN denied 0.03droit VBN given 0.02droit VBN permitted 0.02droit VBN justified 0.01droit VBN qualified 0.01droit VBN allotted 0.01droit VB qualify 0.14droit VB be 0.11droit VB have 0.09droit VB receive 0.08droit VB get 0.07droit VB expect 0.03droit VBG receiving 0.11droit VBG getting 0.08droit NNS rights 0.44droit NNS benefits 0.69Table 10: Examples of word translation coercions.
Co-ercions of the French verb accepter ?to accept?
and theFrench noun droit ?right?
(there is parallel polysemy be-tween the two languages for this word, but the predom-inant sense in our corpus is the philosophical/judicialsense, as opposed to the direction).Eng.
Phrase French Eng.
Prob.Type Phrase PhraseNP dans le cas pre?sent a situation 0.25NP dans le cas pre?sent the subject of debate 0.25NP dans le cas pre?sent the position 0.25NP dans le cas pre?sent it 0.25VP dans le cas pre?sent should apply 1.00ADVP dans le cas pre?sent really 1.00PPNP dans le cas pre?sent in this case 0.63PPNP dans le cas pre?sent in this instance 0.04PPNP dans le cas pre?sent in this actual case 0.04PPNP dans le cas pre?sent in this particular case 0.04PPNP dans le cas pre?sent in that case 0.04PPNP dans le cas pre?sent in the present circumstances 0.04VP acceptons accept 0.48VP acceptons agree 0.14NP acceptons this consent 1.00PPNP par an per year 0.67PPNP par an in each year 0.03PPNP par an for a year 0.03ADVP par an annually 1.00NP par an a year 0.79NP par an each year 0.02NP un discours a speech 0.83NP un discours an address 0.05VP un discours to speak 1.00Table 11: Examples of direct phrase translations (see Ta-ble 4(1)), including some coercions.
