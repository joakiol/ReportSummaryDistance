Correction Grammars for Error Handling in a Speech Dialog SystemHirohiko Sagawa Teruko Mitamura Eric NybergLanguage Technologies Institute, Carnegie Mellon UniversityPittsburgh, PA 15213, U.S.A.{hsagawa, teruko, ehn}@cs.cmu.eduAbstractSpeech recognition errors are inevitable in aspeech dialog system.
This paper presents anerror handling method based on correctiongrammars which recognize the correctionutterances which follow a recognition error.Correction grammars are dynamically createdfrom existing grammars and a set ofcorrection templates.
We also describe aprototype dialog system which incorporatesthis error handling method, and provideempirical evidence that this method canimprove dialog success rate and reduce thenumber of dialog turns required for errorrecovery.1 IntroductionIn a dialog system, speech recognition errors areinevitable and often make smooth communicationbetween a user and a system difficult.
Figure 1 shows anexample of a dialog between a user and a system whichillustrates a system error.
The system misrecognized?Tokyo?
in the user?s utterance (U1) as ?Kyoto?
(S3).
Ifthe system correctly recognized the user?s utterance, theuser could answer ?yes?
at U3 and the weather isreported (S6).
However, in this case, the user mustcorrect the error at U3 and the turns from S4 to U5 arerequired to recover from the error.
The dialog systemmust recognize the user?s response to the system error(correction utterance).
Otherwise, more turns (or acomplete restart) will be required to correct the error.Therefore, an error handling method which corrects asystem error and returns to the normal dialog flowsmoothly is an important requirement for practicaldialog systems.Recent work related to error handling in speechdialog systems has mainly focused on error detection.Walker et al (2000), Bosch et al (2001) andKazemzadeh et al (2003) extracted several parameters(e.g., acoustic, lexical and semantic) from a dialogcorpus, and analyzed the differences between correctionutterances and the other utterances in a dialog.
Theyalso tried to detect system errors by using theseparameters as input to machine learning methods.However, the issue of error recovery is not addressed.Danieli (1996) and LuperFoy & Duff (1996)proposed error detection methods based on planmatching.
An error is detected when the intention or theparameter expressed in the user?s utterance is notconsistent with the system?s assumptions and/orlimitations.
In these studies, the correction utterancesare assumed to be recognized correctly.Kitaoka et al (2003) proposed a method to detectsystem errors based on the similarity of speech patternsand hypotheses overlapping in the recognition result.They also proposed a method to improve the recognitionaccuracy for correction utterances by selecting a speechrecognition grammar according to the results of theerror detection.The previous studies assumed that the rules forspeech recognition or natural language processing ofcorrection utterances were prepared in advance (Danieli ,1996; LuperFoy & Duff, 1996).
These rules areindispensable because the correction utterance oftenincludes the information required to correct the error.The correction utterance depends on the dialog context,especially on the user?s utterances prior to the systemerror.
Therefore it is difficult for the system designer toprepare these rules in advance when the dialog flowbecomes complex.
To solve this problem, a method thatcan automatically create the rules to interpret correctionutterances is desirable.In this paper, we will propose a method todynamically create the rules to recognize correctionutterances and repair recognition errors based on thedialog context.
A prototype dialog system whichincorporates the proposed method has been developed,S1:  Please tell me the area.U1: Tokyo.S2: Please tell me the date.U2: Tomorrow.S3: Would you like to know the weather for Kyototomorrow?U3: No, Tokyo.S4: Did you say Tokyo?U4: Yes.S5:  Would you like to know the weather for Tokyotomorrow?U5: Yes.S6: The weather for Tokyo tomorrow is fine.Correction utteranceSystem errorFigure 1.
Example of a dialog with a system errorand we present experimental results which show theeffectiveness of the approach.2 CAMMIA Dialog SystemOur current approach focuses on dialog systems whichincorporate speech recognition modules utilizing regulargrammars.
The CAMMIA system is an example of sucha dialog system (Nyberg et al, 2002).The CAMMIA system is a client-server dialogmanagement system based on VoiceXML.
Each dialogscenario in this system is described in the format ofDialogXML.
The system has the initiative in the dialog,and dialogs are oriented around slot-filling for particularqueries or requests.
The server sends a VoiceXML datafile to the client VoiceXML interpreter for a particulardialog turn, compiled from the DialogXML scenarioaccording to the current dialog context.
The VoiceXMLdata includes system prompts, names of grammar filesand valid transitions to subsequent dialog states.
Theclient interacts with the user according to theVoiceXML data.Figure 2 shows an example of a grammar rule usedin the CAMMIA system.
The regular grammar rule canbe represented as a transition network.
The followingsentences are recognized by the rule in Figure 2:?
I would like to know the weather for Tokyo.?
I would like to know the weather for Tokyo tomorrow.3 Error Handling Based on CorrectionGrammarsTo recognize the user?s utterances in a dialog system, agrammar for potential user utterances must be preparedin advance for each dialog context.
For error handling, itis also necessary to anticipate correction utterances andprepare a correction grammar.
We propose a method toautomatically create the correction grammar based onthe current dialog context; error detection and repair isimplemented using the correction grammar.To create the correction grammar, the system mustknow the user?s utterances prior to the error, becausecorrection utterances typically depend on them.
If theuser?s utterances are consistent with what the system isexpecting, the correction grammar can be generatedbased on the grammar previously in use by the speechrecognizer.
Therefore, the sequence of grammars usedin the dialog so far is stored in the grammar history asthe dialog context, and the correction grammar iscreated using the grammars in this history.Most of the forms of correction utterances can beexpected in advance because correction utterancesinclude many repetitions of words or phrases fromprevious turns (Kazemzadeh et al, 2003).
We assumethat the rules to generate the correction grammar can beprepared as templates; the correction grammar is createdby inserting information extracted from the grammarhistory into a template.Figure 3 shows an example of a process flow in adialog system which performs error handling based on acorrection grammar.
The ?system prompt n?
is theprocess to output the n-th prompt to the user.
Thecorrection grammar is created based on the grammarused in the ?user response n-1?, which is the process torecognize the (n-1)-th user utterance, and it is used inthe ?user response n?
together with the ?grammar n?which is used to recognize the n-th normal user?sutterance.
The system detects the error when the user?sutterance is recognized using the correction grammar,and then transits into the ?correction of errors?
tomodify the error.
The grammar history in Figure 3stores only the grammar used in the last recognitionprocess.
The number of grammars stored in the historycan be changed depending on the dialog managementstrategy and error handling requirements.4 Generation of Correction GrammarThe correction grammar is created as follows.
(1) Copying the grammar rules in the historyThe user often repeats the same utterance when thesystem misunderstood what s/he spoke.
To detectwhen the user repeats exactly the same utterance, thegrammar rules in the grammar history are copied intothe correction grammar.
(2) Inserting the rules in the history into the templateWhen the user tries to correct the system error, some124?I would like to knowthe weather for??Tokyo?
?tomorrow?3?Tokyo?Figure 2.
Example of the grammar rule used in theCAMMIA systemSystem prompt n-1Grammar n-1Generation ofcorrection grammarCorrectiongrammar n-1Grammar n......TemplateRecognized bycorrection grammar ?YesNoUser response n-1System prompt nUser response nCorrection of errorsSystem prompt n+1Figure 3.
Process flow: Error handling based on acorrection grammarphrases are often added to the original utterance(Kitaoka, 2003).
The template mentioned above isused to support this type of correction utterance.
Anexample of the correction grammar rule generated bythis method is shown in Figure 4.
The ?null?
in Figure4 implies a transition with no condition, and the ?X?shows where the original rule is embedded.
In thisexample, the created grammar rule in Figure 4(c)corresponds to the following sentences:?
No, I?d like to know the weather for Tokyo.?
I said I?d like to know the weather for Tokyo.
(3) Inserting slot-values into the templateThe user often repeats only words or phrases whichthe system is focusing on (Kazemzadeh et al, 2003).In a slot-filling dialog, these correspond to the slotvalues.
Therefore, correction grammar rules are alsocreated by extracting the slot values from the grammarin the history and inserting them into the template.
Ifthere are several slot values that can be corrected atthe same time, all of their possible combinations andpermutations are also generated.
An example is shownin Figure 5.
In Figure 5(b), the slot-values are?Tokyo?
and ?tomorrow?.
The grammar rule in Figure5(c) includes each slot value plus their combination(s),and represents the following sentences:?
I said Tokyo.?
I said tomorrow.?
I said Tokyo tomorrow.5 Prototype System with Error HandlingWe have implemented the proposed error handlingmethod for a set of Japanese dialog scenarios in theCAMMIA system.
We added to this system: a) aprocess to create a correction grammar file when thesystem sends a grammar file to the client, b) a process torepair errors based on the recognition result, and c)transitions to the repair action when the user?s utteranceis recognized by the correction grammar.There are two types of errors: task transition errorsand slot value errors.
If the error is a task transition error,the modification process cancels the current task andtransits to the new task as specified by the correctionutterance.
When the error is a slot value error, the slotvalue is replaced by the value given in the correctionutterance.
However, if the new value is identical to theold one, we assume a recognition error and the secondcandidate in the recognition result is used.
Thistechnique requires a speech recognizer that can outputN-best results; we used Julius for SAPI (Kyoto Univ.,2002) for this experiment.6 ExperimentsWe carried out an experiment to verify whether theproposed method works properly in a dialog system.
Inthis experiment, dialog systems with and without theerror handling method were compared.
In thisexperiment, a weather information dialog was selectedas the task for the subjects and about 1200 dialoginstances were analyzed (both with and without errorhandling).
The dialog flow was the same as shown inFigure 1.
The grammar included 500 words for placenames, and 69 words for the date.
The subjects wereinstructed in advance on the utterance patterns allowedby the system, and used only those patterns during theexperiment.
A summary of the collected data is shownin Table 1.
When error handling is disabled, the systemreturns to the place name query when the user denies thesystem?s confirmation, e.g.
it returns from U3 to S1 inFigure 1.
A comparison of the number of turns in thesetwo systems is shown in Table 2.
?1 error?
in Table 2means that the dialog included one error and ?2 errors?means that the same error was repeated.The success rate for the task and the average numberof turns in the dialog (including errors) are tabulated.Dialogs including more than 3 errors were regarded asincomplete tasks in the calculation of the success rate.The results are shown in Table 3.1X 2?no?null?I said?
(a) Template13?I would liketo knowthe weather for?2?Tokyo?
(b) Grammar rule in the history3 4?I would liketoknow theweather for?
?Tokyo?12 5?no?null?I said?
(c) Created correction grammar ruleFigure 4.
Correction grammar created by insertingthe original rule into a template1X 2null?I said?
(a) Template13?I would like to knowthe weather for?2?Tokyo??tomorrow?
(b) Grammar rule in the history34?Tokyo?12 5null?I said??tomorrow??Tokyo??tomorrow?
(c) Created correction grammar ruleFigure 5.
Correction grammar rules created byinserting slot values into a template7 DiscussionThe task completion rate was improved from 86.4% to93.4% when the proposed error handling method wasused.
The average number of turns was reduced by 3turns as shown in Table 3.
This result shows that theproposed error handling method was working properlyand effectively.One reason that the success rate was improved isthat the proposed method prevents the repetition oferrors.
When the error handling method is notimplemented, errors can be easily repeated.
The errorhandling method can avoid repeated errors by selectingthe second candidate in the recognition result even whenthe correction utterance is also misrecognized.
Therewere 7 dialogs in which the correction utterance wascorrectly recognized by selecting the second candidate.However, there were 13 dialogs in which the errorwas not repaired by one correction utterance.
There aretwo explanations.
One is that there are insertion errorsin speech recognition which causes words not spoken toappear in the recognition result.
For example, thesystem prompt S4 for U3 in Figure 1 becomes asfollows:S4: Did you say Tokyo yesterday?In this case, the user has to speak more correctionutterances.
The second explanation is that therecognition result did not always include the correctresult within the first two candidates.
It is not clear thatextending the repair mechanism to always consideradditional recognition candidates (3rd, 4th, etc.)
is aviable technique, given the drop off in recognitionaccuracy; more study is required.8 ConclusionsIn this paper, we proposed an error handling methodbased on dynamic generation of correction grammars torecognize the user corrections which follow systemerrors.
The correction grammars detect system errorsand also repair the dialog flow, improving taskcompletion rates and reducing the average number ofdialog turns.
We developed a prototype dialog systemusing the proposed method, and demonstratedempirically that the success rate improved by 7.0%, andthe number of turns was reduced by 3.The creation of rules for correction utterances basedon the dialog history could be applicable to dialogsystems which use speech recognition or naturallanguage processing and other kinds of rules beyondregular grammars; we plan to study this in future work.We are also planning to develop an algorithm toimprove the precision of corrections that are based onthe set of recognition candidates for the correctionutterance and an error recovery strategy.
We also plan toapply the proposed method to other types of dialogs,such as user-initiative dialogs and mixed-initiativedialogs.ReferencesAbe Kazemzadeh, Sungbok Lee and ShrikanthNarayanan.
2003.
Acoustic Correlates of UserResponse to Error in Human-Computer Dialogues,Proceedings of ASRU 2003: 215-220.Antal van den Bosch, Emiel Krahmer and MarcSwerts.
2001.
Detecting problematic turns inhuman-machine interactions: Rule-InductionVersus Memory-Based Learning Approaches,Proceedings of ACL 2001: 499-507.Eric Nyberg, Teruko Mitamura, Paul Placeway,Michael Duggan, Nobuo Hataoka.
2002.
DynamicDialog Management with VoiceXML, Proceedingsof HLT-2002.Kyoto University, 2002, Julius Open-Source Real-Time Large Vocabulary Speech RecognitionEngine, http://julius.sourceforge.jp.Marilyn Walker, Jerry Wright and Irene Langkilde.2000.
Using Natural Language Processing andDiscourse Features to Identify UnderstandingErrors in a Spoken Dialogue System, Proceedingsof ICML-2000: 1111-1118.Morena Danieli.
1996.
On the Use of Expectations forDetecting and Repairing Human-MachineMiscommunication, Proceedings of AAAIWorkshop on Detection, Repair and Prevention ofHuman-Machine Miscommunication: 87-93.Norihide Kitaoka, Kaoko Kakutani and SeiichiNakagawa.
2003.
Detection and Recognition ofCorrection Utterance in Spontaneously SpokenDialog, Proceedings of EUROSPEECH 2003: 625-628.Susann LuperFoy and David Duff.
1996.
Disco: AFour-Step Dialog Recovery Program, TheProceedings of the AAAI Workshop on Detection,Repair and Prevention of Human-MachineMiscommunication: 73-76.Table 1.
Summary of the collected dataw/o error handling w/ error handling# of users 2 male, 1 female 2 male, 1 female# of dialog 603 596# of error dialog 66 61Table 2.
Number of turns in the dialogNo error 1 error 2 errorsw/o error handling 13 19w/ error handling 7 11 13Table 3.
Success rate and average number of turnsSuccess rate Ave. # turnsw/o error handling 86.4% 14.6w/ error handling 93.4% 11.6
