Workshop on Computational Linguistics for Literature, pages 64?68,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsDigitizing 18th-Century French Literature:Comparing transcription methods for a critical edition textAnn IrvineComputer Science Dept.Johns Hopkins UniversityBaltimore, MDanni@jhu.eduLaure MarcellesiFrench and Italian Dept.Dartmouth CollegeHanover, NHlaure.marcellesi@dartmouth.eduAfra ZomorodianThe D. E. Shaw GroupNew York, NYAbstractWe compare four methods for transcribingearly printed texts.
Our comparison is througha case-study of digitizing an eighteenth-century French novel for a new critical edition:the 1784 Lettres ta?
?tiennes by Jose?phine deMonbart.
We provide a detailed error analy-sis of transcription by optical character recog-nition (OCR), non-expert humans, and experthumans and weigh each technique based onaccuracy, speed, cost and the need for schol-arly overhead.
Our findings are relevant to18th-century French scholars as well as theentire community of scholars working to pre-serve, present, and revitalize interest in litera-ture published before the digital age.1 IntroductionPreparing a text for modern publication involves thefollowing: (1) digitizing1 a printed version of thetext, and (2) supplementing the original content withnew scholarly contributions such as a critical intro-duction, annotations, and a thorough bibliography.The second task requires a high degree of expertiseand academic insight and the first does not.
How-ever, scholars working on such projects often spendlarge amounts of time transcribing literature fromscratch, instead of focusing on skilled contributions.In this paper, we present an analysis of our effortsusing alternative methods, other than highly skilledscholars themselves, to transcribe a scanned imageof a novel into a modifiable, searchable document.We compare four different methods of transcriptionwith a gold standard and evaluate each for accuracy,speed, and cost-effectiveness.
Choosing an appro-1In this work, digitizing means transcribing an image into amodifiable, searchable file of unicode characters.priate transcription method may save scholars timeand allow them to focus on critical contributions.First published in 1784, Jose?phine de Monbart?sLettres ta?
?tiennes is an epistolary novel dramatiz-ing the European colonial takeover of the newly-encountered island of Tahiti from the fictional pointof view of a young Tahitian woman.
While mostworks of the time painted a fictional Tahitian par-adise of uninhibited sexuality, this novel offers asingular anti-colonial critique by grounding it in thesuffering of the female body.
We describe our worktranscribing the second edition of the novel, which iswritten in French and was published in Paris, with-out date (probably 1786).
The text is comprised of156 pages, which are split into two volumes.There are many off-the-shelf (OTS) natural lan-guage processing (NLP) tools available for French,including optical character recognition (OCR),context-sensitive spell checking, and machine trans-lation.
Additionally, French is a widely spoken lan-guage in the world today and it is often possible torecruit French speakers to do transcription and an-notation.
However, the early-modern (18th-century)form of the language varies substantially from themodern form, which is used to train OTS Frenchtools and is what non-domain-expert transcribers arefamiliar with.
Differences between the modern andearly-modern forms of the language include orthog-raphy, lexical choice, and morphological patterns.An additional challenge is that our transcriptionsare based on a copied version of the bound text avail-able at the Bibliothe`que nationale de France.
Thiscommon scenario introduces the challenge of noise,or ink marks which are not part of the text.
Scattereddots of ink may result in punctuation and characteraccenting errors, for example.In this paper, we compare the accuracy, speed, and64cost of using several different methods to transcribeLettres tahitiennes.
In Section 2 we describe thetranscription methods, and in Section 3 we present adetailed analysis of the types of errors made by each.We also provide a discussion of the difficulty ofpost-editing the output from each transcriber.
Sec-tion 4 gives an overview of prior work in the area andSection 5 a practical conclusion, which may informscholars in the beginning stages of similar projects.2 MethodsWe compare four sources of transcription for 30pages of the novel with one gold standard:?
OTS French OCR output?
Non-expert French speakers on Amazon?s Me-chanical Turk (MTurk)?
Non-expert undergraduate students in the hu-manities, closely supervised by the expert?
Professional transcription service?
Gold standard: early-modern French literaturescholar and editor of the critical editionGiven PDF images of a copy of the novel, eachsource transcribed the same 30 pages2.
The pagesare a representative sample from each of the two vol-umes of the text.We used OTS Abbyy Finereader OCR software,which is trained on modern French text and has afixed cost of $99.Three MTurk workers transcribed each page oftext, and the domain expert chose the best transcrip-tion of each page.
In future work, we could haveanother round of MTurk workers choose the besttranscription among several MTurk outputs, whichhas been shown to be effective in other NLP tasks(Zaidan and Callison-Burch, 2011).
We paid eachMTurk worker $0.10 to transcribe a single page.Two closely supervised undergraduate studentstranscribed the novel3, including the 30 test pages.The cost per page per student was about $0.83.Our group also hired a professional company totranscribe the entire novel, which charged a fixedcost of $1000, or about $3.21 per page.The early-modern French literature domain-expert also transcribed the 30 test pages from2Each page is in the original duodecimo format and containsabout 150 word tokens.3One student transcribed volume 1, the other volume 2.scratch, and this transcription was used as the goldstandard for measuring accuracy.Because the critical edition text should be as faith-ful as possible to the original text, with no alterationto the spelling, syntax, capitalization, italicization,and paragraph indentation, we define as errors to be:?
an incomplete transcription?
missing or added words, letters, or characters?
a word transcribed incorrectly?
capitalization, bold, italics not matching theoriginal text?
incorrect formatting, including missing oradded paragraph indentations and footnote dis-tinctionsIn Section 3, we present a quantitative and quali-tative analysis of the types of errors made by each ofour transcription methods.3 Results and Error AnalysisTable 1 lists the error rate for each transcriber.3.1 S/F errorsOne of the most common errors made by all fourtranscription methods is confusing the letter ?
(orlong s), which is common in early-modern Frenchbut doesn?t appear in modern French, with the letterf.
Figure 1 shows examples of phrases in the originaldocument that include both characters.
These ex-amples illustrate how familiarity with the languagemay impact when transcription errors are made.
Allthree human transcribers (MTurk workers, students,professionals) confused an f for an ?
in (b).
Interest-ingly, the phrase in (b) would never be used in mod-ern French, so the transcribers, not recognizing theoverall meaning of the sentence and wary of ?miss-ing?
a ?, incorrectly wrote seront instead of feront.In contrast, the phrase in (a) is rare but does existin modern French.
The MTurk worker and profes-sional transcriber correctly transcribed feront but thestudent, who probably didn?t know the phrase, tran-scribed the word as seront.The OCR system trained on modern French didnot recognize ?
at all.
In most cases, it transcribedthe letter as an f, but it sometimes chose other letters,such as t, i, or v, in order to output French words thatexist in its dictionary.
Although it may have been65Wednesday, February 22, 2012Figure 1: Correct transcription: (a) ils feront l?aumo?ne(give alms).
The student incorrectly transcribed feront asseront.
(b) ils ne se feront nul scrupule (they will have noqualms).
All four alternative transcription sources incor-rectly transcribed feront as seront.Figure 2: Correct transcription: Outre qu?elles me parois-sent toutes dans la pre?miere jeunesse, elles ont des gracesqui vous ravissent avant d?avoir songe?
a` examiner, si ellese?toient belles (Besides [these women] appearing to me inthe prime of youth, they have graces that delight you be-fore you even think of considering whether they are beau-tiful.
Transcribers made both conjugation (paraissent vs.paroissent) and accenting (pre?miere vs. premie`re) mod-ernization errors in this passage.possible to train the OCR system on early-modernFrench, the very slight difference between the char-acter strokes means that disambiguating between fand ?
would likely remain a difficult task.3.2 Modernization errorsEighteenth-century French is understandableby speakers of modern French, but there area few differences.
In addition to the absenceof the letter ?, modern French conjugatesverbs with ?ai,?ais,?ait,?aient instead of?oi,?ois,?oit,?oient and follows stricter rulesthat no longer allow for variations in spelling oraccenting.
Figure 2 shows examples of both.
Ingeneral, the authors of modern critical editions seekto maintain original spellings so that future scholarscan work as close to the original text as possible,even if the original work includes typos, whichwe have seen.
However, our human transcribersincorrectly modernized and ?fixed?
many originalspellings.
This is likely due to the fact that it ishard for a human transcriber who is familiar withthe language to not ?correct?
a word into its modernform.
We observed this across all human tran-scribers.
For example, our professional transcribertranscribed premie`re instead of pre?miere and oneMTurk worker transcribed chez instead of che?s.
TheOCR model, which is trained on modern French,is also biased toward modern spellings.
Most ofits modernization errors were related to accents.For example, it transcribed graces as gra?ces anddifferentes as diffe?rentes.Some modernization errors occur systematicallyand, thus, are easy to automatically correct after theinitial transcription is complete.
For example, all?aient word endings could be changed to ?oient.This is not true for all modernization errors.3.3 Errors from page noiseSince all of our transcribers worked from a scan ofa copy of the original book held at the Bibliothe`quenationale de France, noise in the form of small dots,originally bits of ink, appears on the pages.
Thesesmall dots are easily confused with diacritics andpunctuation.
Our human transcribers made such er-rors very infrequently.
However, this type of noisegreatly affected the output of the OCR system.
Inaddition to mistaking this type of noise for punctua-tion, sometimes it affected the recognition of words.In once instance, visages became ylfygc because ofsmall dots that appeared below the v and a4.3.4 Formatting errorsWe asked all transcribers to maintain the originalformatting of the text, including paragraph indenta-tions, footnotes, and font styles.
However, becauseof limitations inherent to the MTurk task design in-terface, we were unable to collect anything but plain,unformatted text from those transcribers.
In general,our other human transcribers were able to accuratelymaintain the format of the original text.
The OCRoutput also made formatting mistakes, particularlybold and italicized words.3.5 Other errorsBoth humans and the OCR system made an assort-ment of additional errors.
For example, two MTurkworkers failed to turn off the English automatic spellcorrectors in their text editors, which resulted in let-tre becoming letter and dont becoming don?t.3.6 Scholar overheadTable 1 lists the average number of errors per pagefor each transcription method.
In addition to consid-4In this example, an ?
was also transcribed as an f66Error OCR MTurk Prof. Stud.Modernization 26.29 2.82 0.71 0.46Noise 7.68 0.0 0.32 0.21Formatting 1.96 0.82 0.36 0.0Total 35.93 3.86 1.39 0.71Table 1: Mean number of errors per page, by error typeand transcription method.
The total includes the errortypes shown as well as an assortment of other errors.ering the error rate of each, we found that it is criticalto consider (a) the effort that the scholar must ex-ert to correct, or post-edit, a non-expert?s transcrip-tion, and (b) the amount of overhead required by thescholar to gather the transcriptions.All errors are not equally serious.
We foundthat the expert scholar had an easier time correct-ing some errors in post-editing than others.
For ex-ample, modernization errors may be corrected auto-matically or in a single read through the transcrip-tion, without constantly consulting the original text.In contrast, correcting formatting errors is very timeconsuming.
Similarly, correcting errors resultingfrom page noise requires the scholar to closely com-pare punctuation in the original text with that of thetranscription and takes a lot of time.Previous research on gathering and using non-expert annotations using MTurk (Snow et al, 2008;Callison-Burch and Dredze, 2010; Zaidan andCallison-Burch, 2011) has been optimistic.
How-ever, that work has failed to account for the time andeffort required to compose, post, monitor, approve,and parse MTurk HITs (human intelligence tasks).In our exploration, we found that the time requiredby our expert scholar to gather MTurk annotationsnearly offsets the cost savings that result from us-ing it instead of local student or professional tran-scribers.
Similarly, the scholar had to provide somesupervision to the student transcribers.
The profes-sional transcription service, in contrast, though moreexpensive than the other high quality (non-OCR)methods, required no oversight on the part of thescholar.
After using all methods to transcribe 30pages of Lettres ta?
?tiennes and critically comparingthe costs and benefits of each, we had the profes-sional transcription service complete the project andour expert French literature scholar has based a newcritical edition of the text on this transcription.4 BackgroundSnow et al (2008) gathered annotations on MTurk inorder to supervise a variety of NLP tasks.
In general,they found a high degree of annotator agreement andinspired a plethora of research on using non-expertannotations for additional tasks in language process-ing (Callison-Burch and Dredze, 2010).OCR has been an active area of research in NLPfor decades (Arica and Yarman-Vural, 2001).
Re-cent work has acknowledged that post-editing OCRoutput is an important engineering task but generallyassumes large amounts of training data and does notattempt to maintain text format (Kolak et al, 2003).As we described, for our application, transcribingall content and formatting, including footnotes, ref-erences, indentations, capitalization, etc.
is crucial.Furthermore, OCR output quality was so low thatpost-editing it would have required more work thantranscribing from scratch.
We did not attempt totrain the OCR since, even if it had recognized ?
andlearned an appropriate language model, the format-ting and noise errors would have remained.5 Future Work and ConclusionsIn Section 3.2, we mentioned that it may be possibleto automatically post-edit transcriptions and correctsystematic modernization errors.
The same may betrue for, for example, some types of typos.
This typeof post-editing could be done manually or automati-cally.
One potential automatic approach is to train alanguage model on the first transcription attempt andthen use the model to identify unlikely segments oftext.
We plan to pursue this in future work.Although we hoped that using MTurk or OCRwould provide an inexpensive, high-quality firstround transcription, we found that we preferred touse student and professional transcribers.The trade-offs between speed and accuracy and between lowcost and overhead time were not worthwhile for ourproject.
If a scholar were working with a larger textor tighter budget, investing the time and effort to useMTurk could prove worthwhile.
Using an OCR sys-tem would demand extensive training to the text do-main as well as post-editing.
This paper enumeratesimportant challenges, costs, and benefits of severaltranscription approaches, which are worthy of con-sideration by scholars working on similar projects.67ReferencesN.
Arica and F. T. Yarman-Vural.
2001.
An overview ofcharacter recognition focused on off-line handwriting.Systems, Man, and Cybernetics, Part C: Applicationsand Reviews, IEEE Transactions on, 31(2):216?233,May.Chris Callison-Burch and Mark Dredze.
2010.
Creatingspeech and language data with amazon?s mechanicalturk.
In Proceedings of the NAACL HLT 2010 Work-shop on Creating Speech and Language Data withAmazon?s Mechanical Turk, pages 1?12, Los Angeles,June.
Association for Computational Linguistics.Jose?phine de Monbart.
1786.
Lettres tahitiennes.
LesMarchands de nouveaute?s, Paris.Okan Kolak, William Byrne, and Philip Resnik.
2003.
Agenerative probabilistic ocr model for nlp applications.In Proceedings of the NAACL, pages 55?62.
Associa-tion for Computational Linguistics.Rion Snow, Brendan O?Connor, Daniel Jurafsky, and An-drew Y. Ng.
2008.
Cheap and fast?but is it good?
:evaluating non-expert annotations for natural languagetasks.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing, EMNLP?08, pages 254?263, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Omar F. Zaidan and Chris Callison-Burch.
2011.
Crowd-sourcing translation: Professional quality from non-professionals.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies, pages 1220?1229, Portland, Oregon, USA, June.
Association forComputational Linguistics.68
