Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1317?1325,Beijing, August 2010Paraphrasing with Search Engine Query LogsShiqi Zhao?
?, Haifeng Wang?, and Ting Liu?
?Baidu Inc.?HIT Center for Information Retrieval, Harbin Institute of Technology{zhaoshiqi, wanghaifeng}@baidu.com, tliu@ir.hit.edu.cnAbstractThis paper proposes a method that extractsparaphrases from search engine querylogs.
The method first extracts paraphrasequery-title pairs based on an assumptionthat a search query and its correspond-ing clicked document titles may mean thesame thing.
It then extracts paraphrasequery-query and title-title pairs from thequery-title paraphrases with a pivot ap-proach.
Paraphrases extracted in each stepare validated with a binary classifier.
Weevaluate the method using a query logfrom Baidu1, a Chinese search engine.Experimental results show that the pro-posed method is effective, which extractsmore than 3.5 million pairs of paraphraseswith a precision of over 70%.
The resultsalso show that the extracted paraphrasescan be used to generate high-quality para-phrase patterns.1 IntroductionThe use of paraphrases is ubiquitous in hu-man languages, which also presents a challengefor natural language processing (NLP).
Previousstudies have shown that paraphrasing can play im-portant roles in plenty of areas, such as machinetranslation (MT) (Callison-Burch et al, 2006;Kauchak and Barzilay, 2006), question answer-ing (QA) (Duboue and Chu-Carroll, 2006; Riezleret al, 2007), natural language generation (NLG)(Iordanskaja et al, 1991), and so on.
As a result,the research on paraphrasing and its applicationshave attracted significant interest.1www.baidu.comThis paper proposes a method that uses searchengine query logs for extracting paraphrases,which is illustrated in Figure 1.
Specifically, threekinds of paraphrases can be extracted with ourmethod, which include (1) query-title (Q-T): aquery and a document title that users clicked on;(2) query-query (Q-Q): two queries, for whichusers clicked on the same document title; (3) title-title (T-T): two titles that users clicked on for thesame query.
We train a classifier for each kind tofilter incorrect pairs and refine the paraphrases.Extracting paraphrases using query logs hasmany advantages.
First, query logs keep growing,which have no scale limitation.
Second, querylogs reflect web users?
real needs, hence the ex-tracted paraphrases may be more useful than thatfrom other kinds of corpora.
Third, paraphrasesextracted from query logs can be directed appliedin search engines for query suggestion and doc-ument reranking.
In addition, we find that bothqueries and titles contain a good many questionsentences, which can be useful in developing QAsystems.We conduct experiments using a query log ofa commercial Chinese search engine Baidu, fromwhich we extracted about 2.7 million pairs ofparaphrase Q-T, 0.4 million pairs of paraphrase Q-Q, and 0.4 million pairs of paraphrase T-T. Theprecision of the paraphrases is above 70%.
Inaddition, we generate paraphrase patterns usingthe extracted paraphrases.
The results show that73,484 pairs of paraphrase patterns have been gen-erated, with a precision of over 78%.In the rest of the paper, we first review relatedwork in Section 2.
Section 3 describes our methodin detail.
Section 4 presents the evaluation and re-1317paraphrase Q-T extractionquery title both query and titleparaphrase Q-Q extraction paraphrase T-T extractionparaphrase relationFigure 1: Illustration of the proposed method.sults.
Section 5 concludes the paper and discussesfuture directions.2 Related WorkIn this section, we briefly review previous studieson paraphrase extraction and query log mining ininformation retrieval (IR).2.1 Paraphrase ExtractionA variety of data resources have been exploitedfor paraphrase extraction.
For example, some re-searchers extract paraphrases from multiple trans-lations of the same foreign novel (Barzilay andMcKeown, 2001; Ibrahim et al, 2003), whilesome others make use of comparable news arti-cles that report on the same event within a smalltime interval (Shinyama et al, 2002; Barzilay andLee, 2003; Dolan et al, 2004).
Besides the mono-lingual corpora, bilingual parallel corpora havealso been used for extracting paraphrases (Ban-nard and Callison-Burch, 2005; Callison-Burch,2008; Zhao et al, 2008).
Their basic assumptionis that phrases that align with the same foreignphrase may have the same meaning.The above methods have achieved promisingresults.
However, their performances are usuallyconstrained due to the scale and domain limita-tion.
As an alternative, researchers have triedto acquire paraphrases from large-scale web cor-pora (Lin and Pantel, 2001; Pas?ca and Dienes,2005; Bhagat and Ravichandran, 2008) or directlybased on web mining (Ravichandran and Hovy,2002).
These methods are guided by an extendedversion of distributional hypothesis, namely, iftwo phrases often occur in similar contexts, theirmeanings tend to be similar.
The disadvantageof these methods is that the underlying assump-tion does not always hold.
Phrases with oppositemeanings can also occur in similar contexts, suchas ?X solves Y?
and ?X worsens Y?
(Lin and Pan-tel, 2001).
In addition, the extracted paraphrasesare generally short fragments with two slots (vari-ables) at both ends.2.2 Query Log Mining in IRQuery logs are widely used in the IR commu-nity, especially for mining similar queries.
For ex-ample, Wen et al (2002) clustered queries basedon user click information.
Their basic idea isthat if some queries result in similar user clicks,the meanings of these queries should be similar.Such methods have also been investigated in (Gaoet al, 2007) for cross-lingual query suggestionand (Zhao et al, 2007) for synonymous questionsidentification.
This paper is partly inspired bytheir studies.
However, we do not simply use clickinformation as clues for mining similar queries.Instead, we mine paraphrases across queries andclicked document titles.In addition, query logs can be used for queryexpansion.
For instance, Cui et al (2002)extract probabilistic correlations between queryterms and document terms by analyzing querylogs, which are then used to select high-quality1318H1: If a query q hits a title t, then q andt are likely to be paraphrases.H2: If queries q1 and q2 hit the same title t,q1 and q2 are likely to be paraphrases.H3: If a query q hits titles t1 and t2, thent1 and t2 are likely to be paraphrases.Table 1: Hypotheses for extracting paraphrases.expansion terms for new queries.
Note that theexpansion terms are merely related terms of thequeries, not necessarily paraphrases.There are other studies that use query logsfor constructing ontologies (Sekine and Suzuki,2007), learning named entities (Pas?ca, 2007),building user profiles (Richardson, 2008), correct-ing spelling errors (Ahmad and Kondrak, 2005),and so forth.3 The Proposed Method3.1 Basic IdeaNowadays, more and more users tend to searchlong queries with search engines.
Many userseven directly search questions to get exact an-swers.
By analyzing our query log that recordsrich information including user queries, clickedurls, titles, etc., we find that most titles of clickeddocuments are highly related with search queries.Especially, paraphrases can be easily found fromlong queries and the corresponding clicked ti-tles.
This motivates us to extract paraphrases fromquery-title pairs.
Here we introduce a concept hitthat will be frequently used: given a query q, aweb document d, and d?s title t, if there exist someusers that click on d when searching q, then wesay q hits t.The hypothesis for extracting paraphrase Q-Tis shown in Table 1 (H1).
In addition, we findthat when several queries hit the same title, thequeries are likely to be paraphrases of each other.The other way round, when a query hits severaltitles, paraphrases can also be found among the ti-tles.
We therefore further extract paraphrase Q-Qand T-T from the paraphrase Q-T.
The underly-ing hypotheses can be found in Table 1 (H2 andINPUT: Q: query space, T : title spaceOUTPUT: Pqt: the set of paraphrase Q-T,Pqq: the set of paraphrase Q-Q,Ptt: the set of paraphrase T-T,ParaSet: the set of paraphrases1.
FOR any q ?
Q and t ?
T2.
IF q hits t3.
IF IsParaphrase(q, t)4.
Add ?q, t?
to Pqt5.
END IF6.
END IF7.
END FOR8.
FOR any q1, q2 ?
Q and t ?
T9.
IF ?q1, t?
?
Pqt and ?q2, t?
?
Pqt10.
IF IsParaphrase(q1, q2)11.
Add ?q1, q2?
to Pqq12.
END IF13.
END IF14.
END FOR15.
FOR any t1, t2 ?
T and q ?
Q16.
IF ?q, t1?
?
Pqt and ?q, t2?
?
Pqt17.
IF IsParaphrase(t1, t2)18.
Add ?t1, t2?
to Ptt19.
END IF20.
END IF21.
END FOR22.
RETURN ParaSet = Pqt ?
Pqq ?
PttTable 2: Algorithm for extracting paraphrases.H3).
Note that, based on H2 and H3, paraphraseQ-Q and T-T can be directly extracted from rawQ-T pairs.
However, in consideration of preci-sion, we extract them from paraphrase Q-T. Wecall our paraphrase Q-Q and T-T extraction ap-proach as a pivot approach, since we use titles aspivots (queries as targets) when extracting para-phrase Q-Q and use queries as pivots (titles as tar-gets) when extracting paraphrase T-T.3.2 AlgorithmOur paraphrase extraction algorithm is shown inTable 2.
In particular, lines 1?7 extract para-1319phrase Q-T from the query log.
Lines 8?14 and15?21 extract paraphrase Q-Q and T-T, respec-tively.
Line 22 combines the paraphrase Q-T, Q-Q, and T-T together.
To filter noise, the extractedQ-T, Q-Q, and T-T pairs are all validated usinga function IsParaphrase(s1, s2).
In this work,we recast paraphrase validation as a binary clas-sification problem.
Any pair of ?s1, s2?
is classi-fied as 1 (paraphrase) or 0 (non-paraphrase) witha support vector machine (SVM) classifier.
Thefeatures used for classification will be detailed inSection 3.3.In practice, we exploit a query log that contains287 million Q-T pairs, which are then filtered us-ing the following constraints: (1) exclude Q-Tpairs that are too short, i.e., either query q or tittlet contains less than three terms; (2) exclude Q-Tpairs where q subsumes t or vice versa, e.g., ???
(beef)?
and ??????
(cooking method ofbeef)?
; (3) exclude Q-T pairs in which the similar-ity between q and t is below a predefined thresholdT 2; (4) exclude Q-T pairs whose t contains fre-quent internet terms, such as ???
(home page)?,???
(web site)?, ???
(online)?, since such ti-tles are mostly organization home pages, onlinevideos, downloadable resources, etc., which areuseless for our purpose of paraphrase extraction.3.3 Features for Paraphrase ValidationGiven a pair of candidate paraphrases ?s1, s2?, inwhich s1 and s2 can be either a query or a title, weexploit the following features in the classification-based paraphrase validation.?
Frequency Feature FF .
FF is defined basedon each ?s1, s2?
?s frequency.
We expect that morefrequent ?s1, s2?
should be more reliable.FF (s1, s2) = {c(s1,s2)C if c(s1, s2) < C1 if c(s1, s2) ?
C(1)where c(s1, s2) denotes the number of times thatthe ?s1, s2?
pair occurs in the corpus.
C is a nor-malizing factor (C = 10 in our experiments).2The similarity is computed based on word overlap rate,which will be described in detail in section 3.3.
We set T =0.6 in the experiments.?
Length Rate Feature FLR:FLR(s1, s2) =min{cw(s1), cw(s2)}max{cw(s1), cw(s2)}(2)where cw(s) denotes the number of words in s.?
Word Overlap Rate Feature FWOR:FWOR(s1, s2) =cw(s1 ?
s2)max{cw(s1), cw(s2)}(3)where ?s1 ?
s2?
is the intersection of s1 and s2.?
Character Overlap Rate Feature FCOR.
Chi-nese words are composed of characters.
It is quiteoften that words with similar characters sharesimilar meanings, such as ???
(comfortable)?and ???
(comfortable)?, ???
(sell)?
and ???
(sell)?.
Here we use FCOR to measure the sim-ilarity between s1 and s2 at the character level.Detailedly, we segment s1 and s2 into sets ofcharacters and compute the overlap rate based onEquation (3)3.?
Cosine Similarity Feature FCS .
In FCS , boths1 and s2 are represented as vectors and their co-sine similarity is computed as:FCS(s1, s2) =vecw(s1) ?
vecw(s2)?vecw(s1)?
?
?vecw(s2)?
(4)where vecw(s) is the vector of words in s, ???
de-notes the dot product of two vectors, ?vecw(s)?is the norm of a vector.
Here, the weight of eachword w in a vector is computed using a heuristicsimilar to tf-idf:W (w) = tf(w)?
log( Nc(w) + 0.1) (5)where tf(w) is the frequency of w in the given s,c(w) is the number of times that w occurs in thecorpus, N = maxw c(w).?
Edit Distance Feature FED.
Let ED(s1, s2)be the edit distance at the word level between s1and s2, we compute FED as follows:FED(s1, s2) = 1?ED(s1, s2)max{cw(s1), cw(s2)}(6)3In FCOR, cw(s) of Equation (3) denotes the number ofcharacters in s.1320?
Named Entity (NE) Similarity Feature FNE .NE information is critical in paraphrase identifica-tion (Shinyama et al, 2002).
We therefore com-pute the NE similarity between s1 and s2 and takeit as a feature.
We employ a Chinese NE recog-nition tool that can recognize person names, loca-tions, organizations, and numerals.
The NE simi-larity is computed as:FNE(s1, s2) =cne(s1 ?
s2) + 1max{cne(s1), cne(s2)}+ 1(7)where cne(s) denotes the number of NEs in s.Equation (7) guarantees FNE = 1 if there are noNEs in either s1 or s2.?
Pivot Fertility Feature FPF : FPF is a fea-ture specially designed for paraphrase Q-Q andT-T extraction, which are based on the pivot ap-proach4.
Specifically, we define fertility of a pivotas the number of targets it corresponds to.
Our ob-servation indicates that the larger the fertility of apivot is, the more noisy the targets are.
Hence wedefine FPF as:FPF (s1, s2) = maxp1f(p) (8)where s1 = q1, s2 = q2, p = t when classifyingQ-Q, while s1 = t1, s2 = t2, p = q when classi-fying T-T. f(p) denotes the fertility of the pivot p.The value is maximized over p if s1 and s2 can beextracted with multiple pivots.3.4 Generating Paraphrase PatternsA key feature of our method is that the extractedparaphrases are particularly suitable for generat-ing paraphrase patterns, especially for the hot do-mains that are frequently searched.
For example,there are quite a few paraphrases concerning thetherapy of various diseases, from which we caneasily induce patterns expressing the meaning of?How to treat [X] disease?, such as ?
[X] ?
??
??
?, ???
??
[X] ?
?, and ?
[X] ?
???
???.
Therefore, in this work, we try togenerate paraphrase patterns using the extractedparaphrases.In our preliminary experiments, we only induceparaphrase patterns from paraphrases that contain4FPF is not used in paraphrase Q-T validation.SAME RELA DIFFpercent (%) 55.92 44.08 -Table 3: Human labeling of candidate Q-T.no more than 6 words.
In addition, only one slotis allowed in each pair of paraphrase patterns.
Lets1 and s2 be a pair of paraphrases extracted above.If there exist words w ?
s1 and v ?
s2 that satisfy(1) w = v, (2) w and v are not stop words, thenwe can induce a pair of paraphrase patterns by re-placing w in s1 and v in s2 with a slot ?[X]?.
It isobvious that several pairs of paraphrase patternsmay be induced from one pair of paraphrases.4 ExperimentsWe experiment with a query log that contains atotal of 284,316,659 queries.
Statistics reveal that170,315,807 queries (59.90%) lead to at least oneuser click, each having 1.69 clicks on average.
Weextract 287,129,850 raw Q-T pairs using the querylog, from which 4,448,347 pairs of candidate Q-T are left after filtering as described in Section3.2.
Almost all queries and titles are written inChinese, though some of them contain English orJapanese words.
The preprocessing of candidateQ-T includes Chinese word segmentation (WSeg)and NE recognition (NER).
Our WSeg tool is im-plemented based on forward maximum matching,while the NER tool is based on a NE dictionarymined from the web.4.1 Evaluation of Candidate Q-TWe first evaluate candidate Q-T without valida-tion.
To this end, we randomly sampled 5000pairs of candidate Q-T and labeled them manu-ally.
Each pair is labeled into one of the 3 classes:SAME - q and t have the same meaning; RELA - qand t have related meanings; DIFF - q and t haveclearly different meanings.
The labeling resultsare listed in Table 3.
We can see that no candidateQ-T is in the DIFF class.
This is not surprising,since users are unlikely to click on web pages un-related to their queries.To gain a better insight into the data, we ana-lyzed the subtle types of candidate Q-T in bothSAME and RELA classes.
In detail, we sampled13211000 pairs of candidate Q-T from the 5000 pairslabeled above, in which 563 are in the SAMEclass, while the other 437 are in the RELA class.Our analysis suggests that candidate Q-T in theSAME class can be divided into 4 subtle types:?
Trivial change (12.61%): changes of punctu-ation or stop words, such as ???
??
????
and ??????????.?
Word or phrase replacement (68.38%): re-placements of synonymous words or phrases,such as ???
?
?
??
??
?
(howmach is ...)?
and ???
?
?
??
?????
(what is the price of ...)?.?
Structure change (7.10%): changes of bothwords and word orders, such as ??????
??
?
??
(what fruit can I eat on adiet)?
and ??
??
??
??
??
(whatfruit can help loss weight)?.?
Others (11.90%): candidate Q-T that cannotbe classified into the 3 types above.The above analysis reveals that more than twothirds of candidate Q-T in the SAME class are inthe ?word or phrase replacement?
type, while theones with structure changes are slightly more than7%.
We believe this is mainly because queriesand titles are relatively short and their structuresare simple.
Thus structure rewriting can hardly beconducted.
This distribution is in line with thatreported in (Zhao et al, 2008).As for the RELA class, we find that 42.33% ofsuch candidate Q-T share a problem of named en-tity mismatch, such as ???
(US) ??
?????
and ???
(China) ??
??
??
???.
This indicates that the NE similarity featureis necessary in paraphrase validation.4.2 Evaluation of Paraphrase Q-TThe candidate Q-T extracted above are classifiedwith a SVM classifier5 under its default setting.To evaluate the classifier, we run 5-fold cross val-idation with the 5000 human annotated data, inwhich we use 4000 for training and the rest 1000for testing in each run.
The evaluation criteria are5We use libsvm-2.82 toolkit, which can be downloadedfrom http://www.csie.ntu.edu.tw/ cjlin/libsvm/precision (P), recall (R), and f-measure (F), whichare defined as follows:P = ?Sa ?
Sm??Sa?
(9)R = ?Sa ?
Sm??Sm?
(10)F = 2?
P ?RP +R (11)where Sa is the set of paraphrases automaticallyrecognized with the classifier, Sm is the set ofparaphrases manually annotated.
Precision, re-call, and f-measure are averaged over 5 runs inthe 5-fold cross validation.Figure 2 (a) shows the classification results(dark bars).
For comparison, we also show theprecision, recall6, and f-measure of the candidateQ-T (light bars).
As can be seen, the precision isimproved from 0.5592 to 0.7444 after classifica-tion.
F-measure is also evidently enhanced.
Thisresult indicates that the classification-based para-phrase validation is effective.
We then use all ofthe 5000 annotated data to train a classifier andclassify all the candidate Q-T.
Results show that2,762,291 out of 4,448,347 pairs of candidate Q-T are classified as paraphrases.4.3 Evaluation of Paraphrase Q-Q and T-TFrom the paraphrase Q-T, we further extracted934,758 pairs of candidate Q-Q and 438,954 pairsof candidate T-T (without validation).
We ran-domly sampled 5000 from each for human an-notation.
The results show that the precisions ofcandidate Q-Q and T-T are 0.4672 and 0.6860, re-spectively.
As can be seen, the precision of can-didate Q-Q is much lower than that of candidateT-T. Our analysis reveals that it is mainly becausecandidate Q-Q are more noisy, since user queriescontain quite a lot of spelling mistakes and infor-mal expressions.The candidate Q-Q and T-T are also refinedbased on classification.
We first evaluate the clas-sification performance using the 5000 human la-beled data.
The experimental setups for Q-Q and6We assume all possible paraphrases are included in thecandidates, thus its recall is 100%.1322(a) Q-T classification00.20.40.60.811.2cand.
0.5592 1 0.7173para.
0.7444 0.8391 0.7887P R F(b) Q-Q classification00.20.40.60.811.2cand.
0.4672 1 0.6369para.
0.7345 0.6575 0.6938P R F(c) T-T classification00.20.40.60.811.2cand.
0.686 1 0.8138para.
0.7056 0.9776 0.8196P R FFigure 2: Classification precision (P), recall (R), and f-measure (F).T-T classification are the same as that of Q-T clas-sification, in which we run 5-fold cross validationwith a SVM classifier using its default parameters.Figure 2 (b) and (c) give the classification results(dark bars) as well as the precision, recall, and f-measure of the candidates (light bars).We can see that the precision of Q-Q is signifi-cantly enhanced from 0.4672 to 0.7345 after clas-sification, which suggests that a substantial partof errors and noise are removed.
The increase off-measure demonstrates the effectiveness of clas-sification despite the decrease of recall.
Mean-while, the quality of candidate T-T is not clearlyimproved after classification.
The reason shouldbe that the precision of candidate T-T is alreadypretty high.
We then use all 5000 human labeleddata to train a classifier for Q-Q and T-T respec-tively and classify all candidate Q-Q and T-T. Re-sults show that 390,920 pairs of paraphrase Q-Qand 415,539 pairs of paraphrase T-T are extractedafter classification.4.4 Evaluation of Paraphrase PatternsUsing the method introduced in Section 3.4, wehave generated 73,484 pairs of paraphrase pat-terns that appear at least two times in the cor-pus.
We randomly selected 500 pairs and labeledthem manually.
The results show that the preci-sion is 78.4%.
Two examples are shown in Ta-ble 4, in which p1 and p2 are paraphrase patterns.Some slot fillers are also listed below.
We real-p1 [X]?????
?p2 ????
[X]??
(how to open [X] file)slot 7z; ashx; aspx; bib; cda; cdfs; cmp;cpi; csf; csv; cur; dat; dek...p1 ??
[X]??
?p2 ??
[X]???
(poems about [X])slot ??
(prairies);??
(Yangtze River);??
(Mount Tai);??
(nostalgia)...Table 4: Examples of paraphrase patterns.ize that the method currently used for inducingparaphrase patterns is simple.
Hence we will im-prove the method in our following experiments.Specifically, multiple slots will be allowed in apair of patterns.
In addition, we will try to ap-ply the alignment techniques in the generation ofparaphrase patterns, as Zhao et al (2008) did.4.5 AnalysisFeature Contribution.
To investigate the contri-butions of different features used in classification,we tried different feature combinations for each ofour three classifiers.
The results are shown in Ta-ble 5, in which ?+?
means the feature has contri-bution to the corresponding classifier.
As can beseen, the character overlap rate feature (FCOR),cosine similarity feature (FCS), and NE similarity1323Feature Q-T Q-Q T-TFF +FLR +FWORFCOR + + +FCS + + +FED +FNE + + +FPF +Table 5: Feature contribution.feature (FNE) are the most useful, which play im-portant roles in all the three classifiers.
The otherfeatures are useful in some of the classifiers ex-cept the word overlap rate feature (FWOR).
Theclassification results reported in prior sections areall achieved with the optimal feature combination.Analysis of the Paraphrases.
We combine theextracted paraphrase Q-T, Q-Q and T-T and geta total of 3,560,257 pairs of unique paraphrases.Statistics show that only 8380 pairs (0.24%) arefrom more than one source, which indicates thatthe intersection among the three sets is very small.Further statistics show that the average length ofthe queries and titles in the paraphrases is 6.69(words).To have a detailed analysis of the extractedparaphrases, we randomly selected 1000 pairs andmanually labeled the precision, types, and do-mains.
It is found that more than 43% of the para-phrases are paraphrase questions, in which how(36%), what (19%), and yes/no (14%) questionsare the most common.
In addition, we find thatthe precision of paraphrase questions (84.26%)is evidently higher than non-question paraphrases(65.14%).
Those paraphrase questions are usefulin question analysis and expansion in QA, whichcan hardly be extracted from other kinds of cor-pora.As expected, the paraphrases we extract covera variety of domains.
However, around 50% ofthem are in the 7 most popular domains7, includ-ing: (1) health and medicine, (2) documentarydownload, (3) entertainment, (4) software, (5) ed-7Note that pornographic queries have been filtered fromthe query log beforehand.ucation and study, (6) computer game, (7) econ-omy and finance.
This analysis reflects what webusers are most concerned about.
These domains,especially (4) and (6), are not well covered by theparallel and comparable corpora previously usedfor paraphrase extraction.5 Conclusions and Future DirectionsIn this paper, we put forward a novel method thatextracts paraphrases from search engine querylogs.
Our contribution is that we, for the firsttime, propose to extract paraphrases from userqueries and the corresponding clicked documenttitles.
Specifically, three kinds of paraphrasesare extracted, which can be (1) a query and ahit title, (2) two queries that hit the same title,and (3) two titles hit by the same query.
Theextracted paraphrases are refined based on clas-sification.
Using the proposed method, we ex-tracted over 3.5 million pairs of paraphrases froma query log of Baidu.
Human evaluation resultsshow that the precision of the paraphrases is above70%.
The results also show that we can gener-ate high-quality paraphrase patterns from the ex-tracted paraphrases.Our future research will be conducted along thefollowing directions.
Firstly, we will use a muchlarger query log for paraphrase extraction, so as toenhance the coverage of paraphrases.
Secondly,we plan to have a deeper study of the transitivityof paraphrasing.
Simply speaking, we want to findout whether we can extract ?s1, s3?
as paraphrasesgiven that ?s1, s2?
and ?s2, s3?
are paraphrases.6 AcknowledgmentsWe would like to thank Wanxiang Che, Hua Wu,and the anonymous reviewers for their usefulcomments on this paper.ReferencesFarooq Ahmad and Grzegorz Kondrak.
2005.
Learn-ing a Spelling Error Model from Search QueryLogs.
In Proceedings of HLT/EMNLP, pages 955-962.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with Bilingual Parallel Corpora.
In Pro-ceedings of ACL, pages 597-604.1324Regina Barzilay and Lillian Lee.
2003.
Learningto Paraphrase: An Unsupervised Approach UsingMultiple-Sequence Alignment.
In Proceedings ofHLT-NAACL, pages 16-23.Regina Barzilay and Kathleen R. McKeown.
2001.Extracting Paraphrases from a Parallel Corpus.
InProceedings of ACL/EACL, pages 50-57.Rahul Bhagat and Deepak Ravichandran.
2008.
LargeScale Acquisition of Paraphrases for Learning Sur-face Patterns.
In Proceedings of ACL-08: HLT,pages 674-682.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved Statistical Machine Trans-lation Using Paraphrases.
In Proceedings of HLT-NAACL, pages 17-24.Chris Callison-Burch.
2008.
Syntactic Constraintson Paraphrases Extracted from Parallel Corpora.
InProceedings of EMNLP, pages 196-205.Hang Cui, Ji-Rong Wen, Jian-Yun Nie, Wei-Ying Ma.2002.
Probabilistic Query Expansion Using QueryLogs In Proceedings of WWW, pages 325-332.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised Construction of Large ParaphraseCorpora: Exploiting Massively Parallel NewsSources.
In Proceedings of COLING, pages 350-356.Pablo Ariel Duboue and Jennifer Chu-Carroll.
2006.Answering the Question You Wish They HadAsked: The Impact of Paraphrasing for QuestionAnswering.
In Proceedings of HLT-NAACL, pages33-36.Wei Gao, Cheng Niu, Jian-Yun Nie, Ming Zhou, JianHu, Kam-Fai Wong, and Hsiao-Wuen Hon.
2007.Cross-Lingual Query Suggestion Using Query Logsof Different Languages.
In Proceedings of SIGIR,pages 463-470.Ali Ibrahim, Boris Katz, Jimmy Lin.
2003.
Extract-ing Structural Paraphrases from Aligned Monolin-gual Corpora.
In Proceedings of IWP, pages 57-64.Lidija Iordanskaja, Richard Kittredge, and AlainPolgue`re.
1991.
Lexical Selection and Paraphrasein a Meaning-Text Generation Model.
In Ce?cile L.Paris, William R. Swartout, and William C.
Mann(Eds.
): Natural Language Generation in ArtificialIntelligence and Computational Linguistics, pages293-312.David Kauchak and Regina Barzilay.
2006.
Para-phrasing for Automatic Evaluation.
In Proceedingsof HLT-NAACL, pages 455-462.De-Kang Lin and Patrick Pantel.
2001.
Discovery ofInference Rules for Question Answering.
In Natu-ral Language Engineering 7(4): 343-360.Marius Pas?ca and Pe?ter Dienes.
2005.
Aligning Nee-dles in a Haystack: Paraphrase Acquisition Acrossthe Web.
In Proceedings of IJCNLP, pages 119-130.Marius Pas?ca.
2007.
Weakly-supervised Discoveryof Named Entities using Web Search Queries.
InProceedings of CIKM, pages 683-690.Deepak Ravichandran and Eduard Hovy.
2002.
Learn-ing Surface Text Patterns for a Question AnsweringSystem.
In Proceedings of ACL, pages 41-47.Matthew Richardson.
2008.
Learning about the Worldthrough Long-Term Query Logs.
In ACM Transac-tions on the Web 2(4): 1-27.Stefan Riezler, Alexander Vasserman, IoannisTsochantaridis, Vibhu Mittal and Yi Liu.
2007.Statistical Machine Translation for Query Expan-sion in Answer Retrieval.
In Proceedings of ACL,pages 464-471.Satoshi Sekine and Hisami Suzuki.
2007.
AcquiringOntological Knowledge from Query Logs.
In Pro-ceedings of WWW, pages 1223-1224.Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.2002.
Automatic Paraphrase Acquisition fromNews Articles.
In Proceedings of HLT, pages 40-46.Ji-Rong Wen, Jian-Yun Nie, and Hong-Jiang Zhang.2002.
Query Clustering Using User Logs.
In ACMTransactions on Information Systems 20(1): 59-81,2002.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008.
Pivot Approach for Extracting ParaphrasePatterns from Bilingual Corpora.
In Proceedings ofACL-08:HLT, pages 780-788.Shiqi Zhao, Ming Zhou, and Ting Liu.
2007.
LearningQuestion Paraphrases for QA from Encarta Logs.
InProceedings of IJCAI, pages 1795-1800.1325
