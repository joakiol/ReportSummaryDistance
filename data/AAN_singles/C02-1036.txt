Extraposition: A case study in German sentence realizationMichael GAMON?, Eric RINGGER?, Zhu ZHANG?,Robert MOORE?, Simon CORSTON-OLIVER?
?Microsoft ResearchMicrosoft CorporationRedmond, WA 98052{mgamon, ringger, bobmoore,simonco}@microsoft.com?University of MichiganAnn Arbor, MI 48109zhuzhang@umich.eduAbstractWe profile the occurrence of clausalextraposition in corpora from differentdomains and demonstrate that extrapositionis a pervasive phenomenon in German thatmust be addressed in German sentencerealization.
We present two differentapproaches to the modeling of extraposition,both based on machine learned decision treeclassifiers.
The two approaches differ in theirview of the movement operation: oneapproach models multi-step movementthrough intermediate nodes to the ultimatetarget node, while the other approach modelsone-step movement to the target node.
Wecompare the resulting models, trained on datafrom two domains and discuss thedifferences between the two types of modelsand between the results obtained in thedifferent domains.IntroductionSentence realization, the last stage in naturallanguage generation, derives a surface stringfrom a more abstract representation.
Numerouscomplex operations are necessary to producefluent output, including syntactic aggregation,constituent ordering, word inflection, etc.
Weargue that for fluent output from Germansentence realization, clausal extraposition needsto be included.
We show how to accomplish thistask by applying machine learning techniques.A comparison between English and Germanillustrates that it is possible in both languages toextrapose clausal material to the right peripheryof a clause, as the following examples show:Relative clause extraposition:English: A man just left who had come toask a question.German: Der Mann ist geradeweggegangen, der gekommen war, umeine Frage zu stellen.Infinitival clause extraposition:English: A decision was made to leavethe country.German: Eine Entscheidung wurdegetroffen, das Land zu verlassen.Complement clause extraposition:English: A rumor has been circulatingthat he is ill.German: Ein Ger?cht ging um, dass erkrank ist.Unlike obligatory movement phenomena such asWh-movement, extraposition is subject topragmatic variability.
A widely-cited factorinfluencing extraposition is clausal heaviness; ingeneral, extraposition of heavy clauses ispreferred over leaving them in place.
Considerthe following example from the technicaldomain:German: Es werden Datenstrukturenverwendet, die f?r die Benutzer nichtsichtbar sind.English: Data structures are used whichare not visible to the user.This perfectly fluent sentence contains anextraposed relative clause.
If the relative clause isleft in place, as in the following example, theresult is less fluent, though still grammatical:?
Es werden Datenstrukturen, die f?r dieBenutzer nicht sichtbar sind, verwendet.Data structures which are not visible tothe users are used.Table 1 presents a quantitative analysis of thefrequency of extraposition in different corpora inboth English and German.
This analysis is basedon automatic data profiling using the NLPWinsystem (Heidorn 2000).
The technical manualcorpus consists of 100,000 alignedEnglish-German sentence pairs from Microsofttechnical manuals.
The Encarta corpora consistof 100,000 randomly selected sentences from theEncarta encyclopedia in both English andGerman.
The output of the parser waspost-processed to identify relative clauses(RELCL), infinitival clauses (INFCL), andcomplement clauses (COMPCL) that have beenmoved from a position adjacent to the term theymodify.
According to this data profile,approximately one third of German relativeclauses are extraposed in technical writing, whileonly 0.22% of English relative clauses areextraposed in the corresponding sentence set.
Thehigh number of extraposed relative clauses inGerman is corroborated by numbers from theGerman hand-annotated NEGRA corpus.
InNEGRA, 26.75% of relative clauses areextraposed.
Uszkoreit et al (1998) report 24% ofrelative clauses being extraposed in NEGRA, buttheir number is based on an earlier version ofNEGRA, which is about half the size of thecurrent NEGRA corpus.We also used the NEGRA corpus to verify theaccuracy of our data profiling with NLPWin.These results are presented in Table 2.
We onlytook into account sentences that received acomplete parse in NLPWin.
Of the 20,602sentences in NEGRA, 17,756 (86.19%) fell intothat category.
The results indicate that NLPWinis sufficiently reliable for the identification ofrelative clauses to make our conclusionsnoteworthy and to make learning fromNLPWin-parsed data compelling.Extraposition is so rare in English that a sentencerealization module may safely ignore it and stillyield fluent output.
The fluency of sentencerealization for German, however, will suffer fromthe lack of a good extraposition mechanism.GermantechnicalmanualsEnglishtechnicalmanualsGermanEncartaEnglishEncartaRELCL 34.97% 0.22% 18.97% 0.30%INFCL 3.2% 0.53% 2.77% 0.33%COMPCL 1.50% 0.00% 2.54% 0.15%Table 1: Percentage of extraposed clauses in English and German corporaRelative clauseidentification overallIdentification ofextraposed relative clausesIdentification of non-extraposed relative clausesRecall Precision Recall Precision Recall Precision94.55 93.40 74.50 90.02 94.64 87.76Table 2: NLPWin recall and precision for relative clauses on the NEGRA corpusThis evidence makes it clear that any serioussentence realization component for Germanneeds to be able to produce extraposed relativeclauses in order to achieve reasonable fluency.
Inthe German sentence realization module,code-named Amalgam (Gamon et al 2002,Corston-Oliver et al 2002), we have successfullyimplemented both extraposition models asdescribed here.1 Two strategies for modelingextrapositionThe linguistic and pragmatic factors involved inclause extraposition are inherently complex.
Weuse machine learning techniques to leverage largeamounts of data for discovering the relevantconditioning features for extraposition.
As amachine learning technique for the problem athand, we chose decision tree learning, a practicalapproach to inductive inference in widespreaduse.
We employ decision tree learning toapproximate discrete-valued functions from largefeature sets that are robust to noisy data.
Decisiontrees provide an easily accessible inventory of theselected features and some indication of theirrelative importance in predicting the targetfeatures in question.
The particular tool we usedto build our decision trees is the WinMine toolkit(Chickering et al, 1997, n.d.).
Decision treesbuilt by WinMine predict a probabilitydistribution over all possible target values.We consider two different strategies for themachine-learned modeling of extraposition.
Thetwo strategies are a series of movements versus asingle reattachment.1.1 Multi-step movementIn the multi-step movement approach, thequestion to model for each potential attachmentsite of an extraposable clause is whether theclause should move up to its grandparent (a ?yes?answer) or remain attached to its current parent (a?no?
answer).
In other words, we have cast theproblem as a staged classification task.
Atgeneration runtime, for a given extraposableclause, the movement question is posed, and ifthe DT classifier answers ?yes?, then the clause isreattached one level up, and the question is posedagain.
The final attachment site is reached whenthe answer to the classification task is ?no?, andhence further movement is barred.
Figure 1illustrates the multi-step movement of a clause(lower triangle) through two steps to a newlanding site (the reattached clause is the uppertriangle).
Note that in both Figure 1 and Figure 2linear order is ignored; only the hierarchicalaspects of extraposition are represented.Figure 1: Multi-step movement1.2 One-step movementModeling extraposition as a one-step movementinvolves a classification decision for each node inthe parent chain of an extraposable clause.
Theclassification task can be formulated as ?shouldthe extraposable clause move up to this targetfrom its base position??.
Figure 2 shows theone-step movement approach to extraposition inthe same structural configuration as in Figure 1.In this example, out of the three potential landingsites, only one qualifies.
At generation runtime, ifmore than one node in the parent chain qualifiesas a target for extraposition movement, the nodewith the highest probability of being a target ischosen.
In the event of equally likely target nodes,the target node highest in the tree is chosen.Figure 2: One-step movement2 Data and featuresWe employed two different sets of data to buildthe models for German: the 100,000 sentencetechnical manual corpus, and the 100,000sentence Encarta corpus.
The data were split70/30 for training and parameter tuning purposes,respectively.
We extracted features for each datapoint, using the syntactic and semantic analysisprovided by the Microsoft NLPWin system (seeGamon et al 2002 for more details).
We onlyconsidered sentences for feature extraction whichreceived a complete spanning parse in NLPwin.85.14% of the sentences in the technical domain,and 88.37% of the sentences in the Encartacorpus qualified.
The following features wereextracted:?
syntactic label of the node underconsideration (i.e., the starting node for asingle-step movement), its parent andgrandparent, and the extraposable clause?
semantic relation to the parent node ofthe node under consideration, the parentand the grandparent, and theextraposable clause?
status of the head of the node underconsideration as a separable prefix verb,the same for the parent and thegrandparent?
verb position information (verb-secondversus verb-final) for the node underconsideration, the parent and grandparent?
all available analysis features andattributes in NLPWin (see Gamon et al2002 for a complete list of the currentlyused features and attributes) on the nodeunder consideration, the parent andgrandparent, and on the extraposableclause and its parent and grandparent?
two features indicating whether theextraposable node has any verbalancestor node with verb-final orverb-second properties?
?heaviness?
of extraposable clause asmeasured in both number of words andnumber of characters?
?heaviness?
of the whole sentence asmeasured in both number of words andnumber of charactersA total of 1397 features were extracted for themulti-step movement model.
For the single-stepmovement model, we extracted an additional 21features.
Those features indicate for each of the21 labels for non-terminal nodes whether a nodewith that label intervenes between the parent ofthe extraposable clause and the putative landingsite.Another linguistic feature commonly cited asinfluencing extraposition is the length andcomplexity of the part of the structure betweenthe original position and the extraposed clause.Since in the Amalgam generation moduleextraposition is applied before word andconstituent order is established, length ofintervening strings is not accessible as a feature.For each training set, we built decision trees atvarying levels of granularity (by manipulating theprior probability of tree structures to favorsimpler structures) and selected the model withmaximal accuracy on the correspondingparameter tuning data set.Since the syntactic label of the extraposableclause is one of the extracted features, we decidedto build one general extraposition model, insteadof building separate models for each of the threeextraposable clause types (complement clauseCOMPCL, infinitival clause INFCL, and relativeclause RELCL).
If different conditions apply tothe three types of extraposition, the decision treemodel is expected to pick up on the syntacticlabel of the extraposable clause as a predictivefeature.
If, on the other hand, conditions forextraposition tend to be neutral with respect to thetype of extraposable clause, the modeling ofINFCL and COMPCL extraposition can greatlybenefit from the much larger set of data points inrelative clause extraposition.3 ComparisonTo compare the one-step and multi-step models,we processed a new blind test set of 10,000sentences from each domain, Microsoft technicalmanuals and Encarta, respectively.
Thesesentences were extracted randomly from data inthese domains that were neither included in thetraining nor in the parameter tuning set.
For eachextraposable clause, three different outputs werecomputed: the observed behavior, the predictionobtained by iteratively applying the multi-stepmodel as described in Section 1.1, and theprediction obtained by applying the one-stepmodel.
The values for these outputs were either?no extraposition?
or a specific target node.
Ifeither the general extraposition prediction or thepredicted specific target node did not match theobserved behavior, this was counted as an error.3.1 One-step versus multi-step in thetechnical domainAccuracy data on a blind set of 10,000 sentencesfrom the technical manuals domain are presentedin Table 3.One-step Multi-step BaselineRELCL 81.56% 83.87% 60.93%INFCL 93.70% 92.02% 93.70%COMPCL 98.10% 98.57% 94.29%Overall 84.42% 86.12% 67.58%Table 3: Accuracy numbers for the two models inthe technical domainThe baseline score is the accuracy for a systemthat never extraposes.
Both models outperformthe overall baseline by a large margin; themulti-step movement model achieves anaccuracy 1.7% higher than the one-step model.The baselines in INFCL and COMPCLextraposition are very high.
In the test set therewere only 15 cases of extraposed INFCLs and 12cases of extraposed COMPCLs, making itimpossible to draw definite conclusions.3.2 One-step versus multi-step in theEncarta domainResults from a blind test set of 10,000 sentencesfrom the Encarta domain are presented in Table4.One-step Multi-step BaselineRELCL 87.59% 88.45% 80.48%INFCL 97.73% 97.48% 95.72%COMPCL 97.32% 97.32% 95.97%Overall 89.99% 90.61% 84.15%Table 4: Accuracy numbers for the two models inthe Encarta domainAs in the technical domain, the multi-step modeloutperforms the one-step model, and bothoutperform the baseline significantly.
Again,extraposed COMPCLs and INFCLs are rare inthe dataset (there were only 17 and 6 instances,respectively), making the results on these types ofclauses inconclusive.3.3 Domain-specificity of the modelsSince we have data from two very differentdomains we considered the extent to which thedomain-specific models overlapped.
This is alinguistically interesting question: from alinguistic perspective one would expect bothuniversal properties of extraposition as well asdomain specific generalizations to emerge fromsuch a comparison.3.3.1 Feature selection in the technical domainversus EncartaOf the 1397 features that were extracted for themulti-step model, the best model for the technicaldomain was created by the WinMine tools byselecting 60 features.
In the Encarta domain, 49features were selected.
27 features are shared bythe two models.
This overlap in selected featuresindicates that the models indeed capturelinguistic generalizations that are valid acrossdomains.
The shared features fall into thefollowing categories (where node refers to thestarting node for multi-step movement):?
features relating to verbal properties ofthe nodeo a separable prefix verb asancestor nodeo tense and mood of ancestornodeso presence of a verb-final orverb-second VP ancestoro presence of Modals attribute(indicating the presence of amodal verb) on ancestorso verb-position in the current nodeand ancestors?
?heaviness?-related features on theextraposable clause and the wholesentence:o sentence length in characterso number of words in theextraposable clause?
syntactic labels?
the presence of a prepositional relation?
the presence of semantic subjects andobjects on the node and ancestors?
definiteness features?
the presence of modifiers on the parent?
person and number features?
some basic subcategorization features(e.g., transitive versus intransitive)Interestingly, the features that are not shared (33in the model for the technical domain and 27 inthe model for the Encarta domain) fall roughlyinto the same categories as the features that areshared.
To give some examples:?
The Encarta model refers to the presenceof a possessor on the parent node, thetechnical domain model does not.?
The technical domain model selects moreperson and number features on ancestorsof the node and ancestors of theextraposable clause than the Encartamodel.For the one-step model, 1418 total features wereextracted.
Of these features, the number offeatures selected as being predictive is 49 both inthe Encarta and in the technical domain.Twenty-eight of the selected features are sharedby the models in the two domains.
Again, thisoverlap indicates that the models do pick up onlinguistically relevant generalizations.The shared features between the one-step modelsfall into the same categories as the shared featuresbetween the multi-step models.The results from these experiments suggest thatthe categories of selected features aredomain-independent, while the choice ofindividual features from a particular categorydepends on the domain.3.3.2 Model complexityIn order to assess the complexity of the models,we use the simple metric of number of branchingnodes in the decision tree.
The complexity of themodels clearly differs across domains.
Table 5illustrates that for both multi-step and one-stepmovement the model size is considerably smallerin the Encarta domain versus the technicaldomain.One-step Multi-stepEncarta 68 82Technical 87 116Table 5: Number of branching nodes in thedecision treesWe hypothesize that this difference in modelcomplexity may be attributable to the fact thatNLPWin assigns a higher percentage of spanningparses to the Encarta data, indicating that ingeneral, the Encarta data may yield more reliableparsing output.3.3.3 Cross-domain accuracyThe results in Table 3 and Table 4 above showthat the models based on the Encarta domainachieve a much higher overall accuracy (89.99%and 90.61%) than the models based on thetechnical domain (84.42% and 86.12%), but theyare also based on a much higher baseline ofnon-extraposed clauses (84.15% versus 67.58%in the technical domain).
To quantify the domainspecificity of the models, we applied the modelsacross domains; i.e., we measured theperformance of the Encarta models on thetechnical domain and vice versa.
The resultscontrasted with the in-domain overall accuracyfrom Table 3 and Table 4 are given in Table 6.Encarta Model Technical Model1-step Multi 1-step MultiOnEnc.89.99% 90.61% 84.42% 86.12%OnTech.79.39% 83.03% 88.54% 89.20%Table 6: Cross-domain accuracy of the modelsThe results show that for both one-step andmulti-step models, the models trained on a givendomain will outperform the models trained on adifferent domain.
These results are not surprising;they confirm domain-specificity of thephenomenon.
Viewed from a linguisticperspective, this indicates that the generalizationsgoverning clausal extraposition cannot beformulated independently of the text domain.ConclusionWe have shown that it is possible to modelextraposition in German using decision treeclassifiers trained on automatic linguisticanalyses of corpora.
This method is particularlyeffective for extraposed relative clauses, whichare pervasive in German text in domains asdisparate as news, technical manuals, andencyclopedic text.
Both one-step and multi-stepmodels very clearly outperform the baseline inthe two domains in which we experimented.
Thisin itself is a significant result, given thecomplexity of the linguistic phenomenon ofclausal extraposition.
The machine learningapproach to extraposition has two clearadvantages: it eliminates the need forhand-coding of complex conditioningenvironments for extraposition, and it isadaptable to new domains.
The latter point issupported by the cross-domain accuracyexperiment and the conclusion that extrapositionis governed by domain-specific regularities.We have shown that across domains, themulti-step model outperforms the one-step model.In the German sentence realization systemcode-named Amalgam (Corston-Oliver et al2002, Gamon et al 2002), we have experimentedwith implementations of both the one-step andmulti-step extraposition models, and based on theresults reported here we have chosen themulti-step model for inclusion in the end-to-endsystem.As we have shown, extraposed relative clausesoutnumber other extraposed clause types by alarge margin.
Still, the combined model forclausal extraposition outperforms the baselineeven for infinitival clauses and complementclauses, although the conclusions here are notvery firm, given the small number of relevantdata points in the test corpus.
Since the syntacticlabel of the extraposed clause is one of thefeatures extracted from the training data,however, the setup that we have used will adapteasily once more training data (especially forinfinitival and complement clauses) becomeavailable.
The models will automatically pick updistinctions between the generalizations coveringrelative clauses versus infinitival/complementclauses when they become relevant, by selectingthe syntactic label feature as predictive.Finally, evaluation of the types of features thatwere selected by the extraposition models showthat besides the ?heaviness?
of the extraposedclause, a number of other factors from thestructural context enter the determination oflikelihood of extraposition.
This, in itself, is aninteresting result: it shows how qualitativeinspection of a machine learned model can yieldempirically based linguistic insights.AcknowledgementsOur thanks go to Max Chickering for hisassistance with the WinMine toolkit and to theanonymous reviewers for helpful comments.ReferencesChickering D. M., Heckerman D. and Meek C. (1997).A Bayesian approach to learning Bayesiannetworks with local structure.
In "Uncertainty inArtificial Intelligence: Proceedings of theThirteenth Conference", D. Geiger and P. PunadlikShenoy, ed., Morgan Kaufman, San Francisco,California,  pp.
80-89.Chickering, D. Max.
nd.
WinMine Toolkit Home Page.http://research.microsoft.com/~dmax/WinMine/Tooldoc.htmCorston-Oliver S., Gamon M., Ringger E. and MooreR.
(2002).
An overview of Amalgam: amachine-learned generation module.
To appear inProceedings of the Second International NaturalLanguage Generation Conference 2002, New York.Gamon M., Ringger E., Corston-Oliver S.. (2002).Amalgam: A machine-learned generation module.Microsoft Technical Report MSR-TR-2002-57.Heidorn, G. E. (2000): Intelligent Writing Assistance.In "A Handbook of Natural Language Processing:Techniques and Applications for the Processing ofLanguage as Text", R. Dale, H. Moisl, and H.Somers (ed.
), Marcel Dekker, New York, pp.181-207.Uszkoreit, H., Brants T., Duchier D., Krenn B.,Konieczny L., Oepen S. and Skut W. (1998).Aspekte der Relativsatzextraposition im Deutschen.Claus-Report Nr.99, Sonderforschungsbereich 378,Universit?t des Saarlandes, Saarbr?cken, Germany.
