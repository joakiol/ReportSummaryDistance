Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2127?2131,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsSummarizing Online Forum Discussions ?
Can Dialog Acts of IndividualMessages Help?Sumit Bhatia1, Prakhar Biyani2and Prasenjit Mitra21IBM Almaden Research Centre, 650 Harry Road, San Jose, CA 95123, USA2Information Science and Technology, Pennsylvania State University, University Park, PA 16802sumit.bhatia@us.ibm.com, {pxb5080, pmitra}@ist.psu.eduAbstractA typical discussion thread in an online fo-rum spans multiple pages involving par-ticipation from multiple users and thus,may contain multiple view-points and so-lutions.
A user interested in the topic ofdiscussion or having a problem similar tobeing discussed in the thread may not wantto read all the previous posts but only a fewselected posts that provide her a concisesummary of the ongoing discussion.
Thispaper describes an extractive summariza-tion technique that uses textual featuresand dialog act information of individualmessages to select a subset of posts.
Pro-posed approach is evaluated using two reallife forum datasets.1 IntroductionIn recent times, online discussion boards (or fo-rums) have become quite popular as they providean easily accessible platform to users in differentparts of the world to come together, share informa-tion and discuss issues of common interest.
Thearchives of web forums contain millions of discus-sion threads and act as a valuable repository of hu-man generated information that can be utilized forvarious applications.
Oftentimes, the discussionsin a thread span multiple pages involving partici-pation from multiple users and thus, may containmultiple view-points and solutions.
In such a case,the end-user may prefer a concise summary of theongoing discussion to save time.
Further, such asummary helps the user to understand the back-ground of the whole discussion as well as providesan overview of different view-points in a time ef-ficient manner.
In addition to generic forums onthe web, automatic forum summarization methodscan prove to be useful for various domain specificapplications, such as helping students and support-ing tutors in virtual learning environments (Car-bonaro, 2010).A typical discussion thread in a web forum con-sists of a number of individual posts or messagesposted by different participating users.
Often, thethread initiator posts a question to which otherusers reply, leading to an active discussion.
Asan example, consider the discussion thread shownin Figure 1 where the thread starter describes hisproblem about the missing headphone switch inhis Linux installation.
In the third post in thethread, some other user asks about some clarifyingdetails and in the next post the topic starter pro-vides the requested details that makes the problemclearer.
On receiving additional details about theproblem, some other user provides a possible so-lution to the problem (fifth post).
The topic startertries the suggested solution and reports his experi-ence in the next post (sixth post).
Thus, we see thateach individual post in a discussion thread servesa different purpose in the discussion and we positthat identifying the purpose of each such post isessential for creating effective summaries of thediscussions.
Intuitively, the most important mes-sages in a discussion are the ones that describe theproblem being discussed and the solutions beingproposed to solve the problem.The role of an individual message in a discus-sion is typically specified in terms of dialog acts.There have been efforts to automatically assigndialog acts to messages in online forum discus-sions (Jeong et al., 2009; Joty et al., 2011; Bhatiaet al., 2012) and also using dialog acts for linguis-tic analysis of forum data, such as in subjectiv-ity analysis of forum threads (Biyani et al., 2012;Biyani et al., 2014).
In this paper, we describe ourinitial efforts towards addressing the problem ofautomatically creating summaries of such onlinediscussion threads.
We frame forum summariza-tion as a classification problem and identify mes-sages that should be included in a summary of the2127discussion.
In addition to textual features, we em-ploy dialog act labels of individual messages forsummarization and show that incorporating dialogacts leads to substantial improvements in summa-rization performance.Figure 1: An example thread illustrating differentrole played by each post in the discussion.
Differ-ent users are indicated by different colors.2 Definition of Dialog Acts UsedWe use the same set of dialog acts as defined byBhatia et al.
(2012).
Note that based on the appli-cation context and requirements new dialog actscan be defined and added.1.
Question: The poster asks a question whichinitiates discussion in the thread.
This is usuallythe first post in the thread but not always.
Often,the topic initiator or some other user may ask otherrelated questions in the thread.2.
Repeat Question: Some user repeats a previ-ously asked question (e.g.
Me too having the sameproblem.).3.
Clarification: The poster asks clarifying ques-tions in order to gather more details about theproblem or question being asked.
For example,Could you provide more details about the issueyou are facing.4.
Further Details: The poster provides more de-tails about the problem as asked by other fellowposters.5.
Solution: The poster suggests a solution to theproblem being discussed in the thread.6.
Positive Feedback: Somebody tries the sug-gested solution and provides a positive feedback ifthe solution worked.7.
Negative Feedback: Somebody tries the sug-gested solution and provides a negative feedbackif the solution did not work.8.
Junk: There is no useful information in thepost.
For example, someone justs posts a smileyor some comments that is not useful to topic beingdiscussed.
For example, ?bump?, ?sigh?, etc., ormessages posted by forum moderators such as thisthread is being closed for discussion.3 Proposed Approach for ThreadSummarizationIn general, text summarization techniques canbe classified into two categories, namely extrac-tive Summarization, and Abstractive Summariza-tion (Hahn and Mani, 2000).
Extractive summa-rization involves extracting salient units of text(e.g., sentences) from the document and then con-catenating them to form a shorter version of thedocument.
Abstractive summarization, on theother hand, involves generating new sentences byutilizing the information extracted from the doc-ument corpus (Carenini and Cheung, 2008), andoften involves advanced natural language process-ing tools such as parsers, lexicons and grammars,and domain-specific knowledge bases (Hahn andMani, 2000).
Owing to their simplicity and goodperformance, extractive summarization techniquesare often the preferred tools of choice for varioussummarization tasks (Liu and Liu, 2009) and wealso adopt an extractive approach for discussionsummarization in this work.3.1 Summarization Unit ?
IndividualSentence vs Individual MessageBefore we can perform extractive summarizationon discussion threads, we need to define an ap-propriate text unit that will be used to constructthe desired summaries.
For typical summariza-tion tasks, a sentence is usually treated as a unit oftext and summaries are constructed by extractingmost relevant sentences from a document.
How-ever, a typical discussion thread is different from2128a generic document in that the text of a discus-sion thread is created by multiple authors (usersparticipating in the thread).
Further, the text ofa discussion can be divided into individual usermessages, each message serving a specific rolein the whole discussion.
In that sense, summa-rizing a discussion thread is similar to the taskof multi-document summarization where contentof multiple documents that are topically related issummarized simultaneously to construct an inclu-sive, coherent summary.
However, we also notethat an individual user message in a discussion ismuch smaller than a stand-alone document (com-pare 3 ?
4 sentences in a message to a few dozensentences in a document).
Thus, the sentences in amessage are much more coherent and contextuallyrelated to each other than in a stand-alone docu-ment.
Hence, selecting just a few sentences from amessage may lead to loss of context and make theresulting summaries hard to comprehend.
There-fore, in this work, we choose each individual mes-sage as a text unit and thus, the thread summariesare created by extracting most relevant posts froma discussion.3.2 Framing Thread Summarization as PostClassificationWe consider the problem of extracting relevantposts from a discussion thread as a binary classifi-cation problem where the task is to classify a givenpost as either belonging to the summary or not.We perform classification in a supervised fashionby employing following features.1.
Similarity with Title (TitleSim): This featureis computed as the cosine similarity score betweenthe post and the title of the thread.2.
Length of Post (Length): The number ofunique words in the post.3.
Post Position (Position): The normalized po-sition of the post in the discussion thread.
It isdefined as follows:Position of the post in the threadTotal # of posts in the thread(1)4.
Centroid Similarity (Centroid): This fea-ture is obtained by computing the cosine similarityscore between the post document vector and thevector obtained as the centroid of all the post vec-tors of the thread.
Similarity with centroid mea-sures the relatedness of each post with the under-lying discussion topic.
A post with a higher sim-ilarity score with the thread centroid vector indi-cates that the post better represents the basic ideasof the thread.5.
Inter Post Similarity: This feature is com-puted by taking the mean of the post?s cosine sim-ilarity scores with all the other posts in the thread.6.
Dialog Act Label (Class): This is a set of bi-nary features indicating the dialog act class labelof the post.
We have one binary feature corre-sponding to each dialog act.4 Experimental Evaluation4.1 Data DescriptionWe used the dataset used by Bhatia et al.
(2012)that consists of randomly sampled 100 threadsfrom two different online discussion forums?
ubuntuforums.org and tripadvisor.com.
There are a total of 556 posts in the 100threads from Ubuntu dataset and 916 posts in 100threads from NYC dataset.
The associated dialogact labels of individual messages in each of thethreads are also available.Next, for creating data for the summarizationtask, two independent human evaluators (H1 andH2) were recruited to create summaries of thediscussion threads in the two datasets.
For eachthread, the evaluators were asked to read the wholediscussion and write a summary of the discussionin their own words.
The annotators were requestedto keep the length of summaries roughly between10% and 25% of the original text length.
Thus foreach thread, we obtain two human written sum-maries.These hand-written summaries were then usedto identify most relevant posts in a discussionthread in a manner similar to one used by Ram-bow et al.
(2004).
We compute cosine similarityscores for each post in the thread with the corre-sponding thread summary and the top k rankedposts are then selected to be part of the sum-mary of the thread.
The number k is deter-mined by the compression factor used for creat-ing summaries.
We choose a compression fac-tor of 20%.
The top k ranked posts, thus consti-tute the gold summary of each thread.
Note thatwe obtain two gold summaries for each thread ?one corresponding to each evaluator.
This sum-marization data can be downloaded for researchpurposes from http://sumitbhatia.net/source/datasets.html.2129Evaluator MethodUbuntu NYCPrecision F-1 Precision F-1Baseline 0.39 0.53 0.32 0.46H1Without Dialog Acts 0.578 0.536 0.739 0.607With Dialog Acts 0.620 0.608 0.760 0.655Gain +7.27% +13.43% +2.84% +7.91%Baseline 0.38 0.52 0.31 0.45H2Without Dialog Acts 0.739 0.607 0.588 0.561With Dialog Acts 0.760 0.655 0.652 0.588Gain +14.94% +20.53% +10.88% +4.81%Table 1: Results of post classification for summarization task.
H1 and H2 correspond to the two hu-man evaluators.
Percentage improvements obtained by addition of post class label information is alsoreported.4.2 BaselineAs a baseline method, we use a rule based clas-sifier that classifies all the Question and Solutionposts in a thread as belonging to the summary anddiscards the remaining posts.4.3 Results and DiscussionsWe used Naive Bayes classifier as implementedin the Weka machine learning toolkit (Hall et al.,2009) for classification experiments.
We trainedthe classifier on 75% of the data and used the re-maining 25% for testing.
Table 1 reports the clas-sification results using (i) the baseline method,(ii)features 1?5 only, and (iii) using all the features(dialog act labels, in addition to the five features).For both the datasets, we observe that incorpo-rating dialog act information along with textualfeatures results in performance gain across all re-ported metrics.
The strong performance improve-ments achieved for the two datasets corroboratethe proposed hypothesis that knowing the roleof each individual message in an online discus-sion can help create better summaries of discus-sion threads.
Further, we observe that the preci-sion values are very low for the baseline algorithm(from 0.31 to 0.39) with moderate F-1 values (0.45to 0.53), indicating a higher recall.
This meansthat even though many of the posts in the goldsummaries belong to question and solution cate-gories, not all the posts belonging to these two cat-egories are useful for summarization.
Using tex-tual features and dialog act labels in a supervisedmachine learning framework captures the distin-guishing characteristics of in-summary and out ofsummary posts and thus, yields a much better clas-sification performance.5 Related WorkAmong various applications of text summariza-tion, work on E-Mail thread summarization (Ram-bow et al., 2004; Cohen et al., 2004) can be con-sidered as closely related to the problem discussedin this paper.
An E-Mail thread is similar to a fo-rum discussion thread in that it involves back andforth communication with the participants, how-ever, the problem of discussion thread summariza-tion is very different (and difficult) due to a rela-tively larger number of participants, highly infor-mal and noisy language, and frequent topic driftsin discussions.
Zhou and Hovy (2005) identifyclusters in internet relay chats (irc) and then em-ploy lexical and structural features to summarizeeach cluster.
Ren et al.
(2011) have proposed a fo-rum summarization algorithm that models the re-ply structures in a discussion thread.6 Conclusions and Future WorkWe proposed that dialog act labels of individualmessages in an online forums can be helpful insummarizing discussion threads.
We framed dis-cussion thread summarization as a binary clas-sification problem and tested our hypothesis ontwo different datasets.
We found that for boththe datasets, incorporating dialog act informationas features improves classification performance asmeasured in terms of precision and F-1 measure.As future work, we plan to explore various otherforum specific features such as user reputation andquality of content to improve summarization per-formance.2130ReferencesSumit Bhatia, Prakhar Biyani, and Prasenjit Mitra.2012.
Classifying user messages for managing webforum data.
In Proceedings of the 15th InternationalWorkshop on the Web and Databases 2012, WebDB2012, Scottsdale, AZ, USA, May 20, 2012, pages 13?18.Prakhar Biyani, Sumit Bhatia, Cornelia Caragea, andPrasenjit Mitra.
2012.
Thread specific features arehelpful for identifying subjectivity orientation of on-line forum threads.
In COLING 2012, 24th Inter-national Conference on Computational Linguistics,Proceedings of the Conference: Technical Papers, 8-15 December 2012, Mumbai, India, pages 295?310.Prakhar Biyani, Sumit Bhatia, Cornelia Caragea,and Prasenjit Mitra.
2014.
Using non-lexical features for identifying factual andopinionative threads in online forums.Knowledge-Based Systems, In Press, doi =http://dx.doi.org/10.1016/j.knosys.2014.04.048.Antonella Carbonaro.
2010.
Towards an automaticforum summarization to support tutoring.
In Mil-tiadisD.
Lytras, Patricia Ordonez De Pablos, DavidAvison, Janice Sipior, Qun Jin, Walter Leal, LornaUden, Michael Thomas, Sara Cervai, and DavidHorner, editors, Technology Enhanced Learning.Quality of Teaching and Educational Reform, vol-ume 73 of Communications in Computer and In-formation Science, pages 141?147.
Springer BerlinHeidelberg.Giuseppe Carenini and Jackie Chi Kit Cheung.
2008.Extractive vs. nlg-based abstractive summarizationof evaluative text: The effect of corpus controver-siality.
In Proceedings of the Fifth InternationalNatural Language Generation Conference, pages33?41.
Association for Computational Linguistics.William W. Cohen, Vitor R. Carvalho, and Tom M.Mitchell.
2004.
Learning to Classify Email into?Speech Acts?.
In EMNLP, pages 309?316.
ACL.Udo Hahn and Inderjeet Mani.
2000.
The challengesof automatic summarization.
Computer, 33(11):29?36.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA Data Mining Software: An Up-date.
SIGKDD Explorations, 11(1).Minwoo Jeong, Chin-Yew Lin, and Gary Geunbae Lee.2009.
Semi-supervised speech act recognition inemails and forums.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 3 - Volume 3, EMNLP?09, pages 1250?1259.Shafiq R. Joty, Giuseppe Carenini, and Chin-Yew Lin.2011.
Unsupervised modeling of dialog acts inasynchronous conversations.
In IJCAI, pages 1807?1813.
IJCAI/AAAI.Fei Liu and Yang Liu.
2009.
From extractive to ab-stractive meeting summaries: can it be done by sen-tence compression?
In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 261?264.
Association for Computational Linguistics.O.
Rambow, L. Shrestha, J. Chen, and C. Laurdisen.2004.
Summarizing email threads.
Proceedings ofHLT-NAACL 2004: Short Papers.Zhaochun Ren, Jun Ma, Shuaiqiang Wang, and YangLiu.
2011.
Summarizing web forum threads basedon a latent topic propagation process.
In Proceed-ings of the 20th ACM International Conference onInformation and Knowledge Management, CIKM?11, pages 879?884, New York, NY, USA.
ACM.Liang Zhou and Eduard Hovy.
2005.
Digesting vir-tual ?geek?
culture: The summarization of technicalinternet relay chats.
In Proceedings of the 43rd An-nual Meeting on Association for Computational Lin-guistics, ACL ?05, pages 298?305, Stroudsburg, PA,USA.
Association for Computational Linguistics.2131
