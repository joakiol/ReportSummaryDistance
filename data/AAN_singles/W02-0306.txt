A Transformational-based Learner for Dependency Grammars inDischarge SummariesDavid A. Campbell M.
Phil., Stephen B. Johnson Ph.D.Department of Medical Informatics, Columbia UniversityAbstractNLP systems will be  more portableamong medical domains if acquisitionof semantic lexicons can befacilitated.
We are pursuing lexicalacquisition through the syntacticrelationships of words in medicalcorpora.
Therefore we require asyntactic parser which is flexible,portable, captures head-modifier pairsand does not require a large trainingset.
We have designed a dependencygrammar parser that learns through atransformational-based algorithm.We propose a novel design fortemplates and transformations whichcapitalize on the dependency structuredirectly and produces human-readablerules.
Our parser achieved a 77%accurate parse training on only 830sentences.
Further work will evaluatethe usefulness of this parse for lexicalacquisition.1 IntroductionNatural Language is a vital medium inmedicine.
Health care providers rely on medicalnarratives for recording, representing andsharing complex medical information such asthe description of images, explanation of testresults, or the summary of a patient?s hospitalvisit.
Natural Language Processing (NLP) toolshave been applied to medical narrative for avariety of applications, such as triggeringclinical alerts (Friedman, 1997) and documentclassification (Wilcox, 2000).The effort required to create and maintainNLP systems in the medical setting can beprohibitive.
Most language processors require adomain-specific semantic lexicon to functionand, so far, these lexica have been createdmanually.
The time and cost involved increating these knowledge structures put limitson the extensibility and portability of NLPsystems (Hripcsak, 1998).
One solution to thisbottleneck is to use machine learning to assist incategorizing lexemes into semantic classes.Such a tool could reduce the difficulty in portingNLP systems from one domain to another.2 Dependency GrammarsOne approach to semantic categorization isthe use of syntactic features (Kokkinakis, 2001).This is based on the assumption that lexemesthat share similar syntactic relations to otherlexemes in the corpus will be semanticallysimilar (Dorr, 2000).
The idea of clusteringwords based on syntactic features has been wellinvestigated in general language (Pereira, 1993;Li, 1998)  However, (Harris, 1991) states thatthe syntactic relationships are more well-definedand have less variation in scientific languages(sublanguages), such as the ones used in medicaltexts.
Identifying word classes using syntacticrelationships should be simpler and potentiallymore useful in these types of languages.Dependency grammars (Hudson, 1991)generate parses where words in a sentence arerelated directly to the word which is its syntactichead.
Each word, except for the root has exactlyone head, and the structure is a tree.
Theanalysis does not generate any intermediatesyntactic structures.
Figure 1 shows an exampleof a sentence with a dependency grammar parse.There has been interest in learning dependencygrammars from corpora.
Collins (Collins, 1996)used dependencies as the backbone for hisprobabilistic parser and there has been work onlearning both probabilistic (Carroll, 1992; Lee,1999; Paskin, 2001) and transformation baseddependency grammars (Hajic, 1997).There are a number of attributes ofdependency grammars which make them idealfor our goal of investigating medicalsublanguage.
First, the semantics of a word areoften defined by a feature space of relatedwords.
The head-dependent relationshipsgenerated by a dependency parse can be used asthe relationship for acquisition.
Second,dependency grammars may be a better fit forparsing medical text.
Medical text is frequentlyAssociation for Computational Linguistics.the Biomedical Domain, Philadelphia, July 2002, pp.
37-44.Proceedings of the Workshop on Natural Language Processing ininclude telegraphic omissions, run-on structures,improper use of conjunctions, left attachingnoun modifiers etc (Sager, 1981).
In manycases, many traditional phrase structures areabsent or altered, making a phrase structureparse using traditional production rules difficult.A dependency grammar may still capture usefulsyntactic relationships when an accurate phrasegrammar parse is not possible.
In this way, adependency parse may be compared to ashallow parse, in that it can return a partialanalysis.
However, even with a shallow parser,we would still interested in the dependencyrelationships inside the chunks.
Third, thesyntactic grammar of medical English,specifically regarding discharge summaries, issimpler overall (Campbell, 2001).
We are notinterested so much in the labeling ofintermediate syntactic structures, such as nounphrases and prepositional phrases.
Dependencygrammars may allow us to capitalize on therelative syntactic simplicity of medical languagewithout the overhead of generating andidentifying structures which will not be used.Figure 1.
Dependency grammar parse of thesentence ?In general she was sleeping quietly.
?The dependency grammar used in thisexperiment did not allow crossing dependencies(projectivity).
Crossing dependencies are oneswhere the parent and child of a relationship areon opposite sides of a common ancestor.3 Transformational BasedLearningTransformational Based Learning (TBL) hasbeen applied to numerous language learningproblems, including part-of-speech tagging(Brill, 1994) , and parsing (Florian, 1998).
Italso has been used for learning dependencygrammars (Hajic, 1997).
In general, TBLalgorithms generate smaller rule sets and requireless training material than probabilisticapproaches.
Brill produced a part-of-speechtagger which was comparable in accuracy toother tagging methods.In language, the general paradigm for TBL isto generate logical rules which applytransformations to the text.
The training text  isfirst annotated with the goal state.
In this case,the sentences would be assigned a dependencyparse.
An initial state annotator is then appliedto an unannotated copy of the text.
Forexample, a right branching dependency tree wasused in our experiment as the initial state(compare figure 1 and figure 2).
The goal ofTBL is to then generate rules which transformthe na?ve training state into the goal state.
Inorder to do so, the TBL algorithm will havetemplates which describe the environment in thetraining corpus where a transformation canoccur.
The algorithm also has a scoringfunction which allows the comparison of thetraining state to the goal state.
After iteratingthrough the training corpus and testing allcombinations of templates and transformations,the paired template and transformation whichhas the highest score  becomes a rule.
In otherwords, the best rule is the one which results in acorpus closest to the goal state after applying thetransformation at the locations indicated by thetemplate.
This best rule is applied to thetraining corpus to produce a refined corpus.
Theprocess is then repeated, using the refinedcorpus as the training corpus, until no morepositively scoring rules are produced.
The finalproduct is an ordered set of rules which can beapplied to any unannotated corpus.Figure 2.
The initial dependency parse of thesentence ?In general she was sleeping quietly.
?TBL is a good choice for learning adependency grammar of medical language.Assigning dependency heads is a task that issimilar to part-of-speech tagging; each word inthe text has exactly one dependency head,represented by the index of the head word.Transformations to this representation consist of.was/VBDgeneral/JJshe/PN sleeping/VBGquietly/RBIn/IN.was/VBDgeneral/JJshe/PNquietly/RBsleeping/VBGIn/INchanging a word?s dependency head from oneword to another.4     The Learning Algorithm4.1 Template DesignIn TBL, transformations occur when aspecific environment in the text is found.
Theseenvironments, or triggers, are defined by theproximal relationship of two or more parts ofspeech within a sentence.
For example, inBrill?s early work with POS tagging, one triggerwas the existence of another specific POS tagimmediately preceding the one to betransformed.
The triggers, therefore, composethe ?if?
component of the ?if-then?transformational rules.When considering what triggers would beappropriate for dependency grammars, it wasnoted that many arcs in the grammar span anumber of words.
For example, the arc betweena verb and the head of a noun phrase may spanmany words, especially in medical narrativeswhere noun phrases can be especially lengthy.In previous attempts to parse language usingTBL templates, the triggers have been tokens inthe vicinity of the token to be transformed.While this has been successful for POS tagging,where the context necessary to correctlytransform the tag may be found within two orthree surrounding tokens, the distance of somedependency relationships can be much greater.In order to capture long distance relationshipsexplicitly in a trigger, it would be necessary toexpand the vicinity to be searched.In the case of a dependency grammar parse,words are related to each other not only throughtheir left-to-right arrangement, but also throughthe dependency tree.
We sought to designtriggers that take advantage of the dependencytree itself.
Using the dependency relationshipsdirectly in the trigger is in the spirit of TBLwhere learning must change the triggeringenvironments in the corpus from one iteration tothe next.
For example, in the case of POS taglearning, newly learned POS tags are used insubsequent iterations of the algorithm astriggers.
Similarly, by using the dependencyrelationship directly in the trigger, we wouldexpect the learner to capitalize on parseimprovements through the learning process.Each trigger used in this experiment had sixparameters, which defined the vicinity around atarget token, summarized in figure 3.
Triggerscan search using solely word distance, treedistance, or a combination of both.
Anytemplate can have multiple triggers, requiringmultiple criteria to be met before consideredtrue.Figure 3.
Trigger design and examplesThe parameters of direction and distance areself-explanatory.
Scope defines whether or notthe triggering token must be exactly at thelocation defined by the distance, or within thatdistance.
The third setting for scope is a specialcase.
If the scope is set to all the template willsearch all tokens in the direction set, regardlessof distance (e.g.
if the tree direction is set to leftand the scope is set to all, the trigger will matchall tokens to the left, regardless of distance).Trigger parameters1.
Word distance2.
Word direction (left, right, either)3.
Word scope (exactly at, within, all)4.
Tree distance5.
Tree direction (parent, child, either)6.
Tree scope (exactly at, within, all)Example 1.Trigger:W-dist = 2  W-dir = right  W-scp = withinT-dist  = 1   T-dir  = child  T-scp = withinExample 2Trigger:W-dist = 2  W-dir = right  W-scp = ex.
at.T-dist  = 2   T-dir  = par   T-scp  =  ex.
atx12x22Two examples of triggers are given in figure 3.In both cases the triggers are searching forelements near token x which meet the correctcriteria.
In the first example, the trigger criteriawill be met by any token within the shaded areaof the tree, those tokens which are either one ortwo tokens to the right of x and are descendentsof x with a tree distance of one.
The secondtrigger will match a single token, shown as ablack circle, that is exactly two tokens to theright of x and is also an ancestor of tree distancetwo.4.2 TransformationsThe second principal component of a TBLrule is the transformation, which defines achange to the structure of the sentence.
Forexample, in the case of POS tagging, thetransformation would be to change POS tag x toPOS tag y.
When TBL has been applied toparsing, the transformations have been onbracketed parse trees and have added or deletedbrackets in a balanced method.
Where thetransformations seem intuitive for POS tagging,they are not as transparent for parsing.
A rulefor POS tagging may read, ?If tag x is DT andtag y immediately to the right is VB, change  tagy to NN.?
(see figure 4)  This makes sense, forwe do not expect verbs to immediately traildeterminers, and transforming the verb to a nounwould likely correct an error.
A rule for parsingmay read ?If a bracket is immediately left ofNN, delete a bracket to the left of the NN.?
Thisrule will combine a phrase which has a noun asthe left-most component with the phrase whichcovers it.
While this makes some sense, asmany phrases do not have nouns as their left-most component, there are also many phraseswhich do.
The linguistic motivation behind thetransformation is not immediately obvious.We wanted to give our transformationsthe intuitive readability of the rules seen in thePOS tagging rules.
In the case of ourdependency grammar, we wanted ourtransformations to describe changes madedirectly to the tree.
We considered four ways inwhich one token in the tree could be moved inrelation to another outlined in figure 5.
All fourof the transformations decompose to the firsttransform.
These transformations make intuitivesense for dependency grammars.
We want toidentify tokens in the text which are in theincorrect tree configuration and transform thetree by changing the dependency relationships.For example, the transformations ?Make a nounthe child of a verb?
or ?Make adjectives siblingsof each other?
are both readable in English andare linguistically reasonable.Figure 4.
Examples of applyingtransformations in POS tagging and parsingSome transformations are disallowed in thespecial case that the root node is involved.
Theroot node has no parent and can have no siblingsand therefore transformations which wouldcreate these circumstances are not allowed.
Theshape of the dependency tree is restricted inother ways as described above, in that the treeshave no crossing dependencies.
Theserestrictions are not enforced by thetransformations and it is possible that they couldgenerate trees that violate these restrictions.4.3 Rule ScoringAt every iteration, it is necessary to evaluate thegoodness of the parse that results from theapplication of all tested rules.
The rule whichproduces the best parse for that iteration is theone that is chosen and applied before continuingon to the next iteration.
A number of measuresfor measuring parsing accuracy have beenestablished, including bracketing sensitivity andspecificity.
Parsing accuracy for dependencyPart-of-speech rule applicationBefore:  The/DT fly/VB on/IN the/DT wall/NNApply Rule: If VB right of DT change VB to NNAfter:    The/DT fly/NN on/IN the/DT wall/NNBracketed-tree rule applicationBefore:(((The/DT (fly/NN on/IN)) the/DT) wall/NN)Apply Rule:  If ?(?
left of NN delete ?(?
on leftAfter(((The/DT fly/NN on/IN) the/DT) wall/NN)grammars is often measured as a function of thenumber of tokens which have the correctancestors, or dependency accuracy.
Keepingour goal of generating word-modifier pairs forsubsequent machine learning, we chose anaggressive scoring function, counting onlycorrect parent-child relationships.
This alsokeeps the scoring function as simple as possible.Dependency grammar transformations1.
Make x the child of y2.
Make x the parent of y3.
Make x the sibling of y keeping x?sparent4.
Make x the sibling of y keeping y?sparentFigure 5.
The four basic transformations4.4 The AlgorithmThe general design of TBL algorithms hasbeen well described (Brill, 1994).
The essentialcomponents, outlined above, include thetemplate design, the transformations used, andthe scoring system.
The initial state of thedependency tree is the right branching treeshown in figure 2.
To improve efficiency, weuse the indexed TBL method  outlined byRamshaw and Marcus (Ramshaw, 1994).
Ruleshave pointers to the sentences to which theyapply, and similarly each sentence has pointersto the rules which have applied to it in the past.Rules are held on a heap based on their score,allowing the best rule to be found immediatelyafter each iteration.
The rule is applied to thelist of sentences to which it points, and this listis used in the next iteration so no sentenceswhich have not been modified need be seen.5 MethodsA corpus of 1000 sentences (16,949 words)of text from medical discharge summaries wassplit into a training set of 830 sentences (13,954words) and a test set of 170 sentences (2,995words).
The entire corpus was first POS taggedusing a tagger trained specifically for dischargesummaries (Campbell, 2001).
The corpus wasthen hand parsed with a dependency grammar,and the TBL learner was allowed to learn ruleson the training set.
The sentences in the corpuswere not restricted by length.
Three sets ofincreasingly complex templates were used tolearn rules, summarized in figure 6.Figure 6.
Three template sets usedCorpus score =  # correct dependenciesTemplate Set #11.
Word distance:2.
Word direction:3.
Word scope:4.
Tree distance:5.
Tree direction:6.
Tree scope:1, 2, or 3left, right, or eitherexactly at, within, or allnot usednot usednot usedTemplate Set #21.
Word distance:2.
Word direction:3.
Word scope:4.
Tree distance:5.
Tree direction:6.
Tree scope:all of set 1, and .
.
.not usednot usednot used1, 2, or 3child, parent or eitherexactly at, within, or allTemplate Set #31.
Word distance:2.
Word direction:3.
Word scope:4.
Tree distance:5.
Tree direction:6.
Tree scope:all of set 1, 2, and.
.
.1,2 or 3left, right, or eitherexactly at, within, or all1, 2, or 3child, parent or eitherexactly at, within, or allx y yxx yyxxy zxzyx wxwy y# of dependencies in corpus6 ResultsThe three template sets generated three rulesets, each of which was evaluated on the 170sentence test set.
Each template set was trainedwith increasing amounts of the training corpusto measure the effect of the training set size onthe learner?s accuracy.
Chart 1 shows theimprovement in accuracy gained through largertraining sets.
The best dependency accuracy andnumber of rules generated for each template setis reported in table 1.Table 1.
Results for three template sets usedTable 2.
Effect of sentence length on accuracyTo measure the effect of sentence length onparsing accuracy, the best parser rules were re-tested on two subsets of the test sets.
The firstsubset contained sentences with a length lessthan ten words and the second containedsentences of length less than twenty.
Theresulting accuracy of the parser on thesesentences is summarized in table 2.
The top tenrules acquired with the third template set arereported in table 3.7 Discussion and Further WorkFor all sets of templates, the learner produced arule-based parser with dependency accuracyexceeding 75% when sentence length was notrestricted.
For the best parser generated,limiting the sentence length to 20 and 10 wordsimproved the parsing accuracy to 80.1% and87.6%.
Little difference among the templatesets was found, although the use of tree-basedtemplates gave slightly better performance.Although we expected the inclusion of treebased templates to improve the performance ofthe parser by a greater extent than observed, it issignificant that the learner was reasonablysuccessful with only word-order information.The strongest syntactic dependencies in medicallanguage may be local and the addition of thetree-oriented templates is not very significant.However, when the tree information is available,the learner does use it, as can be seen by thenumber of rules using tree information in thethree sets shows (table 1).
For the third templateset, 46% of the rules learned incorporated treeinformation.Base POS {POS of current token}Trig.
POS      {POS to be found by trigger}W/T Dis {# of tokens trigger is from base}W Dir  {1 = right, -1 = left, 0 = either }T Dir  {1 = par, -1 = child, 0 = either }W/T Scp {1 = at, 2 = within, 3 = all}Xf   {1 = make child, 2 = make par}Table 3.
First 5 rules learned by template set 3The rules generated are easily translated intoEnglish and make good linguistic sense.
Thefirst rule in Table 2 reads ?If this is a singularnoun (Base POS = NN) and there is apreposition (Trg POS = IN) within (W. scp = 2)three tokens (W. dis = 3) to the left (W. dir =-1)then make the preposition the parent of thenoun.?
This is the type of rule we would expectto see, as it begins forming prepositionalphrases attaching to prepositions on the left.The third rule uses information in thedependency tree, reading ?If this is a simple pastverb and there is a singular noun that is thegrandparent, make that noun the child of theverb.
?TemplateSetRulestestedParserRulesTreeRulesParseacc.Set 1 48K+ 424 0 76.5%Set 2 93K+ 498 127 77.0%Set 3 187K+ 541 249 77.0%Test set SentencelengthTotalSents.Avg.LengthParseacc.1 n <= 10 61 7.1 87.6%2 n <= 20 127 11.4 80.1%Full all n 200 17.9 77.0%BasePOSTrg.POSWDisWDirWScpTDisTDirTScpXf1 NN IN 3 -1 2 0 0 0 22 IN NN -1 1 2 0 0 0 23 VBD NN 0 0 0 2 1 1 14 JJ NN 2 1 2 0 0 0 25 VBD VBN 3 1 2 0 0 0 10.650.70.750.80 100 200 300 400 500 600 700 800 900Training set size (sentences)DependencyaccuracyTemplate Set 1Template Set 2Template Set 3Chart 1.
Effect of training set size on dependency accuracy for three template setsThe greatest drawback to this approach isthe computing requirements.
The consequenceof the complex template design used is a largenumber of rules which need to be kept inmemory.
The third template set generated over187,000 rules which need to be stored inmemory.
Of these, only 240 rules were kept inthe rule set.
Because each rule needs to store alist of pointers back to the sentences to which itapplied, the size of a rule grows with the size ofthe training set.
It will be crucial to incorporaterule pruning in the future to allow larger trainingsets and more complex templates.Although the results shown here are fortraining on a specific corpus of dischargesummaries, the learning algorithm itself isdomain independent.
We foresee generatingparsers on a number of medical corpora,including radiology reports, pathology reportsand progress notes.
Therefore, we require aflexible solution that would not demandreengineering the parser for every new domain.The learning algorithm described here could beused on any general corpus where the sentencescan be given a dependency parse.
We intend toevaluate the algorithm on more general corporain the future.Overall, the results are very encouraging.Keeping in mind our goal of gathering head-modifier pairs for machine learning, a 77%accurate parse is approaching an acceptableparse (Sekine, 1992).
The results also show thatlimiting the sentence length can improve theaccuracy of the parser.
If our sole desire is thegeneration of head-modifier pairs, using a largenumber of shorter sentences may be equivalentto using fewer longer ones.
We also believe thatthe parser may be improved throughlexicalization, but that remains future work.The ability to generate a good parser fromsuch a small training set is important in themedical domain.
Previous work has shown thatdifferent medical domains have to be treated asseparate languages for successful NLP(Friedman, 1995).
Therefore, it is likely thatany medical domain we wish to parse willrequire its own training set for the parser.
Ifextensive training set preparation was required,then we are simply trading one difficult task foranother: the task of manually creating andmaintaining a semantic lexicon with the task ofhand dependency-parsing large amounts of text.Although the task of hand-parsing 1,000sentences of discharge summaries is not trivial,it is reasonable and manageable and does notrequire extensive medical  knowledge.
Theshift-reduce parser  described by (Hermjakob,1997) also requires relatively few  trainingexamples but requires semantic features thatmay require  medical knowledge to constructand assign.
Although we do not propose here aspecific application for a dependency grammarin a medical domain, we believe it will bevaluable for future clustering, disambiguationand indexing applications.8 ConclusionsNatural language processors in the medicaldomain will be more flexible and portable withassisted lexicon design.
The syntacticdependencies in a dependency grammar may beuseful for the lexical acquisition necessary tomake this possible.
We have investigated usingtransformational-based learning as a techniquefor learning a dependency grammar in a medicalcorpus.
To better learn dependency grammarswe used a template design which uses thestructure of the parse tree explicitly andtransformations that operated directly on thetrees.
Training on a set of 830 sentences ofparsed medical discharge summaries gave a bestparser with 77% accuracy.
The inclusion of treeinformation in the template design slightlyimproved the parser.
The rules produced wereintuitive and understandable, and the limitedamount of training material will allow thetechnique to be used on other medical domainswithout extensive manual parsing.
Further workwill test the utility of head-dependencyrelationships for machine learning semanticclasses.ReferencesBrill, E. (1994).
A report of recent progress intransformation-based error-driven learning.
InProceedings of the Twelfth NationalConference on Artificial Intelligence,Princeton, NJ.Campbell, D.A., Johnson, S.B.
(2001).Comparing Syntactic Complexity in Medicaland non-Medical Corpora.
In Proc AMIAAnnu Fall Symp.
90-94.Carroll, G., Charniak, E. (1992).
Twoexperiments on learning probabilisticdependency grammars from corpora.
InWorkshop Notes for Statistically-Based NLPTechniques, AAAI.
1-13.Collins, M.
(1996.).
A new statistical parserbased on bigram lexical dependencies.
InProceedings of the 34th Annual Meeting ofACL.
184-191.Dorr, B. J.,  Jones, D. (2000).
Acquisition ofSemantic Lexicons: Using Word SenseDisambiguation to Improve Precision, inEvelyn Viegas (Ed), Breadth and Depth ofSemantic Lexicons, Kluwer AcademicPublishers: Norwell, MA, 79-98.Florian, R., Brill, E. (1998).
TransformationBased Parsing.
Ph.D. Qualifier Project,Computer Science Department, Johns HopkinsUniversity.Friedman, C. (1997).
Towards a comprehensivemedical language processing system: methodsand issues.
In Proc AMIA Annu Fall Symp.595-9.Friedman C, et.
al (1995).
Architecturalrequirements for a multipurpose naturallanguage processor in the clinicalenvironment.
In Proc 19th  Annu SCAMC.347-51.Hajic, J. and K. Ribarov (1997).
Rule-BasedDependencies.
Workshop on EmpiricalLearning of Natural Language ProcessingTasks, Prague, Czech Republic.Harris, Z.
(1991).
A Theory of Language andInformation.
Oxford University Press:Oxford.Hermjakob U.
& Mooney R.J. (1997) LearningParse and Translation Decisions FromExamples With Rich Context, Proc.
of ACL-EACL Conf.
482-489.Hripcsak, G., G. Kuperman, et al (1998).Extracting Findings from Narrative Reports:Software Transferability and Sources ofPhysician Disagreement.
Methods Inf Med 37.1-7.Hudson, Richard.
(1991).
English WordGrammar.
Blackwell:  Cambridge, Mass.Kokkinakis D. (2001),  Syntactic Parsing as aStep for Automatically Augmenting SemanticLexicons, In Proceedings of the 39th ACL andthe 10th EACL, Toulouse, France.
StudentWorkshop.
13-18.Lee, S. and K.-S. Choi (1999).
A ReestimationAlgorithm for Probabilistic DependencyGrammars.
Natural Language Engineering5(3).
251-270.Li H. and Abe N.(1998).
Word clustering anddisambiguation based on co-occurrence data.In Proceedings of COLING - ACL'98.
749-755Paskin, M. (2001).
Grammatical Bigrams.
In T.Dietterich, S. Becker, and Z. Gharahmani eds.,Advances in Neural Information ProcessingSystems 14.
MIT Press: Cambridge, MA.Pereira F., Tishby, N., Lee, L (1993).Distributional clustering of English words.
In30th Annual Meeting of the ACL, 183-190.Ramshaw, L. A., Marcus, M. P. (1994).Exploring the statistical derivation oftransformational rule sequences for part-of-speech tagging.
In Proceedings of theBalancing Act Workshop on CombiningSymbolic and Statistical Approaches toLanguage, Association for ComputationalLinguistics.
86-95.Sager N. (1981).
Natural Language InformationProcessing: A Computer Grammar of Englishand its Applications.
Addison-Wesley:Reading, Massachusetts.Sekine, S. et.
al (1992)  Automatic Learning forSemantic Collocation.
In 3rd Conf.
on AppliedNatural Language Processing  :Trent - Italy.Wilcox, A, Hripcsak G. (2000).
Medical TextRepresentations for Inductive Learning.
ProcAMIA Symp.
923-7.
