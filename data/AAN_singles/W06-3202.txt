Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, pages 11?20,New York City, USA, June 2006. c?2006 Association for Computational LinguisticsImproving Syllabification Models with Phonotactic KnowledgeKarin Mu?llerInstitute of Phonetic SciencesUniversity of Amsterdamkmueller@science.uva.nlAbstractWe report on a series of experimentswith probabilistic context-free grammarspredicting English and German syllablestructure.
The treebank-trained grammarsare evaluated on a syllabification task.
Thegrammar used by Mu?ller (2002) servesas point of comparison.
As she evalu-ates the grammar only for German, we re-implement the grammar and experimentwith additional phonotactic features.
Us-ing bi-grams within the syllable, we canmodel the dependency from the previousconsonant in the onset and coda.
A 10-fold cross validation procedure shows thatsyllabification can be improved by incor-porating this type of phonotactic knowl-edge.
Compared to the grammar of Mu?ller(2002), syllable boundary accuracy in-creases from 95.8% to 97.2% for En-glish, and from 95.9% to 97.2% for Ger-man.
Moreover, our experiments withdifferent syllable structures point out thatthere are dependencies between the on-set on the nucleus for German but notfor English.
The analysis of one of ourphonotactic grammars shows that inter-esting phonotactic constraints are learned.For instance, unvoiced consonants are themost likely first consonants and liquidsand glides are preferred as second conso-nants in two-consonantal onsets.1 IntroductionIn language technology applications, unknownwords are a continuous problem.
Especially, Text-to-speech (TTS) systems like those described inSproat (1998) depend on the correct pronunciationof those words.
Most of these systems use large pro-nunciation dictionaries to overcome this problem.However, the lexicons are finite and every naturallanguage has productive word formation processes.Thus, a TTS system needs a module which con-verts letters to sounds and a second module whichsyllabifies these sound sequences.
The syllabifica-tion information is important to assign the stress sta-tus of the syllable, to calculate the phone duration(Van Santen et al (1997)), and to apply phonologi-cal rules (Kahn (1976), Blevins (1995)).
Many au-tomatic syllabification methods have been suggestede.g., (Daelemans and van den Bosch, 1992; Van denBosch, 1997; Kiraz and Mo?bius, 1998; Vroomenet al, 1998; Mu?ller, 2001; Marchand et al, to ap-pear 2006).
Mu?ller (2001) shows that incorporat-ing syllable structure improves the prediction of syl-lable boundaries.
The syllabification accuracy in-creases if the onset and coda is more fine-grained(Mu?ller, 2002).
However, she only incorporates par-tial phonotactic knowledge in her approach.
For in-stance, her models cannot express that the phoneme/l/ is more likely to occur after an /s/ than after a/t/ in English.
The information that a phoneme isvery probable in a certain position (here, the /l/ ap-pears as second consonant in a two-consonantal on-set cluster) will not suffice to express English phono-tactics of an entire consonant cluster.
Moreover, she11only reports the performance of the German gram-mar.
Thus, we are interested if the detection of syl-lable boundaries can be improved for both Englishand German by adding further phonotactic knowl-edge to a grammar.Phonotactic constraints within the onset or codaseem to be important for various tasks.
Listeners in-deed use phonotactic knowledge from their motherlanguage in various listening situations.
Vitevitchand Luce (1999), e.g., showed if English speak-ers have to rate nonsense words how ?English-like?the stimuli are, highly probable phonotactic stimuliwere rated more ?English-like?
than stimuli with alower probability.
Speakers make also use of theirphonotactic knowledge when they have to segmenta sequence into words.
In a words spotting task,Weber and Cutler (2006) found evidence that speak-ers of American English can segment words mucheasier when the sequence contains phonotactic con-straints of their own language.Beside many perception experiments which showthat phonotactic constraints are useful information,many different methods have been suggested tomodel phonotactic constraints for language tech-nology applications.
Krenn (1997), for instance,uses Hidden Markov Models to tag syllable struc-ture.
The model decides whether a phoneme be-longs to the onset, nucleus or coda.
However, thismodel does not incorporate fine-grained phonotac-tics.
Belz (2000) uses finite state automatons (FSA)to model phonotactic structure of different sylla-ble types.
We use similar positional features ofsyllables.
Moreover, Carson-Berndsen (1998) andCarson-Berndsen et al (2004) focus on automat-ically acquiring feature-based phonotactics by in-duction of automata which can be used in speechrecognition.
In our approach, we concentrate onexplicit phonotactic grammars as we want to testdifferent suggestions about the internal structure ofwords from phonological approaches (e.g.
Kesslerand Treiman (1997)).
We assume, for instance, thatcodas depend on the previous nucleus and that on-sets depend on the subsequent nucleus.In this paper, we present experiments on a seriesof context-free grammars which integrate step bystep more phonological structure.
The paper is or-ganized as follows: we first introduce our grammardevelopment approach.
In section 3, we describe ourexperiments and the evaluation procedure.
The sub-sequent section 4 shows what kind of phonotactic in-formation can be learned from a phonotactic gram-mar.
Last, we discuss our results and draw someconclusions.2 MethodWe build on the approach of Mu?ller (2001) whichcombines the advantages of treebank and brack-eted corpora training.
Her method consists of foursteps: (i) writing a (symbolic i.e.
non-probabilistic)context-free phonological grammar with syllableboundaries, (ii) training this grammar on a pronunci-ation dictionary which contains markers for syllableboundaries (see Example 1; the pre-terminals ?X[?and ?X]?
denote the beginning and end of a sylla-ble such that syllables like [strIN] can be unambigu-ously processed during training), (iii) transformingthe resulting probabilistic phonological grammar bydropping the syllable boundary markers1 (see Ex-ample 2), and (iv) predicting syllable boundariesof unseen phoneme strings by choosing their mostprobable phonological tree according to the trans-formed probabilistic grammar.
The syllable bound-aries can be extracted from the Syl node which gov-erns a whole syllable.
(1) Word ?
X[ Sylone ]X(2) Word ?
SyloneWe use a grammar development procedure to de-scribe the phonological structure of words.
We ex-pect that a more fine-grained grammar increases theprecision of the prediction of syllable boundaries asmore phonotactic information can be learned.
In thefollowing section, we describe the development of aseries of grammars.2.1 Grammar developmentOur point of comparison is (i) the syllable com-plexity grammar which was introduced by Mu?ller(2002).
We develop four different grammars: (ii) thephonotactic grammar, (iii) the phonotactic on-nucgrammar (iv) the phonotactic nuc-coda grammarand (v) the phonotactic on-nuc-coda grammar.
Allfive grammars share the following features: Thegrammars describe a word which is composed of one1We also drop rules with zero probabilities12to n syllables which in turn branch into onset andrhyme.
The rhyme is re-written by the nucleus andthe coda.
Onset or coda could be empty.
Further-more, all grammar versions differentiate betweenmonosyllabic and polysyllabic words.
In polysyl-labic words, the syllables are divided into syllablesappearing word-initially, word-medially, and word-finally.
Additionally, the grammars distinguish be-tween consonant clusters of different sizes (rangingfrom one to five consonants).We assume that phonotactic knowledge withinthe onset and coda can help to solve a syllabifica-tion task.
Hence, we change the rules of the syl-lable complexity grammar (Mu?ller, 2002) such thatphonotactic dependencies are modeled.
We expressthe dependencies within the onset and coda as wellas the dependency from the nucleus by bi-grams.2.1.1 Grammar generationThe grammars are generated automatically (usingperl-scripts).
As all possible phonemes in a languageare known, our grammar generates all possible re-write rules.
This generation process naturally over-generates, which means that we receive rules whichwill never occur in a language.
There are, for in-stance, rules which describe the impossible Englishonset /tRS/.
However, our training procedure andour training data make sure that only those rules willbe chosen which occur in a certain language.The monosyllabic English word string is used asa running example to demonstrate the differencesof the grammar versions.
The word string is tran-scribed in the pronunciation dictionary CELEX as([strIN]) (Baayen et al, 1993).
The opening squarebracket, ?
[?, indicates the beginning of the syllableand the closing bracket, ?
]?, the end of the syllable.The word consists of the tri-consonantal onset [str]followed by the nucleus, the short vowel [I] and thecoda [N ].In the following paragraphs, we will introduce thedifferent grammar versions.
For comparison rea-sons, we briefly describe the grammar of Mu?ller(2002) first.2.1.2 Syllable complexity grammar (Mu?ller,2002)The syllable complexity grammar distinguishesbetween onsets and codas which contain a differ-ent number of consonants.
There are differentrules which describe zero to n-consonantal onsets.Tree (3) shows the complete analysis of the wordstring.
(3) WordSyloneHHHHHOnsetoneOnone.3.1 HHs Onone.3.2 HHt Onone.3.3rRhymeone HHNucleusoneICodaone.1Coone.1.1N(4) Onone.3.1 ?
s Onone.3.2(5) Onone.2.1 ?
s Onone.2.2Rule 4, e.g., describes a tri-consonantal onset, e.g.,[str].
This rule occurs in example tree 3 and willbe used for words such as string or spray.
Rule (5)describes a two-consonantal onset occurring in theanalysis of words such as snake or stand.
However,this grammar cannot model phonotactic dependen-cies from the previous consonant.2.1.3 Phonotactic grammarThus, we develop a phonotactic grammar whichdiffers from the previous one.
Now, a consonant inthe onset or coda depends on the preceding one.
Therules express bi-grams of the onset and coda conso-nants.
The main difference to the previous gram-mars can be seen in the re-writing rules involvingphonemic preterminal nodes (rule 6) as well as ter-minal nodes for consonants (rule 7).
(6) X.r.C.s.t ?
C X.r.C+.s.t(7) X.r.C.s.t ?
CRules of this type bear four features for a conso-nant C inside an onset or a coda (X=On, Cod),namely: the position of the syllable in the word(r=ini, med, fin, one), the current terminal node(C = consonant), the succeeding consonant (C+),the cluster size (t = 1 .
.
.
5), and the position of aconsonant within a cluster (s = 1 .
.
.
5).The example tree (8) shows the analysis of theword string with the current grammar version.
The13rule (9) comes from the example tree showing thatthe onset consonant [t] depends on the previous con-sonant [s].
(8) WordSyloneHHHHHOnsetone.3Onone.s.3.1 HHs Onone.t.3.2 HHt Onone.r.3.3rRhymeoneHHHNucleusoneICodaone.1Coone.t.1.1N(9) Onone.s.3.1 ?
s Onone.t.3.22.1.4 Phonotactic on-nuc grammarWe also examine if there are dependencies of thefirst onset consonant on the succeeding nucleus.
Thedependency of the whole onset on the nucleus isindirectly encoded by the bi-grams within the on-set.
The phonotactic onset-nucleus grammar distin-guishes between same onsets with different nuclei.In example tree (12), the triconsonantal onset start-ing with a phoneme [s] depends on the Nucleus [I].Rule (10) occurs in tree (12) and will be also usedfor words such as strict or strip whereas rule (11) isused for words such as strong or strop.
(10) Onsetone.I.3 ?
Onone.s.3.1(11) Onsetone.O.3 ?
Onone.s.3.1(12) WordSylone.IHHHHHHOnsetone.I.3Onone.s.3.1 HHs Onone.t.3.2 HHt Onone.r.3.3rRhymeone.IHHHNucleusone.IICodaone.1Coone.N.1.1N2.1.5 Phonotactic nuc-coda grammarThe phonotactic nucleus-coda grammar encodesthe dependency of the first coda consonant on thenucleus.
The grammar distinguishes between codasthat occur with various nuclei.
Rule 13 is used, forinstance, to analyze the word string, shown in Ex-ample tree 15.
The same rule will be applied forwords such as bring, king, ring or thing.
If there isa different nucleus, we get a different set of rules.Rule 14, e.g., is required to analyze words such aslong, song, strong or gong.
(13) Codaone.I.1 ?
N Coone.t.1.1(14) Codaone.O.1 ?
N Coone.t.1.1(15) WordSyloneHHHHHHOnsetone.3Onone.s.3.1 HHs Onone.t.3.2 HHt Onone.r.3.3rRhymeone.I HHHNucleusone.IICodaone.I.1Coone.N.1.1N2.1.6 Phonotactic on-nuc-coda grammarThe last tested grammar is the phonotactic onset-nucleus-coda grammar.
It is a combination of gram-mar 2.1.4 and 2.1.5.
In this grammar, the first con-sonant of the onset and coda depend on the nucleus.Tree 16 shows the full analysis of our running exam-ple word string.
(16) WordSylone.IHHHHHHOnsetone.I.3Onone.s.3.1 HHs Onone.t.3.2 HHt Onone.r.3.3rRhymeone.IHHHNucleusone.IICodaone.I.1Coone.N.1.1NThe rules of the subtree (17) are the same for wordssuch as string or spring.
However, words with a dif-ferent nucleus such as strong will be analyzed witha different set of rules.14(17) WordSylone.IHHHHOnsetone.I.3Onone.s.3.1Rhymeone.I HHHNucleusone.IICodaone.I.1Coone.N.1.1N3 ExperimentsIn this section, we report on our experiments withfour different phonotactic grammars introduced inSection 2.1 (see grammar 2.1.3-2.1.6), as well aswith a re-implementation of Mu?ller?s less complexgrammar (Mu?ller, 2002).
All these grammars aretrained on a corpus of transcribed words from thepronunciation lexicon CELEX.
We use the full formsof the lexicon instead of the lemmas.
The Germanlexicon contains 304,928 words and the English lex-icon 71,493 words.
Homographs with the same pro-nunciation but with different part of speech tags aretaken only once.
We use for our German exper-iments 274,435 words for training and 30,492 fortesting (evaluating).
For our English experiments,we use 64,343 for training and 7,249 for testing.3.1 Training procedureWe use the same training procedure as Mu?ller(2001).
It is a kind of treebank training where weobtain a probabilistic context-free grammar (PCFG)by observing how often each rule was used in thetraining corpus.
The brackets of the input guaran-tee an unambiguous analysis of each word.
Thus,the formula of treebank training given by (Charniak,1996) is applied: r is a rule, let |r| be the numberof times r occurred in the parsed corpus and ?
(r) bethe non-terminal that r expands, then the probabilityassigned to r is given byp(r) =|r|?r??{r?|?(r?)=?
(r)} |r?|After training, we transform the PCFG by drop-ping the brackets in the rules resulting in an anal-ysis grammar.
The bracket-less analysis grammar isused for parsing the input without brackets; i.e., thephoneme strings are parsed and the syllable bound-aries are extracted from the most probable parse.In our experiments, we use the same technique.The advantage of this training method is that welearn the distribution of the grammar which maxi-mizes the likelihood of the corpus.3.2 Evaluation procedureWe evaluate our grammars on a syllabification taskwhich means that we use the trained grammars topredict the syllable boundaries of an unseen corpus.As we drop the explicit markers for syllable bound-aries, the grammar can be used to predict the bound-aries of arbitrary phoneme sequences.
The bound-aries can be extracted from the syl-span which gov-erns an entire syllable.Our training and evaluation procedure is a 10-foldcross validation procedure.
We divide the original(German/English) corpus into ten parts equal in size.We start the procedure by training on parts 1-9 andevaluating on part 10.
In a next step, we take parts1-8 and 10 and evaluate on part 9.
Then, we evaluateon corpus 8 and so forth.
In the end, this procedureyields evaluation results for all 10 parts of the orig-inal corpus.
Finally, we calculate the average meanof all evaluation results.3.2.1 Evaluation MetricsOur three evaluation measures are word accuracy,syllable accuracy and syllable boundary accuracy.Word accuracy is a very strict measure and does notdepend on the number of syllables within a word.
Ifa word is correctly analyzed the accuracy increases.We define word accuracy as# of correctly analyzed wordstotal # of wordsSyllable accuracy is defined as# of correctly analyzed syllablestotal # of syllablesThe last evaluation metrics we used is the syllableboundary accuracy.
It expresses how reliable theboundaries were recognized.
It is defined as# of correctly analyzed syllable boundariestotal # of syllable boundariesThe difference between the three metrics canbe seen in the following example.
Let ourevaluation corpus consist of two words, transfer-ring and wet.
The transcription and the sylla-ble boundaries are displayed in table 1.
Let ourtrained grammar predict the boundaries shown intable 2.
Then the word accuracy will be 50%15transferring trA:ns?f3:?rINwet wEtTable 1: Example: evaluation corpustransferring trA:n?sf3:?rINwet wEtTable 2: Example: predicted boundaries(1 correct word2 words ), the syllable accuracy will be 50%(2 correct syllables4 syllables ), and the syllable boundary accu-racy is 75% (3 correct syllable boundaries4 syllable boundaries ).
The differ-ence between syllable accuracy and syllable bound-ary accuracy is that the first metric punishes thewrong prediction of a syllable boundary twice asthe complete syllable has to be correct.
The syllableboundary accuracy only judges the end of the sylla-ble and counts how often it is correct.
Mono-syllabicwords are also included in this measure.
They serveas a baseline as the syllable boundary will be alwayscorrect.
If we compare the baseline for English andGerman (tables 3 and 4, respectively), we observethat the English dictionary contains 10.3% monosyl-labic words and the German one 1.59%.Table 3 and table 4 show that phonotactic knowl-edge improves the prediction of syllable bound-aries.
The syllable boundary accuracy increasesfrom 95.84% to 97.15% for English and from 95.9%to 96.48% for German.
One difference between thetwo languages is if we encode the nucleus in the on-set or coda rules, German can profit from this in-formation compared to English.
This might point ata dependence of German onsets from the nucleus.For English, it is even the case that the on-nuc andthe nuc-cod grammars worsen the results comparedto the phonotactic base grammar.
Only the combi-nation of the two grammars (the on-nuc-coda gram-mar) achieves a higher accuracy than the phonotacticgrammar.
We suspect that the on-nuc-coda grammarencodes that onset and coda constrain each other onthe repetition of liquids or nasals between /s/C on-sets and codas.
For instance, lull and mam are okey,whereas slull and smame are less good.4 Learning phonotactics from PCFGsWe want to demonstrate in this section that ourphonotactic grammars does not only improve syl-grammar version word syllable syll bound.accuracy accuracy accuracybaseline 10.33%(Mu?ller, 2002) 89.27% 91.84% 95.84%phonot.
grammar 92.48% 94.35% 97.15%phonot.
on-nuc 92.29% 94.21% 97.09%phonot.
nuc-cod 92.39% 94.27% 97.11%phonot.
on-nuc-cod 92.64% 94.47% 97.22%Table 3: Evaluation of four English grammar ver-sions.grammar version word syllable syll bound.accuracy accuracy accuracybaseline 1.59%(Mu?ller, 2002) 86.06% 91.96% 95.90%phonot.
grammar 87.95% 93.09% 96.48%phonot.
nuc-cod 89.53% 94.09% 97.01%phonot.
on-nuc 89.97% 94.35% 97.15%phonot.
on-nuc-cod 90.45% 94.62% 97.29%Table 4: Evaluation of four German grammar ver-sions.labification accuracy but can be used to reveal in-teresting phonotactic2 information at the same time.Our intension is to show that it is possible to aug-ment symbolic studies such as e.g., Hall (1992),Pierrehumbert (1994), Wiese (1996), Kessler andTreiman (1997), or Ewen and van der Hulst (2001)with extensive probabilistic information.
Due totime and place constraints, we concentrate on two-consonantal clusters of grammar 2.1.3.Phonotactic restrictions are often expressed by ta-bles which describe the possibility of combinationof consonants.
Table 5 shows the possible combi-nations of German two-consonantal onsets (Wiese,1996).
However, the table cannot express differ-ences in frequency of occurrence between certainclusters.
For instance, it does not distinguish be-tween onset clusters such as [pfl] and [kl].
If we con-sider the frequency of occurrence in a German dic-tionary then there is indeed a great difference.
[kl] ismuch more common than [pfl].4.1 GermanOur method allows additional information to beadded to tables such as shown in table 5.
In whatfollows, the probabilities are taken from the rulesof grammar 2.1.3.
Table 6 shows the probability of2Note that we only deal with phonotactic phenomena on thesyllable level and not on the morpheme level.16mono l R n m s v f t ts p k j z g0.380 S 0.160 0.093 0.056 0.074 0.165 0.318 0.1310.158 k 0.351 0.322 0.175 0.1510.090 b 0.489 0.5100.086 t 0.955 0.0440.083 f 0.620 0.364 0.0150.066 g 0.362 0.617 0.0190.042 p 0.507 0.400 0.030 0.0610.033 d 1.0000.019 s 0.200 0.066 0.100 0.133 0.033 0.133 0.3330.019 ts 1.0000.011 pf 0.882 0.1170.007 v 1.000Table 6: German two-consonantal onsets in monosyllabic words - sorted by probability of occurrencemono l r n m s v f t ts p k j z g w S d0.322 s 0.157 0.001 0.099 0.060 0.001 0.004 0.223 0.150 0.174 0.006 0.1200.148 k 0.375 0.390 0.003 0.003 0.030 0.1960.093 b 0.420 0.574 0.0040.083 f 0.591 0.333 0.0750.079 p 0.480 0.457 0.056 0.0050.072 g 0.283 0.709 0.0060.068 t 0.686 0.039 0.2740.048 d 0.822 0.112 0.0650.035 h 0.089 0.9100.018 T 0.857 0.047 0.0950.014 S 0.878 0.030 0.030 0.0600.004 m 1.0000.003 n 1.0000.002 l 1.0000.002 v 1.000Table 7: English two-consonantal onsets in monosyllabic words - sorted by probability of occurrenceSonorants Obstruentsl R n m s vObstruentsp + + (+) - + -t - + - - - (+)k + + + (+) (+) +b + + - - - -d - + - - - -g + + + (+) - -f + + - - - -v (+) + - - -ts - - - - - +pf + + - - - -S + + + + - +Table 5: (Wiese, 1996) German onset clustersoccurrence of German obstruents ordered by theirprobability of occurrence.
[S] occurs very often inGerman words as first consonant in two-consonantalonsets word initially.
In the first row of table 6,the consonants which occur as second consonantsare listed.
We observe, for instance, that [St] isthe most common two-consonantal onset in mono-syllabic words.
This consonant cluster appears inwords such as Staub (dust), stark (strong), or Stolz(pride).
We believe that there is a threshold indicat-ing that a certain combination is very likely to comefrom a loanword.
If we define the probability of atwo-consonantal onset asp(onset ini 2) =def p(C1)?
p(C2)where p(C1) is the probability of the ruleX.r.C1.s.t ?
C1 X.r.C2.s.tand p(C2) is the probability of the ruleX.r.C2.s.t ?
C2,then we get a list of two-consonantal onsets orderedby their probabilities:p(St) > ... > p(sk) > p(pfl) > p(sl) > ... > p(sf)These onsets occur in words such as Steg (foot-bridge), stolz (proud), Staat (state), Skalp (scalp),Skat (skat) Pflicht (duty), Pflock (stake), or Slang(slang) and Slum (slum).
The least probablecombination is [sf] which appears in the Germanword Spha?re (sphere) coming from the Latin wordsphaera.
The consonant cluster [sl] is also a veryuncommon onset.
Words with this onset are usuallyloanwords from English.
The onset [sk], however, isan onset which occur more often in German words.Most of the words are originally from Latin and aretranslated into German long ago.
Interestingly, theonset [pfl] is also a very uncommon onset.
Mostof these onsets result from the second sound shiftwhere in certain positions the simple onset conso-17nant /p/ became the affricate /pf/.
The English trans-lation of these words shows that the second soundshift was not applied to English.
However, the mostprobable two-consonantal onset is [St].
The wholeset of two-consonantal onsets can be seen in Table 8.4.2 EnglishEnglish two-consonantal onsets show that unvoicedfirst consonants are more common than voiced ones.However, two combinations are missing.
The alveo-lar plosives /t/ and /d/ do not combine with the lateral/l/ in English two-consonantal onsets.
Table 8 showsthe most probable two-consonantal onsets sorted bytheir joint probability.4.3 Comparison between English and GermanThe fricatives /s/ and /S/ are often regarded as extrasyllabic.
According to our study on two-consonantalonsets, these fricatives are very probable first con-sonants and combine with more second consonantsthan all other first consonants.
They seem to forman own class.
Liquids and glides are the most impor-tant second consonants.
However, English prefers /r/over /l/ in all syllable positions and /j/ over /w/ (ex-cept in monosyllabic words) and /n/ as second con-sonants.
Nasals can only combine with very littlefirst consonants.
In German, we observe that /R/ ispreferred over /l/ and /v/ over /n/ and /j/.
Moreover,the nasal /n/ is much more common in German thanin English as second consonants which applies espe-cially to medial and final syllables.When we compare the phonotactic restrictions oftwo languages, it is also interesting to observe whichcombinations are missing.
If certain consonant clus-ters are not very likely or never occur in a language,this might have consequences for language under-standing and language learning.
Phonotactic gapsin one language might cause spelling mistakes in asecond language.
For instance, a typical NorthernGerman name is Detlef which is often misspelled inEnglish as Deltef.
The onset cluster /tl/ can occurin medial and final German syllables but not in En-glish.
The different phonetic realization of /l/ mayplay a certain role that /lt/ is more natural than /tl/ inEnglish.Mono-syllabic: /st/> /kr/> /sk/> /kl/> /br/> /gr/> /sl/> /fl/> /sp/> /tr/> /dr/> /bl/> /sw/> /pl/> /pr/> /sn/> /hw/> /kw/> /fr/> /gl/> /sm/>/tw/> /Tr/> /Sr/> /fj/> /dj/> /kj/> /pj/> /mj/> /dw/> /hj/> /nj/> /tj/> /vj/ > /lj/ > /sj/ > /Tw/ > /sf/ > /Tj/ > /Sw/ > /km/ > /kv/ > /gw/ > /Sn/> /Sm/> /pS/> /bj/> /sr/> /sv/Initial /pr/> /st/> /tr/> /kr/> /sp/> /sk/> /br/> /gr/> /fl/> /kl/> /fr/>/bl/> /pl/> /sl/> /kw/> /dr/> /sn/> /sw/> /gl/> /hw/> /nj/> /sm/> /sj/> /pj/> /Tr/> /mj/> /kj/> /dj/> /tw/> /tj/> /fj/> /hj/> /lj/> /bj/> /ps/> /Sr/> /dw/> /sf/> /vj/> /gj/> /gw/> /pw/> /mn/> /Sm/> /Tj/> /Tw/> /Sn/> /tsw/> /zj/> /pt/> /mw/> /kn/> /gz/Medial: /st/> /tr/> /pr/> /sp/> /gr/> /kj/> /kr/> /kw/> /pl/> /br/> /tj/> /lj/> /dj/> /dr/> /kl/> /nj/> /sk/> /mj/> /fr/> /pj/> /bl/> /fl/> /bj/> /gl/ > /gj/ > /fj/ > /Sn/ > /sj/ > /vj/ > /Sj/ > /Tr/ > /vr/ > /gw/ > /sl/ >/nr/ > /sw/ > /mr/ > /sn/ > /hj/ > /hw/ > /sm/ > /zj/ > /tSr/ > /rj/ > /sr/ >/dw/> /Zr/> /Sr/> /jw/> /tSw/> /tSn/> /vw/> /Dr/> /dZr/> /dn/> /Tj/> /tw/> /Sw/> /Zj/> /zr/> /zn/> /zw/> /Zw/> /dZj/> /dZn/> /dZw/Final: /st/ > /tr/ > /kl/ > /bl/ > /gr/ > /dr/ > /pl/ > /br/ > /sk/ > /sp/ > /pr/> /kr/ > /tj/ > /fr/ > /nj/ > /fl/ > /lj/ > /kw/ > /dj/ > /sj/ > /kj/ > /sl/ > /gl/> /hw/> /Sn/> /vr/> /Sj/> /vj/> /bj/> /pj/> /fj/> /Tr/> /mj/> /gw/>/sr/ > /sw/ > /sm/ > /nr/ > /sn/ > /tSr/ > /mr/ > /tw/ > /dZr/ > /zj/ > /gj/ >/dZj/ > /Sr/ > /Zr/ > /sf/ > /nw/ > /zr/ > /Tj/ > /rj/ > /Dr/ > /vw/ > /dw/ >/dn/> /tSj/> /pw/> /jw/> /hj/> /St/> /Zw/> /tSn/> /Zj/> /pn/> /Dj/>/dZn/> /zn/> /Sw/> /Zn/> /tSw/> /Tw/> /bd/> /tsj/> /Dw/Monosyllabic: /St/ > /tR/ > /Sv/ > /Sl/ > /kl/ > /fl/ > /kR/ > /Sp/ > /bR/ >/bl/> /gR/> /SR/> /dR/> /fR/> /Sm/> /kn/> /gl/> /kv/> /pl/> /Sn/>/tsv/ > /pR/ > /pfl/ > /vR/ > /sk/ > /sl/ > /tv/ > /ps/ > /sp/ > /sv/ > /sm/ >/pfR/> /pn/> /gn/> /sn/> /fj/> /sf/Initial: /St/> /tR/> /pR/> /Sp/> /kR/> /Sv/> /gR/> /Sl/> /fR/> /kl/>/bR/ > /bl/ > /fl/ > /Sm/ > /gl/ > /tsv/ > /pl/ > /kv/ > /kn/ > /Sn/ > /dR/ >/SR/ > /sk/ > /pfl/ > /ps/ > /gn/ > /sl/ > /sm/ > /sts/ > /sf/ > /sv/ > /ks/ >/tv/> /vR/> /sn/> /mn/> /st/> /pn/> /sp/> /fj/> /pfR/> /mj/Medial: /St/ > /tR/ > /bR/ > /fR/ > /Sl/ > /gR/ > /kR/ > /bl/ > /dR/ > /Sp/> /kl/> /fl/> /pR/> /gl/> /Sv/> /SR/> /st/> /pl/> /ks/> /kv/> /gn/>/Sn/> /Sm/> /kn/> /tsv/> /pfl/> /dl/> /dn/> /gm/> /sp/> /sn/> /fn/>/bn/> /vj/> /xR/> /tn/> /sl/> /vR/> /sk/> /pj/> /ps/> /sts/> /xn/> /xl/> /ml/> /Rn/> /Nn/> /NR/> /zn/> /zl/> /mn/> /tl/> /sf/> /ln/> /tsR/> /tsl/> /sR/> /ft/> /zR/> /pfR/> /pt/> /nR/> /sg/> /pn/> /dm/> /tz/> /sv/> /zv/> /tv/Final: /St/ > /tR/ > /bl/ > /Sl/ > /bR/ > /fl/ > /kl/ > /dR/ > /gR/ > /Sp/ >/kR/ > /Sv/ > /fR/ > /SR/ > /gl/ > /ks/ > /dl/ > /pl/ > /gn/ > /pR/ > /Sn/ >/Sm/> /kn/> /dn/> /kv/> /tsv/> /tl/> /ml/> /xl/> /tsl/> /gm/> /pfl/>/Nl/ > /zl/ > /tn/ > /xR/ > /vR/ > /fn/ > /bn/ > /vj/ > /zn/ > /Nn/ > /pn/ >/RR/> /mn/> /xn/> /zR/> /NR/> /lR/> /dZm/> /tsR/> /nl/> /gv/> /ps/> /ft/> /pfR/> /tZl/> /nR/> /sp/> /st/> /sv/> /sk/> /sR/> /sn/> /sl/>/sm/> /sts/Table 8: Two-consonantal onsets ordered by jointprobability (top: English, bottom:German)185 DiscussionComparison of the syllabification performance withother systems is difficult: (i) different approachesdiffer in their training and evaluation corpus;(ii) comparisons across languages are hard to inter-pret; (iii) comparisons across different approachesrequire cautious interpretations.
Nevertheless, wewant to refer to several approaches that examinedthe syllabification task.
Van den Bosch (1997) in-vestigated the syllabification task with five induc-tive learning algorithms.
He reported a general-ization error for words of 2.22% on English data.However, the evaluation procedure differs from oursas he evaluates each decision (after each phoneme)made by his algorithms.
Marchand et al (to ap-pear 2006) evaluated different syllabification algo-rithms on three different pronunciation dictionaries.Their best algorithm (SbA) achieved a word accu-racy of 91.08%.
The most direct point of compari-son are the results presented by Mu?ller (2002).
Herapproach differs in two ways.
First, she only eval-uates the German grammar and second she trainson a newspaper corpus.
As we are interested inhow her grammars perform on our corpus, we re-implemented her grammars and tested both in our10-fold cross evaluation procedure.
We find that thefirst grammar (Mu?ller, 2001) achieves 85.45% wordaccuracy, 88.94% syllable accuracy and 94.37% syl-lable boundary accuracy for English and 84.21%,90.86%, 95.36% for German respectively.
The re-sults show that the syllable boundary accuracy in-creases from 94,37% to 97.2% for English and from95.3% to 97.2% for German.
The experiments pointout that phonotactic knowledge is a valuable sourceof information for syllabification.6 ConclusionsPhonotactic restrictions are important for languageperception and production.
They influence the abil-ity of children to segment words, and they help torecognize words in nonsense sequences.
In thispaper, we presented grammars which incorporatephonotactic restrictions.
The grammars were trainedand tested on a German and an English pronuncia-tion dictionary.
Our experiments show that Englishand German profit from phonotactic knowledge topredict syllable boundaries.
We find evidence thatGerman codas depend on the nucleus which doesnot apply for English.
The English grammars whichmodel the dependency of part of the onset or codaon the nucleus worsen the syllabification accuracy.However, the combination of both show a better per-formance than the base phonotactic grammar.
Thissuggests that there are constrains in the selection ofthe onset and coda consonants.7 AcknowledgmentsI would like to thank Paul Boersma who invitedme as a guest researcher at the Institute of PhoneticSciences of the University of Amsterdam.
Specialthanks also to Detlef Prescher as well as to the threeanonymous reviewers, whose comments were veryuseful while preparing the final version of this pa-per.ReferencesHarald R. Baayen, Richard Piepenbrock, and H. van Rijn.1993.
The CELEX lexical database?Dutch, English,German.
(Release 1)[CD-ROM].
Philadelphia, PA:Linguistic Data Consortium, Univ.
Pennsylvania.Anja Belz.
2000.
Multi-syllable phonotactic mod-elling.
In Proceedings of SIGPHON 2000: Finite-State Phonology, Luxembourg.Juliette Blevins.
1995.
The Syllable in PhonologicalTheory.
In John A. Goldsmith, editor, Handbookof Phonological Theory, pages 206?244, Blackwell,Cambridge MA.Julie Carson-Berndsen, Robert Kelly, and Moritz Neuge-bauer.
2004.
Automatic Acquisition of Feature-BasedPhonotactic Resources.
In Proceedings of the Work-shop of the ACL Special Interest Group on Computa-tional Phonology (SIGPHON), Barcelona, Spain.Julie Carson-Berndsen.
1998.
Time Map Phonology.
Fi-nite State Models and Event Logics in Speech Recog-nition, volume 5 of Text, Speech and Language Tech-nology.
Springer.Eugene Charniak.
1996.
Tree-bank grammars.
In Pro-ceedings of the Thirteenth National Conference on Ar-tificial Intelligence, AAAI Press/MIT Press, MenloPark.Walter Daelemans and Antal van den Bosch.
1992.
Gen-eralization performance of backpropagation learningon a syllabification task.
InM.F.J.
Drossaers and ANi-jholt, editors, Proceedings of TWLT3: Connectionismand Natural Language Processing, pages 27?37, Uni-versity of Twente.19Colin J. Ewen and Harry van der Hulst.
2001.The Phonological Structure of Words.
An Introduc-tion.
Cambridge University Press, Cambridge, UnitedKingdom.Tracy Hall.
1992.
Syllable structure and syllable relatedprocesses in German.
Niemeyer, Tu?bingen.Daniel Kahn.
1976.
Syllable-based Generalizations inEnglish Phonology.
Ph.D. thesis, Massachusetts Insti-tute of Technology, MIT.Brett Kessler and Rebecca Treiman.
1997.
SyllableStructure and the Distribuation of Phonemes in En-glish Syllables.
Journal of Memory and Language,37:295?311.George Anton Kiraz and Bernd Mo?bius.
1998.
Mul-tilingual Syllabification Using Weighted Finite-StateTransducers.
In Proc.
3rd ESCA Workshop on SpeechSynthesis (Jenolan Caves), pages 59?64.Brigitte Krenn.
1997.
Tagging syllables.
In Proceedingsof the 5th European Conference on Speech Commu-nication and Technology, Eurospeech 97, pages 991?994.Yannick Marchand, Connie A. Adsett, and Robert I.Damper.
to appear 2006.
Automatic syllabification inEnglish: A comparison of different algorithms.
Lan-guage and Speech.Karin Mu?ller.
2001.
Automatic Detection of SyllableBoundaries Combining the Advantages of Treebankand Bracketed Corpora Training.
In Proc.
39th AnnualMeeting of the ACL, Toulouse, France.Karin Mu?ller.
2002.
Probabilistic Context-Free Gram-mars for Phonology.
In Proceedings of the Workshopon Morphological and Phonological Learning at ACL2002.Janet Pierrehumbert.
1994.
Syllable structure and wordstructure: a study of triconsonantal clusters in English.In Patricia A. Keating, editor, Phonological Structureand Phonetic Form, volume III of Papers in Labo-ratory Phonology, pages 168?188.
University Press,Cambridge.Richard Sproat, editor.
1998.
Multilingual Text-to-Speech Synthesis: The Bell Labs Approach.
KluwerAcademic, Dordrecht.Antal Van den Bosch.
1997.
Learning to PronounceWritten Words: A Study in Inductive Language Learn-ing.
Ph.D. thesis, Univ.
Maastricht, Maastricht, TheNetherlands.Jan P.H.
Van Santen, Chilin Shih, Bernd Mo?bius, Eve-lyne Tzoukermann, and Michael Tanenblatt.
1997.Multilingual duration modeling.
In Proceedings ofthe European Conference on Speech Communicationand Technology (Eurospeech), volume 5, pages 2651?2654, Rhodos, Greece.Michael S. Vitevitch and Paul A. Luce.
1999.
Proba-bilistic Phonotactics and Neighborhood Activation inSpoken Word Recognition.
Journal of Memory andLanguage, (40):374?408.Jean Vroomen, Antal van den Bosch, and Beatricede Gelder.
1998.
A Connectionist Model for Boot-strap Learning of Syllabic Structure.
Language andCognitive Processes.
Special issue on Language Ac-quisition and Connectionism, 13(2/3):193?220.Andrea Weber and Anne Cutler.
2006.
First-languagephonotactics in second-language listening.
Journal ofthe Acoustical Society of America, 119(1):597?607.Richard Wiese.
1996.
The Phonology of German.Clarendon Press, Oxford.20
