Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 123?127,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsBayesian Word Alignment for Massively Parallel TextsRobert?OstlingDepartment of LinguisticsStockholm Universityrobert@ling.su.seAbstractThere has been a great amount of workdone in the field of bitext alignment, butthe problem of aligning words in mas-sively parallel texts with hundreds or thou-sands of languages is largely unexplored.While the basic task is similar, thereare also important differences in purpose,method and evaluation between the prob-lems.
In this work, I present a non-parametric Bayesian model that can beused for simultaneous word alignment inmassively parallel corpora.
This methodis evaluated on a corpus containing 1144translations of the New Testament.1 IntroductionBitext word alignment is the problem of findinglinks between words given pairs of translated sen-tences (Tiedemann, 2011).
Initially, this was mo-tivated by Statistical Machine Translation (SMT)applications (Brown et al., 1993), but word-aligned texts have also been used to transfer lin-guistic annotation between languages (Yarowskyet al., 2001; T?ackstr?om, 2013), for Word SenseDisambiguation (WSD) (Diab and Resnik, 2002)and lexicon extraction (Wu and Xia, 1994).Massively parallel texts, in the sense used byCysouw and W?alchli (2007), are essentially thesame as bitexts, only with hundreds or thousandsof languages rather than just two.
Parallel corporaused in SMT, for instance the Europarl Corpus(Koehn, 2005), tend to contain few (up to tens of)languages, but many (up to billions of) words ineach language.
Massively parallel corpora, on theother hand, contain many (hundreds of) languages,but usually fewer (less than a million) words ineach language.Additionally, aligned massively parallel corporahave different applications than traditional paral-lel corpora with pairwise alignments.
Whereas thelatter tend to be used for the various NLP tasksmentioned above, massively parallel corpora havemostly been used for investigations in linguistictypology (Cysouw and W?alchli, 2007).There has been surprisingly few studies on mul-tilingual word alignment.
Mayer and Cysouw(2012) treat alignment as a clustering problem,where the words in each sentence are clustered ac-cording to some measure of co-occurrence.
Theyprovide no evaluation, but alignment methodsbased on co-occurrence statistics have been foundto have lower accuracy than even very simple gen-erative models (Och and Ney, 2003), so this mightnot be a promising direction as far as accuracy isconcerned.A related line of research is due to Lardilleuxet al.
(2011), who learn sets of multilingual trans-lation equivalent phrases.
Although later work(Lardilleux et al., 2013) uses phrase pairs ex-tracted with this method for (bitext) word align-ment, their method solves a somewhat differentproblem from what is considered here.Some authors have studied how multilingualparallel corpora can be used to improve bitextalignment.
Filali and Bilmes (2005) use (bitext)alignments to addditional languages as features inbitext alignment, while Kumar et al.
(2007) in-terpolate alignments through multiple bridge lan-guages to produce a bitext alignment for anotherlanguage pair.
Since the goal of this research isnot multilingual alignment, it will not be consid-ered further here.2 Multilingual AlignmentIn bitext alignment, the goal is to find links be-tween individual word tokens in parallel sentencepairs.
The IBM models (Brown et al., 1993) for-malize this in a directional fashion where eachword j in a source language is linked to word iin the target language through alignment variablesi = aj, thus specifying a 1-to-n mapping from123source language words to target language words.An intuitively appealing way to formalize themultilingual alignment problem is through a com-mon representation (or interlingua) to which eachindividual language is aligned.
If the common rep-resentation is isomorphic to one of the languagesin the corpus, this is equivalent to using that lan-guage as a bridge.
However, since all languages(and all translations) have their own idiosyncrasiesthat make linking to other translations difficult, itseems better to learn a common representation thatcorresponds to information in a sentence that ispresent in as many of the translations as possible.3 MethodRecently, it has been shown that Bayesian meth-ods that use priors to bias towards linguisticallymore plausible solutions can improve bitext wordalignment (Mermer and Sarac?lar, 2011; Riley andGildea, 2012; Gal and Blunsom, 2013).
Giventhese promising results and the fact that massivelyparallel texts tend to be rather short, which makesthe role of realistic priors more important, I havedecided to use a Bayesian alignment model for thiswork.3.1 ModelThe model used in this work uses a common rep-resentation of concepts generated by a ChineseRestaurant Process (CRP), which is aligned toeach of the languages in a corpus using the modelof Mermer and Sarac?lar (2011).Table 1 introduces the variables (observed andlatent) as well as the hyperparameters of themodel.
Basically, the model consists of a commonrepresentation c (where token i of sentence s is de-noted csi), which is aligned to one or more wordswlsj(from language l, sentence s, token j) througha set of alignment variables alsjwhich contain theindex within csthat wlsjis linked to.The probability of an assignment c is:CRP(c;?)
=?
(1 + ?)?
(n+ ?)??|Ec|?1??e?Ec(ne?
1)!where neis the number of occurrences of concepttype e in the assignment c, and n =?eneis the(fixed) total number of tokens in the common rep-resentation.For the translation probabilities, I followMermer and Sarac?lar (2011) in assuming thatp(fl|e) ?
Dir(tl; ?l), and that the priors ?laresymmetric (i.e.
all values in these vectors areequal, ?lef= ?).
By specifying a low value for?
(a sparse prior), we can encode our prior knowl-edge that translation probability functions p(fl|e)tend to have a low entropy, or in other words,that each concept is typically only translated intoa very small number of words in each language.The joint probability of the common represen-tation and the alignments is given by:p(c, a, w, t;?, ?)
=p(c;?)
?
p(w|c, a, t) ?
p(a|c) ?
p(t; ?
)(1)where p(c;?)
= CRP(c;?)
and the remainingfactors are the same as in Mermer and Sarac?lar(2011) with the common representation being the?target language?, except that there is a productacross all languages l. Note that since word orderis not modeled, p(a|c) is constant.3.2 LearningThe model is trained using a collapsed Gibbs sam-pler.
Due to space limitations, the full derivationis omitted, but the sampling distribution turns outto be as follows for the common representation:p(csi= e?)
?1n?
1 + ??{?
if ne?= 1ne??
1 if ne?> 1?
?l?f?Alsi?mlsifk=1(nle?f+ ?le?f?
k)?
?fmlsifk=1(?f?Flnle?f+ ?le?f?
k)(2)where Alsiis the set of word types f in language lwhich are aligned to csi, and mlsifis the numberof times each such f is aligned to csi.
In order tospeed up calculations, the product in Equation 2can be approximated by letting l run over a smallrandom subset of languages.
The experiments car-ried out in this work only use this approximationwhen the full corpus of 1144 translations is used,then a subset of 24 languages is randomly selectedwhen each csiis sampled.
An empirical evalua-tion of the effects of this approximation is left forfuture work.The alignment sampling distribution is:p(alsj= i) ?nle?f?+ ?le?f??
1?f(nle?f+ ?le?f)?
1(3)where e?= csalsjis the concept type aligned toword type f?= wlsj.Rather than sampling directly from the distribu-tions above, one can sample from p?
(csi= e?)
?124Table 1: Variables used in the model.Observed variablesFlthe set of word types in language lwlsj?
Flword j of sentence s in language lIs?
N length of sentence s in the common representationJls?
N length of sentence s in language lLatent variablesEcthe set of concepts in the assignment ccsi?
Ecconcept i of sentence s in the common representationalsj?
{1..Is} alignment of wlsjto csi; i = alsjtlef?
R translation probability p(fl|e), where fl?
Fland e ?
EcHyperparameters?
CRP hyperparameter, fixed to 1000 in the experiments?
symmetric Dirichlet prior for translation distributions ?l,fixed to 0.001 in the experimentsp(csi= e?
)?and p?
(alsj= i) ?
p(alsj= i)?.The temperature parameter ?
can be varied dur-ing training to change the amount of randomnesswhile sampling.3.3 InitializationIn order to obtain a reasonable initial state for theGibbs sampling, one can simply initialize the com-mon representation to be identical to one of thelanguages in the corpus.
For this language onethen (trivially) has a perfect alignment, while theremaining languages are initialized randomly andtheir alignments are learned.
Random initializa-tion of the common representation is possible, butturns out to perform poorly.4 ExperimentsThe most basic question about the present modelis whether sampling the common representation ishelpful, compared to simply choosing a languageand aligning all other languages to that one.In order to test this, I initialize the model as de-scribed in section 3.3 and sample alignments (butnot the common representation) for 200 iterationswith ?
linearly increasing from 0 to 2, followed bytwo iterations with ?
?
?.
This gives a strongbaseline, from which one can start learning thejoint model.4.1 DataI use a corpus containing verse-aligned transla-tions of the New Testament into a great number oflanguages.
After some exclusions due to e.g.
non-standard formatting or improperly segmented text,the version used in this work contains 1144 trans-lations in 986 different languages.
The mean num-ber of tokens among the translations is 236 000,and the mean number of types is 9 500.4.2 Evaluation MeasuresPrevious authors have tended to avoid multilingualevaluation altogether.
Mayer and Cysouw (2012)do not evaluate their method, while Lardilleux etal.
(2011) only use bilingual evaluation.Cysouw et al.
(2007) use the fact that sometranslations of the Bible have been annotated withStrong?s Numbers, which map most word tokensto the lemma of its translation equivalent in theoriginal language, to perform bilingual evaluationof Bible corpus alignments.Strong?s Numbers can be used in a differentway to evaluate the type of multilingual alignmentproduced by the method in this work.
Both theStrong?s Numbers and the common representationcan be interpreted as clusterings of the word to-kens in each language.
Ideally one would wantthese two clusterings to be identical, as they wouldbe if the original language had been perfectly con-structed.
Standard clustering evaluation measurescan be used for this task, and in this work I usenormalized mutual information (also reinvented asV-measure by Rosenberg and Hirschberg (2007)).The evaluation is limited to words which are as-signed exactly one Strong?s Number, in an attemptto avoid some of the problems with scope dis-cussed by Cysouw et al.
(2007).
Note that even aperfect alignment from one language to itself doesnot achieve the maximum score using this mea-1250 200 400 600 800 1000Iterations0.680.700.720.740.760.780.80NormalizedMutual InformationdeuengengfraindindnldporrusFigure 1: Alignment quality of Mandarin-initialized model.sure, only a successful reconstruction of the origi-nal text (minus inflections) would.In the Bible corpus used here, nine translationsin seven languages contain Strong?s Numbers an-notations: English and Indonesian (two transla-tions each), as well as German, French, Dutch,Portuguese and Russian (one translation each).4.3 ResultsFigure 1 shows alignment quality during trainingin a model initialized using a translation in Man-darin, which is not related to any of the languagesin the evaluation sample and was chosen to avoidinitialization bias.
After an initial drop when noiseis introduced during the Gibbs sampling process,alignment quality quickly increases as the com-mon representation moves towards the versions inthe evaluation sample.
The final two iterations(with ???)
remove the sampling noise and themodel rapidly converges to a local maximum, re-sulting in a sharp increase in alignment quality atthe end.
Further iterations only result in minor im-provements.Table 2 contains the baseline and joint model re-sults for models initialized with either English orMandarin versions.
The joint model outperformsthe baseline in all cases except when the initial-ization language is the same as the evaluation lan-guage (the two English translations in the left col-umn), which is expected since it is easy to align atext to itself or to a very similar version.The two models described so far only use thenine-translation evaluation sample to learn thecommon representation, since using additionallanguages would unfairly penalize the joint learn-English MandarinA A+J A A+Jdeu 0.817 0.824 0.708 0.788eng 0.854 0.851 0.714 0.800eng20.834 0.833 0.708 0.790fra 0.807 0.816 0.712 0.783ind 0.774 0.785 0.710 0.770ind20.791 0.803 0.721 0.786nld 0.839 0.850 0.724 0.809por 0.807 0.813 0.709 0.782rus 0.792 0.800 0.699 0.772Table 2: Normalized mutual information with re-spect to Strong?s Numbers, using alignment only(A) or joint alignment + common representationlearning (A+J), for models initialized using En-glish or Mandarin.ing model.
I have also tested the model on thefull corpus of 1144 translations with an English-initialized model and the same training setup asabove (initialized from English).
In this case,alignment quality decreased somewhat for the lan-guages most similar to English, which is to be ex-pected since the majority of languages in the cor-pus are unrelated to English and pull the commonrepresentation away from the European languagesin the evaluation sample.
Although it is not possi-ble to directly evaluate alignment quality outsidethe evaluation sample with Strong?s Numbers, thelog-probability of the entire data under the model(Equation 1) increases as expected, by about 5%.5 Conclusions and Future WorkAs the number of translations in a parallel cor-pus increases, the problem of aligning them be-comes a rather different one from aligning trans-lation pairs.
I have presented a Bayesian methodthat jointly learns a common structure along withalignments to each language in the corpus.
Inan empirical evaluation, the joint method outper-forms the baseline where the common structure isone of the languages.Currently the underlying alignment model isquite simplistic, and preliminary results indicatethat including the HMM word order model of Vo-gel et al.
(1996) further improves alignments.AcknowledgmentsThanks to J?org Tiedemann, Mats Wir?en and theanonymous reviewers for their comments.126ReferencesPeter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics,19(2):263?311, June.Michael Cysouw and Bernhard W?alchli.
2007.
Paral-lel texts: Using translational equivalents in linguistictypology.
STUF - Language Typology and Univer-sals, 60(2):95?99.Michael Cysouw, Chris Biemann, and Matthias Ongy-erth.
2007.
Using Strong?s Numbers in the Bible totest an automatic alignment of parallel texts.
STUF -Language Typology and Universals, 60(2):158?171.Mona Diab and Philip Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallel cor-pora.
In Proceedings of the 40th Annual Meetingon Association for Computational Linguistics, ACL?02, pages 255?262, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Karim Filali and Jeff Bilmes.
2005.
Leveraging multi-ple languages to improve statistical MT word align-ments.
In IEEE Workshop on Automatic SpeechRecognition and Understanding, pages 92?97, SanJuan, November.
IEEE.Yarin Gal and Phil Blunsom.
2013.
A systematicbayesian treatment of the ibm alignment models.
InProceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In The Tenth Ma-chine Translation Summit, Phuket, Thailand.Shankar Kumar, Franz J. Och, and WolfgangMacherey.
2007.
Improving word alignment withbridge languages.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 42?50,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Adrien Lardilleux, Yves Lepage, and Franois Yvon.2011.
The contribution of low frequencies to multi-lingual sub-sentential alignment: a differential asso-ciative approach.
International Journal of AdvancedIntelligence, 3(2):189?217.Adrien Lardilleux, Francois Yvon, and Yves Lepage.2013.
Hierarchical sub-sentential alignment withAnymalign.
In Proceedings of the 16th EAMT Con-ference, pages 279?286, Trento, Italy, 28-30 May2012.Thomas Mayer and Michael Cysouw.
2012.
Lan-guage comparison through sparse multilingual wordalignment.
In Proceedings of the EACL 2012 JointWorkshop of LINGVIS & UNCLH, EACL 2012,pages 54?62, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Cos?kun Mermer and Murat Sarac?lar.
2011.
Bayesianword alignment for statistical machine translation.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies: short papers - Volume 2,HLT ?11, pages 182?187, Stroudsburg, PA, USA.Association for Computational Linguistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51,March.Darcey Riley and Daniel Gildea.
2012.
Improving theIBM alignment models using variational Bayes.
InProceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics: Short Papers- Volume 2, ACL ?12, pages 306?310, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Andrew Rosenberg and Julia Hirschberg.
2007.
V-measure: A conditional entropy-based external clus-ter evaluation measure.
In Proceedings of the 2007Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), pages 410?420, Prague, Czech Republic, June.
Association forComputational Linguistics.Oscar T?ackstr?om.
2013.
Predicting Linguistic Struc-ture with Incomplete and Cross-Lingual Supervi-sion.
Ph.D. thesis, Uppsala University, Departmentof Linguistics and Philology.J?org Tiedemann.
2011.
Bitext Alignment.
SynthesisLectures on Human Language Technologies.
Mor-gan & Claypool Publishers.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statisticaltranslation.
In Proceedings of the 16th Conferenceon Computational Linguistics - Volume 2, COLING?96, pages 836?841, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Dekai Wu and Xuanyin Xia.
1994.
Learning anEnglish-Chinese lexicon from a parallel corpus.
InProceedings of the First Conference of the Associa-tion for Machine Translation in the Americas, pages206?213.David Yarowsky, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing multilingual text analy-sis tools via robust projection across aligned cor-pora.
In Proceedings of the First International Con-ference on Human Language Technology Research,HLT ?01, pages 1?8, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.127
