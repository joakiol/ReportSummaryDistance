CSR Corpus DevelopmentGeorge R. DoddingtonSRI InternationalMenlo Park, CAABSTRACTThe CSR (Connected Speech Recognition) corpus represents anew DARPA speech recognition technology development i i ia-tive to advance the state of the art in CSR.
This corpus essentiallysupersedes the now old Resource Management (RM) corpus thathas fueled DARPA speech recognition technology developmentfor the past 5 years.
The new CSR corpus supports research onmajor new problems including unlimited vocabulary, naturalgrammar, and spontaneous speech.
This paper presents an over-view of the CSR corpus, reviews the definition and developmentof the "CSR pilot corpus", and examines the dynamic challenge ofextending the CSR corpus to meet future needs.OVERVIEWCommon speech corpus development and evaluationreceived major emphasis from the very beginning of theDARPA speech recognition program.
At that ime, a set ofcommon corpora were defined to serve the needs of theresearch community.
This resulted in the development ofthe TIMIT speech corpus, which was collected from a largenumber of subjects and intended to support basic researchin acoustic-phonetic re ognition technology.
The ResourceManagement (RM) corpus, collected from fewer subjectsbut representing an application of interest to DARPA, pro-vided the greatest focus of interest in technology through-out the research community.
In the course of R&D usingthese two corpora, the first serious research and advancestoward speaker-independent speech recognition wereachieved.Although the RM corpus erved its intended purpose well,technology advances came to make its limitations painfullyobvious.
The language was artificial and limited, the speechwas read and therefore unnatural, and the corpus com-pletely avoided the central issue of understanding themeaning of the spoken utterances.
In response to these lim-itations and to rapid advances in the performance ofspeechrecognition technology on this RM task, a new research ini-tiative was formed by combining speech recognition andnatural language understanding tasks in a spoken languagesystem (SLS) program.The SLS program took shape with the definition of the Air-line Travel Information System (ATIS) task, a databasequery task which supports research in both speech recogni-tion and natural language.
The ATIS corpus (corpora) iscurrently being collected to provide the experimental datafor developing SLS technology.
This ATIS corpus exhibitsseveral desirable features regarding the speech recognitionproblem that were found lacking in the RM corpus.
Thesefeatures are namely the use of spontaneous goal-directedspeech and the consequent use of a natural grammar and anopen unrestricted vocabulary.Although the ATIS corpus provides the kind of speech datadesired by the speech recognition research community andrequired to address important problems in the applicationof speech recognition to real tasks, there is one unfortunateshortcoming ofthis corpus.
This is that he cost and effortof collecting the data is too great o support the massivedata requirements for advances in speech recognition tech-nology.
Some way of improving the efficiency and produc-tivity of data collection was needed in order to supportfurther advances in speech recognition technology.
Thisneed was the primary motivation for the creation of theCSR research initiative and its related CSR corpus.The CSR research initiative, along with the CSR corpusdevelopment effort, was created in order to provide bettersupport for advances in the state of the art in large vocabu-laiy CSR.
The primary focus in the CSR initiative has beenon the design and development ofa CSR speech corpuswhich is required to fuel the research and through whichthe research might be productively directed.
Primary objec-tives of the CSR corpus have been to increase the realismof the speech data and at the same time to maximize theefficiency of collecting that data.
Efficiency has beenviewed as of paramount importance because it is generallybelieved that significant advances in speech recognitiontechnology will require more comprehensive models ofspeech and correspondingly more massive quantities ofspeech data with which to train them.Janet Baker was the principal champion and designer of theCSR corpus, working as the chair of a CSR corpus designcommittee.
This committee dealt with a large and diverseset of research interests and corpus needs, which made the363task of designing a satisfactory corpus extremely difficult.For example, the desire to collect spontaneous speech wasin direct opposition to the need to make corpus develop-ment efficient (because spontaneous speech requires a gen-erally painstaking and expensive transcription task,whereas read speech can be transcribed far more efficientlyand even largely automatically).
1Major Corpus Design DecisionsRead speech versus pontaneous speech: On theissue of spontaneous speech, it was decided that themajority of the corpus (and in particular the majorityof the training data) should be read speech, for eco-nomic reasons, whereas the majority of the test data(which comprises a small fraction of the total data)should be spontaneous speech.
The reason for thesedecisions i  that it was felt that large amounts of readspeech would provide greater training benefits thansmaller amounts of spontaneous speech, while usingspontaneous speech for testing would better validatethe technology for a relatively small increase in cost.Prompting text: Probably the most significant deci-sion regarding the CSR corpus was the decision towork initially with the Wall Street Journal (WSJ).This decision was influenced by the richness of theWSJ language and by the existence of a preexistingand very large (50 million word) corpus of WSJ text(as part of the ACL-DCI effort).
All of the readspeech data is currently being collected usingprompts derived from the WSJ.
The spontaneousspeech data is being collected using a news reportingdictation paradigm that simulates the WSJ dictationscenario.
2Verbalized punctuation: In dictation, which is thenominal target application for the CSR technologydevelopment effort, dictation users typically saypunctuation such as "comma" and "period" so as toaid in the proper punctuation ofthe dictated ocu-ment.
Therefore, in order to improve the verisimili-tude of the CSR corpus, a strong opinion was voicedthat such verbalized punctuation (VP) be included inthe prompting text.
Opposed to this view was the1.
The design of the CSR pilot corpus is describedin detail in the paper by D. Paul and J. Baker inthis workshop's proceedings entitled "The Designfor the Wall Street Journal-based CSR Corpus".2.
The spontaneous speech data collection effort isdescribed indetail in the paper by J. Bernstein andD.
Danielson in this workshop's proceedings enti-tled "Spontaneous Speech Collection for the CSRCorpus.opinion that such predetermined VP may not repre-sent realistic VP, may limit research on automaticpunctuation, may restrict he task and perplexity,may unduly burden the corpus with VP words, andmay present adifficult and artificial reading task tousers.
As a result, a compromise position was takenin which half of the corpus was collected in VP modeand half in non-VP mode.?
Speaker-independence: TheCSR corpus, althoughdirected primarily toward speaker-independent rec-ognition, also supports research into speaker depen-dent recognition.
Approximately half of the pilotcorpus is dedicated to speaker-dependent work.?
Microphone independence: The primary microphoneis the traditional Sennheiser model HMD-414.
Inaddition, all data were collected also with a second-ary microphone.
Previously, this second microphonewas a single far-field pick-up microphone, such asthe desktop Crown model PZM-6FS.
The CSR pilotcorpus represents a departure from this practice and afirst attempt at true microphone-independent r cog-nition (in much the same spirit as speaker-indepen-dent recognition) by using one of many differentmicrophones for the altemate (secondary) speechchannel.?
Transcription: For the CSR pilot corpus, the originalsource text was preprocessed to produce astring ofwords that represented aswell as practical the stringof words that would result from reading the sourcetext.
This word string was then presented tothe sub-ject as the prompting text.
This approach provided avery efficient ranscription mechanism, because theprompting text could automatically be used as thetranscription (except when the subject made errors inreading).
Also, the language model, although per-haps a bit unnatural to the extent hat the promptstring doesn't represent the statistics of the tree lan-guage model, can be more easily and comprehen-sively estimated by preprocessing large volumes oftext rather than by transcribing relatively smallamounts of speech data.The CSR Corpus Coordinating CommitteeThe charter of the CSR Corpus Coordinating Committee(CCCC) is to coordinate CSR corpus development and toresolve issues which arise in CSR corpus development andevaluation.
There are currently 12 members of the CCCC,namely:Janet Baker, DragonJordan Cohen, IDAGeorge Doddington (chairman)364Francis Kubala, BBNDave Pallett, NISTDoug Paul, Lincoln LabsMike Phillips, M1TMichael Picheny, IBMRaja Rajasekaran, TIXuedong Huang, CMUMitch Weintraub, SRIChin Lee, AT&TThis committee was formed at the SLS coordinating com-mittee meeting in October 1991.
Since that time the com-mittee has met ten times, mostly via teleconference.
CCCCactivities have included:?
Definition of procedures for microphone gain adjust-ment and calibration.?
Defin fion of procedures for transcribing the speechdata.?
Monitoring progress in speech data collection andtranscription.?
Definition of the data distribution schedule and for-mat.?
Definition of procedures for evaluation of vocabu-lary/speaker adaptive systems.?
Definition of procedures for scoring.?
Definition of recommended baseline performanceevaluations.The CSR pilot corpusOne of the primary motivations for creating the CSR taskand corpus was to provide asufficiently large corpus of datato properly support advances in speech recognition technol-ogy.
This implies a very large effort, with many hundreds ofhours of speech data being collected.
Given the massiveeffort required, and appreciating the untried nature of manyof the corpus parameters, it was decided that a pilot corpusshould be collected first to determine the correctness ofthemany corpus design decisions and to allow modifications ofthese as necessary.The CSR pilot corpus is described in a companion paper inthese proceedings entitled "The Design for the Wall StreetJournal-based CSR Corpus" by D. Paul and J. Baker.
Thiscorpus provides for the development and evaluation of bothspeaker-independent (SI) and speaker-dependent (SD) rec-ognition.
It uses the now-standard DARPA corpus approachof providing a three-part corpus: speech data for trainingthe speech recognition system ("TRAINING"), speech datafor developing and optimizing the recognition decision cri-.teria ("DEVELOPMENT TEST"), and speech data for per-forming the formal performance evaluation("EVALUATION TEST").The CSR February 1992 dry run evaluationThe recommended baseline performance evaluations weredefined by selection of training data set(s), testing dataset(s), recognition conditions (vocabulary and languagemodel), and scoring conditions.
In the course of discussionon these issues it became clear that consensus was not pos-sible on definition of a single set of evaluation conditions.This was in addition to the distinct differences betweenspeaker-dependent (SD) and speaker-independent (SI) eval-uation data and conditions.
Some committee members feltthat here should be no constraint on training material, toallow as much freedom as possible to improve performancethrough training data.
Others believed strongly that calibra-tion of performance improvement was paramount and there-fore all sites should be required to use a single baseline setof training data.
In the end, the committee was able only toidentify anumber of different training and test conditions as"recommended" altematives for a baselnie valuation.For training the recommended SI training corpus comprised7240 utterances from 84 speakers.
The recommended SDtraining corpus comprised the 600 training sentences foreach of the 12 SD speakers.
For the large-data speaker-dependent (LSD) training condition, the recommended SDtraining corpus comprised the 2400 training sentences foreach of the 3 LSD speakers.For testing there were a total of 1200 SI test utterances and1120 SD test utterances.
These data comprised, similarlyand separately for SI and SD recognition, approximately400 sentences constrained toa 5000-word vocabulary, 400sentences unconstrained byvocabulary, 200 sentences ofspontaneous dictation, and these 200 sentences a  read laterfrom a prompting text.The vocabulary and language models used for the above-defined test sets were either unspecified (for the spontane-ous and read versions of the spontaneous dictation), or werethe 5000-word vocabulary and bigram grammar as suppliedby Doug Paul from an analysis of the preprocessed WSJcorpus.
(Actually, two different sets of bigram model proba-bilities were used, one modeling verbalized punctuation andone modeling nonverbalized punctuation.
These two wereused appropriately for the verbalized and nonverbalizedpunctuation portions of the test sets, respectively.
)Given the rather massive computational challenge of train-ing and testing in such a new recognition domain, withlarger vocabulary and greater amount of test data, not all ofthe test material was processed by all of the sites perform-ing evaluation.
Also, because of the variety of training andevaluation conditions, few results were produced that couldbe compared across ites.
Two test sets, however, were eval-uated on by more than a single site: Two sites producedresults on the SD 5000-word VP test set (Dragon and Lin-coln), and three sites produced results on the SI 5000-word365VP test set (CMU, Lincoln, and SRI).
These results aregiven in a companion paper on "CSR Pilot Corpus Perfor-mance Evaluation" by David Pallett.Future CSR corpus effort and issuesSeveral issues have been identified that bear on the CSRcorpus and on potential changes in the design of the corpus:?
Verbalized punctuation.
There is a significant argu-ment o discontinue verbalized punctuation, for sev-eral reasons: It doubles the number of languagemodels and test sets and thus the number of evalua-tion conditions.
It is artificial in the sense that it isstatistically unlike normal dictation, it is more diffi-cult for many subjects to read, and it seems uperflu-ous to the development of the underlying speechrecognition technology.?
Preprocessed prompting text.
There is argument toprompt he user with the natural unpreprocessed t xtfrom the WSJ rather than with the preprocessedword strings as produced by the text preprocessor.The reason is that the word strings do not representthe actual statistics of natural speech (see the com-panion paper by Phillips et.
al entitled "Collectionand Analyses of WSJ-CSR Data at MIT").?
Spontaneous speech.
There is argument that the cur-rent paradigm for collecting spontaneous speech isnot adequately refined to represent those aspects ofspontaneous speech that are important in actualusage, and that spontaneous speech should remain inan experimental nd developmental mode during thenext CSR corpus phase.?
Adaptation.
Speaker adaptation and adaptation totheacoustical environment has emerged as a majorinterest.
It is clear that adaptive systems must beaccommodated in the next phase of the CSR corpus.?
CSR corpus development effort.
It is acknowledgedthat the CSR corpus development effort is a keyactivity in the support and direction of CSR research,and that this effort herefore requires program conti-nuity and should not be treated as an occasional pro-duction demand that can be easily started andstopped.These issues are currently under debate in the CCCC, andthe next installment of the CSR corpus, to be called theCSR corpus, phase two, will no doubt reflect a continueddistillation of opinion on these issues.366
