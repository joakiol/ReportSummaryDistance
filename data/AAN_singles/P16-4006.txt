Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics?System Demonstrations, pages 31?36,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsA Web-framework for ODIN AnnotationRyan Georgi Michael Wayne Goodman Fei XiaUniversity of WashingtonSeattle, WA, USA{rgeorgi,goodmami,fxia}@uw.eduAbstractThe current release of the ODIN (On-line Database of Interlinear Text) databasecontains over 150,000 linguistic examples,from nearly 1,500 languages, extractedfrom PDFs found on the web, representinga significant source of data for languageresearch, particularly for low-resource lan-guages.
Errors introduced during PDF-to-text conversion or poorly formatted exam-ples can make the task of automatically an-alyzing the data more difficult, so we aimto clean and normalize the examples in or-der to maximize accuracy during analysis.In this paper we describe a system that al-lows users to automatically and manuallycorrect errors in the source data in order toget the best possible analysis of the data.We also describe a RESTful service formanaging collections of linguistic exam-ples on the web.
All software is distributedunder an open-source license.1 IntroductionThe current release of the ODIN (Online Databaseof INterlinear Text) database contains over150,000 linguistic examples in the form of inter-linear glossed text (IGT), an example of whichis shown in Fig.
1.
These IGT instances areextracted from PDFs found on the web, repre-senting a significant source of data for computa-tional typology, as well as providing informationfor resource-poor languages (RPLs).
These in-stances are additionally useful for inducing anno-tation on RPLs, as demonstrated by Georgi et al(2014, 2015), in which the relationships betweenwords and glosses are identified and encoded forthe purpose of enriching the data with annotationsnot present in the original examples.
However,keen?
Paks?
d?nq-ine-mDEM.PLUR dog five-DEF-ACC?these five dogs?Figure 1: An IGT instance of Aari [aiw], anOmotic language of Ethiopia.
Extracted fromDryer (2007)the PDF-to-text conversion process can introducenoise into the data, and some examples are not for-matted well in the original document.
These andother issues can decrease the efficacy of the auto-matic structural analysis.To address these issues, we have created aweb interface that combines automatic cleaningand normalization procedures with a user-friendlybrowser-based GUI to enable human annotators toreview and improve the data quality of the avail-able IGT instances.
Additionally, as editing ismeant as one of multiple capabilities of the finalsystem, this browser interface is driven by a REST-ful (Fielding, 2000) backend system that will sup-port future interface extensions.2 Related WorkThe system we describe is not the first web-basededitor of IGT, but none of the existing systems(for IGT or annotation in general) that we?re awareof fit our use case.
TYPECRAFT1(Beermannand Mihaylov, 2014) is a wiki-based collabora-tive IGT editor.
As it directly targets IGT, theeditor is designed to support tabular annotationsand is a useful tool for users creating new IGT.However, it limits the kinds of annotations (mor-phemes, POS tags, glosses, etc.)
and it is not ob-vious how the ODIN model (see Section 3) wouldfit, nor how our automated transformation scripts(see Section 4) would be integrated.
The brat1http://typecraft.org31rapid annotation tool2(BRAT; Stenetorp et al,2012), with its RESTful web API, is somewhatsimilar in implementation to our system, but doesnot seem to support tabular visualization of hierar-chical annotations.
The current annotation task forour users is primarily correcting errors in text ex-tracted from PDFs, which is similar in some waysto how RECAPTCHA (Von Ahn et al, 2008) letsusers provide clean transcriptions of text in im-ages.
But, unlike RECAPTCHA, our task re-quires some knowledge of IGT structure.3 ODIN DataThe data that we are seeking to annotate in this pa-per comes from the ODIN 2.1 data release,3whichprovides the data in two formats: the plain text for-mat, and in Xigt, an extensible format for encod-ing IGT (Goodman et al, 2014).3.1 Building ODINThe ODIN database was constructed in severalsteps.
First, documents were retrieved using ameta-crawling approach, where queries with IGT-like search terms such as {3SG, ACC} were di-rected to online search engines.
The resulting doc-uments were converted to text format using an off-the-shelf PDF-to-text conversion tool.
This textoutput was subsequently used to extract featuresto detect the IGT instances within the text, as wellas build a language identification system.
The fulldetails of the construction of the ODIN databasecan be found in Lewis and Xia (2010).3.2 Extracted Textual IGTsThe first format for representing IGT is intended tobe human-readable while maintaining the appro-priate metadata for processing.
An example of thisformat can be seen in Fig.
2.
This format includesthe textual content of the IGT, as well as whether aline belongs to the language line (L), gloss line (G)or translation line (T) of the instance, or whether itis metadata (M).
In addition, secondary tags existfor more fine-grained categorization, such as forcorrupted instances (CR), language name metadata(LN), etc.
Furthermore, a doc_id is providedfor reference to the original source document, aswell as line numbers referring to the lines from thepdftotext4output of the PDF document.2http://brat.nlplab.org3http://depts.washington.edu/uwcl/odin4http://www.foolabs.com/xpdf3.3 Xigt-encoded IGTsThe Xigt format (Goodman et al, 2014) encodesall of this information in a model that is bettersuited for computational work.
The Xigt pack-age provides codes for either XML or JSON, andenables standoff annotation that is capable of pre-serving the original text format while adding mul-tiple annotation layers (Xia et al, 2016).
This isthe format used for storing additional annotation,including the syntactic enrichment found in Xiaet al (2016), as well as metadata such as annota-tor comments.
This standoff annotation is imple-mented as XML elements we call tiers that referback to the elements they annotate.4 Automatic ProcessingThe data in ODIN was assembled using an ap-proach that combined metacrawling for IGT-containing documents with a classifier trained todetect IGT-formatted instances (Lewis and Xia,2010).
The resulting data can look like that inFig.
2; with a variety of corruption and non-linguistically relevant data.
To speed up annota-tion, we run several automated cleaning and nor-malization steps before handing the instance off tohuman annotators.4.1 CleaningIn the first step, we attempt to clean any artifactsintroduced by the PDF-to-text conversion process.First, invalid characters for XML data, such asthe form feed control character U+000C, are auto-matically replaced with the Unicode replacementcharacter U+FFFD.
Line and character corruptionare addressed next.
The instance in Fig.
2 exhibitsboth line corruption and character corruption.
Forline corruption, we merge two lines of the sametype (e.g., L) if they are adjacent, one or both hasthe corruption tag CR, and any characters in thelines line up with whitespace in the other.
In thisexample, the ?ak?
on line 875 would be combinedwith the rest of the text on 876 as the two linesare merged into one.
The output of the clean-ing process is output to a new cleaned Xigt tier.The cleaning process also removes blank lines (ifany) and superfluous initial columns of whitespace(consistently across lines to avoid altering columnalignments).
Currently we do not attempt to au-tomatically fix character corruption (e.g., when acharacter?s diacritics are erroneously extracted as aseparate character), but instead allow users to cor-32doc_id=1482 874 878 M+AC+LN L+CR L+SY+CR G T+DBlanguage: Haitian (hat)line=874 tag=M+AC+LN: (25) Haitian CF (Lefebvre 1998:165)line=875 tag=L+CR : akline=876 tag=L+SY+CR: Jani pale lii/jline=877 tag=G : (John speak with he)line=878 tag=T+DB : (a) ?John speaks with him?, (b) ?John speaks with himself?Figure 2: A text-format ODIN IGT instance exhibiting line corruption, character corruption, and lan-guage names and parentheticals, extracted from Heine (2001).rect the corrupted characters (including Unicode),and we make the original PDF available to the userfor consultation, if it is necessary.
We are also in-vestigating an alternative PDF extractor that moreaccurately extracts Unicode characters, diacritics,combined ligatures, etc.4.2 NormalizationThe second automated step we perform relates toinformation that is either non-linguistic or meta-linguistic in nature.
In Fig.
2, such information in-cludes the instance numbering (25), the languagename (Haitian), author citation (Lefebvre), andquotation marks (on line 878).
In the instance inFig.
2, these elements have been placed on a lineabove the language line, which the IGT detectionalgorithm has tagged as non-IGT data (tag=M).Other times, this data occurs on the language lineand thus instance numbering on the language lineare removed with regular expressions.
Other in-formation, such as the language name or linguisticconstruction, are detected and placed on a sepa-rate M line.
However, not all data can be reliablyautomatically extracted, such as the co-indexationvariables i and j in line 876 which could be inter-preted as being part of the word.4.3 EnrichmentIn addition to cleaning and normalizing, throughthe use of the INterlinear Text ENrichment Toolkit(INTENT) (Georgi, 2016; Xia et al, 2016), weautomatically generate word alignments and part-of-speech tags for the different lines of IGT.
Cur-rently, this is visualized in the editor, as seen inFig.
5, and will be able to be corrected by the an-notators for subsequent tasks.5 A RESTful IGT ServerWhile our immediate needs for the editor are fairlysimple, we anticipate expansion for future tasksthat may be required by the RiPLes (informationengineering and synthesis for Resource-Poor Lan-guages) project (Xia et al, 2016).
In order to fa-cilitate such expansion, we created the backendfor the editor as a general-purpose RESTful IGTserver with the HTTP methods listed in Fig.
4.The data is stored in a custom JSON-basedfilesystem database so that individual IGTs canbe updated without having to reserialize an entirecorpus, but the database abstraction layer makesit straightforward to later add support for otherdatabases.
Through the Accept request header, auser may ask for either the XML or JSON serial-ization of the data.
More information on this inter-face can be found at the project page at:https://github.com/xigt/sleipnir6 Online Editing EnvironmentThe main interface that end-users will experienceat this point is the online editing environment, ascreenshot of which is provided in Fig.
3.
Thisbrowser-based interface allows us to invite an-notators around the world to participate withoutneeding to install Python or any of the supportingpackages required to work with the Xigt-formattedODIN data.The interface is contained in three main panes;in Fig.
3, labels (1) and (2) mark the corpus andinstance browsers, respectively, while the rest ofthe window is dedicated to the instance editor.Loading an Instance To start working on an in-stance, an annotator first selects the corpus fromthe corpus browser (1) and then the particular in-stance from (2).
Instances that have been previ-ously annotated are highlighted with the color oftheir rating, while the currently displayed instanceis highlighted in cyan.Validating an Instance as IGT Once an in-stance is loaded in the editor, the annotator is pre-sented with an interface showing only the raw textof the instance (not shown), and the rating buttons(4).
Since instances in ODIN have been automat-ically identified, some instances may not, in fact,be IGT, or may be too corrupted to derive what theoriginal content might have been.
At this point,33Figure 3: Screenshot of the browser-based editor being used to edit a sentence.
(1) and (2) show thecorpus and instance browsers, respectively, while (3) labels the instance editing area, and (4) shows therating system.GET /corporaretrieve list of available corporaGET /corpora/<CID>retrieve a corpus by its identifier <CID>GET /corpora/<CID>/summaryretrieve a summary of the contents of corpus <CID>GET /corpora/<CID>/igtsretrieve the list of IGTs for corpus <CID> (parametersexist for filtering this list)GET /corpora/<CID>/igts/<IID>retrieve a single IGT by its identifier <IID> from cor-pus <CID>POST /corporaadd a new corpusPOST /corpora/<CID>/igtsadd a new IGT to corpus <CID>PUT /corpora/<CID>/igts/<IID>assign or replace IGT <IID> in corpus <CID>DELETE /corpora/<CID>delete corpus <CID>DELETE /corpora/<CID>/igts/<IID>delete IGT <IID> in corpus <CID>Figure 4: HTTP methods for the IGT server,where <CID> refers to the corpus identifier and<IID> the single IGT identifier.the annotator may click the red ?bad quality?
rat-ing button to flag that instance.
If the instance isIGT and of acceptable quality they may continueonto the next task.Cleaning After the annotator has verified thatan instance is valid, they may click the Gener-ate Cleaned Tier button to trigger the automaticcleaning procedure described in Section 4.1.
Theannotator is then given an opportunity to manu-ally correct any errors made by the automatic cor-ruption removal.
The cleaning stage only correctserrors introduced by the PDF-to-text conversionprocess, so for clean instances there is little to bedone here.
If the annotator has made a mistake orwishes to start over, they may restore the contentof an item to the state after automatically clean-ing, or they may regenerate the clean tier entirelyby re-invoking the cleaning procedure on the rawdata.
The raw tier cannot be edited, so the anno-tator can always get back to the original represen-tation.
Once satisfied, the annotator may continueto the normalization step.Normalization By clicking the Generate Nor-malized Tier button, the annotator triggers thenormalization procedure described in Section 4.2.In addition to placing non-IGT information on Mlines, annotators are also asked to correct spuri-ous or missing whitespace, ensure that there arean equal number of language-line and gloss-linetokens, and, when possible, an equal number ofmorpheme or clitic boundaries denoted by ?-?
or?=?, following the Leipzig Glossing Rules (Com-rie et al, 2015).
Just as with the cleaning step,34Figure 5: Normalized tier analysis, with the sec-tion labeled (1) showing the annotation indicatorlabels and (2) showing the enrichment and align-ment information.
The colors highlighted in (2)are to indicate which elements of the IGT in-stance are referenced by another element.
Here,the alignment between the English go and theJapanese ikasetas visualized.
The titles on the leftrefer to the tier type represented in the Xigt repre-sentation.6the annotator may restore the original normalizedcontent of an item or regenerate the normalizedtier entirely.
At this point, if the annotator be-lieves they have satisfactorily met the normaliza-tion guidelines, they are done editing and continueto the analysis step to ensure the system is able toaccurately infer the IGT structure.Analysis When the annotator clicks the AnalyzeNormalized Tier button, the editor will presentan analysis of the IGT such as the one shown inFig.
5.
This analysis includes both a series of in-dicators (1) to alert the annotator to the aforemen-tioned guidelines, and a visualization of the au-tomatic alignment and enrichment (2) performedby INTENT (see Section 4.3).
The enrichment in-cludes both the automatic word, morpheme, andgloss segmentation (words, morphemes, glosses,respectively), as well as word alignment betweengloss and translation and part-of-speech tags foreach line (bilingual-alignments, pos).
There arecurrently four indicators:COL language and gloss tokens are aligned withwhitespace into columnsTAG language, gloss, and translation lines all ex-ist and have no extraneous metadata on themGLM language and gloss lines have the samenumber of morphological unitsGLW language and gloss lines have the samenumber of whitespace-separated tokensWhen an indicator shows red, the annotatorshould go back to the normalization (or possibly,the cleaning) step and make more corrections, thenreanalyze.
Occasionally an indicator shows redwhen there is no error; e.g., a word in the languageline might have a hyphen that is not a morpho-logical boundary and is thus glossed with a non-hyphenated token.
The visualization of the auto-matically aligned and enriched IGT illustrates tothe annotator how well the system was able to in-fer the structure of the IGT.
Some problems thatcould not be detected with the indicators may be-come obvious by the presence of incorrect align-ments, and the annotator can use this informationto adjust the textual representation until properalignments are obtained.
These two facets of theanalysis?indicators and visualization?help theannotator see how usable the instance will be forfurther processing.Rating and Saving the Instance Finally, if theannotator has proceeded to the normalization oranalysis steps, they may choose to rate the instanceas bad (red), unclean (yellow) or clean (green), de-pending on the level of corruption of the instance.A field is provided to add further comments thatwill be saved into the IGT file.User Management Currently, users are identi-fied by a unique 8-character userid string, that alsoserves as the login.
Annotator accounts are createdand a backend corpus management script is used toinitialize copies of corpus subsections that are as-signed to the annotators.
Annotators?
ratings andcomments are saved in these files along with theiruserid, so that inter-annotator agreement can bequickly and efficiently calculated across selectedoverlapping corpus segments.Availability A fully functioning demonstrationof the interface containing Chinese, German, andJapanese instances may be accessed at:http://editor.xigt.org/user/demoThe source code is released under the MIT license6See Goodman et al (2014) for more.35and is available at:https://github.com/xigt/yggdrasil7 Conclusion and Future ImprovementsThe system we have presented here greatlystreamlines the process of refining and display-ing IGT data.
Such clean, electronically avail-able IGT data can be of great use to linguistssearching for examples of particular phenomena,typologists looking to compare linguistic informa-tion over the thousands of languages for whichIGT data is available, and computational linguistslooking to build NLP tools for resource-poor lan-guages.In the future, we hope to further expand theediting capabilities of the system to include giv-ing annotators the ability to edit word alignmentand POS tag data.
Such annotation would providea high-quality set of data for typological research,as well as evaluation data for the automatic enrich-ment methods used.Finally, while the current system is used onlyfor display and editing, we hope to include theability to search over IGT corpora in a subsequentversion of the tool, replacing the current ODINsearch capability7.AcknowledgmentsThis work is supported by the National ScienceFoundation under Grant No.
BCS-0748919.
Anyopinions, findings, and conclusions or recommen-dations expressed in this material are those of theauthors and do not necessarily reflect the views ofthe NSF.ReferencesDorothee Beermann and Pavel Mihaylov.
2014.TypeCraft collaborative databasing and re-source sharing for linguists.
Language re-sources and evaluation 48(2):203?225.Bernard Comrie, Martin Haspelmath, andBalthasar Bickel.
2015.
Leipzig glossing rules.https://www.eva.mpg.de/lingua/pdf/Glossing-Rules.pdf.Matthew S Dryer.
2007.
Noun phrase structure.In Timothy Shopen, editor, Language Typologyand Syntactic Description, Language typology7http://odin.linguistlist.org/and syntactic description, Cambridge, UnitedKingdom, pages 151?205.Roy Fielding.
2000.
Architectural Styles andthe Design of Network-based Software Archi-tecture.
Ph.D. thesis, University of California,Irvine.Ryan Georgi.
2016. the INterlinear Text ENrich-ment Toolkit.
http://intent-project.info/.Ryan Georgi, William D Lewis, and Fei Xia.
2014.Capturing divergence in dependency trees toimprove syntactic projection.
Language Re-sources and Evaluation 48(4):709?739.Ryan Georgi, Fei Xia, and William D Lewis.
2015.Enriching interlinear text using automaticallyconstructed annotators.
LaTeCH 2015 page 58.Michael Wayne Goodman, Joshua Crowgey, FeiXia, and Emily M Bender.
2014.
Xigt: extensi-ble interlinear glossed text for natural languageprocessing.
Language Resources and Evalua-tion 49(2):455?485.Bernd Heine.
2001.
Accounting for creole reflex-ive forms.
Pidgins and Creoles Archive (8).William D Lewis and Fei Xia.
2010.
DevelopingODIN: A Multilingual Repository of AnnotatedLanguage Data for Hundreds of the World?sLanguages.
Literary and Linguistic Computing25(3):303?319.Pontus Stenetorp, Sampo Pyysalo, Goran Topi?c,Tomoko Ohta, Sophia Ananiadou, and Jun?ichiTsujii.
2012.
BRAT: a web-based tool for NLP-assisted text annotation.
In Proceedings of theDemonstrations at the 13th Conference of theEuropean Chapter of the Association for Com-putational Linguistics.
Association for Compu-tational Linguistics, pages 102?107.Luis Von Ahn, Benjamin Maurer, ColinMcMillen, David Abraham, and ManuelBlum.
2008. recaptcha: Human-based char-acter recognition via web security measures.Science 321(5895):1465?1468.Fei Xia, William D Lewis, Michael Wayne Good-man, Glenn Slayden, Ryan Georgi, JoshuaCrowgey, and Emily M Bender.
2016.
Enrich-ing a massively multilingual database of inter-linear glossed text.
Language Resources andEvaluation pages 1?29.36
