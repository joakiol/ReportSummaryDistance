Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1094?1103,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsNonparametric Learning of Phonological Constraints in OptimalityTheoryGabriel DoyleDepartment of LinguisticsUC San DiegoLa Jolla, CA, USA 92093gdoyle@ucsd.eduKlinton BicknellDepartment of LinguisticsNorthwestern UniversityEvanston, IL, USA 60208kbicknell@northwestern.eduRoger LevyDepartment of LinguisticsUC San DiegoLa Jolla, CA, USA 92093rlevy@ucsd.eduAbstractWe present a method to jointly learn fea-tures and weights directly from distri-butional data in a log-linear framework.Specifically, we propose a non-parametricBayesian model for learning phonologi-cal markedness constraints directly fromthe distribution of input-output mappingsin an Optimality Theory (OT) setting.
Themodel uses an Indian Buffet Process priorto learn the feature values used in the log-linear method, and is the first algorithmfor learning phonological constraints with-out presupposing constraint structure.
Themodel learns a system of constraints thatexplains observed data as well as thephonologically-grounded constraints of astandard analysis, with a violation struc-ture corresponding to the standard con-straints.
These results suggest an alterna-tive data-driven source for constraints in-stead of a fully innate constraint set.1 IntroductionMany aspects of human cognition involve the in-teraction of constraints that push a decision-makertoward different options, whether in something sotrivial as choosing a movie or so important asa fight-or-flight response.
These constraint-drivendecisions can be modeled with a log-linear system.In these models, a set of constraints is weightedand their violations are used to determine a prob-ability distribution over outcomes.
But where dothese constraints come from?We consider this question by examining thedominant framework in modern phonology, Opti-mality Theory (Prince and Smolensky, 1993, OT),implemented in a log-linear framework, MaxEntOT (Goldwater and Johnson, 2003), with outputforms?
probabilities based on a weighted sum ofconstraint violations.
OT analyses generally as-sume that the constraints are innate and univer-sal, both to obviate the problem of learning con-straints?
identities and to limit the set of possiblelanguages.We propose a new approach: to learn con-straints with limited innate phonological knowl-edge by identifying sets of constraint violationsthat explain the observed distributional data, in-stead of selecting constraints from an innate setof constraint definitions.
Because the constraintsare identified as sets of violations, this also per-mits constraints specific to a given language tobe learned.
This method, which we call IBPOT,uses an Indian Buffet Process (IBP) prior to definethe space of possible constraint violation matri-ces, and uses Bayesian reasoning to identify con-straint matrices likely to have generated the ob-served data.
In identifying constraints solely bytheir extensional violation profiles, this methoddoes not directly identify the intensional defini-tions of the identified constraints, but to the extentthat the resulting violation profiles are phonologi-cally interpretable, we may conclude that the datathemselves guide constraint identification.
We testIBPOT on tongue-root vowel harmony in Wolof, aWest African language.The set of constraints learned by the model sat-isfy two major goals: they explain the data as wellas the standard phonological analysis, and their vi-olation structures correspond to the standard con-straints.
This suggests an alternative data-drivengenesis for constraints, rather than the traditionalassumption of fully innate constraints.2 Phonology and Optimality Theory2.1 OT structureOptimality Theory has been used for constraint-based analysis of many areas of language, but wefocus on its most successful application: phonol-ogy.
We consider an OT analysis of the mappings1094between underlying forms and their phonologicalmanifestations ?
i.e., mappings between forms inthe mental lexicon and the actual vocalized formsof the words.1Stated generally, an OT system takes some in-put, generates a set of candidate outputs, deter-mines what constraints each output violates, andthen selects a candidate output with a relativelyunobjectionable violation profile.
To do this, anOT system contains four major components: agenerator GEN, which generates candidate out-put forms for the input; a set of constraints CON,which penalize candidates; a evaluation methodEVAL, which selects an winning candidate; andH , a language-particular weighting of constraintsthat EVAL uses to determine the winning candi-date.
Previous OT work has focused on identifyingthe appropriate formulation of EVAL and the val-ues and acquisition of H , while taking GEN andCON as given.
Here, we expand the learning taskby proposing an acquisition method for CON.To learn CON, we propose a data-drivenmarkedness constraint learning system that avoidsboth innateness and tractability issues.
Unlike pre-vious OT learning methods, which assume knownconstraint definitions and only learn the relativestrength of these constraints, the IBPOT learnsconstraint violation profiles and weights for themsimultaneously.
The constraints are derived fromsets of violations that effectively explain the ob-served data, rather than being selected from a pre-existing set of possible constraints.2.2 OT as a weighted-constraint methodAlthough all OT systems share the same corestructure, different choices of EVAL lead to dif-ferent behaviors.
In IBPOT, we use the log-linear EVAL developed by Goldwater and John-son (2003) in their MaxEnt OT system.
MEOTextends traditional OT to account for variation(cases in which multiple candidates can be thewinner), as well as gradient/probabilistic produc-tions (Anttila, 1997) and other constraint interac-tions (e.g., cumulativity) that traditional OT can-not handle (Keller, 2000).
MEOT also is motivatedby the general MaxEnt framework, whereas mostother OT formulations are ad hoc constructionsspecific to phonology.In MEOT, each constraint Ciis associated with1Although phonology is usually framed in terms of sound,sign languages also have components that serve equivalentroles in the physical realization of signs (Stokoe, 1960).a weight wi< 0.
(Weights are always negativein OT; a constraint violation can never make acandidate more likely to win.)
For a given input-candidate pair (x, y), fi(y, x) is the number of vi-olations of constraint Ciby the pair.
As a maxi-mum entropy model, the probability of y given xis proportional to the exponential of the weightedsum of violations,?iwifi(y, x).
If Y(x) is theset of all output candidates for the input x, thenthe probability of y as the winning output is:p(y|x) =exp (?iwifi(y, x))?z?Y(x)exp (?iwifi(z, x))(1)This formulation represents a probabilisticextension of the traditional formulation ofOT (Prince and Smolensky, 1993).
Traditionally,constraints form a strict hierarchy, where a singleviolation of a high-ranked constraint is worse thanany number of violations of lower-ranked con-straints.
Traditional OT is also deterministic, withthe optimal candidate always selected.
In MEOT,the constraint weights define hierarchies of vary-ing strictness, and some probability is assigned toall candidates.
If constraints?
weights are close to-gether, multiple violations of lower-weighted con-straints can reduce a candidate?s probability belowthat of a competitor with a single high-weight vio-lation.
As the distance between weights in MEOTincreases, the probability of a suboptimal candi-date being chosen approaches zero; thus the tradi-tional formulation is a limit case of MEOT.2.3 OT in practiceFigure 1 shows tableaux, a visualization forOT, applied in Wolof (Archangeli and Pulley-blank, 1994; Boersma, 1999).
We are interestedin four Wolof constraints that combine to inducevowel harmony: *I, PARSE[rtr], HARMONY, andPARSE[atr].
The meaning of these constraints willbe discussed in Sect.
4.1; for now, we will onlyconsider their violation profiles.
Each column rep-resents a constraint, with weights decreasing left-to-right.
Each tableau looks at a single input form,noted in the top-left cell: ete, EtE, Ite, or itE.Each row is a candidate output form.
A blackcell indicates that the candidate, or input-candidatepair, violates the constraint in that column.2Awhite cell indicates no violation.
Grey stripes are2In general, a constraint can be violated multiple timesby a given candidate, but we will be using binary constraints(violated or not) in this work.
See Sect.
5.2 for further discus-sion.1095ete *?
Parse(rtr) Harmony Parse(atr) Score ?te *?
Parse(rtr) Harmony Parse(atr) Scoreete 0 ite -32?te -24 ?te -80et?
-24 it?
-56?t?
-8 ?t?
-72?t?
*?
Parse(rtr) Harmony Parse(atr) Score it?
*?
Parse(rtr) Harmony Parse(atr) Scoreete -32 ite -32?te -48 ?te -120et?
-48 it?
-16?t?
0 ?t?
-72Figure 1: Tableaux for the Wolof input forms ete, EtE, Ite, and itE.
Black indicates violation, white noviolation.
Scores are calculated for a MaxEnt OT system with constraint weights of -64, -32, -16, and -8,approximating a traditional hierarchical OT design.
Values of grey-striped cells have negligible effectson the distribution (see Sect.
4.3).overlaid on cells whose value will have a negligi-ble impact on the distribution due to the values ofhigher-ranked constraint.Constraints fall into two categories, faithful-ness and markedness, which differ in what infor-mation they use to assign violations.
Faithfulnessconstraints penalize mismatches between the in-put and output, while markedness constraints con-sider only the output.
Faithfulness violations in-clude phoneme additions or deletions between theinput and output; markedness violations includepenalizing specific phonemes in the output form,regardless of whether the phoneme is present inthe input.In MaxEnt OT, each constraint has a weight,and the candidates?
scores are the sums of theweights of violated constraints.
In the ete tableauat top left, output ete has no violations, and there-fore a score of zero.
Outputs Ete and etE vio-late both HARMONY (weight 16) and PARSE[atr](weight 8), so their scores are 24.
Output EtE vi-olates PARSE[atr], and has score 8.
Thus the log-probability of output EtE is 1/8 that of ete, and thelog-probability of disharmonious Ete and etE areeach 1/24 that of ete.
As the ratio between scoresincreases, the log-probability ratios can becomearbitrarily close to zero, approximating the deter-ministic situation of traditional OT.2.4 Learning ConstraintsChoosing a winning candidate presumes that aset of constraints CON is available, but where dothese constraints come from?
The standard as-sumption within OT is that CON is innate anduniversal.
But in the absence of direct evidenceof innate constraints, we should prefer a methodthat can derive the constraints from cognitively-general learning over one that assumes they arepre-specified.
Learning appropriate model featureshas been an important idea in the development ofconstraint-based models (Della Pietra et al, 1997).The innateness assumption can induce tractabil-ity issues as well.
The strictest formulation of in-nateness posits that virtually all constraints areshared across all languages, even when there isno evidence for the constraint in a particular lan-guage (Tesar and Smolensky, 2000).
Strict uni-versality is undermined by the extremely largeset of constraints it must weight, as well asthe possible existence of language-particular con-straints (Smith, 2004).A looser version of universality supposes thatconstraints are built compositionally from a setof constraint templates or primitives or phono-logical features (Hayes, 1999; Smith, 2004; Id-sardi, 2006; Riggle, 2009).
This version allowslanguage-particular constraints, but it comes witha computational cost, as the learner must be ableto generate and evaluate possible constraints whilelearning the language?s phonology.
Even with rel-atively simple constraint templates, such as thephonological constraint learner of Hayes and Wil-son (2008), the number of possible constraints ex-pands exponentially.
Depending on the specificformulation of the constraints, the constraint iden-tification problem may even be NP-hard (Idsardi,2006; Heinz et al, 2009).
Our approach of castingthe learning problem as one of identifying viola-tion profiles is an attempt to determine the amountthat can be learned about the active constraints in aparadigm without hypothesizing intensional con-straint definitions.
The violation profile informa-1096tion used by our model could then be used to nar-row the search space for intensional constraints,either by performing post-hoc analysis of the con-straints identified by our model or by combiningintensional constraint search into the learning pro-cess.
We discuss each of these possibilities in Sec-tion 5.2.Innateness is less of a concern for faithfulnessthan markedness constraints.
Faithfulness viola-tions are determined by the changes between aninput form and a candidate, yielding an indepen-dent motivation for a universal set of faithfulnessconstraints (McCarthy, 2008).
Some markednessconstraints can also be motivated in a universalmanner (Hayes, 1999), but many markedness con-straints lack such grounding.3As such, it is un-clear where a universal set of markedness con-straints would come from.3 The IBPOT Model3.1 StructureThe IBPOT model defines a generative process formappings between input and output forms basedon three latent variables: the constraint violationmatrices F (faithfulness) and M (markedness),and the weight vector w. The cells of the violationmatrices correspond to the number of violations ofa constraint by a given input-output mapping.
Fijkis the number of violations of faithfulness con-straint Fkby input-output pair type (xi, yj);Mjlisthe number of violations of markedness constraintM?lby output candidate yj.
Note that M is sharedacross inputs, as Mjlhas the same value for allinput-output pairs with output yj.
The weight vec-tor w provides weight for both F and M .
Proba-bilities of output forms are given by a log-linearfunction:p(yj|xi) =exp (?kwkFijk+?lwlMjl)?yz?Y(xi)exp (?kwkFizk+?lwlMzl)(2)Note that this is the same structure as Eq.
1but with faithfulness and markedness constraintslisted separately.
As discussed in Sect.
2.4, we as-sume that F is known as part of the output of GEN(Riggle, 2009).
The goal of the IBPOT model is to3McCarthy (2008, ?4.8) gives examples of ?ad hoc?
in-tersegmental constraints.
Even well-known constraint types,such as generalized alignment, can have disputed structures(Hyde, 2012).learn the markedness matrix M and weights w forboth the markedness and faithfulness constraints.As for M , we need a non-parametric prior, asthere is no inherent limit to the number of marked-ness constraints a language will use.
We use theIndian Buffet Process (Griffiths and Ghahramani,2005), which defines a proper probability distri-bution over binary feature matrices with an un-bounded number of columns.
The IBP can bethought of as representing the set of dishes thatdiners eat at an infinite buffet table.
Each diner(i.e., output form) first draws dishes (i.e., con-straint violations) with probability proportionalto the number of previous diners who drew it:p(Mjl= 1|{Mzl}z<j) = nl/j.
After choosingfrom the previously taken dishes, the diner cantry additional dishes that no previous diner hashad.
The number of new dishes that the j-th cus-tomer draws follows a Poisson(?/j) distribution.The complete specification of the model is then:M ?
IBP (?
); Y(xi) = Gen(xi)w ?
??
(1, 1); y|xi?
LogLin(M,F,w,Y(xi))3.2 InferenceTo perform inference in this model, we adopt acommon Markov chain Monte Carlo estimationprocedure for IBPs (G?or?ur et al, 2006; Navarroand Griffiths, 2007).
We alternate approximateGibbs sampling over the constraint matrix M ,using the IBP prior, with a Metropolis-Hastingsmethod to sample constraint weights w.We initialize the model with a randomly-drawnmarkedness violation matrix M and weight vectorw.
To learn, we iterate through the output formsyj; for each, we splitM?j?into ?represented?
con-straints (those that are violated by at least oneoutput form other than yj) and ?non-represented?constraints (those violated only by yj).
For eachrepresented constraintM?l, we re-sample the valuefor the cell Mjl.
All non-represented constraintsare removed, and we propose new constraints, vi-olated only by yj, to replace them.
After each it-eration throughM , we use Metropolis-Hastings toupdate the weight vector w.Represented constraint sampling We begin byresampling Mjlfor all represented constraintsM?l, conditioned on the rest of the violations(M?
(jl), F ) and the weights w. This is the sam-pling counterpart of drawing existing features inthe IBP generative process.
By Bayes?
Rule, the1097posterior probability of a violation is propor-tional to product of the likelihood p(Y |Mjl=1,M?jl, F, w) from Eq.
2 and the IBP prior prob-ability p(Mjl= 1|M?jl) = n?jl/n, where n?jlis the number of outputs other than yjthat violateconstraint M?l.Non-represented constraint sampling Aftersampling the represented constraints for yj, weconsider the addition of new constraints that areviolated only by yj.
This is the sampling coun-terpart to the Poisson draw for new features inthe IBP generative process.
Ideally, this woulddraw new constraints from the infinite feature ma-trix; however, this requires marginalizing the like-lihood over possible weights, and we lack an ap-propriate conjugate prior for doing so.
We approx-imate the infinite matrix with a truncated Bernoullidraw over unrepresented constraints (G?or?ur et al,2006).
We consider in each sample at most K?new constraints, with weights based on the auxil-iary vector w?.
This approximation retains the un-bounded feature set of the IBP, as repeated sam-pling can add more and more constraints withoutlimit.The auxiliary vector w?contains the weightsof all the constraints that have been removed inthe previous step.
If the number of constraintsremoved is less than K?, w?is filled out withdraws from the prior distribution over weights.
Wethen consider adding any subset of these new con-straints to M , each of which would be violatedonly by yj.
Let M?represent a (possibly empty)set of constraints paired with a subset of w?.
Theposterior probability of drawingM?from the trun-cated Bernoulli distribution is the product of theprior probability of M?(?K?NY+?K?
)and the like-lihood p(Y |M?, w?,M,w, F ), including the newconstraints M?.Weight sampling After sampling throughall candidates, we use Metropolis-Hastingsto estimate new weights for both con-straint matrices.
Our proposal distribution isGamma(wk2/?, ?/wk), with mean wkandmode wk?
?wk(for wk> 1).
Unlike Gibbssampling on the constraints, which occurs only onmarkedness constraints, weights are sampled forboth markedness and faithfulness features.4 Experiment4.1 Wolof vowel harmonyWe test the model by learning the markedness con-straints driving Wolof vowel harmony (Archangeliand Pulleyblank, 1994).
Vowel harmony in gen-eral refers to a phonological phenomenon whereinthe vowels of a word share certain features in theoutput form even if they do not share them in theinput.
In the case of Wolof, harmony encouragesforms that have consistent tongue root positions.The Wolof vowel system has two relevant fea-tures, tongue root position and vowel height.
Thetongue root can either be advanced (ATR) or re-tracted (RTR), and the body of the tongue can be inthe high, middle, or low part of the mouth.
Thesefeatures define six vowels:high mid lowATR i e @RTR I E aWe test IBPOT on the harmony system providedin the Praat program (Boersma, 1999), previ-ously used as a test case by Goldwater and John-son (2003) for MEOT learning with known con-straints.
This system has four constraints:4?
Markedness:?
*I: do not have I (high RTR vowel)?
HARMONY: do not have RTR and ATRvowels in the same word?
Faithfulness:?
PARSE[rtr]: do not change RTR input toATR output?
PARSE[atr]: do not change ATR input toRTR outputThese constraints define the phonological stan-dard that we will compare IBPOT to, with a rank-ing from strongest to weakest of *I>> PARSE[rtr]>> HARMONY >> PARSE[atr].
Under this rank-ing, Wolof harmony is achieved by changing adisharmonious ATR to an RTR, unless this cre-ates an I vowel.
We see this in Figure 1, wherethree of the four winners are harmonic, but withinput itE, harmony would require violating oneof the two higher-ranked constraints.
As in previ-ous MEOT work, all Wolof candidates are faithful4The version in Praat includes a fifth constraint, but itsvalue never affects the choice of output in our data and isomitted in this analysis.1098with respect to vowel height, either because heightchanges are not considered by GEN, or becauseof a high-ranked faithfulness constraint blockingheight changes.5The Wolof constraints provide an interestingtesting ground for the model, because it is a smallset of constraints to be learned, but contains theHARMONY constraint, which can be violated bynon-adjacent segments.
Non-adjacent constraintsare difficult for string-based approaches becauseof the exponential number of possible relation-ships across non-adjacent segments.
However, theWolof results show that by learning violations di-rectly, IBPOT does not encounter problems withnon-adjacent constraints.The Wolof data has 36 input forms, each of theform V1tV2, where V1and V2are vowels that agreein height.
Each input form has four candidate out-puts, with one output always winning.
The outputsappear for multiple inputs, as shown in Figure 1.The candidate outputs are the four combinationsof tongue-roots for the given vowel heights; theinputs and candidates are known to the learner.We generate simulated data by observing 1000 in-stances of the winning output for each input.6Themodel must learn the markedness constraints *Iand HARMONY, as well as the weights for all fourconstraints.We make a small modification to the constraintsfor the test data: all constraints are limited to bi-nary values.
For constraints that can be violatedmultiple times by an output (e.g., *I twice by ItI),we use only a single violation.
This is necessary inthe current model definition because the IBP pro-duces a prior over binary matrices.
We generatethe simulated data using only single violations ofeach constraint by each output form.
Overcomingthe binarity restriction is discussed in Sect.
5.2.4.2 Experiment DesignWe run the model for 10000 iterations, using de-terministic annealing through the first 2500 it-5In the present experiment, we assume that GEN does notgenerate candidates with unfaithful vowel heights.
If unfaith-ful vowel heights were allowed by GEN, these unfaithful can-didates would incur a violation approximately as strong as *I,as neither unfaithful-height candidates nor I candidates are at-tested in the Wolof data.6Since data, matrix, and weight likelihoods all shape thelearned constraints, there must be enough data for the modelto avoid settling for a simple matrix that poorly explains thedata.
This represents a similar training set size to previouswork (Goldwater and Johnson, 2003; Boersma and Hayes,2001).erations.
The model is initialized with a ran-dom markedness matrix drawn from the IBP andweights from the exponential prior.
We ran ver-sions of the model with parameter settings be-tween 0.01 and 1 for ?, 0.05 and 0.5 for ?, and2 and 5 for K?.
All these produced quantitativelysimilar results; we report values for ?
= 1, ?
=0.5, and K?= 5, which provides the least biastoward small constraint sets.To establish performance for the phonologicalstandard, we use the IBPOT learner to find con-straint weights but do not update M .
The resultantlearner is essentially MaxEnt OT with the weightsestimated through Metropolis sampling instead ofgradient ascent.
This is done so that the IBPOTweights and phonological standard weights arelearned by the same process and can be compared.We use the same parameters for this baseline asfor the IBPOT tests.
The results in this section arebased on nine runs each of IBPOT and MEOT; tenMEOT runs were performed but one failed to con-verge and was removed from analysis.4.3 ResultsA successful set of learned constraints will satisfytwo criteria: achieving good data likelihood (noworse than the phonological-standard constraints)and acquiring constraint violation profiles that arephonologically interpretable.
We find that both ofthese criteria are met by IBPOT on Wolof.Likelihood comparison First, we calculate thejoint probability of the data and model given thepriors, p(Y,M,w|F, ?
), which is proportional tothe product of three terms: the data likelihoodp(Y |M,F,w), the markedness matrix probabil-ity p(M |?
), and the weight probability p(w).
Wepresent both the mean and MAP values for theseover the final 1000 iterations of each run.
Resultsare shown in Table 1.All eight differences are significant accordingto t-tests over the nine runs.
In all cases but meanM , the IBPOT method has a better log-probability.The most important differences are those in thedata probabilities, as the matrix and weight prob-abilities are reflective primarily of the choice ofprior.
By both measures, the IBPOT constraintsexplain the observed data better than the phono-logically standard constraints.Interestingly, the mean M probability is lowerfor IBPOT than for the phonological standard.Though the phonologically standard constraints1099MAP MeanIBPOT PS IBPOT PSData -1.52 -3.94 -5.48 -9.23M -51.7 -53.3 -54.7 -53.3w -44.2 -71.1 -50.6 -78.1Joint -97.4 -128.4 -110.6 -140.6Table 1: Data, markedness matrix, weight vec-tor, and joint log-probabilities for the IBPOT andthe phonological standard constraints.
MAP andmean estimates over the final 1000 iterations foreach run.
All IBPOT/PS differences are significant(p < .005 for MAP M ; p < .001 for others).exist independently of the IBP prior, they fit theprior better than the average IBPOT constraints do.This shows that the IBP?s prior preferences can beovercome in order to have constraints that betterexplain the data.Constraint comparison Our second criterionis the acquisition of meaningful constraints,that is, ones whose violation profiles havephonologically-grounded explanations.
IBPOTlearns the same number of markedness constraintsas the phonological standard (two); over the final1000 iterations of the model runs, 99.2% of the it-erations had two markedness constraints, and therest had three.Turning to the form of these constraints, Figure2 shows violation profiles from the last iterationof a representative IBPOT run.7Because vowelheights must be faithful between input and out-put, the Wolof data is divided into nine separateparadigms, each containing the four candidates(ATR/RTR ?
ATR/RTR) for the vowel heights inthe input.The violations on a given output form onlyaffect probabilities within its paradigm.
As aresult, learned constraints are consistent withinparadigms, but across paradigms, the same con-straint may serve different purposes.For instance, the strongest learned markednessconstraint, shown as M1 in Figure 2, has the sameviolations as the top-ranked constraint that ac-tively distinguishes between candidates in eachparadigm.
For the five paradigms with at leastone high vowel (the top row and left column),M1 has the same violations as *I, as *I penal-izes some but not all of the candidates.
In the7Specifically, from the run with the median joint posterior.other four paradigms, *I penalizes none of thecandidates, and the IBPOT learner has no rea-son to learn it.
Instead, it learns that M1 hasthe same violations as HARMONY, which is thehighest-weighted constraint that distinguishes be-tween candidates in these paradigms.
Thus in thehigh-vowel paradigms, M1 serves as *I, while inthe low/mid-vowel paradigms, it serves as HAR-MONY.The lower-weighted M2 is defined noisily, asthe higher-ranked M1 makes some values of M2inconsequential.
Consider the top-left paradigm ofFigure 2, the high-high input, in which only onecandidate does not violate M1 (*I).
Because M1has a much higher weight than M2, a violation ofM2 has a negligible effect on a candidate?s prob-ability.8In such cells, the constraint?s value is in-fluenced more by the prior than by the data.
Theseinconsequential cells are overlaid with grey stripesin Figure 2.The meaning of M2, then, depends only on theconsequential cells.
In the high-vowel paradigms,M2 matches HARMONY, and the learned and stan-dard constraints agree on all consequential viola-tions, despite being essentially at chance on the in-distinguishable violations (58%).
On the non-highparadigms, the meaning of M2 is unclear, as HAR-MONY is handled by M1 and *I is unviolated.
Inall four paradigms, the model learns that the RTR-RTR candidate violates M2 and the ATR-ATR can-didate does not; this appears to be the model?s at-tempt to reinforce a pattern in the lowest-rankedfaithfulness constraint (PARSE[atr]), which theATR-ATR candidate never violates.Thus, while the IBPOT constraints are notidentical to the phonologically standard ones,they reflect a version of the standard constraintsthat is consistent with the IBPOT framework.9In paradigms where each markedness constraintdistinguishes candidates, the learned constraintsmatch the standard constraints.
In paradigmswhere only one constraint distinguishes candi-dates, the top learned constraint matches it and thesecond learned constraint exhibits a pattern con-sistent with a low-ranked faithfulness constraint.8Given the learned weights in Fig.
2, if the losing candi-date violates M1, its probability changes from 10?12whenthe preferred candidate does not violate M2 to 10?8when itdoes.9In fact, it appears this constraint organization is favoredby IBPOT as it allows for lower weights, hence the large dif-ference in w log-probability in Table 1.1100*?
Harmony M1 M2 *?
Harmony M1 M2 *?
Harmony M1 M2iti eti ?ti?ti ?ti atiit?
et?
?t??t?
?t?
at?ite ete ?te?te ?te ateit?
et?
?t??t?
?t?
at?it?
et?
?t??t?
?t?
at?ita eta ?ta?ta ?ta ataLearnedPhono.
Std.hihihimidhiloPhono.
Std.
LearnedmidlomidmidmidhiPhono.
Std.
LearnedlohilomidloloFigure 2: Phonologically standard (*I, HARMONY) and learned (M1,M2) constraint violation profiles forthe output forms.
Learned weights for the standard constraints are -32.8 and -15.3; for M1 and M2, theyare -26.5 and -8.4.
Black indicates violation, white no violation.
Grey stripes indicate cells whose valueshave negligible effects on the probability distribution.5 Discussion and Future Work5.1 Relation to phonotactic learningOur primary finding from IBPOT is that it is possi-ble to identify constraints that are both effective atexplaining the data and representative of theorizedphonologically-grounded constraints, given onlyinput-output mappings and faithfulness violations.Furthermore, these constraints are successfully ac-quired without any knowledge of the phonologicalstructure of the data beyond the faithfulness vio-lation profiles.
The model?s ability to infer con-straint violation profiles without theoretical con-straint structure provides an alternative solution tothe problems of the traditionally innate and univer-sal OT constraint set.As it jointly learns constraints and weights,the IBPOT model calls to mind Hayes andWilson?s (2008) joint phonotactic learner.
Theirlearner also jointly learns weights and constraints,but directly selects its constraints from a composi-tional grammar of constraint definitions.
This lim-its their learner in practice by the rapid explosionin the number of constraints as the maximum con-straint definition size grows.
By directly learningviolation profiles, the IBPOT model avoids this ex-plosion, and the violation profiles can be automat-ically parsed to identify the constraint definitionsthat are consistent with the learned profile.
Theinference method of the two models is differentas well; the phonotactic learner selects constraintsgreedily, whereas the sampling on M in IBPOTasymptotically approaches the posterior.The two learners also address related but dif-ferent phonological problems.
The phonotacticlearner considers phonotactic problems, in whichonly output matters.
The constraints learned byHayes and Wilson?s learner are essentially OTmarkedness constraints, but their learner does nothave to account for varied inputs or effects of faith-fulness constraints.5.2 Extending the learning modelIBPOT, as proposed here, learns constraints basedon binary violation profiles, defined extensionally.A complete model of constraint acquisition shouldprovide intensional definitions that are phonolog-ically grounded and cover potentially non-binaryconstraints.
We discuss how to extend the modeltoward these goals.IBPOT currently learns extensional constraints,defined by which candidates do or do not violatethe constraint.
Intensional definitions are neededto extend constraints to unseen forms.
Post hoc vi-olation profile analysis, as in Sect.
4.3, providesa first step toward this goal.
Such analysis canbe integrated into the learning process using theRational Rules model (Goodman et al, 2008) toidentify likely constraint definitions composition-ally.
Alternately, phonological knowledge couldbe integrated into a joint constraint learning pro-cess in the form of a naturalness bias on the con-straint weights or a phonologically-motivated re-placement for the IBP prior.The results presented here use binary con-straints, where each candidate violates each con-straint only once, a result of the IBP?s restrictionto binary matrices.
Non-binarity can be handledby using the binary matrix M to indicate whethera candidate violates a constraint, with a second1101distribution determining the number of violations.Alternately, a binary matrix can directly capturenon-binary constraints; Frank and Satta (1998)converted existing non-binary constraints into abinary OT system by representing non-binary con-straints as a set of equally-weighted overlappingconstraints, each accounting for one violation.
Thenon-binary harmony constraint, for instance, be-comes a set {*(at least one disharmony), *(at leasttwo disharmonies), etc.
}.Lastly, the Wolof vowel harmony problem pro-vides a test case with overlaps in the candidate setsfor different inputs.
This candidate overlap helpsthe model find appropriate constraint structures.Analyzing other phenomena may require the iden-tification of appropriate abstractions to find thissame structural overlap.
English regular plurals,for instance, fall into broad categories dependingon the features of the stem-final phoneme.
IBPOTlearning in such settings may require learning anappropriate abstraction as well.6 ConclusionA central assumption of Optimality Theory hasbeen the existence of a fixed inventory of uni-versal markedness constraints innately available tothe learner, an assumption by arguments regardingthe computational complexity of constraint iden-tification.
However, our results show for the firsttime that nonparametric, data-driven learning canidentify sparse constraint inventories that both ac-curately predict the data and are phonologicallymeaningful, providing a serious alternative to thestrong nativist view of the OT constraint inventory.AcknowledgmentsWe wish to thank Eric Bakovi?c, Emily Mor-gan, Mark Mysl?
?n, the UCSD Computational Psy-cholinguistics Lab, the Phon Company, and the re-viewers for their discussions and feedback on thiswork.
This research was supported by NSF awardIIS-0830535 and an Alfred P. Sloan FoundationResearch Fellowship to RL.ReferencesArto Anttila.
1997.
Variation in Finnish phonologyand morphology.
Ph.D. thesis, Stanford U.Diana Archangeli and Douglas Pulleyblank.
1994.Grounded phonology.
MIT Press.Paul Boersma.
1999.
Empirical tests of the GradualLearning Algorithm.
Linguistic Inquiry, 32:45?86.Paul Boersma and Bruce Hayes.
2001.
Optimality-theoretic learning in the Praat program.
In Proceed-ings of the Institute of Phonetic Sciences of the Uni-versity of Amsterdam.Stephen Della Pietra, Vincent Della Pietra, and JohnLafferty.
1997.
Inducing features of random fields.IEEE Transactions on Pattern Analysis and MachineIntelligence, 19:380?393.Robert Frank and Giorgio Satta.
1998.
Optimality the-ory and the generative complexity of constraint vio-lability.
Computational Linguistics, 24:307?315.Sharon Goldwater and Mark Johnson.
2003.
LearningOT constraint rankings using a Maximum Entropymodel.
In Proceedings of the Workshop on Variationwithin Optimality Theory.Noah Goodman, Joshua Tenebaum, Jacob Feldman,and Tom Griffiths.
2008.
A rational analysis of rule-based concept learning.
Cognitive Science, 32:108?154.Dilan G?or?ur, Frank J?akel, and Carl Rasmussen.
2006.A choice model with infinitely many latent features.In Proceedings of the 23rd International Conferenceon Machine Learning.Thomas Griffiths and Zoubin Ghahramani.
2005.
Infi-nite latent feature models and the Indian buffet pro-cess.
Technical Report 2005-001, Gatsby Computa-tional Neuroscience Unit.Bruce Hayes and Colin Wilson.
2008.
A maximum en-tropy model of phonotactics and phonotactic learn-ing.
Linguistic Inquiry, 39:379?440.Bruce Hayes.
1999.
Phonetically driven phonology:the role of optimality theory and inductive ground-ing.
In Darnell et al editor, Formalism and Func-tionalism in Linguistics, vol.
1.
Benjamins.Jeffrey Heinz, Gregory Kobele, and Jason Riggle.2009.
Evaluating the complexity of Optimality The-ory.
Linguistic Inquiry.Brett Hyde.
2012.
Alignment constraints.
NaturalLanguage and Linguistic Theory, 30:789?836.William Idsardi.
2006.
A simple proof that Optimal-ity Theory is computationally intractable.
LinguisticInquiry, 37:271?275.Frank Keller.
2000.
Gradience in grammar: Ex-perimental and computational aspects of degrees ofgrammaticality.
Ph.D. thesis, U. of Edinburgh.John McCarthy.
2008.
Doing Optimality Theory.Blackwell.Daniel Navarro and Tom Griffiths.
2007.
A nonpara-metric Bayesian method for inferring features fromsimilarity judgments.
In Advances in Neural Infor-mation Processing Systems 19.1102Alan Prince and Paul Smolensky.
1993.
Optimalitytheory: Constraint interaction in generative gram-mar.
Technical report, Rutgers Center for CognitiveScience.Jason Riggle.
2009.
Generating contenders.
RutgersOptimality Archive, 1044.Jennifer Smith.
2004.
Making constraints composi-tional: toward a compositional model of Con.
Lin-gua, 114:1433?1464.William Stokoe.
1960.
Sign Language Structure.
Lin-stok Press.Bruce Tesar and Paul Smolensky.
2000.
Learnabilityin Optimality Theory.
MIT Press.1103
