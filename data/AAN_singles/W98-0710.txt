il!II!
!Aligning WordNet  with Addit ional Lexical ResourcesOi Yee KwongComputer Laboratory, University of CambridgeNew Museums Site, Cambridge CB2 3QG, U.K.oyk20@cl.cam.ac.ukAbstractThis paper explores the relationship between Word-Net and other conventional linguistically-based lex-ical resources.
We introduce an algorithm for align-ing word senses from different resources, and useit in our exper~nent to sketch the role played byWordNet, as far as sense discrimination is concerned,when put in the context of other lexical databases.The results show how and where the resources sys-tematically differ from one another with respect tothe degree of polysemy, and suggest how we can (i)overcome the inadequacy of individual resources toachieve an overall balanced degree of sense discrim-ination, and (ii) use a combination of semantic clas-sification schemes to enrich lexical information forNLP.1 IntroductionLexical resources used in natural language process-ing (NLP) have evolved from handcrafted lexicalentries to machine readable lexical databases andlarge corpora which allow statistical manipulation.The availability of electronic versions of linguisticresources was a big leap.
Among these resources wefind conventional dictionaries as well as thesauri.However, it does not often suffice to depend on anysingle resource, either because it does not containall required information or the information is notorganised in a way suitable for the purpose.
Merg-ing different resources is therefore necessary.
Cal-zolaxi's (1988) Italian lexical database, Knight andLuk's (1994) PANGLOSS ontology, and Klavans andTzoukermann's (1995) bilingual lexicon axe some re-sponses to this need.Many attempts have also been made to trans-form the implicit information in dictionary defini-tions to explicit knowledge bases for computationalpurposes (Amsler, 1981; Calzolaxi, 1984; Chodorowet al, 1985; Maxkowitz et al, 1986; Klavans etal., 1990; Vossen and Copestake, 1993).
Nonethe-less, dictionaries axe also infamous for their non-standaxdised sense granularity, and the taxonomiesobtained from definitions axe inevitably ad hoc.
Itwould therefore be a good idea if we could integrate73such information from dictionaries with some exist-ing, and widely exploited, classifications such as thesystem in Roget's Thesaurus (Roget, 1852), whichhas remained intact for years.We can see at least the following ways in whichan integration of lexical resources would be useful inNLP:?
Most NLP functions, notably word sense dis-ambiguation (WSD), need to draw informationfrom a variety of resources and cannot suffi-ciently rely on any single resource.?
When different systems of sense tagging areused in different studies, we need a commonground for comparison.
Knowing where onesense in one resource stands in another wouldenable better evaluation.?
In attempting integration, we can discover howone resource differs from another and thus iden-tify their individual imitations.
This can guideimprovement of the resources.An approach to the integration problem is offeredby WordNet.
WordNet is designed to enable con-ceptual search (Miller et al, 1993), and therefore itshould provide a way of linking word level senses asthose in dictionaries with semantic lasses as thosein thesauri.
However, one important question iswhether WordNet, a psycholinguistically-based r -source, will work the same way as conventional lin-guistic resources do.We can divide this question into two parts.
First,we axe interested in how similar the sense discrimi-nation is in WordNet and in a conventional dictio-nary.
Second, WordNet has a classificatory struc-ture, but the principle of classification is somehowdifferent from that of a thesaurus.
As a result, termswhich axe close in a thesaurus, thus allowing con-textual sense disambiguation, may be found furtherapart in the WordNet taxonomy, which may there-fore not be informative nough.
For example, "car"and "driver" axe located in two different branchesin the WordNet hierarchy and the only way to re-late them is through the top node "entity".
Thisfails to uncover the conceptual closeness of the twoIIIIlliIiIIIiIIIwords as Roget's Thesaurus does, for they are put inadjacent semantic lasses ("Land travel" and "Trav-eller" respectively).
Nevertheless, we believe thatthere must be some relation between the classes inWordNet and those in a thesaurus, which providessome means for us to make an association betweenthem.We have therefore proposed an algorithm to linkup the three kinds of resources, namely a conven-tional dictionary, WordNet and a thesaurus.
This ismade possible with the WordNet taxonomic hierar-chy as the backbone because traversing the hierarchygives many kinds of linking possibility.
The resultingintegrated information structure should then servethe following functions:* enhancing the lexical information in a dictio-nary with the taxonomic hierarchy in WordNet,and vice versa?
complementing the taxonomic hierarchy inWordNet with the semantic lassification i  athesaurus, and vice versaWe have carried out an experiment, using the al-gorithm, to map senses in a dictionary to those inWordNe t, and those in WordNet to the classes in athesaurus.
Our aim has been to (i) assess the plau-sibility of the algorithm, and to (ii) explore how thevarious resources differ from one another.
The re-sults suggest that mappings axe in general successful(i.e.
when links can be made, they are appropriate)while failures mostly arise from the inadequacy ofindividual resources.
Based on these findings, wehave also proposed some ways to overcome such in-adequacies.The algorithm is described in the next section.The test materials and the design are given in Sec-tion 3.
The results are presented in Section 4.
Theyare analysed and discussed in Section 5, where wealso suggest some ways to apply them.2 In tegrat ing  D i f fe rent  Resources2.1 Relations between ResourcesThe three lexic',d resources we used are the 1987 re-vision of Roger's Thesaurus (ROGET) (Kirkpatrick,1987), the Longman Dictionary of ContemporaryEnglish (LDOCE) (Procter, 1978) and the Prologversion of WordNet 1.5 (WN) (Miller et al, 1993).The linking of LDOCE and WN is in principle quitesimilar to Knight and Luk's (1994) approach in thePANGLOSS project.
But our form of comparisonbetween LDOCE and WN, motivated by the organ-isation of individual resources in relation to one an-other, was simpler but as effective.
Figure 1 showshow word senses are organised in the three resourcesand the arrows indicate the direction of mapping.In the middle of the figure is the structure ofWN, a hierarchy with the nodes formed from the74synsets.
If we now look up ROGET for word x2 insynset X, since words expressing every aspect of anidea are grouped together in ROGET, we can ex-pect to find not only words in synset X, but alsothose in the coordinate synsets (i.e.
M and P, withwords ml, m2, Pl, P2, etc.)
and the superordinatesynsets (i.e.
C and A, with words cl, c2, etc.)
inthe same ROGET paragraph.
In other words, thethesaurus class to which x2 belongs hould roughlyinclude X U M U P U C t3 A.
On the other hand,the LDOCE definition corresponding to the sense ofsynset X (denoted by Dz) is expected to be similarto the textual gloss of synset X (denoted by GI(X)).Nevertheless, given that it is not unusual for dic-tionary definitions to be phrased with synonyms orsuperordinate rms, we would also expect to findwords from X and C, or even A, in the LDOCEdefinition.
That means we believe D~: ~ Gl(X) andDzn(XUCUA) ~ ?.
We did not include coordinateterms (called "siblings" in Knight and Luk (1994))because we found that while nouns in WN usuallyhave many coordinate terms, the chance of hittingthem in LDOCE definitions is hardly high enoughto worth the computation effort.2.2 The A lgor i thmOur algorithm defines a mapping chain fromLDOCE to ROGET through WN.
It is based onshallow processing within the resources themselves,exploiting their inter-relatedness, and does not relyon extensive statistical data (e.g.
as suggestedin Yarowsky (1992)).
Given a word with part ofspeech, W(p), the core steps are as follows:Step 1: From LDOCE, get the sense definitionsDr, ..., Dt under the entry W(p).Step 2: From WN, find all the synsetsSn{wt,w2,...} such that W(p) E Sn.
Alsocollect the corresponding loss definitions,Gl(Sn), if any, the hypernym synsets Hyp(S,~),and the coordinate synsets Co(S,~).Step 3: Compute a similarity score matrix ,4 forthe LDOCE senses and the WN synsets.
Asimilarity score A(i, j) is computed for the i thLDOCE sense and the jta WN synset usinga weighted sum of the overlaps between theLDOCE sense and the WN synset, hypernyms,and gloss respectively, that isA(i,j) = atlDi n Sil + a:lDi n Hup(S~)I+ a31D~ n Gt(S~)IFor our tests, we just tried setting at = 3,a., = 5 and a3 -- 2 to reveal the relative signif-icance of finding a hypernym, a synonym, andany word in the textual gloss respectively in thedictionary definition.A120.
N. c l .
cZ  ... (in C);ml .
m2.... (in M): p l .
p?..
B C... (in P): x l ,  x2,... (ia X) ~ ~ (~l.c2....
I, Ol(C'3V .... i \.... E F M P X121.N .... {ml.
m2.... }, Gt(M) {pl.p?,....1.
GI{P) \[xl.
~..... }.
GI(X) /NR T(RoGEr} (WN}xl1, ... dcfiailk'm (Dx) si milia?
m GI(X)0?
de211~d in~ Of wofctS inX c~r C. ctc_2 ....J ....X3I ....2 ....(LDGCE)IIIIIIIIIIIIiIiFigure 1: Organisation of word senses in different resourcesS tep  4: From ROGET, find all paragraphsPm{wl,w2, ...} such that W(p) E P,,~.Step 5: Compute a similarity score matrix B for theWN synsets and the ROGET classes.
A simi-larity score B(j, k) is computed for the jth WNsynset (taking the synset itself, the hypernyms,and the coordinate terms) and the k th ROGETclass, according to the following:B(j,k) = bIISj N P~I + b~iHyp(Sj) N Pkl+ b31Co(Sj) n PklWe have set bl = b2 = b3 = 1.
Since a ROGETclass contains words expressing every aspect ofthe same idea, it should be equally likely to findsynonyms, hypernyms and coordinate terms incommon.Step 6: For i = 1 to t (i.e.
each LDOCE sense), findmax(.A(i,j)) from matrix ,4.
Then trace frommatrix B the jth row and find max(B(j,k)).The i th LDOCE sense should finally be mappedto the ROGET class to which Pk belongs.3 Testing.3.1 MaterialsThree groups of test words (at present we only teston nouns), each containing 12 random samples, wereprepared.
Words have five or fewer WN senses inthe "low polysemy group" (LO), between six to tenin the "medium polysemy group" (MED) , and 11or more in the "high polysemy group" (HI).
Table 1shows the list of test words with the number of sensesthey have in the various lexical resources.3.2 Design and HypothesesOur investigation was divided into three parts.While the application of the algorithm was in thethird part, the first two parts were preliminaries togather some information about the three resourcesso as to give a guide for expecting how well themapping algorithm would work and such informa-tion would also help explain the results.Par t  1: First, we just consider whether the bulk ofinformation, measured by a simple count of thenumber of senses, for each word captured by dif-ferent resources i similar in size.
Basically if itwas not, it would mean that words are treatedtoo differently in terms of sense distinction indifferent resources for the mapping to succeed.A crude way is to look for some linear relation-ship for the number of senses per word in differ-ent resources.
If WN is as linguistically valid asother lexical databases, we would expect strongpositive correlation with other resources for the"amount" of information.Par t  2: Second, we look for some quantitative char-acterisation of the relationship we find for theresources in Part 1.
We achieve this by perform-ing some paired-sample t-tests.
If the resourcesdo in fact capture similar "amount" of informa-tion, we would not expect to find any statisti-cally significant difference for the mean numberof senses per word among different resources.Par t  3: Third, we now apply the mapping algo-rithm and try to relate the results to the in-formation regarding the resources found in theprevious parts.
We map LDOCE senses to WNsynsets, and WN synsets to ROGET classes (i.e.we skip step 6 in this study).We first analyse the results by looking at map-ping accuracy and failure, and secondly bycharacterising the relationship between the twopairs of source and target (i.e.
LDOCE andWN, WN and ROGET) by means of the Poly-semy Factor P. This measure reflects the gran-ularity of the senses in the source resource (S)with respect o those in the target resource (7"),and is defined as follows:Letf : S --} 7- (human judgement )g : $ -+ 7" (a lgor i thm)T '  = (t E T : t = g(s) = f ( s )  fo r  some s E $}rs = {s ~S:g(s) =/(s)}p = IT'IIS'l75Group .h Low Polysemy Words?
'cheque plan par ty  bench indust ry  society chance copy music cur rent  letter ceremonyW 1 3 5 5 3 3 4 4 4 3 4 3L '2 5 9 5 4 6 6 4 5 4 5 3R I 5 I0 6 5 6 2 9 2 3 5 4WLRstep999numberI0i i6statement649Group 2: ~ed ium Polysemy Wordsstr ike power pmture  sense credit  note t it le cast  br idge6 9 8 7 8 9 8 9 93 16 I0 8 8 tO 4 8 75 7 6 4 8 I0 6 13 5Group 3: High Po lysemyWordsl i~ service field card hand face case air place ptece call blockW 13 14 15 II 13 13 16 13 15 II 12 IIL 20 16 12 8 12 8 17 13 21 16 15 8R 8 I0 II I0 13 7 14 7 5' I0 5 IIiiIIlIIIIIIIIITable 1: List of test words and number of sensesT' is therefore the ratio between the minimumnumber of target senses covering all mappedsource senses and all mapped source senses.
Inother words, the smaller this number, the morefine-grained are the senses in S with respect o7".
It tells us whether what is in common be-tween the source and the target is similarly dis-tingnished, and whether any excess informationin the source (as found in Part 2) is attributableto extra fineness of sense distinction.4 ResultsPar t  1: Table 2 shows the correlation matrix forthe number of senses per word in different re-sources.
The upper half of the matrix showsthe overall correlations while the lower halfshows correlations within individual groups oftest words.
(An asterisk denotes tatistical sig-nificance at the .05 level.)
Significant positivecorrelations are found in general, and also forthe LO group between WN and the other tworesources.
Such abstract relations do not nec-essarily mean simple sameness, and the exactnumerical difference is found in Part 2.LDOCEWNROGETLDOCE WN ROGET- 0 .8227* 0.4238*L: 0 .7170.M: 0.6778* - 0 .6133.H: 0.4874L: 0 .5658 L: 0 .5831.M: 0.1026 M: 0 .2605 -H: -0.2424 H: 0.1451Table 2: Correlation of number of senses per wordamong various resourcesPar t  2: The means for the number of senses perword in the three resources are shown in Ta-ble 3.
LDOCE has an average of 1.33 sensesmore than WN for the LO Group, and thisdifference is statistically significant (t = 3.75,p < .05).
Also, a significant difference is foundin the HI group between WN and ROGET,  withthe latter having 3.83 senses fewer on average(t = -4.24, p < .05).LDOCE WN ROGETLO 4.83 3.50 4.83MED 8.17 8.17 7.33HI 13.83 13.08 9125Table 3: Mean'number of senses per wordPar t  3: Apart from recording the accuracy, we alsoanalysed the various types of possible map-ping errors.
They are summarised in Table 4.Incorrectly Mapped and Unmapped-a are both"misses", whereas Forced Error and Unmapped-b are both "false alarms".
These errors are man-ifested either in a wrong match or no match atall.
The performance of the algorithm on thethree groups of nouns is shown in Table 5.Target  Ex is ts  Mapp ing  OutcomeWrong Match  No MatchYes Incorrectly Mapped Unmapped-aNo Forced Error Unmapped-bTable 4: Different types of errorsStatistics from one-way ANOVA show that forthe mapping between LDOCE and WN, thereare significantly more Forced Errors in the HIgroup than both the LO and MED group (F  =7.58, p < .05).For the mapping between WN and ROGET,  theMED group has significantly more IncorrectlyMapped than the LO group (F  = 3.72, p < .05).Also, there are significantly more Forced Errorsin the HI group than the LO and MED group(F - -  8.15, p < .05).76Ii11IIIAccurately MappedIncorrectly MappedUnm app ed- aUnmapped-bForced ErrorLDOCE -+ WNLO64.77%15.37%"2.08%11.25%6.53!~0.79MED HI65.63% 52.96%11.82% 15.17%3.13% 2.57%11.48% 8.46%7.95% 20.83%0.88 0.91WN --r ROGETLO78.89%0.00%2.08%17.36%i.67%0.80"MED HI69.63% 69.79%6.94% 3.64%"1.39% 2.55%14.03% 7.47%8.01% 16.56%0.66 0.59Table 5: Average mapping resultsAs far as the Polysemy Factor is concerned, it isfound to be significantly lower in the HI groupthan the LO group (F = 3.63, p < .05) for themapping between WN and ROGET.5 DiscussionThough the actual figures in Table 5 may not besignificant in themselves given the small s~unple sizein the test, they nevertheless indicate some underly-ing relationships among the resources, and suggestit will be worth pursuing larger scale tests.5.1 Resource Similar it ies and DifferencesResults from the first two parts of the inwestigationgive us a rough idea of the similarity and differenceamong the resources.
Comparing the overall corre-lation between WN and LDOCE with respect o thenumber of senses per word with that between WNand ROGET, the much higher positive correlationfound for the former suggests that WN, though or-ganised like a thesaurus, its content is like that in adictionary.While the correlation results give us an idea of howstrong the linear relationship is, the t-test resultssuggest o us that a conventional dictionary seemsto capture relatively more meanings than WN whena word has fewer than five WN senses.
On the otherhand, a similar relation was found between WN andROGET for words which have more than 10 WNsenses.
However, this could mean two things: eitherthat WN does contain more information than a the-saurus, or that the WN senses are getting relativelymore fine-grained.In the experiment we divided the test nouns intothree groups of different degree of polyserny.
How-ever, a rough count from WordNet 1.5 reveals thatout of the 88200 nouns, only 0.07% belongs to theHI group, with an average of 13.18 senses; whereas0.55% belongs to the MED group, with an averageof 7.05 senses.
Up to 99.37% of the nouns comefrom the LO group, averaging 1.18 senses.
In otherwords, the idiosyncrasy found for the HI group mayhave been magnified in the test samples, and we canexpect in general a rather consistent relatiorLship be-tween WN and the other two resources.5.2 Aligning WN senses w i th  othersThe third part reveals more details of the inter-relationship among the resources.
Knight andLuk (1994) reported a trade-off between coverageand correctness.
Our results, albeit for a smaller testand with different ambiguity grouping, are compara-ble with theirs.
Thus our Accurately Mapped figurescorrespond effectively to their pct correct at theirconfidence level > 0.0.
A similar average of slightlymore than 60% accuracy was achieved.Overall, the Accurately Mapped figures supportour hypothesised structural relationship between aconventional dictionary, a thesaurus and WN, show-ing that we can use this method to align senses in oneresource with those in another.
As we expected, nostatistically significant difference was found for ac-curacy across the three groups of words.
This wouldmean that the algorithm gives similar success ratesregardless of how many meanings a word has.In addition, we have also analysed the unsuccess-ful cases into four categories as shown earlier.
It canbe seen that "false alarms" were more prevalent than"misses", showing that errors mostly arise from theinadequacy of individual resources because there areno targets rather than from failures of the mappingprocess.
Moreover, the number of "misses" can pos-sibly be reduced, for example, by a better way toidentify genus terms, or if more definition patternsare considered.Forced Error refers to cases without any satisfac-tory target, but somehow one or more other targetsscore higher than the rest.
We see that this figure issignificantly higher in the HI group than in the othertwo groups for the mappings between WN and RO-GET, showing that there are relatively more sensesin WN which can find no counterpart in ROGET.
SoWN does have something not captured by ROGET.The polysemy factor 79 can also tell us somethingregarding how fine-grained the senses are in one re-source with respect o the other.
The significantlylower 79 in the HI group implies that as more mean-ings are listed for a word, these meanings can nev-ertheless be grouped into just a few core meanings.Unless we require very detailed distinction, a cruderdiscrimination would otherwise suffice.77IIII!IIIIIIIIIIIIIIThus, the Forced Error and Polysemy Factor datashow that both "more information" (in the sense ofmore coverage of the range of uses of a word) and"more granularity" contribute to the extra; senses inWN in the HI group.
However, no precise conclusioncan be drawn because this is rather variable evenwithin one resource.Another observation was made regarding: the map-ping between WN and ROGET.
Unlike the: mappingbetween LDOCE and WN which is easy to checkby comparing the definitions, synonyms and so on,judging whether a mapping from WN to ROGETis correct is not always straightforward.
This is be-cause either the expected target and the mappedtarget are not identical but are nevertheless closeneighbours in the Roget class hierarchy, o:r becausedifferent argets would be expected epending onwhich part of the definition one's focus is on.
Forinstance, "cast" has the sense of "the actors in aplay".
Strictly speaking it should be put under "as-semblage', but we may be unwilling to say a map-ping to "drama" is wrong.
As we have said, WNand ROGET have different classificatory structures.Nevertheless, we may be able to take adw~tage ofthis difference as discussed in the next section.5.3 Making use of the f indingsClearly successful mappings are influenced by thefineness of the sense discrimination i the resources.How finely they are distinguished can be inferredfrom the similarity score matrices generated fromthe algorithm for the two pairs of mappings.
Read-ing the matrices row-wise shows how vaguely a cer-tain sense is defined, whereas reading them column-wise reveals how polysemous a word is.
The presenceof unattached senses also implies that using only onesingle resource in any NLP application is likely to beinsufficient.This is illustrated for one of the test words (note)in Figure 2.
(.
= correctly mapped, o = ,expectedtarget, x = incorrectly mapped, and * = fi~rced er-ror) Tables 6 and ?
show the corresponding WNsynsets and LDOCE senses.
It can be seen that Dtand D~_ are both about musical notes, whereas D~and Ds can both be construed as letters.Consequently, using this kind of mapping data,we may be able to overcome the inadequacy of WNin at least two ways: (i) supplementing the missingsenses to achieve an overall balanced sense discrim-ination, and (ii) superimposing the WN taxonomywith another semantic lassification scheme such asthat found in ROGET.For the first proposal, we can, for example, con-flare the mapped senses and complement them withthe detached ones, thus resulting in a more com-plete but not redundant sense discrimination.
Inthe above case, we can obtain the following new setof senses for note:78OtD203D4Ds06D?DsD9OloSI $2 S3 $4 S5 S~oeS?
$8eeoFigure 2: LDOCE to WN mapping for noteSynset WN SynsetsS, eminence, distinction, preeminence, note$2$3$4note, promissory note, note of handbill, note, government ote, bank bill, banker'sbill, bank note, banknote, Federal Reservenote, greenbacknote (tone of voice)$5 note, musical note, tone$6 note, annotation, notationS?
note, short letter, lineSs note (written record)Sg note (emotional quality)Table 6: WordNet synsets for note1.
p romissory  note2.
bank note3 .
tone  o f  vo ice4.
musical note5.
annotation6.
le t te r7.
v r i t ten  record8.
eminence9.
emotional qual i ty10.
e lementNote that 1 to 7 are the senses mapped and con-tinted, 8 and 9 are the unattached syusets in WN,and 10 is the unattached sense in LDOCE.The second proposal is based on the observationthat the classificatory structures in WN and RO-GET may be used to complement each other becauseeach of them may provide a better way to capture se-mantic information in a text at different imes.
As inour "cast" example, the WN taxonomy allows prop-erty inheritance and other logical inference from theinformation that "cast" is an assemblage, and thusis a social group; while the ROGET classificationalso captures the :'drama" setting, so that we knowit is not just any group of people, but only those in-volved in drama.
Imagine we have another situationas follows:He sang a song last night.
The notes weretoo high for a bass.The hypernym chains for the underlined nouns inWN are as follows (assuming that we have spottedthe intended senses):II!IIIIIIIIIIIIIIIISense LDOCE Definitionmusical sound, usu.
of a particular length andP ITCHDtD 2 a written sign for any of these soundsDs a quality of voiceD4 any quality ; ELEMENTDsDsa record or reminder  in writ inga remark added to a piece of writ ing and placedoutside the main  part of the writ ing (a~ at theside or bot tom of a pa~e, or at the emi)a short usu.
informal ettera formal letter between governmentsa'piece of paper moneyD7DsD9D1o PROMISSORY NOTETable 7: LDOCE definitions for notesong -- (a short musical composition ...)=> musical composition, opus, ...8> music=> a .
r t ,  fine art=> creat ion=> artifact, artefact=> object, inanimate objec~ .
.
.
.=> entityUol;e, musical noge, ~one=> musical notat ion8> notat ion ,  nota t iona l  system8> wr i t ing ,  symbol ic representat ion8> wr i t ten  co~un icat ion ,  .
.
.=> co~un icat  ion8> soc ia l  re la t ion~> re la t ion8> abst rac t ionbass ,  basso - -  (an adu l t  male s inger  .
.
.
)=> s inger ,  voca l i s t"> musician, instrumentalist, player8> performer, performing ar t i s t=> entertainer=> person, individual .
.
.
.=> l i f e  form, organism .
.
.
.=> ent i ty=> causal agent, cause, ...=> ent i tyAgain, it is important that bass should be able to in-herit the properties from person or note from writtencommunication, and so on, as WN now allows us todo.
But at the same time, it can be seen that thenouns can hardly be related to one another in theWN hierarchical structure xcept at the top node en-tity, and it is then difficult to tell what the discourseis about.
However, if we align the senses with theROGET classes, we can possibly solve the problem.Consequently, the details of how we can fle~dbly usethe two classifications together can be a future di-rection of this research.6 ConclusionIn general we cannot expect that a single resourcewill be sufficient for any NLP application.
WordNetis no exception, but we can nevertheless enhance its79utility.
The study reported here began to explorethe nature of WordNet in relation to other lexicalresources, to find out where and how it differs fromthem, and to identify possible ways to absorb ad-ditional information.
Apart from linking WordNetand LDOCE, as Knight and Luk (1994) did, we alsoexperimented with ROGET to broaden the amountand type of information.
The results suggest hat,with an algorithm like the one described, WordNetcan be fine-tuned and combined with other availableresources to better meet the various information re-quirement of many applications.ReferencesR.
Amsler.
1981.
A taxonomy for English nouns andverbs.
In Proceedings o /ACt  '81, pages 133-138.N.
Calzolari.
1984.
Detecting patterns in a lexical database.
In Proceedings of COLING-84, pages 170-173.N.
Calzolari.
1988.
The dictionary and the thesauruscan be combined.
In M.W.
Evens, editor, RelationalModels of the Lexicon: Representing Knowledge in Se-mantic Networks.
Cambridge University Press.M.S.
Chodorow, R.J. Byrd, and G.E.
Heidorn.
1985.Extracting semantic hierarchies from a large on-linedictionary.
In Proceedings of ACt '85, pages 299-304.B.
Kirkpatrick.
1987.
Roger's Thesaurus of EnglishWords and Phrases.
Penguin Books.J.
Klavans and E. Tzoukermann.
1995.
Combining cor-pus and machine-readable dictionary data for buildingbilingual exicons.
Machine Translation, 10:185-218.J.
Klavans, M. Chodorow, and N. Wacholder.
1990.From dictionary to knowledge base via taxonomy.
InProceedings o/the Sixth Conference of the Universityof Waterloo, Canada.
Centre for the New Oxford En-glish dictionary and Text Research: Electronic TextResearch.K.
Knight and S.K.
Luk.
1994.
Building a large-scaleknowledge base for machine translation.
In Proceed.ings of the Twelfth National Conference on ArtificialIntelligence ( A A A I- g,t ), Seattle, Washington.J.
Markowitz, T. Ahlswede, and M. Evens.
1986.
Se-mantically significant patterns in dictionary defini-tions.
In Proceedings of ACt '86, pages 112-119.G.A.
Miller, R. Beckwith, C. Fellbanm, D. Gross, andK.
Miller.
1993.
Introduction to WordNet: An on-line lexical database.
Five Papers on WordNet.P.
Procter.
1978.
Longman Dictionary of ContemporaryEnglish.
Longman Group Ltd.P.M.
Roget.
1852.
Roget's Thesaurus of English Wordsand Phrases.
Penguin Books.P.
Vossen and A. Copestake.
1993.
Untangling def-inition structure into knowledge representation.
InT.
Briscoe, A. Copestake, and V. de Pairs, editors; In-heritance, Defaults and the Lexicon.
Cambridge Uni-versity Press.D.
Yarowsky.
1992.
Word-sense disambiguation usingstatistical models of Roger's categories trained onlarge corpora.
In Proceedings o/COTING-92, pages454-460, Nantes, France.
