Bi-directional LR Parsing fi'om an Anchor  Wordfor Speech Recognitionltiroaki SaitoCenter for Machine TranslationCarnegie Mellon UniversityPittsburgh, PA 15213, USANet Address: saito+@cs.cmu.eduAbstractThis paper introduces a new technique of parsingsentences from an arbitrary word which is highly reliable orsemantically important.
This technique adopts an efficientLR parsing method and uses a reverse LR table constructedbesides a standard LR table.
This technique is particularlysuitable in parsing a lattice of words hypothesized by aspeech recognition module.
If we choose anchor symbolsin mlch a way that they art almost always acousticallyreliable, the bi-directional LR parsing performs betteragainst misrecognized words than the regular left-to-rightLR lmrser, while most of the LR efficiency is preserved.
Apilot implementation shows a 43 % reduction of the en'orrate against the left-to-right LR method in parsing thespeech input.1.
I n t roduct ionParsing a word lattice produced by a speech recognitionmodule requires much more search them conventionalsemence parsing, and thmvt'ore an extremely efficientpar:dng algorithm is needed.
A word lattice is a set ofwords hypothesized t,~y a speech recognition system froman utterance.
A typical word lattice consists of 30 - 200words for a 10 word utterance, and each word has a scoreindicating probability of its having been actually uttered.Not only are there many junk words which were neverutteced, some actually uttered words may not be present inthe lattice (missing words).A,  island growing parsing in A'IN mechanism presentedthe serious maintenance and practical problems \[10\].
Thefirst promising allempt o pmse an incomplete word latticewas made by Itayes et al \[2\], using semantic aseframes.This attempt revealed that, while the semantic aseframescan provide a reasonable degree of robustness, a veryefficient algori\[hm is required to be practical.
Good effortswere made by Poesio et al \[4\] and Giachin et al \[1\] tomake the semm~tic caseframe approach more efficient androbust.
Meanwhile, Tomita modified the generalized LRparsing algorithm (GLR)\[8\] to handle word lattices \[91\].The GLR algorithm is a very efficient, table-driven, non-deterministic ontext-free parsing algorithm, and it hasbeen applied in speech recognition projects with fl~rthermodification of the algorithm to handle missing words \[5\].It requires heavy search, however, especially when a wordis missed in the beginning part of the utterance, since theparser guesses missing words only from its left context.Thus, the strict left-to-right-heSS sometimes suffersinefficieucy, and it is desired to parse occasionallybackwards from an acoustically reliable word called ananchor word \[10\], Bidirectionality ,also plays an imporlantrole in Head-Driven parsing and a method of bi-directionalparsing was presented by Satta et al\[7\].This paper describes a technique, called bi-directio~mlGLR parsing, to Imrse a word lattice occasionallybackwards without loss of the ruble-driven efficiency.
Areverse LR table is constructed as well as a standard LRtable.
Section 2 reviews the generalized LR parsingalgorithm.
Section 3 then describes how to consU'uctreverse LR tables and how to use them in word latticeparsing.
Section 4 discusses the robustness of bi-directional GLR parsing, and finally concluding remarksare made in Section 5.2.
Background: Generalized LR ParsingThe LR parsing technique was originally developed forcompilers of programming languages arid has beenextended for Natural Language Processing \[8\].
The LRparsing analyzes the input sequence from left to right withno backtracking by looking at the parsing table constructedfrom the context-free grammar rules in advance.
Anexample grammar and its parsing table are shown in Figure2-1 and Figure 2-2 respectively.Entries "s n" in the action table (the left part of the table)indicate the action "shift one word from input buffer ontothe stack and go to state n".
Entries "r n" indicate theaction "reduce constituents on the stack using rule n".
Theentry "acc" stands for the action "accept", and blank spacesrepresent "error".
'$' in the action table is the end-of-inputsymbol.
The goto table (the right part of the table) decidesto which state the parser should go after a reduce action.The LR parsing table in Figure 2-2 is different from theregular LR tables utilized by compilers of programmingi 237languages in that there are multiple entries, called conflicts,on the row of slate 9.
While the encountered ntry has onlyone action, parsing proceeds exactly the same way as thenormal LR parsing.
In case there are multiple actions inone entry, it executes all the actions with thegraph-structured stack \[8\].
The bi-directional GLR parsingmethod begins at an arbitrary spot of the input, while theconventional GLR parsing analyzes the input sequence onlyfrom left to right.
(i) S - ->  NP  VP(2) NP - -> n(3) NP - ->  NP PP(4) VP - -> v NP(5) PP  - ->  p NPFigure 2-1: An Example Ambiguous GrammarAct ion  Tab le  Goto  Tab len v p $ NP VP PP S123456789I0s2s2s2r2 r2 r2s6 s5rlr3 r3 r3r5 r5 ,s5  r5s5 r4aCC379I0Figure 2-2: Generalized LR Parsing Table3.
Bi-directional GLR parsingIn this section we describe the bi-directional GLRparsing algorithm ,and an example of parsing a word lattice.3.1.
Reverse LR tableBi-directional GLR parsing uses a reverse LR tablebesides a standard LR table.
The reverse LR table isconstructed from the context-free gralnmar in which theorder of right-hand-side symbols is reversed in each rule.For example, the grammar in Figure 3-1 is the set ofreverse rules built from the exmnple grammar in Figure2-1.
Its parsing table (Figure 3-2), which is a reverse LRtable, is constructed from the reversed grammar in Figure3-1.
( i ) S - ->  VP NP(2) NP  - ->  n(3) NP - ->  PP NP(4) VP  - ->  NP v(5) PP - ->  NP pFigure 3-1: Reversed GrammarAct ion  Tab le  Goton v p $ NP  VPTab lePP S1 s3234 s35 s367 r48 r59i0s7 s8r2 r2 r2accr3  s8 , r3  r3s8 rl2 5 4 69 4I0 4Figure 3-2: Reverse LR Table for Right-to-left Parsing3.2.
Pars ing f rom the Anchor  Word  in BothDirectionsHere we describe the algorithm for parsing the latticestarting from an anchor symbol and exp~mding in both left,and right directions.Parsing Procedure:1.
Choose the anchor symbol A from the lattice.2.
Because A is a terminal symbol, the initialstate(s) are determined from the action table.Note that only the states in which the shiftaction(s) are performed are valid.
There aretwo kinds of starting states:?
initial states for left-to-right p,'u'singfrom the standard LR table?
initial states for right-to-left parsingfrom the reverse LR tableStart GLR parsing from the initial states inboth directions independently until the reduceaction is suspended ue to the lack of thereduce constituents.
(Since the parsing startsin the middle of the input, this could happenunless A is located on the edge of the lattice.
)The standard LR table is used when theparsing proceeds from left to right and thereverse LR table is used when the parseproceeds in the opposite direction.3.
Perform the suspended reduce action whenthe same number educe action from the otherdirection is ready.Here we show how this procedure works in parsing the238 2lattice in Figure 3-3 using the grammars and the tables inFigures 2-1, 2-2, 3-1 and 3-2.
In parsing a lattice, thejuncture verifier JUNCT(Wi, Wi ) should be prepared whichreturns TRUE if W i and Wj can abut.
15 10 15 20 25 30VW-2nn W-335 40 45\[ I I ~ TIMEnW-5PW-4Figure 3-3: Word LatliceFirst we choose the most probable word from the lattice,i.e.
W-2 (v).
The standard LR table indicates that v isexpected at lhe states 2, 3, 8, and 9.
Only the state 3 isvalid because the other states require reduce actions whichneed previous words.
Thus the parse starts from state 3.
"Itae current word v is shifted and the next state 6 isde, termined which is expecting n. Figure 3-4 shows thissituation.We consult the reverse LR table in the same way.Namely the right-to-left parse starts from the state 2 and thenext state _7 it; decided after v is shifted.
(Figure 3-5.
Statesnumbers and the expecting terminals for the left-boundparsing are written hi italic fonts with underscore bars.
)Here we perform the right-to-left parse first.
State 7 isready for the reduce action 4 by n. But the action "reduce4" can not be performed now even on the assumption thatJUNCT(W-1, W-2) returns TRUE, because the currentstack does not contain enough reduce constituents.
Thatmeans the reduce action 4 is suspended until the left-to-right parsing is ready for the.reduce action 4.Therefore we proceed with the right-bound parsing now.W.-3 (n) is expected by state 6.
On the assumption thatJUNCT(W-2, W-3) returns TRUE, n is shifted and the newstate 2 is determined from the left-to-right action table(Figure 3-6).The new state 2 is ready for the reduce action 2 (NP- ->  n) by v, p, $.
On the assumption that JUNCT(W-3,W.4) returns TRUE, this reduce action is performed.
Theleft-to-right goto table indicates that the new state is 10.
(Figure 3-7)The next word W-4 is expected by state 10.
On theassumption that JUNCT(W-3, W-4) returns TRUE, W-4 is1In practice tile juncture verifier should return file probability ofjuncture instead of just TRUE / FALSE,a v 6 In}Figure 3 - 43 v 6 \[n}Zo.LZ ZF ig .
re  3 - S3 v 6 {n},~ n 2 {vp$}Figure 3 - 63 v 6 {hi33lak2Figure 3-76 {n}N ,~.
.
_~I  o {p$}5 in}Figure 3-86 {n} V~ I o  {p $i nFigure 3-92 {vp$}3nmL26 In},~ NP lo {p$}13Figure 3.10shifted and the new state 5 is determined (Figure 3--8).The parse continues in this way (Figure 3-9 - Figure3-12).In Figure 3-12 the new state 10 is ready for the reduceaction by $ according to the left-to-right action table.
Thus3 2393~LZ6 {hi~.
, .~10 {p $} nIn}PPFigure 3-11g {vp$}B {vp$}3 6 {n},?.~ N~P Io {p$} n1 N~P g {vp$}~L_ pP 8 {vp$}i NP 10 {p $}Figure 3-123,56 In}}~ NP .10 {p$} n!
1 /' .
.i P"Figure 3-13VP9 {vp$}B {vp$}Io (p $}7 {$}the action "reduce 4" is performed.
The next state 7 is alsoready for the reduce action by $.
But this reduce action (s- ->  NP VP) is interrupted because the parsing stack doesnot have enough constituents.
At this point the suspendedright-to-left parse can be resumed because the suspendedaction "reduce 4" is done.
The new state number 5 isdetermined from the right-to-left goto table.
(Figure 3-13)The first word W-1 is expected by state _5.
On theassumption that JUNCT(W-1, W-2) returns TRUE, W-I isshifted and the new state number 3 is detemfined from thereverse LR table.
(Figure 3-14)The new state 3_ is ready for the reduce action by v, p and$.
Since W-1 is the first word in the lattice, the action"reduce 2 (Np - ->  n)" is performed.
(Figure 3-15)nI!a5{n}rl~ 10 \[P $} na {vp$}.
.
.
.
.
.
.
.
.
NP 10 {p $}vp  7 {$}Figure 3-143 vI'llNP#{n}r NP Io {p$} n\[ N P g {v p $}pp B {vp$li NP .
.
.
.
10 {p $}vp  7 {$1./Figure 3-15nNP3 v36 {n}'t~ 1 o  {p$} n{v p $}P P 8 {v p $},~ NP 10 {p $}vP 7 {$}#1 S accacc JFigure 3-16State 10 is ready for the reduce action by $.
Thus theaction "reduce 1 (S - ->  vP NP)" is performed, whichindicates that the suspended left-to-right action "reduce 1"is also done.
(Figure 3-16 shows the end of parsing.
)240 43.3.
Bi-direct ional  GLR f rom Mult iple AnchorsWe have considered the parse from one anchor word inthe previous example.
The bi-direcfional GLR can bestarted from more than one word in the following way.\[l\] Provide each word with its starting states for bothright-bound and left-bound parsing from the action tables.\[2\] Start bi-directional GLR parsing from each word inparallel.\[3\] At the reached skate s i, check if there anynontenninals already exist which s i is expecting accordingto the goto table \[along the row of state s i under the columnlabeled with the nonterminal symbol\].
(Since parsingproceeds in parallel, the nonterminal may have been createdalready.)
If JUNCT(current-word,previously-created-nonterrninal) returns TRUE, shift this nonterminal onto thecurrent word just tile same way as the standard "shillaction" for terminals.
Note that this "nonterminal shiftaction" does not prevent the reguhtr shift/reduce/acceptactions at state  Si.
23.4~ Pars ing Words  in Order  of  Probabi l i tyIn the previous section we showed that the parsing cm~start from multiple anchors.
This assures that tile parse canstart from any word in any order.
This parsing method isvery suitable :for speech recognition, because the parsingcan proceed in tile order of probability of each word in thelattice.3.5, Pars ing Incomplete LatticeIn the previous example the lattice contained everynecessary word.
If the lattice is complete, the generalizedLR parsing method suffices \[91.
It is often the case,however, that some words are missing in the output fromthe speech recognizer.
In an attempt to use the generalizedLR parsing technique for parsing an incomplete lattice\[6\] or for parsing a noisy input sequence \[5\], all possiblyviable symbols are checked.
Especially, handling missingsymbols in the e~ly slage of parsing requires a lot ofsearch.
The bi-directional GLR parsing can handle missingwords more elegantly in that only highly plat, siNe missingcandidates are explored as follows.Suppose W-4("p") is missing from the lattice in Figure3-3 3 .
In parsing the lattice in the order of probability, the2lxt practice, however, regular shift actions do not have to be Ixzffommdin many cases, because the nonterminals previously created are likely tohave a high score due to the fact that the parse starts with anchor symbols.This heuristic method can reduce search.3Such function words as prepositions and articles are likely to bemissing in speech recognition.pzu:se is suspended after W-3 is shifted.
At this moment tl~cleft-to-right parsing is expecting "p" as the following wordof W-3 and the right-to-left parsing is expecting "p" as theprevious word of W-5.
Therefore we can assuredly predict"p" is missing between W-3 and W-5.In case more th,'m one word is missed in the gap, creatingexpected ummy words tentatively from one side or bothfrom left side and from right side can solve the problem.
Atop-down speech input verifier which checks the likelihoodof dummy words should be incorporated, because searchmay grow significantly by indiscreet creation of dummywords.4.
Pars ing  No isy  Speech  InputSaito et al implemented the system which parses thenoisy speech input \[15\].
In that system the parser analyzesthe phoneme sequence from left to right as exploring thepossibilities of substituted, inserted, and missing phonemes.Consequently a much bigger search was required thanconventional text parsing.
Thus the efficient GLR parsingtechnique was adopted.
Since the parse proceeds trictlyfrom left to right pruning the low-scored partial parses, it issometimes hard to parse the speech input whose beginningpart is very noisy.
For example, the speech input"ROEAIBIGAZUZIQKISURU" (the correct phonemesequence is "OYAYUBIGAZUKIZUKISURU" whichmeans "I have a burning pain in the thumb.")
can not lvparsed correctly by the GLR parser, because of the noisyinitial part.
To apply the bi-directional parsing technique tothis problem, we need to make a word lattice from thephoneme sequence, because?
The current speech recognition device \[3\] doesnot give us the probability of each phoneme inthe sequence.. A single phoneme is too primitive to be ananchor symbol.The word lattice built from the phoneme sequence"ROEAIBIGAZUZIQKISURU" is shown in Figure 4-1.This lattice clearly shows that the correct parse"OYAYUBI GA ZUKIZUKI SURU" can be obtained.5 10 15 20 25 30 35 40 45\[ J_ \] l \[ .
L~ \[ ~ TIME"~ \[95\]SURU \[80\]GA \[70\]KUSURI \[61\]ZUKIZUKI \[56\]OYAYU81 \[54\]HIZA \[52\]Figure 4-1: Word Lattice from the Phoneme Sequence5 24 iWe tested 125 sentences (5 speakers spoke 25sentences.)
in the domain of doctor-patient conversation.111 sentences were parsed correctly by the regular GLRmethod (recognition rate: 89.6 %).
6 more sentences wereparsed correctly by the bbdirectional parsing of the wordlattice (recognition rate: 93.6 %).
The remaining 8sentences were very badly pronounced, in which contentwords are missing.
It is necessary to ask the speaker to saythe sentence again or to only speak the unclear portion.5.
Concluding RemarksWe have introduced the bi-directional GLR parsing as arobust parsing technique and how the method is applied,especially for parsing the lattice of words hypothesized bythe speech recognizer using the strong power of handlingmissing words.The prototype parser has been implemented.
Preliminaryresults show that the robusmess power is very effectiveespecially for the lattice where missing words exist in thebeginning part.6.
Saito, H. A Phoneme Lattice Parsing for ContinuousSpeech Recognition.
Tech.
Rept.
TR-I-0033, ATRInterpreting Telephony Research Laboratories, July, 1988.7.
Satta, G. and Stock, O. Head-Driven BidirectionalParsing: A Tabular Method.
1st International Workshop oaParsing Technologies, Pittsburgh, USA, August, 1989.8.
Tomita, M..
Efficient Parsing for Natural Language: AFast Algorithm for Practical Systems.
Kluwer AcademicPublishers, Boston, MA, 1985.9.
Tomita, M. An Efficient Word Lattice ParsingAlgorithm for Continuous Speech Recognition.
IEEE-IECEJ-ASJ International Conference on Acoustics, Speech,and Signal Processing (ICASSP86), Tokyo, April, 1986.10.
Woods, W. A., Bates, M., Brown, G., Bruce, B., Cook,C., Klovstad, J., Makhoul, J., Nash-Webber, B., Schwartz,R., Wolf, J., and Zue, V. Speech Understanding Systems -Final Technical Report.
Tech.
Rept.
3438, Bolt, Beranek,and Newman, Inc., Cambridge, Mass., 1976.AcknowledgementsThe author is grateful to Dr. Masaru Tomita for theuseful comments on this work.
The author also thanks themembers of the Center for Machine Translation forcomments and advice.References1.
Giachin, E. and Rullent, C. Robust parsing of severelycorrupted spoken utterances.
12th International Conferenceon Computational Linguistics (COLING88), Budapest,Hungary, August, 1988.2.
Hayes, P. J., Hauptmann, A. G., Carbonell, J. G., andTomita, M. Parsing Spoken Language: aSemanticCaseframe Approach.
COLING86, Bonn, August, 1986.3.
Hiraoka, S., Morii, S., Hoshimi, M. and Niyada, K.Compact Isolated Word Recognition System for LargeVocabulary.
IEEE-IECEJ-ASJ International Conference onAcoustics, Speech, and Signal Processing (ICASSP86),Tokyo, April, 1986.4.
Massimo Poesio and Claudio Rullent.
ModifiedCaseframe Parsing for Speech Understanding Systems.Proceedings of the Tenth International Joint Conference onArtificial Intelligence, Milan, August, 1987.5.
Saito, H. and Tomita, M. Parsing Noisy Sentences.12th International Conference on ComputationalLinguistics (COLING88), Budapest, Hungary, August,1988.242  6
