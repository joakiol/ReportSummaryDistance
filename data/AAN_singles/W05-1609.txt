Context-sensitive utterance planning for CCGGeert-Jan M. KruijffLanguage Technology LabGerman Research Center for Artificial Intelligence (DFKI GmbH)Saarbru?cken, Germany?gj@dfki.de?
?AbstractThe paper presents an approach to utterance plan-ning, which can dynamically use context informa-tion about the environment in which a dialogueis situated.
The approach is functional in nature,using systemic networks to specify its planninggrammar.
The planner takes a description of acommunicative goal as input, and produces oneor more logical forms that can express that goalin a contextually appropriate way.
Both the goaland the resulting logical forms are expressed in asingle formalism as ontologically rich, relationalstructures.
To realize the logical forms, OpenCCGis used.
The paper focuses primarily on the im-plementation, but also discusses how the planninggrammar can be based on the grammar used inOpenCCG, and trained on (parseable) data.1 IntroductionConversational robots often need to carry out a dialogue withother agents while being situated in a dynamic environment.This poses an interesting challenge: For the robot to con-verse in a natural manner with other interlocutors its commu-nication needs to be contextually appropriate, but referentialcontexts may naturally change in such a setting.
The robotthus must be actively aware of the environment, and use thisawareness when producing utterances.Here, we present an approach to utterance planning wherewe can use context information to dynamically guide deci-sions we need to make during planning.
These decisions areparadigmatic in nature, and get us from a logical form statinga communicative intention, to a logical form (or a set thereof)expressing the intention in a contextually appropriate way.We specify a planning grammar as a systemic network, inthe tradition of generation systems for systemic functionalgrammar [Mathiessen, 1983; Bateman, 1997].
We processusing an agenda/chart-based algorithm, (meaning there is no?determinicity?
assumption).
The utterance planner itselfis embedded in a distributed architecture that makes it pos-sible to access the various models of the situated environ-?This research is supported by the EU FP6 IST IP ?CognitiveSystems for Cognitive Assistants?
(CoSy), FP6-004250-IPment that the robot maintains.
This way we can dynam-ically use contextual information during the planning pro-cess.
The logical forms we operate on are all specified in asingle formalism, namely Hybrid Logic Dependency Seman-tics (HLDS), meaning we have a representational continuumbetween discourse-level and utterance-level representations[Kruijff, 2001; Baldridge and Kruijff, 2002], and can guideutterance planning through content decisions made at higherlevels.
The logical form we obtain from the utterance plannerserves as input to a separate OpenCCG realizer [White andBaldridge, 2003; White, 2004].The resulting approach is related to [Stone and Doran,1997; Cassell et al, 2000].
We adopt their idea of an utter-ance as a description, generated from a communicative goal,and also use an ?ontologically promiscuous?
formalism forrepresenting meaning [Hobbs, 1985].
We differ in that weseparate out the realizer, though minimize the need for back-tracking in the planner by allowing for multiple, alternativelogical forms to be sent to the realizer, cf.
[Foster and White,2004].
Also, to establish contextual status of an entity, we canin principle use any type of model that the robot maintains ofthe environment, as long as we have an ontology on which wecan establish a common ground in interpretation.Our approach places us squarely in the full generationcamp, but there is a continuum: Using the approach to in-cluding canned text as proposed in [Foster and White, 2004],we can freely position the actual planner between full gen-eration and pre-baked generation.
We can use the flexibilityof full generation where necessary, notably to achieve con-textual appropriateness, but if desired we can use more directmethods to specify content.
Our approach owes its perspec-tive to systemic approaches, particularly KPML [Bateman,1997].
Where we differ is in the creation of, and relation be-tween, the resources we use in the parser, the realizer, andthe utterance planner: We use one and the same grammarfor both parsing and realization (though with different algo-rithms), and we can derive the systemic network for utteranceplanning from this grammar (?4) to ensure that we have asingle formulation of the robot?s linguistic knowledge, in theform of a CCG grammar.
We also point out (?4), how we canin principle train the planner, like e.g.
[Stent et al, 2004].Overview In ?2 we briefly discuss HLDS, and the overallarchitecture in which we employ the utterance planner.
?3presents the planner, focusing on the basic structure of theplanning grammar, and context sensitivity.
?4 discusses howwe can base the planning grammar on the specification of thegrammar we employ for parsing and realization, and how wecan in principle train the planning grammar given a corpus of(analyzable) utterances.2 Background2.1 Hybrid Logic Dependency SemanticsHybrid Logic Dependency Semantics (HLDS; [Kruijff, 2001;Baldridge and Kruijff, 2002]) is an ?ontologically promiscu-ous?
[Hobbs, 1985] framework for representing the propo-sitional content (or meaning) of an expression as an onto-logically richly sorted, relational structure.
The relationalstructure connects different bits of meaning using (directed)labelled edges.
The labels on these edges indicate how themeaning of the dependent contributes to the meaning of thewhole, rooted at the head node that governs the dependent.This view on the representation of meaning can be tracedback to various theories of valency in dependency gram-mar and related work on theta-frames.
Under this view weobtain relatively flat representations.
These flat represen-tations are nowadays used in various grammar frameworks,and are closely related to the conceptual structures found inAI knowledge representations.
[Baldridge and Kruijff, 2002;White and Baldridge, 2003] show how HLDS representationscan be built compositionally with CCG using unification, andcompare HLDS to other semantic formalisms like MinimalRecursion Semantics [Copestake et al, 1997].Formally, we represent the meaning of an expression us-ing hybrid logic [Blackburn, 2000; Areces, 2000].
Being atype of modal logic, hybrid logic is ideally suited to capturerelational structures.
Furthermore, it adopts an approach tosorting that enables us to represent meaning as an ontologi-cally richly sorted structure.
This works out as follows.Hybrid logic is a modal logic, but a modal logic with atwist.
Modal logics are interpreted on models consisting ofstates and accessibility relations between these states.
How-ever, we cannot reference these states directly in the languageof a modal logic itself.
This is problematic.
Modal logic isoften used to model temporal structure, e.g.
using Prior?s Pastand Future operators.
Unfortunately, all we can express is thatsomething happened at some point in the past, or will happenat some point in the future.
We cannot specify that point in aformula, which is counter-intuitive; cf.
[Blackburn, 2000].Hybrid logic addresses this issue by introducing nominalsinto the language.
A nominal is a type of formula, which isinterpreted as a unique reference to a state in the underlyingmodel theory of the logic.
Nominals are formulas, and henceequal citizens in the language next to e.g.
propositions.
Thereare several operators that range over nominals, the most ubiq-uitous for our current purposes being the ?@?
operator: @n?means that ?at the state referred to by n, formula ?
holds?.We use the standard modal operators to model relations:@n?R?m means that there is a relation R between the nomi-nals n and m. Particularly important for our purposes is thatwe can sort the nominals further, to indicate the ontologicalsort or category of the proposition that holds at the state re-ferred to by the nominal.
For example, @{k :person}Kathy rep-Figure 1: Conceptual architectureresents the fact that Kathy is a person; note that we can thususe nominals as (neo-Davidsonian style) discourse referents.We obtain a relational structure by relating nominalsthrough modal relations, e.g.
(1).
(1) a. Kathy saw Eli.b.
@{s:observing}(see & ?Tense?past& ?Actor?
(k : person & Kathy)& ?Patient?
(e : person & Eli))Here, s is the nominal (or discourse referent) for the eventsee, which we interpret as an observational process in pasttense.
Related to the event s are two dependents: we have anActor, a person with discourse referent k, being Kathy (theone doing the seeing); and a Patient, another person but withdiscourse referent e, being Eli (the one being seen).We can flatten the representation in (1b) by rewriting it intoa conjunction of elementary predications, akin to MRS terms:(2) @{s:observing}(see)& @{s:observing}?Tense?past& @{s:observing}?Actor?
(k : person)& @{k :person}(Kathy)& @{s:observing}?Patient?
(e : person)& @{e:person}(Eli)The flattened representation in (2) illustrates thatwe have basically three types of elementary predica-tions: lexical predications ?
@{k :person}(Kathy), features?
@{s:observing}?Tense?past, and dependency relations ?@{s:observing}?Actor?
(k : person).2.2 System architectureFigure 1 describes the conceptual architecture that underliesour system.
As a cognitively motivated architecture, it speci-fies the underlying infrastructure for the communication abil-ities for an intelligent embodied agent.The distributed nature of the architecture is inspired bythe general tendency to see cognition as a network of con-current, situated processes, e.g.
[Minsky, 1986; Langley andLaird, 2002].
Distributed information processing facilitatesthe concurrent maintenance of several models of the environ-ment, possibly using different means for representation andinterpretation.
Furthermore, we can adopt a localised ap-proach to the processing and fusion of information stemmingfrom different modalities (local cross-modal fusion), guidedby passive attention mechanisms [Chum and Wolfe, 2001]and active attention mechanisms through a short-term work-ing memory with activated concepts and their associations.The architecture is layered in that we distinguish differentlevels of information processing.
The levels basically corre-spond to the reactive (or perceptual), deliberative, and meta-level processes in the cognitive architecture presented in [Slo-man, 2001].
Like cognitive robotics [Reiter, 2001] we uselogic as a representational medium at the deliberative level,but with an explicit relation to lower-level perceptual pro-cesses [Shanahan, 2000; Shanahan and Witkowski, 2001].We use context models to represent the deliberative in-terpretation of the situation relative to a particular modality,on the basis of which future states can be anticipated andplanned.
Each context model maintains a (model-specific, lo-cal) salience measure over the information in the model, to in-dicate what is currently activated.
Examples of context mod-els are the dialogue context model, capturing the dialogue his-tory which serves as the background against which new dia-logue moves are interpreted and planned, or the action contextwhich keeps track of the current status of tasks and the overallaction plan.
Figure 1 shows these context models as modal-ity specific context models.
It also includes a belief context.The belief context model captures global cross-modal fusion,achieved by fusing information across the different modal-ities at least at the level of token identification.
We estab-lish a common ground for interpretation across modalitiesby relating each layer to a set of ontologies that model cat-egories on which the events, states, and entities at that layercan be interpreted, following recent work in information fu-sion [Wache et al, 2001] and dialogue systems [Gurevych etal., 2003].
There are different levels of granularity for thecommon ground we may be able to establish, due to the po-tential for hybridity across the different local representationsused in the architecture.
On the low end of the scale we havetype identity, to type/token identity, to the high end wherewe have fully shared representations.
The granularity of thecommon ground we are able to establish determines to whatextend information can be fused.For the purposes of this paper we use the example imple-mented architecture, shown in Figure 2.
The goal of thisinstance is to enable a robot to conduct a simple dialogueabout a dynamic, visual scene.
We have implemented thedistributed infrastructure using the Open Agent Architecture[Cheyer and Martin, 2001]; the different boxes in Figure 2 areprocesses implemented as OAA agents.On the interpretation side, we have several layers of pro-cessing for a speech dimension, and for a vision dimension.We process the acoustic signal using Sphinx4 [Walker et al,2004] with a domain-specific, English language model, andthen parse the recognized string using the OpenCCG parserfor combinatory categorial grammar [Baldridge, 2002].
Theparser yields a logical form of the meaning of the string, rep-resented as an HLDS logical form.
This logical form is inter-preted further in a dialogue process, which maintains a modelof the dialogue history.
In parallel to the speech dimension,Figure 2: Example implemented architecturewe also have processes that interpret the visual scene.
Weuse a visual recognition and classification algorithm based onOpenCV 1 that produces a representation of an object in termsof its type, physical properties, and position.
We interpretthese representations on a model of the visual scene, captur-ing proximal and projective spatial relations between objects[Kelleher and Kruijff, 2005b].For production, the architecture in Figure 2 includes onlyspoken language as an output modality.
The dialogue plannerconstructs an HLDS logical form that specifies the communi-cation goal reflecting how the belief context could be updatedwith the information coming from the acoustic and visual di-mensions.
This logical form is taken by the utterance planner,which expands this logical form to a full logical form thatOpenCCG can realize as a well-formed string [White, 2004].Finally, we use FreeTTS2 for speech synthesis.3 Utterance planningFollowing the systemic tradition, we formulate a planninggrammar as a network of systems.
A system represents aparadigmatic choice, i.e.
a choice about an aspect of themeaning to be specified by the logical form we are planning.We specify the decision process involved in this choice as adecision tree or chooser, associated with the system.
In thechooser, we can pose several inquiries about the logical formand the contextual status of discourse referents, to guide thedecision process.
On the basis of the choice we make, thesystem performs one or more operations on the logical form,to expand it; we thus reflect grammatical features directly ascontent in the logical form.A system consists of an entry condition, actions associatedwith the different choices the associated chooser can make,and an output.
Both the entry condition and the output of thesystem take the shape of an HLDS logical form, and an indi-cation of the locus within that logical form.
As a result, thecombination of locus and output logical form of one systemmay be the entry condition for another system.
It is in thisway that we obtain a network of systems.1We would like to thank Somboon Hongeng from BirminghamUniversity for the implementation of this module.2http://freetts.sf.net<system id=??evidencing-modality??
region=????
metafunction=??ideational?
?><chooser id=??c-evidencing-mod?
?/><conditions><condition features=??@type:process?
?/></conditions><actions><action choice=??vision?
?><assign-type type=??observing?
?/><add-proposition propositions=??@see?
?/><add-relation mode=??Actor??
nomvar=??sp??
type=??speaker?
?/><identify-nomvar mode=??Patient??
nomvar=??obj?
?/><move-locus nomvar=??obj?
?/></action>:</actions></system>Figure 3: Example of a systemFigure 3 provides an example specification of a system,called evidencing-modality.
The point of the system is tospecify the kind of mental process the current locus in thelogical form should express to refer to the modality in whichan entity can be grounded.
The chooser associated with thissystem is c-evidencing-mod; cf.
Figure 5 and below.One of the possible answers of this chooser is vision, i.e.the visually situated context is the ?strongest?
modality inwhich we can ground the entity that is part of the commu-nicative goal.
This results in the system performing severalactions on the logical form:1. assign-type specifies the type of the locus as observing2.
add-proposition adds the proposition see to the nomi-nal of the locus3.
add-relation adds a relation of type Actor between thelocus and a nominal sp of type speaker4.
identify-nomvar identifies the nominal to which the Pa-tient relation points, and then moves the locus to thisnominal (identified by variable name obj ).3We have two more operations that a system can specify,besides the above ones.
The operation add-feature adds afeature and a value to the nominal of the current locus.
Thisoperation together with the operations assign-type, add-proposition and add-relation gives us a basic inventory forextending a logical form through substitution:?
add-feature:@{n:nomv}?=?@{n:nomv}?&@{n:nomv}?Feat?(value).?
add-proposition:@{n:nomv}?
=?
@{n:nomv}(?
& prop)?
add-relation:@{n:nomv}?
=?
@{n:nomv}?
& @{n:nomv}?Rel?n?
:nomv?.?
assign-type:@{n:nomv}?
=?
@{n:type}?3We can define for a variable whether it is to have system-localscope, or global scope.
This way, we can reference other parts of alogical form, outside the scope of the subtree that is currently in thelocus.Furthermore, we have an operation adjoin-lf.
With thisoperation we can extend the current logical form by adjoininganother logical form into it.
We can explain adjunction usingthe illustration in Figure 4.Figure 4: AdjunctionWe start with a logicalform which contains thegreyed subtree rooted by anominal n?
of type t?
(1).Next, we remove that sub-tree, leaving an argumentposition for a nominal oftype t?
in the logical formrooted by n : t, (2).
Wenow insert a new subtree,rooted by a nominal n??
of type t?, which itself also containsan argument position of type t?
into which we can slot thegreyed subtree of n?
: t?.
The adjunction operator, the abovesubstitution operators, and the identify-nomvar, give us acomplete inventory of operations for defining logical formsas directed graphs in HLDS.The main way we bring in context-sensitivity is throughthe types of inquiries we can pose in a chooser.
In the archi-tecture, the utterance planner runs as an agent with access tothe various short-term and long-term models that the robotmaintains for the environment it is situated in; cf.
Figure2.
Each of these models is equipped with attentional mech-anisms, which model current attentional prominence (short-term working memory) or salience (longer-term memories,like models of the discursive or visual context).Using the inquiries built into the utterance planner, we canquery the architecture for the contextual status of an entity,and what the strongest evidencing modality is in which wecan ground the entity.4 Based on the results of these inquiries,we can decide how to reflect the contextual status of an en-tity or an event in the logical form.
Contextual appropriate-ness can thereby take various forms, not just in terms of us-ing information structure to reflect attentional status, but also4We assume that the visual context is the strongest modality,followed by the discursive context, and then the (personal) beliefcontext.<chooser id=??c-evidencing-mod??
region=????
metafunction=??textual?
?><dectree><choicenode answer=??*TOP*?
?><inquiry id=??fetch-evid-modality??
type=??string??answerset=??
@vision @dialogue @beliefs?
?><f-mod-maxevid/></inquiry><choicenode answer=??vision?
?><result val=??vision?
?/></choicenode>:</choicenode></dectree></chooser>Figure 5: Example of a chooserby appealing to the appropriate (and maximally informative)modal context to refer.Another way we bring in context-sensitivity is through theinclusion of algorithms for generating referring expressions.One of the actions a system can perform is to call a dedicatedGRE algorithm, to plan a contextually appropriate referringexpression for an entity.
Currently, the planner has accessto an extension of the incremental Dale & Reiter GRE al-gorithm, which is able to generate a referring expression foran entity on the basis of its physical properties as well as itsspatial relations to other entities in the visually situated con-text.
The algorithm returns a full logical form for the mean-ing of the referring expressions.
This algorithm is describedin [Kelleher and Kruijff, 2005a].Example.
To illustrate the way logical forms are planned,consider the network in Figure 6.
The network provides anillustration of how we could plan simple types of groundingfeedback, for example to a statement about the visual scenelike ?The red ball is near the blue box.
?Depending on whether the robot is able to verify thestatement against its models of the dialogue history andthe visual scene, the dialogue planner generates a simplecommunicative goal providing feedback to the statement.For example, if the robot is able to resolve the referentsboth in the dialogue and the visual contexts, then the di-alogue planner will send an acknowledgment to the utter-ance planner: @{d:disc?vantagepoint}?Acknowledgment?
(p1 :process) & @{p1 :process}?Patient?
(o1 : phys ?
obj).
Here,o1 is an identifier for the red ball in the belief context, wherewe fuse the information about identifiers in the dialogue andvisual context.The utterance planner makes d the locus, and enters system(1).
Here, a chooser inquires after the dialogue move to deter-mine the polarity of the utterance.
Because we need to pro-duce an acknowledgment, the polarity is to be positive.
Theutterance planner now extends the logical form to express thepolarity through ?yes?
and a positive state: We add yes to thenominal d, and adjoin a positive state construction between dand the process p1.
We now get the following logical form:(3) @{d:disc?vantagepoint}(yes)& @{d:disc?vantagepoint}?Acknowl.?
(p1 : process)& @{s:state}(do)& @{s:state}?Scope?
(p1 : process))& @{p1 :process}?Patient?
(o1 : phys?
obj)Finally, we move the locus to the process p1, identified bythe variable px in the system.The type of p1, process, satisfies the entry condition forsystem (2).
In this system, we inquire after the strongest ev-idencing modality for the entity referenced in the commu-nicative goal.
Because the strongest modality is the visualcontext, we turn the process into a mental process of type?observing?.
Although the entity can also be grounded in thedialogue and belief contexts, it would be less appropriate tosay ?Yes I do understand ...?
or ?Yes I do believe ..?
than itwould be ?Yes I do see ...?.
The remaining actions in the sys-tem add the proposition see to p1, and add an Actor relationto the speaker:(4) @{d:disc?vantagepoint}(yes)& @{d:disc?vantagepoint}?Acknowl.?
(p1 : process)& @{s:state}(do)& @{s:state}?Scope?
(p1 : process))& @{p1 :process}(see)& @{p1 :process}?Actor?
(sp : speaker)& @{p1 :process}?Patient?
(o1 : phys?
obj)We next move the locus to Patient, i.e.
the entity to beacknowledged.
The type of the entity satisfies the entry con-dition for system (4).
There we trigger the generation of acontextually appropriate referring expression, calling a GREalgorithm with the identifier o1.
(5) @{d:disc?vantagepoint}(yes)& @{d:disc?vantagepoint}?Acknowl.?
(p1 : process)& @{s:state}(do)& @{s:state}?Scope?
(p1 : process))& @{p1 :process}(see)& @{p1 :process}?Actor?
(sp : speaker)& @{p1 :process}?Patient?
(o1 : phys ?
obj)& @{o1 :phys?obj}(ball)& @{o1 :phys?obj}?Delimitation?
(unique)&@{o1 :phys?obj}?Quantification?
(specific singular)Figure 6: Simple network for planning grounding feedback& @{o1 :phys?obj}?Property?
(c1 : color)& @{c1 :color}(red)Finally, the agenda manager moves the locus automaticallyto the nominal sp.
Applying system (3), we introduce the fullspecification of the speaker, to yield the logical form that isoutputted by the utterance planner:(6) @{d:disc?vantagepoint}(yes)& @{d:disc?vantagepoint}?Acknowl.?
(p1 : process)& @{s:state}(do)& @{s:state}?Scope?
(p1 : process))& @{p1 :process}(see)& @{p1 :process}?Actor?
(sp : speaker)& @{sp:speaker}(I)& @{sp:speaker}?Number?
(singular)& @{p1 :process}?Patient?
(o1 : phys ?
obj)& @{o1 :phys?obj}(ball)& @{o1 :phys?obj}?Delimitation?
(unique)&@{o1 :phys?obj}?Quantification?
(specific singular)& @{o1 :phys?obj}?Property?
(c1 : color)& @{c1 :color}(red)3.1 CoverageOne of the topics under investigation in the CoSy projectis how a robot can learn through language, acquiring moreknowledge of its environment through interaction with a hu-man tutor.
As such, we are currently developing grammars forthe utterance planner, so as to be able to handle clarificationdialogues, verbalization of what the robot does or does notknow, and synchronization of different modalities (sequenc-ing, concurrency) through which the robot can communicate.The example below illustrates such a dialogue.
(7) H: ?In front of you you see a desk.
?R: looks in front of it, acquires a visual recognition modelof the object it has in its field of visionR: turns to the tutorR: nods, and says ?Thank you for showing me a desk.
?R: ?Is a desk a kind of table?
?H: ?Yes, that is correct.
?4 Practical planning grammarsIn this section we describe ongoing research on constructingutterance planning grammars for practical systems.4.1 Derivation from a CCG grammarIn a dialogue system, there are usually various grammars:for speech recognition, parsing recognized strings, generat-ing strings from logical forms, an utterance planning gram-mar; and so on.
Ideally, one grammar would be enough ?and should, if we want to maintain a single source of linguis-tic knowledge across the different levels of interpretation andproduction of natural language.
The OpenCCG system al-ready facilitates the use of a single grammar for both parsingand realization.
Here, we discuss how we could derive theplanning grammar from the signature of the CCG grammar,to ensure that we can realize what we can plan.We start from two observations.
First, we can break up themeaning of an expression, down to the level of a single word,in terms of a conjunction of elementary predications; cf.
?2.1.Second, we can organize the computational CCG lexicon as acollection of (monotonic) inheritance hierarchies [Baldridge,2002].
Taken together, this means that we can describe the hi-erarchies in terms of how elementary predications are added,when descending down a hierarchy.
More precisely, becausewe can distinguish between elementary predications that addpropositions, features, or relations, we can describe the hier-archies in terms of what types of structure are being added.Hierarchies are over lexical families.
Given a lexical fam-ily f i , we can define the signature of its meaning in termsof what it (a) inherits from a super-family f j , and (b) con-tributes itself: ?
(f i) = LF f i + ?
(f j : f i v f j ).
Be-cause a contribution to logical form is essentially the speci-fication of the type of the root nominal and a conjunction ofelementary predications epi , LF f i is nom : type plus a setof conjuncts conj(f i) = {ep1 , ..., epn}.
We can separatethe conjuncts further in terms of relations, propositions, andfeatures: conj(f i) = props(f i){ep1 , .., epk} ?
rels(f i) ={epl , ..., epm} ?
feats(f i) = {epn , ..., epo}.Based on the signatures, we define the construction of sys-tems and outline their associated choosers.
Staying with afunctional perspective, we should not map lexical families di-rectly onto systems.
Systems define paradigmatic choices,whereas lexical families reflect an aggregation of several suchchoices: they reflect transitivity through their valency and theassociated structure of their categories, whereas other mean-ingful dimensions are associated with their features.We focus first on transitivity.
This is expressed by the typeof the nominal, and the elementary predications in props andrels.
Given a subtree in the inheritance hierarchy, being afamily f i and its n immediate children f j , we can definea system ?
for the transitivity region in the planning net-work as follows.
The entry condition to the system is definedby the logical form that f i yields, modulo its features i.e.entry(?)
= ?
(f i)?
feats(f i).
The chooser needs to make(n ?
1) decisions, to cover the different possibilities; we de-rive the associated actions (add-proposition, add-relation,assign-type) directly from the type for f j , props(f j ) andrels(f j ).
This procedure yields a shallow network, in whichsystems do not take into account any similarities between thechildren f j of f i .
If we want this, we need to find a com-mon structure between the children.
This is again an inheri-tance hierarchy, over contributions to logical form in terms ofprops(f j ) ?
rels(f j ).
We then define system for each nodein this hierarchy, using the above procedure.We can thus obtain the systems for the transitivity regionof the planning grammar, based on how logical forms in thelexical inheritance hierarchy are expanded by assigning morespecific types, and adding propositions and relations.
To or-ganize regions around features (and their values), we suggestto let this organization follow from the organization of fea-tures and values in the type-hierarchy, which we can specifyfor a CCG grammar [Erkan, 2003].
Given a class of features,and a lexical inheritance hierarchy, we can define systems onthe basis of how these features are set when we descend downthe hierarchy.
Given an inheritance hierarchy, we annotateeach node for a family f j with those features in feats(f j )that are in the class we consider.
The resulting structure maybe sparse, as not every family needs to add features; hence,we can flatten this structure by removing nodes that do notadd any features.
From this structure, we can create systemsin essentially the same way as we did above.
For each subtreein the structure, we create a system that has as entry condi-tion the type for the root f i plus its features in the currentclass.
The chooser needs to make decisions about the speci-fication of the features introduced or further specified by thechildren f j of f i .
For both introduction and specificationthe associated action is add-feature; if a feature is specified,the chooser can already specify a choice point based on theinquiry after the presence and (underspecified) value of thefeature.The resulting utterance planning grammar is based on anetwork in which the entry conditions ensure that the waylogical forms are expanded conforms to the way lexical fam-ilies are formulated in the grammar.
The systems are dis-tributed across different regions, modelling different dimen-sions of paradigmatic choices that the systems in these re-gions make, whereby the organization into regions is drivenby the relational structures defined through the lexical fami-lies (i.e.
transitivity) and the type hierarchies over features.Current research focuses on how we can use XSLT totransform the XSL-based specification of a CCG grammarinto the different structures from which we derive the sys-temic network.
We then use the resulting XML-based struc-tures together with the type hierarchies for the grammar as in-put to the above construction procedures.
The systems we canthus obtain still lack the decisions to be made in the choosers;we are developing a debugger/editor for the sentence plannerto help specifying these.4.2 TrainabilityRelatively recently, the issue of trainability of utterance plan-ners has arisen in the context of practical dialogue systems.Using training, we can automatically adapt and optimize thechoices of a planner to the domain in which the planner needsto be applied.
This has the potential of yielding a significantlyfaster planner; cf.
e.g.
[Stent et al, 2004].For training the planner we discuss in this paper, we are notonly interested in ensuring that we obtain a logical form thatis appropriate given the communicative goal to be expressed(or, in a more structured way, comparable to the rhetoricalstructures considered in [Stent et al, 2004]); the logical formalso needs to be appropriate given ?the?
context.This poses an interesting challenge, because it means thatwe need to train the planner on data that is rated not onlyfor its structural appropriateness, but also for contextual ap-propriateness.
By data we understand a domain-specific cor-pus of parseable expressions, annotated with context featuressuch as the salience of an entity or event across differentmodalities.
We are exploring how we can train the plannerover the logical forms underlying the syntactic analyses ofthe expressions, i.e.
training is not on the surface forms.The basic idea we consider is the following.
Given thelogical form for an expression, written as elementary predi-cations, we can reconstruct the path through the systemic net-work that gives rise to this logical form.
A path consists ofthe systems that need to be entered, and the decisions thatthe associated choosers need to make.
Training then comesdown to learning, for each system, an n-ary classifier thattakes context features and the logical form for the current lo-cus, to output the choice that the chooser should make.5 ConclusionsIn this paper we discussed the implementation of an utteranceplanner which is part of a larger communication subsystemfor a conversational robot.
One of the challenges for such arobot is to produce contextually appropriate utterances in adynamic context.
We presented an approach that can dynam-ically include information about the situated context whileplanning an utterance.
We use systemic networks to guidethe paradigmatic choices the planner needs to make, and wediscussed (briefly) how these networks could be trained, andderived from the CCG grammar that specifies the linguisticknowledge of the robot.
The planner is implemented in Java,and has a (tccg-style) debugger enabling one to trace, andinteract with, the decisions the planner makes, and to realizethe resulting logical forms using OpenCCG.References[Areces, 2000] Carlos Areces.
Logic Engineering.
The Case of De-scription and Hybrid Logics.
Phd thesis, University of Amster-dam, Amsterdam, the Netherlands, 2000.
[Baldridge and Kruijff, 2002] Jason Baldridge and Geert-Jan M.Kruijff.
Coupling CCG and hybrid logic dependency semantics.In Proceedings of ACL 2002, Philadelphia, Pennsylvania, 2002.
[Baldridge, 2002] Jason Baldridge.
Lexically Specified Deriva-tional Control in Combinatory Categorial Grammar.
PhD thesis,University of Edinburgh, 2002.
[Bateman, 1997] John A. Bateman.
Enabling technology for multi-lingual natural language generation: the KPML development en-vironment.
Journal of Natural Language Engineering, 3(1):15?55, 1997.
[Blackburn, 2000] Patrick Blackburn.
Representation, reasoning,and relational structures: a hybrid logic manifesto.
Journal ofthe Interest Group in Pure Logic, 8(3):339?365, 2000.
[Cassell et al, 2000] Justine Cassell, Matthew Stone, and Hao Yan.Coordination and context-dependence in the generation of em-bodied conversation.
In Proceedings of INLG-2000, pages pages171?178, 2000.
[Cheyer and Martin, 2001] Adam Cheyer and David Martin.
Theopen agent architecture.
Journal of Autonomous Agents andMulti-Agent Systems, 4(1):143?148, March 2001.
[Chum and Wolfe, 2001] M. Chum and J. Wolfe.
Visual attention.In E. Bruce Goldstein, editor, Blackwell Handbook of Perception,Handbooks of Experimental Psychology, chapter 9, pages 272?310.
Blackwell, 2001.
[Copestake et al, 1997] Ann Copestake, Dan Flickinger, andIvan A.
Sag.
Minimal recursion semantics.
an introduction.
Un-published Manuscript.
CSLI/Stanford University, 1997.
[Erkan, 2003] Gu?nes?
Erkan.
A type system for CCG.
Master?sthesis, Middle East Technical University, Ankara, Turkey, 2003.
[Foster and White, 2004] Mary Ellen Foster and Michael White.Techniques for text planning with XSLT.
In Proceeedings ofNLPXML-2004, Barcelona, Spain, 2004.
[Gurevych et al, 2003] Iryna Gurevych, Robert Porzel, ElenaSlinko, Norbert Pfleger, Jan Alexandersson, and Stefan Merten.Less is more: Using a single knowledge representation in dia-logue systems.
In Proceedings of the HLT-NAACL WS on TextMeaning, Edmonton, Canada, 2003.
[Hobbs, 1985] Jerry R. Hobbs.
Ontological promiscuity.
In Pro-ceedings of ACL 1985, 1985.
[Kelleher and Kruijff, 2005a] John D. Kelleher and Geert-Jan M.Kruijff.
A context-dependent algorithm for generating locativeexpressions in physically situated environments.
In Proceedingsof ENLG-05, Aberdeen, Scotland, 2005.
[Kelleher and Kruijff, 2005b] John D. Kelleher and Geert-Jan M.Kruijff.
A context-dependent model of proximity in physicallysituated environments.
In Proceedings of the ACL-SIGSEMworkshop The Linguistic Dimension of Prepositions, Colchester,England, 2005.
[Kruijff, 2001] Geert-Jan M. Kruijff.
A Categorial-Modal LogicalArchitecture of Informativity: Dependency Grammar Logic &Information Structure.
PhD thesis, Charles University, Prague,Czech Republic, 2001.
[Langley and Laird, 2002] Pat Langley and John E. Laird.
Cogni-tive architectures: Research issues and challenges.
Technical re-port, Institute for the Study of Learning and Expertise, Palo Alto,CA, 2002.
[Mathiessen, 1983] Christian M.I.M.
Mathiessen.
Systemic gram-mar in computation: the Nigel case.
In Proceedings of EACL1983, 1983.
[Minsky, 1986] Marvin L. Minsky.
The Society of Mind.
Simon andSchuster, New York, NY, 1986.
[Reiter, 2001] Raymond Reiter.
Knowledge in Action: LogicalFoundations for Specifying and Implementing Dynamical Sys-tems.
The MIT Press, Cambridge MA, 2001.
[Shanahan and Witkowski, 2001] Murray P. Shanahan and MichaelWitkowski.
High-level robot control through logic.
In IntelligentAgents VII, pages 104?121.
Springer-Verlag, Berlin, Germany,2001.
[Shanahan, 2000] Murray P. Shanahan.
Reinventing Shakey.
InJack Minker, editor, Logic-Based Artificial Intelligence, pages233?253.
Kluwer Academic Publishers, Dordrecht, the Nether-lands, 2000.
[Sloman, 2001] Aaron Sloman.
Beyond shallow models of emo-tion.
Cognitive Processing, 2(1):177?198, 2001.
[Stent et al, 2004] Amanda Stent, Rashmi Prasad, and MarilynWalker.
Trainable sentence planning for complex informationpresentation in spoken dialog systems.
In Proceedings of ACL2004, Barcelona, Spain, 2004.
[Stone and Doran, 1997] Matthew Stone and Christine Doran.
Sen-tence planning as description using tree-adjoining grammar.
InProceedings of ACL 1997, pages 198?205, 1997.
[Wache et al, 2001] H. Wache, T. Vo?gele, U. Visser, H. Stucken-schmidt, G. Schuster, H. Neumann, and S. Hu?bner.
Ontology-based integration of information - a survey of existing ap-proaches.
In Proceedings of IJCAI 2001 Workshop ?Ontologiesand Information Sharing?, Seattle WA, 2001.
[Walker et al, 2004] Willie Walker, Paul Lamere, Philip Kwok,Bhiksha Raj, Rita Singh, Evandro Gouvea, Peter Wolf, and JoeWoelfel.
Sphinx-4: A flexible open source framework for speechrecognition.
Technical report, SUN Microsystems Inc., 2004.Technical Report TR2004-0811.
[White and Baldridge, 2003] Michael White and Jason Baldridge.Adapting chart realization to CCG.
In Proceedings of ENLG-03,Budapest, Hungary, 2003.
[White, 2004] Michael White.
Efficient realizations of coordinatestructures in combinatory categorial grammar.
Research on Lan-guage and Computation, 2004.
