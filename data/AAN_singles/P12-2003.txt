Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 11?16,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Comparison of Chinese Parsers for Stanford DependenciesWanxiang Che?car@ir.hit.edu.cnValentin I. Spitkovsky?vals@stanford.eduTing Liu?tliu@ir.hit.edu.cn?School of Computer Science and TechnologyHarbin Institute of TechnologyHarbin, China, 150001?Computer Science DepartmentStanford UniversityStanford, CA, 94305AbstractStanford dependencies are widely used in nat-ural language processing as a semantically-oriented representation, commonly generatedeither by (i) converting the output of a con-stituent parser, or (ii) predicting dependenciesdirectly.
Previous comparisons of the two ap-proaches for English suggest that starting fromconstituents yields higher accuracies.
In thispaper, we re-evaluate both methods for Chi-nese, using more accurate dependency parsersthan in previous work.
Our comparison of per-formance and efficiency across seven popularopen source parsers (four constituent and threedependency) shows, by contrast, that recenthigher-order graph-based techniques can bemore accurate, though somewhat slower, thanconstituent parsers.
We demonstrate also thatn-way jackknifing is a useful technique forproducing automatic (rather than gold) part-of-speech tags to train Chinese dependencyparsers.
Finally, we analyze the relations pro-duced by both kinds of parsing and suggestwhich specific parsers to use in practice.1 IntroductionStanford dependencies (de Marneffe and Man-ning, 2008) provide a simple description of rela-tions between pairs of words in a sentence.
Thissemantically-oriented representation is intuitive andeasy to apply, requiring little linguistic expertise.Consequently, Stanford dependencies are widelyused: in biomedical text mining (Kim et al, 2009),as well as in textual entailment (Androutsopou-los and Malakasiotis, 2010), information extrac-tion (Wu and Weld, 2010; Banko et al, 2007) andsentiment analysis (Meena and Prabhakar, 2007).In addition to English, there is a Chinese ver-sion of Stanford dependencies (Chang et al, 2009),(a) A constituent parse tree.
(b) Stanford dependencies.Figure 1: A sample Chinese constituent parse tree and itscorresponding Stanford dependencies for the sentenceChina (??)
encourages (??)
private (??
)entrepreneurs (???)
to invest (??)
innational (??)
infrastructure (??)
construction (??
).which is also useful for many applications, such asChinese sentiment analysis (Wu et al, 2011; Wu etal., 2009; Zhuang et al, 2006) and relation extrac-tion (Huang et al, 2008).
Figure 1 shows a sampleconstituent parse tree and the corresponding Stan-ford dependencies for a sentence in Chinese.
Al-though there are several variants of Stanford depen-dencies for English,1 so far only a basic version (i.e,dependency tree structures) is available for Chinese.Stanford dependencies were originally obtainedfrom constituent trees, using rules (de Marneffe etal., 2006).
But as dependency parsing technolo-gies mature (Ku?bler et al, 2009), they offer increas-ingly attractive alternatives that eliminate the needfor an intermediate representation.
Cer et al (2010)reported that Stanford?s implementation (Klein andManning, 2003) underperforms other constituent1nlp.stanford.edu/software/dependencies_manual.pdf11Type Parser Version Algorithm URLConstituent Berkeley 1.1 PCFG code.google.com/p/berkeleyparserBikel 1.2 PCFG www.cis.upenn.edu/?dbikel/download.htmlCharniak Nov. 2009 PCFG www.cog.brown.edu/?mj/Software.htmStanford 2.0 Factored nlp.stanford.edu/software/lex-parser.shtmlDependency MaltParser 1.6.1 Arc-Eager maltparser.orgMate 2.0 2nd-order MST code.google.com/p/mate-toolsMSTParser 0.5 MST sourceforge.net/projects/mstparserTable 1: Basic information for the seven parsers included in our experiments.parsers, for English, on both accuracy and speed.Their thorough investigation also showed that con-stituent parsers systematically outperform parsingdirectly to Stanford dependencies.
Nevertheless, rel-ative standings could have changed in recent years:dependency parsers are now significantly more ac-curate, thanks to advances like the high-order maxi-mum spanning tree (MST) model (Koo and Collins,2010) for graph-based dependency parsing (McDon-ald and Pereira, 2006).
Therefore, we deemed it im-portant to re-evaluate the performance of constituentand dependency parsers.
But the main purpose ofour work is to apply the more sophisticated depen-dency parsing algorithms specifically to Chinese.Number of \in Train Dev Test Totalfiles 2,083 160 205 2,448sentences 46,572 2,079 2,796 51,447tokens 1,039,942 59,955 81,578 1,181,475Table 2: Statistics for Chinese TreeBank (CTB) 7.0 data.2 MethodologyWe compared seven popular open source constituentand dependency parsers, focusing on both accuracyand parsing speed.
We hope that our analysis willhelp end-users select a suitable method for parsingto Stanford dependencies in their own applications.2.1 ParsersWe considered four constituent parsers.
They are:Berkeley (Petrov et al, 2006), Bikel (2004), Char-niak (2000) and Stanford (Klein and Manning,2003) chineseFactored, which is also the defaultused by Stanford dependencies.
The three depen-dency parsers are: MaltParser (Nivre et al, 2006),Mate (Bohnet, 2010)2 and MSTParser (McDonaldand Pereira, 2006).
Table 1 has more information.2A second-order MST parser (with the speed optimization).2.2 CorpusWe used the latest Chinese TreeBank (CTB) 7.0 inall experiments.3 CTB 7.0 is larger and has moresources (e.g., web text), compared to previous ver-sions.
We split the data into train/development/testsets (see Table 2), with gold word segmentation, fol-lowing the guidelines suggested in documentation.2.3 SettingsEvery parser was run with its own default options.However, since the default classifier used by Malt-Parser is libsvm (Chang and Lin, 2011) with a poly-nomial kernel, it may be too slow for training modelson all of CTB 7.0 training data in acceptable time.Therefore, we also tested this particular parser withthe faster liblinear (Fan et al, 2008) classifier.
Allexperiments were performed on a machine with In-tel?s Xeon E5620 2.40GHz CPU and 24GB RAM.2.4 FeaturesUnlike constituent parsers, dependency models re-quire exogenous part-of-speech (POS) tags, both intraining and in inference.
We used the Stanford tag-ger (Toutanova et al, 2003) v3.1, with the MEMMmodel,4 in combination with 10-way jackknifing.5Word lemmas ?
which are generalizations ofwords ?
are another feature known to be usefulfor dependency parsing.
Here we lemmatized eachChinese word down to its last character, since ?
incontrast to English ?
a Chinese word?s suffix oftencarries that word?s core sense (Tseng et al, 2005).For example, bicycle (???
), car (??)
andtrain (??)
are all various kinds of vehicle (?
).3www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2010T074nlp.stanford.edu/software/tagger.shtml5Training sentences in each fold were tagged using a modelbased on the other nine folds; development and test sentenceswere tagged using a model based on all ten of the training folds.12Dev TestType Parser UAS LAS UAS LAS Parsing TimeConstituent Berkeley 82.0 77.0 82.9 77.8 45:56Bikel 79.4 74.1 80.0 74.3 6,861:31Charniak 77.8 71.7 78.3 72.3 128:04Stanford 76.9 71.2 77.3 71.4 330:50Dependency MaltParser (liblinear) 76.0 71.2 76.3 71.2 0:11MaltParser (libsvm) 77.3 72.7 78.0 73.1 556:51Mate (2nd-order) 82.8 78.2 83.1 78.1 87:19MSTParser (1st-order) 78.8 73.4 78.9 73.1 12:17Table 3: Performance and efficiency for all parsers on CTB data: unlabeled and labeled attachment scores (UAS/LAS)are for both development and test data sets; parsing times (minutes:seconds) are for the test data only and exclude gen-eration of basic Stanford dependencies (for constituent parsers) and part-of-speech tagging (for dependency parsers).3 ResultsTable 3 tabulates efficiency and performance for allparsers; UAS and LAS are unlabeled and labeled at-tachment scores, respectively ?
the standard crite-ria for evaluating dependencies.
They can be com-puted via a CoNLL-X shared task dependency pars-ing evaluation tool (without scoring punctuation).63.1 ChineseMate scored highest, and Berkeley was the most ac-curate of constituent parsers, slightly behind Mate,using half of the time.
MaltParser (liblinear) was byfar the most efficient but also the least performant; itscored higher with libsvm but took much more time.The 1st-order MSTParser was more accurate thanMaltParser (libsvm) ?
a result that differs from thatof Cer et al (2010) for English (see ?3.2).
The Stan-ford parser (the default for Stanford dependencies)was only slightly more accurate than MaltParser (li-blinear).
Bikel?s parser was too slow to be used inpractice; and Charniak?s parser ?
which performsbest for English ?
did not work well for Chinese.3.2 EnglishOur replication of Cer et al?s (2010, Table 1) evalua-tion revealed a bug: MSTParser normalized all num-bers to a <num> symbol, which decreased its scoresin the evaluation tool used with Stanford dependen-cies.
After fixing this glitch, MSTParser?s perfor-mance improved from 78.8 (reported) to 82.5%, thusmaking it more accurate than MaltParser (81.1%)and hence the better dependency parser for English,consistent with our results for Chinese (see Table 3).6ilk.uvt.nl/conll/software/eval.plOur finding does not contradict the main qualita-tive result of Cer et al (2010), however, since theconstituent parser of Charniak and Johnson (2005)still scores substantially higher (89.1%), for English,compared to all dependency parsers.7 In a separateexperiment (parsing web data),8 we found Mate tobe less accurate than Charniak-Johnson ?
and im-provement from jackknifing smaller ?
on English.4 AnalysisTo further compare the constituent and dependencyapproaches to generating Stanford dependencies, wefocused on Mate and Berkeley parsers ?
the bestof each type.
Overall, the difference between theiraccuracies is not statistically significant (p > 0.05).9Table 4 highlights performance (F1 scores) for themost frequent relation labels.
Mate does better onmost relations, noun compound modifiers (nn) andadjectival modifiers (amod) in particular; and theBerkeley parser is better at root and dep.10 Mateseems to excel at short-distance dependencies, pos-sibly because it uses more local features (even witha second-order model) than the Berkeley parser,whose PCFG can capture longer-distance rules.Since POS-tags are especially informative of Chi-nese dependencies (Li et al, 2011), we harmonizedtraining and test data, using 10-way jackknifing (see?2.4).
This method is more robust than training a7One (small) factor contributing to the difference betweenthe two languages is that in the Chinese setup we stop with basicStanford dependencies ?
there is no penalty for further conver-sion; another is not using discriminative reranking for Chinese.8sites.google.com/site/sancl2012/home/shared-task9For LAS, p ?
0.11; and for UAS, p ?
0.25, according towww.cis.upenn.edu/?dbikel/download/compare.pl10An unmatched (default) relation (Chang et al, 2009, ?3.1).13Relation Count Mate Berkeleynn 7,783 91.3 89.3dep 4,651 69.4 70.3nsubj 4,531 87.1 85.5advmod 4,028 94.3 93.8dobj 3,990 86.0 85.0conj 2,159 76.0 75.8prep 2,091 94.3 94.1root 2,079 81.2 82.3nummod 1,614 97.4 96.7assmod 1,593 86.3 84.1assm 1,590 88.9 87.2pobj 1,532 84.2 82.9amod 1,440 85.6 81.1rcmod 1,433 74.0 70.6cpm 1,371 84.4 83.2Table 4: Performance (F1 scores) for the fifteen most-frequent dependency relations in the CTB 7.0 develop-ment data set attained by both Mate and Berkeley parsers.parser with gold tags because it improves consis-tency, particularly for Chinese, where tagging accu-racies are lower than in English.
On developmentdata, Mate scored worse given gold tags (75.4 versus78.2%).11 Lemmatization offered additional usefulcues for overcoming data sparseness (77.8 without,versus 78.2% with lemma features).
Unsupervisedword clusters could thus also help (Koo et al, 2008).5 DiscussionOur results suggest that if accuracy is of primaryconcern, then Mate should be preferred;12 however,Berkeley parser offers a trade-off between accuracyand speed.
If neither parser satisfies the demandsof a practical application (e.g., real-time processingor bulk-parsing the web), then MaltParser (liblinear)may be the only viable option.
Fortunately, it comeswith much headroom for improving accuracy, in-cluding a tunable margin parameter C for the classi-fier, richer feature sets (Zhang and Nivre, 2011) andensemble models (Surdeanu and Manning, 2010).Stanford dependencies are not the only populardependency representation.
We also considered the11Berkeley?s performance suffered with jackknifed tags (76.5versus 77.0%), possibly because it parses and tags better jointly.12Although Mate?s performance was not significantly betterthan Berkeley?s in our setting, it has the potential to tap richerfeatures and other advantages of dependency parsers (Nivre andMcDonald, 2008) to further boost accuracy, which may be diffi-cult in the generative framework of a typical constituent parser.conversion scheme of the Penn2Malt tool,13 usedin a series of CoNLL shared tasks (Buchholz andMarsi, 2006; Nivre et al, 2007; Surdeanu et al,2008; Hajic?
et al, 2009).
However, this tool relieson function tag information from the CTB in deter-mining dependency relations.
Since these tags usu-ally cannot be produced by constituent parsers, wecould not, in turn, obtain CoNLL-style dependencytrees from their output.
This points to another advan-tage of dependency parsers: they need only the de-pendency tree corpus to train and can convenientlymake use of native (unconverted) corpora, such asthe Chinese Dependency Treebank (Liu et al, 2006).Lastly, we must note that although the Berkeleyparser is on par with Charniak?s (2000) system forEnglish (Cer et al, 2010, Table 1), its scores for Chi-nese are substantially higher.
There may be subtlebiases in Charniak?s approach (e.g., the conditioninghierarchy used in smoothing) that could turn out tobe language-specific.
The Berkeley parser appearsmore general ?
without quite as many parametersor idiosyncratic design decisions ?
as evidenced bya recent application to French (Candito et al, 2010).6 ConclusionWe compared seven popular open source parsers ?four constituent and three dependency ?
for gen-erating Stanford dependencies in Chinese.
Mate, ahigh-order MST dependency parser, with lemmati-zation and jackknifed POS-tags, appears most accu-rate; but Berkeley?s faster constituent parser, withjointly-inferred tags, is statistically no worse.
Thisoutcome is different from English, where constituentparsers systematically outperform direct methods.Though Mate scored higher overall, Berkeley?sparser was better at recovering longer-distance re-lations, suggesting that a combined approach couldperhaps work better still (Rush et al, 2010, ?4.2).AcknowledgmentsWe thank Daniel Cer, for helping us replicate the English ex-perimental setup and for suggesting that we explore jackknifingmethods, and the anonymous reviewers, for valuable comments.Supported in part by the National Natural Science Founda-tion of China (NSFC) via grant 61133012, the National ?863?Major Project grant 2011AA01A207, and the National ?863?Leading Technology Research Project grant 2012AA011102.13w3.msi.vxu.se/?nivre/research/Penn2Malt.html14Second author gratefully acknowledges the continued helpand support of his advisor, Dan Jurafsky, and of the DefenseAdvanced Research Projects Agency (DARPA) Machine Read-ing Program, under the Air Force Research Laboratory (AFRL)prime contract no.
FA8750-09-C-0181.
Any opinions, findings,and conclusions or recommendations expressed in this materialare those of the authors and do not necessarily reflect the viewsof DARPA, AFRL, or the US government.ReferencesIon Androutsopoulos and Prodromos Malakasiotis.
2010.A survey of paraphrasing and textual entailment methods.Journal of Artificial Intelligence Research, 38(1):135?187,May.Michele Banko, Michael J. Cafarella, Stephen Soderland, MattBroadhead, and Oren Etzioni.
2007.
Open information ex-traction from the web.
In Proceedings of the 20th interna-tional joint conference on Artifical intelligence, IJCAI?07,pages 2670?2676, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.Daniel M. Bikel.
2004.
A distributional analysis of a lexi-calized statistical parsing model.
In Dekang Lin and DekaiWu, editors, Proceedings of EMNLP 2004, pages 182?189,Barcelona, Spain, July.
Association for Computational Lin-guistics.Bernd Bohnet.
2010.
Top accuracy and fast dependency pars-ing is not a contradiction.
In Proceedings of the 23rd Inter-national Conference on Computational Linguistics (Coling2010), pages 89?97, Beijing, China, August.
Coling 2010Organizing Committee.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-X sharedtask on multilingual dependency parsing.
In Proceedings ofthe Tenth Conference on Computational Natural LanguageLearning (CoNLL-X), pages 149?164, New York City, June.Association for Computational Linguistics.Marie Candito, Joakim Nivre, Pascal Denis, and Enrique Hene-stroza Anguiano.
2010.
Benchmarking of statistical depen-dency parsers for French.
In Coling 2010: Posters, pages108?116, Beijing, China, August.
Coling 2010 OrganizingCommittee.Daniel Cer, Marie-Catherine de Marneffe, Daniel Jurafsky, andChristopher D. Manning.
2010.
Parsing to Stanford depen-dencies: Trade-offs between speed and accuracy.
In Pro-ceedings of the 7th International Conference on LanguageResources and Evaluation (LREC 2010).Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM: A li-brary for support vector machines.
ACM Transactions onIntelligent Systems and Technology, 2(3):27:1?27:27, May.Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christo-pher D. Manning.
2009.
Discriminative reordering withChinese grammatical relations features.
In Proceedings ofthe Third Workshop on Syntax and Structure in StatisticalTranslation, Boulder, Colorado, June.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.
In Pro-ceedings of the 43rd Annual Meeting of the Association forComputational Linguistics (ACL?05), pages 173?180, AnnArbor, Michigan, June.
Association for Computational Lin-guistics.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proceedings of the 1st North American chapterof the Association for Computational Linguistics conference,NAACL 2000, pages 132?139, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Marie-Catherine de Marneffe and Christopher D. Manning.2008.
The Stanford typed dependencies representation.
InCOLING Workshop on Cross-framework and Cross-domainParser Evaluation.Marie-Catherine de Marneffe, Bill MacCartney, and Christo-pher D. Manning.
2006.
Generating typed dependencyparses from phrase structure parses.
In Proceedings of theFifth International Conference on Language Resources andEvaluation (LREC?06).Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A libraryfor large linear classification.
Journal of Machine LearningResearch, 9:1871?1874, June.Jan Hajic?, Massimiliano Ciaramita, Richard Johansson,Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?s Ma`rquez,Adam Meyers, Joakim Nivre, Sebastian Pado?, Jan S?te?pa?nek,Pavel Stran?a?k, Mihai Surdeanu, Nianwen Xue, andYi Zhang.
2009.
The CoNLL-2009 shared task: Syntac-tic and semantic dependencies in multiple languages.
InProceedings of the Thirteenth Conference on ComputationalNatural Language Learning (CoNLL 2009): Shared Task,pages 1?18, Boulder, Colorado, June.
Association for Com-putational Linguistics.Ruihong Huang, Le Sun, and Yuanyong Feng.
2008.
Studyof kernel-based methods for Chinese relation extraction.
InProceedings of the 4th Asia information retrieval conferenceon Information retrieval technology, AIRS?08, pages 598?604, Berlin, Heidelberg.
Springer-Verlag.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, YoshinobuKano, and Jun?ichi Tsujii.
2009.
Overview of BioNLP?09shared task on event extraction.
In Proceedings of the Work-shop on Current Trends in Biomedical Natural LanguageProcessing: Shared Task, BioNLP ?09, pages 1?9, Strouds-burg, PA, USA.
Association for Computational Linguistics.Dan Klein and Christopher D. Manning.
2003.
Accurate unlex-icalized parsing.
In Proceedings of the 41st Annual Meet-ing on Association for Computational Linguistics - Volume1, ACL ?03, pages 423?430, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Terry Koo and Michael Collins.
2010.
Efficient third-order de-pendency parsers.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics, ACL?10, pages 1?11, Stroudsburg, PA, USA.
Association forComputational Linguistics.Terry Koo, Xavier Carreras, and Michael Collins.
2008.
Sim-ple semi-supervised dependency parsing.
In Proceedings ofACL-08: HLT, pages 595?603, Columbus, Ohio, June.
As-sociation for Computational Linguistics.Sandra Ku?bler, Ryan T. McDonald, and Joakim Nivre.
2009.Dependency Parsing.
Synthesis Lectures on Human Lan-guage Technologies.
Morgan & Claypool Publishers.15Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, WenliangChen, and Haizhou Li.
2011.
Joint models for Chinese POStagging and dependency parsing.
In Proceedings of the 2011Conference on Empirical Methods in Natural Language Pro-cessing, pages 1180?1191, Edinburgh, Scotland, UK., July.Association for Computational Linguistics.Ting Liu, Jinshan Ma, and Sheng Li.
2006.
Building a de-pendency treebank for improving Chinese parser.
Journal ofChinese Language and Computing, 16(4).Ryan McDonald and Fernando Pereira.
2006.
Online learningof approximate dependency parsing algorithms.
In Proceed-ings of the 11th Conference of the European Chapter of theACL (EACL 2006), pages 81?88.Arun Meena and T. V. Prabhakar.
2007.
Sentence level sen-timent analysis in the presence of conjuncts using linguisticanalysis.
In Proceedings of the 29th European conference onIR research, ECIR?07, pages 573?580, Berlin, Heidelberg.Springer-Verlag.Joakim Nivre and Ryan McDonald.
2008.
Integrating graph-based and transition-based dependency parsers.
In Proceed-ings of ACL-08: HLT, pages 950?958, Columbus, Ohio,June.
Association for Computational Linguistics.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006.
MaltParser:A data-driven parser-generator for dependency parsing.
InProceedings of the Fifth International Conference on Lan-guage Resources and Evaluation (LREC?06), pages 2216?2219.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDonald,Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007.The CoNLL 2007 shared task on dependency parsing.
InProceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915?932, Prague, Czech Republic, June.Association for Computational Linguistics.Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein.2006.
Learning accurate, compact, and interpretable tree an-notation.
In Proceedings of the 21st International Confer-ence on Computational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics, pages433?440, Sydney, Australia, July.
Association for Computa-tional Linguistics.Alexander M. Rush, David Sontag, Michael Collins, andTommi Jaakkola.
2010.
On dual decomposition and linearprogramming relaxations for natural language processing.
InProceedings of the 2010 Conference on Empirical Methodsin Natural Language Processing, pages 1?11, Cambridge,MA, October.
Association for Computational Linguistics.Mihai Surdeanu and Christopher D. Manning.
2010.
Ensemblemodels for dependency parsing: cheap and good?
In Hu-man Language Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association for Com-putational Linguistics, HLT ?10, pages 649?652, Strouds-burg, PA, USA.
Association for Computational Linguistics.Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu?
?sMa`rquez, and Joakim Nivre.
2008.
The CoNLL 2008 sharedtask on joint parsing of syntactic and semantic dependen-cies.
In CoNLL 2008: Proceedings of the Twelfth Confer-ence on Computational Natural Language Learning, pages159?177, Manchester, England, August.
Coling 2008 Orga-nizing Committee.Kristina Toutanova, Dan Klein, Christopher D. Manning, andYoram Singer.
2003.
Feature-rich part-of-speech taggingwith a cyclic dependency network.
In Proceedings of the2003 Conference of the North American Chapter of theAssociation for Computational Linguistics on Human Lan-guage Technology - Volume 1, NAACL ?03, pages 173?180,Stroudsburg, PA, USA.
Association for Computational Lin-guistics.Huihsin Tseng, Daniel Jurafsky, and Christopher Manning.2005.
Morphological features help POS tagging of un-known words across language varieties.
In Proceedings ofthe fourth SIGHAN bakeoff.Fei Wu and Daniel S. Weld.
2010.
Open information extractionusing Wikipedia.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics, ACL?10, pages 118?127, Stroudsburg, PA, USA.
Association forComputational Linguistics.Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009.Phrase dependency parsing for opinion mining.
In Proceed-ings of the 2009 Conference on Empirical Methods in Nat-ural Language Processing: Volume 3 - Volume 3, EMNLP?09, pages 1533?1541, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2011.Structural opinion mining for graph-based sentiment rep-resentation.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, EMNLP ?11,pages 1332?1341, Stroudsburg, PA, USA.
Association forComputational Linguistics.Yue Zhang and Joakim Nivre.
2011.
Transition-based depen-dency parsing with rich non-local features.
In Proceedingsof the 49th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies: shortpapers - Volume 2, HLT ?11, pages 188?193, Stroudsburg,PA, USA.
Association for Computational Linguistics.Li Zhuang, Feng Jing, and Xiao-Yan Zhu.
2006.
Movie re-view mining and summarization.
In Proceedings of the 15thACM international conference on Information and knowl-edge management, CIKM ?06, pages 43?50, New York, NY,USA.
ACM.16
