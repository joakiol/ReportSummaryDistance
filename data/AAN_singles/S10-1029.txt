Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 142?145,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics273.
Task 5.
Keyphrase Extraction Based on Core WordIdentification and Word ExpansionYou Ouyang        Wenjie Li        Renxian ZhangThe Hong Kong Polytechnic University{csyouyang,cswjli,csrzhang}@comp.polyu.edu.hkAbstractThis paper provides a description of the HongKong Polytechnic University (PolyU) Systemthat participated in the task #5 of SemEval-2,i.e., the Automatic Keyphrase Extraction fromScientific Articles task.
We followed a novelframework to develop our keyphraseextraction system, motivated by differentiatingthe roles of the words in a keyphrase.
We firstidentified the core words which are defined asthe most essential words in the article, andthen expanded the identified core words to thetarget keyphrases by a word expansionapproach.1 IntroductionThe task #5 in SemEval-2 requires extracting thekeyphrases for scientific articles.
According tothe task definition, keyphrases are the words thatcapture the main topic of the given document.Currently, keyphrase extraction is usually carriedout by a two-stage process, including candidatephrase identification and key phrase selection.The first stage is to identify the candidate phrasesthat are potential keyphrases.
Usually, it isimplemented as a process that filters out theobviously unimportant phrases.
After thecandidate identification stage, the targetkeyphrases can then be selected from thecandidates according to their importance scores,which are usually estimated by some features,such as word frequencies, phrase frequencies,POS-tags, etc..
The features can be combinedeither by heuristics or by learning models toobtain the final selection strategy.In most existing keyphrase extraction methods,the importance of a phrase is estimated by acomposite score of the features.
Differentfeatures indicate preferences to phrases withspecific characteristics.
As to the commonfeatures, the phrases that consist of important andcorrelated words are usually preferred.
Moreover,it is indeed implied in these features that thewords are uniform in the phrase, that is, theirdegrees of importance are evaluated by the samecriteria.
However, we think that this may notalways be true.
For example, in the phrase ?videoencoding/decoding?, the word ?video?
appearsfrequently in the article and thus can be easilyidentified by simple features, while the word?encoding/decoding?
is very rare and thus is veryhard to discover.
Therefore, a uniform view onthe words is not able to discover this kind ofkeyphrases.
On the other hand, we observe thatthere is usually at least one word in a keyphrasewhich is very important to the article, such as theword ?video?
in the above example.
In this paper,we call this kind of words core words.
For eachphrase, there may be one or more core words init, which serve as the core component of thephrase.
Moreover, the phrase may contain somewords that support the core words, such as?encoding/decoding?
in the above example.These words may be less important to the article,but they are highly correlated with the core wordand are able to form an integrated concept withthe core words.
Motivated by this, we consider anew keyphrase extraction framework, whichincludes two stages: identifying the core wordsand expanding the core words to keyphrases.
Themethodology of the proposed approaches and theperformance of the resulting system areintroduced below.
We also provide furtherdiscussions and modifications.2 MethodologyAccording to our motivation, our extractionframework consists of three processes, including(1) The pre-processing to obtain the necessaryinformation for the following processes;(2) The core word identification process todiscover the core words to be expanded;(3) The word expansion process to generate thefinal keyphrases.In the pre-processing, we first identify the textfields for each scientific article, including its title,abstract and main text (defined as all the sectiontitles and section contents).
The texts are thenprocessed by the language toolkit GATE 1  tocarry out sentence segmentation, word stemmingand POS (part-of-speech) tagging.
Stop-words1 Publicly available at http://gate.ac.uk/gate142are not considered to be parts of the targetkeyphrases.2.1 Core Word IdentificationCore words are the words that represent thedominant concepts in the article.
To identify thecore words, we consider the features below.Frequencies: In a science article, the words withhigher frequencies are usually more important.To differentiate the text fields, in our system weconsider three frequency-based features, i.e.,Title-Frequency (TF), Abstract-Frequency(AF) and MainText-Frequency (MF), torepresent the frequencies of one word in differenttext fields.
For a word w in an article t, thefrequencies are denoted byTF(w) = Frequency of  w in the title of t;AF(w) = Frequency of w in the abstract of t;MF(w) = Frequency of w in the main text of t.POS tag: The part-of-speech tag of a word is agood indicator of core words.
Here we adopt asimple constraint, i.e., only nouns or adjectivescan be potential core words.In our system, we use a progressive algorithmto identify all the core words.
The effects ofdifferent text fields are considered to improve theaccuracy of the identification result.
First of all,for each word w in the title, it is identified to be acore word when satisfying{ TF(w)> 0 ?
AF(w) > 0 }Since the abstract is usually less indicativethan the title, we use stricter conditions for thewords in the abstract by considering their co-occurrence with the already-identified corewords in the title.
For a word w in the abstract, aco-occurrence-based feature COT(w) is definedas |S(w)|, where S(w) is the set of sentenceswhich contain both w and at least one title coreword.
For a word w in the abstract, it is identifiedas an abstract core word when satisfying{ AF(w)> 0 ?
MF(w) > ?1 ?
COT (w) > ?2}Similarly, for a word w in the main text, it isidentified as a general core word when satisfying{ MF(w) > ?1 ?
COTA (w) >?2}where COTA (w) = |S?
(w)| and S?
(w) is the set ofsentences which contain both w and at least oneidentified title core word or abstract core word.With this progressive algorithm, new corewords can be more accurately identified with thepreviously identified core words.
In the aboveheuristics, the parameters ?
and ?
are pre-definedthresholds, which are manually assigned2.2 (?1, ?2, ?1, ?2) = (10, 5, 20, 10) in the systemAs a matter of fact, this heuristic-basedidentification approach is simple and preliminary.More sophisticated approaches, such as trainingmachine learning models to classify the words,can be applied for better performance.
Moreover,more useful features can also be considered.Nevertheless, we adopted the heuristic-basedimplementation to test the applicability of theframework as an initial study.An example of the identified core words isillustrated in Table 1 below:Type Core WordTitle grid, service, discovery, UDDIAbstract distributed, multiple, web, computing,registry, deployment, scalability, DHT,DUDE, architectureMain proxy, search, node, key, etc.Table 1: Different types of core words2.2 Core Word ExpansionGiven the identified core words, the keyphrasescan then be generated by expanding the corewords.
An example of the expansion process isillustrated below asgrid ?
grid service ?
grid service discovery ?scalable grid service discoveryFor a core word, each appearance of it can beviewed as a potential expanding point.
For eachexpanding point of the word, we need to judge ifthe context words can form a keyphrase alongwith it.
Formally, for a candidate word w and thecurrent phrase e (here we assume that w is theprevious word, the case for the next word issimilar), we consider the following features tojudge if e should be expanded to w+e.Frequencies: the frequency of w (denoted byFreq(w)) and the frequency of the combinationof w and e (denoted by phraseFreq(w, e)) whichreflects the degree of w and e forming anintegrated phrase.POS pattern: The part-of-speech tag of theword w is also considered here, i.e., we only tryto expand w to w+e when w is a noun, anadjective or the specific conjunction ?of?.A heuristic-based approach is adopted hereagain.
We intend to define some loose heuristics,which prefer long keyphrases.
The heuristicsinclude (1) If w and e are in the title or abstract,expand e to e+w when w satisfies the POSconstraint and Freq(w) > 1; (2) If w and e are inthe main text, expand e to e+w when w satisfiesthe POS constraint and phraseFreq(w, e) >1.More examples are provided in Table 2 below.143Core Word Expanded Key Phrasegrid scalable grid service discovery,grid computingUDDI UDDI registry, UDDI keyweb web service,scalability Scalability issueDHT DHT nodeTable 2: Core words and corresponding key phrases3 Results3.1 The Initial PolyU System in SemEval-2In the Semeval-2 test set, a total of 100 articlesare provided.
Systems are required to generate 15keyphrases for each article.
Also, 15 keyphrasesare generated by human readers as standardanswers.
Precision, recall and F-value are used toevaluate the performance.To generate exactly 15 keyphrases with theframework, we expand the core words in the title,abstract and main text in turn.
Moreover, the corewords in one fixed field are expanded followingthe descending order of frequency.
When 15keyphrases are obtained, the process is stopped.For each new phrase, a redundancy check isalso conducted to make sure that the final 15keyphrases can best cover the core concepts ofthe article, i.e.,(1) the new keyphrase should contain at least oneword that is not included in any of the selectedkeyphrases;(2) if a selected keyphrase is totally covered bythe new keyphrase, the covered keyphrase willbe substituted by the new keyphrase.The resulting system based on the abovemethod is the one we submitted to SemEval-2.3.2 Phrase Filtering and RankingInitially, we intend to use just the proposedframework to develop our system, i.e., using theexpanded phrases as the keyphrases.
However,we find out later that it must be adjusted to suitthe requirement of the SemEval-2 task.
In oursubsequent study, we consider two adjustments,i.e., phrase filtering and phrase ranking.In SemEval-2, the evaluation criteria requireexact match between the phrases.
A phrase thatcovers a reference keyphrase but is not equal to itwill not be counted as a successful match.
Forexample, the candidate phrase ?scalable gridservice discovery?
is not counted as a matchwhen compared to the reference keyphrase ?gridservice discovery?.
We call this the ?partialmatching problem?.
In our original framework,we followed the idea of ?expanding the phrase asmuch as possible?
and adopted loose conditions.Consequently, the partial matching problem isindeed very serious.
This unavoidably affects itsperformance under the criteria in SemEval-2 thatrequires exact matches.
Therefore, we consider asimple filtering strategy here, i.e., filtering anykeyphrase which only appears once in the article.Another issue is that the given task requires atotal of exactly 15 keyphrases.
Naturally we needa selection process to handle this.
As to ourframework, a keyphrase ranking process isnecessary for discovering the best 15 keyphrases,not the best 15 core words.
For this reason, wealso try a simple method that re-ranks theexpanded phrases by their frequencies.
The top15 phrases are then selected finally.3.3 ResultsTable 3 below shows the precision, recall and F-value of our submitted system (PolyU), the bestand worst systems submitted to SemEval-2 andthe baseline system that uses simple TF-IDFstatistics to select keyphrases.On the SemEval-2 test data, the performanceof the PolyU system was not good, just a littlebetter than the baseline.
A reason is that we justdeveloped the PolyU system with our pastexperiences but did not adjust it much for betterperformance (since we were focusing ondesigning the new framework).
After thecompetition, we examined two refined systemswith the methods introduced in section 3.2.First, the PolyU system is adapted with thephrase filtering method.
The performance of theresulting system (denoted by PolyU+) is given inTable 4.
As shown in Table 4, the performance ismuch better just with this simple refinement tomeet the requirement on extract matches for theevaluation criteria.
Then, the phrase rankingmethod is also incorporated into the system.
Theperformance of the resulting system (denoted byPolyU++) is also provided in Table 4.
Theperformance is again much improved with thephrase ranking process.3.4 DiscussionIn our participation in SemEval-2, we submittedthe PolyU system with the proposed extractionframework, which is based on expanding thecore words to keyphrases.
However, the PolyUsystem did not perform well in SemEval-2.However, we also showed later that theframework can be much improved after some144Simple but necessary refinements are madeaccording to the given task.
The final PolyU++system with two simple refinements is muchbetter.
These refinements, including phrasefiltering and ranking, are similar to traditionaltechniques.
So it seems that our expansion-basedframework is more applicable along with sometraditional techniques.
Though this conflicts ourinitial objective to develop a totally novelframework, the framework shows its ability offinding those keyphrases which contain differenttypes of words.
As to the PolyU++ system, whenadapted with just two very simple post-processing methods, the extracted candidatephrases can already perform quite well inSemEval-2.
This may suggest that the frameworkcan be considered as a new way for candidatekeyphrase identification for the traditionalextraction process.4 Conclusion and future workIn this paper, we introduced our system in ourparticipation in SemEval-2.
We proposed a newframework for the keyphrase extraction task,which is based on expanding core words tokeyphrases.
Heuristic approaches are developedto implement the framework.
We also analyzedthe errors of the system in SemEval-2 andconducted some refinements.
Finally, weconcluded that the framework is indeedappropriate as a candidate phrase identificationmethod.
Another issue is that we just considersome simple information such as frequency orPOS tag in this initial study.
This indeed limitsthe power of the resulting systems.
In futurework, we?d like to develop more sophisticatedimplementations to testify the effectiveness ofthe framework.
More syntactic and semanticfeatures should be considered.
Also, learningmodels can be applied to improve both the coreword identification approach and the wordexpansion approach.AcknowledgmentsThe work described in this paper is supported byHong Kong RGC Projects (PolyU5217/07E andPolyU5230/08E).ReferencesFrank, E., Paynter, G.W., Witten, I., Gutwin, C. andNevill-Manning, C.G.. 1999.
Domain SpecificKeyphrase Extraction.
Proceedings of the IJCAI1999, pp.668--673.Medelyan, O. and Witten, I. H.. 2006.
Thesaurusbased automatic keyphrase indexing.
Proceedingsof the JCDL 2006, Chapel Hill, NC, USA.Medelyan, O. and Witten, I. H.. 2008.
Domainindependent automatic keyphrase indexing withsmall training sets.
Journal of American Society forInformation Science and Technology.
Vol.
59 (7),pp.
1026-1040SemEval-2.
Evaluation Exercises on SemanticEvaluation.
http://semeval2.fbk.eu/Turney, P.. 1999.
Learning to Extract Keyphrasesfrom Text.
National Research Council, Institute forInformation Technology, Technical Report ERB-1057.
(NRC \#41622), 1999.Wan, X. Xiao, J.. 2008.
Single document keyphraseextraction using neighborhood knowledge.
InProceedings of AAAI 2008, pp 885-860.System 5 Keyphrases 10 Keyphrases 15 Keyphrases P R F P R F P R FBest 34.6% 14.4% 20.3% 26.1% 21.7% 23.7% 21.5% 26.7% 23.8%Worst 8.2% 3.4% 4.8% 5.3% 4.4% 4.8% 4.7% 5.8% 5.2%PolyU 13.6% 5.65% 7.98% 12.6% 10.5% 11.4% 12.0% 15.0% 13.3%Baseline 17.8% 7.4% 10.4% 13.9% 11.5% 12.6% 11.6% 14.5% 12.9%Table 3: Results from SemEval-2System 5 Keyphrases 10 Keyphrases 15 Keyphrases P R F P R F P R FPolyU 13.6% 5.65% 7.98% 12.6% 10.5% 11.4% 12.0% 15.0% 13.3%PolyU+ 21.2% 8.8% 12.4% 16.9% 14.0% 15.3% 13.9% 17.3% 15.4%PolyU++ 31.2% 13.0% 18.3% 22.1% 18.4% 20.1% 20.3% 20.6% 20.5%Table 4: The performance of the refined systems145
