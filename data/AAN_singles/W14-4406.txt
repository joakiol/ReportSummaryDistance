Proceedings of the 8th International Natural Language Generation Conference, pages 35?44,Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational LinguisticsAn ACG Analysis of the G-TAG Generation Process?Laurence DanlosUniversite?
Paris Diderot (Paris 7)ALPAGE, INRIA Paris?RocquencourtInstitut Universitaire de France, Paris, Francelaurence.danlos@inria.frAleksandre Maskharashvili and Sylvain PogodallaINRIA Villers-le`s-Nancy, FranceUniversite?
de Lorraine,CNRS, LORIA, UMR 7503Vand?uvre-le`s-Nancy, Francealeksandre.maskharashvili@inria.frsylvain.pogodalla@inria.frAbstractThis paper presents an encoding ofGeneration-TAG (G-TAG) within AbstractCategorial Grammars (ACG).
We showhow the key notions of G-TAG have a nat-ural interpretation in ACG, allowing us touse its reversibility property for text gen-eration.
It also offers solutions to severallimitations of G-TAG.1 MotivationsG-TAG (Danlos, 1998; Danlos, 2000) is a formal-ism based on the Tree Adjoining Grammar (TAG)formalism (Joshi et al., 1975; Joshi and Schabes,1997) dedicated to text generation.
It focuses onproviding several notions to support useful datastructures, such as g-derivation trees or lexicaldatabases, to effectively relate a surface form (aderived tree or a string) to a conceptual represen-tation.
An actual implementation in ADA was firstprovided for French (Meunier, 1997), and it has re-cently been implemented in the .NET frameworkas the EasyText NLG system and is operationalat Kantar Media, a French subsidiary company ofTNS-Sofres (Danlos et al., 2011).The G-TAG proposal can be seen as a resultof the observation of the mismatch between thederivation tree notion of TAG and the expected se-mantic dependencies (Schabes and Shieber, 1994)from a generation perspective.
Several approachesthat extend the derivation tree notion of TAG havebeen proposed to overcome this difficulty.
Otherapproaches showed that the derivation trees stillcould be used without additional modifications.Such approaches rely on unification (Kallmeyerand Romero, 2004; Kallmeyer and Romero, 2007)or a functional approach to TAG (Pogodalla, 2004;?This work has been supported by the French agencyAgence Nationale de la Recherche (ANR-12-CORD-0004).Pogodalla, 2009)1 based on Abstract CategorialGrammars (ACG) (de Groote, 2001).
The latteris intrinsically reversible: the grammars and thealgorithms are the same for parsing and for gener-ation.We propose then to study G-TAG under theACG perspective.
We show that the key notionof g-derivation tree naturally express itself in thisframework.
The surface form construction froma conceptual representation can then use the gen-eral algorithms of ACG, the very same ones thatcan be used in parsing to analyze mildly con-text sensitive languages (TAG generated language,LCFRS) (de Groote and Pogodalla, 2004), follow-ing (Kanazawa, 2007)?s proposal here applied togive an ACG account of G-TAG.
We do not con-sider here the G-TAG treatment of preferences be-tween the different realizations of the same input.Similarly, we do not consider the generation ofpronouns used in G-TAG and we will work onintegrating a theory of generation of referring ex-pressions.2 Sketching G-TAGG-TAG deals with the How to say it?
task of gen-eration.
The input is a conceptual representation.A G-TAG grammar includes elementary trees, asany TAG grammar.
But it also makes g-derivationtrees primary objects, relating them to the elemen-tary trees and considering them as pivot to the con-ceptual representation level.Conceptual Representation G-TAG concep-tual representation makes use of notions as sec-ond order relation, first order relation and thing.Second order relations have two arguments whichare relations (either first or second order ones)and typically correspond to discourse relations,1Synchronous approaches (Nesson and Shieber, 2006) aresimilar in many respects, as shown in (Storoshenk and Frank,2012).35whereas first order relations have things as theirarguments.
While (Danlos, 2000) uses reified for-mulas of a logical conceptual representation lan-guage as G-TAG inputs, it can also be representedas a higher-order logical formula (Meunier, 1997)or as a SDRT-like formula (Danlos et al., 2001).We follow here this presentation.
Equation (1) ex-emplifies an input that could be realized as Jeana passe?
l?aspirateur pour e?tre re?compense?
parMarie.
Puis il a fait une sieste (John has vacumedin order to be rewarded by Mary.
Then he took anap).SUCCESSION(GOAL(VACUUMING(Jean),REWARDING(Marie, Jean)),NAPPING(Jean)) (1)G-TAG Lexical Database A lexical entry of G-TAG corresponds to a lemma.
For each lexical en-try (i.e.
lemma) there is a set of TAG elementarytrees which corresponds to it.
Among the TAG el-ementary trees that correspond to a given lexicalentry, there is the canonical representative, and allthe other representatives are represented by addingfeatures to the canonical representative.
For exam-ple, if the lexical entry is to love, then the canon-ical representative will be the active form of theverb to love.
Then the passive alternation is rep-resented by adding a feature [+passive] to to love.Moreover, all the lexical entries attached to a con-cept (such as SUCCESSION) belong to a same lexi-cal base.
So for a concept, there can be a lexicalentry describing verbal realizations of the concept.These realizations can correspond to the active orto the passive forms, etc.
There can also be a lex-ical entry which corresponds to nominal realiza-tions, etc.G-Derivation Trees A TAG derivation tree canbe seen as a record of the substitutions and adjunc-tion occurring during a TAG analysis.
The same istrue for g-derivation tree.
However, while TAGderivation trees are considered as a by-product,with inflected anchors, G-TAG derivation trees arefirst class structures that are combined in order toreflect the conceptual input.
To abstract from thesurface form and from the derived tree they canrelate to, they don?t correspond to inflected formsbut bear features that are used in a post-processingstep.
Complex g-derivation trees are built by goingthrough the dynamic selection process of a lexi-cal item from the set of appropriate candidates fora given concept.
So contrary to TAG derivationtrees, they are not fully instantiated trees: their ar-guments are represented by variables whose lexi-calization are not carried out yet.G-Derived Trees A g-derivation tree defines aunique g-derived tree corresponding to it.
Thiscorrespondance is maintained all along the real-ization process and a post-processing module out-puts the surface representation (text) from the g-derived tree.
In addition to inflecting forms usingthe feature values it can make some rewriting topropose different versions of the initial text.
Inthis particular sense, g-derived tree correspondsto possibly multiple text outputs generated by thepost-processing module.3 The G-TAG Generation ProcessLet us assume the input of Equation 1.
The G-TAGprocess starts by lexicalizing relations that havethe widest scope in the conceptual representation:typically second order relations, then first order re-lations, and things.2 Back to the example, we firstlexicalize the second order relation SUCCESSION.Several items are associated with this relation:apre`s (after), avant (before), ensuite (afterwards),auparavant (beforehand), puis (then), etc.
Each ofthem has two arguments, however, some of themproduce texts comprising two or more sentences,like ensuite(afterwards); some of them can pro-duce either two sentence texts or one sentence text,while others produce only one sentence.
For in-stance, Jean a passe?
l?aspirateur.
Ensuite, il a faitune sieste (John has vacuumed.
Afterwards, hetook a nap) is a two sentences text while John afait une sieste apre`s avoir passe?
l?aspirateur (Johntook a nap after having vacuumed) is a one sen-tence text.
For this reason, items describing thearguments or the result of second order relationshave features expressing the following constraints:(+T,+S) indicates it is a text (two ore more sen-tences); (+S) indicates it is either a single sen-tence or a text; (?T,+S) indicates it is a sentence(not a text).
Every second order relation has threefeatures: one for output, and two for inputs.
32Correctness of the process is ensured because the gram-mars don?t contain auxiliary trees that would reverse the pred-ication order.
(Danlos, 2000) argues such cases don?t occur intechnical texts, the first target of G-TAG.
We don?t elaborateon this point since the ACG approach we propose remove thisconstraint for free.3In G-TAG, any discourse connective has exactly two ar-guments.
A discussion about this point is provided in (Dan-36Let us assume that the G-TAG g-derivation treeensuite(+T,+S) belonging to the lexical databaseassociated with the concept SUCCESSION is firstchosen, resulting in a text rather than a sentence(illustrated by the leftmost g-derivation tree of Fig-ure 1 .
The process then tries to realize its two ar-guments.
The first one involves the GOAL relationthat can be realized either by pour (in order to) orby pour que (so that), as exemplified by the right-most g-derivation trees of Figure 1.
Both have fea-tures (?T,+S) for the inputs (i.e.
arguments) andreturn a tree labeled at the root by (?T,+S).ensuite(+T,+S)(1st event)(+S) (2nd event)(+S)arg1 arg2pour(?T,+S)(ACTION)(?T,+S) (PURPOSE)(?T,+S)arg1 arg2pour que(?T,+S)(ACTION)(?T,+S) (PURPOSE)(?T,+S)arg1 arg2Figure 1: G-derivation trees samplesDespite pour and pour que bearing the samefeatures, the syntactic trees corresponding to pourand pour que are quite different.
For pour queS substitution nodes can be substituted by twotensed sentences, while pour takes a finite sen-tence and a ?sentence?
in the infinitive form with-out any nominal subject.
Figure 2 shows the asso-ciated elementary trees.
Selecting one or the otherduring the generation process restricts the possiblerealizations for the arguments.
This is enforced bya feature associated to the elementary tree, namelythe (+reduc-subj) feature as shown in Fig.
3.Again, we may assume that G-TAG selects pour,SS (arg1) PPPreppourSCqueS(arg2)(mood:subj)SS (arg1) PPPreppourS(arg2)(mood:inf)Figure 2: Elementary trees of pour que (so that)and pour (in order to)which will enforce, because of the associated ele-mentary trees, that the subject of the first and thesecond arguments are the same.
Afterwards, weneed to lexicalize these two arguments with a com-mon subject Jean.
From a semantic point of view,the agent of VACUUMING has to be the beneficiaryof REWARDING (the rewardee).
VACUUMING canonly be lexicalized as passer-l?aspirateur (run-the-vacuum-cleaner), while there are several lexical-los, 2000).ization options for the REWARDING: re?compenser(to reward), donner-re?compense (to give-reward),and recevoir-re?compense (to receive-reward).
Letus notice that donner-re?compense does not meetthe constraint on a shared subject as it cannothave the rewardee as its subject4.
The remainingoptions are: recevoir-re?compense, whose canon-ical representation has the rewardee as subject;and re?compense whose passive construction hasthe rewardee as subject.
s Assuming a choice ofre?compenser[+passive],5 the lexicalizations of thearguments of the first order relations remain.
AsMarie occurs only once and in subject position,it can only be lexicalized as Marie.
On the otherhand, Jean three times: one will be the implicitsubject of the subordinate, then as argument ofVACUUMING and NAPPING.
Therefore it can be ei-ther lexicalized in both of the cases as Jean, orJean and the pronoun il (he).
In G-TAG, thereare some post-processing rules that take care ofthe generation of referring expressions, but not ina really principled way so we do not demonstratethem here.
We assume a lexicalization by Jean inboth cases.
Figure 3 shows the g-derivation treeassociated with the input of Equation 1 and Fig.
4show the unique resulting (non-flected) derivedtree.
The post-processing modules then outputs:Jean a passe?
l?aspirateur pour e?tre re?compense?par Marie.
Ensuite, il a fait une sieste.
(Johnvacuumed in order to be rewarded by Mary.
Af-terwards, he took a nap.
)ensuitepour(+reduc-subj)passer-l?aspirateurJeanrecompenser(+reduc-subj,+passive)Marie faire-la-siesteJeanarg1arg1arg1arg2arg1 arg2arg2arg1Figure 3: Fully instantiated g-derivation tree4 ACG DefinitionAbstract Categorial Grammars(ACGs) (de Groote, 2001) are a type theo-4It lacks passivation in French and there is no form equiv-alent to: John was given a reward by Mary.5Of course, all these branching points offer several real-izations of the same entry.
But for explanatory purposes, wedescribe only one at each step.37SSSNPJeanVpasserl?aspirateurPPPreppourSNPVae?treVre?compenserPPPrepparMarie.
SAdvensuiteSNPJeanVfaitunesiesteFigure 4: Non-inflected derived treeretical framework that is able to encode severalgrammatical formalisms (de Groote and Pogo-dalla, 2004).
An ACG defines two languages:the abstract one and the object one.
The abstractlevel describe the admissible parse structures anda lexicon maps these structures to the ones weobserve at the object level (strings for surfaceforms, logical formulas for semantic forms).
Inall cases, the considered languages are sets of?-terms that generalize string and tree languages.Definition.
A higher-order linear signature (alsocalled a vocabulary) is defined to be a triple ?
=?A,C, ?
?, where:?
A is a finite set of atomic types (also notedA?),?
C is a finite set of constants (also noted C?),?
and ?
is a mapping from C to TA the set oftypes built on A: TA ::= A|TA ?
TA (alsonoted T?
).Given a higher-order linear signature ?, ?(?)
isthe set of ?-terms built on ?, and for t ?
?(?
)and ?
?
T?
such that t has type ?, we note t :?
?
(the ?
subscript is omitted when obvious from thecontext).Definition.
An abstract categorial grammar is aquadruple G = ?
?,?,L, s?
where:1. ?
and ?
are two higher-order linear signa-tures, which are called the abstract vocabu-lary and the object vocabulary, respectively;2.
L : ?
??
?
is a lexicon from the abstractvocabulary to the object vocabulary.
It isa homomorphism that maps types and termsbuilt on ?
to types and terms built on ?
asfollows:?
if ?
?
?
?
T?
then L(?
?
?)
=L(?)?
L(?)?
if x ?
?(?)
(resp.
?x.t ?
?(?)
andt u ?
?(?))
then L(x) = x (resp.L(?x.t) = ?x.L(t) and L(t u) =L(t)L(u))It is then enough to define L on the atomictypes and on the constants of ?
to define iton all types and terms, provided that for anyconstant c : ?
of ?
we have L(c) : L(?
).We note t:=G u if L(t) = u and omit the Gsubscript if obvious from the context.3.
s ?
T?
is a type of the abstract vocabulary,which is called the distinguished type of thegrammar.Table 1 provides an ACG example Gd-ed treeswhere the abstract typed constants of ?der?
en-code the combinatorial properties of the associated(through the lexicon Ld-ed trees) elementary trees.Definition.
The abstract language of an ACG G =?
?,?,L, s?
is A(G ) = {t ?
?(?)
| t :?
s}The object language of the grammar O(G ) ={t ?
?(?)
| ?u ?
A(G ).
t = LG(u)}For instance, the term Creward IS Iv CMary CJean :S ?
Gd-ed trees, and its image, the derived tree forMarie re?compense Jean (Mary rewards John).It is important to note that, from a purely math-ematical point of view, there is no structural differ-ence between the abstract and the object vocabu-lary: both are higher-order signatures.
This allowsfor combining ACGs in different ways:?
by having a same abstract vocabulary sharedby several ACGs: this can be used to maketwo object terms (for instance a string anda logical formula) share the same underlyingstructure.
Gd-ed trees and GLog in Fig.
5 illustratesuch a composition.?
by making the abstract vocabulary of oneACG the object vocabulary of another ACG,allowing for the control of the admissiblestructures of the former by the latter.
Gyieldand Gd-ed trees in Fig.
5 illustrate such a com-position.?(?der?)?
(?trees)Gd-ed trees?(?string)Gyield?
(?Log)GLogFigure 5: ACG architecture for TAG38Crucial to our analysis is that ACG parsing ofa term u amounts to finding an abstract term tsuch that t:= u, no matter whether u representsa string, a tree, or a logical formula.
This can bedone in polynomial time for ACGs whose abstractconstant types are at most of order 2: second orderACGs as (Kanazawa, 2007) shows.6 The result re-lies on a reduction of the parsing problem to Data-log querying where the term to be parsed is storedin a database.
Interestingly, this database can rep-resent a set of terms (Kanazawa, 2011, Section4.2) and the query reduces to checking whether atleast one of them can be retrieved.
This allows thequery associated with a term representing a logicalformula to extend to all the terms that are equiva-lent modulo the associativity and the commutativ-ity of the conjunction.5 ACG Encoding5.1 TAG as ACGBecause ACG considers both the abstract lan-guage and the object language, the encoding ofTAG into ACG makes (abstract) terms represent-ing derivation trees primary.
The encoding usestwo ACGs Gd-ed trees = ?
?der?,?trees,Ld-ed trees,S?and Gyield = ?
?trees,?string,Lyield, ?
?.We exemplify the encoding7 of a TAG analyz-ing (2) in Fig.
6.8(2) MarieMaryre?compenserewardsensuitethenJeanJohnThis sentence is usually analyzed in TAG with aderivation tree where the adverb adjoins at the vnode.The three higher-order signatures are:?der?
: Its atomic types include S, v, np, SA,vA.
.
.
where the X types stand for the cate-gories X of the nodes where a substitutioncan occur while the XA types stand for thecategories X of the nodes where an adjunc-tion can occur.
For each elementary tree?lex.
entry it contains a constant Clex.
entry whosetype is based on the adjunction and substitu-tion sites as Table 1 shows.
It additionallycontains constants IX : XA that are meantto provide a fake auxiliary tree on adjunction6It actually extends this result to almost linear objectterms where variables with atomic type can be duplicated,as it commonly happens at the semantic level.7This corresponds to the systematic encoding of (Pogo-dalla, 2009) of TAG and its semantics into ACG.8We follow the grammar of (Abeille?, 2002).sites where no adjunction actually takes placein a TAG derivation.
?trees: Its unique atomic type is ?
the type oftrees.
Then, for any X of arity n belong-ing to the ranked alphabet describing the ele-mentary trees of the TAG, we have a constantXn :n times?
??
??
( ?
?
?
( ?
( ?
?string: Its unique atomic type is ?
the type ofstrings.
The constants are the terminal sym-bols of the TAG (with type ?
), the concatena-tion + : ?
( ?
( ?
and the empty string?
: ?.Table 1 illustrates Ld-ed trees.9 Lyield is defined asfollows:?
Lyield(?)
= ?;?
for n > 0, Lyield(Xn) = ?x1 ?
?
?xn.x1 +?
?
?+ xn;?
for n = 0, X0 : ?
represents a terminal sym-bol and Lyield(X0) = X .Then, the derivation tree, the derived tree, and theyield of Fig.
6 are represented by:?reward?Jean?Marie?then(a) Derivation treeSnpJeanvensuitevre?compensenpMarie(b) Derived treeFigure 6: Marie re?compense ensuite Jean?5 = Creward IS (Cvthen IS) CMarie CJeanLd-ed trees(?5)= S3 (np1 Marie)(v2 (v1 re?compense) ensuite) (np1 Jean)Lyield(Ld-ed trees(?5)) = Marie + re?compense+ ensuite + Jean5.2 G-TAG as ACGIn order to model G-TAG in ACG, first we need todesign the abstract signature ?g-der?
in which wecan have entries for G-TAG.
This entries will re-flect the ideology that G-TAG is based on.
Forinstance, in G-TAG discourse level words like en-suite can take as its arguments texts and sentencesand produces text.
In order to model this, weintroduce types S and T. Then, we can defineDSSthen: S ( S ( T, which means that DSSthen hastakes two arguments of type S and returns a re-sult of type T. As in G-TAG, ensuite can take two9With Ld-ed trees(XA) = ?
( ?
and for any other typeX , Ld-ed trees(XA) = ?
.39Abstract constants of ?der?
Their images by Ld-ed trees The corresponding TAG treesCJean : np cJean : ?= np1 Jean ?Jean =npJeanCvthen : vA ( vA cvthen : (?
( ?)
( (?
( ?
)= ?ovx.v (v2 xensuite) ?then = vensuitev?Creward : SA ( vA ( np( np ( S creward: (?
( ?)
( (?
( ?)
( ?
( ?
( ?= ?oavso.a (S3 s (v (v1 re?compense)) o)?reward = Snpvre?compensenpIX : XA ?x.x : ?
( ?Table 1: A TAG as an ACG: Ld-ed trees and Llog.sem lexiconstexts as arguments and return text as well, we needto do have another entry for modeling this fact.This makes us to introduce another constant DTTthen :T ( T ( T. For the same kind of reason, we in-troduce following constants: DSTthen: S ( T ( T,DTSthen and T ( S ( T. Other relations, like au-paravant is modeled in the same way as ensuite in?g-der?.Apart from ensuite and auparavant, there areconnectives as avant (before) and apre`s (after) thatneed to be modeled differently from ensuite.
In-deed, while ensuite results in a text, placing sideby side a text and a sentence separated with a pe-riod, avant and apre`s in French combine in a sin-gle sentence a (full) clause and an infinitive clausewith an implicit subject: the one of the first clause.It is clear that in order to type avant and apre`s inthe ?g-der?
signature, one should use a type whichschematically looks as .
.
.
( S. On the otherhand, one needs to give the exact type to them.Despite that in TAG and G-TAG avant and apre`stake two sentential arguments (labelled by S), thesecond argument bears a feature indicating it lacksthe subject and that the latter has to be shared withthe first sentence.
For instance: Jean a fait unesieste apre`s avoir passe?
l?aspirateur (John tooka nap after having vacuumed), here the subjectof avoir passe?
l?aspirateur (having vacuumed) isJean, which comes from the sentence Jean a faitune sieste (John took a nap).
So, Jean a fait unesieste (John took a nap) can be seen as a sentencewhose subject is shared by another sentence aswell.
In order to model this point, we use fol-lowing type: Sws ( Sh ( np ( S. Indeed,the Sws and the Sh types correspond to the typeof sentences missing a subject.
Furthermore, weneed to model pour and pour que, which were in-troduced in order to lexicalize the GOAL relation inG-TAG.
First, let us have a look at pour que.
It cantake as its arguments two complete (from a syntaxpoint of view) sentences and results in a sentenceas in: Il travaille pour que vous puissiez manger.So, Dpour que, which is an entry corresponding topour que, can be assigned a S ( S ( S type.The syntactic difference between pour que andpour was highlighted in Section 3: pour takesas arguments a complete sentence and an infini-tive form of a sentence missing a subject whosesubject comes from the first argument.
Thus, inthis case, similarly to case of avant and apre`s,pour has to be modeled as an entry that has typeSws ( Sinf ( np ( S, where Sinf stands forthe type of an infinitive form of a clause missing asubject.
We also need to deal with encoding differ-ent forms of a verb.
For instance, re?compenser hasan active and a passive form.
In G-TAG deriva-tion, both of them can be encountered.
In orderto model this fact, two different entries are intro-duced: one for the passive form and one for theactive form, which is the canonical constructionfor re?compenser.
So, we need to have two distinctentries Dpassiverecompense and Dactiverecompense, and both of themhave type SA ( vA ( np ( np ( S. More-over, (Danlos, 2000) poses the problem that G-TAG cannot handle a text where the adverb adjoinat the v node rather than on the S node as in: Jeana passe?
l?aspirateur.
Il a ensuite fait une sieste(John vacuumed.
He then took a nap.)
Accordingto (Danlos, 2000) modelling such text productionrequires a formalism more powerful than TAG.
Inthe ACG framework, this observations translatesinto defining an entry Dvthen : S ( (vA ( S) (T in ?g-der?
which is third order and that is, as such,beyond the TAC into ACG encoding (that only re-quires second-order types).10 This also offers a10Currently, there is no theoretical complexity result forparsing such ACG fragments.
However, in this particu-40general mechanism for providing constants encod-ing adverbial connectives with two arguments asin discourse grammars such as D-STAG (Danlos,2011), but contrary to D-LTAG where one of thearguments is anaphorically given from the preced-ing discourse (Webber, 2004).G-Derivation Trees to Derivation Trees Wetranslate terms of ?g-der?, which correspond to g-derivation trees, into the TAG derivation tree lan-guage defined on ?der?
using the lexicon Lder-derof Table 2.
It is interesting to see how to inter-Lder-der(S) = Lder-der(T) = Lder-der(Sws)= Lder-der(Sinf) = Lder-der(Sh)= SLder-der(SA) = SALder-der(vA) = vALder-der(np) = npLder-der(IS) = ISLder-der(Iv) = IvTable 2: The Lder-der lexiconpret Dvthen: S ( (vA ( S) ( T into ?der?.For this reason, we introduce in ?der?
the follow-ing constant: s2 : S ( S ( S that allowsfor combining two sentences with a period.
Now,it is possible to translate Dvthen into ?der?
as fol-lows: Lder-der(Dvthen) = ?oS1 S2.s2 S1(S2Cvthen).It means that Dvthen is interpreted as performingboth the operation of combining two sentenceswith a period and the adjunction of ensuite on thev node of the second sentence.G-Derived Trees as Interpretation of G-Derivation Trees As soon as g-derivation treesas term built on ?g-der?
are interpreted as termbuilt on ?der?, we can map them to derived trees.Thus, by composing the two lexicons Lder-der andLd-ed trees we can get directly from G-TAG into de-rived trees5.3 From G-TAG to Montague StyleSemantics Using ACGs(Pogodalla, 2009) defines a signature ?Log and alexicon LLog from ?der?
to ?Log.
The entries in?Log have Montague like semantics.
The lexicontranslates a derivation tree into a correspondingformula.
We will use the same kind of semanticlanguage for conceptual representations.
In otherwords, our language will produce the formulaslar case, we could use a second-order?and polynomial?encoding of multi-component TAG into ACG.that are used in the conceptual representation ofG-TAG, while we will stick to the Montague styletranslations from syntax to semantics.So, we define a signature ?conrep of conceptualrepresentation that is similar to the one of (Pogo-dalla, 2009).
?conrep defines two atomic types eand t and constants such as: j, m .
.
.
of type e, theconstant REWARD of type e ( e ( t, the con-stant CLAIM of type e ( t ( t and the constantSEEM of type t( t. Moreover, we have constantsSUCC, GOAL of type t( t( t.We are able to translate ?g-der?
into ?conrepwith the help of the lexicon Lder-con.
Thelexicon Lder-con is extension of the lexicondefined in (Pogodalla, 2009), because weare adding to the domain (i.e.
abstract lan-guage) the constants that are not in the ?der?.Lder-con(S) = Lder-con(T) = tLder-con(vA) = (e?
t) ( (e?
t)Lder-con(SA) = t( tLder-con(np) = (e?
t) ( tLder-con(Djean) = ?oP.P (j)Lder-con(DSTthen) = Lder-con(DSSthen)= Lder-con(DSTthen)= Lder-con(DTSthen)= Lder-con(DTTthen )= ?s2s1.SUCC s2 s1Lder-con(DSTbef. )
= Lder-con(DSSbef.
)= Lder-con(DSTbef.
)= Lder-con(DTSbef.
)= Lder-con(DTTbef.
)= ?o s1s2.
SUCC s2 s1Lder-con(Drewards) = ?os a O S.s(S(a(?ox.O(?oy.
(REWARD x y))))Note that the interpretation of np is JnpK =(e ?
t) ( t, using a non-linear implication (butalmost linear).
Typically, the sharing of the sub-ject by the two clauses related by pour or avant deinduces non linearity.The Sinf, Sh, and Sws types all are interpretedas JnpK ( JSK = ((e ?
t) ( t) ( t as theydenote clauses lacking a subject.
Then we trans-late the constants Dpour, Dapre`s, and Davant inthe following way:Lder-con(Dpour ) =?os1.?os2.?oN.N(?x.
(GOAL(s1(?P.P x))(s2(?P.P x))))Lder-con(Dapres) =?os1.?os2.?oN.N(?x.
(SUCC(s1(?P.P x))(s2(?P.P x))))41Lder-con(Davant) =?os1.?os2.?oN.N(?x.
(SUCC(s2(?P.P x))(s1(?P.P x))))5.4 The G-TAG Process as a MorphismCompositionWe exemplify the whole process using the termT0 = SUCC(VAC(jean),REWARD(marie, jean))of type t.11 The terms representing the g-derivation trees that generate this conceptual rep-resentation are the antecedents of To by L ?1der-con:L ?1der-con(T0) = {t1, .
.
.
, t8} that all are of typeT.
They are given in Figure 7.
Each of these re-trieved terms t1, .
.
.
, t8 are then mapped to termsrepresenting TAG derivation trees, i.e.
built on?der?
via the lexicon Lder-der.
They can be canin turn be interpreted as syntactic derived treesvia the lexicon Ld-ed trees, and the latter can beinterpreted as strings using the lexicon Lyield.So from T0 we can have eight surface forms:Lyield(Ld-ed trees(Lder-der(ti))), i ?
[1, 8].
Let usshow this process on the example of t512.
It il-lustrates the generation of the example (3).13(3) JeanJohna passe?
l?aspirateur.vacuumed.MarieMarya re?compense?rewardedensuiteafterwardsJean.John.Lder-der(t5) = s2 (CvacISIvCjean)(CrewardISCvthenCmarieCjean)Ld-ed trees(Lder-der(t5) =S3 (S2 (np1 Jean)(v1 a passe?
l?aspirateur))?
(S3(np1 Marie)(v2 (v1 a re?compense?)
ensuite)(np1 Jean))And the surface forms is given by composing theinterpretations:Lyield(Ld-ed trees(Lder-der(t5)) =Jean + a passe?
+ l?aspirateur + .
+Marie + a recompense?
+ ensuite + Jean11The associated conceptual input is a simplified version ofthe conceptual input of Equation 1 without the GOAL conceptand a replacement of the NAP one by the REWARDING one.12t5 is such that Lder-der(t5) = ?5 and the term ?5 wasused as example at Section 5.1.13For sake of simplicity we assume the adverb adjoins onthe whole auxiliary+verb phrase rather than only on the aux-iliary as it would be in French.t1 = DSSthen(DvacISIvDjean)(DrewardISIvDmarieDjean)t2 = DSSthen(DvacISIvDjean)(DpassiverewardISIvDmarieDjean)t3 = DSSbef.
(DrewardISIvDmarieDjean)(DvacISIvDjean)t4 = DSSbef.
(DpassiverewardISIvDjeanDmarie)(DvacISIvDjean)t5 = Dvthen(DvacISIvDjean)(?oa.Dreward IS a DmarieDjean)t6 = Dvthen(DvacISIvDjean)(DpassiverewardISIvDjeanDmarie)t7 = Dafter (DswsvacISIv)(Dreceive-rew.ISIvDjean)Dmariet8 = Dbef.
(DswsvacISIv)(Dreceive-rew.ISIvDjean)DmarieFigure 7: Antecedents of T0 by Lder-con6 Related WorkWe can only quickly mention two related piecesof work.
On the one hand, (Gardent and Perez-Beltrachini, 2010) also takes advantage of theformal properties underlying the tree languageof derivation trees to propose a generation pro-cess using TAG grammars.
On the other hand,(Nakatsu and White, 2010) also includes discourserelations in the grammar with Discourse Combi-natory Categorial Grammar and a type-theoreticalframework to provide a text (rather than sentence)generation process.7 ConclusionThis paper shows how G-TAG can be encoded asACG.
It relies on the fact that both G-TAG and theencoding of TAG within ACG make the deriva-tion tree a primary notion.
Then we can bene-fit from the polynomial reversibility of the ACGframework.
It also offers a generalization of theprocess to all kinds of adjunctions, including thepredicative ones.
It also offers a new insight ondiscourse grammars for the adverbial connectiveencoding (Danlos, 2011).
Note that contrary to animportant part of G-TAG that offers a way (basedon a semantic and a linguistic analysis) to rank thedifferent realizations of a conceptual representa-tion, we do not deal here with such preferences.As syntactic ambiguity treatment is not usuallypart of the syntactic formalism, we prefer the ?re-alization ambiguity?
treatment not to be part of thegeneration formalism.
Finally, a crucial perspec-tive is to integrate a theory of generation of re-ferring expressions relying on type-theoretical ap-proaches to dynamics semantics (de Groote, 2006;de Groote and Lebedeva, 2010) that would ensurea large compatibility with the ACG framework.42References[Abeille?2002] Anne Abeille?.
2002.
Une grammairee?lectronique du franc?ais.
Sciences du langage.CNRS E?ditions.
[Danlos et al.2001] Laurence Danlos, Bertrand Gaiffe,and Laurent Roussarie.
2001.
Document sructuringa` la SDRT.
In Helmut Horacek, Nicolas Nicolov,and Leo Wanner, editors, Proceedings of the ACL2001 Eighth European Workshop on Natural Lan-guage Generation (EWNLG).
http://aclweb.org/anthology/W/W01/W01-0803.pdf.
[Danlos et al.2011] Laurence Danlos, Fre?de?ric Meu-nier, and Vanessa Combet.
2011.
EasyText: anoperational NLG system.
In ENLG 2011, 13thEuropean Workshop on Natural Language Gener-ation, September.
http://hal.inria.fr/inria-00614760/en/.
[Danlos1998] Laurence Danlos.
1998.
G-TAG :Un formalisme lexicalise?
pour la ge?ne?ration detextes inspire?
de TAG.
Traitement Automatiquedes Langues, 39(2).
http://hal.inria.fr/inria-00098489.
[Danlos2000] Laurence Danlos.
2000.
G-TAG: A lex-icalized formalism for text generation inspired bytree adjoining grammar.
In Anne Abeille?
and OwenRambow, editors, Tree Adjoining Grammars: For-malisms, Linguistic Analysis, and Processing, pages343?370.
CSLI Publications.
[Danlos2011] Laurence Danlos.
2011.
D-STAG:a formalism for discourse analysis based onSDRT and using synchronous TAG.
In Philippede Groote, Markus Egg, and Laura Kallmeyer, ed-itors, 14th conference on Formal Grammar - FG2009, volume 5591 of LNCS/LNAI, pages 64?84.Springer.
http://dx.doi.org/10.1007/978-3-642-20169-1_5.
[de Groote and Lebedeva2010] Philippe de Groote andEkaterina Lebedeva.
2010.
Presupposition ac-commodation as exception handling.
In Proceed-ings of the SIGDIAL 2010 Conference, pages 71?74,Tokyo, Japan, September.
Association for Computa-tional Linguistics.
http://www.aclweb.org/anthology/W/W10/W10-4313.
[de Groote and Pogodalla2004] Philippe de Groote andSylvain Pogodalla.
2004.
On the expressive powerof Abstract Categorial Grammars: Representingcontext-free formalisms.
Journal of Logic, Lan-guage and Information, 13(4):421?438.
http://hal.inria.fr/inria-00112956.
[de Groote2001] Philippe de Groote.
2001.
TowardsAbstract Categorial Grammars.
In Associationfor Computational Linguistics, 39th Annual Meet-ing and 10th Conference of the European Chap-ter, Proceedings of the Conference, pages 148?155.
http://aclweb.org/anthology/P/P01/P01-1033.pdf.
[de Groote2006] Philippe de Groote.
2006.
To-wards a montagovian account of dynam-ics.
In Masayuki Gibson and JonathanHowell, editors, Proceedings of Semanticsand Linguistic Theory (SALT) 16.
http://elanguage.net/journals/index.php/salt/article/view/16.1/1791.
[Gardent and Perez-Beltrachini2010] Claire Gardentand Laura Perez-Beltrachini.
2010.
RTG based sur-face realisation for TAG.
In Proceedings of the 23rdInternational Conference on Computational Lin-guistics (COLING 2010), pages 367?375, Beijing,China, August.
Coling 2010 Organizing Committee.http://www.aclweb.org/anthology/C10-1042.
[Joshi and Schabes1997] Aravind K. Joshi and YvesSchabes.
1997.
Tree-adjoining grammars.
InG.
Rozenberg and A. Salomaa, editors, Handbookof formal languages, volume 3, chapter 2.
Springer.
[Joshi et al.1975] Aravind K. Joshi, Leon S. Levy, andMasako Takahashi.
1975.
Tree adjunct gram-mars.
Journal of Computer and System Sciences,10(1):136?163.
[Kallmeyer and Romero2004] Laura Kallmeyer andMaribel Romero.
2004.
LTAG semantics withsemantic unification.
In Proceedings of TAG+7,pages 155?162.
[Kallmeyer and Romero2007] Laura Kallmeyer andMaribel Romero.
2007.
Scope and situationbinding for LTAG.
Research on Language andComputation, 6(1):3?52.
http://dx.doi.org/10.1007/s11168-008-9046-6.
[Kanazawa2007] Makoto Kanazawa.
2007.
Pars-ing and generation as datalog queries.
In Pro-ceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics (ACL),pages 176?183.
http://www.aclweb.org/anthology/P/P07/P07-1023.
[Kanazawa2011] Makoto Kanazawa, 2011.
Parsingand generation as Datalog query evaluation.
Un-der review.
http://research.nii.ac.jp/?kanazawa/publications/pagadqe.pdf.
[Meunier1997] Fre?de?ric Meunier.
1997.
Implantationdu formalisme de ge?ne?ration G-TAG.
Ph.D. thesis,Universite?
Paris 7 ?
Denis Diderot.
[Nakatsu and White2010] Crytal Nakatsu and MichaelWhite.
2010.
Generating with discourse com-binatory categorial grammar.
Linguistic Is-sues in Language Technology, 4(1).
http://elanguage.net/journals/index.php/lilt/article/view/1277/871.
[Nesson and Shieber2006] Rebecca Nesson andStuart M. Shieber.
2006.
Simpler TAG seman-tics through synchronization.
In Proceedingsof the 11th Conference on Formal Grammar,Malaga, Spain, 29?30 July.
CSLI Publications.43http://cslipublications.stanford.edu/FG/2006/nesson.pdf.
[Pogodalla2004] Sylvain Pogodalla.
2004.
Comput-ing Semantic Representation: Towards ACG Ab-stract Terms as Derivation Trees.
In Proceedingsof TAG+7, pages 64?71.
http://hal.inria.fr/inria-00107768.
[Pogodalla2009] Sylvain Pogodalla.
2009.
Advancesin Abstract Categorial Grammars: Language The-ory and Linguistic Modeling.
ESSLLI 2009 Lec-ture Notes, Part II.
http://hal.inria.fr/hal-00749297.
[Schabes and Shieber1994] Yves Schabes and Stu-art M. Shieber.
1994.
An alternative conceptionof tree-adjoining derivation.
Computational Lin-guistics, 20(1):91?124.
http://aclweb.org/anthology/J/J94/J94-1004.pdf.
[Storoshenk and Frank2012] Dennis Ryan Storoshenkand Robert Frank.
2012.
Deriving syntax-semanticsmappings: node linking, type shifting and scope am-biguity.
In Proceedings of TAG+11, pages 10?18.
[Webber2004] Bonnie Webber.
2004.
D-LTAG: Ex-tending :exicalized TAG to discourse.
Cognitive Sci-ence, 28:751?779.
http://dx.doi.org/0.1207/s15516709cog2805_6.44
