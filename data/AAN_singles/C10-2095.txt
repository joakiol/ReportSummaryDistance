Coling 2010: Poster Volume, pages 828?836,Beijing, August 2010A Power Mean Based Algorithm for Combining MultipleAlignment TablesSameer Maskey, Steven J. Rennie, Bowen ZhouIBM T.J. Watson Research Center{smaskey, sjrennie, zhou}@us.ibm.comAbstractMost existing techniques for combiningmultiple alignment tables can combineonly two alignment tables at a time, andare based on heuristics (Och and Ney,2003), (Koehn et al, 2003).
In this pa-per, we propose a novel mathematical for-mulation for combining an arbitrary num-ber of alignment tables using their powermean.
The method frames the combi-nation task as an optimization problem,and finds the optimal alignment lying be-tween the intersection and union of multi-ple alignment tables by optimizing the pa-rameter p: the affinely extended real num-ber defining the order of the power meanfunction.
The combination approach pro-duces better alignment tables in terms ofboth F-measure and BLEU scores.1 IntroductionMachine Translation (MT) systems are trained onbi-text parallel corpora.
One of the first stepsinvolved in training a MT system is obtainingalignments between words of source and targetlanguages.
This is typically done using someform of Expectation Maximization (EM) algo-rithm (Brown et al, 1993), (Och and Ney, 2003),(Vogel et al, 1996).
These unsupervised algo-rithms provide alignment links between englishwords ei and the foreign words fj for a given e?fsentence pair.
The alignment pairs are then usedto extract phrases tables (Koehn et al, 2003), hi-erarchical rules (Chiang, 2005), or tree-to-stringmappings (Yamada and Knight, 2001).
Thus, theaccuracy of these alignment links has a significantimpact in overall MT accuracy.One of the commonly used techniques to im-prove the alignment accuracy is combining align-ment tables obtained for source to target (e2f ) andtarget to source (f2e) directions (Och and Ney,2003).
This combining technique involves obtain-ing two sets of alignment tables A1 and A2 for thesame sentence pair e ?
f , and producing a newset based on union A?
= A1 ?
A2 or intersec-tion A?
= A1 ?A2 or some optimal combinationAo such that it is subset of A1 ?
A2 but a super-set of A1 ?
A2.
How to find this optimal Ao is akey question.
A?
has high precision but low re-call producing fewer alignments and A?
has highrecall but low precision.2 Related WorkMost existing methods for alignment combina-tion (symmetrization) rely on heuristics to iden-tify reliable links (Och and Ney, 2003), (Koehnet al, 2003).
The method proposed in (Och andNey, 2003), for example, interpolates the intersec-tion and union of two asymmetric alignment ta-bles by adding links that are adjacent to intersec-tion links, and connect at least one previously un-aligned word.
Another example is the method in(Koehn et al, 2003), which adds links to the inter-section of two alignment tables that are the diago-nal neighbors of existing links, optionally requir-ing that any added links connect two previouslyunaligned words.Other methods try to combine the tables dur-ing alignment training.
In (Liang et al, 2006),asymmetric models are jointly trained to maxi-mize the similarity of their alignments, by opti-828mizing an EM-like objective function based onagreement heuristics.
In (Ayan et al, 2004), theauthors present a technique for combining align-ments based on various linguistic resources suchas parts of speech, dependency parses, or bilingualdictionaries, and use machine learning techniquesto do alignment combination.
One of the main dis-advantages of (Ayan et al, 2004)?s method, how-ever, is that the algorithm is a supervised learningmethod, and so requires human-annotated data.Recently, (Xiang et al, 2010) proposed a methodthat can handle multiple alignments with soft linkswhich are defined by confidence scores of align-ment links.
(Matusov et al, 2004) on the otherhand, frame symmetrization as finding a set withminimal cost using use a graph based algorithmwhere costs are associated with local alignmentprobabilities.In summary, most existing alignment combina-tion methods try to find an optimal alignment setAo that lies between A?
and A?
using heuristics.The main problems with methods based on heuris-tics are:1. they may not generalize well across languagepairs2.
they typically do not have any parameters tooptimize3.
most methods can combine only 2 align-ments at a time4.
most approaches are ad-hoc and are notmathematically well definedIn this paper we address these issues by propos-ing a novel mathematical formulation for com-bining an arbitrary number of alignment tables.The method frames the combination task as an op-timization problem, and finds the optimal align-ment lying between the intersection and union ofmultiple alignment tables by optimizing the pa-rameter p of the power mean function.3 Alignment combination using thepower meanGiven an english-foreign sentence pair (eI1, fJ1 )the alignment problem is to determine the pres-ence of absence of alignment links aij betweenthe words ei and fj , where i ?
I and j ?
J .
Inthis paper we will use the convention that whenaij = 1, words ei and fj are linked, otherwiseaij = 0.
Let us define the alignment tables we ob-tain for two translation directions as A1 and A2,respectively.
The union of these two alignmenttables A?
contain all of the links in A1 and A2,and the intersection A?
contain only the commonlinks.
Definitions 1 and 2 below define A?
andA?
more formally.
Our goal is to find an align-ment set Ao such that |A?| ?
|Ao| ?
|A?| thatmaximizes some objective function.
We now de-scribe the power mean (PM) and show how thePM can represent both the union and intersectionof alignment tables using the same formula.The power mean:The power mean is defined by equation 1 below,where p is a real number in (??,?)
and an is apositive real number.Sp(a1, a2, ..., an) = (1nn?k=1apk)1p (1)The power mean, also known as the generalizedmean, has several interesting properties that arerelevant to our alignment combination problem.In particular, the power mean is equivalent to thegeometric mean G when p?
0 as shown in equa-tion 2 below:G(a1, a2, ..., an) = (n?i=1ai)1n= limp?0( 1nn?k=1apk)1p (2)The power mean, furthermore, is equivalent to themaximum function M when p??
:M(a1, a2, ..., an) = max(a1, a2, ..., an)= limp??
(1nn?k=1apk)1p (3)Importantly, the PM Sp is a non-decreasingfunction of p. This means that Sp is lowerbounded by G and upper-bounded by M for p ?
[0, ?
]:G < Sp < M, 0 < p <?.
(4)829Figure 1: The power-mean is a principled way to interpolate between the extremes of union and inter-section when combining multiple alignment tables.They key insight underpinning our mathematicalformulation of the alignment combination prob-lem is that the geometric mean of multiple align-ment tables is equivalent to their intersection,while the maximum of multiple alignment tablesis equivalent to their union.Let Aq be an alignment with elements aqij suchthat aqij = 1 if words ei and fj are linked, andaqij = 0 otherwise.
The union and intersection ofa set of n alignment tables can then be formallydefined as follows:Definition 1: The union of alignmentsA1, A2, ..., An is a set A?
with a?ij = 1 if aqij = 1for any q ?
{1, 2, ..., n}.Definition 2: The intersection of alignmentsA1, A2, ..., An is a set A?
with a?ij = 1 if aqij = 1for all q ?
{1, 2, ..., n}.Figure 1 depicts a simple example of the align-ment combination problem for the common caseof alignment symmetrization.
Two alignments ta-bles, Ae?f and Af?e (one-to-many alignments),need to be combined.
The result of takingthe union A?
and intersection A?
of the ta-bles is shown.
A?
can be computed by takingthe element-wise maximum of Ae?f and Af?e,which in turn is equal to the power mean Ap ofthe elements of these tables in the limit as p?
?.The intersection of the two tables, A?, can simi-larly be computed by taking the geometric meanof the elements of Ae?f and Af?e, which isequal to the power mean Ap of the elements ofthese tables in the limit as p?
0.
For p ?
(0,?
),equation 4 implies that Ap has elements with val-ues between A?
and A?.
We now provide formalproofs for these results when combining an arbi-trary number of alignment tables.3.1 The intersection of alignment tablesA1..An is equivalent to theirelement-wise geometric meanG(A1, A2, ..., An), as defined in (2).Proof : Let A?
be the intersection of all Aqwhere q ?
{1, 2, .., n}.
As per our definition ofintersection ?
between alignment tables, A?
con-tains links where aqij = 1 ?
q.Let Ag be the set that contains the elements830of G(A1, A2, ..., An).
Then agij is the geo-metric mean of the elements aqij where q ?
{1, 2, .., n}, as defined in equation 2, that is, agij =(?nq=1 agij)1n .
This product is equal to 1 iff aqij =1 ?
q and zero otherwise, since aqij ?
{0, 1} ?
q.Hence Ag = A?.
Q.E.D.3.2 The union of alignment tables A1..An isequivalent to their element-wisemaximum M(A1, A2, ..., An), as definedin (3).Proof : Let A?
be the union of all Aq for q ?
{1, 2, .., n}.
As per our definition of the union be-tween alignments A?
has links where aqij = 1 forsome q.Let Am be the set that contain the elements ofM(A1, A2, ..., An).
Let amij be the maximum ofthe elements aqij where q ?
{1, 2, .., n}, as definedin equation (3).
The max function is equal to 1iff aqij = 1 for some q and zero otherwise, sinceaqij ?
{0, 1} ?
q.
Hence Am = A?.
Q.E.D.3.3 The element-wise power meanSp(A1, A2, ..., An) of alignment tablesA1..An has entries that arelower-bounded by the intersection ofthese tables, and upper-bounded by theirunion for p ?
[0, ?
].Proof : We have already shown that the unionand intersection of a set of alignment tables areequivalent to the maximum and geometric meanof these tables, respectively.
Therefore given thatthe result in equation 4 is true (we will not prove ithere), the relation holds.
In this sense, the powermean can be used to interpolate between the in-tersection and union of multiple alignment tables.Q.E.D.4 DataWe evaluate the proposed method using anEnglish-Pashto translation task, as defined by theDARPA TransTac program.
The training data forthis task consists of slightly more than 100K par-allel sentences.
The Transtac task was designed toevaluate speech-to-speech translation systems, soall training sentences are conversational in nature.The sentence length of these utterances variesgreatly, ranging from a single word to more thanMethod F-measureI 0.5979H 0.6891GDF 0.6712PM 0.6984PMn 0.7276U 0.6589Table 1: F-measure Based on Various AlignmentCombination Methods50 words.
2026 sentences were randomly sampledfrom this training data to prepare held out devel-opment set.
The held out Transtac test set consistsof 1019 parallel sentences.5 Experiments and DiscussionWe have shown in the previous sections that unionand intersection of alignments can be mathemat-ically formulated using the power mean.
Sinceboth combination operations can be representedwith the same mathematical expression, we cansearch the combination space ?between?
the in-tersection and union of alignment tables by op-timizing p w.r.t.
any chosen objective function.In these experiments, we define the optimal align-ment as the one that maximizes the objective func-tion f({aijt}, {a?ijt}, p), where f is standard F-measure, {a?ijt} is the set of all estimated align-ment entries on some dataset, {aijt} is the set ofall corresponding human-annotated alignment en-tries, and p is the order of the power mean func-tion.
Instead of attempting to optimize the F-measure using heuristics, we can now optimize itby finding the appropriate power order p using anysuitable numerical optimization algorithm.
In ourexperiments we used the general simplex algo-rithm of amoeba search (Nelder and Mead, 1965),which attempts to find the optimal set of parame-ters by evolving a simplex of evaluated points inthe direction that the F-measure is increasing.In order to test our alignment combination for-mulation empirically we performed experimentson English-Pashto language with data described inSection 4.
We first trained two sets of alignments,the e2f and f2e directions, based on GIZA++(Och and Ney, 2003) algorithm.
We then com-bined these alignments by performing intersec-831tion (I) and union (U).
We obtained F-measure of0.5979 for intersection (I), 0.6589 for union (U).For intersection the F-measure is lower presum-ably because many alignments are not shared bythe input alignment tables so the number of linksis under-estimated.
We then also re-produced thetwo commonly used combination heuristic meth-ods that are based on growing the alignment di-agonally (GDF) (Koehn et al, 2003), and addinglinks based on refined heuristics (H) (Och andNey, 2003), respectively.
We obtained F-measureof 0.6891 for H, and 0.6712 for GDF as shown inTable 1.We then used our power mean formulation forcombination to maximize the F-measure functionwith the aforementioned simplex algorithm fortuning the power parameter p, where F-measureis computed with respect to the hand aligned de-velopment data, which contains 150 sentences.This hand aligned development set is differentthan the development set for training MT models.While doing so we also optimized table weightsWq ?
(0, 1),?q Wq = 1, which were applied tothe alignment tables before combining them usingthe PM.
The Wq allow the algorithm to weight thetwo directions differently.
We found that the F-measure function had many local minima so thesimplex algorithm was initialized at several val-ues of p and {Wq} to find the globally optimalF-measure.After obtaining power mean outputs for thealignment entries, they need to be convertedinto binary valued alignment links, that is,Sp(a1ij , a2ij , ...anij) needs to be converted into a bi-nary table.
There are many ways to do this con-version such as simple thresholding or keepingbest N% of the links.
In our experiments we usedthe following simple selection method, which ap-pears to perform better than thresholding.
First wesorted links by PM value and then added the linksfrom the top of the sorted list such that ei and fjare linked if ei?1 and ei+1 are connected to fj , orfj?1 and fj+1 is linked to ei, or both ei and fj arenot connected.
After tuning power mean parame-ter and the alignment weights the best parametergave an F-measure of 0.6984 which is higher thancommonly used GDF by 2.272% and H by 0.93%absolute respectively.
We observe in Figure 2 thateven though PM has higher F-measure comparedwith GDF it has significantly fewer number ofalignment links suggesting that PM has improvedprecision on the finding the alignment links.
Thepresented PM based alignment combination canbe tuned to optimize any chosen objective, so it isnot surprising that we can improve upon previousresults based on heuristics.One of the main advantages of the combiningalignment tables using the PM is that our state-ments are valid for any number of input tables,whereas most heuristic approaches can only pro-cess two alignment tables at a time.
The presentedpower mean algorithm, in contrast, can be usedto combine any number of alignments in a sin-gle step, which, importantly, makes it possible tojointly optimize all of the parameters of the com-bination process.In the second set of experiments the PM ap-proach, which we call PMn, is applied simultane-ously to more than two alignments.
We obtainedfour more sets of alignments from the Berke-ley aligner (BA) (Liang et al, 2006), the HMMaligner (HA) (Vogel et al, 1996), the alignmentbased on partial words (PA), and alignment basedon dependency based reordering (DA) (Xu et al,2009).
Alignment I was obtained by using Berke-ley aligner as an off-the-shelf alignment tool.
Webuilt the HMM aligner based on (Vogel et al,1996) and use the HMM aligner for producingAlignment II.
Producing different sets of align-ments using different algorithms could be usefulbecause some alignments that are pruned by onealgorithm may be kept by another giving us a big-ger pool of possible links to chose from.We produced Alignment III based on partialwords.
Pashto is morphologically rich languagewith many prefixes and suffixes.
In lack of a mor-phological segmenter it has been suggested thatkeeping only first ?n?
characters of a word can ef-fectively reduce the vocabulary size and may pro-duce better alignments.
(Chiang et al, 2009) usedpartial words for alignment training in English andUrdu.
We trained such alignments using usingGIZA++ on parallel data with partial words forPashto sentences.The fourth type of alignment we produced,Alignment IV, was motivated by the (Xu et al,832Figure 2: Number of Alignments Links for Dif-ferent Combination Types2009).
(Xu et al, 2009) showed that transla-tion between subject-verb-object (English) andsubject-object-verb (Pashto) languages can be im-proved by reordering the source side of the par-allel data.
They obtained dependency tree of thesource side and used high level human gener-ated rules to reorder source side using precedence-based movement of dependency subtrees.
Therules were particularly useful in reordering ofverbs that moved to the end of the sentence.
Mak-ing the ordering of source and target side moresimilar may produce better alignments for lan-guage pairs which differ in verb ordering, as manyalignment algorithms penalize or fail to consideralignments that link words that differ greatly insentence position.
A Pashto language expert washired to produce similar precedence-based rulesfor the English-Pashto language pair.
Using therules and algorithm described in (Xu et al, 2009)we reordered all of the source side and usedGIZA++ to align the sentences.The four additional alignment sets just de-scribed, including our baseline alignment, Align-ment V, were combined using the presented PMncombination algorithm, where n signifies thenumber of tables being combined.
As seen onTable 1, we obtained an F-measure of 0.7276which is 12.97% absolute better than intersectionand 6.87% better than union.
Furthermore PMn,which in these experiments utilizes 5 alignments,is better than PM by 2.92% absolute.
This is anencouraging result because this not only showsthat we are finding better alignments than inter-section and union, but also that combining morethan two alignments is useful.
We note that PMnperformed 3.85% absolute better than H (Och andNey, 2003), and 5.64% better than GDF heuris-tics.In the above experiments the parameters ofthe power mean combination method were tunedon development data to optimize alignment F-measure, and the performance of several align-ment combination techniques were compared interms of F-measure.
However, it is not clear howcorrelated alignment F-measures are with BLEUscores, as explained in (Fraser and Marcu, 2007).While there is no mathematical problem withoptimizing the parameters of the presented PM-based combination algorithm w.r.t.
BLEU scores,computationally it is not practical to do so becauseeach iteration would require a complete trainingphase.
To further evaluate the quality of the align-ments methods being compared in this paper, webuilt several MT models based on them and com-pared the resulting BLEU scores.E2F Dev TestI 0.1064 0.0941H 0.1028 0.0894GDF 0.1256 0.1091PM 0.1214 0.1094PMn 0.1378 0.1209U 0.1062 0.0897Table 2: E2F BLEU: PM Alignment CombinationBased MT Model ComparisionWe built a standard phrase-based translationsystem (Koehn et al, 2003) that utilizes a stack-based decoder based on an A?
search.
Based onthe combined alignments, we extracted phrase ta-bles with a maximum phrase length of 6 for En-glish and 8 for Pashto, respectively.
We thentrained the lexicalized reordering model that pro-duced distortion costs based on the number ofwords that are skipped on the target side, ina manner similar to (Al-Onaizan and Papineni,2006).
Our training sentences are a compilationof sentences from various domains collected byDARPA, and hence we were able to build interpo-lated language model which weights the domainsdifferently.
We built an interpolated LM for both833English and Pashto, but for English we had signif-icantly more monolingual sentences (1.4 millionin total) compared to slightly more than 100K sen-tences for Pashto.
We tuned our MT model usingminimum error rate (Och, 2003) training.F2E Dev TestI 0.1145 0.1101H 0.1262 0.1193GDF 0.1115 0.1204PM 0.1201 0.1155PMn 0.1198 0.1196U 0.1111 0.1155Table 3: F2E BLEU : PM Alignment Combina-tion Based MT Model ComparisionWe built five different MT models based onIntersection (I), Union (U), (Koehn et al, 2003)Grow Diagonal Final (GDF), (Och and Ney, 2003)H refined heuristics and Power Mean (PMn) align-ment sets where n = 5.
We obtained BLEU (Pa-pineni et al, 2002) scores for E2F direction asshown in Table 2.
As expected MT model basedon I alignment has the low BLEU score of 0.1064on the dev set and 0.0941 on the test set on E2Fdirection.
Intersection, though, has higher preci-sion, but throws away many alignments, so theoverall number of alignments is too small to pro-duce a good phrase translation table.
Similarlythe U alignment also has low scores (0.1062 and0.0897) on the dev and test sets, respectively.
Thebest scores for E2F direction for both dev and testset is obtained using the model based on PMn al-gorithm.
We obtained BLEU scores of 0.1378 onthe dev set and 0.1209 on the test set which is bet-ter than all heuristic based methods.
It is betterby 1.22 absolute BLEU score on the dev set and1.18 on a test compared to commonly used GDF(Koehn et al, 2003) heuristics.
The above BLEUscores were all computed based on 1 reference.Note that for the e2f direction PM, which com-bines only 2 alignments, is not worse than any ofthe heuristic based methods.
Also note that thedifference in the BLEU score of PM and PMn isquite large, which indicates that combining morethan two alignments using the power mean leadsto substantial gains in performance.Although we saw significant gains on E2F di-Type PT Size (100K)I 182.17H 30.73GDF 27.65PM 60.87PMn 25.67U 24.54Table 4: E2F Phrase Table Sizerection we did not see similar gains on F2E di-rection unfortunately.
Matching our expectationIntersection (I) produced the worse results withBLEU scores of 0.1145 and 0.1101 on the devand test set respectively, as shown in Table 3.
OurPMn algorithm obtained BLEU score of 0.1198on the dev set and 0.1196 on test set which isbetter by 0.83 absolute in dev set over GDF.
Onthe test set though performance between PMn andGDF is only slightly different with 0.1196 forPMn and 0.1204 for GDF.
The standard deviationon test set BLEU scores for F2E direction is only0.0042 which is one third of the standard devia-tion in E2F direction at 0.013 signifying that thealignment seems to make less difference in F2Edirection for our models.
One possible explana-tion for such results is that the Pashto LM for theE2F direction is trained on a small set of sen-tences available from training corpus while En-glish LM for F2E direction was trained on 1.4 mil-lion sentences.
Therefore the English LM, whichis trained on significantly more data, is probablymore robust to translation model errors.Type PT Size (100K)I 139.98H 56.76GDF 22.96PM 47.50PMn 21.24U 20.33Table 5: F2E Phrase Table SizeNote that different alignments lead to differ-ent phrase table (PT) sizes (Figure 2).
The inter-section (I) method has the least number of align-ment links, and tends to produce the largest phrasetables, because there are less restrictions on the834phrases to be extracted.
The Union (U) method,on the other hand, tends to produce the least num-ber of phrases, because the phrase extraction al-gorithm has more constraints to satisfy.
We ob-serve that PT produced by intersection is signifi-cantly larger than others as seen in Tables 4 and5.
The PT size produced by PMn as shown inTable 4 is between I and U and is significantlysmaller than the other heuristic based methods.
Itis 7.1% smaller than GDF heuristic based phrasetable.
Similarly in F2E direction as well (Table5) we see the similar trend where PMn PT sizeis smaller than GDF by 4.2%.
The decrease inphrase table size and increase in BLEU scores formost of the dev and test sets show that our PMbased combined alignments are helping to pro-duce better MT models.6 Conclusion and Future WorkWe have presented a mathematical formulation forcombining alignment tables based on their powermean.
The presented framework allows us to findthe optimal alignment between intersection andunion by finding the best power mean parameterbetween 0 and ?, which correspond to intersec-tion and union operations, respectively.
We eval-uated the proposed method empirically by com-puting BLEU scores in English-Pashto transla-tion task and also by computing an F-measurewith respect to human alignments.
We showedthat the approach is more effective than intersec-tion, union, the heuristics of (Och and Ney, 2003),and the grow diagonal final (GDF) algorithm of(Koehn et al, 2003).
We also showed that our al-gorithm is not limited to two tables, which makesit possible to jointly optimize the combination ofmultiple alignment tables to further increase per-formance.In future work we would like to address twoparticular issues.
First, in this work we convertedpower mean outputs to binary alignment links bysimple selection process.
We are currently investi-gating ways to integrate the binary constraint intothe PM-based optimization algorithm.
Second,we do not have to limit ourselves to alignments ta-bles that are binary.
PM based algorithm can com-bine alignments that are not binary, which makesit easier to integrate other sources of informationsuch as posterior probability of word translationinto the alignment combination framework.7 AcknowledgmentThis work is partially supported by the DARPATRANSTAC program under the contract numberof NBCH2030007.
Any opinions, findings, andconclusions or recommendations expressed in thismaterial are those of the authors and do not nec-essarily reflect the views of DARPA.ReferencesAl-Onaizan, Yaser and Kishore Papineni.
2006.
Dis-tortion models for statistical machine translation.
InProceedings of ACL.Ayan, Necip, Bonnie J. Dorr, , and Nizar Habash.2004.
Multi-align: Combining linguistic and statis-tical techniques to improve alignments for adaptablemt.
In Proceedings of the 6th Conference of the As-sociation for Machine Translation in the Americas.Brown, P., V. Della Pietra, S. Della Pietra, and R. Mer-cer.
1993.
The mathematics of statistical machinetranslation: parameter estimation.
ComputationalLinguistics, 19(2):263?311.Chiang, David, Kevin Knight, and Samad Echihabi.2009.
In Presentation at NIST MT 2009 Workshop,August.Chiang, David.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of ACL.Fraser, Alexander and Daniel Marcu.
2007.
Measur-ing word alignment quality for statistical machinetranslation.
Comput.
Linguist., 33(3):293?303.Koehn, Philipp, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of HLT/NAACL.Liang, Percy, Ben Taskar, and Dan Klein.
2006.Alignment by agreement.
In Proceedings of ACL.Matusov, Evgeny, Richard Zens, and Hermann Ney.2004.
Symmetric word alignments for statisticalmachine translation.
In Proceedings of COLING,page 219, Morristown, NJ, USA.Nelder, JA and R Mead.
1965.
A simplex method forfunction minimization.
The Computer Journal 7:308-313.Och, F. J. and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29(1):19?51.835Och, Franz J.
2003.
Minimum error rate training instatistical machine.
In Proceedings of ACL.Papineni, Kishore, Salim Roukos, Todd Ward, and Weijing Zhu.
2002.
Bleu: A method for automatic eval-uation of machine translation.
In In Proceedings ofACL, pages 311?318.Vogel, Stephan, Hermann Ney, and Christoph Till-mann.
1996.
Hmm-based word alignment in statis-tical translation.
In COLING 96: The 16th Int.
Conf.on Computational Linguistics, pages 836?841.Xiang, Bing, Yonggang Deng, and Bowen Zhou.
2010.Diversify and combine: Improving word alignmentfor machine translation on low-resource languages.In Proceedings of ACL.Xu, Peng, Jaeho Kang, Michael Ringgaard, and FranzOch.
2009.
Using a dependency parser to improvesmt for subject-object-verb languages.
In NAACL,pages 245?253, Morristown, NJ, USA.Yamada, Kenji and Kevin Knight.
2001.
A syntax-based statistical translation model.
In Proceedingsof ACL, pages 523?530, Toulouse, France, July.ACL.836
