iiIiniinimiIiiinIiniIIiianThe TreeBanker: a Tool forSupervised Training of Parsed CorporaDav id  Car terSRI In ternat iona l23 Mil lers Yard, Mill LaneCambr idge  CB2 1RQUni ted K ingdomdmc?cam, sri.
comAbst rac tI describe the TreeBanker, a graphicaltool for the supervised training involved indomain customization of the disambigua-tion component of a speech- or language-understanding system.
The TreeBankerpresents a user, who need not be a systemexpert, with a range of properties that dis-tinguish competing analyses for an utter-ance and that are relatively easy to judge.This allows training on a corpus to be com-pleted in far less time, and with far less ex-pertise, than would be needed if analyseswere inspected irectly: it becomes possi-ble for a corpus of about 20~000 sentencesof the complexity of those in the ATIS cor-pus to be judged in around three weeks ofwork by a linguistically aware non-expert.1 In t roduct ionIn a language understanding system where full,linguistically-motivated analyses of utterances aredesired, the linguistic analyser needs to generatepossible semantic representations and then choosethe one most likely to be correct.
If the analyseris a component of a pipelined speech understandingsystem, the problem is magnified, as the speech rec-ognizer will typically deliver not a word string butan N-best list or a lattice; the problem then becomesone of choosing between multiple analyses of severalcompeting word sequences.In practice, we can only come near to satisfac-tory disambiguation performance if the analyser istrained on a corpus of utterances from the samesource (domain and task) as those it is intended toprocess.
Since this needs to be done afresh for eachnew source, and since a corpus of several thousandsentences will normally be needed, economic onsid-erations mean it is highly desirable to do it as au-tomatically as possible.
Furthermore, those aspectsthat cannot be automated should as far as possiblenot depend on the attention of experts in the systemand in the representations it uses.The Spoken Language Translator (SLT; Becketet al forthcoming; Rayner and Carter, 1996 and1997) is a pipelined speech understanding systemof the type assumed here.
It is constructed fromgeneral-purpose peech recognition, language pro-cessing and speech synthesis components in order toallow relatively straightforward adaptation to newdomains.
Linguistic processing in the SLT systemis carried out by the Core Language Engine (CLE;Alshawi, 1992).
Given an input string, N-best list orlattice, the CLE applies unification-based syntacticrules and their corresponding semantic rules to cre-ate zero or more quasi-logical form (QLF, describedbelow; Alshawi, 1992; Alshawi and Crouch, 1992)analyses of it; disambiguation is then a matter ofselecting the correct (or at least, the best available)QLF.This paper describes the TreeBanker, a programthat facilitates upervised training by interactingwith a non-expert user and that organizes the re-sults of this training to provide the CLE with datain an appropriate format.
The CLE uses this datato analyse speech recognizer output efficiently and tochoose accurately among the interpretations it cre-ates.
I assume here that the coverage problem hasbeen solved to the extent hat the system's grammarand lexicon license the correct analyses of utterancesoften enough for practical usefulness (Rayner, Bouil-lon and Carter, 1995).The examples given in this paper are taken fromthe ATIS (Air Travel Inquiry System; Hemphill etal, 1990) domain.
However, wider domains, suchas that represented in the North American Busi-ness News (NAB) corpus, would present no par-ticular problem to the TreeBanker as long as the(highly non-trivial) coverage problems for those do-mains were close enough to solution.
The examplesgiven here are in fact all for Englis\]h, but the Tree-Banker has also successfully been used for Swedishand French customizations of the CLE (Gamb?ckand Rayner, 1992; Rayner, Carter and Bouillon,1996).2 Representat iona l  Issue.,~In the version of QLF output by the CLE's analyser,content word senses are represented as predicatesand predicate-argument relations are shown, so thatselecting a single QLF during disambiguation e tailsresolving content word senses and many structuralambiguities.
However, many function words, partic-ularly prepositions, are not resolved to senses, andquantifier scope and anaphoric references are alsoleft unresolved.
Some syntactic information, suchas number and tense, is represented.
Thus QLF en-codes quite a wide range of the syntactic and seman-tic information that can be useful both in supervisedtraining and in run-time disambiguation.QLFs are designed to be appropriate for the infer-ence or other processing that follows utterance anal-ysis in whatever application (translation, databasequery, etc.)
the CLE is being used for.
However,they are not easy for humans to work with directly insupervised training.
Even for an expert, inspectingall the analyses produced for a sentence is a tediousand time-consuming task.
There may be dozens ofanalyses that are variations on a small number oflargely independent themes: choices of word sense,modifier attachment, conjunction scope and so on.Further, if the representation language is designedwith semantic and computational considerations inmind, there is no reason why it should be easy toread even for someone who fully understands it.
Andindeed, as already argued, it is preferable that se-lection of the correct analysis should as far as pos-sible not require the intervention of experts at all.The TreeBanker (and, in fact, the CLE's preferencemechanism, omitted here for space reasons but dis-cussed in detail by Becket et al forthcoming) there-fore treats a QLF as completely characterized by itsproperties: smaller pieces of information, extractedfrom the QLF or the syntax tree associated with it,that are likely to be easy for humans to work with.The TreeBanker presents instances of many kindsof property to the user during training.
However,its functionality in no way depends on the specificnature of QLF, and in fact its first action in thetraining process is to extract properties from QLFsand their associated parse trees, and then neveragain to process the QLFs directly.
The database ofanalysed sentences that it maintains contains onlythese properties and not the analyses themselves.It would therefore be straightforward to adapt theTreeBanker to any system or formalism from whichproperties could be derived that both distinguishedcompeting analyses and could be presented to a non-expert user in a comprehensible way.
Many main-stream systems and formalisms would satisfy thesecriteria, including ones such as the University ofPennsylvania Treebank (Marcus et al 1993) whichare purely syntactic (though of course, only syntacticproperties could then be extracted).
Thus althoughI will ground the discussion of the TreeBanker in itsuse in adapting the CLE system to the ATIS do-main, the work described is of much more generalapplication.3 D isc r iminant -Based  Tra in ingMany of the properties extracted from QLFs can bepresented to non-expert users in a form they can eas-ily understand.
Those properties that hold for someanalyses of a particular utterance but not for others Iwill refer to as discriminants (Dagan and ltai, 1994;Yarowsky, 1994).
Discriminants that fairly consis-tently hold for correct but not (some) incorrect anal-yses, or vice versa, are likely to be useful in distin-guishing correct from incorrect analyses at run time.Thus for training on an utterance to be effective,we need to provide enough "user-friendly" discrimi-nants to allow the user to select the correct analyses,and as many as possible "system-friendly" discrim-inants that, over the corpus as a whole, distinguishreliably between correct and incorrect analyses.
Ide-ally, a discriminant will be both user-friendly andsystem-friendly, but this is not essential.
In the restof this paper we will only encounter user-friendlyproperties and discriminants.The TreeBanker presents properties to the user ina convenient graphical form, exemplified in Figure1 for the sentence "Show me the flights to Bostonserving a meal".
Initially, all discriminants are dis-played in inverse video to show they are viewed asundecided.
Through the disambiguation process,discriminants and the analyses they apply to can beundecided, correct ("good", shown in normal video),or incorrect ("bad", normal video but preceded anegation symbol ..... ).
The user may click on anydiscriminant with the left mouse button to selectit as correct, or with the right button to select itas incorrect.
The types of property currently ex-tracted, ordered approximately from most to leastuser-friendly, are as follows; examples are taken fromthe six QLFs for the sentence used in figure 1.?
Constituents: ADVP for "serving a meal" (a10Figure 1: Initial TreeBanker display for "Show me the flights to Boston serving a meal"discriminant, holding only for readings thatcould be paraphrased "show me the flights toBoston while you're serving a meal"); VP for"serving a meal" (holds for all readings, so nota discriminant and not shown in figure 1).Semantic triples: relations between word sensesmediated usually by an argument position,preposition or conjunction (Alshawi and Carter,1994).
Examples here (abstracting from sensesto root word forms, which is how they are pre-sented to the user) are " f l ight  to  Boston"and "show - to  Boston" (the "-" indicates thatthe attachment is not a low one; this distinc-tion is useful at run time as it significantly af-fects the likelihood of such discriminants beingcorrect).
Argument-position relations are lessuser-friendly and so are not displayed.When used at run time, semantic triples un-dergo abstraction to a set of semantic lassesdefined on word senses.
For example, the ob-vious senses of "Boston", "New York" and soon all map onto the class name co_city.
Theseclasses are currently defined manually by ex-perts; however, only one level of abstraction,rather than a full semantic hierarchy, seems tobe required, so the task is not too arduous.Word senses: "serve" in the sense of "fly to"("does United serve Dallas?")
or "provide"("does that flight serve meals?").?
Sentence type: imperative sentence in this case(other moods are possible; fragmentary sen-tences are displayed as "elliptical NP", etc).?
Grammar rules used: the rule name is given.This can be useful for experts in the minorityof cases where their intervention is required.In all, 27 discriminants are created for this sen-tence, of which 15 are user-friendly enough to dis-play, and a further 28 non-discriminant propertiesmay be inspected if desired.
This is far more thanthe three distinct differences between the analyses("serve" as "fly to" or "provide"; "to Boston" at-taching to "show" or "flights"; and, if "to Boston"does attach to "flights", a choice between "servinga meal" as relative or adverbial).
The effect of thisis that the user can give attention to whatever dis-criminants he I finds it easiest o judge; other, harderones will typically be resolved automatically by theTreeBanker as it reasons about what combinationsof discriminants apply to which analyses.
The firstrule the TreeBanker uses in this reasoning processto propagate decisions is:R1 If an analysis (represented as a set of discrim-inants) has a discriminant hat the user hasmarked as bad, then the analysis must be bad.This rule is true by definition.
The other rules useddepend on the assumption that there is exactly one1I make the customary apologies for this use of pro-nouns, and offer the excuse that most use of the Tree-Banker to date has been by men.l lgood analysis among those that have been found,which is of course not true for all sentences; see Sec-tion 4 below for the ramifications of this.R2 If a discriminant is marked as good, then onlyanalyses of which it is true can be good (sincethere is at most one good analysis).R3 If a discriminant is true only of bad analyses,then it is bad (since there is at least one goodanalysis).R4 If a discriminant is true of all the undecidedanalyses, then it is good (since it must be trueof the correct one, whichever it is).Thus if the user selects "the flights to Boston serv-ing a meal" as a correct NP, the TreeBanker appliesrule R2 to narrow down the set of possible good anal-yses to just two of the six (hence the item "2 goodQLFs" at the top of the control menu in the fig-ure; this is really a shorthand for "2 possibly goodQLFs").
It then applies RI-R4 to resolve all theother discriminants except the two for the sense of"serve"; and only those two remain highlighted ininverse video in the display, as shown in Figure 2.So, for example, there is no need for the user explic-itly to make the trickier decision about whether ornot "serving a meal" is an adverbial phrase.
Theuser simply clicks on "serve = prov ide" ,  at whichpoint R2 is used to rule out the other remaininganalysis and then R3 to decide that "serve = f lyto" is bad.The TreeBanker's propagation rules often act likethis to simplify the judging of sentences whose dis-criminants combine to produce an otherwise unman-ageably large number of QLFs.
As a further exam-ple, the sentence "What is the earliest flight that hasno stops from Washington to San Francisco on Fri-day?"
yields 154 QLFs and 318 discriminants, yetthe correct analysis may be obtained with only twoselections.
Selecting "the earliest flight ... on Fri-day" as an NP eliminates all but twenty of the anal-yses produced, and approving "that has no stops" asa relative clause eliminates eighteen of these, leavingtwo analyses which are both correct for the purposesof translation.
152 incorrect analyses may thus bedismissed in less than fifteen seconds.The utterance "Show me the flights serving mealson Wednesday" demonstrates the TreeBanker's fa-cility for presenting the user with multiple alterna-tives for determining correct analyses.
As shown inFigure 3, the following decisions must be made:?
Does "serving" mean "flying to" or "provid-ing" ??
Does "on Wednesday" modify "show","flights", "serving" or "meals"??
Does "serving" modify "show" or "flights"?but this can be done by approving and rejecting var-ious constituents such as "the flights serving meals"and "meals on Wednesday", or through the selectionof triples such as "flight -on Wednesday".
Whichevermethod is used, the user can choose among the 14QLFs produced for this sentence within twenty sec-onds.4 Add i t iona l  Funct iona l i tyAlthough primarily intended for the disambiguationof corpus sentences that are within coverage, theTreeBanker also supports the diagnosis and catego-rization of coverage failures.
Sometimes, the usermay suspect hat none of the provided analyses fora sentence is correct.
This situation often becomesapparent when the TreeBanker (mis-)applies rulesR2-R4 above and insists on automatically assigningincorrect values to some discriminants when the usermakes decisions on others; the coverage failure maybe confirmed, if the user is relatively accomplished,by inspecting the non-discriminant properties as well(thus turning the constituent window into a displayof the entire parse forest) and verifying that the cor-rect parse tree is not among those offered.
Thenthe user may mark the sentence as "Not OK" andclassify it under one of a number of failure types, op-tionally typing a comment as well.
At a later stage,a system expert may ask the TreeBanker to printout all the coverage failures of a given type as an aidto organizing work on grammar and lexicon devel-opment.For some long sentences with many different read-ings, more discriminants may be displayed than willfit onto the screen at one time.
In this case, theuser may judge one or two discriminants (scrollingif necessary to find likely candidates), and ask theTreeBanker thereafter to display only undecided dis-criminants; these will rapidly reduce in number asdecisions are made, and can quite soon all be viewedat once.If the user changes his mind about a discriminant,he can click on it again, and the TreeBanker will takelater judgments as superceding earlier ones, inferringother changes on that basis.
Alternatively, the "Re-set" button may be pressed to undo all judgmentsfor the current sentence.It has proved most convenient to organize the cor-pus into files that each contain data for a few dozensentences; this is enough to represent a good-sized12Figure 2: TreeBanker display after approving topmost "np" discriminantFigure 3: Initial TreeBanker display for "Show me the flights serving meals on Wednesday"13corpus in a few hundred files, but not so big thatthe user is likely to want to finish his session in themiddle of a file.Once part of the corpus has been judged andthe information extracted for run-time use (not dis-cussed here), the TreeBanker may be told to resolvediscriminants automatically when their values cansafely be inferred.
In the ATIS domain, "show - to(c i ty ) "  is a triple that is practically never correct,since it only arises from incorrect PP attachments insentences like "Show me flights to New York".
Theuser can then be presented with an initial screen inwhich that choice, and others resulting from it, arealready made.
This speeds up his work, and mayin fact mean that some sentences do not need to bepresented at all.In practice, coverage development tends to over-lap somewhat with the judging of a corpus.
In viewof this, the TreeBanker includes a "merge" optionwhich allows existing judgments applying to an oldset of analyses of a sentence to be transferred to anew set that reflects a coverage change.
Propertiestend to be preserved much better than whole anal-yses as coverage changes; and since only properties,and not analyses, are kept in the corpus database,the vast bulk of the judgments made by the user canbe preserved.The TreeBanker can also interact directly with theCLE's analysis component to allow a user or devel-oper to type sentences to the system, see what dis-criminants they produce, and select one analysis forfurther processing.
This configuration can be usedin a number of ways.
Newcomers can use it to famil-iarize themselves with the system's grammar.
Moregenerally, beginning students of grammar can use itto develop some understanding of what grammaticalanalysis involves.
It is also possible to use this modeduring grammar development as an aid to visualiz-ing the effect of particular changes to the grammaron particular sentences.5 Eva luat ion  and  Conc lus ionsUsing the TreeBanker, it is possible for a linguisti-cally aware non-expert to judge around 40 sentencesper hour after a few days practice.
When the userbecomes till more practised, as will be the case ifhe judges a corpus of thousands of sentences, thisfigure rises to around 170 sentences per hour in thecase of our most experienced user.
Thus it is rea-sonable to expect a corpus of 20,000 sentences tobe judged in around three person weeks.
A muchsmaller amount of time needs to be spent by expertsin making judgments he felt unable to make (per-haps for one per cent of sentences once the user hasgot used to the system) and in checking the user'swork (the TreeBanker includes a facility for pick-ing out sentences where errors are mostly likely tohave been made, by searching for discriminants withunusual values).
From these figures it would seemthat the TreeBanker provides a much quicker andless skill-intensive way to arrive at a disambiguatedset of analyses for a corpus than the manual anno-tation scheme involved in creating the Penn Tree-bank; however, the TreeBanker method depends onthe prior existence of a grammar for the domain inquestion, which is of course a non-trivial require-ment.Engelson and Dagan (1996) present a scheme forselecting corpus sentences whose judging is likely toprovide useful new information, rather than thosethat merely repeat old patterns.
The TreeBankeroffers a related facility whereby judgments on onesentence may be propagated to others having thesame sequence of parts of speech.
This can be com-bined with the use of representative corpora in theCLE (Rayner, Bouillon and Carter, 1995) to allowonly one representative of a particular pattern, outof perhaps dozens in the corpus as a whole, to be in-spected.
This already significantly reduces the num-ber of sentences needing to be judged, and hence thetime required, and we expect further reductions asEngelson's and Dagan's ideas are applied at a finerlevel.In the current implementation, the TreeBankeronly makes use of context.independent properties:those derived from analyses of an utterance that areconstructed without any reference to the context ofuse.
But utterance disambiguation i general re-quires the use of information from the context.
Thecontext can influence choices of word sense, syntacticstructure and, most obviously, anaphoric reference(see e.g.
Carter, 1987, for an overview), so it mightseem that a disambiguation component trained onlyon context-independent properties cannot give ade-quate performance.However, for QLFs for the ATIS domain, andpresumably for others of similar complexity, this isnot in practice a problem.
As explained earlier,anaphors are left unresolved at the stage of anal-ysis and disambiguation we are discussing here; andcontextual factors for sense and structural ambigu-ity resolution are virtually always "frozen" by theconstraints imposed by the domain.
For example,although there are certainly contexts in which "Tellme flights to Atlanta on Wednesday" could mean"Wait until Wednesday, and then tell me flights toAtlanta", in the ATIS domain this reading is im-possible and so "on Wednesday" must attach to14"flights".
For a wider domain such as NAB, onecould perhaps attack the context problem either byan initial phase of topic-spotting (using a differentset of discriminant scores for each topic category),or by including some discriminants for features ofthe context itself among these to which training wasapplied.AcknowledgementsI am very grateful to Martin Keegan for feedbackon his hard work of judging 16,000 sentences usingthe TreeBanker, and to Manny Rayner, David Mil-ward and anonymous referees for useful commentson earlier versions of this paper.The work reported here was begun under fund-ing from by the Defence Research Agency, Malvern,UK, under Strategic Research Project AS04BP44,and continued with funding from Telia Research ABunder the SLT-2 project.Re ferencesBecket, Ralph, and 19 others (forthcoming).
Spo-ken Language Translator: Phase Two Report.
Jointreport by SRI International nd Telia Research.Alshawi, Hiyan, editor (1992).
The Core LanguageEngine.
The MIT Press, Cambridge, Massachusetts.Alshawi, Hiyan, and David Carter (1994).
"Trainingand Scaling Preference Functions for Disambigua-tion".
Computational Linguistics, 20:4.
*2Alshawi, Hiyan, and Richard Crouch (1992).
"Monotonic Semantic Interpretation".
In Proceed-ingsof 30th Annual Meeting of the Associationfor Computational Linguistics, pp.
32-39, Newark,Delaware.
*Carter, David (1987).
"Interpreting Anaphors inNatural Language Texts".
Chichester: Ellis Hor-wood.Dagan, Ido, and Alon Itai (1994).
"Word Sense Dis-ambiguation Using a Second Language MonolingualCorpus", Computational Linguistics 20:4, pp.
563-596.Engelson, Sean, and Ido Dagan (1996).
"Minimiz-ing Manual Annotation Cost in Supervised Train-ing from Corpora".
In Proceedings of 34th AnnualMeeting of the Association for Computational Lin-guistics, pp.
319-326, Santa Cruz, CA.Gamb~ick, Bj6rn, and Manny Rayner (1992).
"TheSwedish Core Language Engine".
In Proceedings of2 Starred references are also available fromhttp ://www.
cam.
sri.
com.NOTEX-92.
*Hemphill, C.T., J.J. Godfrey and G.R.
Doddington(1990).
"The ATIS Spoken Language Systems pilotcorpus."
Proceedings of DARPA Speech and Nat-ural Language Workshop, Hidden Valley, Pa., pp.96-101.Marcus, Mitchell, Beatrice Santorini, and Mary AnnMarcinkiewicz (1993).
"Building a Large AnnotatedCorpus of English: the Penn Treebank".
Computa-tional Linguistics, 19:2, pp.
313-330.Murveit, Hy, John Butzberger, Vassilios Digalakisand Mitchell Weintraub (1993).
"Large Vocabu-lary Dictation using SRI's DECIPHER(TM) SpeechRecognition System: Progressive Search Tech-niques".
In Proceedings of ICASSP-93.Rayner, Manny, Pierrette Bouillon, and DavidCarter (1995).
"Using Corpora to Develop Limited-Domain Speech Translation Systems".
In Proceed-ings of Translating and the Computer 17, ASLIB,London.
*Rayner, Manny, David Carter, and Pierrette Bouil-lon (1996).
"Adapting the Core Language Engineto French and Spanish".
In Proceedings ofNLP-IA,Moncton, New Brunswick.
*Rayner, Manny, and David Carter (1996).
"FastParsing using Pruning and Grammar Specializa-tion".
In Proceedings of34th Annual Meeting of theAssociation for Computational Linguistics, pp.
223-230, Santa Cruz, CA.
*Rayner, Manny, and David Carter (1997).
"Hybridlanguage processing in the Spoken Language Trans-lator".
In Proceedings ofICASSP-97.
*Yarowsky, David (1994).
"Decision Lists for LexicalAmbiguity Resolution".
In Proceedings of32nd An-nual Meeting of the Association for ComputationalLinguistics, pp.
88-95, Las Cruces, NM.15
