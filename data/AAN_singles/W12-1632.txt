Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 232?236,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsAutomatically Acquiring Fine-GrainedInformation Status Distinctions in GermanAoife CahillEducational Testing Service,660 Rosedale Road,Princeton, NJ 08541, USAacahill@ets.orgArndt RiesterInstitute for Natural Language Processing (IMS)Pfaffenwaldring 5b70569 Stuttgart, Germanyarndt.riester@ims.uni-stuttgart.deAbstractWe present a model for automatically predict-ing information status labels for German refer-ring expressions.
We train a CRF on manuallyannotated phrases, and predict a fine-grainedset of labels.
We achieve an accuracy score of69.56% on our most detailed label set, 76.62%when gold standard coreference is available.1 IntroductionThe automatic identification of information status(Prince, 1981; 1992), i.e.
categorizing discourse en-tities into different classes on the given-new scale,has recently been identified as an important issue innatural language processing (Nissim, 2006; Rahmanand Ng, 2011; 2012).
It is widely acknowledged thatinformation status and, more generally, informationstructure,1 is reflected in word order, in the form ofreferring expressions as well as in prosody.
In com-putational linguistics, the ability to automatically la-bel text with information status, therefore, could beof great benefit to many applications, including sur-face realization, text-to-speech synthesis, anaphoraresolution, summarization, etc.The task of automatically labeling text with infor-mation status, however, is a difficult one.
Part of1Information structure is usually taken to describe clause-internal divisions into focus-background, topic-comment, ortheme-rheme, which are in turn defined in terms of contex-tual factors such as given-new information, salience, contrastand alternatives, cf.
Steedman and Kruijff-Korbayova?
(2003),Krifka (2007).
Information status is the subfield of informationstructure which exclusively deals with the given-new distinctionand which is normally confined to referring expressions.the difficulty arises from the fact that, to a certaindegree, such labeling requires world knowledge andsemantic comprehension of the text, but another ob-stacle is simply that theoretical notions of informa-tion status are not used consistently in the literature.In this paper we outline a system, trained on asmall amount of data, that achieves encouragingresults on the task of automatically labeling tran-scribed German radio news data with fine-grainedinformation status labels.2 Learning information statusA simpler variant of the task is anaphoricity de-tection (discourse-new detection) (Bean and Riloff,1999; Ng and Cardie, 2002; Uryupina, 2003; Denisand Baldridge, 2007; Zhou and Kong, 2011), whichdivides discourse entities into anaphoric (given) andnew.
Identifying discourse-new expressions in textsis helpful as a precursor to coreference resolution,since, by definition, there is no need to identify an-tecedents for new entities.In the linguistic literature, referring expressionshave been distinguished in much more detail, andthere is reason to believe that this could also provideuseful information for NLP applications.
Nissim(2006) and Rahman and Ng (2011) developed meth-ods to automatically identify three different classes:OLD, MEDIATED and NEW expressions.
This classi-fication, which is described in Nissim et al (2004),has been used for annotating the Switchboard dialogcorpus (Calhoun et al, 2010), on which both studiesare based.
Most recently, Rahman and Ng (2012)extend their automatic prediction system to a morefine-grained set of 16 subtypes.232Old.
The class of OLD entities in Nissim et al(2004) is not limited to full-fledged anaphors like inExample (1a) but also includes cases of generic andfirst/second person pronouns like in (1b), which mayor may not possess a previous mention.
(1) a.
Shares in General Electric rose as investorsbet that the US company would take morelucrative engine orders for the A380.b.
I wonder where this comes from.Mediated.
The group of MEDIATED entities mainlyhas two subtypes: (2a) shows an expression whichhas not been mentioned before but which is depen-dent on previous context.
Such items have also beencalled bridging anaphors (Poesio and Vieira, 1998).
(2b) contains a phrase which is generally known butdoes not depend on the discourse context.
(2) a.
Tomorrow, the Shenzhou 8 spacecraft willbe in a position to attempt the docking.b.
They hope that he will be given the right toremain in the Netherlands.New.
The label NEW, following Nissim et al (2004:1024), applies ?to entities that have not yet been in-troduced in the dialog and that the hearer cannot in-fer from previously mentioned entities.
?2 Two kindsof expressions which fall into this category are unfa-miliar definites (3a) and (specific) indefinites (3b).
(3) a.
The man who shot a policeman yesterdayhas not been caught yet.b.
Klose scored a penalty in the 80th minute.Based on work described in Nissim (2006), Rahmanand Ng (2011) develop a machine learning approachto information-status determination.
They develop asupport vector machine (SVM) model from the an-notated Switchboard dialogs in order to predict thethree possible classes.
In an extension of this work,Rahman and Ng (2012) compare a rule-based sys-tem to a classifier with features based on the rules topredict 16 subtypes of the three basic types.
On thisextended label set on the dialog data, they achieveaccuracy of 86.4% with gold standard coreferenceand 78.7% with automatically detected coreference.3 Extending Information Status predictionThe work we present here is most similar to thatof Rahman and Ng (2012), however, our work dif-2Note that this definition fails to exclude cases like (2b).fers from theirs in a number of important respects.We (i) experiment with a different information statusclassification, derived from Riester et al (2010), (ii)use (morpho-)syntactic and functional features auto-matically extracted from a deep linguistic parser inour CRF sequence model, (iii) test our approach ona different language (German), (iv) show that highaccuracy can be achieved with a limited number oftraining examples, and (v) that the approach workson a different genre (transcribed radio news bulletinswhich contain complex embedded phrases like anoffer to the minority Tamil population of Sri Lanka,not typically found in spoken dialog).The annotation scheme by Riester et al (2010)divides referring items differently to Nissim et al(2004).
Arguments are provided in the former pa-per and in Baumann and Riester (to appear).
As itstands, the scheme provides too many labels for ourpurpose.
As a compromise, we group them in sevenclasses: GIVEN, SITUATIVE, BRIDGING, UNUSED,NEW, GENERIC and EXPLETIVE.Given.
Givenness is a central notion in informa-tion structure theory.
Schwarzschild (1999) de-fines givenness of individual-type entities in termsof coreference.
If desired, GIVEN items can be sub-classified, e.g.
whether they are pronouns or fullnoun phrases, and whether the latter are repetitionsor short forms of earlier material, or whether theyconsist of lexically new material (epithets).Situative.
1st and 2nd person pronouns, locative andtemporal adverbials, usually count as deictic expres-sions since they refer to elements in the utterance sit-uation.
We therefore count them as a separate class.SITUATIVE entities may, but need not, corefer.Bridging.
Bridging anaphors, as in (2a) above, havereceived much attention, see e.g.
Asher and Las-carides (1998) or Poesio and Vieira (1998).
Al-though they are discourse-new, they share propertieswith coreference anaphors since they depend on thediscourse context.
They represent a class which canbe easily identified by human annotators but are dif-ficult to capture by automatic techniques.Unused.
In manual annotation practice, it is very of-ten impossible to decide whether an entity is hearer-known, since this depends on who we assume thehearer to be; and even if we agree on a recipient, wemay still be mistaken about their knowledge.
For ex-ample, Wolfgang Bosbach, deputy chairman of the233Countable Boolean Descriptive# Words in phrase* Phrase contains a compound noun Adverbial type, e.g.
locative# Predicative phrases Phrase contains coordination Determiner type, e.g.
definite *# DPs and NPs in phrase Phrase contains time expression Left/Right-most POS tag of phrase# top category children Phrase contains < 2, 5 or 10 words Highest syntactic node label# Labels/titles Phrase does not have a complete parse that dominates the phrase# Depth of syntactic phrase Phrase is a pronoun Grammatical function, e.g.
SUBJ *# Cardinal numbers Phrase contains more than 1 DP Type of pronoun, e.g.
demonstrative# Depth of syntactic phrase and 1 NP (i.e.
phrase contains Syntactic shape, e.g.
apposition withignoring unary branching an embedded argument) a determiner and attributive modifier# Apposition phrases Head noun appears (partly or completely) Head noun type, e.g.
common *# Year phrases in previous 10 sentences * Head noun number, e.g.
singularTable 1: Features of the CRF prediction model (* indicates feature used in baseline model)CDU parliamentary group may be known to partsof a German audience but not to other people.We address this by collecting both hearer-knownand hearer-unknown definite expressions into oneclass UNUSED.
This does not rule out further sub-classification (known/unknown) or the possibility ofusing machine learning techniques to identify thisdistinction, see Nenkova et al (2005).
The fact thatRahman and Ng (2011) report the highest confusionrate between NEW and MEDIATED entities may haveits roots in this issue.New.
Only (specific) indefinites are labeled NEW.Generic.
An issue which is not dealt with in Nissimet al (2004) are GENERIC expressions as in Lionshave manes.
Reiter and Frank (2010) discuss thetask of identifying generic items in a manner sim-ilar to the learning tasks presented above, using aBayesian network.
We believe it makes sense to in-tegrate genericity detection into information-statusprediction.34 German dataOur work is based on the DIRNDL radio news cor-pus of Eckart et al (2012) which has been hand-annotated with information status labels.
We choosea selection of 6668 annotated phrases (1420 sen-tences).
This is an order of magnitude smaller thanthe annotated Switchboard corpus of Calhoun et al(2010).
We parse each sentence with the GermanLexical Functional Grammar of Rohrer and Forst(2006) using the XLE parser in order to automati-3Note that in coreference annotation it is an open questionwhether two identical generic terms should count as coreferent.cally extract (morpho-)syntactic and functional fea-tures for our model.5 Prediction Model for Information StatusCahill and Riester (2009) show that there are asym-metries between pairs of information status labelscontained in sentences, i.e.
certain classes of expres-sions tend to precede certain other classes.
We there-fore treat the prediction of IS labels as a sequencelabeling task.4 We train a CRF using wapiti(Lavergne et al, 2010), with the features outlined inTable 1.
We also include a basic ?coreference?
fea-ture, similar to the lexical features of Rahman andNg (2011), that fires if there is some lexical overlapof nouns (or compound nouns) in the preceding 10sentences.
The original label set described in Riesteret al (2010) contains 21 labels.
Here we work witha subset of maximally 12 labels, but also considersmaller subsets of labels and carry out a mapping tothe Nissim (2006) label set (Table 2).5 We run a 10-fold cross-validation experiment and report averageprediction accuracy.
The results are given in Table3a.
As an informed baseline, we run the same cross-validation experiment with a subset of features thatroughly correspond to the features of Nissim (2006).Our models perform statistically significantly betterthan the baseline (p < 0.001, using the approximaterandomization test) for all label sets.4Preliminary experimental evidence showed that the CRFperformed slightly better than a simple multiclass logistic re-gression model (e.g.
compare 72.19 to 72.43 in Table 3a).5Unfortunately, due to underlying theoretical differences, itis impossible to map between the Riester label set and the ex-tended label set used in Rahman and Ng (2012).234Total Riester 1 Riester 2 Riester 3 Nissim ?06462 GIVEN- GIVEN-GIVEN OLDPRONOUN PRONOUN143 GIVEN- GIVEN-REFLEXIVE REFLEXIVE427 GIVEN-EPITHET169 GIVEN- GIVEN-REPEATED NOUN204 GIVEN-SHORT265 SITUATIVE SITUATIVE SITUATIVE449 BRIDGING BRIDGING BRIDGINGMEDIATED1271 UNUSED- UNUSED- UNUSEDKNOWN KNOWN1227 UNUSED- UNUSED-NEWUNKNOWN UNKNOWN1282 NEW NEW NEW632 GENERIC GENERIC GENERIC96 EXPLETIVE EXPLETIVE EXPLETIVE OTHERTable 2: Varying the granularity of the label setsAs expected, the less fine-grained a label set, theeasier it is to predict the labels.
It remains for fu-ture work to show the effect of different label setgranularities in practical applications.
We approx-imate gold standard coreference information fromthe manually annotated labels (e.g.
all GIVEN la-bel types are by their nature coreferent), and carryout an experiment with gold-standard approximationof coreference marking.
These results are also re-ported in Table 3a.
Here we see a clear performancedifference in the effect of gold-standard corefer-ence on the Riester label set (increasing around 6-10%), compared to the Nissim label set (decreasingslightly).
This is an artifact of the way the mappingwas carried out, deriving the gold standard corefer-ence information from the Riester label set.
There isnot a one-to-one mapping between OLD and GIVEN,and, in the Riester label set, coreferential entitiesthat are labeled as SITUATIVE (deictic terms) are notrecognized as such.The feature set in Table 1 reflects the morpho-syntactic properties of the phrases to be labeled.Sometimes world knowledge is required in orderto be able to accurately predict a label; for exam-ple, to know that the pope can be categorized asUNUSED-KNOWN, because it can occur discourse-initially, whereas the priest must usually be cate-gorized as GIVEN.
The BRIDGING relationship isalso difficult to capture without some world knowl-edge.
For example, to infer that the waitress canbe categorized as BRIDGING in the context of therestaurant requires information that links the twoconcepts.
Rahman and Ng (2012) also note this andinclude features based on FrameNet, WordNet andthe ReVerb corpus for English.For German, we address this issue by introducingtwo further types of features into our model based onthe GermaNet resource (Hamp and Feldweg, 1997).The first type is based on the GermaNet synset ofthe head noun in the phrase and its distance from theroot node (the assumption is that entities closer toroot are more generic than those further away).
Thesecond include the sum and maximum of the Linsemantic relatedness measures (Lin, 1998) of howsimilar the head noun of the phrase is to the othernouns in current and immediately preceding sen-tence surrounding the phrase (calculated with Ger-maNet Pathfinder; Finthammer and Cramer, 2008).The results are given in Table 3b.
Here we see aconsistent increase in performance of around 4% foreach label set over the model that does not includethe GermaNet features.
Again, we see the same de-crease in performance on the Nissim label set whenusing gold standard coreference information.Label Set Accuracy Gold Baselinecoref.
feats.Riester 1 65.49 72.49 57.25Riester 2 67.21 76.88 58.82Riester 3 72.43 82.22 64.20Nissim ?06 76.24 74.06 71.70(a) Only morpho-syntactic featuresLabel Set Accuracy Gold coreferenceRiester 1 69.56 76.62Riester 2 71.99 79.86Riester 3 75.82 84.76Nissim ?06 79.61 78.46(b) Morpho-syntactic + GermaNet featuresTable 3: Cross validation accuracy results6 ConclusionIn this paper we presented a model for automaticallylabeling German text with fine-grained informationstatus labels.
The results reported here show that wecan achieve high accuracy prediction on a complextext type (transcribed radio news), even with a lim-ited amount of data.235ReferencesNicholas Asher and Alex Lascarides.
1998.
Bridging.Journal of Semantics, 15(1):83?113.Stefan Baumann and Arndt Riester.
to appear.
Ref-erential and Lexical Givenness: Semantic, Prosodicand Cognitive Aspects.
In G. Elordieta and P. Prieto,editors, Prosody and Meaning.
Mouton de Gruyter,Berlin.David L. Bean and Ellen Riloff.
1999.
Corpus-BasedIdentification of Non-Anaphoric Noun Phrases.
InProceedings of ACL, pages 373?380, College Park,MD.Aoife Cahill and Arndt Riester.
2009.
IncorporatingInformation Status into Generation Ranking.
In Pro-ceedings of ACL-IJCNLP, pages 817?825, Singapore.Sasha Calhoun, Jean Carletta, Jason Brenier, Neil Mayo,Dan Jurafsky, Mark Steedman, and David Beaver.2010.
The NXT-Format Switchboard Corpus: ARich Resource for Investigating the Syntax, Seman-tics, Pragmatics and Prosody of Dialogue.
LanguageResources and Evaluation, 44(4):387?419.Pascal Denis and Jason Baldridge.
2007.
Global JointDetermination of Anaphoricity and Coreference Res-olution Usinger Integer Programming.
In Proceedingsof ACL-HLT, Rochester, NY.Kerstin Eckart, Arndt Riester, and Katrin Schweitzer.2012.
A Discourse Information Radio News Databasefor Linguistic Analysis.
In C. Chiarcos et al, edi-tors, Linked Data in Linguistics, pages 65?76, Berlin.Springer.Marc Finthammer and Irene Cramer.
2008.
Exploringand Navigating: Tools for GermaNet.
In Proceedingsof LREC, Marrakech, Morocco.Birgit Hamp and Helmut Feldweg.
1997.
GermaNet ?
aLexical-Semantic Net for German.
In Proceedings ofthe ACL Workshop Automatic Information Extractionand Building of Lexical Semantic Resources for NLPApplications, pages 9?15.Manfred Krifka.
2007.
Basic Notions of InformationStructure.
In C. Fe?ry and M. Krifka, editors, The No-tions of Information Structure, pages 57?68.
Univer-sita?tsverlag Potsdam.Thomas Lavergne, Olivier Cappe?, and Franc?ois Yvon.2010.
Practical Very Large Scale CRFs.
In Proceed-ings of ACL, pages 504?513.Dekang Lin.
1998.
An Information-Theoretic Definitionof Similarity.
In International Conference on MachineLearning, pages 296?304.Ani Nenkova, Advaith Siddharthan, and Kathleen McK-eown.
2005.
Automatically Learning Cognitive Sta-tus for Multi-Document Summarization of Newswire.In Proceedings of HLT/EMNLP, pages 241?248, Van-couver.Vincent Ng and Claire Cardie.
2002.
IdentifyingAnaphoric and Non-Anaphoric Noun Phrases to Im-prove Coreference Resolution.
In Proceedings ofCOLING, pages 730?736, Taipei, Taiwan.Malvina Nissim, Shipra Dingare, Jean Carletta, and MarkSteedman.
2004.
An Annotation Scheme for Infor-mation Status in Dialogue.
In Proceedings of LREC,Lisbon.Malvina Nissim.
2006.
Learning Information Status ofDiscourse Entities.
In Proceedings of EMNLP, pages94?102, Sydney.Massimo Poesio and Renata Vieira.
1998.
A Corpus-Based Investigation of Definite Description Use.Computational Linguistics, 24(2).Ellen F. Prince.
1981.
Toward a Taxonomy of Given-New Information.
In P. Cole, editor, Radical Prag-matics, pages 233?255.
Academic Press, New York.Ellen F. Prince.
1992.
The ZPG Letter: Subjects, Def-initeness and Information Status.
In W. Mann andS.
Thompson, editors, Discourse Description, pages295?325.
Benjamins, Amsterdam.Altaf Rahman and Vincent Ng.
2011.
Learning the Infor-mation Status of Noun Phrases in Spoken Dialogues.In Proceedings of EMNLP, pages 1069?1080, Edin-burgh.Altaf Rahman and Vincent Ng.
2012.
Learning the Fine-Grained Information Status of Discourse Entities.
InProceedings of EACL 2012, Avignon, France.Nils Reiter and Anette Frank.
2010.
Identifying GenericNoun Phrases.
In Proceedings of ACL, pages 40?49,Uppsala, Sweden.Arndt Riester, David Lorenz, and Nina Seemann.
2010.A Recursive Annotation Scheme for Referential In-formation Status.
In Proceedings of LREC, Valletta,Malta.Christian Rohrer and Martin Forst.
2006.
ImprovingCoverage and Parsing Quality of a Large-Scale LFGfor German.
In Proceedings of LREC, Genoa, Italy.Roger Schwarzschild.
1999.
GIVENness, AvoidF, andother Constraints on the Placement of Accent.
NaturalLanguage Semantics, 7(2):141?177.Mark Steedman and Ivana Kruijff-Korbayova?.
2003.Discourse Structure and Information Structure.
Jour-nal of Logic, Language and Information, 12:249?259.Olga Uryupina.
2003.
High-precision Identification ofDiscourse New and Unique Noun Phrases.
In Pro-ceedings of the ACL Student Workshop, pages 80?86,Sapporo.Guodong Zhou and Fang Kong.
2011.
Learning NounPhrase Anaphoricity in Coreference Resolution viaLabel Propagation.
Journal of Computer Science andTechnology, 26(1).236
