Proceedings of the ACL Student Research Workshop, pages 1?6,Ann Arbor, Michigan, June 2005. c?2005 Association for Computational LinguisticsHybrid Methods for POS Guessing of Chinese Unknown WordsXiaofei LuDepartment of LinguisticsThe Ohio State UniversityColumbus, OH 43210, USAxflu@ling.osu.eduAbstractThis paper describes a hybrid model thatcombines a rule-based model with twostatistical models for the task of POSguessing of Chinese unknown words.
Therule-based model is sensitive to the type,length, and internal structure of unknownwords, and the two statistical models uti-lize contextual information and the like-lihood for a character to appear in a par-ticular position of words of a particularlength and POS category.
By combiningmodels that use different sources of infor-mation, the hybrid model achieves a pre-cision of 89%, a significant improvementover the best result reported in previousstudies, which was 69%.1 IntroductionUnknown words constitute a major source of diffi-culty for Chinese part-of-speech (POS) tagging, yetrelatively little work has been done on POS guess-ing of Chinese unknown words.
The few existingstudies all attempted to develop a unified statisticalmodel to compute the probability of a word hav-ing a particular POS category for all Chinese un-known words (Chen et al, 1997; Wu and Jiang,2000; Goh, 2003).
This approach tends to missone or more pieces of information contributed bythe type, length, internal structure, or context of in-dividual unknown words, and fails to combine thestrengths of different models.
The rule-based ap-proach was rejected with the claim that rules arebound to overgenerate (Wu and Jiang, 2000).In this paper, we present a hybrid model that com-bines the strengths of a rule-based model with thoseof two statistical models for this task.
The threemodels make use of different sources of information.The rule-based model is sensitive to the type, length,and internal structure of unknown words, with over-generation controlled by additional constraints.
Thetwo statistical models make use of contextual infor-mation and the likelihood for a character to appear ina particular position of words of a particular lengthand POS category respectively.
The hybrid modelachieves a precision of 89%, a significant improve-ment over the best result reported in previous stud-ies, which was 69%.2 Chinese Unknown WordsThe definition of what constitutes a word is prob-lematic for Chinese, as Chinese does not have worddelimiters and the boundary between compoundsand phrases or collocations is fuzzy.
Consequently,different NLP tasks adopt different segmentationschemes (Sproat, 2002).
With respect to any Chi-nese corpus or NLP system, therefore, unknownwords can be defined as character strings that arenot in the lexicon but should be identified as seg-mentation units based on the segmentation scheme.Chen and Bai (1998) categorized Chinese unknownwords into the following five types: 1) acronyms,i.e., shortened forms of long names, e.g., be?i-da` forbe?ij??ng-da`xue?
?Beijing University?
; 2) proper names,including person, place, and organization names,e.g., Ma?o-Ze?do?ng; 3) derived words, which are cre-ated through affixation, e.g., xia`nda`i-hua` ?modern-ize?
; 4) compounds, which are created through com-pounding, e.g., zh??-la?ohu?
?paper tiger?
; and 5) nu-1meric type compounds, including numbers, dates,time, etc., e.g., lia?ng-dia?n ?two o?clock?.
Othertypes of unknown words exist, such as loan wordsand reduplicated words.
A monosyllabic or disyl-labic Chinese word can reduplicate in various pat-terns, e.g., zo?u-zo?u ?take a walk?
and pia`o-pia`o-lia`ng-lia`ng ?very pretty?
are formed by reduplicatingzo?u ?walk?
and pia`o-lia`ng ?pretty?
respectively.The identification of acronyms, proper names,and numeric type compounds is a separate task thathas received substantial attention.
Once a charac-ter string is identified as one of these, its POS cate-gory also becomes known.
We will therefore focuson reduplicated and derived words and compoundsonly.
We will consider unknown words of the cat-egories of noun, verb, and adjective, as most un-known words fall under these categories (Chen andBai, 1998).
Finally, monosyllabic words will not beconsidered as they are well covered by the lexicon.3 Previous ApproachesPrevious studies all attempted to develop a uni-fied statistical model for this task.
Chen et al(1997) examined all unknown nouns1, verbs, andadjectives and reported a 69.13% precision usingDice metrics to measure the affix-category associa-tion strength and an affix-dependent entropy weight-ing scheme for determining the weightings be-tween prefix-category and suffix-category associa-tions.
This approach is blind to the type, length, andcontext of unknown words.
Wu and Jiang (2000)calculated P(Cat,Pos,Len) for each character, whereCat is the POS of a word containing the character,Pos is the position of the character in that word, andLen is the length of that word.
They then calcu-lated the POS probabilities for each unknown wordas the joint probabilities of the P(Cat,Pos,Len) ofits component characters.
This approach was ap-plied to unknown nouns, verbs, and adjectives thatare two to four characters long2.
They did not re-port results on unknown word tagging, but reportedthat the new word identification and tagging mecha-nism increased parser coverage.
We will show thatthis approach suffers reduced recall for multisyllabic1Including proper names and time nouns, which we ex-cluded for the reason discussed in section 2.2Excluding derived words and proper names.words if the training corpus is small.
Goh (2003) re-ported a precision of 59.58% on all unknown wordsusing Support Vector Machines.Several reasons were suggested for rejecting therule-based approach.
First, Chen et al (1997)claimed that it does not work because the syntac-tic and semantic information for each character ormorpheme is unavailable.
This claim does not fullyhold, as the POS information about the componentwords or morphemes of many unknown words isavailable in the training lexicon.
Second, Wu andJiang (2000) argued that assigning POS to Chineseunknown words on the basis of the internal struc-ture of those words will ?result in massive over-generation?
(p. 48).
We will show that overgener-ation can be controlled by additional constraints.4 Proposed ApproachWe propose a hybrid model that combines thestrengths of different models to arrive at better re-sults for this task.
The models we will consider area rule-based model, the trigram model, and the sta-tistical model developed by Wu and Jiang (2000).Combination of the three models will be based onthe evaluation of their individual performances onthe training data.4.1 The Rule-Based ModelThe motivations for developing a set of rules for thistask are twofold.
First, the rule-based approach wasdismissed without testing in previous studies.
How-ever, hybrid models that combine rule-based and sta-tistical models outperform purely statistical modelsin many NLP tasks.
Second, the rule-based modelcan incorporate information about the length, type,and internal structure of unknown words at the sametime.Rule development involves knowledge of Chi-nese morphology and generalizations of the train-ing data.
Disyllabic words are harder to general-ize than longer words, probably because their mono-syllabic component morphemes are more fluid thanthe longer component morphemes of longer words.It is interesting to see if reduction in the degree offluidity of its components makes a word more pre-dictable.
We therefore develop a separate set ofrules for words that are two, three, four, and five2Chars T1 T2 T3 T4 Total2 1 2 1 2 63 2 6 2 5 154 2 2 0 8 125+ 0 1 0 1 2Total 5 11 3 16 35Table 1: Rule distributionor more characters long.
The rules developed fallinto the following four types: 1) reduplication rules(T1), which tag reduplicated unknown words basedon knowledge about the reduplication process; 2)derivation rules (T2), which tag derived unknownwords based on knowledge about the affixation pro-cess; 3) compounding rules (T3), which tag un-known compounds based on the POS informationof their component words; and 4) rules based ongeneralizations about the training data (T4).
Rulesmay come with additional constraints to avoid over-generation.
The number of rules in each set is listedin Table 1.
The complete set of rules are developedover a period of two weeks.As will be shown below, the order in which therules in each set are applied is crucial for dealingwith ambiguous cases.
To illustrate how rules work,we discuss the complete set of rules for disyllabicwords here3.
These are given in Figure 1, whereA and B refer to the component morpheme of anunknown AB.
As rules for disyllabic words tend toovergenerate and as we prefer precision over recallfor the rule-based model, most rules in this set areaccompanied with additional constraints.In the first reduplication rule, the order of thethree cases is crucial in that if A can be both a verband a noun, AA is almost always a verb.
The sec-ond rule tags a disyllabic unknown word formed byattaching the diminutive suffix er to a monosyllabicroot as a noun.
This may appear a hasty general-ization, but examination of the data shows that errarely attaches to monosyllabic verbs except for thefew well-known cases.
In the third rule, a catego-rizing suffix is one that attaches to other words toform a noun that refers to a category of people orobjects, e.g., jia?
?-ist?.
The constraint ?A is not averb morpheme?
excludes cases where B is polyse-mous and does not function as a categorizing suffix3Multisyllabic words can have various internal structures,e.g., a disyllabic noun can have a N-N, Adj-N, or V-N structure.if A equals Bif A is a verb morpheme, AB is a verbelse if A is a noun morpheme, AB is a nounelse if A is an adjective morpheme, AB is a stativeadjective/adverbelse if B equals er, AB is a nounelse if B is a categorizing suffix AND A is not a verbmorpheme, AB is a nounelse if A and B are both noun morphemes but not verbmorphemes, AB is a nounelse if A occurs verb-initially only AND B is not a nounmorpheme AND B does not occur noun-finally only,AB is a verbelse if B occurs noun-finally only AND A is not a verbmorpheme AND A does not occur verb-initially only,AB is a nounFigure 1: Rules for disyllabic wordsbut a noun morpheme.
Thus, this rule tags be`ng-ye`?water-pump industry?
as a noun, but not l?
?-ye` leave-job ?resign?.
The fourth rule tags words such as sha?-xia?ng ?sand-box?
as nouns, but the constraints pre-vent verbs such as so?ng-ko`u ?loosen-button?
frombeing tagged as nouns.
So?ng can be both a nounand a verb, but it is used as a verb in this word.The last two rules make use of two lists of char-acters extracted from the list of disyllabic words inthe training data, i.e., those that have only appearedin the verb-initial and noun-final positions respec-tively.
This is done because in Chinese, disyllabiccompound verbs tend to be head-initial, whereas di-syllabic compound nouns tend to be head-final.
Thefifth rule tags words such as d?
?ng-ya?o ?sting-bite?
asverbs, and the additional constraints prevent nounssuch as fu?-xia`ng ?lying-elephant?
from being taggedas verbs.
The last rule tags words such as xue?-be`i ?snow-quilt?
as nouns, but not zha?i-sha?o pick-tip?pick the tips?.One derivation rule for trisyllabic words has a spe-cial status.
Following the tagging guidelines of ourtraining corpus, it tags a word ABC as verb/deverbalnoun (v/vn) if C is the suffix hua` ?-ize?.
Disambigua-tion is left to the statistical models.4.2 The Trigram ModelThe trigram model is used because it captures the in-formation about the POS context of unknown wordsand returns a tag for each unknown word.
We as-sume that the unknown POS depends on the previ-ous two POS tags, and calculate the trigram proba-bility P (t3|t1, t2), where t3 stands for the unknown3POS, and t1 and t2 stand for the two previous POStags.
The POS tags for known words are taken fromthe tagged training corpus.
Following Brants (2000),we first calculate the maximum likelihood probabil-ities P?
for unigrams, bigrams, and trigrams as in(1-3).
To handle the sparse-data problem, we usethe smoothing paradigm that Brants reported as de-livering the best result for the TnT tagger, i.e., thecontext-independent variant of linear interpolationof unigrams, bigrams, and trigrams.
A trigram prob-ability is then calculated as in (4).P?
(t3) = f(t3)/N (1)P?
(t3|t2) = f(t2, t3)/f(t2) (2)P?
(t3|t1, t2) = f(t1, t2, t3)/f(t1, t2) (3)P (t3|t1, t2) = ?1P?
(t3) + ?2P?
(t3|t2) + ?3P?
(t3|t1, t2) (4)As in Brants (2000), ?1 + ?2 + ?3 = 1, and thevalues of ?1, ?2, and ?3 are estimated by deletedinterpolation, following Brants?
algorithm for calcu-lating the weights for context-independent linear in-terpolation when the n-gram frequencies are known.4.3 Wu and Jiang?s (2000) Statistical ModelThere are several reasons for integrating another sta-tistical model in the model.
The rule-based model isexpected to yield high precision, as over-generationis minimized, but it is bound to suffer low recall fordisyllabic words.
The trigram model covers all un-known words, but its precision needs to be boosted.Wu and Jiang?s (2000) model provides a good com-plement for the two, because it achieves a higherrecall than the rule-based model and a higher pre-cision than the trigram model for disyllabic words.As our training corpus is relatively small, this modelwill suffer a low recall for longer words, but thoseare handled effectively by the rule-based model.
Inprinciple, other statistical models can also be used,but Wu and Jiang?s model appears more appealingbecause of its relative simplicity and higher or com-parable precision.
It is used to handle disyllabic andtrisyllabic unknown words only, as recall drops sig-nificantly for longer words.4.4 Combining ModelsTo determine the best way to combine the threemodels, their individual performances are evaluatedfor each unknown wordif the trigram model returns one single guess, take itelse if the rule-based model returns a non-v/vn tag, take itelse if the rule-based model returns a v/vn tagif W&J?s model returns a list of guesseseliminate non-v/vn tags on that list and return therest of itelse eliminate non-v/vn tags on the list returned by thetrigram model and return the rest of itelse if W&J?s model returns a list of guesses, take itelse return the list of guesses returned by the trigrammodelFigure 2: Algorithm for combining modelsin the training data first to identify their strengths.Based on that evaluation, we come up with the al-gorithm in Figure 2.
For each unknown word, if thetrigram model returns exactly one POS tag, that tagis prioritized, because in the training data, such tagsturn out to be always correct.
Otherwise, the guessreturned by the rule-based model is prioritized, fol-lowed by Wu and Jiang?s model.
If neither of themreturns a guess, the guess returned by the trigrammodel is accepted.
This order of priority is based onthe precision of the individual models in the train-ing data.
If the rule-based model returns the ?v/vn?guess, we first check which of the two tags rankshigher in the list of guesses returned by Wu andJiang?s model.
If that list is empty, we then checkwhich of them ranks higher in the list of guesses re-turned by the trigram model.5 Results5.1 Experiment SetupThe different models are trained and tested on a por-tion of the Contemporary Chinese Corpus of PekingUniversity (Yu et al, 2002), which is segmented andPOS tagged.
This corpus uses a tagset consisting of40 tags.
We consider unknown words that are 1) twoor more characters long, 2) formed through redupli-cation, derivation, or compounding, and 3) in oneof the eight categories listed in Table 2.
The corpusconsists of all the news articles from People?s Dailyin January, 1998.
It has a total of 1,121,016 tokens,including 947,959 word tokens and 173,057 punc-tuation marks.
90% of the data are used for train-ing, and the other 10% are reserved for testing.
Wedownloaded a reference lexicon4 containing 119,7914From http://www.mandarintools.com/segmenter.html.4entries.
A word is considered unknown if it is in thewordlist extracted from the training or test data butis not in the reference lexicon.
Given this defini-tion, we first train and evaluate the individual mod-els on the training data and then evaluate the finalcombined model on the test data.
The distributionof unknown words is summarized in Table 3.Tag Descriptiona Adjectivead Deadjectval adverban Deadjectival nounn Nounv Verbvn Deverbal nounvd Deverbal adjectivez Stative adjective and adverbTable 2: Categories of considered unknown wordsChars Training Data Test DataTypes Tokens Types Tokens2 2611 4789 387 4643 3818 7378 520 7644 490 1229 74 1255+ 188 698 20 56Total 7107 14094 1001 1509Table 3: Unknown word distribution in the data5.2 Results for the Individual ModelsThe results for the rule-based model are listed in Ta-ble 4.
Recall (R) is defined as the number of cor-rectly tagged unknown words divided by the totalnumber of unknown words.
Precision (P) is definedas the number of correctly tagged unknown wordsdivided by the number of tagged unknown words.The small number of words tagged ?v/vn?
are ex-cluded in the count of tagged unknown words forcalculating precision, as this tag is not a final guessbut is returned to reduce the search space for thestatistical models.
F-measure (F) is computed as2 ?
RP/(R + P ).
The rule-based model achievesvery high precision, but recall for disyllabic wordsis low.The results for the trigram model are listed in Ta-ble 5.
Candidates are restricted to the eight POS cat-egories listed in Table 2 for this model.
Precision forthe best guess in both datasets is about 62%.The results for Wu and Jiang?s model are listed inTable 6.
Recall for disyllabic words is much higherthan that of the rule-based model.
Precision for di-syllabic words reaches mid 70%, higher than that ofthe trigram model.
Precision for trisyllabic words isvery high, but recall is low.Chars Data R P F2 Training 24.05 96.94 38.54Test 27.66 96.89 43.033 Training 93.50 99.83 96.56Test 93.72 99.86 96.694 Training 98.70 99.02 98.86Test 99.20 99.20 99.205+ Training 99.86 100 99.93Test 100 100 100Total Training 70.60 99.40 82.56Test 69.72 99.34 81.94Table 4: Results for the rule-based modelGuesses 1-Best 2-Best 3-BestTraining 62.01 93.63 96.21Test 62.96 92.64 94.30Table 5: Results for the trigram modelChars Data R P F2 Training 65.19 75.57 67.00Test 63.82 77.92 70.173 Training 59.50 98.41 74.16Test 55.63 99.07 71.25Table 6: Results for Wu and Jiang?s (2000) model5.3 Results for the Combined ModelTo evaluate the combined model, we first define theupper bound of the precision for the model as thenumber of unknown words tagged correctly by atleast one of the three models divided by the totalnumber of unknown words.
The upper bound is91.10% for the training data and 91.39% for the testdata.
Table 7 reports the results for the combinedmodel.
The overall precision of the model reaches89.32% in the training data and 89.00% in the testdata, close to the upper bounds.6 Discussion and ConclusionThe results indicate that the three models have dif-ferent strengths and weaknesses.
Using rules that donot overgenerate and that are sensitive to the type,length, and internal structure of unknown words,5Chars Training Test2 73.27 74.473 97.15 97.254 98.78 99.205+ 100 100Total 89.32 89.00Table 7: Results for the combined modelthe rule-based model achieves high precision for allwords and high recall for longer words, but recall fordisyllabic words is low.
The trigram model makesuse of the contextual information of unknown wordsand solves the recall problem, but its precision is rel-atively low.
Wu and Jiang?s (2000) model comple-ments the other two, as it achieves a higher recallthan the rule-based model and a higher precisionthan the trigram model for disyllabic words.
Thecombined model outperforms each individual modelby effectively combining their strengths.The results challenge the reasons given in previ-ous studies for rejecting the rule-based model.
Over-generation is a problem only if one attempts to writerules to cover the complete set of unknown words.
Itcan be controlled if one prefers precision over recall.To this end, the internal structure of the unknownwords provides very useful information.
Resultsfor the rule-based model also suggest that as un-known words become longer and the fluidity of theircomponent words/morphemes reduces, they becomemore predictable and generalizable by rules.The results achieved in this study prove a signif-icant improvement over those reported in previousstudies.
To our knowledge, the best result on thistask was reported by Chen et al (1997), which was69.13%.
However, they considered fourteen POScategories, whereas we examined only eight.
Thisdifference is brought about by the different tagsetsused in the different corpora and the decision to in-clude or exclude proper names and numeric typecompounds.
To make the results more compara-ble, we replicated their model, and the results wefound were consistent with what they reported, i.e.,69.12% for our training data and 68.79% for our testdata, as opposed to our 89.32% and 89% respec-tively.Several avenues can be taken for future research.First, it will be useful to identify a statistical modelthat achieves higher precision for disyllabic words,as this seems to be the bottleneck.
It will also be rel-evant to apply advanced statistical models that canincorporate various useful information to this task,e.g., the maximum entropy model (Ratnaparkhi,1996).
Second, for better evaluation, it would behelpful to use a larger corpus and evaluate the in-dividual models on a held-out dataset, to compareour model with other models on more compara-ble datasets, and to test the model on other logo-graphic languages.
Third, some grammatical con-straints may be used for the detection and correctionof tagging errors in a post-processing step.
Finally,as part of a bigger project on Chinese unknown wordresolution, we would like to see how well the generalmethodology used and the specifics acquired in thistask can benefit the identification and sense-taggingof unknown words.ReferencesThorsten Brants.
2000.
TnT ?
a statistical part-of-speechtagger.
In Proceedings of the 6th Conference on Ap-plied Natural Language Processing, pages 224?231.Keh-Jiann Chen and Ming-Hong Bai.
1998.
Unknownword detection for Chinese by a corpus-based learningmethod.
International Journal of Computational Lin-guistics and Chinese Language Processing, 3(1):27?44.Chao-Jan Chen, Ming-Hong Bai, and Keh-Jiann Chen.1997.
Category guessing for Chinese unknown words.In Proceedings of NLPRS, pages 35?40.Chooi-Ling Goh.
2003.
Chinese unknown word identifi-cation by combining statistical models.
Master?s the-sis, Nara Institute of Science and Technology, Japan.Adwait Ratnaparkhi.
1996.
A maximum entropy part-of-speech tagger.
In Proceedings of EMNLP, pages133?142.Richard Sproat.
2002.
Corpus-based methods in Chinesemorphology.
Tutorial at the 19th COLING.Andy Wu and Zixin Jiang.
2000.
Statistically-enhancednew word identification in a rule-based Chinese sys-tem.
In Proceedings of the 2nd Chinese LanguageProcessing Workshop, pages 46?51.Shiwen Yu, Huiming Duan, Xuefeng Zhu, and Bing Sun.2002.
The basic processing of Contemporary ChineseCorpus at Peking University.
Technical report, Insti-tute of Computational Linguistics, Peking University,Beijing, China.6
