Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 84?92,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsWeakly Supervised Slot Tagging with Partially Labeled Sequences from WebSearch Click LogsYoung-Bum Kim?Minwoo Jeong?Karl Stratos?Ruhi Sarikaya?
?Microsoft Corporation, Redmond, WA?Columbia University, New York, NY{ybkim, minwoo.jeong, ruhi.sarikaya}@microsoft.comstratos@cs.columbia.eduAbstractIn this paper, we apply a weakly-supervisedlearning approach for slot tagging using con-ditional random fields by exploiting websearch click logs.
We extend the constrainedlattice training of T?ackstr?om et al (2013) tonon-linear conditional random fields in whichlatent variables mediate between observationsand labels.
When combined with a novelinitialization scheme that leverages unlabeleddata, we show that our method gives signifi-cant improvement over strong supervised andweakly-supervised baselines.1 IntroductionA key problem in natural language processing(NLP) is to effectively utilize large amounts of unla-beled and partially labeled data in situations wherelittle or no annotations are available for a task ofinterest.
Many recent work tackled this problemmostly in the context of part-of-speech (POS) tag-ging by transferring POS tags from a supervised lan-guage via automatic alignment and/or constructingtag dictionaries from the web (Das and Petrov, 2011;Li et al, 2012; T?ackstr?om et al, 2013).In this work, we attack this problem in the con-text of slot tagging, where the goal is to find correctsemantic segmentation of a given query, which is animportant task for information extraction and natu-ral language understanding.
For instance, answeringthe question ?when is the new bill murray movie re-lease date??
requires recognizing and labeling keyphrases: e.g., ?bill murray?
as actor and ?movie?as media type.The standard approach to slot tagging involvestraining a sequence model such as a conditional ran-dom field (CRF) on manually annotated data.
Anobvious limitation of this approach is that it relieson fully labeled data, which is both difficult to adaptand changing tasks and schemas.
Certain films,songs, and books become more or less popular overtime, and the performance of models trained on out-dated data will degrade.
If not updated, modelstrained on live data feeds such as movies, songs andbooks become obsolete over time and their accuracywill degrade.
In order to achieve high accuracy con-tinuously data and even model schemas have to berefreshed on a regular basis.To remedy this limitation, we propose a weaklysupervised framework that utilizes the informationavailable in web click logs.
A web click log is amapping from a user query to URL link.
For ex-ample, users issuing queries about movies tend toclick on links from the IMDB.com or rottentoma-toes.com, which provide rich structured data for en-tities such as title of the movie (?The Matrix?
), thedirector (?The Wachowski Brothers?
), and the re-lease date (?1999?).
Web click logs present an op-portunity to learn semantic tagging models fromlarge-scale and naturally occurring user interactiondata (Volkova et al, 2013).While some previous works (Li et al, 2009) haveapplied a similar strategy to incorporate click logsin slot tagging, they do not employ recent advancesin machine learning to effectively leverage the in-complete annotations.
In this paper, we pursue andextend learning from partially labeled sequences, inparticular the approach of T?ackstr?om et al (2013).84Instead of projecting labels from a high-resource toa low-resource languages via parallel text and wordalignment, we project annotations from structureddata found in click logs.
This can be seen as a bene-fit since typically a much larger volume of click logdata is available than parallel text for low-resourcelanguages.We also extend the constrained lattice trainingmethod of T?ackstr?om et al (2013) from linear CRFsto non-linear CRFs.
We propose a perceptron train-ing method for hidden unit CRFs (Maaten et al,2011) that allows us to train with partially labeledsequences.
We show that combined with a novel pre-training methodology that leverages large quantitiesof unlabeled data, this training method achieves sig-nificant improvements over several strong baselines.2 Model definitions and training methodsIn this section, we describe the two sequence mod-els in our experiments: a conditional random field(CRF) of Lafferty et al (2001) and a hidden unitCRF (HUCRF) of Maaten et al (2011).
Note thatsince we only have partially labeled sequences, weneed a technique to learn from incomplete data.
Fora CRF, we follow a variant of the training methodof T?ackstr?om et al (2013).
In addition, we makea novel extension of their method to train a HU-CRF from partially labeled sequences.
The result-ing perceptron-style algorithm (Figure 2) is simplebut effective.
Furthermore, we propose an initializa-tion scheme that naturally leverages unlabeled datafor training a HUCRF.2.1 Partially Observed CRFA first-order CRF parametrized by ?
?
Rdde-fines a conditional probability of a label sequencey = y1.
.
.
yngiven an observation sequence x =x1.
.
.
xnas follows:p?
(y|x) =exp(?>?
(x, y))?y??Y(x)exp(?>?
(x, y?
))where Y(x) is the set of all possible label se-quences for x and ?
(x, y) ?
Rdis a global fea-ture function that decomposes into local featurefunctions ?
(x, y) =?nj=1?
(x, j, yj?1, yj) by thefirst-order Markovian assumption.
Given fully la-beled sequences {(x(i), y(i))}Ni=1, the standard train-ing method is to find ?
that maximizes the log like-lihood of the label sequences under the model withl2-regularization:?
?= arg max?
?RdN?i=1log p?(y(i)|x(i))?
?2||?||2Unfortunately, in our problem we do not have fullylabeled sequences.
Instead, for each token xjin se-quence x1.
.
.
xnwe have the following two sourcesof label information:?
A set of allowed label types Y(xj).
(Label dic-tionary)?
A label y?jtransferred from a source data.
(Op-tional: transferred label)T?ackstr?om et al (2013) propose a different objec-tive that allows training a CRF in this scenario.
Tothis end, they define a constrained lattice Y(x, y?)
=Y(x1, y?1)?
.
.
.?
Y(xn, y?n) where at each positionj a set of allowed label types is given as:Y(xj, y?j) ={{y?j} if y?jis givenY(xj) otherwiseIn addition to these existing constraints, we intro-duce constraints on the label structure.
In our seg-mentation problem, labels are structured (e.g., somelabel types cannot follow certain others).
We caneasily incorporate this restriction by disallowing in-valid label types as a post-processing step of theform:Y(xj, y?j)?
Y(xj, y?j) ?
Y(xj?1, y?j?1)where Y(xj?1, y?j?1) is the set of valid label typesthat can follow Y(xj?1, y?j?1).T?ackstr?om et al (2013) define a conditional prob-ability over label lattices for a given observation se-quence x:p?
(Y(x, y?
)|x) =?y?Y(x,y?)p?
(y|x)Given a label dictionary Y(xj) for every token typexjand training sequences {(x(i), y?(i))}Ni=1wherey?
(i)is (possibly non-existent) transferred labels for85Figure 1: Illustration of CRFs and hidden unit CRFsx(i)and, the new training method is to find ?
thatmaximizes the log likelihood of the label lattices:?
?= arg max?
?RdN?i=1log p?
(Y(x(i), y?(i))|x(i))?
?2||?||2Since this objective is non-convex, we find a localoptimum with a gradient-based algorithm.
The gra-dient of this objective at each example (x(i), y?
(i))takes an intuitive form:??
?log p?
(Y(x(i), y?(i))|x(i))??2||?||2=?y?Y(x(i),y?)p?(y|x(i))?
(x(i), y)??y?Y(x(i))p?(y|x(i))?
(x(i), y)?
?
?This is the same as the standard CRF training exceptthe first term where the gold features ?
(x(i), y(i))are replaced by the expected value of features in theconstrained lattice Y(x(i), y?
).2.2 Partially Observed HUCRFWhile effective, a CRF is still a linear model.
To seeif we can benefit from nonlinearity, we use a HU-CRF (Maaten et al, 2011): a CRF that introduces alayer of binary-valued hidden units z = z1.
.
.
zn?
{0, 1} for each pair of label sequence y = y1.
.
.
ynand observation sequence x = x1.
.
.
xn.
A HUCRFparametrized by ?
?
Rdand ?
?
Rd?defines a jointprobability of y and z conditioned on x as follows:p?,?
(y, z|x) =exp(?>?
(x, z) + ?>?
(z, y))?z??{0,1}ny??Y(x,z?)exp(?>?
(x, z?)
+ ?>?
(z?, y?
))where Y(x, z) is the set of all possible label se-quences for x and z, and ?
(x, z) ?
Rdand?
(z, y) ?
Rd?are global feature functions that de-compose into local feature functions:?
(x, z) =n?j=1?
(x, j, zj)?
(z, y) =n?j=1?
(zj, yj?1, yj)In other words, it forces the interaction betweenthe observations and the labels at each position j togo through a latent variable zj: see Figure 1 for il-lustration.
Then the probability of labels y is givenby marginalizing over the hidden units,p?,?
(y|x) =?z?{0,1}np?,?
(y, z|x)As in restricted Boltzmann machines (Larochelleand Bengio, 2008), hidden units are conditionallyindependent given observations and labels.
This al-lows for efficient inference with HUCRFs despitetheir richness (see Maaten et al (2011) for details).2.2.1 Training with partially labeled sequencesWe extend the perceptron training method of Maatenet al (2011) to train a HUCRF from partially labeledsequences.
This can be viewed as a modification ofthe constrained lattice training method of T?ackstr?omet al (2013) for HUCRFs.A sketch of our training algorithm is shown inFigure 2.
At each example, we predict the mostlikely label sequence with the current parameters.
Ifthis sequence does not violate the given constrainedlattice, we make no updates.
If it does, we pre-dict the most likely label sequence within the con-86Input: constrained lattices {(x(i), y?
(i))}Ni=1, step size ?Output: HUCRF parameters ?
:= {?, ?}1.
Initialize ?
randomly.2.
Repeatedly select i ?
{1 .
.
.
N} at random:(a) y??
arg maxy?Y(x(i))p?
(y|x(i))(b) If y?6?
Y(x(i), y?(i)):i.
y+?
arg maxy?Y(x(i),y?(i))p?(y|x(i))ii.
Make parameter updates:??
?
+ ?
????(p?
(y+, z+|x(i))?p?
(y?, z?|x(i)))where the following hidden units are com-puted in closed-form (see Gelfand et al(2010)):z+:= arg maxzp?
(z|x(i), y+)z?
:= arg maxzp?
(z|x(i), y?
)Figure 2: A sketch of the perceptron training algorithmfor a partially observed hidden unit CRF.strained lattice.
We treat this as the gold label se-quence, and perform the perceptron updates accord-ingly (Gelfand et al, 2010).
Even though this train-ing algorithm is quite simple, we demonstrate its ef-fectiveness in our experiments.2.2.2 Initialization from unlabeled dataRather than initializing the model parameters ran-domly, we propose an effective initialization scheme(in a similar spirit to the pre-training methods in neu-ral networks) that naturally leverages unlabeled data.First, we cluster observation types in unlabeleddata and treat the clusters as labels.
Then we traina fully supervised HUCRF on this clustered data tolearn parameters ?
for the interaction between obser-vations and hidden units ?
(x, z) and ?
for the inter-action between hidden units and labels ?
(z, y).
Fi-nally, for task/domain specific training, we discard?
and use the learned ?
to initialize the algorithm inFigure 2.
We hypothesize that if the clusters are non-trivially correlated to the actual labels, we can cap-ture the interaction between observations and hiddenunits in a meaningful way.3 Mining Click Log DataWe propose using search click logs which consistof queries and their corresponding web documents.Clicks are an implicit signal for related entities andinformation in the searched document.
In this work,we will assume that the web document is structuredand generated from an underlying database.
Dueto the structured nature of the web, this is not anunrealistic assumption (see Adamic and Huberman(2002) for discussion).
Such structural regularitiesmake obtaining annotated queries for learning a se-mantic slot tagger almost cost-free.As an illustration of how to project annotation,consider Figure 3, where we present an exampletaken from queries about video games.
In the fig-ure, the user queries are connected to a structureddocument via a click log, and then the document isparsed and stored in a structured format.
Then anno-tation types are projected to linked queries throughstructural alignment.
In the following subsectionswe describe each step in our log mining approach indetail.3.1 Click LogsWeb search engines keep a record of search queries,clicked document and URLs which reveal the userbehavior.
Such records are proven to be useful inimproving the quality of web search.
We focus onutilizing query-to-URL click logs that are essentiallya mapping from queries to structured web docu-ments.
In this work, we use a year?s worth of querylogs (from July 2013 to June 2014) at a commercialsearch engine.
We applied a simple URL normaliza-tion procedure to our log data including trimmingand removal of prefixes, e.g.
?www?.3.2 Parsing Structured Web DocumentA simple wrapper induction algorithm described inKushmerick (1997) is applied for parsing web docu-ments.
Although it involves manually engineering arule-based parser and is therefore website-specific, asingle wrapper often generates large amounts of datafor large structured websites, for example IMDB.Furthermore, it is very scalable to large quantities ofdata, and the cost of writing such a rule-based sys-87Figure 3: An example illustrating annotation projection via click-log and wrapper induction.tem is typically much lower than the annotation costof queries.Figure 4 shows the statistics of parsed web docu-ments on 24 domains with approximately 500 tem-plate rules.
One of the chosen domains in our ex-periment, Music, has over 130 million documentsparsed by our approach.3.3 Annotation Projection via StructuralAlignmentWe now turn to the annotation projection step wherestructural alignment is used to transfer type annota-tion from structured data to queries.
Note that this isdifferent from the word-based or phrase-based align-ment scenario in machine translation since we needto align a word sequence to a type-value pair.Let us assume that we are given the user query asa word sequence, w = w1, w2, .
.
.
, wnand a set ofstructured data, s = {s1, s2, .
.
.
, sm}, where siisa pair of slot-type and value.
We define a measure-ment of dissimilarity between word tokens and slots,dist(wi, sj) = 1 ?
sim(wi, sj) where sim(?, ?)
iscosine similarity over character trigrams of wiandsj.
Next we construct a n-by-n score matrix S ofwhich element is maxjdist(wt?...t, sj) meaning thata score of the most similar type-value sjand a seg-ment {t?.
.
.
t} where 1 ?
t?< t ?
n. Finally,given this approximate score matrix S, we use a dy-namic programming algorithm to find the optimalsegments to minimize the objective function:T (t) = mint?<tT (t?
)S(t?, t).Our approach results in a large amount of high-quality partially-labeled data: 314K, 1.2M, and1.1M queries for the Game, Movie and Music do-main, respectively.4 ExperimentsTo test the effectiveness of our approach, we per-form experiments on a suite of three entertainmentdomains for slot tagging: queries about movies, mu-sic, and games.
For each domain, we have two typesof data: engineered data and log data.
Engineereddata is a set of synthetic queries to mimic the be-havior of users.
This data is created during devel-opment at which time no log data is available.
Logdata is a set of queries created by actual users us-ing deployed spoken dialogue systems: thus it is di-rectly transcribed from users?
voice commands withautomatic speech recognition (ASR).
In general wefound log data to be fairly noisy, containing manyASR and grammatical errors, whereas engineereddata consisted of clean, well-formed text.Not surprisingly, synthetic queries in engineereddata are not necessarily representative of real queriesin log data since it is difficult to accurately simu-late what users?
queries will be before a fully func-tioning system is available and real user data canbe gathered.
Hence this setting can greatly benefitfrom weakly-supervised learning methods such asours since it is critical to learn from new incominglog data.
We use search engine log data to projectlattice constraints for weakly supervised learning.In this setup, a user issues a natural languagequery to retrieve movies, music titles, games and/orinformation there of.
For instance, a user could say88Millions125102050100200500BusinessPeopleConsumer_ProductVideoMusicImageBusiness_ListingEvent_Listing TravelBookPeople_ListingPublication FoodApplication FilmComputerLocation_ReferenceDining TV EventProperty_ListingAttractionCountryVideo_GameFigure 4: Statistics of structured web documents.
The vertical axis shows the number of documents (in millions); thehorizontal axis shows the web domain types.
?play the latest batman movie?
or ?find beyonce?smusic?.
Our slot sequence tagger is trained withvariants of CRF using lexical features, gazetteers,Brown clusters and context words.
The domainsconsist of 35 slot types for movies, 25 for music and24 for games.
Slot types correspond to both namedentities (e.g., game name, music title, movie name)as well as more general categories (genre, mediatype, description).
Table 1 shows the size of thedatasets used in our experiments.Domains Training Testgames 32017 5508movies 48173 7074music 46377 8890Table 1: Labeled data set size for games, movies and mu-sic domains partitioned into training and test set.Domains Engineered Log Diff.games 89.63 68.58 21.05movies 88.67 74.21 14.45music 88.77 37.13 51.64AVG.
89.02 59.97 29.05Table 2: The difference in F1 performance of CRF mod-els trained only on engineered data but tested on both en-gineered and log data.4.1 Discrepancy between Engineered Data andLog DataTo empirically highlight the need for learning fromreal user queries, we first train a standard CRF onthe (fully labeled) engineered data and test it on thelog data.
We have manually annotated some log datafor evaluation purposes.
For features in the CRF, weuse n-grams, gazetteer, and clusters.
The clusterswere induced from a large body of unlabeled datawhich consist of log data and click log data.
Table 2shows the F1 scores in this experiment.
They indi-cate that a model fully supervised with engineereddata performs very poorly on log data.
The differ-ence between the scores within engineered data andthe scores in log data is very large (29.05 absoluteF1).4.2 Experiments with CRF VariantsOur main contribution is to leverage search log datato improve slot tagging in spoken dialogue systems.In this section, we assume that we have no log datain training slot taggers.1For parameter estimation, both CRFs andPOCRFs employ L-BFGS, while POHUCRF uses1In practice, this assumption is not necessarily true becausea deployed system can benefit from actual user logs.
However,this controlled setting allows us to show the benefits of employ-ing web search click log data.89Domains games music movies AVG.CRF 74.21 37.13 68.58 59.97POCRF 77.23 44.55 76.89 66.22POHCRF 78.93 46.81 76.46 67.40POHCRF+ 79.28 47.35 78.33 68.32Table 3: The F1 performance of variants of CRF acrossthree domains, test on log dataaverage perceptron.
We did not see a significant dif-ference between perceptron and LBFGS in accuracy,but perceptron is faster and thus favorable for train-ing complex HUCRF models.
We used 100 as themaximum iteration count and 1.0 for the L2 regular-ization parameter.
The number of hidden variablesper token is set to 300.
The same features describedin the previous section are used here.We perform experiments with the following CRFvariants (see Section 2):?
CRF: A fully supervised linear-chain CRFtrained with manually labeled engineered sam-ples.?
POCRF: A partially observed CRF ofT?ackstr?om et al (2013) trained with bothmanually labeled engineered samples and clicklogs.?
POHUCRF: A partially observed hidden unitCRF (Figure 2) trained with both manually la-beled engineered samples and click logs.?
POHUCRF+: POHUCRF with pre-training.Table 3 summarizes the performance of theseCRF variants.
All results were tested on log dataonly.
A standard CRF without click log data yields59.97% of F1 on average.
By using click log data,POCRF consistently improves F1 scores across do-mains, resulting into 66.22% F1 measure.
Ourmodel POHUCRF achieves extra gains on gamesand music, achieving 67.4% F1 measure on aver-age.
Finally, the pre-training approach yields signif-icant additional gains across all domains, achieving68.32% average performance.
Overall we achievea relative error reduction of about 21% over vanillaCRFs.Domain CRF HUCRF HUCRF+alarm 91.79 91.79 91.96calendar 87.60 87.65 88.21communication 91.84 92.49 92.80note 87.72 88.48 88.72ondevice 89.37 90.14 90.64places 88.02 88.64 88.99reminder 87.72 89.21 89.72weather 96.93 97.38 97.63AVG.
90.12 90.75 91.08Table 4: Performance comparison between HUCRF andHUCRF with pre-training.4.3 Weakly-Supervised Learning withoutProjected Annotations via Pre-TrainingWe also present experiments within Cortana per-sonal assistant domain where the click log data isnot available.
The amount of training data we usedwas from 50K to 100K across different domains andthe test data was from 5k to 10k.
In addition, theunlabeled log data were used and their amount wasfrom 100k to 200k.In this scenario, we have access to both engi-neered and log data to train a model.
However, wedo not have access to web search click log data.
Thegoal of these experiments is to show the effective-ness of the HUCRF and pre-training method in theabsence of weakly supervised labels projected viaclick logs.
Table 4 shows a series of experiments oneight domains.For all domains other than alarm, using non-linearCRF (HUCRF) improve performance from 90.12%to 90.75% on average.
Initializing HUCRF with pre-training (HUCRF+) boosts the performance up to91.08%, corresponding to a 10% decrease in errorrelative to a original CRF.
Notably in the weatherand reminder domains, we have relative error re-duction of 23 and 16%, respectively.
We speculatethat pretraining is helpful because it provides bet-ter initialization for training HUCRF: initializationis important since the training objective of HUCRFis non-convex.In general, we find that HUCRF delivers betterperformance than standard CRF: when the trainingprocedure is initialized with pretraining (HUCRF+),it improves further.905 Related WorkPrevious works have explored weakly supervisedslot tagging using aligned labels from a database asconstraints.
Wu and Weld (2007) train a CRF onheuristically annotated Wikipedia articles with rela-tions mentioned in their structured infobox data.
Liet al (2009) applied a similar strategy incorporatingstructured data projected through click-log data asboth heuristic labels and additional features.
Knowl-edge graphs and search logs have been also consid-ered as extra resources (Liu et al, 2013; El-Kahky etal., 2014; Anastasakos et al, 2014; Sarikaya et al,2014; Marin et al, 2014).Distant supervision methods (Mintz et al, 2009;Riedel et al, 2010; Surdeanu et al, 2012; Agichteinand Gravano, 2000) learn to extract relations fromtext using weak supervision from related structureddata sources such as Freebase or Wikipedia.
Theseapproaches rely on named entity recognition as apre-processing step to identify text spans corre-sponding to candidate slot values.
In contrast, ourapproach jointly segments and predicts slots.Works on weakly supervised POS tagging arealso closely related to ours (Toutanova and Johnson,2007; Haghighi and Klein, 2006).
T?ackstr?om et al(2013) investigate weakly supervised POS taggingin low-resource languages, combining dictionaryconstraints and labels projected across languages viaparallel corpora and automatic alignment.
Our workcan be seen as an extension of their approach to thestructured-data projection setup presented by Li etal.
(2009).
A notable component of our extension isthat we introduce a training algorithm for learning ahidden unit CRF of Maaten et al (2011) from par-tially labeled sequences.
This model has a set of bi-nary latent variables that introduce non-linearity bymediating between observations and labels.6 ConclusionsIn this paper, we applied weakly-supervised learn-ing approach for slot tagging, projecting annota-tions from structured data to user queries by lever-aging click log data.
We extended the T?ackstr?omet al (2013) model to nonlinear CRFs by introduc-ing latent variables and applying a novel pre-trainingmethodology.
The proposed techniques provide aneffective way to leverage incomplete and ambiguousannotations from large amounts of naturally occur-ring click log data.
All of our improvements takentogether result in a 21% error reduction over vanillaCRFs trained on engineered data used during systemdevelopment.ReferencesLada A Adamic and Bernardo A Huberman.
2002.
Zipfslaw and the internet.
Glottometrics, 3(1):143?150.Eugene Agichtein and Luis Gravano.
2000.
Snowball:Extracting relations from large plain-text collections.In Proceedings of the fifth ACM conference on Digitallibraries.Tasos Anastasakos, Young-Bum Kim, and Anoop Deo-ras.
2014.
Task specific continuous word represen-tations for mono and multi-lingual spoken languageunderstanding.
In Acoustics, Speech and Signal Pro-cessing (ICASSP), 2014 IEEE International Confer-ence on, pages 3246?3250.
IEEE.Dipanjan Das and Slav Petrov.
2011.
Unsupervisedpart-of-speech tagging with bilingual graph-based pro-jections.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies-Volume 1, pages 600?609.
Association for Computational Linguistics.Ali El-Kahky, Xiaohu Liu, Ruhi Sarikaya, Gokhan Tur,Dilek Hakkani-Tur, and Larry Heck.
2014.
Extend-ing domain coverage of language understanding sys-tems via intent transfer between domains using knowl-edge graphs and search query click logs.
In Acoustics,Speech and Signal Processing (ICASSP), 2014 IEEEInternational Conference on, pages 4067?4071.
IEEE.Andrew Gelfand, Yutian Chen, Laurens Maaten, and MaxWelling.
2010.
On herding and the perceptron cyclingtheorem.
In Advances in Neural Information Process-ing Systems, pages 694?702.Aria Haghighi and Dan Klein.
2006.
Prototype-drivenlearning for sequence models.
In Proceedings ofthe main conference on Human Language TechnologyConference of the North American Chapter of the As-sociation of Computational Linguistics.Nicholas Kushmerick.
1997.
Wrapper induction forinformation extraction.
Ph.D. thesis, University ofWashington.John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Probabilis-tic models for segmenting and labeling sequence data.In Proceedings of the 18th International Conferenceon Machine Learning, pages 282?289.Hugo Larochelle and Yoshua Bengio.
2008.
Classifi-cation using discriminative restricted boltzmann ma-91chines.
In Proceedings of the 25th international con-ference on Machine learning.Xiao Li, Ye-Yi Wang, and Alex Acero.
2009.
Extractingstructured information from user queries with semi-supervised conditional random fields.
In Proceedingsof the 32nd international ACM SIGIR conference onResearch and development in information retrieval.Shen Li, Joao V Grac?a, and Ben Taskar.
2012.
Wiki-ly supervised part-of-speech tagging.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 1389?1398.
Asso-ciation for Computational Linguistics.Xiaohu Liu, Ruhi Sarikaya, Chris Brockett, Chris Quirk,William B Dolan, and Bill Dolan.
2013.
Paraphrasefeatures to improve natural language understanding.In INTERSPEECH, pages 3776?3779.Laurens Maaten, Max Welling, and Lawrence K Saul.2011.
Hidden-unit conditional random fields.
In In-ternational Conference on Artificial Intelligence andStatistics.Alex Marin, Roman Holenstein, Ruhi Sarikaya, and MariOstendorf.
2014.
Learning phrase patterns for textclassification using a knowledge graph and unlabeleddata.
In Fifteenth Annual Conference of the Interna-tional Speech Communication Association.Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP: Volume 2-Volume 2.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions with-out labeled text.
In Machine Learning and KnowledgeDiscovery in Databases.Ruhi Sarikaya, Asli Celikyilmaz, Anoop Deoras, andMinwoo Jeong.
2014.
Shrinkage based features forslot tagging with conditional random fields.
In Proc.of Interspeech.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, andChristopher D Manning.
2012.
Multi-instance multi-label learning for relation extraction.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning.Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, Ryan Mc-Donald, and Joakim Nivre.
2013.
Token and type con-straints for cross-lingual part-of-speech tagging.Kristina Toutanova and Mark Johnson.
2007.
A bayesianlda-based model for semi-supervised part-of-speechtagging.
In Advances in Neural Information Process-ing Systems, pages 1521?1528.Svitlana Volkova, Pallavi Choudhury, Chris Quirk, BillDolan, and Luke S Zettlemoyer.
2013.
Lightly super-vised learning of procedural dialog systems.
In ACL.Fei Wu and Daniel S Weld.
2007.
Autonomously se-mantifying wikipedia.
In Proceedings of the sixteenthACM conference on Conference on information andknowledge management.92
