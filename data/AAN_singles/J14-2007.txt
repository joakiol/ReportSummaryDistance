Identification of Multiword Expressionsby Combining Multiple LinguisticInformation SourcesYulia Tsvetkov?Carnegie Mellon UniversityShuly Wintner?
?University of HaifaWe propose a framework for using multiple sources of linguistic information in the task ofidentifying multiword expressions in natural language texts.
We define various linguisticallymotivated classification features and introduce novel ways for computing them.
We then man-ually define interrelationships among the features, and express them in a Bayesian network.The result is a powerful classifier that can identify multiword expressions of various typesand multiple syntactic constructions in text corpora.
Our methodology is unsupervised andlanguage-independent; it requires relatively few language resources and is thus suitable for alarge number of languages.
We report results on English, French, and Hebrew, and demonstratea significant improvement in identification accuracy, compared with less sophisticated baselines.1.
IntroductionMultiword expressions (MWEs) are lexical items that consist of multiple orthographicwords (ad hoc, New York, look up).
MWEs constitute a significant portion of the lexiconof any natural language (Jackendoff 1997; Erman and Warren 2000; Sag et al.
2002).
Theyare a heterogeneous class of constructions with diverse sets of characteristics, distin-guished by their idiosyncratic behavior.
Morphologically, some MWEs allow some oftheir constituents to freely inflect while restricting (or preventing) the inflection of otherconstituents.
In some cases MWEs may allow constituents to undergo non-standardmorphological inflections that they would not undergo in isolation.
Syntactically, someMWEs behave like words and other are phrases; some occur in one rigid pattern (and afixed order), and others permit various syntactic transformations.
The most characteris-tic property of MWEs is their semantic opacity, although the compositionality of MWEsis gradual, and ranges from fully compositional to completely idiomatic (Bannard,Baldwin, and Lascarides 2003).?
2014 Association for Computational Linguistics?
Language Technologies Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA15213-3891.
E-mail: ytsvetko@cs.cmu.edu.??
Department of Computer Science, University of Haifa Mount Carmel, 31905 Haifa, Israel.E-mail: shuly@cs.haifa.ac.il.Submission received: 6 January 2013; revised submission received: 13 June 2013; accepted for publication:16 August 2013.doi:10.1162/COLI a 00177Computational Linguistics Volume 40, Number 2Because of their prevalence and irregularity, MWEs must be stored in lexiconsof natural language processing (NLP) applications.
Awareness of MWEs was provenbeneficial for a variety of applications, including information retrieval (Doucet andAhonen-Myka 2004), building ontologies (Venkatsubramanyan and Perez-Carballo2004), text alignment (Venkatapathy and Joshi 2006), and machine translation (Baldwinand Tanaka 2004; Uchiyama, Baldwin, and Ishizaki 2005; Carpuat and Diab 2010).We propose a novel architecture for identifying MWEs, of various types and syn-tactic categories, in monolingual corpora.
Unlike much existing work, which focuseson a particular syntactic construction, our approach addresses MWEs of various typesby zooming in on the general idiosyncratic properties of MWEs rather than on spe-cific properties of each subclass thereof.
Addressing multiple types of MWEs has itslimitations: The task is less well-defined, one cannot rely on specific properties ofa particular construction, and the type of the MWE is not extracted along with thecandidate expression.
Nevertheless, there are clear benefits to such an approach.
Certainapplications can benefit from a large, albeit untyped, mixed bag of MWEs; machinetranslation is an obvious candidate (Lambert and Banchs 2005; Ren et al.
2009; Bouamor,Semmar, and Zweigenbaum 2012).
Another use, which motivates our current work, isthe construction of computational lexicons.
Clearly, manual supervision is required be-fore MWE candidates are added to a high-precision lexicon, but our approach providesthe lexicographer with a large-scale set of potential candidates.We focus on bigrams only in this work, that is, on MWEs consisting of two consec-utive tokens.
Many of the features we design, as well as the general architecture, can inprinciple be extended to longer MWEs, but we do not address longer (and, in particular,the harder case of non-contiguous) MWEs here.
The architecture uses Bayesian net-works (Pearl 1985) to express multiple interdependent linguistically motivated features.First, we automatically generate a small (training) set of MWE and non-MWEbigrams (positive and negative instances, respectively) from a small parallel corpus.We then define a set of linguistically motivated features that embody observed char-acteristics of MWEs.
We augment these by features that reflect collocation measures.Finally, we define dependencies among these features, expressed in the structure of aBayesian network model, which we then use for classification.
A Bayesian network (BN)is a directed graph whose nodes express the features used for classification and whoseedges define causal relationships among these features.
In this architecture, learningdoes not result in a black box, expressed solely as feature weights.
Rather, the structureof the BN allows us to study the impact of different MWE features on the classification.The result is a new method for identifying MWEs of various types in text corpora.
Itcombines statistics with an array of linguistically motivated features, organized in anarchitecture that reflects interdependencies among the features.The contribution of this work is manifold.1 First, we use existing approaches toMWE extraction to automatically generate training material.
Specifically, we use ourearlier work (Tsvetkov and Wintner 2012) to extract a set of positive and negative MWEcandidates from a small parallel corpus, and use them for training a BN that can thenextract a new set of MWEs from a potentially much larger monolingual corpus.
As1 This article is a thoroughly revised and extended version of Tsvetkov and Wintner (2011).
Whereas themethodology of that paper required minor supervision, we now present a completely unsupervisedapproach.
We added several linguistically motivated features to the classification task.
We demonstrateresults on two new languages, English and French, to emphasize the generality of the method.Additional extensions include a more complete literature survey and, because new languages are added,different, more reliable data sets for evaluating our results.450Tsvetkov and Wintner Identification of Multiword Expressionsa result, our method is completely unsupervised (more precisely, it does not requiremanual annotation; we do need several language resources, see Section 3.2).Second, we propose several linguistically motivated features that can be computedfrom data and that are demonstrably productive for improving the accuracy of MWEidentification.
These features focus on the expression of linguistic idiosyncrasies of var-ious types, a phenomenon typical of MWEs.
Some of these features are commonplace,but others are new, or are implemented in novel ways.
In particular, we account forthe morphological idiosyncrasy of MWEs using a histogram of the number of inflectedforms, in a technique that draws from image processing.
We also use frequency his-tograms to model the semantic contexts of MWEs.Finally, the methodology we advocate is not language-specific; given relatively fewlanguage resources, it can be easily adapted to new languages.
We demonstrate thegenerality of our methodology by applying it to three languages: English, French, andHebrew.
Our evaluation shows that the use of linguistically motivated features resultsin a reduction of between one quarter and one third of the errors compared with acollocation baseline; organizing the knowledge in a Bayesian network reduces the errorrate by an additional 3?9%.After discussing related work in the next section (borrowing from Tsvetkov andWintner [2012]), we motivate in Section 3 the methodology we propose, and list the re-sources needed for implementing it.
Section 4 discusses the linguistically motivated fea-tures and their implementation; the organization of the Bayesian network is describedin Section 5.
We explain how we generate training materials in Section 6.
Section 7provides a thorough evaluation of the results.
We conclude with suggestions for futureresearch.2.
Related WorkEarly approaches to MWE identification concentrated on their collocational behavior(Church and Hanks 1990).
One of the first approaches was implemented as Xtract(Smadja 1993): Here, word pairs that occur with high frequency within a context offive words in a corpus are first collected, and are then ranked and filtered accordingto contextual considerations, including the parts of speech of their neighbors.
Pecina(2008) compares 55 different association measures in ranking German Adj-N and PP-Verb collocation candidates.
He shows that combining different collocation measuresusing standard statistical classification methods improves over using a single colloca-tion measure.
Other results (Chang, Danielsson, and Teubert 2002; Villavicencio et al.2007) suggest that some collocation measures (especially point-wise mutual informationand log-likelihood) are superior to others for identifying MWEs.Co-occurrence measures alone are probably not enough to identify MWEs, and theirlinguistic properties should be exploited as well (Piao et al.
2005).
Hybrid methods thatcombine word statistics with linguistic information exploit morphological, syntactic,and semantic idiosyncrasies to extract idiomatic MWEs.Cook, Fazly, and Stevenson (2007), for example, use prior knowledge about theoverall syntactic behavior of an idiomatic expression to determine whether an instanceof the expression is used literally or idiomatically.
They assume that in most cases,idiomatic usages of an expression tend to occur in a small number of canonical formsfor that idiom; in contrast, the literal usages of an expression are less syntacticallyrestricted, and are expressed in a greater variety of patterns, involving inflected formsof the constituents.451Computational Linguistics Volume 40, Number 2Ramisch et al.
(2008) evaluate a number of association measures on the task ofidentifying English verb-particle constructions and German adjective-noun pairs.
Theyshow that adding linguistic information (mostly POS and POS-sequence patterns) to theassociation measure yields a significant improvement in performance over using purefrequency.Several works address the lexical fixedness or syntactic fixedness of (certain typesof) MWEs in order to extract them from texts.
An expression is considered lexicallyfixed if replacing any of its constituents by a semantically (and syntactically) similarword generally results in an invalid or literal expression.
Syntactically fixed expressionsprohibit (or restrict) syntactic variation.
For example, Van de Cruys and Villada Moiro?n(2007) use lexical fixedness to extract Dutch verb-noun idiomatic combinations (VNICs).Bannard (2007) uses syntactic fixedness to identify English VNICs.
Another work usesboth the syntactic and the lexical fixedness of VNICs in order to distinguish them fromnon-idiomatic ones, and eventually to extract them from corpora (Fazly and Stevenson2006).
Recently, Green et al.
(2011) use parsing, and in particular Tree SubstitutionGrammars, for identifying MWEs in French.Semantic properties of MWEs can be used to distinguish between compositionaland non-compositional (idiomatic) expressions.
Katz and Giesbrecht (2006) andBaldwin et al.
(2003) use Latent Semantic Analysis (LSA) for this purpose.
They showthat compositional MWEs appear in contexts more similar to their constituents thannon-compositional MWEs.
For example, the co-occurrence measured by LSA betweenthe expression kick the bucket and the word die is much higher than co-occurrenceof this expression and its component words.
The disadvantage of this methodology isthat to distinguish between idiomatic and non-idiomatic usages of the MWE it relies onthe MWE?s known idiomatic meaning, and this information is usually not available.
Inaddition, this approach fails when only idiomatic or only literal usages of the MWE areoverwhelmingly frequent.Although these approaches are in line with ours, they require lexical semanticresources (e.g., a database that determines semantic similarity among words) andsyntactic resources (parsers) that are unavailable for many languages.
Our approachonly requires morphological processing and a bilingual dictionary, which are morereadily available for several languages.
Note also that these approaches target a specificsyntactic construction, whereas ours is appropriate for various types of MWEs.Several properties of Hebrew MWEs are described by Al-Haj (2010); Al-Haj andWintner (2010) use them in order to construct a support vector machine (SVM) classifierthat can distinguish between MWE and non-MWE noun-noun constructions in Hebrew.The features of the SVM reflect several morphological and morphosyntactic propertiesof such constructions.
The resulting classifier performs much better than a naive base-line, reducing the error rate by over one third.
We rely on some of these insights, as weimplement more of the linguistic properties of MWEs.
Again, our methodology is notlimited to a particular construction: Indeed, we demonstrate that our general methodol-ogy, trained on automatically generated, general training data, performs almost as wellas the noun-noun-specific approach of Al-Haj and Wintner (2010) on the very same dataset (Section 7).Recently, Tsvetkov and Wintner (2010b, 2012) introduced a general methodologyfor extracting MWEs from bilingual corpora, and applied it to Hebrew.
The resultswere a highly accurate set of Hebrew MWEs, of various types, along with their Englishtranslations.
A major limitation of this work is that it can only be used to identify MWEsin the bilingual corpus, and is thus limited in its scope.
We use this methodology toextract both positive and negative instances for our training set in the current work;452Tsvetkov and Wintner Identification of Multiword Expressionsbut we extrapolate the results much further by extending the method to monolingualcorpora, which are typically much larger than bilingual ones.Probabilistic graphical models are widely used in statistical machine learning ingeneral, and natural language processing in particular (Smith 2011).
Bayesian networksare an instance of such models, and have been used for classification in several naturallanguage applications.
For example, BNs have been used for POS tagging of unknownwords (Peshkin, Pfeffer, and Savova 2003), dependency parsing (Savova and Peshkin2005), and document classification (Lam, Low, and Ho 1997; Calado et al.
2003; Denoyerand Gallinari 2004).
Very recently, Ramisch et al.
(2010) used BN for Portuguese MWEidentification.
The features used for classification were of two kinds: (1) various colloca-tion measures; (2) bigrams aligned together by an automatic word aligner applied to aparallel (Portuguese?English) corpus.
A BN was used to combine the predictions of thevarious features on the test set, but the structure of the network is not described.
Thecombined classifier resulted in a much higher accuracy than any of the two methodsalone.
However, the use of BN is not central to this work, and its structure does notreflect any insights or intuitions on the structure of the problem domain or on inter-dependencies among features.We, too, acknowledge the importance of combining different sources of knowledgein the hard task of MWE identification.
In particular, we also believe that collocationmeasures are highly important for this task, but cannot completely solve the problem:Linguistically motivated features are crucial in order to improve the accuracy of theclassifier.
In this work we focus on various properties of different types of MWEs,and define general features that may accurately apply to some, but not necessarily all,of them.
An architecture of Bayesian networks is optimal for this task: It enables usto define weighted dependencies among features, such that certain features are moresignificant for identifying some class of MWEs, whereas others are more prominentin identifying other classes (although we never predefine these classes).
As we showherein, this architecture results in significant improvements over a more naive combi-nation of features.3.
Methodology3.1 MotivationThe task we address is identification of MWEs, of various types and syntactic construc-tions, in monolingual corpora.
These include proper names, noun phrases, verb-particlepairs, and so forth.
We focus on bigrams (MWEs consisting of two consecutive tokens)in this work; the methodology, however, can be extended to longer n-grams.
Severalproperties of MWEs make this task challenging: MWEs exhibit idiosyncrasies on avariety of levels, orthographic, morphological, syntactic, and of course semantic.
Such acomplex task calls for a combination of multiple approaches, and much research indeedsuggests ?hybrid?
approaches to MWE identification (Duan et al.
2009; Hazelbeck andSaito 2010; Ramisch et al.
2010; Weller and Fritzinger 2010).
We believe that Bayesiannetworks provide an optimal architecture for expressing various pieces of knowledgeaimed at MWE identification, for the following reasons (noted, e.g., by Heckerman1995): In contrast to many other classification methods, Bayesian networks canlearn (and express) causal relationships between features.
This facilitatesbetter understanding of the problem domain.453Computational Linguistics Volume 40, Number 2 Bayesian networks can encode not only statistical data, but alsoprior domain knowledge and human intuitions, in the form ofinterdependencies among features (a possibility that we use here).Furthermore, we try in this work to leverage the idiosyncrasy of MWEs and use it as atool for identifying them.Our definition of MWEs is operational: An expression is considered a MWE if ithas to be stored in the lexicon of some NLP application; typically, this is because theexpression exhibits some level of idiosyncratic behavior (semantic, syntactic, morpho-logical, orthographic, etc.).
In order to properly handle such expressions in downstreamapplications, the lexicon must store some specific information about the expression.
Thisworking definition motivates and drives our methodology: We leverage the idiosyn-cratic behavior of MWEs and define (Section 4) an array of features that capture andreflect this idiosyncrasy in order to extract MWEs from corpora.3.2 ResourcesAlthough our approach is in general not language-specific, applying it to any partic-ular language requires several language resources which we specify in this section.
Ingeneral, we require corpora (both monolingual and bilingual), morphological analyzersor stemmers, part-of-speech taggers, and bilingual dictionaries.
No deeper processingis assumed (e.g., no parsers or lexical semantic resources are needed).
The method weadvocate is thus appropriate for medium-density languages (Varga et al.
2005).To compute the features discussed in Section 4, we need large monolingual corpora.For English and French, we use the 109 corpora released for WMT-11 (Callison-Burchet al.
2011); the corpora were syntactically parsed using the Berkeley parser (Petrovand Klein 2007), but we only use the POS tags in this work.
For Hebrew, we use amonolingual corpus (Itai and Wintner 2008), which we pre-process as in Tsvetkov andWintner (2012): We use a morphological analyzer (Itai and Wintner 2008) to segmentword forms (separating prefixes and suffixes) and induce POS tags.
Summary statisticsfor each corpus are listed in Table 1.For some features we need access to the lemma of word tokens.
In Hebrew, theMILA morphological analyzer (Itai and Wintner 2008) provides the lemmas, but theparsed corpora we use in English and French do not.
We therefore use the DELAdictionaries of English and French, available from LADL as part of the Unitex project(http://www-igm.univ-mlv.fr/~unitex/).
The French dictionary lists 683,824 single-word entries corresponding to 102,073 lemmas, and 108,436 multiword entries corre-sponding to 83,604 MWEs.
The English dictionary is smaller, with 296,606 single-wordforms corresponding to 150,145 lemmas, and 132,990 multiword entries, correspondingTable 1Statistics of the monolingual corpora.English French HebrewTokens 447,073,250 522,964,336 46,239,285Types 2,421,181 2,416,269 188,572Bigram tokens 429,550,149 505,441,224 45,858,152Bigram types 22,929,768 21,428,007 5,698,581454Tsvetkov and Wintner Identification of Multiword ExpressionsTable 2Statistics of the bilingual corpora.English?French English?HebrewSentences 30,000 30,000 19,626 19,626Tokens 834,707 895,632 271,787 280,508Types 22,787 27,880 14,142 12,555Bigram tokens 804,704 865,632 252,183 280,506Bigram types 218,108 225,660 128,987 149,688to 69,912 MWEs.
If the corpus surface form is not listed in the dictionary, we use thesurface form in lieu of its lemma.
The multiword entries of the DELA dictionaries areonly used for evaluation.For some features we also need a bilingual dictionary.
For English?Hebrew, weuse a small dictionary consisting of 78,313 translation pairs.
Some of the entries arecollected manually, whereas others are produced automatically (Itai and Wintner2008; Kirschenbaum and Wintner 2010).
For English?French, because we are unable toobtain a good-quality dictionary, we use instead Giza++ (Och and Ney 2000) 1-1 wordalignments computed automatically from the entire WMT-11 parallel corpus.In order to prepare training material automatically (Section 6), we use small bilin-gual corpora.
For English?French, we use a random sample of 30,000 parallel sentencesfrom the WMT-11 corpus.
For English-Hebrew, we use the parallel corpus of Tsvetkovand Wintner (2010a).
Statistics of the parallel corpora are listed in Table 2.For evaluation we need lists of MWEs, ideally augmented by lists of non-MWEbigrams.
Such lists are notoriously hard to obtain.
As a general method of evaluation,we run 10-fold cross-validation evaluation using the training materials (which wegenerate automatically).
Additionally, we use three sets of MWEs for evaluation.
First,we extract all the MWE entries from the English WordNet (Miller et al.
1990); we use theWordNet version that is distributed with NLTK (Bird, Klein, and Loper 2009).
Second,we use the MWEs listed in the DELA dictionaries of English and French (see above).These sets only include positive examples, of course, so we only report recall results onthem.
For Hebrew, we use a small set that was used for evaluation in the past (Al-Hajand Wintner 2010; Tsvetkov and Wintner 2012).
This is a small annotated corpus,NN, of Hebrew noun-noun constructions.
The corpus consists of 413 high-frequencybigrams of the same syntactic construction; of those, 178 are tagged as MWEs (in thiscase, noun compounds) and 235 as non-MWEs.
This corpus consolidates the annotationof three annotators: Only instances on which all three agreed were included.
Because itincludes both positive and negative instances, this corpus facilitates a robust evaluationof precision and recall.4.
Linguistically Motivated FeaturesWe define several linguistically motivated features that are aimed at capturing someof the unique properties of MWEs.
Although many idiosyncratic properties of MWEshave been previously studied, we introduce novel ways to express these properties ascomputable features that inform a classifier.
Note that many of the features we describein the following are completely language-independent; others are applicable to a widerange of languages, whereas few are specific to morphologically rich languages, and can455Computational Linguistics Volume 40, Number 2be exhibited in different ways in different languages.
We provide examples in English,French, and Hebrew, drawn from the resources listed in Section 3.2.
The methodologywe advocate, however, is completely general.A common theme for all these features is idiosyncracy: They are all aimed at locatingsome linguistic property on which MWEs may differ from non-MWEs.
We begin bydetailing these properties, along with the features that we define to reflect them.
In allcases, the feature is applied to a candidate MWE, defined here as a bigram of tokens (allpossible bigrams are potential candidates).
The features are computed from the largemonolingual corpora described in Section 3.2.
In order for a feature to fire, at least fiveinstances of the candidate MWE have to be present in the corpus.Orthographic variation.
Sometimes, MWEs are written with hyphens instead of inter-token spaces.
Examples include Hebrew2 xd-cddi (one sided) ?unilateral?, Englishelephant-bird, and French aide-soignant (help carer) ?caregiver?.
Of course, this featureis only relevant for languages that use the hyphen in this way.We define a binary feature, HYPHEN, whose value is 1 iff the corpus includesinstances of the candidate MWE in which the hyphen character connects the two tokensof the bigram.Capitalization.
MWEs are often named entities, and in languages such as English andFrench a large number of MWEs involve words whose first letter is capital.
We thereforedefine a feature, CAPS, whose value is a binary vector with 1 in the i-th place iff thei-th word of the MWE candidate is capitalized.3 For example, the White House willhave the value ?0, 1, 1?.
This feature is of course irrelevant for languages that do not usecapitalization.Fossil words.
MWEs sometimes include constituents that have no usage outside theparticular expression.
Examples include Hebrew ird lTmiwn (went-down to-treasury)?was lost?, French night club, and English hocus pocus; as far as we know, this is a ratheruniversal property.We define a feature, FOSSIL, whose value is a binary vector with 1 in the i-th placeiff the i-th word of the candidate only occurs in this particular bigram; the other wordsof the candidate expression can be morphological variants of each other, but must sharethe same lemma.
For example, the value of FOSSIL for hocus pocus is ?1, 1?, whereasfor French night club it is ?1, 0?.
In order to filter out potential typos, candidates mustoccur at least five times in the corpus in order for this feature to fire.Frozen form.
MWE constituents sometimes occur in one fixed, frozen form, where thelanguage?s morphology licenses also other forms.
For example, spill the beans doesnot license spill the bean, although bean is a valid form.
Similarly, Hebrew bit xwlim(house-of sick-people) ?hospital?
requires that the noun xwlim be in the plural; thevariant bit xwlh (house-of sick-person) ?a sick person?s house?
only has the literalmeaning.
This feature is of use for languages that are not isolating.2 To facilitate readability we use a transliteration of Hebrew using Roman characters; the letters used,in Hebrew lexicographic order, are abgdhwzxTiklmnsypcqrs?t.3 Here and in subsequent examples we do not assume that the length of an MWE is limited to 2.In the present work, however, the vector is of length exactly 2.456Tsvetkov and Wintner Identification of Multiword ExpressionsWe define a feature, FROZEN, whose value is a binary vector with 1 in the i-th placeiff the i-th word of the candidate never inflects in the context of this expression.
Forexample, the value of FROZEN for spill the beans is ?0, 1, 1?, and for Hebrew bit xwlim(house-of sick-people) ?hospital?
it is ?0, 1?.Partial morphological inflection.
In some cases, MWE constituents undergo a (strict butnon-empty) subset of the full inflections that they would undergo in isolation.
Forexample, the Hebrew bit ms?pT (house-of law) ?court?
occurs in the following inflectedforms: bit hms?pT ?the court?
(75%); bit ms?pT ?a court?
(15%); bti hms?pT ?the courts?
(8%);and bti ms?pT ?courts?
(2%).
Crucially, forms in which the second word, ms?pT ?law,?
isin the plural are altogether missing.
Our assumption is that the inflection histograms ofnon-MWEs are more uniform than the histograms of MWEs, in which some inflectionsmay be more frequent and others may be altogether missing.
Of course, restrictions onthe histogram may stem from the part of speech of the expression; such constraints arecaptured by dependencies in the BN structure.We capture this property, which is again relevant for all non-isolating languages,with a technique that has been proven useful in the area of image processing (Jain1989, Section 7.3).
We compute a histogram of the distribution in the corpus of allthe possible surface forms of each MWE candidate.
Such histograms can compactlyrepresent distributional information on morphological behavior, in the same way thathistograms of the distribution of gray levels in a picture are used to represent the pictureitself.
For example, the histogram corresponding to bit ms?pT (house-of law) ?court?would be?
(bit hms?pT, 0.75), (bit ms?pT, 0.15), (bti hms?pT, 0.08), (bti ms?pT, 0.02)?Because each MWE is idiosyncratic in its own way, we do not expect the histogramsof MWEs to have some specific pattern, except non-uniformity.
We therefore sort thecolumns of each histogram, thereby losing information pertaining to the specific inflec-tions, and retaining only information about the idiosyncrasy of the histogram.
For theexample given, the obtained histogram is ?75, 15, 8, 2?.
In contrast, the non-MWE txwmms?pT (domain-of law) ?domain of the law?, which is syntactically identical, occurs innine different inflected forms, and its sorted histogram is ?59, 14, 7, 7, 5, 2, 2, 2, 2?.
Thelonger ?tail?
of the histogram is typical of compositional expressions.Off-line, we compute the average histogram for positive and negative examples:The average histogram of MWEs is shorter and less uniform than the average histogramof non-MWEs.
We define a binary feature, HIST, that determines whether the histo-gram of the candidate is closer, in terms of L1 (Manhattan) distance, to the averagehistogram of positive or of negative examples.In our corpora, the average histogram of English positive examples has exactly fourelements: 93.62, 5.86, 0.45, and 0.05.
This shows a clear tendency (93.62%) of EnglishMWEs to occur in a single form only; and it also implies that no English MWE occurs inmore than four variants.
The English negative instances, in contrast, have a much longerhistogram (12 elements); the first element is 85.83, much lower than the dominatingelement of the positive examples.
In French, which is morphologically much richer, thenumber of elements in the average histogram of positive examples is 32 (the domi-nating elements are 90.8, 6.9, 1.1, 0.4), whereas the number of elements in the averagehistogram of negative examples is 92 (dominated by 75.6, 14.5, 3.9, 2.0).457Computational Linguistics Volume 40, Number 2Context.
We hypothesize that MWEs tend to constrain their (semantic) context morestrongly than non-MWEs.
We expect words that occur immediately after MWEs to varyless freely than words that immediately follow other expressions.
One motivation forthis hypothesis is the observation that MWEs tend to be less polysemous than freecombinations of words, thereby limiting the possible semantic context in which theycan occur.
This seems to us to be a universal property.We define a feature, CONTEXT, as follows.
We first compute a histogram of thefrequencies of words following each candidate MWE.
We trim the tail of the histogramby removing words whose frequency is lower than 0.1% (the expectation is that non-MWEs would have a much longer tail).
Off-line, we compute the same histograms forpositive and negative examples and average them as before.
The value of CONTEXTis 1 iff the histogram of the candidate is closer (in terms of L1 distance) to the positiveaverage.For example, the histogram of Hebrew bit ms?pT ?court?
includes 15 values, dom-inated by bit ms?pT yliwn ?supreme court?
(20%) and bit ms?pT mxwzi ?district court?
(13%), followed by contexts whose frequency ranges between 5% and 0.6%.
In contrast,the non-MWE txwm ms?pT ?domain-of law?
has a much shorter histogram, namely(12, 11, 6): Over 70% of the words following this expression occur with frequency lowerthan 0.1% and are hence in the trimmed tail.Syntactic diversity.
MWEs can belong to various part of speech categories.
We define asfeature, POS, the category of the candidate, with values obtained by selecting frequenttuples of POS tags.
For example, English heart attack is Noun-Noun, dark blue isAdj-Adj, Al Capone is PropN-PropN; French chant fune`bre (song funeral ) ?dirge?
isNoun-Adj, en bas (in low) ?down?
is Prep-Adj; Hebrew rkbt hrim (train-of mountains)?roller-coaster?
is Noun-Noun, and so forth.Translational equivalents.
Because MWEs are often idiomatic, they tend to be translated ina non-literal way, sometimes to a single word.
We use a bilingual dictionary to generateword-by-word translations of candidate MWEs from Hebrew to English, and checkthe number of occurrences of the English literal translation in a large English corpus.For French?English, we check whether the literal translation occurs in the Giza++ (Ochand Ney 2000) alignment results (we use grow-diag-final-and for symmetrization in thiscase, to improve the precision).
Due to differences in word order between the twolanguages, we create two variants for each translation, corresponding to both possibleorders.
We expect non-MWEs to have some literal translational equivalent (possiblywith frequency that correlates with their frequency in the source language), whereas forMWEs we expect no (or few) literal translations.
For example, consider Hebrew sprwtiph (literature pretty) ?belles lettres?.
Literal translation of the expression to Englishyields literature pretty and pretty literature; we expect these phrases to occur rarelyin an English corpus.
In contrast, the compositional tmwnh iph (picture pretty) ?prettypicture?
is much more likely to occur literally in English.We define a binary feature, TRANS, whose value is 1 iff some literal translationof the candidate occurs more than five times in the corpus.
Although this feature isnot language-specific, we assume that it should work best for pairs of rather distinctlanguages.Collocation.
As a baseline, statistical association measure, we use pointwise mutualinformation (PMI).
We define a binary feature, PMI, with two values, low and high,458Tsvetkov and Wintner Identification of Multiword ExpressionsMWECAPSFOSSILHYPHEN CNTXTPOSHISTPMITRANSFRZNFigure 1The Bayesian network for MWE identification.reflecting an experimentally determined threshold.
Clearly, other association measures(as well as combinations of more than one) could be used (Pecina 2005).5.
Feature Interdependencies Expressed as a Bayesian NetworkA Bayesian network (Jensen and Nielsen 2007) is organized as a directed acyclicgraph whose nodes are random variables and whose edges represent interdependenciesamong those variables.
We use a particular view of BN, known as causal networks, inwhich directed edges lead to a variable from each of its direct causes.4 This facilitates theexpression of domain knowledge (and intuitions, beliefs, etc.)
as structural properties ofthe network.
We use the BN as a classification device: Training amounts to computingthe joint probability distribution of the training set, and classification maximizes theposterior probability of the particular node (variable) being queried.For MWE identification we define a BN whose nodes correspond to the features de-scribed in Section 4.
In addition, we define a node, MWE, for the complete classificationtask.
Over these nodes we impose the structure depicted graphically in Figure 1.
Thisstructure, which we motivate below, is manually defined: It reflects our understandingof the problem domain and is a result of our linguistic intuition.
That said, it can ofcourse be modified in various ways, and, in particular, new nodes can be easily addedto reflect additional features.All nodes depend on MWE, as all are affected by whether or not the candidate isan MWE.
The POS of an expression influences its morphological inflection, hence theedges from POS to HIST and to FROZEN.
For example, Hebrew noun-noun constructionsallow their constituents to undergo the full inflectional paradigm, but when such aconstruction is a MWE, inflection is severely constrained (Al-Haj and Wintner 2010);4 The direction of edges is from the target to the observable; this is compatible with the use of BNs inlatent-variable generative models.459Computational Linguistics Volume 40, Number 2similarly, when one of the constituents of a MWE is a conjunction, the entire expressionis very likely to be frozen, as in English by and large and more or less.Fossil words clearly affect all statistical metrics, hence the edge from FOSSIL toPMI.
They also affect the existence of literal translations, because if a word is not inthe lexicon, it does not have a translation, hence the edge from FOSSIL to TRANS.
Also,we assume that there is a correlation between the frequency (and PMI) of a candidateand whether or not a literal translation of the expression exists, hence the edge fromPMI to TRANS.
The edges from PMI and HIST to CONTEXT are justified by the correlationbetween the frequency and variability of an expression and the variability of the contextin which it occurs.Clearly, the process of determining the structure of the graph, and in particular thedirection of some of the edges, is somewhat arbitrary.
Having said that, it does give thedesigner of the system a clear and explicit way of expressing linguistically motivatedintuitions about dependencies among features.Once the structure of the network is established, the conditional probabilities ofeach dependency have to be determined.
We compute the conditional probability tablesfrom our training data (see Section 6) using Weka (Hall et al.
2009), and obtain values forP(X | X1, .
.
.
,Xk) for each variable X and all variables Xi, 1 ?
i ?
k (parents of X), suchthat the graph includes an edge from Xi to X.
We then use the network for classificationby maximizing P(Xmwe | X1, .
.
.
,Xk), where Xmwe corresponds to the node MWE, andX1, .
.
.
,Xk are the variables corresponding to all other nodes in the network.
Accordingto Bayes rule, we haveP(Xmwe | X1, .
.
.
,Xk) ?P(X1, .
.
.
,Xk | Xmwe)?
P(Xmwe)We define the prior, P(Xmwe), to be 0.41: This is the percentage of MWEs in WordNet 1.7(Fellbaum 1998).
This figure is of course rather arbitrary, but several studies indicate thatthe percentage of MWEs in the (mental) lexicon is approximately one half (Jackendoff1997; Erman and Warren 2000; Sag et al.
2002).
Post factum, we experimented withvarious other values for this parameter.
We chose values between 0.3 and 0.55, inincrements of 0.05, and computed the F-score of the system on the task of extractingEnglish MWEs (see Section 7).
As Table 3 shows, the differences are small (and notstatistically significant), meaning that the accuracy of the system seems to be ratherrobust to the actual value of the prior.
Given a small tuning set, it should be possible tooptimize the choice of the prior more systematically.The conditional probabilities P(X1, .
.
.
,Xk | Xmwe) are determined by Weka fromthe conditional probability tables:P(X1, .
.
.
,Xk | Xmwe) = ?ki=1P(Xi | pai)where k is the number of nodes in the BN (other than Xmwe) and pai is the set of parentsof Xi.Table 3F-score as a function of the value of the prior.P(Xmwe) 0.3 0.35 0.4 0.41 0.45 0.5 0.55F-score 0.848 0.84 0.833 0.835 0.831 0.836 0.843460Tsvetkov and Wintner Identification of Multiword ExpressionsTable 4Sizes of the training sets.MWE non-MWE TotalEnglish 1,381 2,004 3,385French 1,445 2,089 3,534Hebrew 350 504 8546.
Automatic Generation of Training DataFor training we need samples of positive and negative instances of MWEs, each asso-ciated with a vector of the values of all features discussed in Section 4.
We generatethis training material automatically, using the small bilingual corpora described inSection 3.2.
Each parallel corpus is first word-aligned with IBM Model 4 (Brown et al.1993), implemented in Giza++ (Och and Ney 2003); we use union for symmetrizationhere, to improve the recall.
Then, we apply the (completely unsupervised) algorithm ofTsvetkov and Wintner (2012), which extracts MWE candidates from the aligned corpusand re-ranks them using statistics computed from a large monolingual corpus.The core idea behind this algorithm is that MWEs tend to be translated in non-literal ways; in a parallel corpus, words that are 1:1 aligned typically indicate literaltranslations and are hence unlikely constituents of MWEs.
The algorithm hence focuseson misalignments: It trusts the quality of 1:1 alignments (which are further verified witha bilingual dictionary) and searches for MWEs exactly in the areas that word alignmentfailed to properly align, not relying on the alignment in these cases.
Specifically, thealgorithm views all words that are not included in 1:1 alignments as potential areasin which to search for MWEs, independently of how these words were aligned by theword-aligner.
Then, it uses statistics computed from a large monolingual corpus to rankthe MWE candidates; specifically, we use the PMI score of candidates based on countsfrom the monolingual corpora.
Finally, the algorithm extracts maximally long sequencesof words from the unaligned parallel phrases, in which each bigram has a PMI scoreabove some threshold (determined experimentally).
All bigrams in those sequences areconsidered MWEs.
See Tsvetkov and Wintner (2012) for more details.The set of MWEs that is determined in this way constitutes the positive examplesin the training set.
For negative examples, we use two sets of bigrams: Those that are 1:1aligned and have high PMI; and those that are misaligned but have low PMI.
To decidehow many negative examples to generate, we rely on the ratio between MWE and non-MWE entries in WordNet, as mentioned above: P(Xmwe) = 0.41.
We thus select from thenegative set approximately 50% more negative examples than positive ones, such thatthe ratio between the sizes of the sets is 0.41 : 0.59.
The sizes of the resulting trainingsets are listed in Table 4.7.
Results and EvaluationWe use the training data described in Section 6 for training and evaluation: We perform10-fold cross validation experiments, reporting accuracy and (balanced) F-score in threeset-ups: One (SVM) in which we train an SVM classifier5 with the features described5 We use Weka SMO with the PolyKernel set-up; experimentation with several other kernels yieldedworse results.461Computational Linguistics Volume 40, Number 2Table 510-fold cross validation evaluation results.Hebrew French EnglishAccuracy (%) F-score Accuracy (%) F-score Accuracy (%) F-scorePMI 66.98 0.67 70.88 0.762 74.15 0.737BN-auto 71.19 0.71 77.45 0.775 82.16 0.822SVM 74.59 0.75 78.38 0.736 82.95 0.828BN 76.82 0.77 79.04 0.778 83.52 0.835in Section 4; one (BN-auto) in which we train a Bayesian network with these features,but let Weka determine its structure (using the K2 algorithm); and one (BN) in whichwe train a Bayesian network whose structure reflects manually crafted linguisticallymotivated knowledge, as depicted in Figure 1.
The results are listed in Table 5; they arecompared with a PMI baseline, obtained by defining a Bayesian network with only twonodes, MWE and PMI.The linguistically motivated features defined in Section 4 are clearly helpful in theclassification task: The accuracy of an SVM, informed by these features, is close to 75%for Hebrew, over 78% for French, and as high as 83% for English, reducing the error rateof the PMI baseline by 23% (Hebrew) to 34% (English).
The contribution of the BN isalso highly significant, reducing 3?9% more errors (with respect to the errors made bythe SVM classifier).6 In total, the best method, BN, reduces the error rate of the PMI-based classifier by one third.
Interestingly, a BN whose structure does not reflect priorknowledge, but is rather learned automatically, performs worse than these two methods(but still much better than relying on PMI alone).7 It is the combination of linguisticallymotivated features with feature interdependencies reflecting domain knowledge thatcontribute to the best performance.We did not investigate the contribution of each of the features to the classificationtask.
However, we did analyze the weights assigned by the SVM classifier to specificfeatures.
Unsurprisingly, the most distinctive feature is PMI.
Among the POS features,the strongest feature is VB NNS, an indication of a negative instance.
Capitalization isalso unsurprisingly a very strong feature.
We leave a more systematic analysis of thecontribution of each feature to future work.To further assess the quality of the results, we performed a human evaluation onthe English data set.
We first produced the results in the BN set-up, and then sortedboth the (predicted) positive and the (predicted) negative instances by their PMI.
Werandomly picked 100 instances of both lists, at the same positions in the ranked lists,to constitute an evaluation set.
We asked three English-speaking annotators to deter-mine whether the 200 expressions were indeed MWEs.
The annotation guidelines aregiven in Appendix A.
Comparing the three annotators?
labels, we found out that theyagreed on 141 of the 200 (70.5%).
This should probably be taken as an upper bound forthe task.6 The improvement of both BN and SVM over the baseline is highly significant statistically (sign test,p < 0.01 in all three cases); the improvement of BN over SVM is significant for English (p < 0.01)but not for French.7 We are not sure why this is the case.
One possible explanation is that our training set contains noisyexamples, and as the BN-auto classifier learns the dependencies from noisy data, it performs worsethan the SVM classifier.
Another possible explanation is that it attempts to learn more dependencies,thereby increasing the parameter space of the model.462Tsvetkov and Wintner Identification of Multiword ExpressionsWe then computed the majority label and compared it with our predicted label.Exactly 142 of the predicted labels were annotated as correct; that?s an accuracy of71%.
Of the 141 instances that the three annotators agreed on, our results predict thecorrect label for 112 instances (79.4%).
We take these figures as a strong indication of theaccuracy of the results.As an additional evaluation measure, we use the sets of bigrams in the EnglishWordNet, and the bigram MWEs in the DELA dictionaries of English and French(Section 3.2).
Because we only have positive instances in these evaluation sets, we canonly report recall.
We therefore use the Bayesian network classifier to extract MWEsfrom the large monolingual corpora discussed in Section 3.2.
For each evaluation set(WordNet, DELA English, and DELA French), we divide the number of bigrams in theset that are classified as MWEs by the size of the intersection of the evaluation set withthe monolingual corpus.
In other words, we exclude from the evaluation those MWEsin the evaluation set that never occur in our corpora.
The results are listed in Table 6.As examples of correctly identified MWEs, consider English advisory board, aircargo, adoption agency, air ticket, crude oil, and so on, and French accord international?international agreement?, acte final ?final act?, banque centrale ?central bank?, ce soir?tonight?, and so forth, all taken from the DELA dictionaries.
The relatively low recall ofour method on these dictionaries is to a large extent due to a very liberal definition ofMWEs that the dictionaries use.Many entries that are listed asMWEs are actually highlycompositional, and hence our method fails to identify them.
DELA entries that are notidentified by our classifier include examples such as English abnormal behavior, abso-lute necessity, academic research, and so on.
The French DELA dictionary is especiallyextensive, with examples such as action sociale, action antitumorale, action associa-tive, action caritative, action collective, action commerciale, action communautaire,and many more, all listed as MWEs.
Our system only recognizes the first of these.The WordNet results are obviously much better.
Correctly identified MWEs includead hoc, outer space, web site, inter alia, road map, and so forth.
WordNet MWEs thatour system failed to identify include has been, as well, in this, a few, set up, and so on.A more involved error analysis is required in order to propose potential directions forimprovement on this set.As a further demonstration of the utility of our approach, we evaluate the algorithmon the set NN of Hebrew noun-noun constructions described in Section 3.2.
We train aBayesian network on the training set described in Section 6 and use it to classify theset NN.
We compare the results of this classifier with a PMI baseline, and also withthe classification results reported by Al-Haj and Wintner (2010); the latter reflects 10-fold cross-validation evaluation using the entire set, so it may be considered an upperbound for any classifier that uses a general training corpus.The results are depicted in Table 7.
They clearly demonstrate that the linguisticallymotivated features we define provide a significant improvement in classification accu-racy over the baseline PMI measure.
Note that our F-score, 0.77, is very close to theTable 6Evaluation results: WordNet and DELA dictionaries.True positives Evaluation set size Recall (%)WordNet 25,549 42,403 60DELA English 11,955 26,460 45DELA French 886 4,798 18463Computational Linguistics Volume 40, Number 2Table 7Evaluation results: noun-noun constructions.Accuracy Precision Recall F-scorePMI 71.43% 0.71 0.71 0.71BN 77.00% 0.77 0.77 0.77AW 80.77% 0.77 0.81 0.79AW = results from Al-Haj and Wintner (2010)best result of 0.79 obtained by Al-Haj and Wintner (2010) as the average of 10-fold crossvalidation runs, using only high-frequency noun-noun constructions for training.
Weinterpret this result as a further proof of the robustness of our architecture.Finally, we conduct an analysis of the quality of extracted (Hebrew) MWEs.
Weused the trained BN to classify the entire set of bigrams present in the (Hebrew side ofthe) Hebrew?English parallel corpus described in Section 3.2.
Of the more than 140,000candidates, only 4,000 are classified as MWEs.
We sort this list of potential MWEs by theprobability assigned by the BN to the positive value of the variable Xmwe.
The resultingsorted list is dominated by high-PMI bigrams, especially proper names, all of which areindeed MWEs.
The first non-MWE (false positive) occurs in the 50th place on the list; itis crpt niqwla ?France Nicolas?, which is obviously a sub-sequence of the larger MWE,neia crpt niqwla srqwzi ?French president Nicolas Sarkozy?.
Similar sub-sequences arealso present, but only five are in the top 100.
Such false positives can be reduced whenlonger MWEs are extracted, as it can be assumed that a sub-sequence of a longer MWEdoes not have to be identified.
Other false positives in the top 100 include some highlyfrequent expressions, but over 85 of the top 100 are clearly MWEs.Although more careful evaluation is required in order to estimate the rate of truepositives in this list, we trust that the vast majority of the positive results are indeedMWEs.8.
Conclusions and Future WorkWe presented a novel architecture for identifying MWEs in text corpora.
The maininsights we emphasize are sophisticated computational encoding of linguistic knowl-edge that focuses on the idiosyncratic behavior of such expressions.
This is reflectedin two ways in our work: by defining computable features that reflect different facetsof irregularities; and by framing the features as part of a larger Bayesian network thataccounts for interdependencies among them.
We also introduce a method for automat-ically generating a training set for this task, which renders the classification entirelyunsupervised.
The result is a classifier that can identify MWEs of several types andconstructions.
Evaluation on three languages (English, French, and Hebrew) shows sig-nificant improvement in the accuracy of the classifier compared with less sophisticatedbaselines.The modular architecture of Bayesian networks facilitates easy exploration withmore features.
We are currently investigating the contribution of various other sourcesof information to the classification task.
For example, Hebrew lacks large-scale lexicalsemantic resources.
However, it is possible to literally translate an MWE candidate toEnglish and rely on the English WordNet for generating synonyms of the literal transla-tion.
Such ?literal synonyms?
can then be back-translated to Hebrew.
The assumption is464Tsvetkov and Wintner Identification of Multiword Expressionsthat if a back-translated expression has a low PMI, the original candidate is very likelynot a MWE.
Although such a feature may contribute little on its own, incorporating itin a well-structured BN may improve performance.
Another feature that can easily beimplemented in this way is whether the POS of MWE constituents is retained when theexpression is translated to another language; we hypothesize that this is much morelikely when the expression is compositional.Appendix A. Annotation GuidelinesThese are the instructions given to the annotators.The task is to annotate each line as either a multi-word expression, in which case mark1 in the first field; or not, in which case the value is 0.
It?s a hard task, but you arerequested to be decisive.
Please do not change the file in any other way.The main criterion for determining whether an expression is a MWE is whether ithas to be stored in a computational lexicon.
Typically, expressions are stored in lexiconsif they exhibit idiosyncratic (irregular) behavior.
This could be due to: non-compositional meaning.
For example, ?green light?
is an MWE because it is nota light.
?kill time?
is not a violent action.
A good indication of non-compositionalmeaning is limited reference.
For example, if someone gives you a green light, youcan?t then refer to it as ?the light I was given?. non-substitutability of elements.
For example, ?breast cancer?
is an MWE becausewhile ?breast?
and ?chest?
can often be substituted, ?breast cancer?
and ?chestcancer?
cannot. fossil words, i.e., words that only occur in the context of the expression.
Forexample, ?mutatis mutandis?. nominalization.
If the expression can occur as a single word, or with a connectinghyphen, it is a strong indication that it is an MWE.
For example, ?road map?
can bewritten ?roadmap?. irregular syntactic and/or morphological behavior.
For example, ?look up?
is anMWE because while ordinarily you can convert ?I walked up the alley?
to ?Up thealley I walked?, you can?t convert ?I looked up that word in a dictionary?
to ?Up thatword I looked?. proper names.
All proper names are by definition MWEs.
This includes people(?Barack Obama?
), places (?Tel Aviv?
), organizations (?United Nations?
), etc.But really, the best criterion is: if I hadn?t known this expression, would I be able to useit properly simply by knowing its two constituents?
Would I understand its meaning,be able to inflect it properly, construct syntactic constructions, and in general use it inthe right context in the right way?AcknowledgmentsThis research was supported by The IsraelScience Foundation (grants 137/06 and1269/07).
We are grateful to GennadiLembersky for his continuous help, and tothe three anonymous ComputationalLinguistics reviewers for very constructivecomments that greatly improved this article.All remaining errors are of course our own.ReferencesAl-Haj, Hassan.
2010.
Hebrew multiwordexpressions: Linguistic properties, lexicalrepresentation, morphological processing,and automatic acquisition.
Master?s thesis,University of Haifa.Al-Haj, Hassan and Shuly Wintner.
2010.Identifying multi-word expressions byleveraging morphological and syntactic465Computational Linguistics Volume 40, Number 2idiosyncrasy.
In Proceedings of the 23rdInternational Conference on ComputationalLinguistics (COLING 2010), pages 10?18,Beijing.Baldwin, Timothy, Colin Bannard, TakaakiTanaka, and Dominic Widdows.
2003.
Anempirical model of multiword expressiondecomposability.
In Proceedings of the ACL2003 Workshop on Multiword Expressions,pages 89?96, Sapporo.Baldwin, Timothy and Takaaki Tanaka.2004.
Translation by machine of complexnominals: Getting it right.
In Second ACLWorkshop on Multiword Expressions:Integrating Processing, pages 24?31,Barcelona.Bannard, Colin.
2007.
A measure of syntacticflexibility for automatically identifyingmultiword expressions in corpora.
InProceedings of the Workshop on a BroaderPerspective on Multiword Expressions,pages 1?8, Prague.Bannard, Colin, Timothy Baldwin, andAlex Lascarides.
2003.
A statisticalapproach to the semantics ofverb-particles.
In Proceedings of the ACL2003 Workshop on Multiword Expressions:Analysis, Acquisition and Treatment,pages 65?72, Sapporo, Japan.Bird, Steven, Ewan Klein, and Edward Loper.2009.
Natural Language Processing withPython.
O?Reilly Media, Sebastopol, CA.Bouamor, Dhouha, Nasredine Semmar, andPierre Zweigenbaum.
2012.
Identifyingbilingual multi-word expressionsfor statistical machine translation.In Proceedings of the Eight InternationalConference on Language Resources andEvaluation (LREC?12), pages 674?679,Istanbul.Brown, Peter F., Stephen Della Pietra,Vincent J. Della Pietra, and Robert L.Mercer.
1993.
The mathematic of statisticalmachine translation: Parameter estimation.Computational Linguistics, 19(2):263?311.Calado, Pa?vel, Marco Cristo, Edleno SilvaDe Moura, Nivio Ziviani, Berthier A.Ribeiro-Neto, and Marcos Andre?Gonc?alves.
2003.
Combining link-basedand content-based methods for webdocument classification.
In Proceedingsof CIKM-03, 12th ACM InternationalConference on Information and KnowledgeManagement, pages 394?401,New Orleans, LA.Callison-Burch, Chris, Philipp Koehn,Christof Monz, and Omar F. Zaidan,editors.
2011.
Proceedings of the SixthWorkshop on Statistical MachineTranslation.
Association for ComputationalLinguistics, Edinburgh.Carpuat, Marine and Mona Diab.
2010.Task-based evaluation of multiwordexpressions: A pilot study in statisticalmachine translation.
In Human LanguageTechnologies: The 2010 Annual Conferenceof the North American Chapter of theAssociation for Computational Linguistics,pages 242?245, Los Angeles, CA.Chang, Baobao, Pernilla Danielsson, andWolfgang Teubert.
2002.
Extraction oftranslation unit from Chinese-Englishparallel corpora.
In Proceedings of the FirstSIGHAN Workshop on Chinese LanguageProcessing, pages 1?5, Morristown, NJ.Church, Kenneth Ward and Patrick Hanks.1990.
Word association norms, mutualinformation, and lexicography.Computational Linguistics, 16(1):22?29.Cook, Paul, Afsaneh Fazly, and SuzanneStevenson.
2007.
Pulling their weight:Exploiting syntactic forms for theautomatic identification of idiomaticexpressions in context.
In Proceedings ofthe ACL Workshop on a Broader Perspectiveon Multiword Expressions (MWE 2007),pages 41?48, Prague.Denoyer, Ludovic and Patrick Gallinari.2004.
Bayesian network model forsemi-structured document classification.Information Processing and Management,40(5):807?827.Doucet, Antoine and Helana Ahonen-Myka.2004.
Non-contiguous word sequencesfor information retrieval.
In Second ACLWorkshop on Multiword Expressions:Integrating Processing, pages 88?95,Barcelona.Duan, Jianyong, Mei Zhang, Lijing Tong,and Feng Guo.
2009.
A hybrid approach toimprove bilingual multiword expressionextraction.
In Thanaruk Theeramunkong,Boonserm Kijsirikul, Nick Cercone, andTu-Bao Ho, editors, Advances in KnowledgeDiscovery and Data Mining, volume 5476of Lecture Notes in Computer Science.Springer, Berlin and Heidelberg,pages 541?547.Erman, Britt and Beatrice Warren.
2000.The idiom principle and the open choiceprinciple.
Text, 20(1):29?62.Fazly, Afsaneh and Suzanne Stevenson.2006.
Automatically constructing a lexiconof verb phrase idiomatic combinations.In Proceedings of the 11th Conference of theEuropean Chapter of the Association forComputational Linguistics (EACL),pages 337?344, Trento.466Tsvetkov and Wintner Identification of Multiword ExpressionsFellbaum, Christiane, editor.
1998.
WordNet:An Electronic Lexical Database.
Language,Speech and Communication.
MIT Press,Cambridge, MA.Green, Spence, Marie-Catherine de Marneffe,John Bauer, and Christopher D. Manning.2011.
Multiword expression identificationwith tree substitution grammars:A parsing tour de force with French.In Proceedings of the 2011 Conference onEmpirical Methods in Natural LanguageProcessing, pages 725?735, Edinburgh.Hall, Mark, Eibe Frank, Geoffrey Holmes,Bernhard Pfahringer, Peter Reutemann,and Ian H. Witten.
2009.
The WEKA datamining software: An update.
SIGKDDExplorations, 11(1):10?18.Hazelbeck, Gregory and Hiroaki Saito.2010.
A hybrid approach for functionalexpression identification in a Japanesereading assistant.
In Proceedings of the 2010Workshop on Multiword Expressions: FromTheory to Applications, pages 81?84, Beijing.Heckerman, David.
1995.
A tutorial onlearning with Bayesian networks.Technical Report MSR-TR-95-06,Microsoft Research, Redmond, WA.Itai, Alon and Shuly Wintner.
2008.Language resources for Hebrew.
LanguageResources and Evaluation, 42(1):75?98.Jackendoff, Ray.
1997.
The Architectureof the Language Faculty.
MIT Press,Cambridge, MA.Jain, Anil K. 1989.
Fundamentals of DigitalImage Processing.
Prentice-Hall, Inc.,Upper Saddle River, NJ.Jensen, Finn V. and Thomas D. Nielsen.
2007.Bayesian Networks and Decision Graphs.Springer, 2nd edition.Katz, Graham and Eugenie Giesbrecht.2006.
Automatic identification ofnon-compositional multi-wordexpressions using latent semantic analysis.In Proceedings of the Workshop on MultiwordExpressions: Identifying and ExploitingUnderlying Properties, pages 12?19, Sydney.Kirschenbaum, Amit and Shuly Wintner.2010.
A general method for creating abilingual transliteration dictionary.In Proceedings of the Seventh Conferenceon International Language Resources andEvaluation (LREC?10), pages 273?276,Valletta.Lam, Wai, Kon F. Low, and Chao Y. Ho.1997.
Using a Bayesian networkinduction approach for text categorization.In Proceedings of IJCAI-97, 15th InternationalJoint Conference on Artificial Intelligence,pages 745?750, Nagoya.Lambert, Patrik and Rafael Banchs.
2005.Data inferred multi-word expressionsfor statistical machine translation.In Proceedings of the MT Summit X,pages 396?403, Phuket.Miller, George A., Richard Beckwith,Christiane Fellbaum, Derek Gross, andKatherine Miller.
1990.
Five paperson WordNet.
International Journal ofLexicography, 3(4):235?312.Och, Franz Josef and Hermann Ney.
2000.Improved statistical alignment models.In ACL ?00: Proceedings of the 38th AnnualMeeting of the Association for ComputationalLinguistics, pages 440?447, Hong Kong.Och, Franz Josef and Hermann Ney.
2003.A systematic comparison of variousstatistical alignment models.
ComputationalLinguistics, 29(1):19?51.Pearl, Judea.
1985.
Bayesian networks:A model of self-activated memory forevidential reasoning.
In Proceedings of the7th Conference of the Cognitive ScienceSociety, pages 329?334, University ofCalifornia, Irvine, CA.Pecina, Pavel.
2005.
An extensive empiricalstudy of collocation extraction methods.In Proceedings of the ACL Student ResearchWorkshop, pages 13?18, Ann Arbor, MI.Pecina, Pavel.
2008.
A machine learningapproach to multiword expressionextraction.
In Proceedings of the LRECWorkshop Towards a Shared Task forMultiword Expressions, pages 54?57,Marrakech.Peshkin, Leonid, Avi Pfeffer, andVirginia Savova.
2003.
Bayesian nets insyntactic categorization of novel words.In Proceedings of the 2003 Conference of theNorth American Chapter of the Associationfor Computational Linguistics on HumanLanguage Technology: Companion Volume ofthe Proceedings of HLT-NAACL 2003?ShortPapers - Volume 2, NAACL ?03,pages 79?81, Edmonton.Petrov, Slav and Dan Klein.
2007.
Improvedinference for unlexicalized parsing.In Proceedings of HLT-NAACL,pages 404?411, Rochester, NY.Piao, Scott Songlin, Paul Rayson, DawnArcher, and Tony McEnery.
2005.Comparing and combining a semantictagger and a statistical tool for MWEextraction.
Computer Speech and Language,19(4):378?397.Ramisch, Carlos, Helena de Medeiros Caseli,Aline Villavicencio, Andre?
Machado, andMaria Finatto.
2010.
A hybrid approachfor multiword expression identification.467Computational Linguistics Volume 40, Number 2In Thiago Pardo, Anto?nio Branco,Aldebaro Klautau, Renata Vieira, andVera de Lima, editors, ComputationalProcessing of the Portuguese Language,volume 6001 of Lecture Notes in ComputerScience.
Springer, Berlin and Heidelberg,pages 65?74.Ramisch, Carlos, Paulo Schreiner, MarcoIdiart, and Alline Villavicencio.
2008.
Anevaluation of methods for the extraction ofmultiword expressions.
In Proceedings ofthe LREC Workshop Towards a Shared Task forMultiword Expressions, pages 50?53,Marrakech.Ren, Zhixiang, Yajuan Lu?, Jie Cao, Qun Liu,and Yun Huang.
2009.
Improvingstatistical machine translation usingdomain bilingual multiword expressions.In Proceedings of the Workshop on MultiwordExpressions: Identification, Interpretation,Disambiguation and Applications,pages 47?54, Singapore.Sag, Ivan, Timothy Baldwin, Francis Bond,Ann Copestake, and Dan Flickinger.
2002.Multiword expressions: A pain in theneck for NLP.
In Proceedings of the ThirdInternational Conference on Intelligent TextProcessing and Computational Linguistics(CICLING 2002), pages 1?15, Mexico City.Savova, Virginia and Leonid Peshkin.
2005.Dependency parsing with dynamicBayesian network.
In Proceedings of the20th National Conference on ArtificialIntelligence?Volume 3, pages 1,112?1,117,Pittsburgh, PA.Smadja, Frank A.
1993.
Retrievingcollocations from text: Xtract.Computational Linguistics, 19(1):143?177.Smith, Noah A.
2011.
Linguistic StructurePrediction.
Synthesis Lectures on HumanLanguage Technologies.
Morgan andClaypool.Tsvetkov, Yulia and Shuly Wintner.
2010a.Automatic acquisition of parallel corporafrom websites with dynamic content.In Proceedings of the Seventh Conferenceon International Language Resources andEvaluation (LREC?10), pages 3,389?3,392,Valletta.Tsvetkov, Yulia and Shuly Wintner.
2010b.Extraction of multi-word expressions fromsmall parallel corpora.
In Proceedingsof the 23rd International Conference onComputational Linguistics (COLING 2010),pages 1256?1264, Beijing.Tsvetkov, Yulia and Shuly Wintner.
2011.Identification of multi-word expressionsby combining multiple linguisticinformation sources.
In Proceedingsof the 2011 Conference on Empirical Methodsin Natural Language Processing,pages 836?845, Edinburgh.Tsvetkov, Yulia and Shuly Wintner.
2012.Extraction of multi-word expressionsfrom small parallel corpora.
NaturalLanguage Engineering, 18(4):549?573.Uchiyama, Kiyoko, Timothy Baldwin, andShun Ishizaki.
2005.
DisambiguatingJapanese compound verbs.
ComputerSpeech & Language, 19(4):497?512.Van de Cruys, Tim and Begon?aVillada Moiro?n.
2007.
Semantics-basedmultiword expression extraction.In Proceedings of the Workshop on a BroaderPerspective on Multiword Expressions,pages 25?32, Prague.Varga, Da?niel, Pe?ter Hala?csy, Andra?s Kornai,Viktor Nagy, La?szlo?
Ne?meth, and ViktorTro?n.
2005.
Parallel corpora for mediumdensity languages.
In Proceedings ofRANLP?2005, pages 590?596, Borovet.Venkatapathy, Sriram and Aravind Joshi.2006.
Using information about multi-wordexpressions for the word-alignmenttask.
In Proceedings of the COLING/ACLWorkshop on Multiword Expressions:Identifying and Exploiting UnderlyingProperties, pages 20?27, Sydney.Venkatsubramanyan, Shailaja and JosePerez-Carballo.
2004.
Multiwordexpression filtering for buildingknowledge.
In Second ACL Workshopon Multiword Expressions: IntegratingProcessing, pages 40?47, Barcelona.Villavicencio, Aline, Valia Kordoni, Yi Zhang,Marco Idiart, and Carlos Ramisch.
2007.Validation and evaluation of automaticallyacquired multiword expressions forgrammar engineering.
In Proceedings of the2007 Joint Conference on Empirical Methodsin Natural Language Processing andComputational Natural Language Learning(EMNLP-CoNLL), pages 1,034?1,043,Prague.Weller, Marion and Fabienne Fritzinger.
2010.A hybrid approach for the identificationof multiword expressions.
In Proceedingsof the SLTC 2010 Workshop on Compoundsand Multiword Expressions, pages 1?2,Linko?ping.468
