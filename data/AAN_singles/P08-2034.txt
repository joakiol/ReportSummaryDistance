Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 133?136,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsSentiment Vector Space Model forLyric-based Song Sentiment ClassificationYunqing Xia Linlin WangCenter for Speech and language Tech.
State Key Lab of Intelligent Tech.
and Sys.RIIT, Tsinghua University Dept.
of CST, Tsinghua UniversityBeijing 100084, China Beijing 100084, Chinayqxia@tsinghua.edu.cn wangll07@mails.tsinghua.edu.cnKam-Fai Wong Mingxing XuDept.
of SE&EM Dept.
of CSTThe Chinese University of Hong Kong Tsinghua UniversityShatin, Hong Kong Beijing 100084, Chinakfwong@se.cuhk.edu.hk xumx@tsinghua.edu.cnAbstractLyric-based song sentiment classificationseeks to assign songs appropriate sentimentlabels such as light-hearted and heavy-hearted.Four problems render vector space model(VSM)-based text classification approach in-effective: 1) Many words within song lyricsactually contribute little to sentiment; 2)Nouns and verbs used to express sentiment areambiguous; 3) Negations and modifiersaround the sentiment keywords make particu-lar contributions to sentiment; 4) Song lyric isusually very short.
To address these problems,the sentiment vector space model (s-VSM) isproposed to represent song lyric document.The preliminary experiments prove that the s-VSM model outperforms the VSM model inthe lyric-based song sentiment classificationtask.1 IntroductionSong sentiment classification nowadays becomes ahot research topic due largely to the increasingdemand of ubiquitous song access, especially viamobile phone.
In their music phone W910i, Sonyand Ericsson provide Sense Me component to catchowner?s mood and play songs accordingly.
Songsentiment classification is the key technology forsong recommendation.
Many research works havebeen reported to achieve this goal using audio sig-nal (Knees et al, 2007).
But research efforts onlyric-based song classification are very few.Preliminary experiments show that VSM-basedtext classification method (Joachims, 2002) is inef-fective in song sentiment classification (see Sec-tion 5) due to the following four reasons.
Firstly,the VSM model considers all content words withinsong lyric as features in text classification.
But infact many words in song lyric actually make littlecontribution to sentiment expressing.
Using allcontent words as features, the VSM-based classifi-cation methods perform poorly in song sentimentclassification.
Secondly, observation on lyrics ofthousands of Chinese pop songs reveals that senti-ment-related nouns and verbs usually carry multi-ple senses.
Unfortunately, the ambiguity is notappropriately handled in the VSM model.
Thirdly,negations and modifiers are constantly foundaround the sentiment words in song lyric to inverse,to strengthen or to weaken the sentiments that thesentences carry.
But the VSM model is not capableof reflecting these functions.
Lastly, song lyric isusually very short, namely 50 words on average inlength, rendering serious sparse data problem inVSM-based classification.To address the aforementioned problems of theVSM model, the sentiment vector space model (s-VSM) is proposed in this work.
We adopt the s-VSM model to extract sentiment features fromsong lyrics and implement the SVM-light(Joachims, 2002) classification algorithm to assignsentiment labels to given songs.1332 Related WorksSong sentiment classification has been investigatedsince 1990s in audio signal processing communityand research works are mostly found relying onaudio signal to make a decision using machinelearning algorithms (Li and Ogihara, 2006; Lu etal., 2006).
Typically, the sentiment classes are de-fined based on the Thayer?s arousal-valence emo-tion plane (Thayer, 1989).
Instead of assigningsongs one of the four typical sentiment labels, Luet al (2006) propose the hierarchical framework toperform song sentiment classification with twosteps.
In the first step the energy level is detectedwith intensity features and the stress level is de-termined in the second step with timbre andrhythm features.
It is proved difficult to detectstress level using audio as classification proof.Song sentiment classification using lyric asproof is recently investigated by Chen et al (2006).They adopt the hierarchical framework and makeuse of song lyric to detect stress level in the secondstep.
In fact, many literatures have been producedto address the sentiment analysis problem in natu-ral language processing research.
Three approachesare dominating, i.e.
knowledge-based approach(Kim and Hovy, 2004), information retrieval-basedapproach (Turney and Littman, 2003) and machinelearning approach (Pang et al, 2002), in which thelast approach is found very popular.
Pang et al(2002) adopt the VSM model to represent productreviews and apply text classification algorithmssuch as Na?ve Bayes, maximum entropy and sup-port vector machines to predict sentiment polarityof given product review.Chen et al (2006) also apply the VSM model inlyric-based song sentiment classification.
However,our experiments show that song sentiment classifi-cation with the VSM model delivers disappointingquality (see Section 5).
Error analysis reveals thatthe VSM model is problematic in representingsong lyric.
It is necessary to design a new lyric rep-resentation model for song sentiment classification.3 Sentiment Vector Space ModelWe propose the sentiment vector space model (s-VSM) for song sentiment classification.
Principlesof the s-VSM model are listed as follows.
(1) Only sentiment-related words are used to pro-duce sentiment features for the s-VSM model.
(2) The sentiment words are appropriately disam-biguated with the neighboring negations andmodifiers.
(3) Negations and modifiers are included in the s-VSM model to reflect the functions of invers-ing, strengthening and weakening.Sentiment unit is found the appropriate elementcomplying with the above principles.To be general, we first present the notation forsentiment lexicon as follows.,...,1},{,...,1},{,...,1},{  };,,{LlmMJjnNIicCMNCLlji=======in which L represents sentiment lexicon, C senti-ment word set, N negation set and M modifier set.These words can be automatically extracted from asemantic dictionary and each sentiment word isassigned a sentiment label, namely light-hearted orheavy-hearted according to its lexical definition.Given a piece of song lyric, denoted as follows,HhwW h ,...,1},{ ==in which W denotes a set of words that appear inthe song lyric, the semantic lexicon is in turn usedto locate sentiment units denoted as follows.MWmNWnCWcmncuUvlvjvivlvjviv?????
?==,,,,,,;  ;,},,{}{Note that sentiment units are unambiguous sen-timent expressions, each of which contains onesentiment word and possibly one modifier and onenegation.
Negations and modifiers are helpful todetermine the unique meaning of the sentimentwords within certain context window, e.g.
3 pre-ceding words and 3 succeeding words in our case.Then, the s-VSM model is presented as follows.
))(),...,(),(( 21 UfUfUfV TS = .in which VS represents the sentiment vector for thegiven song lyric and fi(U) sentiment features whichare usually certain statistics on sentiment units thatappear in lyric.We classify the sentiment units according to oc-currence of sentiment words, negations and modi-fiers.
If the sentiment word is mandatory for anysentiment unit, eight kinds of sentiment units areobtained.
Let fPSW denote count of positive senti-134ment words (PSW), fNSW count of negative senti-ment words (NSW), fNEG count of negations (NEG)and fMOD count of modifiers (MOD).
Eight senti-ment features are defined in Table 1.fi Number of sentiment units satisfying ?f1 fPSW >0, fNSW =fNEG =fMOD =0f2 fPSW =0, fNSW >0, fNEG = fMOD =0f3 fPSW >0, fNSW =0,  fNEG>0, fMOD =0f4 fPSW=0, fNSW >0, fNEG >0, fMOD =0f5 fPSW >0, fNSW =0, fNEG =0, fMOD >0f6 fPSW=0, fNSW >0, fNEG =0, fMOD >0f7 fPSW >0, fNSW =0, fNEG >0, fMOD >0f8 fPSW =0, fNSW >0, fNEG >0, fMOD >0Table 1.
Definition of sentiment features.
Note thatone sentiment unit contains only one sentimentword.
Thus it is not possible that fPSW and fNSW areboth bigger than zero.Obviously, sparse data problem can be well ad-dressed using statistics on sentiment units ratherthan on individual words or sentiment units.4  Lyric-based Song Sentiment Classifica-tionSong sentiment classification based on lyric can beviewed as a text classification task thus can behandled by some standard classification algorithms.In this work, the SVM-light algorithm is imple-mented to accomplish this task due to its excel-lence in text classification.Note that song sentiment classification differsfrom the traditional text classification in featureextraction.
In our case, sentiment units are firstdetected and the sentiment features are then gener-ated based on sentiment units.
As the sentimentunits carry unambiguous sentiments, it is deemedthat the s-VSM is model is promising to carry outthe song sentiment classification task effectively.5 EvaluationTo evaluate the s-VSM model, a song corpus, i.e.5SONGS, is created manually.
It covers 2,653 Chi-nese pop songs, in which 1,632 are assigned labelof light-hearted (positive class) and 1,021 assignedheavy-hearted (negative class).
We randomly se-lect 2,001 songs (around 75%) for training and therest for testing.
We adopt the standard evaluationcriteria in text classification, namely precision (p),recall (r), f-1 measure (f) and accuracy (a) (Yangand Liu, 1999).In our experiments, three approaches are imple-mented in song sentiment classification, i.e.
audio-based (AB) approach, knowledge-based (KB) ap-proach and machine learning (ML) approach, inwhich the latter two approaches are also referred toas text-based (TB) approach.
The intentions are 1)to compare AB approach against the two TB ap-proaches, 2) to compare the ML approach againstthe KB approach, and 3) to compare the VSM-based ML approach against the s-VSM-based one.Audio-based (AB) ApproachWe extract 10 timbre features and 2 rhythm fea-tures (Lu et al, 2006) from audio data of each song.Thus each song is represented by a 12-dimensionvector.
We run SVM-light algorithm to learn on thetraining samples and classify test ones.Knowledge-based (KB) ApproachWe make use of HowNet (Dong and dong,2006), to detect sentiment words, to recognize theneighboring negations and modifiers, and finally tolocate sentiment units within song lyric.
Sentiment(SM) of the sentiment unit (SU) is determined con-sidering sentiment words (SW), negation (NEG)and modifiers (MOD) using the following rule.
(1) SM(SU) = label(SW);(2) SM(SU) = - SM(SU) iff SU contains NEG;(3) SM(SU) = degree(MOD)*SM(SU) iff SUcontains MOD.In the above rule, label(x) is the function to readsentiment label(?
{1, -1}) of given word in thesentiment lexicon and degree(x) to read its modifi-cation degree(?
{1/2, 2}).
As the sentiment labelsare integer numbers, the following formula isadopted to obtain label of the given song lyric.?????
?= ?iiSUSMsignlabel )(Machine Learning (ML) ApproachThe ML approach adopts text classification al-gorithms to predict sentiment label of given songlyric.
The SVM-light algorithm is implementedbased on VSM model and s-VSM model, respec-tively.
For the VSM model, we apply (CHI) algo-rithm (Yang and Pedersen, 1997) to select effectivesentiment word features.
For the s-VSM model, weadopt HowNet as the sentiment lexicon to createsentiment vectors.Experimental results are presented Table 2.135p R f-1 aAudio-based 0.504 0.701 0.586 0.504Knowledge-based 0.726 0.584 0.647 0.714VSM-based 0.587 1.000 0.740 0.587s-VSM-based 0.783 0.750 0.766 0.732Table 2.
Experimental resultsTable 2 shows that the text-based methods out-perform the audio-based method.
This justifies ourclaim that lyric is better than audio in song senti-ment detection.
The second observation is that ma-chine learning approach outperforms theknowledge-based approach.
The third observationis that s-VSM-based method outperforms VSM-based method on f-1 score.
Besides, we surpris-ingly find that VSM-based method assigns all testsamples light-hearted label thus recall reaches100%.
This makes results of VSM-based methodunreliable.
We look into the model file created bythe SVM-light algorithm and find that 1,868 of2,001 VSM training vectors are selected as supportvectors while 1,222 s-VSM support vectors areselected.
This indicates that the VSM model indeedsuffers the problems mentioned in Section 1 inlyric-based song sentiment classification.
As acomparison, the s-VSM model produces more dis-criminative support vectors for the SVM classifierthus yields reliable predictions.6  Conclusions and Future WorksThe s-VSM model is presented in this paper as adocument representation model to address theproblems encountered in song sentiment classifica-tion.
This model considers sentiment units in fea-ture definition and produces more discriminativesupport vectors for song sentiment classification.Some conclusions can be drawn from the prelimi-nary experiments on song sentiment classification.Firstly, text-based methods are more effective thanthe audio-based method.
Secondly, the machinelearning approach outperforms the knowledge-based approach.
Thirdly, s-VSM model is morereliable and more accurate than the VSM model.We are thus encouraged to carry out more researchto further refine the s-VSM model in sentimentclassification.
In the future, we will incorporatesome linguistic rules to improve performance ofsentiment unit detection.
Meanwhile, sentimentfeatures in the s-VSM model are currently equallyweighted.
We will adopt some estimation tech-niques to assess their contributions for the s-VSMmodel.
Finally, we will also explore how the s-VSM model improves quality of polarity classifi-cation in opinion mining.AcknowledgementResearch work in this paper is partially supportedby NSFC (No.
60703051) and Tsinghua Universityunder the Basic Research Foundation (No.JC2007049).ReferencesR.H.
Chen, Z.L.
Xu, Z.X.
Zhang and F.Z.
Luo.
ContentBased Music Emotion Analysis and Recognition.Proc.
of 2006 International Workshop on ComputerMusic and Audio Technology, pp.68-75.
2006.Z.
Dong and Q. Dong.
HowNet and the Computation ofMeaning.
World Scientific Publishing.
2006.T.
Joachims.
Learning to Classify Text Using SupportVector Machines, Methods, Theory, and Algorithms.Kluwer (2002).S.-M. Kim and E. Hovy.
Determining the Sentiment ofOpinions.
Proc.
COLING?04, pp.
1367-1373.
2004.P.
Knees, T. Pohle, M. Schedl and G. Widmer.
A MusicSearch Engine Built upon Audio-based and Web-based Similarity Measures.
Proc.
of SIGIR'07, pp.47-454.
2007T.
Li and M. Ogihara.
Content-based music similaritysearch and emotion detection.
Proc.
IEEE Int.
Conf.Acoustic, Speech, and Signal Processing, pp.
17?21.2006.L.
Lu, D. Liu and H. Zhang.
Automatic mood detectionand tracking of music audio signals.
IEEE Transac-tions on Audio, Speech & Language Processing14(1): 5-18 (2006).B.
Pang, L. Lee and S. Vaithyanathan.
Thumbs up?
Sen-timent Classification using Machine Learning Tech-niques.
Proc.
of EMNLP-02, pp.79-86.
2002.R.
E. Thayer, The Biopsychology of Mood and Arousal,New York, Oxford University Press.
1989.P.
D. Turney and M. L. Littman.
Measuring praise andcriticism: Inference of semantic orientation from as-sociation.
ACM Trans.
on Information Systems,21(4):315?346.
2003.Y.
Yang and X. Liu.
A Re-Examination of Text Catego-rization Methods.
Proc.
of SIGIR?99, pp.
42-49.
1999.Y.
Yang and J. O. Pedersen.
A comparative study onfeature selection in text categorization.
Proc.ICML?97, pp.412-420.
1997.136
