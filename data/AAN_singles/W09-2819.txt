Proceedings of the 2009 Workshop on Language Generation and Summarisation, ACL-IJCNLP 2009, pages 101?102,Suntec, Singapore, 6 August 2009.c?2009 ACL and AFNLPUDel: Generating Referring ExpressionsGuided by Psycholinguistic FindingsCharles Greenbacker and Kathleen McCoyDept.
of Computer and Information SciencesUniversity of DelawareNewark, Delaware, USA[charlieg|mccoy]@cis.udel.eduAbstractWe present an approach to generating refer-ring expressions in context utilizing feature se-lection informed by psycholinguistic research.Features suggested by studies on pronoun in-terpretation were used to train a classifier sys-tem which determined the most appropriateselection from a list of possible references.This application demonstrates one way to helpbridge the gap between computational andempirical means of reference generation.1 IntroductionThis paper provides a system report on our submis-sion for the GREC-MSR (Main Subject References)Task, one of the two shared task competitions forGeneration Challenges 2009.
The objective is to se-lect the most appropriate reference to the main sub-ject entity from a given list of alternatives.
The cor-pus consists of introductory sections from approxi-mately 2,000 Wikipedia articles in which referencesto the main subject have been annotated (Belz andVarges, 2007).
The training set contains articlesfrom the categories of cities, countries, mountains,people, and rivers.
The overall purpose is to developguidelines for natural language generation systemsto determine what forms of referential expressionsare most appropriate in a particular context.2 MethodThe first step of our approach was to perform a lit-erature survey of psycholinguistic research relatedto the production of referring expressions by humanbeings.
Our intuition was that findings in this fieldcould be used to develop a useful set of featureswith which to train a classifier system to perform theGREC-MSR task.
Several common factors govern-ing the interpretation of pronouns were identified bymultiple authors (Arnold, 1998; Gordon and Hen-drick, 1998).
These included Subjecthood, Paral-lelism, Recency, and Ambiguity.
Following (McCoyand Strube, 1999), we selected Recency as our start-ing point and tracked the intervals between refer-ences measured in sentences.
Referring expressionswhich were separated from the most recent referenceby more than two sentences were marked as long-distance references.
To cover the Subjecthood andParallelism factors, we extracted the syntactic cate-gory of the current and three most recent referencesdirectly from the GREC data.
This information alsohelped us determine if the entity was the subject ofthe sentence at hand, as well as the two previoussentences.
Additionally, we tracked whether the en-tity was in subject position of the sentence wherethe previous reference appeared.
Finally, we madea simple attempt at recognizing potential interferingantecedents (Siddharthan and Copestake, 2004) oc-curring in the current sentence and the text since thatlast reference.Observing the performance of prototyping sys-tems led us to include boolean features indicat-ing whether the reference immediately followed thewords ?and,?
?but,?
or ?then,?
or if it appeared be-tween a comma and the word ?and.?
We also foundthat non-annotated instances of the entity?s name,which actually serve as references to the name itselfrather than to the entity, factor into Recency.
Fig-ure 1 provides an example of such a ?non-referentialinstance.?
We added a feature to measure distanceto these items, similar to the distance between refer-ences.
Sentence and reference counters rounded out101the full set of features.The municipality was abolished in 1928, and thename ?Mexico City?
can now refer to two things.Figure 1: Example of non-referential instance.
In thissentence, ?Mexico City?
is not a reference to the main en-tity (Mexico City), but rather to the name ?Mexico City.
?3 System DescriptionA series of C5.0 decision trees (RuleQuest ResearchPty Ltd, 2008) were trained to determine the mostappropriate reference type for each instance in thetraining set.
Each tree used a slightly different sub-set of features.
It was determined that one decisiontree in particular performed the best on mountainand person articles, and another tree on the remain-ing categories.
Both of these trees were incorporatedinto the submitted system.Our system first performed some preprocessingfor sentence segmentation and identified any non-referential instances as described in Section 2.
Next,it marshalled all of the relevant data for the featureset.
These data points were used to represent thecontext of the referring expression and were sent tothe decision trees to determine the most appropriatereference type.
Once the type had been selected, thelist of alternative referring expressions were scannedusing a few simple rules.
For the first instance of aname in an article, the longest non-emphatic namewas chosen.
For subsequent instances, the shortestnon-emphatic name was selected.
For the other 3types, the first matching option in the list was used,backing off to a pronoun or name if the preferredtype was not available.4 ResultsThe performance of our system, as tested on the de-velopment set and scored by the GREC evaluationsoftware, is offered in Table 1.5 ConclusionsWe?ve shown that psycholinguistic research can behelpful in determining feature selection for gener-ating referring expressions.
We suspect the perfor-mance of our system could be improved by employ-Table 1: Scores from GREC evaluation software.Component Score Valuetotal pairs 656reg08 type matches 461reg08 type accuracy 0.702743902439024reg08 type precision 0.702743902439024reg08 type recall 0.702743902439024string matches 417string accuracy 0.635670731707317mean edit distance 0.955792682926829mean normalised edit distance 0.338262195121951BLEU 1 score 0.6245BLEU 2 score 0.6103BLEU 3 score 0.6218BLEU 4 score 0.6048ing more sophisticated means of sentence segmen-tation and named entity recognition for identifyinginterfering antecedents.ReferencesJennifer E. Arnold.
1998.
Reference Form and DiscoursePatterns.
Doctoral dissertation, Department of Lin-guistics, Stanford University, June.Anja Belz and Sabastian Varges.
2007.
Generation of re-peated references to discourse entities.
In Proceedingsof the 11th European Workshop on NLG, pages 9?16,Schloss Dagstuhl, Germany.Peter C. Gordon and Randall Hendrick.
1998.
The rep-resentation and processing of coreference in discourse.Cognitive Science, 22(4):389?424.Kathleen F. McCoy and Michael Strube.
1999.
Gener-ating anaphoric expressions: Pronoun or definite de-scription.
In Proceedings of Workshop on The Rela-tion of Discourse/Dialogue Structure and Reference,Held in Conjunction with the 38th Annual Meeting,pages 63 ?
71, College Park, Maryland.
Associationfor Computational Linguistics.RuleQuest Research Pty Ltd. 2008.
Data miningtools See5 and C5.0.
http://www.rulequest.com/see5-info.html.Advaith Siddharthan and Ann Copestake.
2004.
Gener-ating referring expressions in open domains.
In Pro-ceedings of the 42th Meeting of the Association forComputational Linguistics Annual Conference, pages408?415, Barcelona, Spain.102
