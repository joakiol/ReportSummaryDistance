Multitiered Nonlinear Morphology UsingMultitape Finite Automata: A Case Studyon Syriac and ArabicGeorge  Anton  Kiraz*Bell Laboratories, Lucent TechnologiesHe who corrects the alphabetical ordering \[of this Lexicon\] does nottake into account he letters which are added, or those that change,here and there, due to inflexion at the beginning of the lexis \[i.e.,word\], but goes back to the base form of the word.- Abu Hasan Bar Bahl~l (ft. ca.
963)Syriac Lexicon, Duval's edition (Paris, 1888)This paper presents a computational model for nonlinear morphology with illustrations fromSyriac and Arabic.
The model is a multitiered one in that it allows for multiple lexical representa-tions corresponding to the multiple tiers of autosegmental phonology.
The model consists of threemain components: (i) a lexicon, which is made of sublexica, with each sublexicon representinglexical material from a specific tier, (ii) a rewrite rules component that maps multiple lexicalrepresentations into one surface form and vice versa, and (iii) a morphotactic omponent thatemploys regular grammars.
The system is finite-state in that lexica and rules can be representedby multitape finite-state machines.1.
In t roduct ionThis paper is concerned with presenting a general finite-state framework for comput-ing complex nonlinear (i.e., nonconcatenative) morphophonological descriptions.
Theframework subsumes previous models in that it is not only capable of handling thecomplex nonlinear morphological phenomena we are about to describe, but also theusual linear ones found in many languages.
The framework is a multitiered modelthat encompasses linear and nonlinear morphology.The elegance of the proposed framework lies in the fact that it is capable of han-dling sophisticated linguistic descriptions, uch as those of autosegmental phonology,in a computationally tractable way.
The model consists of three components.
The firstis a multitier lexicon that consists of several sublexica, each describing a lexical tieras in autosegmental phonology.
The second component is a bidirectional rewrite rulessystem that maps, inter alia, the multitier lexical representations to a linearized surfaceform and vice versa.
The third component provides morphotactic constraints.
The pro-posed framework has the computational property that its lexical and rule formalismsare compiled algorithmically into finite-state machinery using operators under whichfinite-state machines are closed.
* 700 Mountain Ave., Murray Hill NJ 07974.
E-mail: gkiraz@research.belMabs.com~) 2000 Association for Computational LinguisticsComputational Linguistics Volume 26, Number 1The rest of this section discusses the importance of nonlinear morphology andoutlines the research objectives of this work.1.1 Nonlinear MorphologyEarly generative morphophonological theory was mainly based on the linear segmen-tal approach of The Sound Pattern of English (Chomsky and Halle 1968).
In the midseventies, however, linguists had departed from this linear framework to a nonlinearone.
Goldsmith (1976), working on the phonology of African tone languages, pro-posed autosegmental phonology with multitiered representations.
Goldsmith madeuse of two tiers to describe tone languages: one to represent sequences of vowelsand consonants, and another to describe tone segments.
McCarthy (1979) applied au-tosegmental phonology to Semitic root-and-pattern morphology resulting in what isnow known as the theory of nonconcatenative (or nonlinear) morphology, as opposedto concatenative morphology.
McCarthy's findings have become ubiquitous.
In fact,"every aspect of the theory of morphology and morphophonology," remarks Spencer(1991, 134), "has had to be reappraised in one way or another in the wake of \[Mc-Carthy's\] analysis of Semitic and other languages.
"Spencer's statement could well apply to the theory of computational morphology.Two-level morphology (Koskenniemi 1983), as well as its predecessor in the work ofKay and Kaplan (1983), is also deeply rooted in the linear concatenative tradition.
In-deed, "if Koskenniemi had been interested in Arabic or Warlpiri rather than Finnish,"notes Sproat (1992, 206), "his system might have taken on a rather different characterfrom the start."
It would prove difficult, if not impossible, to implement Semitic lan-guages using linguistically motivated theoretical models such as those of McCarthyand others in the field with traditional two-level morphology.Kay (1987) was the first computational linguist to make use of McCarthy's find-ings.
He proposed that a four-tape finite-state machine, as opposed to the traditionaltwo-tape machines of two-level morphology, be used to describe the autonomousmorphemes of Arabic.
Kay devised a system for manipulating the multitape machine,albeit using an ad hoc procedure to control the movements of the machine's head(s).We shall build upon Kay's work by providing higher-level lexical and rule formalisms,and algorithms for compiling the formalisms into multitape machines, eliminating theneed for the ad hoc procedure that controls head movements.
We shall revisit Kay'sapproach in Section 6.1.Previous work to implement Semitic languages, namely, Akkadian (Kataja andKoskenniemi 1988), Arabic (Beesley, Buckwalter, and Newton 1989; Beesley 1990, 1991,1996, 1998a, 1998b, 1998c, forthcoming) and Hebrew (Lavie, Itai, and Ornan 1990),employed traditional two-level morphology with some augmentation to handle thenonlinearity of stems, but did not make any use of the then-available theory of non-concatenative morphology.
The challenge here lies in the fact that two-level morphol-ogy assumes the lexical representation f a surface form to be the concatenation fthe corresponding lexical morphemes in question.
To resolve the problem, these au-thors (with the exception of Beesley's work from 1996 on) provided for a simultaneoussearch of various root and affix lexica, the result of which served as the lexical tape ofthe two-level system.
We shall revisit these approaches in Sections 6.2 and 6.3.Other publications dealing with Semitic computational morphology are confinedto proposals for compiling autosegmental descriptions into automata (Kornai 1991;Wiebe 1992; Bird and Ellison 1992).
They revolve around encoding autosegmentalrepresentations (by various encoding mechanisms) and providing ways for compilingsuch encodings into finite machines.
None provide for lexicon and rule formalismsthat can be compiled into their respective ncodings or directly into automata.
No78Kiraz Multitiered Nonlinear MorphologySemitic language, to the best of the author's knowledge, has been implemented withthese proposals.
We shall revisit these approaches in Section 6.4.1.2 Research ObjectivesThe purpose of this work is to provide a theoretical computational framework underwhich nonlinear morphology can be handled in a linguistically and computationallymotivated manner with the following objectives in mind:1.
The framework is to present a general multitiered computationalmorphology model that allows for both linear and nonlinearmorphophonological descriptions.2.
The formalism of the framework is to handle various linguistic theoriesand models including McCarthy's initial findings as well as later modelsfor Hebrew (Bat-E1 1989), moraic theory (McCarthy and Prince 1990a,1995), the affixational approach to handling templates in Arabic(McCarthy 1993), and others.
That is, a flexible formalism that leaves thegrammar writer with ample room to choose the appropriate linguistictheory for an application.3.
Multitiered lexica and grammars written in the formalism are to becompiled into finite-state machines (multitape automata in this case).
Themultitape machines are created by a compiler that employs a finite-stateengine with an algebraic interface to n-way regular expressions.4.
The multitape machines are to be as close as possible in spirit totwo-level morphology in that surface forms map to lexical morphemes.Our lexical level is a multitiered representation.This paper provides an overall description of the theoretical framework, compila-tion algorithms, and illustrations.
Additionally, it discusses other related topics crucialto developing Semitic grammars.Results that emerged earlier from this work appear elsewhere (Kiraz 1994b, 1996,1997a, 1997b, 1997c, in press), but have been thoroughly enhanced and reworked since.New contributions include enhancing the theoretical framework (Section 3), compilinglexica and rules into multitape finite-state machines (Section 4), and evaluating thecurrent model with respect o previous ones (Section 6).2.
Problems in Semitic MorphophonologyThe challenges in implementing Semitic morphophonological grammars are numer-ous.
Here, we shall concentrate only on nonlinearity that poses computational diffi-culties to traditional finite-state models.2.1 The Nonlinear StemThe main characteristic ofSemitic derivational morphology is that of the "root and pat-tern."
The "root" represents a morphemic abstraction, usually consisting of consonants,e.g., {ktb} 'notion of writing'.
Stems are derived from the root by the superimpositionof patterns.
A "pattern" (or "template") is a sequence of segments containing Cs thatrepresent the root consonants, e.g., ClaC2C2aC3 and maC1C2aC3 (the indices refer toroot consonants).
Root consonants are slotted in, in place of the Cs, to derive stems,e.g., Arabic/kattab/ 'wrote '  and/maktab/ 'of f ice '  from the root {ktb} and the abovetwo patterns, respectively.79Computational Linguistics Volume 26, Number 1Table 1Syriac verbal stems with the root {ktb}.
The dataprovides tems in underlying morphological forms;surface forms are parenthesized.
The passive ismarked by the reflexive prefix {?et}.Measure Active Passive ({?et}+)P%l (1) katab (ktab) kateb (?etkteb)Pa~%l (2) katteb kattab?afqel (3) ?akateb (?akteb) ?akatab (?ettaktab)3 a eI IC V C V (7: C V C, C V C,I I I V Ik t b k t ba eV C, V C V CI I Ik t b(~) (b)/katab/ /katteb/ (c)/?akat eb/Figure 1Autosegmental representations of Syriac Measures 1-3.
Each morpheme sits on its ownautonomous tier.2.2 Various Linguistic ModelsThere are various linguistic models for representing patterns.
In traditional accounts,the "vocalism" (i.e., vocalic elements) is collapsed with the pattern (Harris, 1941),e.g., maC1C2aC3 above.
Since the late 1970s, however, more sophisticated descriptionshave emerged, most notably by McCarthy (1981, 1986, 1993) and McCarthy and Prince(1990a, 1990b, 1995).Consider the Syriac verbal data in Table 1 containing verbs classified according tovarious measures.
1 Glancing over the table horizontally, one notes the same patternof consonants and vowels per measure; the only difference is that the vowels areinvariably {ae} in active stems, but {aa} in passive stems (apart from Measure 1whose vocalism is idiosyncratic, a general Semitic phenomenon).
Surface forms thatresult after phonological rules are applied appear in parentheses.
The vowel after \[k\]in the Measure 1 and 3 forms, for example, is deleted because it is a short vowel in anopen syllable, a general phenomenon ofAramaic (of which Syriac is a dialect).
Further,\[7\] in the passive of Measure 3 is assimilated into the preceding \[t\] of the reflexiveprefix.
Both rules are employed in * /?et?akatab/~ /?ettaktab/.Under McCarthy's autosegmental nalysis, a stem is represented by three au-tonomous morphemes: a consonantal root, a vocalism, and a pattern that consists ofCs and Vs. For example, the analysis of /katteb/ (Measure 2) produces three mor-phemes: the root {ktb} 'notion of writing', the vocalism {ae} 'PERF ACT' and thepattern {CVCCVC} 'Measure 2'.
Some stems include affix morphemes, e.g.
the prefix{?a} of Measure 3; these sit on their own tier.
The segments are linked together by as-sociation lines as in Figure 1.
Note the spreading of \[a\] in /katab /and  the geminationof \[t\] in /katteb/ .1 The term "measure" is employed by native grammarians to denote a specific pattern.80Kiraz Multitiered Nonlinear MorphologyO" O'xn a f s(7 o" o,c ?,/r a j  uO" (7 (7 a.
(7 (7 O'.r O" O" O',rJ a. z 1 I r .\] a a.
111 i i  Ii s t, a a 11(a) (b) man (c) island (d) buffah) (e) sultansou lFigure 2Moraic analysis of the Arabic nominals.
Glosses appear under each autosegmental structure.Consonants and vowels, although shown on the same line, belong to different iers.While McCarthy's initial model is the most visible in the computational linguisticsliterature, it is by no means the only one.
McCarthy and Prince (1990b) argue forrepresenting the pattern morpheme in terms of the authentic units of prosody.
Considerthe Arabic nominal stems and their moraic analysis in Figure 2.
Here, a pattern isrepresented by a sequence of syllables, as.
Association takes the following form: asyllable node cr takes a consonant, and its mora # takes a vowel.
In bimoraic syllables,the second # may be associated with either a consonant or a vowel.
At the right edge,all stems end in an extrametrical consonant, denoted by Crx.Other linguistic models have been described by Hammond (1988), Bat-E1 (1989),and McCarthy (1993).2.3 Orthographic IssuesIn addition to the linguistic peculiarities of Semitic, the writing system adds furthercomplications.
The vast majority of Semitic texts (apart from Ethiopic) are orthograph-ically underspecified.
Short vowels are absent from the orthography.
(Imagine the pre-vious sentence had been written "shrt vwls ?r ?bsnt frm th ?rthgrph!")
We shall dealwith vocalization issues in Section 5.4.3.
The Theoretical Framework: A Multitiered ModelThe model presented here assumes two levels of linguistic description in recognitionand synthesis.
The lexical level employs multiple representations (e.g., for patterns,roots, and vocalisms), while the surface level employs only one representation.
Theupper bound on the number of lexical representations is not only language-specific,but also grammar-specific.The proposed model is divided into three components: (i) a lexicon component,which consists of multiple sublexica, each representing entries for a particular lexicalrepresentation r tier, (ii) a rewrite rules component, which maps the multiple lexicalrepresentations to a surface representation, and (iii) a morphotactic component, whichenforces morphotactic constraints.Throughout he following discussion, a tuple of strings represents a surface-to-lexical mapping, where the first element of the tuple represents the surface form andthe remaining elements represent lexical forms.
For instance, the tuple of strings thatrepresents the mapping of /katab/ to its lexical forms is (katab,cvcvc,ktb,a).
2 Theelements are: surface, pattern, root, vocalism.2 Capital-initial strings will be used shortly to denote variables.
For this reason, we represent the patternusing small letters.81Computational Linguistics Volume 26, Number 13.1 The Lexicon ComponentHere, the lexicon consists of multiple sublexica, each sublexicon containing entries forone particular lexical representation (ortier in the autosegmental analysis).
Since an n-tuple contains n -  1 lexical elements (the first element is the surface representation), thelexicon component consists of n - 1 sublexica.
A Syriac lexicon for the data in Table 1requires a pattern sublexicon, a root sublexicon, and a vocalism sublexicon.
Otheraffixes that do not conform to the root-and-pattern nature of Semitic morphology (e.g.,the reflexive prefix {?et}) can either be given their own sublexicon or placed in oneof the three sublexica.
Since pattern segments are the closest--in terms of number--to surface segments, uch morphemes are represented in the pattern sublexicon byconvention.As a way of illustration, the first sublexicon for the Syriac data in Table 1 containsthe following entries: {?et} (representing the reflexive prefix) and {cvcvc} (for theverbal pattern).
Here, we have chosen to derive all verbs from this pattern in a wayreminiscent of McCarthy (1993) rather than entering separate patterns for each mor-pheme.
The second sublexicon maintains roots, e.g., {ktb} 'notion of writing', {pnq}'notion of delight', and {qrb} 'notion of approaching'.
The third sublexicon maintainsvocalisms: {ae} for active stems and {a} (with spreading) for passive ones.3.2 The Rewrite Rules ComponentThe rewrite rules component maps the multiple lexical representations to a surfacerepresentation a d vice versa.
It also provides for phonological, orthographic, andother rules.
The current model adopts the formalism presented by Ruessink (1989)and Pulman and Hepple (1993) with additional extensions to handle multiple lexicalforms.
Below, the top line represents the lexical tiers and the bottom line representsthe corresponding surface form:LLC - LEX -- RLC {o , -}LSC - SURF -- RSCLLC denotes the left lexical context, LEX denotes the lexical form, and RLC denotesthe right lexical context.
LSC, SURF and RSC are the surface counterparts.
The con-text denoted by "*" represents Kleene star as applied to the grammar alphabet (i.e.,matching anything).
When all four contexts are "*", they are omitted from rules; i.e.,the formalism becomes:LEX { =G -- }SURFFurther, capital-initial expressions are variables over predefined finite sets of symbols.The operator ~ is the optional operator.
It states that LEX may surface as SURFin the given context, but may surface otherwise if sanctioned by another ule.
Theoperator - adds obligatory constraints: when LEX appears in the given context, thenthe surface description must satisfy SURF.
A lexical string maps to a surface string ifand only if they can be partitioned into pairs of lexical-surface subsequences, where (i)each pair is licensed by a ~ rule, and (ii) no sequence of zero or more adjacent pairsviolates a - rule.
The interpretation f the latter condition is based on Grimley-Evans,Kiraz, and Pulman (1996).
(See Kiraz \[in press\] for the historical development of theformalism.
)Several extensions are introduced into the formalism to handle multitiered repre-sentations.
Expressions on the upper lexical side (LLC, LEx, and RLC) are tuples ofstrings of the form {Xl, x2,..., Xn-1}.
The ith element in the tuple refers to symbols inthe ith sublexicon of the lexical component.
When a lexical expression makes use of82Kiraz Multitiered Nonlinear Morphology(c,X,s)RI: Xwhere X is a consonant.
(v ,~,x )  =~R2: Xwhere X is a vowel.
* - -R3: * - s -where X is a vowel.CV,.
*, *) - -Figure 3Rules for the derivation of Syriac/ktab/.
R1 and R2 sanction root consonants and vowels,respectively, while R3 handles vowel deletion.\]a a vocalismk j t, b rootc iv c v c pallern13121Iki t a(~)Figure 4k J t i  b tool?
e, t c ,v ic  Iv c lmllern.
~; affi,res00013121\[?
eit ,  k it, i .
(b)Lexical-surface analysis of Syriac/ktab/and/?etktab/.
Vocalic spreading is ignored in thisexample (see Section 5.1).only the first sublexicon, the angle brackets can be ignored.
Hence, the LEX expression(x, e .
.
.
.
.
e) and x are equivalent; in lexical contexts, (x,, .
.
.
.
, *) and x are equivalent.Additionally, the symbol "*" now denotes Kleene star as applied to the alphabet ofthe respective tier.The formalism is illustrated in Figure 3.
The rules derive Syr iac/ktab/(under ly ing*/katab/) from the pattern morpheme {cvcvc} 'verbal Measure 1', the root morpheme{ktb} 'notion of writing', and the vocalism morpheme {aa} 'PERF ACT' (ignoringspreading for the moment).
Rule R1 sanctions root consonants by mapping a \[c\] fromthe first (pattern) sublexicon, a consonant \[X\] from the second (root) sublexicon, and nosymbol from the third (vocalism) sublexicon to surface \[X\].
Rule R2 sanctions vowelsin a similar manner.
The obligatory rule R3 deletes the first vowel of * /katab / in  thegiven context.
The mapping is illustrated in Figure 4(a).
The numbers between thesurface and lexical expressions indicate the rules in Figure 3 that sanction the shownsubsequences.
Empty slots represent the empty string ?.As stated above, morphemes that do not conform to the root-and-pattern nature ofSemitic (e.g., prefixes, suffixes, particles) are given in the first sublexicon.
The identityrule:R0XXwhere X ?~ {c, v}maps such morphemes to the surface.
The rule basically states that any symbol not83Computational Linguistics Volume 26, Number 1Table 2Syriac circumfixes of theimperfect verb.Number Gender CircumfixSing.
masc.
he-Sing.
fern.
te-P1.
masc.
ne-~nP1.
fern.
te-anin { c,v } from the first sublexicon may optionally surface.
Figure 4(b) illustrates theanalysis o f /?etkatab/ f rom the morphemes given earlier.3.3 The Morphotactics ComponentSemitic morphotactics is divided into two categories: Templatic morphotactics occurswhen the pattern, root, vocalism, and possibly other morphemes, join together in anonlinear manner to form a stem.
Non-templatic morphotactics takes place when thestem is combined with other morphemes to form larger morphological or syntacticunits.
The latter is divided in turn into two types: linear nontemplatic morphotactics,which makes use of simple prefixation and suffixation, and nonlinear nontemplaticmorphotactics, which makes use of circumfixation.Templatic morphotactics is handled implicitly by the rewrite rules component.
Forexample, the rules in Figure 3 implicitly dictate the manner in which pattern, root, andvocalism morphemes combine.
Hence, the morphotactic component need not worryabout templatic morphotactics.Linear nontemplatic morphotactics is handled via regular operations, usually n-way concatenation (Kaplan and Kay 1994) in the multitiered case.
Consider for ex-ample Syriac /?etktab/ and its lexical analysis in Figure 4(b).
The lexical analysis ofthe prefix is/?et, e, ?/and that of the stem is (cvcvc, ktb, aa~.
Their n-way concatena-tion gives the tuple /?et cvcvc, ktb, aa/.
One may also use the "continuation classes"paradigm familiar from traditional two-level systems (Koskenniemi 1983, inter alia),in which lexical elements on each sublexicon are marked with the set of morphemeclasses that can follow on the same sublexicon.The last case is that of nonlinear nontemplatic morphotactics.
Normally this arisesin circumfixation operations.
The following morphotactic rule formalism is used todescribe such operations:A ~ PBS(P,s) (pl,sl)(P, S) ---+ (p2, $2)(P,S) (pn, sn)A circumfix here is a pair (P, S) where P represents he prefix portion of the circumfixand S represents the suffix portion.
The circumfixation operation PBS applies thecircumfix (P, S) to B.
By way of illustration, consider the Syriac circumfixes of theimperfect verb in Table 2.
The circumfixation of the circumfixes to the stem Syriac84Kiraz Multitiered Nonlinear Morphology/k tob/  'to write - IMPF' is:Verb --* P ktob S(P,S) --* (ne,?
)(P,S) --* (te, c)(P,S)---* (te, On)(P,S) --* (te, An)Unlike traditional finite-state methods in morphology that employ two-tape trans-ducers, the proposed multitiered model requires multitape transducers.
The algorithmsfor compiling the three components into such machines are given next.4.
Algorithms for Compilation into Multitape AutomataMultitape finite-state machines were first introduced by Rabin and Scott (1959), and El-got and Mezei (1965).
An n-tape finite-state automaton (FSA) is a 5-tuple (Q, G, 6, q0, F),where Q is a finite set of states, G is a finite input alphabet, 6: Q x (p,~)" --, 2 Q is atransition function (where G* = G u { ~ } and c is the empty string), q0 E Q is aninitial state, and F C_ Q is a set of final states.
An n-tape FSA accepts an n-tuple ofstrings if and only if starting from the initial state q0, it can simultaneously scan allthe symbols on every tape i, 1 < i < n, and end up in a final state q E F. An n-tape finite-state transducer (FST) is simply an n-tape finite-state automaton but witheach tape marked as to whether it belongs to the domain or range of the transduc-tion.In addition to common operators under which finite machines are closed, thealgorithms discussed below make use of the following three operators:DefinitionLet L be a regular language.
Id,(L) = {X I X is an n-tuple of the form Ix , .
.
.
,x l ,  x EL } is the n-way identity of L.DefinitionLet R be a regular elation over the alphabet Y, and let m be a set of symbols not neces-sarily in G. Insertm (R) inserts the relation Idn (a) for all a E m freely throughout R.The identity and insert operators are the n-tape version of their counterparts inKaplan and Kay (1994).
3DefinitionLet S and S ~ be same-length n-tuples of strings over some alphabet G, I = Idn(a)for some a E G, and S = $1IS2I... Sk, k > 1, such that S i does not contain I; i.e.,Si E (~n _ {i}),.
We say that Subst i tu t@(s , , i  ) (S) = $1S '$2S ' .
.
.
Sk substitutes everyoccurrence of I in S with Sq3 Insert is also called the ignore operator, e.g., in the Xerox finite-state compiler (Karttunen and Beesley1992; Karttunen 1993).85Computational Linguistics Volume 26, Number 1<v,O,a>( :Y,   'q'7 <v,o,o<v,O,a>Figure 5: ~ , t ,O>Multitape representation f the lexicon.<v,O,e><v,O,e>4.1 Building a Multitape LexiconThe compilation process builds a one-tape automaton for each sublexicon.
The sub-lexica are then put together using the cross product operator with the effect hat theresulting machine accepts entries from the ith sublexicon on its ith tape.Representing a lexical entry W in an automaton is achieved by concatenating thesymbols of W one after the other.
Now let ?i = { W1, W2,... } be the set of lexicalentries in the ith sublexicon.
The expression for the ith sublexicon becomes:Li= U W (1)WE f-.i(Daciuk et al \[2000\] give a more sophisticated incremental lgorithm for compilingacyclic lexica.
)The overall exicon can then be expressed by taking the cross product of all thesublexica.
To make the final lexicon accept same-length uples, we insert 0s throughout,Lexicon=(HInsert{o}(Li))Nrr*\ i=1(2)All invalid tuples resulting from the cross product operation (e.g., (0,0 .
.
.
.
.
0)) areremoved by the intersection with 7r*, where 7r is the set of all feasible tuples computedfrom rules (see Section 4.2).
By way of illustration, Figure 5 gives the lexicon for thepattern {cvcvc}, the roots {ktb}, {pnq}, {qrb}, and {prq}, and the vocalism {ae}.4.2 Compiling the Rewrite Rules ComponentThe algorithm for compiling rewrite rules is based on collaborative work by the authorwith E. Grimley-Evans and S. Pulman (Grimley-Evans, Kiraz, and Pulman 1996).
Thecompilation process is preceded by a preprocessing stage during which all mappingsof unequal lengths are made same-length mappings by inserting a special symbol, 0,when necessary.
(The grammar writer need not worry about this special symbol, butcannot use it in the grammar.)
This is necessary because -containing transducers arenot closed under intersection and subtraction.
Additionally, during preprocessing thefollowing sets are computed: the set of all feasible tuples sanctioned by the grammar,7r (used in expression (2) above); and the set of feasible surface symbols, 7rs (to be usedin expression (23) in Appendix A).The actual compiler takes as its input rules that have been preprocessed.
Thealgorithm is subtractive in nature: it starts off by creating an automaton that acceptssequences of feasible tuples that are sanctioned by rules regardless of context, thenstarts subtracting strings which violate the rules.
This subtractive approach was firstsuggested by E. Grimley-Evans.86Kiraz Multitiered Nonlinear MorphologyS:<S,S,S>Figure 6A four-tape machine for accepting centers.
The symbol s denotes the partition symbol ?.
Thesurface symbol appears to the left of ":" and the lexical tuple to its right.4.2.1 Accepting Centers.
Recall that in the formalism of Section 3.2, a lexical stringmaps to a surface string if and only if they can be partitioned into pairs of lexical-surface subsequences, where (i) each pair is licensed by a ~ rule, and (ii) no sequenceof zero or more adjacent pairs violates a - rule.Let c = s:(ll, 12,. .
.
I  be the center of a rule where s is the surface form and li are thelexical forms, and let C be the set of all such centers in the grammar.
Further, let ?
bea special symbol (not in the grammar's alphabet) to denote a subsequence boundarywithin a partition, and let or' = Tdn(Cr ).
The automaton that accepts the centers of thegrammar is described by the relationCenters = cr'(C ~r')* (3)Centers accepts any sequence of the centers described by the grammar (each cen-ter surrounded by cr/) irrespective of their contexts.
Assuming that /k tab/  is underconsideration, Figure 6 gives the four-tape machine for the centers of the rules fromFigure 3.4.2.2 Valid Contexts.
Now we eliminate all the sequences whose left and right con-texts violate the grammar.
For each center c E C in the entire grammar, let LRc ={(&l, Pl), (2~2,/92) .
.
.
.  }
be the set of valid left and right context pairs for that center.
Theinvalid contexts for c, are expressed by:Restrict = 7r* c 7r* - U &cp (4)(2,,.)
c LRcThe first component of expression (4) gives all the possible contexts for c. The sec-ond component gives all the valid contexts for c. The subtraction results in all theinvalid contexts for c. However, since ?
appears freely in expression (3), it needs to beintroduced in expression (4) as well, resulting in:Restrict:Insert, (*C * (5)The relation in expression (5) works only if the center consists of just one tuple.
Inorder to allow it to be a sequence of tuples, c must be surrounded by c /on  both sides87Computational Linguistics Volume 26, Number 1a:<v,0,a~s:<s,s,s~s:<s,s,s>k:<c.k.O>k:<c.k.O> s:<s,s.s>O:<v,O.a> ?s:<s,s,s>Figure 7The machine from Figure 6 is repeated here after processing the rules in Figure 3.to mark it as one Subsequence.
It also must be devoid of any ?'.
The first conditionis accomplished by simply placing er I to the left and right of c. As for the secondcondition, an auxiliary symbol co is used as a placeholder representing c in order toavoid inserting ?'
within the tuples of c by Insert.
Hence, first we introduce r freelyusing Insert,  then substitute c back in place of 02,Restrict = (6)where 0Y = Idn(cO).
Finally, for each c we subtract all such invalid relations fromCenters, yielding the relation,ValidContexts = Centers - m Restrict (7)ValidContexts now accepts all the sequences of tuples described by the grammar basedon their contexts; however, it does not enforce obligatory rules.
Figure 7 gives themachine after the center of R3 from Figure 3 has been processed.4.2.3 Obligatory Rules.
For each obligatory rule, let C represent the center c with thecorrect lexical expressions and the incorrect surface expression.
The following relationdescribes all sequences of tuples that contain an unlicensed segment:Coerce= O Insert{C} (A~r'Ca'p) (8)(~,,p)ELaThe two ?/s surrounding C ensure that obligatoriness applies to at least one lexical-surface subsequence.
The Insert  operator inserts additional cr/s through the contextsand the center.
The insertion of ?'
through the center allows Coerce to apply to a seriesof lexical-surface subsequences.
To handle the case of epenthetic rules, one needs toallow Coerce to apply on zero subsequences as well.
In such a case, one takes the unionof expression (8) with Insert{C} (Aer'p), i.e., the empty subsequence.Finally, we subtract Coerce from the ValidContexts relation, yielding the relation:Rules = ValidContexts - m Coerce (9)88Kiraz Multitiered Nonlinear Morphologya:~.O.a>k:~c.k.O> k:<c3t O>o:<v.o.~ ~:<s.s.s>a:o.O.~> 0 :~.o .~Figure 8The machine from Figure 7 is repeated here after processing the obligatory rule R3 fromFigure 3.The relation accepts all and only the sequences of tuples described by the grammar.Figure 8 gives the machine after processing the obligatoriness of rule R3.
The last stepin compiling rules is to remove all instances of the symbol ~ and the symbol 0.4.3 Compiling the Morphotactic ComponentThe only class of morphotactics that is of interest here is nonlinear nontemplatic cir-cumfixation per the formalism in Section 3.3.
Let (P, S) = { (pl, Sl), (p2, s2),.
?., (pn, Sn) }be a set of circumfixes and let B be the domain of the circumfixation operation.
A ruleA ~ PBS is compiled into an automaton by the expression in (10):A:  LJ pBs (10)(p,s) S (P,S)An equivalent approach to handling circumfixation is to follow the subtractive ap-proach used in compiling the rewrite rules component above by first overgeneratingand then subtracting all invalid forms.
The two approaches, union or subtraction, areformally equivalent in that they result in the same machine.
Compilation using theunion approach, however, is more efficient in terms of time complexity than the sub-tractive approach.
The latter requires invoking negation and intersection algorithms,both of which are computationally expensive.
It must be noted that the union approachrequires a great deal of care in creating a machine that accepts only grammatical formswith no overgeneration.Beesley (1998c) employed a similar approach for eliminating invalid forms in Ara-bic long-distance dependencies by means of composition.5.
Developing Semitic GrammarsWhen developing Semitic grammars, various issues and problems arise that normallydo not occur with linear grammars.
This section aims at pointing out some of theseissues.5.1 Handling the Nonlinear StemThe example lexica and rules in Sections 3.1 and 3.2 demonstrate how the CV-basedtemplates are implemented in the current framework.
Further, spreading and gemina-tion, which tend to cause difficulties in other computational frameworks (see Section 6),are represented easily in the multitiered model without having to resort to ad hoc no-tation.
For example, the following rule, which uses prosodic templates, demonstrates89Computational Linguistics Volume 26, Number 1the intrasyllabic spreading of vowels:Intrasyllabic spreading: (a,a, C, V)CVVExtrametricality: {ax, C, e} ?~CThe symbol a~, above is a templatic segment denoting a bimoraic syllable.
The rulestates that when a , ,  appears on the pattern tape, a consonant C and a vowel V are readfrom the root and vocalism tapes, respectively; the corresponding surface segments areCVV.
In conjunction with the extrametricality rule above, one obtains surface-lexicaltuples like 3aamuus:(a~a~ax, 3ms, au), where the element o the left of ":" is thesurface form and the tuple to its right represents he lexical forms (see Figure 2(d)).Gemination is handled in one of two ways: The first marks pattern consonantalsegments (C or as) with a subscript (e.g., CIVCaVC3) and provides rules to geminate theappropriate consonant, e.g.,Gemination in /kattab/ :  {c2,X,e) 4:~ XXThe second approach leaves pattern segments unmarked, but provides the properleft and right contexts in rules.
The former approach requires more annotations inlexica and rules, but provides for smaller machines ince no context expressions areused.
The opposite holds for the later approach.
Both, however, require rule features(see Section 5.2) to ensure that the rule applies only to the desired measures.As the multitiered framework does not put any limitations on the number of lexicaltapes, the grammar writer may also choose to place affixes on their own autonomoustape.
Hence, one produces urface-lexical tuples like ?akateb:(?a, cvcvc, ktb, ae) (seeFigure 1(c)).5.2 Using Features to Handle IdiosyncraciesVarious lexical and morphotactic constraints exist in Semitic.
For instance, roots donot appear in all verbal measures; rather, each root occurs in the literature in a subsetof the measures, e.g., {pnq} does not exist in Measure 1 (one gets such informationfrom dictionaries and corpora).
Another example is that the vocalisms of Measure1 in almost all Semitic languages are lexically marked for each root.
In the currentframework, categories of the form:cat-nameATTRIBUTE1 ~ VALUE1ATTRIBUTE2 = VALUE2are used in the lexicon as well as rules to resolve such issues (Bear 1988; Ritchie et al1992).
Here, a value can be either an atom or a set of atoms.
For example, the set ofmeasures in which a root occurs are given in the attribute MEASURE below: \[pattern \]ktb MEASURE = { 1,2,3 } ,VOWEL = a\[ \] qrb MEASURE = { 1,2,3 }VOWEL ~ epattern \]pnq MEASURE = { 2,3 } ,VOWEL ~--- NA90Kiraz Multitiered Nonlinear MorphologyThe vocalisms of Measure I for various roots are marked with the attribute VOWEL.Hence, one gets \[a\] in /k tab / ,  but \[e\] in /qreb/ .Categories are also used in rules.
For example, the gemination rule above is asso-ciated with a category that indicates the measures in which gemination is valid.
Thedefinition of rule obligatoriness is extended to include categories (Pulman and Hepple1993).
The categories are incorporated in the automata compilation process followingthe algorithms in Kiraz (1997a).5.3  L inear  versus  Non l inear  GrammarsConsidering that nonlinearity in Semitic occurs mainly in the stem, maintaining anonlinear lexical representation in rewrite rules causes rules that describe one phono-logical/orthographic phenomenon to be duplicated.
This becomes a challenge to thegrammar writer since Semitic employs very rich phonological rules: assimilation, dis-similation, prosthesis, anaptyxis, syncope, haplology, etc.
(Moscati et al 1969, Sec-tion 9.1 ft.).Consider the derivation of Syr iac/ktab/us ing the rules in Figure 3.
Since voweldeletion in Syriac applies right-to-left, when adding the object pronominal suffix {eh}'MASC 3RD SING', the second vowel should be deleted, */katabeh/ --* /katbeh/.
Byvirtue of its right lexical context, however, R3 in Figure 3 can only apply to the firststem vowel.
Another rule (R4 below) is required for der iv ing/katbeh/from */katab/and the suffix {eh}, where the second stem vowel is deleted.
* - - ( cV ,* , * )R4 * - e - *where V is a vowel.The c in the right lexical context is a concrete symbol from a pattern morpheme, whileV represents the class of all vowels.This does not resolve the problem.
Both R3 and R4 fail when the deleted vowelitself appears in the prefix, e.g.
/wakatbeh/ --* /wkatbeh/ (with the prefix {wa}),requiring another ule.
An additional rule is also needed to delete prefix vowels whenthe right context belongs to a (possibly another) linear prefix, e.g., prefixing the se-quence {wa} 'and', {la} 'to', and {da} 'of' to the stem /katab/ giving /waldaktab/(the \[a\] of {la} and the first stem vowel are deleted).The above examples clearly illustrate the proliferation that would result.
Consid-ering that such phonological rules do not depend on the nonlinear lexical structureof the stem, a better approach divides the lexical-surface mappings into two separateproblems.
The first handles the templatic nature of morphology, mapping the multi-ple lexical representation i to a linearized lexical form, somewhat corresponding toMcCarthy's notion of tier conflation (McCarthy 1986).
Linearization of autosegmentalrepresentations in general has been suggested earlier by Kornai (1991, 1995).The second takes care of phonological/orthographic/graphemic appings be-tween the linearized lexical form and the actual surface.
The entire grammar is takenas the composition of two sets of rules (Karttunen, Kaplan, and Zaenen 1992).
Com-position, however, needs to be defined for multitape machines.
First, we redefine ann-tape finite-state machine as (Q, E, 6, q0, F, d), where the first five elements are as be-fore and d, 1 < d < n, is the number of domain tapes (the number of range tapes issimply n - d).Def in i t ionLet A = (Q1, El, 61, ql, F1, dl) and B = (Q2, ~"2, 62, q2, F2, d2) be two multitape machinesover nl and n2 tapes, respectively.
Further, let si denote the symbol on the ith tape.91Computational Linguistics Volume 26, Number 1There is a composition of A and B, denoted by C, if and only if d2 = nl - dl withC = (Q1 x Q2,~1 u ~2,6, \[ql, q2\],F1 x F2,dl) where for all pl E Q1 and p2 E Q2,6(\[pl,p2\],Sl : " "  : Sdl :s' d2q-1  : " " ?
: Sn2)\ [~ l (p l , s l  : .
.
.
:sdl  : sd l+l  : .
.
.
: sn, ) ,i .
S /  i ~2(p2,s~ : .
?
.
:% ?
d2+1 : ' .
.
: s,2)\]if and only if sd~+l = s~ .
.
.
.
s,~ = s'?
d2 .The resulting machine is an k-tape machine, where k = dl - d2 q- n2.
In our imple-mentation (see Section 7, and Appendix A), the domain and range tapes are given asarguments to the composition function, rather than coding them in machines, in orderto allow for flexibility in using machines.5.4 VocalizationSemitic texts appear in three forms: consonantal texts, which do not incorporate anyvowels but matres lectionis; partially vocalized texts, which incorporate some vowelsto clarify ambiguity; and vocalized texts, which incorporate full vocalization.Handling all such forms is resolved in line with the previous discussion on lin-earizafion.
The grammar writer should assume full vocalization when writing gram-mars.
This will not only get rid of the duplicated rules for the same phonologi-cal/orthographic phenomenon, but will also make understanding and debugging rulesan easier task.
Once a lexical-surface r write rules system has been achieved, a set ofrules that optionally delete vowel segments are specified and composed with the entiresystem.6.
Other Approaches to Finite-State Semitic Morphology6.1 Kay's Multitape ApproachKay (1987) proposed handling the autosegmental analysis of Arabic by means of mul-titape automata?
Kay adds some extensions to traditional FSTs.
Transitions are markedwith quadruples of elements (for vocalism, root, pattern, and surface form, respec-tively), where each element is a pair: a symbol and an instruction concerning themovement of the tape's head.
Kay uses the following notation: An unadorned symbolis read and the tape's head moves to the next position.
A symbol in brackets, \[ \], isread and the tape's head remains stationary?
A symbol in braces, { }, is read and thetape's head moves only if the symbol is the last one on the tape.The transitions for the analysis of Syr iac/kattab/ ' to  write--CAUSATIVE, PASSIVE',excluding the reflexive prefix {?et}, are shown in Figure 9.
After the first transitionon the quadruple {\[ \], k, C, k} in Figure 9(a): no symbol is read from the vocalismtape, \[k\] is read from the root tape and the tape's head is moved, \[C\] is read from thepattern tape and the tape's head is moved, and \[k\] is written on the surface tape andthe tape's head is moved?
At the final configuration, all the tapes have been exhausted.Kay makes use of a special symbol, G, to handle gemination; when read, a symbolfrom the root tape is scanned without advancing the read head of that tape.The model suffers from a number of shortcomings, ome of which have alreadybeen pointed out (Bird and Ellison 1992, Section 5.1).
Firstly, the use of various bracket-ing notations to control the moves of the machine head(s) causes the read heads of thethree upper input tapes to move independently of each other; this put the expressive-ness of the device under question: Bird and Ellison (1992, but not 1994) questioned theformal power of the device.
Wiebe (1992), citing formal results from Fischer (1965),92Kiraz Multitiered Nonlinear MorphologyI "k!
!
!
!
!
iS i t ib i  i i k iv!oic',ivic, I cI\[ki i i i 1~I I i Ik i t i i> l  i i {}I{kiwi i i i I<,I I~,i !
!
\[\]E~kil,~i>l i ~ .
\[1\](",IViGiCiViC o(b)i i I~,Ii klt, TI--;ic, jv!eiC',TVicI\ [k i~ i t i  i i \]t(4) (,:)i I a i i  \ [}I k !
t ib l  \[~\]CIVIGtCtViC OM\ [ \ ]V\] ikil, ib \[b,!
(:ivi(;ic!vlc, c1 i 1\[ki~ititi i l* \[kia.
i t i t ,  iai \]a \ [k}a i t i t la tb ib(d) (e) (?
)Figure 9Kay's Analysis of Syriac/kattab/.
The four tapes are (from top to bottom): vocalism tape, roottape, pattern tape, and surface tape.
Transition quadruples are shown at the right side of thetapes.
The symbol "~" between the lower surface tape and the lexical tapes indicates thecurrent symbols under the read/write heads.stated that Kay's machine goes beyond finite-state power.
No consensus has beenreached on the matter to the best of the author's knowledge.
In contrast, our pro-posed n-tape machines move all the read heads simultaneously ensuring finite-stateexpressive power.
Secondly, the introduction of ad hoc symbols to templates (e.g., Gfor gemination) moves away from the spirit of association i  autosegmental phonologythat Kay wanted to model; other special symbols must also be added to completelyimplement the rest of the paradigm in question.We have demonstrated, however, the usefulness of Kay's proposal.
Indeed, if oneeliminates the ad hoc controls of the read head(s) and provides a rule formalismfrom which machines can be compiled algorithmically, the multitape model is quiteadequate for describing autosegmental representations.6.2 The Intersection of Lexica ApproachKataja and Koskenniemi (1988), working on Akkadian, developed a system undertraditional two-level morphology.
It was mentioned earlier (see Section 1.1) that thechallenge of handling Semitic morphology within traditional two-level morphology isthat the lexical level is not merely the concatenation of the morphemes in question.Kataja and Koskenniemi resolved this by devising a "lexicon component" thatmakes use of two lexica: one for roots and the other for stem patterns and affixes.Entries in the former leave affix elements unspecified, while entries in the latter leaveroot elements unspecified.
For example, the lexical entry for the Arabic root morpheme{ktb} takes the formE~ kEp tEpbEp (11)where Ep is the alphabet of nonroot segments; likewise, the entry for the perfect passivevocalism {ui} takes the form:E r u E r i E r (12)where Gr is the alphabet of root segments.
The intersection of both expressions allowsfor the well-formed str ing/kutib/ ,  as well as numerous ill-formed sequences such as*/ktbui/, inter alia.
Under this framework, the result of the intersection becomes the93Computational Linguistics Volume 26, Number 1lexical level of a traditional two-level morphology system.
The two-level system thentakes care of other morphological, phonological, and orthographic rules, all of whichare linear in nature.
Kataja and Koskenniemi suggested simulating the intersection byhaving the lexical lookup explore both lexica simultaneously.The following computational shortcomings of the intersection approach come tomind.
The intersection of the two lexica works only if Gp and Gr are disjoint.
As thisis not the case in Semitic, one has to introduce ad hoc symbols in the alphabet omake the two alphabets disjoint.
Alternatively, Beesley (forthcoming) introduces aningenious, but cumbersome, bracketing mechanism.
Expression (11) above becomes:A* (k) A* (t) A* (b) A* (13)where A = ~ - { (,) } (I have changed Beesley's curly brackets into angle brackets inorder to avoid confusion with set notation).
Expression (12) then becomes:B* u B* i B* (14)where B = E - V, and V is the disjunction of all vowels.
Finally, each measure is givenby an expression; for instance, Arabic Form V (e.g., /takattab/where th first \[t\] is anaffix not related to the \[t\] of the root) is:tVCVCXVC (15)where C is({ k,t,b }) (16)(i.e., the disjunction of the root symbols surrounded by angle brackets).
The symbolX in expression (15) indicates gemination in a way reminiscent of Kay's G symbol.The intersection of expressions (13), (14), and (15) results in /takatXab/ (X is dealtwith by later rules).
The disjunction of all such intersections results in what one maycall a "quasi lexicon," i.e, the lexical side of subsequent two-level transducers thatdeal with linear phenomena (setting aside long-distance dependencies).
Given r roots(approximately 4,000 in Modern Standard Arabic), v vocalisms, and p patterns (a fewhundred for v x p depending on the linguistic framework used), Beesley's bracketingalgorithm needs to perform m intersections, where r KK m < r x v x p (since each rootonly intersects with lexically defined subsets of the patterns).
In contrast, such a brack-eting mechanism is not necessary in our multitape approach, since the alphabet of onetape does not interfere with the alphabets of other tapes.
Further, our lexicon compilerneeds to perform only n - 1 cross product operations (where n is the number of lex-ical tapes, usually 3).
There is a substantial time complexity difference with practicaleffects.
A faithful implementation of Beesley's bracketing approach and ours was per-formed using the Bell Labs Lextools compiler (Sproat 1995; Kiraz 1997b).
(See Sproat\[1997, Section 3.2\] for a brief description of Lextools.)
The test was also performed byM.
Jansche using a neutral finite-state library (van Noord 1997) to ensure partiality.Jansche was able to substantially enhance the performance of Beesley's method.
Theresults of compiling various numbers of roots with the 24 Arabic verbal patterns ap-pear in Table 3.
The table indicates that for a full-scale system, the proposed multitiercompilation method is far more efficient.
Details of the tests appear in Appendix B.More serious is the fact that bidirectionality of two-level morphology (i.e., mor-phemes mapping to surface forms and vice versa) is lost.
Once intersection is per-formed, the result is an accepting automaton that represents stems rather than inde-pendent morphemes.
In contrast, using our multitape model, the original morphemes94Kiraz Multitiered Nonlinear MorphologyTable 3Evaluation of lexical compilation of Beesley's bracketing mechanism vs.Kiraz's multitiered method using Lextools and van Noord's FSA utilities.The times of the compilation process for the latter are based on anenhanced implementation f Beesley's method by M. Jansche (seeAppendix B).
The ratio columns how the order of complexity (e.g., for100 roots, the multitiered lexical compilation runs 23.7 times faster thanBeesley's bracketing mechanism using Lextools and 4.9 times faster thanJansche's enhancements to Beesley's algorithm).Lextools Van Noord'sRoots Beesley Kiraz Ratio Beesley-Jansche Kiraz Ratio(h min sec) (sec) (sec) (sec)20 4.97s 0.64 7.8 7.4 3.9 1.940 9.85s 0.79 12.5 15.6 6.1 2.660 14.64s 0.81 18.1 25.7 7.4 3.580 19.51s 0.95 20.5 38.1 9.3 4.1100 24.03s 1.13 23.7 52.9 10.8 4.9200 48.52s 1.39 34.9 177.0 22.7 7.8300 lm 10.95s 1.67 42.5 387.7 37.6 10.4400 lm 37.42s 1.87 52.1 677.1 56.3 12.0500 2m 6.94s 2.62 48.4 1124.4 79.2 14.21,000 5m 0.79s 5.64 53.42,000 22m 19.53s 10.20 131.33,000 2h 5m 35.38s 12.60 598.0(root, pattern, and vocalism) can be reconstructed from the multitape lexicon by aprojection operation.
Hence, projection, under which automata re closed, acts as the"reciprocal" operator for cross product in expression (2) ensuring means for bidi-rectionality.
There is no such reciprocal operator for intersection: it is a destructiveoperator in the sense that its arguments cannot be recovered from the result.6.3 Beesley's Other "Intersection" ApproachBeesley and his colleagues (Beesley, Buckwalter, and Newton 1989; Beesley 1990, 1991)developed a large-scale Arabic system under two-level morphology, which even hasthe ability to handle regional Egyptian spelling (Beesley, p. c.).
The lexical lookup ofthe two-level model was augmented by a technique called "detouring" to access rootsand affixes from different lexica (see Sproat \[1992, 163-165\] for details on "detouring").In his 1996 paper, and subsequent work, Beesley reimplemented the system using theXerox lexical and rule compilers (Karttunen 1993; Karttunen and Beesley 1992).
Anon-line demo of the reimplementation was also developed (Beesley 1998a).
4Bidirectionality is maintained in Beesley's ystem by a direct mapping of each rootand pattern pair to their respective surface realizations.
The lexical description givesthe root and pattern superficially concatenated in the form (Beesley 1996, p. c.):\[ktb&CaCaC\] (17)The square brackets are special symbols that delimit the stem, and "&" is another spe-cial symbol that separates the root from the pattern; it is not the intersection operator.4 The new URL is http://www.xrce.xerox.com/research/mltt/arabic.95Computational Linguistics Volume 26, Number 1For each root and pattern pair, a rule of the following form is generated automatically:\[ktb&CaCaC\] ~ katab (18)Each rule of the form in (18) is compiled into a transducer, which is then appliedby composition to the identity transducer of the corresponding lexical description in(17).
The result is a transducer that maps the string "\[ktb&CaCaC\]" into "katab".
Itis worth noting that rules of the form in (18) are reminiscent of Chomsky's earlytransformational ru es for Hebrew stems (Chomsky 1951).
(As "&" in (17) and (18) is a concrete symbol, no real intersection, in the set-theoretic sense, takes place, though Beesley refers to this method as well as to thebracketing mechanism described in the previous ection as "intersection".
)This method requires m (where r << m < r x v x p as before) rules of the formin (18) to be compiled into their respective transducers using algorithms of the Xeroxreplace operator (Karttunen 1997), literally thousands of rules.
Additionally, the entireset of m transducers (or subsets, one subset at a time) needs to be put together intoone (or more) transducer(s) by means of intersection (if the transducers are c-free) orcomposition.
Although this takes place during developing the grammar, rather thanat run-time, the inefficiency that results in the compilation process is apparent fromthe fact that a linguistic phenomenon (here, the linearization of stems) is conveyed byapplying a rule to every single stem of the language.
As one does not provide a ruleto delete \[e\] in Engl ish/move+ing/and another to delete the same in/charge+ing/,etc., but a single \[e\] deletion rule that applies throughout the entire language, stems inSemitic ought to be realized by rules that represent the phenomenon itself, not everysingle instance of the phenomenon.In contrast, he proposed multitier model requires only three rules throughout theentire language to model Beesley's roots and patterns (i.e., with X to denote geminationand hard-coding vocalic spreading): R1 (for stem consonants) and R2 (for stem vowels)from Figure 3, in addition to the following gemination rule (see Section 5.1 for ourhandling of gemination and spreading):Gemination:(x ,C ,~)  - (x , , , c )  - *where C is a consonant.~=~The result of the three rules is a mere (\]R I + 1)-state machine, where R is the set of allroot segments (= 28 for Arabic, 22 for Syriac), which is then applied to the multitieredlexicon.
Figure 10 gives such a machine for R={ k,t,b } and the vowels { a,u,i }.Another disadvantage, although aminor one, of rules of the form in (18) is the lossof alignment between surface segments and their lexical counterparts.
While this doesnot affect the behavior of the resulting machines, having segments aligned helps indebugging at the grammar-design stage.
A cursory look at the transitions in Figure 10indicates to the grammar writer the lexical segments that correspond to a surfacesegment.Having said that, Beesley's ystem remains the largest reported Semitic grammarwritten within finite-state morphology to date.
The system, however, relies on oldlinguistic models, as old as Harris (1941).
No move has been reported to employ mod-ern linguistic models such as the autosegmental framework and other developmentsmentioned in Section 1, although this seems to be the direction of modern researchin computational Semitic morphology as well as linguistics (see the bibliographicalentries cited in Section 1).96Kiraz Multitiered Nonlinear Morphologyi:<v,(t:<c,LO><I  .
.
.
.
.
.
.
.
.
o.o>a:<v,O,a>, u:<v,O,u>, i:<v,O,i>~ k:<c,k,O>~ k:<c,k,O> : , ~,0>/a:<v,O,a> c+ t:<c,t,O>a:<v,O,a>, u;<v,O,u>, i;<v,O,i>,t,O>Figure 10Rules for mapping multitier lexica into stems.
The symbol 0 represents c.c c v c l  i/4 aFigure 11Triangular prism demonstrating the autosegmental representation f Arabic/kattab/.6.4 Encoding Autosegmental Representations ApproachThere have been a number of proposals to encode autosegmental representations.Kornai (1991, 1995) gives a linear coding; Wiebe (1992) and Bird and Ellison (1992)give a multitiered encoding.
We shall illustrate this approach from Bird and Ellison'swork.Every pair of autosegmental tiers constitutes a chart (or plane).
The representationof Arabic/kattab/,  for example, takes the form of a triangular prism as in Figure 11(Pulleyblank 1986).
Each morpheme sits on one of the prism's three longitudinal edges:the pattern on edge 1-2, the vocalism on edge 3-4, and the root on edge 5-6.
The prismhas three longitudinal charts: pattern-vocalism (1-2-3-4), pattern-root (1-2-6-5), androot-vocalism (3-4-5-6).
The corresponding encoding of the diagram is:Tier 1 a:2:0:0Tier 2 C:0:1:0 V:I:0:0 C:0:1:0 C:0:1:0 V:I:0:0 C:0:1:0Tier 3 k:0:l:0 t:0:2:0 b:0:l:0Each expression is an (n + 1)-tuple, where n is the number of charts.
The first elementin the tuple represents he autosegment.
The positions of the remaining elements in thetuple indicate the chart in which an association line occurs, and the numerals indicatethe number of association lines on that chart.
For example, the expression a:2:0:0 statesthat the autosegment "a" has two association lines on the first pattern-vocalism chart,zero lines on the second pattern-root chart, and zero lines on the third root-vocalismchart.97Computational Linguistics Volume 26, Number 1No implementation f a Semitic language, to the best of the author's knowledge,has been carried out using these methods.
Bird and Ellison, however, give an exampleof how they envisage implementing Semitic using their framework.
For each mea-sure, they provide an expression that generalizes over that particular measure, e.g.
for{CVCCVC}:C:1 V:0 C:1 C:1 V:0 C:1 (19)The numbers after the colon refer to the autosegmental ier with which the segmentis linked (0 for vowels and 1 for root segments).
A second expression generalizes overall stems constructed from a particular oot, e.g., for {ktb}:G:0* k:l (G:0* t:l) + b:l (20)where "*" and "+" denote Kleene star and plus, respectively.
A third expression de-scribes the vocalism, e.g., for {a} with spreading:(a U C)* (21)The intersection of the three expressions, per their intersection algorithm for suchencodings, yields:k:l a:0 t:l t:l a:0 b:l (22)Superficially, this approach may seem equivalent to the other intersection ap-proaches mentioned in Section 6.2.
The methodology here, however, is formally moreappealing and linguistically more sound since it provides for a mechanism todescribeautosegmental association.
Bird and Ellison (1992, 87) question if their approach will"cover all possible generalizations about Arabic verbal structure."
It would definitelybe worth investigating how a higher-level autosegmental description of Semitic canbe compiled algorithmically into their machines directly.We mentioned above (Section 6.2) that the intersection approach lacks bidirec-tionality.
It is possible, though this has not been tested, that the indices in Bird andEllison's method can play a role in claiming the various morphemes of a particularsurface form.7.
ImplementationThere are two aspects of the implementation: implementing the theoretical modelbased on the algorithms presented in Section 4 and implementing Semitic grammarsfor the case study.
As for the former, the algorithms in Section 4 were implemented bythe author in SICStus Prolog.
Details of the implementation are given in Appendix A.As for the grammars themselves, a small-scale Syriac grammar was implementedbased on the 100 most frequent roots, including their numerous inflexions, of the Syr-iac New Testament (Kiraz 1994a).
Care was taken, however, to ensure that most of theverbal and nominal classes of the language were exhaustively covered.
Additionally,sample Arabic grammars--but with full coverage of the phenomena under question Ihave been implemented to test various linguistic models of Semitic, including: CVtemplates, moraic templates, affixational templatic morphology, prosodic ircumscrip-tion, and broken plurals.
A detailed description of handling these linguistic modelsappears elsewhere (Kiraz, in press).8.
ConclusionThis paper presented a multitier morphology model that can cope with the nonlinearoperations of Semitic root-and-pattern morphology in a linguistically motivated way.98Kiraz Multitiered Nonlinear MorphologyThe system consists of three main components: a lexicon made of multiple sublex-ica, where each sublexicon represents entries from a particular tier; a rewrite rulessystem that maps multiple lexical representations to a surface representation; and amorphotactic component that makes use of regular rewrite rules.
Rules and lexicaare compiled algorithmically into multitape finite-state machines.
There is no reasonto believe that our multitiered rewrite rules component cannot be applied to otherrewrite rules systems (Koskenniemi 1983; Kaplan and Kay 1994; Mohri and Sproat1996; Karttunen 1997).It was demonstrated that the proposed framework is capable of modeling sophis-ticated linguistic descriptions, especially those of autosegmental phonology.
Havingsaid that, considering that the morphology of Semitic languages i  notoriously dif-ficult to analyze--partly because of its root-and-pattern nature and the existence ofmany morphologically distinct homographic morphemes, but mostly because the or-thographic system is underspecified (see Section 5.4)--the current work, as well as allreported work on Semitic morphology, is far from providing a usable morphologicalsystem.
Much work in the area of morphological disambiguation, which must ventureinto the realms of syntax and semantics, awaits research.The proposed multitape approach may not be confined to Semitic and may proveuseful for autosegmental representation in general.
Since a segment in modern phono-logical theory is a mere shorthand for multitiered features, the model may be appliedto concatenative languages when descriptions are required at the multitiered featurelevel.
While this may be cumbersome for morphological pplications, it may proveuseful for automatic speech recognition and other applications that require subseg-mental analyses.AcknowledgmentsThis research was supported by a St. John's Benefactors' cholarship and was carriedout under the supervision of Dr. Stephen Pulman (University of Cambridge).
Thanksare due to the Master and Fellows of St. John's College and the Computer Labora-tory, Cambridge, for various grants.
Much revision and enhancement took place atBell Laboratories.
Comments by the anonymous reviewers helped in reshaping thepresentation of this paper.
Ken Beesley kindly made a forthcoming paper availableto me and answered many questions.
Martin Jansche performed the test detailed inAppendix B.2 and provided comments.
Christine Nakatani provided many useful ed-itorial comments.Appendix A: ImplementationThe algorithms in Section 4 were implemented by the author in SICStus Prolog us-ing a finite-state library provided by E. Grimley-Evans.
The library allows the cre-ation, manipulation, and destruction of multitape finite-state machines with an easyalgebraic interface to n-way regular expressions.
The Prolog termregexp to fsa(+RegExp,?Automaton) constructs the machine Automaton for the ex-tended regular expression KegExp, e.g., expression 3 (Section 4.2.1) is turned into afour-tape machine with the expressionregexp_to_fsa(t(c,c,c,c)^(\[t(k,c,k,O) .
.
.
.
\ ]^t (c ,c ,c ,c ) ) * ,  Centers)The predicate t (+terminal) denotes a terminal tuple, infix ^  denotes concatena-tion, postfix * denotes Kleene star, and a list denotes union over its elements.
Primi-99Computational Linguistics Volume 26, Number 1tive Prolog procedures (e.g., union/3, kleene/2, etc.)
are also provided for (Kiraz andGrimley-Evans 1998).The algorithms given in Section 4 are closely followed.
First, the lexical compileris invoked creating a multitape machine for each sublexicon, and then putting themtogether with the cross product operator.
The rule compiler then compiles all therules into another machine.
The entire language description is then created with theoperation:Language = (% x Lexicon) N Rules (23)where 7rs denotes the set of all surface symbols.
The first component maps the lexiconto all surface symbols.
The intersection leaves Language with the valid expressionsonly.
(One can also use composition instead of intersection depending on the natureof the rules.
)There is some room to enhance the implementation, especially in time and memoryoverhead.
While the finite state library is capable of handling automata for small-scalegrammars, larger grammars would stretch its capabilities.
The library was successfullyused, however, to implement he algorithms in the current work as well as thosepresented by Grimley-Evans (1997) and Kiraz (1997a).
It must be stressed that thefinite-state calculus library, as well as the rule and lexicon compilers, are prototypeimplementations written for research purposes.
An interpreter version of the workpresented here was described earlier (Kiraz 1996).
The interpreter works on rulesdirectly and can handle larger grammars.Appendix B: Beesley's Bracketing Algorithm vs. Kiraz's Multitape AlgorithmB.1 Using Bell Labs" LextoolsThis test was performed using the Lextools lexical compiler.
Each line in the inputfile is an extended regular expression.
The compiler turns each line into an FSA, thentakes the union of all FSAs.
The file may contain a header, surrounded between twoXXs, for alias definitions.
In Beesley's case, the following source file was used (onlytwo roots andtwo vocalisms are shown):ZZ$(NotRoot) : {Sigma} - ({<}I{>}) ;$(Con) = {<} {Letters} {>} ;$(ktb) = ({<}k{>} {<}t{>} {<}b{>})-$(NotRoot) ;$(qbr) = ({<}q{>} {<}b{>} {<}r{>})~$(SotRoot) ;$(aa) = $(Con)a$(Con)aS(Con) ;$(ui) = $(Con)n$(Con)i$(Con) ;ZZ$(ktb) a $(aa)$(ktb) ~ $(ui)$(qbr) ~ $(aa)$(qbr) a $(ui)// This is A in eq.
13// See eq.
16// Root ktb; see eq.
i3/ /  Root qbr// Pattern CaCaC; eq.
15 with// vowels instantiated// Pattern CuCiC// Intersection for /katab/// Intersection for /kutib/// Intersection for /qabar/// Intersection for /qubir/Each line in the header consists of $ (name), followed by =, followed by an extendedregular expression.
The compiler builds an FSA for the expression and stores it undername.
In regular expressions, curly brackets are used to denote multicharacter symbols(e.g., {Sigma}) or special symbols (e.g., < and > which otherwise are used for weightsin weighted FSAs).
The operators are: - for subtraction, I for union, ~ for insert orignore, a for intersection, and $ (name) for reference to a machine already defined inthe header.The implementation of the Lextools insert operator was modified to provide for afair representation f Beesley's method.
The initial runs took quite some time (many100Kiraz Multitiered Nonlinear Morphologyhours for 100 roots!)
since the insert operator was initially implemented by the ex-pression Range(A o (G U c:B)*) for inserting B into A (Kaplan and Kay 1994).
The newalgorithm inserts B directly into A by iterating over states and adding new statesand arcs.
Additionally, since Beesley's algorithm makes heavy use of alias definitions,access to them was enhanced by applying a binary search mechanism rather thanLextools's original linear search.For Kiraz's method, two source files were used.
The root file is simply a list of allroots, e.g.,ktb  / /qbr  / /and the pattern file is aaa / /ui / /root  k tbroot qbrlisting of all vocalisms, e.g.,vocal ism aavocal ism uiThe two FSAs generated from the two files were fed into a regular expression compilerto compute xpression (2) (Section 4.1).Table 3 (Section 6.2) shows the times spent on compiling up to 3,000 roots withthe 24 patterns described in (Beesley, forthcoming).
The test was performed on a MIPSR5000 180 MHz based Unix system with a memory size of 64 MB.Caveat is required here: To the disadvantage of Kiraz, the two FSAs resultingfrom the root and vocalism files are saved on disk, then loaded again by the regularexpression compiler to compute their cross product adding unnecessary expensiveI /O operations.
Otherwise, the results would be even more in favor of the multitieredmodel.B.2 Using van Noord's FSA Utilities (by Martin Jansche)An independent comparison between the approach described here and the one in(Beesley, forthcoming) was carried out using van Noord's FSA Utilities (van Noord1997) (we use its notation for regular expressions throughout this section).
We com-pared the time spent on compiling lexica of various sizes for both frameworks.
Givena set of roots and a set of patterns, each compiled into a finite automaton as outlinedin Section 4.1, the key difference between the work of Kiraz and that of Beesley is thatthe former uses the cross product operation to compile the full lexicon, while the latteruses intersection.
Since these two operations are very similar, one would not expectmuch of a difference if the elements in each sublexicon were the same.
However, thedifferent formal renderings of roots and patterns in the two approaches results in asignificant difference.Beesley Kirazlexicon by intersection cross productroote.g, ignore(\[<,k,>,<,t,>,<,b,>\], ?-{<,>}) \[k,t,b\]pattern e.g.
\[<,?,>,u,<,?,>,i,<,?,>\] \['C' ,u, 'C' ,?, 'C'\]Using Beesley's approach directly made the task of compiling the root lexiconintractable for more than 10 roots.
After modifications to Beesley's version--such asintersecting the disjunction of roots with the disjunction of patterns once, 5delimiting5 We realize that since roots do not apply to all patterns, but to lexically defined subsets, applyingintersection once does not work in practice.
It was applied here to enhance the performance ofBeesley's algorithm.101Computational Linguistics Volume 26, Number 1root consonants with one special symbol only, and inserting other symbols only be-tween root consonants rather than at arbitrary positions o that a typical root now hasthe shape \[sym*, <, k, sym*, <, t ,  sym*, <, b, sym*\], where syms expands to (?
- <)--itbecame tractable, but was still much slower than the alternative discussed here.Both approaches were implemented asProlog code and macros on top of the FSAUtilities.
The two implementations share common code that contains, among otherthings, a database of roots and patterns in the formpattern(\['C',a,'C',a,'C'\]).pattern(\['C',u,'C',i,'C'\]).%% etc.root (k , t ,b ) .root(p,n,q).%% etc.% Form I,% Form I,Perfect ActivePerfect PassiveThe data represented there are transformed in different ways by the two imple-mentations:%% Kirazroot(\[X,Y,Z\]) :- root(X,Y,Z).%% Beesleyroot(\[sym*,<,X,sym*,<,Y,sym*,<,Z,sym*\]) :- root(X,Y,Z).macro(sym, ?
- <).
~% Beesley's "nonRoot"There is a common macro sublexicon(Pred,N) that calls a metapredicate likef inda l l /3  to find the first N solutions to a call to Pred(W) and collects all the Wsthus obtained into a big disjunction.
The compilation of the lexicon is then very sim-ple:ZZ Kirazmacro(lexicon(R,P),ignore(sublexicon(pattern,P),O) x ignore(sublexicon(root,R),O)).%% Beesleymacro(lexicon(R,P), sublexicon(pattern,P) & sublexicon(root,R)).macro('C', \[<,sym\]).While the pattern database is shared between the two implementations, the mean-ing of ' C' within the patterns is different: for Kiraz, it is just an ordinary symbol,but for Beesley it expands into a marker for a root consonant followed by any othersymbol (the root consonant i self).Table 3 shows the times (in seconds) spent on compiling full lexica with differentnumbers of roots and the 24 patterns described in (Beesley, forthcoming).
Each numberis the minimum obtained after several trials with the "walltime" statistics of SICStusProlog 3.7.1 running on an Intel Pentium 233 MHz based Linux system.102Kiraz Multitiered Nonlinear MorphologyReferencesBat-E1, O.
1989.
Phonology and Word Structurein Modern Hebrew.
Ph.D. thesis, Universityof California at Los Angeles.Bear, J.
1988 Morphology with two-levelrules and negative rule features.
InCOLING-88: Papers Presented to the 12thInternational Conference on ComputationalLinguistics, volume 1, pages 28-31.Beesley, K. 1990.
Finite-state description ofArabic morphology.
In Proceedings oftheSecond Cambridge Conference: BilingualComputing in Arabic and English.Beesley, K. 1991.
Computer analysis ofArabic morphology: A two-levelapproach with detours.
In B. Comrie andM Eid, editors, Perspectives on ArabicLinguistics IIh Papers from the Third AnnualSymposium on Arabic Linguistics.
JohnBenjamins, Amsterdam, pages 155-72.Beesley, K. 1996.
Arabic finite-statemorphological nalysis and generation.
InCOLING-96: Papers Presented to the 16thInternational Conference on ComputationalLinguistics, volume 1, pages 89-94.Beesley, K. 1998a.
Arabic morphologicalanalysis on the Internet.
In Proceedings ofthe 6th International Conference andExhibition on Multi-Lingual Computing,pages 3.1.1-10, Cambridge.Beesley, K. 1998b.
Arabic morphology usingonly finite-state operations.
In M. Rosner,editor, Proceedings ofthe Workshop onComputational Approaches to SemiticLanguages, pages 50-57, Montreal.Beesley, K. 1998c.
Constraining separatedmorphotactic dependencies in finite-stategrammars.
In Proceedings oftheInternational Workshop on Finite StateMethods in Natural Language Processing,pages 118-127, Ankara, Turkey.Beesley, K. Forthcoming.
Arabic stemmorphotactics via finite-state intersection.In E. Benmamoun, editor, Perspectives onArabic Linguistics XIh Papers from theTwelfth Annual Symposium on ArabicLinguistics, pages 85-100.
John Benjamins,Amsterdam.Beesley, K., T. Buckwalter, and S. Newton.1989.
Two-level finite-state analysis ofArabic morphology.
In Proceedings oftheSeminar on Bilingual Computing in Arabicand English.
The Literary and LinguisticComputing Centre, Cambridge.Bird, S. and T. Ellison.
1992.
One-levelphonology: Autosegmentalrepresentations and rules as finite-stateautomata.
Technical Report ResearchPaper EUCCS/RT-51, University ofEdinburgh.Bird, S. and T. Ellison.
1994.
One-levelphonology.
Computational Linguistics,20(1):55-90.Chomsky, N. 1951.
Morphophonemics ofmodern Hebrew.
Master's thesis,University of Pennsylvania.
Published byGarland Press, New York, 1979.Chomsky, N. and M. Halle.
1968.
The SoundPattern of English.
Harper and Row, NewYork.Daciuk, J., S. Mihov, B. Watson, andR.
Watson.
2000.
Incremental constructionof minimal acyclic finite-state automata.Computational Linguistics, 26(1):3-16.Elgot, C. and J. Mezei, 1965.
On relationsdefined by generalized finite automata.IBM Journal of Research and Development,9:47-68.Fischer, P. 1965.
Multi-tape and infinite-stateautomata--A survey.
Communications ofthe ACM, 8:799-805.Goldsmith, J.
1976.
Autosegmental Phonology.Ph.D.
thesis, MIT.
Published asAutosegmental and Metrical Phonology,Oxford, 1990.Grimley-Evans, E. 1997.
Approximatingcontext-free grammars with a finite-statecalculus.
In Proceedings ofthe 35th AnnualMeeting of the Association for ComputationalLinguistics and 8th Conference ofthe EuropeanChapter of the Association for ComputationalLinguistics, pages 452-9, Madrid, Spain.Grimley-Evans, E., G. Kiraz, and S. Pulman.1996.
Compiling a partition-basedtwo-level formalism.
In COLING-96:Papers Presented to the 16th InternationalConference on Computational Linguistics,volume 1, pages 454-59.Hammond, M. 1988.
Templatic transfer inArabic broken plurals.
Natural Languageand Linguistic Theory, 6:247-70.Harris, Z.
1941.
Linguistic structure ofHebrew.
Journal of the American OrientalSociety, 62:143-67.Kaplan, R. and M. Kay.
1994.
Regularmodels of phonological rule systems.Computational Linguistics, 20(3):331-78.Karttunen, L. 1993.
Finite-state l xiconcompiler.
Technical Report, XEROX PaloAlto Research Center, April.Karttunen, L. 1997.
The replace operator.
InE.
Roche and Y. Schabes, editors,Finite-State Language Processing.
MIT Press,chapter 4, pages 117-47.Karttunen, L. and K. Beesley.
1992.Two-level rule compiler.
Technical Report,XEROX Palo Alto Research Center.103Computational Linguistics Volume 26, Number 1Karttunen, L., R. Kaplan, and A Zaenen.1992.
Two-level morphology withcomposition.
In COLING-92: PapersPresented to the 15th \[sic\] InternationalConference on Computational Linguistics,volume 1, pages 141-48, Nantes, France.International Committee onComputational Linguistics.Kataja, L. and K. Koskenniemi.
1988.
Finitestate description of Semitic morphology.In COLING-88: Papers Presented to the 12thInternational Conference on ComputationalLinguistics, volume 1, pages 313-15.Ka~ M. 1987.
Nonconcatenative finite-statemorphology.
In Proceedings ofthe ThirdConference ofthe European Chapter of theAssociation for Computational Linguistics,pages 2-10.Kay, M. and R. Kaplan.
1983.
Wordrecognition.
Unpublished paper.
The coreideas are published in Kaplan and Kay(1994).Kiraz, G. 1994a.
Lexical Tools to the Syriac NewTestament.
JSOT Manuals 7.
SheffieldAcademic Press.Kiraz, G. 1994b.
Multi-tape two-levelmorphology: A case study in Semiticnon-linear morphology.
In COLING-94:Papers Presented to the 15th InternationalConference on Computational Linguistics,volume 1, pages 180-86.Kiraz, G. 1996..SEMH.
E: A generalisedtwo-level system.
In Proceedings ofthe 34thAnnual Meeting, pages 159--66, Associationfor Computational Linguistics.Kiraz, G. 1997a.
Compiling regularformalisms with rule features intofinite-state automata.
In Proceedings ofthe35th Annual Meeting of the Association forComputational Linguistics and 8th Conferenceof the European Chapter of the Association forComputational Linguistics, pages 329-36.Kiraz, G. 1997b.
Lextools 2.0: Tools forfinite-state linguistic analysis.
TechnicalReport 011334-970625-04TM, BellLaboratories.Kiraz, G. 1997c.
Linearization of nonlinearlexical representations.
In J. Coleman,editor, Proceedings ofthe Third Meeting of theACL Special Interest Group in ComputationalPhonology, pages 57-62.Kiraz, G. In press.
Computational NonlinearMorphology: With Emphasis on SemiticLanguages.
Cambridge University Press.Kiraz, G. and E. Grimley-Evans.
1998.Multi-tape automata for speech andlanguage systems: A Prologimplementation.
I  Derick Wood andSheng Yu, editors, AutomataImplementation.
Lecture Notes inComputer Science, Number 1436.Springer Verlag, pages 87-103.Kornai, A.
Formal Phonology.
Ph.D. thesis,Stanford University.
Published in 1995.Kornai, A.
1991.
Formal Phonology.
GarlandPublishing.Koskenniemi, K. 1983.
Two-Level Morphology.Ph.D.
thesis, University of Helsinki.Lavie, A., A. Itai, and U. Ornan.
1990.
Onthe applicability of two level morphologyto the inflection of Hebrew verbs.
InY.
Choueka, editor, Literary and LinguisticComputing 1988: Proceedings ofthe 15thInternational Conference, pages 246-60.McCarthy, J.
1979.
Formal Problems in SemiticPhonology and Morphology.
Ph.D. thesis,MIT, Cambridge, MA.McCarthy, J.
1981.
A prosodic theory ofnonconcatenative morphology.
LinguisticInquiry, 12(3):373-418.McCarthy, J.
1986.
OCP effects: Geminationand antigemination.
Linguistic Inquiry,17:207-63.McCarthy, J.
1993.
Template form inprosodic morphology.
In Stvan, L. et al,editors, Papers from the Third Annual FormalLinguistics Society of Midamerica Conference,pages 187-218.
Indiana UniversityLinguistics Club, Bloomington.McCarthy, J. and A.
Prince.
1990a.
Foot andword in prosodic morphology: TheArabic broken plural.
Natural Languageand Linguistic Theory, 8:209-83.McCarthy, J. and A.
Prince.
1990b.
Prosodicmorphology and templatic morphology.In M. Eid and J. McCarthy, editors,Perspectives on Arabic Linguistics Ih Papersfrom the Second Annual Symposium on ArabicLinguistics.
John Benjamins, Amsterdam,pages 1-54.McCarthy, J. and A.
Prince.
1995.
Prosodicmorphology.
In J. Goldsmith, editor, TheHandbook of Phonological Theory.
Blackwell,chapter 9, pages 318-66.Mohri, M. and R. Sproat.
1996.
An efficientcompiler for weighted rewrite rules.
InProceedings ofthe 34th Annual Meeting,pages 231-8.
Association forComputational Linguistics.Moscati, S., A. Spitaler, E. Ullendorff, andW.
von Soden.
1969.
An Introduction to theComparative Grammar of the SemiticLanguages: Phonology and Morphology.
PortaLinguarum Orientalium.
OttoHarrassowitz, Wiesbaden, Second edition.Pulleyblank, D. 1986.
Tone in LexicalPhonology.
Studies in Natural Languageand Linguistic Theory.
Reidel.Pulman, S. and M. Hepple.
1993.
Afeature-based formalism for two-levelphonology: A description andimplementation.
Computer Speech and104Kiraz Mulfitiered Nonlinear MorphologyLanguage, 7:333-58.Rabin, M. and D. Scott.
1959.
Finiteautomata nd their decision problems.IBM Journal of Research and Development,3:114-25.
Reprinted in E. Moore, editor,Sequential Machines.
Addison-Wesley,Reading, MA.
1964, pages 63-91.Ritchie, G., A.
Black, G. Russell, andS.
Pulman.
1992.
ComputationalMorphology: Practical Mechanisms for theEnglish Lexicon.
MIT Press, Cambridge,MA.Ruessink, H. 1989.
Two level formalisms.Technical Report 5, Utrecht WorkingPapers in NLP.Spencer, A.
1991.
Morphological Theory.
BasilBlackwell.Sprout, R. 1992.
Morphology and Computation.MIT Press, Cambridge, MA.Sprout, R. 1995.
Lextools: Tools forfinite-state linguistic analysis.
TechnicalReport 11522-951108-10TM, BellLaboratories.Sprout, R., editor.
1997.
MultilingualText-to-Speech Synthesis: The Bell LabsApproach.
Kluwer, Boston, MA.van Noord, Gertjan.
1997.
FSA Utilities: Atoolbox to manipulate finite-stateautomata.
In Darrell Raymond, DerickWood, and Sheng Yu, editors, AutomataImplementation, Lecture Notes inComputer Science, Number 1260.Springer Verlag, pages 87-108.Wiebe, B.
1992.
Modelling autosegmentalphonology with multi-tape finite statetransducers.
Master's thesis, Simon FraserUniversity.105
