Proceedings of the TextGraphs-8 Workshop, pages 44?52,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsUnderstanding seed selection in bootstrappingYo Ehara??
Issei Sato??
Graduate School of Information Science and Technology ?
Information Technology CenterThe University of Tokyo / 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan?
JSPS Research FellowKojimachi Business Center Building, 5-3-1 Kojimachi, Chiyoda-ku, Tokyo, Japan{ehara@r., sato@r., oiwa@r., nakagawa@}dl.itc.u-tokyo.ac.jpHidekazu Oiwa??
Hiroshi Nakagawa?AbstractBootstrapping has recently become the focusof much attention in natural language process-ing to reduce labeling cost.
In bootstrapping,unlabeled instances can be harvested from theinitial labeled ?seed?
set.
The selected seed setaffects accuracy, but how to select a good seedset is not yet clear.
Thus, an ?iterative seed-ing?
framework is proposed for bootstrappingto reduce its labeling cost.
Our frameworkiteratively selects the unlabeled instance thathas the best ?goodness of seed?
and labels theunlabeled instance in the seed set.
Our frame-work deepens understanding of this seedingprocess in bootstrapping by deriving the dualproblem.
We propose a method called ex-pected model rotation (EMR) that works wellon not well-separated data which frequentlyoccur as realistic data.
Experimental resultsshow that EMR can select seed sets that pro-vide significantly higher mean reciprocal rankon realistic data than existing naive selectionmethods or random seed sets.1 IntroductionBootstrapping has recently drawn a great deal ofattention in natural language processing (NLP) re-search.
We define bootstrapping as a method forharvesting ?instances?
similar to given ?seeds?
byrecursively harvesting ?instances?
and ?patterns?
byturns over corpora using the distributional hypothe-sis (Harris, 1954).
This definition follows the def-initions of bootstrapping in existing NLP papers(Komachi et al 2008; Talukdar and Pereira, 2010;Kozareva et al 2011).
Bootstrapping can greatlyreduce the cost of labeling instances, which is espe-cially needed for tasks with high labeling costs.The performance of bootstrapping algorithms,however, depends on the selection of seeds.
Al-though various bootstrapping algorithms have beenproposed, randomly chosen seeds are usually usedinstead.
Kozareva and Hovy (2010) recently reportsthat the performance of bootstrapping algorithmsdepends on the selection of seeds, which sheds lighton the importance of selecting a good seed set.
Es-pecially a method to select a seed set consideringthe characteristics of the dataset remains largely un-addressed.
To this end, we propose an ?iterativeseeding?
framework, where the algorithm iterativelyranks the goodness of seeds in response to currenthuman labeling and the characteristics of the dataset.For iterative seeding, we added the following twoproperties to the bootstrapping;?
criteria that support iterative updates of good-ness of seeds for seed candidate unlabeled in-stances.?
iterative update of similarity ?score?
to theseeds.To invent a ?criterion?
that captures the character-istics of a dataset, we need to measure the influenceof the unlabeled instances to the model.
This model,however, is not explicit in usual bootstrapping algo-rithms?
notations.
Thus, we need to reveal the modelparameters of bootstrapping algorithms for explicitmodel notations.To this end, we first reduced bootstrapping al-gorithms to label propagation using Komachi et al44(2008)?s theorization.
Komachi et al(2008) showsthat simple bootstrapping algorithms can be inter-preted as label propagation on graphs (Komachiet al 2008).
This accords with the fact thatmany papers such as (Talukdar and Pereira, 2010;Kozareva et al 2011) suggest that graph-basedsemi-supervised learning, or label propagation, isanother effective method for this harvesting task.Their theorization starts from a simple bootstrap-ping scheme that can model many bootstrapping al-gorithms so far proposed, including the ?Espresso?algorithm (Pantel and Pennacchiotti, 2006), whichwas the most cited among the Association for Com-putational Linguistics (ACL) 2006 papers.After reducing bootstrapping algorithms to labelpropagation, next, we will reveal the model param-eters of a bootstrapping algorithm by taking thedual problem of bootstrapping formalization of (Ko-machi et al 2008).
By revealing the model param-eters, we can obtain an interpretation of selectingseeds which helps us to create criteria for the iter-ative seeding framework.
Namely, we propose ex-pected model rotation (EMR) criterion that workswell on realistic, and not well-separated data.The contributions of this paper are summarized asfollows.?
The iterative seeding framework, where seedsare selected by certain criteria and labeled iter-atively.?
To measure the influence of the unlabeled in-stances to the model, we revealed the modelparameters through the dual problem of boot-strapping.?
The revealed model parameters provides an in-terpretation of selecting seeds focusing on howwell the dataset is separated.?
?EMR?
criterion that works well on not well-separated data which frequently occur as real-istic data.
.2 Related WorkKozareva and Hovy (2010) recently shed light onthe problem of improving the seed set for bootstrap-ping.
They defined several goodness of seeds andproposed a method to predict these measures usingsupport vector regression (SVR) for their doubly an-chored pattern (DAP) system.
However, Kozarevaand Hovy (2010) does not show how effective theseed set selected by the goodness of seeds that theydefined was for the bootstrapping process while theyshow how accurately they could predict the good-ness of seeds.Early work on bootstrapping includes that of(Hearst, 1992) and that of (Yarowsky, 1995).
Abney(2004) extended self-training algorithms includingthat of (Yarowsky, 1995), forming a theory differentfrom that of (Komachi et al 2008).
We chose to ex-tend the theory of (Komachi et al 2008) because itcan actually explain recent graph-based algorithmsincluding that of (Pantel and Pennacchiotti, 2006).The theory of Komachi et al(2008) is also newerand simpler than that of (Abney, 2004).The iterative seeding framework can be regardedas an example of active learning on graph-basedsemi-supervised learning.
Selecting seed sets cor-responds to sampling a data point in active learn-ing.
In active learning on supervised learning, theactive learning survey (Settles, 2012) includes amethod called expected model change, after whichthis paper?s expected model rotation (EMR) isnamed.
They share a basic concept: the datapoint that surprises the classifier the most is selectednext.
Expected model change mentioned by (Settles,2012), however, is for supervised setting, not semi-supervised setting, with which this paper deals.
Italso does not aim to provide intuitive understandingof the dataset.
Note that our method is for semi-supervised learning and we also made the calcula-tion of EMR practical.Another idea relevant to our EMR is an ?an-gle diversity?
method for support vector machines(Brinker, 2003).
Unlike our method, the angle diver-sity method interprets each data point as data ?lines?in a version space.
The weight vector is expressedas a point in a version space.
Then, it samples a data?line?
whose angle formed with existing data linesis large.
Again, our method builds upon differentsettings in that this method is only for supervisedlearning, while ours is for semi-supervised learning.453 Theorization of BootstrappingThis section introduces a theorization of bootstrap-ping by (Komachi et al 2008).3.1 Simple bootstrappingLet D = {(y1,x1), .
.
.
, (yl,xl),xl+1, .
.
.
,xl+u}be a dataset.
The first l data are labeled, and thefollowing u data are unlabeled.
We let n = l + ufor simplicity.
Each xi ?
Rm is an m-dimensionalinput feature vector, and yi ?
C is its correspondinglabel where C is the set of semantic classes.
To han-dle |C| classes, for k ?
C, we call an n-sized 0-1vector yk = (y1k, .
.
.
, ynk)?
a ?seed vector?, whereyik = 1 if the i-th instance is labeled and its label isk, otherwise yik = 0.Note that this multi-class formalization includestypical ranking settings for harvesting tasks as itsspecial case.
For example, if the task is to har-vest animal names from all given instances, suchas ?elephant?
and ?zebra?, C is set to be binary asC = {animal, not animal}.
The ranking is obtainedby the score vector resulting from the seed vectoryanimal ?
ynot animal due to the linearity.By stacking row vectors xi, we denote X =(x1, .
.
.
,xn)?.
Let X be an instance-pattern (fea-ture) matrix where (X)ij stores the value of thejth feature in the ith datum.
Note that we can al-most always assume the matrix X to be sparse forbootstrapping purposes due to the language sparsity.This sparsity enables the fast computation.The simple bootstrapping (Komachi et al 2008)is a simple model of bootstrapping using matrix rep-resentation.
The algorithm starts from f0def= y andrepeats the following steps until f c converges.1.
ac+1 = X?f c. Then, normalize ac+1?2.
f c+1 = Xac+1.
Then, normalize f c+1.The score vector after c iterations of the simplebootstrapping is obtained by the following equation.f =(1m1nXX?
)cy (1)?Simplified Espresso?
is a special version of thesimple bootstrapping where Xij = pmi(i,j)max pmi and wenormalize score vectors uniformly: f c ?
f c/n,ac ?
ac/m.
Here, pmi(i, j)def= log p(i,j)p(i)p(j) .Komachi et al(2008) pointed out that, althoughthe scores f c are normalized during the iterations inthe simple bootstrapping, when c ?
?, f c con-verges to a score vector that does not depend onthe seed vector y as the principal eigenvector of( 1m1nXX?)
becomes dominant.
For bootstrappingpurposes, however, it is appropriate for the resultingscore vector f c to depend on the seed vector y.3.2 Laplacian label propagationTo make f seed dependent, Komachi et al(2008)noted that we should use a power series of a ma-trix rather than a simple power of a matrix.
Asthe following equation incorporates the score vec-tors ((?L)cy) with both low and high c values, itprovides a seed dependent score vector with takinghigher c into account.?
?c=0?c ((?L)cy) = (I + ?L)?1 y (2)Instead of using( 1m1nXX?
), Komachi et al(2008) used L def= I ?
D?1/2XX?D?1/2, a nor-malized graph Laplacian for graph theoretical rea-sons.
D is a diagonal matrix defined as Diidef=?j(XX?
)ij .
This infinite summation of the ma-trix can be expressed by inverting the matrix underthe condition that 0 < ?
< 1?
(L) , where ?
(L) be thespectral radius of L.Komachi et al(2008)?s Laplacian label propaga-tion is simply expressed as (3).
Given y, it outputsthe score vector f to rank unlabeled instances.
Theyreports that the resulting score vector f constantlyachieves better results than those by Espresso (Pan-tel and Pennacchiotti, 2006).f = (I + ?L)?1 y.
(3)4 Proposal: criteria for iterative seedingThis section describes our iterative seeding frame-work.
The entire framework is shown in Algo-rithm 1.Let gi be the goodness of seed for an unlabeledinstance i.
We want to select the instance with thehighest goodness of seed as the next seed added inthe next iteration.i?
= argmaxigi (4)46Algorithm 1 Iterative seeding frameworkRequire: y, X , the set of unlabeled instances U ,the set of classes C.Initialize gk,i?
; ?k ?
C, ?i?
?
UrepeatSelect instance i?
by (4).Label i?.
Let k?
be i?
?s class.U ?
U\{?i}for all i?
?
U doRecalculate gk?,i?end foruntil A sufficient number of seeds are collected.Each seed selection criterion defines each good-ness of seed gi.
To measure the goodness of seeds,we want to measure how an unlabeled instance willaffect the model underlying Eq.
(3).
That is, wewant to choose the unlabeled instance that wouldmost influence the model.
However, as the modelparameters are not explicitly shown in Eq.
(3), wefirst need to reveal them before measuring the influ-ence of the unlabeled instances.4.1 Scores as marginsThis section reveals the model parameters throughthe dual problem of bootstrapping.
We show thatthe score obtained by Eq.
(3) can be regarded asthe ?margin?
between each unlabeled data point andthe hyperplane obtained by ridge regression; specif-ically, we can show that the i-th element of the re-sulting score vector obtained using Eq.
(3) can bewritten as fi = ?
(yi ?
?w?, ?
(xi)?
), where w?
isthe optimal model parameter that we need to reveal(Figure 1).
?
is a feature function mapping xi to afeature space and is set to make this relation hold.Note that, for unlabeled instances, yi = 0 holds, andthus fi is simply fi = ??
?w?, ?
(xi)?.
Therefore,|fi| ?
?
?w?, ?
(xi)?
?
denotes the ?margin?
betweeneach unlabeled data point and the underlying hyper-plane.Let ?
be defined as ?
def= (?
(x1) , .
.
.
, ?
(xn))?.The score vector f can be written using ?
as in (6).If we set ?
as Eq.
(6), Eq.
(5) is equivalent to Eq.
(3).f =(I + ????
)?1y (5)Figure 1: Scores as margins.
The absolute values of thescores of the unlabeled instances are shown as the mar-gin between the unlabeled instances and the underlyinghyperplane in the feature space.???
= L = I ?D?12XXTD?12 (6)By taking the diagonal of ???
in Eq.
(6), it iseasy to see that ??
(xi) ?2 = ??
(xi) , ?
(xi)?
?
1.Thus, the data points mapped into the feature spaceare within a unit circle in the feature space shownas the dashed circles in Figure 1-3.
The weight vec-tor is then represented by the classifying hyperplanethat goes through the origin in the feature space.The classifying hyperplane views all the points posi-tioned left of this hyperplane as the green class, andall the points positioned right of this hyperplane asthe blue gray-stroked class.
Note that all the pointsshown in Figure 1 are unlabeled, and thus the clas-sifying hyperplane does not know the true classes ofthe data points.
Due to the lack of space, the proofis shown in the appendix.4.2 Margin criterionSection 4.1 uncovered the latent weight vector forthe bootstrapping model Eq.
(3).
A weight vectorspecifies a hyperplane that classifies instances intosemantic classes.
Thus, weight vector interpretationeasily leads to an iterative seeding criterion: an unla-beled instance closer to the classifying hyperplane ismore uncertain, and therefore obtains higher good-ness of seed.
We call this criterion the ?margin cri-terion?
(Figure 2).First, we define gk,i?def= |(fk)i?
|/sk as the good-ness of an instance i?
to be labeled as k. sk is thenumber of seeds labeled as class k in the currentseed set.
In the margin criterion, the goodness of theseed i?
is then obtained by the difference between47Figure 2: Margin criterion in binary setting.
The instanceclosest to the underlying hyperplane, the red-and-black-stroked point, is selected.
The part within the large graydotted circle is not well separated.
Margin criterion con-tinues to select seeds from this part only in this example,and fails to sample from the left-bottom blue gray-strokedpoints.
Note that all the points are unlabeled and thus thetrue classes of data points cannot be seen by the underly-ing hyperplane in this figure.the largest and second largest gk,i?
among all classesas follows:gMarginidef= ?(maxkgMargink,i?
?
2ndlargestkgMargink,i?).
(7)The shortcoming of Margin criterion is that it canbe ?stuck?, or jammed, or trapped, when the data arenot well separated and the underlying hyperplanesgoes right through the not well-separated part.
InFigure 2, the part within the large gray dotted cir-cle is not well separated.
Margin criterion continuesto select seeds from this part only in this example,and fails to sample from the left-bottom blue gray-stroked points.4.3 Expected Model RotationTo avoid Margin criterion from being stuck in thepart where the data are not well separated, we pro-pose another more promising criterion: the ?Ex-pected Model Rotation (EMR)?.
EMR measures theexpected rotation of the classifying hyperplane (Fig-ure 3) and selects the data point that rotates the un-Figure 3: EMR criterion in binary setting.
The instancethat would rotate the underlying hyperplane the most isselected.
The amount denoted by the purple brace ?{?
isthe goodness of seeds in the EMR criterion.
This criterionsuccessfully samples from the left bottom blue points.derlying hyperplane ?the most?
is selected.
This se-lection method prevents EMR from being stuck inthe area where the data points are not well sepa-rated.
Another way of viewing EMR is that it selectsthe data point that surprises the current classifier themost.
This makes the data points influential to theclassification selected in early iteration in the itera-tive seeding framework.
A simple rationale of EMRis that important information must be made availableearlier.To obtain the ?expected?
model rotation, in EMR,we define the goodness of seeds for an instance i?,gi?
as the sum of each per-class goodness of seedsgk,i?
weighted by the probability that i?
is labeledas k. Intuitively, gk,i?
measures how the classifyinghyperplane would rotate if the instance i?
were la-beled as k. Then, gk,i?
is weighted by the probabilitythat i?
is labeled as k and summed.
The probabilityfor i?
to be labeled as k can be obtained from thei?-th element of the current normalized score vectorpi?
(k)def= |(fk)i?/sk|?k?C|(fk)i?/sk|, where sk is the numberof seeds labeled as class k in the current seed set.gEMRi?def=?k?Cpi?
(k) gEMRk,i?
(8)The per-class goodness of seeds gk,i?
can be cal-culated as follows:gEMRk,i?def= 1?????w?k||wk||wk,+i?||wk,+i?
||????.
(9)48From Eq.
(17) in the proof, w = ?
?f .
Here, ei?is a unit vector whose i?-th element is 1 and all otherelements are 0.wk = ?
?fk = ??
(I + ?L)?1 yk (10)wk,+i?
= ??fk,+i?
= ??
(I + ?L)?1 (yk + ei?)
(11)Although Eqs.
(10) and (11) use ?, we do notneed to directly calculate ?.
Instead, we can use Eq.
(6) to calculate these weight vectors as follows:w?k wk,+i?
= f?k(I ?D?12XXTD?12)fk,+i?
(12)||w|| =?f?
(I ?D?12XXTD?12)f .
(13)For more efficient computation, we cached(I + ?L) ei?
to boost the calculation in Eqs.
(10)and (11) by exploiting the fact that yk can be writ-ten as the sum of ei for all the instances in class k.5 EvaluationWe evaluated our method for two bootstrappingtasks with high labeling costs.
Due to the natureof bootstrapping, previous papers have commonlyevaluated each method by using running search en-gines.
While this is useful and practical, it also re-duces the reproducibility of the evaluation.
We in-stead used openly available resources for our evalu-ation.First, we want to focus on the separatedness of thedataset.
To this end, we prepared two datasets: oneis ?Freebase 1?, a not well-separated dataset, andanother is ?sb-8-1?, a well-separated dataset.
Wefixed ?
= 0.01 as Zhou et al(2011) reports that?
= 0.01 generally provides good performance onvarious datasets and the performance is not keen to ?except extreme settings such as 0 or 1.
In all exper-iments, each class initially has 1 seed and the seedsare selected and increased iteratively according toeach criterion.
The meaning of each curve is sharedby all experiments and is explained in the caption ofFigure 4.?Freebase 1?
is an experiment for information ex-traction, a common application target of bootstrap-ping methods.
Based on (Talukdar and Pereira,2010), the experiment setting is basically the sameas that of the experiment Section 3.1 in their paper1.1Freebase-1 with Pantel Classes, http://www.talukdar.net/datasets/class_inst/As 39 instances have multiple correct labels, how-ever, we removed these instances from the exper-iment to perform the experiment under multi-classsetting.
Eventually, we had 31, 143 instances with1, 529 features in 23 classes.
The task of ?Freebase1?
is bootstrapping instances of a certain semanticclass.
For example, to harvest the names of stars,given {Vega, Altair} as a seed set, the bootstrap-ping ranks Sirius high among other instances (propernouns) in the dataset.
Following the experiment set-ting of (Talukdar and Pereira, 2010), we used meanreciprocal rank (MRR) throughout our evaluation 2.?sb-8-1?
is manually designed to be well-separated and taken from 20 Newsgroup subsets3.It has 4, 000 instances with 16, 282 features in 8classes.Figure 4 and Figure 5 shows the results.
We caneasily see that ?EMR?
wins in ?Freebase 1?, a notwell-separated dataset, and ?Margin?
wins in ?sb-8-1?, a well-separated dataset.
This result can be re-garded as showing that ?EMR?
successfully avoidsbeing ?stuck?
in the area where the data are notwell separated.
In fact, in Figure 4, ?Random?
wins?Margin?.
This implies that the not well-separatedpart of this dataset causes the classifying hyperplanein ?Margin?
criterion to be stuck and make it loseagainst even simple ?Random?
criterion.In contrast, in the ?sb-8-1?, a well-separated bal-anced dataset, ?Margin?
beats the other remainingtwo.
This implies the following: When the datasetis well separated, uncertainty of a data point is thenext important factor to select a seed set.
As ?Mar-gin?
exactly takes the data point that is the most un-certain to the current hyperplane, ?Margin?
worksquite well in this example.Note that all figures in all the experiments showthe average of 30 random trials and win-and-lose re-lationships mentioned are statistically tested usingMann-Whitney test.While ?sb-8-1?
is a balanced dataset, realistic datalike ?freebase 1?
is not only not-well-separated, butalso imbalanced .
Therefore, we performed ex-periments ?sb-8-1?, an imbalanced well-separateddataset, and ?ol-8-1?, an imbalanced not-well sepa-2MRR is defined as MRR def= 1|Q|?i?Q1ri, where Q isthe test set, i ?
Q denotes an instance in the test set Q, and riis the rank of the correct class among all |C| classes.3http://mlg.ucd.ie/datasets/20ng.html49Figure 4: Freebase 1, a NOT well-separated dataset.
Av-erage of 30 random trials.
?Random?
and ?Margin?
arebaselines.
?Random?
is the case that the seeds are se-lected randomly.
?Margin?
is the case that the seedsare selected using the margin criterion described in ?4.2.?EMR?
is proposed and is the case that the seeds are se-lected using the EMR criterion described in ?4.3.
At therightmost point, all the curves meet because all the in-stances in the seed pool were labeled and used as seedsby this point.
The MRR achieved by this point is shownas the line ?All used?.
If a curve of each method crosses?All used?, this can be intepretted as that iterative seedingof the curve?s criterion can reduce the cost of labeling allthe instances to the crossing point of the x-axis.
?EMR?significantly beats ?Random?
and ?Margin?
where x-axisis 46 and 460 with p-value < 0.01.rated dataset under the same experiment setting usedfor ?sb-8-1?.
?sl-8-1?
have 2, 586 instances with10, 764 features.
?ol-8-1?
have 2, 388 instances with9, 971 features.
Both ?sl-8-1?
and ?ol-8-1?
have 8classes.Results are shown in Figure 6 and Figure 7.
InFigure 6, ?EMR?
beats the other remaining two eventhough this is a well-separated data set.
This im-plies that ?EMR?
can also be robust to the imbal-ancedness as well.
In Figure 7, although the MRRof ?Margin?
eventually is the highest, the MRR of?EMR?
rises far earlier than that of ?Margin?.
Thisresult can be explained as follows: ?Margin?
gets?stuck?
in early iterations as this dataset is not wellseparated though ?Margin?
achieves best once it getsout of being stuck.
In contrast, as ?EMR?
can avoidbeing stuck, it rises early achieving high perfor-mance with small number of seeds, or labeling.
Thisresult suggests that ?EMR?
is pereferable for reduc-Figure 5: sb-8-1.
A dataset manually designed to be wellseparated.
Average of 30 random trials.
Legends are thesame as those in Figure 4.
?Margin?
beats ?Random?
and?EMR?
where x-axis is 500 with p-value < 0.01.Figure 6: sl-8-1.
An imbalanced well separated dataset.Average of 30 random trials.
Legends are the same asthose in Figure 4.
?EMR?
significantly beats ?Random?and ?Margin?
where x-axis is 100 with p-value < 0.01.ing labeling cost while ?Margin?
can sometimes bepreferable for higher performance.6 ConclusionLittle is known about how best to select seed setsin bootstrapping.
We thus introduced the itera-tive seeding framework, which provides criteria forselecting seeds.
To introduce the iterative seed-ing framework, we deepened the understanding ofthe seeding process in bootstrapping through thedual problem by further extending the interpretationof bootstrapping as graph-based semi-supervisedlearning (Komachi et al 2008), which generalizes50Figure 7: ol-8-1.
An imbalanced NOT well separateddataset.
Average of 30 random trials.
Legends are thesame as those in Figure 4.
?EMR?
significantly beats?Random?
and ?Margin?
where x-axis is 100 with p-value < 0.01.
?Margin?
significantly beats ?EMR?
and?Random?
where x-axis is 1, 000 with p-value < 0.01.and improves Espresso-like algorithms.Our method shows that existing simple ?Margin?criterion can be ?stuck?
at the area when the datapoints are not well separated.
Note that many real-istic data are not well separated.
To deal with thisproblem, we proposed ?EMR?
criterion that is notstuck in the area where the data points are not wellseparated.We also contributed to make the calculation of?EMR?
practical.
In particular, we reduced the num-ber of matrix inversions for calculating the goodnessof seeds for ?EMR?.We also showed that the param-eters for bootstrapping also affect the convergencespeed of each matrix inversion and that the typicalparameters used in other work are fairly efficient andpractical.Through experiments, we showed that the pro-posed ?EMR?
significantly beats ?Margin?
and?Random?
baselines where the dataset are not wellseparated.
We also showed that the iterative seed-ing framework with the proposed measures for thegoodness of seeds can reduce labeling cost.Appendix: Proof Consider a simple ridge regres-sion of the following form where 0 < ?
< 1 is apositive constant.minw?2n?i=1?yi ?
?w, ?
(xi)?
?2 + ?w?2 .
(14)We define ?i = yi ?
?w, ?
(xi)?.
By using ?i, wecan rewrite Eq.
(14) into an optimization problemwith equality constraints as follows:minw?2n?i=1?2i + ?w?2 (15)s.t.
?i ?
{1, .
.
.
, n} ; yi = w??
(xi) + ?i.
(16)Because of the equality constraints of Eq.
(16),we obtain the following Lagrange function h. Here,each bootstrapping score fi occurs as Lagrange mul-tipliers: h (w, ?, f) def= 12 ?w?2 + ?2?ni=1 ?2i ?
?ni=1 (?w, ?
(xi)?+ ?i ?
yi) fi.By taking derivatives of h, we can derive w?
byexpressing it with the sum of each fi and ?
(xi).
?h?w = 0?
w?
=n?i=1fi?
(xi) (17)?h?
?i= 0?
fi = ?
(?i = ?yi ?
?w?, ?
(xi)?)
(18)Substituting the relations derived in Eqs.
(17) and(18) to the equation ?h?fi = 0 results in Eq.
(19).
?h?fi= 0?n?j=1fj?
(xi)?
?
(xj)+1?fi = yi (19)Equation (19) can be written as a matrix equationusing ?
defined as ?
def= (?
(x1) , .
.
.
, ?
(xn))?.From Eq.
(20), we can easily derive the form of Eq.
(3) as(???
+ 1?
I)?1y ?
(I + ????
)?1 y.(???
+ 1?I)f = y (20)2ReferencesSteven Abney.
2004.
Understanding the yarowsky algo-rithm.
Computational Linguistics, 30(3):365?395.Klaus Brinker.
2003.
Incorporating diversity in activelearning with support vector machines.
In Proc.
ofICML, pages 59?66, Washington D.C.Zelling S. Harris.
1954.
Distributional structure.
Word.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proc.
of COLING,pages 539?545.Mamoru Komachi, Taku Kudo, Masashi Shimbo, andYuji Matsumoto.
2008.
Graph-based analysis of se-mantic drift in Espresso-like bootstrapping algorithms.In Proc.
of EMNLP, pages 1011?1020, Honolulu,Hawaii.51Zornitsa Kozareva and Eduard Hovy.
2010.
Not all seedsare equal: Measuring the quality of text mining seeds.In Proc.
of NAACL-HLT, pages 618?626, Los Angeles,California.Zornitsa Kozareva, Konstantin Voevodski, and ShanghuaTeng.
2011.
Class label enhancement via related in-stances.
In Proc.
of EMNLP, pages 118?128, Edin-burgh, Scotland, UK.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso:Leveraging generic patterns for automatically harvest-ing semantic relations.
In Proc.
of ACL-COLING,pages 113?120, Sydney, Australia.Burr Settles.
2012.
Active Learning.
Synthesis Lectureson Artificial Intelligence and Machine Learning.
Mor-gan & Claypool Publishers.Partha Pratim Talukdar and Fernando Pereira.
2010.Experiments in graph-based semi-supervised learningmethods for class-instance acquisition.
In Proc.
ofACL, pages 1473?1481, Uppsala, Sweden.David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In Proc.
ofACL, pages 189?196, Cambridge, Massachusetts.Xueyuan Zhou, Mikhail Belkin, and Nathan Srebro.2011.
An iterated graph laplacian approach for rank-ing on manifolds.
In Proc.
of KDD, pages 877?885.52
