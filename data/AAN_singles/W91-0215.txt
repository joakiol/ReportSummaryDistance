A model  for the interact ion of lexical and non- lexicalknowledgein the determinat ion  of word meaningPeter GerstlIBM Germany, Scientific CenterInstitute for Knowledge Based SystemsSchloflstr.
707000 Stuttgart 1e-mail: gersti @ dsOiilog.bitnetAbst ractThe lexicon of a natural anguage understanding system that is not restricted to onesingle application but should be adaptable to a whole range of different asks has toprovide a flexible mechanism for the determination of word meaning.
The reason forsuch a mechanism is the semantic variability of words, i.e.
their potential to denotedifferent hings in different contexts.
The goal of our project is a model that makesthese phenomena explicit.
We approach this goal by defining word meaning as acomplex function resulting from the interaction of processes operating on knowledgeelements.
In the following we characterize the range of phenomena our model isintended to describe and give an outline of the way in which the interpretationprocess may determine the referential potential of words by the integration andevaluation of a variety of factors.1 Introduct ionA system with the capability of natural anguage understanding typically relies on knowl-edge about a restricted domain of application.
For example, as a natural language com-ponent of an information system, it needs to be able to identify the relevant linguisticpatterns.
In case of an information system for flight scheduling words such as "plane","departure", "late", .
.
.wi l l  typically be more relevant han for example: "pahn", "this-tle", "pine" which might be appropriate for a different domain.
In any event, there will bea whole range of words that are commonly used in conversation and, thus, are indepen-dent from the choice of a specific domain.
It is therefore desirable to have a multi-levelarchitecture which can be adapted to different domains without being forced to redesignthe whole system.
A text understanding system based on this kind of architecture wouldprovide the kernel functionality that allows it to couple principles and mechanisms notimmediately dependent on the domain a specific implementation of the system will beused for.
The main problem of such a modular architecture is how and where to drawthe boundary between domain-independent and domain-specific knowledge.
There are atleast two more reasons which motivate a domain-oriented design strategy:With regard to knowledge representation, the history in artificial intelligence researchhas lead from early enthusiastic plans of 'general problem solving capabilities' to morerealistic applications of expert systems.
One reason was the huge amount of data thatwould have to be represented together with a large set of regularities introducing a levelof complexity which could not, be handeled in a realistic manner by the systems currently165available.
Another problem is the inconsistency of data that would necessarily arise oncea lot of different and sometimes conflicting information had to be integrated into a sin-gle knowledge base.
Under this perspective task- and domain-orientation is a matterof rendering the knowledge base manageable and to allow reasoning processes to drawmeaningful inferences on the basis of consistent data.The second argument in favour of a domain-oriented design strategy comes from thearea of lexical semantics.
It is a well known fact that the meaning of a word dependson a multitude of contextual influences.
In a very broad notion of context the task andthe domain of a text understanding system may be considered a part of the context hatlicences an effective restriction of the 'semantic scope' of a single word.
This again ismainly an argument of tractability which in this case helps to minimize the amount oflexical information eeded.
In our example it is a natural design decision to assume thatthe lexicon of a language understanding system as part of an information system aboutflight schedules does not have to account for the 'plant'-reading of "plane".2 The variabi l i ty of wordsThe way in which a word might contribute to the determination f the meaning of linguisticexpressions is indeterminate in different ways.
W. Labov calls the semantic potentialof words enabling them to constitute various links between linguistic expressions andelements of the domain (semantic) variability.
It is this potential which is responsiblefor the already mentioned context dependence of word meaning.
An important goal ofour model is to classify types of variability according to a set of more or less specificproperties.
The questions guiding this classification are: Which kind of representationdoes the variability affect; by which means are the variants related and, how can thereferential potential be restricted in order to single out the intended meaning?
In thelinguistic tradition, these variability phenomena f ll into one of four classes which we willsketch out below.2 .1  Morpho log ica l  ambigu i tyThis class represents cases of identical surface representations of words extracted from adiscourse.
Depending on the kind of representation i  which the natural language inputis encoded (i.e.
orthographic, phonetic, .
.
.
form) cases of homography or homophony maybelong to this class or not.
Homonymy as a specific instance of morphological mbiguityresults from the identity of lexical base forms.
In a lexicon using orthographic representa-tions as is normally the case in dictionaries (singular nouns, infinitive forms of verbs, .
.
.
)there are for example two homonymous entries for "firm" (the adjective and the nounvariant).
In addition, morphological mbiguity captures the more general case of an in-flected form that is identical to a base form or to another inflected form.
An example isthe occurence of "saw" which depending on the context can be understood as noun, asbase form of the verb "saw" or as inflected form derived from the base form "see".It is a notorious problem in lexical semantics \[Kooij 71\] to justify the distinction be-tween coincidental identity of forms (morphologicM ambiguity) and semantic variants ofa single lexical item (chapter 2.2).
In our approach it depends on the purpose of thesystem and, thus, is a design decision comparable to modelling conventions for the do-main knowledge.
Identical basic word forms which are in no relevant and transparent166way related to the representation f knowledge about the domain will be represented bydifferent lexical items.
The question whether two identical forms 'collapse' into a singleentry is then directed by the choice of the domain and the task analogous to the way inwhich drawing a boundary between elements of the domain is motivated.
Defining twoword forms as being homonymous yields the consequence that once the occurence in adiscourse has been morphologically identified and thus mapped onto the correspondinglexical item it is no more possible to skip to a different homonymous variant.
Words whichshall not expose this behaviour should not be modelled as homonymous hut as semanticvariants of a single lexical item.2.2 Po lysemy and po ly funct iona l i tyIn the preceding chapter we outlined the situation where two lexical items realize the sameword form.
The potential of semantic variation encoded in a single lexical item is knownas polysemy.
It remains in effect once the appropriate l xical item has been identifiedby means of morphological processes.
A special case of polysemy is what \[Weber 74\]calls polyfuaclionalily refering to the situation where two variants of a lexical item belongto different syntactic ategories.
Polyfunctionality occurs very frequently since manylexical items allow identical realizations which belong to different syntactic ategoriesbeing related by means of conversion or other morphological processes which do not affectthe word stem.
Examples are the nominal and verbal reading of "point" and the variantsof "clean" which are categorized as adjective, adverb and verb.
The comparison withvariants in a dictionary is not as effective as it was in chapter 2.1 because the entries in adictionary tend to conflate phenomena we call polysemy and cases of variability outlinedin chapter 2.3.2 .3 Metonymy and change o f  semant ic  typeIn the previous chapter we mentioned that a polyfunctional expression can be the analyzedas the realization of different categories in different contexts.
The difference in semanticpotential that arises from this variability sometimes not only involves the transition toa different semantic type in the sense of Montague grammar but it may be paralleledby a more or less extensive shift in conceptual interpretation (cf.
the one-place versustwo-place predicate reading of "drink").
Apart from ambiguities which are reflected bymorphosyntactic properties of a lexical item (eg.
its argument structure) there are in-stances of semantic variation allowing to change the interpretation f a class of linguisticitems in a systematic manner.
The crucial question is if this class should be characterizedby lexical information or on the basis of regularities found in the domain.
Metonymy isa specific instance of this type of variability where the different readings are related byelements of a set of fundamental relationships such as 'part-whole', cause-effect', etc.\[Nunberg 78\] investigates more general mechanisms that licence the use of a word in placeof another in cases where both of them are related by means of a context-specific relation.The phenomena r nge from eases of systematic correspondence such as in the 'newspaper-example '1 to more ideosyncratic ones as the famous 'ham-sandwhich-case '2.
As Nunbergnotes these are not cases of linguistic ambiguity because pointing to the sandwhich would1 The word "newspaper"  eazl be used to refer either to the publ isher  or to the publ icat ion.2A waiter might  apply the expression "the ham sandwhich is s i t t ing at table 20" in order to identi fya un ique guest  who ordered a ham sandwhich.167serve the same purpose as the utterance of the complex phrase.
Nevertheless, it is notclear if the relations are considered as instances of lexical or encyclopaedic knowledge.An example similar to the 'newspaper-case' is the potential of words such as "school","opera", .. .
to select one of the alternative meaning variants 'building', 'process', insti-tution', etc.
The approach outlined in \[Bierwisch 82\] derives this potential from system-atic relationships between concepts representing entities of the domain.
The conceptualknowledge about social instutions has to provide the background information that "theparliament is at the end of the street" is semantically well-formed though "?the govern-ment is at the end of the street" is not.
Since the iexical specifications of "parliament"and "government" cannot account for the fact that it is naturally assumed that the formercan be associated with a specific building whereas a similar assignment is not possible forthe latter.
A comparable argument may be found for the 'substance'-reading of wordsnaming trees.
The iil-formedness of "?this table is made of plane" in contrast o "thistable is made of oak" results from the non-verifiability in the common-sense model ofthe domain.
If an expert would affirm that is quite common to use the wood from palmtrees for the construction of tables we would probably change our model of the domainand licence the acceptability of the first sentence.
This example is different from the'school'/'newspaper'-cases sincein addition to the conceptual shift it involves a modifica-tion of semantic properties of the underlying lexical items.
This in turn is an argumentin favour of a lexicalist position which would classify this type of variability as cases ofpolysemy.
\[Pustejovsky 90\] shows that a lexicalist approach to event structure allows tosystematically characterize a whole range of type-shifting phenomena together with theirconsequences with respect o well-formedness conditions.As a consequence of seeking the portability of domain specific knowledge we followthe lines of Bierwisch in distinguishing lexical and conceptual information.
Yet we donot reject the lexicalist position since we consider semantic type-shifting effects as drivenby regularities of the conceptual structure.
In the following section, we generalize thisposition to a systematic distinction between linguistic and non.lingustic knowledge.
Thisallows us to keep variants introduced by linguistic ambiguities systematically apart fromthose cases we classify as non-linguistic variations.Following \[Binnick 70\] we define polysemous variants of a word as those cases of vari-ability which are (at least in principle) distinguishable onthe basis of linguistic propertiesof the corresonding lexical item.
Polysemous variants of a lexical item thus differ in atleast one morphosyntactie or semantic property.
For non-linguistic variants introduced bymeans of metonymy or type-shifting linguistic properties of a lexical item do not help toidentify the intended reading because the variants have exactly the same linguistic prop-erties.
This situation calls for the disambiguation potential of contextual information iorder to reduce the 'semantic scope '3.2.4 Contextua l  re la t iv i tyVagueness and indexicality also belong to the class of variability phenomena.
They areusually associated with specific groups of linguistic expressions (graduable predicates inease of vagueness and deietie expressions in case of indexieality).
In contrast o theeffects introduced so far, in these eases the class of potential referents cannot simply3We consider the 'semantic scope' of a word as the possible range of interpretation implied by theliteral use of a word.
The more general not ion  of 'referential potential '  additionally accounts for cases ofconceptual shift as in the 'ham-sandwich'  example.168be characterized by an enumeration of alternatives.
As \[Pinkal 80\] points out it is aninherent property of vague predicates to provide a 'grey area' where the decision whetherthe predicate is applicable or not depends on the discourse context.
It is even impossibleto precisely delimit the area of positive or negative applicability.
Following the lines of\[Bosch 83\] we do not consider vagueness as an isolated semantic property of a specific classof words but as an instance of the more general notion of context-dependence 4.
Since thisis an aspect of the referential potential of words our model has to cover theses phenomenaas well.Indexicality is the potential of deictic expressions to select their meaning by exploitingpeculiarities of the discourse situation.
It is similar to vagueness since the implied referen-tial indeterminacy cannot be resolved independently from the specific discourse context.Yet, even deictie expressions are not immune to other types of variability.
For example,the pronoun 'T' may be used to refer to an entity which is somehow related to the speakerin a certain discourse situation.
An example is the utterance of "I am over there" withthe speaker pointing to a desk.
The expression 'T' in this case can be used to refer tothe place, where the speaker usually works.
This is an example of a systematic shift inmeaning motivated by a conceptual relation.
It thus belongs to the phenomena describedin the previous chapter.Another instance of context relativity occurs in cases of privative opposition.
Thisrelativity results from the lack of semantic information for a specific word which couldbe provided by the use of a different word.
According to \[Zwicky/Sadock 75\] "dog" isambiguous between the readings 'male dog' and 'female dog' because it can be forced toprovide both readings in sentences like "that is a dog, but it isn't a dog".
In contrast o"?that is a lion, but it isn't a lion" it seems that a meaningful interpretation can be foundfor the former (the one which forces the selection of different variants for both occurencesof "dog") whereas the latter leads to a contradiction.
The choice of a variant could beforced by the use of "bitch" instead of dog which is not possible for "lion" since thereis not regular lexical specification for something like "lioness".
This illustrates the factthat lack of semantic information for a lexical item can under certain circumstances yieldthe same effect as a disjunction of alternative readings.
This may occur whenever thesemantic 'gap' can be filled by one of a small set of possible alternatives.3 A classification of knowledge typesIn order to have a precise representational basis for our model of word meaning, thischapter is intended to introduce the basic notions used to classify the relevant phenom-ena.
The distinction between linguistic and non-linguistic knowledge mentioned in thepreceding section constitutes the methodical basis of our model.
Up to a certain degree,this distinction allows an independent examination of properties characteristic for onlyone type of knowledge.
By assuming this distinction we do not claim that linguistic andnon-linguistic knowledge are in a way fundamentally different.
We use this distinction as amethodological tool that makes it possible to isolate certain aspects of word meaning notdirectly involving the whole range of both types of knowledge.
In the course of stepwiseextending the complexity of interrelations between linguistic and non-linguistic knowledgewe will have to carefully analyze the tenability of this distinction.4 In general the notion of context dependence applies to referential expressions such as definite nominalphrases.
We will restrict our attention to cases of context-dependence which apply to single words.169We account for possible similarities between both types of knowledge by using thesame formalism for the representation f linguistic and non-linguistic knowledge.
It isa variant of order-sorted predicate logic \[Nebel/Smolka 89\] which combines propertiesof the KL-ONE family of knowledge representation languages with properties of featurebased unification grammars such as HPSG \[Pollard/Sag 87\].
In order to concentrate onthe description of our model we will not go into the details of our formalism here s.The central components of our model are the iezicon on the linguistic side and theontology on the non-linguistic side.
The lexicon and the ontology provide the 'basicbuilding blocks' of linguistic and non-linguistic knowledge respectively.
The elements ofthe lexicon are called categories; the elements of the ontology concepts.
It is important tonote that the lexicon in our model integrates specifications of syntactic ategories (i.e N,V, .
.
.
,  N', .
.
.
,  AP .
.
.
.  )
with lexical items.The formal means for the description of categories and concepts are sorts which arerelated by means of attributes and rules.
Attributes may be used to express characteristicproperties or relationships motivating the choice of a specific distinction between sorts.Rules on the other hand are not considered as tools for the description of inherent andpermanent properties but as representations of regularities which might arise under certaincircumstances.
Apart from that, the collection of attributive characterizations has to beconsistent.
That is not necessarily required for the system of rules as a whole.
Thefundamental organizational principle of subsumption relates categories and concepts arelicencing the inheritance of attributes between sorts.
The subsumption order does onlyapply between elements of one and the same type of knowledge.
The notation used forthe description of sorts is a feature-logic as in \[Shieber 86\] for categories and a simplerelational notation for concepts.
We represent the fact that A subsumes B as A C B.Rules of grammar and rules of inference are represented by using simple predicate logicnotion.
Sorts, attributes and rules will be called knowledge lements.
All of them puttogether constitute the knowledge base of our system.According to our argument in favour of a design strategy specifically tailored to thedomain and the task the system is intended for, the structure of the ontology must becovered by an appropriate theory about entities of the domain, their inherent propertiesand the diverse aspects in which they are related.
We reiterate this methodological claimhere since a similar argument can be applied to the organization of the lexicon.
Thetypical task of a text understanding system is to facilitate the analysis and production oftextual input.
It depends on the capabilities required whether certain aspects of this taskinvolve restrictions on the set of relevant linguistic phenomena 6.
The choice of lexicalitems depends on the domain at issue since the lexical inventory should cover at leastthe range of non-linguistic phenomena represented in the non-linguistic component of thesystem.Categorial knowledge provided by the lexicon together with the rules off grammar con-stitutes the descriptional pparatus for the classification of expressions.
On the one handexpressions serve as input for linguistic processing and on the other hand they representsequential patterns of written or spoken language.
This intermediate status makes them5 Most of our assumptions about the representation f linguistic and non-linguistic knowledge are basedon experiences gained from work in the LILOG-project at IBM Stuttgart.
A description of formalisms andmethods applied in this project can be found in \[Geurts 90\].6 One can for example reduce the computational complexity by limiting the relevant sentence-levelconstructions to simple propositional c auses if the system is not meant to deal with other types ofmodality.
Even if this argument sounds quite trivial the determination f a set of requirements for thelinguistic omponent are as important as they are for the representation f domain knowledge.170elements of discourse knowledge.
Expressions belong to the type of knowledge which servesas a kind of record for the registration of linguistic interactions together with their spatio-temporal specifications.
It directly corresponds to episodic knowledge on the non-linguisticside.
Episodic knowledge has the same intermeditate status as discourse knowledge sinceon the one hand it serves as a record of 'statements' and other 'experiences' with respectto the domain and on the other hand it is used to characterize entities from the domainas individuals on the basis of conceptual knowledge.
Conceptual knowledge combines thestructural information conveyed by the ontology with the additional information expressedby rules of inference.
Individuals which result from the processing of certain linguistic ex-pressions are called referents ince they are open to further reference by linguistic means.The figure below shows the whole classification assumed as the basis of our model./g~era l/Categorial/ \e lements  ruleJ / \Lexical GrammaticalKnowledgeLinguistic\indlvldual \DiscourseNon-linguistic/ $~nera!/Conceptual/ \elemeuts ruleJ / \Ontological Inferential\individu61 \EpisodicExpressions ReferentsFigure 1: The classification of knowledge types.4 Word meaningThe task of our model is an approach to the various aspects of word meaning whichare responsible for the variability effects described in section 2.
In order to reduce thecomplexity of the linguistic domain we restrict the relevant linguistic expressions to thoserepresenting simple word forms which cannot be further decomposed by mophologicalprocesses other than inflection.
As a consequence, the granularity for the representationof linguistic knowledge treats basic morphemes as minimal elements.
Another consequenceis the width of the temporal grid which specifies the minimal 'temporal distance' betweenelements of discourse knowledge.
We introduce temporal indices, allowing to subdividethe linguistic input into a chain of word-level segments.
Each index uniquely identifiesa gap between two words and directly corresponds to a set of intermediate results inthe course of processing the input.
These results are what we call the context.
Formallyspeaking, a context is a set of factors marked by a temporal index specific to a certain stageof processing at which the system is observed.
Factors are functions between knowledgeelements or between instances thereof.
They are elements of specific contexts and thereforediffer from attributes because their existence is strictly tied to a certain stage of processingassociated with a temporal index.
As a result of iterated forwarding a factor may remainapplicable during a sequence of processing steps.
Factors may be classified according171to their origin.
Factors which are directly derived from knowledge lements are calledprimitive factors.
Depending on the type of knowledge lements involved we distinguishtwo modes of origin.
Primitive factors can be ...?
selected as instances of attributes or?
established by the application of rules.Complex factors are derived from primitive ones by one of the following operations:?
the restriction of the domain and/or range of a primitve factor?
the application of set-theoretical operations on primitive factors?
the functional composition of primitive factorsWe present his classification because our analysis of word meaning crucially dependson the notion of contextual factors.
It is the main goal of our project to reconstructword meaning as the result of the interaction of processes with cope with an effectiveintegration of various linguistic and non-linguistic factors primitive and complex in nature.Since we investigate word meaning under the aspect of the potential of words to refer torepresentations of entities of the domain, word meaning in our terminology is a complexfactor which links elements from discourse knowledge (expressions representing words)to elements from episodical knowledge (referents).
The temporary status of factors isresponsible for the fact that for the identification of the referential meaning of a wordthe whole context has to be taken into account.
The linguistic notion of 'word meaning'therefore derives from the analysis of subsets of factors that result from the intersectionof contexts present in a sufficiently large group of different uses of the same word.4.1 The  const i tuents  o f  re fe renceIn order to characterize the interrelation between factors introducing variability effects(productive factors) and those limiting the 'semantic search space' (restrictive factors) weneed to examine the way in which word meaning can be decomposed into a small numberof factors 7.
A segmentation f the interpretation process according to our classification ofknowledge types leads to three components which by application of functional compositionconstitute word meaning.
Since components are derived by functional decomposition fa complex factor (word meaning) they are factors as well.
Components may be furtheranalyzed as the results of set-theoretic operations on basic factors ome of which limit andsome of which extend the 'semantic scope' of a word form s. Factors extending the scopeof interpretation are directly responsible for the variability effects described in section 2.Factors constraining the scope of interpretation are the topic of chapter 4.2.
The followinglist introduces the three components of meaning together with examples of the relevantproductive factors.
An interesting criterion for the classification of productive factors iswhether they are established by the application of rules or selected from attributes be-tween knowledge lements.7We do not  assume contexts  to be finite but  our approach relies on the fact that  a finite subset  ofthe  context  sumces  to descr ibe word mean ing  precisely enough to demonst ra te  the requ i rements  a sys temwith reasonable  d i sambiguat ion  capabi l i t ies has  to fulfil.8 In fact the same funct ion may in one stage of the interpretat io  process erve as product ive factor andin another  as a restr ict ive factor.
Thus ,  the  property  of product iv i ty  or restr ict iv i ty cannot  definit ivelyass igned to specific factors.
More precisely speaking,  it is property  of factors dependent  on the currents tage of process ing represented by the tempora l  index.172(1) CategorizationCategorization as the first component ofthe chain maps expressions representing wordsonto lexical items.
Its relevant productive factor is established by the application of mor-phological rules in some cases involving morphological mbiguity.The following categorization f "saw" is selected from the lexicon because of the identityof phonological forms:PHONSYNcarl4VSEMt sawtMAJOR VTENSE PRESENTSUBCAT ~ .
.
.
~ v .
.
.v  ~ .
.
.TENSE PRESENTSUBCAT ,~conc54A morphological rule establishes the categorization f "saw" as an inflected form de-rived from the lexical base form for "see":carl6PHON f3rdsng(' see')\ [MAJOR V \]SYN TENSE PASTSUBCAT ~ ... ~ v...v ~ ...SEM c0nc75(2) Lexical meaningThe semantic specification of a lexical item and the properties of the correspondingconcept are related by means of the sEi value.
Two basic factors which contribute to therelevant productive factor of lexical meaning originate from attributes in the knowledgebase by means of selection.
The linguistic constituent of lexical meaning may involvepolysemy or polyfunctionality f it provides a range of semantic alternatives and the cor-responding morphosyntactic properties for a single lexical item.
(2a) The l inguistic const i tuent  of lexical meaningThe subcategorization entry of the lexical item selects the following three s polysemousreadings for cat14:?
.
.SUBCAT SYN NP\[NOM\] SEM cone 8 ~"\[ SYN NP\[ACC\] \] \[ SYN NP\[NOM\] \]V < SEM conclo ' SEM cone s >V < ( \ [  SYN PP\[WITH\] 1 ) \ [  SYN NP\[ACC\] \] \[ SYN NP\[NOM\] ~SEM c0nc35 ~ SEM cOnCl3 ~ SEM cone 8The non-linguistic constituent of iexical meaning is responsible for variabilities origi-nating from systematic relationships between different concepts related to a single lexical9As a matter of illustration the subcategorization frame does not exhaust he range of alternativereadings.
It again depends on the task of the linguistic omponent wether the lexlcal item has to providefurther polysemous variants uch as the intransitive reading of "see".173item by means of the semantic specification.
(2b) The non-l inguist ic const i tuent  of  lexical meaningconc75 SITUITIO| E .
.
.time : conc5l ocat ion  : cone3conc23 PERCEPTIO| E SITUATIO|actor  : concstheme : cone13instrument : conc35conc34 REALIZATIO| E SITUATIO|actor : concsproposition : conc19conc39 VISTI|G~ITUATIO|visitorvisited(3) Indlvlduationspatio-temporal propertiesThe filler of the actor role visually perceivesthe filler of the theme roleby using the filler of the instrument roleThe filler of the actor rolerealizes the filler of the proposition roleSITUATIO|conc2 The filler of the visitor roleconc  4 .
.
.This last factor in the chain of meaning components becomes established by the ap-plication of rules of inference.
It maps concepts onto referents.
The productive factor ofindividuation is re ferent ia l i ty  extending the range of possible referents a concept can beindividuated to.
Referentiality here serves as cover term for the phenomena described inchapter 2.4 together with cases of conceptual variation which qualify as 'ad-hoc-anaphora'because they succeed to identify a unique referent in a specific context but cannot be char-acterized as instances of general principles guiding a shift in conceptual interpretation l?.Additional parameters ofthe discourse situation (the time and location of the utteranceas well as a proposition r l )  allow to establ ish an individuation which maps conc34 onto areferent r2 with the following properties:actor(r2) = rspeaker ^proposition(r2) : rl ^location(r2) = r a ^ r3 C Sdiscourse ^time(r2) = r4 A r4 < tdi,?our,eThe three components of word meaning can be considered intermediate steps of theinterpretation process.
They may be analyzed and described in isolation since their in-teraction results from the way in which the range of the preceding component fits to thedomain of the following.
The task of the interpretation process on this background is tofind a 'path' leading from an expression to an individual which under consideration of allthe available contextual factors qualifies as plausible candidate for the referential meaningof the expression.4 .2  How the  semant ic  scope  can  be  res t r i c tedThe crucial question now is how the diverse components interact in order to reduce therange of word meaning by the exclusion of implausible variants.
Here we pick out threel ?Nunberg 's  ham-sandwich is an example instance of this kind of context specific ad-hoc-anaphora.174example groups of factors which in a typical situation may support he reductive factorsof meaning components and such help to reduce the referential potential of a word.
(1) Word-specific factorsThe first group are factors which result from structural relationships expressed bymorphosyntaxtic attributes and rules of grammar.
As we mentioned in chapter 2.3 thesefactors only Mfect variabilities which are introduced by the linguistic part of our knowledgebase.
Factors of this group thus may help to resolve cases of morphological mbiguity, pol-ysemy or polyfunctionality but they have no effect on variants that result from metonymy,change of semantic type or other instances of contextual relativity.Consider the following part of discourse:"I tried to find a possibility to escape.
Then I saw a hole in the fence.
"We'll give a sketch of an analysis of the meaning of "saw" in this example on thebasis of the knowledge lements introduced in the previous ection.
The rules of gram-mar suppress the nominal reading of "saw" since the principles of X-syntax require theconstituent "a hole in the wall" to be 'absorbed'.
Morphological rules do not supportthe disambiguation process.
On the contrary, their productive potential causes the in-troduction of the variant derived from the base form "see".
The variant cat56 is ruledout because of incompatibilities between its subcategorization frame and the syntacticenvironment of "saw" in our example.ca?56PHONSYNVSEMMAJORTENSESUBCATVt sawtvPRESENT\[ SYN NP\[NOMI \]SEM concl8 ~>\[ SYN NP\[ACC\] I \[ SYN NP\[NOM\]SEM conc42 ' SEM cone18TENSE PRESENTSUBCAT ~c0nc75The intransitive polysemous variant fails because of the same reasons as the nominalhomonymous variant.
The transitive reading of cat56 would force an optional preposi-tional argument to be headed by "into "11.
Thus, the polysemous variant conc42 can besingled out purely on the basis of word-specific factors if the rules of grammar do notaccount for the adjunction of a locative PP with the head "in".
In case the grammarlicences the existence of a prepositional djunct, our model of the domain would have tocontribute the restrictive factor that the concept associated with "the fence" does not fitwith conditions on 'sawing'-events.
Since the reductive influence of word-specific factorsends with the selection of polysemous variants we cannot expect a further restriction ofthe 'semantic scope' without additionally considering other types of factors.11 In order to simplify the example this alternative does not occur in the feature structure of cat56.175(2) Se lect iona l  res t r i c t ionsA different group of factors belongs to the semantic level 12 of our model.
Factors inthis group neither are clear instances of linguistic regularities nor of non-linguistic ones.They are partially linguistic and partially non-linguistic in nature and therefore consideredas complex factors derived by the integration of elements from both types of knowledge.They may help to reduce variabilities affecting categorization or lexical meaning.
Yet, likeword-secific factors they do not constrain contextual relativity.Consider the following part of discourse:a piece of wood } "I saw in the bathroom."
a cup of coffeeThe semantic specification for the internal argument of "saw" leads to a concept conc4~representing a class of entities which qualify as fillers of the corresponding role in theconceptual representation f the 'sawing'-event.conc75 BAWl\]l(\] C SITUATIO\]Iactor  : conclsob j  ec t  : conc42instrument : conc29for example: a human beeingfor example: a concrete objectfor example: a set of toolsThe compatibility between the semantic specification of the internal argument of thetwo polysemous readings of "saw" and the type specification of a role belonging to the cor-respondint SEM-value account for the existence of selectional restrictions.
The conceptualrepresentation f '% piece of wood" must be compatible with conc42 in order to establishthe lexical meaning leading to the concept SaWI\]IG.EVE\]IT.
In the case of "this hand-saw sawswell" the external argument would because of requirements on fillers of conceptual roleshave to be mapped on the instruemt role of conc75.
The situation is more tricky if wecompare the instances of the external argument of cat23 in the following example:(1) The policeman saw an accident.
(2) *The ball saw an accident.
(3) The automatic traffic control camera saw an accident.
(4) ?The morning saw an accident.An interesting aspect of this phenomena is that selectional restrictions may be can-celled by contextual factors or by means of rhetoric devices.
The example sentences showhow difficult it might be to identify an obligatory set of selectional restrictions.
Compar-ing (1) with (2) suggests being an instance of the concept PERS0\]I as a reasonable choice.Example (3) however shows that the critical property is something like 'having an opticalsensoring mechanism capable of detecting objects'.
Sentence (4) might imply a metaphor-ical interpretation i spite of its apparent semantic illformedness.
This again yields anargument in favour of a domain-driven design strategy for the semantic level linking be-tween categories and concepts.12 The semantic level is the 'interface' between linguistic and non-linguistic knowledge represented by theSEM values in |exical items together with a set of rules which attune semantic specifications ofargumentstructure to attributes of the corresponding conceptual definitions.176(3) The set of  possible referentsThe last group of factors exemplified here are the only means available to reduce thesemantic scope resulting from contextual relativity.
As we saw in chapter 2.4 contextualrelativity is a fundamental property all referential expressions have in common.
Since the'semantic scope' introduced by variabilities of this type cannot be subdivided into a setof alternative r adings neither lexical nor conceptual information does help to restrict herange of indiviuation.The only way out of this dilemma is to derive a set of possible referents from knowledgeabout the domain and from information occuring in the preceding part of discourse.
Thelatter calls for an investigation of discourse properties on the basis of pragmatic devicessuch as the Gricean conversation principles.
Bridging phenomena 13 as generalizationsof anaphoric binding are promising candidates for an approach to the determination fpossible referents.
C. Sidner emphasizes: "anaphor interpretation can be studied as acomputational process that uses the already existing specification of a noun phrase tofind the specification of an anaphor" \[Sidner 83, p.269\].
The actual limits of a set ofpossible referents thus very much depend on the inferential capabilities of our systemto reconstruct the conceptual relationships undelying text coherence.
The notion of fo-cus presented in the work of Sidner certainly plays a crucial role in the reducion of thecomputational complexity a computation ofall possible bindings would involve if realisticdiscourse situations were to be considered.5 Conc lus ionUp to now we merely picked a collection of phenomena with an impact on the referentialpotential of words ranging from lexical properties to 'genuine' discourse phenomena.
Wepresented a moderately general framework designed in a way that each of these phenomenahas a place to fit in.
The example analysis of "saw" illustrated the interaction of elementsof our model and thereby pointed to problematic aspects that yet have to be resoved.
Acrucial problem is to distinguish between linguistic aspects of lexical meaning which thelexicon has to account for from non-linguistic aspects which derive from relations in con-ceptual structure.
The next step in the evaluation of our model requires the determinationof criteria which help to keep linguistic and non-linguistic aspects of the semantic levelapart.
The ultimate goal of this distinction is to narrow down the flow of information thatpasses through the semantic 'interface' between linguistic and non-linguistic knowledge.
Ifthis strategy succeeds it should be possible to adapt he conceptual knowledge to differentdomains of application ot affecting linguistic knowledge as the basis for capabilities ofdiscourse understanding.References\[Bierwisch 82\] M. Bierwisch, "Semantische und konzeptuelle Repr/isentationlexikalischer Einheiten", R. RfiSi~ka / W. Motsch (eds.
), Unter-suchungen zur Semantik, Studia Grammatica XXII,  Berlin, 1982.13 In the terminology of \[Clark/Haviland 77\].177\[Binnick 70\]\[Bosch 83\]\[Clark/Haviland 77\]\[Geurts 90\]\[Kooij 71\]\[Nebel/Smolka 89\]\[Nunberg 78\]\[Pinkal 80\]\[Pollard/Sag 87\]\[Pustejovsky 90\]\[Shieber 86\]\[Sidner 83\]\[Weber 74\]\[Zwieky/Sadock 75\]R. I. Binnick, "Ambiguity and vagueness", Papers from the SixthRegional Meeting of the Chicago Linguistic Society, Chicago, 1970,pp.
147-153.P.
Bosch, "Vagueness is Context-Dependance: A solution to thesorites paradox", T. T. Bailmer / M. Pinkal (eds.
), ApproachingVagueness, Elsevier Science Publishers B.v. (North-Holland), 1983,pp.
189-210.H.
H. Clark and S. E. Haviland, "Comprehension a d the given-newcontract", R. O. Freedle (ed.
), Discourse Production and Compre-hension, Norwood, New Jersey, 1977.Bart Geurts (ed.
), "Natural Language Understanding in LILOG: AnIntermediate Overview", IWBS Report 187, IBM Germany GmbH,Scientific Center, 1990.J.
G. Kooij.
"Ambiguity in Natural Language.
An investigation ofcertain problems in its linguistic description", Amsterdam, London,1971.B.
Nebel / G. Smolka, "Representation a d Reasoning with Attribu-tive Descriptions", IWBS Report 81, IBM Germany GmbH, ScientificCenter, 1989.G.
D. Nunberg.
"The Pragmatics of Reference", PhD Thesis, Repro-duced by the Indiana University Linguistics Club, 1978.M.
Pinkal, "Semantische Vagheit: Phiinomen und Theorien: Teil I"Linguistische Berichte, 1980.C.
Pollard / E. A.
Sag, "Information-based Syntax and Semantics:Volume r', CSLI Lecture Notes Number 13 Stanford, 1987.J.
Pustejovsky, "Semantic Function and Lexical Decomposition",Schmitz / Schuetz / Kunz (eds.
), Linguistic Approaches to Artifi-cial Intelligence, Lang, 1990, pp.
243-303.S.
M. Shieber.
"An Introduction to Unification-BasedApproaches toGrammar", CLSI Lecture Notes Number 4, Stanford, 1986.C.
L. Sidner.
"Focusing in the comprehension f definite anaphora",M. Brady / Robert C. Berwick, (eds.
), Computational Models of Dis-ourse, Cambridge, Mass.
and London, 1983.H.
J. Weber, "Mehrdeutige Wortformen im heutigen Deutsch: Stu-dien zu ihrer grammatischen Beschreibung und lexikographischenErfassung", Tiibingen, 1974.A.
M. Zwicky and J. M. Sadock, "Ambiguity tests and how to failthem", J. P. Kimball (ed.)
,Syntax and Semantics, pp.
1-36, SanDiego, 1975.178
