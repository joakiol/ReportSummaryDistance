The Incremental Generation of Passive Sentences*Bernd Abb, Michael Herweg, Kai LebethUniversit~it HamburgFB InformatikAB Wissens- und SprachverarbeitungBodenstedtstr.
16D-2000 Hamburg 50Germanyemafl:herweg@rz.informatik.uni-hamburg.dbp.de{ abb, lebeth } @informatik.uni-hamburg.deAbstractThis paper sketches ome basic features of theSYNPHONICS account of the computationalmodelling of incremental language productionwith the example of the generation of passivesentences.
The SYNPHONICS approach aims atlinking psycholinguistic insights into the natureof the human natural language productionprocess with well-established assumptions intheoretical and computational linguisticsconcerning the representation a d processing ofgrammatical knowledge.
We differentiate b tweentwo possible kinds of stimuli within thegeneration process that trigger the formation ofpassive sentences: a Formulator-external stimu-lus and a Formulator-internal one.
TheFormulator-external stimulus is determined bythe conceptual/contextual condition of agentbackgrounding: An agentless semanticrepresentation is verbalized by way ofconstructing an ergativized verbal complex in themorphological structure-building component,rather than by mapping the semanticrepresentation directly onto a passive lemma.The Formulator-internal stimulus is an effect ofthe constraints of rapid, incremental utteranceproduction; inparticular, it causes the Formulat-* The research reported in this paper is carried out in theresearch project "Sprachproduktion: von konzeptuellerStruktur und Kontext zur prosodischen Realisierung derBedeutung" at the University of Hamburg.
The project isfunded by the German Science Foundation (DFG) under grantno.
Ha 1237/4-1.or to integrate a thematically underspecifiedincrement ina prominent s ructural environment.In this case, the formation of passives is a matterof an additional constraint on the LemmaSelection process: Lemma Selection isconstrained by the structural representation f theutterance produced so far.1 Computat ional  Model l ingIncremental Language ProductionofThis paper sketches some basic features of theSYNPHONICS account of the computational modellingof incremental l nguage production with the example ofthe generation ofpassive sentences.
The SYNPHONICS("Syntactic and Phonological Realization of Incremen-tally Generated Conceptual Structures") approach, whichsubscribes to a cognitive science perspective on lan-guage processing, aims at linking psycholinguisticinsights into the nature of the human atural languageproduction process with well-established assumptions intheoretical nd computational linguistics concerning therepresentation a d processing of grammatical knowl-edge.Research in psycholinguistics (e.g., Garrett 1988,Levelt 1989) has revealed that he process of convertinga preverbal, conceptual content into overt speech is per-formed by a number of autonomous sub-processes spe-cialized for different tasks within the overall process: thepre-linguistic conceptualization component ( he Con-ceptualizer, in Levelt's terms) plans a content o beexpressed and delivers a corresponding conceptual repre-sentation to the linguistic formulation component ( heFormulator), which in turn selects the appropriate items(lemmas and lexemes) from the system's lexical database and, guided by the syntactic and phonological spec-ifications of the lexical items, produces abstract syntac-3tic and phonological representations.
The output of theFormulator is taken up by the articulation component(the Articulator), whose task it is to produce aphysicalspeech signal.
These components are considered to beautonomous modules, whose modes of operation areeach governed by theft own sets of principles and restric-tions.
Furthermore, the system as a whole is constrainedby there being a unidirectional flow of information, i.e.,there is no feedback between sub-processes.
1 Finally, itis widely accepted that human language production pro-ceeds in an incremental, piecemeal fashion (Kempen &Hoenkamp 1987): Rather than having to wait for com-plete input structures, components are able to processfragmentary input ("increments").
As soon as a particu-lar component has passed the results on to its successorcomponent, it is ready for processing the next inputincrement.
Thus, a given increment is processed sequen-tially by different components, whereas componentsmay operate in parallel on different increments.Theoretical linguists of various persuasions converge onthe idea that a large amount of grammatical informationthat former theories of grammar handled by extensiverule systems ought o be captured by detailed grammati-cal specifications of lexical items instead.
From thisangle, the grammar of a language merely consists of asmall set of general licensing principles for structm~projected from the lexicon.
The present paper subscribesto this view.
More specifically, the SYNPHONICSFormulator uses a grammar for German in the mold ofHead-driven Phrase Structure Grammar (HPSG; Pollard& Sag 1987, 1992).
The HPSG-style lexical approachto basic aspects of grammar tallies with the central rolethat recent psycholingnistic theories of language produc-tion assign to the lexicon in the formation of linguisticst~ctures (lexicon-&iven generation; e.g., Levelt 1989).In contrast to other approaches to the computationalmodelling of empirically substantiated features ofhuman language production, such as Kempen &Hoenkamp's (1987) Incremental Procedural Grammarand de Smedt's (1990) Incremental Parallel Formulator,however, the SYNPHONICS process model distinguishesstrictly between declarative grammatical knowledge andits procedural application, thus taking the stance oftheoretical linguistics and related computationalapproaches.
As in HPSG, the declarative grammaticalknowledge of the SYNPHONICS Formulator is repre-seated in a unification-based formalism with sorted lea-1 In contrast, AI models that are concerned withincremental processing (e.g., Reithinger 1992) often makeextensive use of feedback at the cost of economy andcognitive adequacy.ture structures.
Unlike deduction-based approaches tonatural language generation i  computational linguistics(e.g., Shieber et al 1990), however, the SYNPHONICSapproach involves a detailed and transparent processmodel, with sub-processes being explicitly specified atany point in the overall process.
This property serves tomake the model adjustable to empirical results about hecourse of human language production and open to a veri-fication of its claims, namely to aim at the computa-tional modelling of cognitive processes.In order to make the above considerations more concrete,we will discuss the roles of the Conceptualizer and theFormulator in the production of a particular linguisticconstruction i some more detail in the remainder ofthis paper.
The discussion of the principles guiding theproduction of passive sentences serves to illustrate towhat extent the determinants of this construction can betraced to the feedback-free interplay between theConceptualizer and the Formulator and the constraintsspecific to the involved modules.
We cannot go into thedetails of the passive here; rather, we will confine thepresentation tosome quite simple cases.
In order to cap-ture the full range of the passive construction acrosslanguages, the account presented here needs to beenlarged in parts.2 The SYNPHONICS ConceptualizerThe conceptual input into the Formulator - in short: CSfor "conceptual structure" - is represented in theRefO/RetN format (Habel 1982, 1986a/b; Eschenbach etal.
1989).
The basic representational units are Referen-tial Objects (ReIDs), which are stored and processed in anet-like structure, aReferential Net (REIN).
RefOs arelabeled, inter alia, with sortal attributes and property andrelation designations.
The notion of RefOs comprisesthe entire range of discourse ntities, such as objects,times, and situations (events, processes, tates).The input representation reflects certain aspects of theorganization of the information which theConceptn_ali~er d livers to the Formulator.
One impor-tant dimension of organization is the relative promi-nence of conceptual units such as particular RefOs.
Inthe incremental process of forming a conceptual repre-sentation of the content to be expressed inan utterance,relative prominence can manifest itself in the timecourse of conceptualization, with more prominent unitstending towards earlier conceptualization than lessprominent ones.
The prominence of a ReID can, forexample, be due to its perceptual saliency (cf.
Floresd'Areais 1987), its conceptual ccessibility (i.e., the easewith which it can be reuieved from memory: cf.
Bock &Warren 1985) or its sortal properties (such as animacy,4humanness, etc.
; eL Bock et al 1992).
We assume thatthe Conceptualizer's output representation is a stream -formally: a list - of RefO/RefN fragments; the positionon the fist indicates the order of conceptualization,which in turn is the order in which these fragments("increments") are made available to the Formulator forsyntactic and phonological encoding.Furthermore, we assume coherence among conceptualincrements.
This means, in technical terms of formalrepresentation, that RefOs are linked by certain means,most notably by what we call embedding information.Embedding information is one instance of a RefO's con-nection with its conceptual environment.
As an exam-ple, embedding information characterizes a RefO's the-matic role in event ypes and other sorts of situations tovarying degrees of specification.3 The SYNPHONICS FormulatorThe SYNPHONICS Formulator, which is a formulationcomponent for German sentence production, consists ofthree sub-components: he semantic encoder, whichtransforms the conceptual input structure CS into anabstract semantic representation SR (cf.
Bierwisch &Schreuder 1992); the syntactic encoder, which, on thebasis of SR, selects lexical items and forms an abstractsyntactic representation; the phonological encoder,which forms an abstract phonological representation.
2Figure 1 (next page) shows the internal structure of theSYNPHONICS Formulator.Syntactic structures are constructed incrementally, usingtwo types of SR information.
At the semantics-syntaxinterface, the so-called Scheme Selector employs the(possibly underspeeified) embedding information associ-ated with RefOs in order to select abstract X-bar-schemata in the form of minimally specified HPSG-likefeature structures, uch as a complementation scheme,which reflects a functor-argument relation, or an adjunc-tion scheme, which reflects amodifier-modified relation.Thereby, the top-down construction of syntactic struc-ture is triggered.
At the semantics-lexicon interface, theso-called Lemma Selector uses the sortal attributes andproperty or relation specifications of RefOs in order toselect the appropriate l xical items, whose syntacticspecifications serve as the starting point for the bottom-up projection of phrasal structures.Both top-down information and bottom-up informationpass through the so-called Functional Inspector, wherethey are checked for the requirements of functional com-pleteness of lexical items with regard to their semanticdemands.
These concern, for example, determiners andcase-marking prepositions as well as passive auxiliaries.If necessary, the Functional Inspector initiates a furtherconsultation of the lexicon.Each newly formed syntactic structure must be licensedby a set of HPSG-style declarative grammatical princi-ples.
In the case of lexical bottom-up information, theprinciples mainly effect phrasal feature projection (HeadFeature Principle, Subcategorization Principle,Semantics Principle).
As regards the top-down struc-tures, the principles erve to enrich the structural infor-mation specified so far (Immediate DominanceSchemata, Subcategorization Principle, etc.
).Next, the so-called Integrator lakes the floor, which con-structs a dynamic syntactic, phonological nd semanticrepresentation u derlying the utterance segment cur-rently being generated.
The construction proceeds incre-mentally and monotonous; the only operation availableto the Integrator is unification of feature structures 3.The procedural execution of integration is guided by anumber of heuristics that reflect he need to meet thedemands of rapid utterance production.
One importantheuristic principle crucial to the present topic is the fol-lowing: "Integrate phonologically filled material as soonas possible into the highest and lefimost position avail-able in the current utterance fragment."
The newlyformed increment representation is again subject o thegrammatical licensing principles.4 Morpho logy  and  Syntax  o f  thePass iveBefore we proceed to the application of our processmodel to the production of passive sentences, we willsketch the basic features of the present SYNPHONICSaccount of the syntax of the passive.The traditional HPSG-account of the passive (Pollard &Sag 1987) consists in a lexical rule that simply restruc-tures the elements on the SUBCAT list of a verb.
Theapplication of the lexical rule to the basic active ntry of2 We will not deal with the semantic and phonologicalencoder in the present paper; cf.
Gfinther et al (1993), Abbet al (1993) and the relevant papers in Herweg (ed., 1992).3 In order to capture nonmonotonic processes (as in thecase of repairs or restarts), the formalism underlying theSYNPHONICS approach must be extended; cf.
de Smedt's(1991) operation of non-destructive unification.Semantic EncoderSemantic RepresentaUonSSP-SCHEMES Scheme SelectorSSP-Schemetop-downinformationDynamicSSP-Structuresbottom-upinformationI~  Fun~onal Inspector 14~1I "IHI Structure Ucenser i'~r'~I Phonolo~lical Encoder?EEENDdedarative component~ '1  procedural componentQ data structureSSP = SemanticJSyntacticJPhonologicalFigl~e 1: The SYNPHONICS Formulator6a verb leads to a revised SUBCAT list in which theformerly highest NP, i.e., the subject, may occupy thelowest oblique position, while the former direct objectNP takes the subject position.
The initial account hassince been modified repeatedly; we simply mention T.Kiss' proposal for German, 4 according to which thepassive rule is split into two parts, a rule of SubjectDemotion and a Subject Condition, which roughly cor-responds to a rule of Object Promotion.Rather than merely stipulating lexical rules such asSubject Demotion and Object Promotion, theSYNPHONICS account traces the effects these rules areintended to capture to properties of the argument s ruc-tures of the passive participle and the passive auxiliary.
5The morphological operation of passive participle for-marion gives rise to what might be regarded as an "erga-rivization" of the verb, i.e., the verb's external argument(in the sense of Williams 1983) is exempt from anysyntactic principle that refers to subcategorized-forarguments.
(Technically, this is realized by transferringthe argument, which is marked by a special externalityfeature, from the verb's SUBCAT list to a blocked-argument \[BLOCKED_ARG\] list.
6) The passive auxil-iary is treated as an argument-attraction verb (cf.Hinrichs & Nakazawa 1991): It subcategorizes for apassive participle and attracts the arguments hat he par-ticiple subcategorizes for as its own subcategorized-forarguments.
Argument attraction is a mechanism thataffects only the argument s ructure of the governed verb,but does not affect the primary link between semanticroles and arguments.
The resulting SUBCAT list of theverbal complex is subject o the relevant grammaticalprinciples, as usual.
In the case of the German passiveauxiliary werden, which we treat as an ergarive raisingverb, the blocked external argument of the participlecannot be attracted.
Rather, the corresponding parameterin the semantics will be existentially bound (if there is4 as yet unpublished work at IBM Germany, Institute forKnowledge-based Systems, Stuttgart5 Note that this approach is intended to capture theformation of the passive in morphologically richlanguages such as German and Dutch, where passivizationis essentially a morphological process.
A differentparametrical variation, such as the development of theauxiliary into a syntactic category in English, may lead to apassive construction that requires an analysis in syntacticterms.6 The term "blocked argument" is borrowed from Haider(1984), who, however, introduced it in a differentframework.no oblique agent phrase).
Figure 2 shows the resultingstructure of the German participle-auxiliary complexgebissen werd- ("oe bitten').LrB~ T ~IP ~ BLOCKED-ARG:\[~\]I PHON:  ",aerd-" 1 l /stmc^T,m,l~ J sv-sc r, .
L.  oo ,Figure 2: Structural Descriotion of a ParticiDle-Auxiliarv ComnlexOn this basis, the effects of Object Promotion followfrom the Subcategorization Principle and a structuralcase theory that replaces the original exical case theoryof Pollard & Sag (1987, 1992; eL Pollard 1991).Technically, arguments in the lexical entry of a verb aremarked by a case-type feature.
The SubcategorizationPrinciple handles the arguments of the verbal complexin the usual way.
The new Case Principle either ealizesthe structural case type by a nominative or accusativevalue (in languages such as German and English), orchecks for the instantiation of the values for the lexicalcase type.
Due to our structural case theory, we reject anisomorphic relation between the order of dements onthe SUBCAT list and the so-called hierarchy of gram-matical functions f'Lxed in the lexicon.
Rather, we def'megrammatical functions, quite GB-like, in structuralterms.
From this angle, the order of elements on theSUBCAT list is nothing but a lexically fixed defaultprominence order of arguments.
If the first argument onthe basic SUBCAT list of a verb has been blocked, i.e.,relegated to the BLOCKED_ARG list, the first subeate-gorized-for argument has to be integrated in the highestaccessible structural position, were it receives nomina-tive case by means of the Case Principle.Figure 3 shows the structural description of the Germanpassive sentence (daft) Peter gebissen wird ('(that) Peteris bitten').
T is the category of the functional elementTense; V/T is a finite verbal projection.V/TPHON: "Peter gebissen wird" 1SUBCAT< >NP \]PHON: "peter"SUBCAT<>TYPE: structuralCASE: LVALUE: nominativeV/TVVPHON: "gebissen werd-"l suBcA' <  BL(X~KED-ARG: IT\]\[~HON: "gebis senUBCAT~/PD wird" II T I PHON: 'present tense' 1 SUBCAT<\[~\] ?
V \[SUBCAT:\[~\]\]>Fimire 3: Structural Description of a Passive SentenceWe note in passing that the theory makes the correctpredictions for German impersonal passives, i.e., pas-sives without nominatively marked NPs, such as Hierwird getanzt \[~ere be (3 sg) danced'\],Den M~mnern wirdgeholfen \['the men (dat pl) be (3 sg) helped ~\] and DerOpfer wird gedacht \['the victims (gen pl) be (3 sg)remembered'\].
Since the passive auxiliary attracts all(non-blocked) argument NPs of the participle, imper-sonal passives are automatically formed if the partici-ple's SUBCAT list is empty (as in the case of getanzt)or contains argument NPs with lexically marked caseonly (as in the case of geholfen and gedacht).
In the lat-ter case, the argument NPs keep their lexically markedmorphological form.
Impersonal passives lack subjectssimply because the least oblique argument NP cannot bestructurally case-marked as nominative.5 The Production of PassivesWe differentiate between two types of stimuli that trig-ger the production of passive sentences.
The fh-St is astimulus external to the linguistic system; the second isa stimulus internal to the linguistic system.
The twotypes exemplify different ways in which the relevantcognitive modules - the Conceptualizer and theFormulator - are synchronized in order to jointly per-form the task of producing an utterance.The first case can be traced to a condition concerning thecontent of the conceptual structure CS that theConceptualizer delivers to the Formulator.
CS mayinclude a situation-type concept (e.g., an event-typeconcept) that is marked for an agentive thematic role,without at the same time including the correspondingagentive RefO.
In terms of its underlying cognitivefunction, this is an extreme case of what has beendescribed as "agent backgrounding" in the typologicalliterature (e.g., Foley & van Valin 1985 and Keenan1985).
There are various motivations for agent back-grounding; the most notable ones are the following:there is a particularly salient or easily inferable agent(e.g., Frank Rijkaard was sent off for knocking downhis opponent); the agent is unknown (e.g., My car hasbeen stolen); the situation-type predicate alone isfocused, with a corresponding defocusing of the agent(e.g., German impersonal passives of the sort Heuteabend wird bier getanzt \['there will be a dance heretonight'; literally: "tonight is here danced"\]).
The pas-sive formation device allows the Formulator to followthe Conceptualizer's decision to dispense with the agentReiD.
Thus, the two modules' principles of informationprocessing tally with each other.More concretely, we assume that the production processinvolves the following crucial steps: The Conceptualizerdelivers a situation type increment whose agent roleremains unspecified (or has as yet not been specified).The Lemma Selector chooses an item that matches thecorresponding semantic representation.
Since this is asituational relation lacking its first argument, he par-ticiple form of the lemma, whose category is adjectival,is selected.
The Functional Inspector completes the cat-egorial requirements of the situation type increment,which actually calls for a verbal category, by initiating acall to the appropriate auxiliary (i.e., werden).
The com-plex form gives rise to a verbal projection whose exter-nal argument appears on the BLOCKED_ARG list andtherefore is not subject to the SubcategorizationPrinciple.
The corresponding parameter is existentiallybound in the semantics.
Thus, the verbal projection sat-isfies the grammatical licensing conditions for construc-tions with non-subcategorized-for external arguments.The second case can be traced to a processing strategythat the Formulator employs when it has to react o theConceptualizer's selection of a particular Reid as themost prominent referential CS constituent, especiallyunder the constraints of rapid utterance production.
Ingeneral, as soon as one process component delivers aninformational increment to its successor component, thelatter strives for further processing the increment with-out delay.
As was claimed above, a certain Reid may bethe first increment that the Conceptualizer passes to theFormulator due to its being the most prominent concep-tual unit in the CS selected for verbalization.
Now, aprominent ReID argument may often be made availableto the Formulator although its embedding information,such as information about its thematic role in an eventtype, is unspecified or at least underdetermined.
In par-ticular, the ReiD may be passed to the Formulator priorto the situation-type concept to which it is an argument.In such cases, the Formulator follows the strategy toassign to the syntactic phrase that verbalizes the Reidthe most prominent available position in the currentutterance segment - i.e., in general, the structural sub-ject position- without waiting for information about heRefO's thematic role.
7 However, if it turns out sub-sequenfly that the phrase, due to information about hethematic role of the corresponding Reid available lateron, doe~ not show the regular argument properties ofsubjects, principles guiding the Lemma Selection pro-cess force the formation of a passive sentence.In this case, the production process involves the follow-ing crucial steps: The ReiD increment is passed fromthe Conceptualizer tothe Formulator prior to the situa-tion type increment.
Following the above mentionedintegration heuristic, the Integrator inserts the phrasecorresponding to the Reid into the most prominent syn-tactic position, where it receives the nominative case bythe structural Case Principle.
No specific informationabout he RefO's thematic role has been used so far.
Atsome stage in the process, however, such informationmust become available to the Formulator.
We assumethat his occurs when the situation type increment entersthe Formulator.
Lemma Selection is restricted not onlyby the corresponding SR, but also by informationlinked to constituents already represented in the tempo-rary utterance fragment constructed so far.
In the presentcase, the Formulator isequipped with additional embed-ding information.
It may turn out that the Reid whoserealizing phrase has already been integrated in the mostprominent position has the standard properties of aninternal argument, for example, because it is the theme7 Abstracting from time factors, the subject position can,in more general terms, be filled without paying attention tothe thematic role the ReID in question holds in a situation.This is essentially suggested by experimental studies usinga picture-description task, where the presentation of thedepiction of an isolated object accompanies thepresentation of the depiction of the entire scene involvingthe object (see, e.g., Turner & Rormnetveit 1968).
Theadditional presentation of the patient object, which raisesits prominence in memory, often sets off the test subjectson the passive voice.
See also the study reported inTannenbanm & Williams (1968), in which drawing thespeaker's attention to either the agent or the patient in asituation by mesns of verbal cues, thereby manipulatingthe speaker's memory access, also affected the choice ofverbal voice.9in an actional event type.
(Technically, the relevantembedding information is available via coindexing ofthe semantics of the already integrated NP and the themeargument of the situation type increment.)
LemmaSelection must take this information into account bychoosing a lemma with a theme as the highest subcate-gorized-for argument (i.e., as the final argument to beprojected by the Subeategorization Pri ciple).
This isexactly the property of the participle form of the lemmaappropriate to the situation type increment in question.From here on, the process of passive sentence formationproceeds as in the ftrst case.6 ConclusionsThis is by far no complete account of the determinantsof the production of passive sentences.
Rather, the aimof the foregoing discussion was to sketch a computa-tional model of natural anguage production that linkspsycholinguistically established aspects of linguisticperformance with a competence model in the form of anHPSG-style declarative grammatical knowledge base.The crucial features of the process model are its incre-mentality and highly constrained modularity.
Each sub-component of the overall process is governed by its ownset of principles, with no feedback between components.We dealt with the relation between the pre-linguisticconceptualizing component and the linguistic formula-tion component in some detail in the present paper.
TheConcep01_~lizer's mode of operation is guided by generalcognitive principles that, for example, select among theingredients of a situation those considered to be apt forlinguistic presentation a d determine the order in whichunits of the content to be expressed are passed on to thelinguistic component, in fact independent in principle ofrequirements specific to the latter.
The Formulator has anumber of language-system internal devices at its com-mand to cope with the material delivered by theConceptualizer.
The discussion of the production of pas-sives served to illustrate how the SYNPHONICS genera-tion system models this situation.ReferencesAbb, B.; Gtinther, C.; Herweg, M.; Lebeth, K.; Maien-born, C.; Schopp, A.
(1993): IncrementalSyntactic and Phonological Encoding - AnOutline of the SYNPHONICS Formulator.Working Paper, University of Hamburg.Bierwisch, M. & Schreuder, R. (1992): From conceptsto lexical items.
Cognition 42:23 - 60.Bock, J. K. & Warren, R. K. (1985): Conceptual cces-sibility and syntactic structure in sentenceformulation.
Cognition 21, 47-67.Book, J. K.; Loebell, H.; Morey, R. (1992): From con-ceptual roles to structural relations: bridg-ing the syntactic left.
PsychologicalReview 99, 150-171.De Smedt, K. & G. Kempen (1991): SegementGrammar:.
a formalism for incrementalsentence generation, in: C. Paris et al(Eds.
), Natural Language Generation inArtificial Intelligence and ComputationalLinguistics.
Dordrecht: Kluwer, 329-349.De Smedt, K. (1990): IPF: an incremental parallel for-mulator, in: R. Dale et al (Eds.
): CurrentResearch in Natural Language Generation.London: Academic Press, S. 167-192.De Smedt, K. (1991): Revisions during generationusing non-destructive unification.
TheThird European Workshop on NaturalLanguage Generation, Juden-stein/Innsbruck, Austria, 13th-15th March1991.
Abstracts of Presented Talks, pp.63-70.Eschenbach, C.; I-Iabel, C.; Herweg, M.; Rehkamper,K.
(1989): Remarks on plural anaphora.Proc.
4th EACL, 161-168.Foley, W. A.
& van Valin, R. D. (1985): Informationpackaging in the clause, in: T.
Shopen(ed.
): Language Typology and SyntacticDescription.
Vol.
1, Clause Structure.Cambridge: Cambridge University Press,pp.
282-364.Flores d'Arcais, G. B.
(1987): Perceptual factors andword order in event descriptions, in: G.Kempen (ed.
), Natural LanguageGeneration.
New Results in ArtificialIntelligence, Psychology, and Linguistics.Dordrecht: Martinus Nijhoff, 441-451.Garrett, M. F. (1988): Processes in language produc-tion.
in: F. J. Newmeyer (Ed.
):Linguistics: The Cambridge Survey.
Vol.III: Language: Psychological andBiological Aspects.
Cambridge:Cambridge Unniversity Press, 69-96.Gtinther, C.; Habel, C.; Maienborn, C.; Schopp, A.
(1993): What's up with the printer?Context relative presentation of concep-tual structure and its prosodic realizationin a language production system.
WoxkingPaper, University of Hamburg.I-Iabel, C. (1982): Referential nets with attributes, in:Proc.
COLING-82, 101-106.Habel, C. (1986a): Prinzipien der Referentialiutt.Springer:.
Berlin.Habel, C. (1986b): Plurals, Cardinalities, and Structuresof Determination.
in: Proc.
COLING-86,62-454.10Haider, H. (1984): Was zu haben ist und was zu sein hat- Bemerkungen zum Infinitiv.
Papiere zurLinguistik 30, 23-36.Herweg, M.
(ed., 1992): Hamburger Arbeitspapiere zurSprachproduktion I. Universit~itHamburg ,  Gradu ier tenko l legKognitionswissenschaft, AP 9.Hinrichs, E. & NakaTawa, T. (1991): Subcategorizationand VP Structure.
Technical Report,Seminar filr Natiirlich-SprachlicheSysteme, Universit/tt Tiibingen.Keenan, E. L. (1985): Passives in the worlds languages.in: T. Shopen (ed.
): Language Typologyand Syntactic Description.
Vol.
1, ClauseStructure.
Cambridge, CambridgeUniversity Press, pp.
243-281.Kempen, G. & E. Hoenkamp (1987): An incrementalprocedural grammar for sentence formula-tion.
Cognitive Science 11,201-258.Levelt, W.J.
(1989): Speaking: From Intention toArticulation.
Cambridge, Mass.
: MITPress.Pollard, C. (1991): Case assignment and a unifiedaccount of passive in German.
Paper pre-sented at the Workshop German Grammarin HPSG, Saarbr~icken, August 8.-9.,1991.Pollard, C. & Sag, I.
(1987): Information-based Syntaxand Semantics.
Vol.
I: Fundamentals.Stanford: Center for the Study ofLanguage and Information.
Lecture NotesNo.
13.Pollard, C. & Sag, I.
(1992): Head-driven PhraseStructure Grammar.
Manuscript, April1992, Stanford: Center for the Study ofLanguage and Information (to appear atChicago University Press).Reithinger, N. (1992): Eine parallele Architektur zurinkrementeUen Generierung multimodalerDialogbeitrage.
StAugustin: infbt.Shieber, S. M.; van Noord, G.; Pereira, F. C. N.;Moore, R. C. (1990): Semantic-head-driven generation.
ComputationalLinguistics 16, 30-42.Tannenbaum, P. H. & Williams, F. (1968): Generationof active and passive sentences a  a func-tion of subject and object focus.
Journalov Berbal Learning and Verbal Behavior 7,246-250.Turner, E. & Rommetveit, R. (1968): Focus of atten-tion in recall of active and passive sen-tences.
Journal of Verbal Learning andVerbal Behavior 7, 543-548.Williams, E. (!983): Argument Structure.
LinguisticInquiry 15, 639-673.11
