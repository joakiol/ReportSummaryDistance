Proceedings of the NAACL HLT 2010: Tutorial Abstracts, pages 9?14,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsInteger Linear Programming in NLP - Constrained Conditional ModelsMing-Wei Chang, Nicholas Rizzolo, Dan RothUniversity of Illinois at Urbana-ChampaignMaking decisions in natural language processing problems often involves assigningvalues to sets of interdependent variables where the expressive dependency structurecan influence, or even dictate, what assignments are possible.
Structured learningproblems such as semantic role labeling provide one such example, but the setting isbroader and includes a range of problems such as name entity and relation recognitionand co-reference resolution.
The setting is also appropriate for cases that may require asolution to make use of multiple (possible pre-designed or pre-learned components) asin summarization, textual entailment and question answering.
In all these cases, it isnatural to formulate the decision problem as a constrained optimization problem, with anobjective function that is composed of learned models, subject to domain or problemspecific constraints.Constrained Conditional Models (aka Integer Linear Programming formulation of NLPproblems) is a learning and inference framework that augments the learning ofconditional (probabilistic or discriminative) models with declarative constraints (written,for example, using a first-order representation) as a way to support decisions in anexpressive output space while maintaining modularity and tractability of training andinference.
In most applications of this framework in NLP, following [Roth & Yih,CoNLL?04], Integer Linear Programming (ILP) was used as the inference framework,although other algorithms can be used for that purpose.This framework, with and without Integer Linear Programming as its inference engine,has recently attracted much attention within the NLP community, with multiple papers inall the recent major conferences, and a related workshop in NAACL?09.
Formulatingproblems as constrained optimization problems over the output of learned models hasseveral advantages.
It allows one to focus on the modeling of problems by providing theopportunity to incorporate problem specific global constraints using a first orderlanguage ?
thus frees the developer from (much of the) low level feature engineering ?and it guarantees exact inference.
It provides also the freedom of decoupling the stageof model generation (learning) from that of the constrained inference stage, oftenresulting in simplifying the learning stage as well as the engineering problem of buildingan NLP system, while improving the quality of the solutions.These advantages and the availability of off-the-shelf solvers have led to a large varietyof natural language processing tasks being formulated within framework, includingsemantic role labeling, syntactic parsing, coreference resolution, summarization,transliteration and joint information extraction.The goal of this tutorial is to introduce the framework of Constrained Conditional Models(CCMs) to the broader ACL community, motivate it as a generic framework for learningand inference in global NLP decision problems, present some of the key theoretical and9practical issues involved in using CCMs and survey some of the existing applications ofit as a way to promote further development of the framework and additionalapplications.
The tutorial will thus be useful for many of the senior and juniorresearchers that have interest in global decision problems in NLP, providing a conciseoverview of recent perspectives and research results.Tutorial OutlineAfter shortly motivating and introducing the general framework, the main part of thetutorial is a methodological presentation of some of the key computational issuesstudied within CCMs that we will present by looking at case studies published in theNLP literature.
In the last part of the tutorial, we will discuss engineering issues thatarise in using CCMs and present some tool that facilitate developing CCM models.1.
Motivation and Task Definition [30 min]We will motivate the framework of Constrained Conditional Models and exemplify itusing the example of Semantic Role Labeling.2.
Examples of Existing Applications [30 min]We will present in details several applications that made use of CCMs ?
includingcoreference resolution, sentence compression and information extraction and use theseto explain several of the key advantages the framework offers.
We will discuss in thiscontext several ways in which constraints can be introduced to an application.3.
Training Paradigms [30 min]The objective function used by CCMs can be decomposed and learned in several ways,ranging from a complete joint training of the model along with the constraints to acomplete decoupling between the learning and the inference stage.
We will present theadvantages and disadvantages offered by different training paradigms and providetheoretical and experimental understanding.
In this part we will also discuss comparisonto other approaches studied in the literature.4.
Inference methods and Constraints [30 min]We will present and discuss several possibilities for modeling inference in CCMs, fromInteger Linear Programming to search techniques.
We will also discuss the use of hardconstraints and soft constraints and present ways for modeling constraints.5.
Introducing background knowledge via CCMs [30 min]We will look at ways in which Constrained Conditional Models (CCMs)can be used toaugment probabilistic models with declarative constraints in order to support decisions10in an expressive output space, and how declarative constraints can be used to aidsupervised and semi-supervised training.6.
Developing CCMs Applications [30 min]We present a modeling language that facilitates developing applications within the CCMframework and present some ?templates?
for possible applications.Tutorial InstructorsMing-Wei ChangComputer Science Department, University of Illinois at Urbana-Champaign, IL, 61801Email: mchang21@uiuc.eduMing-Wei Chang is a Phd candidate in University of Illinois at Urbana-Champaign.He has done work on Machine Learning in Natural Language Processing andInformation Extraction and has published a number of papers in several internationalconferences including "Learning and Inference with Constraints" (AAAI?08), "GuidingSemi-Supervision with Constraint-Driven Learning" (ACL?07) and ?UnsupervisedConstraint Driven Learning For Transliteration Discovery.
(NAACL?09).
He co-presenteda tutorial on CCMs in EACL?09.Nicholas RizzoloComputer Science Department, University of Illinois at Urbana-Champaign, IL, 61801Email: ratinov2@uiuc.eduNicholas Rizollo is a Phd candidate in University of Illinois at Urbana-Champaign.He has done work on Machine Learning in Natural Language Processing and is theprincipal developer of Learning Based Java (LBJ) a modeling language for ConstrainedConditional Models.
He has published a number of papers on these topics, including"Learning and Inference with Constraints" (AAAI?08) and  ?Modeling DiscriminativeGlobal Inference?
(ICSC?07)Dan RothComputer Science Department, University of Illinois at Urbana-Champaign, IL, 61801Phone: +(217) 244-7068; Email: danr@cs.uiuc.edu11Dan Roth is a Professor in the Department of Computer Science at the University ofIllinois at Urbana-Champaign and the Beckman Institute of Advanced Science andTechnology (UIUC) and a Willett Faculty Scholar of the College of Engineering.
He haspublished broadly in machine learning, natural language processing, knowledgerepresentation and reasoning and received several best paper and research awards.
Hehas developed several machine learning based natural language processing systemsincluding an award winning semantic parser, and has presented invited talks in severalinternational conferences, and several tutorials on machine learning for NLP.
Dan Rothhas written the first paper on Constrained Conditional Models along with his studentScott Yih, presented in CoNLL?04, and since then has worked on learning and inferenceissue within this framework as well as on applying it for several NLP problems, includingSemantic Role Labeling, Information Extraction and Transliteration.
He has presentedseveral invited talks that have addresses aspect of this model.BibliographyDan Roth and Wen-tau Yih.
A Linear Programming Formulation for Global Inferencein Natural Language Tasks.
In Proceedings of the Eighth Conference on ComputationalNatural Language Learning (CoNLL-2004), pages 1-8, 2004.Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav Zimak.
Semantic Role LabelingVia Integer Linear Programming Inference.
In Proceedings of the InternationalConference on Computational Linguistics (COLING-2004), pages 1346-1352, 2004.
)Tomacz Marciniak and Michael Strube.
Beyond the Pipeline: Discrete Optimization inNLP.
In Proceedings of the Ninth Conference on Computational Natural LanguageLearning (CoNLL-2005), pages 136-145, 2005.Tzong-Han Tsai, Chia-Wei Wu, Yu-Chun Lin, and Wen-Lian Hsu.
Exploiting FullParsing Information to Label Semantic Roles Using an Ensemble of ME and SVM viaInteger Linear Programming.
In Proceedings of the Ninth Conference on ComputationalNatural Language Learning: Shared Task (CoNLL-2005) Shared Task, pages 233-236,2005.Vasin Punyakanok, Dan Roth and Wen-tau Yih.
The Necessity of Syntactic Parsingfor Semantic Role Labeling.
In Proceedings of the International Joint Conference onArtificial Intelligence (IJCAI-2005), pages 1117-1123, 2005.Vasin Punyakanok, Dan Roth, Wen-tau Yih and Dav Zimak.
Learning and Inferenceover Constrained Output.
In Proceedings of the International Joint Conference onArtificial Intelligence (IJCAI-2005), pages 1124-1129, 2005.12Dan Roth and Wen-tau Yih.
Integer Linear Programming Inference for ConditionalRandom Fields.
In Proceedings of the International Conference on Machine Learning(ICML-2005), pages 737-744, 2005.Regina Barzilay and Mirella Lapata.
Aggregation via Set Partitioning for NaturalLanguage Generation.
In Proceedings of the Human Language Technology Conferenceof the North American Chapter of the Association of Computational Linguistics (HLT-NAACL-2006), pages 359-366, 2006.James Clarke and Mirella Lapata.
Constraint-Based Sentence Compression: AnInteger Programming Approach.
In Proceedings of the COLING/ACL 2006 MainConference Poster Sessions (ACL-2006), pages 144-151, 2006.Sebastian Riedel and James Clarke.
Incremental Integer Linear Programming forNon-projective Dependency Parsing.
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Processing (EMNLP-2006), pages 129-137,2006.Philip Bramsen, Pawan Deshpande, Yoong Keok Lee, and Regina Barzilay.
InducingTemporal Graphs.
In Proceedings of the 2006 Conference on Empirical Methods inNatural Language Processing (EMNLP-2006), 189-198, 2006.Yejin Choi, Eric Breck, and Claire Cardie.
Joint Extraction of Entities and Relations forOpinion Recognition.
In Proceedings of the 2006 Conference on Empirical Methods inNatural Language Processing (EMNLP-2006), 431-439, 2006.Manfred Klenner.
Grammatical Role Labeling with Integer Linear Programming.
InProceedings of the 11th Conference of the European Chapter of the Association forComputational Linguistics, Conference Companion (EACL-2006), pages 187-190, 2006.Pascal Denis and Jason Baldridge.
Joint Determination of Anaphoricity andCoreference Resolution using Integer Programming.
In Proceedings of the AnnualMeeting of the North American Chapter of the Association for Computational Linguistics- Human Language Technology Conference (NAACL-HLT-2007), pages 236-243, 2007.James Clarke and Mirella Lapata.
Modelling Compression with DiscourseConstraints.
In Proceedings of the Conference on Empirical Methods in NaturalLanguage Processing and on Computational Natural Language Learning (EMNLP-CoNLL-2007), pages 1-11, 2007.Manfred Klenner.
Enforcing Consistency on Coreference Sets.
In Recent Advances inNatural Language Processing (RANLP), pages 323-328, 2007Dan Roth and Wen-tau Yih.
Global Inference for Entity and Relation Identification viaa Linear Programming Formulation.
Introduction to Statistical Relational Learning, 2007.13K.
Ganchev, Jo?o Gra?a and B. Taskar.
Expectation Maximization and PosteriorConstraints, Neural Information Processing Systems Conference (NIPS), Vancouver,BC, December 2007.James Clarke and Mirella Lapata.
Global Inference for Sentence Compression: AnInteger Linear Programming Approach.
Journal of Artificial Intelligence Research (JAIR),31, pages 399-429, 2008.Vasin Punyakanok, Dan Roth and Wen-tau Yih.
The Importance of Syntactic Parsingand Inference in Semantic Role Labeling.
Computational Linguistics 34(2), pages257-287, 2008.Jenny Rose Finkel and Christopher D. Manning.
Enforcing Transitivity in CoreferenceResolution.
In Proceedings of the Annual Meeting of the Association for ComputationalLinguistics - Human Language Technology Conference, Short Papers (ACL-HLT-2008),pages 45-48, 2008.K.
Ganchev, Jo?o Gra?a and B. Taskar.
Better Alignments = Better Translations?,Association for Computational Linguistics (ACL), Columbus, Ohio, June 2008.Hal Daum?.
Cross-Task Knowledge-Constrained Self Training In Proceedings of the2008 Conference on Empirical Methods in Natural Language Processing(EMNLP-2008).Dan Goldwasser and Dan Roth.
Transliteration as Constrained Optimization.
InProceedings of the 2008 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP-2008), pages 353-362, 2008.14
