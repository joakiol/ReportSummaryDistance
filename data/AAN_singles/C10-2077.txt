Coling 2010: Poster Volume, pages 674?682,Beijing, August 2010Chinese Frame Identification using T-CRF ModelRu Li*, Haijing Liu+, Shuanghong Li?School of Computer and Information TechnologyShanxi University*liru@sxu.edu.cn+bukaohuaxue@163.com?lishuanghong09@gmail.comAbstractAs one of the important tasks ofSemEval Evaluation, Frame SemanticStructure Extraction based on the Fra-meNet has received much more atten-tion in NLP field.
This task is often di-vided into three sub-tasks: recognizingtarget words which are word expres-sions that evoke semantic frames, as-signing the correct frame to them, name-ly, Frame Identification (FI), and foreach target word, detecting and labelingthe corresponding frame elements prop-erly.
Frame identification is the founda-tion of this task.
Since the existence oflinks between frame semantics and syn-tactic features, we attempt to study FI onthe basis of dependency syntax.
There-fore, we adopt a tree-structured condi-tional random field (T-CRF) model tosolve Chinese frame identification basedon Dependency Parsing.
7 typical lexi-cal units which belong to more than oneframe in Chinese FrameNet were se-lected to be researched.
940 human an-notated sentences serve as the trainingdata, and evaluation on 128 test dataachieved 81.46% precision.
Comparedwith previous works, our result showsobvious improvement.1 IntroductionIn recent years, semantic research has rousedgreat interest in NLP field.
With the progress ofmany semantic lexicons, this research graduallybecomes promising and exciting.
As one of thetasks of SemEval Evaluation, Frame SemanticStructure Extraction based on the FrameNetgrows to be highlighted for special attention.Given a sentence, the task of Frame SemanticStructure Extraction consists of the followingthree parts: recognizing the word expressions(target words) that evoke semantic frames; dis-criminating the word sense (frame) of eachevoking expression; for each target word, label-ing its syntactic dependents with regard towhich roles in that frame they fill (Baker et al,2006).
Among of these three components, frameidentification is the fundamental and key prob-lem.
However, current research of this task inChinese is only focused on semantic role label-ing based on the given target words and theircorresponding frames (Xue, 2008).
We insistthat whether target words can be assigned cor-rect frames in context is a crucial problem de-manding prompt solution in this task.Chinese FrameNet (CFN) (You and Liu,2005), developed by Shanxi University, is anongoing effort of building a semantic lexiconfor Chinese based on the theory of Frame Se-mantics (Fillmore, 1982), referencing the Fra-meNet(Baker et al, 1998) and supported bycorpus evidence.
The CFN project currentlycontains more than 2100 lexical units, morethan 300 semantic frames, and has exemplifiedmore than 21600 annotated sentences.
The ulti-mate goal of this project is to generate informa-tion about the articulation of the semantic andsyntactic requirements of Chinese lexical itemsand presents this information in a variety ofweb-based reports and represents the lexicalsemantics of all the sentences in a Chinese text.674According to statistics, there are 332 lexicalunits belonging to more than one frame in thecurrent CFN databases.
For example, lexicalunit ???
?can evoke the following threeframes: ???
(Expressing_publicly) ?, ???
(Statement) ?
and ???
(representative) ?.
Inorder to extract the semantic structure of a sen-tence containing ambiguous target words, thefirst step is to assign the correct frame to thetarget words in a given context.This task is similar with the word sense dis-ambiguation (WSD) task to a certain extent(Katrin Erk, 2005).
WSD is to resolve the inher-ent polysemia of words by determining the ap-propriate sense for each ambiguous word in agiven text, while frame identification is assign-ing a correct frame for the ambiguous targetword in the current sentence context.
Neverthe-less, essential difference exists between them.WSD prefers to disambiguation on static sense,whereas based on the frame semantics, frameidentification lays particular emphasis on con-sistency between sentence scene and the dy-namic scene described by the candidate frames.Since the existence of links between framesemantics and syntactic features, we adopt atree-structured conditional random field (T-CRF)model to solve Chinese frame identificationbased on Dependency Parsing.
7 typical lexicalunits which belong to more than one frame inCFN were selected to be researched.
940 humanannotated sentences were collected for the train-ing data, and 128 for test data.The rest of this paper is organized as follows.Section 2 introduces some related work.
Section3 gives a simple system description.
Section 4describes Chinese frame identification using T-CRF model.
Section 5 presents our experimen-tal results and some analysis.
Section 6 is theconclusions.2 Related WorkWith the development and improvement ofFrameNet, the research based on this lexicalresource is increasing gradually.
FrameSemantic Structure Extraction based onFrameNet is such hot topics.
One sub-tasks ofthis research is frame identification, which is theresearch problem in this paper.At present, there are some but not much workon frame identification.
Main works are as fol-lows: CL Research participated in the SemEval-2007 task for Frame Semantic Structure Extrac-tion.
They integrated the use of FrameNet in theText Parser component of the CL ResearchKMS.
In particular, they created a FrameNetdictionary from the FrameNet databases withthe CL Research DIMAP dictionary softwareand used this dictionary as a lexical resource.The current FrameNet DIMAP dictionary con-tains 7575 entries, with many entries havingmultiple senses.
For each sense, the FrameNetpart of speech, the definition, the frame name,the ID number, and the definition source (identi-fied as FN or COD) are captured from the Fra-meNet files.
When a lexical unit is recognizedin processing the text, the first step is to retrievethe entry for that item in the dictionary and usethe frame element realization patterns to disam-biguate among the senses.
A score is computedfor each sense and the score with the highestsense was selected.
They evaluated on threetexts and the best result is 66.10% precision(Litkowski, 2007).Adrian Bejan and Hathaway (2007) selectedfrom the FN lexicon 556 target words thatevoke at least two semantic frames and have atleast five sentences annotated for each frame.And then they assembled a multi-class classifierusing two types of models: SVM and MaximumEntropy for each ambiguous target word.
Theyextracted features used in word sense disam-biguation (Florain et al, 2002), lexical featuresof the target word, and NAMED ENTITYFLAGS associated with the root vertex in a syn-tactic parse tree.
For the rest of the ambiguoustarget words that have less than five sentencesannotated, they randomly chose a frame as be-ing the correct frame in a given context.
For FIsub-task, they obtained 76.71% accuracy com-pared to a baseline of 60.72% accuracy that al-ways predicts the most annotated frame for eachof the 556 target words.Johansson and Nugues (2007) firstly usedsome filtering rules to detect target words, andfor the target words left after the filtering, theytrained a disambiguating SVM classifier on allambiguous words listed in FrameNet.
The clas-sifier used the following features: target lemma,target word, sub categorization frame, the set ofdependencies of the target, the set of words ofthe child vertexes, and the parent word of thetarget.
Its accuracy was 84% on the ambiguous675words, compared to a first-sense baseline scoreof 74%.The above researches focused on Englishbased on FrameNet.
To our knowledge, thereexists no work for Chinese by far.
Most meth-ods mentioned above treat the frame identifica-tion as an independent classification problemfor each ambiguous target word in a sentence.However, because of neglecting the relationsbetween the candidate frames, the resultingframe assignment may be semantically inconsis-tent over the sentence.3 System DescriptionOur system consists of three stages.
The firstis corpus construction of our experiments.
Weselected 7 typical lexical units from the currentCFN lexicon which can evoke at least two se-mantic frames.
They are ?
???,???,???,???,???,????,???
?, re-spectively.
For each of them, we collected sen-tences containing this word from Sogou Corpusand CCL Contemporary Chinese Corpus of Bei-jing University.
Through a series of refining,940 sentences annotated correct frame for eachtarget word comprise a standard corpus as thetraining data.
Another 128 sentences serve asthe test data.The second stage is dependency parsing.
Weused LTP of Information Retrieval ResearchCenter, Harbin Institute of Technology (HIT-CIR) to POS tagging and dependency parsingthe training and test sentences.
For the obviouslexical and syntax errors in the outputs, manu-ally corrected was conducted.At last, Chinese frame identification task isregarded as a labeling task on the dependencytree structure.
By using T-CRF, we can modelthis as the maximization of the probability ofword sense (frame) trees, given the scores forvertexes and edges.
In the training phase, ap-propriate features of vertex and edge are ex-tracted, and the weight vectors are optimizedover the training data.Figure 1 gives an illustration of the system.Figure 1.
Framework of the system4 Chinese Frame IdentificationGiven a sentence, frame identification is todetermine an appropriate frame for each oftarget words by comparing consistency betweensentence context and the dynamic scenedescribed by their candidate frames.
Currently,most researchers addressed this task as anindependent classification problem for eachtarget word in a sentence.
Consequently, theresulting frame assignment for each target wordmay be semantically inconsistent over thesentence.We regard Chinese frame identification prob-lem as a labeling task on the dependency treestructure due to the links between syntactic fea-tures and frame semantics.
Our empirical studyshows that the frame of target word not onlyinfluenced by the adjacent words in position butalso its governor and dependents words in syn-tactic structure.
Therefore, we try to solve thisproblem based on dependency parsing.
T-CRFmodel is a special CRF model, which is differ-ent from widely used linear-chain CRFs, inwhich the random variables are organized in atree structure.
As we can see, it should be feasi-ble and reasonable to adopt a T-CRF model toframe identification after parsing the sentence.In this section, we firstly introduce the linear-chain CRFs briefly, and then explain the T-CRFmodel for Chinese frame identification, espe-cially the feature selection and parameter esti-mation.4.1 Tree-Structured Conditional RandomField?T-CRF?Conditional Random Fields (CRFs) are undi-rected graphical models (Lafferty et al 2001).For the observation sequence1 2 3 nX x x x x= " and its corresponding labelsequence 1 2 3 nY y y y y= "  , CRF defines theconditional probability as:676{}1( | )1exp( ( , , ))( )exp( ( , ))k k i ii kk k ii kP Y Xf y y XZ Xg y X???=+?
??
?where X  is the observation sequence, andiy is the label at position i  in label sequence Y .
( )kf ?
and ( )kg ?
are feature functions.k?
and k?
are the weight vectors.
( )Z X  is thenormalization factor.
CRFs are state-of-the-artmethods for sequence labeling problem in manyNLP tasks.Tree-Structured Conditional Random Field(Tang et al, 2006) is a particular case of CRFs,which can model dependencies across hierar-chically laid-out information, such as depend-ency syntactic relations between words in a sen-tence.The graphical structure of T-CRF is a tree, inwhich three main relations exist for a vertex:parent-child, child-parent and sibling vertexes.In our experiments, we only used parent-childedges and child-parent edges.
The sibling-vertexes edges were ignored because of weakdependency syntactic relation between words ina sentence.
So the probability distribution in ourT-CRF model can be written as below.
{ }' ''' ''( | )1exp( )( , ( ), )( , ( ), , , ( ))( , ( ), , , ( ))v Vj jjk kkl llp y xF G SZ xF f v y v xG g v y v x v y vS s v y v x v y v???
?= + +===???
?where F ?
G ?
S  represent the featurefunctions of current vertex, feature functions ofparent vertex of current vertex and feature func-tions of child vertexes of current vertex, respec-tively.
v  is a word corresponding to the vertexin the tree, 'v is the parent vertex of v and ''v arethe child vertexes of v .In Chinese frame identification, the observa-tion x in T-CRF corresponds to a word in thecurrent sentence.
The label y thus correspondsto the frame name for the word.
In the experi-mental corpus, for the target word, y is anno-tated its correct frame name, while for the otherwords left, y is annotated tag ?null?.
These tar-get words are the 7 lexical units we selected andtheir frames come from the current CFN lexicon.At present, only the frame identification of tar-get word was studied, the disambiguation of theother multi-senses words in the sentence wasnot being processed.Although T-CRFs are relatively new models,they have already been applied to several NLPtasks, such as semantic role labeling, semanticannotation, word sense disambiguation, imagemodeling.
(Cohn and Blunsom, 2005; Tang et al,2006; Jun et al, 2009; Awasthi et al, 2007).
Allthese works proved this model to be useful inmodeling the semantic structure in a sentence ora text.
Our study is the first application of T-CRFs to frame identification.4.2 Feature SelectionIn order to apply T-CRF model, it is neces-sary to represent the sentence with a hierarchi-cal structure.
We used LTP of HIT-CIR to POStagging and dependency parsing the training andtest sentences.
To facilitate the description offeature selection based on the dependency treestructure, figure 2 gives the dependency outputof an example.
?SBVADV       ADV        VOB?
VV??
?
??
?ADVADV  VOB  VOB????
??
?
?VOB      MT??
?Figure 2.
Example of a dependency parsed sen-tence.This example sentence is:??????????????????????.
In English,it reads ?He has been want to make films, andfinally has the opportunity to realize his dream677today?.
In the dependency tree structure, arrowpoints from the parent vertex to child vertex, thelabel on a arc is the type of dependency relationbetween the parent and the child vertex.Feature selection is a core problem in se-quence labeling model.
In our experiments, 18template settings were conducted to discover thebest features for frame identification.
Duringthis process, we considered two main factors:firstly, the number of features should not be toolarge so as to avoid the over-fitting phenomenon;secondly, the selected features should be able toprovide enough information conditioned on tol-erated computation, for the purpose of improv-ing the performance of system.
With the in-creasing of the number of features and the costof the system, if the performance of system cannot be improved obviously, we stopped to addfeatures and regard the parameter of currenttemplate as the best.
At this moment, a goodbalance between the performance and cost ofcomputation was achieved.We experimented with two different types offeature settings.
One we used was the very basicfeature sets based on the words and Part ofSpeech (POS) and their bigram features.
In or-der to see the effectiveness of dependency fea-tures, the other type of feature settings includemore informative tree features.
These featurescapture information about a vertex?s parent, itschildren and the relation with its parent andchildren.
These features are semantically andstructurally very informative and we expect toimprove our performance with them.
The baseand tree features we used are listed in table 1.In these features, the setting of basic featuresis fundamental and meaningful because it canbe used to compare T-CRF and linear chainCRF.
For the tree features, given the i -th vertexin the observation ix , ( , )p cf y y and( , )c pf y y represent whether the current vertexhas a parent-child dependency with a parentvertex and whether it has a parent-child depend-ency with a child vertex, respectively.
In de-pendency grammars (Igor' A. Melchuk, 1988),every vertex has only one parent as its governor,and may have more than one child as its de-pendents.
Words in a sentence through certainsyntactic relations form the semantic structureof this sentence.
Therefore, we argue that theTable 1.
Base Features & Tree Featureswords that have syntactic dependency rela-tions with the target word are more impor-tant than the ones neighboring with it in posi-tion for frame identification.
For this reason, weadded the parent vertex and children vertexesinto the tree features.
With respective to the re-lation type, we used the annotation sets definedby HIT-CIR in LTP, which contain 24 kinds ofdependency relation types.
One thing should beconcerned is that we don?t consider all types ofchildren vertexes.
This is because that accordingto our empirical study, not all of the childrenhave strong dependencies with the target word.On the contrary, more features would bringthe noise and affect the efficiency seriously.Hence, we chose 4 types of children relationfrom the linguistic point of view.
They are,?SBV(subject-verb)?
representing ??????,?VOB(verb-object)?
representing ??????,?ADV(adverbial)?
representing ?????
?and ?ATT(attribute) ?
representing ?????
?.From the point of grammars and semantics,these four relations are more influenced on thewords in a sentence.
As we know, the subject,predicate and object constitute the semantic coreof a sentence.
The good news is that experimen-tal results proved this hypothesis relatively cor-rect.Category FeaturesBasefeaturesWord and bigram of word,POS and bigram of POSParent vertex of currentwordThe edge between cur-rent word and its par-ent( , )p cf y yThe dependency rela-tion type between cur-rent word and its par-entchild vertex of currentwordThe edge between cur-rent word and its childTreefeatures( , )c pf y yThe dependency rela-tion type between  cur-rent word and its child6784.3 Parameter EstimationThe parameter estimation is to optimize the pa-rameters { }1, 2,...; 1, 2,...?
?
?
?
?= from train-ing data { }( 1, 1), ( 2, 2),...D x y x y with empiricaldistribution ( ),p x y .
Nowadays, the commonlyused method for parameter estimation is maxi-mum likelihood function.
That isargmax log( ( / ))i iiL p y x?
?= ?
given theobservation sequences { }1 2, ,...x x and label se-quences{ }1 2, ,...y y .In this paper, the conventional L-BFGS me-thod was used to estimate the optimal parame-ters { }1, 2,...; 1, 2,...?
?
?
?
?= (Jorge Nocedaland Stephen J. Wright.
1999).5 Experiments5.1 Data preparationSo far, there has no research on Chinese frameidentification, thus it is unfeasible to do experi-ments based on readily available corpus.
Ac-cordingly, preparing a good and reasonabletraining and test data is our fundamental task.At present, there are 332 lexical units that canevoke at least two frames in the CFN lexicon.
Inthis paper, we selected 7 typical ambiguous lex-ical units to be researched.
They are ????,???,???,???,???,????,????.
Theselection principle is following: first of all, it istime-consuming to construct corpus for all ofthe 332 lexical units, so currently we just stud-ied part of them to prove the validity of themethod we proposed.
Secondly, the framesevoked by these lexical units should be distin-guished clearly by human annotators.
For ex-ample, lexical unit ????
can evoke these threeframes: ?????
(Experiencer_obj)?, ?????
(Experiencer_subj)?
and ?
?
?
?
?(Emotion_directed)?.
All these frames describea tender feeling in psychology, so it is difficultto discriminate among them and thus hard toannotate sentences correctly.
Thirdly, these 7lexical units are high frequency words so it iseasier to collect sentences and make the ex-periments more practical.For each of 7 lexical units, we collected sen-tences containing this word from Sogou Corpusand Contemporary Chinese Corpus of BeijingUniversity.
After a preliminary screening, about1000 sentences compose the original and coarsecorpus.Although these sentences were complete andrelatively standard, some of them didn?t meetthe criterion of Chinese frame identificationresearch.
Such cases mainly include three as-pects.
For one thing, the correct frame of am-biguous target word is difficult to decide byhuman annotator.
For the other, the meaning oftarget word can?t correspond to any frame defi-nition in current CFN version.
For example,lexical unit ???
can express the meaning ofopinion and wish which have the correspondingframes in CFN, while the meaning of thinkingand memory did not.
Lastly, some wordscouldn?t evoke frames though their word formsare the same as lexical unit.
We removed thesentences belonging to the above situations andgot a refined corpus containing 940 sentencesfor training data and 128 for test data.
And then,we used LTP to POS tagging and dependencyparsing the training and test sentences.5.2 Experimental Results and AnalysisFor the linear-chain CRF, we defined the fea-tures based on the words, POS of words andtheir bigram features as the base features.
For T-CRF, we used the base features and tree features.Six different types of template settings on thesefeatures are listed in table 2.template featuresT1 Base featuresT2 Add edge  between current word and its parent on T1T3 Add dependency type between current word and its parent  on T2T4Add edge between current wordand its four types children ver-texes  on T1T5Add dependency type betweencurrent word and its four typeschildren vertexes on T4T6 Add all these tree features  on T1Table 2.
Template settings on different featuresFor each of these template settings, we ex-perimented on different observation windowsize of 1, 2 and 3, which represents one word,679two words and three words previous and next tothe current word respectively.We use thenprecisions= to evaluate our sys-tem, where n is the number of target words la-beled correctly, and s is the total number of tar-get words need to be labeled.
In our 128 testsentences, there are 151 target words becausethere are some sentences containing more thanone ambiguous target word.
Experimental re-sults on 18 templates are listed in table 3.From the table 3, we can get four conclusions.Firstly, the best performance 81.46% in T-CRFmodel increases about 5% over the best per-formance 76.82% in CRF model.
This suggeststhe dependencies on the tree structure can cap-ture more important characteristics than thoseon the linear chains do.
Secondly, when weadded the edge feature between current wordand its parent, the performance declined unex-pectedly.
This can be explained in linguistics: ina dependency parsed sentence, the clique of agovernor and its dependents forms ?a smallworld?
which can express partial meaning of thesentence, while the parent of current vertex (ex-cept the root vertex which has no parent) cannot influence much on it because its parent hasits own clique, and current word is just a tinyfragment of the clique of its parent, on the con-trary, the parent vertex feature will bring nega-tive effect on the current word.
For example, thetarget word ???
in figure 2 can illustrate thiscase clearly.
Thirdly, when we added the chil-dren vertexes, the performance increased, that isbecause current word and its dependents to-gether can form a semantic clique of the sen-tence.
Lastly, when we added the dependencyrelation type on the features of parent-childedge and child-parent edge, the performanceimproved slightly because the relation type ofedge is coarser than the edge between parentand child.
There are only 24 kinds of depend-ency types but exist hundreds of edge combina-tion possibilities between parent and child.
Thus,this feature relived the data sparseness problemto a certain extent.There are two main types of errors in the re-sults: one is that the labeling frames of targetwords are not correct.
For example, in the sen-tence ???????????????????????
, the correct frame of ???
?shouldbe ???
?
instead of ???
?, because itdescribed the attitude of ????
not declared afact or a phenomena.
However, this kind ofdeep semantics of sentence couldn?t be capuredby T-CRF model based on the dependencysyntax.
The other is that the labeling frames ofsome target words are tag ?null?.
The reason isthat some lexical units can?t evoke a framesometimes, so in the training data, these wordsare annotated ?null?.5.3 Contrast ExperimentsQu (2008) argues that any words in a sentencehas a certain attraction between each other andthus constitute the grammars and semanticstructure of the sentence.
Based on this cogni-tion, he proposed a generalized collocation the-ory, which includes fixed collocation, loose col-location and Co-occurrence collocation.
Ac-cording to this theory, a context computingmodel RFR_SUM was presented to deal withthe WSD task.In essence, frame identification also belongsto context computing, so it should be reasonableto solve this problem with the generalized col-location theory.
However, our current corpus istoo insufficient to reflect all these three colloca-tions in the statistical sense.
Hence, we pro-posed a method named compatibility of lexicalunit based on the Co-occurrence collocation toidentify frame for ambiguous target word.Precision Windowsize T1 T2 T3 T4 T5 T61 0.7682 0.7219 0.7351 0.8013 0.8146 0.79472 0.7682 0.7152 0.6887 0.7881 0.8146 0.79473 0.7417 0.6623 0.6689 0.7351 0.8013 0.7616Table 3.
Precisions of different templates based on three types of window size680The connotation of compatibility of lexicalunit is as follows.
In the CFN frame database,every frame defines a lexical units set, inwhich each of lexical unit can evoke thisframe.
When one of these lexical units servesas the target word in a sentence, we can usethe compatibilities of other lexical units in thisset with the sentence to reflect the consistencybetween this frame and current sentence.
Thecompatibility of lexical unit with the sentenceis computed by the Co-occurrence frequencyof lexical unit and the notional words in thesentence in a large corpus.
The calculation isas below.Suppose il in the lexical units set{ }1 2, ,... ,...,i mL l l l l= serves as the target wordin the sentence S .
The words in S except thefunctional words and il constitute a wordset { }1 2, ,..., nW w w w= .
And the compatibil-ity of L  with S  is denoted as C .1 2( , ) ( , ) ... ( , )mc l W c l W c l WCm+ += ,where m  is the number of lexical units in L .1 2( , ) ( , ) ... ( , )( , ) j j j njf l w f l w f l wc l Wn+ + += ,where n is the number of words in W .
( , )( , ) j kj kcount l wf l wsum= , where( , )j kcount l w  represents the number of sen-tences, in which jl and kw  occur together, andthese sentences come from the corpus of Pe-king University People's Daily, January 1998.sum  is the total number of sentences in thesame People's Daily corpus.In this way, the consistency between aframe and the current sentence is scored bythe compatibility of L belonging to the candi-date frame with this sentence, and the onewith highest score is regarded as the correctframe.
For our test data, 71.73% precisionbased on this method was obtained.This model displayed a decline in precisionof about 10% over the T-CRF.
Analysis of theresults found that the compatibility based onCo-occurrence collocation can only reflect aweak correlation between words, neglectingthe position and syntactic structure informa-tion in a sentence.In addition, we used the most-frequency-frame experiment as the baseline.
In the cor-pus consisted of 940 training sentences and128 test sentences, the frequency of eachframe was counted for ranking.
The result ofthis method obtained 61.23% precision, whichproved that T-CRF model performed obviousimprovement.6 ConclusionsIn this paper, we investigated the problem ofFrame Identification in Chinese which is thefirst work on Chinese FrameNet.
A tree-structured conditional random field (T-CRF)model was applied to this task based on thedependency syntactic structure.
This modelprovides a way to incorporating the long-distance dependencies between target wordsand the syntactic related words with it.
In ourexperiments, the syntactic dependency fea-tures were shown to work effectively forFrame Identification, with 71.73%, 76.82%,and 81.46% precision for compatibility of lex-ical unit, CRF and T-CRF, respectively.Although a relatively good performancewas achieved on the test data, the small-scaleand simplicity of sentence structure in corpuscannot be ignored compared with the Frame-Net corpus.
However, the experimental resultsthat we gained is still promising, suggestingthat our model is comparatively appropriate tothe Frame Identification task and still has agreat potential for improvement.
The nextwork will focus on the three aspects: firstly,build a larger corpus containing various sen-tence structures in Chinese; the other is thatmore semantic features will be tried to add inthe T-CRF model, such as the frame elementsand the semantic relations between frames,finally, we will try to identify frames of targetwords using other machine learning methodswhich has been proved high performance inthis task.AcknowledgementsThis work is supported by NSFC Grant:60970053 and International Scientific andTechnological Cooperation of Shanxi Prov-ince Grant: 2010081044.
In addition, the au-681thors would like to thank HIT-CIR for theirLTP.ReferencesCharles J. Fillmore.
1982.
Frame Semantics.
InLinguistic in the Morning Calm, pages 111-137,Seoul, Korea: Hanshin Publishing Company.Collin Baker, Michael Ellsworth and Katrin Erk.2007.
SemEval?07 Task 19: Frame SemanticStructure Extraction.
In Proceedings of the 4thInternational Workshop on Semantic Evalua-tions, pages 99-104, Prague.Collin F. Baker, Charles J. Fillmore, and John B.Lowe.
1998.
The Berkeley FrameNet project.
InProceedings of the COLING-ACL, pages 86-90,Montreal, Canada.Cosmin Adrian Bejan and Hathaway Chris.
2007.UTD-SRL: A Pipeline Architecture for Extract-ing Frame Semantic Structures.
In 45th annualmeeting of Association for Computational Lin-guistics.
pages 460-463, Prague.Igor A.
Mel??cuk.
1988.
Dependency Syntax: The-ory and Practice.
State University Press of NewYork, Albany.John Lafferty, Andrew McCallum and FernandoPereira.
2001.
Conditional Random Fields:Probabilistic Models for Segmenting and Label-ing Sequence Data.
In proceedings of the 18thInternational Conference on Machine Learning,pages 282-289, San Francisco, CA, USA.Jorge Nocedal and Stephen J. Wright.
1999.
Nu-merical Optimization.
Springer, New York.Jun Hatori, Yusuke Miyao and Jun?ichi Tsujii.2009.
On Contribution of Sense Dependenciesto Word Sense Disambiguation.
Natural Lan-guage Processing, 16(5):51-77.Katrin Erk.
2005.
Frame assignment as word sensedisambiguation.
In Proceedings of the 6th In-ternational Workshop on Computational Se-mantics (IWCS-6) .Ken.
Litkowski.
2007.
CLR: Integration of Fra-meNet in a Text Representation System.
In 45thannual meeting of Association for Computa-tional Linguistics.
pages 113-116, Prague.Pranjal Awasthi, Aakanksha Gagrani and Balara-man Ravindran.
2007.
Image modeling usingtree structured conditional random fields.
InProceedings of the 20th International JointConference on Artificial Intelligence (IJCAI2007).
Pages 2060-2065.Qu Weiguang.
2008.
Automatic Disambiguation ofModern Chinese Words in Word-level.
Beijing:Science Press(in Chinese).Richard Johansson and Nugues Pierre.
2007.
LTH:Semantic Structure Extraction using Nonprojec-tive Dependency Trees.
In 45th annual meetingof Association for Computational Linguistics.pages 227-230, Prague.Tang Jie, Mingcai Hong, Juanzi Li, and BangyongLiang.
2006.
Tree-structured Conditional Ran-dom Fields for Semantic Annotation.
InProceedings of 5th International Conference ofSemantic Web (ISWC?2006), Athens, GA, USATrevor Cohn and Philip Blunsom.
2005.
Semanticrole labeling with tree conditional random fields.In Proceedings of CoNLL2005.Wang Ruiqin and Fansheng-Kong.
2009.
The Re-search of Unsupervised Word Sense Disam-biguation.
Journal of Software, (20)8: pages2138?2152.Xue Nianwen and Martha Palmer.
2005.
Auto-matic Semantic Role Labeling for ChineseVerbs.
In Proceedings of the 19th InternationalJoint Conference on Artificial Intelligence.
Ed-inburgh, Scotland.You Liping, Kaiying Liu.
2005.
Building ChineseFrameNet database.
In Proceedings of IEEENLP-KE?05.682
