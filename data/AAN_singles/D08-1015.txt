Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 136?144,Honolulu, October 2008. c?2008 Association for Computational LinguisticsRanking Reader Emotions Using Pairwise Loss Minimization andEmotional Distribution RegressionKevin Hsin-Yih Lin and Hsin-Hsi ChenDepartment of Computer Science and Information EngineeringNational Taiwan UniversityNo.
1 Roosevelt Rd.
Sec.
4, Taipei, Taiwan{f93141, hhchen}@csie.ntu.edu.twAbstractThis paper presents two approaches to rankingreader emotions of documents.
Past studiesassign a document to a single emotion cate-gory, so their methods cannot be applied di-rectly to the emotion ranking problem.Furthermore, whereas previous research ana-lyzes emotions from the writer?s perspective,this work examines readers?
emotional states.The first approach proposed in this paperminimizes pairwise ranking errors.
In the sec-ond approach, regression is used to modelemotional distributions.
Experiment resultsshow that the regression method is more ef-fective at identifying the most popular emo-tion, but the pairwise loss minimizationmethod produces ranked lists of emotions thathave better correlations with the correct lists.1 IntroductionEmotion analysis is an increasingly popular re-search topic due to the emergence of large-scaleemotion data on the web.
Previous work primarilystudies emotional contents of texts from thewriter's perspective, where it is typically assumedthat a writer expresses only a single emotion in adocument.
Unfortunately, this premise does nothold when analyzing a document from the reader'sperspective, because readers rarely agree unani-mously on the emotion that a document instills.Figure 1 illustrates this phenomenon.
In the figure,0%10%20%30%40%HeartwarmingHappySadSurprisingAngryBoringAwesomeUsefulEmotion%of ReadersFigure 1.
Emotional responses of 626 people after read-ing a Yahoo!
News article about an Iranian refugeemother and her two children who finally reunited withtheir family in the March of 2007 after been stranded ina Moscow airport for 10 months due to false passports.readers?
responses are distributed among differentemotion categories.
In fact, none of the emotions inFigure 1 has a majority (i.e., more than 50%) of thevotes.
Intuitively, it is better to provide a rankingof emotions according to their popularity ratherthan associating a single reader emotion with adocument.
As a result, current writer-emotionanalysis techniques for classifying a document intoa single emotion category are not suitable for ana-lyzing reader emotions.
New methods capable ofranking emotions are required.Reader-emotion analysis has potential applica-tions that differ from those of writer-emotionanalysis.
For example, by integrating emotionranking into information retrieval, users will beable to retrieve documents that contain relevantcontents and at the same time produce desired feel-ings.
In addition, reader-emotion analysis can as-sist writers in foreseeing how their work willinfluence readers emotionally.136In this paper, we present two approaches toranking reader emotions.
The first approach is in-spired by the success of the pairwise loss minimi-zation framework used in information retrieval torank documents.
Along a similar line, we devise anovel scheme to minimize the number of incor-rectly-ordered emotion pairs in a document.
In thesecond approach, regression is used to modelreader-emotion distributions directly.
Experimentresults show that the regression method is moreeffective at identifying the most popular emotion,but the pairwise loss minimization method pro-duces ordered lists of emotions that have bettercorrelations with the correct lists.The rest of this paper is organized as follows.Section 2 describes related work.
In Section 3, de-tails about the two proposed approaches are pro-vided.
Section 4 introduces the corpus and Section5 presents how features are extracted from the cor-pus.
Section 6 shows the experiment proceduresand results.
Section 7 concludes the paper.2 Related WorkOnly a few studies in the past deal with the readeraspect of emotion analysis.
For example, Lin et al(2007; 2008) classify documents into reader-emotion categories.
Most previous work focuseson the writer?s perspective.
Pang et al (2002) de-sign an algorithm to determine whether a docu-ment?s author expresses a positive or negativesentiment.
They discover that using Support Vec-tor Machines (SVM) with word unigram featuresresults in the best performance.
Since then, morework has been done to find features better thanunigrams.
In (Hu et al, 2005), word sentiment in-formation is exploited to achieve better classifica-tion accuracy.Experiments have been done to extract emo-tional information from texts at granularities finerthan documents.
Wiebe (2000) investigates thesubjectivity of words, whereas Aman and Szpako-wicz (2007) manually label phrases with emotionalcategories.
In 2007, the SemEval-2007 workshoporganized a task on the unsupervised annotation ofnews headlines with emotions (Strapparava andMihalcea, 2007).As for the task of ranking, many machine-learning algorithms have been proposed in infor-mation retrieval.
These techniques generate rank-ing functions which predict the relevance of adocument.
One class of algorithms minimizes theerrors resulting from ordering document pairs in-correctly.
Examples include (Joachims, 2002),(Freund et al, 2003) and (Qin et al, 2007).
In par-ticular, the training phase of the Joachims?
Rank-ing SVM (Joachims, 2002) is formulated as thefollowing SVM optimization problem:min ?+ kjiCkji ,,T21,, ??
www,subject to:0  :1)),(),((:|),(),,(,,,,T,,?????????>??kjikjijkikjkikjkikkjidqdqssVdqdq?
?w     (1)where V is the training corpus, ?
(qk, di) is the fea-ture vector of document di with respect to query qk,sk,i is the relevance score of di with respect to qk, wis a weight vector, C is the SVM cost parameter,and ?i,j,k are slack variables.
The set of constraintsat (1) means that document pairwise orders shouldbe preserved.Unfortunately, the above scheme for exploitingpairwise order information cannot be applied di-rectly to the emotion ranking task, because the taskrequires us to rank emotions within a documentrather than provide a ranking of documents.
In par-ticular, the definitions of ?
(qk,di), ?
(qk,dj), sk,i andsk,j do not apply to emotion ranking.
In the nextsection, we will show how the pairwise loss mini-mization concept is adapted for emotion ranking.3 Ranking Reader EmotionsIn this section, we provide the formal descriptionof the reader-emotion ranking problem.
Then wedescribe the pairwise loss minimization (PLM)approach and the emotional distribution regression(EDR) approach to ranking emotions.3.1 Problem SpecificationThe reader emotion ranking problem is defined asfollows.
Let D = {d1, d2, ?, dN} be the documentspace, and E = {e1, e2, ?, eM} be the emotionspace.
Let fi : E ?
?
be the emotional probabilityfunction of di?D.
That is, fi(ej) outputs the fractionof readers who experience emotion ej after readingdocument di.
Our goal is to find a function r : D ?EM such that r(di) = (e?
(1), e?
(2), ?, e?
(M)) where ?
is137Input: Set of emotion ordered pairs P1.
G ?
a graph with emotions as vertices and no edge2.
while (P ?
?)3.
remove (ej,ek) with the highest confidence from P4.
if adding edge (ej,ek) to G produces a loop5.
then add (ek,ej) to G6.
else add (ej,ek) to G7.
return topological sort of Ga permutation on {1, 2, ?, M}, and fi(e?
(1)) ?
fi(e?(2))?
?
?
fi(e?
(M)).3.2 Pairwise Loss MinimizationAs explained in Section 2, the information retrievalframework for exploiting pairwise order informa-tion cannot be applied directly to the emotion rank-ing problem.
Hence, we introduce a novelformulation of the emotion ranking problem intoan SVM optimization problem with constraintsbased on pairwise loss minimization.Algorithm 1.
Merge Pairwise Orders.We now describe how we rank the emotions of apreviously unseen document using the M(M ?
1)/2pairwise ranking functions gjk created during thetraining phase.
First, all of the pairwise rankingfunctions are applied to the unseen document,which generates the relative orders of every pair ofemotions.
These pairwise orders need to be com-bined together to produce a ranked list of all theemotions.
Algorithm 1 does exactly this.Whereas Ranking SVM generates only a singleranking function, our method creates a pairwiseranking function gjk : D ?
?
for each pair of emo-tions ej and ek, aiming at satisfying the maximumnumber of the inequalities:In Algorithm 1, the confidence of an emotionordered pair at Line 3 is the probability value re-turned by a LIBSVM classifier for predicting theorder.
LIBSVM?s method for generating this prob-ability is described in (Wu et al, 2003).
Lines 4and 5 resolve the problem of conflicting emotionordered pairs forming a loop in the ordering ofemotions.
The ordered list of emotions returned byAlgorithm 1 at Line 7 is the final output of thePLM method.
?di?D | fi(ej) > fi(ek) : gjk(di) > 0?di?D | fi(ej) < fi(ek) : gjk(di) < 0In other words, we want to minimize the number ofincorrectly-ordered emotion pairs.
We further re-quire gjk(di) to have the linear form wT?
(di) + b,where w is a weight vector, b is a constant, and?
(di) is the feature vector of di.
Details of featureextraction will be presented in Section 5.As Joachims (2002) points out, the above typeof problem is NP-Hard.
However, an approximatesolution to finding gik can be obtained by solvingthe following SVM optimization problem:3.3 Emotional Distribution RegressionIn the second approach to ranking emotions, weuse regression to model fi directly.
A regressionfunction hj : D ?
?
is generated for each ej?E bylearning from the examples (?
(di), fi(ej)) for alldocuments di in the training corpus.min ?+ ib Ci ?
?, www T21,subject to:0  :1))((:)()(|1)(:)()(|TT????+??<????+?>??iiikijiiiikijiiibdefefQdbdefefQd??
?wwThe regression framework we adopt is SupportVector Regression (SVR), which is a regressionanalysis technique based on SVM (Sch?lkopf et al,2000).
We require hj to have the form wT?
(di) + b.Finding hj is equivalent to solving the followingoptimization problem:where C is the SVM cost parameter, ?i are slackvariables, and Q is the training corpus.
We assumeeach document di?Q is labeled with fi(ej) for everyemotion ej?E.min )( 2,1,T21,, 2,1, iib Cii ???
?, ++ ?wwwsubject to:When formulated as an SVM optimization prob-lem, finding gjk is equivalent to training an SVMclassifier for classifying a document into the ej orek category.
Hence, we use LIBSVM, which is anSVM implementation, to obtain the solution.10 , :)())(())(()(:2,1,2,T1,T?????+???+????iiijiiiijiiiefbdbdefQd?????
?ww1 http://www.csie.ntu.edu.tw/~cjlin/libsvm/13802000400060008000[20%,30%)[30%,40%)[40%,50%)[50%,60%)[60%,70%)[70%,80%)[80%,90%)[90%,100%]Percentage of Votes Received by Most Popular EmotionNumber of NewsArticlesFigure 2.
News articles in the entire corpus grouped bythe percentage of votes received by the most popularemotion.where C is the cost parameter, ?
is the maximumdifference between the predicted and actual valueswe wish to maintain, ?i,1 and ?i,2 are slack variables,and Q is the training corpus.
To solve the aboveoptimization problem, we use SVMlight?s SVR im-plementation.2When ranking the emotions of a previously un-seen document dk, we sort the emotions ej?E indescending order of hj(dk).4 Constructing the CorpusThe training and test corpora used in this studycomprise Chinese news articles from Yahoo!
KimoNews3, which allows a user to cast a vote for oneof eight emotions to express how a news articlemakes her feel.
Each Yahoo!
news article containsa list of eight emotions at the bottom of the web-page.
A reader may select one of the emotions andclick on a submit button to submit the emotion.
Aswith many websites which collect user responses,such as the Internet Movie Database, users are notforced to submit their responses.
After submitting aresponse, the user can view a distribution of emo-tions indicating how other readers feel about thesame article.
Figure 1 shows the voting results of aYahoo!
news article.The eight available emotions are happy, sad,angry, surprising, boring, heartwarming, awesome,and useful.
Useful is not a true emotion.
Rather, itmeans that a news article contains practical infor-mation.
The value fi(ej) is derived by normalizingthe number of votes for emotion ej in document diby the total number votes in di.The entire corpus consists of 37,416 news arti-cles dating from January 24, 2007 to August 7,2007.
News articles prior to June 1, 2007 form thetraining corpus (25,975 articles), and the remainingones form the test corpus (11,441 articles).
Wecollect articles a week after their publication datesto ensure that the vote counts have stabilized.2 http://svmlight.joachims.org/3 http://tw.news.yahoo.comAs mentioned earlier, readers rarely agreeunanimously on the emotion of a document.
Figure2 illustrates this.
In 41% of all the news articles inthe entire corpus, the most popular emotion re-ceives less than 60% of the votes.5 Extracting FeaturesAfter obtaining news articles, the next step is todetermine how to convert them into feature vectorsfor SVM and SVR.
That is, we want to instantiate?.
For this purpose, three types of features are ex-tracted.The first feature type consists of Chinese charac-ter bigrams, which are taken from the headline andcontent of each news article.
The presence of a bi-gram is indicated by a binary feature value.Chinese words form the second type of features.Unlike English words, consecutive Chinese wordsin a sentence are not separated by spaces.
To dealwith this problem, we utilize Stanford NLPGroup?s Chinese word segmenter to split a sen-tence into words.4 As in the case of bigrams, bi-nary feature values are used.We use character bigram features in addition toword features to increase the coverage of Chinesewords.
A Chinese word is formed by one or morecontiguous Chinese characters.
As mentioned ear-lier, Chinese words in a sentence are not separatedby any boundary symbol (e.g., a space), so a Chi-nese word segmentation tool is always required toextract words from a sentence.
However, a wordsegmenter may identify word boundaries errone-ously, resulting in the loss of correct Chinesewords.
This problem is particularly severe if thereare a lot of out-of-vocabulary words in a dataset.
InChinese, around 70% of all Chinese words areChinese character bigrams (Chen et al, 1997).Thus, using Chinese character bigrams as featureswill allow us to identify a lot of Chinese words,which when combined with the words extracted bythe word segmenter, will give us a wider coverageof Chinese words.The third feature type is extracted from newsmetadata.
A news article?s metadata are its news4 http://nlp.stanford.edu/software/segmenter.shtml139NDCG@k is used because ACC@k has the dis-advantage of not taking emotional distributionsinto account.
Take Figure 1 as an example.
In thefigure, heartwarming and happy have 31.3% and30.7% of the votes, respectively.
Since the twopercentages are very close, it is reasonable to saythat predicting happy as the first item in a rankedlist may also be acceptable.
However, doing sowould be completely incorrect according toACC@k. In contrast, NDCG@k would consider itto be partially correct, and the extent of correctnessdepends on how much heartwarming and happy?spercentages of votes differ.
To be exact, if happy ispredicted as the first item, then the correspondingNDCG@1 would be 30.7% / 31.3% = 0.98.category, agency, hour of publication, reporter, andevent location.
Examples of news categories in-clude sports and political.
Again, we use binaryfeature values.
News metadata are used becausethey may contain implicit emotional information.6 ExperimentsThe experiments are designed to achieve the fol-lowing four goals: (i) to compare the ranking per-formance of different methods, (ii) to analyze thepairwise ranking quality of PLM, (iii) to analyzethe distribution estimation quality of EDR, and (iv)to compare the ranking performance of differentfeature sets.
The Yahoo!
News training and testcorpora presented in Section 4 are used in all ex-periments.The third metric is SACC@k, or set accuracy atk.
It is a variant of ACC@k. According toSACC@k, a predicted ranked list is correct if theset of its first k items is the same as the true rankedlist?s set of first k items.
In effect, SACC@k evalu-ates a ranking method?s ability to place the top kmost important items in the first k positions.6.1 Evaluation Metrics for RankingWe employ three metrics as indicators of rankingquality: ACC@k, NDCG@k and SACC@k.ACC@k stands for accuracy at position k. Ac-cording to ACC@k, a predicted ranked list is cor-rect if the list?s first k items are identical (i.e., sameitems in the same order) to the true ranked list?sfirst k items.
If two emotions in a list have thesame number of votes, then their positions are in-terchangeable.
ACC@k is computed by dividingthe number of correctly-predicted instances by thetotal number of instances.6.2 Tuning SVM and SVR ParametersSVM and SVR are employed in PLM and EDR,respectively.
Both SVM and SVR have the adjust-able C cost parameter, and SVR has an additional ?parameter.
To estimate the optimal C value for acombination of SVM and features, we perform 4-fold cross-validation on the Yahoo!
News trainingcorpus, and select the C value which results in thehighest binary classification accuracy during cross-validation.
The same procedure is used to estimatethe best C and ?
values for a combination of SVRand features.
The C-?
pair which results in thelowest mean squared error during cross-validationis chosen.
The candidate C values for both SVMand SVR are 2-10, 2-9, ?, 2-6.
The candidate ?
val-ues for SVR are 10-2 and 10-1.
All cross-validationsare performed solely on the training data.
The testdata are not used to tune the parameters.
Also,SVM and SVR allow users to specify the type ofkernel to use.
Linear kernel is selected for bothSVM and SVR.NDCG@k, or normalized discounted cumulativegain at position k (J?rvelin and Kek?l?inen, 2002),is a metric frequently used in information retrievalto judge the quality of a ranked list when multiplelevels of relevance are considered.
This metric isdefined as?
= += ki ik irelzk 1 2 )1(log@NDCGwhere reli is the relevance score of the predicteditem at position i, and zk is a normalizing factorwhich ensures that a correct ranked list has anNDCG@k value of 1.
In the emotion ranking prob-lem, reli is the percentage of reader votes receivedby the emotion at position i.
Note that the log2(i+1)value in the denominator is a discount factor whichdecreases the weights of items ranked later in a list.NDCG@k has the range [0, 1], where 1 is the best.In the experiment results, NDCG@k values areaveraged over all instances in the test corpus.6.3 Nearest Neighbor BaselineThe nearest neighbor (NN) method is used as thebaseline.
The ranked emotion list of a news articlein the test corpus is predicted as follows.
First, the1400.00.20.40.60.81 2 3 4 5 6 7 8ACC@AccuracyNNEDRPLM0.50.60.70.80.91.01 2 3 4 5 6 7 8NDCG@NDCGValueNNEDRPLM0.00.20.40.60.81.01 2 3 4 5 6 7 8SACC@AccuracyNNEDRPLMFigure 3.
ACC@k Figure 4.
NDCG@k Figure 5.
SACC@k0%20%40%60%80%100%1 2 3 4 5 6 7 8ACC@%of Test InstancesBothIncorrectOnly PLMCorrectOnly EDRCorrectBothCorrectFigure 6.
Performance of PLM and EDR.test news article is compared to every trainingnews article using cosine similarity, which is de-fined as||||||),(cosiijiji DDDDdd ?
?=where di and dj are two news articles, and Di and Djare sets of Chinese character bigrams in di and dj,respectively.
The ranked emotion list of the train-ing article having the highest cosine similarity withthe test article is used as the predicted ranked list.6.4 Comparison of MethodsFigures 3 to 5 show the performance of differentranking methods on the test corpus.
For both PLMand EDR, all of the bigram, word, and news meta-data features are used.In Figure 3, EDR?s ACC@1 (0.751) is higherthan those of PLM and NN, and the differences arestatistically significant with p-value < 0.01.
So,EDR is the best method at predicting the mostpopular emotion.
However, PLM has the bestACC@k for k ?
2, and the differences from theother two methods are all significant with p-value< 0.01.
This means that PLM?s predicted rankedlists better resemble the true ranked lists.Figure 3 displays a sharp decrease in ACC@kvalues as k increases.
This trend indicates the hard-ness of predicting a ranked list correctly.
Lookingfrom a different angle, the ranking task under theACC@k metric is equivalent to the classificationof news articles into one of 8!/(8 ?
k)!
classes,where we regard each unique emotion sequence oflength k as a class.
In fact, computing ACC@8 fora ranking method is the same as evaluating themethod?s ability to classify a news article into oneof 8!
= 40,320 classes.
So, producing a completely-correct ranked list is a difficult task.In Figure 4, all of PLM and EDR?s NDCG@kimprovements over NN are statistically significantwith p-value < 0.01.
For some values of k, the dif-ference in NDCG@k between PLM and EDR isnot significant.
The high NDCG@k values (i.e.,greater than 0.8) of PLM and EDR imply that al-though it is difficult for PLM and EDR to generatecompletely-correct ranked lists, these two methodsare effective at placing highly popular emotions tothe beginning of ranked lists.In Figure 5, PLM outperforms the other twomethods for 2 ?
k ?
7, and the differences are allstatistically significant with p-value < 0.01.
Forsmall values of k (e.g., 2 ?
k ?
3), PLM?s higherSACC@k values mean that PLM is better at plac-ing the highly popular emotions in the top posi-tions of a ranked list.To further compare PLM and EDR, we examinetheir performance on individual test instances.
Fig-ure 6 shows the percentage of test instances whereboth PLM and EDR give incorrect lists, only PLMgives correct lists, only EDR gives ranked lists,and both methods give correct lists.
The ?OnlyPLM Correct?
and ?Only EDR Correct?
categoriesare nonzero, so neither PLM nor EDR is alwaysbetter than the other.In summary, EDR is the best at predicting themost popular emotion according to ACC@1,NDCG@1 and SACC@1.
However, PLM gener-ates ranked lists that better resemble the correctranked lists according to ACC@k and SACC@k141Method Average ?b Average p-valuePLM 0.584 0.068EDR 0.474 0.114NN 0.392 0.155Table 1.
Kendall?s ?b statistics.He Su Sa Us Ha Bo AnAw 0.80  0.75  0.78  0.77  0.82  0.76 0.79He  0.79  0.81  0.78  0.81  0.89 0.81Su   0.82  0.78  0.80  0.82 0.82Sa    0.78  0.80  0.84 0.82Us     0.82  0.91 0.82Ha      0.83 0.79Bo      0.80Table 2.
Classification accuracies of SVM pairwiseemotion classifiers on the test corpus.
He = heartwarm-ing, Su = surprising, Sa = sad, Us = useful, Ha = happy,Bo = boring, and An = angry.0.530.580.630.680.730.75 0.8 0.85 0.9Accuracy of Pairwise Emotion ClassificationAverageDiscriminationValueof EmotionPairFigure 7.
Accuracy of pairwise emotion classificationand the corresponding average discrimination value.for k ?
2.
Further analysis shows that neithermethod is always better than the other.6.5 Pairwise Ranking Quality of PLMIn this subsection, we evaluate the performance ofPLM in predicting pairwise orders.We first examine the quality of ranked lists gen-erated by PLM in terms of pairwise orders.
To dothis, we use Kendall?s ?b correlation coefficient,which is a statistical measure for determining thecorrelation between two ranked lists when theremay be ties between two items in a list (Liebetrau,1983).
The value of ?b is determined based on thenumber of concordant pairwise orders and thenumber of discordant pairwise orders between tworanked lists.
Therefore, this measure is appropriatefor evaluating the effectiveness of PLM at predict-ing pairwise orders correctly.
?b has the range [-1,1], where 1 means a perfect positive correlation,and -1 means two lists are the reverse of each other.When computing ?b of two ranked lists, we alsocalculate a p-value to indicate whether the correla-tion is statistically significant.We compute ?b statistics between a predictedranked list and the corresponding true ranked list.Table 1 shows the results.
In Table 1, numbers inthe ?Average ?b?
and ?Average p-value?
columnsare averaged over all test instances.
The statisticsfor EDR and NN are also included for comparison.From the table, we see that PLM has the highestaverage ?b value and the lowest average p-value, soPLM is better at preserving pairwise orders thanEDR and NN methods.
This observation verifiesthat PLM?s minimization of pairwise loss leads tobetter prediction of pairwise orders.We now look at the individual performance ofthe 28 pairwise emotion rankers gjk.
As mentionedin Section 3.2, each pairwise emotion ranker gjk isequivalent to a binary classifier for classifying adocument into the ej or ek category.
So, we look attheir classification accuracies in Table 2.
In thetable, accuracy ranges from 0.75 for the awesome-surprising pair to 0.91 for the useful-boring pair.From the psychological perspective, the rela-tively low accuracy of the awesome-surprising pairis expected, because awesome is surprising in apositive sense.
So, readers should have a hard timedistinguishing between these two emotions.
Andthe SVM classifier, which models reader responses,should also find it difficult to discern these twoemotions.
Based on this observation, we suspectthat the pairwise classification performance actu-ally reflects the underlying emotional ambiguityexperienced by readers.
To verify this, we quantifythe degree of ambiguity between two emotions,and compare the result to pairwise classificationaccuracy.To quantify emotional ambiguity, we introducethe concept of discrimination value between twoemotions ej and ek in a document di, which is de-fined as follows:)()()()(kijikijiefefefef+?where fi is the emotional probability function de-fined in Section 3.1.
Intuitively, the larger the dis-crimination value is, the smaller the degree ofambiguity between two emotions is.Figure 7 shows the relationship between pair-wise classification accuracy and the average dis-crimination value of the corresponding emotion1420.000.020.040.060.08AwesomeHeartwarmingSurprisingSadUsefulHappyBoringAngryEmotionMeanSquaredErrorNNEDRFigure 8.
Mean squared error of NN and EDR for esti-mating the emotional distributions of the test corpus.0.00.20.40.60.81 2 3 4 5 6 7 8ACC@AccuracyMetadataWordsBigramsAllFigure 9.
PLM performance using different features.pair.
The general pattern is that as accuracy in-creases, the discrimination value also increases.
Toprovide concrete evidence, we use Pearson?s prod-uct-moment correlation coefficient, which has therange of [-1, 1], where 1 means a perfect positivecorrelation (Moore, 2006).
The coefficient for thedata in Figure 7 is 0.726 with p-value < 0.01.
Thus,pairwise emotion classification accuracy reflectsthe emotional ambiguity experienced by readers.In summary, PLM?s pairwise loss minimizationleads to better pairwise order predictions than EDRand NN.
Also, the pairwise classification resultsreveal the inherent ambiguity between emotions.6.6 Distribution Estimation Quality of EDRIn this subsection, we evaluate EDR?s performancein estimating the emotional probability function fi.With the prior knowledge that a news article?s fivalues sum to 1 over all emotions, and fi is between0 and 1, we adjust EDR?s fi predictions to produceproper distributions.
It is done as follows.
A pre-dicted fi value greater than 1 or less than 0 is set to1 and 0, respectively.
Then the predicted fi valuesare normalized to sum to 1 over all emotions.NN?s distribution estimation performance is in-cluded for comparison.
For NN, the predicted fivalues of a test article are taken from the emotionaldistribution of the most similar training article.Figure 8 shows the mean squared error of EDRand NN for predicting fi.
In the figure, the errorgenerated by EDR is less than those by NN, and allthe differences are statistically significant with p-value < 0.01.
Thus, EDR?s use of regression leadsto better estimation of fi than the NN.6.7 Comparison of FeaturesFigure 9 shows each of the three feature type?sACC@k for predicting test instances?
ranked listswhen PLM is used.
The feature comparison graphfor EDR is not shown, because it exhibits a verysimilar trend as PLM.
For both PLM and EDR,bigrams are better than words, which are in turnbetter than news metadata.
In Figure 9, the combi-nation of all three feature sets achieves the bestperformance.
For both PLM and EDR, the im-provements in ACC@k of using all features overwords and metadata are all significant with p-value< 0.01, and the improvements over bigrams aresignificant for k ?
2.
Hence, in general, it is betterto use all three feature types together.7 Conclusions and Future WorkThis paper presents two methods to ranking readeremotions.
The PLM method minimizes pairwiseloss, and the EDR method estimates emotional dis-tribution through regression.
Experiments withsignificant tests show that EDR is better at predict-ing the most popular emotion, but PLM producesranked lists that have higher correlation with thecorrect lists.
We further verify that PLM has betterpairwise ranking performance than the other twomethods, and EDR has better distribution estima-tion performance than NN.As for future work, there are several directionswe can pursue.
An observation is that PLM ex-ploits pairwise order information, whereas EDRexploits emotional distribution information.
Weplan to combine these two methods together.
An-other research direction is to improve EDR byfinding better features.
We would also like to inte-grate emotion ranking into information retrieval.AcknowledgmentsWe are grateful to the Computer and InformationNetworking Center, National Taiwan University,for the support of high-performance computingfacilities.
The research in this paper was partiallysupported by National Science Council, Taiwan,under the contract NSC 96-2628-E-002-240-MY3.143ReferencesSaima Aman and Stan Szpakowicz.
2007.
IdentifyingExpressions of Emotion in Text.
In Proceedings of10th International Conference on Text, Speech andDialogue, Lecture Notes in Computer Science 4629,196-205.
Springer, Plze?, CZ.Aitao Chen, Jianzhang He, Liangjie Xu, Frederic Gey,and Jason Meggs.
1997.
Chinese Text Retrievalwihtout using a Dictionary.
In Proceedings of 20thAnnual International ACM SIGIR Conference onResearch and Development in Information Retrieval,42-49.
Association for Computing Machinery, Phila-delphia, US.Yoav Freund, Raj D. Iyer, Robert E. Schapire, andYoram Singer.
2003.
An Efficient Boosting Algorithmfor Combining Preferences.
Journal of MachineLearning Research, 4, 933-969.Yi Hu, Jianyong Duan, Xiaoming Chen, Bingzhen Pei,and Ruzhan Lu.
2005.
A New Method for SentimentClassification in Text Retrieval.
In Proceedings of2nd International Joint Conference on Natural Lan-guage Processing, 1-9.
Jeju Island, KR.Kalervo J?rvelin and Jaana Kek?l?inen.
CumulativeGain-based Evaluation of IR Techniques.
2002.ACM Transactions on Information Systems, 20(4),422-446.Thorsten Joachims.
2002.
Optimizing Search Enginesusing Clickthrough Data.
In Proceedings of 8thACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining.
Association forComputing Machinery, Edmonton, CA.Albert M. Liebetrau.
1983.
Measures of Association.Sage Publications, Newbury Park, US.Kevin H. Lin, Changhua Yang, and Hsin-Hsi Chen.2007.
What Emotions do News Articles Trigger intheir Readers?
In Proceedings of 30th ACM SIGIRConference, 733-734.
Association for ComputingMachinery, Amsterdam, NL.Kevin H. Lin, Changhua Yang, and Hsin-Hsi Chen.2008.
Emotion Classification of Online News Articlesfrom the Reader?s Perspective.
In Proceedings of In-ternational Conference on Web Intelligence.
Instituteof Electrical and Electronics Engineers, Sydney, AU.David Moore.
2006.
The Basic Practice of Statistics.W.H.
Freeman and Company, New York, US.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment Classification UsingMachine Learning Techniques.
In Proceedings of2002 Conference on Empirical Methods in NaturalLanguage Processing, 79-86.
Association for Com-putational Linguistics, Philadelphia, US.Tao Qin, Tie-Yan Liu, Wei Lai, Xu-Dong Zhang, De-Sheng Wang, and Hang Li.
2007.
Ranking with Mul-tiple Hyperplanes.
In Proceedings of 30th ACMSIGIR Conference, 279-286.
Association for Com-puting Machinery, Amsterdam, NL.Bernhard Sch?lkopf, Alex J. Smola, Robert C. William-son, and Peter L. Barlett.
2000.
New Support VectorAlgorithms.
Neural Computation, 12(5), 1207-1245.Carlo Strapparava and Rada Mihalcea.
2007.
SemEval-2007 Task 14: Affective Text.
In Proceedings of 4thInternational Workshop on Semantic Evaluations.Prague, CZ.Janyce M. Wiebe.
2000.
Learning Subjective Adjectivesfrom Corpora.
In Proceedings of 17th Conference ofthe American Association for Artificial Intelligence,735-740.
AAAI Press, Austin, US.Ting-Fan Wu, Chih-Jen Lin, and Ruby C. Weng.
Prob-ability Estimates for Multi-class Classification byPairwise Coupling.
2004.
Journal of Machine Learn-ing Research, 5, 975-1005.144
