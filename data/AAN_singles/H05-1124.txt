Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 987?994, Vancouver, October 2005. c?2005 Association for Computational LinguisticsFlexible Text Segmentation with Structured Multilabel ClassificationRyan McDonald Koby Crammer Fernando PereiraDepartment of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104{ryantm,crammer,pereira}@cis.upenn.eduAbstractMany language processing tasks can be re-duced to breaking the text into segmentswith prescribed properties.
Such tasksinclude sentence splitting, tokenization,named-entity extraction, and chunking.We present a new model of text segmenta-tion based on ideas from multilabel clas-sification.
Using this model, we can natu-rally represent segmentation problems in-volving overlapping and non-contiguoussegments.
We evaluate the model on en-tity extraction and noun-phrase chunkingand show that it is more accurate for over-lapping and non-contiguous segments, butit still performs well on simpler data setsfor which sequential tagging has been thebest method.1 IntroductionText segmentation is a basic task in language pro-cessing, with applications such as tokenization, sen-tence splitting, named-entity extraction, and chunk-ing.
Many parsers, translation systems, and extrac-tion systems rely on such segmentations to accu-rately process the data.
Depending on the applica-tion, segments may be tokens, phrases, or sentences.However, in this paper we primarily focus on seg-menting sentences into tokens.The most common approach to text segmenta-tion is to use finite-state sequence tagging mod-els, in which each atomic text element (characteror token) is labeled with a tag representing its rolein a segmentation.
Models of that form includehidden Markov models (Rabiner, 1989; Bikel etal., 1999) as well as discriminative tagging mod-els based on maximum entropy classification (Rat-naparkhi, 1996; McCallum et al, 2000), conditionalrandom fields (Lafferty et al, 2001; Sha and Pereira,2003), and large-margin techniques (Kudo and Mat-sumoto, 2001; Taskar et al, 2003).
Tagging mod-els are the best previous methods for text segmen-tation.
However, their purely sequential form limitstheir ability to naturally handle overlapping or non-contiguous segments.We present here an alternative view of segmenta-tion as structured multilabel classification.
In thisview, a segmentation of a text is a set of segments,each of which is defined by the set of text positionsthat belong to the segment.
Thus, a particular seg-ment may not be a set of consecutive positions inthe text, and segments may overlap.
Given a textx = x1 ?
?
?
xn, the set of possible segments, whichcorresponds to the set of possible classification la-bels, is seg(x) = {O,I}n; for y ?
seg(x), yi = Iiff xi belongs to the segment.
Then, our segmen-tation task is to determine which labels are correctsegments in a given text.
We have thus a structuredmultilabel classification problem: each instance, atext, may have multiple structured labels, represent-ing each of its segments.
These labels are structuredin that they do not come from a predefined set, butinstead are built from sets of choices associated tothe elements of arbitrarily long instances.More generally, we may be interested in typedsegments, e.g.
segments naming different types of987entities.
In that case, the set of segment labels isseg(x) = T ?
{O,I}n, where T is the set of seg-ment types.
Since the extension is straightforward,we frame the discussion in terms of untyped seg-ments, and only discuss segment types as needed.At first sight, it might appear that we have madethe segmentation problem intractably harder by turn-ing it into a classification problem with a numberof labels exponential on the length of the instance.However, we can bound the number of labels underconsideration and take advantage of the structure oflabels to find the k most likely labels efficiently.
Thiswill allow us to exploit recent advances in online dis-criminative methods for multilabel classification andranking (Crammer and Singer, 2002).Though multilabel classification has been wellstudied (Schapire and Singer, 1999; Elisseeff andWeston, 2001), as far as we are aware, this is thefirst study involving structured labels.2 Segmentation as TaggingThe standard approach to text segmentation is to usetagging techniques with a BIO tag set.
Elements inthe input text are tagged with one of B for the be-ginning of a contiguous segment, I for the insideof a contiguous segment, or O for outside a seg-ment.
Thus, segments must be contiguous and non-overlapping.
For instance, consider the sentence Es-timated volume was a light 2.4 million ounces.
Fig-ure 1a shows how this sentence would be labeledusing the BIO tag set for the problem of identifyingbase NPs in text.
Given a particular tagging for asentence, it is trivial to find all the segments, thosewhose tag sequences are longest matches for the reg-ular expression BI?.
For typed segments, the BIOtag set is easily augmented to indicate not only seg-ment boundaries, but also the type of each segment.Figure 1b exemplifies the tags for the task of findingpeople and organizations in text.Sequential tagging with the BIO tag set hasproven quite accurate for shallow parsing and namedentity extraction tasks (Kudo and Matsumoto, 2001;Sha and Pereira, 2003; Tjong Kim Sang andDe Meulder, 2003).
However, this approachcan only identify non-overlapping, contiguous seg-ments.
This is sufficient for some applications, andin any case, most training data sets are annotatedwithout concern for overlapping or non-contiguoussegments.
However, there are instances in which se-quential labeling techniques using the BIO label setwill encounter problems.Figure 2 shows two simple examples of segmen-tations involving overlapping, non-contiguous seg-ments.
In both cases, it is difficult to see how asequential tagger could extract the segments cor-rectly.
It would be possible to grow the tag set torepresent a bounded number of overlapping, non-contiguous segments by representing all possiblecombinations of segment membership over k over-lapping segments, but this would require an arbitraryupper bound on k and would lead to models that gen-eralize poorly and are expensive to train.Dickinson and Meurers (2005) point out that, aslanguage processing begins to tackle problems infree-word order languages and discourse analysis,annotating and extracting non-contiguous segmen-tations of text will become increasingly important.Though we focus primarily on entity extraction andNP chunking in this paper, there is no reason whyideas presented here could not be extended to man-aging other non-contiguous phenomena.3 Structured Multilabel ClassificationAs outlined in Section 1, we represent segmentationas multilabel classification, assigning to each textthe set of segments it contains.
Figure 3 shows thesegments for the examples of Figure 2.
Each seg-ment is given by a O/I assignment to its words, in-dicating which words belong to the segment.By representing the segmentation problems asmultilabel classification, we have fundamentallychanged the objective of our learning and inferencealgorithms.
The sequential tagging formulation isaimed to learn and find the best possible tagging ofa text.
In multilabel classification, we train modelparameters so that correct labels ?
that is, correctsegments ?
receive higher score than all incorrectones.
Likewise, inference becomes the problem offinding the set of correct labels for a text, that is, theset of correct segments.We now describe the learning problem using thedecision-theoretic multilabel classification and rank-ing framework of Crammer and Singer (2002) andCrammer (2005) as our starting point.
In Sec-988a.
Estimated volume was a light 2.4 million ounces .B I O B I I I I Ob.
Bill Clinton and Microsoft founder Bill Gates met today for 20 minutes .B-PER I-PER O B-ORG O B-PER I-PER O O O O O OFigure 1: Sequential labeling formulation of text segmentation using the BIO label set.
a) NP-chunkingtasks.
b) Named-entity extraction task.a) Today, Bill and Hilary Clinton traveled to Canada.- Person: Bill Clinton- Person: Hilary Clintonb) ... purified bovine P450 11 beta / 18 / 19 - hydroxylase was ...- Enzyme: P450 11 beta-hydroxylase- Enzyme: P450 18-hydroxylase- Enzyme: P450 19-hydroxilaseFigure 2: Examples of overlapping and non-contiguous text segmentations.tion 3.2, we describe a polynomial-time inferencealgorithm for finding up to k correct segments.3.1 Training Multilabel ClassifiersOur model is based on a linear score s(x,y; w) foreach segment y of text x, defined ass(x,y; w) = w ?
f(x,y)where f(x,y) is a feature vector representation ofthe sentence-segment pair, and w is a vector offeature weights.
For a given text x, act(x) ?seg(x) denotes the set of correct segments for x, andbestk(x; w) denotes the set of k segments with high-est score relative to the weight vector w. For learn-ing, we use a training set T = {(xt, act(xt))}|T |t=1 oftexts labeled with the correct segmentation.We will discuss later the design of f(x,y) and anefficient algorithm for finding the k highest scoringsegments (where k is sufficiently large to includeall correct segments).
In this section, we present amethod for learning a weight vector w that seeks toscore correct segments above all incorrect segments.Crammer and Singer (2002), extended by Cram-mer (2005), provide online learning algorithms formultilabel classification and ranking that take oneinstance at a time, construct a set of scoring con-straints for the instance, and adjust the weight vec-tor to satisfy the constraints.
The constraints en-force a margin between the scores of correct labelsand those of incorrect labels.
The benefits of large-margin learning are best known from SVMs (Cris-tianini and Shawe-Taylor, 2000; Scho?lkopf andTraining data: T = {(xt, act(xt))}|T |t=11.
w(0) = 0; i = 02. for n : 1..N3.
for t : 1..|T |4.
w(i+1) = arg minw??
?w ?
w(i)???2s.t.
s(xt, y; w) ?
s(xt, y?
; w) + 1?y ?
act(xt), ?y?
?
bestk(xt; w(i)) ?
act(xt)6. i = i + 17. w = w(N?|T |)Figure 4: A simplified version of the multilabellearning algorithm of Crammer and Singer (2002).Smola, 2002), and are analyzed in detail by Cram-mer (2005) for online multilabel classification.For segmentation, the number of possible labels(segments) is exponential on the length of the text.We make the problem tractable by including only themargin constraints between correct segments and atmost k highest scoring incorrect segments.
Figure 4sketches an online learning algorithm for multilabelclassification based on the work of Crammer (2005).In the algorithm, w(i+1) is the projection of w(i) ontothe set of weight vectors such that the scores of cor-rect segments are separated by a margin of at least1 from the scores of incorrect segments among thek top-scoring segments.
This update is conservativein that there is no weight change if the constraint setis already satisfied or empty; if some constraints arenot satisfied, we make the smallest weight changethat satisfies the constraints.
Since, the objective isquadratic in w and the constraints are linear, the op-timization problem can be solved by Hildreth?s al-989a) Today , Bill and Hilary Clinton traveled to Canada .O O I O O I O O O OO O O O I I O O O Ob) ... purified bovine P450 11 beta / 18 / 19 - hydroxylase was ...O O I I I O O O O I I OO O I O O O I O O I I OO O I O O O O O I I I OFigure 3: Correct segments for two examples.gorithm (Censor and Zenios, 1997).Using standard arguments for linear classifiers(add constant feature, rescale weights) and the factthat all the correct scores in line 4 of Figure 4 are re-quired to be above all the incorrect scores in the topk, that line can be replaced byw(i+1) = arg minw?
?w ?
w(i)??2s.t.
s(xt,y; w) ?
1 and s(xt,y?
; w) ?
?1?y ?
act(xt),?y?
?
bestk(xt; w(i)) ?
act(xt)If v is the number of correct segments for x,this transformation replaces O(kv) constraints withO(k + v) constraints: segment scores are comparedto a single positive or negative threshold rather thento each other.
At test time, we find the segmentswith positive score by finding the k highest scoringsegments and discarding those with a negative score.3.2 InferenceDuring learning and at test time we require a methodfor finding the k highest scoring segments.
At testtime, we predict as correct all the segments with pos-itive score in the top k. In this section we give analgorithm that calculates this precisely.For inference, tagging models typically use theViterbi algorithm (Rabiner, 1989).
The algorithm isgiven by the following standard recurrences:S[i, t] = maxt?
s(t?, t, i) + S[i ?
1, t?
]B[i, t] = arg maxt?
s(t?, t, i) + S[i ?
1, t?
]with appropriate initial conditions, where s(t?, t, i)is the score for going from tag t?
at i ?
1 to tag tat i.
The dynamic programming table S[i, t] storesthe score of the best tag sequence ending at posi-tion i with tag t, and B[i, t] is a back-pointer to theprevious tag in the best sequence ending at i witht, which allows us to reconstruct the best sequence.The Viterbi algorithm has easy k-best extensions.We could find the k highest scoring segments us-ing Viterbi.
However, for the case of non-contiguoussegments, we would like to represent higher-orderdependencies that are difficult to model in Viterbi.
Inparticular, in Figure 3b we definitely want a featurebridging the gap between Bill and Clinton, whichcould not be captured with a standard first-ordermodel.
But moving to higher-order models wouldrequire adding dimensions to the dynamic program-ming tables S and B, with corresponding multipliersto the complexity of inference.To represent dependencies between non-contiguous text positions, for any given segmenty = y1 ?
?
?
yn, let i(y) = 0i1 ?
?
?
im(n + 1) be theincreasing sequence of indices ij such that yij = I,padded for convenience with the dummy first index0 and last index n + 1.
Also for convenience, setx0 = -s- and xn+1 = -e- for fixed start andend markers.
Then, we restrict ourselves to featurefunctions f(x,y) that factor relative to the input asf(x,y) =|i(y)|?j=1g(i(y)j?1, i(y)j) (1)where i(y)j is the jth integer in i(y) and g is a fea-ture function depending on arbitrary properties ofthe input relative to the indices i(y)j?1 and i(y)j .Applying (1) to the segment Bill Clinton in Fig-ure 3, its score would bew ?
[g(0, 3) + g(3, 6) + g(6, 11)]This feature representation allows us to include de-pendencies between non-contiguous segment posi-tions, as well as dependencies on any properties ofthe input, including properties of skipped positions.We now define the following dynamic programS[i] = maxj<i S[j] + w ?
g(j, i)B[i] = arg maxj<i S[j] + w ?
g(j, i)990These recurrences compute the score S[i] of the bestpartial segment ending at i as the sum of the max-imum score of a partial segment ending at positionj < i, and the score of skipping from j to i. Theback-pointer table B allows us to reconstruct the se-quence of positions included in the segment.Clearly, this program requires O(n2) time for atext of length n. Furthermore we can easily augmentthis algorithm in the standard fashion to find the kbest segments, and multiple segment types, result-ing in a runtime of O(n2kT ), where T is the numberof types.
O(n2kT ) is not ideal, but is still practicalsince in this work we are segmenting sentences.
Ifwe can bound the largest gap in any non-contiguoussegment by a constant g  n, then the runtime canbe improved to O(ngkT ).
This runtime does notcompare favorably to the standard Viterbi algorithmthat runs in O(nT 2), especially for large k. How-ever, we found that for even large k we could stilltrain large models in a matter of hours and test onunseen data in a few minutes.3.2.1 RestrictionsOften a segmentation task or data set will restrictparticular kinds of segments.
For instance, it may bethe case that a data set does not have any overlap-ping or non-contiguous segments.
Embedded seg-mentations ?
those in which one segment?s tokensare a subset of another?s ?
is also a phenomenon thatsometimes does not occur.It is easy to restrict the inference algorithm to dis-allow such segments if they are unnecessary.
For ex-ample, if two segments overlap or are embedded, theinference algorithm can just return the highest scor-ing one.
Or it can simply ignore all non-contiguoussegments if it is known that they do not occur in thedata.
In Section 4 we will augment the inferencealgorithm accordingly for each data set.3.3 Feature RepresentationWe now discuss the design of the feature functionfor two consecutive segment positions g(j, i), wherej < i.
We build individual binary-valued featuresfrom predicates over the input, for instance, the iden-tities of words in the sentence at particular posi-tions relative to i and j.
The selection of predicatesvaries by task, and we provide specific predicate setsin Section 4 for various data sets.
In this section,we use for illustration word-pair identity predicatessuch as xj = Bill & xi = Clinton.For sequential tagging models, predicates arecombined with the set of states (or tags) to createa feature representation.
For our model, we definethe following possible states:start ?
j = 0end ?
i = n + 1next ?
j = i ?
1skip ?
j < i ?
1For example, the following features would be on forg(0, 3)1 and g(3, 6), respectively, in Figure 3a:xj = -s- & xi = Bill & startxj = Bill & xi = Clinton & skipThese features indicate a predicate?s role in the seg-ment: at the beginning, at the end, over contiguoussegment words or skipping over some words.
Allfeatures can be augmented to indicate specific seg-ment types for multi-type segmentation tasks.
Nomatter what the task, we always add predicates thatrepresent ranges of the distance i?j, as well as whatwords or part-of-speech tags occur between the twowords.
For instance, g(3, 6) might containword-in-between= and & skipThese features are designed to identify commoncharacteristics of non-contiguous segments suchas the presence of conjunctions or punctuation inskipped portions.
Although we have considered onlybinary features here, the model in principle allowsarbitrary real-valued feature.3.4 SummaryWe presented a method for text segmentation thatequates the problem to structured multilabel classi-fication where each label corresponds to a segment.We showed that learning and inference can be man-aged tractably in the formulation by efficiently find-ing the k highest scoring segments through a dy-namic programming algorithm that factors the struc-ture of each segment.
The only concern is that kmust be large enough to include all correct segments,1Note that ?skip?
is not on for g(0, 3) even though j < i?1.Start and end states override other states.991which we will discuss further in Section 4.
Thismethod naturally models all possible segmentationsincluding those with overlapping or non-contiguoussegments.
Out approach can be seen as multilabelvariant of the work of McDonald et al (2004), whichcreates a set of constraints to separate the score ofthe single correct output from the k highest scoringoutputs with an appropriate large margin.4 ExperimentsWe now describe a set of experiments on named en-tity and base NP segmentation.
For these experi-ments, we set k = n, where n is the length of thesentence.
This represents a reasonable upper boundon the number of entities or chunks in a sentence andresults in a time complexity of O(n3T ).We compare our methods with both the averagedperceptron (Collins, 2002) and conditional randomfields (Lafferty et al, 2001) using identical predicatesets.
Though all systems use identical predicates, theactual features of the systems are different due tothe fundamental differences between the multilabelclassification and sequential tagging models.4.1 Standard data setsOur first experiments are standard named entity andbase NP data sets with no overlapping, embedded ornon-contiguous segments.
These experiments willshow that, for simple segmentations, our model iscompetitive with sequential tagging models.For the named entity experiments we used theCoNLL 2003 (Tjong Kim Sang and De Meulder,2003) data with people, organizations, locations andmiscellaneous entities.
We used standard predicatesbased on word, POS and orthographic informationover a previous to next word window.
For the NPchunking experiments we used the standard CoNLL2000 data set (Kudo and Matsumoto, 2001; Sha andPereira, 2003) using the predicate set defined by Shaand Pereira (2003).The first three rows of Table 1 compare the mul-tilabel classification approach to standard sequen-tial classifiers.
As one might expect, the perfor-mance of the multilabel classification method is be-low that of the sequential tagging methods.
This isbecause those methods model contiguous segmentswell without the need for thresholds or k-best infer-ence.
In addition, the multilabel method shows sig-nificantly higher precision then recall.
One possiblereason for this is that during the course of learning,the model will see many segments that are nearlycorrect, e.g., segments that overlap correct segmentsand differ by a single token.
As a result, the modellearns to score all segments containing even a smallamount of negative evidence as invalid in order toensure that these nearly correct segments have a suf-ficiently low score.One way to alleviate this problem is to restrict theinference algorithm to not return any overlapping,non-contiguous or embedded segmentations as dis-cussed in Section 3.2.1, since this data set does notcontain segments of this kind.
This way, the learningstage only updates the parameters when a nearly cor-rect segment actually out scores the correct one.
Theresults of this system are shown in row 4 of Table 1.We can see that this change did lead to a more bal-anced precision/recall, however it is clear that moreinvestigation is required.4.2 Chemical substance extractionThe second set of experiments involves extract-ing chemical substance names from MEDLINE ab-stracts that relevant to the inhibition of the enzymeCYP450 (PennBioIE, 2005).
We focus on abstractsthat have at least one overlapping or non-contiguousannotation.
This data set contains 6164 annotatedchemical substances, including 6% that are bothoverlapping and non-contiguous.
Figure 3b is anexample from the corpus.
We use identical predi-cates to the named entity experiments in Section 4.1.Though the data does contain overlapping and non-contiguous segments, it does not contain embeddedsegments.
Results are shown in Table 2 using 10-fold cross validation.
The sequential tagging modelswere trained using only sentences with no overlap-ping or non-contiguous entities.
We found this pro-vided the best performance.
Row 4 of Table 2 showsthe multilabel approach with the inference algorithmrestricted to not allow embedded segments.We can see that our method does significantly bet-ter on this data set (up to a 26% reduction in er-ror).
It is also apparent that the model is picking upsome overlapping and non-contiguous entities (seeTable 2).
However, the models performance on thesekinds of entities is lower than overall performance.992a.
Named-Entity Extraction b. NP-chunkingPrecision Recall F-measure Precision Recall F-measureAvg.
Perceptron 82.46 83.14 82.80 94.22 93.88 94.05CRFs 83.36 83.57 83.47 94.57 94.00 94.29Multilabel 92.47 74.19 82.33 94.65 92.28 93.45Multilabel with Restrictions 91.08 76.68 83.26 94.10 93.70 93.90Table 1: Results for named-entity extraction and NP-chunking on data sets with only non-overlapping andcontiguous segments annotated.Chem Substance Extraction - A Chem Substance Extraction - BPrecision Recall F-measure Precision Recall F-measureAvg.
Perceptron 82.98 79.40 81.15 1.0 0.0 0.0CRFs 85.85 79.06 82.31 1.0 0.0 0.0Multilabel 88.24 80.84 84.38 62.56 33.67 43.78Multilabel with Restrictions 88.55 84.59 86.53 72.58 45.92 56.25Table 2: Results for chemical substance extraction.
Table A is for all entities in the data set and Table B isonly for those entities that are overlapping and non-contiguous.4.3 Tuning Precision and RecallThe learning algorithm in Section 3.1 seeks a sep-arator through the origin, though, our experimentalresults suggest that this tends to favor precision atthe expense of recall.
However, at test time we canuse a separation threshold different from zero.
Thisparameter allows us to trade off precision against re-call, and could be tuned on held-out data.Figure 5 plots precision, recall and f-measureagainst the threshold for the basic multilabel modelon the chemical substance, NP chunking and personentity extraction data sets.
These plots clearly showwhat is expected: higher thresholds give higher pre-cision, and lower thresholds give higher recall.
Inthese data sets at least, a zero threshold is almostalways near optimal, though sometimes we wouldbenefit from a slightly lower threshold.5 DiscussionWe have presented a method for text segmentationthat is base on discriminatively learning structuredmultilabel classifications.
The benefits include?
Competitive performance with sequential tag-ging models.?
Flexible modeling of complex segmentations,including overlapping, embedded and non-contiguous segments.?
Adjustable precision-recall trade off.However, there is a computation cost for our models.For a text of length n, training and testing requireO(n3T ) time, where T is the number of segmenttypes.
Fortunately, this still results in training timeson the order of hours.Our approach is related to the work of Bockhorstand Craven (2004).
In this work, a conditional ran-dom field model is trained to allow for overlappingsegments with an O(n2) inference algorithm.
Themodel is applied to biological sequence modelingwith promising results.
However, our approachesdiffer in two major respects.
First, their model isprobabilistic, and trained to maximize segmenta-tion likelihood, while our model is trained to max-imize margin.
Second, our method allows for non-contiguous segments, at the cost of a slower O(n3)inference algorithm.In further work, the classification thresholdshould also be learned to achieve the desired balancebetween precision and recall.
It would also be usefulto investigate methods for combining these modelswith standard sequential tagging models to get topperformance on simple segmentations as well as onoverlapping or non-contiguous ones.A broader area of investigation are other problemsin language processing that can benefit from struc-tured multilabel classification, e.g., ambiguities inlanguage often result in multiple acceptable parsesfor sentences.
It may be possible to extend the al-gorithms presented here to learn to distinguish allacceptable parses from unacceptable ones instead ofjust finding a single parse when many are valid.993?1 ?0.8 ?0.6 ?0.4 ?0.2 0 0.2 0.4 0.6 0.8 10.40.50.60.70.80.91CHEM?1 ?0.8 ?0.6 ?0.4 ?0.2 0 0.2 0.4 0.6 0.8 10.70.750.80.850.90.951NP?1 ?0.8 ?0.6 ?0.4 ?0.2 0 0.2 0.4 0.6 0.8 10.40.50.60.70.80.91PERFigure 5: Precision (squares), Recall (circles) and F-measure (line) plotted against threshold values.
CHEM:chemical substance extraction, NP: noun-phrase chunking, and PER: person name extraction.AcknowledgmentsWe thank the members of the Penn BioIE projectfor the development of the CYP450 corpus that weused for our experiments.
In particular, Seth Kulickanswered many questions about the data.
This workhas been supported by the NSF ITR grant 0205448.ReferencesD.M.
Bikel, R. Schwartz, and R.M.
Weischedel.
1999.An algorithm that learns what?s in a name.
MachineLearning Journal Special Issue on Natural LanguageLearning, 34(1/3):221?231.J.
Bockhorst and M. Craven.
2004.
Markov networks fordetecting overlapping elements in sequence data.
InProc.
NIPS.Y.
Censor and S.A. Zenios.
1997.
Parallel optimization :theory, algorithms, and applications.
Oxford Univer-sity Press.M.
Collins.
2002.
Discriminative training methods forhidden Markov models: Theory and experiments withperceptron algorithms.
In Proc.
EMNLP.K.
Crammer and Y.
Singer.
2002.
A new family of onlinealgorithms for category ranking.
In Proc SIGIR.K.
Crammer.
2005.
Online Learning for Complex Cat-egorial Problems.
Ph.D. thesis, Hebrew University ofJerusalem.
to appear.N.
Cristianini and J. Shawe-Taylor.
2000.
An Introduc-tion to Support Vector Machines.
Cambridge Univer-sity Press.M.
Dickinson and W.D.
Meurers.
2005.
Detecting errorsin discontinuous structural annotation.
In Proc.
ACL.A.
Elisseeff and J. Weston.
2001.
A kernel method formulti-labeled classification.
In Proc.
NIPS.T.
Kudo and Y. Matsumoto.
2001.
Chunking with sup-port vector machines.
In Proc.
NAACL.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
ICML.A.
McCallum, D. Freitag, and F. Pereira.
2000.
Maxi-mum entropy Markov models for information extrac-tion and segmentation.
In Proceedings of ICML.R.
McDonald, K. Crammer, and F. Pereira.
2004.
Largemargin online learning algorithms for scalable struc-tured classication.
In NIPS Workshop on StructuredOutputs.PennBioIE.
2005.
Mining The Bibliome Project.http://bioie.ldc.upenn.edu/.L.
R. Rabiner.
1989.
A tutorial on hidden Markov mod-els and selected applications in speech recognition.Proceedings of the IEEE, 77(2):257?285, February.A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In Proc.
EMNLP.R.
E. Schapire and Y.
Singer.
1999.
Improved boostingalgorithms using confidence-rated predictions.
Ma-chine Learning, 37(3):1?40.B.
Scho?lkopf and A. J. Smola.
2002.
Learning with Ker-nels: Support Vector Machines, Regularization, Opti-mization and Beyond.
MIT Press.F.
Sha and F. Pereira.
2003.
Shallow parsing with condi-tional random fields.
In Proc.
HLT-NAACL.B.
Taskar, C. Guestrin, and D. Koller.
2003.
Max-marginMarkov networks.
In Proc.
NIPS.E.
F. Tjong Kim Sang and F. De Meulder.
2003.
Intro-duction to the CoNLL-2003 shared task: Language-independent named entity recognition.
In Proceedingsof CoNLL-2003.http://www.cnts.ua.ac.be/conll2003/ner.994
