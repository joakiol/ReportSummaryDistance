POLYNOMIAL TIME PARSING OF COMBINATORY CATEGORIALGRAMMARS*K. Vijay-ShankerDepartment of CISUniversity of DelawareDelaware, DE 19716David J. WeirDepartment of EECSNorthwestern UniversityEvanston, IL 60208AbstractIn this paper we present a polynomial time pars-ing algorithm for Combinatory Categorial Grammar.The recognition phase extends the CKY algorithm forCFG.
The process of generating a representation ofthe parse trees has two phases.
Initially, a shared for-est is build that encodes the set of all derivation treesfor the input string.
This shared forest is then prunedto remove all spurious ambiguity.1 In t roduct ionCombinatory Categorial Grammar (CCG) \[7, 5\] is anextension of Classical Categorial Grammar in whichboth function composition and function applicationare allowed.
In addition, forward and backwardslashes are used to place conditions on the relativeordering of adjacent categories that are, to be com-bined.
There has been considerable interest in pars-ing strategies for CCG' \[4, 11, 8, 2\].
One of the majorproblems that must be addressed is that of spuriousambiguity.
This refers to the possibility that a CCGcan generate a large number of (exponentially many)derivation trees that assign the same function argu-ment structure to a string.
In \[9\] we noted that a CCGcan also generate xponentially many genuinely am-biguous (non-spurious)derivations.
This constitutesa problem for the approaches cited above since it re-suits in their respective algorithms taking exponentialtime in the worst case.
The algorithm we present isthe first known polynomial time parser for CCG.The parsing process has three phases.
Once therecognizer decides (in the first phase) that an inputcan be generated by the given CCG the set of parse*This work was partially supported by NSF grant IRI-8909810.
We are very grateful to Aravind Joshi, Michael Niv,Mark Steedman and Kent Wittenburg for helpful discussior~.1trees can be extracted in the second phase.
Ratherthan enumerating all parses, in Section 3, we describehow they can be encoded by means of a shared forest(represented as a grammar) with which an expoo en-tial number of parses are encoded using a polynomi-ally bounded structure.
This shared forest encodesall derivations including those that are spuriously am-biguous.
In Section 4.1, we show that it is possible tomodify the shared forest so that it contains no spuri-ous ambiguity.
This is done (in the third phase) bytraversing the forest, examining two levels of nodes ateach stage, detecting spurious ambiguity locally.
Thethree stage process of recognition, building the sharedforest, and eliminating spurious ambiguity takes poly-nomial time.1.1 Def in i t ion  o f  CCGA CCG, G, is denoted by (VT, VN, S, f, R) where VT isa finite set of terminals (lexical items), VN is a finiteset of nonterminals (atomic categories), S is a dis-tinguished member of VN, f is a function that mapselements of VT to finite sets of categories, R is a fi-nite set of combinatory rules.
Combinatory rules havethe following form.
In each of the rules x, y, z l , .
.
,  arevariables and li E {\ , /}.1.
Forward application: z/y  y .--.
z2.
Backward application: y z\y  ~ z3.
Forward composition (for n > 1):~ly yllz112... I.z.
- xllz112.., l~z.4.
Backward composition (for n_> i):yl,z~12...l.=, x\y--* ~I~=~12...I.=~In the above rules, z \[ y is the primary categoryand the other left-hand-side category is the secondarycategory.
Also, we refer so the leftmost nonterminalof a category as the target of the category.
We assumethat categories are parenthesis-free.
The results pre-sented here, however, generalize to the case of fullyparenthesized categories.
The version of CCG usedin \[7, 5\] allows for the possibility that the use of thesecombinatory rules can be restricted.
Such restrictionslimit the possible categories that can inatantiate thevariables.
We do not consider this possibility here,though the results we present can be extended to han-dle these restrictions.Derivations in a CCG involve the use of the com-binatory rules in R. Let ~ be defined as follows,where Tt and T2 are strings of categories and termi-nals and c, cl, c2 are categories.?
If ctc2 ---* c is an instance of a rule in R thenTtcT2 ~ Ttctc2T2.?
If c E f (a) for some a E Vr and category c thenTzcT2 ==~ TtaT2.The string language generated is defined asL(G) -  {w IS =~ w I w e V~ }.1.2 Context -F ree  PathsIn Section 2 we describe a recognition algorithm thatinvolves extending the CKY algorithm for CFG.
Thedifferences between the CKY algorithm and the onepresented here result from the fact that the derivationtree sets of CCG have more complicated path sets thanthe (regular) path sets of CFG tree sets.
Considerthe set of CCG derivation trees of the form shown inFigure 1 for the language {ww t w E {a, b} ?
}.Due to the nature of the combinatory rules, cate-gories behave rather like stacks since their argumentsare manipulated in a last-in-first-out fashion.
This hasthe effect that the paths can exhibit nested ependen-cies as shown in Figure 1.
Informally, we say that CCGtree sets have context-free paths.
Note that the treesets of CFG have regular paths and cannot producesuch tree sets.2 Recognition of CCGThe recognition algorithm uses a 4 dimensional ar-ray L for the input a t .
.
.a , .
In entries of the ar-ray L we cannot store complete categories ince ex-ponentially many categories can derive the substringAIaSBIbStA$|A tBB S IA IB IBb S1AIB/S SINSIA/S SIB/S bI Ia bFigure 1: Trees with context-free pathsa i .
.
.
aj I it is necessary to store categories carefullyIt is possible, however, to share parts of categories b~tween different entries in L. This follows from the fac'that the use of a combinatory rule depends only on(1) the target category of the primary category of th~rule; (2) the first argument (sufrLx of length 1) of th~primary category of the rule;(3) the entire (boundedsecondary category.
Therefore, we need only find thi:(bounded) information in each array entry in ordelto determine whether a rule can be used.
Entries othe form ((A, a), T) are stored in L\[i, j\]\[p, q\].
This encodes all categories whose target is A, suffix ~, amthat derive the ai ... aj.
The tail T and the indices jand q are used to locate the remaining part of thes~categories.
Before describing precisely the informatiorthat is stored in L we give some definitions.If ~ E ({\,/}VN)" then \[a\[ = n. Given a CCG,G = (VT, VN,S , f ,R )  let kt be the largest n suchthat R contains a rule whose secondary category isylzzzl2.
.
.
InZn and let k2 be the maximum of kl andall n where there is some c E f(a) such that c = Asand \]o~ I = n.In considering how categories that are derived inthe course of a derivation should be stored we havetwo  cases.1.
Categories that are either introduced by lexical1 This is possible since the length of the category can be linearwith respect to j - i.
Since previous approaches to CCG parsin~store entire categories they can take exponential time.items appearing in the input string or whose lengthis less that kt and could therefore be secondary cat-egories of a rule.
Thus all categories whose length isbound by k~ are encoded in their entirety within a sin-gle array entry.2.
All other categories are encoded with a sharingmechanism in which we store up to kt arguments lo-cally together with an indication of where the remain-ing arguments can be found.Next, we give a proposition that characterizes whenan entry is included in the array by the algorithm.An entry (A, a), T) E L\[i, j\]~>, q\] where A E VN anda ~ ({\,/}VN)* when one of the following holds.If T = 7 then 7 e {\, I}VN, 1 < I~l < kx, and forsome a' ~ ({\,/}VN)* the following hold(1) Aa'ct "';~ h i .
.
.%- tAa 'Taq+t  .
.
.a j .
(2) An'7 ~ ap .
.
.%.
(3) Informally, the category An'7 in (1) above is "de-rived" from Aatc~ such that there is no interveningpoint in the derivation before reaching An7 at whichthe all of the suffix a of Aa~a has been "popped"?Alternatively, i fT  = - then 0 <: \[a I < kt +k2,(p, q) = (0, 0) and Ac~ =~=t, al .
.
.a~.
Note that wehave In\[ < kl + k2 rather than \[M <_ k~ (as mighthave been expected from the discussion above).
Thisis the case because a category whose length is strictlyless than k2, can, as a result of function composition,result in a category of length < kl + k~.
Given theway that we have designed the algorithm below, thelatter category is stored in this (non-sharing) form.2.1 A lgor i thmIf c E f(ai) for some category c, such that c - An,then include the tuple ((A, a ) , - )  in L\[i, i\]\[0, \].For some i and j, l < i < j <_ n consider each rulex/~ ~ltzt.. .
I,~z,, ~ xl lzt .
.
,  l.,z., 2.For some k, i < k < j, we look for some ((B, B), - )  EL\[k+l,j\]\[O,O\], where IN - m, (corresponding tothe secondary cate$ory of the rule) and we look for((A, a /B) ,  T) E L\[i, k\]\[p, q\] for some a, T, p and q(corresponding to the primary category of the rule).From these entries in L we know that for somec~' Aa%/B =~ a i .
.
.ak  and B/3 =~ ak+1...a~.2Backward composition and application are treated in thesame way as this rule, except that all occurrences below of iand k are swapped with occurrences of k+ 1 and j,  respectively.Thus, by the combinatory rule given above we haveAsia/3 ~ h i .
.
.a j  and we should store and encod-ing of the category Acgaf?
in L\[i, j\].
This encodingdepends on cd, a, fl, and T,If \ [~\[  < kl + k2 then (case la)  add ((A, aft), - )  toL\[i, j\]\[0, 0\].
Otherwise, (case lb)  add ((A, ),/B) to~\[i,/\]\[i, k\].
*T~-  andre> 1The new category is longer than the one found inL\[i, k\]\[p, q\].
If a ?
e then (case 2a) add ((A, ), IS )to L\[i, Jill, k\], otherwise (case 2b) add ((A, ~),T) toL\[i, j\] \[p, q\].
*T~-  andrn= 1 (case 3)The new category has the same length as the one foundin L\[i, k\]~, q\].
Add ((A, ~/) ,  T) to L\[i, j\]~, q\]..T----7 ~-  and m----OThe new category has the a length one less than theone found in L\[i, k\]~, q\].
If a ~ e then (case 4a)add ((A, a), T) to.
L\[i, j\]\[p, q\].
Otherwise, (case 4b)since a = ?
we have to look for part of the categorythat is not stored locally in L\[i, k\]~, q\].
This may befound by looking in each entry Lip, q\]\[r, s\] for each((A, ~'7), T').
We know that either T' = - or fl' ?
eand add ((A, ~'), T') to L\[i, jilt, s\].
Note that for somea", Aa'l~17 ~ a v. .aq, Aa"/3' /B a~ .ak,and thus by the combinatory rule above Au'~ ~ =~al ?
?
?
a t ?As in the case of CKY algorithm we should haveloop statements hat allow i, j to range from 1 throughn such that the length of the spanned substring startsfrom 1 (i - j) and increases to n (i = 1 and j --- n).When we consider placing entries in L\[i,j\] (i.e., todetect whether a category derives a i ?
.
.a i )  we haveto consider whether there are two subconstituents ( osimplify the discussion let us consider only forwardcombinations) which span the substrings ai .. ?
ak andak+l .
.
.a j .
Therefore we need to consider all valuesfor k between i through j - 1 and consider the entriesin L\[i,k\]~,q\] and L\ [k+ 1,j\]\[0, \] where i ~ p _< q < ko rp=q=0.The above algorithm can be shown to run in timeO(n 7) where n is the length of the input.
In case 4b.we have to consider all possible values for r, s betweenp and q.
The complexity of this case dominates thecomplexity of the algorithm since the other cases doinvolve fewer variables (i.e., r and s are not involved).Case 4b takes time O((q - p)2) and with the loops fori, j, k, p, q ranging from 1 through n the time complex-ity of the algorithm is O(n't).However, this algorithm can be improved to obtaina time complexity of O(n s) by using the same methodemployed in \[9\].
This improvement is achieved bymoving part of case 4b outside of the k loop, sincelooking for ((A, f f /7 ' ) ,  T~) in LIp, q\]\[r, s\] need not bedone within the k loop.
The details of the improvedmethod may be found in \[9\] where parsing of LinearIndexed Grammar (LIG) was considered.
Note thatO(n s) (which we achieve with the improved method)is the best known result for parsing Tree AdjoiningGrammars, which generates the same class of lan-guages generated by CCG and LIG.A\[.-a\] --.
A, \[a,\]... A,x \[a,-a \]A,\[../~\] A,+I \[ai+l\]... A,\[an\]A\[a\] "~ aThe first form of production is interpreted as: if anonterminal A is associated with some stack with thesequence cr on top (denoted \[-.c~\]), it can be rewrittensuch that the i th child inherits this stack with ~ re-placing a.
The remaining children inherit the boundedstacks given in the production.The second form of production indicates that if a non-terminal A has a stack containing a sequence a thenit can be rewritten to a terminal symbol a.The language generated by a LIG is the set of stringsderived from the start symbol with an empty stack.3 Recover ing  Al l  ParsesAt this stage, rather than enumerating all the parses,we will encode these parses by means of a shared foreststructure.
The encoding of the set of all parses must beconcise nough so that even an exponential number ofparses can be represented by a polynomial sized sharedforest.
Note that this is not achieved by any previouslypresented shared forest presentation for CCG \[8\].3.1 Representing the Shared ForestRecently, there has been considerable interest in theuse of shared forests to represent ambiguous parsesin natural language processing \[1, 8\].
Following Bil-lot and Lang \[1\], we use grammars as a representa-tion scheme for shared forests.
In our case, the gram-mars we produce may also be viewed as acyclic and-orgraphs which is the more standard representation usedfor shared forests.The grammatical formalism we use for the repre-sentation of shared forest is Linear Indexed Grammar(LIG) a.
Like Indexed Grammars (IG), in a LIG stackscontaining indices are associated with nonterminals,with the top of the stack being used to determine theset of productions that can be applied.
Briefly, wedefine LIG as follows.If a is a sequence of indices and 7 is an index, weuse the notation A\[c~7\] to represent the case where astack is associated with a nonterminal A having -y ontop with the remaining stack being the c~.
We use thefollowing forms of productions.aIt has been shown in \[I0, 3\] that LIG and CCG generatethe same class of languages.3.2 Building the Shared ForestWe start building the shared forest after the recognizerhas completed the array L and decided that a giveninput al ... an is well-formed.
In recovering the parses,having established that some ~ is in an element of L,we search other elements of L to find two categoriesthat combine to give a.
Since categories behave likestacks the use of CFG for the representation f the setof parse trees is not suitable.
For our purposes the LIGformalism is appropriate since it involves stacks andproduction describing how a stack can be decomposedbased on only its top and bottom elements.We refer to the LIG representing the shared forestas Gsl.
The set of indices used in Ga!
have the form(A, a, i, j).
The terminals used in Gs/ are names forthe combinatory rule or the lexical assignment used(thus derived terminal strings encode derivations inG).
For example, the terminal Fm indicates the useof the forward composition rule z/y yllzII2... ImZmand (c, a) indicates the lexical assignment, c to thesymbol a.
We use one nonterminal, P.An input a l .
.
.an  is accepted if it is the case that((S, e), - )  6 L\[1, n\]\[0, \].
We start by marking thisentry.
By marking an entry ((A, c~), T) e L\[i, j\]~, q\]we are predicting that there is some derivation tree,rooted with the category S and spanning the inputal .
.
.a , ,  in which a category represented by this en-try will participate.
Therefore at some point we willhave to consider this entry and build a shared forestto represent all derivations from this category.Since we start from ((S, e ) , - )  E L\[1, hi\[0, 0\] andproceed to build a (representation f) derivation treesin a top down fashion we will have loop statementsthat vary the substring spanned (a~.. .aj)  from thelargest possible (i.e., i = 1 and j = n) to the smallest(i.e., i = j).
Within these loop statements he algo-rithm (with some particular values for i and j) willconsider marked entries, say ( (A, ct), T) E L\[i, j\]~, q\](where i < p < q < j or p = q = 0), and will buildrepresentations of all derivations from the category(specified by the marked entry) such that the inputspanned is a i .
.
.a j .
Since ((A, ~), T) is a representa-tion of possibly more than one category, several casesarise depending on ot and T. All these cases try to un-cover the reasons why the recognizer placed thin entryin L\[i, j\]~, q\].
Hence the cases considered here are in-verses of the cases considered in the recognition phase(and noted in the algorithm given below).Mark ((S, e), - )  in L\[1, n\]\[0, \].By varying i from 1 to n, j from n to i and for all ap-propriate values of p and q if there is a marked entry,say ((d, a), T) ~ L\[i,j\]~p, q\] then do the following.?
Type I Production ( inverse of  la ,  3, and 4a)If for some k such that i _ k < j, some a, 13 suchthat ~' = a/3, and B E VN we have ((A, a/B),  T) EL\[i, k\]\[p, q\] and ((B,/3), - )  E L\[k + 1, j\]\[0, 0\] then letp be the productionP\[..(A, a', i, j)\] -..* F,, P\[..(A, a/B, i, k)\] P\[(B, B, k + 1, j)\]where m = \[/31.
If p is not already present in G?!
thenadd p and mark ((A, a/B),  T) e L\[i, k\]~,, q\] as well as((B, /3) , - )  e L\[k + i, j\]\[0, 01.?
Type $ Production ( inverse of  lb  and 2a)If for some k such that i < k < j, and a ,B ,T ' , r , s ,kwe have ( (A ,a/B) ,T ' )  E L\[i,k\]\[r,s\] where (p,q) =(i, k), ((B, ~'), - )  e L\[k + 1, j\]\[0, 0\], T =/B ,  and thelengths of a and a' meet the requirements on the cor-responding strings in case lb and 2a of the recognitionalgorithm then then let p be the productionP\[..(A, a/B,  i, k)(A, a', i, 1)\] --F,,, P\[..(A, or~B, i, k)\] P\[(B, a', k + 1, j)\]where m = la'l.
If p is not already present in G?
!then add p and mark ((A, a/B) ,  T') e L\[i, k\]\[r, s\] and((B, ~'), - )  e L\[k + 1,1\]\[0, \].?
Type 3 Production ( inverse of  2b)If for some k such that i < k < j, and some Bit is the case that ((A,/B),  T) 6 L\[i, l:\]\[p, q\] and((B, ~ ' ) , - )  E L\[k + 1, j\]\[0, 0\] where \]a'\] > 1 then thenlet p be the productionP\[.-(A, a', i, 1)\] --.
E,, P\[..(A,/B, i, k)\] P\[(B, a', k + 1, j)\]where m = Intl.
If p is not already present in G,Ithen add p and mark ((A, /B) ,T)  6 L\[i, k\]~, q\] and((S, ~'), - )  e L\[k + 1, j\]\[0, 0\].?
Type 4 Production ( inverse of  4b)If for some h such that i < k < j, and someB,~',r,8,~, we and ((A, IB,),~') ~ L\[i,k\]\[r,~\],((A, a'7'), T) E L\[r,s\]~,q\], and ( (B,e) , - )  6L\[k + 1, j\]\[0, 0\] then then let p be the productionP\[..(A, ~', i, j)\] --Fo P\[..(A, ~'v', , ,)(A,/B, i, k)\] P\[(B, , k + 1, j)\]If p is not already present in G,!
then add p andmark ((A,/B), 7') E L\[i, k\]\[r, s\] and ((B, e), - )  6L\[k + 1, j\]\[0, 0\].
* Type 5 ProductionIf j = i, then it must be the case that T = - and thereis a lexical assignment assigning the category As / tothe input symbol given by at.
Therefore, if it has notalready been included, output the productionP\[(a, ~', i, i)\] - (A~, a,)The number of terminals and nonterminals in thegrammar is bounded by a constant.
The number of in-dices and the number of productions in G,!
are O(nS).Hence the shared forest representation we build ispolynomial with respect o the length of the input, n,despite the fact that the number of derivations treescould be exponential.We will now informally argue that G,!
can be builtin time O(nZ).
Suppose an entry ((A, a'), T) is inL\[i,j\]~,q\] indicating that for some /3 the categoryA/3c~' dominates the substring a l .
.
.a j .
The methodoutlined above will build a shared forest structure torepresent all such derivations.
In particular, we willstart by considering a production whose left hand sideis given by P\[..(A, ~', i, j)\].
It is clear that an intro-duction of production of type 4 dominates the timecomplexity since this case involves three other vari-ables (over input positions), i.e., r, sl k; whereas theintroduction of other types of production involve onlyone new variable k. Since we have to consider all pos-sible values for r, s, k within the range i through j, thisstep will take O((j - 0 3) time.
With the outer loopsfor i, j, p, and q allowing these indices to range from 1through n, the time taken by the algorithm is O(n7).Since the algorithm given here for building theshared forest simply finds the inverses of moves madein the recognition phase we could have modified therecognition algorithm so as to output appropriate G,!productions during the process of recognition withoutaltering the asymptotic omplexity of the recognizer.However this will cause the introduction of useless pro-ductions, i.e., those that describe subderivations whichdo not partake in any derivation from the category Sspanning the entire input string al ... a,.54 Spur ious  Ambigu i tyWe say that a given CCG, G, exhibits spurious am-biguity if there are two distinct derivation trees fora string w that assign the same function argumentstructure.
Two well-known sources of such ambiguityin CCG result from type raising and the associativityof composition.
Much attention has been given to thelatter form of spurious ambiguity and this is the onethat we will focus on in this paper.To illustrate the problem, consider the followingstring of categories.At!A2 A2/Aa .. .
An-z /AnAny pair of adjacent categories can be combined usinga composition rule.
The number of such derivationsis given by the Catalan series and is therefore xpo-nential in n. We return a single representative of theclass of equivalent derivation trees (arbitrarily chosento be the right branching tree in the later discussion).4 .1 Dea l ing  w i th  Spur ious  Ambigu i tyWe have discussed how the shared forest representa-tion, Gsl, is built from the contents of array L. Therecognition algorithm does not consider whether someof the derivations built are spuriously equivalent andthis is reflected in G,I.
We show how productions ofG,!
can be marked to eliminate spuriously ambigu-ous derivations.
Let us call this new grammar Gnu.As stated earlier, we are only interested in detectingspuriously equivalent derivations arising from the as-sociativity of composition.
Consider the example in-volving spurious ambiguity shown in Figure 2.
Thisexample illustrates the general form of spurious am-biguity (due to associativity of composition) in thederivation of a string made up of contiguous substringsai~ .
.
.a  h,  a~ ...aj2, and ai~ ...aj8 resulting in a cat-egory Az alot2a3.
For the sake of simplicity we assumethat each combination indicated is a forward combi-nation and hence i2 = j l  + 1 and i3 = J2 + 1.Each of the 4 combinations that occur in the abovefigure arises due to the use of a combinatory rule, andhence will be specified in G,!
by a production.
Forexample, it is possible for combination 1 to be repre-sented by the following type I production.P\[..( At , ot' ot2 /A3, il , j2)\] -~F,,, P\[..( Ax, ot' /A2, i, ,jx)\] P\[(A2, a2, i2, j2 )\]where i2 = jz + 1, ~' is a suffix of az of length less thanA a a a?
1 1 2 3A 1 % ~A a /A  A a /A  A a1 1 2 2 2 3 3 3a a a a a ai l  j l  i2 12 i3 j31 1 2 3A a /A A a /A  A a11 2 22  3 33a a a a a ai l  j l  i2 j2 13 j3Figure 2: Example of spurious ambiguitykl, and m = la2\[.
Since Aloq/A3 and Aaa3 are usedas secondary categories, their lengths are bounded bykl + 1.
Hence these categories will appear in their en-tirety in their representations in the G,!
productions.The four combinations 4 will hence be represented inG,!
by the productions:Combination 1: P\[..(A1, a'ot2/Aa, il, j2)\] --*Combination 2: P\[..(Aa, a'a~cra, ia, ja)\] "-*F,, P\[..(At, a'a2/A~, it, jr )\] P\[(A,, a3, j~ + 1, j, )\]Combination 3: P\["(A2, ot~ota,ja + 1,ja)\] --*F,, P\[..(A2, ot2/Aa, jx + 1, j2)\] P\[(Aa, ot,, j2 + 1,3'3)\]Combination 4: P\[.-(Ax, a'a2a,, il, j3)\] --*Fna P\["(Ax, ct'/A2, Q,/x)\] P\[(A2, a2c~3, ja + 1, j3)\]where.
,  = = and =4We consider the case where each combination is representedby a Type 1 production.These productions give us sufficient information to de-tect spurious ambiguity locally, i.e., the local left andright branching derivations.
Suppose we choose to re-tain the right branching derivations only.
We are nolonger interested in combination 2.
Therefore we markthe production corresponding to this combination.This production is not discarded at this stage be-cause although it is marked it might still be useful indetecting more spurious ambiguity.
Notice in Figure 3A Q a ~ aI 2 3A a a ~A a /A A a IA A a IA A a1 1 I 2 22  3 33a a a a a a a aio jO i i  Jl i2 j2 i3 j3t 2 3Aa/A  Aaa lA  Aa  I 112  3 33a a 8 a a aI0 iO I I  12 13 j3Figure 3: Reconsidering a marked productionthat the subtree obtained from considering combina-tion 5 and combination 1 is right branching whereasthe entire derivation is not.
Since we are looking forthe presence of spurious ambiguity locally (i.e., by con-sidering two step derivations) in order to mark thisderivation we can only compare it with the derivationwhere combination 7 combines Aa/A1 with Ala la2a3(the result of combination 2) s. Notice we would havealready marked the production corresponding to com-bination 2.
If this production had been discarded thenthe required comparison could not have been madeand the production due to combination 6 can not havebeen marked.
At the end of the marking process allmarked productions can be discarded 6 .In the procedure to build the grammar Gn8 we startwith the productions for lexical assignments (type 5).By varying il from n to 1, jz from i + 2 to n, i~ fromj3 to il + 1, and i3 from i.~ + 1 to j3 we look for agroup of four productions (as discussed above) thatlocally indicates the the presence of spurious ambigu-ity.
Productions involved in derivations that are notright branching are marked.It can be shown that this local marking of spuri-ous derivations will eliminate all and only the spuri-ously ambiguous derivations.
That is, enumerating allderivations using unmarked productions, will give alland only genuine derivations.
If there are two deriva-tions that are spuriously ambiguous (due to the as-sociativity of composition) then in these derivationsthere must be at least one occurrence of subderiva-tions of the nature depicted in Figure 3.
This willresult in the marking of appropriate productions andhence the spurious ambiguity will be detected.
Byinduction it is also possible to show that only the spu-riously ambiguous derivations will be detected by themarking process outlined above.5 Conclusions?
Several parsing strategies for CCG have been givenrecently (e.g., \[4, 11, 2, 8\]).
These approaches haveconcentrated on coping with ambiguity in CCG deriva-tions.
Unfortunately these parsers can take exponen-tial time.
They do not take into account the fact thatcategories spanning a substring of the input could beof a length that is linearly proportional to the lengthof the input spanned and hence exponential in num-ber.
We adopt a new strategy that runs in polynomialtime.
We take advantage of the fact that regardlessof the length of the category only a bounded amountof information (at the beginning and end of the cate-5Although this category is also the result of combination 4,the tree with combinations 5 and 6 can not be compared withthe tree having the combinations 7 and 4.6Steedman \[6\] has noted that although all multiple deriva-tions arising due to the so-called spurious amb;~ty  yield thesame "semantics" they need not be considered useless.7gory) is used in determining when a combinatory rulecan apply.We have also given an algorithm that builds ashared forest encoding the set of all derivations fora given input.
Previous work on the use of sharedforest structures \[1\] has focussed on those appropri-ate for context-free grammars (whose derivation treeshave regular path sets).
Due to the nature of the CCGderivation process and the degree of ambiguity possi-ble this form of shared forest structures i not appro-priate for CCG.
We have proposed a shared forestrepresentation that is useful for CCG and other for-malLsms (such as Tree Adjoining Grammars) used incomputational linguistics that share the property ofproducing trees with context free paths.Finally, we show the shared forest can be markedso that during the process of enumerating all parseswe do not list two derivations that are spuriously am-biguous.
In order to be able to eliminate spuriousambiguity problem in polynomial time, we examinetwo step derivations to locally identify when they areequivalent rather than looking at the entire derivationtrees.
This method was first considered by \[2\] wherethis strategy was applied in the recognition phase.The present algorithm removes purious ambiguityin a separate phase after recognition has been com-pleted.
This is a reasonable approach when a CKY-style recognition algorithm is being used (since the de-gree of ambiguity has no effect on recognition time).However, if a predictive (e.g., Earley-style) parser wereemployed then it would be advantageous to detectspurious ambiguity during the recognition phase.
Ina predictive parser the performance on an ambigu-ous input may be inferior to that on an unambiguousone.
Due to the spurious ambiguity problem in CCG,even without genuine ambiguity, the purser's perfor-mance be poor if spurious ambiguity was not detectedduring recognition.
CKY-style parsers are closely re-lated to predictive parsers such as Earley's.
There-fore, we believe that the techniques presented here,i.e., (1) the sharing of stacks used in recognition and inthe shared forest representation a d (2) the local iden-tification of spurious ambiguity (first proposed by \[2\])can be adapted for use in more practical predictivealgorithms.\[2\]\[3\]\[5\]\[6\]\[7\]\[8\]C9\]\[i0\]\[11\]soc.
Comput Ling., 1989.M.
Hepple and G. Morrill.
Parsing and deriva-tional equivalence.
In European Assoc.
Comput.Ling., 1989.A.
K. Joshi, K. Vijay-Shanker, and D. J.Weir.
The convergence of mildly context-sensitivegrammar formalisms.
In T. Wasow and P. Sells,editors, The Processing of Linguistic Structure.MIT Press, 1989.R.
Pareschi and M. J. Steedman.
A lazy wayto chart-parse with categorial grammars.
In 25 ~hmeeting Assoc.
Comput.
Ling., 1987.M.
Steedman.
Combinators and grammars.
In1~.
Oehrle, E. Bach, and D. Wheeler, editors, Cat-egorial Grammars and Natural Language Struc-tures.
Foris, Dordrecht, 1986.M.
Steedman.
Parsing spoken language usingcombinatory grammars.
: In International Work-shop of Parsing Technologies, Pittsburgh, PA,1989.M.
J. Steedman.
Dependency and coordinationin the grammar of Dutch and English.
Language,61:523-568, 1985.M.
Toraita.
Graph-structured stack and naturallanguage parsing.
In 26 th meeting Assoc.
Corn-put.
Ling., 1988.K.
Vijay-Shanker and D. J. Weir.
The recognitionof Combinatory Categorial Grammars, Linear In-dexed Grammars, and Tree Adjoining Grammars.In International Workshop of Parsing Technolo-gies~ Pittsburgh, PA, 1989.D.
J. Weir and A. K. Joshi.
Combinatory cate-gorial grammars: Generative power and relation-ship to linear context-free r writing systems.
In26 th meeting Assoc.
Comput.
Ling., 1988.K.
B. Wittenburg.
Predictive combinators: amethod for efficient processing of combinatorycategorial grammar.
In 25 th meeting Assoc.
Corn-put.
Ling., 1987.References\[1\] S. Billot and B. Lang.
The structure of sharedforests in ambiguous parsing.
In 27 ~h meeting As-8
