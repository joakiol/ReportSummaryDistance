Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 392?399,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsTranslation Model Adaptation by ResamplingKashif Shah, Lo?
?c Barrault, Holger SchwenkLIUM, University of Le MansLe Mans, France.FirstName.LastName@lium.univ-lemans.frAbstractThe translation model of statistical ma-chine translation systems is trained on par-allel data coming from various sources anddomains.
These corpora are usually con-catenated, word alignments are calculatedand phrases are extracted.
This meansthat the corpora are not weighted accord-ing to their importance to the domain ofthe translation task.
This is in contrastto the training of the language model forwhich well known techniques are used toweight the various sources of texts.
Ona smaller granularity, the automatic cal-culated word alignments differ in quality.This is usually not considered when ex-tracting phrases either.In this paper we propose a method to auto-matically weight the different corpora andalignments.
This is achieved with a resam-pling technique.
We report experimen-tal results for a small (IWSLT) and large(NIST) Arabic/English translation tasks.In both cases, significant improvements inthe BLEU score were observed.1 IntroductionTwo types of resources are needed to train statis-tical machine translation (SMT) systems: parallelcorpora to train the translation model and mono-lingual texts in the target language to build thelanguage model.
The performance of both mod-els depends of course on the quality and quantityof the available resources.Today, most SMT systems are generic, i.e.
thesame system is used to translate texts of all kinds.Therefore, it is the domain of the training re-sources that influences the translations that are se-lected among several choices.
While monolingualtexts are in general easily available in many do-mains, the freely available parallel texts mainlycome from international organisations, like theEuropean Union or the United Nations.
Thesetexts, written in particular jargon, are usuallymuch larger than in-domain bitexts.
As an exam-ple we can cite the development of an NIST Ara-bic/English phrase-based translation system.
Thecurrent NIST test sets are composed of a newswire part and a second part of web-style texts.For both domains, there is only a small numberof in-domain bitexts available, in comparison toalmost 200 millions words of out-of-domain UNtexts.
The later corpus is therefore likely to domi-nate the estimation of the probability distributionsof the translation model.It is common practice to use a mixture languagemodel with coefficients that are optimized on thedevelopment data, i.e.
by these means on the do-main of the translation task.
Domain adaptationseems to be more tricky for the translation modeland it seems that very little research has been donethat seeks to apply similar ideas to the translationmodel.
To the best of our knowledge, there is nocommonly accepted method to weight the bitextscoming from different sources so that the transla-tion model is best optimized to the domain of thetask.
Mixture models are possible when only twodifferent bitexts are available, but are rarely usedfor more corpora (see discussion in the next sec-tion).In this work we propose a new method to adaptthe translation model of an SMT system.
We onlyperform experiments with phrase-based systems,but the method is generic and could be easily ap-plied to an hierarchical or syntax-based system.We first associate a weighting coefficient to eachbitext.
The main idea is to use resampling to pro-duce a new collection of weighted alignment files,followed by the standard procedure to extract thephrases.
In a second step, we also consider the392alignment score of each parallel sentence pair, em-phasizing by these means good alignments anddown-weighting less reliable ones.
All the param-eters of our procedure are automatically tuned byoptimizing the BLEU score on the developmentdata.The paper is organized as follows.
The nextsection describes related work on weighting thecorpora and model adaptation.
Section 3 de-scribes the architecture allowing to resample andto weight the bitexts.
Experimental results are pre-sented in section 4 and the paper concludes with adiscussion.2 Related WorkAdaptation of SMT systems is a topic of in-creasing interest since few years.
In previouswork, adaptation is done by using mixture mod-els, by exploiting comparable corpora and by self-enhancement of translation models.Mixture models were used to optimize the co-efficients to the adaptation domain.
(Civera andJuan, 2007) proposed a model that can be usedto generate topic-dependent alignments by exten-sion of the HMM alignment model and derivationof Viterbi alignments.
(Zhao et al, 2004) con-structed specific language models by using ma-chine translation output as queries to extract sim-ilar sentences from large monolingual corpora.
(Foster and Kuhn, 2007) applied a mixture modelapproach to adapt the system to a new domain byusing weights that depend on text distances to mix-ture components.
The training corpus was dividedinto different components, a model was trained oneach part and then weighted appropriately for thegiven context.
(Koehn and Schroeder, 2007) usedtwo language models and two translation models:one in-domain and other out-of-domain to adaptthe system.
Two decoding paths were used totranslate the text.Comparable corpora are exploited to find addi-tional parallel texts.
Information retrieval tech-niques are used to identify candidate sentences(Hildebrand et al, 2005).
(Snover et al, 2008)used cross-lingual information retrieval to findtexts in the target language that are related to thedomain of the source texts.A self-enhancing approach was applied by(Ueffing, 2006) to filter the translations of thetest set with the help of a confidence score andto use reliable alignments to train an additionalphrase table.
This additional table was used withthe existing generic phrase table.
(Ueffing, 2007)further refined this approach by using transduc-tive semi-supervised methods for effective use ofmonolingual data from the source text.
(Chen etal., 2008) performed domain adaptation simulta-neously for the translation, language and reorder-ing model by learning posterior knowledge fromN-best hypothesis.
A related approach was in-vestigated in (Schwenk, 2008) and (Schwenk andSenellart, 2009) in which lightly supervised train-ing was used.
An SMT system was used to trans-late large collections of monolingual texts, whichwere then filtered and added to the training data.
(Matsoukas et al, 2009) propose to weight eachsentence in the training bitext by optimizing a dis-criminative function on a given tuning set.
Sen-tence level features were extracted to estimate theweights that are relevant to the given task.
Thencertain parts of the training bitexts were down-weighted to optimize an objective function on thedevelopment data.
This can lead to parameterover-fitting if the function that maps sentence fea-tures to weights is complex.The technique proposed in this paper is some-how related to the above approach of weightingthe texts.
Our method does not require an ex-plicit specification of the in-domain and out-of-domain training data.
The weights of the corporaare directly optimized on the development data us-ing a numerical method, similar to the techniquesused in the standard minimum error training of theweights of the feature functions in the log-linearcriterion.
All the alignments of the bitexts are re-sampled and given equal chance to be selected andtherefore, influence the translation model in a dif-ferent way.
Our proposed technique does not re-quire the calculation of extra sentence level fea-tures, however, it may use the alignments score as-sociated with each aligned sentence pair as a con-fidence score.3 Description of the algorithmThe architecture of the algorithm is summarized infigure 1.
The starting point is an (arbitrary) num-ber of parallel corpora.
We first concatenate thesebitexts and perform word alignments in both direc-tions using GIZA++.
This is done on the concate-nated bitexts since GIZA++ may perform badlyif some of the individual bitexts are rather small.Next, the alignments are separated in parts corre-393Figure 1: Architecture of SMT Weighting Systemsponding to the individual bitexts and a weightingcoefficient is associated to each one.
We are notaware of a procedure to calculate these coefficientsin an easy and fast way without building an actualSMT system.
Note that there is an EM procedureto do this for language modeling.In the next section, we will experimentally com-pare equal coefficients, coefficients set to the samevalues than those obtained when building an inter-polated language model on the source language,and a new method to determine the coefficients byoptimizing the BLEU score on the developmentdata.One could imagine to directly use these coef-ficients when calculating the various probabilitiesof the extracted phrases.
In this work, we proposea different procedure that makes no assumptionson how the phrases are extracted and probabilitiesare calculated.
The idea is to resample alignmentsfrom the alignment file corresponding to the indi-vidual bitexts according to their weighting coeffi-cients.
By these means, we create a new, poten-tially larger alignment file, which then in turn willbe used by the standard phrase extraction proce-dure.3.1 Resampling the alignmentsIn statistics, resampling is based upon repeatedsampling within the same sample until a sampleis obtained which better represents a given dataset (Yu, 2003).
Resampling is used for validatingmodels on given data set by using random subsets.It overcomes the limitations to make assumptionsabout the distribution of the data.
Usually resam-pling is done several times to better estimate andselect the samples which better represents the tar-get data set.
The more often we resample, thecloser we get to the true probability distribution.In our case we performed resampling with re-placement according to the following algorithm:Algorithm 1 Resampling1: for i = 0 to required size do2: Select any alignment randomly3: Alscore ?
normalized alignment score4: Threshold?
rand[0, 1]5: if Alscore > Threshold then6: keep it7: end if8: end forLet us call resampling factor, the number oftimes resampling should be done.
An interestingquestion is to determine the optimal value of thisresampling factor.It actually depends upon the task or data we areexperimenting on.
We may start with one timeresampling and could stop when results becomesstable.
Figure 2 plots a typical curve of the BLEUscore as a function of the number of times we re-sample.
It can be observed that the curve is grow-ing proportionally to the resampling factor until itbecomes stable after a certain point.3.2 Weighting SchemesWe concentrated on translation model adaptationwhen the bitexts are heterogeneous, e.g.
in-domain and out-of-domain or of different sizes.
Inthis case, weighting these bitexts seems interest-ing and can be used in order to select data whichbetter represent the target domain.
Secondly whensentences are aligned, some alignments are reli-able and some are less.
Using unreliable align-ments can put negative effect on the translationquality.
So we need to exclude or down-weight3945252.55353.55454.55555.5560  5  10  15  20BLEUResampling factordevtestbaseline(test)Figure 2: The curve shows that by increasing theresampling factor we get better and stable resultson Dev and Test.unreliable alignments and keep or up-weight thegood ones.
We conceptually divided the weight-ing in two parts that is (i) weighting the corporaand (ii) weighting the alignments3.2.1 Weighting CorporaWe started to resample the bitexts with equalweights to see the effect of resampling.
This givesequal importance to each bitext without taking intoaccount the domain of the text to be translated.However, it should be better to give appropriateweights according to a given domain as shown inequation 1?1bitext1 + ?2bitext2 + ..+ ?nbitextn (1)where the ?n are the coefficients to optimize.One important question is how to find out the ap-propriate coefficient for each corpus.
We investi-gated a technique similar to the algorithm used tominimize the perplexity of an interpolated targetLM.
Alternatively, it is also possible to construct ainterpolated language model on the source side ofbitexts.
This approach was implemented and thesecoefficients were used as the weights for each bi-text.
One can certainly ask the question whetherthe perplexity is a good criterion for weighting bi-texts.
Therefore, we worked on direct optimiza-tion of these coefficients by CONDOR (Berghenand Bersini, 2005).
This freely available tool is anumerical optimizer based on Powell?s UOBYQAalgorithm (Powell, 1994).
The aim of CONDORis to minimize a objective function using the leastnumber of function evaluations.
Formally, it isused to find x?
?
Rn with given constraints whichsatisfiesF (x?)
= minxF (x) (2)where n is the dimension of search space and x?is the optimum of x.
The following algorithm wasused to weight the bitexts.Algorithm 2 WeightingCorpora1: Determine word to word alignment withGIZA++ on concatenated bitext.2: while Not converged do3: Run Condor initialized with LM weights.4: Create new alignment file by resamplingaccording to weights given by Condor.5: Use the alignment file to extract phrasesand build the translation table (phrase table)6: Tune the system with MERT (this step canbe skipped until weights are optimized tosave time)7: Calculate the BLEU score8: end while3.2.2 Weighting AlignmentsAlignments produced by GIZA++ have alignmentscores associated with each sentence pair in bothdirection, i.e.
source to target and target to source.We used these alignment scores as confidencemeasurement for each sentence pair.
Alignmentscores depend upon the length of each sentence,therefore, they must be normalized regarding thesize of the sentence.
Alignment scores have a verylarge dynamic range and we have applied a loga-rithmic mapping in order to flatten the probabilitydistribution :log(?
?
( ntrg?asrc trg + nsrc?atrg src)2) (3)where a is the alignment score, n the size of asentence and ?
a coefficient to optimize.
This isalso done by Condor.Of course, some alignments will appear severaltimes, but this will increase the probability of cer-tain phrase-pairs which are supposed to be morerelated to the target domain.
We have observedthat the weights of an interpolated LM build onthe source side of the bitext are good initial val-ues for CONDOR.
Moreover, weights optimizedby Condor are in the same order than these ?LMweights?.
Therefore, we do not perform MERTof the SMT systems build at each step of the op-timization of the weights ?i and ?
by CONDOR,395IWSLT Task NIST TaskDev (Dev6) Test (Dev7) Dev (NIST06) Test (NIST08)Baseline 53.98 53.37 43.16 42.21With equal weights 53.71 53.20 43.10 42.11With LM weights 54.20 53.71 43.42 42.22Condor weights 54.80 53.98 43.49 42.28Table 1: BLEU scores when weighting corpora (one time resampling)IWSLT Task NIST TaskDev (Dev6) Test (Dev7) Dev (NIST06) Test (NIST08)Baseline 53.98 53.37 43.16 42.21With equal weights 53.80 53.30 43.13 42.15With LM weights 54.32 53.91 43.54 42.37Condor weights 55.10 54.13 43.80 42.40Table 2: BLEU scores when weighting corpora (optimum number of resampling)IWSLT Task NIST TaskDev (Dev6) Test (Dev7) TER(Test) Dev (NIST06) Test (NIST08) TER(Test)Baseline 53.98 53.37 32.75 43.16 42.21 51.69With equal weights 53.85 53.33 32.80 43.28 42.21 51.72With LM weights 54.80 54.10 31.50 43.42 42.41 51.50Condor weights 55.48 54.58 31.31 43.95 42.54 51.35Table 3: BLEU and TER scores when weighting corpora and alignments (optimum number of resam-pling)but use the values obtained by running MERT ona system obtained by using the ?LM weights?
toweight the alignments.
Once CONDOR has con-verged to optimal weights, we can then tune oursystem by MERT.
This saves lot of time taken bythe tuning process and it had no impact on the re-sults.4 Experimental evaluationThe baseline system is a standard phrase-basedSMT system based on the Moses SMT toolkit(Koehn and et al, 2007).
In our system weused fourteen features functions.
These featuresfunctions include phrase and lexical translationprobabilities in both directions, seven features forlexicalized distortion model, a word and phrasepenalty, and a target language model.
The MERTtool is used to tune the coefficients of these fea-ture functions.
We considered Arabic to Englishtranslation.
Tokenization of the Arabic sourcetexts is done by a tool provided by SYSTRANwhich also performs a morphological decompo-sition.
We considered two well known officialevaluation tasks to evaluate our approach, namelyNIST and IWSLT.For IWSLT, we used the BTEC bitexts (194Mwords), Dev1, Dev2, Dev3 (60M words each) astraining data, Dev6 as development set and Dev7as test set.
From previous experiments, we haveevidence that the various development corpora arenot equally important and weighting them cor-rectly should improve the SMT system.
We an-alyze the translation quality as measured by theBLEU score for the three methods: equal weights,LM weights and Condor weights and consideringone time resampling.
Further experiments wereperformed using the optimized number of resam-pling with and without weighting the alignments.We have realized that it is beneficial to always in-clude the original alignments.
Even if we resamplemany times there is a chance that some alignmentsmight never be selected but we do not want toloose any information.
By keeping original align-ments, all alignments are given a chance to be se-396lected at least once.
All these results are summa-rized in tables 1, 2 and 3.One time resampling along with equal weightsgave worse results than the baseline system whileimprovements in the BLEU score were observedwith LM and Condor weights for the IWSLT task,as shown in table 1.
Resampling many times al-ways gave more stable results, as already shownin figure 2 and as theoretically expected.
For thistask, we resampled 15 times.
The improvementsin the BLEU score are shown in table 2.
Fur-thermore, using the alignment scores resulted inadditional improvements in the BLEU score.
Forthe IWSLT task, we achieved and overall improve-ment of 1.5 BLEU points on the development setand 1.2 BLEU points on the test set as shown intable 3To validate our approach we further experi-mented with the NIST evaluation task.
Most ofthe training data used in our experiments for theNIST task is made available through the LDC.
Thebitexts consist of texts from the GALE project1(1.6M words), various news wire translations2(8.0M words) on development data from pre-vious years (1.6M words), LDC treebank data(0.4M words) and the ISI extracted bitexts (43.7Mwords).
The official NIST06 evaluation data wasused as development set and the NIST08 evalua-tion data was used as test set.
The same procedurewas adapted for the NIST task as for the IWSLTtask.
Results are shown in table 1 by using differ-ent weights and one time resampling.
Further im-provements in the results are shown in table 2 withthe optimum number of resampling which is 10for this task.
Finally, results by weighting align-ments along with weighting corpora are shown intable 3.
Our final system achieved an improve-ment of 0.79 BLEU points on the development setand 0.33 BLEU points on the test set.
TER scoresare also shown on test set of our final system intable 3.
Note that these results are state-of-the-artwhen compared to the official results of the 2008NIST evaluation3.The weights of the different corpora are shownin table 4 for the IWSLT and NIST task.
In bothcases, the weights optimized by CONDOR aresubstantially different form those obtained when1LDC2005E83, 2006E24, E34, E85 and E922LDC2003T07, 2004E72, T17, T18, 2005E46 and2006E25.3http://www.nist.gov/speech/tests/mt/2008/creating an interpolated LM on the source side ofthe bitexts.
In any case, the weights are clearlynon uniform, showing that our algorithm has fo-cused on in-domain data.
This can be nicely seenfor the NIST task.
The Gale texts were explictelycreated to contain in-domain news wire and WEBtexts and actually get a high weight despite theirsmall size, in comparison to the more general newswire collection from LDC.5 Conclusion and future workWe have proposed a new technique to adapt thetranslation model by resampling the alignments,giving a weight to each corpus and using thealignment score as confidence measurement ofeach aligned phrase pair.
Our technique does notchange the phrase pairs that are extracted,4 butonly the corresponding probability distributions.By these means we hope to adapt the translationmodel in order to increase the weight of transla-tions that are important to the task, and to down-weight the phrase pairs which result from unreli-able alignments.We experimentally verified the new method onthe low-resource IWSLT and the resource-richNIST?08 tasks.
We observed significant improve-ment on both tasks over state-of-the-art baselinesystems.
This weighting scheme is generic andit can be applied to any language pair and targetdomain.
We made no assumptions on how thephrases are extracted and it should be possible toapply the same technique to other SMT systemswhich rely on word-to-word alignments.On the other hand, our method is computation-ally expensive since the optimisation of the coef-ficients requires the creation of a new phrase tableand the evaluation of the resulting system in thetuning loop.
Note however, that we run GIZA++only once.In future work, we will try to directly use theweights of the corpora and the alignments in thealgorithm that extracts the phrase pairs and cal-culates their probabilities.
This would answerthe interesting question whether resampling itselfis needed or whether weighting the corpora andalignments is the key to the observed improve-ments in the BLEU score.Finally, it is straight forward to consider morefeature functions when resampling the alignments.This may be a way to integrate linguistic knowl-4when also including the original alignments397IWSLT Task BTEC Dev1 Dev2 Dev3# of Words 194K 60K 60K 60KLM Coeffs 0.7233 0.1030 0.0743 0.0994Condor Coeffs 0.6572 0.1058 0.1118 0.1253NIST TASK Gale NewsWire TreeBank Dev ISI# of words 1.6M 8.1M 0.4M 1.7M 43.7MLM Coeffs 0.3215 0.1634 0.0323 0.1102 0.3726Condor Coeffs 0.4278 0.1053 0.0489 0.1763 0.2417Table 4: Weights of the different bitexts.edge into the SMT system, e.g.
giving low scoresto word alignments that are ?grammatically notreasonable?.AcknowledgmentsThis work has been partially funded by the Eu-ropean Commission under the project Euromatrixand by the Higher Education Commission(HEC)Pakistan as Overseas scholarship.
We are verythankful to SYSTRAN who provided support forthe Arabic tokenization.ReferencesFrank Vanden Berghen and Hugues Bersini.2005.
CONDOR, a new parallel, constrainedextension of Powell?s UOBYQA algorithm:Experimental results and comparison with theDFO algorithm.
Journal of Computational andApplied Mathematics, 181:157?175, Septem-ber.Boxing Chen, Min Zhang, Aiti Aw, andHaizhou Li.
2008.
Exploiting n-best hypothe-ses for SMT self- enhancement.
In Associationfor Computational Linguistics, pages 157?160.Jorge Civera and Alfons Juan.
2007.
Do-main adaptation in statistical machine transla-tion with mixture modelling.
In Second Work-shop on SMT, pages 177?180.George Foster and Roland Kuhn.
2007.Mixture-model adaptation for SMT.
In Pro-ceedings of the Second Workshop on StatisticalMachine Translation, pages 128?135.
Associa-tion for Computational Linguistics.Almut Silja Hildebrand, Matthias Eck, StephanVogel, and Alex Waibel.
2005.
Adaptationof the translation model for statistical machinetranslation based on information retrieval.
InEAMT, pages 133?142.Philipp Koehn and et al 2007.
Moses: Opensource toolkit for statistical machine transla-tion.
In Association for Computational Linguis-tics, demonstration session., pages 224?227.Philipp Koehn and Josh Schroeder.
2007.
Ex-periments in domain adaptation for statisticalmachine translation.
In Proceedings of the Sec-ond Workshop on Statistical Machine Transla-tion, pages 224?227.
Association for Computa-tional Linguistics.Spyros Matsoukas, Antti-Veikko I. Rosti, andBing Zhang.
2009.
Discriminative corpusweight estimation for machine translation.
InProceedings of the 2009 Conference on Empir-ical Methods in Natural Language Processing,pages 708?717.M.J.D.
Powell.
1994.
A direct search opti-mization method that models the objective andconstraint functions by linar interpolation.
InIn Advances in Optimization and NumericalAnalysis, Proceedings of the sixth Workshopon Optimization and Numerical Analysis, Oax-aca, Mexico, volume 275, pages 51?67.
KluwerAcademic Publishers.Holger Schwenk and Jean Senellart.
2009.Translation model adaptation for an Ara-bic/French news translation system by lightly-supervised training.
In MT Summit.Holger Schwenk.
2008.
Investigations on large-scale lightly-supervised training for statisticalmachine translation.
In IWSLT, pages 182?189.Matthew Snover, Bonnie Dorr, and RichardSchwartz.
2008.
Language and translation398model adaptation using comparalble corpora.In Proceedings of the 2008 Conference on Em-pirical Methods in Natural Language Process-ing, pages 857?866.Nicola Ueffing.
2006.
Using monolingual sour-cce language data to improve MT performance.In IWSLT, pages 174?181.Nicola Ueffing.
2007.
Transductive learning forstatistical machine translation.
In Associationfor Computational Linguistics, pages 25?32.Chong Ho Yu.
2003.
Resampling methods:Concepts, applications, and justification.
InPractical Assessment Research and Evaluation.Bing Zhao, Matthias Ech, and Stephen Vogal.2004.
Language model adaptation for statisticalmachine translation with structured query mod-els.
In Proceedings of the 20th internationalconference on Computational Linguistics.
As-sociation for Computational Linguistics.399
