Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 421?426,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsA Topic Model for Building Fine-grained Domain-specific EmotionLexiconMin Yang?
Baolin Peng?
Zheng Chen?
Dingju Zhu*?,?
Kam-Pui Chow?
?School of Computer Science, South China Normal University, Guangzhou, Chinadingjuzhu@gmail.com?Department of Computer Science, The University of Hong Kong, Hong Kong{myang,chow}@cs.hku.hk?Department of Computer Science, Beihang University, Beijing, Chinab.peng@cse.buaa.edu.cn, tzchen86@gmail.com?Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, ChinaAbstractEmotion lexicons play a crucial role in sen-timent analysis and opinion mining.
In thispaper, we propose a novel Emotion-awareLDA (EaLDA) model to build a domain-specific lexicon for predefined emotionsthat include anger, disgust, fear, joy, sad-ness, surprise.
The model uses a mini-mal set of domain-independent seed wordsas prior knowledge to discover a domain-specific lexicon, learning a fine-grainedemotion lexicon much richer and adap-tive to a specific domain.
By comprehen-sive experiments, we show that our modelcan generate a high-quality fine-graineddomain-specific emotion lexicon.1 IntroductionDue to the popularity of opinion-rich resources(e.g., online review sites, forums, blogs and themicroblogging websites), automatic extraction ofopinions, emotions and sentiments in text is ofgreat significance to obtain useful information forsocial and security studies.
Various opinion min-ing applications have been proposed by differentresearchers, such as question answering, opinionmining, sentiment summarization, etc.
As the fine-grained annotated data are expensive to get, the un-supervised approaches are preferred andmore usedin reality.
Usually, a high quality emotion lexi-con play a significant role when apply the unsuper-vised approaches for fine-grained emotion classi-fication.
*Dingju Zhu is the corresponding authorThus far, most lexicon construction approachesfocus on constructing general-purpose emotionlexicons (Stone et al, 1966; Hu and Liu, 2004;Wilson et al, 2005; Dong and Dong, 2006).
How-ever, since a specific word can carry various emo-tions in different domains, a general-purpose emo-tion lexicon is less accurate and less informativethan a domain-specific lexicon (Baccianella et al,2010).
In addition, in previous work, most of thelexicons label the words on coarse-grained dimen-sions (positive, negative and neutrality).
Such lex-icons cannot accurately reflect the complexity ofhuman emotions and sentiments.
Lastly, previousemotion lexicons are mostly annotated based onmany manually constructed resources (e.g., emo-tion lexicon, parsers, etc.).
This limits the applica-bility of these methods to a broader range of tasksand languages.To meet the challenges mentioned above, wepropose a novel EaLDA model to construct adomain-specific emotion lexicon consisting of sixprimary emotions (i.e., anger, disgust, fear, joy,sadness and surprise).
The proposed EaLDAmodel extends the standard Latent Dirichlet Allo-cation (LDA) (Blei et al, 2003) model by employ-ing a small set of seeds to guide the model gener-ating topics.
Hence, the topics consequently groupsemantically related words into a same emotioncategory.
The lexicon is thus able to best meet theuser?s specific needs.
Our approach is a weakly su-pervised approach since only some seeds emotionsentiment words are needed to lanch the processof lexicon construction.
In practical applications,asking users to provide some seeds is easy as theyusually have a good knowledge what are importantin their domains.421Extensive experiments are carried out to evalu-ate our model both qualitatively and quantitativelyusing benchmark dataset.
The results demonstratethat our EaLDA model improves the quality andthe coverage of state-of-the-art fine-grained lexi-con.2 Related WorkEmotion lexicon plays an important role in opin-ion mining and sentiment analysis.
In order tobuild such a lexicon, many researchers have in-vestigated various kinds of approaches.
However,these methods could roughly be classified into twocategories in terms of the used information.
Thefirst kind of approaches is based on thesaurus thatutilizes synonyms or glosses to determine the sen-timent orientation of a word.
The availability ofthe WordNet (Miller, 1995) database is an impor-tant starting point for many thesaurus-based ap-proaches (Kamps et al, 2004; Hu and Liu, 2004;Esuli and Sebastiani, 2006).
The second kind ofapproaches is based on an idea that emotion wordsco-occurring with each others are likely to conveythe same polarity.
There are numerous studies inthis field (Turney and Littman, 2003; Wiebe andRiloff, 2005; Esuli and Sebastiani, 2006; Barbosaand Feng, 2010).Most of the previous studies for emotion lexi-con construction are limited to positive and nega-tive emotions.
Recently, to enhance the increas-ingly emotional data, a few researches have beendone to identity the fine-grained emotion of words(Strapparava andMihalcea, 2007; Gill et al, 2008;Rao et al, 2012).
For example, Gill et al (2008)utilize computational linguistic tools to identity theemotions of the words (such as, joy, sadness, ac-ceptance, disgust, fear, anger, surprise and antici-pation).
While, this approach is mainly for pub-lic use in general domains.
Rao et al (2012)propose an method of automatically building theword-emotion mapping dictionary for social emo-tion detection.
However, the emtion lexicon is notoutputed explicitly in this paper, and the approachis fully unsupervised which may be difficult to beadjusted to fit the personalized data set.Our approach relates most closely to the methodproposed by Xie and Li (2012) for the constructionof lexicon annotated for polarity based on LDAmodel.
Our approach differs from (Xie and Li,2012) in two important ways: first, we do not ad-dress the task of polarity lexicon construction, butinstead we focus on building fine-grained emotionlexicon.
Second, we don?t assume that every wordin documents is subjective, which is impractical inreal world corpus.3 AlgorithmIn this section, we rigorously define the emotion-aware LDA model and its learning algorithm.
Wedescrige with the model description, a Gibbs sam-pling algorithm to infer the model parameters, andfinally how to generate a emotion lexicon based onthe model output.3.1 Model DescriptionLike the standard LDA model, EaLDA is a gen-erative model.
To prevent conceptual confusion,we use a superscript ?(e)?
to indicate variables re-lated to emotion topics, and use a superscript ?
(n)?to indicate variables of non-emotion topics.
We as-sume that each document has two classes of topics:M emotion topics (corresponding to M differentemotions) andK non-emotion topics (correspond-ing to topics that are not associated with any emo-tion).
Each topic is represented by a multinomialdistribution over words.
In addition, we assumethat the corpus vocabulary consists of V distinctwords indexed by {1, .
.
.
, V }.For emotion topics, the EaLDA model drawsthe word distribution from a biased Dirichlet priorDir(?(e)k).
The vector ?(e)k?
RV is constructedwith ?
(e)k:= ?(e)0(1V?
?k) + ?
(e)1?k, for k ?
{1, .
.
.
,M}.
?k,w= 1 if and only if word w is aseed word for emotion k, otherwise?k,w= 0.
Thescalars ?
(e)0and ?
(e)1are hyperparameters of themodel.
Intuitively, when ?
(e)1> ?
(e)0, the biasedprior ensures that the seed words are more proba-bly drawn from the associated emotion topic.The generative process of word distributions fornon-emotion topics follows the standard LDA def-inition with a scalar hyperparameter ?
(n).For each word in the document, we decidewhether its topic is an emotion topic or a non-emotion topic by flipping a coin with head-tail probability (p(e), p(n)), where (p(e), p(n)) ?Dir(?).
The emotion (or non-emotion) topic issampled according to a multinomial distributionMult(?
(e)) (or Mult(?(n))).
Here, both ?
(e) and?
(n) are document-level latent variables.
Theyare generated from Dirichlet priors Dir(?
(e)) andDir(?
(n)) with ?
(s) and ?
(n) being hyperparame-ters.422We summarize the generative process of theEaLDA model as below:1. for each emotion topic k ?
{1, .
.
.
,M}, draw?(e)k?
Dir(?(e)k)2.
for each non-emotion topic k ?
{1, .
.
.
,K},draw ?(n)k?
Dir(?(n))3.
for each document(a) draw ?
(e) ?
Dir(?
(e))(b) draw ?
(n) ?
Dir(?
(n))(c) draw (p(e), p(n)) ?
Dir(?
)(d) for each word in documenti.
draw topic class indicator s ?Bernoulli(ps)ii.
if s = ?emotion topic?A.
draw z(e) ?
Mult(?(e))B.
draw w ?
Mult(?
(e)z(e)) , emit wordwiii.
otherwiseA.
draw z(n) ?
Mult(?(n))B.
draw w ?
Mult(?
(n)z(n)) , emit wordwAs an alternative representation, the graphicalmodel of the the generative process is shown byFigure 1..ww(e)w(n)z(e)z(n)s?(e)?(n)p?(e)?(n)??(e)?(n)?(e)?
(n)?MKNdDFigure 1: The Emotion-aware LDA model.3.2 Inference AlgorithmAssuming hyperparameters?, ?
(e), ?
(n), and ?(e),?
(n), we develop a collapsed Gibbs sampling algo-rithm to estimate the latent variables in the EaLDAmodel.
The algorithm iteratively takes a word wfrom a document and sample the topic that thisword belongs to.Let the whole corpus excluding the current wordbe denoted by D. Let n(e)i,w(or n(n)j,w) indicatethe number of occurrences of topic i(e) (or topicj(n)) with word w in the whole corpus.
Let m(e)i(or m(n)j) indicate the number of occurrence oftopic i(e) (or topic j(n)) in the current document.All these counts are defined excluding the currentword.
Using the definition of the EaLDA modeland the Bayes Rule, we find that the joint densityof these random variables are equal toPr(p(e), p(n), ?
(e), ?
(e), ?
(n), ?(n)|D)?
Pr(p(e), p(n), ?
(e), ?
(e), ?
(n), ?(n))?
Pr(D|p(e), p(n), ?
(e), ?
(e), ?
(n), ?(n))?(p(e))?+(?Mi=1m(e)i)?(p(n))?+(?Kj=1m(n)j)?M?i=1(?(e)i)?(e)+m(e)i?1?K?j=1(?(n)j)?(n)+m(n)j?1?1?i=0V?w=1(?(e)i,w)?(e)i,w+n(e)i,w?1?K?j=1V?w=1(?(n)j,w)?
(n)+n(n)j,w?1(1)According to equation (1), we see that{p(e), p(n)}, {?
(e)i, ?
(n)j}, {?
(e)i,w} and {?
(n)j,w}are mutually independent sets of random vari-ables.
Each of these random variables satisfiesDirichlet distribution with a specific set of param-eters.
By the mutual independence, we decomposethe probability of the topic z for the current wordasPr(z = i(e)|D)?
E[p(e)] ?
E[?
(e)i] ?
E[?
(e)i,w] (2)Pr(z = j(n)|D)?
E[p(n)] ?E[?
(n)i] ?E[?
(n)j,w] (3)Then, by examining the property of Dirichletdistribution, we can compute expectations on theright hand side of equation (2) and equation (3) byE[p(e)] =?
+?1i=0m(e)i2?
+?Mi=1m(e)i+?Kj=1m(n)j(4)E[p(n)] =?
+?Kj=1m(n)j2?
+?Mi=1m(e)i+?Kj=1m(n)j(5)423E[?
(e)i] =?
(e)+ m(e)iM?(e)+?Mi?=1m(e)i?(6)E[?
(n)j] =?
(e)+ m(n)jK?(n)+?Kj?=1m(n)j?(7)E[?
(e)i,w] =?
(e)i,w+ n(e)i,w?Vw?=1(?
(e)i,w?+ n(e)i,w?)
(8)E[?
(n)j,w] =?
(n)j,w+ n(n)j,wV ?(n)+?Vw?=1n(n)j,w?
(9)Using the above equations, we can sample thetopic z for each word iteratively and estimate alllatent random variables.3.3 Constructing Emotion LexiconOur final step is to construct the domain-specificemotion lexicon from the estimates ?
(e) and ?
(n)that we obtained from the EaLDA model.For each word w in the vocabulary, we com-pare the M + 1 values {?
(e)1,w, .
.
.
, ?
(e)M,w} and1K?Ki=1?(n)i,w.
If ?
(e)i,wis the largest, then the wordw is added to the emotion dictionary for the ithemotion.
Otherwise, 1K?Ki=1?
(n)i,wis the largestamong the M + 1 values, which suggests thatthe word w is more probably drawn from a non-emotion topic.
Thus, the word is considered neu-tral and not included in the emotion dictionary.4 ExperimentsIn this section, we report empirical evaluations ofour proposed model.
Since there is no metric ex-plicitly measuring the quality of an emotion lexi-con, we demonstrate the performance of our algo-rithm in two ways: (1) we perform a case study forthe lexicon generated by our algorithm, and (2) wecompare the results of solving emotion classifica-tion task using our lexicon against different meth-ods, and demonstrate the advantage of our lexiconover other lexicons and other emotion classifica-tion systems.4.1 DatasetsWe conduct experiments to evaluate the effective-ness of our model on SemEval-2007 dataset.
Thisis an gold-standard English dataset used in the 14thtask of the SemEval-2007workshopwhich focuseson classification of emotions in the text.
The at-tributes include the news headlines, the score ofemotions of anger, disgust, fear, joy, sad and sur-prise normalizing from 0 to 100.
Two data setsare available: a training data set consisting of 250records, and a test data set with 1000 records.
Fol-lowing the strategy used in (Strapparava and Mi-halcea, 2007), the task was carried out in an unsu-pervised setting for experiments.In experiments, data preprocessing is performedon the data set.
First, the texts are tokenized witha natural language toolkit NLTK1.
Then, we re-move non-alphabet characters, numbers, pronoun,punctuation and stop words from the texts.
Finally,Snowball stemmer2 is applied so as to reduce thevocabulary size and settle the issue of data spare-ness.4.2 Emotion Lexicon ConstructionWe first settle down the implementation details forthe EaLDAmodel, specifying the hyperparametersthat we choose for the experiment.
We set topicnumberM = 6,K = 4, and hyperparameters?
=0.75, ?
(e) = ?
(n) = 0.45, ?
(n) = 0.5.
The vector?
(e) is constructed from the seed dictionary using?
= (0.25, 0.95).As mentioned, we use a few domain-independent seed words as prior informationfor our model.
To be specific, the seed words listcontains 8 to 12 emotional words for each of thesix emotion categories.3 However, it is importantto note that the proposed models are flexible anddo not need to have seeds for every topic.Example words for each emotion generatedfrom the SemEval-2007 dataset are reported in Ta-ble 1.
The judgment is to some extent subjective.What we reported here are based on our judgmentswhat are appropriate and what are not for eachemotion topic.
From Table 1, we observe that thegenerated words are informative and coherent.
Forexample, the words ?flu?
and ?cancer?
are seem-ingly neutral by its surface meaning, actually ex-pressing fear emotion for SemEval dataset.
Thesedomain-specific words are mostly not included inany other existing general-purpose emotion lexi-cons.
The experimental results show that our al-gorithm can successfully construct a fine-graineddomain-specific emotion lexicon for this corpusthat is able to understand the connotation of thewords that may not be obvious without the context.1http://www.nltk.org2http://snowball.tartarus.org/3http://minyang.me/acl2014/seed-words.html424Anger Disgust Fear Joy Sadness Surpriseattack mar terror good kill surprisewarn sex troop win die firstgunman lebanon flu prize kidnap jumpbaghdad game dead victory lose marijuanaimmigration gaze die adopt confuse arresthit cancer cancer madonna crach sweatkidnap amish kidnap celebrity leave findkill imigration force boost cancer attackalzheim sink iraq ship flu hiviraqi force fear star kidnap discoverTable 1: Part of Emotion example wordsAlgorithm Anger Disgust Fear Joy Sadness SurpriseWordNet-Affect 6.06% - - 22.81% 17.31% 9.92%SWAT 7.06% - 18.27% 14.91% 17.44% 11.78%UA 16.03% - 20.06% 4.21% 1.76% 15.00%UPAR7 3.02% - 4.72% 11.87% 17.44% 15.00%EaLDA 16.65% 10.52% 26.21% 25.57% 36.85% 20.17%Table 2: Experiment results for emotion classification in term of F1 score4.3 Document-level Emotion ClassificationWe compare the performance between a popularemotion lexiconWordNet-Affect (Strapparava andValitutti, 2004) and our approach for emotion clas-sification task.
We also compare our results withthose obtained by three systems participating in theSemEval-2007 emotion annotation task: SWAT,UPAR7 andUA.
The emotion classification resultsis evaluated for each emotion category separately.For each emotion category, we evaluates it as a bi-nary classification problem.
In the evaluation ofemotion lexicons, the binary classification is per-formed in a very simple way.
For each emotioncategory and each text, we compare the number ofwords within this emotion category, and the aver-age number of words within other emotion cate-gories, to output a binary prediction of 1 or 0.
Thissimple approach is chosen to evaluate the robust-ness of our emotion lexicon.In the experiments, performance is evaluated interms of F1-score.
We summarize the results inTable 2.
As an easy observation, the emotion lex-icon generated by the EaLDA model consistentlyand significantly outperforms the WordNet-Affectemotion lexicon and other three emotion classifi-cation systems.
In particular, we are able to obtainan overall F1-score of 10.52% for disgust classifi-cation task which is difficult to work out using pre-viously proposed methods.
The advantage of ourmodel may come from its capability of exploringdomain-specific emotions which include not onlyexplicit emotion words, but also implicit ones.5 Conclusions and Future WorkIn this paper, we have presented a novel emotion-aware LDA model that is able to quickly build afine-grained domain-specific emotion lexicon forlanguages without many manually constructed re-sources.
The proposed EaLDA model extends thestandard LDAmodel by accepting a set of domain-independent emotion words as prior knowledge,and guiding to group semantically related wordsinto the same emotion category.
Thus, it makesthe emotion lexicon containing much richer andadaptive domain-specific emotion words.
Exper-imental results showed that the emotional lexiconsgenerated by our algorithm is of high quality, andcan assist emotion classification task.For future works, we hope to extend the pro-posed EaLDA model by exploiting discoursestructure knowledge, which has been shown sig-nificant in identifying the polarity of content-aware words.425ReferencesStefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
Sentiwordnet 3.0: An enhanced lexicalresource for sentiment analysis and opinion mining.In LREC, volume 10, pages 2200?2204.Luciano Barbosa and Junlan Feng.
2010.
Robust senti-ment detection on twitter from biased and noisy data.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters, pages 36?44.
Association for Computational Linguistics.David M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent dirichlet alocation.
the Journal of ma-chine Learning research, 3:993?1022.Zhendong Dong and Qiang Dong.
2006.
HowNet andthe Computation of Meaning.
World Scientific.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-wordnet: A publicly available lexical resource foropinion mining.
In Proceedings of LREC, volume 6,pages 417?422.Alastair J Gill, Robert M French, Darren Gergle, andJon Oberlander.
2008.
The language of emotion inshort blog texts.
In CSCW, volume 8, pages 299?302.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 168?177.ACM.Jaap Kamps, MJ Marx, Robert J Mokken, and MaartenDe Rijke.
2004.
Using wordnet to measure semanticorientations of adjectives.George AMiller.
1995.
Wordnet: a lexical database forenglish.
Communications of the ACM, 38(11):39?41.Yanghui Rao, Xiaojun Quan, Liu Wenyin, Qing Li,and Mingliang Chen.
2012.
Building word-emotionmapping dictionary for online news.
In SDAD 2012The 1st International Workshop on Sentiment Dis-covery from Affective Data, page 28.Philip J Stone, Dexter CDunphy, andMarshall S Smith.1966.
The general inquirer: A computer approach tocontent analysis.Carlo Strapparava and RadaMihalcea.
2007.
Semeval-2007 task 14: Affective text.
In Proceedings ofthe 4th International Workshop on Semantic Evalu-ations, pages 70?74.
Association for ComputationalLinguistics.Carlo Strapparava and Alessandro Valitutti.
2004.Wordnet affect: an affective extension of wordnet.In LREC, volume 4, pages 1083?1086.Peter D Turney and Michael L Littman.
2003.
Measur-ing praise and criticism: Inference of semantic orien-tation from association.
ACM Transactions on Infor-mation Systems (TOIS), 21(4):315?346.Janyce Wiebe and Ellen Riloff.
2005.
Creating subjec-tive and objective sentence classifiers from unanno-tated texts.
In Computational Linguistics and Intel-ligent Text Processing, pages 486?497.
Springer.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of the con-ference on human language technology and empiri-cal methods in natural language processing, pages347?354.
Association for Computational Linguis-tics.Rui Xie and Chunping Li.
2012.
Lexicon construction:A topic model approach.
In Systems and Informat-ics (ICSAI), 2012 International Conference on, pages2299?2303.
IEEE.426
