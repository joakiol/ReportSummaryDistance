Coling 2008: Companion volume ?
Posters and Demonstrations, pages 35?38Manchester, August 2008Underspecified Modelling of Complex Discourse ConstraintsMarkus Eggegg@let.rug.nlUniversity of GroningenMichaela Regneriregneri@coli.uni-sb.deSaarland UniversityAbstractWe introduce a new type of discourse con-straints for the interaction of discourse re-lations with the configuration of discoursesegments.
We examine corpus-extractedexamples as soft constraints.
We show howto use Regular Tree Gramamrs to processsuch constraints, and how the representa-tion of some constraints depends on the ex-pressive power of this formalism.1 IntroductionDiscourse structures cannot always be describedcompletely, either because they are ambiguous(Stede, 2004), or because a discourse parser failsto analyse them completely.
In either case, un-derspecification formalisms (UFs) can be used torepresent partial information on discourse struc-ture.
UFs are used in semantics to model structuralambiguity without disjunctive enumeration of thereadings (van Deemter and Peters, 1996).Underspecified descriptions of discourse musthandle two kinds of incomplete information, onthe configuration of discourse segments (howthey combine into larger units), and on the dis-course relations that bring about this configura-tion: Our corpus studies on the RST DiscourseTreebank (Carlson et al, 2002) showed interde-pendencies between relations and configuration, aphenomenon first noted by (Corston-Oliver, 1998).These interdependencies can be formulated as con-straints that contribute to the disambiguation of un-derspecified descriptions of discourse structure.E.g., in discourse segments constituted by therelation Condition, the premiss tends to be a dis-c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.course atom (or at least, maximally short).1Simi-larly, there is evidence for an interdependency con-straint for the relation Purpose(1)2.
In most cases,Purpose(1) has a discourse atom as its nucleus.The corpus evaluation furthermore shows thatthose patterns never occur exclusively but only astendencies.
Realised as soft constraints, such ten-dencies can help to sort the set of readings ac-cording to the established preferences, which al-lows to focus on the best reading or the n-bestreadings.
This is of high value for an UF-basedapproach to discourse structure, which must copewith extremely high numbers of readings.
Tomodel interdependency constraints, we will useRegular Tree Grammars (RTGs) (Comon et al,2007).
RTGs can straightforwardly be extendedto weighted Regular Tree Grammars (wRTGs),which can represent both soft and hard constraints.Apart from our corpus-extracted examples, wealso consider a hard interdependency constraintsimilar to the Right Frontier Constraint.
We showthat we can integrate this attachment constraintwith our formalism, and how its representation de-pends on the expressiveness of RTGs.2 Underspecified Discourse StructureWe describe (partial) information on discoursestructure by expressions of a suitable UF, here,dominance graphs (Althaus et al, 2003).
Considere.g.
Fig.
1(a), the dominance graph for (1):(1) [C1I try to read a novel] [C2if I feel bored][C3because the TV programs disappoint me][C4but I can?t concentrate on anything.
]1Following Rhetorical Structure Theory (Mann andThompson, 1988), most discourse relations have a central nu-cleus argument, and a peripheral satellite argument.
For Con-dition, the premiss is the satellite, the nucleus, the conclusion.2?(n)?
as part of a relation name indicates that the nucleusis its n-th argument; relations with names without such anaffix are multinuclear, i.e., link two segments of equal promi-nence.
We sometimes omit the numbers where the position ofthe nucleus is clear from the context.35Cause(2)ContrastC1C2C3C4C1C2C3C4C2C3C4C1C4C1C2C3Condition(1)Condition(1)Condition(1)Condition(1)Cause(2)Cause(2)Cause(2)ContrastC1C2C3C4Condition(1)Cause(2)ContrastContrastContrastCondition(1)123 5476Cause(2)ContrastC1C2C3C4(a) (b) (c) (d) (e) (f)Figure 1: An underspecified discourse structure and its five configurations{1-7}?
Condition({1}, {3-7}) [1] {1-7}?
Cause({1-3}, {5-7}) [1] {3-7}?
Contrast({3-5}, {7}) [1]{3-5}?
Cause({3}, {5}) [1] {1-7}?
Contrast({1-5}, {7}) [1] {1-5}?
Cause({1-3}, {5}) [1]{5-7}?
Contrast({5}, {7}) [1] {1-5}?
Condition({1}, {3-5}) [3] {1-3}?
Condition({1}, {3}) [9]{3-7}?
Cause({3}, {5-7}) [1] {1} ?
C1[1] {3} ?
C2[1] {5} ?
C3[1] {7} ?
C4[1]Figure 2: A wRTG modelling the interdependency constraint for Fig.
1Such constraints describe a set of discoursestructures (formalised as binary tree structures).Their key ingredient are (reflexive, transitive andantisymmetric) dominance relations, which are in-dicated by dotted lines.
Dominance of X1over X2means that X2is part of the structure below (andincluding) X1, but there might be additional mate-rial intervening between X1and X2.Fig.
1(a) states that C1is linked to a part of thefollowing discourse (including at leastC2) byCon-dition, Cause(2) connects two discourse segments(comprising at least C2and C3, respectively), andContrast links a discourse segment to its left (in-cluding at least C3) to C4.This constraint describes (is compatible with)exactly the five tree structures in Fig.
1(b-f), ifdescribed tree structures may only comprise ma-terial that is already introduced in the constraint.They model the potential discourse structures for(1) (see Webber (2004)).
Dominance graphs likeFig.
1a.
are pure chains.
Pure chains describe allbinary trees with the same leaf language, here thediscourse segments, in their textual order.
Purechains define a left-to-right order, in that not onlythe leaves always form the same sequence, but alsothe inner nodes: If a labelled node X is further tothe left in the chain than another node Y, in everydescribed tree, X will either be Y?s left child, or Ywill be X?s right child, or there will be a fragmentF of which X is a successor on the left and Y is aright successor.
Henceforth we will refer to frag-ments with their index in the chain (indicated byencircled numbers in Fig.
1a).3 Representing Soft InterdependenciesThe interdependency constraint for Condition(1) isthat its satellite tends to be maximally short, i.e.,mostly consists of only one discourse atom, andin most remaining cases, of two atoms.
Thus, (b)and (d) are preferred among the configurations inFig.
1, (c) is less preferred, and (e) and (f) are theleast preferred.
Regular Tree Grammars (RTGs) asUF (Koller et al, 2008) can express such complexconstraints straightforwardly, and provide a con-venient framework to process them.
They allowto extract a best configuration with standard algo-rithms very efficiently.Koller et al (2008) show how to generate anRTG describing the same set of trees as a domi-nance graph.
Similar to a context free grammar, anRTG uses production rules with terminal symbolsand nonterminal symbols (NTs), whereby the left-hand side (LHS) is always a nonterminal and theright-hand side (RHS) contains at least one termi-nal symbol.
One NT is the start symbol.
A treeis accepted by the grammar if the grammar con-tains a derivation for it.
An example for an RTG isgiven in Fig.
2, which describes the same trees asthe dominance graph in Fig.
1a.
The start symbolis {1-7}.
To derive e.g.
the tree in Fig.
1d, we firstselect the rule {1-7} ?
Cause({1-3}, {5-7}) thatdetermines Condition as root for the whole tree.The left child of Condition is then derived from{1-7}, and the right child from {5-7} respectively.To emphasize the association with the dominancegraph, we mark nonterminals as the subgraphs theyrepresent, e.g., {1-7} denotes the whole graph.The terminal in the RHS of a grammar rule deter-mines the root of the LHS subgraph.Koller et al (2008) also use weighted RTGs(wRTGs, an extension of RTG with weights) toexpress soft dominance constraints (which, unlikehard constraints, do not restrict but rather rank theset of configurations).
We use wRTGs to modelthe soft interdependency constraints.
The gram-mar in Fig.
2 is also a wRTG that assigns a weightto each derived tree: Its weight is the product overall weights of all rules used for the derivation.Weights appear in squared brackets after the rules.36The (merely expository) weights in our exampleencode the preference of Condition for a maxi-mally short right child: There are three grammarrules that establish Condition as the root of a sub-graph (shaded in Fig.
2), which are distinguishedby the size of the right child of the root (one ({3}),three ({3-5}) or five ({3-7}) nodes).
The shorterthe right child, the higher the weight associatedwith the rule.
(1 is a neutral weight by definition.
)The grammar thus assigns different weights to thetrees in Fig.
1; (b) and (d) get the maximum weightof 9, (b), a medium weight of 3, and (e) and (f), thelowest weight of 1.4 Expressive Power of RTGsAs Koller et al (2008) show, the expressive powerof RTGs is superior to other common underspec-ification formalism.
We show an important appli-cation of the increased expressiveness with Ex.
2,where a. can be continued by b. but not by c:(2) a.
[C1Max and Mary are falling apart.
][C2They no longer meet for lunch.
][C3And, last night, Max went to thepub] [C4but Mary visited her parents.]b.
[C5aShe complained bitterly about hisbehaviour.]c.
[C5bHe left after his fifth pint of lager.
]Segment C5acontinues the preceding clauseabout Mary?s visit with additional informationabout the visit, it thus attaches directly to C4.
Tofind a coherent integration of C5b, we would haveto connect it to C3, as it provides more detailsabout Max?
night at the pub.
However, in the givenconstellation of C3and C4, that form a Contrasttogether, C3is not available any longer for attach-ment of further discourse units.
(This constraint isreminiscent of the Right Frontier Constraint, as itis used by Asher and Lascarides (2003).
However,it is unclear how the Right Frontier Constraint inits exact definition can carry over to binary trees.
)The given attachment constraint is not express-ible with dominance graphs: it excludes the config-urations of its dominance graph (Fig.
3) in whichContrast shows up as a direct left child, e.g.,(3b/e/f) as opposed to (3c/d).
For instance, theexcluded structure emerges in (3e/f) by choosingCause as root of the the subgraph 5-9 (i.e., includ-ing the Contrast- and Sequence-fragments).
Forconvenience, we will talk about this constraint asthe ?left child constraint?
(LCC).S ?
Contrast(S, S) L ?
Evid(S, S)S ?
Sequ(L, S) L ?
List(S, S)S ?
LL ?
C1L ?
C2L ?
C3L ?
C4L ?
C5Figure 5: A filter RTG corresponding to Ex.
2This additional constraint, however, can be ex-pressed by an RTG like Fig.
4.
We explicitlydistinguish between subgraphs (referred to withnumbers) and their associated NTs here.
Cru-cially, some subgraphs can be processed in dif-ferent derivations here, e.g., {5-9} (as right childof List, irrespective of the relative scope of Ev-idence and List), or {3-7} (in the expansions ofboth {EvLiCo} and {LiCoSe}, like in (3c) asopposed to (3d)).
Sometimes this derivation his-tory is irrelevant, like in the case of {5-9} (here,only Contrast may be chosen as root anyway), butthere are cases where it matters: If {3-7} is the leftchild of Sequence, as in (3b/d), the choice of Con-trast as its root is excluded, since this would makeContrast the left child of Sequence, as in (3b).
Incontrast, {3-7} as the right child of Evidence, likein (3c), allows both Contrast and List as root, be-cause Contrast emerges as a right child in eithercase.
Thus, the two occurrences of {3-7} are dis-tinguished in terms of different NTs in the gram-mar, and only in the NT for the latter occurrence isthere more than one further expansion rule.Regular tree languages are closed under inter-section.
Thus, one can derive a grammar like Fig.
4by intersecting a completely underspecified RTG(here, the one derived from Fig.
3a) with a suitablefilter grammar, e.g., Fig.
4.
The filter grammarproduces an infinite language, containing the frag-ments of Fig.
3a and excluding any derivation inwhich Sequence is the direct parent of Contrast.This is guaranteed by introducing the nonterminalL (the left child NT for Sequence), for which thereis no derivation with Contrast as its root.For an arbitrary pure chain with n fragments, thefilter grammar generating the LCC is constructedas follows: S is the start symbol.
For every frag-ment i s.t.
0 < i < n, there is a derivation rulewith S as its LHS and i in its RHS, thus eitherS ?
i, for singleton fragments, or S ?
i(A,S),for binary fragments.
If i is binary, we must de-termine A: If there is at least one fragment f < is.t.
the LCC is assumed for f , we create a newNT Li; every derivation rule with i on its RHS fol-lows the pattern X ?
i(Li, S) (thus A = Liinparticular).
If there is no LCC fragment to the left37C5C2C3C4Evidence(1)SequenceContrastC1ListC1C5C3C4EvidContrSequC2ListC1C3C4EvidContrC2ListC5SequC1C5C4EvidContrSequC3C2ListListC1EvidC2C4C5ContrC3(a) (b)(c) (d) (e)C1C5C4EvidContrListC3C2SequSequ(f)123547689Figure 3: An underspecified discourse structure for Ex.
2 and five of its configurations{EvLiCoSe} ?
Evid({C1}, {LiCoSe}) {EvLiCo} ?
List({Ev}, {Co}) {Ev} ?
Evid({C1}, {C2}){EvLiCoSe} ?
List({Ev}, {CoSe}) {CoSe} ?
Cont({C3}, {Se}) {Li} ?
List({C2}, {C3}){EvLiCoSe} ?
Cont({EvLi}, {Se}) {EvLi} ?
Evid({C1}, {Li}) {Co} ?
Cont({C3}, {C4}){EvLiCoSe} ?
Sequ({EvLiCo}, {C5}) {EvLi} ?
List({Ev}, {C3}) {Se} ?
Sequ({C4}, {C5}){LiCoSe} ?
Sequ({LiCo}L, {C5}) {LiCo}L?
List({C2}, {Co}){LiCoSe} ?
List({C2}, {CoSe}) {LiCo}S?
Cont({Li}, {C4}) {C1} ?
C1{C2} ?
C2{LiCoSe} ?
Cont({Li}, {Se}) {LiCo}S?
Li({Li}, {C4}) {C3} ?
C3{EvLiCo} ?
Evid({C1}, {LiCo}S) {C4} ?
C4{C5} ?
C5Figure 4: A RTG integrating the attachment constraint for Contrast from Ex.
2 into Fig.
3of i, A = S. If a new NT Liwas created, weneed to create its RHSs: For every fragment h s.t.0 < h < i and there is no LCC for h, there is arewrite rule directly deriving h from Li.
If h is asingleton fragment, the rule is Li?
h. Otherwisethe rule is Li?
h(A?, S), whereby A?= S, ifthere is no Lh, or A?= Lhif there is some LCCfragment on the left of h.3The grammar in Fig.
4 can be generated withthat scheme; it has been reduced afterwards in thata general rule S ?
L substitutes for all rules of theform S ?
NT for which there is a correspondingrule L ?
NT (e.g., S ?
Evid(S, S)).5 ConclusionInterdependency constraints that arise from the in-teraction of discourse relations and their surround-ing structures are introduced as a new techniquefor disambiguating discourse structure.
We inte-grate those constraints in underspecified discoursestructures by exploiting the expressive power ofRegular Tree Grammars as UF.
As the corpus anal-ysis yields in many cases only soft interdepen-dency constraints, we use the weighted extensionof RTGs, which allows to sort the readings of anunderspecified representation and to identify pre-ferred discourse structures.
We then showed thatthe representation of some discourse constraintsdepend on the expressive power of RTGs.
Fornotes on implementation and tractability of our ap-proach, see Regneri et al (2008).3To model this as a preference rather than as a hard con-straint, no rules for the L-NTs are omitted, but rather weightedlow.
An intersection with a preference-neutral wRTG wouldrank the configurations violating the constraint low, and allothers with neutral weights.ReferencesAlthaus, Ernst, Denys Duchier, Alexander Koller, KurtMehlhorn, Joachim Niehren, and Sven Thiel.
2003.An efficient graph algorithm for dominance con-straints.
Journal of Algorithms, 48:194?219.Asher, Nicholas and Alex Lascarides.
2003.
Logics ofConversation.
Cambridge UP, Cambridge.Carlson, Lynn, Daniel Marcu, and Mary EllenOkurowski.
2002.
RST Discourse Treebank.
LDC.Comon, H., M. Dauchet, R. Gilleron, C. L?oding,F.
Jacquemard, D. Lugiez, S. Tison, and M. Tom-masi.
2007.
Tree Automata Techniques and Ap-plications.
Available on: http://www.grappa.univ-lille3.fr/tata.
Release 12-10-2007.Corston-Oliver, Simon H. 1998.
Computing Represen-tations of Discourse Structure.
Ph.D. thesis, Dept.
ofLinguistics, University of California, Santa Barbara.van Deemter, Kees and Stanley Peters, editors.
1996.Semantic ambiguity and underspecification.
CSLI,Stanford.Koller, Alexander, Michaela Regneri, and StefanThater.
2008.
Regular tree grammars as a formal-ism for scope underspecification.
In Proceedings ofthe ACL 08.Mann, William C. and Sandra A. Thompson.
1988.Rhetorical Structure Theory: Toward a functionaltheory of text organization.
Text, 8:243?281.Regneri, Michaela, Markus Egg, and Alexander Koller.2008.
Efficient Processing of Underspecified Dis-course Representations.
In Proceedings of the ACL08 (Short Papers).Stede, Manfred.
2004.
The Potsdam Commentary Cor-pus.
In Webber, Bonnie and Donna K. Byron, edi-tors, ACL 2004 Workshop on Discourse Annotation.Webber, Bonnie.
2004.
D-LTAG: extending lexicalizedTAG to discourse.
Cognitive Science, 28:751?779.38
