Interactive Chinese-to-English Speech Translation Based onDialogue ManagementChengqing Zong, Bo Xu, and Taiyi HuangNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of SciencesP.
O.
Box 2728, Beijing 100080, China{cqzong, xubo, huang}@nlpr.ia.ac.cnAbstractIn this paper, we propose a novelparadigm for the Chinese-to-Englishspeech-to-speech (S2S) translation, whichis interactive under the guidance ofdialogue management.
In this approach,the input utterance is first pre-processedand then serially translated by thetemplate-based translator and the inter-lingua based translator.
The dialoguemanagement mechanism (DMM) isemployed to supervise the interactiveanalysis for disambiguation of the input.The interaction is led by the system, sothe system always acts on its owninitiative in the interactive procedure.
Inthis approach, the complicated semanticanalysis is not involved.1 Introduction2Over the past decade, many approaches to S2Stranslation have been proposed.
Unfortunately, theS2S translation systems still suffer from the poorperformance, even though the application domainsare restricted.
The common questions are: whattranslation strategies are necessary?
What do theproblems exist in the current S2S systems?
Andwhat performance of a system is acceptable?Based on the questions, we have analyzed thecurrent approaches to machine translation (MT)and investigated some experimental systems andthe user?s requirements.
A novel paradigm for theChinese-to-English S2S translation has beenproposed, which is interactive under the guidanceof DMM.
In this approach, the input utterance isfirst pre-processed and serially translated by thetemplate-based translator and the inter-linguabased translator.
If the two translators are failed totranslate the input, the dialogue managementmechanism is brought into play to supervise theinteractive analysis for disambiguation of the input.The interaction is led by the system, so the systemalways acts on its own initiative in the interactiveprocedure.
In this approach, the complicatedsemantic analysis is not involved.Remainder of the paper presents ourmotivations and the proposal scheme in detail.Section 2 gives analysis on the current MTapproaches and the user?s requirements.
Section 3describes in detail our approach to Chinese-to-English S2S translation.
Section 4 drawsconclusions and presents the future work.Analysis on MT approaches and S2Stranslation systems2.1 Analysis on MT approachesIn the past decades, many MT approaches havebeen proposed.
We roughly divided the currentapproaches into two types, which are respectivelynamed as the mainstream approaches and the non-mainstream approaches.
The mainstreamapproaches include four basic methods: theanalysis-based method, the example-based method,the template-based method and also the statisticalmethod as well.
The analysis-based method hereincludes the rule-based method, the inter-lingualmethod, or even the knowledge-based method.
Inthe recent years, the approach based on multi-engine has been practiced in many systems (Lavie,Association for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
61-68.Proceedings of the Workshop on Speech-to-Speech Translation:1999; Wahlster, 2000; Zong, 2000a).
However, theengines employed in these experimental systemsare mainly based on the four mainstream methods.The strong points and the weak points of the fourmethods have been analyzed in many works (Zong,1999; Ren, 1999; Zhao, 2000).The non-mainstream approach here refers toany other methods exclusive of the four methodsmentioned above.
To improve the performance ofMT systems, especially to cope with the specificproblems in S2S translation, many schemes havebeen proposed.
Ren (1999) proposed a super-function based MT method, which tries to addressthe MT users?
requests and translates the inputwithout thorough syntactic and semantic analysis.The super-function based MT system is fast,inexpensive, easy to control and easy to update.However, the fluency and the correctness of thetranslation results are usual not high.
Moreover, toextract the practical super-functions from thecorpus is also a hard work.
Yamamoto et al (2001)proposed a paradigm named Sandglass.
In thesandglass system, the input utterances from aspeech recognizer are paraphrased firstly, and theparaphrased text is passed to the transfer controller.The task of the paraphrasing module for the sourcelanguage is to deal with noisy inputs from thespeech recognizer and provides differentexpressions of the input.
An obvious questionabout the Sandglass is why the system wouldrather rewrite the input than to translate it directly?Zong et al (2000b) proposed an MT method basedon the simple expression.
In the method thekeywords in an input utterances are spotted outfirstly and the dependence relation among thekeywords are analyzed.
Then, the translationmodule searches the examples in the knowledgebase according to the keywords and theirdependence relation.
If an example is matched withthe conditions, the target language expression ofthe example is sent out as the translation result ofthe input.
When the input is not very long, and thedomain and the type of the input are restricted, themethod is very practical.
However, to develop theknowledge base with dependence relation ofkeywords and to match an input with all examplesin the knowledge base are sometimes difficult.Wakita et al (1997) proposed a robust translationmethod which locally extracts only reliable parts,i.e., those within the semantic distance thresholdand over some word length.
This technique,however, does not split input into units globally, orsometimes does not output any translation result(Furuse et al 1998).
In addition, the methodclosely lies on the semantic computation, andsometimes it is hard to compute the semanticdistance for the spoken utterances.In summary, both mainstream MT methods andnon-mainstream methods have been practiced inmany experimental S2S translation systems.However, all methods mentioned above areunilateral and based on user's own wishful thinking.The system is passive and blind in some extent.The task that machine translates is imposed byhuman, and some problems are also brought by thespeaker, e.g., the topics are changed casually, orthe ill-formed expressions are uttered.
In thesecases, it is unreasonable to expect the system to getthe correct translation results, but not to give thesystem any rights to ask the speaker about his orher intention or some ambiguous words.
In fact, ifwe examine the procedures that human interpretersuse, we can see that the translation is usuallyinteractive.
When an interpreter is unable todirectly translate an utterance due to an ill-formedexpression or something even worse, theinterpreter may have to ask the speaker to repeat orexplain his / her words.
Based on the ideas, theinteractive paradigms for S2S translation havebeen proposed (Blanchon, 1996; Waibel, 1996;Seligman, 1997; Seligman, 2000; Ren, 2000).Seligman (2000) proposed a ?
quick and dirty?
or?low road?
scheme, in which he suggested that, bystressing interactive disambiguation, practicallyusable speech translation systems may beconstructable in the near term.
In addition, twointeractive MT demos were shown respectively in1997 and 1998 (Seligman, 2000).
However, all theproposed interactive schemes and the demos putthe emphasis on the interface between speechrecognition (SR) and analysis.
The interface can besupplied entirely by the user, who can correct SRresults before passing them to translationcomponents.
That means the translation system isstill passive.
Actually, as we know that the parsingresults and the translation results are not certainlycorrect even though the input is completely correct,but some noisy words usually have not anyinfluence whether they are correct or not.
In thissense, the user should know what the system needs?And what brought the system ambiguity?
Thismeans, the system has rights and obligations to tellthe user what the system want to know.
In anotherwords, the system necessitates a DMM to guide theinteraction between the system and user, andsometimes the system should play the leading role.2.2 Analysis on user?s requirementsAlthough much progress in SR and spokenlanguage parsing has been made, there is still along way to reach the final and ideal goal that thetranslation results are complete correct.
In thissituation, let?s think does a user always need thecomplete correct translation results?
Please see thefollowing three examples:(1) Input: ??????
??????????????????????
(Oh,that ?
well, please reserve a single roomfor me, sure, a single room.
)In the input, there are many redundant words,such as, ?(Oh)???
(that), ???
(well) and soon.
If all words in the input are translated, thetranslation result is verbose and wordy.
In fact, inthe input only three keywords are useful, which are:??
(reserve), ??
(one), and ???
(single room)as well.
The preposition phrase ???
(for me)?
isnot  obligatory.
Even the word ????
is also notobligatory.
(2) Input: ?
?
?
?
?
??
?
?
(Is this ?Xiang Ge Li La?
Hotel?
)In the example, the four characters withunderline are originally a hotel name ??????
(Shangri-la), but they are wrong transliteratedand separated due to the absence of the word in theSR dictionary.
In this case, it is impossible tocorrectly parse the input without user?s help.
(3) Input: ???
?
??
?
??
??
???
(Isthere any ?
ask ... have?
route toHuangshan mountain?
)The input is a result of the SR component.Obviously, in the input two characters withstressing dots are wrong recognized from theoriginal word ???
(tour)?.
In this case, if allwords are translated, the results will beinconceivable.
On the contrary, the result is quiteunderstandable if the two characters with stressingdots are omitted or ignored.The example (1) shows that if the input isrecognized completely correct, the parsing result isstill probably wrong due to the ill-formedexpression of the input.
The example (2) meansthat it is impossible to correctly parse the input dueto the unknown word and its incorrect recognition.The example (3) shows that even though theexpression is formal and there is not any unknownword in the input, the result of SR is still probablywrong.
The parser is impossible to correctlyanalyze the wrong SR result.From the three examples we can easily get thefollowing standpoints: a) the user expects his orher intentions to be translated rather than his (her)all words.
The keywords and their dependencerelations are the main objects to hold the user?sintentions.
b) For the translation component, it isnot indispensable to correct all mistakes in theinput from the SR component.
c) If the parser isfailed to parse the input, and the system onlytranslates the keywords, the translation results maybe still understandable and acceptable.3 Interactive translation based ondialogue management3.1 Overview of the paradigmUtterancesSR N-best SpeakerPre-processor Machine learningInteractiveinterface BP identifierUttr.
segment.DMMn partsInputFTemplate-basedtranslator FParser &EvaluationResultsS Inter-lingua SLanguagegeneratorTTSTarget speech Slot-based translatorFigure 1.
The paradigm of interactive translationBased on the analysis on MT approaches and theuser?s requirements, we propose an interactiveparadigm for the S2S translation, which is basedon the template-based translation, inter-lingualtranslation and the DMM based translation as well.The paradigm is shown as Figure 1.Where, the letter S beside the line with arrowmeans that the results of the former module aresuccessful, and the letter F means the results arefailure.According to the paradigm, an input from the SRcomponent is probably processed and translated bythe following four steps.
First, the input is pre-processed.
Some noisy words are recognized, somerepeated words are deleted, and the numbers areprocessed (Zong, 2000a).
Then the base phrases(BP) in the input are identified, which includenoun phrase (NP) and verb phrase (VP) mainly.And also, if the input is a long utterance containingseveral simple sentences or some fixed expressions,the input is possibly segmented into n parts.
n is aninteger, and n ?
1.
Second, each part of the input ispassed to the template-based translator.
If the inputpart is matched with a translation template, thetranslation result is sent to the text-to-speech (TTS)synthesizer directly.
Otherwise, the input part willbe passed to the inter-lingual translator.
Third, inthe inter-lingual translator, the input is parsed andthe parsing results are evaluated.
If the evaluationscore is bigger than the given threshold value, theparsing results will be mapped into the inter-lingua,and the translation result will be generated by theinter-lingua based target language generator.Otherwise, the system performs the fourth step.Fourth, DMM works to supervise the interactionfor disambiguation of the input.
In the interaction,the user is asked to answer some questionsregarding to the input part.
The system will fill theslots according to the question-answers.
The slotsare designed to express the user?s intentions in theinput.
The system directly generates the translationresult according to the slots.
So, the translation inthe fourth step is named as slot-based translation.Where, the template-based translator employsthe forward maximum match algorithm (Zong,2000c).
The inter-lingua uses the interchangeableformat (IF) developed by C-STAR (Consortium forSpeech Translation Advanced Research).
Theparser oriented to IF is realized on the basis ofHMM spoken language understanding model.
Inthe experimental system we use the tri-gram tocompute the probability of the sequence ofsemantic units (Xie, 2002).
The IF-based languagegenerator employs a task-oriented micro-plannerand a general surface realizer.
The target languageis generated by the combination of templatemethod and generation technology (Wu, 2000).The generic DMM has been proposed by (Xu,2001), which combines both interaction patternsand task structure.
The machine learning module istaking charge of recording the dialogue patterns,topics and modifying the dialogue history, and soon.
This module is still under construction.3.2 Utterance segmentationIn an S2S translation system, how to split the longinput utterances is one of the key problems,because an input is often uttered by thespontaneous speech, and there is not any specialmark to indicate which word is the beginning orthe end of each simple sentence inside theutterance.
In our system an input Chinese utteranceis first split by the SR component according to theacoustic features, including the prosodic cues andpause etc.
Suppose an input utterance has beentranscribed by SR and separated into k parts P1,P2, ?
Pk (k is an integer, and k ?
1.).
Each part Pi(i?
[1 .. k]) is possibly further segmented into m(m is an integer and m?1) units U1, U2, ?, Um bythe segmentation module based on the linguisticanalysis (SBLA).
Where, all Pi (i?
[1 .. k]) and Uj(j?
[1 .. m]) are called as the split units in oursystem.
A split unit is one of the followingexpressions:z A single word.z A fixed expression, such as a greetingphrase in Chinese.z A simple sentence.z A clause indicated by some specialconjunctions.
For example, an input similarwith the pattern ???
(because) ?
, ??
(therefore) ?
?
will be separated into twoparts ?
?
?
(because)??
and ?
?
?
(therefore) ?
?.Each Pi (i?
[1 .. n]) is analyzed and segmentedby SBLA through the following three steps:splitting on the shallow level, splitting on themiddle level, and splitting on the deep level.
Thismeans if a string S is separated into n parts byusing the method on the shallow level, each partwill possibly be further segmented by the methodon the middle level, and so on.3.3 Slot-based translation with DMMThe slot-based translation with DMM is built onthe following viewpoints and hypothesis: 1) thereare some noisy words or ambiguous words in theresults from SR component, but the keywords arerecognized correctly; 2) the user?s intentions lie onthe keywords and their dependence relations; and 3)the translation results based on the keywords areunderstandable and reflect the main intentions ofthe user.
The slot-based translation under theguidance of DMM is performed as the followingsteps:i) Re-analyze the original input string, spot outthe keywords, and also do the analysis on thedependence relation of the keywords.ii) Interact with the user, make decision aboutthe keywords and their dependence relation,and fill the slots for the translation.iii) Generate the translation results according tothe slots.iv) DMM writes down the keywords and theirdependence relations and modifies thedialogue history.3.3.1 Keywords spotting and dependenceanalysisAccording to the evaluation score, if the parsingresult of an input part is too worse, the parsing istreated as failure, and all analysis results, includingbase phrases, are ignored.
The system will spot outthe keywords from the original input and analyzethe dependence relation among the keywords.Please note that the dependence relation of thekeywords in this component is used for seizing theuser?s intentions and generating the translationresults.
It is different with the function in thesimple expression based translation (Zong, 2000b).In a specific domain, it is easy to define somekeywords according to the statistical results of thecollected corpus.
In our system, a word is treatedas the keyword if the following two conditions aremet:?
The part-of-speech (POS) of the word isone of the following three POSs: noun (N),verb (V), and adjective (A), and the wordoccurs with high probability in the specificdomain.?
The word is a number or a time word.In our method, the verb keyword is always treatedas the center when the dependence relations areanalyzed.
The dependence relations between theverb keyword and the noun keywords are definedas four types: (1) agent, (2) direct object, (3)indirect object, and (4) the pivot word as well.
Theagent is usually located at the left of the verbkeyword.
In general, the direct object, indirectobject, and the pivot word all occur at the right ofthe verb keyword.
The pronoun is treated as thenoun.
Other content words are treated as themodification words of the keywords.
The searchdirection and the position relation may be shown asthe following Figure 2.
Where, Wi means acommon word, and KWi means a keyword..W1  ?
KW1(verb) ?
Wi  ?
KW2(noun)?modificationsagent object / pivot wordFigure 2.
Keywor lationsAccording to the charaverbs, there are five case?
There is no object af?
There is one object o?
There are two objecand another one is t?
The object is a claus?
After the verb keywobject (pivot wordagent of another folIn the keyword dictionarits all possible POSs aDMM asks the user qfeatures of a specific ver3.3.2 Interaction and sIn the DMM module,express the user?s intenseries of slots as followsds and their recteristics of the Chineses respectively:ter the verb;nly;ts.
One is the direct objecthe indirect object.e.ord, the first noun is the) and acts as the role oflowed verb.y, each verb is tagged withnd relative features.
Theuestions according to theb, its context, and the slots.lot fillinga frame is designed totions, which consists of a.Frame: ACTION: Keywords (verb)TENSE: {Present/Past/?}EXP.
TYPE: {Interrogative/?
}AGENT: noun;OBJECT1: noun;OBJECT2: noun;QUANTITY1: numeral;UNIT1: classifier;QUANTITY2: numeral;UNIT2: classifier;TIME: numeral & classifier;HOW: adjective;Figure 3.
Frame of slotsWhere, QUANTITY1 and UNIT1 modify theagent, QUANTITY2 and UNIT2 modify theOBJECT1 or OBJECT2.
Because the keywordshave been spotted out and their dependencerelations have been analyzed, the DMM asks theuser according to the analysis results and theconcrete context.
Please see the following example.Input: ?
?
?
?
?
??
?
?
(Is this ?Xiang Ge Li La ?
Hotel?
)Two keywords, ??(be)?
and ???
(hotel)?, arespotted, and the word ????
is recognized as theobject of the verb ??
?.
i.e.,  ACTION=?
;TENSE=Present; EXP.
TYPE= Interrogative;OBJECT1=??
; and other slots are empty.However, there are four noisy characters betweenthe two keywords.
The DMM will ask the user byusing the question pattern: ???
(what) X ??.
Thevariable X is just replaced with the keyword ???
?.The user needs to answer the hotel name.
Becausethe SR module still does not recognize the speechof the word ?????
(Shangri-la)?, the DMM isunable to parse the user?s answer.
The followingdialogue will be done:System: ?????????????????
(Is the word ??????
an adjective or a noun?
)User:   (?)??
(It is a noun.
)System: ???????
?
(Is it the hotelname?
)User:  ??
(yes).System: ???????????
(Pleaseinput the English name of the word ??????
).The DMM will append the word ?????
?both into the SR dictionary and translationdictionary and treat it as the attribute of thekeyword ????.
The input is finally translated byusing the template ?Is this the X ?
?.3.3.3 Generation based on slotsAfter the interaction, the translation result will begenerated based on the templates that are consistedof the slots.
For example, if AGENT and ACTIONare filled, the EXP.
TYPE = Statement, and otherslots are empty.
The generation templateis: !AGENT !ACTION.
Where, !AGENT meansthe English word corresponding to the Chineseword in the AGENT slot.
!ACTION is the Englishword corresponding to the Chinese word in theACTION slot.
However, the morphology of theverb will be changed according to the agent.From the frame of slots we can see that theframe can only express the analysis results ofsimple sentence.
So, the translation result is alwaysexpressed by the simple sentence.
If the subject orthe object of a Chinese input is a clause, the inputwill be translated into two or more simple Englishsentences.
For instance,Input: ??????????????
(How much does it cost if I reserve two singlerooms?
)The input will be mapped into two frames.
Inthe first frame, AGENT=?
; ACTION=??
; EXP.TYPE=Statement; QUANTITY2=?
; UNIT2=?
;OBJECT1= ?
?
?
.
In the second frame,ACTION= ?
?
; EXP.
TYPE= Interrogative;QUANTITY1=??
; OBJECT1=?
.
Therefore,the input is separately translated into two simpleEnglish sentences: ?I reserve two single rooms.
?,and ?How much does it cost??.
Obviously, in thespecific context, the results are completelyunderstandable and acceptable.4 ConclusionThis paper describes a new paradigm for S2Stranslation system, which is based on DMM.According to the description we can see that theparadigm is of the following features:(1) The S2S translation is realized in thecombination of direct translationengines and the interaction led by DMM.The interaction is not always broughtinto the role, and it only works when theformer translation engines work failed.
(2) The interaction is impersonative, target-oriented, and led by the system, notblind.
The user does not need to correctall of the errors in the results of SR. Heor she only needs to concern what thesystem asks.
(3) The system can always give the resultsfor an input speech despite of the ill-formed expressions and the worserecognition results.Although the whole experimental system is underconstruction, some preliminary results have beengained.
Zong (2000c) reported the performance ofthe template-based translator; Xie (2002) reportedthe results of the robust parser for the Chinesespoken language; Xu (2001) presented the resultsof dialogue model; and so on.
The results havemade us confident to develop the practical S2Stranslation system based on the dialoguemanagement.
However, we are facing much hardwork that involve the following aspects at least:?
Develop the reasonable strategies andstandards to evaluate the parsing results;?
Design the effective templates to ask theuser questions according the keywords andthe concrete context;?
Define the practical templates to generatethe translation results;?
Build the machine learning mechanism toenrich the knowledge base of the system.ReferencesBlanchon, H. 1996.
A Customizable InteractiveDisambiguation Methodology and TwoImplementations to Disambiguate French andEnglish Input.
In Proceedings of MIDDIM-96(International Seminar on Multimodal InteractiveDisambiguation), Col de Porte, Fance.Furuse, O., Satsuo Yamada and Kazuhide Yamamoto.1998.
Splitting Long or Ill-formed Input for RobustSpoken-language Translation.
In Proceeding ofCOLING-ACL, Canada.
Vol.
I, pp.
421-427.Lavie, A., Lori Levin et al 1999.
The JANUS-IIITranslation System: Speech-to- Speech Translationin Multiple Domains.
In Proceedings of C-STAR IIWorkshop, Schwetzingen of Germany, 24 Sept.,1999.Ren, F., Shigang Li.
2000.
Dialogue MachineTranslation Based upon Parallel Translation Enginesand Face Image Processing.
In Journal ofINFORMATION?Vol.3, No.4, pp.521-531.Ren, F. 1999.
Super-function Based MachineTranslation, in Communications of COLIPS, 9(1):83-100.Seligman, M. 1997.
Interactive Real-time Translationvia the Internet.
In Working Notes, NaturalLanguage Processing for the World Wide Web.AAAI-97 Spring Symposium, Stanford University.March 24-26, 1997.Seligman, M. 2000.
Nine Issues in Speech Translation.In Machine Translation.
15: 149-185.Waibel, A.
1996.
Interactive Translation ofConversational Speech.
In Proceedings of ATRInternational Workshop on Speech Translation.
pp.1~17.Wahlster, W. 2000.
Mobile Speech-to-SpeechTranslation of Spontaneous Dialogs: An Overviewof the Final Verbmobil System.
In Verbmobil:Foundations of Speech-to-Speech Translation.Springer Press.
pp.
3-21.Wakita, Y., Jun Kawai, Hitoshi Iida.
1997.
Correct PartsExtraction from Speech Recognition Results UsingSemantic Distance Calculation, and Its Applicationto Speech Translation.
In Proceedings of aWorkshop Sponsored by the ACL and by theEuropean Network in Language and Speech(ELSNET).
pp.
24-29.Wu, H., Taiyi Huang, Chengqing Zong, and Bo Xu.2000.
Chinese Generation in a Spoken DialogueTranslation System.
In Proceedings of COLING.
pp.1141-1145.Xie, G., Chengqing Zong, and Bo, Xu.
2002.
ChineseSpoken Language Analyzing Based on Combinationof Statistical and Rule Methods.
Submitted to theInternational Conference on Spoken LanguageProcessing (ICSLP-2002).Xu, W., Taiyi Huang, and Bo Xu.
Towards a GenericDialogue Model for Information-seeking Dialogues.In Proceedings of the National Conference on Man-Machine Speech Communications (NCMMSC6).Shenzhen,  China.
pp.
125-130.Yamamoto, K., Satoshi Shirai, Masashi Sakamoto, andYujie Zhang.
2001.
Sandglass: Twin ParaphrasingSpoken Language Translation.
In Proceedings of the19th International Conference on ComputerProcessing of Oriental Languages (ICCPOL- 2001).pp.
154-159.Zhao, T. et al 2000.
The Principle of MachineTranslation (in Chinese).
Press of Harbin Institute ofTechnology.Zong, C., Taiyi Huang and Bo XU.
1999.
TechnicalAnalysis on Automatic Spoken LanguageTranslation Systems (in Chinese).
In Journal ofChinese Information Processing, 13(2):55-65.Zong, C., Taiyi Huang and Bo Xu.
2000a.
Design andImplementation of a Chinese-to-English SpokenLanguage Translation System.
In Proceedings of theInternational Symposium of Chinese SpokenLanguage Processing (ISCSLP-2000), Beijing,China.
pp.
367-370.Zong, C., Yumi Wakita, Bo Xu, Kenji Matsui andZhenbiao Chen.
2000b.
Japanese-to-Chinese SpokenLanguage Translation Based on the SimpleExpression.
In Proceedings of InternationalConference on Spoken Language Processing(ICSLP-2000).
Beijing, China.
pp.
418-421.Zong, C., Taiyi Huang and Bo Xu.
2000c.
An ImprovedTemplate-based Approach to Spoken LanguageTranslation.
In Proceedings of InternationalConference on Spoken Language Processing(ICSLP-2000).
Beijing, China.
pp.
440-443.
