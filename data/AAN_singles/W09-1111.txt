Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 75?83,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsMining the Web for Reciprocal RelationshipsMichael Paul, Roxana Girju, and Chen LiLinguistics and Computer Science Departments and Beckman Institute,University of Illinois at Urbana-Champaign{mjpaul2, girju, chenli}@illinois.eduAbstractIn this paper we address the problem ofidentifying reciprocal relationships in English.In particular we introduce an algorithm thatsemi-automatically discovers patterns encod-ing reciprocity based on a set of simple buteffective pronoun templates.
Using a set ofmost frequently occurring patterns, we extractpairs of reciprocal pattern instances by search-ing the web.
Then we apply two unsuper-vised clustering procedures to form meaning-ful clusters of such reciprocal instances.
Thepattern discovery procedure yields an accu-racy of 97%, while the clustering proceduresindicate accuracies of 91% and 82%.
More-over, the resulting set of 10,882 reciprocal in-stances represent a broad-coverage resource.1 IntroductionReciprocity is a pervasive concept which has beenstudied a lot in a wide variety of fields from ethicsto game theory where it is analyzed as a highly ef-fective ?tit for tat?
strategy.
The ethic of reciprocity(also known as the golden rule), for example, is amoral code born from social interaction: ?Do ontoothers as you would wish them do onto you?.
Thegolden rule appears in most religions and cultures asa standard used to resolve conflicts.According to sociologists and philosophers, theconcept of reciprocity lies at the foundation of socialorganization.
It strengthens and maintains social re-lations among people, beyond the basic exchange ofuseful goods.
Thus, the way people conceptualizereciprocity and the way it is expressed in languageplay an important role in governing people?s behav-ior, judgments, and thus their social interactions.In this paper we present an analysis of the conceptof reciprocity as expressed in English and present away to model it.
In particular we introduce an al-gorithm that semi-automatically discovers patternsencoding reciprocity based on a set of simple but ef-fective pronoun templates.
We then rank the identi-fied patterns according to a scoring function and se-lect the most frequent ones.
Using these patterns wequery the web and run two unsupervised clusteringprocedures to form meaningful clusters of reciprocalpattern instances.
The pattern discovery procedureyields an accuracy of 97%, while the clustering pro-cedures indicate accuracies of 91% and 82%.
More-over, the resulting set of 10,882 reciprocal instancesrepresent a broad-coverage resource.Next we define the concept of reciprocity as ex-pressed in English.Reciprocity in languageThe Oxford English Dictionary Online1 definesreciprocity as ?a state or relationship in which thereis mutual action, influence, giving and taking, cor-respondence, etc., between two parties?, while inWordNet the verb to reciprocate means ?to act, feel,or give mutually or in return?.Reciprocity is defined as a relation between twoeventualities eo (original eventuality) and er (recip-rocated eventuality), which can occur in various re-ciprocal constructions.
Each eventuality is an event2or a state between two participants.
Thus, the rela-1http://www.oed.com/2We use the term ?event?
to denote all those actions or ac-tivities performed by people.75tion of reciprocity <(eo(X, Y), er(Z, W)) describesa situation where the eventuality er is performed ?inreturn?
for eo.
Thus, reciprocity can be seen as aspecial type of causal relation.The two arguments of each eventuality representthe subject and the object (direct or indirect), in thisorder, and they might not all be explicitely statedin the sentence, but can be inferred.
Moreover, theparticipants of the two eventualities might or mightnot be the same.
A few such examples are presentedbelow with the corresponding reciprocity relations:(1) Mary argued with Paul at the station.<(argue with(Mary, Paul), argue with(Paul Mary)) &<(argue with(Paul, Mary), argue with(Mary, Paul))(2) Paul and Mary hate each other.<(hate(Paul, Mary), hate(Mary, Paul)) &<(hate(Mary, Paul), hate(Paul, Mary))(3) Mary likes Paul and he likes her, too.<(like(Mary, Paul), like(Paul, Mary)) &<(like(Paul, Mary), like(Mary, Paul))(4) Mary likes Paul for helping her sister.<(help(Paul, Mary?s sister), like(Mary,Paul))3As shown in the examples above, in Englishthere are two basic types of reciprocal construc-tions: mono-clausal reciprocals (involving wordssuch as (to) hug, to agree/argue with, partner of, mu-tual(ly), together, each other ?
examples (1) and (2))or sentence-level reciprocals (involving two consec-utive clauses ?
examples (3) and (4)).
Most of thesentence-level reciprocals are paraphrased by coor-dinations or subordinations of two clauses with thesame or different predicate and most of the time in-verted arguments.
They might also manifest variousmarkers as shown in bold in the examples.In this paper we focus only on sentence-level con-structions when the eventualities occur in differentconsecutive clauses, and when the subject ?
objectarguments of each eventuality are personal pronounpairs which occur in reverse order in each eventual-ity.
One such example is ?She likes him for help-ing her?.
Here the two eventualities are like(she,he) and help(he, she).
In this example, although thesubject of the second verb is not explicitely stated,it is easily inferred.
These simplifying assumptions3We assume here that the subject of the verb help has beenrecovered and the coreference solved.will prove very useful in the semi-supervised pat-tern discovery procedure to ensure the accuracy ofthe discovered patterns and their matched instances.Such a resource of reciprocal event pairs canbe very useful in a number of applications, rang-ing from question answering and textual entailment(since reciprocal event pairs encode a type of causalrelation), to behavior analysis of social groups (tomonitor cooperation, trustworthiness and personal-ity), and behavior prediction in negotiations.The paper is organized as follows.
In the next sec-tion we present relevant previous work.
In Section3 we detail a semi-supervised approach of extract-ing patterns which encode reciprocity in English.
Insection 4 we extract pairs of reciprocal instances andcluster them in meaningful clusters.
In section 5 wepresent the experimental data and results.
Discus-sions and conclusion are presented in Section 6.2 Previous workAlthough the concept of reciprocity has been studieda lot in different disciplines such as social sciences(Gergen et al, 1980), anthropology (Sahlins, 1972),economics (Fehr and Gachter, 2000), and philoso-phy (Becker, 1990), linguists have started to lookdeeper into this problem only more recently.
More-over, to the best of our knowledge, in computationallinguistics the problem is novel.In linguistics, most of the work on reciprocity fo-cuses on mono-clausal reciprocal constructions, inparticular on the quantifiers each other and one an-other (Dalrymple et al, 1998; Heim, 1991; Ko?nig,2005).
Most of this work has been done by lan-guage typologists (Maslova and Nedjalkov, 2005;Haspelmath, 2007) who are interested in how recip-rocal constructions of these types vary from one lan-guage to another and they do this through compara-tive studies of large sets of world?s languages.In computational linguistics, our pattern discov-ery procedure extends over previous approachesthat use surface patterns as indicators of semanticrelations between nouns or verbs ((Hearst, 1998;Chklovski and Pantel, 2004; Etzioni et al, 2004;Turney, 2006; Davidov and Rappoport, 2008) interalia).
We extend over these approaches in two ways:(i) our patterns indicate a new type of relation be-tween verbs, (ii) instead of seed or hook words we76use a set of simple but effective pronoun templateswhich ensure the validity of the patterns extracted.To the best of our knowledge, the rest of ourreciprocity model is novel.
In particular, we use anovel procedure which extracts pairs of reciprocalinstances and present two novel unsupervised clus-tering methods which group the instance pairs inmeaningful ways.
We also present some interestingobservations on the data thus obtained and suggestfuture research directions.3 Pattern discovery procedureOur algorithm first discovers clusters of patterns in-dicating reciprocity in English, and then merges theresulting clusters to identify the final set of recipro-cal constructions.
In this section we detail the algo-rithm and evaluate it in subsection 5.2.3.1 Pronoun templatesIn this paper we focus on reciprocal eventualitieswhich occur in two consecutive clauses and havetwo arguments: a subject and an object.
One wayto do this is to fully parse each sentence of a corpusand identify coordinations or subordinations of twoclauses.
Then identify the subject and object argu-ments of each verb in each clause with the help ofa PropBank-style grammatical or semantic role la-beler (Kingsbury et al, 2002) and make sure theyrepresent people named entities (as indicated byproper names, personal pronouns, etc.).
Since ourfocus is on reciprocal constructions, we also have tokeep in mind that the verbs have to have the sameset of arguments (subject-object) in reverse order.Thus, noun and pronoun coreference should also beresolved at this point.Instead of starting with such a complex and error-prone preprocessing procedure, our algorithm con-siders a set of pronoun templates, where personalpronouns are anchor words (they have to be matchedas such).
Each template consists of four personalpronouns corresponding to a subject - object pair inone clause, and a subject - object pair in the otherclause.
Two such examples are?
[Part1] I [Part2] him [Part3] he [Part4] me [Part5]?
and?
[Part1] they [Part2] us [Part3] we [Part4] them [Part5]?,where [Part1] - [Part5] are partitions identifyingany sequence of words.
This is an elegant proce-dure since in English, pronouns have different casessuch as nominative and accusative4 which identifythe subject, and respectively the object of an event.This saves us the trouble of parsing a sentence tofind the grammatical roles of each verb.
In English,there are 30 possible arrangements of nominative -accusative case personal pronoun pairs.
Thus webuilt 30 pronoun templates.This approach is similar to that of seed words(e.g., (Hearst, 1998)) or hook words (e.g., (Davidovand Rappoport, 2008)) in previous work.
However,in our case they are fixed and rich in grammatical in-formation in the sense that they have to correspondto subject - object pairs in consecutive clauses.Since the first two pronouns in each pronoun tem-plate belong to the first clause (C1), and the last twoto the second clause (C2), the templates can be re-stated as [Part1] C1 [Part3] C2 [Part5], with the re-striction that partition 3 should not contain any ofthe four pronouns in the template.
C1 denotes ?Pro-noun1 [Part2] Pronoun2?
and C2 denotes ?Pronoun3[Part4] Pronoun4?.
Partitions 2 and 4 contain theverb phrases (and thus the eventualities) we wouldlike to extract.
For speed and memory reasons, welimit their size to no more than 5 words.Moreover, since the two clauses are consecutive,we hypothesize that they should be very close toeach other.
Thus, we restrict the size of each par-tition 1, 3, and 5 to no more than 5 words.
We thenconsider all possible variations of the pattern wherethe size of each partition varies from 0 to 5.
This re-sults in 216 possible combinations (63).
Moreover,to ensure the accuracy of the procedure, partitions 1and 5 should be bounded to the left and respectivelyto the right by punctuation marks, parentheses, orparagraph boundaries.
An example of an instancematched by one such pattern is ?, I cooked dinnerfor her and she loves me for that .
?3.2 Scoring functionOne way to compute the prominence of the discov-ered patterns would be to consider the frequency ofeach of the five partitions.
However, as our pre-liminary experiments suggest, although individual4In English, the pronouns you has the same form in nomina-tive and accusative.77patterns within each partition do often repeat, rank-ing patterns spanning all three partitions (PART1,PART3, and PART5) is problematic.
Patterns withrelatively long partitions (more than 2 words each)seldomly occur more than once in the entire corpus.Thus frequency would produce very little differenti-ation in ranking the patterns.Thus we developed an alternative scoring systemin lieu of frequencies.
A sequence of size n (seq(n))is an instance of a pronoun template and a subse-quence of size k (seq(k)) is simply a substring of thesequence with k < n. For example, for the instance?I love her and she loves me , too?
of length 9, therewill be two subsequences of length 8: ?love her andshe loves me , too?
and ?I love her and she loves me,?.
Taking into account the frequencies of the subse-quences occurring within instances of each partition,we use the following recursive scoring function (n isthe length of each subsequence of size n):Score(seq(n)) =8><>:Disc(freq(seq(n)))+Pseq(n?1) Disc(Score(seq(n ?
1))), if n> 1freq(seq(n)), if n= 1(1)In addition, in order to ensure a valid rankingover the extracted templates with different lengthsfor each partition, we need to normalize the scoresobtained for PART1, PART3, and PART5.
In otherwords, we need to scale the scores obtained for eachpartition to discount the scores of longer partitions,so that the maximum possible score would remainthe same regardless of how long the partition is.So we use the following formula to compute thediscount for each of PART1, PART3, and PART5,where n is the length of the subsequence:Disc(Score(seq(n))) ={(1.0?
fraction) ?
fractionm?nm?n+1 , if n> 1fractionm?nm?n+1 , if n= 1(2)Fraction is an empirically predetermined parame-ter - here set to 0.5.
The variable m is the length ofthe entire PART1, PART3, or PART5 in question.This allows not only the frequency of the exactpattern to contribute to the score, but also occur-rences of similar patterns, although to a lesser ex-tent.
And since partitions 1, 3, and 5 constitute thesalient parts of the pattern as the environment for thetwo reciprocal clauses C1 and C2, we take the scoreto be ranked as Score(PART1)?Score(PART3)?Score(PART5).We searched the 30 pronoun templates with var-ious partition sizes on a 20 million word Englishcorpus obtained from Project Gutenberg, the largestsingle collection of free electronic books (over27,000) (http://www.gutenberg.org) and British Na-tional Corpus (BNC), an 100 million word collec-tion of English from spoken and written sources.There were 2,750 instances matched which wereranked by the scoring function.
There were 1,613distinct types of patterns which generated 1,866 dis-tinct pattern instances.
Thus, we selected the top15 patterns, after manual validation.
These patternsrepresent 56% of the data (Table 1).
All the otherpatterns were discarded as having very low frequen-cies and being very specific.The manual validation was necessary in order tocollapse some of the identified instances into moregeneral classes.
For example, the patterns ?C1 andC2 to?
(e.g., ?He could not hurt me and I would notwish him to.?
), ?C1 and C2 in?
(e.g., ?I give you andyou take me in.?
), and ?C1 and C2 fast said AuntJane?
(e.g., ?He will come to her and she can holdhim fast said Aunt Jane.?)
were collapsed into ?C1and C2?.
This procedure can be partially solved byidentifying complex verbs such as ?take in?.
How-ever, we leave this improvement for future work.Patterns ExamplesC1 [, |; |.]
C2 I help him; he helps me.C1 and C2 He understands her and she understandshim.C1 and C2 [right] back I kissed him and and he kissed me back.C1 and C2 for that They helped us and we appreciate themfor that.C1 and C2, too I love her and she loves me, too.C1 when C2 He ignores her when she scolds him.C1 whenever C2 He is there for her whenever she needshim.C1 because C2 They tolerate us because we helped them.C1 as much as C2 He loves her as much as she loves him.C1 for C2 (vb-ing) He thanked her for being patient with him.C1 but C2 I loved her but she dumped me.C1 for what C2 They will punish him for what he did tothem.C1 and thus C2 She rejected him and thus he killed her.when C1, C2 When he confronted them, they arrestedhim.C1 as long as C2 She will stay with him as long ashe doesn?t hurt her.Table 1: The top 15 reciprocal patterns along with examples.784 Clustering of Reciprocal EventualitiesIt seems reasonable to expect that certain reciproc-ities could be grouped together.
For example, thelanguage used in convincing a person of some-thing could be characterized by verbs such aseo = {convince, promise, assure, beg} and er ={believe, trust, choose, forgive}.There are many potential uses for this sort ofgrouping.
Having a single group label for multiplereciprocal eventuality pairs would allow us to iden-tify certain language patterns as a particular speechact.
Also, such clusters could be useful if one wantsto perform a macro-level analysis of reciprocity in aspecific domain.
For example, examining reciprocallanguage could be useful in analyzing the nature ofa social community or the theme of a literary work.Generalizing over many similar instances, will giveus better insight into how people communicate ?
asreactions (effects) to other people?s actions (causes).Thus, in this section we present a model for clus-tering the eventualities we extract through the pro-cess described in the previous sections.
Experimen-tal results are presented in Section 5.4.1 Representing the dataAfter obtaining these patterns, we must extract pairsof eventualities of the form (eo, er).
This involvesboth reducing the clauses into a form that is seman-tically representative of some eventuality, as well asdetermining the order of the two eventualities (i.e.,if they are asymmetric).As shown in the previous sections, each pat-tern contains two clauses of the form ?Pronouni[Part2/4] Pronounj?, where the first pronouns isthe subject and the second is the object.
Fromeach clause we extract only the non-auxiliary verb,as it carries the most meaning.
We first stem theverb and then negate it if it is preceded by not orn?t.
For example, ?They do not like him becausehe snubbed them?
is represented as the eventualities(eo, er) = (snub,?like).Certainly, we are missing important informationby excluding phrases and ignoring modality.
How-ever, these features can be difficult to capture accu-rately, and since inaccurate input could degrade theclustering accuracy, in this research we stick withthe important and easily-obtainable features.4.2 Ordering the eventualitiesMost patterns entail a particular ordering of the twoeventualities, corresponding to symmetric (e.g., ?Heloves her and she loves him?)
or asymmetric eventu-alities (e.g., ?He ignores her when she scolds him?
).In ambiguous situations (e.g., He loves her and sheloves him?
and ?He cheated on her and she stillloves him!?
), we determine the order through cluessuch as the relative temporal ordering of the verbs asdetermined by their tense (e.g., past or present tensehappens before future tense) and whether the verbsdenote an action (e.g., ?to chase?)
or a state (e.g.,?to love?).
For this we rely on our previous work(Girju, 2009) where we identified the order of even-tualities based on a set of such features employed ina semi-supervised model whose accuracy is 90.2%.4.3 Modeling the relationshipsThe extracted eventuality pairs can be representedas a bipartite graph with a node for all eo valuesin one partition, a node for all er values in anotherpartition, and an edge between these nodes for each(eo, er) pair.
An intuitive way to cluster these even-tualities is to find groups of nodes such that eachnode in one partition has an edge to every node inthe other partition and vice versa.
This is a form ofhard-clustering, as membership in a cluster is strictlyyes or no.
The goal is that one could randomly pullan eo and an er from a given cluster and the reci-procity would be valid.
For example, ?help?
and?give?
could both be reciprocated by either ?thank?or ?like?.
Thus, given a cluster, not only is there areciprocal relationship between verbs in the eo groupwith the verbs in the er group, but there is oftena kind of similarity relationship between the verbswithin each eo or er group.This approach gives precise and concrete relationsbetween verbs, but while it could be well-suitedto some applications (such as knowledge base con-struction or automatic verb classification (Joanis etal., 2008)5) it has disadvantages in the context ofgrouping these verbs together.
The clusters are smalland sparse, and the results are difficult to interpret,as there are many overlapping clusters.5These verb classes correspond to some extent to the Verb-Net (Kipper et al, 2000) or FrameNet-style (Baker et al, 1998)verb classes such as admire, judgment.79............cheathurtforgivedespisehatebetrayFigure 1: A sample of our data as a bipartite graph.
Some edges havebeen omitted for readability.
The nodes {eo=?betray?, eo=?cheat?,er=?despise?, er=?hate?}
form a cluster with our hard-clustering ap-proach.We instead adopt a probabilistic framework,which allows us to relax the restrictiveness ofthe clusters while retaining information about thestrength of the pairwise relations.
Thus, we designa bimodal mixture model in which we assume thateach pair of eventualities (eo, er) belongs to a latentclass z, and each class is associated with two distinctmultinomial distributions from which the two even-tualities are independently drawn.
Thus, the proba-bility of generating a particular pair is:P (eo, er) =|Z|?kP (eo|z = k)P (er|z = k) (3)Each class can be thought of as a general type ofreciprocity, such as an action followed by apprecia-tion, or an attack followed by retaliation.
We shouldbe clear that each class is characterized not by a dis-tribution of specific pairs, but by a distribution ofeo verbs and a distribution of er verbs.
This allowsfor the classification of (eo, er) pairs that do not ap-pear in the corpus.
For example, if we have not seenthe pair (slap, punch), but we know that (slap, hit)and (kick, punch) belong to the same class, then itis likely that (slap, punch) is in the same group.This model can be used in a fully supervised aswell as a semi-/unsupervised setting.
If some orall of the class labels are unknown, we can learnthe model parameters using an estimator such asExpectation-Maximization (EM) (Dempster et al,1977).
For each eventuality pair ci in a collectionC, we update P (z = k|ci) with the following equa-tion, which represents the E-step:P (z|ci) ?
P (z)P (e(ci)o |z)P (e(ci)r |z) (4)In the M-step, we use the following update equa-tions:P (z = k) ?
?
+|C|?iP (z = k|ci) (5)P (eo = j|z) = ?
+?|C|i I(e(ci)o = j)P (z|ci)|Eo|?
+?j?
?i I(e(ci)o = j?
)P (z|ci)(6)where I is a binary indicator function.
The equa-tion for P (er = j|z) is identical to that for eo, butwith er instead6.?
and ?
are the hyperparameters of the uniformDirichlet priors of P (z) and P (e?|z).
They canbe tuned to control the level of smoothing; a valueof 1.0 is equivalent to the commonly-used Laplacesmoothing (Nigam et al, 2000).4.4 Identifying polarity wordsSince we are interested in analyzing how people in-teract, we would also like to identify the polarity(affective value) associated with each eventuality.Thus, we automatically identify polarity words inboth clauses.
For this we consider the standard po-larity values: Good, Bad, and Neutral.In the next section we present in detail the resultsof the evaluation.5 Experimental data and results5.1 Data collectionWhile the Gutenberg and BNC collections are use-ful in obtaining the frequent patterns, they do notcontain a very large number of eventuality pairsto do meaningful clustering.
We thus query theweb through Google to easily obtain thousands ofexamples.
We queried each of the top 15 pat-terns and all pronoun combinations thereof (e.g.
?they * us because we * them?)
and took the top500 results for each pattern/pronoun combination(15*30*500)7.
We then extracted the clauses fromthe result snippets using the procedure outlined inthe previous section and ended up with 10,882 pairs6We sometimes use the shorthand P (z) to represent P (z =k), which is updated for each particular value of z.7This is because Google limits traffic.
However, in the futurewe can acquire more instances.80(4,403 unique pairs) since some of the queries hadless than 500 matched instances8.5.2 Pattern discovery procedureSince we wanted to see to what extent the 15 mostfrequently occurring patterns encode reciprocity, weselected a sample of 10 pattern instances matchedby each pattern in the text collection obtained fromthe web.
We presented the resulting 130 sentences(a few patterns were not frequent on the web, so weobtained a few less than 10 instances) to 2 judgeswho evaluated them as encoding reciprocity (?yes?
)or not (?no?).
The judges agreed 97% of the time.Moreover, only 2.3% of the 130 pattern instancesdid not encode reciprocity as agreed by both judges.These statistics show that these patterns are highlyaccurate indicators of reciprocity in English.5.3 Unsupervised clusteringWe can capture pattern instance clusters with noprior labeling by initializing the EM parameters ran-domly.
In our experiments we used ?
= 1.0 and?
= 0.01, with varying numbers of clusters (whichwe denote as k).
EM is sensitive to the initial pa-rameters and can perform poorly due to many localmaxima.
We thus ran the algorithm several times,and saved the output with the best log-likelihood.Results from clustering with k = 6 are shownin Table 2.
The examples shown correspond to arandom sample of 10 pairs within the top 10% ofP (eo, er|cluster) within each cluster.
We find thatwith larger values of k such as 30 or 50, some of theclusters become noisier, but we can capture finer-grained clusters such as eo = {libel, defame} ander = {sue,?sue}.Upon a close look at the clusters in Table 2, onecan see that each one seems to have a central theme.Cluster 1 seems to contain mostly positive actionsreciprocated by verbs describing gratitude and ap-preciation.
Cluster 2 has to do with cognition; Clus-ter 3 has to do with the way people communicate andinteract.
Cluster 4 captures relationships of need anddesire.
Cluster 5 is about love and adoration, whileCluster 6 is about hate and other negative events, andhow they are reciprocated.8The reciprocity dataset is available for download athttp://apfel.ai.uiuc.edu/resources.html.AccuracyNo.
instances 6 clusters 9 clustersTop 20 90.8% 82.2%20/100 71.7% 66.1%20/All 34.2% 26.1%Table 3: Cluster membership accuracy for 6 and 9 clusters.Cluster membership is defined as argmaxcP (eo|c) P (er|c).
We took three samples of pairs:(1) the top 20 pairs with the highest P (eo, er|c) val-ues, (2) a random 20 of the top 10%, and (3) a ran-dom 20 of all pairs assigned to each cluster.
We pre-sented the pairs to two judges who were asked toidentify each pair as belonging to the cluster or notbased on coherence; that is, all pairs labeled ?yes?appear to be related in some way.Because we fix the number of clusters, we aremaking the assumption that each reciprocal paircould be put into one of k groups, which is obviouslyan assumption that will not hold true.
However, if apair does not fit well into any of the clusters, thisshould be reflected by a low probability.
Thus wecan achieve decently high accuracy if we consideronly the highest-ranked pairs.
The accuracy whenconsidering all pairs is only 34% which means that34% of reciprocal pairs can be meaningfully placedinto only 6 groups, which is actually fairly high.A big source of inter-annotator disagreementcomes from the ambiguity of certain verbs, whichis a weakness of our limited representation.
For ex-ample, without additional information it is not clearhow a pair like (know, ask) might relate to others.5.4 Polarity word identificationFor this procedure we used the Subjectivity Clues(Wilson et al, 2005) which provides 8,220 entries.From all the 10,882 eventuality pairs, 40.1% of thetotal number of words were in the subjectivity lexi-con, while 36.9% of the pairs had both words in thesubjectivity lexicon.Table 4 shows all possible combinations of pairsof affective values and their associated probabilitiesin the corpus.
These values are computed for thosepairs where both words have known polarity.As one might expect, each polarity class is mostlikely to be reciprocated by itself: Good for Good(altruism) and Bad for Bad (retaliation).
Further-more, it is more likely that Good follows Bad (?turn81eo er eo er eo er eo er eo er eo erhelp thank know respect call tell need need love love hate hateallow thank trust know ask give need trust adore love attack hateinvite thank tell trust tell help want need understand love attack forgiverescue thank tell know tell tell want trust love adore slap hatejoin thank know know contact tell want want teach love hurt attackinform thank know trust meet hear help need protect love betray punishjoin admire know follow follow see offer need feed love kill hatesend thank give let watch send help help challenge love hit cursesupport thank let like tell ignore help trust need love treat disliketeach owe help marry confront tell love need give love ruin shootTable 2: The clusters induced after running our unsupervised algorithm with k = 6 clusters.
The pairs correspond to a sample of the top 10% ofpairs with the highest value of P (eo, er|cluster) for each cluster.Good Bad Neutral TotalGood 0.90 0.18 0.29 0.63Bad 0.09 0.82 0.08 0.29Neutral 0.01 0.002 0.63 0.09Table 4: All possible combinations of pairs of affective values andtheir associated probabilities as found in the corpus.
The numbers in thetable correspond to conditional probabilities P(rowi|colj ).
The Totalcolumn indicates the probability of each affective class (P(rowi)).the other cheek?)
than that Bad follows Good.We experimented with incorporating polarity intoour clustering process.
We defined 9 clusters foreach combination of polarity pairs, and initializedthe model by labeling the eventuality pairs wherethe polarity of both words was known.
We thenran the EM process on all of the pairs, and sincethe model parameters were initialized with these 9groups, their pairs were more likely to fit into clus-ters that matched their polarity.
We found, how-ever, that it had trouble clustering the less-commonclasses ?
essentially, everything but (Good, Good)and (Bad, Bad).
For example, the cluster that wasinitialized as (Bad, Good) ended up being dominatedby er = thanks and mostly positive-polarity wordsas eo.
This seems to be due to the fact that many ofthese pairs included er = thanks (often in sarcasm,as in ?he thanked them for embarrassing him?).
Butthere are many more words associated with thanksthat are Good, thus those pairs were put into thesame group, and the Good verbs eventually overtookthe cluster.
Problems such as this could perhaps beavoided with more varied labeled data.We selected a sample of the top 20 pair instancesfor each of the 9 clusters of polarity pairs and gavethem to 2 judges who agreed 82% of the time.6 Discussion and ConclusionsIn this paper we presented an analysis of the conceptof reciprocity as expressed in English and a way tomodel it.
The experimental results provided nice in-sights into the problem, but can be further improved.We noticed that the identification of polaritywords is not always enough to capture the affect ofeach eventuality.
Thus, the text needs to be furtherprocessed to identify speech acts corresponding toeach clause in the reciprocal patterns.
For exam-ple, words such as ?sorry?
can be classified as neg-ative, while the entire clause ?I am sorry?
capturesthe speech act of APOLOGY which is associated withgood intentions.
As future work, we will reclusterthe reciprocity pairs.Another observation concerns the reciprocityproperty of magnitude (cf.
(Jackendoff, 2005))or equivalence of value between two eventualities.Most of the time reciprocal eventualities have thesame or similar magnitude, as the patterns identifiedindicate a more or less equivalence of value ?
i.e.,hugs for kisses, thanks for help.
And most of theseconstructions do not focus so much on the magni-tude, but on the order in which one eventuality (theeffect) is a reaction to the other (the cause).
How-ever, a closer look at our data shows that there arealso constructions which indicate this property moreprecisely.
One such example is ?C1 as much as C2?where even a negation in C1 or C2 might destroy themagnitude balance (e.g., ?She does not love him asmuch as he loves her.?
).We would like to study this property in more de-tail as well.
This kind of study is very importantin the analysis of people?s behavior, judgments, andthus their social interactions.82ReferencesC.
Baker, Ch.
Fillmore, and J. Lowe.
1998.
The BerkeleyFrameNet Project.
In Proceedings of the 36th AnnualMeeting of the Association for Computational Linguis-tics and 17th International Conference on Computa-tional Linguistics (COLING-ACL 1998), pages 86?90,Montreal, Canada.L.
Becker, editor.
1990.
Reciprocity.
University ofChicago Press, Chicago.T.
Chklovski and P. Pantel.
2004.
Verbocean: Miningthe web for fine-grained semantic verb relations.
InProceedings of the Empirical Methods in Natural Lan-guage Processing (EMNLP) Conference.M.
Dalrymple, M. Kazanawa, Y. Kim, S. Mchombo,and S. Peters.
1998.
Reciprocal expressions and theconcept of reciprocity.
Linguistics and Philosophy,21:159?210.D.
Davidov and A. Rappoport.
2008.
Unsuperviseddiscovery of generic relationships using pattern clus-ters and its evaluation by automaticaly generated satanalogy questions.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics (ACL).A.
P. Dempster, N.M. Laird, and D. B. Rdin.
1977.Maximum likelihood from incomplete data via the EMalgorithm.
Journal of the Royal Statistical Society,39:1?38.O.
Etzioni, M. Cafarella, D. Downey, A. Popescu,T.
Shaked, S. Soderland, D. Weld, and A. Yates.
2004.Methods for domain-independent information extrac-tion from the web: An experimental comparison.
InProceedings of the National Conference on ArtificialIntelligence (AAAI) Conference.E.
Fehr and S. Gachter.
2000.
Cooperation and Punish-ment in Public Goods Experiments.
American Eco-nomic Review, 90:980?994.K.
Gergen, M. Greenberg, and R. Willis, editors.
1980.Social Exchange: Advances in Theory and Research.New York: Plenum.R.
Girju.
2009.
Reciprocity in language.
In TechnicalReport.
University of Illinois at Urbana-Champaign.M.
Haspelmath.
2007.
Further remarks on reciprocalconstructions.
In Vladimir P. Nedjalkov, editor, Re-ciprocal Constructions, pages 2087?2115.M.
Hearst.
1998.
Automated Discovery of WordNet Re-lations.
In Christiane Fellbaum, editor, An ElectronicLexical Database and Some of its Applications, pages131?151.
MIT Press, Cambridge, MA.I.
Heim.
1991.
Reciprocity and plurality.
Linguistic In-quiry, 22:63?101.R.
Jackendoff.
2005.
The peculiar logic of value.
Jour-nal of Cognition and Culture, 6:375?407.E.
Joanis, S. Stevenson, and D. James.
2008.
A generalfeature space for automatic verb classification.
Natu-ral Language Engineering, 14(3).P.
Kingsbury, M. Palmer, and M. Marcus.
2002.
AddingSemantic Annotation to the Penn Treebank.
In Pro-ceedings of the 2nd Human Language TechnologyConference (HLT 2002), pages 252?256, San Diego,California.K.
Kipper, H. Trang Dang, and M. Palmer.
2000.
Class-based construction of a verb lexicon.
In Proceedingsof the National Conference on Artificial Intelligence(AAAI), pages 691?696, Austin, TX.E.
Ko?nig.
2005.
Reciprocity in language: Cultural con-cepts and patterns of encoding.
Uhlenbeck Lecture,23.E.
Maslova and V. Nedjalkov.
2005.
Reciprocal con-structions.
In M. Haspelmath, M. Dryer, D. Gill,and B. Comrie, editors, The World Atlas of LanguageStructures, pages 430?433.
New York: Oxford Univer-sity Press.K.
Nigam, A. McCallum, S. Thrun, and T. Mitchell.2000.
Text classification from labeled and unlabeleddocuments using EM.
Machine Learning, 39:103?134.M.
Sahlins, editor.
1972.
Stone Age Economics.Chicago: Aldine-Atherton.P.
Turney.
2006.
Similarity of semantic relations.
Com-putational Linguistics, 32(3):379?416.T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recogniz-ing contextual polarity in phrase-level sentiment anal-ysis.
In Proceedings of the Human Language Technol-ogy (HLT/EMNLP) Conference.83
