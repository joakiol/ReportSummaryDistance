Automatic Extraction of English-Chinese Transliteration Pairsusing Dynamic Window and TokenizerChengguo JinDept.
of Graduate School for InformationTechnology, POSTECH, Koreachengguo@postech.ac.krDong-Il KimLanguage Engineering Institute, YUST,Chinadongil@ybust.edu.cnSeung-Hoon NaDept.
of Computer Science & EngineeringPOSTECH, Koreansh1979@postech.ac.krJong-Hyeok LeeDept.
of Computer Science & EngineeringPOSTECH, Koreajhlee@postech.ac.krAbstractRecently, many studies have been focusedon extracting transliteration pairs from bi-lingual texts.
Most of these studies arebased on the statistical transliteration mod-el.
The paper discusses the limitations ofprevious approaches and proposes novelapproaches called dynamic window and to-kenizer to overcome these limitations.
Ex-perimental results show that the averagerates of word and character precision are99.0% and 99.78%, respectively.1 IntroductionMachine transliteration is a type of translationbased on phonetic similarity between two lan-guages.
Chinese Named entities including foreignperson names, location names and company names,etc are usually transliterated from foreign words.The main problem of transliteration resulted fromcomplex relations between Chinese phonetic sym-bols and characters.
Usually, a foreign word can betransliterated into various Chinese words, andsometimes this will lead to transliteration complex-ity.
In addition, dozens of Chinese characters cor-respond to each pinyin which uses the Latinalphabet to represent sounds in Standard Mandarin.In order to solve these problems, Chinesegovernment published the ?Names of the world'speoples?
[12] containing 630,000 entries in 1993,which took about 40 years.
However, some newforeign names still cannot be found in the diction-ary.
Constructing an unknown word dictionary is adifficult and time consuming job, so in this paperwe propose a novel approach to automatically con-struct the resource by efficiently extracting trans-literation pairs from bilingual texts.Recently, much research has been conducted onmachine transliteration.
Machine transliteration isclassified into two types.
One is automatic genera-tion of transliterated word from the source lan-guage [6]; the other one is extracting transliterationpairs from bilingual texts [2].
Generally, the gen-eration process performs worse than the extractionprocess.
Especially in Chinese, people do not al-ways transliterate foreign words only by sound butalso consider the meanings.
For example, the word?blog?
is not transliterated into ????
?
(Bu-LaoGe) which is phonetically equivalent to thesource word, but transliterated into ????
(BoKe)which means ?a lot of guests?.
In this case, it is toodifficult to automatically generate correct translit-eration words.
Therefore, our approach is based onthe method of extracting transliteration pairs frombilingual texts.The type of extraction of transliteration pairs canalso be further divided into two types.
One is ex-tracting transliteration candidates from each lan-guage respectively, and then comparing the pho-netic similarities between those candidates of twolanguages [2, 8].
The other one is only extractingtransliteration candidates from the source language,and using the candidates to extract correspondingtransliteration words from the target language [1].In Chinese, there is no space between two wordsand no special character set to represent foreignwords such as Japanese; hence the candidate ex-traction is difficult and usually results in a low pre-cision.
Therefore, the method presented in [2]which extracted transliteration candidates from9Sixth SIGHAN Workshop on Chinese Language Processingboth English and Chinese result in a poor perform-ance.
Compared to other works, Lee[1] only ex-tracts transliteration candidates from English, andfinds equivalent Chinese transliteration wordswithout extracting candidates from Chinese texts.The method works well, but the performance isrequired to be improved.
In this paper we present anovel approaches to obtain a remarkable result inextracting transliteration word pairs from paralleltexts.The remainder of the paper is organized as fol-lows: Section 2 gives an overview of statisticalmachine transliteration and describes proposedapproaches.
Section 3 describes the experimentalsetup and a quantitative assessment of performanceof our approaches.
Conclusions and future workare presented in Section 4.2 Extraction of English-Chinese translit-eration pairsIn this paper, we first extract English named en-tities from English-Chinese parallel texts, and se-lect only those which are to be transliterated intoChinese.
Next we extract Chinese transliterationwords from corresponding Chinese texts.
[Fig.
1]shows the entire process of extracting translitera-tion word pairs from English-Chinese parallel texts.
[Fig 1].
The process of extracting transliteration pairs fromEnglish-Chinese parallel corpus2.1 Statistical machine transliteration modelGenerally, the Chinese Romanization system pin-yin which is used to represent the pronunciation ofeach Chinese character is adopted in Chinese trans-literation related studies.
For example, the Chineseword ?????
is first transformed to pinyin ?KeLin Dun?, and we compare the phonetic similaritiesbetween ?Clinton?
and ?KeLinDun?.
In this paper,we assume that E is written in English, while C iswritten in Chinese, and TU represents translitera-tion units.
So P(C|E), ?
?P( ?
|Clinton) can betransformed to P(KeLinDun|Clinton).
In this paperwe define English TU as unigram, bigram, and tri-gram; Chinese TU is pinyin initial, pinyin final andthe entire pinyin.
With these definitions we canfurther write the probability, ?
?P( ?|Clinton), asfollows:(P ???
| Clinton ) ?
)|( ClintonkelindunP?
)|()|()|()|()|( onunPdtPininPllPCkeP (1)[Fig 2].
TU alignment between English and Chinese pinyin[Fig 2] shows the possible alignment between Eng-lish word ?Clinton?
and Chinese word ?????
?spinyin ?KeLinDun?.In [1], the authors add the match type informa-tion in Eq.
(1).
The match type is defined with thelengths of TUs of two languages.
For example, inthe case of )|( CkeP the match type is 2-1, be-cause the size of Chinese TU ke is 2 and the sizeof English TU C is 1.
Match type is useful whenestimating transliteration model?s parameters with-out a pronunciation dictionary.
In this paper, weuse the EM algorithm to estimate transliterationmodel?s parameters without a pronunciation dic-tionary, so we applied match type to our model.Add Match type(M) to Eq.
(1) to formulate as fol-lows:)|(),|(max)|( EMPEMCPECPM?
)(),|(max MPEMCPM?
(2)( )?=+?NiiiiMmPuvPECP1)(log)|((logmax)|(log  (3)10Sixth SIGHAN Workshop on Chinese Language Processingwhere u, v are English TU and Chinese TU, re-spectively and m is the match type of u and v.[Fig 3].
The alignment of the English word and the Chinesesentence containing corresponding transliteration word[Fig 3] shows how to extract the correct Chinesetransliteration ??
??
(KeLinDun) with the givenEnglish word ?Clinton?
from a Chinese sentence.2.2 Proposed methodsWhen the statistical machine transliteration isused to extract transliteration pairs from a paralleltext, the problems arise when there is more thanone Chinese character sequence that is phoneticallysimilar to the English word.
In this paper we pro-pose novel approaches called dynamic window andtokenizer to solve the problems effectively.2.2.1 Dynamic window methodThe dynamic window approach does not find thetransliteration at once, but first sets the windowsize range according to the English word candi-dates, and slides each window within the range tofind the correct transliterations.
[Fig 4].
Alignment result between English word ?Clinton?and correct Chinese transliteration, add a character into correctChinese transliteration, and eliminate a character from correctChinese transliteration.If we know the exact Chinese transliteration?ssize, then we can efficiently extract Chinese trans-literations by setting the window with the length ofthe actual Chinese transliteration word.
For exam-ple, in [Fig 4] we do alignment between the Eng-lish word ?Clinton?
and correct Chinese translit-eration ?????
(KeLinDun), add a character intocorrect Chinese transliteration ?
?
?
???
(KeLinYiDun), and eliminate a character fromcorrect Chinese transliteration ?
?
?(LinDun)respectively.
The result shows that the highestscore is the alignment with correct Chinese trans-literation.
This is because the alignment betweenthe English word and the correct Chinese translit-eration will lead to more alignments between Eng-lish TUs and Chinese TUs, which will result inhighest scores among alignment with other Chi-nese sequences.
This characteristic does not onlyexist between English and Chinese, but also existsbetween other language pairs.However, in most circumstances, we can hardlydetermine the correct Chinese transliteration?slength.
Therefore, we analyze the distribution be-tween English words and Chinese transliterationsto predict the possible range of Chinese translitera-tion?s length according to the English word.
We11Sixth SIGHAN Workshop on Chinese Language Processingpresent the algorithm for the dynamic window ap-proach as follows:Step 1: Set the range of Chinese transliteration?slength according to the extracted English wordcandidate.Step 2: Slide each window within the range tocalculate the probability between an English wordand a Chinese character sequence contained in thecurrent window using Eq 3.Step 3: Select the Chinese character sequencewith highest score and back-track the alignmentresult to extract the correct transliteration word.
[Fig 5] shows the entire process of using the dy-namic window approach to extract the correcttransliteration word.English Word ZieglerChinese Sentence ??
?
???
??
?1963 ??
??
?English Sentence Ziegler and Italian Chemist Julio re-ceived the Nobel prize of 1963 together.Extracted translit-eration withoutusing dynamicwindow??
?
(JiaJuLiAo)Correct translitera-tion ??
(QiGeLe)Steps1.
Set Chinese transliteration?s range according to Englishword ?Ziegler?
to [2, 7] (After analyzing the distribution be-tween an English word and a Chinese transliteration word, wefound that if the English word length is ?, then the Chinesetransliteration word is between ?/3 and?.)2.
Slide each window to find sequence with highest score.3 Select the Chinese character sequence with highest score andback-track the alignment result to extract a correct translitera-tion word.Win-dowsizeChinese character sequence with high-est score of each window (underlinethe back-tracking result)Score(normal-ize withwindowsize)2 ?
(QiGe) -9.3273 ??
(QiGeLe) -6.2904 ??
?
(QiGeLeYu) -8.4335 ??
?
(QiGeLeYuYi) -9.7196 ??
??
(JiaJuLiAoGongTong) -10.4587 ??
?
(QiGeLeYuYiDaLi) -10.721[Fig 5].
Extract the correct transliteration using the dynamicwindow methodThe dynamic window approach can effectivelysolve the problem shown in [Fig 5] which is themost common problem that arises from using sta-tistical machine transliteration model to extract atransliteration from a Chinese sentence.
However,it can not handle the case that a correct translitera-tion with correct window size can not be extracted.Moreover, when the dynamic window approach isused, the processing time will increase severely.Hence, the following approach is presented to dealwith the problem as well as to improve the per-formance.2.2.2 Tokenizer methodThe tokenizer method is to divide a sentencewith characters which have never been used inChinese transliterations and applies the statisticaltransliteration model to each part to extract a cor-rect transliteration.There are certain characters that are frequentlyused for transliterating foreign words, such as?(shi)?
(de)?
(le)?
(he) ??.
On the otherhand, there are other characters, such as ?
(shi),(de)?
(le)?
(he),?
?, that have never beenused for Chinese transliteration, while they arephonetically equivalent with the above characters.These characters are mainly particles, copulas andnon-Chinese characters etc., and always come withnamed entities and sometimes also cause someproblems.
For example, when the English word?David?
is transliterated into Chinese, the last pho-neme is omitted and transliterated into ???(DaWei).
In this case of a Chinese charactersuch as ?
?
(De) which is phonetically similarwith the omitted syllable ?d?, the statistical translit-eration model will incorrectly extract ?
??
(DaWeiDe) as transliteration of ?David?.
In [1],the authors deal with the problem through a post-process using some linguistic rules.
Lee and Chang[1] merely eliminate the characters which havenever been used in Chinese transliteration such as?
?
(De) from the results.
Nevertheless, the ap-proach cannot solve the problem shows in [Fig 6],because the copula ?
?
(Shi) combines with theother character ?
?
(zhe) to form the charactersequence ?
?
(ZheShi) which is phoneticallysimilar with the English word ?Jacey?, and is in-correctly recognized as a transliteration of ?Jacey?.Thus, in this case, although the copula ?
?
(Shi) is12Sixth SIGHAN Workshop on Chinese Language Processingeliminated from the result through the post-processmethod presented in [1], the remaining part is notthe correct transliteration.
Compared with themethod in [1], our tokenizer approach eliminatescopula ?
?
(Shi) at pre-processing time and thenthe phonetic similarity between ?Jacey?
and theremaining part ?
?
(Zhe) becomes very low; henceour approach overcomes the problem  prior to theentire process.
In addition, the tokenizer approachalso reduces the processing time dramatically dueto separating a sentence into several parts.
[Fig 6]shows the process of extracting a correct translit-eration using the tokenizer method.English Word JaceyChinese Sentence ?
?
??
?
?English Sentence The authors of this book are Peni-nah  Thomson and Jacey  Grahame.Incorrectly extractedtransliteration (ZheShi)Correct transliteration ?
(JieXi)Steps1.
Separate the Chinese sentence with characters, ?
?, , ,??
(including non-Chinese characters such as punctuation,number, English characters etc.
), which have never been usedin Chinese transliteration as follows:?
?
?
????2.
Apply statistical transliteration model to each part and se-lect the part with highest score, and back-track the part to ex-tract a correct transliteration.No.Chinese character sequence ofeach part (underline the back-tracking result)Score(normalize withwindow size)1 ?
(BenShu) -24.792  (ZuoZhe) -15.833 ?
(PeiNiNaTangMuShen) -16.324 ?
????
(JieXi) -10.29[Fig 6].
Extracting the correct transliteration using the to-kenizer method.In conclusion, the two approaches complementeach other; hence using them together will lead toa better performance.3  ExperimentsIn this section, we focus on the setup for the ex-periments and a performance evaluation of theproposed approaches to extract transliteration wordpairs from parallel corpora.3.1 Experimental setupWe use 300 parallel English-Chinese sentencescontaining various person names, location names,company names etc.
The corpus for training con-sists of 860 pairs of English names and their Chi-nese transliterations.
The performance of translit-eration pair extraction was evaluated based on pre-cision and recall rates at the word and characterlevels.
Since we consider exactly one proper namein the source language and one transliteration inthe target language at a time, the word recall ratesare the same as the word precision rates.
In orderto demonstrate the effectiveness of our approaches,we perform the following experiments: firstly, onlyuse STM(Statistical transliteration model) which isthe baseline of our experiment; secondly, we applythe dynamic window and tokenizer method withSTM respectively; thirdly, we apply these twomethods together; at last, we perform experimentpresented in [1] to compare with our methods.3.2 Evaluation of dynamic window and to-kenizer methods[table 1].
The experimental results of extractingtransliteration pairs using proposed methodsMethods Word  precisionCharacterprecisionCharacterrecallSTM (baseline) 75.33% 86.65% 91.11%STM+DW 96.00% 98.51% 99.05%STM+TOK 78.66% 85.24% 86.94%STM+DW+TOK 99.00% 99.78% 99.72%STM+CW 98.00% 98.81% 98.69%STM+CW+TOK 99.00% 99.89% 99.61%As shown in table 1, the baseline STM achievesa word precision rate of 75%.
The STM worksrelatively well with short sentences, but as thelength of sentences increases the performance sig-nificantly decreases.
The dynamic window ap-proach overcomes the problem effectively.
If thedynamic window method is applied with STM, themodel will be tolerant with the length of sentences.The dynamic window approach improves the per-formance of STM around 21%, and reaches theaverage word precision rate of 96% (STM+DW).In order to estimate the highest performance thatthe dynamic window approach can achieve, weapply the correct window size which can be ob-tained from the evaluation data set with STM.
Theresult (STM+CW) shows around 98% word preci-13Sixth SIGHAN Workshop on Chinese Language Processingsion rate and about 23% improvement over thebaseline.
Therefore, dynamic window approach isremarkably efficient; it shows only 2% differencewith theoretically highest performance.
However,the dynamic window approach increases the proc-essing time too much.When using tokenizer method (STM+TOK),only about 3% is approved over the baseline.
Al-though the result is not considerably improved, it isextremely important that the problems that the dy-namic window method cannot solve are managedto be solved.
Thus, when using both dynamic win-dow and tokenizer methods with STM (STM+DW+TOK), it is found that around 3% improve-ment is achieved over using only the dynamic win-dow (STM+DW), as well as word precision ratesof 99%.
[table 2].
Processing time evaluation of proposed methodsMethods Processing timeSTM (baseline) 5 sec (5751 milisec)STM+DW 2min 34sec (154893 milisec)STM+TOK 4sec (4574 milisec)STM+DW+TOK 32sec (32751 milisec)Table 2 shows the evaluation of processing timeof dynamic window and tokenizer methods.
Usingthe dynamic window leads to 27 times more proc-essing time than STM, while using the tokenizermethod with the dynamic window method reducesthe processing time around 5 times than the origi-nal.
Hence, we have achieved a higher precision aswell as less processing time by combining thesetwo methods.3.3 Comparing experimentIn order to compare with previous methods, weperform the experiment presented in [1].
Table 3shows using the post-processing method presentedin [1] achieves around 87% of word precision rates,and about 12% improvement over the baseline.However, our methods are 11% superior to themethod in [1].
[Table 3] Comparing experiment with previous work4 Conclusions and future workIn this paper, we presented two novel approachescalled dynamic window and tokenizer based on thestatistical machine transliteration model.
Our ap-proaches achieved high precision without any post-processing procedures.
The dynamic window ap-proach was based on a fundamental property,which more TUs aligned between correct translit-eration pairs.
Also, we reasonably estimated therange of correct transliteration?s length to extracttransliteration pairs in high precision.
The token-izer method eliminated characters that have neverbeen used in Chinese transliteration to separate asentence into several parts.
This resulted in a cer-tain degree of improvement of precision and sig-nificantly reduction of processing time.
These twomethods are both based on common natures of alllanguages; thus our approaches can be readily portto other language pairs.In this paper, we only considered the Englishwords that are to be transliterated into Chinese.Our work is ongoing, and in near future, we willextend our works to extract transliteration pairsfrom large scale comparable corpora.
In compara-ble corpora, there are many uncertainties, for ex-ample, the extracted English word may be nottransliterated into Chinese or there may be no cor-rect transliteration in Chinese texts.
However, withlarge comparable corpora, a word will appear sev-eral times, and we can use the frequency or entropyinformation to extract correct transliteration pairsbased on the proposed   perfect algorithm.AcknowledgementThis work was supported by the Korea Science and Engineer-ing Foundation (KOSEF) through the Advanced InformationTechnology Research Center (AITrc), also in part by the BK21 Project and MIC & IITA through IT Leading R&D SupportProject in 2007.Reference[1] C.-J.
Lee, J.S.
Chang, J.-S.R.
Jang, Extraction of translit-eration pairs from parallel corpora using a statistical translit-eration model, in: Information Sciences 176, 67-90 (2006)[2] Richard Sproat, Tao Tao, ChengXiang Zhai, Named EntityTransliteration with Comparable Corpora, in: Proceedings ofthe 21st International Conference on Computational Linguis-tics.
(2006)[3] J.S.
Lee and K.S.
Choi, "English to Korean statisticaltransliteration for information retrieval," International Journalof Computer Processing of Oriental Languages, pp.17?37,(1998).Methods Word  PrecisionCharacterPrecisionCharacterRecallSTM (baseline) 75.33% 86.65% 91.11%STM+DW+TOK 99.00% 99.78% 99.72%STM+[1]?smethod 87.99% 90.17% 91.11%14Sixth SIGHAN Workshop on Chinese Language Processing[4] K. Knight, J. Graehl, Machine transliteration, Computa-tional Linguistics 24 (4), 599?612, (1998).
[5] W.-H. Lin, H.-H. Chen, Backward transliteration by learn-ing phonetic similarity, in: CoNLL-2002, Sixth Conference onNatural Language Learning, Taipei, Taiwan, (2002).
[6] J.-H. Oh, K.-S. Choi, An English?Korean transliterationmodel using pronunciation and contextual rules, in: Proceed-ings of the 19th International Conference on ComputationalLinguistics (COLING), Taipei, Taiwan, pp.
758?764, (2002).
[7] C.-J.
Lee, J.S.
Chang, J.-S.R.
Jang, A statistical approachto Chinese-to-English Backtransliteration, in: Proceedings ofthe 17th Pacific Asia Conference on Language, Information,and Computation (PACLIC), Singapore, pp.
310?318, (2003).
[8] Jong-Hoon Oh, Sun-Mee Bae, Key-Sun Choi, An Algo-rithm for extracting English-Korean Transliteration pairs usingAutomatic E-K Transliteration In Proceedings of Korean In-formation Science Socieity (Spring).
(In Korean), (2004).
[9] Jong-Hoon Oh, Jin-Xia Huang, Key-Sun Choi, An Align-ment Model for Extracting English-Korean Translations ofTerm Constituents, Journal of Korean Information ScienceSociety, SA, 32(4), (2005)[10] Chun-Jen Lee, Jason S. Chang, Jyh-Shing Roger Jang:Alignment of bilingual named entities in parallel corpora us-ing statistical models and multiple knowledge sources.
ACMTrans.
Asian Lang.
Inf.
Process.
5(2): 121-145 (2006)[11] Lee, C. J. and Chang, J. S., Acquisition of English-Chinese Transliterated Word Pairs from Parallel-AlignedTexts Using a Statistical Machine Transliteration Model, In.Proceedings of HLT-NAACL, Edmonton, Canada, pp.
96-103,(2003).
[12] Xinhua Agency, Names of the world's peoples: a com-prehensive dictionary of names in Roman-Chinese ( ??
?
), (1993)15Sixth SIGHAN Workshop on Chinese Language Processing
