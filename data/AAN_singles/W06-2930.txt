Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 206?210, New York City, June 2006. c?2006 Association for Computational LinguisticsInvestigating Multilingual Dependency ParsingRichard JohanssonDepartment of Computer ScienceLTH, Lund University221 00 Lund, SwedenRichard.Johansson@cs.lth.sePierre NuguesDepartment of Computer ScienceLTH, Lund University221 00 Lund, SwedenPierre.Nugues@cs.lth.seAbstractIn this paper, we describe a system forthe CoNLL-X shared task of multilin-gual dependency parsing.
It uses a base-line Nivre?s parser (Nivre, 2003) that firstidentifies the parse actions and then la-bels the dependency arcs.
These two stepsare implemented as SVM classifiers usingLIBSVM.
Features take into account thestatic context as well as relations dynami-cally built during parsing.We experimented two main additions toour implementation of Nivre?s parser: N -best search and bidirectional parsing.
Wetrained the parser in both left-right andright-left directions and we combined theresults.
To construct a single-head, rooted,and cycle-free tree, we applied the Chu-Liu/Edmonds optimization algorithm.
Weran the same algorithm with the same pa-rameters on all the languages.1 Nivre?s ParserNivre (2003) proposed a dependency parser that cre-ates a projective and acyclic graph.
The parser is anextension to the shift?reduce algorithm.
As with theregular shift?reduce, it uses a stack S and a list ofinput words W .
However, instead of finding con-stituents, it builds a set of arcs G representing thegraph of dependencies.Nivre?s parser uses two operations in addition toshift and reduce: left-arc and right-arc.
Given a se-quence of words, possibly annotated with their partof speech, parsing simply consists in applying a se-quence of operations: left-arc (la), right-arc (ra),reduce (re), and shift (sh) to the input sequence.2 Parsing an Annotated CorpusThe algorithm to parse an annotated corpus isstraightforward from Nivre?s parser and enables usto obtain, for any projective sentence, a sequence ofactions taken in the set {la,ra,re,sh} that parsesit.
At a given step of the parsing process, let TOPbe the top of the stack and FIRST , the first token ofthe input list, and arc, the relation holding betweena head and a dependent.1.
if arc(TOP,FIRST ) ?
G, then ra;2. else if arc(FIRST, TOP ) ?
G, then la;3. else if ?k ?
Stack, arc(FIRST, k) ?
G orarc(k, FIRST ) ?
G, then re;4. else sh.Using the first sentence of the Swedish corpusas input (Table 1), this algorithm produces the se-quence of 24 actions: sh, sh, la, ra, re, la, sh,sh, sh, la, la, ra, ra, sh, la, re, ra, ra, ra,re, re, re, re, and ra (Table 2).3 Adapting Nivre?s Algorithm toMachine?Learning3.1 OverviewWe used support vector machines to predict theparse action sequence and a two step procedure to206Table 1: Dependency graph of the sentence ?kten-skapet och familjen ?r en gammal institution, somfunnits sedan 1800-talet ?Marriage and family arean old institution that has been around from the 19thcentury?.ID Form POS Head Rel.1 ?ktenskapet NN 4 SS2 och ++ 3 ++3 familjen NN 1 CC4 ?r AV 0 ROOT5 en EN 7 DT6 gammal AJ 7 AT7 institution NN 4 SP8 , IK 7 IK9 som PO 10 SS10 funnits VV 7 ET11 sedan PR 10 TA12 1800-talet NN 11 PA13 .
IP 4 IPproduce the graph.
We first ran the classifier to se-lect unlabeled actions, la, ra, sh, re.
We then rana second classifier to assign a function to ra and laparse actions.We used the LIBSVM implementation of theSVM learning algorithm (Chang and Lin, 2001).
Weused the Gaussian kernel throughout.
Optimal val-ues for the parameters (C and ?)
were found using agrid search.
The first predicted action is not alwayspossible, given the parser?s constraints.
We trainedthe model using probability estimates to select thenext possible action.3.2 Feature SetWe used the following set of features for the classi-fiers:?
Word and POS of TOP and FIRST?
Word and POS of the second node on the stack?
Word and POS of the second node in the inputlist?
POS of the third and fourth nodes in the inputlist?
The dependency type of TOP to its head, if any?
The word, POS, and dependency type of theleftmost child of TOP to TOP, if any?
The word, POS, and dependency type of therightmost child of TOP to TOP, if any?
The word, POS, and dependency type of theleftmost child of FIRST to FIRST, if anyFor the POS, we used the Coarse POS, the FinePOS, and all the features (encoded as boolean flags).We did not use the lemma.Table 2: Actions to parse the sentence ?ktenskapetoch familjen ?r en gammal institution, som funnitssedan 1800-talet.Ac.
Top word First word Rel.sh nil ?ktenskapetsh ?ktenskapet ochla och familjen ++ra ?ktenskapet familjen CCre familjen ?rla ?ktenskapet ?r SSsh nil ?rsh ?r ensh en gammalla gammal institution ATla en institution DTra ?r institution SPra institution , IKsh , somla som funnits SSre , funnitsra institution funnits ETra funnits sedan TAra sedan 1800-talet PAre 1800-talet .re sedan .re funnits .re institution .ra ?r .
IP4 Extensions to Nivre?s Algorithm4.1 N -best SearchWe extended Nivre?s original algorithm with a beamsearch strategy.
For each action, la, ra, sh and re,207we computed a probability score using LIBSVM.These scores can then be used to carry out an N -best search through the set of possible sequences ofactions.We measured the improvement over a best-firststrategy incrementing values of N .
We observed thelargest difference between N = 1 and N = 2, thenleveling off and we used the latter value.4.2 Bidirectionality and VotingTesni?re (1966) classified languages as centrifuge(head to the left) and centripetal (head to the right)in a table (page 33 of his book) that nearly exactlyfits corpus evidence from the CONLL data.
Nivre?sparser is inherently left-right.
This may not fit allthe languages.
Some dependencies may be easierto capture when proceeding from the reverse direc-tion.
Jin et al (2005) is an example of it for Chinese,where the authors describe an adaptation of Nivre?sparser to bidirectionality.We trained the model and ran the algorithm inboth directions (left to right and right to left).
Weused a voting strategy based on probability scores.Each link was assigned a probability score (simplyby using the probability of the la or ra actions foreach link).
We then summed the probability scoresof the links from all four trees.
To construct a single-head, rooted, and cycle-free tree, we finally appliedthe Chu-Liu/Edmonds optimization algorithm (Chuand Liu, 1965; Edmonds, 1967).5 Analysis5.1 Experimental SettingsWe trained the models on ?projectivized?
graphs fol-lowing Nivre and Nilsson (2005) method.
We usedthe complete annotated data for nine langagues.
Dueto time limitations, we could not complete the train-ing for three languages, Chinese, Czech, and Ger-man.5.2 Overview of the ResultsWe parsed the 12 languages using exactly the samealgorithms and parameters.
We obtained an averagescore of 74.93 for the labeled arcs and of 80.39 forthe unlabeled ones (resp.
74.98 and 80.80 for thelanguages where we could train the model using thecomplete annotated data sets).
Table 3 shows theresults per language.
As a possible explanation ofthe differences between languages, the three lowestfigures correspond to the three smallest corpora.
Itis reasonable to assume that if corpora would havebeen of equal sizes, results would have been moresimilar.
Czech is an exception to this rule that ap-plies to all the participants.
We have no explanationfor this.
This language, or its annotation, seems tobe more complex than the others.The percentage of nonprojective arcs also seemsto play a role.
Due to time limitations, we trainedthe Dutch and German models with approximatelythe same quantity of data.
While both languagesare closely related, the Dutch corpus shows twiceas much nonprojective arcs.
The score for Dutch issignificantly lower than for German.Our results across the languages are consistentwith the other participants?
mean scores, where weare above the average by a margin of 2 to 3% ex-cept for Japanese and even more for Chinese wherewe obtain results that are nearly 7% less than the av-erage for labeled relations.
Results are similar forunlabeled data.
We retrained the data with the com-plete Chinese corpus and you obtained 74.41 for thelabeled arcs, still far from the average.
We have noexplanation for this dip with Chinese.5.3 Analysis of Swedish and PortugueseResults5.3.1 SwedishWe obtained a score of 78.13% for the labeled at-tachments in Swedish.
The error breakdown showssignificant differences between the parts of speech.While we reach 89% of correct head and dependentsfor the adjectives, we obtain 55% for the preposi-tions.
The same applies to dependency types, 84%precision for subjects, and 46% for the OA type ofprepositional attachment.There is no significant score differences for theleft and right dependencies, which could attributedto the bidirectional parsing (Table 4).
Distance playsa dramatic role in the error score (Table 5).
Preposi-tions are the main source of errors (Table 6).5.3.2 PortugueseWe obtained a score 84.57% for the labeled at-tachments in Portuguese.
As for Swedish, errordistribution shows significant variations across the208Table 3: Summary of results.
We retrained the Chi-nese* model after the deadline.Languages Unlabeled LabeledCompleted trainingArabic 75.53 64.29Chinese* 79.13 74.41Danish 86.59 81.54Dutch 76.01 72.67Japanese 87.11 85.63Portuguese 88.4 84.57Slovene 74.36 66.43Spanish 81.43 78.16Swedish 84.17 78.13Turkish 73.59 63.39x 80.80 74.98?
5.99 8.63Noncompleted trainingChinese 77.04 72.49Czech 77.4 71.46German 83.09 80.43x all languages 80.39 74.93?
all languages 5.36 7.65parts of speech, with a score of 94% for adjectivesand only 67% for prepositions.As for Swedish, there is no significant score dif-ferences for the left and right dependencies (Ta-ble 7).
Distance also degrades results but the slope isnot as steep as with Swedish (Table 8).
Prepositionsare also the main source of errors (Table 9).5.4 AcknowledgmentsThis work was made possible because of the anno-tated corpora that were kindly provided to us: Ara-bic (Hajic?
et al, 2004), Bulgarian (Simov et al,2005; Simov and Osenova, 2003), Chinese (Chenet al, 2003), Czech (B?hmov?
et al, 2003), Danish(Kromann, 2003), Dutch (van der Beek et al, 2002),German (Brants et al, 2002), Japanese (Kawata andBartels, 2000), Portuguese (Afonso et al, 2002),Slovene (D?eroski et al, 2006), Spanish (Civit Tor-ruella and Mart?
Anton?n, 2002), Swedish (Nilssonet al, 2005), and Turkish (Oflazer et al, 2003; Ata-lay et al, 2003).Table 4: Precision and recall of binned HEAD direc-tion.
Swedish.Dir.
Gold Cor.
Syst.
R Pto_root 389 330 400 84.83 82.50left 2745 2608 2759 95.01 94.53right 1887 1739 1862 92.16 93.39Table 5: Precision and recall of binned HEAD dis-tance.
Swedish.Dist.
Gold Cor.
Syst.
R Pto_root 389 330 400 84.83 82.501 2512 2262 2363 90.05 95.732 1107 989 1122 89.34 88.153-6 803 652 867 81.20 75.207-... 210 141 269 67.14 52.42Table 6: Focus words where most of the errors occur.Swedish.Word POS Any Head Dep Bothtill PR 48 20 45 17i PR 42 25 34 17p?
PR 39 22 32 15med PR 28 11 25 8f?r PR 27 22 25 20Table 7: Precision and recall of binned HEAD direc-tion.
Portuguese.Dir.
Gold Cor.
Syst.
R Pto_root 288 269 298 93.40 90.27left 3006 2959 3020 98.44 97.98right 1715 1649 1691 96.15 97.52Table 8: Precision and recall of binned HEAD dis-tance.
Portuguese.Dist.
Gold Cor.
Syst.
R Pto_root 288 269 298 93.40 90.271 2658 2545 2612 95.75 97.432 1117 1013 1080 90.69 93.803-6 623 492 647 78.97 76.047-... 323 260 372 80.50 69.89209Table 9: Focus words where most of the errors occur.Portuguese.Word POS Any Head Dep Bothem prp 66 38 47 19de prp 51 37 35 21a prp 46 30 39 23e conj 28 28 0 0para prp 21 13 18 10ReferencesA.
Abeill?, editor.
2003.
Treebanks: Building and Us-ing Parsed Corpora, volume 20 of Text, Speech andLanguage Technology.
Kluwer Academic Publishers,Dordrecht.S.
Afonso, E. Bick, R. Haber, and D. Santos.
2002.
?Flo-resta sint?(c)tica?
: a treebank for Portuguese.
In Proc.of the Third Intern.
Conf.
on Language Resources andEvaluation (LREC), pages 1698?1703.N.
B. Atalay, K. Oflazer, and B.
Say.
2003.
The annota-tion process in the Turkish treebank.
In Proc.
of the 4thIntern.
Workshop on Linguistically Interpreteted Cor-pora (LINC).A.
B?hmov?, J.
Hajic?, E.
Hajic?ov?, and B. Hladk?.
2003.The PDT: a 3-level annotation scenario.
In Abeill?
(Abeill?, 2003), chapter 7.S.
Brants, S. Dipper, S. Hansen, W. Lezius, and G. Smith.2002.
The TIGER treebank.
In Proc.
of theFirst Workshop on Treebanks and Linguistic Theories(TLT).Chih-Chung Chang and Chih-Jen Lin, 2001.
LIBSVM: alibrary for support vector machines.K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,and Z. Gao.
2003.
Sinica treebank: Design criteria,representational issues and implementation.
In Abeill?
(Abeill?, 2003), chapter 13, pages 231?248.Y.J.
Chu and T.H.
Liu.
1965.
On the shortest arbores-cence of a directed graph.
Science Sinica, 14:1396?1400.M.
Civit Torruella and Ma A.
Mart?
Anton?n.
2002.
De-sign principles for a Spanish treebank.
In Proc.
of theFirst Workshop on Treebanks and Linguistic Theories(TLT).S.
D?eroski, T. Erjavec, N. Ledinek, P. Pajas, Z.
?abokrt-sky, and A.
?ele.
2006.
Towards a Slovene depen-dency treebank.
In Proc.
of the Fifth Intern.
Conf.
onLanguage Resources and Evaluation (LREC).J.
Edmonds.
1967.
Optimum branchings.
Journal of Re-search of the National Bureau of Standards, 71B:233?240.J.
Hajic?, O.
Smr?, P. Zem?nek, J.
?naidauf, and E. Be?ka.2004.
Prague Arabic dependency treebank: Develop-ment in data and tools.
In Proc.
of the NEMLAR In-tern.
Conf.
on Arabic Language Resources and Tools,pages 110?117.Meixun Jin, Mi-Young Kim, and Jong-Hyeok Lee.2005.
Two-phase shift-reduce deterministic depen-dency parser of Chinese.
In Proceedings of the SecondInternational Joint Conference on Natural LanguageProcessing.Y.
Kawata and J. Bartels.
2000.
Stylebook for theJapanese treebank in VERBMOBIL.
Verbmobil-Report 240, Seminar f?r Sprachwissenschaft, Univer-sit?t T?bingen.M.
T. Kromann.
2003.
The Danish dependency treebankand the underlying linguistic theory.
In Proc.
of theSecond Workshop on Treebanks and Linguistic Theo-ries (TLT).J.
Nilsson, J.
Hall, and J. Nivre.
2005.
MAMBA meetsTIGER: Reconstructing a Swedish treebank from an-tiquity.
In Proc.
of the NODALIDA Special Session onTreebanks.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-projectivedependency parsing.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL?05), pages 99?106, Ann Arbor, June.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of the 8th In-ternational Workshop on Parsing Technologies (IWPT03), pages 149?160, Nancy, 23-25 April.K.
Oflazer, B.
Say, D. Zeynep Hakkani-T?r, and G. T?r.2003.
Building a Turkish treebank.
In Abeill?
(Abeill?, 2003), chapter 15.K.
Simov and P. Osenova.
2003.
Practical annotationscheme for an HPSG treebank of Bulgarian.
In Proc.of the 4th Intern.
Workshop on Linguistically Inter-preteted Corpora (LINC), pages 17?24.K.
Simov, P. Osenova, A. Simov, and M. Kouylekov.2005.
Design and implementation of the BulgarianHPSG-based treebank.
In Journal of Research on Lan-guage and Computation ?
Special Issue, pages 495?522.
Kluwer Academic Publishers.Lucien Tesni?re.
1966.
?l?ments de syntaxe structurale.Klincksieck, Paris, 2e edition.L.
van der Beek, G. Bouma, R. Malouf, and G. van No-ord.
2002.
The Alpino dependency treebank.
In Com-putational Linguistics in the Netherlands (CLIN).210
