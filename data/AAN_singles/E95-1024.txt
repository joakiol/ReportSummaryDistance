Off-line Optimization for Earley-style HPSG ProcessingGuido Minnen, Dale Gerdemann~ Thilo GStz *Sonderforschungsbereich 340University of TfibingenWilhelmstr.
11372074-TfibingenGermanyE-mail: minnen@sfs.nphil.uni-t uebingen.deAbstractA novel approach to HPSG based naturallanguage processing is described that usesan off-line compiler to automatically primea declarative grammar for generation orparsing, and inputs the primed grammar toan advanced Earley-style processor.
Thisway we provide an elegant solution to theproblems with empty heads and efficientbidirectional processing which is illustratedfor the special case of HPSG generation.
Ex-tensive testing with a large HPSG grammarrevealed some important constraints on theform of the grammar.1 IntroductionBidirectionality of grammar is a research topic innatural anguage processing that is enjoying increas-ing attention (Strzalkowski, 1993a).
This is mainlydue to the clear theoretical and practical advantagesof bidirectional grammar use (see, among others,Appelt, 1987).
We address this topic in describinga novel approach to HPSG (Pollard and Sag, 1994)based language processing that uses an off-line com-piler to automatically prime a declarative grammarfor generation or parsing, and hands the primedgrammar to an advanced Earley processor.
The de-veloped techniques are direction independent in thesense that they can be used for both generation andparsing with HPSG grammars.
In this paper, we fo-cus on the application of the developed techniquesin the context of the comparatively neglected areaof  HPSG generation.Shieber (1988) gave the first use of Earley's al-gorithm for generation, but this algorithm does not*The presented research was sponsored by 'l~eilpro -jekt B4 "Constraints on Grammar for Efficient Genera-tion" of the Sonderforschungsbereich 340 "Sprachtheo-retische Grundlagen fiir die Computerllnguistik" of theDeutsche Forschungsgemeinschaft.
Theauthors wish tothank Paul King, Detmar Meurers and Shuly Wintnerfor valuable comments and discussion.
Of course, theauthors are responsible for all remaining errors.use the prediction step to restrict feature instantia-tions on the predicted phrases, and thus lacks goal-directedness.
Though Gerdemann (1991) showedhow to modify the restriction function to make top-down information available for the bottom-up com-pletion step, Earley generation with top-down pre-diction still has a problem in that generating the sub-parts of a construction i the wrong order might leadto massive nondeterminacy or even nontermination.Gerdemann (1991) partly overcame this problem byincorpQrating a head-driven strategy into Earley'salgorithm.
However, evaluating the head of a con-struction prior to its dependent subparts till suffersfrom efficiency problems when the head of a con-struction is either missing, displaced or underspec-ified.
Furthermore, Martinovid and Strzalkowski(1992) and others have observed that a simple head-first reordering of the grammar ules may still makeinsufficient restricting information available for gen-eration unless the form of the grammar is restrictedto unary or binary rules.Strzalkowski's Essential Arguments Approach(Ehh; 1993b) is a top-down approach to generationand parsing with logic grammars that uses off-linecompilation to automatically invert parser-orientedlogic grammars.
The inversion process consists ofboth the automatic static reordering of nodes inthe grammar, and the interchanging of arguments inrules with recursively defined heads.
It is based onthe notion of essential arguments, arguments whichmust be instantiated to ensure the efficient and ter-minating execution of a node.
Minnen et al (1995)observe that the EAA is computationally infeasible,because it demands the investigation of almost allpossible permutations of a grammar.
Moreover,the interchanging of arguments in recursive proce-dures as proposed by Strzalkowski fails to guaranteethat input and output grammars are semanticallyequivalent.
The Direct Inversion Approach (DI,~) ofMinnen et al (1995) overcomes these problems bymaking the reordering process more goal-directedand developing a reformulation technique that al-lows the successful treatment of rules which exhibithead-recursion.
Both the EAA and the DIA were173presented as approaches to the inversion of parser-oriented grammars into grammars suitable for gen-eration.
However, both approaches can just as welltake a declarative grammar specification as input toproduce generator and/or parser-oriented grammarsas in Dymetman et al (1990).
In this paper weadopt the latter theoretically more interesting per-spective.We developed a compiler for off-line optimizationof phrase structure rule-based typed feature struc-ture grammars which generalizes the techniques de-veloped in the context of the DIA, and we advanceda typed extension of the Earley-style generator ofGerdemann (1991).
Off-line compilation (section 3)is used to produce grammars for the Earley-stylegenerator (section 2).
We show that our use of off-line grammar optimization overcomes problems withempty or displaced heads.
The developed techniquesare extensively tested with a large HPSG grammar forpartial vP topicallzation i German (iiinrichs et al,1994).
This uncovered some important constraintson the form of the phrase structure rules (phrasestructure rules) in a grammar imposed by the com-piler (section 4).2 Advanced Earley GenerationAs Shieber (1988) noted, the main shortcoming ofEarley generation is a lack of goal-directedness thatresults in a proliferation ofedges.
Gerdemann (1991)tackled this shortcoming by modifying the restric-tion function to make top-down information avail-able for the bottom-up completion step.
Gerde-mann's generator follows a head-driven strategy inorder to avoid inefficient evaluation orders.
Morespecifically, the head of the right-hand side of eachgrammar ule is distinguished, and distinguishedcategories are scanned or predicted upon first.
Theresulting evaluation strategy is similar to that of thehead-corner approach (Shieber et al, 1990; Gerde-mann and IIinrichs, in press): prediction followsthe main flow of semantic information until a lex-ical pivot is reached, and only then are the head-dependent subparts of the construction built up ina bottom-up fashion.
This mixture of top-down andbottom-up information flow is crucial since the top-down semantic information from the goal categorymust be integrated with the bottom-up subcatego-rization information from the lexicon.
A strict top-down evaluation strategy suffers from what may becalled head-recursion, i.e.
the generation analog ofleft recursion in parsing.
Shieber et al (1990) showthat a top-down evaluation strategy will fail for rulessuch as vP --* vp x, irrespective of the order of eval-uation of the right-hand side categories in the rule.By combining the off-line optimization process witha mixed bottom-up/top-down evaluation strategy,we can refrain from a complete reformulation of thegrammar as, for example, in Minnen et al (1995).2.1 Opt imizat ionsWe further improved a typed extension of Gerde-mann's Earley generator with a number of tech-niques that reduce the number of edges created ur-ing generation.
Three optimizations were especiallyhelpful.
The first supplies each edge in the chartwith two indices, a backward index pointing to thestate in the chart that the edge is predicted from,and a forward index poinfing to the states that arepredicted from the edge.
By matching forward andbackward indices, the edges that must be combinedfor completion can be located faster.
This index-ing technique, as illustrated below, improves uponthe more complex indices in Gerdemann (1991) andis closely related to OLDT-resolution (Tamaki andSato, 1986).1) active(Xo---~Xl*X2,1~2~2) active(X:--~.Y1Y2,~3))3) active(X2---*Y1.Y2, i , y4) passive(X2 --+ Y1 I/2 o, 2)Active edge 2 resulted from active edge 1 throughprediction.
The backward index of edge 2 is there-fore identified with the forward index of edge 1.Completion of an active edge results in an edge withidentical backward index.
In the case of our exam-ple, this would be the steps from edge 2 to edge 3and edge 3 to edge 4.
As nothing gets predictedfrom a passive dge (4), it does not have a forwardindex.
In order to use passive dge 4 for completionof an active edge, we only need to consider thoseedges which have a forward index identical to thebackward index of 4.The second optimization creates a table of the cat-egories which have been used to make predictionsfrom.
As discussed in Gerdemann (1991), such a ta-ble can be used to avoid redundant predictions with-out a full and expensive subsumption test.
The thirdindexes lexical entries which is necessary to obtainconstant-time lexical access.The optimizations of our Earley-generator leadto significant gains in efficiency.
However, despitethese heuristic improvements, he problem of goal-directedness is not solved.2.2 Empty  HeadsEmpty or displaced heads present the principal goal-directedness problem for any head-driven generationapproach (Shieber et al, 1990; K6nig, 1994; Gerde-mann and IIinrichs, in press), where empty headrefers not just to a construction i  which the headhas an empty phonology, but to any constructionin which the head is partially unspecified.
Since174phonology does not guide generation, the phonologi-cal realization of the head of a construction plays nopart in the generation of that construction.
To bet-ter illustrate the problem that underspecified headspose, consider the sentence:Hal Karl Marie geki~'fltHas Karl Marie kissed?
"Did Karl kiss Mary?
"for which we adopt the argument composition anal-ysis presented in Hinrichs and Nakazawa (1989): thesubeat list of the auxiliary verb is partially instan-tiated in the lexicon and only becomes fully instan-tiated upon its combination with its verbal comple-ment, the main verb.
The phrase structure rule thatdescribes this construction is 1cat 0\]\] subcatcontIcat vfin +aux +subcat ( \['3"1l r?1 )Lcont \[\]I cat v lJ L, ub?~t \[EI \ [ \ ]Though a head-driven generator must generate firstthe head of the rule, nothing prescribes the order ofgeneration of the complements of the head.
If thegenerator generates econd the main verb then thesubcat list of the main verb instantiates the subcatlist of the head, and generation becomes a deter-ministic procedure in which complements are gener-ated in sequence.
However, if the generator gener-ates second some complement other than the mainverb, then the subcat list of the head contains norestricting information to guide deterministic gener-ation, and generation becomes a generate-and-testprocedure in which complements are generated atrandom, only to be eliminated by further unifica-tions.
Clearly then, the order of evaluation of thecomplements in a rule can profoundly influence theefficiency of generation, and an efficient head-drivengenerator must order the evaluation of the comple-ments in a rule accordingly.2.3 Of f - l ine  versus  On- l ineDynamic, on-line reordering can solve the orderingproblem discussed in the previous ubsection, but israther unattractive: interpreting rammar ules at1For expository reasons, we refrain from a divisionbetween the subject and the other complements of averb as in chapter 9 of Pollard and Sag (1994).
Thetest-grammar does make this division and always guar-antees the correct order of the complements onthe compslist with respect o the obliqueness hierarchy.
Further-more, we use abbreviations of paths, such as coat forsyasemlloc\[coat , and assume that the semantics princi-ple is encoded in the phrase structure rule.run time creates much overhead, and locally deter-mining the optimal evaluation order is often impos-sible.
Goal-freezing can also overcome the orderingproblem, but is equally unappealing: goal-freezingis computationally expensive, it demands the proce-dural annotation of an otherwise declarative gram-mar specification, and it presupposes that a gram-mar writer possesses substantial computational pro-cessing expertise.
We chose instead to deal with theordering problem by using off-line compilation to au-tomatically optimize a grammar such that it can beused for generation, without additional provision fordealing with the evaluation order, by our Earley gen-erator.3 Off-line Grammar OptimizationOur off-line grammar optimization is based on a gen-eralization of the dataflow analysis employed in theDIA to a dataflow analysis for typed feature struc-ture grammars.
This dataflow analysis takes as in-put a specification of the paths of the start categorythat are considered fully instantiated.
In case ofgeneration, this means that the user annotates thepath specifying the logical form, i.e., the path cont(or some of its subpaths), as bound.
We use thetype hierarchy and an extension of the unificationand generalization operations uch that path anno-tations are preserved, to determine the flow of (se-mantic) information between the rules and the lexicalentries in a grammar.
Structure sharing determinesthe dataflow within the rules of the grammar.The dataflow analysis is used to determine the rel-ative efficiency of a particular evaluation order ofthe right-hand side categories in a phrase structurerule by computing the maximal degree of nondeter-minacy introduced by the evaluation of each of thesecategories.
The maximal degree of nondeterminacyintroduced by a right-hand side category equals themaximal number of rules and/or lexical entries withwhich this category unifies given its binding anno-tations.
The optimal evaluation order of the right-hand side categories i found by comparing the max-imal degree of nondeterminacy introduced by theevaluation of the individual categories with the de-gree of nondeterminacy the grammar is allowed tointroduce: if the degree of nondeterminacy intro-duced by the evaluation of one of the right-hand sidecategories in a rule exceeds the admissible degreeof nondeterminacy the ordering at hand is rejected.The degree of nondeterminacy the grammar is al-lowed to introduce is originally set to one and con-secutively incremented until the optimal evaluationorder for all rules in the grammar is found.3.1 ExampleThe compilation process is illustrated on the basisof the phrase structure rule for argument composi-tion discussed in 2.2.
Space limitations force us to175abstract over the recursive optimization of the rulesdefining the right-hand side categories through con-sidering only the defining lexical entries.Unifying the user annotated start category withthe left-hand side of this phrase structure rule leadsto the annotation of the path specifying the logicalform of the construction as bound (see below).
As aresult of the structure-sharing between the left-handside of the rule and the auxiliary verb category, thecont-value of the auxiliary verb can be treated asbound, as well.
In addition, the paths with a valueof a maximal specific type for which there are noappropriate f atures pecified, for example, the pathcat, can be considered bound:subcatbo..acont b o ~.
a~l lb?~nd + \[ f lnbound --8.UXbound + , 53 , \[2\] , \[\]l.UXbo.nd ~~ub~t (~I El', L, ub?~t \[\]3157LcOntbo~.a \[\]On the basis of this annotated rule, we investigatethe lexical entries defining its right-hand side cate-gories.
The auxiliary verb category is unified withits defining lexical entries (under preservation of thebinding annotations).
The following is an exampleof such a lexical entry.
(Note that subpaths of a pathmarked as bound are considered bound too.
)c~ttbound Vfinbou.4 +~.UXbo,.~nd -I-subcat <\[contbou.4 ~>contbo..a I nucleusbo~.a I argbo..aThe binding annotations of the lexical entries defin-ing the auxiliary verb are used to determine withhow many lexical entries the right-hand side cate-gory of the rule maximally unifies, i.e., its maximaldegree of nondeterminacy.
In this case, the maxi-mal degree of nondeterminacy that the evaluationof the auxiliary verb introduces is very low as thelogical form of the auxiliary verb is considered fullyinstantiated.
Now we mark the paths of the defininglexical entries whose instantiation can be deducedfrom the type hierarchy.
To mimic the evaluationof the auxiliary verb, we determine the informationcommon to all defining lexical entries by taking theirgeneralization, i.e., the most specific feature struc-ture subsuming all, and unify the result with theoriginal right-hand side category in the phrase struc-ture rule.
Because both the generalization and theunification operations preserve binding annotations,this leads (via structure-sharing) to the annotationthat the logical form of the verbal complement canbe considered instantiated.
Note that the nonver-bal complements do not become further instantiated.By subsequent investigation of the maximal degreeof nondeterminacy introduced by the evaluation ofthe complements in various permutations, we findthat the logical form of a sentence only restricts theevaluation of the nonverbal complements after theevaluation of the verbal complement.
This can beverified on the basis of a sample lexical entry for amain verb.
"phoncatfinauxsubcatliebenv< \[coat \['6\]\] !\[cont rT\]\], r,o o,c?nt ' numeus \[loved r-#\] jThe relative efficiency of this evaluation leads ourcompiler to choose\[ cat v fin 4- ~UX ~LLcont \[\]cat {}\[~\]subcat -----,cont, \[\] aUXL,ub?~t 531 \[\]\[i\],\[\]as the optimal evaluation order of our phrase struc-ture rule for argument composition.3.2 Processing HeadThe optimal evaluation order for a phrase structurerule need not necessarily be head-first.
Our dataflowanMysis treats heads and complements alike, and in-cludes the head in the calculation of the optimalevaluation order of a rule.
If the evaluation of thehead of a rule introduces much nondeterminacy orprovides insufficient restricting information for theevaluation of its complements, our dataflow analysismight not select he head as the first category to beevaluated, and choose insteadsubcat -----+contpat v >\] It at v fin 4-\ [ \ ]  aux ~ux + , N ,  \ [ \ ]Lsubeat Fill \ [ \ ]  L ~?nt \ [ \ ]  'as the optimal evaluation order.
This clearly demon-strates an extremely important consequence of us-ing our dataflow analysis to compile a declarativegrammar into a grammar optimized for generation.Empty or displaced heads pose us no problem, sincethe optimal evaluation order of the right-hand sideof a rule is determined regardless of the head.
Ourdataflow analysis ignores the grammatical head, butidentifies instead the 'processing head', and (no less176importantly) the 'first processing complement', the'second processing complement', and so on.4 Const ra in ts  on GrammarOur Earley generator and the described compilerfor off-line grammar optimization have been exten-sively tested with a large HPSG grammar.
This test-grammar is based on the implementation f an anal-ysis of partial vP topicalization i German (Hinrichset al, 1994) in the Troll system (Gerdemann andKing, 1994).
Testing the developed techniques un-covered important constraints on the form of thephrase structure rules in a grammar imposed by thecompiler.4.1 Complement DisplacementThe compiler is not able to find an evaluation or-der such that the Earley generator has sufficient re-stricting information to generate all subparts of theconstruction efficiently in particular cases of comple-ment displacement.
More specifically, this problemarises when a complement receives essential restrict-ing information from the head of the constructionfrom which it has been extracted, while, at the sametime, it provides essential restricting information forthe complements hat stayed behind.
Such a case isrepresented schematically in figure 1 (see next page).The first processing complement (el)  of the head(H) has been displaced.
This is problematic in casec l  provides essential bindings for the successful eval-uation of the complement c2.
c l  can not be evalu-ated prior to the head and once H is evaluated itis no longer possible to evaluate c l  prior to c2.An example of problematic omplement displace-ment taken from our test-grammar is given in fig-ure 2 (see next page).
The topicalized partial vP"Anna lichen" receives its restricting semantic infor-mation from the auxiliary verb and upon its eval-uation provides essential bindings not only for thedirect object, but also for the subject that stayedbehind in the Mittelfeld together with the auxiliaryverb.
These mutual dependencies between the sub-constituents of two different local trees lead eitherto the unrestricted generation of the partial vP, orto the unrestricted generation of the subject in theMittelfeld.
We handled this problem by partial exe-cution (Pereira and Shieber, 1987) of the filler-headrule.
This allows the evaluation of the filler rightafter the evaluation of the auxiliary verb, but priorto the subject.
A head-driven generator has to relyon a similar solution, as it will not be able to find asuccessful ordering for the local trees either, simplybecause it does not exist.4.2 GeneralizationA potential problem for our approach constitutesthe requirement that the phrase structure rules inthe grammar need to have a particular degree ofspecificity for the generalization operation to beused successfully to mimic its evaluation.
This isbest illustrated on the basis of the following, more'schematic', phrase structure rule:\[cat (}l~.\]\] [i at v fin ~- >1 (~ ,ff\]NN subcat _.... ubcat  ,~ \ ] , \ [~  ' 'Lcont\[contUnderspecification of the head of the rule allows it tounify with both finite auxiliaries and finite ditransi-tive main verbs.
In combination with the underspec-ification of the complements, this allows the rule notonly to be used for argument composition construc-tions, as discussed above, but also for constructionsin which a finite main verb becomes aturated.
Thismeans that the logical form of the nonverbal com-plements (if\] and \[~) becomes available ither uponthe evaluation of the complement tagged \[\] (in caseof argument composition), or upon the evaluationof the finite verb (in case the head of the rule isa ditransitive main verb).
As a result, the use ofgeneralization does not suffice to mimic the evalua-tion of the respective right-hand side categories.
Be-cause both verbal categories have defining lexical en-tries which do not instantiate the logical form of thenonverbal arguments, the dataflow analysis leads tothe conclusion that the logical form of the nonver-bal complements never becomes instantiated.
Thiscauses the rejection of all possible evaluation ordersfor this rule, as the evaluation of an unrestricted non-verbal complement clearly exceeds the allowed max-imal degree of nondeterminacy of the grammar.
Weare therefore forced to split this schematic phrasestructure rule into two more specific rules at leastduring the optimization process.
It is important tonote that this is a consequence of a general imita-tion of dataflow analysis (see also Mellish, 1981).5 Conc lud ing  RemarksAn innovative approach to HPSG processing is de-scribed that uses an off-line compiler to automat-ically prime a declarative grammar for generationor parsing, and inputs the primed grammar to anadvanced Earley processor.
Our off-line compilerextends the techniques developed in the context ofthe DIA in that it compiles typed feature struc-ture grammars, rather than simple logic grammars.The approach allows efficient bidirectional process-ing with similar generation and parsing times.
Itis shown that combining off-line techniques with anadvanced Earley-style generator provides an elegantsolution to the general problem that empty or dis-placed heads pose for conventional head-driven gen-eration.The developed off-line compilation techniquesmake crucial use of the fundamental properties of theHPSG formalism.
The monostratal, uniform treat-ment of syntax, semantics and phonology supports177l H \] C2Figure 1: Complement displacement.c at vsubcat ()cont\[~'\[\[ nucleus I arg\[ nucleus lover .
.
.
kar l ' .
.
.
\ ] \ ]  loved anna' .\[\]F cat ( )\[~ll F~/subcatLcont"cat vfinFat n Fat nsubcat \['g'\] lease ~m \[~\] [casecont contslash {}lovercont \[\] nucleus \[loved ~N-'I\]is:L, ~-slashcontfin +aux +subcat (\[~\])sl,.,h {D}eont I~llnueleuslarg \[\]\[\]Anna lieben wirdAnna love will"Karl will love Anna"Figure 2: Example of problematic complement displacement.Karl.Karl.178.dataflow analysis, which is used extensively to pro-vide the information upon which off-line compilationis based.
Our compiler uses the type hierarchy to de-termine paths with a value of a minimal type with-out appropriate features as bound.
However, theequivalent of this kind of minimal types in untypedfeature structure grammars are constants which canbe used in a similar fashion for off-line optimization.ReferencesAppelt, Douglas.
1987.
Bidirectional Grammarsand the Design of Natural Language GenerationSystems.
In Proceedings of TINLAP-3, Las Cruces,New Mexico, USA.Dymetman, Marc; Pierre Isabelle and FranqoisPerrault.
1990.
A Symmetrical Approach to Pars-ing and Generation.
In Proceedings of COLING-90,Helsinki, Finland.Gerdemann, Dale.
1991.
Parsing and Generationof Unification Grammars.
Doctoral dissertation.University of Illinois.
Published as Beckman Insti-tute Cognitive Science technical report, numbercs-91-06.
Urbana-Champaign, Illinois, usa.Gerdemann, Dale and Erhard Hinrichs.
in press.Some Open Problems in Head-driven Genera-tion.
In Linguistics and Computation.
CSLI Lec-ture Notes.
Stanford, California, usA.Gerdemann, Dale and Paul King.
1994.
The Correctand Efficient Implementation f AppropriatenessSpecifications for Typed Feature Structures.
InProceedings of COLING-94(, Kyoto, Japan.Hinrichs, Erhard and Tsuneko Nakazawa.
1989.Subcategorization a d vP Structure in German.Paper presented to the '3rd Symposium on Ger-manic Linguistics' at Purdue University.
Pub-lished as SFB 340 technical report.
Tiibingen, Ger-many.tIinrichs, Erhard; Detmar Meurers and TsunekoNakazawa.
1994.
Partial ve and Split NP Top-icalization in German: An HPSG Analysis and itsImplementation.
SFB 340 technical report nr.
58.Tiibingen, Germany.KSnig, Esther.
1994.
Syntactic-Head-Driven Gener-ation.
In Proceedings of COLING-9~.
Kyoto, JapanMartinovid, Miroslav and Tomek Strzalkowski.1992.
Comparing Two Grammar-based Genera-tion Algorithms: A Case Study.
In Proceedings ofACL-92, Newark, Delaware, usa.Mellish, Chris.
1981.
The Automatic Generation ofMode Declarations for Prolog Programs.
In Pro-ceedings of the Workshop on Logic Programmingand Intelligent Systems, Los Angeles, California,USA.Minnen, Guido; Dale Gerdemann and ErhardHinrichs.
1995.
Direct Automated Inversion ofLogic Grammars.
In New Generation Computing,volume 13, number 2.Pereira, Fernando and Stuart Shieber.
1987.
Pro-log and Natural Language Analysis.
CSLI LectureNotes, number 10.
Stanford, California, usA.Pollard, Carl and Ivan Sag.
1994.
Head-driven Phrase Structure Grammar.
University ofChicago Press, Chicago, Illinois, usa.Shieber, Stuart.
1988.
A Uniform Architecturefor Parsing and Generation.
In Proceedings ofCOLING-88.
Budapest, Hungary.Shieber, Stuart; Gertjan van Noord; FernandoPereira and Robert Moore.
1990.
Semantic Head-Driven Generation.
In Computational Linguistics,volume 16, number 1.Strzalkowski, Tomek (editor).
1993a.
Re-versible Grammar in Natural Language Process-ing.
Kluwer Academic Publishers, Dordrecht, TheNetherlands.Strzalkowski, Tomek.
1993b.
A General Com-putational Method for Grammar Inversion.
InStrzalkowski 1993a.Tamaki, HHisao and Taisuke Sato 1986.
OLD Resolu-tion with Tabulation.
In Proceedings of the ThirdInternational Conference on Logic Programming.Berlin, Germany179
