Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 311?321,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsExploring Representations from Unlabeled Data with Co-trainingfor Chinese Word SegmentationLongkai Zhang Houfeng Wang?
Xu Sun Mairgup MansurKey Laboratory of Computational Linguistics (Peking University) Ministry of Education, Chinazhlongk@qq.com, wanghf@pku.edu.cn, xusun@pku.edu.cn, mairgup@gmail.com,AbstractNowadays supervised sequence labelingmodels can reach competitive performanceon the task of Chinese word segmenta-tion.
However, the ability of these mod-els is restricted by the availability of an-notated data and the design of features.We propose a scalable semi-supervised fea-ture engineering approach.
In contrastto previous works using pre-defined task-specific features with fixed values, we dy-namically extract representations of labeldistributions from both an in-domain cor-pus and an out-of-domain corpus.
Weupdate the representation values with asemi-supervised approach.
Experimentson the benchmark datasets show that ourapproach achieve good results and reachan f-score of 0.961.
The feature engineer-ing approach proposed here is a generaliterative semi-supervised method and notlimited to the word segmentation task.1 IntroductionChinese is a language without natural worddelimiters.
Therefore, Chinese Word Segmen-tation (CWS) is an essential task required byfurther language processing.
Previous researchshows that sequence labeling models trained onlabeled data can reach competitive accuracy onthe CWS task, and supervised models are moreaccurate than unsupervised models (Xue, 2003;Low et al 2005).
However, the resource of man-ually labeled training corpora is limited.
There-fore, semi-supervised learning has become one?Corresponding authorof the most natural forms of training for CWS.Traditional semi-supervised methods focus onadding new unlabeled instances to the trainingset by a given criterion.
The possible mislabeledinstances, which are introduced from the auto-matically labeled raw data, can hurt the per-formance and not easy to exclude by setting asound selecting criterion.In this paper, we propose a simple and scal-able semi-supervised strategy that works by pro-viding semi-supervision at the level of represen-tation.
Previous works mainly assume that con-text features are helpful to decide the potentiallabel of a character.
However, when some of thecontext features do not appear in the trainingcorpus, this assumption may fail.
An example isshown in table 1.
Although the context of ??
?and ???
is totally different, they share a homo-geneous structure as ?verb-noun?.
Therefore.
Amuch better way is to map the context informa-tion to a kind of representation.
More precisely,the mapping should let the similar contexts mapto similar representations, while let the distinctcontexts map to distinct representations.???
??
?Label B BCharacter ?
?
?
?
?
?Context C-1= ?
C-1= ?Features C0= ?
C0= ?C1= ?
C1= ?Table 1: Example of the context of ???
in ????
(Eat fruits)?
and the context of ???
in ????
(Play basketball)?We use the label distribution information that311is extracted from the unlabeled corpus as thisrepresentation to enhance the supervised model.We add ?pseudo-labels?
by tagging the unla-beled data with the trained model on the train-ing corpus.
These ?pseudo-labels?
are not accu-rate enough.
Therefore, we use the label distri-bution, which is much more accurate.To accurately calculate the precise label dis-tribution, we use a framework similar to the co-training algorithm to adjust the feature valuesiteratively.
Generally speaking, unlabeled datacan be classified as in-domain data and out-of-domain data.
In previous works these two kindsof unlabeled data are used separately for differ-ent purposes.
In-domain data is mainly used tosolve the problem of data sparseness (Sun andXu, 2011).
On the other hand, out-of domaindata is used for domain adaptation (Chang andHan, 2010).
In our work, we use in-domain andout-of-domain data together to adjust the labelsof the unlabeled corpus.We evaluate the performance of CWS on thebenchmark dataset of Peking University in thesecond International Chinese Word Segmenta-tion Bakeoff.
Experiment results show that ourapproach yields improvements compared withthe state-of-art systems.
Even when the la-beled data is insufficient, our methods can stillwork better than traditional methods.
Com-pared to the baseline CWS model, which hasalready achieved an f-score above 0.95, we fur-ther reduce the error rate by 15%.Our method is not limited to word segmen-tation.
It is also applicable to other problemswhich can be solved by sequence labeling mod-els.
We also applied our method to the Chi-nese Named Entity Recognition task, and alsoachieved better results compared to traditionalmethods.The main contributions of our work are as fol-lows:?
We proposed a general method to utilizethe label distribution given text contexts asrepresentations in a semi-supervised frame-work.
We let the co-training process ad-just the representation values from labeldistribution instead of using manually pre-defined feature templates.?
Compared with previous work, our methodachieved a new state-of-art accuracy on theCWS task as well as on the NER task.The remaining part of this paper is organizedas follows.
Section 2 describes the details of theproblem and our algorithm.
Section 3 describesthe experiment and presents the results.
Section4 reviews the related work.
Section 5 concludesthis paper.2 System Architecture2.1 Sequence LabelingNowadays the character-based sequence label-ing approach is widely used for the Chinese wordsegmentation problem.
It was first proposed inXue (2003), which assigns each character a labelto indicate its position in the word.
The mostprevalent tag set is the BMES tag set, whichuses 4 tags to carry word boundary information.This tag set uses B, M, E and S to represent theBeginning, the Middle, the End of a word anda Single character forming a word respectively.We use this tag set in our method.
An exampleof the ?BMES?
representation is shown in table2.Character: ?
?
?
?
?
?
?Tag: S S B E B M ETable 2: An example for the ?BMES?
representa-tion.
The sentence is ?????????
(I love Bei-jing Tian-an-men square), which consists of 4 Chi-nese words: ???
(I), ???
(love), ????
(Beijing),and ?????
(Tian-an-men square).2.2 Unlabeled DataUnlabeled data can be divided into in-domaindata and out-of-domain data.
In previous works,these two kinds of unlabeled data are used sep-arately for different purposes.
In-domain dataonly solves the problem of data sparseness (Sunand Xu, 2011).
Out-of domain data is usedonly for domain adaptation (Chang and Han,2010).
These two functionalities are not contra-dictory but complementary.
Our study shows312that by correctly designing features and algo-rithms, both in-domain unlabeled data and out-of-domain unlabeled data can work together tohelp enhancing the segmentation model.
In ouralgorithm, the dynamic features learned fromone corpus can be adjusted incrementally withthe dynamic features learned from the other cor-pus.As for the out-of-domain data, it will be evenbetter if the corpus is not limited to a specificdomain.
We choose a Chinese encyclopedia cor-pus which meets exactly this requirement.
Weuse the corpus to learn a large set of informativefeatures.
In our experiment, two different viewsof features on unlabeled data are considered:Static Statistical Features (SSFs): Thesefeatures capture statistical information of char-acters and character n-grams from the unlabeledcorpus.
The values of these features are fixedduring the training process once the unlabeledcorpus is given.Dynamic Statistical Features (DSFs):These features capture label distribution infor-mation from the unlabeled corpus given fixedtext contexts.
As the training process proceeds,the value of these features will change, since thetrained tagger at each training iteration may as-sign different labels to the unlabeled data.2.3 FrameworkSuppose we have labeled data L, two unla-beled corpora Ua and Ub (one is an in-domaincorpus and the other is an out-of-domain cor-pus).
Our algorithm is shown in Table 3.During each iteration, we tag the unlabeledcorpus Ua using Tb to get pseudo-labels.
Thenwe extract features from the pseudo-labels.
Weuse the label distribution information as dy-namic features.
We add these features to thetraining data to train a new tagger Ta.
To adjustthe feature values, we extract features from onecorpus and then apply the statistics to the othercorpus.
This is similar to the principle of co-training (Yarowsky, 1995; Blum and Mitchell,1998; Dasgupta et al 2002).
The difference isthat there are not different views of features, butdifferent kinds of unlabeled data.
Detailed de-scription of features is given in the next section.AlgorithmInit:Using baseline features only:Train an initial tagger T0 based on L ()Label Ua and Ub individually using T0BEGIN LOOP:Generate DSFs from tagged UaAugment L with DSFs to get LaGenerate DSFs from tagged UbAugment L with DSFs to get LbUsing baseline features, SSFs and DSFs:Train new tagger Ta using LaTrain new tagger Tb using LbLabel Ua using TbLabel Ub using TaLOOP until performance does not improveRETURN the tagger which is trained within-domain features.Table 3: Algorithm description2.4 Features2.4.1 Baseline FeaturesOur baseline feature templates include thefeatures described in previous works (Sun andXu, 2011; Sun et al 2012).
These features arewidely used in the CWS task.
To be convenient,for a character ci with context .
.
.
ci?1cici+1 .
.
.,its baseline features are listed below:?
Character uni-grams: ck (i?
3 < k < i+3)?
Character bi-grams: ckck+1 (i ?
3 < k <i+ 2)?
Whether ck and ck+1 are identical (i?
2 <k < i + 2)?
Whether ck and ck+2 are identical (i?
4 <k < i + 2)The last two feature templates are designed todetect character reduplication, which is a mor-phological phenomenon in Chinese language.An example is ??????
(Perfect), which isa Chinese idiom with structure ?ABAC?.3132.4.2 Static statistical featuresStatistical features are statistics that distilledfrom the large unlabeled corpus.
They areproved useful in the Chinese word segmenta-tion task.
We define Static Statistical Features(SSFs) as features whose value do not changeduring the training process.
The SSFs in ourapproach includes Mutual information, Punctu-ation information and Accessor variety.
Previ-ous works have already explored the functionsof the three static statistics in the Chinese wordsegmentation task, e.g.
Feng et al(2004); Sunand Xu (2011).
We mainly follow their defini-tions while considering more details and givingsome modification.Mutual informationMutual information (MI) is a quantity thatmeasures the mutual dependence of two randomvariables.
Previous works showed that larger MIof two strings claims higher probability that thetwo strings should be combined.
Therefore, MIcan show the tendency of two strings formingone word.
However, previous works mainly fo-cused on the balanced case, i.e., the MI of stringswith the same length.
In our study we find that,in Chinese, there remains large amount of imbal-anced cases, like a string with length 1 followedby a string with length 2, and vice versa.
Wefurther considered the MI of these string pairsto capture more information.Punctuation informationPunctuations can provide implicit labels forthe characters before and after them.
The char-acter after punctuations must be the first char-acter of a word.
The character before punctua-tions must be the last character of a word.
Whena string appears frequently after punctuations,it tends to be the beginning of a word.
The situ-ation is similar when a string appears frequentlypreceding punctuations.
Besides, the probabil-ity of a string appears in the corpus also affectsthis tendency.
Considering all these factors,we propose ?punctuation rate?
(PR) to capturethis information.
For a string with length lenand probability p in the corpus, we define theleft punctuation rate LPRlen as the number oftimes the string appears after punctuations, di-vided by p. Similarly, the right punctuationrate RPRlen is defines as the number of timesit appears preceding punctuations divided by itsprobability p. The length of string we consideris from 1 to 4.Accessor varietyAccessor variety (AV) is also known as lettersuccessor variety (LSV) (Harris, 1955; Hafer andWeiss, 1974).
If a string appears after or pre-ceding many different characters, this may pro-vide some information of the string itself.
Pre-vious work of Feng et al(2004), Sun and Xu(2011) used AV to represent this statistic.
Sim-ilar to punctuation rate, we also consider bothleft AV and right AV.
For a string s with lengthl, we define the left accessor variety (LAV) asthe types of distinct characters preceding s inthe corpus, and the right accessor variety (RAV)as the types of distinct characters after s in thecorpus.
The length of string we consider is alsofrom 1 to 4.2.4.3 Dynamic statistical featuresThe unlabeled corpus lacks precise labels.
Wecan use the trained tagger to give the unla-beled data ?pseudo-labels?.
These labels can-not guarantee an acceptable precision.
How-ever, the label distribution will not be largelyaffected by small mistakes.
Using the label dis-tribution information is more accurate than us-ing the pseudo-labels directly.Based on this assumption, we propose ?dy-namic statistical features?
(DSFs).
The DSFsare intended to capture label distribution infor-mation given a text context.
The word ?Dy-namic?
is in accordance with the fact that thesefeature values will change during the trainingprocess.We give a formal description of DSFs.
Sup-pose there are K labels in our task.
For example,K = 4 if we take BMES labeling method.
Wedefine the whole character sequence with lengthn as X = (x1, x2 ?
?
?xj ?
?
?xn).
Given a text con-text Ci, where i is current character position,the DSFs can be represented as a list,DSF (Ci) = (DSF (Ci)1, ?
?
?
, DSF (Ci)K)314Each element in the list represents the proba-bility of the corresponding label in the distribu-tion.For convenience, we further define function?count(condition)?
as the total number of timesa ?condition?
is true in the unlabeled corpus.For example, count (current=?a?)
represents thetimes the current character equals ?a?, which isexactly the number of times character ?a?
ap-pears in the unlabeled corpus.According to different types of text contextCi, we can divide DSFs into 3 types:1.Basic DSFFor Basic DSF of Ci, we define D(Ci):D(Ci) = (D(Ci)1, .
.
.
, D(Ci)K)We define Basic DSF with current character po-sition i, text context Ci and label l (the lth di-mension in the list) as:D(Ci)l = P (y = l|Ci = xi)= count(Ci = xi ?
y = l)count(Ci = xi)In this equation, the numerator counts the num-ber of times current character is xi with label l.The denominator counts the number of timescurrent character is xi.We use the term ?Basic?
because this kind ofDSFs only considers the character of position ias its context.
The text context refers to the cur-rent character itself.
This feature captures thelabel distribution information given the charac-ter itself.2.BigramDSFBasic DSF is simple and very easy to imple-ment.
The weakness is that it is less power-ful to describe word-building features.
Althoughcharacters convey context information, charac-ters themselves in Chinese is sometimes mean-ingless.
Character bi-grams can carry more con-text information than uni-grams.
We modifyBasic DSFs to bi-gram level and propose BigramDSFs.For Bigram DSF of Ci, we define B(Ci):B(Ci) = (B(Ci)1, .
.
.
, B(Ci)K)We define Bigram DSF with current characterposition i, text context Ci and label l (the lthdimension in the list) as:B(Ci)l = P (y = l|Ci = xi?jxi?j+1)= count(Ci = xi?jxi?j+1 ?
y = l)count(Ci = xi?jxi?j+1)j can take value 0 and 1.In this equation, the numerator counts thenumber of times current context is xi?jxi?j+1with label l. The denominator counts the num-ber of times current context is xi?jxi?j+1.3.WindowDSFConsidering Basic DSF and Bigram DSF onlymight cause the over-fitting problem, thereforewe introduce another kind of DSF.
We call itWindow DSF, which considers the surroundingcontext of a character and omits the characteritself.For Window DSF, we define W (Ci):W (Ci) = (W (Ci)1, .
.
.
,W (Ci)K)We define Window DSF with current characterposition i, text context Ci and label l (the lthdimension in the list) as:W (Ci)l = P (y = l|Ci = xi?1xi+1)= count(Ci = xi?1xi+1 ?
y = l)count(Ci = xi?1xi+1)In this equation, the numerator counts thenumber of times current context is xi?1xi+1with label l. The denominator counts the num-ber of times current context is xi?1xi+1.2.4.4 Discrete features VS. ContinuousfeaturesThe statistical features may be expressed asreal values.
A more natural way is to use dis-crete values to incorporate them into the se-quence labeling models .
Previous works likeSun and Xu (2011) solve this problem by set-ting thresholds and converting the real valueinto boolean values.
We use a different methodto solve this, which does not need to considertuning thresholds.
In our method, we processstatic and dynamic statistical features using dif-ferent strategies.315For static statistical value:For mutual information, we round the realvalue to their nearest integer.
For punctuationrate and accessor variety, as the values tend tobe large, we first get the log value of the featureand then use the nearest integer as the corre-sponding discrete value.For dynamic statistical value:Dynamic statistical features are distributionsof a label.
The values of DSFs are all percentagevalues.
We can solve this by multiply the proba-bility by an integer N and then take the integerpart as the final feature value.
We set the valueof N by cross-validation..2.5 Conditional Random FieldsOur algorithm is not necessarily limited toa specific baseline tagger.
For simplicity andreliability, we use a simple Conditional Ran-dom Field (CRF) tagger, although other se-quence labeling models like Semi-Markov CRFGao et al(2007) and Latent-variable CRF Sunet al(2009) may provide better results thana single CRF.
Detailed definition of CRF canbe found in Lafferty et al(2001); McCallum(2002); Pinto et al(2003).3 Experiment3.1 Data and metricsWe used the benchmark datasets provided bythe second International Chinese Word Segmen-tation Bakeoff1 to test our approach.
We chosethe Peking University (PKU) data in our exper-iment.
Although the benchmark provides an-other three data sets, two of them are data oftraditional Chinese, which is quite different fromsimplified Chinese.
Another is the data from Mi-crosoft Research (MSR).
We experimented onthis data and got 97.45% in f-score comparedto the state-of-art 97.4% reported in Sun et al(2012).
However, this corpus is much largerthan the PKU corpus.
Using the labeled dataalone can get a relatively good tagger and theunlabeled data contributes little to the perfor-mance.
For simplicity and efficiency, our further1http://www.sighan.org/bakeoff2005/experiments are all conducted on the PKU data.Details of the PKU data are listed in table 4.We also used two un-segmented corpora asunlabeled data.
The first one is Chinese Giga-word2 corpus.
It is a comprehensive archive ofnewswire data.
The second one is articles fromBaike3 of baidu.com.
It is a Chinese encyclope-dia similar to Wikipedia but contains more Chi-nese items and their descriptions.
In the exper-iment we used about 5 million characters fromeach corpus for efficiency.
Details of unlabeleddata can be found in table 5.In our experiment, we did not use any ex-tra resources such as common surnames, part-of-speech or other dictionaries.F-score is used as the accuracy measure.
Wedefine precision P as the percentage of wordsin the output that are segmented correctly.
Wedefine recall R as the percentage of the wordsin reference that are correctly segmented.
ThenF-score is as follows:F = 2 ?
P ?RP +RThe recall of out-of-vocabulary is also taken intoconsideration, which measures the ability of themodel to correctly segment out of vocabularywords.3.2 Main ResultsTable 6 summarizes the segmentation resultson test data with different feature combinations.We performed incremental evaluation.
In thistable, we first present the results of the taggeronly using baseline features.
Then we show theresults of adding SSF and DSF individually.
Inthe end we compare the results of combiningSSF and DSF with baseline features.Because the baseline features is strong toreach a relative good result, it is not easy tolargely enhance the performance.
Neverthe-less, there are significant increases in f-score andOOV-Recall when adding these features.
Fromtable 6 we can see that by adding SSF and DSFindividually, the F-score is improved by +1.1%2http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2003T093http://baike.baidu.com/316Identical words Total word Identical Character Total character5.5 ?
104 1.1 ?
106 5 ?
103 1.8 ?
106Table 4: Details of the PKU dataCorpus Character usedGigaword 5000193Baike 5000147Table 5: Details of the unlabeled data.P R F OOVBaseline 0.950 0.943 0.946 0.676+SSF 0.961 0.953 0.957 0.728+DSF 0.958 0.953 0.955 0.678+SSF+DSF 0.965 0.958 0.961 0.731Table 6: Segmentation results on test data withdifferent feature combinations.
The symbol ?+?means this feature configuration contains features setcontaining the baseline features and all features after?+?.
The size of unlabeled data is fixed as 5 millioncharacters.and +0.9%.
The OOV-Recall is also improved,especially after adding SSFs.
When consideringSSF and DSF together, the f-score is improvedby +1.5% while the OOV-Recall is improved by+5.5%.To compare the contribution of unlabeleddata, we conduct experiments of using differ-ent sizes of unlabeled data.
Note that the SSFsare still calculated using all the unlabeled data.However, each iteration in the algorithm usesunlabeled data with different sizes.Table 7 shows the results when changing thesize of unlabeled data.
We experimented onthree different sizes: 0.5 million, 1 million and 5million characters.P R F OOVDSF(0.5M) 0.962 0.954 0.958 0.727DSF(1M) 0.963 0.955 0.959 0.728DSF(5M) 0.965 0.958 0.961 0.731Table 7: Comparison of results when changing thesize of unlabeled data.
(0.5 million, 1 million and 5million characters).We further experimented on unlabeled corpuswith larger size (up to 100 million characters).However the performance did not change signif-icantly.
Besides, because the number of featuresin our method is very large, using too large un-labeled corpus is intractable in real applicationsdue to the limitation of memory.Our method can keep working well even whenthe labeled data are insufficient.
Table 8 showsthe comparison of f-scores when changing thesize of labeled data.
We compared the resultsof using all labeled data with 3 different situa-tions: using 1/10, 1/2 and 1/4 of all the labeleddata.
In fact, the best system on the Second In-ternational Chinese Word Segmentation bakeoffreached 0.95 in f-score by using all labeled data.From table 8 we can see that our algorithm onlyneeds 1/4 of all labeled data to achieve the samef-score.Baseline +SSF+DSF Improve1/10 0.934 0.943 +0.96%1/4 0.946 0.951 +0.53%1/2 0.952 0.956 +0.42%All 0.957 0.961 +0.42%Table 8: Comparison of f-scores when changing thesize of labeled data.
(1/10, 1/4, 1/2 and all labeleddata.
The size of unlabeled data is fixed as 5 millioncharacters.
)We also explored how the performancechanges as iteration increases.
Figure 1 showsthe change of F-score during the first 10 itera-tions.
From figure 1 we find that f-score has afast improvement in the first few iterations, andthen stables at a fixed point.
Besides, as the sizeof labeled data increases, it converges faster.Using an in-domain corpus and an out-of-domain corpus is better than use one corpusalone.
We compared our approach with themethod which uses only one unlabeled corpus.To use only one corpus, we modify our algorithmto extract DSFs from the Chinese Giga wordcorpus and apply the learned features to itself.317Figure 1: Learning curve of using different size oflabeled dataTable 9 shows the result.
We can see that ourmethod outperforms by +0.2% in f-score and+0.7% in OOV-Recall.Finally, we compared our method with thestate-of-art systems reported in the previous pa-pers.
Table 10 listed the results.
Best05 repre-sents the best system reported on the Second In-ternational Chinese Word Segmentation Bake-off.
CRF + Rule system represents a combina-tion of CRF model and rule based model pre-sented in Zhang et al(2006).
Other three sys-tems all represent the methods using their cor-responding model in the corresponding papers.Note that these state-of-art systems are eitherusing complicated models with semi-Markov re-laxations or latent variables, or modifying mod-els to fit special conditions.
Our system uses asingle CRF model.
As we can see in table 10,our method achieved higher F-scores than theprevious best systems.3.3 Results on NER taskOur method is not limited to the CWS prob-lem.
It is applicable to all sequence labelingproblems.
We applied our method on the Chi-nese NER task.
We used the MSR corpus ofthe sixth SIGHAN Workshop on Chinese Lan-guage Processing.
It is the only NER corpususing simplified Chinese in that workshop.
Wecompared our method with the pure sequence la-beling approach in He and Wang (2008).
We re-implemented their method to eliminate the dif-ference of various CRFs implementations.
Ex-periment results are shown in table 11.
We cansee that our methods works better, especiallywhen handling the out-of-vocabulary named en-tities;4 Related workRecent studies show that character sequencelabeling is an effective method of Chinese wordsegmentation for machine learning (Xue, 2003;Low et al 2005; Zhao et al 2006a,b).
These su-pervised methods show good results.
Unsuper-vised word segmentation (Maosong et al 1998;Peng and Schuurmans, 2001; Feng et al 2004;Goldwater et al 2006; Jin and Tanaka-Ishii,2006) takes advantage of the huge amount of rawtext to solve Chinese word segmentation prob-lems.
These methods need no annotated corpus,and most of them use statistics to help modelthe problem.
However, they usually are less ac-curate than supervised ones.Currently ?feature-engineering?
methodshave been successfully applied into NLP ap-plications.
Miller et al(2004) applied thismethod to named entity recognition.
Koo et al(2008) applied this method to dependency pars-ing.
Turian et al(2010) applied this method toboth named entity recognition and text chunk-ing.
These papers shared the same concept ofword clustering.
However, we cannot simplyequal Chinese character to English word becausecharacters in Chinese carry much less informa-tion than words in English and the clusteringresults is less meaningful.Features extracted from large unlabeled cor-pus in previous works mainly focus on statisti-cal information of characters.
Feng et al(2004)used the accessor variety criterion to extractword types.
Li and Sun (2009) used punctua-tion information in Chinese word segmentationby introducing extra labels ?L?
and ?R?.
Changand Han (2010), Sun and Xu (2011) used richstatistical information as discrete features ina sequence labeling framework.
All these ap-proaches can be viewed as using static statisticsfeatures in a supervised approach.
Our methodis different from theirs.
For the static statisticsfeatures in our approach, we not only considerricher string pairs with the different lengths, butalso consider term frequency when processing318P R F OOVUsing one corpus 0.963 0.955 0.959 0.724Our method 0.965 0.958 0.961 0.731Table 9: Comparison of our approach with using only the Gigaword corpusMethod P R F-scoreBest05 (Chen et al(2005)) 0.953 0.946 0.950CRF + rule-system (Zhang et al(2006)) 0.947 0.955 0.951Semi-perceptron (Zhang and Clark (2007)) N/A N/A 0.945Latent-variable CRF (Sun et al(2009)) 0.956 0.948 0.952ADF-CRF (Sun et al(2012)) 0.958 0.949 0.954Our method 0.965 0.958 0.961Table 10: Comparison of our approach with the state-of-art systemsP R F OOVTraditional 0.925 0.872 0.898 0.712Our method 0.916 0.887 0.902 0.737Table 11: Comparison of our approach with tradi-tional NER systemspunctuation features.There are previous works using features ex-tracted from label distribution of unlabeled cor-pus in NLP tasks.
Schapire et al(2002) use aset of features annotated with majority labelsto boost a logistic regression model.
We aredifferent from their approach because there isno pseudo-example labeling process in our ap-proach.
Qi et al(2009) investigated on largeset of distribution features and used these fea-tures in a self-training way.
They applied themethod on three tasks: named entity recogni-tion, POS tagging and gene name recognitionand got relatively good results.
Our approach isdifferent from theirs.
Although we all considerlabel distribution, the way we use features aredifferent.
Besides, our approach uses two unla-beled corpora which can mutually enhancing toget better result.5 Conclusion and PerspectivesIn this paper, we presented a semi-supervisedmethod for Chinese word segmentation.
Twokinds of new features are used for the itera-tive modeling: static statistical features and dy-namic statistical features.
The dynamic statis-tical features use label distribution informationfor text contexts, and can be adjusted automat-ically during the co-training process.
Experi-mental results show that the new features canimprove the performance on the Chinese wordsegmentation task.
We further conducted exper-iments to show that the performance is largelyimproved, especially when the labeled data isinsufficient.The proposed iterative semi-supervisedmethod is not limited to the Chinese wordsegmentation task.
It can be easily extendedto any sequence labeling task.
For example, itworks well on the NER task as well.
As ourfuture work, we plan to apply our method toother natural language processing tasks, suchas text chunking.AcknowledgmentsThis research was partly supported by Ma-jor National Social Science Fund of China(No.12&ZD227),National High Technology Researchand Development Program of China (863 Pro-gram) (No.
2012AA011101) and National Natu-ral Science Foundation of China (No.91024009).We also thank Xu Sun and Qiuye Zhao for proof-reading the paper.319ReferencesBlum, A. and Mitchell, T. (1998).
Combininglabeled and unlabeled data with co-training.In Proceedings of the eleventh annual confer-ence on Computational learning theory, pages92?100.
ACM.Chang, B. and Han, D. (2010).
Enhancingdomain portability of chinese segmentationmodel using chi-square statistics and boot-strapping.
In Proceedings of the 2010 Con-ference on Empirical Methods in Natural Lan-guage Processing, pages 789?798.
Associationfor Computational Linguistics.Chen, A., Zhou, Y., Zhang, A., and Sun, G.(2005).
Unigram language model for chineseword segmentation.
In Proceedings of the4th SIGHAN Workshop on Chinese LanguageProcessing, pages 138?141.
Association forComputational Linguistics Jeju Island, Korea.Dasgupta, S., Littman, M. L., and McAllester,D.
(2002).
Pac generalization bounds for co-training.
Advances in neural information pro-cessing systems, 1:375?382.Feng, H., Chen, K., Deng, X., and Zheng, W.(2004).
Accessor variety criteria for chineseword extraction.
Computational Linguistics,30(1):75?93.Gao, J., Andrew, G., Johnson, M., andToutanova, K. (2007).
A comparative studyof parameter estimation methods for statisti-cal natural language processing.
In ANNUALMEETING-ASSOCIATION FOR COMPU-TATIONAL LINGUISTICS, volume 45, page824.Goldwater, S., Griffiths, T., and Johnson, M.(2006).
Contextual dependencies in unsuper-vised word segmentation.
In Proceedings ofthe 21st International Conference on Compu-tational Linguistics and the 44th annual meet-ing of the Association for Computational Lin-guistics, pages 673?680.
Association for Com-putational Linguistics.Hafer, M. A. and Weiss, S. F. (1974).
Word seg-mentation by letter successor varieties.
Infor-mation storage and retrieval, 10(11):371?385.Harris, Z. S. (1955).
From phoneme to mor-pheme.
Language, 31(2):190?222.He, J. and Wang, H. (2008).
Chinese named en-tity recognition and word segmentation basedon character.
In Sixth SIGHAN Workshop onChinese Language Processing, page 128.Jin, Z. and Tanaka-Ishii, K. (2006).
Unsu-pervised segmentation of chinese text by useof branching entropy.
In Proceedings of theCOLING/ACL on Main conference postersessions, pages 428?435.
Association for Com-putational Linguistics.Koo, T., Carreras, X., and Collins, M. (2008).Simple semi-supervised dependency parsing.Lafferty, J., McCallum, A., and Pereira, F.(2001).
Conditional random fields: Proba-bilistic models for segmenting and labeling se-quence data.Li, Z. and Sun, M. (2009).
Punctuationas implicit annotations for chinese wordsegmentation.
Computational Linguistics,35(4):505?512.Low, J., Ng, H., and Guo, W. (2005).
Amaximum entropy approach to chinese wordsegmentation.
In Proceedings of the FourthSIGHAN Workshop on Chinese LanguageProcessing, volume 164.
Jeju Island, Korea.Maosong, S., Dayang, S., and Tsou, B.
(1998).Chinese word segmentation without using lex-icon and hand-crafted training data.
In Pro-ceedings of the 17th international confer-ence on Computational linguistics-Volume 2,pages 1265?1271.
Association for Computa-tional Linguistics.McCallum, A.
(2002).
Efficiently inducing fea-tures of conditional random fields.
In Proceed-ings of the Nineteenth Conference on Uncer-tainty in Artificial Intelligence, pages 403?410.Morgan Kaufmann Publishers Inc.Miller, S., Guinness, J., and Zamanian, A.(2004).
Name tagging with word clustersand discriminative training.
In Proceedings ofHLT-NAACL, volume 4.Peng, F. and Schuurmans, D. (2001).
Self-supervised chinese word segmentation.
Ad-320vances in Intelligent Data Analysis, pages238?247.Pinto, D., McCallum, A., Wei, X., and Croft,W.
(2003).
Table extraction using conditionalrandom fields.
In Proceedings of the 26th an-nual international ACM SIGIR conference onResearch and development in informaion re-trieval, pages 235?242.
ACM.Qi, Y., Kuksa, P., Collobert, R., Sadamasa,K., Kavukcuoglu, K., and Weston, J.
(2009).Semi-supervised sequence labeling with self-learned features.
In Data Mining, 2009.ICDM?09.
Ninth IEEE International Confer-ence on, pages 428?437.
IEEE.Schapire, R., Rochery, M., Rahim, M., andGupta, N. (2002).
Incorporating priorknowledge into boosting.
In MACHINELEARNING-INTERNATIONAL WORK-SHOP THEN CONFERENCE-, pages538?545.Sun, W. and Xu, J.
(2011).
Enhancing chi-nese word segmentation using unlabeled data.In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing,pages 970?979.
Association for ComputationalLinguistics.Sun, X., Wang, H., and Li, W. (2012).
Fast on-line training with frequency-adaptive learningrates for chinese word segmentation and newword detection.
In Proceedings of the 50th An-nual Meeting of the Association for Computa-tional Linguistics (Volume 1: Long Papers),pages 253?262, Jeju Island, Korea.
Associa-tion for Computational Linguistics.Sun, X., Zhang, Y., Matsuzaki, T., Tsuruoka,Y., and Tsujii, J.
(2009).
A discriminativelatent variable chinese segmenter with hybridword/character information.
In Proceedings ofHuman Language Technologies: The 2009 An-nual Conference of the North American Chap-ter of the Association for Computational Lin-guistics, pages 56?64.
Association for Compu-tational Linguistics.Turian, J., Ratinov, L., and Bengio, Y.
(2010).Word representations: a simple and gen-eral method for semi-supervised learning.
InProceedings of the 48th Annual Meeting ofthe Association for Computational Linguis-tics, pages 384?394.
Association for Compu-tational Linguistics.Xue, N. (2003).
Chinese word segmentation ascharacter tagging.
Computational Linguisticsand Chinese Language Processing, 8(1):29?48.Yarowsky, D. (1995).
Unsupervised word sensedisambiguation rivaling supervised methods.In Proceedings of the 33rd annual meetingon Association for Computational Linguistics,pages 189?196.
Association for ComputationalLinguistics.Zhang, R., Kikui, G., and Sumita, E. (2006).Subword-based tagging by conditional ran-dom fields for chinese word segmentation.
InProceedings of the Human Language Technol-ogy Conference of the NAACL, CompanionVolume: Short Papers, pages 193?196.
Asso-ciation for Computational Linguistics.Zhang, Y. and Clark, S. (2007).
Chi-nese segmentation with a word-based percep-tron algorithm.
In ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONALLINGUISTICS, volume 45, page 840.Zhao, H., Huang, C., and Li, M. (2006a).
Animproved chinese word segmentation systemwith conditional random field.
In Proceed-ings of the Fifth SIGHAN Workshop on Chi-nese Language Processing, volume 117.
Syd-ney: July.Zhao, H., Huang, C., Li, M., and Lu, B.
(2006b).Effective tag set selection in chinese word seg-mentation via conditional random field mod-eling.
In Proceedings of PACLIC, volume 20,pages 87?94.321
