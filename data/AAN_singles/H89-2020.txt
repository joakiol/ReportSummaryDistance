A Simple Statistical Class Grammar for Measuring Speech RecognitionPerformanceAlan DerrR ichard SchwartzBBN Systems and Technologies  Corporat ionCambr idge ,  MA 02138ABSTRACTIn this paper we will discuss our development of a newgrammar that is to be used for evaluation of speechrecognition systems.
The grammar is a statistical first-order class grammar and has been developed for fortwo different ask domains (the DARPA 1000-word Re-source Management domain and a 2000-word personneldatabase domain).
We will first motivate the develop-ment of this grammar, next describe the grammar andits development, and finally present results and conclu-sions.1 MOTIVAT IONIn recent DARPA speech community-wide r cognitionsystem evaluations, the recognition systems have beentested using two grammatical conditions: no grammar(or null grammar), and the word-pair grammar.
Thesegrammars suffer from several inadequacies.The null grammar simply forces the recognition sys-tem to partition the input speech into whole-word unitswithout using any knowledge of the language to placerestrictions on the possible sequences of words that areallowed.
As a result, the "no grammar" test conditionprovides only a worst case recognition test point for theevaluation of recogmtion systems.The word-pair grammar, on the other hand, was de-rived from the sentence patterns that were used to gener-ate the 2800 sentences in the Resource Management cor-pus.
Only pairs of words that could occur in a sentencegenerated by the patterns was allowed in the word-pairgrammar.
On the average, each word in the vocabularycan be followed by about 60 words.
No probabilitiesare assigned to the different words Oust 0 or 1).
Asa result, the recognition rate is artificially high, sincemany reasonable word sequences are disallowed.
At thesame time, ff a real sentence has one of these disallowedword-pairs, it could not be recognized correctly.As a result of the unrealistic restrictions imposed bythe word-pair grammar, the recognition performance ofsystems using this grammar is too high to allow reliablemeasurement of system improvements without resortingtothe use of very large evaluation test sets.
Creating newsentences for the test set becomes a problem, since thereis a danger that new sentences that are within the taskdomain may not be parsed tallowed) by the word-pairgrammar.We desired a grammar that would overcome the de-ficiencies of the null and word-pair grammars, while atthe same time providing several additional benefits.
Wewanted the new grammar to capture statistics that arerepresentative of the real data in the task domain while,at the same time, providing full coverage (i.e., allowingall sentences that are possible within the task domain tobe parsed by the grammar).
We also wanted the gram-mar to be "tunable" to some degree, by allowing itsperplexity to be adjusted.
Increasing the glammar's per-plexity will allow us to simulate a recognition system'sperformance with a more difficult (e.g., larger) task do-main.
For this reason we used several approximations inthe method for estimating the grammar that caused thegrammar to have higher perplexity.
Finally.
we wanteda grammar that would allow us to change task domainswith relative ease.2 DESCRIPT IONThe grammar that we developed is a statistical first-orderclass grammar m which the probability of a word (W1)being followed by another word (W2) is given by:P(W21~V1) = E P(CIlWI)P(C21C1)P(W2',C2)pathJWhere C1 is each of the classes to which WI  be-longs, and C2 is each of the classes to which W2 be-147longs.
Since each of W I and W2 may belong to mul-tiple classes, the summation is over all possible pathsfxom W1 to W2.
This is represented graphically below:l/PtCl\[?
- wo.d ntxloQ - class node w/~a~enea kx~ fte.
:Note that, in the diagram, the silence at the beginningof a sentence ("start silence") and the silence at the endof a sentence ("end silence") are simply special cases ofWI and |V2, respectively, where each is in a separateclass.
The "'class node w/silence loop" indicates that asilence may be inserted between each word.In our work to date, we have made two simplifyingassumptions.
The conditional probability P(CI iWI)  isapproximated by:Nwlgcl -~ for Wl in CIP(CI i~VI) = 0 otherwiseWhere Nw~c~ is the number of classes of whichword W1 is a member.
(For example, if a word is amember of two classes, PfCI lWI)  will be 0.5 for eachof those classes and 0.0 for all other classes.)
A similarapproximation is made for P(W2--C2), where:Nw2Ec2 -1 for W2 in C2P(W2 \[C2) = 0 otherwiseWhere NwzEc2 is the number of words in class C2.The probabilities P(CI IWD and PfW2!C2) are fixedand not changed during the training of the grammar.With this simplification, the only term that must be esti-mated during the training of the grammar is P(C2!CI),the class-to-class transition probabilities.3 GRAMMAR TRAININGTo train the grammar, we began by assigning class(es)to each word in the vocabulary.
A word may be as-signed to multiple classes.
For example, the word "SEA-WOLF" is assigned to one class: ship-name.
On theother hand, the word "DISPLAY" is assigned to threeclasses: command-verb, adjectave, and noun.
Once thewords are assigned to appropriate classes, the statistics ofthe grammar were counted irectly from the training databy counting the number of transitions from each class toeach other class.
These counts were then padded slightly(to account for unobserved class-to.class transitions) toallow the grammar to parse sentences containing unob-served class transitions.
Finally, the grammar was testedon a test set to measure its perplexity.4 GRAMMAR PERFORMANCEBelow is a summary some of the characteristics of thestatistical first-order class grammar with 99 classes forthe DARPA 1000-word Resource Management task do-main.
with null and word-pair grammar characteristicsgiven for comparison.~t PerplexityGrammar Coverage \[Train \[ TestNull 100% 992 992Word-pair 80% 60 NAStar.
class 100% 72 77Recog.error12.6%2.5%5.9%Table 1: Grammar Performance ComparisonThe class grammar figures given here are based on agrammar trained using all 2800 sentences available for148the 1000 word DARPA resource management task do-main.
The training set perplexity is computed over theentire training set and the test set perplexity is computedover the 300 sentences used for the May 1988 standardsystem evaluation.
The word-pair coverage and perplex-ity are approximate heoretical figures assuming an inde-pendent test set.
The test set perplexity for the word-pairis degenerate, since, if a single sentence doesn't parse,the perplexity becomes infinite.In informal tests, we were able to "tune" the perplexityof the grammar by adjusting the number of classes intowhich the words are categorized.
On a fixed test set of100 sentences and the full training set of 2800 sentences,the perplexity varied from 203 (with 50 classes) to 62(with 168 classes).We have obtained some preliminary results for a sta-tistical class grammar designed for a 2170 word per-sonnel database access task domain.
The grammar uses637 classes (l to 5 per word) and is trained using 750sentences.
The perplexity of this grammar on an inde-pendent est set of 200 sentences was measured to be89.4.
The perplexity measured on the training set was46.1.
We haven't yet performed a full set of recognitionexperiments using this grammar.AcknowledgementsThe work reported here was supported by the AdvancedResearch Projects Agency and was momtored by the Of.rice of Naval Research under N00014-85-C-.0279.
Theviews and conclusions contained in this document arethose of the authors and should not be interpreted asnecessarily representing the official policies, either ex-pressed or implied, of the Defense Advanced ResearchProjects Agency or the United States Government.5 CONCLUSIONSWe have described the development of a statistical first-order class grammar.
The structure of this grammar al-lows for relatively easy development of a new grammarfor a new task domain.
The grammar provides for fullcoverage of the task domain, even if all possible classsequences are not observable in the data used to trainthe grammar probabilities.
It also provides a method foradjusting the perplexity of the grammar by varying thenumber of classes in the grammar.We recommend that this grammar should be madeanother standard grammar for the DARPA speech com-mumty.
We believe that this grammar could extend thelife of the Resource Management task by decreasing therecogmtion system's performance while still placing re.straints on the possible sequencing of words in a mean-ingful way.
Decreasing the recognition performance willallow the (statistically significant) measurement of smallsystem improvements without needing to increase thesize of the evaluation test.
We also recommend thatthis grammar eplace the word-pair for official systemevaluations.149
