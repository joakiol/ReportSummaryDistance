BioNLP 2007: Biological, translational, and clinical language processing, pages 105?112,Prague, June 2007. c?2007 Association for Computational LinguisticsFrom Indexing the Biomedical Literature to Coding Clinical Text:Experience with MTI and Machine Learning ApproachesAlan R. Aronson1, Olivier Bodenreider1, Dina Demner-Fushman1, Kin Wah Fung1,Vivian K. Lee1,2, James G. Mork1, Aur?lie N?v?ol1, Lee Peters1, Willie J. Rogers11Lister Hill CenterNational Library of MedicineBethesda, MD 20894{alan, olivier, demnerd,kwfung, mork, neveola,peters, wrogers}@nlm.nih.gov2Vanderbilt UniversityNashville, TN 37235vivian.lee@vanderbilt.eduAbstractThis paper describes the application of anensemble of indexing and classificationsystems, which have been shown to be suc-cessful in information retrieval and classi-fication of medical literature, to a new taskof assigning ICD-9-CM codes to the clini-cal history and impression sections of radi-ology reports.
The basic methods used are:a modification of the NLM Medical TextIndexer system, SVM, k-NN and a simplepattern-matching method.
The basic meth-ods are combined using a variant of stack-ing.
Evaluated in the context of a MedicalNLP Challenge, fusion produced an F-score of 0.85 on the Challenge test set,which is considerably above the meanChallenge F-score of 0.77 for 44 participat-ing groups.1 IntroductionResearchers at the National Library of Medicine(NLM) have developed the Medical Text Indexer(MTI) for the automatic indexing of the biomedicalliterature (Aronson et al, 2004).
The unsupervisedmethods within MTI were later successfully com-bined with machine learning techniques and ap-plied to the classification tasks in the GenomicsTrack evaluations at the Text Retrieval Conference(TREC) (Aronson et al, 2005 and Demner-Fushman et al, 2006).
This fusion approach con-sists of using several basic classification methodswith complementary strengths, combining the re-sults using a modified ensemble method based onstacking (Ting and Witten, 1997).While these methods have shown reasonableperformance on indexing and retrieval tasks ofbiomedical articles, it remains to be determinedhow they would perform on a different biomedicalcorpus (e.g., clinical text) and on a different task(e.g., coding to a different controlled vocabulary).However, except for competitive evaluations suchas TREC or BioCreAtIvE, corpora and gold stan-dards for such tasks are generally not available,which is a limiting factor for such studies.
For asurvey of currently available corpora and devel-opments in biomedical language processing, seeHunter and Cohen, 2006.The Medical NLP Challenge 1  sponsored by anumber of groups including the ComputationalMedicine Center (CMC) at the Cincinnati Chil-dren?s Hospital Medical Center gave us the oppor-tunity to apply our fusion approach to a clinicalcorpus.
The Challenge was to assign ICD-9-CMcodes (International Classification of Diseases, 9thRevision, Clinical Modification) 2  to clinical textconsisting of anonymized clinical history and im-pression sections of radiology reports.The Medical NLP Challenge organizers distrib-uted a training corpus of almost 1,000 of the ano-nymized, abbreviated radiology reports along with1 See www.computationalmedicine.org/challenge/.2 See www.cdc.gov/nchs/icd9.htm.105gold standard ICD-9-CM assignments for eachreport obtained via a consensus of three independ-ent sets of assignments.
The primary measure forthe Challenge was defined as the balanced F-score,with a secondary measure being cost-sensitive ac-curacy.
These measures were computed for sub-missions to the Challenge based on a test corpussimilar in size to the training corpus but distributedwithout gold standard code assignments.The main objective of this study is to determinewhat adaptation of the original methods is requiredto code clinical text with ICD-9-CM, in contrast toindexing and retrieving MEDLINE?.
Note that anearlier study (Gay et al, 2005) showed that onlyminor adaptations were required in extending theoriginal model to full-text biomedical articles.
Asecondary objective is to evaluate the performanceof our methods in this new setting.2 MethodsIn early experimentation with the training corpusprovided by the Challenge organizers, we discov-ered that several of the training cases involved ne-gated assertions in the text and that deleting theseimproved the performance of all basic methodsbeing tested.
For example, ?no pneumonia?
occursmany times in the impression section of a report,sometimes with additional context.
Section 2.1describes the process we used to remove these ne-gated expressions; section 2.2 consists of descrip-tions of the four basic methods used in this study;and section 2.3 defines the fusion of the basicmethods to form a final result.2.1 Document PreparationThe NegEx program (Chapman et al, 2001a and2001b, and Goldin and Chapman, 2003), whichdiscovers negated expressions in text, was used tofind negated expressions in the training and testcorpora using a dictionary generated from conceptsfrom the 2006AD version of the UMLS?
Metathe-saurus?
(excluding the AMA vocabularies).
A ta-ble containing the concept unique identifier (CUI)and English string (STR with LAT=?ENG?)
wasextracted from the main concept table, MRCON,and was used as input to NegEx to generate a dic-tionary that was later used as the universe of ex-pressions which NegEx could find to be negated inthe target corpora.
(See the Appendix for examplesof the input and output to this process.
)The XML text of the training and test corporawas converted to a tree representation and thentraversed, operating on one radiology report at atime.
The clinical history and impression sectionsof each report were tokenized to allow whitespaceto be separated from the punctuation, numbers andalphabetic text.
The concepts from the UMLS weretokenized in the same way, to allow the conceptsfound by NegEx to be aligned with the text.
Thenegation phrases discovered by NegEx were alsotokenized to find the appropriate negation phrasepreceding or trailing the target concept.
Using thelocation information obtained by matching the setof one or more target concepts and the associatednegation phrase, the overlapping concept spanswere merged and the span for the negation phraseand the outermost negated concept was removed.Any intervening concepts associated with the samenegation phrase were removed, too.
The abbrevi-ated tree representation was then re-serialized backinto XML.As an example of our use of NegEx, considerthe report with clinical history ?13-year 2-month -old female evaluate for cough.?
and impression?No focal pneumonia.?
After removal of negatedtext, the clinical history becomes ?13-year 2-month- old female?, and the discussion is empty.2.2 Basic MethodsThe four basic methods used for the Medical NLPChallenge are MTI (a modification of NLM?sMedical Text Indexer system), SVM (SupportVector Machines), k-NN (k Nearest Neighbors)and Pattern Matching (a simple, pattern-based clas-sifier).
Each of these methods is described here.Note that the MTI method uses a ?Restrict to ICD-9-CM?
algorithm that is described in the next sec-tion.MTI.
The original Medical Text Indexer (MTI)system, shown in Figure 1, consists of an infra-structure for applying alternative methods of dis-covering MeSH?
headings for citation titles andabstracts and then combining them into an orderedlist of recommended indexing terms.
The top por-tion of the diagram consists of two paths, or meth-ods, for creating a list of recommended indexingterms: MetaMap Indexing and PubMed?
RelatedCitations.
The MetaMap Indexing path actually106computes UMLS Metathesaurus concepts, whichare passed to the Restrict to MeSH process(Bodenreider et al, 1998).
The results from eachpath are weighted and combined using Post-Processing, which also refines the results to con-form to NLM indexing policy.
The system ishighly parameterized not only by path weights butalso by several parameters specific to the Restrictto MeSH and Post-Processing processes.Figure 1: Medical Text Indexer (MTI) SystemFor use in the Challenge, the Medical Text In-dexer (MTI) program itself required few adapta-tions.
Most of the changes involved the environ-ment from which MTI obtains the data it useswithout changing the normal parameter settings.We also added a further post-processing compo-nent to filter our results.For the environment, we replaced MTI?s normal?Restrict to MeSH?
algorithm with a ?Restrict toICD-9-CM?
algorithm, described below, in orderto map UMLS concepts to ICD-9-CM codes in-stead of MeSH headings.
We also trained the Pub-Med Related Citations component, TexTool (Ta-nabe and Wilbur, 2002), on the Medical NLP Chal-lenge training data instead of the entire MED-LINE/PubMed database as is the case for normalMTI use at NLM.
For both of these methods, weused the actual ICD-9-CM codes to mimic UMLSCUIs used internally by MTI.To create the new training data for the TexTool(Related Citations), we reformatted the MedicalNLP Challenge training data into a pseudo-MEDLINE format using the ?doc id?
componentas the PMID, the ?CLINICAL_HISTORY?
textcomponent for the Title, the ?IMPRESSION?
textcomponent for the Abstract, and all of the?CMC_MAJORITY?
codes as MeSH Headings(see Figure 2).
This provided us with direct ICD-9-CM codes to work with instead of MeSH Head-ings.<doc id="97663756" type="RADIOLOGY_REPORT"><codes><code origin="CMC_MAJORITY" type="ICD-9-CM">780.6</code><code origin="CMC_MAJORITY" type="ICD-9-CM">786.2</code><code origin="COMPANY3" type="ICD-9-CM">786.2</code><code origin="COMPANY1" type="ICD-9-CM">780.6</code><code origin="COMPANY1" type="ICD-9-CM">786.2</code><code origin="COMPANY2" type="ICD-9-CM">780.6</code><code origin="COMPANY2" type="ICD-9-CM">786.2</code></codes><texts><text origin="CCHMC_RADIOLOGY"type="CLINICAL_HISTORY">Cough and fever.</text><text origin="CCHMC_RADIOLOGY"type="IMPRESSION">Normal radiographic appear-ance of the chest, no pneumonia.</text></texts></doc>PMID- 97663756TI  - Cough and fever.AB  - Normal radiographic appearance of thechest, no pneumonia.MH  - Fever (780.6)MH  - Cough (786.2)Figure 2: XML Medical NLP Training Data modi-fied to pseudo-ASCII MEDLINE formatWithin MTI we also utilized an experimentaloption for MetaMap (Composite Phrases), whichprovides a longer UMLS concept match than usual.We did not use the following: (1) UMLS concept-specific checking and exclusion sections; and (2)the MeSH Subheading generation, checking, andremoval elements, since they were not needed forthis Challenge.
We then had MTI use the new Re-107strict to ICD-9-CM file and the new TexTool togenerate its results.Restrict to ICD-9-CM.
The mapping of everyUMLS concept to ICD-9-CM developed for theMedical NLP Challenge is an adaptation of theoriginal mapping to MeSH, later generalized to anytarget vocabulary (Fung and Bodenreider, 2005).Based on the UMLS Metathesaurus, the mappingutilizes four increasingly aggressive techniques:synonymy, built-in mappings, hierarchical map-pings and associative mappings.
In order to complywith coding rules in ICD-9-CM, mappings to non-leaf codes are later resolved into leaf codes.Mappings to ICD-9-CM are identified throughsynonymy when names from ICD-9-CM are in-cluded in the UMLS concept identified byMetaMap.
For example, the ICD-9-CM code 592.0Calculus of kidney is associated with the UMLSconcept C0392525 Nephrolithiasis through synon-ymy.Built-in mappings are mapping relations be-tween UMLS concepts implied from mappingsprovided by source vocabularies in the UMLS.
Forexample, the UMLS concept C0239937 Micro-scopic hematuria is mapped to the conceptC0018965 (which contains the ICD-9-CM code599.7 Hematuria) through a mapping provided bySNOMED CT.In the absence of a mapping through synonymyor built-in mapping, a hierarchical mapping isattempted.
Starting from the concept identified byMetaMap, a graph of ancestors is built by first us-ing its parent concepts and broader concepts, thenadding the parent concepts and broader concepts ofeach concept, recursively.
Semantic constraints(based on semantic types) are applied in order toprevent semantic drift.
Ancestor concepts closestto the MetaMap source concept are selected fromthe graph.
Only concepts that can be resolved intoICD-9-CM codes (through synonymy or built-inmapping) are selected.
For example, starting fromC0239574 Low grade pyrexia, a mapping is foundto ICD-9-CM code 780.6 Fever, which is con-tained in the concept C0015967, one of the ances-tors of C0239574.The last attempt to find a mapping involves notonly hierarchical, but also associative relations.Instead of starting from the concept identified byMetaMap, associative mappings explore the con-cepts in associative relation to this concept.
Forexample, the concept C1458136 Renal stone sub-stance is mapped to ICD-9-CM code 592.0 Calcu-lus of kidney.Finally, when the identified ICD-9-CM codewas not a leaf code (e.g., 786.5 Chest pain), weremapped it to one of the corresponding leaf codesin the training set where possible (e.g., 786.50 Un-specified chest pain).Of the 2,331 UMLS concepts identified byMetaMap in the test set after freezing the method,620 (27%) were mapped to ICD-9-CM.
More spe-cifically, 101 concepts were mapped to one of the45 target ICD-9-CM codes present in the trainingset.
Of the 101 concepts, 40 were mapped throughsynonymy, 11 through built-in mappings, 40through hierarchical mapping and 10 through asso-ciative mapping.After the main MTI processing was completed,we applied a post-processing filter, restricting ourresults to the list of 94 valid combinations of ICD-9-CM codes provided in the training set (hence-forth referred to as allowed combinations) andslightly emphasizing MetaMap results.
Examplesof the post-processing rules are:?
If MTI recommended 079.99 (Unspecifiedviral infection in conditions?)
via eitherMetaMap or Related Citations, use 079.99,493.90 (Asthma, unspecified type?
), and780.6 (Fever) for indexing.
This is the onlyvalid combination for this code based on thetraining corpus.?
Similarly, if MTI recommended ?Enlarge-ment of lymph nodes?
(785.6) via theMetaMap path with a score greater thenzero, use 785.6 and 786.2 (Cough) for in-dexing.The best F-score (F = 0.83) for the MTI methodwas obtained on the training set using the negation-removed text.
This was a slight improvement overusing the original text (F = 0.82).SVM.
We utilized Yet Another Learning Envi-ronment3 (YALE), an open source application de-veloped for machine learning and data mining, todetermine the data classification performance ofsupport vector machine (SVM) learning on the3 See http://rapid-i.com.108training data.
To prepare the Challenge data foranalysis, we removed all stop words and createdfeature vectors for the free text extracted from the?CLINICAL_HISTORY?
and ?IMPRESSION?fields of the records.
Since both the training andtest Challenge data had a known finite number ofindividual ICD-9-CM labels (45) and distinct com-binations of ICD-9-CM labels (94), the data wasprepared both as feature vectors for 45 individuallabels as well as a model with 94 combination la-bels.
In addition, the feature vectors were createdusing both simple term frequency as well as in-verse document frequency (IDF) weighting, wherethe weight is (1+log(term frequency))*(totaldocuments/document frequency).
There were thusa total of four feature vector datasets: 1) 45 indi-vidual ICD-9-CM labels and simple term fre-quency, 2) 45 ICD-9-CM labels and IDF weight-ing, 3) 94 ICD-9-CM combinations and simpleterm frequency, and 4) 94 ICD-9-CM combina-tions and IDF weighting.The YALE tool encompasses a number of SVMlearners and kernel types.
For the classificationproblem at hand, we chose the C-SVM learner andthe radial basis function (rbf) kernel.
The C-SVMlearner attempts to minimize the error function?=+NiiT Cww1,21 ?Niandbxw iiiTi ,,1,01))(( K=??
?+ ???
?where w is the vector of coefficients, b is a con-stant, ?
is the kernel function, x are the independ-ent variables, and ?i are parameters for handlingthe inputs.
C > 0 is the penalty parameter of theerror function.
The rbf kernel is defined as K(x,x?)
= exp(??
|x ?
x?|2), ?
> 0 where ?
is a kernelparameter that determines the rbf width.
We rancross-validation experiments using YALE on alltraining datasets and varying C (10, 100, 1000,10000) and ?
(0.01, 0.001, 0.0001, 0.00001) to de-termine the optimal C and ?
combination.
Thecross-validation experiments generated classifica-tion models that were then applied to the completetraining datasets to analyze the performance of thelearner.
The 94 ICD-9-CM combination and sim-ple term frequency dataset with C = 10000 and ?
=0.01 had the best F-score at 0.86.
The best F-scorefor the 94 ICD-9-CM combination and IDF weightdataset was 0.79, where C = 0.001 and ?
= 10000.Further preprocessing the training dataset byremoving negated expressions was found to im-prove the best F-score from 0.86 to 0.87.
The C =10000 and ?
= 0.01 combination was then appliedto the test dataset, which was preprocessed to re-move negation and stop words and transformed toa feature vector using 94 ICD-9-CM combinationsand simple term weighting.
The predicted ICD-9-CM classifications and confidence of the predic-tions for each clinical free text report were outputand later combined with other methods to optimizethe accuracy and precision of our ICD-9-CM clas-sifications.k-NN.
The Challenge training set was used tobuild a k-NN classifier.
The k-NN classificationmethod works by identifying, within a labelled set,documents similar to the document being classi-fied, and inferring a classification for it from thelabels of the retrieved neighbors.The free text in the training data set was proc-essed to obtain a vector-space representation of thepatient reports.Several methods of obtaining this representationwere tested: after stop words were removed, simpleterm frequency and inverse document frequency(IDF) weighting were applied alternatively.
Ahigher weight was also given to words appearing inthe history portion of the text (vs. impression).Eventually, the most efficient representation wasobtained by using controlled vocabulary terms ex-tracted from the free text with MetaMap.4 Furtherprocessing on this representation of the trainingdata showed that removing negated portions of thefree text improved the results, raising the F-scorefrom 0.76 to 0.79.Other parameters were also assessed on thetraining data, such as the number of neighbors touse (2 was found to be the best vs. 5, 10 or 15) andthe restriction of the ICD-9-CM predictions to theset of 94 allowed combinations.
When the predic-tion for a given document was not within the set ofallowed 94 combinations, an allowed subset of theICD-9-CM codes predicted was selected based onthe individual scores obtained for each ICD-9-CMcode.The best F-score (F = 0.79) obtained on thetraining set used the MetaMap-based representa-4 Note that this use of MetaMap is independent of itsinclusion as a component of MTI.109tion with simple frequency counts on the text withnegated expressions removed.
ICD-9-CM predic-tions were obtained from the nearest neighbors andrestricted to one of the 94 allowed combinations.Pattern Matching.
We developed a pattern-matching classifier as a baseline for our more so-phisticated classification methods.
A list of allUMLS string representations for each of 45 codes(including synonyms from source vocabulariesother than ICD-9-CM) was created as described inthe MTI section above.
The strings were then con-verted to lower case, punctuation was removed,and strings containing terms unlikely to be foundin a clinical report were pruned.
For example, Ab-domen NOS pain and Abdominal pain (finding)were reduced to abdominal pain.
For the same rea-sons, some of the strings were relaxed into pat-terns.
For example, it is unlikely to see PAINCHEST in a chart, but very likely to find pain inchest.
The string, therefore, was relaxed to the fol-lowing pattern: pain.*chest.
The text of the clinicalhistory and the impression fields of the radiologyreports with negated expressions removed (seeSection 2.2) was broken up into sentences.
Eachsentence was then searched for all available pat-terns.
A corresponding code was assigned to thedocument for each matched pattern.
This patternmatching achieved F-score = 0.79 on the trainingset.
To reduce the number of codes assigned to adocument, a check for allowed combinations wasadded as a post-processing step.
The combinationof assigned codes was looked up in the table ofallowed codes.
If not present, the codes were re-duced to the combination of assigned codes mostfrequently occurring in the training set.
Thisbrought the F-score up to 0.84 on the training data.As the performance of this classifier was compara-ble to other methods, we decided to include theseresults when combining the predictions of the otherclassifiers.2.3 Fusion of  Basic Methods: StackingExperience with ad hoc retrieval tasks in the TRECGenomics Track has shown that combining predic-tions of several classifiers either significantly im-proves classification results, or at least providesmore consistent and stable results when the train-ing data set is small (Aronson et al, 2005).
Wetherefore experimented with stacking (Ting andWitten, 1997), using a simple majority vote and aunion of all assigned codes as baselines.
The pre-dictions of base classifiers described in the previ-ous section were combined using our re-implementation of the stacked generalization pro-posed by Ting and Witten.3 ResultsTable 1 shows the results obtained for the trainingset.
The best stacking results were obtained usingpredictions of all four base classifiers on the textwith deleted negated expressions and with check-ing for allowed combinations.
We retained all finalpredictions with probability of being a valid codegreater than 0.3.
Checking for the allowed combi-nations for the ensemble classifiers degraded the F-score significantly.Classifier F-scoreMTI 0.83SVM 0.87 (x-validation)k-NN 0.79 (x-validation)Pattern Matching 0.84Majority 0.82Stacking 0.89Table 1: Training results for each classifier, the ma-jority and stackingSince stacking produced the best F-score on thetraining corpus and is known to be more robustthan the individual classifiers, the correspondingresults for the test corpus were submitted to theChallenge submission website.
The stacking resultsfor the test corpus achieved an F-score of 0.85 anda secondary, cost-sensitive accuracy score of 0.83.For comparison purposes, 44 Challenge submis-sions had a mean F-score of 0.77 with a maximumof 0.89.
Our F-score of 0.85 falls between the 70thand 75th percentiles.4 DiscussionIt is significant that it was fairly straightforward toport various methods developed for ad hoc MED-LINE citation retrieval, indexing and classificationto the assignment of codes to clinical text.
Themodifications to MTI consisted of replacing Re-strict to MeSH with Restrict to ICD-9-CM, trainingthe Related Citations method on clinical text andreplacing MTI?s normal post-processing with amuch simpler version.
Preprocessing the text using110NegEx to remove negated expressions was a fur-ther modification of the overall approach.It is noteworthy that a simple pattern-matchingmethod performed as well as much more sophisti-cated methods in the effort to fuse results fromseveral methods into a final outcome.
This unex-pected success might be explained by the follow-ing limitations of the Challenge.Possible limitations on the extensibility of thecurrent research arise from two observations: (1)the Challenge cases were limited to two relativelynarrow topics, cough/fever/pneumonia and uri-nary/kidney problems; and (2) the clinical text wasalmost error-free, a situation that would not be ex-pected in the majority of clinical text.
It is possiblethat these conditions contributed to the success ofthe pattern-matching method but also causedanomalous behavior, such as the fact that simplefrequency counts provided a better representationthan IDF for the SVM and k-NN methods.Finally, as a result of low confidence in theICD-9-CM code assignment, no codes were as-signed to 29 records in the test set.
It is worthwhileto explore the causes for such null assignments.One of the reasons for low confidence could be theaggressive pruning of the text by the negation algo-rithm.
For example, after removal of negated textin the sample report given in section 2.1, the onlyremaining text is ?13-year 2-month - old female?from the clinical history field; this provided noevidence for code assignment.
Secondly, in somecases the original text was not sufficient for confi-dent code assignment.
For example, for the docu-ment with clinical history ?Bilateral grade 3.?
andimpression ?Interval growth of normal appearingKidneys?, no code was assigned by the SVM, k-NN, or pattern-matching classifiers.
Code 593.70corresponding to the UMLS concept Vesicouret-eral reflux with reflux nephropathy, unspecified orwithout reflux nephropathy was assigned by MTIwith a very low confidence, which was not suffi-cient for the final assignment of the code.
The thirdreason for assigning no code to a document wasthe wide range of assignments provided by thebase classifiers.
For example, for the followingdocument: ?CLINICAL_HISTORY: 3-year - oldmale with history of left ureteropelvic and uret-erovesical obstruction.
Status post left pyeloplastyand left ureteral reimplantation.
IMPRESSION: 1.Stable appearance and degree of hydronephrosisinvolving the left kidney.
Stable urothelial thicken-ing.
2.
Interval growth of kidneys, left greater thanright.
3.
Normal appearance of the right kidneywith interval resolution of right urothelial thicken-ing.?
MTI assigned codes 593.89 Other specifieddisorders of kidney and ureter and 591 Hy-dronephrosis.
Codes 593.70 Vesicoureteral refluxwith reflux nephropathy, unspecified or withoutreflux nephropathy and 753.3 Double kidney withdouble pelvis were assigned by the k-NN classifier.Pattern matching resulted in assignment of code591 with fairly low confidence.
No code was as-signed to this document by the SVM classifier.Despite failing to assign codes to these 29 records,the conservative approach (using threshold) re-sulted in better performance, achieving F-score0.85 compared to F-score 0.80 when all 1,634codes assigned by the base classifiers were used.5 ConclusionWe are left with two conclusions.
First, this re-search confirms that combining several comple-mentary methods for accomplishing tasks, rangingfrom ad hoc retrieval to categorization, producesresults that are better and more stable than the re-sults for the contributing methods.
Furthermore,we have shown that the basic methods employingdomain knowledge and advanced statistical algo-rithms are applicable to clinical text without sig-nificant modification.
Second, although there aresome limitations of the current Challenge test col-lection of clinical text, we appreciate the efforts ofthe Challenge organizers in the creation of a testcollection of clinical text.
This collection providesa unique opportunity to apply existing methods to anew and important domain.AcknowledgementsThis work was supported in part by the IntramuralResearch Program of the NIH, National Library ofMedicine and by appointments of Aur?lie N?v?oland Vivian Lee to the NLM Research ParticipationProgram sponsored by the National Library ofMedicine and administered by the Oak Ridge Insti-tute for Science and Education.The authors gratefully acknowledge the manyessential contributions to MTI, especially W. JohnWilbur for the PubMed Related Citations indexingmethod, and Natalie Xie for adapting TexTool (aninterface to Related Citations) for this paper.111ReferencesAronson AR, Demner-Fushman D, Humphrey SM, LinJ, Liu H, Ruch P, Ruiz ME, Smith LH, Tanabe LK,Wilbur WJ.
Fusion of knowledge-intensive and sta-tistical approaches for retrieving and annotating tex-tual genomics documents.
Proc TREC 2005, 36-45.Aronson AR, Mork JG, Gay CW, Humphrey SM andRogers WJ.
The NLM Indexing Initiative's MedicalText Indexer.
Medinfo.
2004: 268-72.Bodenreider O, Nelson SJ, Hole WT and Chang HF.Beyond synonymy: exploiting the UMLS semanticsin mapping vocabularies.
Proc AMIA Symp 1998:815-9.Chapman WW, Bridewell W, Hanbury P, Cooper GF,Buchanan B.
Evaluation of negation phrases in narra-tive clinical reports.
Proc AMIA Symp.
2001a:105-9.Chapman WW, Bridewell W, Hanbury P, Cooper GFand Buchanan BG.
A simple algorithm for identify-ing negated findings and diseases in discharge sum-maries.
J Biomed Inform.
2001b;34:301-10.Demner-Fushman D, Humphrey SM, Ide NC, Loane RF,Ruch P, Ruiz ME, Smith LH, Tanabe LK, Wilbur WJand Aronson AR.
Finding relevant passages in scien-tific articles: fusion of automatic approaches vs. aninteractive team effort.
Proc TREC 2006, 569-76.Fung KW and Bodenreider O. Utilizing the UMLS forsemantic mapping between terminologies.
AMIAAnnu Symp Proc 2005: 266-70.Gay CW, Kayaalp M and Aronson AR.
Semi-automaticindexing of full text biomedical articles.
AMIA AnnuSymp Proc.
2005:271-5.Goldin I and Chapman WW.
Learning to detect nega-tion with ?not?
in medical texts.
Proc Workshop onText Analysis and Search for Bioinformatics, ACMSIGIR, 2003.Hunter L and Cohen KB.
Biomedical language process-ing: what?s beyond PubMed?
Mol Cell.
2006 Mar3;21(5):589-94.Tanabe L and Wilbur WJ.
(2002) Tagging gene andprotein names in biomedical text.
Bioinformatics,Aug 2002; 18: 1124 ?32.Ting WK and Witten I.
1997.
Stacking bagged and dag-ged models.
367-375.
Proc.
of ICML'97.
MorganKaufmann, San Francisco, CA.AppendixA sample of the input to NegEx for dictionary generation:C0002390 pneumonitis, allergic interstitialC0002390 allergic interstitial pneumonitis, nosC0002390 extrinsic allergic bronchiolo alveolitisC0002390 extrinsic allergic bronchiolo alveolitis, nosC0002390 hypersensitivity pneumoniaC0002390 hypersensitivity pneumonia, nosC0002390 eaa  extrinsic allergic alveolitisC0002390 allergic extrinsic alveolitis nos (disorder)C0002390 extrinsic allergic alveolitis (disorder)C0002390 hypersensitivity pneumonitis nos (disorder)A sample of the dictionary generated by NegEx for later use in detecting negated expressions:C0002098 hypersensitivity granuloma (morphologic abnormalityC0151726 hypersensitivity injection siteC0020517 hypersensitivity nosC0429891 hypersensitivity observationsC0002390 hypersensitivity pneumoniaC0002390 hypersensitivity pneumonia, nosC0002390 hypersensitivity pneumonitidesC0005592 hypersensitivity pneumonitides, avianC0002390 hypersensitivity pneumonitisC0182792 hypersensitivity pneumonitis antibody determination re-agents112
