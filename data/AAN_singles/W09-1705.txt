Proceedings of the NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 36?44,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsGraph Connectivity Measures for Unsupervised Parameter Tuningof Graph-Based Sense Induction SystemsIoannis Korkontzelos, Ioannis Klapaftis and Suresh ManandharDepartment of Computer ScienceThe University of YorkHeslington, York, YO10 5NG, UK{johnkork, giannis, suresh}@cs.york.ac.ukAbstractWord Sense Induction (WSI) is the task ofidentifying the different senses (uses) of a tar-get word in a given text.
This paper focuseson the unsupervised estimation of the free pa-rameters of a graph-based WSI method, andexplores the use of eight Graph Connectiv-ity Measures (GCM) that assess the degree ofconnectivity in a graph.
Given a target wordand a set of parameters, GCM evaluate theconnectivity of the produced clusters, whichcorrespond to subgraphs of the initial (unclus-tered) graph.
Each parameter setting is as-signed a score according to one of the GCMand the highest scoring setting is then selected.Our evaluation on the nouns of SemEval-2007WSI task (SWSI) shows that: (1) all GCM es-timate a set of parameters which significantlyoutperform the worst performing parametersetting in both SWSI evaluation schemes, (2)all GCM estimate a set of parameters whichoutperform the Most Frequent Sense (MFS)baseline by a statistically significant amountin the supervised evaluation scheme, and (3)two of the measures estimate a set of parame-ters that performs closely to a set of parame-ters estimated in supervised manner.1 IntroductionUsing word senses instead of word forms is essentialin many applications such as information retrieval(IR) and machine translation (MT) (Pantel and Lin,2002).
Word senses are a prerequisite for word sensedisambiguation (WSD) algorithms.
However, theyare usually represented as a fixed-list of definitionsof a manually constructed lexical database.
Thefixed-list of senses paradigm has several disadvan-tages.
Firstly, lexical databases often contain generaldefinitions and miss many domain specific senses(Agirre et al, 2001).
Secondly, they suffer from thelack of explicit semantic and topical relations be-tween concepts (Agirre et al, 2001).
Thirdly, theyoften do not reflect the exact content of the contextin which the target word appears (Veronis, 2004).WSI aims to overcome these limitations of hand-constructed lexicons.Most WSI systems are based on the vector-spacemodel that represents each context of a target wordas a vector of features (e.g.
frequency of cooccur-ring words).
Vectors are clustered and the resultingclusters are taken to represent the induced senses.Recently, graph-based methods have been employedto WSI (Dorow and Widdows, 2003; Veronis, 2004;Agirre and Soroa, 2007b).Typically, graph-based approaches represent eachword co-occurring with the target word, within apre-specified window, as a vertex.
Two verticesare connected via an edge if they co-occur in oneor more contexts of the target word.
This co-occurrence graph is then clustered employing differ-ent graph clustering algorithms to induce the senses.Each cluster (induced sense) consists of words ex-pected to be topically related to the particular sense.As a result, graph-based approaches assume thateach context word is related to one and only onesense of the target one.Recently, Klapaftis and Manandhar (2008) arguedthat this assumption might not be always valid, sincea context word may be related to more than onesenses of the target one.
As a result, they pro-36posed the use of a graph-based model for WSI, inwhich each vertex of the graph corresponds to acollocation (word-pair) that co-occurs with the tar-get word, while edges are drawn based on the co-occurrence frequency of their associated colloca-tions.
Clustering of this collocational graph wouldproduce clusters, which consist of a set of collo-cations.
The intuition is that the produced clusterswill be less sense-conflating than those producedby other graph-based approaches, since collocationsprovide strong and consistent clues to the senses ofa target word (Yarowsky, 1995).The collocational graph-based approach as wellas the majority of state-of-the-art WSI systems es-timate their parameters either empirically or by em-ploying supervised techniques.
The SemEval-2007WSI task (SWSI) participating systems UOY andUBC-AS used labeled data for parameter estimation(Agirre and Soroa, 2007a), while the authors of I2R,UPV SI and UMND2 have empirically chosen val-ues for their parameters.
This issue imposes limitson the unsupervised nature of these algorithms, aswell as on their performance on different datasets.More specifically, when applying an unsupervisedWSI system on different datasets, one cannot be surethat the same set of parameters is appropriate for alldatasets (Karakos et al, 2007).
In most cases, a newparameter tuning might be necessary.
Unsupervisedestimation of free parameters may enhance the unsu-pervised nature of systems, making them applicableto any dataset, even if there are no tagged data avail-able.In this paper, we focus on estimating the freeparameters of the collocational graph-based WSImethod (Klapaftis and Manandhar, 2008) usingeight graph connectivity measures (GCM).
Given aparameter setting and the associated induced cluster-ing solution, each induced cluster corresponds to asubgraph of the original unclustered graph.
A graphconnectivity measure GCMi scores each cluster byevaluating the degree of connectivity of its corre-sponding subgraph.
Each clustering solution is thenassigned the average of the scores of its clusters.
Fi-nally, the highest scoring solution is selected.Our evaluation on the nouns of SWSI showsthat GCM improve the worst performing parame-ter setting by large margins in both SWSI evaluationschemes, although they are below the best perform-ing parameter setting.
Moreover, the evaluation ina WSD setting shows that all GCM estimate a setof parameters which are above the Most FrequentSense (MFS) baseline by a statistically significantamount.
Finally our results show that two of themeasures, i.e.
average degree and weighted averagedegree, estimate a set of parameters that performsclosely to a set of parameters estimated in a super-vised manner.
All of these findings, suggest thatGCM are able to identify useful differences regard-ing the quality of the induced clusters for differentparameter combinations, in effect being useful forunsupervised parameter estimation.2 Collocational graphs for WSILet bc, be the base corpus, which consists of para-graphs containing the target word tw.
The aim isto induce the senses of tw given bc as the only in-put.
Let rc be a large reference corpus.
In Klapaftisand Manandhar (2008) the British National Corpus1is used as a reference corpus.
The WSI algorithmconsists of the following stages.Corpus pre-processing The target of this stage isto filter the paragraphs of the base corpus, in order tokeep the words which are topically (and possibly se-mantically) related to the target one.
Initially, tw isremoved from bc and both bc and rc are PoS-tagged.In the next step, only nouns are kept in the para-graphs of bc, since they are characterised by higherdiscriminative ability than verbs, adverbs or adjec-tives which may appear in a variety of different con-texts.
At the end of this pre-processing step, eachparagraph of bc and rc is a list of lemmatized nouns(Klapaftis and Manandhar, 2008).In the next step, the paragraphs of bc are fil-tered by removing common nouns which are noisy;contextually not related to tw.
Given a contex-tual word cw that occurs in the paragraphs of bc, alog-likelihood ratio (G2) test is employed (Dunning,1993), which checks if the distribution of cw in bcis similar to the distribution of cw in rc; p(cw|bc) =p(cw|rc) (null hypothesis).
If this is true, G2 has asmall value.
If this value is less than a pre-specifiedthreshold (parameter p1) the noun is removed frombc.1The British National Corpus (BNC) (2001, version 2).
Dis-tributed by Oxford University Computing Services.37Target: cnn nbc Target: nbc newsnbc tv nbc tvcnn tv soap operacnn radio nbc shownews newscast news newscastradio television nbc newshourcnn headline cnn headlinenbc politics radio tvbreaking news breaking newsTable 1: Collocations connected to cnn nbc and nbc newsThis process identifies nouns that are more indica-tive in bc than in rc and vice versa.
However, in thissetting we are not interested in nouns which havea distinctive frequency in rc.
As a result, each cwwhich has a relative frequency in bc less than in rcis filtered out.
At the end of this stage, each para-graph of bc is a list of nouns which are assumed tobe contextually related to the target word tw.Creating the initial collocational graph The tar-get of this stage is to determine the related nouns,which will form the collocations, and the weight ofeach collocation.
Klapaftis and Manandhar (2008)consider collocations of size 2, i.e.
pairs of nouns.For each paragraph of bc of size n, collocationsare identified by generating all the possible (cn2)combinations.
The frequency of a collocation c isthe number of paragraphs in the whole SWSI corpus(27132 paragraphs), in which c occurs.Each collocation is assigned a weight, measuringthe relative frequency of two nouns co-occurring.Let freqij denote the number of paragraphs inwhich nouns i and j cooccur, and freqj denote thenumber of paragraphs, where noun j occurs.
Theconditional probability p(i|j) is defined in equation1, and p(j|i) is computed in a similar way.
Theweight of collocation cij is the average of these con-ditional probabilities wcij = p(i|j) + p(j|i).p(i|j) = freqijfreqj (1)Finally, Klapaftis and Manandhar (2008) only ex-tract collocations which have frequency (parame-ter p2) and weight (parameter p3) higher than pre-specified thresholds.
This filtering appears to com-pensate for inaccuracies in G2, as well as for low-frequency distant collocations that are ambiguous.Each weighted collocation is represented as a ver-tex.
Two vertices share an edge, if they co-occur inone or more paragraphs of bc.Populating and weighing the collocational graphThe constructed graph, G, is sparse, since the pre-vious stage attempted to identify rare events, i.e.co-occurring collocations.
To address this problem,Klapaftis and Manandhar (2008) apply a smooth-ing technique, similar to the one in Cimiano etal.
(2005), extending the principle that a word ischaracterised by the company it keeps (Firth, 1957)to collocations.
The target is to discover new edgesbetween vertices and to assign weights to all edges.Each vertex i (collocation ci) is associated toa vector V Ci containing its neighbouring vertices(collocations).
Table 1 shows an example of twovertices, cnn nbc and nbc news, which are discon-nected in G of the target word network.
The examplewas taken from Klapaftis and Manandhar (2008).In the next step, the similarity between all vertexvectors V Ci and V Cj is calculated using the Jaccardcoefficient, i.e.
JC(V Ci, V Cj) = |V Ci?V Cj ||V Ci?V Cj | .
Twocollocations ci and cj are mutually similar if ci is themost similar collocation to cj and vice versa.Given that collocations ci and cj are mutuallysimilar, an occurrence of a collocation ck with oneof ci, cj is also counted as an occurrence with theother collocation.
For example in Table 1, if cnn nbcand nbc news are mutually similar, then the zero-frequency event between nbc news and cnn tv isset equal to the joint frequency between cnn nbcand cnn tv.
Marginal frequencies of collocationsare updated and the overall result is consequently asmoothing of relative frequencies.The weight applied to each edge connecting ver-tices i and j (collocations ci and cj ) is the maximumof their conditional probabilities: p(i|j) = freqijfreqj ,where freqi is the number of paragraphs collocationci occurs.
p(j|i) is defined similarly.Inducing senses and tagging In this final stage,the collocational graph is clustered to produced thesenses (clusters) of the target word.
The clusteringmethod employed is Chinese Whispers (CW) (Bie-mann, 2006).
CW is linear to the number of graphedges, while it offers the advantage that it does notrequire any input parameters, producing the clustersof a graph automatically.38Figure 1: An example undirected weighted graph.Initially, CW assigns all vertices to differentclasses.
Each vertex i is processed for a number ofiterations and inherits the strongest class in its lo-cal neighbourhood (LN) in an update step.
LN isdefined as the set of vertices which share an edgewith i.
In each iteration for vertex i: each class, cl,receives a score equal to the sum of the weights ofedges (i, j), where j has been assigned to class cl.The maximum score determines the strongest class.In case of multiple strongest classes, one is chosenrandomly.
Classes are updated immediately, mean-ing that a vertex can inherit from its LN classes thatwere introduced in the same iteration.Once CW has produced the clusters of a targetword, each of the instances of tw is tagged withone of the induced clusters.
This process is simi-lar to Word Sense Disambiguation (WSD) with thedifference that the sense repository has been auto-matically produced.
Particularly, given an instanceof tw in paragraph pi: each induced cluster cl is as-signed a score equal to the number of its collocations(i.e.
pairs of words) occurring in pi.
We observe thatthe tagging method exploits the one sense per collo-cation property (Yarowsky, 1995), which means thatWSD based on collocations is probably finer thanWSD based on simple words, since ambiguity is re-duced (Klapaftis and Manandhar, 2008).3 Unsupervised parameter tuningIn this section we investigate unsupervised ways toaddress the issue of choosing parameter values.
Tothis end, we employ a variety of GCM, which mea-sure the relative importance of each vertex and as-sess the overall connectivity of the correspondinggraph.
These measures are average degree, clustercoefficient, graph entropy and edge density (Navigliand Lapata, 2007; Zesch and Gurevych, 2007).GCM quantify the degree of connectivity of theproduced clusters (subgraphs), which represent thesenses (uses) of the target word for a given cluster-ing solution (parameter setting).
Higher values ofGCM indicate subgraphs (clusters) of higher con-nectivity.
Given a parameter setting, the inducedclustering solution and a graph connectivity measureGCMi, each induced cluster is assigned the result-ing score of applying GCMi on the correspondingsubgraph of the initial unclustered graph.
Each clus-tering solution is assigned the average of the scoresof its clusters (table 6), and the highest scoring oneis selected.For each measure, we have developed two ver-sions, i.e.
one which considers the edge weights inthe subgraph, and a second which does not.
In thefollowing description the terms graph and subgraphare interchangeable.Let G = (V,E) be an undirected graph (in-duced sense), where V is a set of vertices and E ={(u, v) : u, v ?
V } a set of edges connecting vertexpairs.
Each edge is weighted by a positive weight,W : wuv ?
[0,?).
Figure 1 shows a small exampleto explain the computation of GCM.
The graph con-sists of 8 vertices, |V | = 8, and 10 edges, |E| = 10.Edge weights appear on edges, e.g.
wab = 14 .Average Degree The degree (deg) of a vertex u isthe number of edges connected to u:deg(u) = |{(u, v) ?
E : v ?
V }| (2)The average degree (AvgDeg) of a graph can becomputed as:AvgDeg(G(V,E)) = 1|V |?u?Vdeg(u) (3)The first row of table 2 shows the vertex degreesof the example graph (figure 1) and AvgDeg(G) =208 = 2.5.Edge weights can be integrated into the degreecomputation.
Let mew be the maximum edgeweight in the graph:mew = max(u,v)?Ewuv (4)Average Weighted Degree The weighted de-gree(w deg) of a vertex is defined as:w deg(u) = 1|V |?
(u,v)?Ewuvmew (5)39a b c d e f g hdeg(u) 2 2 3 4 3 3 2 1wdeg(u) 54 1 52 94 74 32 32 14Tu 1 1 1 1 1 2 1 0cc(u) 1 1 13 16 13 23 1 0WTu 34 1 14 14 12 32 14 0wcc(u) 34 1 112 124 16 12 14 0p(u) 110 110 320 15 320 320 110 120en(u) ?
100 33 33 41 46 41 41 33 22wp(u) 116 120 18 980 780 340 340 180we(u) ?
100 25 22 38 35 31 28 28 8Table 2: Computations of graph connectivity measuresand relevant quantities on the example graph (figure 1).Average weighted degree (AvgWDeg), similarly toAvgDeg, is averaged over all vertices of the graph.In the graph of figure 1, mew = 1.
The second rowof table 2 shows the weighted degrees of all vertices.AvgWDeg(G) = 4836 ' 1.33.Average Cluster Coefficient The cluster coeffi-cient (cc) of a vertex, u, is defined as:cc(u) = Tu2?1ku(ku ?
1) (6)Tu =?(u,v)?E?
(v,x)?Ex 6=u1 (7)Tu is the number of edges between the ku neigh-bours of u.
Obviously ku = deg(u).
2?1ku(ku?
1)would be the number of edges between the neigh-bours of u if the graph they define was fully con-nected.
Average cluster coefficient (AvgCC) is aver-aged over all vertices of the graph.The computations of Tu and cc(u) on the examplegraph are shown in the third and fourth rows of table2.
Consequently, AvgCC(G) = 916 = 0.5625.Average Weighted Cluster Coefficient Let WTube the sum of edge weights between the neighboursof u over mew.
Weighted cluster coefficient (wcc)can be computed as:wcc(u) = WTu2?1ku(ku ?
1) (8)WTu = 1mew?(u,v)?E?
(v,x)?Ex 6=uwvx (9)Average weighted cluster coefficient (AvgWCC) isaveraged over all vertices of the graph.
The com-putations of WTu and wcc(u) on the example graph(figure 1) are shown in the fifth and sixth rows oftable 2 and AvgWCC(G) = 678?24 ' 0.349.Graph Entropy Entropy measures the amount ofinformation (alternatively the uncertainty) in a ran-dom variable.
For a graph, high entropy indicatesthat many vertices are equally important and low en-tropy that only few vertices are relevant (Navigli andLapata, 2007).
The entropy (en) of a vertex u can bedefined as:en(u) = ?p(u) log2 p(u) (10)The probability of a vertex, p(u), is determined bythe degree distribution:p(u) ={deg(u)2|E|}u?V(11)Graph entropy (GE) is computed by summing allvertex entropies and normalising by log2 |V |.
Theseventh and eighth row of table 2 show the compu-tations of p(u) and en(u) on the example graph, re-spectively.
Thus, GE ' 0.97.Weighted Graph Entropy Similarly to previousgraph connectivity measures, the weighted entropy(wen) of a vertex u is defined as:we(u) = ?wp(u) log2 wp(u) (12)where: wp(u) ={ w deg(u)2 ?mew ?
|E|}u?VWeighted graph entropy (GE) is computed by sum-ming all vertex weighted entropies and normalisingby log2 |V |.
The last two rows of table 2 show thecomputations of wp(u) and we(u) on the examplegraph.
Consequently, WGE ' 0.73.Edge Density and Weighted Edge Density Edgedensity (ed) quantifies how many edges the graphhas, as a ratio over the number of edges of a fullyconnected graph of the same size:A(V ) = 2(|V |2)(13)40Edge density (ed) is a global graph connectivitymeasure; it refers to the whole graph and not a spe-cific vertex.
Edge density (ed) and weighted edgedensity (wed) can be defined as follows:ed(G(V,E)) = |E|A(V ) (14)wed(G(V,E)) = 1A(V )?
(u,v)?Ewu,vmew (15)In the graph of figure 1: A(V ) = 2(82) = 28,ed(G) = 1028 ' 0.357,?
wu,vmew = 6 and wed(G) =628 ' 0.214.The use of the aforementioned GCM allows theestimation of a different parameter setting for eachtarget word.
Table 3 shows the parameters of the col-locational graph-based WSI system (Klapaftis andManandhar, 2008).
These parameters affect how thecollocational graph is constructed, and in effect thequality of the induced clusters.4 Evaluation4.1 Experimental settingThe collocational WSI approach was evaluated un-der the framework and corpus of SemEval-2007WSI task (Agirre and Soroa, 2007a).
The corpusconsists of text of the Wall Street Journal corpus,and is hand-tagged with OntoNotes senses (Hovy etal., 2006).
The evaluation focuses on all 35 nouns ofSWSI.
SWSI task employs two evaluation schemes.In unsupervised evaluation, the results are treated asclusters of contexts and gold standard (GS) sensesas classes.
In a perfect clustering solution, each in-duced cluster contains the same contexts as one ofthe classes (Homogeneity), and each class containsthe same contexts as one of the clusters (Complete-ness).
F-Score is used to assess the overall quality ofclustering.
Entropy and purity are also used, com-plementarily.
F-Score is a better measure than en-tropy or purity, since F-Score measures both homo-geneity and completeness, while entropy and puritymeasure only the former.
In the second scheme, su-pervised evaluation, the training corpus is used tomap the induced clusters to GS senses.
The testingcorpus is then used to measure WSD performance(Table 4, Sup.
Recall).The graph-based collocational WSI method is re-ferred as Col-Sm (where ?Col?
stands for the ?col-Parameter Range ValueG2 threshold 5, 10, 15 p1 = 5Collocation frequency 4, 6, 8, 10 p2 = 8Collocation weight 0.2, 0.3, 0.4 p3 = 0.2Table 3: Parameters ranges and values in Klapaftis andManandhar (2008)locational WSI?
approach and ?Sm?
for its ver-sion using ?smoothing?).
Col-Bl (where ?Bl?
standsfor ?baseline?)
refers to the same system withoutsmoothing.
The parameters of Col-Sm were origi-nally estimated by cross-validation on the trainingset of SWSI.
Out of 72 parameter combinations, thesetting with the highest F-Score was chosen and ap-plied to all 35 nouns of the test set.
This is referredas Col-Sm-org (where ?org?
stands for ?original?)
inTable 4.
Table 3 shows all values for each parameter,and the chosen values, under supervised parameterestimation2.
Col-Bl-org (Table 4) induces senses asCol-Sm-org does, but without smoothing.In table 4, Col-Sm-w (respectively Col-Bl-w)refers to the evaluation of Col-Sm (Col-Bl), follow-ing the same technique for parameter estimation asin Klapaftis and Manandhar (2008) for each targetword separately (?w?
stands for ?word?).
Given thatGCM are applied for each target word separately,these baselines will allow to see the performance ofGCM compared to a supervised setting.The 1c1inst baseline assigns each instance to adistinct cluster, while the 1c1w baseline groups allinstances of a target word into a single cluster.
1c1wis equivalent to MFS in this setting.
The fifth columnof table 4 shows the average number of clusters.The SWSI participant systems UOY and UBC-ASused labeled data for parameter estimation.
The au-thors of I2R, UPV SI and UMND2 have empiricallychosen values for their parameters.The next subsection presents the evaluation ofGCM as well as the results of SWSI systems.
Ini-tially, we provide a brief discussion on the differ-ences between the two evaluation schemes of SWSIthat will allow for a better understanding of GCMperformance.4.2 Analysis of results and discussionEvaluation of WSI methods is a difficult task.
Forinstance, 1c1inst (Table 4) achieves perfect purity2CW performed 200 iterations for all experiments, becauseit is not guaranteed to converge.41System Unsupervised Evaluation Sup.FSc.
Pur.
Ent.
# Cl.
RecallCol-Sm-org 78.0 88.6 31.0 5.9 86.4Col-Bl-org 73.1 89.6 29.0 8.0 85.6Col-Sm-w 80.9 88.0 32.5 4.3 85.5Col-Bl-w 78.1 88.3 31.7 5.4 84.3UBC-AS 80.8 83.6 43.5 1.6 80.7UPV SI 69.9 87.4 30.9 7.2 82.5I2R 68.0 88.4 29.7 3.1 86.8UMND2 67.1 85.8 37.6 1.7 84.5UOY 65.8 89.8 25.5 11.3 81.61c1w-MFS 80.7 82.4 46.3 1 80.91c1inst 6.6 100 0 73.1 N/ATable 4: Evaluation of WSI systems and baselines.and entropy.
However, F-Score of 1c1inst is low,because the GS senses are spread among clusters,decreasing unsupervised recall.
Supervised recall of1c1inst is undefined, because each cluster tags onlyone instance.
Hence, clusters tagging instances inthe test corpus do not tag any instances in the traincorpus and the mapping cannot be performed.
1c1wachieves high F-Score due to the dominance of MFSin the testing corpus.
However, its purity, entropyand supervised recall are much lower than other sys-tems, because it only induces the dominant sense.Clustering solutions that achieve high supervisedrecall do not necessarily achieve high F-Score,mainly because F-Score penalises systems for in-ducing more clusters than the corresponding GSclasses, as 1cl1inst does.
Supervised evaluationseems to be more neutral regarding the number ofclusters, since clusters are mapped into a weightedvector of senses.
Thus, inducing a number of clus-ters similar to the number of senses is not a require-ment for good results (Agirre and Soroa, 2007a).High supervised recall means high purity and en-tropy, as in I2R, but not vice versa, as in UOY.
UOYproduces many clean clusters, however these are un-reliably mapped to senses due to insufficient train-ing data.
On the contrary, I2R produces a few cleanclusters, which are mapped more reliably.Comparing the performance of SWSI systemsshows that none performs well in both evaluationsettings, in effect being biased against one of theschemes.
However, this is not the case for the collo-cational WSI method, which achieves a high perfor-mance in both evaluation settings.Table 6 presents the results of applying the graphSystem Bound Unsupervised Evaluation Sup.type FSc.
Pur.
Ent.
# Cl.
RecallCol-Sm MaxR 79.3 90.5 26.6 7.0 88.6Col-Sm MinR 62.9 89.0 26.7 12.7 78.8Col-Bl MaxR 72.9 91.8 23.2 9.6 88.7Col-Bl MinR 57.5 89.0 26.4 14.4 76.2Col-Sm MaxF 83.2 90.0 28.7 4.9 86.6Col-Sm MinF 43.6 90.2 22.1 17.6 83.7Col-Bl MaxF 81.1 90.0 28.7 5.3 81.8Col-Bl MinF 34.1 90.5 20.5 20.4 81.5Table 5: Upper and lower performance bounds for sys-tems Col-Sm and Col-Bl.connectivity measures of section 3 in order to choosethe parameter values for the collocational WSI sys-tem, for each word separately.
The evaluation isdone both for Col-Sm and Col-Bl that use and ignoresmoothing, respectively.To evaluate the supervised recall performanceusing the graph connectivity measures, we com-puted both the upper and lower bounds of Col-Sm,i.e.
the best and worst supervised recall, respectively(MaxR and MinR in table 5).
In the former case,we selected the parameter combination per targetword that performs best (Col-Sm, MaxR in table 5),which resulted in 88.6% supervised recall (F-Score:79.3%), while in the latter we selected the worst per-forming one, which resulted in 78.8% supervised re-call (F-Score: 62.9%).
In table 6 we observe thatthe supervised recall of all measures is significantlylower than the upper bound.
However, all measuresperform significantly better than the lower bound(McNemar?s test, confidence level: 95%); the small-est difference is 4.9%, in the case of weighted edgedensity.
The picture is the same for Col-Bl.In the same vein, we computed both the upper andlower bounds of Col-Sm in terms of F-Score, 83.2%and 43.6%, respectively (Col-Sm, MinF and MaxFin table 5).
The performance of the system is lowerthan the upper bound, for all GCM.
Despite that, weobserve that all measures except edge density andweighted edge density outperform the lower boundby large margins.The comparison of GCM performance againstthe lower and upper bounds of Col-Sm and Col-Blshows that GCM are able to identify useful differ-ences regarding the degree of connectivity of in-duced clusters, and in effect suggest parameter val-ues that perform significantly better than the worst42Col-Sm Col-BlUnsupervised Evaluation Sup.
Unsupervised Evaluation Sup.Graph Connectivity Measure FSc Pur.
Ent.
# Cl.
Recall FSc Pur.
Ent.
# Cl.
RecallAverage Degree 79.2 87.2 34.2 3.9 84.8 77.5 31.3 88.4 5.7 83.8Average Weighted Degree 77.1 87.8 32.0 5.5 84.2 75.1 28.3 89.6 8.5 83.3Average Cluster Coefficient 72.5 88.8 28.5 9.1 83.9 68.7 24.0 90.9 12.9 83.9Average Weighted Cluster Coefficient 65.8 88.4 28.0 9.6 84.1 68.9 22.4 91.3 13.9 83.7Graph Entropy 67.0 89.6 25.9 12.3 83.8 68.5 22.1 91.8 14.4 84.4Weighted Graph Entropy 72.7 89.4 28.1 9.6 84.1 72.2 23.5 91.2 12.5 84.0Edge Density 47.8 91.8 19.4 18.4 84.8 42.0 16.9 92.8 21.9 84.1Weighted Edge Density 53.4 90.2 23.1 15.5 83.7 42.2 17.1 92.7 21.9 83.9Table 6: Unsupervised & supervised evaluation of the collocational WSI approach using graph connectivity measures.case.
However, they are all unable to approximatethe upper bound for both evaluation schemes, whichis also the case for the supervised estimation of pa-rameters per target word (Col-Sm-w and Col-Bl-w).In Table 6, we also observe that all measuresachieve higher supervised recall scores than theMFS baseline.
The increase is statistically signif-icant (McNemar?s test, confidence level: 95%) inall cases.
This result shows that irrespective of thenumber of clusters produced (low F-Score), GCMare able to estimate a set of parameters that providesclean clusters (low entropy), which when mapped toGS senses improve upon the most frequent heuristic,unlike the majority of unsupervised WSD systems.Regarding the comparison between differentGCM, we observe that average degree and weightedaverage degree for Col-Sm (Col-Bl) performclosely to Col-Sm-w (Col-Bl-w) for both evaluationschemes.
This is due to the fact that they produce anumber of clusters similar to Col-Sm-w (Col-Bl-w),while at the same time their distributions of clustersover the target words?
instances are also similar.On the contrary, the remaining GCM tend to pro-duce larger numbers of clusters compared to bothCol-Sm-w (Col-Bl-w) and the GS, in effect beingpenalised by F-Score.
As it has already been men-tioned, supervised recall is less affected by a largenumber of clusters, which causes small differencesamong GCM.Determining whether the weighted or unweightedversion of GCM performs better depends on theGCM itself.
Weighted graph entropy performs in allcases better than the unweighted version.
For aver-age cluster coefficient and edge density, we cannotextract a safe conclusion.
Unweighted average de-gree performs better than the weighted version.5 Conclusion and future workIn this paper, we explored the use of eight graph con-nectivity measures for unsupervised estimation offree parameters of a collocational graph-based WSIsystem.
Given a parameter setting and the associ-ated induced clustering solution, each cluster wasscored according to the connectivity degree of itscorresponding subgraph, as assessed by a particulargraph connectivity measure.
Each clustering solu-tion was then assigned the average of its clusters?scores, and the highest scoring one was selected.Evaluation on the nouns of SemEval-2007 WSItask (SWSI) showed that all eight graph connectiv-ity measures choose parameters for which the corre-sponding performance of the system is significantlyhigher than the lower performance bound, for boththe supervised and unsupervised evaluation scheme.Moreover, the selected parameters produce resultswhich outperform the MFS baseline by a statisti-cally significant amount in the supervised evalua-tion scheme.
The best performing measures, averagedegree and weighted average degree, perform com-parably well to the set of parameters chosen by asupervised parameter estimation.
In general, graphconnectivity measures can quantify significant dif-ferences regarding the degree of connectivity of in-duced clusters.Future work focuses on further exploiting graphconnectivity measures.
Graph theoretic literatureproposes a variety of measures capturing graphproperties.
Some of these measures might help inimproving WSI performance, while at the same timekeeping graph-based WSI systems totally unsuper-vised.43ReferencesEneko Agirre and Aitor Soroa.
2007a.
Semeval-2007task 02: Evaluating word sense induction and discrim-ination systems.
In Proceedings of the Fourth Interna-tional Workshop on Semantic Evaluations (SemEval-2007), pages 7?12, Prague, Czech Republic.
Associa-tion for Computational Linguistics.Eneko Agirre and Aitor Soroa.
2007b.
Ubc-as: A graphbased unsupervised system for induction and classi-fication.
In Proceedings of the Fourth InternationalWorkshop on Semantic Evaluations (SemEval-2007),pages 346?349, Prague, Czech Republic.
Associationfor Computational Linguistics.Eneko Agirre, Olatz Ansa, Eduard Hovy, and David Mar-tinez.
2001.
Enriching wordnet concepts with topicsignatures, Sep.Chris Biemann.
2006.
Chinese whispers - an efficientgraph clustering algorithm and its application to nat-ural language processing problems.
In Proceedingsof TextGraphs: the Second Workshop on Graph BasedMethods for Natural Language Processing, pages 73?80, New York City, June.
Association for Computa-tional Linguistics.Philipp Cimiano, Andreas Hotho, and Steffen Staab.2005.
Learning concept hierarchies from text corporausing formal concept analysis.
Journal of Artificial In-telligence research, 24:305?339.Beate Dorow and Dominic Widdows.
2003.
Discover-ing corpusspecific word senses.
In Proceedings 10thconference of the European chapter of the ACL, pages79?82, Budapest, Hungary.Ted E. Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
Computational Lin-guistics, 19(1):61?74.John R. Firth.
1957.
A synopsis of linguistic theory,1930-1955.
Studies in Linguistic Analysis, pages 1?32.Eduard Hovy, Mitchell Marcus, Martha Palmer, LanceRamshaw, and Ralph Weischedel.
2006.
Ontonotes:The 90% solution.
In Proceedings of the Human Lan-guage Technology Conference of the NAACL, Com-panion Volume: Short Papers, pages 57?60, New YorkCity, USA.
Association for Computational Linguistics.Damianos Karakos, Jason Eisner, Sanjeev Khudanpur,and Carey Priebe.
2007.
Cross-instance tuning of un-supervised document clustering algorithms.
In HumanLanguage Technologies 2007: The Conference of theNorth American Chapter of the Association for Com-putational Linguistics; Proceedings of the Main Con-ference, pages 252?259, Rochester, New York, April.Association for Computational Linguistics.Ioannis P. Klapaftis and Suresh Manandhar.
2008.
Wordsense induction using graphs of collocations.
In InProceedings of the 18th European Conference on Ar-tificial Intelligence, (ECAI-2008), Patras, Greece.R.
Navigli and M. Lapata.
2007.
Graph connectiv-ity measures for unsupervised word sense disambigua-tion.
In 20th International Joint Conference on Artifi-cial Intelligence (IJCAI 2007), pages 1683?1688, Hy-derabad, India, January.Patrick Pantel and Dekang Lin.
2002.
Discoveringword senses from text.
In KDD ?02: Proceedingsof the eighth ACM SIGKDD international conferenceon Knowledge discovery and data mining, pages 613?619, New York, NY, USA.
ACM Press.Jean Veronis.
2004.
Hyperlex: lexical cartography forinformation retrieval.
Computer Speech & Language,18(3):223?252, July.David Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In Meeting ofthe Association for Computational Linguistics, pages189?196.Torsten Zesch and Iryna Gurevych.
2007.
Analysis ofthe wikipedia category graph for NLP applications.
InProceedings of the Second Workshop on TextGraphs:Graph-Based Algorithms for Natural Language Pro-cessing, pages 1?8, Rochester, NY, USA.
Associationfor Computational Linguistics.44
