A Semant ic -Head-Dr iven  Generat ion A lgor i thmfor Un i f icat ion-Based Formal ismsStuart  M. Shieber," Ger t jan  van Noord, t Robert  C. Moore,"and Fernando C. N.
Pereira.
*"Artif icial  Intel l igence CenterSRI  In ternat iona lMenlo Park,  CA 94025, USAtDepar tment  of LinguisticsRi jksunivers i te i t  UtrechtUtrecht,  Nether landsAbstractWe present an algorithm for generating stringsfrom logical form encodings that improves uponprevious algorithms in that it places fewer restric-tions on the class of grammars to which it is ap-plicable.
In particular, unlike an Earley deductiongenerator (Shieber, 1988), it allows use of seman-tically nonmonotonic grammars, yet unlike top-down methods, it also permits left-recursion.
Theenabling design feature of the algorithm is its im-plicit traversal of the analysis tree for the stringbeing generated in a semantic-head-driven fashion.1 IntroductionThe problem of generating a well-formed natural-language xpression from an encoding of its mean-ing possesses certain properties which distinguishit from the converse problem of recovering a mean-ing encoding from a given natural-language ex-pression.
In previous work (Shieber, 1988), how-ever, one of us attempted to characterize thesediffering properties in such a way that a sin-gle uniform architecture, appropriately parame-terized, might be used for both natural-languageprocesses.
In particular, we developed an archi-tecture inspired by the Earley deduction work ofPereira and Warren (1983) but which generalizedthat work allowing for its use in both a parsingand generation mode merely by setting the valuesof a small number of parameters.As a method for generating natural-languageexpressions, the Earley deduction method is rea-sonably successful along certain dimensions.
Itis quite simple, general in its applicability to arange of unification-based and logic grammar for-malisms, and uniform, in that it places only onerestriction (discussed below) on the form of the lin-guistic analyses allowed by the grammars used ingeneration.
In particular, generation from gram-mars with recursions whose welbfoundedness relieson lexical information will terminate; top-downgeneration regimes such as those of Wedekind(1988) or Dymetman and Isabelle (1988) lack thisproperty, discussed further in Section 3.1.Unfortunately, the bottom-up, left-to-right pro-cessing regime of Earley generation--as it mightbe called--has its own inherent frailties.
Efficiencyconsiderations require that only grammars pos-sessing a property of semantic monotonicity canbe effectively used, and even for those grammars,processing can become overly nondeterministic.The algorithm described in this paper is an at-tempt to resolve these problems in a satisfactorymanner.
Although we believe that this algorithmcould be seen as an instance of a uniform archi-tecture for parsing and generation--just as theextended Earley parser (Shieber, 1985b) and thebottom-up generator were instances of the general-ized Earley deduction architecture= our efforts todate have been aimed foremost oward the devel-opment of the algorithm for generation alone.
Wewill have little to say about its relation to parsing,leaving such questions for later research.12 Applicability of the Algo-rithmAs does the Earley-based generator, the new algo-rithm assumes that the grammar is a unification-based or logic grammar with a phrase-structurebackbone and complex nonterminMs.
Further-more, and again consistent with previous work,we assume that the nonterminals associate to thephrases they describe logical expressions encodingtheir possible meanings.
We will describe the al-gorithm in terms of an implementation f it fordefinite-clause grammars (DCG), although we be-I Martin Kay (personal communication) has developeda parsing algorithm that seems to be the parsing correlateto the generation algorithm presented here.
Its existencemight point the way towards a uniform architecture.lieve the underlying method to be more broadlyapplicable.A variant of our method is used in Van No-ord's BUG (Bottom-Up Generator) system, partof MiMo2, an experimental machine translationsystem for translating international news items ofTeletext, which uses a Prolog version of PATI~-IIsimilar to that of Hirsh (1987).
According to Mar-tin Kay (personal communication), the STREPmachine translation project at the Center for theStudy of Language and Information uses a ver-sion of our algorithm to generate with respect ogrammars based on head-driven phrase-structuregrammar (HPSG).
Finally, Calder et al (1989)report on a generation algorithm for unificationcategorial grammar that appears to be a specialcase of ours.3 Problems with ExistingGeneratorsExisting generation algorithms have efficiency ortermination problems with respect to certainclasses of grammars.
We review the problems ofboth top-down and bottom-up regimes in this sec-tion.3.1 P rob lems w i th  Top-Down Gen-e ra torsConsider a naive top-down generation mechanismthat takes as input the semantics to generate fromand a corresponding syntactic ategory and buildsa complete tree, top-down, left-to-right by apply-ing rules of the grammar nondeterministically tothe fringe of the expanding tree.
This controlregime is realized, for instance, when running aDCG "backwards" as a generator.Clearly, such a generator may not terminate.For example, consider a grammar that includesthe rulesiS --> np/NP, vp(gP)/S.
(The intention is that verb phrases like, say,"loves Mary" be associated with a nonterminalvp(X)/love(X, mary).)
Once this rule is ap-plied to the goal s / love( john ,  mary), the sub-goal np/NP will be considered.
But the generationsearch space for that goal is infinite and so hasinfinite branches, because all noun phrases, andthus arbitrarily large ones, match the goal.
Thisis an instance of the general problem known fromlogic programming that a logic program may notterminate when called with a goal less instanti-ated than what was intended by the program'sdesigner.
Dymetman and Isabelle (1988), not-ing this problem, propose allowing the grammar-writer to specify a separate goal ordering for pars-ing and for generation.
For the case at hand,the solution is to generate the VP first--from thegoal vp(NP)/loves(john, mary)--in the courseof which the variable NP will become bound sothat the generation from np/NP will terminate.Wedekind (1988) achieves this goal by expandingfirst nodes that are connected, that is, whose se-mantics is instantiated.
Since the NP  is not con-nected in this sense, but the VP  is, the latter willbe expanded first.
In essence, the technique is akind of goal freezing (Colmerauer, 1982) or im-plicit wail declaration (Naish, 1986).
For cases inwhich the a priori ordering of goals is insufficient,Dymetman and Isabelle also introduce goal freez-ing to control expansion.Although vastly superior to the naive top-downalgorithm, even this sort of amended top-down ap-proach to generation based on goal freezing underone guise or another fails to terminate with cer-tain linguistically plausible analyses.
For example,the "complements" rule given by Shieber (1985a,pages 77-78) in the PATR-II formalismVP1 ~ VP2 X(VPI head) = (VP2 head)(VP2 syncat first) = (X)(VP2 syncat rest) - (VP1 syncat)can be encoded as the DCG-style rule:vp(Head, Synca~) -->vp(Head, \[CompllSyncat\]), Compl.Top-down generation using this rule will be forcedto expand the lower VP before its complement,since Comp1 is uninstantiated initially.
But appli-cation of the rule can recur indefinitely, leading tonontermination.The problem arises because there is no limit tothe size of the subcategorization list.
Althoughone might propose an ad hoc upper bound for lexi-ca/entries, even this expedient may be insufficient.In analyses of Dutch cross-serial verb construc-tions (Evers, 1975; Huybrechts, 1984), subcate-gorization lists such as these may be appended bysyntactic rules (Moortgat, 1984; Steedman, 1985;Pollard, 1988), resulting in indefinitely long lists.Consider the Dutch sentencedat \[Jan \[Marie \[de oppasser \[de olifantenthat John Mary the keeper the elephants\[zag helpen voeren\]\]\]\]saw help feedthat John saw Mary help the keeper feed theelephantsThe string of verbs is analysed by appending theirsubcategorization lists as follows:V \[e,k,md\]v \[mj\] V \[e,k,m\]zagsatov \[k,m\] V \[e,k\]I Ihelpen voerenhelp feedSubcategorization lists under this analysis canhave any length, and it is impossible to predictfrom a semantic structure the size of its corre-sponding subcategorization list mereiy by exam-ining the lexicon.In summary, top-down generation algorithms,even if controlled by the instantiation status ofgoals, can fail to terminate on certain grammars.In the case given above the well-foundedness of thegeneration process resides in lexical informationunavailable to top-down regimes.3.2 Problems with Bottom-UpGeneratorsThe bottom-up Earley-deduction generator doesnot fall prey to these problems of nonterminationin the face of recursion, because lexical informa-tion is available immediately.
However, several im-portant frailties of the Earley generation methodwere noted, even in the earlier work.For efficiency, generation using this Earley de-duction method requires an incomplete searchstrategy, filtering the search space using seman-tic information.
The semantic filter makes gen-eration from a logical form computationally feasi-ble, but preserves completeness of the generationprocess only in the case of semantically monotonicgrammars - -  those grammars in which the seman-tic component of each right-hand-side nonterminalsubsumes some portion of the semantic omponentof the left-hand-side.
The semantic monotonicityconstraint itself is quite restrictive.
Although it isintuitively plausible that the semantic ontent ofsubconstituents ought to play a role in the seman-tics of their combination--this  just a kind ofcompositionality claim--there are certain cases inwhich reasonable linguistic analyses might violatethis intuition.
In general, these cases arise when aparticular lexical item is stipulated to occur, thestipulation being either lexical (as in the case ofparticles or idioms) or grammatical (as in the caseof expletive xpressions).Second, the left-to-right scheduling of Earleyparsing, geared as it is toward the structureof the string rather than that of its meaning,is inherently more appropriate for parsing thangeneration.
~ This manifests itself in an overly highdegree of nondeterminism in the generation pro-tess.
For instance, various nondeterministic pos-sibilities for generating a noun phrase (using dif-ferent cases, say) might be entertained merely be-cause the NP occurs before the verb which wouldmore fully specify, and therefore limit, the options.This nondeterminism has been observed in prac-tice.3.3 Source of the ProblemsWe can think of a parsing or generation processas discovering an analysis tree, 3 one admitted bythe grammar and satisfying certain syntactic or se-mantic conditions, by traversing a virtual tree andconstructing the actual tree during the traversal.The conditions to be satisfied--possessing a ivenyield in the parsing case, or having a root node la-beled with given semantic information in the caseof generation--reflect the different premises of thetwo types of problem.From this point of view, a naive top-down parseror generator performs a depth-first, left-to-righttraversal of the tree.
Completion steps in Earley'salgorithm, whether used for parsing or generation,correspond to a post-order traversal (with predic-tion acting as a pre-order filter).
The left-to-righttraversal order of both of these methods is gearedtowards the given information in a parsing prob-lem, the string, rather than that of a generationproblem, the goal logical form.
It is exactly thismismatch between structure of the traversal and2Pereira and Warren (1983) point out that  Earley de-duct ion  is not  restr icted to a left-to-right expansion ofgoals, but  this suggestion was not fol lowed up with a spe-cific a lgor i thm addressing the problems discussed here.3We use the term "analysis tree" rather than  the morefamiliar "parse tree" to make clear that  the source of thetree is not  necessarily a parsing process; rather  the treeserves on ly  to codify a part icular analysis of the structureof the str ing.9structure of the problem premise that accounts forthe profligacy of these approaches when used forgeneration.Thus for generation, we want a traversal ordergeared to the premise of the generation problem,that is, to the semantic structure of the sentence.The new algorithm is designed to reflect such atraversal strategy respecting the semantic struc-ture of the string being generated, rather than thestring itself.4 The New Algor i thmGiven an analysis tree for a sentence, we definethe pivot node as the lowest node in the tree suchthat it and all higher no.des up to the root have thesame semantics.
Intuitively speaking, the pivotserves as the semantic head of the root node.
Ourtraversal will proceed both top-down and bottom-up from the pivot, a sort of semantic-head-driventraversal of the tree.
The choice of this traversalallows a great reduction in the search for rules usedto build the analysis tree.To be able to identify possible pivots, we dis-tinguish a subset of the rules of the grammar,the chain rules, in which the semantics of someright-hand-side element is identical to the seman-?
tics of the left-hand side.
The right-hand-side ele-ment will be called the rule's semantic head.
4 Thetraversal, then, will work top-down from the pivotusing a nonchain rule, for if a chain rule were used,the pivot would not be the lowest node sharingsemantics with the root.
Instead, the pivot's se-mantic head would be.
After the nonchain rule4 In case there axe two right-hand-side el ments hat aresemantically identical  to the left -hand side, there is somefreedom in choosing the semantic head, although the choiceis not without ramifications.
For instance, in some analysesof NP  structure, a rule such asnp/NP--> det/NP, nbar/NP.is postulated.
In general, a chain rule is used bottom-upfrom its semantic head and top-down on the non-semantic-head siblings.
Thus, if a non-semantic-head subconstituenthas the same semant ics  as the left-hand-side, a recursivetop-down generation with the same semantics will be in-voked.
In theory, this can lead to nonterrnination, unlesssyntactic factors eliminate the recursion, as they would inthe rule above regardless of which element is chosen as se-mantic head.
In a rule for relative clause introduction suchas the following (in highly abbreviated form)nbarlg --> nbarlN, sbar/N.we can (and must) choose the nominal as semantic headto effect termination.
However, there are other problem-atic cases, such as verb-movement analyses of verb-secondlanguages, whose detailed discussion is beyond the scope ofthis paper.is chosen, each of its children must be generatedrecursively.The bottom-up steps to connect he pivot to theroot of the analysis tree can be restricted to chainrules only, as the pivot (along with all interme-diate nodes) has the same semantics as the rootand must therefore be the semantic head.
Again,after a chain rule is chosen to move up one nodein the tree being constructed, the remaining (non-semantic-head) children must be generated recur-sively.The top-down base case occurs when the non-chain rule has no nonterminal children, i.e., itintroduces lexical material only.
The bottom-upbase case occurs when the pivot and root are triv-ially connected because they are one and the samenode.4.1 A DCG Implementat ionTo make the description more explicit, we will de-velop a Prolog implementation f the algorithm forDCGs, along the way introducing some niceties ofthe algorithm previously glossed over.In the implementation, a term of the formnode(Cat, P0, P) represents a phrase with thesyntactic and semantic information given by Catstarting at position P0 and ending at position P inthe string being generated.
As usual for DCGs,  astring position is represented by the list of stringelements after the position.
The  generation pro-cess starts with a goal category and attempts togenerate an appropriate node, in the process in-stantiating the generated string.gen(Cat, String) :-generate (node (Cat, String, \[\] ) ).To  generate from a node, we nondeterministi-cally choose a nonchain rule whose left-hand sidewill serve as the pivot.
For each right-hand-side el-ement, we recursively generate, and then connectthe pivot to the root.generate(Root) :-choose nonchain ruleappl icable_non_chain_rule (Root,Pivot, RHS),generate all subconstituentsgenerate _rhs ( RHS ),generate material on path to rootconnect (Pivot, Root).The  processing within genera'ce_rhs is a simpleiteration.generate_rhs(D).10generate_rhs(\[First \[ Rest\]) :-generate (First),generat e_rhs (Rest).The connection of a pivot to the root, as notedbefore, requires choice of a chain rule whosesemantic head matches the pivot, and the re-cursive generation of the remaining right-hand-side.
We assume a predicate app l i cab le_cha in_rule(Semrlead, LHS, Rool;, RHS) that holds ifthere is a chain rule admitting a node LHS as theleft-hand-side, SeraHead as its semantic head, andRHS as the remaining right-hand-side nodes, suchthat the left-hand-side node and the root nodeRoot can themselves be connected.cormect (Pivot, Root) : -choose chain ruleapplicable_chain_rule (Pivot, LHS,Root, RHS),generate remaining siblingsgenerate_rhs (RHS),~$ connect the new parent to the rootconnect.
(LItS, Root).The base case occurs when the root and thepivot are the same.
Identity checks like this onemust be implemented correctly in the generatorby using a sound Unification algorithm with theoccurs check.
(The default unification in mostProlog systems is unsound in this respect.)
Forexample, a grammar with a gap-threading treat-ment of wh-movement (Pereira, 1981; Pereira andShieber, 1985) might include the rulenp(Agr, \[np(Agr)/SemlX\]-X)/Sem---> \[\].stating that an NP with agreement Agr and se-mantics Sera can be empty provided that the list ofgaps in the NP can be represented as the differencelist \[np(Agr)/SemlX\]-X, that is the list contain-ing an NP gap with the same agreement featuresAgr (Pereira and Shieber, 1985, p. 128).
Becausethe above rule is a nonchain rule, it will be consid-ered when trying to generate any nongap NP, suchas the proper noun np(3-s ing,G-G) / john.
Thebase case of connecl; will try to unify that termwith the head of the rule above, leading to the at-tempted unification of X with l'np(Agr)/SemIX\],an occurs-check failure.
The base case, incorpo-rating the explicit call to a sound unification algo-rithm is thus as follows:cozmect(Pivot, Root) : -% trivially connect pivot to rootunify(Pivot, Root).11Now, we need only define the notion of an ap-plicable chain or nonchain rule.
A nonchain ruleis applicable if the semantics of the left-hand-sideof the rule (which is to become the pivot) matchesthat of the root.
Further, we require a top-downcheck that syntactically the pivot can serve as thesemantic head of the root.
For this purpose, weassume a predicate chained_nodes that codifiesthe transitive closure of the semantic head rela-tion over categories.
This is the correlate of thelink relation used in left-corner parsers with top-down filtering; we direct the reader to the discus-sion by Matsumoto et al (1983) or Pereira andShieber (1985, p. 182) for further information.applicable_non_chain_rule (Root, Pivot,RHS) :-7o semantics of  root and pivot are samenode_semantics (Root, Sem),node_semantics(Pivot, Sem),~o choose a nonchain rulenon_ehain_rule(r.HS, RttS),~$ ...whose lhs matches the pivotunify(Pivot, LHS),make sure the categories can connectchained_nodes(Pivot, Root).A chain rule is applicable to connect a pivot to aroot if the pivot can serve as the semantic headof the rule and the left-hand-side of the rule isappropriate for linking to the root.applicable_chain_rule (Pivot, Parent,Root, RHS) :-70 choose a chain rulechain_rule(Parent, RHS, SemHead),... whose sere.
head matches pivotunify(Pivot, SemHead),make sure the categories can connectchained_nodes(Parent, Root).The information eeded to guide the generation(given as the predicates chain_rule,  non_chain_-ru le ,  and chained_nodes) can be computed au-tomatically from the grammar; a program to com-pile a DCG into these tables has in fact been im-plemented.
The details of the process will not bediscussed further.
The careful reader will have no-ticed, however, that no attention has been givento the issue of terminal symbols on the right-handsides of rules.
During the compilation process, theright-hanOi side of a rule is converted from a list ofcategories and terminal strings to a list of nodesconnected together by the difference-list threadingtechnique used for standard DCG compilation.
Atthat point, terminal strings can be introduced intosentence/decl(S) ---> s ( f in i te) /S .
(1)sentence/imp(S) ---> vp(nonfinite,\[np(_)/you\])/S.s(Form)/S ---> Subj, vp(Fona,\[Subj\])/S.
(2)vp(Form,Subcat)/S ---> vp(Form,\[Compl\[Subcat\])/S, Compl.
(3)vp(Form,\[Subj\])/S ---> vp(Forl,\[Subj\])/VP, adv(VP)/S.vp(finite,\[np(_)/O,np(3-sing)/S\])/love(S,O) ---> \[loves\].vp(finite, \[np(_)/O,p/up,np(3-sing)/S\])/call_up(S,O) ---> \[calls\].
(4)vp(finite,\[np(3-sing)/S\])/leave(S) ---> \[leaves\].np(3-sing)/john ---> \[john\].
(5)np(3-p1)/friends ---> \[fr iends\].
(6)adv(VP)/often(VP) ---> \[often\].det(3-sing,X,P)/qterm(every,X,P) ---> \[every\].n(3-sing,X)/friend(X) ---> \[friend\].n(3-pl,l)/friend(X) ---> \[friends\]?.
.
?p/up-- -> \[up\].
(7)p/on ---> \[on\].?
Figure 1: Grammar Fragmentthe string threading and need never be consideredfurther.4 .2  An  ExampleWe turn now to a simple example to give a senseof the order of processing pursued by this genera-tion algorithm?
The grammar fragment in Figure1 uses an infix operator / to separate syntactic andsemantic ategory information.
Subcategorizationfor complements is performed lexically.Consider the generation from the categorysen~ence/dec1(call_up(john,friends) ).
Theanalysis tree that we will be implicitly traversingin the course of generation is given in Figure 2.The rule numbers are keyed to the grammar.
Thepivots chosen during generation and the branchescorresponding to the semantic head relation areshown in boldface.We begin by attempting to find a nonchain rulethat will define the pivot?
This is a rule whoseleft-hand-side semantics matches the root seman-tics decl  ( cal l_up (john, f r iends  ) ) (although itssyntax may differ)?
In fact, the only such nonchainrule issentence/decl(S) ---> s ( f in i te ) /S .
(1)We conjecture that the pivot is labeledsent ence /dec l (ca l l _up( j  ohn, f r iends)  ).
Interms of the tree traversal, we are implicitly choos-ing the root node \[a\] as the pivot?
We recursivelygenerate from the child's node \[b\], whose categoryis s(f inite)/cal l_up(john,fr iends).
For thiscategory, the pivot (which will turn out to be nodeIf\]) will be defined by the nonchain rulevp(f in i te , \ [np(_) /0,p/up,np(3-sing)/S\])/call_up(S,0) ---> \ [ca l ls \ ] .
(4)(If there were other forms of the verb, these wouldbe potential candidates, but would be eliminatedby the chained_nodes check, as the semantic headrelation requires identity of the verb form of a sen-tence and its VP head.)
Again, we recursively gen-erate for all the nonterminal elements of the right-hand side of this rule, of which there are none.We must therefore connect the pivot \[f\] tothe root \[b\].
A chain rule whose semantic head12\[a\] sentence/decl(call_up ( john,fr iends))(:)\[b\] s ( f in i te)/call_up ( john, friends )\[c\] np(3-sing)/ johnIf/(s)John\[d\] vp(fini~e,\[np(3-sing)/john\])/call_up(john,friends)\[e\] vp(finite,Cp/up,np(3-s?ng)/john\])/call_up(john,friends)vp ( finite, \[np (3- pl)/friends,p/up,np(3-sing)/john\])/call_up (john,friends)(4)callsnp(3-pl)/friendsI (81friendsp/up  \[h\](T)up\[g\]Figure 2: Analysis Tree Traversalmatches the pivot must be chosen.
The only choiceis the rulevp (Form, Subcat)/S --->vp (Form, \[Compl I Subcat \] ) IS, Compl.
(z)Unifying in the pivot, we find that we must re-cursively generate the remaining RttS elementnp(_) / f r iends,  and then connect he left-handside node \[e\] with categoryvp (finite, \[lex/up,np (3-s ing)/j ohn\] )Icall_up (j ohn, friends)to the same root \[b\].
The recursive generationyields a node covering the string "friends" follow-ing the previously generated string "calls".
Therecursive connection will use the same chain rule,generating the particle "up", and the new nodeto be connected \[d\].
This node requires the chainrules(Form)IS --->Subj, vp(Form, \[Subj\])/S.
(2)for connection.
Again, the recursive generation forthe subject yields the string "John", and the newnode to be connected s ( f in i te ) /ca l l _up( john ,f r iends) .
This last node connects to the root \[b\]by virtue of identity.This completes the process of generatingtop-down from the original pivot senl;ence/decl(call_up(john,friends)).
All that re-mains is to connect this pivot to the original root.Again, the process is trivial, by virtue of the basecase for connection.
The generation process is thuscompleted, yielding the string "John calls friendsup".
The drawing summarizes the generation pro-cess by showing which steps were performed top-down or bottom-up by arrows on the analysis treebranches.13The grammar presented here was perforce triv-ial, for expository reasons.
We have developedmore extensive xperimental grammars that cangenerate relative clauses with gaps and sentenceswith quantified NPs from quantified logical formsby using a version of Cooper storage (Cooper,1983).
We give an outline of our treatment ofquantification i Section 6.2.5 Important Properties ofthe AlgorithmSeveral properties of the algorithm are exhibitedby the preceding example xample.First, the order of processing is not left-to-right.The verb was generated before any of its comple-ments.
Because of this, the semantic informationabout the particle "up" was available, even thoughthis information appears nowhere in the goal se-mantics.
That is, the generator operated appropri-ately despite a semantically nonmonotonic gram-mar.In addition, full information about the subject,including agreement information was available be-fore it was generated.
Thus the nondeterminismthat is an artifact of left-to-right processing, anda source of inefficiency in the Earley generator, iseliminated.
Indeed, the example here was com-pletely deterministic; all rule choices were forced.Finally, even though much of the processing istop-down, left-recursive rules (e.g., rule (3)) arestill handled in a constrained manner by the algo-rithm.For these reasons, we feel that the semantic-head-driven algorithm is a significant improve-ment over top-down methods and the previousbottom-up method based on Earley deduction.6 ExtensionsWe will now outline how the algorithm and thegrammar it uses can be extended to encompasssome important analyses and constraints.6 .1  Completeness  and  CoherenceWedekind (1988) defines completeness and coher-ence of a generation algorithm as follows.
Supposea generator derives a string w from a logical forms, and the grammar assigns to w the logical forma.
The generator is complete if s always subsumesa and coherent if a always subsumes .
The gen-erator defined in Section 4.1 is not coherent orcomplete in this sense; it requires only that a ands be compatible, that is, unifiable.If the logical-form language and semantic in-terpretation system provide a sound treatment ofvariable binding and scope, abstraction and appli-cation, completeness and coherence will be irrele-vant because the logical form of any phrase will notcontain free variables.
However, neither semanticprojections in lexical-functional grammar (LFG)(Halvorsen and Kaplan, 1988) nor definite-clausegrammars provide the means for such a soundtreatment: logical-form variables or missing argu-ments of predicates are both encoded as unboundvariables (attributes with unspecified values in theLFG semantic projection) at the description level.Then completeness and coherence become impor-tant.
For example, suppose a grammar associatedthe following strings and logical forms.eat(john, X)'John ate'ea~: (j  olin, banana)'John ate a banana'eat ( john ,  n ice(ye l low(banana)) )'John ate a nice yellow banana'The generator of Section 4.1 would generate anyof these sentences for the logical form eat ( john,X) (because of its incoherence) and would generate'John ate' for the logical form eat ( john,  banana)(because of its incompleteness).Coherence can be achieved by removing the con-fusion between object-level and metalevel vari-ables mentioned above, that is, by treating logical-form variables as constants at the description level.In practice, this can be achieved by replacing eachvariable in the semantics from which we are gen-erating by a new distinct constant (for instancewith the numbervaxs predicate built into some im-plementations of Prolog).
These new constantswill not unify with any augmentations to the se-mantics.
A suitable modification of our generatorwould begen(Cat, String) :-cat_semantics (Cat, Sem),numbervaxs (Sere, O, _),generate(node(Cat,String, \['1 ) ).This leaves us with the completeness problem.This problem arises when there are phrases whosesemantics are not ground at the description level,but instead subsume the goal logical form or gener-ation.
For instance, in our hypothetical example,the string 'John eats' will be generated for seman-tics eat ( john ,  banana).
The solution is to testat the end of the generation procedure whether the14feature structure that is found is complete with re-spect to the original feature structure.
However,because of the way in which top-down informationis used, it is unclear what semantic information isderived by the rules themselves, and what seman-tic information is available because of unificationswith the original semantics.
For this reason, so-called "shadow" variables are added to the gener-ator that represent he feature structure derivedby the grammar itself.
Furthermore a copy of thesemantics of the original feature structure is madeat the start of the generation process.
Complete-ness is achieved by testing whether the semanticsof the shadow is subsumed by the copy.6.2 Quantifier StorageWe will outline here how to generate from a quan-tiffed logical form sentences with quantified NPsone of whose readings is the original logical form,that is, how to do quantifier-lowering automati-cally.
For this, we will associate a quantifier storewith certain categories and add to the grammarsuitable store-manipulation rules.Each category whose constituents may createstore elements will have a store feature.
Further-more, for each such category whose semantics canbe the scope of a quantifier, there will be an op-tional nonchain rule to take the top element of anordered store and apply it to the semantics of thecategory.
For example, here is the rule for sen-tences:s(Form, GO-G, Store)/quant(Q,X,R,S) --->s(Form, GO-G, \[qterm(Q,X,R) JStore\])/S.The term quant (C~, X, R, S) represents a quantifiedformula with quantifier Q, bound variable X, re-striction R and scope $, and cltez~(Q,X,R) is thecorresponding store element.In addition, some mechanism is needed to com-bine the stores of the immediate constituents of aphrase into a store for the phrase.
For example,the combination of subject and complement s oresfor a verb into a clause store is done in one of ourtest grammars by lexical rules such asvp(linite, \[np(_, SO)/O,np(3-sing, SS)IS\], SC)llove(S,O) --->\[loves\], {shuffle(SS, SO, SC)}.which states that the store SC of a clause withmain verb 'love' and the stores SS and S0 of thesubject and object the verb subcategorizes for sat-isfy the constraint shuf:fle(SS, SO, SC), mean-ing that SC is an interleaving of elements of SS andS0 in their original order, sFinally, it is necessary to deal with the nounphrases that create store elements.
Ignoring theissue of how to treat quantifiers from within com-plex noun phrases, we need lexical rules for deter-miners, of the formdet(3-sJ.ng,X,P, \[qterm(every,X,P)\] )/X --->\[every\].stating that the semantics of a quantified NP  issimply the variable bound by the store elementarising from the NP.
For rules of this form to workproperly, it is essential that distinct bound logical-form variables be represented as distinct constantsin the terms encoding the logical forms.
This is aninstance of the problem of coherence discussed inthe previous section.The rules outlined here are less efficient thannecessary because the distribution of store ele-ments among the subject and complements of averb does not check whether the variable boundby a store element actually appears in the seman-tics of the phrase to which it is being assigned,leading to many dead ends in the generation pro-cess.
Also, the rules are sound for generation butnot for analysis, because they do not enforce theconstraint hat every occurrence of a variable inlogical form be outscoped by the variable's binder.Adding appropriate side conditions to the rules,following the constraints discussed by Hobbs andShieber (Hobbs and Shieber, 1987) would not bedifficult.6.3 Postponing Lexical ChoiceAs it stands, the generation algorithm chooses par-ticular lexical forms on-line.
This approach canlead to a certain amount of unnecessary nonde-terminism.
For instance, the choice of verb formmight depend on syntactic features of the verb'ssubject available only after the subject has beengenerated.
This nondeterminism can be elimi-nated by deferring lexical choice to a postprocess.The generator will yield a list of lexical items in-stead of a list of words.
To this list a small phono-logical front end is applied.
BUG uses such amechanism to eliminate much of the uninterest-ing nondeterminism in choice of word forms.
Ofcourse, the same mechanism could be added to anyof the other generation techniques discussed to inthis paper.5Further details of the use of shuffle in scoplng aresiren by Pereira and Shieber (1985).157 Fur ther  ResearchFurther enhancements to the algorithm are envi-sioned.
First, any system making use of a tabularlink predicate over complex nonterminals (like thechained_nodes predicate used by the generationalgorithm and including the link predicate usedill the BUP parser (Matsumoto et al, 1983)) issubject to a problem of spurious redundancy inprocessing if the elements in the link table arenot mutually exclusive.
For instance, a singlechain rule might be considered to be applicabletwice because of the nondeterminism of the callto chained_nodes.
This general problem has todate received little attention, and no satisfactorysolution is found in the logic grammar literature.More generally, the backtracking regimen of ourimplementation f the algorithm may lead to re-computation of results.
Again, this is a generalproperty of backtrack methods and is not partic-ular to our application.
The use of dynamic pro-gramming techniques, as in chart parsing, wouldbe an appropriate augmentation to the implemen-tation of the algorithm.
Happily, such an augmen-tation would serve to eliminate the redundancycaused by the linking relation as well.Finally, in order to incorporate a general facilityfor auxiliary conditions in rules, some sort of de-layed evaluation triggered by appropriate instanti-ation (e.g., wait declarations (Nalsh, 1986)) wouldbe desirable.
None of these changes, however, con-stitutes restructuring of the algorithm; rather theymodify its realization i  significant and importantways.AcknowledgmentsShieber, Moore, and Pereira were supported inthis work by a contract with the Nippon Tele-phone and Telegraph Corp. and by a gift fromthe Systems Development Foundation as part ofa coordinated research effort with the Center forthe Study of Language and Information, StanfordUniversity; van Noord was supported by the Euro-pean Community and the Nederlands Bureau voorBibliotheekwezen en Informatieverzorgin throughthe Eurotra project.
We would like to thank MaryDalrymple and Louis des Tombe for their helpfuldiscussions regarding this work.BibliographyJonathan Calder, Mike Reape, and Hank Zeevat.1989.
An algorithm for generation i unificationcategorial grammar.
In Proceedings of the ~th16Conference of the European Chapter of the As-sociation for Computational Linguistics, pages233-240, Manchester, England (10-12 April).University of Manchester Institute of Scienceand Technology.Alain Colmerauer.
1982.
PROLOG II: Manuelde r~ference et module th~orique.
Technical re-port, Groupe d'Intelligence Artificielle, Facult~des Sciences de Luminy, Marseille, France.Robin Cooper.
1983.
Quantification and Syntac-tic Theory, Volume 21 of Synthese Language Li-brary.
D. Reidel, Dordrecht, Netherlands.Marc Dymetman and Pierre Isabelle.
1988.
Re-versible logic grammars for machine transla-tion.
In Proceedings of the Second InternationalConference on Theoretical and Methodologi-cal Issues in Machine Translation of NaturalLanguages, Pittsburgh, Pennsylvania.
Carnegie-Mellon University.Arnold Evers.
1975.
The transformational cyclein German and Dutch.
Ph.D. thesis, Universityof Utrecht, Utrecht, Netherlands.Per-Kristian Halvorsen and Ronald M. Kaplan.1988.
Projections and semantic descriptionin lexical-functional grammar.
In Proceedingsof the International Conference on Fifth Gen-eration Computer Systems, pages 1116-1122,Tokyo, Japan.
Institute for New GenerationComputer Technology.Susan Hirsh.
1987.
P-PATR, a compiler for uni-fication based grammars.
In Veronica Dahl andPatrick Saint-Dizier, editors, Natural LanguageUnderstanding and Logic Programming, II.
El-sevier Science Publishers.Jerry R. Hobbs and Stuart M. Shieber.
1987.An algorithm for generating quantifier scopings.Computational Linguistics, 13:47-63.Riny A.C. Huybrechts.
1984..
The weak inad-equacy of context-free phrase structure gram-mars.
In G. de Haan, M. Trommelen, andW.
Zonneveld, editors, Van Periferie naarKern.
Forts, Dordrecht, Holland.Yuji Matsumoto, Hozumi Tanaka, Hideki Hi-rakawa, Hideo Miyoshi, and Hideki Yasukawa.1983.
BUP: a bottom-up arser embedded inProlog.
New Generation Computing, 1(2):145-158.Michael Moortgat.
1984.
A Fregean restriction onmeta-rules.
In Proceedings of NELS 14, pages306-325, Amherst, Massachusetts.
University ofMassachusetts.Lee Naish.
1986.
Negation and Control in Pro.log, Volume 238 of Lecture Notes in ComputerScience.
Springer-Verlag, Berlin, Germany.Fernando C.N.
Pereira and Stuart M. Shieber.1985.
Prolog and Natural-Language Analysis,Volume 10 of CSLI Lecture Notes.
Center forthe Study of Language and Information, Stan-ford, California.
Distributed by Chicago Uni-versity Press.Fernando C.N.
Pereira and David H.D.
Warren.1983.
Parsing as deduction.
In Proceedingsof the 21st Annual Meeting, Cambridge, Mas-sachusetts (June 15-17).
Association for Com-putational Linguistics.Fernando C.N.
Pereira.
1981.
Extraposi-ties grammars.
Computational Linguistics,7(4):243-256 (October-December).Carl Pollard.
1988.
Categorial grammar andphrase structure grammar: an excursion onthe syntax-semantics frontier.
In R. Oehrle,E.
Bach, and D. Wheeler, editors, CategorialGrammars and Natural Language Structures.
D.Reidel, Dordrecht, Holland.Stuart M. Shieber.
1985a.
An Introductionto Unification-Based Approaches to Grammar,Volume 4 of CSLI Lecture Notes.
Center for theStudy of Language and Information, Stanford,California.
Distributed by Chicago UniversityPress.Stuart M. Shieber.
1985b.
Using restriction toextend parsing algorithms for complex-feature-based formalisms.
In 28rd Annual Meeting ofthe Association for Computational Linguistics,pages 145-152, Morristown, New Jersey.
Asso-ciation for Computational Linguistics.Stuart M. Shieber.
1988.
A uniform architecturefor parsing and generation.
In Proceedings ofthe 12th International Conference on Compu-tational Linguistics, pages 614-619, Budapest,Hungary.Mark Steedman.
1985.
Dependency and coordi-nation in the grammar of Dutch and English.Language, 61(3):523-568.Jiirgen Wedekind.
1988.
Generation as structuredriven derivation.
In Proceedings of the 12th In-ternational Conference on Computational Lin-guistics, pages 732-737, Budapest, Hungary.17
