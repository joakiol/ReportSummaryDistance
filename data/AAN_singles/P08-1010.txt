Proceedings of ACL-08: HLT, pages 81?88,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsPhrase Table Training For Precision and Recall:What Makes a Good Phrase and a Good Phrase Pair?Yonggang Deng?
, Jia Xu+ and Yuqing Gao?
?IBM T.J. Watson Research Center, Yorktown Heights, NY 10598, USA{ydeng,yuqing}@us.ibm.com+Chair of Computer Science VI, RWTH Aachen University, D-52056 Aachen, Germanyxujia@cs.rwth-aachen.deAbstractIn this work, the problem of extracting phrasetranslation is formulated as an information re-trieval process implemented with a log-linearmodel aiming for a balanced precision and re-call.
We present a generic phrase training al-gorithm which is parameterized with featurefunctions and can be optimized jointly withthe translation engine to directly maximizethe end-to-end system performance.
Multipledata-driven feature functions are proposed tocapture the quality and confidence of phrasesand phrase pairs.
Experimental results demon-strate consistent and significant improvementover the widely used method that is based onword alignment matrix only.1 IntroductionPhrase has become the standard basic translationunit in Statistical Machine Translation (SMT) sinceit naturally captures context dependency and modelsinternal word reordering.
In a phrase-based SMTsystem, the phrase translation table is the definingcomponent which specifies alternative translationsand their probabilities for a given source phrase.
Inlearning such a table from parallel corpus, two re-lated issues need to be addressed (either separatelyor jointly): which pairs are considered valid trans-lations and how to assign weights, such as proba-bilities, to them.
The first problem is referred to asphrase pair extraction, which identifies phrase pairsthat are supposed to be translations of each other.Methods have been proposed, based on syntax, thattake advantage of linguistic constraints and align-ment of grammatical structure, such as in Yamadaand Knight (2001) and Wu (1995).
The most widelyused approach derives phrase pairs from word align-ment matrix (Och and Ney, 2003; Koehn et al,2003).
Other methods do not depend on word align-ments only, such as directly modeling phrase align-ment in a joint generative way (Marcu and Wong,2002), pursuing information extraction perspective(Venugopal et al, 2003), or augmenting with model-based phrase pair posterior (Deng and Byrne, 2005).Using relative frequency as translation probabil-ity is a common practice to measure goodness ofa phrase pair.
Since most phrases appear only afew times in training data, a phrase pair translationis also evaluated by lexical weights (Koehn et al,2003) or term weighting (Zhao et al, 2004) as addi-tional features to avoid overestimation.
The transla-tion probability can also be discriminatively trainedsuch as in Tillmann and Zhang (2006).The focus of this paper is the phrase pair extrac-tion problem.
As in information retrieval, precisionand recall issues need to be addressed with a rightbalance for building a phrase translation table.
Highprecision requires that identified translation candi-dates are accurate, while high recall wants as muchvalid phrase pairs as possible to be extracted, whichis important and necessary for online translation thatrequires coverage.
In the word-alignment derivedphrase extraction approach, precision can be im-proved by filtering out most of the entries by usinga statistical significance test (Johnson et al, 2007).On the other hand, there are valid translation pairsin the training corpus that are not learned due toword alignment errors as shown in Deng and Byrne(2005).81We would like to improve phrase translation ac-curacy and at the same time extract as many as pos-sible valid phrase pairs that are missed due to in-correct word alignments.
One approach is to lever-age underlying word alignment quality such as inAyan and Dorr (2006).
In this work, we present ageneric discriminative phrase pair extraction frame-work that can integrate multiple features aiming toidentify correct phrase translation candidates.
A sig-nificant deviation from most other approaches is thatthe framework is parameterized and can be opti-mized jointly with the decoder to maximize transla-tion performance on a development set.
Within thegeneral framework, the main work is on investigat-ing useful metrics.
We employ features based onword alignment models and alignment matrix.
Wealso propose information metrics that are derivedfrom both bilingual and monolingual perspectives.All these features are data-driven and independent oflanguages.
The proposed phrase extraction frame-work is general to apply linguistic features such assemantic, POS tags and syntactic dependency.2 A Generic Phrase Training ProcedureLet e = eI1 denote an English sentence and letf = fJ1 denote its translation in a foreign lan-guage, say Chinese.
Phrase extraction begins withsentence-aligned parallel corpora {(ei, fi)}.
We useE = eieib and F = fjejbto denote an English andforeign phrases respectively, where ib(jb) is the po-sition in the sentence of the beginning word of theEnglish(foreign) phrase and ie(je) is the position ofthe ending word of the phrase.We first train word alignment models and will usethem to evaluate the goodness of a phrase and aphrase pair.
Let fk(E,F ), k = 1, 2, ?
?
?
,K be Kfeature functions to be used to measure the qualityof a given phrase pair (E,F ).
The generic phraseextraction procedure is an evaluation, ranking, fil-tering, estimation and tuning process, presented inAlgorithm 1.Step 1 (line 1) is the preparation stage.
Begin-ning with a flat lexicon, we train IBM Model-1 wordalignment model with 10 iterations for each trans-lation direction.
We then train HMM word align-ment models (Vogel et al, 1996) in two directionssimultaneously by merging statistics collected in theAlgorithm 1 A Generic Phrase Training Procedure1: Train Model-1 and HMM word alignment models2: for all sentence pair (e, f) do3: Identify candidate phrases on each side4: for all candidate phrase pair (E,F ) do5: Calculate its feature function values fk6: Obtain the score q(E,F ) =?Kk=1 ?kfk(E,F )7: end for8: Sort candidate phrase pairs by their final scores q9: Find the maximum score qm = max q(E,F )10: for all candidate phrase pair (E,F ) do11: If q(E,F ) ?
qm?
?
, dump the pair into the pool12: end for13: end for14: Built a phrase translation table from the phrase pair pool15: Discriminatively train feature weights ?k and threshold ?E-step from two directions motivated by Zens et al(2004) with 5 iterations.
We use these models to de-fine the feature functions of candidate phrase pairssuch as phrase pair posterior distribution.
More de-tails will be given in Section 3.Step 2 (line 2) consists of phrase pair evalua-tion, ranking and filtering.
Usually all n-grams upto a pre-defined length limit are considered as can-didate phrases.
This is also the place where lin-guistic constraints can be applied, say to avoid non-compositional phrases (Lin, 1999).
Each normalizedfeature score derived from word alignment modelsor language models will be log-linearly combinedto generate the final score.
Phrase pair filtering issimply thresholding on the final score by comparingto the maximum within the sentence pair.
Note thatunder the log-linear model, applying threshold forfiltering is equivalent to comparing the ?likelihood?ratio.Step 3 (line 14) pools all candidate phrase pairsthat pass the threshold testing and estimates the fi-nal phrase translation table by maximum likelihoodcriterion.
For each candidate phrase pair which isabove the threshold, we assign HMM-based phrasepair posterior as its soft count when dumping theminto the global phrase pair pool.
Other possibilitiesfor the weighting include assigning constant one orthe exponential of the final score etc.One of the advantages of the proposed phrasetraining algorithm is that it is a parameterized pro-cedure that can be optimized jointly with the trans-82lation engine to minimize the final translation errorsmeasured by automatic metrics such as BLEU (Pa-pineni et al, 2002).
In the final step 4 (line 15), pa-rameters {?k, ?}
are discriminatively trained on adevelopment set using the downhill simplex method(Nelder and Mead, 1965).This phrase training procedure is general in thesense that it is configurable and trainable with dif-ferent feature functions and their parameters.
Thecommonly used phrase extraction approach basedon word alignment heuristics (referred as ViterbiEx-tract algorithm for comparison in this paper) as de-scribed in (Och, 2002; Koehn et al, 2003) is a spe-cial case of the algorithm, where candidate phrasepairs are restricted to those that respect word align-ment boundaries.We rely on multiple feature functions that aim todescribe the quality of candidate phrase translationsand the generic procedure to figure out the best wayof combining these features.
A good feature func-tion pops up valid translation pairs and pushes downincorrect ones.3 FeaturesNow we present several feature functions that we in-vestigated to help extracting correct phrase transla-tions.
All these features are data-driven and definedbased on models, such as statistical word alignmentmodel or language model.3.1 Model-based Phrase Pair PosteriorIn a statistical generative word alignment model(Brown et al, 1993), it is assumed that (i) a randomvariable a specifies how each target word fj is gen-erated by (therefore aligned to) a source 1 word eaj ;and (ii) the likelihood function f(f ,a|e) specifies agenerative procedure from the source sentence to thetarget sentence.
Given a phrase pair in a sentencepair, there will be many generative paths that alignthe source phrase to the target phrase.
The likelihoodof those generative procedures can be accumulatedto get the likelihood of the phrase pair (Deng andByrne, 2005).
This is implemented as the summa-tion of the likelihood function over all valid hiddenword alignments.1The word source and target are in the sense of word align-ment direction, not as in the source-channel formulation.More specifically, let A(j1,j2)(i1,i2) be the set of wordalignment a that aligns the source phrase ej1i1 to thetarget phrase f j2j1 (links to NULL word are ignoredfor simplicity):A(j1,j2)(i1,i2) = {a : aj ?
[i1, i2] iff j ?
[j1, j2]}The alignment set given a phrase pair ignores thosepairs with word links across the phrase boundary.Consequently, the phrase-pair posterior distributionis defined asP?
(ei2i1 ?
fj2j1 |e, f) =?a?A(j1,j2)(i1,i2)f(a, f |e; ?
)?a f(a, f |e; ?).
(1)Switching the source and the target, we can obtainthe posterior distribution in another translation di-rection.
This distribution is applicable to all wordalignment models that follow assumptions (i) and(ii).
However, the complexity of the likelihood func-tion could make it impractical to calculate the sum-mations in Equation 1 unless an approximation isapplied.Several feature functions will be defined on top ofthe posterior distribution.
One of them is based onHMM word alignment model.
We use the geometricmean of posteriors in two translation directions asa symmetric metric for phrase pair quality evalua-tion function under HMM alignment models.
Table1 shows the phrase pair posterior matrix of the ex-ample.Replacing the word alignment model with IBMModel-1 is another feature function that we added.IBM Model-1 is simple yet has been shown to beeffective in many applications (Och et al, 2004).There is a close form solution to calculate the phrasepair posterior under Model-1.
Moreover, word toword translation table under HMM is more concen-trated than that under Model-1.
Therefore, the pos-terior distribution evaluated by Model-1 is smootherand potentially it can alleviate the overestimationproblem in HMM especially when training data sizeis small.3.2 Bilingual Information MetricTrying to find phrase translations for any possible n-gram is not a good idea for two reasons.
First, dueto data sparsity and/or alignment model?s capabil-ity, there would exist n-grams that cannot be aligned83f1                  f2                 f3(that)   (is)   (what)what?s   thate1                e2e11 e21 e22 HBL(fj2j1)f11 0.0006 0.012 0.89 0.08f21 0.0017 0.035 0.343 0.34f31 0.07 0.999 0.0004 0.24f22 0.03 0.0001 0.029 0.7f32 0.89 0.006 0.006 0.05f33 0.343 0.002 0.002 0.06HBL(ei2i1) 0.869 0.26 0.70Table 1: Phrase pair posterior distribution for the examplewell, for instance, n-grams that are part of a para-phrase translation or metaphorical expression.
Togive an example, the unigram ?tomorrow?
in ?the dayafter tomorrow?
whose Chinese translation is a sin-gle word ???.
Extracting candidate translationsfor such kind of n-grams for the sake of improvingcoverage (recall) might hurt translation quality (pre-cision).
We will define a confidence metric to esti-mate how reliably the model can align an n-gram inone side to a phrase on the other side given a par-allel sentence.
Second, some n-grams themselvescarry no linguistic meaning; their phrase translationscan be misleading, for example non-compositionalphrases (Lin, 1999).
We will address this in section3.3.Given a sentence pair, the basic assumption is thatif the HMM word alignment model can align an En-glish phrase well to a foreign phrase, the posteriordistribution of the English phrase generating all for-eign phrases on the other side is significantly biased.For instance, the posterior of one foreign phrase isfar larger than that of the others.
We use the entropyof the posterior distribution as the confidence metric:HBL(ei2i1 |e, f) = H(P?
?HMM (ei2i1 ?
?))
(2)where H(P ) = ?
?x P (x) logP (x) is the entropyof a distribution P (x), P?
?HMM (ei2i1 ?
?)
is thenormalized probability (sum up to 1) of the pos-terior P?HMM (ei2i1 ?
?)
as defined in Equation 1.Low entropy signals a high confidence that the En-glish phrase can be aligned correctly.
On the otherhand, high entropy implies ambiguity presented indiscriminating the correct foreign phrase from theothers from the viewpoint of the model.Similarly we calculate the confidence metric ofaligning a foreign phrase correctly with the wordalignment model in foreign to English direction.
Ta-ble 1 shows the entropy of phrases.
The unigramof foreign side f22 is unlikely to survive with suchhigh ambiguity.
Adding the entropy in two direc-tions defines the bilingual information metric as an-other feature function, which describes the reliabil-ity of aligning each phrase correctly by the model.Note that we used HMM word alignment model tofind the posterior distribution.
Other models such asModel-1 can be applied in the same way.
This fea-ture function quantitatively captures the goodness ofphrases.
During phrase pair ranking, it can helpto move upward phrases that can be aligned welland push downward phrases that are difficult for themodel to find correct translations.3.3 Monolingual Information MetricNow we turn to monolingual resources to evaluatethe quality of an n-gram being a good phrase.
Aphrase in a sentence is specified by its boundaries.We assume that the boundaries of a good phraseshould be the ?right?
place to break.
More generally,we want to quantify how effective a word bound-ary is as a phrase boundary.
One would perform sayNP-chunking or parsing to avoid splitting a linguis-tic constituent.
We apply a language model (LM)to describe the predictive uncertainty (PU ) betweenwords in two directions.Given a history wn?11 , a language model specifiesa conditional distribution of the future word beingpredicted to follow the history.
We can find the en-tropy of such pdf: HLM (wn?11 ) = H(P (?|wn?11 )).So given a sentencewN1 , the PU of the boundary be-tween word wi and wi+1 is established by two-wayentropy sum using a forward and backward languagemodel: PU(wN1 , i) = HLMF (wi1) + HLMB(wi+1N )We assume that the higher the predictive uncer-tainty is, the more likely the left or right part of theword boundary can be ?cut-and-pasted?
to form an-other reasonable sentence.
So a good phrase is char-acterized with high PU values on the boundaries.For example, in ?we want to have a table near thewindow?, the PU value of the point after ?table?
is0.61, higher than that between ?near?
and ?the?
0.3,using trigram LMs.With this, the feature function derived from84monolingual clue for a phrase pair can be definedas the product of PUs of the four word boundaries.3.4 Word Alignments Induced MetricThe widely used ViterbiExtract algorithm relieson word alignment matrix and no-crossing-link as-sumption to extract phrase translation candidates.Practically it has been proved to work well.
How-ever, discarding correct phrase pairs due to incorrectword links leaves room for improving recall.
Thisis especially true for not significantly large trainingcorpora.
Provided with a word alignment matrix,we define within phrase pair consistency ratio (WP-PCR) as another feature function.
WPPCR was usedas one of the scores in (Venugopal et al, 2003) forphrase extraction.
It is defined as the number of con-sistent word links associated with any words withinthe phrase pair divided by the number of all wordlinks associated with any words within the phrasepair.
An inconsistent link connects a word withinthe phrase pair to a word outside the phrase pair.
Forexample, the WPPCR for (e21, f21 ) in Table 1 is 2/3.As a special case, the ViterbiExtract algorithm ex-tracts only phrase pairs with WPPCR is 1.To further discriminate the pairs with higher WP-PCR from those with lower ratio, we apply a Bi-Linear Transform (BLT) (Oppenheim and Schafer,1989) mapping.
BLT is commonly used in sig-nal processing to attenuate the low frequency parts.When used to map WPPCR, it exaggerates the dif-ference between phrase pairs with high WPPCR andthose with low WPPCR, making the pairs with lowratio more unlikely to be selected as translation can-didates.
One of the nice properties of BLT is thatthere is a parameter that can be changed to adjustthe degree of attenuation, which provides another di-mension for system optimization.4 Experimental ResultsWe evaluate the effect of the proposed phrase extrac-tion algorithm with translation performance.
We doexperiments on IWSLT (Paul, 2006) 2006 Chinese-English corpus.
The task is to translate Chinese ut-terances in travel domain into English.
We reportonly text (speech transcription) translation results.The training corpus consists of 40K Chinese-English parallel sentences in travel domain with to-Eval Set 04dev 04test 05test 06dev 06test# of sentences 506 500 506 489 500# of words 2808 2906 3209 5214 5550# of refs 16 16 16 7 7Table 2: Dev/test set statisticstal 306K English words and 295K Chinese words.In the data processing step, Chinese characters aresegmented into words.
English text are normalizedand lowercased.
All punctuation is removed.There are five sets of evaluation sentences intourism domain for development and test.
Theirstatistics are shown in Table 2.
We will tune trainingand decoding parameters on 06dev and report resultson other sets.4.1 Training and Translation SetupOur decoder is a phrase-based multi-stack imple-mentation of the log-linear model similar to Pharaoh(Koehn et al, 2003).
Like other log-linear modelbased decoders, active features in our transla-tion engine include translation models in two di-rections, lexicon weights in two directions, lan-guage model, lexicalized distortion models, sen-tence length penalty and other heuristics.
These fea-ture weights are tuned on the dev set to achieve op-timal translation performance using downhill sim-plex method.
The language model is a statisticaltrigram model estimated with Modified Kneser-Neysmoothing (Chen and Goodman, 1996) using onlyEnglish sentences in the parallel training data.Starting from the collection of parallel trainingsentences, we build word alignment models in twotranslation directions, from English to Chinese andfrom Chinese to English, and derive two sets ofViterbi alignments.
By combining word alignmentsin two directions using heuristics (Och and Ney,2003), a single set of static word alignments is thenformed.
Based on alignment models and word align-ment matrices, we compare different approaches ofbuilding a phrase translation table and show the fi-nal translation results.
We measure translation per-formance by the BLEU (Papineni et al, 2002) andMETEOR (Banerjee and Lavie, 2005) scores withmultiple translation references.85BLEU ScoresTable 04dev 04test 05test 06dev 06testHMM 0.367 0.407 0.473 0.200 0.190Model-4 0.380 0.403 0.485 0.210 0.204New 0.411 0.427 0.500 0.216 0.208METEOR ScoresTable 04dev 04test 05test 06dev 06testHMM 0.532 0.586 0.675 0.482 0.471Model-4 0.540 0.593 0.682 0.492 0.480New 0.568 0.614 0.691 0.505 0.487Table 3: Translation Results4.2 Translation ResultsOur baseline phrase table training method is theViterbiExtract algorithm.
All phrase pairs with re-spect to the word alignment boundary constraint areidentified and pooled to build phrase translation ta-bles with the Maximum Likelihood criterion.
Weprune phrase translation entries by their probabili-ties.
The maximum number of words in Chinese andEnglish phrases is set to 8 and 25 respectively for allconditions2.
We perform online style phrase train-ing, i.e., phrase extraction is not particular for anyevaluation set.Two different word alignment models are trainedas the baseline, one is symmetric HMM word align-ment model, the other is IBM Model-4 as imple-mented in the GIZA++ toolkit (Och and Ney, 2003).The translation results as measured by BLEU andMETEOR scores are presented in Table 3.
We noticethat Model-4 based phrase table performs roughly1% better in terms of both BLEU and METEORscores than that based on HMM.We follow the generic phrase training procedureas described in section 2.
The most time consumingpart is calculating posteriors, which is carried out inparallel with 30 jobs in less than 1.5 hours.We use the Viterbi word alignments from HMMto define within phrase pair consistency ratio as dis-cussed in section 3.4.
Although Table 3 implies thatModel-4 word alignment quality is better than thatof HMM, we did not get benefits by switching toModel-4 to compute word alignments based featurevalues.In estimating phrase translation probability, weuse accumulated HMM-based phrase pair posteriors2We chose large numbers for phrase length limit to build astrong baseline and to avoid impact of longer phase length.as their ?soft?
frequencies and then the final trans-lation probability is the relative frequency.
HMM-based posterior was shown to be better than treatingeach occurrence as count one.Once we have computed all feature values for allphrase pairs in the training corpus, we discrimina-tively train feature weights ?ks and the threshold?
using the downhill simplex method to maximizethe BLEU score on 06dev set.
Since the translationengine implements a log-linear model, the discrim-inative training of feature weights in the decodershould be embedded in the whole end-to-end systemjointly with the discriminative phrase table trainingprocess.
This is globally optimal but computation-ally demanding.
As a compromise, we fix the de-coder feature weights and put all efforts on optimiz-ing phrase training parameters to find out the bestphrase table.The translation results with the discriminativelytrained phrase table are shown as the row of ?New?in Table 3.
We observe that the new approach is con-sistently better than the baseline ViterbiExtract algo-rithmwith either Model-4 or HMMword alignmentson all sets.
Roughly, it has 0.5% higher BLEU scoreon 2006 sets and 1.5% to 3% higher on other setsthan Model-4 based ViterbiExtract method.
Similarsuperior results are observed when measured withMETEOR score.5 DiscussionsThe generic phrase training algorithm follows an in-formation retrieval perspective as in (Venugopal etal., 2003) but aims to improve both precision andrecall with the trainable log-linear model.
A clearadvantage of the proposed approach over the widelyused ViterbiExtract method is trainability.
Under thegeneral framework, one can put as many features aspossible together under the log-linear model to eval-uate the quality of a phrase and a phase pair.
Thephrase table extracting procedure is trainable andcan be optimized jointly with the translation engine.Another advantage is flexibility, which is pro-vided partially by the threshold ?
.
As the figure1 shows, when we increase the threshold by al-lowing more candidate phrase pair hypothesized asvalid translation, we observe the phrase table size in-creases monotonically.
On the other hand, we notice861234567891011121314150.170.180.190.2ThresholdThresholding EffectsTranslation Performance05101555.566.5Log10 of the number of Entries in the PhraseTableBLEUPhrasetable SizeFigure 1: Thresholding effects on translation perfor-mance and phrase table sizethat the translation performance improves gradually.After reaching its peak, the BLEU score drops as thethreshold ?
increases.
When ?
is large enough, thetranslation performance is not changing much butstill worse than the peak value.
It implies a balanc-ing process between precision and recall.
The finaloptimal threshold ?
is around 5.The flexibility is also enabled by multiple con-figurable features used to evaluate the quality of aphrase and a phrase pair.
Ideally, a perfect combina-tion of feature functions divides the correct and in-correct candidate phrase pairs within a parallel sen-tence into two ordered separate sets.
We use featurefunctions to decide the order and the threshold ?
tolocate the boundary guided with a development set.So the main issue to investigate now is whichfeatures are important and valuable in ranking can-didate phrase pairs.
We propose several informa-tion metrics derived from posterior distribution, lan-guage model and word alignments as feature func-tions.
The ViterbiExtract is a special case wherea single binary feature function defined from wordalignments is used.
Its good performance (as shownin Table 3) suggests that word alignments are veryindicative of phrase pair quality.
So we design com-parative experiments to capture word alignment im-pact only.
We start with basic features that in-clude model-based posterior, bilingual and mono-lingual information metrics.
Its results on differenttest sets are presented in the ?basic?
row of Table 4.We add word alignment feature (?+align?
row), andFeatures 04dev 04test 05test 06dev 06testbasic 0.393 0.406 0.496 0.205 0.199+align 0.401 0.429 0.502 0.208 0.196+align BLT 0.411 0.427 0.500 0.216 0.208Table 4: Translation Results (BLEU) of discriminativephrase training approach using different features75K250K 132KPP1PP3PP2Model?4NewFeatures 04dev 04test 05test 06dev 06testPP2 0.380 0.395 0.480 0.207 0.202PP1+PP2 0.380 0.403 0.485 0.210 0.204PP2+PP3 0.411 0.427 0.500 0.216 0.208PP1+PP2+PP3 0.412 0.432 0.500 0.217 0.214Table 5: Translation Results (BLEU) of Different PhrasePair Combinationthen apply bilinear transform to the consistency ratioWPPCR as described in section 3.4 (?+align BLT?row).
The parameter controlling the degree of atten-uation in BLT is also optimized together with otherfeature weights.With the basic features, the new phrase extractionapproach performs better than the baseline methodwith HMM word alignment models but similar tothe baseline method with Model-4.
With the wordalignment based feature WPPCR, we obtain a 2%improvement on 04test set but not much on othersets except slight degradation on 06test.
Finally, ap-plying BLT transform to WPPCR leads to additional0.8 BLEU point on 06dev set and 1.2 point on 06testset.
This confirms the effectiveness of word align-ment based features.Now we compare the phrase table using the pro-posed method to that extracted using the baselineViterbiExtract method with Model-4 word align-ments.
The Venn diagram in Table 5 shows how thetwo phrase tables overlap with each other and sizeof each part.
As expected, they have a large num-ber of common phrase pairs (PP2).
The new methodis able to extract more phrase pairs than the base-line with Model-4.
PP1 is the set of phrase pairsfound by Model-4 alignments.
Removing PP1 fromthe baseline phrase table (comparing the first groupof scores) or adding PP1 to the new phrase table87(the second group of scores) overall results in no ormarginal performance change.
On the other hand,adding phrase pairs extracted by the new methodonly (PP3) can lead to significant BLEU score in-creases (comparing row 1 vs. 3, and row 2 vs. 4).6 ConclusionsIn this paper, the problem of extracting phrase trans-lation is formulated as an information retrieval pro-cess implemented with a log-linear model aiming fora balanced precision and recall.
We have presenteda generic phrase translation extraction procedurewhich is parameterized with feature functions.
Itcan be optimized jointly with the translation engineto directly maximize the end-to-end translation per-formance.
Multiple feature functions were investi-gated.
Our experimental results on IWSLT Chinese-English corpus have demonstrated consistent andsignificant improvement over the widely used wordalignment matrix based extraction method.
3Acknowledgement We would like to thank Xi-aodong Cui, Radu Florian and other IBM colleaguesfor useful discussions and the anonymous reviewersfor their constructive suggestions.ReferencesN.
Ayan and B. Dorr.
2006.
Going beyond AER: Anextensive analysis of word alignments and their impacton MT.
In Proc.
of ACL, pages 9?16.S.
Banerjee and A. Lavie.
2005.
METEOR: An auto-matic metric for MT evaluation with improved cor-relation with human judgments.
In Proc.
of the ACLWorkshop on Intrinsic and Extrinsic Evaluation Mea-sures for Machine Translation and/or Summarization,pages 65?72.P.
Brown, S. Della Pietra, V. Della Pietra, and R. Mer-cer.
1993.
The mathematics of machine transla-tion: Parameter estimation.
Computational Linguis-tics, 19:263?312.S.
F. Chen and J. Goodman.
1996.
An empirical study ofsmoothing techniques for language modeling.
In Proc.of ACL, pages 310?318.Y.
Deng and W. Byrne.
2005.
HMM word and phrasealignment for statistical machine translation.
In Proc.of HLT-EMNLP, pages 169?176.3By parallelism, we have shown the feasibility and effec-tiveness (results not presented here) of the proposed method inhandling millions of sentence pairs.H.
Johnson, J. Martin, G. Foster, and R. Kuhn.
2007.
Im-proving translation quality by discarding most of thephrasetable.
In Proc.
of EMNLP-CoNLL, pages 967?975.P.
Koehn, F. Och, and D.Marcu.
2003.
Statistical phrase-based translation.
In Proc.
of HLT-NAACL, pages 48?54.D.
Lin.
1999.
Automatic identification of non-compositional phrases.
In Proc.
of ACL, pages 317?324.D.
Marcu and D. Wong.
2002.
A phrase-based, jointprobability model for statistical machine translation.In Proc.
of EMNLP, pages 133?139.J.
A. Nelder and R. Mead.
1965.
A simplex methodfor function minimization.
Computer Journal, 7:308?313.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.F.
J. Och, D. Gildea, and et al 2004.
A smorgasbord offeatures for statistical machine translation.
In Proc.
ofHLT-NAACL, pages 161?168.F.
Och.
2002.
Statistical Machine Translation: FromSingle Word Models to Alignment Templates.
Ph.D.thesis, RWTH Aachen, Germany.A.
V. Oppenheim and R. W. Schafer.
1989.
Discrete-Time Signal Processing.
Prentice-Hall.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.Bleu: a method for automatic evaluation of machinetranslation.
In Proc.
of ACL, pages 311?318.M.
Paul.
2006.
Overview of the IWSLT 2006 evaluationcampaign.
In Proc.
of IWSLT, pages 1?15.C.
Tillmann and T. Zhang.
2006.
A discriminative globaltraining algorithm for statistical MT.
In Proc.
of ACL,pages 721?728.A.
Venugopal, S. Vogel, and A. Waibel.
2003.
Effectivephrase translation extraction from alignment models.In Proc.
of ACL, pages 319?326.S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM basedword alignment in statistical translation.
In Proc.
ofthe COLING.D.
Wu.
1995.
An algorithm for simultaneously bracket-ing parallel texts by aligning words.
In Proc.
of ACL,pages 244?251.K.
Yamada and K. Knight.
2001.
A syntax-based statis-tical translation model.
In Proc.
of ACL, pages 523?530.R.
Zens, E. Matusov, and H. Ney.
2004.
Improved wordalignment using a symmetric lexicon model.
In Proc.of COLING, pages 36?42.B.
Zhao, S. Vogel, M. Eck, and A. Waibel.
2004.
Phrasepair rescoring with term weighting for statistical ma-chine translation.
In Proc.
of EMNLP, pages 206?213.88
