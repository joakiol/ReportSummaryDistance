An Annotation System for Enhancing Quality of Natural LanguageProcessingHideo Watanabe*, Katashi Nagao**, Michael C. McCord*** and Arendse Bernth**** IBM Research,Tokyo Research Laboratory1623-14 Shimotsuruma, Yamato,Kanagawa 242-8502, Japanhiwat@jp.ibm.com** Dept.
of Information EngineeringNagoya UniversityFuro-cho, Chikusa-ku,Nagoya 464-8603, Japannagao@nuie.nagoya-u.ac.jp*** IBM T. J. WatsonResearch CenterRoute 134, Yorktown Heights,NY 10598, USAmcmccord@us.ibm.com,arendse@us.ibm.comAbstractNatural language processing (NLP) programs areconfronted with various diculties in processingHTML and XML documents, and have the po-tential to produce better results if linguistic infor-mation is annotated in the source texts.
We havetherefore developed the Linguistic Annotation Lan-guage (or LAL), which is an XML-compliant tag setfor assisting natural language processing programs,and NLP tools such as parsers and machine trans-lation programs which can accept LAL-annotatedinput.
In addition, we have developed a LAL-annotation editor which allows users to annotatedocuments graphically without seeing tags.
Fur-ther, we have conducted an experiment to checkthe translation quality improvement by using LALannotation.1 IntroductionRecently there has been increasing interest inapplying natural language processing (NLP) sys-tems, such as keyword extraction, automatic textsummarization, and machine translation, to Inter-net documents.
However, there are various ob-stacles that make it dicult for them to producegood results.
It is true that NLP technologies arenot perfect, but some of the diculties result fromproblems in HTML.
Further, in general, if linguis-tic information is added to source texts, it greatlyhelps NLP programs to produce better results.
Inwhat follows, we would like to show some examplesrelated to machine translation.In general, it is very helpful for machine transla-tion programs to know boundaries on many levels(such as sentence, phrases, and words) and to knowword-to-word dependency relations.
For instance,in the following example, since \St."
has two possi-ble meanings, \street" and \saint," it is dicult todetermine whether the following example consistsof one or two sentences.I went to Newark St. Paul lived theretwo years ago.As another example, the following sentence hastwo interpretations; one interpretation is that whathe likes is people and the other interpretation isthat what he likes is accommodating.He likes accommodating people.If there are tags indicating the direct-object mod-ier of the word \like," then the correct interpreta-tion is possible.
NLP may be able to resolve theseambiguities eventually by using advanced contextprocessing techniques, but current NLP technologygenerally needs a hint from the author for thesesorts of ambiguities.Further, there are issues in HTML/XML.
WhenMT systems are applied to Web pages, most of theerrors are generated by the linguistic incomplete-ness of MT technology, but some are generated byproblems in HTML and XML tag usage.
For in-stance, writers often use <br> tag to sentence ter-mination.
Sometimes writers intend that a <br>tag should terminate the sentence (even withoutterminating punctuation such as a period), and inother cases writers intend <br> only as a format-ting device.
In the HTML <table> shown in Figure1, the writer intends each line of a cell to expressone linguistic unit.
The MT program cannot tellwhether each line is a unit for translation, or, in-stead, the two lines form one unit.
In this example,some MT programs would try to produce a transla-tion of a unit \NetVista Models ThinkPad News.
"As shown in the above examples, NLP appli-cations do not achieve their full potential, on ac-count of problems unrelated to the essential NLPprocesses.
If tags expressing linguistic information<table><tr><td><a href="...">NetVista Models</a><br><a href="...">ThinkPad News</a><br></td></tr></table>Figure 1: An example of using hbri tags in a tableare inserted into source documents, they help NLPprograms recognize document and linguistic struc-tures properly, allowing the programs to producemuch better results.
At the same time, it is truethat NLP technologies are incomplete, but their de-ciencies can sometimes be circumvented throughthe use of such tags.
Therefore, this paper proposesa set of tags for helping NLP programs, called Lin-guistic Annotation Language (or LAL).2 Linguistic Annotation LanguageLAL is an XML-compliant tag set and its XMLnamespace prex is lal.The LAL tag set is designed to be as simple aspossible for the following reasons: (1) A simple tagset is easier for developers to check manually.
(2)An easy-to-use annotation tool is mandatory forthis annotation scheme.
Simplicity is importantfor making an easy-to-use annotation tool, since ifwe use a feature-rich tag set, the user must checkmany annotation items.2.1 Basic TagsThe sentence tag s is used to delimit a sentence.<lal:s>This is the first sentence.</lal:s><lal:s>This is the second sentence.</lal:s>The attribute type="hdr" means that the sen-tence is a title or header.The word tag w is used to delimit a word.
Itcan have attributes for additional information suchas base form (lex), part-of-speech (pos), features(ftrs), and sense (sense) of a word.
The values ofthese attributes are language-dependent, and arenot described in this paper because of space limi-tations.
The following example illustrates some ofthese tags and attributes.<lal:s><lal:w lex="this" pos="det">This</lal:w><lal:w lex="be" pos="verb" ftr="sg,3rd">is</lal:w><lal:w lex="a" pos="det">a</lal:w><lal:w lex="pen" pos="noun" ftr="sg,count">pen</lal:w></lal:s>The dependency (or word-to-word modication)relationship can be expressed by using the id andmod attributes of a word tag; that is, a word canhave the ID value of its modiee in a mod attribute.The ID value of a mod attribute must be an ID valueof a word tag or a segment tag.
For instance, thefollowing example contains attributes showing thatthe word \with" modies the word \saw," meaningthat \she" has a telescope.She <lal:w id="w1" lex="see" pos="v"sense="see1">saw</lal:w> a man<lal:w mod="w1">with</lal:w>a telescope.The phrase (or segment) tag seg is used to spec-ify a phrase scope on any level.
In addition, youcan specify the syntactic category for a phrase byusing an optional attribute cat.
The following ex-ample species the scope of a noun phrase \a man... a telescope," and it is a noun phrase.
This alsoimplies that the prepositional phrase \with a tele-scope" modies the noun phrase \a man.
"She saw <lal:seg cat="np">a man with atelescope</lal:seg>.The attribute para="yes" means that the seg-ment is a coordinated segment.
The following ex-ample shows that the word \software" and the word\hardware" are coordinated.This company deals with <lal:seg cat="np"para="yes">software and hardware</lal:seg>for networking.The ref attribute has the ID value of the refer-ent of the current word.
This can be used to specifya pronoun referent, for instance:<lal:s>He bought <lal:seg id="w1">anew car</lal:seg> yesterday.</lal:s><lal:s>She was very surprised tolearn that <lal:w ref="w1">it</lal:w>was very expensive.</lal:s>2.2 Expressing Multiple ParsesAs mentioned earlier, since natural language con-tains ambiguities, it is useful for LAL annotationto have a mechanism for expressing syntactic am-biguities.We have introduced a parse identier (or PID)in attribute values for distinguishing parses.
Anattribute value which may be changed accordingto parses can be allowed to be expressed as space-separated multiple values, each of which consists ofa PID prex followed by a colon and an attributevalue.<lal:s><lal:w id="1" mod="2">He</lal:w><lal:w id="2" mod="0">likes</lal:w><lal:w id="3" mod="p1:2 p2:4">accommodating</lal:w><lal:w id="4" mod="p1:3 p2:2">people</lal:w>.</lal:s>This example shows that there are two interpre-tations whose PIDs are p1 and p2, and that the p1interpretation is \He likes people" and p2 is \Helikes accommodating.
"3 LAL-Aware NLP ProgramsWe have modied certain NLP systems to beLAL-aware.
ESG [5, 6] is an English parsing sys-tem developed by the IBM Watson Research Cen-ter, and updated to accept and generate LAL-annotatedEnglish.
We have also developed a Japanese pars-ing system with LAL output functionality.
TheseLAL-aware versions of parsers are used as a back-end process to show users the system's default in-terpretation for a given sentence in the LAL-annotationeditor described below.Further, the English to German, French, Span-ish, Italian and Portuguese translation engines [6,7] and English to Japanese translation engine [9]are modied to accept LAL-annotated English HTMLinput.14 The LAL-Annotation EditorSince inserting tags into documents manually isnot generally an easy task for end users, it is impor-tant to provide an easy-to-use GUI-based editingenvironment.
In developing such an environment,we took into consideration the following points: (1)Users should not have to see any tags.
(2) Usersshould not have to see internal representations ex-pressing linguistic information.
(3) Users should beable to view and modify linguistic information suchas feature values, but only if they want to.Considering these points, we have found thatmost of the errors made by NLP programs resultfrom their failure to recognize the phrasal struc-tures of sentences.
Therefore, we have decided to1In addition, Watanabe [11] reported on an algorithmfor accelerating CFG-parsing by using LAL tag informa-tion, and it is implemented in the above English-to-Japanesetranslation engine.show only a structural view of a sentence in the ini-tial screen; other information is shown only if theuser requests it.The important issue here is how to represent thesyntactic structure of a sentence to the user.
NLPprograms normally deal with a linguistic structureby means of a syntactic tree, but such a structureis not necessarily easy for end users to understand.For instance, Figure 2 shows the dependency struc-ture of the English sentence \IBM announced a newcomputer system for children with voice function.
"This dependency structure is dicult for end users,partly because a dependency tree does not keep thesurface word order, so that it is dicult to map itto the original sentence quickly.2Therefore, an im-portant property for the linguistic structural viewis that users can easily reconstruct the original sur-face sentence string.The next important issue is how easily a usercan understand the overall linguistic structure.
Ifa user is, at rst, presented with detailed linguisticstructure at the word level, then it is dicult tograsp the important linguistic skeleton of a sen-tence.
Therefore, another necessary property isto give users a view in which the overall sentencestructure is easily recognized.Figure 2: An example of tree structure of an En-glish sentenceWith these requirements in mind, we have devel-oped a GUI tool called the LAL Editor.
To satisfythe last requirement, this editor has two presenta-tion modes: the reduced presentation view and theexpanded presentation view.
In the reduced pre-sentation view, a main verb and its modiers arebasic units for presenting dependencies, and theyare located on dierent lines, keeping the surfaceorder.
Figure 3 shows an example of this reducedpresentation view.
In this view, since dependen-cies that are obvious for native speakers (e.g.
\a"and \computer" ) are not displayed explicitly, theuser can concentrate on dependencies between key2You must perform an inorder tree walk to reconstruct asurface sentence string.Figure 3: Screen Images of LAL Editor - ReducedViewunits (or phrases).
If the user nds any depen-dency errors in the reduced view, he or she canenter the expanded view mode in which all wordsare basic units for presenting dependencies.
Fig-ure 4 (a, b) shows examples of this expanded view.In these views, to satisfy the former requirement,dependencies between basic units are expressed byusing indentation.
Therefore you can easily recon-struct the surface sentence string by just looking atwords from top to bottom and from left to right,and easily know dependencies of words by lookingat words located in the same column.
For detailsof the algorithm, see [12].In Figure 3, you can easily grasp the overallstructure.
In this case, since the dependencies be-tween \for" and \announced," and \with" and \an-nounced" are wrong, the user can change the modeto the expanded view (as shown in Figure 4 (a)).In this view, the user can change dependencies bydragging a modier to the correct modiee usinga mouse.
The corrected dependency structure isshown in Figure 4 (b).In addition, the LAL Editor has the capability oftesting translation by using LAL annotation.
Fig-ure 5 shows a window in which the top pane showsthe input sentence, the second pane shows the LAL-annotation of the input, the third pane shows thetranslation result using the LAL annotation, andthe fourth pane shows the default translation with-out using the LAL annotation.
The user can easilycheck whether the current annotation can improvetranslations.5 ExperimentWe have conducted a small experiment for eval-uating LAL annotation to our English-to-Japanesemachine translation system[9].
We gathered about60 sentences from Web pages in the computer do-main, and added LAL annotation to these sen-(a) Expanded View (before correction)(b) Expanded View (after correction)Figure 4: Screen Images of LAL Editor - ExpandedViewtences with the LAL annotation editor.
In thisexperiment, only word-to-word modications werecorrected.
Due to severe parsing errors and glitchesof the annotation editor, 53 of the 60 sentenceswere used in this experiment.
The average sentencelength for this test set was 21 words.
Two evalu-ators assigned a quality evaluation ranging from 1(worst) to 5 (best) for each translation, with andwithout use of annotation.Translation results for 18 sentences (about 34%)were better for the annotated case than the non-annotated case.
These better sentences were 1.16Figure 5: Translation test window of LAL Editorpoints better (27% better in quality score).
Onthe other hand, 26 sentences (about 49%) were notchanged, and 9 sentences (about 17%) were worse.The main reason why these 9 sentences were worsewas the structural mismatch between the outputof the LAL Editor and the expected structure ofEtoJ translation system, since the LAL Editor andthe EtoJ MT system use dierent parsing systems.We have developed a structure conversion routinefrom LAL editor output to EtoJ input, but it doesnot yet cover all situations.
This is the reason whythese 9 sentences become worse.Note that this experiment only uses word-to-word modication corrections, so there is room forproducing better translations if we use other typesof annotation such as part-of-speech, and word sense.6 DiscussionThere have been several eorts to dene tagsfor describing language resources, such as TEI [10],OpenTag [8], CES [1], EAGLES [2], GDA [3].
Themain focus of these eorts other than GDA hasbeen to share linguistic resources by expressing themin a standard tag set, and therefore they dene verydetailed levels of tags for expressing linguistic de-tails.
GDA has almost the same purposes but ithas also dened a very complex tag set.
This com-plexity discourages people from using these tag setswhen writing documents, and it also becomes dif-cult to make an annotation tool for these tags.LAL is not opposed to these previous eorts, butattempts to strike a useful balance between expres-siveness and simplicity, so that annotation can beused widely.As mentioned in the discussion of the experi-ment, there is an issue when the parsing systemof LAL editor and the parsing system of a NLPtool which accepts the output of LAL editor aredierent.
As mentioned before, we used the ESGparser for producing LAL-annotated English, andJapanese-to-EnglishMT system for accepting LAL-annotated English.
Since these systems have beenindependently developed based on dierent approachesby dierent developers, we found there are somestructural dierences.
For instance, given a prepo-sitional phrase Prep N, ESG's head word of theprepositional phrase is Prep, but EtoJ MT engine'shead is N. In most cases, we can make systematicconversion routines for dierent structures.
In fact,for most of sentences whose translation is worsewhen annotation is used, we can provide struc-tural conversion routines for linguistic structuresincluded in them.
The basic idea of LAL-awarenessfor NLP tools is that an NLP tool uses LAL infor-mation as much as possible, but if LAL informationproduces a severe conict with the internal process-ing, then such information should not be used.
OurEtoJ MT program was basically implemented thisway based on the algorithm described in [11], butwe seem to need more research on this issue.7 ConclusionIn this paper, we have proposed an XML-complianttag set called Linguistic Annotation Language (orLAL), which helps NLP programs perform theirtasks more correctly.
LAL is designed to be assimple as possible so that humans can use it withminimal help from assisting tools.
We have also de-veloped a GUI-based LAL annotation editor, andhave shown in an experiment that use of LAL anno-tation enhances translation quality.
We hope thatwide acceptance of LAL will make it possible to usemore intelligent Internet tools and services.References[1] CES, \Corpus Encoding Standard (CES),"(http://www.cs.vassar.edu/CES/)[2] EAGLES, \Expert Advisory Group on Language Engi-neering Standards,"(http://www.ilc.pi.cnr.it/EAGLES/home.html)[3] GDA, \Global Document Annotation,"(http://www.etl.go.jp/etl/nl/gda/)[4] Koichi Hashida, Katashi Nagao, et.
al, \Progressand Prospect of Global Document Annotation," (inJapanese) Proc.
of 4th Annual Meeting of the Asso-ciation of Natural Language Processing, pp.
618{621,1998[5] McCord, M. C., \Slot Grammars," Computational Lin-guistics, Vol.
6, pp.
31{43, 1980.
[6] McCord, M. C., \Slot Grammar: A System for Sim-pler Construction of Practical Natural Language Gram-mars," in (ed) R. Studer, Natural Language and Logic:International Scientic Symposium, Lecture Notes inComputer Science, pp.
118{145, Springer Verlag, 1990.
[7] McCord, M. C., and Bernth, A., \The LMT Transfor-mational System," Proc.
of Proceedings of AMTA-98,pp.
344{355, 1998.
[8] OpenTag, \A Standard Extraction/Abstraction TextFormat for Translation and NLP Tools,"(http://www.opentag.org/)[9] Takeda, K., \Pattern-Based Machine Translation,"Proc.
of 16th COLING, Vol.
2, pp.
1155{1158, August1996.
[10] TEI, \Text Encoding Initiative (TEI),"(http://www.uic.edu:80/orgs/tei/)[11] Watanabe, H., \A Method for Accelerating CFG-Parsing by Using Dependency Information," Proc.
of18th COLING, 2000.
[12] Watanabe, H., Nagao, K., McCord, M. C., and Bernth,A., \Improving Natural Language Processing by Lin-guistic Document Annotation," Proc.
of COLING 2000Workshop for Semantic Annotation and Intelligent Con-tent, pp.
20{27, 2000.
