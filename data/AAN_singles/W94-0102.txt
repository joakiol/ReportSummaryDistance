AMALGAM:  :Automat ic  Mapp ing  AmongLex ico -Grammat ica l  Annotat ion  Mode lsEr ic  A twe l l ,  J ohn  Hughes ,  and  C l ive  SouterCentre for Computer  Analysis of Language And SpeechSchool of Computer  Studies, Leeds University, Leeds LS2 9JT,  UKeric@scs, leeds, ac.
uk j ohn@scs, leeds, ac.
uk cs@scs, leeds, ac.
ukAbst ractSeveral Corpus Linguistics research groups have gonebeyond collation of 'raw' text, to syntactic annotationof the text.
However, linguists developing these lin-guistic resources have used quite different wordtaggingand parse-tree labelling schemes in each of these anno-tated corpora.
This restricts the accessibility of eachcorpus, making it impossible for speech and handwrit-ing researchers to collate them into a single very largetraining set.
This is particularly problematic as thereis evidence that one of these parsed corpora on its ownis too small for a general statistical model of grammat-ical structure, but the combined size of all the aboveannotated corpora should deliver a much more reliablemodel.We are developing a set of mapping algorithms tomap between the main tagsets and phrase structuregrammar schemes used in the above corpora.
We planto develop a Multi-tagged Corpus and a MultiTreebank,a single text-set annotated with all the above taggingand parsing schemes.
The text-set is the Spoken En-glish Corpus: this is a half-way house between formalwritten text and colloquial conversational speech.
How-ever, the main deliverable to the computational linguis-tics research community is not the SEC-based Multi-Treebank, but the mapping suite used to produce it- this can be used to combine currently-incompatiblesyntactic training sets into a large unified multicorpus.Our architecture combines standard statistical languagemodelling and a rule-base derived from linguists' anal-yses of tagset-mappings, in a novel yet intuitive way.Our development of the mapping algorithms aims todistinguish notational from substantive differences inthe annotation schemes, and we will be able to evalu-ate tagging schemes in terms of how well they fit stan-dard statistical language models uch as n-pos (Markov)models.
11This research began with grants from the UK Scienceand Engineering Research Council (SERC) and the Univer-sities Funding Council's Knowledge Based Systems Initia-tive (UFC KBSI), and is now funded by the UK Engineer-ing and Physical Sciences Research Council (EPSRC) andIn t roduct ionSeveral research projects around the world are buihli.ggrammatically analysed corpora; that is, collections o1"text annotated with part-of-speech wordtags and sy.-tax trees.
Tagged and parsed English corpora (Ba.k ofEnglish \[54\]; BNC \[441, \[22\]; Brown \[24\]; ICE \[12\], \[28\],\[64\]; Lancaster-IBM \[26\], \[22\]; LOB \[1\], \[3\], \[38\], \[.12\];London-Lund \[62\]; Nijmegen \[12\]; PoW \[23\], \[55\], \[57\];SEC \[631; TOSCA \[46\], \[311, \[12\]; UPenn \[53\], \[45\]; etc)are used, among other things, as atithoritative exal n piesby researchers in English Language Teaching and Lexi-cography (e.g.
\[44\]), and as training data for statisticalsyntactic onstraint models to improve recognition ac-curacy in speech and handwriting recognisers (e.g.
\[37\],\[I01).However, projects have used quite different wordtag-ging and parsing schemes.
In contrast o the Speechresearch community, which has reached broad agree-ment on an uncontentious set of labelling conventionsfor phonetic/phonemic analysis, there is no general con-sensus in the international Natural Language researchcommunity on analogous conventions for grammaticalanalysis, Developers of corpora adhere to a variety o\['competing models or theories of grammar and parsing,with the effect of restricting the accessibility of theirrespective corpora, and the potential for collation intoa single fully parsed corpus.In view of this heterogeneity, we have begun to in-vestigate and develop methods of automatically map-ping between the annotation schemes of the most widelyknown corpora, thus assessing their differences and im-proving the reusability of the corpora.
Annotating asingle corpus with the different schemes allows for com-parisons, and will provide a rich test-bed for automaticparsers.The most widely known tagged colrpora for Englishare: the Lancaster-Oslo/Bergen (LOB) Corpus; theBrown Corpus; and the London-Lund Corpus.
In addi-the Higher Education Funding Councils' New TechnologiesInitiative (HEFCs' NTI); we gratefully acknowledge theirfinancial support.
We are also grateful to the Corpus \[,in-guistics research teams who have generously provided back-ground information on their tagging and parsing schcnlt:s.11lion, the International Corpus of English (ICE) shouldb,, included as its tagset has now been published \[28\].Parsed corpora for English include: the Lancaster-IBMl'rcebank; the Lancaster-IBM Spoken English Corpus(SEC) 'rreebank; the Lancaster-Leeds Treebank; thePolytechnic of Wales (PEW) Corpus; the Nijmegen('orpus; the TOSCA Corpus;; and the University ofP,,nnsylvania (UPenn) Treebank.
We plan to includethe parsed ICE-GB (Great Britain component of ICE)and the BNC (British National Corpus) in the projectwhen they become available.As a development and testing resource, we are us-ing the text of the Lancaster-IBM Spoken English Cor-pus (SEC).
The SEC is a collection of recordings of ra-dio broadcasts with accompanying annotated transcrip-tie,s, collected by Lancaster University and IBM UKas a general research resource.
The SEC is availablefrom the International Computer Archive of ModernEnglish (ICAME) based at the Norwegian Computing(',entre for the Humanities (in Bergen, Norway).
Thecorpus exists in several forms and annotations: the digi-tiscd acoustic waveform; the graphemic transcriptiona.m~otated with prosodic markings; and a part-of-speechanalysis (using the LOB Corpus tagset).
Skeletal pars-ing has been added to create the SEC Treebank, andthis forms a subset of the Lancaster-IBM Treebank.
(;crry Knowles (Lancaster) and Peter Roach (Leeds)are collaborating in an ESRC-funded project to set upa time-aligned atabase of recorded speech, accompa-nied by phonetic and graphemic transcriptions.
Ourproposal will produce, as a side-effect, several alterna-tive tagged and parsed versions of the SEC which willb,, made available to the SEC database project collab-orators.
It will also be able to act as a test-bed for the('ompa.rison and evaluation of parsing schemes.Objectives of the projectThe main objectives are as follows :To design and implement algorithms for mapping be-ween corpus annotation schemes; for both wordtag setsa ml phrase structure grammar schemes.To empirically evaluate the accuracy and shortcom-ings of the developed mapping algorithms, by applyingthem to the tagged SEC and the SEC Treebank.
The~,ulcome of this evaluation will be to highlight the no-la~h)nal and substantive differences between the alter-Ilative tagging and parsing schemes.To build a Multi-Tagged Corpus, by enhancing theSpok~,n English Corpus with different wordtagging~chCIItes.To build a Multi-Treebank, by enhancing the SpokenEnglish Corpus with grammatical nalyses according tos,,v,,ral alternative grammatical theories.To investigate tim use of tile Multi-Treebank as ah,.~chmark for grammars and parsers.Itfil.ially, we considered adopting the 'lnterlingua p-I,r,,ach' to mapping, as used in Machine Translationl,r,~j,','ts such as EUR.OTRA.
This would require usto develop tagset mappings between the LOB Corpus(our primary tagset Interlingua) and each of the 'ma-jor' tagged corpora: BROWN, ICE, Lancaster-IBM,and UPenn.
Next full grammar mappings would bedeveloped between the Lancaster-IBM Treebank (ourprimary parsing scheme Interlingua) and each of: theUPenn Treebank and the Lancaster-Leeds Treehank.The ICE and BNC tagsets and parsing schemes couldbe included when they become available.
Mapping be-tween tagsets will involve relabelling of words, whereasmapping between grammar schemes also involves truc-tural manipulation.
These treebanks have been chosenfor their skeletal parsing schemes, which are of rela-tively similar structure apart from a small number ofsystematic differences.We have chosen the SEC as a 'core' text for thisproject, because1.
the tagged SEC uses the same tagset as the LOBCorpus (widely considered to be the UK standardand our proposed primary tagset);2. the parsed SEC uses the same grammatical scheme asthe Lancaster-IBM Treebank (our proposed primaryparsing scheme);3. these are the annotation schemes which we have mostprior experience of;4. the text material, BBC radio broadcasts, are a neu-tral compromise between written and conversationalspoken English genres.Our aim is to develop bidirectional mappings forthe above tagsets and grammar schemes, although weappreciate that for mapping from simple to delicateschemes this will not be possible, and that mappingswill be imperfect.
As mapping algorithms are devel-oped and tested, and whilst building the Multi-TaggedCorpus and Multi-Treebank, we will compile "hand-books" of common errors (i.e.
mismatches) and theircorrections.
These will help future users of the devel-oped mapping algorithms to straightforwardly post-edittheir mapped corpora and treebanks, thus maximisingresource reusability.
To map between two tagsets otherthan LOB, two mappings will be necessary (via theprimary tagset, our "interlingua" representation); simi-laxly for non-terminal grammar schemes.
We appreciatethe danger of propogating incorrect mappings.If there is sufficient ime, we hope to go on to in-vestigate mapping algorithms for other (more detailed)grammar schemes; for example the parsed Pew Cor-pus (Systemic Functional Grammar), and the parsedNijmegen Corpus (Extended Affix Grammar).
Thenon-corpus-based Generalised Phrase Structure Gram-mar (GPSG) (as used in the Alvey Natural LanguageToolkit ANLT) should also be included.
Mapping fromthese to the Lancaster-IBM Treebank grammar schemewould only be uni-directional i.e.
from a d,:tail,~d to askeletal analysis.The Multi-Treebank will be produced by applyingthe final version of each grammar scheme mapping al-12gorithm to the SEC Treebank.
Similarly, for the Multi-Tagged Corpus, the final version of each tagset mappingalgorithm will be applied to the tagged SEC.
The re-suiting annotations will then be intensively proofreadand post-edited.
This will require consultations withauthorities in each of the tagsets and grammar schemesinvolved.Progress to dateWe envisage three main stages to the project: imple-mentation of algorithms for mapping between tagsets;implementation of algorithms for mapping betweenphrase structure grammatical analysis schemes; andinvestigating applications of the mapping programs,multi-tagged corpus, and multi-treebank.We are currently in the first of these.
Mapping algo-rithms are being designed and implemented between theLOB Corpus tagset and each of: the tagged BROWNCorpus, the tagged ICE, the Lancaster-IBM Treebank,the UPenn Tagset (and the BNC tagset will be addedwhen published).
Each tagset is being considered inturn:1.
Analysis of the notational and substantive differencesbetween the LOB tagset and the 'current' tagset.2.
Design and implementation of a mapping algorithm(two-way, where possible).3.
Evaluate success of algorithm by applying it to thetagged SEC; incrementally improve in light of com-mon errors and linguistic intuition.A side-effect of this phase is the production of aMulti-Tagged Corpus: the SEC text annotated witheach tagset.A s tandard  fo rmat  for  tagged and  parsedcorporaAs well as using different agsets and parsing schemes,different annotated corpora come in a range of differentformats - see \[57\], \[59\], \[60\].
A non-trivial first step inmerging tagged and parsed corpora is to decide on aunitary standardised format.
Although the Text En-coding Initiaitive (TEI) \[61\], \[18\] offers general guide-lines for text formatting standards, and some corpora(including BNC, ICE) aim to be "rEI-conformant", inpractice it seems almost as hard for Corpus linguiststo agree to accept a single annotation format as it isto agree on a single annotation scheme.
Our mappingsoftware will use a standardised internal format for tag-gings and parse-trees, but will have to be able to acceptinput and produce output in a range of existing formats.Hand-c ra f t ing  a deta i led  mapp ingOne approach to obtaining a mapping between twotagsets is to use expert linguistic knowledge in iden-tifying the relationship between particular tags, and isexemplified in, for example, \[58\].
In this work, Souterdrew up a mapping between the parts of speech used inthe CELEX database \[17\], (which were thet,,sclw,s <t,,-rived largely from those in LDOCE \[51\]), and th,, sys-temic functional grammar (SFG) used to hand pars,"the Polytechnic of Wales corpus \[23\], \[551 .The aim was to provide a large lexicon to supporLSFG-based parsing programs.
The original CELEX h.x-icon, which contained some 80,000 English wordforms.was transformed into a lexicon with SFG tags, usi,g asemi-automatic mapping program, written in the AWKprogramming language.
The resulting lexicon was tl,,.compatible with a large corpus-based systemic gram-mar consisting of over 4,000 phrase-structure rules \[56\].Together they can then support relatively robust prob-abilistic parsing programs.The problems encountered in trying to specify sucha mapping result from disparity in the level of delicacyin the two tagging schemes.
Mapping from a coats,,- tofine-grained grammar must be achieved manually, us,'subcategorisation information contained in the lexi~'o.,contextual information, or exception lists.
Souter's pro-gram contained simple one-to-one mappings, many-l.o-one mappings, and one-to-many mappings upportedby exception lists and subcategorisation information.In his work, contextual information could not bc ,sedto support he mapping because the source material w~usa lexicon and not a tagged corpus.
A small part of themapping code (used to map between pronoun labels) isshown in Figure 1.else if (category ffi= "PRON") # pronouns(if (\$8 ffi "Y") printf("HWH)(") # I/H-pronounselse if ((\$I ~ffi "no-one")l l\( \$1 == "nobody")\[ 1\( \$1 .
.
.
.
nothing") \[ l \(\$I == "noone") J l\(\$I .... none") )printf("HPN) (") # negative pronounselse printf("HP)(") # other pronouns}Figure 1: Fragment of an AWK mappingfrom CELEX to SFG tagsetsHere, the coarse-grained CELEX tag PRON (pro-noun) is mapped to three SFG tags, HWH, HPN andHP.
The default mapping is to HP (pronominal head ofthe nominal group), but if the CELEX lexicon containssubcategorisation information in the form of a Y in col-umn 8, then we can assign the label for wh-pronou,head (HWH).
An exception list is used to map to thethird SFG pronoun label (HPN), for negative pronounheads.Inc rementa l  re f inement  th rough feedbackEarlier work at Leeds \[32\] explored ways that a prob-abilistic grammar may be improved with positiw, fi~ed-back from a human user; this has direct implications13fi)r how to improve the mappings incrementally.
As themapped annotations are to be hand-corrected by ex-i)(,rts this provides positive feedback.
Rather than tagthe cole text completely using the best derived mappinga better idea would be to do it in sections and then haveIho ~,xpert correct he errors in each section in turn.
Af-ter each section is complete the mapping rules will beul)dated to incorporate the new information.
Hopefullythis will enable future sections to be mapped more ac-curately.
This method is similar to that used by theNi.imegen corpus parsing group, \[47\]P rob lems w i th  the  in ter l ingua-basedapproachTIw interlingua idea seems sound for several reasons.Amongst hese is the saving made in required map-pings.
For instance, tire tagging schemes would requiretwenty mappings if each pair is mapped irectly in both(lir~,ctions.
However only eight mappings axe requiredif one of the tagging schemes acts as an interlingua.This saving becomes greater as more tagging schemesarc considered.
The interlingua lso helps the map-pings attain a level of consistency as the interlinguais I.ho basis of all possible mappings from one taggingscheme to another.
However, the interlingua may causeprol)lenm in the instances where it is coarse-grained rel-ative to other tagging schemes.
For instance, the LOBtagset has no notion of verb transitivity whereas theICE tagset does.
If a mapping is being made betweentwo tagging schemes both of which incorporate the con-cept of transitivity then a tag may be wrongly allocateda.~ the sense of transitivity is lost via the LOB tagsetintcrlingua.One problem with the work plan is the strong em-phasis on this problem of imperfect mappings due tocourse-grained parts of the interlingua.
It may turn outafter experimentation that the contextual informationof the surrounding tags and words make up for this.
'l'hc sentence, S, the interlingua tags, a, and the otherI..Igging scheme's tags, b, can be represented as follows:!Sentence Tagging 1 Tagging 2$1 al bl82 a2 b2$3 as baS.
-  u an-2 bn- 2Sn-1 an-1 bn-1S.
a. b,~Using a window of the closest four neighbours, say,the tag ai when presented with a difficult tag, bi, hasI,hc additional context information of Si-2, S i - t ,  Si+l,N',t:,, o,-2, ai--t, ai+l and ai+a to work on.
Previousrcs,.arch (including \[4\], \[5\], \[33\], \[34\], \[35\], \[36\]) has indi-,.at,.d I hat there is a high degree of useful contextual in-I',~rmal ion implied by the surrounding items.
This con-textual information can be used with clustering tech-niques to classify words.
These techniques could beapplied to the tagging scheme with little modification.The classifications could then be examined to see whichtypes of tag are difficult to group.
Tags which are dif-ficult to cluster may be useful in identifying problemareas early.
As an example, Figure 2 shows a clusteringdendogram for the LOB Corpus tagset.One possible problem might be: given the set ofWords in (SI ... Sn) and the interlingua tags (al... an)how are the other tagging scheme's tags (bl...bn) de-rived?
Obviously, the tagging scheme itself can be usedto map directly the words ($I... Sn) onto the tags(bl...bn) without knowledge of the interlingua tags(al...an).
Also, mappings could be made solely be-tween the interlingua tags (al ... an) and the other tags(bl ... bn).
This could be done by having an expert taga section of the 'core text' with both the interlingua andthe other tagging scheme.
Probabilisitic rules could bederived indicating how the tags match up.
These ruleswould be strengthened if the context of the surroundingtags was incorporated.When the two pieces of information axe combined itis hoped that a more accurate mapping can be achieved.This can be done by mapping directly from the wordplus tag to the new tag.
For instance;Si + ai ~ bi.However, rules could grow very large even when reg-ularities are used to reduce their number.Alternatively, a mapping could be made for Si ~-* bilaccording to the standard annotation rules for the non-interlingua tagging scheme; and a mapping could bedone for ai ~ bi2 according to the procedure outlinedabove.
These mappings produce two potential tags in-dependently.
One algorithm might always accept bilwhen bil = hi2.
When b~l ~ bi2 a decision needs tobe made as to which, if any, of the tags should be cho-sen. Brill \[14\] developed a clever and highly accuratetagging scheme which could have implications for thisproblem.
He tagged every occurrence of a word with itsmost probable tag if there was more than one choice.
Asecond pass of the corpus would update the tags accord-ing to a set of automatically acquired rules.
A similaridea could be utilised to choose between the tags.
Per-haps the most probable tag would always be selectedon the first pass but we would allow that decision to bealtered on a second pass according to rules derived fromearlier sections of the corpus that had been tagged andchecked by the expert linguist.
This, then, is anotherexample of incremental learning.Combin ing  Symbol i c  and  Stat i s t i ca lApproaches  to LanguageOur research is particularly relevant to this work-shop, as it is clear we will have to combine rule-based symbol-mapping knowledge with statistical dis-ambiguation models.
We envisage that the bulk of a14g,ummMDVBmg,1olmiv~)gtDtI== ~!Figure 2: A Clustering of LOB Tagsmapping can be done using simple one-to-one symbolreplacement rules; but some rules will map one sourcesymbol onto a set of more than one target symbol.
Astatistical part-of-speech tagger along the lines of th,~CLAWS tagger used on LOB \[42\], [3\], \[25\] ca,, th,'.,, l.,used to select between the reduced camlhhtt,, set ush,g ~,statistical context model; probably a lst-order Mark, wor Bi-Pos model is most appropriate as this is tt,' sim-plest 'standard' statistical language model and is widelyused and understood, see for example \[2\], \[48\], \[7\], \[37\],\[9\], \[49\].We can arrive at such a model of source-to-tart:itmapping by 'working backwards': first run a CLAWS-style Markovian target-tagset tagger over the text, ig-noring the source tags; proofread the output to notewhere this makes mistakes (assigns incorrect targettags); and then devise source-to-target tag mappingrules only for these cases.
We are aware from our owninitial attempts at deivising tag-mappings that this re-quires a high level of specialist linguistic knowledge, ofboth source and target agset; this "symbolic patchingof the statistical model" approach minimises the 'lin-guistic expertise' we need to capture (and first develop!
)to devise symbolic mapping rules.
We have learnt ofcorpus-tagset mapping work by a number of other re-searchers (including \[13\], \[30\], \[20\] [39\] [41\], \[52\]), I utgenerally such research in the past has been merely ameans to an end (to create a re-tagged Corpus), sothe full mapping algorithms have not been formalis~,dor published; but if all we need is a limited nub~'r ofmapping-rules to "patch" the Markov model the,t wemay be able to glean sufficient details from informalnotes etc.
It may appear that we are promoting badSoftware Engineering principles in advocating symbolic"patches" to fix the flaws in the statistical model as andwhen we spot them - patching up a program as the bugsseep out, However, we prefer to view this as a princi-pled, well-founded approach to combining symbolic andstatistical models, minimising the 'overlap' by ensufi,gthat each has a separate useful contribution to mak(, I.othe overall mapping task.We envisage combining a CLAWS-style tagger mod-ule for each of the target tagsets into a single Multi-tagger program.
This accepts as input a stream ofwords annotated with tag(s) from one (or more) of tlwsource tagsets; to output is a stream of words plus t~tgsfrom ALL target tagsets.
This model allows for inclu-sion of mapping rules both direct from source to targ,q.tagset, and via an interlingua (a backup default o tryif there are no direct mapping rules).Future WorkThe remainder of the project will be devoted to timtwo other phases of the plan listed earlier, mapping be-tween phrase-structure parsing schemes, and investigkt-ing applications of the multi-tagged corpus and multi-treebank.15Imp lementat ion  of  A lgor i thms ForMapp ing  Between Grammar  SchemesInitially mapping algorithms will be designed and im-plemented between the Lancaster-IBM Treebank gram-mar scheme, and each of the UPenn Treebank and theLancaster-Leeds Treebank.
Each grammar scheme willbc considered in turn:1.
Analysis of the notational nd substantive differencesb~.tween the Lancaster-IBM grammar scheme and the~cHrrent' grammar scheme.2.
Mammlly parse a subset of the SEC according to the'current' grammar scheme.
This subset should besufficient to allow a prototype mapping algorithm toI~q~ imluced.:~.
Apply mapping algorithm to the parsed SEC; incre-mentally improve in light of common errors and lin-guistic intuition.Dcpending on how much time is available, mappingalgorithms for more detailed grammar schemes will beinvestigated: parsed POW Corpus, parsed Nijmegen(',orpus, GPSG, and the BNC grammar scheme (whenpublished).
A side-effect of this phase will be the pro-duction of a Multi-Treebank; the SEC automaticallya:mml.ated with each grammar scheme.The all-in-one Multi-tagger architecture outlined~d,ove can be carried over to a Multi-parser.
Insteadof a CLAWS-style Markovian tagger, for each targetparsing scheme agrammar and parser can be extracteddirectly from the corresponding training Treebank.
AContext-Free Grammar can be elicited directly by ex-tracting each non-terminal nd its immediate-daughter-scqu~'nce, to become the left-hand-side and right-hand-side respectively ofa context-free grammar rule \[6\]; fre-quencies of constituents in the training treebank can beused to make this a Probabilistic Context Free Gram-mar \[49\], useable in a treebank-trained probabilisticparser such as those in \[2\], \[29\], \[9\], \[50\].
Rather thanproducing a single, fully correct parse-tree for eachinput sentence, these probabilistic Treebank-trainedp~rser generally output an ordered list of possible parse-trees, with a probability or weight attached to each.As with the procedure for developing a partial tag-mapping, we need only devise source-to-target parse-tree-constituent mappings in cases where the target-parser's 'best' parsetree is not fully correct.Assessment  o f  the  Mu l t i -T reebank  as aBenchmark  for Grammars'this requires analysis of the substantive differences bee-tw,'en different parses of the SEC sentences; detailedanalysis of how many and which constructs differ intlw dilfcrent language umdels.
It may be possible todivide.
I,he sentences in the SEC into two subsets: a~'ommon core of "uncontentious" sentences which all ormost lheories analyse in much the same way; and a"troublesome" subset of sentences which linguists canconcentrate heir debate on.One possible criticism of a lot of work in CorpusLinguistics, including the AMALGAM proposed work-plan, is that we restrict ourselves to variants of exist-ing tagging and parsing schemes which are specificallycrafted for Corpus annotation, but which are quite dif-ferent from grammar models being advocated and de-veloped by non-Corpus-based theoretical linguists, suchas GPSG or HPSG (see e.g.
\[27\]).
Unfortunately, weknow of no English corpus parsed according to sucha feature-based unification-oriented formalism, so onecannot readily be included in the AMALGAM project;however, we would like to hear from theoretical linguistswho we could collaborate with in extending the multi-parser to a unificational grammar formalism.
It is notclear that our multi-corpus will be a 'fair' benchmarkfor testing grammars and parsers from such widely-differing theories; it will be interesting to see whetherthe partition between "uncontentious" and "trouble-some" sentences i  also applicable in assessment of uni-ficational grammars.Another constraint of the AMALGAM project is thatwe are not considering Corpus-based semantic taggingschemes (e.g.
\[4O\], \[22\], \[21\]), only syntactic taggingschemes.
Again, it will be interesting to see whetherthe syntactically "troublesome" sentences are also se-mantically complex or anomalous; but this is a questionfor another, follow-up, project.Compar i son  o f  the  Mu l t i -T reebank  w i tho ther  parsed  corporaWe will compare the SEC data with other parsed texts(LOB, UPenn, POW,  Nijmegen, etc), to assess differ-ences in the range and frequency distributions of gram-matical constructs.
The SEC consists of transcriptsof scripted (and probably rehearsed) radio broadcasts.Some natural anguage researchers may feel that theSpoken English dataset is thus inappropriate for theirwork, since the grammars and parsers they are devel-oping are designed for a different type of language,for example, unrehearsed informal spoken dialogue asfound in the London-Lund Corpus and British Na-tional Corpus spoken section, or more formal published(written) text as found in the Brown and Lancaster-Oslo/Bergen Corpora.
It may be appropriate to aug-ment the SEC dataset with additional material fromalternative sources.
On the other hand, it may be thatthe main differences are in vocabulary rather than syn-tax, and that the coverage of the SEC, though not com-plete or perfect, is adequate for most applications.
Wcwill try to find empirical evidence for or against the ac-ceptability of 'scripted' Spoken English to the NL  com-mun ity.16Assessment  o f  Mu l tbTreebank  as aBenchmark  for ParsersThis will involve attempting toparse the SEC text withother parsers, available from a variety of sources.
Toavoid the need for intensive manual proofreading orchecking of results, a (semi-)antomatic assessment pro-cedure will be developed.Ant ic ipated  Resu l tsThe tangible 'deliverables' of use to the Speech andLanguage research community include:.
Final implementations of algorithms for mapping be-tween pairs of tagsets.
Final implementations of algorithms for mapping be-tween pairs of Treebanks?
Handbooks of common errors and corrections forpost-editing?
The Multi-Tagged Corpus.
The MultiTreebank?
Reports on the aboveThe mapping software, Multi-tagged Corpus andMultiTreebank (along with postediting handbooks anddocumentation) will be delivered to ICAME and Ox-ford Text Archive for public distribution; they willalso be available for incorporation i to the SEC SpeechDatabase.
Reports on the findings of the three stagesof investigations will be made widely available to all in-terested parties through SALT and ELSNET (UK andEuropean Networks of Excellence) and other channelsincluding conference presentations and journal papers.ApplicationsThe implemented mapping algorithms will be madewidely available to the UK and international speechand language research community.
They will allow re-search groups who are using corpus-based training datato make use of other corpora straightforwardly, withoutsubstantial modifications.
Any current and future usersof corpora will have a much expanded resource.The Multi-Tagged Corpus and the Multi-Treebankwill be distributed, along with the main Spoken EnglishCorpus, through ICAME.
They will also be available forincorporation i to the SEC Speech Database currentlybeing created by Gerry Knowles and Peter Roach, fur-ther enhancing the SEC as a general research resource.Both the Multi-Tr'eebank and the Multi-Tagged cor-pus will potentially be used by speech and languagetechnology groups for many research and teaching pur-poses, including: training data for speech-recognisers,optical text recognisers, word processor text-critiquingsystems, machine translation systems, natural languageinterfaces, and NLP applications generally; and for pro-viding examples for English Language Teaching (ELT)grammar textbooks and training material.
In addi-tion, the Multi-Treebank may be used as a testbed andbenchmark for parsers (explored in the workpla.).
Itwould also be a rich resource for grammar-learning ,,x-periments - a research topic of growing interest (see ,,.g.\[8\], \[11\], [16\], [33\]).We envisage supplying the computational linguisticsresearch community with a valuable research rcso,,rc,',and the ACL Workshop will be all invaluable ol?port,nity for us to survey potential customer require.w.tsand preferences!References\[1\] Eric Steven Atwell.
1982.
LOB Corpus 7'ag.qz,lgProject: Manual Post-edit Handbook.
Departmentsof Computer Studies and Linguistics, Lancaster Uni-versity.\[2\] Eric Atwell.
1983.
Constituent Likelihood Gram-mar.
In Journal of the International CompulerArchive of Modern English (1CAME Journal), No.
7,pages 34-66.
Norwegian Computing Centre for I.heHumanities, Bergen University\[3\] Eric Steven Atwell, Geoffrey Leech and Roger Car-side 1984.
Analysis of the LOB Corpus: progress aridprospects in Jan Aarts and Willem Meijs (ed), ('or-pus Linguistics: Proceedings of the ICAME ~th Inter-national Conference on the Use of Computer Corporain English Language Research pp40-52, Amsterdam:Rodopi.\[4\] Eric Steven Atwell.
1987.
A parsing expert systemwhich learns from corpus analysis.
In Willem Meijs,editor, Corpus Linguistics and Beyond: Proceediu.q~of the ICAME 7th International Conference, pages227-235.
Amsterdam, Rodopi.\[5\] Eric Steven Atwell and Nikos Drakos.
1987. l~attcrnRecognition Applied to the Acquisition of a Gram-matical Classification System from Unrestricted E,-glish Text.
In Bente Maegaard, editor, Proeeediuqs ofthe Third Conference of European Chapter of the A.~-sociation for Computational Linguistics, New Jersey,Association for Computational Linguistics.\[6\] Eric Steven Atwell.
1988.
Transforming a p~zrscdcorpus into a corpus parser.
In Merja Kyto, OssiIhalainen, and Matti Risanen, editors, Corpus Lin-guistics, Hard and Soft: Proceedings of the ICA ME8th International Conference, pages 61-70.
Amster-dam, ttodopi.\[7\] Eric Steven Atwell.
1988.
Grammatical nalysis ofenglish by statistical pattern recognition.
In .\]osefKittler, editor, Pattern Recognition: Proceedings ofthe 4th International Conference Cambridge, pages626-635.
Berlin, Springer-Verlag.\[8\] Eric Steven Atwell.
1992.
Overview of grammaracquisition research.
In Henry Thompson, editor,Workshop on sublanguage grammar and lexicon ac-quisition for speech and language: proceedings, pages65-70.
Human Communication l:tesearch Centre, Ed-inburgh University.17\[9\] Eric Steven Atwell.
1993.
Corpus-based statisticalmodelling of English grammar.
In Clive Souter andEric Atwell, editors, Corpus-Based ComputationalLi~,fluistics, pages 195-214.
Amsterdam, Rodopi.\[10\] Eric Steven Atwell.
1993.
Linguistic Constraintsfor Large-Vocabulary Speech Recognition In EricStcw:n Atwell (ed), h'nowledge at Work in, Univer-,~ilies: Proceedings of the second annual conferenceof the Higher Education Funding Councils' Knowl-cdgc Based Systems Initiative, pp26-32.
Leeds, LeedsI~ n iversity Press.\[11\] Eric Steven Atwell, Simon Arnfield, Georgel)~.metriou, Stephen Itanlon, John Hughes, Uwe Jost,I?ot> Pocock, Clive Souter, and Joerg Ueberla.
1993.Multi-level disambiguation grammar inferred fromI,:uglish corpus, treebank and dictionary.
In Proceed-ing.~ of the IEE Two One-Day Colloquia on Gram-mutical Infi:rence : Theory, Applications and Alter-oati~,cs, (Ref 1993/092).
London, Institution of Elec-i rical Engim~crs (lEE).\[12\] Ih~nk Barkema.
1994.
The TOSCA Analysis En-~,~ro~,mcnt for ICE.
Technical Report, Departmentof I,auguage and Speech, Katholieke Universiteit Ni-.imegen, The Netherlands.\[13\] Nancy Belmore.
1991.
Tagging Brown with theI,OB tagging suite.
In Journal of the InternationalUompnter Archive of Modern English (ICAME Jonr-,al).
No.
15, pages 63-86.
Norwegian ComputingCentre for the Humanities, Bergen University.\[14\] Eric Brill.
1991.
A Simple Rule-Based Part ofSpeech Tagger.
Technical Report: Department ofC.omputer Science, University of Pennsylvania.\[15\] Eric Brill and Mitchel Marcus.
1992.
Tagging anUnfamiliar Text with Minimal Human Supervision.In Robert Goldman, editor, Working notes of theA A AI ~hli Symposium on Probabilistic Approachesto Natural Language, AAAI Press.\[1{~\] Eric Brill, David Magerman, Mitchell Marcus,:~ml Beatrice Santorini.
1992.
Deducing LinguisticStructure from the Statistics of Large Corpora.
InCarl Weir and Ralph Grishman, editors, Proceedingsof AAAI-gP Workshop Program: Statistically.BasedNLP Techniques San Jose, California.\[I 7\] Gavin Burnage.
1990.
CELEX - A Guide for Users.N ij n wgen: Centre for Lexical Information (CELEX).\[18\] Lou Burnard.
1991.
What is the TEI?
In D. Green-stein, editor, Modelling Historical Data.
Goettingen:St. Katharinen.\[19\] K. Church.
1992.
Parts of Speech Tagging.
FifthAmm:d CUNY Conference on Human Science Pro-~:~.ssiwlg.\[211\] Aviv Cohen.
1994. personal communication.\[71\] (h'~rgc C. Demetriou and Eric Steven Atwell.199,1.
Machinc-Lc~irs~abic, Non-Compositional Se-maolic.~ fiJr Domain Independent Speech or TextRecognition to appear in Proceedings of 2nd Hellenic-European Conference on Mathematics and Informat-ies (HERMIS), Athens University of Economics andBusiness.\[22\] Elizabeth Eyes and Geoffrey Leech.
1993.
Progressin UCREL research: Improving corpus annotationpractices.
In Jan Aarts, Pieter de Haan, and NellekeOostdijk, editors, English Language Corpora: de-sign, analysis and exploitation; Proceedings of the13th ICAME conference, pages 123-144.
Amsterdam:Rodopi.\[23\] Robin Fawcett and Michael Perkins.
1980.
ChildLanguage Transcripts 6-12.
(With a preface, in J vol-umes).
Department of Behavioural and Communica-tion Studies, Polytechnic of Wales.\[24\] W.N.
Francis and H. Ku~era.
1979.
Manualof Information to Accompany a Standard Corpus ofPresent-Day Edited American English, for use withDigital Computers (Corrected and Revised edition).Department of Linguistics, Brown University, Provi-dence, Rhode Island.\[25\] Roger Garside, Geoffrey Leech, and GeoffreySampson (editors).
1987.
The Computational Analy-sis of English : A Corpus-Based Approach.
Longman,London and New York.\[26\] Roger Garside, Geoffrey Leech and Tam~ V~iradi.1990.
Manual of Information for the LancasterParsed Corpus.
Technical Report, Department ofLinguistics and Modern English, University of Lan-caster, UK.\[27\] Gerald Ga~dar and Chris Mellish.
1989.
NaturalLanguage Processing in POP-11 : An Introductionto Computational Linguistics.
Addison Wesley.\[28\] Sidney Greenbaum.
1993.
The Tagset for the In-ternational Corpus of English.
In Clive Souter andEric Atwell (eds.)
Corpus-based Computational Lin-guistics Amsterdam: Rodopi.\[29\] Robin Haigh, Geoffrey Sampson and Eric Atwell.1988.
Project APRIL - a progress report on the Leedsannealing parser project.
In Proceedings of the ~6thAnnual Meeting of the Association for Computa-tional Linguistics (ACL), pages 104-112.
New Jersey,Association for Computational Linguistics (ACL).\[30\] Robin Haigh.
1993. personal communication.\[31\] Hans van Halteren and Nelleke Oostdijk.
1993.Towards a syntactic database: the TOSCA anal-ysis system.
In Jan Aarts, Pieter de Haan, andNelleke Oostdijk, editors, English Language Corpora:design, analysis and exploitation; Proceedings of the13th ICAME conference, pages 145-162.
Amsterdam:Rodopi.\[32\] John Hughes.
1989.
A Learning Interface to theRealistic Annealing Parser.
Technical Report: Schoolof Computer Studies, The University of Leeds.18\[33\] John ltughes and Erie Steven Atwell.
1993. uto-matically acquiring and evaluating a classification ofwords In Proceedings of the IEE Two One-Day Col.loquia on Grammatical Inference : Theory, Applica-tions and Alternatives, (Ref 1993/092).
London, In-stitution of Electrical Engineers (IEE).\[34\] John Hughes.
1994.
Automatically Acquiring aClassification of Words.
PhD Thesis: School of Com-puter Studies, The University of Leeds.\[35\] John Hughes and Eric Steven Atwell.
1994.
AMethodical Approach to Word Class Formation Us-ing Automatic Evaluation.
In Lindsay Evett andTony Rose, editors, Proceedings of AISB workshopon Computational Linguistics for Speech and Hand-writing Recognition.
Leeds University.\[36\] John Hughes and Erie Steven Atwell.
1994.
TheAutomated Evaluation of Inferred Word Classifica-tions.
In Tony Cohn (ed), Proceedings of the 1I thEuropean Conference on Artificial Intelligence, Am-sterdam.\[37\] F. Jelinek.
1990.
Self-organised language modellingfor speech recognition.
In Alex Waibel and Kai-FuLee, editors, Readings in Speech Recognition, pages450-506.
Morgan Kaufmann.\[38\] Stig Johansson, Eric Atwell, Roger Garside andGeoffrey Leech.
1986.
The Tagged LOB Corpus-Users' Manual.
The Norwegian Centre for the Hu-manities, Bergen.\[39\] Stig Johansson.
1994. personal communication.\[40\] Uwe Jost and Eric Steven Atwell.
1993.
Deriving aprobabilistic grammar of semantic markers from un-restricted English text In Proceedings of the lEE TwoOne-Day Colloquia on Grammatical Inference : The-ory, Applications and Alternatives, (Ref 1993/0921.London, Institution of Electrical Engineers (lEE).\[41\] Judith Klavans.
1994. personal communication.\[42\] Geoffrey Leech, Roger Garside and Eric Atwell.1983.
The automatic grammatical tagging of theLOB Corpus.
In Journal of the International Com-puter Archive of Modern English (1CAME Journal),No.
7, pages 13-33.
Norwegian Computing Centre forthe Humanities, Bergen University.\[43\] Geoffrey Leech and Roger Garside.
1991.
Runninga grammar factory: The production of syntacticallyanalysed corpora or "treebanks".
In Stig Johanssonand Anna-Brits Stenstr6m, editors, English Com-puter Corpora: Selected Papers and Research Guide.Berlin: Mouten de Gruyter.\[44\] Geoffrey Leech.
1993.
100 Million Words of En-glish: The British National Corpus (BNC) Project.English Today.\[45\] Miteh P. Marcus and Beatrice Santorini.
1992.Building Very Large Natural Language Corpora: ThePenn Treebank.
In N. Ostler, editor, Proceedings ofthe 1992 Pisa Symposium on European Textual (:ol.-pora.06\] Nelleke Oostdijk.
1989.
TOSCA Corpus MaT~ual.University of Nijmegen.\[47\] Nelleke Oostdijk.
1991.
Corpus linguistic~ and theautomatic analysis of English.
Amst, erdam: I{,o,lopi.\[48\] Marian Owen.
1987.
Evaluating automatic gram-marital tagging of text.
In Newsletter of the Interna-tional Computer Archive of Modern English (ICAMENEWS), No.
11, pages 18-26.
Norwegian ComputingCentre for the Humanities, Bergen University.\[49\] Rob Pocock and Eric Atwell.
1993.
Extracting sta-tistical grammars from the Lancaster-IBM SpokenEnglish Corpus Treebank.
Technical Report 93.29,School of Computer Studies, Leeds University.\[50\] Rob Pocock and Eric Atwell.
1993.
Probabilis-tic grammatical models for treebank-trained latticedisambiguation.
Technical Report 93.30, School ofComputer Studies, Leeds University.\[51\] Paul Procter.
1978.
Longman Dictionary of Con-temporary English.
London: Longman.\[52\] Geoffrey Sampson.
1994.
"personal comnm,fi('a-tion".\[53\] Beatrice Santorini.
1990.
Part-of-speech ta!l.qingguidelines for the Penn treebank project.
Teclmi('alReport MS-CIS-90-47, Department ofComputer and?
Information Science, University of Pennsylvania.\[54\] John Sinclair.
1987.
'Looking Up: An Account ofthe COBUILD Project in Lexical Computing.
Collins,Glasgow.\[55\] Clive Souter.
1989.
A short handbook to the Pol.q-technic of Wales Corpus.
Bergen: Norwegian (',om-puting Centre for the Humanities, Bergen Uniw;rsity.\[56\] Clive Sourer.
1990.
Systemic functional grammarsand corpora.
In J. Aarts and W. Meijs, editors, The-ory and Practice in Corpus Linguistics, pages 179-211.
Amsterdam: Rodopi.\[57\] Clive Sourer and Eric Steven Atwell.
1992.
Arichly annotated corpus for probabilistic parsing.
InCarl Weir and Ralph Grishman, editors, Proceedingsof AAAI workshop on Statistically-Based NLP Tech-niques, San Jose, CA, pages 28-38.\[58\] Clive Souter.
1993.
Harmonising a lexical datal)a~sewith a corpus-based grammar.
In Souter andAtwell, editors, Corpus-based Computational Lin-guistics, pages 181-193.
Amsterdam: Rodopi.\[59\] Clive Souter.
1993.
Towards a standard format fi)rparsed corpora.
In Jan Aarts, Pieter de Iiaan, andNelleke Oostdijk, editors, English Language Corpora:design, analysis and exploitation; Proceedings of the13th ICAME conference, pages 197-214.
Amsterdam:Rodopi.19\[(10\] Clive Souter and Eric Steven Atwell.
1994.
Us-ing Parsed Corpora: A review of current practice InN~lleke Oostdijk and Pieter de Haan (eds), Corpus-based Research Into Language, pp143-158.
Amster-dam,  l'~odopi.\[(;1\] C. Sperberg-McQueen and L. Burnard.
1990.Guidelines for the encoding and interchange ofmachine-readable t zts, TEI P1, Technical report,\[l n iversities of Chicago and Oxford.\[62\] Jan Svartvik (ed).
1990.
The London-Lund Corpusof Spoken English: Description and Research.
LundUniversity Press, Lund, Sweden.\[(i:~\] L.J.
Taylor and G. Knowles.
1988.
Manual of In-formation to Accompany the SEC Corpus.
TechnicalReport, Unit for Computer Research on the Englishl,anguage,University of Lancaster, UK.\[(il\] Ni Yihin 1993.
The ICE Tagset - A Complete Listof Tags used by the Tag-Selector for the Reference,~f Tag.Selectors and Researchers.
Technical Report,I)epartment of English, University College London,UK.20
