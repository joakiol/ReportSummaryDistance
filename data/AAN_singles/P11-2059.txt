Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 341?345,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsLanguage Use: What can it Tell us?
[name][address1][address2][address3][email][name][address1][address2][address3][email][name][address1][address2][address3][email]AbstractFor 20 years, information extraction has fo-cused on facts expressed in text.
In contrast,this paper is a snapshot of research in progresson inferring properties and relationshipsamong participants in dialogs, even thoughthese properties/relationships need not be ex-pressed as facts.
For instance, can a machinedetect that someone is attempting to persuadeanother to action or to change beliefs or is as-serting their credibility?
We report results onboth English and Arabic discussion forums.1 IntroductionExtracting explicitly stated information has beentested in MUC1 and ACE2 evaluations.
For exam-ple, for the text Mushaima'a, head of the opposi-tion Haq movement, an ACE system extracts therelation LeaderOf(Mushaima'a, HaqMovement).
InTREC QA3 systems answered questions, e.g.
?When was Mozart born?
?, for which the answer iscontained in one or a few extracted text phrases.Sentiment analysis uses implicit meaning oftext, but has focused primarily on text known to berich in opinions (product reviews, editorials) anddelves into only one aspect of implicit meaning.Our long-term goal is to predict social roles ininformal group discussion from language uses(LU), even if those roles are not explicitly stated;for example, using the communication during ameeting, identify the leader of a group.
This paperprovides a snapshot of preliminary, ongoing re-search in predicting two classes of language use:1http://www-nlpir.nist.gov/related_projects/muc/2http://www.nist.gov/speech/tests/ace/3http://trec.nist.gov/data/qa.htmlEstablish-Credibility and Attempt-To-Persuade.Technical challenges include dealing with the factsthat those LUs are rare and subjective and that hu-man judgments have low agreement.Our hybrid statistical & rule-based approachdetects those two LUs in English and Arabic.
Ourresults are that (1) annotation at the message (turn)level provides training data useful for predictingrare phenomena at the discussion level while re-ducing the requirement for turn-level predictions tobe accurate; (2)weighing subjective judgmentsovercomes the need for high annotator consistency.Because the phenomena are rare, always predictingthe absence of a LU is a very high baseline.
ForEnglish, the system beats those baselines.
For Ara-bic, more work is required, since only 10-20% ofthe amount of training data exists so far.2 Language Uses (LUs)A language use refers to an aspect of the socialintention of how a communicator uses language.The information that supports a decision about animplicit social action or role is likely to be distrib-uted over more than one turn in a dialog; therefore,a language use is defined, annotated, and predictedacross a thread in the dialog.
Because our currentwork uses discussion forums, threads provide anatural, explicit unit of analysis.
Our current workstudies two language uses.An Attempt-to-Persuade occurs when a postertries to convince other participants to change theirbeliefs or actions over the course of a thread.
Typi-cally, there is at least some resistance on the part ofthe posters being persuaded.
To distinguish be-tween actual persuasion and discussions that in-volve differing opinions, a poster needs to engage341in multiple persuasion posts (turns) to be consid-ered exhibiting the LU.Establish-Credibility occurs when a poster at-tempts to increase their standing within the group.This can be evidenced with any of several moves,e.g., explicit statements of authority, demonstrationexpertise through knowledge, providing verifiableinformation (e.g., from a trusted source or citingconfirmable facts), or providing a justified opinion(e.g., a logical argument or personal experience).3 ChallengesThere were two significant challenges: (a) sparsityof the LUs, and (b) inter-annotator agreement.
Toaddress the sparsity of data, we tried to automati-cally select data that was likely to contain contentof interest.
Data selection focused on the numberof messages and posters in a thread, as well as thefrequency of known indicators like quotations.(withheld).
Despite these efforts, the LUs of inter-est were rare, especially in Arabic.Annotation was developed using cycles ofguideline development, annotation, evaluation ofagreement, and revision of guidelines.
Elsewhere,similar, iterative annotation processes have yieldedsignificant improvements in agreement for wordsense and coreference (Hovy et al, 2006).
WhileLUs were annotated for a poster over the fullthread, annotators also marked specific messagesin the thread for presence of evidence of the lan-guage use.
Table 1 includes annotator consistencyat both the evidence (message) and LU level.English ArabicMsg LU Msg LUAgr # Agr # Agr # Agr #Per.
0.68 4722 0.75 2151 0.57 652 0.49 360Cred.
0.66 3594 0.68 1609 0.35 652 0.45 360Table 1: Number of Annotated Data Units and Annota-tor Agreement (measured as F)The consistency numbers for this task were sig-nificantly lower than we have seen in other lan-guage processing tasks.
Discussions suggested thatdisagreement did not come from a misunderstand-ing of the task but was the result of differing intui-tions about difficult-to-define labels.
In thefollowing two sections, we describe how the eval-uation framework and system development pro-ceeded despite low levels of consistency.4 Evaluation FrameworkTask.
The task is to predict for every participant ina given thread, whether the participant exhibitsAttempt-to-Persuade and/or Establish-Credibility.If there is insufficient evidence of an LU for a par-ticipant, then the LU value for that poster is nega-tive.
The external evaluation measured LUpredictions.
Internally we measured predictions ofmessage-level evidence as well.Corpora.
For English, 139 threads fromGoogle Groups and LiveJournal have been anno-tated for Attempt-to-Persuade, and 103 threads forAttempt-to-Establish-Credibility.
For Arabic,threads were collected from al-handasa.net.4 31threads were annotated for both tasks.
Counts ofannotated messages appear in Table 1.Measures.
Due to low annotator agreement, at-tempting to resolve annotation disagreement by thestandard adjudication process was too time-consuming.
Instead, the evaluation scheme, similarto the pyramid scheme used for summarizationevaluation, assigns scores to each example basedon its level of agreement among the annotators.Specifically, each example is assigned positive andnegative scores, p = n+/N and n = n-/N, where n+ isthe number of annotators that annotate the exampleas positive, and n- for the negative.
N is the totalnumber of annotators.
A system that outputs posi-tive on the example results in p correct and n incor-rect.
The system gets p incorrect and n correct forpredicting negative.
Partial accuracy and F-measure can then be computed.Formally, let X = {xi} be a set of examples.Each example xi is associated with positive andnegative scores, pi and ni.
Let ri = 1 if the systemoutputs positive for example xi and 0 for negative.The partial accuracy, recall, precision, and F-measure can be computed by:pA = 100?
?i(ripi+(1-ri)ni) / ?i(pi+ni)pR = 100?
?iripi / ?ipipP = 100?
?iripi / ?iripF = 2 pR pP/(pR+pP)The maximum pA and pF may be less than 100when there is disagreement between annotators.
Toachieve accuracy and F scores on a scale of 100,pA and pF are normalized using the maximumachievable scores with respect to the data.npA = 100?pA/max(pA)npF = 100?pF/max(pF)4URLs and judgments are available by email.3425 System and Empirical ResultsOur architecture is shown in Figure 1.
We processa thread in three stages: (1) linguistic analysis ofeach message (post) to yield features, (2) Predic-tion of message-level properties using an SVM onthe extracted features, and (3) Simple rules thatpredict language uses over the thread.Figure 1: Message and LU PredictionPhase 1: The SERIF Information ExtractionEngine extracts features which are designed to cap-ture different aspects of the posts.
The features in-clude simple features that can be extracted fromthe surface text of the posts and the structure of theposts within the threads.
These may correlate di-rectly or indirectly correlate to the language uses.In addition, more syntactic and semantic-drivenfeatures are also used.
These can indicate the spe-cific purpose of the sentences; specifically target-ing directives, imperatives, or shows authority.
Thefollowing is a partial list of features which are usedboth in isolation and in combination with each oth-er.Surface and structural features: average sen-tence length; number of names, pronouns, and dis-tinct entities; number of sentences, URLs (links),paragraphs and out-of-vocabulary words; specialstyles (bold, italics, stereotypical punctuation e.g.!!!!
), depth in thread, and presence of a quotation.Syntactic and semantic features: predicate-argument structure including the main verb, sub-ject, object, indirect object, adverbial modifier,modal modifier, and negation, imperative verbs,injection words, subjective words, and mentions ofattack events.Phase 2: Given training data from the messagelevel (Section 3), an SVM predicts if the post con-tains evidence for an LU.
The motivation for thislevel is (1) Posts provide a compact unit with reli-ably extractable, specific, explicit features.
(2)There is more training data at the post level.
(3)Pointing to posts offers a more clear justificationfor the predictions.
(4) In our experiments, errorshere do not seem to percolate to the thread level.
Infact, accuracy at the message level is not directlypredictive of accuracy at the thread level.Phase 3: Given the infrequency of the Attempt-to-Persuade and Establish-Credibility LUs, wewrote a few rules to predict LUs over threads, giv-en the predictions at the message level.
For in-stance, if the number of messages with evidencefor persuasion is greater than 2 from a given partic-ipant, then the system predicts AttemptToPer-suade.
Phase 3 is by design somewhat robust toerrors in Phase 2.
To predict that a poster is exhib-iting the Attempt-to-Persuade LU, the system neednot find every piece of evidence that the LU is pre-sent, but rather just needs to find sufficient evi-dence for identifying the LU.Our message level classifiers were trained withan SVM that optimizes F-measure (Joachims,2005).
Because annotation disagreement is a majorchallenge, we experimented with various ways toaccount for (and make use of) noisy, dual annotat-ed text.
Initially, we resolved the disagreement au-tomatically, i.e.
removing examples withdisagreement; treating an example as negative ifany annotator marked the example negative; andtreating an example as positive if any annotatormarked the example as positive.
An alternative(and more principled) approach is to incorporatepositive and negative scores for each example intothe optimization procedure.
Because each examplewas annotated by the same number of annotators (2in this case), we are able to treat each annotator?sdecision as an independent example without aug-menting the SVM optimization process.The results below use the training procedurethat performed best on the leave-one-thread-outcross validation results (Table 23 and Table 34).Counts of threads appear in Section 4.
We compareour system?s performance (S) with two simplebaselines.
Baseline-A (A) always predicts absentfor the LU/evidence.
Baseline-P (P) predicts posi-tive (present) for all messages/LUs.
Table 4Table 3shows results for predicting message level evi-dence of an LU (Phase 2).
Table 5Table 4 showsperformance on the task of predicting an LU foreach poster.The results show significantly worse perfor-mance in Arabic than English-- not surprising con-sidering 5-10-fold difference in training examples.Additionally, Arabic messages are much shorter,and the phenomena is even more rare (as illustratedby the high npA, accuracy, of the A baseline).343Persuade Establish CredibilitynpA npF npA npFEn Ar En Ar En Ar En ArA 72.5 83.2 0.0 0.0 77.6 95.0 0.0 0.0P 40.4 29.7 61.1 50.7 33.9 14.4 54.5 30.9S 86.5 81.3 79.2 61.9 86.7 95.5 73.9 54.0Table 43: Performance on Message Level EvidencePersuade Establish CredibilitynpA npF npA npFEn Ar En Ar En Ar En ArA 90.9 86.7 0.0 0.0 87.7 90.2 0.0 0.0P 12.1 27.0 23.8 48.2 18.0 21.5 33.7 41.1S 94.6 88.3 76.8 38.8 95.1 92.4 80.0 36.0Table 54: Cross Validation Performance on Poster LUsTable 6Table 5 shows LU prediction resultsfrom an external evaluation on held out data.
Un-like our dataset, each example in the external eval-uation dataset was annotated by 3 annotators.
Theresults are similar to our internal experiment.Persuade Establish CredibilitynpA npF npA npFEn Ar En Ar En Ar En ArA 96.2 98.4 0.0 0.0 93.6 94.0 93.6 0.0P 13.1 4.2 27.6 11.7 11.1 10.1 11.1 22.2S 96.5 94.6 75.1 59.1 97.7 92.5 97.7 24.7Table 65: External, Held-Out Results on Poster LUs6 Related ResearchResearch in authorship profiling (Chung & Penne-baker, 2007; Argamon et al in press; and Abbasiand Chen, 2005) has identified traits, such as sta-tus, sex, age, gender, and native language.
Modelsand predictions in this field have primarily usedsimple word-based features, e.g.
occurrence andfrequency of function words.Social science researchers have studied how so-cial roles develop in online communities (Fisher, etal., 2006), and have attempted to categorize theseroles in multiple ways (Golder and Donath 2004;Turner et al, 2005).
Welser et al (2007) have in-vestigated the feasibility of detecting such rolesautomatically using posting frequency (but not thecontent of the messages).Sentiment analysis requires understanding theimplicit nature of the text.
Work on perspectiveand sentiment analysis frequently uses a corpusknown to be rich in sentiment such as reviews oreditorials (e.g.
(Hardisty, 2010), (Somasundaran&Weibe, 2009).
The MPQA corpus (Weibe, 2005)annotates polarity for sentences in newswire, butthe focus of this corpus is at the sentence level.Both the MPQA corpus and the various corpora ofeditorials and reviews have tended towards moreformal, edited, non-conversational text.
Our workin contrast, specifically targets interactive discus-sions in an informal setting.
Work outside of com-putational linguistics that has looked at persuasionhas tended to examine language in a persuasivecontext (e.g.
sales, advertising, or negotiations).Like the current work, Strzalkowski, et al(2010) investigates language uses over informaldialogue.
Their work focuses on chat transcripts inan experimental setting designed to be rich in thephenomena of interest.
Like our work, their predic-tions operate over the conversation, and not a sin-gle utterance.
The specific language uses in theirwork (topic/task control, involvement, and disa-greement) are different than those discussed here.Our work also differs in the data type of interest.We work with threaded online discussions inwhich the phenomena in question are rare.
Ourannotators and system must distinguish betweenthe language use and text that is opinionated with-out an intention to persuade or establish credibility.7 Conclusions and Future WorkIn this work in progress, we presented a hybridstatistical & rule-based approach to detecting prop-erties not explicitly stated, but evident from lan-guage use.
Annotation at the message (turn) levelprovided training data useful for predicting rarephenomena at the discussion level while reducingthe need for turn-level predictions to be accurate.Weighing subjective judgments overcame the needfor high annotator consistency.
For English, thesystem beats both baselines with respect to accura-cy and F, despite the fact that because the phenom-ena are rare, always predicting the absence of alanguage use is a high baseline.
For Arabic, morework is required, particularly since only 10-20% ofthe amount of training data exists so far.This work has explored LUs, the implicit, socialpurpose behind the words of a message.
Futurework will explore incorporating LU predictions topredict the social roles played by the participants ina thread, for example using persuasion and credi-bility to establish which participants in a discus-sion are serving as informal leaders.344AcknowledgementThis research was funded by the Office of the Directorof National Intelligence (ODNI), Intelligence AdvancedResearch Projects Activity (IARPA), through the _____.All statements of fact, opinion or conclusions containedherein are those of the authors and should not be con-strued as representing the official views or policies ofIARPA, the ODNI or the U.S. Government.ReferencesArgamon, S., Koppel, M., Pennebaker, J.W., and Schler,J.
(2009).
?Automatically profiling the author ofan anonymous text?.
Communications of the Asso-ciation for Computing Machinery (CACM).
Vol-ume 52 Issue 2.Abbasi A., and Chen H. (2005).
?Applying authorshipanalysis to extremist-group web forum messages?.In IEEE Intelligent Systems, 20(5), pp.
67?75.Boyd, D, Golder, S, and Lotan, G. (2010).
?Tweet,Tweet, Retweet: Conversational Aspects of Re-tweeting on Twitter.?
HICSS-43.
IEEE: Kauai, HI.Chung, C.K., and Pennebaker, J.W.
(2007).
?The psy-chological functions of function words?.
In K.Fiedler (Ed.
), Social communication, pp.
343-359.New York: Psychology Press.Golder S., and Donath J.
(2004) "Social Roles in Elec-tronic Communities," presented at the Associationof Internet Researchers (AoIR).
Brighton, EnglandHovy E., Marcus M., Palmer M., Ramshaw L., andWeischedel R. (2006).
?Ontonotes: The 90% solu-tion?.
In Proceedings of the Human LanguageTechnology Conference of the NAACL, Compan-ion Volume: Short Papers, pp.
57?60.
Associationfor Computational Linguistics, New York City,USA.Joachims, T. (2005), ?A Support Vector Method forMultivariate Performance Measures?, Proceedingsof the International Conference on MachineLearning (ICML).Kelly, J., Fisher, D., Smith, D., (2006) ?Friends, foes,and fringe: norms and structure in political discus-sion networks?, Proceedings of the 2006 interna-tional conference on Digital government research.NIST Speech Group.
(2008).
?The ACE 2008 evalua-tion plan: Assessment of Detection and Recogni-tion of Entities and Relations Within and AcrossDocuments?.http://www.nist.gov/speech/tests/ace/2008/doc/ace08 -evalplan.v1.2d.pdfRanganath, R., Jurafsky, D., and McFarland, D. (2009)?It?s Not You, it?s Me: Detecting Flirting and itsMisperception in Speed-Dates?
Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 334?342.Somasundaran, S & Wiebe, J(2009).
RecognizingStances in Online Debates.
ACL-IJCNLP 2009.Strzalkowski, T, Broadwell, G, Stromer-Galley, J,Shaikh, S, Taylor, S and Webb, N. (2010) ?Model-ing Socio-Cultural Phenomena in Discourse?.Proceedings of the 23rd International Conferenceon Computational Linguistics (Coling 2010), pag-es 1038?1046, Beijing, August 2010Turner T. C., Smith M. A., Fisher D., and Welser H. T.(2005) ?Picturing Usenet: Mapping computer-mediated collective action?.
In Journal of Com-puter-Mediated Communication, 10(4).Voorhees, E. & Tice, D.
(2000).
"Building a QuestionAnswering Test Collection", Proceedings ofSIGIR, pp.
200-207.Welser H. T., Gleave E., Fisher D., and Smith M.,(2007).
"Visualizing the signatures of social roles inonline discussion groups," In The Journal of SocialStructure, vol.
8, no.
2.Wiebe, J, Wilson, T and Cardie, C (2005).
Annotatingexpressions of opinions and emotions in language.Language Resources and Evaluation, volume 39, is-sue 2-3, pp.
165-210.345
