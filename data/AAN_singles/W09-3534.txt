Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 161?167,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPAnalysis and Robust Extraction of Changing Named EntitiesMasatoshi Tsuchiya?
Shoko Endo?
Seiichi Nakagawa?
?Information and Media Center / ?Department of Information and Computer Sciences,Toyohashi University of Technologytsuchiya@imc.tut.ac.jp, {shoko,nakagawa}@slp.ics.tut.ac.jpAbstractThis paper focuses on the change of namedentities over time and its influence on theperformance of the named entity tagger.First, we analyze Japanese named enti-ties which appear in Mainichi Newspaperarticles published in 1995, 1996, 1997,1998 and 2005.
This analysis reveals thatthe number of named entity types andthe number of named entity tokens arealmost steady over time and that 70 ?80% of named entity types in a certainyear occur in the articles published eitherin its succeeding year or in its precedingyear.
These facts lead that 20 ?
30%of named entity types are replaced withnew ones every year.
The experimentagainst these texts shows that our propos-ing semi-supervised method which com-bines a small annotated corpus and a largeunannotated corpus for training works ro-bustly although the traditional supervisedmethod is fragile against the change ofname entity distribution.1 IntroductionIt is widely agreed that extraction of named entity(henceforth, denoted as NE) is an important sub-task for various NLP applications, such as infor-mation retrieval, machine translation, informationextraction and natural language understanding.Several conferences like Message UnderstandingConference(Grishman and Sundheim, 1996) andthe IREX workshop (Sekine and Eriguchi, 2000)were conducted to encourage researchers of NEextraction and to provide its common evaluationbasis.In Japanese NE extraction, it is quite commonto apply morphological analysis as preprocessingstage which segments a sentence into a sequenceof morphemes.
After that, either a pattern matcherbased on hand-crafted rules or a statistical chun-ker is employed to extract NEs from a sequence ofmorphemes.
Various machine learning approachessuch as maximum entropy(Uchimoto et al, 2000),decision list(Sassano and Utsuro, 2000; Isozaki,2001), and Support Vector Machine(Yamada etal., 2002; Isozaki and Kazawa, 2002) were in-vestigated for extracting NEs.
These researchesshow that machine learning approaches are morepromising than approaches based on hand-craftedrules if a large corpus whose NEs are properly an-notated is available as training data.However, it is difficult to obtain an enough cor-pus in the real world because of the increasingnumber of NE types and the increasing time gapbetween the training corpus and the test corpus.There is the increasing number of NE types likepersonal names and company names in the realworld.
For example, a large database of organi-zation names(Nichigai Associates, 2007) alreadycontains 171,708 types and is still increasing.
Be-cause annotation work is quite expensive, the an-notated corpus may become obsolete in a shortperiod of time.
Both of two factors expands thedifference of NE distribution between the trainingcorpus and the test corpus, and it may decrease theperformance of the NE tagger as shown in (Motaand Grishman, 2008).
Therefore, a robust methodto extract NEs which do not occur or occur fewtimes in a training corpus is necessary.This paper focuses on the change of NEs overtime and its influence on the performance of theNE tagger.
First, we annotate NEs in MainichiNewspaper articles published in 1996, 1997, 1998and 2005, and analyze NEs which appear inthese texts and an existing corpus.
It consists ofMainichi Newspaper articles published in 1995,thus, we get an annotated corpus that spans 10years.
This analysis reveals that the number ofNE types and the number of NE tokens are almost161Table 1: Statistics of NE categories of IREX cor-pusNE Categories Frequency (%)ARTIFACT 747 (4.0)DATE 3567 (19.1)LOCATION 5463 (29.2)MONEY 390 (2.1)ORGANIZATION 3676 (19.7)PERCENT 492 (2.6)PERSON 3840 (20.6)TIME 502 (2.7)Total 18677steady over time and that that 70 ?
80% of NEtypes in a certain year occur in the articles pub-lished either in its succeeding year or in its preced-ing year.
These facts lead that 20 ?
30% of namedentity types are replaced with new ones every year.The experiment against these corpora shows thatthe traditional supervised method is fragile againstthe change of NE types and that our proposingsemi-supervised method which combines a smallannotated corpus and a large unannotated corpusfor training is robust against the change of NEtypes.2 Analysis of Changing Named Entities2.1 Task of the IREX WorkshopThe task of NE extraction of the IREX work-shop (Sekine and Eriguchi, 2000) is to recognizeeight NE categories in Table 1.
The organizerof the IREX workshop provided a training corpus(henceforth, denoted as IREX corpus), which con-sists of 1,174 Mainichi Newspaper articles pub-lished from January 1st 1995 to 10th which in-clude 18,677 NEs.
In the Japanese language, noother corpora whose NEs are annotated are pub-licly available as far as we know.1 Thus, IREXcorpus is referred as a golden sample of NE distri-bution in this paper.2.2 Data DescriptionThe most homogeneous texts which are written indifferent days are desirable, to explore the influ-ence of the text time frame on NE distribution.
Be-cause IREX corpus is referred as a golden sample1The organizer of the IREX workshop also provides thetesting data to its participants, however, we cannot see it be-cause we did not join it.???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?Figure 1: Distribution of NE categories????????????????????
??
??
?
?
?
?
?????????????????????????????????????????????????????????????????????????????????????
?Figure 2: Overlap ratio of NEs over yearsin this paper, Mainichi Newspaper articles writ-ten in different years than IREX corpus is suit-able.
Thus, ordinal days of June and October in1996, 1997, 1998 and 2005 are randomly selectedas sampling days.Because annotating work is too expensive forus to annotate all articles published in samplingdays, thirty percent of them are only annotated.Each article of Mainichi Newspaper belongs into16 categories like front page articles, internationalstories, economical stories, political stories, edito-rial columns, and human interest stories.
Becausethese categories may influence to NE distribution,it is important to keep the proportion of categoriesin the sampled texts to the proportion in the wholenewspaper, in order to investigate NE distributionover the whole newspaper.
Therefore, thirty per-cent articles of each category published at sam-pling days are randomly selected and annotated inaccordance with the IREX regulation.2.3 Analysis of Annotated SamplesTable 2 shows the statistics of our annotated cor-pus.
The leftmost column of Table 2 (whose pub-162Table 2: Statistics of sampling textsPublished date 1995 1996 1997 1998 2005Jan.
1?10 Jun.
5 Oct. 15 Jun.
10 Oct. 7 Jun.
8 Oct. 21 Jun.
23 Oct. 12# of articles 1174 120 133 106 117 96 126 90 99# of characters 407881 60790 53625 46653 50362 51006 67744 49038 44344# of NE types 6979 1446 1656 1276 1350 1190 1226 1230 1113# of NE tokens 18677 2519 2652 2145 2403 2126 2052 1902 2007# of NE types / # of characters 0.0171 0.0238 0.0309 0.0274 0.0268 0.0233 0.0181 0.0251 0.0251# of NE tokens / # of characters 0.0458 0.0414 0.0495 0.0460 0.0477 0.0417 0.0303 0.0388 0.0453Table 3: Overlap of NE types between texts published in different yearsPublished date of Published year of unannotated corpus Uannotated corpus A 1993 1994 1995 1996 1997 1998 1999Jan.
1?10 (1995) 73.2% 78.6% ?
74.4% 65.0% 64.4% 63.3%Jun.
6, Oct. 15 (1996) 67.2% 71.7% 72.2% ?
77.3% 76.0% 75.1%Jun.
6, Oct. 7 (1997) 71.2% 73.4% 74.4% 78.6% ?
80.8% 78.6%Jun.
8, Oct. 21 (1998) 72.5% 74.6% 76.2% 79.7% 82.7% ?
84.0%Jun.
23, Oct. 12 (2005) 62.3% 64.1% 66.8% 68.7% 71.2% 72.9% 73.8%lish date is January 1st to 10th in 1995) is corre-sponding to IREX corpus, and other columns arecorresponding to articles annotated by ourselves.Table 2 illustrates that the normalized number ofNE types and the normalized number of NE tokensare almost steady over time.
Figure 1 shows thedistributions of NE categories for sampling textsand that there is no significant difference betweenthem.We also investigate the relation of the time gapbetween texts and NE types which appear in thesetexts.
The overlap ratio of NE types between theannotated corpus A published in the year YA andthe annotated corpus B published in the year YBwas defined in (Mota and Grishman, 2008) as fol-lowstype overlap(A,B) = |TA ?
TB||TA|+ |TB| ?
|TA ?
TB|,where TA and TB are lists of NE types which ap-pear in A and B respectively.
However, it is im-possible to compute reliable type overlap in ourresearch because enough annotated texts are un-available.
As an alternative of type overlap, theoverlap ratio of NE types between the annotatedcorpus A and the unannotated corpus U publishedin the year YU is defined as followsstring overlap(A,U) =?s?TA ?
(s, U)|TA|,where ?
(s, U) is the binary function to indicatewhether the string s occurs in the string U or not.Table 3 shows string ratio values of annotatedtexts.
It shows that 70 ?
80% of TA appear in thepreceding year of YA, and that 70 ?
80% of TAappear in the succeeding year of YA.Figure 2 shows the relation between the timegap YU ?
YA and string ratio(A,U).
Sup-pose that all NEs are independent and equiv-alent on their occurrence probability and thatstring ratio(A,U) is equal to 0.8 when the timegap YU ?
YA is equal to one.
When the time gapYU ?
?
YA is equal to two years, although this as-sumption leads that string ratio(A,U ?)
will beequal to 0.64, string ratio(A,U ?)
in Figure 2 isgreater than 0.7.
This suggests that NEs are notequivalent on their occurrence probability.
Andmore, Table 4 shows that the longer time spanof the annotated text increases the number of NEtypes.
These facts lead that some NEs are short-lived and superseded by other new NEs.3 Robust Extraction of Changing NamedEntitiesIt is infeasible to prepare a large annotated cor-pus which covers all increasing NEs.
A semi-supervised learning approach which combines asmall annotated corpus and a large unannotatedcorpus for training is promising to cope this prob-lem.
(Miller et al, 2004) proposed the methodusing classes which are assigned to words basedon the class language model built from a largeunannotated corpus.
(Ando and Zhang, 2005) pro-163Table 4: Number of NE types and Time Span of Annotated Text1995 1995?1996 1995?1997 1995?1998 1995?2005ARTIFACT 541 (1.00) 743 (1.37) 862 (1.59) 1025 (1.89) 1169 (2.16)DATE 950 (1.00) 1147 (1.21) 1326 (1.40) 1461 (1.54) 1583 (1.67)LOCATION 1403 (1.00) 1914 (1.36) 2214 (1.58) 2495 (1.78) 2692 (1.92)MONEY 301 (1.00) 492 (1.63) 570 (1.89) 656 (2.18) 749 (2.49)ORGANIZATION 1487 (1.00) 1890 (1.27) 2280 (1.53) 2566 (1.73) 2893 (1.95)PERCENT 249 (1.00) 319 (1.28) 353 (1.42) 401 (1.61) 443 (1.78)PERSON 1842 (1.00) 2540 (1.38) 3175 (1.72) 3683 (2.00) 4243 (2.30)TIME 206 (1.00) 257 (1.25) 291 (1.41) 314 (1.52) 332 (1.61)Total 6979 (1.00) 9302 (1.33) 11071 (1.59) 12601 (1.81) 14104 (2.02)(Values in brackets are rates of increase comparing to 1995.
)Morpheme Feature Similar Morpheme Feature Character(English POS (English POS Type Chunk Labeltranslation) translation) Feature??
(kyou) (today) Noun?Adverbial ??
(kyou) (today) Noun?Adverbial ?1, 0, 0, 0, 0, 0?
O?
(no) gen Particle ?
(no) gen Particle ?0, 1, 0, 0, 0, 0?
O??
(Ishikari) (Ishikari) Noun?Proper ??
(Kantou) (Kantou) Noun?Proper ?1, 0, 0, 0, 0, 0?
B-LOCATION??
(heiya) (plain) Noun?Generic ??
(heiya) (plain) Noun?Generic ?1, 0, 0, 0, 0, 0?
I-LOCATION?
(no) gen Particle ?
(no) gen Particle ?0, 1, 0, 0, 0, 0?
O??
(tenki) (weather) Noun?Generic ??
(tenki) (weather) Noun?Generic ?1, 0, 0, 0, 0, 0?
O?
(ha) top Particle ?
(ha) top Particle ?0, 1, 0, 0, 0, 0?
O??
(hare) (fine) Noun?Generic ??
(hare) (fine) Noun?Generic ?1, 1, 0, 0, 0, 0?
OFigure 3: Example of Training Instance for Proposed Methodposed the method using thousands of automati-cally generated auxiliary classification problemson an unannotated corpus.
(?)
proposed the semi-supervised discriminative model whose potentialfunction can treat both an annotated corpus and anunannotated corpus.In this paper, the method proposed by (Tsuchiyaet al, 2008) is employed, because its implementa-tion is quite easy.
It consists of two steps.
Thefirst step is to assign the most similar and famil-iar morpheme to each unfamiliar morpheme basedon their context vectors calculated from a largeunannotated corpus.
The second step is to employConditional Random Fields(CRF)2(Lafferty et al,2001) using both features of original morphemesand features of similar morphemes.This section gives the detail of this method.3.1 Chunking of Named EntitiesIt is quite common that the task of extractingJapanese NEs from a sentence is formalized asa chunking problem against a sequence of mor-phemes.
For representing proper chunks, we em-ploy IOB2 representation, one of representationswhich have been studied well in various chunking2http://chasen.org/?taku/software/CRF++/tasks of NLP (Tjong Kim Sang, 1999).
This rep-resentation uses the following three labels.B Current token is the beginning of a chunk.I Current token is a middle or the end of achunk consisting of more than one token.O Current token is outside of any chunk.Actually, we prepare the 16 derived labels fromthe label B and the label I for eight NE categories,in order to distinguish them.When the task of extracting Japanese NEs froma sentence is formalized as a chunking problemof a sequence of morphemes, the segmentationboundary problem arises as widely known.
Forexample, the NE definition of IREX tells that aChinese character ??
(bei)?
must be extracted asan NE means America from a morpheme ???(hou-bei)?
which means visiting America.
A naivechunker using a morpheme as a chunking unit can-not extract such a kind of NEs.
In order to copethis problem, (Uchimoto et al, 2000) proposedemploying translation rules to modify problematicmorphemes, and (Asahara and Matsumoto, 2003;Nakano and Hirai, 2004) formalized the task of ex-tracting NEs as a chunking problem of a sequenceof characters instead of a sequence of morphemes.In this paper, we keep the naive formalization, be-cause it is still enough to analyze the influence of164the text time frame.3.2 Assignment of Similar MorphemeA context vector Vm of a morpheme m is a vectorconsisting of frequencies of all possible unigramsand bigrams,Vm =????
?f(m,m0), ?
?
?
f(m,mN ),f(m,m0,m0), ?
?
?
f(m,mN ,mN ),f(m0,m), ?
?
?
f(mN ,m),f(m0,m0,m), ?
?
?
f(mN ,mN ,m)????
?,where M ?
{m0,m1, .
.
.
,mN} is a set of allmorphemes of the unannotated corpus, f(mi,mj)is a frequency that a sequence of a morpheme miand a morpheme mj occurs in the unannotatedcorpus, and f(mi,mj ,mk) is a frequency that asequence of morphemes mi,mj and mk occurs inthe unannotated corpus.Suppose an unfamiliar morpheme mu ?
M ?MF , where MF is a set of familiar morphemesthat occur frequently in the annotated corpus.
Themost similar morpheme m?u to the morpheme mumeasured with their context vectors is given by thefollowing equation,m?u = argmaxm?MFsim(Vmu , Vm), (1)where sim(Vi, Vj) is a similarity function betweencontext vectors.
In this paper, the cosine functionis employed as it.3.3 FeaturesThe feature set Fi at i-th position is defined asa tuple of the morpheme feature MF (mi) of thei-th morpheme mi, the similar morpheme featureSF (mi), and the character type feature CF (mi).Fi = ?
MF (mi), SF (mi), CF (mi) ?The morpheme feature MF (mi) is a pair of thesurface string and the part-of-speech of mi.
Thesimilar morpheme feature SF (mi) is defined asSF (mi) ={MF (m?i) if mi ?
M ?MFMF (mi) otherwise,where m?i is the most similar and familiar mor-pheme to mi given by Eqn.
1.
The character typefeature CF (mi) is a set of six binary flags to in-dicate that the surface string of mi contains a Chi-nese character, a hiragana character, a katakana??
Chunking Direction ?
?Feature set Fi?2 Fi?1 Fi Fi+1 Fi+2Chunk label ci?2 ci?1 ciFigure 4: Chunking Directioncharacter, an English alphabet, a number and another character respectively.When we identify the chunk label ci for the i-th morpheme mi, the surrounding five feature setsFi?2, Fi?1, Fi, Fi+1, Fi+2 and the preceding twochunk labels ci?2, ci?1 are referred as shown inFigure 4.Figure 3 shows an example of training instanceof the proposed method for the sentence ???(kyou)?
(no)??
(Ishikari)??
(heiya)?
(no)??
(tenki)?
(ha)??
(hare)?
which means ?Itis fine at Ishikari-plain, today?.
???
(Kantou)?is assigned as the most similar and familiar mor-pheme to ???
(Ishikari)?
which is unfamiliar inthe training corpus.3.4 Experimental ResultFigure 5 compares performances of the proposedmethod and the baseline method over the test textswhich were published in 1996, 1997, 1998 and2005.
The proposed method combines a small an-notated corpus and a large unannotated corpus asalready described.
This experiment refers IREXcorpus as a small annotated corpus, and refersMainichi Newspaper articles published from 1993to the preceding year of the test text publishedyear as a large unannotated corpus.
For example,when the test text was published in 1998, MainichiNewspaper articles published from 1993 to 1997are used.
The baseline method is trained fromIREX corpus with CRF.
But, it uses only MF andCF as features, and does not use SF .
Figure 5 il-lustrates two points: (1) the proposed method out-performs the baseline method consistently, (2) thebaseline method is fragile to changing of test texts.Figure 6 shows the relation between the per-formance of the proposed method and the size ofunannotated corpus against the test corpus pub-lished in 2005.
It reveals that that increasing unan-notated corpus size improves the performance ofthe proposed method.4 ConclusionIn this paper, we explored the change of NE dis-tribution over time and its influence on the per-165????????????????????????????????????????????????????????????????
????
????
????????????????????????????????????????????????????????
?Figure 5: Comparison between proposed methodand baseline method?????????????????????????????????????
????????????????????????????????????????????????????????????????????????????????????????????????????
?Figure 6: Relation of performance and unanno-tated corpus sizeformance of the NE tagger.
First, we annotatedMainichi Newspaper articles published in 1996,1997, 1998 and 2005, and analyzed NEs whichappear in these texts and IREX corpus which con-sists of Mainichi Newspaper articles published in1995.
This analysis illustrated that the number ofNE types and the number of NE tokens are al-most steady over time, and that 70 ?
80% of NEtypes seen in a certain year occur in the texts pub-lished either in its succeeding year or in its pre-ceding year.
The experiment against these textsshowed that our proposing semi-supervised NEtagger works robustly although the traditional su-pervised NE tagger is fragile against the change ofNE types.
Based on the results described in thispaper, we will investigate the relation between theperformance of NE tagger and the similarity of itstraining corpus and its test corpus.ReferencesRie Kubota Ando and Tong Zhang.
2005.
A high-performance semi-supervised learning method fortext chunking.
In Proc.
of ACL ?05, pages 1?9, June.Masayuki Asahara and Yuji Matsumoto.
2003.Japanese named entity extraction with redundantmorphological analysis.
In Proc.
of HLT?NAACL?03, pages 8?15.Ralph Grishman and Beth Sundheim.
1996.
Mes-sage understanding conference-6: a brief history.
InProc.
of the 16th COLING, pages 466?471.Hideki Isozaki and Hideto Kazawa.
2002.
Efficientsupport vector classifiers for named entity recogni-tion.
In Proc.
of the 19th COLING, pages 1?7.Hideki Isozaki.
2001.
Japanese named entity recogni-tion based on a simple rule generator and decisiontree learning.
In Proc.
of ACL ?01, pages 314?321.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional Random Fields: Prob-abilistic Models for Segmenting and Labeling Se-quence Data.
In Proceedings of ICML, pages 282?289.Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name tagging with word clusters and dis-criminative training.
In Proc.
of HLT-NAACL 2004,pages 337?342, May.Cristina Mota and Ralph Grishman.
2008.
Is this NEtagger getting old?
In Proceedings of the SixthInternational Language Resources and Evaluation(LREC?08), May.Keigo Nakano and Yuzo Hirai.
2004.
Japanese namedentity extraction with bunsetsu features.
Transac-tions of Information Processing Society of Japan,45(3):934?941, Mar.
(in Japanese).Nichigai Associates, editor.
2007.
DCS Kikan-meiJisho.
Nichigai Associates.
(in Japanese).Manabu Sassano and Takehito Utsuro.
2000.
Namedentity chunking techniques in supervised learningfor japanese named entity recognition.
In Proc.
ofthe 18th COLING, pages 705?711.Satoshi Sekine and Yoshio Eriguchi.
2000.
Japanesenamed entity extraction evaluation: analysis of re-sults.
In Proc.
of the 18th COLING, pages 1106?1110.E.
Tjong Kim Sang.
1999.
Representing text chunks.In Proc.
of the 9th EACL, pages 173?179.Masatoshi Tsuchiya, Shinya Hida, and Seiichi Naka-gawa.
2008.
Robust extraction of named entity in-cluding unfamiliar word.
In Proceedings of ACL-08: HLT, Short Papers, pages 125?128, Columbus,Ohio, June.
Association for Computational Linguis-tics.166Kiyotaka Uchimoto, Ma Qing, Masaki Murata, HiromiOzaku, Masao Utiyama, and Hitoshi Isahara.
2000.Named entity extraction based on a maximum en-tropy model and transformation rules.
Journal ofNatural Language Processing, 7(2):63?90, Apr.
(inJapanese).Hiroyasu Yamada, Taku Kudo, and Yuji Matsumoto.2002.
Japanese named entity extraction using sup-port vector machine.
Transactions of InformationProcessing Society of Japan, 43(1):44?53, Jan. (inJapanese).167
