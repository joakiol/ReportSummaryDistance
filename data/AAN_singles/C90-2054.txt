A POLYNOMIAL- -ORDER ALGORITHMFOROPT IMAL  PHRASE SEQUENCE SELECT ION FROM A PHRASE LATT ICEAND ITS  PARALLEL  LAYERED IMPLEMENTATIONKazuh i ko  OZEKIThe Un ivens  i ty  o f  E lec t  co - -Gommunica< ionsCho ' f fu ,  Tokyo ,  \] 82 ,  JapanAbst ractThis paper deals  with a problem of se lec t -ing an opt imal  phrase sequence from a phrasela t t i ce ,  which is  o f ten  encountered  inlanguage process ing  such as word process ingand post -process ing  for  speech recogn i t ion .The problem is formulated as one of combina-to r ia l  opt imizat ion ,  and a polynomial  ordera lgor i thm is der ived .
This a lgor i thm f indsan opt imal  phrase sequence and i t s  dependen-cy s t ruc ture  s imu l taneous ly ,  and is there -fore par t i cu la r ly  su i ted  for  an in ter facebetween speech  recogn i t ion  and var iouslanguage process ing .
What the a lgor i thm doesis numer ica l  opt imizat ion  ra ther  than sym-bo l i c  operat ion  un l ike  convent iona l  pars -e rs .
A para l le l  and layered  s t ruc ture  toimplement the a lgor i thm is a lso presented ,Although the language taken up here is Japa-nese,  the a lgor i thm can be extended to covera wider :family of languages.1.
In t roduct ionIn Japanese language process ing  re la ted  tospeech recogn i t ion  and word process ing ,  weo f ten  encounter  a prob lem of se lec t ing  aphrase :sequence which const i tu tes  the mostacceptab le  sentence from a phrase la t t i ce ,that  i s ,  a se t  of phrases  w i th  var iouss tar t ing  and end ing pos i t ions ,  By so lv ingth i s  problem, l ingu is t i c  ambigu i t ies  and/oruncer ta in t ies  coming from the inaccuracy  inspeech : recogn i t ion  are expected to be re -so lved.This problem can be so lved,  in p r inc ip le ,by enumerat ing a l l  the poss ib le  combinat ionsof the phrases and measuring the syntact i cand semant ic  acceptab i l i ty  of each phrasesequence as a sentence .
Obviously,  however,the amount of computat ion in th i s  enumera-t i ve  method grows exponent ia l l y  with respectto the length of the sequence and becomes in -t rac tab le  even for a moderate problem s ize .In th i s  paper we formulate  th i s  task as acombinator ia l  opt imizat ion  prob lem andder ive  a set  of recur rence  equat ions ,  whichleads to an a lgor i thm of polynomial  order int ime and space .
We ut i l i ze  the idea  ofdependency grammar \[Hays 64\] for  de f in ingthe acceptab i l i ty  of a phrase sequence as aJapanese sentence .With a review of recent  theoret i ca l  deve l -opment on th i s  top ic ,  a para l le l  and layeredimplementat ion  of the a lgor i thm is p resent -ed.2.
Dependency St ructure  of JapaneseIn Japanese,  words and morphemes are con-catenated  to form a l ingu is t i c  un i t  ca l led'bnnsetsu ' ,  which is re fe r red  to as simply'phrase '  here.
h typ ica l  phrase cons is ts  ofa content  word fol lowed by some funct iona lmorphemes, h Japanese sentence is a sequenceof phrases with a s t ruc ture  which can be de-sc r ibed  by a d iagram as in  F ig .
1\[Hashimoto 463.
For a sequence of phrasesX lXZ.
.
.x  n to be a we l l - fo rmed Japanesesentence ,  i t  must have a s t ruc ture  sat i s fy -ing the fo l low ing  const ra in ts  \[Yoshida 72\]:(e l )  For any i ( l< i<n-1) ,  there  ex is tsunique j ( i<j<n)  such that  x i modi f ies  xj ina wide sense.
(c2) For any i , j , k ,1  ( l< i< j<k<l<n) ,  i tnever  occurs  that  x i mod i f ies  x k and xjmodifies x I.A s t ruc ture  sat i s fy ing  these const ra in tsis ca l led  a dependency s t ruc ture  here.
Mereformal ly  we def ine  a dependency s t ruc ture  asfo l lows \ [Ozek i  86a\],Def in i t ion  1(1) I f  x 0 is  a phrase ,  then <x0> is a de-pendency s t ruc ture ,(2) If  X 1 .
.
.
.
.
X n are dependency s t ruc turesand x 0 is  a phrase,  then <Xl.
.
.X n x0> is adependency s t ruc ture .A dependency  s t ruc ture  <XI .
.
.X  n x0>(X i=<.
.
.x i>)  impl ies  that  each x i ,  which isthe las t  phrase in X i ,  mod i f ies  x 0, I t  iseas i ly  ver i f ied  that  a s t ruc ture  sat i s fy ingthe const ra in ts  (e l )  and (c2) is a dependen-cy s t ruc ture  in the sense of Def in i t ion  1and v ice versa \[Ozeki 86a3.When a dependency s t ruc ture  X is composedof phrases Xl,X 2 .
.
.
.
.
x n we say that  X is adependency s t ruc ture  on XlX2.
.
.x  n. The setof a l l  the  dependency  s t ruc tures  onX lX2 .
.
.x  n is  denoted as K (X lX2 .
.
.Xn) :  andfor a sequence of phrase sets  A1,A 2 .
.
.
.
.
A n ,we def ineKB(A 1 ,A 2 .
.
.
.
.
A n)={X\[XeK(XlX2...Xn), xieh i (l<i<n)}.Fig.1 Example of dependency s t ruc turein Japanese.
A,B .
.
.
.
are phrases.311I3.
Acceptabi l i ty  of a Dependency StructureFor a pair  of phrases x 1 and x 0' we canthink of a penalty  imposed on a modi f ier -modificant re la t ion  between x 1 and x 0.
Thisnon-negative value is denoted as pen(xl ;x0).The smaller value of pen(xl;x 0) representsthe more natura l  l i ngu is t i c  re la t ion .
Al-though it  is very important to estab l i sh  away of computing pen(xl ;x0),  we wil l  not gointo that problem in th is  paper.
Based onthe ' l oca l '  penalty,  a 'g loba l '  penalty P(X)of a dependency s t ruc ture  X is de f inedrecurs ive ly  as fol lows \[0zeki 86a\].Def in i t ion 2(1) For X=<x>, P(X)=O.
(2) For X=<Xl...X n xo>, where X i=<.
.
.x i>(I<i<n) is a dependency s t ructure ,P(X)= P(Xl)+...+P(X n)+pen(xl;xo)+...?pen(xn;XO).Note that P(X) is the sum of the penaltyof a l l  the phrase pairs which are supposedto be in modif ier-modif icant re la t ion  in thedependency s t ruc ture  X.
This funct ion  isinvar iant under permutation of X 1 .
.
.
.
.
X n inaccordance with the character i s t i c  of Japa-nese.4.
Formulation of the ProblemFor s imp l i c i ty ,  l e t  us begin  with aspecial  type of phrase la t t i ce  composed of asequence of phrase sets  BI,B 2 .
.
.
.
.
B N asshown in F ig.2,  which we ca l l  phrase ma-t r ix .
Suppose we are given a phrase matrixand a re l iab i l i ty  funct ions :  BIUB2U...UB N --> R+,where R+ denotes the set  of non-negat ivereal  numbers.
The smal ler  value of s(x)represents the higher re l iab i l i ty  of x. Weencounter th is  special  type of phrase la t -t ice in iso lated phrase speech recognit ion.In that case B i is the set of output candi-dates for the ith utterance,  and s(x) is therecognit ion score for a candidate phrase x.For a dependency s t ruc ture  X on a phrasesequence XlX2...x N, the tota l  re l iab i l i tyof X is defined asS(X)= S(Xl)+...+S(XN).Combining the acceptab i l i ty  and the re l i -ab i l i ty ,  we def ine  an ob jec t ive  funct ionF(X) asF(X)= P(X) +S(X) .B 1 B 2 ?
?
?
B NX l l  x21 - XN1x12  x22  .- _ XN2X l3  x23  XN3Fig.2 Phrase matrix.
B 1 .
.
.
.
.
B N arephrase sets .Then the centra l  problem here is formulat-ed as the fol lowing combinatorial  optimiza-t ion problem \[Matsunaga 86, 0zeki 86a\].Problem Find a dependency st ructureXeKB(B1,B 2 .
.
.
.
.
B N)which minimizes the ob ject ive funct ion F(X).By solving this  problem, we can obtain theopt imal  phrase sequence and the opt imaldependency s t ructure  on the sequence simul-taneously.When \[Bll=\[B2I=...=IBN\] : M,we have\[KB(B1,B 2 .
.
.
.
.
BN)\[= (2(N_I)C(N-1))/N)MN,where C denotes combination.
This oecomes ahuge number even for  a moderate problemsize,  rendering an enumerative method prac-t i ca l l y  impossible.5.
Recurrence equat ions  and a resu l t ingalgorithmCombining two dependency s t ructures  X andY=<YI .
.
.
.
.
Ym,Y>, a new dependency s t ructure<X,Y 1 .
.
.
.
.
Ym,y> is obtained which is denotedas X O V. Conversely, any dependency s t ruc-ture Z with length greater  than 1 can bedecomposed as Z= X@ Y, where X is the topdependency s t ructure  in Z.
Moreover, it  iseas i ly  ver i f ied  from the de f in i t ion  of theob ject ive funct ion thatF(Z)= F(X) ?
F(Y) ?
pen(x;y),where x and y are the last  phrases in X andY, respect ive ly .
The fol lowing argument isbased on this  fact .We denote elements in B i as Xjl,Xi2 .
.
.
.
.For l<i<j<N and l<p<lBj\[ , 'where \ [B j \ [ 'denotesthe number of elements in Bj, we defineopt ( i , j ;p )=min{F(X) XeKB(B i .
.
.
.
.
Bj_l{Xjp})}andopts ( i , j  p)=argminCF(X)\[X~KB(B i .
.
.
.
.
Bj_l{Xjp})}.Then the fo l lowing recurrence equat ionshold for opt ( i , j ;p )  and opts ( i , j ;p ) ,  respec-t i ve ly  \[Ozeki 86a\].Proposi t ion 1 For l<i~jJN and I~p<\[Bj\[(1) i f  i=j,  then opt ( i , j ;p )=s(X jp ) ,(2) and if  i<j,  thenopt ( i , j ;p )=min{f(k,q)\[iJk<j-l,l~q~\]Bk\[},wheref (k ,q )=opt ( i , k ;q )?opt (k+l , j ;p )?pen(xkq;Xjp).Proposi t ion 1' For l~i<j<N and lJp<\]Bj ,(1) i f  i=j,  then opts( i , j ;p)=<Xjp>,(2) and if  i<j,  thenopts ( i , j ;p )=opts( i ,*k;*q)  O opts (*k+l , j ;p ) ,where *k is the best segmentation point and*q is the best phrase number in Bgk:(*k,*q)=argmin{f(k,q) \ [ i~k<j- l , l<q~\[Bk\[}.According to Proposit ion 1, i f  the valuesof opt ( i , k ;q )  and opt (k?l , j ;p )  are known forl~k<j-1 and l<q<\[Bk\[,  i t  is poss ib le  toca lcu la te  the value of opt ( i , j :p )  by search-ing the best segmentation point and the bestphrase number at the segmentat ion  po in t .This fact  enables us to ca lcu late  the value312  2of opt (1 ,N 'p )  recurs ive ly ,  s ta r t ing  withopt ( i , i ;q )  (lJi<N,lJqJlBiI).
This is thepr inc ip le  of dynamic programming \ [Be l l -man 57\].Let *p= argmin{opt(1,N'p) ll<p<lBN\[},then we have the f ina l  so lut ionopt (1 ,Ngp)=min{F(X) \ [XeKB(B  1 .
.
.
.
.
BN)}andopts(1,N;gp)=argmin{F(X) lXeKB(B 1 .
.
.
.
.
BN)}.The opts (1 ,N '*p)  can be ca lcu la ted  recur -s ive ly  using Propos i t ion  2.
F ig.3 i l l us -t ra tes  an a lgor i thm t rans la ted  from theserecur rence  equat ions  \[Ozeki  86a\] .
Thisa lgor i thm uses  two tab les ,  tab le l  andtable2, of upper t r iangu lar  matrix form asshown in F ig .4 .
The ( i , j )  element of thematrix has \[Bil 'p igeon-ho les ' .
The valueof opt ( i , j ;p )  ts " s tored in tab le l  and thepair  of the best segmentation point and thebest phrase number is stored in tableZ.
Itshould be noted that there is much freedomin the order of scanning i , j  and p, whichwil l  be u t i l i zed  when we discuss a para l le limplementation of the algorithm.Optimal Dependency_Structure;begin/* Analysis Phase */for j :=l  to N dofor i :=j  downto 1 dofor  p:=l to IBjl doif i=j thentablel(i,j;p):=s(Xjp);elsebegintablel(i,j;p):=min{tablel(i,k;q)+tablel(k+!,j;p)+pen(xkq;Xip)ll<k<j-l,l<q<\[Bkl}"tab le2( i , j ;p ):=argmin{tab le l ( i ,k ;q)+tab le l (k+l , j ;p )+pen(xkq;Xip)Ii~k<j-l,t<q<|gkl\[:end:/* Composition Phase */*p:=argmin{tablel(1,N;p)\]I<p<IBNI}:resu l t :=opts (1 ,N :#p) :end.funct ion opts( i  j ;p ) : char  s t r ing;beginif  i=j thenopts:='<Xjp>'elsebegin( *k , *q) :=tab le2( i , j ;p ) ;opts :=opts ( i , *k ; *q)  (~)opts (*k i l , j ;p ) ;end;end.Fig.3 Algorithm to se lect  an optimaldependency s t ructure  from a phrasematrix.(T,3T.
~') .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
{r -, = .
.
.
.
.
.
.
.
_ _?
- -22  -_-?
_-.7 Z - {2, 5; \]),I I .
.
.
.
.
.
.
.
.
.
?
g-2K .
.
.
.
:.17?
2--21 , ;-# 7_-.77: - - : :  22221--_-2 :-_: JFig.4 Tr iangular matrix table .
.
.
.
.
.
.
.
.for tab le l  and table2.
- .
.
.
.
.
.
.In th is  example, N=7 and ~ - ~IBII=...:IBTI:3.
~77523character  pos i t ion1 2 3 4 5 '6 7 8 9 10 11 12 13 14 151~ 1 A) I B(S,8) B(12) B(35) \[ B(68) ~ B(11,15) --1 B(9,13)Fig.5 Example of phrase la t t i ce .When IB1\]=...=IBNI=M, the number of opera-t ions (add i t ions  and comparisons) necessaryto f i l l  table l  is O(M2N3).These recurrence equat ions and algor i thmcan be eas i ly  extended so that  they canhandle a general  phrase la t t i ce .
A Phrasela t t i ce  is a set of phrase sets,  which looksl i ke  F ig .5 .
B ( i , j )  denotes  the set  ofphrases beginning at character  pos i t ion  iand ending at j.
A phrase la t t i ce  is oh--rained, for example, as the output of a con-tinuous speech recognit ion system, and alsoas the resu l t  of a morphological analys is  ofnon-segmented Japanese text spel led in kanacharacters  only.
We denote the elements ofB (~ j~ as X i j l ,X i j  2 .
.
.
.
.
and in para l le lwi be de f in i t ion  of opt and opts ,  wedefine opt '  and opts '  as fol lows.For l<i<m<j(N and Xmj p,opt ' ( i , j ,m;p)=the minimum value of \ [P(X) iS(X) \ ]  as Xruns over a l l  the dependency s t ruc tureson a l l  the poss ib le  phrase sequencesbeginning at i and ending at j with thelast  phrase being fixed as Xmj p,andopts ' ( i , j ,m;p)=the dependency s t ructure  which gives theabove minimum.Then recur rence  equat ions  s imi la r  toP ropos i t ion  1 and Propos i t ion  1' hold foropt '  and opts ' \ [Ozek i  86bJ:Proposi t ion 2 For l !
i Jm!
j !S  andl Jp<lB(m,j) \ [ ,(1) if i=m, then opt ' ( i , j ,m;p)=S(Xmjp) ,3133(2) and if i<m, thenopt ' ( i , j ,m;p)=min{f' (k ,n,q)  l i<n<k<m-1, l Jq J lB(n,k)  l},wheref ' (k , r l ,q )= ept ' ( i , k ,n ;q )?opt ' (k+l , j ,m;p)?pen(xnkq:Xmjp)Propo~;ition 2' For \[<i<mi3~N andlJpJIB(m,J)l,(I) if i=m then opts'(i,j,m;p)=<Xmjp>,(2) and if i<m, thenopts'(i j,m;p)=opts ' ( i  *k,gn;gq) O opts ' (gk+l , j ,m;p) ,where *k is the best segmentation point ,  *nis the top pos i t ion  of the best phrase atthe segmentation point and *q is the bestphrase number in B(*n,*k):(~k,$n,*q)=argmin{f(k,n,q)  l i<n<k<m-l , l Jq J IB(n ,k) \ [} .The minimum is searched on 3 var iab les  inth is  case.
I t  is a s t ra ight  forward matterto t rans la te  these recurrence equations intoan a lgor i thm s imi la r  to Fig.3 \[Ozeki 88b,Kohda 86\] .
In th i s  case ,  the order  ofamount of computat ion  is O(M2NS), whereM=IB( i , j ) I  and N is the number of s ta r t ingand end ing pos i t ions  of phrases  in thetop layernode( I ,1)  bottom layer  node(7,7)Fig.6 2-dimensional  array of computingelements.lattice.Also, we can modify the algorithm in sucha way that up to kth optimal solutions areobtained.6.
Para l le l  and Layered ImplementationWhen only one processor  is ava i lab le ,  theamount of computation dominates the proc-ess ing time.
On the other  hand, when thereis no l imi t  as to the number of processors ,the process ing time depends on how much ofthe computation can be executed in para l le l .There ex is ts  a t idy  para l le l  and layereds t ruc ture  to implement the above algor i thm.For s imp l i c i ty ,  le t  us conf ine ourse lvesto a phrase matr ix case here.
Furthermore,let  us f i r s t  consider the case where thereis on ly  one e lement  x i in each of thephrase set B i .
I f  we def ineopt ' ' ( i , j )=min{P(X) lXeK(x  i .
.
.
.
.
xj)}then Propos i t ion  1 is reduced to the fo l low-ing s impler form.Propos i t ion  3 For l J i J j JN ,(1) i f  i=j ,  then opt" ( i , j )=O,(2) and i f  i<j ,  thenopt" ( i , j )=min{opt" ( i , k ) iopt" (k+l , j )+pen(xk;x j ) \ [ i<k<j -1},I t  i s  easy  to see that  opt ' ' ( i , j )  andopt" ( i?m, j?m)  (m~O) can be ca lcu la ted  inde-pendently of each other .
This mot ivates usto devise a para l le l  and layered computa-t ion s t ruc ture  in which process ing elementsare a r ranged in a 2 -d imens iona l  a r ray  asshown in F ig.6.
There are N(N+I)/2 process-ing elements in to ta l .
The node( i , j )  has anin terna l  s t ruc ture  as shown in F ig.7,  and isconnected with node( i , k )  and node(k?l , j )( l Jk<j -1)  as in Fig.8.
The bottom elements,node( i , i ) ' s  ( l< i<N) ,  hold va lue 0 and donothing e lse .
The node( i , j )  ca lcu la tes  thevalue of opt" ( i , j )  and holds the resu l t  inmemory i together  with the optimal segmenta-t ion point in memory 2.
Within a layer  a l lthe nodes work independently in para l le l  andthe computation proceeds from the lower toupper layer .
An upper node rece ives  informa-t ion  about a longer  sub-sequence  than alower node: an upper node processes  moreglobal  in fo rmat ion  than a lower node.
When\[.
oinio;zatio.. .
.x,  '"ut t onJ 0 node(i?l.j' / 0 node(i+g,J)0 node(i.i) 0 node(i.i+l)memory I o~ut  pmin ; ut 1, , L \ ]~~ u t a t i o n  ofFig.7 In terna l  s t ruc ture  of node( i , j ) .314 4e( i , j )node( i , j -1 )  node( i+ l , j )/ \1 \1 \node ( i  , i+ l) node( j - I ,  j )dnode( i , i )  node( j , j )~F ig .8  Nodes connected to node( i , j ) .
(1, 6;5)d:  C~ / / "//C~"/3C~\ >3 2nd (~aver/(D\\ 'C )x(\], i;!)
bottom layer (6,6:1)F ig .9  3--dimendional  a r ray  of computinge lements .the top e lement ,  node(1 ,N) ,  f in i shes  i t siob,  each node holds in fo rmat ion  which isuecessary  to compose the opt ima l  dependency' .~t ructure  on X lX2 .
.
.x  N. Th is  computat ion~;t ructure ,  having many s imple in ter - re la tedcomputing e lements ,  might be remin iscent  ofa conneet ion is t  model or a neura l  network.This resu l t  can be eas i ly  extended,  based,:)n P ropos i t ion  1, to the case in which eachphrase  set  has more than one e lements .
Ini:his case process ing  e lements  are ar rangedin a 3 -d imens iona l  a r ray  as shown in F ig .9 .The bottom e lements ,  node( i , i ;p ) ' s ,  hold theva lue of s (X ip ) .
The node( i , jp )  ca lcu la tesI:he va lue  of  opt ( i , j ;p ) .
The computat ioni , roceeds from tile lower to upper layer  jus tas in the prev ious  s impler  case .
Fur therextens ion  of th i s  s t r .uc ture  is  a l so  poss ib le:',o that  i t  can handle a genera l  phrase la t -l ; ice.?.
Re la ted  WorksThe prob lem of se lec t ing  an appropr ia te?hrase  sequence from a phrase  la t t i ce  hasbeen t reated  in the f ie ld  of Japanese word?
recess ing ,  where a non-segmented Japaneset:ext spe \ ] .
led  in kana character  must beconver ted  in to  an or thograph ic  s ty le  spe l ledin kana and kan j i .
Severa l  p ract i ca l  methodshave been dev ised  so fa r .
Among them, theapproach in \[Oshima 86\] is  c lose  in idea tothe present  one in that  i t  u t i l i zes  theJapanese case grammar in o rder  to d i sambi -guate  a phrase  la t t i ce .
However ,  the i rmethod i s  enumerat ion -or iented  and somekind of heur i s t i c  p rocess  i s  necessary  toreduce the s i ze  of the phrase la t t i ce  beforesyntact i c  ana lys i s  is  per formed.In o rder  to d i sambiguate  the resu l t  ofspeech recogn i t ion ,  an app l i ca t ion  of de-pendency ana lys i s  was a t tempted  \[Matsunaga86, Matsunaga 87\].
The a lgor i thm used is  abot tom-up,  depth - f i r s t  search ,  and i t  i srepor ted  that  i t  takes  cons iderab le  process -ing t ime.
By in t roduc ing  a beam searchtechn ique ,  computing time can be very muchreduced \[Nakagawa 87\ ] ,  but  w i th  loss  ofg loba l  opt ima l i ty .Perhaps  ti le most c lose ly  re la ted  a lgo -r i thm wi l l  be (extended)CYK a lgor i thm withprobab i l i s t i c  rewr i t ing  ru les  \ [Levinson 85,Ney 87, Nakagawa 87\].
In sp i te  of the d i f -fe rence  in the in i t ia l  ideas  and the formu-la t ions ,  both  approaches  lead  to s imi la rbot tom-up,  b readth - f i r s t  a lgor i thms based onthe pr inc ip le  of dynamic programming.In F ig .2 ,  i f  each phrase  set  has only onephrase ,  and the  va lue  of  between-phrasepena l ty  i s  0 or 1, then the a lgor i thm re -duces to the convent iona l  Japanese dependen-cy ana lyzer  \ [H i taka  80\].
Thus, the a lgor i thmpresented  here is  a twofold extens ion  of theconvent iona l  Japanese dependency ana lyzer :the va lue  of  between-phrase  pena l ty  cantake  an arb i t ra ry  rea l  number and i t  canana lyze  not  on ly  a phrase  sequence  but aphrase matr ix  and a phrase la t t i ce  in po ly -nomial t ime.We have cons idered  a spec ia l  type of de-pendency s t ructure  ill th i s  paper ,  in which amod i f i cant  never precedes  the mod i f ie r  as i snormal ly  the case in Japanese.
I t  has beenshown that  the a lgor i thm can be extended tocover  a more genera l  dependency  s t ructure\[Katoh 893.The fundamental  a lgor i thm presented  herehas been modi f ied  and extended,  and ut i l i zedfor  speech recogn i t ion  \[Matsunaga 88\].8.
Concluding RemarksIn the method presented  here ,  the l ingu is -t i c  data  and the a lgor i thm are  complete lyseparated .
The l ingu is t i c  data  are condensedin the pena l ty  funct ion  which measures thenatura lness  of mod i f ie r -mod i f i cant  re la t ionbetween two phrases .
No heur i s t i cs  hass l ipped  in to  the a lgor i thm.
This makes thewhole procedure  very t ransparent .The essent ia l  par t  of  the a lgor i thm isexecut ion  of numer ica l  opt imizat ion  ra therthan symbol ic  matching un l ike  convent iona lparsers .
There fore  i t  can be eas i ly  imple-mented on an ar i thmet ic  p rocessor  such asDSP (D ig i ta l  S igna l  P rocessor ) .
The para l le l5 315and layered s t ructure  wi l l  f i t  LSI imple-mentation.An obvious l im i ta t ion  of th is  method isthat  i t  takes account of only pa i r -w isere la t ion  between phrases.
Because of th is ,the c lass  of sentences  which have a lowpenalty in the present c r i te r ion  tends to bebroader than the c lass of sentences which wenormally consider acceptable.
Nevertheless,th i s  method is use fu l  in reduc ing  thenumber of candidates so that a more sophis-t icated l ingu is t i c  analys is  becomes possiblewithin rea l i s t i c  computing time in a la terstage.A reasonable way of computing the penaltyfor a phrase pair  is yet to be establ ished.There seems to be two approaches to th i sproblem: a determin is t i c  approach tak ingsyntact ic  and semantic re la t ion  between twophrases into cons iderat ion,  and a s ta t i s t i -cal one based on the frequency of co-occu-fence of two phrases.AcknowledgementThe author is g ra te fu l  to the support ofHose Bunka Foundation for this work.References\[Bellman 573 Bellman,R.
: 'Dynamic Program-ming', Princeton Univ.
Press, 1957.\[Hashimoto 46\] Hashimoto,S.
: 'Kokugo-gakuGairon' ,  lwanami.
1946.\[Hays 64\] llays,D.G,: 'Dependency Theory: AFormalism and Some Observat ions ' ,  Lan-guage, Vol.40, No.4, pp.511-525, 1964.\ [Hitaka 80\] n i taka ,T ,  and Yosh ida ,S .
'ASyntax Parser Based on the Case Dependencyand I t s  E f f i c iency '  Prec .
COLING'80,pp.15-20, 1980.\[Katoh 89\] Katoh,N.
and Ehara,T.
?
'A fastalgorithm for dependency st ructure  analy-s i s '  Prec.
39th Annual Convention IPSJapan, 1989.EKohda 86\] Kohda,M.'
'An a lgor i thm foroptimum se lect ion  of phrase sequence fromphrase la t t i ce ' ,Paper  Tech.
Group, IECEJapan, SP86-72, pp.9-16, 1986.\ [Levinson 853 Lev inson ,S .E . '
'S t ruc tura lMethods in Automatic Speech Recognit ion'Prec.
of IEEE, Vol .
?3,  No .
l l ,  pp.1625-1649, 1985.\[Matsunaga 86\] Matsunaga,S.
and Kohda,M.''
Pos t -p rocess ing  using dependency s t ruc -ture of inter -phrases for speech recogni-t ion ' ,  Prec.
Acoust .
Soc.
Jpn.
Spr ingMeeting, pp.45-46, 1986.\[Matsunaga 87\] Matsunaga,S.
and Kohda,M,:'Speech Recognition.
of Minimal Phrase Se-quence Taking Account of Dependency Rela-t ionsh ips  between Minimal Phrases ' ,Trans.
IEICE Vol.
JTO-D,No.ll, pp.2102-2107,1987.\[Matsunaga 88\] Matsunaga,S.
and Kohda,M."'
L ingu is t i c  processing using a dependencys t ruc ture  grammar for speech recogn i t ionand unders tand ing '  Prec .
COLING'88,pp.402-407, 1988.\[Nakagawa 873 Nakagawa,S.
and I to ,T .
:'Recognit ion of Spoken Japanese SentencesUsing Menu-Syl lab le  Units and BackwardKakar i -Uke Pars ing  A lgor i thm' ,  Trans.IEICE Vol.
J70-D,No.12, pp.2469-2478, 1987.\[Nakagawa 87\] Nakagawa.
S : 'Un i f i cat ion  ofKakar i -Uke Ana lys i s  and Context -F reePars ing by CYK Algorithm for  ContinuousSpeech Recogn i t ion ' ,  Prec.
Acoust.
Soc.Jpn.
Spring Meeting, pp.131-13Z, 1987.\[Ney 87\] Ney,H.
: 'Dynamic Programming SpeechRecognition Using a Context-Free Grammar',Prec.
ICASSP'87, pp,69-72, 1987.\[Oshima 86\] Oshima,Y., Abe,M,, Yuura,K.
andTakeichi,N.
: 'A Disambiguation Method inKana-Kanj i  Convers ion Using Case FrameGrammar' ,  Trans.
IPSJ,  Vo l .27,  No.7,pp.679-687, 1986.\[Ozeki 86a\] Ozeki,K.
: 'A mult i -stage deci -sion a lgor i thm for optimum bunsetsu se-quence selection', Paper Tech.
Group, IECEJapan, SP86-32, pp.41-48, 1986.\[Ozeki 86b\] Ozeki,K.
: 'A multi-stage deci-sion algorithm for optimum bunsetsu se-quence selection from bunsetsu la t t i ce ' ,Paper Tech.
Group, IECE Japan, COMP86-47,pp.47-57, 1986.\[Yoshida 72\] Yoshida,S.
: 'Syntax analys is  ofJapanese sentence based on kakariuke re la -t ion between two bunsetsu ' .
Trans.
IECEJapan, Vol.
J55-D, No.4, 1972.316 6
