A spoken dialogue interface for TV operations based ondata collected by using WOZ methodJunGotoNHK STRLHuman ScienceTokyo 157-8510Japangoto.j-fw@nhk.or.jpYeun-BaeKimNHK STRLHuman ScienceTokyo 157-8510Japankimu.y-go@nhk.or.jpMasaruMiyazakiNHK STRLHuman ScienceTokyo 157-8510Japanmiyazaki.m-fk@nhk.or.jpKazuteruKomineNHK STRLHuman ScienceTokyo 157-8510Japankomine.k-cy@nhk.or.jpNoriyoshiUrataniNHK STRLHuman ScienceTokyo 157-8510Japanuratani.n-fc@nhk.or.jpAbstractThe development of multi-channel digitalbroadcasting has generated a demand notonly for new services but also for smartand highly functional capabilities in allbroadcast-related devices.
This is espe-cially true of the television receivers onthe viewer's side.
With the aim of achiev-ing a friendly interface that anybody canuse with ease, we built a prototype inter-face system that operates a televisionthrough voice interactions using naturallanguage.
At the current stage of our re-search, we are using this system to inves-tigate the usefulness and problem areas ofthe spoken dialogue interface for televi-sion operations.1 IntroductionIn Japan, the television reception environment hasbecome quite diverse in recent years.
In addition toanalog broadcasts, BS (Broadcast Satellite) digitaltelevision and data broadcasts have been operatingsince 2000.
At the same time, TV operations forreceiving such broadcasts are becoming increas-ingly complex, and an ever increasing variety ofperipheral devices such as video tape recorders,disk recorders, DVD players, and game consolesare now being connected to televisions, and operat-ing such devices with different kinds of interfacesis becoming troublesome not only for the elderlybut for general users as well (Komine et al, 2000).Recently we conducted a usability test targetingdata broadcasts in BS digital broadcasting.
Theresults of the test revealed that many subjects hadtrouble accessing hierarchically arranged data.This finding revealed the need for an easymeans of accessing desired programs.
One suchmeans is a spoken natural language dialogue (here-after spoken dialogue) interface for TV operations.If spoken dialogue could be used to select andsearch for programs, to operate peripheral devices,and to give information in reply to system queries,we can envisage such an interface as being ex-tremely valuable in a multi-channel and multi-service function viewing environment.
With this inmind, we have set out to build an interface systemthat could operate a television via spoken dialoguein place of manual operations.2 Collecting dialogue data for TV opera-tionsAssuming that a television is intelligent enough tounderstand the words spoken by a human, whatkind of language expressions would a user use togive commands to that television?
In other words,it is important that the words spoken by a user insuch a situation be carefully examined when de-signing a television interface using spoken dia-logues.
Therefore first we built an experimentalenvironment that would enable us to collect dia-logue data based on WOZ (Wizard of OZ) method.2.1 Wizard of OZWe set up a television-operation environment ac-cording to the WOZ framework in which the sub-jects were instructed that ?the character appearingon the television screen can understand anythingyou say, and that the character will operate thetelevision for you.
?The number of channels that could be selectedwas 19, and screens displaying Electronic ProgramGuide (EPG) and user interface for programsearching were presented as needed (Komine et al,2002).This WOZ environment required two operators,one in charge of voice responses and the other ofuser interface operations.
The voice-response op-erator returns a voice response to the subject by aspeech synthesizer after selecting a reply fromabout 50 previously prepared statements or input-ting replies directly from a keyboard.
If the subjecthappens to be silent, the operator returns a re-sponse that introduces new services or prompts thesubject to say something.
The user interface opera-tor first determines what the subject wants, andthen manipulates user interface or EPG and per-forms basic television operations such as changingchannels.The subjects selected for data collection con-sisted of 10 men and 10 women ranging in agefrom 24 to 31 (average age: 28.7), and each wasallowed to speak freely with the television for 5minutes under an assumption that the ?televisionhas a certain amount of intelligence.
?2.2 Results of data analysisFigure 1 shows an example of dialogue data re-corded during a WOZ session.
On analyzing col-lected utterances made by the subjects  (1,268utterances in total), it was found that 83% of userutterances concerned requests made to the televi-sion, and that 89% of those requests includedwords belonging to specific categories such asprogram title, genre, performer, station, time, andTV operation commands.
The remaining 17% ofutterances did not concern the system but wererather a result of subjects talking or muttering tothemselves for self-confirmation and the like.Here, we consider the following reason whymost utterances belonged to specific categoriesdespite the fact that a variety of request could bemade.
In this system, TV program- and operation-related information is displayed on the televisionscreen, and based on this information, subjectstended to underestimate television capability and toomit utterances not dealing with service functionsthey saw as possible.
It is also thought that theconventional image of television inside subjects?minds served to restrict user utterances.As a part of this WOZ experiment, we also hadthe subjects fill out a questionnaire with regards totelevision operations by using spoken dialogueinterface.
When asked to give an opinion on oper-ating a television by voice, more than half replied?Yes, I would like to?
therefore apparently indicat-ing a high demand for the spoken dialogue inter-face.
On the other hand, most subjects that replied?No, I would not like to?
gave simple embarrass-ment at speaking out loud as one reason and a re-luctance to vocalize commands when watchingtelevision together with their families as another.In this regard, we think that embarrassment couldprobably be reduced through user experience andappropriate environment configuration.3 Spoken dialogue interface system forTV operationsBased on the results of the data analysis, we built aprototype system that enables television operationsvia spoken dialogue.
Figure 2 shows the configura-tion of this system.
The system allows users to se-lect real-time broadcast programs from 19 channels.It also enables the presentation of program in-00:27:08 Subject     Well, I?m looking for a program.00:30:23 WOZ    You can also choose by genre.Would you like to see the list ofprograms by genre?00:36:25 Subject  Yes.00:38:00 WOZ  All right.00:47:02 Subject     Ah!00:47:02 WOZ        Please select a genre.00:50:04 Subject     Well, let?s see.How about ?Variety?
?00:55:11 WOZ       OK!01:02:06 Subject    I see.01:03:29    WOZ     Please select the program youwould like to see.01:08:27 Subject    Well, I would like see more at thebottom of the screen.01:12:09 WOZ       OK, I will do it.01:15:23 Subject  Um, Just a little bit more.01:17:27 WOZ       OK, how?s that?Figure 1: Example of dialogue dataformation obtained from the Internet or overlaiddata in digital broadcasts; the scheduling of pro-gram recording; and the browsing of program-related information from Internet.
All of thesefunctions can be operated through spoken naturallanguage interactions.
The main processing mod-ules of the system are described below.3.1 Robot interfaceThe user makes operation requests to interface ro-bot (IFR) as shown in Figure 3, and the IFR oper-ates the television accordingly for the user.
TheIFR is equipped with a super-unidirectional micro-phone and a speaker, and communicates and acti-vates the speech recognition and voice synthesis,and dialogue processing of the system.
The IFRhas been given the appearance of a stuffed animal.One advantage of this IFR is that it can be directlytouched and manipulated to create a feeling ofwarmth and closeness.On hearing a greeting or being called by itsname, the IFR opens its eyes and enters a state thatcan perform various operations.
For example, theIFR can assist the user search for a program, canpresent information about any program on the tele-vision screen, and can return voice responses.3.2 Speech recognitionThe speech recognition module uses an algorithmthat can finalize recognition results in a sequentialmanner for a real-time operation and a high speechrecognition rate.
When applying this module to anews program, a speech recognition rate of about95% can be obtained (Imai, 2000).In speech that occurs during television opera-tions, the words such as program titles, names ofbroadcast stations, names of entertainers and etc.have a high probability of occurring and are alsoupdated frequently.
For this reason, newly acquiredword-lists are automatically registered in a diction-ary on a daily basis.
In addition, as program titlesoften consist of multiple words, it is necessary toregister them as a single word in order to improvethe recognition rate.Despite several additional forms of tuning, it isstill difficult to achieve perfect results with currentspeech recognition technology.
To enable feedbackto be given to the user at the time of erroneous rec-ognition, results of recognition are always dis-played on the lower left corner of the televisionscreen.3.3 Dialogue processingIn dialogue processing, it is generally difficult tounderstand intent by performing only a lexicalanalysis of speech.
If we limit tasks to dialogueused in television operation, the words spoken by auser have a high probability of falling into specificcategories such as program name, as indicated bythe results of the data analysis described in 2.2.
Asa consequence, user intent can be inferred from acombination of specific categories and predicates.From the viewpoint of processing speed, process-ing can be performed in real time if we use pattern-base approach.
This approach is also used in otherdialogue systems such as PC-based agent televi-sion systems in the (FACTS) project and (Sumiyo-shi et al, 2002).The dialogue processing module performs real-time morphological analysis of input statementsfrom the speech recognition module.
A statementis then identified by pattern matching in units ofmorphemes and the meaning ascribed beforehandto that statement is obtained.
An example of suchpattern is shown in Figure 4 using the meta-characters listed in Table 1:UserInternetIndividual profilemanagement programProgram retrieval  Profile searchTV programdatabaseDialog processingSpeech recognitionVoice synthesisMachinecontrolPresentationDigitalbroadcastingOperationrequestFigure 3: Interface robot and an operation scene Figure 2: Configuration of interface systemTable 1: Meta-characters used in patternIn the pattern matching process, categories im-portant to television operations are stored as slots.Table 2 lists these category-slots and examples oftheir members.
The words stored in these slots arethen used as a basis for generating television op-eration commands and search expressions to accessthe TV program database.
Response statements toinput statements may take various forms dependingon the patterns and current circumstances, and theyare here generated by taking into account slot in-formation, response history, results of searchingfor program information.Table 2: Content of category-slots4 ConclusionWe have built a spoken dialogue system based onthe results of a WOZ experiment with the aim ofachieving a television operation interface easyenough for anybody to use.In the preliminary system operation test, 5 sub-jects were asked to give some examples of TV pro-grams that they watch at home, and to use thissystem to see whether they could obtain informa-tion in relation to those programs.
Results of thistest showed that all subjects could access informa-tion on desired programs.
In a subsequent ques-tionnaire, moreover, all subjects stated that?program selection was easy, and particularly therewas no need to know about hierarchical structureof program information.
?On the other hand, the test also revealed thatsome issues remain to be addressed in speech rec-ognition but that a favorable evaluation could beobtained from all subjects with regard to televisionoperations via spoken dialogue.
We are currentlyconducting even more detailed experiments todemonstrate the usefulness of a spoken dialogueinterface for television control and to examineproblem areas.ReferencesFACTS (FIPA Agent Communication Technologies andServices) A1 Work Package.
Available athttp://sharon.cselt.it/projects/facts-a1/.Hideki Sumiyoshi, Ichiro Yamada, and Nobuyuki Yagi.2002.
Multimedia Education System for InteractiveEducational Services.
Proceedings of IEEE Interna-tional Conference on Multimedia and Expo, CD-ROM.Kazuteru Komine, Nobuyuki Hiruma, Tatsuya Ishihara,Eiji Makino, Takao Tsuda, Takayuki Ito, and HaruoIsono.
2000.
Usability Evaluation of Remote Con-trollers for Digital Television receivers.
Proceedingsof SPIE, Human Vision and Electronic Imaging 5,Vol.
3959:458-467.Kazuteru Komine, Toshiya Morita, Jun Goto, and Nori-yoshi Uratani.
2002.
Analysis of Speech Utterancesin TV Program Selection Operations using a SpokenDialogue Interface.
Proceeding of Human InterfaceSymposium, No.3231:631-634.
(in Japanese).Toru Imai.
2000.
Progressive 2-pass Decoder for real-time Broadcast news captioning.
Proceedings ofICASSP-2000, Vol.3:1559-1562.Meta-character Description* any number of any words+ one word!
non-matching word{} optional[] mandatory() any order@ slots| or, delimiterSlot Examples@Moviename Blade Runner, My Fair Lady etc@Performer?snameHarrison Ford, Chizuru IkewakiNorika Fujiwara, etc@Genre Drama, Animation, News, etc@Time 10:20, Tomorrow, Tonight, etc@Broadcaststation nameNHK, TBS, WOWOW, etc@Direct opera-tionVolume, Channel, etc@Action Search, Watch, Turn up, etcInput statementI?d like to watch Blade Runner tonightPattern* [watch|search] * @Moviename * @TimeFigure 4:  Example of pattern matching
