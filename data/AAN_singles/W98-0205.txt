Visualization for Large Collections of Multimedia InformationDave HimmelGraphics and MultimediaApplied Research and TechnologyBoeing Shared Services GroupP.O.
Box 3707, MS 7L-43Seattle.
WA 98124david.p.himmel @boeine.comMark Greaves, Anne Kao.
Steve PoteetNatural Language ProcessingApplied Research and TechnologyBoeing Shared Services GroupP.O.
Box 3707, MS 7L-43Seattle, WA 98124mark.t.~reaves@boein_o.comanne.kao @boeing.comstephen.r.poteet@boeing.comAbstractOrganizations that make use of largeamounts of multimedia material(especially images and video) requireeasy access to such information.
Recentdevelopments in computer hardware andalgorithm design have made possiblecontent indexing of digital videoinformation and efficient display of 3Ddata representations.
This paperdescribes collaborative work betweenBoeing Applied Research & Technology(AR&T), Carnegie Mellon University(CMU), and the Battelle PacificNorthwest National Laboratories(PNNL).
to integrate media indexingwith computer visualization to achieveeffective content-based access to videoinformation.
Text metadata, representingvideo content, was extracted from theCMU Informedia system, processed byAR&T's text analysis software, andpresented to users via PNNL's Starlight3D visualization system.
This approachshows how to make multimediainformation accessible to a text-basedvisualization system, facilitating aglobalview of large collections of such data.We evaluated our approach by makingseveral experimental queries against alibrary of eight hours of videosegmented into several hundred "videoparagraphs."
We conclude that searchperformance of Inforrnedia wasenhanced in terms of ease of explorationby the integration with Starlight.33IntroductionBoeing uses very large collections of data inthe process of engineering and manufacturingcommercial jet airplanes and in deliveringcomplex military and space systems.
Thecompany also creates large amounts ofinformation in the form of manuals and otherdocuments obe delivered with these products.The need to control the cost of creating andaccessing this information is motivation fornew methods of indexing and searchingcomputerized digital data.In 1996, the Natural Language ProcessingGroup at Boeing AR&T began a collaborationwith PNNL to jointly develop the Starlightinformation visualization system.
AR&Tdeveloped the Text Processing Toolset (TPT)to perform indexing and querying operations inhigh-dimensional document spaces, and PNNLdeveloped software for 3D graphicspresentations.
Although Starlight has a richvisual presentation, it processes only text andstatic imagery, and lacks any inherentcapability for extracting content frommultimedia data.
Concurrently.
as part ofongoing research into digital libraries, theAR&T Multimedia Group began support of theCMU Informedia project and obtained ademonstration system for searching indexeddigital video information.
At the heart ofInformedia is a subsystem that creates textmetadata that is descriptive of digital videocontent.
This suggested awav to integrate thetwo systems.1 InformediaThe Informedia Project has established a largeon-line digital video library, incorporatingvideo assets from WQED/Pittsburgh.
Theproject is creating intelligent, automaticmechanisms for populating the library andallowing for its full-content and knowledge-based search and segment retrieval.
Ourapproach applies several techniques forcontent-based searching and video-sequenceretrieval.
Content is conveyed in both thenarrative (speech and language) and the image.Only by the collaborative interaction of image,speech, and natural-language understandingtechnology can we successfully populate,segment, index, and search diverse videocollections with satisfactory recall andprecision.The Informedia Project uses the Sphinx-IIspeech recognition system to transcribenarratives and dialogues automatically.
Theresulting transcript is then processed withmethods of natural anguage understanding toextract subjective descriptions and markpotential segment boundaries where significantsemantic changes occur.
Comparativedifference measures are used in processing thevideo to mark potential segment boundaries.Images with small lfistogram disparity areconsidered to be relatively equivalent.
Bydetecting significant changes in the weightedhistogram of each successive frame, asequence of images can be grouped into asegment.
This simple and robust method forsegmentation is fast and can detect 90% of thescene changes in video.Segment breaks produced by image processingare examined along with the boundariesidentified by the natural language processingof the transcript, and an improved set ofsegment boundaries are heuristically derived topartition the video library into sets ofsegments, or "video paragraphs.
"Figure 1 illustrates the video searchingfacilities of Informedia, which include:?
Filmstrip (lower-left of Figure 1) - Selectthumbnail mages to view video paragraph.?
Selective play (upper right of Figure 1) -Prev/next paragraph, prev/next term hit.?
Cursor browse - Abstracts and searchterms available in filmstrip and playwindow.?
Text query (upper left of Figure 1) - Termsparsed from natural anguage query.?
Skim (not shown) - View video in 10% ofnormal time.Figure 1 - Informedia Search ScreenThe reader can find more in-depth discussionsof the Informedia project and technologies inReferences 1-4.342 StarlightStarlight was originally developed as aninteractive information visualizationenvironment for the US Army Intelligence andSecurity Command (INSCOM).
It is designedto integrate several types of data (unstructuredand structured text documents, geographicinformation, and digital imagery') into a singleanalysis space for rapid comparison of contentand interrelationships (see reference 5).
In thissection, we will concentrate on the Starlighttext processing and indexing functions.A major problem with incorporating free-textdocuments into a visualization environment isthat each document must be coded so that itcan be clustered with other documents.
TheBoeing TPT is a prototype software ngine thatsupports automatic oding and categorizationof documents, concept-based querying, andvisualization over large text documentdatabases.
The TPT combines techniques fromstatistics, linear algebra, and computationallinguistics in order to take account of the totalcontext in which words occur in a givendocument or qUery; it statistically compares adocument context with similar contexts fromother documents in the database.
Through thistechnique, document sets can be represented ina way that supports visualization and analysisby the presentation components of Starlight.The TPT performs two functions: First.
itprovides a powerful and flexible mechanismfor concept-based searching over large textdatabases; second, it automatically assignsindividual text units to coordinates in a user-configurable 3D semantic space.
Both of thesefunctions derive from the TPT core techniqueof representing large numbers of text units aspoints in a higher dimensional space andperforming similarity calculations in thisspace.
Conceptually, the flow of data throughthe TPT is diagrammed in Figure 2:Process PrincipalTernn ~.n.~ Co m portentsFrequ enci es A nalys isCreate Measure@ Reduced @ DocumentRe prese ntati on Sim ila rity~\] ' - I  "--.-._..~,,~,,.
F"Ter.rr,?
D,:,o~ | Frequency' IVectorCt~ ~te Matrix Metr~ Oecomloostio~F ooo,mo q J LC?~?ne~ts._l "-'"--.i I"" Do~mer,~-1I h New Term I F Weigl-,t q ._,...._,--,----'J" I,_ Space ,..I ~- L M=" J \4LC?
?
?e u?'
Transform Vectors/#toi New Slo~?eOuch, --I /New Ten'n ISpace .JRanked Matoh UstCelcp~te  VectorD~tence~Figure 2 - TPT Processing Flow Diagram35Prior to TPT indexing, a text collection must bepreprocessed in three stages involving manualintervention: First, the text is divided into unitswith topical granularity that best correlates withthe expected query patterns.
The units can betitles, subject lines, abstracts, individualparagraphs or an entire document.
It can also bea caption or a piece of transcribed text from avideo.
Next, the text is "tokenized" intoindividual words and phrases.
Finally, a list of"'stopwords,'" or ignored terms, is chosen.
Theseinclude determiners (e.g., a, the), conjunctions(e.g., and, or), and relatives (e.g., what, which),and certain domain-specific terms.After preprocessing, operation of the TPTindexing system is automatic (see Figure 2).
Thesoftware builds a document/term matrix,performs everal transformation and dimensionreduction calculations, and stores outputmatrices in an object-oriented database for useby the Starlight visualization component.Users of Starlight can visually explore thetopical structure of a large text database bynavigating through a 3D topic space where eachitem is represented as a point in a scatterplot.Items with close visual proximity have similarcontent.
The TPT provides a selection ofdimensions (with associated topic words), anythree of which can potentially be selected foraxes of the scatterplot.Figure 3 shows a Starlight visualization screencontaining a 3D scatterplot of the 322-itemvideo metadata extracted from InformecUa: eachaxis is labeled with the dominant topicsmeasured by the TPT.
At the right of Figure 3 isan example query with results.Figure 3 - Starlight Visualization Screen363 In tegrat ionIntegration of the two systems required theinsertion of two processing steps, each involvingnew software development.
Figure 4 shows theflow of data in and between the two systems;new integration elements are shown as shadedboxes.
The two key elements are: (1) Extractvideo paragraph text metadata from Informedia,and (2) Display selected video paragraphs.CMU Informedia?
DigitizeMPEGVideo?
Create texttranscripts?
Ind~xvideoIBoeing AR&TTPTProcessingt .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i PNNL Starlight iit1\[ .
.~:~ ~:~.F igure 4 - Integrat ion of  In fo rmed ia  and Star l ight?
Video file name?
"In" and "Out" frames in the video file(for viewing the video paragraph)?
Title of video paragraph?
Abstract of video paragraph?
Transcript textExtraction of metadata is accomplished by a Cprogram that reads ASCII text and controlparameters from several flies in the Informediasystem and writes a collection of itemscompatible with TPT processing.
Each itemrepresents one video paragraph and includes thefollowing fields:37Display of video paragraphs occurs in thecontext of a web page containing a video viewerand the text transcript; Figure 5 shows anexample.
When the user selects a particulardocument within Starlight.
a browser displaysthe HTML page.
The browser was coded in Javaand the MPEG viewer is a MicrosoftActiveMovie control.
Each digital video file waskept intact, that is.
the video paragraphs werenot partitioned into separate files; rather,paragraphs are viewed by playing from thespecified "In" frame to the "Out" frame of theappropriate MPEG file.advantages.
Neither system was designed fornarrow, precise data querying, rather Starlightfeatures all-inclusive views and Informediafacilitates iterative, progressive narrowing offocus.
Motivation for integrating the systemswas twofold: Give Starlight access tomultimedia data, and investigate possibleadvantages of the global overview that Starlightcan bring to the Informedia database.We collected the following list of video titlesfrom diverse sources at Boeing:?
PBS Feature: 21st Century Jet (Parts 1-6)?
Boeing Education Network (BEN) Tutorial:Excel Charting?
Boeing Education Network (BEN) Lecture:Computer Graphics?
Business Realities with Phil Condit: Cashnow?
BTV News: Boeing Announces thePurchase of Rockwell?
Computer-Based Training: 757 Maintenance?
Maintenance Training: Airline Safety andYou?
Maintenance Training: 777 Doors andSlides/Rafts?
Everett Factor 3' Video: 767 Inboard LeadingEdgeAltogether, this material comprises about eighthours of viewing.
The digitized MPEG filesoccupy approximately 4.5GB of disk space andthe metadata (transcripts, thumbnail mages, andcross-reference fil s) is about 25MB in size.Figure 5 - Video Paragraph Display4 Exper imenta l  ResultsAlthough both Informedia and Starlightseparately exhibit powerful capabilities foraccessing large collections of data, it wasinteresting to speculate about synergisticThe video data was indexed by Informedia, thenwe passed the resulting metadata to Starlight asdescribed above.
Starlight presents the entirecollection of hundreds of video paragraphs as ascatterplot of points for viewing, which can becolor-coded by video title.
We immediatelyobserved that items with like colors tended tocluster together, verifying that TPT processingwas effective in bringing together topicallyrelated items.In an experiment to evaluate the further effectsof integration, we posed several queries to bothInformedia and Starlight, noted commonaltiesand differences in response, then used the global38view of Starlight o find other items with similarcontent and to discover additional search terms.After Starlight reported query "hits," weobserved the region in 3D space encompassedby the video file containing the most hits.
Usingthe cursor brush to see abstracts, we examinedTable 1 - Exper imenta l  ResultsInitial QueryHow do I use the emergency 6exits?What is fly by wire?
4Tell me about scientific 12visualization.What do you have on the Boeingmerger with Rockwell?InformediaHitsThe last three columns indicate a positive resultby showing additional video paragraphs andsearch terms relating to the initial query.
Theadditional items varied in degree of relevance,but the cost of the new information is low in thatonly a few seconds were required to examineeach.
This illustrates the capacity of theintegrated approach as an interactive tool forready access to video content.ConclusionThis effort clearly succeeded in the goal ofproviding access to multimedia content for theStarlight system.
We have also shown theusefullness of Starlight global visualization oftext metadata for video content.all items (of any color) within this region, andnoted interesting terms.
Because the axes weretopically labeled, additional terms were alsoavailable from the axis in the vicinity of thecluster.
Table 1 shows the results of thisexperiment.Starlight HitsTotal Same asInformedia5 44 4Other Items inStarlight RegionTotal Relevant10 830 08 7 26 123 3 12 3AdditionalSearchTopicsDiscoveredHazard,Safety, TestPlane,ETOPS,Flight deck,First flightChart, See,Data, MisfitCompany,Parts, People,WorkingTogether,Japanesesuppliers,AustriasuppliersThe concept of bringing text metadata intoStarlight is extensible to image, sound,animation, and other media, which suggestsfurther experimentation with other forms ofmultimedia information and methods ofgenerating metadata.Both Informedia indexing and Starlightprocessing require some manual intervention.
Inorder for these approaches to be efficient andcost-effective, we must develop fully automaticmethods for creating and processing textmetadata for multimedia information.
It may bepossible to do this by compromising the qualityof metadata (perhaps by using unedited speechrecognition from Informedia); a futureexperiment would be to attempt this compromiseand discover the effect on search performance.39AcknowledgmentsOur thanks go to Ricky Houghton and BryanMaher at the Carnegie Mellon UniversityInformedia project, and to John Risch, ScottDowson, Brian Moon, and Bruce Rex at theBattelle Pacific Northwest National LaboratoriesStarlight project for their excellent work leadingto this result.
The Boeing team also includesDean Billheimer, Andrew Booker, Fred Holt,Michelle Keim, Dan Pierce, and Jason Wu.References1.
Wactlar, Howard D., Kanade, Takeo, Smith,Michael A., and Stevens, Scott M. bztelligentAccess to Digital Video: bzformedia Project, IEEEComputer, May 1996 pp46-522.
Ravishankar.
Mosur K. Some Results on SearchComplexity vs Accuracy, Proceedings of DARPASpoken Systems Technology Workshop, Feb. 19973.
Christel, Michael G., Winkler, David B., andTaylor, Roy C. Mtdtimedia Abstractions for aDigital Video Librao', Proceedings of ACMDigital Libraries '97, Philadelphia, PA, July 1997.4.
Kanade, Takeo bnmersion into Visual Media:New Applications of Image Understanding.
IEEEExpert.
February 1996, pp73-80.5.
Risch, John, May, Richard, Dowson, Scott, andThomas, James A Virtual Environment forMultimedia b~telligence Data Anal, sis, IEEEComputer Graphics and Applications, November1997.40
