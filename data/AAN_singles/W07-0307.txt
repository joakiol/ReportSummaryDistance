Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 48?55,NAACL-HLT, Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsExperiments on the France Telecom 3000 Voice Agency corpus: academicresearch on an industrial spoken dialog system?Ge?raldine DamnatiFrance Te?le?com R&DTECH/SSTP/RVA2 av.
Pierre Marzin22307 Lannion Cedex 07, Francegeraldine.damnati@orange-ftgroup.comFre?de?ric Be?chet Renato De MoriLIAUniversity of AvignonAGROPARC, 339 ch.
des Meinajaries84911 Avignon Cedex 09, Francefrederic.bechet,renato.demori@univ-avignon.frAbstractThe recent advances in speech recognitiontechnologies, and the experience acquiredin the development of WEB or Interac-tive Voice Response interfaces, have facil-itated the integration of speech modulesin robust Spoken Dialog Systems (SDS),leading to the deployment on a large scaleof speech-enabled services.
With theseservices it is possible to obtain very largecorpora of human-machine interactions bycollecting system logs.
This new kinds ofsystems and dialogue corpora offer newopportunities for academic research whileraising two issues: How can academic re-search take profit of the system logs ofdeployed SDS in order to build the nextgeneration of SDS, although the dialoguescollected have a dialogue flow constrainedby the previous SDS generation?
On theother side, what immediate benefits canacademic research offer for the improve-ment of deployed system?
This paper ad-dresses these aspects in the framework ofthe deployed France Telecom 3000 VoiceAgency service.
?This work is supported by the 6th Framework ResearchProgramme of the European Union (EU), Project LUNA,IST contract no 33549.
The authors would like to thankthe EU for the financial support.
For more informationabout the LUNA project, please visit the project home-page,www.ist-luna.eu .1 IntroductionSince the deployment on a very large scale of theAT&T How May I Help You?
(HMIHY) (Gorin etal., 1997) service in 2000, Spoken Dialogue Sys-tems (SDS) handling a very large number of calls arenow developed from an industrial point of view.
Al-though a lot of the remaining problems (robustness,coverage, etc.)
are still spoken language process-ing research problems, the conception and the de-ployment of such state-of-the-art systems mainly re-quires knowledge in user interfaces.The recent advances in speech recognition tech-nologies, and the experience acquired in the devel-opment of WEB or Interactive Voice Response inter-faces have facilitated the integration of speech mod-ules in robust SDS.These new SDS can be deployed on a very largescale, like the France Telecom 3000 Voice Agencyservice considered in this study.
With these servicesit is possible to obtain very large corpora of human-machine interactions by collecting system logs.
Themain differences between these corpora and thosecollected in the framework of evaluation programslike the DARPA ATIS (Hemphill et al, 1990) or theFrench Technolangue MEDIA (Bonneau-Maynardet al, 2005) programs can be expressed through thefollowing dimensions:?
Size.
There are virtually no limits in theamount of speakers available or the timeneeded for collecting the dialogues as thou-sands of dialogues are automatically processedevery day and the system logs are stored.Therefore Dialog processing becomes similar48to Broadcast News processing: the limit is notin the amount of data available, but rather in theamount of data that can be manually annotated.?
Speakers.
Data are from real users.
The speak-ers are not professional ones or have no rewardfor calling the system.
Therefore their behav-iors are not biased by the acquisition protocols.Spontaneous speech and speech affects can beobserved.?
Complexity.
The complexity of the serviceswidely deployed is necessarily limited in orderto guarantee robustness with a high automationrate.
Therefore the dialogues collected are of-ten short dialogues.?
Semantic model.
The semantic model of suchdeployed system is task-oriented.
The inter-pretation of an utterance mostly consists in thedetection of application-specific entities.
In anapplication like the France Telecom 3000 VoiceAgency service this detection is performed byhand-crafted specific knowledge.The AT&T HMIHY corpus was the first large dia-logue corpus, obtained from a deployed system, thathas the above mentioned characteristics.
A servicelike the France Telecom 3000 Voice Agency servicehas been developed by a user interface developmentlab.
This new kind of systems and dialogue corporaoffer new opportunities for academic research thatcan be summarized as follows:?
How can academic research take profit of thesystem logs of deployed SDS in order to buildthe next generation of SDS, although the di-alogues collected have a dialogue flow con-strained by the previous SDS generation??
On the other side, what immediate benefits canacademic research offer for the improvementof deployed system, while waiting for the nextSDS generation?This paper addresses these aspects in the frame-work of the deployed FT 3000 Voice Agency ser-vice.
Section 3 presents how the ASR process canbe modified in order to detect and reject Out-Of-Domain utterances, leading to an improvement inthe understanding performance without modifyingthe system.
Section 4 shows how the FT 3000 cor-pus can be used in order to build stochastic modelsthat are the basis of a new Spoken Language Un-derstanding strategy, even if the current SLU systemused in the FT 3000 service is not stochastic.
Sec-tion 5 presents experimental results obtained on thiscorpus justifying the need of a tighter integration be-tween the ASR and the SLU models.2 Description of the France Telecom 3000Voice Agency corpusThe France Telecom 3000 (FT3000) Voice Agencyservice, the first deployed vocal service at FranceTelecom exploiting natural language technologies,has been made available to the general public in Oc-tober 2005.
FT3000 service enables customers toobtain information and purchase almost 30 differ-ent services and access the management of their ser-vices.
The continuous speech recognition system re-lies on a bigram language model.
The interpretationis achieved through the Verbateam two-steps seman-tic analyzer.
Verbateam includes a set of rules toconvert the sequence of words hypothesized by thespeech recognition engine into a sequence of con-cepts and an inference process that outputs an inter-pretation label from a sequence of concepts.2.1 Specificities of interactionsGiven the main functionalities of the application,two types of dialogues can be distinguished.
Someusers call FT 3000 to activate some services theyhave already purchased.
For such demands, usersare rerouted toward specific vocal services that arededicated to those particular tasks.
In that case, theFT3000 service can be seen as a unique automaticfrontal desk that efficiently redirects users.
For suchdialogues the collected corpora only contain the in-teraction prior to rerouting.
It can be observed in thatcase that users are rather familiar to the system andare most of the time regular users.
Hence, they aremore likely to use short utterances, sometimes justkeywords and the interaction is fast (between one ortwo dialogue turns in order to be redirected to thedemanded specific service).Such dialogues will be referred as transit dia-logues and represent 80% of the calls to the FT300049service.
As for the 20% other dialogues, referred toas other, the whole interaction is proceeded withinthe FT3000 application.
They concern users that aremore generally asking for information about a givenservice or users that are willing to purchase a newservice.
For these dialogues, the average utterancelength is higher, as well as the average number ofdialogue turns.other transit# dialogues 350 467# utterances 1288 717# words 4141 1454av.
dialogue length 3.7 1.5av.
utterance length 3.2 2.0OOV rate (%) 3.6 1.9disfluency rate (%) 2.8 2.1Table 1: Statistics on the transit and other dialoguesAs can be observed in table 1 the fact that usersare less familiar with the application in the other dia-logues implies higher OOV rate and disfluency rate1.An important issue when designing ASR and SLUmodels for such applications that are dedicated tothe general public is to be able to handle both naiveusers and familiar users.
Models have to be robustenough for new users to accept the service and inthe meantime they have to be efficient enough forfamiliar users to keep on using it.
This is the reasonwhy experimental results will be detailed on the twocorpora described in this section.2.2 User behavior and OOD utterancesWhen dealing with real users corpora, one has totake into account the occurrence of Out-Of-Domain(OOD) utterances.
Users that are familiar with a ser-vice are likely to be efficient and to strictly answerthe system?s prompts.
New users can have more di-verse reactions and typically make more commentsabout the system.
By comments we refer to suchcases when a user can either be surprised what amI supposed to say now?, irritated I?ve already saidthat or even insulting the system.
A critical aspectfor other dialogues is the higher rate of commentsuttered by users.
For the transit dialogues this phe-nomenon is much less frequent because users are fa-1by disfluency we consider here false starts and filled pausesmiliar to the system and they know how to be effi-cient and how to reach their goal.
As shown in ta-ble 2, 14.3% of the other dialogues contain at leastone OOD comment, representing an overall 10.6%of utterances in these dialogues.other transit# dialogues 350 467# utterances 1288 717# OOD comments 137 24OOD rate (%) 10.6 3.3dialogues with OOD (%) 14.3 3.6Table 2: Occurrence of Out-Of-Domain commentson the transit and other dialoguesSome utterances are just comments and some con-tain both useful information and comments.
In thenext section, we propose to detect these OOD se-quences and to take this phenomenon into accountin the global SLU strategy.3 Handling Out-Of-Domain utterancesThe general purpose of the proposed strategy is todetect OOD utterances in a first step, before enteringthe Spoken Language Understanding (SLU) mod-ule.
Indeed standard Language Models (LMs) ap-plied to OOD utterances are likely to generate erro-neous speech recognition outputs and more gener-ally highly noisy word lattices from which it mightnot be relevant and probably harmful to apply SLUmodules.Furthermore, when designing a general interac-tion model which aims at predicting dialogue statesas proposed in this paper, OOD utterances are asharmful for state prediction as can be an out-of-vocabulary word for the prediction of the next wordwith an n-gram LM.This is why we propose a new composite LM thatintegrates two sub-LMs: one LM for transcribing in-domain phrases, and one LM for detecting and delet-ing OOD phrases.
Finally the different SLU strate-gies proposed in this paper are applied only to theportions of signal labeled as in-domain utterances.503.1 Composite Language Model for decodingspontaneous speechAs a starting point, the comments have been manu-ally annotated in the training data in order to easilyseparate OOD comment segments from in-domainones.
A specific bigram language model is trainedfor these comment segments.
The comment LM wasdesigned from a 765 words lexicon and trained on1712 comment sequences.This comment LM, called LMOOD has been in-tegrated in the general bigram LMG.
Commentsequences have been parsed in the training corpusand replaced by a OOD tag.
This tag is added tothe general LM vocabulary and bigram probabilitiesP ( OOD |w) and P (w| OOD ) are trained alongwith other bigram probabilities (following the prin-ciple of a priori word classes).
During the decodingprocess, the general bigram LM probabilities and theLMOOD bigram probabilities are combined.3.2 Decision strategyGiven this composite LM, a decision strategy is ap-plied to select those utterances for which the wordlattice will be processed by the SLU component.This decision is made upon the one-best speechrecognition hypotheses and can be described as fol-lows:1.
If the one-best ASR output is a single OODtag, the utterance is simply rejected.2.
Else, if the one-best ASR output contains anOOD tag along with other words, those wordsare processed directly by the SLU component,following the argument that the word lattice forthis utterance is likely to contain noisy infor-mation.3.
Else (i.e.
no OOD tag in the one-best ASRoutput), the word-lattice is transmitted to fur-ther SLU components.It will be shown in the experimental section thatthis pre-filtering step, in order to decide whether aword lattice is worth being processed by the higher-level SLU components, is an efficient way of pre-venting concepts and interpretation hypothesis to bedecoded from an uninformative utterance.3.3 Experimental setup and evaluationThe models presented are trained on a corpus col-lected thanks to the FT3000 service.
It contains realdialogues from the deployed service.
The resultspresented are obtained on the test corpus describedin section 2.The results were evaluated according to 3 crite-ria: the Word Error Rate (WER), the Concept ErrorRate (CER) and the Interpretation Error Rate (IER).The CER is related to the correct translation of anutterance into a string of basic concepts.
The IER isrelated to the global interpretation of an utterancein the context of the dialogue service considered.Therefore this last measure is the most significantone as it is directly linked to the performance of thedialogue system.IER all other transitsize 2005 717 1288LMG 16.5 22.3 13.0LMG + OOD 15.0 18.6 12.8Table 3: Interpretation error rate according to theLanguage ModelTable 3 presents the IER results obtained with thestrategy strat1 with 2 different LMs for obtainingW?
: LMG which is the general word bigram model;and LMG + OOD which is the LM with the OOD com-ment model.
As one can see, a very significant im-provement, 3.7% absolute, is achieved on the otherdialogues, which are the ones containing most ofthe comments.
For the transit dialogues a small im-provement (0.2%) is also obtained.4 Building stochastic SLU strategies4.1 The FT3000 SLU moduleThe SLU component of the FT3000 service consid-ered in this study contains two stages:1. the first one translates a string of words W =w1, .
.
.
, wn into a string of elementary con-cepts C = c1, .
.
.
, cl by means of hand-writtenregular grammars;2. the second stage is made of a set of about 1600inference rules that take as input a string of con-cepts C and output a global interpretation ?
of51a message.
These rules are ordered and thefirst match obtained by processing the conceptstring is kept as the output interpretation.These message interpretations are expressed by anattribute/value pair representing a function in the vo-cal service.The models used in these two stages are manuallydefined by the service designers and are not stochas-tic.
We are going now to present how we can use acorpus obtained with such models in order to definean SLU strategy based on stochastic processes.4.2 Semantic knowledge representationThe actual FT3000 system includes semantic knowl-edge represented by hand-written rules.
These rulescan also be expressed in a logic form.
For this rea-son, some basic concepts are now described with thepurpose of showing how logic knowledge has beenintegrated in a first probabilistic model and how itcan be used in a future version in which optimal poli-cies can be applied.The semantic knowledge of an application is aknowledge base (KB) containing a set of logic for-mulas.
Formulas return truth and are constructedusing constants which represent objects and may betyped, variables, functions which are mappings fromtuples of objects to objects and predicates whichrepresent relations among objects.
An interpretationspecifies which objects, functions and relations inthe domain are represented by which symbol.
Basicinference problem is to determine whether KB |= Fwhich means that KB entails a formula F .In SLU, interpretations are carried on by bindingvariables and instantiating objects based on ASR re-sults and inferences performed in the KB.
Hypothe-ses about functions and instantiated objects are writ-ten into a Short Term Memory (STM).A user goal is represented by a conjunction ofpredicates.
As dialogue progresses, some predi-cates are grounded by the detection of predicate tags,property tags and values.
Such a detection is madeby the interpretation component.
Other predicatesare grounded as a result of inference.
A user goal Gis asserted when all the atoms of its conjunction aregrounded and asserted true.Grouping the predicates whose conjunction is thepremise for asserting a goal Gi is a process that goesthrough a sequence of states: S1(Gi), S2(Gi), .
.
.Let ?ik be the content of the STM used for as-serting the predicates grounded at the k-th turn of adialogue.
These predicates are part of the premisefor asserting the i-th goal.Let Gi be an instance of the i-th goal asserted aftergrounding all the predicates in the premise.
?ik can be represented by a composition from apartial hypothesis ?ik?
1 available at turn k ?
1, themachine action ak?1 performed at turn k ?
1 andthe semantic interpretation ?ik i.e.
:?ik = ?
(?ik, ak?1,?ik?1)Sk(Gi) is an information state that can lead to auser?s goal Gi and ?ik is part of the premise for as-serting Gi at turn k.State probability can be written as follows:P (Sk(Gi)|Yk) = P(Gi|?ik)P(?ik|Yk) (1)where P(Gi|?ik)is the probability that Gi is thetype of goal that corresponds to the user interac-tion given the grounding predicates in ?ik.
Yk is theacoustic features of the user?s utterance at turn k.Probabilities of states can be used to define a be-lief of the dialogue system.A first model allowing multiple dialog state se-quence hypothesis is proposed in (Damnati et al,2007).
In this model each dialog state correspondto a system state in the dialog automaton.
In orderto deal with flexible dialog strategies and followingprevious work (Williams and Young, 2007), a newmodel based on a Partially Observable Markov De-cision Process (POMDP) is currently studied.If no dialog history is taken into account,P(?ik|Y)comes down to P(?ik|Y), ?ik being asemantic attribute/value pair produced by the Ver-bateam interpretation rules.The integration of this semantic decoding processin the ASR process is presented in the next section.5 Optimizing the ASR and SLU processesWith the stochastic models proposed in section 4,different strategies can be built and optimized.
Weare interested here in the integration of the ASR andSLU processes.
As already shown by previous stud-ies (Wang et al, 2005), the traditional sequential ap-proach that first looks for the best sequence of words52W?
before looking for the best interpretation ??
of anutterance is sub-optimal.
Performing SLU on a wordlattice output by the ASR module is an efficient wayof integrating the search for the best sequence ofwords and the best interpretation.
However there arereal-time issues in processing word lattices in SDS,and therefore they are mainly used in research sys-tems rather than deployed systems.In section 3 a strategy is proposed for selectingthe utterances for which a word lattice is going to beproduced.
We are going now to evaluate the gain inperformance that can be obtained thanks to an inte-grated approach on these selected utterances.5.1 Sequential vs. integrated strategiesTwo strategies are going to be evaluated.
The firstone (strat1) is fully sequential: the best sequence ofword W?
is first obtained withW?
= argmaxWP (W |Y )Then the best sequence of concepts C?
is obtainedwithC?
= argmaxCP (C|W?
)Finally the interpretation rules are applied to C?
inorder to obtain the best interpretation ?
?.The second strategy (strat2) is fully integrated: ?
?is obtained by searching at the same time for W?
andC?
and ??.
In this case we have:??
= argmaxW,C,?P (?|C)P (C|W )P (W |Y )The stochastic models proposed are implementedwith a Finite State Machine (FSM) paradigm thanksto the AT&T FSM toolkit (Mohri et al, 2002).Following the approach described in (Raymondet al, 2006), the SLU first stage is implemented bymeans of a word-to-concept transducer that trans-lates a word lattice into a concept lattice.
This con-cept lattice is rescored with a Language Model onthe concepts (also encoded as FSMs with the AT&TGRM toolkit (Allauzen et al, 2003)).The rule database of the SLU second stage is en-coded as a transducer that takes as input conceptsand output semantic interpretations ?.
By applyingthis transducer to an FSM representing a concept lat-tice, we directly obtain a lattice of interpretations.The SLU process is therefore made of the com-position of the ASR word lattice, two transducers(word-to-concepts and concept-to-interpretations)and an FSM representing a Language Model on theconcepts.
The concept LM is trained on the FT3000corpus.This strategy push forward the approach devel-opped at AT&T in the How May I Help You?
(Gorinet al, 1997) project by using richer semantic mod-els than call-types and named-entities models.
Moreprecisely, the 1600 Verbateam interpretation rulesused in this study constitute a rich knowledge base.By integrating them into the search, thanks to theFSM paradigm, we can jointly optimize the searchfor the best sequence of words, basic concepts, andfull semantic interpretations.For the strategy strat1 only the best path is kept inthe FSM corresponding to the word lattice, simulat-ing a sequential approach.
For strat2 the best inter-pretation ??
is obtained on the whole concept lattice.error WER CER IERstrat1 40.1 24.4 15.0strat2 38.2 22.5 14.5Table 4: Word Error Rate (WER), Concept ErrorRate (CER) and Interpretation Error Rate (IER) ac-cording to the SLU strategyThe comparison among the two strategies is givenin table 4.
As we can see a small improvement is ob-tained for the interpretation error rate (IER) with theintegrated strategy (strat2).
This gain is small; how-ever it is interesting to look at the Oracle IER thatcan be obtained on an n-best list of interpretationsproduced by each strategy (the Oracle IER being thelowest IER that can be obtained on an n-best list ofhypotheses with a perfect Oracle decision process).This comparison is given in Figure 1.
As one cansee a much lower Oracle IER can be achieved withstrat2.
For example, with an n-best list of 5 interpre-tations, the lowest IER is 7.4 for strat1 and only 4.8for strat2.
This is very interesting for dialogue sys-tems as the Dialog Manager can use dialogue con-text information in order to filter such n-best lists.53456789101  2  3  4  5  6  7  8  9  10OracleIERsize of the n-best list of interpretationssequential search (strat1)integrated search (strat2)Figure 1: Oracle IER according to an n-best list of interpretations for strategies strat1 and strat25.2 Optimizing WER, CER and IERTable 4 also indicates that the improvements ob-tained on the WER and CER dimensions don?t al-ways lead to similar improvements in IER.
This isdue to the fact that the improvements in WER andCER are mostly due to a significant reduction in theinsertion rates of words and concepts.
Because thesame weight is usually given to all kinds of errors(insertions, substitutions and deletions), a decreasein the overall error rate can be misleading as inter-pretation strategies can deal more easily with inser-tions than deletions or substitutions.
Therefore thereduction of the overall WER and CER measures isnot a reliable indicator of an increase of performanceof the whole SLU module.level 1-best Oracle hyp.WER 33.7 20.0CER 21.2 9.7IER 13.0 4.4Table 5: Error rates on words, concepts and interpre-tations for the 1-best hypothesis and for the Oraclehypothesis of each levelThese results have already been shown for WERby previous studies like (Riccardi and Gorin, 1998)IERfrom word Oracle 9.8from concept Oracle 7.5interpretation Oracle 4.4Table 6: IER obtained on Oracle hypotheses com-puted at different levels.or more recently (Wang et al, 2003).
They are il-lustrated by Table 5 and Table 6.
The figures shownin these tables were computed on the subset of utter-ances that were passed to the SLU component.
Ut-terances for which an OOD has been detected arediscarded.
In Table 5 are displayed the error ratesobtained on words, concepts and interpretations bothon the 1-best hypothesis and on the Oracle hypothe-sis (the one with the lowest error rate in the lattice).These Oracle error rates were obtained by lookingfor the best hypothesis in the lattice obtained at thecorresponding level (e.g.
looking for the best se-quence of concepts in the concept lattice).
As for Ta-ble 6, the mentioned IER are the one obtained whenapplying SLU to the Oracles hypotheses computedfor each level.
As one can see the lowest IER (4.4)is not obtained on the hypotheses with the lowestWER (9.8) or CER (7.5).546 ConclusionThis paper presents a study on the FT3000 corpuscollected from real users on a deployed general pub-lic application.
Two problematics are addressed:How can such a corpus be helpful to carry on re-search on advanced SLU methods eventhough it hasbeen collected from a more simple rule-based dia-logue system?
How can academic research trans-late into short-term improvements for deployed ser-vices?
This paper proposes a strategy for integratingadvanced SLU components in deployed services.This strategy consists in selecting the utterances forwhich the advanced SLU components are going tobe applied.
Section 3 presents such a strategy thatconsists in filtering Out-Of-Domain utterances dur-ing the ASR first pass, leading to significant im-provement in the understanding performance.For the SLU process applied to in-domain utter-ances, an integrated approach is proposed that lookssimultaneously for the best sequence of words, con-cepts and interpretations from the ASR word lat-tices.
Experiments presented in section 5 on realdata show the advantage of the integrated approachtowards the sequential approach.
Finally, section 4proposes a unified framework that enables to definea dialogue state prediction model that can be appliedand trained on a corpus collected through an alreadydeployed service.ReferencesCyril Allauzen, Mehryar Mohri, and Brian Roark.
2003.Generalized algorithms for constructing statistical lan-guage models.
In 41st Annual Meeting of the Asso-ciation for Computational Linguistics (ACL?03), Sap-poro, Japan.Helene Bonneau-Maynard, Sophie Rosset, Christelle Ay-ache, Anne Kuhn, and Djamel Mostefa.
2005.
Se-mantic annotation of the french media dialog corpus.In Proceedings of the European Conference on SpeechCommunication and Technology (Eurospeech), Lis-boa, Portugal.Geraldine Damnati, Frederic Bechet, and RenatoDe Mori.
2007.
Spoken Language Understandingstrategies on the France Telecom 3000 voice agencycorpus.
In Proceedings of the International Con-ference on Acoustics, Speech and Signal Processing(ICASSP), Honolulu, USA.A.
L. Gorin, G. Riccardi, and J.H.
Wright.
1997.
HowMay I Help You ?
In Speech Communication, vol-ume 23, pages 113?127.Charles T. Hemphill, John J. Godfrey, and George R.Doddington.
1990.
The ATIS spoken language sys-tems pilot corpus.
In Proceedings of the workshop onSpeech and Natural Language, pages 96?101, HiddenValley, Pennsylvania.Mehryar Mohri, Fernando Pereira, and Michael Ri-ley.
2002.
Weighted finite-state transducers inspeech recognition.
Computer, Speech and Language,16(1):69?88.Christian Raymond, Frederic Bechet, Renato De Mori,and Geraldine Damnati.
2006.
On the use of finitestate transducers for semantic interpretation.
SpeechCommunication, 48,3-4:288?304.Giuseppe Riccardi and Allen L. Gorin.
1998.
Languagemodels for speech recognition and understanding.
InProceedings of the International Conference on Spo-ken Langage Processing (ICSLP), Sidney, Australia.Ye-Yi Wang, A. Acero, and C. Chelba.
2003.
Is worderror rate a good indicator for spoken language under-standing accuracy?
In Automatic Speech Recognitionand Understanding workshop - ASRU?03, St. Thomas,US-Virgin Islands.Ye-Yi Wang, Li Deng, and Alex Acero.
2005.
Spokenlanguage understanding.
In Signal Processing Maga-zine, IEEE, volume 22, pages 16?31.Jason D. Williams and Steve Young.
2007.
Partially ob-servable markov decision processes for spoken dialogsystems.
Computer, Speech and Language, 21:393?422.55
