Spoken Language Recognition and UnderstandingVictor Zue and Lynette HirschmanSpoken Language Systems GroupLaboratory for Computer ScienceMassachusetts Institute of TechnologyCambridge, Massachusetts 021391.
PROJECT GOALSThe goal of this research is to demonstrate spoken lan-guage systems in support of interactive problem solving.The MIT spoken language system combines SUMMIT, asegment-based speech recognition system, and TINA, aprobabilistic natural anguage system, to achieve speechunderstanding.
The system accepts continuous peechinput and handles multiple speakers without explicitspeaker enrollment.
It engages in interactive dialoguewith the user, providing output in the form of tabularand graphical displays, as well as spoken and written re-sponses.
We have demonstrated the system on severalapplications, including travel planning and direction as-sistance; it has also been ported to several anguages,including Japanese and French.2.
RECENT RESULTS?
Improved recognition and understanding:Reduced word error rate by over 30% through theuse of improved phonetic modeling and more pow-erful N-gram language models; improved languageunderstanding by 35% making use of stable corpusof annotated ata; other improvements include theability to generate a word lattice.?
Real-time~ software-only SLS system: Devel-oped near (1.5 times) real-time software only ver-sion of SUMMIT, using MFCC and fast match in themixture Gaussian computation, running on a DECAlpha or an HP735 workstation.?
Evaluation of interactive dialogue: Continuedstudy of interactive dialogue, focusing on error de-tection and recovery issues; supported multi-sitelogfile evaluation through distribution of portablelogfile evaluation software and instructions.?
On-line ATIS: Applied spoken language technologyto access on-line dynamic air travel system via Com-puserve; the demonstration system, extending theMIT ATIS system, provides an interactive language-based interface to find flights, make reservations andshow seating assignments.?
Multi- l ingual VOYAGER: Ported SUMMIT andTINA to Japanese, to create a speaker-independentbilingual VOYAGER; English and Japanese usethe same semantic frame representation and thegeneration mechanism is modular and language-independent, supporting a system with indepen-dently toggled input and output languages.?
Support  to DARPA SLS community:  Chairedthe ISAT Study Group on Multi-Modal Language-Based Systems; continued to chair MADCOW co-ordinating multi-site data collection, including in-troduction of experimental end-to-end evaluation;chaired first Spoken Language Technology Work-shop at MIT, Jan. 20-22, 1993.3.
FUTURE PLANS?
Large vocabulary spoken language systems:Explore realistic large vocabulary spoken languageapplications, (e.g., on-line air travel planning), in-cluding issues of system portability and language-based interface design.?
Multi l ingual knowledge-base access: Use auniform language-independent semantic frame tosupport extensions of VOYAGER and ATIS to other(more inflected) languages, e.g., French, German,Italian, and Spanish.?
Interfacing speech and language: Investigateloosely and tightly coupled integration, using wordlattice and TINA-2'S layered bigram model.?
Dialogue modeling: Incorporate dialogue state-specific language models to improve recognitionin interactive dialogue, collect and study data onhuman-human i teractive problem-solving, and ex-plore alternative generation and partial understand-ing strategies.?
Language modeling: Investigate low-perplexitylanguage models and the capture of higher level in-formation, e.g., semantic lass, phrase level infor-mation, and automatic grammar acquisition.401
