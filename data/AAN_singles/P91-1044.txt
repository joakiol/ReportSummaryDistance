Action representation for NL instructionsBarbara Di Eugenio*Department  of Computer  and Informat ion ScienceUniversity of PennsylvaniaPhi ladelphia, PAdieugeni~l inc.c is .upenn.edu1 Introduct ionThe need to represent actions arises in many differ-ent areas of investigation, such as philosophy \[5\], se-mantics \[10\], and planning.
In the first two areas,representations are generally developed without anycomputational concerns.
The third area sees actionrepresentation mainly as functional to the more gen-eral task of reaching a certain goal: actions have of-ten been represented by a predicate with some argu-ments, such as move(John, block1, room1, room2),augmented with a description of its effects and ofwhat has to be true in the world for the action tobe executable \[8\].
Temporal relations between ac-tions \[1\], and the generation relation \[12\], \[2\] havealso been explored.However, if we ever want to be able to give in-structions in NL to active agents, such as robots andanimated figures, we should start looking at the char-acteristics of action descriptions in NL, and devisingformalisms that should be able to represent thesecharacteristics, at least in principle.
NL action de-scriptions axe complex, and so are the inferences theagent interpreting them is expected to draw.As far as the complexity of action descriptionsgoes, consider:Ex.
1 Using a paint roller or brush, apply paste tothe wall, starting at the ceiling line and pasting downa few feet and covering an area a few inches widerthan the width of the fabric.The basic description apply paste to the wall isaugmented with the instrument to be used and withdirection and eztent modifiers.
The richness of thepossible modifications argues against representingactions as predicates having a fixed number of ar-guments.Among the many complex inferences that an agentinterpreting instructions i assumed to be able todraw, one type is of particular interest to me, namely,the interaction between the intentional description ofan action - which I'll call the goal or the why- and*This research was supported by DARPA grant no.
N0014-85 -K0018.333its executable counterpart - the how 1.
Consider:Ex.
2 a) Place a plank between two laddersto create a simple scaffold.b) Place a plank between two ladders.In both a) and b), the action to be executedis aplace a plank between two ladders ~.
However,Ex.
2.b would be correctly interpreted by placing theplank anywhere between the two ladders: this showsthat in a) the agent must be inferring the proper po-sition for the plank from the expressed why "to createa simple scaffoldLMy concern is with representations that allowspecification of both bow's and why's, and with rea-soning that allows inferences such as the above tobe made.
In the rest of the paper, I will argue thata hybrid representation formalism is best suited forthe knowledge I need to represent.2 A hybrid action representa-t ion formalismAs I have argued elsewhere based on analysis of nat-urally occurring data \[14\], \[7\], actions - action types,to be precise - must be part of the underlying ontol-ogy of the representation formalism; partial actiondescriptions must be taken as basic; not only mustthe usual participants in an action such as agent orpatient be represented, but also means, manner, di-rection, extent etc.Given these basic assumptions, it seems thatknowledge about actions falls into the following twocategories:1.
Terminological knowledge about an action-type: its participants and its relation to otheraction-types that it either specializes or ab-stracts - e.g.
slice specializes cut, loosen a screwcarefully specializes loosen a screw.2.
Non-terminological knowledge.
First of all,knowledge about the effects expected to occur1V~ta.t executable means  is debatable:  see for example  \[12\],p. 63ff.when an action of a given type is performed.Because effects may occur during the perfor-mance of an action, the basic aspectua\] profileof the action-type \[11\] should also be included.Clearly, this knowledge is not terminological; inEx.
3 Turn the screw counterclockwise butdon't loosen it completely.the modifier not ... completely does not affectthe fact that don't loosen it completely is a loos-ening action: only its default culmination con-dition is affected.Also, non-terminological knowledge must in-clude information about relations betweenaction-types: temporal, generation, enablement,and testing, where by testing I refer to the rela-tion between two actions, one of which is a teston the outcome or execution of the other.The generation relation was introduced by Gold-man in \[9\], and then used in planning by \[1\], \[12\],\[2\]: it is particularly interesting with respect othe representation f how's and why's, becauseit appears to be the relation holding betweenan intentional description of an action and itsexecutable counterpart - see \[12\].This knowledge can be seen as common.senseplanning knowledge, which includes facts suchas to loosen a screw, you have to turn it coun-terelockwise, but not recipes to achieve a certaingoal \[2\], such as how to assemble a piece of fur-niture.The distinction between terminological nd non-terminological knowledge was put forward in the pastas the basis of hybrid KR system, such as those thatstemmed from the KL-ONE formalism, for exampleKRYPTON \[3\], KL-TWO \[13\], and more recentlyCLASSIC \[4\].
Such systems provide an assertionalpart, or A-Box, used to assert facts or beliefs, and aterminological part, or T-Box, that accounts for themeaning of the complex terms used in these asser-tions.In the past however, it has been the case thatterms defined in the T-box have been taken to cor-respond to noun phrases in Natural Language, whileverbs are mapped onto the predicates used in the as-sertions tored in the A-box.
What I am proposinghere is that, to represent action-types, verb phrasestoo have to map to concepts in the T-Box.
I am advo-cating a 1:1 mapping between verbs and action-typenames.
This is a reasonable position, given that theentities in the underlying ontology come from NL.The knowledge I am encoding in the T-box is atthe linguistic level: an action description is composedof a verb, i.e.
an action-type name, its argumentsand possibly, some modifiers.
The A-Box containsthe non-terminological knowledge delineated above.I have started using CLASSIC to represent actions:it is clear that I need to tailor it to my needs, because334it has limited assertional capacities.
I also want toexplore the feasibility of adopting techniques similarto those used in CLASP \[6\] to represent what I calledcommon-sense planning knowledge: CLASP buildson top of CLASSIC to represent actions, plans andscenarios.
However, in CLASP actions are still tra-ditionally seen as STRIPS-like operators, with pre-and post-conditions: as I hope to have shown, thereis much more to action descriptions than that.References\[1\] J. Allen.
Towards a general theory of action andtime.
Artificial Intelligence, 23:123-154, 1984.\[2\] C. Balkanski.
Modelling act-type relations in collab-orative activity.
Technical Report TR-23-90, Cen-ter for Research in Computing Technology, HarvardUniversity, 1990.\[3\] R. Brachman, R.Fikes, and H. Levesque.
KRYP-TON: A Functional Approach to Knowledge Repre-sentation.
Technical Report FLAIR 16, FairchildLaboratories for Artificial Intelligence, Palo Alto,California, 1983.\[4\] R. Bra~hman, D. McGninness, P. Patel-Schneider,L.
Alperin Resnick, and A. Borgida.
Living withCLASSIC: when and how to use a KL-ONE-IIke lan-guage.
In J. Sowa, editor, Principles of SemanticNetworks, Morgan Kaufmann Publishers, Inc., 1990.\[5\] D. Davidson.
Essays on Actions and Events.
OxfordUniversity Press, 1982.\[6\] P. Devanbu and D. Litman.
Plan-Based Termino-logical Reasoning.
1991.
To appear in Proceedingsof KR 91, Boston.\[7\] B.
Di Eugenio.
A language for representing actiondescriptions.
Preliminary Thesis Proposal, Univer-sity of Pennsylvania, 1990.
Manuscript.\[8\] R. Fikes and N. Nilsson.
A new approach to theapplication of theorem proving to problem solving.Artificial Intelligence, 2:189-208, 1971.\[9\] A. Goldman.
A Theory of Human Action.
PrincetonUniversity Press, 1970.\[10\] R. Jackendoff.
Semantics and Cognition.
CurrentStudies in Linguistics Series, The MIT Press, 1983.\[11\] M. Moens and M. Steedman.
Temporal Ontologyand Temporal Reference.
Computational Linguis-tics, 14(2):15-28, 1988.\[12\] M. Pollack.
Inferring domain plans in question-answering.
PhD thesis, University of Pennsylvania,1986.\[13\] M. VilMn.
The Restricted Language Architectureof a Hybrid Representation System.
In IJCAI-85,1985.\[14\] B. Webber and B.
Di Eugenio.
Free Adjuncts inNatural Language Instructions.
In Proceedings Thir-teen& International Conference on ComputationalLinguistics, COLING 90, pages 395-400, 1990.
