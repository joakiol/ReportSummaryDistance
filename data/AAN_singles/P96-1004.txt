Morphological Cues for Lexical SemanticsMarc LightSeminar ffir SprachwissenschaftUniversitgt TfibingenWi lhelmstr .
113D-72074 TfibingenGermanylight~sf s. nph?l, uni-tuebingen, deAbst rac tMost natural language processing tasks re-quire lexical semantic information.
Au-tomated acquisition of this informationwould thus increase the robustness andportability of NLP systems.
This pa-per describes an acquisition method whichmakes use of fixed correspondences be-tween derivational affixes and lexical se-mantic information.
One advantage ofthismethod, and of other methods that relyonly on surface characteristics of language,is that the necessary input is currentlyavailable.1 Introduct ionSome natural anguage processing (NLP) tasks canbe performed with only coarse-grained semantic in-formation about individual words.
For example,a system could utilize word frequency and a wordcooccurrence matrix in order to perform informa-tion retrieval.
However, many NLP tasks require atleast a partial understanding of every sentence orutterance in the input and thus have a much greaterneed for lexical semantics.
Natural language gen-eration, providing a natural anguage front end toa database, information extraction, machine trans-lation, and task-oriented dialogue understanding allrequire lexical semantics.
The lexical semantic in-formation commonly utilized includes verbal argu-ment structure and selectional restrictions, corre-sponding nominal semantic lass, verbal aspectualclass, synonym and antonym relationships betweenwords, and various verbal semantic features uch ascausation and manner.Machine readable dictionaries do not includemuch of this information and it is difficult and timeconsuming to encode it by hand.
As a consequence,current NLP systems have only small lexicons andthus can only operate in restricted omains.
Auto-mated methods for acquiring lexical semantics couldincrease both the robustness and the portability ofsuch systems.
In addition, such methods might pro-vide inSight into human language acquisition.After considering different possible approaches toacquiring lexicM semantic information, this paperconcludes that a "surface cueing" approach is cur-rently the most promising.
It then introduces mor-phological cueing, a type of surface cueing, and dis-cusses an implementation.
It concludes by evalu-ating morphological cues with respect o a list ofdesiderata for good surface cues.2 Approaches to Acquir ing LexicalSemanticsOne intuitively appealing idea is that humans ac-quire the meanings of words by relating them tosemantic representations resulting from perceptualor cognitive processing.
For example, in a situationwhere the father says Kim is throwing the ball andpoints at Kim who is throwing the ball, a child mightbe able learn what throw and ball mean.
In thehuman language acquisition literature, Grimshaw(1981) and Pinker (1989) advocate this approach;others have described partial computer implementa-tions: Pustejovsky (1988) and Siskind (1990).
How-ever, this approach cannot yet provide for the auto-matic acquisition of lexical semantics for use in NLPsystems, because the input required must be handcoded: no current artificial intelligence system hasthe perceptual nd cognitive capabilities required toproduce the needed semantic representations.Another approach would be to use the semanticsof surrounding words in an utterance to constrainthe meaning of an unknown word.
Borrowing anexample from Pinker (1994), upon hearing I glippedthe paper to shreds, one could guess that the mean-ing of glib has something to do with tearing.
Sim-ilarly, one could guess that filp means somethinglike eat upon hearing I filped the delicious sandwichand now I'm full.
These guesses are cued by themeanings of paper, shreds, sandwich, delicious, full,and the partial syntactic analysis of the utterancesthat contain them.
Granger (1977), Berwick (1983),and Hastings (1994) describe computational systems25that implement his approach.
However, this ap-proach is hindered by the need for a large amountof initial lexical semantic information and the needfor a robust natural anguage understanding systemthat produces emantic representations a output,since producing this output requires precisely thelexical semantic information the system is trying toacquire.A third approach does not require any semanticinformation related to perceptual input or the in-put utterance.
Instead it makes use of fixed cor-respondences between surface characteristics of lan-guage input and lexical semantic information: sur-face characteristics serve as cues for lexical seman-tics of the words.
For example, if a verb is seenwith a noun phrase subject and a sentential comple-ment, it often has verbal semantics involving spa-tial perception and cognition, e.g., believe, think,worry, and see (Fisher, Gleitman, and Gleitman,1991; Gleitman, 1990).
Similarly, the occurrenceof a verb in the progressive tense can be used asa cue for the non-stativeness of the verb (Dorrand Lee, 1992); stative verbs cannot appear in theprogress tense ( e.g.,* Mary is loving her new shoes).Another example is the use of patterns such asNP,  NP  * ,and otherNP to find lexical semanticinformation such as hyponym (Hearst, 1992).
Tem-ples, treasuries, and other important civic buildingsis an example of this pattern and from it the infor-mation that temples and treasuries are types of civicbuildings would be cued.
Finally, inducing lexicalsemantics from distributional data (e.g., (Brown etal., 1992; Church et al, 1989)) is also a form of sur-face cueing.
It should be noted that the set of fixedcorrespondences between surface characteristics andlexical semantic information, at this point, have tobe acquired through the analysis of the researcher--the issue of how the fixed correspondences can beautomatically acquired will not be addressed here.The main advantage of the surface cueing ap-proach is that the input required is currently avail-able: there is an ever increasing supply of on-line text, which can be automatically part-of-speechtagged, assigned shallow syntactic structure by ro-bust partial parsing systems, and morphologicallyanalyzed, all without any prior lexical semantics.A possible disadvantage of surface cueing is thatsurface cues for a particular piece oflexical semanticsmight be difficult to uncover or they might not existat all.
In addition, the cues might not be presentfor the words of interest.
Thus, it is an empiricalquestion whether easily identifiable abundant sur-face cues exist for the needed lexical semantic infor-mation.
The next section explores the possibility ofusing derivational affixes as surface cues for lexicalsemantics.263 Morpho log ica l  Cues  fo r  Lex ica lSemant ic  In fo rmat ionMany derivational affixes only apply to bases withcertain semantic characteristics and only producederived forms with certain semantic haracteristics.For example, the verbal prefix un- applies to telicverbs and produces telic derived forms.
Thus, it ispossible to use un- as a cue for telicity.
By search-ing a sufficiently large corpus we should be able toidentify a number of telic verbs.
Examples from theBrown corpus include clasp, coil, fasten, lace, andscrew.A more implementation-oriented description ofthe process is the following: (i) analyze affixes byhand to gain fixed correspondences between affix andlexical semantic information (ii) collect a large cor-pus of text, (iii) tag it with part-of-speech tags, (iv)morphologically analyze its words, (v) assign wordsenses to the base and the derived forms of theseanalyses, and (vi) use this morphological structureplus fixed correspondences to assign semantics toboth the base senses and the derived form senses.Step (i) amounts to doing a semantic analysis of anumber of affixes the goal of which is to find se-mantic generalizations for an affix that hold for alarge percentage of its instances.
Finding the rightgeneralizations and stating them explicitly can betime consuming but is only performed once.
Taggingthe corpus is necessary to make word sense disam-biguation and morphological nalysis easier.
Wordsense disambiguation is necessary because one needsto know which sense of the base is involved in aparticular derived form, more specifically, to whichsense should one assign the feature cued by the affix.For example, stress can be either a noun the stresson the third syllable or a verb the advisor stressedthe importance of finishing quickly.
Since the suffix-ful applies to nominal bases, only a noun reading ispossible as the stem of stressful and thus one wouldattach the lexical semantics cued by -ful to the nounsense.
However, stress has multiple readings evenas a noun: it also has the reading exemplified bythe new parent was under a lot of stress.
Only thisreading is possible for stressful.In order to produce the results presented in thenext section, the above steps were performed as fol-lows.
A set of 18 affixes were analyzed by hand pro-viding the fixed correspondences between cue andsemantics.
The cued lexical semantic informationwas axiomatized using Episodic Logic (Hwang andSchubert, 1993), a situation-based xtension of stan-dard first order logic.
The Penn Treebank ver-sion of the Brown corpus (Marcus, Santorini, andMarcinkiewicz, 1993) served as the corpus.
Onlyits words and part-of-speech tags were utilized.
Al-though these tags were corrected by hand, part-of-speech tagging can be automatically performed withan error rate of 3 to 4 percent (Merialdo, 1994; Brill,1994).
The Alvey morphological nalyzer (Ritchie etal., 1992) was used to assign morphological struc-ture.
It uses a lexicon with just over 62,000 en-tries.
This lexicon was derived from a machine read-able dictionary but contains no semantic informa-tion.
Word sense disambiguation for the bases andderived forms that could not be resolved using part-of-speech tags was not performed.
However, thereexist systems for such word sense disambiguationwhich do not require explicit lexical semantic infor-mation (Yarowsky, 1993; Schiitze, 1992).Let us consider an example.
One sense of the suf-fix -ize applies to adjectival bases (e.g., centralize).This sense of the affix will be referred to as -Aize.
(A related but different sense applies to nouns, e.g.,glamorize.
The part-of-speech of the base is usedto disambiguate these two senses of -ize.)
First,the regular expressions ".
*IZ(E\[ING\[ES\[ED)$" and"^V.
*" are used to collect tokens from the corpusthat were likely to have been derived using -ize.
TheAlvey morphological nalyzer is then applied to eachtype.
It strips off -Aize from a word if it can findan entry with a reference form of the appropriate or-thographic shape and has the features "uninflected,""latinate," and "adjective."
It may also build an ap-propriate base using other affixes, e.g.,\[\[tradition-a~-Aize\].
1 Finally, all derived forms are assigned thelexical semantic feature CHANGE-OF-STATE and allthe bases are assigned the lexical semantic featureIZE-DEPENDENT.
Only the CHANGE-OF-STATE fea-ture will be discussed here.
It is defined by the axiombelow.For all predicates P with featuresCHANGE-OF-STATE and DYADIC :Vx ,y ,e  \ [P (x ,y )**e ->\[3ol : \[at-end-of (el, e) Acause(e, el)\]\[rstate(P) (y)**el\] A3e2 : at-beginning-of (e2, e)\[-~rstate (P) (y)**e2\]\] JThe operator ** is analogous to ~ in situationsemantics; it indicates, among other things, that aformula describes an event.
P is a place holder forthe semantic predicate corresponding to the wordsense which has the feature.
It is assumed that eachword sense corresponds to a single semantic predi-cate.
The axiom states that if a CHANGE-OF-STATEpredicate describes an event, then the result state ofthis predicate holds at the end of this event and thatit did not hold at the beginning, e.g., if one wants to1In an alternative version of the method, the mor-phological analyzer is also able to construct a base onits own when it is unable to find an appropriate basein its lexicon.
However, these "new" bases seldom cor-respond to actual words and thus the results presentedhere were derived using a morphological nalyzer config-ured to only use bases that are directly in its lexicon orcan be constructed from words in its lexicon.27formalize something it must be non-formal to beginwith and will be formal after.
The result state of an-Aize predicate is the predicate corresponding to itsbase; this is stated in another axiom.Precision figures for the method were collected asfollows.
The method returns a set of normalized(i. e., uninflected) word/feature pairs.
A human thendetermines which pairs are "correct" where correctmeans that the axiom defining the feature holds forthe instances (tokens) of the word (type).
Because ofthe lack of word senses, the semantics assigned to aparticular word is only considered correct~ if it holdsfor all senses occurring in the relevant derived wordtokens.
2 For example, the axiom above must holdfor all senses of centralize occurring in the corpusin order for the centralize~CHANGE-OF-STATE pairto be correct.
The axiom for IZE-DEPENDENT musthold only for those senses of central that occur in thetokens of centralize for the central/IzE-DEPENDENTpair to be correct.
This definition of correct wasconstructed, in part, to make relatively quick hu-man judgements possible.
It should also be notedthat the semantic judgements require that the se-mantics be expressed in a precise way.
This disciplineis enforced in part by requiring that the features beaxiomatized in a denotational logic.
Another argu-ment for such an axiomatization is that many NLPsystems utilize a denotational logic for representingsemantic information and thus the axioms provide astraightforward interface to the lexicon.To return to our example, as shown in Table 1,there were 63 -Aize derived words (types) of which78 percent conform to the CHANGE-OF-STATE ax-iom.
Of the bases, 80 percent conform to the IZE-DEPENDENT axiom which will be discussed in thenext section.
Among the conforming words wereequalize, stabilize, and federalize.
Two words thatseem to be derived using the -ize suffix but do notconform to the CHANGE-OF-STATE axiom are penal-ize and socialize (with the guests).
A different sortof non-conformity is produced when the morpholog-ical analyzer finds a spurious parse.
For example, itanalyzed subsidize as \[sub- \[side -ize\]\] and thus pro-duced the sidize/CHANGE-OF-STATE pair which forthe relevant okens was incorrect.
In the first sort,the non-conformity arises because the cue does notalways correspond to the relevant lexical semanticinformation.
In the second sort, the non-conformityarises because a cue has been found where one doesnot exist.
A system that utilizes a lexicon so con-structed is interested primarily in the overall preci-sion of the information contained within and thusthe results presented in the next section conflatethese two types of false positives.2Although this definition is required for many cases,in the vast majority of the cases, the derived form andits base have only one possible sense (e.g., stressful).4 Resu l tsThis section starts by discussing the semantics of 18derivational affixes: re-, un-, de-, - ize,-en,- i fy, - le,-ate, -ee, -er, -ant, -age, -ment, mis-,-able, -ful, -less, and -ness.
Following this discussion, a table ofprecision statistics for the performance of these sur-face cues is presented.
Due to space limitations, thelexical semantics cued by these affixes can only beloosely specified.
However, they have been axiom-atized in a fashion exemplified by the CHANGE-OF-STATE axiom above (see (Light, 1996; Light, 1992)).The verbal prefixes un-, de-, and re- cue aspec-tual information for their base and derived forms.Some examples from the Brown corpus are unfas-ten, unwind, decompose, defocus, reactivate, andreadapt.
Above it was noted that un- is a cue fortelicity.
In fact, both un- and de- cue the CHANGE-OF-STATE feature for their base and derived forms--the CHANGE-OF-STATE feature ntails the TELIC fea-ture.
In addition, for un- and de-, the result state ofthe derived form is the negation of the result state ofthe base (NEG-OF-BASE-IS-RSTATE), e.g., the resultof unfastening something is the opposite of the resultof fastening it.
As shown by examples like reswimthe last lap, re- only cues the TELIC feature for itsbase and derived forms: the lap might have beenswum previously and thus the negation of the resultstate does not have to have held previously (DoTty,1979).
For re-, the result state of the derived formis the same as that of the base (RSTATE-EQ-BASE-RSTATE), e.g., the result of reactivating something isthe same as activating it.
In fact, if one reactivatessomething then it is also being activated: the derivedform entails the base (ENTAILS-BASE).
Finally, forre-, the derived form entails that its result state heldpreviously, e.g., if one recentralizes something thenit must have been central at some point previous tothe event of recentralization (PRESUPS-RSTATE).The suffixes -Aize, -Nize, -en, -Airy, -Nify allcue the CHANGE-OF-STATE feature for their derivedform as was discussed for -Aize above.
Some ex-emplars are centralize, formalize, categorize, colo-nize, brighten, stiffen, falsify, intensify, mummify,and glorify.
For -Aize, -en and -Airy a bit more canbe said about the result state: it is the base predi-cate (RSTATE-EQ-BASE), e.g., the result of formaliz-ing something is that it is formal.
Finally -Aize, -en,and -Airy cue the following feature for their bases:if a state holds of some individual then either anevent described by the derived form predicate oc-curred previously or the predicate was always trueof the individual (IZE-DEPENDENT), e.g., if some-thing is central then either it was centralized or itwas always central.The "suffixes" -le and -ate should really be calledverbal endings ince they are not suffixes in English,i.e., if one strips them off one is seldom left with aword.
(Consequently, only regular expressions were28used to collect ypes; the morphological nalyzer wasnot used.)
Nonetheless, they cue lexical semanticsand are easily identified.
Some examples are chuckle,dangle, alleviate, and assimilate.
The ending -atecues a CHANGE-OF-STATE verb and -le an ACTIVITYverb.The derived forms produced by -ee, -er, and -antall refer to participants of an event described by theirbase (PART-IN-E).
Some examples are appointee, de-porlee, blower, campaigner, assailant, and claimant.In addition, the derived form of -ee is also sentientof this event and non-volitional with respect to it(Barker, 1995).The nominalizing suffixes -age and -ment bothproduce derived forms that refer to something re-sulting from an event of the verbal base predicate.Some examples are blockage, seepage, marriage, pay-ment, restatement, shipment, and treatment.
Thederived forms of -age entail that an event occurredand refer to something resulting from it (EVENT-AND-RESULTANT)), e.g., seepage ntails that seep-ing took place and that the seepage resulted fromthis seeping.
Similarly, the derived forms of -mententail that an event took place and refer either tothis event, the proposition that the event occurred,or something resulting from the event (REFERS-TO-E-OR-PROP-OI~-RESULT), e.g., a restatement entailsthat a restating occurred and refers either to thisevent, the proposition that the event occurred, or tothe actual utterance or written document resultingfrom the restating event.
(This analysis is based on(Zucchi, 1989).
)The verbal prefix mis-, e.g., miscalculate and mis-quote, cues the feature that an action is performedin an incorrect manner (INCORRECT-MANNER.).
Thesuffix -able cues a feature that it is possible to per-form some action (ABLE-TO-BE-PEP, FORMED), e.g.,something is enforceable if it is possible that some-thing can enforce it (DoTty, 1979).
The words de-rived using -hess refer to a state of something havingthe property of the base (STATE-OF-HAVING-PROP-OF-BASE), e.g., in Kim's fierceness at the meetingyesterday was unusual the word fierceness refers toa state of Kim being fierce.
The suffix -ful marksits base as abstract (ABSTRACT): careful, peaceful,powerful, etc.
In addition, it marks its derived formas the antonym of a form derived by -less if it exists(LESS-ANTONYM).
The suffix -less marks its derivedforms with the analogous feature (FUL-ANTONYM).Some examples are colorful/less, fearful/less, harm-ful/less, and tasteful/less.The precision statistics for the individual exicalsemantic features discussed above are presented inTable 1 and Table 2.
Lexical semantic informa-tion was collected for 2535 words (bases and derivedforms).
One way to summarize these tables is to cal-culate a single precision number for all the featuresin a table, i.e., average the number of correct typesfor each affix, sum these averages, and then dividethis sum by the total number of types.
Using thisstatistic it can be said that if a random word is de-rived, its features have a 76 percent chance of beingtrue and if it is a stem of a derived form, its featureshave a 82 percent chance of being true.Computing recall requires finding all true tokensof a cue.
This is a labor intensive task.
It wasperformed for the verbal prefix re- and the recallwas found to be 85 percent.
The majority of themissed re- verbs were due to the fact that the systemonly looked at verbs starting with RE and not otherparts-of-speech, e.g., many nominalizations such asreaccommodat ion contain the re- morphological cue.However, increasing recall by looking at all openclass categories would probably decrease precision.Another cause of reduced recall is that some stemswere not in the Alvey lexicon or could not be prop-erly extracted by the morphological analyzer.
Forexample, -Nize could not be stripped from hypoth-esize because Alvey failed to reconstruct hypothesisfrom hypothes.
However, for the affixes discussedhere, 89 percent of the bases were present in theAlvey lexicon.5 Evaluat ionGood surface cues are easy to identify, abundant,and correspond to the needed lexical semantic in-formation (Hearst (1992) identifies a similar setof desiderata).
With respect to these desiderata,derivational morphology is both a good cue and abad cue.Let us start with why it is a bad cue: there maybe no derivational cues for the lexical semantics ofa particular word.
This is not the case for othersurface cues, e.g., distributional cues exist for everyword in a corpus.
In addition, even if a derivationalcue does exist, the reliability (on average approxi-mately 76 percent) of the lexical semantic informa-tion is too low for many NLP tasks.
This unrelia-bility is due in part to the inherent exceptionality oflexical generalization and thus can be improved onlypartially.However, derivational morphology is a good cuein the following ways.
It provides exactly the typeof lexical semantics needed for many NLP tasks: theaffixes discussed in the previous section cued nomi-nal semantic lass, verbal aspectual class, antonymrelationships between words, sentience, etc.
In ad-dition, working with the Brown corpus (1.1 millionwords) and 18 affixes provided such information forover 2500 words.
Since corpora with over 40 millionwords are common and English has over 40 com-mon derivational affixes, one would expect o be ableto increase this number by an order of magnitude.In addition, most English words are either derivedthemselves or serve as bases of at least one deriva-tional affix.
3 Finally, for some NLP tasks, 76 per-3The following experiment supports this claim.
Just29FeatureTELICRSTATE-EQ-BASE-RSTATEENTAILS-BASEPRESUPS-RSTATECHANGE-OF-STATENEG-OF-BASE-IS-RSTATECHANGE-OF-STATENEG-OF-BASE-IS-RSTATECHANGE-OF-STATERSTATE-EQ-BASECHANGE-OF-STATEACTIVITYCHANGE-OF-STATERSTATE-EQ-BASECHANGE-OF-STATERSTATE-EQ-BASECHANGE-OF-STATECHANGE-OF-STATEPART-IN-ESENTIENTNON-VOLITIONALPART-IN-EPART-IN-EEVENT-AND-RESULTANTREFERS-TO-E-OR-PROP-OR-RESULTANTINCORRECT-MANNERABLE-TO-BE-PERFORMEDSTATE-OF-HAVING-PROP-OF-BASEFUL-ANTONYMLESS-ANTONYM\] Affix I Types \] Precision Ire- 164 91%re- 164 65%re- 164 65%re- 164 65%un- 23 100%un- 23 91%de- 35 34%de- 35 20%-Aize 63 78%-Aize 63 75%-Nize 86 56%-le 71 55%-en 36 100%-en 36 97%-Airy 17 94%-Aify 17 58%-Nify 21 67%-ate 365 48%-ee 22 91%-ee 22 82%-ee 22 68%-er 471 85%-ant 21 81%-age 43 58%-ment 166 88%mis- 21 86%-able 148 84%-hess 307 97%.less 22 77%-\]ul 22 77%Table 1: Derived wordsFeature I Affix \[Types \[PrecisionTELIC re- 164 91%CHANGE-OF-STATE Vun- 23 91%CHANGE-OF-STATE Vde- 33 36%IZE-DEPENDENT -Aize 64 80%IZE-DEPENDENT -en 36 72%IZE-DEPENDENT -Airy 15 40%ABSTRACT -ful 76 93%Table 2: Base wordscent reliability may be adequate.
In addition, someaffixes are much more reliable cues than others andthus if higher reliability is required then only theaffixes with high precision might be used.The above discussion makes it clear that morpho-logical cueing provides only a partial solution to theproblem of acquiring lexical semantic information.However, as mentioned in section 2 there are manytypes of surface cues which correspond to a vari-ety of lexical semantic information.
A combinationof cues should produce better precision where thesame information is indicated by multiple cues.
Forexample, the morphological cue re- indicates telic-ity and as mentioned above, the syntactic ue theprogressive tense indicates non-stativity (Dorr andLee, 1992).
Since telicity is a type of non-stativity,the information is mutually supportive.
In addition,using many different types of cues should provide agreater variety of information i general.
Thus mor-phological cueing is best seen as one type of surfacecueing that can be used in combination with othersto provide lexical semantic information.6 AcknowledgementsA portion of this work was performed at the Uni-versity of Rochester Computer Science Departmentand supported by ONR/ARPA research grant num-ber N00014-92-J-1512.Re ferencesBarker, Chris.
1995.
The semantics of -ee.
In Pro-ceedings of the SALT conference.Berwick, Robert.
1983.
Learning word meaningsfrom examples.
In Proceedings of the 8th Interna-tional Joint Conference on Artificial Intelligence(IJCAI-S3).Brill, Eric.
1994.
Some advances in transformation-based part of speech tagging.
In Proceedings ofthe Twelfth National conference on Artificial In-telligence: American Association for Artificial In-telligence (AAAI).Brown, Peter F., Vincent J. Della Pietra, Peter V.deSouza, Jennifer C. Lai, and Robert L. Mercer.1992.
Class-based n-gram models of natural lan-guage.
Computational Linguistics, 18(4).Church, Kenneth, William Gale, Patrick Hanks, andDonald Hindle.
1989.
Parsing, word associa-tions and typical predicate-argument relations.
InInternational P~'~rkshop nParsing Technologies,pages 389-98.over 400 open class words were picked randomly fromthe Brown corpus and the derived forms were markedby hand.
Based on this data, a random open class wordin the Brown corpus has a 17 percent chance of beingderived, a56 percent chance of being a stem of a derivedform, and an 8 percent chance of being both.Dorr, Bonnie J. and Ki Lee.
1992.
Building a lex-icon for machine translation: Use of corpora foraspectual c assification ofverbs.
Technical ReportCS-TR-2876, University of Maryland.Dowty, David.
1979.
I~rd Meaning and MontagueGrammar.
Reidel.Fisher, Cynthia, Henry Gleitman, and Lila R. Gleit-man.
1991.
On the semantic content of subcatego-rization frames.
Cognitive Psychology, 23(3):331-392.Gleitman, Lila.
1990.
The structural sources of verbmeanings.
Language Acquisition, 1:3-55.Granger, R. 1977.
Foulup: a program that figuresout meanings of words from context.
In Proceed-ings of the 5th International Joint Conference onArtificial Intelligence.Grimshaw, Jane.
1981.
Form, function, and the lan-guage acquisition device.
In C. L. Baker and J. J.McCarthy, editors, the logical problem of languageacquisition.
MIT Press.Hastings, Peter.
1994.
Automatic Acquistion ofI~rd Meaning from Context.
Ph.D. thesis, Uni-versity of Michigan.Hearst, Marti.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedingsof the fifteenth International Conference on Com-putational Linguistics (COLING).Hwang, Chung Hee and Lenhart Schubert.
1993.Episodic logic: a comprehensive natural represen-tation for language understanding.
Mind and Ma-chine, 3(4):381-419.Light, Marc.
1992.
Rehashing Re-.
In Proceedingsof the Eastern States Conference on Linguistics.Cornell University Linguistics Department Work-ing Papers.Light, Marc.
1996.
Morphological Cues for LexicalSemantics.
Ph.D. thesis, University of Rochester,Rochester, NY.Marcus, Mitchell, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
Compu-tational Linguistics, 19(2):313-330.Merialdo, Bernard.
1994.
Tagging English text witha probabilistic model.
Computational Linguistics,20(2):155-172.Pinker, Steven.
1989.
Learnability and Cognition:The Acquisition of Argument Structure.
MITPress.Pinker, Steven.
1994.
How could a child use verbsyntax to learn verb semantics?
Lingua, 92:377-410.Pustejovsky, James.
1988.
Constraints on the acqui-sition of semantic knowledge.
International jour-nal of intelligent systems, 3:247-268.30Ritchie, Graeme D., Graham J. Russell, Alan W.Black, and Steve G. Pulman.
1992.
Computa-tional Morphology: Practical Mechanisms for theEnglish Lexicon.
MIT press.Schiitze, Hinrich.
1992.
Word sense disambiguationwith sublexical representations.
In Statistically-Based NLP Techniques (American Associationfor Artificial Intelligence l~'~rkshop, July 12-16,1992, San Jose, CA.
), pages 109-113.Siskind, Jeffrey M. 1990.
Acquiring core meaningsof words, represented as Jackendoff-style concep-tual structures, from correlated streams of linguis-tic and non-linguistic input.
In Proceedings ofthe 28th Meeting of the Association for Compu-tational Linguistics.Yarowsky, David.
1993.
One sense per collocation.In Proceedings of the ARPA l~'~rkshop nHumanLanguage Technology.
Morgan Kaufmann.Zucchi, Alessandro.
1989.
The Language of Propo-sitions and Events: Issues in the Syntax and theSemantics of Nominalization.
Ph.D. thesis, Uni-versity of Massachusetts, Amherst, MA.31
