Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 534?545,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsNaturalLI: Natural Logic Inference for Common Sense ReasoningGabor AngeliStanford UniversityStanford, CA 94305angeli@cs.stanford.eduChristopher D. ManningStanford UniversityStanford, CA 94305manning@cs.stanford.eduAbstractCommon-sense reasoning is important forAI applications, both in NLP and manyvision and robotics tasks.
We proposeNaturalLI: a Natural Logic inference sys-tem for inferring common sense facts ?
forinstance, that cats have tails or tomatoesare round ?
from a very large databaseof known facts.
In addition to being ableto provide strictly valid derivations, thesystem is also able to produce derivationswhich are only likely valid, accompaniedby an associated confidence.
We bothshow that our system is able to capturestrict Natural Logic inferences on the Fra-CaS test suite, and demonstrate its abilityto predict common sense facts with 49%recall and 91% precision.1 IntroductionWe approach the task of database completion:given a database of true facts, we would like topredict whether an unseen fact is true and shouldbelong in the database.
This is intuitively cast asan inference problem from a collection of candi-date premises to the truth of the query.
For exam-ple, we would like to infer that no carnivores eatanimals is false given a database containing the catate a mouse (see Figure 1).These inferences are difficult to capture ina principled way while maintaining high recall,particularly for large scale open-domain tasks.Learned inference rules are difficult to general-ize to arbitrary relations, and standard IR methodseasily miss small but semantically important lex-ical differences.
Furthermore, many methods re-quire explicitly modeling either the database, thequery, or both in a formal meaning representation(e.g., Freebase tuples).Although projects like the Abstract MeaningRepresentation (Banarescu et al., 2013) have madeNo carnivoreseat animals?The carnivoreseat animalsThe cateats animalsThe catate an animalThe catate a mousew?wfNo catseat animalsNo catseat micew.
.
.w.
.
.Figure 1: Natural Logic inference cast as search.The path to the boxed premise the cat ate a mousedisproves the query no carnivores eat animals, asit passes through the negation relation (f).
Thispath is one of many candidates taken; the premiseis one of many known facts in the database.
Theedge labels denote Natural Logic inference steps.headway in providing broad-coverage meaningrepresentations, it remains appealing to use hu-man language as the vessel for inference.
Fur-thermore, OpenIE and similar projects have beenvery successful at collecting databases of naturallanguage snippets from an ever-increasing corpusof unstructured text.
These factors motivate ouruse of Natural Logic ?
a proof system built on thesyntax of human language ?
for broad coveragedatabase completion.Prior work on Natural Logic has focused on in-ferences from a single relevant premise, makinguse of only formally valid inferences.
We improveupon computational Natural Logic in three ways:(i) our approach operates over a very large set ofcandidate premises simultaneously; (ii) we do notrequire explicit alignment between a premise andthe query; and (iii) we allow imprecise inferencesat an associated cost learned from data.Our approach casts inference as a single uni-fied search problem from a query to any valid534supporting premise.
Each transition along thesearch denotes a (reverse) inference step in Natu-ral Logic, and incurs a cost reflecting the system?sconfidence in the validity of that step.
This ap-proach offers two contributions over prior work indatabase completion: (i) it allows for unstructuredtext as the input database without any assump-tions about the schema or domain of the text, and(ii) it proposes Natural Logic for inference, ratherthan translating to a formal logic syntax.
More-over, the entire pipeline is implemented in a singleelegant search framework, which scales easily tolarge databases.2 MacCartney?s Natural LogicNatural Logic aims to capture common logical in-ferences by appealing directly to the structure oflanguage, as opposed to running deduction on anabstract logical form.
The logic builds upon tra-ditional rather than first-order logic: to a first ap-proximation, Natural Logic can be seen as an en-hanced version of Aristotle?s syllogistic system(van Benthem, 2008).
A working understandingof the logic as syllogistic reasoning is sufficient forunderstanding the later contributions of the paper.While some inferences of first-order logic are notcaptured by Natural Logic, it nonetheless allowsfor a wide range of intuitive inferences in a com-putationally efficient and conceptually clean way.We build upon the variant of the logic intro-duced by the NatLog system (MacCartney andManning, 2007; 2008; 2009), based on earlier the-oretical work on Natural Logic and MonotonicityCalculus (van Benthem, 1986; Valencia, 1991).Later work formalizes many aspects of the logic(Icard, 2012; Djalali, 2013); we adopt the formalsemantics of Icard and Moss (2014), along withmuch of their notation.At a high level, Natural Logic proofs operate bymutating spans of text to ensure that the mutatedsentence follows from the original ?
each step ismuch like a syllogistic inference.
We construct acomplete proof system in three parts: we defineMacCartney?s atomic relations between lexical en-tries (Section 2.1), the effect these lexical muta-tions have on the validity of the sentence (Sec-tion 2.2), and a practical approach for executingthese proofs.
We review MacCartney?s alignment-based approach in Section 2.3, and show that wecan generalize and simplify this system in Sec-tion 3.D?
?
?(equivalence)D?
v ?
(forward entail.)D?
w ?
(reverse entail.
)D?f ?(negation)D?
 ?(alternation)D?
` ?
(cover)Figure 2: The model-theoretic interpretation of theMacCartney relations.
The figure shows the re-lation between the denotation of ?
(dark) and ?(light).
The universe is denoted by D.2.1 Lexical RelationsMacCartney and Manning (2007) introduce sevenset-theoretic relations between the denotations ofany two lexical items.
The denotation of a lexicalitem is the set of objects in the domain of discourseD to which that lexical item refers.
For instance,the denotation of cat would be the set of all cats.Two denotations can then be compared in terms ofset algebra: if we define the set of cats to be ?
andthe set of animals to be ?, we can state that ?
?
?.The six informative relations are summarized inFigure 2; a seventh relation (#) corresponds toto the completely uninformative relation.
For in-stance, the example search path in Figure 1 makesuse of the following relations:No x y f The x ycat v carnivoreanimal ?
a animalanimal w mouseDenotations are not required to be in thespace of predicates (e.g., cat, animal).
Inthe first example, the denotations of No andThe are in the space of operators p?
(p?
t):functions from predicates p to truth valuest.
The f relation becomes the conjunctionof two claims: ?x?y ?
(no x y ?
the x y) and?x?y (no x y ?
the x y).
This is analogous to theconstruction of the set-theoretic definition of f inFigure 2: ?
?
?
= ?
and ?
?
?
= D (see Icardand Moss (2014)).535Examples of the last two relations ( and`) andthe complete independence relation (#) include:cat  doganimal ` nonhumancat # friendly2.2 Monotonicity and PolarityThe previous section details the relation betweenlexical items; however, we still need a theory forhow to ?project?
the relation induced by a lexicalmutation as a relation between the two containingsentences.
For example, cat v animal, and somecat meowsv some animal meows, but no cat barks6v no animal barks.
Despite differing by the samelexical relation, the first example describes a validentailment, while the second does not.We appeal to two important concepts: mono-tonicity as a property of arguments to natural lan-guage operators, and polarity as a property of lexi-cal items in a sentence.
Much like monotone func-tions in calculus, an [upwards] monotone operatorhas an output truth value which is non-decreasing(i.e., material implication) as the input ?increases?
(i.e., the subset relation).
From the example above,some is upwards monotone in its first argument,and no is downwards monotone in its first argu-ment.Polarity is a property of lexical items in a sen-tence determined by the operators acting on it.
Alllexical items have upward polarity by default; up-wards monotone operators preserve polarity, anddownwards monotone operators reverse polarity.For example, mice in no cats eat mice has down-ward polarity, whereas mice in no cats don?t eatmice has upward polarity (it is in the scope of twodownward monotone operators).
The relation be-tween two sentences differing by a single lexicalrelation is then given by the projection function ?in Table 1.12.3 Proof By AlignmentMacCartney and Manning (2007) approach the in-ference task in the context of inferring whether asingle relevant premise entails a query.
Their ap-proach first generates an alignment between thepremise and the query, and then classifies eachaligned segment into one of the lexical relationsin Figure 2.
Inference reduces to projecting each1Note that this table optimistically assumes every operatoris additive and multiplicative, as defined in Icard (2012).r ?
v w  ` f #?
(r) ?
w v `  f #Table 1: The projection function ?, shown fordownward polarity contexts only.
The input r isthe lexical relation between two words in a sen-tence; the projected relation ?
(r) is the relationbetween the two sentences differing only by thatword.
Note that ?
is the identity function in up-ward polarity contexts../ ?
v w f  ` #?
?
v w f  ` #v v v #   # #w w # w ` # ` #f f `  ?
w v #  #  v # v #` ` ` # w w # ## # # # # # # #Table 2: The join table as shown in Icard (2012).Entries in the table are the result of joining a rowwith a column.of these relations according to the projection func-tion ?
(Table 1) and iteratively joining two pro-jected relations together to get the final entailmentrelation.
This join relation, denoted as ./, is givenin Table 2.To illustrate, we can consider MacCartney?sexample inference from Stimpy is a cat toStimpy is not a poodle.
An alignment ofthe two statements would provide three lexicalmutations: r1:= cat?
dog, r2:= ?
?
not, andr3:= dog?
poodle.
Each of these are then pro-jected with the projection function ?, and arejoined using the join relation:r0./ ?
(r1) ./ ?
(r2) ./ ?
(r3),where the initial relation r0is axiomatically ?.
InMacCartney?s work this style of proof is presentedas a table.
The last column (si) is the relation be-tween the premise and the ithstep in the proof, andis constructed inductively as si:= si?1./ ?
(ri):Mutation ri?
(ri) sir1cat?dog   r2?
?not f f vr3dog?poodle w v vIn our example, we would conclude that Stimpyis a cat v Stimpy is not a poodle since s3is v;therefore the inference is valid.536?w `fv fvw`?f`w?fv?fv?f`w???
??
; ???
?
?fw`?vf`v?wany(a) (b)Figure 3: (a) Natural logic inference expressed as a finite state automaton.
Omitted edges go to theunknown state (#), with the exception of omitted edges from ?, which go to the state of the edge type.Green states (?, v) denote valid inferences; red states (, f) denote invalid inferences; blue states (w,`) denote inferences of unknown validity.
(b) The join table collapsed into the three meaningful statesover truth values.3 Inference as a Finite State MachineWe show that the tabular proof formulation fromSection 2.3 can be viewed as a finite state machine,and present a novel observation that we can loss-lessly collapse this finite state machine into onlythree intuitive inference states.
These observationsallow us to formulate our search problem such thata search path corresponds to an input to (i.e., paththrough) this collapsed state machine.Taking notation from Section 2.3, we constructa finite state machine over states s ?
{v,w, .
.
.
}.A machine in state sicorresponds to relation siholding between the initial premise and the de-rived fact so far.
States therefore correspond tostates of logical validity.
The start state is ?.
Out-going transitions correspond to inference steps.Each transition is labeled with a projected relation?
(r) ?
{v,w, .
.
.
}, and spans from a source states to a target s?according to the join table.
That is,the transition s?(r)???
s?exists iff s?= s ./ ?
(r).For example, the path in Figure 1 yields the tran-sitions ?f??fw?????w??.
Figure 3a shows theautomaton, with trivial edges omitted for clarity.Our second contribution is collapsing this au-tomaton into the three meaningful states we use asoutput: valid (?
?
?
), invalid (?
?
??
), andunknown validity (?
; ?).
We can cluster statesin Figure 3a into these three categories.
The rela-tions ?
and v correspond to valid inferences; fand  correspond to invalid inferences; w, ` and# correspond to unknown validity.
This cluster-ing mirrors that used by MacCartney for his tex-tual entailment experiments.Collapsing the FSA into the form in Figure 3bbecomes straightforward from observing the reg-ularities in Figure 3a.
Nodes in the valid clustertransition to invalid nodes always and only on therelations f and .
Symmetrically, invalid nodestransition to valid nodes always and only onf and`.
A similar pattern holds for the other transitions.Formally, for every relation r and nodes a1and a2in the same cluster, if we have transitionsa1r??
b1and a2r??
b2then b1and b2are neces-sarily in the same cluster.
As a concrete example,we can take r = f and the two states in the in-valid cluster: a1= f, a2=.
Although ff??
?and f?
?v, both ?
and v are in the same cluster(valid).
It is not trivial a priori that the join tableshould have this regularity, and it certainly simpli-fies the logic for inference tasks.A few observations deserve passing remark.First, even though the states w and ` appearmeaningful, in fact there is no ?escaping?
thesestates to either a valid or invalid inference.
Sec-ond, the hierarchy over relations presented in Icard(2012) becomes apparent ?
in particular,f alwaysbehaves as negation, whereas its two ?weaker?versions ( and `) only behave as negation in cer-tain contexts.
Lastly, with probabilistic inference,transitioning to the unknown state can be replacedwith staying in the current state at a (potentiallyarbitrarily large) cost to the confidence of valid-ity.
This allows us to make use of only two states:valid and invalid.5374 Inference As SearchNatural Logic allows us to formalize our approachelegantly as a single search problem.
Given aquery, we search over the space of possible factsfor a valid premise in our database.
The nodes inour search problem correspond to candidate facts(Section 4.1); the edges are mutations of thesefacts (Section 4.2); the costs over these edges en-code the confidence that this edge maintains aninformative inference (Section 4.5).
This mirrorsthe automaton defined in Section 3, except impor-tantly we are constructing a reversed derivation,and are therefore ?traversing?
the FSA backwards.This approach is efficient over a large databaseof 270 million entries without making use of ex-plicit queries over the database; nor does theapproach make use of any sort of approximatematching against the database, beyond lemmatiz-ing individual lexical items.
The motivation inprior work for approximate matches ?
to improvethe recall of candidate premises ?
is captured ele-gantly by relaxing Natural Logic itself.
We showthat allowing invalid transitions with appropriatecosts generalizes JC distance (Jiang and Conrath,1997) ?
a common thesaurus-based similarity met-ric (Section 4.3).
Importantly, however, the entireinference pipeline is done within the framework ofweighted lexical transitions in Natural Logic.4.1 NodesThe space of possible nodes in our search is theset of possible partial derivations.
To a first ap-proximation, this is a pair (w, s) of a surface formw tagged with word sense and polarity, and an in-ference state s ?
{valid, invalid} in our collapsedFSA (Figure 3b).
For example, the search path inFigure 1 traverses the nodes:(No carnivores eat animals, valid)(The carnivores eat animals, invalid)(The cat eats animals, invalid)(The cat eats an animal, invalid)(The cat ate a mouse, invalid)During search, we assume that the validitystates s are reversible ?
if we know that the cat atea mouse is true, we can infer that no carnivoreseat animals is false.
In addition, our search keepstrack of some additional information:Mutation Index Edges between sentences aremost naturally defined to correspond to mutationsof individual lexical items.
We therefore maintainan index of the next item to mutate at each searchstate.
Importantly, this enforces that each deriva-tion orders mutations left-to-right; this is compu-tationally efficient, at the expense of rare searcherrors.
A similar observation is noted in MacCart-ney (2009), where prematurely collapsing to # oc-casionally misses inferences.Polarity Mutating operators can change the po-larity on a span in the fact.
Since we do not havethe full parse tree at our disposal at search time,we track a small amount of metadata to guess thescope of the mutated operator.4.2 TransitionsWe begin by introducing some terminology.
Atransition template is a broad class of transitions;for instance WordNet hypernymy.
A transition(or transition instance) is a particular instantiationof a transition template.
For example, the tran-sition from cat to feline.
Lastly, an edge in thesearch space connects two nodes, which are sep-arated by a single transition instance.
For exam-ple, an edge exists between some felines have tailsand some cats have tails.
Transition [instances]are stored statically in memory, whereas edges areconstructed on demand.Transition templates provide a means of defin-ing transitions and subsequently edges in oursearch space using existing lexical resources (e.g.,WordNet, distributional similarity, etc.).
We canthen define a mapping from these templates toNatural Logic lexical relations.
This allows usto map every edge in our search graph back tothe Natural Logic relation it instantiates.
Thefull table of transition templates is given in Ta-ble 3, along with the Natural Logic relation thatinstances of the template introduce.
We includemost relations in WordNet as transitions, andparametrize insertions and deletions by the part ofspeech of the token being inserted/deleted.Once we have an edge defining a lexical mu-tation with an associated Natural Logic relationr, we can construct the corresponding end node(w?, s?)
such that w?is the sentence with the lex-ical mutation applied, and s?is the validity stateobtained from the FSA in Section 3.
For instance,if our edge begins at (w, s), and there exists a tran-sition in the FSA from s?r??
s, then we define theend point of the edge to be (w?, s?).
To illustrateconcretely, suppose our search state is:(some felines have tails, valid)538Transition Template RelationWordNet hypernym vWordNet hyponym wWordNet antonym?WordNet synonym/pertainym?
?Distributional nearest neighbor ?Delete word?vAdd word?wOperator weaken vOperator strengthen wOperator negate fOperator synonym ?Change word sense ?Table 3: The edges allowed during inference.Entries with a dagger (?)
are parametrized bytheir part-of-speech tag, from the restricted list of{noun,adjective,verb,other}.
The first column de-scribes the type of the transition.
The set-theoreticrelation introduced by each relation is given in thesecond column.The transition template for WordNet hyper-nymy gives us a transition instance from felineto cat, corresponding to the Natural Logic infer-ence catv??
feline.
Recall, we are constructingthe inference in reverse, starting from the conse-quent (query).
We then notice that the transitionvalidv??
valid in the FSA ends in our currentinference state (valid), and set our new inferencestate to be the start state of the FSA transition ?
inthis case, we maintain validity.Note that negation is somewhat subtle, as thetransitions are not symmetric from valid to in-valid and visa versa, and we do not know our trueinference state with respect to the premise yet.In practice, the search procedure treats all threeof {f, ,`} as negation, and re-scores completederivations once their inference states are known.It should be noted that the mapping from transi-tion templates to relation types is intentionally im-precise.
For instance, clearly nearest neighbors donot preserve equivalence (?
); more subtly, whileall cats like milk  all cats hate milk, it is notthe case that some cats like milk  some cats hatemilk.2We mitigate this imprecision by introducinga cost for each transition, and learning the appro-priate value for this cost (see Section 5).
The costof an edge from fact (w, v) with surface form w2The latter example is actually a consequence of the pro-jection function in Table 1 being overly optimistic.and validity v to a new fact (w?, v?
), using a transi-tion instance tiof template t and mutating a wordwith polarity p, is given by fti?
?t,v,p.
We definethis as:fti: A value associated with every transitioninstance ti, intuitively corresponding to how?far?
the endpoints of the transition are.
?t,v,p: A learned cost for taking a transition oftemplate t, if the source of the edge is in a in-ference state of v and the word being mutatedhas polarity p.The notation for ftiis chosen to evoke an anal-ogy to features.
We set ftito be 1 in most cases;the exceptions are the edges over the WordNet hy-pernym tree and the nearest neighbors edges.
Inthe first case, taking the hypernymy relation fromw to w?to be ?w?w?, we set:f?w?w?= logp(w?
)p(w)= log p(w?)?
log p(w).The value f?w?w?is set analogously.
We definep(w) to be the ?probability?
of a concept ?
thatis, the normalized frequency of a word w or anyof its hyponyms in the Google N-Grams corpus(Brants and Franz, 2006).
Intuitively, this ensuresthat relatively long paths through fine-grained sec-tions of WordNet are not unduly penalized.
Forinstance, the path from cat to animal traverses sixintermediate nodes, na?
?vely yielding a prohibitivesearch depth of 6.
However, many of these tran-sitions have low weight: for instance f?cat?felineisonly 0.37.For nearest neighbors edges, we take Neu-ral Network embeddings learned in Huang et al.
(2012) corresponding to each vocabulary entry.We then define fNNw?w?to be the arc cosine ofthe cosine similarity (i.e., the angle) between wordvectors associated with lexical items w and w?
:fNNw?w?= arccos(w ?
w??w??w??
).For instance, fNNcat?dog= 0.43.
In practice, weexplore the 100 nearest neighbors of each word.We can express ftias a feature vector by rep-resenting it as a vector with value ftiat the indexcorresponding to (t, v, p) ?
the transition template,the validity of the inference, and the polarity ofthe mutated word.
Note that the size of this vectormirrors the number of cost parameters ?t,v,p, and539is in general smaller than the number of transitioninstances.A search path can then be parametrized by asequence of feature vectors f1, f2, .
.
.
, fn, whichin turn can be collapsed into a single vector f =?ifi.
The cost of a path is defined as ?
?
f , where?
is the vector of ?t,v,pvalues.
Both f and ?
areconstrained to be non-negative, or else the searchproblem is misspecified.4.3 Generalizing SimilaritiesAn elegant property of our definitions of ftiis itsability to generalize JC distance.
Let us assume wehave lexical itemsw1andw2, with a least commonsubsumer lcs.
The JC distance distjc(w1, w2) is:distjc(w1, w2) = logp(lcs)2p(w1) ?
p(w2).
(1)For simplicity, we simplify ?
?,v,pand ?
?,v,passimply ?
?and ??.
Without loss of generality, wealso assume that a path in our search is only modi-fying a single lexical item w1, eventually reachinga mutated form w2.We can factorize the cost of a path, ?
?
f , alongthe path fromw1tow2through its lowest commonsubsumer (lcs), [w1, w(1)1, .
.
.
, lcs, .
.
.
, w(1)2, w2],as follows:?
?
?
= ??
([log p(w(1)1)?
log p(w1)]+ .
.
.)+??
([log p(lcs)?
log p(w(n)1)]+ .
.
.
)= ??
(logp(lcs)p(w1))+ ??
(logp(lcs)p(w2))= logp(lcs)??+??p(w1)???
p(w2)?
?.Note that setting both ?
?and ?
?to 1 exactlyyields Formula (1) for JC distance.
This, in addi-tion to the inclusion of nearest neighbors as tran-sitions, allows the search to capture the intuitionthat similar objects have similar properties (e.g.,as used in Angeli and Manning (2013)).4.4 Deletions in InferenceAlthough inserting lexical items in a derivation(deleting words from the reversed derivation) istrivial, the other direction is not.
For brevity, werefer to a deletion in the derivation as an insertion,since from the perspective of search we are insert-ing lexical items.Na?
?vely, at every node in our search we mustconsider every item in the vocabulary as a possi-ble insertion.
We can limit the number of items weconsider by storing the database as a trie.
Sincethe search mutates the fact left-to-right (as perSection 4.1), we can consider children of a trienode as candidate insertions.
To illustrate, givena search state with fact w0w1.
.
.
wnand mutationindex i, we would look up completions wi+1forw0w1.
.
.
wiin our trie of known facts.Although this approach works well when i isrelatively large, there are too many candidate in-sertions for small i.
We special case the most ex-treme example for this, where i = 0 ?
that is,when we are inserting into the beginning of thefact.
In this case, rather than taking all possiblelexical items that start any fact, we take all itemswhich are followed by the first word of our currentfact.
To illustrate, given a search state with factw0w1.
.
.
wn, we would propose candidate inser-tions w?1such that w?1w0w?1.
.
.
w?kis a knownfact for some w?1.
.
.
w?k.
More concretely, if weknow that fluffy cats have tails, and are at a nodecorresponding to cats like boxes, we propose fluffyas a possible insertion: fluffy cats like boxes.4.5 Confidence EstimationThe last component in inference is translating asearch path into a probability of truth.
We noticefrom Section 4.2 that the cost of a path can be rep-resented as ?
?
f .
We can normalize this value bynegating every element of the cost vector ?
andpassing it through a sigmoid:confidence =11 + e?(??
?f).Importantly, note that the cost vector must benon-negative for the search to be well-defined, andtherefore the confidence value will be constrainedto be between 0 and12.At this point, we have a confidence that thegiven path has not violated strict Natural Logic.However, to translate this value into a probabilitywe need to incorporate whether the inference pathis confidently valid, or confidently invalid.
To il-lustrate, a fact with a low confidence should trans-late to a probability of12, rather than a probabilityof 0.
We therefore define the probability of valid-ity as follows: We take v to be 1 if the query is inthe valid state with respect to the premise, and ?1if the query is in the invalid state.
For complete-ness, if no path is given we can set v = 0.
The540probability of validity becomes:p(valid) =v2+11 + ev??f.
(2)Note that in the case where v = ?1, the aboveexpression reduces to12?
confidence; in the casewhere v = 0 it reduces to simply12.
Furthermore,note that the probability of truth makes use of thesame parameters as the cost in the search.5 Learning Transition CostsWe describe our procedure for learning the transi-tion costs ?.
Our training data D consists of queryfacts q and their associated gold truth values y.Equation (2) gives us a probability that a partic-ular inference is valid; we axiomatically considera valid inference from a known premise to be justi-fication for the truth of the query.
This is at the ex-pense of the (often incorrect) assumption that ourdatabase is clean and only contains true facts.We optimize the likelihood of our gold annota-tions according to this probability, subject to theconstraint that all elements in our cost vector ?be non-negative.
We run the search algorithm de-scribed in Section 4 on every query qi?
D. Thisproduces the highest confidence path x1, alongwith its inference state vi.
We now have annotatedtuples: ((xi, vi), yi) for every element in our train-ing set.
Analogous to logistic regression, the loglikelihood of our training data D, subject to costs?, is:l?
(D) =?0?i<|D|[yilog(vi2+11 + evi?
?f(xi))+ (1?
yi) log(?vi2+11 + e?vi?
?f(xi))],where yiis 1 if the example is annotated true and0 otherwise, and f(xi) are the features extractedfor path xi.
The objective function is the negativelog likelihood with an L2regularization term anda log barrier function to prohibit negative costs:O(D) = ?l?
(D) +12?2???22?
 log(?
).We optimize this objective using conjugate gra-dient descent.
Although the objective is non-convex, in practice we can find a good initializa-tion of weights to reduce the risk of arriving at lo-cal optima.An elegant property of this formulation is thatthe weights we are optimizing correspond directly?
Category Count Precision Recall AccuracyN M08 N M08 N M07 M081 Quantifiers 44 91 95 100 100 95 84 972 Plurals 24 80 90 29 64 38 42 753 Anaphora 6 100 100 20 60 33 50 504 Ellipses 25 100 100 5 5 28 28 245 Adjectives 15 80 71 66 83 73 60 806 Comparatives 16 90 88 100 89 87 69 817 Temporal 36 75 86 53 71 52 61 588 Verbs 8 ?
80 0 66 25 63 629 Attitudes 9 ?
100 0 83 22 55 89Applicable (1,5,6) 75 89 89 94 94 89 76 90Table 4: Results on the FraCaS textual entailmentsuite.
N is this work; M07 refers to MacCartneyand Manning (2007); M08 refers to MacCartneyand Manning (2008).
The relevant sections of thecorpus intended to be handled by this system aresections 1, 5, and 6 (although not 2 and 9, whichare also included in M08).to the costs used during search.
This creates a pos-itive feedback loop ?
as better weights are learned,the search algorithm is more likely to find con-fident paths, and more data is available to trainfrom.
We therefore run this learning step for mul-tiple epochs, re-running search after each epoch.The weights for the first epoch are initialized toan approximation of valid Natural Logic weights.Subsequent epochs initialize their weights to theoutput of the previous epoch.6 ExperimentsWe evaluate our system on two tasks: the Fra-CaS test suite, used by MacCartney and Manning(2007; 2008), evaluates the system?s ability to cap-ture Natural Logic inferences even without the ex-plicit alignments of these previous systems.
Inaddition, we evaluate the system?s ability to pre-dict common-sense facts from a large corpus ofOpenIE extractions.6.1 FraCaS Entailment CorpusThe FraCaS corpus (Cooper et al., 1996) is a smallcorpus of entailment problems, aimed at provid-ing a comprehensive test of a system?s handling ofvarious entailment patterns.
We process the cor-pus following MacCartney and Manning (2007).It should be noted that many of the sections ofthe corpus are not directly applicable to Natu-ral Logic inferences; MacCartney and Manning(2007) identify three sections which are in thescope of their system, and consequently our sys-tem as well.Results on the dataset are given in Table 4.541System P R F1AccuracyLookup 100.0 12.1 21.6 56.0NaturalLI Only 88.8 40.1 55.2 67.5NaturalLI + Lookup 90.6 49.1 63.7 72.0Table 5: Accuracy inferring common-sense factson a balanced test set.
Lookup queries the lem-matized lower-case fact directly in the 270M factdatabase.
NaturalLI Only disallows such lookups,and infers every query from only distinct premisesin the database.
NaturalLI + Lookup takes theunion of the two systems.Since the corpus is not a blind test set, the re-sults are presented less as a comparison of perfor-mance, but rather to validate the expressive powerof our search-based approach against MacCart-ney?s align-and-classify approach.
For the exper-iments, costs were set to express valid NaturalLogic inference as a hard constraint.The results show that the system is able to cap-ture Natural Logic inferences with similar accu-racy to the state-of-the-art system of MacCartneyand Manning (2008).
Note that our system is com-paratively crippled in this framework along at leasttwo dimensions: It cannot appeal to the premisewhen constructing the search, leading to the intro-duction of a class of search errors which are en-tirely absent from prior work.
Second, the deriva-tion process itself does not have access to the fullparse tree of the candidate fact.Although precision is fairly high even on thenon-applicable sections of FraCaS, recall is sig-nificantly lower than prior work.
This is a directconsequence of not having alignments to appealto.
For instance, we can consider two inferences:Jack saw Jill is playing?=?
Jill is playingJill saw Jack is playing?=?
Jill is playingIt is clear from the parse of the sentence thatthe first is valid and the second is not; however,from the perspective of the search algorithm bothmake the same two edits: inserting Jack and saw.In order to err on the side of safety, we disallowdeleting the verb saw.6.2 Common Sense ReasoningWe validate our system?s ability to infer unseencommon sense facts from a large database ofsuch facts.
Whereas evaluation on FraCaS showsthat our search formulation captures applicable in-ferences as well as prior work, this evaluationpresents a novel use-case for Natural Logic infer-ence.For our database of facts, we run the Ol-lie OpenIE system (Mausam et al., 2012) overWikipedia,3Simple Wikipedia,4and a random 5%of CommonCrawl.
Extractions with confidencebelow 0.25 or which contained pronouns werediscarded.
This yielded a total of 305 millionunique extractions composed entirely of lexicalitems which mapped into our vocabulary (186 707items).
Each of these extracted triples (e1, r, e2)was then flattened into a plain-text fact e1r e2andlemmatized.
This yields 270 million unique lem-matized premises in our database.
In general, eachfact in the database could be arbitrary unstructuredtext; our use of Ollie extractions is motivated onlyby a desire to extract short, concise facts.For our evaluation, we infer the top 689 mostconfident facts from the ConceptNet project (Tan-don et al., 2011).
To avoid redundancy with Word-Net, we take facts from eight ConceptNet rela-tions: MemberOf, HasA, UsedFor, CapableOf,Causes, HasProperty, Desires, and CreatedBy.
Wethen treat the surface text field of these facts asour candidate query.
This yields queries like thefollowing:not all birds can flynoses are used to smellnobody wants to diemusic is used for pleasureFor negative examples, we take the 689 ReVerbextractions (Fader et al., 2011) judged as falseby Mechanical Turk workers (Angeli and Man-ning, 2013).
This provides a set of plausible butnonetheless incorrect examples, and ensures thatour recall is not due to over-zealous search.
Searchcosts are tuned from an additional set of 540 trueConceptNet and 540 false ReVerb extractions.Results are shown in Table 5.
We compareagainst the baseline of looking up each fact verba-tim in the fact database.
Note that both the queryand the facts in the database are short snippets, al-ready lemmatized and lower-cased; therefore, it isnot in principle unreasonable to expect a databaseof 270 million extractions to contain these facts.Nonetheless, only 12% of facts were found via adirect lookup.
We show that NaturalLI (allowinglookups) improves this recall four-fold, at only an9.4% drop in precision.3http://wikipedia.org/ (2013-07-03)4http://simple.wikipedia.org/ (2014-03-25)5427 Related WorkA large body of work is devoted to compilingopen-domain knowledge bases.
For instance,OpenIE systems (Yates et al., 2007; Fader et al.,2011) extract concise facts via surface or depen-dency patterns.
In a similar vein, NELL (Carlsonet al., 2010; Gardner et al., 2013) continuouslylearns new high-precision facts from the internet.Many NLP applications query large knowl-edge bases.
Prominent examples include ques-tion answering (Voorhees, 2001), semantic pars-ing (Zelle and Mooney, 1996; Zettlemoyer andCollins, 2007; Kwiatkowski et al., 2013; Berantand Liang, 2014), and information extraction sys-tems (Hoffmann et al., 2011; Surdeanu et al.,2012).
A goal of this work is to improve accuracyon these downstream tasks by providing a proba-bilistic knowledge base for likely true facts.A natural alternative to the approach taken inthis paper is to extend knowledge bases by in-ferring and adding new facts directly.
For in-stance, Snow et al.
(2006) present an approach toenriching the WordNet taxonomy; Tandon et al.
(2011) extend ConceptNet with new facts; Soder-land et al.
(2010) use ReVerb extractions to enricha domain-specific ontology.
Chen et al.
(2013) andSocher et al.
(2013) use Neural Tensor Networksto predict unseen relation triples in WordNet andFreebase, following a line of work by Bordes etal.
(2011) and Jenatton et al.
(2012).
Yao et al.
(2012) and Riedel et al.
(2013) present a relatedline of work, inferring new relations between Free-base entities via inference over both Freebase andOpenIE relations.
In contrast, this work runs infer-ence over arbitrary text, without restricting itself toa particular set of relations, or even entities.The goal of tackling common-sense reasoningis by no means novel in itself.
Work by Reiterand McCarthy (Reiter, 1980; McCarthy, 1980) at-tempts to reason about the truth of a consequent inthe absence of strict logical entailment.
Similarly,Pearl (1989) presents a framework for assigningconfidences to inferences which can be reason-ably assumed.
Our approach differs from these at-tempts in part in its use of Natural Logic as the un-derlying inference engine, and more substantiallyin its attempt at creating a broad-coverage sys-tem.
More recently, work by Schubert (2002) andVan Durme et al.
(2009) approach common sensereasoning with episodic logic; we differ in our fo-cus on inferring truth from an arbitrary query, andin making use of longer inferences.This work is similar in many ways to workon recognizing textual entailment ?
e.g., Schoen-mackers et al.
(2010), Berant et al.
(2011).
Workby Lewis and Steedman (2013) is particularly rele-vant, as they likewise evaluate on the FraCaS suite(Section 1; 89% accuracy with gold trees).
Theyapproach entailment by constructing a CCG parseof the query, while mapping questions which areparaphrases of each other to the same logical formusing distributional relation clustering.
However,their system is unlikely to scale to either our largedatabase of premises, or our breadth of relations.Fader et al.
(2014) propose a system for ques-tion answering based on a sequence of paraphraserewrites followed by a fuzzy query to a structuredknowledge base.
This work can be thought of asan elegant framework for unifying this two-stageprocess, while explicitly tracking the ?risk?
takenwith each paraphrase step.
Furthermore, our sys-tem is able to explore mutations which are onlyvalid in one direction, rather than the bidirectionalentailment of paraphrases, and does not require acorpus of such paraphrases for training.8 ConclusionWe have presented NaturalLI, an inference systemover unstructured text intended to infer commonsense facts.
We have shown that we can run infer-ence over a large set of premises while maintain-ing Natural Logic semantics, and that we can learnhow to infer unseen common sense facts.Future work will focus on enriching the classof inferences we can make with Natural Logic.For example, extending the approach to handlemeronymy and relation entailments.
Furthermore,we hope to learn richer lexicalized parameters, anduse the syntactic structure of a fact during search.AcknowledgementsWe thank the anonymous reviewers for theirthoughtful comments.
We gratefully acknowl-edge the support of the Defense Advanced Re-search Projects Agency (DARPA) Deep Explo-ration and Filtering of Text (DEFT) Program un-der Air Force Research Laboratory (AFRL) con-tract no.
FA8750-13-2-0040.
Any opinions,findings, and conclusion or recommendations ex-pressed in this material are those of the authors anddo not necessarily reflect the view of the DARPA,AFRL, or the US government.543ReferencesGabor Angeli and Christopher Manning.
2013.Philosophers are mortal: Inferring the truth of un-seen facts.
In CoNLL.Laura Banarescu, Claire Bonial, Shu Cai, MadalinaGeorgescu, Kira Griffitt, Ulf Hermjakob, KevinKnight, Philipp Koehn, Martha Palmer, and NathanSchneider.
2013.
Abstract meaning representationfor sembanking.
Proc.
Linguistic Annotation Work-shop.J.
Berant and P. Liang.
2014.
Semantic parsing viaparaphrasing.
In Association for ComputationalLinguistics (ACL).Jonathan Berant, Ido Dagan, and Jacob Goldberger.2011.
Global learning of typed entailment rules.
InProceedings of ACL, Portland, OR.Antoine Bordes, Jason Weston, Ronan Collobert,Yoshua Bengio, et al.
2011.
Learning structuredembeddings of knowledge bases.
In AAAI.Thorsten Brants and Alex Franz.
2006.
Web 1T 5-gram version 1.
Linguistic Data Consortium.Andrew Carlson, Justin Betteridge, Bryan Kisiel,Burr Settles, Estevam R Hruschka Jr, and Tom MMitchell.
2010.
Toward an architecture for never-ending language learning.
In AAAI.Danqi Chen, Richard Socher, Christopher D Man-ning, and Andrew Y Ng.
2013.
Learning newfacts from knowledge bases with neural tensor net-works and semantic word vectors.
arXiv preprintarXiv:1301.3618.Robin Cooper, Dick Crouch, Jan Van Eijck, ChrisFox, Johan Van Genabith, Jan Jaspars, Hans Kamp,David Milward, Manfred Pinkal, Massimo Poesio,et al.
1996.
Using the framework.
Technical report,The FraCaS Consortium.Alex J Djalali.
2013.
Synthetic logic.
Linguistic Issuesin Language Technology, 9:1?18.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open information ex-traction.
In EMNLP.Anthony Fader, Luke Zettlemoyer, and Oren Etzioni.2014.
Open question answering over curated andextracted knowledge bases.
In KDD.Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel,and Tom Mitchell.
2013.
Improving learning andinference in a large knowledge-base using latentsyntactic cues.
EMNLP.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S Weld.
2011.
Knowledge-based weak supervision for information extractionof overlapping relations.
In ACL-HLT.Eric H Huang, Richard Socher, Christopher D Man-ning, and Andrew Y Ng.
2012.
Improving wordrepresentations via global context and multiple wordprototypes.
ACL.Thomas Icard, III and Lawrence Moss.
2014.
Recentprogress on monotonicity.
Linguistic Issues in Lan-guage Technology.Thomas Icard, III.
2012.
Inclusion and exclusion innatural language.
Studia Logica.Rodolphe Jenatton, Nicolas L Roux, Antoine Bordes,and Guillaume R Obozinski.
2012.
A latent factormodel for highly multi-relational data.
In NIPS.Jay J Jiang and David W Conrath.
1997.
Semanticsimilarity based on corpus statistics and lexical tax-onomy.
Proceedings of the 10th International Con-ference on Research on Computational Linguistics.Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and LukeZettlemoyer.
2013.
Scaling semantic parsers withon-the-fly ontology matching.Mike Lewis and Mark Steedman.
2013.
Combineddistributional and logical semantics.
TACL, 1:179?192.Bill MacCartney and Christopher D Manning.
2007.Natural logic for textual inference.
In ACL-PASCALWorkshop on Textual Entailment and Paraphrasing.Bill MacCartney and Christopher D Manning.
2008.Modeling semantic containment and exclusion innatural language inference.
In Coling.Bill MacCartney and Christopher D Manning.
2009.An extended model of natural logic.
In Proceedingsof the eighth international conference on computa-tional semantics.Bill MacCartney.
2009.
Natural Language Inference.Ph.D.
thesis, Stanford.Mausam, Michael Schmitz, Robert Bart, StephenSoderland, and Oren Etzioni.
2012.
Open languagelearning for information extraction.
In EMNLP.John McCarthy.
1980.
Circumscription?a form ofnon-monotonic reasoning.
Artificial intelligence.Judea Pearl.
1989.
Probabilistic semantics for non-monotonic reasoning: A survey.
Principles ofKnowledge Representation and Reasoning.Raymond Reiter.
1980.
A logic for default reasoning.Artificial intelligence, 13(1):81?132.Sebastian Riedel, Limin Yao, Andrew McCallum, andBenjamin M Marlin.
2013.
Relation extractionwith matrix factorization and universal schemas.
InNAACL-HLT.Stefan Schoenmackers, Oren Etzioni, Daniel S Weld,and Jesse Davis.
2010.
Learning first-order hornclauses from web text.
In EMNLP.544Lenhart Schubert.
2002.
Can we derive general worldknowledge from texts?
In HLT.Rion Snow, Daniel Jurafsky, and Andrew Y Ng.
2006.Semantic taxonomy induction from heterogenousevidence.
In ACL.Richard Socher, Danqi Chen, Christopher D Manning,and Andrew Ng.
2013.
Reasoning with neural ten-sor networks for knowledge base completion.
InNIPS.Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu,Oren Etzioni, et al.
2010.
Adapting open infor-mation extraction to domain-specific relations.
AIMagazine.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallap-ati, and Christopher D. Manning.
2012.
Multi-instance multi-label learning for relation extraction.In EMNLP.Niket Tandon, Gerard de Melo, and Gerhard Weikum.2011.
Deriving a web-scale common sense factdatabase.
In AAAI.V?
?ctor Manuel S?anchez Valencia.
1991.
Studies onnatural logic and categorial grammar.
Ph.D. thesis,University of Amsterdam.Johan van Benthem.
1986.
Essays in logical seman-tics.
Springer.Johan van Benthem.
2008.
A brief history of naturallogic.
Technical Report PP-2008-05, University ofAmsterdam.Benjamin Van Durme, Phillip Michalak, and Lenhart KSchubert.
2009.
Deriving generalized knowledgefrom corpora using wordnet abstraction.
In EACL.Ellen M Voorhees.
2001.
Question answering inTREC.
In Proceedings of the tenth internationalconference on Information and knowledge manage-ment.Limin Yao, Sebastian Riedel, and Andrew McCal-lum.
2012.
Probabilistic databases of universalschema.
In Proceedings of the Joint Workshop onAutomatic Knowledge Base Construction and Web-scale Knowledge Extraction.Alexander Yates, Michael Cafarella, Michele Banko,Oren Etzioni, Matthew Broadhead, and StephenSoderland.
2007.
TextRunner: Open informationextraction on the web.
In ACL-HLT.John M. Zelle and Raymond J. Mooney.
1996.
Learn-ing to parse database queries using inductive logicprogramming.
In AAAI/IAAI, Portland, OR.Luke S. Zettlemoyer and Michael Collins.
2007.
On-line learning of relaxed CCG grammars for parsingto logical form.
In EMNLP-CoNLL.545
