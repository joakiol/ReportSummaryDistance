Large Scale Collocation Data and Their Applicationto Japanese Word Processor TechnologyYasuo Koymna, Masako Yasutake, Kenji Yoshimura nd Kosho ShudoInstitute for Informalion and Conlrol Systmas, Fukuoka UniversityN ~  Fukuoka, 814-0180 Japankoymm@aisott co.jp, yasutake@helio.tt fukuoka-u.ac.jp, yosimura@flsmtl.fukuoka  ac.jp,shudo@flstm.tt fukuoka-u.ac.jpabstractWord processors or computers used in Japanemploy Japanese input method through key-board stroke combined with Kana (phonetic)character to Kanji (ideographic, Chinese) char-acter conversion technology.
The key factor ofKana-to-Kanji conversion technology is howto raise the accuracy of the conversion throughthe homophone processing, since we have somany homophonic Kanjis.
In this paper, wereport he results of our Kana-to-Kanji conver-sion experiments which embody the homo-phone processing based on large scale colloca-tion data.
It is shown that approximately135,000 collocations yield 9.1% raise of theconversion accuracy compared with the pro-totype system which has no collocation data.1.
IntroductionWord processors or computers used in Japan ordi-narily employ Japanese input method through key-board stroke combined ~ with Kana (phonetic) toKanji (ideographic, Chinese) character conversiontechnology.
The Kana-to-Kanji conversion is per-formed by the morphological nalysis on the inputKana siring with no space between words.
Word- orphrase-segmentation is carried out by the analysis toidentify the substring of the input which has to beconverted from Kana to Kanji.
Kana-Kanji mixedstring, which is the ordinary form of Japanese writ-ten text, is obtained as the final result.
The majorissue of this technology lies in raising the accuracyof the segmentation a d the homophone processingto select he correct Kanji among many homophoniccandidates.The conventional methodology for processing ho-mophones have used the function that gives the pri-ority to the word which was used lastly or to thehigh frequency word.
In fact, however, this methodsometimes tends to cause inadequate conversion dueto the lack of consideration f the semantic onsis-tency of the word concurrence.
While it is difficultto employ the syntactic or semantic processing inearnest for the word processor from the cost vs.performance viewpoints, for example, the followingtrials to improve the conversion accuracy have beenreported: Employing the case-frame to check thesemantic consistency of combination of words\[Oshima, Y. et al, 1986\].
Employing the neural net-work to describe the consistency of the concurrenceof words \[Kobayashi, T. et al,1992\], Making a con-currence dictionary for the specific topic or field,and giving the priority to the word which is in thedictionary when the topic is identified \[Yamamoto,K.
et al, 1992\].
In any of these studies, however,many problems are left unsolved in realizing itspractical system.Besides these semantic or quasi-semantic gadgets,we think it much more practical and effective to usesurface level resources, namely, to use extensivelythe collocation.
But how many collocations contrib-ute to the accuracy of Kana-to-Kanji conversion isnot known yet.In this paper, we present some results of our ex-periments of Kana-to-Kanji conversion, focusing onthe usage of large scale collocation data.
In chapter2, descriptions of the collocations used in our sys-tem and their classification are given.
In chapter 3,the technological framework of our Kana-to-Kanjiconversion systems is outlined.
In chapter 4, themethod and the results of the experiments are givenalong with some discussions.
In chapter 5, con-eluding remarks are given.2.
Collocation DataUnlike the recent works on the automatic extractionof collocations from corpus \[Church, K. W, et al1990, Ikehara, S. et al 1996, etc.\], our data havebeen collected manually through the intensive in-vestigation of various texts, spending years on it.This is because no stochastic framework assures the694accuracy of the extraction, amely the necessity andsufficiency of the data set.
The collocations whichare used in our Kana-to-Kanji conversion systemconsist of two kinds: (1) idiomatic expressions,whose meanings eem to be difficult to composefrom the typical meaning of the individual compo-nent words \[Shudo, K. et al, 1988\].
(2) stereotypicalexpressions in which the concurrence of componentwords is seen in the texts with high frequency.
Thecollocations are also classified into two classes by agrammatical criterion: one is a class of functionalcollocations, which work as functional words suchas particles (postpositionals) or auxiliary verbs, theother is a class of conceptual collocations whichwork as nouns, verbs, adjectives, adverbs, etc.
Thelatter is further classified into two kinds: uninter-ruptible collocations, whose concurrence r lation-ship of words are so strong that they can be dealtwith as single words, and interruptible collocations,which are occasionally used separately.In the following, the parenthesized number is thenumber of expressions adopted in the system.2.1 Functional Collocations (2,174)We call expressions which work like a particle rela-tional collocation and expressions which work likean auxiliary verb at the end of the predicate auxili-ary predicative collocation \[Shudo, K. et al, 1980\].relational collocations (760)ex.
\[ 7./') t, x-Cni/tuae (about)auxiliary predicative collocations (1,414)naKereoa/naranai (must)2.2 Uninterruptible Conceptual Col-locations (54,290)four-Kanji-compound (2,231)ex.
~ ZJlYg.gaaeninsut(every miller draws water to his own mill)adverb + particle type (3,089)ex ~t:,5,tz.&?
atafutat'o'(da sconcertedly)adverb + suru type (1,043)< <-?eX'agt~u<se~cusuru to i l  and moil)noun type (21,128)ex.
~09/~3,akano/tanin (perfect stranger)verb type (13,225)ex.
~ '9  ~J ~'~/~ 1-ootsur iga /~- ru  .
.
(be enough to make the change)adjective type (2,394)ex \ ] t~ L t,~?
uraganashii (mournful)adjective verb type (397)ex ~t~J~"goldge-n/naname (in a bad mood)adverb and other type (8,185)ex ~ 17../,~'C?
meni/miete (remarkably)proverb type (2,598)ex ~ I, ~'C I~I~J ~.I~ ~.?
otteha/koni/shitagae(when old, obey your children)2.3 Interruptible Conceptual Colloca-tions (78,251)noun type (7,627)ex.
~$(7)/tttt,akugyouno/mukui (fruit of an evil deed)verb type (64,087)ex.
~,~.
tt:~/~ I 7b~.~usnlrogamlwo/nlKareru(feel as if one's heart were left behind)adjective type (3,617)ex ~Tb~/:~-~ t,~"taittbgcr~ool~i ( act in a lordly manner)adjective verb type (2,018)ex.
tt~Tb~/?yakushaga/ue (be more able)others (902)ex ~lz/~li'J'~?
atoni/~il~nu (can not give up)3.
Kana-to-Kanji Conversion SystemsWe developed four different Kana-to-Kanji conver-sion systems, phasing in the collocation data de-scribed in 2.
The technological framework of thesystem is based on extended bunsetsu (e-bunsetsu) model \[Shndo, K. et al, 1980\] for theunit of the segmentation f the input Kana string,and on minimum cost method \[Yoshimura, K.
etal., 1987\] combined with Viterbi's algorithm\[Viterbi, A,, J., 1967\] for the reduction of the ambi-guity of the segmentation.A bnn.~etsu is the basic postpositional or predicative695phrase which composes Japanese sentences, and ane-bunsetsu, which is a natural extension of the bun-setsu, is defined roughly as follows:<e-bunsetsu>::= <prefix>* <conceptual word luninterruptible conceptual collocation><suffix>* <functional word lfunctional collocation>*The e-bunsetsu which includes no collocation is thebunsetsu.
More refmed rules are used in the actualsegmentation process.
The interruptible conceptualcollocation is not treated as a single unit but as astring ofbunsetsus inthe segmentation process.Each collocation in the dictionary which is com-posed of multiple number of bunsetsus i markedwith the boundary between bunsetsus.
The systemfirst tries to segment the input Kana string into e-bunsetsus.
Every possible segmentation is evaluatedby its cost.
A segmentation which is assigned theleast cost is chosen as the solution.The boundary between e-bunsetsus in examples inthis paper is denoted by "/".ex.
two results of e-bunsetsu-segmentation:, hitoh.a/kigqkikunikositagotol, taarimasen(there is nothing like being watchful)hitohdv'Mga/Idkimi/ko3itcv;kotoha/arimasenIn the above examples, JKT~/~I\] < kiga/kiku: isuninterruptible conceptual collocation and IS-/il~ I.,Lx/II~|~/~ ) ~'t~ A~ ni/kosita/kotoha/arimasen: isa functional collocation.
In the first example, thesecollocations are dealt with a single words.
Thesecond example shows the conventional bunsetsu-segmentation.The cost for the segmentation candidate is the sumof three partial costs: b-cost, c-cost and d-costshown below.
(1)a segment cost is assigned to each segment.
Sumof segment costs of all segments i the basic cost(b-cost) of a segmentation candidate.
By this, thecollocation tends to have priority over the ordi-nary word.
The standard and initial value of eachsegment cost is 2, and it is increased by 1 for eachoccurrence of the prefix, su_Wnx, etc.
in the seg-ment.
(2)a concatenation cost (c-cost) is assigned to speci-fic e-bunsetsu boundaries to revise the b-cost.The concatenation, such as adnominal-noun, ad-verb-verb, noun-noun, etc.
is paid a bonus ,namely anegative cost, -1.
(3)a dependency ost (d-cost), which has a negativevalue, is assigned to the strong dependency rela-tionship between conceptual words in the candi-date, representing the consistency of concurrenceof conceptual words.
By this, the segmentationcontaining the interrupted conceptual collocationtends to have priority.
The value of a d-cost variesfrom -3 to -1, depending on the strength of theconcurrence.
The interruptible conceptual collo-cation is given the biggest bonus i.e.-3.The reduction of the homophonic ambiguity, whichlimits Kanji candidates, is carried out in the courseof the segmentation a d its evaluation by the cost.3.1 Prototype System AWe first developed a prototype Kana-to-Kanji con-version system which we call System A, revisingKana-to-Kanji conversion software on the market,WXG Ver2.05 for PC.System A has no collocation data but conventionallexical resources, namely functional words (1,010)and conceptual words (131,66 I).3.2 System B, C and DWe reinforced System A to obtain System B, C andD by phasing in the following collocational re-sources.
System B is System A equipped addition-ally with functional collocations (2,174) and unin-terruptible conceptual collocations except for four-Kanji-compound and proverb type collocations(49,461).
System C is System B equipped addition-ally with four-Kanji-compound (2,231) and proverbtype collocations (2,598).
Further, System D isSystem C equipped additionally with interruptibleconceptual collocations (78,251).4.
Experiments4.1 Text Data for EvaluationPrior to the experiments of Kana-to-Kanji conver-sion, we prepared a large volume of text data byhand which is formally a set of triples whose firstcomponent a is a Kana string (a sentence) with nospace, The second component b is the correct seg-mentation result of a, indicating each boundarybetween bunsetsus with "/" or ".".
'7" and ....means obligatory and optional boundary, respec-tively.
The third component c is the correct conver-sion result of a, which is a Kana-Kanji mixed string.ex.
{ a: {S-;\[9\[s-\[~7b~l,~-Ct,~Toniwanibaragasaiteiru696(roses are in bloom in a garden)b: IZab)\[7-/\[~?~/~ \[, .
(,~70niwani/baraga/saite, iruc: I~I~.I#~#J~II~I,~T..I,x,'~ }The introduction of the optional boundary assuresthe flexible evaluation.
For example, each ofl~lA"C/t ,~ saite/iru (be in bloom) and I~I,~'CIA~saiteiru is accepted as a correct result.
The data fdeis divided into two sub-files, fl and 12, dependingon the number of bunsetsus in the Kana string a. flhas 10,733 triples, whose a has less than fivebunsetsus and t2 has 12,192 triples, whose a hasmore than four bunsetsus.4.2 Method of EvaluationEach a in the text data is fed to the conversion sys-tem.
The system outputs two forms of the least costresult: b', Kana string segmented to bunsetsus by"/", and c', Kana-Kanji mixed string correspondingto b and c of the correct data, respectively.
Each ofthe following three cases is counted for the evalua-tion.SS (Segmentation Success): bTM bCS (Complete Success): bTM b and ?
'= ?TS (Tolerative Success): b'= b and ?
'~ ?There are many kinds of notational f uctuation inJapanese.
For example, the conjugational suffix ofsome kind of Japanese verb is not always necessi-tated, therefore,~l,,I I'{'f,~fi I'I'Y and ~.1: are allacceptable r sults for input ~ L)~ I~ uriage (sales).Besides, a single word has sometimes more thanone Kanji notations, e.g.
"~g hama (beach) and ;~hama (beach) are both acceptable, and so on.
c'- ?in the case of TS means that e' coincides with ?completely or excepting the part which is hetero-morphic in the above sense.
For this, each of ourconversion system has a dictionary which containsapproximately 35,000 fluctuated notations of con-ceptual words.4.3 Results of ExperimentsResults of the experiments are given in Table 1 andTable 2 for input file fl and 12, respectively.Comparing the statistics of system A with D, we canconclude that the introduction of approximately135,000 collocation data causes 8.1% and 10.5 %raise of CS and TS rate, respectively, in case of re-latively short input strings (fl).
The raise of SS ratefor t"1 is 2.7%.
In case of the longer input strings (t2)whose average number of bunsetsus is approxi-mately 12.6, the raise ofCS, TS and SS rate is 2.4 %,5.2 % and 5.7 %, respectively.
As a consequence,the raise ofCS, TS and SS rate is 6.2 %, 9.1% and3.8 % on the average, respectively.SS(Segmentation Success)CS(Complete Success)TS(Tolerative Success)S~,stem A S)rstem B S~/stern C9,656(90.0?,6) 9,912(92.4%) 9,927(92.5%)5,085(47.4%) 5,638(52.5%) 5,677(52.9?,6)6,226(58.0?,6) 6,971(64.9?,6) 7,024(65.4?,6)Table 1 :Result of the experiments for10,733 short input strings d~a, fl.
(average number of Kana characters per input is 13.7)S~?stem D9,954(92.7%)5,953(55.5%)7,355(68.5%)SSCSTSS~tma A S) ,~ B S),stma C8,345(68.4%) 8,978(73.6%) 8,988(73.7%)2,422(19.9?,6) 2,660(21.8%) 2~673(21.90"6)3,965(32.5%) 4,555(37.4%) 4,568(37.5%)Table 2: Result ofthe expea-huents for 12,192 long input strings dam, t2.
(average number of Kana characters per input is 42.7)S~?stem D9,037(74.1%)2,717(22.3%)4,601(37.7%)S~-tem D' WXGSS 9,949(92.7%) 9,804(91.3%)CS 6,180(57.6%) 5,877(54.8?,6)TS 7,646(71.2%) 7,290(67.9?,6)Table 3 :CompmJson fsystem D' with WXG for fl.S mD'SS 8,928(73.2%) 8,815(72.3%)CS 2,738(22.5%) 2,694(22.1%)TS 4,649(38.1%) 4,543(37.3%)Table 4: Comparison fsystem D' with WXG for 12.6974.4 Comparison with a Software on theMarketWe compared System D with a Kana-to-Kanji conver-sion soRware for PC on the market, WXG Ver2.05 underthe same condition except for the anaount of installedcollocation dam For this, system D was reinforced andrenmned D', by equipping with WXG's 10,000 items ofword dependency description.
Both systems were dis-abled for the learning functiom WXG has approximately60,000 collocations (3,000 unintcrmptible and 57,000interruptible collocations), whereas Syst~nn D' has ap-proximately 135,000 collocations.
The statistical resultsare givm in Table 3 and Table 4 for the corpus fl and t2,respectively.The tables how that the raise of CS, TS and SS rme,which was oblained by System D' is 2.5 %, 4.5 % and3.9 % on the average, respectively.
No fialher compari-son with the conanercial products has been done, sincewe judge the perfommnce ofWXG Ver.2.05 to be aver-age among them.4.5 DiscussionsTable 1 '~ 4 show that the longer input the system isgiven, the more difficult for the system to make the cor-rect solution and the difference between accuracy rate ofWXG and system D' is less for f2 than for fl.
Furtherinvestigation clarified that the error of System D ismainly caused by missing words or expressions in themachine dictionmy.
Specifically, it was clmified that hedictionary does not have the sufficient number of Kata-Kzna words and people's names.
In Mdition, the numberof fluctualional variants installed in the dictionary men-fioned in 4.2 turned out to be inst~cient.
These problemsshould be rmaedied infuture.5.
Concluding RemarksIn this p,%~r, the effectiveness of the large scale colloca-tion data for the improvement of the conversion accuracyof Kana-to-Kanji conversion process used in Japmeseword processors was chrified, by relatively large scaleexperiments.The extensive collection of the collocations has beenc,m'fied out manually these ten years by the authors inorder to realize not only high precision word processorbut also more general Japanese language ~ infuture.
A lot of resources, chool texttx3oks, newspapers,novels, journals, dictionaries, etc.
have been investigatedby workers for the collection.
The candidates for the col-location have been judged one after another by them.Among collocations described inthis paper, the idiomaticexpressions are quite burdensome in the developmera ofNLP, since thW do not follow the principle of composi-lionality of the memaing Generally speaking the moreextensive collocational d__~___ it deals with, the less the"rule syst~n" of the rule based NLP system is burdened.This means the great importance of the enrichment ofcollocalional data Whereas it is inevitable that the ~oi-awiness lies in the human judgment and selection ofcollocations, we believe that our collocation r l~ is farmore refined than the automalicany extracted one fromcorpora which has been recently reported \[Church, K. W.etal, 1990, Ikeham, S. etal, 1996, etc.\].We believe that he approach descrlqxxi here is importantfor the evolution of NLP product in general s well.ReferencesShudo, K. et ~,  1980.
Morphological Aspect of JapaneseLanguage Processing, inProc.
of 8 th Int~a,-~Con?
onComps_ _ a~__'onal Linguistics(COLING80)Oshima, Y. et al, 1986.
A Disarnbiguation Method inKana-to-Kanji Conversion Using Case Frame Gram-rn,'~, in Trans.
oflPSJ, 27-7.
(in Japanese)Kobayashi, T. et al ,1986.
RealiTation of Kana-to-KanjiConversion Using Neural Networks.
in ToshibaReview, 47-11.
(in J~anese)Yoshimura, K. et a1.,1987.
Morphological Analysis of Ja-panese S~tences u ing the Least Cost Metho~ in IPSJSIG NL.60.
(in J   nese)Shudo, K. et al ,1988.
On the Idiomatic Expressions inJapanese Language.
in IPSJ SIG NL-66.
(in Japanese)Church, K.W.
et al 1990.
Word Association Norms,Mutual Information, and Lexicography.
inComput-ational Linguistics, 16.Yamamoto, K. et al ,1992.
Kana-to-Kanji ConversionUsing Co-occtm~ce Groups.
in Proc.
of44th Con?
ofIPSJ.
(in Japanese)Ikehara, S. et al,  1996.
A Statistical Method forExtracting Uninterrupted and Interrupted Collocationsl~om Very Large Corpora_ in Proc.
of 16th Internat.Conf.
on Computational Linguistics (COLING 96)Viterbi,A.,J., 1967,F_gor Bounds for Convolutional Codesand an Asymptotically Optimal Decoding Algorithm.in ~ Trans.
on Infommfion Theory 13.698
