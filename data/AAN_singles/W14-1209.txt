Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 74?83,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsImproving Readability of Swedish Electronic Health Recordsthrough Lexical Simplification: First ResultsGintar?e Grigonyt?ea, Maria Kvistbc, Sumithra Velupillaib, Mats Wir?enaaDepartment of Linguistics, Stockholm University, SwedenbDepartment of Computer and Systems Sciences, Stockholm University, SwedencDepartment of Learning, Informatics, Management and Ethics, Karolinska Institutet, Swedengintare@ling.su.se, maria.kvist@karolinska.se,sumithra@dsv.su.se, mats.wiren@ling.su.seAbstractThis paper describes part of an ongo-ing effort to improve the readability ofSwedish electronic health records (EHRs).An EHR contains systematic documenta-tion of a single patient?s medical historyacross time, entered by healthcare pro-fessionals with the purpose of enablingsafe and informed care.
Linguistically,medical records exemplify a highly spe-cialised domain, which can be superfi-cially characterised as having telegraphicsentences involving displaced or missingwords, abundant abbreviations, spellingvariations including misspellings, and ter-minology.
We report results on lexicalsimplification of Swedish EHRs, by whichwe mean detecting the unknown, out-of-dictionary words and trying to resolvethem either as compounded known words,abbreviations or misspellings.1 IntroductionAn electronic health record (EHR; Swedish: pa-tientjournal) contains systematic documentationof a single patient?s medical history across time,entered by healthcare professionals with the pur-pose of enabling safe and informed care.
Thevalue of EHRs is further increased by the fact thatthey provide a source of information for statis-tics and research, and a documentation for the pa-tient through the Swedish Patient Data Act.
EHRscollect information from a range of sources, suchas administration of drugs and therapies, test re-sults, preoperative notes, operative notes, progressnotes, discharge notes, etc.EHRs contain both structured parts (such asdetails about the patient, lab results, diagnosticcodes, etc.)
and unstructured parts (in the form offree text).
The free-text part of EHRs is referredto as clinical text, as opposed to the kind of gen-eral medical text found in medical journals, booksor web pages containing information about healthcare.
Clinical texts have many subdomains de-pending on the medical speciality of the writer andthe intended reader.
There are more formal kindsof EHRs, such as discharge summaries and radiol-ogy reports, directed to other physicians, and moreinformal kinds such as daily notes, produced bynurses and physicians (as memory notes for them-selves or for the team).
In spite of the Patient DataAct, the patient is seldom seen as a receiver orreader of the document.Linguistically, health records exemplify ahighly specialised domain, which can be super-ficially characterised as having telegraphic sen-tences involving displaced or missing words,abundant abbreviations, undisputed misspellings,spelling variation which may or may not amount tomisspellings depending on the degree of prescrip-tivism, and terminology.
While this specialisedstyle has evolved as an efficient means of com-munication between healthcare professionals, itpresents formidable challenges for laymen tryingto decode it.In spite of this, there has been no previous workon the problem of automatically improving thereadability of Swedish EHRs.
As an initial at-tempt in this direction, we provide an automaticapproach to the problem of lexical simplification,by which we mean detecting the unknown, out ofdictionary words and trying to resolve them eitheras compounds generated from known words, asabbreviations or as misspellings.
As an additionalresult, we obtain a distribution of how prevalentthese problems are in the clinical domain.2 Lexical challenges to readability ofEHRsA major reason for the obstacles to readability ofEHRs for laymen stems from the fact that they74are written under time pressure by professionals,for professionals (Kvist et al., 2011).
This re-sults in a telegraphic style, with omissions, ab-breviations and misspellings, as reported for sev-eral languages including Swedish, Finnish, En-glish, French, Hungarian and German (Laippalaet al., 2009; Friedman et al., 2002; Hag`ege etal., 2011; Surj?an and H?eja, 2003; Bretschneider etal., 2013).
The omitted words are often subjects,verbs, prepositions and articles (Friedman et al.,2002; Bretschneider et al., 2013).Unsurprisingly, medical terminology aboundsin EHRs.
What makes this problem an evengreater obstacle to readability is that many medicalterms (and their inflections) originate from Latinor Greek.
Different languages have adapted theseterms differently (Bretschneider et al., 2013).
TheSwedish medical terminology went through achange during the 1990s due to a swedificationof diagnostic expressions performed in the 1987update of the Swedish version of ICD, the Inter-national Classification of Diseases1.
For this ver-sion, the Swedish National Board of Health andWelfare decided to partly change the terminologyof traditional Latin- and Greek-rooted words to aspelling compatible to Swedish spelling rules, aswell as abandoning the original rules for inflec-tion (Smedby, 1991).
In this spelling reform, cand ch pronounced as k was changed to k, ph waschanged to f, th to t, and oe was changed to e.For example, the technical term for cholecsystitis(inflammation of the gall bladder) is spelled kole-cystit in contemporary Swedish, thus following theconvention of changing ch to k and removing theLatin ending of -is.
The results2of exact match-ing to kolecystit (English: cholecystitis) and somepresumed spelling variants clearly demonstrate theslow progress (Table 1).As medical literature is predominantly writtenin English nowadays, physicians increasingly getexposed to the English spelling of Latin and Greekwords rather than the Swedish one.
This has re-sulted in a multitude of alternate spellings of sev-eral medical terms.
For example, tachycardia(rapid heart) is correctly spelled takykardi, but is1http://www.who.int/classifications/icd/en/2Based on a subset of the Stockholm Electronic Pa-tient Record Corpus (Dalianis et al., 2012) of 100,000 dailynotes (DAY) written by physicians of varying disciplines (4mill.
tokens) and 435,000 radiology reports (X-RAY) writ-ten by radiologists (20 mill.
tokens).
KORP: http://spraakbanken.gu.se/korp/Term KORP DAY X-RAYkolecystit 51 48 84colecystit 0 1 8cholecystit 4 88 1613Table 1: Alternate spellings of the Swedishmedical term kolecystit (eng.
cholecystitis) inthe Swedish corpus collection Korp, daily notes(DAY) and radiology reports (X-RAY), respec-tively.
Correct spelling in bold.also frequently found as tachycardi, tachykardi,and takycardi (Kvist et al., 2011).
A similarFrench study found this kind of spelling variationto be abundant as well (Ruch et al., 2003).EHRs also contain neologisms.
These are oftenverbs, typically describing events relating to thepatient in active form, such as ?the patient is in-farcting?
(Swedish: patienten infarcerar) insteadof the unintentional ?the patient is having a my-ocardial infarction?.
Similar phenomena are de-scribed by Josefsson (1999).Abbreviations and acronyms in EHRs can fol-low standardised writing rules or be ad hoc (Liuet al., 2001).
They are often domain-specificand may be found in medical dictionaries suchas MeSH3and Snomed CT4.
For instance, 18 ofthe 100 most common words in Swedish radiol-ogy reports were abbreviations, and 10 of themwere domain-specific (Kvist and Velupillai, 2013).Because many medical terms are multiword ex-pressions that are repeated frequently in a pa-tient?s EHR, the use of acronyms is very common.Skeppstedt et al.
(2012) showed that 14% of di-agnostic expressions were abbreviated in Swedishclinical text.Abbreviations are often ambiguous.
As anexample, 33% of the short abbreviations in theUMLS terminology are ambiguous (Liu et al.,2001).
Pakhomov et al.
(2005) found that the ab-breviation RA had more than 20 expansions in theUMLS terminology alone.
Furthermore, a certainword or expression can be shortened in several dif-ferent ways.
For instance, in a Swedish intensivecare unit, the drug Noradrenalin was creativelywritten in 60 different ways by the nurses (Allvinet al., 2011).It should be noted that speech recognition, al-though common in many hospitals around the3www.ncbi.nlm.nih.gov4http://www.ihtsdo.org/75world, has not been introduced in Sweden, andmany physicians and all nurses type the notesthemselves.
This is one explanation to the vari-ation with respect to abbreviations.User studies have shown that the greatest bar-riers for patients lie mainly in the frequent useof abbreviations, jargon and technical terminol-ogy (Pyper et al., 2004; Keselman et al., 2007;Adnan et al., 2010).
The most common com-prehension errors made by laymen concern clini-cal concepts, medical terminology and medicationnames.
Furthermore, there are great challenges forhigher-level processing like syntax and semantics(Meystre et al., 2008; Wu et al., 2013).
The re-search presented in this paper focuses on lexicalsimplification of clinical text.3 Related researchWe are aware of several efforts to construct au-tomated text simplification tools for clinical textin English (Kandula et al., 2010; Patrick et al.,2010).
For Swedish, there are few studies on med-ical language from a readability perspective.
Borinet al.
(2009) present a thorough investigation onSwedish (and English) medical language, but EHRtexts are explicitly not included.
This section sum-marizes research on Swedish (clinical) text withrespect to lexical simplification by handling of ab-breviations, terminology and spelling correction.3.1 Abbreviation detectionAbbreviation identification in English biomedicaland clinical texts has been studied extensively (e.g.Xu et al.
(2007), Liu et al.
(2001)).
For detec-tion of Swedish medical abbreviations, there arefewer studies.
Dann?ells (2006) reports detectionof acronyms in medical journal text with 98% re-call and 94% precision by using part of speechinformation and heuristic rules.
Clinical Swedishpresents greater problems than medical texts, be-cause of ad hoc abbreviations and noisier text.
Byusing lexicons and a few heuristic rules, Isenius etal.
(2012) report the best F-score of 79% for ab-breviation detection in clinical Swedish.3.2 Compound splittingGood compound analysis is critical especially forlanguages whose orthographies concatenate com-pound components.
Swedish is among those lan-guages, in which every such concatenation thuscorresponds to a word.
The most common ap-proach to compound splitting is to base it on a lex-icon providing restrictions on how different wordforms can be used for generating compounds.
Forexample, Sj?obergh and Kann (2006) used a lex-icon derived from SAOL (the Swedish Academyword list), and?Ostling and Wir?en (2013) used theSALDO lexicon of Swedish morphology (Borinand Forsberg, 2009).
With this kind of approach,compound splitting is usually very reliable forgenres like newspaper text, with typical accuraciesfor Swedish around 97%, but performs poorer indomain specific genres.3.3 Terminology detectionThe detection of English medical terminology isa widely researched area.
An example of termdetection in English clinical texts is Wang andPatrick (2009) work based on rule-based and ma-chine learning methods, reporting 84% precision.For Swedish clinical text, Kokkinakis andThurin (2007) have employed domain terminol-ogy matching and reached 98% precision and 87%recall in detecting terms of disorders.
Using sim-ilar approaches, Skeppstedt et al.
(2012), reached75% precision and 55% recall in detecting termsof disorders.
With a machine learning based ap-proach, improved results were obtained: 80%precision, 82% recall (Skeppstedt et al., 2014).Skeppstedt et al.
(2012) have also demonstratedthe negative influence of abbreviations and mul-tiword expressions in their findings.3.4 Spelling correctionA system for general spelling correction ofSwedish is described by Kann et al.
(1998), butwe are not aware of any previous work related tospelling correction of Swedish clinical text.
Anexample of spelling correction of clinical text forother languages is Tolentino et al.
(2007), who useseveral algorithms for word similarity detection,including phonological homonym lookup and n-grams for contextual disambiguation.
They reporta precision of 64% on English medical texts.
An-other example is Patrick et al.
(2010) and Patrickand Nguyen (2011), who combine a mixture ofgeneration of spelling candidates based on ortho-graphic and phonological edit distance, and a 2-word window of contextual information for rank-ing the spelling candidates resulting in an accuracyof 84% on English patient records.
Sikl?oski et al.
(2013) use a statistical machine translation model76Figure 1: Distribution of 100 PR dataset sentences by length (number of sentences on the y-axis andnumber of tokens on the x-axis).
(with 3-grams) for spelling correction, achieving88% accuracy on Hungarian medical texts.4 Experimental dataThis study uses clinical notes5from the StockholmElectronic Patient Record corpus containing morethan 600,000 patients of all ages from more than500 health units during 2006?2013 (Dalianis et al.,2012).A randomly selected subset of 100 daily notesfrom different EHRs written by physicians be-tween 2009?2010 was used as a gold standarddataset for evaluating abbreviation detection, com-pound splitting and spelling corrections.
This 100daily notes dataset contains 433 sentences and3,888 tokens, as determined by Stagger (?Ostling,2013), a Swedish tokenizer and POS tagger.
Themajority of sentences contain between 4?11 to-kens (see Figure 1.
)The text snippet in Figure 2 provides an illus-trative example of the characteristics of a healthrecord.
What is immediately striking is the num-ber of misspellings, abbreviations, compounds andwords of foreign origin.
But also the syntax ispeculiar, alternating between telegraphic clauseswith implicit arguments, and long sentences withcomplex embeddings.5Approved by the Regional Ethical Review Board inStockholm (Etikpr?ovningsn?amnden i Stockholm), permis-sion number 2012/2028-31/55 Lexical normalization of EHRsNormalization of lexis in clinical text relies heav-ily on the lookup in available lexicons, corpora anddomain terminologies.
Although these resourcesusually cover the majority of words (i.e.
tokens)in texts, however due to the ever evolving lan-guage and knowledge inside the domain, medi-cal texts, when analysed with the NLP tools, alsocontain unknown6words.
These remaining wordsthat are not covered by any lexicon, or corpora re-source, can be misspellings, abbreviations, com-pounds (new word formations), words in foreignlanguages (Latin, Greek, English), or new terms.Our approach to dealing with unknown wordscombines a rule-based abbreviation detection andSwedish statistical language model-based com-pound analysis and misspelling resolution.The following sections describe three methodsthat are applied in a pipeline manner.
That is, first,all known abbreviations are detected and marked;second the unknown words are checked whetherthey are compounds; finally, for the remaining un-known words, context dependent word correctionsare made.5.1 Detecting abbreviationsThis section describes the heuristics and lexi-con lookup-based abbreviation detection method.The Swedish Clinical Abbreviation and Medi-cal Terminology Matcher (SCATM) is based on6By unknown words we mean words that cannot belooked up in available lexical resources or linguistically ana-lyzed by POS tokenizer.77Figure 2: Characteristics of a health record: misspellings (underline), abbreviations (bold), compounds(italic) and words of foreign origin (red).SCAN (Isenius et al., 2012).
The SCATM methoduses domain-adapted Stagger (?Ostling, 2013)for the tokenization and POS-tagging of text.The adapted version of Stagger handles clinical-specific7abbreviations from three domains, i.e.
ra-diology, emergency, and dietology.
SCATM alsouses several lexicons to determine whether a wordis a common word (in total 122,847 in the lexi-con), an abbreviation (in total 7,455 in the lexi-con), a medical term (in total 17,380 in the lexi-con), or a name (both first and last names, in total404,899 in the lexicon).
All words that are at most6 characters long, or contains the characters ?-?and/or ?.?
are checked against these lexicons in aspecific order in order to determine whether it isan abbreviation or not.The SCATM method uses various lexicons8ofSwedish medical terms, Swedish abbreviations,7Abbreviations that do not follow conventional orthogra-phy styles, e.g.
a typical abbreviation p.g.a.
(en.
due to) canhave the following variants p g a, pga, p. G. A., p. gr.
a.8the sources of lexicons are: anatomin.se,neuro.ki.se smittskyddsinstitutet.se,medicinskordbok.se, runeberg.org, g3.spraakdata.gu.se/saob, sv.wikipedia.org/wiki/Lista_ver_frkortningar, karolinska.se/Karolinska-Universitetslaboratoriet/Sidor-om-PTA/Analysindex-alla-enheter/Forkortningar/ and the list of Swedish names (Carlssonand Dalianis, 2010).Swedish words and Swedish names (first and last).5.2 Compound splittingFor compound splitting, we use a collection of lex-ical resources, the core of which is a full-formdictionary produced by Nordisk spr?akteknologiholding AS (NST), comprising 927,000 en-tries9.
In addition, various resources from themedical domain have been mined for vocab-ulary: Swedish SNOMED10terminology, theL?akartidningen medical journal11corpus, andSwedish Web health-care guides/manuals12.A refinement of the basic lexicon-driven tech-nique described in the related research section isthat our compound splitting makes use of contex-tual disambiguation.
As the example of hj?artekoillustrates, this compound can be hypotheticallysplit into13:hj?art+eko (en.
cardiac+echo)9Available at: www.nb.no/Tilbud/Forske/Spraakbanken/Tilgjengelege-ressursar/Leksikalske-ressursar10www.socialstyrelsen.se/nationellehalsa/nationelltfacksprak/11http://spraakbanken.gu.se/eng/research/infrastructure/korp12www.1177.se and www.vardguiden.se13Korp (http://spraakbanken.gu.se/korp) is a collection ofSwedish corpora, comprising 1,784,019,272 tokens, as ofJanuary 2014.78KORP freq.
: 642 + 5,669hj?arte+ko (en.
beloved+cow)KORP freq.
: 8 + 8,597For choosing the most likely composition in thegiven context, we use the Stockholm LanguageModel with Entropy (SLME) (?Ostling, 2012)which is a simple n-gram language model.The max probability defines the correct wordformation constituents:hj?art+eko 2.3e-04hj?arte+ko 5.1e-07The SMLE is described in the following section.5.3 Misspelling detectionThe unknown words that are not abbreviations orcompounds can very likely be misspellings.
Mis-spellings can be a result of typing errors or the lackof knowledge of the correct spelling.Our approach to clinical Swedish misspellingsis based on the best practices of spell checkersfor Indo-European languages, namely the phoneticsimilarity key method combined with a methodto measure proximity between the strings.
Inour spelling correction method, the Edit distance(Levenshtein, 1966) algorithm is used to measurethe proximity of orthographically possible can-didates.
The Soundex algorithm (Knuth, 1973)shortlists the spelling candidates which are phono-logically closest to the misspelled word.
Further,the spelling correction candidates are analyzed ina context by using the SLME n-gram model.The SLME employs the Google Web 1T 5-gram, 10 European Languages, Version 1, datasetfor Swedish, which is the largest publically avail-able Swedish data resource.
The SLME is a sim-ple n-gram language model, based on the StupidBackoff Model (Brants et al., 2007).
The n-gramlanguage model calculates the probability of aword in a given context:P (wL1) =L?i=1P (wi|wi?11) ?L?i=1?P (wi|wi?1i?n+1)(1)The maximum-likelihood probability estimatesfor the n-grams are calculated by their relative fre-quencies:r(wi|wi?1i?n+1) =f(wii?n+1)f(wi?1i?n+1)(2)The smoothing is used when the complete n-gram is not found.
If r(wi?1i?n+1) is not found,then the model looks for r(wi?1i?n+2) , r(wi?1i?n+3),and so on.
The Stupid backoff (Brants et al.,2007) smoothing method uses relative frequenciesinstead of normalized probabilities and context-dependent discounting.
Equation (3) shows howscore S is calculated:S(wi|wi?1i?k+1) ==????
?f(wii?k+1)f(wi?1i?k+1)iff(wii?k+1)) > 0?S(wi|wi?1i?k+2) otherwise(3)The backoff parameter ?
is set to 0.4, which washeuristically determined by (Brants et al., 2007).The recursion stops when the score for the lastcontext word is calculated.
N is the size of thecorpus.S(wi) =f(wi)N(4)The SLME n-gram model calculates theprobability of a word in a given context:p(word|context).
The following example14shows the case of spelling correction:Original:Vpl p?a onsdag.
UK tortdag.(en.
Vpl on wednesday.
UK thsday.
)torgdag (en.
marketday): 4.2e-10torsdag (en.
Thursday): 1.1e-06Corrected:Vpl p?a onsdag.
UK torsdag.6 Experiments and resultsOur approach to lexical normalization wastested against a gold standard, namely, the 100EHR daily notes dataset.
The dataset was anno-tated for abbreviations, compounds including ab-breviations and misspellings by a physician.We carried out the following experiments (seeTable 2):1.
SCATM to mark abbreviations and terms;14Vpl stands for V?ardplanering (en.
planning for care), UKstands for utskrivningsklar (en.
ready for discharge).79Method Lexical normalization task Gold-standard,occurencesPrecision, % Recall, %SCATM 1 Abbreviation detection 550 91.1 81.0SCATM 1a Abbreviations included incompounds only78 89.74 46.15NoCM 1 Out-of-dictionary compoundsplitting97 83.5 -NoCM 1a Out-of-dictionary com-pounds which includeabbreviations44 59.1 -NoCM 2 Spelling correction 41 54.8 63.12SCATM+NoCM Spelling correction 41 83.87 76.2Table 2: Results of lexical normalization.2.
NoCM (lexical normalization of compoundsand misspellings as described in sections5.2 and 5.3) to resolve compounds and mis-spellings;3.
The combined experiment SCATM+NoCMto resolve misspellings.The last experimental setting was designed as asolution to deal with compounds that include ab-breviations.
Marking abbreviations prior to thespelling correction can help to reduce the numberof false positives.The 433 sentences contained a total of 550 ab-breviations (78 of these were constituents of com-pound words), and 41 misspellings of which 13were misspelled words containing abbreviations.Due to the tokenization errors, a few sentenceboundaries were detected incorrectly, e.g.
inter-rupted dates and abbreviations.
Because of thissome abbreviations were separated into differentsentences and thus added to false negatives andfalse positives.The first experiment (SCATM 1 and 1a) of de-tecting abbreviations achieved both high precisionand recall.
As a special case of demonstrating thesource of errors (see SCATM 1a) is the evaluationof detecting abbreviations which are part of com-pounds only.
The low recall is due to the design ofthe SCATM which does not handle words longerthan 6 characters, thus resulting in compoundedabbreviations like k?arlkir or ?overvak to go unde-tected.The evaluation of the second experiment(NoCM 1, 1a and 2) showed that the majorityof out-of-dictionary compounds was resolved cor-rectly (NoCM 1) and reached 83.5% precision.Errors mainly occurred due to spelling candi-date ranking, e.g.
even+tull instead of eventuelland compounds containing abbreviations and mis-spelled words.
As a special case of demonstratingthe source of errors of the latter (see NoCM 1a) isthe evaluation of those compounds15only whichcontain abbreviations.
The task of spelling correc-tion (NoCM 2) performed poorly, reaching only54.8% precision.
This can be explained by failingto resolve misspellings in compounds where ab-breviations are compounded together with a mis-spelled words, e.g.
aciklocvirkonc (aciklovir kon-centrate).The third experiment (SCATM+NoCM) com-bined abbreviation detection followed by the out-of-dictionary word normalization (spelling cor-rection and compound splitting).
This settinghelped to resolve the earlier source of errors, i.e.words that contain both misspelling(s) and abbre-viation(s).
The overall precision of spelling cor-rection is 83.87%.7 ConclusionsOur attempt to address the problem of lexical sim-plification, and, in the long run, improve readabil-ity of Swedish EHRs, by automatically detectingand resolving out of dictionary words, achieves91.1% (abbreviations), 83.5% (compound split-ting) and 83.87% (spelling correction) precision,respectively.
These results are comparable to those15This number of compounds is derived from the numberof abbreviations included in compounds (from SCATM 1a)by selecting only those out-of -dictionary words which do notcontain punctuation.80reported in similar studies on English and Hungar-ian patient records (Patrick et al., 2010; Sikl?osi etal., 2013).Furthermore, the analysis of the gold standarddata revealed that around 14% of all words inSwedish EHRs are abbreviations.
More specifi-cally, 2% of all the words are compounds includ-ing abbreviations.
In contrast, and somewhat un-expectedly, only 1% are misspellings.
This dis-tribution result is an important finding for futurestudies in lexical simplification and readabilitystudies of EHRs, as it might be useful for inform-ing automatic processing approaches.We draw two conclusions from this study.
First,to advance research into the field of readabilityof EHRs, and thus to develop suitable readabilitymeasures it is necessary to begin by taking thesefindings into account and by relating abbrevia-tions, spelling variation, misspellings, compoundsand terminology to reading comprehension.Second, as a future guideline for the overallpipeline for detecting and resolving unknown, out-of-dictionary words, we suggest handling abbrevi-ations in a first step, and then taking care of mis-spellings and potential compounds.
The most ur-gent area for future improvement of the method isto handle compound words containing both abbre-viations and misspellings.AcknowledgementsThe authors wish to thank the anonymous review-ers for valuable feedback.
Maria Kvist and Sum-ithra Velupillai were in part funded by the V?ardalFoundation, Sumithra also by the Swedish Re-search Council and the Swedish Fulbright com-mission.
We thank Robert?Ostling who pro-vided the POS tagger and the Stockholm Lan-guage Model with Entropy.ReferencesM.
Adnan, J. Warren, and M. Orr.
2010.
Assess-ing text characteristics of electronic discharge sum-maries and their implications for patient readabil-ity.
In Proceedings of the Fourth Australasian Work-shop on Health Informatics and Knowledge Man-agement - Volume 108, HIKM ?10, pages 77?84,Darlinghurst, Australia, Australia.
Australian Com-puter Society, Inc.H.
Allvin, E. Carlsson, H. Dalianis, R. Danielsson-Ojala, V. Daudaravicius, M. Hassel, D. Kokki-nakis, H. Lundgren-Laine, G.H.
Nilsson, ?.
Nytr?,S.
Salanter?a, M. Skeppstedt, H. Suominen, andS.
Velupillai.
2011.
Characteristics of Finnish andSwedish intensive care nursing narratives: a com-parative analysis to support the development of clin-ical language technologies.
Journal of BiomedicalSemantics, 2(Suppl 3):S1, doi:10.1186/2041-1480-2-S3-S1, July.L.
Borin and M. Forsberg.
2009.
All in the family: Acomparison of SALDO and WordNet.
In Proceed-ings of the Nodalida 2009 Workshop on WordNetsand other Lexical Semantic Resources, pages 7?12.NEALT.L.
Borin, N. Grabar, M. Gronostaj, C. Hallett, D. Hard-castle, D. Kokkinakis, S. Williams, and A. Willis.2009.
Semantic Mining Deliverable D27.2: Em-powering the patient with language technology.Technical report, Semantic Mining (NOE 507505).T.
Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean.2007.
Large language models in machine transla-tion.
In In Proceedings of the 2007 Joint ConferenceEMNLP-CoNLL, pages 858?867.C.
Bretschneider, S. Zillner, and M. Hammon.
2013.Identifying pathological findings in German radiol-ogy reports using a syntacto-semantic parsing ap-proach.
In Proceedings of the 2013 Workshop onBiomedical Natural Language Processing (BioNLP2013).
ACL.E.
Carlsson and H. Dalianis.
2010.
Influence of Mod-ule Order on Rule-Based De-identification of Per-sonal Names in Electronic Patient Records Writ-ten in Swedish.
In Proceedings of the Seventh In-ternational Conference on Language Resources andEvaluation, LREC 2010, pages 3071?3075, Valletta,Malta, May 19?21.H.
Dalianis, M. Hassel, A. Henriksson, and M. Skepp-stedt.
2012.
Stockholm EPR Corpus: A ClinicalDatabase Used to Improve Health Care.
In PierreNugues, editor, Proc.
4th SLTC, 2012, pages 17?18,Lund, October 25-26.D.
Dann?ells.
2006.
Automatic acronym recognition.In Proceedings of the 11th conference on Europeanchapter of the Association for Computational Lin-guistics (EACL).C.
Friedman, P. Kra, and A. Rzhetsky.
2002.
Twobiomedical sublanguages: a description based on thetheories of Zellig Harris.
Journal of Biomedical In-formatics, 35(4):222?235.C.
Hag`ege, P. Marchal, Q. Gicquel, S. Darmoni,S.
Pereira, and M. Metzger.
2011.
Linguisticand temporal processing for discovering hospital ac-quired infection from patient records.
In Proceed-ings of the ECAI 2010 Conference on KnowledgeRepresentation for Health-care, KR4HC?10, pages70?84, Berlin, Heidelberg.
Springer-Verlag.N.
Isenius, S. Velupillai, and M. Kvist.
2012.
Initialresults in the development of scan: a swedish clini-cal abbreviation normalizer.
In Proceedings of the81CLEF 2012 Workshop on Cross-Language Evalu-ation of Methods, Applications, and Resources foreHealth Document Analysis - CLEFeHealth2012,Rome, Italy, September.
CLEF.G.
Josefsson.
1999.
F?a feber eller tempa?
N?agratankar om agentivitet i medicinskt fackspr?ak.S.
Kandula, D. Curtis, and Q. Zeng-Treitler.
2010.
ASemantic and Syntactic Text Simplification Tool forHealth Content.
In Proc AMIA 2010, pages 366?370.V.
Kann, R. Domeij, J. Hollman, and M. Tillenius.1998.
Implementation Aspects and Applications ofa Spelling Correction Algorithm.
.
Technical ReportTRITA-NA-9813, NADA, KTH.A.
Keselman, L. Slaughter, CA.
Smith, H. Kim, G. Di-vita, A. Browne, and et al.
2007.
Towardsconsumer-friendly PHRs: patients experience withreviewing their health records.
In AMIA Annu SympProc 2007, pages 399?403.D.
E. Knuth, 1973.
The Art of Computer Program-ming: Volume 3, Sorting and Searching, pages 391?392.
Addison-Wesley.D.
Kokkinakis and A. Thurin.
2007.
Identifica-tion of Entity References in Hospital Discharge Let-ters.
In Proceedings of the 16th Nordic Conferenceof Computational Linguistics (NODALIDA) 2007,pages 329?332, Tartu, Estonia.M.
Kvist and S. Velupillai.
2013.
ProfessionalLanguage in Swedish Radiology Reports ?
Char-acterization for Patient-Adapted Text Simplifica-tion.
In Proceedings of the Scandinavian Con-ference on Health Informatics 2013, Copenhagen,Denmark, August.
Link?oping University ElectronicPress, Link?opings universitet.M.
Kvist, M. Skeppstedt, S. Velupillai, and H. Dalianis.2011.
Modeling human comprehension of swedishmedical records for intelligent access and summa-rization systems, a physician?s perspective.
In Proc.9th Scandinavian Conference on Health Informat-ics, SHI, Oslo, August.V.
Laippala, F. Ginter, S. Pyysalo, and T. Salakoski.2009.
Towards automated processing of clinicalFinnish: Sublanguage analysis and a rule-basedparser.
Int journal of medical informatics, 78:e7?e12.VI Levenshtein.
1966.
Binary Codes Capable of Cor-recting Deletions, Insertions and Reversals.
SovietPhysics Doklady, 10:707?710.H.
Liu, Y.
A. Lussier, and C. Friedman.
2001.
Disam-biguating Ambiguous Biomedical Terms in Biomed-ical Narrative Text: An Unsupervised Method.Journal of Biomedical Informatics, 34:249?261.S.
M. Meystre, G. K. Savova, K. C. Kipper-Schuler,and John E. Hurdle.
2008.
Extracting informa-tion from textual documents in the electronic healthrecord: a review of recent research.
IMIA Yearbookof Medical Informatics 2008.
47 Suppl 1:138-154.R.
?Ostling and M. Wir?en, 2013.
Compounding ina Swedish Blog Corpus, pages 45?63.
StockholmStudies in Modern Philology.
New series 16.
Stock-holm university.R.?Ostling.
2012.http://www.ling.su.se/english/nlp/tools/slme/stockholm-language-model-with-entropy-slme-1.101098 .R.?Ostling.
2013.
Stagger: an Open-Source Part ofSpeech Tagger for Swedish.
Northern EuropeanJournal of Language Technology, 3:1?18.S.
Pakhomov, T. Pedersen, and C. G. Chute.
2005.
Ab-breviation and Acronym Disambiguation in ClinicalDiscourse.
In Proc AMIA 2005, pages 589?593.J.
Patrick and D. Nguyen.
2011.
Automated ProofReading of Clinical Notes.
In Helena Hong Gaoand Minghui Dong, editors, PACLIC, pages 303?312.
Digital Enhancement of Cognitive Develop-ment, Waseda University.J.
Patrick, M. Sabbagh, S. Jain, and H. Zheng.
2010.Spelling correction in Clinical Notes with Emphasison First Suggestion Accuracy.
In 2nd Workshop onBuilding and Evaluating Resources for BiomedicalText Mining, pages 2?8.C.
Pyper, J. Amery, M. Watson, and C. Crook.
2004.Patients experiences when accessing their on-lineelectronic patient records in primary care.
TheBritish Journal of General Practice, 54:38?43.P.
Ruch, R. Baud, and A. Geissb?uhler.
2003.
Usinglexical disambiguation and named-entity recogni-tion to improve spelling correction in the electronicpatient record.
Artificial Intelligence in Medicine,29(1-2):169?184.B.
Sikl?osi, A. Nov?ak, and G. Pr?osz?eky, 2013.
Context-Aware Correction of Spelling Errors in Hungar-ian Medical Documents, pages 248?259.
NumberLecture Notes in Computer Science 7978.
SpringerBerlin Heidelberg.J.
Sj?obergh and V. Kann.
2006.
Vad kan statistikavsl?oja om svenska sammans?attningar?
Spr?ak ochstil, 1:199?214.M.
Skeppstedt, M. Kvist, and H Dalianis.
2012.Rule-based Entity Recognition and Coverage ofSNOMED CT in Swedish Clinical Text.
In Pro-ceedings of the Eighth International Conference onLanguage Resources and Evaluation, LREC 2012,pages 1250?1257, Istanbul, Turkey, May 23?25.M.
Skeppstedt, M. Kvist, G. H. Nilsson, and H. Dalia-nis.
2014.
Automatic recognition of disorders,findings, pharmaceuticals and body structures from82clinical text: An annotation and machine learn-ing study.
Journal of Biomedical Informatics,http://dx.doi.org/10.1016/j.jbi.2014.01.012.B.
Smedby.
1991.
Medicinens Spr?ak: spr?aketi sjukdomsklassifikationen ?
mer konsekventf?orsvenskning efterstr?avas [Language of Medicine:the language of diagnose classification - moreconsequent Swedification sought].
L?akartidningen,pages 1519?1520.G.
Surj?an and G. H?eja.
2003.
About the language ofHungarian discharge reports.
Stud Health TechnolInform, 95:869?873.H.
D. Tolentino, M. D. Matters, W. Walop, B. Law,W.
Tong, F. Liu, P. A. Fontelo, K. Kohl, and D. C.Payne.
2007.
A UMLS-based spell checker for nat-ural language processing in vaccine safety.
BMCMed.
Inf.
& Decision Making, 7.Y.
Wang and J. Patrick.
2009.
Cascading classifiers fornamed entity recognition in clinical notes.
In Pro-ceedings of the Workshop on Biomedical Informa-tion Extraction, WBIE ?09, pages 42?49, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.D.
T. Y. Wu, D. A. Hanauer, Q. Mei, P. M. Clark,L.
C. An, J. Lei, J. Proulx, Q. Zeng-Treitler, andK.
Zheng.
2013.
Applying Multiple Methods to As-sess the Readability of a Large Corpus of MedicalDocuments.
Stud Health Technol Inform, 192:647?651.H.
Xu, P. D. Stetson, and C. Friedman.
2007.
A Studyof Abbreviations in Clinical Notes.
In Proc AMIA2007, pages 821?825.83
