Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 229?232,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsSpeakers?
Intention Prediction Using Statistics of Multi-level Features ina Schedule Management DomainDonghyun Kim Hyunjung Lee Choong-Nyoung SeonDiquest Research Center Computer Science & Engineering Computer Science & EngineeringDiquest Inc. Sogang University Sogang UniversitySeoul, Korea Seoul, Korea Seoul, Koreakdh2007@sogang.ac.kr juvenile@sogang.ac.kr wilowisp@gmail.comHarksoo Kim Jungyun SeoComputer & Communications Engineering Computer Science & EngineeringKangwon National University Sogang UniversityChuncheon, Korea Seoul, Koreanlpdrkim@kangwon.ac.kr seojy@sogang.ac.krAbstractSpeaker?s intention prediction modules can bewidely used as a pre-processor for reducingthe search space of an automatic speech re-cognizer.
They also can be used as a pre-processor for generating a proper sentence in adialogue system.
We propose a statisticalmodel to predict speakers?
intentions by usingmulti-level features.
Using the multi-level fea-tures (morpheme-level features, discourse-level features, and domain knowledge-levelfeatures), the proposed model predicts speak-ers?
intentions that may be implicated in nextutterances.
In the experiments, the proposedmodel showed better performances (about29% higher accuracies) than the previousmodel.
Based on the experiments, we foundthat the proposed multi-level features are veryeffective in speaker?s intention prediction.1 IntroductionA dialogue system is a program in which a userand system communicate in natural language.
Tounderstand user?s utterance, the dialogue systemshould identify his/her intention.
To respondhis/her question, the dialogue system should gen-erate the counterpart of his/her intention by refer-ring to dialogue history and domain knowledge.Most previous researches on speakers?
intentionshave been focused on intention identification tech-niques.
On the contrary, intention prediction tech-niques have been not studied enough althoughthere are many practical needs, as shown in Figure1.When is the changed date?Response, Timetable-update-dateAsk-ref, Timetable-update-dateIt is changed into 4 May.It is changed into 14 May.
?Prediction ofuser?s intentionIdentification ofsystem?s intentionReducing the search spaceof an ASRIt is changed into 12:40.The date is changed.Is it changed into 4 May?
?It is changed into 4 May.The result ofspeech recognitionExample 1: Prediction of user?s intentionExample 2: Prediction of system?s intentionIt is 706-8954.Ask-confirm, Timetable-insert-phonenumResponse, Timetable-insert-phonenumResponse generationIs it 706-8954?Identification ofuser?s intentionPrediction ofsystem?s intentionFigure 1.
Motivational exampleIn Figure 1, the first example shows that an inten-tion prediction module can be used as a pre-processor for reducing the search space of an ASR(automatic speech recognizer).
The second exam-ple shows that an intention prediction module canbe used as a pre-processor for generating a propersentence based on dialogue history.There are some researches on user?s intentionprediction (Ronnie, 1995; Reithinger, 1995).
Rei-thinger?s model used n-grams of speech acts asinput features.
Reithinger showed that his modelcan reduce the searching complexity of an ASR to19~60%.
However, his model did not achieve goodperformances because the input features were notrich enough to predict next speech acts.
The re-searches on system?s intention prediction havebeen treated as a part of researches on dialoguemodels such as a finite-state model, a frame-based229model (Goddeau, 1996), and a plan-based model(Litman, 1987).
However, a finite-state model hasa weak point that dialogue flows should be prede-fined.
Although a plan-based model can managecomplex dialogue phenomena using plan inference,a plan-based model is not easy to be applied to thereal world applications because it is difficult tomaintain plan recipes.
In this paper, we propose astatistical model to reliably predict both user?s in-tention and system?s intention in a schedule man-agement domain.
The proposed model determinesspeakers?
intentions by using various levels of lin-guistic features such as clue words, previous inten-tions, and a current state of a domain frame.2 Statistical prediction of speakers?
inten-tions2.1 Generalization of speakers?
intentionsIn a goal-oriented dialogue, speaker?s intention canbe represented by a semantic form that consists ofa speech act and a concept sequence (Levin, 2003).In the semantic form, the speech act represents thegeneral intention expressed in an utterance, and theconcept sequence captures the semantic focus ofthe utterance.Table 1.
Speech acts and their meaningsSpeech act DescriptionGreeting The opening greeting of a dialogueExpressive The closing greeting of a dialogueOpening Sentences for opening a goal-oriented dialogueAsk-ref WH-questionsAsk-if YN-questionsResponse Responses of questions or requesting actionsRequest Declarative sentences for requesting actionsAsk-confirm Questions for confirming the previous actionsConfirm Reponses of ask-confirmInform Declarative sentences for giving some informationAccept AgreementTable 2.
Basic concepts in a schedule managementdomain.Table name Operation name Field nameTimetable Insert, Delete, Select, UpdateAgent, Date, Day-of-week,Time, Person, PlaceAlarm Insert, Delete, Select, Update Date, TimeBased on these assumptions, we define 11 domain-independent speech acts, as shown in Table 1, and53 domain-dependent concept sequences accordingto a three-layer annotation scheme (i.e.
Fully con-necting basic concepts with bar symbols) (Kim,2007) based on Table 2.
Then, we generalizespeaker?s intention into a pair of a speech act and aconcept sequence.
In the remains of this paper, wecall a pair of a speech act and a concept sequence)an intention.2.2 Intention prediction modelGiven n utterancesnU ,1  in a dialogue, let 1+nSI  de-note speaker?s intention of the n+1th utterance.Then, the intention prediction model can be for-mally defined as the following equation:)|,(maxarg)|(,111,,1111nnnCSSAnn UCSSAPUSIPnn+++++?
(1)In Equation (1), 1+nSA  and 1+nCS  are the speech actand the concept sequence of the n+1th utterance,respectively.
Based on the assumption that theconcept sequences are independent of the speechacts, we can rewrite Equation (1) as Equation (2).
)|()|(maxarg)|(,11,11,,1111nnnnCSSAnn UCSPUSAPUSIPnn+++++?
(2)In Equation (2), it is impossible to directly com-pute )|(,11 nn USAP +  and )|( ,11 nn UCSP +  because a speakerexpresses identical contents with various surfaceforms of n sentences according to a personal lin-guistic sense in a real dialogue.
To overcome thisproblem, we assume that n utterances in a dialoguecan be generalized by a set of linguistic featurescontaining various observations from the first ut-terance to the nth utterance.
Therefore, we simplifyEquation (2) by using a linguistic feature set 1+nFS(a set of features that are accumulated from thefirst utterance to nth utterance) for predicting then+1th intention, as shown in Equation (3).
)|()|(maxarg)|( 1111,,1111+++++++?
nnnnCSSAnn FSCSPFSSAPUSIPnn(3)All terms of the right hand side in Equation (3) arerepresented by conditional probabilities given avarious feature values.
These conditional probabili-ties can be effectively evaluated by CRFs (condi-tional random fields) (Lafferty, 2001) that globallyconsider transition probabilities from the first ut-230terance to the n+1th utterance, as shown in Equa-tion (4).
)),(exp()(1)|()),(exp()(1)|(111,11,11,1111,11,11,1+=++++=+++==ni jiijjnnnCRFni jiijjnnnCRFFSCSFFSZFSCSPFSSAFFSZFSSAP??
(4)In Equation (4), ),( iij FSSAF and ),( iij FSCSF  are fea-ture functions for predicting the speech act and theconcept sequence of the ith utterance, respectively.
)(FSZ  is a normalization factor.
The feature func-tions receive binary values (i.e.
zero or one) ac-cording to absence or existence of each feature.2.3 Multi-level featuresThe proposed model uses multi-level features asinput values of the feature functions in Equation(4).
The followings give the details of the proposedmulti-level features.?
Morpheme-level feature: Sometimes a fewwords in a current utterance give importantclues to predict an intention of a next utterance.We propose two types of morpheme-level fea-tures that are extracted from a current utterance:One is lexical features (content words annotatedwith parts-of-speech) and the other is POS fea-tures (part-of-speech bi-grams of all words inan utterance).
To obtain the morpheme-levelfeatures, we use a conventional morphologicalanalyzer.
Then, we remove non-informativefeature values by using a well-known 2?
statis-tic because the previous works in documentclassification have shown that effective featureselection can increase precisions (Yang, 1997).?
Discourse-level feature: An intention of a cur-rent utterance affects that dialogue participantsdetermine intentions of next utterances becausea dialogue consists of utterances that are se-quentially associated with each other.
We pro-pose discourse-level features (bigrams ofspeakers?
intentions; a pair of a current inten-tion and a next intention) that are extractedfrom a sequence of utterances in a current di-alogue.?
Domain knowledge-level feature: In a goal-oriented dialogue, dialogue participants accom-plish a given task by using shared domainknowledge.
Since a frame-based model is moreflexible than a finite-state model and is moreeasy-implementable than a plan-based model,we adopt the frame-based model in order to de-scribe domain knowledge.
We propose twotypes of domain knowledge-level features; slot-modification features and slot-retrieval features.The slot-modification features represent whichslots are filled with suitable items, and the slot-retrieval features represent which slots arelooked up.
The slot-modification features andthe slot-retrieval features are represented by bi-nary notation.
In the slot-modification features,?1?
means that the slot is filled with a properitem, and ?0?
means that the slot is empty.
Inthe slot-retrieval features, ?1?
means that theslot is looked up one or more times.
To obtaindomain knowledge-level features, we prede-fined speakers?
intentions associated with slotmodification (e.g.
?response & timetable-update-date?)
and slot retrieval (e.g.
?request &timetable-select-date?
), respectively.
Then, weautomatically generated domain knowledge-level features by looking up the predefined in-tentions at each dialogue step.3 Evaluation3.1 Data sets and experimental settingsWe collected a Korean dialogue corpus simulatedin a schedule management domain such as ap-pointment scheduling and alarm setting.
The dialo-gue corpus consists of 956 dialogues, 21,336utterances (22.3 utterances per dialogue).
Eachutterance in dialogues was manually annotatedwith speech acts and concept sequences.
The ma-nual tagging of speech acts and concept sequenceswas done by five graduate students with the know-ledge of a dialogue analysis and post-processed bya student in a doctoral course for consistency.
Toexperiment the proposed model, we divided theannotated messages into the training corpus andthe testing corpus by a ratio of four (764 dialogues)to one (192 dialogues).
Then, we performed 5-foldcross validation.
We used training factors of CRFsas L-BGFS and Gaussian Prior.3.2 Experimental resultsTable 3 and Table 4 show the accuracies of theproposed model in speech act prediction and con-cept sequence prediction, respectively.231Table 3.
The accuracies of speech act predictionFeatures Accuracy-S (%) Accuracy-U (%)Morpheme-levelfeatures 76.51 72.01Discourse-levelfeatures 87.31 72.80Domain know-ledge-level feature 63.44 49.03All features 88.11 76.25Table 4.
The accuracies of concept sequence pre-dictionFeatures Accuracy-S (%) Accuracy-U (%)Morpheme-levelfeatures 66.35 59.40Discourse-levelfeatures 86.56 62.62Domain know-ledge-level feature 37.68 49.03All features 87.19 64.21In Table 3 and Table 4, Accuracy-S means the ac-curacy of system?s intention prediction, and Accu-racy-U means the accuracy of user?s intentionprediction.
Based on these experimental results, wefound that multi-level features include differenttypes of information and cooperation of the multi-level features brings synergy effect.
We also foundthe degree of feature importance in intention pre-diction (i.e.
discourse level features > morpheme-level features > domain knowledge-level features).To evaluate the proposed model, we comparethe accuracies of the proposed model with those ofReithinger?s model (Reithinger, 1995) by using thesame training and test corpus, as shown in Table 5.Table 5.
The comparison of accuraciesSpeaker Type Reithinger?smodelThe proposedmodelSystemSpeech act 43.37 88.11Concept sequence 68.06 87.19User Speech act 37.59 76.25 Concept sequence 49.48 64.21As shown in Table 5, the proposed model outper-formed Reithinger?s model in all kinds of predic-tions.
We think that the differences betweenaccuracies were mainly caused by input features:The proposed model showed similar accuracies toReithinger?s model when it used only domainknowledge-level features.4 ConclusionWe proposed a statistical prediction model ofspeakers?
intentions using multi-level features.
Themodel uses three levels (a morpheme level, a dis-course level, and a domain knowledge level) offeatures as input features of the statistical modelbased on CRFs.
In the experiments, the proposedmodel showed better performances than the pre-vious model.
Based on the experiments, we foundthat the proposed multi-level features are very ef-fective in speaker?s intention prediction.AcknowledgmentsThis research (paper) was performed for the Intel-ligent Robotics Development Program, one of the21st Century Frontier R&D Programs funded bythe Ministry of Commerce, Industry and Energy ofKorea.ReferencesD.
Goddeau, H. Meng, J. Polifroni, S. Seneff, and S.Busayapongchai.
1996.
?A Form-Based DialogueManager for Spoken Language Applications?, Pro-ceedings of International Conference on SpokenLanguage Processing, 701-704.D.
Litman and J. Allen.
1987.
A Plan Recognition Mod-el for Subdialogues in Conversations, CognitiveScience, 11:163-200.H.
Kim.
2007.
A Dialogue-based NLIDB System in aSchedule Management Domain: About the method toFind User?s Intentions, Lecture Notes in ComputerScience, 4362:869-877.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
?Condi-tional Random Fields: Probabilistic Models for Seg-menting And Labeling Sequence Data?, Proceedingsof ICML, 282-289.L.
Levin, C. Langley, A. Lavie, D. Gates, D. Wallace,and K. Peterson.
2003.
?Domain Specific SpeechActs for Spoken Language Translation?, Proceedingsof the 4th SIGdial Workshop on Discourse and Di-alogue.N.
Reithinger and E. Maier.
1995.
?Utilizing StatisticalDialog Act Processing in VerbMobil?, Proceedingsof ACL, 116-121.R.
W. Smith and D. R. Hipp, 1995.
Spoken NaturalLanguage Dialogue Systems: A Practical Approach,Oxford University Press.Y.
Yang and J. Pedersen.
1997.
?A Comparative Studyon Feature Selection in Text Categorization?, Pro-ceedings of the 14th International Conference onMachine Learning.232
