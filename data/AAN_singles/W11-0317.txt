Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 145?153,Portland, Oregon, USA, 23?24 June 2011. c?2011 Association for Computational LinguisticsUsing Second-order Vectors in aKnowledge-based Method for Acronym DisambiguationBridget T. McInnes?College of PharmacyUniversity of MinnesotaMinneapolis, MN 55455Ted PedersenDepartment of Computer ScienceUniversity of MinnesotaDuluth, MN 55812Ying LiuCollege of PharmacyUniversity of MinnesotaMinneapolis, MN 55455Serguei V. PakhomovCollege of PharmacyUniversity of MinnesotaMinneapolis, MN 55455Genevieve B. MeltonInstitute for Health InformaticsUniversity of MinnesotaMinneapolis, MN 55455AbstractIn this paper, we introduce a knowledge-basedmethod to disambiguate biomedical acronymsusing second-order co-occurrence vectors.
Wecreate these vectors using information about along-form obtained from the Unified MedicalLanguage System and Medline.
We evaluatethis method on a dataset of 18 acronyms foundin biomedical text.
Our method achieves anoverall accuracy of 89%.
The results showthat using second-order features provide a dis-tinct representation of the long-form and po-tentially enhances automated disambiguation.1 IntroductionWord Sense Disambiguation (WSD) is the taskof automatically identifying the appropriate sense ofa word with multiple senses.
For example, the wordculture could refer to anthropological culture(e.g., the culture of the Mayan civilization), or alaboratory culture (e.g., cell culture).Acronym disambiguation is the task of automat-ically identifying the contextually appropriate long-form of an ambiguous acronym.
For example, theacronym MS could refer to the disease Multiple Scle-rosis, the drug Morphine Sulfate, or the state Missis-sippi, among others.
Acronym disambiguation canbe viewed as a special case of WSD, although, un-like terms, acronyms tend to be complete phrasesor expressions, therefore collocation features arenot as easily identified.
For example, the featurerate when disambiguating the term interest, as in?Contact author : bthomson@umn.edu.interest rate, may not be available.
Acronyms alsotend to be noun phrases, therefore syntactic featuresdo not provide relevant information for the purposesof disambiguation.Identifying the correct long-form of an acronymis important not only for the retrieval of informationbut the understanding of the information by the re-cipient.
In general English, Park and Byrd (2001)note that acronym disambiguation is not widelystudied because acronyms are not as prevalent in lit-erature and newspaper articles as they are in specificdomains such as government, law, and biomedicine.In the biomedical sublanguage domain, acronymdisambiguation is an extensively studied problem.Pakhomov (2002) note acronyms in biomedical lit-erature tend to be used much more frequently than innews media or general English literature, and tendto be highly ambiguous.
For example, the Uni-fied Medical Language System (UMLS), which in-cludes one of the largest terminology resources inthe biomedical domain, contains 11 possible long-forms of the acronym MS in addition to the fourexamples used above.
Liu et al (2001) show that33% of acronyms are ambiguous in the UMLS.
In asubsequent study, Liu et al (2002a) found that 80%of all acronyms found in Medline, a large repositoryof abstracts from biomedical journals, are ambigu-ous.
Wren and Garner (2002) found that there exist174,000 unique acronyms in the Medline abstractsin which 36% of them are ambiguous.
The authorsalso estimated that the number of unique acronymsis increasing at a rate of 11,000 per year.Supervised and semi-supervised methods havebeen used successfully for acronym disambiguation145but are limited in scope due to the need for sufficienttraining data.
Liu et al (2004) state that an acronymcould have approximately 16 possible long-forms inMedline but could not obtain a sufficient number ofinstances for each of the acronym-long-form pairsfor their experiments.
Stevenson et al (2009) citea similar problem indicating that acronym disam-biguation methods that do not require training data,regardless if it is created manually or automatically,are needed.In this paper, we introduce a novel knowledge-based method to disambiguate acronyms usingsecond-order co-occurrence vectors.
This methoddoes not rely on training data, and therefore, is notlimited to disambiguating only commonly occurringpossible long-forms.
These vectors are created us-ing the first-order features obtained from the UMLSabout the acronym?s long-forms and second-orderfeatures obtained from Medline.
We show that us-ing second-order features provide a distinct repre-sentation of the long-form for the purposes of dis-ambiguation and obtains a significantly higher dis-ambiguation accuracy than using first order features.2 Unified Medical Language SystemThe Unified Medical Language System (UMLS) isa data warehouse that stores a number of distinctbiomedical and clinical resources.
One such re-source, used in this work, is the Metathesaurus.The Metathesaurus contains biomedical and clin-ical concepts from over 100 disparate terminol-ogy sources that have been semi-automatically in-tegrated into a single resource containing a widerange of biomedical and clinical information.
Forexample, it contains the Systematized Nomencla-ture of Medicine?Clinical Terms (SNOMED CT),which is a comprehensive clinical terminology cre-ated for the electronic exchange of clinical healthinformation, the Foundational Model of Anatomy(FMA), which is an ontology of anatomical conceptscreated specifically for biomedical and clinical re-search, and MEDLINEPLUS, which is a terminol-ogy source containing health related concepts cre-ated specifically for consumers of health services.The concepts in these sources can overlap.
Forexample, the concept Autonomic nerve exists in bothSNOMED CT and FMA.
The Metathesaurus assignsthe synonymous concepts from the various sourcesa Concept Unique Identifiers (CUIs).
Thus boththe Autonomic nerve concepts in SNOMED CT andFMA are assigned the same CUI (C0206250).
Thisallows multiple sources in the Metathesaurus to betreated as a single resource.Some sources in the Metathesaurus contain ad-ditional information about the concept such as aconcept?s synonyms, its definition and its relatedconcepts.
There are two main types of relationsin the Metathesaurus that we use: the parent/childand broader/narrower relations.
A parent/child re-lation is a hierarchical relation between two con-cepts that has been explicitly defined in one of thesources.
For example, the concept Splanchnic nervehas an is-a relation with the concept Autonomicnerve in FMA.
This relation is carried forward tothe CUI level creating a parent/child relations be-tween the CUIs C0037991 (Splanchnic nerve) andC0206250 (Autonomic nerve) in the Metathesaurus.A broader/narrower relation is a hierarchical relationthat does not explicitly come from a source but iscreated by the UMLS editors.
We use the entireUMLS including the RB/RN and PAR/CHD rela-tions in this work.3 MedlineMedline (Medical Literature Analysis and RetrievalSystem Online) is a bibliographic database contain-ing over 18.5 million citations to journal articlesin the biomedical domain which is maintained bythe National Library of Medicine (NLM).
The 2010Medline Baseline, used in this study, encompassesapproximately 5,200 journals starting from 1948 andis 73 Gigabytes; containing 2,612,767 unique uni-grams and 55,286,187 unique bigrams.
The majorityof the publications are scholarly journals but a smallnumber of newspapers, and magazines are included.4 Acronym DisambiguationExisting acronym disambiguation methods can beclassified into two categories: form-based andcontext-based methods.
Form-based methods, suchas the methods proposed by Taghva and Gilbreth(1999), Pustejovsky et al (2001), Schwartz andHearst (2003) and Nadeau and Turney (2005), dis-ambiguate the acronym by comparing its letters di-146rectly to the initial letters in the possible long-formsand, therefore, would have difficulties in distin-guishing between acronyms with similar long-forms(e.g., RA referring to Refractory anemia or Rheuma-toid arthritis).In contrast, context-based methods disambiguatebetween acronyms based on the context in which theacronym is used with the assumption that the contextsurrounding the acronym would be different for eachof the possible long-forms.
In the remainder of thissection, we discuss these types of methods in moredetail.4.1 Context-based Acronym DisambiguationMethodsLiu et al (2001) and Liu et al (2002b) introducea semi-supervised method in which training andtest data are automatically created by extracting ab-stracts from Medline that contain the acronym?slong-forms.
The authors use collocations and a bag-of-words approach to train a Naive Bayes algorithmand report an accuracy of 97%.
This method be-gins to treat acronym disambiguation as more of aWSD problem by looking at the context in whichthe acronym exists to determine its long-form, ratherthan the long-form itself.
In a subsequent study, Liuet al (2004) explore using additional features andmachine learning algorithms and report an accuracyof 99% using the Naive Bayes.Joshi (2006) expands on Liu, et als work.
Theyevaluate additional machine learning algorithms us-ing unigrams, bigrams and trigrams as features.They found that given their feature set, SVMs ob-tain the highest accuracy (97%).Stevenson et al (2009) re-recreate this dataset us-ing the method described in Liu et al (2001) to auto-matically create training data for their method whichuses a mixture of linguistics features (e.g., colloca-tions, unigrams, bigrams and trigrams) in combina-tion with the biomedical features CUIs and Medi-cal Subject Headings, which are terms manually as-signed to Medline abstracts for indexing purposes.The authors evaluate the Naive Bayes, SVM andVector Space Model (VSM) described by Agirre andMartinez (2004), and report that VSM obtained thehighest accuracy (99%).Pakhomov (2002) also developed a semi-supervised method in which training data wasautomatically created by first identifying the long-form found in the text of clinical reports, replacingthe long-form with the acronym to use as trainingdata.
A maximum entropy model trained and testedon a corpus of 10,000 clinical notes achieved anaccuracy of 89%.
In a subsequent study, Pakhomovet al (2005) evaluate obtaining training data fromthree sources: Medline, clinical records and theworld wide web finding using a combination ofinstances from clinical records and the web obtainedthe highest accuracy.Joshi et al (2006) compare using the NaiveBayes, Decision trees and SVM on ambiguousacronyms found in clinical reports.
The authorsuse the part-of-speech, the unigrams and the bi-grams of the context surrounding the acronym asfeatures.
They evaluate their method on 7,738manually disambiguated instances of 15 ambiguousacronyms obtaining an accuracy of over 90% foreach acronym.5 Word Sense DisambiguationMany knowledge-based WSD methods have beendeveloped to disambiguate terms which are closelyrelated to the work presented in this paper.
Lesk(1986) proposes a definition overlap method inwhich the appropriate sense of an ambiguous termwas determined based on the overlap between itsdefinition in a machine readable dictionary (MRD).Ide and Ve?ronis (1998) note that this work provideda basis for most future MRD disambiguation meth-ods; including the one presented in this paper.Banerjee and Pedersen (2002) use the Lesk?soverlap method to determine the relatedness be-tween two concepts (synsets) in WordNet.
They ex-tend the method to not only include the definition(gloss) of the two synsets in the overlap but also theglosses of related synsets.Wilks et al (1990) expand upon Lesk?s method bycalculating the number of times the words in the def-inition co-occur with the ambiguous words.
In theirmethod, a vector is created using the co-occurrenceinformation for the ambiguous word and each of itspossible senses.
The similarity is then calculated be-tween the ambiguous word?s vector and each of thesense vectors.
The sense whose vector is most simi-lar is assigned to the ambiguous word.1470.3000000disphosphoricglucosefructosephosphoricesterschangedeffect00000glycolyteenzymescombineddecreasesintensityacid0metabolitesFEATURES0000.20acid000.1000000.500esters0000000.1000000000000000000fructose0000000000000diphosphate000000isomer0000000prevalent0000000.10.3.5.202nd order vector forFructose Diphosphate000.100ExtendedDefinitionfor FructoseDiphosphateFigure 1: 2nd Order Vector for Fructose Diphosphate (FDP)Patwardhan and Pedersen (2006) introduce a vec-tor measure to determine the relatedness betweenpairs of concepts.
In this measure, a second orderco-occurrence vector is created for each concept us-ing the words in each of the concepts definition andcalculating the cosine between the two vectors.
Thismethod has been used in the task of WSD by calcu-lating the relatedness between each possible senseof the ambiguous word and its surrounding context.The context whose sum is the most similar is as-signed to the ambiguous word.Second-order co-occurrence vectors were first in-troduced by Schu?tze (1992) for the task of wordsense discrimination and later extended by Puran-dare and Pedersen (2004).
As noted by Pedersen(2010), disambiguation requires a sense-inventoryin which the long-forms are known ahead of time,where as in discrimination this information is notknown a priori.6 MethodIn our method, a second-order co-occurrence vec-tor is created for each possible long-form of theacronym, and the acronym itself.
The appropriatelong-form of the acronym is then determined bycomputing a cosine between the vector represent-ing the ambiguous acronym and each of the vectorsrepresenting the long-forms.
The long-form whosevector has the smallest angle between it and theacronym vector is chosen as the most likely long-form of the acronym.To create a second-order vector for a long-form,we first obtain a textual description of the long-formin the UMLS, which we refer to as the extended defi-nition.
Each long-form, from our evaluation set, wasmapped to a concept in the UMLS, therefore, we usethe long-form?s definition plus the definition of itsparent/children and narrow/broader relations and theterms in the long-form.We include the definition of the related conceptsbecause not all concepts in the UMLS have a defini-tion.
In our evaluation dataset, not a single acronymhas a definition for each possible long-form.
Onaverage, each extended definition contains approx-imately 453 words.
A short example of the extendeddefinition for the acronym FDP when referring to148fructose diphosphate is: ?
Diphosphoric acid estersof fructose.
The fructose diphosphate isomer is mostprevalent.
fructose diphosphate.
?After the extended definition is obtained, we cre-ate the second-order vector by first creating a wordby word co-occurrence matrix in which the rowsrepresent the content words in the long-forms, ex-tended definition, and the columns represent wordsthat co-occur in Medline abstracts with the words inthe definition.
Each cell in this matrix contains theLog Likelihood Ratio (Dunning (1993)) of the wordfound in the row and the word in the column.
Sec-ond, each word in the long-forms, extended defini-tion is replaced by its corresponding vector, as givenin the co-occurrence matrix.
The centroid of thesevectors constitutes the second order co-occurrencevector used to represent the long-form.For example, given the example corpus contain-ing two instances: 1) The metabolites, glucose fruc-tose and their phosphoric acid esters are changeddue to the effect of glycolytic enzymes, and 2)The phosphoric acid combined with metabolites de-creases the intensity.
Figure 1 shows how thesecond-order co-occurrence vector is created for thelong-form fructose diphosphate using the extendeddefinition and features from our given corpus above.The second-order co-occurrence vector for theambiguous acronym is created in a similar fashion,only rather than using words in the extended defini-tion, we use the words surrounding the acronym inthe instance.Vector methods are subject to noise introduced byfeatures that do not distinguish between the differ-ent long-forms of the acronym.
To reduce this typeof noise, we select the features to use in the secondorder co-occurrence vectors based on the followingcriteria: 1) second order feature cannot be a stop-word, and 2) second order feature must occur at leasttwice in the feature extraction dataset and not occurmore than 150 times.
We also experiment with thelocation of the second-order feature with respect tothe first-order feature by varying the window size ofzero, four, six and ten words to the right and the leftof the first-order feature.
The experiments in thispaper were conducted using CuiTools v0.15.
1Our method is different from other context-based1http://cuitools.sourceforge.netacronym disambiguation methods discussed in therelated work because it does not require annotatedtraining data for each acronym that needs to be dis-ambiguated.
Our method differs from the methodproposed by Wilks et al (1990) in two fundamen-tal aspects: 1) using the extended definition ofthe possible long-forms of an acronym, and 2) usingsecond-order vectors to represent the instance con-taining the acronym and each of the acronym?s pos-sible long-forms.7 Data7.1 Acronym DatasetWe evaluated our method on the ?Abbrev?
dataset 2made available by Stevenson et al (2009).
Theacronyms and long-forms in the data were initiallypresented by Liu et al (2001).
Stevenson et al(2009) automatically re-created this dataset by iden-tifying the acronyms and long-forms in Medline ab-stracts and replacing the long-form in the abstractwith its acronym.
Each abstract contains approxi-mately 216 words.
The dataset consists of three sub-sets containing 100 instances, 200 instances and 300instances of the ambiguous acronym referred to asAbbrev.100, Abbrev.200, Abbrev.300, respectively.The acronyms long-forms were manually mapped toconcepts in the UMLS by Stevenson, et alA sufficient number of instances were not foundfor each of the 21 ambiguous acronyms by Steven-son et al (2009).
For example, ?ASP?
only con-tained 71 instances and therefore not included in anyof the subsets.
?ANA?
and ?FDP?
only containedjust over 100 instances and therefore, are only in-cluded in the Abbrev.100 subset.
?ACE?, ?ASP?and ?CSF?
were also excluded because several ofthe acronyms?
long-forms did not occur frequentlyenough in Medline to create a balanced dataset.We evaluate our method on the same subsets thatStevenson et al (2009) used to evaluate their super-vised method.
The average number of long-formsper acronym is 2.6 and the average majority senseacross all subsets is 70%.7.2 Feature Extraction DatasetWe use abstracts from Medline, containing ambigu-ous acronym or long-form, to create the second-2http://nlp.shef.ac.uk/BioWSD/downloads/corpora149order co-occurrence vectors for our method as de-scribed in Section 6.
Table 1 shows the number ofMedline abstracts extracted for the acronyms.Acronyms # Abstracts Acronym # AbstractsANA 3,267 APC 11,192BPD 3,260 BSA 10,500CAT 44,703 CML 8,777CMV 13,733 DIP 2,912EMG 16,779 FDP 1,677LAM 1,572 MAC 6,528MCP 2,826 PCA 11,044PCP 5,996 PEG 10,416PVC 2,780 RSV 5,091Table 1: Feature Extraction Data for Acronyms8 ResultsTable 2 compares the majority sense baseline and thefirst-order baseline with the results obtained usingour method on the Acronym Datasets (Abbrev.100,Abbrev.200 and Abbrev.300) using a window sizeof zero, four, six and ten.
Differences between themeans of disambiguation accuracy produced by var-ious approaches were tested for statistical signifi-cance using the pair-wise Student?s t-tests with thesignificance threshold set to 0.01.Window AbbrevSize 100 200 300Maj.
Sense Baseline 0.70 0.70 0.701-order Baseline 0.57 0.61 0.61Our Method0 0.83 0.83 0.814 0.86 0.87 0.866 0.88 0.90 0.8910 0.88 0.90 0.89Table 2: Overall Disambiguation ResultsThe majority sense baseline is often used to evalu-ate supervised learning algorithms and indicates theaccuracy that would be achieved by assigning themost frequent sense (long-form) to every instance.The results in Table 2 demonstrate that our method issignificantly more accurate than the majority sensebaseline (p ?
0.01).We compare the results using second-order vec-tors to first-order vectors.
Table 2 shows that ac-curacy of the second-order results is significantlyhigher than the first-order results (p ?
0.01).The results in Table 2 also show that, as the win-dow size grows from zero to six, the accuracy of thesystem increases and plateaus at a window size often.
There is no statistically significant differencebetween using a window size of six and ten but thereis a significant difference between a window size ofzero and six, as well as four and six (p ?
0.01).Acronym # Long Abbrev Abbrev Abbrevforms 100 200 300ANA 3 0.84APC 3 0.88 0.87 0.87BPD 3 0.96 0.95 0.95BSA 2 0.95 0.93 0.92CAT 2 0.88 0.87 0.87CML 2 0.81 0.84 0.83CMV 2 0.98 0.98 0.98DIP 2 0.98 0.98EMG 2 0.88 0.89 0.88FDP 4 0.65LAM 2 0.86 0.87 0.88MAC 4 0.94 0.95 0.95MCP 4 0.73 0.67 0.68PCA 4 0.78 0.79 0.79PCP 2 0.97 0.96 0.96PEG 2 0.89 0.89 0.88PVC 2 0.95 0.95RSV 2 0.97 0.98 0.98Table 3: Individual Results using a Window Size of 6.9 Error AnalysisTable 3 shows the results obtained by our method forthe individual acronyms using a window size of six,and the number of possible long-forms per acronym.Of the 18 acronyms, three obtain an accuracy below80 percent: FDP, MCP and PCA.FPD has four possible long-forms: FructoseDiphosphate (E1), Formycin Diphosphate (E2), Fib-rinogen Degradation Product (E3) and Flexor Dig-itorum Profundus (E4).
The confusion matrix inTable 4 shows that the method was unable to dis-tinguish between the two long-forms, E1 and E2,which are both diphosphates, nor E2 and E3.Long-Form E1 E2 E3 E4E1: Fructose DiphosphateE2: Formycin Diphosphate 5 2 11 19E3: Fibrinogen Degradation Product 4E4: Flexor Digitorum Profundus 59Table 4: FDP Confusion MatrixMCP also has four possible long-forms: Multicat-alytic Protease (E1), Metoclopramide (E2), Mono-cyte Chemoattractant Protein (E3) and Membrane150Cofactor Protein (E4).
The confusion matrix in Ta-ble 5 shows that the method was not able to distin-guish between E3 and E4, which are both proteins,and E1, which is a protease (an enzyme that breaksdown a protein).Long-Form E1 E2 E3 E4E1: Multicatalytic Protease 1 5 6 1E2: Metoclopramide 15E3: Monocyte Chemoattractant Protein 1 3 44 11E4: Membrane Cofactor Protein 13Table 5: MCP Confusion MatrixPCA has four possible long-forms: Passive Cu-taneous Anaphylaxis (E1), Patient Controlled Anal-gesia (E2), Principal Component Analysis (E3), andPosterior Cerebral Artery (E4).
The confusion ma-trix in Table 6 shows that the method was not ableto distinguish between E2 and E3.
Analyzing theextended definitions of the concepts showed that E2includes the definition to the concept Pain Manage-ment.
The words in this definition overlap withmany of the words used in E3s extended definition.Long-Form E1 E2 E3 E4E1:Passive Cutaneous Anaphylaxis 18 6 1E2:Patient Controlled Analgesia 5 15E3:Principal Component Analysis 48E4:Posterior Cerebral Artery 7Table 6: PCA Confusion Matrix10 Comparison with Previous WorkOf the previously developed methods, Liu et al(2004) and Stevenson et al (2009) evaluated theirsemi-supervised methods on the same dataset as weused for the current study.
A direct comparisoncan not be made between our method and Liu et al(2004) because we do not have an exact duplicationof the dataset that they use.
Their results are com-parable to Stevenson et al (2009) with both report-ing results in the high 90s.
Our results are directlycomparable to Stevenson et al (2009) who reportan overall accuracy of 98%, 98% and 99% on theAbbrev.100, Abbrev.200 and Abbrev.300 datasetsrespectively.
This is approximately 10 percentagepoints higher than our results.The advantage of the methods proposed byStevenson et al (2009) and Liu et al (2004) is thatthey are semi-supervised which have been shown toobtain higher accuracies than methods that do notuse statistical machine learning algorithms.
The dis-advantage is that sufficient training data are requiredfor each possible acronym-long-form pair.
Liu etal.
(2004) state that an acronym could have approxi-mately 16 possible long-forms in Medline but a suf-ficient number of instances for each of the acronym-long-form pairs were not found in Medline and,therefore, evaluated their method on 15 out of theoriginal 34 acronyms.
Stevenson et al (2009) citea similar problem in re-creating this dataset.
Thisshows the limitation to these methods is that a suffi-cient number of training examples can not be ob-tained for each acronym that needs to be disam-biguated.
The method proposed in the paper doesnot have this limitation and can be used to disam-biguate any acronym in Medline.11 DiscussionIn this paper, we presented a novel method to disam-biguate acronyms in biomedical text using second-order features extracted from the UMLS and Med-line.
The results show that using second-order fea-tures provide a distinct representation of the long-form that is useful for disambiguation.We believe that this is because biomedical textcontains technical terminology that has a rich sourceof co-occurrence information associated with themdue to their compositionality.
Using second-orderinformation works reasonably well because whenthe terms in the extended definition are broken upinto their individual words, information is not beinglost.
For example, the term Patient Controlled Anal-gesia can be understood by taking the union of themeanings of the three terms and coming up with anappropriate definition of the term (patient has con-trol over their analgesia).We evaluated various window sizes to extract thesecond-order co-occurrence information from, andfound using locally occurring words obtains a higheraccuracy.
This is consistent with the finding reportedby Choueka and Lusignan (1985) who conducted anexperiment to determine what size window is neededfor humans to determine the appropriate sense of anambiguous word.The amount of data used to extract the second-151order features for each ambiguous acronym varieddepending on its occurrence in Medline.
Table 1 inSection 7.2 shows the number of abstracts in Med-line used for each acronym.
We compared the accu-racy obtained by our method using a window size ofsix on the Abbrev.100 dataset with the number of ab-stracts in the feature extraction data.
We found thatthe accuracy was not correlated with the amount ofdata used (r = 0.07).
This confirms that it is not thequantity but the content of the contextual informa-tion that determines the accuracy of disambiguation.We compared using second-order features andfirst-order features showing that the second-order re-sults obtained a significantly higher accuracy.
Webelieve that this is because the definitions of the pos-sible concepts are too sparse to provide enough in-formation to distinguish between them.
This find-ing coincides to that of Purandare and Pedersen(2004) and Pedersen (2010) who found that withlarge amounts of data, first-order vectors performbetter than second-order vectors, but second-ordervectors are a good option when large amounts ofdata are not available.The results of the error analysis indicate thatfor some acronyms using the extended definitiondoes not provide sufficient information to makefiner grained distinctions between the long-forms.This result also indicates that, although many long-forms of acronyms can be considered coarse-grainedsenses, this is not always the case.
For example, theanalysis of MCP showed that two of its possiblelong-forms are proteins which are difficult to differ-entiate from given the context.The results of the error analysis also show thatindicative collocation features for acronyms are noteasily identified because acronyms tend to be com-plete phrases.
For example, two of the possiblelong-forms of DF are Fructose Diphosphate andFormycin Diphosphate.Two main limitations of this work must be men-tioned to facilitate the interpretation of the results.The first is the small number of acronyms and thesmall number of long-forms per acronym in thedataset; however, the acronyms in this dataset arerepresentative of the kinds of acronyms one wouldexpect to see in biomedical text.
The second limita-tion is that the dataset contains only those acronymswhose long-forms were found in Medline abstracts.The main goal of this paper was to determine if thecontext found in the long-forms, extended definitionwas distinct enough to distinguish between them us-ing second-order vectors.
For this purpose, we feelthat the dataset was sufficient although a more ex-tensive dataset may be needed in the future for im-proved coverage.12 Future WorkIn the future, we plan to explore three differentavenues.
The first avenue is to look at obtainingcontextual descriptions of the possible long-formsfrom resources other than the UMLS such as theMetaMapped Medline baseline and WordNet.
Thesecond avenue is limiting the features that are usedin the instance vectors.
The first-order features inthe instance vector contain the words from the entireabstract.
As previously mentioned, vector methodsare subject to noise, therefore, in the future we planto explore using only those words that are co-locatednext to the ambiguous acronym.
The third avenue isexpanding the vector to allow for terms.
Currently,we use word vectors, in the future, we plan to extendthe method to use terms, as identified by the UMLS,as features rather than single words.We also plan to test our approach in the clinicaldomain.
We believe that acronym disambiguationmay be more difficult in this domain due to the in-crease amount of long-forms as seen in the datasetsused by Joshi et al (2006) and Pakhomov (2002).13 ConclusionsOur study constitutes a significant step forward inthe area of automatic acronym ambiguity resolu-tion, as it will enable the incorporation of scalableacronym disambiguation into NLP systems used forindexing and retrieval of documents in specializeddomains such as medicine.
The advantage of ourmethod over previous methods is that it does not re-quire manually annotated training for each acronymto be disambiguated while still obtaining an overallaccuracy of 89%.AcknowledgmentsThis work was supported by the National Insti-tute of Health, National Library of Medicine Grant#R01LM009623-01.152ReferencesE.
Agirre and D. Martinez.
2004.
The Basque CountryUniversity system: English and Basque tasks.
In Pro-ceedings of the 3rd ACL workshop on the Evaluationof Systems for the Semantic Analysis of Text (SENSE-VAL), pages 44?48.S.
Banerjee and T. Pedersen.
2002.
An adapted lesk al-gorithm for word sense disambiguation using Word-Net.
In Proceedings of the 3rd International Confer-ence on Intelligent Text Processing and ComputationalLinguistics, pages 136?145.Y.
Choueka and S. Lusignan.
1985.
Disambiguationby short contexts.
Computers and the Humanities,19(3):147?157.T.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Computational Linguistics,19(1):61?74.N.
Ide and J.
Ve?ronis.
1998.
Introduction to the specialissue on word sense disambiguation: the state of theart.
Computational Linguistics, 24(1):2?40.M.
Joshi, S. Pakhomov, T. Pedersen, and C.G.
Chute.2006.
A comparative study of supervised learning asapplied to acronym expansion in clinical reports.
InProceedings of the Annual Symposium of AMIA, pages399?403.M.
Joshi.
2006.
Kernel Methods for Word Sense Disam-biguation and Abbreviation Expansion.
Master?s the-sis, University of Minnesota.M.
Lesk.
1986.
Automatic sense disambiguation usingmachine readable dictionaries: how to tell a pine conefrom an ice cream cone.
Proceedings of the 5th AnnualInternational Conference on Systems Documentation,pages 24?26.H.
Liu, YA.
Lussier, and C. Friedman.
2001.
Disam-biguating ambiguous biomedical terms in biomedicalnarrative text: an unsupervised method.
Journal ofBiomedical Informatics, 34(4):249?261.H.
Liu, A.R.
Aronson, and C. Friedman.
2002a.
A studyof abbreviations in MEDLINE abstracts.
In Proceed-ings of the Annual Symposium of AMIA, pages 464?468.H.
Liu, S.B.
Johnson, and C. Friedman.
2002b.
Au-tomatic resolution of ambiguous terms based on ma-chine learning and conceptual relations in the UMLS.JAMIA, 9(6):621?636.H.
Liu, V. Teller, and C. Friedman.
2004.
A multi-aspect comparison study of supervised word sense dis-ambiguation.
JAMIA, 11(4):320?331.D.
Nadeau and P. Turney.
2005.
A supervised learningapproach to acronym identification.
In Proceedingsof the 18th Canadian Conference on Artificial Intelli-gence, pages 319?329.S.
Pakhomov, T. Pedersen, and C.G.
Chute.
2005.
Ab-breviation and acronym disambiguation in clinical dis-course.
In Proceedings of the Annual Symposium ofAMIA, pages 589?593.S.
Pakhomov.
2002.
Semi-supervised maximum en-tropy based approach to acronym and abbreviationnormalization in medical texts.
In Proceedings ofthe 40th Annual Meeting on Association for Compu-tational Linguistics, pages 160?167.Y.
Park and R.J. Byrd.
2001.
Hybrid text mining for find-ing abbreviations and their definitions.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 126?133.S.
Patwardhan and T. Pedersen.
2006.
Using WordNet-based context vectors to estimate the semantic related-ness of concepts.
In Proceedings of the EACL 2006Workshop Making Sense of Sense - Bringing Com-putational Linguistics and Psycholinguistics Together,pages 1?8.T.
Pedersen.
2010.
The effect of different context repre-sentations on word sense discrimination in biomedicaltexts.
In Proceedings of the 1st ACM International IHISymposium, pages 56?65.A.
Purandare and T. Pedersen.
2004.
Word sense dis-crimination by clustering contexts in vector and sim-ilarity spaces.
In Proceedings of the Conference onComputational Natural Language Learning (CoNLL),pages 41?48.J.
Pustejovsky, J. Castano, B. Cochran, M. Kotecki,M.
Morrell, and A. Rumshisky.
2001.
Extraction anddisambiguation of acronym-meaning pairs in medline.Unpublished manuscript.H.
Schu?tze.
1992.
Dimensions of meaning.
In Proceed-ings of the 1992 ACM/IEEE Conference on Supercom-puting, pages 787?796.A.S.
Schwartz and M.A.
Hearst.
2003.
A simplealgorithm for identifying abbreviation definitions inbiomedical text.
In Proceedings of the Pacific Sym-posium on Biocomputing (PSB), pages 451?462.M.
Stevenson, Y. Guo, A. Al Amri, and R. Gaizauskas.2009.
Disambiguation of biomedical abbreviations.In Proceedings of the ACL BioNLP Workshop, pages71?79.K.
Taghva and J. Gilbreth.
1999.
Recognizing acronymsand their definitions.
ISRI UNLV, 1:191?198.Y.
Wilks, D. Fass, C.M.
Guo, J.E.
McDonald, T. Plate,and B.M.
Slator.
1990.
Providing machine tractabledictionary tools.
Machine Translation, 5(2):99?154.J.D.
Wren and H.R.
Garner.
2002.
Heuristics for iden-tification of acronym-definition patterns within text:towards an automated construction of comprehensiveacronym-definition dictionaries.
Methods of Informa-tion in Medicine, 41(5):426?434.153
