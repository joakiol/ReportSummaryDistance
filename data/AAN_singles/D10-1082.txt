Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 843?852,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsA Fast Decoder for Joint Word Segmentation and POS-Tagging Using aSingle Discriminative ModelYue Zhang and Stephen ClarkUniversity of Cambridge Computer LaboratoryWilliam Gates Building,15 JJ Thomson Avenue,Cambridge CB3 0FD, UK{yue.zhang, stephen.clark}@cl.cam.ac.ukAbstractWe show that the standard beam-search al-gorithm can be used as an efficient decoderfor the global linear model of Zhang andClark (2008) for joint word segmentation andPOS-tagging, achieving a significant speed im-provement.
Such decoding is enabled by:(1) separating full word features from par-tial word features so that feature templatescan be instantiated incrementally, according towhether the current character is separated orappended; (2) deciding the POS-tag of a poten-tial word when its first character is processed.Early-update is used with perceptron trainingso that the linear model gives a high score to acorrect partial candidate as well as a full out-put.
Effective scoring of partial structures al-lows the decoder to give high accuracy with asmall beam-size of 16.
In our 10-fold cross-validation experiments with the Chinese Tree-bank, our system performed over 10 times asfast as Zhang and Clark (2008) with little ac-curacy loss.
The accuracy of our system onthe standard CTB 5 test was competitive withthe best in the literature.1 Introduction and MotivationSeveral approaches have been proposed to solveword segmentation and POS-tagging jointly, includ-ing the reranking approach (Shi and Wang, 2007;Jiang et al, 2008b), the hybrid approach (Nakagawaand Uchimoto, 2007; Jiang et al, 2008a), and thesingle-model approach (Ng and Low, 2004; Zhangand Clark, 2008; Kruengkrai et al, 2009).
Thesemethods led to accuracy improvements over the tra-ditional, pipelined segmentation and POS-taggingbaseline by avoiding segmentation error propagationand making use of part-of-speech information to im-prove segmentation.The single-model approach to joint segmentationand POS-tagging offers consistent training of all in-formation, concerning words, characters and parts-of-speech.
However, exact inference with dynamicprogramming can be infeasible if features are de-fined over a large enough range of the output, suchas over a two-word history.
In our previous work(Zhang and Clark, 2008), which we refer to asZ&C08 from now on, we used an approximate de-coding algorithm that keeps track of a set of partiallybuilt structures for each character, which can be seenas a dynamic programming chart which is greatly re-duced by pruning.In this paper we follow the line of single-modelresearch, in particular the global linear model ofZ&C08.
We show that effective decoding can beachieved with standard beam-search, which givessignificant speed improvements compared to the de-coding algorithm of Z&C08, and achieves accura-cies that are competitive with the state-of-the-art.Our research is also in line with recent research onimproving the speed of NLP systems with little orno accuracy loss (Charniak et al, 2006; Roark andHollingshead, 2008).Our speed improvement is achieved by the useof a single-beam decoder.
Given an input sentence,candidate outputs are built incrementally, one char-acter at a time.
When each character is processed,it is combined with existing candidates in all possi-ble ways to generate new candidates, and an agendais used to keep the N -best candidate outputs from843the begining of the sentence to the current character.Compared to the multiple-beam search algorithm ofZ&C08, the use of a single beam can lead to an orderof magnitude faster decoding speed.1.1 The processing of partial wordsAn important problem that we solve in this paperis the handling of partial words with a single beamdecoder for the global model.
As we pointed outin Z&C08, it is very difficult to score partial wordsproperly when they are compared with full words,although such comparison is necessary for incre-mental decoding with a single-beam.
To allow com-parisons with full words, partial words can either betreated as full words, or handled differently.We showed in Z&C08 that a naive single-beamdecoder which treats partial words in the same wayas full words failed to give a competitive accu-racy.
An important reason for the low accuracy isover-segmentation during beam-search.
Considerthe three characters ????
(tap water)?.
The firsttwo characters do not make sense when put togetheras a single word.
Rather, when treated as two single-character words, they can make sense in a sentencesuch as ??
(please)?
(self)?
(come)?
(take)?.Therefore, when using single-beam search to pro-cess ????
(tap water)?, the two-character wordcandidate ????
is likely to have been thrown offthe agenda before the third character ???
is con-sidered, leading to an unrecoverable segmentationerror.This problem is even more severe for a joint seg-mentor and POS-tagger than for a pure word seg-mentor, since the POS-tags and POS-tag bigram of???
and ???
further supports them being separatedwhen ???
is considered.
The multiple-beam searchdecoder we proposed in Z&C08 can be seen as ameans to ensure that the three characters ????
?always have a chance to be considered as a singleword.
It explores candidate segmentations from thebeginning of the sentence until each character, andavoids the problem of processing partial words byconsidering only full words.
However, since it ex-plores a larger part of the search space than a single-beam decoder, its time complexity is correspond-ingly higher.In this paper, we treat partial words differentlyfrom full words, so that in the previous example,the decoder can take the first two characters in ????
(tap water)?
as a partial word, and keep itin the beam before the third character is processed.One challenge is the representation of POS-tags forpartial words.
The POS of a partial word is unde-fined without the corresponding full word informa-tion.
Though a partial word can make sense witha particular POS-tag when it is treated as a com-plete word, this POS-tag is not necessarily the POS ofthe full word which contains the partial word.
Takethe three-character sequence ?????
as an exam-ple.
The first character ???
represents a single-character word ?below?, for which the POS can beLC or VV.
The first two characters ????
repre-sent a two-character word ?rain?, for which the POScan be VV.
Moreover, all three characters when puttogether make the word ?rainy day?, for which thePOS is NN.
As discussed above, assigning POS tagsto partial words as if they were full words leads tolow accuracy.An obvious solution to the above problem is not toassign a POS to a partial word until it becomes a fullword.
However, lack of POS information for partialwords makes them less competitive compared to fullwords in the beam, since the scores of full words arefuther supported by POS and POS ngram informa-tion.
Therefore, not assigning POS to partial wordspotentially leads to over segmentation.
In our exper-iments, this method did not give comparable accura-cies to our Z&C08 system.In this paper, we take a different approach, andassign a POS-tag to a partial word when its first char-acter is separated from the final character of the pre-vious word.
When more characters are appended toa partial word, the POS is not changed.
The idea isto use the POS of a partial word as the predicted POSof the full word it will become.
Possible predictionsare made with the first character of the word, and thelikely ones will be kept in the beam for the next pro-cessing steps.
For example, with the three characters????
?, we try to keep two partial words (besidesfull words) in the beam when the first word ???
isprocessed, with the POS being VV and NN, respec-tively.
The first POS predicts the two-character word????
?and the second the three-character word?????.
Now when the second character is pro-cessed, we still need to maintain the possible POSNN in the agenda, which predicts the three-character844word ????
?.As a main contribution of this paper, we show thatthe mechanism of predicting the POS at the first char-acter gives competitive accuracy.
This mechanismcan be justified theoretically.
Unlike alphabeticallanguages, each Chinese character represents somespecific meanings.
Given a character, it is natural fora human speaker to know immediately what typesof words it can start.
The allows the knowledge ofpossible POS-tags of words that a character can start,using information about the character from the train-ing data.
Moreover, the POS of the previous words tothe current word are also useful in deciding possiblePOS for the word.1The mechanism of first-character decision of POSalso boosts the efficiency, since the enumeration ofPOS is unecessary when a character is appended tothe end of an existing word.
As a result, the com-plexity of each processing step is reduce by halfcompared to a method without POS prediction.Finally, an intuitive way to represent the status ofa partial word is using a flag explicitly, which meansan early decision of the segmentation of the next in-coming character.
We take a simpler alternative ap-proach, and treat every word as a partial word un-til the next incoming character is separated from thelast character of this word.
Before a word is con-firmed as a full word, we only apply to it featuresthat represent its current partial status, such as char-acter bigrams, its starting character and its part-of-speech, etc.
Full word features, including the firstand last characters of a word, are applied immedi-ately after a word is confirmed as complete.An important component for our proposed systemis the training process, which needs to ensure thatthe model scores a partial word with predicted POSproperly.
We use the averaged perceptron (Collins,2002) for training, together with the ?early update?mechanism of Collins and Roark (2004).
Ratherthan updating the parameters after decoding is com-plete, the modified algorithm updates parameters atany processing step if the correct partial candidatefalls out of the beam.In our experiments using the Chinese Treebank1The next incoming characters are also a useful sourceof information for predicting the POS.
However, our systemachieved competitive accuracy with Z&C08 without such char-acter lookahead features.data, our system ran an order of magnitude fasterthan our Z&C08 system with little loss of accuracy.The accuracy of our system was competitive withother recent models.2 Model and Feature TemplatesWe use a linear model to score both partial and fullcandidate outputs.
Given an input x, the score of acandidate output y is computed as:Score(y) = ?
(y) ?
~w,where ?
(y) is the global feature vector extractedfrom y, and ~w is the parameter vector of the model.Figure 1 shows the feature templates for themodel, where templates 1 ?
14 contain only seg-mentation information and templates 15 ?
29 containboth segmentation and POS information.
Each tem-plate is instantiated according to the current charac-ter in the decoding process.
Row ?For?
shows theconditions for template instantiation, where ?s?
in-dicates that the corresponding template is instanti-ated when the current character starts a new word,and ?a?
indicates that the corresponding template isinstantiated when the current character does not starta new word.
In the row for feature templates, w, tand c are used to represent a word, a POS-tag anda character, respectively.
The subscripts are basedon the current character, where w?1 represents thefirst word to the left of the current character, andp?2 represents the POS-tag on the second word tothe left of the current character, and so on.
As anexample, feature template 1 is instantiated when thecurrent character starts a new word, and the resultingfeature value is the word to the left of this charac-ter.
start(w), end(w) and len(w) represent the firstcharacter, the last character and the length of wordw, respectively.
The length of a word is normalizedto 16 if it is larger than 16. cat(c) represents the POScategory of character c, which is the set of POS-tagsseen on character c, as we used in Z&C08.Given a partial or complete candidate y, its globalfeature vector ?
(y) is computed by instantiating allapplicable feature templates from Table 1 for eachcharacter in y, according to whether or not the char-acter is separated from the previous character.The feature templates are mostly taken from, orinspired by, the feature templates of Z&C08.
Tem-plates 1, 2, 3, 4, 5, 8, 10, 12, 13, 14, 15, 19, 20,845Feature template For1 w?1 s2 w?1w?2 s3 w?1, where len(w?1) = 1 s4 start(w?1)len(w?1) s5 end(w?1)len(w?1) s6 end(w?1)c0 s7 c?1c0 a8 begin(w?1)end(w?1) s9 w?1c0 s10 end(w?2)w?1 s11 start(w?1)c0 s12 end(w?2)end(w?1) s13 w?2len(w?1) s14 len(w?2)w?1 s15 w?1t?1 s16 t?1t0 s17 t?2t?1t0 s18 w?1t0 s19 t?2w?1 s20 w?1t?1end(w?2) s21 w?1t?1c0 s22 c?2c?1c0t?1, swhere len(w?1) = 123 start(w0)t0 s24 t?1start(w?1) s25 t0c0 s, a26 c0t0start(w0) a27 ct?1end(w?1), swhere c ?
w?1 and c 6= end(w?1)28 c0t0cat(start(w0)) s29 ct?1cat(end(w?1)), swhere c ?
w?1 and c 6= end(w?1)30 c0t0c?1t?1 s31 c0t0c?1 aTable 1: Feature templates.24, 27 and 29 concern complete word information,and they are used in the model to differentiate cor-rect and incorrect output structures in the same wayas our Z&C08 model.
Templates 6, 7, 9, 16, 17,18, 21, 22, 23, 25, 26 and 28 concern partial wordinformation, whose role in the model is to indicatethe likelihood that the partial word including the cur-rent character will become a correct full word.
Theyact as guidance for the action to take for the cur-function DECODE(sent, agenda):CLEAR(agenda)ADDITEM(agenda, ??
)for index in [0..LEN(sent)]:for cand in agenda:new?
APPEND(cand, sent[index])ADDITEM(agenda, new)for pos in TAGSET():new?
SEP(cand, sent[index], pos)ADDITEM(agenda, new)agenda?
N-BEST(agenda)return BEST(agenda)Figure 1: The incremental beam-search decoder.rent character according to the context, and are thecrucial reason for the effectiveness of the algorithmwith a small beam-size.2.1 DecodingThe decoding algorithm builds an output candidateincrementally, one character at a time.
Each char-acter can either be attached to the current word orseparated as the start a new word.
When the currentcharacter starts a new word, a POS-tag is assigned tothe new word.
An agenda is used by the decoder tokeep the N -best candidates during the incrementalprocess.
Before decoding starts, the agenda is ini-tialized with an empty sentence.
When a character isprocessed, existing candidates are removed from theagenda and extended with the current character in allpossible ways, and the N -best newly generated can-didates are put back onto the agenda.
After all inputcharacters have been processed, the highest-scoredcandidate from the agenda is taken as the output.Pseudo code for the decoder is shown in Figure1.
CLEAR removes all items from the agenda, AD-DITEM adds a new item onto the agenda, N-BESTreturns the N highest-scored items from the agenda,and BEST returns the highest-scored item from theagenda.
LEN returns the number of characters in asentence, and sent[i] returns the ith character fromthe sentence.
APPEND appends a character to thelast word in a candidate, and SEP joins a characteras the start of a new word in a candidate, assigninga POS-tag to the new word.846Both our decoding algorithm and the decoding al-gorithm of Z&C08 run in linear time.
However, inorder to generate possible candidates for each char-acter, Z&C08 uses an extra loop to search for pos-sible words that end with the current character.
Arestriction to the maximum word length is appliedto limit the number of iterations in this loop, with-out which the algorithm would have quadratic timecomplexity.
In contrast, our decoder does not searchbackword for the possible starting character of anyword.
Segmentation ambiguities are resolved by bi-nary choices between the actions append or sepa-rate for each character, and no POS enumeration isrequired when the character is appended.
This im-proves the speed by a significant factor.2.2 TrainingThe learning algorithm is based on the generalizedperceptron (Collins, 2002), but parameter adjust-ments can be performed at any character during thedecoding process, using the ?early update?
mecha-nism of Collins and Roark (2004).The parameter vector of the model is initialized asall zeros before training, and used to decode trainingexamples.
Each training example is turned into theraw input format, and processed in the same way asdecoding.
After each character is processed, partialcandidates in the agenda are compared to the cor-responding gold-standard output for the same char-acters.
If none of the candidates in the agenda arecorrect, the decoding is stopped and the parametervector is updated by adding the global feature vectorof the gold-standard partial output and subtractingthe global feature vector of the highest-scored par-tial candidate in the agenda.
The training processthen moves on to the next example.
However, if anyitem in the agenda is the same as the correspond-ing gold-standard, the decoding process moves tothe next character, without any change to the pa-rameter values.
After all characters are processed,the decoder prediction is compared with the trainingexample.
If the prediction is correct, the parame-ter vector is not changed; otherwise it is updated byadding the global feature vector of the training ex-ample and subtracting the global feature vector ofthe decoder prediction, just as the perceptron algo-rithm does.
The same training examples can be usedto train the model for multiple iterations.
We usethe averaged parameter vector (Collins, 2002) as thefinal model.Pseudocode for the training algorithm is shown inFigure 2.
It is based on the decoding algorithm inFigure 1, and the main differences are: (1) the train-ing algorithm takes the gold-standard output and theparameter vector as two additional arguments; (2)the training algorithm does not return a prediction,but modifies the parameter vector when necessary;(3) lines 11 to 20 are additional lines of code for pa-rameter updates.Without lines 11 to 16, the training algorithm isexactly the same as the generalized perceptron al-gorithm.
These lines are added to ensure that theagenda contains highly probable candidates duringthe whole beam-search process, and they are crucialto the high accuracy of the system.
As stated earlier,the decoder relies on proper scoring of partial wordsto maintain a set of high quality candidates in theagenda.
Updating the value of the parameter vectorfor partial outputs can be seen as a means to ensurecorrect scoring of partial candidates at any character.2.3 PruningWe follow Z&C08 and use several pruning methods,most of which serve to to improve the accuracy byremoving irrelevant candidates from the beam.
First,the system records the maximum number of charac-ters that a word with a particular POS-tag can have.For example, from the Chinese Treebank that weused for our experiments, most POS are associatedwith only with one- or two-character words.
Theonly POS-tags that are seen with words over ten char-acters long are NN (noun), NR (proper noun) andCD (numbers).
The maximum word length informa-tion is initialized as all ones, and updated accordingto each training example before it is processed.Second, a tag dictionary is used to record POS-tags associated with each word.
During decoding,frequent words and words with ?closed set?
tags2are only allowed POS-tags according to the tag dic-tionary, while other words are allowed every POS-tagto make candidate outputs.
Whether a word is a fre-quent word is decided by the number of times it hasbeen seen in the training process.
Denoting the num-2?Closed set?
tags are the set of POS-tags which are onlyassociated with a fixed set of words, according to the Penn Chi-nese Treebank specifications (Xia, 2000).847function TRAIN(sent, agenda, gold-standard, ~w):01: CLEAR(agenda)02: ADDITEM(agenda, ??
)03: for index in [0..LEN(sent)]:04: for cand in agenda:05: new?
APPEND(cand, sent[index])06: ADDITEM(agenda, new)07: for pos in TAGSET():08: new?
SEP(cand, sent[index], pos)09: ADDITEM(agenda, new)10: agenda?
N-BEST(agenda)11: for cand in agenda:12: if cand = gold-standard[0:index]:13: CONTINUE14: ~w?
~w + ?
(gold-standard[0:index])15: ~w?
~w - ?
(BEST(agenda))16: return17: if BEST(agenda) 6= gold-standard:18: ~w?
~w + ?
(gold-standard)19: ~w?
~w - ?
(BEST(agenda))20: return21: returnFigure 2: The incremental learning function.ber of times the most frequent word has been seenwith M , a word is a frequent word if it has beenseen more than M/5000 + 5 times.
The thresholdvalue is taken from Z&C08, and we did not adjustit during development.
Word frequencies are initial-ized as zeros and updated according to each trainingexample before it is processed; the tag dictionary isinitialized as empty and updated according to eachtraining example before it is processed.Third, we make an additional record of the initialcharacters for words with ?closed set?
tags.
Duringdecoding, when the current character is added as thestart of a new word, ?closed set?
tags are only as-signed to the word if it is consistent with the record.This type of pruning is used in addition to the tagdictionary to prune invalid partial words, while thetag dictionary is used to prune complete words.
Therecord for initial character and POS is initially empty,and udpated according to each training example be-fore it is processed.Finally, at any decoding step, we group partialcandidates that are generated by separating the cur-rent character as the start of a new word by the sig-nature p0p?1w?1, and keep only the best amongthose having the same p0p?1w?1.
The signaturep0p?1w?1 is decided by the feature templates weuse: it can be shown that if two candidates cand1and cand2 generated at the same step have the samesignature, and the score of cand1 is higher than thescore of cand2, then at any future step, the highestscored candidate generated from cand1 will alwayshave a higher score than the highest scored candidategenerated from cand2.From the above pruning methods, only the thirdwas not used by Z&C08.
It can be seen as an extramechanism to help keep likely partial words in theagenda and improve the accuracy, but which doesnot give our system a speed advantage over Z&C08.3 ExperimentsWe used the Chinese Treebank (CTB) data to per-form one set of development tests and two sets of fi-8480.40.50.60.70.80.95  10  15  20  25  30F-measureTraining iterationbeam=1beam=2beam=4beam=8beam=16beam=32Figure 3: The influence of beam-sizes, and the conver-gence of the perceptron.nal tests.
The CTB 4 was split into two parts, with theCTB 3 being used for a 10-fold cross validation testto compare speed and accuracies with Z&C08, andthe rest being used for development.
The CTB 5 wasused to perform the additional set of experiments tocompare accuracies with other recent work.We use the standard F-measure to evaluate outputaccuracies.
For word segmentation, precision is de-fined as the number of correctly segmented wordsdivided by the total number of words in the output,and recall is defined as the number of correctly seg-mented words divided by the total number of wordsin the gold-standard output.
For joint segmentationand POS-tagging, precision is defined as the num-ber of correctly segmented and POS-tagged wordsdivided by the total number of words from the out-put, and recall is defined as the correctly segmentedand POS-tagged words divided by the total numberof words in the gold-standard output.All our experiments were performed on a Linuxplatform, and a single 2.66GHz Intel Core 2 CPU.3.1 Development testsOur development data consists of 150K words in4798 sentences.
80% of the data were randomlychosen as the development training data, while therest were used as the development test data.
Our de-velopment tests were mainly used to decide the sizeof the beam, the number of training iterations, the ef-fect of partial features in beam-search decoding, andthe effect of incremental learning (i.e.
early update).Figure 3 shows the accuracy curves for joint seg-mentation and POS-tagging by the number of train-ing iterations, using different beam sizes.
With thesize of the beam increasing from 1 to 32, the accura-cies generally increase, while the amount of increasebecomes small when the size of the beam becomes16.
After the 10th iteration, a beam size of 32 doesnot always give better accuracies than a beam sizeof 16.
We therefore chose 16 as the size of the beamfor our system.The testing times for each beam size between 1and 32 are 7.16s, 11.90s, 18.42s, 27.82s, 46.77sand 89.21s, respectively.
The corresponding speedsin the number of sentences per second are 111.45,67.06, 43.32, 28.68, 17.06 and 8.95, respectively.Figure 3 also shows that the accuracy increaseswith an increased number of training iterations, butthe amount of increase becomes small after the 25thiteration.
We chose 29 as the number of iterations totrain our system.The effect of incremental training: We comparethe accuracies by incremental training using earlyupdate and normal perceptron training.
In the nor-mal perceptron training case, lines 11 to 16 are takenout of the training algorithm in Figure 2.
The algo-rithm reached the best performance at the 22nd iter-ation, with the segmentation F-score being 90.58%and joint F-score being 83.38%.
In the incrementaltraining case, the algorithm reached the best accu-racy at the 30th training iteration, obtaining a seg-mentation F-score of 91.14% and a joint F-score of84.06%.3.2 Final tests using CTB 3CTB 3 consists of 150K words in 10364 sentences.We follow Z&C08 and split it into 10 equal-sizedparts.
In each test, one part is taken as the testdata and the other nine are combined together asthe training data.
We compare the speed and accu-racy with the joint segmentor and tagger of Z&C08,which is publicly available as the ZPar system, ver-sion 0.23.The results are shown in Table 2, where each rowshows one cross validation test.
The column head-ings ?sf?, ?jf?, ?time?
and ?speed?
refer to segmen-tation F-measure, joint F-measure, testing time (in3http://www.sourceforge.net/projects/zpar849Z&C08 this paper# sf jf time speed sf jf time speed1 97.18 93.27 557.97 1.86 97.25 93.51 44.20 23.442 97.65 93.81 521.63 1.99 97.66 93.97 42.07 24.263 96.08 91.04 444.69 2.33 95.55 90.65 39.23 26.414 96.31 91.93 431.04 2.40 96.37 92.15 39.54 26.205 96.35 91.94 508.39 2.04 95.84 91.51 43.30 23.936 94.48 88.63 482.78 2.15 94.25 88.53 43.77 23.677 95.27 90.52 361.95 2.86 95.10 90.42 41.76 24.818 94.98 90.01 418.54 2.47 94.87 90.30 39.81 26.029 95.23 90.84 471.3 2.20 95.21 90.55 42.03 26.6510 96.49 92.11 500.72 2.08 96.33 92.12 43.12 24.03average 96.00 91.41 469.90 2.24 95.84 91.37 41.88 24.94Table 2: Speed and acccuracy comparisons with Z&C08 by 10-fold cross validation.seconds) and testing speed (in the number of sen-tences per second), respectively.Our system gave a joint segmentation and POS-tagging F-score of 91.37%, which is only 0.04%lower than that of ZPar 0.2.
The speed of our systemwas over 10 times as fast as ZPar 0.2.3.3 Final tests using CTB 5We follow Kruengkrai et al (2009) and split the CTB5 into training, development testing and testing sets,as shown in Table 3.
We ignored the developmenttest data since our system had been developed in pre-vious experiments.Kruengkrai et al (2009) made use of charactertype knowledge for spaces, numerals, symbols, al-phabets, Chinese and other characters.
In the previ-ous experiments, our system did not use any knowl-edge beyond the training data.
To make the compar-ison fairer, we included knowledge of English let-ters and Arabic numbers in this experiment.
Duringboth training and decoding, English letters and Ara-bic numbers are segmented using simple rules, treat-ing consecutive English letters or Arabic numbers asa single word.The results are shown in Table 4, where row?N07?
refers to the model of Nakagawa and Uchi-moto (2007), rows ?J08a?
and ?b?
refer to the mod-els of Jiang et al (2008a) and Jiang et al (2008b),and row ?K09?
refers to the models of Kruengkrai etal.
(2009).
Columns ?sf?
and ?jf?
refer to segmen-tation and joint accuracies, respectively.
Our systemSections Sentences WordsTraining 1?270 18,085 493,892400?9311001?1151Dev 301?325 350 6,821Test 271?300 348 8,008Table 3: Training, development and test data on CTB 5.sf jfK09 (error-driven) 97.87 93.67our system 97.78 93.67K09 (baseline) 97.79 93.60J08a 97.85 93.41J08b 97.74 93.37N07 97.83 93.32Table 4: Accuracy comparisons with recent studies onCTB 5.gave comparable accuracies to these recent works,obtaining the best (same as the error-driven versionof K09) joint F-score.4 Related WorkThe effectiveness of our beam-search decodershowed that the joint segmentation and taggingproblem may be less complex than previously per-ceived (Zhang and Clark, 2008; Jiang et al, 2008a).At the very least, the single model approach with asimple decoder achieved competitive accuracies towhat has been achieved so far by the reranking (Shi850and Wang, 2007; Jiang et al, 2008b) models andan ensemble model using machine-translation tech-niques (Jiang et al, 2008a).
This may shed new lighton joint segmentation and POS-tagging methods.Kruengkrai et al (2009) and Zhang and Clark(2008) are the most similar to our system amongrelated work.
Both systems use a discriminativelytrained linear model to score candidate outputs.
Thework of Kruengkrai et al (2009) is based on Nak-agawa and Uchimoto (2007), which separates theprocessing of known words and unknown words,and uses a set of segmentation tags to represent thesegmentation of characters.
In contrast, our modelis conceptually simpler, and does not differentiateknown words and unknown words.
Moreover, ourmodel is based on our previous work, in line withZhang and Clark (2007), which does not treat wordsegmentation as character sequence labeling.Our learning and decoding algorithms are alsodifferent from Kruengkrai et al (2009).
While Kru-engkrai et al (2009) perform dynamic programmingand MIRA learning, we use beam-search to performincremental decoding, and the early-update versionof the perceptron algorithm to train the model.
Dy-namic programming is exact inference, for whichthe time complexity is decided by the locality offeature templates.
In contrast, beam-search is ap-proximate and can run in linear time.
The param-eter updating for our algorithm is conceptually andcomputationally simpler than MIRA, though its per-formance can be slightly lower.
However, the early-update mechanism we use is consistent with our in-cremental approach, and improves the learning ofthe beam-search process.5 ConclusionWe showed that a simple beam-search decoding al-gorithm can be effectively applied to the decodingproblem for a global linear model for joint wordsegmentation and POS-tagging.
By guiding searchwith partial word information and performing learn-ing for partial candidates, our system achieved sig-nificantly faster speed with little accuracy loss com-pared to the system of Z&C08.The source code of our joint segmentor and POS-tagger can be found at:www.sourceforge.net/projects/zpar, version 0.4.AcknowledgementsWe thank Canasai Kruengkrai for discussion on effi-ciency issues, and the anonymous reviewers for theirsuggestions.
Yue Zhang and Stephen Clark are sup-ported by the European Union Seventh FrameworkProgramme (FP7-ICT-2009-4) under grant agree-ment no.
247762.ReferencesEugene Charniak, Mark Johnson, Micha Elsner, JosephAusterweil, David Ellis, Isaac Haxton, Catherine Hill,R.
Shrivaths, Jeremy Moore, Michael Pozar, andTheresa Vu.
2006.
Multilevel coarse-to-fine PCFGparsing.
In Proceedings of HLT/NAACL, pages 168?175, New York City, USA, June.
Association for Com-putational Linguistics.Michael Collins and Brian Roark.
2004.
Incrementalparsing with the perceptron algorithm.
In Proceedingsof ACL, pages 111?118, Barcelona, Spain, July.Michael Collins.
2002.
Discriminative training meth-ods for hidden Markov models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofEMNLP, pages 1?8, Philadelphia, USA, July.Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan Lu?.2008a.
A cascaded linear model for joint Chineseword segmentation and part-of-speech tagging.
InProceedings of ACL/HLT, pages 897?904, Columbus,Ohio, June.Wenbin Jiang, Haitao Mi, and Qun Liu.
2008b.
Wordlattice reranking for Chinese word segmentation andpart-of-speech tagging.
In Proceedings of COLING,pages 385?392, Manchester, UK, August.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichiKazama, Yiou Wang, Kentaro Torisawa, and HitoshiIsahara.
2009.
An error-driven word-character hybridmodel for joint Chinese word segmentation and POStagging.
In Proceedings of ACL/AFNLP, pages 513?521, Suntec, Singapore, August.Tetsuji Nakagawa and Kiyotaka Uchimoto.
2007.
Ahybrid approach to word segmentation and POS tag-ging.
In Proceedings of ACL Demo and Poster Ses-sion, Prague, Czech Republic, June.Hwee Tou Ng and Jin Kiat Low.
2004.
Chinese part-of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based?
In Proceedings of EMNLP,Barcelona, Spain.Brian Roark and Kristy Hollingshead.
2008.
Classify-ing chart cells for quadratic complexity context-freeinference.
In Proceedings of COLING, pages 745?752, Manchester, UK, August.
Coling 2008 Organiz-ing Committee.851Yanxin Shi and Mengqiu Wang.
2007.
A dual-layer CRFbased joint decoding method for cascade segmentationand labelling tasks.
In Proceedings of IJCAI, Hyder-abad, India.Fei Xia, 2000.
The part-of-speech tagging guidelines forthe Chinese Treebank (3.0).Yue Zhang and Stephen Clark.
2007.
Chinese segmenta-tion with a word-based perceptron algorithm.
In Pro-ceedings of ACL, pages 840?847, Prague, Czech Re-public, June.Yue Zhang and Stephen Clark.
2008.
Joint word segmen-tation and POS tagging using a single perceptron.
InProceedings of ACL/HLT, pages 888?896, Columbus,Ohio, June.852
