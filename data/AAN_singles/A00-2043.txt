An Empirical Assessment of Semantic InterpretationMart in  Romacker  &: Udo  HahnText Understanding Lab, \ [ -~ Group,Freiburg University, Freiburg, D-79085, Germany{mr, hahn}~coling, uni-freiburg, deAbst rac tWe introduce a framework for semantic interpreta-tion in which dependency structures are mapped toconceptual representations based on a parsimoniousset of interpretation schemata.
Our focus is on theempirical evaluation of this approach to semantic in-terpretation, i.e., its quality in terms of recall andprecision.
Measurements are taken with respect otwo real-world omains, viz.
information technologytest reports and medical finding reports.1 IntroductionSemantic interpretation has been an actively investi-gated issue on the research agenda of the logic-basedparadigm of NLP in the late eighties (e.g., Charniakand Goldman (1988), Moore (1989), Pereira andPollack (1991)).
With the emergence of empiricalmethodologies in the early nineties, attention has al-most completely shifted away from this topic.
Sincethen, semantic issues have mainly been dealt withunder a lexical perspective, viz.
in terms of the res-olution of lexico-semantie ambiguities (e.g., Schfitze(1998), Pedersen and Bruce (1998)) and the gener-ation of lexical hierarchies from large text corpora(e.g., Li and Abe (1996), Hirakawa et al (1996))massively using statistical techniques.The research on semantic interpretation that wasconducted in the pre-empiricist age of NLP wasmainly driven by an interest in logical formalismsas carriers for appropriate semantic representationsof NL utterances.
With this representational bias,computational matters - -  how can semantic repre-sentation structures be properly derived from parsetrees for a large variety of linguistic phenomena?
- -became a secondary issue.
In particular, this re-search lacked entirely quantitative data reflectingthe accuracy of the proposed semantic interpreta-tion mechanisms on real-world language data.One might be tempted to argue that recent eval-uation efforts within the field of information extrac-tion (IE) systems (Chinchor et al, 1993) are going toremedy this shortcoming.
Given, however, the fixednumber of knowledge templates and the restrictedtypes of entities, locations, and events they encodeas target information to be extracted, one readily re-alizes that such an evaluation framework provides,at best, a considerably biased, overly selective testenvironment for judging the understanding potentialof text analysis ystems which are not tuned for thisspecial application.On the other hand, the IE experiments clearly in-dicate the need for a quantitative assessment of theinterpretative p rformance of natural anguage un-derstanding systems.
We will focus on this challengeand propose such a general evaluation framework.We first outline the model of semantic interpretationunderlying our approach and then focus on 'its em-pirical assessment for two basic syntactic structuresof the German language, viz.
genitives and auxiliaryconstructions, in two domains.2 The  Bas ic  Mode l  for  Semant icInterpretationThe problem of semantic interpretation can be de-scribed as the mapping from syntactic to semantic(or conceptual) representation structures.
In our ap-proach, the syntactic representation structures aregiven as dependency graphs (Hahn et al, 1994).
Un-like constituency-based syntactic descriptions, de-pendency graphs consist of lexical nodes only, andthese nodes are connected by vertices, each one ofwhich is labeled by a particular dependency relation(cf.
Figure 1).For the purpose of semantic interpretation, de-pendency graphs can be decomposed into semanti-cally interpretable subgraphs3 Basically, two typesof semantically interpretable subgraphs can be dis-tinguished.
The first one consists of lexical nodeswhich are labeled by content words only (lexical in-stances of verbs, nouns, adjectives or adverbs) andwhich are directly linked by a single dependency re-lation of any type whatsoever.
Such a subgraph isillustrated in Figure 1 by 8peicher- genatt - Com-puters.
The second type of subgraph is also delim-ited by labels of content words but, in addition, aseries of n -- 1... 4 intermediary lexical nodes may1This notion and all subsequent criteria for interpretationare  formally described in Romacker et al (1999).327pro  :kann subject: L _/ Der  Computers  .
e rwe i te r tI spec i f ie r /~  II des * m~ject :SDRAM-Modu len/The  memory, o f  the computer  -- can  -- with SDRAM-modu les  -- ex tended -- be\]The memory of the computer can be extended with SDRAM-modulesFigure 1: Dependency Graph for a Sample Sentenceappear between these content words, all of which arelabeled by non-content words (such as auxiliary ormodal verbs, prepositions).
Hence, in contrast odirect linkage we speak here of indirect linkage be-tween content words.
Such a subgraph, with twointervening non-content words - the modal "kann"and the auxiliary "werden" -, is given in Figure 1 bySpe ieher -  subject - kann-  verbpart - werden-verbpart - erweitert .
Another subgraph with justone intervening non-content word - the preposition"mit" - is illustrated by erwe i te r t -  ppadjunct - mit- pobject - SDRAM-Modu len .
From these consid-erations follows that, e.g., the subgraph spanned bySpe ieher  and SDRAM-Modu len  does not form asemantically interpretable subgraph, since the con-tent word erwe i te r t  intervenes on the linking path.Our approach to semantic interpretation sub-scribes to the principles of locality and composition-ality.
It operates on discrete and well-defined units(subgraphs) of the parse tree, and the results of se-mantic interpretation are incrementally combined byfusing semantically interpretable subgraphs.As semantic target language we have chosen theframework of KL-ONE-type description logics (DL)(Woods and Schmohe, 1992).
Since these logics arecharacterized by a settheoretical semantics we stayon solid formal ground.
Fhrthermore, we take ad-vantage of the powerful inference ngine of DL sys-tems, the description classifier, which turns out to beessential for embedded reasoning during the seman-tic interpretation process.
By equating the semanticrepresentation language with the conceptual one, wefollow arguments discussed by Allen (1993).The basic idea for semantic interpretation is asfollows: Each lexical surface form of a content wordis associated with a set of concept identifiers repre-senting its (different) lexical meanings.
This way,lexical ambiguity is accounted for.
These concep-tual correlates are internal to the domain knowledgebase, where they are described by a list of attributesor conceptual roles, and corresponding restrictionson permitted attribute values or role fillers are asso-ciated with them., , ~s -~0~iN0-~0~Y f .  '
- l@ /!XTENS I 0N-PATIENTEXTENSION.
04 ~ r ,k~ MODALITY L ....... ,Figure 2: Concept Graph for a Sample SentenceAs an example, consider the description for theconcept COMPUTER-SYSTEM.
It may be character-ized by a set of roles, such as HAS-HARD-DISK Or HAS-WORKING-MEMORY, with corresponding restrictionson the concept ypes of potential role fillers.
HAS-WORKING-MEMORY, e.g., sanctions only fillers ofthe concept ype MEMORY.
These conceptual con-straints are used for semantic filtering, i.e., for theelimination of syntactically admissible dependencygraphs which, nevertheless, do not have a valid se-mantic interpretation.Semantic interpretation, in effect, boils down tofinding appropriate conceptual relations in the do-main knowledge that link the conceptual correlatesof the two content words spanning the semanti-cally interpretable subgraph, irrespective of whethera direct or an indirect linkage holds at the syn-tactic level.
Accordingly, Figure 2 depicts the se-mantic/conceptual interpretation of the dependencystructure given in Figure 1.
Instances represent-ing the concrete discourse entities and events inthe sample sentence are visualized as solid rectan-gles containing a unique identifier (e.g., COMPUTER-SYSTEM.02).
Labeled and directed edges indicateinstance roles.
Dashed rectangles characterize sym-bols used as makers for tense and modality.
2Note that in Figure 2 each tuple of content wordswhich configures a minimal subgraph in Figure 1has already received an interpretation i terms of arelation linking the conceptual correlates.
For exam-ple, Spe icher -  genatt - Computers  (cf.
Figure 1,box 1) is mapped to COMPUTER-SYSTEM.02 HAS-WORKING-MEMORY MEMORY.01 (cf.
Figure 2, box1).
However, the search for a valid conceptual rela-tion is not only limited to a simple one-link slot-fillerstructure.
We rather may determine conceptual re-lation paths between conceptual correlates of lexicalitems, the length of which may be greater than 1.2We current ly do not further interpret the information con-tained in tense or modal i ty  markers.328VerbTrans iliary<subject: {agent patient}><dirobject: {patient co-patient}>ierweitern (extend) werden_.passive<{patient co-patient}>LexemeNominal Pre ~ositionNoun _ Pronoun: <genitive attribute:~ > ::Speicher (memory) mlt (with)<{has-part instrument ...}>Figure 3: Fragment of the Lexeme Class Hierarchy(Thus, the need for role composition in the DL lan-guage becomes evident.)
The directed search in theconcept graph of the domain knowledge requires o-phisticated structural and topological constraints tobe manageable at all.
These constraints are encap-sulated in a special path finding and path evaluationalgorithm specified in Markert and Hahn (1997).Besides these conceptual constraints holding inthe domain knowledge, we further attempt to reducethe search space for finding relation paths by twokinds of syntactic riteria.
First, the search may beconstrained by the type of dependency relation hold-ing between the content words of the currently con-sidered semantically interpretable subgraph (directlinkage), or it may be constrained by the interveninglexical material, viz.
the non-content words (indirectlinkage).
Each of these syntactic onstraints has animmediate mapping to conceptual ones.For some dependency configurations, however, nosyntactic onstraints may apply.
Such a case of un-constrained semantic interpretation (e.g., for geni-tive attributes directly linked by the genatt relation)leads to an exhaustive directed search in the knowl-edge base in order to find all conceptually compati-ble role fillings among the two concepts involved.Syntactic restrictions on semantic interpretationeither come from lexeme classes or concrete lexemes.They are organized in terms of the lexeme class hi-erarchy superimposed on the fully lexicalized epen-dency grammar we use (Hahn et al, 1994).
In thefragment depicted in Figure 3, the lexeme class oftransitive verbs, VERBTRANS, requires that when-ever a subject dependency relation is encountered,semantic interpretation is constrained to the con-ceptual roles AGENT or PATIENT and all their sub-relations (such as EXTENSION-PATIENT).
All otherconceptual roles are excluded from the subsequentsemantic interpretation.
Exploiting the property in-heritance mechanisms provided by the hierarchic or-ganization of the lexicalized ependency grammar,all concrete lexemes ubsumed by the lexeme classVERBTRANS, like "erweitern" (extend), inherit thecorresponding constraint.
However, there are lexemeclasses uch as NOUN which do not render any con-straints for dependency relations uch as evidencedby gen\[itive\] att\[ribute\] (cf.
Fig.
3).It may even happen that such restrictions can onlybe attached to concrete lexemes in order to avoidovergeneralization.
Fortunately, we observed thatthis only happened to be the case for closed-class,i.e., non-content words.
Accordingly, in Figure 3the preposition "with" is characterized by the con-straint hat only the conceptual roles HAS-PART, IN-STRUMENT, etc.
must be taken into consideration forsemantic interpretation.Since the constraints at the lexeme class or the lex-eme level are hard-wired in the class hierarchy, werefer to the mapping of dependency relations (or id-iosyncratic lexemes) to a set of conceptual relations(expanded to their transitive closure) as static inter-pretation.
In contradistinction, the computation ofrelation paths for tuples of concepts during the sen-tence analysis process is called dynamic interpreta-tion, since the latter process incorporates additionalconceptual constraints on the fly.The above-mentioned conventions allow thespecification of high-level semantic interpretationschemata covering a large variety of different syntac-tic constructions by a single schema.
For instance,each syntactic onstruction for which no conceptualconstraints apply (e.g., the interpretation of geni-tives, most adjectives, etc.)
receives its semanticinterpretation by instantiating the same interpreta-tion schema (Romacker et al, 1999).
The power ofthis approach comes from the fact that these high-level schemata re instantiated in the course of theparsing process by exploiting the dense specificationsof the inheritance hierarchies both at the grammarlevel (the lexeme class hierarchy), as well as the con-ceptual evel (the concept and role hierarchies).We currently supply up to ten semantic interpre-tation schemata for declaratives, relatives, and pas-329sives at the clause level, complement subcategoriza-tion via PPs, auxiliaries, all tenses at the VP level,pre- and and postnominal modifiers at the NP level,and anaphoric expressions.
We currently do not ac-count for control verbs (work in progress), coordina-tion and quantification.3 The  Eva luat ion  o f  Semant icIn terpretat ionIn this section, we want to discuss, for two particulartypes of German language phenomena, the adequacyof our approach in the light of concrete languagedata taken from the two corpora we work with.
Thispart of the enterprise, the empirical assessment ofse-mantic interpretation, is almost entirely neglected inthe literature (for two notable exceptions, cf.
Bon-nema et al (1997) and Bean et al (1998)).Though similarities exist (viz.
dealing with theperformance of NLP systems in terms of their abil-ity to generate semantic/conceptual structures), thesemantic interpretation (SI) task has to be clearlydistinguished from the information extraction (IE)task and its standard evaluation settings (Chinchoret al, 1993).
In the IE task, a small subset of thetemplates from the entire domain is selected intowhich information from the texts are mapped.
Also,the design of these templates focus on particularlyinteresting facets (roles, in our terminology), so thatan IE system does not have to deal with the fullrange of qualifications that might occur - -  even re-lating to relevant, selected concepts.
Note that inany case, a priori relevance decisions limit the rangeof a posteriori fact retrieval.The SI task, however, is far less restricted.
Wehere evaluate the adequacy of the conceptual rep-resentation structures relating, in principle (only re-stricted, of course, by the limits of the knowledge ac-quisition devices), to the entire domain of discourse,with all qualifications mentioned in a text.
Whetherthese are relevant or not for a particular applicationhas to be determined by subsequent data/knowledgecleansing.
In this sense, semantic interpretationmight deliver the raw data for transformation i toappropriate IE target structures.
Only becauseof feasibility reasons, the designers of IE systemsequate IE with SI.
The cross-linking of IE and SItasks, however, bears the risk of having to determine,in advance, what will be relevant or not for later re-trieval processes, assumptions which are likely to beflawed by the dynamics of domains and the unpre-dictability of the full range of interests of prospectiveusers.3.1 Methodo log ica l  IssuesOur methodology to deal with the evaluation of se-mantic interpretation is based on a triple division oftest conditions.
The first category relates to checkswhether so-called static constraints, effected by themapping from a single dependency relation to oneor more conceptual relations, are valid (cf.
Figure 3for restrictions of this type).
Second, one may in-vestigate the appropriateness of the results from thesearch of the domain knowledge base, i.e., whether arelation between two concepts can be determined atall, and, if so, whether that relation (or role chain)is adequate.
The conceptual constraints which comeinto play at this stage of processing are here referredto as dynamic onstraint propagation, since they areto be computed on the fly, while judging the valid-ity of the role chain in question.
3 Third, interactionsbetween the above-mentioned static constraints anddynamic constraint propagation may occur.
Thisis the case for the interpretation of auxiliaries orprepositions, where intervening lexical material andassociated constraints have to be accounted for si-multaneously.In our evaluation study, we investigated the effectsof category II and category III phenomena by consid-ering genitives and modal as well as auxiliary verbs,respectively.
The knowledge background is consti-tuted by a domain ontology that is divided into anupper generic part (containing about 1,500 conceptsand relations) and domain-specific extensions.
Wehere report on the two specialized omains we dealwith - -  a hardware-biased information technology(IT) domain model and an ontology covering partsof anatomical medicine (MED).
Each of these twodomain models adds roughly about 1,400 conceptsand relations to the upper model.
Correspondinglexeme entries in the lexicon provide linkages to theentire ontology.
In order to avoid error chaining, wealways assume a correct parse to be delivered for thesemantic interpretation process.We took a random selection of 54 texts (compris-ing 18,500 words) from the two text corpora, viz.IT test reports and MEDical finding reports.
Forevaluation purposes (cf.
Table 1), we concentratedon the interpretation of genitives (as an instance ofdirect linkage; GEN) and on the interpretation ofperiphrastic verbal complexes, i.e., passive, tempo-ral and modal constructions (as instances of indirectlinkage; MODAUX).The choice of these two grammatical patterns al-lows us to ignore the problems caused by syntac-tic ambiguity, since in our data no structural am-3Note that computations at the domain knowledge levelwhich go beyond mere type checking are usually located out-side the scope the semantic onsiderations.
This is due tothe fact that encyclopedic knowledge and its repercussions onthe understanding process are typically not considered partof the semantic interpretation task proper.
While this maybe true from a strict linguistic point of view, from the com-putational perspective of NLP this position cannot seriouslybe maintained.
Even more so, when semantic and conceptualrepresentations are collapsed.330biguities occurred.
If one were to investigate thecombined effects of syntactic ambiguity and seman-tic interpretation the evaluation scenario had to bechanged.
Methodologically, the first step were to ex-plore the precision of a semantic interpretation taskwithout structural ambiguities (as we do) and then,in the next step, incorporate the treatment of syn-tactic ambiguities (e.g., by semantic filtering devices,cf.
Bonnema et al (1997)).Several guidelines were defined for the evaluationprocedure.
A major issue dealt with the correctnessof a semantic interpretation.
In cases with interpre-tation, we considered a semantic interpretation tobe a correct one, if the conceptual relation betweenthe two concepts involved was considered adequateby introspection (otherwise, incorrect).
This qualifi-cation is not as subjective as it may sound, since weapplied really strict conditions adjusted to the fine-grained domain knowledge.
4 Interpretations wereconsidered to be correct in those cases which con-tained exactly one relation, as well as cases of se-mantical/conceptual ambiguities (up to three read-ings, the most), presumed the relation set containedthe correct one.
5 A special case of incorrectness,called nil, occurred when no relation path could bedetermined though the two concepts under scrutinywere contained in the domain knowledge base andan interpretation should have been computed.We further categorized the cases where the sys-tem failed to produce an interpretation due to atleast one concept specification missing (with respectto the two linked content words in a semanticallyinterpretable subgraph).
In all those cases with-out interpretation, insufficient coverage of the uppermodel was contrasted with that of the two domainmodels in focus, MED and IT, and with cases inwhich concepts referred to other domains, e.g., fash-ion or food.
Ontological subareas that could nei-ther be assigned to the upper model nor to partic-ular domains were denoted by phrases referring totime (e.g., "the beginning of the year"), space (e.g.,4The major i ty  of cases were easy to judge.
For instance,"the infiltration of the stroma" resulted in a correct reading- STROMA being the PATIENT of the INF ILTRAT ION event - ,as well as in an incorrect one - being the AGENT of the IN-FILTRATION.
Among the incorrect semant ic  interpretat ions wealso categorized, e.g., the interpretat ion of the expression "theprices of the manufacturers" as a conceptual inkage fromPRICE via PRICE-OF to PRODUCT via HAS-MANUFACTURER toMANUFACTURER (this type of role chaining can be consideredan intr iguing example of the embedded reasoning performedby the description logic inference ngine), since it did not ac-count for the interpretation that MANUFACTURERS fix PRICESas part of their market ing strategies.
After all, correct inter-pretat ions always boiled down to entirely evident cases, e.g.,HARD-DISK PART-OF COMPUTER.5At the level of semantic interpretation, the notion of se-mant ic  ambiguity relates to the fact that  the search algor i thmfor valid conceptual relation paths retrieves more than a singlerelation (chain).
"the surface of the storage medium"), and abstractnotions (e.g., "the acceptance of IT technology").Finally, we further distinguished evaluative xpres-sions (e.g., "the advantages ofplasma display") fromfigurative language, including idiomatic expressions(e.g., "the heart of the notebook").At first glance, the choice of genitives may appearsomewhat rivial.
From a syntactic point of view,genitives are directly linked and, indeed, constitutean easy case to deal with at the dependency level.From a conceptual perspective, however, they pro-vide a real challenge.
Since no static constraints areinvolved in the interpretation ofgenitives (cf.
Figure3, lexeme class NOUN) and, hence, no prescriptionsof (dis)allowed conceptual relations are made, an un-constrained search (apart from connectivity condi-tions imposed on the emerging role chains) of thedomain knowledge base is started.
Hence, the mainburden rests on the dynamic constraint processingpart of semantic interpretation, i.e., the path find-ing procedure muddling through the complete do-main knowledge base in order to select he adequateconceptual reading(s).
Therefore, genitives make astrong case for test category II mentioned above.Dependency graphs involving modal verbs or aux-iliaries are certainly more complex at the syntac-tic level, since the corresponding semantically in-terpretable subgraphs may be composed of up tosix lexical nodes.
However, all intervening non-content-word nodes accumulate constraints for thesearch of a valid relation for semantic interpretationsand, hence, allows us to test category III phenom-ena.
The search space is usually pruned, since onlythose relations that are sanctioned by the interven-ing nodes have to be taken into consideration.3.2 Eva luat ion  DataWe considered a total of almost 250 genitives in allthese texts, from which about 59%/33% (MED/IT)received an interpretation.
6 Out of the total loss dueto incomplete conceptual coverage, 56%/58% (23 of41 genitives/57 of 98 genitives) can be attributed toinsufficient coverage of the domain models.
Only theremaining 44%/42% are due to the residual factorslisted in Table 1.In our sample, the number of syntactic onstruc-tions containing modal verbs or auxiliaries amout to292 examples.
Compared to genitives, we obtaineda more favorable recall for both domains: 66% forMED and 40% for IT.
As for genitives, lacking in-terpretations, in the majority of cases, can be at-tributed to insufficient conceptual coverage.
For theIT domain, however, a dramatic increase in the num-ber of missing concepts is due to gaps in the uppermodel (78 or 63%) indicating that a large number of6Confidence intervals at a 95% reliability level are given inbrackets in Table 1.331MED-GEN IT-GEN MED-MODAUX IT-MODAUX# texts 29 25 29 25# words 4,300 14,200 4,300 14,200recall 57% 31% 66% 40%precision 97% 94% 95% 85%100 # occurrences ...?
.
.
w i th  in terpretat ion\[confidence intervals\]correct (single reading)?
correct (multiple readings)incorrectnil?
.
.
w i thout  in terpretat iondomain model (MED/IT)59 (59%)\[48%-67%153 (53%)4 (4%)0241 (41%)23 (23%)14749 (33%)\[24%-41%\]28 (19%)18 (12%)3098 (67%)57 (39%)5840 (69%)\[56%-81%\]38 (66%)0 (0%)0218 (31%)11 (19%)upper modelother domains?
time?.
space?.
abstracta, generics?.
evaluative xpressions.. figurative language.
.
.
.
.
.
.
miscellaneous300711010234158128171234Ill (47%)\[40%-53%\]88 (38%)6 (3%)143123 (53%)42 (34%)780I5163243Table 1: Empirical Results for the Semantic Interpretation of Genitives (GEN) and Modal Verbs and Aux-iliaries (MODAUX) in the IT and MED domainsessential concepts for verbs were not modeled.
Also,figurative speech plays a more important role in ITwith 24 occurrences.
Both observations mirror thefact that IT  reports are linguistically far less con-strained and are rhetorically more advanced thantheir MED counterparts.Another interesting observation which is not madeexplicit in Table 1 concerns the distribution of modalverbs and auxiliaries.
In MED, we encountered 57passives and just one modal verb and no temporalauxiliaries, i.e., our data are in line with prevailingfindings about the basic patterns of medical sublan-guage (Dunham, 1986).
For the IT  domain, cor-responding occurrences were far less biased, viz.
80passives, 131 modal verbs, and 23 temporal auxil-iaries.
Finally, for the two domains 25 samples con-tained both modal verbs and auxiliaries, thus form-ing semantically interpretable subgraphs with fourword nodes.One might be tempted to formulate a null hy-pothesis concerning the detrimental impact of thelength of semantically interpretable subgraphs (i.e.,the number of intervening lexical nodes carryingnon-content words) on the quality of semantic inter-pretation.
In order to assess the role of the lengthof the path in a dependency graph, we separatelyinvestigated the results for these subclasses of com-bined verbal complexes?
From the entire four-nodeset (cf.
Table 2) with 25 occurrences (3 for MED and22 for IT), 16 received an interpretation (3 for MED,13 for IT).
While we neglect the MED data due tothe small absolute numbers, the IT domain revealedMED IT4-nodes 4-nodesrecall - 59%precision - 85%# occurrences ... 3 22?
.. with interpretat ion 3 13. .
.
.
.
.
.
correct 3 11Table 2: Interpretation Results for Semantically In-terpretable Graphs Consisting of Four Nodes59% recall and 85% precision.
If we compare thisto the overall figures for recall (40%) and precision(85%), the data might indicate a gain in recall forlonger subgraphs, while precision keeps stable.The results we have worked out are just a first stepinto a larger series of broader and deeper evaluationefforts.
The concrete values we present, sobering asthey may be for recall (57%/31% for genitives and66%/40% for modal verbs and auxiliaries), encour-aging, however, for precision (97%/94% for genitivesand 95%/85% for modal verbs and auxiliaries), canonly be interpreted relative to other data still lackingon a broader scale.As with any such evaluation, idiosyncrasies of thecoverage of the knowledge bases are inevitably tiedwith the results and, thus, put limits on too far-reaching generalizations.
However, our data reflectthe intention to submit a knowledge-intensive textunderstander to a realistic, i.e., conceptually un-constrained and therefore "unfriendly" test environ-ment.332Judged from the figures of our recall data, thereis no doubt, whatsoever, that conceptual coverageof the domain constitutes the bottleneck for anyknowledge-based approach to NLP.
~ Sublanguagedifferences are also mirrored systematically in thesedata, since medical texts adhere more closely to well-established concept taxonomies and writing stan-dards than magazine articles in the IT domain.4 Re la ted  WorkAfter a period of active research within the logic-based paradigm (e.g., Charniak and Goldman(1988), Moore (1989), Pereira and Pollack (1991)),work on semantic interpretation has almost ceasedwith the emergence of the empiricist movement inNLP (cf.
Bos et al (1996) for one of the more recentstudies dealing with logic-based semantic interpreta-tion in the framework of the VERBMOBIL project).Only few methodological proposals for semanticcomputations were made since then (e.g., higher-order colored unification as a mechanism to avoidover-generation i herent to unconstrained higher-order unification (Gardent and Kohlhase, 1996)).An issue which has lately received more focused at-tention are ways to cope with the tremendous com-plexity of semantic interpretations in the light of anexploding number of (scope) ambiguities.
Withinthe underspecification framework of semantic repre-sentations, e.g., DSrre (1997) proposes a polynomialalgorithm which constructs packed semantic repre-sentations directly from parse forests.All the previously mentioned studies (with the ex-ception of the experimental setup in DSrre (1997)),however, lack an empirical foundation of their var-ious claims.
Though the MUC evaluation rounds(Chinchor et al, 1993) yield the flavor of an empiri-cal assessment of semantic structures, their scope isfar too limited to count as an adequate valuationplatform for semantic interpretation.
Nirenburg etal.
(1996) already criticize the 'black-box' architec-ture underlying MUC-style evaluations, which pre-cludes to draw serious conclusions from the short-comings of MUC-style systems as far as single lin-guistic modules are concerned.
More generally, inthis paper the rationale underlying size (of the lex-icons, knowledge or rule bases) as the major assess-ment category is questioned.
Rather dimensions re-lating to the depth and breadth of the knowledgesources involved in complex system behavior shouldbe taken more seriously into consideration.
This isexactly what we intended to provide in this paper.As far as evaluation studies are concerned ealingwith the assessment of semantic interpretations, few7At least for the medical domain, we are currently activelypursuing research on the semiautomatic creation of large-scaleontologies from weak knowledge sources (medical terminolo-gies); cf.
Schulz and Hahn (2000).have been carried out, some of which under severerestrictions.
For instance, Bean et al (1998) nar-row semantic interpretation down to a very limitedrange of spatial relations in anatomy, while Gomez etal.
(1997) bias the result by preselecting only thosephrases that were already covered by their domainmodels, thus optimizing for precision while shuntingaside recall considerations.A recent study by Bonnema et al (1997) comesclosest o a serious confrontation with a wide rangeof real-world ata (Dutch dialogues on a train traveldomain).
This study proceeds from a corpus ofannotated parse trees to which are assigned type-logical formulae which express the corresponding se-mantic interpretation.
The goal of this work is tocompute the most probable semantic interpretationfor a given parse tree.
Accuracy (i.e., precision) israther high and ranges between 89,2%-92,3% de-pending on the training size and depth of the parsetree.
Our accuracy criterion is weaker (the intendedmeaning must be included in the set of all read-ings), which might explain the slightly higher rateswe achieve for precision.
However, this study doesnot distinguish between different syntactic onstruc-tions that undergo semantic interpretation, or doesit consider the level of conceptual interpretation (wefocus on) as distinguished from the level of semanticinterpretation to which Bonnema et al refer.5 Conc lus ionsThe evaluation of the quality and adequacy of se-mantic interpretation data is still in its infancy.
Ourapproach which confronts semantic interpretationdevices with a random sample of textual real-worlddata, without intentionally constraining the selec-tion of these language data, is a real challenge forthe proposed methodology and it is unique in itsexperimental rigor.However, our work is just a step in the right di-rection rather than giving a complete picture or al-lowing final conclusions.
Two reasons may be givenfor the lack of such experiments.
First, interest inthe deeper conceptual aspects of text interpretationhas ceased in the past years, with almost all effortsdevoted to robust and shallow syntactic processingof large data sets.
This also results in a lack of so-phisticated semantic and conceptual specifications,in particular, for larger text analysis systems.
Sec-ond, providing a gold standard for semantic inter-pretation is, in itself, an incredibly underconstrainedand time-consuming process for which almost no re-sources have been allocated in the NLP communityup to now.Acknowledgements .
We want to thank the mem-bers of the ~-~ group for close cooperation.
Martin Ro-macker is supported by a grant from DFG (Ha 2097/5-1).333ReferencesJames F. Allen.
1993.
Natural language, knowledgerepresentation, and logical form.
In M. Bates andR.
M. Weischedel, editors, Challenges in NaturalLanguage Processing, pages 146-175.
Cambridge:Cambridge University Press.Carol A. Bean, Thomas C. Rindflesch, andCharles A. Sneiderman.
1998.
Automatic seman-tic interpretation ofanatomic spatial relationshipsin clinical text.
In Proceedings of the 1998 AMIAAnnual Fall Symposium., pages 897-901.
Orlando,Florida, November 7-11, 1998.Remko Bonnema, Rens Bod, and Remko Scha.
1997.A DOP model for semantic interpretation.
In Pro-ceedings of the 35th Annual Meeting of the Asso-ciation for Computational Linguistics ~ 8th Con-ference of the European Chapter of the ACL, pages159-167.
Madrid, Spain, July 7-12, 1997.Johan Bos, BjSrn Gamb~ick, Christian Lieske,Yoshiki Mori, Manfred Pinkal, and KarstenWorm.
1996.
Compositional semantics in VERB-MOBIL.
In COLING'96 - Proceedings of the 16thInternational Conference on Computational Lin-guistics, pages 131-136.
Copenhagen, Denmark,August 5-9, 1996.Eugene Charniak and Robert Goldman.
1988.
Alogic for semantic interpretation.
In Proceedingsof the 26th Annual Meeting of the Association forComputational Linguistics, pages 87-94.
Buffalo,New York, U.S.A., 7-10 June 1988.Nancy Chinchor, Lynette Hirschman, and David D.Lewis.
1993.
Evaluating message understandingsystems: an analysis of the third Message Un-derstanding Conference (MUC-3).
ComputationalLinguistics, 19(3):409-447.Jochen DSrre.
1997.
Efficient construction of un-derspecified semantics under massive ambiguity.In Proceedings of the 35th Annual Meeting of theAssociation for Computational Linguistics ~ 8thConference of the European Chapter of the A CL,pages 386-393.
Madrid, Spain, July 7-12, 1997.George Dunham.
1986.
The role of syntax in thesublanguage of medical diagnostic statements.
InR.
Grishman and R. Kittredge, editors, Analyz-ing Language in Restricted Domains: SublanguageDescription and Processing, pages 175-194.
Hills-dale, NJ & London: Lawrence Erlbaum.Claire Gardent and Michael Kohlhase.
1996.Higher-order coloured unification and natural an-guage semantics.
In ACL'96 - Proceedings of the34th Annual Meeting of the Association for Com-putational Linguistics, pages 1-9.
Santa Cruz,California, U.S.A., 24-27 June 1996.Fernando Gomez, Carlos Segami, and RichardHull.
1997.
Determining prepositional attach-ment, prepositional meaning, verb meaning andthematic roles.
Computational Intell., 13(1):1-31.Udo Hahn, Susanne Schacht, and Norbert Br5ker.1994.
Concurrent, object-oriented natural lan-guage parsing: the PARSETALK model.
Inter-national Journal of Human-Computer Studies,41(1/2):179-222.Hideki Hirakawa, Zhonghui Xu, and Kenneth Haase.1996.
Inherited feature-based similarity measurebased on large semantic hierarchy and large textcorpus.
In COLING'96 - Proceedings of the 16thInternational Conference on Computational Lin-guistics, pages 508-513.
Copenhagen, Denmark,August 5-9, 1996.Hang Li and Naoki Abe.
1996.
Clustering wordswith the MDL principle.
In COLING'96 - Pro-ceedings of the 16th International Conference onComputational Linguistics, pages 4-9.
Copen-hagen, Denmark, August 5-9, 1996.Katja Markert and Udo Hahn.
1997.
On the in-teraction of metonymies and anaphora.
In IJ-CA I '97-  Proceedings of the 15th InternationalJoint Conference on Artificial Intelligence, pages1010-1015.
Nagoya, Japan, August 23-29, 1997.Robert C. Moore.
1989.
Unification-based seman-tic interpretation.
In Proceedings of the 27th An-nual Meeting of the Association for Computa-tional Linguistics, pages 33-41.
Vancouver, B.C.,Canada, 26-29 June 1989.Sergei Nirenburg, Kavi Mahesh, and Stephen Beale.1996.
Measuring semantic coverage.
In COL-ING'96 - Proceedings of the 16th InternationalConference on Computational Linguistics, pages83-88.
Copenhagen, Denmark, August 5-9, 1996.Ted Pedersen and Rebecca Bruce.
1998.
Knowledgelean word-sense disambiguation.
In AAAI'98 -Proceedings of the 15th National Conference onArtificial Intelligence, pages 800-805.
Madison,Wisconsin, July 26-30, 1998.Fernando C.N.
Pereira and Martha E. Pollack.
1991.Incremental interpretation.
Artificial Intelligence,50(1):37-82.Martin Romacker, Katja Markert, and Udo Hahn.1999.
Lean semantic interpretation.
In IJCAI'99- Proceedings of the 16th International Joint Con-ference on Artificial Intelligence, pages 868-875.Stockholm, Sweden, July 31 - August 6, 1999.Stefan Schulz and Udo Hahn.
2000.
Knowledge n-gineering by large-scale knowledge reuse: experi-ence from the medical domain.
In Proceedings ofthe 7th International Conference on Principles ofKnowledge Representation and Reasoning.
Breck-enridge, CO, USA, April 12-15, 2000.Hinrich Schiitze.
1998.
Automatic word sensediscrimination.
Computational Linguistics,24(1):97-124.William A.
Woods and James G. Schmolze.
1992.The KL-ONE family.
Computers ~ Mathematicswith Applications, 23(2/5):133-177.334
