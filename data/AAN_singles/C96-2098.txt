Extraction of Lexical Translations from Non-Aligned CorporaKumiko  TANAKAFacul ty  of Engineer ingThe  Univers i ty of Tokyo7-3-1 Hongo, Bunkyo-kuTokyo 113 JAPANkumiko@ip l ,  t .
u - tokyo ,  ac .
jpHideya  IWASAKI*Educat iona l  Computer  CentreThe  Univers i ty of Tokyo2-11-16 Yayoi, Bunkyo-kuTokyo 113 JAPANiwasak i@rds ,  ecc .
u - tokyo ,  ac .
jpAbst ractA method for extracting lexical trans-lations from non-aligned corpora is pro-posed to cope with the unavailability oflarge aligned corpus.
The assumptionthat "translations of two co-occurringwords in a source language also co-occurin the target language" is adopted andrepresented in the stochastic matrix for-mulation.
The translation matrix pro-vides the co-occurring information trans-lated from the source into the target.This translated co-occurring informationshould resemble that of the original inthe target when the ambiguity of thetranslational relation is resolved.
An al-gorithm to obtain the best translationmatrix is introduced.
Some experimentswere performed to evaluate the effective-ness of the ambiguity resolution and therefinement of the dictionary.1 In t roduct ionAlignment of corpora is now being actively stud-ied to support example-based automatic transla-tion and dictionary refinement.
Focusing on thelatter, in order to obtain lexical translations, themaximum likelihood method is applied to roughlyaligned corpus.
One of the problems of thismethod is that it needs a large amount of alignedcorpus for training (Brown, 1993).When it exists, a qualified dictionary is alsolikely to exist, because it should have been createdand used when the corpus in the source languagewas translated by hand to make the aligned cor-pus.
There are few requirements to improve dic-tionaries in such a case.
On the other hand, whena large amount of aligned corpus does not existbut only two independent corpora do, for exam-ple, the corpora between two 'not so international'*Author's current address: Department of Com-puter Science, Tokyo University of Agriculture andTechnology.
2-24-16 Naka-machi, Koganei, Tokyo184 JAPAN.languages or those in a constrained omain, thelow quality dictionaries need to be improved.To make a new dictionary between two uncom-mon languages, it is often necessary to transformpublished ictionaries, one between the source andthe international language, the other between theinternational nd the target language.
The prob-lem in this process is to eliminate the irrelevanttranslations introduced by words with ambiguousmeanings (Tanaka, 1994).This carl be thought of as choosing thetranslations from several candidates with-out aligned corpus.
Note that adopting alignedcorpus of insufficient size cause the same situation.We therefore propose a method to extract lexi-cal translations using two corpora which are notaligned in the source and target language.
Ourmethod is proposed as the extension of the frame-work to solve the problem of choosing the trans-lation according to the context.
Thus, one of tilemerits of our research is that two problems, look-ing for the translation according to the global andlocal context, are handled within the same frame-work.2 Assumpt ion  and  Ambigu i tyReso lu t ionThe source language is denoted as LA and thetarget as LB.
Japanese and English have beenadopted as LA and LB, respectively.
Matrix A isdefined with its (i, j)-th element as the value rep-resenting co-occurrence b tween two words ai andaj in LA, with a similar definition for B.
A andB are symmetric matrices.
The number of wordsin LA and LB are denoted as NA and NB.
The(i,j)-th element of matrix X is denoted as Xij.The cited Japanese xamples are listed in theAppendix with their transliterations and firstmeanings.
The cited English examples are writtenin this font.2.1 FormalizationTranslations of two co-occurring words in asource language also co-occur in the targetlanguage is assumed.
For example, doctor and580Tau ~ bkAS  ~ Tt AT vs. Ba.
~ btTFigure 1: Calculation of TtATnurse co-occur in English and their translations\ [~  and ~ also co-occur in Japanese.Rapp (1995) verified this assumption betweenEnglish and German.
He showed that two matri-ces A and B resemble ach ottmr, when ai cor-respond to bi for all i.
Thus, the resem'ch adthe additional assumption that, English words andGerman words correspond one~to-one.We introdnce the translation matrix T from Ato B because a word corresponds to several wordsrather than one.
The ( i , j ) - th element of T is de-fined a~s the conditional probability p(bj\[ai), thetranslational probability of bj given hi.
T formsa stochastic matrix, such that the sum of all ele-ments in the same row is 1.0.The co-occurrences A~ in LA can be translatedinto LB using both p(bklau) mid p(btlav):~-~p(bkla=)A=~p(btla,) (11Denoting for all Bkl, (1) can be rewritten in asimple matrix formulation as follows:TtAT  (2)Note that tim resulting matrix is also symmetric.Returning to the example of doctor given in thissection, its translation is ~ but not |~:t:, be-cause ~ ,  the translation of the co-occurringword nurse, co-occurs with ~ but not with 15::1:.Thus, our assumption serves to resolve ambiguity.This fact indicates that the translated co~occurring matrix T t AT  should resemble/3 (Figure1).
Defining IX -  Y\] as a certain distance betweenmatrices X and Y, ambiguity resolution is possi~ble by simply obtaining T which minimizes thefollowing formula:F(T)  = IT tAT  - BI (3)when A and B are known.
Note that the aboveformulation assumes that the co-occurrence in LAcan be transformed congruently into L~.
Thus,T gives the pattern matching of two structuresformed by co-occurrence r lations (Section 4.2).2.2 The  Cho ice  o f  Co-occur rence~qeasure  and  Mat r ix  D is tanceThere :~:c many alternatives to measure co-occurrence between two words x and y (Church,1990; Dunning, 1993).
Having fi'eq(x) as the countof x in the entire text, freq(x, y) as the number ofappearances of both x and y within a window ofa fixed number of words, and N as the number ofwords in the text concerned, we adopt the follow-ing mutual information:Nfreq(ai, a j) (4)freq( ai ) fi'eq( aj )Rapp argues that, freq(ai, aj)2/freq(ai)freq(aj) isalthough more sensitive than above.
Formula (4),however, will be adopted due to its statisticalproperty being already studied (Church, 1990).Rapp normalized matrices A and B.
We, how-ever, do not normalize from the reason that thevalue by Formula (4) is already normalized by N 1 .Distance for matrices hould also be considered.Rapp used the sum of absolute distance of the ele-ments.
Since our requirement is that the distanceis easy to handle analytically to obtain T as inSection 4.1, the following definition was ctmsen:I x  - r l  = - (5 )i,j3 Loca l  Ambigu i ty  Reso lu t ionNote that, the elements with value 0.0 in a matrixare denoted by " - "  in the following discussion.3.1 Example  of  doctorSuppose that doctor occurs in the local con-text "The doctor nursed the patient."
We wmltto disambiguate the meaning of doctor as themedical doctor, not Ph.D.  As doctor co-occurswith nurse and patient, nurse with doctor and pa-tient etc., tim matrix A can be defined by Formula(4) as follows2:doctor nurse patientdoctor - 3.0 3.0nurse 3.0 - 3.0patient 3.0 3.0 -For T, only the ambiguity of doctor is concernedhere for simplicity, not that of nurse or patient,giving T as follows:doctor ~I~ 1 - - T41 -nurse  - 1 .0  - -pat ient  - 1.0  --Note that ~ is a co-occurring word with |~t .Here we are interested in whether Tll = 1.0 (doc-to r -  \ [~)  or ~/~1 = 1.0 (doctor-- -  |~d:): thecorrect answer is clearly T11 = 1.0.1When we renormalized A and B and applied theincremental calculation which will be indicated in Sec-tion 4, T empirically oscillated and did not converge,because NA and NB can differ drastically.2The value 3.0 refers to NA, which is calculated as(NA X 1)/(1 x 1) -=  NA.
whereas 1 is the frequencyof each occurrence.
Here NA is 3, the three wordsdoctor, nurse and patient.Tile quality of A is poor from a statistical pointof view (Church, 1990).
What is needed in the lo-cal ambiguity resolution is only the information of co-occurring words, and the co-occurrence values are notthat important when forming A.
Although there areother solutions for forming A, for example, to put allelements concerned simply to 1.0, this definition wasused because the local and global problems can behandled within exactly the same framework.581B is obtained globally from the corpus in LB.Suppose that B for the words in question is givenfor simplicity as follows:N~ - ~0.0 50.0 -~ l -  ~5 10.0 2.0 8.0 -~ 50.0 8.0 .
.
.
.-~t?
- - - 3.0 15.0~ - - - 15 .0  3 .0We experimentally put Tl1 = 1.0, so that doctorcorresponds to I!K~, and calculated TtAT  givingthe following result with F(T) = 5038:N~ ~i~-~ , ~  t$?
?~-N~ -~ 3 .0  3 .0  - -~ 70 3 .0  - 3 .0  - -?
:~  3 .0  3 .0  - -t *?
.
.
.
.
.Next, we put T41 = 1.0, so that doctor corre-sponded to ~$:t:.
TtAT  gave the following resultwith F(T) = 5758:~-?~ - - 3 .O  3 .0  -~ 3.0 - 3.0 -iS?
- 3 .0  3 .0  - -~ .
.
.
.
.These two results indicate that T with ~/\]l = 1.0(doctor -  N~ff) makes TtAT  and B closer thanT with T41 = 1.0 (doctor -  ~i~=t:).
Therefore thetranslation of doctor is determined to be \ [~ .The algorithm to choose the translation fromseveral candidates reflecting the local context issummarized as follows:1.
Create a local A.2.
Make a T that assumes one candidate to bethe translation.
Calculate the distance F(T)for each candidate.3.
Choose the T with the minimum F(T).3.2 Re la ted  WorkDagan (1994) proposed a method to choose atranslation according to the local context.
Thesignificance of this work is that the ambiguity isnot solved within LA, as was trmtitionally stud-led, but was solved in LB, same as our standpoint.Word to be translated (a~) and its relating word(av) concerning phrasal structure (for example ob-jective for verb) were translated into Lu (bi andby, respectively), using an electronic dictionary.The co-occurring frequency within LB was mea-sured and p(bk, bl lau, a.)
was estimated as follows:\]req(bk, bt) (6)Dagan chose bk of the largest p(bk,blla~,,av) astranslation after statistically testing its reliability.The difference with our method is that he esti-mated the translational probability between pairs(the word and its co-occurrence) whereas ourframework reduces the translational probability ofpairs into that of words.
Thus, our method canbe applied to obtain global translations, which willbe explained in the following section.4 G loba l  Ext rac t ion  o fT rans la t ionsThe extraction of global lexical translations i for-mulated using the same framework as ambiguityresolution in the local context.
The difference isthat A is formed globally from the corpus in LA.For local context, the number of possible trans-lations is small enough that each case can hetested one after another to find the best T. Un-fortunately, the same method cannot be appliedto obtain global translations because the numberof combinations of possible translations explodes.Hence, we propose a method to update T incr~mentally.4.1  S teepest  Descent  MethodT is not a square matrix and the number of equa-tions obtained by TtAT  = B is not always equalto that of variables Tij, so the equation may notbe solved directly.
We therefore try to obtain thebest T by the Steepest Descent Method (SDM)to minimize the Formula (3).
T is incrementallyupdated from T~ to T,~+l by:T,~+I = T,~ + dT (7)where dT can be calculated with ds being a certainsmall length as:OFdTij -- OTij ds (8)The result can be represented as follows:dT = -4AT(TtAT  - B)ds (9)The constraint for T that the sum of the samerow must be 1.0 can be reflected on the calcu-lation using Lagrange's method of indeterminatecoefficients.4.2  Character i s t i cs  o f  Our  MethodIf words are regarded as nodes, relations such asco-occurrences and translations as branches, thenmatrices A, B and T represent graphs.Suppose that A and B are exactly the samegraph as in Figure 2.
The representation matricesare also indicated in the figure.The best T is obviously as follows,- - 1 .0  -T= - 1.0 - -1 .0  - - -Th is  means that al, as, a3, a4 correspond to b4,b3, b2, bl respectively.
It also indicates that al582A= p - r s B = r q r s r -- s - q pa l  b4a2 I:~t-~ a 3B ISa4 blFigure 2: Graphs of Matrices A and B-) qpbt b5I( A)B = ~ A A b2 b7b4 bsFigure 3: Another Graph of Matrix Bdoes not eorrest)ond to b3, b2, or b~, whi('h is ex-actly the disambiguation.
In terms of linear al-gel)ra, the calculation TtAT is so-called a "con-gruent transformation."
T provi(tes the l)atternmatching of the two graphs given by A and B.Next, sut)pose that A is defined ,~ al)ove and IIis written in a block matrix as shown in Figure 3,containing the same grat)hs as A.
~/' will clearlybe T = 1/2(E E) with E being a unit matrix ofsize 4.
The I)oint is that our algorithm has a limitfor aunbiguity resolution especially when there areseveral resembling raphs interc(mnected, that is,the ambiguity of aj cannot be resolved between b:land b~.On the other hand, as shown in (Brown, 1993),methods using aligned corlms does not have thislimit.
Starting his nmthod with every Englishword eorrest)onding to all French words, only sev-eral French words remain as translations in theresult.
This difference shows our weak point com-t)ared with Brown's.Our inethod, assunfing that two graphs can belinearly transformed, only tries to make a matchbetween two grat)hs in LA and LB without alignedcorpus, so some hints for obtaining the correct cor-respondences, some compensations for the.
lack ofaligned corpus, are nee(ted.
For example, whenthe wtlue of ( i , j ) - th element is zero in T0, thevalue of the saine element can be ket)t at zero dur-ing the SDM.4.3  Re la ted  WorkSome research using aligne(t corpus point (),itproblems with corpus size and noise, which leadsto insufficient a('curacy in translations.Fling (11995) asserts l;hat translation of wordsor I)hrases might not exist even in the alignedcorpus.
She extracte(l noun translations fromnoisy aligned corpus.
First, a number of obv i -Table 1: Local Ambiguity Resolution Powerverbn?unPOS ~ unresolved276adjective 1 2adverb 4total 49ous translations were statistically extracted, thenthe mlce.rtaill translations were found using theco-occurrence with the obvious ones.Utsuro (1994) claimed that there is a nee(t toextract lexical translations even from an alignedcorpus of a small size an(t proposed to use an (dec-tronic (tictionary as an aid.
First, a certain nlllll-bcr of candidates are found.
If a candidate in LBco-occurs with miother found ill the electronic di('-tionary, its probability of being the translation isadjusted to be higher.The cominon idea in the two approaches, theuse of lexical co-occurrence within Lu, was alsointroduced by Dagan (1994).5 Exper imentsTwo experiments, local and global, were t)er~formed t)y choosing the ,Japanese translations forEnglish words.
The corpora adoptc(t are the 30MWall Street Jom'nal and 33M political and eco-nonfi(" articles of Asahi Newspaper.These were morphologically mlalyzed a to ex-tract; nouns, verbs, adje(:tives and adverbs incanonical forms.
Co-oecurren(:cs were counted us-ing an 11 word window size.
A and B were createdas was depicted in Section 2.1.
Elements underthe certain thresholds were set at 0.0.
The initialbilingual dictionary used was Edict (Breen, 1995),a word-to-word public dictionary.5.1  Loca l  Ambigu i ty  Reso lu t ionWe randoinly extracted 11 successive words fromcort)us.
If the 6th c(mter word was ambiguous at-isfying the following three conditions, the methodexplained in Section 3.1 was applied for (tisam-t)iguation: its translations could t)e subjectivelyjudged according to the context; the translationsexist in Edict; Edict contains candidates otherthan the translation.The calculation choice was selected as the onewhich exhibited the minimum F(T).
If all tit(;scores were the same, it was judged unresolved.When our subjectively ju(lged translations con-tained the calculation choice, it was correct, o her-wise wrong.
The experiinent was performed ,mtilthe amhiguity was resolved for 200 ditferent words.Table 1 shows tile results.
The applicability,the rate of words which were not unT~;solw:d, asapC-KIMMO and JUMAN were used.583research scissors15o.o /1oouniversity -'" professor - ' -  paper~15.0~.
7~;.0 ~175~doctor15 .0 / t  -,='~ "-175,0 / ~  to:unurse - -  hospital - -  patient - -  hurt10.0 15.0 5.0Figure 4: A Graph of doctor3.o~50.o ~:~-5 .0 -~-5 .0 -  -~:~ /10 .0\] 5 .0  ~:~/175.0  i~.~?
(~ z 175.0 j~" 7s.o \10.0 15.0 5.0 10.0Figure 5: A Graph of ~ and 1~?75.5% ((124+27)/200).
The correctness (preci-sion), the rate of the correct candidates among thewords not unresolved, was 82.1% (124/(124+27)).The general trends found are as follows:?
Translations reflect the trends in the corpus.For example, for doctor, I~ilf was calculatedto be the best choice.
Although I~  was alsoa candidate meaning medical doctor, it wasdropped, because \ [~ is a rather uncommonusage in the corpus.?
Most words with two obviously differentmeanings were calculated to obtain the cor-rect result.The applicability depends on the window size,such that the window should be large enough tofocus the meaning of the word in question.
Thesmaller the size is, the lower the rate should be.However, even if the window is made wider, therate should eventually reach a certain limit.5.2 Global Extract ion of TranslationsExample of  doctorFigure 4 shows a small graph concerning doc-tor.
The values attached to branches representco-occurrences.
Figure 5 shows the correspondinggraph in Japanese.
We initially defined A and Bfrom these graphs, and To as each English wordcorresponding one-to-one to the Japanese word(with a value 1.0), except that three ambiguouswords have the following correspondences:doctor -+ ~$(0.333), is?
(0.333),~(0 .334)pa~ent --+ ~?~J-~ (0.5),, ,~(0.5)paper ~ ~(0 .5) ,~(0 .5 )SDM was applied to To and its convergence wasjudged with the first 5 digits of F(T) .
This needed3400 iterations for convergence.
The result T3400is as follows:doctor -~ ~i~ (0.502), iS=i: (0.498),~ (0.0)patient -~ ~?~-4-~5 (0.0), ~ (1.0)paper --+ \]~5~ (0.989), ~ (0.011)doctornurse - -  hospital - -  patient - -  hurt10.0 15.0 5.0Figure 6: A Graph of medical doctorresearch scissors/ .
.
3"~ ' '~  50  0 5 o " 5.0 / lO .Oun versity ~ professor - -  pa~er~"15.0  75.0 ~175.0doctorFigure 7: A Graph of Ph.D.The wrong translation doctor - -~ was dropped.Next, we removed from Figure 4 the portionof the graph which corresponds to the meaningof Ph.D. (Figure 6) so that the context was re-stricted to medical doctor.
This time the resultW~L~:doctor -~ ~?~ (1.0), is=t: (0.0), ~ (0.0) Ipatient --~ ~?J~5 (0.0), ~ (1.0) IThen we removed from Figure 4 the portion ofthe graph which corresponded to the meaning ofmedical doctor (Figure 7) so that the context wasrestricted to Ph.D, giving the result:doctor ---} ~g/li (0.0), i s?
(1.0), ~}~ (0.0) \]paper --+ ~$9: (0.996), ~ (0.004) IThese three small experiments show that thetranslation for doctor reflects the context repre-sented by the source graph in LA.Minor Analys is  of  378 wordsThe best experiment is to calculate T for entiredictionary and measure how much the obtainedtranslations reflect the corpus context, but thisis difficult both from calculation time and judg-ment of context reflection.
Hence we intentionallyadded to Edict the irrelevant translations to see ifthey drop out by our method.The irrelevant translations were chosen ran-domly so that they become the same number asthose which existed originally in Edict.
This wasperformed for entire English words in Edict.
Awas formed so that all the words involved arereachable within 2 co-occurrence branch distancesfrom the test word.
B is created by all translationsof words involved in A.
The test words appliedSDM was selected by the following conditions: atest word has more than one candidate (ambigu-ous words) in Edict; its all co-occurrence valuesare greater than a certain threshold.If the candidates are separated into the follow-ing three categories through calculation: thosewhich gain value, decrease value, and those whosevalues do not change, then we define the word inquestion as applicable.
The following rates werecalculated for CDIW (correctly dropped irrelevantwords, ~he irrelevant words added as a noise anddropped correctly by the method) for each appli-cable test words:584Table 2: Dropped Irrelevant Translationsthreshold \[ applicability correctness coverage50.0 \] 68.3% 84.7% 35.2%30.0 84.7% 84.6% 41.9%?
The fraction between the number of CDIWand dropped words.
(correctness, recall)?
The fraction between the number of CDIWand irrelevant words.
(coverage)The results are listed in Table 2.The applicability and coverage depend on thethreshold: the lower the threshold is, the higherthe two rates increase because  more  co-occurrenceinformation is obtained.
The threshold is a trade-off with calculation time.About 15% (100-84.6) incorrectly droppedones were original translations contained in Edict.These did not match the context, similar to thecase of (doctor - -~)  shown in Section 5.1.6 ConclusionsLexical translations were extracted from non-aligned corpora.
The assumption that "trans-lations of two co-occurring words in a sourcelanguage also co-occur in the target language"was introduced and represented in the stochas-tic matrix formulation.
The translation matrixprovides the co-occurring information translatedfrom the source into the target.
This translatedco-occurring information should resemble that inthe target when the ambiguity of translational re-lation is resolved.
This condition was used to ob-tain the best translation matrix.The proposed framework, aimed at ambiguityresolution, serves to globally obtain lexical trans-lations using non-aligned corpora just as to choosea translation according to the local context.
Thealgorithms for obtaining the best translation ma-trix were shown based on the Steepest DescentMethod, an algorithm well known in the field ofnon-linear programming.Two experiments were t)erformed to exanfinethe power of local ambiguity resolution and dictio-nary refinement.
The former showed a precisionof 82.1% with applicability of 75.5%.
In the latter,irrelevant ranslations were intentionally added tothe dictionary to examine whether the relevantones will be chosen.
It was found that 84.7% ofthe dropped words were indeed irrelevant ones.An important future task is to decrease thecomputational complexity.
The method is appli-cable to matrix calculation with the size of an en-tire dictionary, but this is unrealistic at this stage.We must also increase the rate of ambigqfity reso-lution.
The corpus is regarded as non-structureddata in this paper, the ambiguity might be re-solved more effectively by introducing a phrasalstructure.AcknowledgmentWe thank Dr. Koiti Hasida for useful discus-sion.
Our experiments are supported by Dr. KyojiUmemura's corpus data.
We express our grati-tudes to Mr. Breen for providing his Edict for ourexperiments.ReferencesJames W. Breen, (1995).
Edict, Freeware Japanese /English Dictionary.Peter F. Brown et al (1993).
The Mathematics ofStatistical Machine Translation: Parameter Es-timation.
Computational Linguistics, vol.
19(2),pp.
263-311.Kenneth W. Church and Patrick Hanks (1990).
WordAssociation Norms, Mutual Information, and Lex~icography.
Computational Linguistics, vol.
16(1),pp.
22 29.Ido Dagan and Alon Itai (1994).
Word Sense Dis-ambiguation Using a Second Language Monolin-gual Corpus, Computational Linguistics, vol.
20 (4.),pp.
563-596.Ted Dunning (1993).
Accurate Methods for the Statis-tics of Surprise and Coincidence.
ComputationalLinguistics, vol.
19 (1), pp.
61-74.Paseale Fung (1995).
A Pattern Matching Method forFinding Noun and Proper Noun Translations fromNoisy Parallel Corpora.
Proceedings of ACL '95~pp.
236-243.Reinhard Rapp (1995).
Identifying Word Translationsin Non-Parallel Texts.
Proceedings of ACL '95,pp.
321-322.Kumiko Tanaka and Violaine Prince (t995).
Amelio-ration Automatique Incr(~mentale d DictionnairesBilingues Utilisant un Corpus Monolingue.
Confer-ence Internationale d'A UPELF '95.Kumiko Tanaka and Kyoji Umenmra (1994).
Con-struction of a Bilingual Dictionary Intermediatedby A Third Language.
Proceedings of the Inter-national Conference for Computational Linguistics'9~, pp.
293-393.Takehito Utsuro et al (1994).
Bilingual Text Match-ing using Bilingual Dictionary and Statistics.
Pro-ceedings of the International Conference for Com-putational Linguistics '9~, pp.
1076-1082.AppendixJapanese Transliteration First meaningi?kgishaishihakasekangohukangosurukanjaitaidaigakuronbunkyoujugamansurukamih,~amimedical doctormedical doctorPh.D.nurseto nursepatienthurtuniversitypaper as articlesprofessorbe patientpaper to write onscissors585
