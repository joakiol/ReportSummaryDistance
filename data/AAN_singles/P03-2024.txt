A Limited-Domain English to Japanese Medical Speech TranslatorBuilt Using REGULUS 2Manny RaynerResearch Institute for AdvancedComputer Science (RIACS),NASA Ames Research Center,Moffet Field, CA 94035mrayner@riacs.eduPierrette BouillonUniversity of GenevaTIM/ISSCO,40, bvd du Pont-d?Arve,CH-1211 Geneva 4,Switzerlandpierrette.bouillon@issco.unige.chVol Van Dalsem IIIEl Camino Hospital2500 Grant RoadMountain View, CA 94040vvandal3@aol.comHitoshi Isahara, Kyoko KanzakiCommunications Research Laboratory3-5 HikaridaiSeika-cho, Soraku-gunKyoto, Japan 619-0289{isahara,kanzaki}@crl.go.jpBeth Ann HockeyResearch Institute for AdvancedComputer Science (RIACS),NASA Ames Research Center,Moffet Field, CA 94035bahockey@riacs.eduAbstractWe argue that verbal patient diagnosis is apromising application for limited-domainspeech translation, and describe an ar-chitecture designed for this type of taskwhich represents a compromise betweenprincipled linguistics-based processing onthe one hand and efficient phrasal transla-tion on the other.
We propose to demon-strate a prototype system instantiating thisarchitecture, which has been built on topof the Open Source REGULUS 2 platform.The prototype translates spoken yes-noquestions about headache symptoms fromEnglish to Japanese, using a vocabulary ofabout 200 words.1 Introduction and motivationLanguage is crucial to medical diagnosis.
Dur-ing the initial evaluation of a patient in an emer-gency department, obtaining an accurate history ofthe chief complaint is of equal importance to thephysical examination.
In many parts of the worldthere are large recent immigrant populations that re-quire medical care but are unable to communicatefluently in the local language.
In the US these im-migrants are especially likely to use emergency fa-cilities because of insurance issues.
In an emer-gency setting there is acute need for quick accuratephysician-patient communication but this communi-cation is made substantially more difficult in caseswhere there is a language barrier.
Our system isdesigned to address this problem using spoken ma-chine translation.Designing a spoken translation system to obtaina detailed medical history would be difficult if notimpossible using the current state of the art.
Thereason that the use of spoken translation technol-ogy is feasible is because what is actually needed inthe emergency setting is more limited.
Since medi-cal histories traditionally are obtained through two-way physician-patient conversations that are mostlyphysician initiative, there is a preestablished limitingstructure that we can follow in designing the trans-lation system.
This structure allows a physician tosucessfully use one way translation to elicit and re-strict the range of patient responses while still ob-taining the necessary information.Another helpful constraint on the conversationalrequirements is that the majority of medical condi-tions can be initiatlly characterized by a relativelysmall number of key questions about quality, quan-tity and duration of symptoms.
For example, keyquestions about chest pain include intensity, loca-tion, duration, quality of pain, and factors that in-crease or decrease the pain.
These answers to thesequestions can be sucessfully communicated by alimited number of one or two word responses (e.g.yes/no, left/right, numbers) or even gestures (e.g.pointing to an area of the body).
This is clearly adomain in which the constraints of the task are suf-ficient for a limited domain, one way spoken trans-lation system to be a useful tool.2 An architecture for limited-domainspeech translationThe basic philosophy behind the architecture of thesystem is to attempt an intelligent compromise be-tween fixed-phrase translation on one hand (e.g.
(IntegratedWaveTechnologies, 2002)) and linguisti-cally motivated grammar-based processing on theother (e.g.
VERBMOBIL (Wahlster, 2000) and Spo-ken Language Translator (Rayner et al, 2000a)).At run-time, the system behaves essentially like aphrasal translator which allows some variation in theinput language.
This is close in spirit to the approachused in most normal phrase-books, which typicallyallow ?slots?
in at least some phrases (?How muchdoes ?
cost??
; ?How do I get to ?
??).
However,in order to minimize the overhead associated withdefining and maintaining large sets of phrasal pat-terns, these patterns are derived from a single largelinguistically motivated unification grammar; thusthe compile-time architecture is that of a linguisti-cally motivated system.
Phrasal translation at run-time gives us speed and reliability; the linguisticallymotivated compile-time architecture makes the sys-tem easy to extend and modify.The runtime system comprises three main mod-ules.
These are respectively responsible for sourcelanguage speech recognition, including parsing andproduction of semantic representation; transfer andgeneration; and synthesis of target language speech.The speech processing modules (recognition andsynthesis) are implemented on top of the standardNuance Toolkit platform (Nuance, 2003).
Recogni-tion is constrained by a CFG language model writtenin Nuance Grammar Specification Language (GSL),which also specifies the semantic representationsproduced.
This language model is compiled froma linguistically motivated unification grammar us-ing the Open Source REGULUS 2 platform (Rayneret al, 2003; Regulus, 2003); the compilation pro-cess is driven by a small corpus of examples.
Thelanguage processing modules (transfer and genera-tion) are a suite of simple routines written in SICStusProlog.
The speech and language processing mod-ules communicate with each other through a mini-mal file-based protocol.The semantic representations on both the sourceand target sides are expressed as attribute-valuestructures.
In accordance with the generally mini-malistic design philosophy of the project, semanticrepresentations have been kept as simple as possi-ble.
The basic principle is that the representation ofa clause is a flat list of attribute-value pairs: thus forexample the representation of ?Did your headachestart suddenly??
is the attribute-value list[[utterance_type,ynq],[tense,past],[symptom,headache],[state,start],[manner,suddenly]]In a broad domain, it is of course trivial to con-struct examples where this kind of representationruns into serious problems.
In the very narrow do-main of a phrasebook translator, it has many desir-able properties.
In particular, operations on semanticrepresentations typically manipulate lists rather thantrees.
In a broad domain, we would pay a heavyprice: the lack of structure in the semantic represen-tations would often make them ambiguous.
The verysimple ontology of the phrasebook domain howevermeans that ambiguity is not a problem; the compo-nents of a flat list representation can never be de-rived from more than one functional structure, sothis structure does not need to be explicitly present.Transfer rules define mappings of sets of attribute-value pairs to sets of attribute-value pairs; the ma-jority of the rules map single attribute-value pairsto single attribute-value pairs.
Generation is han-dled by a small Definite Clause Grammar (DCG),which converts attribute-value structures into sur-face strings; its output is passed through a minimalpost-transfer component, which applies a set of ruleswhich map fixed strings to fixed strings.
Speech syn-thesis is performed either by the Nuance VocalizerTTS engine or by concatenation of recorded wave-files, depending on the output language.One of the most important questions for a med-ical translation system is that of reliability; we ad-dress this issue using the methods of (Rayner andBouillon, 2002).
The GSL form of the recognitiongrammar is run in generation mode using the Nu-ance generate utility to generate large numbersof random utterances, all of which are by construc-tion within system coverage.
These utterances arethen processed through the system in batch mode us-ing all-solutions versions of the relevant processingalgorithms.
The results are checked automaticallyto find examples where rules are either deficient orambiguous.
With domains of the complexity underconsideration here, we have found that it is feasibleto refine the rule-sets in this way so that holes andambiguities are effectively eliminated.3 A medical speech translation systemWe have built a prototype medical speech transla-tion system instantiating the functionality outlinedin Section 1 and the architecture of Section 2.
Thesystem permits spoken English input of constrainedyes/no questions about the symptoms of headaches,using a vocabulary of about 200 words.
This isenough to support most of the standard examina-tion questions for this subdomain.
There are twoversions of the system, producing spoken output inFrench and Japanese respectively.
Since English ?Japanese is distinctly the more interesting and chal-lenging language pair, we will focus on this version.Speech recognition and source language analy-sis are performed using REGULUS 2.
The grammaris specialised from the large domain-independentgrammar using the methods sketched in Section 2.The training corpus has been constructed by handfrom an initial corpus supplied by a medical pro-fessional; the content of the questions was kept un-changed, but where necessary the form was revisedto make it more appropriate to a spoken dialogue.When we felt that it would be difficult to remem-ber what the canonical form of a question wouldbe, we added two or three variant forms.
For exam-ple, we permit ?Does bright light make the headacheworse??
as a variant for ?Is the headache aggra-vated by bright light?
?, and ?Do you usually haveheadaches in the morning??
as a variant for ?Doesthe headache usually occur in the morning??.
Thecurrent training corpus contains about 200 exam-ples.The granularity of the phrasal rules learned bygrammar specialisation has been set so that the con-stituents in the acquired rules are VBARs, post-modifier groups, NPs and lexical items.
VBARsmay include both inverted subject NPs and adverbs1.Thus for example the training example ?Are theheadaches usually caused by emotional upset??
in-duces a top-level rule whose context-free skeleton isUTT --> VBAR, VBAR, POSTMODSFor the training example, the first VBAR in the in-duced rule spans the phrase ?are the headaches usu-ally?, the second VBAR spans the phrase ?caused?,and the POSTMODS span the phrase ?by emotionalupset?.
The same rule could potentially be used tocover utterances like ?Is the pain sometimes pre-ceded by nausea??
and ?Is your headache ever as-sociated with blurred vision??.
The same trainingexample will also induce several lower-level rules,the least trivial of which are rules for VBAR andPOSTMODS with context-free skeletonsVBAR --> are, NP, ADVPOSTMODS --> P, NPThe grammar specialisation method is described infull detail in (Rayner et al, 2000b).With regard to the transfer component, we havehad two main problems to solve.
Firstly, it is well-known that translation from English to Japanese re-quires major reorganisation of the syntactic form.Word-order is nearly always completely different,and category mismatches are very common.
It ismainly for this reason that we chose to use a flatsemantic representation.
As long as the domain issimple enough that the flat representations are un-ambiguous, transfer can be carried out by mappinglists of elements into lists of elements.
For example,we translate ?are your headaches caused by fatigue?as ?tsukare de zutsu ga okorimasu ka?
(lit.
?fatigue-CAUSAL headache-SUBJ occur-PRESENT QUES-TION?).
Here, the source-language representation is[[utterance_type,ynq],[tense,present],[symptom,headache],[event,cause],[cause,fatigue]]and the target-language one is[[utterance_type,sentence],[tense,present],[symptom,zutsu],1This non-standard definition of VBAR has technical advan-tages discussed in (Rayner et al, 2000c)do your headaches often appear at night ?yoku yoru ni zutsu ga arimasu ka(often night-AT headache-SUBJ is-PRES-Q)is the pain in the front of the head ?itami wa atama no mae no hou desu ka(pain-TOPIC head-OF front side is-PRES-Q)did your headache start suddenly ?zutsu wa totsuzen hajimari mashita ka(headache-TOPIC sudden start-PRES-Q)have you had headaches for weeks ?sushukan zutsu ga tsuzuite imasu ka(weeks headache-SUBJ have-CONT-PRES-Q)is the pain usually superficial ?itsumo itami wa hyomenteki desu ka(usually pain-SUBJ superficial is-PRES-Q)is the severity of the headaches increasing ?zutsu wa hidoku natte imasu ka(headache-TOPIC severe becoming is-PRES-Q)Table 1: Examples of utterances covered by the pro-totype[event,okoru],[postpos,causal],[cause,tsukare]]Each line in the source representation maps into thecorresponding one in the target in the obvious way.The target-language grammar is constrained enoughthat there is only one Japanese sentence which canbe generated from the given representation.The second major problem for transfer relates toelliptical utterances.
These are very important dueto the one-way character of the interaction: insteadof being able to ask a WH-question (?What doesthe pain feel like??
), the doctor needs to ask a se-ries of Y-N questions (?Is the pain dull?
?, ?Is thepain burning?
?, ?Is the pain aching?
?, etc).
Werapidly found that it was much more natural forquestions after the first one to be phrased ellipti-cally (?Is the pain dull?
?, ?Burning?
?, ?Aching??
).English and Japanese have however different con-ventions as to what types of phrase can be usedelliptically.
Here, for example, it is only pos-sible to allow some types of Japanese adjectivesto stand alone.
Thus we can grammatically andsemantically say ?hageshii desu ka?
(lit.
?burn-ing is-QUESTION?)
but not ?
*uzukuyona desuka?
(lit.
?
*aching is-QUESTION?).
The prob-lem is that adjectives like ?uzukuyona?
must com-bine adnominally with a noun in this context:thus we in fact have to generate ?uzukuyona itamidesu ka?
(?aching-ADNOMINAL-USAGE pain is-QUESTION?).
Once again, however, the very lim-ited domain makes it practical to solve the problemrobustly.
There are only a handful of transforma-tions to be implemented, and the extra informationthat needs to be added is always clear from the sortaltypes of the semantic elements in the target represen-tation.Table 1 gives examples of utterances covered bythe system, and the translations produced.ReferencesIntegratedWaveTechnologies, 2002. http://www.i-w-t.com/investor.html.
As of 15 Mar 2002.Nuance, 2003. http://www.nuance.com.
As of 25 Febru-ary 2003.M.
Rayner and P. Bouillon.
2002.
A phrasebook stylemedical speech translator.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics (demo track), Philadelphia, PA.M.
Rayner, D. Carter, P. Bouillon, V. Digalakis, andM.
Wire?n, editors.
2000a.
The Spoken LanguageTranslator.
Cambridge University Press.M.
Rayner, D. Carter, and C. Samuelsson.
2000b.
Gram-mar specialisation.
In Rayner et al (Rayner et al,2000a).M.
Rayner, B.A.
Hockey, and F. James.
2000c.
Compil-ing language models from a linguistically motivatedunification grammar.
In Proceedings of the EighteenthInternational Conference on Computational Linguis-tics, Saarbrucken, Germany.M.
Rayner, B.A.
Hockey, and J. Dowding.
2003.
Anopen source environment for compiling typed unifica-tion grammars into speech recognisers.
In Proceed-ings of the 10th EACL (demo track), Budapest, Hun-gary.Regulus, 2003. http://sourceforge.net/projects/regulus/.As of 24 April 2003.W.
Wahlster, editor.
2000.
Verbmobil: Foundations ofSpeech-to-Speech Translation.
Springer.
