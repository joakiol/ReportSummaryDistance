ALGORITHMS FOR GENERATION IN  LAMBEKTHEOREM PROVINGErik-Jan van der Linden *Guido MinnenInstitute for Language Technology and Artificial IntelligenceTilburg UniversityPO Box 90153, 5000 LE Tilburg, The NetherlandsE-maih vdlindenOkub.nlABSTRACTWe discuss algorithms for generation within theLambek Theorem Proving Framework.
Efficientalgorithms for generation i this framework takea semantics-driven strategy.
This strategy canbe modeled by means of rules in the calculus thatare geared to generation, or by means of an al-gorithm for the Theorem Prover.
The latter pos-sibility enables processing of a bidirectional cal-culus.
Therefore Lambek Theorem Proving is anatural candidate for a 'uniform' architecture fornatural anguage parsing and generation.Keywords: generation algorithm; natural lan-guage generation; theorem proving; bidirection-ality; categorial grammar.1 INTRODUCTIONAlgorithms for tactical generation are becomingan increasingly important subject of research incomputational linguistics (Shieber, 1988; Shieberet al, 1989; Calder et al, 1989).
In this pa-per, we will discuss generation algorithms withinthe Lambek Theorem Proving (LTP) framework(Moortgat, 1988; Lambek, 1958; van Benthem,1988).
In section (2) we give an introduction to acategorial calculus that is extended towards bidi-rectionality.
The naive top-down control strategyin this section does not suit the needs of efficientgeneration.
Next, we discuss two ways to imple-ment a semantics-driven strategy.
Firstly, we addinference rules and cut rules geared to generationto the calculus (3).
Secondly, since these changesin the calculus do not support bidirectionality, we*We would llke to thank Gosse Bouma, WietskeSi~tsma and Marianne Sanders for their comments on anearlier draft of the paper.220introduce a second implementation: a bottom-upalgorithm for the theorem prover (4).2 EXTENDING THE CAL-CULUSNatura l  Language Processing as deduct ionThe architectures in this paper resemble the uni-form architecture in Shieber (1988) because lan-guage processing is viewed as logical deduction, inanalysis and generation:"The generation of strings matching some crite-ria can equally well be thought of as a deductiveprocess, namely a process of constructive proof ofthe existence of a string that matches the crite-ria."
(Shieber, 1988, p. 614).In the LTP framework a categorial reduction sys-tem is viewed as a logical calculus where parsinga syntagm is an attempt o show that it followsfrom a set of axioms and inference rules.
Theseinference rules describe what he processor does inassembling a semantic representation (representa-tional non-autonomy: Crain and Steedman, 1982;Ades and Steedman, 1982).
Derivation trees rep-resent a particular parse process (Bouma, 1989).These rules thus seem to be nondeclarative, andthis raises the question whether they can be usedfor generation.
The answer to this question willemerge throughout this paper.Lexical information As in any categorialgrammar, linguistic information i  LTP is for thelarger part represented with the signs in the lex-icon and not with the rules of the calculus (signsare denoted by prosody:syntax:semantlcs).
Agenerator using a categorial grammar needs lex-ical information about the syntactic form of afunctor that is connected to some semantic func-tot in order to syntactically correctly generate thesemantic arguments of this functor.
For a parser,the reverse is true.
In order to fulfil both needs,lexical information is made available to the the-orem prover in the form of in~t6aces of o~ionu.
IAxioms then truely represent what should be ax-iomatic in a lexicalist description of a language:the \]exical items, the connections between formand meaning.
2I* s l i a inat ionru les  */(U,\[Pros_Fu:X/Y:Functor\],\[TIR\],V)=>\[Z\] <-\[Pros_Fu:X/Y:Functor\] =>\[Pros_Fu:X/Y:Functor\] k\[TIR\] => \[Pros Arg:Y:Ar~ k(U,\[(Pros_Fu*l~os_Arg):X:Functor@Arg\],V) =>\[z\].
(U,\[T\[R\],\[Pros_Fu:Y\X:Functor\],V) => \[Z\] <-\[Pros_Fu:Y\X:Functor\] =>\[Pros_Fu:Y\X:Functor\] k\[TIR\] => \[Pros_arg:Y:krg\] k(U,\[(Pros_krg*Pros_Fu):X:FunctorQArg\],V) =>\[z\].Ru les  Whenever inference rules are applied, anattempt is made to axiomatize the functor thatparticipates in the inference by the first subse-quent of the elimination rules.
This way, lexicalinformation is retrieved from the lexicon./* introduction ru lss  */\[T\[R\]=>\[Pros:Y\X:Var_Y'Tsra_X\] <-nogsnvar(Y\X) k(\[id:Y:Var_Y\],\[T\[R\]) =>\[(id*Pros):X:Tarm_X\].A prosodic operator connects prosodic ele-ments.
A prosodic identity element, id, is neces-sary because introduction rules are prosodical\]yvacuous.
In order to avoid unwanted matchingbetween axioms and id-elements, one special ax-iota is added for id-elements.
Meta-logical checksare included in the rules in order to avoid vsri-ables occuring in the final derivation, nogenv,2rreeursively checks whether any part of an expres-sion is a variable.A sequent in the calculus is denoted withP => T, where P, called the antecedent, and T,the succedent, are finite sequences of signs.
Thecalculus is presented in (1) .
In what follows, Xand ?
are categories; T and Z, are signs; R, Uand V are possibly empty sequences of signs; @denotes functional application, a caret denotes ~-abstraction, s(i)/* axioms */\[Pros:X:?\] => \[Pros:X:Y\] <-\[Pros:l:Y\] =i> \[Pros:X:Y\] ktrue.\[Pros:X:Y\] => \[Pros:X:Y\] <-(nossnvar(X), nonvar(Y)) k1;rue.\[TIR\] => \[Pros:X/Y:Var_Y'Tsrm_X\] <-nogsnvar(X/Y) k(\[T\[R\],Cid:Y:Var_Y\]) ->\[(Pros*id):l:Term_X\]./* axiom for prosodic id-element */\[id:X:Y\] =i> \[id:X:Y\] <-isvs.r(Y)./* lexicon, lexioms */\[john:np:john\] =1> \[john:np:john\].\[mary:np:mexy\] =1> \[maxy:np:maxy\].\ [ loves : (np \s ) /np : lovn \ ]  =1>\ [ loves : (np \s ) /np : lows \ ] .In order to initiate analysis, the theorem prover ispresented with sequents like (2).
Inference rulesare applied recursively to the antecedent of thesequent until axioms are found.
This regime canbe called top-down from the point of view ofprob-\]em solving and bottom-up from a "parsing" pointof view.
For generation, a sequent like (3) is pre-sented to the theorem prover.
Both analysis andgeneration result in a derivation like (4).
Notethat generation ot only results in a sequence oflexical signs, but also in a peosodic pl~rasing thatcould be helpful for speech generation.
(2)lVem der Linden and Minnen (submitted) contains amore elaborate comparison ofthe extended cedcu\]tm withthe origins\] calculus as proposed in Moortgat (1988).2A suggestion similar to this proposal was made byK~nig (1989) who stated that lexicsI items are to be seenas axioms, but did not include them as such in her de-scription of the L-calculus.SThroughout this paper we will use a Prolog notationbecause the architectures presented here depend partly onthe Prolog un\[i~cstlon mechanism.221\[john:A:B,lovss:C:D,msxy:E:F\] => \[Pros:s:Ssm\](3)U => \[Pros:s:loves@maryQjohn\]Although both (2) and (3) result (4), in thecase of generation, (4) does not represent he(4)j ohn :np : john  1or*s :  (np \s ) /np : loves  ma~ry:np:mary => john*( loves*mary) : s : lovesQaary@john <-loves :  (np \s ) /np : loves  => loves :  (np \s ) /np :1oves  <-loves :  (np \s ) /np : loves  =I> loves : (np \s ) /np :1oves  <- t rueaary :np :aary  => aary :np :aary  <-ms.ry:np:aa~ry =I> aary :np :aary  <- t ruejohn:  np:  J olm loves*mary  : np \s  : lovea@aary => j ohn* ( loves*mary)  : s : loves@aary@j olm <-loves*aary  :np \s  : loves@mary => loves*aary  :np \s  : loves@mary <- t ruejohn:np : john  => john:np : john  <-john:np : john  -1> john:np : john  <- t ruejohn*  ( loves*aary)  :s  : lovss@aaryQj  ohn => john*  ( loves*mary)  : s : loves@aary@j ohn: <- t rueexact proceedings of the theorem prover.
Itstarts applying rules, matching them with the an-tecedent, without making use of the original se-mantic information, and thus resulting in an in-efficient and nondeterministic generation process:all possible derivations including all hxical itemsare generated until some derivation is found thatresults in the succedent.
4 We conclude that thealgorithm normally used for parsing in LTP is in-efficient with respect o generation.3 CALCUL I  DES IGNEDFOR GENERATIONA solution to the ei~ciency problem raised inthe previous section is to start from the origi-hal semantics.
In this section we discuss calculithat make explicit use of the original semantics.Firstly, we present Lambek-like rules especiallydesigned for generation.
Secondly, we introducea Cut-rule for generation with sets of categorialreduction rules.
Both entail a variant of the cru-cial starting-point ofthe semantic-he~d-driven al-gorithms described in Calder et al (1989) andShieber et al (1989): if the functor of a semanticrepresentation can be identified, and can be re-fated to a lexical representation containing syn-tactic information, it is possible to generate thearguments yntactically.
The efficiency of thisstrategy stems from the fact that it is guided bythe known semantic and syntactic information,and lexical information is retrieved as soon as pos-sible.In contrast o the semantic-head-driven al>-proach, our semantic representations do not al-low for immediate recognition of semantic heads:these can only be identified after all arguments4ef.
Shleber et el.
(1989) on top-down generationalgorithms.
2 2 2have been stripped of the functor recursively(loves@mary@john =:> loves@mary => loves).Calder et al conjecture that their algorithm"(...) extends naturally to the rules of compo-sition, division and permutation of CombinatoryCategorial Grammar (Steedman, 1987) and theLambek Calculus (1958)" (Calder et al, 1989, p.23 ).This conjecture should be handled with care.
Aswe have stated before, inference rules in LTP de-scribe ho~ a processor operates.
An importantdifference with the categorial reduction rules ofCalder et al is that inference.rules in LTP implic-itly initiate the recursion of the parsing and gen-eration process.
Technically speaking, Lambekrules cannot be arguments of the rule-predicateof Calder et al (1989, p. 237).
The gist of ourstrategy is similar to theirs, but the algorithmsdilTer.Lambek-l lke generat ion Rules are presentedin (5) that explicitly start from the known infor-mation during generation: the syntax and seman-tics of the succedent.
Literally, the inference rulestates that a sequent consisting of an antecedentthat unifies with two sequences of signs U andY, and a succedent that unifies with a sign withsemantics Sem_FuQSem_Arg is a theorem ofthe calculus if Y reduces to a syntactic functorlooking for an argument on its left side with thefunctor-meaning of the original semantics, and Ureduces to its argument.
This rule is an equiva-lent of the second elimination rule in (I).
(5)/* e l~ inat ionru le  */~,v \ ]  =>\[(Pros_krg*Pros_Fu):X:Sem_Fu@Sea_krg\] <-V =>\[Pros_Fu:Y\X:Sen_Fu\] tU =>\[Pros_Arg:Y:Sen_krg\]./* introduction-rule */\[T\[R\] => \[Pros:Y\l:Var_Y'Tera_X\] <-nogenvsr(Y\X) k(CCid:Y:Vnur_Y\]\],CTIR\]) =>\[(id*Pros):X:Tora_l\].4 A COMBINED BOT-TOM-UP/TOP-DOWNREGIMEIn this section, we describe an algorithm forthe theorem prover that proceeds in a combinedbottom-up/top-down fashion from the problemsolving point of view.
It maintains the samesemantics-driven strategy, and enables efficientgeneration with the bidirectional calculus in (I).The algorithm results in derivations like (4), inthe same theorem prover architecture, be it alonganother path.A Cut - ru le  for generat ion  A Cut-rule is astructural rule that can be used within the L-calculus to include partial proofs derived withcategorial reduction rules into other proofs.
In(6) a generation Cut-rule is presented togetherwith the AB-system.
(6)/* Cut-rule for generation */\[U.V\] => \[Pros_Z:Z:Su_Z\] <-\[Pros_X:X:Sem_X, Pros_Y:Y:Sem_Y\] =*>\[Pros_g:z:sem_Z\]U => \[Pros_Z:X:Sem_Z\]V ffi> \[Proe_Y:Y:Sem_Y\]./* reduction rules,  system AB */\[Pros_Fu:X/Y:Functor.
lhcos_Arg:Y:lrg\] =*>(Pros_FU*Pros_Arg):X:Functor@Arg\].\[Pros_Arg:Y:Arg, Pros_Fu:Y\l:Functor\] =*>(Pros.Arg*Pros_Fu):X:Functor@ArS\].The generator regimes presented in this sectionare semantics-driven: they start from a seman-tic representation, assume that it is part of theuppermost sequent within a derivation, and worktowards the lexical items, axioms, with the recur-sive application of inference rules.
From the pointof view of theorem proving, this process shouldbe described as a top-down problem solving strat-egy.
The rules in this section are, however, gearedtowards generation.
Use of these rules for pars-ing would result in massive non-determinism.
El-ficient parsing and generation require differentrules: the calculus is not bidirectioaal.
223B id i rect iona l i ty  There are two reasons toavoid duplication of grammars for generation andinterpretation.
Firstly, it is theoretically more el-egant and simple to make use of one grammar.Secondly, for any language processing system, hu-man or machine, it is more economic (Bunt, 1987,p.
333).
Scholars in the area of language gen-eration have therefore pleaded in favour of thebidirectionalit~ of linguistic descriptions (Appelt,1987).Bidirectionality might in the first place be im-plemented by using one grammar and two sepa-rate algorithms for analysis and generation (Ja-cobs, 1985; Calder et el., 1989).
However, apartfrom the desirability to make use of one and thesame grammar for generation and analysis, itwould be attractive to have one and the sameprocessiag architecture for both analysis and gen-eration.
Although attempts to find such architec-tures (Shieber, 1988) have been termed "lookingfor the fountain of youth',  s it is a stimulatingquestion to what extent it is possible to use thesame architecture for both tasks.Example  An example will illustrate how ouralgorithm proceeds.
In order to generate froma sign, the theorem prover assumes that it isthe succedent of one of the subsequeats of oneof the inference rules (7-1/2).
(In case of anintroduction rule the sign is matched with thesuccedent of the headseq~en~; this implies a top-down step.)
If unification with one of these subse-quents can be established, the other subsequentsand the headsequent can be partly instantiated.These sequents can then serve as starting pointsfor further bottom-up processing.
Firstly, theheadsequent is subjected to bottom-up rocess-SRon Kaplan during discussion of the $hieber presen-tation at Coling 1988.Generation of  nounphrase ~he ~abie.
Start with sequentP => \[Pros :np: the@table\]l- Assume suecedent is part of  an axiom:\[Pros : np: the0t able\] => \[Pros :np: the@table\]2- Match axiom with last subsequent of an inference rule:(U, \[Pros_Fu:X/Y:Functor\],  \[T\[I~,V) => \[Z\] <-\[Pros_Fu:X/Y:Functor\] => \[Pros_Fu:X/Y:Functor\] &\[T \[ R\] => \[Pros_krg : Y : Arg\] &(U, \[ (Pros_Fu*Pros_Arg) : X: Functor@~g\],  V) => \[Z\].Z = Pros:np:the@table; Functor : the; Arg = table; X = np; U = \[ \]; V = \[ \].3- Derive instantiated head sequent:\[Pros_Fu: np/Y: the\ ] ,  \[T \[ R\] => \[Pros :rip: the0table\]4- No more applications in head sequent: Prove (bottom-up) first instantiated subsequent:\[Pros_Fu: np/Y: the\] ,,> \[Pros_Fu :np/Y : the\]Unifies with the axiom for "the": Pros_Fu = the; Y = n.5- Prove (bottom-up) second instantiated subsequent:\[T\[ R\] => \[Pros_Arg: n: "~ able\]Unifies with axiom for "table": Pros_Arg = table; T = table:n:table; R = \[ \]6- Prove (bottum-up) last subsequent: is a nonlexical ax/om.\[ ( the*t able) :np : the@table\] => \[ ( the*table)  : np: theQtable\] .7- Final derivation:the :np /n : the  tab le :n : tab le  => the*table:np.the@table <-the :np /n : the  => the :np /n : the  <-the :np /n : the  =1> the :np /n : the  <- t ruetab le :n : tab le  => tab le :n : tab le  <-tab le :n : tab le  =i> tabls:n:table <- t ruethe*table :np:the@table => the*table :np:the@table <- true224ing (7-3), in order to axiomatize the head functoras soon as possible.
Bottom-up rocessing stopswhen no more application operators can be elim-insted from the head sequent (7-4).
Secondly,working top-down, the other subsequents (7-4/5)are made subject o bottom-up rocessing, and atlast the last subsequent (7-6).
(7) presents gen-eration of a nounphrsse, the ~able.Non-determinism A source for non-determin-ism in the semantics-driven strategy is the factthat the theorem prover forms hypotheses aboutthe direction a functor seeks its arguments, andthen checks these against he lexicon.
A possibil-ity here would be to use a calculus where dora-inance and precedence are taken apart.
We willpursue rids suggestion i  future research.5 CONCLUDINGREMARKSImplementat ion The algorithms and calculipresented here have been implemented with theuse of modified versions of the categorial calculiinterpreter described in Moortgat (1988).Conclusion Efl\]cient, bidirectional use of cat-egorial calculi is possible if extensions are madewith respect o the calculus, and if s combinedbottom-up/top-down algorithm is used for gener-ation.
Analysis and generation take place withinthe same processing architecture, with the samelinguistics descriptions, be it with the use of dif-ferent algorithms.
LTP thus serves as a naturalcandidate for a uniform architecture of parsingand generation.Semantic non-monotonie i ty  A constraint ongrammar formalisms that can be dealt with incurrent generation systems is semantic mono-tonicity (Shieber, 1988; but cf.
Shieber et al,1989).
The algorithm in Calder et al (1989) re-quires an even stricter constaint.
Firstly, in vander Linden and Minnen (submitted) we describehow the addition of a unification-based semanticsto the calculus described here enables process-ing of non-monotonic phenomena such as non-compositional verb particles and idioms.
Identitysemantics (cf.
Calder et al p. 235) should beno problem in this respect.
Secondly, unary rulesand type-raising (ibid.)
are part of the L-calculus,and are neither fundamental problems.Inverse E-reduct ion A problem that exists forall generation systems that include some form of~-semantics is that generation ecessitates the in-verse operation of~-reduction.
Although we haveimplemented algorithms for inverse E-reduction,these are not computationally tractable,  A wayout could be the inclusion of a unification basedsemantics.
7SBunt (1987) states that  an expression with n constantsresults in 2 n - 1 possible inverse ~-reduct lons.7As proposed in van der L inden and  Minnen (submit -ted) for the calculus in (2).
2256 REFERENCESAdes, A., and Steedman, M., 1982 On the orderof words.
Linguistics and Pkilosoph~/, 4, pp.
517-558.Appelt, D.E., 1987 Bidirectional Grammars andthe Design of Natural Language Systems.
InWilks, Y.
(Ed.
), Theoretical Issues in NaturalLanguage Processing.
Las Cruces, New Mexico:New Mexico State University, January 7-9, pp.185-191.Van Benthem, J., 1988 Categorial Grammar.Chapter 7 in Van Benthem, J., Essays in Logi-cal Semantics.
Reidel, Dordrecht.Boums, G., 1989 Emcient Processing of Flexi-ble Categorial Grammar.
In Proceedings of theEACL 1989, Manchester.
pp.
19-26.Bunt, H., 1987 Utterance generation from seman-tic representations augmented with pragmatic in-formation.
In Kempen 1987.Calder, J., Reape M., and Zeevat, H., 1989 Analgorithm for generation in Unification Catego-rial Grammar.
In Proceedings of the EACL 1989,Manchester.
pp.
233-240.Crain, S., and Steedman, M., 1982 On not beingled up the garden path.
In Dowry, Karttunen andZwicky (Eds.)
Natu~l language pQrsing.
Cam-bridge: Cambridge University Press.Jacobs, P., 1985 PHRED, A generator for NaturalLanguage Interfaces.
Computational Linguistics11, 4, pp.
219-242.Kempen , G., (Ed.)
1987 Natural language gen-eration: new results in artificial intelligence, pay.cttology and linouiatics.
Dordrecht: Nijhoff.K6nig, E., 1989 Parsing as natured eduction.
InProceedings of the ACL 1989, Vancouver.Lsmbek, J., 1958 The mathematics of sentencestructure.
Am.
Math Monthly, 85, 154-169.Linden, E. van der, and Minnen, G., (submit-ted) An account of Non-monotonous phenomenain bidirectional Lambek Theorem Proving.Moortgat, M., 1988 Categorial Inueatigetions.Logical and Hnguistic ?apects of the Lambek cal-culus.
Disseration, University of Amsterdam.Shieber, S., 1988 A uniform architecture for Pars-ing and Generation.
In Proceedings of Coling1988, Budapest, pp.
614-619.Shieber, S., van Noord, G., Moore, R., andPereira, P., 1989 A semantic-Head-Driven Gen-eration Algorithm for Unification-Based For-mallsms.
In Proceedings of ACL 1989 Vancouver.Steedman, M., 1987 Combinatory Grammars andParasitic Gaps Natural Language and LinguisticTheory, 5, pp.
403-439.226
