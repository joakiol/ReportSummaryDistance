Proceedings of the ACL 2007 Demo and Poster Sessions, pages 81?84,Prague, June 2007. c?2007 Association for Computational LinguisticsUsing Error-Correcting Output Codes with Model-Refinement toBoost Centroid Text ClassifierSongbo TanInformation Security Center, ICT, P.O.
Box 2704, Beijing, 100080, Chinatansongbo@software.ict.ac.cn, tansongbo@gmail.comAbstractIn this work, we investigate the use oferror-correcting output codes (ECOC) forboosting centroid text classifier.
Theimplementation framework is to decomposeone multi-class problem into multiplebinary problems and then learn theindividual binary classification problemsby centroid classifier.
However, this kindof decomposition incurs considerable biasfor centroid classifier, which results innoticeable degradation of performance forcentroid classifier.
In order to address thisissue, we use Model-Refinement to adjustthis so-called bias.
The basic idea is to takeadvantage of misclassified examples in thetraining data to iteratively refine and adjustthe centroids of text data.
The experimentalresults reveal that Model-Refinement candramatically decrease the bias introducedby ECOC, and the combined classifier iscomparable to or even better than SVMclassifier in performance.1.
IntroductionIn recent years, ECOC has been applied toboost the na?ve bayes, decision tree and SVMclassifier for text data (Berger 1999, Ghani 2000,Ghani 2002, Rennie et al 2001).
Following thisresearch direction, in this work, we explore theuse of ECOC to enhance the performance ofcentroid classifier (Han et al 2000).
To the best ofour knowledge, no previous work has beenconducted on exactly this problem.
Theframework we adopted is to decompose onemulti-class problem into multiple binary problemsand then use centroid classifier to learn theindividual binary classification problems.However, this kind of decomposition incursconsiderable bias (Liu et al 2002) for centroidclassifier.
In substance, centroid classifier (Han etal.
2000) relies on a simple decision rule that agiven document should be assigned a particularclass if the similarity (or distance) of thisdocument to the centroid of the class is the largest(or smallest).
This decision rule is based on astraightforward assumption that the documents inone category should share some similarities witheach other.
However, this hypothesis is oftenviolated by ECOC on the grounds that it ignoresthe similarities of original classes whendisassembling one multi-class problem intomultiple binary problems.In order to attack this problem, we use Model-Refinement (Tan et al 2005) to reduce this so-called bias.
The basic idea is to take advantage ofmisclassified examples in the training data toiteratively refine and adjust the centroids.
Thistechnique is very flexible, which only needs oneclassification method and there is no change tothe method in any way.To examine the performance of proposedmethod, we conduct an extensive experiment ontwo commonly used datasets, i.e., Newsgroup andIndustry Sector.
The results indicate that Model-Refinement can dramatically decrease the biasintroduce by ECOC, and the resulted classifier iscomparable to or even better than SVM classifierin performance.2.
Error-Correcting Output CodingError-Correcting Output Coding (ECOC) is aform of combination of multiple classifiers(Ghani 2000).
It works by converting a multi-class supervised learning problem into a largenumber (L) of two-class supervised learningproblems (Ghani 2000).
Any learning algorithmthat can handle two-class learning problems, suchas Na?ve Bayes (Sebastiani 2002), can then beapplied to learn each of these L problems.
L canthen be thought of as the length of the codewords811 Load training data and parameters;2 Calculate centroid for each class;3 For iter=1 to MaxIteration Do3.1 For each document d in training set Do3.1.1 Classify d labeled ?A1?
into class ?A2?
;3.1.2 If (A1!=A2) DoDrag centroid of class A1 to d using formula (3);Push centroid of class A2 against d usingformula (4);TRAINING1 Load training data and parameters, i.e., the length of codeL and training class K.2 Create a L-bit code for the K classes using a kind ofcoding algorithm.3 For each bit, train the base classifier using the binaryclass (0 and 1) over the total training data.TESTING1 Apply each of the L classifiers to the test example.2 Assign the test example the class with the largest votes.with one bit in each codeword for each classifier.The ECOC algorithm is outlined in Figure 1.Figure 1: Outline of ECOC3.
Methodology3.1 The bias incurred by ECOC forcentroid classifierCentroid classifier is a linear, simple and yetefficient method for text categorization.
The basicidea of centroid classifier is to construct acentroid Ci for each class ci using formula (1)where d denotes one document vector and |z|indicates the cardinality of set z.
In substance,centroid classifier makes a simple decision rule(formula (2)) that a given document should beassigned a particular class if the similarity (ordistance) of this document to the centroid of theclass is the largest (or smallest).
This rule is basedon a straightforward assumption: the documentsin one category should share some similaritieswith each other.?=?
icdii dcC 1(1)????????
?=22maxargiii CdCdc c(2)For example, the single-topic documentsinvolved with ?sport?
or ?education?
can meetwith the presumption; while the hybrid documentsinvolved with ?sport?
as well as ?education?break this supposition.As such, ECOC based centroid classifier alsobreaks this hypothesis.
This is because ECOCignores the similarities of original classes whenproducing binary problems.
In this scenario, manydifferent classes are often merged into onecategory.
For example, the class ?sport?
and?education?
may be assembled into one class.
Asa result, the assumption will inevitably be broken.Let?s take a simple multi-class classificationtask with 12 classes.
After coding the originalclasses, we obtain the dataset as Figure 2.
Class 0consists of 6 original categories, and class 1contains another 6 categories.
Then we calculatethe centroids of merged class 0 and merged class1 using formula (1), and draw a Middle Line thatis the perpendicular bisector of the line betweenthe two centroids.Figure 2: Original Centroids of Merged Class 0 andClass 1According to the decision rule (formula (2)) ofcentroid classifier, the examples of class 0 on theright of the Middle Line will be misclassified intoclass 1.
This is the mechanism why ECOC canbring bias for centroid classifier.
In other words,the ECOC method conflicts with the assumptionof centroid classifier to some degree.3.2 Why Model-Refinement can reducethis bias?In order to decrease this kind of bias, weemploy the Model-Refinement to adjust the classrepresentative, i.e., the centroids.
The basic ideaof Model-Refinement is to make use of trainingerrors to adjust class centroids so that the biasescan be reduced gradually, and then the training-set error rate can also be reduced gradually.Figure 3: Outline of Model-Refinement StrategyFor example, if document d of class 1 ismisclassified into class 2, both centroids C1 andC2 should be moved right by the followingformulas (3-4) respectively,dCC ?+= ?1*1                             (3)dCC ?
?= ?2*2                            (4)Middle Line Class 0 Class 1C1C0d82where ?
(0<?<1) is the Learning Rate whichcontrols the step-size of updating operation.The Model-Refinement for centroid classifier isoutlined in Figure 3 where MaxIteration denotesthe pre-defined steps for iteration.
More detailscan be found in (Tan et al 2005).
The timerequirement of Model-Refinement is O(MTKW)where M denotes the iteration steps.With this so-called move operation, C0 and C1are both moving right gradually.
At the end of thiskind of move operation (see Figure 4), noexample of class 0 locates at the right of MiddleLine so no example will be misclassified.Figure 4: Refined Centroids of Merged Class 0 andClass 13.3 The combination of ECOC and Model-Refinement for centroid classifierIn this subsection, we present the outline(Figure 5) of combining ECOC and Model-Refinement for centroid classifier.
In substance,the improved ECOC combines the strengths ofECOC and Model-Refinement.
ECOC research inensemble learning techniques has shown that it iswell suited for classification tasks with a largenumber of categories.
On the other hand, Model-Refinement has proved to be an effectiveapproach to reduce the bias of base classifier, thatis to say, it can dramatically boost theperformance of the base classifier.Figure 5: Outline of combining ECOC and Model-Refinement4.
Experiment Results4.1 DatasetsIn our experiment, we use two corpora:NewsGroup1, and Industry Sector2.NewsGroup The NewsGroup dataset containsapproximately 20,000 articles evenly dividedamong 20 Usenet newsgroups.
We use a subsetconsisting of total categories and 19,446documents.Industry Sector The set consists of companyhomepages that are categorized in a hierarchy ofindustry sectors, but we disregard the hierarchy.There were 9,637 documents in the dataset, whichwere divided into 105 classes.
We use a subsetcalled as Sector-48 consisting of 48 categoriesand in all 4,581 documents.4.2 Experimental DesignTo evaluate a text classification system, we useMicroF1 and MacroF1 measures (Chai et al2002).
We employ Information Gain as featureselection method because it consistently performswell in most cases (Yang et al 1997).
We employTFIDF (Sebastiani 2002) to compute featureweight.
For SVM classifier we employSVMTorch.
(www.idiap.ch/~bengio/projects/SVMTorch.html).4.3 Comparison and AnalysisTable 1 and table 2 show the performancecomparison of different method on two datasetswhen using 10,000 features.
For ECOC, we use63-bit BCH coding; for Model-Refinement, wefix its MaxIteration as 8.
For brevity, we use MRto denote Model-Refinement.From the two tables, we can observe thatECOC indeed brings significant bias for centroidclassifier, which results in considerable decreasein accuracy.
Especially on sector-48, the biasreduces the MicroF1 of centroid classifier from0.7985 to 0.6422.On the other hand, the combination of ECOCand Model-Refinement makes a significantperformance improvement over centroid classifier.1 www-2.cs.cmu.edu/afs/cs/project/theo-11/www/wwkb.2 www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/.TRAINING1 Load training data and parameters, i.e., the length ofcode L and training class K.2 Create a L-bit code for the K classes using a kind ofcoding algorithm.3 For each bit, train centroid classifier using the binaryclass (0 and 1) over the total training data.4 Use Model-Refinement approach to adjust centroids.TESTING1 Apply each of the L classifiers to the test example.2 Assign the test example the class with the largest votes.Middle Line Class 0 Class 1C*1C*0d83On Newsgroup, it beats centroid classifier by 4percents; on Sector-48, it beats centroid classifierby 11 percents.
More encouraging, it yields betterperformance than SVM classifier on Sector-48.This improvement also indicates that Model-Refinement can effectively reduce the biasincurred by ECOC.Table 1: The MicroF1 of different methodsMethodDatasetCentroidMR+CentroidECOC+CentroidECOC+ MR+CentroidSVMSector-48 0.7985 0.8671 0.6422 0.9122 0.8948NewsGroup 0.8371 0.8697 0.8085 0.8788 0.8777Table 2: The MacroF1 of different methodsMethodDatasetCentroidMR+CentroidECOC+CentroidECOC+ MR+CentroidSVMSector-48 0.8097 0.8701 0.6559 0.9138 0.8970NewsGroup 0.8331 0.8661 0.7936 0.8757 0.8759Table 3 and 4 report the classification accuracyof combining ECOC with Model-Refinement ontwo datasets vs. the length BCH coding.
ForModel-Refinement, we fix its MaxIteration as 8;the number of features is fixed as 10,000.Table 3: the MicroF1 vs. the length of BCH codingBitDataset15bit 31bit 63bitSector-48 0.8461 0.8948 0.9105NewsGroup 0.8463 0.8745 0.8788Table 4: the MacroF1 vs. the length of BCH codingBitDataset15bit 31bit 63bitSector-48 0.8459 0.8961 0.9122NewsGroup 0.8430 0.8714 0.8757We can clearly observe that increasing thelength of the codes increases the classificationaccuracy.
However, the increase in accuracy isnot directly proportional to the increase in thelength of the code.
As the codes get larger, theaccuracies start leveling off as we can observefrom the two tables.5.
Conclusion RemarksIn this work, we examine the use of ECOC forimproving centroid text classifier.
Theimplementation framework is to decomposemulti-class problems into multiple binaryproblems and then learn the individual binaryclassification problems by centroid classifier.Meanwhile, Model-Refinement is employed toreduce the bias incurred by ECOC.In order to investigate the effectiveness androbustness of proposed method, we conduct anextensive experiment on two commonly usedcorpora, i.e., Industry Sector and Newsgroup.
Theexperimental results indicate that the combinationof ECOC with Model-Refinement makes aconsiderable performance improvement overtraditional centroid classifier, and even performscomparably with SVM classifier.ReferencesBerger, A. Error-correcting output coding for textclassification.
In Proceedings of IJCAI, 1999.Chai, K., Chieu, H. and Ng, H. Bayesian onlineclassifiers for text classification and filtering.
SIGIR.2002, 97-104Ghani, R. Using error-correcting codes for textclassification.
ICML.
2000Ghani, R. Combining labeled and unlabeled data formulticlass text categorization.
ICML.
2002Han, E. and Karypis, G. Centroid-Based DocumentClassification Analysis & Experimental Result.PKDD.
2000.Liu, Y., Yang, Y. and Carbonell, J.
Boosting toCorrect Inductive Bias in Text Classification.
CIKM.2002, 348-355Rennie, J. and Rifkin, R. Improving multiclass textclassification with the support vector machine.
InMIT.
AI Memo AIM-2001-026, 2001.Sebastiani, F. Machine learning in automated textcategorization.
ACM Computing Surveys,2002,34(1): 1-47.Tan, S., Cheng, X., Ghanem, M., Wang, B. and Xu,H.
A novel refinement approach for textcategorization.
CIKM.
2005, 469-476Yang, Y. and Pedersen, J.
A Comparative Study onFeature Selection in Text Categorization.
ICML.1997, 412-420.84
