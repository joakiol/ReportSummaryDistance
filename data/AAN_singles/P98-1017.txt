An Efficient Kernel for Multilingual Generation inSpeech-to-Speech Dialogue TranslationT i lman Becker  and Wol fgang F ink le r  and Anne K i lger  and Peter  Po l le rGerman Research Center for Artificial Intelligence (DFKI  GmbH)Stuhlsatzenhausweg 3D-66123 SaarbriickenGermanybecker~dfk i .de ,  f ink le r~dfk i .de ,  k i lgerOdfk i .de ,  po l le r~dfk i .deAbst rac tWe present core aspects of a fully implementedgeneration component in a multilingual speech-to-speech dialogue translation system.
Its de-sign was particularly influenced by the neces-sity of real-time processing and usability formultiple languages and domains.
We devel-oped a general kernel system comprising a mi-croplanning and a syntactic realizer module.Tile microplanner performs lexical and syntac-tic choice, based on constraint-satisfaction tech-niques.
The syntactic realizer processes HPSGgrammars reflecting the latest developments ofthe underlying linguistic theory, utilizing theirpre-processing into the TAG formalism.
Thedeclarative nature of the knowledge bases, i.e.,the microplanning constraints and the HPSGgrammars allowed an easy adaption to new do-mains and languages.
The successful integra-tion of our component into the translation sys-tem Verbmobil proved the fulfillment of the spe-cific real-time constraints.1 In t roduct ionIn this paper we present core aspects of the mul-tilingual natural language generation compo-nent VM-GECO 1 that has been integrated intothe research prototype of Verbmobil (Wahlster,1993; Bub et al, 1997), a system for sponta-neous speech-to-speech dialog translation.In order to achieve multilinguality as ele-gantly as possible we found that a clear modu-lar separation between a language-independentgeneral kernel generator and language-specificparts which consist of syntactic and lexicalknowledge sources was a very promising ap-proach.
Accordingly, our generation component1VM-GECO is an acronym for "VerbMobil GEnera-tion COmponents.
"consists of one kernel generator and language-specific knowledge sources for the languagesused in Verbmobih German and English withcurrent work on Japanese.Additionally, the kernel generator itself canbe modularized furthermore into two separatecomponents.
The task of the so-called mi-eroplanning component is to plan an utteranceon a phrase- or sentence-level (Hovy, 1996) in-cluding word-choice (section 2).
It generates anannotated ependency structure which is usedby the syntactic generation component to re-alize an appropriate surface string for it (sec-tion 3).
The main goal of this further modular-ization is a stepwise constraining of the search-space of alternative linguistic realizations, usingabstracted views on different choice criteria.Multilingual generation in dialog translationimposes trong requirements on the generationmodule.
A very prominent problem is the non-wellformedness (incorrectness, irrelevance, andinconsistency) of spontaneous input.
It forcesthe realization of robust generation to be ableto cope with erroneous and incomplete inputdata so that the quality of the generated out-put may vary between syntactically correct sen-tences and semantically understandable utter-ances.
On the level of knowledge sources thisis achieved by using a highly declarative HPSGgrammar which very closely reflects the latestdevelopments of the underlying linguistic the-ory (Pollard and Sag, 1994) and covers phe-nomena of spoken language.
This HPSG iscompiled into a TAG grammar in an offtinepre-Processing step (Kasper et al, 1995) whichkeeps the declarative nature of the grammar in-tact (section 3).Maybe the most important requirement onthe generation module of a speech-to-speechtranslation system is real-time processing.
The110above mentioned features of VM-GECO con-tribute to the efficiency of the generation com-ponent.
The TAG-formalism is well known forthe existence of efficient syntactic generation al-gorithms (Kilger and Finkler, 1995).In general, all knowledge sources of all mod-ules are declarative.
The main advantage isthat this allows for an easier adaptation of thegeneration component to other domains, lan-guages and semantic representation languagesbesides the easier extendability of the currentsystem.
The feasibility of the language adap-tation was proved in the Verbmobil project it-self where the (originally English) generator wasrecently extended to cover German and is cur-rently adapted for Japanese.
The adaptationto another domain and also to another specifi-cation language for intermediate structures wasshown in another translation project which usesin contrast o Verbmobil an interlingua basedapproach (section 4.1).2 The  Mic rop lannerA generation system for target language utter-ances in an approach to speech-to-speech trans-lation has to work on input elements represent-ing intermediate results of recognition, analy-sis, and transfer components.
In that setting,several of the tasks of a complete natural an-guage generation system such as selection andorganization of the contents to be expressed areoutside of the control of our generator.
Theyhave been decided by the human user of thetranslation system or they have been negoti-ated and computed by a transfer component.Nevertheless, there remain a number of differentbut highly interrelated subtasks of the genera-tion process where decisions have to be madein order to determine and realize the trans-lation result to be sent to a speech synthesiscomponent.
The diverse subtasks - -  often col-lectively denoted as microplanning (cf.
(Levelt,1989; Hovy, 1996)) - -  comprise the planningof a rough structure of the target language ut-terance, the determination of sentence borders,sentence type, topicalization, theme-rheme or-ganization of sentential units, focus control, uti-lization of nominalized, or infinitival style, aswell as triggering the generation of anaphoraand lexical choice.
In addition, they have toaddress the problem of expressibility of the se-lected contents in a text realization component,i.e., bridging the generation gap (see (Meteer,1990)).The input to our microplanning componentconsists of semantic representations encoded ina minimal recursive structure following a vari-ant of UDRT.
Each individual indicated bysome input utterance is formally represented bya discourse referent.
Information about the in-dividual is encoded within the DRS-conditions.Relations between descriptions of different dis-course referents lead to a hierarchical semanticstructure (see Figure 1 for a graphical represen-tation of fragments of an example input to thegenerator).
Discourse referents are depicted asboxes headed by individual names in; conditionsare illustrated within those boxes.\[ \]mm _ \[\]  / Im==> {1151416 IS}\ [ \ ]temp_loc {i213}workjcceptable 12arg3 {i214}perspective {i2 I1);em_Groul1,3 I,,o.
13 I ~ ~ ' ~Itll demonstrative {i3 It2 ht 1) JFigure 1: Example Input to the GeneratorBesides these input terms from the transfercomponent, the generator may access knowl-edge about the dialogue act, the dialogue his-tory as well as some prosodic information of theuser's utterance.The output of the microplanner is a sentenceplan that serves as input for the syntactic real-ization component.
It describes a dependencytree over lexical items annotated with syntac-tic, semantic, and pragmatic information whichis relevant o produce an acceptable utteranceand guide the speech synthesis component.2.1 Des ign of the  M ic rop lann ing  Kerne lAn important design principle of our generatoris the demand to cope with multidirectional de-pendencies among decisions of the diverse sub-tasks of microplanning without preferring one111order of decisions over others.
E.g., the choiceof an interrogative sentence requires an (at leastelliptical) verbal phrase as a major constituentof the sentence; nominalization or the choiceof passive voice depends on the result of wordchoice, etc.
Therefore, we conceived microplan-ning as a constraint-satisfaction problem (Ku-mar, 1992) representing undirected relations be-tween variables.
Thereby, variables are createdfor elements in the input to the generator.
Theyare connected by means of weighted constraints.The domains of the variables correspond to ab-stractions of possible alternatives for syntacticrealizations of the semantic elements includingsets of specifications of lexical items and syntac-tic features.
A solution of the constraint systemis a globally consistent instantiation of the vari-ables and is guaranteed to be a valid input forthe syntactic generation module.
Since theremight be locally optimal mappings that lead tocontradiction on a global level, the microplan-net generally uses these weighted constraints todirect a backtracking or propagation process.One the one hand, the advantages of utiliz-ing a constraint system lie in the declarativ-ity of the knowledge sources allowing for aneasier adaptation of the system to other do-mains and languages.
We benefited from thisdesign decision and realized microplanning forEnglish and German by means of merely estab-lishing new rule sets for lexical and syntacticchoice.
The core engine for constraint process-ing was reused without modification.
On theother hand, having defined a suitable represen-tation of the problem to be solved, a constraint-based approach also establishes a testbed forexamining the pros and cons of different eval-uation methods, including backtracking, con-straint propagation, heuristics for the order ofthe instantiation of variable values, to name afew means of dealing with competition amongalternatives and to find a solution.The microplanner makes use of the minimalrecursive structure of its semantic input term(see Fig.
1) by triggering activities by bundles ofconditions, discourse referents, and holes repre-senting underspecified scope relations in the in-put.
These three input categories are reflectedby different microplanning rule sets that are ap-plied conjointly during the process of microplan-ning.
The rules are represented as pattern-condition-action triples.
A pattern is to bematched with part of the input, a conditiondescribes additional context-dependent require-ments to be fulfilled by the input, and the ac-tion part describes a bundle of syntactic featuresrealizing lexical entities and their relations tocomplements and modifiers.A microplanning rule for the combination ofthe semantic predicates WORK_ACCEPTABLE, ARG3,and PERSPECTIVE which get realized as a finiteverb, i.e., representing a 3:1 mapping of se-mantic predicates to a syntactic specification isshown in Figure 2.; ;  s tandard  f in i te  verb  w i th  2 complements((WORK_ACCEPTABLE (L I) ARG3 (L 1 12) ;; patternPERSPECTIVE (L% I I3))($not ($sem-match NOM (L I))) ;; condition(WORK_ACCEPTABLE (CAT V) ;; action(HEAD (OR SUIT_V1 SUIT_V2)) (FORM ordinary)(TENSE Sget-tense I) (VOICE Sget-voice I))(I2 (GENDER (NOT MAS FEM)))(REGENT-DEP-FUNC WORK_ACCEPTABLE 12 AGENT)(REGENT-DEP-FUNC WORK_ACCEPTABLE 13 PATIENT)(KEY KEY-V) ); ; nominalized form .
.
.Figure 2: Example Microplanning Content RuleIn the condition part of the verbal mappingthe existence of a NOM-condition within the se-mantic input information is tested.
It wouldforbid the verbal form by demanding a nomi-nalized form.
The action part describes the re-sult of lexical selection (the lemma "suit") plusgeneric functions for computing relevant syntac-tic features like tense and voice.
I2 which standsfor the ARG3 of WORK_ACCEPTABLE, defined by adatabase of linking-information as the semanticagent is characterized as neither allowing gen-der masc(uline) nor fem(inine) for preventing"he suits" in the sense of "he is okay".
En-tries starting with KEY define identifiers used forcomputing the preference value of a microplan-ning rule with respect to the given situation.In an additional database, KEYs are associatedwith weights for predefined situation character-istics such as time pressure, or register.
Themicroplanning content rules are not directly en-tered by a rule writer but are compiled off-linefrom several knowledge sources for lexical choicerules, rules for syntactic decisions and linkingrules, thereby filtering out contradictory combi-nations without requiring on-line runtime.Regarding the sets of alternatives that result112from the application of the microplanning rules,the most direct way of realizing a constraintnet seems to be the definition of one variablefor each condition, discourse referent, and hole,leading to a variable net as shown in Figure 3.Figure 3: Variable Net for MicroplanningFor our task, it is not enough to define bi-nary matching constraints between each pairof variables that purely test the compatibilityof the described syntactic features.
Some syn-tactic specifications may contain identificationsof further entities, e.g., discourse referents andsyntactic identifiers which influence the resultof the compatibility test between a pair of vari-ables referring to these identifiers.
Thus, theconstraint net is not easily subdivided into sub-nets that can be efficiently evaluated.
The largenumber of combinations of alternative values ishandled by known means for CSP such as unit-ing variables with 1-value domains and apply-ing matching mechanisms to their values, com-putation of 2-consistency by matching valuepairs and filtering out inconsistent ones, storingand reusing knowledge about binary incompat-ibility and performing intelligent backtracking.The result of the constraint solving processfor the input shown in Fig.
1 is given in Fig.
4.L21-QUEST(intention w/i-question) ~clau=e(real hs) (cat utt.par)L -WORK_ACCEP+AB'E\/ ==gent/(voice active) \ .. ~ temp =pe?~'/ / (head(  .
.
.
.
it_vl ~patient "~- - 'L6-TEMP_LOC / suit2)) "~ "~(head whenl) / (tensefut.)
L10-PRON L15-TEMP_LOC(wh-focus t) / (cat v) (pers 2a) (head then adv)(cat adv) ~ (cat ppron) (cat adv)L13-PRON (aura s$)(pers 3)(cat ppron)(hum sg)Figure 4: Microplanning Result for the Example3 The  Rea l i zerThe syntactic realizer 2 proceeds from the mi-croplanning result as shown in Figure 5.
It pro-duces a derived phrase structure from which theoutput string is read off.
The realizer is basedon a fully lexicalized grammar in the sense thatevery lexical item selects for a finite set of possi-ble phrase structures (called elementary trees).In particular, we use a Feature-Based Lexical-ized Tree-Adjoining Grammar (FB-LTAG, see(Vijay-Shanker and Joshi, 1988; Schabes et at.,1988)) that is derived from an HPSG grammar(see section 4 for some more details).
The el-} ementary trees (see Figure 9) can be seen asmaximal partial projections.
A derivation of anutterance is constructed by combining appro-priate elementary trees with the two elementaryTAG operations of adjunction and substitution.For each node (i.e., lexical item) in the de-pendency tree, the tree selection phase deter-mines the set of relevant TAG trees.
A firsttree retrieval step maps every object of thedependency tree into a set of applicable ele-mentary TAG trees.
The main tree selectionphase uses information from the microplanneroutput to further refine the set of retrievedtrees.
The combination phase finds a success-ful combination of trees to build a (derived)phrase structure tree.
The final inflection phaseuses the information in the feature structuresof the leaves (i.e., the words) to apply appro-priate morphological functions.
An initial pre-processing phase is needed to accommodate hehandling of auxiliaries which are not determinedin microplanning.
They are derived from thetense, aspect and sentence mood information assupplied by microplanning.
(expand ,vxiliazi=s) (adj~lining ~id ~ubstiIUilOll)l ~ g- 'AGFigure 5: Steps of the syntactic generator.The two core phases are the tree selection and2A more detailed escription iscontained in (Becker,1998).113the combination phase.
The tree selection isdriven by the HPSG instance or word class thatis supplied by the microplanner.
It is mapped toa lexical type by a lexicon that is automaticallycompiled from the HPSG grammar.
The lexi-cal types are then mapped to a tree family, i.e.,a set of elementary TAG trees representing allpossible minimally complete phrase structuresthat can be build from the instance.
The ad-ditional information in the dependency tree isthen used to add further feature values to thetrees.
This additional information acts as a fil-ter for selecting appropriate trees in two stages:Some values are incompatible with values al-ready present in the trees.
These trees cantherefore be filtered immediately from the set.E.g., a syntactic structure for an imperativeclause is marked as such by a feature and canbe discarded if a declarative sentence is to begenerated.
Additional features can prevent hecombination with other trees during the combi-nation phase.
This is the case, e.g., with agree-ment features.The combination phase completely belongs tothe core machinery.
It can be exchanged withmore efficient algorithms without change of thegrammar or lexicon.
It explores the search spaceof all possible combinations of trees from thecandidate sets for each lexical item (instance).Since there is sufficient information availablefrom the microplanner result and from the trees,a well-guided best-first search strategy can beemployed in the current system.As part of the tree selection phase, based onthe rich annotation of the input structure, thetree sets are sorted locally such that preferredtrees are tested first.
Then a modified back-tracking algorithm traverses the dependencytree in a bottom-up fashion a.
At each node andfor each subtree in the dependency tree, a can-didate for the phrase structure of the subtreeis constructed.
Then all possible adjunction orsubstitution sites are computed, possibly sorted(e.g., allowing for preferences in word order) andthe best candidate for a combined phrase struc-ture is returned.
Since the combination of twopartial phrase structures by adjunction or sub-stitution might fail due to incompatible featurestructures, a backtracking algorithm must be3The algorithm stores intermediate r sults with amemoization technique.used.
A partial phrase structure for a subtree ofthe dependency is finally checked for complete-ness.
These tests include the unifiability of alltop and bottom feature structures and the satis-faction of all other constraints (e.g., obligatoryadjunctions or open substitution odes) sinceno further adjunctions or substitutions will oc-cur in this subtree.The necessity of a spoken dialog translationsystem to robustly produce output calls forsome relaxations in these tests.
E.g., 'obliga-tory' arguments may be missing in the utter-ance.
This can be caused by ellipsis in sentencessuch as "Ok, we postpone."
or by false segmen-tations in the analysis uch as segmenting "WitsoIlten (we should) das Treffen verschieben (themeeting postpone)."
into two segments "Witsollten" and "das Treffen verschieben".
In orderto generate "postpone the meeting" for the sec-ond segment, the tests in the syntactic genera-tor must accept a phrase with a missing subjectif no other complete phrase can be generated.Figure 6 shows a combination of the treeretrieval and the tree selection phases.
Inthe tree retrieval phase for L5-WORK.ACCEPTABLE,first the HEAD information is used to determinethe lexical types of the possible realizationsSUIT_Vl and SUIT_V2, namely MV_NP_TRANS_LEand MV_EXPL_PREP_TRANSIE respectively 4.
Thesetypes are then mapped to their respective sets ofelementary trees, a total of 25 trees.
In the treeselection phase, this number is reduced to six.For example, the tree MV_NP_TRANS_LE.2 inFigure 9 has a feature C\[_-MODE with the valueIMPERATIVE.
Now, the microplanner outputfor the root entity LGVI contains the informa-tion (INTENTION WH-QUESTION).
The INTENTIONinformation is unified with all appropriate CL-MODE features, which in this case fails.
There-fore the tree MV_NP_TRANS_LE.2 is discardedin the tree selection phase.The combination phase uses the best-firstbottom-up algorithm described above to deter-mine one suitable tree for every entity and alsoa target node in the tree that is selected for thegoverning entity.
For the above example, theselected trees and their combination odes are4MV_NP_TRANS_LE is an abbreviation for "Main Verb,NP object, TRANSitive Lexical Entry" used in sentenceslike "Monday suits me.
"114; ;  traverse for: LS-WORK_ACCEPTABLEreturned MV_NP_TRANS_LEreturned MV_EXPL_PREP_TRANS_LEtotal: 6 trees;; traverse for: LI3-PRONreturned PERS_PRO_LEtotal: 1 tree;; traverse for: LIO-PRONreturned PERS_PR0_LEtotal: I tree; traverse for: L6-TEMP L0Creturned WH_ADVERB_W0RD_LEtotal: 2 treestraverse for: LI5-TEMP_LOCreturned NP_ADV_WORD LEtotal: 5 trees; traverse for: LGVIreturned WILL_AUX_P0S_LEtotal: 2 treesFigure 6: An excerpt from the tree retrieval andselection phase.shown in Figure 75 .s o.
- - - - - .,"  S/ADV " ' .  "
' ,  A DV-"' -::: .
.
- I , -  .
.
.
.
.
.
.
.
.
.
.
'," VP VP: v/%,4, ADV . "
"  NP ,I I ',--'" I I v l  Iw~tesl ~vill il xldl you thenL6 -'rEMP_LOC I~ lY l  LZ3-PRON L5-~JZT  LZO-Pl ION L15 -T I4(P_LOCFigure 7: The trees finally selected for the enti-ties of the example sentence.Figure 8 shows the final phrase structure forthe example.
The inflection function selectsthe base form of "suit" according to the BSEvalue of the VFORM feature and correctly uses"will."
Information about the sentence modeWH-QUESTION can be used to annotate the re-sulting string for the speech-synthesis module.4 Resu l tsOur approach to separate a generation mod-ule into a language-independent kernel andlanguage-specific knowledge sources has beensuccessfully implemented in a dialogue trans-lation system.
Furthermore, the mentionedadaptability to other generation tasks has alsobeen proved by an adaptation of the generationmodule to a new application domain and also toa completely different semantic representation5Note that the node labels hown in Figures 7 and 8are only a concession toreadability.
The TAG require-ment hat in an auxiliary tree the foot node must havethe same category label as the root node is fulfilled.SADV S/ADVIv.'he.
V VPIADVIV NP VPI Iwi l l  i t  VP ADVV NP thenI isuit  youFigure 8: The final phrase structure for "Whenwill it suit you then?
"MV_NP TRANS LF - !
MV_NP_TRANS LF~2 MV NP TRANS_LE.3 MV NP TRANS LEAVP S S SMV NP_TRANS L| V NP J,l I IMV_NP TRAN$ LE MV NP_TRANS LE MV NP TRANS_LEFigure 9: Some of the trees for transitive verbs.They are compiled from the corresponding lex-ical type MV_NP_TRANS_LE as defined in theHPSG grammar.
Trees 3 and 4 differ only withrespect to their feature structures which are notshown in this figure.language by adapting the microplanning knowl-edge sources to the new formalism.VM-GECO is fully implemented (in CommonLisp) and integrated into the speech-to-speechtranslation system Verbmobil for two outputlanguages, English and German.
The adapta-tion to Japanese generation will be performed inthe current project phase.
Our experience fromadding German makes us confident hat thiscan be done straightforwardly b creating theappropriate knowledge sources without modi-fications of the kernel generator.
To give thereader a more detailed impression of the im-plementation of the generation component wepresent some characteristic data of the Englishgenerator.
The numbers for the German sys-tem, especially for lexicon and processing time,are similar.The underlying English grammar is a lexical-ized TAG which consists of 2844 trees.
Thesetrees were transformed uring an of\[line pre-processing step from 2961 HPSG lexical en-tries of the linguistically well motivated En-glish HPSG grammar written at CSLI.
Onthe other hand the microplanner's knowledgesources consist of 2730 partially pre-processedmicroplanning rules which are utilized in an in-115tegrated handling of structural and lexical de-cisions based on constraint propagation.
Themicroplanning rules are of course especiallyadapted to the underlying semantic represen-tation formalism.
Furthermore, the underlyinglexicon covers the word list that has been con-structed from a large corpus of the applicationdomain of the Verbmobil system, i.e., negotia-tion dialogues in spontaneous speech.The TAG grammar esulting from the com-pilation step allows for highly efficient lexicallydriven robust syntactic generation mainly con-sisting of tree adjoinings, substitutions, and fea-ture unifications.
The average overall genera-tion time per sentence (up to length 24) is 0.7seconds on a SUN ULTRA-1 machine, 68 % ofthe runtime are needed for the microplanningwhile the remaining 32 % of the runtime areneeded for syntactic generation.4.1 Reus ing the Kerne lBeside the usability for multiple languages inVerbmobil our kernel generation component hasalso proven its adaptability to a very differ-ent semantic representation language (system-atically and terminologically) in another stillongoing multilingual (currently 12 languages)translation project.
The project utilizes aninterlingua-based approach to semantic rep-resentations of utterances.
The goal of thisproject is to overcome the international lan-guage barrier which is exemplarily realized by alarge corpus improvement ofthe transparency ofconsisting of international law texts.
Our partin this project is the realization and implemen-tation of the German generation component.Because of our language-independent core gen-erator the adaptation of the generation compo-nent to this semantic representation decreasedto the adaptation of the structural and lexi-cal knowledge bases of the microplanning com-ponent and appropriate domain-specific exten-sions on the lexicon of the syntactic generator.With an average sentence length of 15 wordsthe average runtime per sentence on a SUNULTRA-2 is less than 0.5 seconds.
Currently,even the longest sentence (40 words) needs un-der 2 seconds runtime.Within Verbmobil, the generation componentwill also be used for text generation when pro-ducing protocols as described in (Alexanderssonand Poller, 1998).ReferencesJ.
Alexandersson and P. Poller.
1998.
Towardsmultilingual protocol generation for spon-taneous speech dialogues.
In 9th INLGW,Niagara-on-the-lake, Canada.T.
Becker.
1998.
Fully lexicalized head-driven syntactic generation.
In 9th INLGW,Niagara-on-the-lake, Canada.Th.
Bub, W. Wahlster, and A. Waibel.
1997.Verbmobil: The combination of deep andshallow processing for spontaneous peechtranslation.
In Proceedings of ICASSP '97.E.
Hovy.
1996.
An overview of automated natu-ral language generation.
In X. Huang, editor,Proc.
of the Intl.
Symposium on NL Genera-tion and the Processing of the Chinese Lan-guage, INP(C)-96, Shanghai, China.R.
Kasper, B. Kiefer, K. Netter, and K. Vijay-Shanker.
1995.
Compilation of HPSG toTAG.
In 33rd A CL, Cambridge, Mass.A.
Kilger and W. Finkler.
1995.
Incremen-tal generation for real-time applications.Research Report RR-95-11, DFKI GmbH,Saarbrficken, Germany, July.V.
Kumar.
1992.
Algorithms for constraint-satisfaction problems: A survey.
AI Maga-zine, 13(1):32-44.W.J.M.
Levelt.
1989.
Speaking: From Intentionto Articulation.
The MIT Press, Cambridge,MA.M.W.
Meteer.
1990.
The "Generation Gap"-The Problem of Expressibility in Text Plan-ning.
Ph.D. thesis, Amherst, MA.
BBN Re-port No.
7347.C.
Pollard and I.
A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
Studies in Con-temporary Linguistics.
University of ChicagoPress, Chicago.Y.
Schabes, A. Abeill~, and A. K. Joshi.
i988.Parsing strategies with 'lexicalized' gram-mars: Application to tree adjoining gram-mars.
In COLING-88, pages 578-583, Bu-dapest, Hungary.K.
Vijay-Shanker and A. K. Joshi.
1988.
Fea-ture structure based tree adjoining rammars.In COLING-88, pages 714-719, Budapest,Hungary.W.
Wahlster.
1993.
Verbmobih Translationof face-to-face dialoges.
In MT Summit IV,Kobe, Japan.116
