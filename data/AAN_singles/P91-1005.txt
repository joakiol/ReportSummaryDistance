AN ALGORITHM FOR PLAN RECOGNIT ION INCOLLABORATIVE  D ISCOURSE*Karen E. LochbaumAiken Computat ion  LabHarvard University33 Oxford StreetCambridge,  MA 02138ke l~harvard .harvard .eduABSTRACTA model of plan recognition i discourse must be basedon intended recognition, distinguish each agent's be-liefs and intentions from the other's, and avoid as-sumptions about the correctness or completeness ofthe agents' beliefs.
In this paper, we present an algo-rithm for plan recognition that is based on the Shared-Plan model of collaboration (Grosz and Sidner, 1990;Lochbaum et al, 1990) and that satisfies these con-straints.INTRODUCTIONTo make sense of each other's utterances, conversa-tional participants must recognize the intentions be-hind those utterances.
Thus, a model of intended planrecognition is an important component of a theory ofdiscourse understanding.
The model must distinguisheach agent's beliefs and intentions from the other's andavoid assumptions about the correctness or complete-ness of the agents' beliefs.Early work on plan recognition in discourse, e.g.Allen & Perrault (1980); Sidner & Israel (1981), wasbased on work in AI planning systems, in particu-lar the STRIPS formalism (Fikes and Nilsson, 1971).However, as Pollack (1986) has argued, because thesesystems do not differentiate between the beliefs andintentions of the different conversational participants,they are insufficient for modelling discourse.
AlthoughPollack proposes a model that does make this distinc-tion, her model has other shortcomings.
In particular,it assumes a master/slave r lationship between agents(Grosz and Sidner, 1990) and that the inferring agenthas complete and accurate knowledge of domain ac-tions.
In addition, like many earlier systems, it reliesupon a set of heuristics to control the application ofplan inference rules.In contrast, Kautz (1987; 1990) presented a theo-retical formalization of the plan recognition problem,*This research as been supported by U S WEST Ad-vanced Technologies and by a Bellcore Graduate Fellow-ship.and a corresponding algorithm, in which the only con-clusions that are drawn are those that are "absolutelyjustified."
Although Kautz's work is quite elegant, ittoo has several deficiencies as a model of plan recogni-tion for discourse.
In particular, it is a model of keyholerecognition m the inferring agent observes the actionsof another agent without that second agent's knowl-edge - -  rather than a model of intended recognition.Furthermore, both the inferring and performing agentsare assumed to have complete and correct knowledgeof the domain.In this paper, we present an algorithm for intendedrecognition that is based on the SharedPlan model ofcollaboration (Grosz and Sidner, 1990; Lochbaum etal., 1990) and that, as a result, overcomes the limita-tions of these previous models.
We begin by brieflypresenting the action representation used by the algo-rithm and then discussing the type of plan recogni-tion necessary for the construction of a SharedPlan.Next, we present he algorithm itself, and discuss aninitial implementation.
Finally, because Kautz's planrecognition Mgorithms are not necessarily tied to theassumptions made by his formal model, we directlycompare our algorithm to his.ACTION P~EPRESENTATIONWe use the action representation formally defined byBalkanski (1990) for modelling collaborative actions.We use the term act-type to refer to a type of action;e.g.
boiling water is an act-type that will be repre-sented by boil(water).
In addition to types of actions,we also need to refer to the agents who will performthose actions and the time interval over which they willdo so.
We use the term activity to refer to this typeof information1; e.g.
Carol's boiling water over sometime interval (tl) is an activity that will be representedby (boil(water),carol,tl).
Throughout the rest of thispaper, we will follow the convention of denoting ar-bitrary activities using uppercase Greek letters, whileusing lowercase Greek letters to denote act-types.
In1This terminology supersedes that used in (Lochbaumet al, 1990).33RelationsConstructorsAct-type ActivityCGEN(71,72,C)CENABLES(7~,~f2,C)sequence(v1 ,...,Tn)simult(71 .... ,7-)conjoined(v1 ,.-.,7n)iteration(AX.v\[XJ,{X1,...Xn})GEN(r,,r~)ENABLES(FI,r2)g(r l  ..... r , )I(Ax.rixl,iX~,...x,})Table 1: Act-type/Activity Relations and Constructors defined by Balkanski (1990)addition, lowercase letters denote the act-type of theactivity represented by the corresponding uppercaseletter, e.g.
7 -- act-type(F).Balkanski also defines act-type and activity con-structors and relations; e.g.
sequence(boil(water),add(noodles,water)) represents the sequence of doingan act of type boil(water) followed by an act of typeadd(noodles,water), while CGEN(mix(sauce,noodles),make(pasta_dish),C) represents that the first act-typeconditionally generates the second (Goldman, 1970;Pollack, 1986).
Table 1 lists the act-type and corre-sponding activity relations and constructors that willbe used in this paper.Act-type constructors and relations are used inspecifying recipes.
Following Pollack (1990), we usethe term recipe to refer to what an agent knowswhen the agent knows a way of doing something.As an example, a particular agent's recipe for lift-ing a piano might be CGEN(simult(lift(foot(piano)),lift(keyboard(piano))), lift(piano), AG.\[IGI=2\]); thisrecipe encodes that simultaneously lifting the foot- andkeyboard ends of a piano results in lifting the piano,provided that there are two agents doing the lifting.For ease of presentation, we will sometimes representrecipes graphicMly using different ypes of arrows torepresent specific act-type relations and constructors.Figure 1 contains the graphical presentation of the pi-ano lifting recipe.lift(pi~o)\]" AG.\[IGI-= 2\]simult (lift (foot (piano)),lift (keyboaxd(piano)))c, / \c2lift(foot(piano)) lift (keyboaxd (piano))TC indicates generation subject to the condition Cc~/indicates constituent i of a complex act-typeFigure 1: A recipe for lifting a pianoTHE SHAREDPLAN AUGMENTATIONALGORITHMA previous paper (Lochbaum et hi., 1990) describesan augmentation algorithm based on Grosz and Sid-ner's SharedPlan model of collaboration (Grosz andSidner, 1990) that delineates the ways in which anagent's beliefs are affected by utterances made in thecontext of collaboration.
A portion of that algorithmis repeated in Figure 2.
In the discussion that follows,we will assume the context specified by the algorithm.SharedPlan*(G1,G2,A,T1,T2) represents that G1 andG2 have a partial SharedPlan at time T1 to performact-type A at time T2 (Grosz and Sidner, 1990).Assume:Act is an action of type 7,G~ designates the agent who communicates Prop(Act),Gj designates the agent being modelledi, j E {1,2}, i ~ j,SharedPlan*(G1 ,G~,A,T1,T2).4.
Search own beliefs for Contributes(7,A) and where pos-sible, more specific information as to how 7 contributesto A.Figure 2: The SharedPlan Augmentation AlgorithmStep (4) of this algorithm is closely related to thestandard plan recognition problem.
In this step, agentGj is trying to determine why agent G~ has mentionedan act of type 7, i.e.
Gj is trying to identify the roleGi believes 7 will play in their SharedPlan.
In ourprevious work, we did not specify the details of howthis reasoning was modelled.
In this paper, we presentan algorithm that does so.
The algorithm uses a newconstruct: augmented rgraphs.AUGMENTED RGRAPH CONSTRUCTIONAgents Gi and Gj each bring to their collaboration pri-vate beliefs about how to perform types of actions, i.e.recipes for those actions.
As they collaborate, a signifi-cant portion of their communication is concerned withdeciding upon the types of actions that need to be per-formed and how those actions are related.
Thus, theyestablish mutual belief in a recipe for action s. In ad-dition, however, the agents must also determine which2Agents do not necessarily discuss actions in a fixed or-der (e.g.
the order in which they appear in a recipe).
Con-sequently, our algorithm is not constrained to reasoningabout actions in a fixed order.34agents will perform each action and the time inter-val over which they will do so, in accordance with theagency and timing constraints specified by their evolv-ing jointly-held recipe.
To model an agent's reasoningin this collaborative situation, we introduce a dynamicrepresentation called an augmented recipe graph.
Theconstruction ofan augmented recipe graph correspondsto the reasoning that an agent performs to determinewhether or not the performance of a particular activ-ity makes ense in terms of the agent's recipes and theevolving SharedPlan.Augmented recipe graphs are comprised of twoparts, a recipe graph or rgraph, representing activitiesand relations among them, and a set of constraints,representing conditions on the agents and times ofthose activities.
An rgraph corresponds to a partic-ular specification of a recipe.
Whereas a recipe rep-resents information about the performance, in the ab-stract, of act-types, an rgraph represents more spe-cialized information by including act-type performanceagents and times.
An rgraph is a tree-like representa-tion comprised of (1) nodes, representing activities and(2) links between odes, representing activity relations.The structure of an rgraph mirrors the structure of therecipe to which it corresponds: each activity and ac-tivity relation in an rgraph is derived from the corre-sponding act-type and act-type relation in its associ-ated recipe, based on the correspondences in Table 1.Because the constructors and relations used in specify-ing recipes may impose agency and timing constraintson the successful performance ofact-types, the rgraphrepresentation is augmented by a set of constraints.Following Kautz, we will use the term explaining torefer to the process of creating an augmented rgraph.AUGMENTED RGRAPH SCHEMASTo describe the explanation process, we will assumethat agents Gi and Gj are collaborating to achieve anact-type A and Gi communicates a proposition fromwhich an activity F can be derived 3 (cf.
the assump-tions of Figure 2).
Gj's reasoning in this context ismodelled by building an augmented rgraph that ex-plains how F might be related to A.
This representa-tion is constructed by searching each of Gj's recipes forA to find a sequence of relations and constructors link-ing 7 to A. Augmented rgraphs are constructed duringthis search by creating appropriate nodes and links aseach act-type and relation in a recipe is encountered.By considering each type of relation and construc-tor that may appear in a recipe, we can specify gen-eral schemas expressing the form that the correspond-ing augmented rgraph must take.
Table 2 containsthe schemas for each of the act-type relations and3F need not include a complete agent or time specifica-tion.constructors 4.The algorithm for explaining an activity F accordingto a particular ecipe for A thus consists of consider-ing in turn each relation and constructor in the recipelinking 7 and A and using the appropriate schemato incrementally build an augmented rgraph.. Eachschema specifies an rgraph portion to create and theconstraints to associate with that rgraph.
If agentG/ knows multiple recipes for A, then the algorithmattempts to create an augmented rgraph from eachrecipe.
Those augmented rgraphs that are successfullycreated are maintained as possible explanations for Funtil more information becomes available; they repre-sent Gj's current beliefs about Gi's possible beliefs.If at any time the set of constraints associated withan augmented rgraph becomes unsatisfiable, a failureoccurs: the constraints stipulated by the recipe are notmet by the activities in the corresponding r raph.
Thisfailure corresponds to a discrepancy between agentGj's beliefs and those Gj has attributed to agent G~.On the basis of such a discrepancy, agent G i mightquery Gi, or might first consider the other recipes thatshe knows for A (i.e.
in an attempt to produce a suc-cessful explanation using another ecipe).
The algo-rithm follows the latter course of action.
When a recipedoes not provide an explanation for F, it is eliminatedfrom consideration and the algorithm continues look-ing for "valid" recipes.To illustrate the algorithm, we will consider thereasoning done by agent Pare in the dialogue inFigure 3; we assume that Pam knows the recipegiven in Figure 1.
To begin, we consider the ac-tivity derived from utterance (3) of this discourse:F1 =(lift(foot(piano)), {joe},tl), where tl is the time in-terval over which the agents will lift the piano.
To ex-plain F1, the algorithm creates the augmented rgraphshown in Figure 4.
It begins by considering the otheract-types in the recipe to which 7x=lift(foot(piano))isrelated.
Because 71 is a component of a simultaneousact-type, the simult schema is used to create nodes N1,N2, and the link between them.
A constraint of thisschema is that the constituents of the complex activ-ity represented by node N2 have the same time.
Thisconstraint is modelled irectly in the rgraph by creat-ing the activity corresponding to lift(keyboard(piano))to have the same time as F1.
No information aboutthe agent of this activity is known, however, so a vari-able, G1, is used to represent the agent.
Next, becausethe simultaneous act-type is related by a CGEN rela-tion to lift(piano), the CGEN schema is used to createnode N3 and the link between N2 and N3.
The firsttwo constraints of the schema re satisfied by creatingnode N3 such that its activity's agent and time are the4The technicM report (Lochbaum, 1991) contains amoredetailed iscussion of the derivation of these schemas fromthe definitions given by Balkanski (1990).35Recipe Augmented RgraphRgraph ConstraintsCGEN(7, 6,C)CENABLES(7, 6,C)sequence(71,72,...7-)conjoined(71,72, ...7-)simult (71,72, ...7,)iteration(AX.7\[X\],{Xa, X2, ...X,})(6,G,T)T GENr(8, G,T)~r ENABLESrK(rl, r2, ..., r , )=AI cir~K(rl, r2 .... r , )=AJ ciriK(ra, r2, :..r,)=AI clr~I(AX.r\[x\], {X~, ...X~})=AI ci\[xx.rixllx~G=agent(r)T=time(r)HOLDS'(C,G,T)HOLDS'(C,agent(r),time(r))BEFORE(time(F),T)Yj BEFORE(time(r)),time(rj+l))agent(A)=Ujagent(rj)time(A)=cover_interval({time(rj )})~.agent(A)=Ujagent(rj)time(A)=coverAnterval({ time(r) ))Yj time(r3)=time(rj+,)agent (A)=~j j  agent ( r , )time(A)=coverAnterval({time(rj )})agent(A)=agent(r)time(A)=time(r)Table 2: Rgraph Schemassame as node N2's.
The third constraint is instantiatedand associated with the rgraph.
(1) Joe: I want to lift the piano.
(2) Pare: OK.(3) Joe: On the count of three, I'll pick up this\[deictic to foot\] end,(4) and you pick up that\[deictic to keyboard\] end.
(5) Pam: OK.(6) Joe: One, two, three!Figure 3: A sample discourseRgraph:NS:{lift(piano),{joe} v G 3,tl)1" GENN2:K({lift(foot(pitmo)),{joe},t 1},0ift(keyboard(piano)),G1 ,t 1})I clN 1: 0ift (foot (piano)),{joe } #1}ConBtrainta: {HOLDS'(AG.\[\[G I -- 2\],{joe} u Gl,tl)}Figure 4: Augmented rgraph explaining (lift(foot(pi-ano)),{joe},tl)MERGING AUGMENTED RGRAPHSAs discussed thus far, the construction algorithm pro-duces an explanation for how an activity r is relatedto a goal A.
However, to properly model collaboration,one must also take into account he context of previ-ously discussed activities.
Thus, we now address howthe algorithm explains an activity r in this context.Because Gi and Gj are collaborating, it is appropri-ate for Gj to assume that any activity mentioned byGi is part of doing A (or at least that Gi believes thatit is).
If this is not the case, then Gi must explicitlyindicate that to Gj (Grosz and Sidner, 1990).
Giventhis assumption, Gj's task is to produce a coherent ex-planation, based upon her recipes, for how all of theactivities that she and Gi discuss are related to A.We incorporate this model of Gj's task into the algo-rithm by requiring that each recipe have at most onecorresponding augmented rgraph, and implement thisrestriction as follows: whenever an rgraph node corre-sponding to a particular act-type in a recipe is created,the construction algorithm checks to see whether thereis Mready another node (in a previously constructedrgraph) corresponding to that act-type.
If so, the al-gorithm tries to merge the augmented rgraph currentlyunder construction with the previous one, in part bymerging these two nodes.
In so doing, it combines theinformation contained in the separate xplanations.The processing of utterance (4) in the sample di-Mogue illustrates this procedure.
The activity de-rived from utterance (4) is r2=(lifl(keyboard(piano)),{pare}, tl).
The initial augmented rgraph portion cre-ated in explaining this activity is shown in Figure5.
Node N5 of the rgraph corresponds to the act-type simult(lifl(foot(piano)),lift(keyboard(piano))) andincludes information derived from r2.
But the rgraph(in Figure 4) previously constructed in explaining r lalso includes a node, N2, corresponding to this act-type(and containing information derived from rl) .
Ratherthan continuing with an independent explanation forr2, the algorithm attempts to combine the information5The function cover_interval takes a set of time intervalsas an argument and returns a time interval spanning theset (Balkanski, 1990).from the two activities by merging their augmentedrgraphs.Rgraph:NS:K((lift(foot(piano)),G2,t 1),(lift(keyboard(piano)),{pam} ,tl))I c2N4:(lift (keyboard(piano)),{pam} ,tl)Constraints:{}Figure 5: Augmented rgraph partially explaining(lift(keyboard(piano)) ,{pain} ,tl)Two augmented rgraphs are merged by first merg-ing their rgraphs at the two nodes corresponding tothe same act-type (e.g.
nodes N5 and N2), and thenmerging their constraints.
Two nodes are merged byunifying the activities they represent.
If this unifica-tion is successful, then the two sets of constraints aremerged by taking their union and adding to the result-ing set the equality constraints expressing the bindingsused in the unification.
If this new set of constraintsis satisfiable, then the bindings used in the unificationare applied to the remainder of the two rgraphs.
Oth-erwise, the algorithm fails: the activities represented inthe two rgraphs are not compatible.
In this case, be-cause the recipe corresponding to the rgraphs does notprovide an explanation for all of the activities discussedby the agents, it is removed from further consideration.The augmented rgraph resulting from merging the twoaugmented rgraphs in Figures 4 and Figure 5 is shownin Figure 6.Rgraph:N3:{lift (piano),{joe,pam} ,tl)T GENN2:K((lift (foot (piano)),{joe} ,tl),(lift(keyboard(piano)),{pam} ,tl))/ ?1 \ ?2N1 :(lift(foot(piano)),{joe},t 1) N4:(lift(keyboard(piano)),{pam},t 1 )Constraints: {HOLDS'(AG.IlG I = 2\],{joe} Lt Gl,t l) ,  Gl={pam}}Figure 6: Augmented rgraph resulting from mergingthe augmented rgraphs in Figures 4 and 5IMPLEMENTATIONAn implementation of the algorithm is currently un-derway using the constraint logic programming lan-guage, CLP(7~) (Jaffar and Lassez, 1987; Jaffar andMiehaylov, 1987).
Syntactically, this language is verysimilar to Prolog, except that constraints on real-valued variables may be intermixed with literals inrules and goals.
Semantically, CLP(~) is a generaliza-tion of Prolog in which unifiability is replaced by solv-ability of constraints.
For example, in Prolog, the pred-icate X < 3 fails if X is uninstantiated.
In CLP(~),however, X < 3 is a constraint, which is solvable ifthere exists a substitution for X that makes it true.Because many of the augmented rgraph constraintsare relations over real-valued variables (e.g.
the timeof one activity must be before the time of another),CLP(T~) is a very appealing language in which to im-plement he augmented rgraph construction process.The algorithm for implementing this process in a logicprogramming language, however, differs markedly fromthe intuitive algorithm described in this paper.RGRAPHS AND CONSTRAINTS VS. EGRAPHSKautz (1987) presented several graph-based algorithmsderived from his formal model of plan recognition.
InKautz's algorithms, an explanation for an observationis represented in the form of an explanation graph oregraph.
Although the term rgraph was chosen to par-allel Kautz's terminology, the two representations andalgorithms are quite different in scope.Two capabilities that an algorithm for plan recog-nition in collaborative discourse must possess are theabilities to represent joint actions of multiple agentsand to reason about hypothetical ctions.
In addition,such an algorithm may, and for efficiency should, ex-ploit assumptions of the communicative situation.
Theaugmented rgraph representation and algorithm meetthese qualifications, whereas the egraph representationand algorithms do not.The underlying action representation used in r-graphs is capable of representing complex relationsamong acts, including simultaneity and sequentiality.In addition, relations among the agents and times ofacts may also be expressed.
The action representationused in egraphs is, like that in STRIPS, simple step de-composition.
Though it is possible to represent simul-taneous or sequential actions, the egraph representa-tion can only model such actions if they are performedby the same agent.
This restriction is in keeping withKautz's model of keyhole recognition, but is insuffi-cient for modelling intended recognition in multiagentsettings.Rgraphs are only a part of our representation.
Aug-mented rgraphs also include constraints on the activ-ities represented in the rgraph.
Kautz does not havesuch an extended representation.
Although he usesconstraints to guide egraph construction, because theyare not part of his representation, his algorithm canonly check their satisfaction locally.
In contrast, by col-lecting together all of the constraints introduced by thedifferent relations or constructors in a recipe, we canexploit interactions among them to determine unsat-isfiability earlier than an algorithm which checks con-straints locally.
Kautz's algorithm checks each event'sconstraints independently and hence cannot determinesatisfiability until a constraint is ground; it cannot, forexample, reason that one constraint makes another un-satisfiable.Because agents involved in collaboration dedicate asignificant portion of their time to discussing the ac-tions they need to perform, an algorithm for rood-37elling plan recognition in discourse must model rea-soning about hypothetical and only partially specifiedactivities.
Because the augmented rgraph representa-tion allows variables to stand for agents and times inboth activities and constraints, it meets this criteria.Kautz's algorithm, however, models reasoning aboutactual event occurrences.
Consequently, the egraphrepresentation does not include a means of referring toindefinite specifications.In modelling collaboration, unless explicitly indi-cated otherwise, it is appropriate to assume that allacts are related.
In the augmented rgraph constructionalgorithm, we exploit this by restricting the reasoningdone by the algorithm to recipes for A, and by combin-ing explanations for acts as soon as possible.
Kautz'salgorithm, however, because it is based on a model ofkeyhole recognition, does not and cannot make use ofthis assumption.
Upon each observation, an indepen-dent egraph must be created explaining all possibleuses of the observed action.
Various hypotheses arethen drawn and maintained as to how the action mightbe related to other observed actions.CONCLUSIONS ~ FUTURE DIRECTIONSTo achieve their joint goal, collaborating agents musthave mutual beliefs about the types of actions they willperform to achieve that goal, the relations among thoseactions, the agents who will perform the actions, andthe time interval over which they will do so.
In thispaper, we have presented a representation, augmentedrgraphs, modelling this information and have providedan algorithm for constructing and reasoning with it.The steps of the construction algorithm parallel thereasoning that an agent performs in determining therelevance of an activity.
The algorithm does not re-quire that activities be discussed in a fixed order andallows for reasoning about hypothetical or only par-tially specified activities.Future work includes: (1) adding other types of con-straints (e.g.
restrictions on the parameters of actions)to the representation; (2) using the augmented rgraphrepresentation i  identifying, on the basis of unsatisfi-able constraints, particular discrepancies in the agents'beliefs; (3) identifying information conveyed in Gi'sutterances as to how he believes two acts are related(Balkanski, 1991) and incorporating that informationinto our model of Gj's reasoning.ACKNOWLEDGMENTSI would like to thank Cecile Balkanski, Barbara Grosz,Stuart Shieber, and Candy Sidner for many helpfuldiscussions and comments on the research presentedin this paper.REFERENCESAllen, J. and Perrault, C. 1980.
Analyzing intentionin utterances.
Artificial Intelligence, 15(3):143-178.Balkanski, C. T. 1990.
Modelling act-type relationsin collaborative activity.
Technical Report TR-23-90, Harvard University.Balkanski, C. T. 1991.
Logical form of complex sen-tences in task-oriented ialogues.
In Proceedings ofthe 29th Annual Meeting of the ACL, Student Ses-sion, Berkeley, CA.Fikes, R. E. and Nilsson, N. J.
1971.
STRIPS: A newapproach to the application of theorem proving toproblem solving.
Artificial Intelligence, 2:189-208.Goldman, A. I.
1970.
A Theory Of Human Action.Princeton University Press.Grosz, B. and Sidner, C. 1990.
Plans for discourse.In Cohen, P., Morgan, J., and Pollack, M., editors,Intentions in Communication.
MIT Press.Jaffar, J. and Lassez, J.-L. 1987.
Constraint logicprogramming.
In Proceedings of the 14th ACMSymposium on the Principles of Programming Lan-guages, pages 111-119, Munich.Jaffar, J. and Michaylov, S. 1987.
Methodology andimplementation f a CLP system.
In Proceedings ofthe .~th International Conference on Logic Program-ming, pages 196-218, Melbourne.
MIT Press.Kautz, H. A.
1987.
A Formal Theory of Plan Recog-nition.
PhD thesis, University of Rochester.Kautz, H. A.
1990.
A circumscriptive theory ofplan recognition.
In Cohen, P., Morgan, J., andPollack, M., editors, Intentions in Communication.MIT Press.Lochbaum, K. E., Grosz, B. J., and Sidner, C. L.1990.
Models of plans to support communica-tion: An initial report.
In Proceedings of AAAI-90,Boston, MA.Lochbaum, K. E. 1991.
Plan recognition in collabo-rative discourse.
Technical report, Harvard Univer-sity.Pollack, M. E. June 1986.
A model of plan inferencethat distinguishes between the beliefs of actors andobservers.
In Proceedings of the 2~th Annual Meetingof the ACL.Pollack, M. E. 1990.
Plans as complex mental at-titudes.
In Cohen, P., Morgan, J., and Pollack, M.,editors, Intentions in Communication.
MIT Press.Sidner, C. and Israel, D. J.
1981.
Recognizing in-tended meaning and speakers' plans.
In Proceedingsof IJCAI-81.38
