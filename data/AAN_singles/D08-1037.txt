Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 353?362,Honolulu, October 2008. c?2008 Association for Computational LinguisticsTransliteration as Constrained OptimizationDan Goldwasser Dan RothDepartment of Computer ScienceUniversity of IllinoisUrbana, IL 61801{goldwas1,danr}@uiuc.eduAbstractThis paper introduces a new method for iden-tifying named-entity (NE) transliterations inbilingual corpora.
Recent works have shownthe advantage of discriminative approaches totransliteration: given two strings (ws, wt) inthe source and target language, a classifier istrained to determine if wt is the translitera-tion of ws.
This paper shows that the translit-eration problem can be formulated as a con-strained optimization problem and thus takeinto account contextual dependencies and con-straints among character bi-grams in the twostrings.
We further explore several methodsfor learning the objective function of the opti-mization problem and show the advantage oflearning it discriminately.
Our experimentsshow that the new framework results in over50% improvement in translating English NEsto Hebrew.1 IntroductionNamed entity (NE) transliteration is the process oftranscribing a NE from a source language to sometarget language based on phonetic similarity be-tween the entities.
Identifying transliteration pairsis an important component in many linguistic appli-cations which require identifying out-of-vocabularywords, such as machine translation and multilingualinformation retrieval (Klementiev and Roth, 2006b;Hermjakob et al, 2008).It may appear at first glance that identifying thephonetic correlation between names based on anorthographic analysis is a simple, straight-forwardFigure 1: Named entities transliteration pairs in Englishand Hebrew and the character level mapping between thetwo names.
The Hebrew names can be romanized as ee-ta-l-ya and a-yatask; however in many cases a consistent deter-ministic mapping between characters does not ex-ist; rather, the mapping depends on the context thecharacters appear in and on transliteration conven-tions which may change across domains.
Figure 1exhibits two examples of NE transliterations in En-glish and Hebrew, with the correct mapping acrossthe two scripts.
Although the two Hebrew namesshare a common prefix1, this prefix can be mappedinto a single English character or into two differ-ent characters depending on the context it appearsin.
Similarly, depending on the context it appears in,the English character a can be mapped into differentcharacters or to an ?empty?
character.1In all our example the Hebrew script is shown left-to-rightto simplify the visualization of the transliteration mapping.353In recent years, as it became clear that solutionsthat are based on linguistics rules are not satisfac-tory, machine learning approaches have been de-veloped to address this problem.
The common ap-proach adopted is therefore to view this problemas a classification problem (Klementiev and Roth,2006a; Tao et al, 2006) and train a discriminativeclassifier.
That is, given two strings, one in thesource and the other in the target language, extractpairwise features, and train a classifier that deter-mines if one is a transliteration of the other.
Sev-eral papers have followed up on this basic approachand focused on semi-supervised approaches to thisproblem or on extracting better features for the dis-criminative classifier (Klementiev and Roth, 2006b;Bergsma and Kondrak, 2007; Goldwasser and Roth,2008).
While it has been clear that the relevancy ofpairwise features is context sensitive and that thereare contextual constraints among them, the hope wasthat a discriminative approach will be sufficient toaccount for those by weighing features appropri-ately.
This has been shown to be difficult for lan-guage pairs which are very different, such as Englishand Hebrew (Goldwasser and Roth, 2008).In this paper, we address these difficulties byproposing to view the transliteration decision as aglobally phrased constrained optimization problem.We formalize it as an optimization problem overa set of local pairwise features ?
character n-grammatches across the two string ?
and subject to legit-imacy constraints.We use a discriminatively trained classifier as away to learn the objective function for the globalconstrained optimization problem.
Our technicalapproach follows a large body of work developedover the last few years, following (Roth and Yih,2004) that has formalized global decisions problemsin NLP as constrained optimization problems andsolved these optimization problems using IntegerLinear Programming (ILP) or other methods (Pun-yakanok et al, 2005; Barzilay and Lapata, 2006;Clarke and Lapata, ; Marciniak and Strube, 2005).We investigate several ways to train our objectivefunction, which is represented as a dot product be-tween a set of features chosen to represent a pair(ws, wt), and a vector of initial weights.
Our firstbaseline makes use of all features extracted from apair, along with a simple counting method to deter-mine initial weights.
We then use a method simi-lar to (Klementiev and Roth, 2006a; Goldwasser andRoth, 2008) in order to discriminatively train a betterweight vector for the objective function.Our key contribution is that we use a constrainedoptimization approach also to determine a better fea-ture representation for a given pair.
(Bergsma andKondrak, 2007) attempted a related approach to re-stricting the set of features representing a transliter-ation candidate.
However, rather than directly align-ing the two strings as done there, we exploit the ex-pressiveness of the ILP formulation and constraintsto generate a better representation of a pair.
Thisis the representation we then use to discriminativelylearn a better weight vector for the objective func-tion used in our final model.Our experiments focus on Hebrew-Englishtransliteration, which were shown to be very dif-ficult in a previous work (Goldwasser and Roth,2008).
We show very significant improvements overexisting work with the same data set, proving theadvantage of viewing the transliteration decision asa global inference problem.
Furthermore, we showthe importance of using a discriminatively trainedobjective function.The rest of the paper is organized as follows.
Themain algorithmic contribution of this paper is de-scribed in Sec.
2.
Our experimental study is de-scribes in Sec.
3 and Sec.
4 concludes.2 Using inference for transliterationIn this section we present our transliteration decisionframework, which is based on solving a constrainedoptimization problem with an objective function thatis discriminatively learned.
Our framework consistsof three key elements:1.
Decision Model When presented with a NEin the source language ws and a set of candi-dates {wt}k1 in the target language, the decisionmodel ranks the candidate pairs (ws, wt) andselects the ?best?
candidate pair.
This is framedas an optimization problemw?t = argmaxi{w ?
F (ws, wit)}, (1)where F is a feature vector representation ofthe pair (ws, wit) and w is a vector of weightsassigned to each feature.3542.
Representation A pair s = (ws, wt) of sourceand target NEs is represented as a vector of fea-tures, each of which is a pair of character n-grams, from ws and wt, resp.
Starting with abaseline representation introduced in (Klemen-tiev and Roth, 2006a), denoted here AF (s),we refine this representation to take into ac-count dependencies among the individual n-gram pairs.
This refinement process is framedas a constrained optimization problem:F (s)?
= argmaxF?AF {w ?AF (s)}, (2)subject to a set C of linear constraints.
HereAF is the initial representation (All?Features),w is a vector of weights assigned to each fea-ture and C is a set of constraints accounting forinterdependencies among features.3.
Weight Vector Each pairwise n-gram feature isassociated with a weight; this weigh vector isused in both optimization formulations above.The weight vector is determined by consideringthe whole training corpus.
The initial weightvector is obtained generatively, by counting therelative occurrence of substring pairs in posi-tive examples.
The representation is refined bydiscriminatively training a classifier to maxi-mize transliteration performance on the train-ing data.
In doing that, each example is rep-resented using the feature vector representationdescribed above.The three key operations described above are be-ing used in several stages, with different parameters(weight vectors and representations) as describedin Alg.
1.
In each stage a different element is re-fined.
The input to this process is a training corpusTr=(DS ,DT ) consisting of NE transliteration pairss = (ws, wt), where ws, wt are NEs in the sourceand target language, respectively.
Each such sam-ple point is initially represented as a feature vectorAF (s) (for All?Features), where features are pairsof substrings from the two words (following (Kle-mentiev and Roth, 2006a)).Given the set of feature vectors generated by ap-plying AF to Tr, we assign initial weights W tothe features ((1) in Alg.
1).
These weights formthe initial objective function used to construct a newfeature based representation, Informative?Features,IFW (s) ((2) in Alg.
1).
Specifically, for an instances, IFW (s) is the solution of the optimization prob-lem in Eq.
2, with W as the weight vector, AF (s)as the representation, and a set of constraints ensur-ing the ?legitimacy?
of the selected set of features(Sec.
2.2.1).Input: Training Corpora Tr=(DS ,DT )Output: Transliteration model M1.
Initial Representation and WeightsFor each sample s ?
Tr, use AF to generate afeature vector{(fs, ft)1, (fs, ft)2, .
.
.
, (fs, ft)n} ?
{0, 1}n.Define W :f ?R s.t.
foreach feature f =(fs, ft)W (f) = #(fs,ft)#(fs) ?#(fs,ft)#(ft)2.
Inferring Informative Representation (W )Modify the initial representation by solving thefollowing constrained optimization problem:IFW (s)?
= argmaxIF (s)?
(AF (s))W ?AF (s),subject to constraints C.3.
Discriminative TrainingTrain a discriminative model on Tr, using{IF (s)}s?Tr.Let WD be the new weight vector obtained bydiscriminative training.4.
Inferring Informative Representation (WD)Modify the initial representation by solving thefollowing constrained optimization problem.
Thistime, the objective function is determined by thediscriminatively trained weight vector WD.IFWD (s)?
= argmaxIF (s)?
(AF (s))WD ?AF (s),subject to constraints C.5.
Decision ModelGiven a word ws and a list of candidatesw1t , w2t , .
.
.
wkt , the chosen transliteration is wt?
,determined by:t?
= argmaxi{WD ?
IFWD ((ws, wit))}Algorithm 1: Transliteration Framework.The new feature extraction operator IFW (s) isnow used to construct a new representation of thetraining corpus.
With this representation, we traindiscriminately a new weight vector WD.
Thisweight vector, now defines a new objective functionfor the optimization problem in Eq.
2; WD is theweight vector and AF (s) the representation.
We de-355note by IFWD(s) the solution of this optimizationproblem for an instance s.Given a representation and a weight vector, theoptimization problem in Eq.
1 is used to find thetransliteration of ws.
Our best decision model makesuse of Eq.
1 using WD as the feature vector andIFWD(s) as the feature representation of s.The rest of this section provides details on the op-erations and how we use them in different stages.2.1 Initial Representation and WeightsThe feature space we consider consists of n po-tential features, each feature f = (fs, ft) repre-sents a pairing of character level n-grams, wherefs ?
{Source-Language ?
empty-string } and ft ?
{Target-Language ?
empty-string}.
A given sample(ws, wt) consisting of a pair of NEs is representedas a features vector s ?
{0, 1}n. We say that a fea-ture f i is active if f i = 1 and that s1 ?
s2, ??
{f i}{f i= 1 in s1} ?
{f i}{f i=1 in s2}.
We representthe active features corresponding to a pair as a bipar-tite graph G = (V,E), in which each vertex v ?
Veither represents the empty string, a single characteror a bi-gram.
V S , V T denote the vertices represent-ing source and target language n-grams respectively.Each of these sets is composed of two disjoint sub-sets: VS = V SU ?
V SB , VT = V TU ?
V TB consistingof vertices representing the uni-gram and bi-gramstrings.
Given a vertex v, degree(v, V ?
)denotes thedegree of v in a subgraph of G, consisting only ofV ?
?
V ; index(v) is the index of the substring rep-resented by v in the original string.Edges in the bipartite graph represent active fea-tures.
The only deviation is that the vertex represent-ing the empty string can be connected to any other(non-empty) vertex.Our initial feature extraction method follows theone presented in (Klementiev and Roth, 2006a),in which the feature space consists of n-gram pairsfrom the two languages.
Given a pair, each wordis decomposed into a set of character substrings ofup to a given length (including the empty string).Features are generated by pairing substrings fromthe two sets whose relative positions in the originalwords differ by k or less places, or formally:E = {e = (vi, vj) | (vi ?
VS ?
vj ?
VT ) ?
(index(vj) + k ?
index(vi) ?
index(vj)?
k) ?Figure 2: All possible unigram and bigram pairs gener-ated by the AF operator.
The Hebrew name can be ro-manized as lo-n-do-n(vi 6= vempty?string ?
vj 6= vempty?string)}.In our experiments we used k=1 which tested em-pirically, achieved the best performance.Figure 2 exhibits the active features in the exam-ple using the graph representation.
We refer to thisfeature extraction method as All-Features (AF ),and define it formally as an operator AF : s ?
{(fs, ft)i} that maps a sample point s = (ws, wt)to a set of active features.The initial sample representation generates fea-tures by coupling substrings from the two termswithout considering the dependencies between thepossible consistent combinations.
Ideally, givena positive sample, it is desirable that paired sub-strings would encode phonetic similarity or a dis-tinctive context in which the two substrings corre-late.
However, AF simply pairs substrings from thetwo words, resulting in a noisy representation of thesample point.
Given enough positive samples, weassume that features appearing with distinctive fre-quency will encode the desired relation.
We use thisobservation, and construct a weight vector, associ-ating each feature with a positive number indicatingits relative occurrence frequency in the training datarepresentation formed by AF .
This weight is com-puted as follows:Definition 1 (Initial Feature Weights Vector) LetW :f ?R s.t.
for each feature f={fs, ft},W (f) = #(fs, ft)#(fs) ?#(fs, ft)#(ft) ,where #(fs, ft) is the number of occurrences of thatfeature in the positive sample set, and #(fL), L ={s, t} is the number of occurrences of an individualsubstring, in any of the features extracted from pos-itive samples in the training set.356These weights transform every example into aweighted graph, where each edge is associated by Wwith the weight assigned to the feature it represents.As we empirically tested, this initialization assignshigh weights to features that preserve the phoneticcorrelation between the two languages.
The top partof figure 5 presents several examples of weights as-signed by W to features composed of different En-glish and Hebrew substrings combinations.
It can beobserved that combination which are phoneticallysimilar are associated with a higher weight.
How-ever, as it turns out, transliteration mappings do notconsist of ?clean?
and consistent mappings of pho-netically similar substrings.
In the following sectionwe explain how to use these weights to generate amore compact representation of samples.2.2 Inferring Informative RepresentationsIn this section we suggest a new feature extractionmethod for determining the representation of a givenword pair.
We use the strength of the active featurescomputed above, along with legitimacy constraintson mappings between source and target strings tofind an optimal set of consistent active features thatrepresents a pair.
This problem can be naturally en-coded as a linear optimization problem, which seeksto maximize a linear objective function determinedby W , over a set of variables representing the ac-tive features selection, subject to a set of linear con-straints representing the dependencies between se-lections.
We follow the formulation given by (Rothand Yih, 2004), and define it as an Integer LinearProgramming (ILP) optimization problem, in whicheach integer variable a(j,k), defined over {0, 1}, rep-resents whether a feature pairing an n-gram j ?
Swith an n-gram k ?
T , is active.
Although using ILPis in general NP-hard, it has been used efficiently inmany natural language (see section 1).
Our experi-ence as well has been that this process is very effi-cient due to the sparsity of the constraints used.2.2.1 Constraining Feature DependenciesTo limit the selection of active features in eachsample we require that each element in the decom-position of ws into bi-grams should be paired withan element in wt, and the vice-versa.
We restrictthe possible pairs by allowing only a single n-gramto be matched to any other n-gram, with one excep-tion - we allow every bi-gram to be mapped into anempty string.
Viewed as a bipartite graph, we alloweach node (with the exception of the empty string)to have only one connected edge.
These constraints,given the right objective function, should enforce analignment of bi-grams according to phonetic simi-larity; for example, the word pairs described in Fig-ure 1, depicts a character level alignment betweenthe words, where in some cases a bi-gram is mappedinto a single character and in other cases single char-acters are mapped to each other, based on phoneticsimilarity encoded by the two scripts.
However, im-posing these constraints over the entire set of candi-date features would be too restrictive; it is unlikelythat one can consistently represent a single ?correct?phonetic mapping.
We wish to represent both thecharacter level and bi-gram mapping between namesas both represent informative features on the corre-spondence between the names over the two scripts.To allow this, we decompose the problem into twodisjoint sets of constraints imposing 1-1 mappings,one over the set of single character substrings andthe other over the bi-gram substrings.
Given the bi-partite graph generated by AF, we impose the fol-lowing constraints:Definition 2 (Transliteration Constraints) Let Cbe the set of constraints, consisting of the followingpredicates:?v ?
V S , degree(v,V S?V TU )?1 ?
?v ?
V S , degree(v,V S?V TB )?1 ?
?v ?
V T , degree(v,V T?V SU )?1 ?
?v ?
V T , degree(v,V T?V SB )?1For example, Figure 2 shows the graph of all pos-sible candidates produced by AF .
In Figure 3, thegraph is decomposed into two graphs, each depict-ing possible matches between the character leveluni-gram or bi-gram substrings.
the ILP constraintsensure that in each graph, every node (with the ex-ception of the empty string) has a degree of one .Figure 4 gives the results of the ILP process ?
aunified graph in which every node has only a singleedge associated with it.Definition 3 (Informative Feature Extraction (IF))We define the Informative-Features(IF ) featureextraction operator, IF : s ?
{(fs, ft)i} as thesolution to the ILP problem in Eq.
2.
Namely,357Figure 3: Find informative features by solving an ILPproblem.
Dependencies between matching decisions aremodeled by allowing every node to be connected to a sin-gle edge (except the node representing the empty-string).Figure 4: The result of applying the IF operator by solv-ing an ILP problem, represented as a pruned graph.IF (s)?
= argmaxIF (s)?
(AF (s))w ?AF (s),subject to constraints C.We will use this operator with w = W , definedabove, and denote it IFW , and also use it with adifferent weight vector, trained discriminatively, asdescribed next.2.3 Discriminative TrainingUsing the IFW operator, we generate a better rep-resentation of the training data, which is now usedto train a discriminative model.
We use a linearclassifier trained with a regularized average percep-tron update rule (Grove and Roth, 2001) as imple-mented in SNoW, (Roth, 1998).
This learning al-gorithm provides a simple and general linear clas-sifier that has been demonstrated to work well inother NLP classification tasks, e.g.
(Punyakanoket al, 2005), and allows us to incorporate extensionssuch as strength of features naturally into the train-ing algorithm.
We augment each sample in the train-Figure 5: Several examples of weights assigned to fea-tures generated by coupling English and Hebrew sub-strings.
Top figure: initial weights.
Bottom figure: Dis-criminatively learned weights.
The Hebrew characters,ordered left to right, can be romanized as y,z,t,shing data with feature weights; given a sample, thelearner is presented with a real-valued feature vec-tor instead of a binary vector.
This can be viewedas providing a better starting point for the learner,which improves the learning rate (Golding and Roth,1999; Ng and Jordan, 2001).The weight vector learned by the discriminativetraining is denoted WD.
Given the new weight vec-tor, we can define a new feature extraction opera-tor, that we get by applying the objective function inEq.
2 with WD instead of W .
Given a sample s, thefeature representation generated by this new infor-mation extraction operator is denoted IFWD(s).
Thekey difference between W and WD is that the latterwas trained over a corpora containing both negativeand positive examples, and as a result WD containsnegative weights.
To increase the impact of trainingwe multiplied the negative weights by 2.Figure 5 presents some examples of the benefitof discriminately learning the objective function; theweighted edges in the top figure show the values as-signed to features by W , while the bottom figureshows the weights assigned by WD.
In all cases,phonetically similar characters were assigned higherscores by WD, and character pairs not phoneticallysimilar were typically assigned negative weights.
Itis also interesting to note a special phenomena oc-curring in English-Hebrew transliterations.
The En-glish vowels will be paired to almost any Hebrewcharacter when generating pairs using AF , sincevowels in most cases are omitted in Hebrew, thereis no distinctive context in which English vowelsappear.
We can see for example, in the top graph358presented in Figure 5 an edge matching a vowel toa Hebrew character with a high weight, the bottomgraph showing the results of the discriminative train-ing process show that this edge is associated with azero weight score.2.4 Decision ModelsThis section defines several transliteration decisionmodels given a word ws and a list of candidatesw1t , w2t , .
.
.
wkt .
The models are used to identify thecorrect transliteration pair from the set of candidates{si = (ws, wit)}i=1...k.In all cases, the decision is formulated as in Eq.
1,where different models differ by the representationsand weight vectors used.Decision Model 1 Ranking the transliteration can-didates is done by evaluatings?
= argmaxi W ?AF (si),which selects the transliteration pair which maxi-mizes the objective function based on the genera-tively computed weight vector.Decision Model 2 Ranking the transliteration can-didates is done by evaluating:s?
= argmaxi WD ?AF (si)).This decision model is essentially equivalent to thetransliteration models used in (Klementiev andRoth, 2006a; Goldwasser and Roth, 2008), in whicha linear transliteration model was trained using a fea-ture extraction method equivalent to AF.Decision Model 3 Ranking the transliteration can-didates is done by evaluating:s?
= argmaxi W ?
IFW (si),which maximizes the objective function with thegeneratively computed weight vector and the infor-mative feature representation derived based on it.Decision Model 4 Ranking the transliteration can-didates is done by evaluating:s?
= argmaxi WD ?
IFW (si)),which conceptually resembles the transliterationmodel presented in (Bergsma and Kondrak, 2007),in that a discriminative classifier was trained andused over a pruned feature set.Decision Model 5 Ranking the transliteration can-didates is done by evaluating:s?
= argmaxi WD ?
IFWD(si),which maximize the objective function with the dis-criminately derived weight vector and the informa-tive features inferred based on it.
This decisionmodel is the only model that incorporates discrim-inative weights as part of the feature extraction pro-cess; WD is used as the objective function usedwhen inferring IFWD .3 EvaluationWe evaluated our approach over a corpus of 300English-Hebrew transliteration pairs, and used an-other 250 different samples for training the models.We constructed the test set by pairing each Englishname with all Hebrew names in the corpus.
The sys-tem was evaluated on its ability to correctly iden-tify the 300 transliteration pairs out of all the pos-sible transliteration candidates.
We measured per-formance using the Mean Reciprocal Rank (MRR)measure.
This measure, originally introduced inthe field of information retrieval, is used to evaluatesystems that rank several options according to theirprobability of correctness.
MRR is a natural mea-sure in our settings and has been used previouslyfor evaluating transliteration systems, for exampleby (Tao et al, 2006).Given a set Q of queries and their respectiveresponses ranked according to the system?s confi-dence, we denote the rank of the correct responseto a query qi ?
Q as rank(qi).
MRR is then de-fined as the average of the multiplicative inverse ofthe rank of the correct answer, that is:MRR = 1|Q|?i=1...|Q|1rank(qi) .In our experiments we solved an ILP problem forevery transliteration candidate pairs, and computedMRR with respect to the confidence of our decisionmodel across the candidates.
Although this requiredsolving thousands of ILP instances, it posed no com-putational burden as these instances typically con-tained a small number of variables and constraints.The entire test set is solved in less than 20 minutes359using the publicly available GLPK package (http://www.gnu.org/software/glpk/ ).The performance of the different models is sum-marized in table 1, these results are based on a train-ing set of 250 samples used to train the discrimi-native transliteration models and also to constructthe initial weight vector W .
Figure 6 shows perfor-mance over different number of training examples.Our evaluation is concerns with the core transliter-ation and decision models presented here and doesnot consider any data set optimizations that were in-troduced in previous works, which we view as or-thogonal additions, hence the difference with the re-sults published in (Goldwasser and Roth, 2008).The results clearly show that our final model,model 5, outperform other models.
Interestingly,model 1, a simplistic model, significantly outper-forms the discriminative model presented in (Kle-mentiev and Roth, 2006b).
We believe that this isdue to two reasons.
It shows that discriminativetraining over the representation obtained using AFis not efficient; moreover, this phenomenon is ac-centuated given that we train over a very small dataset, which favors generative estimation of weights.This is also clear when comparing the performanceof model 1 to model 4, which shows that learningover the representation obtained using constrainedoptimization (IF) results in a very significant perfor-mance improvement.The improvement of using IFW is not automatic.Model 3, which uses IFW , and model 1, which usesAF, converge to nearly the same result.
Both thesemodels use generative weights to make the translit-eration decision, and this highlights the importanceof discriminative training.
Both model 4 and model5 use discriminatively trained weights and signifi-cantly outperform model 3.
These results indicatethat using constraint optimization to generate the ex-amples?
representation in itself may not help; the ob-jective function used in this inference has a signifi-cant role in improved performance.The benefit of discriminatively training the objec-tive function becomes even clearer when compar-ing the performance of model 5 to that of model 4,which uses the original weight vector when inferringthe sample representation.It can be assumed that this algorithm can bene-fit from further iterations ?
generating a new featureDecision Model MRRBaseline model, used in (KR?06,GR?08)Model 2 0.51Models presented in this paperModel 1 0.713Model 3 0.715Model 4 0.832Model 5 0.848Table 1: Results of the different transliteration models,trained using 250 samples.
To facilitate readability (Kle-mentiev and Roth, 2006b; Goldwasser and Roth, 2008)are referenced as KR?06 and GR?08 respectively.Figure 6: Results of the different constraint optimizationtransliteration models.
Performance is compared relativeto the number of samples used for training.representations, training a model on it, and using theresulting model as a new objective function.
How-ever, it turns out that after a single round, improvedweights due to additional training do not change thefeature representation; the inference process doesnot yield a different outcome.3.1 Normalized Objective FunctionFormulating the transliteration decision as an op-timization problem also allows us to naturally en-code other considerations into our objective func-tion.
in this case we give preference to matchingshort words.
We encode this preference as a normal-ization factor for the objective function.
When eval-uating on pair (ws, wt), we divide the weight vectorlength of the shorter word; our decision model nowbecomes:Decision Model 6 (Model 5 - LengthNormalization)360Decision Model MRRModel 5 0.848Model 5 - LN 0.894Table 2: Results of using model 5 with and without anormalized objective function.
Both models were trainedusing 250 samples.
The LN suffix in the model?s nameindicate that the objective function used length normal-ization.Figure 7: Results of using model 5 with and without anormalized objective function.
Performance is comparedrelative to the number of samples used for training.Ranking the transliteration candidates is done byevaluating:s?
= argmaxi WD ?
IFWD(si)/min(|ws|, |wt|)As described in table 2 and figure 7, usinglength normalization significantly improves the re-sults.
This can be attributed to the fact that typicallyHebrew names are shorter and therefore every pair(ws, wt) considered by our model will be effecteddifferently by this normalization factor.4 DiscussionWe introduced a new approach for identifying NEtransliteration, viewing the transliteration decisionas a global inference problem.
We explored sev-eral methods for combining discriminative learningin a global constraint optimization framework andshowed that discriminatively learning the objectivefunction improves performance significantly.From an algorithmic perspective, our key contri-bution is the introduction of a new method, in whichlearning and inference are used in an integrated way.We use learning to generate an objective function forthe inference process; use the inference process togenerate a better representation for the learning pro-cess, and iterate these stages.From the transliteration perspective, our key con-tribution is in deriving and showing the significanceof a good representation for a pair of NEs.
Ourrepresentation captures both phonetic similarity anddistinctive occurrence patterns across character levelmatchings of the two input strings, while enforcingthe constraints induced by the interdependencies ofthe individual matchings.
As we show, this represen-tation serves to improve the ability of a discrimina-tive learning algorithm to weigh features appropri-ately and results in significantly better transliterationmodels.
This representation can be viewed as a com-promise between models that do not consider depen-dencies between local decisions and those that try toalign the two strings.
Achieving this compromise isone of the advantages of the flexibility allowed bythe constrained optimization framework we use.
Weplan to investigate using more constraints within thisframework, such as soft constraints which can pe-nalize unlikely local decisions while not completelyeliminating the entire solution.AcknowledgmentsWe wish to thank Alex Klementiev and the anony-mous reviewers for their insightful comments.
Thiswork is partly supported by NSF grant SoD-HCER-0613885 and DARPA funding under the BootstrapLearning Program.ReferencesR.
Barzilay and M. Lapata.
2006.
Aggregation via SetPartitioning for Natural Language Generation.
In Pro-ceedings of HLT/NAACL, pages 359?366, New YorkCity, USA, June.
Association for Computational Lin-guistics.S.
Bergsma and G. Kondrak.
2007.
Alignment-baseddiscriminative string similarity.
In Proceedings of the45th Annual Meeting of the Association of Computa-tional Linguistics, pages 656?663, Prague, Czech Re-public, June.
Association for Computational Linguis-tics.J.
Clarke and M. Lapata.
Modeling compression withdiscourse constraints.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-361guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 1?11.A.
R. Golding and D. Roth.
1999.
A Winnow basedapproach to context-sensitive spelling correction.
Ma-chine Learning, 34(1-3):107?130.D.
Goldwasser and D. Roth.
2008.
Active sample selec-tion for named entity transliteration.
In Proceedingsof ACL-08: HLT, Short Papers, Columbus, OH, USA,Jun.
Association for Computational Linguistics.A.
Grove and D. Roth.
2001.
Linear concepts and hiddenvariables.
Machine Learning, 42(1/2):123?141.Ulf Hermjakob, Kevin Knight, and Hal Daume?
III.
2008.Name translation in statistical machine translation -learning when to transliterate.
In Proceedings of ACL-08: HLT, pages 389?397, Columbus, Ohio, June.
As-sociation for Computational Linguistics.A.
Klementiev and D. Roth.
2006a.
Named entitytransliteration and discovery from multilingual com-parable corpora.
In Proc.
of the Annual Meeting of theNorth American Association of Computational Lin-guistics (NAACL), pages 82?88, June.A.
Klementiev and D. Roth.
2006b.
Weakly supervisednamed entity transliteration and discovery from mul-tilingual comparable corpora.
In Proc.
of the AnnualMeeting of the ACL, July.T.
Marciniak and M. Strube.
2005.
Beyond the Pipeline:Discrete Optimization in NLP.
In Proceedings of theNinth CoNLL, pages 136?143, Ann Arbor, Michigan,June.
Association for Computational Linguistics.A.
Y. Ng and M. I. Jordan.
2001.
On discriminative vs.generative classifiers: A comparison of logistic regres-sion and na?
?ve bayes.
In Neural Information Process-ing Systems, pages 841?848.V.
Punyakanok, D. Roth, and W. Yih.
2005.
The neces-sity of syntactic parsing for semantic role labeling.
InProc.
of the International Joint Conference on Artifi-cial Intelligence (IJCAI), pages 1117?1123.D.
Roth and W. Yih.
2004.
A linear programming formu-lation for global inference in natural language tasks.
InHwee Tou Ng and Ellen Riloff, editors, Proc.
of theAnnual Conference on Computational Natural Lan-guage Learning (CoNLL), pages 1?8.
Association forComputational Linguistics.D.
Roth.
1998.
Learning to resolve natural language am-biguities: A unified approach.
In Proceedings of theNational Conference on Artificial Intelligence (AAAI),pages 806?813.Tao Tao, Su-Youn Yoon, Andrew Fister, Richard Sproat,and ChengXiang Zhai.
2006.
Unsupervised namedentity transliteration using temporal and phonetic cor-relation.
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Processing,pages 250?257, Sydney, Australia, July.
Associationfor Computational Linguistics.362
