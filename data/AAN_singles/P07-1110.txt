Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 872?879,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsBenefits of the ?Massively Parallel Rosetta Stone?
:Cross-Language Information Retrieval with over 30 LanguagesPeter A. ChewSandia National LaboratoriesP.
O.
Box 5800, MS 1012Albuquerque, NM 87185-1012, USApchew@sandia.govAhmed AbdelaliNew Mexico State UniversityP.O.
Box 30002, Mail Stop 3CRLLas Cruces, NM 88003-8001, USAahmed@crl.nmsu.eduAbstractIn this paper, we describe our experiencesin extending a standard cross-language in-formation retrieval (CLIR) approachwhich uses parallel aligned corpora andLatent Semantic Indexing.
Most, if notall, previous work which follows this ap-proach has focused on bilingual retrieval;two examples involve the use of French-English or English-Greek parallel cor-pora.
Our extension to the approach is?massively parallel?
in two senses, onelinguistic and the other computational.First, we make use of a parallel alignedcorpus consisting of almost 50 paralleltranslations in over 30 distinct languages,each in over 30,000 documents.
Given thesize of this dataset, a ?massively parallel?approach was also necessitated in themore usual computational sense.
Our re-sults indicate that, far from adding morenoise, more linguistic parallelism is betterwhen it comes to cross-language retrievalprecision, in addition to the self-evidentbenefit that CLIR can be performed onmore languages.1 IntroductionApproaches to cross-language information retrieval(CLIR) fall generally into one of two types, orsome combination thereof: the ?query translation?approach or the ?parallel corpus?
approach.
Thefirst of these, which is perhaps more common, in-volves translation of the query into the target lan-guage, for example using machine translation oron-line dictionaries.
The second makes use of par-allel aligned corpora as training sets.
One approachwhich uses parallel corpora does this in conjunc-tion with Latent Semantic Indexing (LSI) (Lan-dauer and Littman 1990, Young 1994).
Accordingto Berry et al (1994:21), the use of LSI with paral-lel corpora can be just as effective as the querytranslation approach, and avoids some of the draw-backs of the latter, discussed in Nie et al (1999).Generally, research in CLIR has not attemptedto use very many languages at a time (see for ex-ample Nie and Jin 2002).
With query translation(although that is not the approach that Nie and Jintake), this is perhaps understandable, as for eachnew language, a new translation algorithm must beincluded.
The effort involved in extending querytranslation to multiple languages, therefore, islikely to be in proportion to the number of lan-guages.With parallel corpora, the reason that researchhas been limited to only a few languages at a time?
and usually just two at a time, as in the LSI workcited above ?
is more likely to be rooted in thewidespread perception that good parallel corporaare difficult to obtain (see for example Asker2004).
However, recent work (Resnik et al 1999,Chew et al 2006) has challenged this idea.One advantage of a ?massively parallel?
multi-lingual corpus is perhaps self-evident: within theLSI framework, the more languages are mappedinto the single conceptual space, the fewer restric-tions there are on which languages documents canbe selected from for cross-language retrieval.However, several questions were raised for us as872we contemplated the use of a massively parallelcorpus.
Would the addition of languages not usedin testing create ?noise?
for a given language pair,reducing the precision of CLIR?
Could partiallyparallel corpora be used?
Our work appears toshow both that more languages are generally bene-ficial, and even incomplete parallel corpora can beused.
In the remainder of this paper, we provideevidence for this claim.
The paper is organized asfollows: section 2 describes the work we undertookto build the parallel corpus and its characteristics.In section 3, we outline the mechanics behind the'Rosetta-Stone' type method we use for cross-language comparison.
In section 4, we present anddiscuss the results of the various tests we per-formed.
Finally, we conclude on our findings insection 5.2 The massively parallel corpusFollowing Chew et al (2006), our parallel corpuswas built up from translations of the Bible whichare freely available on the World Wide Web.
Al-though reliable comparable statistics are hard tofind, it appears to be generally agreed that the Bi-ble is the world?s most widely translated book,with complete translations in 426 languages andpartial translations in 2,403 as of December 31,2005 (Bible Society, 2006).
Great care is takenover the translations, and they are alignable bychapter and verse.
According to Resnik et al(1999), the Bible?s coverage of modern vocabularymay be as high as 85%.
The vast majority of thetranslations we used came from the ?Unbound Bi-ble?
website (Biola University, 2005-2006); fromthis website, the text of a large number of differenttranslations of the Bible can ?
most importantly forour purposes ?
be downloaded in a tab-delimitedformat convenient for loading into a database andthen indexing by chapter and verse in order to en-sure ?parallelism?
in the corpus.
The number oftranslations available at the website is apparentlybeing added to, based on our observations access-ing the website on a number of different occasions.The languages we have included in our multilin-gual parallel corpus include those both ancient andmodern, and are as follows:Language No.
oftranslationsUsed intestsAfrikaans 1 12+Albanian 1 27+Arabic 1 AllChinese (Simplified) 1 44+Chinese (Traditional) 1 44+Croatian 1 27+Czech 2 12+Danish 1 12+Dutch 1 12+English 7 AllFinnish 3 27+French 2 AllGerman 4 8,27+Greek (New Testament) 2 46+Hebrew (Old Testament) 1 46+Hebrew (Modern) 1 6,12+Hungarian 1 6+Italian 2 8,27+Japanese* 1 9+Korean 1 27+Latin 1 8,9,28+Maori 1 7,8,9,27+Norwegian 1 27+Polish* 1 27+Portuguese 1 27+Russian 1 AllSpanish 2 AllSwedish 1 27+Tagalog 1 27+Thai 1 27+Vietnamese 1 27,44+Table 1.
Languages1The languages above represent many of the ma-jor language groups: Austronesian (Maori andTagalog); Altaic (Japanese and Korean); Sino-Tibetan (Chinese); Semitic (Arabic and Hebrew);Finno-Ugric (Finnish and Hungarian); Austro-Asiatic (Vietnamese); Tai-Kadai (Thai); and Indo-European (the remaining languages).
The two NewTestament Greek versions are the Byzan-tine/Majority Text (2000), and the parsed versionof the same text, in which we treated distinct mor-phological elements (such as roots or inflectionalendings) as distinct terms.
Overall, the list includes1 Translations in languages marked with an asterisk abovewere obtained from websites other than the ?Unbound Bible?website.
?Used in tests?
indicates in which tests in Table 2below the language was used as training data, and hence theorder of addition of languages to the training data.87347 versions in 31 distinct languages (assumingwithout further discussion here that each entry inthe list represents a distinct language).We aligned the translations by verse, and, sincethere are some differences in versification betweentranslations (for example, the Hebrew Old Testa-ment includes the headings for the Psalms as sepa-rate verses, unlike most translations), we spentsome time cleaning the data to ensure the align-ment was as good as possible, given available re-sources and our knowledge of the languages.
(Evenafter this process, the alignment was not perfect,and differences in how well the various transla-tions were aligned may account for some of thevariability in the outcome of our experiments, de-pending on which translations were used.)
The endresult was that our parallel corpus consisted of31,226 ?mini-documents?
?
the total number of textchunks2 after the cleaning process, aligned acrossall 47 versions.
The two New Testament Greekversions, and the one Old Testament Hebrew ver-sion, were exceptions because these are only par-tially complete; the former have text in only 7,953of the verses, and the latter has text in 23,266 ofthe verses.
For some versions, a few of the versetranslations are incomplete where a particular versehas been skipped in translation; this also explainsthe fact that the number of Hebrew and Greek textchunks together do not add up to 31,226.
However,the number of such verses is negligible in compari-son to the total.3 FrameworkThe framework we used was the standard LSIframework described in Berry et al (1994).
Eachaligned mini-document from the parallel corpusconsists of the combination of text from all the 31languages.
A document-by-term matrix is formedin which each cell represents a weighted frequencyof a particular term t in a particular document k.We used a standard log-entropy weighting scheme,where the weighted frequency W is given by:W = log2 (F) ?
(1 + Ht / log2 (N))where F is the raw frequency of t in k, Ht is thestandard ?p log p?
measure of the entropy of theterm across all documents, and N is the number of2 The text chunks generally had the same boundaries as theverses in the original text.documents in the corpus.
The last term in the ex-pression above, log2 (N), is the maximum entropythat any term can have in the corpus, and therefore(1 + Ht / log2 (N)) is 1 for the most distinctiveterms in the corpus, 0 for those which are least dis-tinctive.The sparse document-by-term matrix is sub-jected to singular value decomposition (SVD), anda reduced non-sparse matrix is output.
Generally,we used the output corresponding to the top 300singular values in our experiments.
When we had asmaller number of languages in the mix, it waspossible to use SVDPACK (Berry et al 1996),which is an open-source non-parallel algorithm forcomputing the SVD, but for larger problems (in-volving more than a couple of dozen parallel ver-sions), use of a parallel algorithm (in a librarycalled Trilinos) was necessitated.
(This was run ona Linux cluster consisting of 4,096 dual CPU com-pute nodes, running on Dell PowerEdge 1850 1UServers with 6GB of RAM.
)In order to test the precision versus recall of ourframework, we used translations of the 114 surasof the Qu?ran into five languages, Arabic, English,French, Russian and Spanish.
The number ofdocuments used for testing is fairly small, but largeenough to give comparative results for our pur-poses which are still highly statistically significant.The test set was split into each of the 10 possiblelanguage-pair combinations: Arabic-English, Ara-bic-French, English-French, and so on.For each language pair and test, 228 distinct?queries?
were submitted ?
each query consistingof one of the 228 sura ?documents?.
If the highest-ranking document in the other language of the pairwas in fact the query?s translation, then the resultwas deemed ?correct?.
To assess the aggregate per-formance of the framework, we used two meas-ures: average precision at 0 (the maximumprecision at any level of recall), and average preci-sion at 1 document (1 if the ?correct?
documentranked highest, zero otherwise).
The second meas-ure is a stricter one, but we generally found thatthere is a high rate of correlation between the twomeasures anyway.4 Results and DiscussionThe following tables show the results of our tests.First, we present in Table 2 the overall summary,874with averages across all language pairs used intesting.Average precision No.
ofparallelversionsAt 0 at 1 doc.2 0.706064 0.5714913 0.747620 0.6492694 0.617615 0.5318735 0.744951 0.6561406 0.811666 0.7326027 0.827246 0.7530708 0.824501 0.7500009 0.823430 0.74605312 0.827761 0.75263227 0.825577 0.75131628 0.823137 0.74780744 0.839346 0.76578946 0.839319 0.76666747 0.842936 0.774561Table 2.
Summary results for all language pairsFrom the above, the following should be clear:as more parallel translations are added to the index,the average precision rises considerably at first,and then begins to level off after about the seventhparallel translation.
The results will of course varyaccording to which combination of translations isselected for the index.
The number of such combi-nations is generally very large: for example, with47 translations available, there are 47!
/ (40!
7!
), or62,891,499, possible ways of selecting 7 transla-tions.
Thus, for any particular number of parallelversions, we had to use some judgement in whichparallel versions to select, since there was no wayto achieve anything like exhaustive coverage of thepossibilities.Further, with more than 7 parallel translations,there is certainly no justification for saying thatadding more translations or languages increases the?noise?
for languages in the test set, since beyond 7the average precision remains fairly level.
If any-thing, in fact, the precision still appears to riseslightly.
For example, the average precision at 1document rises by more than 0.75 percentagepoints between 46 and 47 versions.
Given that ineach of these experiments, we are measuring preci-sion 228 times per language pair, and therefore2,280 times in total, this small rise in precision issignificant (p ?
0.034).
Interestingly, the 47th ver-sion to be added was parsed New TestamentGreek.
It appears, therefore, that the parsing helpedin particular; we also have evidence from otherexperiments (not presented here) that overall preci-sion is generally improved for all languages whenArabic wordforms are replaced by their respectivecitation forms (the bare root, or stem) ?
also a formof morphological parsing.
Ancient Greek, likeArabic, is morphologically highly complex, so itwould be understandable that parsing (or stem-ming) would help when parsing of either languageis used in training.One other point needs to be made here: the threeversions added after the 44th version were the threeincomplete versions (the two Greek versions coverjust the New Testament, while Ancient Hebrewcovers just the Old Testament).
The above-mentioned increase in precision which resultedfrom the addition of these three versions is clearevidence that even in the case where a parallel cor-pus is defective for some language(s), includingthose languages can still result in the twofold bene-fit that (1) those languages are now available foranalysis, and (2) precision is maintained or in-creased for the remaining languages.Finally, precision at 1 document, the stricter ofthe two measures, is by definition less than orequal to precision at 0.
This taken into account, itis also interesting that the gap between the twomeasures seems to narrow as more parallel transla-tions and parsing are added, as Figure 1 shows.For certain applications where it is importantthat the translation is ranked first, not just highly,among all retrieved documents, there is thus a par-ticular benefit in using a ?massively parallel?aligned corpus.0%2%4%6%8%10%12%14%16%2 3 4 5 6 7 8 9 12 27 28 44 46 47Number of parallel translationsDifferentialinpercentagepointsFigure 1.
Differential between precision at 0 andprecision at 1 document, by number of languages875Now we move on to look at more detailed re-sults by language pair.
Figure 2 below breaksdown the results for precision at 1 document bylanguage pair.
In all tests, the two languages ineach pair were (naturally) always included in thelanguages used for training.
There is more volatil-ity in the results by language pair than there is inthe overall results, shown again at the right of thegraph, which should come as no surprise since theaverages are based on samples a tenth of the size.Generally, however, the pattern is the same forparticular language pairs as it is overall; the moreparallel versions are used in training, the better theaverage precision.There are some more detailed observationswhich should also be made from Figure 2.
First,the average precision clearly varies quite widelybetween language pairs.
The language pairs withthe best average precision are those in which twoof English, French and Spanish are present.
Of thefive languages used for testing, these three clustertogether genetically, since all three are Western(Germanic or Romance) Indo-European languages.Moreover, these are the three languages of the fivewhich are written in the Roman alphabet.00.10.20.30.40.50.60.70.80.91Spanish-ArabicArabic-FrenchRussian-ArabicEnglish-ArabicSpanish-RussianRussian-FrenchEnglish-RussianEnglish-SpanishSpanish-FrenchEnglish-FrenchOVERALLLanguage PairPrecisionat1document2 3 4 5 6 7 8 9 12 27 28 44 46 47Number of languagesFigure 2.
Chart of precision at 1 doc.
by language pair and number of parallel training versionsHowever, we believe the explanation for thepoorer results for language pairs involving eitherArabic, Russian, or both, can be pinned down tosomething more specific.
We have already par-tially alluded to the obvious difference betweenArabic and Russian on the one hand, and English,French and Spanish on the other: that Arabic andRussian are highly morphologically rich, whileEnglish, French and Spanish are generally analyticlanguages.
This has a clear effect on the statisticsfor the languages in question, as can be seen inTable 3, which is based on selected translations ofthe Bible for each of the languages in question.Translation Types TokensEnglish (King James) 12,335 789,744Spanish (Reina Valera 1909) 28,456 704,004Russian (Synodal 1876) 47,226 560,524Arabic (Smith Van Dyke) 55,300 440,435French (Darby) 20,428 812,947Table 3.
Statistics for Bible translations in 5 lan-guages used in test data876Assuming that the respective translations arefaithful (and we have no reason to believe other-wise), and based on the statistics in Table 3, itshould be the case that Arabic contains the most?information?
per term (in the information theoreticsense), followed by Russian, Spanish, English andFrench.3 Again, this corresponds to our intuitionthat much information is contained in Arabic pat-terns and Russian inflectional morphemes, whichin English, French and Spanish would be containedin separate terms (for example, prepositions).Without additional pre-processing, however,LSI cannot deal adequately with root-pattern orinflectional morphology.
Moreover, it is clearly aweakness of LSI, or at least the standard log-entropy weighting scheme as applied within thisframework, that it makes no adjustment for differ-ences in information content per word betweenlanguages.
Even though we can assume near-equivalency of information content between thedifferent translations above, according to the stan-dard log-entropy weighting scheme there are largedifferences between the total entropy of particularparallel documents; in general, languages such asEnglish are overweighted while those such as Ara-bic are underweighted.Now that this issue is in perspective, we shoulddraw attention to another detail in Figure 2.
Notethat the language pairs which benefited most fromthe addition of Ancient Greek and Hebrew into thetraining data were those which included Russian,and Russian-Arabic saw the greatest increase inprecision.
Recall also that the 47th version to beadded was the parsed Greek, so that essentiallyeach Greek morpheme is represented by a distinctterm.
From Figure 2, it seems clear that the inclu-sion of parsed Greek in particular boosted the pre-cision for Russian (this is most visible at the right-hand side of the set of columns for Russian-Arabicand English-Russian).
There are, after all, notablesimilarities between modern Russian and AncientGreek morphology (for example, the nominal casesystem).
Essentially, the parsed Greek acts as a?clue?
to LSI in associating inflected forms in Rus-3 To clarify the meaning of ?term?
here: for all languages ex-cept Chinese, text is tokenized in our framework into termsusing regular expressions; each non-word character (such aspunctuation or white space) is assumed to mark the boundaryof a word.
For Chinese, we made the simplifying assumptionthat each character represented a separate term.sian with preposition/non-inflected combinationsin other languages.
These results seem to be furtherconfirmation of the notion that parsing just one ofthe languages in the mix helps overall; the greatestboost is for those languages with morphology re-lated to that of the parsed language, but there is atleast a maintenance, and perhaps a small boost, inthe precision for unrelated languages too.Finally, we turn to look at some effects of theparticular languages selected for training.
Includedin the results above, there were three separate testsrun in which there were 6 training versions.
In allthree, Arabic, English, French, Russian and Span-ish were included.
The only factor we varied in thethree tests was the sixth version.
In the three tests,we used Modern Hebrew (a Semitic language,along with Arabic), Hungarian (a Uralic language,not closely related to any of the other five lan-guages), and a second English version respectively.The results of these tests are shown in Figure 3,with figures for the test in which only 5 versionswere included for comparative purposes.From these results, it is apparent first of all thatit was generally beneficial to add a sixth version,regardless of whether the version added was Eng-lish, Hebrew or Hungarian.
This is consistent withthe results reported elsewhere in this paper.
Sec-ond, it is also apparent that the greatest benefitoverall was had by using an additional English ver-sion, rather than using Hebrew or Hungarian.Moreover, perhaps surprisingly, the use of Hebrewin training ?
even though Hebrew is related toArabic ?
was of less benefit to Arabic than eitherHungarian or an additional English version.
It ap-pears that the use of multiple versions in the samelanguage is beneficial because it enables LSI tomake use of the many different instantiations in theexpression of a concept in a single language, andthat this effect can be greater than the effect whichobtains from using heterogeneous languages, evenif there is a genetic relationship to existing lan-guages.87700.10.20.30.40.50.60.70.80.91Russian-ArabicSpanish-ArabicArabic-FrenchEnglish-ArabicSpanish-RussianRussian-FrenchEnglish-RussianEnglish-SpanishSpanish-FrenchEnglish-FrenchOVERALLLanguage pairPrecisionat1doc.Arabic, English, French, Russian, Spanish Arabic, English, French, Hebrew, Russian, SpanishArabic, English, French, Hungarian, Russian, Spanish Arabic, English x 2, French, Russian, SpanishFigure 3.
Precision at 1 document for 6 training versions, with results of using different mixes of lan-guages for trainingFigure 3 may also shed some additional light onone other detail from Figure 2: a perceptible jumpin precision between 28 and 44 training versionsfor Arabic-English and Arabic-French.
It should bementioned that among the 16 additional versionswere five English versions (American StandardVersion, Basic English Bible, Darby, Webster?sBible, and Young?s Literal Translation), and oneFrench version (Louis Segond 1910).
It seems thatFigure 2 and Figure 3 both point to the same thing:that the use of parallel versions or translations in asingle language can be particularly beneficial tooverall precision within the LSI framework ?
evento a greater extent than the use of parallel transla-tions in different languages.5 ConclusionIn this paper, we have shown how ?massive paral-lelism?
in an aligned corpus can be used to im-prove the results of cross-language informationretrieval.
Apart from the obvious advantage (theability to automate the processing of a greater vari-ety of linguistic data within a single framework),we have shown that including more parallel trans-lations in training improves the precision of CLIRacross the board.
This is true whether the addi-tional translations are in the language of anothertranslation already within the training set, whetherthey are in a related language, or whether they arein an unrelated language; although this is not to saythat these choices do not lead to (generally minor)variations in the results.
The improvement in preci-sion also appears to hold whether the additionaltranslations are complete or incomplete, and it ap-pears that morphological pre-processing helps, notjust for the languages pre-processed, but againacross the board.Our work also offers further evidence that thesupply of useful pre-existing parallel corpora is notperhaps as scarce as it is sometimes claimed to be.Compilation of the 47-version parallel corpus weused was not very time-consuming, especially ifthe time taken to clean the data is not taken into878account, and all the textual material we used ispublicly available on the World Wide Web.While the experiments we performed were onnon-standard test collections (primarily becausethe Qu?ran was easy to obtain in multiple lan-guages), it seems that there is no reason to believeour general observation ?
that more parallelism inthe training data is beneficial for cross-languageretrieval ?
would not hold for text from other do-mains.
Whether the genre of text used as trainingdata affects the absolute rate of retrieval precisionfor text of a different genre (e.g.
news articles,shopping websites) is a separate question, and onewe intend to address more fully in future work.In summary, it appears that we are able toachieve the results we do partly because of the in-herent properties of LSI.
In essence, when the datafrom more and more parallel translations are sub-jected to SVD, the LSI ?concepts?
become moreand more reinforced.
The resulting trend for preci-sion to increase, despite ?blips?
for individual lan-guages, can be seen for all languages.
To put it inmore prosaic terms, the more different ways thesame things are said in, the more understandablethey become ?
including in cross-language infor-mation retrieval.AcknowledgementSandia is a multiprogram laboratory operated bySandia Corporation, a Lockheed Martin Company,for the United States Department of Energy?s Na-tional Nuclear Security Administration under con-tract DE-AC04-94AL85000.ReferencesLars Asker.
2004.
Building Resources: Experiencesfrom Amharic Cross Language Information Re-trieval.
Paper presented at Cross-Language Informa-tion Retrieval and Evaluation: Workshop of theCross-Language Evaluation Forum, CLEF 2004.Ricardo Baeza-Yates and Berthier Ribeiro-Neto.
1999.Modern Information Retrieval.
New York: ACMPress.Michael Berry, Theresa Do, Gavin O?Brien, VijayKrishna, and Sowmimi Varadhan.
1996.SVDPACKC (Version 1.0) User?s Guide.
Knoxville,TN: University of Tennessee.Bible Society.
2006.
A Statistical Summary of Lan-guages with the Scriptures.
Accessed athttp://www.biblesociety.org/latestnews/latest341-slr2005stats.html on Jan. 5, 2007.Biola University.
2005-2006.
The Unbound Bible.
Ac-cessed at http://www.unboundbible.com/ on Jan. 5,2007.Peter Chew, Stephen Verzi, Travis Bauer and JonathanMcClain.
2006.
Evaluation of the Bible as a Re-source for Cross-Language Information Retrieval.
InProceedings of the Workshop on Multilingual Lan-guage Resources and Interoperability, 68-74.
Syd-ney: Association for Computational Linguistics.Susan Dumais.
1991.
Improving the Retrieval of Infor-mation from External Sources.
Behavior ResearchMethods, Instruments, and Computers 23(2):229-236.Julio Gonzalo.
2001.
Language Resources in Cross-Language Text Retrieval: a CLEF Perspective.
InCarol Peters (ed.).
Cross-Language Information Re-trieval and Evaluation: Workshop of the Cross-Language Evaluation Forum, CLEF 2000: 36-47.Berlin: Springer-Verlag.Dragos Munteanu and Daniel Marcu.
2006.
ImprovingMachine Translation Performance by ExploitingNon-Parallel Corpora.
Computational Linguistics31(4):477-504.Jian-Yun Nie and Fuman Jin.
2002.
A Multilingual Ap-proach to Multilingual Information Retrieval.
Pro-ceedings of the Cross-Language Evaluation Forum,101-110.
Berlin: Springer-Verlag.Jian-Yun Nie, Michel Simard, Pierre Isabelle, and Rich-ard Durand.
1999.
Cross-Language Retrieval basedon Parallel Texts and Automatic Mining of ParallelTexts from the Web.
Proceedings of the 22nd AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, 74-81,August 15-19, 1999, Berkeley, CA.Carol Peters (ed.).
2001.
Cross-Language InformationRetrieval and Evaluation: Workshop of the Cross-Language Evaluation Forum, CLEF 2000.
Berlin:Springer-Verlag.Recherche appliqu?e en linguistique informatique(RALI).
2006.
Corpus align?
bilingue anglais-fran?ais.
Accessed at http://rali.iro.umontreal.ca/ onFebruary 22, 2006.Philip Resnik, Mari Broman Olsen, and Mona Diab.1999.
The Bible as a Parallel Corpus: Annotating the"Book of 2000 Tongues".
Computers and the Hu-manities, 33: 129-153.879
