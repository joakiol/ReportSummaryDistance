Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 591?599,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsLinguistic Steganography Using Automatically Generated ParaphrasesChing-Yun ChangUniversity of CambridgeComputer LaboratoryChing-Yun.Chang@cl.cam.ac.ukStephen ClarkUniversity of CambridgeComputer LaboratoryStephen.Clark@cl.cam.ac.ukAbstractThis paper describes a method for checkingthe acceptability of paraphrases in context.We use the Google n-gram data and a CCGparser to certify the paraphrasing grammati-cality and fluency.
We collect a corpus of hu-man judgements to evaluate our system.
Theultimate goal of our work is to integrate textparaphrasing into a Linguistic Steganographysystem, by using paraphrases to hide informa-tion in a cover text.
We propose automati-cally generated paraphrases as a new and use-ful source of transformations for LinguisticSteganography, and show that our method forchecking paraphrases is effective at maintain-ing a high level of imperceptibility, which iscrucial for effective steganography.1 IntroductionSteganography is concerned with hiding informa-tion in some cover medium, by manipulating prop-erties of the medium in such a way that the hiddeninformation is not easily detectable by an observer(Fridrich, 2009).
The covert communication is suchthat the very act of communication is to be kept se-cret from outside observers.
A related area is Wa-termarking, in which modifications are made to acover medium in order to identify it, for example forthe purposes of copyright.
Here the changes maybe known to an observer, and the task is to makethe changes in such a way that the watermark cannoteasily be removed.There is a large literature on image steganogra-phy and watermarking, in which images are mod-ified to encode a hidden message or watermark.Image stegosystems exploit the redundancy in animage representation together with limitations ofthe human visual system.
For example, a stan-dard image stegosystem uses the least-significant-bit(LSB) substitution technique.
Since the differencebetween 11111111 and 11111110 in the value forred/green/blue intensity is likely to be undetectableby the human eye, the LSB can be used to hide infor-mation other than colour, without being perceptableby a human observer.1A key question for any steganography system isthe choice of cover medium.
Given the ubiqui-tous nature of natural languages and electronic text,text is an obvious medium to consider.
However,the literature on Linguistic Steganography, in whichlinguistic properties of a text are modified to hideinformation, is small compared with other media(Bergmair, 2007).
The likely reason is that it iseasier to make changes to images and other non-linguistic media which are undetectable by an ob-server.
Language has the property that even smalllocal changes to a text, e.g.
replacing a word by aword with similar meaning, may result in text whichis anomalous at the document level, or anomalouswith respect to the state of the world.
Hence find-ing linguistic transformations which can be appliedreliably and often is a challenging problem for Lin-guistic Steganography.In this paper we focus on steganography ratherthan watermarking, since we are interested in the re-quirement that any changes to a text be impercep-tible to an observer.
Figure 1 shows the LinguisticSteganography framework.
First, some secret mes-sage, represented as a sequence of bits, is hidden in a1The observer may also be a computer program, designed todetect statistical anomalies in the image representation whichmay indicate the presence of hidden information.591Figure 1: The Linguistic Steganography frameworkcover text using the embedding algorithm, resultingin the stego text.2 Next, the stego text passes the hu-man observer, who is happy for innocuous messagesto pass between the sender and receiver, but will ex-amine the text for any suspicious looking content.Once the stego text reaches the receiver, the hiddenmessage is recovered using the extracting algorithm.There is a fundamental tradeoff in all steganogra-phy systems, and one that is especially apparent inthe Linguistic Steganography framework: the trade-off between imperceptibility and payload.
Payloadis the number of bits that can be encoded per unitof cover medium, for example per sentence in thelinguistic case.
The tradeoff arises because any at-tempt to hide additional information in the covertext, through the application of more linguistic trans-formations, is likely to increase the chances of rais-ing the suspicions of the observer, by introducinganomalies into the text.The key elements of a Linguistic Steganographysystem are the linguistic transformation and the em-bedding method.
In this paper we focus on the lin-guistic transformation.
Section 5 describes a pos-sible embedding method for our framework, andfor readers unfamiliar with linguistic steganographyshows how linguistic transformations can be used toembed hidden bits in text.Section 2 describes some of the previous transfor-mations used in Linguistic Steganography.
Note thatwe are concerned with transformations which are2The message may have been encrypted initially also, as inthe figure, but this is not important in this paper; the key pointis that the hidden message is a sequence of bits.linguistic in nature, rather than dealing with superfi-cial properties of the text, e.g.
the amount of whitespace between words (Por et al, 2008).
Our pro-posed method is based on the automatically acquiredparaphrase dictionary described in Callison-Burch(2008), in which the application of paraphrases fromthe dictionary encodes secret bits.
One advantageof the dictionary is that it has wide coverage, be-ing automatically extracted; however, a disadvan-tage is that it contains many paraphrases which areeither inappropriate, or only appropriate in certaincontexts.
Since we require any changes to be im-perceptible to a human observer, it is crucial to oursystem that any uses of paraphrasing are grammati-cal and retain the meaning of the original cover text.In order to test the grammaticality and meaningpreserving nature of a paraphrase, we employ a sim-ple technique based on checking whether the con-texts containing the paraphrase are in the Google n-gram corpus.
This technique is based on the sim-ple hypothesis that, if the paraphrase in context hasbeen used many times before on the web, then it isan appropriate use.
We test our n-gram-based sys-tem against some human judgements of the gram-maticality of paraphrases in context.
We find thatusing larger contexts leads to a high precision sys-tem (100% when using 5-grams), but at the cost ofa reduced recall.
This precision-recall tradeoff re-flects the inherent tradeoff between imperceptibilityand payload in a Linguistic Steganography system.We also experiment with a CCG parser (Clark andCurran, 2007), requiring that the contexts surround-ing the original phrase and paraphrase are assigned592the same CCG lexical categories by the parser.
Thismethod increases the precision of the Google n-gramcheck with a slight loss in recall.A contribution of this paper is to advertise the Lin-guistic Steganography problem to the ACL commu-nity.
The requirement that any linguistic transfor-mation maintain the grammaticality and meaning ofthe cover text makes the problem a strong test forexisting NLP technology.2 Previous Work2.1 Synonym SubstitutionThe simplest and most straightforward subliminalmodification of text is to substitute selected wordswith their synonyms.
The first lexical substitu-tion method was proposed by Chapman and Davida(1997).
Later works, such as Atallah et al (2001a),Bolshakov (2004), Taskiran et al (2006) and Top-kara et al (2006b), further made use of part-of-speech taggers and electronic dictionaries, such asWordNet and VerbNet, to increase the robustness ofthe method.
Taskiran et al (2006) attempt to usecontext by prioritizing the alternatives using an n-gram language model; that is, rather than randomlychoose an option from the synonym set, the systemrelies on the language model to select the synonym.Topkara et al (2005) and Topkara et al (2006b) re-port an average embedding capacity of 0.67 bits persentence for the synonym substitution method.2.2 Syntactic TransformationsThe second and the most widely used manipulationsfor linguistic steganography are syntactic transfor-mations.
This method is based on the fact that a sen-tence can be transformed into more than one seman-tically equivalent syntactic structure, using trans-formations such as passivization, topicalization andclefting.
The first syntactic transformation method ispresented by Atallah et al (2001a).
Later, Atallah etal.
(2001b) embedded information in the tree struc-ture of the text by adjusting the structural proper-ties of intermediate representations of sentences.
Inother words, instead of performing lexical substitu-tion directly to the text, the secret message is embed-ded into syntactic parse trees of the sentences.
Liuet al (2005), Meral et al (2007), Murphy (2001),Murphy and Vogel (2007) and Topkara et al (2006a)all belong to the syntactic transformation category.After embedding the secret message, modified deepstructure forms are converted into the surface struc-ture format via language generation tools.
Atallah etal.
(2001b) and Topkara et al (2006a) attained theembedding capacity of 0.5 bits per sentence with thesyntactic transformation method.2.3 Semantic TransformationsThe semantic transformation method is the most so-phisticated approach for linguistic steganography,and perhaps impractical given the current state-of-the-art for NLP technology.
It requires some sophis-ticated tools and knowledge to model natural lan-guage semantics.
Atallah et al (2002) used seman-tic transformations and embed information in text-meaning representation (TMR) trees of the text byeither pruning, grafting or substituting the tree struc-ture with information available from ontological se-mantic resources.
Vybornova and Macq (2007)aimed to embed information by exploiting the lin-guistic phenomenon of presupposition, with the ideathat some presuppositional information can be re-moved without changing the meaning of a sentence.3 Data Resources3.1 Paraphrase DictionaryThe cover text used for our experiments consists ofnewspaper sentences from Section 00 of the PennTreebank (Marcus et al, 1993).
Hence we requirepossible paraphrases for phrases that occur in Sec-tion 00.
The paraphrase dictionary that we usewas generated for us by Chris Callison-Burch, usingthe technique described in Callison-Burch (2008),which exploits a parallel corpus and methods devel-oped for statistical machine translation.Table 1 gives summary statistics of the paraphrasedictionary and its coverage on Section 00 of thePenn Treebank.
The length of the extracted n-gramphrases ranges from unigrams to five-grams.
Thecoverage figure gives the percentage of sentenceswhich have at least one phrase in the dictionary.
Thecoverage is important for us because it determinesthe payload capacity of the embedding method de-scribed in Section 5.Table 2 lists some examples 5-gram phrases andparaphrases from the dictionary.
The format of the593N-gram Number of Coverage onphrases section 00 (%)Unigrams 5,856 99Bigrams 13,473 96Trigrams 6,574 65Four-grams 1,604 40Five-grams 295 10Table 1: Statistics for the paraphrase dictionaryOriginal phrase Paraphrasesthe end of this year later this yearthe end of the yearyear enda number of people some of my colleaguesdifferencesthe European peoples partythe PPE groupTable 2: Example phrases and paraphrases from the dic-tionarydictionary is a mapping from phrases to sets of pos-sible paraphrases.
Each paraphrase also has a prob-ability, based on a statistical machine translationmodel, but we do not use that feature here.
The ex-amples show that, while some of the paraphrases areof a high quality, some are not.
For example, dif-ferences is unlikely to be a suitable paraphrase fora number of people in any context.
Moreover, thereare some ?phrase, paraphrase?
pairs which are onlysuitable in particular contexts.
For example, yearend is an unsuitable paraphrase for the end of thisyear in the sentence The chart compares the goldprice at the end of last year with the end of this year.Barzilay and McKeown (2001) also note that the ap-plicability of paraphrases is strongly influenced bycontext.
Section 4 describes our method for deter-mining if a paraphrase is suitable in a given context.3.2 Google N-gram DataThe Google n-gram data was collected by GoogleResearch for statistical language modelling, and hasbeen used for many tasks such as lexical disam-biguation (Bergsma et al, 2009), and contains En-glish n-grams and their observed frequency counts,for counts of at least 40.
The striking feature ofFigure 2: The web-based annotation systemthe n-gram corpus is the large number of n-gramsand the size of the counts, since the counts were ex-tracted from over 1 trillion word tokens of Englishtext on publicly accessible Web pages collected inJanuary 2006.
For example, the 5-gram phrase thepart that you were has a count of 103.
The com-pressed data is around 24 GB on disk.3.3 Paraphrase Judgement CorpusThe focus of the paper is to develop an automaticsystem for checking the grammaticality and flu-ency of paraphrases in context.
In order to evaluatethe system, we collected some human judgements,based on 70 sentences from Section 00 of the PennTreebank.
For each sentence, we took every phrasein the sentence which is in the dictionary, and foreach paraphrase of that phrase, replaced the phrasewith the paraphrase to create an instance.
This pro-cedure resulted in 500 cases of paraphrases in con-text.Each case was then evaluated by a human judge,using a web-based annotation system that we devel-oped.
The judges were asked to judge each case ontwo dimensions: a) whether the paraphrase is gram-matical in context; and b) whether the paraphraseretains the meaning of the original phrase given thecontext.
Figure 2 gives a screen shot of the annota-tion system.50 of the 500 cases were judged by two judges, inorder to obtain some indication of whether the gram-maticality and meaning retention judgements are vi-able; the rest were judged by one annotator.
(The500 instances were randomly distributed among 10native speakers, each being given 55 instances tojudge.)
For the meaning retention check, only 34 outof the 50 cases received the same judgement.
Onereason for the low agreement may be that, for 11 ofthe 16 disagreement cases, we were asking annota-594tors to judge the meaning retention of paraphraseswhich had been judged to be ungrammatical in con-text, which may not be a meaningful task.
For thegrammatical check, 42 out of the 50 cases receivedthe same judgement, a much higher level of agree-ment.Since the meaning retention judgements were un-reliable, we used only the grammatical judgementsto evaluate our system.
Hence we are interestedin evaluating whether our n-gram and parser-basedsystems can determine if a paraphrase is grammat-ical in context.
Meaning retention is important forthe imperceptibility requirement, but grammatical-ity is even more so, since ungrammatical sentenceswill be easy for an observer to spot.
However, werecognise that only testing for grammaticality doesnot fully test the imperceptibility properties of thesystem, only part of it.For the 8 cases which received different judge-ments on grammaticality, the second author of thispaper made the definitive judgement, which resultedin a test set of 308 paraphrases judged as grammat-ical in context, and 192 paraphrases judged as un-grammatical in context.4 Proposed Method and Experiments4.1 Google N-gram MethodThe main idea for testing the use of paraphrases isto check if the various contextual n-grams appearin the Google n-gram data, or were already in theoriginal sentence (before paraphrasing).
Let us firstdefine some notation to be used in describing themethod.
The leftmost and rightmost <m> words inthe phrase/paraphrase are represented as <m>INLeftand <m>INRight, respectively.
Words at the left andright side of the substituted phrase are defined as<c>OUTLeft and <c>OUTRight, where <c> is aninteger which indicates the number of words rep-resented.
Also, we define a context window pairW<c><n> = (WL<c><n>,WR<c><n>), where WL<c><n> iscomposed by <c>OUTLeft concatenated with <n-c>INLeft, and WR<c><n> is composed by <n-c>INRightconcatenated with <c>OUTRight.
Figure 3 gives anexample of the context window pairs W 13 and W23 inthe sentence Soviets said that it is too early to saywhether that will happen where the phrase too earlyto is being considered in context.Figure 3: An example of the context window pairINPUT: S, P, P ?, n,maxCOUTPUT: the acceptability of paraphrase P ?checked by (n, maxC)FOR each context size C from 1 to maxCGET a context window pair WCnIF O(WCn ) is zero THENOUTPUT paraphrase P ?
failsEND FOROUTPUT paraphrase P ?
passesFigure 4: Procedure for checking acceptabilityWe define a google-count function G().
This func-tion takes a context window pair W<c><n> as input andoutputs a frequency count pair of W<c><n> recorded inthe Google n-gram data.
If a context window cannotbe found in the Google n-gram data, the frequencycount of that window is zero.
Also, we define a bi-nary occurrence function O().
It is used to deter-mine whether a context window pair can be passedas acceptable.
The input of this function is W<c><n>.The function outputs one if either both WL<c><n> andWR<c><n> already occurred in the original sentence(before paraphrasing) or if the frequency counts out-put by G(W<c><n>) are both greater than zero.The two major components in our method are theparaphrase dictionary and the Google n-gram data.Once a phrase P in the cover sentence S is matchedwith that in the paraphrase dictionary, we test the useof its paraphrase P ?
by the following method.
Thismethod takes into account maximum C contextualwords at both sides of the target phrase, and usesGoogle n-gram data as a check, where n = 2, 3, 4 or5, and maxC = 1 to n?
1.
Each pair of (n, maxC)provides a separate check, by considering both leftand right contexts for these values.Figure 4 describes the procedure for checking the595acceptability of paraphrasing phrase P with P ?
ina given sentence S, given the n-gram size and themaximum considered context size maxC.
For ex-ample, we want to check the acceptability of theparaphrase in context shown in Figure 3 by usinggoogle tri-gram data (n = 3) and taking maximumcontext size equal to two into consideration (maxC= 2).
The procedure starts from taking context sizeC equal to one into account, namely checking theoccurrence of W 13 .
If the paraphrase P?
passes thecurrent test, in the next iteration it will be tested bytaking one more context word into account, namelyW 23 .
However, If the paraphrase P?
fails the current(n, C) check the checking procedure will terminateand report that the paraphrase fails.
In contrast, ifthe paraphrase passes all the (n, C) checks whereC = 1 to maxC, the procedure determines the para-phrase as acceptable.
What is happening is that an n-gram window is effectively being shifted across theparaphrase boundary to include different amounts ofcontext and paraphrase.4.2 Syntactic FilterIn order to improve the grammaticality checking, weuse a parser as an addition to the basic Google n-gram method.
We use the Clark and Curran (2007)CCG parser to analyse the sentence before and af-ter paraphrasing.
Combinatory Categorial Grammar(CCG) is a lexicalised grammar formalism, in whichCCG lexical categories ?
typically expressing sub-categorisation information ?
are assigned to eachword in a sentence.
The grammatical check worksby checking if the words in the sentence outside ofthe phrase and paraphrase receive the same lexicalcategories before and after paraphrasing.
If there isany change in lexical category assignment to thesewords then the paraphrase is judged ungrammati-cal.
Hence the grammar check is at the word, ratherthan derivation, level; however, CCG lexical cate-gories contain a large amount of syntactic informa-tion which this method is able to exploit.4.3 ResultsThe test corpus described in Section 3.3 was splitinto development and test data: 100 instances fordevelopment and 400 for testing.
The developmentdata was used for preliminary experiments.
For thetest data, 246 of the examples (61.5%) had beenAcc% P% R% F%baseline 61.5 61.5 100.0 76.2parser 68.3 67.4 93.9 78.4Table 3: Grammar check using CCG parserjudged as grammatical, and 154 (38.5%) had beenjudged as ungrammatical by the annotators.The performance of the system is evaluated us-ing accuracy, precision, recall and balanced F-measure.
Accuracy is the percentage of correctjudgements over all grammatical and ungrammati-cal paraphrases.
Precision is the percentage of para-phrases judged grammatical by the system which arejudged grammatical by the human judges, and recallis the percentage of paraphrases judged grammaticalby human judges which are also judged grammaticalby the system.
Precision and recall are relevant inour setting because high precision implies high im-perceptibility, since grammatical phrases in contextare less likely to be viewed as suspicious by the ob-server; whereas high recall maximises the payload(given the dictionary), since high recall implies thatphrases are being paraphrased where possible (andhence embedding as much information as possible).An accuracy baseline is obtained by always re-turning the majority class, in this case always judg-ing the paraphrase grammatical, which gives an ac-curacy of 61.5%.
Table 3 gives the performancewhen only the CCG parser is used for checking gram-maticality.
As far as steganography is concerned, theprecision is low, since over 30% of the paraphrasesused are ungrammatical, which is likely to raise thesuspicions of the observer.Table 4 gives the results for the Google n-grammethod, for various n-gram and context sizes.
As then-gram size increases ?
meaning that a larger partof the context is used ?
the accuracy falls belowthat of the baseline.
However, from a steganogra-phy aspect, accuracy is not useful, since the trade-off between precision and recall is more relevant.As expected, with larger n-grams checking the leftand right contexts, the precision increases, reaching100% for the 5-grams.
Hence, as far as grammati-cality judgements are concerned, the imperceptibil-ity requirement is completely satisified.
However,the large drop in recall means that the imperceptibil-596N-gramContext Accuracy Precision Recall F-measureSize (%) (%) (%) (%)2-gram1 62.0 62.1 98.0 76.03-gram1 62.5 65.1 84.2 73.42 67.3 72.9 74.4 73.64-gram1 58.5 71.3 54.5 61.82 53.2 84.7 29.3 43.53 51.8 89.6 24.4 38.35-gram1 54.8 85.0 32.1 46.62 43.5 95.5 8.5 15.73 41.0 100.0 4.1 7.84 41.0 100.0 4.1 7.8Table 4: Performance of google n-gram methodity is achieved at the cost of a reduced payload, sincemany of the grammatical paraphrases that could beused to embed information are being discarded.Table 5 shows the results for the Google n-grammethod followed by the parser check; that is, if theGoogle n-gram method judges the paraphrase to begrammatical, then it is passed to the CCG parser foran additional check.
Adding the parser generallyincreases the precision with a slight loss in recall.Which settings are best to use in practice would de-pend on how the steganography user wished to tradeoff imperceptibility for payload.5 Possible embedding methodIn this section, we propose a linguistic hidingmethod which can be integrated with an automaticparaphrasing system.
It needs a large paraphrasedictionary to determine modifiable phrases and pro-vide available paraphrases.
The embedding capacityof the proposed linguistic stegosystem relies on thenumber of paraphrasable sentences in the cover text.If every sentence in the cover text is paraphrasable,the system can have the maximum embedding ca-pacity equal to 1 bit per sentence which is compara-ble to other linguistic steganography methods usingsyntactic transformations and synonym substitution.N-gramContext Accuracy Precision Recall F-measureSize (%) (%) (%) (%)2-gram1 68.0 67.7 91.9 78.03-gram1 67.3 70.9 79.3 74.92 69.5 77.7 70.7 74.04-gram1 59.5 75.6 50.4 60.52 53.8 88.6 28.5 43.13 52.0 92.2 24.0 38.15-gram1 53.8 86.8 29.3 43.82 43.3 95.2 8.1 15.03 41.0 100.0 4.1 7.84 41.0 100.0 4.1 7.8Table 5: Performance of google n-gram method with theCCG parser filter5.1 Data Embedding ProcedureFirst the sentences in a cover text T are identi-fied using a sentence segmentation algorithm, giv-ing N sentences s1, s2,.
.
.
, sN .
The paraphrasabil-ity of each sentence is then checked using our au-tomatic method.
If a sentence contains at least oneparaphrasable phrase, we call the sentence a para-phrasable sentence or a non-paraphrasable sen-tence otherwise.
Let D be the maximum number ofsentence boundaries between two subsequent para-phrasable sentences in T. Thus, for every D sen-tences within a cover text T, there will be at leastone paraphrasable sentence.
Let every unit of D sen-tences serve as one embedding unit in which a singlesecret bit can be embedded.
If we want to embed0 in an embedding unit, we transform all the para-phrasable sentences in this embedding unit to non-paraphrasable sentences (assuming certain proper-ties of the dictionary; see end of this section for dis-cussion).
If we want to embed 1, we leave the em-bedding unit without any modifications.Figure 5 demonstrates the embedding of the se-cret bitstring 101 in a cover text containing nine sen-tences t1, t2,.
.
.
, t9 defined by a sentence segmenta-tion algorithm.
First, t1, t3, t4, t7 and t9 are de-termined as paraphrasable sentences and thus D, the597Figure 5: Embedding secret bits in a cover text using sen-tence segmentation methodsize of an embedding unit, is 3.
Next, we segmentthe cover text into three embedding units u1, u2 andu3, each of which contains three sentences.
Sincewe want to embed secret bits 101 in u1, u2 and u3 re-spectively, the embedding unit u2 should contain noparaphrasable sentence.
That is, the paraphrasablephrase in t4 should be replaced by its paraphrase.Finally, the stego text is output and sent along withthe private key D to the other party.
A private key isknown only to the parties that exchange messages.In order for this method to work, we require cer-tain properties of the paraphrase dictionary.
For ex-ample, it is crucial that, once a phrase has been para-phrased, it does not produce another phrase that canbe paraphrased.
This can be achieved by simplyrequiring that any paraphrase ?on the RHS?
of thedictionary does not also appear as a phrase on theLHS.
In fact, this is not so unnatural for the Callison-Burch dictionary, which consists of phrases mappedto sets of paraphrases, many of which only appearon one side.5.2 Data Extracting ProcedureFor extracting the secret data, first, the stego textT ?
undergoes sentence segmentation, and N definedsentences s?1, s?2,.
.
.
, s?N are obtained.
Accordingto the private key D, every D sentences are treatedas an information unit, and in each unit we checkthe occurrence of paraphrasable sentences makinguse of our paraphrasing method.
If an informationunit contains at least one paraphrasable sentence,this information unit implies the embedding of 1.In contrast, if none of the sentences in the informa-tion unit are paraphrasable, it implies the embeddingof 0.
Hence, in order to recover the hidden mes-sage, the receiver requires the sentence segmentationalgorithm, the paraphrase dictionary, the automaticprogram determining grammaticality of paraphrasesin context, and the secret key D. The extraction pro-cess essentially reverses the embedding method.6 ConclusionsThe contributions of this paper are to develop anautomatic system for checking the grammaticalityand fluency of paraphrases in context, and the pro-posal of using paraphrases as a suitable transfor-mation for Linguistic Steganography.
An advan-tage of our proposed method is that it is somewhatlanguage and domain independent, requiring only aparaphrase dictionary and a Google n-gram corpus,both of which are likely to be available for a rangeof languages in the future.There are various practical issues in the applica-tion of Linguistic Steganography systems that wehave chosen to ignore.
For example, we have notdiscussed the choice of cover text.
If a newspaper ar-ticle were chosen as the cover text, then any changescould be easily found in practice by comparing thestego text with the original article, which is likelyto be readily available.
Another interesting ques-tion that we have not addressed is whether some lan-guages are better suited to Linguistic Steganographythan others, or whether some languages are bettersuited to particular linguistic transformations thanothers.
Finally, we have only evaluated our gram-matical checker and not the steganography systemitself (other than giving an indication of the likelypayload).
How best to evaluate the imperceptibilityof such a system we leave to future work.AcknowledgementsWe would like to thank Chris Callison-Burch for pro-viding the paraphrase dictionary, Katja Markert, StephenPulman, Laura Rimell, and the anonymous reviewers foruseful comments.
Ching-Yun Chang was funded by anOxford University Clarendon scholarship.598ReferencesMikhail J. Atallah, Craig J. McDonough, Victor Raskin,and Sergei Nirenburg.
2001a.
Natural language pro-cessing for information assurance and security: anoverview and implementations.
In Proceedings of the2000 workshop on New security paradigms, pages 51?65, Ballycotton, County Cork, Ireland.Mikhail J. Atallah, Victor Raskin, Michael C. Crogan,Christian Hempelmann, Florian Kerschbaum, DinaMohamed, and Sanket Naik.
2001b.
Natural lan-guage watermarking: design, analysis, and a proof-of-concept implementation.
In Proceedings of the 4thInternational Information Hiding Workshop, volume2137, pages 185?199, Pittsburgh, Pennsylvania.Mikhail J. Atallah, Victor Raskin, Christian F. Hempel-mann, Mercan Karahan, Umut Topkara, Katrina E.Triezenberg, and Radu Sion.
2002.
Natural languagewatermarking and tamperproofing.
In Proceedings ofthe 5th International Information Hiding Workshop,pages 196?212, Noordwijkerhout, The Netherlands.Regina Barzilay and Kathleen R. McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of the 39th ACL, pages 50?57, Toulouse.Richard Bergmair.
2007.
A comprehensive bibliogra-phy of linguistic steganography.
In Proceedings of theSPIE Conference on Security, Steganography, and Wa-termarking of Multimedia Contents, volume 6505.Shane Bergsma, Dekang Lin, and Randy Goebel.
2009.Web-scale n-gram models for lexical disambiguation.In Proceedings of the 21st International Joint Con-ference on Artifical Intelligence, pages 1507?1512,Pasadena, CA.Igor A. Bolshakov.
2004.
A method of linguisticsteganography based on coladdressally-verified syn-onym.
In Information Hiding: 6th International Work-shop, volume 3200, pages 180?191, Toronto, Canada.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of the EMNLP Conference, pages 196?205,Honolulu, Hawaii.Mark Chapman and George I. Davida.
1997.
Hiding thehidden: A software system for concealing ciphertextas innocuous text.
In Proceedings of the First Interna-tional Conference on Information and CommunicationSecurity, volume 1334, pages 335?345, Beijing.Stephen Clark and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCG andlog-linear models.
Comp.
Ling., 33(4):493?552.Jessica Fridrich.
2009.
Steganography in Digital Media:Principles, Algorithms, and Applications.
CambridgeUniversity Press, first edition.Yuling Liu, Xingming Sun, and Yong Wu.
2005.
A nat-ural language watermarking based on Chinese syntax.In Advances in Natural Computation, volume 3612,pages 958?961, Changsha, China.Mitchell P. Marcus, Beatrice Santorini, and Mary A.Marcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19:313?330.Hasan M. Meral, Emre Sevinc, Ersin Unkar, BulentSankur, A. Sumru Ozsoy, and Tunga Gungor.
2007.Syntactic tools for text watermarking.
In Proceed-ings of the SPIE Conference on Security, Steganogra-phy, and Watermarking of Multimedia Contents, vol-ume 6505, San Jose, CA.Brian Murphy and Carl Vogel.
2007.
The syntax of con-cealment: reliable methods for plain text informationhiding.
In Proceedings of the SPIE Conference on Se-curity, Steganography, and Watermarking of Multime-dia Contents, volume 6505, San Jose, CA.Brian Murphy.
2001.
Syntactic information hiding inplain text.
Masters Thesis.
Trinity College Dublin.Lip Y. Por, Ang T. Fong, and B. Delina.
2008.Whitesteg: a new scheme in information hiding usingtext steganography.
WSEAS Transactions on Comput-ers, 7:735?745.Cuneyt M. Taskiran, Mercan Topkara, and Edward J.Delp.
2006.
Attacks on linguistic steganography sys-tems using text analysis.
In Proceedings of the SPIEConference on Security, Steganography, and Water-marking of Multimedia Contents, volume 6072, pages97?105, San Jose, CA.Mercan Topkara, Cuneyt M. Taskiran, and Edward J.Delp.
2005.
Natural language watermarking.In Proceedings of the SPIE Conference on Secu-rity, Steganography, and Watermarking of MultimediaContents, volume 5681, pages 441?452, San Jose, CA.Mercan Topkara, Umut Topkara, and Mikhail J. Atallah.2006a.
Words are not enough: sentence level naturallanguage watermarking.
In Proceedings of the ACMWorkshop on Content Protection and Security, pages37?46, Santa Barbara, CA.Umut Topkara, Mercan Topkara, and Mikhail J. Atal-lah.
2006b.
The hiding virtues of ambiguity: quan-tifiably resilient watermarking of natural language textthrough synonym substitutions.
In Proceedings of the8th Workshop on Multimedia and Security, pages 164?174, Geneva, Switzerland.M.
Olga Vybornova and Benoit Macq.
2007.
Amethod of text watermarking using presuppositions.In Proceedings of the SPIE Conference on Secu-rity, Steganography, and Watermarking of MultimediaContents, volume 6505, San Jose, CA.599
