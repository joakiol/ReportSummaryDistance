Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1834?1839,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsDependency-based Discourse Parser for Single-Document SummarizationYasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and Masaaki NagataNTT Communication Science Laboratories, NTT Corporation2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan{yoshida.y,suzuki.jun,hirao.tsutomu,nagata.masaaki}@lab.ntt.co.jpAbstractThe current state-of-the-art single-document summarization method gen-erates a summary by solving a TreeKnapsack Problem (TKP), which is theproblem of finding the optimal rooted sub-tree of the dependency-based discoursetree (DEP-DT) of a document.
We canobtain a gold DEP-DT by transforming agold Rhetorical Structure Theory-baseddiscourse tree (RST-DT).
However, thereis still a large difference between theROUGE scores of a system with a goldDEP-DT and a system with a DEP-DTobtained from an automatically parsedRST-DT.
To improve the ROUGE score,we propose a novel discourse parserthat directly generates the DEP-DT.
Theevaluation results showed that the TKPwith our parser outperformed that withthe state-of-the-art RST-DT parser, andachieved almost equivalent ROUGEscores to the TKP with the gold DEP-DT.1 IntroductionDiscourse structures of documents are believedto be highly beneficial for generating informa-tive and coherent summaries.
Several discourse-based summarization methods have been devel-oped, such as (Marcu, 1998; Daum?e III andMarcu, 2002; Hirao et al., 2013; Kikuchi et al.,2014).
Moreover, the current best ROUGE scorefor the summarization benchmark data of the RST-discourse Treebank (Carlson et al., 2002) has beenprovided by (Hirao et al., 2013), whose methodalso utilizes discourse trees.
Thus, the discourse-based summarization approach is one promisingway to obtain high-quality summaries.One possible weakness of discourse-based sum-marization techniques is that they rely greatly onthe accuracy of the discourse parser they use.For example, the above discourse-based summa-rization methods utilize discourse trees based onthe Rhetorical Structure Theory (RST) (Mann andThompson, 1988) for their discourse information.Unfortunately, the current state-of-the-art RSTparser, as described in (Hernault et al., 2010),is insufficient as an off-the-shelf discourse parser.In fact, there is empirical evidence that the qual-ity (i.e., ROUGE score) of summaries from auto-parsed discourse trees is significantly degradedcompared with those generated from gold dis-course trees (Marcu, 1998; Hirao et al., 2013).From this background, the goal of this paperis to develop an appropriate discourse parser fordiscourse-based summarization.
We first focus onone of the best discourse-based single documentsummarization methods as proposed in (Hirao etal., 2013).
Their method formulates a single doc-ument summarization problem as a Tree Knap-sack Problem (TKP) over a dependency-based dis-course tree (DEP-DT).
In their method, DEP-DTsare automatically transformed from (auto-parsed)RST-discourse trees (RST-DTs) by heuristic rules.Instead, we develop a DEP-DT parser, that di-rectly provides DEP-DTs for their state-of-the-artdiscourse-based summarization method.
We showthat summaries generated by our parser improvethe ROUGE scores to almost the same level asthose generated by gold DEP-DTs.
We also inves-tigate the way in which the parsing accuracy helpsto improve the ROUGE scores.2 Single-Document Summarization as aTree Knapsack ProblemHirao et al.
(2013) formulated single-documentsummarization as a TKP that is run on the DEP-DT.
They obtained a summary by trimming theDEP-DT, i.e.
the summary is a rooted subtree ofthe DEP-DT.Suppose that we have N EDUs in a document,1834Root!N!
S!N!
S!
N!
S!S!
N!
N!
S!
S!
N!
S!
N!N!
N!N!
S!Elaboration!Background!Elaboration!Elaboration!Contrast!
Contrast!Evidence!Example!Concession!
Antithesis!
(a)Background Elabora.onElabora.onElabora.on Elabora.onConcession ExampleEvidenceAn.thesis(b)Background Elabora.on Elabora.onElabora.on Elabora.on Concession ExampleEvidence An.thesis(c)Figure 1: Examples of RST-DT and DEP-DT.
e1, ?
?
?
, e10are EDUs.
(a) Example of an RST-DT from(Marcu, 1998).
n1, ?
?
?
, n19are the non-terminal nodes.
(b) Example of the DEP-DT obtained from theincorrect RST-DT that is made by swapping the Nucleus-Satellite relationship of the node n2and thenode n3.
(c) The correct DEP-DT obtained from the RST-DT in (a).and the i-th EDU eihas liwords.
L is the maxi-mum number of words allowed in a summary.
Inthe TKP, if we select ei, we need to select its par-ent EDU in the DEP-DT.
We denote parent(i) asthe index of the parent of eiin the DEP-DT.
x isan N -dimensional binary vector that represents asummary, i.e.
xi= 1 denotes that eiis included inthe summary.
The TKP is defined as the followingILP problem:maximizex?Ni=1F (ei)xis.t.?Ni=1lixi?
L?i : xparent(i)?
xi?i : xi?
{0, 1},where F (ei) is the score of ei.
We define F (ei) asfollows:F (ei) =?w?W (ei)tf(w,D)Depth(ei),where W (ei) is the set of words contained in ei.tf(w,D) is the term frequency of word w in a doc-ument D. Depth(ei) is the depth of eiin the DEP-DT.3 Tree Knapsack Problem withDependency-based Discourse Parser3.1 MotivationIn (Hirao et al., 2013), they automatically ob-tain the DEP-DT by transforming from the parsedRST-DT.
We simply followed their method for ob-taining the DEP-DTs1.
The transformation algo-rithm can be found in detail in (Hirao et al., 2013).Figure 1(a) shows an example of the RST-DT.
Ac-cording to RST, a document is represented as a treewhose terminal nodes correspond to elementarydiscourse units (EDUs) and whose non-terminalnodes indicate the role of the contiguous EDUs,namely, ?nucleus (N)?
or ?satellite (S)?.
Since a nu-cleus is more important than a satellite in terms ofthe writer?s purpose, a satellite is always a child ofa nucleus in the RST-DT.
Some discourse relationsbetween a nucleus and a satellite or two nuclei aredefined.Since the TKP of (Hirao et al., 2013) employsa DEP-DT obtained from an automatically parsedRST-DT, their method strongly relies on the ac-curacy of the RST parser.
For example, in Fig-ure 1(a), if the RST-DT parser incorrectly setsthe node n2as Satellite and the node n3as Nu-cleus, we obtain an incorrect DEP-DT in Figure1(b) because the transformation algorithm usesthe Nucleus-Satellite relationships in the RST-DT.The dependency relationships in Figure 1(b) arequite different from that of the correct DEP-DT inFigure 1(c).
In this example, the parser failed todetermine the most salient EDU e2, that is the rootEDU of the gold DEP-DT.
Thus, the summary ex-tracted from this DEP-DT will have a low ROUGEscore.The results motivated us to design a new dis-course parser fully trained on the DEP-DTs and1Li et al.
also defined a similar transformation algorithm(Li et al., 2014).
In this paper, we follow the transformationalgorithm defined in (Hirao et al., 2013).1835Discourse)Dependency)ParserDocument SummaryDiscourse)Dependency)ParserTree)Knapsack)ProblemParser)Training)PhaseSummariza;on)Phasee2#e1# e3# e8# e10#e4# e5# e7# e9#e6#Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#Background# e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#Background# e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#Background#DEP=DTse2#e1# e3# e8# e10#e4# e5# e7# e9#e6#Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#Background#DEP=DTRoot$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ SS$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$RST=DTsTransforma;on)Algorithm(a)e2#e1# e3# e8# e10#e4# e5# e7# e9#e6#Elabora3on# Elabora3on#Elabora3on# Elabora3on# An3thesis#Example#Evidence# Concession#Background#RST$ParserDocument Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$ SummaryRST$ParserTransforma3on$Algorithm Tree$Knapsack$ProblemParser$Training$PhaseSummariza3on$PhaseRoot$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ S$S$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$Root$N$ S$N$ S$ N$ SS$ N$ N$ S$ S$ N$ S$ N$N$ N$N$ S$e1$ e2$ e3$ e4$ e5$ e6$ e7$ e8$ e9$ e10$Elabora7on$Background$Elabora7on$Elabora7on$Contrast$Evidence$Example$Concession$ An7thesis$RST>DTsRST>DT DEP>DT(b)Figure 2: (a) Overview of our proposed method.
In the parser training phase, the parser is trained onthe DEP-DTs, and in the summarization phase, the document is directly parsed into the DEP-DT.
(b)Overview of (Hirao et al., 2013).
In the parser training phase, the parser is trained on RST-DTs, andin the summarization phase, the document is parsed into the RST-DT, and then transformed into theDEP-DT.that could directly generate the DEP-DT.
Figure2(a) shows an overview of the TKP combined withour DEP-DT parser.
In the parser training phase,we transform RST-DTs into DEP-DTs, and di-rectly train our parser with the DEP-DTs.
In thesummarization phase, our method parses a rawdocument directly into a DEP-DT, and generatesa summary with the TKP.3.2 Description of Discourse DependencyParserOur parser is based on the first-order MaximumSpanning Tree (MST) algorithm (McDonald et al.,2005b).
Our parser extracts the features from theEDU eiand the EDU ej.
We use almost the fea-tures as those shown in (Hernault et al., 2010).Lexical N-gram features use the beginning (orend) lexical N-grams (N ?
{1, 2, 3}) in eiandej.
We also include POS tags for the beginning(or end) lexical N-grams (N ?
{1, 2, 3}) in eiandej.
Organizational features include the distancebetween eiand ej.
They also include the num-ber of tokens, and features for identifying whetheror not eiand ejbelong to the same sentence (orparagraph).
Soricut et al.
(2003) introduced dom-inance set features.
They include syntactic labelsand the lexical heads of head and attachment nodesalong with their dominance relationship.
We can-not use the strong compositionality features andrhetorical structure features described in (Her-nault et al., 2010) because we have to know thesubtree structures in advance when using thesefeatures.To train the parser, we choose the Margin In-fused Relaxed Algorithm (MIRA) (McDonald etal., 2005a; Crammer et al., 2006).
We denotes(w,y) = wTfyas a score function given aweight vector w and a DEP-DT y.
L(y,y?)
isa loss function, and we define it as the number ofEDUs that have an incorrect parent EDU in a pre-dicted DEP-DT y?= arg maxys(w,y).
Then, wesolve the following optimization problem:minw||w ?w(t)||s.t.
s(w,y) ?
s(w,y?)
?
L(y,y?
),(1)where w(t)is a weight vector in the t-th iteration.3.3 Redesign of Loss Function for TreeKnapsack ProblemWhen we make a summary by solving a TKP, wedo not necessarily need a DEP-DT where all of theparent-child relationships are correct.
This is be-cause we rarely select the EDUs around the leavesin the DEP-DT.
On the other hand, the parent-child relationships around the root EDU in theDEP-DT are important because we often select theEDUs around the root EDU.
Incorporating theseintuitions enables us to develop a DEP-DT parseroptimized for the TKP.
To incorporate this infor-mation, we define the following loss function:LDepth(y,y?)
=?
(i,r,j)?y[1 ?
I(y?, i, j)]Depth(ei), (2)where I(y?, i, j) is an indicator function thatequals 1 if EDU ejis the parent of EDU eiin the1836DEP-DT y?and 0 otherwise.
In Section 4, we re-port results with the original loss function L(?, ?
)and with the modified loss function LDepth(?, ?
).4 Experimental Evaluation4.1 CorpusWe used the RST-DT corpus (Carlson et al., 2002)for our experimental evaluations.
The corpus con-sists of 385 Wall Street Journal articles with RSTannotation, and 30 of these documents also haveone human-made reference summary.
We usedthese 30 documents as the test documents for thesummarization evaluation, and used the remaining355 RST annotated documents as the training datafor the parser.
Note that we did not use the 30 testdocuments for the summarization evaluation whenwe trained the parser.4.2 Summarization EvaluationWe compared the following three systems that dif-fer in the way they obtain the DEP-DT.TKP-GOLD Used a DEP-DT converted from agold RST-DT.TKP-DIS-DEP Used a DEP-DT automaticallyparsed by our discourse dependency-basedparser (DIS-DEP).
Figure 2(a) shows anoverview of this system.TKP-DIS-DEP-LOSS Used a DEP-DT automat-ically parsed by our discourse dependency-based parser (DIS-DEP).
Figure 2(a) showsan overview of this system.
It is trained withthe loss function defined in equation (2).TKP-HILDA Used a DEP-DT obtained by trans-forming a RST-DT parsed by HILDA, a state-of-the-art RST-DT parser (Hernault et al.,2010).
Figure 2(b) shows an overview of thissystem.Hirao et al.
(2013) proved that TKP-HILDAoutperformed other methods including Marcu?smethod (Marcu, 1998), a simple knapsack model,a maximum coverage model and LEAD methodthat simply takes the first L tokens (L = summarylength).
Thus, we only employed TKP-HILDA asour baseline.We follow the evaluation conditions describedin (Hirao et al., 2013).
The number of tokens ineach summary is determined by the number in theROUGE-1 ROUGE-2TKP-GOLD 0.321 0.112TKP-DIS-DEP 0.319 0.109TKP-DIS-DEP-LOSS 0.323 0.121TKP-HILDA 0.284 0.093Table 1: ROUGE Recall scoreshuman-annotated reference summary.
The aver-age length of the reference summaries correspondsto about 10% of the words in the source document.This is also the commonly used evaluation con-dition for single-document summarization evalu-ation on the RST-DT corpus.
We employed therecall of ROUGE-1, 2 as the evaluation measures.Table 1 shows ROUGE scores on the RST-DTcorpus.
We can see TKP-DIS-DEP and TKP-DIS-DEP-LOSS outperformed TKP-HILDA, andachieved almost the same ROUGE scores as TKP-GOLD.
Wilcoxon?s signed rank test in termsof ROUGE rejected the null hypothesis, ?thereis a difference between TKP-HILDA and TKP-DIS-DEP (or TKP-DIS-DEP-LOSS)?
(Wilcoxon,1945).
This would be because test documents arerelatively small.We analyzed the differences between the pro-posed systems (TKP-DIS-DEP and TKP-DIS-DEP-LOSS) and TKP-HILDA.
First, we evaluatedthe overlaps between the EDUs in summaries gen-erated by the system and the EDUs in summariesgenerated by TKP-GOLD.
To see the overlaps, wecalculated the average F-value using Recall andPrecision defined as follows: Recall = |Ss?Sg|/|Sg|, Precision = |Ss?
Sg|/|Ss|, where Ssis a set of EDUs in a summary generated by a sys-tem, and Sga set of EDUs in a summary generatedby TKP-GOLD.
The first line in Table 2 shows theresults.
TKP-DIS-DEP and TKP-DIS-DEP-LOSSoutperformed TKP-HILDA as regards the aver-age F-values.
The result revealed that TKP-DIS-DEP and TKP-DIS-DEP-LOSS have more EDUsin common with TKP-GOLD than TKP-HILDA.This result is evidence that TKP-DIS-DEP andTKP-DIS-DEP-LOSS outperformed TKP-HILDAin terms of ROUGE score.Second, we evaluated the root accuracy (RA),the rate at which a parser can find the root of DEP-DTs.
Since the root of a gold DEP-DT is the mostsalient EDU in a document, it should be includedin the summary.
The second line in Table 2 showsthat our methods succeeded in extracting the root1837TKP-DIS-DEP TKP-DIS-DEP-LOSS TKP-HILDAAvg F-value 0.532?0.532?0.415RA 0.933?0.933?0.733Avg DAS 0.847?0.843?0.596?
: significantly better than TKP-HILDA (p < .05)Table 2: Average F-value, Root Accuracy (RA), and average Dependency Accuracy in Summary (DAS).Wilcoxon?s signed rank test in terms of average F-value, RA and DAS accepted the null hypothesis.TKP-GOLD:Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results.
Elcotel, a telecommunications company, had netincome of $272,000, or five cents a share, in its year-earlier second quarter.
The lower results, Mr. Pierce said.
Elcotel willalso benefit from moving into other areas.
Elcotel has also developed an automatic call processor.
Automatic call processorswill provide that system for virtually any telephone, Mr. Pierce said, not just phones.TKP-DIS-DEP, TKP-DIS-DEP-LOSS:Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results.
Elcotel, a telecommunications company, had netincome of $272,000, or five cents a share, in its year-earlier second quarter.
George Pierce, chairman and chief executive officer,said in an interview.
Although Mr. Pierce expects that line of business to strengthen in the next year.
Elcotel will also benefitfrom moving into other areas.
Elcotel has also developed an automatic call processor.TKP-HILDA:Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results.
That several new products will lead to a ?muchstronger?
performance in its second half.
George Pierce, chairman and chief executive officer, said in an interview.
Mr.Pierce said Elcotel should realize a minimum of $10 of recurring net earnings for each machine each month.
Elcotel has alsodeveloped an automatic call processor.
Automatic call processors will provide that system for virtually any telephone.Figure 3: Summaries of wsj 2317.
The sentences shown in bold-face are the root EDUs in each DEP-DTof the summary.of DEP-DT with high accuracy.Third, to evaluate the coherency of the gener-ated summaries, we compared the average Depen-dency Accuracy in Summary (DAS), which is de-fined as follows:DAS(S) =1|S|?e?S?(e),?
(e) ={1 (if parent(e) ?
S)0 (otherwise),where S is a set of EDUs contained in the sum-mary and parent(e) returns the parent EDU of ein the gold DEP-DT.
DAS(S) measures the rate ofthe correct parent-child relationships in S. WhenDAS equals 1, the summary is a rooted subtree ofthe gold DEP-DT.
The third line in Table 2 showsthe results.
The results demonstrate that the sum-maries generated by TKP-DIS-DEP or TKP-DIS-DEP-LOSS tend to preserve the upper level depen-dency relationships between the EDUs within thegold DEP-DT.Figure 3 shows summaries of wsj 2317 gener-ated by the three systems.
The EDUs correspond-ing to the root of the DEP-DT are used in eachsystem shown in boldface.
We can see that theroot EDU in the gold DEP-DT is found in thesummaries generated by TKP-DIS-DEP and TKP-DIS-DEP-LOSS, but not in the summary gener-ated by TKP-HILDA.5 ConclusionIn this paper, we proposed a novel dependency-based discourse parser for single-document sum-marization.
The parser enables us to obtain theDEP-DT without transforming the RST-DT.
Theevaluation results showed that the TKP with ourparser outperformed that with the state-of-the-artRST-DT parser, and achieved almost equivalentROUGE scores to the TKP with the gold DEP-DT.ReferencesLynn Carlson, Daniel Marcu, and Mary EllenOkurowski.
2002.
Rst discourse treebank,ldc2002t07.Koby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2006.
Onlinepassive-aggressive algorithms.
The Journal of Ma-chine Learning Research, 7:551?585.1838Hal Daum?e III and Daniel Marcu.
2002.
A noisy-channel model for document compression.
In Pro-ceedings of the 40th Annual Meeting of the Associa-tion for Computational Linguistics (ACL), pages 449?
456, Philadelphia, PA, July 6 ?
12.Hugo Hernault, Helmut Prendinger, Mitsuru Ishizuka,et al.
2010.
Hilda: a discourse parser using supportvector machine classification.
Dialogue and Dis-course, 1(3).Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,Norihito Yasuda, and Masaaki Nagata.
2013.Single-document summarization as a tree knapsackproblem.
In Proceedings of the 2013 Conference onEMNLP, pages 1515?1520.Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Man-abu Okumura, and Masaaki Nagata.
2014.
Singledocument summarization based on nested tree struc-ture.
In Proceedings of the 52nd Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 315?320, Baltimore,Maryland, June.
Association for Computational Lin-guistics.Sujian Li, Liang Wang, Ziqiang Cao, and Wenjie Li.2014.
Text-level discourse dependency parsing.
InProceedings of the 52nd Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 25?35, Baltimore, Maryland,June.
Association for Computational Linguistics.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, 8(3):243?281.Daniel Marcu.
1998.
Improving summarizationthrough rhetorical parsing tuning.
In Proc.
of The6th Workshop on VLC, pages 206?215.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005a.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd An-nual Meeting on Association for Computational Lin-guistics, ACL ?05, pages 91?98, Stroudsburg, PA,USA.
Association for Computational Linguistics.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005b.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceed-ings of Human Language Technology Conferenceand Conference on Empirical Methods in NaturalLanguage Processing, pages 523?530, Vancouver,British Columbia, Canada, October.
Association forComputational Linguistics.Radu Soricut and Daniel Marcu.
2003.
Sentence leveldiscourse parsing using syntactic and lexical infor-mation.
In Proceedings of the 2003 Human Lan-guage Technology Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics.Frank Wilcoxon.
1945.
Individual Comparisons byRanking Methods.
Biometrics Bulletin, 1(6):80?83,December.1839
