NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 37?40,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsMining Search Query Logs for Spoken Language UnderstandingDilek Hakkani-Tu?r, Gokhan Tu?r, Asli CelikyilmazMicrosoft, Mountain View, CA 94041, USAdilek|gokhan.tur|asli@ieee.orgAbstractIn a spoken dialog system that can handle nat-ural conversation between a human and a ma-chine, spoken language understanding (SLU)is a crucial component aiming at capturingthe key semantic components of utterances.Building a robust SLU system is a challeng-ing task due to variability in the usage of lan-guage, need for labeled data, and requirementsto expand to new domains (movies, travel, fi-nance, etc.).
In this paper, we survey recentresearch on bootstrapping or improving SLUsystems by using information mined or ex-tracted from web search query logs, whichinclude (natural language) queries entered byusers as well as the links (web sites) they clickon.
We focus on learning methods that helpunveiling hidden information in search querylogs via implicit crowd-sourcing.1 IntroductionBuilding a robust spoken dialog system involves hu-man language technologies to cooperate to answernatural language (NL) user requests.
First user?sspeech is recognized using an automatic speechrecognition (ASR) engine.
Then a spoken languageunderstanding (SLU) engine extracts their meaningto be sent to dialog manager for taking the appropri-ate system action.Three key tasks of an SLU system are domainclassification, intent determination and slot filling(Tur and Mori, 2011).
While the state-of-the-artSLU systems rely on data-driven methods, collect-ing and annotating naturally spoken utterances totrain the required statistical models is often costlyand time-consuming, representing a significant bar-rier to deployment.
However, previous work showsthat it may be possible to alleviate this hurdle byleveraging the abundance of implicitly labeled websearch queries in search engines.
Large-scale en-gines, e.g., Bing or Google, log more than 100Mqueries every day.
Each logged query has an associ-ated set of URLs that were clicked after the users en-tered the query.
This information can be valuable forbuilding more robust SLU components, therefore,provide (noisy) supervision in training SLU mod-els.
Take domain detection problem: Two users whoenter different queries but click on the same URL(www.hotels.com) would probably be searching forconcepts in the same domain (?hotels?
in this case).The use of click information obtained throughmassive search query click logs has been the fo-cus of previous research.
Specifically, query logshave been used for building more robust web searchand better information retrieval (Pantel and Fuxman,2011; Li et al, 2008), improve personalization expe-rience and understand social networking behaviors(Wang et al, 2011), etc.
The use of query logs inspoken dialog research is fairly new.
In this paper,we will survey the recent research on utilizing thesearch query logs to obtain more accurate and ro-bust spoken dialog systems, focusing on the SLU.Later in the discussion section, we will discuss theimplimications on the dialog models.The paper is organized as follows: In ?
2, webriefly describe query click logs.
We then summa-rize recent research papers to give a snapshot of howuser search queries are being used in ?
3, and howinformation from click-through graphs (queries and37movie theatersin san brunoregal sunsetsquare cinemasthe majesticcrest theatercinema in rosewellrave cinemasin eastfieldQueries Clicked URLsmoviefone.commovies.eventful.comyelp.comamctheaters.comfind cheap ticketsfor inceptionmovie ticket dealswatch moviedeals for inceptionQueries Clicked URLsfandango.commovietickets.commovie.yahoo.comticketmakers.commovieworld carsltonticket prices178320530322454946121Figure 1: A sample query click graph.
The squared queriesare samples from training data which are natural language ut-terances.
Edges include click frequencies from query to link.clicked links) are exploited to boost the SLU perfor-mance.
Lastly, we discuss possible future directions.2 What are Query Click Logs (QCL)?QCL are logs of unstructured text including both theusers queries sent to a search engine and the linksthat the users clicked on from the list of sites re-turned by that search engine.
A common representa-tion of such data is a bi-partite query-click graph asshown in (Fig 1), where one set of nodes representsqueries, and the other set of nodes represents URLs,and an edge is placed between two nodes represent-ing a query q and a URL u, if at least one user whotyped the q clicked on u.Traditionally, the edge of the click graph isweighted based on the raw click frequency (numberof clicks) from a query to a URL.
Some of the chal-lenges in extracting useful information from QCL isthat the feature space is high dimensional (there arethousands of url clicks linked to many queries), andthere are millions of queries logged daily.3 Exploiting NL Search Queries for SLUPrevious work on web search has benefited from theuse of query click logs for improving query intentclassification.
Li et al use query click logs to de-termine the domain of a query (typically keywordsearch queries), and then infer the class member-ships of unlabeled queries from those of the labeledsearch queries using the URLs the users clicked (Liet al, 2009; Li et al, 2008).
QCL have been used toextract named-entities to improve web search and adpublishing experience (Hillard and Leggetter, 2010)using (un)supervised learning methods on keywordbased search queries.
Different from previous re-search, in this paper we focus on recent research thatutilize NL search queries to boost the performanceof SLU components, i.e., domain detection, intentdetermination, and slot filling.In (Hakkani-Tur et al, 2011a), they use the searchquery logs for domain classification by integrat-ing noisy supervision into the semi-supervised la-bel propagation algorithm, and sample high-qualityquery click data.
Specifically, they extract a set ofqueries, whose users clicked on the URLs that arerelated to their target domain categories.
Then theymine query click logs to get al instances of thesesearch queries and the set of links that were clickedon by search engine users who entered the samequery.
They compare two semi-supervised learn-ing methods, self-training and label propagation, toexploit the domain information obtained form theURLs user have clicked on.
The analysis indicatethat query sampling through semi-supervised learn-ing enables extracting NL queries for use in domaindetection.
They also argue that using raw querieswith and without the noisy labels in semi-supervisedlearning reduces domain detection error rate by 20%relative to supervised learning which uses only themanually labeled examples.The search queries found in click logs and the NLspoken utterances are different in the sense that thesearch queries are usually short and keyword basedcompared to NL utterances that are longer and areusually grammatical sentences (see Fig.
1).
Hence,in (Hakkani-Tur et al, 2012), they choose a statis-tical machine translation (SMT) approach to searchquery mining for SLU as sketched in Fig.
2.
Theassumption is that, users typically have conceptualintents underlying their requests when they inter-act with web search engine or use a virtual assis-tance system with built in SLU engine, e.g., ?avatarawards?
versus ?which awards did the movie avatarwin??.
They translate NL queries into search queriesand mine similar search queries in QCL.
They alsoexploit QCL for bootstrapping domain detectionmodels, using only the NL queries hitting to seeddomain indicator URLs (Hakkani-Tur et al, 2011c).Specifically, if one needs to detect a domain detectorfor the hotels domain, the queries hitting hotels.com,or tripadvisor.com, may be used to mine.Query click logs have been explored for slot fill-ing models as well.
The slot filling models of SLU38Figure 2: Using natural language to query language translationfor mining query click logs.aim to capture semantic components given the do-main and a common way is to use gazetteer features(dictionaries specific to domain such as movie-nameor actors in movie domain).
In (Hillard et al, 2011),they propose to mine and weight gazetteer entriesusing query click logs.
The gazetteer entries arescored using a function of posterior probabilities forthat entry hitting a URL (compared to others URLs)and for that URL being related to the target domain.In such a schema the movie name ?gone with thewind?
gets higher score than the movie ?up?.In (Tur et al, 2011), an unsupervised approach ispresented to implicitly annotate the training data us-ing the QCL.
Being unsupervised, this method auto-matically populates gazetteers as opposed to man-ually crafted gazetteers.
Specifically they use anabundant set of web search query logs with theirclick information (see Fig.
1).
They start by de-tecting target URLs (such as imdb.com/titlefor the movie names).
Then they obtain a listof entities and their target URLs (for example,www.imdb.com/title/tt047723 can be the target URLfor the movie ?the count of monte carlo?.
Then theyextract all queries hitting those links if they includethat entity.
This method enables automatically ob-taining annotated queries such as: ?review of thehand?
or ?mad men season one synopsis?
(boldterms are automatically discovered entities.
)4 Mining Click Graph Features for SLUIn the previous section, we presented examples ofrecent research that use queries obtained from QCLto bootstrap and improve SLU models.
Note thateach query in QCL is linked to one or many websites (links), which indicate a certain feature of thequery (queries that the hotels.com linked are clickedafter they are entered might indicate hotels domain).Such features extracted from QCL data (called click-through features) has been demonstrated to signifi-cantly improve the performance of ranking modelsfor Web search applications (Gao et al, 2009), es-timating relations between entities and web searchqueries (Pantel and Fuxman, 2011), etc.In SLU research community, only recently the useof click-through features has shown to improve theperformance of domain and intent of NL user utter-ances.
In one study (Hakkani-Tur et al, 2011b), in-stead of mining more data to train a domain clas-sifier with lexical features, they enrich their fea-tures using the click-through features with the in-tuition that the queries with similar click patternsshould be semantically similar.
They search all theNL utterances in the training data set amongst thesearch queries.
Once they obtain search queries,they pull the list of clicked URLs and their frequen-cies for each query which represent the click fea-tures.
To reduce the number of features, they ex-tract only the base URLs (such as opentable.com orwikipedia.com), as is commonly done in the websearch literature.
T use the list of the 1000 most fre-quently clicked base URLs for extracting classifica-tion features (QCL features).
For each input userutterance, xj , they compute P (URLi|xj), wherei = 1..1000.
They compute the click probability dis-tribution distance between a query and the queries ina target domain, Dk, using the KL divergence:KLk = KL(P (URLi|xj)||P (URLi|Dk)) (1)Thus, for a given domain Dk, the KLk and the do-main with the lowest KL divergence are used as ad-ditional features.Although the click-through are demonstrated tobe beneficial for SLU models, such benefits, how-ever, are severely limited by the data sparsenessproblem, i.e., many queries and documents have noor very few clicks.
The SLU models thus cannot relystrongly on click-through features.
In (Celikyilmazet al, 2011), the sparsity issue of representing thequeries with click-through features are investigated.They represent each unlabeled query from QCL as39a high dimensional sparse vector of click frequen-cies.
Since the true dimensionality of a query is un-known (the number of clicks are infinitely many),they utilize an unbounded factor analysis approachand build an infinite dimensional latent factor anal-ysis, namely the Indian Buffet Process (IBP) (Grif-fiths and Ghahramani, 2005), specifically to modelthe latent factor structure of the given set of queries.They implement a graph summarization algorithmto capture representative queries from a large set ofunlabeled queries that are similar to a rather smallerset of labeled queries.
They capture the latent factorstructure of the labeled queries via IBP and reducethe dimensionality of the queries to manageable sizeand collect additional queries in this latent factorspace.
They use the new set of utterances boost theintent detection performance of SLU models.5 Discussions and Future DirectionsThis paper surveyed previous research on the usageof the query click logs (the click through data) pro-vide valuable statistics that can potentially improveperformance of the SLU models.
We presented sev-eral methods that has been used to extract infor-mation in the form of additional vocabulary, unla-beled utterances and hidden features to represent ut-terances.
The current research is only the beginning,and most approaches such as query expansion, sen-tence compression, etc.
can be easily adopted fordialog state update processes.
Thus, the state-of-theart in NL understanding can be improved by:?
clustering of URLs as well as queries for extract-ing better features as well as to extend ontologies.The search community has access to vast amountsof search data that would benefit natural languageprocessing research,?
mining multi-lingual data for transferring dialogsystems from one language to others,?
mining information from search sessions, for ex-ample, users rephrasing of their own search queriesfor better results.One issue that has been the topic of recent discus-sions is the accessibility of QCL data to researchers.Note that, QCL is not a crowd-source data that onlylarge web search organizations like Google or Mi-crosoft Bing can mine and exploit for NL under-standing, but various other forms may be imple-mented by interested researchers by using a simpleweb service or a mobile app (such as AT&T SpeakItor Dragon Go) or using a targeted search engine.ReferencesA.
Celikyilmaz, D. Hakkani-Tur, and G. Tur.
2011.Leveraging web query logs to learn user intent viabayesian latent variable model.
In ICML?11 - WS onCombining Learning Strategies to Reduce Label Cost.J.
Gao, J.-Y.
Nie, W. Yuan, X. Li, and K. Deng.
2009.Smoothing clickthrough data for web search ranking.In SIGIR?09.T.
Griffiths and Z. Ghahramani.
2005.
Infinite latent fea-ture models and the indian buffet process.
In NIPS?05.D.
Hakkani-Tur, G. Tur, and L. Heck.
2011a.
Exploitingweb search query click logs for utterance domain de-tection in spoken language understanding.
In ICASSP2011.D.
Hakkani-Tur, G. Tur, L. Heck, A. Celikyilmaz, A. Fi-dler, D. Hillard, R. Iyer, and S. Parthasarathy.
2011b.Employing web search query click logs for multi-domain spoken language understanding.
In ASRU?11.D.
Hakkani-Tur, G. Tur, L. Heck, and E. Shriberg.
2011c.Bootstrapping domain detection using query click logsfor new domains.
In Interspeech?11.D.
Hakkani-Tur, G. Tur, R. Iyer, and L. Heck.
2012.Translating natural language utterances to searchqueries for slu domain detection using query clicklogs.
In ICASSP?12.D.
Hillard and C. Leggetter.
2010.
Clicked phrase doc-ument expansion for sponsored search ad retrieval.
InSIGIR?10.D.
Hillard, A. Celikyilmaz, D. Hakkani-Tur, and G. Tur.2011.
Learning weighted entity lists from web clicklogs for slu.
In Interspeech?11.X.
Li, Y.-Y.
Wang, and A. Acero.
2008.
Learning queryintent from regularized click graphs.
In SIGIR08.X.
Li, Y.-Y.
Wang, and A. Acero.
2009.
Extract-ing structured information from user queries withsemi-supervised conditional random fields.
In ACMSIGIT?09.P.
Pantel and A. Fuxman.
2011.
Jigs and lures: Associ-ating web queries with structured entities.
In ACL?11.G.
Tur and R. De Mori, editors.
2011.
Spoken LanguageUnderstanding: Systems for Extracting Semantic In-formation from Speech.
John Wiley and Sons.G.
Tur, D. Hakkani-Tur, D. Hillard, and A. Celikyilmaz.2011.
Towards unsupervised spoken language under-standing: Exploiting query click logs for slot filling.In Interspeech?11.C.
Wang, R. Raina, D. Fong, D. Zhou, J. Han, andG.
Badros.
2011.
Learning relevance from a hetero-geneous social network and application in online tar-geting.
In SIGIR?11.40
