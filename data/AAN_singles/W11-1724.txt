Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 182?188,24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational LinguisticsInstance Level Transfer Learning for Cross Lingual Opinion AnalysisRuifeng Xu, Jun Xu and Xiaolong WangKey Laboratory of Network Oriented Intelligent ComputationDepartment of Computer Science and TechnologyShenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China{xuruifeng,xujun}@hitsz.edu.cn, wangxl@insun.hit.edu.cnAbstractThis paper presents two instance-level transferlearning based algorithms for cross lingualopinion analysis by transferring usefultranslated opinion examples from otherlanguages as the supplementary trainingdata for improving the opinion classifier intarget language.
Starting from the union ofsmall training data in target language andlarge translated examples in other languages,the Transfer AdaBoost algorithm is appliedto iteratively reduce the influence of lowquality translated examples.
Alternatively,starting only from the training data in targetlanguage, the Transfer Self-training algorithmis designed to iteratively select high qualitytranslated examples to enrich the trainingdata set.
These two algorithms are applied tosentence- and document-level cross lingualopinion analysis tasks, respectively.
Theevaluations show that these algorithmseffectively improve the opinion analysis byexploiting small target language training dataand large cross lingual training data.1 IntroductionIn recent years, with the popularity of Web 2.0,massive amount of personal opinions includingcomments, reviews and recommendations in dif-ferent languages have been shared on the Internet.Accordingly, automated opinion analysis hasattracted growing attentions.
Opinion analysis, alsoknown as sentiment analysis, sentiment classifica-tion, and opinion mining, aims to identify opinionsin text and classify their sentiment polarity (Pangand Lee, 2008).Many sentiment resources such as sentimentlexicons (e.g., SentiWordNet (Esuli and Sebastiani,2006))and opinion corpora (e.g., MPQA (Blitzeret al, 2007)) have been developed on differentlanguages in which most of them are for English.The lack of reliably sentiment resources is oneof the core issues in opinion analysis for otherlanguages.
Meanwhile, the manually annotationis costly, thus the amount of available annotatedopinion corpora are still insufficient for supportingsupervised learning, even for English.
These factsmotivate to ?borrow?
the opinion resources in onelanguage (source language, SL) to another language(target language, TL) for improving the opinionanalysis on the target language.Cross lingual opinion analysis (CLOA) tech-niques are investigated to improve opinion analysisin TL through leveraging the opinion-relatedresources, such as dictionaries and annotatedcorpus in SL.
Some CLOA works used bilingualdictionaries (Mihalcea et al, 2007), or alignedcorpus (Kim and Hovy, 2006) to align the expres-sions between source and target languages.
Theseworks are puzzled by the limited aligned opinionresources.
Alternatively, some works used machinetranslation system to do the opinion expressionalignment.
Banea et al (2008) proposed severalapproaches for cross lingual subjectivity analysis bydirectly applying the translations of opinion corpusin source language to train the opinion classifieron target language.
Wan (2009) combined theannotated English reviews, unannotated Chinesereviews and their translations to co-train twoseparate classifiers for each language, respectively.182These works directly used all of the translation ofannotated corpus in source language as the trainingdata for target language without considering thefollowing two problems: (1) the machine translationerrors propagate to following CLOA procedure; (2)The annotated corpora from different languages arecollected from different domains and different writ-ing styles which lead the training and testing datahaving different feature spaces and distributions.Therefore, the performances of these supervisedlearning algorithms are affected.To address these problems, we propose twoinstance level transfer learning based algorithmsto estimate the confidence of translated SL ex-amples and to transfer the promising ones asthe supplementary TL training data.
We firstlyapply Transfer AdaBoost (TrAdaBoost) (Dai etal., 2007) to improve the overall performance withthe union of target and translated source languagetraining corpus.
A boosting-like strategy is usedto down-weight the wrongly classified translatedexamples during iterative training procedure.
Thismethod aims to reduce the negative affection of lowquality translated examples.
Secondly, we proposea new Transfer Self-training algorithm (TrStr).
Thisalgorithm trains the classifier by using only thetarget language training data at the beginning.
Byautomatically labeling and selecting the translatedexamples which is correct classified with higherconfidence, the classifier is iteratively trained byappending new selected training examples.
Thetraining procedure is terminated until no newpromising examples can be selected.
Differen-t from TrAdaBoost, TrStr aims to select highquality translated examples for classifier training.These algorithms are evaluated on sentence- anddocument-level CLOA tasks, respectively.
Theevaluations on simplified Chinese (SC) opinionanalysis by using small SC training data and largetraditional Chinese (TC) and English (EN) trainingdata, respectively, show that the proposed transferlearning based algorithms effectively improve theCLOA.
Noted that, these algorithms are applicableto different language pairs.The rest of this paper is organized as follows.Section 2 describes the transfer learning basedapproaches for opinion analysis.
Evaluations anddiscussions are presented in Section 3.
Finally,Section 4 gives the conclusions and future work.2 CLOA via Transfer LearningGiven a large translated SL opinion training data,the objective of this study is to transfer more highquality training examples for improving the TLopinion analysis rather than use the whole translatedtraining data.
Here, we propose to investigate theinstance level transfer learning based approaches.In the case of transfer learning, the set of trans-lated training SL examples is denoted by Ts ={(xi, yi)}ni=1, and the TL training data is denotedby Tt={(xi, yi)}n+mi=n+1, while the size of Tt is muchsmaller than that of Ts, i.e., |m| ?
|n|.
The ideaof transfer learning is to use Tt as the indicator toestimate the quality of translated examples.
Byappending selected high quality translated examplesas supplement training data, the performance ofopinion analysis on TL is expected to be enhanced.2.1 The TrAdaBoost ApproachTrAdaBoost is an extension of the AdaBoostalgorithm (Freund and Schapir, 1996).
It usesboosting technique to adjust the sample weightautomatically (Dai et al, 2007).
TrAdaBoost joinsboth the source and target language training dataduring learning phase with different re-weightingstrategy.
The base classifier is trained on theunion of the weighted source and target examples,while the training error rate is measured on theTL training data only.
In each iteration, for a SLtraining example, if it is wrongly classified by priorbase classifier, it tends to be a useless examplesor conflict with the TL training data.
Thus, thecorresponding weight will be reduced to decreaseits negative impact.
On the contrary, if a TL trainingexample is wrongly classified, the correspondingweight will be increased to boost it.
The ensembleclassifier is obtained after several iterations.In this study, we apply TrAdaBoost algorithmwith small revision to fit the CLOA task, as de-scribed in Algorithm 1.
Noted that, our revisedalgorithm can handle multi-category problem whichis different with original TrAdaBoost algorithm forbinary classification problem only.
More details andtheoretical analysis of TrAdaBoost are given in Daiet al?s work (Dai et al, 2007).183Algorithm 1 CLOA with TrAdaBoost.Input: Ts, translated opinion training data in SL,n= |Ts|; Tt, training data in TL , m= |Tt|; L,base classifier; K, iteration number.1: Initialize the distribution of training samples:D1(i) = 1/(n+m).2: for each k ?
[1,K] do3: Get a hypothesis hk by training L with thecombined training set Ts ?
Tt using distribu-tion Dk: hk = L(Ts ?
Tt, Dk).4: Calculate the training error of hk on Tt:?t =?n+mi=n+1Dk(i)?I[hk(xi) ?=yi]?n+mi=n+1 Dk(i).5: if ?t = 0 or ?k ?
1/2 then6: K = k ?
1, break.7: end if8: Set ?k = ?k/(1?
?k), ?
= 1/(1 +?2 lnnK ).9: if hk(xi) ?= yi then10: Update the distribution:Dk+1(i) ={ Dk(i)?Zk1 ?
i ?
nDk(i)/?kZkn + 1 ?
i ?
n + m, whereZk is a normalization constant and?n+mi=1 Dk+1(i) = 1.11: end if12: end forOutput: argmaxy?K?K/2?I[hk(x) = y]log(1/?k)/* I[?]
is an indicator function, which equals 1 if theinner expression is true and 0 otherwise.
*/2.2 The Transfer Self-training ApproachDifferent from TrAdaBoost which focuses on thefiltering of low quality translated examples, wepropose a new Transfer Self-training algorithm(TrStr) to iteratively train the classifier throughtransferring high quality translated SL training datato enrich the TL training data.
The flow of thisalgorithm is given in Algorithm 2.The algorithm starts from training a classifieron Tt.
This classifier is then applied to Ts, thetranslated SL training data.
For each category inTs (subjective/objective or positive/negative in ourdifferent experiments), top p correctly classifiedtranslated examples are selected.
These translatedexamples are regarded as high quality ones and thusthey are appended in the TL training data.
Next, theclassifier is re-trained on the enriched training data.The updated classifier is applied to SL examplesagain to select more high quality examples.
SuchAlgorithm 2 CLOA with Transfer Self-training.Input: Ts, translated opinion training data in SL,n= |Ts|; Tt, training data in TL , m= |Tt|; L,base classifier; K, iteration number.1: T0 = Tt, k = 1.2: Get a hypothesis hk by training a base classifierL with the training set Tk?1.3: for each instance (xi, yi) ?
Ts do4: Use hk to label (xi, yi) .5: if ht(xi) = yi then6: Add (xi, yi)to T ?7: end if8: end for9: Choose p instances per class with top confi-dence from T ?
and denote the set as Tp.10: Tk = Tk?1?Tp, Ts = Ts ?
Tp.11: k = k + 1.12: Iterate K times over steps 2 to 11 or repeat untilTp = ?.Output: Final classifier by using the enriched train-ing set Tk.procedure terminates until the increments are lessthan a specified threshold or the maximum numberof iterations is exceeded.
The final classifier isobtained by training on the union of target data andselected high quality translated SL training data.3 Evaluation and DiscussionThe proposed approaches are evaluated on sentence-and document-level opinion analysis tasks in thebi-lingual case, respectively.
In our experiments,the TL is simplified Chinese (SC) and the SL forthe two experiments are English (EN)/traditionalChinese (TC) and EN, respectively.3.1 Experimental Setup3.1.1 DatasetsIn the sentence-level opinionated sentence recog-nition experiment , the dataset is from the NTCIR-7Multilingual Opinion Analysis Tasks (MOAT) (Se-ki et al, 2008) corpora.
The information ofthis dataset is given in Table 1.
Two experi-ments are performed.
The first one is denoted bySenOR : TC ?
SC, which uses TCs as sourcelanguage training dataset, while the second one184is SenOR : EN ?
SC, which uses ENs1.
SCsis shrunk to different scale as the target languagetraining corpus by random.
The opinion analysisresults are evaluated with simplified Chinese testingdataset SCt under lenient and strict evaluationstandard 2, respectively, as described in (Seki et al,2008).Note Lang.
Data Total subjective/objectiveLenient StrictSCs SC Training 424 130/294 \SCt Test 4877 1869/3008 898/2022TCs TC Training 1365 740/625 \ENs EN Training 1694 648/1046 \Table 1: The NTCIR-7 MOAT Corpora(unit:sentence).In the document-level review polarity classifi-cation experiment,, we used the dataset adoptedin (Wan, 2009).
Its English subset is collected byBlitzer et al (2007), which contains a collection of8,000 product reviews about four types of products:books, DVDs, electronics and kitchen appliances.For each type of products, there are 1,000 positivereviews and 1,000 negative ones, respectively.
TheChinese subset has 451 positive reviews and 435negative reviews of electronics products such asmp3 players, mobile phones etc.
In our experiments,the Chinese subset is further split into two partsrandomly: TL training dataset and test set.
Thecross lingual review polarity classification task isthen denoted by DocSC: EN?SC.In this study, Google Translate3 is choose for pro-viding machine translation results.3.1.2 Base Classifier and Baseline MethodsThis study focus on the approaches improving theopinion analysis by using cross lingual examples,while the classifier improving on target language isnot our major target.
Therefore, in the experiments,a Support Vector Machines (SVM) with linearkernel is used as the base classifier.
We use the1There are only 248 sentences in NTCIR-7 MOAT Englishtraining data set.
It is too small to use for CLOA.
We s-plit some samples from the test set to build a new Englishdataset for training, which contains all sentences from topics:N01,N02,T01,N02,N03,N04,N05,N06 and N07.2All sentences are annotated by 3 assessors, strict standardmeans all 3 assessors have the same annotation and lenientmeans any 2 of them have the same annotation.3http://translate.google.com/open source SVM package ?LIBSVM(Chang andLin, 2001) with all default parameters.
In theopinionated sentence recognition experiment, weuse the presences of following linguistic featuresto represent each sentence example includingopinion word, opinion operator, opinion indicator,the unigram and bigram of Chinese words.
It isdeveloped with the reference of (Xu et al, 2008).In the review polarity classification experiment, weuse unigram, bigram of Chinese words as featureswhich is suggested by (Wan, 2009).
Here, documentfrequency is used for feature selection.
Meanwhile,term frequency weighting is chosen for documentrepresentation.In order to investigate the effectiveness of thetwo proposed transfer learning approaches, theyare compared with following baseline methods: (1)NoTr(T), which applies SVM with only TL trainingdata; (2) NoTr(S),which applies SVM classifier withonly the translated SL training data; (3) NoTr(S&T),which applies SVM with the union of TL and SLtraining data.3.1.3 Evaluation CriteriaAccuracy (Acc), precision (P), recall (R) and F-measure (F1) are used as evaluation metrics.
All theperformances are the average of 10 experiments.3.2 Experimental Results and DiscussionHere, the number of iterations in TrAdaBoost is setto 10 in order to avoid over-discarding SL examples.3.2.1 Sentence Level CLOA ResultsThe achieved performance of the opinionatedsentence recognition task under lenient and strictevaluation are given in Table 2 respectively, inwhich only 1/16 target train data is used as Tt.It is shown that NoTr(T) achieves a acceptableaccuracy, but the recall and F1 for ?subjective?category are obviously low.
For the two sub-tasks,i.e.
SenOR : TC ?SC and SenOR :EN ?SCtasks, the accuracies achieved by NoTr(S&T) arealways between that of NoTr(T) and NoTr(S).The reason is that some translated examples fromsource language may likely conflict with the targetlanguage training data.
It is shown that the directuse of all of the translated training data is infeasible.It is also shown that our approaches achieve better185Method Sub-taskLenient Evaluation Strict EvaluationAcc subjective objective Acc subjective objectiveP R F1 P R F1 P R F1 P R F1NoTr(T) .6254 .534 .3468 .355 .6824 .7985 .7115 .6922 .5259 .3900 .3791 .7725 .8264 .7776NoTr(S)TC?SC.6059 .4911 .7828 .6035 .7861 .4960 .6082 .6448 .4576 .8352 .5912 .8845 .5603 .6860NoTr(S&T) .6101 .4943 .7495 .5957 .7711 .5236 .6235 .6531 .4632 .8051 .588 .8714 .5856 .7004TrAdaBoost .6533 .5335 .7751 .6314 .8063 .5777 .6720 .7184 .5273 .8473 .6494 .9077 .6611 .7643TrStr .6625 .5448 .7309 .6238 .7884 .6199 .6934 .7304 .5414 .8182 .6511 .896 .6914 .7801NoTr(S)EN?SC.6590 .5707 .4446 .4998 .6966 .7922 .7413 .7390 .5872 .5100 .5459 .7944 .8408 .8169NoTr(S&T) .6411 .5292 .5759 .5515 .7212 .6817 .7009 .7105 .5254 .608 .5637 .8129 .7560 .7834TrAdaBoost .6723 .5988 .4371 .5018 .7019 .8184 .7549 .7630 .6485 .5019 .5614 .8002 .8789 .8371TrStr .6686 .5691 .5746 .5678 .7360 .7271 .7292 .7484 .589 .6276 .6026 .8315 .8021 .8147Table 2: The Performance of Opinionated Sentence Recognition Task.performance on both tasks while few TL trainingdata is used.
In which, TrStr performances thebest on SenOR:TC?SC task while TrAdaBoostoutperforms other methods on SenOR :EN?SCtask.
The proposed transfer learning approachesenhanced the accuracies achieved by NoTr(S&T)for 4.2-8.6% under lenient evaluation and 5.3-11.8%under strict evaluation, respectively.3.2.2 Document Level CLOA ResultsMethod Acc positive negativeP R F1 P R F1NoTr(T) .7542 .7447 .8272 .7747 .8001 .6799 .7235NoTr(S) .7122 .6788 .8248 .7447 .7663 .5954 .6701NoTr(S&T) .7531 .714 .8613 .7801 .8187 .6415 .7179TrAdaBoost .7704 .8423 .6594 .7376 .7285 .8781 .7954TrStr .7998 .8411 .7338 .7818 .7727 .8638 .8144Table 3: The Results of Chinese Review Polarity Classi-fication Task (Features:Unigrams; m=20).Method Acc positive negativeP R F1 P R F1NoTr(T) .7518 .7399 .8294 .7741 .7983 .6726 .7185NoTr(S) .7415 .7143 .8204 .7637 .7799 .6598 .7148NoTr(S&T) .7840 .7507 .8674 .8035 .8385 .6982 .7592TrAdaBoost .7984 .8416 .7297 .7792 .7707 .8652 .8138TrStr .8022 .8423 .7393 .7843 .7778 .8634 .8164Table 4: The Results of Chinese Review Polarity Classi-fication Task (Features:Unigrams+Bigrams; m=20).Table 3 and Table 4 give the achieved results ofdifferent methods on the task DocSC : EN?SCby using 20 Chinese annotated reviews as Tt.
It isshown that transfer learning approaches outperformother methods, in which TrStr performs better thanTrAdaBoost when unigram+bigram features areused.
Compared to NoTr(T&S), the accuraciesare increased about 1.8-6.2% relatively.
Overall,the transfer learning approaches are shown arebeneficial to TL polarity classification.3.2.3 Influences of Target Training Corpus Size0.560.580.60.620.640.660.680.70.721/32 1/16 1/8 1/4 1/2 1AccuracySize of  Target Languae Training Data (SCs)NoTr(T)NoTr(T&S) TrAdaBoostTransfer Self-training(a) SenOR : TC ?
SC0.560.580.60.620.640.660.680.70.721/32 1/16 1/8 1/4 1/2 1AccuracySize of  Target Languae Training Data (SCs)NoTr(T)NoTr(T&S) TrAdaBoostTransfer Self-training(b) SenOR : EN ?
SCFigure 1: Performances with Different Size of SCs onOpinionated Sentence Recognition Task under Lenient E-valuationIn order to estimate the influence of different sizeof TL training data, we conduct a set of experimentson both tasks.
Fig 1 and Fig 2 show the influence1860.60.650.70.750.80.8510  20  30  40  50  60  70  80  90  100AccuracyNumber of Target Training InstancesTransfer Self-trainingTrAdaBoostNoTr(S&T)NoTr(T)(a) Unigrams0.60.650.70.750.80.8510  20  30  40  50  60  70  80  90  100AccuracyNumber of Target Training InstancesTransfer Self-trainingTrAdaBoostNoTr(S&T)NoTr(T)(b) Unigrams+BigramsFigure 3: Performances with Different Number of TL Training Instances on Task of DocSC: EN?SC0.60.650.70.750.81/32 1/16 1/8 1/4 1/2 1AccuracySize of  Target Languae Training Data (SCs)NoTr(T)NoTr(T&S) TrAdaBoostTransfer Self-training(a) SenOR : TC ?
SC0.60.650.70.750.81/32 1/16 1/8 1/4 1/2 1AccuracySize of  Target Languae Training Data (SCs)NoTr(T)NoTr(T&S) TrAdaBoostTransfer Self-training(b) SenOR : EN ?
SCFigure 2: Performances with Different Size of SCs onOpinionated Sentence Recognition Task under Strict E-valuationon the opinionated sentence recognition task underlenient and strict evaluation respectively.
Fig 3shows the influence on task DocSC : EN ?SC.Fig 3(a) shows the results use unigram featuresand Fig 3(b) uses both unigrams and bigrams.
It isobserved that TrAdaBoost and TrStr achieve betterperformances than the baseline NoTr(S&T) in mostcases.
More specifically, TrStr performs the bestwhen few TL training data is used.
When more TLtraining data is used, the performance improvementsby transfer learning approaches become small.
Thereason is that less target training data is helpful totransfer useful knowledge in translated examples.If too much TL training data is used, the weightsof SL instances may decrease exponentially afterseveral iterations, and thus more source trainingdata is not obviously helpful.4 Conclusions and Future WorkTo address the problems in CLOA caused by inac-curate translations and different domain/categorydistributions between training data in differentlanguages, two transfer learning based algorithmsare investigated to transfer promising translated SLtraining data for improving the TL opinion analysis.In this study, Transfer AdaBoost and TransferSelf-Training algorithms are investigated to reducethe influences of low quality translated examplesand to select high quality translated examples,respectively.
The evaluations on sentence- anddocument-level opinion analysis tasks show that theproposed algorithms improve opinion analysis byusing the union of few TL training data and selectedcross lingual training data.One of our future directions is to develop othertransfer leaning algorithms for CLOA task.
Anotherfuture direction is to employ other moderate weight-ing scheme on source training dataset to reduce theover-discarding of training examples from sourcelanguage.187ReferencesBo Pang and Lillian Lee.
2008.
Opinion miningand sentiment analysis.
Foundations and Trendsin Information Retrieval, 2(1?2):1?135.Andrea Esuli and Fabrizio Sebastiani.
2006.
SENTI-WORDNET: A publicly available lexical resourcefor opinion mining.
Proceedings of the 5th Inter-national Conference on Language Resources andEvaluation, 417?422.Janyce Wiebe, Theresa Wilson, and Claire Cardie.2005.
Annotating expressions of opinions and e-motions in language.
Language Resources and E-valuation, 39(2?3):165?210.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.2007.
Learning multilingual subjective languagevia cross-lingual projections.
Proceedings of the45th Annual Meeting of the Association of Com-putational Linguistics, Prague, Czech Republic.Soo-Min Kim and Eduard Hovy.
2006.
Identifyingand analyzing judgment opinions.
Proceedings ofHLT/NAACL-2006, 200?207.Carmen Banea, Rada Mihalcea, Janyce Wiebe andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
Proceedingsof the 2008 Conference on Empirical Methods inNatural Language Processing, Honolulu, Hawaii,127?135.Xiaojun Wan.
2009.
Co-training for cross-lingualsentiment classification.
Proceedings of the 47thAnnual Meeting of the ACL and the 4th IJCNLPof the AFNLP, Suntec, Singapore, 235?243.Wenyuan Dai ,Qiang Yang, GuiRong Xue and YongYu.
2007.
Boosting for transfer learning.
Pro-ceedings of the 24th International Conference onMachine Learning, 193?200.John Blitzer, Mark Dredze, and Fernando Pereira.2007.
Biographies, bollywood, boom-boxes andblenders: domain adaptation for sentiment classi-fication.
Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics,440?447.Xiaojun Wan.
2008.
Using bilingual knowledgeand ensemble techniques for unsupervised chi-nese sentiment analysis.
Proceedings of EMNLP2008,553?561.Yoav Freund and Robert E. Schapire.
1996.
Experi-ments with a new boosting algorithm.
Proceedingsof the 13th International Conference on MachineLearning, 148?156.Yohei Seki, David K. Evans, Lun-Wei Ku, Le Sun,Hsin-Hsi Chen, and Noriko Kand.
2008.
Overviewof multilingual opinion analysis task at NTCIR-7.Proceeding of NTCIR-7, NII, Tokyo, 185?203.Ruifeng Xu, Kam-Fai Wong, Qin Lu, and YunqingXia 2008.
Learning Multilinguistic Knowledgefor Opinion Analysis.
D. S. Huang et al, edi-tors:Proceedings of ICIC 2008, volume 5226 of L-NCS, 993?1000, Springer-Verlag.Chih-Chung Chang and Chih-Jen Lin.2001.
LIBSVM: a library for supportvector machines.
Software available athttp://www.csie.ntu.edu.tw/ cjlin/libsvm.188
