Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 430?435,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsA Shortest-path Method for Arc-factored Semantic Role LabelingXavier Llu?
?sTALP Research CenterUniversitat Polit`ecnica deCatalunyaxlluis@cs.upc.eduXavier CarrerasXerox Research CentreEuropexavier.carreras@xrce.xerox.comLlu?
?s M`arquezALT Research GroupQatar Computing ResearchInstitutelmarquez@qf.org.qaAbstractWe introduce a Semantic Role Labeling(SRL) parser that finds semantic roles for apredicate together with the syntactic pathslinking predicates and arguments.
Ourmain contribution is to formulate SRL interms of shortest-path inference, on the as-sumption that the SRL model is restrictedto arc-factored features of the syntacticpaths behind semantic roles.
Overall, ourmethod for SRL is a novel way to ex-ploit larger variability in the syntactic re-alizations of predicate-argument relations,moving away from pipeline architectures.Experiments show that our approach im-proves the robustness of the predictions,producing arc-factored models that per-form closely to methods using unrestrictedfeatures from the syntax.1 IntroductionSemantic role labeling (SRL) consists of findingthe arguments of a predicate and labeling themwith semantic roles (Gildea and Jurafsky, 2002;M`arquez et al., 2008).
The arguments fill roles thatanswer questions of the type ?who?
did ?what?
to?whom?, ?how?, and ?why?
for a given sentencepredicate.
Most approaches to SRL are based ona pipeline strategy, first parsing the sentence toobtain a syntactic tree and then identifying andclassifying arguments (Gildea and Jurafsky, 2002;Carreras and M`arquez, 2005).SRL methods critically depend on features ofthe syntactic structure, and consequently parsingmistakes can harm the quality of semantic rolepredictions (Gildea and Palmer, 2002).
To allevi-ate this dependence, previous work has exploredk-best parsers (Johansson and Nugues, 2008),combination systems (Surdeanu et al., 2007) orjoint syntactic-semantic models (Johansson, 2009;Henderson et al., 2008; Llu?
?s et al., 2013).In this paper we take a different approach.
Inour scenario SRL is the end goal, and we as-sume that syntactic parsing is only an intermedi-ate step to extract features to support SRL predic-tions.
In this setting we define a model that, givena predicate, identifies each of the semantic rolestogether with the syntactic path that links the pred-icate with the argument.
Thus, following previouswork (Moschitti, 2004; Johansson, 2009), we takethe syntactic path as the main source of syntac-tic features, but instead of just conditioning on it,we predict it together with the semantic role.
Themain contribution of this paper is a formulation ofSRL parsing in terms of efficient shortest-path in-ference, under the assumption that the SRL modelis restricted to arc-factored features of the syntac-tic path linking the argument with the predicate.Our assumption ?that features of an SRLmodel should factor over dependency arcs?
issupported by some empirical frequencies.
Table 1shows the most frequent path patterns on CoNLL-2009 (Haji?c et al., 2009) data for several lan-guages, where a path pattern is a sequence of as-cending arcs from the predicate to some ancestor,followed by descending arcs to the argument.
ForEnglish the distribution of path patterns is rathersimple: the majority of paths consists of a num-ber of ascending arcs followed by zero or one de-scending arc.
Thus a common strategy in SRL sys-tems, formulated by Xue and Palmer (2004), is tolook for arguments in the ancestors of the pred-icate and their direct descendants.
However, inCzech and Japanese data we observe a large por-tion of paths with two or more descending arcs,which makes it difficult to characterize the syn-tactic scope in which arguments are found.
Also,in the datasets for German, Czech and Chinese thethree most frequent patterns cover over the 90% ofall arguments.
In contrast, Japanese exhibits muchmore variability and a long tail of infrequent types430English German Czech Chinese Japanese?% % path?% % path?% % path?% % path?% % path63.63 63.6298 ?
77.22 77.2202 ?
63.90 63.8956 ?
78.09 78.0949 ?
37.20 37.1977 ?
?73.97 10.3429 ??
93.51 16.2854 ??
86.26 22.3613 ??
85.36 7.26962 ??
51.52 14.3230 ?80.63 6.65915 ?
97.43 3.92111 ???
90.24 3.98078 ??
91.27 5.90333 ???
60.79 9.27270 ??
?85.97 5.33352 ?
98.19 0.76147 ??
93.95 3.71713 ???
95.93 4.66039 ??
70.03 9.23857 ?90.78 4.81104 ???
98.70 0.51640 ????
95.48 1.52168 ???
97.53 1.60392 ?
74.17 4.13359 ???
?93.10 2.31928 ????
99.17 0.46096 ?
96.92 1.44091 ?
98.28 0.75086 ????
76.76 2.59117 ?
?95.19 2.09043 ??
99.43 0.26841 ???
97.68 0.76714 ???
98.77 0.48734 ??
78.82 2.06111 ???
?96.26 1.07468 ?????
99.56 0.12837 ????
98.28 0.59684 ????
99.13 0.36270 ???
80.85 2.03381 ????
?97.19 0.92482 ??
99.67 0.10503 ?????
98.60 0.31759 ????
99.45 0.31699 ?????
82.66 1.80631 ??
?97.93 0.74041 ???
99.77 0.10503 ??
98.88 0.28227 ????
99.72 0.27041 ????
83.71 1.05558 ??
?98.41 0.48565 ??????
99.82 0.04960 ???
99.15 0.26721 ????
99.82 0.10049 ???
84.74 1.02828 ????
?98.71 0.29769 ????
99.87 0.04960 ???
99.27 0.12430 ?????
99.86 0.03623 ???
85.68 0.93500 ????
?98.94 0.22733 ???????
99.90 0.02626 ?
99.37 0.10103 ?????
99.89 0.02890 ????
86.61 0.93273 ?????
?99.11 0.17805 ???
99.92 0.02042 ?????
99.47 0.09747 ??
99.92 0.02890 ??????
87.29 0.68249 ?????
?99.27 0.15316 ???
99.94 0.02042 ??????
99.56 0.08515 ?????
99.94 0.02846 ?
87.90 0.60969 ???
?99.39 0.12065 ?????
99.95 0.01459 ?????
99.63 0.07419 ?????
99.96 0.02070 ?????
88.47 0.56646 ?????
?99.50 0.11024 ????
99.96 0.01167 ????
99.69 0.05667 ?????
99.97 0.00992 ?????
89.01 0.53689 ??????
?99.60 0.09931 ????????
99.97 0.00875 ????
99.73 0.04216 ??????
99.98 0.00733 ???????
89.49 0.48684 ?????
?99.65 0.05283 ????
99.98 0.00875 ???????
99.76 0.02875 ??????
99.99 0.00431 ??????
89.94 0.45044 ???
?Table 1: Summary of the most frequent paths on the CoNLL-2009 Shared Task datasets.
?
indicates that we traverse a syntacticdependency upwards from a modifier to a head.
?
is for dependencies following a descending head to modifier edge.
Thesymbol ?
represents that the argument is the predicate itself.
We exclude from this table Catalan and Spanish as predicates andarguments are always trivially related by a single syntactic dependency that descends.of patterns.
In general it is not feasible to capturepath patterns manually, and it is not desirable thata statistical system depends on rather sparse non-factored path features.
For this reason in this paperwe explore arc-factored models for SRL.Our method might be specially useful in appli-cations were we are interested in some target se-mantic role, i.e.
retrieving agent relations for someverb, since it processes semantic roles indepen-dently of each other.
Our method might also begeneralizable to other kinds of semantic relationswhich strongly depend on syntactic patterns suchas relation extraction in information extraction ordiscourse parsing.2 Arc-factored SRLWe define an SRL parsing model that re-trieves predicate-argument relations based on arc-factored syntactic representations of paths con-necting predicates with their arguments.
Through-out the paper we assume a fixed sentence x =x1, .
.
.
, xnand a fixed predicate index p. TheSRL output is an indicator vector z, wherezr,a= 1 indicates that token a is filling roler for predicate p. Our SRL parser performsargmaxz?Z(x,p)s(x, p, z), where Z(x, p) definesthe set of valid argument structures for p, ands(x, p, z) computes a plausibility score for z givenx and p. Our first assumption is that the scorefunction factors over role-argument pairs:s(x, p, z) =?zr,a=1s(x, p, r, a) .
(1)Then we assume two components in the model,one that scores the role-argument pair alone, andanother that considers the best (max) syntactic de-pendency pathpi that connects the predicate pwiththe argument a:s(x, p, r, a) = s0(x, p, r, a) +maxpissyn(x, p, r, a,pi) .
(2)The model does not assume access to the syntac-tic structure of x, hence in Eq.
(2) we locally re-trieve the maximum-scoring path for an argument-role pair.
A path pi is a sequence of dependencies?h,m, l?
where h is the head, m the modifier and lthe syntactic label.
We further assume that the syn-tactic component factors over the dependencies inthe path:ssyn(x, p, r, a,pi)=??h,m,l?
?pissyn(x, p, r, a, ?h,m, l?)
.
(3)This will allow to employ efficient shortest-pathinference, which is the main contribution of thispaper and is described in the next section.
Notethat since paths are locally retrieved per role-argument pair, there is no guarantee that the setof paths across roles forms a (sub)tree.As a final note, in this paper we follow Llu?
?set al.
(2013) and consider a constrained space ofvalid argument structures Z(x, p): (a) each role isrealized at most once, and (b) each token fills atmost one role.
As shown by Llu?
?s et al.
(2013),this can be efficiently solved as a linear assign-431Figure 1: Graph representing all possible syntactic pathsfrom a single predicate to their arguments.
We find in thisgraph the best SRL using a shortest-path algorithm.
Note thatmany edges are omitted for clarity reasons.
We labeled thenodes and arcs as follows: p is the predicate and source ver-tex; u1, .
.
.
, unare tokens reachable by an ascending path;v1, .
.
.
, vnare tokens reachable by a ascending path (possi-bly empty) followed by a descending path (possibly empty);ai?jis an edge related to an ascending dependency fromnode uito node uj; di?jis a descending dependency fromnode vito node vj; 0i?iis a 0-weighted arc that connects theascending portion of the path ending at uiwith the descend-ing portion of the path starting at vi.ment problem as long as the SRL model factorsover role-argument pairs, as in Eq.
(1).3 SRL as a Shortest-path ProblemWe now focus on solving the maximization oversyntactic paths in Eq.
(2).
We will turn it into aminimization problem which can be solved with apolynomial-cost algorithm, in our case a shortest-path method.
Assume a fixed argument and role,and define ?
?h,m,l?to be a non-negative penalty forthe syntactic dependency ?h,m, l?
to appear in thepredicate-argument path.
We describe a shortest-path method that finds the path of arcs with thesmaller penalty:minpi??h,m,l??pi??h,m,l?.
(4)We find these paths by appropriately constructinga weighted graph G = (V,E) that represents theproblem.
Later we show how to adapt the arc-factored model scores to be non-negative penal-ties, such that the solution to Eq.
(4) will be thenegative of the maximizer of Eq.
(2).It remains only to define the graph construc-tion where paths correspond to arc-factored edgesweighted by ?
penalties.
We start by noting thatany path from a predicate p to an argument viisformed by a number of ascending syntactic arcsfollowed by a number of descending arcs.
The as-cending segment connects p to some ancestor q (qmight be p itself, which implies an empty ascend-ing segment); the descending segment connects qwith vi(which again might be empty).
To com-pactly represent all these possible paths we definethe graph as follows (see Figure 1):1.
Add node p as the source node of the graph.2.
Add nodes u1, .
.
.
, unfor every token of thesentence except p.3.
Link every pair of these nodes ui, ujwith adirected edge ai?jweighted by the corre-sponding ascending arc, namely minl?
?j,i,l?.Also add ascending edges from p to any uiweighted by minl??i,p,l?.
So far we havea connected component representing all as-cending path segments.4.
Add nodes v1, .
.
.
, vnfor every token of thesentence except p, and add edges di?jbe-tween them weighted by descending arcs,namely minl??i,j,l?.
This adds a secondstrongly-connected component representingdescending path segments.5.
For each i, add an edge from uito viwithweight 0.
This ensures that ascending anddescending path segments are connected con-sistently.6.
Add direct descending edges from p to all thevinodes to allow for only-descending paths,weighted by minl?
?p,i,l?.Dijkstra?s algorithm (Dijkstra, 1959) will findthe optimal path from predicate p to all tokens intime O(V2) (see Cormen et al.
(2009) for an in-depth description).
Thus, our method runs thisalgorithm for each possible role of the predicate,obtaining the best paths to all arguments at eachrun.4 Adapting and Training Model ScoresThe shortest-path problem is undefined if a nega-tive cycle is found in the graph as we may indefi-nitely decrease the cost of a path by looping overthis cycle.
Furthermore, Dijkstra?s algorithm re-quires all arc scores to be non-negative penalties.However, the model in Eq.
(3) computes plausibil-ity scores for dependencies, not penalties.
And, ifwe set this model to be a standard feature-basedlinear predictor, it will predict unrestricted real-valued scores.One approach to map plausibility scores topenalties is to assume a log-linear form for our432model.
Let us denote by x?
the tuple ?x, p, r, a?,which we assume fixed in this section.
The log-linear model predicts:Pr(?h,m, l?
| x?)
=exp{w ?
f(x?, ?h,m, l?)}Z(x?
),(5)where f(x?, ?h,m, l?)
is a feature vector for anarc in the path, w are the parameters, and Z(x?
)is the normalizer.
We can turn predictions intonon-negative penalties by setting ?
?h,m,l?to bethe negative log-probability of ?h,m, l?
; namely?
?h,m,l?= ?w ?
f(x?, ?h,m, l?)
+ logZ(x?).
Notethat logZ(x?)
shifts all values to the non-negativeside.However, log-linear estimation of w is typicallyexpensive since it requires to repeatedly com-pute feature expectations.
Furthermore, our modelas defined in Eq.
(2) combines arc-factored pathscores with path-independent scores, and it is de-sirable to train these two components jointly.
Weopt for a mistake-driven training strategy basedon the Structured Averaged Perceptron (Collins,2002), which directly employs shortest-path infer-ence as part of the training process.To do so we predict plausibility scores for a de-pendency directly as w ?
f(x?, ?h,m, l?).
To mapscores to penalties, we define?0= max?h,m,l?w ?
f(x?, ?h,m, l?
)and we set?
?h,m,l?= ?w ?
f(x?, ?h,m, l?)
+ ?0.Thus, ?0has a similar purpose as the log-normalizer Z(x?)
in a log-linear model, i.e., itshifts the negated scores to the positive side; butin our version the normalizer is based on the maxvalue, not the sum of exponentiated predictions asin log-linear models.
If we set our model functionto bessyn(x?, ?h,m, l?)
= w ?
f(x?, ?h,m, l?)?
?0then the shortest-path method is exact.5 ExperimentsWe present experiments using the CoNLL-2009Shared Task datasets (Haji?c et al., 2009), for theverbal predicates of English.
Evaluation is basedon precision, recall and F1over correct predicate-argument relations1.
Our system uses the fea-ture set of the state-of-the-art system by Johansson(2009), but ignoring the features that do not factorover single arcs in the path.The focus of these experiments is to see the per-formance of the shortest-path method with respectto the syntactic variability.
Rather than runningthe method with the full set of possible depen-dency arcs in a sentence, i.e.
O(n2), we only con-sider a fraction of the most likely dependencies.To do so employ a probabilistic dependency-basedmodel, following Koo et al.
(2007), that computesthe distribution over head-label pairs for a givenmodifier, Pr(h, l | x,m).
Specifically, for eachmodifier token we only consider the dependenciesor heads whose probability is above a factor ?
ofthe most likely dependency for the given modi-fier.
Thus, ?
= 1 selects only the most likely de-pendency (similar to a pipeline system, but with-out enforcing tree constraints), and as ?
decreasesmore dependencies are considered, to the pointwhere ?
= 0 would select all possible dependen-cies.
Table 2 shows the ratio of dependencies in-cluded with respect to a pipeline system for the de-velopment set.
As an example, if we set ?
= 0.5,for a given modifier we consider the most likelydependency and also the dependencies with proba-bility larger than 1/2 of the probability of the mostlikely one.
In this case the total number of depen-dencies is 10.3% larger than only considering themost likely one.Table 3 shows results of the method on develop-ment data, when training and testing with different?
values.
The general trend is that testing with themost restricted syntactic graph results in the bestperformance.
However, we observe that as we al-low for more syntactic variability during training,the results largely improve.
Setting ?
= 1 for bothtraining and testing gives a semantic F1of 75.9.This configuration is similar to a pipeline approachbut considering only factored features.
If we allowto train with ?
= 0.1 and we test with ?
= 1 theresults improve by 1.96 points to a semantic F1of 77.8 points.
When syntactic variability is toolarge, e.g., ?
= 0.01, no improvements are ob-served.Finally, table 4 shows results on the verbal En-glish WSJ test set using our best configuration1Unlike in the official CoNLL-2009 evaluation, in thiswork we exclude the predicate sense from the features andthe evaluation.433Threshold ?
1 0.9 0.5 0.1 0.01Ratio 1 1.014 1.103 1.500 2.843Table 2: Ratio of additional dependencies in the graphs withrespect to a single-tree pipeline model (?
= 1) on develop-ment data.Threshold prec (%) rec (%) F1training ?
= 11 77.91 73.97 75.890.9 77.23 74.17 75.670.5 73.30 75.03 74.160.1 58.22 68.75 63.050.01 32.83 53.69 40.74training ?
= 0.51 81.17 73.57 77.180.9 80.74 73.78 77.100.5 78.40 74.79 76.550.1 65.76 71.61 68.560.01 42.95 57.68 49.24training ?
= 0.11 84.03 72.52 77.850.9 83.76 72.66 77.820.5 82.75 73.33 77.750.1 77.25 72.20 74.640.01 63.90 65.98 64.92training ?
= 0.011 81.62 69.06 74.820.9 81.45 69.19 74.820.5 80.80 69.80 74.900.1 77.92 68.94 73.160.01 74.12 65.92 69.78Table 3: Results of our shortest-path system for differentnumber of allowed dependencies showing precision, recalland F1on development set for the verbal predicates of theEnglish language.from the development set.
We compare to thestate-of-the art system by Zhao et al.
(2009) thatwas the top-performing system for the English lan-guage in SRL at the CoNLL-2009 Shared Task.We also show the results for a shortest-path systemtrained and tested with ?
= 1.
In addition we in-clude an equivalent pipeline system using all fea-tures, both factored and non-factored, as definedin Johansson (2009).
We observe that by not be-ing able to capture non-factored features the finalperformance drops by 1.6 F1points.6 ConclusionsWe have formulated SRL in terms of shortest-path inference.
Our model predicts semantic rolestogether with associated syntactic paths, and as-sumes an arc-factored representation of the path.This property allows for efficient shortest-path al-System prec(%) rec(%) F1Zhao et al.
2009 86.91 81.22 83.97Non-factored 86.96 75.92 81.06Factored ?
= 1 79.88 76.12 77.96Factored best 85.26 74.41 79.46Table 4: Test set results for verbal predicates of the in-domainEnglish dataset.
The configurations are labeled as follows.Factored ?
= 1: our shortest-path system trained and testedwith ?
= 1, similar to a pipeline system but without en-forcing tree constraints and restricted to arc-factored features.Factored best: our shortest-path system with the best resultsfrom table 3.
Non-factored: an equivalent pipeline systemthat includes both factored and non-factored features.gorithms that, given a predicate and a role, retrievethe most likely argument and its path.In the experimental section we prove the fea-sibility of the approach.
We observe that arc-factored models are in fact more restricted, with adrop in accuracy with respect to unrestricted mod-els.
However, we also observe that our methodlargely improves the robustness of the arc-factoredmethod when training with a degree of syntac-tic variability.
Overall, ours is a simple strategyto bring arc-factored models close to the perfor-mance of unrestricted models.
Future work shouldexplore further approaches to parse partial syntac-tic structure specific to some target semantic rela-tions.AcknowledgmentsThis work was financed by the European Com-mission for the XLike project (FP7-288342); andby the Spanish Government for projects Tacardi(TIN2012-38523-C02-00) and Skater (TIN2012-38584-C06-01).
For a large part of this workXavier Carreras was at the Universitat Polit`ecnicade Catalunya under a Ram?on y Cajal contract(RYC-2008-02223).ReferencesXavier Carreras and Llu?
?s M`arquez.
2005.
Intro-duction to the CoNLL-2005 shared task: Semanticrole labeling.
In Proceedings of the Ninth Confer-ence on Computational Natural Language Learning(CoNLL-2005), pages 152?164, Ann Arbor, Michi-gan, June.
Association for Computational Linguis-tics.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In Proceedingsof the 2002 Conference on Empirical Methods in434Natural Language Processing, pages 1?8.
Associ-ation for Computational Linguistics, July.Thomas H. Cormen, Charles E. Leiserson, Ronald L.Rivest, and Clifford Stein.
2009.
Introduction toAlgorithms.
The MIT Press.Edsger W. Dijkstra.
1959.
A note on two problemsin connexion with graphs.
Numerische Mathematik,1(1):269?271.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3):245?288, September.Daniel Gildea and Martha Palmer.
2002.
The necessityof parsing for predicate argument recognition.
InProceedings of 40th Annual Meeting of the Associa-tion for Computational Linguistics, pages 239?246,Philadelphia, Pennsylvania, USA, July.
Associationfor Computational Linguistics.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, Pavel Stra?n?ak, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic depen-dencies in multiple languages.
In Proceedings ofthe 13th Conference on Computational Natural Lan-guage Learning (CoNLL-2009), June 4-5, Boulder,Colorado, USA.James Henderson, Paola Merlo, Gabriele Musillo, andIvan Titov.
2008.
A latent variable model of syn-chronous parsing for syntactic and semantic depen-dencies.
In Proceedings of CoNLL-2008 SharedTask.Richard Johansson and Pierre Nugues.
2008.Dependency-based syntactic?semantic analysis withpropbank and nombank.
In CoNLL 2008: Pro-ceedings of the Twelfth Conference on Computa-tional Natural Language Learning, pages 183?187,Manchester, England, August.
Coling 2008 Orga-nizing Committee.Richard Johansson.
2009.
Statistical bistratal depen-dency parsing.
In Proceedings of the 2009 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 561?569, Singapore, August.
As-sociation for Computational Linguistics.Terry Koo, Amir Globerson, Xavier Carreras, andMichael Collins.
2007.
Structured prediction mod-els via the matrix-tree theorem.
In Proceedingsof the 2007 Joint Conference on Empirical Meth-ods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 141?150, Prague, Czech Republic,June.
Association for Computational Linguistics.Xavier Llu?
?s, Xavier Carreras, and Llu?
?s M`arquez.2013.
Joint Arc-factored Parsing of Syntactic andSemantic Dependencies.
Transactions of the As-sociation for Computational Linguistics (TACL),1(1):219?230, May.Llu?
?s M`arquez, Xavier Carreras, Kenneth C.Litkowski, and Suzanne Stevenson.
2008.
SemanticRole Labeling: An Introduction to the Special Issue.Computational Linguistics, 34(2):145?159, June.Alessandro Moschitti.
2004.
A study on convolutionkernels for shallow statistic parsing.
In Proceedingsof the 42nd Meeting of the Association for Compu-tational Linguistics (ACL?04), Main Volume, pages335?342, Barcelona, Spain, July.Mihai Surdeanu, Llu?
?s M`arquez, Xavier Carreras, andPere R. Comas.
2007.
Combination strategies forsemantic role labeling.
Journal of Artificial Intelli-gence Research.Nianwen Xue and Martha Palmer.
2004.
Calibrat-ing features for semantic role labeling.
In DekangLin and Dekai Wu, editors, Proceedings of EMNLP2004, pages 88?94, Barcelona, Spain, July.
Associ-ation for Computational Linguistics.Hai Zhao, Wenliang Chen, Jun?ichi Kazama, KiyotakaUchimoto, and Kentaro Torisawa.
2009.
Multi-lingual dependency learning: Exploiting rich fea-tures for tagging syntactic and semantic dependen-cies.
In Proceedings of the Thirteenth Confer-ence on Computational Natural Language Learning(CoNLL 2009): Shared Task, pages 61?66, Boulder,Colorado, June.
Association for Computational Lin-guistics.435
