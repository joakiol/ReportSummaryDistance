Proceedings of NAACL-HLT 2013, pages 540?549,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsModeling Syntactic and Semantic Structures in Hierarchical Phrase-basedTranslationJunhui LiUniversity of MarylandCollege Park, USAlijunhui@umiacs.umd.eduPhilip ResnikUniversity of MarylandCollege Park, USAresnik@umd.eduHal Daume?
IIIUniversity of MarylandCollege Park, USAhal@umiacs.umd.eduAbstractIncorporating semantic structure into alinguistics-free translation model is chal-lenging, since semantic structures areclosely tied to syntax.
In this paper, wepropose a two-level approach to exploitingpredicate-argument structure reordering in ahierarchical phrase-based translation model.First, we introduce linguistically motivatedconstraints into a hierarchical model, guidingtranslation phrase choices in favor of thosethat respect syntactic boundaries.
Second,based on such translation phrases, we proposea predicate-argument structure reorderingmodel that predicts reordering not onlybetween an argument and its predicate, butalso between two arguments.
Experiments onChinese-to-English translation demonstratethat both advances significantly improvetranslation accuracy.1 IntroductionHierarchical phrase-based (HPB) translation mod-els (Chiang, 2005; Chiang, 2007) that utilize syn-chronous context free grammars (SCFG) have beenwidely adopted in statistical machine translation(SMT).
Although formally syntactic, such modelsrarely respect linguistically-motivated syntax, andhave no formal notion of semantics.
As a re-sult, they tend to produce translations containingboth grammatical errors and semantic role confu-sions.
Our goal is to take advantage of syntacticand semantic parsing to improve translation qual-ity of HPB translation models.
Rather than intro-ducing semantic structure into the HPB model di-rectly, we construct an improved translation modelby incorporating linguistically motivated syntacticconstraints into a standard HPB model.
Once thetranslation phrases are linguistically constrained, weare able to propose a predicate-argument reorder-ing model.
This reordering model aims to solvetwo problems: ensure that arguments are orderedproperly after translation, and to ensure that theproper argument structures even exist, for instancein the case of PRO-drop languages.
Experimentalresults on Chinese-to-English translation show thatboth the hard syntactic constraints and the predicate-argument reordering model obtain significant im-provements over the syntactically and semanticallyuninformed baseline.In principle, semantic frames (or, more specifi-cally, predicate-argument structures: PAS) seem tobe a promising avenue for translational modeling.While languages might diverge syntactically, theyare less likely to diverge semantically.
This haspreviously been recognized by Fung et al(2006),who report that approximately 84% of semanticrole mappings remained consistent across transla-tions between English and Chinese.
Subsequently,Zhuang and Zong (2010) took advantage of thisconsistency to jointly model semantic frames onChinese/English bitexts, yielding improved framerecognition accuracy on both languages.While there has been some encouraging work onintegrating syntactic knowledge into Chiang?s HPBmodel, modeling semantic structure in a linguisti-cally naive translation model is a challenge, becausethe semantic structures themselves are syntacticallymotivated.
In previous work, Liu and Gildea (2010)model the reordering/deletion of source-side seman-tic roles in a tree-to-string translation model.
Whileit is natural to include semantic structures in a tree-based translation model, the effect of semantic struc-tures is presumably limited, since tree templatesthemselves have already encoded semantics to some540extent.
For example, template (VP (VBG giving)NP#1 NP#2) entails NP#1 as receiver and NP#2 asthing given.
Xiong et al(2012) model the reorder-ing between predicates and their arguments by as-suming arguments are translated as a unit.
However,they only considered the reordering between argu-ments and their predicates.2 Syntactic Constraints for HPBTranslation ModelIn this section, we briefly review the HPB model,then present our approach to incorporating syntacticconstraints into it.2.1 HPB Translation ModelIn HPB models, synchronous rules take the formX ?
?
?, ?,?
?, where X is the non-terminal sym-bol, ?
and ?
are strings of lexical items and non-terminals in the source and target side, respectively,and ?
indicates the one-to-one correspondence be-tween non-terminals in ?
and ?.
Each such ruleis associated with a set of translation model fea-tures {?i}, including phrase translation probabil-ity p (?
| ?)
and its inverse p (?
| ?
), the lexicaltranslation probability plex (?
| ?)
and its inverseplex (?
| ?
), and a rule penalty that affects prefer-ence for longer or shorter derivations.
Two otherwidely used features are a target language modelfeature and a target word penalty.Given a derivation d, its translation probability isestimated as:P (d) ?
?i?i (d)?i(1)where ?i is the corresponding weight of feature ?i.See (Chiang, 2007) for more details.2.2 Syntactic ConstraintsTranslation rules in an HPB model are extractedfrom initial phrase pairs, which must include at leastone word inside one phrase aligned to a word insidethe other, such that no word inside one phrase canbe aligned to a word outside the other phrase.
Itis not surprising to observe that initial phrases fre-quently are non-intuitive and inconsistent with lin-guistic constituents, because they are based only onstatistical word alignments.
Nothing in the frame-work actually requires linguistic knowledge.Koehn et al(2003) conjectured that such non-intuitive phrases do not help in translation.
Theytested this conjecture by restricting phrases to syn-tactically motivated constituents on both the sourceand target side: only those initial phrase pairs aresubtrees in the derivations produced by the model.However, their phrase-based translation experiments(on Europarl data) showed the restriction to syn-tactic constituents is actually harmful, because toomany phrases are eliminated.
The idea of hard syn-tactic constraints then seems essentially to have beenabandoned: it doesn?t appear in later work.On the face of it, there are many possible rea-sons Koehn et al(2003)?s hard constraints did notwork, including, for example, tight restrictions thatunavoidably exclude useful phrases, and practical is-sues like the quality of parse trees.
Although en-suing work moved in the direction of soft syntacticconstraints (see Section 6), our ultimate goal of cap-turing predicate-argument structure requires linguis-tically valid syntactic constituents, and therefore werevisit the idea of hard constraints, avoiding prob-lems with their strictness by relaxing them in threeways.First, requiring source phrases to be subtrees ina linguistically informed syntactic parse eliminatesmany reasonable phrases.
Consider the English-Chinese phrase pair ?the red car, hongse de qiche?.1It is easily to get a translation entry for the wholephrase pair.
By contrast, the phrase pair ?the red,hongse de?
is typically excluded because it does notcorrespond to a complete subtree on the source side.Yet translating the red is likely to be more usefulthan translating the red car, since it is more general:it can be followed by any other noun translation.
Tothis end, we relax the syntactic constraints by allow-ing phrases on the source side corresponding to ei-ther one subtree or sibling subtrees with a commonparent node in the syntactic parse.
For example, thered in Figure 1(a) is allowed since it spans two sub-trees that have a common parent node NP.Second, we might still exclude useful phrases be-cause the syntactic parses of some languages, likeChinese, prefer deep trees, resulting in a head andits modifiers being distributed across multiple struc-tural levels.
Consider the English sentence I still1We use English as source language for better readability.541like the red car very much and its syntactic structureas shown in Figure 1(a).
Phrases I still, still like,I still like are not allowed, since they don?t map toeither a subtree or sibling subtrees.
Logically, how-ever, it might make sense not just to include phrasesmapping to (sibling) subtrees, but to include phrasesmapping to subtrees with the same head.
To this end,we flatten the syntactic parse so that a head and all itsmodifiers appear at the same level.
Another advan-tage of this flattened structure is that flattened treesare more reliable than unflattened ones, in the sensethat some bracketing errors in unflattened trees canbe eliminated during tree flattening.
Figure 1(b) il-lustrates flattening a syntactic parse by moving thehead (like) and all its modifiers (I, still, the red car,and very much) to the same level.Third, initial phrase pair extraction in Chiang?sHPB generates a very large number of rules, whichmakes training and decoding very slow.
To avoidthis, a widely used strategy is to limit initial phrasesto a reasonable length on either side during rule ex-traction (e.g., 10 in Chiang (2007)).
A correspond-ing constraint to speed up decoding prohibits any Xfrom spanning a substring longer than a fixed length,often the same as the maximum phrase length in ruleextraction.
Although the initial phrase length limita-tion mainly keeps non-intuitive phrases out, it alsocloses the door on some useful phrases.
For ex-ample, a translation rule ?I still like X, wo rengranxihuan X?
will be prohibited if the non-terminal Xcovers 8 or more words.
In contrast, our hard con-straints have already filtered out dominating non-intuitive phrases; thus there is more room to includeadditional useful phrases.
As a result, we can switchoff the constraints on initial phrase length in bothtraining and decoding.2.3 Reorderable Glue RulesIn decoding, if no good rule (e.g., a rule whose left-hand side is X) can be applied or the length of thepotential source span is larger than a pre-definedlength, a glue rule (either S ?
?X1, X1?
or S ?
?S1X2, S1X2?)
will be used to simply stitch twoconsequent translated phrases together in monotonicway.
This will obviously prevent some reasonabletranslation derivations because in certain cases, theorder of phrases may be inverted on the target side.Moreover, even that the syntactic constraints dis-a.
Word alignment for an English-Chinese sentence pairwith the parse tree for the English sentenceIADVPlike the red car very muchNPstillVBP NP ADVPSb.
Flattened parse tree for the English sentenceS?
??
??
??
??
??
?wo rengran feichang xihua hongse de qicheVPVPIADVPlike the red car very muchNPstillVBP NP ADVPFigure 1: Example of flattening parse tree.cussed above make translation nodeXs are syntacti-cally informed, stitching translated phrases from leftto right will unavoidably generate non-syntacticallyinformed node Ss.
For example, the combination ofX (like) and X (the) does not make much sense inlinguistic perspective.Alternatively, we replace glue rules of HPB withreorderable ones:?
T ?
?X1, X1??
T ?
?T1T2, T1T2??
T ?
?T1T2, T2T1?where the second (third) rule combines two trans-lated phrases in a monotonic (inverted) way.
Specif-ically, we set the translation probability of the firsttranslation rule as 1 while estimating the probabil-ities of the other two rules from training data.
Inboth training and decoding, we require the phrasescovered by T to satisfy our syntactic constraints.Therefore, all translation nodes (both Xs and T s)in derivations are syntactically informed, providingroom to explore PAS reordering in HPB model.3 PAS Reordering ModelIdeally, we aim to model PAS reordering based onthe true semantic roles of both the source and tar-get side, as to better cater not only consistence but542IAM-TMPlike the red car very muchA0stillVBP A1 AM-MNR?
??
??
??
??
?
?
?wo rengran feichang xihua hongse de qichea.
Word alignment for an English-Chinese sentencepair with semantic roles for the English sentencePAS-SAM-TMP 2A0 1  VBP3 A1 4  AM-MNR 5PAS-TX 2  X 1  X 5  X 3  X 4b.
PAS-S and PAS-T for predicate likeFigure 2: Example of PAS on both the source and targetside.
Items are aligned by indices.divergence between semantic frames of the sourceand target language.
However, considering there isno efficient way of jointly performing MT and SRL,accurate SRL on target side can only be done aftertranslation.
Similar to related work (Liu and Gildea,2010; Xiong et al 2012), we obtain the PAS ofthe source language (PAS-S) via a shallow seman-tic parser and project the PAS of the target language(PAS-T) using the word alignment derived from thetranslation process.
Specifically, we use PropBankstandard (Palmer et al 2005; Xue, 2008) which de-fines a set of numbered core arguments (i.e., A0-A5)and adjunct-like arguments (e.g., AM-TMP for tem-poral, AM-MNR for manner).
Figure 2(b) showsan example of PAS projection from source languageto target language.2 The PAS reordering model de-scribes the probability of reordering PAS-S into PAS-T.
Given a predicate p, it takes the following form:P (PAS-T | PAS-S, PRE=p) (2)Note that cases for untranslated roles can be natu-rally reflected in our PAS reordering model.
For ex-ample, if the argument IA0 is untranslated in Figure2, its PAS-T will be X2X5X3X4.2In PAS-S, we use parts-of-speech (POS) of predicates todistinguish different types of verbs since the semantic structuresof Chinese adjective verbs are different from those of others.3.1 Probability EstimationWhile it is hard and unnecessary to translate a pred-icate and all its associated arguments with one rule,especially if the sentence is long, a practicable way,as most decoders do, is to translate them in multi-ple level rules.
In addition, some adjunct-like argu-ments are optional, or structurally dispensable partof a sentence, which may result in data sparsity is-sue.
Based on these observations, we decomposeFormula 2 into two parts: predicate-argument re-ordering and argument-argument reordering.Predicate-Argument Reordering estimates thereordering probability between a predicate and oneof its arguments.
Taking predicate like and its argu-ment A1 the red car in Figure 2(a) as an example,the predicate-argument pattern on the source side(PA-S) is VBP1 A12 while the predicate-argumentpattern on the target side (PA-T) is X1X2.
The re-ordering probability is estimated as:PP-A (PA-T=X1 X2 | PA-S=VBP1 A12, PRE=like) =Count (PA-T=X1 X2, PA-S=VBP1 A12, PRE=like)?T ??
(PA-S) Count (PA-T=T , PA-S=VBP1 A12, PRE=like)(3)where ?
(PA-S) enumerates all possible reorder-ings on the target side.
Moreover, we take the pred-icate lexicon of predicate into account.
To avoiddata sparsity, we set a threshold (e.g., 100) to re-tain frequent predicates.
For infrequent predicates,their probabilities are smoothed by replacing predi-cate lexicon with its POS.
Finally, if source side pat-terns are infrequent (e.g., less than 10) for frequentpredicates, their probabilities are smoothed as wellwith the same way.Argument-Argument Reordering estimates thereordering probability between two arguments, i.e.,argument-argument pattern on the source side (AA-S) and its counterpart on the target side (AA-T).However, due to that arguments are driven and piv-oted by their predicates, we also include predicatein patterns of AA-S and AA-T. Let?s revisit Fig-ure 2(a).
A1 the red car and AM-MNR very muchare inverted on the target side, whose probability isestimated as:PA-A (AA-T=X3 X1 X2 | AA-S=VBP1 A12 AM-MNR3, PRE=like)(4)Similarly we smooth the probabilities by distin-guishing frequent predicates from infrequent ones,543as well as frequent patterns from infrequent ones.3.2 Integrating the PAS Reordering Model intothe HPB ModelWe integrate the PAS reordering model into the HPBSMT by adding a new feature into the log-lineartranslation model.
Unlike the conventional phraseand lexical translation features whose values arephrase pair-determined and thus can be calculatedoffline, the value of the PAS reordering model canonly be obtained with being aware of the predicate-argument structures a hypothesis may cover.
Beforewe present the algorithm of integrating the PAS re-ordering model, we define a few functions by assum-ing p for a predicate, a for an argument, and H for ahypothesis:?
A (i, j, p): returns arguments of p which arefully located within the span from word i to jon the source side.
For example, in Figure 2,A (4, 8, like) = {A1, AM -MRN}.3?
B (i, j, p): returns true if p is located within [i, j];otherwise returns false.?
C (a, p): returns true if predicate-argument reorder-ing for a and p has not calculated yet; otherwise re-turns false.?
D (a1, a2, p): returns true if argument-argumentreordering for p?s arguments a1 and a2 has not cal-culated yet; otherwise returns false.?
PP -A (H, a, p): according to Eq.
3, returns theprobability of predicate-argument reordering of aand p, given a and p are covered by H .
The po-sitional relation of a and p on the target side can bedetected according to translation derivation of H .?
PA-A (H, a1, a2, p): according to Eq.
4, returnsthe probability of argument-argument reordering ofp?s arguments a1 and a2, given a1, a2 and p are cov-ered by H .Algorithm 1 integrates the PAS reordering modelinto a CKY-style decoder whenever a new hypothe-sis is generated.
Given a hypothesis H , it first looksfor predicates and their arguments which are covered3The hard constraints make sure a valid source text spanwould never fully cover some roles while partially cover otherroles.
For example, phrases like the red, the read car very inFigure 1 are invalid.Algorithm 1: Integrating the PAS reorderingmodel into a CKY-style decoderInput: Sentence f in the source languagePredicate-Argument Structures of fHypothesis H spanning from word i to jOutput: Log-Probability of the PAS reorderingmodel1.
set prob = 0.02. for predicate p in f , such that B (i, j, p) is true3.
ARG = A (i, j, p)4. for a ?
ARG such that C (a, p) is true5.
prob+= logPP -A (H, a, p)6. for a1, a2 ?
ARG such that a1 6= a2 andD (a1, a2, p) is true7.
prob+= logPA-A (H, a1, a2, p)8. return probby H (line 2-3).
Then it respectively calculates theprobabilities of predicate-argument reordering andargument-argument reordering(line 4-7).4 ExperimentsWe have presented our two-level approach to in-corporating syntactic and semantic structures in aHPB system.
In this section, we test the effect ofsuch structural information on a Chinese-to-Englishtranslation task.
The baseline system is a reproduc-tion of Chiang?s (2007) HPB system.
The bilin-gual training data contains 1.5M sentence pairs with39.4M Chinese words and 46.6M English words.4We obtain the word alignments by running GIZA++(Och and Ney, 2000) on the corpus in both direc-tions and applying ?grow-diag-final-and?
refinement(Koehn et al 2003).
We use the SRI language mod-eling toolkit to train a 5-gram language model on theXinhua portion of the Gigaword corpus and standardMERT (Och, 2003) to tune the feature weights onthe development data.To obtain syntactic parse trees for instantiatingsyntactic constraints and predicate-argument struc-tures for integrating the PAS reordering model, wefirst parse the source sentences with the BerkeleyParser (Petrov and Klein, 2007) trained on ChineseTreeBank 6.0 and then ran the Chinese semantic role4This dataset includes LDC2002E18, LDC2003E07,LDC2003E14, Hansards portion of LDC2004T07,LDC2004T08 and LDC2005T06544System MT 02 MT 04 MT 05 Ave.max-phrase-length=10max-char-span=10base HPB 40.00 35.33 32.97 36.10+ basic constraints + unflattened tree 33.90 32.00 29.83 31.91+ our constraints + unflattened tree 38.47 34.51 32.15 35.04+ our constraints + flattened tree 38.55 35.38 32.44 35.46max-phrase-length=?max-char-span=?+ basic constraints + unflattened tree 35.38 32.89 30.42 32.90+ our constraints + unflattened tree 39.41 36.02 33.21 36.21+ our constraints + flattened tree 40.01 36.24 33.65 36.71Table 1: Effects of hard constraints.
Here max-phrase-length is for maximum initial phrase length in training andmax-char-span for maximum phrase length can be covered by non-terminal X in decoding.labeler (Li et al 2010) on all source parse trees toannotate semantic roles for all verbal predicates.We use the 2003 NIST MT evaluation test data(919 sentence pairs) as the development data, andthe 2002, 2004 and 2005 NIST MT evaluationtest data (878, 1788 and 1082 sentence pairs, re-spectively) as the test data.
For evaluation, theNIST BLEU script (version 11b) is used to calcu-late the NIST BLEU scores, which measures case-insensitive matching of n-grams with n up to 4.
Totest whether a performance difference is statisticallysignificant, we conduct significance tests followingthe paired bootstrapping approach (Koehn, 2004).4.1 Effects of Syntactic ConstraintsWe have also tested syntactic constraints that simplyrequire phrases on the source side to map to a sub-tree (called basic constraints).
Similar to requiringinitial phrases on the source side to satisfy the con-straints in training process, we only perform chartparsing on text spans which satisfy the constraintsin decoding process.
Table 1 shows the results ofapplying syntactic constraints with different experi-mental settings.
From the table, we have the follow-ing observations.?
Consistent with the conclusion in Koehn etal.
(2003), using the basic constraints is harmful toHPB.
Fortunately, our constraints consistently workbetter than the basic constraints.?
Relaxing maximum phrase length in training andmaximum char span length in decoding, we obtainan average improvement of about 1.0?1.2 BLEUpoints for systems with both basic constraints andour constraints.
It is worth noting that after re-laxing the lengths, the system with our constraintsperforms on a par with the base HPB system (e.g.,36.21 vs. 36.10).System MT 02 MT 04 MT 05 Ave.base HPB 40.00 35.33 32.97 36.10+our constraints 40.01 36.24++ 33.65+ 36.71with reorderableglue rules40.70+ 36.00+ 33.67+ 36.79+PAS model 40.41+ 36.73++??
34.24++?
37.13Table 2: Effects of reorderable glue rules and the PASreordering model.
+/++: significant over base HPB at0.05/0.01; */**: significant over the system with reorder-able glue rules at 0.05/0.01.?
Flattening parse trees further improves 0.4?0.5BLEU points on average for systems with our syn-tactic constraints.
Our final system with constraintsoutperforms the base HPB system with an averageof 0.6 BLEU points improvement (36.71 vs. 36.10).Another advantage of applying syntactic constraintsis efficiency.
By comparing the base HPB systemand the system with our syntactic constraints (i.e.,the last row in Table 1), it is not surprising to ob-serve that the size of rules extracted from trainingdata drops sharply from 193M in base HPB sys-tem to 60M in the other.
Moreover, the systemwith constraints needs less decoding time than baseHPB does.
Observation on 2002 NIST MT test data(26 words per sentence on average) shows that basicHPB system needs to fill 239 cells per sentence onaverage in chart parsing while the other only needsto fill 108 cells.4.2 Effects of Reorderable Glue RulesBased on the system with our syntactic constraintsand relaxed phrase lengths in training and decoding,we replace traditional glue rules with reorderableglue rules.
Table 2 shows the results, from whichwe find that the effect of reorderable glue rules iselusive: surprisingly, it achieves 0.7 BLEU points545sentence length 1-10 11-20 21-30 31-40 41+ allsentence count 337 1001 1052 768 590 3748base HPB 32.21 37.51 36.71 34.96 35.00 35.73+our constraints 31.70 37.57 37.10 36.20++ 35.78++ 36.39++Table 3: Experimental results over different sentencelength on the three test sets.
+/++: significant over baseHPB at 0.05/0.01.improvement on NIST MT 2002 test set while hav-ing negligible or even slightly negative impact on theother two test sets.
The reason of reorderable gluerules having limited influence on translation resultsover monotonic only glue rules may be due to thatthe monotonic reordering overwhelms the invertedone: estimated from training data, the probability ofthe monotonic glue rule is 95.5%.4.3 Effects of the PAS Reordering ModelBased on the system with reorderable glue rules, weexamine whether the PAS reordering model is capa-ble of improving translation performance.
The lastrow in Table 2 presents the results .
It shows the sys-tem with the PAS reordering model obtains an aver-age of 0.34 BLEU points over the system without it(e.g., 37.13 vs. 36.79).
It is interesting to note that itachieves significant improvement on NIST MT 2004and 2005 test sets (p < 0.05) while slightly loweringperformance on NIST MT 2002 test set (p > 0.05):the surprising improvement of applying reorderableglue rules on NIST MT 2002 test set leaves lessroom for further improvement.
Finally, it shows weobtain an average improvement of 1.03 BLEU pointson the three test sets over the base HPB system.5 Discussion and Future WorkThe results in Table 1 demonstrate that significantand sometimes substantial gains over baseline canbe obtained by incorporating hard syntactic con-straints into the HPB model.
Due to the capability oftranslation phrases of arbitrary length, we conjecturethat the improvement of our system over the baselineHPB system mostly comes from long sentences.
Totest the conjecture, we combine all test sentences inthe three test sets and group them in terms of sen-tence length.
Table 3 presents the sentence distri-bution and BLEU scores over different length.
Theresults validate our assumption that the system withconstraints outperforms the base systems on longsentences (e.g., sentences with 20+ words).Figure 3 displays a translation example whichshows the difference between the base HPBsystem and the system with constraints.
Theinappropriate translation of the base HPBsystem can be mainly blamed on the rule?X[2,5] ?
?2?
?3X[4,5], X[4,5] the development of?,where ?2 ?
?3 , a part of the subtree [0, 3] span-ning from word 0 to 3, is translated immediatelyto the right of X[2,5], making a direct impact thatsubtree [0, 3] is translated discontinuously on thetarget side.
On the contrary, we can see that ourconstraints are able to help select appropriate phrasesegments with respect to its syntactic structure.Although our syntactic constraints apply on thesource side, they are completely ignorant of syn-tax on the target side, which might result in ex-cluding some useful translation rules.
Let?s re-visit the sentence in Figure 3, where we can seethat a transition rule spanning from word 0 to 5,say?X[0,5] ?
X[0,3]?4??
?5, X[0,3] depends on?is intuitive: the syntactic structure on the target sidesatisfies the constraints, although that of the sourceside doesn?t.
One natural extension of this work,therefore, would be to relax the constraints by in-cluding translation rules whose syntactic structureof either the source side or the target side satisfiesthe constraints.To illustrate how the PAS reordering model im-pacts translation output, Figure 4 displays two trans-lation examples of systems with or without it.
Thepredicate ?
?/convey in the first example has threecore arguments, i.e., A0, A2, and A1.
The differencebetween the two outputs is the reordering of A1 andA2 while the PAS reordering model gives priority topattern VV A1 A2.
In the second example, we clearlyobserve two serious translation errors in the systemwithout PAS reordering model: ?
?/themA1 is un-translated; ?
?/chinaA0 is moved to the immediateright of predicate ?
?/allow and plays as direct ob-ject.Including the PAS reordering model improves theBLEU scores.
One further direction to refine the ap-proach is to alleviate verb sparsity via verb classes.Another direction is to include useful context in es-timating reordering probability.
For example, thecontent of a temporal argument AM-TMP can be a546( ( ( ( ??
?? )
?)
?? )
?
( ???
( ( ( ??
?? )
? )
??)
)  ?
)0      1      2      3     4       5        6        7     8      9      10X [0,1] : lot X [4,5] : depends onX [2,5] : X [4,5]  the development ofX [6,9] : the devet.
of the world sit.
X [10,10] : .X [7,7] : sit.X [6,7] : world X [7,7]X [ 9,9] : devet.X [0,1] : lotX [0,3] : X [0,1]  developmentX [5,9] : depends on X [9,9]  of the X [6,7]X [0,10] : X [0,3]  X [5,9] .Figure 3: A translation example of the base HPB system (above) and the system with constraints (below).
[ ?]
A0  [ ?]
AM-ADVP  [ ?
?]
A2  [ ??]
PRE  ??
[ ??
??
?
??]
A1   A0 1   AM-ADVP 2   A2 3   VV4   A1 5[south korean] [will] [deliver] hope [resume talks message] [to the dprk]       X 1   X 2   X 4   X 5   X 3[korean] [will] [convey] [to the] hope of [resuming talks information]         X 1   X 2   X 4   X 3   X 5Sourcew/owithRef.
south korean conveys its desire to resume talking with north korean                  ----[ ??]
A0  [ ???]
AM-TMP  [ ??]
PRE  [ ??]
A1  [ ??
??
??]
A2  ?
A0 1  AM-TMP 2  VV3  A1 4  A2 5[china] [friday] [allowed] [them] [to seoul th rough the philippines] .
X 1   X 2   X 3   X 4   X 5[friday] [allowed] [china] [to seoul through the philippines] .
X 2   X 3   X 1   X 5Sourcew/owithRef.
in friday, china allowed them to travel to seoul through philippines .
----Figure 4: Two translation examples of the system with/without PAS reordering modelshort/simple phrase (e.g., friday) or a long/complexone (e.g., when I was 20 years old), which has im-pact on its reordering in translation.6 Related WorkWhile there has been substantial work on linguis-tically motivated SMT, we limit ourselves hereto several approaches that leverage syntactic con-straints yet still allow cross-constituent transla-tions.
In terms of tree-based SMT with cross-constituent translations, Cowan et al(2006) al-lowed non-constituent sub phrases on the sourceside and adopted phrase-based translation model formodifiers in clauses.
Marcu (2006) and Galleyet al(2006) inserted artificial constituent nodes inparsing tree as to capture useful but non-constituentphrases.
The parse tree binarization approach(Wang et al 2007; Marcu, 2007) and the forest-based approach (Mi et al 2008) would also covernon-constituent phrases to some extent.
Shen etal.
(2010) defined well-formed dependency struc-ture to cover uncompleted dependency structure intranslation rules.
In addition to the fact that theconstraints of Shen et al(2010) and this paperare based on different syntactic perspectives (i.e.,dependency structure vs. constituency structure),the major difference is that in this work we don?tlimit the length of phrases to a fixed maximum size(e.g., 10 in Hiero).
Consequently, we obtain sometranslation rules that are not found in Hiero sys-tems constrained by the length.
In terms of (hi-erarchical) phrase-based SMT with syntactic con-straints, particular related to constituent boundaries,Koehn et al(2003) tested constraints allowing con-stituent matched phrases only.
Chiang (2005) andCherry (2008) used a soft constraint to award or pe-nalize hypotheses which respect or violate syntacticboundaries.
Marton and Resnik (2008) further ex-plored the idea of soft constraints by distinguishingamong constituent types.
Xiong et al(2009; 2010)presented models that learn phrase boundaries fromaligned dataset.On the other hand, semantics motivated SMT hasalso seen an increase in activity recently.
Wu and547Fung (2009) re-ordered arguments on the target sidetranslation output, seeking to maximize the cross-lingual match of the semantic frames of the re-ordered translation to that of the source sentence.Liu and Gildea (2010) added two types of semanticrole features into a tree-to-string translation model.Although Xiong et al(2012) and our work are bothfocusing on source side PAS reordering, our modeldiffers from theirs in two main aspects: 1) we con-sider reordering not only between an argument andits predicate, but also between two arguments; and2) our reordering model can naturally model casesof untranslated arguments or predicates.7 ConclusionIn this paper, we have presented an approach toincorporating syntactic and semantic structures forthe HPB translation model.
To accommodate theclose tie of semantic structures to syntax, we firstrevisited the idea of hard syntactic constraints, andwe demonstrated that hard constraints can, in fact,lead to significant improvement in translation qual-ity when applied to Chiang?s HPB framework.
Thenour PAS reordering model, thanks to the constraintswhich guided translation phrases in favor of syntac-tic boundaries, made further improvements by pre-dicting reordering not only between an argumentand its predicate, but also between two arguments.In the future work, we will extend the PAS reorder-ing model to include useful context, e.g., the headwords and the syntactic categories of arguments.AcknowledgmentsThis research was supported in part by the BOLTprogram of the Defense Advanced Research ProjectsAgency, Contract No.
HR0011-12-C-0015.
Anyopinions, findings, conclusions or recommendationsexpressed in this paper are those of the authors anddo not necessarily reflect the view of DARPA.
Theauthors would like to thank three anonymous re-viewers for providing helpful suggestions, and alsoacknowledge Ke Wu and other CLIP labmates inMT group for useful discussions.
We also thankcreators of the valuable off-the-shelf NLP packages,such as GIZA++ and Berkeley Parser.ReferencesColin Cherry.
2008.
Cohesive phrase-based decodingfor statistical machine translation.
In Proceedings ofACL-HLT 2008, pages 72?80.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofACL 2005, pages 263?270.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Brooke Cowan, Ivona Kuc?erova?, and Michael Collins.2006.
A discriminative model for tree-to-tree transla-tion.
In Proceedings of EMNLP 2006, pages 232?241.Pascale Fung, Zhaojun Wu, Yongsheng Yang, and DekaiWu.
2006.
Automatic learning of Chinese-Englishsemantic structure mapping.
In Proceedings of SLT2006, pages 230?233.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and IgnacioThayer.
2006.
Scalable inference and training ofcontext-rich syntactic translation models.
In Proceed-ings of ACL-COLING 2006, pages 961?968.Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofNAACL 2003, pages 48?54.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP 2004, pages 388?395.Junhui Li, Guodong Zhou, and Hwee Tou Ng.
2010.Joint syntactic and semantic parsing of Chinese.
InProceedings of ACL 2010, pages 1108?1117.Ding Liu and Daniel Gildea.
2010.
Semantic role fea-tures for machine translation.
In Proceedings of COL-ING 2010, pages 716?724.Daniel Marcu, Wei Wang, Abdessamad Echihabi, andKevin Knight.
2006.
SPMT: Statistical machinetranslation with syntactified target language phrases.In Proceedings of EMNLP 2006, pages 44?52.Steve DeNeefe; Kevin Knight; Wei Wang; Daniel Marcu.2007.
What can syntax-based mt learn from phrase-based mt?
In Proceedings of EMNLP-CoNLL 2007,pages 755?763.Yuval Marton and Philip Resnik.
2008.
Soft syntacticconstraints for hierarchical phrased-based translation.In Proceedings of ACL-HLT 2008, pages 1003?1011.Haitao Mi, Liang Huang, and Qun Liu.
2008.
Forest-based translation.
In Proceedings of ACL-HLT 2008,pages 192?199.Franz Josef Och and Hermann Ney.
2000.
Improvedstatistical alignment models.
In Proceedings of ACL2000, pages 440?447.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of ACL2003, pages 160?167.548Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An annotated corpus ofsemantic roles.
Computational Linguistics, 31(1):71?106.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of NAACL-HLT 2007, pages 404?411.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2010.String-to-dependency statistical machine translation.Computational Linguistics, 36(4):649?671.Wei Wang, Kevin Knight, and Daniel Marcu.
2007.Binarizing syntax trees to improve syntax-based ma-chine translation accuracy.
In Proceedings of EMNLP-CoNLL 2007, pages 746?754.Dekai Wu and Pascale Fung.
2009.
Semantic roles forsmt: A hybrid two-pass model.
In Proceedings ofNAACL-HLT 2009, pages 13?16.Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li.
2009.A syntax-driven bracketing model for phrase-basedtranslation.
In Proceedings of ACL-IJCNLP 2009,pages 315?323.Deyi Xiong, Min Zhang, and Haizhou Li.
2010.
Learn-ing translation boundaries for phrase-based decoding.In Proceedings of NAACL-HLT 2010, pages 136?144.Deyi Xiong, Min Zhang, and Haizhou Li.
2012.
Model-ing the translation of predicate-argument structure forsmt.
In Proceedings of ACL 2012, pages 902?911.Nianwen Xue.
2008.
Automatic labeling of semanticroles.
Computational Linguistics, 34(4):225?255.Tao Zhuang and Chengqing Zong.
2010.
Joint inferencefor bilingual semantic role labeling.
In Proceedings ofEMNLP 2010, pages 304?314.549
