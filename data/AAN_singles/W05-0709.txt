Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 63?70,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsThe Impact of Morphological Stemming on Arabic MentionDetection and Coreference ResolutionImed Zitouni, Jeff Sorensen, Xiaoqiang Luo, Radu Florian{izitouni, sorenj, xiaoluo, raduf}@watson.ibm.comIBM T.J. Watson Research Center1101 Kitchawan Rd, Yorktown Heights, NY 10598, USAAbstractArabic presents an interesting challenge tonatural language processing, being a highlyinflected and agglutinative language.
Inparticular, this paper presents an in-depthinvestigation of the entity detection andrecognition (EDR) task for Arabic.
Westart by highlighting why segmentation isa necessary prerequisite for EDR, continueby presenting a finite-state statistical seg-menter, and then examine how the result-ing segments can be better included intoa mention detection system and an entityrecognition system; both systems are statis-tical, build around the maximum entropyprinciple.
Experiments on a clearly statedpartition of the ACE 2004 data show thatstem-based features can significantly im-prove the performance of the EDT systemby 2 absolute F-measure points.
The sys-tem presented here had a competitive per-formance in the ACE 2004 evaluation.1 IntroductionInformation extraction is a crucial step toward un-derstanding and processing language.
One goal ofinformation extraction tasks is to identify importantconceptual information in a discourse.
These taskshave applications in summarization, information re-trieval (one can get al hits for Washington/personand not the ones for Washington/state or Washing-ton/city), data mining, question answering, languageunderstanding, etc.In this paper we focus on the Entity Detection andRecognition task (EDR) for Arabic as described inACE 2004 framework (ACE, 2004).
The EDR hasclose ties to the named entity recognition (NER) andcoreference resolution tasks, which have been the fo-cus of several recent investigations (Bikel et al, 1997;Miller et al, 1998; Borthwick, 1999; Mikheev et al,1999; Soon et al, 2001; Ng and Cardie, 2002; Florianet al, 2004), and have been at the center of evalu-ations such as: MUC-6, MUC-7, and the CoNLL?02and CoNLL?03 shared tasks.
Usually, in computa-tional linguistics literature, a named entity is an in-stance of a location, a person, or an organization, andthe NER task consists of identifying each of theseoccurrences.
Instead, we will adopt the nomencla-ture of the Automatic Content Extraction program(NIST, 2004): we will call the instances of textualreferences to objects/abstractions mentions, whichcan be either named (e.g.
John Mayor), nominal(the president) or pronominal (she, it).
An entity isthe aggregate of all the mentions (of any level) whichrefer to one conceptual entity.
For instance, in thesentencePresident John Smith said he has no com-mentsthere are two mentions (named and pronomial) butonly one entity, formed by the set {John Smith, he}.We separate the EDR task into two parts: a men-tion detection step, which identifies and classifies allthe mentions in a text ?
and a coreference resolutionstep, which combinines the detected mentions intogroups that refer to the same object.
In its entirety,the EDR task is arguably harder than traditionalnamed entity recognition, because of the additionalcomplexity involved in extracting non-named men-tions (nominal and pronominal) and the requirementof grouping mentions into entities.
This is particu-larly true for Arabic where nominals and pronounsare also attached to the word they modify.
In fact,most Arabic words are morphologically derived froma list of base forms or stems, to which prefixes andsuffixes can be attached to form Arabic surface forms(blank-delimited words).
In addition to the differ-ent forms of the Arabic word that result from the63derivational and inflectional process, most preposi-tions, conjunctions, pronouns, and possessive formsare attached to the Arabic surface word.
It is theseorthographic variations and complex morphologicalstructure that make Arabic language processing chal-lenging (Xu et al, 2001; Xu et al, 2002).Both tasks are performed with a statistical frame-work: the mention detection system is similar tothe one presented in (Florian et al, 2004) andthe coreference resolution system is similar to theone described in (Luo et al, 2004).
Both systemsare built around from the maximum-entropy tech-nique (Berger et al, 1996).
We formulate the men-tion detection task as a sequence classification prob-lem.
While this approach is language independent,it must be modified to accomodate the particulars ofthe Arabic language.
The Arabic words may be com-posed of zero or more prefixes, followed by a stem andzero or more suffixes.
We begin with a segmentationof the written text before starting the classification.This segmentation process consists of separating thenormal whitespace delimited words into (hypothe-sized) prefixes, stems, and suffixes, which become thesubject of analysis (tokens).
The resulting granular-ity of breaking words into prefixes and suffixes allowsdifferent mention type labels beyond the stem label(for instance, in the case of nominal and pronominalmentions).
Additionally, because the prefixes andsuffixes are quite frequent, directly processing unseg-mented words results in significant data sparseness.We present in Section 2 the relevant particularitiesof the Arabic language for natural language process-ing, especially for the EDR task.
We then describethe segmentation system we employed for this task inSection 3.
Section 4 briefly describes our mention de-tection system, explaining the different feature typeswe use.
We focus in particular on the stem n-gram,prefix n-gram, and suffix n-gram features that arespecific to a morphologically rich language such asArabic.
We describe in Section 5 our coreferenceresolution system where we also describe the advan-tage of using stem based features.
Section 6 showsand discusses the different experimental results andSection 7 concludes the paper.2 Why is Arabic InformationExtraction difficult?The Arabic language, which is the mother tongue ofmore than 300 million people (Center, 2000), presentsignificant challenges to many natural language pro-cessing applications.
Arabic is a highly inflected andderived language.
In Arabic morphology, most mor-phemes are comprised of a basic word form (the rootor stem), to which many affixes can be attached toform Arabic words.
The Arabic alphabet consistsof 28 letters that can be extended to ninety by ad-ditional shapes, marks, and vowels (Tayli and Al-Salamah, 1990).
Unlike Latin-based alphabets, theorientation of writing in Arabic is from right to left.In written Arabic, short vowels are often omitted.Also, because variety in expression is appreciatedas part of a good writing style, the synonyms arewidespread.
Arabic nouns encode information aboutgender, number, and grammatical cases.
There aretwo genders (masculine and feminine), three num-bers (singular, dual, and plural), and three gram-matical cases (nominative, genitive, and accusative).A noun has a nominative case when it is a subject,accusative case when it is the object of a verb, andgenitive case when it is the object of a preposition.The form of an Arabic noun is consequently deter-mined by its gender, number, and grammatical case.The definitive nouns are formed by attaching theArabic article ?
@ to the immediate front of thenouns, such as in the word ??Q???
@ (the company).Also, prepositions such as H. (by), and ?
(to) can beattached as a prefix as in ??Q????
(to the company).A noun may carry a possessive pronoun as a suffix,such as in ??
D?Q??
(their company).
For the EDR task,in this previous example, the Arabic blank-delimitedword ??
D?Q??
should be split into two tokens: ??Q??
and??.
The first token ??Q??
is a mention that refers toan organization, whereas the second token ??
is alsoa mention, but one that may refer to a person.
Also,the prepositions (i.e., H. and ?)
not be considered apart of the mention.Arabic has two kinds of plurals: broken plurals andsound plurals (Wightwick and Gaafar, 1998; Chenand Gey, 2002).
The formation of broken plurals iscommon, more complex and often irregular.
As anexample, the plural form of the noun ?g.
P (man) is?A g. P (men), which is formed by inserting the infix@.
The plural form of the noun H. AJ?
(book) is I.
J?
(books), which is formed by deleting the infix @.
Theplural form and the singular form may also be com-pletely different (e.g.
?@Q?
@for woman, but ZA?
forwomen).
The sound plurals are formed by addingplural suffixes to singular nouns (e.g., IkAK. meaningresearcher): the plural suffix is H@ for feminine nounsin grammatical cases (e.g., HAJkAK.), 	??
for masculinenouns in the nominative case (e.g., 	?
?JkAK.), and 	?Kfor masculine nouns in the genitive and accusativecases (e.g., 	?JkAK.).
The dual suffix is 	?
@ for the nom-inative case (e.g., 	?AJkAK.), and 	?Kfor the genitive oraccusative (e.g., 	?JkAK.).Because we consider pronouns and nominals as men-tions, it is essential to segment Arabic words intothese subword tokens.
We also believe that the in-64formation denoted by these affixes can help with thecoreference resolution task1.Arabic verbs have perfect and imperfect tenses (Ab-bou and McCarus, 1983).
Perfect tense denotes com-pleted actions, while imperfect denotes ongoing ac-tions.
Arabic verbs in the perfect tense consist of astem followed by a subject marker, denoted as a suf-fix.
The subject marker indicates the person, gender,and number of the subject.
As an example, the verb?K.
A?
(to meet) has a perfect tense I?
K. A?
for the thirdperson feminine singular, and @??
K. A?
for the third per-son masculine plural.
We notice also that a verb witha subject marker and a pronoun suffix can be by itselfa complete sentence, such us in the word ??
D?K.
A?
: ithas a third-person feminine singular subject-markerH (she) and a pronoun suffix ??
(them).
It is alsoa complete sentence meaning ?she met them.?
Thesubject markers are often suffixes, but we may finda subject marker as a combination of a prefix and asuffix as in ???K.
A?K (she meets them).
In this example,the EDR system should be able to separate ???K.
A?K,to create two mentions ( H and ??).
Because thetwo mentions belong to different entities, the EDRsystem should not chain them together.
An Arabicword can potentially have a large number of vari-ants, and some of the variants can be quite complex.As an example, consider the word A ?DJkAJ.
??
(and toher researchers) which contains two prefixes and onesuffix ( A ?
+ ??kAK. + ?
+ ?
).3 Arabic SegmentationLee et al (2003) demonstrates a technique for seg-menting Arabic text and uses it as a morphologicalprocessing step in machine translation.
A trigramlanguage model was used to score and select amonghypothesized segmentations determined by a set ofprefix and suffix expansion rules.In our latest implementation of this algorithm, wehave recast this segmentation strategy as the com-position of three distinct finite state machines.
Thefirst machine, illustrated in Figure 1 encodes the pre-fix and suffix expansion rules, producing a lattice ofpossible segmentations.
The second machine is a dic-tionary that accepts characters and produces identi-fiers corresponding to dictionary entries.
The finalmachine is a trigram language model, specifically aKneser-Ney (Chen and Goodman, 1998) based back-off language model.
Differing from (Lee et al, 2003),we have also introduced an explicit model for un-1As an example, we do not chain mentions with dif-ferent gender, number, etc.known words based upon a character unigram model,although this model is dominated by an empiricallychosen unknown word penalty.
Using 0.5M wordsfrom the combined Arabic Treebanks 1V2, 2V2 and3V1, the dictionary based segmenter achieves a exactword match 97.8% correct segmentation.SEP/epsilona/A#epsilon/#a/epsilona/epsilonb/epsilonb/BUNK/epsilonc/Cb/epsilonc/BCe/+Eepsilon/+d/epsilond/epsilonepsilon/epsilonb/AB#b/A#B#e/+DEc/epsilon d/BCD e/+D+EFigure 1: Illustration of dictionary based segmenta-tion finite state transducer3.1 BootstrappingIn addition to the model based upon a dictionary ofstems and words, we also experimented with modelsbased upon character n-grams, similar to those usedfor Chinese segmentation (Sproat et al, 1996).
Forthese models, both arabic characters and spaces, andthe inserted prefix and suffix markers appear on thearcs of the finite state machine.
Here, the languagemodel is conditioned to insert prefix and suffix mark-ers based upon the frequency of their appearance inn-gram character contexts that appear in the train-ing data.
The character based model alone achievesa 94.5% exact match segmentation accuracy, consid-erably less accurate then the dictionary based model.However, an analysis of the errors indicated that thecharacter based model is more effective at segment-ing words that do not appear in the training data.We seeked to exploit this ability to generalize to im-prove the dictionary based model.
As in (Lee et al,2003), we used unsupervised training data which isautomatically segmented to discover previously un-seen stems.
In our case, the character n-gram modelis used to segment a portion of the Arabic Giga-word corpus.
From this, we create a vocabulary ofstems and affixes by requiring that tokens appearmore than twice in the supervised training data ormore than ten times in the unsupervised, segmentedcorpus.The resulting vocabulary, predominately of wordstems, is 53K words, or about six times the vo-cabulary observed in the supervised training data.This represents about only 18% of the total num-ber of unique tokens observed in the aggregatetraining data.
With the addition of the automat-ically acquired vocabulary, the segmentation accu-racy achieves 98.1% exact match.653.2 Preprocessing of Arabic Treebank DataBecause the Arabic treebank and the gigaword cor-pora are based upon news data, we apply somesmall amount of regular expression based preprocess-ing.
Arabic specific processing include removal ofthe characters tatweel (), and vowels.
Also, the fol-lowing characters are treated as an equivalence classduring all lookups and processing: (1) ?
,?, and(2)@ , @,@ ,@.
We define a token and introduce whites-pace boundaries between every span of one or morealphabetic or numeric characters.
Each punctuationsymbol is considered a separate token.
Characterclasses, such as punctuation, are defined accordingto the Unicode Standard (Aliprand et al, 2004).4 Mention DetectionThe mention detection task we investigate identifies,for each mention, four pieces of information:1. the mention type: person (PER), organiza-tion (ORG), location (LOC), geopolitical en-tity (GPE), facility (FAC), vehicle (VEH), andweapon (WEA)2. the mention level (named, nominal, pronominal,or premodifier)3. the mention class (generic, specific, negativelyquantified, etc.)4.
the mention sub-type, which is a sub-categoryof the mention type (ACE, 2004) (e.g.
OrgGov-ernmental, FacilityPath, etc.
).4.1 System DescriptionWe formulate the mention detection problem as aclassification problem, which takes as input seg-mented Arabic text.
We assign to each token in thetext a label indicating whether it starts a specificmention, is inside a specific mention, or is outsideany mentions.
We use a maximum entropy Markovmodel (MEMM) classifier.
The principle of maxi-mum entropy states that when one searches amongprobability distributions that model the observeddata (evidence), the preferred one is the one thatmaximizes the entropy (a measure of the uncertaintyof the model) (Berger et al, 1996).
One big advan-tage of this approach is that it can combine arbitraryand diverse types of information in making a classi-fication decision.Our mention detection system predicts the four la-bels types associated with a mention through a cas-cade approach.
It first predicts the boundary andthe main entity type for each mention.
Then, it usesthe information regarding the type and boundary indifferent second-stage classifiers to predict the sub-type, the mention level, and the mention class.
Af-ter the first stage, when the boundary (starting, in-side, or outside a mention) has been determined, theother classifiers can use this information to analyzea larger context, capturing the patterns around theentire mentions, rather than words.
As an example,the token sequence that refers to a mention will be-come a single recognized unit and, consequently, lex-ical and syntactic features occuring inside or outsideof the entire mention span can be used in prediction.In the first stage (entity type detection and classifica-tion), Arabic blank-delimited words, after segment-ing, become a series of tokens representing prefixes,stems, and suffixes (cf.
section 2).
We allow anycontiguous sequence of tokens can represent a men-tion.
Thus, prefixes and suffixes can be, and oftenare, labeled with a different mention type than thestem of the word that contains them as constituents.4.2 Stem n-gram FeaturesWe use a large set of features to improve the predic-tion of mentions.
This set can be partitioned into4 categories: lexical, syntactic, gazetteer-based, andthose obtained by running other named-entity clas-sifiers (with different tag sets).
We use features suchas the shallow parsing information associated withthe tokens in a window of 3 tokens, POS, etc.The context of a current token ti is clearly one ofthe most important features in predicting whether tiis a mention or not (Florian et al, 2004).
We de-note these features as backward token tri-grams andforward token tri-grams for the previous and nextcontext of ti respectively.
For a token ti, the back-ward token n-gram feature will contains the previousn ?
1 tokens in the history (ti?n+1, .
.
.
ti?1) and theforward token n-gram feature will contains the nextn ?
1 tokens (ti+1, .
.
.
ti+n?1).Because we are segmenting arabic words intomultiple tokens, there is some concern that tri-gram contexts will no longer convey as muchcontextual information.
Consider the followingsentence extracted from the development set:H.
Qj??
???AJ??
@ I.
J????
Q?
??
@ ?J??@Y?
(transla-tion ?This represents the location for PoliticalParty Office?).
The ?Political Party Office?
istagged as an organization and, as a word-for-wordtranslation, is expressed as ?to the Office of thepolitical to the party?.
It is clear in this examplethat the word Q?
?
(location for) contains crucialinformation in distinguishing between a locationand an organization when tagging the token I.
J??66(office).
After segmentation, the sentence becomes:+ I.
J??
+ ?
@ + ?
+ Q?
?
+ ?
@ + ?J?
+ ?+ @Y?.H.
Qk + ?
@ + ?
+ ???AJ?
+ ?
@When predicting if the token I.
J??
(office) is thebeginning of an organization or not, backward andforward token n-gram features contain only ?
@ + ?
(for the) and ???AJ?
+ ?
@ (the political).
This ismost likely not enough context, and addressing theproblem by increasing the size of the n-gram contextquickly leads to a data sparseness problem.We propose in this paper the stem n-gram features asadditional features to the lexical set.
If the currenttoken ti is a stem, the backward stem n-gram featurecontains the previous n ?
1 stems and the forwardstem n-gram feature will contain the following n?
1stems.
We proceed similarly for prefixes and suffixes:if ti is a prefix (or suffix, respectively) we take theprevious and following prefixes (or suffixes)2.
In thesentence shown above, when the system is predict-ing if the token I.
J??
(office) is the beginning of anorganization or not, the backward and forward stemn-gram features contain Q?
?
?J?
(represent locationof) and H. 	Qk ???AJ?
(political office).
The stem fea-tures contain enough information in this example tomake a decision that I.
J??
(office) is the beginning ofan organization.
In our experiments, n is 3, thereforewe use stem trigram features.5 Coreference ResolutionCoreference resolution (or entity recognition) is de-fined as grouping together mentions referring to thesame object or entity.
For example, in the followingtext,(I) ?John believes Mary to be the best student?three mentions ?John?, ?Mary?, ?student?
are un-derlined.
?Mary?
and ?student?
are in the same en-tity since both refer to the same person.The coreference system system is similar to the Belltree algorithm as described by (Luo et al, 2004).In our implementation, the link model between acandidate entity e and the current mention m is com-puted asPL(L = 1|e, m) ?
maxmk?e P?L(L = 1|e, mk, m), (1)2Thus, the difference to token n-grams is that the to-kens of different type are removed from the streams, be-fore the features are created.where mk is one mention in entity e, and the basicmodel building block P?L(L = 1|e, mk, m) is an ex-ponential or maximum entropy model (Berger et al,1996).For the start model, we use the following approxima-tion:PS(S = 1|e1, e2, ?
?
?
, et, m) ?1 ?
max1?i?tPL(L = 1|ei, m) (2)The start model (cf.
equation 2) says that the prob-ability of starting a new entity, given the currentmention m and the previous entities e1, e2, ?
?
?
, et, issimply 1 minus the maximum link probability be-tween the current mention and one of the previousentities.The maximum-entropy model provides us with aflexible framework to encode features into the thesystem.
Our Arabic entity recognition system usesmany language-indepedent features such as strictand partial string match, and distance features (Luoet al, 2004).
In this paper, however, we focus on theaddition of Arabic stem-based features.5.1 Arabic Stem Match FeatureFeatures using the word context (left and right to-kens) have been shown to be very helpful in corefer-ence resolution (Luo et al, 2004).
For Arabic, sincewords are morphologically derived from a list of roots(stems), we expected that a feature based on theright and left stems would lead to improvement insystem accuracy.Let m1 and m2 be two candidate mentions wherea mention is a string of tokens (prefixes, stems,and suffixes) extracted from the segmented text.In order to make a decision in either linking thetwo mentions or not we use additional featuressuch as: do the stems in m1 and m2 match, dostems in m1 match all stems in m2, do stemsin m1 partially match stems in m2.
We proceedsimilarly for prefixes and suffixes.
Since prefixes andsuffixes can belong to different mention types, webuild a parse tree on the segmented text and we canexplore features dealing with the gender and numberof the token.
In the following example, betweenparentheses we make a word-for-word translations inorder to better explain our stemming feature.
Let ustake the two mentions H.
Qj??
???AJ??
@ I.
J????
(to-the-office the-politic to-the-party) and?G.Qm?
'@ I.
J??
(office the-party?s) segmented asH.
Qk + ?
@ + ?
+ ???AJ?
+ ?
@ + I.
J??
+ ?
@ + ?and ?+ H. 	Qk + ?
@ + I.
J??
respectively.
In our67development corpus, these two mentions are chainedto the same entity.
The stemming match featurein this case will contain information such us allstems of m2 match, which is a strong indicatorthat these mentions should be chained together.Features based on the words alone would not helpthis specific example, because the two strings m1and m2 do not match.6 Experiments6.1 DataThe system is trained on the Arabic ACE 2003 andpart of the 2004 data.
We introduce here a clearlydefined and replicable split of the ACE 2004 data,so that future investigations can accurately and cor-rectly compare against the results presented here.There are 689 Arabic documents in LDC?s 2004 re-lease (version 1.4) of ACE data from three sources:the Arabic Treebank, a subset of the broadcast(bnews) and newswire (nwire) TDT-4 documents.The 178-document devtest is created by takingthe last (in chronological order) 25% of docu-ments in each of three sources: 38 Arabic tree-bank documents dating from ?20000715?
(i.e., July15, 2000) to ?20000815,?
76 bnews documents from?20001205.1100.0489?
(i.e., Dec. 05 of 2000 from11:00pm to 04:89am) to ?20001230.1100.1216,?
and64 nwire documents from ?20001206.1000.0050?
to?20001230.0700.0061.?
The time span of the testset is intentionally non-overlapping with that of thetraining set within each data source, as this modelshow the system will perform in the real world.6.2 Mention DetectionWe want to investigate the usefulness of stem n-gram features in the mention detection system.
Asstated before, the experiments are run in the ACE?04framework (NIST, 2004) where the system will iden-tify mentions and will label them (cf.
Section 4)with a type (person, organization, etc), a sub-type(OrgCommercial, OrgGovernmental, etc), a mentionlevel (named, nominal, etc), and a class (specific,generic, etc).
Detecting the mention boundaries (setof consecutive tokens) and their main type is one ofthe important steps of our mention detection sys-tem.
The score that the ACE community uses (ACEvalue) attributes a higher importance (outlined byits weight) to the main type compared to other sub-tasks, such as the mention level and the class.
Hence,to build our mention detection system we spent a lotof effort in improving the first step: detecting themention boundary and their main type.
In this pa-per, we report the results in terms of precision, recall,and F-measure3.Lexical featuresPrecision Recall F-measure(%) (%) (%)Total 73.3 58.0 64.7FAC 76.0 24.0 36.5GPE 79.4 65.6 71.8LOC 57.7 29.9 39.4ORG 63.1 46.6 53.6PER 73.2 63.5 68.0VEH 83.5 29.7 43.8WEA 77.3 25.4 38.2Lexical features + StemPrecision Recall F-measure(%) (%) (%)Total 73.6 59.4 65.8FAC 72.7 29.0 41.4GPE 79.9 67.2 73.0LOC 58.6 31.9 41.4ORG 62.6 47.2 53.8PER 73.8 64.6 68.9VEH 81.7 35.9 49.9WEA 78.4 29.9 43.2Table 1: Performance of the mention detection sys-tem using lexical features only.To assess the impact of stemming n-gram featureson the system under different conditions, we considertwo cases: one where the system only has access tolexical features (the tokens and direct derivatives in-cluding standard n-gram features), and one wherethe system has access to a richer set of information,including lexical features, POS tags, text chunks,parse tree, and gazetteer information.
The formerframework has the advantage of being fast (makingit more appropriate for deployment in commercialsystems).
The number of parameters to optimize inthe MaxEnt framework we use when only lexical fea-tures are explored is around 280K parameters.
Thisnumber increases to 443K approximately when all in-formation is used except the stemming feature.
Thenumber of parameters introduced by the use of stem-ming is around 130K parameters.
Table 1 reportsexperimental results using lexical features only; weobserve that the stemming n-gram features boost theperformance by one point (64.7 vs. 65.8).
It is im-portant to notice the stemming n-gram features im-proved the performance of each category of the maintype.In the second case, the systems have access to a largeamount of feature types, including lexical, syntac-tic, gazetteer, and those obtained by running other3The ACE value is an important factor for us, but itsrelative complexity, due to different weights associatedwith the subparts, makes for a hard comparison, whilethe F-measure is relatively easy to interpret.68AllFeaturesPrecision Recall F-measure(%) (%) (%)Total 74.3 64.0 68.8FAC 72.3 36.8 48.8GPE 80.5 70.8 75.4LOC 61.1 35.4 44.8ORG 61.4 50.3 55.3PER 75.3 70.2 72.7VEH 83.2 38.1 52.3WEA 69.0 36.6 47.8All-Features + StemPrecision Recall F-measure(%) (%) (%)Total 74.4 64.6 69.2FAC 68.8 38.5 49.4GPE 80.8 71.9 76.1LOC 60.2 36.8 45.7ORG 62.2 51.0 56.1PER 75.3 70.2 72.7VEH 81.4 41.8 55.2WEA 70.3 38.8 50.0Table 2: Performance of the mention detection sys-tem using lexical, syntactic, gazetteer features as wellas features obtained by running other named-entityclassifiersnamed-entity classifiers (with different semantic tagsets).
Features are also extracted from the shal-low parsing information associated with the tokensin window of 3, POS, etc.
The All-features systemincorporates all the features except for the stem n-grams.
Table 2 shows the experimental results withand without the stem n-grams features.
Again, Ta-ble 2 shows that using stem n-grams features gavea small boost to the whole main-type classificationsystem4.
This is true for all types.
It is interesting tonote that the increase in performance in both cases(Tables 1 and 2) is obtained from increased recall,with little change in precision.
When the prefix andsuffix n-gram features are removed from the featureset, we notice in both cases (Tables 1 and 2) a in-significant decrease of the overall performance, whichis expected: what should a feature of preceeding (orfollowing) prepositions or finite articles captures?As stated in Section 4.1, the mention detection sys-tem uses a cascade approach.
However, we were curi-ous to see if the gain we obtained at the first level wassuccessfully transfered into the overall performanceof the mention detection system.
Table 3 presentsthe performance in terms of precision, recall, and F-measure of the whole system.
Despite the fact thatthe improvement was small in terms of F-measure(59.4 vs. 59.7), the stemming n-gram features gave4The difference in performance is not statistically sig-nificantinteresting improvement in terms of ACE value tothe hole EDR system as showed in section 6.3.Precision Recall F-measure(%) (%) (%)All-Features 64.2 55.3 59.4All-Features+Stem 64.4 55.7 59.7Lexical 64.4 50.8 56.8Lexical+Stem 64.6 52.0 57.6Table 3: Performance of the mention detection sys-tem including all ACE?04 subtasks6.3 Coreference ResolutionIn this section, we present the coreference results onthe devtest defined earlier.
First, to see the effect ofstem matching features, we compare two coreferencesystems: one with the stem features, the other with-out.
We test the two systems on both ?true?
andsystem mentions of the devtest set.
?True?
men-tions mean that input to the coreference system arementions marked by human, while system mentionsare output from the mention detection system.
Wereport results with two metrics: ECM-F and ACE-Value.
ECM-F is an entity-constrained mention F-measure (cf.
(Luo et al, 2004) for how ECM-F iscomputed), and ACE-Value is the official ACE eval-uation metric.
The result is shown in Table 4: thebaseline numbers without stem features are listed un-der ?Base,?
and the results of the coreference systemwith stem features are listed under ?Base+Stem.
?On true mention, the stem matching features im-prove ECM-F from 77.7% to 80.0%, and ACE-valuefrom 86.9% to 88.2%.
The similar improvement isalso observed on system mentions.The overall ECM-F improves from 62.3% to 64.2% and the ACE valueimproves from 61.9 to 63.1%.
Note that the increaseon the ACE value is smaller than ECM-F.
This isbecause ACE-value is a weighted metric which em-phasizes on NAME mentions and heavily discountsPRONOUN mentions.
Overall the stem features giverise to consistent gain to the coreference system.7 ConclusionIn this paper, we present a fully fledged Entity Detec-tion and Tracking system for Arabic.
At its base, thesystem fundamentally depends on a finite state seg-menter and makes good use of the relationships thatoccur between word stems, by introducing featureswhich take into account the type of each segment.In mention detection, the features are represented asstem n-grams, while in coreference resolution theyare captured through stem-tailored match features.69Base Base+StemECM-F ACEVal ECM-F ACEValTruth 77.7 86.9 80.0 88.2System 62.3 61.9 64.2 63.1Table 4: Effect of Arabic stemming features on coref-erence resolution.
The row marked with ?Truth?represents the results with ?true?
mentions while therow marked with ?System?
represents that mentionsare detected by the system.
Numbers under ?ECM-F?
are Entity-Constrained-Mention F-measure andnumbers under ?ACE-Val?
are ACE-values.These types of features result in an improvement inboth the mention detection and coreference resolu-tion performance, as shown through experiments onthe ACE 2004 Arabic data.
The experiments are per-formed on a clearly specified partition of the data, socomparisons against the presented work can be cor-rectly and accurately made in the future.
In addi-tion, we also report results on the official test data.The presented system has obtained competitive re-sults in the ACE 2004 evaluation, being rankedamongst the top competitors.8 AcknowledgementsThis work was partially supported by the DefenseAdvanced Research Projects Agency and monitoredby SPAWAR under contract No.
N66001-99-2-8916.The views and findings contained in this material arethose of the authors and do not necessarily reflectthe position of policy of the U.S. government and noofficial endorsement should be inferred.ReferencesPeter F. Abbou and Ernest N. McCarus, editors.
1983.Elementary modern standard Arabic.
Cambridge Univer-sity Press.ACE.
2004.
Automatic content extraction.http://www.ldc.upenn.edu/Projects/ACE/.Joan Aliprand, Julie Allen, Joe Becker, Mark Davis,Michael Everson, Asmus Freytag, John Jenkins, MikeKsar, Rick McGowan, Eric Muller, Lisa Moore, MichelSuignard, and Ken Whistler.
2004.
The unicode stan-dard.
http://www.unicode.org/.A.
Berger, S. Della Pietra, and V. Della Pietra.
1996.
Amaximum entropy approach to natural language process-ing.
Computational Linguistics, 22(1):39?71.D.
M. Bikel, S. Miller, R. Schwartz, and R. Weischedel.1997.
Nymble: a high-performance learning name-finder.In Proceedings of ANLP-97, pages 194?201.A.
Borthwick.
1999.
A Maximum Entropy Approach toNamed Entity Recognition.
Ph.D. thesis, New York Uni-versity.Egyptian Demographic Center.
2000.http://www.frcu.eun.eg/www/homepage/cdc/cdc.htm.Aitao Chen and Fredic Gey.
2002.
Building an arabicstemmer for information retrieval.
In Proceedings of theEleventh Text REtrieval Conference (TREC 2002), Na-tional Institute of Standards and Technology, November.S.
F. Chen and J. Goodman.
1998.
An empirical studyof smoothing techinques for language modeling.
Techni-cal Report TR-10-98, Center for Research in Comput-ing Technology, Harvard University, Cambridge, Mas-sachusettes, August.R.
Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kamb-hatla, X. Luo, N Nicolov, and S Roukos.
2004.
A statisti-cal model for multilingual entity detection and tracking.In Proceedings of HLT-NAACL 2004, pages 1?8.Y.-S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Has-san.
2003.
Language model based Arabic word segmen-tation.
In Proceedings of the ACL?03, pages 399?406.Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, NandaKambhatla, and Salim Roukos.
2004.
A mention-synchronous coreference resolution algorithm based onthe bell tree.
In Proc.
of ACL?04.A.
Mikheev, M. Moens, and C. Grover.
1999.
Namedentity recognition without gazetteers.
In Proceedings ofEACL?99.S.
Miller, M. Crystal, H. Fox, L. Ramshaw, R. Schwarz,R.
Stone, and R. Weischedel.
1998.
Bbn: Description ofthe SIFT system as used for MUC-7.
In MUC-7.V.
Ng and C. Cardie.
2002.
Improving machine learningapproaches to coreference resolution.
In Proceedings ofthe ACL?02, pages 104?111.NIST.
2004.
Proceedings of ace evaluation and pi meet-ing 2004 workshop.
Alexandria, VA, September.
NIST.W.
M. Soon, H. T. Ng, and C. Y. Lim.
2001.
A ma-chine learning approach to coreference resolution of nounphrases.
Computational Linguistics, 27(4):521?544.R.
Sproat, C. Shih, W. Gale, and N. Chang.
1996.
Astochastic finite-state word-segmentation algorithm forChinese.
Computational Linguistics, 22(3).M.
Tayli and A. Al-Salamah.
1990.
Building bilingualmicrocomputer systems.
Communications of the ACM,33(5):495?505.J.
Wightwick and M. Gaafar.
1998.
Arabic Verbs andEssentials of Grammar.
Passport Books.J.
Xu, A. Fraser, and R. Weischedel.
2001.
Trec2001cross-lingual retrieval at bbn.
In TREC 2001, Gaithers-burg: NIST.J.
Xu, A. Fraser, and R. Weischedel.
2002.
Empiricalstudies in strategies for arabic information retrieval.
InSIGIR 2002, Tampere, Finland.70
