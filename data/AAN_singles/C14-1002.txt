Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 2?13, Dublin, Ireland, August 23-29 2014.Unsupervised learning of rhetorical structure with un-topic modelsDiarmuid?O S?eaghdhaComputer LaboratoryUniversity of CambridgeCambridge, UKdo242@cam.ac.ukSimone TeufelComputer LaboratoryUniversity of CambridgeCambridge, UKsht25@cam.ac.ukAbstractIn this paper we investigate whether unsupervised models can be used to induce conventionalaspects of rhetorical language in scientific writing.
We rely on the intuition that the rhetoricallanguage used in a document is general in nature and independent of the document?s topic.We describe a Bayesian latent-variable model that implements this intuition.
In two empiricalevaluations based on the task of argumentative zoning (AZ), we demonstrate that our generalityhypothesis is crucial for distinguishing between rhetorical and topical language and that featuresprovided by our unsupervised model trained on a large corpus can improve the performance of asupervised AZ classifier.1 IntroductionScientific writing has many conventions.
Some exist at the level of sentence construction, such asa preference for the passive voice or for deverbal nominalisations.
Others relate to the high-levelorganisation of a paper: a typical paper at an NLP conference may be divided into sections covering theintroduction, related work, methods, experimental results and conclusion.
There are also intermediatelevels of convention that use lexical and phrasal items to signal the role played by each part of the text inthe argument the authors wish to construct.
The theory of argumentative zoning (AZ) describes how ascientific article can be analysed in terms of text blocks (or zones) that share a rhetorical function (Teufel,2010).
For example: part of the article may consist of background information, another part may describethe aim of the research, other parts may report the authors?
own work or compare that work to alternativeapproaches in the literature.
Supervised computational systems can be trained to mark up the AZ structureof a text automatically (see Section 2); the output of such systems has been shown to aid summarisationand human browsing of the scientific literature (Teufel and Moens, 2002; Guo et al., 2011a; Contractor etal., 2012).
However, supervised systems require manually annotated training data that must be createdanew for each discipline (and language) before they can be deployed, while large quantities of unannotatedtext are often available.
For this reason, there is considerable value in developing unsupervised systemsthat induce aspects of rhetorical structure from unannotated text.In this paper we advance a hypothesis about the generality of rhetorical language.
We propose that thewords and linguistic constructs used to express rhetorical function in a scientific paper are independentof the paper?s topic.
Naturally there will be some variation across research areas and there may be largedifferences across disciplines, but within a discipline we do not expect that the specific subject of a paperplays a significant role in how the authors construct their argument.
For example, the following templatecould be used to generate an abstract for very many papers in NLP and other fields:The problem of has received a lot of attention because of its relevance to.
CITATION proposed an approach based on the method of .In this paper we present a method for that has the following advantages over prior work:.
We demonstrate the empirical effectiveness of our method by reportingexperiments on data, where it outperforms the approach of CITATION by %.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/2This leads us to the idea of two-stage ?recipes?
for scientific papers, whereby the authors start with aframework of boilerplate text that matches the rhetorical argument they wish to make.
The authors canthen fill in the gaps with the substance of their research contribution.The two-stage model is of course an idealisation of how scientists construct their papers, but it isuseful as an inspiration for a computational model that implements the generality hypothesis.
We proposeBOILERPLATE-LDA, a generative model that assigns responsibility for generating each word in anabstract to a document-specific topic model or to a rhetorical language model that is not specific tothe document.
Essentially, we induce argumentative structure from the parts of the text that are notwell-explained by the topic model.
Hence we describe BOILERPLATE-LDA as an ?un-topic model?.
Weevaluate our model in two settings: a clustering evaluation that treats BOILERPLATE-LDA as performingunsupervised argumentative zoning, and a downstream evaluation where the induced structure is not takenas explicitly modelling argumentative zones but is used to provide informative features for a supervisedAZ classifier.
In both cases, we show that BOILERPLATE-LDA performs well on a very challenging task.2 Related workThere has been great interest in unsupervised learning among NLP researchers due to the availabilityof large amounts of unprocessed text through the Web, newswire providers, scientific repositories andother sources in contrast to the onerous requirements of creating task-specific manually annotated datafor training supervised analysers.
Particularly relevant to our work is the field of topic modelling, whereBayesian latent-variable models are used to induce meaningful generalisations from observations ofco-occurrences.
Blei et al.
(2003) introduced Latent Dirichlet Allocation (LDA) as a model of thematicstructure in documents, but subsequent work has adapted the general framework to many different purposesin modelling text as well as other kinds of data.
This includes research on modelling aspects of documentstructure such as topic segmentation, implementing the intuitions that neighbouring blocks of text arecoherent in the sense of lexical similarity (Purver et al., 2006; Gruber et al., 2007; Eisenstein and Barzilay,2008; Du et al., 2013).
The model most similar to ours (that we are aware of) is the model of Ritter etal.
(2010), which captures dialogue acts and transitions between them in Twitter conversations.Despite the general popularity of unsupervised approaches, rhetorical analysis has generally beentreated as a problem for supervised machine learning.
Classification-based approaches to argumentativezoning typically use a sequence classifier such as a maximum-entropy Markov model or conditionalrandom field (Teufel and Moens, 2002; Siddharthan and Teufel, 2007; Hirohata et al., 2008; Guo et al.,2010).
Guo et al.
(2011b) take a semi-supervised approach based on active learning and self-training.Two unsupervised approaches in the literature are Varga et al.
(2012) and Reichart and Korhonen(2012).
Varga et al.
use a topic model variant called ZONE-LDA that assigns each sentence a latentvariable index or ?topic?
and assumes that the words in the sentence are generated from a distributionparticular to the topic; in this situation each topic is assumed to correspond to a distinct argumentativezone.
Such a model will have the effect of clustering sentences that share lexical items.
Varga et al.
alsopropose a model they call ZONE-LDA-B, in which some common words are assigned to a ?background?distribution that is independent of the sentence category; this model performs worse than ZONE-LDA intheir evaluation.
Reichart and Korhonen take an approach based on Markov random fields.
They constructa graphical model in which sentence vertices are connected by potentials weighted according to adjacencyand sentence similarity, as well as hand-defined rules about passivisation and sentence location.The papers cited in the two preceding paragraphs have focused on rhetorical analysis in scientificwriting, yet there are many other textual genres where argumentation is conventionalised.
For example,Burstein et al.
(2003) identify building blocks analogous to AZ zones in the writing of English languagelearners and demonstrate that a supervised classification approach can be used to mark up their essays.Also in the educational domain, Madnani et al.
(2012) train a supervised classifier to detect the ?shell?language that learners use to organise the high-level structure of their compositions; this is quite closeto our idea of ?templates?
or ?recipes?
for scientific papers.
Sauper and Barzilay (2009) and Chen etal.
(2009) both present models that learn structural conventions in Wikipedia articles without relying onhuman annotation.
Sauper and Barzilay?s model induces the typical section structure of Wikipedia articles3about a specific entity type (e.g., Actors or Diseases) and retrieves web snippets relevant to each sectionfor a target entity, before performing multidocument summarisation to produce a new entry for postingto Wikipedia.
Chen et al.
take a Bayesian segmentation approach to implicitly learn the topical sectionstructure of articles and use a generalised Mallows model, a distribution over permutations, to identify acanonical ordering for sections.1Other forms of general rhetorical analysis include Rhetorical StructureTheory (Mann and Thompson, 1988; Marcu, 2000), which captures local discourse relations betweensegments of text; RST provides a layer of analysis that is separate and complementary to more globalschemes such as argumentative zoning.3 IntuitionsThe performance of unsupervised learning depends on how intuitions about the task are incorporated inthe statistical model.
Our approach relies on three main intuitions:Sentence similarity: All else being equal, we expect that lexically similar sentences will have similarpurposes.
At the same time, lexical similarity alone is not sufficient to capture shared argumentativefunction: all sentences in a paper about parsing will be similar to each other, while the introductorysentences of a parsing paper and a machine translation paper may share few similar lexical items.Adjacency: The theory of argumentative zones suggests that sentences with the same rhetorical functionwill often be grouped together into blocks.
Additionally, we expect that authors will follow generalconventions about the order of zones, e.g., starting with background and goal statements andprogressing to results and conclusions.Generality: We expect that the language used to convey rhetorical function is independent of the topicalcontent of the paper.Sentence similarity can be captured using standard lexical similarity measures or through the clusteringeffects of a topic model.
The adjacency assumption can be implemented using a linear-chain sequencemodel such as a Hidden Markov Model.
The ZONE-LDA approach of Varga et al.
(2012) relies onsentence similarity alone.
Reichart and Korhonen?s (2012) model combines sentence similarity andadjacency.
To the best of our knowledge, the generality hypothesis has not previously been investigated.The model we describe in Section 4 incorporates all three intuitions in its structure.4 ModelsThe model we propose assumes that each word in a sentence is generated either from an LDA-style topicmodel or from a distribution associated with the rhetorical category assigned to the sentence.
The formercaptures the subject matter of the document; the latter captures conventional language that is independentof the document?s subject matter.
The sentence categories are generated from a first-order Markov model.The assignment of responsibility for a word is implemented through a so-called ?switching variable?, abinary-valued latent variable.
This is a commonly used mechanism for interpolating language models(Griffiths et al., 2004; Reisinger and Mooney, 2010; Ahmed and Xing, 2010); in many cases, the goal is toassign common words to a ?background?
distribution that is not considered an object of interest from atopic modelling perspective.
In our case it is this non-topical part of the text that is the object of interest.The dependencies between variables in our full BOILERPLATE-LDA model are shown by the platediagram in Figure 1.
The corresponding ?generative story?
is as follows:1It would be interesting to swap in Chen et al.
?s generalised Mallows model for the HMM-style ordering model inBOILERPLATE-LDA.
The former has the advantage of capturing non-local ordering effects, while the latter has the advantage ofnot assuming a single canonical ordering.4for topic t ?
{1 .
.
.
|T |} do(Draw a distribution over words)?t?
Dirichlet(?
)end forfor zone z ?
{1 .
.
.
|Z|} do(Draw a distribution over words)?z?
Dirichlet(?
)(Draw a transition distribution)?z?
Dirichlet(?
)end for(Draw the switch distribution)?
?
Beta(?0, ?1)for doc d ?
{1 .
.
.
|D|} do(Draw a distribution over topics)?d?
Dirichlet(?
)for sentence s ?
Sentences(d) dozs?Multinomial(?zs?1)for word i ?Words(s) do(Draw a switch indicator)bi= Beta(?
)if bi= 0 then(Draw a word from the zone-word distribution)wi?Multinomial(?zs)else(Draw a topic)ti?Multinomial(?d)(Draw a word from the topic-word distribution)wi?Multinomial(?ti)end ifend forend forend forWe train the model using Gibbs sampling.
Due to Dirichlet-multinomial and beta-Bernoulli conjugacyit is relatively straightforward to integrate out the multinomial and Bernoulli distribution parameters?, ?, ?
and ?
and derive update rules for a collapsed Gibbs sampler.
Each iteration of the sampler visitseach sentence in the corpus in turn, first sampling the sentence label assignment zsand then sampling foreach word in the sentence the switch indicator biand (if bi= 1) the topic assignment ti.
The sentencelabel update is performed using what Gao and Johnson (2008) call a pointwise collapsed Gibbs sampler.Omitting hyperparameters for clarity, the sampling probabilities can be written asP (zi= z|z?i,w, b) ?fzi?1?z+ ?zfzi?1+?z?
?z?fz?zi+1+ I(z = zi+1) + ?zi+1f?iz+ I(z = zi+1) +?z??z??v?V?
(f?izv,b=0+ fsiv,b=0+ ?)?
(f?iz+ fsi+ ?|V |)(1)where fz?>z?is the transition frequency from zone z to zone z?, fzis the number of sentences assignedzone z; I(z = zi+1) has value 1 if the two zone assignments are equal and 0 otherwise; V is the vocabularyof word types; fzv,b=0is the number of words of type z that appear in sentences assigned zone z andwhose corresponding switch variable has value 0; fsiv,b=0is the number of words of type v that appear insentence siand whose corresponding switch variable has value 0; the superscript?iindicates that thefrequency is calculated over all sentences except si.
We introduce observed start and end state variableszsand zeto handle the boundaries at the beginning and end of each document.5zsz1z2znzew wwt ttWords(s1) Words(s2)Words(sn)b bb??D??0?1??Z??Z?
?TFigure 1: Plate diagram for BOILERPLATE-LDAThe topic and switch variables for each word are sampled in a blocked fashion; the sampling probabilitiesare similar to the standard LDA updates:P (bj= 0, tj= ?|z?j,b?j, t,w) ?
(f?jb=0+ ?0)f?jziwj,b=0+ ?fzi,b=0+ |V |?P (bj= 1, tj= t|z?j,b?j, t,w) ?
(f?jb=1+ ?1)f?jtwj+ ?zf?jwj,b=1+?z?
?z?f?jzwj+ ?f?jz+ |V |?P (bi= 0, ti6= ?|z?j,b?j, t,w) = 0P (bi= 1, ti= ?|z?j,b?j, t,w) = 0 (2)where we use j to index words and i to index sentences; ftwjis the number of words of type wjthat areassigned topic t; the superscript?jindicates that the frequency is calculated over all words except j.5 Experiments5.1 DataFor evaluation, we use a collection of abstracts compiled by Guo et al.
(2010).
These abstracts hadoriginally been collected in the context of semi-automated cancer risk assessment by searching PubMedfor abstracts mentioning one or more of a list of chemicals known to have carcinogenic properties(Korhonen et al., 2009).
Guo et al.
annotated abstracts for five of these chemicals using an AZ schemewith seven categories: Background, Objective, Method, Result, Conclusion, Related work and Futurework.2In order to test whether our models can also perform over a large, heterogeneous dataset, we alsoused a collection of 129,595 abstracts taken from a collection of open-access journal articles.
Preprocessinginvolved sentence splitting, tokenisation and part-of-speech tagging using the Stanford CoreNLP toolkit3and the removal of all tokens containing non-alphanumeric characters, all tokens of character length one2The annotated dataset has been made available at http://www.cl.cam.ac.uk/?yg244/abstract_az.html.3http://nlp.stanford.edu/software/corenlp.shtml6and a small set of stop words.4This left a training corpus of 16,841,280 tokens.5.2 Clustering Evaluation5.2.1 EvaluationOur first quantitative evaluation investigates whether the zones induced by BOILERPLATE-LDA corre-spond to the argumentative zones identified by human theorists.
We treat this as a clustering task withthe gold standard provided by Guo et al.
?s (2010) dataset.
The clustering evaluation measures we useare the Adjusted Rand Index (Hubert and Arabie, 1985) and Adjusted Mutual Information (Vinh et al.,2010); both measures are normalised to have a maximum value of 1 and are adjusted for chance so thatthe expected score given to a random clustering is 0.
This second property makes them conservative incomparison to other evaluation measures.
We report results with the number of zones |Z| ?
{10, 20, 50}and number of topics |T | ?
{10, 20, 50, 100}; for each combination of settings we report the averageevaluation score attained by three independent runs of the learning algorithm.5.2.2 ModelsFor our evaluation, we test the following models:BOILERPLATE-LDA: Our full model, as described in Section 4.BOILERPLATE-LDA-MULT: A simplified model where the Markov dependencies between zone as-signments are replaced by a flat multinomial; the probability of a zone is independent of the adjacentsentences.BOILERPLATE-LDA-NOTOPICS: A simplified model where all words in a sentence are generatedfrom the zone distribution ?zs; this is almost identical to Varga et al.
?s (2012) ZONE-LDA model.K-MEANS: A standard k-means clustering model run until convergence.
The features for each sentenceconsist of tf-idf-transformed lexical frequencies, part-of-speech tags and a location feature computedby dividing the abstract into 5 bins.The BOILERPLATE-LDA models are all trained for 1000 iterations of Gibbs sampling.
The Dirichlethyperparameters are re-estimated every 10 iterations; the topic hyperparameters ?
are optimised usinga fixed-point iteration to maximise the log-evidence (Minka, 2003; Wallach, 2008), while the otherhyperparameters are sampled using Hamiltonian Monte Carlo (Neal, 2010).
K-MEANS was run untilconvergence.5.2.3 ResultsFigure 2 gives an illustration of the zone representation induced at the end of one run of BOILERPLATE-LDA with the settings |Z| = 10, |T | = 100.
Firstly, we list the most probable words for each zone(2a).
While the model may not find a perfect match for the gold-standard inventory of argumentativezones, we can see that some induced zones describe standard methodology (8,9), others describe resultsand implications (1,3,7) and others describe motivations (2,5,6).
Inspection of the transition matrix (2b)confirms our expectation that self-transitions have the highest probability; we also observed that thezones most frequently transitioned to from the start state are the motivational zones and the zones mostfrequently transitioned from to the end state are the results/implications zones.
The example abstracts inFigure 3 illustrate how BOILERPLATE-LDA can be used to mark up the text of an abstract as ?boilerplate?or ?non-boilerplate?
based on the values of the switch variables bi.4The part-of-speech tags are not used by BOILERPLATE-LDA but they are used as features for other models.71 results, suggest, our, data, study, role, findings, we, between, indicate, important, studies2 study, we, using, used, investigated, determine, present, between, investigate, analysis, aim3 increased, significantly, levels, showed, found, observed, significant, after, compared, higher4 two, sequence, we, found, region, sequences, we, three, identified, between, different, analysis5 use, more, studies, study, used, however, important, health, most, treatment, clinical, potential6 role, important, known, studies, however, shown, including, involved, mechanisms, cell7 case, we, patient, report, rare, most, common, reported, presented, disease, associated, cause8 CI, significantly, respectively, significant, between, group, mean, higher, compared, more, found9 study, years, using, two, patients, included, total, group, three, data, after, used, collected, age10 we, data, analysis, used, using, new, approach, based, method, information, developed, more(a) Most probable words for each zoneFromToStart 1 2 3 4 5 6 7 8 9 10 EndStart 0.00 0.00 0.10 0.01 0.08 0.24 0.36 0.10 0.00 0.03 0.08 0.001 0.00 0.37 0.01 0.04 0.01 0.03 0.01 0.00 0.00 0.00 0.01 0.502 0.00 0.02 0.26 0.25 0.07 0.01 0.02 0.00 0.05 0.29 0.01 0.003 0.00 0.27 0.02 0.59 0.02 0.02 0.02 0.00 0.02 0.00 0.01 0.044 0.00 0.12 0.02 0.09 0.62 0.00 0.03 0.00 0.01 0.00 0.05 0.055 0.00 0.01 0.10 0.00 0.00 0.55 0.03 0.02 0.00 0.06 0.04 0.186 0.00 0.06 0.21 0.05 0.05 0.05 0.50 0.01 0.00 0.01 0.05 0.027 0.00 0.02 0.02 0.01 0.01 0.15 0.04 0.63 0.01 0.02 0.00 0.088 0.00 0.09 0.01 0.14 0.01 0.07 0.00 0.02 0.61 0.04 0.01 0.019 0.00 0.01 0.11 0.05 0.01 0.05 0.00 0.02 0.20 0.54 0.01 0.0010 0.00 0.05 0.02 0.01 0.07 0.02 0.01 0.00 0.01 0.01 0.68 0.12End 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00(b) Zone transition probabilities between adjacent sentencesFigure 2: Zones induced by one run of BOILERPLATE-LDA (|Z| = 10, |T | = 100)8VASP: A Volumetric Analysis of Surface Properties Yields Insights into Protein-Ligand Binding SpecificityMany algorithms that compare protein structures can reveal similarities that suggestrelated biological functions, even at great evolutionary distances.
Proteins with re-lated function often exhibit differences in binding specificity, but few algorithmsidentify structural variations that effect specificity.
To address this problem, we de-scribe the Volumetric Analysis of Surface Properties (VASP), a novel volumetricanalysis tool for the comparison of binding sites in aligned protein structures.
VASPuses solid volumes to represent protein shape and the shape of surface cavities,clefts and tunnels that are defined with other methods.
Our approach, inspired bytechniques from constructive solid geometry, enables the isolation of volumetri-cally conserved and variable regions within three dimensionally superposed volumes.We applied VASP to compute a comparative volumetric analysis of the ligand bindingsites formed by members of the steroidogenic acute regulatory protein (StAR)-relatedlipid transfer (START) domains and the serine proteases.
Within both families, VASPisolated individual amino acids that create structural differences between ligand bind-ing cavities that are known to influence differences in binding specificity.
Also, VASPisolated cavity subregions that differ between ligand binding cavities which are essen-tial for differences in binding specificity.
As such, VASP should prove a valuable toolin the studyof protein-ligand binding specificity.A new usage of functionalized oligodeoxynucleotide probe for site-specificmodification of a guanine base within RNASite-specific modification of RNA is of great significance to investigate RNA structure,function and dynamics.
Recently, we reported a new method for sequence- andcytosine-selective chemical modification of RNA based on the functional group trans-fer reaction of the 1-phenyl-2-methylydene-1,3-diketone unit of the 6-thioguanosinebase incorporated in the oligodeoxynucleotide probe.
In this study, we describe thatthe functionality transfer rate is greatly enhanced and the selectivity is shifted to theguanine base when the reaction is performed under alkaline conditions.Detailed investigation indicated that the 2-amino group of the enolate form of rG isthe reactant of the functionality transfer reaction.
As a potential application of thisefficient functionality transfer reaction, a pyrene group as a relatively large fluorescentgroup was successfully transferred to the target guanine base of RNA with a highguanine and site selectivity.
This functionality transfer reaction with high efficiency andhigh site-selectivity would provide a new opportunity as a unique tool for the study ofRNA.Figure 3: Examples of abstracts marked up for boilerplate (underlined) and non-boilerplate (faded text) byBOILERPLATE-LDA9Model |T | |Z| = 10 |Z| = 20 |Z| = 50ARI NMI ARI NMI ARI NMIBOILERPLATE-LDA 10 0.19 0.15 0.09 0.09 0.04 0.0720 0.20 0.16 0.03 0.10 0.03 0.0850 0.26 0.21 0.18 0.16 0.05 0.10100 0.32 0.28 0.20 0.20 0.07 0.14BOILERPLATE-LDA-MULT 10 0.13 0.11 0.08 0.08 0.04 0.0620 0.10 0.13 0.04 0.09 0.03 0.0750 0.21 0.16 0.13 0.14 0.06 0.10100 0.18 0.16 0.14 0.14 0.07 0.11BOILERPLATE-LDA-NOTOPICS 0 0.00 0.02 0.04 0.05 0.06 0.05K-MEANS 0 0.05 0.05 0.03 0.06 0.03 0.04Table 1: Results of the clustering evaluation.
|Z| is the number of zones; |T | is the number of topics.The results of the clustering evaluation are presented in Table 1.
Clearly, this is a challenging task; theBOILERPLATE-LDA-NOTOPICS and K-MEANS models, which do not filter out topic-specific vocabulary,perform little better than chance in terms of identifying argumentative zones (recall that for the ARIand AMI measures, zero means ?not greater than expected by chance?
rather than ?no correlation atall?).
BOILERPLATE-LDA-MULT performs better than those models though not as well as the fullBOILERPLATE-LDA model, indicating that sequential structure is important for inducing rhetoricalregularities.
In general, the best results are attained with low settings of |Z| and high settings of |T |; thisseems to create the ?bottleneck?
effect needed to focus the model on purely rhetorical information.
Thehighest scores (ARI = 0.32, AMI = 0.28) are attained by BOILERPLATE-LDA with the settings |Z| = 10,|T | = 100.5.3 Supervised Evaluation5.3.1 EvaluationA second evaluation of BOILERPLATE-LDA?s usefulness is to test whether it can yield features thatimprove the performance of a supervised argumentative zoning system.
It is possible for an unsupervisedmodel to induce structure that does not map exactly onto a pre-existing set of labels but still capturesvaluable information about the underlying phenomenon that can be of use to a supervised classifier whencombined with other information sources.
To this end, we train and evaluate supervised models on thesame dataset of Guo et al.
(2010) that we used for the clustering evaluation.
We perform 10-fold cross-validation and report Accuracy (proportion of sentences labelled correctly) as well as macro-averagedPrecision, Recall and F-Score.
To measure statistical significance we use two-tailed paired t-tests,following Dietterich (1998).55.3.2 ModelsWe use two supervised sequence classification algorithms for training models:LR: A logistic regression classifier with a ?history?
feature encoding the previous sentence?s label, trainedwith L1regularisation, using the implementation in LibLinear.6CRF: A first-order conditional random field classifier, trained with L1regularisation, using the imple-mentation in Mallet.7In both cases, the predicted labelling for a test document is given by the most probable (Viterbi) sequenceaccording to the trained model.
We use the following feature sets:5In order to address concerns about the suitability of the t-tests under non-normality, we replicated the tests using Wilcoxon?ssigned-ranks test as recommended by Dem?sar (2006); the results were identical.6http://www.csie.ntu.edu.tw/?cjlin/liblinear/7http://mallet.cs.umass.edu/10LR CRFModel Acc P R F Acc P R FBASELINE 0.83 0.71 0.70 0.70 0.85 0.75 0.64 0.67+BOILERPLATE-LDA 0.84 0.72 0.71 0.71 0.86 0.74 0.65 0.68+LDA-BAG (50) 0.83 0.69 0.68 0.68 0.84 0.73 0.62 0.64+LDA-BAG (100) 0.83 0.69 0.69 0.69 0.84 0.72 0.64 0.66+LDA-MAX (50) 0.83 0.71 0.69 0.69 0.85 0.72 0.64 0.66+LDA-MAX (100) 0.84 0.71 0.69 0.70 0.85 0.74 0.63 0.66Table 2: Results of the supervised evaluationBASELINE: Our baseline set of features is a standard set for supervised argumentative zoning: allunigrams and bigrams in the sentence, all part-of-speech tags in the sentence and a location featurecomputed by dividing the abstract into 5 bins.+BOILERPLATE-LDA: The baseline model with additional features corresponding to the zone indexassigned by BOILERPLATE-LDA to the sentence.
We set |Z| = 10, |T | = 100 since that settingperformed best in the clustering evaluation.
As before, we use the output of three independentlylearned sampling chains, giving each sentence three zone features; the classifier should learn whichchains are better than others during training.+LDA-BAG: The baseline model with additional features derived from standard Latent Dirichlet Alloca-tion models trained on the same corpus as BOILERPLATE-LDA.
As LDA assigns a topic to eachword in a sentence, we add all topics assigned to all words in the sentence as additional features.
Asabove, we use the output of three sampling chains.
We report results for models with 50 topics and100 topics.+LDA-MAX: The baseline model with additional features derived from LDA models.
Here each modelassigns each sentence the single topic assigned to the greatest number of words in the sentence (tiesare broken randomly).5.3.3 ResultsResults for the supervised evaluation are presented in Table 2.
+BOILERPLATE-LDA is the only aug-mented feature set that consistently gives an improvement over the baseline features.
The improvementsin accuracy are statistically significant (p < 0.01).
In every case but one (which is not statisticallysignificant), the LDA models fail to improve on the baseline in either accuracy or F-Score, showing thatthe latent structure induced by BOILERPLATE-LDA captures aspects of rhetorical language that are notcaptured by topical word clustering.6 ConclusionWe consider the work presented in this paper to be a first step towards the ambitious goal of inducinglatent descriptions of the templates used by scientists and writers in other fields.
We have shown how ourhypothesis about the generality of rhetorical language allows the construction of models that can separateout topical and rhetorical language use.
One focus for future work will be to enrich the model structure; anapproach based on adaptor grammars (Johnson et al., 2006) could be used to break the reductive unigramassumption in BOILERPLATE-LDA and identify multiword collocations that carry rhetorical information.Another focus will be to broaden our understanding of how unsupervised rhetorical models trained onlarge corpora can improve the robustness of supervised systems.
For example, we have observed thatlexicalised AZ classifiers trained on texts from one scientific domain will often perform poorly on textsfrom another domain; unsupervised models have the potential to induce relevant lexical commonalitiesacross domains.11AcknowledgementsThis research is supported by the Intelligence Advanced Research Projects Activity (IARPA) via De-partment of Interior National Business Center (DoI/NBC) contract number D11PC20153.
The U.S.Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstandingany copyright annotation thereon.
Disclaimer: The views and conclusions contained herein are those ofthe authors and should not be interpreted as necessarily representing the official policies or endorsements,either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government.ReferencesAmr Ahmed and Eric P. Xing.
2010.
Staying informed: Supervised and semi-supervised multi-view topicalanalysis of ideological perspective.
In Proceedings of EMNLP-10, Cambridge, MA.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003.
Latent Dirichlet allocation.
Journal of MachineLearning Research, 3:993?1022.Jill Burstein, Daniel Marcu, and Kevin Knight.
2003.
Finding the WRITE stuff: Automatic identification ofdiscourse structure in student essays.
IEEE Intelligent Systems, 18(1):32?39.Harr Chen, S.R.K.
Branavan, Regina Barzilay, and David R. Karger.
2009.
Global models of document structureusing latent permutations.
In Proceedings of NAACL-09, Boulder, CO.Danish Contractor, Yufan Guo, and Anna Korhonen.
2012.
Using argumentative zones for extractive summariza-tion of scientific articles.
In Proceedings of COLING-12, Mumbai, India.Janez Dem?sar.
2006.
Statistical comparisons of classifiers over multiple data sets.
Journal of Machine LearningResearch, 7:1?30.Thomas G. Dietterich.
1998.
Approximate statistical tests for comparing supervised classification learning algo-rithms.
Neural Computation, 10(7):1895?1923.Lan Du, Wray Buntine, and Mark Johnson.
2013.
Topic segmentation with a structured topic model.
In Proceed-ings of NAACL-13, Atlanta, GA.Jacob Eisenstein and Regina Barzilay.
2008.
Bayesian unsupervised topic segmentation.
In Proceedings ofEMNLP-08, Honolulu, HI.Jianfeng Gao and Mark Johnson.
2008.
A comparison of Bayesian estimators for unsupervised Hidden MarkovModel POS taggers.
In Proceedings of EMNLP-08, Honolulu, HI.Thomas L. Griffiths, Mark Steyvers, David M. Blei, and Joshua B. Tenenbaum.
2004.
Integrating topics andsyntax.
In Proceedings of NIPS-04, Vancouver, BC.Amit Gruber, Michal Rosen-Zvi, and Yair Weiss.
2007.
Hidden topic Markov models.
In Proceedings of AISTATS-07, San Juan, Puerto Rico.Yufan Guo, Anna Korhonen, Maria Liakata, Ilona Silins, Lin Sun, and Ulla Stenius.
2010.
Identifying the informa-tion structure of scientific abstracts: An investigation of three different schemes.
In Proceedings of BioNLP-10,Uppsala, Sweden.Yufan Guo, Anna Korhonen, Maria Liakata, Ilona Silins, Johan H?ogberg, and Ulla Stenius.
2011a.
A comparisonand user-based evaluation of models of textual information structure in the context of cancer risk assessment.BMC Bioinformatics, 12:69.Yufan Guo, Anna Korhonen, and Thierry Poibeau.
2011b.
A weakly-supervised approach to argumentative zoningof scientific documents.
In Proceedings of EMNLP-11, Edinburgh, UK.Kenji Hirohata, Naoaki Okazaki, Sophia Ananiadou, and Mitsuru Ishizuka.
2008.
Identifying sections in scientificabstracts using conditional random fields.
In Proceedings of IJCNLP-08, Hyderabad, India.Lawrence Hubert and Phipps Arabie.
1985.
Comparing partitions.
Journal of Classification, 2(1):193?218.Mark Johnson, Thomas L. Griffiths, and Sharon Goldwater.
2006.
Adaptor grammars: A framework for specifyingcompositional nonparametric Bayesian models.
In Proceedings of NIPS-06, Vancouver, BC.12Anna Korhonen, Ilona Silins, Lin Sun, and Ulla Stenius.
2009.
The first step in the development of text min-ing technology for cancer risk assessment: identifying and organizing scientific evidence in risk assessmentliterature.
BMC Bioinformatics, 10:303.Nitin Madnani, Michael Heilman, Joel Tetreault, and Martin Chodorow.
2012.
Identifying high-level organiza-tional elements in argumentative discourse.
In Proceedings of NAACL-12, Montreal, QC.William C. Mann and Sandra A. Thompson.
1988.
Rhetorical structure theory: Toward a functional theory of textorganization.
Text, 8(3):243?281.Daniel Marcu.
2000.
The rhetorical parsing of unrestricted texts: A surface-based approach.
ComputationalLinguistics, 26(3):395?448.Thomas P. Minka.
2003.
Estimating a Dirichlet distribution.
Available at http://research.microsoft.com/en-us/um/people/minka/papers/dirichlet/.Radford M. Neal.
2010.
MCMC using Hamiltonian dynamics.
In Steve Brooks, Andrew Gelman, Galin L. Jones,and Xiao-Li Meng, editors, Handbook of Markov Chain Monte Carlo.
Chapman and Hall/CRC Press, BocaRaton, FL.Matthew Purver, Konrad K?ording, Tom Griffiths, and Josh Tenenbaum.
2006.
Unsupervised topic modelling formulti-party spoken discourse.
In Proceedings of COLING-ACL-06, Sydney, Australia.Roi Reichart and Anna Korhonen.
2012.
Document and corpus level inference for unsupervised and transductivelearning of information structure of scientific documents.
In Proceedings of COLING-12, Mumbai, India.Joseph Reisinger and Raymond Mooney.
2010.
A mixture model with sharing for lexical semantics.
In Proceed-ings of EMNLP-10, Cambridge, MA.Alan Ritter, Colin Cherry, and Bill Dolan.
2010.
Unsupervised modeling of Twitter conversations.
In Proceedingsof NAACL-HLT-10, Los Angeles, CA.Christina Sauper and Regina Barzilay.
2009.
Automatically generating Wikipedia articles: A structure-awareapproach.
In Proceedings of ACL-IJCNLP-09, Singapore.Advaith Siddharthan and Simone Teufel.
2007.
Whose idea was this, and why does it matter?
Attributing scientificwork to citations.
In Proceedings of NAACL-07, Rochester, NY.Simone Teufel and Marc Moens.
2002.
Summarizing scientific articles: Experiments with relevance and rhetoricalstatus.
Computational Linguistics, 28(4):409?445.Simone Teufel.
2010.
The Structure of Scientific Articles: Applications to Citation Indexing and Summarization.CSLI Publications, Stanford, CA.Andrea Varga, Daniel Preot?iuc-Pietro, and Fabio Ciravegna.
2012.
Unsupervised document zone identificationusing probabilistic graphical models.
In Proceedings of LREC-12, Istanbul, Turkey.Nguyen Xuan Vinh, Julien Epps, and James Bailey.
2010.
Information theoretic measures for clusterings com-parison: Variants, properties, normalization and correction for chance.
Journal of Machine Learning Research,11:2837?2854.Hanna M. Wallach.
2008.
Structured topic models for language.
Ph.D. thesis, University of Cambridge.13
