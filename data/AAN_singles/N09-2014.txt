Proceedings of NAACL HLT 2009: Short Papers, pages 53?56,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsTowards Natural Language Understanding of Partial Speech RecognitionResults in Dialogue SystemsKenji Sagae and Gwen Christian and David DeVault and David R. TraumInstitute for Creative Technologies, University of Southern California13274 Fiji Way, Marina del Rey, CA 90292{sagae,gchristian,devault,traum}@ict.usc.eduAbstractWe investigate natural language understand-ing of partial speech recognition results toequip a dialogue system with incremental lan-guage processing capabilities for more realis-tic human-computer conversations.
We showthat relatively high accuracy can be achievedin understanding of spontaneous utterancesbefore utterances are completed.1 IntroductionMost spoken dialogue systems wait until the userstops speaking before trying to understand and re-act to what the user is saying.
In particular, in atypical dialogue system pipeline, it is only once theuser?s spoken utterance is complete that the resultsof automatic speech recognition (ASR) are sent onto natural language understanding (NLU) and dia-logue management, which then triggers generationand synthesis of the next system prompt.
Whilethis style of interaction is adequate for some appli-cations, it enforces a rigid pacing that can be un-natural and inefficient for mixed-initiative dialogue.To achieve more flexible turn-taking with humanusers, for whom turn-taking and feedback at the sub-utterance level is natural and common, the systemneeds to engage in incremental processing, in whichinterpretation components are activated, and in somecases decisions are made, before the user utteranceis complete.There is a growing body of work on incremen-tal processing in dialogue systems.
Some of thiswork has demonstrated overall improvements in sys-tem responsiveness and user satisfaction; e.g.
(Aistet al, 2007; Skantze and Schlangen, 2009).
Severalresearch groups, inspired by psycholinguistic mod-els of human processing, have also been exploringtechnical frameworks that allow diverse contextualinformation to be brought to bear during incremen-tal processing; e.g.
(Kruijff et al, 2007; Aist et al,2007).While this work often assumes or suggests it ispossible for systems to understand partial user ut-terances, this premise has generally not been givendetailed quantitative study.
The contribution of thispaper is to demonstrate and explore quantitativelythe extent to which one specific dialogue system cananticipate what an utterance means, on the basis ofpartial ASR results, before the utterance is complete.2 NLU for spontaneous spoken utterancesin a dialogue systemFor this initial effort, we chose to look at incrementalprocessing of natural language understanding in theSASO-EN system (Traum et al, 2008), a complexspoken dialog system for which we have a corpusof user data that includes recorded speech files thathave been transcribed and annotated with a semanticrepresentation.
The domain of this system is a nego-tiation scenario involving the location of a medicalclinic in a foreign country.
The system is intended asa negotiation training tool, where users learn aboutnegotiation tactics in the context of the culture andsocial norms of a particular community.2.1 The natural language understanding taskThe NLU module must take the output of ASR asinput, and produce domain-specific semantic framesas output.
These frames are intended to capturemuch of the meaning of the utterance, although a53dialogue manager further enriches the frame rep-resentations with pragmatic information (Traum,2003).
NLU output frames are attribute-value ma-trices, where the attributes and values are linked to adomain-specific ontology and task model.Complicating the NLU task of is the relativelyhigh word error rate (0.54) in ASR of user speechinput, given conversational speech in a complex do-main and an untrained broad user population.The following example, where the user attemptsto address complaints about lack of power in the pro-posed location for the clinic, illustrates an utterance-frame pair.?
Utterance (speech): we are prepared to giveyou guys generators for electricity downtown?
ASR (NLU input): we up apparently give youguys generators for a letter city don town?
Frame (NLU output):<s>.mood declarative<s>.sem.agent kirk<s>.sem.event deliver<s>.sem.modal.possibility can<s>.sem.speechact.type offer<s>.sem.theme power-generator<s>.sem.type eventThe original NLU component for this system wasdescribed in (Leuski and Traum, 2008).
For the pur-poses of this experiment, we have developed a newNLU module and tested on several different datasets as described in the next section.
Our approachis to use maximum entropy models (Berger et al,1996) to learn a suitable mapping from features de-rived from the words in the ASR output to semanticframes.
Given a set of examples of semantic frameswith corresponding ASR output, a classifier shouldlearn, for example, that when ?generators?
appearsin the output of ASR, the value power-generators islikely to be present in the output frame.
The specificfeatures used by the classifier are: each word in theinput string (bag-of-words representation of the in-put), each bigram (consecutive words), each pair ofany two words in the input, and the number of wordsin the input string.0102030405060 123456789101112131415161718192021222324Lengthn (words)Number of utterances (bars)050100150200250300350400450Cumulative number ofutterances (line)Exactly n wordsAt most n wordsFigure 1: Length of utterances in the development set.2.2 DataOur corpus consists of 4,500 user utterances spreadacross a number of different dialogue sessions.
Ut-terances that were out-of-domain (13.7% of the cor-pus) were assigned a ?garbage?
frame, with no se-mantic content.
Approximately 10% of the utter-ances were set aside for final testing, and another10% was designated the development corpus for theNLU module.
The development and test sets werechosen so that all the utterances in a session werekept in the same set, but sessions were chosen at ran-dom for inclusion in the development and test sets.The training set contains 136 distinct frames,each of which is composed of several attribute-valuepairs, called frame elements.
Figure 1 shows the ut-terance length distribution in the development set.2.3 NLU results on complete ASR outputTo evaluate NLU results, we look at precision, re-call and f-score of frame elements.
When the NLUmodule is trained on complete ASR utterances inthe training set, and tested on complete ASR utter-ances in the development set, f-score of frame ele-ments is 0.76, with precision at 0.78 and recall at0.74.
To gain insight on what the upperbound onthe accuracy of the NLU module might be, we alsotrained the classifier using features extracted fromgold-standard manual transcription (instead of ASRoutput), and tested the accuracy of analyses of gold-standard transcriptions (which would not be avail-able at run-time in the dialogue system).
Underthese ideal conditions, NLU f-score is 0.87.
Trainingon gold-standard transcriptions and testing on ASRoutput produces results with a lower f-score, 0.74.543 NLU on partial ASR resultsRoughly half of the utterances in our training datacontain six words or more, and the average utter-ance length is 5.9 words.
Since the ASR module iscapable of sending partial results to the NLU mod-ule even before the user has finished an utterance, inprinciple the dialogue system can start understand-ing and even responding to user input as soon asenough words have been uttered to give the systemsome indication of what the user means, or evenwhat the user will have said once the utterance iscompleted.
To measure the extent to which our NLUmodule can predict the frame for an input utterancewhen it sees only a partial ASR result with the firstn words, we examine two aspects of NLU with par-tial ASR results.
The first is correctness of the NLUoutput with partial ASR results of varying lengths, ifwe take the gold-standard manual annotation for theentire utterance as the correct frame for any of thepartial ASR results for that utterance.
The second isstability: how similar the NLU output with partialASR results of varying lengths is to what the NLUresult would have been for the entire utterance.3.1 Training the NLU module for analysis ofpartial ASR resultsThe simplest way to performNLU of partial ASR re-sults is simply to process the partial utterances usingthe NLU module trained on complete ASR output.However, better results may be obtained by train-ing separate NLU models for analysis of partial ut-terances of different lengths.
To train these sepa-rate NLU models, we first ran the audio of the utter-ances in the training data through our ASR module,recording all partial results for each utterance.
Then,to train a model to analyze partial utterances con-taining n words, we used only partial utterances inthe training set containing n words (unless the entireutterance contained less than n words, in which casewe simply used the complete utterance).
In somecases, multiple partial ASR results for a single utter-ance contained the same number of words, and weused the last partial result with the appropriate num-ber of words 1.
We trained separate NLU models for1At run-time, this can be closely approximated by takingthe partial utterance immediately preceding the first partial ut-terance of length n+ 1.0102030405060708012345678910allLengthn (words)F-scoreTrained on all dataTrained on partialsup tolengthnTrained on partialsup tolengthn + contextFigure 2: Correctness for three NLU models on partialASR results up to n words.n varying from one to ten.3.2 ResultsFigure 2 shows the f-score for frames obtained byprocessing partial ASR results up to length n usingthree NLU models.
The dashed line is our baselineNLU model, trained on complete utterances only(model 1).
The solid line shows the results obtainedwith length-specific NLU models (model 2), and thedotted line shows results for length-specific modelsthat also use features that capture dialogue context(model 3).
Models 1 and 2 are described in the previ-ous sections.
The additional features used in model3 are unigram and bigram word features extractedfrom the most recent system utterance.As seen in Figure 2, there is a clear benefit totraining NLU models specifically tailored for partialASR results.
Training a model on partial utteranceswith four or five words allows for relatively high f-score of frame elements (0.67 and 0.71, respectively,compared to 0.58 and 0.66 when the same partialASR results are analyzed using model 1).
Consider-ing that half of the utterances are expected to havemore than five words (based on the length of the ut-terances in the training set), allowing the system tostart processing user input when four or five-wordpartial ASR results are available provides interestingopportunities.
Targeting partial results with sevenwords or more is less productive, since the time sav-ings are reduced, and the gain in accuracy is modest.The context features used in model 3 did not pro-vide substantial benefits in NLU accuracy.
It is pos-55010203040506070809010012345678910Lengthn of partial ASR output used in model 2Stability F-scoreFigure 3: Stability of NLU results for partial ASR resultsup to length n.sible that other ways of representing context or di-alogue state may be more effective.
This is an areawe are currently investigating.Finally, figure 3 shows the stability of NLU re-sults produced by model 2 for partial ASR utter-ances of varying lengths.
This is intended to be anindication of how much the frame assigned to a par-tial utterance differs from the ultimate NLU outputfor the entire utterance.
This ultimate NLU outputis the frame assigned by model 1 for the completeutterance.
Stability is then measured as the F-scorebetween the output of model 2 for a particular partialutterance, and the output of model 1 for the corre-sponding complete utterance.
A stability F-score of1.0 would mean that the frame produced for the par-tial utterance is identical to the frame produced forthe entire utterance.
Lower values indicate that theframe assigned to a partial utterance is revised sig-nificantly when the entire input is available.
As ex-pected, the frames produced by model 2 for partialutterances with at least eight words match closelythe frames produced by model 1 for the complete ut-terances.
Although the frames for partial utterancesof length six are almost as accurate as the frames forthe complete utterances (figure 2), figure 3 indicatesthat these frames are still often revised once the en-tire input utterance is available.4 ConclusionWe have presented experiments that show that itis possible to obtain domain-specific semantic rep-resentations of spontaneous speech utterances withreasonable accuracy before automatic speech recog-nition of the utterances is completed.
This allows forinteresting opportunities in dialogue systems, suchas agents that can interrupt the user, or even finishthe user?s sentence.
Having an estimate of the cor-rectness and stability of NLU results obtained withpartial utterances allows the dialogue system to es-timate how likely its initial interpretation of an userutterance is to be correct, or at least agree with itsultimate interpretation.
We are currently working onthe extensions to the NLU model that will allow forthe use of different types of context features, and in-vestigating interesting ways in which agents can takeadvantage of early interpretations.AcknowledgmentsThe work described here has been sponsored by theU.S.
Army Research, Development, and Engineer-ing Command (RDECOM).
Statements and opin-ions expressed do not necessarily reflect the positionor the policy of the United States Government, andno official endorsement should be inferred.ReferencesG.
Aist, J. Allen, E. Campana, C. G. Gallo, S. Stoness,M.
Swift, and M. K. Tanenhaus.
2007.
Incrementaldialogue system faster than and preferred to its non-incremental counterpart.
In Proc.
of the 29th AnnualConference of the Cognitive Science Society.A.
L. Berger, S. A. Della Pietra, and V. J. Della Pietra.1996.
A maximum entropy approach to naturallanguage processing.
Computational Linguistics,22(1):39?71.G.
J. Kruijff, P. Lison, T. Benjamin, H. Jacobsson, andN.
Hawes.
2007.
Incremental, multi-level processingfor comprehending situated dialogue in human-robotinteraction.
In Language and Robots: Proc.
from theSymposium (LangRo?2007).
University of Aveiro, 12.A.
Leuski and D. Traum.
2008.
A statistical approachfor text processing in virtual humans.
In 26th ArmyScience Conference.G.
Skantze and D. Schlangen.
2009.
Incremental dia-logue processing in a micro-domain.
In Proc.
of the12th Conference of the European Chapter of the ACL.D.
Traum, S. Marsella, J. Gratch, J. Lee, and A. Hartholt.2008.
Multi-party, multi-issue, multi-strategy negotia-tion for multi-modal virtual agents.
In Proc.
of Intelli-gent Virtual Agents Conference IVA-2008.D.
Traum.
2003.
Semantics and pragmatics of ques-tions and answers for dialogue agents.
In Proc.
of theInternational Workshop on Computational Semantics,pages 380?394, January.56
