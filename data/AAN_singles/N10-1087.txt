Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 618?626,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsNot All Seeds Are Equal: Measuring the Quality of Text Mining SeedsZornitsa Kozareva and Eduard HovyUSC Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{kozareva,hovy}@isi.eduAbstractOpen-class semantic lexicon induction is ofgreat interest for current knowledge harvest-ing algorithms.
We propose a general frame-work that uses patterns in bootstrapping fash-ion to learn open-class semantic lexicons fordifferent kinds of relations.
These patterns re-quire seeds.
To estimate the goodness (the po-tential yield) of new seeds, we introduce a re-gression model that considers the connectiv-ity behavior of the seed during bootstrapping.The generalized regression model is evaluatedon six different kinds of relations with over10000 different seeds for English and Span-ish patterns.
Our approach reaches robust per-formance of 90% correlation coefficient with15% error rate for any of the patterns whenpredicting the goodness of seeds.1 Introduction: What is a Good Seed?The automated construction of semantically typedlexicons (terms classified into their appropriate se-mantic class) from unstructured text is of great im-portance for various kinds of information extraction(Grishman and Sundheim, 1996), question answer-ing (Moldovan et al, 1999), and ontology popu-lation (Suchanek et al, 2007).
Maintaining largesemantic lexicons is a time-consuming and tedioustask, because open classes (such as: all singers, alltypes of insects) are hard to cover completely, andeven closed classes (such as: all countries, all largesoftware companies) change over time.
Since it ispractically impossible for a human to collect suchknowledge adequately, many supervised, unsuper-vised, and semi-supervised techniques have been de-veloped.All these techniques employ some sort of contextto specify the appearance in text of the desired in-formation.
This approach is based on the generalintuition, dating back at least to the distributionalsimilarity idea of (Harris, 1954), that certain con-texts are specific enough to constrain terms or ex-pressions within them to be specific classes or types.Often, the context is a string of words with an emptyslot for the desired term(s); sometimes, it is a regu-lar expression-like pattern that includes word classes(syntactic or semantic); sometimes, it is a more ab-stract set of features, including orthographic fea-tures like capitalization, words, syntactic relations,semantic types, and other characteristics, which isthe more complete version of the distributional sim-ilarity approach.In early information extraction work, these con-texts were constructed manually, and resembled reg-ular expressions (Appelt et al, 1995).
More re-cently, researchers have focused on learning themautomatically.
Since unsupervised algorithms re-quire large training data and may or may not producethe types and granularities of the semantic class de-sired by the user, and supervised algorithms may re-quire a lot of manual oversight, semi-supervised al-gorithms have become more popular.
They requireonly a couple of seeds (examples filling the desiredsemantic context) to enable the learning mechanismto learn patterns that extract from unlabeled textsadditional instances of the same class (Riloff andJones, 1999; Etzioni et al, 2005; Pasca, 2004).Sometimes, the pattern(s) learned are satisfactory618enough to need no further elaboration.
They areapplied to harvest as many additional terms of thedesired type as possible (for example, the instance-learning pattern ?<type> such as ??
introduced in(Hearst, 1992)).
More often, the method is appliedrecursively: once some pattern(s) have been learned,they are used to find additional terms, which are thenused as new seeds in the patterns to search for addi-tional new patterns, etc., until no further patterns arefound.
At that point, the satisfactory patterns are se-lected and large-scale harvesting proceeds as usual.In an interesting variation of this method, (Kozarevaet al, 2008) describe the ?doubly-anchored pat-tern?
(DAP) that includes a seed term in conjunc-tion with the open slot for the desired terms to belearned, making the pattern itself recursive by al-lowing learned terms to replace the initial seed termsdirectly: ?<type> such as <seed> and ?
?.Context-based information harvesting is well un-derstood and has been the focus of extensive re-search.
The core unsolved problem is the selec-tion of seeds.
In current knowledge harvesting al-gorithms, seeds are chosen either at random (Davi-dov et al, 2007; Kozareva et al, 2008), by pickingthe top N most frequent terms of the desired class(Riloff and Jones, 1999; Igo and Riloff, 2009), or byasking experts (Pantel et al, 2009).
None of thesemethods is quite satisfactory.
(Etzioni et al, 2005)report on the impact of seed set noise on the finalperformance of semantic class learning, and Pan-tel et al observe a tremendous variation in the en-tity set expansion depending on the initial seed setcomposition.
These studies show that the selectionof ?good?
seeds is very important.
Recently, (Vyaset al, 2009) proposed an automatic system for im-proving the seeds generated by editors (Pantel et al,2009).
The results show 34% improvement in finalperformance using the appropriate seed set.
How-ever, using editors to select seeds or to guide theirseed selection process is expensive and therefore notalways possible.
Because of this, we address in thispaper two questions: ?What is a good seed??
and?How can the goodness of seeds be automaticallymeasured without human intervention?
?.The contributions of this paper are as follows:?
First, we use recursive patterns to automaticallylearn seeds for open-class semantic lexicons.?
Second, we define what the ?goodness?
of aseed term is.
Then we introduce a regressionmodel of seed quality measurement that, aftera certain amount of training, automatically es-timates the goodness of new seeds with above90% accuracy for bootstrapping with the givenrelation.?
Next, importantly, we discover that training aregression model on certain relations enablesone to predict the goodness of a seed even forother relations that have never been seen be-fore, with an accuracy rate of over 80%.?
We conduct experiments with six kinds ofrelations and more than 10000 automaticallyharvested seed examples in both English andSpanish.The rest of the paper is organized as follows.In the next section, we review related work.
Sec-tion 3 describes the recursive pattern bootstrap-ping (Kozareva et al, 2008).
Section 4 presents ourseed quality measurement regression model.
Sec-tion 5 discusses experiments and results.
Finally, weconclude in Section 6.2 Related WorkSeeds are used in automatic pattern extraction fromtext corpora (Riloff and Jones, 1999) and from theWeb (Banko, 2009).
Seeds are used to harvest in-stances (Pasca, 2004; Etzioni et al, 2005; Kozarevaet al, 2008) or attributes of a given class (Pas?ca andVan Durme, 2008), or to learn concept-specific re-lations (Davidov et al, 2007), or to expand alreadyexisting entity sets (Pantel et al, 2009).
As men-tioned above, (Etzioni et al, 2005) report that seedset composition affects the correctness of the har-vested instances, and (Pantel et al, 2009) observe anincrement of 42% precision and 39% recall betweenthe best and worst performing seed sets for the taskof entity set expansion.Because of the large diversity of the usage ofseeds, there has been no general agreement regard-ing exactly how many seeds are necessary for agiven task.
According to (Pantel et al, 2009) 10 to20 seeds are a sufficient starting set in a distribu-tional similarity model to discover as many new cor-rect instances as may ever be found.
This observa-tion differs from the claim of (Pas?ca and Van Durme,2008) that 1 or 2 instances are sufficient to dis-cover thousands of instance attributes.
For some619pattern-based algorithms one to two seeds are suf-ficient (Davidov et al, 2007; Kozareva et al, 2008),some require ten seeds (Riloff and Jones, 1999; Igoand Riloff, 2009), and others use a variation of 1, 5,10 to 25 seeds (Talukdar et al, 2008).As mentioned, seed selection is not yet well un-derstood.
Seeds may be chosen at random (Davi-dov et al, 2007; Kozareva et al, 2008), by pickingthe most frequent terms of the desired class (Riloffand Jones, 1999; Igo and Riloff, 2009), or by ask-ing humans (Pantel et al, 2009).
The intuitions forseed selection that experts develop over time seemto prefer instances that are neither ambiguous nortoo frequent, but that at the same time are prolificand quickly lead to the discovery of a diverse set ofinstances.
These criteria are vague and do not al-ways lead to the discovery of good seeds.
For someapproaches, infrequent and ambiguous seeds are ac-ceptable while for others they lead to deteriorationin performance.
For instance, the DAP (Kozareva etal., 2008) performance is not affected by the ambi-guity of the seed, because the class and the seed inthe pattern mutually disambiguate each other, whilefor the distributional similarity model of (Pantel etal., 2009), starting with an ambiguous seed leadsto ?leakage?
and the harvesting of non-true class in-stances.
(Kozareva et al, 2008) show that for theclosed class country, both high-frequency seeds likeUSA and low-frequency seeds like Burkina Fasocan equally well yield all remaining instances.
Anopen question to which no-one provides an answeris whether and which high/low frequency seeds canyield all instances of large, open classes like peopleor singers.3 Bootstrapping Recursive PatternsThere are many algorithms for harvesting informa-tion from the Web.
The main objective of our workis not the creation of a new algorithm, but rather de-termining the effect of seed selection on the gen-eral class of recursive bootstrapping harvesting al-gorithms for the acquisition of semantic lexicons foropen class relations.
For our experiments, since itis time-consuming and difficult for humans to pro-vide large sets of seeds to start the bootstrappingprocess, we employ the recursive DAP mechanismintroduced by (Kozareva et al, 2008) that producesseeds on its own.The algorithm starts with a seed of type classwhich is fed into the doubly-anchored pattern?<class> such as <seed> and *?
and learns in the* position new instances of type class.
The newlylearned instances are then systematically placed intothe position of the seed in the DAP pattern, and theharvesting process is repeated until no new instancesare found.
The general framework is as follows:1.
Given:a language L={English, Spanish}a pattern Pi={e.g., [verb prep, noun, verb]}a seed seed for Pi2.
Build a query in DAP-like fashion for Pi usingtemplate Ti of the type ?class such as seed and*?, ?
* and seed verb prep?, ?
* and seed noun?,?
* and seed verb?3.
submit Ti to Yahoo!
or another search engine4.
extract instances occupying the * position5.
take instances from 4. and go to 2.6. repeat steps 2?5 until no new instances arefoundAt the end of bootstrapping, the harvested in-stances can be considered to be seeds with whichthe bootstrapping procedure could have been initi-ated.
We can now compare any of them to studytheir relative ?goodness?
as bootstrapping seeds.4 Seed Quality Measurement4.1 Problem FormulationWe define our task as:Task Definition: Given a seed and a pattern in alanguage (say English or Spanish), (1) use the boot-strapping procedure to learn instances from the Web;(2) build a predictive model to estimate the ?good-ness?
of seeds (whether generated by a human orlearned) .Given a desired semantic class, a recursive harvest-ing pattern expressing its context, and a seed termfor use in this pattern, we define the ?goodness?
ofthe seed as consisting of two measures:?
the yield: the total number of instances learned,not counting duplicates, until the bootstrappingprocedure has run to exhaustion;?
the distance: the number of iterations requiredby the process to reach exhaustion.620Our approach is to build a model of the behavior ofmany seeds for the given pattern.
Any new seed canthen be compared against this model, once its basiccharacteristics have been determined, and its yieldand distance estimates produced.
In order to deter-mine the characteristics of the new seed, it first hasto be employed in the pattern for a small number ofiterations.
The next subsection describes the regres-sion model we employ in our approach.4.2 Regression ModelGiven a seed s, we seek to predict the yield g of s asdefined above.
We do this via a parametrized func-tion f :g?
= f(s;w), where w ?
Rd are the weights.Our approach is to learn w from a collection of Ntraining examples {< si, gi >}Ni=1, where each si isa seed and each gi ?
R.Support vector regression (Drucker et al, 1996)is a well-known method for training a regressionmodel by solving the following optimization prob-lem:minw?Rs12||w||2 + CNN?i=1max(0, |gi ?
f(si;w)| ?
?)?
??
?
?-insensitive loss functionwhere C is a regularization constant and ?
con-trols the training error.
The training algorithm findsweights w that define a function f minimizing theempirical risk.Let h be a function from seeds into some vector-space representation ?
Rd, then the function f takesthe form: f(s;w) = h(s)Tw = ?Ni=1 ?iK(s, si),where f is re-parameterized in terms of a polyno-mial kernel function K with dual weights ?i.
Kmeasures the similarity between two seeds.
Full de-tails of the regression model and its implementationare beyond the scope of this paper; for more de-tails see (Scho?lkopf and Smola, 2001; Smola et al,2003).
In our experimental study, we use the freelyavailable implementation of SVM in Weka (Wittenand Frank, 2005).To evaluate the quality of our prediction model,we compare the actual yield of a seed with the pre-dicted value obtained, and compute the correlationcoefficient and the relative absolute error.5 Experiments and Results5.1 Data CollectionWe conducted an exhaustive evaluation study withthe open semantic classes people and city, initiatedwith the seeds John and London.
For each class, wesubmitted the DAP patterns as web queries to Ya-hoo!Boss and retrieved the top 1000 web snippetsfor each query, keeping only unique instances.
Intotal, we collected 1.5GB of snippets for people and1.9GB of snippets for cities.
The algorithm ran un-til complete exhaustion, requiring 19 iterations forpeople and 12 for cities.
The total number of uniqueharvested instances was 3798 for people and 5090for cities.
We used all instances as seeds and instan-tiated for each seed the bootstrapping process fromthe very beginning.
This resulted in 3798 and 5090separate bootstrapping runs for people and cities re-spectively.
For each seed, we recorded the totalnumber of instances learned at the end of bootstrap-ping, the number of iterations, and the number ofunique instances extracted on each iteration.
Afterthe harvesting part terminated, we analyzed the con-nectivity / bootstrapping behavior of the seeds, andproduced the regression model.5.2 Seed CharacteristicsFor many knowledge harvesting algorithms, the se-lection of a non-ambiguous seeds is of great impor-tance.
In the DAP bootstrapping framework, the am-biguity of the seed is eliminated as the class and theseed mutually disambiguate each other.
Of great im-portance to the bootstrapping algorithm is the selec-tion of a seed that can yield a large number of in-stances and can keep the bootstrapping process en-ergized.Figure 1: Seed ConnectivityFigure 1 shows the different kinds of seeds wefound on analyzing the results of the bootstrappingprocess.
Based on the yield learned on each iter-ation, we identify four major kinds of seeds: her-mit, one-step, mid, and high connectors.
In thefigure, seed (a) is a hermit because it does not dis-cover other instances.
Seed (b) is a one-step connec-tor as it discovers instances on the first iteration but621then becomes inactive.
Seeds (d) and (e) are highconnectors because they find a rich population of in-stances.
Seed (c) is a mid connector because it haslower yield than (d) and (e), but higher than (a) and(b).Table 1 shows the results of classifying the 3798people and 5090 city seeds into the four kinds ofseed.
The majority of the seeds for both patterns arehermits, from 23 to 41% are high connectors, andthe rest are one-step and mid connectors.
For eachkind of seed, we also show three examples.people such as X and * examples#hermit 2271 (60%) Leila, Anne Boleyn, Sophocles#one-step 329 (9%) Helene, Frida Kahlo, Cornelius#mid 315 (8%) Brent, Ferdinand, Olivia#high 883 (23%) Diana, Donald Trump, Christophercities such as X and * examples#hermit 2393 (47%) Belfast, Najafabad, El Mirador#one-step 406 (8%) Durnstein, Wexford, Al-Qaim#mid 207 (4%) Bialystok, Gori, New Albany#high 2084 (41%) Vienna, Chicago, MarrakeshTable 1: Connectivity-based Seed Classification.This study shows that humans are very likely tochoose non-productive seeds for bootstrapping: it isdifficult for a human to know a priori that a namelike Diana will be more productive than Leila, He-lene, or Olivia.Another interesting characteristic of a seed is thespeed of learning.
Some seeds, such as (e), ex-tract large quantity of instances from the very be-ginning, resulting in fewer bootstrapping iterations,while others, such as (d), spike much later, resultingin more.
In our analysis, we found that some highconnector seeds of the people pattern can learn thewhole population in 12 iterations, while others re-quire from 15 to 20 iterations.
Figure 2 shows thespeed of learning of ten high connector seeds forthe people pattern.
The y axis shows the numberof unique instances harvested on each iteration.
In-tuitively, a good seed is the one that produces a largeyield of instances in short distance.
Thus the ?good-ness?
of seed (e) is better than that of seed (d).As shown in Figure 2, for each seed, we observea single hump that corresponds to the point in whicha seed generates the maximum number of instances.The peak occurs on different iterations because it isdependent both on the yield learned with each iter-ation and the total distance, for each seed.
The oc-010020030040050060070080090010001  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19YieldIterations1s2s3s4s5s6s7s8s9s10Figure 2: Seed Learning Speedcurrence of a single hump reveals regularity in theconnectivity behavior of seeds, and is discussed inthe Conclusion.
We model this behavior as featuresin our regression model and use it to measure thequality of new seeds.
The next subsection explainsthe features of the regression model and the experi-mental results obtained.5.3 Predicting the Goodness of SeedsBuilding a pattern specific model: For each pat-tern, we build N different regression models, whereN corresponds to the total number of bootstrappingiterations of the pattern.
For regression model Ri,we use the yield of a seed from iterations 1 to i asfeatures.
This information is used to model the ac-tivity of the seed in the bootstrapping process andlater on to predict the extraction power of new seeds.For example, in Figure 1 on the first iteration seeds(b), (c), and (d) have the same low connectivity com-pared to seed (e).
As bootstrapping progresses, seed(d) reaches productive neighbors that discover moreinstances, while seeds (b) and (c) become inactive.This example shows that the yield in the initial stageof bootstrapping is not sufficient to accurately pre-dict the quality of the seeds.
Since we do not knowexactly how many iterations are necessary to accu-rately determine the ?goodness?
of seeds, we modelthe yield learned on each iteration by each seed andsubsequently include this information in the regres-sion models.The yield of a seed sk at iteration i is computed asyield(sk)i =?nm=1(sm), where n is the total num-ber of unique instances sm harvested on iteration i.Y ield(sk)i is high when sk discovers a large numberof instances (new seeds), and small otherwise.
Forhermit seeds, yield=0 at any iteration, because theseeds are totally isolated and do not discover other622instances (seeds).
For example, when building thesecond regression model R2 using seeds (d) and (e)from Figure 1, the feature values corresponding toeach seed in R2 are: yield(sd)1=1 and yield(sd)2=2for seed (d), and yield(se)1=3 and yield(se)2=5 forseed (e).Results: Figure 3 shows the correlation coefficients(cc) and the relative absolute errors of each regres-sion model Ri for the people and city patterns.
Theresults are computed over ten-fold cross validationof the 3798 people and 5090 city seeds.
The x axisshows the regression model Ri,.
The y axis in thetwo upper graphs shows the correlation coefficientof the predicted and the actual total yield of the seedsusing Ri, and in the two lower graphs, the y axisshows the error rate of each Ri.00.10.20.30.40.50.60.70.80.911  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18CorrelationCoefficientRegression Model RiPeoplecut_off, t00.10.20.30.40.50.60.70.80.911  2  3  4  5  6  7  8  9  10  11  12  13  14  15CorrelationCoefficientRegression Model RiCitiescut_off, t0510152025303540455055601  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18RelativeAbsoluteError (%)Regression Model RiPeople05101520253035404550556065701  2  3  4  5  6  7  8  9  10  11  12  13  14  15RelativeAbsoluteError (%)Regression Model RiCitiesFigure 3: Regression for People and City.We consider as a baseline model the regressionR1 which uses only the yield of the seeds on firstiteration.
The prediction of R1 has cc=0.6 with50% error for people and cc=0.4 with 70% errorfor cities.
These results confirm our previous obser-vation that the quality of the seeds cannot be accu-rately measured in the very beginning of bootstrap-ping.
However, by the ninth iteration, the regres-sion models for people and cities reach cc=1.0 with5% error rate.
To make such an accurate prediction,the model uses around one half of all bootstrappingiterations?generally, just past the hump in Figure 2,once the yield starts dropping.Often in real applications or when under limitedresources (e.g., a fixed amount of Web queries perday), running half the bootstrapping iterations is notfeasible.
This problem can be resolved by employ-ing different stopping criteria, at the cost of lowercc and greater error.
For example, one cut-off pointcan be the (averaged) iteration number of the humpfor the given pattern.
For people, the average humpoccurs at the seventh iteration, and for the city atthe fifth iteration.
At this point, both patterns have acc=0.9 with 15% error rate.
An alternative stoppingpoint can be the fourth iteration, where cc=0.7?0.8with 35% error.Overall, our study shows that it is possible tomodel the behavior of seeds and use it to accuratelypredict the ?goodness?
of previously unseen seeds.The results obtained for both people and city pat-terns are very promising.
However, a disadvantageof this regression is that it requires training over thewhole extent of the given pattern.
Also, each regres-sion model is specific to the particular pattern it istrained over.
Next, we propose a generalized regres-sion model which surmounts the problem of trainingpattern-specific regression models.5.4 Generalized Model for Goodness of SeedsWe built a generalized regression model (RG) com-bining evidence from the people and city patterns.We generated the features of each model as previ-ously described in Section 5.3.
From each pattern,we randomly picked 1000 examples which resultedin 30% of the people and 20% of the city seeds.
Weused these seed examples to train the RGi models.In total, we built 15 RGi, which is the maximumnumber of overlapping iterations between the twopatterns.
We tested our RG model with the remain-ing 2798 people and 4090 city seeds.Figure 4 shows the results of the RGi models forthe people and city patterns.
In the first two itera-tions, the predictions of the RG model are poorercompared to the pattern-specific regression.
On thefourth iteration, both models have cc=0.7 and 0.8 forthe people and city patterns respectively.
The errorrates of the generalized model are 41% and 35% forpeople and city, while for the pattern-specific modelthe errors are 37% and 32%.
The early iterationsshow a difference of around 4% in the error rate ofthe two models, but around the ninth iteration bothmodels have comparable results.62300.10.20.30.40.50.60.70.80.911  2  3  4  5  6  7  8  9  10  11  12  13  14  15CorrelationCoefficientGeneralized Regression Model RGiCitiesPeople05101520253035404550556065701  2  3  4  5  6  7  8  9  10  11  12  13  14  15RelativeAbsoluteError (%)Generalized Regression Model RGiCitiesPeopleFigure 4: Generalized Regression for People and City.This study shows that it is possible to combineevidence from two patterns harvesting different se-mantic information to predict accurately the behav-ior of unseen seed examples for either of the twopatterns.5.5 Evaluating the Generalized Model onDifferent Languages and Kinds of PatternsSo far, we have studied the performance of the gen-eralized seed quality prediction method for specificpatterns in English.
However, the connectivity be-havior of the seeds might change for other languagesand kinds of patterns, making the generalized modelimpractical to use in such cases.
To verify this,we evaluated the generalized model (RG) from Sec-tion 5.4 with the people and city patterns in Spanish(?
gente como X y *?
and ?
ciudades como X y *?
), aswell as with two new kinds of patterns (?
* and X flyto?
and ?
* and X work for?1).
For each pattern, weran the bootstrapping process from Section 3 untilexhaustion and collected all seeds.First, for each pattern we studied the connectivitybehavior of the seeds.
Table 2 shows the obtainedresults.
The distribution is similar to the seed distri-bution for the English people and cities patterns.
Al-though the total number of harvested instances (i.e.,seeds) is different for each pattern, the proportion ofhermits to other seeds remains larger.
From 20%to 37% of the seeds are high connectors, and therest are one-step and mid connectors.
This analysisshows that the connectivity behavior of seeds acrossdifferent languages and patterns is similar, at leastfor the examples studied.
In addition to the seedanalysis, we show in the table the total number ofbootstrapping iterations for each pattern.
The ?work1The X indicates the position of the seed and (*) correspondsto the instances learned during bootstrapping.for?
and ?fly to?
patterns run for a longer distancecompared to the other patterns.
While for the ma-jority of the patterns the hump is observed on thefifth or seventh iteration, for these two patterns theaverage peak is observed on the fifteenth.gente como X y ciudades como X y#hermit 318 (56%) 1061 (51%)#one-step 58 (10%) 150 (8%)#mid 79 (14%) 79 (4%)#high 117 (20%) 795 (38%)tot#iter 20 16and X fly to and X work for#hermit 389 (45%) 1262 (48%)#one-step 87 (9%) 238 (9%)#mid 75 (8%) 214 (8%)#high 322 (37%) 922 (35%)tot#iter 26 33Table 2: Seed Classification for Spanish and Verb-PrepPatterns.Second, we test the RGi models from Section 5.4,which were trained on people and cities, to predictthe total yield of the seeds in the new patterns.
Fig-ure 5 shows the correlation coefficient and the rela-tive absolute error results of each pattern for RGi.00.10.20.30.40.50.60.70.80.911  2  3  4  5  6  7  8  9  10  11  12  13  14  15CorrelationCoefficientGeneralized Regression Model RGiWork ForFly ToCiudadesGente0510152025303540455055601  2  3  4  5  6  7  8  9  10  11  12  13  14  15RelativeAbsoluteError (%)Generalized Regression Model RGiWork ForFly ToCiudadesGenteFigure 5: Generalized Regression for Different Lan-guages and Patterns.Interestingly, we found that our generalizedmethod has consistent performance across the dif-ferent languages and patterns.
On the twelfth iter-ation, the model is able to predict the ?goodness?of seeds with cc=1.0 and from 0.4% to 8.0% errorrate.
Around the fifth and sixth iterations, all pat-terns reach cc=0.8 with error of 5% to 15%.
Thehigher error bound is for patterns like ?work for?
and?fly to?
which run for a longer distance.
This experi-mental study confirms the robustness of our general-ized model which is trained on the behavior of seedsfrom one kind of pattern and tested with seeds in dif-ferent languages and on completely different kindsof patterns.6246 Conclusions and Future WorkIt would, a fortiori, seem impossible to estimate thegoodness of a seed term used in a recursive boot-strapping pattern for harvesting information fromthe web.
After all, its eventual total yield and dis-tance depend on the cumulation of the terms pro-duced in each iteration of the bootstrapping, andthere are no external constraints or known web lan-guage structure to be exploited.We have shown that it is possible to create, usingregression, a model of the grown behavior of seedsfor a given pattern, and fitting it with an indication ofa new seed?s growth (considering its grown behaviorin a limited number of bootstrapping iterations) inorder to obtain a quite reliable estimate of the newseed?s eventual yield and distance.Going further, we are delighted to observe thatthe regularity of the single-hump harvesting behav-ior makes it possible to learn a regression model thatenables one to predict, with some accuracy, both theyield and the distance of a new seed, even when thepattern being considered is not yet seen.
All that isrequired is the indication of the seed?s growth be-havior, obtained through a number of iterations us-ing the pattern of interest.Our ongoing analysis takes the following ap-proach.
Let Ti be the set of all new terms (termsnot yet found) harvested during iteration i. ThenT0 = {t0,1}, just the initial seed term.
Let NY (ti,j)be the novel yield of term ti,j , that is, the numberof as yet undiscovered terms produced by a singleapplication of the pattern using the term ti,j .
Noticethat bootstrapping ceases when for some i = d (thedistance), ?j NY (td,j) = 0.
Since the total numberof terms that can be learned,?di=0?j NY (ti,j) =N , is finite and fixed, there are exactly three al-ternatives for the growth of the NY curve whenit is shown summed over each iteration: (i) either?j NY (ti,j) =?j NY (ti+1,j) and there is nolarger NY sum for any iteration; or (ii) ?j NY (ti,j)grows to a maximal value for some iteration i =m and then decreases again; or (iii) ?j NY (ti,j)reaches more than one locally maximal value at dif-ferent iterations.
The first case, in which exactlythe same number of new terms is harvested everyiteration for several or all iterations, would requirethat each new term once learned yields precisely andonly one subsequent new term, or that the numberof hermits is exactly balanced by the NY of one ormore of the other terms in that iteration.
This situa-tion is so unlikely as to be dismissed outright.
Case(ii), in which there is a single hump, appears to behow text is written on the web, as shown in Fig-ure 2.
Case (iii), the multi-hump case, would re-quire that the terms be linked in semi-disconnected?islands?, with a relatively much smaller inter-islandconnectivity than intra-island one.
Given our stud-ies, it appears that language on the web is not orga-nized this way, at least not for the patterns we stud-ied.
However, it is not impossible: this two-humpcase would have to have occurred in (Kozareva etal., 2008) when the ambiguous seed term Georgiawas used in the DAP ?states such as Georgia and *?,where initially the US states were harvested but, atsome point, the learned term Georgia also initiatedharvesting of the ex-USSR states.
Such ?leakage?into a new semantic domain requires not only ambi-guity of the seed but also parallel ambiguity of theclass term, which is highly unlikely as well.Accepting case (ii), therefore, we postulate thatfor any (or all regular) patterns there is some iter-ation m in which ?j NY (tm,j) is maximal.
Thequestion is how rapidly the summed NY curve ap-proaches it and then abates again.
This depends onthe out-degree connectivity of terms overall.
In thepopulation of N terms for a given semantic pattern,is the distribution of out-degrees Poisson (or Zip-fian), or is it normal (Gaussian)?
In the former case,there will be a few high-degree connector terms anda large number (the long tail) of one-step and hermitterms; in the latter, there will be a small but equalnumber of low-end and high-end connector terms,with the bulk of terms falling in the mid-connectorrange.
One direction of our ongoing work is to deter-mine this distribution, and to empirically derive itsparameters.
It might be possible to discover some in-teresting regularities about the (preferential) uses ofterms within semantic domains, as reflected in termnetwork connectivity.Although not all seeds are equal, it appears tobe possible to treat them with a single regressionmodel, regardless of pattern, to predict their ?good-ness?.Acknowledgments: This research was supported byNSF grant IIS-0705091.625ReferencesDouglas E. Appelt, Jerry R. Hobbs, John Bear, David Is-rael, Megumi Kameyama, Andy Kehler, David Martin,Karen Myers, and Mabry Tyson.
1995.
SRI Interna-tional FASTUS system MUC-6 test results and analy-sis.
In Proceedings of the Sixth Message Understand-ing Conference (MUC-6), pages 237?248.Michele Banko.
2009.
Open information extraction fromthe web.
In Ph.D. Dissertation from University ofWashington.Dmitry Davidov, Ari Rappoport, and Moshel Koppel.2007.
Fully unsupervised discovery of concept-specific relationships by web mining.
In Proc.
of the45th Annual Meeting of the Association of Computa-tional Linguistics, pages 232?239, June.Harris Drucker, Chris J.C. Burges, Linda Kaufman, AlexSmola, and Vladimir Vapnik.
1996.
Support vector re-gression machines.
In Advances in NIPS, pages 155?161.Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel S. Weld, and Alexander Yates.
2005.
Unsuper-vised named-entity extraction from the web: an exper-imental study.
Artificial Intelligence, 165(1):91?134,June.Ralph Grishman and Beth Sundheim.
1996.
Messageunderstanding conference-6: a brief history.
In Pro-ceedings of the 16th conference on Computational lin-guistics, pages 466?471.Zellig S. Harris.
1954.
Distributional structure.
Word,10:140?162.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proc.
of the 14th confer-ence on Computational linguistics, pages 539?545.Sean Igo and Ellen Riloff.
2009.
Corpus-based seman-tic lexicon induction with web-based corroboration.In Proceedings of the Workshop on Unsupervised andMinimally Supervised Learning of Lexical Semantics.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008.Semantic class learning from the web with hyponympattern linkage graphs.
In Proceedings of ACL-08:HLT, pages 1048?1056.Dan I. Moldovan, Sanda M. Harabagiu, Marius Pasca,Rada Mihalcea, Richard Goodrum, Roxana Girju, andVasile Rus.
1999.
Lasso: A tool for surfing the answernet.
In TREC.Marius Pas?ca and Benjamin Van Durme.
2008.
Weakly-supervised acquisition of open-domain classes andclass attributes from web documents and query logs.In Proceedings of ACL-08: HLT.Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-Maria Popescu, and Vishnu Vyas.
2009.
Web-scaledistributional similarity and entity set expansion.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing, pages 938?947, August.Marius Pasca.
2004.
Acquisition of categorized namedentities for web search.
In Proc.
of the thirteenth ACMinternational conference on Information and knowl-edge management, pages 137?145.Ellen Riloff and Rosie Jones.
1999.
Learning dictio-naries for information extraction by multi-level boot-strapping.
In AAAI ?99/IAAI ?99: Proceedings of thesixteenth national conference on Artificial intelligenceand the eleventh Innovative applications of artificialintelligence conference innovative applications of ar-tificial intelligence.Bernhard Scho?lkopf and Alexander J. Smola.
2001.Learning with Kernels: Support Vector Machines,Regularization, Optimization, and Beyond (AdaptiveComputation and Machine Learning).
The MIT Press.Alex J. Smola, Bernhard Schlkopf, and Bernhard SchOlkopf.
2003.
A tutorial on support vector regression.Technical report, Statistics and Computing.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowledge.In WWW ?07: Proceedings of the 16th internationalconference on World Wide Web, pages 697?706.Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca,Deepak Ravichandran, Rahul Bhagat, and FernandoPereira.
2008.
Weakly-supervised acquisition of la-beled class instances using graph random walks.
InProceedings of the Conference on Empirical Methodsin Natural Language Processing, EMNLP 2008, pages582?590.Vishnu Vyas, Patrick Pantel, and Eric Crestan.
2009.Helping editors choose better seed sets for entity setexpansion.
In Proceedings of the 18th ACM Con-ference on Information and Knowledge Management,CIKM, pages 225?234.Ian H. Witten and Eibe Frank.
2005.
Data Mining: Prac-tical Machine Learning Tools and Techniques.
Mor-gan Kaufmann, second edition.626
