P ICARD:  The Next  GeneratorStephen Beale  and Sergei  N i renburgComputing Research LaboratoryBox 30001New Mexico State UniversityLas Cruces, New Mexico 88003sb,sergeK~crl.nmsu.eduAbstractThis paper 1 introduces a new line of researchwhich ensures oundness and completeness in Nat-ural Language text planners on top of an effi-cient control strategy.
The work builds on theHUNTER-GATItERER analysis system (Beale.96; Beale & Nirenburg, 96).
That system em-ploys constraint satisfaction, branch-and-boundand solution synthesis techniques to produce nearlinear-time processing for knowledge-based seman-tic analysis.
PICARD enables similar resultsfor the field of text planning by recasting local-ized means-end planning instances into abstrac-tions connected by usage constraints that al-low HUNTER-GATHERER to process the globalproblem as a simple constraint satisfaction prob-lem.
PICARD is currently being used to plan En-ghsh and Spanish text in the Mikrokosmos Ma-chine Translation Project.HUNTER-GATHERER Overv iewImplied information, background knowledge,ellipsis, coreference, figurative speech, lexicalambiguity; these are just a few of the immensechallenges a computationM-semantic systemfaces.
Nevertheless, humans process languagein real time every day with very little apparentmisunderstanding.
How can we make a com-puter do the same?By constraining the problem.
With searchspaces that can reach 10 TM and more just todeal with basic semantic dependencies in a sen-tence (disambiguating word senses and deter-mining the semantic onnections between them- or lexical choice and implementing semanticconnections for generation), exhaustive searchtechniques are untenable.
Constraint satisfac-tion problem (CSP) techniques allow early dis-ambiguation and drastic search space reduc-tion, while maintaining the integrity (sound-ness) of the solutions found.a Research reported in this paper was supported inpart by Contract MDA904-92-C-5189 from the U.S. De-partment of Defense.Beale (1996) introduced a new controlstrategy for computational-semantic process-ing.
The HUNTER-GATHERER methodol-ogy uses knowledge of constraint dependen-cies to identify small sub-problems which canbe processed independently.
Solution syn-thesis methods are then utilized to combine(gather) solutions to these sub-problems, orcircles, into larger and larger solutions untilthe entire sentence is analyzed.
As solutionsfor each circle are created, branch-and-boundand constraint satisfaction techniques are usedto prune away (hunt down) non-optimal solu-tions.HUNTER-GATHERER is a general controlstrategy that works particularly well for NLproblems.
Central to our application of thismethodology tocomputational semantics, bothin analysis and generation, is the hypothe-sis that such problems can almost always beviewed as bundles of tightly constrained sub-problems, each of which combine at higher,relatively constraint-free l vels to produce acomplete solution.
Constraint dependency in-formation, retrieved from the semantic co-occurrence information stored in the lexicon,which in turn exploits syntactic information,can be used to partition the complex disam-biguation problem into simpler sub-problems,or "circles of dependency.
"The concept of relatively independent "cir-cles of dependency" can be exploited to al-low inexpensive local analyses to be com-bined non-exponentially into global solutions.This is accomplished using a computationaltool known as solution synthesis.
Freuder(1978) introduced Solution Synthesis (SS) asa means to "gather up" all solutions for a CSPwithout resorting to traditional search meth-ods.
Freuder's algorithm created a set of two-variable nodes that contained all solutions forevery two variable combination.
These two-variable nodes were then combined into three-21variable nodes, and so on, until a node contain-ing all the variables, i.e.
the solution, was syn-thesized.
At each step, constraints were prop-agated down and then back up the "tree" ofsynthesized nodes.The HUNTER-GATHERER work extendsand generalizes the solution synthesis method-ology.
The basic idea of synthesizing solutionsets one order higher than their immediate an-cestors is discarded.
Instead, solution synthesisoperates with maximally interacting roupings(circles) of variables of any order and extendsto the highest levels of synthesizing.
Freuderonly creates econd order nodes from adjacentvariables in a list.
After that.
third and higherorder nodes are blindly created from combina-tions of second order nodes.
We redefine syn-thesis to operate on nodes of any size.
Circlesof co-constrained variables guide the synthesisprocess from beginning to end.In addition to this modified solution synthe-sis, HUNTER-GATHERER employs branch-and-bound and constraint satisfaction meth-ods to prune away non-optimal or impossi-ble solutions from the search space.
Beale,Nirenburg & Mahesh (1996) report "near" lin-ear time processing for semantic analysis, withexhaustive search spaces in the trillions re-duced to hundreds.
The PICARD system ex-tends the HUNTER-GATHERER analysis ca-pabilities to the field of text planning by usingconstraint circles to identify localized means-end plan combinations.
Constraint satisfactiontechniques can then be used to ensure that onlyconsistent plans are used together, while theother mechanisms in HUNTER-GATtlERER,solution synthesis and branch-and-bound, effi-ciently find the optimal solution.Us ing  Const ra in t  Sat i s fac t ion  toEnab le  Abst ract ionsFigure 1 is a representation f the semanticcontent of a simple natural anguage sentence.In English the sentence could be rendered"Grupo Roche acquired Dr. Andreu througha subsidiary in Spain."
The node namesare semantic oncepts taken from a language-independent ontology.
Arc labels correspondto relations between concepts.
The ontologydefines for each concept he set of arcs that areallowed/expected, as well as the appropriatefiller concepts.
For simplicity, additional se-mantic information such as temporal relation-ships are not shown.
Please consult (Beale,Nirenburg & Mahesh, 1995) for more infor-mation about semantic representation in theMikrokosmos ystem.
For our purposes, theFigure 1: Example Semantic RepresentationWAR11 OBJ :  .<VAR2: :~-Figure 2: Lexicon Entry for acquiredetails of the semantic representation a d gen-eration lexicon entries to follow are unimpor-tant; they serve only as simple examples of con-trol concepts that will apply to more complexproblems.Generation lexicon entries attempt to matchparts of the input semantic structures and mapthem into target language surface structures.For instance, a lexicon entry for the conceptACQUIRE might look like Figure 2.
TheVARs in the entry will be bound to the corre-sponding semantic structures in the input, andtheir target realization will be planned sepa-rately and inserted into the output structureas shown.
Typically, lexicon entries also con-tain semantic and pragmatic onstraints.
Forinstance, VAR1 might be constrained to beHUMAN.
The entry could also be constrainedto apply only to texts with certain stylisticcharacteristics.
Collocational constraints arealso important in generation.
Any of theseconstraints can apply locally or can be prop-agated down to the VARs.
The interplay ofconstraints i  a major factor in determining thebest overall plan.Planning for Machine Translation comes inwhen we try to combine information in var-ious lexicon entries to best match the inputsemantics with as little redundancy as possi-ble and maximal adherence to the constraints.22ACQUIRE-1ACQ UIR.L~ ~"acqutre" ' 1L ob.l: WAR2 VARI  VAR2ACQUIRE-2  "procure"ACQUIRE r subj: VAR1PP"with" MAR1 MAR2 MAR3 L obj: VAR3ACQUIRE-322VARI  VAR2 VAR3I '"lbuy" subj: VARI obj: VA_R2PP'for"L obj: V A 1~,.3Figure 3: Three entries for ACQUIREINSTRUMENT-  1V AR1 PP"th.mut,la"in.+m.nt ~ lD  obj: VAR.2 JVA.R2Figure 4: An entry for INSTRUMENTThe case study given here exemplifies the is-sues in lexical choice.
Obviously text plan-ning involves much more than simply pickingwords, but the principles outlined below applyto other components of text planning as well.Figures 3, 4 and 5 represent some possible lexi-con entries that might be used in planning tar-get English sentences for Figure 1.It would be useful if we could dividetext planning problems into relatively in-dependent sub-problems and use HUNTER-GATHERER's solution synthesis to efficientlycombine the smaller solutions.
The problem isthat solution synthesis requires an unchanging,orderly set of variables to start with.
In textplanning, as in all types of means-end plan-ning systems, there is no fixed number of vari-ables.
"Variable," in this context, refers toa set of possible plans from which one mustbe chosen.
A variable can be set up for AC-QUIRE ,  which has three possible plans.
Oneof them must be chosen.
On the other hand,sometimes a plan for instrument is needed, andsometimes not.
For instance, if ACQUIRE-lCORPORATION-  1CORPORATION ~ \["corp oratlon'' }CORPORATION-2CORPORATION ownedCby "~ORGANIZAT ION"subsidiary" \]Figure 5: Two entries for CORPORATION(Figure 3) is used, a separate sub-plan must bemade for the instrument relation.
Two "vari-ables" would be needed, one for ACQUIREand one for instrument.
If the ACQUIRE-2is used, the instrument plan and variable areunnecessary.
Lexicon entries which have differ-ent set of VARS, different preconditions and/orcontain more or fewer relations all create dif-fering amounts of sub-plans.
These differencesare compounded as different paths through thespace of possible plans are taken.PICARD solves this problem in a simple way.Means-end planning is carried out locally todetermine, for each lexicon entry, the addi-tional sub-plans that are needed.
Again, thesesub-plans correspond to VARs and missing re-lations or preconditions in the lexicon entry.For instance, the ACQUIRE-1 entry requiresa sub-plan for the missing instrument relation.For each needed sub-plan, a "usage constraint"is added to the lexicon entry that will "request"some "non-dummy ''2 sub-plan to be used thatfulfills the need.
The ACQUIRE-I entry, forexample, would receive a usage constraint thatrequires it to use one of the sub-plans for in-strument.
In addition, for each of the sub-plansthat can fill the need, a usage constraint isadded such that those entries can only be usedif "requested" by some other plan.The main benefit this gives is that a sta-ble set of "variables" can be created.
Therewill be an ACQUIRE variable, from whichone of the three lexicon entries must be se-lected.
There will be an instrument variable,from which either the entry shown in Figure 4will be used or the newly created ummy entry.These variables can then be processed by a so-lution synthesis algorithm.
Whenever a choiceis made, for instance selecting ACQUIRE-I forAQUIRE,  the constraint satisfaction mech-anism in HUNTER-GATHERER will elimi-nate all conflicting sub-plans.
Picking entry2,,Dummy,, plans are explained next.23ACQUIRE-1 will eliminate the dummy entryfor instrument.
Choosing entry ACQUIRE-2will eliminate all of the non-dummy instrumentplans, as well as all the sub-plans that are cre-ated by the instrument plans.
In this way, lo-cal plans can be linked together, but can beprocessed globally by an efficient solution syn-thesis control.Conc lus ionTo summarize, a means-end planner is usedlocally to set up possible sub-plans.
Thesub-plans are connected with a system ofusage constraints that inhibit or allow us-age depending on the other sub-plans be-ing used.
The HUNTER-GATHERER sys-tem can then efficiently process the collec-tion of sub-plans to find the best overall plan.Co,stralnt satisfaction techniques described in(Beale, 96) automatically control the combi-nation of sub-plans.
Constraint satisfactionalso ensures the soundness of all preconditionsused in the lexicon entries, including thosewhich are not related to the ideas presentedabove.
Efficiency is gained by restricting themeans-end planning component o local sub-problems.
Solutions to these sub-problemsare then combined, utilizing solution synthesis,branch-and-bound and constraint satisfaction,by HUNTER-GATHERER.The HUNTER-GATHERER control archi-tecture has been used extensively in theMikrokosmos emantic analyzer.
The follow-ing table shows actual results of semantic anal-yses of various size problems (from sentencesselected randomly from our corpus):Sent A Sent B Sent C# plans 79 95 119exhaustive 7.8 Mil 56.7 Mil 235 BilHUNT-GATHER 179 254 327It is interesting to note that a 207o increasein the number of total plans 3 (79 to 95) resultsin a 626% increase (7.8M to 56M) in the num-ber of exhaustive combinations possible, butonly a 42% increase (179 to 254) in the num-ber of combinations considered by HUNTER-GATHERER.
As one moves on to even morecomplex problems, a 25% increase (95 to 119)in the number of plans catapults the exhaustivecomplexity by 414,600% (56M to 235B) andyet only increases the HUNTER-GATHERER3The total number of "plans" corresponds to thetotal number of word senses for all the words in thesentence.complexity by 29% (254 to 327).
As the prob-lem size increases, the minor effects of non-local interactions diminish with respect o thesize of the problem.
We expect, therefore, thebehavior of this algorithm to move even closerto linear with larger problems (for example,ones involving discourse).Generation in the Mikrokosmos project isa relatively new development.
Currently weare developing methods to reverse multllin-gual analysis lexicons.
PICARD has been usedto back-translate he semantic analyses of theMikrokosmos analyzer using these reversed lex-icons.
Efficiency results similar to those re-ported above were obtained.The HUNTER-GATHERER algorithms arecomplete with respect to the set of mono-tonic solutions.
Currently, solutions with plansthat temporarily violate preconditions of otherplans (with the "violation" corrected by a laterplan) will not be allowed.
Besides this limi-tation, HUNTER-GATHERER is guaranteedto find the same solution(s) as an exhaus-tive search.
In addition, the constraint satis-faction component of HUNTER-GATHERERensures soundness.
By converting means-endplanners into a format that can be used byHUNTER-GATHER, PICARD achieves effi-cient processing with guaranteed soundnessand completeness without sacrificing the gen-erality of means-end planning.Re ferencesStephen Beale.
1996.
HUNTER-GATHERER:Applying Constraint Satisfaction, Branch-and-Bound and Solution Synthesis to Natural Lan-guage Semantics.
Technical Report, MCCS-96-289, Computing Research Lab, New Mexico StateUniv.Stephen Beale, Sergei Nirenburg and Kavi Ma-hesh.
1996.
HUNTER-GATHERER: ThreeSearch Techniques Integrated for Natural Lan-guage Semantics.
To appear in the ThirteenthNational Conference on Artificial Intelligence(AAAI96), Portland, Oregon.Stephen Beale, Sergei Nirenburg and Kavi Ma-hesh.
1995.
Semantic Analysis in the MikrokosmosMachine Translation Project.
In Proceedings ofthe2nd Symposium on Nalural Language Processing,297-307.
Bangkok, Thailand.E.C.
Freuder.
1978.
Synthesizing Constraint Ex-pressions.
Communications A CM 21 ( t 1): 958-966.24
