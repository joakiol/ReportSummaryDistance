SOME NOTES ABOUT RESEARCH AND DEVELOPMENTAT KTHRolf CarlsonDepartment  o f  Speech Communicat ion  and Mus ic  Acoust icsRoya l  Institute o f  Techno logy  (KTH)Stockho lm,  SwedenThe Department of Speech Communication and MusicAcoustics of The Royal Institute of Technology is a three-professor  department  with chairs in: SpeechCommunication, Music Acoustics, and Hearing Technology.The activities within the department are multi-disciplinarywith a concentration on research.The speech communication group is the biggest withinthe department with more than 20 researchers.
The workcovers a wide variety of topics, ranging from detailedtheoretical developments of speech production modelsthrough phonetic analyses to practical applications ofspeech technology.Contacts with other research institutions in Sweden andinternationally are well developed.
Of major importance inthis respect is the scientific journal, the STL-QPSR (SpeechTransmission Laboratory, Quarterly Progress and StatusReport) which is published three or four times a year in 1000copies distributed to 45 countries.The department is engaged in European cooperationwithin the COST-project on speech synthesis andrecognition, and has also been invited to the EuropeanCommunity project on Blindness and Technology.
Togetherwith the Swedish Telecom, we are engaged in the SAMproject (Speech Assessment Methods) in the second phase ofESPRIT.
The Swedish Teleeom is an important industrialcontact for the department.
Close technical and scientificcontacts exist with Infovox AB which markets multi-lingualtext-to-speech and also recognition products based on ourresearch and development.For many years we have been engaged in studyingspeaker characteristics both from an analytical point of viewand in modelling different speaker and speaking styles.
Aspeech database is under development in which realizationsof segmental and prosodic structures are investigated.Variation in coarticulation strategies, reductions andelaborations along the hypo/hyper speech dimension will bestudied in context on this database.
Studies of positionalvariants of sonorants and duration models have already beencarried out.The text-to-speech project \[8\] has recently focused onimproved prosodic models and new strategies for segmentalsynthesis.
A new synthesis model has been developed whichincludes a new model of the voice source.
It will increase thepossibilities of modelling different speaker characteristicsand speaking styles.
Methods in the speech recognitionproject have been influenced by this work.
As a consequencethe two projects are, in some respect, merging.
This hasmade our speech recognition efforts slightly different fromthe general trend.We now emphasize the research on knowledge-basedrecognition for large vocabularies.
The research program"Nebula" \[4,5\], includes, for example, speech analysis basedon auditory models, feature extraction in a parallel network\[9\], and prediction models based on speech synthesis\[1,2,3\].A major effort at the department has been to study voicesource characteristics \[6\].
The voice source has pronouncedeffects on the overall shape of the speech spectrum.
Intra-speaker voice source variation can cause severe spectraldistortion and contributes to recognition errors in currentspeaker-independent as well as in speaker-dependentrecognition systems.
The high frequency region of thespeech spectrum can vary by 20-30 dB relative to the low-frequency region for a single speaker and still more betweenamong speakers.
The voice source carries mainly non-segmental information (apart from the voiced/unvoiceddistinction).
The prosodic information carried by the voicesource is important and should not be discarded.
Thisinformation is lost in many of the current echniques usingparameter estimation methods intended to be insensitive tovoice source behavior.
Since the voice characteristics arechanging during an utterance, the adaptation should be partof the recognition process itself.
The speed of theadaptation should be faster than in normal acousticadaptation.
Modelling the source of variation rather thanthe effect on the speech acoustics potentially makes fastadaptation possible.As more explicit knowledge on speech production iscollected and formulated, it is of interest to explore the use ofsuch information in speech recognition research.
Adescription of speech on a level closer to articulation, ratherthan the acoustic base that is used in present-day speechrecognition will make generalization to different speakerseasier.
The production component in the form of a speechsynthesis ystem will ideally make the collection of trainingdata unnecessary.
During the last year, special projectsstudying speaker-independent recognition based on storedphoneme prototypes have been undertaken \[3\].
In theseexperiments, the references are generated during therecognition process itself.
Thus, it is possible todynamically take into account word juncture and wordposition effects.
The synthetic references can be modified tomatch the voice of the current speaker.
The experimentshave shown promising results, see Table 1.12aburw natural referencesDTWFinite statenetworkFinite statenetworksynthetic references from atext-to-speech systemsynthetic referencessynthetic references withvoice adaptation93%89%88%96%Table 1.
Results of pilot experiments using syntheticreferences d) with and c) without adaption.
The scoreindicates correct word identification i  an isolated wordrecognition test.
Our text-to-speech system was used asa base-line in b) and human speakers in a).Artificial neural networks have also been explored as partof a recognition system \[9\].
We know from linguisticresearch that phonetic features are a powerful tool to separatephones from each other.
A special network was trained torecognize anumber of features.
The features were recognizedwith 80% to 95% accuracy.
The features were combined withthe original spectrum as input to a phone recognizer.
Thework will be continued with a dynamic assignment of featurestrengths.Most of the speech technology application studies arenow made outside the department.
Some recent hesis workhas, however, been devoted to this, e.g., speech recognitionfor air traffic controllers and speech synthesis in the processindustry.
Speech recognition has also been used in a systemfor environment control for persons with severe mobilityimpairments.
Speech recognition for mobile telephony hasbeen developed in cooperation with Infovox and Ericsson.The noisy environment in the car has called for severalmodifications to the original algorithms.ACKNOWLEDGEMENTSThe work is supported bythe Swedish Board for TechnicalDevelopment.
I would also like to thank the organizingcommittee for inviting foreign guests to participate in thisinteresting workshop.REFERENCES1.
Blomberg, M. (1989): "Synthetic phoneme prototypes ina connected-word speech recognition system,"in Proe.ICASSP-Glasgow, Vol.
1, Edinburgh, UK2.
Blomberg, M. (1989): "Voice source adaptation ofsynthetic phoneme spectra in speech recognition," inEurospeech 89, Paris, Vol.
H, CPC Consultants Ltd,Edinburgh, UK3.
Blomberg, M. (1990): "Adaptation to a speaker's voice ina speech recognition system based on synthetic phonemereferences," Proc.
ESCA Workshop on SpeakerCharacterization in Speech Technology, Edinburgh, UK,June 1990, CSTR, Univ.
of Edinburgh4.
Blomberg, M., Carlson, R., Elenius, K., Granstrom, B.,& Hunnicutt, S. (1988): "Word recognition usingsynthesized templates," in Proc.
SPEECH '88, Book 4 (7thFASE-symposium), Institute of Acoustics, Edinburgh.5.
Blomberg, M., Carlson, R., Elenius, K., Granstrom, B.
&Hunnicutt, S. (1988): "Word recognition using synthesizedreference templates.
", Proc.
Second Symposium on AdvancedMan-Machine Interface Through Spoken Language, Hawaii,USA, also in STL-QPSR 2-3/1988, pp.
69-81.6.
Carlson, R., Fant, G., Gobl, C., Granstrom, B., Karlsson,I.
& Lin, Q.
(1989): "Voice source rules for text-to-speechsynthesis", Proc IEEE 1989 Int.
Conf.
on Acoustics, Speech,and Signal Processing, Glasgow, Scotland7.
Carlson, R. Granstrom, B.
& Karlsson, I.
(1990):"Experiments with voice modelling in speech synthesis",Proc.
of ESCA workshop on Speaker Characterization inSpeech Technology, 26-28 June 1990, Edinburgh8.
Carlson, R., Granstrom, B.
& Hunnicutt, S.(1991):"Multilingual text-to-speech development andapplications", A.W.
Ainsworth (ed), Advances in speech,hearing and language processing, JAI Press, London9.
Elenius K. (1990):"Acoustic-phonetic recognition ofcontinuous speech by artificial neural networks", in STL-QPSR 2-3 1990.13
