Self-Organizing Markov Models andTheir Application to Part-of-Speech TaggingJin-Dong KimDept.
of Computer ScienceUniversity of Tokyojdkim@is.s.u-tokyo.ac.jpHae-Chang RimDept.
of Computer ScienceKorea Universityrim@nlp.korea.ac.krJun?ich TsujiiDept.
of Computer ScienceUniversity of Tokyo, andCREST, JSTtsujii@is.s.u-tokyo.ac.jpAbstractThis paper presents a method to de-velop a class of variable memory Markovmodels that have higher memory capac-ity than traditional (uniform memory)Markov models.
The structure of the vari-able memory models is induced from amanually annotated corpus through a de-cision tree learning algorithm.
A series ofcomparative experiments show the result-ing models outperform uniform memoryMarkov models in a part-of-speech tag-ging task.1 IntroductionMany major NLP tasks can be regarded as prob-lems of finding an optimal valuation for randomprocesses.
For example, for a given word se-quence, part-of-speech (POS) tagging involves find-ing an optimal sequence of syntactic classes, and NPchunking involves finding IOB tag sequences (eachof which represents the inside, outside and begin-ning of noun phrases respectively).Many machine learning techniques have been de-veloped to tackle such random process tasks, whichinclude Hidden Markov Models (HMMs) (Rabiner,1989), Maximum Entropy Models (MEs) (Rat-naparkhi, 1996), Support Vector Machines(SVMs) (Vapnik, 1998), etc.
Among them,SVMs have high memory capacity and show highperformance, especially when the target classifica-tion requires the consideration of various features.On the other hand, HMMs have low memorycapacity but they work very well, especially whenthe target task involves a series of classifications thatare tightly related to each other and requires globaloptimization of them.
As for POS tagging, recentcomparisons (Brants, 2000; Schro?der, 2001) showthat HMMs work better than other models whenthey are combined with good smoothing techniquesand with handling of unknown words.While global optimization is the strong point ofHMMs, developers often complain that it is difficultto make HMMs incorporate various features and toimprove them beyond given performances.
For ex-ample, we often find that in some cases a certainlexical context can improve the performance of anHMM-based POS tagger, but incorporating such ad-ditional features is not easy and it may even degradethe overall performance.
Because Markov modelshave the structure of tightly coupled states, an ar-bitrary change without elaborate consideration canspoil the overall structure.This paper presents a way of utilizing statisticaldecision trees to systematically raise the memorycapacity of Markov models and effectively to makeMarkov models be able to accommodate various fea-tures.2 Underlying ModelThe tagging model is probabilistically defined asfinding the most probable tag sequence when a wordsequence is given (equation (1)).T (w1,k) = arg maxt1,k P (t1,k|w1,k) (1)= arg maxt1,kP (t1,k)P (w1,k|t1,k) (2)?
arg maxt1,kk?i=1P (ti|ti?1)P (wi|ti) (3)By applying Bayes?
formula and eliminating a re-dundant term not affecting the argument maximiza-tion, we can obtain equation (2) which is a combi-nation of two separate models: the tag languagemodel, P (t1,k) and the tag-to-word translationmodel, P (w1,k|t1,k).
Because the number of wordsequences, w1,k and tag sequences, t1,k is infinite,the model of equation (2) is not computationallytractable.
Introduction of Markov assumption re-duces the complexity of the tag language model andindependent assumption between words makes thetag-to-word translation model simple, which resultin equation (3) representing the well-known HiddenMarkov Model.3 Effect of Context ClassificationLet?s focus on the Markov assumption which ismade to reduce the complexity of the original tag-ging problem and to make the tagging problemtractable.
We can imagine the following processthrough which the Markov assumption can be intro-duced in terms of context classification:P (T = t1,k) =k?i=1P (ti|t1,i?1) (4)?k?i=1P (ti|?
(t1,i?1)) (5)?k?i=1P (ti|ti?1) (6)In equation (5), a classification function ?
(t1,i?1) isintroduced, which is a mapping of infinite contextualpatterns into a set of finite equivalence classes.
Bydefining the function as follows we can get equation(6) which represents a widely-used bi-gram model:?
(t1,i?1) ?
ti?1 (7)Equation (7) classifies all the contextual patternsending in same tags into the same classes, and isequivalent to the Markov assumption.The assumption or the definition of the aboveclassification function is based on human intuition.
( )conjP |?
( )conjfwP ,|?
( )conjvbP ,|?
( )conjvbpP ,|?vbvbvbpvbpFigure 1: Effect of 1?st and 2?nd order contextatatprepprepnnnn( )prepP |?
( )in'',| prepP ?
( )with'',| prepP ?
( )out'',| prepP ?Figure 2: Effect of context with and without lexicalinformationAlthough this simple definition works well mostly,because it is not based on any intensive analysis ofreal data, there is room for improvement.
Figure 1and 2 illustrate the effect of context classification onthe compiled distribution of syntactic classes, whichwe believe provides the clue to the improvement.Among the four distributions showed in Figure 1,the top one illustrates the distribution of syntacticclasses in the Brown corpus that appear after all theconjunctions.
In this case, we can say that we areconsidering the first order context (the immediatelypreceding words in terms of part-of-speech).
Thefollowing three ones illustrates the distributions col-lected after taking the second order context into con-sideration.
In these cases, we can say that we haveextended the context into second order or we haveclassified the first order context classes again intosecond order context classes.
It shows that distri-butions like P (?|vb, conj) and P (?|vbp, conj) arevery different from the first order ones, while distri-butions like P (?|fw, conj) are not.Figure 2 shows another way of context extension,so called lexicalization.
Here, the initial first ordercontext class (the top one) is classified again by re-ferring the lexical information (the following threeones).
We see that the distribution after the prepo-sition, out is quite different from distribution afterother prepositions.From the above observations, we can see that byapplying Markov assumptions we may miss muchuseful contextual information, or by getting a bettercontext classification we can build a better contextmodel.4 Related WorksOne of the straightforward ways of context exten-sion is extending context uniformly.
Tri-gram tag-ging models can be thought of as a result of theuniform extension of context from bi-gram taggingmodels.
TnT (Brants, 2000) based on a second or-der HMM, is an example of this class of models andis accepted as one of the best part-of-speech taggersused around.The uniform extension can be achieved (rela-tively) easily, but due to the exponential growth ofthe model size, it can only be performed in restric-tive a way.Another way of context extension is the selectiveextension of context.
In the case of context exten-sion from lower context to higher like the examplesin figure 1, the extension involves taking more infor-mation about the same type of contextual features.We call this kind of extension homogeneous con-text extension.
(Brants, 1998) presents this type ofcontext extension method through model mergingand splitting, and also prediction suffix tree learn-ing (Schu?tze and Singer, 1994; D. Ron et.
al, 1996)is another well-known method that can perform ho-mogeneous context extension.On the other hand, figure 2 illustrates heteroge-neous context extension, in other words, this typeof extension involves taking more information aboutother types of contextual features.
(Kim et.
al, 1999)and (Pla and Molina, 2001) present this type of con-text extension method, so called selective lexicaliza-tion.The selective extension can be a good alternativeto the uniform extension, because the growth rateof the model size is much smaller, and thus variouscontextual features can be exploited.
In the follow-VPN C$$ C N P VP-1-$ C N P VFigure 3: a Markov model and its equivalent deci-sion treeing sections, we describe a novel method of selectiveextension of context which performs both homoge-neous and heterogeneous extension simultaneously.5 Self-Organizing Markov ModelsOur approach to the selective context extension ismaking use of the statistical decision tree frame-work.
The states of Markov models are representedin statistical decision trees, and by growing the treesthe context can be extended (or the states can besplit).We have named the resulting models Self-Organizing Markov Models to reflect their ability toautomatically organize the structure.5.1 Statistical Decision Tree Representation ofMarkov ModelsThe decision tree is a well known structure that iswidely used for classification tasks.
When there areseveral contextual features relating to the classifi-cation of a target feature, a decision tree organizesthe features as the internal nodes in a manner wheremore informative features will take higher levels, sothe most informative feature will be the root node.Each path from the root node to a leaf node repre-sents a context class and the classification informa-tion for the target feature in the context class will becontained in the leaf node1 .In the case of part-of-speech tagging, a classifi-cation will be made at each position (or time) of aword sequence, where the target feature is the syn-tactic class of the word at current position (or time)and the contextual features may include the syntactic1While ordinary decision trees store deterministic classifi-cation information in their leaves, statistical decision trees storeprobabilistic distribution of possible decisions.VP,*,N C$$ C N W-1- VP-1-$ C N P VP,out, tP,*,P,out, tFigure 4: a selectively lexicalized Markov modeland its equivalent decision treeVP,*,N(N)C( )$$ P-2- N W-1- VP-1-$ C N P VP,out, tP,*,P,out, t(V)C( )(*)C( )(*)C( )(N)C( ) (V)C( )Figure 5: a selectively extended Markov model andits equivalent decision treeclasses or the lexical form of preceding words.
Fig-ure 3 shows an example of Markov model for a sim-ple language having nouns (N), conjunctions (C),prepositions (P) and verbs (V).
The dollar sign ($)represents sentence initialization.
On the left handside is the graph representation of the Markov modeland on the right hand side is the decision tree repre-sentation, where the test for the immediately preced-ing syntactic class (represented by P-1) is placed onthe root, each branch represents a result of the test(which is labeled on the arc), and the correspond-ing leaf node contains the probabilistic distributionof the syntactic classes for the current position2 .The example shown in figure 4 involves a furtherclassification of context.
On the left hand side, it isrepresented in terms of state splitting, while on theright hand side in terms of context extension (lexi-calization), where a context class representing con-textual patterns ending in P (a preposition) is ex-tended by referring the lexical form and is classi-fied again into the preposition, out and other prepo-sitions.Figure 5 shows another further classification of2The distribution doesn?t appear in the figure explicitly.
Justimagine each leaf node has the distribution for the target featurein the corresponding context.context.
It involves a homogeneous extension ofcontext while the previous one involves a hetero-geneous extension.
Unlike prediction suffix treeswhich grow along an implicitly fixed order, decisiontrees don?t presume any implicit order between con-textual features and thus naturally can accommodatevarious features having no underlying order.In order for a statistical decision tree to be aMarkov model, it must meet the following restric-tions:?
There must exist at least one contextual featurethat is homogeneous with the target feature.?
When the target feature at a certain time is clas-sified, all the requiring context features must bevisibleThe first restriction states that in order to be aMarkov model, there must be inter-relations be-tween the target features at different time.
The sec-ond restriction explicitly states that in order for thedecision tree to be able to classify contextual pat-terns, all the context features must be visible, andimplicitly states that homogeneous context featuresthat appear later than the current target feature can-not be contextual features.
Due to the second re-striction, the Viterbi algorithm can be used with theself-organizing Markov models to find an optimalsequence of tags for a given word sequence.5.2 Learning Self-Organizing Markov ModelsSelf-organizing Markov models can be inducedfrom manually annotated corpora through the SDTLalgorithm (algorithm 1) we have designed.
It is avariation of ID3 algorithm (Quinlan, 1986).
SDTLis a greedy algorithm where at each time of the nodemaking phase the most informative feature is se-lected (line 2), and it is a recursive algorithm in thesense that the algorithm is called recursively to makechild nodes (line 3),Though theoretically any statistical decision treegrowing algorithms can be used to train self-organizing Markov models, there are practical prob-lems we face when we try to apply the algorithms tolanguage learning problems.
One of the main obsta-cles is the fact that features used for language learn-ing often have huge sets of values, which cause in-tensive fragmentation of the training corpus alongwith the growing process and eventually raise thesparse data problem.To deal with this problem, the algorithm incor-porates a value selection mechanism (line 1) whereonly meaningful values are selected into a reducedvalue set.
The meaningful values are statisticallydefined as follows: if the distribution of the targetfeature varies significantly by referring to the valuev, v is accepted as a meaningful value.
We adoptedthe ?2-test to determine the difference between thedistributions of the target feature before and after re-ferring to the value v. The use of ?2-test enablesus to make a principled decision about the thresholdbased on a certain confidence level3.To evaluate the contribution of contextual featuresto the target classification (line 2), we adopted Lopezdistance (Lo?pez, 1991).
While other measures in-cluding Information Gain or Gain Ratio (Quinlan,1986) also can be used for this purpose, the Lopezdistance has been reported to yield slightly better re-sults (Lo?pez, 1998).The probabilistic distribution of the target fea-ture estimated on a node making phase (line 4) issmoothed by using Jelinek and Mercer?s interpola-tion method (Jelinek and Mercer, 1980) along theancestor nodes.
The interpolation parameters areestimated by deleted interpolation algorithm intro-duced in (Brants, 2000).6 ExperimentsWe performed a series of experiments to comparethe performance of self-organizing Markov modelswith traditional Markov models.
Wall Street Jour-nal as contained in Penn Treebank II is used as thereference material.
As the experimental task is part-of-speech tagging, all other annotations like syntac-tic bracketing have been removed from the corpus.Every figure (digit) in the corpus has been changedinto a special symbol.From the whole corpus, every 10?th sentence fromthe first is selected into the test corpus, and the re-maining ones constitute the training corpus.
Table 6shows some basic statistics of the corpora.We implemented several tagging models based onequation (3).
For the tag language model, we used3We used 95% of confidence level to extend context.
Inother words, only when there are enough evidences for improve-ment at 95% of confidence level, a context is extended.Algorithm 1: SDTL(E, t, F )Data : E: set of examples,t: target feature,F : set of contextual featuresResult : Statistical Decision Tree predicting tinitialize a null node;for each element f in the set F do1 sort meaningful value set V for f ;if |V | > 1 then2 measure the contribution of f to t;if f contributes the most thenselect f as the best feature b;endendendif there is b selected thenset the current node to an internal node;set b as the test feature of the current node;3 for each v in |V | for b domake SDTL(Eb=v, t, F ?
{b}) as thesubtree for the branch corresponding tov;endendelseset the current node to a leaf node;4 store the probability distribution of t overE ;endreturn current node;1,289,20168,590Total129,1006,859Test1,160,10161,731Training         Figure 6: Basic statistics of corporathe following 6 approximations:P (t1,k) ?k?i=1P (ti|ti?1) (8)?k?i=1P (ti|ti?2,i?1) (9)?k?i=1P (ti|?
(ti?2,i?1)) (10)?k?i=1P (ti|?
(ti?1, wi?1)) (11)?k?i=1P (ti|?
(ti?2,i?1, wi?1)) (12)?k?i=1P (ti|?
(ti?2,i?1, wi?2,i?1))(13)Equation (8) and (9) represent first- and second-order Markov models respectively.
Equation (10)?
(13) represent self-organizing Markov models atvarious settings where the classification functions?(?)
are intended to be induced from the trainingcorpus.For the estimation of the tag-to-word translationmodel we used the following model:P (wi|ti)= ki ?
P (ki|ti) ?
P?
(wi|ti)+(1 ?
ki) ?
P (?ki|ti) ?
P?
(ei|ti) (14)Equation (14) uses two different models to estimatethe translation model.
If the word, wi is a knownword, ki is set to 1 so the second model is ig-nored.
P?
means the maximum likelihood probabil-ity.
P (ki|ti) is the probability of knownness gener-ated from ti and is estimated by using Good-Turingestimation (Gale and Samson, 1995).
If the word, wiis an unknown word, ki is set to 0 and the first termis ignored.
ei represents suffix of wi and we used thelast two letters for it.With the 6 tag language models and the 1 tag-to-word translation model, we construct 6 HMM mod-els, among them 2 are traditional first- and second-hidden Markov models, and 4 are self-organizinghidden Markov models.
Additionally, we used T3,a tri-gram-based POS tagger in ICOPOST release1.8.3 for comparison.The overall performances of the resulting modelsestimated from the test corpus are listed in figure 7.From the leftmost column, it shows the model name,the contextual features, the target features, the per-formance and the model size of our 6 implementa-tions of Markov models and additionally the perfor-mance of T3 is shown.Our implementation of the second-order hid-den Markov model (HMM-P2) achieved a slightlyworse performance than T3, which, we are in-terpreting, is due to the relatively simple imple-mentation of our unknown word guessing module4.While HMM-P2 is a uniformly extended modelfrom HMM-P1, SOHMM-P2 has been selectivelyextended using the same contextual feature.
It isencouraging that the self-organizing model suppressthe increase of the model size in half (2,099Kbyte vs5,630Kbyte) without loss of performance (96.5%).In a sense, the results of incorporating wordfeatures (SOHMM-P1W1, SOHMM-P2W1 andSOHMM-P2W2) are disappointing.
The improve-ments of performances are very small compared tothe increase of the model size.
Our interpretationfor the results is that because the distribution ofwords is huge, no matter how many words the mod-els incorporate into context modeling, only a few ofthem may actually contribute during test phase.
Weare planning to use more general features like wordclass, suffix, etc.Another positive observation is that a homo-geneous context extension (SOHMM-P2) and aheterogeneous context extension (SOHMM-P1W1)yielded significant improvements respectively, andthe combination (SOHMM-P2W1) yielded evenmore improvement.
This is a strong point of usingdecision trees rather than prediction suffix trees.7 ConclusionThrough this paper, we have presented a frameworkof self-organizing Markov model learning.
Theexperimental results showed some encouraging as-pects of the framework and at the same time showedthe direction towards further improvements.
Be-cause all the Markov models are represented as de-cision trees in the framework, the models are hu-4T3 uses a suffix trie for unknown word guessing, while ourimplementations use just last two letters.?96.6?
?T396.996.896.396.596.595.6 	                 	24,628KT0P-2, W-1, P-1SOHMM-P2W1W-2, P-2, W-1, P-1W-1, P-1P-2, P-1P-2, P-1P-1T0T0T0T0T014,247KSOHMM-P1W135,494K2,099K5,630K123KSOHMM-P2SOHMM-P2W2HMM-P2HMM-P1                Figure 7: Estimated Performance of Various Modelsman readable and we are planning to develop editingtools for self-organizing Markov models that helpexperts to put human knowledge about language intothe models.
By adopting ?2-test as the criterion forpotential improvement, we can control the degree ofcontext extension based on the confidence level.AcknowledgementThe research is partially supported by InformationMobility Project (CREST, JST, Japan) and GenomeInformation Science Project (MEXT, Japan).ReferencesL.
Rabiner.
1989.
A tutorial on Hidden Markov Mod-els and selected applications in speech recognition.
inProceedings of the IEEE, 77(2):257?285A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP).V.
Vapnik.
1998.
Statistical Learning Theory.
Wiley,Chichester, UK.I.
Schr o?der.
2001.
ICOPOST - Ingo?s CollectionOf POS Taggers.
In http://nats-www.informatik.uni-hamburg.de/?ingo/icopost/.T.
Brants.
1998 Estimating HMM Topologies.
In TheTbilisi Symposium on Logic, Language and Computa-tion: Selected Papers.T.
Brants.
2000 TnT - A Statistical Part-of-Speech Tag-ger.
In 6?th Applied Natural Language Processing.H.
Sch u?tze and Y.
Singer.
1994.
Part-of-speech taggingusing a variable memory Markov model.
In Proceed-ings of the Annual Meeting of the Association for Com-putational Linguistics (ACL).D.
Ron, Y.
Singer and N. Tishby.
1996 The Power ofAmnesia: Learning Probabilistic Automata with Vari-able Memory Length.
In Machine Learning, 25(2-3):117?149.J.-D. Kim, S.-Z.
Lee and H.-C. Rim.
1999 HMMSpecialization with Selective Lexicalization.
InProceedings of the Joint SIGDAT Conference onEmpirical Methods in NLP and Very Large Cor-pora(EMNLP/VLC99).F.
Pla and A. Molina.
2001 Part-of-Speech Taggingwith Lexicalized HMM.
In Proceedings of the Inter-national Conference on Recent Advances in NaturalLanguage Processing(RANLP2001).R.
Quinlan.
1986 Induction of decision trees.
In Ma-chine Learning, 1(1):81?106.R.
L o?pez de M a?ntaras.
1991.
A Distance-Based At-tribute Selection Measure for Decision Tree Induction.In Machine Learning, 6(1):81?92.R.
L o?pez de M a?ntaras, J. Cerquides and P. Garcia.
1998.Comparing Information-theoretic Attribute SelectionMeasures: A statistical approach.
In Artificial Intel-ligence Communications, 11(2):91?100.F.
Jelinek and R. Mercer.
1980.
Interpolated estimationof Markov source parameters from sparse data.
In Pro-ceedings of the Workshop on Pattern Recognition inPractice.W.
Gale and G. Sampson.
1995.
Good-Turing frequencyestimatin without tears.
In Jounal of Quantitative Lin-guistics, 2:217?237
