Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 69?78, Dublin, Ireland, August 23-29 2014.Deep Convolutional Neural Networks forSentiment Analysis of Short TextsC?
?cero Nogueira dos SantosBrazilian Research LabIBM Researchcicerons@br.ibm.comMa?
?ra GattiBrazilian Research LabIBM Researchmairacg@br.ibm.comAbstractSentiment analysis of short texts such as single sentences and Twitter messages is challengingbecause of the limited contextual information that they normally contain.
Effectively solving thistask requires strategies that combine the small text content with prior knowledge and use morethan just bag-of-words.
In this work we propose a new deep convolutional neural network that ex-ploits from character- to sentence-level information to perform sentiment analysis of short texts.We apply our approach for two corpora of two different domains: the Stanford Sentiment Tree-bank (SSTb), which contains sentences from movie reviews; and the Stanford Twitter Sentimentcorpus (STS), which contains Twitter messages.
For the SSTb corpus, our approach achievesstate-of-the-art results for single sentence sentiment prediction in both binary positive/negativeclassification, with 85.7% accuracy, and fine-grained classification, with 48.3% accuracy.
For theSTS corpus, our approach achieves a sentiment prediction accuracy of 86.4%.1 IntroductionThe advent of online social networks has produced a crescent interest on the task of sentiment analysis forshort text messages (Go et al., 2009; Barbosa and Feng, 2010; Nakov et al., 2013).
However, sentimentanalysis of short texts such as single sentences and and microblogging posts, like Twitter messages, ischallenging because of the limited amount of contextual data in this type of text.
Effectively solving thistask requires strategies that go beyond bag-of-words and extract information from the sentence/messagein a more disciplined way.
Additionally, to fill the gap of contextual information in a scalable manner, itis more suitable to use methods that can exploit prior knowledge from large sets of unlabeled texts.In this work we propose a deep convolutional neural network that exploits from character- to sentence-level information to perform sentiment analysis of short texts.
The proposed network, named Characterto Sentence Convolutional Neural Network (CharSCNN), uses two convolutional layers to extract rele-vant features from words and sentences of any size.
The proposed network can easily explore the richnessof word embeddings produced by unsupervised pre-training (Mikolov et al., 2013).
We perform experi-ments that show the effectiveness of CharSCNN for sentiment analysis of texts from two domains: moviereview sentences; and Twitter messages (tweets).
CharSCNN achieves state-of-the-art results for the twodomains.
Additionally, in our experiments we provide information about the usefulness of unsupervisedpre-training; the contribution of character-level features; and the effectiveness of sentence-level featuresto detect negation.This work is organized as follows.
In Section 2, we describe the proposed the Neural Network archi-tecture.
In Section 3, we discuss some related work.
Section 4 details our experimental setup and results.Finally, in Section 5 we present our final remarks.2 Neural Network ArchitectureGiven a sentence, CharSCNN computes a score for each sentiment label ?
?
T .
In order to scorea sentence, the network takes as input the sequence of words in the sentence, and passes it throughThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/69a sequence of layers where features with increasing levels of complexity are extracted.
The networkextracts features from the character-level up to the sentence-level.
The main novelty in our networkarchitecture is the inclusion of two convolutional layers, which allows it to handle words and sentencesof any size.2.1 Initial Representation LevelsThe first layer of the network transforms words into real-valued feature vectors (embeddings) that cap-ture morphological, syntactic and semantic information about the words.
We use a fixed-sized wordvocabulary Vwrd, and we consider that words are composed of characters from a fixed-sized charactervocabulary Vchr.
Given a sentence consisting of N words {w1, w2, ..., wN}, every word wnis con-verted into a vector un= [rwrd; rwch], which is composed of two sub-vectors: the word-level embeddingrwrd?
Rdwrdand the character-level embedding rwch?
Rcl0uof wn.
While word-level embeddings aremeant to capture syntactic and semantic information, character-level embeddings capture morphologicaland shape information.2.1.1 Word-Level EmbeddingsWord-level embeddings are encoded by column vectors in an embedding matrix Wwrd?
Rdwrd?|Vwrd|.Each columnWwrdi?
Rdwrdcorresponds to the word-level embedding of the i-th word in the vocabulary.We transform a word w into its word-level embedding rwrdby using the matrix-vector product:rwrd= Wwrdvw(1)where vwis a vector of size??Vwrd?
?which has value 1 at index w and zero in all other positions.
Thematrix Wwrdis a parameter to be learned, and the size of the word-level embedding dwrdis a hyper-parameter to be chosen by the user.2.1.2 Character-Level EmbeddingsRobust methods to extract morphological and shape information from words must take into considerationall characters of the word and select which features are more important for the task at hand.
For instance,in the task of sentiment analysis of Twitter data, important information can appear in different partsof a hash tag (e.g., ?#SoSad?, ?#ILikeIt?)
and many informative adverbs end with the suffix ?ly?
(e.g.
?beautifully?, ?perfectly?
and ?badly?).
We tackle this problem using the same strategy proposed in(dos Santos and Zadrozny, 2014), which is based on a convolutional approach (Waibel et al., 1989).
Asdepicted in Fig.
1, the convolutional approach produces local features around each character of the wordand then combines them using a max operation to create a fixed-sized character-level embedding of theword.Given a word w composed of M characters {c1, c2, ..., cM}, we first transform each character cmintoa character embedding rchrm.
Character embeddings are encoded by column vectors in the embeddingmatrix Wchr?
Rdchr?|Vchr|.
Given a character c, its embedding rchris obtained by the matrix-vectorproduct:rchr= Wchrvc(2)where vcis a vector of size??Vchr?
?which has value 1 at index c and zero in all other positions.
The inputfor the convolutional layer is the sequence of character embeddings {rchr1, rchr2, ..., rchrM}.The convolutional layer applies a matrix-vector operation to each window of size kchrof successivewindows in the sequence {rchr1, rchr2, ..., rchrM}.
Let us define the vector zm?
Rdchrkchras the con-catenation of the character embedding m, its (kchr?
1)/2 left neighbors, and its (kchr?
1)/2 rightneighbors1:zm=(rchrm?
(kchr?1)/2, ..., rchrm+(kchr?1)/2)T1We use a special padding character for the characters with indices outside of the word boundaries.70Figure 1: Convolutional approach to character-level feature extraction.The convolutional layer computes the j-th element of the vector rwch?
Rcl0u, which is the character-levelembedding of w, as follows:[rwch]j= max1<m<M[W0zm+ b0]j(3)where W0?
Rcl0u?dchrkchris the weight matrix of the convolutional layer.
The same matrix is used toextract local features around each character window of the given word.
Using the max over all characterwindows of the word, we extract a ?global?
fixed-sized feature vector for the word.Matrices Wchrand W0, and vector b0are parameters to be learned.
The size of the character vectordchr, the number of convolutional units cl0u(which corresponds to the size of the character-level embed-ding of a word), and the size of the character context window kchrare hyper-parameters.2.2 Sentence-Level Representation and ScoringGiven a sentence x with N words {w1, w2, ..., wN}, which have been converted to joint word-leveland character-level embedding {u1, u2, ..., uN}, the next step in CharSCNN consists in extracting asentence-level representation rsentx.
Methods to extract a sentence-wide feature set most deal with twomain problems: sentences have different sizes; and important information can appear at any position inthe sentence.
We tackle these problems by using a convolutional layer to compute the sentence-widefeature vector rsent.
This second convolutional layer in our neural network architecture works in a verysimilar way to the one used to extract character-level features for words.
This layer produces localfeatures around each word in the sentence and then combines them using a max operation to create afixed-sized feature vector for the sentence.The second convolutional layer applies a matrix-vector operation to each window of size kwrdofsuccessive windows in the sequence {u1, u2, ..., uN}.
Let us define the vector zn?
R(dwrd+cl0u)kwrdasthe concatenation of a sequence of kwrdembeddings, centralized in the n-th word2:zn=(un?
(kwrd?1)/2, ..., un+(kwrd?1)/2)T2We use a special padding token for the words with indices outside of the sentence boundaries.71The convolutional layer computes the j-th element of the vector rsent?
Rcl1uas follows:[rsent]j= max1<n<N[W1zn+ b1]j(4)where W1?
Rcl1u?
(dwrd+cl0u)kwrdis the weight matrix of the convolutional layer.
The same matrix isused to extract local features around each word window of the given sentence.
Using the max overall word windows of the sentence, we extract a ?global?
fixed-sized feature vector for the sentence.Matrix W1and vector b1are parameters to be learned.
The number of convolutional units cl1u(whichcorresponds to the size of the sentence-level feature vector), and the size of the word context windowkwrdare hyper-parameters to be chosen by the user.Finally, the vector rsentx, the ?global?
feature vector of sentence x, is processed by two usual neuralnetwork layers, which extract one more level of representation and compute a score for each sentimentlabel ?
?
T :s(x) = W3h(W2rsentx+ b2) + b3(5)where matrices W2?
Rhlu?cl1uand W3?
R|T |?hlu, and vectors b2?
Rhluand b3?
R|T |are parametersto be learned.
The transfer function h(.)
is the hyperbolic tangent.
The number of hidden units hluis ahyper-parameter to be chosen by the user.2.3 Network TrainingOur network is trained by minimizing a negative likelihood over the training set D. Given a sentence x,the network with parameter set ?
computes a score s?
(x)?for each sentiment label ?
?
T .
In order totransform these scores into a conditional probability distribution of labels given the sentence and the setof network parameters ?, we apply a softmax operation over the scores of all tags ?
?
T :p (?
|x, ?)
=es?(x)???i?Tes?
(x)i(6)Taking the log, we arrive at the following conditional log-probability:log p (?
|x, ?)
= s?(x)??
log(??i?Tes?
(x)i)(7)We use stochastic gradient descent (SGD) to minimize the negative log-likelihood with respect to ?:?
7??
(x,y)?D?log p(y|x, ?)
(8)where (x, y) corresponds to a sentence in the training corpus D and y represents its respective label.The backpropagation algorithm is a natural choice to efficiently compute gradients of network archi-tectures such as the one proposed in this work (Lecun et al., 1998; Collobert, 2011).
In order to performour experiments, we implement the proposed CharSCNN architecture using the Theano library (Bergstraet al., 2010).
Theano is a versatile Python library that allows the efficient definition, optimization, andevaluation of mathematical expressions involving multi-dimensional arrays.
We use Theano?s automaticdifferentiation capabilities in order to implement the backpropagation algorithm.3 Related WorkThere are a few works on neural network architectures for sentiment analysis.
In (Socher et al., 2011),the authors proposed a semi-supervised approach based on recursive autoencoders for predicting senti-ment distributions.
The method learns vector space representation for multi-word phrases and exploitsthe recursive nature of sentences.
In (Socher et al., 2012), it is proposed a matrix-vector recursive neu-ral network model for semantic compositionality, which has the ability to learn compositional vector72representations for phrases and sentences of arbitrary length.
The vector captures the inherent meaningof the constituent, while the matrix captures how the meaning of neighboring words and phrases arechanged.
In (Socher et al., 2013b) the authors propose the Recursive Neural Tensor Network (RNTN)architecture, which represents a phrase through word vectors and a parse tree and then compute vectorsfor higher nodes in the tree using the same tensor-based composition function.
Our approach differ fromthese previous works because it uses a feed-forward neural network instead of a recursive one.
Moreover,it does not need any input about the syntactic structure of the sentence.Regarding convolutional networks for NLP tasks, in (Collobert et al., 2011), the authors use a convo-lutional network for the semantic role labeling task with the goal avoiding excessive task-specific featureengineering.
In (Collobert, 2011), the authors use a similar network architecture for syntactic parsing.CharSCNN is related to these works because they also apply convolutional layers to extract sentence-level features.
The main difference in our neural network architecture is the addition of one convolutionallayer to extract character features.In terms of using intra-word information in neural network architectures for NLP tasks, Alexandrescuet al.
(2006) present a factored neural language model where each word is represented as a vector offeatures such as stems, morphological tags and cases and a single embedding matrix is used to lookup all of these features.
In (Luong et al., 2013), the authors use a recursive neural network (RNN) toexplicitly model the morphological structures of words and learn morphologically-aware embeddings.Lazaridou et al.
(Lazaridou et al., 2013) use compositional distributional semantic models, originallydesigned to learn meanings of phrases, to derive representations for complex words, in which the baseunit is the morpheme.
In (Chrupala, 2013), the author proposes a simple recurrent network (SRN) to learncontinuous vector representations for sequences of characters, and use them as features in a conditionalrandom field classifier to solve a character level text segmentation and labeling task.
The main advantageof our approach to extract character-level features is it flexibility.
The convolutional layer allows theextraction of relevant features from any part of the word and do not need handcrafted inputs like stemsand morpheme lists (dos Santos and Zadrozny, 2014).4 Experimental Setup and Results4.1 Sentiment Analysis DatasetsWe apply CharSCNN for two different corpora from two different domains: movie reviews and Twitterposts.
The movie review dataset used is the recently proposed Stanford Sentiment Treebank (SSTb)(Socher et al., 2013b), which includes fine grained sentiment labels for 215,154 phrases in the parsetrees of 11,855 sentences.
In our experiments we focus in sentiment prediction of complete sentences.However, we show the impact of training with sentences and phrases instead of only sentences.The second labeled corpus we use is the Stanford Twitter Sentiment corpus (STS) introduced by(2009).
The original training set contains 1.6 million tweets that were automatically labeled as posi-tive/negative using emoticons as noisy labels.
The test set was manually annotated by Go et al.
(2009).In our experiments, to speedup the training process we use only a sample of the training data consistingof 80K (5%) randomly selected tweets.
We also construct a development set by randomly selecting 16Ktweets from Go et al.
?s training set.
In Table 1, we present additional details about the two corpora.Dataset Set # sentences / tweets # classesSSTbTrain 8544 5Dev 1101 5Test 2210 5STSTrain 80K 2Dev 16K 2Test 498 3Table 1: Sentiment Analysis datasets.734.2 Unsupervised Learning of Word-Level EmbeddingsWord-level embeddings play a very important role in the CharSCNN architecture.
They are meant tocapture syntactic and semantic information, which are very important to sentiment analysis.
Recentwork has shown that large improvements in terms of model accuracy can be obtained by performingunsupervised pre-training of word embeddings (Collobert et al., 2011; Luong et al., 2013; Zheng etal., 2013; Socher et al., 2013a).
In our experiments, we perform unsupervised learning of word-levelembeddings using the word2vec tool3, which implements the continuous bag-of-words and skip-gramarchitectures for computing vector representations of words (Mikolov et al., 2013).We use the December 2013 snapshot of the English Wikipedia corpus as a source of unlabeled data.The Wikipedia corpus has been processed using the following steps: (1) removal of paragraphs that arenot in English; (2) substitution of non-western characters for a special character; (3) tokenization of thetext using the tokenizer available with the Stanford POS Tagger (Manning, 2011); (4) and removal ofsentences that are less than 20 characters long (including white spaces) or have less than 5 tokens.
Likein (Collobert et al., 2011) and (Luong et al., 2013), we lowercase all words and substitute each numericaldigit by a 0 (e.g., 1967 becomes 0000).
The resulting clean corpus contains about 1.75 billion tokens.When running theword2vec tool, we set that a word must occur at least 10 times in order to be includedin the vocabulary, which resulted in a vocabulary of 870,214 entries.
To train our word-level embeddingswe use word2vec?s skip-gram method with a context window of size 9.
The training time for the Englishcorpus is around 1h10min using 12 threads in a IntelrXeonrE5-2643 3.30GHz machine.In our experiments, we do not perform unsupervised pre-training of character-level embeddings, whichare initialized by randomly sampling each value from an uniform distribution: U (?r, r), where r =?6|Vchr|+ dchr.
There are 94 different characters in the SSTb corpus and 453 different characters inthe STS corpus.
Since the two character vocabularies are relatively small, it has been possible to learnreliable character-level embeddings using the labeled training corpora.
The raw (not lowercased) wordsare used to construct the character vocabularies, which allows the network to capture relevant informationabout capitalization.4.3 Model SetupWe use the development sets to tune the neural network hyper-parameters.
Many different combinationsof hyper-parameters can give similarly good results.
We spent more time tuning the learning rate thantuning other parameters, since it is the hyper-parameter that has the largest impact in the predictionperformance.
The only two parameters with different values for the two datasets are the learning rateand the number of units in the convolutional layer that extract sentence features.
This provides someindication on the robustness of our approach to multiple domains.
For both datasets, the number oftraining epochs varies between five and ten.
In Table 2, we show the selected hyper-parameter values forthe two labeled datasets.Parameter Parameter Name SSTb STSdwrdWord-Level Embeddings dimension 30 30kwrdWord Context window 5 5dchrChar.
Embeddings dimension 5 5kchrChar.
Context window 3 3cl0uChar.
Convolution Units 10 50cl1uWord Convolution Units 300 300hluHidden Units 300 300?
Learning Rate 0.02 0.01Table 2: Neural Network Hyper-Parameters3https://code.google.com/p/word2vec/74In order to assess the effectiveness of the proposed character-level representation of words, we com-pare the proposed architecture CharSCNN with an architecture that uses only word embeddings.
Inour experiments, SCNN represents a network which is fed with word representations only, i.e, for eachword wnits embedding is un= rwrd.
For SCNN, we use the same NN hyper-parameters values (whenapplicable) shown in Table 2.4.4 Results for SSTb CorpusIn Table 3, we present the result of CharSCNN and SCNN for different versions of the SSTb corpus.
Notethat SSTb corpus is a sentiment treebank, hence it contains sentiment annotations for all phrases in allsentences in the corpus.
In our experiments, we check whether using examples that are single phrases, inaddition to complete sentences, can provide useful information for training the proposed NN.
However,in our experiments the test set always includes only complete sentences.
In Table 3, the column Phrasesindicates whether all phrases (yes) or only complete sentences (no) in the corpus are used for training.The Fine-Grained column contains prediction results for the case where 5 sentiment classes (labels) areused (very negative, negative, neutral, positive, very positive).
The Positive/Negative column presentsprediction results for the case of binary classification of sentences, i.e, the neutral class is removed, thetwo negative classes are merged as well as the two positive classes.Model Phrases Fine-Grained Positive/NegativeCharSCNN yes 48.3 85.7SCNN yes 48.3 85.5CharSCNN no 43.5 82.3SCNN no 43.5 82.0RNTN (Socher et al., 2013b) yes 45.7 85.4MV-RNN (Socher et al., 2013b) yes 44.4 82.9RNN (Socher et al., 2013b) yes 43.2 82.4NB (Socher et al., 2013b) yes 41.0 81.8SVM (Socher et al., 2013b) yes 40.7 79.4Table 3: Accuracy of different models for fine grained (5-class) and binary predictions using SSTb.In Table 3, we can note that CharSCN and SCNN have very similar results in both fine-grained and bi-nary sentiment prediction.
These results suggest that the character-level information is not much helpfulfor sentiment prediction in the SSTb corpus.
Regarding the use of phrases in the training set, we can notethat, even not explicitly using the syntactic tree information when performing prediction, CharSCNNand SCNN benefit from the presence of phrases as training examples.
This result is aligned with Socheret al.
?s (2013b) suggestion that information of sentiment labeled phrases improves the accuracy of otherclassification algorithms such as support vector machines (SVM) and naive Bayes (NB).
We believethat using phrases as training examples allows the classifier to learn more complex phenomena, sincesentiment labeled phrases give the information of how words (phrases) combine to form the sentimentof phrases (sentences).
However, it is necessary to perform more detailed experiments to confirm thisconjecture.Regarding the fine-grained sentiment prediction, our approach provides an absolute accuracy improve-ment of 2.6 over the RNTN approach proposed by (Socher et al., 2013b), which is the previous bestreported result for SSTb.
CharSCN, SCNN and Socher et al.
?s RNTN have similar accuracy performancefor binary sentiment prediction.
Compared to RNTN, our method has the advantage of not needing theoutput of a syntactic parser when performing sentiment prediction.
For comparison reasons, in Table3 we also report Socher et al.
?s (2013b) results for sentiment classifiers trained with recursive neuralnetworks (RNN), matrix-vector RNN (MV-RNN), NB, and SVM algorithms.Initializing word-embeddings using unsupervised pre-training gives an absolute accuracy increase ofaround 1.5 when compared to randomly initializing the vectors.
The Theano based implementation ofCharSCNN takes around 10 min.
to complete one training epoch for the SSTb corpus with all phrases75and five classes.
In our experiments, we use 4 threads in a IntelrXeonrE5-2643 3.30GHz machine.4.5 Results for STS CorpusIn Table 4, we present the results of CharSCNN and SCNN for sentiment prediction using the STS cor-pus.
As expected, character-level information has a greater impact for Twitter data.
Using unsupervisedpre-training, CharSCNN provides an absolute accuracy improvement of 1.2 over SCNN.
Additionally,initializing word-embeddings using unsupervised pre-training gives an absolute accuracy increase ofaround 4.5 when compared to randomly initializing the word-embeddings.In Table 4, we also compare CharSCNN performance with other approaches proposed in the literature.In (Speriosu et al., 2011), a label propagation (LProp) approach is proposed, while Go et al.
(2009)use maximum entropy (MaxEnt), NB and SVM-based classifiers.
CharSCNN outperforms the previousapproaches in terms of prediction accuracy.
As far as we know, 86.4 is the best prediction accuracyreported so far for the STS corpus.Model Accuracy Accuracy (random(unsup.
pre-training) word embeddings)CharSCNN 86.4 81.9SCNN 85.2 82.2LProp (Speriosu et al., 2011) 84.7MaxEnt (Go et al., 2009) 83.0NB (Go et al., 2009) 82.7SVM (Go et al., 2009) 82.2Table 4: Accuracy of different models for binary predictions (positive/negative) using STS Corpus.4.6 Sentence-level featuresIn figures 2 and 3 we present the behavior of CharSCNN regarding the sentence-level features extractedfor two cases of negation, which are correctly predicted by CharSCNN.
We choose these cases becausenegation is an important issue in sentiment analysis.
Moreover, the same sentences are also used asillustrative examples in (Socher et al., 2013b).
Note that in the convolutional layer, 300 features are firstextracted for each word.
Then the max operator selects the 300 features which have the largest valuesamong the words to construct the sentence-level feature set rsent.
Figure 2 shows a positive sentence(left) and its negation.
We can observe that in both versions of the sentence, the extracted featuresconcentrate mainly around the main topic, ?film?, and the part of the phrase that indicates sentiment(?liked?
and ?did ?nt like?).
Note in the left chart that the word ?liked?
has a big impact in the set ofextracted features.
On the other hand, in the right chart, we can see that the impact of the word ?like??
isreduced because of the negation ?did ?nt?, which is responsible for a large part of the extracted features.In Figure 3 a similar behavior can be observed.
While the very negative expression ?incredibly dull?is responsible for 69% of the features extracted from the sentence in the left, its negation ?definitelynot dull?, which is somewhat more positive, is responsible for 77% of the features extracted from thesentence in the chart at right .
These examples indicate CharSCNN?s robustness to handle negation, aswell as its ability to capture information that is important to sentiment prediction.5 ConclusionsIn this work we present a new deep neural network architecture that jointly uses character-level, word-level and sentence-level representations to perform sentiment analysis.
The main contributions of thepaper are: (1) the idea of using convolutional neural networks to extract from character- to sentence-level features; (2) the demonstration that a feed-forward neural network architecture can be as effectiveas RNTN (Socher et al., 2013a) for sentiment analysis of sentences; (3) the definition of new state-of-the-art results for SSTb and STS corpora.7610203040506070I liked everysingleminuteof this film .010203040506070I did n?t like a singleminuteof this film .Figure 2: Number of local features selected at each word when forming the sentence-level representation.In this example, we have a positive sentence (left) and its negation (right).102030405060708090100110120It ?s just incrediblydull2030405060708090It ?s definitelynot dullFigure 3: Number of local features selected at each word when forming the sentence-level representation.In this example, we have a negative sentence (left) and its negation (right).As future work, we would like to analyze in more detail the role of character-level representationsfor sentiment analysis of tweets.
Additionally, we would like to check the impact of performing theunsupervised pre-training step using texts from the specific domain at hand.ReferencesAndrei Alexandrescu and Katrin Kirchhoff.
2006.
Factored neural language models.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, pages 1?4, New York City, USA, June.Luciano Barbosa and Junlan Feng.
2010.
Robust sentiment detection on twitter from biased and noisy data.
InProceedings of the 23rd International Conference on Computational Linguistics, pages 36?44.James Bergstra, Olivier Breuleux, Fr?ed?eric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins,Joseph Turian, David Warde-Farley, and Yoshua Bengio.
2010.
Theano: a CPU and GPU math expressioncompiler.
In Proceedings of the Python for Scientific Computing Conference (SciPy).Grzegorz Chrupala.
2013.
Text segmentation with character-level text embeddings.
In Proceedings of the ICMLworkshop on Deep Learning for Audio, Speech and Language Processing.R.
Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa.
2011.
Natural language processing(almost) from scratch.
Journal of Machine Learning Research, 12:2493?2537.R.
Collobert.
2011.
Deep learning for efficient discriminative parsing.
In Proceedings of the Fourteenth Interna-tional Conference on Artificial Intelligence and Statistics (AISTATS), pages 224?232.C?
?cero Nogueira dos Santos and Bianca Zadrozny.
2014.
Learning character-level representations for part-of-speech tagging.
In Proceedings of the 31st International Conference on Machine Learning, JMLR: W&CPvolume 32, Beijing, China.77Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twitter sentiment classification using distant supervision.
Tech-nical report, Stanford University.Angeliki Lazaridou, Marco Marelli, Roberto Zamparelli, and Marco Baroni.
2013.
Compositional?ly derived rep-resentations of morphologically complex words in distributional semantics.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Linguistics (ACL), pages 1517?1526.Yann Lecun, Lon Bottou, Yoshua Bengio, and Patrick Haffner.
1998.
Gradient-based learning applied to documentrecognition.
In Proceedings of the IEEE, pages 2278?2324.Minh-Thang Luong, Richard Socher, and Christopher D. Manning.
2013.
Better word representations with recur-sive neural networks for morphology.
In Proceedings of the Conference on Computational Natural LanguageLearning, Sofia, Bulgaria.Christopher D. Manning.
2011.
Part-of-speech tagging from 97% to 100%: Is it time for some linguistics?
InProceedings of the 12th International Conference on Computational Linguistics and Intelligent Text Processing,CICLing?11, pages 171?189.Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
2013.
Efficient estimation of word representations invector space.
In Proceedings of Workshop at International Conference on Learning Representations.Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva, Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013.Semeval-2013 task 2: Sentiment analysis in twitter.
In Second Joint Conference on Lexical and ComputationalSemantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation(SemEval 2013), pages 312?320, Atlanta, Georgia, USA, June.
Association for Computational Linguistics.Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Manning.
2011.
Semi-supervised recursive autoencoders for predicting sentiment distributions.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing, pages 151?161.Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng.
2012.
Semantic compositionalitythrough recursive matrix-vector spaces.
In Proceedings of theConference on Empirical Methods in NaturalLanguage Processing, pages 1201?1211.Richard Socher, John Bauer, Christopher D. Manning, and Andrew Y. Ng.
2013a.
Parsing with compositionalvector grammars.
In Proceedings of the Annual Meeting of the Association for Computational Linguistics.Richard Socher, Alex Perelygin, JeanWu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and ChristopherPotts.
2013b.
Recursive deep models for semantic compositionality over a sentiment treebank.
In Proceedingsof the Conference on Empirical Methods in Natural Language Processing, pages 1631?1642.Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Jason Baldridge.
2011.
Twitter polarity classification with la-bel propagation over lexical links and the follower graph.
In Proceedings of the First Workshop on UnsupervisedLearning in NLP, EMNLP, pages 53?63.A.
Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. J. Lang.
1989.
Phoneme recognition using time-delayneural networks.
IEEE Transactions on Acoustics, Speech and Signal Processing, 37(3):328?339.Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu.
2013.
Deep learning for chinese word segmentation and postagging.
In Proceedings of the Conference on Empirical Methods in NLP, pages 647?657.78
