Annotating and measuring temporal relations in textsPhilippe Muller Xavier TannierIRIT, Universit?
Paul Sabatier IRIT, Universit?
Paul SabatierToulouse, France Toulouse, Francemuller@irit.fr tannier@emse.frAbstractThis paper focuses on the automated processingof temporal information in written texts, morespecifically on relations between events intro-duced by verbs in finite clauses.
While thisproblem has been largely studied from a the-oretical point of view, it has very rarely beenapplied to real texts, if ever, with quantified re-sults.
The methodology required is still to bedefined, even though there have been proposalsin the strictly human annotation case.
We pro-pose here both a procedure to achieve this taskand a way of measuring the results.
We havebeen testing the feasibility of this on newswirearticles, with promising results.1 Annotating temporal informationThis paper focuses on the automated annotation oftemporal information in texts, more specifically re-lations between events introduced by finite verbs.While the semantics of temporal markers and thetemporal structure of discourse are well-developedsubjects in formal linguistics (Steedman, 1997),investigation of quantifiable annotation of unre-stricted texts is a somewhat recent topic.
The is-sue has started to generate some interest in com-putational linguistics (Harper et al, 2001), as it ispotentially an important component in informationextraction or question-answer systems.
A few taskscan be distinguished in that respect:?
detecting dates and temporal markers?
detecting event descriptions?
finding the date of events described?
figuring out the temporal relations betweenevents in a textThe first task is not too difficult when looking fordates, e.g.
using regular expressions (Wilson etal., 2001), but requires some syntactic analysis in alarger framework (Vazov, 2001; Shilder and Habel,2001).
The second one raises more difficult, onto-logical questions; what counts as an event is not un-controversial (Setzer, 2001): attitude reports, suchas beliefs, or reported speech have an unclear statusin that respect.
The third task adds another level ofcomplexity: a lot of events described in a text donot have an explicit temporal stamp, and it is notalways possible to determine one, even when tak-ing context into account (Filatova and Hovy, 2001).This leads to an approach more suited to the level ofunderspecification found in texts: annotating rela-tions between events in a symbolic way (e.g.
that anevent e1 is before another one e2).
This is the pathchosen by (Katz and Arosio, 2001; Setzer, 2001)with human annotators.
This, in turn, raises newproblems.
First, what are the relations best suited tothat task, among the many propositions (linguisticor logical) one can find for expressing temporal lo-cation ?
Then, how can an annotation be evaluated,between annotators, or between a human annotatorand an automated system ?
Such annotations can-not be easy to determine automatically anyway, andmust use some level of discourse modeling (cf.
thework of (Grover et al, 1995)).We want to show here the feasibility of such aneffort, and we propose a way of evaluating the suc-cess or failure of the task.
The next section willprecise why evaluating this particular task is not atrivial question.
Section 3 will explain the methodused to extract temporal relations, using also a formof symbolic inference on available temporal infor-mation (section 4).
Then section 5 discusses howwe propose to evaluate the success of the task, be-fore presenting our results (section 6).2 Evaluating annotationsWhat we want to annotate is something close to thetemporal model built by a human reader of a text; assuch, it may involve some form of reasoning, basedon various cues (lexical or discursive), and may beexpressed in several ways.
As was noticed by (Set-zer, 2001), it is difficult to reach a good agreementbetween human annotators, as they can express re-lations between events in different, yet equivalent,ways.
For instance, they can say that an event e1happens during another one e2, and that e2 happensbefore e3, leaving implicit that e1 too is before e3,while another might list explicitly all relations.
Oneoption could be to ask for a relation between allpairs of events in a given text, but this would bedemanding a lot from human subjects, since theywould be asked for n?
(n?
1)/2 judgments, mostof which would be hard to make explicit.
Anotheroption, followed by (Setzer, 2001) (and in a verysimplified way, by (Katz and Arosio, 2001)) is touse a few rules of inference (similar to the exam-ple seen in the previous paragraph), and to comparethe closures (with respect to these rules) of the hu-man annotations.
Such rules are of the form "if r1holds between x and y, and r2 holds between y andz, then r3 holds between x and z".
Then one canmeasure the agreement between annotations withclassical precision and recall on the set of triplets(event x,event y,relation).
This is certainly an im-provement, but (Setzer, 2001) points out that hu-mans still forget available information, so that it isnecessary to help them spell out completely the in-formation they should have annotated.
Setzer esti-mates that an hour is needed on average for a textwith a number of 15 to 40 events.Actually, this method has two shortcomings.First, the choice of temporal relations proposed toannotators, i.e.
"before", "after", "during", and "si-multaneously".
The latter is all the more difficultto judge as it lacks a precise semantics, and is de-fined as "roughly at the same time" ((Setzer, 2001),p.81).
The second problem is related to the infer-ential model considered, as it is only partial.
Eventhough the exact mental processing of such infor-mation is still beyond reach, and thus any claim tocognitive plausibility is questionable, there are moreprecise frameworks for reasoning about temporalinformation.
For instance the well-studied Allen?srelations algebra (see Figure 2).
Here, relations be-tween two time intervals are derived from all thepossibilities for the respective position of those in-tervals endpoints (before, after or same), yielding13 relations.
What this framework can also expressare more general relations between events, such asdisjunctive relations (relation between event 1 andevent 2 is relation A or relation B), and reasoningon such knowledge.
We think it is important atleast to relate annotation relations to a clear tem-poral model, even if this model is not directly used.Besides, we believe that measuring agreement onthe basis of a more complete "event calculus" willbe more precise, if we accept to infer disjunctive re-lation.
Then we want to give a better score to theannotation "A or B" when A is true, than to an an-notation where nothing is said.
Section 5 gives moredetails about this problem.We will now present our method to achieve thetask of annotating automatically event relations.This has been tested on a small set of Frenchnewswire texts from the Agence France Press.3 A method for annotating temporalrelationsWe will now present our method to achieve the taskof annotating automatically event relations.
Thishas been tested on a small set of French newswiretexts from the Agence France Press.
The startingpoint was raw text plus its broadcast date.
We thenapplied the following steps:?
part of speech tagging with Treetagger(Schmid, 1994), with some post-processing tolocate some lexicalised prepositional phrases;?
partial parsing with a cascade of regular ex-pressions analyzers (cf.
(Abney, 1996); wealso used Abney?s Cass software to apply therules)1.
This was done to extract dates, tem-poral adjuncts, various temporal markers, andto achieve a somewhat coarse clause-splitting(one finite verb in each clause) and to attachtemporal adjuncts to the appropriate clause(this is of course a potentially large source oferrors).
Relative clauses are extracted and putat the end of their sentence of origin, in a waysimilar to (Filatova and Hovy, 2001).
Table1 gives an idea of the kind of temporal infor-mation defined and extracted at this step andfor which potentially different temporal inter-pretations are given (for now, temporal focusis always the previously detected event; this isobviously an over-simplification).?
date computation to precise temporal locationsof events associated with explicit, yet impre-cise, temporal information, such as dates rela-tive to the time of the text (e.g.
last Monday).?
for each event associated to a temporal adjunct,a temporal relation is established (with a datewhen possible).?
a set of discourse rules is used to establishpossible relations between two events appear-ing consecutively in the text, according tothe tenses of the verbs introducing the events.These rules for French are similar to rules forEnglish proposed in (Grover et al, 1995; Songand Cohen, 1991; Kameyama et al, 1993), but1We have defined 89 rules, divided in 29 levels.are expressed with Allen relations instead of aset of ad hoc relations (see Table 1 for a sub-set of the rules).
These rules are only appliedwhen no temporal marker indicates a specificrelation between the two events.?
the last step consists in computing a fixed pointon the graph of relations between events recog-nized in the text, and dates.
We used a classi-cal path-consistency algorithm (Allen, 1984).More explanation is given section 4.Allen relations are illustrated Figure 2.
In the fol-lowing (and Table 1) they will be abbreviated withtheir first letters, adding an "i" for their inverse re-lations.
So, for instance, "before" is "b" and "after"is "bi" (b(x,y)?
bi(y,x)).
Table 1 gives the disjunc-tion of possible relations between an event e1 withtense X and a event e2 with tense Y following e1 inthe text.
This is considered as a first very simplifieddiscourse model.
It only tries to list plausible rela-tions between two consecutive events, when there isno marker than could explicit that relation.
For in-stance a simple past e1 can be related with e, b, m,s, d, f, o to a following simple past event e2 in sucha context (roughly saying that e1 is before or dur-ing e2 or meets or overlaps it).
This crude model isonly intended as a basis, which will be refined oncewe have a larger set of annotated texts.
This will beenriched later with a notion of temporal focus, fol-lowing for instance (Kameyama et al, 1993; Songand Cohen, 1991), and a notion of temporal per-spective necessary to capture more complex tenseinteractions.The path consistency algorithm is detailed in thenext section.4 Inferring relations between eventsXYXXXYYYfinishesbeforemeetsoverlapsXXYYequalsduringstartsXYFigure 2: Allen Relations between two intervals Xand Y (Time flies from left to right)We have argued in favor of the use of Allen rela-tions for defining annotating temporal relations, notonly because they have a clear semantics, but alsobecause a lot of work has been done on inferenceprocedures over constraints expressed with these re-lations.
We therefore believe that a good way ofavoiding the pitfalls of choosing relations for hu-man annotation and of defining inference patternsfor these relations is to define them from Allen rela-tions and use relational algebra computation to inferall possible relations between events of a text (that issaturate the constraint graph, see below), both froma human annotation and an annotation given by asystem, and then to compare the two.
In this per-spective, any event is considered to correspond to aconvex time interval.The set of all relations between pairs of events isthen seen as a graph of constraints, which can becompleted with inference rules.
The saturation ofthe graph of relations is not done with a few hand-crafted rules of the form (relation between e1 ande2) + (relation between e2 and e3) gives (a simplerelation between e1 and e3) (Setzer, 2001; Katz andArosio, 2001) but with the use of the full algebra ofAllen relation.
This will reach a more complete de-scription of temporal information, and also gives away to detect inconsistencies in an annotation.An algebra of relation can be defined on any set ofrelations that are mutually exclusive (two relationscannot hold at the same time between two entities)and exhaustive (at least one relation must hold be-tween two given entities).
The algebra starts from aset of base relations U= {r1, r2, ...}, and a generalrelation is a subset of U, interpreted as a disjunctionof the relations it contains.
From there we can de-fine union and intersection of relations as classicalset union and intersection of the base relations theyconsist of.
Moreover, one can define a compositionof relations as follows:(r1 ?
r2)(x, z) ?
?y r1(x, y) ?
r2(y, z)By computing beforehand the 13?13 compositionsof base relations of U, we can compute the composi-tion of any two general relations (because r?r ?
=?when r, r?
are basic and r6= r?
):{r1, r2, ...rk} ?
{s1, s2, ...sm} =?i,j(ri ?
sj)Saturating the graph of temporal constraints meansapplying these rules to all compatible pairs ofconstraints in the graph and iterating until a fix-point is reached.
The following, so-called "path-consistency" algorithm (Allen, 1984) ensures thisfixpoint is reached:date(1/2) : non absolute date ("march 25th", "in June").dateabs : absolute date "July 14th, 1789".daterelST : date, relative to utterance time ("two yearsago").daterelTF : date, relative to temporal focus ("3 days later").datespecabs : absolute date, with imprecise reference ("inthe beginning of the 80s").datespecrel : relative date, special forms (months, seasons).dur : basic duration ("during 3 years").dur2 : duration with two dates (from February, 11 to Octo-ber, 27. .
.
).durabs : absolute duration ("starting July 14").durrelST : relative duration, w.r.t utterance time ("for ayear").durrelTF : relative duration, w.r.t temporal focus ("since").tatom : temporal atom (three days, four years, .
.
.
).Figure 1: Temporal elements extracted by shallow parsing (with examples translated from French)e1/e2 imp pp pres spimp o, e, s, d, f, si, di, fi bi, mi, oi e, b o, d, s, f, e, si, di, fipp b, m, o, e, s, d, f b, m, o, e, s, d, f, bi, mi e, b b, m, opres U U b, m, o, si, di, fi, e Usp b, m, o, e, s, d, f e, s, d, f, bi, mi e, b e, b, m, s, d, f, oTable 1: Some Discursive temporal constraints for the main relevant tenses, sp=simple past and perfect,imp=French imparfait, pp=past perfect, pres=presentLet{A = the set of all edges of the graphN = the set of vertices of the graphU = the disjunction of all 13 Allen relationsRm,n = the current relation betweennodes m and n1.
changed = 02. for all pair of nodes (i, j) ?
N ?N and for allk ?
N such that ((i, k) ?
A ?
(k, j) ?
A)(a) R1i,j = (Ri,k ?
Rk,j)(b) if no edge (a relation R2i,j) existed beforebetween i and j, then R2i,j = U(c) intersect: Ri,j = R1i,j ?
R2i,j(d) if Ri,j = ?
(inconsistency detected)then : error(e) if Ri,j = U (=no information) do nothingelse update edgechanged = 13. if changed = 1, then go back to 1.It is to be noted that this algorithm is correct: ifit detects an inconsistency then there is really one,but it is incomplete in general (it does not neces-sarily detect an inconsistent situation).
There aresub-algebras for which it is also complete, but it re-mains to be seen if any of them can be enough forour purpose here.5 Measuring successIn order to validate our method, we have comparedthe results given by the system with a "manual" an-notation.
It is not really realistic to ask humans(whether they are experts or not) for Allen relationsbetween events.
They are too numerous and someare too precise to be useful alone, and it is prob-ably dangerous to ask for disjunctive information.But we still want to have annotation relations with aclear semantics, that we could link to Allen?s alge-bra to infer and compare information about tempo-ral situations.
So we have chosen relations similarto that of (Bruce, 1972) (as in (Li et al, 2001)), whoinspired Allen; these relations are equivalent to cer-tain sets of Allen relations, as shown Table 2.
Wethought they were rather intuitive, seem to have anappropriate level of granularity, and since three ofthem are enough to describe situations (the other 3being the converse relations), they are not to hard touse by naive annotators.To abstract away from particulars of a given an-notation for some text, and thus to be able to com-pare the underlying temporal model described by anannotation, we try to measure a similarity betweenannotations given by a system and human annota-tions, from the saturated graph of detected tempo-ral relations in each case (the human graph is satu-rated after annotation relations have been translatedas equivalent disjunctions of Allen relations).
We donot want to limit the comparison to "simple" (base)relations, as in (Setzer, 2001), because it makes theevaluation very dependent on the choice of rela-tions, and we also want to have a gradual measureof the imprecision of the system annotation.
For in-stance, finding there is a "before or during" relationbetween two events is better than proposing "after"is the human put down "before", and it is less goodBEFORE ?
i ?
j (i before j ?
((i b j) ?
(i m j)))AFTER ?
i ?
j (i after j ?
((i bi j) ?
(i mi j)))OVERLAPS ?
i ?
j (i overlaps j ?
((i o j)))IS_OVERLAPPED ?
i ?
j (i is_overlapped j ?
((i oi j)))INCLUDES ?
i ?
j (i includes j ?
((i di j) ?
(i si j) ?
(i fi j) ?
(i e j)))IS_INCLUDED ?
i ?
j (i is_included j ?
((i d j) ?
(i s j) ?
(i f j) ?
(i e j)))Table 2: Relations proposed for annotationthan the correct answer "before".Actually we are after two different notions.
Thefirst one is the consistency of the system?s annota-tion with the human?s: the information in the textis compatible with the system?s annotation, i.e.
theformer implies the latter.
The second notion is howprecise the information given by the system is.
Avery disjunctive information is less precise than asimple one, for instance (a or b or c) is less precisethan (a or b) if a correct answer is (a).In order to measure these, we propose two ele-mentary comparison functions between two sets ofrelations S and H, where S is the annotation pro-posed by the system and H is the annotation inferredfrom what was proposed by the human.finesse = |S?H||S| coherence =|S?H||H|The global finesse score of an annotation is the aver-age of a measure on all edges that have informationaccording to the human annotation (this excludesedges with the universal disjunction U) once thegraph is saturated, while coherence is averaged onthe set of edges that bear information according tothe system annotation.Finesse is intended to measure the quantity of in-formation the system gets, while coherence givesan estimate of errors the system makes with re-spect to information in the text.
Finesse and coher-ence thus are somewhat similar respectively to re-call and precision, but we decided to use new termsto avoid confusion ("precision" being an ambigu-ous term when dealing with gradual measures, asit could mean how close the measure is to the max-imum 1).Obviously if S=H on all edges, all measures areequal to 1.
If the system gives no information atall, S is a disjunction of all relations so H ?
S,H ?
S = H and coherence=1, but then finesse isvery low.These measures can of course be used to estimateagreement between annotators.6 ResultsIn order to see whether the measures we proposeare meaningful, we have looked at how the mea-sures behave on a text "randomly" annotated in thefollowing way: we have selected at random pairs ofevents in a text, and for each pair we have picked arandom annotation relation.
Then we have saturatedthe graph of constraints and compared with the hu-man annotation.
Results are typically very low, asshown on a newswire message taken as example Ta-ble 3.We have then made two series of measures: oneon annotation relations (thus disjunctions of Allenrelations are re-expressed as disjunctions of annota-tion relations that contains them), and one on equiv-alent Allen relations (which arguably reflects morethe underlying computation, while deteriorating themeasure of the actual task).
In the first case, anAllen relation answer equals to b or d or s betweentwo events is considered as ?before or is_included?
(using relations used by humans) and is comparedto an annotation of the same form.We then used finesse and coherence to estimateour annotation made according to the method de-scribed in the previous sections.
We tried it on astill limited2 set of 8 newswire texts (from AFP),for a total of 2300 words and 160 events, compar-ing to the English corpus of (Setzer, 2001), whichhas 6 texts for less than 2000 words and also about160 events.
Each one of these texts has between 10and 40 events.
The system finds them correctly withprecision and recall around 97%.
We made the com-parison only on the correctly recognized events, inorder to separate the problems.
This course limitsthe influence of errors on coherence, but handicapsfinesse as less information is available for inference.The measures we used were then averaged on thenumber of texts.
This departs from what could beconsidered a more standard practice, summing ev-erything and dividing by the number of comparisonsmade.
The reason behind this is we think compar-ing two graphs as comparing two temporal modelsof a text, not just finding a list of targets in a setof texts.
It might be easier to accept this if one re-members that the number of possible relations be-tween n events is n(n?1)/2.
A text t1 with k more2We are still annotating more texts manually to give moresignificance to the results.Finesse Coherenceannotation relations 0.114 0.011Allen relations 0.083 0.094Table 3: Example of evaluation on a "random" annotationevents than a text t2 will thus have about k2 timesmore importance in a global score, and we find con-fusing this non-linear relation between the size of atext and its weight in the evaluation process.
There-fore, both finesse and coherence are generalized asglobal measure of a temporal model of a text.
Itcould then be interesting to relate temporal infor-mation and other features of a given text (size beingonly one factor).Results are shown Table 4.
These results seempromising when considering the simplifications wehave made on every step of the process.
Caution isnecessary though, given the limited number of textswe have experimented on, and the high variation wehave observed between texts.
At this stage we be-lieve the quality of our results is not that important.Our main objective, above all, was to show the fea-sibility of a robust method to annotate temporal re-lations, and provide useful tools to evaluate the task,in order to improve each step separately later.
Ourfocus was on the design of a good methodology.If we try a first analysis of the results, sourcesof errors fall on various categories.
First, a numberof temporal adverbials were attached to the wrongevent, or were misinterpreted.
This should be fine-tuned with a better parser than what we used.
Then,we have not tried to take into account the specificnarrative style of newswire texts.
In our set of texts,the present tense was for instance used in a lot ofplaces, sometimes to refer to events in the past,sometimes to refer to events that were going to hap-pen at the time the text was published.
However,given the method we adopted, one could have ex-pected better coherence results than finesse results.It means we have made decisions that were not cau-tious enough, for reasons we still have to analyze.One potential reason is that relations offered to hu-mans are maybe too vague in the wrong places: alot of information in a text can be asserted to be"strictly before" something else (based on dates forinstance), while human annotators can only say thatevents are "before or meets" some other event; eachtime this is the case, coherence is only 0.5.It is important to note that there are few pointsof comparison on this problem.
To the best of ourknowledge, only (Li et al, 2001) and (Mani andWilson, 2000) mention having tried this kind of an-notation, as a side job for their temporal expressionsmark-up systems.
The former considers only rela-tions between events within a sentence, and the lat-ter did not evaluate their method.Finally, it is worth remembering that human an-notation itself is a difficult task, with potentially alot of disagreement between annotators.
For now,our texts have been annotated by the two authors,with an a posteriori resolution of conflicts.
Wetherefore have no measure of inter-annotator agree-ment which could serve as an upper bound of theperformance of the system, although we are plan-ning to do this at a later stage.7 ConclusionThe aim of this study was to show the feasibility ofannotating temporal relations in a text and to pro-pose a methodology for the task.
We thus define away of evaluating the results, abstracting away fromvariations of human descriptions for similar tempo-ral situations.
Our preliminary results seem promis-ing in this respect.
Obviously, parts of the methodneed some polishing, and we need to extend thestudy to a larger data set.
It remains to be seen howimproving part of speech tagging, syntactic analy-sis and discourse modeling can influence the out-come of the task.
Specifically, some work needs tobe done to evaluate the detection of temporal ad-juncts, a major source of information in the process.We could also try to mix our symbolic method withsome empirical learning.
Provided we can collectmore annotated data, it would be easy to improvethe discourse model by (at least local) optimizationon the space of possible rules, starting with our ownset.
We hope that the measures of temporal infor-mation we have used will help in all these aspects,but we are also planning to further investigate theirproperties and that of other candidate measures notconsidered here.ReferencesSteven Abney, 1996.
Corpus-Based Methods inLanguage and Speech, chapter Part-of-SpeechTagging and Partial Parsing.
Kluwer AcademicPublisher.J.
Allen.
1984.
Towards a general theory of actionand time.
Artificial Intelligence, 23:123?154.B.
Bruce.
1972.
A model for temporal referencesFinesse Standard Deviation Coherence SDannotation relations 0.477499 0.286781 0.449899 0.175922Allen relations 0.448222 0.289856 0.495755 0.204974Table 4: Evaluationand its application in a question answering pro-gram.
Artificial Intelligence, 3(1-3):1?25.Elena Filatova and Eduard Hovy.
2001.
Assign-ing time-stamps to event-clauses.
In Harper et al(Harper et al, 2001).Claire Grover, Janet Hitzeman, and Marc Moens.1995.
Algorithms for analysing the temporalstructure of discourse.
In Sixth InternationalConference of the European Chapter of the As-sociation for Computational Linguistics.
ACL.Lisa Harper, Inderjeet Mani, and Beth Sundheim,editors.
2001.
ACL Workshop on Temporaland Spatial Information Processing, 39th AnnualMeeting and 10th Conference of the EuropeanChapter.
Association for Computational Linguis-tics.M.
Kameyama, R. Passonneau, and M. Poesio.1993.
Temporal centering.
In Proceedings ofACL 1993, pages 70?77.Graham Katz and Fabrizio Arosio.
2001.
The an-notation of temporal information in natural lan-guage sentences.
In Harper et al (Harper et al,2001), pages 104?111.W.
Li, K-F. Wong, and C. Yuan.
2001.
A modelfor processing temporal reference in chinese.
InHarper et al (Harper et al, 2001).I.
Mani and G. Wilson.
2000.
Robust temporal pro-cessing of news.
In Proceedings of ACL 2000.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings ofthe International Conference on New Methods inLanguage Processing.Andrea Setzer.
2001.
Temporal Information inNewswire Articles: an Annotation Scheme andCorpus Study.
Ph.D. thesis, University ofSheffield, UK.Franck Shilder and Christopher Habel.
2001.
Fromtemporal expressions to temporal information:Semantic tagging of news messages.
In Harperet al (Harper et al, 2001), pages 65?72.F.
Song and R. Cohen.
1991.
Tense interpretationin the context of narrative.
In Proceedings ofAAAI?91, pages 131?136.Mark Steedman.
1997.
Temporality.
In J.
Van Ben-them and A. ter Meulen, editors, Handbook ofLogic and Language.
Elsevier Science B.V.Nikolai Vazov.
2001.
A system for extraction oftemporal expressions from french texts based onsyntactic and semantic constraints.
In Harperet al (Harper et al, 2001).George Wilson, Inderjeet Mani, Beth Sundheim,and Lisa Ferro.
2001.
A multilingual approach toannotating and extracting temporal information.In Harper et al (Harper et al, 2001).
