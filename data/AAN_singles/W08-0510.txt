Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 58?65,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsDesign of the Moses Decoder for Statistical Machine TranslationHieu HoangUniversity of Edinburghh.hoang@sms.ed.ac.ukPhilipp KoehnUniversity of Edinburghpkoehn@inf.ed.ac.ukAbstractWe present a description of the implemen-tation of the open source decoder for statis-tical machine translation which has becomepopular with many researchers in SMT re-search.
The goal of the project is to createan open, high quality phrase-based decoderwhich can reduce the time and barrier toentry for researchers wishing to do SMTresearch.
We discuss the major design ob-jective for the Moses decoder, its perform-ance relative to other SMT decoders, andthe steps we are taking to ensure that itssuccess will continue.1 MotivationPhrase-based translation has been one of themajor advances in statistical machine translation(Brown et al 1990) in recent years and is currentlyone of the techniques which can claim to be state-of-the-art in machine translation.
Phrase-basedmodels are a development of the word based mod-els as exemplified by the (Brown et al 1990).
Inphrase-based translation, contiguous segments ofwords in the input sentence are mapped to contigu-ous segments of words in the output sentence.In SMT, we are given a source language sen-tence, s, which is to be translated into a target lan-guage sentence, t. The goal of machine translationis to find the translation, t?
, which is defined as:?
arg max ( | )tt p t s=where ( | )p t s is the probability model.
The argmaximplies a search for the best translation t?
in thespace of possible translations t. This search is thetask of the decoder, which we will concentrate onin this paper.There have been numerous implementations ofphrase-based decoders for SMT prior to our work.Early systems such as the Alignment TemplateSystem (ATS) (Och and Ney 2004) and Pharaoh(Koehn 2004) were widely used and accepted bythe research community.
ATS is perhaps the cross-over system, in that word classes were translated asphrases but the surface words were translated wordby word.
Pharaoh substituted the word classes withsurface words, thereby discarding the use of wordclasses in decoding altogether.There has been other phrase-based decoderssuch as PORTAGE (Sadat et al 2005), Phramer(Olteanu et al 2006), the MITLL/AFRL system(Shen et al 2005), ITC-irst (Bertoldi et al 2004),Ramses/Mood (Patry et al 2006) to name but afew.
Other researchers such as (Kumar and Byrne2003) have also used weighted finite state trans-ducers but they have more difficulty modeling re-ordering.Many early systems came with restrictive li-censes; ATS has never been publicly released,Pharaoh was released in 2003 as a pre-compiledbinary with documentation.
This severely limitedthe extent to which other researchers can study andenhance the decoder.
Without access to the de-coder source code research was generally restrictedto altering the input, augmenting it with extra in-formation, or modifying the output or re-rankingthe n-best list output.The main contribution of this paper is to showhow we have created an extensible decoder, hasacceptable run time performance compared tosimilar systems, and the ease of use and develop-ment that has made it the preferred choice for re-searchers looking for a phrase-based SMT decoder.58As an indication of the take-up of the Mosestoolkit, out of over 20 competing teams at the re-cent IWSLT 2007 conference1, half used Moses.As an indication of the extensibility of the de-coder, there are currently four language model im-plementations which has been integrated with thedecoder by various researchers.
In addition, theframework exists to integrate language models,such as those described in (Bilmes and Kirchhoff2003), which takes advantage of the factored rep-resentation within Moses.It is noted that Mood/Ramses also supportsmultiple LM implementations, an internally devel-oped language model, in additional to SRILM, toovercome the latter?s licensing restrictions.In addition, there are two built-in phrase tableimplementations, one which loads all data intomemory for fast decoding, and a binary phrase ta-ble as described in (Zens and Ney 2007) whichloads on demand to conserve memory usage.The Moses decoder has the ability to acceptsimple sentence input, confusion network or latticenetworks, in common with SMT decoders such asthe MITLL/AFRL or ITC-irst systems.
The de-coder also produces diverse types of output, rang-ing from 1-best, n-best lists and word lattices.2 Comparison with other projectsThe Moses decoder is designed within a strictmodular and object-oriented framework for easymaintainability and extensibility.In designing the decoder, we modeled the soft-ware design methodology and aims on some re-search-oriented software libraries outside of theSMT and NLP field which is open source, writtenin C++, have a large and diverse user-base, havesucceeded in becoming the industry norm in theirfield.Specifically, we modeled the software on theCGAL library (Fabri et al 2000), used in computa-tional geometry, and DCMTK (Eichelberg et al2004) library used in medical imaging.
We believethey set good examples of the standards that weshould follow.However, there are differences between our pro-ject and CGAL or DCMTK.The first difference is project size, for example,whereas CGAL consists of over 500,000 lines of1http://iwslt07.oitc.it/menu/program.htmlcode and multiple libraries and example program,the Moses decoder consists of 20,000 lines in 2libraries.
The difference is scale makes implement-ing some steps in the development life cycle im-practical or unnecessary.
For example, functional-ity specification before implementation was de-scribed for CGAL and is typical of large projectsbut would have been cumbersome for Moses.Secondly, the aims of Moses and these projectsare different.
The goal of the CGAL project is to?make?computational geometry available for in-dustrial application?2.Both CGAL and DCMTK are used extensivelyin commercial applications.
Therefore, issues suchrobustness, cross-platform compatibility and ease-of-use are predominant for these projects.Commercialization is not an aim of the Mosesproject but we believe these issues are still as im-portant as they affect the usability and uptake ofthe system.
Therefore, the Moses decoder was builtto address these issues without compromising theacademic priorities of the project.Thirdly, the correct implementation is easier todecide in libraries such as CGAL as the algorithmsare closely specified by the mathematical specifi-cation, therefore, testing and specification writingis more prevalent and easier than in Moses.
ForDCMTK, the medical imaging standards and pro-tocols offers a clear guide for implementation.
Bycontrast, the function of an SMT decoder is searchfor which there are no correct implementation, wecan only measure its performance relative to previ-ous versions and other similar decoders.These differences are minor compared to thesimilarities Moses has to CGAL and DCMTK, andindeed, to any well developed software project.Design goals such as robustness, flexibility, ease ofuse and efficiency are commonality that we shareand which we will discuss in more detail in thenext section.As a contrast to CGAL and DCMTK whose de-sign we would like to emulate, we also looked at aproject within the NLP field which contains certainaspect in the design we would like to avoid.GIZA++ (Och and Ney 2003) is a very popularsystem within SMT for creating word alignmentfrom parallel corpus, in fact, the Moses trainingscripts uses it.
The system was release under theGPL open source license.
However, its lack of2http://cordis.europa.eu/esprit/src/21957.htm59clear design, documentation and obscure codingstyle makes it difficult for other researcher to con-tribute or extend the system.
For a long time, itcouldn?t even be compiled on modern GCC com-pilers.
Other systems which seeks to improve wordalignment and segmentation, such as MTTK (Denget al 2006), have been created to replace GIZA++.3 Design GoalsWe decided to develop the Moses decoder as aC++ library.We steered clear of scripting languages for per-formance reasons and the fact they often offer evenless in the way of cross-platform compatibility.Java was also avoided for performance reasons butit?s rich library and multi-platform support wouldhave been useful.We note that Hiero (Chiang 2005) is written in ascripting language with performance critical com-ponents rewritten in a compiled language.
This isnot the approach we considered as we believed itwould have raised the complexity and reduce reli-ability of the project having to develop (and debug)in two languages and managing the interface be-tween them.
We also note that the LinearB andPhramer decoders are implemented in Java andhave reported significantly worse run time speeds,(Olteanu et al 2006).C++ can be inelegant and difficult for inexperi-enced developers but using other object orientedlanguage such as Smalltalk or C# was out of thequestion as they lack acceptance within the MTresearch community.3.1 Comparable PerformanceThe Pharaoh decoder (Koehn 2004) representedthe state-of-the-art in phrase-based decoders priorto the introduction of Moses.
Moses was designedto supersede Pharaoh in performance and function-ality.
Moses was used as the basis for the JHUWorkshop (Koehn et al 2006) on Factored Ma-chine Translation where it was extensively en-hanced; we capitalized on the experience of col-leagues at the workshop and used Pharaoh as thebaseline during development to ensure that we ob-tain comparable performance.
Table 1 shows thecomparison of the translation performance of Phar-aoh and Moses for a typical decoding of 2000 sen-tence trained on the news-commentary corpus3.
Wealso include Phramer as an example of a Java-based decoder.
Due to improvements in the searchalgorithm, Moses can slightly outperform Pharaohon most tasks, which was confirmed by (Shen et al2007).Table 1 Comparison with pharaoh & Phramer for atypical fr-en translation of 2000 sentencesTimetakenPeakmemoryusageBLEUPharaoh 99min 46MB 19.57Moses 69min 154MB 19.57Moses, with loadon-demand PT &LM102min 239MB 19.57Phramer 649min 1218MB 19.44In addition, most of the functionality of Pharaohhas been replicated.3.2 Integration of Word-Level FactorsThe Moses decoder isn?t purely a clone of Phar-aoh, it was created to conduct research into word-level factors in phrase-base MT.
Whereas tradi-tional, non-factored SMT typically deals only withthe surface form of words, factored translationmodels augments different factors, such as POStags or lemma, into source and target sentences toimprove translation.
This transforms the represen-tation of a word from a string to a vector of strings,and a phrase or sentence from a sequence of wordsto a sequence of vectors.
Such a change to the ba-sic data structure of a decoder propagated through-out the rest of the system, therefore, it was simplerto build the Moses decoder from scratch ratherthan extend an existing decoder such as Pharaoh.Some research into factored machine translationhas been published by (Koehn and Hoang 2007).3.3 FlexibilityFlexibility is an important software design goalwhich will enable researchers to extend the use ofthe Moses decoders to tasks that were not origi-nally envisioned.Following (Fabri et al 2000), we identify foursub-issues which affects flexibility:i. Modularity3http://www.statmt.org/wmt07/shared-task.html60ii.
Adaptabilityiii.
Extensibilityiv.
Openness3.4 ModularityFirstly, software modularity enables developersto work on one component of the decoder withoutaffecting other components.
A modular design re-duces the learning curve for developers by shield-ing them from having to understand the entire sys-tem if they are only developing a specific part.Modularity also assists in the re-using of com-ponents by separating the implementation detailsfrom the module interface.Moses takes advantage of C++ support for ob-ject-oriented and generic programming to enablemodularity.In keeping with the extensible design of CGALand DCMTK, the core of the decoder is compiledas a static library which can interact with othercomponents through a well-defined API.
The sim-ple application which currently comes with thedecoder enables users to use the system via thecommand line and also provides an example of theAPI.Therefore, the current typical compilation of thedecoder would combine the libraries fromIRSTLM, SRILM, Moses, and moses-cmd to cre-ate a binary executable.SRILM IRSTLMmosesmoses-cmdFigure 1 Project DependenciesAny of these libraries can be dropped or re-placed with other components with the same API.We detail some examples of the object-orienteddesign of Moses below.The input into the decoder can be one of threetypes: a simple string (sentence), a confusion net-work or a lattice network, Figure 2.Figure 2 Input TypesLanguage models are abstracted to enable differentimplementations to be used and provide a frame-work for more complex models such as factoredLM and the Bloom filter language model (Talbotand Osborne 2007).
Similarly, phrase tables areabstracted to provide support for multiple imple-mentations.Each component model which contributes to thelog-linear hypothesis score inherits from theScoreProducer base class, Figure 3.Figure 3 Score ProducerThe Moses library provide a simple API whosemain entry point is the classManagerThis class is instantiated in the client application,moses-cmd in our case.
Each input is decoded bycalling the class method below:ProcessSentence()3.5 AdaptabilityPhrase-based SMT is a fast moving researchfield where virtually all aspects of the theory are61still being explored and implementations can beimproved.
The Moses decoder has to be amenableto researchers to adapt any component of the de-coder in ways that perhaps wasn?t foreseen in theoriginal implementation.Certainly, modularity plays an important partin this but it can also have the opposite effect ofallowing obtuse or badly written implementation tohide behind the API, reducing the ability for re-searchers to question, investigate or extend.
As avoluntary project, there is limited power to enforcegood implementation and it would be difficult notto accept added functionality.However, we use coding standards and designsduring the development of the decoder that wehope makes the task of working with Moses easierfor developers, and that they will continue to usethose standards to uphold the clarity of the code.These coding standards include:i. strict object-oriented designii.
descriptive variable, class, object andfunction namesiii.
consistent indentationiv.
use of STL containersv.
implementation of STL-compatible it-erators for internal container classes.The source code for the Moses decoder has con-tributions from a number of developers in the lasttwo years, Figure 4, including four developers whohave made significant contributions but were not inthe original JHU Workshop.
However, code clarityhas, by-and-large, remained intact.0%10%20%30%40%50%60%70%lexi_birchccorbettnicolabertoldiabarunjdschroedereherbstphkoehnkonrad_rawlikzensredponyhieuhoang1972%ageof codecommitedFigure 4 Code committedWe do not know how the decoder will bechanged in future, nor do we know where and bywhom it will be used.
Moses is first and foremostan academic project but that doesn?t exclude its usein commercial applications.We also believe that it will be useful as a teach-ing tool for computational linguists, machine trans-lation researchers or general computer science stu-dents.
It is important with such a diverse potentialuser base, with widely varying degrees of C++ andprogramming experience, that we make the devel-opment and use of Moses as easy as possible,without imposing a significant burden on advancedusers.We would like to lower the learning curve byletting users use Moses in an environment andtools where they are most comfortable with.
There-fore, the Moses decoder is operating system andcompiler neutral.
It is known to run on Windows(natively, or with Cygwin), Linux 32 and 64 bits,Mac OSX and OpenBSD.
It is known to be com-pileable with modern gcc compilers, Visual Stu-dio.net, Intel C++ for both Linux and Windows.We encourage the use of modern graphical inte-grated development environments (IDE) for Mosesand include project files for Visual Studio, Eclipseand XCode, in addition to conventional makefiles.We note that almost half of the source codedownloads for the Moses toolkit from Sourceforgeare for the non-Unix version, and that 58% of thevisitors to the Moses website uses Windows,Figure 5.Window sLinuxMacOtherFigure 5 OS of Moses website visitorsThis heterogeneous approach allows developerswho have previously been excluded to participatewithin the SMT community and strengthens thedecoder by allowing people of different back-grounds to apply their skills.
This is of particularconcern to us as we are attempting to integrate lin-62guistic information into machine translation withfactored decoding.It also enables best-of-breed tools to be boughtto the development of the decoder, regardless ofplatform.
For example, we use both open sourceand commercial tools on Linux and Windows totrack down memory issues, as well as performanceprofilers.
This greatly enhances the efficiency ofdevelopment and the reliability of the decoder.Other NLP libraries, such as SRILM (Stolcke2002) can be compiled and executed under multi-ple platforms but its development are very muchUnix-centric so requires porting tools for non-Unixplatforms.
We believe the platform and compileragnostic approach is unique for a major opensource C++ project within recent NLP history.3.6 OpennessAn important reason for initiating the Mosesproject was the need to create a competitive de-coder which could be extended with factors, aswell as other advances in phrase-based machinetranslation.
It is open source to enable other re-searchers to extend a state-of-the-art decoder with-out having to recreate what we have already built.The decoder was improved at the JHU Work-shop by a number of researchers so it needed to beflexible from the beginning.
From this experience,we realize that releasing the source code is notenough.
The decoder must be written and struc-tured in a clear way to enable other researchers tocontribute to the project.Aside from the legalese of releasing the sourcecode under an open source license, we believe thatopen source also means the source code is clearand accessible to allow others to examine, critiqueand contribute.
Coding standards aimed at sourcecode clarity and support for modern tools backsthis goal.Documentation of the algorithms used, and ofthe source code are also essential to allow others tounderstand the details of the decoder.
Every classand function in the Moses decoder is commentedin a Doxygen compatible format, HTML docu-ments and figures, such as those in Figure 2 andFigure 3, are generated automatically from thesecomments and accessible via the Web4.Development is done through a source controlsystem and all code changes are open to inspec-4http://www.statmt.org/moses/html/tion.
We encourage and enable all developers touse and extend Moses and feed back improve-ments.
However, to ensure that the performance ofthe decoder is maintained and that changes to thedecoder doesn?t break existing setups, we maintaincertain controls over the commit process.There is a regression test suite which should bepassed before any code can be committed to ensurethat unintended divergence haven?t crept in.
Aframework exists for creation of regression tests,developers who add new functionality to the de-coder are encouraged to create additional tests toensure that their functionality will work in future.However, no amount of automated testing canbe exhaustive.
New committers are subject to peerreview by a more experience contributor before thecode is committed, and before the contributor isgranted write access to the source control system.Also, code commits are monitored via email notifi-cations to a public mailing list.These measures add a little overhead to the de-velopment process this is necessary to maintain thequality of the system and assure to users and de-velopers.We have benefited from the examples of soundsoftware engineering principles set by the CGALand DCMTK project and hope that we will emulatetheir success by bringing these engineering princi-ples into NLP.
In contrast to the ?abandonware?status of GIZA++, both CGAL and DCMTK arestill being developed.4 Supporting InfrastructureOther factors have contributed to the wide adop-tion of Moses.4.1 ?One-Stop Shop?
for Phrase-Based SMTThe Moses project encompasses the decoder andmany of the other components necessary to createa translation system which were previously avail-able separately.
These include scripts for creatingalignments from a parallel corpus, creating phrasetables and language models, binarizing phrase ta-bles, scripts for weight optimization using MERT(Och 2003), and testing scripts.Steps such as MERT and testing which are CPUintensive have been re-engineered to run in parallelusing Sun Grid Engine.All scripts have also been extended for factoredtranslation.634.2 Ongoing supportWe assist in the adoption of Moses by offeringongoing support to users and developers throughthe support mailing list 5 .
Questions relating toMoses, phrase-based translation or machine trans-lation in general are often asked, and usually an-swered.
The archived emails are publicly availableand searchable, and have become an importantknowledge source for the community.The mailing list popularity has been steadily in-creasing since its inception, Figure 6, and is nowthe most popular mailing list for machine transla-tion, based on volume.020406080100120140160Nov-06Dec-06Jan-07Feb-07Mar-07Apr-07May-07Jun-07Jul-07Aug-07Sep-07Oct-07Nov-07Dec-07Jan-08Feb-08Figure 6 Emails to Moses support mailing list5 Future WorkThere has been some important developments inphrase-based translation in recent years, includingthe hierarchical phrase-based model as described in(Chiang 2005).
Research have also been made intoalternatives to the current log-linear scoring modelsuch as discriminative models with millions of fea-tures (Liang et al 2006), or kernel based models(Wang et al 2007).From a software engineering point of view,these improvements would require fundamentalchanges to the structure if they were to be imple-mented into Moses.We are also interested in seeing the Moses de-coder employed in search tasks outside of machinetranslation; Moses has been used for OCR correc-tion, recasing, and transliteration.Other improvements such as smaller, faster,more efficient phrase tables are also welcomed.Lastly, we would like to see the training andtuning scripts re-engineered to the same modular5moses-support@mit.edudesign as the decoder.
The future direction of theMoses decoder requires even more complex mod-els which are already stretching the current scriptimplementation to the limit of adaptability and re-liability.6 ConclusionWe have applied the sound software engineeringprinciples and design to the implementation of theMoses decoder which has enabled other research-ers to use and extend its functionality.
We believethis has been a major factor for the widespreadadoption of Moses within the SMT community.We hope that the design of the decoder will enableit to maintain it leading edge status into the future.AcknowledgementsThis work was supported in part under theGALE program of the  Defense Advanced Re-search Projects Agency, Contract No.
HR0011-06-C-0022 and in part under the EuroMatrix projectfunded by the European Commission (6th Frame-work Programme.ReferencesBertoldi, N., R. Cattoni, et al (2004).
The ITC-irst Sta-tistical Machine Translation System for IWSLT-2004.IWSLT, Kyoto, Japan.Bilmes, J.
A. and K. Kirchhoff (2003).
Factored lan-guage models and Generalized Parallel Backoff.HLT/NACCL.Brown, P. F., J. Cocke, et al (1990).
"A statistical ap-proach to machine translation.
"Chiang, D. (2005).
A hierarchical phrase-based modelfor statistical machine translation.
ACL.Deng, Y., S. Kumar, et al (2006).
"Segmentation andalignment of parallel text for statistical machine transla-tion."
Natural Language Engineering.Eichelberg, M., J. Riesmeier, et al (2004).
"Ten years ofmedical imaging standardization and prototypical im-plementation: the DICOM standard and the OFFIS DI-COM toolkit (DCMTK)."
Medical Imaging 2004:PACS and Imaging Informatics 5371: 57-68 (2004).Fabri, A., G.-J.
Giezeman, et al (2000).
"On the Designof CGAL, a Computational Geometry Algorithms Li-64brary."
Software?Practice & Experience 30(11,  Spe-cial issue on discrete algorithm engineering).Koehn, P. (2004).
Pharaoh: a Beam Search Decoder forPhrase-Based Statistical Machine Translation Models.AMTA.Koehn, P., M. Federico, et al (2006).
Open SourceToolkit for Statistical Machine Translation.
Report ofthe 2006 Summer Workshop at Johns Hopkins Univer-sity.Koehn, P. and H. Hoang (2007).
Factored TranslationModels.
EMNLP.Kumar, S. and W. Byrne (2003).
A weighted finite statetransducer implementation of the alignment templatemodel for statistical machine translation.
ACL, Edmon-ton, Canada.Liang, P., A.
Bouchard-C?t?, et al (2006).
An End-to-End Discriminative Approach to Machine Translation.COLING/ACL.Och, F. J.
(2003).
Minimum Error Rate Training forStatistical Machine Translation.
ACL.Och, F. J. and H. Ney (2003).
"A Systematic Compari-son of Various Statistical Alignment Models."
Compu-tational Linguistics 29(1): 19-51.Och, F. J. and H. Ney (2004).
"The alignment templateapproach to statistical machine translation."
Computa-tional Linguistics.Olteanu, M., C. Davis, et al (2006).
Phramer - An OpenSource Statistical Phrase-Based Translator.
ACL Work-shop on Statistical Machine Translation.Patry, A., F. Gotti, et al (2006).
Mood at work: Ramsesversus Pharaoh.
ACL, New York City, USA.Sadat, F., H. Johnson, et al (2005).
PORTAGE: APhrase-based Machine Translation System.
ACL Work-shop on Building and Using Parallel Texts: Data-DrivenMachine Translation and Beyond, Ann Arbor, Michigan,USA.Shen, W., B. Delaney, et al (2005).
The MITLL/AFRLMT System.
IWSLT, Pittsburgh, PA, USA.Shen, Y., C.-k.
Lo, et al (2007).
HKUST StatisticalMachine Translation Experiments for IWSLT 2007.IWSLT, Trento.Stolcke, A.
(2002).
SRILM An Extensible LanguageModeling Toolkit.
Intl.
Conf.
on Spoken LanguageProcessing.Talbot, D. and M. Osborne (2007).
Smoothed Bloomfilter language models: Tera-Scale LMs on the Cheap.EMNLP, Prague, Czech Republic.Wang, Z., J. Shawe-Taylor, et al (2007).
Kernel Re-gression Based Machine Translation.
NAACL HLT.Zens, R. and H. Ney (2007).
Efficient phrase-table rep-resentation for machine translation with applications toonline MT and speech recognition.
HLT/NAACL.65
