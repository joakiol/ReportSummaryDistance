Proceedings of the ACL 2010 Conference Short Papers, pages 17?21,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsFiltering Syntactic Constraints for Statistical Machine TranslationHailong Cao and Eiichiro SumitaLanguage Translation Group, MASTAR ProjectNational Institute of Information and Communications Technology3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan, 619-0289{hlcao, eiichiro.sumita }@nict.go.jpAbstractSource language parse trees offer very usefulbut imperfect reordering constraints for statis-tical machine translation.
A lot of effort hasbeen made for soft applications of syntacticconstraints.
We alternatively propose the se-lective use of syntactic constraints.
A classifieris built automatically to decide whether a nodein the parse trees should be used as a reorder-ing constraint or not.
Using this informationyields a 0.8 BLEU point improvement over afull constraint-based system.1 IntroductionIn statistical machine translation (SMT), thesearch problem is NP-hard if arbitrary reorderingis allowed (Knight, 1999).
Therefore, we need torestrict the possible reordering in an appropriateway for both efficiency and translation quality.The most widely used reordering constraints areIBM constraints (Berger et al, 1996), ITG con-straints (Wu, 1995) and syntactic constraints(Yamada et al, 2000; Galley et al, 2004; Liu etal., 2006; Marcu et al, 2006; Zollmann andVenugopal 2006; and numerous others).
Syntac-tic constraints can be imposed from the sourceside or target side.
This work will focus on syn-tactic constraints from source parse trees.Linguistic parse trees can provide very usefulreordering constraints for SMT.
However, theyare far from perfect because of both parsing er-rors and the crossing of the constituents and for-mal phrases extracted from parallel training data.The key challenge is how to take advantage ofthe prior knowledge in the linguistic parse treeswithout affecting the strengths of formal phrases.Recent efforts attack this problem by using theconstraints softly (Cherry, 2008; Marton andResnik, 2008).
In their methods, a candidatetranslation gets an extra credit if it respects theparse tree but may incur a cost if it violates aconstituent boundary.In this paper, we address this challenge from aless explored direction.
Rather than use all con-straints offered by the parse trees, we proposeusing them selectively.
Based on parallel trainingdata, a classifier is built automatically to decidewhether a node in the parse trees should be usedas a reordering constraint or not.
As a result, weobtain a 0.8 BLEU point improvement over a fullconstraint-based system.2 Reordering Constraints from SourceParse TreesIn this section we briefly review a constraint-based system named IST-ITG (Imposing SourceTree on Inversion Transduction Grammar, Ya-mamoto et al, 2008) upon which this workbuilds.When using ITG constraints during decoding,the source-side parse tree structure is not consid-ered.
The reordering process can be more tightlyconstrained if constraints from the source parsetree are integrated with the ITG constraints.
IST-ITG constraints directly apply source sentencetree structure to generate the target with thefollowing constraint: the target sentence is ob-tained by rotating any node of the source sen-tence tree structure.After parsing the source sentence, a bracketedsentence is obtained by removing the nodesyntactic labels; this bracketed sentence can thenbe directly expressed as a tree structure.
Forexample1, the parse tree ?
(S1 (S (NP (DT This))(VP (AUX is) (NP (DT a) (NN pen)))))?
isobtained from the source sentence ?This is apen?, which consists of four words.
By removing1 We use English examples for the sake of readability.17the node syntactic labels, the bracketed sentence?
((This) ((is) ((a) (pen))))?
is obtained.
Such abracketed sentence can be used to produceconstraints.For example, for the source-side bracketedtree ?
((f1 f2) (f3 f4)) ?, eight target sequences [e1,e2, e3, e4], [e2, e1, e3, e4], [e1, e2, e4, e3], [e2,e1, e4, e3], [e3, e4, e1, e2], [e3, e4, e2, e1], [e4,e3, e1, e2], and [e4, e3, e2, e1] are possible.
Forthe source-side bracketed tree ?
(((f1f2) f3) f4),?eight sequences [e1, e2, e3, e4], [e2, e1, e3, e4],[e3, e1, e2, e4], [e3, e2, e1, e4], [e4, e1, e2, e3],[e4, e2, e1, e3], [e4, e3, e1, e2], and [e4, e3, e2,e1] are possible.
When the source sentence treestructure is a binary tree, the number of wordorderings is reduced to 2N-1 where N is the lengthof the source sentence.The parsing results sometimes do not producebinary trees.
In this case, some subtrees havemore than two child nodes.
For a non-binary sub-tree, any reordering of child nodes is allowed.For example, if a subtree has three child nodes,six reorderings of the nodes are possible.3 Learning to Classify Parse TreeNodesIn IST-ITG and many other methods which usesyntactic constraints, all of the nodes in the parsetrees are utilized.
Though many nodes in theparse trees are useful, we would argue that somenodes are not trustworthy.
For example, if weconstrain the translation of ?f1 f2 f3 f4?
withnode N2 illustrated in Figure 1, then word ?e1?will never be put in the middle the other threewords.
If we want to obtain the translation ?e2 e1e4 e3?, node N3 can offer a good constraintwhile node N2 should be filtered out.
In real cor-pora, cases such as node N2 are frequent enoughto be noticeable (see Fox (2002) or section 4.1 inthis paper).Therefore, we use the definitions in Galley etal.
(2004) to classify the nodes in parse trees intotwo types: frontier nodes and interior nodes.Though the definitions were originally made fortarget language parse trees, they can be straight-forwardly applied to the source side.
A nodewhich satisfies both of the following two condi-tions is referred as a frontier node:?
All the words covered by the node can betranslated separately.
That is to say, thesewords do not share a translation with anyword outside the coverage of the node.?
All the words covered by the node remaincontiguous after translation.Otherwise the node is an interior node.For example, in Figure 1, both node N1 andnode N3 are frontier nodes.
Node N2 is an inte-rior node because the source words f2, f3 and f4are translated into e2, e3 and e4, which are notcontiguous in the target side.Clearly, only frontier nodes should be used asreordering constraints while interior nodes arenot suitable for this.
However, little work hasbeen done on how to explicitly distinguish thesetwo kinds of nodes in the source parse trees.
Inthis section, we will explore building a classifierwhich can label the nodes in the parse trees asfrontier nodes or interior nodes.Figure 1: An example parse tree and align-ments3.1 TrainingIdeally, we would have a human-annotated cor-pus in which each sentence is parsed and eachnode in the parse trees is labeled as a frontiernode or an interior node.
But such a target lan-guage specific corpus is hard to come by, andnever in the quantity we would like.Instead, we generate such a corpus automati-cally.
We begin with a parallel corpus which willbe used to train our SMT model.
In our case, it isthe FBIS Chinese-English corpus.Firstly, the Chinese sentences are segmented,POS tagged and parsed by the tools described inKruengkrai et al (2009) and Cao et al (2007),both of which are trained on the Penn ChineseTreebank 6.0.Secondly, we use GIZA++ to align the sen-tences in both the Chinese-English and English-Chinese directions.
We combine the alignmentsusing the ?grow-diag-final-and?
procedure pro-vided with MOSES (Koehn, 2007).
Becausethere are many errors in the alignment, we re-move the links if the alignment count is less thanthree for the source or the target word.
Addition-ally, we also remove notoriously bad links inf1        f2      f3   f4e2       e1      e4   e3N3N2N118{de, le} ?
{the, a, an} following Fossum andKnight (2008).Thirdly, given the parse trees and the align-ment information, we label each node as a fron-tier node or an interior node according to thedefinition introduced in this section.
Using thelabeled nodes as training data, we can build aclassifier.
In theory, a broad class of machinelearning tools can be used; however, due to thescale of the task (see section 4), we utilize thePegasos 2  which is a very fast SVM solver(Shalev-Shwartz et al 2007).3.2 FeaturesFor each node in the parse trees, we use the fol-lowing feature templates:?
A context-free grammar rule which rewritesthe current node (In this and all the followinggrammar based features, a mark is used toindicate which non terminal is the currentnode.)?
A context-free grammar rule which rewritesthe current node?s father?
The combination of the above two rules?
A lexicalized context-free grammar rulewhich rewrites the current node?
A lexicalized context-free grammar rulewhich rewrites the current node?s father?
Syntactic label, head word, and head POStag of the current node?
Syntactic label, head word, and head POStag of the current node?s left child?
Syntactic label, head word, and head POStag of the current node?s right child?
Syntactic label, head word, and head POStag of the current node?s left brother?
Syntactic label, head word, and head POStag of the current node?s right brother?
Syntactic label, head word, and head POStag of the current node?s father?
The leftmost word covered by the currentnode and the word before it?
The rightmost word covered by the currentnode and the word after it4 ExperimentsOur SMT system is based on a fairly typicalphrase-based model (Finch and Sumita, 2008).For the training of our SMT model, we use amodified training toolkit adapted from the2 http://www.cs.huji.ac.il/~shais/code/index.htmlMOSES decoder.
Our decoder can operate on thesame principles as the MOSES decoder.
Mini-mum error rate training (MERT) with respect toBLEU score is used to tune the decoder?s pa-rameters, and it is performed using the standardtechnique of Och (2003).
A lexical reorderingmodel was used in our experiments.The translation model was created from theFBIS corpus.
We used a 5-gram language modeltrained with modified Knesser-Ney smoothing.The language model was trained on the targetside of FBIS corpus and the Xinhua news in GI-GAWORD corpus.
The development and testsets are from NIST MT08 evaluation campaign.Table 1 shows the statistics of the corpora usedin our experiments.Data Sentences ChinesewordsEnglishwordsTraining set 243,698 7,933,133 10,343,140Development set 1664 38,779 46,387Test set 1357 32377 42,444GIGAWORD 19,049,757 - 306,221,306Table 1: Corpora statistics4.1 Experiments on Nodes ClassificationWe extracted about 3.9 million example nodesfrom the training data, i.e.
the FBIS corpus.There were 2.37 million frontier nodes and 1.59million interior nodes in these examples, giverise to about 4.4 million features.
To test the per-formance of our classifier, we simply use the lastten thousand examples as a test set, and the restbeing used as Pegasos training data.
All the pa-rameters in Pegasos were set as default values.
Inthis way, the accuracy of the classifier was71.59%.Then we retrained our classifier by using all ofthe examples.
The nodes in the automaticallyparsed NIST MT08 test set were labeled by theclassifier.
As a result, 17,240 nodes were labeledas frontier nodes and 5,736 nodes were labeledas interior nodes.4.2 Experiments on Chinese-English SMTIn order to confirm that it is advantageous to dis-tinguish between frontier nodes and interiornodes, we performed four translation experi-ments.The first one was a typical beam search decod-ing without any syntactic constraints.All the other three experiments were based onthe IST-ITG method which makes use of syntac-19tic constraints.
The difference between thesethree experiments lies in what constraints areused.
In detail, the second one used all nodesrecognized by the parser; the third one only usedfrontier nodes labeled by the classifier; the fourthone only used interior nodes labeled by the clas-sifier.With the exception of the above differences,all the other settings were the same in the fourexperiments.
Table 2 summarizes the SMT per-formance.Syntactic Constraints BLEUnone 17.26all nodes 16.83frontier nodes 17.63interior nodes 16.59Table 2: Comparison of different constraints bySMT qualityClearly, we obtain the best performance if weconstrain the search with only frontier nodes.Using just frontier yields a 0.8 BLEU point im-provement over the baseline constraint-basedsystem which uses all the constraints.On the other hand, constraints from interiornodes result in the worst performance.
This com-parison shows it is necessary to explicitly distin-guish nodes in the source parse trees when theyare used as reordering constraints.The improvement over the system withoutconstraints is only modest.
It may be too coarseto use pare trees as hard constraints.
We believea greater improvement can be expected if we ap-ply our idea to finer-grained approaches that useconstraints softly (Marton and Resnik (2008) andCherry (2008)).5 Conclusion and Future WorkWe propose a selectively approach to syntacticconstraints during decoding.
A classifier is builtautomatically to decide whether a node in theparse trees should be used as a reordering con-straint or not.
Preliminary results show that it isnot only advantageous but necessary to explicitlydistinguish between frontier nodes and interiornodes.The idea of selecting syntactic constraints iscompatible with the idea of using constraintssoftly; we plan to combine the two ideas and ob-tain further improvements in future work.AcknowledgmentsWe would like to thank Taro Watanabe andAndrew Finch for insightful discussions.
We alsowould like to thank the anonymous reviewers fortheir constructive comments.ReferenceA.L.
Berger, P.F.
Brown, S.A.D.
Pietra, V.J.D.
Pietra,J.R.
Gillett, A.S. Kehler, and R.L.
Mercer.
1996.Language translation apparatus and method of us-ing context-based translation models.
United Statespatent, patent number 5510981, April.Hailong Cao, Yujie Zhang and Hitoshi Isahara.
Em-pirical study on parsing Chinese based on Collins'model.
2007.
In PACLING.Colin Cherry.
2008.
Cohesive phrase-Based decodingfor statistical machine translation.
In ACL- HLT.Andrew Finch and Eiichiro Sumita.
2008.
Dynamicmodel interpolation for statistical machine transla-tion.
In SMT Workshop.Victoria Fossum and Kevin Knight.
2008.
Using bi-lingual Chinese-English word alignments to re-solve PP attachment ambiguity in English.
InAMTA Student Workshop.Heidi J.
Fox.
2002.
Phrasal cohesion and statisticalmachine translation.
In EMNLP.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What's in a translation rule?In HLT-NAACL.Kevin Knight.
1999.
Decoding complexity in wordreplacement translation models.
ComputationalLinguistics, 25(4):607?615.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Ber-toldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, Evan Herbst.
2007.
Moses:Open Source Toolkit for Statistical Machine Trans-lation.
In ACL demo and poster sessions.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun'ichiKazama, Yiou Wang, Kentaro Torisawa and Hito-shi Isahara.
2009.
An error-driven word-characterhybrid model for joint Chinese word segmentationand POS tagging.
In ACL-IJCNLP.Yang Liu, Qun Liu, Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machinetranslation.
In ACL-COLING.Daniel Marcu, Wei Wang, Abdessamad Echihabi, andKevin Knight.
2006.
SPMT: Statistical machinetranslation with syntactified target languagephrases.
In EMNLP.20Yuval Marton and Philip Resnik.
2008.
Soft syntacticconstraints for hierarchical phrased-based transla-tion.
In ACL-HLT.Franz Och.
2003.
Minimum error rate training in sta-tistical machine translation.
In ACL.Shai Shalev-Shwartz, Yoram Singer and Nathan Sre-bro.
2007.
Pegasos: Primal estimated sub-gradientsolver for SVM.
In ICML.Dekai Wu.
1995.
Stochastic inversion transductiongrammars with application to segmentation, brack-eting, and alignment of parallel corpora.
In IJCAI.Kenji Yamada and Kevin Knight.
2000.
A syntax-based statistical translation model.
In ACL.Hirofumi Yamamoto, Hideo Okuma and EiichiroSumita.
2008.
Imposing constraints from thesource tree on ITG constraints for SMT.
In Work-shop on syntax and structure in statistical transla-tion.Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax augmented machine translation via chart pars-ing.
In SMT Workshop, HLT-NAACL.21
