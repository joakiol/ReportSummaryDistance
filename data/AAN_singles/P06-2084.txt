Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 651?658,Sydney, July 2006. c?2006 Association for Computational LinguisticsCombining Association Measures for Collocation ExtractionPavel Pecina and Pavel SchlesingerInstitute of Formal and Applied LinguisticsCharles University, Prague, Czech Republic{pecina,schlesinger}@ufal.mff.cuni.czAbstractWe introduce the possibility of combininglexical association measures and presentempirical results of several methods em-ployed in automatic collocation extrac-tion.
First, we present a comprehensivesummary overview of association mea-sures and their performance on manu-ally annotated data evaluated by precision--recall graphs and mean average precision.Second, we describe several classificationmethods for combining association mea-sures, followed by their evaluation andcomparison with individual measures.
Fi-nally, we propose a feature selection algo-rithm significantly reducing the number ofcombined measures with only a small per-formance degradation.1 IntroductionLexical association measures are mathematicalformulas determining the strength of associationbetween two or more words based on their occur-rences and cooccurrences in a text corpus.
Theyhave a wide spectrum of applications in the fieldof natural language processing and computationallinguistics such as automatic collocation extrac-tion (Manning and Sch?tze, 1999), bilingual wordalignment (Mihalcea and Pedersen, 2003) or de-pendency parsing.
A number of various associa-tion measures were introduced in the last decades.An overview of the most widely used techniquesis given e.g.
in Manning and Sch?tze (1999) orPearce (2002).
Several researchers also attemptedto compare existing methods and suggest differ-ent evaluation schemes, e.g Kita (1994) and Evert(2001).
A comprehensive study of statistical as-pects of word cooccurrences can be found in Evert(2004) or Krenn (2000).In this paper we present a novel approach to au-tomatic collocation extraction based on combin-ing multiple lexical association measures.
We alsoaddress the issue of the evaluation of associationmeasures by precision-recall graphs and mean av-erage precision scores.
Finally, we propose a step-wise feature selection algorithm that reduces thenumber of combined measures needed with re-spect to performance on held-out data.The term collocation has both linguistic andlexicographic character.
It has various definitionsbut none of them is widely accepted.
We adoptthe definition from Choueka (1988) who definesa collocational expression as ?a syntactic and se-mantic unit whose exact and unambiguous mean-ing or connotation cannot be derived directly fromthe meaning or connotation of its components?.This notion of collocation is relatively wide andcovers a broad range of lexical phenomena such asidioms, phrasal verbs, light verb compounds, tech-nological expressions, proper names, and stockphrases.
Our motivation originates from machinetranslation: we want to capture all phenomena thatmay require special treatment in translation.Experiments presented in this paper were per-formed on Czech data and our attention was re-stricted to two-word (bigram) collocations ?
pri-marily for the limited scalability of some meth-ods to higher-order n-grams and also for the rea-son that experiments with longer word expressionswould require processing of much larger corpus toobtain enough evidence of the observed events.2 Reference dataThe first step in our work was to create a refer-ence data set.
Krenn (2000) suggests that col-location extraction methods should be evaluatedagainst a reference set of collocations manuallyextracted from the full candidate data from a cor-pus.
To avoid the experiments to be biased byunderlying data preprocessing (part-of-speech tag-ging, lemmatization, and parsing), we extractedthe reference data from morphologically and syn-tactically annotated Prague Dependency Treebank2.0 containing about 1.5 million words annotatedon analytical layer (PDT 2.0, 2006).
A corpus ofthis size is certainly not sufficient for real-worldapplications but we found it adequate for our eval-uation purposes ?
a larger corpus would have madethe manual collocation extraction task infeasible.651Dependency trees from the corpus were brokendown into dependency bigrams consisting of lem-mas of the head word and its modifier, their part--of-speech pattern, and dependency type.
From87 980 sentences containing 1 504 847 words, weobtained a total of 635 952 different dependencybigrams types.
Only 26 450 of them occur in thedata more than five times.
The less frequent bi-grams do not meet the requirement of sufficientevidence of observations needed by some meth-ods used in this work (they assume normal dis-tribution of observations and become unreliablewhen dealing with rare events) and were not in-cluded in the evaluation.
We, however, mustagree with Moore (2004) arguing that these casescomprise majority of all the data (the Zipfianphenomenon) and thus should not be excludedfrom real-world applications.
Finally, we filteredout all bigrams having such part-of-speech pat-terns that never form a collocation (conjunction?preposition, preposition?pronoun, etc.)
and ob-tained a list consisting of 12 232 dependency bi-grams, further called collocation candidates.2.1 Manual annotationThe list of collocation candidates was manuallyprocessed by three trained linguists in parallel andindependently with the aim of identifying colloca-tions as defined by Choueka.
To simplify and clar-ify the work they were instructed to select thosebigrams that can be assigned to these categories:?
idiomatic expressions- studen?
v?lka (cold war)- vis?
otazn?k (question mark is hanging?
open question)?
technical terms- pr?edseda vl?dy (prime minister)- oc?it?
sve?dek (eye witness)?
support verb constructions- m?t pravdu (to be right)- uc?init rozhodnut?
(make decision)?
names of persons, locations, and other entities- Pra?sk?
hrad (Prague Castle)- C?erven?
kr???
(Red Cross)?
stock phrases- z?sadn?
probl?m (major problem)- konec roku (end of the year)The first (expected) observation was that the in-terannotator agreement among all the categorieswas rather poor: the Cohen?s ?
between annota-tors ranged from 0.29 to 0.49, which demonstratesthat the notion of collocation is very subjective,domain-specific, and somewhat vague.
The reasonthat three annotators were used was to get a moreprecise and objective idea about what can be con-sidered a collocation by combining outcomes frommultiple annotators.
Only those bigrams that allthree annotators independently recognized as col-locations (of any type) were considered true collo-cations.
The reference data set contains 2 557 suchbigrams, which is 20.9% of all.
?
between thesetwo categories reanged from 0.52 to 0.58.The data was split into six stratified samples.Five folds were used for five-fold cross validationand average performance estimation.
The remain-ing one fold was put aside and used as held-outdata in experiments described in Section 5.3 Association measuresIn the context of collocation extraction, lexical as-sociation measures are formulas determining thedegree of association between collocation com-ponents.
They compute an association score foreach collocation candidate extracted from a cor-pus.
The scores indicate the potential for a can-didate to be a collocation.
They can be used forranking (candidates with high scores at the top),or for classification (by setting a threshold and dis-carding all bigrams below this threshold).If some words occur together more often thanby chance, then this may be evidence that theyhave a special function that is not simply explainedas a result of their combination (Manning andSch?tze, 1999).
This property is known in linguis-tics as non-compositionality.
We think of a cor-pus as a randomly generated sequence of wordsthat is viewed as a sequence of word pairs (de-pendency bigrams in our case).
Occurrence fre-quencies and marginal frequencies are used in sev-eral association measures that reflect how muchthe word cooccurrence is accidental.
Such mea-sures include: estimation of joint and conditionalbigram probabilities (Table 1, 1?3), mutual infor-mation and derived measures (4?9), statistical testsof independence (10?14), likelihood measures (15?16), and various other heuristic association mea-sures and coefficients (17?55) originating in differ-ent research fields.By determining the entropy of the immediatecontext of a word sequence (words immediatelypreceding or following the bigram), the associa-tion measures (56?60) rank collocations accordingto the assumption that they occur as (syntactic)units in a (information-theoretically) noisy envi-ronment (Shimohata et al, 1997).
By comparingempirical contexts of a word sequence and of itscomponents (open-class words occurring within652# Name Formula1.
Joint probability P (xy)?2.
Conditional probability P (y|x)3.
Reverse conditional prob.
P (x|y)4.
Pointwise mutual inform.
log P (xy)P (x?
)P (?y)5.
Mutual dependency (MD) log P (xy)2P (x?
)P (?y)6.
Log frequency biased MD log P (xy)2P (x?
)P (?y)+logP (xy)7.
Normalized expectation 2f(xy)f(x?)+f(?y)8.
Mutual expectation 2f(xy)f(x?
)+f(?y) ?P (xy)?9.
Salience log P (xy)2P (x?
)P (?y) ?
logf(xy)10.
Pearson?s ?2 test Pi,j(fij?f?ij)2f?ij11.
Fisher?s exact test f(x?)!f(x??)!f(?y)!f(?y?)!N!f(xy)!f(xy?)!f(x?y)!f(x?y?
)!12.t test f(xy)?f?(xy)?f(xy)(1?
(f(xy)/N))13.z score f(xy)?f?(xy)?f?(xy)(1?(f?(xy)/N))14.
Poison significance measure f?
(xy)?f(xy) logf?(xy)+logf(xy)!logN15.
Log likelihood ratio ?2Pi,jfij logfijf?ij16.
Squared log likelihood ratio ?2Pi,jlogfij2f?ijAssociation coefficients:17.
Russel-Rao aa+b+c+d18.
Sokal-Michiner a+da+b+c+d19.
Rogers-Tanimoto a+da+2b+2c+d20.
Hamann (a+d)?(b+c)a+b+c+d21.
Third Sokal-Sneath b+ca+d22.
Jaccard aa+b+c?23.
First Kulczynsky ab+c24.
Second Sokal-Sneath aa+2(b+c)25.
Second Kulczynski 12 ( aa+b+ aa+c )?26.
Fourth Sokal-Sneath 14 ( aa+b+ aa+c+ dd+b+ dd+c )?27.
Odds ratio adbc28.
Yulle?s ??ad??bc?ad+?bc29.
Yulle?s Q ad?bcad+bc30.
Driver-Kroeber a?(a+b)(a+c)31.
Fifth Sokal-Sneath ad?(a+b)(a+c)(d+b)(d+c)32.
Pearson ad?bc?(a+b)(a+c)(d+b)(d+c)33.
Baroni-Urbani a+?ada+b+c+?ad?34.
Braun-Blanquet amax(a+b,a+c)?35.
Simpson amin(a+b,a+c)36.
Michael 4(ad?bc)(a+d)2+(b+c)237.
Mountford 2a2bc+ab+ac38.
Fager a?
(a+b)(a+c)?12max(b, c)39.
Unigram subtuples log adbc?3.29q1a+ 1b + 1c + 1d40.
U cost log(1+ min(b,c)+amax(b,c)+a )41.
S cost log(1+min(b,c)a+1 )?1242.
R cost log(1+ aa+b )?log(1+ aa+c )43.
T combined cost ?U?S?R44.
Phi P (xy)?P (x?
)P (?y)?P (x?
)P (?y)(1?P (x?
))(1?P (?y))45.
Kappa P (xy)+P (x?y?
)?P (x?
)P (?y)?P (x??
)P (?y?
)1?P (x?
)P (?y)?P (x??
)P (?y?)46.
J measure max[P (xy)logP (y|x)P (?y) +P (xy?
)logP (y?|x)P (?y?)
,P (xy)logP (x|y)P (x?)
+P (x?y)logP (x?|y)P (x??)
]# Name Formula47.
Gini index max[P (x?
)(P (y|x)2+P (y?|x)2)?P (?y)2+P (x??
)(P (y|x?
)2+P (y?|x?
)2)?P (?y?
)2,P (?y)(P (x|y)2+P (x?|y)2)?P (x?
)2+P (?y?
)(P (x|y?
)2+P (x?|y?
)2)?P (x??)2]48.
Confidence max[P (y|x), P (x|y)]49.
Laplace max[NP (xy)+1NP (x?
)+2 ,NP (xy)+1NP (?y)+2 ]50.
Conviction max[P (x?
)P (?y)P (xy?)
,P (x??
)P (?y)P (x?y) ]51.
Piatersky-Shapiro P (xy)?P (x?
)P (?y)52.
Certainity factor max[P (y|x)?P (?y)1?P (?y) ,P (x|y)?P (x?
)1?P (x?)
]53.
Added value (AV) max[P (y|x)?P (?y), P (x|y)?P (x?)]54.
Collective strength P (xy)+P (x?y?
)P (x?
)P (y)+P (x??
)P (?y) ?1?P (x?
)P (?y)?P (x??
)P (?y)1?P (xy)?P (x?y?)?55.
Klosgen pP (xy) ?AVContext measures:?56.
Context entropy ?Pw P (w|Cxy) logP (w|Cxy)?57.
Left context entropy ?Pw P (w|Clxy) logP (w|Clxy)58.
Right context entropy ?Pw P (w|Crxy) logP (w|Crxy)59.
Left context divergence P (x?)
logP (x?
)?PwP (w|Clxy) logP (w|Clxy)60.
Right context divergence P (?y) logP (?y)?PwP (w|Crxy) logP (w|Crxy)61.
Cross entropy ?PwP (w|Cx) logP (w|Cy)62.
Reverse cross entropy ?PwP (w|Cy) logP (w|Cx)63.
Intersection measure 2|Cx?Cy||Cx|+|Cy|?64.
Euclidean normqPw(P (w|Cx)?P (w|Cy))265.
Cosine normPw P (w|Cx)P (w|Cy)Pw P (w|Cx)2?Pw P (w|Cy)2?66.
L1 norm Pw |P (w|Cx)?P (w|Cy)|67.
Confusion probability Pw P (x|Cw)P (y|Cw)P (w)P (x?)?68.
Reverse confusion prob.
Pw P (y|Cw)P (x|Cw)P (w)P (?y)?69.
Jensen-Shannon diverg.
12 [D(p(w|Cx)|| 12 (p(w|Cx)+p(w|Cy)))+D(p(w|Cy)|| 12 (p(w|Cx)+p(w|Cy)))]?70.
Cosine of pointwise MIPw MI(w,x)MI(w,y)?Pw MI(w,x)2?
?Pw MI(w,y)271.
KL divergence Pw P (w|Cx) logP (w|Cx)P (w|Cy)72.
Reverse KL divergence Pw P (w|Cy) logP (w|Cy)P (w|Cx)?73.
Skew divergence D(p(w|Cx)||?(w|Cy)+(1??)p(w|Cx))74.
Reverse skew divergence D(p(w|Cy)||?p(w|Cx)+(1??)p(w|Cy))75.
Phrase word coocurrence 12 (f(x|Cxy)f(xy) +f(y|Cxy)f(xy) )76.
Word association 12 (f(x|Cy)?f(xy)f(xy) +f(y|Cx)?f(xy)f(xy) )Cosine context similarity: 12 (cos(cx,cxy)+cos(cy,cxy))cz=(zi); cos(cx,cy)=P xiyi?P xi2?
?P yi2?77.
in boolean vector space zi=?(f(wi|Cz))78.
in tf vector space zi=f(wi|Cz)79. in tf?idf vector space zi=f(wi|Cz)?
Ndf(wi); df(wi)= |{x :wi?Cx}|Dice context similarity: 12 (dice(cx,cxy)+dice(cy ,cxy))cz=(zi); dice(cx,cy)=2P xiyiP xi2+P yi280.
in boolean vector space zi=?(f(wi|Cz))81.
in tf vector space zi=f(wi|Cz)82. in tf?idf vector space zi=f(wi|Cz)?
Ndf(wi); df(wi)= |{x :wi?Cx}|a=f(xy) b=f(xy?)
f(x?
)c=f(x?y) d=f(x?y?)
f(x??
)f(?y) f(?y?)
NA contingency table contains observed frequencies and marginal frequencies for a bigramxy; w?
stands for any word except w; ?
stands for any word; N is a total number of bi-grams.
The table cells are sometimes referred to as fij .
Statistical tests of independencework with contingency tables of expected frequenciesf?(xy)=f(x?
)f(?y)/N .Cw empirical context of wCxy empirical context of xyClxy left immediate context of xyCrxy right immediate context of xyTable 1: Lexical association measures used for bigram collocation extraction.
?denotes those selected by the model reduction algorithm discussed in Section 5.653RecallPrecision0.0 0.2 0.4 0.6 0.8 1.00.20.40.60.81.0Unaveraged precision curveAveraged precison curveFigure 1: Vertical averaging of precision-recall curves.
Thincurves represent individual non-averaged curves obtained byPointwise mutual information (4) on five data folds.a specified context window), the association mea-sures rank collocations according to the assump-tion that semantically non-compositional expres-sions typically occur as (semantic) units in differ-ent contexts than their components (Zhai, 1997).Measures (61?74) have information theory back-ground and measures (75?82) are adopted from thefield of information retrieval.3.1 EvaluationCollocation extraction can be viewed as classifi-cation into two categories.
By setting a threshold,any association measure becomes a binary clas-sifier: bigrams with higher association scores fallinto one class (collocations), the rest into the otherclass (non-collocations).
Performance of suchclassifiers can be measured for example by accu-racy ?
fraction of correct predictions.
However,the proportion of the two classes in our case is farfrom equal and we want to distinguish classifierperformance between them.
In this case, severalauthors, e.g.
Evert (2001), suggest using precision?
fraction of positive predictions correct and re-call ?
fraction of positives correctly predicted.
Thehigher the scores the better the classification is.3.2 Precision-recall curvesSince choosing a classification threshold dependsprimarily on the intended application and there isno principled way of finding it (Inkpen and Hirst,2002), we can measure performance of associa-tion measures by precision?recall scores withinthe entire interval of possible threshold values.
Inthis manner, individual association measures canbe thoroughly compared by their two-dimensionalprecision-recall curves visualizing the quality ofranking without committing to a classificationthreshold.
The closer the curve stays to the topand right, the better the ranking procedure is.RecallAverageprecision0.0 0.2 0.4 0.6 0.8 1.00.20.40.60.81.0Pointwise mutual information (4)Pearson?s test (10)z score (13)Cosine context similarity in boolean vector space (77)Unigram subtuple measure (39)Figure 2: Crossvalidated and averaged precision-recallcurves of selected association measures (numbers in brack-ets refer to Table 1).Precision-recall curves are very sensitive to data(see Figure 1).
In order to obtain a good esti-mate of their shapes cross validation and averag-ing are necessary: all cross-validation folds withscores for each instance are combined and a singlecurve is drawn.
Averaging can be done in threeways: vertical ?
fixing recall, averaging precision,horizontal ?
fixing precision, averaging recall, andcombined ?
fixing threshold, averaging both preci-sion and recall (Fawcett, 2003).
Vertical averag-ing, as illustrated in Figure 1, worked reasonablywell in our case and was used in all experiments.3.3 Mean average precisionVisual comparison of precision-recall curves isa powerfull evaluation tool in many research fields(e.g.
information retrieval).
However, it has a seri-ous weakness.
One can easily compare two curvesthat never cross one another.
The curve that pre-dominates another one within the entire intervalof recall seems obviously better.
When this is notthe case, the judgment is not so obvious.
Alsosignificance tests on the curves are problematic.Only well-defined one-dimensional quality mea-sures can rank evaluated methods by their per-formance.
We adopt such a measure from in-formation retrieval (Hull, 1993).
For each cross--validation data fold we define average precision(AP) as the expected value of precision for all pos-sible values of recall (assuming uniform distribu-tion) and mean average precision (MAP) as a meanof this measure computed for each data fold.
Sig-nificance testing in this case can be realized bypaired t-test or by more appropriate nonparametricpaired Wilcoxon test.Due to the unreliable precision scores for lowrecall and their fast changes for high recall, esti-mation of AP should be limited only to some nar-rower recall interval, e.g.
?0.1,0.9?654Meanaverageprecision0.20.30.40.50.60.777 80 32 30 10 42 4 28 63 22 23 7 20 19 43 6 9 50 48 8 59 73 61 25 11 74 68 53 52 35 41 55 47 81 46 2 51 78 58 57 1739 38 31 13 5 37 27 29 16 24 45 33 21 18 34 54 76 3 82 44 66 71 26 15 14 72 70 64 49 65 69 40 75 56 12 60 36 79 62 1 67 77 38 30 5 4 29 22 45 20 18 6 76 48 44 73 26 11 72 53 49 41 40 81 12 51 79 57 6767577951128140414953721126734448766182045222945303877Figure 3: a) Mean average precision of all association measures in descending order.
Methods are referred by numbersfrom Table 1.
The solid points correspond to measures selected by the model reduction algorithm from Section 5. b) Visu-alization of p-values from the significance tests of difference between each method pair (order is the same for both graphs).
Thedarker points correspond to p-values greater than ?=0.1 and indicate methods with statistically indistinguishable performance(measured by paired Wilcoxon test on values of average precision obtained from five independent data folds).3.4 Experiments and resultsIn the initial experiments, we implemented all 82association measures from Table 1, processed allmorphologically and syntactically annotated sen-tences from PDT 2.0, and computed scores of allthe association measures for each dependency bi-gram in the reference data.
For each associa-tion measure and each of the five evaluation datafolds, we computed precision-recall scores anddrew an averaged precision-recall curve.
Curvesof some well-performing methods are depicted inFigure 2.
Next, for each association measure andeach data fold, we estimated scores of average pre-cision on narrower recall interval ?0.1,0.9?, com-puted mean average precision, ranked the asso-ciation measures according to MAP in descend-ing order, and result depicted in Figure 3 a).
Fi-nally, we applied a paired Wilcoxon test, detectedmeasures with statistically indistinguishable per-formance, and visualized this information in Fig-ure 3 b).A baseline system ranking bigrams randomlyoperates with average precision of 20.9%.
Thebest performing method for collocation extrac-tion measured by mean average precision is co-sine context similarity in boolean vector space (77)(MAP 66.49%) followed by other 16 associa-tion measures with nearly identical performance(Figure 3 a).
They include some popular meth-ods well-known to perform reliably in this task,such as pointwise mutual information (4), Pear-son?s ?2 test (10), z score (13), odds ratio (27), orsquared log likelihood ratio (16).The interesting point to note is that, in termsof MAP, context similarity measures, e.g.
(77),slightly outperform measures based on simple oc-curence frequencies, e.g.
(39).
In a more thoroughcomparison by percision-recall curves, we observethat the former very significantly predominates thelatter in the first half of the recall interval and viceversa in the second half (Figure 2).
This is a casewhere the MAP is not a sufficient metric for com-parison of association measure performance.
It isalso worth pointing out that even if two methodshave the same precision-recall curves the actual bi-gram rank order can be very different.
Existenceof such non-correlated (in terms of ranking) mea-sures will be essential in the following sections.4 Combining association measuresEach collocation candidate xi can be described bythe feature vector xi = (xi1, .
.
.
, xi82)T consistingof 82 association scores from Table 1 and assigneda label yi ?
{0, 1} which indicates whether thebigram is considered to be a collocation (y = 1)or not (y = 0).
We look for a ranker functionf(x)?R that determines the strength of lexicalassociation between components of bigram x andhence has the character of an association measure.This allows us to compare it with other associationmeasures by the same means of precision-recallcurves and mean average precision.
Further, wepresent several classification methods and demon-strate how they can be employed for ranking, i.e.what function can be used as a ranker.
For refer-ences see Venables and Ripley (2002).4.1 Linear logistic regressionAn additive model for binary response is repre-sented by a generalized linear model (GLM) ina form of logistic regression:logit(pi) = ?0 + ?1x1 + .
.
.+ ?pxp655method AP MAPR=20 R=50 R=80 R=?0.1,0.9?
+NNet (5 units) 89.56 82.74 70.11 80.81 21.53NNet (3 units) 89.41 81.99 69.64 79.71 19.88NNet (2 units) 86.92 81.68 68.33 78.77 18.47SVM (linear) 85.72 79.49 63.86 75.66 13.79LDA 84.72 77.18 62.90 75.11 12.96SVM (quadratic) 84.29 79.54 64.24 74.53 12.09NNet (1 unit) 77.98 76.83 66.75 73.25 10.17GLM 82.45 76.26 58.61 71.88 8.11Cosine similarity (77) 80.94 68.90 50.54 66.49 0.00Unigram subtuples (39) 74.55 67.49 55.16 65.74 -Table 2: Performance of methods combining all associationmeasures: average precision (AP) for fixed recall values andmean average precision (MAP) on the narrower recall intervalwith relative improvement in the last column (values in %).where logit(pi)= log(pi/(1?pi)) is a canonical linkfunction for odds-ratio and pi ?
(0, 1) is a con-ditional probability for positive response givena vector x.
The estimation of ?0 and ?
is doneby maximum likelihood method which is solvedby the iteratively reweighted least squares algo-rithm.
The ranker function in this case is definedas the predicted value ?, or equivalently (due tothe monotonicity of logit link function) as the lin-ear combination ?
?0 + ?
?Tx.4.2 Linear discriminant analysisThe basic idea of Fisher?s linear discriminant anal-ysis (LDA) is to find a one-dimensional projectiondefined by a vector c so that for the projected com-bination cTx the ratio of the between variance Bto the within variance W is maximized:maxccTBccTW cAfter projection, cTx can be directly used as ranker.4.3 Support vector machinesFor technical reason, let us now change the labelsyi?{-1,+1}.
The goal in support vector machines(SVM) is to estimate a function f(x)=?0+?Tx andfind a classifier y(x) = sign(f(x)) which can besolved through the following convex optimization:min?0,?n?i=1[1?yi(?0 + ?T xi)]++ ?2 ||?||2with ?
as a regularization parameter.
The hingeloss function L(y,f(x)) = [1?yf(x)]+ is activeonly for positive values (i.e.
bad predictions) andtherefore is very suitable for ranking models with?
?0+ ?
?Tx as a ranker function.
Setting the regu-larization parameter ?
is crucial for both the es-timators ?
?0, ??
and further classification (or rank-ing).
As an alternative to a often inappropriate gridRecallAverageprecision0.0 0.2 0.4 0.6 0.8 1.00.20.40.60.81.0Neural network (5 units)Support vector machine (linear)Linear discriminant analysisNeural network (1 unit)Linear logistic regressionCosine context similarity in boolean vector space (77)Unigram subtuple measure (39)Figure 4: Precision-recall curves of selected methods com-bining all association measures compared with curves of twobest measures employed individually on the same data sets.search, Hastie (2004) proposed an effective algo-rithm which fits the entire SVM regularization path[?0(?),?(?)]
and gave us the option to choose theoptimal value of ?.
As an objective function weused total amount of loss on training data.4.4 Neural networksAssuming the most common model of neural net-works (NNet) with one hidden layer, the aim is tofind inner weights wjh and outer weights whi foryi=?0(?0 +?whi?h(?h +?wjhxj))where h ranges over units in the hidden layer.
Ac-tivation functions ?h and function ?0 are fixed.Typically, ?h is taken to be the logistic function?h(z) = exp(z)/(1 + exp(z)) and ?0 to be theindicator function ?0(z) = I(z > ?)
with ?
asa classification threshold.
For ranking we simplyset ?0(z) = z. Parameters of neural networks areestimated by the backpropagation algorithm.
Theloss function can be based either on least squaresor maximum likehood.
To avoid problems withconvergence of the algorithm we used the formerone.
The tuning parameter of a classifier is thenthe number of units in the hidden layer.4.5 Experiments and resultsTo avoid incommensurability of association mea-sures in our experiments, we used a common pre-processing technique for multivariate standardiza-tion: we centered values of each association mea-sure towards zero and scaled them to unit variance.Precision-recall curves of all methods were ob-tained by vertical averaging in five-fold cross val-idation on the same reference data as in the ear-lier experiments.
Mean average precision wascomputed from average precision values estimated656on the recall interval ?0.1,0.9?.
In each cross--validation step, four folds were used for trainingand one fold for testing.All methods performed very well in compari-son with individual measures.
The best result wasachieved by a neural network with five units in thehidden layer with 80.81% MAP, which is 21.53%relative improvement compared to the best indi-vidual associaton measure.
More complex mod-els, such as neural networks with more than fiveunits in the hidden layer and support vector ma-chines with higher order polynomial kernels, werehighly overfitted on the training data folds and bet-ter results were achieved by simpler models.
De-tailed results of all experiment are given in Ta-ble 2 and precision-recall curves of selected meth-ods depicted in Figure 4.5 Model reductionCombining association measures by any of thepresented methods is reasonable and helps in thecollocation extraction task.
However, the combi-nation models are too complex in number of pre-dictors used.
Some association measures are verysimilar (analytically or empirically) and as predic-tors perhaps even redundant.
Such measures haveno use in the models, make their training harder,and should be excluded.
Principal componentanalysis applied to the evaluation data showed that95% of its total variance is explained by only 17principal components and 99.9% is explained by42 of them.
This gives us the idea that we shouldbe able to significantly reduce the number of vari-ables in our models with no (or relativelly small)degradation in their performance.5.1 The algorithmA straightforward, but in our case hardly feasible,approach is an exhaustive search through the spaceof all possible subsets of all association measures.Another option is a heuristic step-wise algorithmiteratively removing one variable at a time untilsome stopping criterion is met.
Such algorithmsare not very robust, they are sensitive to data andgenerally not very recommended.
However, wetried to avoid these problems by initializing ourstep-wise algorithm by clustering similar variablesand choosing one predictor from each cluster asa representative of variables with the same contri-bution to the model.
Thus we remove the highlycorelated predictors and continue with the step--wise procedure.RecallAverageprecision0.0 0.2 0.4 0.6 0.8 1.00.20.40.60.81.0NNet (5 units) with 82 predictorsNNet (5 units) with 42 predictorsNNet (5 units) with 17 predictorsNNet (5 units) with 7 predictorsCosine context similarity in boolean vector space (77)Unigram subtuple measure (39)Figure 5: Precision-recall curves of four NNet models fromthe model reduction process with different number of predic-tors compared with curves of two best individual methods.The algorithm starts with the hierarchical clus-tering of variables in order to group those witha similar contribution to the model, measured bythe absolute value of Pearson?s correlation coeffi-cient.
After 82?d iterations, variables are groupedinto d non-empty clusters and one representativefrom each cluster is selected as a predictor into theinitial model.
This selection is based on individualpredictor performance on held-out data.Then, the algorithm continues with d predictorsin the initial model and in each iteration removesa predictor causing minimal degradation of perfor-mance measured by MAP on held-out data.
Thealgorithm stops when the difference becomes sig-nificant ?
either statistically (by paired Wilcoxontest) or practically (set by a human).5.2 Experiments and resultsWe performed the model reduction experiment onthe neural network with five units in the hiddenlayer (the best performing combination method).The similarity matrix for hierarchical clusteringwas computed on the held-out data and parame-ter d (number of initial predictors) was experimen-tally set to 60.
In each iteration of the algorithm,we used four data folds (out of the five used in pre-vious experiments) for fitting the models and theheld-out fold to measure the performance of thesemodels and to select the variable to be removed.The new model was cross-validated on the samefive data-folds as in the previous experiments.Precision-recall curves for some intermediatemodels are shown in Figure 5.
We can concludethat we were able to reduce the NNet model toabout 17 predictors without statistically signifi-cant difference in performance.
The correspond-ing association measures are marked in Table 1and highlighted in Figure 3a).
They include mea-sures from the entire range of individual mean av-erage precision values.6576 Conclusions and discussionWe created and manually annotated a referencedata set consisting of 12 232 Czech dependencybigrams.
20.9% of them were agreed to be a col-location by three annotators.
We implemented 82association measures, employed them for collo-cation extraction and evaluated them against thereference data set by averaged precision-recallcurves and mean average precision in five-foldcross validation.
The best result was achieved bya method measuring cosine context similarity inboolean vector space with mean average precisionof 66.49%.We exploit the fact that different subgroups ofcollocations have different sensitivity to certainassociation measures and showed that combiningthese measures aids in collocation extraction.
Allinvestigated methods significantly outperformedindividual association measures.
The best resultswere achieved by a simple neural network withfive units in the hidden layer.
Its mean averageprecision was 80.81% which is 21.53% relativeimprovement with respect to the best individualmeasure.
Using more complex neural networks ora quadratic separator in support vector machinesled to overtraining and did not improve the perfor-mace on test data.We proposed a stepwise feature selection algo-rithm reducing the number of predictors in com-bination models and tested it with the neural net-work.
We were able to reduce the number of itsvariables from 82 to 17 without significant degra-dation of its performance.No attempt in our work has been made to selectthe ?best universal method?
for combining associ-ation measures nor to elicit the ?best associationmeasures?
for collocation extraction.
These tasksdepend heavily on data, language, and notion ofcollocation itself.
We demonstrated that combin-ing association measures is meaningful and im-proves precission and recall of the extraction pro-cedure and full performance improvement can beachieved by a relatively small number of measurescombined.Preliminary results of our research were alreadypublished in Pecina (2005).
In the current work,we used a new version of the Prague DependecyTreebank (PDT 2.0, 2006) and the reference datawas improved by additional manual anotation bytwo linguists.AcknowledgmentsThis work has been supported by the Ministry ofEducation of the Czech Republic, projects MSM0021620838 and LC 536.
We would like to thankour advisor Jan Hajic?, our colleagues, and anony-mous reviewers for their valuable comments.ReferencesY.
Choueka.
1988.
Looking for needles in a haystack or lo-cating interesting collocational expressions in large textualdatabases.
In Proceedings of the RIAO.S.
Evert and B. Krenn.
2001.
Methods for the qualitativeevaluation of lexical association measures.
In Proceedingsof the 39th Annual Meeting of the ACL, Toulouse, France.S.
Evert.
2004.
The Statistics of Word Cooccurrences: WordPairs and Collocations.
Ph.D. thesis, Univ.
of Stuttgart.T.
Fawcett.
2003.
ROC graphs: Notes and practical con-siderations for data mining researchers.
Technical report,HPL-2003-4.
HP Laboratories, Palo Alto, CA.T.
Hastie, S. Rosset, R. Tibshirani, and J. Zhu.
2004.
Theentire regularization path for the support vector machine.Journal of Machine Learning Research, 5.D.
Hull.
1993.
Using statistical testing in the evaluation ofretrieval experiments.
In Proceedings of the 16th annualinternational ACM SIGIR conference on Research and de-velopment in information retrieval, New York, NY.D.
Inkpen and G. Hirst.
2002.
Acquiring collocations forlexical choice between near synonyms.
In SIGLEX Work-shop on Unsupervised Lexical Acquisition, 40th meetingof the ACL, Philadelphia.K.
Kita, Y. Kato, T. Omoto, and Y. Yano.
1994.
A compar-ative study of automatic extraction of collocations fromcorpora: Mutual information vs. cost criteria.
Journal ofNatural Language Processing.B.
Krenn.
2000.
The Usual Suspects: Data-Oriented Modelsfor Identification and Representation of Lexical Colloca-tions.
Ph.D. thesis, Saarland University.C.
D. Manning and H. Sch?tze.
1999.
Foundations of Statis-tical Natural Language Processing.
The MIT Press, Cam-bridge, Massachusetts.R.
Mihalcea and T. Pedersen.
2003.
An evaluation exercisefor word alignment.
In Proceedings of HLT-NAACL Work-shop, Building and Using Parallel Texts: Data Driven Ma-chine Translation and Beyond, Edmonton, Alberta.R.
C. Moore.
2004.
On log-likelihood-ratios and the signif-icance of rare events.
In Proceedings of the 2004 Confer-ence on EMNLP, Barcelona, Spain.D.
Pearce.
2002.
A comparative evaluation of collocation ex-traction techniques.
In Third International Conference onlanguage Resources and Evaluation, Las Palmas, Spain.P.
Pecina.
2005.
An extensive empirical study of colloca-tion extraction methods.
In Proceedings of the ACL 2005Student Research Workshop, Ann Arbor, USA.S.
Shimohata, T. Sugio, and J. Nagata.
1997.
Retrieving col-locations by co-occurrences and word order constraints.In Proc.
of the 35th Meeting of ACL/EACL, Madrid, Spain.W.
N. Venables and B. D. Ripley.
2002.
Modern AppliedStatistics with S. 4th ed.
Springer Verlag, New York.C.
Zhai.
1997.
Exploiting context to identify lexical atoms:A statistical view of linguistic context.
In Internationaland Interdisciplinary Conf.
on Modeling and Using Context.PDT 2.0.
2006. http://ufal.mff.cuni.cz/pdt2.0/.658
