Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 637?642,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsTraining a Korean SRL System with Rich Morphological FeaturesYoung-Bum Kim, Heemoon Chae, Benjamin Snyder and Yu-Seop Kim*University of Wisconsin-Madison, Hallym University*{ybkim, hmchae21, bsnyder}@cs.wisc.edu, yskim01@hallym.ac.kr*AbstractIn this paper we introduce a semantic rolelabeler for Korean, an agglutinative lan-guage with rich morphology.
First, wecreate a novel training source by semanti-cally annotating a Korean corpus contain-ing fine-grained morphological and syn-tactic information.
We then develop a su-pervised SRL model by leveraging mor-phological features of Korean that tendto correspond with semantic roles.
Ourmodel also employs a variety of latentmorpheme representations induced from alarger body of unannotated Korean text.These elements lead to state-of-the-art per-formance of 81.07% labeled F1, represent-ing the best SRL performance reported todate for an agglutinative language.1 IntroductionSemantic Role Labeling (SRL) is the task of auto-matically annotating the predicate-argument struc-ture in a sentence with semantic roles.
Ever sinceGildea and Jurafsky (2002), SRL has become animportant technology used in applications requir-ing semantic interpretation, ranging from infor-mation extraction (Frank et al, 2007) and ques-tion answering (Narayanan and Harabagiu, 2004),to practical problems including textual entailment(Burchardt et al, 2007) and pictorial communica-tion systems (Goldberg et al, 2008).SRL systems in many languages have beendeveloped as the necessary linguistic resourcesbecome available (Taul?e et al, 2008; Xue andPalmer, 2009; B?ohmov?a et al, 2003; Kawahara etal., 2002).
Seven languages were the subject of theCoNLL-2009 shared task in syntactic and seman-tic parsing (Haji?c et al, 2009).
These languagescan be categorized into three broad morphologicaltypes: fusional (4), analytic (2), and one aggluti-native language.PaulstudiesmathematicswithJaneatalibraryPoleundoseogwaneseoJeingwasuhageullgongbuhandaFigure 1: English (SVO) and Korean (SOV) wordsalignment.
The subject, verb, and object are high-lighted as red, blue, and green, respectively.
Also,prepositions and suffixes are highlighted as purple.Bj?orkelund et al (2009) report an average la-beled semantic F1-score of 80.80% across theselanguages.
The highest performance was achievedfor the analytic language group (82.12%), whilethe agglutinative language, Japanese, yielded thelowest performance (76.30%).
Agglutinative lan-guages such as Japanese, Korean, and Turkish arecomputationally difficult due to word-form spar-sity, variable word order, and the challenge of us-ing rich morphological features.In this paper, we describe a Korean SRL systemwhich achieves 81% labeled semantic F1-score.As far as we know, this is the highest accuracyobtained for Korean, as well as any agglutinativelanguage.
Figure 1 displays a English/Korean sen-tence pair, highlighting the SOV word order of Ko-rean as well as its rich morphological structure.Two factors proved crucial in the performance ofour SRL system: (i) The analysis of fine-grainedmorphological tags specific to Korean, and (ii) theuse of latent stem and morpheme representationsto deal with sparsity.
We incorporated both ofthese elements in a CRF (Lafferty et al, 2001) rolelabeling model.Besides the contribution of this model and SRLsystem, we also report on the creation and avail-ability of a new semantically annotated Koreancorpus, covering over 8,000 sentences.
We usedthis corpus to develop, train, and test our KoreanSRL model.
In the next section, we describe theprocess of corpus creation in more detail.6372 A Semantically Annotated KoreanCorpusWe annotated predicate-argument structure ofverbs in a corpus from the Electronics andTelecommunications Research Institute of Korea(ETRI).1Our corpus was developed over twoyears using a specialized annotation tool (Song etal., 2012), resulting in more than 8,000 semanti-cally annotated sentences.
As much as possible,annotations followed the PropBank guidelines forEnglish (Bonial et al, 2010).We view our work as building on the efforts ofthe Penn Korean PropBank (PKPB).2Our corpusis roughly similar in size to the PKPB, and takentogether, the two Korean corpora now total abouthalf the size of the Penn English PropBank.
Oneadvantage of our corpus is that it is built on top ofthe ETRI Korean corpus, which uses a richer Ko-rean morphological tagging scheme than the PennKorean Treebank.
Our experiments will show thatthese finer-grained tags are crucial for achievinghigh SRL accuracy.All annotations were performed by two peopleworking in a team.
At first, each annotator as-signs semantic roles independently and then theydiscuss to reduce disagreement of their annotationresults.
Initially, the disagreement rate betweentwo annotators was about 14%.
After 4 monthsof this process, the disagreement rate fell to 4%through the process of building annotation rulesfor Korean.
The underlying ETRI syntactically-annotated corpus contains the dependency treestructure of sentences with morpho-syntactic tags.It includes 101,602 multiple-clause sentences with21.66 words on average.We encountered two major difficulties duringannotation.
First, the existing Korean frame filesfrom the Penn Korean PropBank include 2,749verbs, covering only 13.87% of all the verbs in theETRI corpus.
Secondly, no Korean PropBankingguidelines have previously been published, lead-ing to uncertainty in the initial stages of annota-tion.
These uncertainties were gradually resolvedthrough the iterative process of resolving inter-annotator disagreements.Table 1 shows the semantic roles considered inour annotated corpus.
Although these are based onthe general English PropBank guidelines (Bonialet al, 2010), they also differ in that we used only1http://voice.etri.re.kr/db/db pop.asp?code=882http://catalog.ldc.upenn.edu/LDC2006T03Roles Definition RateARG0 Agent 10.02%ARG1 Patient 26.73%ARG2Start point /Benefactive5.18%ARG3 Ending point 1.10%ARGM-ADV Adverbial 1.26%ARGM-CAU Cause 1.17%ARGM-CND Condition 0.36%ARGM-DIR Direction 0.35%ARGM-DIS Discourse 28.71%ARGM-EXT Extent 4.50%ARGM-INS Instrument 1.04%ARGM-LOC Locative 4.51%ARGM-MNR Manner 8.72%ARGM-NEG Negation 0.26%ARGM-PRD Predication 0.27%ARGM-PRP Purpose 0.77%ARGM-TMP Temporal 5.05%Table 1: Semantic roles in our annotated corpus.4 numbered arguments from ARG0 to ARG3 in-stead of 5 numbered arguments.
We thus consider17 semantic roles in total.
Four of them are num-bered roles, describing the essential arguments ofa predicate.
The other roles are called modifierroles that play more of an adjunct role.We have annotated semantic roles by followingthe PropBank annotation guideline (Bonial et al,2010) and by using frame files of the Penn KoreanPropBank built by Palmer et al (2006).
The Prop-Bank and our corpus are not exactly compatible,because the former is built on constituency-basedparse trees, whereas our corpus uses dependencyparses.More importantly, the tagsets of these corporaare not fully compatible.
The PKPB uses muchcoarser morpho-syntactic tags than the ETRIcorpus.
For example, the PCA tag in PKPB usedfor a case suffix covers four different functioningtags used in our corpus.
Using coarser suffixtags can seriously degrade SRL performance, aswe show in Section 6, where we compare theperformance of our model on both the new corpusand the older PKPB.6383 Previous WorkKorean SRL research has been limited to domesti-cally published Korean research on small corpora.Therefore, the most direct precedent to the presentwork is a section in Bj?orkelund et al (2009) onJapanese SRL.
They build a classifier consistingof 3 stages: predicate disambiguation, argumentidentification, and argument classification.They use an L2-regularized linear logistic re-gression model cascaded through these threestages, achieving F1-score of 80.80% on averagefor 7 languages (Catalan, Chinese, Czech, English,German, Japanese and Spanish).
The lowest re-ported performance is for Japanese, the only ag-glutinative language in their data set, achievingF1-score of 76.30%.
This result showcases thecomputational difficulty of dealing with morpho-logically rich agglutinative languages.
As we dis-cuss in Section 5, we utilize these same features,but also add a set of Korean-specific features tocapture aspects of Korean morphology.Besides these morphological features, we alsoemploy latent continuous and discrete morphemerepresentations induced from a larger body ofunannotated Korean text.
As our experiments be-low show, these features improve performance bydealing with sparsity issues.
Such features havebeen useful in a variety of English NLP mod-els, including chunking, named entity recogni-tion (Turian et al, 2010), and spoken language un-derstanding (Anastasakos et al, 2014).
Unlike theEnglish models, we use individual morphemes asour unit of analysis.4 ModelFor the semantic role task, the input is a sentenceconsisting of a sequence of words x = x1, .
.
.
, xnand the output is a sequence of corresponding se-mantic tags y = y1, .
.
.
, yn.
Each word con-sists of a stem and some number of suffix mor-phemes, and the semantic tags are drawn from theset {NONE, ARG?, .
.
.
, ARGM-TMP}.
We modelthe conditional probability p(y|x) using a CRFmodel:Z(x)?1x?i=1exp?m?mfm(yi?1, yi, x, i),where fm(yi?1, yi, x, i) are the feature functions.These feature functions include transition featuresthat identify the tag bigram (yi?1, yi), and emis-sion features that combine the current semantic tag(yi) with instantiated feature templates extractedfrom the sentence x and its underlying morpho-logical and dependency analysis.
The functionZ is the normalizing function, which ensures thatp(y|x) is a valid probability distribution.
We used100 iteration of averaged perceptron algorithm totrain the CRF.5 FeaturesWe detail the feature templates used for our ex-periments in Table 2.
These features are catego-rized as either general features, Korean-specificfeatures, or latent morpheme representation fea-tures.
Korean-specific features are built upon themorphological analysis of the suffix agglutinationof the current word xi.Korean suffixes are traditionally classified intotwo groups called Josa and Eomi.
Josa is usedto define nominal cases and modify other phrases,while Eomi is an ending of a verb or an adjectiveto define a tense, show an attitude, and connector terminate a sentence.
Thus, the Eomi and Josacategorization plays an important role in signalingsemantic roles.
Considering the functions of Josaand Eomi, we expect that numbered roles are rele-vant to Josa while modifier roles are more closelyrelated to Eomi.
The one exception is adverbialJosa, making the attached phrase an adverb thatmodifies a verb predicate.For all feature templates, ?A-?
or ?P-?
are usedrespectively to signify that the feature correspondsto the argument in question (xi), or rather is de-rived from the verbal predicate that the argumentdepends on.General features: We use and modify 18 fea-tures used for Japanese from the prior work ofBj?orkelund et al (2009), excluding SENSE, PO-SITION, and re-ranker features.?
Stem: a stem without any attachment.
Forinstance, the first word Poleun at the Figure 1consists of a stem Pol plus Josa eun.?
POS Lv1: the first level (coarse classifi-cation) of a POS tag such as noun, verb,adjective, or adverb.639Feature DescriptionA-Stem, P-Stem Stem of an argument and a predicateA-POS Lv1, P-POS Lv1 Coarse-grained POS of A-Stem and P-StemA-POS Lv2, P-POS Lv2 Fine-grained POS of A-Stem and P-StemA-Case, P-Case Case of A-Stem and P-StemA-LeftmostChildStem Stem of the leftmost child of an argumentA-LeftSiblingStem Stem of the left sibling of an argumentA-LeftSiblingPOS Lv1 Coarse-grained POS of A-LeftSiblingStemA-LeftSiblingPOS Lv2 Fine-grained POS of A-LeftSiblingStemA-RightSiblingPOS Lv1 Coarse-grained POS of a stem of the right sibling of an argumentA-RightSiblingPOS Lv2 Fine-grained POS of a stem of the right sibling of an argumentP-ParentStem Stem of a parent of a predicateP-ChildStemSet Set of stems of children of a predicateP-ChildPOSSet Lv1 Set of coarse POS of P-ChildStemSetP-ChildCaseSet Set of cases of P-childStemSetA-JosaExist If 1, Josa exists in an argument, otherwise 0.A-JosaClass Linguistic classification of JosaA-JosaLength Number of morphemes consisting of JosaA-JosaMorphemes Each morpheme consisting of JosaA-JosaIdenity Josa of an argumentA-EomiExist If 1, Eomi exists in an argument, otherwise 0.A-EomiClass Lv1 Linguistic classification of EomiA-EomiClass Lv2 Another linguistic classification of EomiA-EomiLength Number of morphemes consisting of EomiA-EomiMorphemes Each morpheme consisting of EomiA-EomiIdentity Eomi of an argumentA-StemRepr Stem representation of an argumentA-JosaRepr Josa representation of an argumentA-EomiRepr Eomi representation of an argumentTable 2: Features used in our SRL experiments.
Features are grouped as General, Korean-specific, orLatent Morpheme Representations.
For the last group, we employ three different methods to build them:(i) CCA, (ii) deep learning, and (iii) Brown clustering.?
POS Lv2: the second level (fine classifica-tion) of a POS tag.
If POS Lv1 is noun, ei-ther a proper noun, common noun, or otherkinds of nouns is the POS Lv2.?
Case: the case type such as SBJ, OBJ, orCOMP.The above features are also applied to some depen-dency children, parents, and siblings of argumentsas shown in Table 2.Korean-specific features: We have 11 differentkinds of features for the Josa (5) and Eomi (6).
Wehighlight several below:?
A-JosaExist: an indicator feature checkingany Josa whether or not exists in an argument.It is set to 1 if any Josa exists, otherwise 0.?
A-JosaClass: the linguistic classification ofJosa with a total of 8 classes.
These classesare adverbial, auxiliary, complemental, con-nective, determinative, objective, subjective,and vocative.?
A-JosaLength: the number of morphemesconsisting of Josa.
At most five morphemesare combined to consist of one Josa in ourdata set.?
A-JosaMorphemes: Each morpheme com-posing the Josa.?
A-JosaIdentity: The Josa itself.?
A-EomiClass Lv1: the linguistic classifica-tion of Eomi with a total of 14 classes.
These14 classes are adverbial, determinative, coor-dinate, exclamatory, future tense, honorific,imperative, interrogative, modesty, nominal,normal, past tense, petitionary, and subordi-nate.?
A-EomiClass Lv2: Another linguistic classi-fication of Eomi with a total of 4 classes.
Thefour classes are closing, connection, prefinal,and transmutation.
The EomiClass Lv1 andLv2 are combined to display the characteris-tic of Eomi such as ?Nominal TransmutationEomi?, but not all combinations are possible.640Corpus Gen Gen+KorGen+Kor+LMRCCA Deep Brown AllPKPB 64.83% 75.17% 75.51% 75.43% 75.55% 75.54%Our annotated corpus 66.88% 80.33% 80.88% 80.84% 80.77% 81.07%PKPB + our annotated corpus 64.86% 78.61% 79.32% 79.44% 78.91% 79.20%Table 3: Experimental F1-score results on every experiment.
Abbreviation on features are Gen: generalfeatures, Kor: Korean specific features, LMR: latent morpheme representation features.Latent morpheme representation features: Toalleviate the sparsity, a lingering problem in NLP,we employ three kinds of latent morpheme repre-sentations induced from a larger body of unsuper-vised text data.
These are (i) linear continuous rep-resentation through Canonical Correlation Analy-sis (Dhillon et al, 2012), (ii) non-linear contin-uous representation through Deep learning (Col-lobert and Weston, 2008), and (iii) discrete rep-resentation through Brown Clustering (Tatu andMoldovan, 2005).The first two representations are 50 dimensionalcontinuous vectors for each morpheme, and thelatter is a set of 256 clusters over morphemes.6 Experiments and ResultsWe categorized our experiments by the scenariosbelow, and all results are summarized in Table 3.The F1-score results were investigated for eachscenario.
We randomly divided our data into 90%training and 10% test sets for all scenarios.For latent morpheme representations, we usedthe Donga news article corpus.3The Donga cor-pus contains 366,636 sentences with 25.09 wordson average.
The Domain of this corpus cov-ers typical news articles such as health, entertain-ment, technology, politics, world and others.
Weran Kokoma Korean morpheme analyzer4on eachsentence of the Donga corpus to divide words intomorphemes to build latent morpheme representa-tions.1st Scenario: We first tested on general featuresin previous work (2nd column in Table 3).
Weachieved 64.83% and 66.88% on the PKPB andour corpus.
When the both corpora were com-bined, we had 64.86%.2nd Scenario: We then added the Korean-specific morphological features to signify its ap-3http://www.donga.com4http://kkma.snu.ac.kr/propriateness in this scenario.
These features in-creased greatly performance improvements (3rdcolumn in Table 3).
Although both the PKPBand our corpus had improvements, the improve-ments were the most notable on our corpus.
Thisis because PKPB POS tags might be too coarse.We achieved 75.17%, 80.33%, and 78.61% on thePKPB, our corpus, and the combined one, respec-tively.3rd Scenario: This scenario is to reveal the ef-fects of the different latent morpheme represen-tations (4-6th columns in Table 3).
These threerepresentations are from CCA, deep learning, andBrown clustering.
The results gave evidences thatall representations increased the performance.4th Scenario: We augmented our model with allkinds of features (the last column in Table 3).
Weachieved our best F1-score of 81.07% over all sce-narios on our corpus.7 ConclusionFor Korean SRL, we semantically annotated acorpus containing detailed morphological annota-tion.
We then developed a supervised model whichleverages Korean-specific features and a varietyof latent morpheme representations to help dealwith a sparsity problem.
Our best model achieved81.07% in F1-score.
In the future, we will con-tinue to build our corpus and look for the way touse unsupervised learning for SRL to apply to an-other language which does not have available cor-pus.AcknowledgmentsWe thank Na-Rae Han and Asli Celikyilmaz forhelpful discussion and feedback.
This researchwas supported by the Basic Science Research Pro-gram of the Korean National Research Foundation(NRF), and funded by the Korean Ministry of Ed-ucation, Science and Technology (2010-0010612).641ReferencesTasos Anastasakos, Young-Bum Kim, and Anoop Deo-ras.
2014.
Task specific continuous word represen-tations for mono and multi-lingual spoken languageunderstanding.
In Proceedings of the IEEE Interna-tional Conference on Acoustics, Speech, and SignalProcessing (ICASSP).Anders Bj?orkelund, Love Hafdell, and Pierre Nugues.2009.
Multilingual semantic role labeling.
In Pro-ceedings of the Thirteenth Conference on Compu-tational Natural Language Learning: Shared Task,pages 43?48.
Association for Computational Lin-guistics.Alena B?ohmov?a, Jan Haji?c, Eva Haji?cov?a, and BarboraHladk?a.
2003.
The prague dependency treebank.
InTreebanks, pages 103?127.
Springer.Claire Bonial, Olga Babko-Malaya, Jinho D Choi, JenaHwang, and Martha Palmer.
2010.
Propbank an-notation guidelines.
Center for Computational Lan-guage and Education Research, CU-Boulder.Aljoscha Burchardt, Nils Reiter, Stefan Thater, andAnette Frank.
2007.
A semantic approach to tex-tual entailment: system evaluation and task analy-sis.
In Proceedings of the ACL-PASCAL Workshopon Textual Entailment and Paraphrasing, RTE ?07,pages 10?15, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: Deepneural networks with multitask learning.
In Pro-ceedings of the 25th international conference onMachine learning, pages 160?167.
ACM.Paramveer Dhillon, Jordan Rodu, Dean Foster, andLyle Ungar.
2012.
Two step cca: A new spec-tral method for estimating vector models of words.arXiv preprint arXiv:1206.6403.Anette Frank, Hans-Ulrich Krieger, Feiyu Xu, HansUszkoreit, Berthold Crysmann, Brigitte J?org, andUlrich Sch?afer.
2007.
Question answering fromstructured knowledge sources.
Journal of AppliedLogic, 5(1):20 ?
48.
Questions and Answers: Theo-retical and Applied Perspectives.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational linguis-tics, 28(3):245?288.Andrew B Goldberg, Xiaojin Zhu, Charles R Dyer,Mohamed Eldawy, and Lijie Heng.
2008.
Easyas abc?
: facilitating pictorial communication viasemantically enhanced layout.
In Proceedings ofthe Twelfth Conference on Computational NaturalLanguage Learning, pages 119?126.
Association forComputational Linguistics.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, et al 2009.
The conll-2009shared task: Syntactic and semantic dependenciesin multiple languages.
In Proceedings of the Thir-teenth Conference on Computational Natural Lan-guage Learning: Shared Task, pages 1?18.
Associa-tion for Computational Linguistics.Daisuke Kawahara, Sadao Kurohashi, and K?oitiHasida.
2002.
Construction of a japanese relevance-tagged corpus.
In LREC.John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.Srini Narayanan and Sanda Harabagiu.
2004.
Ques-tion answering based on semantic structures.
InProceedings of the 20th international conference onComputational Linguistics, COLING ?04, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Martha Palmer, Shijong Ryu, Jinyoung Choi, SinwonYoon, and Yeongmi Jeon.
2006.
Korean propbank.Linguistic data consortium.Hye-Jeong Song, Chan-Young Park, Jung-Kuk Lee,Min-Ji Lee, Yoon-Jeong Lee, Jong-Dae Kim, andYu-Seop Kim.
2012.
Construction of korean se-mantic annotated corpus.
In Computer Applicationsfor Database, Education, and Ubiquitous Comput-ing, pages 265?271.
Springer.Marta Tatu and Dan Moldovan.
2005.
A seman-tic approach to recognizing textual entailment.
InProceedings of the conference on Human LanguageTechnology and Empirical Methods in Natural Lan-guage Processing, pages 371?378.
Association forComputational Linguistics.Mariona Taul?e, Maria Ant`onia Mart?
?, and Marta Re-casens.
2008.
Ancora: Multilevel annotated corporafor catalan and spanish.
In LREC.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 384?394.
Association forComputational Linguistics.Nianwen Xue and Martha Palmer.
2009.
Adding se-mantic roles to the chinese treebank.
Natural Lan-guage Engineering, 15(01):143?172.642
