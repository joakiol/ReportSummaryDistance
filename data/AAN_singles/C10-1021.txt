Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 179?187,Beijing, August 2010Emotion Cause Detection with Linguistic ConstructionsYing Chen*?, Sophia Yat Mei Lee?, Shoushan Li?, Chu-Ren Huang?*Dep.
of Computer EngineeringChina Agricultural University?Dep.
of Chinese and Bilingual StudiesThe Hong Kong Polytechnic University{chenying3176,sophiaym,shoushan.li,churenhuang}@gmail.comAbstractThis paper proposes a multi-label ap-proach to detect emotion causes.
Themulti-label model not only detects mul-ti-clause causes, but also captures thelong-distance information to facilitateemotion cause detection.
In addition,based on the linguistic analysis, we cre-ate two sets of linguistic patterns duringfeature extraction.
Both manually gener-alized patterns and automatically gener-alized patterns are designed to extractgeneral cause expressions or specificconstructions for emotion causes.
Ex-periments show that our systemachieves a performance much higherthan a baseline model.1 IntroductionText-based emotion processing has been a cen-ter of attention in the NLP field in the past fewyears.
Most previous researches have focusedon detecting the surface information of emo-tions, especially emotion classes, e.g., ?happi-ness?
and ?anger?
(Mihalcea and Liu 2006,Strapparava and Mihalcea 2008, Abbasi et al2008, Tokuhisa et al 2008).
Although mostemotion theories recognize the important role ofcauses in emotion analysis (Descartes, 1649;James, 1884; Plutchik 1980, Wierzbicka 1999),very few studies explore the interactions be-tween emotion and causes.
Emotion-cause in-teraction is the eventive relation which poten-tially yields the most crucial information interms of information extraction.
For instance,knowing the existence of an emotion is ofteninsufficient to predict future events or decide onthe best reaction.
However, if the emotion causeis known in addition to the type of emotion,prediction of future events or assessment of po-tential implications can be done more reliably.In other words, when emotion is treated as anevent, causal relation is the pivotal relation todiscover.
In this paper, we explore one of thecrucial deep level types of information of emo-tion, i.e.
cause events.Our study focuses on explicit emotions inwhich emotions are often presented by emotionkeywords such as ?shocked?
in ?He wasshocked after hearing the news?.
Emotion caus-es are the explicitly expressed propositions thatevoke the presence of the corresponding emo-tions.
They can be expressed by verbs, nomi-nalizations, and nominals.
Lee et al (2010a)explore the causes of explicit emotions by con-structing a Chinese emotion cause corpus.Based on this corpus, we formalize the emotioncause detection problem through extensive dataanalysis.
We find that ~14% emotion causes arecomplicated events containing multi-clauses, towhich previous cause detection systems canhardly be applied directly.
Most previous causedetection systems focus on the causal relationbetween a pair of small-size text units, such asclauses or phrases.
They are thus not able todetect emotion causes that are multi-clauses.
Inthis paper, we formalize emotion cause detec-tion as a multi-label classification task (i.e.
eachinstance may contain more than one label),which allows us to capture long-distance infor-mation for emotion cause detection.In term of feature extraction, as emotioncause detection is a case of cause detection,some typical patterns used in existing cause de-tection systems, e.g., ?because?
and ?thus?, canbe adopted.
In addition, various linguistic cuesare examined which potentially indicate emo-tion causes, such as causative verbs and epis-temic markers (Lee at al.
2010a).
Then somelinguistic patterns of emotion causes are manu-179ally generalized by examining the linguisticcontext of the empirical data (Lee et al, 2010b).It is expected that these manually generalizedpatterns often yield a low-coverage problem.Thus, we extracted features which enable us toautomatically capture more emotion-specificconstructions.
Experiments show that such anintegrated system with various linguistic fea-tures performs promisingly well.
We believethat the present study should provide the foun-dation for future research on emotion analysis,such as the detection of implicit emotion orcause.The paper is organized as follows.
Section 2discusses the related work on cause-effect de-tection.
Section 3 briefly describes the emotioncause corpus, and then presents our data analy-sis.
Section 4 introduces the multi-label classifi-cation system for emotion cause detection.
Sec-tion 5 describes the two kinds of features for oursystem, one is based on hand-coded patterns andthe other is the generalized features.
Section 6presents the evaluation and performance of oursystem.
Section 7 highlights our main contribu-tions and the possible future work.2 Related WorkMost previous studies on textual emotion proc-essing focus on emotion recognition or classifi-cation given a known emotion context (Mihal-cea and Liu 2006, Strapparava and Mihalcea2008, Abbasi et al 2008, Tokuhisa et al 2008).However, the performance is far from satisfac-tory.
One crucial problem in these works is thatthey limit the emotion analysis to a simple clas-sification and do not explore the underlying in-formation regarding emotions.
Most theoriesconclude that emotions are often invoked by theperception of external events.
An effective emo-tion recognition model should thus take this intoaccount.To the best of our knowledge, little researchhas been done with respect to emotion causedetection.
Lee et al (2010a) first investigate theinteractions between emotions and the corre-sponding causes from a linguistic perspective.They annotate a small-scale emotion cause cor-pus, and identify six groups of linguistic cuesfacilitating emotion cause detection.
Based onthese findings, they develop a rule-based systemfor automatic emotion cause detection (Lee etal., 2010b).Emotion cause detection can be considered asa kind of causal relation detection, which hasbeen intensively studied for years.
Most previ-ous cause detection studies focus on a specificdomain, such as aviation (Persing and Ng, 2009)and finance (Low, et al, 2001).
Few works(Marcu and Echihabi, 2002; Girju, 2003; Changand Choi, 2005) examine causal relation foropen domains.In recognizing causal relations, most existingsystems involve two steps: 1) cause candidateidentification; 2) causal relation detection.
Tosimplify the task, most systems omit the step ofidentifying cause candidates.
Instead, they oftenpredefine or filter out possible causes based ondomain knowledge, e.g., 14 kinds of cause typesare identified for aviation incidents (Persing andNg, 2009).
For events without specific domaininformation, open-domain systems choose tolimit their cause candidate.
For example, thecause-effect pairs are limited to two nounphrases (Chang and Choi, 2005; Girju, 2003), ortwo clauses connected with fixed conjunctionwords (Marcu and Echihabi, 2002).Given pairs of cause-effect candidates, causalrelation detection is considered as a binary clas-sification problem, i.e.
?causal?
vs. ?non-causal?.
In general, there are two kinds of in-formation extracted to identify the causal rela-tion.
One is patterns or constructions expressinga cause-effect relation (Chang and Choi, 2005;Girju, 2003), and the other is semantic informa-tion underlying in a text (Marcu and Echihabi,2002; Persing and Ng, 2009), such as word pairprobability.
Undoubtedly, the two kinds of in-formation usually interact with each other in areal cause detection system.In the literature, the three common classifica-tion methods, i.e.
unsupervised, semi-supervised,and supervised, have all been used for causedetection systems.
Marcu and Echihabi (2002)first collected a cause corpus using an unsuper-vised approach with the help of several conjunc-tion words, such as ?because?
and ?thus?, anddetermined the causal relation for a clause pairusing the word pair probability.
Chang and Choi(2005) used a semi-supervised method to recur-sively learn lexical patterns for cause recogni-tion based on syntactic trees.
Bethard and Mar-tin (2008) put various causal information in a180supervised classifier, such as the temporal in-formation and syntactic information.For our emotion cause detection, severalpractical issues need to be investigated and re-solved.
First, for the identification of cause can-didates, we need to define a reasonable span ofa cause.
Based on our data analysis, we find thatemotion causes often appear across phrases oreven clauses.
Second, although in emotioncause detection the effect is fixed, the cause isopen-domain.
We also notice that besides thecommon patterns, emotion causes have theirown expression patterns.
An effective emotioncause detection system should take them intoaccount.3 Corpus AnalysisIn this section, we briefly introduce the Chineseemotion cause corpus (Lee et al, 2010a), anddiscuss emotion cause distribution.3.1 Emotion Cause corpusLee at al.
(2010a) made the first attempt to ex-plore the correlation between emotions andcauses, and annotate a Chinese emotion causecorpus.
The emotion cause corpus focuses onfive primary emotions, namely ?happiness?,?sadness?, ?fear?, ?anger?, and ?surprise?.
Theemotions are explicitly expressed by emotionkeywords, e.g., gao1xing4 ?happy?, shang1xin1?sad?, etc.
The corpus is created as follows.1.
6,058 entries of Chinese sentences are ex-tracted from the Academia Sinica BalancedCorpus of Mandarin Chinese (Sinica Cor-pus) with the pattern-match method as wellas the list of 91 Chinese primary emotionkeywords (Chen et al, 2009).
Each entrycontains the focus sentence with the emo-tion keyword ?<FocusSentence>?
plus thesentence before ?<PrefixSentence>?
andafter ?<SuffixSentence>?
it.
For each entry,the emotion keywords are indexed sincemore than one emotion may be presented inan entry;2.
Some preprocessing, such as balancing thenumber of entry among emotions, is doneto remove some entries.
Finally, 5,629 en-tries remain;3.
Each emotion keyword is annotated withits corresponding causes if existing.
Anemotion keyword can sometimes be associ-ated with more than one cause, in such acase, both causes are marked.
Moreover,the cause type is also identified, which iseither a nominal event or a verbal event (averb or a nominalization).Lee at al.
(2010a) notice that 72% of the ex-tracted entries express emotions, and 80% of theemotional entries have a cause.3.2 The Analysis of Emotion CausesTo have a deeper understanding of emotioncause detection, we take a closer look at theemotion cause distribution, including the distri-bution of emotion cause occurrence and the dis-tribution of emotion cause text.The occurrence of emotion causes: Accordingto most emotion theories, an emotion is gener-ally invoked by an external event.
The corpusshows that, however, 20% of the emotional en-tries have no cause.
Entries without causes ex-plicitly expressed are mainly due to the follow-ing reasons:i) There is not enough contextual information,for instance the previous or the suffix sentenceis interjections, e.g., en heng ?aha?
;ii) When the focus sentence is the beginningor the ending of a paragraph, no prefix sentenceor suffix sentence can be extracted as the con-text.
In this case, the cause may be beyond thecontext;iii) The cause is obscure, which can be veryabstract or even unknown reasons.The emotion cause text: A cause is consideredas a proposition.
It is generally assumed that aproposition has a verb which optionally takes anoun occurring before it as the subject and anoun after it as the object.
However, a cause canalso be expressed as a nominal.
In other words,both the predicate and the two arguments areoptional provided that at least one of them ispresent.
Thus, the fundamental issue in design-ing a cause detection system is the definition ofthe span of a cause text.
As mentioned, mostprevious studies on causal relations choose toignore the identification of cause candidates.
Inthis paper, we first analyze the distribution ofcause text and then determine the cause candi-dates for an emotion.Based on the emotion cause corpus, we findthat emotion causes are more likely to be ex-181pressed by verbal events than nominal events(85% vs. 15%).
Although a nominalization (akind of verbal events) is usually a noun phrase,a proposition containing a verb plays a salientrole in the expressions of emotion causes, andthus a cause candidate are more likely to be aclause-based unit.In addition, the actual cause can sometimesbe too long and complicated, which involvesseveral events.
In order to explore the span of acause text, we do the following analysis.Table 1: The clause distribution of cause textsPosition Cause (%) Position Cause (%)Left_0 12.90 Right _0 15.54Left_1 31.37 Right _1  9.55Left_2 13.31 Right_n(n>1)9.18Left_n(n>2)10.15Total  67.73  32.27Table 2: The multi-clause distribution of causetextSame clause % Cross-clauses %Left_0 16.80 Left_2_1_0 0.25Left_1 31.82 Left_2_1 10.84Left_2 7.33 Left_1_0 0.62Right _0 18.97 Right_0_1 2.55Right _1  10.59Total 85.75  14.25Firstly, for each emotion keyword, an entry issegmented into clauses with four punctuations(i.e.
commas, periods, question marks and ex-clamation marks), and thus an entry becomes alist of cause candidates.
For example, when anentry has four clauses, its corresponding list ofcause candidates contains five text units, i.e.<left_2, left_1, left_0, right_0, right_1>.
If weassume the clause where emotion keyword lo-cates is a focus clause, ?left_2?
and ?left_1?
areprevious two clauses, and ?right_1?
is the fol-lowing one.
?left_0?
and ?right_0?
are the partialtexts of the focus clause, which locate in the leftside of and the right side of the emotion key-word, respectively.
Moreover, a cause candidatemust contain either a noun or a verb because acause is either a verbal event or a nominal event;otherwise, it will be removed from the list.Secondly, we calculate whether a cause can-didate overlaps with the real cause, as shown inTable 1.
We find that emotion causes are morelikely to occur in the left of emotion keyword.This observation is consistent with the fact thatan emotion is often trigged by an external hap-pened event.
Thirdly, for all causes occurringbetween ?left_2?
and ?right_1?, we calculatewhether a cause occurs across clauses, as in Ta-ble 2.
We observe that most causes locatewithin the same clause of the representation ofthe emotion (85.57%).
This suggests that aclause may be the most appropriate unit to de-tect a cause.4 Emotion Cause Detection Based onMulti-label ClassificationA cause detection system is to identify the caus-al relation between a pair of two text units.
Foremotion cause detection, one of the two textunits is fixed (i.e.
the emotion keyword), andtherefore the remaining two unresolved issuesare the identification of the other text unit andthe causal relation.From the above data analysis, there are twoobservations.
First, most emotion causes areverbal events, which are often expressed by aproposition (or a clause).
Thus, we define an-other text unit as a clause, namely a cause can-didate.
Second, as most emotion causes occurbetween ?left_2?
and ?right_1?
(~80%), we de-fine the cause candidates for an emotion as<left_2, left_1, left_0, right_0, right_1>.Differing from the existing cause systems, weformalize emotion cause detection as a multi-label problem.
In other words, given an emotionkeyword and its context, its label is the loca-tions of its causes, such as ?left_1, left_0?.
Thismulti-label-based formalization of the causedetection task has two advantages.
First, it is anintegrated system detecting causes for an emo-tion from the contextual information.
In mostprevious cause detection systems, a causal rela-tion is identified based on the information be-tween two small text units, i.e.
a pair of clausesor noun phrases, and therefore it is often thecase that long-distance information is missed.Second, the multi-label-based tagging is able to182capture the relationship between two cause can-didates.
For example, ?left_2?
and ?left_1?
areoften combined as a complicated event as acause.As a multi-label classification task, everymulti-label classifier is applicable.
In this study,we use a simple strategy: we treat each possiblecombination of labels appearing in the trainingdata as a unique label.
Note that an emotionwithout causes is labeled as ?None?.
This con-verts multi-label classification to single-labelclassification, which is suitable for any multi-class classification technologies.
In particular,we choose a Max Entropy tool, Mallet1, to per-form the classification.5 Linguistic FeaturesAs explained, there are basically two kinds offeatures for cause detection, namely pattern-based features and semantic-based features.
Inthis study, we develop two sets of patternsbased on linguistic analysis: one is a set of ma-nually generalized patterns, and the other con-tains automatically generalized patterns.
All ofthese patterns explore causal constructions ei-ther for general causal relations or for specificemotion cause relations.5.1 Linguistic CuesBased on the linguistic analysis, Lee et al(2010a) identify six groups of linguistic cuewords that are highly collocated with emotioncauses, as shown in Table 3.
Each group of thelinguistic cues serves as an indicator markingthe causes in different emotional constructions.In this paper, these groups of linguistic cues arereinterpreted from the computational perspec-tive, and are used to develop pattern-based fea-tures for the emotion cause detection system.Table 3:  Linguistic cue words for emotioncause detection (Lee et al 2010a)Group Cue WordsI:Prepositions?for?
as in ?I will do this for you?
: wei4,wei4le?for?
as in ?He is too old for the job?
:dui4, dui4yu2?as?
: yi31http://mallet.cs.umass.edu/II:Conjunctions?because?
: yin1, yin1wei4, you2yu2?so?
: yu1shi4, suo3yi3, yin1er2?but?
: ke3shi4III:Light Verbs ?to make?
: rang4, ling4, shi3IV:ReportedVerbs?to think about?
: xiang3dao4,xiang3qi3, yi1xiang3, xiang3 lai2?to talk about?
: shuo1dao4, shuo1qi3,yi1shuo1, jiang3dao4, jiang3qi3,yi1jiang3, tan2dao4, tan2qi3, yi1tan2,ti2dao4, ti2qi3, yi1ti2V:EpistemicMarkers?to hear?
: ting1, ting1dao4, ting1shuo1?to see?
: kan4, kan4dao4, kan4jian4,jian4dao4, jian4, yan3kan4, qiao2jian4?to know?
: zhi1dao4, de2zhi1, de2xi1,huo4zhi1, huo4xi1, fa1xian4, fa1jue2?to exist?
: you3VI:Others?is?
: deshi4?say?
: deshuo1?at?
: yu2?can?
: neng2For emotion cause processing, Group I and IIcontain cues which are for general cause detec-tion, and while Group III, IV and V includecues specifically for emotion cause detection.Group VI includes other linguistic cues that donot fall into any of the five groups.Group I covers some prepositions which allroughly mean ?for?, and Group II contains theconjunctions that explicitly mark the emotioncause.
Group I is expected to capture the prepo-sitions constructions in the focus clause wherethe emotion keyword locates.
Group II tends tocapture the rhetorical relation expressed by con-junction words so as to infer causal relationamong multi-clauses.
These two groups are typ-ical features for general cause detection.Group III includes three common light verbswhich correspond to the English equivalents ?tomake?
or ?to cause?.
Although these light verbsthemselves do not convey any concrete meaning,they are often associated with several construc-tions to express emotions and at the same timeindicate the position of emotion causes.
For ex-ample, ?The birthday party made her happy?.One apparent difference between emotioncauses and general causes is that emotions areoften triggered by human activities or the per-ception of such activities, e.g., ?glad to say?
or?glad to hear?.
Those human activities are oftenstrong indicators for the location of emotion183causes.
Group IV and V are used to capture thiskind of information.
Group IV is a list of verbsof thinking and talking, and Group V includesfour types of epistemic markers which are usu-ally verbs marking the cognitive awareness ofemotions in the complement position.
The epis-temic markers include verbs of seeing, hearing,knowing, and existing.5.2 Linguistic PatternsWith the six groups of linguistic cues, we gen-eralize 14 rules used in Lee et al (2010b) tolocate the clause positions of an emotion cause,as shown in Table 4.
The abbreviations used inthe rules are given as follows:C = CauseK = Emotion keywordB = Clauses before the focus clauseF = Focus clause/the clause containing the emotionverbA = Clauses after the focus clauseTable 4: Linguistic rules for emotion cause de-tection (Lee et al 2010b)No.
Rules1 i) C(B/F) + III(F)  + K(F)ii) C = the nearest N/V before I in F/B2 i)  IV/V/I/II(B/F) + C(B/F) + K(F)ii) C = the nearest N/V before K in F3 i) I/II/IV/V (B) + C(B)  + K(F)ii) C = the nearest N/V after I/II/IV/V in B4 i) K(F) + V/VI(F) + C(F/A)ii) C = the nearest N/V after V/VI in F/A5 i) K(F)+II(A)+C(A)ii) C = the nearest N/V after II in A6 i) III(F) + K(F) + C(F/A)ii) C = the nearest N/V after K in F or A7 i) yue4 C yue4 K ?the more C the more K?
(F)ii) C = the V in between the two yue4?s in F8 i) K(F) + C(F)ii) C = the nearest N/V after K in F9 i) V(F) + K(F)ii) C = V+(an aspectual marker) in F10 i) K(F)  + de ?possession?
(F) + C(F)ii) C = the nearest N/V +?+N after de in F12 i) K(B) + IV (B) + C(F)ii) C = the nearest N/V after IV in F13 i) IV(B) + C(B) + K(F)ii) C = the nearest N/V after IV in B14 i) C(B) +  K(F)ii) C = the nearest N/V before K in BFor illustration, an example of the rule descrip-tion is given in Rule 1.Rule 1:i) C(B/F) + III(F) + K(F)ii) C = the nearest N/V before III in F/BRule 1 indicates that the cause (C) comes beforeGroup III cue words.
Theoretically, in identify-ing C, we look for the nearest verb/noun occur-ring before Group III cue words in the focusclause (F) or the clauses before the focus clause(B), and consider the clause containing thisverb/noun as a cause.
Practically, for each causecandidate, i.e.
?left_1?, if it contains thisverb/noun, we create a feature with?left_1_rule_1=1?.5.3 Generalized PatternsRule-based patterns usually achieve a ratherhigh accuracy, but suffer from low coverage.
Toavoid this shortcoming, we extract a generalizedfeature automatically according to the rules inTable 4.
The features are able to detect twokinds of constructions, namely functional con-structions, i.e.
rhetorical constructions, and spe-cific constructions for emotion causes.Local functional constructions: a cause occur-ring in the focus clause is often expressed withcertain functional words, such as ?because of?,?due to?.
In order to capture the various expres-sions of these functional constructions, we iden-tify all functional words around the given emo-tion keyword.
For an emotion keyword, wesearch ?left_0?
from the right until a noun or averb is found.
Next, all unigrams and bigramsbetween the noun or the verb and the emotionkeyword are extracted.
The same applies to?right_0?.Long-distance conjunction constructions:Group II enumerates only some typical conjunc-tion words.
To capture more general rhetoricalrelations, according to the given POS tags, theconjunction word is extracted for each causecandidate, if it occurs at the beginning of thecandidate.Generalized action and epistemic verbs:Group IV and V cover only partial action andepistemic verbs.
To capture possible related ex-pressions, we take the advantage of Chinesecharacters.
In Chinese, each character itself usu-ally has a meaning and some characters have astrong capability to create words with extendedmeaning.
For example, the character ?ting1-listen?
combines with other characters to create184words expressing ?listening?, such as ting1jian4,ting1wen5.
With the selected characters regard-ing reported verbs and epistemic markers, eachcause candidate is checked to see whether itcontains the predefined characters.6 ExperimentsFor the emotion cause corpus, we reserve 80%as the training data, 10% as the developmentdata, and 10% as the test data.
During evalua-tion, we first convert the multi-label tag output-ted from our system into a binary tag (?Y?means the presence of a causal relation; ?N?
in-dicates the absence of a causal relation) betweenthe emotion keyword and each candidate in itscorresponding cause candidates.
Thus, theevaluation scores for binary classification basedon three common measures, i.e.
precision, recalland F-score, are chosen.6.1 Linguistic Feature AnalysisAccording to the distribution in Table 1, we de-sign a naive baseline to allow feature analysis.The baseline searches for the cause candidatesin the order of <left_1, right_0, left_2, left_0,right_1>.
If the candidate contains a noun orverb, consider this clause as a cause and stop.We run the multi-label system with differentgroups of features and the performances areshown in Table 5.
The feature set begins withlinguistic patterns (LP), and is then incorporatedwith local functional constructions (LFC), long-distance conjunction constructions (LCC), andgeneralized action and epistemic verbs (GAE),one by one.
Since the ?N?
tag is overwhelming,we report only the Mac average scores for both?Y?
and ?N?
tags.In Table 5, we first notice that the perform-ances achieve significant improvement from thebaseline to the final system (~17%).
This indi-cates that our linguistic features are effective foremotion cause detection.
In addition, we ob-serve that LP and LFC are the best two effectivefeatures, whereas LCC and GAE have slightcontributions.
This shows that our feature ex-traction has a strong capability to detect localcausal constructions, and is yet unable to detectthe long-distance or semantic causal informa-tion.
Here, ?local?
refers to the information inthe focus clause.
We also find that incorporatingLFC, which is a pure local feature, generallyimproves the performances of all cause candi-dates, i.e.
~5% improvement for ?left_1?.
Thisindicates that our multi-label integrated systemis able to convey information among cause can-didates.Table 5: The overall performance with differentfeature sets of the multi-label systemPrecision Recall F-scoreBaseline 56.64 57.70 56.96LP 74.92 66.70 69.21+ LFC 72.80 71.94 72.35+ LCC 73.60 72.50 73.02+ GAE 73.90 72.70 73.26Table 6: The separate performances for ?Y?
and?N?
tags of the multi-label system?Y?
?N?Baseline 33.06 80.85LP 48.32 90.11+ LFC 55.45 89.24+ LCC 56.48 89.57+ GPE 56.84 89.68Table 6 shows the performances (F-scores)for ?Y?
and ?N?
tags separately.
First, we noticethat the performances of the ?N?
tag are muchbetter than the ones of ?Y?
tag.
Second, it is sur-prising that incorporating the linguistic featuressignificantly improves only the ?Y?
tag (from33% to 56%), but does not affect ?N?
tag.
Thissuggests that our linguistic features are effectiveto detect the presence of causal relation, and yetdo not hurt the detection of ?non_causal?
rela-tion.
For the ?Y?
tag, the features LP and LFCachieve ~15% and ~7% improvements respec-tively.
LCC and GPE, on the other hand, showslight improvements only.Finally, Table 7 shows the detailed perform-ances of our multi-label system with all features.The last row shows the overall performances of?Y?
and ?N?
tags.
For the ?Y?
tag, the closer thecause candidates are to the emotion keyword,the better performances the system achieves.This proves that the features we propose effec-tively detect local emotion causes, more effort,185Table 7: The detailed performance for the multi-label system including all features?Y?
tag Precision Recall F-score ?N?
tag Precision Recall F-scoreLeft_0 68.92 68.92 68.92 Left_0 93.72 93.72 93.72Left_1 57.63 63.35 60.36 Left_1 82.90 79.22 81.02Left_2 29.27 20.69 24.24 Left_2 89.23 92.93 91.04Right_0 67.78 64.89 66.30 Right_0 82.63 84.41 83.51Right_1 54.84 30.91 39.54 Right_1 92.00 96.90 94.38Total 58.84 54.98 56.84 Total 88.96 90.42 89.68Table 8: The detailed performance for the single-label system including all features?Y?
tag Precision Recall F-score ?N?
tag Precision Recall F-scoreLeft_0 65.39  68.92 67.11 Left_0 93.65  92.62 93.13Left_1 61.19  50.93 55.59 Left_1 79.64   85.60 82.51Left_2 28.57   20.69 24.00 Left_2 89.20   92.68 90.91Right_0 70.13   57.45 63.16 Right_0 80.30  87.63 83.81Right_1 33.33   40.00 36.36 Right_1 92.50   90.24 91.36Total 55.67   50.00 52.68 Total 87.85  90.08 88.95however, should be put on the detection oflong-distance causes.
In addition, we find thatthe detection of long-distance causes usuallyrelies on two kinds of information for inference:rhetorical relation and deep semantic informa-tion.6.2 Modeling AnalysisTo compare our multi-label model with single-label models, we create a single-label system asfollows.
The single-label model is a binaryclassification for a pair comprising the emotionkeyword and a candidate in its correspondingcause candidates.
For each pair, all linguisticfeatures are extracted only from the focusclause and its corresponding cause candidate.Note that we only use the features in the focusclause for ?left_0?
and ?right_0?.
The perform-ances are shown in Table 8.Comparing Tables 7 and 8, all F-scores ofthe ?Y?
tag increase and the performances ofthe ?N?
tag remain almost the same for both thesingle-label model and our multi-label model.We also find that the multi-label model takesmore advantage of local information, and im-proves the performances, particularly for?left_1?.To take an in-depth analysis of the cause de-tection capability of the multi-label model, anevaluation is designed that the label is treatedas a tag from the multi-label classifier.
Due tothe tag sparseness problem (as in Table 2), onlythe ?left_2, left_1?
tag is detected in the testdata, and its performance is 21% precision,26% recall and 23% F-score.
Furthermore, wenotice that ~18% of the ?left_1?
tags are de-tected through this combination tag.
Thisshows that some causes need to take into ac-count the mutual information between clauses.Although the scores are low, it still shows thatour multi-label model provides an effectiveway of detecting some of the multi-clausescauses.7 ConclusionWe treat emotion cause detection as a multi-label task, and develop two sets of linguisticfeatures for emotion cause detection based onlinguistic cues.
The experiments on the small-scale corpus show that both the multi-labelmodel and the linguistic features are able toeffectively detect emotion causes.
The auto-matic detection of emotion cause will in turnallow us to extract directly relevant informationfor public opinion mining and event prediction.It can also be used to improve emotion detec-tion and classification.
In the future, we willattempt to improve our system from two as-pects.
On the one hand, we will explore morepowerful multi-label classification models forour system.
On the other hand, we will investi-gate more linguistic patterns or semantic in-formation to further help emotion cause detec-tion.186ReferencesAbbasi, A., H. Chen, S. Thoms, and T. Fu.
2008.Affect Analysis of Web Forums and Blogs usingCorrelation Ensembles?.
In IEEE Tran.
Knowl-edge and Data Engineering, vol.
20(9), pp.
1168-1180.Bethard, S. and J. Martin.
2008.
Learning SemanticLinks from a Corpus of Parallel Temporal andCausal Relations.
In Proceedings of ACL.Descartes, R. 1649.
The Passions of the Soul.
In J.Cottingham et al (Eds), The Philosophical Writ-ings of Descartes.
Vol.
1: 325-404.Chang, D.-S. and K.-S. Choi.
2006.
Incremental cuephrase learning and bootstrapping method forcausality extraction using cue phrase and wordpair probabilities.
Information Processing andManagement.
42(3): 662-678.Chen, Y., S. Y. M. Lee and C.-R. Huang.
2009.
AreEmotions Enumerable or Decomposable?
AndIts Implications for Emotion Processing.
In Pro-ceedings of the 23rd Pacific Asia Conference onLanguage, Information and Computation.Girju, R. 2003.
Automatic Detection of Causal Re-lations for Question Answering.
In the 41st An-nual Meeting of the Association for Computa-tional Linguistics, Workshop on MultilingualSummarization and Question Answering - Ma-chine Learning and Beyond, Sapporo, Japan.James, W. 1884.
What is an Emotion?
Mind,9(34):188?205.Lee, S. Y. M., Y. Chen and C.-R. Huang.
2010a.
AText-driven Rule-based System for EmotionCause Detection.
In Proceedings of NAACL-HLT2010 Workshop on Computational Approaches toAnalysis and Generation of Emotion in Text.Lee, S. Y. M., Y. Chen, S. Li and C.-R. Huang.2010b.
Emotion Cause Events: Corpus Construc-tion and Analysis.
In Proceedings of LREC 2010.Low, B. T., K. Chan , L. L. Choi , M. Y. Chin , S. L.Lay.
2001.
Semantic Expectation-Based Causa-tion Knowledge Extraction: A Study on HongKong Stock Movement Analysis, In Proceedingsof the 5th Pacific-Asia Conference on KnowledgeDiscovery and Data Mining, p.114-123, April16-18.Marcu, D., and A. Echihabi.
2002.
An UnsupervisedApproach to Recognizing Discourse Relations.
InProceedings of ACL.Mihalcea, R. and H. Liu.
2006.
A Corpus-basedApproach to Finding Happiness.
In Proceedingsof the AAAI Spring Symposium on ComputationalApproaches to Weblogs.Persing, I. and V. Ng.
2009.
Semi-Supervised CauseIdentification from Aviation Safety Reports.
InProceedings of ACL.Plutchik, R. 1980.
Emotions: A PsychoevolutionarySynthesis.
New York: Harper & Row.Strapparava, C. and R. Mihalcea.
2008.
Learning toIdentify Emotions in Text.
In Proceedings of theACM Conference on Applied Computing ACM-SAC.Tokuhisa, R., K. Inui, and Y. Matsumoto.
2008.Emotion recognition Using Massive ExamplesExtracted from the Web.
In Proceedings of COL-ING.Wierzbicka, A.
1999.
Emotions across Languagesand Cultures: Diversity and Universals.
Cam-bridge: Cambridge University Press.187
