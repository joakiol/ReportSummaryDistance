The Use of Shared Forests in Tree Ad jo in ing Grammar  Parsing*K. Vijay-ShankerDepartment of Computer &Information SciencesUniversity of DelawareNewark, DE 19716USAvijay@udel.eduDavid J. WeirSchool of Cognitive &Computing SciencesUniversity of SussexFalmer, Brighton BN1 9QHUKdavidw@ cogs.
sussex, ac.ukAbstractWe study parsing of tree adjoining ram-mars with particular emphasis on the useof shared forests to represent all the parsetrees deriving a well-formed string.
Weshow that there are two distinct ways ofrepresenting the parse forest one of whichinvolves the use of linear indexed grammarsand the other the use of context-free gram-mars.
The work presented in this paper isintended to give a general framework forstudying tag parsing.
The schemes usinglig and cfg to represent parses can be seento underly most of the existing tag parsingalgorithms,1 IntroductionWe study parsing of tree adjoining rammars (tag)with particular emphasis on the use of shared foreststo represent all the parse trees deriving a well-formed string.
Following Billot and Lang \[1989\] andLang \[1992\] we use grammars as a means of recordingall parses.
Billot and Lang used context-free gram-mars (cfg) for representing all parses in a cfg parserdemonstrating that a shared forest grammar can beviewed as a specialization of the grammar for thegiven input string.
Lang \[1992\] extended this ap-proach considering both the recognition problem aswell as the representation f all parses and suggestshow this can be applied to tag.This paper examines this approach to tag pars-ing in greater detail.
In particular, we show that*We are very grateful to Bernard Lang for helpfuldiscussions.there are two distinct ways of representing the parseforest.
One possibility is to use linear indexedgrammars (lig), a formalism that is e~uivalent totag \[Vijay-Shanker and Weir, in pressa\].
The useof lig is not surprising in that we would expect o beable to represent parses of a formalism in an equiva-lent formalism.
However, we also show that there isa second way of representing parses that makes useofa cfg.The work presented in this paper is intended togive a general framework for studying tag parsing.The schemes using lig and cfg to represent parses canbe seen to underly most of the existing tag parsingalgorithms.We begin with brief definitions of the tag and ligformalisms.
This is followed by a discussion of themethods for cfg recognition and the representation fparses trees that were described in \[Billot and Lang,1989; Lang, 1992\].
In the remainder of the paper weexamine how this approach can be applied to tag.
Wefirst consider the representation f parses using a cfgand give the space and time complexity of recogni-tion and extraction of parses using this representa-tion.
We then consider the same issues where lig isused as the formalism for representing parses.
Weconclude by comparing these results with those forexisting tag parsing algorithms.2 Tree Adjoining GrammarsTa~ is a tree generating formalism introducedin \[Joshi et al, 1975\].
A tag is defined by a finiteset of elementary trees that are composed by meansof the operations of tree adjunction and substitution.In this paper, we only consider the use of the adjunc-tion operation.384Def in i t ion  2.1 A tag, G, is denotedG= (V,, VT,S,I,A)whereVjv is a finite set of nonterminals symbols,VT is a finite set of terminal symbols,S E V/v is the start symbol,I is a finite set of initial trees,A is a finite set of auxiliary trees.An in i t ia l  tree is a tree with root labeled by S andinternal nodes and leaf nodes labeled by nonterminaland terminal symbols, respectively.
An aux i l ia rytree is a tree that has a leaf node (the foot  node) thatis labeled by the same nonterminal that labels theroot node.
The remaining leaf nodes are labeled byterminal symbols and all internal nodes are labeledby nonterminals.
The path from the root node tothe foot node of an auxiliary tree is called the sp ineof the auxiliary tree.
An e lementary  tree is eitheran initial tree or an auxiliary tree.
We use a to referto initial trees and/3 for auxiliary trees.A node of an elementary tree is called an e lemen-ta ry  node  and is named with an e lementary  nodeaddress.
An elementary node address is a pair com-prising of the name of the elementary tree to whichthe node belongs and the address of the node withinthat tree.
We will assume the standard addressingscheme: the root node has an address c; if a nodewith address /~ has /?
children then the \]c children(in left to right order) have addresses p ?
1 , .
.
.
,  p .
k.Thus, for each address p we have p E A/'* where .hfis the set of natural numbers.
In this section we usep to refer to addresses and r I to refer to elementarynode addresses.
In general, we can write 1/=~ 7, Pwhere 7 is an elementary tree and p E dom (7) anddora (7) is the set of addresses of the nodes in 7.Let 7 be a tree with internal node labeled by anonterminal A. Let/3 be an auxiliary tree with rootand foot node labeled by the same nonterminal A.The tree, 7 ~, that results from the ad junct ion  of/3at the node in 7 labeled A is formed by removingthe subtree of 7 rooted at this node, inserting/3 inits place, and substituting it at the foot node of/3.Each elementary node is associated with a selec-t ive  ad jo in ing (SA) constraint that determines theset of auxiliary trees that can be adjoined at thatnode.
In addition when adjunction is mandatoryat a node it is said to have an ob l igatory  adjo in-ing (OA) constraint.
Whether/3 can be adjoined atthe node (labeled by A) in 7 is determined by the SAconstraint of the node.
In 7 t the nodes contributedby/3 have the same constraints as those associatedwith the corresponding nodes in/3.
The remainingnodes in 7 ~ have the constraints of the correspondingnodes in 7.Given p E dom(7), by Ibl(7,p) we refer to thelabel of the node addressed # in 7.
Similarly, we willuse sa(7, p) and oa(7, p) to refer to the SA and OAconstraints of a node addressed p in a tree 7.
Finally,we will use ft (/3) to refer to the address of the footnode of an auxiliary tree/3.adj (7, P,/3) denotes the tree that results from theadjunction of/3 at the node in 7 with address p. Thisis defined when fl E sa(7, p).
If adj (% #,/3) = 7 ~ thenthe nodes in 7 ~ are defined as follows.?
don ' , ( ' r ' )={Pl I plEdorn(7) andPl ~ P" P2 for some P2 E A f*}u (~-  m I 1,1 e dom(/3)}U {p. ft (/3)- Pl I P" P le  dom (7) and~ ~ ~}?
if Pl E dora (7) such that Pl ~ P "Pl for somePl E Af*, (i.e., the node in 7 with address Pl isnot equal to or dominated by the node addressedp in 7) then- I b l (7 ' ,~)  = Ib l (%~l) ,-- sa (~J , f /1 )  = sa( \ ]?
,~ i ) ,- oa(~ ' ,~d = oa(%m),?
if # .
Pl E dom (7') such that Pl E dom (/3) then- tbl(~', ~.
~)  = IbS(/3, ~d,- sa(~',  ~ .
~)  = sa(/3, ~) ,- o~(~',~ .~i) = o~( /3 ,~d,?
if p ?
ft(/3) ?
p~ E dora(7') such that p ?
Pl Edora (7) then- I~ l (~ ' ,~.
f t ( /3) .
~)  = mbK%~-m) ,- sa(-f', i'" ft ( /3).
l'~) = s~('r, ~," ~,~),- oa(7',p, ft (/3).
Pl) = oa(7,p.
Pl),In general, if p is the address of a node in 7 then< 7, P > denotes the elementary node address of thenode that contributes to its presence, and hence itslabel and constraints.The tree language, T(G), generated by a TAG, G,is the set of trees derived starting from an initial treesuch that no node in the resulting tree has an OAconstraint.
The (string) language, L(G), generatedby a TAG, G, is the set of strings that appear on thefrontier of trees in T(G).Example  2.1 Figure 1 gives a TAG, G, whichgenerates the language {wcw \[ w E {a,b}*}.
Theconstraints associated with the root and foot of/3specify that no auxiliary trees can be adjoined atthese nodes.
This is indicated in Figure 1 by as-sociating the empty set, ~, with these nodes.
Anexample derivation of the strings aca and abeab isshown in Figure 2.385s {pz~2} IZz s OI '% {P'"}SO ap2 soAb S {pZ,p2}sO bFigure 1: Example of a TAG Gi lplp2}?/t s0?
//~,elS,zSO ?I?$0Ab$o bSO aI?Figure 2: Sample derivations in G3 L inear  Indexed GrammarsAn indexed grammar \[Aho, 1968\] can be viewed asa cfg in which objects are nonterminals with an as-sociated stack of symbols.
In addition to rewritingnonterminals, the rules of the grammar can have theeffect of pushing or popping symbols on top of thestacks that are associated with each nonterminal.In \[Gazdar, 1988\] a restricted form of indexed gram-mars was discussed in which the stack associatedwith the nonterminal on the left of each productioncan only be associated with one of the occurrences ofnonterminals on the right of the production.
Stacksof bounded size are associated with other occurrencesof nonterminals on the right of the production.
Wecall this linear indexed grammars (lig}.
Lig generatethe same class of languages as tag \[Vijay-Shankerand Weir, in pressa\].Definit ion 3.1 A LIG, G, is denotedG = ( Vjv , VT , VI , S, P )whereVlv is a finite set of nonterminals,VT is a finite set of terminals,VI is a finite set of indices (stack symbols),S ?
VN is the start symbol, andP is a finite set of productions.Given a lig, G = (V~?, VT, VI, S, P), we define theset of objects of G asVc(G) = { A\[a\] \[A ?
VN and cr ?
V~* }We use A\[oo a\] to denote the nonterminal A associ-ated with an arbitrary stack with the string a on topand A\[\] to denote that an empty stack is associatedwith A.
We use T to denote strings in (Vc(G)UVT)*.The general form of a lig production is:A\[oo a\] ---* TB\[oo a'\]T'where A, B e VN, a, a' G VI* and T, T' G (Vc(C)UVT)*.Given a grammar, G = (V1v, VT, VI, S, P), thederivation relation, o=~, is defined such that ifA\[oo a\] --~ TB\[oo a'\]T' G Pthen for every f le  V\[ and TI,T2 ?
(Vc(G) U VT)*:T1AL0 \]T T1TB\[Z '\]T'TAs a result of the linearity in the rules, the stack~/a associated with the object in the left-hand side ofthe derivation and the stack j3cJ associated with oneof the objects in the right-hand side have the initialpart fl in common.
In the derivation above, we saythat the object BLSa' \] is the dist inguished child ofALSa \].
Given a derivation, the dist inguished de-scendant relation is the reflexive, transitive closureof the distinguished child relation.The language generated by a lig, G is:where ~ denotes the reflexive, transitive closureGof ~.GExample 3.1 The language{ wcw i w e {a,b}* }is generated by the ligG = ({S ,T} ,{a ,b ,c} ,{7a ,7b},S ,P )where P contains the following productions.S\[oo \] -*  aS\[oo 7.\] S\[oo \] -~ bS\[oo 7b\]S\[oo \] --~ T\[oo \] T\[oo 7a\] -+ T\[oo \]aT\[oo 7b \] --* T\[oo\]b T\[\] --* cThis grammar generates the string abcab as follows.S\[\] ~ aSbo \]G===# abS\[TaTb \]G==~ abT\[Ta 7b\] OabT\[Ta\]bG==*.
abT\[\]abGabcabG3864 Parsing as Intersection withRegular LanguagesIn the case of cfg parsing, \[Billot and Lung, 1989;Lang, 1992\] show that a cfg can be used to encode allof the parses for a given string.
For example, let Gobe a grammar and let the string w = al .
.
.
an be inL(Go).
All parses for the string w can be representedby the shared forest grammar G~.
The nonterminalsin Gw are of the form (A, i, j )  where A is a nonter-minal of Go and 0 < i < j < n. The construction ofG~0 is such that any derivation from (A, i, j )  encodesa derivationA ::~ ai+l...ajOoFor instance, suppose A .--, BC is a production inGo that is used in the first step of a derivation of thesubstring ai+l...a/ from A.
Corresponding to thisproduction, Gw contains a production(A, i,j) -.-* (B, i, k)(C, k,j)for each 0_< i< k < j < n. This can be used toencode all parses of ai+x .
.
.
aj from A whereB ::~ ai+l...a~ and C -~ a~+t .
.
.a jIn general, corresponding to a productionA -+ X1 .
.
.Xrin Go the grammar G~ contains a production(A, i l , j ,) --* (X1, i l , j l ) .
.
.
(X,, it, j,)for every i l , j l , .
.
.
, i , , j~ E { 1 , .
.
.
,n}  such that foreach 1 _< k < r if X~ E VT then ik + 1 = jk, otherwiseik+l  < jk.
Additionally, G~ includes the production(a~,k,k + l) --, a~for each 1 < k < n.Note that the number of nonterminals in theshared forest grammar, Gw, is O(n 2) and the num-ber of productions is O(n re+l) where Iw I = n andm is the maximum number of nonterminals in theright-hand-side of a production in Go.
Therefore, ifthe object grammar were in Chomsky normal form,the number of productions i O(nZ).Lung \[1992\] extended this by showing that parsinga string w according to a grammar G can be viewedas intersecting the language L(G) with the regularlanguage {w }.
Suppose we have an object context-free grammar Go and some deterministic finite stateautomaton M. For the sake of simplicity, let us as-sume that Go is in Chomsky normal form.
The stan-dard proof that context-free languages are closed un-der intersection with regular languages, constructs acontext-free grammar for L(Go) f3 L(M) with a pro-duction(A,p, q) - .
(B,p, r)(C, r, q)for each production A --~ BC of Go and statesp, q, r of M. Also for each terminal a the production(a,p, q) --~ a will be included if and only if 6(p, a) = qwhere/~ is the transition function of M.Lung \[1992\] applied this to cfg recognition as fol-lows.
Given an input, w - a l .
.
.an ,  define the dfaM~ such that L(M~ ) - { w }.
The state set of Mw is{ 0, 1 , .
.
.
,n  }; the transition function 5 is such that6(i, ai+l) = i + 1 for each 0 _< i < n; 0 is the ini-tial state; and n is the final state.
The shared for-est grammar G~ is obtained when the standard in-tersection construction described above is applied toGo and Mw.
Furthermore, since L(Gw) = L(Go) NL(M,~) and L(M,~) = {w}, we have w E L(Go) ifand only if L(G,~) is not the empty set.
That is, theoriginal recognition problem can be turned into oneof generating the shared forest grammar, Gw, anddeciding whether the start nonterminal, (S, 0, n), ofGw is an useful symbol, i.e., whether there is someterminal string z such that(S,0, n) =~xOwHere S has been taken to be the start nonterminal ofGo.
Note that Gw can be constructed in O(n s) timeand "recognition" can also be accomplished withinthis time bound.One advantage that arises from viewing parsingas intersection with regular languages i that exactlythe same algorithm can be given a word net (a reg-ular language that is not a singleton) rather than asingle word as input.
This could be useful if we wishto deal with ill-formed inputs.5 Derivation versus Derived Trees inTAGFor grammar formalisms involving the derivation oftrees, a tree is called a der ived  tree with respect o agiven grammar if it can be derived using the rewrit-ing rules of the grammar.
A der ivat ion  tree of thegrammar, on the other hand, is a tree that encodesthe sequence of rewritings used in deriving a derivedtree.
In the case of cfg, a tree that is derived containsall the information about its derivation and there isno need to distinguish between derivation trees andderived trees.
This is not always the case.
In par-ticular, for a tree-rewriting system like tag we needto distinguish between derived and derivation trees.In fact there are at least two ways one can encodetag derivation trees.
The first (see \[Vijay-Shanker,1987\]) captures the fact that derivations in tag areconte~t-free, i.e., the trees that can be adjoined ata node can be determined a priori and are not de-pendent on the derivation history.
We capture thiscontext-freeness by giving a cfg to represent the setof all possible derivation sequences in a tag.
An al-ternate scheme uses a tag or a lig (see \[Vijay-Shanker387and Weir, in pressb\]) to represent the set of all pos-sible derivations.We briefly consider the first scheme to show howgiven a tag, Go and a string, w, context-free gram-mar can be used to represent shared forests.
In latersections we will study the second scheme using ligfor shared forests.6 Us ing  CFG fo r  Shared  Fores tsGiven a TAG,Go = (VN, VT,S , I ,A)and a string w - ax .
.
.an  we construct a context-free grammar, Gto such that L(G,~) ~ d~ if and onlyif w E L(Go).
Let M~ be the dfa for w described inSection 4.Consider a tree fl that has been derived from someauxiliary tree in A.
Let the string on the frontier offl that is to the left of the foot node be us and thestring to the right of the foot node be ur.
Considerthe tree that results from the adjunction of/3 at anode in with elementary node address I T/where v isthe string on the frontier of the subtree rooted at ,7.After adjunction the strings us and ur will appear tothe left and right (respectively) of v.Suppose that in a derivation of the string w bythe grammar Go the strings ul and ur form twocontinuous ubstrings w: i.e., uz = ai+l.. .ap andur = aq+l.. .aj  for some 0 < i < p< q < j < n.Thus, according to the definition of M~ we wouldhave ~(i, us) = p and 6(q, ur) = j.
Hence, we canuse the four states i, j, p and q of Mr0 to account forwhich parts of w are spanned by the frontier of ft.Since the string appearing at the subtree rooted at7/is v then if 6(p, v) = q we have 6(i, usvur) = j andp and q identify the substring of w that is spanned bythe subtree rooted at 7/.
However, the node T/may beon the spine of some auxiliary tree, i.e., on the pathfrom the root to the foot node.
In that case we willhave to view the frontier of the subtree rooted at r/as comprising two substrings, say vl and vr to theleft and right of the foot node, respectively.
The twostates p, q of Mw are do not fully characterize thefrontier of subtree rooted at I/.
We need four states,sayp, q, r, s, where 6(p, vs ) = r and 6( s, vr ) = s. Notethat the four states in question only characterize thefrontier of subtree rooted at T/ before the adjunctionof fl takes place.
The four states i, j, r, s characterizethe situation after adjunction of fl since 6(i, ut) = p,6(p, vz) = r (therefore 6(i, ulvl) = p) and 6(s, vrur ) =6(q, u~) = j.In the shared forest cfg Gw the derivation of the1Rather than repeatedly saying a node with an ele-mentary node address y/, henceforth we simply refer to itas the node 7/.string at frontier of tree rooted at ~/before adjunc-tion will be captured by the use of a nonterminal ofthe form ( l ,  rhp, q,r,s ) and the situation after ad-junction will be characterized by (T, T/, i , j ,  r, s).
Weuse the symbols T and .L to capture the fact thatconsideration of a node involves two phases: (i) theT part where we consider adjunction at a node, and(ii) the I part where we consider the subtree rootedat this node.
Note that the states r, s are only neededwhen 0 is a node on the spine of an auxiliary tree.When this is not the case we let r = s = - .Since we have characterized the frontier of fl (i.e.,the subtree rooted at the root/), the root of fl) bythe four states i, j, p, q, we can use the nonterminal(T, roots, i, j, p, q) and can capture the derivation in-volving adjunction of/3 at ~/by a production of theform(T, 'I, i, j, r, s) --~ (T, root/), i, j, p, q) (1, r h p, q, r, s)Without further discussion, we will give the pro-ductions of Gw.
For each elementary node 7/do thefollowing.Case 1: When 7/is a node that is labeled by a ter-minal a, add the production(T, Ti, p ,q , - , - ) - - ,  aif and only if 6(p, a) = q.Case 2a: Let T}I and T/2 be the children of ~1 and theleft-child zh dominates the foot node then add theproduction(l,TI, i , j ,p,q)-- .
(T, Th, i , k ,p ,q ) (T ,~,k , j , - , -  )if neither children dominate the foot node then addthe production(.L, rhi, j , - , - )  --* ( r ,  ql, i , k , - , - ) (Y ,  rl2, k , j , - , - )Case 2b: Let 7/1 and 02 be the children of r/and theright-child 7/2 dominates the foot node then add theproduction(?,Ti, i, j ,p,q)--~ (T, T Iy , i , k , - , - ) (T ,  Tl2, k, j ,p,q)Case 3: When 7/is a nonterminal node that doesnot have an OA constraint, then to capture the factthat it is not necessary to adjoin at this node, weadd(T, Th i, j,p,q)--~ (?,lh i, j ,p,q)Case 4a: When 0 is a node where fl can be adjoinedand root/) is the root node of fl add the production(T,~I,i , j ,r,s)--* (T, root/),i, j,p,q)(.L,~I,p,q,r,s)Case 4b: When r/is the foot node of the auxiliarytree/3 add the production( l ,~hP, q,p,q)--*?388If t / is the root of an initial tree then add the pro-ductionS --~ (T, r/, O, n , - , - ) .where S is the start symbol of Gw.Note that (cases 2a and 2b) we are assuming bi-nary branching merely to  simplify the presentation.We can use a sequence of binary cfg productions toencode situations where t /has more than two chil-dren.
That is, even if the object-level grammar wasnot binary branching, the shared forest grammar canstill be.Note that since the state set of Mw is {0, .
.
.
,  n},the number of nonterminals in Go is O(n4).
Sincethere are at most three nonterminals in a production,there are at most six states involved in a production.Therefore, the number of productions is O(n 6) andconstruction of this grammar takes O(n 6) time.
Al-though the derivations of Gto encode derivations ofthe string w by Go the specific set of terminal stringsthat is generated by G,o is not important.
We dohowever have L(G~) # ~b if and only if w E L(Go).As before, we can determine whether L(G~) # ~ bychecking whether the start nonterminal S is useful.Furthermore this can be detected in time and spacelinear to the size of the grammar.
Since w E L(Go)if and only if L(Gto) # (h, recognition can be done inO(n 6) time and space.Once we have found all the useful symbols in thegrammar we can prune the grammar by retainingonly those productions that have only useful sym-bols.
Since Gto is a cfg and since we can now guar-antee that every nonterminal can derive a terminalstring and therefore using any production will yielda terminal string eventually, the derivations of w inGo can be read off by simply reading off derivationsin Gw.7 Us ing  L IG  fo r  Shared  Fores tsWe now present an alternate scheme to represent thederivations of a string w from a given object taggrammar Go.
In later sections how how it can beused for solving the recognition problem and how asingle parse can be extracted.The scheme presented in Section 6 that produceda cfg shared forest grammar captured the context-freeness of tag derivations.
The approach that wenow consider captures an alternative view of tagderivations in which a derivation is viewed as sen-sitive to the derivation history.
In particular, thecontrol of derivation can be captured with the use ofadditional stack machinery.
This underlies the useof lig to represent the shared forests.In order to understand how a lig can be used to en-code a tag derivation, consider a top-down derivationin the object grammar as follows.
A tag derivationcan be seen as a traversal over the elementary treesbeginning at the root of one of the initial trees.
Sup-pose we have reached some elementary node t/.
Wemust first consider adjunction at t/ and after thatwe must visit each of t/'s subtrees from left to right.When we first reach 7/we say that we are in the topphase of 1/.
The derivation lig encodes this with thenonterminal T associated with a stack whose top el-ement is t/.
After having considered adjunction at r/we are in the bottom phase of 7/.
The derivation ligencodes this with the nonterminal _L associated witha stack whose top element is 7/.When considering adjunction at r/we may have achoice of either not adjoining at all or selecting someauxiliary tree to adjoin.
If the former case we movedirectly to the bottom phase of r/.
In the latter casewe move to (visit) the root of the auxiliary tree f/that we have chosen to adjoin.
Once we have finishedvisiting the nodes of f/(i.e., we have reached the footof 3) we must return to (the bottom phase of) t/.Therefore, it is necessary, while visiting the nodesin ~ to store the adjunction node t/.
This can bedone by pushing ~/onto the stack at the point thatwe move to the root of ~.
Note that the stack maygrow to unbounded length since we might adjoin ata node within ~, and so on.
When we reach thebottom phase of foot node of 3 the stack is poppedand we find the node at which 3 was adjoined at thetop of the stack.gFrom the above discussion it is clear that the ligneeds just two nonterminals, T and _L.
At each stepof a derivation in the lig shared forest grammar thetop of the stack will specify the node being currentlybeing visited.
Also, if the node r/being visited be-longs to an auxiliary tree and is on its spine we canexpect he symbol below the top of the stack to giveus the node where 3 is adjoined.
If r/is not on thespine of an auxiliary tree then it is the only symbolon the stack.We now show how the lig shared forest grammarcan be constructed for a given string w = at .
.
.an.Suppose we have a tagGo = (VN, VT, S,I,A)and the dfaMw "- (VN,Q, qo, if, F)as defined in Section 4.
We construct he ligV~ = (Vk, Vr, V~,S',P)that generates the intersection of L(G) and L(Mw).P includes the following set of productions for thestart symbol S'iS ' \ [ \ ]  .---, (T, qo, q/)\[r/\] I q; e F andt/ is root of  initial treeIn addition, for each elementary node t /do  the fol-lowing.389Case 1: When , is a node that is labeled by a ter-minal a P includes the production(T, p, q)\[ti\] ~ afor each p, q E Q such that q E 6(p, a).Case 2a: When ti1 and .2 are the children of a node.
such that the left sibling ti1 is on the spine or nei-ther child is on the spine, P includes the production( / ,  p, q)\[oo .\] ~ (T, p, r)\[oo .1\] (T, r, q)\[.2\]for each p, q, r E Q.
Note that the stack of adjunctionpoints must be passed to the ancestor of the footnode all the way to the root.Case 2b: When ti1 and ~/~ are the children of anode ~/such that the right sibling T/2 is on the spineP includes the production(_L, p, q)\[oo .\] ~ (T, p, r)\[ti1\] (T, r, q)\[oo .2\]for each p, q, r E Q.Case 3: When r} is a nonterminal node that does nothave an OA constraint P includes the production(T,p, q)\[oo.\] --~ (_L,p, q)\[oo 7/\]for each p, q E Q.
This production is used when noadjunction takes place and we move directly betweenthe top and bottom phases of 77.Case 4a: When ti is a node where fl can be adjoinedand ti~ is the root node of/~ P includes the production(T, p, q)\[oo ti\] --~ (T, p, q)\[oo r/ti'\]for each p, q E Q.
Note that the adjunction ode tihas been pushed below the new node rf on the stack.Case 4b: When t} is a node where 77 can be adjoinedand 171 is the foot node offl P includes the production( / ,  p, q)\[oo ti.
'\] --~ (_L, p, q)\[oo .\]for each p, q E Q.
Note that the stack symbol thatappeared below ti will be the node at which fl wasadjoined.Since the state set of Mw is (0 , .
.
.
,n}  there areO(n 2) nonterminals in the grammar.
Since at mostthree states are used in the productions, M~ hasO(n 3) productions.
The time taken to construct thisgrammar is also O(n3).
As in the cfg shared forestgrammar constructed in Section 6 we have assumedthat the tag is binary branching for sake of sim-plifying the presentation.
The construction can beadapted to allow for any degree of branching throughthe use of additional (binary) lig productions.
Fur-thermore, this would not increase the space complex-ity of the grammar.
Finally, note that unlike the cfgshared forest grammar, in the lig shared forest gram-mar Gt0, w is derived in Go if and only if w is derivedin Gt,.
Of course in both cases L(Gt,) = {w}NL(Go)and hence the recognition problem can be solved bydetermining whether the shared forest grammar gen-erates the empty set or not.8 Removing Useless SymbolsAs in the case of the cfg shared forest grammar, tosolve the original recognition problem we have to de-termine if L(G~) ~ ?.
In particular, we have to de-termine whether S~\[\] derives a terminal string.
Wesolve this question by construcing an nfa, Ma~, fromGto where the states of Ma .
correspond to the non-terminal and terminal symbols of Gw.
This trans-forms the question of determining whether a symbolis useful into a reachibility question on the graph ofMa.
.
In particular, for any string of stack symbols% the object A\[7\] derives a string of terminals if andonly if it is possible, in the nfa Ma.., to reach a fi-nal state from the state corresponding to A on theinput 7.
Thus, w e L(Go) if and only if S'\[\] ::~ wGwif and only if in Ma.
a final state is reachable fromthe state corresponding to S ~ on the empty string.Given a lig Gw = (V2v, TIT, VI,S', P) we constructthe nfa Ma.
= (Q, E, 6, q0, F) as follows.
Let thestate set of M be the nonterminal and terminal al-phabet of Gw: i.e., Q = VN U VT.
The initial stateof MG,.
is the start symbol of Gw, i.e., q0 - S'.
Theinput alphabet of MG,.
is the stack alphabet of G,,:i.e., E = VI.
Note that since Gw is the lig sharedforest the set VI is the set of the elementary nodeaddresses of the object tag grammar Go.
The set offinal states, F, of MG,.
is the set VT.
The transitionfunction 6 of Ma .
is defined as follows.Case 1: If P contains the productionA\[ti\]then add a to 6(A, tl).Case 2a: If P contains the productionA\[oo .\] --* B\[oo ~h\]C\[.2\]then if 6(C, 172) n F ?
?
and D E 6(B, .1) add D to6(A, 7/).Case 2b: The case where P contains the productionA\[oo .1 ~ C\[,~\]B\[oo ti1\]is similar to Case 2a.Case 3: If P contains the productionA\[oo .\] ---* B\[oo .\]then if C E 6(B, ~}) add C E 6(A, ti).Case 4a: If P contains the productionA\[oo ~/\] --.
B\[oo .rf\]then for each C such that C E 6(B, tf) and each Dsuch that D e 6(C, ~}) add D to 6(A, 77).Case 4b: If P contains the productionA\[oo tit/' \] --* B\[ti\]then add B to 6(A, 71').390Case 5: If P contains the productionS'\[\] ---* A\[~T\]then if B e 6(A, 7) add B to ~f(S', e).Given that w = a l .
.
.an  and that the nontermi-nals (and corresponding states in Ma,.)
of Gw are ofthe form (T , i , j )  or (.
l .
, i , j) where 0 < i < j < n,there are O(n 2) nonterminals ( tates in Mto) inthelig Gw.
The size of Maw is O(n 4) since there areO(n 2) out-transitions from each state.We can use standard ynamic programming tech-niques to ensure that each production is consideredonly once.
Given such an algorithm it is easy to checkthat the construction of Ma,.
will take O(n s) time.The worst case corresponds to case 4a which will takeO(n 4) for each production.
However, there are onlyO(n 2) such productions (for which case 4a applies).Once the nfa has been constructed the recognitionproblem (i.e., whether w e L(Go)) takes O(n 2) time.We have to check if there is an e-transition from theinitial state to a final state and hence we will haveto consider O(n 2) transitions.A straightforward algorithm can be used to removethe states for nonterminals that do not appear in anysentential form derived from S I.
In other words, onlykeep states uch that for some 3' there is a derivationS\[\] ~ TIA\[TIT2for some TIT2 E (Vv(Gu,) U VT)*.Note that the states to be removed are not thosestates that are not reachable from the initial stateof Me, .
The set of states reachable from the initialstate includes only the set of nonterminals in objectsthat are the distiguished descendent of the root nodein some derivation./,From the construction of Mew it is that case thatfor each A E VN the set{ 3' l a e/~(A, 3') for some a 6 F }is equal to the setThus, if a final state is accessible from a state .4then for some 3' (that witnesses the accessibility of afinal state from .4).413'1for some z E V~.Once the construction of Me,  is complete we onlyretain those productions in Gw that involve nonter-minals that remain in the state set of of Me , .
IIow-ever, unlike the case of the cfg shared forest gram-mar, the extraction of individual parses for the inputw does not simply involve reading off a derivation ofGw.
This is due to the fact that although retain-ing the state A does mean that there is a derivationS\[\] =~ TIA\[7\]T2 for some 3' and TIT2, we canQwnot guarantee that A\[7\] will derive a string of ter-minals.
The next section describes how to deal withthis problem.9 Recovery  o f  a ParseLet the lig Gw with useless productions removed be= ( VN , VT , VI , S '  , P )and let the nfa Maw constructed in Section 8 withunnecessary states removed beMaw = (VN U VT, V1,5, S', VT)Recovering a parse of the string w by the objectgrammar Go has now been converted into the prob-lem of extracting one of the derivations of Gw.
How-ever, this is not entirely straightforward.The presence of a state A in V N \[.J VT indicates thatfor some 7 in V\[ and T1, T~ in (Vc(Gw) U liT)* wehaveS'\[\] ~ T1A\[TIT2However, it is not necessarily the case that $(A, 7)f3lit i~ ?, i.e., it might not be possible to reach a finalstate of Ma,, from A with input 7.
All we know isthat there is some 3 / E V/* (that could be distinctfrom 7) such that A\[7' \] derives a terminal string,i.e., at least one final state is accessible from A onthe string 7'.This means that in recovering a derivation of Gwby considering the top-down application of produc-tions we must be careful about which production wechoose at each stage.
We cannot assume that anychoice of production for an object, A\[7\] will eventu-ally lead to a complete derivation.
Even if the topof the stack 3' is compatible with the use of a pro-duction, this does not guarantee that A\[3'\] derives aterminal string.We give an procedure recover that can be used torecover a derivation of G~ by using the nfa Ma.
.This procedure guarantees that when we reach astate A by traversing a path 3' from the initial statethen on the same string 3' a final state can be reachedfrom the state A.If recover(T1 .
.
.
T,a) is invoked the following hold..n~l?
aEVT?
T~ -- (Ai,~i) where Ai E VN and ~i E ~ foreach 1 < i < n?
recover(T1...Tnql) returns a derivation from391?
St\[\] =:~ ZAl\[qn ...t/1\]y for some z, V6 V~ G.?
Al \[t / , .
.
.
t / l \ ]  =~ Tx,tA2\[t/n...rl~lTl,rGwTn-l,tA,\[t/n\]Tn-l,r O~$-----f Tn,taTn,r Ou~?
6(Ai,t/n...t/i) = a for each 1 < i < n,To recover a parse we call recover(((-r, 1, n), ,j)a)where a E liT such that 6((T, 1, n), O) = a and T/6 litis the root of some initial tree.
The definition ofrecover  is as follows.Procedure recover((A 1, t/1)7"2... Tn a)Case 1: If n = 1 andp = Al\[t/1\] --* a ?
Pthen output p. Note there must be such a productionCase 2a: If there is some productionp = Al\[oo t/l\] -~ B\[oo t'\] C\[V'\] ?
Psuch that 6(C, 1") = b for some b ?
VT, and eithern > 1 and A2 ?
~(B,l') (where T2 = (A2,t/2)) orn = 1 and a ?
6(B, 1') then outputp.
recover((B, I')T2... Tna).
recover((C, l")b)Case 2b: If there is some productionp = Al\[oo y,\] -~ C\[l"\] B\[oo I'\] ?
Psuch that 6(0, l") = b for some b ?
VT and eithern > 1 and A2 ?
6(S,l ')  (where T2 = (A2,t/2)) orn = 1 and a ?
6(B, i') then outputp.
recover((B, l ')T2... Tna).
recover((C,/")b)Case 3: If there is some productionp = Al\[OO t/l\] ---* B\[oo 1'\] ?
Psuch that either n > 1 and A2 ?
6(B,l') (whereT2 = (A2, t/2)) or n = 1 and a ?
6(B, l') then outputp.
recover((B, l' )T2 .
.
.
Tna)Case 4a: If there is some productionp = Ax\[oo 71\] ~ B\[oo y21'\]inPsuch that C ?
6(B, l ~) for some C ?
VN and A2 ?6(C, th) and either n > 1 and T~ = (A2, t/z) or n = 1and a ?
6(C, t/l) then outputp.
recover((B, l' )( C, t/l )T2  .
.
.
T ,  a )Case 4b: If there is a productionp = Al\[oo t/2t/1\] ---* A~\[oo y~\] ?
Psuch that n > 1 and T2 = (Az,y2) then outputp.
recover(T2... T,)Given the form of the nonterminals and produc-tions of Gto we can see that the complexity of ex-tracting a parse as above is dominated by the com-plexity by Case 4a which takes O(n 4) time.
If inGo every elementary tree has at least one terminalsymbol in its frontier (as in a lexicalized tag) thento derive a string of length n there can beat  most nadjunctions.
In that case, when we wish to recovera parse the derivation height (which gives recursiondepth of the the invocation of the above procedure)is O(n) and hence recovery of a parse will take O(n 5)time.10 Conc lus ionsWe have shown that there are two distinct ways ofrepresenting the parses of a tag using lig and cfg.?
The cfg representation captures the fact that thechoice of which trees to adjoin at each step of aderivation is context-free.
In this approach thenumber of nonterminals i O(n4), the numberof productions is O(n 6) and, hence, the recog-nition problem can be resolved in O(n 6) timewith O(n 4) space.
Note that now the prob-lem of whether the input string can be derivedin the tag grammar is equivalent o decidingwhether the shared forest cfg obtained generatesthe empty language or not.
Each derivation ofthe shared forest cfg represents a parse of thegiven input string by the tag.?
In the scheme that uses lig the number of non-terminals is O(n 2) and the number of produc-tions is O(n3).
While the space complexity ofthe shared forest is more compact in the caseof lig, recovering a parse is less straightforward.In order to facilitate recovery of a parse as wellas to solve the recognition problem (i.e., deter-mine if the language generated by the sharedforest grammar is nonempty) we use an aug-mented data structure (the nfa, Me , ) .
Withthis structure the recognition problem can again6 4 be resolved in O(n ) with O~n ) space and theextraction of a parse has O(n ~) time complexity.The work described here is intended to provide ageneral framework that can be used to study andcompare xisting tag parsing algorithms (for exam-ple \[Vijay-Shanker and Joshi, 1985; Vijay-Shankerand Weir, in pressb; Schabes and Joshi, 1988\]).
Ifwe factor out the particular dynamic programmingalgorithm used to determine the sequence in whichthese rules are considered then the productions ofour cfg and lig shared forest grammars encapsulatethe steps of all of these algorithms.
In particular,the algorithm presented in \[Vijay-Shanker and Joshi,1985\] can be seen to corresponds to the approach in-volving the use of cfg to encode derivations, whereas,the algorithm of \[Vijay-Shanker and Weir, in pressb\]392uses lig in this role.
Although the space complexityof the cited parsing algorithms is O(n4), the datastructures used by them do not explicitly give theshared forest representation provided by our sharedforest grammars.
The data structures would haveto be extended to record how each entry in the tablegets added.
With this kind of additional informationthe space requirements of these algorithms would be-come O(n6).It is perhaps not surprising that the lig shared for-est and cfg shared forest described here turn outto be closely related.
In the nfa MG, (after use-less symbols have been removed) we have (B,p, q) Edf((A, i,j), ri) if and only if in the cfg shared forest(A, r/, i, j, p, q) is not a useless ymbol.
In addition,there is a close correspondence b tween productionsin the two shared forest grammars.
This shows thatthe two schemes result in essentially the same algo-rithms that store essentially the same information inthe tables that they build.We end by noting that Lang \[1992\] also considerstag parsing with shared forest grammars, however,he uses the tag formalism itself to encode the sharedforest.
This does not utilize the distinction betweenderivation and derived trees in a tag.
The algorithmspresented here specialize the derivation tree Gram-mar to get shared forest whereas Lang \[1992\] spe-cializes object grammar itself.
As a result, in or-der to get O(n 6) time complexity Lang must assumethe object grammar tree in a very restricted normalform.\[Vijay-Shanker and Joshi, 1985\]K. Vijay-Shanker and A. K. Joshi.
Some compu-tational properties of tree adjoining grammars.
In23 rd meeting Assoc.
Comput.
Ling., pages 82-93,1985.\[Vijay-Shanker and Weir, in pressa\]K. Vijay-Shanker and D. J. Weir.
The equiva-lence of four extensions of context-free grammars.Math.
Syst.
Theory, in press.\[Vijay-Shanker and Weir, in pressb\]K. Vijay-Shanker and D. J. Weir.
Parsing con-strained grammar formalisms.
Comput.
Ling., inpress.\[Vijay-Shanker, 1987\] K. Vijay-Shanker.
A Study ofTree Adjoining Grammars.
PhD thesis, Universityof Pennsylvania, Philadelphia, PA, 1987.References\[Aho, 1968\] A. V. Aho.
Indexed grammars - -  Anextension to context free grammars.
J. ACM,15:647-671, 1968.\[Billot and Lang, 1989\] S. Billot and B. Lang.
Thestructure of shared forests in ambiguous parsing.In 27 th meeting Assoc.
Comput.
Ling., 1989.\[Gazdar, 1988\] G. Gazdar.
Applicability of indexedgrammars to natural anguages.
In U. Reyle andC.
Rohrer, editors, Natural Language Parsing andLinguistic Theories.
D. Reidel, Dordrecht, Hol-land, 1988.\[Joshi et al, 1975\] A. K. Joshi, L. S. Levy, andM.
Takahashi.
Tree adjunct grammars.
J. Corn-put.
Syst.
Sci., 10(1), 1975.\[Lang, 1992\] B. Lang.
Recognition can be harderthan parsing.
Presented at the Second TAG Work-shop, 1992.\[Schabes and Joshi, 1988\] Y. Schabes and A. K.Joshi.
An Earley-type parsing algorithm for treeadjoining rammars.
In 26 th meeting Assoc.
Com-pat.
Ling., 1988.393
