LEXICO-SEMANTIC  PATTERN MATCHINGAS A COMPANION TO PARSING IN TEXT UNDERSTANDINGPaul S. Jacobs, George R. Krupka and Lisa F. RauArtificial Intelligence LaboratoryGE Research and DevelopmentSchenectady, NY 12301ABSTRACTOrdinarily, one thinks of the problem of natural language un-derstanding as one of making a single, left-to-right pass throughan input, producing a progressively refined and detailed interpre-tation.
In text interpretation, however, the constraints of strictleft-to-right processing are an encumbrance.
Multi-pass meth-ods, especially by interpreting words using corpus data and as-sociating units of text with possible interpretations, can be moreaccurate and faster than single-pass methods of data extraction.Quality improves because corpus-based data and global contexthelp to control false interpretations; speed improves because pro-cessing focuses on relevant sections.The most useful forms of pre-processing for text interpre-tation use fairly superficial analysis that complements he styleof ordinary parsing but uses much of the same knowledge base.Lexico-semantic pattern matching, with rules that combine lex-local analysis with ordering and semantic ategories, is a goodmethod for this form of analysis.
This type of pre-processing isefficient, takes advantage of corpus data, prevents many gardenpaths and fruitless parses, and helps the parser cope with thecomplexity and flexibility of real text.INTRODUCTIONThe interpretation of large volumes of text poses many con-trol problems, including limiting the complexity of analysis andensuring the production of valid interpretations without consid-ering too many possibifities.
These problems are especially severein processing news stories, where long sentences, information-richnews-style constructions, and the complex structure of eventsmake normal syntax-first analysis especially impractical.Normal eft-to-right syntactic parsing, in virtually all its forms,is a disaster for interpreting broad classes of extended texts.Multiple-path methods are haunted by attachment problems thatcan lead to a combinatoric explosion of paths, while simple deter-ministic methods bring on parser failures and problems in com-bining preferences.
In previous work aimed at word sense codingof news stories \[1\], we have found that even heavy pruning ofa multiple-path chart parsing strategy often leaves hundreds ofparses to consider for a single sentence.
Even worse, minor ir-regularities in linguistic structure or word usage bring on parserfailures and inadequate interpretations.Better parsing strategies, including control using statisticaldata, flexible partial parsing, and recovery, can certainly helpwith some of these problems, but some of the easiest improve-ments in the control of parsing come from the creative use ofpre-processing.
Our system incorporates a lexico-semantic pat-tern mateher, which uses much of the same knowledge base as theparser and semantic interpreter but performs a global, superficialanalysis of text prior to parsing.
The design and implementationof the pattern matcher is simple; instead of concentrating on itsdetails, this paper focuses on the functionality of pre-processingand its impact on parser control.Three aspects of pre-processing have particular promise forthe quality and efficiency of later processing--tagging, templateaciiva~ion (including topic analysis), and segmentation (orbrack-eting).
Tagging uses lexical data to constrain the part of speechand word senses of important words, template activation deter-mines a set of possible templates, or frames, and segmentation as-sociates portions of text with templates or template fillers.
Thesetechniques help the language analyzer to cope with the complex-ity of real text, both by reducing the combinatorics of parsingand by constraining word senses and attachment decisions.
Thefollowing is a sample text taken from the development corpus ofthe MUC-3 message understanding evaluation 1, with the resultsof pre-processing after segmentation:Original text:SIX PEOPLE WERE KILLED AND FIVE WOUNDEDTODAY IN A BOMB ATTACK THAT DESTROYEDA PEASANT HOME IN THE TOWN OF QUINCHIA,ABOUT 300 KM WEST OF BOGOTA, IN THECOFFEE-GROWING DEPARTMENT OF RISAR-ALDA, QUINCHIA MAYOR SAUL BOTERO HASREPORTED.
(41 words)Segmented text:\[SiX PEOPLE\] \[h: WERE KILLED\] AND FIVE\[A: WOUNDED\] \[TIME: TODAY\] IN \[A: A BOMBATTACK\] THAT \[h: DESTROYED\] \ [ i  PEASANTHOME\] \[LOCATION: IN THE TOWN OF QUINCHIA\]\[DISTANCE: *COMMA* ABOUT 300 KM WESTOF BOGOTA\] \[LOCATION: *COMMA* IN THE1MUC-3, the third government-sponsored m ssage understandingevaluation, is in progress.
Later in this paper, we will discuss thetask and performance on the task.337COFFEE *HYPHEN* GROWING DEPARTMENTOF RISARALDA\] \[SOURCE: *COMMA* QUINCHIAMAYOR SAUL BOTERO HAS REPORTED\] *PE-RIOD*The label A in some segments indicates that those segments aretemplate activators for a single event (single events are generallythe default for multiple references within a sentence, unless thereis a specific contextual cue such as a shift of time or location).The other labels are names of possible roles in templates.
As istypical in news stories, roles can be shared (like time or location)or can apply to a single sub-event (like the number killed andwounded).By grouping and labeling portions of text early, the programgreatly reduces the amount of real parsing that must be done,eliminates many failed parses, and provides template-filllng in-formation that helps with later processing.
For example, thephrase IN THE TOWN OF QUINCHIA is at least five waysambiguous--it could modify A PEASANT HOME, DESTROYED,A BOMB ATTACK, WOUNDED, or WERE KILLED AND FIVE\[WERE\] WOUNDED.
However, all five of these possibilities havethe same effect on the final templates produced, so the programcan defer any decisions about how to parse these phrases un-til after it has determined that the killing, wounding, attacking,and destruction are all part of the same event.
Since these choicescombine with the ambiguity of other phrases, the parsing processwould otherwise be needlessly combinatoric.
In fact, parsing con-tributes nothing after A PEASANT HOME, so this sentence canbe processed as a 16-word example with some extra modifiers.In addition to reducing the combinatorics ofmodifier attach-ment, pre-processing helps in resolving false ambiguities that area matter of style in this sort of text.
In this example, the el-lipsis in FIVE \[WERE\] WOUNDED would be difficult, exceptthat WOUNDED, llke many transitive verbs, is never used as anactive verb without a direct object.
The ellipsis is thus detectedprior to parsing, to be resolved uring parsing rather than as paxtof recovering or detecting a syntactic gap.
The early bracketingof the text allows the parser to resolve these complexities andambiguities without much extra baggage, and without having towait for a complete verb phrase.Pre-processing ot only speeds up parsing by avoiding com-binatorics; it also improves the accuracy of interpretation, bothby avoiding failures and by recognizing phrases and constructionsthat have specialized meaning or syntactic properties.
The nextsection describes the design of a lexicon-driven pattern matcherthat performs this sort of analysis prior to parsing, and the restof the paper will present several types of examples where pre-processing serves to improve parsing.LEXICO-SEMANTIC  PATTERNMATCHINGThe Pat tern  LanguageBecause the pattern matcher is designed as an efficient "trig-ger" mechanism and an aid in parsing, the patterns are mostlysimple combinations of lexical categories.
The patterns largelyadopt the language of regular expressions, including the followingterms and operators:?
Lexical features that can be tested in a pattern:- token "name" (e.g.
"AK-4T')- lexical category (e.g.
"adj")- root (e.g.
"shoot")- conceptual category (e.g.
"human")?
Logical combination of lexical feature tests- OR, AND , and NOT?
Wild cards$ - 0 or 1 tokens* - 0 or more tokens+ - 1 or more tokens?
Variable assignment from pattern components?X =?
Grouping operators:<> for grouping0 for disjunctive grouping?
Repetition* -  0ormore  +-  1 or more?
Range*N-0toN +N-  1 toN?
Optional Constituents{} - optionalThe Rule BaseFor the MUC-3 corpus, the knowledge base of patterns thusfar contains about 150 rules, where each rule contains a patternwith an action (such as tagging, bracketing, deleting, adding, orotherwise nhancing the "tokenized" input to help the parser).The rules range from mundane combinations ofwords to intricatestylistic expressions.
Below, we will go through some examplesof some of these rules, and the next section will characterize theircapabilities in more general terms.
This is work in progress, o wewill discuss both the current implementation a d the directionsfor further work.The strategy for pre-processing, as with parsing, is to pro-cess the text in stages, starting with coarse topic analysis andfiltering, then moving on to tagging, segmentation, and templateactivation.
Among the useful side benefits of the pattern matcheris that it discards portions of text that do not activate (or sup-port) any templates.
In MUC-3, this process eliminates about75% of the input.
On the first test set, the program did not skipany texts that contained relevant emplates.Because of this multi-stage design, the first stage of pat-tern matching contains the simplest patterns, and these includemostly expanded morphological forms, to avoid even the mor-phological analysis of large portions of irrelevant text.
Below arethree examples of these activator rules:338;;; rule 11?PIVOT=(or found left shot) ?OBJ=* ?EFFECT=dead=> (mark -ac t ivator  murder d-vp) ;; ; ;  ru le  40?0BJf$bombs 7hD3=* ?PIV0Tffi(or shook exploded dest royeddest roy ing  damaged damaging)=> (mark-activator bombing b-s) ;In addition to providing a rough screen of the input, these coarsetemplate activation patterns "mark up" the text.
Variable as-signments effectively tag portions of text to help the parser.
Forexample, the PIVOT tag tells the parser to favor a particular lex-ical term for the head of linguistic attachments, and the 0BJ tagtells the semantic interpreter to try to fill a conceptual object rolefor a constituent.
Since these patterns perform only the crudestform of linguistic analysis, their purpose is not to replace parsingbut to allow the parser to focus its processing and not "pruneoff" paths that are likely to be critical.Rule 11 above handles inputs such as The attack left 9 peo-ple dead.
Rule 40 handles, for example, The dynamite chargepartially destroyed the bank facilities.The macros on the right hand sides of rules, such as mark-activator, generally use the results of the pattern match, includ-ing variable assignments, along with some other constants, uchas murder and d-vp, to tag and segment the text.
Template ac-tivation tags, like murder, allow the semantic interpreter to frillslots and apply constraints from the appropriate template dur-ing parsing.
Grammatical tags, like d-vp (the double-object verbphrase, including adjectival complements) give a preferred parse,so the parser can try to favor a parse consistent with the lexlco-semantic pattern.The second set of rules, after the initial filtering and trig-gering, performs the cleanup of the input text, including manynames, dates, punctuation, and marking of locative and tempo-ral phrases.
These rules can be somewhat more involved, as inthe following examples:; ; ;  rule 97?N-~uJ.l.name*?om~t*?APP=<(not after fullname rpnoun auxpast_part_verb pres_part_verb)(not fullname was were *coma**semicolon*)* >(or *semicolon* *comma*)=> mark-appositive ;; ; ;  ru le  113{*coma*} ?PREP={(and prep (not between of))}{det} $ 7TYPEffi$1oc+2 \[of <known as>\] {det}\[<?IAME=place-neme ?TYPEffi{$1oc}> ?|AME=$1oc\]{*coma*}?POSSf{<*apostrophe-s* capital>}=> mark-location ;Rule 97 helps to distinguish appositive phrases from fists, relativeclauses, and other constructions with internal punctuation.
Theparser handles many punctuated forms using grammar ules ormeta-rules, but these can qnicldy get out of control.
A simpleexample is He is in charge of the investigations of the deaths ofGuillermo Cano, director of the newspaper El Espectador, andJaime Pardo Leal, the president of the Patriotic Union.Rule 113 catches many locative expressions.The most complex patterns perform tagging and segmenta-tion of grammatical constructions.
While these are probably themost interesting and promising for the general control of pars-ing, we have only begun to encode them.
The following are twoexamples:; ; ;  ru le  127(or 1-number numword) ?0B3=.4 k i l l ed(or  eoordconj  con j )*2 (or 1-number numeord)?SPOTffi(or injured wounded)=> mark-ellipsis ;; ; ;  rule 128{aux} ?V=verb_leave (or  1-number numword)?FOBJ=*4 ?Elffi(or injured dead wounded){<?Cffi(or coordconj conj)*2 (or 1-number numsord)?SOBJffi*4 ?E2f(or injured sounded)>}ffi> mark-left-dead ;Rule 127 recognizes many cases of ellipsis involving death andinjury, as in Six people were killed and five wounded, and rule 127segments examples where the verb leave is used to express deathand injury, as in left 6 people dead.
These rules often overlap, asrule 128 overlaps with rule 11.
The motivation for this is thatrule 11 simply spots certain cases where left is used to expressdeath (a very smaU percentage of occurrences of left), while themore powerful rule, 128, tries to segment the objects and effects.The Algor i thmWhen the system loads the pattern-activation rules, it in-dexes each pattern by the lexical features (i.e.
the words, lexicalcategories, roots and concepts) of each of its constituents, distin-guishing those that require lexical analysis from the word-onlyrules.
At rim-time, the pattern matcher performs the followingfour operations:1.
It examines each input token (only) once for any featuresthat index pattern tests.2.
Each satisfied pattern test "triggers" its enveloping rule.The satisfied pattern tests are cached so subsequent occur-rences of the same input token avoid the feature xamina-tion.3.
After all input tokens have been examined, the programmatches all triggered rules (those that have all of their non-optional tests satisfied) against he input.
The matchinguses a best-first search algorithm, where the "best" matchis one that uses the most pattern constituents and the most339input tokens.
This matching process is implemented as a OQOELI, 45 .
.
.
.table traversal.4.
The system executes the actions of all matched rules.We now turn to how this simple form of pre-processing helpsparsing and how it is likely to influence future advances in textinterpretation.FEATURES OF PRE-PROCESSINGThis section gives some examples from news stories of theplaces where pattern matching eliminates or assists with worktypically left for parsing.
Pushing these tasks into this pre-processing phase with a less computation-intensive m chanismspeeds up language analysis, reduces the complexity of the in-put texts, allows for modularity between topic analysis and dataextraction, and increases the accuracy of the resulting analysis.Pattern matching performs the following tasks:1.
Name recogn i t ion  and  reduct ion :  Person names maycontain long and complex titles and appositives, as in the follow-ing examples:FORMER PERUVIAW DEFEISE MINISTERGENERAL EBRIqUE LOPEZ ALBUJARFARIO SOLORZhIIO NARTIIEZ, LEADER OFGUATEMALA'S DEMOCRATIC SOCIALISTPARTY,...We recognize these constructs with the pattern matcher, usingpatterns that contain variables for first names and variables fortitles.2.
Spat ia l  phrase  recogn i t ion  and  reduct ion :  Pre-processingcan easily identify and compress many locatives, using patternsthat look for combinations of spatial prepositions with knownlocations, as in the following:II THE TOWI OF QUIICHIA, ABOUT 300 KMWEST OF BOGOTA, II TIIE COFFEE-GROWlIiGDEPARTNEIJT OF RISARALDA ...3.
Tempora l  phrase  recogn i t ion  and  reduct ion :  The pat-tern matcher picks out many temporal adverbial phrases, suchas:II THE PAST FEW HOURSMORE TilhB 3 MOBTIIS AGO.4.
"C leanup"  of  news sty le  text :  Patterns capture and helpinterpret style-specific onstructions, as in the following exam-ples:WITH LICEBSE PLATE UF-21715.
Tagging and  segmentat ion :  Some complex constructs, es-pecially ellipsis and conjunction, are easier to identify and parsewith identification at pre-processing, for example, the construct< event>... <verb-leave>... Y < heal~h-atate> and...Z <health_state>in the following sentence:THE UPRISING, WHICH BEGAN AT 1100 (1700 GMT)ON 26 MARCH AND WHICH INCLUDES DEMANDS FORBETTER JAIL CONDITIONS, HAS LEFT AT LEAST 12 DEADAND SOME 20 INJURED, ACCORDING TO POLICE SPOKES-MEN.6.
Topic  ana lys is  and  f i l ter ing:  Patterns for topical keywordsand phrases help to perform topic analysis and filtering of stories.For example, stories containing patterns like <attack> ...<civilian>are likely to be about terrorist attacks.
This type of relevancedetermination is useful at the paragraph and sentence level aswell.
Eliminating irrelevant sentences saves the language analy-sis programs from having to parse them, and often avoids "falsepositives" by eliminating background information from interpre-tation, as in the following paragraph:ALL OF THESE CHARACTERISTICS MAKE HONDURASA DEMOCRACY, AND EVERY SECTOR OF HONDURANSOCIETY SHOULD STRIVE TO STRENGTHEN THEM BYAVOIDING VIOLENCE AT ALL COSTS, OBEYING THE LAW,AND CONDEMNING AND ATTACKING EXTREME TER-RORIST GROUPS REGARDLESS OF THEIR AFFILIATION,THUS ENABLING US TO CONSOLIDATE OUR DEMOC-RACY AND REACH THE LEVEL OF POLITICAL DEVEL-OPMENT ATTAINED BY OTHER DEMOCRATIC COUN-TRIES.These six examples il lustrate some of the places where fairlywell-understood techniques from Artificial Intelligence, combinedwith a large lexical and conceptual hierarchy, are very useful inanalyzing texts for natural language data extraction.
In somecases, such as topic analysis, the pattern matcher operates as aseparable component from the rest of the text processing sys-tem; in others, Hke syntactic segmentation and spatial/temporalreduction, it is more closely coupled with the parser.
This ap-proach has many of the advantages ofphrasal parsing, such as ro-bust coverage of a range of grammaticM constructions, the elim-ination of grammatical complexity, and the easy adaptation ofthe system to handle sublanguage constructs.
But it retains theadvantages of parsing for handling agreement, attachment, andsemantic interpretation of the text.The next section compares this style of processing with earlierwork in phrasal parsing.PRE-PROCESSING AND PHRASALPARSINGWe have pointed out some of the problems with traditionalleft-to-right single pass parsing methods, including the lack of in-fluence of global context on local interpretation, the complexity340of long sentences, tylized constructs, and garden paths.
Thesewell-known symptoms of syntactic parsing point to two gen-eral means of improving control---sublanguage nalysis \[2\] anddomain-driven or conceptual nalysis \[3\].
Roughly speaking, thismeans that the system must constrain the input through eitherlinguistic or semantic methods wherever possible.
Pattern match-ing is an effective vehicle to enforce such constraints.In some ways, the use of pattern matching for pre-processingis reminiscent ofphrasal styles of language analysis \[4, 5, 6\], whichin turn derive in part from semantic grammars \[7\].
These con-trolled styles of parsing were especially useful for engineering ap-plications in limited domains, where it is much easier to cover therange of meaningful expressions and their interpretations than tocontrol eft-to-right parsing and subsequent semantic interpreta-tion.
However, phrasal analysis, like syntax-first parsing, tried totreat most of language interpretation within a single-pass, ingle-strategy process.
This confined the approach to fairly simpleapplications and made it difficult to port from one domain toanother.In addition to this brittleness and limited scope of phrasalparsing, the phrasal approach suffered from a more fundamentalproblem: treating phrases or constructions a  a replacement forgrammatical rules seemed to miss the point of grammar entirely,leaving no place to account for most of the regularities of lan-guage.
Even most of the rigid constructions and "idioms" of alanguage (like riddled with bullets) are grammatical.
Thus theencoding of most of the knowledge about these expressions wasreally redundant, forcing the phrasal analyzer to apply interpre-tation rules and enforce constraints that easily could have beenexpressed in more general terms.
This causes problems both indeveloping broad coverage and in applying automated methodsof acquiring phrasal knowledge.Lexico-semantic pre-processing, by introducing domain con-straints and linguistic constrncts prior to processing, controlsparsing through two vehicles: (1) Triggering grammatical con-strncts prior to parsing allows the parser to apply the same gram-matical knowledge to many different types of input without beingconstantly led to garden paths or false interpretations, and (2}Using filtering and template activation to capture some domainknowledge prior to parsing allows the parser to direct attach-ment and pruning toward the production of relations that affectthe domain result.
This sort of multi-stage analysis seems tobe the right style for accomplishing the directed processing ofthe phrasal and sublanguage approaches while allowing for thebreadth and portability that current ext processing applicationsrequire.CURRENT STATUS AND FUTUREENHANCEMENTSOur system, known as the GE NLToolset \[8\], is one of themore complete and mature text interpretation programs, havingdeveloped from a substantial research thrust into several applica-tions outside of the research laboratory.
Like other esearchers intext interpretation, we have come to evaluate this sort of work inpart through the system's performance on government-sponsoredbenchmark evaluations.The second message understanding evaluation conference, in1989, known as MUCK-II \[9\], used a corpus of slightly over 100naval operations reports, with a final test on 5 such messages.The current MUC-3 development corpus contains 1300 open-source foreign news stories, with a final test on 100 such stories.The total corpus for MUC-3 is about 400,000 words, comparedwith about 3200 for MUCK-II.
The MUC-3 task also requiresboth broader and deeper analysis of the texts, with an uncon-strained range of responses.
For example, the example sentenceabout the bombing in Risaralda would produce the template il-lustrated in Figure I.The MUC-3 evaluation scores each system on its ability tomatch a "correct" set of over 100 filled templates on 100 newsstories.The scale-up over the two years from MUCK-II to MUG-3 hasstrained parsing systems in throughput, coverage, and accuracy,and pre-processing has been essential to all three.
Our systemthroughput is now an order of magnitude greater in words perminute (about 1000/minnte) than in MUCK-II, the coverage isorders of magnitude greater, and the accuracy is about the sameas at this point in MUCK-II, in spite of a harsher scoring system.Improvements in the grammar, lexicon, preference module, andrecovery strategies have helped in this advance.
However, largeimprovements in parsing are hard to come by, hence the incre-mental contribution of pre-processing is disproportionate, giventhe simplicity of the algorithm and rules.Two major challenges remain in integrating the pattern matchermore effectively with the parser, and both should be accom-plished, at least in part, before the end of MUC-3.
We viewthe apparent success of simple pattern matching methods notas a replacement for real parsing, but rather as an example ofhow much work is involved in controlling parsing of texts.
Thecurrent coupling of the parser with the pattern matcher is notsufficiently fluid to take advantage of much of the informationthat the pattern matcher can produce, leaving room for furtherintegration.The first apparent challenge is to tie the linguistic patterns,where appropriate, to "top-down" domain knowledge.
In manycases, the common expressions, forms, and preferences derivefrom conceptual relationships in the domain; for example, theleave dead expressions are part of a general class of descriptionsthat follow events with the effects of events.
For efficiency, thepattern matcher must recognize these descriptions at the lexicallevel, but there is no reason why domain knowledge cannot helpto collect and create such lexical patterns.The second challenge is to use the results of pattern matchingmore for parser preferences, using a strategy we call relation-driven control.
This strategy looks for attachments of phrasesto pivots which appear at the head of template activators.
Wehave already implemented relation-driven control as a means ofrecovering from failed parses, but much of the task of nsing pivotsand brackets to guide preferences remains.In addition to these two challenges, another task, which ismore difficult than it would seem, is to combine pattern match-ing with other, more syntactic methods of pre-processing, suchas stochastic analysis or finite-state recognition of constituents.341
