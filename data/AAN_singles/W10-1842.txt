Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 265?273,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsDesign and Evaluation of Shared Prosodic Annotationfor Spontaneous French Speech:From Expert Knowledge to Non-Expert AnnotationAnne Lacheret1 Nicolas Obin1, 2Mathieu Avanzi1, 31Modyco Lab, Paris Ouest University, Nanterre, France2Analysis-Synthesis team, Ircam, Paris, France3Neuch?tel University, Neuch?tel, Switzerlandanne@lacheret.com, nobin@iracm.fr; Mathieu.avanzi@unine.chAbstractIn the area of large French speech corpora,there is a demonstrated need for a commonprosodic notation system allowing for easydata exchange, comparison, and automatic an-notation.
The major questions are: (1) how todevelop a single simple scheme of prosodictranscription which could form the basis ofguidelines for non-expert manual annotation(NEMA), used for linguistic teaching and re-search; (2)  based on this NEMA, how to es-tablish reference prosodic corpora (RPC) fordifferent discourse genres (Cresti and Mo-neglia, 2005); (3) how to use the RPC to de-velop corpus-based learning methods forautomatic prosodic labelling in spontaneousspeech (Buhman et al, 2002; Tamburini andCaini 2005, Avanzi, et al 2010).
This paperpresents two pilot experiments conducted witha consortium of 15 French experts in prosodyin order to provide a prosodic transcriptionframework (transcription methodology andtranscription reliability measures) and to es-tablish reference prosodic corpora in French.1 IntroductionIn this paper the case of the prosodic annotationof spontaneous French speech is discussed.
Eversince the ToBI system was introduced in the in-ternational speech community (Silverman et al,1992), it has been considered by some ?
irrespec-tive of the language to be annotated1 - as a stan-dard for prosodic annotation, while others con-tend that ToBI cannot be regarded as a universalannotation tool, i.e.
it is not appropriate to cap-ture the prosodic properties of certain languages.This is especially true when dealing with sponta-neous speech, for which new methods of annota-tion must be found.
In other words, a better pro-1For French, see the work of Post (2000) and Jun &Fougeron (2002).sodic labelling is essential to improve linguisticanalyses of prosody (Martin 2003, as well as re-search in speech technology (Wightman 2002).Linguistics and speech technology have dealtwith prosodic transcription from various pointsof view, which makes a precise definition of thetask difficult.
An initial distinction can be drawnbetween (i) phonological approaches (Silvermanet al, 1992; Hirst and Di Cristo, 1998; Delais-Roussarie, 2005; etc.
), and (ii) acoustic-phoneticprosodic analysis (Beaugendre et al, 1992;Mertens, 2004).
Nowadays, these two ap-proaches still remain problematic.
The codingschemes of the former reflect not only a specific,and rather narrow, phonological point of view,but also the phonetic poverty of the transcription(most of the time, only information about thefundamental frequency is delivered, and no in-formation regarding intensity, vocal quality,variations in syllabic length and speech disfluen-cies is provided).
In the second approach, veryfine-grained descriptions and modelling havebeen conducted (House, 1990; Mertens, 2004),but they are too rich to be easily exportable.
Thequestion therefore remains: what is the bestcompromise between an overly detailed phoneticdescription and a phonological annotation whichis too narrow from a theoretical point of view?
Inan attempt to answer this question, the followingprerequisites underpin our approach to prosodicannotation.
First, it should be based on a theory-independent phonological labelling.
To achievethis, we have designed an inductive prosodicprocessing which does not impose a phonologi-cal (generative) mould, but in which various ex-isting notation systems (such as ToBI, Intsint,IVTS, see references below) could be integrated.Second, the annotation proposed by the expertshould be easily reproducible by non-expert an-notators and finally carried out by computers (inorder to reduce the cost of human processing and265to avoid the subjectivity and variability of man-ual treatment).This paper deals with an initial set of funda-mental questions: (i) What does it mean to de-velop a theory-independent method of annota-tion?
What does it imply in terms of methodo-logical choices?
(ii) Can we consider a type ofannotation which is based on a categorical proc-essing of prosody as well as continuous judg-ment, or is the latter too difficult to implementand process in a shared prosodic annotation?
(iii)What kind of preliminary analysis is required inorder to write a well-documented guideline shar-able in the community for French prosody anno-tation?
These three questions led us to conducttwo pilot experiments in 2009, which are pre-sented here.
Each section is structured as fol-lows: description of the corpus, the task, and theresults, and a brief discussion of the experimentin question to explain the final choices made forthe reference prosodic labelling summarized inthe conclusion.2 Pilot experiment oneThis first experiment was conducted on a 63 sec.
(335 syllables) recording, consisting in a mono-logue of spontaneous speech (interview with ashopkeeper in southern France).
The recordingwas processed by 15 expert annotators (nativeFrench researchers in phonology and/or phonet-ics).
The goal of this section is to present (?2.1)the task and its different steps, (?2.2) the resultsof the coding regarding inter-annotator agree-ment and (?2.3) the major problems revealed bythe results concerning the coding method.2.1 The taskThe prosodic annotation is based first on themarking of two boundary levels, second on theidentification of perceptual prominences, andfinally on the labelling of disfluencies and hesita-tions.Given our bias neutrality theory, no constraintwas set a priori regarding prosodic domain andconstituents separated by a prosodic break(rhythmic, syntactic or pragmatic units; this pointconcerns the functional interpretation to be con-ducted later).
Concerning prominences, we con-sidered that prominence was syllabic and had notto be merged with the notion of stress.
Thismeans that a prominent syllable is considered asa perceptual figure emerging from its back-ground.
Finally, we defined disfluency as anelement which breaks the linear flow of speech,whatever the element is: it can be a syllable, aword, a morpheme unit, part of a sentence, etc.The starting point of the procedure is a semi-automatic alignment processing (Goldman,2008) conducted under Praat (Boersma andWeenink, 2010 which provides a 3-layer seg-mentation structure: segmentation within aphones string, syllabic string, and words string.They are all displayed on 3 temporally alignedtiers.
Three empty tiers aligned on the syllabictier have to be annotated (FRONT for markingthe prosodic boundaries, PROM for annotatingprominences and DYSF for coding disfluencies).Finally, a COMMENTS tier can be used to pointout some mistakes in the annotation task and/orerrors in the pre-processing (wrong segmentationor transcription, etc).
An example of an anno-tated output file is given in figure 1.Since the annotators do not have access to theacoustic parameters (melodic and intensity line,spectral information), the identification of pro-sodic boundaries, prominences and disfluenciesis based only on perceptual processing.
The cod-ing methodology (categorical scale for the anno-tation) is structured in the following way: eachannotator browses the file from left to right andorganises the work in 3 steps.?
First step: FRONT Tier processing,two degrees of prosodic boundaryFirst, each annotator has to identify breathgroups (henceforth BG, marker ?2?
at the end ofthe BG).
A BG is defined as follows: it corre-sponds to a string of syllables bounded left andright by a silent pause, regardless of the functionor duration of the pause.Example:#C?est clair2#(#it is obvious#)Second, in each BG, the expert indicateswhere he perceives the end of an internal pro-sodic group (IPG, marker ?1?
).Example:#mais1 je vais aussi1 leur donner de moi-m?me2#(#and I will also give them of myself#)If the annotator is not sure about the presence ofa prosodic boundary, he uses the indeterminacymarker ???.
In this way, two degrees of prosodicboundary are identified (major: BG and minor:IPG).
Then, IPG are used to determine internalprosodic segments, which form the new anchor266points (coding span) for the following processingsteps (prominences and disfluencies annotation).?
Second step: PROM tier processingThe marker ?1?
is associated to syllables per-ceived as prominent (?
terminal: la re1lation1:the relationship), and the indeterminacy marker???
indicates the locations where the annotatorhesitates between the presence and the absenceof a prominence.Example:La personne?
va vous ra1conter sa vie1(the man will tell you his life).The accentual clash rule (Dell, 1984; Pasdeloup1990) is not taken into account.
In other words,two or more contiguous syllables can be anno-tated as prominent.?
Third step: DISF tier processingAs for the coding of prominences, the expertsuse the symbol ?1?
to indicate the disfluenciesclearly identified and ???
to point out a hesitation.The latter context is often linked to lengtheningand final post-tonic schwa.Figure 1.
Example of prosodic annotation in pilot experiment one.
Tiers indicate, from top to bottom: phones,syllables, boundaries (FRONT), prominences (PROM), disfluencies (DISF), graphemic words and comments.The empty segments correspond to any prosodic events detected in which the comment points out an incorrectsyllabic labelling.2.2 Results of the coding: inter-annotatoragreement in pilot experiment one?
Agreement measureThe kappa statistic has been widely used in thepast decade to assess inter-annotator agreementin prosodic labelling tasks (Syrdal and McGory,2000), and in particular the reliability of inter-annotator agreement in the case of a categoricalrating, (Carletta, 1996).
Among the many ver-sions proposed in the literature, we selected theFleiss?
kappa (Fleiss, 1971), which provides anoverall agreement measure over a fixed numberof annotators in the case of categorical rating(unlike Cohen's Kappa which only provides ameasure of pairwise agreement).?
ResultsFigure 2 presents the Fleiss?
kappa agreement foreach prosodic label.
Indeterminacy markers weresimply processed as missing values and removedfrom the annotation data.267Figure 2.
Inter-annotator agreement for each prosodiclabelThese results show moderate agreement onprosodic boundaries for FRONT1 (0.56) andFRONT2 (0.86).
While agreement on major pro-sodic boundaries seems to be strong, it should beremembered that this marker was formally im-posed on the annotators in the instructions.
Con-sequently, the score questions the relevancy ofthe task: if a few annotators did not follow it, it isprobably because in specific distributions, theend of a BG does not correspond to a major pro-sodic boundary.
Furthermore, experts noticedthat a prosodic break could be stronger at the endof an IPG than at the end of a BG where the si-lent pause is not necessarily due to a prosodicbreak, especially in spontaneous speech.
Promi-nence labeling provides moderate agreement(0.68), better than FRONT1, and better than theagreement scores found in the literature for otherprominence labelling tasks for French speech(Morel et al, 2006)2.
Finally, disfluency label-ling shows substantial agreement, disagreementsbeing mostly due to confusion between theprominent or disfluent status of a syllable.2.3 Conclusion on pilot experiment oneThe results of this first experiment call for thefollowing comments.
While identification ofhesitations and disfluencies seems to be an easytask, the annotation of prosodic boundaries andprominences raises a set of methodological andlinguistic questions: (i) Are the concepts suffi-ciently well-defined to represent the same pro-sodic reality for each annotator?
(ii) How far arethe experts influenced by their theoretical back-ground or phonological knowledge?
(iii) To whatextent does the fixed coding methodology intro-duce noise in the labelling (for instance, does theend of a BG systematically correspond to a majorprosodic boundary)?
(iv) Is a 3-step annotationcoding too heavy a cognitive task, incompatiblewith the principle of economy required by asharable prosodic annotation scheme?3 Pilot experiment twoFor this second experiment, we chose the samerecording (speaker from southern France, 63 sec.2These better results are probably due to the more stringentmethod of annotation imposed.of speech) and a second one that was more diffi-cult because of its interactive dimension and be-cause it contains many speech overlaps and dis-fluencies (3 speakers of Normandy, 60 secondsof speech, 284 syllables to label).
The data wereprocessed by 11 experts.
This section follows thesame organization as section 2.3.1 The task: focus on prosodic packagingFor this second experiment, we selected to focusthe annotation on the most problematic point inthe first experiment, namely the coding of pro-sodic breaks.
We conjectured that the lack ofagreement derived first from the terminology thatthe experts were asked to use: the concept ofprosodic boundary, which is phonologicallymarked and also theory-dependent, might explainthe lack of consensus between experts belongingto different schools.
Consequently, each annota-tor was asked to carry out only one task, calledprosodic packaging.
In this task, the expert hadto segment the flow of speech into a string ofprosodic packages (Mertens, 1993; Chafe 1998)as far as possible according to his perceptualprocessing, i.e.
independently of any underlyingfunctional and formal constraints.Given the nature of the task, the method of an-notation was not imposed, unlike the first ex-periment.
In other words, each annotator fixedhis own coding span.
Finally the experts wererequired to carry out a meta-analysis, justifyingtheir coding span and trying to understand andexplain the cues they had used for the packagingtask (acoustic, rhythmic, syntactic, pragmaticcriteria).Each Praat textgrid is composed of five tiers(see figure 3 below): three tiers are used as an-chor points for the annotation (syllables, wordsand ?Loc.
?, which indicates the speakerchanges), and only one tier has to be annotated(prosodic packages); the Comments tier is alsodisplayed with the same function as in experi-ment one.
Four symbols are used for the annota-tion (continuous scale rating): ???
: hesitancy re-garding the end of a package; ?1?
: end of a pack-age, weak break with the following package;?2??
: indeterminacy regarding the degree of thetransition between two packages (weak orstrong); ?2?
: strong breaks between two pack-ages.268Figure 3.
Example of transcription in prosodic packages in pilot experiment 2.Tiers indicate, from top to bottom:syllables, boundaries (FRONT), speakers (LOC, where L1 and L2 mean speaker one and speaker 2, L1-L2 =overlap between the 2 speakers), comments and phonetic words.3.2 Results of the coding: inter-annotatoragreement in pilot experiment two?
Agreement measuresIn addition to the Fleiss?kappa test used in thefirst experiment, we introduced here theWeighted Cohen's Kappa (Fleiss and Cohen,1973) which provides a pairwise agreementmeasure in the case of ordinal categorical rating(categorical labels are ordered along a continu-ous scale).
In particular, weighted Cohen?sKappa weights disagreement according to thenature of the disagreed labels.
Linear Cohen?sKappa was used in this experiment.In this second experiment, we addressed threekind of inter-annotator agreement: (i) Presenceof the end of a prosodic package (PPP), i.e.
towhat extent did annotators agree about the end ofa prosodic package?
(ii) Location of the end ofa prosodic package: annotators may agree on aPPP, but disagree on the exact location of thisboundary.
This was measured by adding a toler-ance on the location of the PPP (1-order syllablecontext).
(iii) Strength of the end of PPP, i.e.how much annotators agree about the degree of aprosodic boundary.Fleiss?
kappa was estimated for the first twoproblems, and Linear Cohen?s Kappa for the last(indeterminacy markers being considered as in-termediate degrees).?
ResultsFigure 4 presents the agreement scores for thethree cases mentioned above and for the two cor-pora used.Figure 4.
Inter-annotator agreement according topresence, location, and strength of the end of prosodicpackage.Overall agreement scores indicate a significantlylower agreement for the second corpus.
This isprobably related to its higher complexity (lowaudio quality, high level of interaction, manydisfluencies, regional accent) which made thetask harder to process.
The comparison of pres-ence (corpus 1 = 0.71; corpus 2 = 0.56) versusstrength (corpus 1 = 0.67; corpus 2 = 0.53) ofthe end of a prosodic package agreements sug-gests that categorical rating is more reliable thanordinal rating.
In other words, annotators appearto perform better at rating the categorical statusof a syllable rather than its precise degree.
On thelocation problem, it is first interesting to notethat the occurrence of such a location shift is sig-nificant in the prosodic labelling.
In the presentstudy, the location shift represents respectively12% and 18% of syllables that were rated as PPPby at least one of the annotators (balance effect,see figure 5).
Thus, merging these shifts leads toa higher agreement score (corpus 1 = 0.75 andcorpus 2 = 0.63 after merging).269Figure 5.
Examples of balance effect in the segment ?son neveu l?
est en train d??-?
(his nephew is therenow)?
Annotator clusteringFinally, we investigated whether the experts?phonological models affected the way in whichthey perceive prosodic objects.First, annotators were labelled by the authorsaccording to their assumed underlying phono-logical model.
This resulted in 4 groups (3 dif-ferent phonological models + a residual group:two speech engineers involved in signal process-ing with no phonological model).The annotators were then hierarchically clus-tered according to their agreement score (see fig-ure 6).
This hierarchical clustering was achievedthrough complete linkage on semi-euclidean dis-tance between annotator agreement (see Hastie etal., 2009 for details)Figure 6.
Agglomerative hierarchical clustering of theannotators according to their agreement on both cor-pora.Interestingly, this results in three main clustersthat significantly match the three previously de-fined groups for process annotation: (i) A tonalperception (G1) and syntactic functional ap-proach (Mertens, 1993); (ii) Cognitive process-ing (G2), trying to segment the flow of speechindependently of syntactic constraints (Lacheret,2007; see the notion of flow of thought in Chafe,1998); (iii) a formal approach (G3) based on pro-sodic phonology (Nespor and Vogel, 1986) andthe problem of mapping between prosodic struc-ture and generative syntax (Selkirk, 1984).3.3 Conclusion on pilot experiment twoTwo main conclusions emerge from this secondexperiment.
(i) Even if prosodic constructionsare in many respects continuous mechanisms, itseems more realistic for the time being to con-sider a method based on a categorical annotation.
(ii) This second experiment confirms that theexperts?
phonological models significantly affectannotation and questions the reliability of expertannotation.
However further investigation isneeded and a comparison with non-expert anno-tators must be conducted before drawing anydefinitive conclusions.4 ConclusionGiven the results of pilot experiments 1 and 2,we conclude that neither the static concept ofprosodic boundary, nor its dynamic substituteprosodic packaging leads to a high inter-annotator consensus.
In other words, these twoconcepts are probably too dependent on differentlevels of processing (syntactic, phonological, andrhythmic) and each annotator, depending on hisown definition of the notion (formal or func-tional) will focus on one aspect or another.
Con-270sequently, even if precise instructions are givenfor annotation, the labelled data still remain het-erogeneous.
Therefore, these two conceptsshould not be used as the basis for the develop-ment of a shared prosodic annotation methodaiming to establish a reference prosodic corpusand annotation software, which are essentialtools in handling large volumes of speech data.In contrast, we hypothesize that prominence an-notation based on perceptual criteria representsthe cornerstone of speech prosodic segmentation,as prosodic structure will be generated fromprominence labelling.
Although the results of thefirst pilot experiment are rather poor 0.68), re-cent experiments have shown that the scores rise(0.86) after training sessions (Avanzi et al2010b).
We have therefore decided to focus ourannotation guideline on the labelling of promi-nences (two levels of prominence: strong orweak) and disfluencies (hesitations, false starts,speaker overlaps, post-tonic schwas, etc.).
Themethod does not depend on some abstract prop-erty of words or groups of words, as in the caseof lexical stress (Martin, 2006; Poir?, 2006; Postet al 2006), but is based on a neutral phoneticdefinition of prominence, associated with percep-tual salience in the context of the speech back-ground.
This approach has the advantage of be-ing consensual, whatever the theoretical frame-work adopted.
Based on these criteria, a one daytraining session has been organized for 5 noviceannotators (students in linguistics) in order toannotate 3.30 hours of different speech genres(private, public, professional), over 2 months(from February to April 2010).
For each genre amonologal and an interactional sample of around5 minutes (42 speech files altogether) have to belabelled.
Prominences and disfluencies are codedon two independent tiers.The annotation deliverable will be processedduring the spring by five experts who will haveto perform four tasks: (i) compute the inter-annotator scores applying the statistical measuresused in the two pilot experiments; (ii) diagnosethe distributions with the poorest scores for allthe samples; (iii) diagnose the genres with theworst scores and  (iv)  make explicit decisions toprovide an output prosodic reference annotationand to enhance automatic prominence detectionsoftware (see for French: Avanzi et al, 2010a;Martin 2010; Obin et al 2008a, 2008b, 2009;Simon et al 2008).AcknowledgementsThis research is supported by the Agence Nationalede la Recherche (ANR-07-CORP-030-01, ?Rhapsodie?
Corpus prosodique de r?f?rence du fran?ais parl??
).We would like to thanks our colleagues from LPL(Aix-en-Provence), ERSS (Toulouse), Ircam (Paris),MODYCO (Paris) and also University of Geneve(Switzerland), Louvain-la-Neuve, Leuven (Belgium)to have conduct this work for Rhapsodie.ReferencesMathieu Avanzi, Anne Lacheret and Anne-CatherineSimon.
2010.
Proceedings of Prosodic Promi-nence, Speech Prosody 2010 Satellite Workshop,Chicago, May 10th.Mathieu Avanzi, Anne Lacheret and Bernard Victorri.2010a.
A Corpus-Based Learning Method forProminences Detection in Spontaneous Speech.Proceedings of Prosodic Prominence, SpeechProsody 2010 Satellite Workshop, Chicago, May10th.Mathieu Avanzi, Anne-Catherine Simon, Jean-Philippe Goldman and Antoine Auchlin, 2010b.C-PROM.
An annotated corpus for French promi-nence studies.
Proceedings of Prosodic Promi-nence, Speech Prosody 2010 Satellite Workshop,Chicago, May 10th.Fr?d?ric Beaugendre, Christophe d?Alessandro, AnneLacheret-Dujour and Jacques Terken.
1992.
APerceptual Study of French Intonation.
Proceed-ings of the International Conference on SpokenLanguage Processing, J. Ohala (ed.
), Canada,739-742.Paul Boersma and David Weenink.
2010.
Praat: doingphonetics by computer (version 5.1),www.praat.org.Jeska Buhmann, Johanneke Caspers, Vincent J. vanHeuven, Heleen Hoekstra, Jean-Pierre Mertens andMarc Swerts.
2002.
Annotation of prominentwords, prosodic boundaries and segmental length-ening by non-expert transcribers in the SpokenDutch Corpus.
Proceedings of LREC2002, LasPalmas, 779-785.Jean Carletta, 1996.
Assessing agreement on classifi-cation tasks: the Kappa statistic.
ComputationalLinguistics, 22(2):249-254.Wallace Chafe.
1998.
Language and the Flow ofThought.
New Psychology of language, M.Tomasello (ed.
), New Jersey, Lawrence ErlbraumPublishers, 93-111.Emmanuela Cresti and Massimo Moneglia, eds.
2005.C-ORAL-ROM.
Integrated Reference Corpora forSpoken Romance Languages, Studies in CorpusLinguistics 15.
Amsterdam, Benjamins.271Elisabeth Delais-Roussarie.
2005.
Phonologie etgrammaire, ?tude et mod?lisation des interfacesprosodiques.
M?moire d?habilitation ?
diriger desrecherches, Toulouse.Fran?ois Dell.
1984.
L?accentuation dans les phrasesfran?aises.
Forme sonore du langage, structuredes repr?sentations en phonologie, F. Dell et alParis, Hermann, 65-122.Joseph L. Fleiss.
1971.
Measuring nominal scaleagreement among many raters.
Psychological Bul-letin, 76(5):378?382.Joseph L. Fleiss and Jacob Cohen.
1973.
The equiva-lence of weighted kappa and the intraclass correla-tion coefficient as measures of reliability.
Educa-tional and Psychological Measurement, 33:613-619.Jean-Philippe Goldman.
2008.
EasyAlign: asemi-automatic phonetic alignment tool underPraat, http://latlcui.unige.ch/phonetique.Trevor Hastie, Robert Tibshirani and Jerome Fried-man, 2009.
Hierarchical clustering.
The Elementsof Statistical Learning (2nd ed.).
New York:Springer, 520-528.Daniel Hirst and Albert Di Cristo.
1998.
IntonationSystems: A Survey of Twenty Languages, Cam-bridge, Cambridge University Press.David House.1990.
Tonal perception in Speech, LundUniversity Press.Sun Ah Jun and C?cile Fougeron.
2002.
The Realiza-tions of the Accentual Phrase for French Intona-tion?, Probus, 14:147-172.Anne Lacheret.
2007.
Prosodie du discours, une inter-face ?
multiples facettes.
Nouveaux Cahiers de lin-guistique fran?aise, 28:7-40.Philippe Martin.
2003.
ToBI : l?illusion scientifique?Actes du colloque international Journ?es Prosodie2001.
Universit?
de Grenoble, 109-113.Philippe Martin.
2006.
La transcription des pro?mi-nences accentuelles : mission impossible?, Bulletinde phonologie du fran?ais contemporain, 6:81-88.Philippe Martin.
2010.
Prominence Detection withoutSyllabic Segmentation, Proceedings of ProsodicProminence, Speech Prosody 2010 Satellite Work-shop, Chicago, May 10th.Piet Mertens.
1993.
Intonational Grouping, bounda-ries, and syntactic structure in French.
WorkingPapers Lund University, 41:156-159.Piet Mertens.
2004.
The Prosogram: Semi-AutomaticTranscription of prosody based on a Tonal Percep-tion Model.
Proceedings of Speech Prosody 2004,Nara, Japan.
549-552.Michel Morel, Anne Lacheret-Dujour, Chantal Lyche,Morel M. and Fran?ois Poir?.
2006.
?Vous avezdit pro?minence?, Actes des 26?mes journ?esd?
?tude sur la parole, Dinard, France.
183-186.Marina Nespor and Irene Vogel.
1986.
ProsodicPhonology, Foris, DordrechtNicolas Obin, Xavier Rodet and Anne Lacheret-Dujour.
2008a.
French prominence: a probabilisticframework.
Proceedings of ICASSP?08, Las Vegas,U.S.A.Nicolas Obin, Jean-Philippe Goldman, MathieuAvanzi and Anne Lacheret.
2008b.
Comparaisonde trois outils de d?tection automatique de pro?mi-nences en fran?ais parl?.
Actes des 27?mes journ?esd?
?tude sur la parole, Avignon, France.Nicolas Obin, Xavier Rodet and Anne Lacheret-Dujour.
2009.
A Syllable-Based Prominence De-tection Model Based on Discriminant Analysis andContext-Dependency, Proceedings of SPE-COM?09, St-Petersburg, Russia.Val?rie Pasdeloup.
1990.
Mod?le de r?gles rythmi-ques du fran?ais appliqu?
?
la synth?se de la pa-role, PhD, Universit?
de Provence.Fran?ois Poir?.
2006.
La perception des pro?minenceset le codage prosodique, Bulletin de phonologie dufran?ais contemporain, 6:69-79.Brechtje Post.
2000.
Tonal and phrasal structures inFrench intonation.
The Hague, Thesus.Brechtje Post, Elisabeth Delais-Roussarie and AnneCatherine Simon.
2006.
IVTS, un syst?me detranscription pour la variation prosodique, Bulletinde phonologie du fran?ais contemporain, 6:51-68.Elisabeth Selkirk.
1984.
Phonology and Syntax: theRelation between Sounds and Structure.
Cam-bridge, Cambridge MIT Press.Kim Silverman, Mary Beckman, John Pitrelli, MaryOstendorf, Colin Wightman, Patti Price, Janet Pi-errehumbert and Julia Hirschberg.
1992.
ToBI: Astandard for Labeling English prosody, Proceed-ings of the International Conference on SpokenLanguage Processing (ICSLP).
867-870.Anne Catherine Simon, Mathieu Avanzi, Jean-Philippe Goldman, 2008.
La d?tection des pro-?minences syllabiques.
Un aller-retour entrel?annotation manuelle et le traitement automati-que.
Actes du 1er Congr?s Mondial de LinguistiqueFran?aise, Paris.1673-1686.Caroline L. Smith.
2009.
Na?ve listeners?
perceptionsof French prosody compared to the predictions oftheoretical models.
Proceedings of the third sym-posium Prosody/discourse interfaces, Paris, Sep-tember 2009.Ann K. Syrdal and Julia McGory.
2000.
Inter-transcribers Reliability of ToBI Prosodic Labelling.Proceedings of the International Conference on272Spoken Language Processing, Beijing, China.
Vol.3, 235-238.Fabrizio Tamburini and Carlo Caini.
2005.
An auto-matic System for Detecting Prosodic Prominencein American English Continuous Speech.
Interna-tional Journal of Speech technology, 8:33-44.Colin W. Wightman.
2002.
ToBI or not ToBI?.
Pro-ceedings of Speech Prosody, Aix-en-Provence,France, 25-29.273
