A t3ottom-up Generation for Principle-based Grammars UsingConstraint PropagationMasato IshizakiNTT Communications and Information Processing Laboratories1-2356 Take Yokosuka-shi Kanagawa-ken, 238-03 JapanE-mail: islfizaki%nttnly.nt t.jp@relay.cs.netAbst ractA bottom-up generation algorithm forprinciple-based grammars is proposed.Bottom-up generation has (1) an ineffi-ciency because of a high degree ofnonde-terminism, (2) a limitation caused by in-ability to process logical forms producedby grammar rules, and (3) an identitysemantic problem.
This paper describesa solution to these problems and imple-mentation issues for the algorithm usinga constraint logic programming language.1 Introduct ionThe generation of strings from logical forms was stud-ied intensively by \[Shi88,89\]\[Ca189\].
The study ofthis problem shed light not only on the efficiency andsoundness of generation algorithms, but also on thedescriptive appropriateness of grammar itself.A generation algorithm based ou the Early'smethod has proposed, which is capable of analyzingand generating sentences in a uniform architecture\[Shi88\].
In this architecture the criterion of"seman-tic monotonicity" is assumed to reduce fruitless gen-eration.
As Shieber has mentioned, this method isstill inefficient and limited, and ,instead, has shownan efficient and general top-down generation algo-rithm using the semantic-head concept 1 \[Shi89\].An algorithm for Categorial Unification Gram-mar(C.UG) is mentioned in \[Ca189\].
As to the impor-tant ~:ole of lexicon, this grammar shares the sameproperty as principle-based grammars, but difthrs inthat CUG has grammar rules in the lexicon(Thisenables top-down generation with prediction as dis-cussed in \[Shi89\]).
The identity semantic problemand the lexical indexing problem are some of thesame problem noted in principle-based grammars.Generation based on Lexical Functional Gram-mar(LFG) is formalized in \[Wed88\].
He definedthe derivability and the generability of f-structure-to-string and semantic-structure-to-string mapping.These concepts seem to be suitable for top-downlPrecisely his a lgor i thm tMces a mixture of top-down andtop-down way.strategies.
His idea is intrigning in that discourseinformation, such as topic, can be reflected on anoutput string.
Bottom-up generation also has thepossibility of incorporating this information.
Thisissue will be discussed later.I propose a bottom-up generation algorithm forprinciple-based grammars, which makes use of thesame grammar as a parser.
Bottom-up generation isinefficient due to a high degree of nondeterminism.It is limited by its inability to process se,nantic ex-pressions created by grammar ules.
It also has anidentity semantic problem.
This paper describes thesolution to these problems and the issues concerningimplementation of the algorithm using a constraintlogic programming language, cu-PROLOG.First, the problems of bottom-up generation areshown.
Next the generation algorithm using con-straint propagation and solutions to these problemsare considered.
Third, some issues concerning imple-mentation and an example of this algorithm are men-tioned.
Finally, the problem of logical form equiva-lence, lexical indexing, and controlled search usingthe discourse information are discussed.2 Problems of Pr inciple-basedGrammar Generat ionPrinciple-based grammars like tlead-driven PhraseStructure Grammar(HPSG) or Japanese PhraseStructure Grammar(JPSG) seem to be inadequatefor top-down operations.
The reasons for this are;(1) as principle-based grammars have few skeletonrules, top-down operations that are  assumed to userules are not adequate for them,(2) much information is in lexical items instead ofgrammar ules in principle-based gramm~Lrs, and(3) the construction of semantic expressions i intu-itively adequate for bottom-up operations ~.Therefore, an efficient bottom-up generator forprinciple-based grammars must be developed.Bottom-up generation has two advantages; it canuse lexical information at an early phase, and canbot tom-up  strategy.
But generat ion is fundamentMly driven in a2U:aification can be used for bl-dlrectional operations.
However, if you need destruct ive semant ic  operat ions( 'destruct ive'  m ansthat  a resultant  semant ic  expressions cannot be constructed from base semantic expressions without  these special functions), uni-ficatlon cannot  be used for these operations.1188avoid the left recursion because of the property sim-ilar to bottom-up arsing, tIowever, bottom-up gen-eration has three problems\[Shi88,89\]\[Ca189\];(1) inefficiency because of a high degree of nondeter-minism,(2) limitation which is caused by inability to processsemantic expressions created by grammar ules, and(3) vestigial\[Shi88\], or identity semantic prob-lem\[Ca189\] (hereafter called identity semantic prob-lem).
(2) and (3) relate to completeness and coherenceproblems\[Wed88\].Inefficiency because of a high degree of nondeter-minism means that a naive bottom-up generation al-gorithm cannot use semantic information properly,and many semantic-irrelevant subexpressioas thatare syntactically correct will result.One of the reasons that Shieber adopted a top-down strategy is that he insisted on the existence oflogical tbrms produced by gramnmr ules.
This as-sumpti0n means that sub-semantic expressions can-not be derived from resultant semantic ones that aredifferent from normal ones.
It is shown later that ifwe permit this kind of destructive semantic opera-tion, we cannot obtain an efficient algorithm.An identity semantic problem is common amonggeneration algorithms using lexical-based grammars.The semantic expressions are classified into substan-tial eh'ments that contribute to the whole semanticexpres.~ions, and functional elements(these are iden-tity semantic expressions) without influencing thewhole ones.
Examples of tile functional elements arecomplementisers in English, or case-marking postpo-sition ~n 3apanese.
Simply speaking, the solution isto introduce these items at some time, but this alsoproduces high inefficiency.3 Pr inc ip le-based Grammar Gen-erat ionpendent of data, it does not incur such a problem.Hasida has shown that sentence analysis and syn-thesis can be described following a simple programwith a constraint, constitttent 3struct( Category,X,Y); constituent(Category,X,Y).If active constraint solving techniques are appliedto the problem, can this program be executed effi-ciently?
Active constraint solving is equivalent ofold/unfold transformation \[Tud89\].
If the constraintclause is simply unfolded, then the number of clausescreated will be the same as the number of lexicalitems.
Presently this is not an efficient way 4.If passive constraint solving techniques are used,then how is data obtained?
The answer is to predictthe base lexical item, which is the core of a sentence,using a top-down prediction analogous to a bottom-up parsing technique.gen(cat(P,F,Aa,Au,Sc,Sem)) :-pred(cat(P,F,Aa,Au,Sc,Sem),Sem,BaseLex),gen1(Sem,BaseLex,NewBaseLex,cat(P,F,Aa,Au,Sc,Sem)).genl(Sem,BaseLex,NewBaseLex,Cat)verify(NewBaseLex,Cat).genl(Sem,BaseLex,NewBaseLex,Cat)getLex(Sem,BaseLex,BaseLexl),gen1(Sem,BaseLexl,NewBaseLex).getLex(Sem,BaseLex,NewBaseLex) ' -getLex l (Sem,Lex) ;psr(Lex,BaseLex,NewBaseLex).getLex(Sem,BaseLex,NewBaseLex) "-getLex l (Sem,Lex) ,  introduceFLex(FLex);ps r (Lex ,FLex ,Lex l ) ,psr(Lexl ,BaseLex,NewBaseLex) .Figure 1: The generation algorithm.3 .1  Generat ion  A lgor i thm Us ing  Con-s t ra in t  P ropagat ionNatural language processing, such as sentence com-prehension and production, is thought of as con-straint satisfaction problems\[Has86\].
Constraintpropagation techniques are very effective in theseproblems\[Din86\].
Constraint propagation techniquesare classified into two methodologies: active con-straiut, which transforms constraints into more ef-ficient ones, and passive constraint, which is realizedby the function such as freeze in Metalog.
Passiveconstraint is similar to data-driven control, so if datadoes not arrive, the constraints are unsolved.
As ac-tive constraint solving transforms constraints inde-This generation algorithm is sketched by the cu-PROLOG, or proiogIII notation ill figure 1.
Tilepredicate gen produces a sentence string from theterm cat(P,F, Aa,Au, Sc, Sem,) 5, Tile term cat repre-sents a set of features: P is tile feature for part-of-speech, F is form such as verb inflection, Aa is ad-jacent node specification, Au is adjunct node specifi-cation, Sc is subcategorization information, and Sereis semantic information.
The predicate prod antici-pates BaseLez that is the core of a sentence(normallyhead verb), using part-of-speech and semantic infor-mation.
BaseLez has lexical and feature information.The predicate genl gets a lexical item, and appliesprinciples to the item and the base item until produc-ing a sentence, getLez extracts a lexical item that is3This is rather misleading.
An efficiency problem of generation and theoretical consideration about the problem are alsomentioned in \[Has86 I.4If other techniques are developed, this consideration isnot always correct.SAlthough this top predicate is a recognizer, constructing a tree or a string is easily realized with little effort.2189constrained by principles 6 using semantic informa-tion.
introduceFLez extracts an identity semanticitem that is constrained by principles.3.2 Counterarguments to Bottom-upGeneration Deficiency3.2.1 InefRciency Due to High Degree ofNondetermin ismC.onstraint propagation techniques in the previoussection remedies nondeterminism of a bottom-upgeneration problem.
An example of nondetermin-ism is the noun phrase generation in \[Shi89\].
If aNP occurs before a verb, different case NPs will begenerated nondeterministically in figure 2.eSp i verbe~PnFigure 2: Nondeterminism in NP generation.~PZeNPie.~P.?
JoeNP npsr (Daughter,ttead,Mother);member(Daughter,Head.subcategorization).psv represents a Mother --, Daughter Head rule.The predicate member is used as a constraint, whichsays the Daughter node is a member of a subcatego-rization of tire Head node.
The constraint propaga-tion process is shown in figure 3.verb  cor, st rair~s ,VPjdue to i t s  ~ubcate~or i za t ion  l~t .~ verbFigure 3: Reduction of nondeterminism in NPgeneration.Constraints can also eliminate the irrelevantphonolotgical expressions shown in \[Ca189\], and com-pactly express tire order-variant subcategorizationlist in JPSG.3.2.2 :L imitat ion Owing to Special  Semant ic:ExpressionsSuppose a Mother --~ Daughter Head rule, whereMother.sent = f(Daughter.sem, Head.sem)and semantic function f destructively createsMother.sem from Daughter.sere and Head.sere.
Thatis, Daughter.sem and Head.sere cannot be predictedfrom Mother.sere.
To get the value of Daughter.sereor Head.sere from Mother.sere, the inverse func-tion f -1  is needed.
The implicit assumption of in-versability of the function\[Shi89\] is very severe, and arather tricky feature structure must be constructedto escape the completeness problem.
Therefore, itseems better to use another function in a semantic-monotonous framework instead of this one.However, we can easily modify the predicate pre-dict to get another head using the semantic informa-tion to which the function is applied, if this inversefunction is obtained.3.2.3 An Ident i ty  Semant ic  P rob lemWhen using constraints to access fuuctlonal exicalitems, an exhaustive search is not required.
The in-sertion of Non-null constituents, uch as case markersand fnnctional nouns, can be restricted using variousconstraints (syntactic, semantic information).
Forexample, case markers that indicate the relationshipsbetween verbs and nouns are demanded by subcat-egori~ation information of the verbs.
By using theconstraint solving techniques, efficiency can be im-proved equal to or more than that of the top-downalgorithm.
Of Course since such occurrences(e.g, mdlconstituents, or gap) cannot be restrained, this con-venient mechanism cannot be used.
However, thissituation is the same as top-down algorithms.4 Implementation4.1 Grammar FormaUsm and Imple-mentat ion LanguageOur algorithm exploits JPSG as phrase structuregrammar formalism.
The concept of JPSG inheritsthe fundamental property of HPSG.
That is, JPSGmakes use of a set of feature-value pairs, feature con-straints and unification to stipulate Japanese gram-mar instead of rewriting rules for terminal and non-terminal symbols.
Subcategorization inforlnation isstored in lexical entries, instead of being stored ingrammar ules.Logical forms are expressed by the semantic rep-resentation language proposed by \[Hob85\].
The dis-tinctive feature of this language is its simplicity ofthe form for discourse processing.
The reason forthis simple form is; (1)a conjunction of atomic predi-cates, (2)all variables are existentially quantified withthe widest possible scope, and (3)there is no func-tions, functionals, nested quantifiers, disjunctions,negations, or modal or intensional operators.The algorithm is implemented using the cu-PROLOG developed in ICOT\[Tud89\].
The main fen-~A few phrase structure rules that observe principles, such as the head feature principle, are used in the program.3190~ure of this language is to adopt constraint unificationinstead of normal unification.
This gives it more de-:;criptive power and more deelarativeness than nor-real prologs.
The clause of cu-PROLOG is repre-sented as;h ,--- bl,b2,...,bn;el,c2,...,cnwhere h is a head, bl,b2,...,bn bodies, and cl,c2,_.,enconstraints.p,~r(cat(P,  F, \ [ \ ] ,  \ [ \ ] ,  Sc, Sere),ca t (Pos ,  Form, \ [ca t (P ,  F, \ [ \ ] ,  \ [ \ ] ,  Sc, Sere)\], Au, SubCat, SEM),ca t (Pos ,  Form, \ [ \ ] ,  Au, SubCat, SEM), \ [adjacent  p \ ] ) .\ ]?sr (cat (P ,  F, \ [ \ ] ,  Au, Sc, Sem),ca t (Pos ,  Form, \ [ \ ] ,  Adj, \ [ cat (P ,  F, \ [ \ ] ,  /lu, So, Sem) lKest \ ] ,  SEM),ca t (Pes ,  Form, \ [ \ ] ,  Adj, B.est, SEM),\[subcat p\] ) ; sc  cond(P ,Pos) .~,c cond(p.~v) .sc cond(adl l ,n) .sc_cond(n~p) .d ie t  (shorten,cat  (n ,n ,  \[\] , \[\] , \[\] , \[boy,X\] ) ) .d ie t  ( tama,cat  (n ,n ,  \[\] , \[\] , \[\] , \ [ba l l ,X \ ] ) )  .dict (ker,cat(v,vcr,\[\],\[\],S,\[\[kick,E,Sbj,Obj\],\[R1,Sbj\],\[R2,0bj\]\]));pp_wo ga(S,Obj,Sbj,R2,R1).d:i.et(ga,cat(p,ga,cat(n,F,lta,Au,Sc,Sem), \[\] , \[\] ,Sem)) .d: tc t (wo ,cat (p ,wo,cat (n ,F ,Aa ,Au ,Sc ,Sem) ,  \[\] , \[\] ,Sere)) .This grammar is shared with the parser mentioned in \[Tud89\]Figure 4: Part of grammar ules and a lexicon.shonen-ga  tama-~0 ke l ' -ucat  (v,  .
.
.
.
\ [ \ ] .
\[ \ [k i ck ,  1~:, X. Y\], \ [boy ,  X\].
\ [ba i t ,  ?
\ ] \ ] )ca t  (n .
.
.
.
.
\ [boy ,X \ ] )  ca t  (p, ga, .
, ~ ~ ~ ~ ~ ~ ~ ~  '  "~cat  (v .
.
.
.
.
.
\ [ ca t  (p, wo .
.
.
.  )
,  ca t  (p,  ga .
.
.
.  )
\] .
.
.
.
)Figure 5: The generation process example.This language has the ability to solve constraintsin an active or passive way, but we use it for passiveconstraint solving.4 .2  An  ExamplePart of the grammar rules and a lexicon, and theprocess of generation from the logical form,\[ \[ kick,E,X,Y \] , \[ boy,X \] , \[ ball,Y \] \]are shown in figure 4 and figure 5.The flow of the algorithm is described as fol-lows; First, base lexical item (1)(a top down pre-diction) is predicted.This prediction instanciates tilepacked subcategorization list, and constrains counoterpart conditions(2).
Next, a lexical item is usedto satisfy the constraints(2).
Since this goal cannotbe achieved by only the existing lexical item, a func-tional element is inserted that observes the restric-tion of the subcategoriz, ation list(3).
As for (4) and(5), a similar process continues until a sentence is191produced.
Finally we get an outputshonen-ga tama-wo ker-u.a boy a ball kicksfrom the semantic expression.Figure 6 shows the result tree of real cu-PROLOGexecution.v \[vcr\] : \[ \[kick ,E_2516 ,Y_2517 ,Y_2518\] , \[boy, Y_2517\] , \[ball ,Y_2518\] \] --- \[subcat_p\]- -p  \[ga\] : \[boy, Y_2517\] - - -  \[adj acenl;_p\]II --n \[n\] : \[boy, Y_2517\] --- \[shonen\]II __p \[ga, AJA{n \[n\] }\] : \[boy ,Y 2517\] --- \[ga\]__v\[vcr,SC{p\[wo\]}\]  : \ [ \ [k ick,E_2516,Y_2517,Y_2518\] , \ [boy,Y_2517\] , \ [bal l ,Y  2518\]\] .... \[subcat p\]- -p \ [a \ ] : \ [ba l \ ] : ,Y  2518\] - - -  \[adj acent p\]lI --n \[n\] : \ [bal l ,  Y_2518\ ]  - - -  \[t ama\]Il__p\[wo,AJA{n\[n\]}\] : \[bal l ,Y_2518\]--- \[wo\]_ V \ [VCr ,SC{p\[ga\ ] ,p \ [wo\]}\ ] : \ [ \ [k ick ,E  2516,Y_2517 ,Y 2518\], \ [boy ,Y 2517\] , \ [bal l ,Y_2518\] \ ] - - - \ [ker\]E = E_2516 X = Y_2517 Y : Y_2518 S = \[shonen,ga,tama,wo,keru\]Figure 6: The real execution result of the example using the cu-PROLOG.5 Remain ing Problems5.1 The  Prob lem o f  Log ica l  FormEqu iva lenceThe problem of logical form equivalence has been dis-cussed in \[App87\].
This problem concerns genera-tion algorithms which are sensitive to logical forms.Namely, if an input semantic expression is convertedby meaning postulates, different expressions withthe same meaning are produced by different proce-dures.This problem occurs in the generation of ex-pressions that have quantificational mbiguities.A conversion using meaning postulates does notneed syntactic or semantic information, but needsdiscourse information.
Since generation strategiessuch as \[Shi89\], \[Ca189\] as well as ours use syntac-tic and semantic information, it is reasonable not toconsider those operations.
However, algorithms musthave enough extendibility to reflect discourse infor-n'tation.5.2  Lex ica l  Index ing  St ra tegySearching lexical items is very important for efficientalgorithms.
Metaknowledge about semantic expres-sions is necessary for this purpose, especially in thecase of complex ones\[Cal89\].This problem is not peculiar to generation.
Forexample, discourse processing in which various infer-ences are executed by using the semantic expressionshas the same problem.
To cope with this problem,\[Hob85\] has proposed more simple logical forms.
Ialso consider this a good idea for generation.5 .3  Cont ro l l ing  Search  Us ing  D is -course  In fo rmat ionMany sentences corresponding to one meaning canbe generated by our algorithm(or other algorithms).Idealistically all sentences are distinctively producedaccording to other information such ~s discourse in-formation.
Our algorithm has the possibility for eas-ily realizing this mechanism.Suppose that an information uni~ agrees with apredicate in the semantic information.
Control of theelement position is realized by solving the constraintof the older information in turn r. Passivisation inJapanese is achieved by controlling the insertion offunctional elements.Transformational Grammar(the antecedent ofParameter and Principle theory) indicates the inter-esting piece of data that have many sentences withthe same meaning.
This concerns the position of theelements and the introduction of functional elements.As mentioned above, our algorithm is capable of re-fleeting discourse information on surface structuresbecause of constraints.~This assumpt ion  is problematic because correspondence is not guaranteed and if r~ semant ic  element is uniquely mapped to alexical entry, the posit ion is directly designated by the order of the semant ic  elements.5192The algorithm proposed in \[Wed88\] can generatesentences that reflect discourse phenomena such astopicalization i LFG, but the formalization of topicgreatly helps to simplify the algorithm.6 ConclusionIn this paper an efficient bottom-up generation algo-rithm for principle-based grammars using constraintpropagation is proposed, and a solution to bottom-up generation problems is mentioned.
Issues aboutimplementation a d an example processed by the al-gorithm are also shown.
Both the parser\[Tud89\] andthe generator use the same grammar, that is, thegrammar is reversible.Since problems not inherent in bottom-up gener-ation are connected to the logical form problem, orthe knowledge representation problem, they shouldbe discussed more deliberately from the viewpoint ofgeneration.AcknowledgementThe author wishes to extend his sincere gratitude toYoshihiko Hayashi, Tsuneaki Kato, and Gen-ichiroKikui for their comments on the initial idea of thisgeneration algorithm.
The author also wishes to ex-press his indebtness to Tuda ttirosi, and Hasida Koitiof ICOT for permitting him to use the cu-PROLOG.Thanks are also due to Dr. Terashima, Mr. Sakama,Mr.
tfigashida, Mr. Shimazaki and all the membersof the Natural Language Processing Division for theircooperation.ReferenceslApp87\] Douglas E. Appelt.
1987.
"Bidirectionalgrammars and the design of natural language gen-eration systems", Theoretical Issues in NaturalLanguage Processing - 3, New Mexico, 185-191.\[Cal89\] Jonathan Calder, Mike Reape, and HenkZeevat.
1989.
"An Algorithm for Generation inUnification Categorial Grammar", Proceedings ofthe 4tlh Conference of the European Chapter ofthe Association for Computational Linguistics,Manchester, 10-12 April, 233-240.\[Din86\] Dincbas, M. 1986.
"Constraints, Logic Pro-gramming and Deductive Databases", Proceed-ings of France-Japan Artificial Intelligence andComputer Science Symposium 86, Tokyo, 30November-3 December, 1-27.\[Has87\] Hasida Koichi and Isizaki Shun.
1987.
"De-pendency Propagation: a Unified Theory of Sen-tence Comprehension a d Generation", Proceed-ings of the 11th International Conference onComputational Linguistics, Milan, 23-28 August,664-670.\[Hob85\] Itobbs, R. 1985.
"Ontological Promiscuity",23rd Annual Meeting of the Association for Com-putational Linguistics, New Jersey, 61-69.\[Po187\] Carl Pollard and Ivan A.Sag.
1987.
"AnInformation-based Syntax And Semantics", Vol 1Fundamentals, CSLI  Lecture Notes Number 13.\[Gun87\] Takao Gunji.
1987.
"Japanese Phrase Struc-ture Grammar", D.Reidel Publishing Company.\[Shi88\] Stuart M. Shieber.
1988.
"A Uniform Archi-tecture for Parsing and Generation", Proceedingsof the 12th International C.onference on C, om-putational Linguistics, Budapest, 22-27 August,614-619.\[Shi89\] Stuart M. Shieber, Gertjan van Noord,Robert C. Moore, and Feraando C.N.Pereira.1989.
"A Semantic-Head-Driven Generation Al-gorithm for Unificati0n-Based Foriualisms", 27thAnnual Meeting of the Association for Computa-tional Linguistics, British Columbia, 26-29 June,7-17.\[Tud89\] Tuda Hirosi, Hasida Koiti, and SiraiHidetosi.
1989.
"JPSG Parser on ConstraintLogic Programming", Proceedings of the 4thConference of the European chapter of tile As-sociation for Computational Linguistics, Manch-ester, 10-12 April, 95-102.\[Wed88\] Jurgen Wedekind.
1988.
"Generation asStructure Driven Derivation", Proceedings of the12th International Conference on C'.omputationalLinguistics, Budapest, 22-27 August, 732-737.193
