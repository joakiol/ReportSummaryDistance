A PORTABLE APPROACH TO LAST RESORTPARSING AND INTERPRETAT IONMarcia C. Linebarger, Lewis M. Norton, Deborah A. DaMABSTRACTThis paper describes an approach to robust processing whichis domain-independent in i s design, yet which can easily takeadvantage ofdomain-specific information.
Robust processingis well-integrated into standard processing in this approach,requiring essentially only a single new BNF rule in the gram-mar.
We describe the results of implementing this approachin two different domains.1.
I n t roduct ionFor best performance, natural language processing sys-tems must be able to extract as much information aspossible from their inputs, even inputs which cannot befully processed.
In order to do this, systems must beequipped with robust processing mechanisms.
In addi-tion, cases also occur in which the system has the abilityto process an input, given sufficient ime, but it is not de-sirable to allow unlimited amounts of processing time.
Inthis paper we describe an approach to robust processingwhich is domain-independent in its general architecture,but which can be easily customized to particular domainsby simply listing key words and/or key concepts.
Theapproach uses the extensive grammar already availableto the system for standard processing but augments itwith a special BNF rule, called "backup", which is ableto prune the wordstream while it searches for key con-cepts.
Backup can be triggered either by a failure of nor-mal parsing or by timing out.
This approach as beenimplemented in two distinct domains.
In one of thesedomains, when sufficient ime is allotted to attain maxi-mal performance, backup results in an 18% improvementin score.
We describe the general approach, discuss howdifferences in the data in each domain lead to slightlydifferent implementations, and discuss our results.2.
ApproachThe approach to robust processing which is describedin this paper is implemented in the PUNDIT naturallanguage processing system developed at Paramax Sys-tems Corporation \[6, 1\].
PUNDIT includes a domain-independent, op-down parser \[7\] which is the primarycomponent involved in robust processing.
The key fea-ture of robust processing in PUNDIT is that the parserParamax Systems Corporat ion(a Unisys  Company)70 East  Swedesford  RoadPaol i ,  PA 19301is allowed to skip over words when it is unable to finda parse using every word.
Skipping is an appropriatestrategy for the data in the two domains we are workingwith, because parsing failures tend to be due to extra-neous material such as interpolated irrelevant commentsand false starts.
Another possible strategy, relaxation ofconstraints as suggested by \[19\], is less appropriate forthe data we have examined, since few parsing failuresare due to violation of grammatical constraints.
Skip-ping over words has also been implemented in the ro-bust parsing strategies of Seneff \[15\] and Strzalkowski\[18\]; our approach differs from these in that in additionto skipping, it provides a simple way of taking domain-specific knowledge into account in the skipping process.That is, when an analysis is not possible using everyword, the system begins searching through the word-stream for keywords (or words denoting key concepts),which are simply listed in a file.
The use of keywordspermits the system to make use of the domain-specificknowledge that certain words or concepts are importantin the domain.
In fact, in a mature domain, the list ofkeywords and concepts can be automatically generatedfrom the system's emantic interpretation rules.Because the backup mechanism is implemented byadding a single new BNF rule into the normal gram-mar, robust processing has been implemented in PUN-DIT without losing the advantages of the broad-coveragesyntactic grammar already in the system.
This is in con-trast to approaches like the template matcher discussedin \[8\] or the frame combiner discussed in \[16\] which arecompletely separate mechanisms from the standard lin-guistic processing components.In addition to inputs for which the system cannot find aparse using the standard algorithm, there are also caseswhere a complete analysis would be too costly in terms oftime.
The system can also invoke backup in these cases,using a variation of the timeout mechanism described in\[17\].
The timeout mechanism in \[17\] allocates an abso-lute amount of time per sentence; in contrast, PUNDIT'Stimeout allocates time as a function of the number ofwords in the input sentence so as not to penalize rela-tively longer sentences.31Previous approaches to robust processing have typi-cally either focused solely on data from one domain\[8, 16, 15, 4\] or have implemented a domain-independentapproach \[17\].
Both of these alternatives have disad-vantages.
Approaches which have been tested on onlya single domain cannot be guaranteed to be extensibleto other domains.
Entirely new approaches may be re-quired when the system is ported to another domain.
Onthe other hand, the performance of domain-independentapproaches may suffer in domain-specific applicationsbecause they are not able to use domain-specific knowl-edge to constrain the processing.
Our approach differsfrom previous approaches in that, while the basic archi-tecture is domain-independent, theapproach also allowsdomain-specific knowledge to assist in the processing.We demonstrate the general applicability of the archi-tecture by describing implementations in two distinctdomains.
Although the basic mechanism is the samein each domain, we also discuss differences in the im-plementation which follow from basic differences in thekind of data which must be processed.3.
DomainsWe now briefly describe our two application domains,with emphasis on those properties of the domains whichaffect the details of implementing backup "last resort"processing.3.1.
Air  Traffic Contro lAir traffic control (ATC) involves oral communication,as controllers interact with pilots via radio, issuing com-mands which govern the movements of planes both onthe ground and in the air \[3\].
Since the controllers arealready speaking into microphones, their half of this di-alogue is easy to capture in a high-quality signal.
Ifthis input can be understood, possible applications willrange from intelligent indexing for archival purposes toreal-time monitoring for safety and planning purposes.Utterances in the ATC domain tend to be short se-quences of relatively independent commands.
The rangeof possible commands is well-bounded, and controllersare trained to avoid expressing these commands in dif-ferent phrasings.
As a consequence, it is possible to sep-arate utterances into their constituent commands withhigh reliability, and similarly, to resume processing atthe next command if processing of the present commandfails for any reason.
Also, some commands may be irrel-evant for a given application.
For example, wind advi-sories could be ignored by an application only concernedwith ground operations.A sample well-formed utterance follows:Delta seven forty six turn right heading two seven zerocleared to land runway two nine left.3.2 .
A i r  T rave l  In fo rmat ion  SystemOur second domain is called ATIS (Air Travel Informa-tion System) \[12, 13, 11\].
This is basically a databasequery application.
The input utterances are retrievalrequests addressed to a database of information aboutflight schedules, fares, etc.
This application has beenset up by DARPA as an infrastructure for research inspoken language understanding.DARPA has arranged for the collection of data in thisdomain \[5\].
This data is spontaneous speech from naiveusers, who have no idea what phrasings will work andwhich will not.
Thus, they use an extremely wide setof variations for each request, so that the system is ex-pected to process inputs ranging from a vanilla Show meflights from Boston to Denver to I am going to have to goto Denver; I will be leaving from Boston, etc.
Disfluen-cies are more prevalent in this domain, since the speak-ers are not trained users.
Another feature distinguishingATIS from ATC is that ATIS utterances, no matter howdiscursive they appear, normally constitute a single re-quest.
Therefore parse fragments created by the backupmechanism seldom correspond to individual commandsas they do in the ATC domain; instead, a single requestmay give rise to several fragments which must be inte-grated during semantic and pragmatic processing 1.In both domains, since the input is spoken, there is theadditional possibility of errors introduced by the speechrecognition component.
While the techniques discussedin this paper have obvious applicability to recovery fromsuch errors, in what follows we will assume perfectionon the part of the recognizer, and that all errors anddisfluencies originate with the speaker.
Note, however,that current recognizers do not include punctuation intheir output, either within sentences or at the end ofthem.
We-therefore have included no punctuation i  ourdata.4.
Imp lementat ionGrammars used with PUNDIT have at the top level a BNFrule for the "center" node.
This rule is always a disjunc-tion of possibilities; for example, in a toy grammar, thecenter ule might expand to either assertion or question.In typical application domains this rule is more com-plex, including perhaps compounds and/or fragments.One important fact about the disjuncts for the presentdiscussion is that they are required to consume the whole1A detailed discussion of PUNDIT's general approach to frag-ments can be found in \[9\].32input word string in order to succeed.In any grammar, our approach to robust parsing is im-plemented by adding one additional disjunct at the endof the center rule.
We call this disjunct "backup".
TheBNF rule for backup has the following form:?
If positioned at a keyword, reset the time allotmentif necessary, then retry the other center options, re-laxing the requirement to consume the entire wordstring.
If a parse is found, call the center rule onthe remainder of the word string.?
If not positioned at a keyword, or if a parse is notfound in the previous tep, skip to the next keywordif any, reset the time allotment if necessary, and callthe center rule on the word string starting with thekeyword.
If no keyword is found, fail.The backup rule is entered either if normal parsing fails(i.e., none of the other disjunets of the center rule pro-duce a parse consuming the whole word string), or iftimeout occurs.
Users specify an amount of time in theform of a number (possibly fractional) of seconds perword, so that longer inputs are given more time.
Oncetime has expired, no rule will execute xcept he backuprule, which will reallot time based on the length of theremaining word string, and then proceed as describedabove.The opportunity for introducing domain knowledge toinfluence the behavior of the backup rule comes in thespecification of the keywords.
To discuss what we havedone in the two domains we experimented with, we firstneed to introduce the PUNDIT knowledge base.
This issimply a mapping of word tokens to a hierarchical set ofconcepts \[10\].
Synonyms usually denote the same con-cept.
The "is-a" relation is defined over the hierarchy,so that a concorde is-a jet is-a plane, a propeller_planealso is-a plane, etc.The keywords used by backup can be specified as wordtokens or as concepts.
In the latter case, the concept istaken to refer to any word token that maps to the con-cept or any descendant of the concept in the knowledgebase.
Keywords may also be specified by syntactic at-egory, e.g., determiners or tensed verbs may function askeywords.4 .1 .
A i r  T ra f f i c  Cont ro lIn the ATC domain, we designated only word tokens askeywords.
Furthermore, the list of keywords was chosenmanually with great care, and is not very extensive.
Thechoices were dictated by tile semantics of the possiblecommands which controllers may issue, and the normalphraseology (defined by the FAA) for expressing thosecommands.
The intent, which we were able to achieveto a large degree, was to have skipping to the next key-word be equivalent o skipping to the start of the nextcommand.
Most of the keywords are verbs, correspond-ing to the imperative form most often used to expresscommands.4 .2 .
A i r  T rave l  In fo rmat ion  SystemIn contrast, the list of keywords for the ATIS domainis much larger, and consists mostly of concepts, whichin effect makes it even larger in terms of words.
Thebasic idea is not to skip over any word which might beuseful.
Thus we included prepositions, wh-introducers,and such word tokens, plus all the concepts known to thePUNDIT semantic interpreter for that domain.
This list ofconcepts was obtained mechanically from the files driv-ing the interpreter, followed by the removal of conceptswhich were descendants of other concepts in the list, forthese would be redundant for the purposes of the backupprocedure.
As a consequence, the only words skippedare meaningless (to the semantic interpreter), includingunknown words.An ATIS utterance normally constitutes a singledatabase retrieval request.
Therefore an additional stepin this domain is to integrate the parse fragments ob-tained by the robust parsing procedure.
We delegatethis responsibility to the semantic and pragmatic inter-preter \[14, 2\].
For those fragments which are completesentences, no extensions are necessary.
The interpretermerely treats them as distinct sentences coming in se-quentially in the context of the ongoing dialogue.For true fragments we did need to add some new capabil-ity.
We assume that the overall content of the utteranceis either a request for some flights or some fares.
Fornoun phrase fragments, either the head is a flight or afare, or it is not.
If it is, our normal reference resolutioncapabilities are sufficient o resolve the flight or fare withany other flight or fare in the context 2.
If the head isnot a flight or fare, flight and fare entities are explicitlygenerated into the context space maintained by the se-mantic interpreter, and the fragment is interpreted as amodifier of either the flight or the fare.
Then normal ref-erence resolution takes over.
For example, the fragmentafternoon ends up with the same semantic representa-tion as does afternoon flight, and the system proceeds asbefore.2This is because dialogues often proceed like the following:Show me flights from Boston to Denver.
\[answer\] Show me justafternoon flights.
So in effect, afternoon flights is treated as showafternoon flights \[2, 13, 11\].33Prepositional phrase fragments are treated in a mannercompletely analogous to noun phrase fragments whoseheads are not flights or fares.
For example, in the af-ternoon becomes flight in the afternoon, and the systemproceeds as before.The data for this domain has not warranted treatmentof any other fragment ypes.5.
Resu l ts5.1 .
A i r  T ra f f i c  Cont ro lWe performed experiments on a set of 233 utterancesin the ATC domain, incorporating utterances from twodifferent controllers.
One was guiding planes which hadjust landed; the other was guiding planes as they taxiedin preparation for takeoff.Substantial benefits are gained from using backup, or"last-resort" processing, after normal parsing fails or atimeout occurs.
Figure 1 shows that application accu-racy is improved by the use of such processing, at two dif-ferent settings of the timeout parameter.
In fact, perfor-mance with backup at the lower timeout setting clearlyexceeds performance without backup at the higher time-out setting.
The improvement comes at a cost of in-crease(\] cpu time, as can be seen in Figure 2; the increaseis less for the higher value of the timeout parameter, eventhough the benefit to accuracy remains high.Figure 1: Effect of backup on score0.50.40.3,~  0.2C0.1\ [ \ ]  backup?
no  backup0.3Timeout Parameter1.1Figure 2: Effect of backup on runtimeWe investigated the effects of varying the timeout param-eter when backup processing is in use.
Recall that thisparameter is the amount of cpu time allotted for eacl~word of an utterance before timeout.
Backup processingresets this allotment, adjusted for the current positionin the utterance, so that the amount of time spent pro-cessing an utterance can increase by a factor of two tofour over the initial allotment, depending on the numberof keywords in the utterance.100 ?908 7oO~i i - - - - l i - - I I  ?I I I I I i $ I ( I I I ( I0,1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5Timeout ParameterFigure 3: Effect of varying timeoutFigure 3 shows the results of our investigation.
A settingof the timeout parameter below 0.3 is clearly undesirable.A setting of 0.3 enables the system to process correctlyall but a handful of the utterances it could handle at ahigher setting; that is, the curve changes at this point toa nearly horizontal orientation.
At a setting of 1.1, thesystem achieves maximal performance accuracy.
Some-what surprisingly, if the utterances of each controller areconsidered separately, these findings remain the same,even though the content and phrasing of the utterancesvary noticeably.The optimal setting of the timeout parameter dependson the relative costs of processing time and applicationerrors.
The 0.3 setting might be optimal for archival pur-poses or high volume processing.
The 1.1 setting mightbe necessary for applications which demand maximal ac-curacy at any cost.5 .2 .
A i r  T rave l  In fo rmat ion  SystemAs examples of data which our system handles prop-erly, we list some inputs which are successfully processed.All of them were previously unseen test data from theNovember 1992 ATIS test.
None of them would resultin a parse from normal parsing.
These inputs includefalse starts, corrections, constructions not covered by ourgrammar, and breaks in parsing due to unknown words.Our technique contributes for all these phenomena.I would like to do you have any flights between Philadel-phia and Allanta (false start)Okay shoot I would have to choose the Delta flight nineseventy seven departing at twelve pm and arriving in SanFrancisco at two ten pm shoot and choose were unknownwords, but the system recovers and understands the cho-sen flight.34Okay American Airlines does it leave Philadelphia forDallas in the mornings Left dislocation, not in our gram-mar; the airline is parsed as a fragment separate fromthe main body of the question, and semantic processingintegrates the two parses correctly.Yes could you please give me a list of all American Air-line first class flights lo from Philly to Dallas Fort Worthplease The correction of the preposition at to from Phillyis successfully handled by our technique; to is dropped,and parse fragments are produced for the rest of the in-put starting at from.Quant i ta t ive  Resu l ts  Because the semantic integra-tion of fragmentary information is still in progress, therobust processing mechanism did not affect our finalscore on the ATIS evaluation.
However, we did lookclosely at the effect of robust processing on parsing ac-curacy, in order to answer the following two questions:?
How much does the backup mechanism improveparsing accuracy??
How often does the backup mechanism do the rightthing?In order to answer the first question, we compared theproportion of usable or potentially usable non-X parseswhich the system produced with and without backupon the subset of the 1992 ATIS test collected at BBN.Without backup, 77% of the parses were usable; withbackup, 88% were usable.
Thus, backup resulted in an11% increase in the number of usable parses.In order to answer the second question, we looked at theparses produced by backup.
We found that 45% of themwere usable or potentially usable by semantics.
Of theparses that were not usable, we found that most of thetime they were unusable because the system did not haveinformation about some semantically important word inthe sentence.
Because of this missing information, thesystem ended up ignoring the word, and consequentlythe parse did not contain this important word.
The factthat many of the unusable parses were due to lexicalgaps was encouraging, because it means that the backupmechanism will continue to improve in this respect sim-ply as new words are added to the system in the normalcourse of development.6, Conc lus ion  and  Future  D i rec t ionsWe have described a domain-independent approach torobust processing which can be customized to particulardomains through the simple mechanism of building a listof keywords, where keywords may correspond to specificword tokens, syntactic ategories, or semantic oncepts.The approach was tested in two different domains, ATCand ATIS.
Differences in the way that information isconveyed in the two domains necessitated slight differ-ences in the implementations across the two domains; inparticular, additional semantic processing was requiredin the ATIS domain to put together information fromthe fragmentary outputs of the parser.
Future plans in-clude development ofkeyword selection techniques, bothdomain-independent and domain-specific; and improve-ments to the semantic integration process.Re ferences1.
Deborah A. DaM.
PUNDIT - natural language inter-faces.
In G. Comyn, N.E.
Fuchs, and M.J. Ratcliffe, edi-tors, Logic Programming in action, Heidelberg, Germany,September 1992.
Springer-Verlag.2.
Deborah A. Dahl and Catherine N. Ball.
Reference reso-lution in PUNDIT.
In P. Saint-Dizier and S. Szpakowicz,editors, Logic and logic grammars .for language p,vcess-ing.
Ellis Horwood Limited, 1990.3.
Deborah A. Dahl, Lewis M. Norton, and Nghi N. Nguyen.Air traffic control instruction monitoring using spokenlanguage understanding.
In Proceedings of the 36th AirTraffic Control Association Meeting, Atlantic City, N J,November 1992.4.
Philip J. Hayes and George V. Mouradian.
Flexible pars-ing.
American Journal of Computational Linguistics,7(4):232-242, 1981.5.
Charles T. Hemphill, John J. Godfrey, and George R.Doddington.
The ATIS spoken language systems pilotcorpus.
In Proceedings o\] the DARPA Speech and Lan-guage Workshop, Hidden Valley, PA, June 1990.6.
L. Hirschman, M. Palmer, J. Dowding, D. Dahl,M.
Linebarger, R. Passonneau, F.-M. Lang, C. Ball, andC.
Weir.
The PUNDIT natural-language processing sys-tem.
In AI Systems in Government Con\].
Computer So-ciety of the IEEE, March 1989.7.
Lynette Hirsehman and John Dowding.
Restrictiongrammar: A logic grammar.
In P. Saint-Dizier and S. Sz-pakowicz, editors, Logic and Logic Grammars \]or Lan-guage Processing, pages 141-167.
Ellis Horwood, 1990.8.
Eric Jackson, Douglas Appelt, John Bear, Robert Moore,and Ann Podtozny.
A template matcher for robust NLinterpretation.
In Proceedings of the DARPA Speech andNatural Language Workshop.
Morgan Kaufmann, Febru-ary 1991.9.
Marcia C. Linebarger, Deborah A. Dahl, LynetteHirschman, and Rebecca J. Passonneau.
Sentence frag-ments regular structures.
In Proceedings o\] the 26th An-nual Meeting of the Association for Computational Lin-guistics, Buffalo, NY, June 1988.10.
David L. Matuszek.
K-Pack: A programmer's interfaceto KNET.
Technical Memo 61, Unisys Corporation, P.O.Box 517, Paoli, PA 19301, October 1987.11.
Lewis M. Norton, Deborah A. DaM, and Marcia C.Linebarger.
Recent improvements and benchmark re-suits for the Paramax ATIS system.
In Proceedings ofthe DARPA Speech and Language Workshop, Harriman,New York, February 1992.3512.
Lewis M. Norton, Deborah A. DaM, Donald P. McKay,Lynette Hirschman, Marcia C. Linebarger, David Mager-man, and Catherine N. Ball.
Management and evalua-tion of interactive dialog in the air travel domain.
InProceedings of the DARPA Speech and Language Work-shop, Hidden Valley, PA, June 1990.13.
Lewis M. Norton, Marcia C. Linebarger, Deborah A.Da~hl, and Nghi Nguyen.
Augmented role filling capabil-ities for semantic interpretation of natural anguage.
InProceedings of the DARPA Speech and Language Work-shop, Pacific Grove, CA, February 1991.14.
Martha Palmer.
Semantic Processing ]or Finite Do-mains.
Cambridge University Press, Cambridge, Eng-land, 1990.15.
Stephanie Seneff.
A relaxation method for understandingspontaneous utterances.
In Proceedings o] the DARPASpeech and Natural Language Workshop.
Morgan Kauf-mann, February 1992.16.
David Stallard and Robert Bobrow.
Fragment processingin the DELPHI system.
In Proceedings of the Speechand Natural Language Workshop, San Marco, California,1992.
Morgan Kaufmann.17.
Tomek Stralkowski.
TTP: a fast and robust parser fornatural language.
Technical report, New York UniversityDepartment of Computer Science, New York, NY, 1991.18.
Tomek Strzalkowski and Barbara Vauthey.
Informationretrieval using robust natural anguage processing.
InProceedings of the Thirtieth Annual Meeting of the As-sociation for Computational Linguistics, pages 104-111,1992.19.
R. M. Weischedel and N. K. Sondheimer.
Meta-rules as abasis for processing ill-formed input.
American Journalof Computational Linguistics, 9(3-4):161-177, 1983.36
