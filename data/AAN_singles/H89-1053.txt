Automatic Discovery of Contextual FactorsDescribing Phonological VariationFrancine R. Chen and ,Jeff ShragerXEROX PALO ALTO RESEARCH CENTER3333 Coyote Hill RoadPalo Alto, CA 94304AbstractIn this paper we describe a method for automatically discovering subsets of contextual factors which,taken together, axe useful for predicting the realizations, or pronunciations, of English words for contin-uous speech recognition.
A decision tree is used for organizing contextual descriptions of phonologicalvariation.
This representation enables us to categorize different realizations according to the context inwhich they appear in the corpus.
In addition, this organization permits us to consider simplificationssuch as pruning and branch clustering, leading to parsimonious descriptions that better predict allo-phones in these contexts.
We created trees to examine the working assumption that preceding phonemeand following phoneme provide important contexts, as exemplified by the use of triphones in hiddenMaxkov models; our results were in general accordance with the assumption.
However, we found thatother contexts also play a significant role in phoneme realizations.Introduction-Context Sensitivity in RealizationsPhonologists claim that the context in which a phoneme occurs leads to consistent differences in how it ispronounced.
For example, one phonological rule may state that the phoneme/t / is  often flapped when it ispreceded and followed by a vocalic (as in "butter").
The construction of these rules is typically an intricateprocess of theory formation, rule construction and then validation or disconfirmation f these rules.In this paper we describe an approach to partially automate rule construction, allowing for a largernumber of examples to be examined and checked for consistencies.
Our examples come from comparingtranscriptions of spoken speech with a dictionary representation f the words spoken.
We shall call thedictionary pronunciation symbols phonemes and define the realizations, or allophones, of a phoneme to bethe set of transcription symbols corresponding to that phoneme.
For example, pronunciations of the phoneme/t/ include the released, flapped, and unreleased realizations as characteristically occur in "tap", "butter",and "pat new", respectively.
In addition, we shall refer to a context as having values.
For example, thecontext stress has values primary, secondary, and unstressed.The approach is based on automatically forming and simplifying decision trees.
Decision trees have beenused for both understanding and classification of data (Henrichon and Fu, 1969).
In our application, theyprovide a way of using context o organize the various realizations of a phoneme.
The probability of arealization varies with the context in which the phoneme occurs.
Contexts which have similar realizationdistributions are grouped together.
The decision tree thus provides a method for representing the partitionsof allophones with dissimilar probabilities, based on context.Decision trees can be formed automatically (Breiman et al, 1984; Quinlan, 1986) and converted to rules(Quinlan, 1987).
The problem addressed here is to construct decision trees that are appropriate for use inthe construction ofpronunciation rules and for predicting realizations in context.
In addition, an importantpart of the tree induction method is the discovery of appropriate descriptive categories for the formation ofsuch trees.
These categories often resemble theoretical categories, uch as vocalic or plosive, and define theorganization of the tree.MethodTo organize the realizations of a phoneme according to context, we adapted a decision tree induction methodbased upon ID3 (Quinlan, 1986).
The nodes of the tree represent the attribute upon which the branching isbased.
In a pronunciation tree, as in Figure 1, the various contexts correspond to attributes.
Each branchof a tree represents a different value of an attribute.
For example, in Figure 1 the context syllable boundary(SYLL-BDRY) can take on the values final (F) and initial (1) or not-initial-and-not-final (NI-NF).
Associated witheach leaf in the tree are the exemplars that are characterized bythe context values encountered in traversingthe tree from the root node to reach the leaf.
The exemplars are grouped into classes, which correspond to284\]POST-PHONEME s I \](- 94) (.
S) 2J //lC h t $ ~ D e Y 9 ^ p E f d I PIIL b k,LL-.,, .
/ I ' " ' ' " ??
Ir 3 / IPRE-PHOPIEIIE 6'~JPRE-PHOPIEHE 118|e l  r i 1Y j ? "
n IISYLL-BI\]RY 18~POST-PHOrIEflE l l r t  I ,(- 9B) (* 2) 12,|111-MF I I "~..JPOST-PHOPIEPIE I l oY~.o~U==:^E.Z  R,~ ~L  t3  I(- too) ,41I(:"'88) (.
20) 51I(- 188) 71I(- 68) (?
32) 91Figure h Pruned tree showing contexts when / t /  is glottalized (+) and not glottalized (-).
Nodes arenumbered in the upper right corner of each box.realizations of a phoneme in our application, and the percentage of each realization in a leaf is paired withthe class label.Two characteristics of speech are captured by our tree representation: 1) A phoneme can be pronouncedin multiple ways, as in the previous example wi th / t / ;  and 2) The number of values for some contexts may belarge.
For example, the context preceding phoneme has 46 values in our dictionary's alphabet.
Splitting on all46 values rapidly decreases the number of exemplars per node.
These two characteristics are accommodatedby using a general metric in tree induction and by using clustering of context values, both of which aredescribed in the next sections.Tree Induct ionA decision tree is induced by recursively splitting a node into new nodes.
At each node the attribute isselected which has values that best separate the realizations of the data, (i.e., make each node "purer'l).The exemplars in the current node are subdi~,ided according to the value of the selected attribute for eachexemplar, creating a new set of nodes.To handle multiple realizations, we used a reduction of entropy criterion with a variable number ofpossible classes.
Intuitively, as entropy is reduced, the nodes of the tree become purer and the differentrealizations are better separated.
We briefly review the criterion calculations here (adapted from Breimanet aL, 1984; Chou, 1988; Gallager, 1968; and Ganapathy and Rajaraman, 1973).Before splitting, the entropy at a node based on classes X is H(X).
The average ntropy of the classes inthe new nodes created by splitting on the values V of a given attribute is: E(H(XIv)) = ~v P(v)g(XIv)"The average ntropy can also be expressed as the conditional entropy of class X given attribute values V, orH(XIV ).
Thus the gain for attribute a, G(a), which is the difference between the entropy of the classes ata node, H(X), and the conditional entropy of X given V at a node, is the mutual information between Xand V: G(a) = H(X) - H(XIV ) = I(Z; Y).
To normalize for the variable number of attribute values, thegain for attribute a is normalized by the entropy of the number of values associated with a. Quinlan callsthis the gain ratio: R(a) = G(a)/H(V).
The attribute which maximizes the gain ratio, R(a), is selected forsplitting.This decision tree induction procedure is used in our application to separate the different realizations ofa phoneme based on context values.
In the next section we discuss the clustering procedure which groupscontext values with similar realization distributions to potentially reduce the number of splits at a node andform categories.C luster ing of A t t r ibute  ValuesTraditionally, in tree induction, nodes are split either along all values of an attribute (e.g., Quinlan, 1986)or else binary splits are used (e.g., Breiman ?t ai., 1984).
When there are only a few values per attribute,splitting along all values of an attribute will not reduce quickly the number of exemplars per node.
Butz A pure node contains exemplars of only one realization type.285sometimes attributes may have many different values.
In speech, some of the values are thought o be similarin their influence on sound realizations; hence, in theory one would not want to split separately on all values,but instead would like to keep sounds with similar effects together.
The values could be pre-clustered by aperson according to theoretical ideas of what is similar, but the groupings may change depending on context.Alternatively, the values could be clustered into a predefined number of groups at each node (Chou, 1988).However, the appropriate number of groups is not the same for all sounds and again may depend on thecurrent context.
Thus, we want to cluster the values of each context at a node and want the number ofclusters to be determined by the exemplars in the node.
The context values within each resulting roup willthen be similar in their prediction of the distribution of realizations.Hierarchical clustering is used to group the values of an attribute.
This type of clustering was chosenbecause it allows the number of clusters for each set of attribute values to be determined from the data, ratherthan predefined.
Mutual information is used as the distance metric and is computed as in Jelinek (1985).That is, let the average mutual information between context value or attribute value vi and realizations orclasses X be:The increase in average mutual information resulting from pairing two attribute values vm and v, is thedifference between the average mutual information resulting from pairing vm and vn and the contribution tothe average mutual information before pairing v,~ and v, : AI (V ;  X )  = I(v,~ U v,; X )  - I(v,,~; X )  - I (v , ;  X) .At each iteration, the pairing that results in the largest increase in mutual information is selected andforms a new cluster.
This is continued until one of the following conditions for stopping is reached: 1) Thereare only two clusters left; 2) The increase in the mutual information is negative and more than doublesfrom one iteration to the next; 3) The increase in the mutual information measure decreases more thana threshold, which we set at -30.
At each iteration, the increase in mutual information is often negativebecause some information is usually lost each time a new cluster is formed.
The conditions for stoppingdefine when the loss in mutual information is too great to continue clustering.Since we cluster the values of each attribute prior to splitting, it may be useful to split on this attributeagain under a more specific context (i.e., farther down the tree).
Thus, in contrast o ID3, after an attributeis selected for splitting, it is not removed from the set of attributes considered.
This is also the case in thebinary split method of Breiman et al (1984); however, our method has the potential of providing meaningfulsplits which accommodate graded categorization i the realizations.Pruning of TreesA tree that has been constructed by this method may be too specialized to the training exemplars.
Inthe extreme case, each leaf is pure, which is not desirable because such a tree would not be robust withrespect to new data.
In understanding the relationship between contexts and realizations, we want touncover generalizations.
This can be achieved by pruning, which combines ubtrees, resulting in moregeneral distinctions.
Many methods of pruning have been suggested (e.g., Breiman et al, 1984 and Chou,1988), but in general their primary goal is to optimize the probability of error versus some characteristic ofthe tree, such as average length or number of leaves.Since our concern is to use only the parts of the tree which will be robust to new data, a differenttype of pruning was used.
First, nodes are extended only when the number of exemplars is greater than aspecified threshold (Breiman et al, 1984); we used 20.
In addition, only nodes relevant o the classificationof exemplars are kept.
A chi-square test (Quinlan, 1986) at the .01 level of significance is used.
Each tree isalso pruned by running a separate set of exemplars, or cross-validation set, through the constructed tree.
Ifthe cross-validation exemplars in a node indicate that an attribute is not relevant o the classification of theexemplars in a node, the subtree beginning at the node is collapsed into a leaf.DataThe data comprised almost 30,000 hand-transcribed segments from approximately 900 of the "sx" sentencesfrom the TIMIT acoustic-phonetic speech database (Lamel el al., 1986; Fisher et al, 1987), spoken by morethan 180 different speakers.
Trees were induced using 60% of the data; the results that will be described arebased on trees pruned on the remaining 40% of the data.
The transcribed TIMIT data were automatically286contextpreceding phonemefollowing phonemesyllable partstresssyllable boundary typefoot boundary typeword boundary typecluster typeopen syllable?true vowel?function word?values(all phonemes)(all phonemes)onset, nucleus, codaprimary, secondary, unstressedinitial, final, not-initial-and-not-final, initial-and-finalinitial, final, not-initial-and-not-final, initial-and-finalinitial, final, not initial-and-not-final, initial-and-finalonset, coda, niltrue, falsetrue, falsetrue, falseTable h Contexts used in pronunciation experimentsaligned to the dictionary baseforms from the Merriam-Webster ~0,000 Word Pocket Dictionary to producemappings between dictionary phonemes and transcribed segments.
Each mapping was then described by aset of theoretically motivated contexts based on a set used by Withgott and Bagley (1987) in a pronunciationgeneration system.
These contexts and corresponding values, which are the union of possible values over allphonemes, are listed in Table 1.
Note that some contexts, uch as stress and foot-boundary efer to how thephoneme functions within a larger unit.
Because lexical context is used, contexts uch as foot-boundary areeasily determined.
Also note that the context values based on adjacent phonemes are defined across wordboundaries.
For example, in the phrase "two words" the post (following) phoneme to /u /  would be/w/ .Some of the common predicate rule contexts were combined into a context ype and the clustering algorithmwas used to group these values to form predicates when appropriate.
For example, the predicates syllable-initial?, syllable-final?, and syllable-internal?
were combined into the type syllable-boundary.
The predicatesyllable-initial?
is formed when the values of syllable-boundary-type are clustered into the groups {initial} and{final, not-initial-and-not-final, initial-and-final}.Resu l tsA sample tree constructed using the previously described method is shown in Figure 1.
This tree is for thespecial case describing whether/t /  is glottalized.
A context other than preceding phoneme and followingphoneme is incorporated; the first split (nodes 0 and 10) in this tree is on syllable boundary (SYLL-BDRY),indicating that when / t /  is glottalized it is generally in syllable-final position.
Note that grouping thesyllable boundary context values not-initial-and-not-final (NF-NI) and initial (I) separately from final (F) canbe interpreted as the predicate syllable-final?.
Without clustering, selection of this attribute would resultin a three-way split.
Further examination of this tree suggests additional conditions on this generalization.For example, node 3 may be described as containing a subset of voiced sounds; in particular all semivowelsand nasals and most of the voiced fricatives and tense vowels.
Node 1 contains primarily plosives, unvoicedfricatives, and lax vowels.
Additionally, the nodes labeled 5 and 9 are preceded by PRE-PHONEME nodescontaining vocalics.
Thus, we might produce a more precise rule, predicting that a / t /  in syllable-finalposition and preceded by a vocalic will be glottalized with greater likelihood when preceded by a phonemem node 8 than in node 4.Along with trees such as these, we have constructed 45 general trees, one for each phoneme in thedictionary.
These trees were more general in that all the realizations of a phoneme composed the classes.Twenty of the trees (p t k b d g m n w h u U i I I E x c s T) had preceding phoneme and following phonemeas their initial contexts for splitting; in nine trees (C J r l y e A Z D) preceding phoneme but not followingphoneme appeared in the first two levels; and in eight trees (G o Y @ a z f v) the following phoneme butnot preceding phoneme appeared in the first two levels.
This agrees with the common working assumptionthat preceding phoneme and following phoneme are the most important contexts for describing phonologicalvariation.
However, we also observed that other contexts are useful for differentiating among the realizationdistributions.
The additional contextual factors which appeared in the first two levels of the tree and the287\]FMC-NORD-PIPRE-PHOIIEIiE ~K " "\]"It" T i e ~ G d S R Y FIIL u r C t s d 0%|FOOT -BDRY//~NI -NF\~PRE-PHOMEflE|h u t" k m b 9 n 1 p z 8 ~;OOT-BORY1 F~ 100)2 I\]PRE-PHO.EME 4 l(jh ~5) (v 25) 513' //\]d CK \PRE-PHONEME s6 l(w 90) (sh 5) (MIL 5) TGRur t|PRE-PHOMEME 101 ~(v 62) (NIL 3S) 1119~.. .
/ /~9 1 n f P " b k I|'~-,JPRE-PHOHEME|h u 12 I (y  03) (N IL  1F) 13 I14 I(V 86) (=h 14) 151Figure 2: Pruned tree of/y/realizations.
Nodes are numbered in the upper right corner of each box.number of times each appeared are: stress 13, function-word7 8, foot boundary type 5, syllable boundarytype 5, syllable part 3, open syllable?
1, and word boundary type 1.By using a clustering technique in which the number of groups was determined by the data, many timesthe preceding and following context categories corresponded tolinguistic ategories, uch as place or manner.For example, the POST-PHONEME values in the /s/ realizations were clustered into the set {~, ~, V} and theset of all other phonemes.
In addition, the predominance of preceding phoneme and following phoneme asuseful contextual factors is due in part to the flexibility in the number of groups.Discuss ion-Relevance to Speech  Recognit ionContexts used in the creation of pronunciation networks for some hidden Markov model speech recognitionsystems have been limited.
This is partially due to the amount of data needed to train the network unitsin which context is represented.
These units include whole word models, where phones are represented inthe context of the word in which they occur (e.g., Paul, 1988), generalized triphones (Lee, 1988), and ahierarchy from words to subsets of triphones (Chow et al, 1986).
Whole word models provide the mostcomplete context of the internal phones, but usually do not model word boundary effects well.
Although asubword unit, such as the triphone, can be concatenated into word models, thus providing easy additionsto the lexicon, triphones account for only a subset of contextual factors.
Work using log-linear modeling(Chen, 1987) has shown that use of only the preceding and following contexts do not adequately describerealization distributions.To test the common working assumption that preceding phoneme and following phoneme are the mostuseful contextual factors, as in triphone models, we examined the contexts in the trees constructed for eachphoneme.
As stated in the previous ection, when the realizations of a phoneme are considered jointly,the preceding phoneme and following phoneme are the most useful contexts overall.
However, additionalcontextual factors other than preceding phoneme and following phoneme can provide better estimates of thelikelihood of different realizations.
We thus suggest a mixed context unit based on the partitioning repre-sented by the computed trees for use in continuous speech recognition.
The organization ofthe phonologicalrealizations into trees provides a way to specify contexts for creating models intermediate in the continuumof context models from adjacent phone to whole word.
A subset of a predetermined set of possible contextswhich are useful for differentiating among the realization distributions i identified.
This subset is a largernumber of contexts than the data would permit if the selected contexts were always considered together.Consequently, a larger overall number of contexts can be used for describing the realizations.
For exam-ple, in Figure 2, the contexts of PRE-PHONEME, FNC-WORD-P, and FOOT-BDRY are used for describing therealizations o f /y / ,  but only two contexts, either eRE-PHONEME and FNC-WOaD-P or PRE-PHONEME andFOOT-BDRY, are used to describe ach leaf.In tree induction, different realizations are considered simultaneously and the partitioning based oncontext values is mutually exclusive.
By considering all realizations of a phoneme simultaneously, the overallusefulness of the different contextual factors is analyzed.
The set of selected contexts generally is not thesame as those chosen in trees in which the occurrence ofeach realization of a phoneme isseparately computed.Since each exemplar belongs to one set of context values because of the partitioning, the proportion of eachrealization for each set of context values can be estimated.288ConclusionsIn our work describing phonological variation for speech recognition, we use a systematic, data-intensiveapproach.
Contexts are identified that correlate with the phonological variation exhibited in a large hand-transcribed atabase of utterances.
From these correlations, we identify useful context descriptions.
Thecombination of decision tree induction and hierarchical clustering organizes the realization data into a rep-resentation conditioned on context.
The tree induction attempts to separate different realizations, whilethe hierarchical clustering provides for theoretically meaningful grouping of the context values, which, inturn, allows for better estimates of the realization distributions.
The use of a tree structure allows multiplemutually exclusive context sets to be used to describe allophone distributions.
The trees can be traversedto produce pronunciation distributions for each phoneme in a dictionary baseform.
Because the chosen con-textual factors in a tree are dependent on contextual factors chosen closer to the root node (e.g., for thephoneme/y / in  Figure 2, FOOT-BDKY is useful when PRE-PHONEME has the values {h, v, f, k, m, b, g, n, l, p,z}), the context rees, rather than the set of contexts in the trees, should be used for building pronunciationnetworks for speech recognition systems.
The context rees can be reinterpreted straightforwardly, and weare examining the clustered context values in each branch for such general descriptions.AcknowledgementThis work was sponsored in part by the Defense Advanced Research Projects Agency (DOD), under theInformation Science and Technology Office, contract #N00140-86-C-8996.ReferencesL.
Breiman, J.H.
Friedman, R.A. Olshen, and C.J.
Stone, Classification and Regression Trees, Wadsworth Interna-tional Group, Belmont, CA, 1984.F.
Chen, "The importance of context on the realization of phonemes," J. Acoust.
Soc.
Am., Suppl.
1, vol.
82, 1987.P.
Chou, Applications of Information Theory to Pattern Recognition and the Design of Decision Trees and Trellises,Doctoral Dissertation, Stanford University, Stanford, CA, June 1988.Y.-L. Chow, R. Schwartz, S. Roucos, O. Kimball, P. Price, F. Kubala, M. Dunham, M. Krasner, J. Makhoul, "Therole of word-dependent coarticulatory effects in a phoneme-based speech recognition system," Proc.
IEEE Int.Conf.
on Acoust., Speech and Signal Proc., pp.
1593-1596, 1986.W.
Fisher, V. Zue, J. Bernstein, D. Pallett, "An acoustic-phonetic data base," J. Acoust.
Soc.
Am., Suppl.
1, vol.81, 1987.R.
Gallager, Information Theory and Reliable Communication, John Wiley and Sons, New York, 1968.S.
Ganapathy and V. Rajaraman, "Information theory applied to the conversion of decision tables to computerprograms," Commun.
of the ACM, vol.
16, no.
9, pp.
532-539, 1973.J.
Henrichon and K. Fu, "A nonparametric partitioning procedure for pattern classification," IEEE Transactionson Computers, vol.
C-18, pp.
604-624, May 1969.F.
Jelinek, "Self-organized language modeling for speech recognition," unpublished, IBM T.J. Watson ResearchCenter, Yorktown Heights, N.Y., 1985.L.
Lamel, R. Kassel, S. Seneff, "Speech database development: design and analysis of the acoustic-phonetic corpus,"Proceedings of the DARPA Speech Recognition Workshop, L. Baumann, ed., pp.
100-109, 1986.K.-F. Lee, Large-Vocabulary Speaker-Independent Continuous Speech Recognition: The SPHINX System, DoctoralDissertation, Carnegie Mellon University, Pittsburgh, PA, April 1988.D.
Paul, "Speaker stress-resistant continuous speech recognition," Proc.
1EEE Int.
Conf.
on Acoust., Speech andSignal Proe., pp.
283-286, 1988.J.R.
Quinlan, "Induction of decision trees," Machine Learning, Kluwer Academic Publishers, Boston, vol.
1, pp.1-86, 1986.J.R.
Quinlan, "Generating production rules from decision trees," IJCAI-87, pp.
304-307, 1987.M.
Withgott and S. Bagley, The Variant Pronunciation Rule System, (implementation), Xerox Palo Alto ResearchCenter, Palo Alto, CA, 1987.~89
