Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 158?163,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsOmnifluentTM English-to-French and Russian-to-English Systems for the2013 Workshop on Statistical Machine TranslationEvgeny Matusov, Gregor LeuschScience Applications International Corporation (SAIC)7990 Science Applications Ct.Vienna, VA, USA{evgeny.matusov,gregor.leusch}@saic.comAbstractThis paper describes OmnifluentTM Trans-late ?
a state-of-the-art hybrid MT sys-tem capable of high-quality, high-speedtranslations of text and speech.
The sys-tem participated in the English-to-Frenchand Russian-to-English WMT evaluationtasks with competitive results.
Thefeatures which contributed the most tohigh translation quality were training datasub-sampling methods, document-specificmodels, as well as rule-based morpholog-ical normalization for Russian.
The latterimproved the baseline Russian-to-EnglishBLEU score from 30.1 to 31.3% on a held-out test set.1 IntroductionOmnifluent Translate is a comprehensive multilin-gual translation platform developed at SAIC thatautomatically translates both text and audio con-tent.
SAIC?s technology leverages hybrid machinetranslation, combining features of both rule-basedmachine and statistical machine translation for im-proved consistency, fluency, and accuracy of trans-lation output.In the WMT 2013 evaluation campaign, wetrained and tested the Omnifluent system on theEnglish-to-French and Russian-to-English tasks.We chose the En?Fr task because Omnifluent En?Fr systems are already extensively used by SAIC?scommercial customers: large human translationservice providers, as well as a leading fashion de-signer company (Matusov, 2012).
Our Russian-to-English system also produces high-quality transla-tions and is currently used by a US federal govern-ment customer of SAIC.Our experimental efforts focused mainly on theeffective use of the provided parallel and monolin-gual data, document-level models, as well usingrules to cope with the morphological complexityof the Russian language.
While striving for thebest possible translation quality, our goal was toavoid those steps in the translation pipeline whichwould make a real-time use of the Omnifluent sys-tem impossible.
For example, we did not integratere-scoring of N-best lists with huge computation-ally expensive models, nor did we perform systemcombination of different system variants.
This al-lowed us to create a MT system that produced ourprimary evaluation submission with the translationspeed of 18 words per second1.
This submissionhad a BLEU score of 24.2% on the Russian-to-English task2, and 27.3% on the English-to-Frenchtask.
In contrast to many other submissions fromuniversity research groups, our evaluation systemcan be turned into a fully functional, commer-cially deployable on-line system with the samehigh level of translation quality and speed withina single work day.The rest of the paper is organized as follows.
Inthe next section, we describe the core capabilitiesof the Omnifluent Translate systems.
Section 3explains our data selection and filtering strategy.In Section 4 we present the document-level trans-lation and language models.
Section 5 describesmorphological transformations of Russian.
In sec-tions 6 we present an extension to the system thatallows for automatic spelling correction.
In Sec-tion 7, we discuss the experiments and their evalu-ation.
Finally, we conclude the paper in Section 8.2 Core System CapabilitiesThe Omnifluent system is a state-of-the-art hybridMT system that originates from the AppTek tech-nology acquired by SAIC (Matusov and Ko?pru?,2010a).
The core of the system is a statisticalsearch that employs a combination of multiple1Using a single core of a 2.8 GHz Intel Xeon CPU.2The highest score obtained in the evaluation was 25.9%158probabilistic translation models, including phrase-based and word-based lexicons, as well as reorder-ing models and target n-gram language models.The retrieval of matching phrase pairs given aninput sentence is done efficiently using an algo-rithm based on the work of (Zens, 2008).
Themain search algorithm is the source cardinality-synchronous search.
The goal of the search is tofind the most probable segmentation of the sourcesentence into non-empty non-overlapping contigu-ous blocks, select the most probable permutationof those blocks, and choose the best phrasal trans-lations for each of the blocks at the same time.
Theconcatenation of the translations of the permutedblocks yields a translation of the whole sentence.In practice, the permutations are limited to allowfor a maximum of M ?gaps?
(contiguous regionsof uncovered word positions) at any time duringthe translation process.
We set M to 2 for theEnglish-to-French translation to model the mostfrequent type of reordering which is the reorder-ing of an adjective-noun group.
The value of Mfor the Russian-to-English translation is 3.The main differences of Omnifluent Trans-late as compared to the open-source MT sys-tem Moses (Koehn et al 2007) is a reorderingmodel that penalizes each deviation from mono-tonic translation instead of assigning costs propor-tional to the jump distance (4 features as describedby Matusov and Ko?pru?
(2010b)) and a lexicaliza-tion of this model when such deviations depend onwords or part-of-speech (POS) tags of the last cov-ered and current word (2 features, see (Matusovand Ko?pru?, 2010a)).
Also, the whole input doc-ument is always visible to the system, which al-lows the use of document-specific translation andlanguage models.
In translation, multiple phrasetables can be interpolated linearly on the countlevel, as the phrasal probabilities are computedon-the-fly.
Finally, various novel phrase-level fea-tures have been implemented, including binarytopic/genre/phrase type indicators and translationmemory match features (Matusov, 2012).The Omnifluent system also allows for partialor full rule-based translations.
Specific source lan-guage entities can be identified prior to the search,and rule-based translations of these entities canbe either forced to be chosen by the MT system,or can compete with phrase translation candidatesfrom the phrase translation model.
In both cases,the language model context at the boundaries ofthe rule-based translations is taken into account.Omnifluent Translate identifies numbers, dates,URLs, e-mail addresses, smileys, etc.
with manu-ally crafted regular expressions and uses rules toconvert them to the appropriate target languageform.
In addition, it is possible to add manualtranslation rules to the statistical phrase table ofthe system.3 Training Data Selection and FilteringWe participated in the constrained data track ofthe evaluation in order to obtain results which arecomparable to the majority of the other submis-sions.
This means that we trained our systems onlyon the provided parallel and monolingual data.3.1 TrueCasingInstead of using a separate truecasing module, weapply an algorithm for finding the true case of thefirst word of each sentence in the target trainingdata and train truecased phrase tables and a true-cased language model3.
Thus, the MT search de-cides on the right case of a word when ambiguitiesexist.
Also, the Omnifluent Translate system hasan optional feature to transfer the case of an inputsource word to the word in the translation outputto which it is aligned.
Although this approach isnot always error-free, there is an advantage to itwhen the input contains previously unseen namedentities which use common words that have to becapitalized.
We used this feature for our English-to-French submission only.3.2 Monolingual DataFor the French language model, we trained sepa-rate 5-gram models on the two GigaWord corporaAFP and APW, on the provided StatMT data for2007?2012 (3 models), on the EuroParl data, andon the French side of the bilingual data.
LMs wereestimated and pruned using the IRSTLM toolkit(Federico et al 2008).
We then tuned a linearcombination of these seven individual parts to op-timum perplexity on WMT test sets 2009 and 2010and converted them for use with the KenLM li-brary (Heafield, 2011).
Similarly, our English LMwas a linear combination of separate LMs built forGigaWord AFP, APW, NYT, and the other parts,StatMT 2007?2012, Europarl/News Commentary,and the Yandex data, which was tuned for best per-plexity on the WMT 2010-2013 test sets.3Source sentences were lowercased.1593.3 Parallel DataSince the provided parallel corpora had differ-ent levels of noise and quality of sentence align-ment, we followed a two-step procedure for fil-tering the data.
First, we trained a baseline sys-tem on the ?good-quality?
data (Europarl andNews Commentary corpora) and used it to trans-late the French side of the Common Crawl datainto English.
Then, we computed the position-independent word error rate (PER) between theautomatic translation and the target side on thesegment level and only kept those original seg-ment pairs, the PER for which was between 10%and 60%.
With this criterion, we kept 48% of theoriginal 3.2M sentence pairs of the common-crawldata.To leverage the significantly larger Multi-UNparallel corpus, we performed perplexity-baseddata sub-sampling, similarly to the method de-scribed e. g. by Axelrod et al(2011).
First, wetrained a relatively small 4-gram LM on the source(English) side of our development data and evalu-ation data.
Then, we used this model to computethe perplexity of each Multi-UN source segment.We kept the 700K segments with the lowest per-plexity (normalized by the segment length), so thatthe size of the Multi-UN corpus does not exceed30% of the total parallel corpus size.
This proce-dure is the only part of the translation pipeline forwhich we currently do not have a real-time solu-tion.
Yet such a real-time algorithm can be imple-mented without problems: we word-align the orig-inal corpora using GIZA++ahead of time, so that af-ter sub-sampling we only need to perform a quickphrase extraction.
To obtain additional data forthe document-level models only (see Section 4),we also applied this procedure to the even largerGigaword corpus and thus selected 1M sentencepairs from this corpus.We used the PER-based procedure as describedabove to filter the Russian-English Common-crawl corpus to 47% of its original size.
The base-line system used to obtain automatic translationfor the PER-based filtering was trained on NewsCommentary, Yandex, and Wiki headlines data.4 Document-level ModelsAs mentioned in the introduction, the Omnifluentsystem loads a whole source document at once.Thus, it is possible to leverage document contextby using document-level models which score thephrasal translations of sentences from a specificdocument only and are unloaded after processingof this document.To train a document-level model for a specificdocument from the development, test, or evalua-tion data, we automatically extract those sourcesentences from the background parallel trainingdata which have (many) n-grams (n=2...7) in com-mon with the source sentences of the document.Then, to train the document-level LM we take thetarget language counterparts of the extracted sen-tences and train a standard 3-gram LM on them.To train the document-level phrase table, we takethe corresponding word alignments for the ex-tracted source sentences and their target counter-parts, and extract the phrase table as usual.
Tokeep the additional computational overhead min-imal yet have enough data for model estimation,we set the parameters of the n-gram matchingin such a way that the number of sentences ex-tracted for document-level training is around 20Kfor document-level phrase tables and 100K fordocument-level LMs.In the search, the counts from the document-level phrase table are linearly combined with thecounts from the background phrase table trainedon the whole training data.
The document-levelLM is combined log-linearly with the general LMand all the other models and features.
The scal-ing factors for the document-level LMs and phrasetables are not document-specific; neither is thelinear interpolation factor for a document-levelphrase table which we tuned manually on a devel-opment set.
The scaling factor for the document-level LM was optimized together with the otherscaling factors using Minimum Error Rate Train-ing (MERT, see (Och, 2003)).For English-to-French translation, we used bothdocument-level phrase tables and document-levelLMs; the background data for them contained thesub-sampled Gigaword corpus (see Section 3.3).We used only the document-level LMs for theRussian-to-English translation.
They were ex-tracted from the same data that was used to trainthe background phrase table.5 Morphological Transformations ofRussianRussian is a morphologically rich language.
Evenfor large vocabulary MT systems this leads to datasparseness and high out-of-vocabulary rate.
To160mitigate this problem, we developed rules for re-ducing the morphological complexity of the lan-guage, making it closer to English in terms of theused word forms.
Another goal was to ease thetranslation of some morphological and syntacticphenomena in Russian by simplifying them; thisincluded adding artificial function words.We used the pymorphy morphological analyzer4to analyze Russian words in the input text.
Theoutput of pymorphy is one or more alternativeanalyses for each word, each of which includesthe POS tag plus morphological categories suchas gender, tense, etc.
The analyses are generatedbased on a manual dictionary, do not depend onthe context, and are not ordered by probability ofany kind.
However, to make some functional mod-ifications to the input sentences, we applied thetool not to the vocabulary, but to the actual inputtext; thus, in some cases, we introduced a contextdependency.
To deterministically select one of thepymorphy?s analyses, we defined a POS prioritylist.
Nouns had a higher priority than adjectives,and adjectives higher priority than verbs.
Other-wise we relied on the first analysis for each POS.The main idea behind our hand-crafted ruleswas to normalize any ending/suffix which does notcarry information necessary for correct translationinto English.
Under normalization we mean therestoration of some ?base?
form.
The pymorphyanalyzer API provides inflection functions so thateach word could be changed into a particular form(case, tense, etc.).
We came up with the followingnormalization rules:?
convert all adjectives and participles to first-person masculine singular, nominative case;?
convert all nouns to the nominative casekeeping the plural/singular distinction;?
for nouns in genitive case, add the artificialfunction word ?of ?
after the last noun beforethe current one, if the last noun is not morethan 4 positions away;?
for each verb infinitive, add the artificialfunction word ?to ?
in front of it;?
convert all present-tense verbs to their infini-tive form;?
convert all past-tense verbs to their past-tensefirst-person masculine singular form;?
convert all future-tense verbs to the artificialfunction word ?will ?
+ the infinitive;4https://bitbucket.org/kmike/pymorphy?
For verbs ending with reflexive suffixes??/?
?, add the artificial function word ?sya ?in front of the verb and remove the suf-fix.
This is done to model the reflexion (e.g.???
?????????
???
sya_ ???????
?
?hewashed himself?, here ?sya ?
corresonds to?himself?
), as well as, in other cases, the pas-sive mood (e.g.
???
??????????
?  ?
?sya_ ??????????
?it is inserted?
).An example that is characteristic of all these mod-ifications is given in Figure 1.It is worth noting that not all of these transfor-mations are error-free because the analysis is alsonot always error-free.
Also, sometimes there is in-formation loss (as in case of the instrumental nouncase, for example, which we currently drop insteadof finding the right artificial preposition to expressit).
Nevertheless, our experiments show that this isa successful morphological normalization strategyfor a statistical MT system.6 Automatic Spelling CorrectionMachine translation input texts, even if preparedfor evaluations such as WMT, still contain spellingerrors, which lead to serious translation errors.
Weextended the Omnifluent system by a spelling cor-rection module based on Hunspell5 ?
an open-source spelling correction software and dictionar-ies.
For each input word that is unknown both tothe Omnifluent MT system and to Hunspell, weadd those Hunspell?s spelling correction sugges-tions to the input which are in the vocabulary ofthe MT system.
They are encoded in a lattice andassigned weights.
The weight of a suggestion isinversely proportional to its rank in the Hunspell?slist (the first suggestions are considered to be moreprobable) and proportional to the unigram proba-bility of the word(s) in the suggestion.
To avoiderrors related to unknown names, we do not applyspelling correction to words which begin with anuppercase letter.The lattice is translated by the decoder usingthe method described in (Matusov et al 2008);the globally optimal suggestion is selected in thetranslation process.
On the English-to-Frenchtask, 77 out of 3000 evaluation data sentenceswere translated differently because of automaticspelling correction.
The BLEU score on thesesentences improved from 22.4 to 22.6%.
Man-ual analysis of the results shows that in around5http://hunspell.sourceforge.net161source ????
??????????
?
?????
?????????
??????
?????????
?????
?????
?????????
????
??
???
?prep ????
sya_ ????????
?
?????
?????????
??????
?????????
????
?????
?????????
of_ ???
??
???
?ref The dinner was held at a Washington hotel a few hours after the conference of the court over the caseFigure 1: Example of the proposed morphological normalization rules and insertion of artificial functionwords for Russian.System BLEU PER[%] [%]baseline 31.3 41.1+ extended features 31.7 41.0+ alignment combination 32.1 40.6+ doc-level models 32.7 39.3+ common-crawl/UN data 33.0 39.9Table 1: English-to-French translation results(newstest-2012-part2 progress test set).70% of the cases the MT system picks the rightor almost right correction.
We applied automaticspelling correction also to the Russian-to-Englishevaluation submissions.
Here, the spelling correc-tion was applied to words which remained out-of-vocabulary after applying the morphological nor-malization rules.7 Experiments7.1 Development Data and EvaluationCriteriaFor our experiments, we divided the 3000-sentence newstest-2012 test set from the WMT2012 evaluation in two roughly equal parts, re-specting document boundaries.
The first part weused as a tuning set for N-best list MERT opti-mization (Och, 2003).
We used the second partas a test set to measure progress; the results on itare reported below.
We computed case-insensitiveBLEU score (Papineni et al 2002) for optimiza-tion and evaluation.
Only one reference translationwas available.7.2 English-to-French SystemThe baseline system for the English-to-Frenchtranslation direction was trained on Europarl andNews Commentary corpora.
The word align-ment was obtained by training HMM and IBMModel 3 alignment models and combining theirtwo directions using the ?grow-diag-final?
heuris-tic (Koehn, 2004).
The first line in Table 1 showsthe result for this system when we only use thestandard features (phrase translation and word lex-icon costs in both directions, the base reorder-System BLEU PER[%] [%]baseline (full forms) 30.1 38.9morph.
reduction 31.3 38.1+ extended features 32.4 37.3+ doc-level LMs 32.3 37.4+ common-crawl data 32.9 37.1Table 2: Russian-to-English translation results(newstest-2012-part2 progress test set).ing features as described in (Matusov and Ko?pru?,2010b) and the 5-gram target LM).
When wealso optimize the scaling factors for extended fea-tures, including the word-based and POS-basedlexicalized reordering models described in (Ma-tusov and Ko?pru?, 2010a), we improve the BLEUscore by 0.4% absolute.
Extracting phrase pairsfrom three different, equally weighted alignmentheuristics improves the score by another 0.3%.The next big improvement comes from usingdocument-level language models and phrase ta-bles, which include Gigaword data.
Especially thePER decreases significantly, which indicates thatthe document-level models help, in most cases, toselect the right word translations.
Another signifi-cant improvement comes from adding parts of theCommon-crawl and Multi-UN data, sub-sampledwith the perplexity-based method as described inSection 3.3.
The settings corresponding to the lastline of Table 1 were used to produce the Omniflu-ent primary submission, which resulted in a BLEUscore of 27.3 on the WMT 2013 test set.After the deadline for submission, we discov-ered a bug in the extraction of the phrase tablewhich had reduced the positive impact of the ex-tended phrase-level features.
We re-ran the opti-mization on our tuning set and obtained a BLEUscore of 27.7% on the WMT 2013 evaluation set.7.3 Russian-to-English SystemThe first experiment with the Russian-to-Englishsystem was to show the positive effect of themorphological transformations described in Sec-tion 5.
Table 2 shows the result of the baselinesystem, trained using full forms of the Russian162words on the News Commentary, truecased Yan-dex and Wiki Headlines data.
When applying themorphological transformations described in Sec-tion 5 both in training and translation, we obtaina significant improvement in BLEU of 1.3% ab-solute.
The out-of-vocabulary rate was reducedfrom 0.9 to 0.5%.
This shows that the morpholog-ical reduction actually helps to alleviate the datasparseness problem and translate structurally com-plex constructs in Russian.Significant improvements are obtained for Ru?En through the use of extended features, includingthe lexicalized and ?POS?-based reordering mod-els.
As the ?POS?
tags for the Russian words weused the pymorphy POS tag selected deterministi-cally based on our priority list, together with thecodes for additional morphological features suchas tense, case, and gender.
In contrast to the En?Fr task, document-level models did not help here,most probably because we used only LMs andonly trained on sub-sampled data that was alreadypart of the background phrase table.
The last boostin translation quality was obtained by adding thosesegments of the cleaned Common-crawl data tothe phrase table training which are similar to thedevelopment and evaluation data in terms of LMperplexity.
The BLEU score in the last line of Ta-ble 2 corresponds to Omnifluent?s BLEU score of24.2% on the WMT 2013 evaluation data.
This isonly 1.7% less than the score of the best BLEU-ranked system in the evaluation.8 Summary and Future WorkIn this paper we described the Omnifluent hybridMT system and its use for the English-to-Frenchand Russian-to-English WMT tasks.
We showedthat it is important for good translation quality toperform careful data filtering and selection, as wellas use document-specific phrase tables and LMs.We also proposed and evaluated rule-based mor-phological normalizations for Russian.
They sig-nificantly improved the Russian-to-English trans-lation quality.
In contrast to some evaluation par-ticipants, the presented high-quality system is fastand can be quickly turned into a real-time system.In the future, we intend to improve the rule-basedcomponent of the system, allowing users to addand delete translation rules on-the-fly.ReferencesAmittai Axelrod, Xiaodong He, and Jianfeng Gao.2011.
Domain Adaptation via Pseudo In-DomainData Selection.
In International Conference on Em-perical Methods in Natural Language Processing,Edinburgh, UK, July.Marcello Federico, Nicola Bertoldi, and Mauro Cet-tolo.
2008.
IRSTLM: an open source toolkit forhandling large scale language models.
In Proceed-ings of Interspeech, pages 1618?1621.Kenneth Heafield.
2011.
KenLM: faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages187?197, Edinburgh, Scotland, United Kingdom,July.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbst.
2007.
Moses:Open source toolkit for statistical machine transla-tion.
In Annual Meeting of the Association for Com-putational Linguistics (ACL), Prague, Czech Repub-lic.
Association for Computational Linguistics.Philipp Koehn.
2004.
Pharaoh: a beam searchdecoder for phrase-based statistical machine trans-lation models.
In 6th Conference of the As-sociation for Machine Translation in the Ameri-cas (AMTA 04), pages 115?124, Washington DC,September/October.Evgeny Matusov and Selc?uk Ko?pru?.
2010a.
AppTek?sAPT Machine Translation System for IWSLT 2010.In Proc.
of the International Workshop on SpokenLanguage Translation, Paris, France, December.Evgeny Matusov and Selc?uk Ko?pru?.
2010b.
Improv-ing Reordering in Statistical Machine Translationfrom Farsi.
In AMTA 2010: The Ninth Conferenceof the Association for Machine Translation in theAmericas, Denver, Colorado, USA, November.Evgeny Matusov, Bjo?rn Hoffmeister, and HermannNey.
2008.
ASR word lattice translation withexhaustive reordering is possible.
In Interspeech,pages 2342?2345, Brisbane, Australia, September.Evgeny Matusov.
2012.
Incremental Re-training of aHybrid English-French MT System with CustomerTranslation Memory Data.
In 10th Conference of theAssociation for Machine Translation in the Amer-icas (AMTA 12), San Diego, CA, USA, October-November.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In 41st Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 160?167, Sapporo, Japan, July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In ACL ?02: Pro-ceedings of the 40th Annual Meeting on Associa-tion for Computational Linguistics, pages 311?318,Morristown, NJ, USA.
Association for Computa-tional Linguistics.Richard Zens.
2008.
Phrase-based Statistical MachineTranslation: Models, Search, Training.
Ph.D. the-sis, RWTH Aachen University, Aachen, Germany,February.163
