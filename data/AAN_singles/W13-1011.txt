Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 73?81,Atlanta, Georgia, 13-14 June 2013. c?2013 Association for Computational LinguisticsAutomatic Detection of Stable Grammatical Features in N-GramsMikhail Kopotev1 Lidia Pivovarova1,2 Natalia Kochetkova3 Roman Yangarber11 University of Helsinki, Finland2 St.Petersburg State University, Russia3 Moscow Institute of Electronics and Mathematics, NRU HSE, RussiaAbstractThis paper presents an algorithm that allowsthe user to issue a query pattern, collectsmulti-word expressions (MWEs) that matchthe pattern, and then ranks them in a uniformfashion.
This is achieved by quantifying thestrength of all possible relations between thetokens and their features in the MWEs.
The al-gorithm collects the frequency of morphologi-cal categories of the given pattern on a unifiedscale in order to choose the stable categoriesand their values.
For every part of speech, andfor all of its categories, we calculate a normal-ized Kullback-Leibler divergence between thecategory?s distribution in the pattern and itsdistribution in the corpus overall.
Categorieswith the largest divergence are considered tobe the most significant.
The particular valuesof the categories are sorted according to a fre-quency ratio.
As a result, we obtain morpho-syntactic profiles of a given pattern, which in-cludes the most stable category of the pattern,and their values.1 IntroductionIn n-grams, the relations among words and amongtheir grammatical categories cover a wide spectrum,ranging from idioms to syntactic units, such as averb phrase.
In most cases, the words are linked to-gether by both grammatical and lexical relations.
Itis difficult to decide, which relation is stronger ineach particular case.
For example, in the idiomaticphrase meet the eye, the relationship is lexical ratherthan grammatical.
A phrasal verb meet up is similarto single-word verbs and has its own meaning.
It canbe interpreted as one lexeme, spelled as two words.On the other hand, phrases like meet the require-ments, meet the specifications, meet the demandsare traditionally called ?collocations.?
However, thequestion arises about the role played by the noun fol-lowing the verb: is it a lexically free direct object,or a part of stable lexical unit, or to some extendboth?
These words are bound by both grammaticaland lexical relations, and we assume that the major-ity of word combinations in any language have sucha dual nature.Lastly, the relationship between the words in theEnglish phrase meet her differs from those above inthat it may be described as purely grammatical?theverb meet receives a direct object.Distinguishing collocations, i.e.
?co-occurrencesof words?
from colligations, i.e.
?co-occurrence ofword forms with grammatical phenomena?
(Griesand Divjak, 2009) is not always a simple task; thereis no clear boundary between various types of wordcombinations inasmuch as they can be simultane-ously a collocation and a colligation?this type ofMWE is called collostructions in (Stefanowitsch andGries, 2003).
It was proposed that language as suchis a ?constructicon?
(Goldberg, 2006), which meansthat fusion is its core nature.
For this reason, devis-ing formal methods to measure the strength of mor-phological or lexical relations between words be-comes a challenge.Our approach aims to treat multi-word expres-sions (MWEs) of various nature?idioms, multi-word lexemes, collocations and colligations?on anequal basis, and to compare the strength of vari-ous possible relations between the tokens in a MWEquantitatively.
We search for ?the underlying cause?73for the frequent co-occurrence of certain words:whether it is due to their morphological categories,or lexical compatibility, or a combination of both.
Inthis paper, however, we focus on colligations, ignor-ing collocations and collostructions.For languages with rich morphology the situationis more complicated, because each word may haveseveral morphological categories that are not inde-pendent and interact with each other.
This paper fo-cuses on Russian, which not only has free word or-der and rich morphology,1 but is also a language thatis well-investigated.
A good number of corpora andreference grammars are available to be used for eval-uation.
The data we use in this work is the n-gramcorpus, extracted from a deeply annotated and care-fully disambiguated (partly manually) sub-corpus ofthe Russian National Corpus (RNC).
The size of dis-ambiguated corpus used in this paper is 5 944 188words of running text.2 Related WorkMuch effort has been invested in automatic extrac-tion of MWEs from text.
A great variety of methodare used, depending on the data, the particular tasksand the types of MWEs to be extracted.
Pecina(2005) surveys 87 statistical measures and meth-ods, and even that is not a complete list.
Themost frequently used metrics, inter alia, are Mu-tual Information (MI), (Church and Hanks, 1990), t-score (Church et al 1991), and log-likelihood (Dun-ning, 1993).
The common disadvantage of these istheir dependency on the number of words includedin the MWE.
Although there is a large number ofpapers that use MI for bigram extraction, only a fewuse the MI measure for three or more collocates,e.g., (Tadic?
and S?ojat, 2003; Wermter and Hahn,2006; Kilgarriff et al 2012),Frantzi et al(2000) introduced the c-value andnc-value measures to extract terms of differentlengths.
Daudaravicius (2010) has developed apromising method that recognizes collocations intext.
Rather than extracting MWEs, this method cutsthe text into a sequence of MWEs of length from1 to 7 words; the algorithm may produce different1The Multitext-East specification, which aims to create anunified cross-language annotation scheme, defines 156 morpho-syntactic tags for Russian as compared to 80 tags for English(http://nl.ijs.si/ME/V4/msd/html).chunking for the same segment of text within dif-ferent corpora.
Nevertheless, extraction of variable-length MWE is a challenging task; the majority ofpapers in the field still use measures that take thenumber of collocates as a core parameter.Entropy and other probabilistic measures havebeen used for MWE extraction since the earliestwork.
For example, the main idea in (Shimohata etal., 1997; Resnik, 1997), is that the MWE?s idiosyn-crasy, (Sag et al 2002), is reflected in the distribu-tions of the collocates.
Ramisch et al(2008) intro-duced the Entropy of Permutation and Insertion:EPI = ?m?a=0p(ngrama) log[p(ngrama)] (1)where ngram0 is the original MWE, and ngramaare its syntactically acceptable permutations.Kullback-Leibler divergence was proposedby Resnik (1997) to measure selective prefer-ence for the word sense disambiguation (WSD)task.
Fazly and Stevenson (2007) applied a set ofstatistical measures to classify verb+noun MWEsand used Kullback-Leibler divergence, among othermethods, to measure the syntactic cohesion of aword combination.
Van de Cruys and Moiro?n(2007) used normalized Kullback-Leibler diver-gence to find idiomatic expression with verbs inDutch.Russian MWE-studies have emerged over the lastdecade.
Khokhlova and Zakharov (2009) appliedMI, t-score and log-likelihood to extract verb collo-cations; Yagunova and Pivovarova (2010) studiedthe difference between Russian lemma/token col-locations and also between various genres; Do-brov and Loukachevitch (2011) implemented termextraction algorithms.
However, there is a lack ofstudy of both colligations and collostructions in Rus-sian.
The only work known to us is by Sharoff(2004), who applied the MI-score to extract prepo-sitional phrases; however, the only category he usedwas the POS.As far as we aware, the algorithm we present inthis paper has not been applied to Russian or to otherlanguages.3 MethodThe input for our system is any n-gram of length 2?4, where one position is a gap?the algorithm aims74Figure 1: Distributions of noun cases in the corpus and ina sample?following the preposition ???
(in)Figure 2: Distributions of nominal gender in the corpusand in a sample?following the preposition ???
(in)to find the most stable morphological categories ofwords that can fill this gap.
Moreover, the user canspecify the particular properties of words that can fillthe gap?for example, specify that the output shouldinclude only plural nouns.
Thus, the combination ofthe surrounding words and morphological constrainsform an initial query pattern for the algorithm.Our model tries to capture the difference betweendistributions of linguistic features in the general cor-pus as compared to distributions within the givenpattern.
For example, Figure 1 shows the distribu-tion of cases in the corpus overall vs. their distribu-tion in words following the preposition ???
(in/into).Figure 2 shows the corresponding distributions ofgender.
Gender is distributed similarly in the cor-pus and in the sample restricted by the pattern; bycontrast, the distribution of cases is clearly different.This is due to the fact that the preposition governsthe case of the noun, but has no effect on gender.
Tomeasure this difference between the distributions weuse the Kullback-Leibler divergence:Div(C) =N?i=1P patterni ?
log(P patterniP corpusi) (2)where C is the morphological category in apattern?e.g., case or gender,?having the values1..N , P patterni is the relative frequency of value irestricted by the pattern, and P corpusi is the relativefrequency of the same value in the general corpus.Since the number of possible values for a category isvariable?e.g., eleven for case, four for gender, andhundreds of thousands for lemmas?the divergenceneeds to be normalized.
The normalization couldbe done in various ways, e.g., against the entropy orsome maximal divergence in the data; in our experi-ments, the best results were obtained using a variantproposed in (Bigi, 2003), where the divergence be-tween the corpus distribution and the uniform distri-bution is used as the normalizing factor:NormDiv(C) =Div(C)E(C) + log(n)(3)where E(C) is the entropy of category C and n isthe number of possible values of C; the term log(n)is the entropy of the uniform distribution over n out-comes (which is the maximal entropy).
The categorywith the highest value of normalized divergence isseen as maximally preferred by the pattern.However, divergence is unable to determine theexact values of the category, and some of these val-ues are clearly unreliable even if they seem to ap-pear in the pattern.
For example, Figure 1 showsthat preposition ???
(in) in the data is sometimesfollowed by the nominative case, which is grammat-ically impossible.
This is due to a certain amount ofnoise, which is unavoidable in a large corpus due tomark-up errors or inherent morphological ambigu-ity.
In Russian, the nominative and accusative casesoften syncretize (assume identical forms), which cancause inaccuracies in annotation.
On the other hand,some values of a category can be extremely rare;thus, they will be rare within patterns as well.
Forinstance, the so-called ?second accusative?
case (la-beled ?acc2?
in Figure 1) is rare in modern Russian,75which is why its appearance in combination withpreposition ???
(in) is significant, even though itsfrequency is not much higher than the frequency ofthe (erroneous) nominative case in the same pattern.To find the significant values of a particular cate-gory we use the ratio between the frequencies of thevalue in a sample and in the corpus:frequency ratio =P patterniP corpusi(4)If frequentcy ratio > 1, then the category?s valueis assumed to be selected by the pattern.Finally, we note that the distribution of POS variesconsiderably within every pattern as compared to itsdistribution in the corpus.
For example, prepositionscan be followed only by noun groups and can neverbe followed by verbs or conjunctions.
This meansthe Kullback-Leibler divergence for any POS, nat-urally assumes the highest value in any pattern; forthis reason, we exclude the POS category from con-sideration in our calculation, aiming to find moresubtle and interesting regularities in the data.To summarize, the algorithm works as follows:for a given query pattern1.
search all words that appear in the query patternand group them according to their POS tags.2.
for every POS, calculate the normalizedKullback-Leibler divergence for all of its cat-egories; categories that show the maximum di-vergence are considered to be the most signifi-cant for the given pattern;3. for every relevant category, sort its values ac-cording to the frequency ratio; if frequency ra-tio is less than 1, the value considered to be ir-relevant for this pattern.4 ExperimentsIn this paper, we conduct an in-depth evaluation fo-cusing on a limited number of linguistic phenom-ena, namely: bigrams beginning with single-tokenprepositions, which impose strong morpho-syntacticconstraints in terms of case government.
We in-vestigate 25 prepositions, such as ?????
(without),???
(in/to), etc.
We evaluate the corpus of bi-grams systematically against these queries, althoughwe expect that the model we propose here pro-duces relevant results for a much wider range ofconstructions?to be confirmed in further work.4.1 Prepositions and Morphological CategoryA syntactic property of prepositions in Russian isthat they govern nominal phrases, i.e., that we expectthe largest normalized divergence in queries such as{ Preposition + X }, where the POS of X is noun,to occur exactly with the category of case.
Figure 3shows the normalized divergence for four lexical andmorphological categories.
Among them, Case hasthe maximal divergence for all prepositions, whichmatches our expectation with 100% accuracy.According to the figure, the morphological cat-egory of Animacy2 is also interesting, in that ithas a high value for some prepositions, like ???-????
(from under), ?????
(under), ?????
(above).A good example is the preposition ???-????
(fromunder).
Its semantic properties cause inanimatenouns to appear much more frequently than ani-mate ones.
Consequently, we observe a higher diver-gence, due to inanimate nouns like ???-???
??????
(from under ground), ???-???
??????
(from underthe snow), etc.
Another good example of hiddensemantic properties is a pair of prepositions ?????
(under) and ?????
(above).
One can expect thattheir syntactic behaviour is more or less similar,but the histogram shows that Animacy (surprisingly)has a much higher divergence for ?????
(under) tobe ignored.
Indeed, a deeper corpus-based anal-ysis reveals a stable, frequently used construction,which gives many points to animate nouns, e.g.,????????????????
???
????????
(disguised as abride).
It is notable that this particular effect is notmentioned in any grammar book, (to the best of ourknowledge).To conclude, the Case category is the clear win-ner in terms of having the greatest normalized di-vergence, and the output fully matches the expecta-tion on all 25 common prepositions that we tested.Other results are also clearly interesting due to theirlinks to semantic properties, that is, to colloca-tions.
The next task is, therefore to discriminate2Animacy is a morphological category of Russian nounsbased on whether the referent of the noun is considered sen-tient or living.
Most nouns denoting humans and animals areanimate, while the majority of other nouns are inanimate.76Figure 3: Normalized divergence of noun categories (grammemes) for pattern preposition+X.between the runners-up, like Animacy for ?????
(under), which seem to be interesting to some ex-tent, and clear losers like Gender, in the exampleabove.
To do that we need to find an appropriatethreshold?preferably automatically?between rel-evant and non-relevant results.
The algorithm ranksthe categories according to their divergence; the cat-egory that has the top rank is certainly meaning-ful.
The question is how to determine which amongthe rest are significant as well; this is left for futurework.4.2 Specific Values of the Category withMaximum DivergenceThe next question we explore is which particularvalues of the maximally divergent category?here,Case?are selected by a given preposition.
As wementioned above, we use the frequency ratio for thistask.
We collected a list of cases3 that appear af-ter the given preposition, according to the algorithmwith frequency ratio > 1; which cases are pos-sible according to grammatical descriptions,4 which3The current annotation scheme of our data has eleven casetags, namely: nom, voc, gen, gen2, dat, acc, acc2, ins, loc, loc2,adnum.4Note, that not all possible prep+case combinations are rep-resented in the corpus; for example, the combination { ??????
(for the sake of) + gen2 } does not appear in our data, and onlyeight times in the RNC overall.
For evaluation we take intocases were produced by the algorithm, and the num-ber of correct cases in the system?s response.
Weexpect that by using the frequency ratio we can re-duce the noise; for example, of the eight cases thatmatch the pattern { ?c?
(with) + Noun } only fourare relevant.The algorithm predicts the correct relevant set for21 of 25 prepositions, giving a total precision of95%, recall of 89%, and F-measure of 92%.
Theprepositions highlighted in bold in Table 1 are thosethat were incorrectly processed for various reasons;the error analysis is presented below.14: ???
(about) The algorithm unexpectedly flagsthe voc (vocative) as a possible case after this prepo-sition.
This is incorrect; checking the data we dis-covered that this mistake was due to erroneous an-notation: the interjection ?o?
(oh), as in ?O ????!?
(Oh God!
), is incorrectly annotated as the preposi-tion ?o?
(about).
The error occurs twice in the data.However, as the vocative is extremely rare in the data(its frequency in the corpus is less than 0,0004), twoerroneous tags are sufficient to give it a high rank.Similar annotation errors for more frequent cases areeliminated by the algorithm.
For example, as wementioned in the previous section, the nominativeconsideration only those prep+case combinations that appear atleast once in our dataset.77Preposition Meaning Expected cases Response1 ???
without gen/gen2 gen/gen22 ?
in/into acc/acc2/loc/loc2 acc/acc2/loc/loc23 ???
for gen/gen2 gen/gen24 ??
until gen/gen2 gen/gen25 ??
behind acc/ins acc/ins6 ??
from gen/gen2 gen/gen27 ??-??
from behind gen/gen2 gen/gen28 ??-???
from under gen/gen2 gen/gen29 ?
to dat dat10 ?????
beyond gen gen11 ?????
between ins ins12 ??
on acc/loc/loc2 acc/loc/loc213 ???
above ins ins14 ?
about acc/loc loc/voc15 ??
from gen/gen2 gen/gen216 ?????
in front of ins ins17 ????
in front of ins ins18 ??
by/up to dat/loc/acc dat19 ???
under acc/ins acc/ins20 ???
at/by loc loc21 ???
about acc acc22 ????
for gen gen23 ?
with gen/gen2/acc/ins gen2/ins24 ?
near gen gen25 ?????
through acc acc/adnumExpected 45Response 42Correct 40Precision 0.95Recall 0.89F-measure 0.92Table 1: Noun cases expected and returned by the algorithm for Russian prepositions.case after preposition ???
(in) appears 88 times inour data; however this case is not returned by the al-gorithm, since it is below the frequency ratio thresh-old.25: ???????
(through/past) The adnumerative(adnum) is a rare case in our data, so even a singleoccurrence in a sample is considered important bythe algorithm.
A single bigram is found in the data,where the token ??????
(hours)?correctly anno-tated with the adnum tag?predictably depends onthe Numeral, i.e., ?????
(two), rather than on prepo-sition ???????
(through/past), see Figure 4.
Thenumeral appears in post-position?a highly markedword order that is admissible in this colloquial con-struction in Russian: ??????
????
????
(lit.
: afterhours two = idiom: after about two hours), whereFigure 4: Distributions of cases in the corpus and in asample.
(Arrows indicate syntactic dependency.
)the preposition governs the Case of the numeral, andthe numeral governs a noun that precedes it.Because our algorithm at the moment processeslinear sequences, these kinds of syntactic inversionphenomena in Russian will pose a challenge.
In gen-eral this problem can be solved by using tree-banksfor MWE extraction, (Seretan, 2008; Martens andVandeghinste, 2010).
However, an appropriate tree-78bank is not always available for a given language; infact, we do not have access to any Russian tree-banksuitable for this task.23: ???
(with) This is a genuine error.
The algo-rithm misses two of four correct cases, Genitive andAccusative, because both are widely used across thecorpus, which reduces their frequency ratio in thesub-sample.
Our further work will focus on findingflexible frequency ratio thresholds, which is now setto one.
Two of the correct cases (Instrumental andGen2) are well over the threshold, while Genitive,with 0.6924, and Accusative, with 0.0440, fall short.18: ????
(by/along) For this preposition the al-gorithm predicts 1 case out of 3.
This situation isslightly different from the previous ones, since theaccusative and locative cases are much more rarewith preposition ????
(by/along) than the dative:245 instances out of 15387 for accusative, and 222for locative in our data.
We hypothesize that thismeans that such ?Prep+case?
combinations are con-strained lexically to a greater extent than grammat-ically.
To check this hypothesis we calculate thefrequency ratio for all lemmas that appear with therespective patterns { ????
(by/along) + acc } and{ ????
(by/along) + loc }.
As a result, 15 distinctlemmas were extracted by { ????
(by) + acc }; 13out of them have frequency ratio > 1.
The major-ity of the lemmas belong to the semantic class ?partof the body?
and are used in a very specific Rus-sian construction, which indicates ?an approximatelevel?, e.g.
???
???????
(up to (one?s) elbow), cf.English ?up to one?s neck in work?.
This construc-tion has limited productivity, and we are satisfiedthat the Accusative is omitted in the output for gram-matical categories, since the algorithm outputs alltokens that appear in the { ????
(by/along) + acc }as relevant lemmas.The case of { ????
(by) + loc } is more com-plex: 44 of 76 combinations return a frequencygreater than 1.
Analysis of annotation errors revealsa compact collection of bureaucratic cliches, like???
?????????
(upon arrival), ???
??????????
(upon completion), etc., which all share the seman-tics of ?immediately following X?, and are pragmat-ically related.
These are expressions belonging tothe same bureaucratic jargon and sharing the samemorphological pattern, however, they are below thethreshold.
Again, we are faced with need to tune thethreshold to capture this kind of potentially interest-ing lexical combinations.
In general, semantic andpragmatic factors influence the ability of words tocombine, and the algorithm shows it in some way,though these aspects of the problem are beyond thescope of our experiments in the current stage.5 Discussion and Future Work5.1 Development of the algorithmWe have presented a part an overall system under de-velopment.
In the preceding sections, we investigatean area where collocations and colligations meet.
Tosummarize, the algorithm, based on the corpus of n-grams, treats both morpho-syntactic and lexical co-occurrences as a unified continuum, which has noclear borders.
The evaluation of the morphologicaloutput raises some new questions for further devel-opment:?
At present, the low precision for both low- andhigh-frequency tags depends on the threshold,which needs to be studied further.?
The values of divergences are currently notnormalized among the different query patterns.This may be a difficult question, and we plan toinvestigate this further.
The algorithm providesa way to compare the strength of very diversecollocations, which have nothing in common,in terms of their degree of idiomatization.?
We observe that the longer the n-gram, themore we expect it to be a collocation; stablebigrams appear more frequently to be colliga-tions, while stable 4-grams are more often col-locations.
The problem is that those colloca-tions with a highly frequent first collocate, e.g.,???
(in), cannot be found using our algorithmas it stands now.?
Token/lexeme stability is the next task we willconcentrate on.
Wermter and Hahn (2006) andKilgarriff et al(2012) proposed that sortingtokens/lexemes according to plain frequencyworks well if there is no grammatical knowl-edge at hand.
We do have such knowledge.
Toimprove the accuracy of lexeme/token extrac-tion we rely on the idea of grammatical pro-79files, introduced by Gries and Divjak (2009).We plan to develop this approach with thefurther assumption that the distribution of to-kens/lexemes within a pattern is based on rel-evant grammatical properties, which are ob-tained in an earlier step of our algorithm.
Forinstance, for ???
??
X?
(not up to X) we havefound that the grammatical profile for X isN.gen/gen2, and the token frequency ratio isgreater than 1 as well.
Building the list of to-kens that are the most stable for this pattern, wecompare their distributions within the pattern toall N.gen/gen2 tokens in the corpus.
This yieldsthe following tokens as the most relevant: ?????
??????
(lit.
: not up to laughter.gen = id-iom: no laughing matter);???
??
?????
(lit.not up to fat.gen2 = idiom: no time/place forcomplacency), which reveals an interesting setof idioms.5.2 Extensions and ApplicationsThe model has no restriction on the length of datato be used, and is applicable to various languages.Finnish (which is morphologically rich) and English(morphologically poor) will be examined next.
Asfor Russian, so far the algorithm has been systemat-ically evaluated against bigrams, although we have3-, 4- and 5-grams at our disposal for future work.A reliable method that is able to determine pat-terns of frequently co-occurring lexical and gram-matical features within a corpus can have far-reaching practical implications.
One particular ap-plication that we are exploring is the fine-tuningof semantic patterns that are commonly used in in-formation extraction (IE), (Grishman, 2003).
Ourwork on IE focuses on different domains and differ-ent languages, (Yangarber et al 2007; Atkinson etal., 2011).
Analysis of MWEs that occur in extrac-tion patterns would provide valuable insights intohow the patterns depend on the particular style orgenre of the corpus, (Huttunen et al 2002).
Subtle,genre-specific differences in expression can indicatewhether a given piece of text is signaling the pres-ence an event of interest.5.3 Creating Teaching-Support ToolsInstructors teaching a foreign language are regu-larly asked how words co-occur: What cases andword forms appear after a given preposition?
Whichones should I learn by rote and which ones followrules?
The persistence of such questions indicatesthat this is an important challenge to be addressed?we should aim to build a system that can automati-cally generate an integrated answer.
A tool that pro-duces answers to these questions would be of greathelp for teachers as well as students.
The presentedalgorithm can support an easy-to-use Web-based ap-plication, or an application for a mobile device.
Weplan to develop a service, which is able to processqueries described in the paper.
This service wouldbe an additional interface to a corpus, aimed at find-ing not only the linear context of words but also theircollocational and constructional preferences.
We be-lieve that such an interface would be useful for bothresearch and language-learning needs.AcknowledgmentsWe are very grateful to the Russian National Cor-pus developers, especially E. Rakhilina and O. Lya-shevskaya, for providing us with the data.ReferencesMartin Atkinson, Jakub Piskorski, Erik van der Goot, andRoman Yangarber.
2011.
Multilingual real-time eventextraction for border security intelligence gathering.In U. Kock Wiil, editor, Counterterrorism and OpenSource Intelligence, pages 355?390.
Springer LectureNotes in Social Networks, Vol.
2, 1st edition.Brigitte Bigi.
2003.
Using Kullback-Leibler distancefor text categorization.
In Fabrizio Sebastiani, edi-tor, Advances in Information Retrieval, volume 2633of Lecture Notes in Computer Science, pages 305?319.Springer Berlin, Heidelberg.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lexicogra-phy.
Computational linguistics, 16(1):22?29.Kenneth Church, William Gale, Patrick Hanks, and Don-ald Kindle.
1991.
Using statistics in lexical analy-sis.
Lexical acquisition: exploiting on-line resourcesto build a lexicon.Vidas Daudaravicius.
2010.
Automatic identification oflexical units.
Computational Linguistics and Intelli-gent text processing CICling-2009.Boris Dobrov and Natalia Loukachevitch.
2011.
Mul-tiple evidence for term extraction in broad domains.In Proceedings of the 8th Recent Advances in Natu-ral Language Processing Conference (RANLP 2011).Hissar, Bulgaria, pages 710?715.80Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational linguis-tics, 19(1):61?74.Afsaneh Fazly and Suzanne Stevenson.
2007.
Dis-tinguishing subtypes of multiword expressions usinglinguistically-motivated statistical measures.
In Pro-ceedings of the Workshop on A Broader Perspective onMultiword Expressions, pages 9?16.
Association forComputational Linguistics.Katerina Frantzi, Sophia Ananiadou, and Hideki Mima.2000.
Automatic recognition of multi-word terms:the c-value/nc-value method.
International Journal onDigital Libraries, 3(2):115?130.Adele Goldberg.
2006.
Constructions at work: The na-ture of generalization in language.
Oxford UniversityPress, USA.Stefan Th.
Gries and Dagmar Divjak.
2009.
Behavioralprofiles: a corpus-based approach to cognitive seman-tic analysis.
New directions in cognitive linguistics,pages 57?75.Ralph Grishman.
2003.
Information extraction.
InThe Handbook of Computational Linguistics and Nat-ural Language Processing, pages 515?530.
Wiley-Blackwell.Silja Huttunen, Roman Yangarber, and Ralph Grishman.2002.
Diversity of scenarios in information extraction.In Proceedings of the Third International Conferenceon Language Resources and Evaluation (LREC 2002),Las Palmas de Gran Canaria, Spain, May.Maria Khokhlova and Viktor Zakharov.
2009.
Statisticalcollocability of Russian verbs.
After Half a Centuryof Slavonic Natural Language Processing, pages 125?132.Adam Kilgarriff, Pavel Rychly`, Vojtech Kova?r, and V?tBaisa.
2012.
Finding multiwords of more than twowords.
In Proceedings of EURALEX2012.Scott Martens and Vincent Vandeghinste.
2010.
An effi-cient, generic approach to extracting multi-word ex-pressions from dependency trees.
In CoLing Work-shop: Multiword Expressions: From Theory to Appli-cations (MWE 2010).Pavel Pecina.
2005.
An extensive empirical study ofcollocation extraction methods.
In Proceedings of theACL Student Research Workshop, pages 13?18.
Asso-ciation for Computational Linguistics.Carlos Ramisch, Paulo Schreiner, Marco Idiart, and AlineVillavicencio.
2008.
An evaluation of methods forthe extraction of multiword expressions.
In Proceed-ings of the LREC Workshop-Towards a Shared Task forMultiword Expressions (MWE 2008), pages 50?53.Philip Resnik.
1997.
Selectional preference and sensedisambiguation.
In Proceedings of the ACL SIGLEXWorkshop on Tagging Text with Lexical Semantics:Why, What, and How, pages 52?57.
Washington, DC.Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-take, and Dan Flickinger.
2002.
Multiword expres-sions: A pain in the neck for NLP.
Computational Lin-guistics and Intelligent Text Processing, pages 189?206.Violeta Seretan.
2008.
Collocation extraction based onsyntactic parsing.
Ph.D. thesis, University of Geneva.Serge Sharoff.
2004.
What is at stake: a case study ofRussian expressions starting with a preposition.
InProceedings of the Workshop on Multiword Expres-sions: Integrating Processing, pages 17?23.
Associ-ation for Computational Linguistics.Sayori Shimohata, Toshiyuki Sugio, and Junji Nagata.1997.
Retrieving collocations by co-occurrences andword order constraints.
In Proceedings of the eighthconference on European chapter of the Association forComputational Linguistics, pages 476?481.
Associa-tion for Computational Linguistics.Anatol Stefanowitsch and Stefan Th Gries.
2003.
Col-lostructions: Investigating the interaction of words andconstructions.
International journal of corpus linguis-tics, 8(2):209?243.Marko Tadic?
and Kres?imir S?ojat.
2003.
Finding multi-word term candidates in Croatian.
In Proceedings ofIESL2003 Workshop, pages 102?107.Tim Van de Cruys and Begona Villada Moiro?n.
2007.Lexico-semantic multiword expression extraction.
InProceedings of the 17th Meeting of ComputationalLinguistics in the Netherlands (CLIN), pages 175?190.Joachim Wermter and Udo Hahn.
2006.
You can?t beatfrequency (unless you use linguistic knowledge) ?
aqualitative evaluation of association measures for col-location and term extraction.
In Proceedings of the21st International Conference on Computational Lin-guistics and 44th Annual Meeting of the Associationfor Computational Linguistics, pages 785?792.Elena Yagunova and Lidia Pivovarova.
2010.
The natureof collocations in the Russian language.
The experi-ence of automatic extraction and classification of thematerial of news texts.
Automatic Documentation andMathematical Linguistics, 44(3):164?175.Roman Yangarber, Clive Best, Peter von Etter, FlavioFuart, David Horby, and Ralf Steinberger.
2007.Combining information about epidemic threats frommultiple sources.
In Proceedings of the MMIESWorkshop, International Conference on Recent Ad-vances in Natural Language Processing (RANLP2007), Borovets, Bulgaria, September.81
