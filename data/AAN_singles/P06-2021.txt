Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 160?167,Sydney, July 2006. c?2006 Association for Computational LinguisticsUsing WordNet to Automatically Deduce Relations between Words inNoun-Noun CompoundsFintan J. Costello,School of Computer Science,University College Dublin,Dublin 6, Ireland.fintan.costello@ucd.ieTony Veale,Department of Computer Science,University College Dublin,Dublin 6, Ireland.tony.veale@ucd.ieSimon Dunne,Department of Computer Science,University College Dublin, Dublin 6, Ireland.sdunne@inismor.ucd.ieAbstractWe present an algorithm for automaticallydisambiguating noun-noun compounds bydeducing the correct semantic relation be-tween their constituent words.
This algo-rithm uses a corpus of 2,500 compoundsannotated with WordNet senses and cov-ering 139 different semantic relations (wemake this corpus available online for re-searchers interested in the semantics ofnoun-noun compounds).
The algorithmtakes as input the WordNet senses for thenouns in a compound, finds all parentsenses (hypernyms) of those senses, andsearches the corpus for other compoundscontaining any pair of those senses.
Therelation with the highest proportional co-occurrence with any sense pair is returnedas the correct relation for the compound.This algorithm was tested using a ?leave-one-out?
procedure on the corpus of com-pounds.
The algorithm identified the cor-rect relations for compounds with highprecision: in 92% of cases where a re-lation was found with a proportional co-occurrence of 1.0, it was the correct re-lation for the compound being disam-biguated.Keywords: Noun-Noun Compounds, ConceputalCombination, Word Relations, WordNet1 IntroductionNoun-noun compounds are short phrases made upof two or more nouns.
These compounds arecommon in everyday language and are especiallyfrequent, and important, in technical documents(Justeson & Katz, 1995, report that such phrasesform the majority of technical content of scien-tific and technical documents surveyed).
Under-standing these compounds requires the listener orreader to infer the correct semantic relationshipbetween the words making up the compound, in-ferring, for example, that the phrase ?flu virus?refers to a virus that causes flu, while ?skin virus?describes a virus that affects the skin, and marshvirus a virus contracted in marshes.
In this paperwe describe a novel algorithm for disambiguat-ing noun-noun compounds by automatically de-ducing the correct semantic relationship betweentheir constituent words.Our approach to compound disambiguationcombines statistical and ontological informationabout words and relations in compounds.
On-tological information is derived from WordNet(Miller, 1995), a hierarchical machine readabledictionary, which is introduced in Section 1.
Sec-tion 2 describes the construction of an annotatedcorpus of 2,500 noun-noun compounds covering139 different semantic relations, with each nounand each relation annotated with its correct Word-Net sense.1Section 3 describes our algorithm for findingthe correct relation between nouns in a com-pound, which makes use of this annotated cor-pus.
Our general approach is that the correct re-lation between two words in a compound can bededuced by finding other compounds containingwords from the same semantic categories as thewords in the compound to be disambiguated: if aparticular relation occurs frequently in those othercompounds, that relation is probably also the cor-rect relation for the compound in question.
Our al-1A file containing this corpus is available for downloadfrom http://inismor.ucd.ie/?fintanc/wordnet compounds160Table 1: Thematic relations proposed by Gagne?.relation examplehead causes modifier flu virusmodifier causes head college headachehead has modifier picture bookmodifier has head lemon peelhead makes modifier milk cowhead made of modifier chocolate birdhead for modifier cooking toymodifier is head dessert foodhead uses modifier gas antiqueshead about modifier travel magazinehead located modifier mountain cabinhead used by modifier servant languagemodifier located head murder townhead derived from modifier oil moneygorithm implements this approach by taking as in-put the correct WordNet senses for the constituentwords in a compound (both base senses and parentor hypernyms of those senses), and searching thecorpus for other compounds containing any pairof those base or hypernym senses.
Relations aregiven a score equal to their proportional occur-rence with those sense pairs, and the relation withthe highest proportional occurrence score acrossall sense-pairs is returned as the correct relationfor the compound.
Section 4 describes two differ-ent leave-one-out tests of this ?Proportional Rela-tion Occurrence?
(PRO) algorithm, in which eachcompound is consecutively removed from the cor-pus and the algorithm is used to deduce the cor-rect sense for that compound using the set of com-pounds left behind.
These tests show that thePRO algorithm can identify the correct relationsfor compounds, and the correct senses of those re-lations, with high precision.
Section 6 comparesour algorithm for compound disambiguation withone recently presented alternative, Rosario et al?s(2002) rule-based system for the disambiguationof noun-noun compounds.
The paper concludeswith a discussion of future developments of thePRO algorithm.2 Introduction to WordNetIn both our annotated corpus of 2,500 noun-nouncompounds and our proportional relation selectionalgorithm we useWordNet (Miller, 1995).
The ba-sic unit of WordNet is the sense.
Each word inWordNet is linked to a set of senses, with eachsense identifying one particular meaning of thatword.
For example, the noun ?skin?
has senses rep-resenting (i) the cutis or skin of human beings, (ii)the rind or peel of vegetables or fruit, (iii) the hideor pelt of an animal, (iv) a skin or bag used as acontainer for liquids, and so on.
Each sense con-tains an identifying number and a ?gloss?
(explain-ing what that sense means).
Each sense is linkedto its parent sense, which subsumes that sense aspart of its meaning.
For example, sense (i) of theword ?skin?
(the cutis or skin of human beings) hasa parent sense ?connective tissue?
which containsthat sense of skin and also contains the relevantsense of ?bone?, ?muscle?, and so on.
Each par-ent sense has its own parents, which in turn havetheir own parent senses, and so on up to the (no-tional) root node of the WordNet hierarchy.
Thishierarchical structure allows computer programsto analyse the semantics of natural language ex-pressions, by finding the senses of the words ina given expression and traversing the WordNetgraph to make generalisations about the meaningsof those words.3 Corpus of Annotated CompoundsIn this section we describe the construction of acorpus of noun-noun compounds annotated withthe correct WordNet noun senses for constituentwords, the correct semantic relation between thosewords, and the correct WordNet verb sense for thatrelation.
In addition to providing a set of com-pounds to use as input for our compound disam-biguation algorithm, one aim in constructing thiscorpus was to examine the relations that exist innaturally occurring noun-noun compounds.
Thisfollows from existing research on the relations thatoccur between noun-noun compounds (e.g.
Gagne?& Shoben, 1997).
Gagne?
and her colleagues pro-vide a set of ?thematic relations?
(derived fromrelations proposed by, for example, Levi, 1978)which, they argue, cover the majority of semanticrelations between modifier (first word) and head(second word) in noun-noun compounds.
Table1 shows the set of thematic relations proposed inGagne?
& Shoben (1997).
A side-effect of the con-struction of our corpus of noun-noun compoundswas an assessment of the coverage and usefulnessof this set of relations.3.1 ProcedureThe first step in constructing a corpus of anno-tated noun-noun compounds involved selection ofa set of noun-noun compounds to classify.
Thesource used was the set of noun-noun compounds161Figure 1: Selecting WordNet senses for nouns.defined in WordNet.
Compounds from WordNetwere used for two reasons.
First, each compoundhad an associated gloss or definition written bythe lexicographer who entered that compound intothe corpus: this explains the relation between thetwo words in that compound.
Sets of compoundsfrom other sources would not have such associateddefinitions.
Second, by using compounds fromWordNet, we could guarantee that all constituentwords of those compounds would also have en-tries in WordNet, ensuring their acceptability toour compound disambiguation algorithm.
An ini-tial list of over 40,000 two-word noun-noun com-pounds were extracted from WordNet version 2.0.From this list we selected a random subset of com-pounds and went through that set excluding allcompounds using scientific latin (e.g.
ocimumbasilicum), idiomatic compounds (e.g.
zero hour,ugli fruit), compounds containing proper nouns(e.g.
Yangtze river), non-english compounds (e.g.faux pas), and chemical terminology (e.g.
carbondioxide).The remaining compounds were placed in ran-dom order, and the third author annotated eachcompound with the WordNet noun senses of theconstituent words, the semantic relation betweenthose words, and the WordNet verb sense of thatrelation (again, with senses extracted from Word-Net version 2.0).
A web page was created forthis annotation task, showing the annotator thecompound to be annotated and the WordNet gloss(meaning) for that compound (see Figure 1).
Thispage also showed the annotator the list of possibleWordNet senses for the modifier noun and headnoun in the compound, allowing the annotator toselect the correct WordNet sense for each word.After selecting correct senses for the words in thecompound, another page was presented (Figure 2)Figure 2: Selecting relation and relation senses.allowing the annotator to identify the correct se-mantic relation for that compound, and then to se-lect the correct WordNet sense for the verb in thatrelation.We began by assuming that Gagne?
& Shoben?s(1997) set of 14 relations was complete and couldaccount for all compounds being annotated.
How-ever, a preliminary test revealed some commonrelations (e.g., eats, lives in, contains, and re-sembles) that were not in Gagne?
& Shoben?s set.These relations were therefore added to the list ofrelations we used.
Various other less commonly-occuring relations were also observed.
To allowfor these other relations, a function was added tothe web page allowing the annotator to enter theappropriate relation appearing in the form ?noun(insert relation) modifier?
and ?modifier (insert re-lation) noun?.
They would then be shown the setof verb senses for that relation and asked to selectthe correct sense.3.2 ResultsWord sense, relation, and relation sense informa-tion was gathered for 2,500 compounds.
Relationoccurrence was well distributed across these com-pounds: there were 139 different relations used inthe corpus.
Frequency of these relations rangedwidely: there were 86 relations that occured forjust one compound in the corpus, and 53 relationsthat occurred more than once.
For the relationsthat occured more than once in the corpus, theaverage number of occurrences was 46.
Table 2shows the 5 most frequent relations in the corpus:these 5 relations account for 54% of compounds.Note that 2 of the 5 relations in Table 2 (head con-162Table 2: 5 most frequent relations in the corpus.relation frequency number ofrelation senseshead used for modifier 382 3head about modifier 360 1head located modifier 226 3head contains modifier 217 3head resembles modifier 169 1tains modifier and head resembles modifier) arenot listed in Gagne?
?s set of taxonomic relations.This suggests that the taxonomy needs to be ex-tended by the addition of further relations.In addition to identifying the relations used incompounds in our corpus, we also identified theWordNet verb sense of each relation.
In total 146different relation senses occurred in the corpus.Most relations in the corpus were associated withjust 1 relation sense.
However, a significant mi-nority of relations (29 relations, or 21% of all re-lations) had more than one relation sense; on aver-age, these relations had three different senses each.Relations with more than one sense in the corpustended to be the more frequently occurring rela-tions: as Table 2 shows, of the 5 most frequentrelations in the corpus, 3 were identified as hav-ing more than one relation sense.
The two rela-tions with the largest number of different relationsenses occurring were carry (9 senses) and makes(8 senses).
Table 3 shows the 3 most frequentsenses for both relations.
This diversity of rela-tion senses suggests that Gagne?
?s set of thematicrelations may be too coarse-grained to capture dis-tinctions between relations.4 Compound Disambiguation AlgorithmThe previous section described the developmentof a corpus of associations between word-senseand relation data for a large set of noun-nouncompounds.
This section presents the ?Pro-portional Relation Occurrence?
(PRO) algorithmwhich makes use of this information to deduce thecorrect relation for a given compound.Our approach to compound disambiguationworks by finding other compounds containingwords from the same semantic categories as thewords in the compound to be disambiguated: if aparticular relation occurs frequently in those othercompounds, that relation is probably also the cor-rect relation for the compound in question.
Wetake WordNet senses to represent semantic cate-Table 3: Senses for relations makes and carries.relation relation sense gloss exampleMakes bring forth or yield; spice treeMakes cause to occur or exist; smoke bombMakes create or manufacture cider milla man-made product;Carries contain or hold, have within; pocket watchCarries move while supporting, in passenger vana vehicle or one?s hands;Carries transmit or serve as the radio wavemedium for transmission;gories.
Once the correct WordNet sense for a wordhas been identified, that word can placed a setof nested semantic categories: the category repre-sented by that WordNet sense, by the parent sense(or hypernym) of that sense, the parent of thatparent, and so on up to the (notional) root senseof WordNet (the semantic category which sub-sumes every other category in WordNet).
Our al-gorithm uses the set of semantic categories for thewords in a compound, and searches for other com-pounds containing words from any pair of thosecategories.Figure 3 shows the algorithm in pseudocode.The algorithm uses a corpus of annotated noun-noun compounds and, to disambiguate a givencompound, takes as input the correct WordNetsense for the modifier and head words of that com-pound, plus all hypernyms of those senses.
The al-gorithm pairs each modifier sense with each headsense (lines 1 & 2 in Figure 3).
For each sense-pair, the algorithm goes through the corpus ofnoun-noun compounds and extracts every com-pound whose modifier sense (or a hypernym ofthat sense) is equal to the modifier sense in thecurrent sense-pair, and whose head sense (or a hy-pernym of that sense) is equal to the head sense inthat pair (lines 5 to 8).
The algorithm counts thenumber of times each relation occurs in that setof compounds, and assigns each relation a Propor-tional Relation Occurrence (PRO) score for thatsense-pair (lines 10 to 12).
The PRO score for agiven relation R in a sense-pair S is a tuple withtwo components, as in Equation 1:PRO(R,S) = ?|R ?
S||S|,|R ?
S||D|?.
(1)The first term of this tuple is the proportion oftimes relationR occurs with sense-pair S (in otherwords, the conditional probability of relation R163Preconditions:The entry for each compound C in corpus D contains:CmodList = sense + hypernym senses for modifier of C;CheadList = sense + hypernym senses for head of C;Crel = semantic relation of C;CrelSense = verb sense for semantic relation for C;Input:X = compound for which a relation is required;modList = sense + hypernym senses for modifier of X;headList = sense + hypernym senses for head of X;finalResultList = ();Begin:1 for each modifier sense M ?
modList2 for each head sense H ?
headList3 relCount = ();4 matchCount = 0;5 for each compound C ?
corpus D6 if ((M ?
CmodList) and (H ?
CheadList))7 relCount[Crel] = relCount[Crel] + 1;8 matchCount = matchCount + 1;9 for each relation R ?
relCount10 condProb = relCount[R]/matchCount;11 jointProb = relCount([R]/|D|;12 scoreTuple = (relProp, jointProb);13 prevScoreTuple = finalResultList[R];14 if (scoreTuple[1] > prevScoreTuple[1])15 finalResultList[R] = relSscoreTuple;16 if (scoreTuple[1] = prevScoreTuple[1])17 if (scoreTuple[2] > prevScoreTuple[2])18 finalResultList[R] = scoreTuple;19 sort finalResultList by relation score tuples;20 return finalResultList;End.Figure 3: Compound disambiguation algorithm.given sense-pair S); the second term is simply theproportion of times the relation co-occurs with thesense pair in the database of compounds D (inother words, the joint probability of relationR andsense-pair S).
The algorithm compares the PROscore obtained for each relationR from the currentsense-pair with the score obtained for that relationfrom any other sense-pair, using the first term ofthe score tuple as the main key for comparison(lines 14 and 15), and using the second term asa tie-breaker (lines 16 to 18).
If the PRO score forrelation R in the current sense-pair is greater thanthe PRO score obtained for that relation with someother sense pair (or if no previous score for the re-lation has been entered), the current PRO tuple isrecorded for relation R. In this way the algorithmfinds the maximum PRO score for each relation Racross all possible sense-pairs for the compoundin question.
The algorithm returns a list of can-didate relations for the compound, sorted by PROscore (lines 19 and 20).
The relations at the frontof that list (those with the highest PRO scores) arethose most likely to be the correct relation for thatcompound.Tests of this algorithm suggest that, in manycases, candidate relations for a given compoundwill be tied on the first term of their PRO scoretuple.
The use of the second score-tuple term istherefore an important part of the algorithm.
Forexample, suppose that two competing relations forsome compound have a proportional occurenceof 1.0 (both relations occur in every occurrenceof some sense-pair in the compound corpus).
Ifthe first relation occurs 20 times with its selectedsense pair (i.e.
there are 20 occurrences of thesense-pair in the corpus, and the relation occurs ineach of those 20 occurrences), but the second rela-tion only occurs occurs 2 times with its selectedsense pair (i.e.
there are 2 occurrences of thatsense-pair in the corpus, and the relation occursin each of those 2 occurrences), the first relationwill be preferred over the second relation, becausethere is more evidence for that relation being thecorrect relation for the compound in question.The algorithm in Figure 3 returns a list of can-didate semantic relations for a given compound(returning relations such as ?head carries modi-fier?
for the compound vegetable truck or ?mod-ifier causes head?
for the compound storm dam-age, for example).
This algorithm can also returna list of relation senses for a given compound (re-turning the WordNet verb sense ?carries: moveswhile supporting, in a vehicle or one?s hands?
forthe relation for the compound vegetable truck butthe verb sense ?carries: transmits or serves as themedium for transmission?
for the compound ra-dio wave, for example).
To return a list of rela-tion senses rather than relations, we replace Crelwith CrelSense throughout the algorithm in Figure3.
Section 5 describes a test of both versions of thealgorithm.5 Testing the AlgorithmTo test the PRO algorithm it was implemented in aPerl program and applied to the corpus of com-pounds described in Section 3.
We applied theprogram to two tasks: computing the correct re-lation for a given compound, and computing thecorrect relation sense for that compound.
Weused a ?leave-one-out?
cross-validation approach,in which we consecutively removed each com-pound from the corpus (making it the ?query com-pound?
), recorded the correct relation or relationsense for that compound, then passed the correct164Precision vs PRO level050010001500200025000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1PRO levelnumberof compoundsTotal number ofresponsesreturned at thisPRO levelNumber ofcorrectresponsesreturned at thisPRO levelFigure 4: Graph of precision versus PRO value forreturned relationshead and modifier senses of that query compound(plus their hypernyms), and the corpus of remain-ing compounds (excluding the query compound),to the Perl program.
We carried out this processfor each compound in the corpus.
The result of thisprocedure was a list, for each compound, of can-didate relations or relation senses sorted by PROscore.We assessed the performance of the algorithmin two ways.
We first considered the rank ofthe correct relation or relation sense for a givencompound in the sorted list of candidate rela-tions/relation senses returned by the algorithm.The algorithm always returned a large list of can-didate relations or relation senses for each com-pound (over 100 different candidates returned forall compounds).
In the relation selection task, thecorrect relation for a compound occurred in thefirst position in this list for 41% of all compounds(1,026 out of 2,500 compounds), and occured inone of the first 5 positions (in the top 5% of re-turned relations or relation senses) for 72% of allcompounds (1780 compounds).
In the relation-sense selection task, the correct relation for a com-pound occured in the first position in this list for43% of all compounds, and occured in one of thefirst 5 positions for 74% of all compounds.
Thisperformance suggests that the algorithm is doingwell in both tasks, given the large number of pos-sible relations and relation senses available.Our second assessment considered the precisionand the recall of relation/relation senses returnedby the algorithm at different proportional occur-rence levels (different levels for the first term inPRO score tuples as described in Equation 1).
Foreach proportional occurrence level between 0 and1, we assumed that the algorithm would only re-turn a relation or relation sense when the first rela-Precision vs PRO level050010001500200025000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1PRO levelnumberof compoundsTotal number ofresponsesreturned at thisPRO levelNumber ofcorrectresponsesreturned at thisPRO levelFigure 5: Graph of precision versus PRO value forreturned relation sensestion in the list of candidate relations returned hada score at or above that level.
We then counted thetotal number of compounds for which a responsewas returned at that level, and the total number ofcompounds for which a correct response was re-turned.
The precision of the algorithm at a givenPRO level was equal to the number of correctresponses returned by the algorithm at that PROlevel, divided by the total number of responses re-turned by the algorithm at that level.
The recallof the algorithm at a given PRO level was equalto the number of correct responses returned by thealgorithm at that level, divided by the total numberof compounds in the database (the total number ofcompounds for which the algorithm could have re-turned a correct response).Figure 4 shows the total number of responses,and the total number of correct responses, returnedat each PRO level for the relation selection task.Figure 5 shows the same data for the relation-senseselection task.
As both graphs show, as PRO levelincreases, the total number of responses returnedby the algorithm declines, but the total number ofcorrect responses does not fall significantly.
Forexample, in the relation selection task, at a PROlevel of 0 the algorithm return a response (selectsa relation) for all 2,500 compounds, and approx-imately 1,000 of those responses are correct (thealgorithm?s precision at this level is 0.41).
At aPRO level of 1, the algorithm return a response(selects a relation) for just over 900 compounds,and approximately 850 of those responses are cor-rect (the algorithm?s precision at this level is 0.92).A similar pattern is seen for the relation sense re-sponses returned by the algorithm.
These graphsshow that with a PRO level around 1, the algorithmmakes a relatively small number of errors when se-lecting the correct relation or relation sense for a165given compound (an error rate of less than 10%).The PRO algorithm thus has a high degree of pre-cision in selecting relations for compounds.As Figures 4 and 5 show, the number of cor-rect responses returned by the PRO algorithm didnot vary greatly across PRO levels.
This meansthat the recall of the algorithm remained relativelyconstant across PRO levels: in the relation selec-tion task, for example, recall ranged from 0.41 (ata PRO level of 0) to 0.35 (at a PRO level of 1).
Asimilar pattern occurred in the relation-sense se-lection task.6 Related WorkVarious approaches to noun-noun compound dis-ambiguation in the literature have used the seman-tic category membership of the constituent wordsin a compound to determine the relation betweenthose words.
Most of these use hand-crafted lex-ical hierarchies designed for particular semanticdomains.
We compare our algorithm for com-pound disambiguation with one recently presentedalternative, Rosario, Hearst, and Fillmore?s (2002)rule-based system for the disambiguation of noun-noun compounds in the biomedical domain.6.1 Rule-based disambiguation algorithmRosario et al?s (2002) general approach to noun-noun compound disambiguation is based, as oursis, on the semantic categories of the nouns mak-ing up a compound.
Rosario et al make use ofthe MeSH (Medical Subject Headings) hierarchy,which provides detailed coverage of the biomed-ical domain they focus on.
Their analysis in-volves automatically extracting a corpus of noun-noun compounds from a large set of titles and ab-stracts from the MedLine collection of biomedicaljournal articles, and identifying the MeSH seman-tic categories under which the modifier and headwords of those compounds fall.
This analysis gen-erates a set of category pairs for each compound(similar to our sense pairs), with each pair consist-ing of a MeSH category for the modifier word anda MeSH category for the head.The aim of Rosario et al?s analysis was to pro-duce a set of rules which would link the MeSHcategory pair for a given compound to the correctsemantic relation for that compound.
Given sucha set of rules, their algorithm for disabmiguat-ing noun-noun compounds involves obtaining theMeSH category membership for the constituentwords of the compounds to be disambiguated,forming category pairs, and looking up those cat-egory pairs in the list of category-pair?relationrules.
If a rule was found linking the category pairfor a given compound to a particular semantic re-lation, that relation was returned as the correct re-lation for the compound in question.To produce a list of category-pair?relationrules, Rosario et al first selected a set of cate-gory pairs occurring in their corpus of compounds.For each category pair, they manually examined20% of the compounds falling under that categorypair, paraphrasing the relation between the nounsin that compound by hand, and seeing if that re-lation was the same across all compounds underthat category pair.
If that relation was the sameacross all selected compounds, that category pairwas recorded as a rule linked to the relation pro-duced.
If, on the other hand, several different re-lations were produced for a given category pair,analysis decended one level in the MeSH hierar-chy, splitting that category pair into several sub-categories.
This repeated until a rule was pro-duced assigning a relation to every compound ex-amined.
The rules produced by this process werethen tested using a randomly chosen test set of20% of compounds falling under each categorypair, entirely distinct from the compound set usedin rule construction, and applying the rules tothose new compounds.
An evaluator checked eachcompound to see whether the relation returned forthat compound was an acceptable reflection of thatcompound?s meaning.
The results varied between78.6% correct to 100% correct across the differentcategory pairs.6.2 Comparing the algorithmsIn this section we first compare Rosario et al?salgorithm for compound disambiguation with ourown, and then compare the procedures used to as-sess those algorithms.
While both algorithms arebased on the association between category pairs(sense pairs) and semantic relations, they differ inthat Rosario et al?s algorithm uses a static list ofmanually-defined rules linking category pairs andsemantic relations, while our PRO algorithm au-tomatically and dynamically computes links be-tween sense pairs and relations on the basis of pro-portional co-occurrence in a corpus of compounds.This gives our algorithm an advantage in termsof coverage: where Rosario et al?s algorithm can166only disambiguate compounds whose constituentwords match one of the category-pair?relationrules on their list, our algorithm should be able toapply to any compound whose constituent wordsare defined in WordNet.
This also gives our al-gorithm an advantage in terms of extendability, inthat while adding a new compound to the corpusof compounds used by Rosario et al could poten-tially require the manual removal or re-definitionof a number of category-pair?relation rules,adding a new compound to the annotated corpusused by our PRO algorithm requires no such in-tervention.
Of course, the fact that Rosario et al?salgorithm is based on a static list of rules linkingcategories and relations, while our algorithm dy-namically computes such links, gives Rosario etal.
?s algorithm a clear efficiency advantage.
Im-proving the efficiency of the PRO algorithm, per-haps by automatically compiling a tree of associa-tions between word senses and semantic relationsand using that tree in compound disambiguation,is an important aim for future research.Our second point of comparison concerns theprocedures used to assess the two algorithms.
InRosario et al?s assessment of their rule-based al-gorithm, an evaluator checked the relations re-turned by the algorithm for a set of compounds,and found that those relations were acceptable in alarge proportion of cases (up to 100%).
A problemwith this procedure is that many compounds canfall equally under a number of different acceptablesemantic relations.
The compound storm damage,for example, is best defined by the relation causes(?damage caused by a storm?
), but also falls underthe relations makes (?damage made by a storm?
)and derived from (?damage derived from a storm?
):most people would agree that these paraphrasesall acceptably describe the meaning of the com-pound (Devereux & Costello, 2005).
This meansthat, while the relations returned for compoundsby Rosario et al?s algorithmmay have been judgedacceptable for those compounds by the evaluator,they were not necessarily the most appropriate re-lations for those compounds: the algorithm couldhave returned other relations that would have beenequally acceptable.
In other words, Rosario et al?sassessment procedure is somewhat weaker thanthe assessment procedure we used to test the PROalgorithm, in which there was one correct relationidentified for each compound and the algorithmwas taken to have performed correctly only if it re-turned that relation.
One aim for future work is toapply the assessment procedure used by Rosario etal.
to the PRO algorithm?s output, asking an eval-uator to assess the acceptability of the relations re-turned rather than simply counting the cases wherethe best relation was returned.
This would providea clearer basis for comparison between the algo-rithms.6.3 ConclusionsIn this paper we?ve described an algorithm fornoun-noun compound disambiguation which au-tomatically identifies the semantic relations andrelation senses used in such compounds.
We?vegiven evidence showing that, coupled with acorpus of noun-noun compounds annotated withWordNet senses and semantic relations, this al-gorithm can identify the correct semantic rela-tions for compounds with high precision.
Unlikeother approaches to automatic compound disam-biguation which typically apply to particular spe-cific domains, our algorithm is not domain specificand can identify relations for a random sampleof noun-noun compounds drawn from the Word-Net dictionary.
Further, our algorithm is fully au-tomatic: unlike other approaches, our algorithmdoes not require the manual construction of rela-tion rules to produce successful compound disam-biguation.
In future work we hope to extend thisalgorithm to provide a more efficient algorithmicimplementation, and also to apply the algorithmin areas such as the machine translation of noun-noun compounds, where the identification of se-mantic relations in compounds is a crucial step inthe translation process.ReferencesB.
Devereux & F. J. Costello.
2005.
Investigating theRelations used in Conceptual Combination.
Artificial In-telligence Review, 24(3?4): 489?515.C.
L.
Gagne?, & E. J. Shoben, E. 1997.
Influenceof thematic relations on the comprehension of modifier-noun combinations.
Journal of Experimental Psychology:Learning, Memory and Cognition, 23: 71?87.J.
Justeson & S. Katz.
1995.
Technical Terminology: Somelinguistic properties and an algorithm for identification intext.
Natural Language Engineering, 1?1: 9?27.J.
Levi.
1978.
The Syntax and Semantics of Complex Nomi-nals.
New York: Academic Press.G.
Miller.
1995.
WordNet: A lexical database.
Communi-cation of the ACM, 38(11), 39?41.B.
Rosario, M. Hearst, & C. Fillmore.
2002.
The De-scent of Hierarchy, and Selection in Relational Semantics.Proceedings of ACL-02: 247?254.167
