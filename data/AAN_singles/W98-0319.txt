Lexical, Prosodic, and Syntactic Cues for Dialog ActsDaniel  Jurafsky*,  E l izabeth Shr ibergt ,  Barbara  Fox*, and Traci Curl*University of Colorado*SRI InternationaltAbstractThe structure of a discourse is reflected in many as-pects of its linguistic realization, including its lexi-cal, prosodic, syntactic, and semantic nature.
Multi-party dialog contains a particular kind of discoursestructure, the dialog act (DA).
Like other types ofstructure, the dialog act sequence of a conversationis also reflected in its lexical, prosodic, and syntac-tic realization.
This paper presents a preliminary in-vestigation into the realization of a particular classof dialog acts which play an essential structuringrole in dialog, the backchannels or acknowledge-ments tokens.
We discuss the lexical, prosodic, andsyntactic realization of these and subsumed or re-lated dialog acts like continuers, assessments, yes-answers, agreements, and incipient-speakership.We show that lexical knowledge plays a role indistinguishing these dialog acts, despite the wide-spread ambiguity of words such as yeah, and thatprosodic knowledge plays a role in DA identifica-tion for certain DA types, while lexical cues maybe sufficient for the remainder.
Finally, our investi-gation of the syntax of assessments suggests that atleast some dialog acts have a very constrained syn-tactic realization, aper-dialog act 'microsyntax'.1 IntroductionThe structure of a discourse is reflected in many as-pects of its linguistic realization.
These include 'cuephrases', words like now and well which can in-dicate discourse structure, as well as other lexical,prosodic, or syntactic 'discourse markers'.
Multi-party dialog contains a particular kind of discoursestructure, the dialog act, related to the speech actsof Searle (1969), the conversational moves of Car-letta et al (1997), and the adjacency pair-partsof Schegloff (1968) Sacks et al (1974) (see alsoe.g.
Allen and Core (1997; Nagata and Morimoto(1994)).
Like other types of structure, the dia-log act sequence of a conversation is also reflectedin its lexical, prosodic, and syntactic realization.This paper presents apreliminary investigation i tothe realization of a particular class of dialog actswhich play an essential structuring role in dialog,the backehannels or acknowledgements tokens.We discuss the importance of words like yeah ascue-phrases for dialog structure, the role of prosodicknowledge, and the constrained syntactic realiza-tion of certain dialog acts.This is part of a larger project on automaticallydetecting discourse structure for speech recogni-tion and understanding tasks, originally part of the1997 Summer Workshop on Innovative Techniquesin LVCSR at Johns Hopkins.
See Jurafsky et al(1997a) for a summary of the project and its relationto previous attempts to build stochastic models ofdialog structure (e.g.
Reithinger et al (1996),Suhmand Waibel (1994),Taylor et al (1998) and manyothers), Shriberg et al (1998) for more details onthe automatic use of prosodic features, Stolcke etal.
(1998) for details on the machine learning archi-tecture of the project, and Jurafsky et al (1997a) onthe applications to automatic speech recognition.In this paper we focus on the realization of fiveparticular dialog acts which are subsumed by or re-lated to backchannel acts, utterances which givediscourse-structuring feedback to the speaker.
Four(continuers, assessments, incipient speakership,and to some extent agreements), are subtypes ofbackchannels.
These four and the fifth type (yes-answers) overlap strongly in their lexical realiza-tion; many or all of them are realized with wordslike yeah, okay, uh-huh, or mm-hmm.
Distinguish-ing true markers of agreements or factual answersfrom mere continuers i essential in understanding adialog or modeling its structure.
Knowing whether aspeaker is trying to take the floor (incipient speak-ership) or merely passively following along (con-tinuers) is essential for predictive models of speak-ers and dialog.114Tag ExampleStatementContinuerOpinionAgree/AcceptAbandoned/Turn-ExitAppreciationYes-No-QuestionNon-verbalYes answersConventional-closingUninterpretableWh-QuestionNo answersResponse AckHedgeDeclarative QuestionOtherMe, I'm in the legal department.Uh.huh.I think it's greatThat's exactly it.So, -/I can imagine.Do you have to have any special training<Laughter>, <Throat_clearing>Yes.Well, it's been nice talking to you.But, uh, yeahWell, how old are you?No,Oh, okay.I don't know if I'm making any senseSo you can afford to get a house?Well give me a break, you know.Is that Backchannel-Question._~_._____fight ?37,09625,19710,82010,5694,6334,6243,5482,9342,4862,1581,9111,3401.2771,1821,1741,0741,01919% I13% \]5% \[5% '1%Table 1:18 most frequent ags (of42)2 The Tag Set and Manual TaggingThe SWBD-DAMSL dialog act tagset (Jura(sky etal., 1997b) was adapted from the DAMSL tag-set(Core and Allen, 1997), and consists of approxi-mately 60 labels in orthogonal dimensions (so la-bels from different dimensions could be :ombined).Seven CU-Boulder linguistic graduate students la-beled 1155 conversations from the Switchboard(SWBD) database (Godfrey et al, 1992) of human-to-human telephone conversations with these tags,resulting in 220 unique tags for the 205,000 SWBDutterances.The SWBD conversations had already been hand-segmented into utterances by the Linguistic DataConsortium (Meteer and others, 1995; an utteranceroughly corresponds to a sentence).
Each utterancereceived exactly one of these 220 tags.
For practicalreasons, the first labeling pass was done only fromtext transcriptions without listening to the speech.The average conversation consisted of 144 turns,271 utterances, and took 28 minutes to label.
Thelabeling agreement was 84% (n = .80; (Carletta,1996)).
The resulting 220 tags included many whichwere extremely rare, making statistical analysis im-possible.
We thus clustered the 220 tags into 42 fi-nal tags.
The 18 most frequent of these 42 tags areshown in Table 1.
In the rest of this section we givelonger examples of the 4 types which play a role inthe rest of the paper.A continuer is a short utterance which playsdiscourse-structuring roles like indicating that theother speaker should go on talking (Jefferson, t984;Schegloff, 1982; Yngve, 1970).
Because contin-uers are the most common kind of backchannel, ourgroup and others have used the term 'backchannel'as a shorthand for 'continuer-backchannels'.
Forclarity in this paper we will use the term contin-uer, in order to avoid any ambiguity with the largerclass of utterances which give discourse-structuringfeedback to the speaker.
Table 2 shows examples ofcontinuers in the context of a Switchboard conver-sation.Jefferson (1984)(see also Jefferson (1993)) notedthat continuers vary along the dimension of incipi-ent speakership; continuers which acknowledge thatthe other speaker still has the floor reflect 'passiverecipiency', and those which indicate an intentionto take the floor reflect 'preparedness to shift fromrecipiency to speakership'.
She noted that tokens ofpassive recipiency are often realized as mm-hmm,while tokens of incipient speakership are often re-alized as yeah, or sometimes as yes.
The examplein Table 2 is one of Passive Recipiency.
Table 3shows an example of a continuer that marks incipi-ent speakership.
In our original coding, these werenot labeled differently (tokens of passive recipi-ency and incipient speakership were both markedas 'backchannels').
Afterwards, we took all contin-uers which the speaker followed by further talk andcoded them as incipient speakership, l~This simple coding unfortunately misses more complexcases  of incipiency, such as the speaker's next turns beginning115Table 2: Examples: ContinuersSpkr Dialog Act UtteranceB Statement but, uh, we're to the point now where ourfinancial incomeis enough that we can consider putting some away -A Continuer Uh-huh.
/B Statement - fo r  college, /B Statement so we are going to be starting a regularpayroll deduction -A Continuer Urn.
/B Statement ~ in the fa l l /B Statement and then the money that I will be making this summerwe'll be putting away for the college fund.A Urn.
Sounds good.
AppreciationTable 3: Examples: Incipient Speakership.Spkr Dialog Act UtteranceB ~ Wh-Question Now, how long does it takefor your contribution to vest?A Statement God, I don't know /A Statement <laughter> It's probably along time <laughter>.A Statement I'm sure it's not tillA Statement like twenty-five years, thirty years.B Incipient Yeah.
/B Statement the place I work at's, health insurance is kind of expensive.~The yes-answer DA (Table 4) is a subtype of theanswer category, which includes any sort of an-swers to questions, yes-answer includes yes, yeah,yep, uh-huh, and such other variations on yes, whenthey are acting as an answer to a Yes-No-Question.The various agreements (accept, reject, partialaccept etc.)
all mark the degree to which speakeraccepts ome previous proposal, plan, opinion, orstatement.
Because SWBD consists of free con-versation and not task-oriented dialog, the majorityof our tokens were agree/accepts, which for con-venience we will refer to as agreements.
Theseare used to indicate the speaker's agreement with astatement or opinion expressed by another speaker,or the acceptance of a proposal.
Table 5 shows anexample.3 Lexical Cues to Dialog Act IdentityPerhaps the most studied cue for discourse structureare lexical cues, also called 'cue phrases', whichare defined as follows by Hirschberg and Litman(1993): "Cue phrases are linguistic expressionsa telling (Drummond and Hopper, 1993b)such as NOW and WELL that function as explicitindicators of the structure of a discourse".
This sec-tion examines the role of lexical cues in distinguish-ing four common DAs with considerable overlap inlexical realizations.
These are continuers, agree-ments, yes-answers, and incipient-speakership.What makes these four types so difficult to dis-tinguish is that they all can be realized by commonwords like uh.huh, yeah, right, yes, okay.But while some tokens (like yeah) are highly am-biguous, others, (like uh-huh or okay) are somewhatless ambiguous, occurring with different likelihoodsin different DAs.
This suggests a generalization ofthe 'cue word' hypothesis: while some utterancesmay be ambiguous, in general the lexical form of aDA places strong constraints on which DA the ut-terance can realize.
Indeed, we and our colleaguesas well as many other researchers working on au-tomatic DA recognition, have found that the wordsand phrases in a DA were the strongest cue to itsidentity.Examining the individual realization of our fourDAs, we see that although the word yeah is highlyambiguous, in general the distribution of possible116Table 4: Examples: yes-answer.Spkr Dialog Act UtteranceA Declarative-Question So you can afford to get a house ?B Yes-Answer Yeah, /B Statement-Elaboration we'd like to do that some day.
/Table 5: Example: AgreementSpkr Dialog Act UtteranceA Opinion So, L I think, if anything, itwould have to be /A Opinion a very close to unanimous decision.
/B Agreement Yeah, /B Agreement I'd agree with that.
/realizations i quite different across DAs.
Table 6shows the most common realizations.As Table 6 shows, the Switchbc, ard data supportsJefferson's (1984) hypothesis that uh-huh tends tobe used for passive recipiency, while yeah tends tobe used for incipient speakership.
(Note that thetranscriptions do not distinguish mm-hm from uh-huh; we refer to both of these as uh-huh).
In factuh-huh is twice as likely as yeah to be used as a con-tinuer, while yeah is three times as likely as uh-huhto be used to take the floor.Our results differ somewhat from earlier sta-tistical investigation of incipient speakership.
Intheir analysis of 750 acknowledge tokens fromtelephone conversations, Drummond and Hopper(1993a) found that yeah was used to initiate a turnabout half the time, while uh huh and mm-hmwere only used to take the floor 4% - 5% of thetime.
Note that in Table 6, uh-huh is used to takethe floor 1402 times.
The corpus contains a to-tal of 15,818 tokens of uh-huh, of which 13,106(11,704+1402) are used as backchannels.
Thus 11%of the backchannel tokens of uh-huh (or alterna-tively 9% of the total tokens Of uh-huh) are usedto take the floor, about twice as many as in Drum-mond and Hopper's tudy.
This difference could becaused by differences between SWBD and their cor-pora, and bears further investigation.Drummond and Hopper (1993b) were not ableto separately code yes-answers and agreements,which suggests that their study might be extendedin this way.
Since we did code these sepa-rately, we also checked to see what percentageof just the backchannel uses of yeah marked in-cipient speakership.
We found that 41% of thebackchannel uses of veah were used to take the floor(4773/(4773+6961 )) similar to their finding of 46%.While veah is the most common token for con-tinuer, agreement, and yes-answer, the rest of thedistribution is quite different.
Uh-huh is much lesscommon as an yes-answer than tokens of veah oryes - in fact 86% of the yes-answer tokens con-tained the words yes, yeah.
or vep, while only 14%contained uh-huh.Note also that uh-huh is also not a good cuefor agreements, only occurring 4% of the time.Tokens like exactly and that's right, on the otherhand.
uniquely specify agreements (among thesefour types).
The word no, while not unique (it alsomarks incipient speakership), is a generally gooddiscriminative cue for agreement (it is very com-monly used to agree with negative statements).We are currently investigating speaker-dependencies in the realization of these fourDAs.
Anecdotally we have noticed that somespeakers used characteristic intonation on a particu-lar lexical item to differentiate between its use as acontinuer and an agreement, while others seemedto use one lexical item exclusively for backchannetsand others for agreements.4 Prosodic Cues to Dialog Act IdentityWhile lexical information is a strong cue to DAidentity, prosody also clearly plays an importantrole.
For example Hirschberg and Litman (1993)found that intonational phrasing and pitch accentplay a role in disambiguating cue phrases, andhence in helping determine discourse structure.117Agreemen~ .... Conunuer IncipientSpeaker Yes-Answer:36% -uh-huh " 11704 45% yeah 3304 ~right 1074 11%yes 613 6%that's right 553 6%no 489 5%uh-huh 443 4%that's true 352 3%exactly 299 3%oh yeah 227 2%i know 198 2%sure 95 1%it is 95 I%okay 94 1%absolutely 90 <1%i agree 73 <1%(LAUGH) yeah 66 <1%ohyes 58 <1%yeah 6961fight 2437oh 974yes 365oh yeah 357okay 274um 256sun 246huh-uh 241huh 217huh 137uh 131really 114yeahCLAUGH) II0oh uh-huh I02oh okay 9227%9%3%1%1%yeahuh-huhrightokayoh yeahyes477314026032431991621% (LAUGH) yeah1% oh< 1% sure<1% no< 1% well yeah< 1% really< 1% huh< 1% oh really< 1% oh okay< 1% huh-uh< 1% allright887958494741343131272559%17% yes7% uh-huh3%2%2% oh yes1%<1%<1% yeah (LAUGH)<1%<1%<1% yes (LAUGH)<1%<1%<1% i<1%<1%yeah 1596 56%497 17%401 14%oh yeah 125 4%uh yeah 50 1%31 1%well yeah 29 1%uh yes 25 < 1%24 < 1%um yeah 18 < 1%yep 18 <1%I1 <1%Table 6: Most common lexical realizations for the four DAsHirschberg and Litman also looked at the differ-ence in cues between text transcriptions and com-plete speech.We followed a similar line of research to examinethe effect of prosody on DA identification, by study-ing how DA labeling is affected when labelers areable to listen to the soundfiles.
As mentioned ear-lier, labeling had been done only from transcriptsfor practical reasons, since listening would haveadded time and resource requirements beyond whatwe could handle for the JHU workshop.
The fourthauthor (an original abeler) listened to and relabeled44 randomly selected conversations that she hadpreviously labeled only from text.
In order not tobias changes in the labeling, she was not informedof the purpose of the relabeling, other than that sheshould label after listening to each utterance.
As inthe previous labeling, the transcript and full contextwas available; this time, however, her originally-coded labels were also present on the transcripts.Also as previously, segmentations were not allowedto be changed; this made it feasible to match up pre-vious and new labels.
The relabeling by listeningtook approximately 30 minutes per conversation.For this set of 44 conversations, 114 of the 5757originally labeled Dialog Acts (2%) were changed,The fact that 98% of the DAs were unchanged sug-gests that DA labeling from text transcriptions wasprobably agood idea for our purposes overall.
How-ever, there were some frequent changes which weresignificant for certain DAs.
Table 7 shows the DAsthat were most affected by relabeling, and hencewere presumably most ambiguous from text-alone:Changed DA Count %continuers --+ agreements 43/114 38%opinions --+ statements 22/I 14 19%statements --+ opinions 17/I 14 15%ether 32 (< 3 % each)Table 7: DA changes m 44 conversationsThe most prominent change was clearly the con-version of continuers to agreements.
This ac-counted for 38% of the 114 changes made.
Whilethere were also a number of changes to state-ments and opinions, the changes to cont inuerswere primary for two reasons.
First, statementshave a much higher prior probability than contin-uers or agreements.
After normalizing the num-ber of changes by DA prior, continuer --~ agree-ment changes occur for over 4% of original con-tinuer labelers.
In contrast, he normalized rate forthe second and third most frequent types of changeswere 22/989 (2%) for opinions ~ statements and17/2147 (1%) for statements ~ opinions.
Second,continuer -+ agreement changes often played acausal role in the other changes: a continuer whichchanged to an agreement often caused a precedingstatement tobe relabeled as an opinion.There are a number of potential causes for thehigh rate of cont inuer -+ agreement changes.First, because continuers were more frequent andless marked than agreements, labelers were origi-nally instructed to code ambiguous cases as contin-118uers.
Second, the two codes often shared identicallexical form: as was mentioned above, while somespeakers used lexical form to distinguish agree-merits from continuers, many others used prosody.We did find some distinctive prosodic indicatorswhen a continuer was relabeled as an agreement.
Ingeneral, continuers are shorter in duration, less in-tonationally marked (lower F0, flatter, lower energy(less loud)) than agreements.
There are exceptions,however.
A continuer can be higher in F0, with con-siderable nergy and duration, if it ends in a contin-uation rise.
This has the effect of inviting the otherspeaker to continue, resembling question intonationfor English.
A high fall, on the other hand, soundsmore like an agreement than a continuer.Another important prosodic factor not reflectedin the text is the latency between DAs, since pauseswere not marked in the SWBD transcripts.
Onemark of a dispreferred response is a significantpause before speaking.
Thus when listening, a DAwhich was marked as an agreement in the textcould be easily heard as a continuer if it beganwith a particularly long pause.
Lack of a pause,conversely, contributes to an opposite change, fromcontinuer ~ agreement.
The SWBD segmenta-tion conventions placed yeah and uh-huh in sepa-rate units from the subsequent utterances.
Listen-ing, however, sometimes indicated that these veahsor uh-htths were followed by no discernible pause ordelay, in effect "latched" onto the subsequent u ter-ance.
Taken as a single utterance, the combinationof the affirmative lexical items and the other mate-rial actually indicated agreement.
In the followingexample there is no pause between A.1 and A.2,which led to relabeling of A.1 as an agreement,based mainly on this latching effect and to a lesserextent on the intonation (which is probably coloredby the latching, since both utterances are part of oneintonation contour).Spk Dialog Act UtteranceB OpinionA AgreeA OpinionI don't think they even Irealize vohat's ottt there I and to vchat extent.
I<Lipsmack> Yeah, / fI'm sure a lot of them are Imissing those household Iitems <laugh>.
It5 Syntactic CuesAs part of our exploratory study, we have also be-gun to examine the syntactic realization of certaindialog acts.
In particular, we have been interestedin the syntactic formats found in evaluations and as-sessments.Evaluations and assessments represent a subtypeof what Lyons (1972) calls "ascriptive sentences"(471).
Ascriptive sentences "are used...to ascribeto the referent of the subject-expression a certainproperty" (471).
In the case of evaluations and as-sessments, the property being ascribed is part of thesemantic field of positive-negative, good-bad.
Com-mon examples of evaluations and assessments are:1.
That's good.2.
Oh that's nice.3.
It's great.The study of evaluations and assessmentshas attracted quite a bit of work in the area ofConversation Analysis.
Goodwin and Goodwin(1987) provide an early description of evalua-tions/ assessments.
Goodwin (1996:391) foundthat assessments often display the following format:Pro Term + Copula + (lntensifierp +Assessment AdjectiveIn examining evaluations and assessments in theSWBD data.
we found that this format does occurextremely frequently.
But perhaps more interest-ingly, at least in these data we find a very strongtendency with regard to the exact lexical identity ofthe Pro Term (the first grammatical item in the for-mat): that is, we found that the Pro Term is over-whelmingly "that" in the Switchboard ata (out of1150 instances with an overt subject.
922 (80%1had that as the subject).
Moreover.
in the 1150 ut-terances included in this study (those displaying anovert subject), intensifiers (like very, so) were ex-tremely rare, occurring in only 27 instances (2%),and all involved the same two intensifiers - -  re-ally and preny.
Of the 1150 utterances used as thedatabase for this exploratory study, those utterancesthat showed an assessment adjective displayed avery small range of such adjectives.
The entire listfollows: great, good, nice, wonderful, cool, fun,terrible, exciting, interesting, wild, scary, hilarious.neat, funny, amazing, tough, incredible, awful.The very strong patterning of these utterances:suggests a much more restricted notion of gram-matical production than linguistic theories typicallypropose.
This result lends itself to the notion of"micro-syntax" - -  that is, the possibility that panic-119ular dialog acts show their own syntactic patterningand may, in fact, be the site of syntactic patterning.6 ConclusionThis work is still preliminary, but we have some ten-tative conclusions.
First, lexical knowledge clearlyplays a role in distinguishing these five dialog acts,despite the wide-spread ambiguity of words such asyeah.
Second, prosodic knowledge plays a role inDA identification for certain DA types, while lexi-cal cues may be sufficient for the remainder.
Finally,our investigation of the syntax of assessments sug-gests that at least some dialog acts have a very con-strained syntactic realization, a per-dialog act 'mi-crosyntax'.AcknowledgmentsThe original Switchboard iscourse-tagging whichthis project draws on was supported by the generosityof many: the 1997 Workshop on Innovative Techniquesin LVCSR, the Center for Speech and Language Process-ing at Johns Hopkins University, and the NSF (via IRI-9619921 and IRI-9314967 to Elizabeth Shriberg).
Spe-cial thanks to the rest of our WS97 team: Rebecca Bates,Noah Coccaro, Rachel Martin, Marie Meteer, KlausRies, Andreas Stolcke, Paul Taylor, and Carol Van Ess-Dykema, and to the students at Boulder who did the la-beling: Debra Biasca (who managed the labelers), Mar-ion Bond, Traci Curl, Anu Erringer, Michelle Gregory,Lori Heintzelman, Taimi Metzler, and Amma Oduro.
Fi-nally, many thanks to Susann LuperFoy, Nigel Whrd,James Allen, Julia Hirschberg, and Marilyn Walker foradvice on the design of the SWBD-DAMSL tag-set, andto Julia and an anonymous reviewer for Language andSpeech who suggested relabeling from speech.ReferencesJ Allen and M Core.
1997.
Draft of DAMSL: Dialog actmarkup in several layers.J Carletta, A Isard, S Isard, J.
C Kowtko, G Doherty-Sneddon,and A. H Anderson.
1997, The reliability of a dia-logue structure coding scheme.
Computational Linguistics,23(1):13-32.J Carletta.
1996.
Assessing agreement onclassification tasks:The Kappa statistic.
Computational Linguistics, 22(2):249-254.
June.M.
G Core and J Alien.
1997.
Coding dialogs with theDAMSL annotation scheme.
In AAAI Fall Symposium onCommunicative Action in Humans and Machines, MIT,Cambridge, MA, November.K Drummond and R Hopper.
1993a.
Back channels revisited:Acknowledgement tokens and speakership incipienc~,.
Re-search on Langauge and Social Interaction, 26(2): 157-177.K Drurnmond and R Hopper.
1993b.
Some uses of yeah.
Re-search on Langauge and Social Interaction, 26(2):203-212.J Godfrey, E Holliman, and J McDaniel.
1992.
SWITCH-BOARD: Telephone speech corpus for research and devel-opment.
In Proceedings oflCASSP-92, pages 517-520, SanFrancisco.C Goodwin and M Goodwin.
1987.
Concurrent operations ontalk.
Paper in Pragmatics, 1:1-52.C Goodwin.
1996.
Transparent vision.
In Interaction andGrammar.
Cambridge University Press, Cambridge.J Hirschberg and D. J Litman.
1993.
Empirical studies on thedisambiguation f cue phrases.
Computational Linguistics,19(3):501-530.G Jefferson.
1984.
Notes on a systematic deployment of theacknowledgement tokens 'yeah' and 'ram hm'.
Papers inLinguistics, ( 17): 197-216.G Jefferson.
1993.
Caveat speaker: Preliminary notes on re-cipient opic-shift implicature.
Research on Langauge andSocial Interaction, 26(1): 1-30.
Originally published 1983.D Jurafsky, R Bates, N Coccaro, R Martin, M Metcer,K Ries, E Shriberg, A Stolcke, P Taylor, and C Van Ess-Dykema.
1997a.
Automatic detection ofdiscourse structurefor speech recognition and understanding.
In Proceedingsof the 1997 IEEE Workshop on Speech Recognition and Un-derstanding, pages 88-95, Santa Barbara.D Jurafsky, E Shriberg, and D Biasca.
1997b.
Switch-board SWBD-DAMSL Labeling Project Coder's Manual,Draft 13.
Technical Report 97-02, University of Col-orado Institute of Cognitive Science.
Also available ashttp://stripe.colorado.edu/-jurafsky/manual.august 1 .html.J Lyons.
1972.
Human language.
In Non-verbal Communica-tion.
Cambridge University Press, Cambridge.M Meteer et al 1995.
Dysfluency Annotation Style-book for the Switchboard Corpus.
Linguistic DataConsortium.
Revised June 1995 by Ann Taylor.ftp://ftp.cis.upenn.edu/pub/treebank/swbd/doc/DFL-book.ps.gz.M Nagata nd T Morimoto.
1994.
First steps toward statisticalmodeling of dialogue to predict he speech act type of thenext utterance.
Speech Communication, 15:193-203.N Reithinger, R Engel, M Kipp, and M Klesen.
1996.
Predict-ing dialogue acts for a speech-to-speech translation system.In ICSLP.96, pages 65..I..-657, Philadephia.H Sacks, E. A Scheglo~.
and G Jefferson.
1974.
A simplestsystematics for the organization fturn-taking for conversa-tion.
Language, 50(4):696...-735.E Schegloff.
1968.
Sequencing in conversational openings.American Anthropologist, 70:1075-1095.E.
A Schegloff.
1982.
Discourse as an interactional chieve-ment: Some uses of 'uh huh' and other things that come be-tween sentences.
InD Tannen, editor, Analyzing Discourse:Text and Talk.
George',own University Press, Washington,D.C.J.
R Searle.
1969.
Speec,".
Acts.
Cambridge University Press,Cambridge.E Shriberg, R Bates, P Taylor, A Stolcke, D Jurafsky, K Ries,N Coccaro, R Martin, M Meteer.
and C. V Ess-Dykema.1998.
Can prosody aid the automatic classification fdialogacts in conversational speech?
7: appear in Language andSpeech Special Issue on Prosody and Conversation.A Stolcke, E Shriberg, R Bates, N Coccaro, D Jurafsky, R Mar-tin, M Meteer, K Ries, P Taylor, and C. V Ess-Dykema.1998.
Dialog act modeling for conversational speech.
InIn Papers from the AAAI Spring Symposium on ApplyingMachine Learning to Discourse Processing, pages 98-105,Menlo Park, CA.
AAAI Press.
Technical Report SS.98-01.B Suhm and A Waibel.
1994.
Toward better language modelsfor spontaneous speech.
In ICSLP.94, pages 831-834.P Taylor, S King, S Isard, and H Wright.
1998.
Intonationand dialogue context as constraints for speech recognition.Language and Speech.
to appear.V.
H Yngve.
1970.
On getting aword in edgewise.
In Papersfrom the 6th Regional Meeting of the Chicago LinguisticsSociety, pages 567-577, Chicago.120
