Picking Reference Events from TenseA Formal, Implement able Theory ofEnglish Tense-Aspect SemanticsTrees:Lenhart K. Schubert and Chung Hee HwangDepartment of Computer Science, University of RochesterRochester, New York 14627, U. S. A., andDepartment of Computing Science, University of AlbertaEdmonton, Alberta, Canada T6G 2H1Abst ract .
Despite numerous investigations into Englishtense-aspect semantics, the problem of formally inter-preting tense and aspect remains in large part unsolved.A formal solution requires (a) a well-defined mappingfrom a subset of English covering the most commontense-aspect onstructions (including embedded tensedclauses) to a formal meaning representation, and (b)a well-defined enotational semantics for the meaningrepresentation, which accords with speakers' intuitionsabout the original text.
We propose a simple structurecalled a tense tree (or a set of connected tense trees)as a basis for interpreting tense-aspect constructionsand some time adverbials in a context-dependent way.The de-indexicalization process simultaneously trans-forms tense trees and logical forms, the former in accordwith simple recursion equations and the latter in accordwith formal equivalences between context-indexed andcontext-independent logical forms.
The rules have beenimplemented, and yield meaning representations i  a for-mal episodic logic for narrative understanding.I.
In t roduct ionNarratives describe and relate episodes (events, situa-tions, eventualities).
The episodes successively intro-duced appear to "line up" in systematic ways as a func-tion of the text structure, with tense and aspect playinga crucial role.
(1-2) illustrate this familiar phenomenon:(1) John grinned at Mary.
She frowned.
(2) John knocked, but soon realized Mary had left.Each of the verbs in (1) appears to introduce an episode;the past inflection places them before the utterance vent(or speech time), and the surface ordering suggests tem-poral sequencing, and probably a causal connection.
In(2) we appear to have at least three episodes, a "knock-ing," a "realizing" and a "leaving."
The past perfect aux-iliary relates the "leaving" to a past episode serving asreference point.
(This reference point seems closely cor-related with the "realizing" episode, but on our theory isnot identical with it.)
As well, the adverb soon implic-itly references and relates the "knocking" and "realizing"episodes.The problem of automatically extracting these rela-tionships is complicated by a number of subtle issues:?
How many episodes (events, situations, etc.)
doesa sentence implicitly introduce?
We remarked thatthe introduction of episodes appears correlated withverbs; but in(3) John did not elude the tackle and score atouchdown, disappointing the fans.the causally relevant episode is characterized by thenon-occurrence of successive "eluding" and "scor-ing" events; and in(4) When each guest congratulated Mary andgave her a present, she felt quite overwhelmed.the focus is on a "quantified" event consisting of anynumber of "congratulating" and "giving" events.What are the relative (semantic) scopes of tense andaspect, relative to NPs, VPs, adverbials, negation,etc.?
Syntax suggests that tense scope is confinedto the tensed verb or VP, yet in a sentence like(5) For a whole week this summer, no rain fell.this simple view is troublesome: if the past tense isconfined to the VP (so that fell means "falls-before-now"), then the sentence is true if we can find aweek any time this summer in which there are nopast rainfalls- a property that holds of all remaining(i.e., future) weeks of the summer!Do simple past or present-tense ntences make def-inite or indefinite reference to episodes (or times)?Davidson\[3\], Harman\[5\], Reichenbach\[13\] anda ma-jority of writers after them took event reference insimple past and present to be indefinite (existen-tial), and this seems in accord with intuition in suchsentences as(6) John got married last year.where there is no definite commitment as to the timeof the event (apart from its being confined to lastyear).
On the other hand, Partee\[12\] pointed outthe seemingly anaphoric haracter of tense referencein sentences like(7) I left the stove on.Also, Leech\[8\], McCawley\[9\], Webber\[19\] and manyothers have noted that the simple past normally in-volves a "point of orientation" such as an immedi-34ately preceding event, and that Reichenbach's "ref-erence time" appears to be definite at least in thecase of perfect.Our goal is a comprehensive account of how episodesand their relationships are determined by syntax, seman-tics, and pragmatics.
The account is to be an intrinsicpart of a general theory of the understanding process,and is to be formulated in a mathematically precise andcomputationally implementable way.
At the most gen-eral level, the task can be viewed in terms of the followingsort of schema:English (~) \[ (~)--t- ' \[ MR .
.
.
.
.
.
.
.
WORLDContextSuitable forinferenceI.e., English in conjunction with suitable context struc-tures needs to be mapped to a formal meaning repre-sentation (O), and this MR needs to be formally inter-pretable (Q), with truth conditions that are in intuitiveaccord with intuitions about the original English text.Thus we will have some assurance that inferences basedon the MR will be those intuitively warranted.With respect o this schema, most previous tudies oftense and aspect have been more formally explicit about(~) than about (~).
The MR is often some dialect of first-order logic, or a modal or intensional logic, with formalsemantics in the traditional vein (e.g., possible-worldsmodels with multiple time indices).The description of (~), however, is often very infor-mal or limited to a very restricted set of constructions.Furthermore, the formalized accounts (e.g., \[4\], \[6\], \[14\])tend to take context for granted - the focus is on truthconditions, and so the model is simply assumed to sup-ply the needed reference times.
AI-motivated work ontense and aspect has emphasized their pragmatic signif-icance, e.g., for discourse segment structure (see \[1\], cA.13 & 14), and their role in the practical extraction oftemporal relationships from discourse in applied NL sys-tems (e.g., see several of the articles in ComputationalLinguistics 11(2), 1988).
Much of this work has treated(~) heuristically, restricting attention to simple types ofsentences and viewing tense and aspect as phenomenato be handled by a separate module, rather than as anintegral part of a compositional mapping from text tomeaning representations.Non-compositional pproaches based on simple sen-tence types run the risk of being ungeneralizable.
Forinstance, they may tie event introduction to verb phrasesin a way that doesn't generalize to logical compounds (asin sentences (3) and (4)).
Also, they may get the seman-tics of embedded sentences wrong.
For instance, simplesentence types suggest hat past tense places an eventbefore the speech time.
But in(8) Mary will realize a year from now that her wed-ding to John, which takes place tomorrow, was abig mistake.the past tense is used for a future event.
Thus weneed to characterize the semantics of particular syntacticconstructs - including tense-aspect onstructs - in a waythat holds for all syntactic environments in which theconstructs may occur.On the issue of compositionality, we should also re-mark that we find much of the work on tense and aspect"unduly Reichenbachian".
Though the importance ofReichenbach's seminal work in this area is undisputed,it is based on the dubious view that tensed perfects arecomplex variants of "simple" past, present and futuretense.
Since these "complex" tenses appear to involvea reference time (besides the event and speech times),Reichenbach attributed such a reference time to "sim-ple" tenses as well.
But from a compositional perspec-tive, it is much more natural to view tense (past andpresent) and perfect as making separate contributions tothe VP or sentence meaning.
After all, each can occur ina VP without the other ("John probably forgot", "Johnis likely to have forgotten").
Thus semantic dependenceon Reichenbach's reference time may well be particularto the perfect - jus t  as dependence on speech time (or amore general sentence reference time) seems particularto tense.In the remaining sections of the paper we report ourprogress o far on the tense-aspect problem within theabove schema.
Section 2 briefly elaborates our concep-tion of the understanding process.
Section 3 explainsthe intuitive idea behind our method of transformingindexical logical forms (LFs) to nonindexical LFs ina principled way, using context structures called tensetrees.
These provide the "points of orientation" (ref-erence episodes) needed to interpret ense and aspect,and are transformed in the course of "de-indexicalizing"LFs in a way that can be concisely stated by recursionequations.
Section 4 provides a formal statement withexamples of the basic de-indexicalization rules for tenseand aspect.
Section 5 summarizes our progress and workleft to be done.In the course of the paper, we make commitmentsabout key aspects of the issues enumerated above.Briefly, our view is that at the level of LF, tensed En-glish sentences contain separate past, pres, perf and futroperators; (will and would have separate tense and futrcomponents); that not only past, pres, perf, and futr in-troduce episodes, but that various logical operators doso as well, including negation, conjunction, and quan-tification; that past and pres are sentence-level operatorsgenerally taking wide scope (despite syntactic appear-ances); and that the episodes introduced by past andpres, and indeed by any operators, are indefinite (ex-istentially quantified).
This last claim applies even tothe past in the past perfect, consistently with our com-positional view of tense and aspect.
The way the pastperfect auxiliary connects up with a pre-existing "pointof orientation" is not by direct anaphoric reference, butby a mechanism that applies to all statives.35I I .
A Formal  V iew o f  the  Unders tand ingProcessThe following illustrates our current view of the stages ofthe understanding process, at a theoretical level.
(At theprocedural level these stages are interleaved.)
This viewincorporates ideas from GPSG, HPSG, DRT and situa-tion semantics, and evolved in the course of our own re-search on mapping English into logic \[17\], \[18\] and storyunderstanding \[15\], \[16\].0.
Assume that an episode e0 has just been described.e0: After their doubles victory, Mary and Sue weresurrounded by their fans.New sentence:  A man kissed Mary1.
GPSG parser:\[s \[NP \[Det a\] \[N man\]\] [vP Iv kissed\] \[NP Mary\]\]\]2.
Ru le -by- ru le  LF computat ion :\[<3 man> <past kiss> Mary\]3.
Scoping: (past (3:e: \[z man\]\[x kiss Mary\]))4.
De- indexica l izat ion (using context structure C):(3e:\[\[e before Now3\] A \[e0 orients e\]\]\[(3x:\[z man\]\[x kiss Mary\]) ** e\])5.
P ragmat ic  inference:(3e:\[\[e before Now3\] A \[e right-after e0\]\]\[(3:e:\[x man\]Ix kiss Mary\]) ** el)6.
In ference based on MPs  & wor ld knowledge:The man liked Mary a lot;he was happy about her victory; etc.A preliminary unscoped, indexical LF is derived viasemantic rules paired with phrase structure rules.
Pred-icate infixing (with the predicate following its "subject"argument and followed by additional arguments, if any)is used for readability.
Angle brackets indicate unscopedoperators that are to be "raised" to some sentence-levelposition.
Scoping quantifiers involves variable introduc-tion and conversion of the restriction predicate to a re-striction formula.
Note that after the third stage the 3-quantifier and past operator are scoped in the example;in general we take tense to have a strong, though not ab-solute, wide-scoping tendency (but like quantifiers, it is"trapped" by scope islands, such as embedded clauses).The fourth stage is our main focus in this paper.In this stage the scoped, but still indexical, LF is de-indexicalized.
In particular, explicit episodic variablesare introduced, and tense and aspect operators are re-placed by relationships among episodes.
This processmakes use of tense trees as part of a context s~ructure,modifying these trees by adding branches and episode to-kens as a "side effect".
In general we envisage this stageas also performing other kinds of de-indexicMization,most importantly the explicit augmentation f anaphoricexpressions (such as (The x: Ix man\] ...)) by Context-derived predications (such as (The z: \[\[x man\] A \[z has-possible-antecedents (tuple ...)\]\] ...)).Note the connective "**" in the nonindexical formulas,connecting a formula to an episode which it characterizes(or completely describes).
This is a strengthened versionof "*", or partially describes, an operator that is essen-tially the same ms Reichenbach\[13\]'s "*", and similar toBarwise\[2\]'s ~.
For semantics ee \[16\].Note also the orients relationship in 4th stage (itali-cized) sample result.
This is intended to echo Leech'snotion of a "point of orientation" (as cited in \[19\]).We refer to this relation, and certain others derivedfrom context (including has-possible-antecedents above)as context-charged.
The idea is that their meaning isto be "discharged" using uncertain (probabilistic) infer-ence.
For instance, the fact that e0 in the example ori-ents (serves as point of orientation for) e suggests amongother possibilities that e immediately follows e0 (in e0's"consequent" or "result" phase, in the terminology of\[10\] or \[11\]).
Given the assumed types of e0 (Mary andSue being surrounded by their fans) and e (a man kiss-ing Mary), this is a very plausible inference, but in othercases the most plausible conclusion from the orients rela-tion may be a subepisode relation ("It was a great party.Mary did her Chef impression"), an explanatory relation("John went shopping.
Mary's birthday was in a week"),or any of the discourse relations that have been discussedin the literature (e.g., \[7\]).The de-indexicalization stage is followed by inferencestages which discharge context-charged relations andmore generally do input-driven plausible inference basedon the text interpreted so far, meaning postulates (MPs)and world knowledge.
In these stages unique referentsfor referring expressions, predictions, and explanationsare computed which ultimately give a causally coherentelaboration of what has been said.We now turn to a detailed account of the de-indexicalization stage.
For a much more complete de-scription of our overall approach to knowledge represen-tation, inference and understanding, the reader is re-ferred to \[15\] and \[16\].I I I .
De- Index ica l i za t ion :  T ravers ingTense  TreesA formal theory of how indexical formulas are convertedto nonindexical ones as a function of context requires anexplicit specification of the type of context structure tobe used.
We will not attempt a full specification, sincewe are not addressing all aspects of de-indexicalization(such as anaphoric processing).Rather, we will specify a new type of context compo-nent called a tense tree (or a set of embedded trees),which serves the purpose of context-dependent tense-aspect interpretation.
Apart from this, we assume a"clock" which generates a succession of Now-points,hearer and speaker parameters, and whatever additionalinformation a more complete discourse theory may callfor; e.g., a nested segment structure which records theevolving set of relationships among discourse segments,36F igure  1.
Tense Treesembedding presnode .
........... " " ~ e  is homeHe left ~,,b~,c~,d ~\[ ~ Hehas le f t  \]perf l  , fu~xxxx 1.o,c ?b,eHe had left He would leaveHe will leaveperf@He will have leftincluding time, hearer and speaker parameters for thosesegments, history lists or focus lists of entities referencedwithin them, etc.
In fact, we may want to view our tensetree structures as part of the "fine-grained" structureof discourse segments, recording the pragmatic relation-ships among the clauses and subclauses of a segment.The form of a tense tree is illustrated in Figure 1.
Eachnode has up to three branches, a diagonally leftward onecorresponding to a past operator, a vertical one to a perfoperator, and a diagonally rightward one to a futr op-erator.
As an indexical LF is processed in a recursivetop-down manner to de-indexicalize its tense and aspectoperators (and adverbials, etc.
), the tense tree is tra-versed in a way dictated by the operators encountered.The position of the current traversal is called the focalnode, or focus, of the tense tree structure and is indicatedas ?.
Where branches do not exist, they are created,and as new episode variables are introduced into the LF,copies of these variables are added to lists maintained atthe nodes of the tense tree.
As an aid to intuition, thenodes in Figure 1 are annotated with simple sentenceswhose indexical LFs would lead to those nodes in thecourse of de-indexicalization.Subordinating constructions (as in VPs with that-complement clauses) cause one tree to embed another,and this is indicated by horizontal embedding links froma (non-root) node of a tense tree to the root node ofanother.
A set of trees connected by embedding linksis called a tense tree structure.
(This is in effect a treeof tense trees, since a tense tree can be embedded byonly one other tree.)
In Figure 1 an embedding link tothe root is shown, since we assume that the utterancesof a speaker (or sentences of a text, etc.)
are ultimatelyrepresented in terms of performative modal predications,such as (pres \[Speaker assert (that ~)\]) or (pres \[Speakerask (whether ~)\]).
Here that and whether are "facsimi-les" of the nominalization operators That and Whether.By that we mean that they are semantically indistin-guishable from the latter, but since they were in effect"inserted" by the hearer, they are treated slightly differ-ently in the tree traversals (as will be seen).The additional annotations a, br, cr, d at the past nodein Figure 1, and b, c at the past-perfand past-futr nodes,are based on the following two short passages:(9) a. John entered the room.b.
Mary had taken down his paintings,c.
and had hung up Schwarzenegger posters.d.
He groaned.
(10) a. Mary's note made up John's mind.b.
He would leave,c.
and would let her live her own life.d.
He began to pack.The a at the past node indicates that an episode tokenfor the event of John's entering the room in (9) a, or theevent of Mary's note making up John's mind in (10) a, isadded at that node in de-indexicalizing the LFs of thosesentences.
Similarly the br indicates that an episode to-ken for the reference point of the perfect in (9) b or (10) bis added at the past node in processing the LFs of thesesentences; imilarly for b, cr, c, and d.We will specify these operations formally, but whatwe have said so far allows us to explain intuitively howoccurrences of tense-aspect operators are converted toexplicit episode relationships.
The idea is that episodetokens adjacent at a node (e.g., tokens for a and brabove) generate orienting relationships (e.g., \[a orientsb~\]); the episode last added at a past node is beforea correlated episode at the mother's embedding node(which will be a speaking episode, thinking episode, orthe like);(simplifying a bit) the episode last added at aperf node lasts at least until a correlated episode at themother; and similarly for futr.A crucial observation about (9) is that the tokens forthe "entering" event in a and the "taking down paint-ings" event in b are not placed at the same node -whereas the "groaning" event in d does end up at thesame node as a.
Assuming that the "reference pisodes"b~ and c~ can be inferred to be at approximately thesame time as the entering event a (and it turns out thatthey can), then the "groaning" event d can be inferredto be shortly after the "entering".
As well, note that the"taking down paintings" and "hanging up Schwarzeneg-get posters" episodes band c are adjacent at the past-parrnode, so that b orients c. So the collocation of episodetokens in the tense tree is such that we can "read off'the relationships implicit in the tense-aspect operatorsand surface ordering of sentences.We can now make the de-indexicalization process andassociated tense tree transformations more precise.IV .
Bas ic  Tense-Aspect  Ru lesAssume that we already have a tense tree structure T,with a particular node in focus, as a result of process-ing previous inputs and partially processing the currentinput.
(If not, we generate a one-node tree using the"new-tree" function ~ .)
Then de-indexicalization f anLF formula with a top-level pres operator, relative to T,is defined by the equivalencePres :  (pres ~)T ~ (3aT: \[\[aT at-about EmbT\] A\[Last T orients aT\] \]37\[~OT ** eT\]),tree transformation: (pres 9)" r = 9 .
(or )Here e T is assumed to be a new episode variable nameuniquely defined for any given T (e.g., the letter e withsubscript i where i is the least integer such that ei doesnot yet occur in T).
"OT" means "store e T at the focalnode of T." Emb T denotes the last-added episode at thenode which directly embeds the tree containing the focalnode of T. (This is usually an episode corresponding toa performative or attitude verb.)
If there is no embed-ding node, Emb T is the Now-point of the current context.Last T is the last-stored episode variable at the focus ofT.Thus the de-indexicalization rule "creates" a newepisode token, which it predicates to be at about the timeof embedding event (e.g., the assertion of the sentencebeing processed), designates the last-stored episode atthe current focus as the point of orientation for the newepisode, and states that the formula 9 on which pres op-erates, after recursive de-indexicalization (with e T nowstored at the focus), characterizes the new episode.The tree transformation which is induced by this de-indexicalization (in the implementation, as a side effect)is separately stated above.
The dot symbolizes the tree-structure transformation function,?
: LF-expressions ?
Tense-tree structuresTense-tree structuresThus, the effect of (pres 9) on T is just storage of e T atthe focus of T, followed by whatever additional transfor-mations 9 induces.
(Note that the function compositionin "9  ?
(OT)" is read "from the inside to the outside,"as usual.
)Next, the de-indexicalization f past is given byPast:  (past 9)T ~ (JET: \[\[e T before EaUbT\] A\[Last/,  T orients eT\] \]\[(I~./T ** eT\] ),tree transformation: (past if)" T = T(9" (O~,/T))Here " l  T" signifies T with the focus displaced to the left(i.e., past) daughter, with creation of a new daughter ifnecessary.
Thus the orienting episode for the new pastepisode e T is the last-stored episode at the past daugh-ter of the focal node.
(So for a succession of simplepast-tensed sentences, each episode generated will orientthe next one.
As well, all of them will be before theirembedding episode, i.e., the appropriate sentence utter-ance.)
Again, the recursively de-indexicalized 9 (withthe T-focus shifted left and e T stored there) is taken tocharacterize the new episode.
In the tree transformationequation, the upward arrow signals upward displacementof the focus to the mother.
This restores the focus to itsoriginal position, assuming that recursive processing ofq~ has no net effect on the focus (which it doesn't, thanksto the way the remaining rules work).Actually, the above Past-rule is a slight simplifica-tion.
It applies as stated only when the focal node is not"past-dominated," i.e., if there are no past-branches inits ancestry (with embedding links counting as ancestrylinks).
If the focus is past-dominated, \[eT before ErabT\]is replaced by \[e T at-or-before EmbT\].
Here at-or-beforeis regarded as a context-charged relation, with differentprobable consequences depending on the aspectual classof its first argument.
In particular, for stative T, \[e T at-or-before EmbT\] strongly suggests \[e T at ErabT\].
This isaimed at "sequence of tense" phenomena, observable insentences like(11) John knew that Mary left.
(12) John knew Mary had a cold.For (11), our rules predict that the "leaving" is stronglypreferred to be prior to the "knowing" (though a variantlike "John noticed that Mary winked at him" forces aconcurrent-event reading); while for (12), they predictthat the "cold" episode is strongly preferred to be at thesame time as the "knowing" episode (though a variantlike "John remembered that Mary had a cold when theygot married" forces an earlier-episode r ading).To understand the next rule, recall that we take willand would (in their future and future-in-the-past read-ings) to consist logically of tense plus the futr operator.Thus the futr operator is encountered only after its im-plicit tense operator has been processed, so that a char-acterizing ("**") relation will already embed the (futrif) expression.Futr :  \[(futr 9)T ** ~\] ~-~ \[(JET: \[\[e T after r/\] A\ [Las t \ r  orients er\] \]** et\])  ** (Ftree transformation: (futr 9)" r = T (~" (O\  r))This is quite analogous to pres and past, except hat thetemporal location of the new episode e T is specified rel-ative to the episode 7/(usually a present or past episode)characterized by "having 9 true in its future," ratherthan relative to an "embedding episode."
Also, (F r/) inthe rule denotes "the facts about r/."
Roughly speaking,this is needed because the formula preceding "** (F r/)"is an atemporal characterization f the propositional con-tent of r/ (one that is simply true or false, rather thantrue of some episodes and false of others); whereas (futr9)W is a temporal characterization f r/("being followedat some future time by a 9-episode" can be true of someepisodes - namely, those that do precede a 9-episode -and false of others).
The "** (F ~)" could be droppedwithout falsifying the forward direction of the equiva-lence.For the perfect, we need to assume an ambiguity: thepresent perfect auxiliary (has or have) is always trans-lated as APAz<pres (pert1 \[z P\])> (so that apart fromthe tense, the perfect is logically pert1); but when occur-ring untensed or in combination with past, the perfect islogically either pert1 or pert2.Per t ( l ) :  \[(perfl ?
)T ** 7/\]\[(3eT: \[e T until r/\]\[Col r @ eT\] ) ** (F r/)\],tree transformation:(perfi ?)"
T : T (9" (OIT)), (i = 1,2);where @ ?
for ?
stative;\[~ @ ~\] ~ (Je:\[e recent-subep ~\]\[9 * el), otherwise.38Here recent-subep is another context-charged relation,which for a state-change  of type ?
as first argumentsuggests the truth of \[~ * (fin r\])\], whenever \[?
** elientails \[~ ?
(fin el)\] for all el (where fin means "finalmoment of').
For instance, consider(13) John has been sleeping.
(14) John has woken up.For (13), we will get a subformula \[(prog \[John sleep\])@ e~\], for some i.
Since progressives are stative, thisis equivalent to \[(prog \[John sleep\]) * ei\], meaning thatJohn is sleeping over the entire episode ei.
This episodelasts until "rf' in the complete formula, which is nothingelse but the reference pisode for the perfect (correspond-ing to Reichenbach's reference time).
For (13), this 7/isa "present" episode (by the Pres-rule), so (13) means, ineffect, that John has been sleeping until now.
We takethis to be the desired inference.For (14), we will get a subformula \[\[John wake-up\] @ei\], and since this is nonstative,(Je: \[e recent-subep ei\] \[\[John wake-up\] * e\]).Since further \[\[John wake-up\] ** el\] entails \[\[John awake\]?
(fin el)\] for all el (via suitable meaning postulates),this suggests\[\[John awake\] * (fin ei)\],where as in (13), ei lasts until r\], the (present) refer-ence episode.
In other words, John is still awake.
Notethat this is only an implication, since we can perfectlywell say, without contradiction, "John has woken up andfallen asleep again.
"The second variant of perfect is simpler, amounting toa "relative past":Per f (2) :  \[(perfz ?
)T ** r\]\]\[(JET: \[\[e T before rl\] A \[Last~T orients eT\] \]\[?o,T ** eT\]) ** ( f  r\])\]Note that in the Perf(1)-rule, episode e T was taken tolast until the reference pisode, and to be only indirectlycharacterized by ?
(via "@"); here e T is before the ref-erence episode, and is directly characterized by ?
(afterde-indexicalization).
The two main consequences are,first, that there is no longer an implication that a sta-tive episode persists to the reference time; and second,the episode stored in the tense tree is now the actualif-event, not an episode which by inference contains aC-event.
The differences between perfl and perf2 helpto account for the following contrasts:(15) a.
*John has left yesterday.b.
John had left the day before.c.
John will have left the day before.
(16) a. John has woken up and *has immediatelydressed.b.
John had woken up and had immediatelydressed.c.
John will have woken up and will immediatelyhave dressed.On our account, only perfl is available in the a-sentences; so in (15)a, we do not get "John's leaving"stored in the tense tree, but only an episode containingJohn's leaving and lasting till now - but that cannotpossibly be contained in yesterday.
Similarly in (16)a,John's waking up is not directly stored in the tense tree,and so is not directly available in the interpretation ofimmediately.
(We think that there may be a recoverymechanism in the interpretation of adverbials, whichlooks for suitable points of orientation in the history list(where we assume that all indefinites and definites arerecorded, whether explicitly mentioned or inferred) afterfailing to find them in the tense tree.)
In the b and csentences in (15) and (16), no difficulties are encounteredbecause of the availability of the perf2 reading.Perhaps the most important point about our treat-ment of the perfect, alluded to earlier, is that the refer-ence episode is introduced simply by the normal effectof operators (usually past, pres or futr) "exterior" to it.Briefly reconsidering (9)b, for example, we see that the(wide-scope) past will generate an episode in the pastrelative to the time of speech, and oriented by the "en-tering" episode in (9)a.
It is this past episode whichbecomes the reference pisode for the perfect.
Now thekey to the seemingly anaphoric haracter of this refer-ence episode is this: if \[el orients e2\], and e2 is stative,then there is a strong suggestion that e2 is either con-current with el (namely, when ex is stative as well) orcontiguous with its end point (when el is nonstative).This is apparent, for instance, in the following variant of(9):(177) a. John entered the room.b.
His paintings were gone.c.
In their place were Schwarzenegger posters.In b, the episode of the paintings being gone covers (atleast) a short time-span immediately following John'sentering.
In c, the episode of the posters being in placeis concurrent with the paintings being gone, since bothepisodes are stative.
Now, recognizing that perfect ref-erence episodes are stative (because the state of beingafter some given type of event can persist indefinitely,and holds of the subintervals of any intervals of which itholds), the same analysis places the past episode in (9) b(serving as reference pisode for the perfect) right afterJohn's entering, contiguous with it.
This is tantamountto making the end of John's entering the "reference time"for the perfect.
So we get the desired "anaphoric" effect,without reating past as anaphoric, and without singlingout the past in past perfect for special treatment.Next we mention the de-indexicalization rules forThat- and that-nominalizations:That ( l ) :  (That ~)T =(That ~T) ,tree transformation:(That ?)"
T = ~ (~" (~--~T))That(2):  (that ?
)T =(That CUT),tree transformation:(that ,I~)" T = ~ (~" (?--+ T))The rules cause focus shifts to the root of an embed-ded tree, indicated by the ~ and ~ operations.
The39first of t:hese always adds a new embedding link whosedestination is a new root node, whereas the second onlydoes so if no embedding link exists at the current focus;otherwise, it causes re-traversal of the last embeddinglink added at the current focus.
The leftward arrowsin the two rules indicate focus restoration much like theupward arrows in the preceding rules.
Intuitively, thedistinction between a sentence nominalization derivedexplicitly from the text and one introduced through animplicit performative is motivated by the following sortof contrast:(18) a. John knows that Mary got home before mid-night?b.
He also knows that she watched a movie?
(19) a. Mary got home before midnight.b.
She watched a movie.In (18) the sentences about Mary in a and b are ob-jects of attitudes, and it is much less clear than in (19)whether they refer to successive pisodes.
Now, theLFs for (19)a,b will contain performative predicatesand that-nominalization operators; since the rule forthat causes re-traversal of embedding links, the a and bepisodes will end up at the same node.
But in (18) onlythe "knowing" episodes map to the same node, whilethe episodes involving Mary map to different embeddednodes.
Thus it will be harder to establish a connec-tion between them (i.e., tense structure alone Will notestablish a connection though inference based on otherinformation still might).Before proceeding to further rules we illustrate someof the ones so far with a "trace" of an LF de-indexicalization, amely, that of sentence (21), utteredright after (20):(20) Mary looked pale.
(21) John realized that Mary was tired.The tree structure after processing of (20) will beT= ?
'e~p ?- e 1where e0 corresponds to the added performative - i.e.,the speaker's utterance of (20), and el corresponds toMary's looking pale at a point in the past.
The logicalform of (121) is initially (without performative)\[John <past realize> (That \[Mary <past tired>\])\].and after scoping and addition of the implicit performa-tive,(pres \[Speaker assert (that (past \[John realize(That (past \[Mary tired\]))\]))\]).By the Pres-rule, the first step of the de-indexicalizationrelative to T yields(3e2:\[\[e2 at-about Now2\] A \[e0 orients e2\]\]\[\[Speaker assert (that (past \[John realize(That (past \[Mary tired\]))\]))\]T, ** e2\])eoe2where T' = (~)....-po el /Next, a simple rule we have not mentioned moves theT ~ inward to the that-clause.
The That(2)-rule causesretraversal of the embedding link, and the Past-rule thengives the following altered form of the outer that-clause:(That (3e3:\[\[e3 before e2\] A \[el orients e3\]\]\[\[John realize (That(past \[Mary tired\]))\]T,, ** e3\]))eoe2where T" = ?
.........Again T" is moved inward to the embedded That-clause,and the That (1)-rule generates a new embedding linkand tree root at the focal node.
It then remains to pro-cess the innermost tensed clause (past \[Mary tired\])T,,witheoe2T Ill = ?
.
.
.
.
.
.
.
.
.
"'.'.Z.'.
'....e le3One more application of the Past-rule, but keeping inmind that we are now at a past-dominated node, con-verts the tensed clause to(3e4:\[e4 at-or-before a\] \[\[Mary tired\] ** e4\])assuming the orienting predication is omitted when thereis no orienting episode.
The final tree structure will beSince e4 is stative (given its characterization \[Marytired\]), the inference from the context-charged predica-tion is that e4 is concurrent with e3 (i.e., John's real-ization), in the absence of contrary information.
Alsothe earlier context-charged relation \[el orients e3\] willlead to the inference that John's realization was duringMary's looking pale, in view of the fact that el is stativeand e3 nonstative.
(As well, a causal relation can betentatively inferred.)
The results of de-indexicalizationthus seem to be in complete accord with intuition.Besides the above rules, our current theory includesrules for conjunction, negation, quantification, and someadverbials and nominalizations.
However, space limita-tions prevent inclusion of any details.
Untensed conjunc-tions, negation and quantification i troduce pisodes for?
the clauses they operate on, explaining phenomenon likeillustrated in (3) and (4).
Adverbs and PP-adverbials oftemporal location, duration, and manner are treated in auniform way that de-indexicalizes them into predicationsabout episodes.
However, we make no attempt as yet to40interpret anaphoric NPs in those PPs (such as the NPin before ?he war).
Also, relative clauses and clausal ad-verbials remain largely beyond the scope of our presentwork.V.
Conclus ions and Further WorkWe have described a new, principled approach to tenseand aspect interpretation within a compositional frame-work for language understanding.
The central conceptis that of a tense tree structure as part of a more gen-eral context structure.
This provides a straightforwardand easily visualized way of converting originally index-ical LFs to representations of the meaning of an utter-ance which are context-independent at least as far as theepisodic relations implicit in the tense-aspect s ructureare concerned.
This includes the most common "orient-ing" relations between episodes, and some of the moresubtle relations conveyed by perfective aspect.Our Common Lisp implementation of the de-indexicalization process allows rules to be straightfor-wardly represented and easily edited; example sentencesof the type in this paper (modulo simplification of someof the adverbials) run in roughly a tenth of a second ona Sun SPARCstation 1.Future work will focus on extension of the rules so as tocover more types of adverbials (especially clausal ones),tenseless VPs and clauses (some of which we already han-dle, such as action nominalizations like "To have lovedand lost is not unusual"), and relative clause.
A prelimi-nary look at some of these phenomena, especially clausaladverbials and relative clauses, suggests that an opera-tion on pairs of trees may be required, something onemight call a "two-point overlay" Ti:T2, where the rootnode of T1 and another node of T1 are aligned with twonodes of T2, creating orienting relationships between cer-tain episodes tored at the aligned nodes.
In any case,the potential of our approach as certainly not been ex-hausted.AcknowledgementsWe are grateful for some interesting suggestions fromBob Wilensky concerning the semantics of perfect, whichcaused us to modify our rules.
The research wassupported by NSERC Operating Grant A8818 (LKS),an Izaak W. Kil lam Memorial Scholarship (CHH), theBoeing Co. under Purchase Contract W-288104, andONR/DARPA research contract no.
N00014-82-K-0193.References\[1\] Allen, J. Natural\[2\]\[3\]Language Understanding.
Ben-jamin/Cummings Publ.
Co., Reading, Mass., 1987.Barwise, J.
The Situation in Logic.
CSLI: Stanford, CA,1989.Davidson, D. "The logical form of action sentences."
InD.
Davidson and G. Harman, eds., The Logic of Gram-mar, 235-245, Dickenson, Encino, CA, 1975.\[4\] Dowty, D. "Tense, time adverbs and compositional se-mantic theory."
Ling.
and Phil., 5:23-55, 1982.\[5\] Harman, G. "Logical form."
In D. Davidson and G. Har-man, eds., The Logic of Grammar, 289-307, Dickenson,Encino, CA, 1975.\[6\] Hinrichs, E. W.. "Tense, quantifiers, and contexts."Comput.
Ling., 14(2):3-14, 1988.\[7\] Hobbs, J. R., "Coherence and coreference', Cog.
Sci.,3(1):67-82, 1979.\[8\] Leech, G. Meaning and the English Verb (2nd edition),Longman, London, 1987.\[9\] McCawley, J.D., "Notes on the English present perfect",Australian J. of Ling., 1:81-90, 1981.\[10\] Moens, M. and Steedman, M. "Temporal ontology andtemporal reference."
Comput.
Ling., 14(2):15-28, 1988.\[11\] Passonneau, R.J., "A computational model of the se-mantics of tense and aspect."
Comput.
Ling.
14(2):44-60, 1988.\[12\] Partee, B., "Some structural analogies between tensesand pronouns in English."
J. of Phil., 70: 601-609, 1973.\[13\] Reichenbach, H. Elements of Symbolic Logic.
Macmillan,New York, NY, 1947.\[14\] Richards, B., "Tenses, temporal quantifiers and seman-tic innocence", in E. LePore (ed.
), New Directions inSemantics, 337-384, Academic Press, New York, NY,1987.\[15\] Schubert, L. K. and Hwang, C. H. "An episodic knowl-edge representation for narrative texts."
In 1st Inter.Conf.
on Principles of Knowledge Representation andReasoning (KR89), 444-458, Toronto, Canada, May 15-18, 1989.\[16\] Schubert, L. K. and Hwang, C. H. "An episodic knowl-edge representation for narrative texts."
TR 345, U. ofRochester, Rochester, NY, May 1990.\[17\] Schubert, L. K. and Pelletier, F. J.
"From English tologic: context free computation of 'conventional' logi-cal translations."
American J. of Comp.
Ling., 8:26-44,1982.
Also in Readings in Natural Language Processing,B.
Grosz, K. Jones and B. Webber, eds., 293-311, Mor-gan Kaufman, Los Altos, CA, 1986.\[18\] Schubert, L. K. and Pelletier, F. J.
"Generically speak-ing, or, using discourse representation theory to in-terpret generics."
In G. Chierchia, B. Partee, andR.
Turner, editors, Property Theory, Type Theory, andSemantics, V.2: Semantic Issues, 193-268.
Kluwer Aca-demic Publ., Boston, MA, 1989.\[19\] Webber, B. L. "Tense as discourse anaphor."
Comput.Ling., 14(2):61-73, 1988.41
