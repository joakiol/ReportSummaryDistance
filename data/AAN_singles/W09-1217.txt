Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 109?113,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA Joint Syntactic and Semantic Dependency Parsing System based onMaximum Entropy ModelsBuzhou Tang1 Lu Li2 Xinxin Li1 Xuan Wang2 Xiaolong Wang2Shenzhen Graduate SchoolHarbin Institute of TechnologyShenzhen,518055, China1{tangbuzhou,lixxin2}@gmail.com2{lli,wangxuan,wangxl}@insun.hit.edu.cnAbstractA joint syntactic and semantic dependencyparsing system submitted to the CoNLL-2009shared task is presented in this paper.
Thesystem is composed of three components: asyntactic dependency parser, a predicate clas-sifier and a semantic parser.
The first-orderMSTParser is used as our syntactic depen-dency pasrser.
Projective and non-projectiveMSTParsers are compared with each other onseven languages.
Predicate classification andsemantic parsing are both recognized as clas-sification problem, and the Maximum EntropyModels are used for them in our system.
Forsemantic parsing and predicate classifying, wefocus on finding optimized features on multi-ple languages.
The average Macro F1 Scoreof our system is 73.97 for joint task in closedchallenge.1 IntroductionThe task for CoNLL-2009 is an extension of theCoNLL-2008 shared task to multiple languages: En-glish (Surdeanu et al, 2008), Catalan plus Span-ish (Mariona Taule?
et al, 2008), Chinese (MarthaPalmer et al, 2009), Czech (Jan Hajic?
et al,2006), German (Aljoscha Burchardt et al, 2006) andJapanese (Daisuke Kawahara et al, 2002).
Com-pared to the CoNLL-2008 shared task, the predi-cates are given for us in semantic dependencies task.Therefore, we have only need to label the semanticroles of nouns and verbs, and the frames of predi-cates.In this paper, a joint syntactic and semantic de-pendency parsing system submitted to the CoNLL-2009 shared task is presented.
The system is com-posed of three components: a syntactic dependencyparser, a predicate classifier and a semantic parser.The first-order MSTParser is used as our syntacticdependency parser.
Projective and non-projectiveMSTParsers are compared with each other on sevenlanguages.
The predicate classifier labeling theframes of predicates and the semantic parser label-ing the semantic roles of nouns and verbs for eachpredicate are both recognized as classification prob-lem, and the Maximum Entropy Models (MEs) areused for them in our system.
Among three com-ponents, we mainly focus on the predicate classifierand the semantic parser.For semantic parsing and predicate classifying,features of different types are selected to our sys-tem.
The effect of them on multiple languages willbe described in the following sections in detail.2 System DescriptionGenerally Speaking, a syntactic and semantic de-pendency parsing system is usually divided into fourseparate subtasks: syntactic parsing, predicate iden-tification, predicate classification, and semantic rolelabeling.
In the CoNLL-2009 shared task, the pred-icate identification is not required, since the pred-icates are given for us.
Therefore, the system wepresent is only composed of three components: asyntactic dependency parser, a predicate classifierand a semantic parser.
The syntactic dependenciesare processed with the MSTParser 0.4.3b.
The pred-icates identification and semantic role label are pro-cessed with MEs-based classifier respectively.
Un-like conventional systems, the predicates identifica-109tion and the semantic parser are independent witheach other.
Figure 1 is the architecture of our sys-tem.Figure 1: System ArchitectureIn our system, we firstly select an appropriatemode (projective or non-projective) of Graph-basedParser (MSTParser) for each language, then con-struct the MEs-based predicates classification andthe MEs-based semantic parser with syntactic de-pendency relationships and predicate classificationrespectively.2.1 Syntactic Dependency ParsingMSTParser (McDonald, 2008) is used as our syn-tactic dependency parser.
It is a state-of-the-art de-pendency parser that searches for maximum span-ning trees (MST) over directed graph.
Both of pro-jective and non-projective are supported by MST-Parser.
Our system employs the first-order frame-work with projective and non-projective modes onseven given languages.2.2 Predicate ClassificationIn this phase, we label the sense of each predicateand the MEs are adopted for classification.
Featuresof different types are extracted for each predicate,and an optimized combination of them is adopted inour final system.
Table 1 lists all features.
1-20 arethe features used in Li?s system (Lu Li et al, 2008),No Features No Features1 w0 20 Lemma2 p0 21 DEPREL3 p?1 22 CHD POS4 p1 23 CHD POS U5 p?1p0 24 CHD REL6 p0p1 25 CHD REL U7 p?2p0 26 SIB REL8 p0p2 27 SIB REL U9 p?3p0 28 SIB POS10 p0p3 29 SIB POS U11 p?1p0p1 30 VERB V12 w0p0 31 4+1113 w0p?1p0 32 Indegree14 w0p0p1 33 Outdegree15 w0p?2p0 34 Degree16 w0p0p2 35 ARG IN17 w0p?3p0 36 ARG OUT18 w0p0p3 37 ARG Degree19 w0p?1p0p1 38 SpanTable 1: Features for Predicate Classification.and 21-31 are a part of the optimized features pre-sented in Che?s system (Wanxiang Che et al, 2008)In Table 1, ?w?
denotes the word and ?p?
de-notes POS of the words.
Features in the form ofpart1 part2 denote the part2 of the part1, while fea-tures in the form of part1+part2 denote the combi-nation of the part1 and part2.
?CHD?
and ?SIB?
de-note a sequence of the child and the sibling wordsrespectively, ?REL?
denotes the type of relations,?U?
denotes the result after reducing the adjacentduplicate tags to one, ?V?
denotes whether the partis a voice, ?In?
and ?OUT?
denote the in degree andout degree, which denotes how many dependencyrelations coming into this word and going away fromthis word,and ?ARG?
denotes the semantic roles ofthe predicate.
The ?Span?
denotes the maximumlength between the predicate and its arguments.
Thefinal optimized feature combination is :1-31 and 33-37.2.3 Semantic Role LabelingThe semantic role labeling usually contains two sub-tasks: argument identification and argument classi-fication.
In our system, we perform them in a single110stage through one classifier, which specifies a par-ticular role label to the argument candidates directlyand assigns ?NONE?
label to the argument candi-dates with no role.
MEs are also adopted for classifi-cation.
For each word in a sentence, MEs gives eachcandidate label (including semantic role labels andnone label) a probability for the predicate.
The fea-tures except for the feature (lemma plus sense num-ber of the predicate in (Lu Li et al, 2008)) and thefeatures 32-38 in Table 1 are selected in our system.3 Experiments and ResultsWe train the first-order MSTParser 1 with projectiveand non-projective modes in terms of default param-eters respectively.
Our maximum entropy classifiersare implemented with the Maximum Entropy Mod-eling Toolkit 2 .
The default classifier parameters areused in our system except for iterations.
All mod-els are trained using all training data, and tested onthe whole development data and test data, with 64-bit 3.00GHz Intel(R) Pentium(R) D CPU and 4.0Gmemory.3.1 Syntactic Dependency ParsingTable 2 is a performance comparison between pro-jective parser and non-projective parser on the devel-opment data of seven languages.
In Table 2, ?LAS?,?ULAS?
and ?LCS?
denote as Labeled attachmentscore, Unlabeled attachment score and Label accu-racy score respectively.The experiments show that Catalan, Chinese andSpanish have projective property and others havenon-projective property.3.2 Predicate ClassificationTo get the optimized system, three group features areused for comparison.?
group 1: features 1-20 in Table 1.?
group 2: features 1-31 in Table 1.?
group 3: all features in Table 1.The performance of predicate classification on thedevelopment data of the six languages, which con-tain this subtask, are given in Table 3.
The results1http://sourceforge.net/projects/mstparser.2http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.LAS(%) ULAS(%) LCS(%)Catalan 84.18 88.18 91.7683.69 87.74 91.59Chinese 72.58 77.06 82.0762.85 69.47 73.00Czech 72.79 81.40 80.9373.18 81.86 81.30English 86.89 90.29 91.5086.88 90.34 91.58German 83.43 86.89 90.2484.00 87.40 90.61Japanese 92.23 93.16 98.3892.23 93.14 98.45Spanish 83.88 87.93 91.3683.46 87.46 91.37Table 2: Performance of Syntactic DependencyParsing with different modes.
The above line is theperformance of projective mode, while the belowone is the performance of non-projective mode foreach language.group 1 group 2 group 3Catalan 75.51 80.90 82.23Chinese 93.79 94.99 94.75Czech 91.83 91.77 91.86English 92.12 92.48 93.20German 74.49 74.14 75.85Spanish 74.01 76.22 76.53Table 3: Performance of predicate classification (F1scores) for different group features on the develop-ment data of the six languages.show that Che?s features and the degrees of the pred-icate and its arguments are useful for all languages,the former improves the labeled F1 measure by 0.3%to 5.4%, and the latter by 0.3% to 1.7%.3.3 Semantic Role LabelingIn this phase, feature selection and performance losecaused by P-columns are studied.
Firstly, we com-pare the following two group features:?
group 1: The features except for the lemmaplus sense number of the predicate in (Lu Liet al, 2008).111LF1 ULF1 PF1Catalan 73.25 92.69 38.4172.71 91.93 35.2283.23 100.00 61.88Chinese 69.60 82.15 28.3571.49 81.71 29.4185.44 95.21 58.20Czech 80.62 92.49 70.0479.10 91.44 68.3485.42 96.93 77.78English 73.91 87.26 33.1676.10 88.58 36.2879.35 91.74 43.32German 64.85 88.05 27.2165.36 88.63 26.7072.78 94.54 41.50Japanese 69.43 82.79 29.2769.87 83.31 29.6972.80 87.13 34.96Spanish 73.49 93.15 39.6478.18 91.68 33.5781.96 99.98 59.20Table 4: Performance of Semantic Role Labeling(F1 score) with different features.?
group 2: group1+the degrees of the predicateand its arguments presented in the last section.Secondly, features extracted from golden-columnsand P-columns are both used for testing.The performance of them are given in Table 4,where ?LF1?, ?ULF1?
and ?PF1?
denote as LabeledF1 score, Unlabeled F1 score and Proposition F1score respectively.
The above line is the F1 scores ofSemantic Role Labeling with different features.
Theuppermost line is the result of group1 features, themiddle line is the result of group2 features extractedfrom P-columns, and the downmost one is the resultof group2 features extracted from golden-columnsfor each language.The results show that the features of degree alsoimproves the labeled F1 measure by 3.4% to 15.8%,the different labeled F1 between golden-columnsand P-columns is about 2.9%?13.9%.LAS LF1 M LF1Catalan 84.18 72.71 81.4675.68 66.95 71.32Chinese 72.58 71.49 72.2063.95 67.06 65.53Czech 73.18 79.10 76.3772.60 79.08 75.85Czech-ood 69.81 79.80 74.81English 86.88 76.10 82.8986.61 77.17 81.92English-ood 80.09 67.21 73.69German 84.00 65.36 83.0679.85 61.98 70.93German-ood 71.86 61.83 66.86Japanese 92.23 69.87 83.7791.26 69.58 80.49Spanish 83.88 71.18 80.7477.21 66.23 71.72Table 5: Overall performance of our final joint sys-tem.3.4 Overall PerformanceIn the final system, we select the optimized featuresubset discussed in the former sections.
The overallperformance of the system on the development data ,test data and Out-of-domain data are shown in Table5 (all features are extracted from P-columns).
Theaverage Macro F1 Scores of our system are 73.97on test data and 71.79 on Out-of-domain data.In Table 5, ?LAS?, ?LF1?
and ?M LF1?
denoteas Labeled accuracy score for Syntactic DependencyParsing, Labeled F1 score for Semantic Role Label-ing, and Overall Macro Labeled F1 score respec-tively.
The topmost line is the result on the devel-opment data, the middle one is the result on the testdata for each language and the downmost one is theresult on the Out-of-domain data if the data exist.4 Conclusion and DiscussionWe present a joint syntactic and semantic depen-dency parsing system for CoNLL2009 Shared Task,which composed of three components: a syntac-tic dependency parser, a predicate classifier and asemantic parser.
All of them are built with somestate-of-the-art methods.
For the predicate classifierand the semantic parser, a new kind of features?112degrees, which reflect the activeness of the wordsin a sentence improves their performance.
In orderto improve the performance further, we will studynew machine learning methods for semantic depen-dency parsing, especially the joint learning methods,which can avoid the information loss problem of oursystem.AcknowledgmentsWe would like to thank McDonald for providingthe MSTParser program, to Zhang Le for provid-ing the Maxent program.
This research has beenpartially supported by the National Natural ScienceFoundation of China(No.60703015) and the Na-tional 863 Program of China (No.2006AA01Z197,No.2007AA01Z194).ReferencesJan Hajic?
and Massimiliano Ciaramita and Richard Jo-hansson and Daisuke Kawahara and Maria Anto`niaMart??
and Llu?
?s Ma`rquez and Adam Meyers andJoakim Nivre and Sebastian Pado?
and Jan S?te?pa?nekand Pavel Stran?a?k and Miahi Surdeanu and NianwenXue and Yi Zhang.
2009.
The CoNLL-2009 SharedTask: Syntactic and Semantic Dependencies in Multi-ple Languages.
Proceedings of the 13th Conference onComputational Natural Language Learning (CoNLL-2009), June 4-5.
Boulder, Colorado, USA.Mariona Taule?
and Maria Anto`nia Mart??
and Marta Re-casens.
2008.
AnCora: Multilevel Annotated Cor-pora for Catalan and Spanish.
Proceedings of the 6thInternational Conference on Language Resources andEvaluation (LREC-2008).
Marrakesh, Morroco.Martha Palmer and Nianwen Xue.
2009.
Adding seman-tic roles to the Chinese Treebank.
Natural LanguageEngineering, 15(1),pages 143?172.Jan Hajic?
and Jarmila Panevova?
and Eva Hajic?ova?
andPetr Sgall and Petr Pajas and Jan S?te?pa?nek and Jir??
?Havelka and Marie Mikulova?
and Zdene?k Z?abokrtsky?.2006.
Prague Dependency Treebank 2.0.
CD-ROM,Cat.
No.
LDC2006T01, ISBN 1-58563-370-4.
Lin-guistic Data Consortium, Philadelphia, Pennsylvania,USA.
URL: http://ldc.upenn.edu.Surdeanu, Mihai and Johansson, Richard and Meyers,Adam and Ma`rquez, Llu?
?s and Nivre, Joakim.
2008.The CoNLL-2008 Shared Task on Joint Parsing ofSyntactic and Semantic Dependencies.
Proceedings ofthe 12th Conference on Computational Natural Lan-guage Learning(CoNLL-2008).Aljoscha Burchardt and Katrin Erk and Anette Frank andAndrea Kowalski and Sebastian Pado?
and ManfredPinkal.
2006.
The SALSA corpus: a German corpusresource for lexical semantics.
Proceedings of the 5rdInternational Conference on Language Resources andEvaluation (LREC-2006), pages 2008?2013.
Genoa,Italy.Daisuke Kawahara and Sadao Kurohashi and Ko?itiHasida.
2002.
Construction of a Japanese Relevance-tagged Corpus.
Proceedings of the 3rd InternationalConference on Language Resources and Evaluation(LREC-2002), pages 2008?2013.
Las Palmas, CanaryIslands.McDonald and Ryan.
2006.
Discriminative Learningand Spanning Tree Algorithms for Dependency Pars-ing, Ph.D. thesis.
University of Pennsylvania.Lu Li, Shixi Fan, Xuan Wang, XiaolongWang.
2008.Discriminative Learning of Syntactic and SemanticDependencies.
CoNLL 2008: Proceedings of the12th Conference on Computational Natural LanguageLearning, pages 218?222.
Manchester.Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang Li,Bing Qin, Ting Liu, Sheng Li.
2008.
A CascadedSyntactic and Semantic Dependency Parsing System.CoNLL 2008: Proceedings of the 12th Conferenceon Computational Natural Language Learning, pages238?242.
Manchester.113
