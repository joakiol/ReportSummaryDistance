Cluster Stopping Rules for Word Sense DiscriminationGuergana Savova, Terry Therneau and Christopher Chute,Mayo Clinic, Rochester, MN, USA[Savova.Guergana;therneau;chute]@mayo.eduAbstractAs text data becomes plentiful, unsuper-vised methods for Word Sense Disam-biguation (WSD) become more viable.
Aproblem encountered in applying WSDmethods is finding the exact number ofsenses an ambiguity has in a training cor-pus collected in an automated manner.That number is not known a priori; ratherit needs to be determined based on thedata itself.
We address that problem us-ing cluster stopping methods.
Such tech-niques have not previously applied toWSD.
We implement the methods ofCalinski and Harabasz (1975) and Harti-gan (1975) and our adaptation of the Gapstatistic (Tibshirani, Walter and Hastie,2001).
For evaluation, we use the WSDTest Set from the National Library ofMedicine, whose sense inventory is theUnified Medical Language System.
Thebest accuracy for selecting the correctnumber of clusters is 0.60 with the C&Hmethod.
Our error analysis shows that thecluster stopping methods make finer-grained sense distinctions by creating ad-ditional clusters.
The highest F-scores(82.89), indicative of the quality of clus-ter membership assignment, are compa-rable to the baseline majority sense(82.63) and point to a path towards accu-racy improvement via additional clusterpruning.
The importance and significanceof the current work is in applying clusterstopping rules to WSD.1 IntroductionThe dominant approach in word sense disam-biguation (WSD) is based on supervised learningfrom manually sense-tagged text.
While this iseffective, it is quite difficult to get a sufficientnumber of manually sense-tagged examples totrain a system.
Mihalcea (2003) estimates that80-person years of annotation would be neededto create training corpora for 20,000 ambiguousEnglish words, given 500 instances per word.For that reason, we are developing unsupervisedknowledge-lean methods that avoid the bottle-necks created by sense-tagged text.
Unsupervisedclustering methods utilize only raw corpora astheir source of information, and there are grow-ing amounts of general and specialized domaincorpora available, e.g.
biomedical domain cor-pora.Improvements in WSD methods would be ofimmediate value in indexing and retrievals ofbiomedical text given the explosion of biomedi-cal literature as well as the rapid deployment ofelectronic medical records.
Semantic/conceptualindexing and retrieval in that domain is oftendone in regard to the Unified Medical LanguageSystem (UMLS) developed at the National Li-brary of Medicine (NLM) at the United StatesNational Institutes of Health (NIH)1.
It is impor-tant to understand that the UMLS is significantlydifferent than a dictionary, which is often thesource of the sense inventory.
Rather, the UMLSintegrates more than 100 medical domain con-trolled vocabularies such as SNOMED-CT2 andthe International Classification of Diseases(ICD)3.
UMLS has three main components.
Thefirst component, the Metathesaurus, includes allterms from the controlled vocabularies and isorganized by concept, which is a cluster of termsrepresenting the same meaning.
Each concept isassigned a concept unique identifier (CUI),which is inherited by each term in the cluster.UMLS-based semantic indexing is based on CUIassignments.
The second component, the Seman-tic Network, groups the concepts into 134 typesof categories and indicates the relationships be-tween them.
The Semantic Network is a coarseontology of the concepts.
The third component,the SPECIALIST lexicon, contains syntactic in-formation for the Metathesaurus terms.1 http://www.nlm.nih.gov/pubs/factsheets/umls.html2 http://www.snomed.org/3 http://www.who.int/classifications/help/icdfaq/en/9MeSH, an ontology within UMLS, is heavilyused for indexing biomedical scientific publica-tions, e.g.
Medline4.
Hospitals, medical practicesand biomedical research increasingly rely on theUMLS, or a subset ontology within it, to indexand retrieve relevant information.
It is estimatedthat approximately 7400 UMLS terms map tomultiple concepts which creates ambiguity(Weeber, Mork and Aronson., 2001).
Term am-biguity has been pointed out to be one of the ma-jor challenges for UMLS-based semantic index-ing and retrieval (Weeber et al, 2001).
For ex-ample, ?cold?
has the following six UMLSmeanings, each with its own UMLS CUI: coldtemperature, common cold, cold sensation, coldtherapy, chronic obstructive lung disease(COLD), and Cold brand of chlorpheniramine-phenylpropanolamine.The problem we are addressing in this paper isdiscovering the number of senses an ambiguousword has in a given corpus, which is a compo-nent within a completely unsupervised WSD sys-tem.
For example, if a corpus of 1000 instancescontaining the word ?cold?
has been compiledfrom patients medical records, how many ?cold?senses are in that corpus?
This is a challenge anyNLP system implementing WSD faces.
To ad-dress this problem, we apply cluster stoppingrules in an automated way.The paper is organized as follows.
Section 2overviews the related work on cluster stoppingrules.
Section 3 outlines our methods, tools, fea-tures selection, test set and evaluation metrics.Section 4 presents the results and discusses them.Section 5 is the conclusions.2 Background and Related WorkOur work is based on cluster analysis.
Clusteranalysis is often performed to discover thegroups that the data naturally fall into.
The num-ber of groups is not known a priori; rather, itneeds to be determined based on the data itself.Such methods or ?cluster stopping rules?
usuallyrely on within-cluster dissimilarity/error (W(k))metrics which in general exhibit a decline whenthe number of clusters increases.
Splitting a natu-ral group into subgroups reduces the criterionless than when well-separated clusters are dis-covered.
In those cases, the W(k) will not have asharp decline as the instances are close.
Thisphenomenon has been described in statisticalliterature as the ?elbow?
effect as illustrated in4 http://www.nlm.nih.gov/pubs/factsheets/medline.htmlFigure 1.
Methods for locating the ?elbow havebeen the goal of many research studies (Hartigan,1975; Calinski and Harabasz, 1975; Milligan andCooper, 1987; Tibshirani, Walter and Hastie,2001 among many).Milligan and Cooper (1985) offer the mostcomprehensive comparative study of the per-formance of 30 stopping rules.
They carry outtheir study on ?mildly truncated data from multi-variate normal distributions, and one would notexpect their ranking of the set of stopping rulesto be reproduced exactly if a different cluster-generating strategy were adopted.?
(Gordon,1999, p. 61).
The five rules which were the topperformance in the Milligan and Cooper studyare Calinski and Harabasz (1974) a.k.a.
C&H,Goodman and Kruskal (1954), C index (Hubertand Schultz, 1976), Duda and Hart (1973) andBeale (1969).
Tibshirani et al (2001) introducethe Gap statistic and compare its performance tothe methods of Calinski and Harabasz (1974),Krzanowski and Lai (1985), Hartigan (1975),and the Silhouette method (Kaufman andRousseeuw, 1990).
On the simulated and DNAmicroarray data Tibshirani and colleagues usedfor their experiments, the Gap statistic yields thebest result.In general, stopping rules fall into two catego-ries ?
global and local (Gordon, 1999; Tibshiraniet al, 2001).
Global rules take into account acombination of within-cluster and between-cluster similarity measures over the entire data.Global rules choose such k where that combinedmetric is optimal.
Global rules, however, in mostcases do not work for k=1, that is they do notmake predictions of when the data should not bepartitioned at all.
Global rules look at the entiredata over k number of clusters.
Local rules, onthe other hand, are based only on a given k solu-tion or individual pairs of clusters and testwhether they should be grouped together.
Theyneed a threshold value or a significance level,which depends on the specific data and in mostcases have to be empirically determined.3 Methodology3.1 OverviewIn this study, we explore three cluster stoppingmethods as applied to unsupervised WSD ?
Har-tigan (1975), Calinski and Harabasz (1974), andthe Gap statistic (Tibshirani et al, 2001).
Thedata to be clustered is instances of context sur-rounding each ambiguity.
Each instance is con-verted into a feature vector where the features are10ngrams (unigrams or bigrams) and each cell isthe frequency of occurrence of a unigram or bi-gram or the log-likelihood of a bigram occurringin that particular instance after applying a featureselection method.
The clustering algorithm forthis set of experiments is agglomerative cluster-ing (see Section 3.5 for a more detailed descrip-tion).Our goal is to group contexts into separateclusters based on the underlying sense of the am-biguous word.
Thus, the observations are con-texts and the features are the identified lexicalfeatures (i.e.
significant word(s)) that representthe contexts.
Our observed data matrix generallyshows the following characteristics ?1) it is discrete2) it is high dimensional/multivariate3) it can be real valued or integer, or binary4) it is sparse; while the number of featurescan be in few hundreds, contexts have a lengthlimit (ignoring the commonly occurring ?closedclass words?
like ?the?, ?an?, ?on?
etc.
)5) it represents a distribution of contexts thatis generally skewed.Following is our motivation for choosing thethree cluster stopping rules.
Hartigan (1975) andCalinski and Harabasz (1974) have been consis-tently used as baselines in a number of studies,e.g.
Tibshirani et al (2001).
The Hartiganmethod is computationally simple and efficientand unlike C&H, it is defined for k=1.
The C&Hmethod was ranked the top among 30 stoppingrules in the comprehensive study conducted byMilligan and Cooper (1975).
The Gap statistic(Tibshirani et al, 2001) is a fairly recent methodthat has gained popularity by showing excellentresults when applied to the bio domain, e.g.
clus-tering DNA mircoarray data.
None of the meth-ods, however, have been applied or adapted toWSD.3.2 Calinski and Harabasz (1975) MethodThe C&H method is reported to perform the bestamong 30 stopping rules (Milligan and Cooper,1985).
C&H is a global method.
The VarianceRatio Criteria C&H uses isknkWGSSkkBGSSkVRC )(1)()(where BGSS (between group sum of squares) isthe sum of the dispersions between the k clustercentroids and the general centroid; WGSS(within-group sum of squares) is the sum of eachcluster?s dispersion of its cluster members(measured by the sum of squared distances be-tween each member and the cluster centroid)weighed by the number of cluster members; k isthe number of clusters and n is the number ofinstances.
The distance used is the Euclidean dis-tance.
As Calinski and Harabasz point out, VRC?is analogous to the F-statistic in univariateanalysis?
(Calinski and Harabasz, 1975, p. 10).C&H seeks to maximize VRC.3.3 Hartigan (1975) MethodHartigan (1975) proposes a cluster stopping rule:)1(1)1()()( ??????
 knkWGSSkWGSSkHwhere n is the total number of instances to beclustered, k is the number of clusters andWGSS(k) is the total sum of squared distances ofcluster members from their cluster centroid in allclusters when clustered in k clusters.H(k) is used to decide when k+1 clusters areneeded rather than k clusters.
Its distribution ap-proximates the F distribution.
A large value ofH(k) would indicate that the addition of a clusteris warranted.
Hartigan suggests that as a cruderule of thumb, values exceeding 10 justify in-creasing the number of clusters from k to k+1(Hartigan, 1975, p. 91).
Thus, a solution is thesmallest k ?
1 such that H(k) ?
10.
The methodcan return 1 cluster as the optimal solution.
Har-tigan (1975) is a local method.3.4 Gap Statistic MethodIn general, the ?gap?
method compares the dif-ference/gap between the within-cluster disper-sion measure for the observed distribution andthat for an appropriate null distribution of thedata.
Tibshirani and colleagues (Tibshirani et al,2001) start with the assumption of a single clus-ter null model which is to be rejected in favor ofa k-component model (k>1) if the observed datasupports it.
Tibshirani and colleagues use a uni-form distribution as the null distribution of thedata to standardize the comparison between allthe W(k) over the various values of k where W(k)is the pooled within cluster sum of squaresaround the cluster means (distance is squaredEuclidean distance).
The uniform distribution isthe least favorable distribution and the mostlikely to produce spurious clusters.
However,11Tibshirani and colleagues also point out that thechoice of an appropriate null distribution de-pends on the data.
Tibshirani and colleaguescompare the curve of log(W(k)) to the log(W*(k))curve obtained from the reference uniformly dis-tributed over the data.
The estimated optimalnumber of clusters is the k value where the gapbetween the two curves is the largest.
Figure 1 isan example of log(W(k)) to the log(W*(k)) curvesused in the computation of the Gap statistic.The two main advantages of the Gap statisticover various previously proposed ?stoppingrules?
are its ability to work with data created byalmost any type of clustering and its ability toaccurately estimate the optimal number of clus-ters even for data that naturally falls into just onecluster.
The Gap statistic is an application of pa-rametric bootstrap methods to the clusteringproblem.
Unlike non-parametric methods, para-metric techniques represent the observed datadistribution.
The basic strategy is to create multi-ple random data sets over the observed distribu-tion for which there are no clusters, apply thechosen clustering method to them, and tabulatethe apparent decrease in within-cluster variationthat ensues.
This gives a measure of optimismwith which to compare the clustering of the ob-served data.The complete methodology can be broadlyclassified into two important components namelythe reference distribution and the algorithmwhich uses the reference distribution.
We de-scribe each of the two components below.Figure 1: The functions log(W(k)) (observed)and log(W*(k)) (reference) used for computingthe Gap statisticReference Distribution Generation for anNLP TaskHere, we describe how we extend the generationof the reference distribution over the observeddata to retain the characteristics mentioned at endof section 3.1.
We will use the observed datashown in Table 1 as a running example.
To simu-late the structure of the observed data, the fol-lowing features are to be emulated:(a) Context length is the number of featuresthat can occur in a context.
Contexts can be sen-tences, paragraphs, entire documents or just anyspecified window size.
In general, the number ofavailable features will be at least in the hundreds,however, only a few might occur in a given con-text, especially if the context is limited to thesentence the target ambiguity occurs in.
Addi-tionally, context length is influenced by the fea-ture selection method ?
if only very frequentlexical units are retained as features, then onlythose units will represent the context.
Thus, acontext length could be very small compared tothe size of the feature set.
In the example fromTable 1, context length is captured by the rowmarginals, e.g.
the context length for Context1 is3, which means that overall there are only threefeatures for that context.
(b) Sparsity is a consequence of relativelysmall context length.
Currently, our assumptionis that contexts are derived from small discourseunits (sentences or abstracts at the most).
Forbigger discourse units, e.g.
several paragraphs orentire documents, our proposed generation of thereference distribution should be modified to re-flect feature occurrences over those units.
In theexample from Table 1, for instance in Context1,there are 3 features that are present ?
Feature1,Feature4 and Feature5 ?
the rest are absent.Sparsity can be viewed as the number of ab-sent/zero-valued features for each row.
(c) Feature distribution is the frequency of oc-currence of each feature across all contexts.
It iscaptured by the column marginals of the ob-served data matrix.
For example, in Table 1 Fea-ture1 occurs twice over the entire data; similarlyFeature2 occurs twice and so on.
Feature distri-bution can be viewed as the number of occur-rences of each feature in the entire corpus.Now we describe how we do the referencegeneration to stay faithful to the characteristicsdescribed above.
We use the uniform and theproportional methods.
The uniform method gen-erates data that realizes (a) and (b) characteristicsof the data and is the used originally in Tibshi-rani et al (2001).
The proportional method cap-tures (a), (b), and (c) and is our adaptation of theGap method.The data is constructed as follows.
To retainthe context lengths of the observed data in the12Feature1 Feature2 Feature3 Feature4 Feature5 ?FeatureP Total number ofnon-zero value cellsContext1 1 0 0 1 1 ???
3Context2 0 1 1 0 1 ???
3Context3 1 0 0 0 1 ???
2Context4 0 1 1 1 1 ???
4?ContextN ???
???
???
???
???
???
??
?2 2 2 2 4 ???
12Table 1: Observed data (sample)reference data, the row marginals of the refer-ence data are fixed to be equal to those of theobserved data.
In Table 1, the row marginals forthe reference data will be {3, 3, 2, 4}.
Carryingthe observed marginals to the reference data ap-plies to both the uniform and proportional meth-ods.
Note that currently we fix only the row mar-ginals.
Due to the current assumption of binaryfeature frequency, the generated reference data isbinary too and this is true for both methods.The main difference between the uniformand proportional methods lies in whether the fea-ture distribution is maintained in the simulation.The uniform method does not weigh the features;rather, all features are given equal probability ofoccurring in the generated data.
A uniform ran-dom number r over the range [1, featureSetSize]is drawn.
The cell corresponding to the rth col-umn (i.e.
feature) in the current row under con-sideration (i.e.
context) is assigned ?1?.
For ex-ample, in our running example let?s say we aregenerating reference data for the 3rd row fromTable 1.
We first generate a random number overthe range [1, p].
Let?s assume that the generatednumber is 4.
Then, the cell [3, 4] is assignedvalue ?1?.
This procedure is repeated twice sincethe row marginal for this row of the referencedata is 2.
The proportional method factors in thedistribution of the column marginals of the ob-served data while generating the random data.Unlike the uniform method, it takes into accountthe weight of each feature.
In other words, thefeatures by their frequency assign themselves arange.
For example, the features in the Table 1will be assigned the following ranges: Feature1 -[1, 2]; Feature2 - [3, 4]; Feature3 ?
[5, 6]; Fea-ture4 ?
[7, 8]; Feature5 ?
[9, 12].
A randomnumber is generated over the range [1, totalnumber of feature occurrences].
For the data inTable 1, a random number is generated over therange [1, 12].
The feature corresponding to therange in which the random number falls is as-signed ?1?.
For example, if we are generating thereference for Context3 and the generated randomnumber over the range [1, 12] is 5, then a look-up determines that 5 falls in the range for Fea-ture3.
Hence, the cell in Context3 correspondingto Feature3 is assigned ?1?.
Similar to the uni-form method we would repeat this proceduretwice to achieve the row marginal total of 2.Currently we proceed with the binary refer-ence data created by the procedure describedabove.
Note that this binary reference matrix canbe converted to a strength-of-association matrixby multiplying it with a diagonal matrix that con-tains the strength-of-association scores, e.g.
loglikelihood ratio, Mutual Information, Pointwisemutual information, Chi-squared to name a few.AlgorithmThe complete algorithm of the Gap Statisticswhich the reference distribution is a part of is:1.Cluster the observed data, varying the totalnumber of clusters from k = 1, 2, ?., K, givingwithin dispersion measures W(k), k = 1, 2,?.K.2.Generate B reference datasets using the uni-form or the proportional methods as describedabove, and cluster each one giving within dis-persion measures W*(kb), b = 1, 2, ?
B, k =1, 2,?
K. Compute the estimated Gap statistic:))(log())(*log()/1()( kWkbWBkGapb63.
Let ?BkbWBl ))(*log()/1( , compute the stan-dard deviation2/12]))(*(log()/1[()( lkbWBksdB ?
and defineBksdks /11)()(  .
Finally choose the number ofclusters via)1()1()(_?
t kskGapkGapuchThatsmallestKskThe final step is the criterion for selecting theoptimal k value.
It says to choose the smallest kvalue for which the gap is greater than the gapfor the earlier k value by the significance test of?one standard error?.
The ?one standard error?calculations are modified to account for thesimulation error.
Tibshirani and colleagues alsoadvise to use a multiplier to the s(k) for betterrejection of the null hypothesis.133.5 Tools, Feature Selection and MethodParametersrus strings (Weeber et al, 2001).
Each ambiguityhas 100 manually sense-tagged instances.
Allinstances were randomly chosen from Medlineabstracts.
Each ambiguity instance is providedwith the sentence it occurred in and the Medlineabstract text it was derived from.
The senses forevery ambiguity are the UMLS senses plus a?none of the above?
category which captures allinstances not fitting the available UMLS senses.For feature representation, selection, context rep-resentation and clustering, we used Sense-Clusters0.69 (http://senseclusters.sourceforge.net).
Itoffers a variety of lexical features (ngrams, col-locations, etc.)
and feature selection methods(frequency, log likelihood, etc.).
The contextscan then be represented with those features invector space using first or second order vectorswhich are then clustered.
A detailed descriptioncan be found in Purandare and Pedersen (2004)and http://www.d.umn.edu/~tpederse/senseclusters.html.SenseClusters links to CLUTO for the clusteringpart (http://www-users.cs.umn.edu/~karypis/cluto/download.html).
CLUTO implements in afast and efficient way the main clustering algo-rithms ?
agglomerative, partitional and repeatedbisections.For the current study, we modified the NLMWSD by excluding instances sense-tagged withthe ?none of the above?
category.
This is moti-vated by the fact that that category is a catch-allcategory for all senses that do not fit the currentUMLS inventory.
First, we excluded wordswhose majority category was ?none of theabove?.
Secondly, from the instances of the re-maining words, we removed those marked with?none of the above?.
That subset of the originalNLM WSD set we refer to as the ?modifiedNLM WSD set?
(Table 2).We chose the following methods for featurerepresentation and selection.
Method1 uses bi-grams as features, average link clustering insimilarity space and the abstract as the context toderive the features from.
The method is de-scribed in Purandare and Pedersen (2004).
It isbased on first order context vectors, which repre-sent features that occur in that context.
A similar-ity matrix is clustered using the average link ag-glomerative method.
Purandare and Pedersen(2004) report that this method generally per-formed better where there was a reasonably largeamount of data available (i.e., several thousandcontexts).
The application of that method to thebiomedical domain is described in a technicalreport (Savova, Pedersen, Kulkarni and Puran-dare, 2005).
Method2 uses unigrams which occurat least 5 times in the corpus.
The context is theabstract.
The choice of those features is moti-vated by Joshi, Pedersen and Maclin (2005)study which achieves best results with unigramfeatures.3.7 EvaluationOur evaluation of the performance of the clusterstopping rules is two-fold.
Accuracy is a directevaluation measuring the correctly recognizednumber of senses:words with correctly predicted number of sensesall wordsAccuracy evaluates how well the methods dis-cover the exact number of senses in the test cor-pus.
The F-score of the WSD is an indirectevaluation for the quality of the cluster assign-ment:callecision?callecision)(?scoreFRePr2RePr12_Precision is the number of correctly clusteredinstances divided by the number of clustered in-stances; Recall is the number of correctly clus-tered instances divided by all instances.
Theremay be some number of contexts that the cluster-ing algorithm declines to process, which leads tothe difference in precision and recall.For the Hartigan cluster stopping method, thethreshold is set to 10 which is the recommenda-tion in the original algorithm.
For the Gap clusterstopping method, we experiment with B=100,and the uniform and proportional reference gen-eration methods.
Our baseline is a simple clustering algorithm thatassigns all instances of a target word to a singlecluster.3.6 Test SetOur test set is the NLM WSD5 set which com-prises 5000 disambiguated instances for 50highly frequent ambiguous UMLS Metathesau-4 Results and DiscussionTable 3 presents the results for the three methods5http://wsd.nlm.nih.gov/Restricted/Reviewed_Results/index.shtml14Word, instances, senses after removalof ?none of the above?
senseWord, instances, senses after removalof ?none of the above?
senseWord, instances, senses after re-moval of ?none of the above?
senseAdjustment, 93, 3 Frequency, 94, 1 Radiation, 98, 2Blood pressure, 100, 3 Growth, 100, 2 Repair, 68, 2Cold, 95, 4 Immunosuppression, 100, 2 Scale, 65, 1Condition, 92, 2 Implantation, 98, 2 Secretion, 100, 1Culture, 100, 2 Inhibition, 99, 2 Sex, 100, 3Degree, 65, 2 Japanese, 79, 2 Single, 100, 2Depression, 85, 1 Ganglion, 100, 2 Strains, 93, 2Determination, 79, 1 Glucose, 100, 2 Surgery, 100, 2Discharge, 75, 2 Man, 92, 4 Transient, 100, 2Energy, 100, 2 Mole, 84, 2 Transport, 94, 2Evaluation, 100, 2 Mosaic, 97, 2 Ultrasound, 100, 2Extraction, 87, 2 Nutrition, 89, 4 Variation, 100, 2Fat, 73, 2 Pathology, 99, 2 White, 90, 2Fluid, 100, 1 Pressure, 96, 1Table 2: Modified NLM WSD setIn terms of accuracy (Table 3, column 3), theC&H method has the best results (p<0.01 with t-test).
Note that the modified NLM WSD set con-tains seven words with one sense ?
depression,pressure, determination, fluid, frequency, scale,secretion ?
for which the C&H method is at adisadvantage as it cannot return one cluster solu-tion.In terms of predicted number of senses (Table3, column 5), the Hartigan method tends to un-derestimate the number of senses (overcluster),thus making coarser sense distinctions.
Theadapted Gap and C&H methods tend to overes-timate them (undercluster), thus making finergrained sense distinctions.In terms of cluster member assignment asdemonstrated by the F-scores (Table 3, column4), our adapted Gap method and the Hartiganmethod perform better than the C&H method(p<0.05 with t-test).
The Hartigan method F-scores  along with Gap uniform with Method 1feature selection are not significantly differentfrom the baseline (p>0.05 with t-test); the restare significantly lower than the majority sensebaseline (p<0.05 with t-test).The high F-scores point to a path for improv-ing accuracy results.
Singleton clusters could bepruned as they could be insignificant to sensediscrimination.
As it was pointed out, the bestperforming algorithms (C&H and Gap propor-tional) tend to create too many clusters (Table 3,column 5).
Another way of dealing with single-ton or smaller clusters is to present them for hu-man review as they might represent new sensedistinctions not included in the sense inventory.One explanation for the performance of thestopping rules (overclustering in particular)might be that some senses are very similar, e.g.
?cold temperature?
and ?cold sensation?
for the?cold?
ambiguity in instances like ?Her feet arecold.?
Another explanation is that the stoppingrules rely on the clustering algorithm used.
In ourcurrent study, the experiments were run withonly agglomerative clustering as implemented inCLUTO.
The distance measure that we used isEuclidean distance, which is only one of manychoices.
Yet another explanation is in the featuresets we experimented with.
They performed verysimilarly on both the accuracy and F-scores.
Fu-ture work we plan to do is aimed at experiment-ing with different features, clustering algorithms,distance measures as well as applying SingularValue Decomposition (SVD) to the referencedistribution matrix for our adapted Gap method.We are actively pursuing reference generationwith fixed column and row marginals.
The workof Pedersen, Kayaalp and Bruce (1996) uses thistechnique to find significant lexical relationships.They use the CoCo (Badsberg, 1995) packagewhich implements the Patefield (1981) algorithmfor I x J tables.
Another venue is in the combina-tion of several stopping rules which will takeadvantage of each rule?s strengths.
Yet anothercomponent that needs to be addressed towardsthe path of completely automated WSD is clusterlabeling.5 ConclusionsIn this work, we explored the problem of discov-ering the number of the senses in a given targetambiguity corpus by studying three cluster stop-ping rules.
We implemented the original algo-rithms of Calinski and Harabasz (1975) and Har-tigan (1975) and adapted the reference genera-tion of the Gap algorithm (Tibshirani et al,2001) to our task.
The best accuracy for selectingthe correct number of clusters is 0.60 with the15FeatureSelectionStopping Rule Accuracy F-score(baseline majority sense = 82.63)Average number of senses (trueaverage number of senses = 2.19)Method1 C&H 0.49 80.71 2.90 (overestimates)Hartigan 0.10 82.15 1.27 (underestimates)Gap (uniform) 0.02 82.00 1.49 (underestimates)Gap (proportional) 0.24 81.31 2.51 (overestimates)Method2 C&H 0.60 80.27 3.36 (overestimates)Hartigan 0.02 82.89 1.10 (underestimates)Gap (uniform) 0.05 81.63 2.44 (overestimates)Gap (proportional) 0.12 81.15 2.59 (overestimates)Table 3: Results ?
accuracy, F-score and predicted average number of senseC&H method.
Our error analysis shows that thecluster stopping methods make finer-grainedsense distinctions by creating additional single-ton clusters.
The F-scores, indicative of the qual-ity of cluster membership assignment, are in the80?s and point to a path towards accuracy im-provement via additional cluster pruning.AcknowledgementsThe Perl modules of our implementations of thealgorithms can be downloaded fromhttp://search.cpan.org/dist/Statistics-CalinskiHarabasz/,http://search.cpan.org/dist/Statistics-Hartigan/,http://search.cpan.org/dist/Statistics-Gap/.
We aregreatly indebted to Anagha Kulkarni and TedPedersen for their participation in this research.We would also like to thank Patrick Duffy,James Buntrock and Philip Ogren for their sup-port and collegial feedback, and the Mayo Clinicfor funding the work.ReferencesA.
D. Gordon.
1999.
Classification (Second Edition).Chapman & Hall, LondonA.
Purandare and T. Pedersen.
2004.
Word SenseDiscrimination by Clustering Contexts in Vectorand Similarity Spaces.
Proceedings of the Confer-ence on Computational Natural Language Learning(CoNLL): 41-48, May 6-7, 2004, Boston, MAE.
M.L.
Beale.
1969.
Euclidean cluster analysis.
Bul-letin of the International Statistical Institute:92?94,1969G.
Savova, T. Pedersen, A. Kulkarni and A. Puran-dare.
2005.
Resolving Ambiguities in the Biomedi-cal Domain.
Technical Report.
Minnesota Super-computing Institute.G.
W. Milligan and M.C.
Cooper.
1985.
An examina-tion of procedures for determining the number ofclusters in a data set.
Psychometrika 50:159-179.J.
H. Badsberg.
1995.
An environment for graphicalmodels.
PhD dissertation, Aalborg University.J.
Hartigan.
1975.
Clustering Algorithms, Wiley, NewYork.L.
A. Goodman and W.H.
Kruskal.
1954.
Measures ofassociation for cross classifications.
J. of Amer.Stat.
Assoc., 49:732--764, 1954.L.
Hubert and J. Schultz.
1976.
Quadratic assignmentas a general data-analysis strategy.
British Journalof Mathematical and Statistical Psychologie.29:190-241L.
Kaufman and P. Rowsseeuw.
1990.
Finding groupsin data: an introduction to cluster analysis.
NewYork.
Wiley.M.
Joshi, T. Pedersen and R. Maclin.
2005.
A com-parative study of support vector machines appliedto the supervised word sense disambiguation prob-lem in the medical domain.
IICAI.
India.M.
Weeber, J. Mork and A. Aronson.
2001.
Develop-ing a test collection for biomedical word sense dis-ambiguation.
Proc.
AMIAR.
B. Calinski and J. Harabasz.
1974.
A dendritemethod for cluster analysis.
Communications instatistics 3:1-27.R.
Mihalcea.
2003.
The role of non-ambiguous wordsin natural language disambiguation.
RANLP-2003,Borovetz, BulgariaR.
O. Duda and P. E. Hart.
1973.
Pattern Classifica-tion and Scene Analysis.
Wiley, New York, 1973R.
Tibshirani, G. Walther and T. Hastie.
2001.
Esti-mating the number of clusters in a dataset via theGap statistic.
Journal of the Royal Statistics Soci-ety (Series B).T.
Pedersen, M. Kayaalp and R. Bruce.
1996.
Signifi-cant lexical relationships.
Proc.
of the 13th NationalConference on Artificial Intelligence, August 1996,Portland, Oregon.W.
J. Krzanowski and Y. T. Lai.
1985.
A criterion fordetermining the number of groups in a data set us-ing the sum of squares clustering.
Biometrics44:23-34.W.
Patefield.
1981.
An efficient method of generatingrandom R x C tables with given row and columntotals.
Applied Statistics 30:91-97.16
