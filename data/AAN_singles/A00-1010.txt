TALK'N'TRAVEL: A CONVERSATIONAL SYSTEM FOR AIRTRAVEL PLANNINGDavid StallardBBN Technologies, GTE70 Fawcett St.Cambridge, MA, USA, 02238Stallard@bbn.comAbstractWe describe Talk'n'Travel, a spokendialogue language system for making airtravel plans over the telephone.Talk'n'Travel is a fully conversational,mixed-initiative system that allows theuser to specify the constraints on his travelplan in arbitrary order, ask questions, etc.,in general spoken English.
The systemoperates according to a plan-based agendamechanism, rather than a finite statenetwork, and attempts to negotiate withthe user when not all of his constraints canbe met.IntroductionThis paper describes Talk'n'Travel, a spokenlanguage dialogue system for making complexair travel plans over the telephone.Talk'n'Travel is a research prototype systemsponsored under the DARPA Communicatorprogram (MITRE, 1999).
Some other systemsin the program are Ward and Pellom (1999),Seneff and Polifroni (2000) and Rudnicky et al(1999).
The common task of this program is amixed-initiative dialogue over the telephone, inwhich the user plans a multi-city trip by air,including all flights, hotels, and rental cars, all inconversational English over the telephone.The Communicator common task presentsspecial challenges.
It is a complex task withmany subtasks, including the booking of eachflight, hotel, and car reservation.
Because thenumber of legs of the trip may be arbitrary, thenumber of such subtasks is not known inadvance.
Furthermore, the user has completefreedom to say anything at any time.
Hisutterances can affect just the current subtask, ormultiple subtasks at once ("I want to go fromDenver to Chicago and then to San Diego").
Hecan go back and change the specifications forcompleted subtasks.
And there are importantconstraints, such as temporal relationshipsbetween flights, that must be maintained for thesolution to the whole task to be coherent.In order to meet this challenge, we have soughtto develop dialogue techniques forTalk'n'Travel that go beyond the rigid system-directed style of familiar IVR systems.Talk'n'Travel is instead a mixed initiativesystem that allows the user to specify constraintson his travel plan in arbitrary order.
At anypoint in the dialogue, the user can supplyinformation other than what the system iscurrently prompting for, change his mind aboutinformation he has previously given and evenask questions himself.
The system also tries tobe helpful, eliciting constraints from the userwhen necessary.
Furthermore, if at any point theconstraints the user has specified cannot all bemet, the system steps in and offers a relaxationof them in an attempt o negotiate a partialsolution with the user.The next section gives a brief overview of thesystem.
Relevant components are discussed insubsequent sections.I System OverviewThe system consists of the following modules:speech recognizer, language understander,dialogue manager, state manager, languagegenerator, and speech synthesizer.
The modules68interact with each other via the central hubmodule of the Communicator CommonArchitecture.The speech recognizer is the Byblos system(Nguyen, 1995).
It uses an acoustic modeltrained from the Macrophone telephone corpus,and a bigram/trigram language model trainedfrom -40K utterances derived from varioussources, including data collected under theprevious ATIS program (Dahl et al 1994).The speech synthesizer is Lucent's commercialsystem.
Synthesizer and recognizer bothinterface to the telephone via Dialogicstelephony board.
The database is currently afrozen snapshot of actual flights between 40different US cities (we are currently engaged ininterfacing to a commercial air travel website).The various language components are written inJava.
The complete system runs on WindowsNT, and is compliant with the DARPACommunicator Common architecture.The present paper is concerned with the dialogueand discourse management, language generationand language understanding components.
In theremainder of the paper, we present more detaileddiscussion of these components, beginning withthe language understander in Section 2.
Section3 discusses the discourse and dialoguecomponents, and Section 4, the languagegenerator.2 Language Understanding2.1 Meaning RepresentationSemantic frames have proven useful as ameaning representation for many applications.Their simplicity and useful computationalproperties have often been seen as moreimportant han their limitations in expressivepower, especially in simpler domains.Even in such domains, however, flames stillhave some shortcomings.
While most naturallyrepresenting equalities between slot and filler,flames have a harder time with inequalities, uchas 'the departure time is before 10 AM', or 'theairline is not Delta'.
These require the slot-fillerto be some sort of predicate, interval, or setobject, at a cost to simplicity uniformity.
Otherproblematic ases include n-ary relations ('3miles from Denver'), and disjunctions ofproperties on different slots.In our Talk'n'Travel work, we have developeda meaning representation formalism called pathconstraints, which overcomes these problems,while retaining the computational advantagesthat made frames attractive in the first place.
Apath constraint is an expression of the form :(<path> <relation> <arguments>*)The path is a compositional chain of one or moreattributes, and relations are 1-place or higherpredicates, whose first argument is implicitly thepath.
The relation is followed by zero or moreother arguments.
In the simplest case, pathconstraints can be thought of as flattenings of atree of frames.
The following represents theconstraint that the departure time of the first legof the itinerary is the city Boston :LEGS.0.ORIG_CITY EQ BoSToNBecause this syntax generalizes to any relation,however, the constraint "departing before 10AM" can be represented in a syntacticallyequivalent way:LEGS.0.DEPART_TIME LT 1000Because the number of arguments i arbitrary, itis equally straightforward to represent a one-place property like "x is nonstop" and a threeplace predicate like "x is 10 miles from Denver".Like flames, path constraints have a fixedformat that is indexed in a computationallyuseful way, and are simpler than logical forms.Unlike flames, however, path constraints can becombined in arbitrary conjunctions, disjunctions,and negations, even across different paths.
Pathconstraint meaning representations are also flatlists of constraints rather than trees, makingmatching rules, etc, easier to write for them.692.2 The GEM Understanding SystemLanguage understanding in Talk'n'Travel iscarried out using a system called GEM (forGenerative Extraction Model).
GEM (Miller,1998) is a probabilistic semantic grammar that isan outgrowth of the work on the HUM system(Miller, 1996), but uses hand-specifiedknowledge in addition to probability.
The hand-specified knowledge is quite simple, and isexpressed by a two-level semantic dictionary.
Inthe first level, the entries map alternative wordstrings to a single word class.
For example, thefollowing entry maps several alternative formsto the word class DEPART:Leave, depart, get out of => DEPARTIn the second level, entries map sequences ofword classes to constraints:Name: DepartCity 1Head: DEPARTClasses: \[DEPART FROM CITY\]Meaning: (DEST_CITY EQ <CITY>)The "head" feature allows the entry to pass oneof its constituent word classes up to a higherlevel pattern, allowing the given pattern to be aconstituent of others.The dictionary entries generate a probabilisticrecursive transition network (PRTN), whosespecific structure is determined by dictionaryentries.
Paths through this network correspondone-to-one with parse trees, so that given a path,there is exactly one corresponding tree.
Theprobabilities for the arcs in this network can beestimated from training data using the EM(Expectation-Maximization) procedure.GEM also includes a noise state to whicharbitrary input between patterns can be mapped,making the system quite robust to ill-formedinput.
There is no separate phase for handlingungrammatical input, nor any distinctionbetween grammatical nd ungrammatical input.3 Discourse and Dialogue ProcessingA key feature of the Communicator task is thatthe user can say anything at any time, adding orchanging information at will.
He may add newsubtasks (e.g.
trip legs) or modifying existingones.
A conventional dialogue state networkapproach would be therefore infeasible, as thenetwork would be almost unboundedly arge andcomplex.A signifigant additional problem is that changesneed not be monotonic.
In particular, whenchanging his mind, or correcting the system'smisinterpretations, the user may delete subtaskstructures altogether, as in the subdialog:S: What day are you returning to Chicago?U: No, I don't want a return flight.Because they take information away rather thanadd it, scenarios like this one make itproblematic to view discourse processing asproducing a contextualized, or "thick frame",version of the user's utterance.
In our system,therefore, we have chosen a somewhat differentapproach.The discourse processor, called the statemanager, computes the most likely new taskstate, based on the user's input and the currenttask state.
It also computes a discourse vent,representing its interpretation f what happenedin the conversation as a result of the user'sutterance.The dialogue manager is a separate module, ashas no state managing responsibilities at all.Rather, it simply computes the next action totake, based on its current goal agenda, thediscourse vent returned by the state manager,and the new state.
This design has the advantageof making the dialogue manager considerablysimpler.
The discourse event also becomesavailable to convey to the user as confirmation.We discuss these two modules in more detailbelow.703.1 State ManagerThe state manager is responsible for computingand maintaining the current ask state.
The taskstate is simply the set of path constraints whichcurrently constrain the user's itinerary.
Alsoincluded in the task state are the history of userand system utterances, and the current subtaskand object in focus, if any.The state manager takes the N-best list ofrecognition hypotheses as input.
It invokes theunderstanding module on a hypothesis to obtaina semantic interpretation.
The semanticinterpretation so obtained is subjected to thefollowing steps:1.
Resolve ellipses if any2.
Match input meaning to subtask(s)3.
Expand local ambiguities4.
Apply inference and coherency rules5.
Compute database satisfiers6.
Relax constraints if neccesary7.
Determine the most likely alternative andcompute the discourse ventAt any of these steps, zero or more alternativenew states can result, and are fed to the nextstep.
If zero states result at any step, the newmeaning representation is rejected, and anotherone requested from the understander.
If no morehypotheses are available, the entire utterance isrejected, and a DONT_UNDERSTAND event isreturned to the dialogue manager.Step 1 resolves ellipses.
Ellipses include bothshort responses like "Boston" and yes/noresponses.
In this step, a complete meaningrepresentation such as ' (ORIQCITY EQBOSTON)' is generated based on the system'sprompt and the input meaning.
The hypothesisrejected if this cannot be done.Step 2 matches the input meaning to one or moreof the subtasks of the problem.
For theCommunicator p oblem, the subtasks are legs ofthe user's itinerary, and matching is done basedon cities mentioned in the input meaning.
Thedefault is the subtask currently in focus in thedialogue.A match to a subtask is represented by addingthe prefix for the subtask to the path of theconstraint.
For example, "I want to arrive inDenver by 4 PM" and then continue on toChicago would be :LEGS.0.DEST_CITY EQ DENVERLEGS.0.ARRIVE_TIME LE 1600LEGS.
1.ORIG_CITY EQ DENVERLEGS.
1.DEST CITY EQ CHICAGOIn Step 3, local ambiguities are expanded intotheir different possibilities.
These includepartially specified times such as "2 o'clock"Step 4 applies inference and coherency rules.These rules will vary from application toapplication.
They are written in the pathconstraint formalism, augmented with variablesthat can range over attributes and other values.The following is an example, representing theconstraint a flight leg cannot be scheduled todepart until after the preceding flight arrives:LEGS.$N.ARRIVELTLEGS.
$N+ 1 .DEPARTStates that violate coherency constraints arediscarded.Step 5 computes the set of objects in thedatabase that satisfy the constraints on thecurrent subtask.
This set will be empty when theconstraints are not all satisfiable, in which casethe relaxation of Step 6 is invoked.
Thisrelaxation is a best-first search for the satisfiablesubset of the constraints that are deemed closestto what the user originally wanted.
Alternativerelaxations are scored according to a sum ofpenalty scores for each relaxed constraint,derived from earlier work by Stallard (1995).The penalty score is the sum of two terms: onefor the relative importance of the attributeconcerned (e.g.
relaxations of DEPART_DATEare penalised more than relaxations ofAIRLINE) and the other for the nearness of thesatisfiers to the original constraint (relevant fornumber-like attributes like departure time).71The latter allows the system to give credit tosolutions that are near fits to the user's goals,even if they relax strongly desired constraints.For example, suppose the user has expressed adesire to fly on Delta and arrive by 3 PM, whilethe system is only able to find a flight on Deltathat arrives at 3:15 PM.
In this case, this flight,which meets one constraint and almost meets theother, may well satisfy the user more than aflight on a different airline that happens to meetthe time constraint exactly.In the final step, the alternative new states arerank-ordered according to a pragmatic score, andthe highest-scoring alternative is chosen.
Thepragmatic score is computed based on a numberof factors, including the plausibility ofdisambiguated times and whether or not the stateinterpreted the user as responding to the systemprompt.The appropriate discourse event is thendeterministicaUy computed and returned.
Thereare several types of discourse vent.
The mostcommon is UPDATE, which specifies theconstraints that have been added, removed, orrelaxed.
Another type is REPEAT, which isgenerated when the user has simply repeatedconstraints the system already knows.
Othertypes include QUESTION, TIMEOUT, andDONT UNDERSTAND.3.1 Dialogue ManagerUpon receiving the new discourse event fromthe state manager, the dialogue managerdetermines what next action to take.
Actionscan be external, such as speaking to the user orasking him a question, or internal, such asquerying the database or other elements of thesystem state.
The current action is determined byconsulting a stack-based agenda of goals andactions.The agenda stack is in turn determined by anapplication-dependent library of plans.
Plans aretree structures whose root is the name of the goalthe plan is designed to solve, and whose leavesare either other goal names or actions.
Anexample of a plan is the following:Completeltinerary =>(Prompt "How can I help you?
")(forall legs $nGetRoutelnfoGetSpecificFlightGetHotelAndCarGetNextLeg))This is a plan for achieving the goalCompleteltinerary.
It begins with a open-endedprompt and then iterates over values of thevariable $N for which constraints on the prefixLEGS.$N exist, working on high-level subgoals,such as getting the route and booking a flight,for each leg.
The last goal determines whetherthere is another leg to the itinerary, in whichcase the iteraThe system begins the interaction with the high-level goal START on its stack.
At each step, thesystem examines the top of its goal stack andeither executes it if it is an action suitable forexecution, or replaces it on the stack with itsplan steps if it is a goal.Actions are objects with success and relevancypredicates and an execute method, somewhatsimilar to the "handlers" of Rudnicky and Xu(1999).
An action has an underlying oal, suchas finding out the user's constraints on someattribute.
The action's success predicate willreturn true if this underlying goal has beenachieved, and its relevancy predicate will returntrue if it is still relevant to the current situation.Before carrying out an action, the dialoguemanager first checks to see if its successpredicate returns false and its relevancypredicate returns true.
If either condition is notmet, the action is popped off the stack anddisposed of without being executed.
Otherwise,the action's execute method is invoked.The system includes a set of actions that arebuilt in, and may be parameterized for each eachdomain.
For example, the action type ELICIT isparameterized by an attribute A, a path prefix P,and verbalization string S. Its success predicatereturns true if the path 'P.A' is constrained in thecurrent state.
Its execute method generates ameaning frame that is passed to the language72generator, ultimately prompting the user with aquestion such as "What city are you flying to?
"Once an action's execute method is invoked, itremains on the stack for the next cycle, where itis tested again for success and relevancy.
In thiscase, if the success condition is met - that is, ifthe user did indeed reply with a specification ofhis destination city - the action is popped off thestack.
If the system did not receive thisinformation, either because the user made astipulation about some different attribute, askeda question, or simply was not understood, theaction remains on the stack to be executed again.Of course, the user may have already specifiedthe destination city in a previous utterance.
Inthis case, the action is already satisfied, and isnot executed.
In this way, the user hasflexibility in how he actually carries out thedialogue.In certain situations, other goals and actions maybe pushed onto the stack, temporarilyinterrupting the execution of the current plan.For example, the user himself may ask aquestion.
In this case, an action to answer thequestion is created, and pushed onto the stack.The dialogue manager then executes this actionto answer the user's question before continuingon with the plan.
Or the state manager maygenerate a clarification question, which thedialogue manager seeks to have the user answer.Actions can also have a set of conditionalbranchings that are tested after the action isexecuted.
If present, these determine the nextaction to execute or goal to work on.
Forexample, the action that asks the user "Do youwant a return flight to X?"
specifies the branchto be taken when the user replies in the negative.This branch includes an action that asks the user"Is Y your final destination?
", an action that isexecuted if the user did not specify an additionaldestination along with his negative reply.Unlike the approach taken by Ward and Pellom(1999), which seeks to avoid scripting entirelyby driving the dialogue off the current status ofthe itinerary, the Talk'n'Travel dialoguemanager thus seeks to allow partially scripteddialogue where appropriate to the situation.4 Language GenerationThe language generator takes a meaning framefrom the dialogue manager, and generates a textstring in English for it.
It uses a set of pattern-based rules that map constraints into alternativesyntactic realisations.
For example, thefollowing rule allows a constraint on departuretime to be realized as "leave at 3 PM"or "3 PM flight":LEG.$N.DEPART_TIME EQ $X=~ \[leave at $X\],\[nom-comp $X\]Different realization rules can be selected fordepending upon whether the constraint is to berealized as an assertion or as a description.
Thegeneration algorithm assembles the selectedrealizations for each constraint into a simplifiedsyntax tree, selecting appropriate inflections ofverb and noun heads as it does so.
Terminalvalues in constraints are realized as type-specificnominals, such as "3 PM" or "Delta".A crucial feature of the generation process isthat it adds to each prompt a paraphrase of themost recent discourse event, corresponding towhat the system thinks the user just said.
Thishelps keep the conversation grounded in termsof mutual understanding between theparticipants.5 Example ScenarioThe following is an example dialog with thesystem:S: Welcome to Talk'n'Travel.
How can I helpyou?U: I need a flight from Boston to Denvertomorrow.S: On Thursday, November 18, flying fromBoston to Denver.
What time do you want toleave?U: I want to leave before 10 AM.S: Leaving before 10 AM.
Do you have anairline preference?U: Continental.73S: Continental.
I 'm sorry, there are no flights onContinental leaving before 10 AM.
I can getyou a flight on Continental leaving at 10:10 AMinstead.
Would that be OK?U: Yes.S: OK, I've got you on Continental flight 429,departing Boston at 10:10 AM, arriving atDenver at 3:44 PM.
Do you want to book areturn flight from Denver to Boston?U: Yes, on Monday.S: Alright, we'll add a flight on Monday,November 22, from Boston to Denver to youritinerary.
I have a Continental flight at 7 AM.Is that OK?U.
Anything later?S: Leaving after 7 AM.
There are no flights onContinental after 7 AM.
I can get you a flightafter 7 AM on Frontier, Northwest, and Unitedinstead.
Would that be OK?U: How about United.S: United.
I have a United flight at 8:01 AM.
Isthat flight OK?U: Yes.S: OK, I've got you on United flight 1762,departing Denver at 8:01 AM, arriving at Bostonat 1:42 PM.6 Current Status and ConclusionsThe Talk'n'Travel system described here wassuccessfully demonstrated at the DARPACommunicator Compare and ContrastWorkshop in June 1999.
We are currentlycollecting data with test subjects and are usingthe results to improve the system's performancein all areas, in preparation for the forthcomingcommon evaluation of Communicator systemsin June 2000.8 of the subjects were successful.
Of successfulsessions, the average duration was 387 seconds,with a minimum of 272 and a maximum of 578.The average number of user utterances was 25,with a minimum of 18 and a maximum of 37.The word error rate of the recognizer was11.8%.The primary cause of failure to complete thescenario, as well as excessive time spent oncompleting it, was corruption of the discoursestate due to recognition or interpretation errors.While the system informs the user of the changein state after every utterance, the user was notalways successful in correcting it when it madeerrors, and sometimes the user did not evennotice when the system had made an error.
If theuser is not attentive at the time, or happens notto understand what the synthesizer said, there isno implicit way for him to find out afterwardswhat the system thinks his constraints are.While preliminary, these results point to twodirections for future work.
One is that the systemneeds to be better able to recognize and dealwith problem situations in which the dialogue isnot advancing.
The other is that the systemneeds to be more communicative about itscurrent understanding of the user's goals, evenat points in the dialogue at which it might beassumed that user and system were inagreement.AcknowledgementsThis work was sponsored by DARPA andmonitored by SPAWAR Systems Center underContract No.
N66001-99-D-8615.To determine the performance of the system, weran an informal experiment in which 11 differentsubjects called into the system and attempted touse it to solve a travel problem.
None of thesubjects were system developers.
Each subjecthad a single session in which he was given athree-city trip to plan, including dates of travel,constraints on departure and arrival times, airlinepreferences.The author wishes to thank Scott Miller for theuse of his GEM system.ReferencesMITRE (1999) DARPA Communicator homepagehttp://fofoca.mitre.org\].Ward W., and Pellom, B.
(1999) The CUCommunicator System.
In 1999 IEEE Workshopon Automatic Speech Recognition andUnderstanding, Keystone, Colorado.-/4.Miller S. (1998) The Generative Extraction Model.Unpublished manuscript.Dahl D., Bates M., Brown M., Fisher, W. Hunicke-Smith K., Pallet D., Pao C., Rudnicky A., andShriberg E. (1994) Expanding the scope of theATIS task.
In Proceedings of the ARPA SpokenLanguage Technology Workshop, Plainsboro, NJ.,pp 3-8.Constantinides P., Hansma S., Tchou C. andRudnicky, A.
(1999) A schema-based approach todialog control.
Proceedings oflCSLP, Paper 637.Rudnicky A., Thayer, E., Constantinides P., TchouC., Shern, R., Lenzo K., Xu W., Oh A.
(1999)Creating natural dialogs in the Carnegie MellonCommunicator system.
Proceedings ofEurospeech, 1999, Vol 4, pp.
1531-1534Rudnicky A., and Xu W. (1999) An agenda-baseddialog management architecture for sokenlanguage systems.
In 1999 IEEE Workshop onAutomatic Speech Recognition and Understanding,Keystone, Colorado.Seneff S., and Polifroni, J.
(2000) DialogueManagement in the Mercury Flight ReservationSystem.
ANLP Conversational Systems Workshop.Nguyen L., Anastasakos T., Kubala F., LaPre C.,Makhoul J., Schwartz R., Yuan N., ZavaliagkosG., and Zhao Y.
(1995) The 1994 BBN/BYBLOSSpeech Recognition System, In Proc of ARPASpoken Language Systems Technology Workshop,Austin, Texas, pp.
77-81.Stallard D. (1995) The Initial Implementation of theBBN ATIS4 Dialog System, In Proc of ARPASpoken Language Systems Technology Workshop,Austin, Texas, pp.
208-211.Miller S. and Stallard D. (i996) A Fully StatisticalApproach to Natural Language Interfaces, In Procof the 34 th Annual Meeting of the Association forComputational Linguistics, Santa Cruz, California.76
