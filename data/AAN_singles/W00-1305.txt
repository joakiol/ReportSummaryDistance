Topic Analysis Using a Finite Mixture ModelHang Li and  Ken j i  Yamanish iNEC Corporation{lihang,yamanisi} @ccm.cl.nec.co.jpAbst rac tWe address the issue of 'topic analysis,' bywhich is determined a text's topic structure,which indicates what topics are included in atext, and how topics change within the text.We propose a novel approach to this issue, onebased on statistical modeling and learning.We represent topics by means of word clusters,and employ a finite mixture model to repre-sent a word distribution within a text.
Ourexperimental results indicate that our methodsignificantly outperforms a method that com-bines existing techniques.1 In t roduct ion-:We consider here the issue of 'topic analysis,'by which is determined a text's topic struc-ture, which indicates what topics are includedin a text and how topics change within thetext.
Topic analysis consists of two maintasks: topic identification and text segmen-tation (based on topic changes).Topic analysis is extremely useful in a vari-ety of text processing applications.
For exam-plea it can be used in the automatic indexingof texts for purposes of information retrieval.With it, one can understand what the maintopics and subtopics of a text are, and wherethose subtopics lie within the text.To the best of our knowledge, however, noprevious tudy has so far dealt with the topicanalysis problem in the above sense.
Themost closely related are key word extractionand text segmentation.
A keyword extrac-tion method (e.g., that using tf-idf (Saltonand Yang, 1973)) generally extracts from atext key words which represent topics withinthe text, but it does not conduct segmenta-tion.
A segmentation method (e.g., TextTil-ing (Hearst, 1997)) generally segments a textinto blocks (paragraphs) in accord with topicchanges within the text, but it does not iden-tify (or label) by itself the topics discussed ineach of the blocks.The purpose of tMs paper is to provide asingle framework for conducting topic analy-sis, i.e., performing both topic identificationand text segmentation.The key characteristics of our frameworkare 1) representing a topic by means of a clus-ter of words that are closely related to thetopic, and 2) employing a stochastic model,called a .finite mixture model (e.g., (Everittand Hand, 1981)), to represent a word dis-tribution within a text.
The finite mixturemodel has a hierarchical structure of probabil-ity distributions.
The first level is a probabil-ity distribution of topics (topic distribution).The second level consists of probability distri-butions of words included within topics (worddistributions).
These word distributions arelinearly combined to represent a word distri-bution within a text, with the topic distribu-tion being used as the coefficient vector.
Here-after we refer to a finite mixture model hav-ing this structure as a stochastic topic model(STM).Before conducting topic analysis, we createword clusters (topics) on the basis of word co-occurrence in corpus data.
We have devel-oped a new method for word clustering usingstochastic omplexity (or the MDL principle)(Rissanen, 1996).In topic analysis, we estimate a sequenceof STMs that would have given rise to a giventext, assuming that each block of a text is gen-erated by an individual STM.
We perform textsegmentation by detecting significant differ-ences between STMs and perform topic iden-tification by means of estimation of STMs.With the results, we obtain the text's topicstructure which consists of segmented blocksand their topics.It is possible to perform topic analysisby combining an existing word extractionmethod (e.g., tf-idf) and an existing text seg-35mentation method (e.g., TextTiling).
Specif-ically, one can extract key words from a textusing tf-idf, view these extracted key wordsas topics, segment he text into blocks us-ing TextTiling, and estimate the distributionof topics (key words) within each block.
Ex-perimental results indicate, :however, that ourmethod significantly outper~brms such a com-bined method in topic identification and out-performs it in text segmentation, because itutilizes word cluster information and employsa well-defined probability framework.Finite mixture models have been employedin a number of text processing applications,such as text classification (e.g., (Li and Ya-mauishi, 1997; Nigam et al, 2000)) and infor-mation retrieval (e.g., (Hofmann, 1999)).
Aswill be discussed, however, our definition of afinite mixture model and the way we use ithere .differs significantly.2 S tochast i c  Top ic  Mode l2.1 TopicWhile the term 'topic' is used in different waysin different linguistic theories, we simply viewit here as a subject within a text.
We rep-resent a topic by means of a cluster of wordsthat are closely related to the topic, assum-ing that a cluster has a seed word (or severalseed words) which indicates a topic.
Figure 1shows an example topic with the word 'trade'being the seed word.I trade: trade export import tariff trader GATT protectionist IIFigure 1: Example topic2.2 Def in i t ion  o f  STMLet W denote a set of words, and K a set oftopics.
We first define a distribution of topics(clusters) P(k) : ~kEIK P(k) = 1.
Then, foreach topic k E K, we define a probability dis-tribution of words P(wik) : ~ ,ew P(wlk) =1.
Here the value of P(wik) will be zeroif w isnot included in k. We next define a Stochas-tic Topic Model (STM) as a finite mixturemodel, which is a linear combination of theword probability distributions P(w\[k), withthe topic distribution P(k) being used as thecoefficient vector.
The probability of word win W is, then,P(w) = ~ P(k)P(wlk ) we  W.kEKFigure 2 depicts an example STM.Figure 2: Example STMFor the purposes of statistical modeling, itis advantageous to conceive of a text (i.e., aword sequence) as having been generated bysome 'true' STMs, which we then seek to esti-mate as closely as possible.
A text may have anumber of blocks, and each block is assumedto be generated by an individual STM.
TheSTMs within a text are assumed to have thesame set of topics, but have different param-eter values.From the linguistic viewpoint, a text gener-ally focuses on a single main topic, but it maydiscuss different subtopics in different blocks.While a text is discussing any one topic, it willmore frequently use words strongly related tothat topic.
Hence, STM is a natural represen-tation of statistical word occurrence based ontopics.3 Word  C lus ter ingBefore conducting topic analysis, we createword clusters using a large data corpus.
Moreprecisely, we treat all words in a vocabulary asseed words, and for each seed word we collectfrom the data those words which frequentlyco-occur with it and group them into a cluster.As one example, the word-cluster in Figure 1has been constructed with the word 'trade' asthe seed word.We have developed a new method for reli-ably collecting frequently co-occurring wordson the basis of stochastic omplexity, or theMDL principle.
For a given data sequencez m = x l .
.
.
zm and for a fixed probabilitymodel M, 1 the stochastic omplexity of x mrelative to M, which we denote as SC(x m :M), is defined as the least code length re-quired to encode xrn with M (Rissanen, 1996).SC(x m : M) can be interpreted as the amountinformation included in x n relative to M. The1 Here, we use 'model' to refer to aprobabi l i ty dis-tnbution which has specified paxameters but unspeci-fied parameter values.36MDL (Minimum Description Length) princi-ple is a model selection criterion which assertsthat, for a given data sequence, the lower amodel's SC value, the greater its likelihood ofbeing a model which would have actually gen-erated the data.
MDL has many good prop-erties as a criterion for model selection.
2For a fixed seed word s, we take a word w asa frequently co-occurring word if the presenceof s is a statistically significant indicator ofthe presence of w.Let a data sequence: (s l ,wl ) ,  (s2,w2), .-.,(Sin,Win) be given where (si, wi) denotes thestate of co-occurrence of words s and w inthe i-th text in the corpus data.
Here, sl E{1,O},wi e {1,0},(i = 1, .
- .
, rn) ,  1 denotesthe presence of a word, while 0 the absenceof it.
We further denote s TM = sl .
.
.sm, andW TM ~.. W 1 ?
.
.
W m .Then as in (Rissanen, 1996), the SC value ofw TM relative to a model I in which the presenceor absence of w is independent from those ofs (i.e., a Bernoulli model), is calculated asSC(w TM : I) = mH + ~ log ~ + log 7r,where m + denotes the number of l 's in wm.Here, log denotes the logarithm to the base2, ~- the circular constant, and H(z) deJ- z logz  - (1 - z)log(1 - z), when 0 < z < 1;H(z) des = 0, whenz=0orz= 1.Let w m" be the sequence of all wi's (wi Ew rn) such that its corresponding si is 1, wherems denotes the number of l 's in s ~.
Let w rn''be the sequence ofaU wi's (wi E w m) such thatits corresponding si is 0, where rn.~s denotesthe number O's in s m. The SC value of w mrelative to a model D in which the presenceor absence of w is dependent on those of s isthen calculated asSC(w  ( s.u log ): = + ~logT~ ++ (m"sH (-m'-'~'~'~ W ?1?g-m-='~ W l?gr) 2~where ms + denotes the number of l 's in wm',and w~+s the number of l 's in w m~,.2For an introduction to MDL,  see (Li, 1998).We can then calculate6SC = "~(SC(wm : I) - SC(wm : D))\ [ ( )  m \m.~/ jf l  IOarn~rn- , ,~/-1  o j"(I)According to the MDL principle, the largerthe 6SC value, the more likely that the pres-ence or absence of w is dependent on those of8.
3Actually, we may think of a word w forwhich the value of 6SC is larger than a pre-determined threshold 3' and P(wls ) > P(w)is satisfied as that which occurs significantlyfrequently with the seed word s.Note that the word clustering process isindependent of topic analysis.
While onecould employ other methods (e.g., (Hofmann,1999)) here for word clustering, our clus-tering algorithm is more efficient than con-ventional ones.
For example, Hofmann's isof order O(\]DIIWI2), while ours is only ofO(ID I + \]WI2), where IDI denotes the numberof texts and IW\] the number of words.
Thatmeans that our method is more practical whena large amount of text data is available.4 Top ic  Ana lys i s4.1 Input  and  OutputIn topic analysis, we use STM to parse agiven text and output a topic structure whichconsists of segmented blocks and their top-ics.
Figure 3 shows an example topic struc-ture as output with our method.
The text hasbeen segmented into five blocks, and to eachblock, a number of topics having high prob-ability values have been assigned (topics axerepresented by their seed words).
The topicstructure clearly represents what topics are in-cluded in the text and how the topics changewithin the text.4.2 Out l ineOur topic analysis consists of three processes:a pre-process called 'topic spotting,' text seg-mentation, and topic identification.
In topicSNote that the quantity within \[---\] in (1) is (em-pir ical)  mutua l  inyormat ion,  which is an effective mea-sure for word co-occurrence calculation (cf.,(Brown etal., 1992)).
When the sample size is small, mutualinformation values tend to be undesirably large.
Thequantity within {-..} in (1) can help avoid this unde-sirable tendency because its value will become largewhen data size is small.37ASIAI SXPOITERS PSAk DAEAOS Fit05 U.S.-IAPA| RIFT (25-HAE-1987)block 0 .
.
.
.
.
.
.
.
t rade-expor~-car i~t- impo:rt(O,12) Japan-Japa.l~ese(O.07) U$(0.06)0 Sountin S t rade f r i c t ion  between the U.:3. and $opau has ra ised  fears  amen S many of l s ia*s  export ing nat ions  chat  the row could in f l i c t  .
.
.1 They to ld  Router correspondents in Asian cap i ta l s  a U.S. move aga inst  Japan might boost p ro te?t ion is t  sent iment in she U.S. ~nd lead to .
.
.2 But some exporters  said Chat while the conf l i c t  would hurt  them in the lens- run,  in the shor t - term Tokyo's loss  might be the i r  ga in .3 The U.S. Xas said i t  s i l l  ~apose 300 ~tn d l rs  of ta r i f f s  on imports of Japanese e lec t ron ics  seeds on Apr i l  17. in re ta l ia t ion  fo r  Japa~*s .
.
.4 Unof f i c ia l  Japanese ost~Jnates put the impact of the ta r i f f s  a t  10 b i l l i on  d l ro  and spokesmen fo r  major e lec t ron ics  1irma said they would .
.
.5 "go wouldn't be able to do bus iness , "  Isaid a spokesman fo r  l .od in  S ;apanese e lec t ron ics  ~irm Satanoh i ta  E lec t r i c  Indust r ia l  ?o Lad t l t .6 " I f  the ta r i f f s  remain in p lace for  any length of time beyond a ~eg months i t  s i l l  ~an the complete eros ion of experts  (o~ good8 subject  .
.
.block I .
.
.
.
.
.
.
.
trade-export-ta~vif~-Impo:rt(O. lT)  US(O.Og) Taiwan(O.05) dlrs(O.O$)T In Taigan.
businessmen and o f f i c ia l s  ~re a lso  worried.$ "We i re  agLre of the ser iousness  ot the U.5.
th reat  aga ins t  Japan because i t  serves as a warning to o | , "  sa id  ?
senior  Taiganese t rade  .
.
.g Taiu&n had z t rade t rade surplus of 15~6 b i l l i on  d i re  las t  year?
gS pot of i t  u i tb  the U.$.10 The surplus helped sge l l  7aiwan's fo re ign  exchange reserves  to 53 b i l l i on  d l r s .
ninon S the wor ld 's  la rgest .11 "Re must quickly open our markets,  remove t rade bar r ie rs  and cut Import ta r i f f s  to al low imports o~ U.S. p red ic ts ,  i f  ue want to de~nse .
.
.12 I sen ior  o f f i c i L1  ef South \ [o rea 's  tr~Lde promotion assoc ia t ion  said the t rade  d ispute between the U.S. and Japan might a lso  lead to .
.
.13 L i s t  year South |u rea  had a t rade surplus ef 7.1 b i l l i on  dlro u i th  the U.S .
.
np ~ron t .9  b i l l i on  d l r s  in 1985.1~ In Ha lays ia .
erode o f f i cers  and businessmen said ~ou~h curbs aga ins t  Japan might a l len  hard -h i t  producers o~ anuLicondnctors in th i rd  .
.
.block 2 .
.
.
.
.
.
.
.
Hong-|en$(0.16) t rado-expor t - ta~i f f - imper t (O .
10) U5(0.06)15 In Hung long, where nauspaporo have a l leged  Japan has been na i l ing  ba ler -cos t  semiconductors, some e lec t ron icsmanu~acturnrn  share .
.
.16 "That i s  a very shor t - te rm v ies . "
sa id Lawrn~ce R i l l s ,  d i rec tor -genera l  o~ the Federat ion of Hung Eerie Industry .17 "I~ the uhole purpose i s  te  prevent imports ,  one day i t  g i l l  be extended to other  sources.
Hush more ser ious  fo r  Hsng Ions i s  the .
.
.18 The U.S. las t  year gas Hon K Eong's h iogest  expert  market, accounting fo r  ever 30 pot of domest ica l ly  produced exports .block 3 .
.
.
.
.
.
.
.
t rade-expor t - ta r i f f - impor t (0 .14)  Button(O.08) ~apan-lapaneoe(O.07)19 ~ho Aust ra l ian  government is  ana i t ing  the outcome of t rade ta lks  botmean the U.S. and Japan u i tb  in teres t  and concern, Indust ry  .
.
.20 *'1his kind o~ deter io ra t ion  in t rade re la t ions  between sue countr ies  nhich &r~majer  t rad ing  par tners  of ours i s  a very .
.
.21 He said los t ra l ia*s  concerns centred en coal and beef,  Anst rn l ia :8  tee la rses t  exports to Japan and a l so  s ign i f i cant  U.S .
.
.
.22 Heanwhile U.S.- JapanaSe "diplomatic manoeuvmes to solve the trade s tand-o f f  cont inue.block 4 .
.
.
.
.
.
.
.
Japan-Japanese(O,12) measure(O.06) t rade-expor t - ta r i f f - i~por t (O .O5)23 Japan's  ru l ing  L ibera l  Democratic Party  yesterday out l ined a package of economic measuru8 to boost the ~apananu $csnony.24 The Measures proposed include ?
lapse supplementary budget and record publ ic  works spending in the f i r so  ha l f  of ohe f inanc ia l  year .25 \]hey a lso ca l l  gor stepped-up spending as an emergency measure to s t imu late  the economy danpi te  Prime S in i s ter  Yasuhiro HaJ~asome .
.
.26 Deputy U.S. Trade kepreanutagive 5 ichae l  Sunth and H~koto ln r rda ,  Japan's  deputy min is ter  of In ternat iona l  Trade ~nd Zndustry (BZTZ) .
.
.
.0-26; sentence id( .
. )
:  p robab i l i ty  valueFigure 3: Topic structure of textspotting, we select opics discussed in a giventext.
We can then construct STMs on thebasis of the topics.
In text segmentation, wesegment the text on the basis of the STMs,assuming that each block is generated by anindividual STM.
In topic identification, we es-timate the parameters of the STM for eachsegmented block and select topics with highprobabilities for the block.
In this way, weobtain a topic structure for the text.4.3 Topic Spott ingIn topic spotting, we first select key wordsfrom a given text.
We calculate what we callthe Shannon i formation of each word in thetext.
The Shannon information of word w intext t is defined asI(w) = -N(w)logP(w),where N(w) denotes the frequency of w in t,and P(w) the probability of the occurrence ofw as estimated from corpus data.
I(w) maybe interpreted as the amount of informationrepresented by w. We select as key words thetop I words sorted in descending order of I.While Shannon information is similar tothe tf-idf widely used in information retrieval(e.g., (Salton and Yang, 1973)), the use ofShannon information can be justified on thebasis of information theory, but that of tf-idfcannot.
Our preliminary experimental resultsindicate that Shannon information performsbetter than or at least as well as tf-idf in keyword extraction.
4From the results of word clustering, we nextselect any cluster (topic) whose seed word isincluded among the selected key words.We next merge any two clusters if one oftheir seed words is included in the other's clus-ter.
For example, when a cluster with seedword 'trade' contains the word 'import,' anda cluster with seed word 'import' contains theword 'trade,' we merge the two.
After twosuch merges, we may obtain a relatively largecluster with, for example, ~trade-import-tariff-export' as its seed words, as is shown in Fig-ure 3.
Figure 4 shows the merging algorithm.In this way, we obtain the most conspicuousand mutually independent topics discussed ina given text.4.4 Text Segmentat ionIn segmentation, we first identify candidatesfor points of segmentation within the giventext.
When we assume a relatively short text~We will discuss it in the full version of the paper.38kl, ?
?
?
,  kn: clusters,V = {{ki},i = 1,2, .
.
.
,n}.For each cluster pair (ki, kj), if the seedword of ki is included in kj and the seedword of kj is included in ki, then push(ki, kj) into queue Q;while (Q # 0) {Remove the first element (kl, kj) from Q;if (kl and kj belong to different setsW1,W2 in V)Replace W1 and W2 in V withw~ u w2 ;}For each element W of V, merge theclusters in it.Figure 4: Algorithm: mergefor the purposes of our explanation here, allsentence-ending periods will be candidates.For each candidate, we create two pseudo-texts, one consisting of the h sentences pre-ceding it, and the other of the h sentencesfollowing it (when fewer than h exist in any..:direction, we simply use those which do exist).We use the EM algorithm ((Dempster et al,1977), cL, Figure 5) to separately estimate theparameters of an STM from each of the twopseudo texts.
It is theoretically guaranteedthat the EM algorithm converges to a localmaximum of the likelihood.
We next calculatethe similarity (i.e., essentially the converse no-tion of distance s) between the STM basedon the preceding pseudo-text, and the STMbased on the following pseudo-text.
TheseSTMs axe denoted, respectively, as PL(W) andPR(w).
The similarity between PL(W) andPR(w) is defined asS(LI\[R) = 1 - E~w \ [PL (w)  - PR(w)\[2The numerator is referred to in statistics asvariational distance and has good propertiesas a distance between two probability dis-tributions (cf., (Cover and Thomas, 1991),p.299).Figure 7 shows a graph of calculated simi-laxity values for each of the candidates in the5We use similarity rather than distance here in or-der to simplify comparison between our method andTextTiling (Hearst, 1997).s: predetermined number.For the lth iteration (I = 1,- .
.
,  s),we calculatePU)(k)PU)(wlk)P(Z+l)(klw) = Ek~P(')(k)P(')(wlk)p(l+l)(k) = N(w)PU+l)(klw)NP(Z+l)(w\]k) = N(w)P(l+l)(k\[ w)~wew g(w)P(~+ l )(k\[w)N(w) denotes the frequency of word win the data; N = ~ew N(w).Figure 5: EM algorithmn: number of segmentation candidates,S(i) i(i = 0. .
.
n): similarity score.for (i = 1;i < n -  1;i + +){if (S(i - 1) > S(i) & S(i + 1) > S(i)){j= i -1 ;while (j > 0 & S(j - 1) > S(j))j - - ;P1 = S(j);j= i+ l;while(j  < n & S(j + 1) > S(j))j++;P2 = S(j);i f (P1 - S( i )  > ~ & P2-  S( i )  > 8)Conduct segmentation at i.
})Figure 6: Algorithm: segmenttext shown in Figure 3.
'Valleys' (i.e., low-similarity values) in the graph suggest pointsfor reasonable segmentations.
In actual prac-tice, segmentation is performed for each valleywhose similarity values is lower to a predeter-mined degree 0 than each of the values of itsleft 'peak' and right 'peak' (cf., Figure 6) Forexample, for the text in Figure 3, segmenta-tion was performed at candidates (i.e., end ofsentences) 6, 14, 18, and 22, with 8 = 0.05.4.5 Topic Ident i f icat ionAfter segmentation, we separately estimatethe parameters of the STM for each block,again using the EM algorithm, and obtaina topic (cluster) probability distribution foreach block.
We then choose those topics (dus-ters) in each block having.high probability val-ues.
In this way, we construct a topic struc-390.350.30.250.20.150.10.05% ;' ' "STM" ~ '  ti = ,o 15 2'o 2'5sentence nurn~,erFigure 7: Similarity values for segmentationcandidatesture as in Figure 3 for the given text (topicsare here represented by their seed words).We can view topics appearing in all theblocks as main topics, and topics appearingonly in individual blocks as subtopics.
Inthe text in Figure 3, the topic representedby seed-words 'trade-export-tariff-import' isthe main topic, and 'Japan-Japanese,' 'HongKong,' etc., are subtopics.5 App l i ca t ionsOur method can be used in a variety of textprocessing applications.For example, given a collection of texts(e.g., home pages), we can automatically con-struct an index of the texts on the basis of theextracted topics.
We can indicate which topicis from which text or even which block of atext.
Furthermore, we can indicate which top-ics are main topics of texts and which topicsare subtopics (e.g., by displaying main topicsin boldface, etc).
In this way, users can get afair sense of the contents of the texts simplyby looking through the index.
For a specifictext, users can get a rough sense of the con-tent by looking at the topic structure as, forexample, it is shown in Figure 3.Our method can also be useful for text min-ing, text summarization, information extrac-tion, and other text processing, which requireone to first analyze the structure of a text.6 Re la ted  WorkTo the best of our knowledge, no previousstudy has so far dealt with topic identificationand text segmentation within a single frame-work.A widely used method for key word extrac-tion calculates the tf-idf value of each word ina text and uses those words having the largesttf-idf values as key words for that text (e.g.,(Salton and Yang, 1973)).
One can view theseextracted key words as the topics of the text.No keyword extraction method by itself, how-ever, is able to conduct segmentation.With respect o text segmentation, exist-ing methods can be classified into two groups.One is to divide a text into blocks (e.g.,TextTiling (Hearst, 1997)), the other to di-vide a stream of texts into its original texts(e.g.,(Allan et al, 1998; Yamron et al, 1998;Beeferman et al, 1999; tteynar, 1999)).
Theformer group generally employs unsupervisedlearning, while the latter supervised one.
Noexisting segmentation method, however, hasattempted topic identification.TextTiling creates for each segmentationcandidate two pseudo-texts, one preceding itand the other following it, and calculates assimilarity the cosine value between the wordfrequency vectors of the two pseudo texts.
Itthen conducts egmentation at valley pointsin a similar way to that of our method.
Sincethe problem setting of TextTiling (in generalthe former group) is most close to that of ourstudy, we use TextTiling for comparison i ourexperiments.Our method by its nature performs topicidentification and segmentation within a sin-gle framework.
While it is possible with acombination of existing methods to extractkey words from a given text by using tf-idf,view the extracted key words as topics, seg-ment the text into blocks by employing Text-Tiling, estimate distribution of topics in eachblock, and identify topics having high prob-abilities in each block.
Our method outper:forms such a combination (referred to here-after as 'Corn') for topic identification, be-cause it utilizes word duster information.
Italso performs better than Com in text seg-mentation because it is based on a well-definedprobability framework.
Most importantly isthat our method is able to output an easilyunderstandable topic structure, which has notbeen proposed so far.Note that topic analysis is different fromtext classification (e.g., (Lewis et al, 1996; Liand Yamanishi, 1999; Joachims, 1998; Weisset al, 1999; Nigam et al, 2000)).
While textclassification uses a number of pre-determinedcategories, topic analysis includes no notionof category.
The output of topic analysis is atopic structure, while the output o f  text clas-40sification is a label representing a category.Furthermore, text classification is generallybased on supervised learning, which uses la-beled text data 6.
By way of contrast, topicanalysis is based on unsupervised learning,which uses only unlabeled text data.Finite mixture models have been used ina variety of applications in text processing(e.g., (Li and Yamanishi, 1997; Nigam et al,2000; Hofmann, 1999)), indicating that theyare essential to text processing.
We shouldnote, however, that their definitions and theways they use them axe different from thosefor STM in this paper.
For example, Li andYamanishi propose to employ in text classi-fication a mixture model (Li and Yamanishi,1997) defined over categories:P(WIC) = ~ P(klc)P(wlk),w e W,c e C,kEKwhere W denotes a set of words, and C aset of categories.
In their framework, a newtext d is assigned into a category c* such thatc* = argmaxeee P(c\]d) is satisfied.
I-Iofmannproposes using in information retrieval a jointdistribution which he calls 'an aspect model,'.Aefined as (Hofmann, 1999)P(w,d) = P(d)P(wld)= P(d) EkeK P(kld)P(wlk),wEW,  dEDwhere D denotes a set of texts.
Furthermore,he proposes extracting in retrieval those textswhose estimated word distributions P(w\[d)are similar to the word distribution of a query.7 Exper imenta l  Resu l t sWe have evaluated the performance of ourtopic analysis method (STM) in terms of threeaspects: topic structure adequacy, text seg-mentation accuracy, and topic identificationaccuracy.7.1 Data  SetWe know of no data available for the pur-pose of evaluation of topic analysis.
We thusutilized Reuters news articles referred to as'Reuters-21578,' which has been widely usedin text classification v. We used a preparedSAn exception is the method proposed in (McCal-lure and Nigam, 1999), which, instead of labeled texts,uses  unlabeled texts, pre-determined categories, andkeywords defined by humans for each category.rAvailable at http://www.reseaxch.att.com/lewis/.split of the data 'Apte split,' which consistsof 9603 texts for training and 3299 texts fortest.
All of the texts had already been classi-fied into 90 categories by human subjects.For each text, we used the Oxford Learner'sDictionary s to conduct stemming, and re-moved 'stop words' (e.g., 'the,' 'and') that wehad included on a previously prepared list.The average length of a text was about 115words.
(We did not use phrases, however,which would further improve xperimental re-sults.
)7.2 Word  C luster ingWe conducted word clustering with 9603training texts.
7340 individual words had atotal frequency of more than 5, and we usedthem as seeds with which to collect frequentlyco-occurring words.
The threshold for clus-tering 7 was set at 0.005, and this yielded970 word clusters having more than one word(i.e., not simply containing a seed word alone).Note that the category labels of the trainingtexts need not be used in clustering.We next conducted a topic analysis on allthe 3299 texts.
The thresholds of l, h, and 0were set at 20, 3, and 0.05, respectively, onthe basis of preliminary experimental results.7.3 Topic S t ruc tureWe looked at the topic structures of the 3299texts obtained by our method to determinehow well they conformed to human intuition.For topic identification i  this experiment,clusters in each block were sorted in descend-ing order of their probabilities, and the top7 seed words were extracted to represent thetopics of the block.Figure 3 show results for the text with ID14826; they generally agree well with humanintuition.
The text has been segmented into5 blocks and the topics of each block is rep-resented by 7 seed words.
The main topic isrepresented by the seed-words 'trade-export-tariff-import.'
The subtopics are representedby 'Japan-Japanese,' 'Taiwan,' Hong Kong,'etc.
There were, however, a small numberof errors.
For example, the text should alsohave been segmented after sentences 11 and13, but, due to limited sentence content, it wasnot.
Furthermore, assigning subtopic of 'But-ton' (from 'Mr.
Button') into block 3 (dueto the high Shannon information value of theword 'Button') was also undesirable.SAvailable at  ftp://sable.ox.ac.uk.41Table 1:10 categories and their identificationwordscategoryearnacqmoney-fxgraincrudetradeinterestshipwheatcornidentification vcordsearning, share, profit, dividendacquisition, acquire, sell, buycurrency, dollar, yen, stggrain, cereal, cropoil, crude, gastrade, export, import, tariffinterest & rateship, vessel, ferry, tankerwheatcori1, maize7.4 Main Topic Identi f icat ionWe conducted an evaluation to determinewhether or not the main topics in the topicstructures obtained for the 3299 test textscould be approximately matched with the la-bels (categories) assigned to the test texts.Note that here labels are used only for eval-uation, not for training.
This is in contrastto the situation in most text classification ex-periments, in which labels are generally usedboth for training and for evaluation.
It is notparticularly meaningful, then, to compare theresults for main topic identification obtainedhere with those for text classification.With STM, clusters in each block weresorted in descending order of their probabil-ities, and the top k seed words were extractedto represent the topics of the block.
Further-more, a seed word appearing in all the blocksof the text was considered to represent a maintopic.
When a text had not been segmented(i.e., has only one block), all top k seed wordswere considered to represent main topics.Table 1 lists the largest 10 categories in theReuters data.
On the basis of the definition ofeach of the 10 categories, we assigned based onour intuition to each of them the identificationwords that are listed in Table 1.For the evaluation, when the seed words formain topics contained at least one of the iden-tification words, we considered our method tohave identified the corresponding main topicequivalent to a human-determined category.We then evaluated these in terms of preci-sion and recall.
Here, precision is defined asthe ratio of the number of decisions correctlymade to the total number of decisions made.Recall is defined as the ratio of the mrmber ofdecisions correctly made to the total numberTable 2: Main topic identification results withrespect o 7 top wordscategoryearnacqmoney-fxgraincrudetradeinterestshipwheatcornSTMrec.
pre.Comrec.
pre.0.790 0.9710.245 0.8540.436 0.4560.322 0.7500.487 0.6760.667 0.4730.107 0.7000.247 0.9570.620 0.9360.429 0.9600.526 0.9760.184 0.8410.285 0.4210.174 0.6500.407 0.6640.590 0.3560.084 0.7330.270 0.8280.408 0.9670.446 1.00micro-average 0.515 0.824 0.365 0.774Table 3: Main topic identification results withrespect o 5 top wordscategoryearnacqmoney-fxgraincrudetradeinterestshipwheatcornmicro-averageSTMrec.
pre.0.742 0.9710.184 0.8680.413 0.5030.295 0.7590.471 0.7180.479 0.5050.053 0.7000.169 1.0000.577 0.9530.357 0.9520.461 0.850Cornrec.
pre.0.348 0.9770.120 0.8690.268 0.4710.121 0.6000.333 0.6560.513 0.4030.069 0.8180.180 0.7620.282 0.9520.321 1.0000.257 0.767of decisions which should have been correctlymade.We also looked at the performance of Corn(cf., Section 6).
For Corn, we extracted from atext the key words with the 20 largest Shan-non information values, segmented the textusing TextTiling, and extracted in each blockthe key words having the largest k probabil-ity values.
Any key word extracted in allblocks was considered to represent a maintopic.
When the key words for main top-ics contained at least one of the identificationwords, we viewed that text as having the cor-responding main topic.Table 2 shows the results achieved withSTM and Corn in the case of k ~-- 7.
9 Table 39For the definition of micro-averaging, see, for ex-42Tit le:  gOYPY BUYS PL 480 RHSAT FLOU!
- U.S. YRADSItS"Body: ggyp1 bought 125,723 sonnet o~ U.S. shoat ~lour in i t s  PL480 tender yesterdxy, trade ooQrceo sa id .
The purchase inc luded$t,880 tonnes ~er  Say shipn~nt ~d 73,843 tennes for  June sb ipnent .P r i ce  deta i l s  gere not available.Content Words (Freq.
): tone(S) shipment(2) buy(t) deta i l ( I )ggypt(1) t lour ( l )  include(I) June(l) PL(I) price(t) purchase(l)source( l )  trade(l) US(l) 9heat(l)Icy Bordo (ShLn.
Ing.
):  tonne(17.5) ohi~4nent(1S.3) PL(IO.6) flour(9.8)Sgypt(9.3) detail(7.S) Juno(7.2) uheat(6.8) purchas?
(6.6) source(S.S)U$(6.1) buy(6.0) inclnde(6.O) trade(B.3) price (S.l)Con Yopics (Prob.
): tonn?
(O.17) shipnent(O.l l) price(O.06) June(O.O6)in?lude(O.00) purcbaoe(O.06) source(O.O6)BIB Iopico (Prob.)
: ilour~sheat(O.IB) tonn4(0.12) shipmont(O.tl)purchaoe-buy(O.tl) Egypt(O.O6)Cluster :  (S ieur-wheat:  ghent tonne ~lour)(purchase-buy: purchase bny)Figure 8: Topic Identification Exampleshows the results in the case of k = 5.
Thecomparison may be considered fair in that itrequires each of the two methods to providethe same number of words to represent top-ics.
Results indicate that STM significantlyoutperforms Corn, particularly in terms of re-call.The main reason for the higher performanceachieved by STM is that it utilizes word clus-ter information.
Figure 8 shows topic analysisresults for the text with ID 15572 labeled with'wheat.'
The text contains only 15 contentwords (word types), thus all of the 15 wordswere extracted as key words and the text wasnot segmented by either method.
Corn wasunable to identify the main topic 'wheat,' be-cause the probability of each of the relevantkey words 'wheat' and 'flour' was low.
Incontrast, STM successfully identified the topicbecause the relevant key words were classifiedinto the same cluster, and its probability wasrelatively high.7.5 Segmentat ion  and Subtop icIdent i f icat ionWe collected the 50 longest test texts (re-ferred to here as 'seed texts') from each of the10 categories, and combined each with a testtext randomly selected from other categoriesto produce 500 pseudo-texts.
Placement ofthe seed text within its pseudo-text (i.e., be-fore or after the other text) was determinedrandomly.We used both STM and Corn to segmenteach of the pseudo-texts into two blocks andidentify subtopics.
Table 4 shows the segmen-tation results for the two method evaluatedample, (Lewis and Ringnette, 1994).Table 5: Subtopic identification resultscategory ofseed texteaxnacqmoney-fxgraincrudetradeinterestshipwheatcornAverageSTMrec.
pre.0.430 0.9450.237 0.9390.585 0.9500.276 0.9470.572 0.9790.634 0.9510.211 0.9370.260 1.0000.500 0.9700.317 1.000Cornrec.
pre.0.324 0.9730.217 0.9590.533 0.9610.222 0.9380.557 O.9900.627 0.8990.136 1.0000.340 0.9940.395 0.9800.441 0.8820.402 0.962 0.379 0.958in terms of recall, precision, and error prob-ability.
Table 5 shows the results of subtopicidentification as evaluated in terms of recalland precision.
Error probability is a metricfor evaluating segmentation results proposedin (Allan et ai., 1998; Beeferman etal.
,  1999).It is defined here as the probability that a ran-domly chosen pair of sentences a distance of ksentence apart is incorrectly segmented.
1?Experimental results indicate that STMoutperforms Corn in both segmentation andidentification, n8 Conc lus ionsWe have proposed a new method of topicanalysis that employs a finite mixture model,referred to here as a stochastic topic model(STM).Topic analysis consists of two main tasks:text segmentation and topic identification.With topic analysis, one can obtain a topicstructure for a text.Our method addresses topic analysis withina single framework.
It has the following novelfeatures: 1) it represents topics by means ofword dusters and employs a finite mixturemodel (STM) to represent a word distributionwithin a text; 2) it constructs topics on thebasis of corpus data before conducting topicanalysis; 3) it segments a text by detectingsignificant differences between STMs; and 4)it identifies topics by estimating parameters1?Here, k was set to 5 because the average length ofa text was about 10 sentences.
....l lWe will discuss the results in the full version ofthe paper.43Table 4: Text segmentation resultscategory ofseed textearnacqmoney-fxgraincrudetradeinterestshipwheatcornAverageSTM0.6600.820 0.820 0.0590.700 0.700 0.0870.700 0.700 0.0740.860 0.860 0.0510.800 0.800 0.0720.760 0.760 0.1190.837 0.854 0.0740.760 0.760 0.0750.625 0.625 0.147Cornrec.
pre.
err.
rec.
pre.
err.0.660 0.167 0.640 0.640 0.1710.740 0.740 0.0850.660 0.660 0.1210.660 0.660 0.0760.820 0.820 0.0660.800 0.800 0.0810.820 0.820 0.0840.816 0.833 0.0840.640 0.640 0.1300.650 0.650 0.1050.725 0.726 0.100 0.752 0.754 0.092of STMs.Experimental results indicate that ourmethod outperforms a method that combinesexisting techniques.
More specifically, it sig-nificantly outperforms the combined methodin topic identification.Re ferencesJ.
Allan, J. Carbonell, G. Doddington, J. Yam-ron, and Y. Yang.
1998.
Topic detection andtracking pilot study: Final report.
Proc.
of theDARPA Broadcast News Transcription and Un-derstanding Workshop, pages 194-218.D.
Beeferman, A. Berger, and J. Lafferty.1999.
Statistical models for text segmentation.Machi.
Lrn., 34:177-210.P.
F. Brown, V. J. Della Pietra, P. V. deSouza,J.
C. Lai, and R. L. Mercer.
1992.
Class-basedn-gram models of natural language.
Comp.Ling., 18(4):283-298.T.
M. Cover and J.
A. Thomas.
1991.
Elements ofInformation Theory.
John Wiley & Sons Inc.,New York.A.P.
Dempster, N.M. Laird, and D.B.
Rubin.1977.
Maximum likelihood from incompletedata via the em algorithm.
Journ.
of Roy.
Star.Soci., Ser.
B, 39(1):1-38.B.
Everitt and D. Hand.
1981.
Finite MiNute Dis-tribntions.
Chapman and Hall.M.
Hearst.
1997.
Texttiling: Segmenting textinto multi-paragraph subtopic passages.
Comp.Ling., 23(1):33-64.Thomas Hofmann.
1999.
Probabilistic latent se-mantic indexing.
Proc.
of SIGIR '99, pages 50-57.T.
Joachirns.
1998.
Text categorization with sup-port vector machines: Learning with many rel-evant features.
Proc.
of ECML '98.D.
D. Lewis and M. Ringuette.
1994.
A compar-ison of two learning algorithms for test catego-rization.
Proc.
of 3rd Ann.
Syrup.
on Doc.
Ana.and Info.
Retr., pages 81-93.D.
D. Lewis, R. E. Schapire, J. P. Callan, andR.
Papka.
1996.
Training algorithms for lineartext classifiers.
Proc.
of SIGIR'96.H.
Li and K. Yamanishi.
1997.
Document classi-fication using a finite mixture model.
Proc.
ofA CL '97, pages 39-47.H.
Li and K. Yamanishi.
1999.
Text classificationusing ESC-based stochastic decision lists.
Proc.of ACM-CIKM'99, pages 122-130.H.
Li.
1998.
A Probabilistic Approach to LezicalSemantic Knowledge Acquisition and StructuralDisambignation.
Ph.D. Thesis, Univ.
of Tokyo.A.
K. McCallum and K. Nigam.
1999.
Text clas-sification by bootstrapping with keywords, emand shrinkage.
Proc.
of ACL'g9 Workshop Un-supervised Learning in NLP.K.
Nigarn, A. K. McCallum, S. Thrun, andT.
Mitchell.
2000.
Text classification fromlabeled and unlabeled documents using era.Maehi.
Lrn., 39:103-134.J.
C. Reynar.
1999.
Statistical models for topicsegmentation.
Proc.
of ACL '99, pages 357-364.J.
Rissanen.
1996.
Fisher information andstochastic omplexity.
1EEE Trans.
on Info.Thry., 42(1):40-47.G.
Salton and C.S.
Yang.
1973.
On the speci-fication of term values in automatic indexing.Journ.
of Doc., 29(4):351-372.S.
M. Weiss, C. Apte, F. Damerau, F. J. Oles,T.
Goers, and T. Hampp.
1999.
Maximiz-ing text-mining performance.
IEEE Intel.
Sys.,14(4):63-69.J.P.
Yamron, I. Carp, L. Gillick, S. Lowe, andP.
van Mulbregt.
1998.
A Hidden MarkovModel approach to text segmentation a d eventtracking.
Proc.
of ICASSP'99, pages 333-336.44
