Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1116?1126,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsJoint Dependency Parsing and Multiword Expression TokenisationAlexis Nasr, Carlos Ramisch, Jos?e Deulofeu, Andr?e ValliAix Marseille Universit?e, CNRS, LIF UMR 7279Marseille, FranceFirstName.LastName@lif.univ-mrs.frAbstractComplex conjunctions and determinersare often considered as pretokenized unitsin parsing.
This is not always realistic,since they can be ambiguous.
We pro-pose a model for joint dependency parsingand multiword expressions identification,in which complex function words are rep-resented as individual tokens linked withmorphological dependencies.
Our graph-based parser includes standard second-order features and verbal subcategoriza-tion features derived from a syntactic lex-icon.We train it on a modified version ofthe French Treebank enriched with mor-phological dependencies.
It recognizes81.79% of ADV+que conjunctions with91.57% precision, and 82.74% of de+DETdeterminers with 86.70% precision.1 IntroductionStandard NLP tool suites for text analysis are of-ten made of several processes that are organizedas a pipeline, in which the input of a process isthe output of the preceding one.
Among theseprocesses, one commonly finds a tokenizer, whichsegments a sentence into words, a part-of-speech(POS) tagger, which associates to every word apart-of-speech tag, and a syntactic parser, whichbuilds a parse tree for the sentence1.
These threeprocesses correspond to three formal operationson the string: segmentation into linguistically rel-evant units (words), tagging the words with POStags and linking the (word, POS) pairs by meansof syntactic dependencies.This setup is clearly not ideal, as some decisionsare made too early in the pipeline (Branco andSilva, 2003).
More specifically, some tokenizationand tagging choices are difficult to make without1This paper considers dependency syntactic structures.taking syntax into account.
To avoid the pitfall ofpremature decisions, probabilistic tokenizers andtaggers can produce several solutions in the formof lattices (Green and Manning, 2010; Goldbergand Elhadad, 2011).
Such approaches usually leadto severe computational overhead due to the hugesearch space in which the parser looks for the opti-mal parse tree.
Besides, the parser might be biasedtowards short solutions, as it compares scores oftrees associated to sequences of different lengths(De La Clergerie, 2013).This problem is particularly hard when parsingmultiword expressions (MWEs), that is, groups oftokens that must be treated as single units (Bald-win and Kim, 2010).
The solution we presentin this paper is different from the usual pipeline.We propose to jointly parse and tokenize MWEs,transforming segmentation decisions into linkingdecisions.
Our experiments concentrate on twodifficult tokenization cases.
Hence, it is the parserthat will choose, in such cases, whether to groupor not several tokens.Our first target phenomenon is the family ofADV+que constructions, a type of complex con-junction in French.
They are formed by adverbslike bien (well) or ainsi (likewise) followed by thesubordinative conjunction que (that).
They func-tion like English complex conjunctions so that andnow that.
Due to their structure, ADV+que con-structions are generally ambiguous, like in the fol-lowing examples:1.
Je mange bien que je n?aie pas faimI eat although I am not hungry2.
Je pense bien que je n?ai pas faimI think indeed that I am not hungryIn example 1, the sequence bien que forms acomplex conjunction (although) whereas in exam-ple 2, the adverb bien (indeed) modifies the verbpense (think), and the conjunction que (that) intro-duces the sentential complement je n?ai pas faim1116(I am not hungry).
In treebanks, the different read-ings are represented through the use of words-with-spaces in the case of complex conjunctions.Our second target phenomenon is the family ofpartitive articles which are made of the prepositionde (of ) followed by the definite determiner le, la,l?
or les2(the).
These de+DET constructions areambiguous, as shown in the following examples:3.
Il boit de la bi`ereHe drinks some beer4.
Il parle de la bi`ereI talks about the beerIn example 3, the sequence de la forms a deter-miner (some) whereas in example 4, de is a prepo-sition (about) and la is the determiner (the) of thenoun bi`ere (bi`ere).We focus on these constructions for two rea-sons.
First, because they are extremely frequent.For instance, in the frWaC corpus, from a total of54.8M sentences, 1.15M sentences (2.1%) containone or more occurrences of our target ADV+queconstructions and 26.7M sentences (48.6%) con-tain a de+DET construction (see Tables 1 and 2).Moreover, in a corpus of 370 M words in French,3des is the 7thmost frequent word.
Second, be-cause they are perfect examples of phenomenawhich are difficult to process by a tokenizer.
In or-der to decide, in example 1, that bien que is a com-plex subordinate conjunction, non-trivial morpho-logical, lexical and syntactic clues must be takeninto account, such as the subcategorization frameof the verb of the principal clause and the mood ofthe subordinate clause.
All these clues are difficultto take into account during tokenization, where thesyntactic structure of the sentence is not yet ex-plicit.Ask the parser to perform tokenization will notalways solve the problem.
Even state-of-the-artparsers can fail to predict the right structure forthe cases we are dealing with.
The main reasonis that they are trained on treebanks of limitedsize, and some lexico-syntactic phenomena can-not be well modeled.
This brings us to the sec-ond topic of this paper, which is the integration ofexternal linguistic resources in a treebank-trainedprobabilistic parser.
We show that, in order to cor-2Sequences de le and de les do not appear as such inFrench.
They have undergone a morpho-phonetic processknown as amalgamation and are represented as tokens du anddes.
In our pipeline, they are artificially detokenized.3Newspaper Le Monde from 1986 to 2002.rectly solve the two problems at hand, the parsermust have access to lexico-syntactic informationthat can be found in a syntactic lexicon.
We pro-pose a simple way to introduce such information inthe parser by defining new linguistic features thatblend smoothly with treebank features used by theparser when looking for the optimal parse tree.The paper is organized as follows: Section 2 de-scribes related work on MWE parsing.
Section 3proposes a way to represent multiword units bymeans of syntactic dependencies.
In Section 4, webriefly describe the parser that has been used inthis work, and in Section 5, we propose a way tointegrate a syntactic lexicon into the parser.
Sec-tion 6 describes the data sets used for the experi-ments, which results are presented and discussedin Section 7.
Section 8 concludes the paper.2 Related WorkThe famous ?pain-in-the-neck?
article by Sag etal.
(2002) discusses MWEs in parsers, contrastingtwo representation alternatives in the LinGO ERGHPSG grammar of English: compositional rulesand words-with-spaces.
The addition of composi-tional rules for flexible MWEs has been tested in asmall-scale experiment which showed significantcoverage improvements in HPSG parsing by theaddition of 21 new MWEs to the grammar (Villav-icencio et al, 2007).It has been demonstrated that pre-groupingMWEs as words-with-spaces can improve the per-formance of shallow parsing for English (Ko-rkontzelos and Manandhar, 2010).
Nivre and Nils-son (2004) obtained similar results for dependencyparsing of Swedish.
They compare models trainedon two representations: one where MWEs arelinked by a special ID dependency, and anotherone based on gold pre-tokenization.
Their resultsshow that the former model can recognize MWEswith F1=71.1%, while the latter can significantlyimprove parsing accuracy and robustness in gen-eral.
However, the authors admit that ?it remainsto be seen how much of theoretically possible im-provement can be realized when using automaticmethods for MWU recognition?.Several methods of increasing complexity havebeen proposed for fully automatic MWE tokeniza-tion: simple lexicon projection onto a corpus(Kulkarni and Finlayson, 2011), synchronous lex-icon lookup and parsing (Wehrli et al, 2010; Sere-tan, 2011), token-based classifiers trained using1117association measures and other contextual features(Vincze et al, 2013a), or contextual sequencemodels like conditional random fields (Constantand Sigogne, 2011; Constant et al, 2013b; Vinczeet al, 2013b) and structured perceptron (Schnei-der et al, 2014).
In theory, compound functionwords like ADV+que and de+DET allow no inter-nal variability, thus they should be represented aswords-with-spaces.
However, to date no satisfac-tory solution has been proposed for automaticallytokenizing ambiguous MWEs.Green et al (2013) propose a constituency pars-ing model which, as a by-product, performs MWEidentification.
They propose a flat representationfor contiguous expressions in which all elementsare attached to a special node, and then they com-pare several parsing models, including an origi-nal factored-lexicon PCFG and a tree substitutiongrammar.
These generic parsing models can beused for parsing in general, but they have inter-esting memorization properties which favor MWEidentification.
Their experiments on French andArabic show that the proposed models beat thebaseline in MWE identification while producingacceptable general parsing results.Candito and Constant (2014) and Vincze et al(2013c) present experiments on dependency pars-ing for MWE identification which are the closestto our settings.
Vincze et al (2013c) focus on lightverb constructions in Hungarian.
They proposedistinguishing regular verbal dependencies fromlight verbs and their complements through fourspecial labels prefixed by LCV-.
Then, they trainthe Bohnet parser (Bohnet, 2010) using standardparameters and features, and evaluate on a goldtest set.
They report no significant changes in at-tachment scores, whereas F1 for light verb iden-tification is 75.63%, significantly higher than thebaseline methods of lexicon projection (21.25%)and classification (74.45%).Candito and Constant (2014) compare severalarchitectures for dependency parsing and MWEidentification in French.
For regular MWEs likenoun compounds, they use regular expressions toautomatically generate an internal syntactic struc-ture, combining standard and MWE-dedicated de-pendency labels.
Irregular expressions like com-plex conjunctions are represented as separate to-kens, with a special DEP CPD dependency thatlinks all tokens to the first MWE word (Constantet al, 2013a).
They compare different architec-tures for MWE identification before, during andafter parsing, showing that the best architecturedepends on whether the target MWEs are regularor irregular.Similarly to these two papers, we use a specialdependency to model MWEs and evaluate pars-ing and identification accuracy.
Our work departsfrom theirs on three important aspects.
First, weconcentrate on syntactically irregular compounds,that we represent with a new kind of dependency.Second, we integrate into the parser a syntacticlexicon in order to help disambiguate ADV+queand de+DET constructions.
Third, we built a spe-cific evaluation corpus to get a better estimation ofthe performances of our model on ADV+que andde+DET constructions.3 The MORPH DependencyIn order to let the parser take the tokenization de-cisions, we propose not to group sequences of to-kens of the form ADV+que and de+DET at tok-enization time.
Instead, we transform the task ofsegmentation decision into a parsing decision task.We associate a syntactic structure to ADV+queand de+DET constructions by introducing a newtype of dependency that we call MORPH.
It is nota standard syntactic dependency, but a reminiscentof the morphological dependencies of Mel?
?cuk(1988), similar to the DEP CPD label proposed byCandito and Constant (2014) or the ID depen-dency of Nivre and Nilsson (2004), except that wefocus on syntactically-motivated MWEs, propos-ing a regular structure for them.The syntactic structures of examples 1 and 2,introduced in Section 1, are represented below4.Example 1.CLS VRB ADV CSU ... VRB ...Je mange bien que ... aie ...SUJMODMORPHOBJExample 2.CLS VRB ADV CSU ... VRB ...Je pense bien que ... ai ...SUJOBJMODOBJ4In the examples, parts of speech CLS, VRB, ADV and CSUrespectively stand for subject clitic pronoun, verb, adverb andsubordinating conjunction.
Syntactic labels SUJ, MOD, OBJ,DE-OBJ and SPE stand for subject, modifier, object, indirectobject introduced by the preposition de and specifier.1118In example 1, the complex conjunction bien queis represented by the presence of the MORPH de-pendency, whereas, in example 2, the adverb bienmodifies the verb pense and que introduces its ob-ject.
From an NLP perspective, the two readingsare treated the same way by the tokenizer and thetagger.
It is only at parsing time that the presenceof the complex conjunction is predicted.The syntactic structures of examples 3 and 4 arerepresented below.
In example 3, the partitive ar-ticle de la is represented by means of the MORPHdependency.
Example 4 exhibits a standard prepo-sitional phrase structure.Example 3.CLI VRB PRE DET NOMIl boit de la bi`ereSUJOBJSPEMORPHExample 4.CLI VRB PRE DET NOMIl parle de la bi`ereSUJ DE-OBJOBJSPE4 ParsingThe parser used in this study is a second-ordergraph-based parser (K?ubler et al, 2009).
Givena sentence W = w1.
.
.
wl, the parser looks for thedependency tree?T of W that maximizes the scores:?T = argmaxT?T (W )?F?F(T )s(F )where T (W ) is the set of all possible depen-dency trees for sentence W and F(T ) is the set ofall relevant subparts, called factors, of tree T ands(F ) is the score of factor F .
The values of thesescores are parameters estimated during training.We can define different models of increasingcomplexity depending on the decomposition of thetree into factors.
The most simple one is the arc-factored or first-order model, which simply de-composes a tree into single dependencies and as-signs them a score, independently of their context.We used a second-order parser which decomposesa tree into factors of three types:1. first-order factors, made of one dependency;2. sibling factors, made of two dependenciessharing a common governor;3. grandchildren factors, made of two depen-dencies where the dependent of one of themis the governor of the other one.5 Integration with a Syntactic LexiconAlthough this kind of parsers achieve state-of-the-art performances (Bohnet, 2010), their predictionsare limited to the phenomena that occur in the tree-banks they are trained on.
In particular, they of-ten fail at correctly distinguishing elements thatare subcategorized by a verb (henceforth comple-ments) from others (modifiers).
This is due to thefact that the nature and number of the comple-ments is specific to each verb.
If the verb did notoccur, or did not occur often enough, in the tree-bank, the nature and number of its complementswill not be correctly modeled by the parser.A precise description of verb complementsplays an important role in the task of predictingthe MORPH dependency, as we illustrate in exam-ple 1.
In this example, the verb manger (eat) doesnot accept an object introduced by the subordinateconjunction que (that) .
This is a vital informationin order to predict the correct syntactic structureof the sentence.
If the parser cannot link the con-junction que to the verb manger with an OBJ de-pendency, then it has to link it with a MOD depen-dency (it has no other reasonable solution).
Butque by itself cannot be a MOD of the verb unless itis a complex conjunction.
The parser has thereforeno other choice than linking que with the adverbusing a MORPH dependency.In order to help the parser build the rightsolution in such cases, we have introduced infor-mation derived from a syntactic lexicon in theparser.
The syntactic lexicon associates, eachverb lemma, the features +/-QUE and +/-DE, thatindicate respectively if the verb accepts an objectintroduced by the subordinating conjunction queand by the preposition de.
The verbs of ourexamples would have the following values:manger -QUE -DEpenser +QUE -DEboire -QUE -DEparler -QUE +DEWe will call such features subcat features (SFs).The semantics of positive feature values are quitedifferent from the semantics of negative ones.
Theformer indicates that a verb may (but does not needto) license a complement introduced by the con-junction que or the preposition de, whereas the1119latter indicates that the verb cannot license such acomplement.
Negative feature values have, there-fore, a higher predictive power.Every verbal lemma occurrence in the treebankis enriched with subcat features and three new fac-tor templates have been defined in the parser in or-der to model the co-occurrence of subcat featuresand some syntactic configurations.
These tem-plates are represented in Figure 1.
The first one isa first-order template and the others are grandchil-dren templates.
In the template description, G, Dand GD stand respectively for governor, dependentand grand-dependent.
SF, POS, FCT and LEM re-spectively stand for subcat feature, part of speech,syntactic function and lemma.1 G.SF G.POS D.FCT D.POS2 G.SF G.POS D.FCT D.POS GD.POS3 G.SF G.POS D.FCT D.LEM GD.POSFigure 1: Factor templates modeling the co-occurrence of subcat features and syntactic con-figurations.Two factors, of the types 1 and 3, have been rep-resented in Figure 2.
The first one models the co-occurrence of subcat feature -QUE and an objectintroduced by a subordinating conjunction.
Suchfeature will receive a negative score at the endof training, since a verb having the -QUE featureshould not license a direct object introduced bya subordinating conjunction.
The second featuremodels the co-occurrence of the feature -QUE anda modifier introduced by the subordinating con-junction QUE and having an adverb as a depen-dent.
Such a feature will receive a positive score.1 -QUE VRB OBJ CSU3 -QUE VRB MOD QUE ADVFigure 2: Two factors modeling the co-occurrenceof subcat features and syntactic configurations.6 Experimental SetupWe test the proposed model to verify the linguisticplausibility and computational feasibility of usingMORPH links to represent syntactically idiosyn-cratic MWEs in a dependency parser enrichedwith subcat features.
Therefore, we train a prob-abilistic dependency parsing model on modifiedtreebank, representing ADV+que and de+DET con-structions using this special syntactic relation in-stead of pretokenization.
Furthermore, in additionto regular features learned from the treebank, wealso introduce and evaluate subcat features basedon a lexicon of verbal valency, which helps iden-tifying subordinative clauses and de prepositionalphrases (see Section 5).
We evaluate parsing pre-cision and MWE identification on a test treebankand, more importantly, on a dataset built specifi-cally to study the representation of our target con-structions.
All experiments used the NLP toolsuite MACAON5, which comprises a second-ordergraph-based parser.6.1 Data Sets and ResourcesFrench Treebank (FTB) The parser was trainedon the French Treebank, a syntactically annotatedcorpus of news articles from Le Monde (Abeill?e etal., 2003).
We used the version which was trans-formed into dependency trees by Candito et al(2009), and which was also used by Candito andConstant (2014) for experiments on MWE pars-ing.
We used a standard split of 9,881 sentences(278K words) for training and 1,235 sentencesfor test (36K words).
We applied simple rules totransform the flat representation of ADV+que andde+DET constructions into MORPH-linked individ-ual tokens.
All other MWEs are kept unchanged intraining and test data.
They are represented as sin-gle tokens, not decomposed into individual words.MORPH Dataset The test portion of the FTBcontains relatively few instances of our target con-structions (see Tables 4 and 6).
Thus, we havecreated two specific data sets to evaluate the pre-diction of MORPH links.
As for ADV+que con-structions, we manually selected the 7 most po-tentially ambiguous combinations from the top-20most frequent combinations in the French Web asCorpus ?
frWaC (Baroni and Bernardini, 2006).6As for de+DET constructions, we selected all 4possible combinations.
For each target ADV+queand de+DET construction, we randomly selected1,000 sentences from the frWaC based on two cri-teria: (1) sentences should contain only one oc-currence of the target construction and (2) sen-tences should have between 10 and 20 words, toavoid distracting the annotators while still provid-ing enough context.
Additionally, for de+DET weselected only sentences in which a verb precededthe construction, in order to minimize the occur-5http://macaon.lif.univ-mrs.fr6http://wacky.sslmit.unibo.it/1120ADV+que #sent conj.
other #occurainsi 103 76.7 23.3 498,377alors 110 88.2 11.8 291,235autant 107 86.0 14.0 39,401bien 99 37.4 62.6 156,798encore 93 21.5 78.5 18,394maintenant 120 55.8 44.2 16,567tant 98 20.4 79.6 168,485Total 730 56.4 43.6 1,189,257Table 1: Annotations for ADV+que combinationsin MORPH dataset: number of annotated sen-tences, proportion (%) of complex conjunctionuses (MORPH) and other uses, number of occur-rences in frWaC.de+DET #sent det.
other #occurle (du) 136 33.1 66.9 16,609,049la 138 21.0 79.0 10,849,384les (des) 129 77.5 22.5 23,395,857l?
136 16.9 83.1 8,204,687Total 539 36.5 63.5 59,058,977Table 2: Annotations for de+DET combina-tions MORPH dataset: number of annotated sen-tences, proportion (%) of complex determiner uses(MORPH) and other uses, number of occurrencesin frWaC.rence of nominal complements (pr?esident de lar?epublique - president of the republic) and focuson the determiner/preposition ambiguity.
Two ex-pert French native speakers annotated around 100sentences per construction.
Malformed or am-biguous sentences were discarded.
Disagreementswere either discussed and resolved or the sentencewas discarded.7We can see in Table 1 that ADV+que construc-tions are highly ambiguous, with 56.4% of thecases being complex conjunctions.
However, theyalso present high variability: even though theyshare identical syntactic behavior, some of themtend to form complex conjunctions very often(alors) while others occur more often in other syn-tactic configurations (tant and encore).
As one cansee in Table 2, de+DET sequences tend to functionas prepositions followed by a determiner with thenotable exception of de les.
The reason is that de7The dataset is available at http://pageperso.lif.univ-mrs.fr/%7Ecarlos.ramisch/?page=downloads/morphles (actually the amalgame des) is actually the plu-ral of the indefinite article (un), used with any plu-ral noun, while the other determiners are partitivesthat tend to be used only with massive nouns.
Thelast column of these tables shows the number ofoccurrences of each construction in the frWaC cor-pus.
We can see that they are very recurrent com-binations, specially de+DET constructions, whichaccount for 3.7% of the total number of bigramsin the corpus.
This underlines the importance ofcorrectly predicting their syntactic structure in aparser.DicoValence Lexicon DicoValence (van denEynde and Mertens, 2003) is a lexical resourcewhich lists the subcategorization frames of morethan 3, 700 French verbs.8It describes morespecifically the number and nature of the verbs?complements.
Dicovalence gives a more fine-grained description of the complements than whatis needed in our feature templates.
We have onlykept, as described in Section 5, the subcat features-QUE, +QUE, -DE and +DE of each verb.
Table 3below shows the number of verbal entries havingeach of our four subcat features.
Although thenumber of verbs described in DicoValence is mod-erate, its coverage is high on our data sets.
It isequal to 97.82% on the FTB test set and is equalto 95.48% on the MORPH dataset.-QUE +QUE -DE +DE3,814 356 3,450 720Table 3: Number of verbs in DicoValence pervalue of subcat feature.6.2 EvaluationWe evaluate our models on two aspects: parsingquality and MWE identification (Nivre and Nils-son, 2004; Vincze et al, 2013c; Candito and Con-stant, 2014).
First, we use standard parsing at-tachment scores to verify whether our models im-pact parsing performance in general.
We comparethe generated dependency trees with the referencein the test portion of the FTB, reporting the pro-portion of matched links, both in terms of struc-ture ?
unlabeled attachment score (UAS) ?
and oflabeled links ?
labeled attachment score (LAS).Since our focus is on MWE parsing, we are also8http://bach.arts.kuleuven.be/dicovalence/1121interested in MWE identification metrics.
We fo-cus on words whose dependency label is MORPHand calculate the proportion of correctly predictedMORPH links among those in the parser output(precision), among those in the reference (recall)and the F1 average.
Since some of the phenomenaare quite rare in the FTB test portion, we focuson the MORPH dataset, which contains around 100instances of each target construction.We compare our approach with two simplebaselines.
The first one consists in pretokenizingADV+que systematically as a single token, whilede+DET is systematically left as two separate to-kens.
This baseline emulates the behavior of mostparsing pipelines, which deal with functional com-plex words during tokenization.
This correspondsto choosing the majority classes in the last row ofTables 1 and 2.
For ADV+que, the precision of thebaseline is 56.4%.
If we assume recall is 100%,this yields an F1 score of 72.2%.
For de+DET,however, recall is 0% since no MORPH link is pre-dicted at all.
Therefore, we only look at the base-line?s precision of 63.5%.
A second, slightly moresophisticated baseline, consists in choosing themajority class for each individual construction andaverage precisions over the constructions.
In thiscase, the average precision is 75.3% for ADV+queand 76.6% for de+DET.We compare our model to the one proposedby Green et al (2013).
We used the pretrainedmodel available as part of the Stanford parser9.Their model outputs constituent trees, which wereautomatically converted to unlabeled dependencystructures.
We ignore the nature of the dependencylink, only checking whether the target constructionelements are linked in the correct order.Our experiments use the MACAON tool suite.For the FTB, gold POS and gold lemmas are givenas input to the parser.
In the case of the MORPHdataset, for which we do not have gold POS andlemmas, they are predicted by MACAON.
The firstbest prediction is given as input to the parser.7 Evaluation Results7.1 ADV+que ConstructionsTable 4 reports the performances of the parser10on the test set of FTB.
The rows of the table9http://nlp.stanford.edu/software/lex-parser.shtml10Trained on the modified train set of the FTB, where com-plex conjunctions and partitive determiners have been repre-sented by means of the MORPH dependencySF LAS UAS MORPH Prec.
Rec.no 88.98 90.63 27 87.10 100yes 88.96 90.56 27 81.81 100Table 4: Attachment scores, count, precision andrecall of the MORPH dependency for ADV+que inFTB test, without and with subcat features (SF).respectively display the results obtained withoutand with the use of subcat features (SF).
The sec-ond and third columns represent standard attach-ment metrics, column four displays the number ofADV+que conjunctions present in the FTB test setFTB and the two last columns show the precisionand recall of the MORPH dependency prediction.The table shows that the number of occurrencesof ADV+que conjunctions is very small (27).
It istherefore difficult draw clear conclusions concern-ing the task of predicting the MORPH dependency.The precision and recall have nevertheless been re-ported.
The recall is perfect (all MORPH depen-dencies have been predicted) and the the precisionis reasonable (the parser overpredicts a little).
Thetable also shows that the use of subcat features isnot beneficial, as attachment scores as well as pre-cision decrease.
The decrease of precision is mis-leading, though, due to the small number of occur-rences it has been computed on.Table 5 displays the precision, recall and F1 ofthe prediction of the MORPH dependency on the730 ADV+que sentences of the MORPH dataset,without and with the use of subcat features.
Thescores obtained are lower than the same experi-ments on the FTB.Precision is higher than recall,which indicates that the parser has a tendency tounderpredict.
We also present the precision ofthe two baselines described in Section 6.2.
Onlyin two cases the per-construction majority base-line (indiv.)
outperforms our parser without sub-cat features.
These two constructions do not tendto form complex conjunctions, that is, the parserovergenerates MORPH dependencies.
Here, subcatfeatures help increasing precision, systematicallyoutperforming the baselines.The introduction of subcat features has a ben-eficial but limited impact on the results, increas-ing precision and lowering a bit recall, augment-ing the tendency of the parser to under predictMORPH dependencies.
Overall, our models aremore precise than the Stanford parser at predict-ing MORPH links, specially for bien que and en-1122Baseline prec.
Green et Without SF With SFADV+que global indiv.
al.
(2013) Prec.
Recall F1 Prec.
Recall F1ainsi que 76.7 76.7 81.44 96.00 91.14 93.50 95.94 89.87 92.81alors que 88.2 88.2 95.10 92.78 92.78 92.78 93.81 93.81 93.81autant que 86.0 86.0 92.00 86.95 65.21 74.53 86.66 70.65 77.84bien que 37.4 62.6 55.22 86.84 89.18 88.00 91.66 89.18 90.41encore que 21.5 78.5 64.52 72.72 80.00 76.19 92.85 65.00 76.47maintenant que 55.8 55.8 87.01 85.24 77.61 81.25 90.91 74.62 81.96tant que 20.4 79.6 90.91 78.94 75.00 76.92 82.35 70.00 75.67Total 56.4 75.3 83.06 88.71 82.03 85.24 91.57 81.79 86.41Table 5: MORPH link prediction for ADV+que constructions: precision of global majority baseline, preci-sion of individual per-construction baseline, precision of Green et al (2013) constituent parser, precision,recall and F1 of our dependency parser without and with subcat features.core que.
However, this is not verified for all in-dividual ADV+que constructions.
The table alsoshows an important variety among the seven com-plex conjunctions studied.
Some of them are verywell predicted (F1 = 93.5) while others are poorlypredicted (F1 = 75.67).
This is partly due to thetendency of some ADV+que sequences to be partof larger frozen or semi-frozen constructions andto be used with a different semantico-syntactic be-havior.
An error analysis performed on the tantque sequence revealed that 40% of the errors weredue to the occurrence of tant que as part of thelarger en tant que expression, while 20% of theerrors were due to the usage of tant que as a com-parative expression.7.2 de+DET ConstructionsSF LAS UAS MORPH Prec.
Rec.no 89.02 90.23 145 85.85 81.12yes 88.37 89.67 145 86.52 83.92Table 6: Attachment scores, count, precision andrecall of the MORPH dependency for de+DET inFTB test, without and with subcat features (SF).Table 6 reports the results of the same experi-ments on de+DET constructions.
It shows that thefrequency of de+DET constructions is higher thanADV+que constructions.
It also shows that the in-troduction of subcat features has a positive impacton the prediction of the MORPH dependency, but anegative effect on the attachment scores.Table 7 reveals that the prediction of the correctstructure of de+DET constructions is more difficultthan that of ADV+que constructions for the parser.Here, not only the majority class is the non-MWEanalysis (63.5%), but also there is higher ambigu-ity because of nominal and adverbial complementsthat have the same structure.
This impacts the per-formance of the Stanford parser, which overgener-ates MORPH links, achieving the lowest precisionfor all constructions except for des.
Results alsoshow that the introduction of subcat features hasan important impact on the quality of the predic-tion (F1 jumps from 75% to 84.67%).
The useof subcat features slightly improves the identifi-cation of de les, which is a determiner most ofthe time.
On the other hand, it greatly improvesF1 for other constructions, which appear less of-ten as determiners.
We believe that the higher im-pact of subcat frames on de+DET is mainly due tothe fact that the number of verbs licensing comple-ments introduced by the preposition de is higherthan the number of verbs licensing complementsintroduced by the conjunction que (see Table 3).Therefore, the parser trained without subcat fea-tures can only rely on the examples present in theFTB which are proportionally smaller in the firstcase than in the second.8 ConclusionsThis paper introduced and evaluated a joint pars-ing and MWE identification model that can ef-fectively detect and represent ambiguous com-plex function words.
The difficulty of process-ing such expressions is underestimated becauseof their limited variability.
They often are pre-grouped as words-with-spaces in many parsing ar-chitectures (Sag et al, 2002).
However, we didnot use gold tokenization, unrealistic for ambigu-ous MWEs (Nivre and Nilsson, 2004; Korkontze-1123Baseline prec.
Green et Without SF With SFde+DET global indiv.
al.
(2013) Prec.
Recall F1 Prec.
Recall F1de le 66.9 79.0 56.96 72.50 64.44 68.23 85.41 91.11 88.17de la 79.0 77.5 22.83 58.13 86.20 69.44 81.25 89.65 85.24de les 22.5 66.9 87.72 97.36 74.00 84.09 98.70 76.00 85.87de l?
83.1 83.1 18.55 57.14 69.56 62.74 64.51 86.95 74.07Total 63.5 76.6 44.37 77.00 73.09 75.00 86.70 82.74 84.67Table 7: MORPH link prediction for de+DET constructions: precision of global majority baseline, preci-sion of individual per-construction baseline, precision of Green et al (2013) constituent parser, precision,recall and F1 of our dependency parser without and with subcat features.los and Manandhar, 2010).We proposed to deal with these constructionsduring parsing, when the required syntactic infor-mation to disambiguate them is available.
Thus,we trained a graph-based dependency parser on amodified treebank where complex function wordswere linked with a MORPH dependency.
Our re-sults demonstrate that a standard parsing modelcan correctly learn such special links and predictthem for unseen constructions.
Nonetheless, themodel is more accurate when we integrate exter-nal information from a syntactic lexicon.
Thisimproved precision for ADV+que and speciallyde+DET constructions.
For the latter, F1 improvedin almost 10%, going from 75% to 84.61%.This study raised several linguistic and compu-tational questions.
Some complex function wordsinclude more than two elements, like si bien que(so much that) and d?autant (plus) que (especiallyas).
Moreover, they may contain nested expres-sions with different meanings and structures, e.g.tant que (as long as) is a conjunction but en tantque (as) is a preposition.
The same applies forquantified partitive determiners, like beaucoup de(much) and un (petit) peu de (a (little) bit of ).Their identification and representation is plannedas a future extension to this work.We also would like to compare our approach tosequence models (Schneider et al, 2014).
Care-ful error analysis could help us understand inwhich cases syntactic features can help.
More-over, different variants of the syntactic featuresand more sophisticated representation for syntac-tic lexicons can help improve MWE parsing fur-ther.
For instance, we represent the subcat fea-tures of pronominal verbs and their simple ver-sions with the same features, but they should bedistinguished, e.g.
se rappeler (remember) is +DEbut rappeler (remind) is -DE.AcknowledgementsThis work has been funded by the French AgenceNationale pour la Recherche, through the projectsORFEO (ANR-12-CORP-0005) and ASFALDA(ANR-12-CORD-023) and by FAPERGS andCNRS through the AIM-WEST project.ReferencesAnne Abeill?e, Lionel Cl?ement, and Franc?ois Tou-ssenel.
2003.
Building a treebank for french.
InAnne Abeill?e, editor, Treebanks: building and usingparsed corpora, pages 165?168.
Kluwer academicpublishers, Dordrecht, The Netherlands.Timothy Baldwin and Su Nam Kim.
2010.
Multi-word expressions.
In Nitin Indurkhya and Fred J.Damerau, editors, Handbook of Natural LanguageProcessing, pages 267?292.
CRC Press, Taylor andFrancis Group, Boca Raton, FL, USA, 2 edition.Marco Baroni and Silvia Bernardini, editors.
2006.Wacky!
Working papers on the Web as Corpus.GEDIT, Bologna, Italy.
224 p.Bernd Bohnet.
2010.
Top accuracy and fast depen-dency parsing is not a contradiction.
In Huang andJurafsky (Huang and Jurafsky, 2010), pages 89?97.Ant?onio Horta Branco and Jo?ao Ricardo Silva.
2003.Contractions: Breaking the tokenization-tagging cir-cularity.
In Nuno J. Mamede, Jorge Baptista, IsabelTrancoso, and Maria das Grac?as Volpe Nunes, ed-itors, Proc.
of the 6th PROPOR (PROPOR 2003),volume 2721 of LNCS (LNAI), pages 195?195, Faro,Portugal, Jun.
Springer.Marie Candito and Matthieu Constant.
2014.
Strate-gies for contiguous multiword expression analysisand dependency parsing.
In Proc.
of the 52nd ACL(Volume 1: Long Papers), pages 743?753, Balti-more, MD, USA, Jun.
ACL.Marie Candito, Beno?
?t Crabb?e, Pascal Denis, andFranc?ois Gu?erin.
2009.
Analyse syntaxique dufranc?ais : des constituants aux d?ependances.
In1124Proc.
of Traitement Automatique des Langues Na-turelles, Senlis, France, Jun.Matthieu Constant and Anthony Sigogne.
2011.MWU-aware part-of-speech tagging with a CRFmodel and lexical resources.
In Kordoni et al (Kor-doni et al, 2011), pages 49?56.Matthieu Constant, Marie Candito, and Djam?e Sed-dah.
2013a.
The LIGM-Alpage architecture forthe SPMRL 2013 shared task: Multiword expres-sion analysis and dependency parsing.
In Proceed-ings of the Fourth Workshop on Statistical Parsingof Morphologically-Rich Languages, pages 46?52,Seattle, Washington, USA, October.
Association forComputational Linguistics.Matthieu Constant, Joseph Le Roux, and Anthony Si-gogne.
2013b.
Combining compound recognitionand PCFG-LA parsing with word lattices and condi-tional random fields.
ACM Trans.
Speech and Lang.Process.
Special Issue on MWEs: from theory topractice and use, part 2 (TSLP), 10(3).Eric De La Clergerie.
2013.
Exploring beam-basedshift-reduce dependency parsing with DyALog: Re-sults from the SPMRL 2013 shared task.
In Pro-ceedings of the Fourth Workshop on Statistical Pars-ing of Morphologically-Rich Languages, pages 53?62, Seattle, Washington, USA, October.
Associationfor Computational Linguistics.Yoav Goldberg and Michael Elhadad.
2011.
Joint he-brew segmentation and parsing using a PCFGLA lat-tice parser.
In Proc.
of the 49th ACL: HLT (ACLHLT 2011), pages 704?709, Portland, OR, USA,Jun.
ACL.Spence Green and Christopher D. Manning.
2010.Better Arabic parsing: Baselines, evaluations, andanalysis.
In Huang and Jurafsky (Huang and Juraf-sky, 2010), pages 394?402.Spence Green, Marie-Catherine de Marneffe, andChristopher D. Manning.
2013.
Parsing modelsfor identifying multiword expressions.
Comp.
Ling.,39(1):195?227.Chu-Ren Huang and Dan Jurafsky, editors.
2010.Proc.
of the 23rd COLING (COLING 2010), Beijing,China, Aug.
The Coling 2010 Organizing Commit-tee.Valia Kordoni, Carlos Ramisch, and Aline Villavicen-cio, editors.
2011.
Proc.
of the ACL Workshop onMWEs: from Parsing and Generation to the RealWorld (MWE 2011), Portland, OR, USA, Jun.
ACL.Ioannis Korkontzelos and Suresh Manandhar.
2010.Can recognising multiword expressions improveshallow parsing?
In Proc.
of HLT: The 2010 AnnualConf.
of the NAACL (NAACL 2003), pages 636?644,Los Angeles, California, Jun.
ACL.S.
K?ubler, R. McDonald, and J. Nivre.
2009.
Depen-dency parsing.
Synthesis Lectures on Human Lan-guage Technologies, 1(1):1?127.Nidhi Kulkarni and Mark Finlayson.
2011. jMWE: AJava toolkit for detecting multi-word expressions.
InKordoni et al (Kordoni et al, 2011), pages 122?124.Igor A.
Mel??cuk.
1988.
Dependency Syntax: Theoryand Practice.
State University of New York Press,New York.Joakim Nivre and Jens Nilsson.
2004.
Multiword unitsin syntactic parsing.
In Proc.
of the LREC Work-shop on Methodologies and Evaluation of Multi-word Units in Real-World Applications (MEMURA),Lisbon, Portugal.Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-take, and Dan Flickinger.
2002.
Multiword expres-sions: A pain in the neck for NLP.
In Proc.
of the3rd CICLing (CICLing-2002), volume 2276/2010of LNCS, pages 1?15, Mexico City, Mexico, Feb.Springer.Nathan Schneider, Emily Danchik, Chris Dyer, andA.
Noah Smith.
2014.
Discriminative lexical se-mantic segmentation with gaps: Running the mwegamut.
Transactions of the Association of Compu-tational Linguistics ?
Volume 2, Issue 1, pages 193?206.Violeta Seretan.
2011.
Syntax-Based Collocation Ex-traction, volume 44 of Text, Speech and LanguageTechnology.
Springer, Dordrecht, Netherlands, 1stedition.
212 p.Karel van den Eynde and Piet Mertens.
2003.
La va-lence: l?approche pronominale et son application aulexique verbal.
Journal of French Language Studies,(13):63?104.Aline Villavicencio, Valia Kordoni, Yi Zhang, MarcoIdiart, and Carlos Ramisch.
2007.
Validation andevaluation of automatically acquired multiword ex-pressions for grammar engineering.
In Jason Eis-ner, editor, Proc.
of the 2007 Joint Conference onEMNLP and Computational NLL (EMNLP-CoNLL2007), pages 1034?1043, Prague, Czech Republic,Jun.
ACL.Veronika Vincze, Istv?an Nagy T., and Rich?ard Farkas.2013a.
Identifying English and Hungarian light verbconstructions: A contrastive approach.
In Proc.
ofthe 51st ACL (Volume 2: Short Papers), pages 255?261, Sofia, Bulgaria, Aug. ACL.Veronika Vincze, Istv?an Nagy T., and J?anos Zsibrita.2013b.
Learning to detect english and hungarianlight verb constructions.
ACM Trans.
Speech andLang.
Process.
Special Issue on MWEs: from theoryto practice and use, part 1 (TSLP), 10(2).Veronika Vincze, J?anos Zsibrita, and Istv?an Nagy T.2013c.
Dependency parsing for identifying hun-garian light verb constructions.
In Proceedings ofthe Sixth International Joint Conference on Natu-ral Language Processing, pages 207?215, Nagoya,Japan, October.
Asian Federation of Natural Lan-guage Processing.1125Eric Wehrli, Violeta Seretan, and Luka Nerima.
2010.Sentence analysis and collocation identification.
In?Eric Laporte, Preslav Nakov, Carlos Ramisch, andAline Villavicencio, editors, Proc.
of the COLINGWorkshop on MWEs: from Theory to Applications(MWE 2010), pages 27?35, Beijing, China, Aug.ACL.1126
