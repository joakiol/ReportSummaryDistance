Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 408?413,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsFrameNet+: Fast Paraphrastic Tripling of FrameNetEllie Pavlick1Travis Wolfe2,3Pushpendre Rastogi2Chris Callison-Burch1Mark Dredze2,3Benjamin Van Durme2,31Computer and Information Science Department, University of Pennsylvania2Center for Language and Speech Processing, Johns Hopkins University3Human Language Technology Center of Excellence, Johns Hopkins UniversityAbstractWe increase the lexical coverage ofFrameNet through automatic paraphras-ing.
We use crowdsourcing to manuallyfilter out bad paraphrases in order to en-sure a high-precision resource.
Our ex-panded FrameNet contains an additional22K lexical units, a 3-fold increase overthe current FrameNet, and achieves 40%better coverage when evaluated in a prac-tical setting on New York Times data.1 IntroductionFrame semantics describes a word in relation toreal-world events, entities, and activities.
Framesemantic analysis can improve natural languageunderstanding (Fillmore and Baker, 2001), andhas been applied to tasks like question answering(Shen and Lapata, 2007) and recognizing textualentailment (Burchardt and Frank, 2006; Aharonet al, 2010).
FrameNet (Fillmore, 1982; Bakeret al, 1998) is a widely-used lexical-semantic re-source embodying frame semantics.
It containsclose to 1,000 manually defined frames, i.e.
rep-resentations of concepts and their semantic prop-erties, covering a wide array of concepts from Ex-pensiveness to Obviousness.Frames in FrameNet are characterized by a setof semantic roles and a set of lexical units (LUs),which are word/POS pairs that ?evoke?
the frame.For example, the following sentence contains amention (i.e.
target) of the Obviousness frame: Inlate July, it was barely visible to the unaided eye.This particular target instantiates several semanticroles of the Obviousness frame, including a Phe-nomenon (it) and a Perceiver (the unaided eye).Here, the LU visible.a evokes the frame.
Intotal, the Obviousness frame has 13 LUs includingclarity.n, obvious.a, and show.v.1well received a rating of 3.67 as a paraphrase of clearlyin the context the intention to do so is clearly present.accurate, ambiguous, apparent, apparently, audible,axiomatic, blatant, blatantly, blurred, blurry, cer-tainly, clarify, clarity, clear, clearly, confused, con-fusing, conspicuous, crystal-clear, dark, definite,definitely, demonstrably, discernible, distinct, evi-dent, evidently, explicit, explicitly, flagrant, fuzzy,glaring, imprecise, inaccurate, lucid, manifest, man-ifestly, markedly, naturally, notable, noticeable,obscure, observable, obvious, obviously, opaque,openly, overt, patently, perceptible, plain, precise,prominent, self-evident, show, show up, significantly,soberly, specific, straightforward, strong, sure, tan-gible, transparent, unambiguous, unambiguously,uncertain, unclear, undoubtedly, unequivocal, un-equivocally, unspecific, vague, viewable, visibility,visible, visibly, visual, vividly, well,1woollyTable 1: 81 LUs invoking the Obviousness frame accordingto the new FrameNet+.
New LUs (bold) have been added us-ing the method of paraphrasing and human-vetting describedin Section 4.The semantic information in FrameNet (FN)is broadly useful for problems such as entail-ment (Ellsworth and Janin, 2007; Aharon et al,2010) and knowledge base population (Mohit andNarayanan, 2003; Christensen et al, 2010; Gre-gory et al, 2011), and is of general enough inter-est to language understanding that substantial ef-fort has focused on building parsers to map nat-ural language onto FrameNet frames (Gildea andJurafsky, 2002; Das and Smith, 2012).
In practice,however, FrameNet?s usefulness is limited by itssize.
FN was built entirely manually by linguisticexperts.
As a result, despite many years of work,most of the words that one confronts in naturallyoccurring text do not appear at all in FN.
For ex-ample, the word blatant is likely to evoke the Ob-viousness frame, but is not present in FN?s list ofLUs (Table 1).
In fact, out of the targets we samplein this work (described in Section 4), fewer than50% could be mapped to a correct frame using theLUs in FrameNet.
This finding is consistent withwhat has been reported by Palmer and Sporleder(2010).
Such low lexical coverage prevents FNfrom applying to many real-world applications.408Frame Original Paraphrase Frame-annotated sentenceQuantity amount figure It is not clear if this figure includes the munitions.
.
.Expertise expertise specialization .
.
.
the technology, specialization, and infrastructure.
.
.Labeling called dubbed .
.
.
eliminate who he dubbed Sheiks of sodomite.
.
.Importance significant noteworthy .
.
.
assistance provided since the 1990s is noteworthy.
.
.Mental property crazy berserk You know it?s berserk.Table 2: Examples paraphrases from FrameNet?s annotated fulltext.
The bolded words are automatically proposed rewritesfrom PPDB.In this work, we triple the lexical coverage ofFrameNet quickly and with high precision.
Wedo this in two stages: 1) we use rules from theParaphrase Database (Ganitkevitch et al, 2013) toautomatically paraphrase FN sentences and 2) weapply crowdsourcing to manually verify that theautomatic paraphrases are of high quality.
Whileprior efforts have entertained the idea of expand-ing FN?s coverage (Ferr?andez et al, 2010; Das andSmith, 2012; Fossati et al, 2013), none have re-sulted in a publicly available resource that can beeasily used.
As our main contribution, we releaseFrameNet+, a huge, manually-vetted extension tothe current FrameNet.
FrameNet+ provides over22,000 new frame/LU mappings in a format thatcan be readily incorporated into existing systems.We demonstrate that the expanded resource pro-vides a 40% improvement in lexical coverage in apractical setting.2 Expanding FrameNet AutomaticallyThe Paraphrase Database (PPDB) (Ganitkevitchet al, 2013) is an enormous collection of lexical,phrasal, and syntactic paraphrases.
The databaseis released in six sizes (S to XXXL) ranging fromhighest precision/lowest recall to lowest averageprecision/highest recall.
We focus on lexical (sin-gle word) paraphrases from the XL distribution, ofwhich there are over 370K.Our aim is to increase the type-level coverageof FN.
We use the rules in PPDB along witha 5-gram Kneser-Ney smoothed language model(Heafield et al, 2013) to paraphrase FN?s fullframe-annotated sentences (called fulltext).
We ig-nore paraphrase rules which are redundant withLUs already covered by FN.
This method for auto-matic paraphrasing has been discussed previouslyby Rastogi and Van Durme (2014).
However,whereas their work only discussed the idea as ahypothetical way of augmenting FN, we apply themethod, vet the results, and release it as a publicresource.In total, we generate 188,061 paraphrased sen-tences, covering 686 frames.
Table 2 shows someof the paraphrases produced.3 Manual Refining with CrowdsourcingOur automatic process produces a large number ofgood paraphrases, but does not address issues likeword sense, and many of the paraphrased LUs al-ter the sentence so that it no longer evokes the in-tended frame.
For example, PPDB proposes freeas a paraphrase of open.
This is a good paraphrasein the Secrecy status frame but does not hold forthe Openness frame (Table 3).X Secrecy statusThe facilities are open to public scrutinyThe facilities are free to public scrutinyX OpennessMuseum (open Wednesday and Friday.
)Museum (free Wednesday and Friday.
)Table 3: Turkers approved free as a paraphrase of open forthe Secrecy status frame (rating of 4.3) but rejected it in theOpenness frame (rating of 1.6).We therefore refine the automatic paraphrasesmanually to remove paraphrased LUs which donot evoke the same frame as the original LU.
Weshow each sentence to three unique workers onAmazon Mechanical Turk (MTurk) and ask eachto judge how well the paraphrase retains the mean-ing of the original phrase.
We use the 5-point grad-ing scale for paraphrase proposed by Callison-Burch (2008).To ensure that annotators perform our task con-scientiously, we embed gold-standard control sen-tences taken from WordNet synsets.
Overall,workers were 76% accurate on our controls andshowed good levels of agreement?
the averagecorrelation between two annotators?
ratings was ?= 0.49.Figure 1 shows the distribution of Turkers?
rat-ings for the 188K automatically paraphrased tar-gets.
In 44% of cases, the new LU was judgedto retain the meaning of the original LU given theframe-specific context.
These 85K sentences con-tain 22K unique frame/LU mappings which we are409able to confidently add to FN, tripling the totalnumber in the resource.
Figure 1 shows 69 newLUs added to the Obviousness frame.Figure 1: Distribution of MTurk ratings for paraphrased full-text sentences.
44% received an average rating ?
3, indicat-ing the paraphrased LU was a good fit for the frame-specificcontext.4 EvaluationWe aim to measure the type-level coverage im-provements provided by our expanded FrameNetin a practical setting.
Ideally, one would liketo identify frames evoked by arbitrary sentencesfrom natural text.
To emulate this setting, weconsider potentially frame-evoking LUs sampledfrom the New York Times.
The question we askis: does the resource contain an entry associatingthis LU with the frame that is actually evoked bythis target?FrameNet+ We refer to the expandedFrameNet, which contains the current FN?sLUs as well as the proposed paraphrased LUs,as FrameNet+.
The size and precision ofFrameNet+ can be tuned by setting a threshold tand only including LU/frame mappings for whichthe average MTurk rating was at least t. Settingt = 0 includes all paraphrases, even those whichhuman?s judged to be incorrect, while settingt > 5 includes no paraphrases, and is equal to thecurrent FN.
Unless otherwise specified, we sett = 3.
This includes all paraphrases which werejudged minimally as ?retaining the meaning of theoriginal.
?Sampling LUs We consider a word to be ?po-tentially frame-evoking?
if FN+ (t = 0) containssome entry for the word, i.e.
the word is either anLU in the current FN or appears in PPDB-XL asa paraphrase of some LU in the current FN.
Wesample 300 potentially frame-evoking word typesfrom the New York Times: 100 each nouns, verbs,and adjectives.
We take a stratified sample: withineach POS, types are divided into buckets basedon their frequency, and we sample uniformly fromeach bucket.Annotation For each of the potentially frame-evoking words in our sample, we have expert (non-MTurk) annotators determine the frame evoked.The annotator is given the candidate LU in thecontext of the NYT sentence in which it occurred,and is shown the list of frames which are poten-tially evoked by this LU according to FrameNet+.The annotator then chooses which of the proposedframes fits the target, or determines that none do.We measure agreement by having two experts la-bel each target.
On average, agreement was good(?=0.56).
In cases where they disagreed, the an-notators discussed and came to a final consensus.Results We compute the coverage of a resourceas the percent of targets for which the resourcecontained a correct LU/frame mapping.
Figure2 shows the coverage computed for the currentFN compared to FN+.
By including the human-vetted paraphrases, FN+ is able to return a cor-rect LU/frame mapping for 60% of the targets inour sample, 40% more targets than were coveredby the current FN.
Table 4 shows some sentencescovered by FN+ that are missed by the current FN.Figure 2: Number of LUs covered by the current FrameNetvs.
two versions of FrameNet+: one including manually-approved paraphrases (t = 3), and one including all para-phrases (t = 0).Figure 3 compares FN+?s coverage and numberof LUs per frame using different paraphrase qual-ity thresholds t. FN+ provides an average of morethan 40 LUs per frame, compared to just over 10LUs per frame in the current FN.
Adding un-vetted410LU Frame NYT Sentenceoutsider Indigenous origin .
.
.
I get more than my fair share because I ?m the ultimate outsider.
.
.mini Size .
.
.
a mini version of ?The King and I ?
.
.
.prod Attempt suasion He gently prods his patient to step out of his private world.
.
.precious Expensiveness Keeping precious artwork safe.sudden Expectation .
.
.
on the sudden passing of David .Table 4: Example sentences from the New York Times.
The frame-invoking LUs in these sentences are not currently coveredby FrameNet but are covered by the proposed FrameNet+.LU paraphrases (setting t = 0) provides nearly 70LUs per frame and offers 71% coverage.Figure 3: Overall coverage and average number of LUs perframe for varying values of t.5 Data ReleaseThe augmented FrameNet+ is available todownload at http://www.seas.upenn.edu/?nlp/resources/FN+.zip.
The re-source contains over 22K new manually-verifiedLU/frame pairs, making it three times larger thanthe currently available FrameNet.
Table 5 showsthe distribution of FN+?s full set of LUs by part ofspeech.Noun 12,786 Prep.
455 Conj.
14Verb 10,862 Number 163 Wh-adv.
12Adj.
6,195 Article 43 Particle 6Adv.
749 Modal 22 Other 19Table 5: Part of speech distribution for 31K LUs inFrameNet+.The release also contains 85K human-approvedparaphrases of FN?s fulltext.
This is a huge in-crease over the 4K fulltext sentences currently inFN, and the new data can be easily used to retrainexisting frame semantic parsers, improving theircoverage at application time.6 Related WorkSeveral efforts have worked on expanding FN cov-erage.
Most approaches align FrameNet?s LUs toWordNet or other lexical resources (Shi and Mi-halcea, 2005; Johansson and Nugues, 2007; Pen-nacchiotti et al, 2008; Ferr?andez et al, 2010).Das and Smith (2011) and Das and Smith(2012) used graph based semi-supervised meth-ods to improve frame coverage and Hermann et al(2014) used word and frame embeddings to im-prove generalization.
All of these improvementsare restricted to their respective tool rather thana general-use resource.
In principle one of thesetools could be used to annotate a large corpus insearch of new LUs, but their precision on unseenpredicates/LUs (our focus here) is still below 50%,considerably lower than this work.Fossati et al (2013) added new frames to FN bycollecting full frame annotations through crowd-sourcing, a more complicated task that again didnot result in a useable resource.
Buzek et al(2010) applied crowdsourced paraphrasing to ex-pand training data for machine translation.
Ourapproach differs in that we expand the number ofLUs directly using automatic paraphrasing and usecrowdsourcing to verify that the new LUs are cor-rect.
We apply our method in full, resulting in alarge resource can be easily incorporated into ex-isting systems.7 ConclusionWe have applied automatic paraphrasing togreatly increase the type-level lexical coverage ofFrameNet, a widely used resource embodying thetheory of frame semantics.
We use crowdsourc-ing to manually verify that the newly added lex-ical units are correct, resulting in FrameNet+, ahigh-precision resource that is three times as largeas the existing resource.
We demonstrate that in apractical setting, the expanded resource provides a40% increase in the number of sentences for whichFN is able to identify the correct frame.
The datareleased will improve the applicability of FN toend-use applications with diverse vocabularies.Acknowledgements This research was sup-ported by the Allen Institute for Artificial Intel-411ligence (AI2), the Human Language TechnologyCenter of Excellence (HLTCOE), and by giftsfrom the Alfred P. Sloan Foundation, Google, andFacebook.
This material is based in part on re-search sponsored by the NSF under grant IIS-1249516 and DARPA under agreement numberFA8750-13-2-0017 (the DEFT program).
TheU.S.
Government is authorized to reproduce anddistribute reprints for Governmental purposes.The views and conclusions contained in this pub-lication are those of the authors and should not beinterpreted as representing official policies or en-dorsements of DARPA or the U.S. Government.The authors would like to thank Nathan Schnei-der and the anonymous reviewers for theirthoughtful suggestions.ReferencesRoni Ben Aharon, Idan Szpektor, and Ido Dagan.2010.
Generating entailment rules from framenet.In ACL, pages 241?246.Collin F Baker, Charles J Fillmore, and John B Lowe.1998.
The Berkeley FrameNet Project.
In COLING.Aljoscha Burchardt and Anette Frank.
2006.Approaching textual entailment with LFG andFrameNet frames.
In Proceedings of the SecondPASCAL RTE Challenge Workshop.
Citeseer.Olivia Buzek, Philip Resnik, and Benjamin B Beder-son.
2010.
Error driven paraphrase annotation usingmechanical turk.
In Proceedings of the NAACL HLT2010 Workshop on Creating Speech and LanguageData with Amazon?s Mechanical Turk, pages 217?221.
Association for Computational Linguistics.Chris Callison-Burch.
2008.
Syntactic constraintson paraphrases extracted from parallel corpora.
InEMNLP, pages 196?205.
Association for Computa-tional Linguistics.Janara Christensen, Stephen Soderland, Oren Etzioni,et al 2010.
Semantic role labeling for open infor-mation extraction.
In Proceedings of the NAACLHLT 2010 First International Workshop on For-malisms and Methodology for Learning by Reading,pages 52?60.
Association for Computational Lin-guistics.Dipanjan Das and Noah A Smith.
2011.
Semi-supervised frame-semantic parsing for unknownpredicates.
In ACL, pages 1435?1444.Dipanjan Das and Noah A Smith.
2012.
Graph-basedlexicon expansion with sparsity-inducing penalties.In NAACL.Michael Ellsworth and Adam Janin.
2007.
Mu-taphrase: Paraphrasing with framenet.
In Proceed-ings of the ACL-PASCAL Workshop on Textual En-tailment and Paraphrasing, pages 143?150.Oscar Ferr?andez, Michael Ellsworth, Rafael Munoz,and Collin F Baker.
2010.
Aligning FrameNetand WordNet based on semantic neighborhoods.
InLREC.Charles J Fillmore and Collin F Baker.
2001.
Framesemantics for text understanding.
In Proceedingsof WordNet and Other Lexical Resources Workshop,NAACL.
Association for Computational Linguistics.Charles Fillmore.
1982.
Frame semantics.
Linguisticsin the morning calm.Marco Fossati, Claudio Giuliano, and Sara Tonelli.2013.
Outsourcing FrameNet to the crowd.
In ACL,pages 742?747.Juri Ganitkevitch, Benjamin Van Durme, and ChrisCallison-Burch.
2013.
Ppdb: The paraphrasedatabase.
In HLT-NAACL.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational linguis-tics, 28(3):245?288.Michelle L Gregory, Liam McGrath, Eric Belanga Bell,Kelly O?Hara, and Kelly Domico.
2011.
Domainindependent knowledge base population from struc-tured and unstructured data sources.
In FLAIRSConference.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan HClark, and Philipp Koehn.
2013.
Scalable modifiedkneser-ney language model estimation.
In ACL.Karl Moritz Hermann, Dipanjan Das, Jason Weston,and Kuzman Ganchev.
2014.
Semantic frame iden-tification with distributed word representations.
InACL.Richard Johansson and Pierre Nugues.
2007.
UsingWordNet to extend FrameNet coverage.
In Build-ing Frame Semantics Resources for Scandinavianand Baltic Languages, pages 27?30.
Department ofComputer Science, Lund University.Behrang Mohit and Srini Narayanan.
2003.
Semanticextraction with wide-coverage lexical resources.
InNAACL-HLT, pages 64?66.Alexis Palmer and Caroline Sporleder.
2010.
Evalu-ating FrameNet-style semantic parsing: The role ofcoverage gaps in framenet.
In COLING.
Associationfor Computational Linguistics.Marco Pennacchiotti, Diego De Cao, Roberto Basili,Danilo Croce, and Michael Roth.
2008.
Automaticinduction of FrameNet lexical units.
In EMNLP.412Pushpendre Rastogi and Benjamin Van Durme.
2014.Augmenting FrameNet via PPDB.
In Proceedingsof the 2nd Workshop on Events: Definition, Detec-tion, Coreference, and Representation.
Associationof Computational Linguistics.Dan Shen and Mirella Lapata.
2007.
Using semanticroles to improve question answering.
In EMNLP-CoNLL.Lei Shi and Rada Mihalcea.
2005.
Putting pieces to-gether: Combining FrameNet, VerbNet and Word-Net for robust semantic parsing.
In Computationallinguistics and intelligent text processing.
Springer.413
