Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 905?912,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Grammatical Approach to Understanding Textual Tables usingTwo-Dimensional SCFGsDekai WU1 Ken Wing Kuen LEEHuman Language Technology CenterHKUSTDepartment of Computer Science and EngineeringUniversity of Science and TechnologyClear Water Bay, Hong Kong{dekai,cswkl}@cs.ust.hkAbstractWe present an elegant and extensiblemodel that is capable of providing seman-tic interpretations for an unusually widerange of textual tables in documents.
Un-like the few existing table analysis mod-els, which largely rely on relatively ad hocheuristics, our linguistically-oriented ap-proach is systematic and grammar based,which allows our model (1) to be conciseand yet (2) recognize a wider range of datamodels than others, and (3) disambiguateto a significantly finer extent the under-lying semantic interpretation of the tablein terms of data models drawn from rela-tion database theory.
To accomplish this,the model introduces Viterbi parsing undertwo-dimensional stochastic CFGs.
Thecleaner grammatical approach facilitatesnot only greater coverage, but also gram-mar extension and maintenance, as well asa more direct and declarative link to se-mantic interpretation, for which we alsointroduce a new, cleaner data model.
Indisambiguation experiments on recogniz-ing relevant data models of unseen web ta-bles from different domains, a blind evalu-ation of the model showed 60% precisionand 80% recall.1 IntroductionNatural language processing has historicallytended to emphasize understanding of linearstrings?sentences, paragraphs, discourse struc-ture.
The vast body of work that focuses on textunderstanding is often seen as an approximation of1The authors would like to thank the Hong Kong Re-search Grants Council (RGC) for supporting this researchin part through grants RGC6083/99E, RGC6256/00E, andDAG03/04.EG09.spoken language understanding.
Yet real-life textis actually heavily dependent on visual layout andformatting, which compensate for cues normallyfound in spoken language but are absent in text.As Scott (2003) reiterated in the opening ACL?03invited talk: ?The overlay of graphics on text is inmany ways equivalent to the overlay of prosody onspeech... Just as prosody undoubtedly contributesto the meaning of utterances, so too does a text?sgraphical presentation contribute to its meaning.However... few natural language understandingsystems use graphical presentational features toaid interpretation...?
(Power et al, 2003).Nowhere is this more evident than in the wide-spread use of tables in real-world, unsimplifiedtext documents.
Tables have a comparable orgreater complexity as other elements of text.
Un-fortunately, in mainstream NLP it is not uncom-mon for tables to be regarded as a somehow ?de-generate?
form of text, unworthy of the same de-gree of attention as the rest of the text.
But aswe will discuss, the degree of ambiguity in ta-ble understanding is at least as great as for manysense and attachment problems.
Many of the samemechanisms used for understanding linear text arealso required for table understanding.
The samedivision of surface syntax and underlying seman-tics is found.Indeed, to perceive the limitations of existingtable understanding models, we may distinguishseveral very different levels of table analysis tasks.In table classification, the table is classified intoone of several coarse categories (in the extremecase, some models simply predict whether the pur-pose of the table is for page layout versus tabulardata).
In table synactic recognition, the surfacetypes of individual cells or block regions are la-beled (e.g., as heading or data) but the underlyingsemantic relationships between the table elementsremain unrecognized and usually highly ambigu-ous (i.e., no logical relations between the elements905in the table are assigned).
In contrast, in table se-mantic interpretation, the exact logical relationsbetween the elements in the table must be recog-nized (e.g., by associating the table and/or subre-gions thereof with precise table schemas in rela-tional database style).Existing table understanding work largely lies atthe level of superficial table classification or syn-tactic recognition.
Rarely, if ever, are precise logi-cal relations assigned between the elements in thetable.
Ad hoc heuristic approaches tend to rule,rather than linguistic approaches.On the other hand, in the linguistic approach ad-vocated by Scott (2003) and (Power et al, 2003),tables were not considered.
The various physicalpresentation elements discussed included head-ings, captions, and bulleted lists?all of whichexhibit numerous similarities to tabular elements.Possibly, tables were not considered because theyare difficult to describe adequately within the ex-pressiveness of common linguistic formalisms likeCFGs.The work presented here aims to address thisproblem.
Our model provides an enabling foun-dation toward a linguistic approach by first shift-ing to a two-dimensional CFG framework.
Thispermits us to construct a grammar where all therules are meaningfully discriminative, such that?unlike existing table understanding models?anyanalysis of a table includes a full parse tree thatassigns precise data model labels to all its regions(including nested subregions) thereby specifyingthe logical relations between the table?s elements.Additionally, probabilities on the production rulessupport thresholding (or ranking) of the alternativecandidate table interpretation hypotheses.As with many natural language phenomena, afull model of disambiguation must ultimately inte-grate lexical semantics.
However, in this researchstep we focus on the question of howmuch seman-tic interpretation can be performed on the basis ofother features, in the absence of a lexical or on-tological model.
Just as syntax and morphologyand prosody alone already permit much recogni-tion and disambiguation of semantic roles and ar-gument structure to be done for sentence, the samecan be done for tables.
At the same time, we be-lieve future integration of lexical semantics will befacilitated by the grammatical framework of ourmodel.One way to think about this is that we wish toTable 1: Example ?Martian?
table (see text).Pbje Kwe Zxc AmcHoer 15 - 18 17 - 20 19 - 23NQ 85 - 95% 70 - 90% 75 - 95%Ncowifl Djhi Djhi Rubzlxmodel what you might be able to recognize from a?Martian?
table such as that in Table 1.
The non-Martian reader relies solely on knowledge of al-phabets and numbers, can spot font and formattingclues, and is familiar with the conventions (i.e.,grammars) of tables in general.You might reasonably interpret this table as acollection of vertical records with an attributesheader column (Pbje, Hoer, NQ, Ncowifl) on theleft.
You might additionally interpret it as a ta-ble that contains an record key header row (Kwe,Zxc, Amc) along with the attributes header col-umn (Pbje, Hoer, NQ, Ncowifl).
You might as-sign the latter interpretation a slightly higher prob-ability, noticing the slightly longer form of Pbjecompared to Kwe, Zxc, and Amc.
On the otherhand, even without reading English, you could re-ject the interpretation as a collection of horizon-tal records under the header attributes row (Pbje,Kwe, Zxc, Amc), since each row contains differ-ent forms and types, in a pattern that is consistentacross columns.
Other interpretations are also pos-sible, but unlikely given the regularity of the pat-terns.Thus by analyzing the structure of a table, thereader would form a hypothesis about its datamodel, providing a semantic interpretation that al-lows the reader to extract information from the ta-ble.
As can be seen from the restored originalEnglish version of the same example in Table 2,the most likely interpretation was predicted evenwithout access to specific lexical knowledge.
Weaim to show that a fairly useful baseline level ofsemantic interpretation accuracy can already beachieved, even with relatively little lexical and on-tological knowledge.We model these alternative hypotheses for theinterpretation of ambiguous tables as competingparses.
Just as with ordinary parsing and seman-tic interpretation, the reader often builds multiplecompeting interpretations of the same table.Note that many previous models do not evendistinguish between the alternative possible inter-pretations in the Martian example.
Existing mod-906els such as Hurst (2000) and Yang (2002) inter-pret tables with the same structural layout simplyby assigning them same data model, which stopsshort of recognizing that it is necessary to rankmultiple competing interpretations that entail dif-ferent sets of logical relations.In contrast, our proposed model is capable ofproducing multiple competing parses indicatingdifferent semantic interpretations of tables havingthe same structural layout, by selecting specificdata models for the table and its subregions.2 Data Models for Specifying SemanticInterpretationsTo begin, some formal basis is needed to facilitateprecise specification of the alternative semantic in-terpretations of a table, such that the exact logicalrelations between its elements are unambiguouslyspecified.
This will enable us to then design a ta-ble understanding model that attempts to map anygiven table (and recursively, its subregions) to al-ternative data models depending on which is mostappropriate.The set of data models we define below is amore comprehensive and precise inventory thanfound in the previous table analysis models dis-cussed in this paper.
It describes all the commonconventional patterns of logical relations we havefound in the course of empirically analyzing tablesfrom corpora.
One advantage of this inventory ofdata models arises from our appropriation of re-lational database theory wherever possible to helpdescribe the form of the data models (Silberschatzet al, 2002), allowing broad coverage of differenttable types without sacrificing precision as to thelogical relations between entities.Each data model assigns a clear semantics interms of logical relations between the table ele-ments, thereby allowing extraction of relationalfacts.
In contrast, previous work on table analy-sis tends to either classify a table using only onesingle limited data model (e.g., Hurst (2000)), orusing data models which essentially are merelysurface layout types whose semantics are vagueand ambiguous (e.g., Yang (2002), Yang and Luk(2002), Wang et al (2000), Yoshida et al (2001)).A table is a logical view of a collection of inter-related items usually presented as a row-columnstructure such that the reader?s ability to accessand compare information can be enhanced, as alsonoted by Wang (1996).
From a database manage-Table 2: Example from Table 1 in its original ver-sion, with the English words restored.Date Thu Fri SatTemp 15 - 18 17 - 20 19 - 23RH 85 - 95% 70 - 90% 75 - 95%Weather Cool Cool Cloudyment system perspective, each table can be con-sidered as a (tiny) database.
Like a program, thereader accesses the data.
As a result, we considerthat every table must correspond to a data model,and this model determines how the reader extractsinformation from the table.Each data model has a schema which, as weshall see below, may or may not surface (partiallyor completely) as a subset of cells in the table thatdescribe attributes.
Recognizing the data modelsof a table correctly therefore also implies that bothattribute-value pairings and table structures havebeen recognized.At the top level, we categorize the data modelsinto three broad types:?
Flat model: A table is interpreted as adatabase table in non-1NF normal relationalmodel.?
Nested model: A table is interpreted as adatabase table in an object-relational model,which allow complex types such as nested re-lations and concept hierarchy.?
Dimensional data model: A table (usuallycross-tabular) is interpreted as a data cube(multidimensional table) in a multidimen-sional data model.We now consider each of these types of datamodels in turn.2.1 Flat modelA flat model is used for the semantic interpretationof any table as a relational database table in non-1NF.
For example, tables such as Tables 2 and 3are often interpreted by humans in terms of flatmodels.
It is obvious that Table 3 can be viewedas a relational database table with a schema (Pos,Teams, Pld, Pts) and three records, because thetable?s surface form resembles how records arestored in a relational database tables.
Similarly,Table 2 resembles a relational database table, buttransposed to a vertical orientation, with the first907Table 3: Example of a ranking table, which is typ-ically laid out in a flat relational model.Pos Teams Pld Pts1.
Chelsea 38 952.
Arsenal 38 833.
Man United 38 77column as the schema (Date, Temp, RH, Weather)and other columns as data records.The flat model is closest to the 1-dimensionaltable approach used by the majority of previousmodels, but our approach designates the flat modelas a semantic representation, in contrast to theprevious models which see 1-dimensional tablesmerely as a syntactic surface form (e.g., Yang(2002), Yang and Luk (2002), Wang et al (2000),Yoshida et al (2001)).
While such previous mod-els only recognize tables that are physically laidout in this form, our approach clearly delineates anexplicit separation of syntax and semantics, whichprovides greater flexibility allowing any table to beinterpreted as a flat model, regardless of its surfaceform (though the flat model interpretation is morecommon for some surface forms than others).As an example showing that any kind oftable can be categorized as flat model, considerTable 6.
Even such a table can be semanticallyinterpreted as a flat model because related at-tributes can join together to form a compositeattribute, though humans would less naturallychoose this semantic interpretation.
Certainlythere are hierarchical relationship betweenattributes; for example, Ass1 is a subtype ofAssignments.
However, it is also valid to considerthe attributes along a hierarchical path as onecomposite attribute.
For example, ?Mark -> As-signments -> Ass1?
becomes the single attribute?Mark-Assignments-Ass1?.
Then the completeflat model schema is (Year, Team, Mark-Assignments-Ass1, Mark-Assignments-Ass2,Mark-Assignments-Ass3, Mark-Examinations-Midterm, Mark-Examinations-Final), and the firstrecord is (1991, Winter, 85, 80, 75, 60, 75, 75).2.2 Nested modelWith the exception of Hurst (2000), previous workhas not generally considered nested models in ex-plicit fashion.
Hurst (2000)?s model is based onWang (1996)?s abstract table model, in which at-tributes may be related in a hierarchical way.
Onthe other hand, Wang et al (2000) oversimplis-tically considers nested models as 1-dimensional,thus missing the correct relationships between at-tributes and values.A nested model can be seen as a generalizationof the flat model, in which attributes may be re-lated through composition or inheritance.
Table 6is naturally interpreted as a nested data model be-cause the attributes have an inheritance relation-ship.
The corresponding schema is (Year, Team,Mark (Assignments (Ass1, Ass2, Ass3), Exami-nations (Midterm, Final, Grade)).A nested model is not appropriate for tableswithout hierarchical structure, such as Table 2 andTable 3.2.3 Dimensional modelOur approach also nicely handles dimensionalmodels, which are generally handled quite weaklyin previous models.
A dimensional model refersto a table, such as the table in Table 4, that resem-bles a view of collection of data stored in multi-dimensional data model.
A multidimensional datacube, as described in the database literature (e.g.,Han and Kamber (2000), Chaudhuri and Dayal(1997)), consists of a set of numeric measures(though in fact the data need not be numeric), eachof which is determined by a set of dimensions.Each dimension is described by a set of attributes.For example, Table 5 can be semantically inter-preted using the multidimensional data model de-picted in Figure 1.
Likewise, the cross-tabular ta-ble in Table 4 can also be semantically interpretedusing the same multidimensional data model inFigure 1.
The value of the first three columns inTable 5 are the dimension attributes and the rev-enue values are the measures.In contrast, among previous models, Yang(2002) produces a semantically incorrect recogni-tion of a multidimensional table that inappropri-ately presents the attributes in hierarchical struc-ture.
Yang and Luk (2002) and Wang et al(2000) only recognize the simplest 2-dimensionalcase and apparently cannot handle 3 or more di-mensions.
Yoshida et al (2001) only handle 1-dimensional cases.A dimensional model is an inappropriate inter-pretation for non-cross-tabular tables, such as Ta-ble 2 and Table 3.
A dimensional model is also notvalid for tables such as Table 6.
Semantically, itis not possible for ?Assignments?
and ?Midterm?908Table 4: Example table showing revenue accord-ing to Location = {Vancouver, Victoria}, Type ={Phone, Computer} and Time = {2001, 2002}, us-ing a tabular view of a 3-dimensional data cube.Vancouver VictoriaPhone Computer Phone Computer2001 845 1078 818 9682002 943 1130 894 10241Table 5: Example relational database table con-taining the same logical information as Table 4.Location Type Time RevenueVancouver Phone 2001 845Vancouver Phone 2002 943Vancouver Computer 2001 1078Vancouver Computer 2002 1130Victoria Phone 2001 818Victoria Phone 2002 894Victoria Computer 2001 968Victoria Computer 2002 1024LocationTypeTimeVancouver VictoriaPhoneComputer84510782001 2002Figure 1: Multidimensional data cube corre-sponding to Tables 4 and 5.to belong to different dimensions because it is in-correct to determine the score by both ?Assign-ments?
and ?Midterm?.
Syntactically, the textsin the last attribute row of Table 6 are all unique;however, the last attribute row of the table in Ta-ble 4 is a repeating sequence of (?Phone?, ?Com-puter?).
Therefore, to a non-English reader, anEnglish cross-tabular table which possess repeat-ing sequences in the attribute rows is likely to besemantically interpreted as a dimensional model,while a cross-tabular table which does not havethis property is likely to be interpreted as a nestedTable 6: Example table of grades.MarkAssignments ExaminationsAss1 Ass2 Ass3 Midterm Final GradeWinter 85 80 75 60 75 75Spring 80 65 75 60 70 70Fall 80 85 75 55 80 75Winter 85 80 70 70 75 75Spring 80 80 70 70 75 75Fall 75 70 65 60 80 70Year Team199119921model.3 A 2D SCFG Model for Table AnalysisIn this section, we will present our two-dimensional SCFG parsing model for table analy-sis which has several advantages over the ad hocapproaches.
First, the probabilistic grammar ap-proach permits a cleaner encapsulation and gen-eralization of the kind of knowledge that previ-ous models attempted to capture within their adhoc heuristics.
Most previous works (e.g.
Yang(2002), Yang and Luk (2002), Hurst (2000), Hurst(2002)) gradually built up their ad hoc heuristicsmanually by inspecting some set of training sam-ples.
This approach may work if tables are fromlimited domains of similar nature.
However, liketext documents, the syntactic layout of textual ta-bles may be determined by its context as well as itslanguage.
For instance, it is natural for an Arabicreader to read an Arabic table taking the rightmostcolumn as the attribute column, instead of the left-most column.
Yoshida et al (2001) use machine-learning techniques to analyze nine types of tablestructures, all 1-dimensional.
Our grammar-basedapproach allows the model to be readily adaptedto different situations by applying different sets ofgrammar rules.Another advantage is that grammatical ap-proach can make more accurate decisions whilebeing simpler to implement, because it requiresonly a single integrated parsing process to com-plete the entire table analysis.
This includes clas-sifying the functions of each cell (as attribute orvalue), pairing attributes and values, and identify-ing the structure and the data model of a table.
Incontrast, previous works require several stages tocomplete the entire analysis, introducing complex909problems that are difficult to resolve, such as pre-mature commitment to incorrect early-stage deci-sions.To our knowledgeWang et al (2000) is the onlytextual table analysis model that uses a grammarto describe table structures.
However, in that case,only a simple template matching analyzer is used.Their grammar notation is unable to show bothphysical structure and the semantics of a table atthe same time in a hierarchical manner.
In con-trast, information such as ?a data block containsthree rows of data cell?
can be stored in the parsetree constructed by our parsing model.Outside of the table understanding literature,there exists a different 2D parsing technique calledPLEX (Feder, 1971), (Costagliola et al, 1994)which allows an object to have finite sets of attach-ing points.
PLEX is used to generate 2D diagramssuch as molecular structures, circuit diagrams andflow charts in a grammatical way.
However, weconsider it too complex and computationally ex-pensive for our application because it does not ex-ploit that fact that a textual table cell only has atmost four attaching points in fixed directions.Our parser is a two-dimensional extension ofthe conventional probabilistic chart parsing algo-rithm (Lari and Young, 1990), (Goodman, 1998).Intuitively, consider a sentence as a vector of to-kens that will be parsed horizontally; then a ta-ble is a matrix of tokens (like a crossword puzzle)that will be parsed both horizontally and vertically.Because of this, our parser must run in both direc-tions.
We achieve this by employing a grammarnotation that specifies the direction of parsing.The two-dimensional grammar notation in-cludes of a set of nonterminals, terminals, and twogeneration operators ??>?
and ?|->?.
Let X be anonterminal and Y, Z, be two symbols which maybe either nonterminals or terminals.
Then:?
X ?> Y Z denotes a horizontal productionrule saying that the nonterminal X horizon-tally generates two symbols Y and Z.?
X |-> Y Z denotes a vertical production rulesaying that the nonterminal X vertically gen-erates two symbols Y and Z.?
X ?> Y or X |-> Y equivalently denote aunary production rule saying that the nonter-minal X generates a symbol Y.We assume that all rules are binary without lossof generality, since any grammar can be mechan-ically binarized without materially changing theparse tree structure, just as in the case of ordinary1D grammars.The operators ??>?
and ?|->?
control the gen-eration direction.
In term of table analysis, a non-terminal represents a matrix of tokens and a termi-nal represents a single token.
Sub-matrices gen-erated by a horizontal rule will have same heightbut not necessarily same width; similarly, sub-matrices generated by a vertical rule will havesame width but not necessarily same height.
Inother words, a matrix is partitioned into two halvesby the binary production rule.Probabilities are placed on each rule, as in ordi-nary 1D SCFGs.
They are used to eliminate parsesfalling below a threshold, which also helps to re-duce the time complexity in practice.Parsing with two-dimensional grammars can beconceptualized most easily via parse tree exam-ples.
Figure 2 shows a complete parse tree forparsing the table in Table 7 into a flat model.
Fig-ure 3 is a portion of a parse tree for parsing thetable in Table 8 into a nested model, while Figure4 is a portion of parse trees for parsing Table 7 intoa dimensional model.
The following is the gram-mar fragment that gives the parse tree as Figure2:T1-1H |-> FlatModelFlatModel |-> FlatSchema RecordsFlatSchema --> CompositeAttribute FlatSchemaFlatSchema --> CompositeAttributeRecords |-> Record RecordsRecords |-> RecordRecord --> Data RecordRecord --> RecordNote that the internal nodes of the parse treesserve to label subregions with data models, thusassigning a semantic interpretation specifying theexact logical relations between table elements.None of the previous models construct declara-tive parse trees like these, which are necessary formany types of subsequent analysis, including in-formation extraction applications.4 Experimental MethodTo the best of our knowledge, unfortunately noneof the table corpora mentioned in previous workare available to the public.
Thus, it was neces-sary to construct a corpus for our experiments.We collected a large sample of tables by issuingGoogle searches with a list of random keywords,for example, census age, confusion matrix, datatable, movie ranking, MSFT, school ranking, tele-phone plan, tsunami numbers, weather report, and910D:\ust\ner\docs\emnlp\parse_flat.htmlT1-1H |->FlatModel |->FlatSchema -->CompositeAttribute |->Attribute |->VACompositeAttribute |->AttributePFlatSchema -->CompositeAttribute |->Attribute |->VACompositeAttribute |->AttributeCFlatSchema -->CompositeAttribute |->Attribute |->VBCompositeAttribute |->Attribute |->PFlatSchema -->CompositeAttribute |->Attribute |->VBCompositeAttribute |->AttributeCRecords |->Record -->Data |->11Record -->Data |->12Record -->Data |->13Data |->14Records |->Record -->Data |->21Record -->Data |->22Record -->Data |->23Data |->241Figure 2: A parse tree for a flat model.NestedModelSchema -->NestedAttribute |->Base |->VAFinal -->Attribute |->PFinal -->Attribute |->CNestedAttribute |->Base |->VBFinal -->Attribute |->XFinal -->Attribute |->Y1Figure 3: A partial parse for a nested model.DimensionalModelSchema |->Dimension -->DimAttribute |->DimAttribute |->VADimension -->DimAttribute |->PDimension-->DimAttribute |->CDimension -->DimAttribute |->DimAttribute |->VBDimension -->DimAttribute |->PDimension-->DimAttribute |->C1Figure 4: A partial parse for a dimensional model.so on.
Tables were extracted from the collectedsample, automatically cleaned, and tokenized intotwo-dimensional array of tokens.Table 7: Example table for Figures 2 and 4.VA VBP C P C11 12 13 1421 22 23 241Table 8: Example table for Figure 3.VA VBP C X Y11 12 13 1421 22 23 241Table 9: Example table showing a floor legend.6 School of Business & Management5 Department of Biochemistry4 Classrooms 4202 - 42053 Department of Computer Science3 Department of MathematicsFor the blind evaluation, a human annotator in-dependently manually annotated a randomly cho-sen sample of 45 tables from the collection.
All ta-bles in the evaluation sample were previously un-seen test cases, never inspected prior to the con-struction of the two-dimensional grammar.Each tokenized table was tagged by the humanjudge with a list of types T relevant to the table.The relevance is defined as follows: a data modelis relevant to a table if and only if the humanwould agree that such a data model would natu-rally be hypothesized as an interpretation for thattable (analogously to the way that word senses aremanually annotated for WSD evaluations).
Eachtype is a tuple of the form (R, O, S), where R isthe relevant data model, O is the reading orienta-tion of R, and S is a boolean saying if a schema(i.e.
attributes) exist in the table.
Thus, Table 2would be tagged as {(flat, vertical, true)} whilethe table in Table 4 would be tagged as {(flat, hor-izontal, true), (flat, vertical, true), (dimensional, ,true)}.
But Table 9 may be tagged as {(flat, hor-izontal, false)}.
The exceptions are that both thenested model and the dimensional model alwayshave a schema, while the dimensional model doesnot have orientation.
In cases where multiple legit-imate readings were possible, the table was tagged911Table 10: Experimental results.Precision Recall0.60 0.80with multiple types.
A total of 92 relevant typeswere generated from the tokenized tables.We processed the tokenized tables with the two-dimensional SCFG parser, and computed the pre-cision and the recall rates against the judge?s listsof tags for all the test cases.5 Results and DiscussionThe experimental results are summarized in Table10.
All tables could be parsed; in general, it is veryrare for any table to be rejected by the parser, sincethe grammar permits so many different configura-tions that can be recursively composed.Unfortunately it is impossible to compare re-sults directly against previous models, since nei-ther those models nor the data they evaluated onare available.Moreover, it is difficult to compare with pre-vious models as our evaluation criteria are morestringent than in earlier work.
Most previous workevaluated the performance in terms of the (vaguerand less demanding) criteria of number of correctattribute-value pairings.
Such an evaluation ap-proach gives unduly high weight to large repetitivetables, and neglects structural errors in the analysisof the table.
In contrast, our approach gives equalweight to all tables regardless of how many entriesthey contain, requires semantically valid structuralanalyses, and yet still accepts any parse that yieldsthe correct attribute-value pairings (since the tag-ging of the test set includes all legitimate typeswhen there are multiple valid alternatives).The fact that precision was lower than recall isdue to the fact that many tables were wrongly in-terpreted as tables without schema or in wrong ori-entations.
The current grammar has difficulty dis-tinguishing attributes from values.
Significant im-provement can be obtained by using constraints tolimit the number of incorrect parses, a strategy weare currently implementing.6 ConclusionWe have introduced a framework to support amore linguistically-oriented approach to finer in-terpretation of tables, using two-dimensional sto-chastic CFGs with Viterbi parsing to find appro-priate semantic interpretations of textual tables interms of different data models.
This approachyields a concise model that at the same time fa-cilitates broader coverage than existing models,and is more easily scalable and maintainable.
Wealso introduce a cleaner and richer data model torepresent semantic interpretations, and illustratehow it systematically captures a wider range of ta-ble types.
Without such a data model, the rightattribute-value relations caanot be extracted froma table, even if surface elements like ?header?
and?data?
are correctly labeled as previous models at-tempted to do.
Our experiments show that evenwithout other ontological and linguistic knowl-edge, excellent semantic interpretation accuracycan be obtained by parsing with a two-dimensionalgrammar based on these data models, by usinga wide variety of surface features in the terminalsymbols.
We plan next to extend the model by in-corporating ontological and linguistic knowledgefor additional disambiguation leverage.ReferencesSurajit Chaudhuri and Umesh Dayal.
An overview of data warehousing andOLAP technology.
ACM SIGMOD Record, 26(1), March 1997.Gennaro Costagliola, Andrea De Lucia, and Sergio Orefice.
Towards efficientparsing of diagrammatic languages.
In AVI ?94: Proceedings of the work-shop on Advanced visual interfaces, pages 162?171, New York, NY, USA,1994.
ACM Press.Jerome Feder.
Plex languages.
Information Sciences, 3:225?241, 1971.Joshua T. Goodman.
Parsing Inside-Out.
PhD thesis, Harvard University,1998.Jiawei Han and Micheline Kamber.
Data Mining: Concepts and Techniques.Morgan Kaufmann, 1 edition, 2000.Matthew Francis Hurst.
The Interpretation of Tables in Texts.
PhD thesis, TheUniversity of Edinburgh, 2000.Matthew Hurst.
Classifying table elements in html.
In The 11th InternationalWorld Wide Web Conference, Hawaii, USA, 2002.K.
Lari and S. J.
Young.
The estimation of stochastic context-free grammarsusing the inside-outside algorithm.
Computer Speech and Language, 4:35?36, 1990.Richard Power, Donia Scott, and Nadjet Bouayad-Agha.
Document structure.Computational Linguistics, 29(4):211?260, Dec 2003.Donia Scott.
Layout in NLP: The case for document structure (invited talk).In 41st Annual Meeting of the Association for Computational Linguistics(ACL-2003), Aug 2003.Abraham Silberschatz, Henry F. Korth, and S. Sudarshan.
Database SystemConcepts.
McGraw-Hill, 4th edition, 2002.H.
L. Wang, S. H. Wu, I. C. Wang, C. L. Sung, W. L. Hsu, and W. K. Shih.Semantic search on internet tabular information extraction for answeringqueries.
In CIKM ?00: Proceedings of the ninth international conferenceon Information and knowledge management, pages 243?249, New York,NY, USA, 2000.
ACM Press.Xinxin Wang.
Tabular Abstraction, Editing, and Formatting.
PhD thesis, TheUniversity of Waterloo, Waterloo, Ontario, Canada, 1996.Yingchen Yang and Wo-Shun Luk.
A framework for web table mining.
InWIDM ?02: Proceedings of the 4th international workshop on Web infor-mation and data management, pages 36?42, New York, NY, USA, 2002.ACM Press.Yingchen Yang.
Web table mining and database discovery.
Master?s thesis,Simon Fraser University, August 2002.M.
Yoshida, K. Torisawa, and J. Tsujii.
A method to integrate tables of theworld wide web, 2001.912
