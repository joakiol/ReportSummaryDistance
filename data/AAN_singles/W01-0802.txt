A Two-stage Model for Content DeterminationSomayajulu G.SripadaDept.
of Comp.
Sc.Univ.
of Aberdeen,Aberdeen, UKssripada@csd.abdn.ac.ukEhud ReiterDept.
of Comp.
Sc.Univ.
of Aberdeen,Aberdeen, UKereiter@csd.abdn.ac.ukJim HunterDept.
of Comp.
Sc.Univ.
of Aberdeen,Aberdeen, UKjhunter@csd.abdn.ac.ukJin YuDept.
of Comp.
Sc.Univ.
of Aberdeen,Aberdeen, UKjyu@csd.abdn.ac.ukAbstractIn this paper we describe a two-stagemodel for content determination insystems that summarise time seriesdata.
The first stage involves building aqualitative overview of the data set, andthe second involves using thisoverview, together with the actual data,to produce summaries of the time-series data.
This model is based on ourobservations of how human expertssummarise time-series data.1  IntroductionThis paper addresses the problem of contentdetermination in data summarisation.
Contentdetermination as the name indicates is theprocess responsible for determining the contentof the texts generated by an NLG system (Reiterand Dale 2000).
Although content-determination is probably the most importantpart of an NLG system from the end-user'sperspective, there is little agreement in the NLGcommunity as to how content-determinationshould be done, with different systems adaptingwidely varying approaches.
Also, algorithmsand architectures for content-determinationseem to often be based on the intuitions ofsystem developers, instead of on empiricalobservations, although detailed contentdetermination rules are often based on corpusanalysis and interaction with experts.In this paper we propose a general architecturefor content determination in data summarisationsystems which assumes that contentdetermination happens in two stages: first aqualitative overview of the data is formed, andsecond the content of the actual summaries isdecided upon.
This model is based on extensiveknowledge acquisition (KA) activies that wehave carried out in the SUMTIME  project(Sripada, 2001), and also matches observationsmade during KA activities carried out in theSTOP  project (Reiter et al 2000).
We have notyet implemented this model, and indeed one ofthe issues that we need to think about is to whatdegree a content-determination strategy used byhuman experts is also an appropriate one for acomputer NLG system.2 Content DeterminationContent determination is the task of deciding onthe information content of a generated text.
Inthe three-stage pipeline model of Reiter andDale (2000), content determination is part of thefirst stage, document planning, along withdocument structuring (determining the textualand rhetorical structure of a text).
Contentdetermination is extremely important to endusers; in most applications users probably prefera text which poorly expresses appropriatecontent to a text which nicely expressesinappropriate content.
From a theoreticalperspective content determination shouldprobably be based on deep reasoning about thesystem's communicative goal, the user'sintentions, and the current context (Allen andPerrault 1980), but this requires an enormousamount of knowledge and reasoning, and isdifficult to do robustly in real applications.In recent years many new content determinationstrategies have been proposed, ranging from theuse of sophisticated signal-processingtechniques (Boyd 1997) to complex planningalgorithms (Mittal et al 1998) to systems whichexploit cognitive models of the user (Fiedler1998).
However, most of these strategies haveonly been demonstrated in one application.Furthermore, as far as we can tell thesestrategies are usually based on the intuition andexperiences of the developers.
Whilerealisation, microplanning, and documentstructuring techniques are increasingly based onanalyses of how humans perform these tasks(including corpus analysis, psycholinguisticstudies, and KA activities), most papers oncontent determination make little reference tohow human experts determine the content of atext.
Human experts are often consulted withregard to the details of content rules, especiallywhen schemas are used for contentdetermination (Goldberg et al 1994, McKeownet al 1994, Reiter et al 2000); but they rarelyseem to be consulted (as far as we can tell) whendeciding on the general algorithm or strategy touse for content determination.3  Summarising Time-Series Data3.1  Text summaries of Time-Series DataTime-series data is a collection of values of a setof parameters over time.
Such data is verycommon in the modern world, with itsproliferation of databases and sensors, andhumans frequently need to examine and makeinferences from time-series data.Currently, human examination of time-seriesdata is generally done either by direct inspectionof the data (for small data sets), by graphicalvisualisation, or by statistical analyses.However, in some cases textual summaries oftime-series data are also useful.
For example,newspapers regularly publish textual summariesof weather predictions, the results of polls andsurveys, and stock market activity, instead ofjust showing numbers and graphs.
This may bebecause graphical depictions of time-series datarequire time and skill to interpret, which is notalways available.
A doctor rushing to the sideof a patient who is suffering from a heart attack,for example, may not have time to examine a setof graphs of time-series data, and a newspaperreader may not have the statistical knowledgenecessary to interpret raw poll results.Perhaps the major problem today with textualdescriptions of time-series data is that they mustbe produced manually, which makes themexpensive and also means they can not beproduced instantly.
Graphical depictions ofdata, in contrast, can be produced quickly andcheaply using off-the-shelf computer software;this may be one reason why they are so popular.If textual summaries of time-series data could beautomatically produced by software as cheaplyand as quickly as graphical depictions, then theymight be more widely used.3.2 SUMTIMEThe goal of the SUMTIME  project is to developbetter techniques for automatically generatingtextual summaries of time-series data, in part byintegrating leading-edge NLG and time-seriesanalysis technology.
We are currently focusingon two domains:Meteorology ?
producing weather forecastsfrom numerical weather simulations.
This workis done in collaboration with Weather News Inc(WNI)/Oceanroutes, a leading meteorologicalcompany.Gas Turbines  ?
summarising sensor readingsfrom a gas turbine.
This work is done incollaboration with Intelligent Applications, aleading developer of monitoring software forgas turbines.These domains are quite different in time-seriesterms, not least in the size of the data set.
Atypical weather forecast is based on tens ofvalues for tens of parameters, while a summaryof gas-turbine sensor readings may be based ontens of thousands of values for hundreds ofparameters.
We hope that looking at suchdifferent domains will help ensure that ourresults are generalisable and not domain-specific.
We will start working on a thirddomain in 2002; this is likely to be a medicalone, perhaps (although this is not definite)summarising sensor readings in neonatalintensive care units.The first year of SUMTIME  (which started inApril 2000) has mostly been devoted toknowledge acquisition, that is to trying tounderstand how human experts summarise time-series data.
This was done using varioustechniques, including corpus analysis,observation of experts writing texts, analysis ofcontent rules suggested by experts, discussionwith experts, and think-aloud sessions, whereexperts ?think aloud?
while writing texts(Sripada, 2001).3.3  ExampleThe following table shows an example segmentof meteorological time series data, specificallypredicted wind speed and wind direction at anoffshore oil exploration site.
The time field isshown in ?day/hour?
format.Time(day/hour)WindDirectionWindSpeedKnots05/06 SE 2205/09 SE 2405/12 SE 3005/15 SE 2505/18 SSE 2805/21 SSE 2206/00 SE 16This data was summarised by WNI's humanforecasters as follows:FORECAST 06-24 GMT,FRIDAY,05-Jan2001WIND(KTS)      CONF   HIGH10M: SE 20-25 OCCASIONALLY25-30, EASING 15-20 LATERThe above example is just a sample showing thedata and its corresponding forecast text for thewind subsystem.
Real weather forecast reportsare much longer and are produced from datainvolving many more weather parameters thanjust wind speed and wind direction.4 Human Summarisation4.1 MeteorologyIn the domain of weather forecasting, weobserved how human experts carry out the taskof summarising weather data by video recordinga meteorologist thinking aloud while writingweather forecasts.
Details of the KA have beendescribed in Sripada (2001).
Our observationsincluded the following:1.
In the case of weather forecasts, time-seriesdata represent the values of importantweather parameters (wind speed, direction,temperature, rainfall), which collectivelydescribe a single system, the weather.
Itseemed as though the expert wasconstructing a mental picture of their sourceusing the significant patterns in time series.Thus the first activity is that of datainterpretation to obtain a mental model ofweather.2.
The mental model of the weather is mostlyin terms of the elements/objects related toatmosphere, like cold fronts and warmfronts; it also seems to be qualitative insteadof numerical.
In other words, it qualitativelydescribes the meteorological state of theatmosphere.
The expert calls this an?overview of the weather?.3.
Building the overview involves the task ofinterpretation of the time series weatherdata.
While interpreting this data the expertused his meteorological knowledge (whichincludes his personal experience ininterpreting weather data) to arrive at anoverview of the weather.
During this phase,he appeared to be unconcerned about theend user of the overview (see 4.1.1 below).We call this process Domain ProblemSolving (DPS) where information isprocessed using exclusively the domainknowledge.4.
Forecasts are written after the forecaster getsa clear mental picture (overview) of theweather.
Building the overview from thedata is an objective process which does notdepend on the forecast client (user), whereaswriting the forecast is subjective and varieswith client.4.1.1  ExamplesTwo examples of the influence of the overviewon wind texts (Section 3.3) are:1.
When very cold air flows over a warm sea,surface winds may be underestimated by thenumerical weather model.
In such cases theforecaster uses his ?overview of the weather?to increase wind speeds and also perhapsadd other instability features to the forecastsuch as squalls.2.
If the data contains an outlier, such as awind direction which is always N except forone time period in which it is NE, then theexpert uses the overview to decide if theoutlier is meteorologically plausible andhence should be reported or if it is likely tobe an artefact of the simulation and henceshould not be reported.The above examples involve reasoning about theweather system.
Forecasters also consider usergoals and tasks, but this may be less affected bythe overview.
For example, in one think-aloudsession, the forecaster decided to use the phrase20-24 to describe wind speed when the data filepredicted a wind speed of 19kt.
He explained tous that he did this because he knew that oil-rigstaff used different operational procedures (forexample for docking supply boats) when thewind exceeded 20kt, and he also knew that evenif the average wind speed in the period was19kt, the actual speed was going to vary minuteby minute and often be above 20kt.
Hence hedecided to send a clear signal to the rig staff thatthey should expect to use ?20kt or higher?procedures, by predicting a wind speed of 20-24.This reasoning about the user took place afterthe overview had been created, and did not seemto involve the overview.4.2 Gas Turbine SensorsUnlike the previous domain, in the domain ofgas turbine (GT), currently there are no textualsummaries of turbine data written by humans.Thus we have asked the domain experts tocomment orally on the data.
However, theexperts have attempted to summarise theircomments at the end of each session if theyfound something worth summarising.
Ourobservations included:1.
The main task is to identify the abnormaldata and summarise it.
However, anabnormal trend in a specific channel mighthave been caused due to a change in anotherchannel (for instance, an increase in theoutput voltage can be explained with acorresponding increase in the fuel input).Thus individual channel data needs to beinterpreted in the context of the otherchannels.2.
The expert agrees during the KA sessionthat he first analyses the data numerically toobtain  qualitative trends relating to the GTbefore generating comments.
Therefore thestate of the GT that produced the data isconstructed through data interpretation andthe knowledge of the state is then used tocheck if the turbine is in a healthy state ornot.
Since GT is an artefact created byhumans it is possible to have a fairlyaccurate model of states of a GT (unlikeweather!).3.
The phrases used by the expert often expressthe trends in the data as if they werephysical happenings on the turbine, like?running down?
for a decreasing trend inshaft speed data.
This indicates that theexpert is merely expressing the state of theGT.
This in turn indicates that at the timethe summarisation is done, the mental modelof the state of the GT is available.5 Evidence from Other ProjectsAfter making the above observations, weexamined think-aloud transcripts from an earlierproject at the University of Aberdeen, STOP(Reiter et al 2000), which involved building anNLG system that produced smoking-cessationletters from smoking questionnaires.
Thesetranscripts (from think-aloud sessions of doctorsand other health professionals manually writingsmoking-cessation letters) showed that in thisdomain as well experts would usually first buildan overview (in this case, of the smoker) beforestarting to determine the detailed content of aletter.
Below is an excerpt from one of thetranscripts of a KA session :?
?.
The first thing I have got to do is to readthrough the questionaire just to get some idea ofwhere he is at with his smoking.
??
?We did not investigate overview formation inany detail in STOP, but the issue did come uponce in a general discussion with a doctor aboutthe think-aloud process.
This particular doctorsaid that he built in his mind a mental image ofthe smoker (including a guess at what he or shelooked like), and that he found this image veryuseful in deciding how best to communicatewith the smoker.In another work, RajuGuide, once again there isevidence of an overview influencing contentdetermination (Sripada 1997).
RajuGuide is asystem that generates route descriptions.
At ahiger level of abstraction, RajuGuide has twoparts.
The first part is responsible for planningthe route the user wanted.
The second module isresponsible for generating the text describing theroute.
The route computed by the first part,which is in the form of a series of coordinates, isnot directly communicated to the user.
Insteadthe second part attempts to enrich the routedepending upon what the user already knowsand what additional information the knowledgebase knows for that particular route.
We believethat the route computed by the route planner isthe overview in this case and it drives thecontent determination process in the second part.6 Two-stage Model for contentdeterminationThese observations have led us to make thefollowing hypotheses:1.
Humans form a qualitative overview of theinput data set.2.
Not all the information in the overview isused in the text.3.
The overview is not dependent on pragmaticfactors such as the user?s taste, these areconsidered at a later stage of the contentdetermination process.Based on the above hypotheses, we propose atwo-stage model for content determination asdepicted in Figure 1.
It is assumed that DomainData Source (DDS) is external to the textgenerator.
It has been assumed that a DomainProblem Solver or Domain Reasoner (DR) isavailable for data processing.
This reasoningmodule is essentially useful to draw inferenceswhile interpreting the input data set andultimately is responsible for generating theoverview.
Communication Goal (CG) is theinput to the data summarisation system inresponse to which it accesses DDS to producean overview of the data using the DR.
In thecontext of the overview produced by DR, theData ComprehensionGoal (Derived fromComm.
Goal)DomainData Source(DDS)DomainReasoner (DR)DataOverview CommunicationReasoner (CR)FinalContentCommunicationGoalConstraintsdue to UserConstraints due to otherpragmatic factorsFigure 1.
Two stage model for content determinationCommunication Reasoner (CR) systemgenerates the final content specification takinginto account the influence of the UserConstraints (UC) and other pragmatic factors.This content is then sent to subsequent NLGmodules (not shown), such as microplanningand surface realisation.Our model has some similarities to the oneproposed by Barzilay et al (1998), in that theDomain Reasoner uses general domainknowledge similar to their RDK, while theCommunication Reasoner uses communicationknowledge similar to their CDK and DCK.The central feature of the above model is theidea of data overview and its effect on contentselection.
One possible use of overviews is totrigger context-dependent content rules.
Thetime-series analysis part of SUMTIME  is largelybased on Shahar's model (1997), which makesheavy use of such rules.
In Shahar's modelcontexts are inferred by separate mechanisms;we believe that these should be incorporated intothe overview, but this needs furtherinvestigation.At the current stage of our project we have onlya gross idea of what makes up the proposed dataoverview.
Our suspicion is that it is hard tomake a generic definition of the data overviewfor all domains.
Instead, we would like toimagine the data overview as the result ofinferences made from the input data so as tohelp in triggering the right content determinationrules.
For example, in out meteorology domain,the input time-series data comes from anumerical weather prediction (NWP) model, buteven the most sophisticated NWP models do notfully represent the real atmosphere ?
all modelswork with approximations.
Thus the NWP datadisplayed to the meteorologist is interpreted byhim to arrive at a conceptual model in his or herhead, which is the overview.7  Issues with the two stage modelThere are a number of issues that need to beresolved with respect to the two-stage modeldescribed above.7.1 Is overview creation a humanartefact?The main basis for including the overview intwo stage model has been the observation madeduring the think aloud sessions that experts formoverviews before writing texts.
Now it can beargued that even if humans need an overview,computer programs may not.
Evidently, it ishard to ever prove the contrary.
But what can bedone is to show the advantages gained by acomputer program by using an overview forcontent selection.7.2 Does the overview have any otherutility than just providing context forcontent determination rules?We believe that the overview can play multipleroles in the overall process of writing textualforecasts.
First, the overview can bring inadditional information into the text that is notdirectly present in the underlying raw data.
InReiter and Dale's (2000) terminology, overviewsare a technique for generating Computable Datacontent, that is content which is not directlypresent in the input data but can be computed orinferred from it.
Such content provides much ofthe value of summary texts.
Indeed, one couldargue that simple textual descriptions of a set ofdata values without extra computed or inferredcontent, such as those produced by TREND(Boyd, 1997), might not be that much moreuseful than a graph of the data.The overview may also help in deciding howreliable the input data is, which is especiallyimportant in the meteorology domain, since thedata comes from an NWP simulation.
Thiscould, for example, help the generation systemdecide whether to use precise temporal termssuch as Midnight  or vague temporal terms suchas tonight.
Again one could argue that the abilityto convey such uncertainty and reliabilityinformation to a non-specialist is a keyadvantage of textual summaries over graphs.In general, the overview allows reasoning to becarried out on the raw data and this willprobably be useful in many ways.7.3  How is the overview related to thedomain ontology?The basic concepts present in an overview maybe quite different from the basic conceptspresent in a written text.
For example, theoverview built by our expert meteorologist wasbased on concepts such as lapse rate (the rate atwhich temperature varies with height),movement of air masses, and atmosphericstability.
However, the texts he wrotementioned none of these, instead it talked aboutwind speed, wind direction, and showers.
In theSTOP  domain, overviews created by doctorsseemed to often contain many qualitativepsychological attributes (depression, self-confidence, motivation to quit, etc) which werenot explicitly mentioned in the actual textswritten by the doctors.This suggests that the conceptual ontology, thatis the specification of underlying concepts,underlying the overview may be quite differentfrom the ontology underlying the actual texts.The overview ontology includes concepts usedby experts when reasoning about a domain (suchas air masses or motivation), while the textontology includes concepts useful forcommunicating information to the end user(such as wind speed, or longer life expectancy).7.4  What do experts think about the two-stage model?When the two stage model was reported back toa WNI expert who participated in a think-aloudsession, the expert agreed that he does build anoverview (as he did during the KA session)while writing forecasts, but felt that it?s use maynot be necessary for writing all forecasts.
In hisopinion, the interpretation of most data setsdoesn?t require the use of the overview.However, he was quick to add that the quality ofthe forecasts can be improved by usingoverviews which faciliate reasoning with theweather data.8  EvaluationWe are currently building a testbed systemcalled SUMTIME-MOUSAM  which will enable usto test the hypotheses we have presented in thispaper and other hypotheses suggested by ourKA activities.
SUMTIME-MOUSAM  is aframework system that consists of?
"Infrastructure" software for accessing datafiles, regression testing of new softwareversions, etc.?
An ontology, which defines a conceptuallevel of representation of texts.?
A corpus of human-written texts with theircorresponding conceptual representationsdefined using the above ontology.?
Scoring software which compares the outputof a module (either at a conceptual or textlevel) against the human corpus.Because we are primarily interested in contentissues, it is important to evaluate our system at acontent level as well as at a text level.
Tosupport this, we are developing conceptualrepresentations of the texts we will begenerating, which can also be extracted fromhuman texts by manual analysis.SUMTIME-MOUSAM  is currently best developedin the area of producing wind texts.
In this area,we have developed a conceptual representationand manual annotation guide (with good inter-annotator agreement, generally kappa values of.9 or higher); built an initial software system toautomatically produce such texts based on athreshold model without an overview; andbegun the process of analysing differences.
Weare currently working on extending SUMTIME-MOUSAM  to other parts of weather forecasts,such as statements describing clouds andprecipitation, and plan in the future to extend itto the gas-turbine domain.With regard to testing hypotheses specificallyabout two-stage content determination (thesubject of this paper), our plan is as follows1.
Compare the output of the non-overviewbased software to human summary texts,and identify cases where an overview seemsto be used.2.
Ask human experts to build an overview(using a GUI), modify our software to usethis overview when generating texts, and seeif this results in texts more similar to thehuman texts.3.
Attempt to automatically generate theoverview from the data, and again comparethe resultant texts to human texts.At some point towards the end of SUMTIME, wealso hope to conduct user task evaluations.
Forexample, we may show gas-turbine engineersour summary texts and see if this helps themdetect problems in the gas turbine.9  ConclusionOur experience in three domains shows thathuman experts build qualitative overviews whenwriting texts, and that these overviews are usedby the experts for inference and to provide acontext for specific content rules.
We believethat overviews could also be very useful incomputer NLG systems, and are currentlyworking on testing this hypothesis, as part of theSUMTIME  project.AcknowledgementsMany thanks to our collaborators atWNI/Oceanroutes and Intelligent Applications,especially Ian Davy, Dave Selway, Rob Milne,and Jon Aylett; this work would not be possiblewithout them!
Thanks also to Sandra Williamsand the anonymous reviewers for theircomments on a draft of this paper.
This projectis supported by the UK Engineering andPhysical Sciences Research Council (EPSRC),under grant GR/M76881.ReferencesAllen J. and Perrault C. R. (1980).
AnalyzingIntention in Utterances.
Artificial Intelligence,26:1-33.Barzilay R, McCullough D, Rambow O,DeChristofaro J, Korelsky T, and Lavoie B (1998)A New Approach to Expert System Explanations,In Proceedings of INLG-1998,  pages 78-87.Boyd S (1997).
Detecting and Describing Patterns inTime-varying Data Using Wavelets.
In Advancesin Intelligent Data Analysis: Reasoning AboutData, X Lui and P Cohen (Eds.
), Lecture Notes inComputer Science 1280, Springer Verlag.Fiedler A (1998).
Macroplanning with a CognitiveArchitecture for the Adaptive Explanation ofProofs.
In Proceedings of INLG-1998, pp 88-97.Goldberg E, N Driedger and RL Kittredge (1994),Using Natural-Language Processing to ProduceWeather Forecasts,  IEEE Expert,  9, 2, pp 45-53.McKeown K, Kukich K, Shaw J (1994).
PracticalIssues in Automatic Document Generation.
InProceedings of ANLP-1994,  pp 7-14.Mittal V, Moore J, Carenini G, and Roth S (1998).Describing Complex Charts in Natural Language:A Caption Generation System.
ComputationalLinguistics 24: 431-467.Reiter E. and Dale R. (2000)  Building NaturalLanguage Generation Systems.
CambridgeUniversity Press.Reiter E., Robertson R. and Osman L. (2000)Knowledge Acquisition for Natural LanguageGeneration.
In Proceedings of the FirstInternational Conference on Natural LanguageGeneration (INLG-2000), 217-224 pp.Shahar Y (1997), ?Framework for Knowledge-BasedTemporal Abstraction?, Artificial Intelligence90:79-133..Sripada S. G. (1997) Communicating Plans inNatural Language: Planning and Realisation.PhD Thesis,  Indian Institute of Technology,Madras, India.Sripada S. G. (2001) SUMTIME: Observations fromKA for Weather Domain.
Technical Report,Computing Science Dept.
Univ of Aberdeen,Aberdeen AB24 3UE, UK.
Awaiting approvalfrom industrial collaborators.
