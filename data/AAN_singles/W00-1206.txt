Enhancement of a Chinese Discourse Marker Tagger with C4.5Benjamin K. T'sou l, Torn B. Y. Lai 2, Samuel W. K. Chan 3, Weijun Gao 4, Xuegang Zhan 523Languag e Information Sciences Research CentreCity University of Hong KongTat Chee Avenue, KowloonHong Kong SAR, ChinaNortheastern U iversity, China{ ~rlbtsou, 2ettomlai} @uxmail.cityu.edu.hk, 3swkchan@cs.cityu.edu.hk,4wj gao@mail.neu.edu.cn, Szxg@ics.cs.neu.edu.cnAbstractDiscourse markers are complexdiscontinuous linguistic expressions whichare used to explicitly signal the discoursestructure of a text.
This paper describesefforts to improve an automatic taggingsystem which identifies and classifiesdiscourse markers in Chinese texts byapplying machine learning (ML) to thedisambiguation f discourse markers, as anintegral part of automatic text summarizationvia rhetorical structure.
Encouraging resultsare reported.Keywords: discourse marker, Chinesecorpus, rhetorical relation, automatic tagging,machine learning1 IntroductionDiscourse refers to any form oflanguage-based communication involvingmultiple sentences or utterances.
The mostimportant forms of discourse of interest oNatural Language Processing (NLP) are textand dialogue.
The function of discourseanalysis is to divide a text into discoursesegments, and to recognize and re-constructthe discourse structure of the text as intendedby its author.Automatic text abstraction has receivedconsiderable attention (Paice 1990).
Varioussystems have been developed (Chan et al2000).
Ono et al (1994), T'sou et al (1992)and Marcu (1997) focus on discoursestructure in summarization using theRhetorical Structure Theory (RST, Mann andThompson 1986).
The theory has beenexploited in a number of computationalsystems (e.g.
Hovy 1993).
The main idea isto build a discourse tree where each node ofthe tree represents an RST relation.Summarization is achieved by trimminglmimportant sentences on the basis of therelative saliency or rhetorical relations.The SIFAS (Syntactic Marker basedFull-Text Abstraction System) system hasbeen implemented to use discourse markersin the automatic summarization of Chinese(T'sou et al 1999).
In this paper, we reportour efforts to improve the SIFAS taggingsystem by applying machine learningtechniques to disambiguation of discoursemarkers.
C4.5 (Quirdan, 1993) is used in oursystem.2 Manual Tagging ProcessTo tag the discourse markers, thefollowing coding scheme is designed toencode Real Discourse Markers (RDM)appearing in the SIFAS corpus (T'sou et al1998).
We describe the z ~h discourse markerwith a 7-tuple RDM;RDMi=< DM i, RRi, RPi, CTi, MNi,RNi, OT i >, where38DMiRP i ::MN~ :RNi :OT~ :the lexical item of theDiscourse Marker, or thevalue'NULL'.the Rhetorical Relation inwhich DIVI~ is a constituentmarker.the Relative Position of DMi.the Connection Type of RRi.the Discourse MarkerSequence Number.the Rhetorical RelationSequence Number.the Order Type of RR~.
Thevalue of OTi can be 1, -1 or 0,denoting respectively thenormal order, reverse order orirrelevance of the premise-consequence ordering of RR i .For apparent discourse markers that donot function as a real discourse marker in atext, a different coding scheme is used toencode them.
We describe the i th apparentdiscourse marker using a 3-Tuple ADM~:ADMi =< LIi, *, SNi >, whereLIi : the Lexical Item of theapparent discourse marker.SNi : the Sequence Number of theapparent discourse marker.In Chinese, discourse markers can beeither words or phrases.
To tag the SIFAScorpus, all discourse markers are organizedinto a discourse marker pair-rhetoricalrelation correspondence table.
Part of thetable is shown Table 1.To construct an automatic taggingsystem, let us first examine the sequentialsteps in the tagging process of a humantagger.S1.
Written Chinese consists of rurming textswithout word delimiters; the first step isis to segment the text into Chinese wordsequences.$2.
On the basis of a discourse marker list,we identify those words in the textwhich appear on the list as CandidateDiscourse Markers (CDMs).$3.
To winnow Real Discourse Markers(RDMs) and Apparent DiscourseMarkers (ADMs) from the CDMs, andencode the ADMs with a 3-tuple.$4.
To encode the RDM with a 7-tupleaccording to a Discourse Marker Pair-Rhetorical Relation correspondencetable.Relat-ionAdver-sativityAdver-sativityCausa-ntyCausa-lityFront Back Con-nectionTypeInterIntraIntra 1Intra -1Table 1 Discourse Marker Pair-Rhetorical Relation TableOrderType3 Automat ic  Tagg ing  ProcessThe identification of candidate discoursemarkers is based on a discourse marker list,which now contains 306 discourse markersplus a NULL marker.
The markers areextracted from newspaper editorials of HongKong, Mainland China, Taiwan andSingapore.
These markers constitute 480distinct discontinuous pairs that correspondto 25 rhetorical relations.
In actual usage,some discourse marker pairs designatemultiple rhetorical relations according tocontext.
Some pairs can represent bothINTER-sentence and INTRA-sentencerelations.
Thus the correspondence b tweenthe discourse marker pairs and the rhetoricalrelations is not single-valued.
Somediscourse marker pairs correspond to morethan one rhetorical relation or connectiontype.
We have 504 correspondences betweenthe discourse marker pairs and the rhetoricalrelations.39In practice, one discontinuousconstituent member of a marker pair is oftenomitted.
We use the NULL marker toindicate the omission.
In the 504correspondences, 244 of them are doubleconstituent marker pairs, 260 are singleconstituent markers (i.e.
One of the markersis NULL).
And in the 244 double constituentmarkers, only 3 are not single-valuedcorrespondences (one of" which is anINTER/INTRA relation, and can easily bedistinguished.).
Thus the tagging of the 244double constituent markers is basically atable searching process.
But for the 260single constituent markers, the identity of theNULL marker is often difficult o determine.The SIFAS tagging system works in twomodes: automatic and interactive (semi-automatic).
The automatic tagging procedureis as follows:1.
Data preparation: Input data files aremodified according to the requiredformat.2.
Word segmentation: Because there areno delimiters between Chinese words ina text, words have to be extractedthrough asegmentation process.3.
CDM identification4.
Full-Marker RDM recognition5.
ADM identification (first pass,deterministic)6.
CDM feature xtraction7.
ADM identification (2nd pass, via ML)8.
Tagging NuLL-marker CDM pairs (viaML)9.ADM and RDM sequencing, proof-reading, training data generation, andstatisticsThe following principles are adopted bythe tagging algorithm to resolve ambiguity inthe process of matching discontinuousdiscourse markers:1. the principle of greediness: Whenmatching a pair of discourse markers fora rhetorical relation, priority is given tothe first matched relation from the left.2.the principle of locality: Whenmatching apair of discourse markers fora rhetorical relation, priority is given tothe relation where the distance betweenits constituent markers is shortest.3.the principle of explicitness: Whenmatching a pair of discourse markers fora rhetorical relation, priority is given tothe relation where both markers areexplicitly presented.4.
the principle of superiority: Whenmatching a pair of discourse markers fora rhetorical relation, priority is given tothe inter-sentence r lation whose backdiscourse marker matched with the firstword of a sentence.5.
the principle of Back-markerpreference: This is applicable only torhetorical relations where either thefront or the back marker is absent, or toa NULL marker.
In such cases, priorityis given to the relation with the backmarker present.Steps 1 to 6 and the five principlesunderlie the original naive tagger of theSIFAS system (T'sou et al 1998), which alsocontains the system framework.4 Improvement4.1 ProblemsMany Chinese discourse markers haveboth discourse senses and alternate sententialsenses in different context.
For a humantagger, steps $3 and $4 in section 2 are notdifficult because he/she can identify anADM/RDM based on his/her textcomprehension.
However, for an automaticprocess, it is quite difficult o distinguish anADM from an RDM if no syntactic/semanticinformation is available.Another problem is the location ofNULL-Marker described above.
Our earlierstatistics howed some characteristics in thedistance measured by punctuation marks.Statistics from 80 tagged editorials how thatmost of the relations are INTRA-Sentencerelations (about 93%), about 70% of theINTRA RDM pairs have NULL markers.Most of these RDM pairs are separated byONE comma (62%).
These statistics how40the importance of the problems ofpositioning the NULL markers.The naive tagger partially solved theCDM discrimination and NULL markerlocation problems.
Our experiment showsthat about 45% of the ADMs can becorrectly identified, and about 60% of theNULL markers can be correctly located onecomma/period away from the current RDM.This leaves much room for improvement.One solution is to add a few rulesaccording to previous tatistics.
The originalnaive tagger did not assume any knowledgeof the statistics and behavioral patterns ofdiscourse markers.
From the error analysis,we extracted some additional rules to guidethe classification and matching of thediscourse markers.
For example, one of therules we extracted is:"A matching pair must be separated byat least two words or by punctuationmarks".
Using this rule, the followingfull marker matching error is avoided.< ~ ~ >< ~ ~ >< ~ x ~ ><./~ ,conjunction,Front, Intra,5,5,1>< ~ >< ~,conjunction, Back, Intra, 6,5,1><~>, <~t~><7~?~x~><~><t$ i~>,  <~,* ,7xf f~><X><~x<~><~x~><~x~_~><~>0Another solution is to use?
syntactic/semantic information throughmachine learning.4.2 C4.5Most empirical learning systems aregiven a set of pre-classified cases, eachdescribed by a vector of attribute values, andconstruct from them a mapping fromattribute values to classes.
C4.5 is one suchsystem that learns decision-tree classifiers.
Ituses a divide-and-conquer approach togrowing decision trees.
The current versionof C4.5 is C5.0 for Unix and See5 forWindows.Let attributes be denoted A={a~, a2, ...,a,,J, cases be denoted D={d 1, d2, ..., d J ,  andclasses be denoted C={c, c 2, ..., cJ.
For aset of cases D, a test 1q is a split of D basedon attribute at.
It splits D into mutuallyexclusive subsets D~, D 2, ..., D r Thesesubsets of cases are single-class collectionsof cases.If a test T is chosen, the decision treefor D consists of a node identifying the testT ,  and one branch for each possible subsetD~.
For each subset D~, a new test is thenchosen for further split.
If D~ satisfies astopping criterion, the tree for Dr is a leafassociated with the most frequent class in D~.One reason for stopping is that cases in D~belong to one class.C4.5 uses arg max(gain(D,1)) or argmax(gain ratio(D,T)) to choose tests forsplit:kInfo(D) = -~p(c , ,D)  * log2(p(c,,D))i=ISplit(D,T) = _L ID ,  I .
log2(~-~)i=l IDIGain(D,T) = Info(D)- "J"'~.~'.
Di I.  Info(Di)i=l I DIGain ratio(D, T) = gain(D, T) / Split(D, T)where, p(c~,D) denotes the proportion ofcases in D that belong to the i th class.4.3 Application of C4.5Since using semantic informationrequires a comprehensive thesaurus, which isunavailable at present, we only use syntacticinformation through machine learning.The attributes used in the originalSIFAS system include the candidatediscourse marker itself, two wordsimmediately to the left of the CDM, and twowords immediately to the right of the CDM.The attribute names are F2, F1, CDM, B1,B2, respectively (T'sou et al 1999).
SIFASonly uses the Part Of Speech attribute of theneighboring words.
This reflects to somedegree the syntactic characteristics of theCDM.To reflect the distance characteristics,we add two other attributes: the number ofdiscourse delimiters (commas, semicolonsfor INTRA-sentence relation, periods and41exclamation marks for INTER-sentencerelation) before and after the current CDM,denoted Fcom and Boom, respectively.
Forthe location of the NULL marker, we stilladd an actual number of delirniters Acorn.The order of these attributes is: CDM,F1, F2, B1, B2, Fcom, Boom Acorn for Nullmarker location, and CDM, F1, F2, B1, B2,Fcom, Bcom, IsRDM for CDM classification,where IsRDM is a Boolean value.The following are two examples ofcases:9~: _N.
,?,q,a,a,7,1,1 for NULL markerlocationN~,d,?,u,?,l ,0,F for CDM classificationwhere "?"
denotes that no correspondingword is at the position (beginning or end ofsentence); a, d, q, and u are part-of-speechsymbols in our segmentation dictionary,representing adjective, adverb, classifier, andauxiliary, respectively.The following are two examples of therules generated by the C4.5.
The first is aCDM classification rule, and the other is aNULL marker location rule.Rule 5: (11/1, lift 2.2)CDM =B1 =vFcom > 0class T \[0.846\]which can be explained as: if the word afterthe CDM "~:" is a verb, and there is onecomma in the sentence, before "~J:~:", then"~:" is an RDM.Rule 22: (1, lift 3.4)B2 = pFcom > 1class 2 \[0.667\]which can be explained as: if the secondword after the RDM is a preposition, andthere is more then one commas before thecurrent RDM, then the location of the NULLmarker is two commas away from the RDM.4.4 Objects in the SIFAS systemThe objects in the new SIFAS taggingsystem are listed below.1.
Dictionary Editor: for the update ofword segmentation dictionary and therhetorical relation table.2.
Data Manager: for the modification ofthe input data (editorial texts) toconform with the required format.3.
Word Segmenter: for the segmentationof the original texts, and the recognitionof CDMs.4.
RDM Tagger: The initial identificationof RDMs is a table searching process.All those full-marker pairs are identifiedas rhetorical relations according to theprinciples described above.
For thoseNull-marker pairs, the location of theNull maker is left to the rule interpreter.5.
ADM Tagger: The identification ofADMs is also a table searching process,because, without othersyntactic/semantic information, the onlyway to identify ADMs from the CDMsis to find out that the CDM cannot forma valid pair with any other CDMs(including the NULL marker) tocorrespond to a rhetorical relation.6.
CDM Feature Extractor: For thoseuntagged CDMs, the classification iscarried out through C4.5.
The FeatureExtractor extracts yntactic informationabout he current CDM and send it to theRule Interpreter (see below).7.
Rule Interpreter: C4.5 takes feature datafile as the input to construct a classifier,and the rules formed are stored in anoutput file.
The rule interpreter eadsthis output file and applies the rules toclassify the CDMs.
In our system, TheRule Interpreter functions as a NULLMarker Locator and a CDM classifier.8.
Sequencer: for the rearrangement ofRDM and ADM order number.
In therearranging process, the Sequencer alsoextracts statistical information foranalysis.9.
Interaction Recorder: for the recordingof user interaction information for42statistics use.10.
Data Retriever: for data retrieval andbrowsing.5 EvaluationIn order to evaluate the effectiveness ofthe tagging system in terms of the percentageof discourse markers that can be taggedcorrectly, we have chosen 80 taggededitorials from Ming Pao, a Chinesenewspaper of Hong Kong, in the durationfrom December 1995 to January 1996 toform a training data set.
Then we randomlyselected 20 editorials from Mainland Chinaand Hong Kong newspapers for the systemto tag automatically, and then manuallychecked the results.The total CDMs in the training data setis 4764, in which 2116 are RDMs and 2648are ADMs.
The distribution of INTER-sentence r lations, INTRA-sentence r lations,and NULL marker pairs is shown below.TotalRelationsInter-SentenceRelationsIntra-SentenceRelationsRelationswithNULLmarkerpair1589 98 1491 1062100% 6.17% 93.83% 66.83%Table 2 Distribution of INTER-/INTRA-sentence relations,and NULL marker pairsOur evaluation is based on counting thenumber of discourse markers that arecorrectly and incorrectly tagged.The total CDMs in the test data set is1134, in which 563 are RDMs and 571 areADMs.
The distribution of INTER-sentencerelations, INTRA-sentence relations, andNULL marker pairs in the test data set isshown in Table 3.TotalRelationsInter-SentenceRelationsIntra-SentenceRelationsRelationswithNULLmarkerpair424 23 401 285100% 5.42% 94.58% 67.22%Table 3 Distribution of INTER-/INTRA-sentence relations, and NULL markerpairs in testing data set451 399 11 1 65 3Table 4 Test ResultsFrom the test results shown in Table 4,we can see that most of the errors are causedby the misclassification f the CDMs.
Anexample of Other errors is shown below.The following sentence is from an editorialof People's Daily.< ~ ~17 >< ~ ~.~ >< ~ ~ > ,<NULL,sufficienc y, Front, Intra, O,81,1x -- ~ ~ff \[\]><~ ><~.
~lJ><~.~.>< \[\] ~>,  <~><~iA><--+~ \[ \ ]><~><)~lJ>, <~><~iA><~><~,*,80><~ \[\]><1~><--~52">, <~~><~,sufticiency, Back,Intra,81,81,1 < ~ ~ x :~ x~.><~><~>,  <~ ~><~ :~ ><~,*,SZ><~ l~J,><~>?In the above sentence, the first "R"  ismatched with the NULL marker, but thesecond "R" is left as an ADM.
This causesan "Other error" and an "ADM/RDMclassification error".The Gross Accuracy (GA) as defined inT'sou et al (1999) is:GA = correctly tagged discoursemarkers / total number of discourse markers= 95.38%This greatly improves the performancecompared with the original GA = 68.89%.The overgeneration problem (tagged 415,actual 424) is caused by the mismatch ofCDMs as RDM pairs, or by the43misclassification of CDMs as RDMs.Following are two examples.< ~\[I ~ ,sufficieney, Front, Intra,54,54,1x ~ ~1"\] >_<~\[1- ~><~,* ,56x~xf f  ~ >, <~A.x~x~ :t:>< ~ > , < ~1~.
,sufficieney, Back,Intra,57,54,1>_<,*,58><~ x~ ~><~><:~ ~x~ ~x><~I l~ .
l><~x(~ ~ x~,* ,59><~ A.x~ ~><:t:~><--~>?In this example, "~tl ~"  could havematched <:~,*.55>, < ~,*,56>, or<~,*,58>.Only the <:~,*,55> and the <~,*,58> can beeliminated from the candidates according tothe "simple rules" mentioned in section 4.1.The system has to choose from <~,*,56> and<}J~,*,57> to match with "~zn~'.
Luckily,the system has given a right choice here.< --  ~" ~ \[\] >< ~ ,conjunction,Front, Intra,46,46,1><~~><~><~r~> , <NULL,conjunction,Front, Intra,0,49,1 ><-- f" ~ \[\] ><)~>< ~,~ ,conjunction,Back, Intra,47,46,1><~i~,*,48>< ~ ~><1~ \]\]~><~E ~><~><~ ><~ \[\] A .><~><~ ~ ><th~> , <,eonjunction,Baek,Intra,49,49,1>< ~ ~tJ ~><?x~ ~><\[ \ ]  ~><~n><~,*,50><l~#\[\]><~ I x~x\ [ \ ]  g,~><~ ~>< ~ ><Lib>.The two "~" are misclassified as RDMs,and causes a mismatch of RDM pair.
Sucherrors are difficult to avoid for an automaticsystem.
Without further syntactic/semanticanalysis, we can only hope for the MLalgorithm to give us a solution from moretraining data.6 Conc lus ionIn order to study discourse markers foruse in the automatic summarization ofChinese text, we have designed andimplemented the SIFAS system.
In thispaper, we have focused on the problems ofNULL marker location and the classificationof RDMs and ADMs.
A study on applyingmachine learning techniques to discoursemarker disambiguation is conducted.
C4.5 isused to generate decision tree classifiers.
Ourresults indicate that machine learning is aneffective approach to improving the accuracyof discourse marker tagging.
For interactiveuse of the system, if we set a threshold forthe rule precision and only display those lowprecision rules for interactive selection, wecan greatly speed up the semi-automatictagging process.7 ReferencesChart S., Lai T., Gao W. J. and T'sou B. K.(2000) "Mining Discourse Markers forChinese Textual Summarization."
InProceedings of the Sixth Applied NaturalLanguage Processing Conference and theNorth American Chapter of theAssociation for Computational Linguistics.Workshop on Automatic Summarization,Seattle, Washington, 29 April to 3 May,2000.Grosz B.J.
and Sidner C. (1986) "Attention,Intention, and the Structure of Discourse,"Computational Linguistics 12(3): 175-204.Hirst G. (1981) "Discourse OrientedAnaphoral Resolution in Natural LanguageUnderstanding: A Review."
ComputationalLinguistics 7(2): 85-98.Hovy E. (1993) "Automated DiscourseGeneration using Discourse StructureRelations."
Artificial Intelligence 63: 341-385.Hwang C. H. and Schubert L. K. (1992)"Tense Trees as the 'Fine Structure' ofDiscourse."
In Proc.
30th Annual Meeting,Assoc.
for Computational Linguistics, pp.232-240.Lin H. L., T'sou B. K., H. C. Ho, Lai T., LunC., C. K. Choi and C.Y.
Kit.
(1991)"Automatic Chinese Text GenerationBased on Inference Trees."
In Proe.
ofROCLING Computational LinguisticConference IV, Taipei, pp.
215-236.Litman D. J. and Allen J.
(1990) "DiscourseProcessing and Commonsense Plans."
InCohen et al(ed.)
Intentions inCommunications, pp.
365-388.Mann W. C. and Thompson S. A (1988)"Rhetorical Structure Theory: Towards aFunctional Theory of Text Organization."44?
Text 8(3): 243-281.Marcu D. (1997) "From Discourse Structuresto Text Summaries."
In Proceedings of theACL/EACL'97 Workshop on IntelligentScalable Text Summarization, Spain, pp.82-88.McKeown K. and Radev D. (1995)"Summaries of Multiple News Articles.
"In Proceedings of the 18th AnnualInternational ACM SIGIR Conference onResearch and Development in InformationRetrieval, Seattle, pp.
74-82.Ono K., Surnita K. and S. Miike.
(1994)"Abstract Generation based on RhetoricalStructure Extraction."
In Proceedings ofInternational Conference onComputational Linguistics, Japan, pp.
344-348.Paice C. D. (1990) "Constructing LiteratureAbstracts by Computer: Techniques andProspects."
Information Processing andManagement 26(1): 171-186.Qulnlan J. Ross (1993) "C4.5 Programs forMachine Learning."
San Mateo, CA:Morgan Kaufmann.T'sou B. K., Ho H. C., Lai B.
?., Lun C. andLin H. L. (1992) "A Knowledge-basedMachine-aided System for Chinese TextAbstraction."
In Proceedings ofInternational Conference onComputational Linguistics, France, pp.1039-1042.T'sou B. K., Gao W. J., Lin H. L., Lai T. B.Y.
and Ho H. C. (1999) "TaggingDiscourse Markers: Towards a Corpusbased Study of Discourse Marker Usage inChinese Text" In Proceedings of the 18thInternational Conference on ComputerProcessing of Oriental Languages, March1999, Japan, pp.
391-396.T'sou B. K., Lin H. L., Ho H. C., Lai T. andChan T. (1996) "Automated Chinese Full-text Abstraction Based on RhetoricalStructure Analysis."
Computer Processingof Oriental Languages 10(2): 225-238.Tsou, B.K., et al, 1998: ~1~,  ~ ,i ~ ~ 1 - ~ 3 - ~ ~  ~ ~ " ,ICCIP'98, Beijing, Nov. 18-20, 1998.45
