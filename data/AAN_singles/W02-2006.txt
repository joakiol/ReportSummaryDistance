Bootstrapping a Multilingual Part-of-speech Taggerin One Person-daySilviu Cucerzan and David YarowskyDepartment of Computer Science andCenter for Language and Speech ProcessingJohns Hopkins UniversityBaltimore, MD 21218 USA{silviu,yarowsky}@cs.jhu.eduAbstractThis paper presents a method for bootstrapping afine-grained, broad-coverage part-of-speech (POS)tagger in a new language using only one person-day of data acquisition effort.
It requires only threeresources, which are currently readily available in60-100 world languages: (1) an online or hard-copypocket-sized bilingual dictionary, (2) a basic libraryreference grammar, and (3) access to an existingmonolingual text corpus in the language.
The al-gorithm begins by inducing initial lexical POS dis-tributions from English translations in a bilingualdictionary without POS tags.
It handles irregular,regular and semi-regular morphology through a ro-bust generative model using weighted Levenshteinalignments.
Unsupervised induction of grammaticalgender is performed via global modeling of context-window feature agreement.
Using a combination ofthese and other evidence sources, interactive train-ing of context and lexical prior models are accom-plished for fine-grained POS tag spaces.
Experi-ments show high accuracy, fine-grained tag resolu-tion with minimal new human effort.1 IntroductionPrevious work in minimally supervised languagelearning has defined minimal using several differentcriteria.
Some have assumed only partially taggedtraining corpora (Merialdo, 1994), while othershave begin with small tagged seed wordlists (suchas Collins and Singer (1999) and Cucerzan andYarowsky (1999) for named-entity tagging).
Oth-ers have exploited the automatic transfer of somealready existing annotated resource in a differentmedium or language (such as the translingual pro-jection of part-of-speech tags, syntactic bracket-ing and inflectional morphology in Yarowsky et al(2001), requiring no direct supervision in the for-eign language).
Ngai and Yarowsky (2000) ob-served that an often more practical measure of thedegree of supervision is not simply the quantity ofannotated words, but the total weighted human la-bor and resource costs of different modes of su-pervision (allowing manual rule writing to be com-pared directly with active learning on a commoncost-performance learning curve).In this paper we observe that another useful mea-sure of (minimal) supervision is the additional costof obtaining a desired functionality from existingcommonly available knowledge sources.
In particu-lar, we note that for a remarkably wide range of lan-guages, academic libraries, many booksellers andwebsites offer a foundation of linguistic wisdom inreference grammars and dictionaries.
Thus startingfrom this baseline, what is the marginal cost of dis-tilling from and augmenting this existing knowledgeto achieve a desired new task functionality?2 Inducing POS Tag Candidates fromUnlabeled Bilingual DictionariesA substantial percentage of foreign language dic-tionaries that are available on line or in smaller pa-perback format are simple bilingual word or phrasetranslation lists which fail to specify part of speech.1Thus one component question of this work is howcan one extract preliminary part-of-speech distribu-tions from untagged monolingual translation lists.Figure 1 illustrates such a bilingual dictionary, alsospecifying the true part of speech for each possibletranslation, which we do not assume to be generallyavailable.One approach is to take an unweighted mixtureof the prior part-of-speech distributions for the En-glish words given in the translation list (TL) asillustrated in Figure 2.
These probabilities may beestimated from a large and preferably balanced, cor-pus.
In this work, we used statistics from the Brownand WSJ corpora combined.1In this section, we will use the term POS tag to denoteonly the main part-of-speech tags (noun, verb, adjective, ad-verb, preposition, etc.)
and not the fine-grained tags (such asNoun-Genitive-fem-plur-def).TrueRomanian POS English translation listmandat N warrant; proxy; mandate;money order;power of attorneymanechin N model, dummymanifesta V arise, express itself, showmanual Adj manual;N manual; textbook;handbookmare Adj large; big; great; tall;old; important;N seamaro Adj brown, chestnutFigure 1: A sample Romanian-English dictionary.The POS tags are used only for evaluation and arenot available in many bilingual dictionaries.MANDAT  WarrantProxyMandate.55  .00    .45.66   .34    .00.80  .20    .00.67   .18   .15N AVN AVe i jP(Pos  | e  )iFW P(Pos  | FW)j(via English treebank)dictionarybilingualviaFigure 2: Inducing a preliminary POS distributionfor the Romanian word mandat via a simple Englishtranslation list.However, when a translation candidate is phrasal(e.g.
mandat  money order), one can model themore general probability of the foreign word?s partof speech tag () given the part of speech sequenceof the English phrasal translation ().For example, one could model P(Tmoney or-der) via P(T and P(Tmanifest itself) viaP(T.
However, because English wordsoften have multiple parts of speech (e.g.
order maybe a verb), one may weight phrasal POS sequenceprobabilities (making an independence assumption)as: 	      	       	       	       	   And in general:         where   is estimated from the dictionaryas above.
Without an independence assumption:      There are two major options via which one canestimate  .
The first is to assumethat the part-of-speech usage of phrasal (English)translations is generally consistent across dictionar-ies (e.g.
  remains high regardlessof publisher or language).
Hence one could useany foreign-English bilingual dictionary that alsoincludes the true foreign word part of speech in ad-dition to its translations to train these probabilities.Alternately, one could do a first-pass assignmentof foreign-word part of speech based on only sin-gle word translations as in Figure 2, and use this totrain   for those foreign words hav-ing both phrasal and single-word definitions (suchas mandat).
The advantage of this approach is that itmay benefit dictionaries with different phrasal trans-lation styles from the training dictionary (e.g.
useor omission of the word ?to?
in verb definitions).However, given the assumption of relatively consis-tent dictionary formatting styles (which was unfor-tunately not the case for Kurdish), we evaluated thiswork based on supervised phrasal training from asingle independent third language dictionary.Table 1 measures the POS induction performanceon three languages, where the true POS tags weregiven in the dictionary (as in Figure 1), but ignoredexcept for evaluation.
The accuracy values in thistable are based on exact matches between a word?sdictionary-provided POS and the most probable tagin its induced distribution.For our target application of part-of-speech tag-ging, what matters is to have a robust tag probabil-ity distribution that includes the true candidate withsufficiently large probability to seed further train-ing.
By setting this baseline threshold to 0.1 anddeleting lower ranked candidates, up to 98% of thetrue POS were found to be above this threshold andhence were considered in future training.The Mean Probability of Truth, as shown in Ta-ble 1, is another measure of the quality of the POSpredictions made by the algorithm, representing theprobability mass associated with the true POS tagaveraged over all words.In some cases the algorithm could not predict aPOS tag, primarily due to English translations forwhich no POS distribution was known (often an ob-scure word, proper name or OCR error).
This oc-Target Training Accuracy Correct POS Coverage Mean ProbabilityLanguage Dictionary Exact POS Over Threshold of TruthRomanian Spanish - English 92.9 97.8 98 .91Kurdish Spanish - English 76.8 93.1 95 .82Spanish Romanian - English 83.3 94.9 97 .86Table 1: Performance of inducing candidate part-of-speech distributions derived solely from untagged En-glish translation lists.
Results are measured by type (all dictionary entries are weighted equally).casional omission is measured by the coverage col-umn.Most of the observed errors are due to differencesin phrasal definitional conventions in the trainingand testing dictionaries, long phrasal idioms, single-word definitions with ambiguous English parts-of-speech and OCR errors.
The Kurdish dictionary wasparticularly hindered by frequent long phrasal trans-lations which often included an explanation or def-inition in their translation.
Because all dictionaryentries are equally weighted, errors on rare wordssuch as mythological characters or kinship termscan substantially downgrade performance.
But forthe purposes of providing seed POS distributions tocontext-sensitive taggers, performance is quite ade-quate for this follow-on task.3 Inducing Morphological AnalysesThere has been extensive previous work in thesupervised and minimally supervised induction ofboth affix paradigms (e.g.
Goldsmith, 2000; Snoverand Brent, 2001) and diverse models of regular andirregular concatenative and non-concatenative mor-phology (e.g.
Schone and Jurafsky, 2000; van denBosch and Daelemans, 1999; Yarowsky and Wicen-towski, 2000).
While such approaches are impor-tant from the perspective of learning theory or broadcoverage handling of irregular forms, another pos-sible paradigm for minimal supervision is to beginwith whatever knowledge can be efficiently manu-ally entered from the grammar book in several hourswork.We defined such grammar-based ?supervision?
asentry of regular inflectional affix changes and theirassociated part of speech in standardized ordering offine-grained attributes, as in Table 2 for Spanish andRomanian.
The full tables have approximately 200lines each and required roughly 1.5-2 person-hoursfor entry.Given a dictionary marked with core parts ofspeech, it is trivial to generate hypothesized in-flected forms following the regular paradigms, asshown in the left size of Figure 3.
However, dueto irregularities and semi-regularities such as stem-Root InflectedAffix Affix Part-of-speech TagSpanish:o$ o$ Adj-masc-singo$ os$ Adj-masc-pluro$ a$ Adj-fem-singo$ as$ Adj-fem-plure$ e$ Adj-masc,fem-singe$ es$ Adj-masc,fem-plurar$ o$ Verb-Indic_Pres-p1-singar$ as$ Verb-Indic_Pres-p2-singar$ a$ Verb-Indic_Pres-p3-singar$ amos$ Verb-Indic_Pres-p1-plurar$ ?is$ Verb-Indic_Pres-p2-plurar$ an$ Verb-Indic_Pres-p3-plurRomanian:a?$ e$ Noun-Nomin-p3-fem-plur-indefe$ i$ Noun-Nomin-p3-fem-plur-indefea$ ele$ Noun-Nomin-p3-fem-plur-indefi$ ile$ Noun-Nomin-p3-fem-plur-indefa$ ale$ Noun-Nomin-p3-fem-plur-indef$ $ Adj-masc,neut-sing$ a?$ Adj-fem-sing$ i$ Adj-masc,neut,fem-plur$ e$ Adj-fem,neut-plurru$ ra$ Adj-fem-singru$ ri$ Adj-masc,neut,fem-plurru$ re$ Adj-fem-plur... ... ...e$ $ Verb-Indic_Pres-p1-singe$ i$ Verb-Indic_Pres-p2-singe$ e$ Verb-Indic_Pres-p3-singe$ em$ Verb-Indic_Pres-p1-plure$ et?i$ Verb-Indic_Pres-p2-plure$ $ Verb-Indic_Pres-p3-plurTable 2: Sample extracted regular inflectionalparadigms (suffix context is marked by $).changes, such generation will clearly have substan-tial inaccuracies and overgenerations.However, through weighted-Levenshtein-basediterative alignment models, such as described inYarowsky and Wicentowski (2000), one can per-form a probabilistic string match from all lexical to-kens actually observed in a monolingual corpus, asz->cdestrozan destroc?destroz?V-pres-3plV-pret-1sgV-subj-3pl destrozendestrocendestrozandestrozar/Vz->cdestruodestru?destruenV-pres-1sgV-pres-1sgV-pret-1sgdestrue destru?destruyodestruyedestruyendestruir/VV-pres-3sg->y->y?
?->yV-pres-3plV-pret-3pldoler/Vdormir/VV-pres-1sgdormenV-pres-3pldormodolendoli?o->ueo->uedoli?duelenduermenduermodormi?dorm?andorm?andurmi?V-pret-3plV-imprf-3plo->ueo->uObservedRootwordDictionary CorpusRegularWordsInflectionGeneration?Figure 3: Inflectional analysis induction viaweighted string alignment to noisy generations fromdictionary roots under regular paradigmsin the right side of Figure 32.For example, when looking for a potential anal-ysis path for the Spanish irregular inflection de-strocen, the closest string match is the regular hy-pothesis destrozar/V  destrozen/V-pres_subj-3pl.Likewise, the closest string match for destruyen isdestruir/V  destruen/V-pres_indic-3pl.
The dif-ferences between these regular hypotheses and ob-served inflected forms are the relatively productivestem changes  and , neither of which waslisted in the inflectional supervision table, and yetthey were correctly handled.
Note that a traditional POSsuffix) model would fail to handle this casegiven that the common inflection suffix -en corre-sponds to two different parts of speech here (presentindicative or subjunctive depending on -ir or -arparadigm).Also note that the irregular stem change pro-cesses such as dormirduermen have a correctbest-fit analysis, despite the absence of any internalstem change exemplars (e.g.
oue) in the human-generated inflectional supervision table.For further robustness, the consensus model of   is estimated as a weighted mixture ofthe part-of-speech tags of the most closely aligned2For processing efficiency, one additional constraint is thatpotential hypothesizedobserved string pair candidates mustexactly match in both initial consonant cluster and suffix of thegenerated hypothesis.pseudo-regular generated inflections.The inflections of closed-class words (such aspronouns, determiners and auxiliary verbs) are notwell handled by this generative-alignment model,both due to their often very high irregularity (e.g.the Spanish verb ser (to be)) and/or their typ-ical shortness (e.g.
the pronominal inflectionsof mi, tu, su).
Thus as one final amount ofsupervision, lists of closed-class words, pairedwith their inflections and fine-grained part-of-speech tags were entered manually from the gram-mar book (e.g.
aquellas#(aquel)Adj_Dem-fem-plur-p3).
This final source of supervisionutilized an average of 400 lines and 3 person-hoursper language.4 POS Model InductionThe non-traditional supervision methodology inSections 2 and 3 yields a noisy but broad-coveragecandidate space of parts of speech with little humaneffort.We then perform a noise-robust combination ofmodel estimation and re-estimation techniques forthe syntagmatic trigram models   and lexical priors   using the word co-occurrence information from a raw corpus. A suffix-based part-of-speech probabilitymodel  suffix using hierarchicallysmoothed tries is trained on the raw initialtag distributions, yielding coverage to unseenwords and smoothing of low-confidence initialtag assignments. Paradigmatic cross-context tag modeling isperformed as in Cucerzan and Yarowsky(2000) when sufficiently large unannotatedcorpora are available. Sub-part-of-speech contextual agreement forfeatures such as gender is performed as de-scribed in Section 4.1. The part-of-speech tag sequence models   utilize a weighted backoffbetween fine-grained and coarse-grained tags. Both the tag-sequence and lexical prior modelsare iteratively retrained using these additionalevidence sources and first-pass probability dis-tributions.The success of this model is based on the as-sumption that (a) words of the same part of speechtend to have similar tag sequence behavior, and (b)there are sufficient instances of each POS tag la-beled by either the morphology models or closed-class entries described in Section 3.
One examplewhere these assumptions do not hold is for the Ro-manian word a, which has 5 possible POS tags, in-cluding Infinitive_Marker (corresponding tothe English word to).
But because the Infini-tive_Marker tag has no other word instances inRomanian, no other filial supervision exists to re-solve the ambiguity of a if no context-sensitive tag-ging is provided (such as the preference for a tobe labeled Infinitive_Markerwhen followedby a Verb-Infinitive).
Thus one avenue ofpotential improvement to these models would beto include limited tagged contexts for ambiguoussmall class (or singleton class) words, although suchsupervision is less readily extractable from gram-mar books by non-native speakers, and was not em-ployed here.4.1 Contextual-agreement models forpart-of-speech subtagsTraditional part-of-speech models assume a strictMarkovian sequential dependency.
However, Adj-Noun, Det-Noun and Noun-Verb agreement at thesubtag-level (e.g.
for person, number, case and gen-der) often do not require direct adjacency, and arebased on the selective matching of isolated subfea-tures.
This is particularly important for grammaticalgender, where the lack of gender features projectedfrom English rootwords in a bilingual dictionary (asin Section 2) require contextual agreement to assigngender to many inflected and root forms.However, given the assumptions of minimal su-pervision, it is not reasonable to require a parser ordependency model to identify non-adjacent agree-ing pairs explicitly.
Rather, we utilize a much moregeneral tendency for words exhibiting a propertysuch as grammatical gender to co-occur in a rela-tively narrow window with other words of the samegender (etc.)
with a probability greater than chance.Empirically, we observe this in Figures 4-5, whichshow the gender-agreement ratio between a targetnoun/adjective and other gender marked words ap-pearing in context at relative position .
Adjec-tives in Romanian exhibit a stronger agreement ten-dency with words to their left (5/1 ratio), while fornouns the agreement ratio is quite closely balancedbetween -1 (primarily determiners) and +1 (primar-ily adjectives), although weaker (2.4/1 ratio), per-haps due to a greater relative tendency for nouns tojuxtapose directly with other independent clauses ofdifferent gender.
Also, both parts of speech con-0123456-10 -9 -8 -7 -6 -5 -4 -3 -2 -1Relative Position0Agreement/Non-Agreement Ratio1 2 3 4 5 6 7 8 9 10Adjectives0122.5-10 -9 -8 -7 -6 -5 -4 -3 -2 -1NounsAgreement/Non-Agreement Ratio0Relative Position1 2 3 4 5 6 7 8 9 10Figure 4: Ratio of the frequency that a gender-marked adjective (above) or noun (below) agreesin gender with another noun/adjective/determiner atrelative position i over the frequency of gender dis-agreement at that relative position.0.40.50.60.70.80.91.01 2 3 4tokenswithincontextwindowProbabilityofexistenceofgender-markedContext Width5 6 7 8 9 10Figure 5: The probability that at least one gender-marked word will occur within a window of words relative to another gender marked word (ofany part of speech).verge on the agreement ratio expected by chance(0.82) relatively quickly.
Thus while any individ-ual context may suggest incorrect gender based onagreement, if one aggregates over all occurrences ofa word in a corpus, a consensus gender preferenceemerges, with the true gender agreement signal ex-ceeding nearby spurious gender noise.Formally, we can model this window-weightedglobal feature consensus as:  	 The  window-size parameter was selectedprior to the studies shown in Figures 4-5, but is sup-ported by them.
Beyond this window the agree-ment/disagreement ratio approaches chance, butwith a smaller window the probability of finding anygender-marked word in the window drops below the80% coverage observed for , trading lower cov-erage for increased accuracy.If one makes the assumption that the overwhelm-ing majority of nouns have a single grammaticalgender independent of context, we perform smooth-ing to force nouns with sufficient global context fre-quency towards their single most likely gender.Finally, the trie-based suffix model noted in Sec-tion 3 can be utilized here to further generalize gen-der affixal tendencies for use in smoothing poorlyrepresented single words.
Through this approachwe successfully discover a wide space of low-entropy gender affix tendencies, including the com-mon -a, -dad and -ci?n feminine affixes in Span-ish, without any human or dictionary supervisionof nominal gender.
But even those words with-out gender-distinguishing affixes (e.g.
parte, cabal)can be successfully learned via global context max-imization.5 Evaluation of the Full Part-of-speechTaggerOne problem with minimally supervised learning offoreign languages is that annotated evaluation dataare often not available for the features being in-duced, or are otherwise difficult to obtain.
Thus wehave used for initial test languages two languagesfamiliar to the authors (Romanian and Spanish) forwhich sufficient evaluation resources could be ob-tained.
However, the monolingual corpora utilizedfor bootstrapping were quite small (123 thousandwords of the book 1984 for Romanian and 3.2 mil-lion words of newswire for Spanish), which are eas-ily comparable to the sizes that can be accessed on-line for 60-100 world languages.
The seed dictio-naries were located online (for Spanish - 42k en-tries) and via OCR (for Romanian - 7k entries), andsmall grammar references were obtained at a localbookstore.
1000 words of test data were annotatedwith a standardized, finely detailed part-of-speechtag inventory including the full complex distinctionsfor gender, person, number, case, detailed tense andnominal definiteness (an inventory of 259 and 230fine-grained tags were used for Spanish and Roma-nian respectively).The minimal supervision in this study consistedof an average total of 4 person-hours per languagefor manually entering the inflectional paradigmsand associated parts of speech from a grammar asin Section 3, and an additional average of 3 person-hours per language for dictionary extraction and en-try parsing.
OCR itself on our high-speed 2-sidedscanner with OmniPage Pro took under 30 min-utes).
As would be expected given that data en-try was done by computer scientists which werenot native speakers of the test languages, significantanalysis errors or gaps were introduced when ratherblindly transferring from the reference grammar.Thus to test the relative contributions of limited na-tive speaker help when available, for roughly 4 addi-tional total person hours in a second test conditionfor Romanian a native speaker corrected and aug-mented gaps in the patterns previously entered fromthe grammar book, focusing almost exclusively onthe complex inflections of closed-class words.A summary of the results for these three super-vision modes is given in Table 3.
Performance isbroken down by fine-grained part of speech.
Exact-match accuracy is measured over both the full fine-grained (up to 5-feature) part-of-speech space, aswell as the 12-class core POS tag (noun and propernoun, pronoun, verb, adjective, adverb, numeral,determiner, conjunction, preposition, interjection,particle, punctuation).
The feature of grammaticalgender was specifically isolated because it is rarelysalient for cross-language applications such as ma-chine translation (where grammatical gender rarelytransfers), and because its induction algorithm inSection 4.1 depends heavily on the size of the mono-lingual corpus (which is small in these experiments,suggesting size-dependent potential for significantfurther improvement here).Finally, a post-hoc analysis of the system vs. testdata discrepancies showed that a significant numberwere simply arbitrary differences in annotation con-vention between the grammar-book analyses andthe test data tagging policy.
For example, one such?error?/discrepancy is the rather arbitrary distinc-tion of whether the Romanian word oricare (mean-ing any) should be considered an adjective (as listedin a standard bilingual dictionary) or a determiner.Another difference is whether proper-name citationsof common nouns (e.g.
Casa Blanca) should be an-notated for gender/number etc.
or not.Yet regardless of exactly how many system-testdiscrepancies are just policy differences rather thanerrors, even the raw accuracy here is very promisinggiven the very fined-grained part-of-speech inven-tory and small monolingual data size used for boot-strapping.
And ultimately the performance is quiteSpanish RomanianNNS NNS NNS-8h8h 8h NS-4hAll wordscore-tag 93.1 86.3 89.2exact-match 86.5 68.6 75.5exact w/o gender 87.0 76.7 83.0Nounscore-tag 90.3 97.4 97.4*number 100.0 97.4 98.9*gender 100.0 54.9 64.7*definiteness ?
96.6 93.7*case ?
97.4 97.4Verbscore-tag 94.7 87.9 89.5*tense 93.0 92.6 93.2*number 100.0 91.5 91.2*person 97.2 92.6 93.2Adjectivescore-tag 79.7 78.6 81.5*gender 100.0 81.3 82.2*number 100.0 98.3 98.3Table 3: Performance of POS tagger inductionbased on 1 person-day of supervision, no taggedtraining corpora and a fine-grained (250 tags)tagset.
NNS and NN refer to non-native-speaker andnative-speaker effort.remarkable given that it is the result of less than 1total person day of data collection and supervision,in contrast to the thousands of hours and $100,000-$1,000,000 spent on some annotated training datain a much more limited tagset inventories.
Thusin terms of cost-benefit analysis, the supervisionparadigm and associated bootstrapping models pre-sented here offer quite a good value of new func-tionality per labor invested.6 ConclusionThis paper has presented an alternative to tradi-tional corpus annotation-based supervision of part-of-speech taggers.
Given that even obscure lan-guages have reference grammars and dictionariesavailable in large bookstores, libraries or even on-line, the focus of this work is on using human su-pervision for efficient structured entry of this seedknowledge (in the form of regular and semi-regularinflectional paradigms and often irregular closed-class part-of-speech entries).
Minimally supervisedbootstrapping procedures then used corpus-deriveddistributional data to induce lexical tag probabilitiesfrom dictionaries, irregular morphological analysesvia weighted Levenshtein-based alignment models,tag sequence probability induction and grammati-cal gender agreement modeling.
Experiments showhigh accuracy coarse and fine-grained ( 250 tag)part-of-speech analyses using only one person dayof new human supervision based on readily avail-able linguistic resources.AcknowledgementsThis work was partially supported by NSF grantIIS-9985033 and ONR/MURI contract N00014-01-1-0685.ReferencesBaum, L. 1972.
An inequality and associated maximiza-tion technique in statistical estimation of probabilisticfunctions of a Markov process.
Inequalities, 3:1?8.Collins, M., and Y.
Singer, 1999 Unsupervised modelsfor named entity classification.
In Proceedings of theJoint SIGDAT Conference on EMNLP and VLC 1999,pp.
100-110.Cucerzan, S., and D. Yarowsky, 1999.
Language inde-pendent named entity recognition combining morpho-logical and contextual evidence.
In Proceedings of theJoint SIGDAT Conference on EMNLP and VLC 1999,pp.
90-99.Cucerzan, S., and D. Yarowsky, 2000.
Language in-dependent minimally supervised induction of lexicalprobabilities.
In Proceedings of ACL 2000, pp.
270-277.Goldsmith, J.
A., 2000 Unsupervised learning of themorphology of a natural language.
ComputationalLinguistics 27(2):153?198.Merialdo, B., 1994.
Tagging English text with a prob-abilistic model.
Computational Linguistics 20:155?171.Ngai, G., and D. Yarowsky, 2000.
Inducing multilin-gual POS taggers and NP bracketers via robust projec-tion across aligned corpora.
In Proceedings of NAACL2000, pp.
200-207.Schone, P., and D. Jurafsky, 2000.
Knowledge-free in-duction of morphology using latent semantic analysis.In Proceedings of CoNLL 2000.Snover, M. G., and M. R. Brent, 2001.
A Bayesian modelfor morpheme and paradigm identification.
In Pro-ceedings of ACL 2001, pp.
482-490.Van den Bosch, A., and W. Daelemans, 1999.
Memory-based morphological analysis.
In Proceedings of ACL1999, pp.285-292Yarowsky, D., G. Ngai, and R. Wicentowski, 2001.
In-ducing Multilingual Text Analysis Tools via RobustProjection across Aligned Corpora.
In Proceedings ofHLT 2001, pp.
161-168.Yarowsky, D., and R. Wicentowski, 2000.
Minimally su-pervised morphological analysis by multimodal align-ment.
In Proceedings of ACL 2000, pp.
207-216.
