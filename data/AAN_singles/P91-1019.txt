SUBJECT-DEPENDENT CO-OCCURRENCE AND WORD SENSED ISAMBIGUATIONJoe A. Guthrie,* Louise Guthrie, Yorick Wilks, and Homa AidinejadComputing Research LabomtoD,Box 30001New Mexico State UniversityLas Cruces, NM 88003-0001ABSTRACTWe describe a method for obtainingsubject-dependent word sets relative to some(subjecO domain.
Using the subjectclassifications given in the machine-readable ver-sion of Longman's Dictionary of ContemporaryEnglish, we established subject-dependent co-occurrence links between words of the definingvocabulary to construct these "neighborhoods".Here, we describe the application of these neigh-borhoods to information retrieval, and present amethod of word sense disambiguation based onthese co-occurrences, an extension of previouswork.INTRODUCTIONWord associations have been studiedfor some time in the fields of psycholinguis-tics (by testing human subjects on words),linguistics (where meaning is often based onhow words co-occur with each other), andmore recently, by researchers in naturallanguage processing (Church and Hanks,1990; Hindle and Rooth, 1990; Dagan,1990; McDonald et al, 1990; Wilks et al,1990) using statistical measures to identifysets of associated words for use in variousnatural language processing tasks.One of the tasks where the statisticaldata on associated words has been used withsome success is lexical disambiguation.However, associated word sets gathered* Present address: Mathematics Department, Universityof Texas at k-:l Paso, El Paso, Tx 79968from a general corpus may contain wordsthat are associated with many differentsenses.
For example, vocabulary associatedwith the word "bank" includes "money","rob", "river" and "sand".
In this paper, wedescribe a method for obtaining subject-dependent associated word sets, or "neigh-borhoods" of a given word, relative to a par-ticular (subject) domain.
Using the subjectclassifications of Longman's Dictionary ofContemporary English (LDOCE), we haveestablished subject-dependent co-occurrencefinks between words of the defining vocabu-lary to construct hese neighborhoods.
Wewill describe the application of these neigh-borhoods to information reuieval, andpresent a method of word sense disambigua-tion based on these co-occurrences, anextension of previous work.CO-OCCURRENCE NEIGHBORHOODSWords which occur frequently with agiven word may be thought of as forming a"neighborhood" of that word.
If we candetermine which words (i.e.
spelling forms)co-occur frequently with each word sense,we can use these neighborhoods to disambi-guate the word in a given text.Assume that we know of only two ofthe classic senses of the word bank:1) A repository for money, and2) A pile of earth on the edge of a river.We can expect the "money" sense ofbank to co-occur frequently with such words146as "money", "loan", and "robber", while the"fiver" sense would be more frequently asso-ciated with "river", "bridge", and "earth".
Inorder to disambiguate "bank" in a text, wewould produce neighborhoods for eachsense, and intersect hem with the text, ourassumption being that the neighborhoodwhich shared more words with the textwould determine the correct sense.
Varia-tions of this idea appear in (l.,esk, 1986;McDonald, et al, 1990; Wilks, 1987; 1990;Veronis and Ide, 1990).Previously, McDonald and Plate(McDonald et al, 1990; Schvaneveldt, 1990)used the LDOCE definitions as their text, inorder to generate co-occurrence data for the2,187 words in the LDOCE control(defining) vocabulary.
They used variousmethods to apply this data to the problem ofdisambiguating control vocabulary words asthey appear in the LDOCE example sen-tences.
In every case however, the neighbor-hood of a given word was a co-occurrenceneighborhood for its spelling form over allthe definitions in the dictionary.
Distinctneighborhoods corresponding to distinctsenses had to be obtained by using thewords in the sense definition as a core forthe neighborhood, and expanding it by com-bining it with additional words from the co-occurrence neighborhoods of the core words.SUBJECT-DEPENDENT NEIGHBORHOODSThe study of word co-occurrence in atext is based on the cliche that "one (a word)is known by the company one keeps".
Wehold that it also makes a difference wherethat company is kept: since a word mayoccur with different sets of words in dif-ferent contexts, we construct word neighbor-hoods which depend on the subject of thetext in question.
We call these, naturallyenough, "subject-dependent neighborhoods".A unique feature of the electronic ver-sion of LDOCE is that many of the wordsense definitions are marked with a subjectfield code which tells us which subject areathe sense pertains to.
For example, the"money"-related senses of bank  are markedEC (Economics), and for each such mainsubject heading, we consider the subset ofLDOCE definitions that consists of thosesense definitions which sham that subjectcode.
These definitions are then collectedinto one file, and co-occurrence data for theirdefining vocabulary is generated.
Word x issaid to co-occur with word y if x and yappear in the same sense definition; the totalnumber of times they co-occur is denoted asWe then construct a 2,187 x 2,187matrix in which each row and columncorresponds to one word of the definingvocabulary, and the entry in the xth row andyth column represents the number of timesthe xth word co-occurred with the yth word.
(This is a symmetric matrix, and therefore itis only necessary to maintain half of it.)
Wedenote by f ,  the total number of times wordx appeared.
While many statistics may beused to measure the relatedness of words xand y, we used the functionr (x,y ) = f x~ .in this study.
We choose a co-occurrenceneighborhood of a word x from a set ofclosely related words.
We may choose theten words with the highest relatedness tatis-tic, for instance.Neighborhoods of the word "metal" inthe category "Economics" and "Business"are presented below:Table 1.
Economics neighborhood f metalSubject Code EC ffi Economicsmetal idea coin them silverw, al should pocket goldwell himTable 2. Business neighborhood of recta/Subject Code BU = Businessmetal bear apparatus mouthspring entrance platetight sheetinsidebrags147In this example, the ~ghborhoodsreflect a fundamental difference between thetwo subject areas.
Economics is a moretheoretical subject, and therefore its neigh-borhood contains words like "idea", "gold","silver", and "real", while in the more practi-cal domain of Business, we find the words"brass", "apparatus", spring", and "plate".We can expect the contrast betweensubject neighborhoods to be especially greatfor words with senses that fall into differentsubject areas.
Consider the actual neighbor-hoods of our original example, bank.Table 3.
Economics neighborhood fbankbankSubject Code EC = Economiesaccount cheque money byinto have keep orderout pay at putfrom draw an busymore supply it safeTable 4.
Engineering neighborhood of bankbankSubject Code EG = Engineeringriver wall flood thickearth prevent opposite chairhurry paste spread overflowwalk help we throwclay then wide levelNotice that even though we includedthe twenty most closely related words ineach neighborhood, they are still unrelatedor disjoint, although many of the wordswhich appear in the lists are indeed sugges-tive of the sense or senses which fall underthat subject category.
In LDOCE, three ofthe eleven senses of bank are marked withthe code EC for Economics, and theserepresent the "money" senses of the word.
Itis a quirk of the classification in LDOCEthat the "river" senses of bank are notmarked with a subject code.This lack of a subject code for a wordsense in LDOCE is not uncommon, how-ever, and as was the case with bank, someword senses may have subject codes, whileothers do not.
We label this lack of a sub-ject code the "null code", and form a neigh-borhood of this type of sense by using allsense definitions without code as text.
This"null code neighborhood" can reveal thecommon, or "generic" sense of the word.The twenty most frequently occurringwords with bank in definitions with the nullsubject code form the following neighbor-hood:Table 5.
Null Code neighborhood fbankSubject Code NULL = no code assignedbank rob river account lendoverflow flood money criminallake flow snow cliffpolice shore heap thiefborrow along steep earthIt is obvious that approximately half ofthese words are associated with our twomain senses of bank-but a new element hascrept in: the appearance of four out of eightwords which refer to the money sense ("rob","criminal", "police", and "thief") reveal asense of bank which did not appear in theEC neighborhood.
In the null codedefinitions, there are quite a few referencesto the potential for a bank to be robbed.Finally, for comparison, consider aneighborhood for bank which uses all theLDOCE definitions (see McDonald et al,1990; Schvaneveldt, 1990; Wilks et al,1990):Table 6.
Unrestricted neighborhood of bankSubject Code Allbank account bank busy chequecriminal earn flood flowinterest lake lend moneyoverflow pay river robsafes and thief wallOnly four of these words ("bank","cam", "sand", and "thief") are not found in148the other three neighborhoods, and thenumber of words in the intersection of thisneighborhood with the Economics,Engineering, and Null neighborhoods are:six, four, and eleven, respectively.
Recallingthat the Economics and Engineering neigh-borhoods are disjoint, this data supports ourhypothesis that the subject-dependent neigh-borhoods help us to distinguish senses moreeasily than neighborhoods which areextracted from the whole dictionary.There are over a hundred main subjectfield codes in LDOCE, and over three-hundred sub-divisions within these.
Forexample, "medicine-and-biology" is a mainsubject field (coded "MD"), and has twenty-two sub-divisions uch as "anatomy" and"biochemistry".
These main codes and theirsub-divisions constitute the only two levelsin the LDOCE subject code hierarchy, andmain codes such as "golf' and "sports" arenot related to each other.
Cknrently, we useonly the main codes when we are construct-ing a subject-dependent neighborhood.
Buteven this division of the definition text isfine enough so that, given a word and a sub-ject code, the word may not appear in thedefinitions which have that subject code atall.To overcome this problem, we haveadopted a restructured hierarchy of the sub-ject codes, as developed b~y Slator (1988).This tree structure has a node at the top,representing all the definitions.
At the nextlevel are six fundamental categories such as"science" and "transportation", as well as thenull code.
These clusters are further sub-divided so that some main codes becomesub-divisions of others ("golf' becomes asub-division of "sports", etc.).
The max-imum depth of this tree is five levels.If the word for which we want to pro-duce a neighborhood appears too infre-quently in definitions with a given code, wetravel up the hierarchy and expand the textunder consideration until we have reached apoint where the word appears frequentlyenough to allow the neighborhood to be con-structed.
The worst case scenario would beone in which we had traveled all the way tothe top of the hierarchy and used all thedefinitions as the text, only to wind up withthe same co-occurrence neighborhoods asdid McDonald and Plate (Schvaneveldt,1990; Wilks et al, 1990)!There are certain drawbacks in usingLDOCE to construct he subject-dependentneighborhoods, however, the amount of textin LDOCE about any one subject area israther limited, is comprised of a controlvocabulary for dictionary definitions only,and uses sample sentences which were con-cocted with non-native English speakers inmind.In the next phase of our research, largecorpora consisting of actual documents froma given subject area will be used, in order toobtain neighborhoods which more accuratelyreflect he sorts of texts which will be usedin applications.
In the future, these neigh-borhoods may replace those constructedfrom LDOCE, while leaving the subjectcode hierarchy and various applicationsintact.WORD SENSE DISAMBIGUATIONIn this section, we describe an applica-tion of subject-dependent co-occurrenceneighborhoods to the problem of word sensedisambiguation.
The subject-dependent co-occurrence neighborhoods are used as build-ing blocks for the neighborhoods used indisambiguation.
For each of the subjectcodes (including the null code) which appearwith a word sense to be disambiguated, weintersect the corresponding subject-dependent co-occurrence n ighborhood withthe text being considered (the size of textcan vary from a sentence to a paragraph).The intersection must contain a pre-selectedminimum number of words to be considered.But if none of the neighborhoods intersect atgreater than this threshold level, we replacethe neighborhood N by the neighborhoodN(1), which consists of N together with thefirst word from each neighborhood of wordsin N, using the same subject code.
If neces-sary, we add the second most strongly asso-ciated word for each of the words in the ori-ginal neighborhood N, forming the neighbor-149hood N(2).
We continue this process until asubject-dependent co-occurrence neighbor-hood has intersection above the thresholdlevel.
Then, the sense or senses with thissubject code is selected.
If more than onesense has the selected code, we use theirdefinitions as cores to build distinguishingneighborhoods for them.
These are againintersected with the text to determine thecorrect sense.The following two examples illustratethis method.
Note that some of the neigh-borhoods differ from those given earliersince the text used to construct these neigh-borhoods includes any example sentenceswhich may occur in the sense definitions.Those neighborhoods presented earlierignored the example sentences.
In eachexample, we attempt to disambiguate theword "bank" in a sentence which appears asan example sentence in the CollinsCOBUILD English Language Dictionary.The disambiguation consists of choosing thecorrect sense of "bank" from among the thir-teen senses given in LDOCE.
These sensesare summarized below.bank(l) : \[ \] : land along the side of a fiver,lake, etc.bank(2) : \[ \] : earth which is heaped up in afield or garden.bank(3) : \[ \] : a mass of snow, clouds, mud, etc.bank(4) : \[AU\] : a slope made at bends in a roador race-track.bank(5) : \[ \] : a sandbank in a river, etc.bank(6) : \[ALl\] : to move a ear or aircraft withone side higher than the other.bank('/) : \[ \] : a row, especially of oars in anancient boat or keys on a typewriter.bank(8) : \[EC\] : a place in which money is keptand paid out on demand.bank(9) : \[MD\] : a place where something isheld ready for use, such as blood.bank(10) : \[GB\] : (a person who keeps) a supplyof money or pieces for payment in a gam-bling game.bank(ll) : \[ \] : break the bank is to win all themoney in bank(10).bank(12) : \[EC\] : to put or keep (money) in abank.bank(13) : \[EC\] : to keep ones money in a bank.Example 1.
The sentence is 'Whe air-craft turned, banking slightly.
"The neighborhoods of "bank" for the fiverelevant subject codes are given below.Table 7.
Automotive neighborhood fbankSubject Code ALl = Automotivebank make go up moveso they high alsoround car side turnroad aircraft slope bendsafeTable 8.
Economics neighborhood f bankbankSubject Code EC = Economicshave it person outinto take money putwrite keep pay orderanother paper draw supplyaccount safe sum chequeTable 9.
Gambling neighborhood f bankbankSubject Code GB = Gamblingperson use money pieceplay keep pay gamevarious supply chanceTable 10.
Medical neighborhood f bankSubject Code MD - Medicine and Biologybank something use place holdmedicine ready blood humanorigin organ store hospitaltream~ent product comb150Table 11.
Null Code neighborhood of bankbankSubject Code NULL = No code assignedgame earth stone boatfiver bar snow lakesand shore mud frameworkflood cliff heap harborocean parallel overflow clerkThe AU neighborhood contains twowords, "aircraft" and "turn", which alsoappear in the sentence.
Note that we con-sider all forms of tum (tumed, tuming, etc.
)to match "turn".
Since none of the otherneighborhoods have any words in commonwith the sentence, and since our thresholdvalue for this short sentence is 2, AU isselected as the subject code.
We must nowdecide between the two senses which havethis code.At this point we remove the functionwords from the sense definitions and replaceeach remaining word by its root form.
Weobtain the following neighborhoods.Table 12.
Words in sense 4 of bankDefinition bank(4)slope make bend road sothey safe car go roundTable 13.
Words in sense 6 of bankDefinition bank(6)car aircraft move sidehigh make turnSince bank(4) has no words in com-mon with the sentence, and bank(6) has twoCtum" and "aircraft"), bank(6) is selected.This is indeed the sense of "bank" used inthe sentence.Example 2.
The sentence is "We gota bank loan to buy a car."
The originalneighborhoods of "bank" are, of course, thesame as in Example 1.
The threshold isagain 2.
None of the neighborhoods hasmore than one word in common with thesentence, so the iterative process of enlarg-ing the neighborhoods is used.
The AUneighborhood is expanded to include"engine" since it is the first word in the AUneighborhood of "make".
The first word inthe AU neighborhood of "up" is "increase",so "increase" is added to the neighborhood.If the word to be added already appears inthe neighborhood of "bank", no word isadded.On the fifteenth iteration, the ECneighborhood contains "get" and "buy".None of the other neighborhoods have morethan one word in common with the sentence,so EC is selected as the subject code.Definitions 8, 12, and 13 of bank all havethe EC subject code, so their definitions areused as cores to build neighborhoods toallow us to choose one of them.
Aftertwenty-three iterations, bank(8) is selected.Experiments are underway to test thismethod and variations of it on large numbersof sentences so that its effectiveness may becompared with other disambiguation tech-niques.
Results of these experiments will bereported elsewhere.FURTHER APPUCATIONSSeveral applications of subject-dependent neighborhoods in addition toword-sense disambiguation are being pur-sued, as well.
For information retrieval, pre-viously constructed neighborhoods relevantto the subject area can be used to expand aquery and the target (titles, key words, etc.
)to include more words in the intersection,and improve both recall and precision.Another application is the determination ofthe subject area of a text.
Since the effec-tiveness of searching for key words to deter-mine the topic of a text is limited by thechoice of the particular list of key words,and the fact that the text may use synonymsor refer to the concept the key wordrepresents without using it (for example byusing a pronoun in its place), we could lookfor word associations (thereby involvingmore words in the process and making itless vulnerable to the above problems),151rather than simply searching for key wordsindicative of a topic.
Neighborhoods ofwords in the text could be constructed foreach of the six fundamental categories, andintersected with the surrounding words inthe text.
After choosing the category withthe greatest intersection, we would thentraverse the subject code tree downward toarrive at a more specific code, stopping atany point where there is not enough data toallow us to choose one code over the othersat that level.
Once a subject code is selectedfor a text, it could be used as a context forword-sense disambiguation.CONCLUSIONAlthough the words in the LDOCEdefinitions constitute a small text (almostone million words, compared with themega-texts used in other co-occurrence stu-dies), the unique feature of subject codeswhich can be used to distinguish manydefinitions, and LDOCE's small controlvocabulary (2,187 words) make it a usefulcorpus for obtaining co-occurrence data.The development of techniques for informa-tion retrieval and word-sense disambiguationbased on these subject-dependent co-occurrence neighborhoods is very promisingindeed.ACKNOWLEDGEMENTSThis research was supported by theNew Mexico State University ComputingResearch Laboratory through NSF Grant No.IRI-8811108.
Grateful acknowledgement isaccorded to all the members of the CRLNatural Language Group for their commentsand suggestions.REFERENCESChurch, Kenneth W., and Patrick Hanks(1990).
Word Association Norms, Mutual Infor-mation, and Lexicography.
ComputationalLinguistics, 16, 1, pp.22-29.Dagan, Ido, and Alon Itai (1990).
Process-ing Large Corpora for Reference Resolution.Proceedings of the 13th International Conferenceon Computational Linguistics (COLING-90),Helsinki, Finland, 3, pp.330-332.Hindle, Donald, and Mats Rooth (1990).Structural Ambiguity and Lexical Relations.Proceedings of the DARPA Speech and NaturalLanguage Workshop.Lesk, Michael E. (1986).
Automatic SenseDisambiguation Using Machine Readable Dic-tionaries: How to Tell a Pine Cone from an IceCream Cone.
Proceedings of the ACM SIGDOCConference, Toronto, Ontario.McDonald, James E., Tony Plate, andRoger W. Schvaneveldt (1990).
UsingPathfinder to extract semantic information fromtext.
In R. W. Schvaneveldt (ed.
), PathfinderAssociative Networks: Studies in KnowledgeOrganization.
Norwood, NJ: Ablex.Schvaneveldt, Roger W. (1990).
Path-finder Associative Networks: Studies inKnowledge Organization.
New Jersey: Ablex.Slator, Brian M. 0988).
ConstructingContextually Organized Lexical SemanticKnowledge-bases.
Proceedings of the ThirdAnnual Rocky Mountain Conference on ArtificialIntelligence (RMCAI-88), Denver, CO, pp.142-148.Veronis, Jean., Nancy Ide (1990).
VeryLarge Neural Networks for Word-sense Disambi-guation.
COLING '90, 389-394.Wilks, Yorick A., Dan C. Fass, Cheng-ming Guo, James E. McDonald, Tony Plate, andBrian M. Slator (1987).
A Tractable MachineDictionary as a Resource for ComputationalSemantics.
Memorandum in Computer and Cog-nitive Science, MCCS-87-105, ComputingResearch Laboratory, New Mexico State Univer-sity.
In Branimir Boguraev and Ted Briscoe(eds.
), Computational IJ.xicography for NaturalLanguage Processing.
Harlow, Essex, England:Longman Group Limited.Wilk.% Ymick A., Dan C. Fass, Cheng-ming Guo, James E. McDonald, Tony Plate, andBrian M. Slator (1990).
Prodding MachineTractable Dictionary Tools.
Journal of MachineTranslation, 2.
Also to appear in Theoretical andComputational Issues in Lexical Semantics , J.Pnstejovsky (~!.
)152
