c?
2004 Association for Computational LinguisticsWord Translation Disambiguation UsingBilingual BootstrappingHang Li?
Cong Li?Microsoft Research Asia Microsoft Research AsiaThis article proposes a new method for word translation disambiguation, one that uses a machine-learning technique called bilingual bootstrapping.
In learning to disambiguate words to be trans-lated, bilingual bootstrapping makes use of a small amount of classified data and a large amountof unclassified data in both the source and the target languages.
It repeatedly constructs classi-fiers in the two languages in parallel and boosts the performance of the classifiers by classifyingunclassified data in the two languages and by exchanging information regarding classified databetween the two languages.
Experimental results indicate that word translation disambiguationbased on bilingual bootstrapping consistently and significantly outperforms existing methodsthat are based on monolingual bootstrapping.1.
IntroductionWe address here the problem of word translation disambiguation.
If, for example, wewere to attempt to translate the English noun plant, which could refer either to a typeof factory or to a form of flora (i.e., in Chinese, either to [gongchang] or to[zhiwu]), our goal would be to determine the correct Chinese translation.
That is, wordtranslation disambiguation is essentially a special case of word sense disambiguation(in the above example, gongchang would correspond to the sense of factory and zhiwuto the sense of flora).1We could view word translation disambiguation as a problem of classification.
Toperform the task, we could employ a supervised learning method, but since to doso would require human labeling of data, which would be expensive, bootstrappingwould be a better choice.Yarowsky (1995) has proposed a bootstrapping method for word sense disam-biguation.
When applied to translation from English to Chinese, his method startslearning with a small number of English sentences that contain ambiguous Englishwords and that are labeled with correct Chinese translations of those words.
It thenuses these classified sentences as training data to create a classifier (e.g., a decision list),which it uses to classify unclassified sentences containing the same ambiguous words.The output of this process is then used as additional training data.
It also adopts theone-sense-per-discourse heuristic (Gale, Church, and Yarowsky 1992b) in classifyingunclassified sentences.
By repeating the above process, an accurate classifier for wordtranslation disambiguation can be created.
Because this method uses data in a singlelanguage (i.e., the source language in translation), we refer to it here as monolingualbootstrapping (MB).?
5F Sigma Center, No.
49 Zhichun Road, Haidian, Beijing, China, 100080.
E-mail:{hangli,i-congl}@microsoft.com.1 In this article, we take English-Chinese translation as an example; but the ideas and methods describedhere can be applied to any pair of languages.2Computational Linguistics Volume 30, Number 1In this paper, we propose a new method of bootstrapping, one that we refer to asbilingual bootstrapping (BB).
Instead of using data in one language, BB uses data intwo languages.
In translation from English to Chinese, for example, BB makes use ofunclassified data from both languages.
It also uses a small number of classified datain English and, optionally, a small number of classified data in Chinese.
The data inthe two languages should be from the same domain but are not required to be exactlyin parallel.BB constructs classifiers for English-to-Chinese translation disambiguation by re-peating the following two steps: (1) Construct a classifier for each of the languageson the basis of classified data in both languages, and (2) use the constructed classifierfor each language to classify unclassified data, which are then added to the classifieddata of the language.
We can use classified data in both languages in step (1), becausewords in one language have translations in the other, and we can transform data fromone language into the other.We have experimentally evaluated the performance of BB in word translationdisambiguation, and all of our results indicate that BB consistently and significantlyoutperforms MB.
The higher performance of BB can be attributed to its effective useof the asymmetric relationship between the ambiguous words in the two languages.Our study is organized as follows.
In Section 2, we describe related work.
Specifi-cally, we formalize the problem of word translation disambiguation as that of classifi-cation based on statistical learning.
As examples, we describe two such methods: oneusing decision lists and the other using naive Bayes.
We also explain the Yarowskydisambiguation method, which is based on Monolingual Bootstrapping.
In Section 3,we describe bilingual bootstrapping, comparing BB with MB, and discussing the re-lationship between BB and co-training.
In Section 4, we describe our experimentalresults, and finally, in Section 5, we give some concluding remarks.2.
Related Work2.1 Word Translation DisambiguationWord translation disambiguation (in general, word sense disambiguation) can beviewed as a problem of classification and can be addressed by employing varioussupervised learning methods.
For example, with such a learning method, an Englishsentence containing an ambiguous English word corresponds to an instance, and theChinese translation of the word in the context (i.e., the word sense) corresponds to aclassification decision (a label).Many methods for word sense disambiguation based on supervised learning tech-nique have been proposed.
They include those using naive Bayes (Gale, Church, andYarowsky 1992a), decision lists (Yarowsky 1994), nearest neighbor (Ng and Lee 1996),transformation-based learning (Mangu and Brill 1997), neural networks (Towell andVoorhees 1998), Winnow (Golding and Roth 1999), boosting (Escudero, Marquez, andRigau 2000), and naive Bayesian ensemble (Pedersen 2000).
The assumption behindthese methods is that it is nearly always possible to determine the sense of an ambigu-ous word by referring to its context, and thus all of the methods build a classifier (i.e.,a classification program) using features representing context information (e.g., sur-rounding context words).
For other related work on translation disambiguation, seeBrown et al (1991), Bruce and Weibe (1994), Dagan and Itai (1994), Lin (1997), Ped-ersen and Bruce (1997), Schutze (1998), Kikui (1999), Mihalcea and Moldovan (1999),Koehn and Knight (2000), and Zhou, Ding, and Huang (2001).Let us formulate the problem of word sense (translation) disambiguation as fol-lows.
Let E denote a set of words.
Let ?
denote an ambiguous word in E, and let e3Li and Li Word Translation Disambiguation Using Bilingual Bootstrappingdenote a context word in E. (Throughout this article, we use Greek letters to representambiguous words and italic letters to represent context words.)
Let T?
denote the setof senses of ?, and let t?
denote a sense in T?.
Let e?
stand for an instance representinga context of ?, that is, a sequence of context words surrounding ?:e?
= (e?,1, e?,2, .
.
.
, (?
), .
.
.
, e?,m), e?,i ?
E, (i = 1, .
.
.
, m)For the example presented earlier, we have ?
= plant, T?
= {1, 2}, where 1 representsthe sense factory and 2 the sense flora.
From the phrase ?.
.
.
computer manufacturingplant and adjacent.
.
.
?
we obtain e?
= (.
.
.
computer, manufacturing, (plant), and,adjacent, .
.
.
).For a specific ?, we define a binary classifier for resolving each of its ambiguitiesin T?
in a general form as2P(t?
| e?
), t?
?
T?
and P(?t?
| e?
), t??
= T?
?
{t?
}where e?
denotes an instance representing a context of ?.
All of the supervised learningmethods mentioned previously can automatically create such a classifier.
To constructclassifiers using supervised methods, we need classified data such as those in Figure 1.2.2 Decision ListsLet us first consider the use of decision lists, as proposed in Yarowsky (1994).
Let f?denote a feature of the context of ?.
A feature can be, for example, a word?s occurrenceimmediately to the left of ?.
We define many such features.
For each feature f?, weuse the classified data to calculate the posterior probability ratio of each sense t?
withrespect to the feature as?(t?
| f?)
=P(t?
| f?)P(?t?
| f?
)For each feature f?, we create a rule consisting of the feature, the sensearg maxt??T??(t?
| f?
)and the scoremaxt??T??(t?
| f?
)We sort the rules in descending order with respect to their scores, provided that thescores of the rules are larger than the defaultmaxt??T?P(t?)P(?t?
)The sorted rules form an if-then-else type of rule sequence, that is, a decision list.3 Fora new instance e?, we use the decision list to determine its sense.
The rule in the listwhose feature is first satisfied in the context of e?
is applied in sense disambiguation.2 In this article we always employ binary classifiers even there are multiple classes.3 We note that there are two types of decision lists.
One is defined as here; the other is defined as aconditional distribution over a partition of the feature space (cf.
Li and Yamanishi 2002).4Computational Linguistics Volume 30, Number 1P1 .
.
.Nissan car and truck plant.
.
.
(1)P2 .
.
.
computer manufacturing plant and adjacent.
.
.
(1)P3 .
.
.
automated manufacturing plant in Fremont.
.
.
(1)P4 .
.
.divide life into plant and animal kingdom.
.
.
(2)P5 .
.
.
thousands of plant and animal species.
.
.
(2)P6 .
.
.
zonal distribution of plant life.
.
.
(2).
.
.. .
.Figure 1Examples of classified data (?
= plant).2.3 Naive Bayesian EnsembleLet us next consider the use of naive Bayesian classifiers.
Given an instance e?, we cancalculate??(e?)
= maxt??T?P(t?
| e?)P(?t?
| e?
)= maxt??T?P(t?)P(e?
| t?)P(?t?)P(e?
| t??
)(1)according to Bayes?
rule and select the senset?(e?)
= arg maxt??T?P(t?)P(e?
| t?)P(?t?)P(e?
| t??
)(2)In a naive Bayesian classifier, we assume that the words in e?
with a fixed t?
areindependently generated from P(e?
| t?)
and calculateP(e?
| t?)
=m?i=1P(e?,i | t?
)Here P(e?
| t?)
represents the conditional probability of e in the context of ?
given t?.We calculate P(e?
| t??)
similarly.
We can then calculate (1) and (2) with the obtainedP(e?
| t?)
and P(e?
| t??
).The naive Bayesian ensemble method for word sense disambiguation, as proposedin Pedersen (2000), employs a linear combination of several naive Bayesian classifiersconstructed on the basis of a number of nested surrounding contexts4P(t?
| e?)
=1hh?i=1P(t?
| e??,i)e?
?,1 ?
?
?
?
?
e?
?,i ?
?
?
?
e?
?,h = e??
(i = 1, .
.
.
, h)The naive Bayesian ensemble is reported to perform the best for word sense disam-biguation with respect to a benchmark data set (Pedersen 2000).2.4 Monolingual BootstrappingSince data preparation for supervised learning is expensive, it is desirable to developbootstrapping methods.
Yarowsky (1995) proposed such a method for word sensedisambiguation, which we refer to as monolingual bootstrapping.4 Here u ?
v denotes that u is a sub-sequence of v.5Li and Li Word Translation Disambiguation Using Bilingual BootstrappingLet L?
denote a set of classified instances (labeled data) in English, each represent-ing one context of ?:L?
= {(e?,1, t?,1), (e?,2, t?,2), .
.
.
, (e?,k, t?,k)}t?,i ?
T?
(i = 1, 2, .
.
.
, k)and U?
a set of unclassified instances (unlabeled data) in English, each representingone context of ?:U?
= {e?,1, e?,2, .
.
.
, e?,l}The instances in Figure 1 can be considered examples of L?.
Furthermore, we haveLE =??
?EL?, UE =??
?EU?, T =??
?ET?,An algorithm for monolingual bootstrapping is presented in Figure 2.
For a bettercomparison with bilingual bootstrapping, we have extended the method so that itInput: E, T, LE, UE, Parameter: b, ?Repeat the following processes until unable to continue1.
1 for each (?
?
E) {2 for each (t ?
T?)
{3 use L?
to create classifier:P(t | e?
), t ?
T?
and P(?t | e?
), t?
?
T?
?
{t}; }}2.
4 for each (?
?
E) {5 NU ?
{}; NL ?
{};6 for each (t ?
T?)
{7 St ?
{};8 Qt ?
{};}9 for each (e?
?
U?
){10 calculate ??(e?)
= maxt?T?P(t | e?
)P(?t | e?
);11 let t?(e?)
= arg maxt?T?P(t | e?
)P(?t | e?
);12 if (??(e?)
> ?
& t?(e?)
= t)13 put e?
into St;}14 for each (t ?
T?
){15 sort e?
?
St in descending order of ??(e?)
and put the top belements into Qt;}16 for each (e?
?
?t Qt){17 put e?
into NU and put (e?, t?(e?))
into NL;}18 L?
?
L?
?NL;19 U?
?
U?
?
NU;}Figure 2Monolingual bootstrapping.6Computational Linguistics Volume 30, Number 1performs disambiguation for all the words in E. Note that we can employ any kindof classifier here.At step 1, for each ambiguous word ?
we create binary classifiers for resolving itsambiguities (cf.
lines 1?3 of Figure 2).
At step 2, we use the classifiers for each word?
to select some unclassified instances from U?, classify them, and add them to L?
(cf.lines 4?19).
We repeat the process until all the data are classified.Lines 9?13 show that for each unclassified instance e?, we classify it as havingsense t if t?s posterior odds are the largest among the possible senses and are largerthan a threshold ?.
For each class t, we store the classified instances in St. Lines 14?15show that for each class t, we only choose the top b classified instances in terms of theposterior odds.
For each class t, we store the selected top b classified instances in Qt.Lines 16?17 show that we create the classified instances by combining the instanceswith their classification labels.After line 17, we can employ the one-sense-per-discourse heuristic to further clas-sify unclassified data, as proposed in Yarowsky (1995).
This heuristic is based on theobservation that when an ambiguous word appears in the same text several times, itstokens usually refer to the same sense.
In the bootstrapping process, for each newlyclassified instance, we automatically assign its class label to those unclassified instancesthat also contain the same ambiguous word and co-occur with it in the same text.Hereafter, we will refer to this method as monolingual bootstrapping with onesense per discourse.
This method can be viewed as a special case of co-training (Blumand Mitchell 1998).2.5 Co-trainingMonolingual bootstrapping augmented with the one-sense-per-discourse heuristic canbe viewed as a special case of co-training, as proposed by Blum and Mitchell (1998)(see also Collins and Singer 1999; Nigam et al 2000; and Nigam and Ghani 2000).
Co-training conducts two bootstrapping processes in parallel and makes them collaboratewith each other.
More specifically, co-training begins with a small number of classifieddata and a large number of unclassified data.
It trains two classifiers from the classifieddata, uses each of the two classifiers to classify some unclassified data, makes the twoclassifiers exchange their classified data, and repeats the process.3.
Bilingual Bootstrapping3.1 Basic AlgorithmBilingual bootstrapping makes use of a small amount of classified data and a largeamount of unclassified data in both the source and the target languages in translation.It repeatedly constructs classifiers in the two languages in parallel and boosts theperformance of the classifiers by classifying data in each of the languages and byexchanging information regarding the classified data between the two languages.Figures 3 and 4 illustrate the process of bilingual bootstrapping.
Figure 5 showsthe translation relationship among the ambiguous words plant, zhiwu, and gongchang.There is a classifier for plant in English.
There are also two classifiers, one each forzhiwu and gongchang, respectively, in Chinese.
Sentences containing plant in Englishand sentences containing zhiwu and gongchang in Chinese are used.In the beginning, sentences P1 and P4 on the English side are assigned labels 1 and2, respectively (Figure 3).
On the Chinese side, sentences G1 and G3 are assigned labels1 and 3, respectively, and sentences Z1 and Z3 are assigned labels 2 and 4, respectively.The four labels here correspond to the four links in Figure 5.
For example, label 1represents the sense factory and label 2 represents the sense flora.
Other sentences are7Li and Li Word Translation Disambiguation Using Bilingual BootstrappingFigure 3Bilingual bootstrapping (1).Figure 4Bilingual bootstrapping (2).8Computational Linguistics Volume 30, Number 1~ ?~Figure 5Example of translation dictionary.not labeled.
Bilingual bootstrapping uses labeled sentences P1, P4, G1, and Z1 to createa classifier for plant disambiguation (between label 1 and label 2).
It also uses labeledsentences Z1, Z3, and P4 to create a classifier for zhiwu and uses labeled sentences G1,G3, and P1 to create a classifier for gongzhang.
Bilingual bootstrapping next uses theclassifier for plant to label sentences P2 and P5 (Figure 4).
It uses the classifier for zhiwuto label sentences Z2 and Z4, and uses the classifier for gongchang to label sentencesG2 and G4.
The process is repeated until we cannot continue.To describe this process formally, let E denote a set of words in English, C a set ofwords in Chinese, and T a set of senses (links) in a translation dictionary as shown inFigure 5.
(Any two linked words can be translations of each other.)
Mathematically,T is defined as a relation between E and C, that is, T ?
E ?
C. Let ?
stand for anambiguous word in E, and ?
an ambiguous word in C. Also let e stand for a contextword in E, c a context word in C, and t a sense in T.For an English word ?, T?
= {t | t = (?, ??
), t ?
T} represents the set of ?
?s possiblesenses (i.e., its links), and C?
= {??
| (?, ??)
?
T} represents the Chinese words that canbe translations of ?
(i.e., Chinese words to which ?
is linked).
Similarly, for a Chineseword ?, let T?
= {t | t = (?
?, ?
), t ?
T} and E?
= {??
| (?
?, ?)
?
T}.For the example in Figure 5, when ?
= plant, we have T?
= {1, 2} and C?
={gongchang, zhiwu}.
When ?
= gongchang, T?
= {1, 3} and E?
= {plant, mill}.
When?
= zhiwu, T?
= {2, 4} and E?
= {plant, vegetable}.
Note that gongchang and zhiwushare the senses {1, 2} with plant.Let e?
denote an instance (a sequence of context words surrounding ?)
in English:e?
= (e?,1, e?,2, .
.
.
, e?,m), e?,i ?
E (i = 1, 2, .
.
.
, m)Let c?
denote an instance (a sequence of context words surrounding ?)
in Chinese:c?
= (c?,1, c?,2, .
.
.
, c?,n, c?,i ?
C (i = 1, 2, .
.
.
, n)For an English word ?, a binary classifier for resolving each of the ambiguities in T?
isdefined asP(t?
| e?
), t?
?
T?
and P(?t?
| e?
), t??
= T?
?
{t?
}Similarly, for a Chinese word ?, a binary classifier is defined asP(t?
| c?
), t?
?
T?
and P(?t?
| c?
), t?
= T?
?
{t?
}Let L?
denote a set of classified instances in English, each representing one contextof ?:L?
= {(e?,1, t?,1), (e?,2, t?,2), .
.
.
, (e?,k, t?,k)}, t?,i ?
T?
(i = 1, 2, .
.
.
, k)9Li and Li Word Translation Disambiguation Using Bilingual Bootstrappingand U?
a set of unclassified instances in English, each representing one context of ?:U?
= {e?,1, e?,2, .
.
.
, e?,l}Similarly, we denote the sets of classified and unclassified instances with respect to ?in Chinese as L?
and U?
, respectively.
Furthermore, we haveLE =??
?EL?, LC =???CL?
, UE =??
?EU?, UC =??
?CU?We also haveT =???ET?
=??
?CT?Sentences P1 and P4 in Figure 3 are examples of L?.
Sentences Z1, Z3 and G1, G3 areexamples of L?
.We perform bilingual bootstrapping as described in Figure 6.
Note that we can,in principle, employ any kind of classifier here.The figure explains the process for English (left-hand side); the process for Chinese(right-hand side) behaves similarly.
At step 1, for each ambiguous word ?, we createbinary classifiers for resolving its ambiguities (cf.
lines 1?3).
The main point here isthat we use classified data from both languages to construct classifiers, as we describein Section 3.2.
For the example in Figure 3, we use both L?
(sentences P1 and P4) andL?
, ?
?
C?
(sentences Z1 and G1) to construct a classifier resolving ambiguities inT?
= {1, 2}.
Note that not only P1 and P4, but also Z1 and G1, are related to {1, 2}.At step 2, for each word ?, we use its classifiers to select some unclassified instancesfrom U?, classify them, and add them to L?
(cf.
lines 4?19).
We repeat the process untilwe cannot continue.Lines 9?13 show that for each unclassified instance e?, we use the classifiers toclassify it into the class (sense) t if t?s posterior odds are the largest among the possibleclasses and are larger than a threshold ?.
For each class t, we store the classifiedinstances in St. Lines 14?15 show that for each class t, we choose only the top bclassified instances (in terms of the posterior odds), which are then stored in Qt.
Lines16?17 show that we create the classified instances by combining the instances withtheir classification labels.
We note that after line 17 we can also employ the one-sense-per-discourse heuristic.3.2 An ImplementationAlthough we can in principle employ any kind of classifier in BB, we use here naiveBayes (or naive Bayesian ensemble).
We also use the EM algorithm in classified datatransformation between languages.
As will be made clear, this implementation of BBcan naturally combine the features of naive Bayes (or naive Bayesian ensemble) andthe features of EM.
Hereafter, when we refer to BB, we mean this implementation ofBB.We explain the process for English (left-hand side of Figure 6); the process forChinese (right-hand side of figure) behaves similarly.
At step 1 in BB, we construct anaive Bayesian classifier as described in Figure 7.
At step 2, for each instance e?, weuse the classifier to calculate??(e?)
= maxt??T?P(t?
| e?)P(?t?
| e?
)= maxt??T?P(t?)P(e?
| t?)P(?t?)P(e?
| t??
)10Computational Linguistics Volume 30, Number 1Figure 6Bilingual bootstrapping.We estimateP(e?
| t?)
=m?i=1P(e?,i | t?
)We estimate P(e?
| t??)
similarly.
We estimate P(e?
| t?)
by linearly combining P(E)(e?
| t?
)estimated from English and P(C)(e?
| t?)
estimated from Chinese:P(e?
| t?)
= (1 ?
??
?)P(E)(e?
| t?)
+ ?P(C)(e?
| t?)
+ ?P(U)(e?)
(3)where 0 ?
?
?
1, 0 ?
?
?
1, ?
+ ?
?
1, and P(U)(e?)
is a uniform distribution over E,which is used for avoiding zero probability.
In this way, we estimate P(e?
| t?)
usinginformation from not only English, but also Chinese.We estimate P(E)(e?
| t?)
with maximum-likelihood estimation (MLE) using L?
asdata.
The estimation of P(C)(e?
| t?)
proceeds as follows.For the sake of readability, we rewrite P(C)(e?
| t?)
as P(e | t).
We define a finite-mixture model of the form P(c | t) =?e?E P(c | e, t)P(e | t), and for a specific ?
weassume that the data inL?
= {(c?,1, t?,1), (c?,2, t?,2), .
.
.
, (c?,h, t?,h)}, t?,i ?
T?
(i = 1, .
.
.
, h), ??
?
C?11Li and Li Word Translation Disambiguation Using Bilingual Bootstrappingestimate P(E)(e?
| t?)
with MLE using L?
as data;estimate P(C)(e?
| t?)
with EM algorithm using L?
for each ?
?
C?
as data;calculate P(e?
| t?)
as a linear combination of P(E)(e?
| t?)
and P(C)(e?
| t?
);estimate P(t?)
with MLE using L?
;calculate P(e?
| t??)
and P(?t?)
similarly.Figure 7Creating a naive Bayesian classifier.are generated independently from the model.
We can therefore employ the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977) to estimate the pa-rameters of the model, including P(e | t).
Note that e and c represent context words.Recall that E is a set of words in English, C is a set of words in Chinese, and Tis a set of senses.
For a specific English word e, Ce = {c?
| (e, c?)
?
T} represents theChinese words that are its possible translations.Initially, we setP(c | e, t) =??
?1|Ce|, if c ?
Ce0, if c?
CeP(e | t) = 1|E| , e ?
EWe next estimate the parameters by iteratively updating them, as described in Figure 8,until they converge.
Here f (c, t) stands for the frequency of c in the instances whichhave sense t. The context information in Chinese f (c, t?)
is then ?transformed?
into theEnglish version P(C)(e?
| t?)
through the links in T.Figure 9 shows an example of estimating P(e?
| t?)
with respect to the factory sense(i.e., sense 1).
We first use sentences such as P1 in Figure 3 to estimate P(E)(e?
| t?)
withMLE as described above.
We next use sentences such as G1 to estimate P(C)(e?
| t?)
asdescribed above.
Specifically, with the frequency data f (c, t?)
and EM we can estimateP(C)(e?
| t?).
Finally, we linearly combine P(E)(e?
| t?)
and P(C)(e?
| t?)
to obtain P(e?
| t?
).3.3 Comparison of BB and MBWe note that monolingual bootstrapping is a special case of bilingual bootstrapping(consider the situation in which ?
= 0 in formula (3)).BB can always perform better than MB.
The asymmetric relationship between theambiguous words in the two languages stands out as the key to the higher performanceE-step: P(e | c, t) ?
P(c | e, t)P(e | t)?e?E P(c | e, t)P(e | t)M-step: P(c | e, t) ?
f (c, t)P(e | c, t)?c?C f (c, t)P(e | c, t)P(e | t) ?
?c?C f (c, t)P(e | c, t)?c?C f (c, t)Figure 8The EM algorithm.12Computational Linguistics Volume 30, Number 1Figure 9Parameter estimation.Figure 10Example application of BB.of BB.
By asymmetric relationship we mean the many-to-many mapping relationshipbetween the words in the two languages, as shown in Figure 10.Suppose that the classifier with respect to plant has two classes (denoted as Aand B in Figure 10).
Further suppose that the classifiers with respect to gongchang andzhiwu in Chinese each have two classes (C and D) and (E and F), respectively.
A andD are equivalent to one another (i.e., they represent the same sense), and so are B andE.Assume that instances are classified after several iterations of BB as depicted inFigure 10.
Here, circles denote the instances that are correctly classified and crossesdenote the instances that are incorrectly classified.Since A and D are equivalent to one another, we can transform the instances with Dand use them to boost the performance of classification to A, because the misclassifiedinstances (crosses) with D are those mistakenly classified from C, and they will nothave much negative effect on classification to A, even though the translation fromChinese into English can introduce some noise.
Similar explanations can be given forother classification decisions.In contrast, MB uses only the instances in A and B to construct a classifier.
Whenthe number of misclassified instances increases (as is inevitable in bootstrapping), itsperformance will stop improving.
This phenomenon has also been observed when MBis applied to other tasks (cf.
Banko and Brill 2001; Pierce and Cardie 2001).13Li and Li Word Translation Disambiguation Using Bilingual Bootstrapping3.4 Relationship between BB and Co-trainingWe note that there are similarities between BB and co-training.
Both BB and co-trainingexecute two bootstrapping processes in parallel and make the two processes collabo-rate with one another in order to improve their performance.
The two processes look atdifferent types of information in data and exchange the information in learning.
How-ever, there are also significant differences between BB and co-training.
In co-training,the two processes use different features, whereas in BB, the two processes use differentclasses.
In BB, although the features used by the two classifiers are transformed fromone language into the other, they belong to the same space.
In co-training, on the otherhand, the features used by the two classifiers belong to two different spaces.4.
Experimental ResultsWe have conducted two experiments on English-Chinese translation disambiguation.In this section, we will first describe the experimental settings and then present theresults.
We will also discuss the results of several follow-on experiments.4.1 Translation Disambiguation Using BBAlthough it is possible to straightforwardly apply the algorithm of BB described inSection 3 to word translation disambiguation, here we use a variant of it better adaptedto the task and for fairer comparison with existing technologies.
The variant of BB weuse has four modifications:1.
It actually employs naive Bayesian ensemble rather than naive Bayes,because naive Bayesian ensemble generally performs better than naiveBayes (Pedersen 2000).2.
It employs the one-sense-per-discourse heuristic.
It turns out that in BBwith one sense per discourse, there are two layers of bootstrapping.
Onthe top level, bilingual bootstrapping is performed between the twolanguages, and on the second level, co-training is performed within eachlanguage.
(Recall that MB with one sense per discourse can be viewed asco-training.)3.
It uses only classified data in English at the beginning.
That is to say, itrequires exactly the same human labeling efforts as MB does.4.
It individually resolves ambiguities on selected English words such asplant and interest.
(Note that the basic algorithm of BB performsdisambiguation on all the words in English and Chinese.)
As a result, inthe case of plant, for example, the classifiers with respect to gongchangand zhiwu make classification decisions only on D and E and not C andF (in Figure 10), because it is not necessary to make classificationdecisions on C and F. In particular, it calculates ??
(c) as ??
(c) = P(c | t)and sets ?
= 0 in the right-hand side of step 2.4.2 Translation Disambiguation Using MBWe consider here two implementations of MB for word translation disambiguation.In the first implementation, in addition to the basic algorithm of MB, we also use(1) naive Bayesian ensemble, (2) one sense per discourse, and (3) a small amount ofclassified data in English at the beginning.
(We will denote this implementation as MB-B hereafter.)
The second implementation is different from the first one only in (1).
That14Computational Linguistics Volume 30, Number 1Table 1Data descriptions in Experiment 1.
'! 8 8	  	    );  .) 	 	 	     	is, it employs a decision list as the classifier.
This implementation is exactly the oneproposed in Yarowsky (1995).
(We will denote it as MB-D hereafter.)
MB-B and MB-Dcan be viewed as the state-of-the-art methods for word translation disambiguationusing bootstrapping.4.3 Experiment 1: WSD Benchmark DataWe first applied BB, MB-B, and MB-D to translation disambiguation on the Englishwords line and interest using a benchmark data set.5 The data set consists mainlyof articles from the Wall Street Journal and is prepared for conducting word sensedisambiguation (WSD) on the two words (e.g., Pedersen 2000).We collected from the HIT dictionary6 the Chinese words that can be translationsof the two English words; these are listed in Table 1.
One sense of an English wordlinks to one group of Chinese words.
(For the word interest, we used only its fourmajor senses, because the remaining two minor senses occur in only 3.3% of the data.
)For each sense, we selected an English word that is strongly associated with thesense according to our own intuition (cf.
Table 1).
We refer to this word as a seedword.
For example, for the sense of money paid for the use of money, we selected theword rate.
We viewed the seed word as a classified ?sentence,?
following a similarproposal in Yarowsky (1995).
In this way, for each sense we had a classified instancein English.
As unclassified data in English, we collected sentences in news articlesfrom a Web site (www.news.com), and as unclassified data in Chinese, we collectedsentences in news articles from another Web site (news.cn.tom.com).
Note that weneed to use only the sentences containing the words in Table 1.
We observed that thedistribution of the senses in the unclassified data was balanced.
As test data, we usedthe entire benchmark data set.Table 2 shows the sizes of the data sets.
Note that there are in general moreunclassified sentences (and texts) in Chinese than in English, because one Englishword usually can link to several Chinese words (cf.
Figure 5).As the translation dictionary, we used the HIT dictionary, which contains about76,000 Chinese words, 60,000 English words, and 118,000 senses (links).
We then usedthe data to conduct translation disambiguation with BB, MB-B, and MB-D, as describedin Sections 4.1 and Section 4.2.5 http://www.d.umn.edu/?tpederse/data.html.6 This dictionary was created by Harbin Institute of Technology.15Li and Li Word Translation Disambiguation Using Bilingual BootstrappingTable 2Data set sizes in Experiment 1.Unclassified sentences (texts)Words English Chinese Test sentencesinterest 1,927 (1,072) 8,811 (2,704) 2,291line 3,666 (1,570) 5,398 (2,894) 4,148For both BB and MB-B, we used an ensemble of five naive Bayesian classifierswith window sizes of ?1,?3,?5,?7, and ?9 words, and we set the parameters ?, b,and ?
to 0.2, 15, and 1.5, respectively.
The parameters were tuned on the basis of ourpreliminary experimental results on MB-B; they were not tuned, however, for BB.
Weset the BB-specific parameter ?
to 0.4, which meant that we weighted informationfrom English and Chinese equally.Table 3 shows the translation disambiguation accuracies of the three methods aswell as that of a baseline method in which we always choose the most frequent sense.Figures 11 and 12 show the learning curves of MB-D, MB-B, and BB.
Figure 13 showsthe accuracies of BB with different ?
values.
From the results, we see that BB consistentlyand significantly outperforms both MB-D and MB-B.
The results from the sign test arestatistically significant (p-value < 0.001).
(For the sign test method, see, for example,Yang and Liu [1999]).Table 4 shows the results achieved by some existing supervised learning methodswith respect to the benchmark data (cf.
Pedersen 2000).
Although BB is a method nearlyequivalent to one based on unsupervised learning, it still performs favorably whencompared with the supervised methods (note that since the experimental settings aredifferent, the results cannot be directly compared).4.4 Experiment 2: Yarowsky?s WordsWe also conducted translation on seven of the twelve English words studied in Yarowsky(1995).
Table 5 lists the words we used.Table 3Accuracies of disambiguation in Experiment 1.Words Major (%) MB-D (%) MB-B (%) BB (%)interest 54.6 54.7 69.3 75.5line 53.5 55.6 54.1 62.7Table 4Accuracies of supervised methods.interest (%) line (%)Naive Bayesian ensemble 89 88Naive Bayes 74 72Decision tree 78 ?Neural network ?
76Nearest neighbor 87 ?16Computational Linguistics Volume 30, Number 1Figure 11Learning curves with interest.Figure 12Learning curves with line.Figure 13Accuracies of BB with different ?
values.17Li and Li Word Translation Disambiguation Using Bilingual BootstrappingTable 5Data set descriptions in Experiment 2.
' ! 8 =   = = = =   =)	 = = = = =  =.=   =Table 6Data set sizes in Experiment 2.Unclassified sentences (texts) TestWords English Chinese sentencesbass 142 (106) 8,811 (4,407) 200drug 3,053 (1,048) 5,398 (3,143) 197duty 1,428 (875) 4,338 (2,714) 197palm 366 (267) 465 (382) 197plant 7,542 (2,919) 24,977 (13,211) 197space 3,897(1,494) 14,178 (8,779) 197tank 417 (245) 1,400 (683) 199Total 16,845 (6,954) 59,567 (33,319) 1,384For each of the English words, we extracted about 200 sentences containing theword from the Encarta7 English corpus and hand-labeled those sentences using ourown Chinese translations.
We used the labeled sentences as test data and the unlabeledsentences as unclassified data in English.
Table 6 shows the data set sizes.
We alsoused the sentences in the Great Encyclopedia8 Chinese corpus as unclassified data inChinese.
We defined, for each sense, a seed word in English as a classified instance inEnglish (cf.
Table 5).
We did not, however, conduct translation disambiguation on thewords crane, sake, poach, axes, and motion, because the first four words do not frequentlyoccur in the Encarta corpus, and the accuracy of choosing the major translation forthe last word already exceeds 98%.We next applied BB, MB-B, and MB-D to word translation disambiguation.
Theparameter settings were the same as those in Experiment 1.
Table 7 shows the dis-ambiguation accuracies, and Figures 14?20 show the learning curves for the sevenwords.From the results, we see again that BB significantly outperforms MB-D and MB-B.Note that the results of MB-D here cannot be directly compared with those in Yarowsky(1995), because the data used are different.
Naive Bayesian ensemble did not performwell on the word duty, causing the accuracies of both MB-B and BB to deteriorate.7 http://encarta.msn.com/default.asp.8 http://www.whlib.ac.cn/sjk/bkqs.htm.18Computational Linguistics Volume 30, Number 1Figure 14 Figure 15Learning curves with bass.
Learning curves with drug.Figure 16 Figure 17Learning curves with duty.
Learning curves with palm.Figure 18 Figure 19Learning curves with plant.
Learning curves with space.Figure 20Learning curves with tank.19Li and Li Word Translation Disambiguation Using Bilingual BootstrappingTable 7Accuracies of disambiguation in Experiment 2.Words Major (%) MB-D (%) MB-B (%) BB (%)bass 61.0 57.0 89.0 92.0drug 77.7 78.7 79.7 86.8duty 86.3 86.8 72.0 75.1palm 82.2 80.7 83.3 92.4plant 71.6 89.3 95.4 95.9space 64.5 83.3 84.3 87.8tank 60.3 76.4 76.9 84.4Total 71.9 78.8 82.9 87.8Table 8Top words for interest rate sense of interest.MB-B BBpayment savingcut paymentearn benchmarkshort whoseshort-term baseyield preferu.s.
fixedmargin debtbenchmark annualregard dividend4.5 DiscussionWe investigated the reason for BB?s outperforming MB and found that the explanationin Section 3.3 appears to be valid according to the following observations.1.
In a naive Bayesian classifier, words with large values of likelihood ratio P(e|t)P(e|?t)will have strong influences on classification.
We collected the words having the largestlikelihood ratio with respect to each sense t in both BB and MB-B and found that BBobviously has more ?relevant words?
than MB-B.
Here words relevant to a particularsense refer to the words that are strongly indicative of that sense according to humanjudgments.Table 8 shows the top 10 words in terms of likelihood ratio with respect to theinterest rate sense in both BB and MB-B.
The relevant words are italicized.
Figure 21shows the numbers of relevant words with respect to the four senses of interest in BBand MB-B.2.
From Figure 13, we see that the performance of BB remains high or gets highereven when ?
becomes larger than 0.4 (recall that ?
was fixed at 0.2).
This result stronglyindicates that the information from Chinese has positive effects.3.
One might argue that the higher performance of BB can be attributed to thelarger amount of unclassified data it uses, and thus if we increase the amount ofunclassified data for MB, it is likely that MB can perform as well as BB.
We conductedan additional experiment and found that this is not the case.
Figure 22 shows theaccuracies achieved by MB-B as the amount of unclassified data increases.
The plotshows that the accuracy of MB-B does not improve when the amount of unclassified20Computational Linguistics Volume 30, Number 1Figure 21Number of relevant words.Figure 22When more unclassified data available.data increases.
Figure 22 plots again the results of BB as well as those of a methodreferred to as MB-C.
In MB-C, we linearly combined two MB-B classifiers constructedwith two different unclassified data sets, and we found that although the accuraciesare improved in MB-C, they are still much lower than those of BB.4.
We have noticed that a key to BB?s performance is the asymmetric relationshipbetween the classes in the two languages.
Therefore, we tested the performance ofMB and BB when the classes in the two languages are symmetric (i.e., one-to-onemapping).We performed two experiments on text classification in which the categories werefinance and industry, and finance and trade, respectively.
We collected Chinese textsfrom the People?s Daily in 1998 that had already been assigned class labels.
We usedhalf of them as unclassified training data in Chinese and the remaining as test data inChinese.
We also collected English texts from the Wall Street Journal.
We used them asunlabeled training data in English.
We used the class names (i.e., finance, industry, andtrade, as seed data (classified data)).
Table 9 shows the accuracies of text classification.From the results we see that when the classes are symmetric, BB cannot outperformMB.5.
We also investigated the effect of the one-sense-per-discourse heuristic.
Table 10shows the performance of MB and BB on the word interest with and without the heuris-tic.
We see that with the heuristic, the performance of both MB and BB is improved.Even without the heuristic, BB still performs better than MB with the heuristic.21Li and Li Word Translation Disambiguation Using Bilingual BootstrappingTable 9Accuracy of text classification.Classes MB-B (%) BB (%)Finance and industry 93.2 92.9Finance and trade 78.4 78.6Table 10Accuracy of disambiguation.MB-D (%) MB-B (%) BB (%)With one sense per discourse 54.7 69.3 75.5Without one sense per discourse 54.6 66.4 71.65.
ConclusionWe have addressed here the problem of classification across two languages.
Specificallywe have considered the problem of bootstrapping.
We find that when the task is wordtranslation disambiguation between two languages, we can use the asymmetric rela-tionship between the ambiguous words in the two languages to significantly boost theperformance of bootstrapping.
We refer to this approach as bilingual bootstrapping.We have developed a method for implementing this bootstrapping approach that nat-urally combines the use of naive Bayes and the EM algorithm.
Future work includes atheoretical analysis of bilingual bootstrapping (generalization error of BB, relationshipbetween BB and co-training, etc.)
and extensions of bilingual bootstrapping to morecomplicated machine translation tasks.AcknowledgmentsWe thank Ming Zhou, Ashley Chang andYao Meng for their valuable comments andsuggestions on an early draft of this article.We acknowledge the four anonymousreviewers of this article for their valuablecomments and criticisms.
We thank MichaelHolmes, Mark Petersen, Kevin Knight, andBob Moore for their checking of the Englishof this article.
A previous version of thisarticle appeared in Proceedings of the FortiethAnnual Meeting of the Association forComputational Linguistics.ReferencesBanko, Michele, and Eric Brill.
2001.
Scalingto very very large corpora for naturallanguage disambiguation.
In Proceedings ofthe 39th Annual Meeting of the Association forComputational Linguistics, pages 26?33,Toulouse, France.Blum, Avrim, and Tom M. Mitchell.
1998.Combining labeled and unlabeled datawith co-training.
In Proceedings of the 11thAnnual Conference on ComputationalLearning Theory, pages 92?100, Madison,WI.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, and Robert L.Mercer.
1991.
Word sense disambiguationusing statistical methods.
In Proceedings ofthe 29th Annual Meeting of the Association forComputational Linguistics, pages 264?270,University of California, Berkeley.Bruce, Rebecca, and Janyce Weibe.
1994.Word-sense disambiguation usingdecomposable models.
In Proceedings of the32nd Annual Meeting of the Association forComputational Linguistics, pages 139?146,New Mexico State University, Las Cruces.Collins, Michael, and Yoram Singer.
1999.Unsupervised models for named entityclassification.
In Proceedings of the 1999Joint SIGDAT Conference on EmpiricalMethods in Natural Language Processing andVery Large Corpora, University ofMaryland, College Park.Dagan, Ido, and Alon Itai.
1994.
Word sensedisambiguation using a second languagemonolingual corpus.
ComputationalLinguistics, 20(4):563?596.22Computational Linguistics Volume 30, Number 1Dempster, A. P., N. M. Laird, and D. B.Rubin.
1977.
Maximum likelihood fromincomplete data via the EM algorithm.Journal of the Royal Statistical Society B,39:1?38.Escudero, Gerard, Lluis Marquez, andGerman Rigau.
2000.
Boosting applied toword sense disambiguation.
In Proceedingsof the 12th European Conference on MachineLearning, pages 129?141, Barcelona.Gale, William, Kenneth Church, and DavidYarowsky.
1992a.
A method fordisambiguating word senses in a largecorpus.
Computers and Humanities,26:415?439.Gale, William, Kenneth Church, and DavidYarowsky.
1992b.
One sense per discourse.In Proceedings of DARPA Speech and NaturalLanguage Workshop, pages 233?237,Harriman, NY.Golding, Andrew R., and Dan Roth.
1999.
AWinnow-based approach tocontext-sensitive spelling correction.Machine Learning, 34:107?130.Kikui, Genichiro.
1999.
Resolving translationambiguity using non-parallel bilingualcorpora.
In Proceedings of ACL ?99 Workshopon Unsupervised Learning in NaturalLanguage Processing, University ofMaryland, College Park.Koehn, Philipp, and Kevin Knight.
2000.Estimating word translation probabilitiesfrom unrelated monolingual corpora usingthe EM algorithm.
In Proceedings of the 17thNational Conference on Artificial Intelligence,pages 711?715, Austin, TX.Li, Hang, and Kenji Yamanishi.
2002.
Textclassification using ESC-based stochasticdecision lists.
Information Processing andManagement, 38:343?361.Lin, Dekang.
1997.
Using syntacticdependency as local context to resolveword sense ambiguity.
In Proceedings of the35th Annual Meeting of the Association forComputational Linguistics, pages 64?71,Universidad Nacional de Educacio?n aDistancia (UNED), Madrid.Mangu, Lidia, and Eric Brill.
1997.Automatic rule acquisition for spellingcorrection.
In Proceedings of the 14thInternational Conference on Machine Learning,pages 187?194, Nashville, TN.Mihalcea, Rada, and Dan I. Moldovan.
1999.A method for word sense disambiguationof unrestricted text.
In Proceedings of the37th Annual Meeting of the Association forComputational Linguistics, pages 152?158,University of Maryland, College Park.Ng, Hwee Tou, and Hian Beng Lee.
1996.Integrating multiple knowledge sources todisambiguate word sense: Anexemplar-based approach.
In Proceedings ofthe 34th Annual Meeting of the Association forComputational Linguistics, pages 40?47,University of California, Santa Cruz.Nigam, Kamal, Andrew McCallum,Sebastian Thrun, and Tom M. Mitchell.2000.
Text classification from labeled andunlabeled documents using EM.
MachineLearning, 39(2?3):103?134.Nigam, Kamal, and Rayid Ghani.
2000.Analyzing the effectiveness andapplicability of co-training.
In Proceedingsof the 9th International Conference onInformation and Knowledge Management,pages 86?93, McLean, VA.Pedersen, Ted.
2000.
A simple approach tobuilding ensembles of naive Bayesianclassifiers for word sense disambiguation.In Proceedings of the First Meeting of theNorth American Chapter of the Association forComputational Linguistics, Seattle.Pedersen, Ted, and Rebecca Bruce.
1997.Distinguishing word senses in untaggedtext.
In Proceedings of the Second Conferenceon Empirical Methods in Natural LanguageProcessing, pages 197?207, Providence, RI.Pierce, David, and Claire Cardie.
2001.Limitations of co-training for naturallanguage learning from large datasets.
InProceedings of the 2001 Conference onEmpirical Methods in Natural LanguageProcessing, Carnegie Mellon University,Pittsburgh.Schutze, Hinrich.
1998.
Automatic wordsense discrimination.
ComputationalLinguistics, 24(1):97?124.Towell, Geoffrey, and Ellen M. Voorhees.1998.
Disambiguating highly ambiguouswords.
Computational Linguistics,24(1):125?146.Yang, Yiming, and Xin Liu.
1999.
Are-examination of text categorizationmethods.
In Proceedings of the 22nd AnnualInternational ACM SIGIR Conference onResearch and Development in InformationRetrieval, pages 42?49, Berkeley, CA.Yarowsky, David.
1994.
Decision lists forlexical ambiguity resolution: Applicationto accent restoration in Spanish andFrench.
In Proceedings of the 32nd AnnualMeeting of the Association for ComputationalLinguistics, pages 88?95, New MexicoState University, Las Cruces.Yarowsky, David.
1995.
Unsupervised wordsense disambiguation rivaling supervisedmethods.
In Proceedings of the 33rd AnnualMeeting of the Association for ComputationalLinguistics, pages 189?196.Zhou, Ming, Yuan Ding, and ChangningHuang.
2001.
Improving translationselection with a new translation modeltrained by independent monolingualcorpora.
International Journal ofComputational Linguistics and ChineseLanguage Processing, 6(1):1?26.
