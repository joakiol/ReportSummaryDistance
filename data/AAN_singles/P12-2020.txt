Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 100?104,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Comparative Study of Target Dependency Structuresfor Statistical Machine TranslationXianchao Wu?, Katsuhito Sudoh, Kevin Duh?, Hajime Tsukada, Masaaki NagataNTT Communication Science Laboratories, NTT Corporation2-4 Hikaridai Seika-cho, Soraku-gun Kyoto 619-0237 Japanwuxianchao@gmail.com,sudoh.katsuhito@lab.ntt.co.jp,kevinduh@is.naist.jp,{tsukada.hajime,nagata.masaaki}@lab.ntt.co.jpAbstractThis paper presents a comparative study oftarget dependency structures yielded by sev-eral state-of-the-art linguistic parsers.
Our ap-proach is to measure the impact of these non-isomorphic dependency structures to be usedfor string-to-dependency translation.
Besidesusing traditional dependency parsers, we alsouse the dependency structures transformedfrom PCFG trees and predicate-argumentstructures (PASs) which are generated by anHPSG parser and a CCG parser.
The experi-ments on Chinese-to-English translation showthat the HPSG parser?s PASs achieved the bestdependency and translation accuracies.1 IntroductionTarget language side dependency structures havebeen successfully used in statistical machine trans-lation (SMT) by Shen et al (2008) and achievedstate-of-the-art results as reported in the NIST 2008Open MT Evaluation workshop and the NTCIR-9Chinese-to-English patent translation task (Goto etal., 2011; Ma and Matsoukas, 2011).
A primary ad-vantage of dependency representations is that theyhave a natural mechanism for representing discon-tinuous constructions, which arise due to long-distance dependencies or in languages where gram-matical relations are often signaled by morphologyinstead of word order (McDonald and Nivre, 2011).It is known that dependency-style structures canbe transformed from a number of linguistic struc-?Now at Baidu Inc.?Now at Nara Institute of Science & Technology (NAIST)tures.
For example, using the constituent-to-dependency conversion approach proposed by Jo-hansson and Nugues (2007), we can easily yield de-pendency trees from PCFG style trees.
A seman-tic dependency representation of a whole sentence,predicate-argument structures (PASs), are also in-cluded in the output trees of (1) a state-of-the-arthead-driven phrase structure grammar (HPSG) (Pol-lard and Sag, 1994; Sag et al, 2003) parser, Enju1(Miyao and Tsujii, 2008) and (2) a state-of-the-artCCG parser2 (Clark and Curran, 2007).
The moti-vation of this paper is to investigate the impact ofthese non-isomorphic dependency structures to beused for SMT.
That is, we would like to provide acomparative evaluation of these dependencies in astring-to-dependency decoder (Shen et al, 2008).2 Gaining Dependency Structures2.1 Dependency treeWe follow the definition of dependency graph anddependency tree as given in (McDonald and Nivre,2011).
A dependency graph G for sentence s iscalled a dependency tree when it satisfies, (1) thenodes cover all the words in s besides the ROOT;(2) one node can have one and only one head (word)with a determined syntactic role; and (3) the ROOTof the graph is reachable from all other nodes.For extracting string-to-dependency transferrules, we use well-formed dependency structures,either fixed or floating, as defined in (Shen et al,2008).
Similarly, we ignore the syntactic roles1http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html2http://groups.inf.ed.ac.uk/ccg/software.html100when the fluid pressure cylinder 31 is used , fluid is gradually applied .t0 t1 t2 t3 t4 t5 t6 t7 t8 t9 t10 t11 t12c2 c5 c7 c9 c11 c12 c14 c15 c17 c20 c22 c24 c25c3c4c6c8c10 c13c18c19c21c23c16c1c0conj_arg12det_arg1adj_arg1noun_arg1noun_arg0adj_arg1aux_arg12verb_arg12punct_arg1noun_arg0aux_arg12adj_arg1verb_arg12* +* +* +*+* +* +* +** +* +* +* +* ++Figure 1: HPSG tree of an example sentence.
?
*?/?+?=syntactic/semantic heads.
Arrows in red (upper)=PASs, orange (bottom)=word-level dependencies gener-ated from PASs, blue=newly appended dependencies.both during rule extracting and target dependencylanguage model (LM) training.2.2 Dependency parsingGraph-based and transition-based are two predom-inant paradigms for data-driven dependency pars-ing.
The MST parser (McDonald et al, 2005) andthe Malt parser (Nivre, 2003) stand for two typicalparsers, respectively.
Parsing accuracy comparisonand error analysis under the CoNLL-X dependencyshared task data (Buchholz and Marsi, 2006) havebeen performed by McDonald and Nivre (2011).Here, we compare them on the SMT tasks throughparsing the real-world SMT data.2.3 PCFG parsingFor PCFG parsing, we select the Berkeley parser(Petrov and Klein, 2007).
In order to generate word-level dependency trees from the PCFG tree, we usethe LTH constituent-to-dependency conversion tool3written by Johansson and Nugues (2007).
The headfinding rules4 are according to Magerman (1995)and Collins (1997).
Similar approach has been orig-inally used by Shen et al (2008).2.4 HPSG parsingIn the Enju English HPSG grammar (Miyao et al,2003) used in this paper, the semantic content of3http://nlp.cs.lth.se/software/treebank converter/4http://www.cs.columbia.edu/ mcollins/papers/headsa sentence/phrase is represented by a PAS.
In anHPSG tree, each leaf node generally introduces apredicate, which is represented by the pair made upof the lexical entry feature and predicate type fea-ture.
The arguments of a predicate are designated bythe arrows from the argument features in a leaf nodeto non-terminal nodes (e.g., t0?c3, t0?c16).Since the PASs use the non-terminal nodes in theHPSG tree (Figure 1), this prevents their direct us-age in a string-to-dependency decoder.
We thus needan algorithm to transform these phrasal predicate-argument dependencies into a word-to-word depen-dency tree.
Our algorithm (refer to Figure 1 for anexample) for changing PASs into word-based depen-dency trees is as follows:1. finding, i.e., find the syntactic/semantic headword of each argument node through a bottom-up traversal of the tree;2. mapping, i.e., determine the arc directions(among a predicate word and the syntac-tic/semantic head words of the argument nodes)for each predicate type according to Table 1.Then, a dependency graph will be generated;3. checking, i.e., post modifying the dependencygraph according to the definition of dependencytree (Section 2.1).Table 1 lists the mapping from HPSG?s PAS typesto word-level dependency arcs.
Since a non-terminalnode in an HPSG tree has two kinds of heads, syn-tactic or semantic, we will generate two dependencygraphs after mapping.
We use ?PAS+syn?
to repre-sent the dependency trees generated from the HPSGPASs guided by the syntactic heads.
For semanticheads, we use ?PAS+sem?.For example, refer to t0 = when in Figure 1.Its arg1 = c16 (with syntactic head t10), arg2= c3 (with syntactic head t6), and PAS type =conj arg12.
In Table 1, this PAS type correspondsto arg2?pred?arg1, then the result word-level de-pendency is t6(is)?t0(when)?t10(is).We need to post modify the dependency graph af-ter applying the mapping, since it is not guaranteedto be a dependency tree.
Referring to the definitionof dependency tree (Section 2.1), we need the strat-egy for (1) selecting only one head from multiple101PAS Type Dependency Relationadj arg1[2] [arg2 ?]
pred ?
arg1adj mod arg1[2] [arg2 ?]
pred ?
arg1 ?
modaux[ mod] arg12 arg1/pred ?
arg2 [?
mod]conj arg1[2[3]] [arg2[/arg3]] ?
pred ?
arg1comp arg1[2] pred ?
arg1 [?
arg2]comp mod arg1 arg1 ?
pred ?
modnoun arg1 pred ?
arg1noun arg[1]2 arg2 ?
pred [?
arg1]poss arg[1]2 pred ?
arg2 [?
arg1]prep arg12[3] arg2[/arg3] ?
pred ?
arg1prep mod arg12[3] arg2[/arg3] ?
pred ?
arg1 ?
modquote arg[1]2 [arg1 ?]
pred ?
arg2quote arg[1]23 [arg1/]arg3 ?
pred ?
arg2lparen arg123 pred/arg2 ?
arg3 ?
arg1relative arg1[2] [arg2 ?]
pred ?
arg1verb arg1[2[3[4]]] arg1[/arg2[/arg3[/arg4]]] ?
predverb mod arg1[2[3[4]]] arg1[/arg2[/arg3[/arg4]]]?pred?modapp arg12,coord arg12 arg2/pred ?
arg1det arg1,it arg1,punct arg1 pred ?
arg1dtv arg2 pred ?
arg2lgs arg2 arg2 ?
predTable 1: Mapping fromHPSG?s PAS types to dependencyrelations.
Dependent(s)?
head(s), / = and, [] = optional.heads and (2) appending dependency relations forthose words/punctuation that do not have any head.When one word has multiple heads, we only keepone.
The selection strategy is that, if this arc wasdeleted, it will cause the biggest number of wordsthat can not reach to the root word anymore.
In caseof a tie, we greedily pack the arc that connect twowords wi and wj where |i?
j| is the biggest.
For allthe words and punctuation that do not have a head,we greedily take the root word of the sentence astheir heads.
In order to fully use the training data,if there are directed cycles in the result dependencygraph, we still use the graph in our experiments,where only partial dependency arcs, i.e., those targetflat/hierarchical phrases attached with well-formeddependency structures, can be used during transla-tion rule extraction.2.5 CCG parsingWe also use the predicate-argument dependenciesgenerated by the CCG parser developed by Clarkand Curran (2007).
The algorithm for generatingword-level dependency tree is easier than processingthe PASs included in the HPSG trees, since the wordlevel predicate-argument relations have already beenincluded in the output of CCG parser.
The mappingfrom predicate types to the gold-standard grammat-ical relations can be found in Table 13 in (Clark andCurran, 2007).
The post-processing is like that de-scribed for HPSG parsing, except we greedily usethe MST?s sentence root when we can not determineit based on the CCG parser?s PASs.3 Experiments3.1 SetupWe re-implemented the string-to-dependency de-coder described in (Shen et al, 2008).
Dependencystructures from non-isomorphic syntactic/semanticparsers are separately used to train the transferrules as well as target dependency LMs.
For intu-itive comparison, an outside SMT system is Moses(Koehn et al, 2007).For Chinese-to-English translation, we use theparallel data from NIST Open Machine TranslationEvaluation tasks.
The training data contains 353,796sentence pairs, 8.7M Chinese words and 10.4M En-glish words.
The NIST 2003 and 2005 test dataare respectively taken as the development and testset.
We performed GIZA++ (Och and Ney, 2003)and the grow-diag-final-and symmetrizing strategy(Koehn et al, 2007) to obtain word alignments.
TheBerkeley Language Modeling Toolkit, berkeleylm-1.0b35 (Pauls and Klein, 2011), was employed totrain (1) a five-gram LM on the Xinhua portion ofLDC English Gigaword corpus v3 (LDC2007T07)and (2) a tri-gram dependency LM on the Englishdependency structures of the training data.
We re-port the translation quality using the case-insensitiveBLEU-4 metric (Papineni et al, 2002).3.2 Statistics of dependenciesWe compare the similarity of the dependencies witheach other, as shown in Table 2.
Basically, we in-vestigate (1) if two dependency graphs of one sen-tence share the same root word and (2) if the head ofone word in one sentence are identical in two depen-dency graphs.
In terms of root word comparison, weobserve that MST and CCG share 87.3% of iden-tical root words, caused by borrowing roots fromMST to CCG.
Then, it is interesting that Berkeleyand PAS+syn share 74.8% of identical root words.Note that the Berkeley parser is trained on the Penntreebank (Marcus et al, 1994) yet the HPSG parseris trained on the HPSG treebank (Miyao and Tsujii,5http://code.google.com/p/berkeleylm/102Dependency Precision Recall BLEU-Dev BLEU-Test # phrases # hier rules # illegal dep trees # directed cyclesMoses-1 - - 0.3349 0.3207 5.4M - - -Moses-2 - - 0.3445 0.3262 0.7M 4.5M - -MST 0.744 0.750 0.3520 0.3291 2.4M 2.1M 251 0Malt 0.732 0.738 0.3423 0.3203 1.5M 1.3M 130,960 0Berkeley 0.800 0.806 0.3475 0.3312 2.4M 2.2M 282 0PAS+syn 0.818 0.824 0.3499 0.3376 2.2M 1.9M 10,411 5,853PAS+sem 0.777 0.782 0.3484 0.3343 2.1M 1.6M 14,271 9,747CCG 0.701 0.705 0.3442 0.3283 1.7M 1.3M 61,015 49,955Table 3: Comparison of dependency and translation accuracies.
Moses-1 = phrasal, Moses-2 = hierarchical.Malt Berkeley PAS PAS CCG+syn +semMST 70.5 62.5 69.2 53.3 87.3(77.3) (64.6) (58.5) (58.1) (61.7)Malt 66.2 73.0 46.8 62.9(63.2) (57.7) (56.6) (58.1)Berkeley 74.8 44.2 56.5(64.3) (56.0) (59.2)PAS+ 59.3 62.9syn (79.1) (61.0)PAS+ 60.0sem (58.8)Table 2: Comparison of the dependencies of the Englishsentences in the training data.
Without () = % of similarroot words; with () = % of similar head words.2008).
In terms of head word comparison, PAS+synand PAS+sem share 79.1% of identical head words.This is basically due to that we used the similarPASs of the HPSG trees.
Interestingly, there are only59.3% identical root words shared by PAS+syn andPAS+sem.
This reflects the significant difference be-tween syntactic and semantic heads.We also manually created the golden dependencytrees for the first 200 English sentences in the train-ing data.
The precision/recall (P/R) are shown inTable 3.
We observe that (1) the translation accura-cies approximately follow the P/R scores yet are notthat sensitive to their large variances, and (2) it isstill tough for domain-adapting from the treebank-trained parsers to parse the real-world SMT data.PAS+syn performed the best by avoiding the errorsof missing of arguments for a predicate, wronglyidentified head words for a linguistic phrase, and in-consistency dependencies inside relatively long co-ordinate structures.
These errors significantly influ-ence the number of extractable translation rules andthe final translation accuracies.Note that, these P/R scores on the first 200 sen-tences (all from less than 20 newswire documents)shall only be taken as an approximation of the totaltraining data and not necessarily exactly follow thetendency of the final BLEU scores.
For example,CCG is worse than Malt in terms of P/R yet with ahigher BLEU score.
We argue this is mainly due tothat the number of illegal dependency trees gener-ated by Malt is the highest.
Consequently, the num-ber of flat/hierarchical rules generated by using Malttrees is the lowest.
Also, PAS+sem has a lower P/Rthan Berkeley, yet their final BLEU scores are notstatistically different.3.3 ResultsTable 3 also shows the BLEU scores, the number offlat phrases and hierarchical rules (both integratedwith target dependency structures), and the num-ber of illegal dependency trees generated by eachparser.
From the table, we have the following ob-servations: (1) all the dependency structures (exceptMalt) achieved a significant better BLEU score thanthe phrasal Moses; (2) PAS+syn performed the bestin the test set (0.3376), and it is significantly betterthan phrasal/hierarchical Moses (p < 0.01), MST(p < 0.05), Malt (p < 0.01), Berkeley (p < 0.05),and CCG (p < 0.05); and (3) CCG performed aswell as MST and Berkeley.
These results lead us toargue that the robustness of deep syntactic parserscan be advantageous in SMT compared with tradi-tional dependency parsers.4 ConclusionWe have constructed a string-to-dependency trans-lation platform for comparing non-isomorphic tar-get dependency structures.
Specially, we proposedan algorithm for generating word-based dependencytrees from PASs which are generated by a state-of-the-art HPSG parser.
We found that dependencytrees transformed from these HPSG PASs achievedthe best dependency/translation accuracies.103AcknowledgmentsWe thank the anonymous reviewers for their con-structive comments and suggestions.ReferencesSabine Buchholz and Erwin Marsi.
2006.
Conll-x sharedtask on multilingual dependency parsing.
In Proceed-ings of the Tenth Conference on Computational Nat-ural Language Learning (CoNLL-X), pages 149?164,New York City, June.
Association for ComputationalLinguistics.Stephen Clark and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with ccg and log-linear models.
Computational Linguistics, 33(4):493?552.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proceedings of the35th Annual Meeting of the Association for Computa-tional Linguistics, pages 16?23, Madrid, Spain, July.Association for Computational Linguistics.Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, andBenjamin K. Tsou.
2011.
Overview of the patent ma-chine translation task at the ntcir-9 workshop.
In Pro-ceedings of NTCIR-9, pages 559?578.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for english.
InIn Proceedings of NODALIDA, Tartu, Estonia, April.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the ACL 2007 Demo and Poster Sessions, pages177?180.Jeff Ma and Spyros Matsoukas.
2011.
Bbn?s systemsfor the chinese-english sub-task of the ntcir-9 patentmtevaluation.
In Proceedings of NTCIR-9, pages 579?584.David Magerman.
1995.
Statistical decision-tree modelsfor parsing.
In In Proceedings of of the 33rd AnnualMeeting of the Association for Computational Linguis-tics, pages 276?283.Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,Robert MacIntyre, Ann Bies, Mark Ferguson, KarenKatz, and Britta Schasberger.
1994.
The penn tree-bank: Annotating predicate argument structure.
InProceedings of the Workshop on HLT, pages 114?119,Plainsboro.Ryan McDonald and Joakim Nivre.
2011.
Analyzingand integrating dependency parsers.
ComputationalLinguistics, 37(1):197?230.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics(ACL?05), pages 91?98, Ann Arbor, Michigan, June.Association for Computational Linguistics.Yusuke Miyao and Jun?ichi Tsujii.
2008.
Feature forestmodels for probabilistic hpsg parsing.
ComputationalLingustics, 34(1):35?80.Yusuke Miyao, Takashi Ninomiya, and Jun?ichi Tsu-jii.
2003.
Probabilistic modeling of argument struc-tures including non-local dependencies.
In Proceed-ings of the International Conference on Recent Ad-vances in Natural Language Processing, pages 285?291, Borovets.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of the 8th In-ternational Workshop on Parsing Technologies (IWPT,pages 149?160.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalu-ation of machine translation.
In Proceedings of ACL,pages 311?318.Adam Pauls and Dan Klein.
2011.
Faster and smallern-gram language models.
In Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages258?267, Portland, Oregon, USA, June.
Associationfor Computational Linguistics.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Human Language Tech-nologies 2007: The Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics; Proceedings of the Main Conference, pages404?411, Rochester, New York, April.
Association forComputational Linguistics.Carl Pollard and Ivan A.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
University of Chicago Press.Ivan A.
Sag, Thomas Wasow, and Emily M. Bender.2003.
Syntactic Theory: A Formal Introduction.Number 152 in CSLI Lecture Notes.
CSLI Publica-tions.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation algo-rithm with a target dependency language model.
InProceedings of ACL-08:HLT, pages 577?585, Colum-bus, Ohio.104
