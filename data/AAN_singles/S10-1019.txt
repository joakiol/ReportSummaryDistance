Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 96?99,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsUBIU: A Language-Independent System for Coreference ResolutionDesislava ZhekovaUniversity of Bremenzhekova@uni-bremen.deSandra K?ublerIndiana Universityskuebler@indiana.eduAbstractWe present UBIU, a language indepen-dent system for detecting full coreferencechains, composed of named entities, pro-nouns, and full noun phrases which makesuse of memory based learning and a fea-ture model following Rahman and Ng(2009).
UBIU is evaluated on the task?Coreference Resolution in Multiple Lan-guages?
(SemEval Task 1 (Recasens et al,2010)) in the context of the 5th Interna-tional Workshop on Semantic Evaluation.1 IntroductionCoreference resolution is a field in which majorprogress has been made in the last decade.
Af-ter a concentration on rule-based systems (cf.
e.g.
(Mitkov, 1998; Poesio et al, 2002; Markert andNissim, 2005)), machine learning methods wereembraced (cf.
e.g.
(Soon et al, 2001; Ng andCardie, 2002)).
However, machine learning basedcoreference resolution is only possible for a verysmall number of languages.
In order to make suchresources available for a wider range of languages,language independent systems are often regardedas a partial solution.
To this day, there have beenonly a few systems reported that work on multiplelanguages (Mitkov, 1999; Harabagiu and Maio-rano, 2000; Luo and Zitouni, 2005).
However, allof those systems were geared towards predefinedlanguage sets.In this paper, we present a language indepen-dent system that does require syntactic resourcesfor each language but does not require any effortfor adapting the system to a new language, exceptfor minimal effort required to adapt the feature ex-tractor to the new language.
The system was com-pletely developed within 4 months, and will be ex-tended to new languages in the future.2 UBIU: System StructureThe UBIU system aims at being a language-independent system in that it uses a combinationof machine learning, in the form of memory-basedlearning (MBL) in the implementation of TiMBL(Daelemans et al, 2007), and language indepen-dent features.
MBL uses a similarity metric to findthe k nearest neighbors in the training data in orderto classify a new example, and it has been shownto work well for NLP problems (Daelemans andvan den Bosch, 2005).
Similar to the approachby Rahman and Ng (2009), classification in UBUIis based on mention pairs (having been shown towork well for German (Wunsch, 2009)) and usesas features standard types of linguistic annotationthat are available for a wide range of languagesand are provided by the task.Figure 1 shows an overview of the system.
Inpreprocessing, we slightly change the formattingof the data in order to make it suitable for the nextstep in which language dependent feature extrac-tion modules are used, fromwhich the training andtest sets for the classification are extracted.
Ourapproach is untypical in that it first extracts theheads of possible antecedents during feature ex-traction.
The full yield of an antecedent in the testset is determined after classification in a separatemodule.
During postprocessing, final decisionsare made concerning which of the mention pairsare considered for the final coreference chains.In the following sections, we will describe fea-ture extraction, classification, markable extraction,and postprocessing in more detail.2.1 Feature ExtractionThe language dependent modules contain finitestate expressions that detect the heads based on thelinguistic annotations.
Such a language module re-quires a development time of approximately 1 per-son hour in order to adapt the regular expressions96Figure 1: Overview of the system.to the given language data (different POS tagsets,differences in the provided annotations).
This isthe only language dependent part of the system.We decided to separate the task of finding headsof markables, which then serve as the basis for thegeneration of the feature vectors, from the identi-fication of the scope of a markable.
For the En-glish sentence ?Any details or speculation on whospecifically, we don?t know that at this point.
?, wefirst detect the heads of possible antecedents, forexample ?details?.
However, the decision on thescope of the markable, i.e.
the decision between?details?
or ?Any details or speculation on whospecifically?
is made in the postprocessing phase.One major task of the language modules is thecheck for cyclic dependencies.
Our system re-lies on the assumption that cyclic dependencies donot occur, which is a standard assumption in de-pendency parsing (K?ubler et al, 2009).
However,since some of the data sets in the multilingual taskcontained cycles, we integrated a module in thepreprocessing step that takes care of such cycles.After the identification of the heads of mark-ables, the actual feature extraction is performed.The features that were used for training a classifier(see Table 1) were selected from the feature pool# Feature Description1 mj- the antecedent2 mk- the mention to be resolved3 Y ifmjis pron.
; else N4 Y ifmjis subject; else N5 Y ifmjis a nested NP; else N6 number - Sg.
or Pl.7 gender - F(emale), M(ale), N(euter), U(nknown)8 Y ifmkis a pronoun; else N9 Y ifmkis a nested NP; else N10 semantic class ?
extracted from the NEs in the data11 the nominative case ofmkif pron.
; else NA12 C if the mentions are the same string; else I13 C if one mention is a substring of the other; else I14 C if both mentions are pron.
and same string; else I15 C if both mentions are both non-pron.
and samestring; else I16 C if both m. are pron.
and either same pron.
or diff.w.r.t.
case; NA if at least one is not pron.
; else I17 C if the mentions agree in number; I if not; NA if thenumber for one or both is unknown18 C if both m. are pron.
I if neither19 C if both m. are proper nouns; I if neither; else NA20 C if the m. have same sem.
class; I if not; NA if thesem.
class for one or both m. is unknown21 sentence distance between the mentions22 concat.
values for f. 6 formjandmk23 concat.
values for f. 7 formjandmk24 concat.
values for f. 3 formjandmk25 concat.
values for f. 5 formjandmk26 concat.
values for f. 10 formjandmk27 concat.
values for f. 11 formjandmkTable 1: The pool of features for all languages.presented by Rahman and Ng (2009).
Note thatnot all features could be used for all languages.We extracted all the features in Table 1 if the cor-responding type of annotation was available; oth-erwise, a null value was assigned.A good example for the latter concerns the gen-der information represented by feature 7 (for pos-sible feature values cf.
Table 1).
Let us considerthe following two entries - the first from the Ger-man data set and the second from English:1.
Regierung Regierung Regierung NN NNcas=d|num=sg|gend=fem cas=d|num=sg|gend=fem 3131 PN PN .
.
.2. law law NN NN NN NN 2 2 PMOD PMOD .
.
.Extracting the value from entry 1, wheregend=fem, is straightforward; the value being F.However, there is no gender information providedin the English data (entry 2).
As a result, the valuefor feature 7 is U for the closed task.2.2 Classifier TrainingBased on the features extracted with the featureextractors described above, we trained TiMBL.Then we performed a non-exhaustive parameter97optimization across all languages.
Since a full op-timization strategy would lead to an unmanageablenumber of system runs, we concentrated on vary-ing k, the number of nearest neighbors consideredin classification, and on the distance metric.Furthermore, the optimization is focused onlanguage independence.
Hence, we did not op-timize each classifier separately but selected pa-rameters that lead to best average results acrossall languages of the shared task.
In our opinion,this ensures an acceptable performance for newlanguages without further adaptation.
The optimalsettings for all the given languages were k=3 withthe Overlap distance and gain ratio weighting.2.3 Markable ExtractionThe markable extractor makes use of the depen-dency relation labels.
Each syntactic head togetherwith all its dependents is identified as a separatemarkable.
This approach is very sensitive to incor-rect annotations and to dependency cycles in thedata set.
It is also sensitive to differences betweenthe syntactic annotation and markables.
In theDutch data, for example, markables for named en-tities (NE) often exclude the determiner, a nominaldependent in the dependency annotation.
Thus,the markable extractor suggests the whole phraseas a markable, rather than just the NE.During the development phase, we determinedexperimentally that the recognition of markablesis one of the most important steps in order toachieve high accuracy in coreference resolution:We conducted an ablation study on the trainingdata set.
We used the train data as training set andthe devel data as testing set and investigated threedifferent settings:1.
Gold standard setting: Uses gold markableannotations as well as gold linguistic anno-tations (upper bound).2.
Gold linguistic setting: Uses automaticallydetermined markables and gold linguistic an-notations.3.
Regular setting: Uses automatically deter-mined markables and automatic linguistic in-formation.Note that we did not include all six languages:we excluded Italian and Dutch because there isno gold-standard linguistic annotation provided.The results of the experiment are shown in Table2.
From those results, we can conclude that theS Lang.
IM CEAF MUC B3BLANC1Spanish 85.8 52.3 12.8 60.0 56.9Catalan 85.5 56.0 11.6 59.4 51.9English 96.1 68.7 17.9 74.9 52.7German 93.6 70.0 19.7 73.4 64.52Spanish 61.0 41.5 11.3 42.4 48.7Catalan 60.8 40.5 9.6 41.4 48.3English 72.1 54.1 11.6 57.3 50.3German 57.7 45.5 12.2 45.7 44.33Spanish 61.2 41.8 10.3 42.3 48.5Catalan 61.3 40.9 11.3 41.9 48.5English 71.9 54.7 13.3 57.4 50.3German 57.5 45.4 12.0 45.6 44.2Table 2: Experiment results (as F1 scores) whereIM is identification of mentions and S - Setting.figures in Setting 2 and 3 are very similar.
Thismeans that the deterioration from gold to automat-ically annotated linguistic information is barelyvisible in the coreference results.
This is a greatadvantage, since gold-standard data has alwaysproved to be very expensive and difficult or im-possible to obtain.
The information that proved tobe extremely important for the performance of thesystem is the one providing the boundaries of themarkables.
As shown in Table 2, the latter leads toan improvement of about 20%, which is observ-able in the difference in the figures of Setting 1and 2.
The results for the different languages showthat it is more important to improve markable de-tection than the linguistic information.2.4 PostprocessingIn Section 2.1, we described that we decided toseparate the task of finding heads of markablesfrom the identification of the scope of a markable.Thus, in the postprocessing step, we perform thelatter (by the Markables Extractor module) as wellas reformat the data for evaluation.Another very important step during postpro-cessing is the selection of possible antecedents.
Incases where more than one mention pair is classi-fied as coreferent, only the pair with highest con-fidence by TiMBL is selected.
Since nouns canbe discourse-new, they do not necessarily have acoreferent antecedent; pronouns however, requirean antecedent.
Thus, in cases where all possibleantecedents for a given pronoun are classified asnot coreferent, we select the closest subject as an-tecedent; or if this heuristic is not successful, theantecedent that has been classified as not corefer-ent with the lowest confidence score (i.e.
the high-est distance) by TiMBL.98Lang.
S IM CEAF MUC B3BLANCCatalan G 84.4 52.3 11.7 58.8 52.2R 59.6 38.4 8.6 40.9 47.8English G 95.9 65.7 20.5 74.8 54.0R 74.2 53.6 14.2 58.7 51.0German G 94.0 68.2 21.9 75.7 64.5R 57.6 44.8 10.4 46.6 48.0Spanish G 83.6 51.7 12.7 58.3 54.3R 60.0 39.4 10.0 41.6 48.4Italian R 40.6 32.9 3.6 34.8 37.2Dutch R 34.7 17.0 8.3 17.0 32.3Table 3: Final system results (as F1 scores) whereIM is identification of mentions and S - Setting.For more details cf.
(Recasens et al, 2010).3 ResultsUBIU participated in the closed task (i.e.
only in-formation provided in the data sets could be used),in the gold and regular setting.
It was one of twosystems that submitted results for all languages,which we count as preliminary confirmation thatour system is language independent.
The final re-sults of UBIU are shown in Table 3.
The figuresfor the identification of mentions show that this isan area in which the system needs to be improved.The errors in the gold setting result from an in-compatibility of our two-stage markable annota-tion with the gold setting.
We are planning to usea classifier for mention identification in the future.The results for coreference detection show thatEnglish has a higher accuracy than all the otherlanguages.
We assume that this is a consequenceof using a feature set that was developed for En-glish (Rahman and Ng, 2009).
This also meansthat an optimization of the feature set for individ-ual languages should result in improved systemperformance.4 Conclusion and Future WorkWe have presented UBIU, a coreference resolutionsystem that is language independent (given differ-ent linguistic annotations for languages).
UBIUis easy to maintain, and it allows the inclusion ofnew languages with minimal effort.For the future, we are planning to improve thesystem while strictly adhering to the language in-dependence.
We are planning to separate pronounand definite noun classification, with the possibil-ity of using different feature sets.
We will alsoinvestigate language independent features and im-plement a markable classifier and a negative in-stance sampling module.ReferencesWalter Daelemans and Antal van den Bosch.
2005.Memory Based Language Processing.
CambridgeUniversity Press.Walter Daelemans, Jakub Zavrel, Ko van der Sloot, andAntal van den Bosch.
2007.
TiMBL: Tilburg mem-ory based learner ?
version 6.1 ?
reference guide.Technical Report ILK 07-07, Induction of Linguis-tic Knowledge, Computational Linguistics, TilburgUniversity.Sanda M. Harabagiu and Steven J. Maiorano.
2000.Multilingual coreference resolution.
In Proceedingsof ANLP 2000, Seattle, WA.Sandra K?ubler, Ryan McDonald, and Joakim Nivre.2009.
Dependency Parsing.
Morgan Claypool.Xiaoqiang Luo and Imed Zitouni.
2005.
Multi-lingual coreference resolution with syntactic fea-tures.
In Proceedings of HLT/EMNLP 2005, Van-couver, Canada.Katja Markert and Malvina Nissim.
2005.
Comparingknowledge sources for nominal anaphora resolution.Computational Linguistics, 31(3).Ruslan Mitkov.
1998.
Robust pronoun resolu-tion with limited knowledge.
In Proceedings ofACL/COLING 1998, Montreal, Canada.Ruslan Mitkov.
1999.
Multilingual anaphora resolu-tion.
Machine Translation, 14(3-4):281?299.Vincent Ng and Claire Cardie.
2002.
Improvingmachine learning approaches to coreference resolu-tion.
In Proceedings of ACL 2002, pages 104?111,Philadelphia, PA.Massimo Poesio, Tomonori Ishikawa, SabineSchulte im Walde, and Renata Vieira.
2002.Acquiring lexical knowledge for anaphora resolu-tion.
In Proceedings of LREC 2002, Las Palmas,Gran Canaria.Altaf Rahman and Vincent Ng.
2009.
Supervised mod-els for coreference resolution.
In Proceedings ofEMNLP 2009, Singapore.Marta Recasens, Llu?
?s M`arquez, Emili Sapena,M.Ant`onia Mart?
?, Mariona Taul?e, V?eronique Hoste,Massimo Poesio, and Yannick Versley.
2010.Semeval-2010 task 1: Coreference resolution inmultiple languages.
In Proceedings of the 5thInternational Workshop on Semantic Evaluations(SemEval-2010), Uppsala, Sweden.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Holger Wunsch.
2009.
Rule-Based and Memory-Based Pronoun Resolution for German: A Compar-ison and Assessment of Data Sources.
Ph.D. thesis,Universit?at T?ubingen.99
