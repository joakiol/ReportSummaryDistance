2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 543?547,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsTuning as Linear RegressionMarzieh Bazrafshan, Tagyoung Chung and Daniel GildeaDepartment of Computer ScienceUniversity of RochesterRochester, NY 14627AbstractWe propose a tuning method for statistical ma-chine translation, based on the pairwise rank-ing approach.
Hopkins and May (2011) pre-sented a method that uses a binary classifier.In this work, we use linear regression andshow that our approach is as effective as us-ing a binary classifier and converges faster.1 IntroductionSince its introduction, the minimum error rate train-ing (MERT) (Och, 2003) method has been the mostpopular method used for parameter tuning in ma-chine translation.
Although MERT has nice proper-ties such as simplicity, effectiveness and speed, it isknown to not scale well for systems with large num-bers of features.
One alternative that has been usedfor large numbers of features is the Margin InfusedRelaxed Algorithm (MIRA) (Chiang et al, 2008).MIRA works well with a large number of features,but the optimization problem is much more compli-cated than MERT.
MIRA also involves some modi-fications to the decoder itself to produce hypotheseswith high scores against gold translations.Hopkins and May (2011) introduced the methodof pairwise ranking optimization (PRO), which caststhe problem of tuning as a ranking problem be-tween pairs of translation candidates.
The problemis solved by doing a binary classification between?correctly ordered?
and ?incorrectly ordered?
pairs.Hopkins and May (2011) use the maximum entropyclassifier MegaM (Daume?
III, 2004) to do the binaryclassification.
Their method compares well to theresults of MERT, scales better for high dimensionalfeature spaces, and is simpler than MIRA.In this paper, we use the same idea for tuning, but,instead of using a classifier, we use linear regression.Linear regression is simpler than maximum entropybased methods.
The most complex computation thatit needs is a matrix inversion, whereas maximum en-tropy based classifiers use iterative numerical opti-mization methods.We implemented a parameter tuning programwith linear regression and compared the results toPRO?s results.
The results of our experiments arecomparable to PRO, and in many cases (also on av-erage) we get a better maximum BLEU score.
Wealso observed that on average, our method reachesthe maximum BLEU score in a smaller number ofiterations.The contributions of this paper include: First, weshow that linear regression tuning is an effectivemethod for tuning, and it is comparable to tuningwith a binary maximum entropy classifier.
Second,we show linear regression is faster in terms of thenumber of iterations it needs to reach the best re-sults.2 Tuning as RankingThe parameter tuning problem in machine transla-tion is finding the feature weights of a linear trans-lation model that maximize the scores of the candi-date translations measured against reference transla-tions.
Hopkins and May (2011) introduce a tuningmethod based on ranking the candidate translationpairs, where the goal is to learn how to rank pairs ofcandidate translations using a gold scoring function.543PRO casts the tuning problem as the problem ofranking pairs of sentences.
This method iterativelygenerates lists of ?k-best?
candidate translations foreach sentence, and tunes the weight vector for thosecandidates.
MERT finds the weight vector that max-imizes the score for the highest scored candidatetranslations.
In contrast, PRO finds the weight vec-tor which classifies pairs of candidate translationsinto ?correctly ordered?
and ?incorrectly ordered,?based on the gold scoring function.
While MERTonly considers the highest scored candidate to tunethe weights, PRO uses the entire k-best list to learnthe ranking between the pairs, which can help pre-vent overfitting.Let g(e) be a scoring function that maps eachtranslation candidate e to a number (score) using aset of reference translations.
The most commonlyused gold scoring function in machine translationis the BLEU score, which is calculated for the en-tire corpus, rather than for individual sentences.
Touse BLEU as our gold scoring function, we need tomodify it to make it decomposable for single sen-tences.
One way to do this is to use a variation ofBLEU called BLEU+1 (Lin and Och, 2004), whichis a smoothed version of the BLEU score.We assume that our machine translation systemscores translations by using a scoring function whichis a linear combination of the features:h(e) = wTx(e) (1)where w is the weight vector and x is the feature vec-tor.
The goal of tuning as ranking is learning weightssuch that for every two candidate translations e1 ande2, the following inequality holds:g(e1) > g(e2) ?
h(e1) > h(e2) (2)Using Equation 1, we can rewrite Equation 2:g(e1) > g(e2) ?
wT(x(e1) ?
x(e2)) > 0 (3)This problem can be viewed as a binary classifica-tion problem for learning w, where each data point isthe difference vector between the feature vectors ofa pair of translation candidates, and the target of thepoint is the sign of the difference between their goldscores (BLEU+1).
PRO uses the MegaM classifierto solve this problem.
MegaM is a binary maximumentropy classifier which returns the weight vectorw as a linear classifier.
Using this method, Hop-kins and May (2011) tuned the weight vectors forvarious translation systems.
The results were closeto MERT?s and MIRA?s results in terms of BLEUscore, and the method was shown to scale well tohigh dimensional feature spaces.3 Linear Regression TuningIn this paper, we use the same idea as PRO for tun-ing, but instead of using a maximum entropy clas-sifier, we use a simple linear regression to estimatethe vector w in Equation 3.
We use the least squaresmethod to estimate the linear regression.
For a ma-trix of data points X, and a target vector g, theweight vector can be calculated as:w = (XTX)?1XTg (4)Adding L2 regularization with parameter ?
has thefollowing closed form solution:w = (XTX + ?I)?1XTg (5)Following the sampling method used in PRO, thematrices X and vector g are prepared as follows:For each sentence,1.
Generate a list containing the k best transla-tions of the sentence, with each translation escored by the decoder using a function of theform h(e) = wTx(e).2.
Use the uniform distribution to sample n ran-dom pairs from the set of candidate transla-tions.3.
Calculate the gold scores g for the candidates ineach pair using BLEU+1.
Keep a pair of can-didates as a potential pair if the difference be-tween their g scores is bigger than a thresholdt.4.
From the potential pairs kept in the previousstep, keep the s pairs that have the highest dif-ferences in g and discard the rest.5.
For each pair e1 and e2 kept in step 4, make twodata points (x(e1)?
x(e2), g(e1)?
g(e2)) and(x(e2) ?
x(e1), g(e2) ?
g(e1)).544The rows of X consist of the inputs of the data pointscreated in step 5, i.e., the difference vectors x(e1)?x(e2).
Similarly, the corresponding rows in g arethe outputs of the data points, i.e., the gold scoredifferences g(e1) ?
g(e2).One important difference between the linear re-gression method and PRO is that rather than usingthe signs of the gold score differences and doing abinary classification, we use the differences of thegold scores directly, which allows us to use the in-formation about the magnitude of the differences.4 Experiments4.1 SetupWe used a Chinese-English parallel corpus with theEnglish side parsed for our experiments.
The cor-pus consists of 250K sentence pairs, which is 6.3Mwords on the English side.
The corpus derives fromnewswire texts available from LDC.1 We used a 392-sentence development set with four references forparameter tuning, and a 428-sentence test set withfour references for testing.
They are drawn from thenewswire portion of NIST evaluations (2004, 2005,2006).
The development set and the test set onlyhad sentences with less than 30 words for decodingspeed.We extracted a general SCFG (GHKM) grammarusing standard methods (Galley et al, 2004; Wanget al, 2010) from the parallel corpus with a mod-ification to preclude any unary rules (Chung et al,2011).
All rules over scope 3 are pruned (Hopkinsand Langmead, 2010).
A set of nine standard fea-tures was used for the experiments, which includesglobally normalized count of rules, lexical weight-ing (Koehn et al, 2003), and length penalty.
Ourin-house decoder was used for experiments with atrigram language model.
The decoder is capableof both CNF parsing and Earley-style parsing withcube-pruning (Chiang, 2007).We implemented linear regression tuning using1We randomly sampled our data from various differ-ent sources (LDC2006E86, LDC2006E93, LDC2002E18,LDC2002L27, LDC2003E07, LDC2003E14, LDC2004T08,LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E26,LDC2005E83, LDC2006E34, LDC2006E85, LDC2006E92,LDC2006E24, LDC2006E92, LDC2006E24) The languagemodel is trained on the English side of entire data (1.65M sen-tences, which is 39.3M words.
)Average of max BLEU Max BLEUdev test dev testRegression 27.7 (0.91) 26.4 (0.82) 29.0 27.6PRO 26.9 (1.05) 25.6 (0.84) 28.0 27.2Table 1: Average of maximum BLEU scores of the ex-periments and the maximum BLEU score from the ex-periments.
Numbers in the parentheses indicate standardof deviations of maximum BLEU scores.the method explained in Section 3.
Following Hop-kins and May (2011), we used the following param-eters for the sampling task: For each sentence, thedecoder generates the 1500 best candidate transla-tions (k = 1500), and the sampler samples 5000pairs (n = 5000).
Each pair is kept as a potentialdata point if their BLEU+1 score difference is big-ger than 0.05 (t = 0.05).
Finally, for each sentence,the sampler keeps the 50 pairs with the highest dif-ference in BLEU+1 (s = 50) and generates two datapoints for each pair.4.2 ResultsWe ran eight experiments with random initial weightvectors and ran each experiment for 25 iterations.Similar to what PRO does, in each iteration, we lin-early interpolate the weight vector learned by the re-gression (w) with the weight vector of the previousiteration (wt?1) using a factor of 0.1:wt = 0.1 ?
w + 0.9 ?
wt?1 (6)For the sake of comparison, we also implementedPRO with exactly the same parameters, and ran itwith the same initial weight vectors.For each initial weight vector, we selected the iter-ation at which the BLEU score on the developmentset is highest, and then decoded using this weightvector on the test set.
The results of our experi-ments are presented in Table 1.
In the first column,we show the average over the eight initial weightvectors of the BLEU score achieved, while in thesecond column we show the results from the ini-tial weight vector with the highest BLEU score onthe development set.
Thus, while the second col-umn corresponds to a tuning process where the sin-gle best result is retained, the first column shows theexpected behavior of the procedure on a single ini-tial weight vector.
The linear regression method has5451214161820222426280  5  10  15  20  25BLEUIterationreg-avgpro-avgFigure 1: Average of eight runs of regression and PRO.higher BLEU scores on both development and testdata for both the average over initial weights and themaximum over initial weights.Figure 1 shows the average of the BLEU scoreson the development set of eight runs of the experi-ments.
We observe that on average, the linear regres-sion experiments reach the maximum BLEU scorein a smaller number of iterations.
On average, linearregression reached the maximum BLEU score after14 iterations and PRO reached the maximum BLEUscore after 20 iterations.
One iteration took severalminutes for both of the algorithms.
The largest por-tion of this time is spent on decoding the develop-ment set and reading in the k-best list.
The samplingphase, which includes performing linear regressionor running MegaM, takes a negligible amount oftime compared to the rest of the operations.We experimented with adding L2 regularizationto linear regression.
As expected, the experimentswith regularization produced lower variance amongthe different experiments in terms of the BLEUscore, and the resulting set of the parameters had asmaller norm.
However, because of the small num-ber of features used in our experiments, regulariza-tion was not necessary to control overfitting.5 DiscussionWe applied the idea of tuning as ranking and modi-fied it to use linear regression instead of binary clas-sification.
The results of our experiments show thattuning as linear regression is as effective as PRO,and on average it reaches a better BLEU score in afewer number of iterations.In comparison with MERT, PRO and linear re-gression are different in the sense that the latter twoapproaches take into account rankings of the k-bestlist, whereas MERT is only concerned with separat-ing the top 1-best sentence from the rest of the k-best list.
PRO and linear regression are similar inthe sense that both are concerned with ranking thek-best list.
Their difference lies in the fact that PROonly uses the information on the relative rankingsand uses binary classification to rank the points; onthe contrary, linear regression directly uses the infor-mation on the magnitude of the differences.
This dif-ference between PRO and linear regression explainswhy linear regression converges faster and also mayexplain the fact that linear regression achieves asomewhat higher BLEU score.
In this sense, lin-ear regression is also similar to MIRA since MIRA?sloss function also uses the information on the magni-tude of score difference.
However, the optimizationproblem for linear regression is simpler, does not re-quire any changes to the decoder, and therefore thefamiliar MERT framework can be kept.Acknowledgments We thank the anonymous re-viewers for their helpful comments.
This work wassupported by NSF grant IIS-0910611.ReferencesDavid Chiang, Yuval Marton, and Philip Resnik.
2008.Online large-margin training of syntactic and struc-tural translation features.
In Conference on EmpiricalMethods in Natural Language Processing (EMNLP-08).David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Tagyoung Chung, Licheng Fang, and Daniel Gildea.2011.
Issues concerning decoding with synchronouscontext-free grammar.
In Proceedings of the ACL2011 Conference Short Papers, Portland, Oregon.
As-sociation for Computational Linguistics.Hal Daume?
III.
2004.
Notes on CG and LM-BFGS opti-mization of logistic regression.
August.Michel Galley, Mark Hopkins, Kevin Knight, and DanielMarcu.
2004.
What?s in a translation rule?
In Pro-ceedings of the 2004 Meeting of the North Americanchapter of the Association for Computational Linguis-tics (NAACL-04), pages 273?280, Boston.Mark Hopkins and Greg Langmead.
2010.
SCFG decod-ing without binarization.
In Proceedings of the 2010546Conference on Empirical Methods in Natural Lan-guage Processing, pages 646?655, Cambridge, MA,October.
Association for Computational Linguistics.Mark Hopkins and Jonathan May.
2011.
Tuning as rank-ing.
In Proceedings of the 2011 Conference on Empir-ical Methods in Natural Language Processing, pages1352?1362, Edinburgh, Scotland, UK., July.
Associa-tion for Computational Linguistics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of the 2003 Meeting of the North American chap-ter of the Association for Computational Linguistics(NAACL-03), Edmonton, Alberta.Chin-Yew Lin and Franz Josef Och.
2004.
Orange: amethod for evaluating automatic evaluation metrics formachine translation.
In Proceedings of Coling 2004,pages 501?507, Geneva, Switzerland, Aug 23?Aug27.
COLING.Franz Josef Och.
2003.
Minimum error rate training forstatistical machine translation.
In Proceedings of the41th Annual Conference of the Association for Com-putational Linguistics (ACL-03).Wei Wang, Jonathan May, Kevin Knight, and DanielMarcu.
2010.
Re-structuring, re-labeling, and re-aligning for syntax-based machine translation.
Com-putational Linguistics, 36:247?277, June.547
