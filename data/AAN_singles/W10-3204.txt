Proceedings of the 8th Workshop on Asian Language Resources, pages 22?29,Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language ProcessingSequential Tagging of Semantic Roles on Chinese FrameNetJihong LIComputer CenterShanxi Universitylijh@sxu.edu.cnRuibo WANG, Yahui GAOComputer CenterShanxi University{wangruibo,gaoyahui}@sxu.edu.cnAbstractIn this paper, semantic role labeling(SRL)on Chinese FrameNet is divided into thesubtasks of boundary identification(BI)and semantic role classification(SRC).These subtasks are regarded as the se-quential tagging problem at the wordlevel, respectively.
We use the conditionalrandom fields(CRFs) model to train andtest on a two-fold cross-validation dataset.
The extracted features include 11word-level and 15 shallow syntactic fea-tures derived from automatic base chunkparsing.
We use the orthogonal array ofstatistics to arrange the experiment so thatthe best feature template is selected.
Theexperimental results show that given thetarget word within a sentence, the bestF-measures of SRL can achieve 60.42%.For the BI and SRC subtasks, the best F-measures are 70.55 and 81%, respectively.The statistical t-test shows that the im-provement of our SRL model is not signif-icant after appending the base chunk fea-tures.1 IntroductionSemantic parsing is important in natural lan-guage processing, and it has attracted an increas-ing number of studies in recent years.
Cur-rently, its most important aspect is the formaliza-tion of the proposition meaning of one sentencethrough the semantic role labeling.
Therefore,many large human-annotated corpora have beenconstructed to support related research, such asFrameNet (Baker et al, 1998), PropBank (Kings-bury and Palmer, 2002), NomBank (Meyers et al,2004), and so on.
On this basis, several interna-tional semantic evaluations have been organized,which include Senseval 3 (Litkowski, 2004),SemEval 2007 (Baker,et al, 2007), CoNLL2008 (Surdeanu et al, 2008), CoNLL 2009 (Hajicet al, 2009), and so on.The first SRL model on FrameNet was pro-posed by Gildea and Jurafsky(2002).
The modelconsists of two subtasks of boundary identifica-tion(BI) and semantic role classification(SRC).Both subtasks were implemented on the pretreat-ment results of the full parsing tree.
Many lex-ical and syntactic features were extracted to im-prove the accuracy of the model.
On the test dataof FrameNet, the system achieved 65% precisionand 61% recall.Most works on SRL followed Gildea?s frame-work of processing the SRL task on EnglishFrameNet and PropBank.
They built their modelon the full parse tree and selected features usingvarious machine learning methods to improve theaccuracy of SRL models.
Many attempts havemade significant progress, ssuch as the works ofPradhan et al (2005), Surdeanu et al (2007),and so on.
Other researchers regarded the taskof SRL as a sequential tagging problem and em-ployed the shallow chunking technique to solve it,as described by Marquez at al.
(2008).Although the SRL model based on a full parsetree has good performance in English, this methodof processing is not available in other languages,especially in Chinese.
A systemic study of Chi-nese SRL was done by Xue et al (2008).
Likethe English SRL procedure, he removed many22uncorrelated constituents of a parse tree and re-lied on the remainder to identify the semanticroles using the maximum entropy model.
Whenhuman-corrected parse is used, the F-measureson the PropBank and NomBank achieve 92.0 and69.6%, respectively.
However, when automaticfull parse is used, the F-measures only achieve71.9 and 60.4%, respectively.
This significant de-crease prompts us to analyze its causes and to finda potential solution.First, the Chinese human-annotated resourcesof semantic roles are relatively small.
Sun andGildea only studied the SRL of 10 Chinese verbsand extracted 1,138 sentences in the Chinese TreeBank.
The size of the Chinese PropBank andChinese NomBank used in the paper of Xue issignificantly smaller than the ones used in En-glish language studies.
Moreover, more verbs ex-ist in Chinese than in English, which increases thesparsity of Chinese Semantic Role data resources.The same problem also exists in our experiment.The current corpus of Chinese FrameNet includesabout 18,322 human-annotated sentences of 1,671target words.
There is only an average of less than10 sentences for every target word.
To reduce theinfluence of the data sparsity, we adopt a two-foldcross validation technique for train and test label-ing.Second, because of the lack of morphologicalclues in Chinese, the accuracy of a state-of-the-artparsing system significantly decreases when usedfor a realistic scenario.
In the preliminary stageof building an SRL model of CFN, we employeda Stanford full parser to parse all sentences in thecorpus and adopted the traditional SRL techniqueon our data set.
However, the experiment resultwas insignificant.
Only 76.48% of the semanticroles in the data set have a constituent with thesame text span in the parse tree, and the F-measureof BI can only achieves 54%.
Therefore, we at-tempted to use another processing technique forSRL on CFN.
We formalized SRL on CFN into asequential tagging problem at the word level.
Wefirst extracted 11 word features into the baselinemodel.
Then we added 15 additional base chunkfeatures into the SRL model.In this paper, the SRL task of CFN comprisestwo subtasks: BI and SRC.
These are regarded asa sequential tagging problem at the word level.Conditional random fields(CRFs) model is em-ployed to train the model and predict the resultof the unlabeled sentence.
To improve the accu-racy of the model, base chunk features are intro-duced, and the feature selection method involvingan orthogonal array is adopted.
The experimen-tal results illustrate that the F-measure of our SRLmodel achieves 60.42%.
This is the best SRL re-sult of CFN so far.The paper is organized as follows.
In Section2, we describe the situation of CFN and introduceSRL on CFN.
In Section 3, we propose our SRLmodel in detail.
In Section 4, the candidate featureset is proposed, and the orthogonal-array-basedfeature selection method is introduced.
In Sec-tion 5, we describe the experimental setup usedthroughout this paper.
In Section 6, we list ourexperimental results and provide detailed analy-sis.
The conclusions and several further directionsare given at the end of this paper.2 CFN and Its SRL taskChinese FrameNet(CFN) (You et al, 2005) is a re-search project that has been developed by ShanxiUniversity, creating an FN-styled lexicon for Chi-nese, based on the theory of Frame Semantics(Fillmore, 1982) and supported by corpus evi-dence.
The results of the CFN project include alexical resource, called the CFN database, and as-sociated software tools.
Many natural languageprocessing(NLP) applications, such as Informa-tion Retrieval and Machine Translation, will ben-efit from this resource.
In FN, the semantic rolesof a predicate are called the frame elements of aframe.
A frame has different frame elements.
Agroup of lexical units (LUs) that evokes the sameframe share the same names of frame elements.The CFN project currently contains more than1,671 LUs, more than 219 semantic frames, andhas exemplified more than 18,322 annotated sen-tences.
In addition to correct segmentation andpart of speech, every sentence in the database ismarked up to exemplify the semantic and syntac-tic information of the target word.
Each annotatedsentence contains only one target word.(a).
<medium-np-subj ?
1/m ?/q > <tgt=??????/v><msg-np-obj??/n?/c??/n23?
?/n >?/wThe CFN Corpus is currently at an early stage,and the available CFN resource is relatively lim-ited, so the SRL task on CFN is described as fol-lows.
Given a Chinese sentence, a target word,and its frame, we identify the boundaries of theframe elements within the sentence and label themwith the appropriate frame element name.
This isthe same as the task in Senseval-3.3 Shallow SRL ModelsThis section proposes our SRL model architec-ture, and describes the stages of our model in de-tail.3.1 SRL Model ArchitectureA family of SRL models can be constructed usingonly shallow syntactic information as the input.The main differences of the models in this familymainly focus on the following two aspects.i) model strategy: whether to combine the sub-tasks of BI and SRC?ii) tagging unit: which is used as the taggingunit, word or chunk.The one-stage and two-stage models are twopopular strategies used in SRL tasks, as describedby Sui et al (2009).
The word and the chunk areregarded as the two different tagging units of theSRL task.In our SRL model, we consider BI and SRC astwo stages, and the word is always used as the tag-ging unit.
The detailed formalization is addressedin the following subsections.3.2 BIThe aim of the BI stage is to identify all wordspans of the semantic roles in one Chinese sen-tence.
It can be regarded as a sequential taggingproblem.
Using the IOB2 strategy (Erik et al,1999), we use the tag set {B,I,O} to tag all words,where tag ?B?
represents the beginning word of achunk, ?I?
denotes other tokens in the chunk, and?O?
is the tag of all tokens outside any chunks.Therefore, the example sentence (a) can be repre-sented as follows:(b).
?
1|B ?
|I ??
|O ??
|B ?
|I ??
|I??
|I ?|OTo avoid the problem of data sparsity, we use allsentences in our train data set to train the model ofBI.3.3 SRCAfter predicting the boundaries of semantic rolechunks in a sentence, the proper semantic roletypes should be assigned in the SRC step.
Al-though it can be easily modeled as a classificationproblem, we regarded it as a sequential taggingproblem at the word level.
An additional con-straint is employed in this step: the boundary tagsof the predicting sequence of this stage should beconsistent with the the output of the BI stage.One intuitive reason for this model strategy isthat the SRC step can use the same feature set asBI, and it can further prove the rationality of ourfeature optimization method.3.4 PostprocessingNot all predicted IOB2 sequences can be trans-formed to the original sentence correctly; there-fore, they should satisfy the following compulsoryconstraints.
(1) The tagging sequence should be regular.?I...
?, ?...
OI...?, ?I-X...?, ?...
O-I-X...?, ?...
B-X-I-Y...?, and ?B-I-X-I-X-I-Y...?
are not the regularIOB2 sequences.
(2) The tag for the target word must be ?O?.We use the Algorithm 1 to justify whether theIOB2 sequences are regular.Moreover, at the SRC stage, the boundary tagsof the IOB2 sequence must be consistent with thegiven boundary tags.For the BI stage, we firstly add an additionalchunk type tag X to all ?B?
and ?I?
tags in theIOB2 sequences, and then use Algorithm 1 to jus-tify the regularity of the sequences.In the testing stage of the SRL model, we usethe regular sequence with the max probability asthe optimal output.24Algorithm 1. justify the regular IOB2 sequenceInput: (1) IOB2 sequence:S = (s1, .., sn)where si ?
{B ?X, I ?X,O}, and 1 ?
i ?
n(2) The position of target word in sentence pt1, Initialization:(1) Current chunk type: ct = NULL;(2) Regularity of sequence: state =?
REG?
;2, Check the tag of target word: spt:(1) If spt ==?
O?
: go to Step 3;(2) If spt <>?
O?
: state =?
IRR?, and go to Step 4;3,For(i = 1; i ?
n; i + +)(1) If si ==?
B ?X ?
: ct =?
X ?
;(2) If si ==?
I ?X ?
and ct <>?
X ?
: state =?
IRR?,and go to Step 4;(3) If si ==?
O?
: ct = NULL;4, StopOutput: Variable state;3.5 Why Word-by-word?We ever tried to use the methods of constituent-by-constituent and chunk-by-chunk to solve ourSRL task on CFN, but the experiment results il-lustrate that they are not suitable to our task.We use the Stanford Chinese full parser to parseall sentences in the CFN corpus and use the SRLmodel proposed by Xue et al(2008) in our task.However, the results is insignificant.
Only 66.72%of semantic roles are aligned with the constituentsof the full parse tree, and the F-measure of BI onlyachieves 52.43%.
The accuracy of the state-of-the-art Chinese full parser is not high enough, soit is not suitable to our SRL task.Chunk-by-chunk is another choice for our task.When We use base chunk as the tagging unit ofour model, only about 15% of semantic roles didnot align very well with the boundary of automati-cally generated base chunks, and the F-measure issignificantly lower than the method of word-by-word, as described by Wang et al(2009).Therefore, words are chosen as the tagging unitof our SRL model, which showed significant re-sults from the experiment.4 Feature Selection and OptimizationWord-level features and base-chunk features areused in our SRL research.Base chunk is a Chinese shallow parsingscheme proposed by Professor Zhou.
He con-structed a high accuracy rule-based Chinese basechunk parse (Zhou, 2009), the F-measure ofwhich can achieve 89%.
We use this parse to gen-erate all base chunks of the sentences in our cor-pus and to extract several types of features fromthem.
The automatically generated base chunksof example sentences (a) are given as follows:(c).[mp-ZX?
1/m?/q ] [vp-SG?
?/v ] [np-SG?
?/n ]?/c [np-AM??/n?
?/n ]?/w4.1 Candidate Feature SetThree types of features are given as follows:Features at the word level:Word: The current token itself;Part-of-Speech: The part of speech of the cur-rent token;Position: The position of the current word rela-tive to the target word(before, after, or on);Target word: The target word in the sentence;Features at the base chunk level:Syntactic label: The syntactic label of the cur-rent token, such as, B-np,I-vp, etc;Structural label: The structural label of the cur-rent token, such as, B-SG, I-ZX, etc;Head word and its Part of Speech: The headword and its part of speech of the base chunk;Shallow syntactic path: The combination ofthe syntactic tags from the source base chunk,which contains the current word, to the target basechunk, which contains the target word of the sen-tence;Subcategory: The combination of the syntactictags of the base chunk around the target word;Other Features:Named entity: The three types of named entitiesare considered: person, location, and time.
Theycan be directly mapped from the part of speech ofthe current word.Simplified sentence: A boolean feature.
We usethe punctuation count of the sentence to estimatewhether the sentence is the simplified sentence.Aside from the basic features described above,we also use combinations of these features, suchas word/POS combination, etc.4.2 Feature Optimization MethodIn the baseline model, we only introduce the fea-tures at the word level.
Table 1 shows the candi-date features of our baseline model and proposestheir optional sizes of sliding windows.For Table 1, we use the orthogonal arrayL32(49 ?
24) to conduct 32 different templates.25The best template is chosen from the highest F-measure for testing the 32 templates.
The detailedorthogonal-array-based feature selection methodwas proposed by Li et al(2010).Table 1.
Candidate features of baseline modelsFeature type Window sizeword [0,0] [-1,1] [-2,2] [-3,3]bigram of word - [-1,1] [-2,2] [-3,3]POS [0,0] [-1,1] [-2,2] [-3,3]bigram of POS - [-1,1] [-2,2] [-3,3]position [0,0] [-1,1] [-2,2] [-3,3]bigram of position - [-1,1] [-2,2] [-3,3]word/POS - [0,0] [-1,1] [-2,2]word/position - [0,0] [-1,1] [-2,2]POS/position - [0,0] [-1,1] [-2,2]trigram of position - [-2,0] [-1,1] [0,2]word/target word - [0,0]target word [0,0]Compared with the baseline model, the featuresat the word and base chunk levels are all consid-ered in Table 2.Table 2.
Candidate features of the base chunk-based modelFeature type Window sizeword [0,0] [-1,1] [-2,2]bigram of word - [-1,1] [-2,2]POS [0,0] [-1,1] [-2,2]bigram of POS - [-1,1] [-2,2]position [0,0] [-1,1] [-2,2]bigram of position - [-1,1] [-2,2]word/POS - [0,0] [-1,1]word/position - [0,0] [-1,1]POS/position - [0,0] [-1,1]trigram of position - [-2,0] [-1,1]syntactic label [0,0] [-1,1] [-2,2]syn-bigram - [-1,1] [-2,2]Syn-trigram - [-1,1] [-2,2]head word [0,0] [-1,1] [-2,2]head word-bigram - [-1,1] [-2,2]POS of Head [0,0] [-1,1] [-2,2]POS-bigram of head - [-1,1] [-2,2]syn/head word [0,0] [-1,1] [-2,2]stru/head word [0,0] [-1,1] [-2,2]shallow path - [0,0] [-1,1]subcategory - [0,0] [0,0]named Entity - [0,0] [0,0]simplified Sentence - [0,0] [0,0]target word(compulsory) [0,0]The orthogonal arrayL54(21?325) is employedto select the best feature template from all candi-date feature templates in Table 2.
To distinguishit from the baseline model, we call the modelbased on the table 2 as the ?base chunk-based SRLmodel?.For both feature sets described above, the targetword is the compulsory feature in every template,and the boundary tags are introduced as featuresduring the SRC stage.The feature templates in Table 2 cannot con-tain the best feature template selected from Table1.
This is a disadvantage of our feature selectionmethod.5 Experimental Setup and EvaluationMetrics5.1 Data SetThe experimental data set consists of all sentencesof 25 frames selected in the CFN corpus.
Thesesentences have the correct POS tags and CFN se-mantic information; they are all auto parsed bythe rule-based Chinese base chunk parser.
Table3 shows some statistics on these 25 frames.Table 3.
Summary of the experimental data setFrame FEs Sents Frame FEs Sents??
6 569 ??
7 140????
5 345 ??
10 1,603??
3 141 ??
4 170??
5 185 ???
4 70????
14 499 ??
12 198??
9 320 ??
6 90??
8 283 ??
7 80?????
13 379 ???
11 125??
9 258 ??
9 101??
8 218 ???
9 260??
12 298 ??
10 106??
6 126 ????
8 74????
5 54 Totals 200 6,6925.2 Cross-validation techniqueIn all our experiments, three groups of two-foldcross-validation sets are used to estimate the per-formance of our SRL model.
All sentences in aframe are cut four-fold on average, where everytwo folder are merged as train data, and the othertwo folds are used as test data.
Therefore, we canobtain three groups of two-fold cross-validationdata sets.Estimating the parameter of fold number isone of the most difficult problems in the cross-validation technique.
We believe that in the task ofSRL, the two-fold cross validation set is a reason-able choice, especially when the data set is relativesmall.
With a small data set, dividing it in half issplit of data set is the best approximation of thereal-world data distribution of semantic roles andthe sparse word tokens.265.3 ClassifiersCRFs model is used as the learning algorithmin our experiments.
Previous SRL research hasdemonstrated that CRFs model is one of the beststatistical algorithms for SRL, such as the worksof Cohn et al (2005) and Yu et al (2007).The crfpp toolkit1 is a good implementation ofthe CRF classifier, which contains three differenttraining algorithms: CRFL1, CRFL2, and MIRA.We only use CRFL2 with Gaussian priori regular-ization and the variance parameter C=1.0.5.4 Evaluation MetricsAs described in SRL reseach, precision, recall,and F-measure are also used as our evaluationmetrics.
In addition, the standard deviation of theF-measure is also adopted as an important metricof our SRL model.
The computation method ofthese metrics is given as follows:Let P ij , Rij and F ij be the precision, recall, andF-measure of the jth group of the ith cross valida-tion set, where j = 1, 2, 3 and i = 1, 2.
The finalprecision(P ), recall(R), and F-measure(F ) of ourSRL model are the expectation values of the P ij ,Rij , and F ij , respectively.The estimation of the variance of cross-validation is another difficult problem in thecross-validation technique.
Although it has beenproven that the uniform and unbiased estimationof the variance of cross-validation does not ex-ist (Yoshua et al, 2007), we adopted the methodproposed by Nadeau et al (2007), to estimate thevariance of the F-measure of cross-validation sets.This method is proposed hereinafter.Let Fj be the average F-measure of the j groupexperiment, that is, Fj = 12(F 1j + F 2j ), wherej = 1, 2, 3.
The proposed estimator of the vari-ance of Fj in the work of Nadeau et al (2007) isas follows:V?
ar(Fj) = (1K +n2n1)2?i=1(F ij ?
Fj)= (12 + 1)2?i=1(F ij ?
Fj)1crfpp toolkit: http://crfpp.sourceforge.net/where, K is the fold number of cross-validationand n1 and n2 are the counts of training examplesand testing examples.
In our experimental setting,K = 2 and n2n1 ?
1.
Moreover, the estimation ofthe variance of the total F-measure is as follows:V ar(F ) = V ar(13(F1 + F2 + F3))= 193?j=1V ar(Fj)Using V?
ar(Fj) to estimate V ar(Fj), we canobtain:V?
ar(F ) = 193?j=1V?
ar(Fj)= 163?j=12?i=1(F ij ?
Fj)Finally, we can derive the standard deviation ofthe F-measure, that is, std(F ) =?V?
ar(F ).5.5 Significance Test of Two SRL ModelsTo test the significance of SRL models A and B,we use the following statistics S.S = F (A)?
F (B)?V ar(F (A)) + V ar(F (B))?
t(n)where F (A) and F (B) are the F-measures ofmodels A and B, and n is the freedom degree oft-distribution, an integer nearest to the n?.n?
= 3(V ar(F (A)) + V ar(F (B)))2(V ar(F (A))2 + V ar(F (B))2)We use the p?
value(?)
to test the significanceof SRL models A and B, which are given as fol-lows:p?
value(F (A), F (B)) = P (S ?
t1?
?/2(n))If p ?
value(F (A), F (B)) ?
0.05, the differ-ence of the F-measures between models A and Bis significant at 95% level.276 Experimental Results and DiscussionWe summarized the experiment results of everystage of our SRL model, that is, BI, SRC and acombination of these two steps (BI+SRC).6.1 Baseline SRL ModelThe results of the baseline model are given in Ta-ble 4, which only uses the features in Table 1.Table 4.
Results of the baseline modelP(%) R(%) F(%) std(F)BI 74.42 66.80 70.40 0.0031SRC - - 80.32 0.0032BI+SRC 62.87 56.44 59.48 0.0050In Table 1, because the results of the SRC stageare based on human-corrected boundary informa-tion, the precision, recall, and F-measure of thisstage are the same.
Therefore, we only give theF-measure and its deviation at the SRC stage.In the baseline model, the BI stage is the bot-tleneck of our SRL model.
Its F-measure onlyachieves 70.4%, and the recall is lower than theprecision.
Moreover, the F-measure of the finalmodel only achieves 59.48%, and its standard de-viation is larger than both stages.6.2 Base chunk-based SRL ModelWhen base chunk features, proposed in Table 2,are employed in the SRL model, we can obtainthe results summarized in Table 5.Table 5.
Results of the base chunk-based modelP(%) R(%) F(%) std(F)BI 74.69 66.85 70.55 0.0038SRC - - 81.00 0.0029BI+SRC 63.97 57.25 60.42 0.0049A comparison of Table 4 and Table 5 providesthe following two conclusions.
(1) When base chunk features are used, all P, R,F at every stage slightly increase (< 1%).
(2) The significance test values between thebaseline model and the base chunk-based modelare given in Table 6.
For every stage, the perfor-mance boost after introducing the base chunk fea-tures is not significant at 95% level.
However, theimpact of base chunk features at the SRC stage islarger than that at the BI stage.Table 6.
Test values between two SRL modelsBI SRC BI+SRCp?
value 0.77 0.166 0.2287 Conclusions and Further DirectionsThe SRL of Chinese predicates is a challengingtask.
In this paper, we studied the task of SRLon the CFN.
We proposed a two-stage model andexploited the CRFs classifier to implement the au-tomatic SRL systems.
Moreover, we introducedthe base chunk features and the OA-based methodto improve the performance of our model.
Exper-imental results shows that the F-measure of ourbest model achieves 60.42%, and the base chunkfeatures cannot improve the SRL model signifi-cantly.In the future, we plan to introduce unlabeleddata into the training phase and use the EM-schemed semi-supervised learning algorithms toboost the accuracy of our SRL model.AcknowledgementThe authors would like to thank Prof. KaiyingLIU for his comments and Prof. Qiang ZHOU forthe base-chunk parser.ReferencesBaker, C., Fillmore, C., and John B.
1998.
The Berke-ley Framenet project.
In Proceedings of COLING-ACL, 86-90, Montreal, Canada.Baker, C., Ellsworth, M., Erk, K. 2007.
SemEval?07Task 19: Frame semantic structure extraction.
Pro-ceedings of the 4th International Workshop on Se-mantic Evaluations, 99-104, Prague, Czech Repub-lic.Cohn, T., Blunsom P. 2005.
Semantic role labelingwith tree conditional random fields.
Proceedings ofCoNLL 2005, ACL, 169-172.Erik F., and John V. 1999.
Representing text chunks.In Proceedings of EACL?99, 173-179.Fillmore, C. 1982.
Frame Semantics.
In The Linguis-tic Society of Korea, Seoul: Hanshin.Gildea, D., and Jurafsky, D. 2002.
Automatic label-ing for semantic roles.
Computational Linguistics,28(3):245-288.Hajic, J., Ciaramita, M., Johansson, R., Kawahara, D.,Marti, M., Ma`rquez, L., Meyers, A., Nivre, J., Pado?,S., Ste?pa?nek, J., Stranak, P., Surdeanu, M., Nian-wen X., Zhang, Y.
2009.
The CoNLL-2009 sharedtask: syntactic and semantic dependencies in multi-ple languages.
In Proceedings of CoNLL 2009, 1-18, Boulder, CO, USA..28Jihong, L., Ruibo, W., Weilin, W., and Guochen, L.2010.
Automatic Labeling of Semantic Roles onChinese FrameNet.
Journal of Software, 2010,21(4):597-611.Jiangde, Y., Xiaozhong, F., Wenbo, P., and Zhengtao,Y.
2007.
Semantic role labeling based on condi-tional random fields Journal of southeast university(English edition), 23(2):5361-364.Liping, Y., and Kaiying, L. 2005.
Building ChineseFrameNet database.
In Proceedings of IEEE NLP-KE?05 , 301-306.Litkowski, K. 2004.
Senseval-3 task automatic label-ing of semantic roles.
Third International Workshopon the Evaluation of Systems for the Semantic Anal-ysis of Text, 9-12, Barcelona, Spain.Ma`rquez, L., Carreras, X., Litkowski, K., Stevenson,S.
2008.
Semantic Role Labeling: An Introduc-tion to the Special Issue.
Computational Linguis-tics, 34(2):145-159.Meyers, A., Reeves, R., Macleod, C., Szekely, R.,Zielinska, V., Young, B., and Grishman, R. 2004.The NomBank Project: An interim report.
In Pro-ceedings of the NAACL/HLT Workshop on Frontiersin Corpus Annotation, 24-31, Boston, MA, USA.Nadeau, C., and Bengio, Y.
2003.
Inference for thegeneralization error.
Machine Learning, 52: 239-281.Nianwen, X.
2008.
Labeling Chinese Predicates withSemantic Roles.
Computational Linguistics, 2008,34(2): 225-255.Paul, K., and Martha, P. 2002.
From TreeBank toPropBank.
In Proceedings of LREC-2002, CanaryIslands, Spain.Pradhan, S., Hacioglu, K., Krugler, V., Ward, W., Mar-tin, J., Jurafsky, D. 2005.
Support vector learn-ing for semantic argument classification.
MachineLearning, 2005, 60(1):11-39.Qiang, Z.
2007.
A rule-based Chinese base chunkparser.
In Proc.
of 7th International Conferenceof Chinese Computation (ICCC-2007), 137-142,Wuhan, China.Ruibo, W. 2004.
Automatic Semantic Role Label-ing of Chinese FrameNet Based On ConditionalRandom Fields Model.
Thesis for the 2009 Mas-ter?s Degree of Shanxi University, Taiyuan, Shanxi,China.Surdeanu, M., Johansson, R., Meyers, A., Ma`rquez,L., Nivre, J.
2008.
The CoNLL 2008 shared taskon joint parsing of syntactic and semantic depen-dencies.
In Proceedings of CoNLL 2008, 159-177,Manchester, England, UK.Surdeanu, M., Ma`rquez, L., Carreras, X., Comas, P.2007.
Combination strategies for semantic role la-beling.
Journal of Artificial Intelligence Research,29:105-151.Yoshua, B., and Yves, G. 2004.
No unbiased estimatorof the variance of K-fold cross-validation Journal ofMachine Learning Research, 5:1089-1105.Weiwei, S., Zhifang, S., Meng, W., and Xing, W. 2009.Chinese semantic role labeling with shallow pars-ing.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Process-ing(EMNLP 2009), ACL, 1475-1483.29
