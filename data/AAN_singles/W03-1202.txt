Using Thematic Information in Statistical Headline GenerationStephen WanCenter for LanguageTechnologyMacquarie UniversitySydney, Australiaswan@ics.mq.edu.auMark DrasCenter for LanguageTechnologyMacquarie UniversitySydney, Australiamadras@ics.mq.edu.auC?cile ParisCSIRO Mathematicaland InformationSciencesLocked Bag 17North Ryde 1670Sydney, AustraliaCecile.Paris@csiro.auRobert DaleCenter for LanguageTechnologyMacquarie UniversitySydney, Australiardale@ics.mq.edu.auAbstractWe explore the problem of singlesentence summarisation.
In the newsdomain, such a summary mightresemble a headline.
The headlinegeneration system we present usesSingular Value Decomposition (SVD) toguide the generation of a headlinetowards the theme that best representsthe document to be summarised.
Indoing so, the intuition is that thegenerated summary will more accuratelyreflect the content of the sourcedocument.
This paper presents SVD asan alternative method to determine if aword is a suitable candidate forinclusion in the headline.
The results ofa recall based evaluation comparingthree different strategies to wordselection, indicate that thematicinformation does help improve recall.1 IntroductionOurs is an age where many documents arearchived electronically and are availablewhenever needed.
In the midst of this plethora ofinformation, the successful completion of aresearch task is affected by the ease with whichusers can quickly identify the relevant electronicdocuments that satisfy their information needs.To do so, a researcher often relies on generatedsummaries that reflect the contents of theoriginal document.We explore the problem of single sentencesummarisation, the primary focus of this paper.Instead of identifying and extracting the mostimportant sentence, we generate a new sentencefrom scratch.
The resulting sentence summarymay not occur verbatim in the source documentbut may instead be a paraphrase combining keywords and phrases from the text.As a precursor to single sentence summarisation,we first explore the particular case of headlinegeneration in the news domain, specificallyEnglish news.
Although headlines are oftenconstructed to be sensationalist, we regardheadline generation as an approximation tosingle sentence summarisation, given that acorpus of single sentence summaries does notexist.Our system re-uses words from the news articleto generate a single sentence summary thatresembles a headline.
This is done by selectingand then appending words from the sourcearticle.
This approach has been explored by anumber of researchers (eg.
see Witbrock andMittal, 1999; Jin and Hauptmann, 2002) and wewill describe their work further in the nextsection.
In existing approaches, a word isselected on the basis of two criteria: how well itacts as a summary word, and how grammatical itwill be given the preceding summary words thathave already been chosen.The purpose of this paper is to present workwhich investigates the use of Singular ValueDecomposition (SVD) as a means ofdetermining if a word is a good candidate forinclusion in the headline.To introduce the notion of using SVD for singlesentence summarisation in this paper, weexamine the simplest summarisation scenario.Thus, presently we are only concerned withsingle document summarisation.
In addition, welimit the focus of our discussion to thegeneration of generic summaries.In the remainder of this paper, we describe ourmotivation for using SVD by describingdifficulties in generating headlines in Section 2.In Section 3, as motivation for our approach, weillustrate how words can be used out of context,resulting in factually incorrect statements.Section 4 provides an overview of related work.In Section 5, we give a detailed description ofhow we generate the sentence summarystatistically and how we use SVD to guide thegeneration process.
In Section 6, we present ourexperimental design in which we evaluated ourapproach, along with the results andcorresponding discussion.
Finally, in Section 7,we present our conclusions and future work.2 The Veracity of Generated SummariesBerger and Mittal (2000) describe limitations tothe generation of headlines by recycling wordsfrom the article.
One such limitation is that theproposition expressed by the generated summaryis not guaranteed to reflect the information in thesource text.
As an example, they present twosentences of differing meaning which uses thesame words.
We present their example inExample 1, which illustrates the case in whichthe subject and object are swapped.The dog bit the postmanThe postman bit the dog.Example 1.
An example of different propositionspresented in two sentences which use the samewords.However, we believe that the veracity of thegenerated sentence, with respect to the originaldocument, is affected by a more basic problemthan variation in word order.
Because wordsfrom any part of a source document can becombined probabilistically, there is a possibilitythat words can be used together out of context.We refer to this as Out-of-Context error.
Figure1 presents an example of a generated headline inwhich the adverb wrongly reports stock pricemovement.
It also presents the actual context inwhich that adverb was used.Generated headline?singapore stocks shares rebound?
?Actual headline:?Singapore shares fall, seen higher afterholidays.
?Original context of use of ?rebound?
:?Singapore shares closed down below the2,200 level on Tuesday but were expected torebound immediately after Chinese LunarNew Year and Muslim Eid Al-Fitr holidays,dealers said.
?Figure 1.
An error in the generated headline dueto a word being re-used out of context.Out-of-Context errors arise due to limitations inthe two criteria for selecting words mentioned inSection 1.
While, for selection purposes, a wordis scored according to its goodness as candidatesummary word, word order is determined by anotion of grammaticality, modelledprobabilistically using ngrams of lexemes.However, the semantic relationship implied byprobabilistically placing two words next to eachother, for example an adjective and a noun,might be suspect.
As the name ?Out-of-Context?
suggests, this is especially true if thewords were originally used in non-contiguousand unrelated contexts.
This limitation in theword selection criteria can be characterized asbeing due to a lack of long distance relationshipinformation.3 Our Approach to ?Encouraging Truth?In response to this limitation, we explore the useof a matrix operation, Singular ValueDecomposition (SVD) to guide the selection ofwords.
Although our approach still does notguarantee factual correctness with respect to thesource document, it has the potential to alleviatethe Out-of-Context problem by improving theselection criteria of words for inclusion in thegenerated sentence, by considering the originalcontexts in which words were used.
With thisimproved criteria, we hope to "encourage truth"by incorporating long distance relationshipsbetween words.
Conceptually, SVD provides ananalysis of the data which describes therelationship between the distribution of wordsand sentences.
This analysis includes agrouping of sentences based on similar worddistributions, which correspond to what we willrefer to here as the main themes of thedocument.1  By incorporating this informationinto the word selection criteria, the generatedsentence will "gravitate" towards a single theme.That is, it will tend to use words from thattheme, reducing the chance that words areplaced together out of context.By reflecting the content of the main theme, thesummary may be informative (Borko, 1975).That is, the primary piece of information withinthe source document might be included withinthe summary.
However, it would remiss of us toclaim that this quality of the summary isguaranteed.
In general, the generated summariesare at least useful to gauge what the source textis about, a characteristic described by Borko asbeing indicative.Figure 2 presents the generated summary usingSVD for the same test article presented in Figure1.
In this case, the summary is informative asnot only are we told that the article is about astock market, but the movement in price in thisexample is correctly determined.Generated headline using SVD:?singapore shares fall?Figure 2.
The headline generated using an SVD-based word selection criterion.
The movementin share price is correct.4 Related WorkAs the focus of this paper is on statistical single-sentence summarisation we will not focus onpreceding work which generates summariesgreater in length than a sentence.
We direct thereader to Paice (1990) for an overview ofsummarisation based on sentence extraction.Examples of recent systems include Kupiec etal.
(1995) and Brandow et al (1995).
Forexamples of work in producing abstract-likesummaries, see Radev and McKeown (1998),which combines work in information extraction1Theme is a term that is used in many ways by manyresearchers, and generally without any kind of formaldefinition.
Our use of the term here is akin to thenotion that underlies work on text segmentation,where sentences naturally cluster in terms of their?aboutness?.and natural language processing.
Hybridmethods for abstract-like summarisation whichcombine statistical and symbolic approacheshave also been explored; see, for example,McKeown et al (1999), Jing and McKeown(1999), and Hovy and Lin (1997).Statistical single sentence summarisation hasbeen explored by a number of researchers (seefor example, Witbrock and Mittal, 1999; Zajic etal., 2002).
We build on the approach employedby Witbrock and Mittal (1999) which we willdescribe in more detail in Section 3.Interestingly, in the work of Witbrock and Mittal(1999), the selection of words for inclusion inthe headline is decided solely on the basis ofcorpus statistics and does not use statisticalinformation about the distribution of words inthe document itself.
Our work differs in that weutilise an SVD analysis to provide informationabout the document to be summarized,specifically its main theme.Discourse segmentation for sentence extractionsummarisation has been studied in work such asBoguraev and Neff (2000) and Gong and Liu(2001).
The motivation behind discoveringsegments in a text is that a sentence extractionsummary should choose the most representativesentence for each segment, resulting in acomprehensive summary.
In the view of Gongand Liu (2001), segments form the main themesof a document.
They present a themeinterpretation of the SVD analysis, as it is usedfor discourse segmentation, upon which our useof the technique is based.
However, Gong andLiu use SVD for creating sentence extractionsummaries, not for generating a single sentencesummary by re-using words.In subsequent work to Witbrock and Mittal(1999), Banko et al (2000) describe the use ofinformation about the position of words withinfour quarters of the source document.
Theheadline candidacy score of a word is weightedby its position in one of quarters.
We interpretthis use of position information as a means ofguiding the generation of a headline towards thecentral theme of the document, which for newsarticles typically occurs in the first quarter.SVD potentially offers a more generalmechanism for handling the discovery of thecentral themes and their positions within thedocument.Jin et al (2002) have also examined a statisticalmodel for headlines in the context of aninformation retrieval application.
Jin andHauptmann (2001) provide a comparison of avariety of learning approaches used byresearchers for modelling the content ofheadlines including the Iterative Expectation-Maximisation approach, the K-Nearestneighbours approach, a term vector approachand the approach of Witbrock and Mittal (1999).In this comparison, the approach of Witbrockand Mittal (1999) fares favourably, rankingsecond after the term vector approach to titleword retrieval (see Jin and Hauptmann, 2001,for details).
However, while it performs well,the term vector approach Jin et al (2002)advocate doesn't explicitly try to model the waya headline will usually discuss the main themeand may thus be subject to the Out-of-Contextproblem.Finally, for completeness, we mention the workof Knight and Marcu (2000), who examinesingle sentence compression.
Like Witbrockand Mittal (1999), they couch summarisation asa noisy channel problem.
Under this framework,the summary is a noise-less source ofinformation and the full text is the noisy result.However, in contrast to our approach, Knightand Marcu (2000) handle parse trees instead ofthe raw text.
Their system learns how tosimplify parse trees of sentences extracted fromthe document to be summarized, to uncover theoriginal noise-less forms.5 Generating a Single Sentence SummaryIn this section, we describe our approach tosingle sentence summarisation.
As mentionedearlier, our approach is based on that ofWitbrock and Mittal (1999).
It differs in theway we score words for inclusion in theheadline.
Section 5.1 presents our re-implementation of Witbrock and Mittal?s (1999)framework and introduces the Content Selectionstrategy they employ.
Section 5.2 describes ourextension using SVD resulting in two alternativeContent Selection strategies.5.1 Searching for a Probable HeadlineWe re-implemented the work described inWitbrock and Mittal (1999) to provide a singlesentence summarisation mechanism.
For fulldetails of their approach, we direct the reader totheir paper (Witbrock and Mittal, 1999).
A briefoverview of our implementation of theiralgorithm is presented here.Conceptually, the task is twofold.
First, thesystem must select n words from a news articlethat best reflect its content.
Second, the best(grammatical) word ordering of these n wordsmust be determined.
Witbrock and Mittal(1999) label these two tasks as Content Selectionand Realisation.
Each of these criteria arescored probabilistically, whereby the probabilityis estimated by prior collection of corpusstatistics.To estimate Content Selection probability foreach word, we use the Maximum LikelihoodEstimate (MLE).
In an offline training stage, thesystem counts the number of times a word isused in a headline, with the condition that itoccurs in the corresponding news article.
Toform the probability, this frequency data isnormalised by the number of times the word isused in articles across the whole corpus.
Thisparticular strategy of content selection, we referto this as the Conditional probability.The Realisation criterion is determined simplyby the use of bigram statistics, which are againcollected over a training corpus during thetraining stage.
The MLE of the probability ofword sequences is calculated using these bigramstatistics.
Bigrams model the grammaticality ofa word given the preceding word that hasalready been chosen.It should be noted that both the ContentSelection and Realisation criteria influencewhether a word is selected for inclusion in theheadline.
For example, a preposition mightpoorly reflect the content of a news article andscore a low Content Selection probability.However, given the context of the precedingword, it may be the only likely choice.In both the training stage and the headlinegeneration stage, the system employs the samepreprocessing.
The preprocessing, whichmirrors that used by Witbrock and Mittal (1999),replaces XML markup tags and punctuation(except apostrophes) with whitespace.
Inaddition, the remaining text is transformed intolower case to make string matching caseinsensitive.
The system performs tokenisationby using whitespace as a word delimiter.In Witbrock and Mittal?s approach (1999), theheadline generation problem reduces to findingthe most probable path through a bag of wordsprovided by the source document, essentially asearch problem.
They use the beam searchvariety of the Viterbi algorithm (Forney, 1973)to efficiently search for the headline.
In ourimplementation, we provided the path length asa parameter to this search mechanism.
Inaddition, we used a beam size of 20.To use the Viterbi algorithm to search for a path,the probability of adding a new word to anexisting path is computed by combining theContent selection probability, the Realisationprobability and the probability of the existingpath, which is recursively defined.
Combiningeach component probability is done by findingthe logs of the probabilities and adding themtogether.
The Viterbi algorithm sorts the pathsaccording to the path probabilities, directing thesearch towards the more probable wordsequences first.
The use of repeated words inthe path is not permitted.5.2 Using Singular Value Decomposition forContent SelectionAs an alternative to the Conditional probability,we examine the use of SVD in determining theContent Selection probability.
Before weoutline the procedure for basing this probabilityon SVD, we will first outline our interpretationof the SVD analysis, based on that of Gong andLiu (2001).
Our description is not intended tobe a comprehensive explanation of SVD, and wedirect the reader to Manning and Sch?tze (2000)for a description of how SVD is used ininformation retrieval.Conceptually, when used to analyse documents,SVD can discover relationships between wordco-occurrences in a collection of text.
Forexample, in the context of information retrieval,this provides one way to retrieve additionaldocuments that contain synonyms of queryterms, where synonymy is defined by similarityof word co-occurrences.
By discoveringpatterns in word co-occurrences, SVD alsoprovides information that can be used to clusterdocuments based on similarity of themes.In the context of single documentsummarisation, we require SVD to clustersentences based on similarities of themes.
TheSVD analysis provides a number of relatedpieces of information relating to how words andsentences relate to these themes.
One such pieceof information is a matrix of scores, indicatinghow representative the sentence is of eachtheme.
Thus, for a sentence extractionsummary, Gong and Liu (2001) would pick thetop n themes, and for each of these themes, usethis matrix to choose the sentence that bestrepresents it.For single sentence summarisation, we assumethat the theme of the generated headline willmatch the most important theme of the article.The SVD analysis orders its presentation ofthemes starting with the one that accounts forthe greatest variation between sentences.
TheSVD analysis provides another matrix whichscores how well each word relates to eachtheme.
Given a theme, scores for each word,contained in a column vector of the matrix, canthen normalised to form a probability.
Theremainder of this section provides a moretechnical description of how this is done.To begin with, we segment a text into sentences.Our sentence segmentation preprocessing isquite simple and based on the heuristics found inManning and Sch?tze (2000).
After removingstopwords, we then form a terms by sentencesmatrix, A.
Each column of A represents asentence.
Each row represents the usage of aword in various sentences.
Thus the frequencyof word t in sentence s is stored in the cell  Ats.This gives us an t * s matrix, where t ?
s.  Thatis, we expect the lexicon size of a particularnews article to exceed the number of sentences.For such a matrix, the SVD of A is a processthat provides the right hand side of the followingequation:A = U.S. Vtransposewhere U is  a t * r matrix, S is an r * r matrix,and V is an s * r matrix.
The dimension size r isthe rank of A, and is less than or equal to thenumber of columns of A, in this case, s.    Thematrix S is a diagonal matrix with interestingproperties, the most important of which is thatthe diagonal is sorted by size.
The diagonalvalues indicate the variation across sentences fora particular theme, where each theme isrepresented by a separate diagonal element.
Thematrix V indicates how representative a sentenceis of a score.
Similarly the matrix U indicateshow related to the themes each word is.
Adiagram of this is presented in Figure 3.Before describing how we use each of thesematrices, it is useful to outline what SVD isdoing geometrically.
Each sentence, a columnin the matrix A, can be thought of as an object int dimensional space.
SVD uncovers therelations between dimensions.
For example, inthe case of text analysis, it would discoverrelationships between words such as synonyms.In a trivial extreme of this case where twosentences differ only by a synonym, SVD wouldideally discover that the two synonyms havevery similar word co-occurrences.
In theanalysis matrices of U, S and V, the redundantdimensions corresponding to these highlysimilar words might be removed, resulting in areduced number of dimensions, r, required torepresent the sentences.Figure 3.
A diagram of our interpretation of theSVD matrices as it relates to single sentencesummarisation.Of the resulting matrices, V is an indication ofhow each sentence relates to each theme,indicated by a score.
Thus, following Gong andLiu (2001), a plausible candidate for the mostimportant sentence is found by taking the firstcolumn vector of V (which has s elements), andfinding the element with the highest value.
Thissentence will be the one which is mostrepresentative of the theme.
The index of thatelement is the index of the sentence to extract.However, our aim is not to extract a sentence butto utilise the theme information.
The U matrixof the analysis provides information about howwell words correspond to a particular theme.We examine the first column of the U matrix,sum the elements and then normalize eachelement by the sum to form a probability.
Thisprobability, which we refer to as the SVDprobability, is then used as the Content Selectionprobability in the Viterbi search algorithm.As an alternative to using the SVD probabilityand the Conditional Probability in isolation, aCombined Probability is calculated using theharmonic mean of the two.
The harmonic meanwas used in case the two componentprobabilities differed consistently in theirrespective orders of magnitude.
Intuitively,when calculating a combined probability, thisevens the importance of each componentprobability.To summarize, we end up with three alternativestrategies in estimating the Content SelectionProbability: the Conditional Probability, theSVD Probability and the Combined Probability.6 Experiments6.1 DataIn our experiments, we attempted to match theexperimental conditions of Witbrock and Mittal(1999).
We used news articles from the first sixmonths of the Reuters 1997 corpus (Jan 1997 toJune 1997).
Specifically, we only examinednews articles from the general Reuters category(GCAT) which covers primarily politics, sportand economics.
This category was chosen notbecause of any particular domain coverage butbecause other categories exhibited frequent useof tabular presentation.
The GCAT categorycontains in excess of 65,000 articles.
FollowingWitbrock and Mittal (1999), we randomlyselected 25,000 articles for training and a further1000 articles for testing, ensuring that there wasno overlap between the two data sets.
Duringthe training stage, we collected bigrams from theheadline data, and the frequency of wordsoccurring in headlines.6.2 Experiment DesignWe conducted an evaluation experiment tocompare the performance of the three ContentSelection strategies that we identified in Section5: the Conditional probability, the SVDprobability, and the Combined probability.
Wemeasure performance in terms of recall, i.e.
howmany of the words in the actual headline matchwords in the generated headline.2  The recallmetric is normalised to form a percentage bydividing the word overlap by the number ofwords in the actual headline.For each test article, we generated headlinesusing each of the three strategies.
For eachstrategy, we generated headlines of varyinglengths, ranging from length 1 to 13, where thelatter is the length of the longest headline foundin the test set.
We then compared the differentstrategies for generated headlines of equallength.To determine if differences in recall scores weresignificant, we used the Wilcoxon Matched PairsSigned Ranks (WMPSR) test (Seigel andCastellan, 1988).
In our case, for a particularpair of Content Selection strategies, the alternatehypothesis was that the choice of ContentSelection strategy affects recall performance.The null hypothesis held that there was nodifference between the two content selectionstrategies.
Our use of the non-parametric testwas motivated by the observation that recallscores were not normally distributed.
In fact,our results showed a positive skew for recallscores.
To begin with, we compared the recallscores of the SVD strategy and the Conditionalstrategy in one evaluation.
The strategy that wasfound to perform better was then compared withthe Combined strategy.2Word overlap, whilst the easiest way to evaluate thesummaries quantitatively, is an imprecise measureand must be interpreted with the knowledge that non-recall words in the generated headline might stillindicate clearly what the source document is about.In addition to the recall tests, we conducted ananalysis to determine the extent to which theSVD strategy and the Conditional probabilitystrategy were in agreement about which wordsto select for inclusion in the generated headline.For this analysis, we ignored the bigramprobability of the Realisation component andjust measured the agreement between the top nranking words selected by each content selectionstrategy.
Over the test set, we counted howmany words were selected by both strategies,just one strategy, and no strategies.
Bynormalising scores by the number of test cases,we determine the average agreement across thetest set.
We ran this experiment for a range ofdifferent values of N, ranging from 1 to 13, thelength of the longest headline in the test set.6.3 Results6.3.1 Recall ComparisonThe results for the comparison of recall scoresare presented in Table 1 and Table 2.
Table 1shows results of the WMPSR test whencomparing the SVD strategy with theConditional strategy.3  Since the Conditionalstrategy was found to perform better, we thencompared this with the Combined strategy, asshown in Table 2.
From Table 1, it is clear that,for all sentence lengths, there is a significantdifference between the SVD strategy and theConditional strategy, and so we reject the nullhypothesis.
Similarly, Table 2 shows that thereis a significant difference between theConditional strategy and the Combined strategy,and again we reject the null hypothesis.
Weconclude that SVD probability alone isoutperformed by the Conditional probability;however, using both probabilities together leadsto a better performance.3The performance of our Conditional strategy isroughly comparable to the results obtained by Banko,Mittal and Witbrock (2000), in which they reportrecall scores between 20% to 25%, depending on thelength of the generated headline.SentenceLengthAverageRecall :SVDAverageRecall :Cond.
ProbabilityRejectH01 03.68% 03.98% p ?
0.0 yes2 07.02% 06.97% p ?
0.5 yes3 10.05% 11.44% p ?
0.0 yes4 12.39% 13.90% p ?
0.0 yes5 14.21% 15.73% p ?0.0 yes6 15.57% 17.84% p ?1.1e-05 yes7 16.59% 19.14% p ?
1.8e-07 yes8 17.74% 20.30% p ?
1.3e-07 yes9 18.74% 21.33% p ?
1.3e-06 yes10 19.73% 22.44% p ?
1.0e-06 yes11 20.19% 23.50% p ?
2.2e-10 yes12 20.85% 24.54% p ?
4.4e-13 yes13 21.13% 25.13% p ?
1.4e-12 yesTable 1.
A comparison of recall scores for theSVD strategy and the Conditional strategy.SentenceLengthAverageRecall :CondAverageRecall :Combined ProbabilityRejectH01 03.98% 04.05% p ?
0.1305 yes2 06.97% 08.60% p ?
2.8e-13 yes3 11.44% 12.34% p ?
0.0007 yes4 13.90% 15.44% p ?
8.5e-09 yes5 15.73% 17.33% p ?
1.9e-09 yes6 17.84% 18.72% p ?
0.0003 yes7 19.14% 20.34% p ?
1.3e-05 yes8 20.30% 21.48% p ?
2.9e-06 yes9 21.33% 22.60% p ?
4.0e-06 yes10 22.44% 23.82% p ?
1.2e-06 yes11 23.50% 24.56% p ?
0.0003 yes12 24.54% 25.44% p ?
0.0008 yes13 25.13% 26.37% p ?
8.6e-06 yesTable 2.
A comparison of recall scores for theConditional strategy and the Combined strategy.6.3.2 Agreement between StrategiesThe agreement between strategies is presented inTable 3.
Interestingly, of the words recalled, themajority have only been selected by one contentselection strategy.
That is, the set of wordsrecalled by one content selection strategy do notnecessarily subsume the set recalled by theother.
This supports the results obtained in therecall comparison in which a combined strategyleads to higher recall.
Interestingly, the lastcolumn in the table shows that the potentialcombined recall is greater than the recallachieved by the combined strategy; we willreturn to this point in Section 6.4.SentenceLengthSelectedby neithermethodSelected byonly 1methodSelectedby bothmethodsTotalRecall1 91.6% 8.0% 0.3% 8.3%2 84.7% 14.1% 1.0% 15.1%3 79.9% 17.5% 2.5% 20.0%4 76.6% 19.3% 3.9% 23.2%5 73.8% 21.0% 5.1% 26.1%6 71.4% 22.1% 6.4% 28.5%7 69.6% 22.4% 7.8% 30.2%8 67.9% 22.9% 9.1% 32.0%9 66.4% 23.2% 12.3% 35.5%10 65.0% 23.5% 11.3% 34.8%11 63.9% 23.6% 12.3% 35.9%12 63.0% 23.6% 13.2% 36.8%13 62.1% 23.5% 14.3% 37.8%Table 3.
Agreement of words chosen betweenthe SVD strategy and the Conditionalprobability strategy to content selection6.4 DiscussionThe SVD strategy ultimately did not perform aswell ass we might have hoped.
There are anumber of possible reasons for this.1.
Whilst using the Combined probability didlead to a significantly improved result, thisincrease in recall was only small.
Indeed,the analysis of the agreement between theConditional strategy and the SVD strategyindicates that the current method ofcombining the two probabilities is notoptimal and that there is still considerablemargin for improvement.2.
Even though the recall of the SVD strategywas poorer by a only a few percent, the lackof improvement in recall is perplexing,given that we expected the thematicinformation to ensure words were used incorrect contexts.
There are several possibleexplanations, each warranting furtherinvestigation.
It may be the case that thethemes identified by the SVD analysis werequite narrow, each encompassing only smallnumber of sentences.
If this is the case,certain words occurring in sentences outsidethe theme would be given a lowerprobability even if they were good headlineword candidates.
Further investigation isnecessary to determine if this is a short-coming of our SVD strategy or an artefact ofthe domain.
For example, it might be thecase that the sentences of news articles arealready thematically quite dissimilar.3.
One might also question our experimentaldesign.
Perhaps the kind of improvementbrought about when using the SVDprobability cannot be measured by simplycounting recall.
Instead, it may be the casethat an evaluation involving a panel ofjudges is required to determine if thegenerated text is qualitatively better in termsof how faithful the summary is to theinformation in the source document.
Forexample, a summary that is more accuratemay not necessarily result in better recall.Finally, it is conceivable that the SVDstrategy might be more sensitive topreprocessing stages such as sentencedelimitation and stopword lists, which arenot necessary when using the Conditionalstrategy.Despite these outstanding questions, there arepragmatic benefits when using SVD.
Theconditional strategy requires a paired training setof summaries and source documents.
In ourcase, this was easily obtained by using headlinesin lieu of single sentence summaries.
However,in cases where a paired corpus is not availablefor training, the SVD strategy might be moreappropriate, given that the performance does notdiffer considerably.
In such a situation, acollection of documents is only necessary forcollecting bigram statistics.7 ConclusionCombining both the SVD probability andConditional probability marginally improvesrecall, lending support to the intuition thatthematic information may help generate bettersingle sentence summaries.
However, there arestill many unanswered questions.
In futurework, we intend to investigate these techniquesin a domain other than news text so that we candraw conclusions as to how well these strategiesgeneralise to other genres.
We also intend toconduct user evaluations to gauge the quality ofthe generated summaries for both theConditional and the SVD strategies.
Indeed, auser-based evaluation would be extremelyhelpful in determining if the thematicinformation provided by the SVD strategy doeshelp improve the veracity of the generatedsummaries.ReferencesBanko M., Mittal V., and Witbrock M. (2000)Headline generation based on statistical translation.In Proceedings of the 38th Annual Meeting of theAssociation for Computational Linguistics.Boguraev B., and Neff M. (2000) Discoursesegmentation in aid of document summarization.
InProceedings of the Hawaii InternationalConference on System Sciences (HICSS- 33),Minitrack on Digital Documents Understanding.Maui, Hawaii: IEEE.Borko, H., and Bernier, C. (1975) AbstractingConcepts and Methods.
New York: AcademicPress.Brandow, R., Mitze, K., and Rau, L. (1995)Automatic condensation of electronic publicationsby sentence selection.
In Information Processingand Management, 31(5), pages 675-685.Forney G. D. (1973) The Viterbi Algorithm.
In theProceedings of the IEEE, pages 268-278.Gong Y., and Liu, X.
(2001) Generic TextSummarization Using Relevance Measure andLatent Semantic Analysis.
In the ProceedingsSIGIR 2001: pages 19-25.Hovy, E. and Lin, C. (1997) Automated textsummarization in SUMMARIST.
In theProceedings of ACL-EACL?97 Workshop onIntelligent Scalable Text Summarization, pages 18-24.Jin, R., and Hauptmann, A.
(2001) Learning to SelectGood Title Words: An New Approach based onReversed Information Retrieval.
In theProceedings of the Eighteen InternationalConference on Machine Learning (ICML 2001),Williams College,MA, June 28-July 1.Jin, R., Zhai, C., and Hauptmann, A.
(2002) Titlelanguage model for information retrieval.
In theProceedings of the 25th Annual International ACMSIGIR Conference on Research and Developmentin Information Retrieval (SIGIR 2002), Tampere,Finland, August 11-15.Jing, H., and McKeown, K. (1999) Thedecomposition of human-written summarysentences.
In the Proceedings of the 22ndConference on Research and Development inInformation Retrieval (SIGIR--99).Knight, K. and Marcu, D. (2000) Statistics-basedsummarization---Step one: Sentence compression.In Proceedings of AAAI-2000.Kupiec, J., Pedersen, J., and Chen, F. (1995) ATrainable Document Summarizer.
In Proceedingsof the 18th Annual International ACM SIGIRConference on Research and Development inInformation Retrieval.
Fox, E., Ingwersen, P., andFidel, R. (Editors), pages 68?73.Manning C. and Sch?tze H. (2000) Foundations ofStatistical Natural Language Processing.
MITPress: Cambridge MA.Marcu, D. (2000) The Theory and Practice ofDiscourse Parsing and Summarization.Cambridge: The MIT Press.McKeown, K., Klavans, J., Hatzivassiloglou, V.,Barzilay, R., and Eskin, E. (1999) Towardsmultidocument summarization by reformulation:Progress and prospects.
In the Proceedings of theSixteenth National Conference on ArtificialIntelligence (AAAI--99).Paice, C. (1990) Constructing Literature Abstracts byComputers: Techniques and Prospects.
InInformation Processing and Management, Vol.
26,No.
1, pages 171?186.Radev, D. and McKeown, K. (1998) Generatingnatural language summaries from multiple on-linesources.
Computational Linguistics, 24(3):469-500,September.Siegel, Sidney and Castellan, Jr. N. John.
(1988)Nonparametric Statistics For The BehavioralSciences.
McGraw-Hill, Inc., second edition.Witbrock, M., and Mittal, V. (1999)Ultrasummarization: A statistical approach togenerating highly condensed non-extractivesummaries.
In the Proceedings of the 22ndInternational Conference on Research andDevelopment in Information Retrieval (SIGIR '99).Zajic D., Door B., and Schwartz R. (2002) AutomaticHeadline Generation for Newspaper Stories.
In theProceedings of the Document UnderstandingConference (DUC 2002).
