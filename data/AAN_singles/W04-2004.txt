Syntactic parser combination for improved dependency analysisFrancis Brunet-ManquatLaboratoire CLIPS-IMAGCNRS ?
UJF - INPG385, rue de la  Biblioth?queBP 53 ?
38041 Grenoble Cedex 9, FranceFrancis.Brunet-Manquat@imag.frAbstractThe goal of this article is to present our workabout a combination of several syntacticparsers to produce a more robust parser.
Wehave built a platform which allows us tocompare syntactic parsers for a given languageby splitting their results in elementary pieces,normalizing them, and comparing them withreference results.
The same platform is used tocombine several parsers to produce adependency parser that has larger coverageand is more robust than its component parsers.In the future, it should be possible to?compile?
the knowledge extracted fromseveral analyzers into an autonomousdependency parser.1 IntroductionOur laboratory is involved in two internationalprojects: C-STAR (Blanchon and Boitet 2000),with its associated European project NESPOLE!,for speech translation and UNL, UniversalNetworking Language (S?rasset and Boitet 2000),for written translation.
These two projects arecharacterized by the use of a pivot representationof the utterance and by the fact that the utterance tobe translated is likely to be ?ill-formed?, i.e.
notconform to a academic language grammar.
In apivot system, an utterance in a source language isparsed to yield a pivot representation whichgenerate into a target language is performed.
Toprocess ill-formed data, we need robust analysistools capable of producing a partial analysis.The goal is to specify, design and develop amultilingual platform, called DepAn (DependencyAnalysis), which compares parsers for a givenlanguage by splitting their results in elementarypieces, normalizing them, and comparing themwith reference results, and which combine theseparsers to produce a dependency parser that haslarger coverage and is more robust than itscomponent parsers.The platform combines several analyses of thesame utterance, and then computes the best data toproduce the best possible analysis.
Our approach isbased on the method called ?vote by majority?, themore common to the different parsers one data willbe, the stronger its weight will be, and also basedon a training method which adapts each voteaccording to the typologies of utterances (domain,style) and the abilities of the parsers.The approach used, called c o m b i n a t i o napproach, has known lots of success in speechrecognition (Fiscus 1997, Schwenck and Gauvain2000), part of speech tagging (Halteren and al.1998, Brill and al.
1998, Marquez et Padro 1998),named entity recognition (Borthwick and al.
1998),word sense disambiguation (Pedersen, 2000) andrecently in parsing (Henderson and Brill 1999),Inui and Inui 2000, Monceaux and Robba 2003).These works prove that combining differentsystems provides an improvement in comparison tothe best system.Our work in syntactic analysis are distinguishedfrom our predecessors by the combination methodsthat we use.
Our platform is made up of astatistical processing, a correspondence processingand a reconstruction processing.
Furthermore, webase our platform on a dependency representationthat describes the syntactic relations betweenwords.
A study realized within the framework ofthe international projects, CSTAR and UNL,suggests that this representation type is adapted toa robust and partial parsing.2 Analysis platform designThe platform must not integrate the parsers, but itmust be able to extract the linguistic data fromtheir analyses, interpret them, combine them, andproduce a dependency tree (or several) combiningthe best extracted data.2.1 Processing stepsThe platform process comprizes two stages: thestandardization of the analysis results and theconstruction of the dependency analysis (seeFigure 1).The standardization is made up of two steps:?
The extraction step permits to recover thelinguistic data of analysis produced by thelinguistic parsers.
These parsers are shared outin three groups according to their analysisresults (Monceaux and Robba 2002): theparsers based on the chunks which segmentthe sentence in syntagms (chunks), the parsersbased on the dependencies which producedependencies between words of a sentence,and the parsers based on the chunks and thedependencies which segment the sentence insyntagms and produce dependencies betweensyntagms and words.?
The projection step process the extracted datato produce a set of dependency structures,called standardized structures.
a rate isassociated at each data (pos, syntacticrelations, etc.)
according to the parser whichproduces it.
These rates, called confidencerates, are pre-calculated during a training step(see 2.3 Confidence rate).
A dependencystructure is described by a matrixrepresentation offering both handiness andefficiency (see 2.2 Dependency matrix).The construction is made up of three steps:?
The correspondence step links the nodes of thedifferent normalized structures provided by theprevious step.
So, we create a structure, calledsegmentation network (SN), which representsthe different segmentations of a sentence andthe links between the nodes of the normalizedstructures.
This network represents the ?pivotl ink?
between these structures (see 3.1Correspondence of the dependency structures).?
The combination step according to establishedlinks produces a single dependencyrepresentation which contains all the extractedlinguistic data.
The resulting data can be suchas inconsistancies i.e.
a word can?t be both anoun and a verb (contradictory part-of-speech).The confidence rate of these data are  thenrecalculated (see 3.2 Combination of thelinguistic data).?
The production step  builds the newdependency structures according to thecombined data, their new confidence rates, andsome linguistic and structural constraints (see3.3 Production of the dependency structures).Figure 1: Functional architecture2.2 Dependency matrixOur analysis platform is based on thedependencies, i.e.
it produces dependenciesbetween the words of a sentence.
In our platform, adependency structure is described by a matrixrepresentation.
Our representation, calledDependency Matrix (DM), is made up of a couple<L,M>:?
L is a list of nodes.
A node is made up of a setof linguistic data (part of speech andgrammatical variable).
Each node represents aword.?
M  is a square matrix which describes thedependencies between the nodes of L. M(i,j)contains the set of syntactic dependenciesbetween i node and j node of L.Figure 2: Syntatic dependency structureThe DM corresponding to the syntacticdependency structure above is:L =la :: pos=determinantrecherche :: pos=nounfran?aise :: pos=adjectiveperd :: pos=verbses :: pos=determinantmoyens :: pos=nounM =A matrix representation has two advantages forthe automatic process:?
Handiness: mathematic tools are associated tomatrix: addition, deletion, comparison, etc.These tools permit a simple processing of thedata contained in the matrix.?
Effectiveness: efficient methods are associatedto matrix: pattern matching methods,combination methods, etc.We choose also to use a matrix representationbecause the combination of different dependencystructures provides a graph containing all thepossible dependencies.2.3 Confidence rate trainingIn (Brunet-Manquat 2003), we present projectionrules to transform the extracted data into a set ofnormalized data.
Each normalized data D  isassociated to a confidence rate of the data Daccording to the parser which produces it.The rates are calculated according to the parserevaluations.
For each parser?Ai , we calculate therecall and the accuracy of each linguistic data Dproduced by?Ai :?RecallAi(D) =number of corrected data Dnumber of reference data D?AccuracyAi(D) =number of corrected data Dnumber of nominated data DThe confidence rate corresponds to the F-measure which combines recall and accuracy in asingle measure:?F -measureAi(D) =(?
2 +1) ?AccuracyAi(D) ?RecallAi(D)?
2 ?AccuracyAi(D) + RecallAi(D)Where ?
is an accuracy coefficient, 1 ?
?
?
0.Within the framework of our work, we want tobe able to set our platform according to our needsin analysis: information retrieval, machinetranslation, parsing, etc.
We introduce theaccuracy coefficient ?
(between 0 and 1) into theF-measure.
It permits to customize the platformand so the final analysis: if ?
is close to 0, theaccuracy will be favoured in the calculation of theconfidence rate.
In the following, ?
will be equal to1.
It will be interesting to introduce a secondcoefficient for the recall (evaluation in progress).3 Dependency structure constructionAt the end of the normalization process, a set ofdependency strutures is associated to eachsentence.
The next step consists in combining thesestructures to obtain a single dependencyrepresentation which contains all the linguistic dataof these structures.
To perform this combination,we must put in correspondence these dependencystructures.3.1 Correspondence of the dependencystructuresThe structure correspondence consists inregrouping the nodes representing the same wordinto a sentence (the shared minimal data).
But itconsists also in representing the word conflictsproduced by the different segmentations of asentence because of, for example, compoundwords (words high energy or word high-energy),dictionnary terms (words United Kingdom or wordUnited_Kingdom), etc.In order to represent the correspondences, wecreate a structure, called segmentation network(SN), that represents the different segmentations ofa sentence and links the nodes of the normalizedstructures.
This network represents the ?pivot link?between these structures.A SN is a lattice; each node of this latticerepresents a possible segment of a word and servesto link the nodes of the dependency structures.
Inpractice, a node Nsnof a SN is made up of twodata:?
SNODE: a sequence which represents asubstring of a sentence.
For example, thewords of the sentence ?On avait d?nombr?cent vingt-neuf candidats?
have to SNODE:On[1,2], avait[3-7], d?nombr?
[8-15], etc.
Thisdata is based on the proposal of (Boitet andZaharin,1988) Structured String-TreeCorrespondences (SSTC).?
L: a set which contains the nodes of thenormalized structures linked to the node Nrs.The first step consists in creating an initial SNfor each dependency structure.
Each initial nodeNsnof an initial SN is created according to a nodeNiof the dependency structure Sk:SNODE(Nsn)=SNODE(Sk.Ni) & L(Nsn)={Sk.Ni}Then the nodes of the initial SN are inserted intothe lattice according to their appearance order intothe sentence (according to their SNODE).
In thefollowing, we take two dependency structures S1and S2, and their initial segmentation networks SN1and SN2:Let us do the correspondences between SN1andSN2.
First, the initial network SN1is chosen as thebasic SN, called SNbase.
We use two rules tointroduce the nodes of the others SN into the basicSN:?
Rule 1) Correspondence: If a node Niof SNkis equal to a node Nsnof the SNbase(equal ifSNODE(Ni)==SNODE(Nsn)), Nsnwill belinked to the node Ni: L(Nsn) = L(Nsn) ?
L(Ni).?
Rule 2) Insertion: If a node Niof SNkis notequal to a node of SNbase, this node will beinserted in SNbaseaccording to their SNODE.The first nodes on[1-2], avait[3-7], d?nombr?
[8-15] of SN2verify the first rule.
They correspond tothe nodes on[1-2], avait[3-7], d?nombr?
[8-15] ofSNbase.
The fourth node cent vingt-neuf[16-19] ofSN2verifies the second rule, so it is inserted intoSNbase.
The last node of SN2candidats[30-38]verifies the first rule.
We obtain the followinglattice:The final segmentation network represents thepossible segmentations of the sentence and linksthe nodes of structures between them1.
Now thecorrespondences between the nodes of thestructures are established, we can combine thesestructures to provide a single dependencyrepresentation, which combine all linguistic data ofthese structures.3.2 Combination of the linguistic dataThe correspondences between the differentstructures being established, the combination stepof linguistic data can begin.
The method used hereis based on the method known as ?majority vote?
:the more common to the different parsers one datawill be, the stronger its weight will be.At the end of the correspondence phase, a set ofdependency structures and a segmentation networkSN are associated to every sentence.
The first stageconsists in creating a dependency structure, calledcombined matrix CM (the nodes of the SN will beused as nodes for this representation) for eachsegmentation network.
This matrix is filled withthe linguistic data contained in the associateddependency structures.For example, we regroup dependencies for theprevious SNb:1In (Brunet-Manquat 2004), we propose to improve thecorrespondence step by adding correspondence rulesallowing processing the compound words or dictionaryterms, for example, by establishing a relation betweenthe node United_Kingdom and the nodes United andKingdom.Subsequently, we associate a confidence rate pfor each data:Each confidence rate could be seen as a weightedvote of a parser Aifor a data D. During a trainingphase, these rates (votes) will be adapted to thedifferent abilities of the parser according to thetypologies (domain, style) of the referenceutterances.Some linguistic data will be equivalent, someothers will be contradictory (for example thedependency Subject(x, y) is contradictory with thedependency Object(x, y), the part-of-speech aremutually contradictory into a same word).Finally, we group all the linguistic data Diof asentence S (Diis the data D provided by the parseri), and we calculate the new associated confidencerate, called combined rate, for each data D .
Acombined rate of a data D is calculated accordingto the confidence rates of all the data D .
Wepropose two calculations: standardized a n dcorrected calculations.Standardized calculation: the combined rate ofa data D is equal to the sum of the confidence ratesof the data Didivided by the number n of parsersthat can provide this data D:?Rcombined(D) =( Rconfidence(Di)i?
)nWhere i = parser producing the data D;n = number of parsers that can provide the data D.For example, let us calculate the combined rateassociated to the dependency OBJ(x, y) (the wordy is the object of the word x) provided by theparsers A1 and A2.
The combined rate associatedto OBJ(x, y) is equal to the sum of the twoconfidence rates provided by A1 and A2:confidence(OBJ::A1)=0.5 and confidence(OBJ::A2)=0.7, divided by the number of parsersthat can provide this type of information (three forthe example), (0.5+0.7+0)/3 = 0.4.
If the thirdparser provides an other dependency, for exampleSUBJ (x, y) (the word y is the subject of the wordx), and if the confidence rate of this data is 0.8, themerged rate associated to SUBJ(x, y) is equal to(0+0+0.8)/3 = 0.26.Corrected calculation: the combined rate of thedata D is equal to the sum of the confidence ratesof data Diminus the sum (multiplied by acorrection coefficient) of the confidence rates ofthe data contradictory to D, the whole divided bythe number of parsers that can provide the data D:?Rcombined(D) =( Rconfidence(Di)i????
Rconfidence(Dp)p?
)nWhere i = parser producing the data D;n = number of parsers that can provide the data D;p = parser producing a date contradictory to D.?
= an correction coefficient, 1 ?
?
?
0.For the previous example, the syntacticdependencies between words x and y arecontradictories: either OBJ(x, y), or SUBJ(x, y).The combined rate associated to OBJ(x, y) is equalto ((0.5+0.7) - (0.4*0.8))/3 = 0.29 (with acorrection coefficient at 0.4) and the combined rateassociated to SUBJ(x, y) is equal to (0.8 ?0.4*(0.5+0.7))/3 = 0.1.These two calculations favour the linguistic dataprovided by the greatest number of parsers.
Thecorrected calculation permits to treat both thesilence and the contradiction of others parsers.3.3 Production of the dependency structuresThis last step permits to build the new dependencystructures according to the data combined in theprevious step.
These structures are producedaccording to the combined rate associated to thesedata, and linguistic and structural constraints.
Theproduction is based on a constraint satisfactionmethod made up of three rules:Let D  be a part-of-speech or a grammaticalvariable of a combined matrix CM:?
For each node N  of CM, D  is kept if itscombined rate is higher than the combinedrates of the contradictory data.Let D be a syntactic relation of CM:?
Only one syntactic dependency between twonodes Niet Nkis kept: The data with the bestconfidence rate on the case CM(i, k) is kept;?
A node Nidepends on only one node Nk: In thecolumn CM(i), which represents thedependencies Nk?
Ni, only the data with thebest confidence rate is kept.Concerning the word conflicts resulting from thedifferent possible segmentations of a sentence, wechoose to keep only the nodes resulting from the?best?
word chunker among our parsers, i.e.
theparser with the word segmentation closer to thesegmentation of the reference corpus.
Soon we willintroduce a process that associates a segmentationrate to each node, which represents the confidenceon the word segmentation according to the parsers,like the confidence rate on the linguistic data.
Thisrate will permit us to introduce a segmentationconstraint in our production step.4 Experimentation and measures4.1 Parsers and corpusWe experiment our platform on French.
We havethree parsers for this evaluation: IFSP (IncrementalFinite-State Parser) (A?t-Mokhtar and Chanod1997) which builds the syntactic groups (chunks)of a sentence, and then uses the structure built toextract the syntactic dependencies between words,the parser of the GREYC (Vergne 1998) whichcombines tagging methods to build not-recursivechunks and a dependency algorithm to calculatethe dependency structure and XIP (XeroxIncremental Parser) (Ha?t-mokhtar and al.
2002)which has different linguistic processingsorganized in an incremental way (morphologicaltagging, chunk parsing, dependency extraction) toobtain an dependency analysis.The corpus used is the corpus of the universityParis VII (Abeill?
and Cl?ment 1999).
This corpusis made up of a million sentences extracted from?Le Monde?, a French newspaper.
The sentencesare chunked and the words tag.
A small part of thiscorpus was standardized to correspond to adependency corpus.
For this experimentation, weuse a reference corpus made up of 400 sentences,arbitrarily selected, made up of long and complexsentences, 30 words on average per sentence(minimum 9 words, maximum 73 words).
Forexample:?
La cessation de paiement constat?e, le tribunalde commerce nomme un administrateur judiciaire,qui doit ?valuer les dettes - alors gel?es - etproposer soit un plan de continuation, soit laliquidation judiciaire.
?4.2 TrainingThe first 200 sentences of the reference corpus areused in the training step.
Our experimentation isrestricted with 10 linguistic data: 6 part-of-speech(noun, verb, adjective, pronoun, preposition anddeterminant) and 4 syntactic dependencies(subject, object, complement and determinant).Figure 3 represents the global measures for thepart-of-speech.
Figure 4 represents the globalmeasures for the syntactic dependencies.The syntactic dependency measures are badbecause the word average per sentence of thereference corpus is high and also because thesentences are difficult to analyze.
The confidencerates (F-measure) of each part-of-speech (forexample, F-measure of noun pos: IFSP: 78,4%,GREYC: 77,8%, XIP: 79,9%) and each syntacticdependency (for example, F-measure of subjectpos: IFSP: 50,0%, GREYC: 36,4%, XIP: 50,5%)enable us to produce our combination results onthe 200 remaining sentences (see 3 Dependencystructure construction).76,985,881,181,880,281,082,879,781,270 75 80 85 90RecallAccuracyF-measurepercentageXIPGREYCIFSPFigure 3: Part-of-speech measures61,355,058,052,959,155,866,755,060,350 52 54 56 58 60 62 64 66 68RecallAccuracyF-measurePercentageXIPGREYCIFSPFigure 4: Syntactic dependency measures4.3 EvaluationWe evaluate our platform analysis and the otherparser analysis.
The platform DepAn uses thestandardized calculation to combine the linguisticdata (see 3.2 Combination of the linguistic data).The evaluation of part-of-speech tagging (seeFigure 5) shows that our approach permits asignificant gain of 2.6% in comparison to the bestparser according to the F-measure (DepAn: 86,3%and GREYC: 84,1%).
However, the gain is notsignificant for the evaluation of syntacticdependency (see Figure 6).
It is equal to 1.1% incomparison to the best parser (DepAn: 62,9% andXIP: 62,2%).This weak gain is understandable because thestandardized calculation used to combine all thedata D does not consider the data contradictory toD.
To improve the analysis, we propose anothercalculation combining the linguistic data, thecorrected calculation (see 3.2 Combination of thelinguistic data).
This calculation permits to treatboth silences and contradictions of others parsers.The evaluation of the platform with the correctedcalculation is currently in progress.79,887,283,386,082,384,185,477,781,486,586,186,370,0 72,0 74,0 76,0 78,0 80,0 82,0 84,0 86,0 88,0 90,0RecallAccuracyF-measurePercentageDePanXIPGREYCIFSPFigure 5: Part-of-speech measures61,060,760,855,258,056,669,756,262,270,856,662,950,0 55,0 60,0 65,0 70,0 75,0RecallAccuracyF-measurePercentageDePanXIPGREYCIFSPFigure 6: Syntactic dependency measures5 ConclusionThe platform DepAn allows us to comparesyntactic parsers for a given language by splittingtheir results in elementary pieces, normalizingthem, and comparing them with reference results.The same platform is used to combine severalparsers to produce a customized dependencyparser, which combines the different abilities ofthese parsers and which is adapted to the style orthe domain of the reference utterances.The evaluations show that our approach, acombination processing associated with astatistical processing, improve the analysis incomparition to the used parsers.
The gain is notsignificant for the moment but the futurecorrections will improve this gain.Our platform is currently tested on English.
Weuse the SUSANNE (http://www.grampson.net)corpus.
The SUSANNE Corpus was created, withthe sponsorship of the Economic and SocialResearch Council (UK), as part of the process ofdeveloping a comprehensive language-engineering-oriented taxonomy and annotationscheme for the logical and surface grammar ofEnglish.
The SUSANNE Corpus itself comprisesan approximately 130,000-word subset of theBrown Corpus of American English.In the short term, we also hope to combine otherparser types (semantic for example) to thesyntactic parsers to produce multilevel dependencystructures containing several linguistic levels:semantics, logic, syntactic, etc.
In the future, wehope to learn from the combination of severalparsers.
For example, it should by possible to?compile?
the knowledge extracted from theseparsers into an autonomous dependency parser.6 AcknowledgementsWe would like to express our special thanks to allthe creators of the parsers used here for enablingall of this research by providing their systems tous.ReferencesAbeill?
A. and L. Cl?ment (1999).
A taggedreference corpus for French, LINC?99Proceedings, EACL workshop, Bergen.A?t-Mokhtar S. and Chanod JP.
(1997),Incremental finite-state parsing, in AppliedNatural Language Processing 1997, April 1997,Washington.Ait-Mokhtar S., Chanod JP.
and Roux C. (2002),Robustness beyond Shallowness: IncrementalDeep Parsing, in Natural Language Engineering,8 (2/3), pp 121-144, Cambridge UniversityPress.Blanchon H. and Boitet C. (2000).
SpeechTranslation for French within the C-STAR IIConsortium and Future Perspectives.
Proc.ICSLP 2000.
Beijing, China, Oct. 16-20, 2000.vol 4/4: pp.
412-417.Boitet Ch.
and Zaharin Y.
(1988), ?Representationtrees and string-tree correspondences?
,published in COLING-88, pp 59-64.Brill E. and Wu J.
(1998) Classifier Combinaisonfor Improved Lexical Disambiguation.
In Proc.of the 17thCOLING, pp.
191-195.Brothwick A., Sterling J., Agichtein E. andGrishman R. (1998) Exploiting diverseknowledge sources via maximum entropy innamed entity recognition.
Proceedings of thesixth workshop on very large corpora, pages152-160, Montreal.Brunet-Manquat F. (2004), ?Description etconception d?une plate-forme robuste combinantdes analyseurs d??nonc?
?, journal on line ISDM,vol.
13, f?vrier 2004, 12 pages.Brunet-Manquat F. (2003), ?Fusionner pour mieuxanalyser: quelques id?es et une premi?reexp?rience?, In Proc.
Of RECITAL-2003, Batz-sur-mer, France, 10-14 juin 2003.
Vol 1/2, pp429-438.Fiscus J.G.
(1997), ?A post-processing system toyield reduced error word rates: Recognizeroutput voting error reduction (ROVER)?,published in IEEE Workshop on AutomaticSpeech Recognizer and Understanding, pp 347-354.Halteren H., J. Zavrel and W. Daelemans (1998).Improving data driven wordclass tagging bysystem combination .
In Proc.
of the 17thCOLING.Henderson, J. C. and Bril E. (1999).
ExploitingDiversity in Natural Language Processing:Combining Parsers.
In Proc.
of the 1999SIGDAT Conference on EMNLP and VLC, pp.187-194.Illouz G. (1999), ?M?ta-?tiqueteur adaptatif: versune utilisation pragmatique des resourceslinguistiques?, published in TALN?99.Inui T. and Inui K. (2000), Committee-basedDecision Making in Probabilistic PartielParsing, In Proc.
of COLING-2000.Marquez and Padro (1998).
On the evaluation andcomparaison of taggers?
: the effect of noise intest corpora.
Actes COLING/ACL?98, Montreal,Canada.Monceaux L. and Isabelle Robba I.
(2002), ?Lesanalyseurs syntaxiques?
: atouts pour une analysedes questions dans un syst?me de question-r?ponse??
?, Actes de TALN?2003, pp.195-204.Pedersen T. (2000), A Simple Approach toBuilding Ensembles of Naive BayesianClassifiers for Word Sense Disambigusation InProc.
of the NAACL, pp.
63-69, 2000.S?rasset G. and Boitet C. (2000).
On UNL as thefuture "html of the linguistic content" & thereuse of existing NLP components in UNL-related applications with the example of a UNL-French deconverter, Proc.
of COLING-2000,Saarbr?cken, 31 July ?
3 August 2000Schwenk H. and Gauvain J.L.
(2000), ?Combiningmultiple speech recognizers using voting andlanguage model information?, published in IEEEInternational Conference on Speech andLanguage Processing (ICSLP), pp.
II:915-918.Vergne J. and Giguet E. (1998), Regards th?oriquesur le ??Tagging?
?, Actes de TALN?1998, pp 24-33.
